{
  "metadata": {
    "timestamp": 1736560793180,
    "page": 486,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQ5MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "worldveil/dejavu",
      "stars": 6475,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.041015625,
          "content": "*.pyc\nwav\nmp3\n*.wav\n*.mp3\n.DS_Store\n*.cnf\n"
        },
        {
          "name": "INSTALLATION.md",
          "type": "blob",
          "size": 1.8984375,
          "content": "# Installation of Dejavu\n\nSo far Dejavu has only been tested on Unix systems.\n\n* [`pyaudio`](http://people.csail.mit.edu/hubert/pyaudio/) for grabbing audio from microphone\n* [`ffmpeg`](https://github.com/FFmpeg/FFmpeg) for converting audio files to .wav format\n* [`pydub`](http://pydub.com/), a Python `ffmpeg` wrapper\n* [`numpy`](http://www.numpy.org/) for taking the FFT of audio signals\n* [`scipy`](http://www.scipy.org/), used in peak finding algorithms\n* [`matplotlib`](http://matplotlib.org/), used for spectrograms and plotting\n* [`MySQLdb`](http://mysql-python.sourceforge.net/MySQLdb.html) for interfacing with MySQL databases\n\nFor installing `ffmpeg` on Mac OS X, I highly recommend [this post](http://jungels.net/articles/ffmpeg-howto.html).\n\n## Fedora 20+\n\n### Dependency installation on Fedora 20+\n\nInstall the dependencies:\n\n    sudo yum install numpy scipy python-matplotlib ffmpeg portaudio-devel\n    pip install PyAudio\n    pip install pydub\n    \nNow setup virtualenv ([howto?](http://www.pythoncentral.io/how-to-install-virtualenv-python/)):\n\n    pip install virtualenv\n    virtualenv --system-site-packages env_with_system\n\nInstall from PyPI:\n\n    source env_with_system/bin/activate\n    pip install PyDejavu\n\n\nYou can also install the latest code from GitHub:\n\n    source env_with_system/bin/activate\n    pip install https://github.com/worldveil/dejavu/zipball/master\n\n## Max OS X\n\n### Dependency installation for Mac OS X\n\nTested on OS X Mavericks. An option is to install [Homebrew](http://brew.sh) and do the following:\n\n```\nbrew install portaudio\nbrew install ffmpeg\n\nsudo easy_install pyaudio\nsudo easy_install pydub\nsudo easy_install numpy\nsudo easy_install scipy\nsudo easy_install matplotlib\nsudo easy_install pip\n\nsudo pip install MySQL-python\n\nsudo ln -s /usr/local/mysql/lib/libmysqlclient.18.dylib /usr/lib/libmysqlclient.18.dylib\n```\n\nHowever installing `portaudio` and/or `ffmpeg` from source is also doable. \n"
        },
        {
          "name": "LICENSE.md",
          "type": "blob",
          "size": 1.044921875,
          "content": "### MIT License\n\nCopyright (c) 2013 Will Drevo\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.0244140625,
          "content": "include requirements.txt\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 15.419921875,
          "content": "dejavu\n==========\n\nAudio fingerprinting and recognition algorithm implemented in Python, see the explanation here:  \n[How it works](http://willdrevo.com/fingerprinting-and-audio-recognition-with-python/)\n\nDejavu can memorize audio by listening to it once and fingerprinting it. Then by playing a song and recording microphone input or reading from disk, Dejavu attempts to match the audio against the fingerprints held in the database, returning the song being played. \n\nNote: for voice recognition, *Dejavu is not the right tool!* Dejavu excels at recognition of exact signals with reasonable amounts of noise.\n\n## Quickstart with Docker\n\nFirst, install [Docker](https://docs.docker.com/get-docker/).\n\n```shell\n# build and then run our containers\n$ docker-compose build\n$ docker-compose up -d\n\n# get a shell inside the container\n$ docker-compose run python /bin/bash\nStarting dejavu_db_1 ... done\nroot@f9ea95ce5cea:/code# python example_docker_postgres.py \nFingerprinting channel 1/2 for test/woodward_43s.wav\nFingerprinting channel 1/2 for test/sean_secs.wav\n...\n\n# connect to the database and poke around\nroot@f9ea95ce5cea:/code# psql -h db -U postgres dejavu\nPassword for user postgres:  # type \"password\", as specified in the docker-compose.yml !\npsql (11.7 (Debian 11.7-0+deb10u1), server 10.7)\nType \"help\" for help.\n\ndejavu=# \\dt\n            List of relations\n Schema |     Name     | Type  |  Owner   \n--------+--------------+-------+----------\n public | fingerprints | table | postgres\n public | songs        | table | postgres\n(2 rows)\n\ndejavu=# select * from fingerprints limit 5;\n          hash          | song_id | offset |        date_created        |       date_modified        \n------------------------+---------+--------+----------------------------+----------------------------\n \\x71ffcb900d06fe642a18 |       1 |    137 | 2020-06-03 05:14:19.400153 | 2020-06-03 05:14:19.400153\n \\xf731d792977330e6cc9f |       1 |    148 | 2020-06-03 05:14:19.400153 | 2020-06-03 05:14:19.400153\n \\x71ff24aaeeb55d7b60c4 |       1 |    146 | 2020-06-03 05:14:19.400153 | 2020-06-03 05:14:19.400153\n \\x29349c79b317d45a45a8 |       1 |    101 | 2020-06-03 05:14:19.400153 | 2020-06-03 05:14:19.400153\n \\x5a052144e67d2248ccf4 |       1 |    123 | 2020-06-03 05:14:19.400153 | 2020-06-03 05:14:19.400153\n(10 rows)\n\n# then to shut it all down...\n$ docker-compose down\n```\n\nIf you want to be able to use the microphone with the Docker container, you'll need to do a [little extra work](https://stackoverflow.com/questions/43312975/record-sound-on-ubuntu-docker-image). I haven't had the time to write this up, but if anyone wants to make a PR, I'll happily merge.\n\n## Docker alternative on local machine\n\nFollow instructions in [INSTALLATION.md](INSTALLATION.md)\n\nNext, you'll need to create a MySQL database where Dejavu can store fingerprints. For example, on your local setup:\n\t\n\t$ mysql -u root -p\n\tEnter password: **********\n\tmysql> CREATE DATABASE IF NOT EXISTS dejavu;\n\nNow you're ready to start fingerprinting your audio collection! \n\nYou may also use Postgres, of course. The same method applies.\n\n## Fingerprinting\n\nLet's say we want to fingerprint all of July 2013's VA US Top 40 hits. \n\nStart by creating a Dejavu object with your configurations settings (Dejavu takes an ordinary Python dictionary for the settings).\n\n```python\n>>> from dejavu import Dejavu\n>>> config = {\n...     \"database\": {\n...         \"host\": \"127.0.0.1\",\n...         \"user\": \"root\",\n...         \"password\": <password above>, \n...         \"database\": <name of the database you created above>,\n...     }\n... }\n>>> djv = Dejavu(config)\n```\n\nNext, give the `fingerprint_directory` method three arguments:\n* input directory to look for audio files\n* audio extensions to look for in the input directory\n* number of processes (optional)\n\n```python\n>>> djv.fingerprint_directory(\"va_us_top_40/mp3\", [\".mp3\"], 3)\n```\n\nFor a large amount of files, this will take a while. However, Dejavu is robust enough you can kill and restart without affecting progress: Dejavu remembers which songs it fingerprinted and converted and which it didn't, and so won't repeat itself. \n\nYou'll have a lot of fingerprints once it completes a large folder of mp3s:\n```python\n>>> print djv.db.get_num_fingerprints()\n5442376\n```\n\nAlso, any subsequent calls to `fingerprint_file` or `fingerprint_directory` will fingerprint and add those songs to the database as well. It's meant to simulate a system where as new songs are released, they are fingerprinted and added to the database seemlessly without stopping the system. \n\n## Configuration options\n\nThe configuration object to the Dejavu constructor must be a dictionary. \n\nThe following keys are mandatory:\n\n* `database`, with a value as a dictionary with keys that the database you are using will accept. For example with MySQL, the keys must can be anything that the [`MySQLdb.connect()`](http://mysql-python.sourceforge.net/MySQLdb.html) function will accept. \n\nThe following keys are optional:\n\n* `fingerprint_limit`: allows you to control how many seconds of each audio file to fingerprint. Leaving out this key, or alternatively using `-1` and `None` will cause Dejavu to fingerprint the entire audio file. Default value is `None`.\n* `database_type`: `mysql` (the default value) and `postgres` are supported. If you'd like to add another subclass for `BaseDatabase` and implement a new type of database, please fork and send a pull request!\n\nAn example configuration is as follows:\n\n```python\n>>> from dejavu import Dejavu\n>>> config = {\n...     \"database\": {\n...         \"host\": \"127.0.0.1\",\n...         \"user\": \"root\",\n...         \"password\": \"Password123\", \n...         \"database\": \"dejavu_db\",\n...     },\n...     \"database_type\" : \"mysql\",\n...     \"fingerprint_limit\" : 10\n... }\n>>> djv = Dejavu(config)\n```\n\n## Tuning\n\nInside `config/settings.py`, you may want to adjust following parameters (some values are given below).\n\n    FINGERPRINT_REDUCTION = 30\n    PEAK_SORT = False\n    DEFAULT_OVERLAP_RATIO = 0.4\n    DEFAULT_FAN_VALUE = 5\n    DEFAULT_AMP_MIN = 10\n    PEAK_NEIGHBORHOOD_SIZE = 10\n    \nThese parameters are described within the file in detail. Read that in-order to understand the impact of changing these values.\n\n## Recognizing\n\nThere are two ways to recognize audio using Dejavu. You can recognize by reading and processing files on disk, or through your computer's microphone.\n\n### Recognizing: On Disk\n\nThrough the terminal:\n\n```bash\n$ python dejavu.py --recognize file sometrack.wav \n{'total_time': 2.863781690597534, 'fingerprint_time': 2.4306554794311523, 'query_time': 0.4067542552947998, 'align_time': 0.007731199264526367, 'results': [{'song_id': 1, 'song_name': 'Taylor Swift - Shake It Off', 'input_total_hashes': 76168, 'fingerprinted_hashes_in_db': 4919, 'hashes_matched_in_input': 794, 'input_confidence': 0.01, 'fingerprinted_confidence': 0.16, 'offset': -924, 'offset_seconds': -30.00018, 'file_sha1': b'3DC269DF7B8DB9B30D2604DA80783155912593E8'}, {...}, ...]}\n```\n\nor in scripting, assuming you've already instantiated a Dejavu object: \n\n```python\n>>> from dejavu.logic.recognizer.file_recognizer import FileRecognizer\n>>> song = djv.recognize(FileRecognizer, \"va_us_top_40/wav/Mirrors - Justin Timberlake.wav\")\n```\n\n### Recognizing: Through a Microphone\n\nWith scripting:\n\n```python\n>>> from dejavu.logic.recognizer.microphone_recognizer import MicrophoneRecognizer\n>>> song = djv.recognize(MicrophoneRecognizer, seconds=10) # Defaults to 10 seconds.\n```\n\nand with the command line script, you specify the number of seconds to listen:\n\n```bash\n$ python dejavu.py --recognize mic 10\n```\n\n## Testing\n\nTesting out different parameterizations of the fingerprinting algorithm is often useful as the corpus becomes larger and larger, and inevitable tradeoffs between speed and accuracy come into play. \n\n![Confidence](plots/confidence.png)\n\nTest your Dejavu settings on a corpus of audio files on a number of different metrics:\n\n* Confidence of match (number fingerprints aligned)\n* Offset matching accuracy\n* Song matching accuracy\n* Time to match\n\n![Accuracy](plots/matching_graph.png)\n\nAn example script is given in `test_dejavu.sh`, shown below:\n\n```bash\n#####################################\n### Dejavu example testing script ###\n#####################################\n\n###########\n# Clear out previous results\nrm -rf ./results ./temp_audio\n\n###########\n# Fingerprint files of extension mp3 in the ./mp3 folder\npython dejavu.py --fingerprint ./mp3/ mp3\n\n##########\n# Run a test suite on the ./mp3 folder by extracting 1, 2, 3, 4, and 5 \n# second clips sampled randomly from within each song 8 seconds \n# away from start or end, sampling offset with random seed = 42, and finally, \n# store results in ./results and log to ./results/dejavu-test.log\npython run_tests.py \\\n    --secs 5 \\\n    --temp ./temp_audio \\\n    --log-file ./results/dejavu-test.log \\\n    --padding 8 \\\n    --seed 42 \\\n    --results ./results \\\n    ./mp3\n```\n\nThe testing scripts are as of now are a bit rough, and could certainly use some love and attention if you're interested in submitting a PR! For example, underscores in audio filenames currently [breaks](https://github.com/worldveil/dejavu/issues/63) the test scripts. \n\n## How does it work?\n\nThe algorithm works off a fingerprint based system, much like:\n\n* [Shazam](http://www.ee.columbia.edu/~dpwe/papers/Wang03-shazam.pdf)\n* [MusicRetrieval](http://www.cs.cmu.edu/~yke/musicretrieval/)\n* [Chromaprint](https://oxygene.sk/2011/01/how-does-chromaprint-work/)\n\nThe \"fingerprints\" are locality sensitive hashes that are computed from the spectrogram of the audio. This is done by taking the FFT of the signal over overlapping windows of the song and identifying peaks. A very robust peak finding algorithm is needed, otherwise you'll have a terrible signal to noise ratio.\n\nHere I've taken the spectrogram over the first few seconds of \"Blurred Lines\". The spectrogram is a 2D plot and shows amplitude as a function of time (a particular window, actually) and frequency, binned logrithmically, just as the human ear percieves it. In the plot below you can see where local maxima occur in the amplitude space:\n\n![Spectrogram](plots/spectrogram_peaks.png)\n\nFinding these local maxima is a combination of a high pass filter (a threshold in amplitude space) and some image processing techniques to find maxima. A concept of a \"neighboorhood\" is needed - a local maxima with only its directly adjacent pixels is a poor peak - one that will not survive the noise of coming through speakers and through a microphone.\n\nIf we zoom in even closer, we can begin to imagine how to bin and discretize these peaks. Finding the peaks itself is the most computationally intensive part, but it's not the end. Peaks are combined using their discrete time and frequency bins to create a unique hash for that particular moment in the song - creating a fingerprint.\n\n![Spectgram zoomed](plots/spectrogram_zoomed.png)\n\nFor a more detailed look at the making of Dejavu, see my blog post [here](https://willdrevo.com/fingerprinting-and-audio-recognition-with-python/).\n\n## How well it works\n\nTo truly get the benefit of an audio fingerprinting system, it can't take a long time to fingerprint. It's a bad user experience, and furthermore, a user may only decide to try to match the song with only a few precious seconds of audio left before the radio station goes to a commercial break.\n\nTo test Dejavu's speed and accuracy, I fingerprinted a list of 45 songs from the US VA Top 40 from July 2013 (I know, their counting is off somewhere). I tested in three ways:\n\n1. Reading from disk the raw mp3 -> wav data, and\n1. Playing the song over the speakers with Dejavu listening on the laptop microphone.\n1. Compressed streamed music played on my iPhone\n\nBelow are the results.\n\n### 1. Reading from Disk\n\nReading from disk was an overwhelming 100% recall - no mistakes were made over the 45 songs I fingerprinted. Since Dejavu gets all of the samples from the song (without noise), it would be nasty surprise if reading the same file from disk didn't work every time!\n\n### 2. Audio over laptop microphone\n\nHere I wrote a script to randomly chose `n` seconds of audio from the original mp3 file to play and have Dejavu listen over the microphone. To be fair I only allowed segments of audio that were more than 10 seconds from the starting/ending of the track to avoid listening to silence. \n\nAdditionally my friend was even talking and I was humming along a bit during the whole process, just to throw in some noise.\n\nHere are the results for different values of listening time (`n`):\n\n![Matching time](plots/accuracy.png)\n\nThis is pretty rad. For the percentages:\n\nNumber of Seconds | Number Correct | Percentage Accuracy\n----|----|----\n1 | 27 / 45 | 60.0%\n2 | 43 / 45 | 95.6%\n3 | 44 / 45 | 97.8%\n4 | 44 / 45 | 97.8%\n5 | 45 / 45 | 100.0%\n6 | 45 / 45 | 100.0%\n\nEven with only a single second, randomly chosen from anywhere in the song, Dejavu is getting 60%! One extra second to 2 seconds get us to around 96%, while getting perfect only took 5 seconds or more. Honestly when I was testing this myself, I found Dejavu beat me - listening to only 1-2 seconds of a song out of context to identify is pretty hard. I had even been listening to these same songs for two days straight while debugging...\n\nIn conclusion, Dejavu works amazingly well, even with next to nothing to work with. \n\n### 3. Compressed streamed music played on my iPhone\n\nJust to try it out, I tried playing music from my Spotify account (160 kbit/s compressed) through my iPhone's speakers with Dejavu again listening on my MacBook mic. I saw no degredation in performance; 1-2 seconds was enough to recognize any of the songs.\n\n## Performance\n\n### Speed\n\nOn my MacBook Pro, matching was done at 3x listening speed with a small constant overhead. To test, I tried different recording times and plotted the recording time plus the time to match. Since the speed is mostly invariant of the particular song and more dependent on the length of the spectrogram created, I tested on a single song, \"Get Lucky\" by Daft Punk:\n\n![Matching time](plots/matching_time.png)\n\nAs you can see, the relationship is quite linear. The line you see is a least-squares linear regression fit to the data, with the corresponding line equation:\n\n    1.364757 * record_time - 0.034373 = time_to_match\n    \nNotice of course since the matching itself is single threaded, the matching time includes the recording time. This makes sense with the 3x speed in purely matching, as:\n    \n    1 (recording) + 1/3 (matching) = 4/3 ~= 1.364757\n    \nif we disregard the miniscule constant term.\n\nThe overhead of peak finding is the bottleneck - I experimented with multithreading and realtime matching, and alas, it wasn't meant to be in Python. An equivalent Java or C/C++ implementation would most likely have little trouble keeping up, applying FFT and peakfinding in realtime.\n\nAn important caveat is of course, the round trip time (RTT) for making matches. Since my MySQL instance was local, I didn't have to deal with the latency penalty of transfering fingerprint matches over the air. This would add RTT to the constant term in the overall calculation, but would not effect the matching process. \n\n### Storage\n\nFor the 45 songs I fingerprinted, the database used 377 MB of space for 5.4 million fingerprints. In comparison, the disk usage is given below:\n\nAudio Information Type | Storage in MB \n----|----\nmp3 | 339\nwav | 1885\nfingerprints | 377\n\nThere's a pretty direct trade-off between the necessary record time and the amount of storage needed. Adjusting the amplitude threshold for peaks and the fan value for fingerprinting will add more fingerprints and bolster the accuracy at the expense of more space. "
        },
        {
          "name": "dejavu.cnf.SAMPLE",
          "type": "blob",
          "size": 0.16796875,
          "content": "{\n    \"database\": {\n        \"host\": \"127.0.0.1\",\n        \"user\": \"root\",\n        \"password\": \"rootpass\",\n        \"database\": \"dejavu\"\n    },\n    \"database_type\": \"mysql\"\n}\n"
        },
        {
          "name": "dejavu.py",
          "type": "blob",
          "size": 2.9140625,
          "content": "import argparse\nimport json\nimport sys\nfrom argparse import RawTextHelpFormatter\nfrom os.path import isdir\n\nfrom dejavu import Dejavu\nfrom dejavu.logic.recognizer.file_recognizer import FileRecognizer\nfrom dejavu.logic.recognizer.microphone_recognizer import MicrophoneRecognizer\n\nDEFAULT_CONFIG_FILE = \"dejavu.cnf.SAMPLE\"\n\n\ndef init(configpath):\n    \"\"\"\n    Load config from a JSON file\n    \"\"\"\n    try:\n        with open(configpath) as f:\n            config = json.load(f)\n    except IOError as err:\n        print(f\"Cannot open configuration: {str(err)}. Exiting\")\n        sys.exit(1)\n\n    # create a Dejavu instance\n    return Dejavu(config)\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser(\n        description=\"Dejavu: Audio Fingerprinting library\",\n        formatter_class=RawTextHelpFormatter)\n    parser.add_argument('-c', '--config', nargs='?',\n                        help='Path to configuration file\\n'\n                             'Usages: \\n'\n                             '--config /path/to/config-file\\n')\n    parser.add_argument('-f', '--fingerprint', nargs='*',\n                        help='Fingerprint files in a directory\\n'\n                             'Usages: \\n'\n                             '--fingerprint /path/to/directory extension\\n'\n                             '--fingerprint /path/to/directory')\n    parser.add_argument('-r', '--recognize', nargs=2,\n                        help='Recognize what is '\n                             'playing through the microphone or in a file.\\n'\n                             'Usage: \\n'\n                             '--recognize mic number_of_seconds \\n'\n                             '--recognize file path/to/file \\n')\n    args = parser.parse_args()\n\n    if not args.fingerprint and not args.recognize:\n        parser.print_help()\n        sys.exit(0)\n\n    config_file = args.config\n    if config_file is None:\n        config_file = DEFAULT_CONFIG_FILE\n\n    djv = init(config_file)\n    if args.fingerprint:\n        # Fingerprint all files in a directory\n        if len(args.fingerprint) == 2:\n            directory = args.fingerprint[0]\n            extension = args.fingerprint[1]\n            print(f\"Fingerprinting all .{extension} files in the {directory} directory\")\n            djv.fingerprint_directory(directory, [\".\" + extension], 4)\n\n        elif len(args.fingerprint) == 1:\n            filepath = args.fingerprint[0]\n            if isdir(filepath):\n                print(\"Please specify an extension if you'd like to fingerprint a directory!\")\n                sys.exit(1)\n            djv.fingerprint_file(filepath)\n\n    elif args.recognize:\n        # Recognize audio source\n        songs = None\n        source = args.recognize[0]\n        opt_arg = args.recognize[1]\n\n        if source in ('mic', 'microphone'):\n            songs = djv.recognize(MicrophoneRecognizer, seconds=opt_arg)\n        elif source == 'file':\n            songs = djv.recognize(FileRecognizer, opt_arg)\n        print(songs)\n"
        },
        {
          "name": "dejavu",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker-compose.yaml",
          "type": "blob",
          "size": 0.37109375,
          "content": "version: '3'\nservices:\n  db:\n    build:\n      context: ./docker/postgres\n    environment:\n      - POSTGRES_DB=dejavu\n      - POSTGRES_USER=postgres\n      - POSTGRES_PASSWORD=password\n    networks:\n      - db_network\n  python:\n    build:\n      context: ./docker/python\n    volumes:\n      - .:/code\n    depends_on:\n      - db\n    networks:\n      - db_network\nnetworks:\n  db_network:"
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "example_docker_postgres.py",
          "type": "blob",
          "size": 1.07421875,
          "content": "import json\n\nfrom dejavu import Dejavu\nfrom dejavu.logic.recognizer.file_recognizer import FileRecognizer\nfrom dejavu.logic.recognizer.microphone_recognizer import MicrophoneRecognizer\n\n# load config from a JSON file (or anything outputting a python dictionary)\nconfig = {\n    \"database\": {\n        \"host\": \"db\",\n        \"user\": \"postgres\",\n        \"password\": \"password\",\n        \"database\": \"dejavu\"\n    },\n    \"database_type\": \"postgres\"\n}\n\nif __name__ == '__main__':\n\n    # create a Dejavu instance\n    djv = Dejavu(config)\n\n    # Fingerprint all the mp3's in the directory we give it\n    djv.fingerprint_directory(\"test\", [\".wav\"])\n\n    # Recognize audio from a file\n    results = djv.recognize(FileRecognizer, \"mp3/Josh-Woodward--I-Want-To-Destroy-Something-Beautiful.mp3\")\n    print(f\"From file we recognized: {results}\\n\")\n\n    # Or use a recognizer without the shortcut, in anyway you would like\n    recognizer = FileRecognizer(djv)\n    results = recognizer.recognize_file(\"mp3/Josh-Woodward--I-Want-To-Destroy-Something-Beautiful.mp3\")\n    print(f\"No shortcut, we recognized: {results}\\n\")\n"
        },
        {
          "name": "example_script.py",
          "type": "blob",
          "size": 1.3017578125,
          "content": "import json\n\nfrom dejavu import Dejavu\nfrom dejavu.logic.recognizer.file_recognizer import FileRecognizer\nfrom dejavu.logic.recognizer.microphone_recognizer import MicrophoneRecognizer\n\n# load config from a JSON file (or anything outputting a python dictionary)\nwith open(\"dejavu.cnf.SAMPLE\") as f:\n    config = json.load(f)\n\nif __name__ == '__main__':\n\n    # create a Dejavu instance\n    djv = Dejavu(config)\n\n    # Fingerprint all the mp3's in the directory we give it\n    djv.fingerprint_directory(\"test\", [\".wav\"])\n\n    # Recognize audio from a file\n    results = djv.recognize(FileRecognizer, \"mp3/Josh-Woodward--I-Want-To-Destroy-Something-Beautiful.mp3\")\n    print(f\"From file we recognized: {results}\\n\")\n\n    # Or recognize audio from your microphone for `secs` seconds\n    secs = 5\n    results = djv.recognize(MicrophoneRecognizer, seconds=secs)\n    if results is None:\n        print(\"Nothing recognized -- did you play the song out loud so your mic could hear it? :)\")\n    else:\n        print(f\"From mic with {secs} seconds we recognized: {results}\\n\")\n\n    # Or use a recognizer without the shortcut, in anyway you would like\n    recognizer = FileRecognizer(djv)\n    results = recognizer.recognize_file(\"mp3/Josh-Woodward--I-Want-To-Destroy-Something-Beautiful.mp3\")\n    print(f\"No shortcut, we recognized: {results}\\n\")\n"
        },
        {
          "name": "mp3",
          "type": "tree",
          "content": null
        },
        {
          "name": "plots",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.119140625,
          "content": "pydub==0.23.1\nPyAudio==0.2.11\nnumpy==1.17.2\nscipy==1.3.1\nmatplotlib==3.1.1\nmysql-connector-python==8.0.17\npsycopg2==2.8.3\n"
        },
        {
          "name": "run_tests.py",
          "type": "blob",
          "size": 6.3271484375,
          "content": "import argparse\nimport logging\nimport time\nfrom os import makedirs\nfrom os.path import exists, join\nfrom shutil import rmtree\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom dejavu.tests.dejavu_test import (DejavuTest, autolabeldoubles,\n                                      generate_test_files, log_msg, set_seed)\n\n\ndef main(seconds: int, results_folder: str, temp_folder: str, log: bool, silent: bool,\n         log_file: str, padding: int, seed: int, src: str):\n\n    # set random seed if set by user\n    set_seed(seed)\n\n    # ensure results folder exists\n    if not exists(results_folder):\n        makedirs(results_folder)\n\n    # set logging\n    if log:\n        logging.basicConfig(filename=log_file, level=logging.DEBUG)\n\n    # set test seconds\n    test_seconds = [f'{i}sec' for i in range(1, seconds + 1, 1)]\n\n    # generate testing files\n    for i in range(1, seconds + 1, 1):\n        generate_test_files(src, temp_folder, i, padding=padding)\n\n    # scan files\n    log_msg(f\"Running Dejavu fingerprinter on files in {src}...\", log=log, silent=silent)\n\n    tm = time.time()\n    djv = DejavuTest(temp_folder, test_seconds)\n    log_msg(f\"finished obtaining results from dejavu in {(time.time() - tm)}\", log=log, silent=silent)\n\n    tests = 1  # djv\n    n_secs = len(test_seconds)\n\n    # set result variables -> 4d variables\n    all_match_counter = [[[0 for x in range(tests)] for x in range(3)] for x in range(n_secs)]\n    all_matching_times_counter = [[[0 for x in range(tests)] for x in range(2)] for x in range(n_secs)]\n    all_query_duration = [[[0 for x in range(tests)] for x in range(djv.n_lines)] for x in range(n_secs)]\n    all_match_confidence = [[[0 for x in range(tests)] for x in range(djv.n_lines)] for x in range(n_secs)]\n\n    # group results by seconds\n    for line in range(0, djv.n_lines):\n        for col in range(0, djv.n_columns):\n            # for dejavu\n            all_query_duration[col][line][0] = djv.result_query_duration[line][col]\n            all_match_confidence[col][line][0] = djv.result_match_confidence[line][col]\n\n            djv_match_result = djv.result_match[line][col]\n\n            if djv_match_result == 'yes':\n                all_match_counter[col][0][0] += 1\n            elif djv_match_result == 'no':\n                all_match_counter[col][1][0] += 1\n            else:\n                all_match_counter[col][2][0] += 1\n\n            djv_match_acc = djv.result_matching_times[line][col]\n\n            if djv_match_acc == 0 and djv_match_result == 'yes':\n                all_matching_times_counter[col][0][0] += 1\n            elif djv_match_acc != 0:\n                all_matching_times_counter[col][1][0] += 1\n\n    # create plots\n    djv.create_plots('Confidence', all_match_confidence, results_folder)\n    djv.create_plots('Query duration', all_query_duration, results_folder)\n\n    for sec in range(0, n_secs):\n        ind = np.arange(3)\n        width = 0.25  # the width of the bars\n\n        fig = plt.figure()\n        ax = fig.add_subplot(111)\n        ax.set_xlim([-1 * width, 2.75])\n\n        means_dvj = [round(x[0] * 100 / djv.n_lines, 1) for x in all_match_counter[sec]]\n        rects1 = ax.bar(ind, means_dvj, width, color='r')\n\n        # add some\n        ax.set_ylabel('Matching Percentage')\n        ax.set_title(f'{test_seconds[sec]} Matching Percentage')\n        ax.set_xticks(ind + width)\n\n        labels = ['yes', 'no', 'invalid']\n        ax.set_xticklabels(labels)\n\n        box = ax.get_position()\n        ax.set_position([box.x0, box.y0, box.width * 0.75, box.height])\n        autolabeldoubles(rects1, ax)\n        plt.grid()\n\n        fig_name = join(results_folder, f\"matching_perc_{test_seconds[sec]}.png\")\n        fig.savefig(fig_name)\n\n    for sec in range(0, n_secs):\n        ind = np.arange(2)\n        width = 0.25  # the width of the bars\n\n        fig = plt.figure()\n        ax = fig.add_subplot(111)\n        ax.set_xlim([-1 * width, 1.75])\n\n        div = all_match_counter[sec][0][0]\n        if div == 0:\n            div = 1000000\n\n        means_dvj = [round(x[0] * 100 / div, 1) for x in all_matching_times_counter[sec]]\n        rects1 = ax.bar(ind, means_dvj, width, color='r')\n\n        # add some\n        ax.set_ylabel('Matching Accuracy')\n        ax.set_title(f'{test_seconds[sec]} Matching Times Accuracy')\n        ax.set_xticks(ind + width)\n\n        labels = ['yes', 'no']\n        ax.set_xticklabels(labels)\n\n        box = ax.get_position()\n        ax.set_position([box.x0, box.y0, box.width * 0.75, box.height])\n        autolabeldoubles(rects1, ax)\n\n        plt.grid()\n\n        fig_name = join(results_folder, f\"matching_acc_{test_seconds[sec]}.png\")\n        fig.savefig(fig_name)\n\n    # remove temporary folder\n    rmtree(temp_folder)\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser(description=f'Runs a few tests for dejavu to evaluate '\n                                                 f'its configuration performance. '\n                                                 f'Usage: %(prog).py [options] TESTING_AUDIOFOLDER'\n                                     )\n\n    parser.add_argument(\"-sec\", \"--seconds\", action=\"store\", default=5, type=int,\n                        help='Number of seconds starting from zero to test.')\n    parser.add_argument(\"-res\", \"--results-folder\", action=\"store\", default=\"./dejavu_test_results\",\n                        help='Sets the path where the results are saved.')\n    parser.add_argument(\"-temp\", \"--temp-folder\", action=\"store\", default=\"./dejavu_temp_testing_files\",\n                        help='Sets the path where the temp files are saved.')\n    parser.add_argument(\"-l\", \"--log\", action=\"store_true\", default=False, help='Enables logging.')\n    parser.add_argument(\"-sl\", \"--silent\", action=\"store_false\", default=False, help='Disables printing.')\n    parser.add_argument(\"-lf\", \"--log-file\", default=\"results-compare.log\",\n                        help='Set the path and filename of the log file.')\n    parser.add_argument(\"-pad\", \"--padding\", action=\"store\", default=10, type=int,\n                        help='Number of seconds to pad choice of place to test from.')\n    parser.add_argument(\"-sd\", \"--seed\", action=\"store\", default=None, type=int, help='Random seed.')\n    parser.add_argument(\"src\", type=str, help='Source folder for audios to use as tests.')\n\n    args = parser.parse_args()\n\n    main(args.seconds, args.results_folder, args.temp_folder, args.log, args.silent, args.log_file, args.padding,\n         args.seed, args.src)\n"
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.03125,
          "content": "[flake8]\nmax-line-length = 120\n\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 1.97265625,
          "content": "from setuptools import find_packages, setup\n\n\ndef parse_requirements(requirements):\n    # load from requirements.txt\n    with open(requirements) as f:\n        lines = [l for l in f]\n        # remove spaces\n        stripped = list(map((lambda x: x.strip()), lines))\n        # remove comments\n        nocomments = list(filter((lambda x: not x.startswith('#')), stripped))\n        # remove empty lines\n        reqs = list(filter((lambda x: x), nocomments))\n        return reqs\n\n\nPACKAGE_NAME = \"PyDejavu\"\nPACKAGE_VERSION = \"0.1.3\"\nSUMMARY = 'Dejavu: Audio Fingerprinting in Python'\nDESCRIPTION = \"\"\"\nAudio fingerprinting and recognition algorithm implemented in Python\n\nSee the explanation here:\n\n`http://willdrevo.com/fingerprinting-and-audio-recognition-with-python/`__\n\nDejavu can memorize recorded audio by listening to it once and fingerprinting\nit. Then by playing a song and recording microphone input or on disk file,\nDejavu attempts to match the audio against the fingerprints held in the\ndatabase, returning the song or recording being played.\n\n__ http://willdrevo.com/fingerprinting-and-audio-recognition-with-python/\n\"\"\"\nREQUIREMENTS = parse_requirements(\"requirements.txt\")\n\nsetup(\n    name=PACKAGE_NAME,\n    version=PACKAGE_VERSION,\n    description=SUMMARY,\n    long_description=DESCRIPTION,\n    author='Will Drevo',\n    author_email='will.drevo@gmail.com',\n    maintainer=\"Will Drevo\",\n    maintainer_email=\"will.drevo@gmail.com\",\n    url='http://github.com/worldveil/dejavu',\n    license='MIT License',\n    include_package_data=True,\n    packages=find_packages(),\n    platforms=['Unix'],\n    install_requires=REQUIREMENTS,\n    classifiers=[\n        'Development Status :: 4 - Beta',\n        'Environment :: Console',\n        'Intended Audience :: Developers',\n        'License :: OSI Approved :: MIT License',\n        'Operating System :: OS Independent',\n        'Topic :: Software Development :: Libraries :: Python Modules',\n    ],\n    keywords=\"python, audio, fingerprinting, music, numpy, landmark\",\n)\n"
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "test_dejavu.sh",
          "type": "blob",
          "size": 0.701171875,
          "content": "#####################################\n### Dejavu example testing script ###\n#####################################\n\n###########\n# Clear out previous results\nrm -rf ./results ./temp_audio\n\n###########\n# Fingerprint files of extension mp3 in the ./mp3 folder\npython dejavu.py -f ./mp3/ mp3\n\n##########\n# Run a test suite on the ./mp3 folder by extracting 1, 2, 3, 4, and 5 \n# second clips sampled randomly from within each song 8 seconds \n# away from start or end, sampling with random seed = 42, and finally \n# store results in ./results and log to dejavu-test.log\npython run_tests.py \\\n\t--secs 5 \\\n\t--temp ./temp_audio \\\n\t--log-file ./results/dejavu-test.log \\\n\t--padding 8 \\\n\t--seed 42 \\\n\t--results ./results \\\n\t./mp3\n"
        }
      ]
    }
  ]
}