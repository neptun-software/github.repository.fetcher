{
  "metadata": {
    "timestamp": 1736560859173,
    "page": 566,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjU3MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "KevinMusgrave/pytorch-metric-learning",
      "stars": 6066,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".flake8",
          "type": "blob",
          "size": 0.3271484375,
          "content": "[flake8]\n\nextend-ignore =\n    # too many leading '#' for block comment\n    E266 \n    # whitespace before ':'\n    E203 \n    # module level import not at top of file\n    E402 \n    # line too long\n    E501 \n    # ambiguous variable names\n    E741 \n    # block comment should start with #\n    E265 \n\nper-file-ignores =\n    __init__.py:F401"
        },
        {
          "name": ".git-blame-ignore-revs",
          "type": "blob",
          "size": 0.10546875,
          "content": "# Switch to unix newlines\nec2a6fe862d8bd1a22c5e3a60051921569fe654a\n025e647af5bdf6262c162e811c97ee0feea3f6a9\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.361328125,
          "content": "__pycache__/\n*.py[cod]\n.nfs*\nbuild/\ndist/\n*.egg-info/\nsite/\nvenv/\n**/.vscode\n.ipynb_checkpoints\nexamples/notebooks/dataset\nexamples/notebooks/CIFAR10_Dataset\nexamples/notebooks/CIFAR100_Dataset\nexamples/notebooks/example_logs\nexamples/notebooks/example_saved_models\nexamples/notebooks/example_tensorboard\nexamples/notebooks/data\nexamples/notebooks/pytorch_resnet_cifar10"
        },
        {
          "name": "CONTENTS.md",
          "type": "blob",
          "size": 18.861328125,
          "content": "## Library contents\n\n### [Datasets](https://kevinmusgrave.github.io/pytorch-metric-learning/datasets)\n| Name | Reference Papers |\n|---|---|\n| [**CUB**](https://kevinmusgrave.github.io/pytorch-metric-learning/datasets/#cub-200-2011) | [The caltech-ucsd birds-200-2011 dataset](https://authors.library.caltech.edu/27452/1/CUB_200_2011.pdf)\n| [**Cars196**](https://kevinmusgrave.github.io/pytorch-metric-learning/datasets/#cars196) | 3D Object Representations for Fine-Grained Categorization\n| [**INaturalist2018**](https://kevinmusgrave.github.io/pytorch-metric-learning/datasets/#inaturalist2018) | [The iNaturalist Species Classification and Detection Dataset](https://openaccess.thecvf.com/content_cvpr_2018/papers/Van_Horn_The_INaturalist_Species_CVPR_2018_paper.pdf)\n| [**StanfordOnlineProducts**](https://kevinmusgrave.github.io/pytorch-metric-learning/datasets/#stanfordonlineproducts) | [Deep Metric Learning via Lifted Structured Feature Embedding](https://cvgl.stanford.edu/papers/song_cvpr16.pdf)\n\n\n### [Distances](https://kevinmusgrave.github.io/pytorch-metric-learning/distances)\n| Name | Reference Papers |\n|---|---|\n| [**CosineSimilarity**](https://kevinmusgrave.github.io/pytorch-metric-learning/distances/#cosinesimilarity) |\n| [**DotProductSimilarity**](https://kevinmusgrave.github.io/pytorch-metric-learning/distances/#dotproductsimilarity) |\n| [**LpDistance**](https://kevinmusgrave.github.io/pytorch-metric-learning/distances/#lpdistance) |\n| [**SNRDistance**](https://kevinmusgrave.github.io/pytorch-metric-learning/distances/#snrdistance) | [Signal-to-Noise Ratio: A Robust Distance Metric for Deep Metric Learning](http://openaccess.thecvf.com/content_CVPR_2019/papers/Yuan_Signal-To-Noise_Ratio_A_Robust_Distance_Metric_for_Deep_Metric_Learning_CVPR_2019_paper.pdf)\n\n### [Losses](https://kevinmusgrave.github.io/pytorch-metric-learning/losses)\n| Name | Reference Papers |\n|---|---|\n| [**AngularLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#angularloss) | [Deep Metric Learning with Angular Loss](https://arxiv.org/pdf/1708.01682.pdf)\n| [**ArcFaceLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#arcfaceloss) | [ArcFace: Additive Angular Margin Loss for Deep Face Recognition](https://arxiv.org/pdf/1801.07698.pdf)\n| [**CircleLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#circleloss) | [Circle Loss: A Unified Perspective of Pair Similarity Optimization](https://arxiv.org/pdf/2002.10857.pdf)\n| [**ContrastiveLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#contrastiveloss) | [Dimensionality Reduction by Learning an Invariant Mapping](http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf)\n| [**CosFaceLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#cosfaceloss) | - [CosFace: Large Margin Cosine Loss for Deep Face Recognition](https://arxiv.org/pdf/1801.09414.pdf) <br/> - [Additive Margin Softmax for Face Verification](https://arxiv.org/pdf/1801.05599.pdf)\n| [**DynamicSoftMarginLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#dynamicsoftmarginloss) | [Learning Local Descriptors With a CDF-Based Dynamic Soft Margin](https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhang_Learning_Local_Descriptors_With_a_CDF-Based_Dynamic_Soft_Margin_ICCV_2019_paper.pdf)\n| [**FastAPLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#fastaploss) | [Deep Metric Learning to Rank](http://openaccess.thecvf.com/content_CVPR_2019/papers/Cakir_Deep_Metric_Learning_to_Rank_CVPR_2019_paper.pdf)\n| [**GeneralizedLiftedStructureLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#generalizedliftedstructureloss) | [In Defense of the Triplet Loss for Person Re-Identification](https://arxiv.org/pdf/1703.07737.pdf)\n| [**HistogramLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#histogramloss) | [Learning Deep Embeddings with Histogram Loss](https://arxiv.org/pdf/1611.00822.pdf)\n| [**InstanceLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#instanceloss) | [Dual-Path Convolutional Image-Text Embeddings with Instance Loss](https://arxiv.org/pdf/1711.05535.pdf)\n| [**IntraPairVarianceLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#intrapairvarianceloss) | [Deep Metric Learning with Tuplet Margin Loss](http://openaccess.thecvf.com/content_ICCV_2019/papers/Yu_Deep_Metric_Learning_With_Tuplet_Margin_Loss_ICCV_2019_paper.pdf)\n| [**LargeMarginSoftmaxLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#largemarginsoftmaxloss) | [Large-Margin Softmax Loss for Convolutional Neural Networks](https://arxiv.org/pdf/1612.02295.pdf)\n| [**LiftedStructreLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#liftedstructureloss) | [Deep Metric Learning via Lifted Structured Feature Embedding](https://arxiv.org/pdf/1511.06452.pdf)\n| [**ManifoldLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#manifoldloss) | [Ensemble Deep Manifold Similarity Learning using Hard Proxies](https://openaccess.thecvf.com/content_CVPR_2019/papers/Aziere_Ensemble_Deep_Manifold_Similarity_Learning_Using_Hard_Proxies_CVPR_2019_paper.pdf)\n| [**MarginLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#marginloss) | [Sampling Matters in Deep Embedding Learning](https://arxiv.org/pdf/1706.07567.pdf)\n| [**MultiSimilarityLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#multisimilarityloss) | [Multi-Similarity Loss with General Pair Weighting for Deep Metric Learning](http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Multi-Similarity_Loss_With_General_Pair_Weighting_for_Deep_Metric_Learning_CVPR_2019_paper.pdf)\n| [**NCALoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#ncaloss) | [Neighbourhood Components Analysis](https://www.cs.toronto.edu/~hinton/absps/nca.pdf)\n| [**NormalizedSoftmaxLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#normalizedsoftmaxloss) | - [NormFace: L2 Hypersphere Embedding for Face Verification](https://arxiv.org/pdf/1704.06369.pdf) <br/> - [Classification is a Strong Baseline for DeepMetric Learning](https://arxiv.org/pdf/1811.12649.pdf)\n| [**NPairsLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#npairsloss) | [Improved Deep Metric Learning with Multi-class N-pair Loss Objective](http://www.nec-labs.com/uploads/images/Department-Images/MediaAnalytics/papers/nips16_npairmetriclearning.pdf)\n| [**NTXentLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#ntxentloss) | - [Representation Learning with Contrastive Predictive Coding](https://arxiv.org/pdf/1807.03748.pdf) <br/> - [Momentum Contrast for Unsupervised Visual Representation Learning](https://arxiv.org/pdf/1911.05722.pdf) <br/> - [A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/abs/2002.05709)\n| [**P2SGradLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#p2sgradloss) | [P2SGrad: Refined Gradients for Optimizing Deep Face Models](https://arxiv.org/abs/1905.02479)\n| [**PNPLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#pnploss) | [Rethinking the Optimization of Average Precision: Only Penalizing Negative Instances before Positive Ones is Enough](https://arxiv.org/pdf/2102.04640.pdf)\n| [**ProxyAnchorLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#proxyanchorloss) | [Proxy Anchor Loss for Deep Metric Learning](https://arxiv.org/pdf/2003.13911.pdf)\n| [**ProxyNCALoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#proxyncaloss) | [No Fuss Distance Metric Learning using Proxies](https://arxiv.org/pdf/1703.07464.pdf)\n| [**RankedListLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#rankedlistloss) | [Ranked List Loss for Deep Metric Learning](https://arxiv.org/abs/1903.03238)\n| [**SignalToNoiseRatioContrastiveLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#signaltonoiseratiocontrastiveloss) | [Signal-to-Noise Ratio: A Robust Distance Metric for Deep Metric Learning](http://openaccess.thecvf.com/content_CVPR_2019/papers/Yuan_Signal-To-Noise_Ratio_A_Robust_Distance_Metric_for_Deep_Metric_Learning_CVPR_2019_paper.pdf)\n| [**SoftTripleLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#softtripleloss) | [SoftTriple Loss: Deep Metric Learning Without Triplet Sampling](http://openaccess.thecvf.com/content_ICCV_2019/papers/Qian_SoftTriple_Loss_Deep_Metric_Learning_Without_Triplet_Sampling_ICCV_2019_paper.pdf)\n| [**SphereFaceLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#spherefaceloss) | [SphereFace: Deep Hypersphere Embedding for Face Recognition](https://arxiv.org/pdf/1704.08063.pdf)\n| [**SubCenterArcFaceLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#subcenterarcfaceloss) | [Sub-center ArcFace: Boosting Face Recognition by Large-scale Noisy Web Faces](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123560715.pdf)\n| [**SupConLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#supconloss) | [Supervised Contrastive Learning](https://arxiv.org/abs/2004.11362)\n| [**ThresholdConsistentMarginLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#thresholdconsistentmarginloss) | [Threshold-Consistent Margin Loss for Open-World Deep Metric Learning](https://arxiv.org/pdf/2307.04047)\n| [**TripletMarginLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#tripletmarginloss) | [Distance Metric Learning for Large Margin Nearest Neighbor Classification](https://papers.nips.cc/paper/2795-distance-metric-learning-for-large-margin-nearest-neighbor-classification.pdf)\n| [**TupletMarginLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#tupletmarginloss) | [Deep Metric Learning with Tuplet Margin Loss](http://openaccess.thecvf.com/content_ICCV_2019/papers/Yu_Deep_Metric_Learning_With_Tuplet_Margin_Loss_ICCV_2019_paper.pdf)\n| [**VICRegLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#vicregloss) | [VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning](https://arxiv.org/pdf/2105.04906.pdf)\n\n### [Miners](https://kevinmusgrave.github.io/pytorch-metric-learning/miners)\n| Name | Reference Papers |\n|---|---|\n| [**AngularMiner**](https://kevinmusgrave.github.io/pytorch-metric-learning/miners/#angularminer) |\n| [**BatchEasyHardMiner**](https://kevinmusgrave.github.io/pytorch-metric-learning/miners/#batcheasyhardminer) | [Improved Embeddings with Easy Positive Triplet Mining](http://openaccess.thecvf.com/content_WACV_2020/papers/Xuan_Improved_Embeddings_with_Easy_Positive_Triplet_Mining_WACV_2020_paper.pdf) \n| [**BatchHardMiner**](https://kevinmusgrave.github.io/pytorch-metric-learning/miners/#batchhardminer) | [In Defense of the Triplet Loss for Person Re-Identification](https://arxiv.org/pdf/1703.07737.pdf)\n| [**DistanceWeightedMiner**](https://kevinmusgrave.github.io/pytorch-metric-learning/miners/#distanceweightedminer) | [Sampling Matters in Deep Embedding Learning](https://arxiv.org/pdf/1706.07567.pdf)\n| [**EmbeddingsAlreadyPackagedAsTriplets**](https://kevinmusgrave.github.io/pytorch-metric-learning/miners/#embeddingsalreadypackagedastriplets) | \n| [**HDCMiner**](https://kevinmusgrave.github.io/pytorch-metric-learning/miners/#hdcminer) | [Hard-Aware Deeply Cascaded Embedding](http://openaccess.thecvf.com/content_ICCV_2017/papers/Yuan_Hard-Aware_Deeply_Cascaded_ICCV_2017_paper.pdf)\n| [**MultiSimilarityMiner**](https://kevinmusgrave.github.io/pytorch-metric-learning/miners/#multisimilarityminer) | [Multi-Similarity Loss with General Pair Weighting for Deep Metric Learning](http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Multi-Similarity_Loss_With_General_Pair_Weighting_for_Deep_Metric_Learning_CVPR_2019_paper.pdf)\n| [**PairMarginMiner**](https://kevinmusgrave.github.io/pytorch-metric-learning/miners/#pairmarginminer) | \n| [**TripletMarginMiner**](https://kevinmusgrave.github.io/pytorch-metric-learning/miners/#tripletmarginminer) | [FaceNet: A Unified Embedding for Face Recognition and Clustering](https://arxiv.org/pdf/1503.03832.pdf)\n| [**UniformHistogramMiner**](https://kevinmusgrave.github.io/pytorch-metric-learning/miners/#uniformhistogramminer) |\n\n### [Reducers](https://kevinmusgrave.github.io/pytorch-metric-learning/reducers)\n| Name | Reference Papers |\n|---|---|\n| [**AvgNonZeroReducer**](https://kevinmusgrave.github.io/pytorch-metric-learning/reducers/#avgnonzeroreducer)\n| [**ClassWeightedReducer**](https://kevinmusgrave.github.io/pytorch-metric-learning/reducers/#classweightedreducer)\n| [**DivisorReducer**](https://kevinmusgrave.github.io/pytorch-metric-learning/reducers/#divisorreducer)\n| [**DoNothingReducer**](https://kevinmusgrave.github.io/pytorch-metric-learning/reducers/#donothingreducer)\n| [**MeanReducer**](https://kevinmusgrave.github.io/pytorch-metric-learning/reducers/#meanreducer)\n| [**PerAnchorReducer**](https://kevinmusgrave.github.io/pytorch-metric-learning/reducers/#peranchorreducer)\n| [**ThresholdReducer**](https://kevinmusgrave.github.io/pytorch-metric-learning/reducers/#thresholdreducer)\n\n### [Regularizers](https://kevinmusgrave.github.io/pytorch-metric-learning/regularizers)\n| Name | Reference Papers |\n|---|---|\n| [**CenterInvariantRegularizer**](https://kevinmusgrave.github.io/pytorch-metric-learning/regularizers/#centerinvariantregularizer) | [Deep Face Recognition with Center Invariant Loss](http://www1.ece.neu.edu/~yuewu/files/2017/twu024.pdf)\n| [**LpRegularizer**](https://kevinmusgrave.github.io/pytorch-metric-learning/regularizers/#lpregularizer) | \n| [**RegularFaceRegularizer**](https://kevinmusgrave.github.io/pytorch-metric-learning/regularizers/#regularfaceregularizer) | [RegularFace: Deep Face Recognition via Exclusive Regularization](http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhao_RegularFace_Deep_Face_Recognition_via_Exclusive_Regularization_CVPR_2019_paper.pdf)\n| [**SparseCentersRegularizer**](https://kevinmusgrave.github.io/pytorch-metric-learning/regularizers/#sparsecentersregularizer) | [SoftTriple Loss: Deep Metric Learning Without Triplet Sampling](http://openaccess.thecvf.com/content_ICCV_2019/papers/Qian_SoftTriple_Loss_Deep_Metric_Learning_Without_Triplet_Sampling_ICCV_2019_paper.pdf)\n| [**ZeroMeanRegularizer**](https://kevinmusgrave.github.io/pytorch-metric-learning/regularizers/#zeromeanregularizer) | [Signal-to-Noise Ratio: A Robust Distance Metric for Deep Metric Learning](http://openaccess.thecvf.com/content_CVPR_2019/papers/Yuan_Signal-To-Noise_Ratio_A_Robust_Distance_Metric_for_Deep_Metric_Learning_CVPR_2019_paper.pdf)\n\n### [Samplers](https://kevinmusgrave.github.io/pytorch-metric-learning/samplers)\n| Name | Reference Papers |\n|---|---|\n| [**MPerClassSampler**](https://kevinmusgrave.github.io/pytorch-metric-learning/samplers/#mperclasssampler) |\n| [**HierarchicalSampler**](https://kevinmusgrave.github.io/pytorch-metric-learning/samplers/#hierarchicalsampler) | [Deep Metric Learning to Rank](http://openaccess.thecvf.com/content_CVPR_2019/papers/Cakir_Deep_Metric_Learning_to_Rank_CVPR_2019_paper.pdf)\n| [**TuplesToWeightsSampler**](https://kevinmusgrave.github.io/pytorch-metric-learning/samplers/#tuplestoweightssampler) |\n| [**FixedSetOfTriplets**](https://kevinmusgrave.github.io/pytorch-metric-learning/samplers/#fixedsetoftriplets) |\n\n### [Trainers](https://kevinmusgrave.github.io/pytorch-metric-learning/trainers)\n| Name | Reference Papers |\n|---|---|\n| [**MetricLossOnly**](https://kevinmusgrave.github.io/pytorch-metric-learning/trainers/#metriclossonly)\n| [**TrainWithClassifier**](https://kevinmusgrave.github.io/pytorch-metric-learning/trainers/#trainwithclassifier)\n| [**CascadedEmbeddings**](https://kevinmusgrave.github.io/pytorch-metric-learning/trainers/#cascadedembeddings) | [Hard-Aware Deeply Cascaded Embedding](http://openaccess.thecvf.com/content_ICCV_2017/papers/Yuan_Hard-Aware_Deeply_Cascaded_ICCV_2017_paper.pdf)\n| [**DeepAdversarialMetricLearning**](https://kevinmusgrave.github.io/pytorch-metric-learning/trainers/#deepadversarialmetriclearning) | [Deep Adversarial Metric Learning](http://openaccess.thecvf.com/content_cvpr_2018/papers/Duan_Deep_Adversarial_Metric_CVPR_2018_paper.pdf)\n| [**TwoStreamMetricLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/trainers/#twostreammetricloss) |\n\n### [Testers](https://kevinmusgrave.github.io/pytorch-metric-learning/testers)\n| Name | Reference Papers |\n|---|---|\n| [**GlobalEmbeddingSpaceTester**](https://kevinmusgrave.github.io/pytorch-metric-learning/testers/#globalembeddingspacetester) |\n| [**WithSameParentLabelTester**](https://kevinmusgrave.github.io/pytorch-metric-learning/testers/#withsameparentlabeltester) |\n| [**GlobalTwoStreamEmbeddingSpaceTester**](https://kevinmusgrave.github.io/pytorch-metric-learning/testers/#globaltwostreamembeddingspacetester) |\n\n### Utils\n| Name | Reference Papers |\n|---|---|\n| [**AccuracyCalculator**](https://kevinmusgrave.github.io/pytorch-metric-learning/accuracy_calculation) | \n| [**HookContainer**](https://kevinmusgrave.github.io/pytorch-metric-learning/logging_presets) | \n| [**InferenceModel**](https://kevinmusgrave.github.io/pytorch-metric-learning/inference_models) |\n| [**TorchInitWrapper**](https://kevinmusgrave.github.io/pytorch-metric-learning/common_functions/#torchinitwrapper) |\n| [**DistributedLossWrapper**](https://kevinmusgrave.github.io/pytorch-metric-learning/distributed/#distributedlosswrapper) |\n| [**DistributedMinerWrapper**](https://kevinmusgrave.github.io/pytorch-metric-learning/distributed/#distributedminerwrapper) |\n\n### Base Classes, Mixins, and Wrappers\n| Name | Reference Papers |\n|---|---|\n| [**CrossBatchMemory**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#crossbatchmemory) | [Cross-Batch Memory for Embedding Learning](https://arxiv.org/pdf/1912.06798.pdf)\n| [**GenericPairLoss**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#genericpairloss) |\n| [**MultipleLosses**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#multiplelosses) |\n| [**MultipleReducers**](https://kevinmusgrave.github.io/pytorch-metric-learning/reducers/#multiplereducers) |\n| **EmbeddingRegularizerMixin** |\n| **WeightMixin** |\n| [**WeightRegularizerMixin**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#weightregularizermixin) |\n| [**BaseDistance**](https://kevinmusgrave.github.io/pytorch-metric-learning/distance/#basedistance) | \n| [**BaseMetricLossFunction**](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#basemetriclossfunction) | \n| [**BaseMiner**](https://kevinmusgrave.github.io/pytorch-metric-learning/miners/#baseminer) |\n| [**BaseReducer**](https://kevinmusgrave.github.io/pytorch-metric-learning/reducers/#basereducer) |\n| [**BaseRegularizer**](https://kevinmusgrave.github.io/pytorch-metric-learning/regularizers/#baseregularizer) |\n| [**BaseTrainer**](https://kevinmusgrave.github.io/pytorch-metric-learning/trainers/#basetrainer) |\n| [**BaseTester**](https://kevinmusgrave.github.io/pytorch-metric-learning/testers/#basetester) |\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.064453125,
          "content": "MIT License\r\n\r\nCopyright (c) 2019 Kevin Musgrave\r\n\r\nPermission is hereby granted, free of charge, to any person obtaining a copy\r\nof this software and associated documentation files (the \"Software\"), to deal\r\nin the Software without restriction, including without limitation the rights\r\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\r\ncopies of the Software, and to permit persons to whom the Software is\r\nfurnished to do so, subject to the following conditions:\r\n\r\nThe above copyright notice and this permission notice shall be included in all\r\ncopies or substantial portions of the Software.\r\n\r\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\r\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\r\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\r\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\r\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\r\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\r\nSOFTWARE."
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 16.4267578125,
          "content": "<h1>\n<a href=\"https://github.com/KevinMusgrave/pytorch-metric-learning\">\n<img alt=\"PyTorch Metric Learning\" src=\"https://github.com/KevinMusgrave/pytorch-metric-learning/blob/master/docs/imgs/Logo2.png\">\n</a>\n</h1>\n\n<p align=\"center\">\n <a href=\"https://pypi.org/project/pytorch-metric-learning\">\n     <img alt=\"PyPi version\" src=\"https://img.shields.io/pypi/v/pytorch-metric-learning?color=bright-green\">\n </a>\n\t\n\t\n \n <a href=\"https://anaconda.org/conda-forge/pytorch-metric-learning\">\n     <img alt=\"Anaconda version\" src=\"https://img.shields.io/conda/v/conda-forge/pytorch-metric-learning?color=bright-green\">\n </a>\n</p>\n\n## News\n\n**December 11**: v2.8.0\n- Added the [Datasets](https://kevinmusgrave.github.io/pytorch-metric-learning/datasets) module for easy downloading of common datasets:\n  - [CUB200](https://kevinmusgrave.github.io/pytorch-metric-learning/datasets/#cub-200-2011)\n  - [Cars196](https://kevinmusgrave.github.io/pytorch-metric-learning/datasets/#cars196)\n  - [INaturalist 2018](https://kevinmusgrave.github.io/pytorch-metric-learning/datasets/#inaturalist2018)\n  - [Stanford Online Products](https://kevinmusgrave.github.io/pytorch-metric-learning/datasets/#stanfordonlineproducts)\n- Thank you [ir2718](https://github.com/ir2718).\n\n**November 2**: v2.7.0\n- Added [ThresholdConsistentMarginLoss](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#thresholdconsistentmarginloss).\n- Thank you [ir2718](https://github.com/ir2718).\n\n## Documentation\n- [**View the documentation here**](https://kevinmusgrave.github.io/pytorch-metric-learning/)\n- [**View the installation instructions here**](https://github.com/KevinMusgrave/pytorch-metric-learning#installation)\n- [**View the available losses, miners etc. here**](https://github.com/KevinMusgrave/pytorch-metric-learning/blob/master/CONTENTS.md) \n\n\n## Google Colab Examples\nSee the [examples folder](https://github.com/KevinMusgrave/pytorch-metric-learning/blob/master/examples/README.md) for notebooks you can download or run on Google Colab.\n\n\n## PyTorch Metric Learning Overview\nThis library contains 9 modules, each of which can be used independently within your existing codebase, or combined together for a complete train/test workflow.\n\n![high_level_module_overview](docs/imgs/high_level_module_overview.png)\n\n\n\n## How loss functions work\n\n### Using losses and miners in your training loop\nLet’s initialize a plain [TripletMarginLoss](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#tripletmarginloss):\n```python\nfrom pytorch_metric_learning import losses\nloss_func = losses.TripletMarginLoss()\n```\n\nTo compute the loss in your training loop, pass in the embeddings computed by your model, and the corresponding labels. The embeddings should have size (N, embedding_size), and the labels should have size (N), where N is the batch size.\n\n```python\n# your training loop\nfor i, (data, labels) in enumerate(dataloader):\n\toptimizer.zero_grad()\n\tembeddings = model(data)\n\tloss = loss_func(embeddings, labels)\n\tloss.backward()\n\toptimizer.step()\n```\n\nThe TripletMarginLoss computes all possible triplets within the batch, based on the labels you pass into it. Anchor-positive pairs are formed by embeddings that share the same label, and anchor-negative pairs are formed by embeddings that have different labels. \n\nSometimes it can help to add a mining function:\n```python\nfrom pytorch_metric_learning import miners, losses\nminer = miners.MultiSimilarityMiner()\nloss_func = losses.TripletMarginLoss()\n\n# your training loop\nfor i, (data, labels) in enumerate(dataloader):\n\toptimizer.zero_grad()\n\tembeddings = model(data)\n\thard_pairs = miner(embeddings, labels)\n\tloss = loss_func(embeddings, labels, hard_pairs)\n\tloss.backward()\n\toptimizer.step()\n```\nIn the above code, the miner finds positive and negative pairs that it thinks are particularly difficult. Note that even though the TripletMarginLoss operates on triplets, it’s still possible to pass in pairs. This is because the library automatically converts pairs to triplets and triplets to pairs, when necessary.\n\n### Customizing loss functions\nLoss functions can be customized using [distances](https://kevinmusgrave.github.io/pytorch-metric-learning/distances/), [reducers](https://kevinmusgrave.github.io/pytorch-metric-learning/reducers/), and [regularizers](https://kevinmusgrave.github.io/pytorch-metric-learning/regularizers/). In the diagram below, a miner finds the indices of hard pairs within a batch. These are used to index into the distance matrix, computed by the distance object. For this diagram, the loss function is pair-based, so it computes a loss per pair. In addition, a regularizer has been supplied, so a regularization loss is computed for each embedding in the batch. The per-pair and per-element losses are passed to the reducer, which (in this diagram) only keeps losses with a high value. The averages are computed for the high-valued pair and element losses, and are then added together to obtain the final loss.\n\n![high_level_loss_function_overview](docs/imgs/high_level_loss_function_overview.png)\n\nNow here's an example of a customized TripletMarginLoss:\n```python\nfrom pytorch_metric_learning.distances import CosineSimilarity\nfrom pytorch_metric_learning.reducers import ThresholdReducer\nfrom pytorch_metric_learning.regularizers import LpRegularizer\nfrom pytorch_metric_learning import losses\nloss_func = losses.TripletMarginLoss(distance = CosineSimilarity(), \n\t\t\t\t     reducer = ThresholdReducer(high=0.3), \n\t\t\t \t     embedding_regularizer = LpRegularizer())\n```\nThis customized triplet loss has the following properties:\n\n - The loss will be computed using cosine similarity instead of Euclidean distance.\n - All triplet losses that are higher than 0.3 will be discarded.\n - The embeddings will be L2 regularized.  \n\n### Using loss functions for unsupervised / self-supervised learning\n\nA `SelfSupervisedLoss` wrapper is provided for self-supervised learning:\n\n```python\nfrom pytorch_metric_learning.losses import SelfSupervisedLoss\nloss_func = SelfSupervisedLoss(TripletMarginLoss())\n\n# your training for-loop\nfor i, data in enumerate(dataloader):\n\toptimizer.zero_grad()\n\tembeddings = your_model(data)\n\taugmented = your_model(your_augmentation(data))\n\tloss = loss_func(embeddings, augmented)\n\tloss.backward()\n\toptimizer.step()\n```\n\nIf you're interested in [MoCo](https://arxiv.org/pdf/1911.05722.pdf)-style self-supervision, take a look at the [MoCo on CIFAR10](https://github.com/KevinMusgrave/pytorch-metric-learning/tree/master/examples#simple-examples) notebook. It uses CrossBatchMemory to implement the momentum encoder queue, which means you can use any tuple loss, and any tuple miner to extract hard samples from the queue.\n\n\n## Highlights of the rest of the library\n\n- For a convenient way to train your model, take a look at the [trainers](https://kevinmusgrave.github.io/pytorch-metric-learning/trainers/).\n- Want to test your model's accuracy on a dataset? Try the [testers](https://kevinmusgrave.github.io/pytorch-metric-learning/testers/).\n- To compute the accuracy of an embedding space directly, use [AccuracyCalculator](https://kevinmusgrave.github.io/pytorch-metric-learning/accuracy_calculation/).\n\nIf you're short of time and want a complete train/test workflow, check out the [example Google Colab notebooks](https://github.com/KevinMusgrave/pytorch-metric-learning/tree/master/examples).\n\nTo learn more about all of the above, [see the documentation](https://kevinmusgrave.github.io/pytorch-metric-learning). \n\n\n## Installation\n\n### Required PyTorch version\n - ```pytorch-metric-learning >= v0.9.90``` requires ```torch >= 1.6```\n - ```pytorch-metric-learning < v0.9.90``` doesn't have a version requirement, but was tested with ```torch >= 1.2```\n\nOther dependencies: ```numpy, scikit-learn, tqdm, torchvision```\n\n### Pip\n```\npip install pytorch-metric-learning\n```\n\n**To get the latest dev version**:\n```\npip install pytorch-metric-learning --pre\n```\n\n**To install on Windows**:\n```\npip install torch===1.6.0 torchvision===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\npip install pytorch-metric-learning\n```\n\n**To install with evaluation and logging capabilities**\n\n(This will install the unofficial pypi version of faiss-gpu, plus record-keeper and tensorboard):\n```\npip install pytorch-metric-learning[with-hooks]\n```\n\n**To install with evaluation and logging capabilities (CPU)**\n\n(This will install the unofficial pypi version of faiss-cpu, plus record-keeper and tensorboard):\n```\npip install pytorch-metric-learning[with-hooks-cpu]\n```\n\t\n### Conda\n```\nconda install -c conda-forge pytorch-metric-learning\n```\n\n**To use the testing module, you'll need faiss, which can be installed via conda as well. See the [installation instructions for faiss](https://github.com/facebookresearch/faiss/blob/master/INSTALL.md).**\n\n</details>\n\t\n\n\n## Benchmark results\nSee [powerful-benchmarker](https://github.com/KevinMusgrave/powerful-benchmarker/) to view benchmark results and to use the benchmarking tool.\n\n\n## Development\nDevelopment is done on the ```dev``` branch:\n```\ngit checkout dev\n```\n\nUnit tests can be run with the default ```unittest``` library:\n```bash\npython -m unittest discover\n```\n\nYou can specify the test datatypes and test device as environment variables. For example, to test using float32 and float64 on the CPU:\n```bash\nTEST_DTYPES=float32,float64 TEST_DEVICE=cpu python -m unittest discover\n```\n\nTo run a single test file instead of the entire test suite, specify the file name:\n```bash\npython -m unittest tests/losses/test_angular_loss.py\n```\n\nCode is formatted using ```black``` and ```isort```:\n```bash\npip install black isort\n./format_code.sh\n```\n\n\n## Acknowledgements\n\n### Contributors\nThanks to the contributors who made pull requests!\n\n| Contributor | Highlights |\n| -- | -- |\n|[domenicoMuscill0](https://github.com/domenicoMuscill0)| - [ManifoldLoss](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#manifoldloss) <br/> - [P2SGradLoss](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#p2sgradloss) <br/> - [HistogramLoss](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#histogramloss) <br/> - [DynamicSoftMarginLoss](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#dynamicsoftmarginloss) <br/> - [RankedListLoss](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#rankedlistloss) |\n|[mlopezantequera](https://github.com/mlopezantequera) | - Made the [testers](https://kevinmusgrave.github.io/pytorch-metric-learning/testers) work on any combination of query and reference sets <br/> - Made [AccuracyCalculator](https://kevinmusgrave.github.io/pytorch-metric-learning/accuracy_calculation/) work with arbitrary label comparisons |\n|[cwkeam](https://github.com/cwkeam) | - [SelfSupervisedLoss](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#selfsupervisedloss) <br/> - [VICRegLoss](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#vicregloss) <br/> - Added mean reciprocal rank accuracy to [AccuracyCalculator](https://kevinmusgrave.github.io/pytorch-metric-learning/accuracy_calculation/) <br/> - BaseLossWrapper|\n| [ir2718](https://github.com/ir2718) | - [ThresholdConsistentMarginLoss](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#thresholdconsistentmarginloss)  <br/> - The [Datasets](https://kevinmusgrave.github.io/pytorch-metric-learning/datasets) module |\n|[marijnl](https://github.com/marijnl)| - [BatchEasyHardMiner](https://kevinmusgrave.github.io/pytorch-metric-learning/miners/#batcheasyhardminer) <br/> - [TwoStreamMetricLoss](https://kevinmusgrave.github.io/pytorch-metric-learning/trainers/#twostreammetricloss) <br/> - [GlobalTwoStreamEmbeddingSpaceTester](https://kevinmusgrave.github.io/pytorch-metric-learning/testers/#globaltwostreamembeddingspacetester) <br/> - [Example using trainers.TwoStreamMetricLoss](https://github.com/KevinMusgrave/pytorch-metric-learning/blob/master/examples/notebooks/TwoStreamMetricLoss.ipynb) |\n| [chingisooinar](https://github.com/chingisooinar) | [SubCenterArcFaceLoss](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#subcenterarcfaceloss) |\n| [elias-ramzi](https://github.com/elias-ramzi) | [HierarchicalSampler](https://kevinmusgrave.github.io/pytorch-metric-learning/samplers/#hierarchicalsampler) |\n| [fjsj](https://github.com/fjsj) | [SupConLoss](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#supconloss) |\n| [AlenUbuntu](https://github.com/AlenUbuntu) | [CircleLoss](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#circleloss) |\n| [interestingzhuo](https://github.com/interestingzhuo) | [PNPLoss](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#pnploss) |\n| [wconnell](https://github.com/wconnell) | [Learning a scRNAseq Metric Embedding](https://github.com/KevinMusgrave/pytorch-metric-learning/blob/master/examples/notebooks/scRNAseq_MetricEmbedding.ipynb) |\n| [mkmenta](https://github.com/mkmenta) | Improved `get_all_triplets_indices` (fixed the `INT_MAX` error) |\n| [AlexSchuy](https://github.com/AlexSchuy) | optimized ```utils.loss_and_miner_utils.get_random_triplet_indices``` |\n| [JohnGiorgi](https://github.com/JohnGiorgi) | ```all_gather``` in [utils.distributed](https://kevinmusgrave.github.io/pytorch-metric-learning/distributed) |\n| [Hummer12007](https://github.com/Hummer12007) | ```utils.key_checker``` |\n| [vltanh](https://github.com/vltanh) | Made ```InferenceModel.train_indexer``` accept datasets |\n| [btseytlin](https://github.com/btseytlin) | ```get_nearest_neighbors``` in [InferenceModel](https://kevinmusgrave.github.io/pytorch-metric-learning/inference_models) |\n| [mlw214](https://github.com/mlw214) | Added ```return_per_class``` to [AccuracyCalculator](https://kevinmusgrave.github.io/pytorch-metric-learning/accuracy_calculation/) |\n| [layumi](https://github.com/layumi) | [InstanceLoss](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#instanceloss) |\n| [NoTody](https://github.com/NoTody) | Helped add `ref_emb` and `ref_labels` to the distributed wrappers. |\n| [ElisonSherton](https://github.com/ElisonSherton) | Fixed an edge case in ArcFaceLoss. |\n| [stompsjo](https://github.com/stompsjo) | Improved documentation for NTXentLoss. |\n| [Puzer](https://github.com/Puzer) | Bug fix for PNPLoss. |\n| [elisim](https://github.com/elisim) | Developer improvements to DistributedLossWrapper. |\n| [GaetanLepage](https://github.com/GaetanLepage) | |\n| [z1w](https://github.com/z1w) | |\n| [thinline72](https://github.com/thinline72) | |\n| [tpanum](https://github.com/tpanum) | |\n| [fralik](https://github.com/fralik) | |\n| [joaqo](https://github.com/joaqo) | |\n| [JoOkuma](https://github.com/JoOkuma) | |\n| [gkouros](https://github.com/gkouros) | |\n| [yutanakamura-tky](https://github.com/yutanakamura-tky) | |\n| [KinglittleQ](https://github.com/KinglittleQ) | |\n| [martin0258](https://github.com/martin0258) | |\n| [michaeldeyzel](https://github.com/michaeldeyzel) | |\n| [HSinger04](https://github.com/HSinger04) | |\n| [rheum](https://github.com/rheum) | |\n| [bot66](https://github.com/bot66) | |\n\n\n\n### Facebook AI\nThank you to [Ser-Nam Lim](https://sites.google.com/site/sernam) at [Facebook AI](https://ai.facebook.com/), and my research advisor, [Professor Serge Belongie](https://www.belongielab.org/). This project began during my internship at Facebook AI where I received valuable feedback from Ser-Nam, and his team of computer vision and machine learning engineers and research scientists. In particular, thanks to [Ashish Shah](https://www.linkedin.com/in/ashish217/) and [Austin Reiter](https://www.linkedin.com/in/austin-reiter-3962aa7/) for reviewing my code during its early stages of development.\n\n### Open-source repos\nThis library contains code that has been adapted and modified from the following great open-source repos:\n- https://github.com/bnu-wangxun/Deep_Metric\n- https://github.com/chaoyuaw/incubator-mxnet/blob/master/example/gluon/embedding_learning\n- https://github.com/facebookresearch/deepcluster\n- https://github.com/geonm/proxy-anchor-loss\n- https://github.com/idstcv/SoftTriple\n- https://github.com/kunhe/FastAP-metric-learning\n- https://github.com/ronekko/deep_metric_learning\n- https://github.com/tjddus9597/Proxy-Anchor-CVPR2020\n- http://kaizhao.net/regularface\n- https://github.com/nii-yamagishilab/project-NN-Pytorch-scripts\n\n### Logo\nThanks to [Jeff Musgrave](https://www.designgenius.ca/) for designing the logo.\n\n## Citing this library\nIf you'd like to cite pytorch-metric-learning in your paper, you can use this bibtex:\n```latex\n@article{Musgrave2020PyTorchML,\n  title={PyTorch Metric Learning},\n  author={Kevin Musgrave and Serge J. Belongie and Ser-Nam Lim},\n  journal={ArXiv},\n  year={2020},\n  volume={abs/2008.09164}\n}\n```\n"
        },
        {
          "name": "build_script.sh",
          "type": "blob",
          "size": 0.2255859375,
          "content": "./format_code.sh\npython -m unittest discover && \\\nWITH_COLLECT_STATS=true python -m unittest discover && \\\nrm -rfv build/ && \\\nrm -rfv dist/ && \\\nrm -rfv src/pytorch_metric_learning.egg-info/ && \\\npython3 setup.py sdist bdist_wheel"
        },
        {
          "name": "conda_build",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "format_code.sh",
          "type": "blob",
          "size": 0.1005859375,
          "content": "black src tests\nisort src tests --profile black\nnbqa black examples\nnbqa isort examples --profile black"
        },
        {
          "name": "mkdocs.yml",
          "type": "blob",
          "size": 1.1240234375,
          "content": "site_name: PyTorch Metric Learning\nnav:\n    - Home: index.md\n    - Datasets: datasets.md\n    - Distances: distances.md\n    - Losses: losses.md\n    - Miners: miners.md\n    - Reducers: reducers.md\n    - Regularizers: regularizers.md\n    - Samplers: samplers.md\n    - Trainers: trainers.md\n    - Testers: testers.md\n    - Utils: \n      - Accuracy Calculation: accuracy_calculation.md\n      - Inference Models: inference_models.md\n      - Logging Presets: logging_presets.md\n      - Common Functions: common_functions.md\n      - Distributed: distributed.md\n    - How to extend this library:\n      - Custom datasets: extend/datasets.md\n      - Custom losses: extend/losses.md\n      - Custom miners: extend/miners.md\n    - Frequently Asked Questions: faq.md\ntheme:\n  name: 'material'\n  palette:\n    primary: 'red'\n    accent: 'red'\n  logo: imgs/TinyLogo.png\n  favicon: imgs/Favicon.png\nmarkdown_extensions:\n  - admonition\n  - pymdownx.details\n  - pymdownx.highlight\n  - pymdownx.superfences \n  - toc:\n      permalink: true\n  - attr_list\nrepo_name: 'KevinMusgrave/pytorch-metric-learning'\nrepo_url: 'https://github.com/KevinMusgrave/pytorch-metric-learning'\n"
        },
        {
          "name": "run_linter.sh",
          "type": "blob",
          "size": 0.1044921875,
          "content": "flake8 src tests --count --show-source --statistics\nnbqa flake8 examples --count --show-source --statistics"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 1.5029296875,
          "content": "import sys\n\nimport setuptools\n\nsys.path.insert(0, \"src\")\nimport pytorch_metric_learning\n\nwith open(\"README.md\", \"r\") as fh:\n    long_description = fh.read()\n\nextras_require_with_hooks = [\n    \"record-keeper >= 0.9.32\",\n    \"faiss-gpu >= 1.6.3\",\n    \"tensorboard\",\n]\nextras_require_with_hooks_cpu = [\n    \"record-keeper >= 0.9.32\",\n    \"faiss-cpu >= 1.6.3\",\n    \"tensorboard\",\n]\nextras_require_docs = [\"mkdocs-material\"]\nextras_require_dev = [\"black\", \"isort\", \"nbqa\", \"flake8\"]\n\nsetuptools.setup(\n    name=\"pytorch-metric-learning\",\n    version=pytorch_metric_learning.__version__,\n    author=\"Kevin Musgrave\",\n    description=\"The easiest way to use deep metric learning in your application. Modular, flexible, and extensible. Written in PyTorch.\",\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    url=\"https://github.com/KevinMusgrave/pytorch-metric-learning\",\n    package_dir={\"\": \"src\"},\n    packages=setuptools.find_packages(where=\"src\"),\n    license_files=('LICENSE',),\n    classifiers=[\n        \"Programming Language :: Python :: 3\",\n        \"License :: OSI Approved :: MIT License\",\n        \"Operating System :: OS Independent\",\n    ],\n    python_requires=\">=3.0\",\n    install_requires=[\n        \"numpy\",\n        \"scikit-learn\",\n        \"tqdm\",\n        \"torch >= 1.6.0\",\n    ],\n    extras_require={\n        \"with-hooks\": extras_require_with_hooks,\n        \"with-hooks-cpu\": extras_require_with_hooks_cpu,\n        \"docs\": extras_require_docs,\n        \"dev\": extras_require_dev,\n    },\n)\n"
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}