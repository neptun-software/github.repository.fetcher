{
  "metadata": {
    "timestamp": 1736560431976,
    "page": 4,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjEw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "rq/rq",
      "stars": 9973,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".coveragerc",
          "type": "blob",
          "size": 0.1884765625,
          "content": "[run]\nsource = rq\nomit =\n    rq/contrib/legacy.py\n    rq/local.py\n    rq/tests/*\n    tests/*\n\n[report]\nexclude_lines =\n    if __name__ == .__main__.:\n    if TYPE_CHECKING:\n    pragma: no cover\n"
        },
        {
          "name": ".deepsource.toml",
          "type": "blob",
          "size": 0.1669921875,
          "content": "version = 1\n\ntest_patterns = [\"tests/**\"]\n\nexclude_patterns = [\"examples/**\"]\n\n[[analyzers]]\nname = \"python\"\nenabled = true\n\n  [analyzers.meta]\n  runtime_version = \"3.x.x\""
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.1982421875,
          "content": "*.pyc\n*.egg-info\n\n.DS_Store\n\n/dump.rdb\n/.direnv\n/.envrc\n/.tox\n/dist\n/build\n.tox\n.pytest_cache/\n.vagrant\nVagrantfile\n.idea/\n.coverage*\n/.cache\n.python-version\n\nGemfile\nGemfile.lock\n_site/\n.venv/\n.vscode/\n"
        },
        {
          "name": ".mailmap",
          "type": "blob",
          "size": 0.33984375,
          "content": "Cal Leeming <cal@iops.io> <cal.leeming@simplicitymedialtd.co.uk>\nMark LaPerriere <marklap@gmail.com> <mark.a.laperriere@disney.com>\nSelwin Ong <selwin.ong@gmail.com> <selwin@ui.co.id>\nVincent Driessen <me@nvie.com> <vincent@3rdcloud.com>\nVincent Driessen <me@nvie.com> <vincent@datafox.nl>\nzhangliyong <lyzhang87@gmail.com> <zhangliyong@umeng.com>\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.296875,
          "content": "repos:\n  - repo: https://github.com/psf/black\n    rev: 23.3.0\n    hooks:\n        - id: black\n  - repo: https://github.com/charliermarsh/ruff-pre-commit\n    rev: \"v0.0.267\"\n    hooks:\n      - id: ruff\n  - repo: https://github.com/tox-dev/pyproject-fmt\n    rev: 0.12.0\n    hooks:\n      - id: pyproject-fmt\n"
        },
        {
          "name": "CHANGES.md",
          "type": "blob",
          "size": 34.115234375,
          "content": "### RQ 2.1.0 (2024-12-23)\n* `job.id` must not contain `:`. Thanks @sanurielf!\n* Various type hint improvements by @terencehonles!\n* `job.ended_at` should be set when job is run synchronously. Thanks @alexprabhat99!\n* `Group.all()` now properly handles non existing group. Thanks @eswolinsky3241!\n* Use `ruff` instead of `black` as formatter. Thanks @hongquan!\n\n### RQ 2.0 (2024-10-28)\n\nNew Features:\n* Multiple job executions: a job can now have multiple executions running simultaneously. This will enable future support for long running scheduled jobs. Thanks @selwin!\n* `Worker(default_worker_ttl=10)` is deprecated in favor of `Worker(worker_ttl=10)`. Thanks @stv8!\n* Added a `cleanup` parameter to `registry.get_job_ids()` and `registry.get_job_count()`. Thanks @anton-daneyko-ultramarin!\n* Added support for AWS Elasticache Serverless Redis. Thanks @bobbywatson3!\n* You can now specify TTL for deferred jobs. Thanks @hberntsen!\n* RQ's code base is now typed (mostly). Thanks @terencehonles!\n* Other minor fixes and improvements. Thanks @hongquan, @rbange, @jackkinsella, @terencehonles, @wckao, @sim6!\n\nBreaking Changes:\n* Dropped support for Redis server < 4\n* `RoundRobinWorker` and `RandomWorker` are deprecated. Use  `--dequeue-strategy <round-robin/random>` instead.\n* `Job.__init__` requires both `id` and `connection` to be passed in.\n* `Job.exists()` requires `connection` argument to be passed in.\n* `Queue.all()` requires `connection` argument.\n* `@job` decorator now requires `connection` argument.\n* Built in Sentry integration has been removed. To use Sentry with RQ, please refer to [Sentry's docs](https://docs.sentry.io/platforms/python/integrations/rq/).\n\nBug Fixes:\n* Fixed an issue where abandoned jobs are sometimes not enqueued. Thanks @Marishka17!\n* Fixes an issue where Redis connection does not expose `name` attribute. Thanks @wckao!\n* `job.get_status()` will now always return `JobStatus` enum. Thanks @indepndnt!\n* Queue key should always be created even if jobs are deferred. Thanks @sim6!\n* RQ's pubsub thread will now attempt to reconnect on Redis connection errors. Thanks @fcharlier!\n\n### RQ 1.16.2 (2024-05-01)\n* Fixed a bug that may cause jobs from intermediate queue to be moved to FailedJobRegistry. Thanks @selwin!\n\n### RQ 1.16.1 (2024-03-09)\n* Added `worker_pool.get_worker_process()` to make `WorkerPool` easier to extend. Thanks @selwin!\n\n### RQ 1.16 (2024-02-24)\n* Added a way for jobs to wait for latest result `job.latest_result(timeout=60)`. Thanks @ajnisbet!\n* Fixed an issue where `stopped_callback` is not respected when job is enqueued via `enqueue_many()`. Thanks @eswolinsky3241!\n* `worker-pool` no longer ignores `--quiet`. Thanks @Mindiell!\n* Added compatibility with AWS Serverless Redis. Thanks @peter-gy!\n* `worker-pool` now starts with scheduler. Thanks @chromium7!\n\n### RQ 1.15.1 (2023-06-20)\n* Fixed a bug that may cause a crash when cleaning intermediate queue. Thanks @selwin!\n* Fixed a bug that may cause canceled jobs to still run dependent jobs. Thanks @fredsod!\n\n### RQ 1.15 (2023-05-24)\n* Added `Callback(on_stopped='my_callback)`. Thanks @eswolinsky3241!\n* `Callback` now accepts dotted path to function as input. Thanks @rishabh-ranjan!\n* `queue.enqueue_many()` now supports job dependencies. Thanks @eswolinsky3241!\n* `rq worker` CLI script now configures logging based on `DICT_CONFIG` key present in config file. Thanks @juur!\n* Whenever possible, `Worker` now uses `lmove()` to implement [reliable queue pattern](https://redis.io/commands/lmove/). Thanks @selwin!\n* Require `redis>=4.0.0`\n* `Scheduler` should only release locks that it successfully acquires. Thanks @xzander!\n* Fixes crashes that may happen by changes to `as_text()` function in v1.14. Thanks @tchapi!\n* Various linting, CI and code quality improvements. Thanks @robhudson!\n\n### RQ 1.14.1 (2023-05-05)\n* Fixes a crash that happens if Redis connection uses SSL. Thanks @tchapi!\n* Fixes a crash if `job.meta()` is loaded using the wrong serializer. Thanks @gabriels1234!\n\n### RQ 1.14.0 (2023-05-01)\n* Added `WorkerPool` (beta) that manages multiple workers in a single CLI. Thanks @selwin!\n* Added a new `Callback` class that allows more flexibility in declaring job callbacks. Thanks @ronlut!\n* Fixed a regression where jobs with unserializable return value crashes RQ. Thanks @tchapi!\n* Added `--dequeue-strategy` option to RQ's CLI. Thanks @ccrvlh!\n* Added `--max-idle-time` option to RQ's worker CLI. Thanks @ronlut!\n* Added `--maintenance-interval` option to RQ's worker CLI. Thanks @ronlut!\n* Fixed RQ usage in Windows as well as various other refactorings. Thanks @ccrvlh!\n* Show more info on `rq info` CLI command. Thanks @iggeehu!\n* `queue.enqueue_jobs()` now properly account for job dependencies. Thanks @sim6!\n* `TimerDeathPenalty` now properly handles negative/infinite timeout. Thanks @marqueurs404!\n\n### RQ 1.13.0 (2023-02-19)\n* Added `work_horse_killed_handler` argument to `Worker`. Thanks @ronlut!\n* Fixed an issue where results aren't properly persisted on synchronous jobs. Thanks @selwin!\n* Fixed a bug where job results are not properly persisted when `result_ttl` is `-1`. Thanks @sim6!\n* Various documentation and logging fixes. Thanks @lowercase00!\n* Improve Redis connection reliability. Thanks @lowercase00!\n* Scheduler reliability improvements. Thanks @OlegZv and @lowercase00!\n* Fixed a bug where `dequeue_timeout` ignores `worker_ttl`. Thanks @ronlut!\n* Use `job.return_value()` instead of `job.result` when processing callbacks. Thanks @selwin!\n* Various internal refactorings to make `Worker` code more easily extendable. Thanks @lowercase00!\n* RQ's source code is now black formatted. Thanks @aparcar!\n\n### RQ 1.12.0 (2023-01-15)\n* RQ now stores multiple job execution results. This feature is only available on Redis >= 5.0 Redis Streams. Please refer to [the docs](https://python-rq.org/docs/results/) for more info. Thanks @selwin!\n* Improve performance when enqueueing many jobs at once. Thanks @rggjan!\n* Redis server version is now cached in connection object. Thanks @odarbelaeze!\n* Properly handle `at_front` argument when jobs are scheduled. Thanks @gabriels1234!\n* Add type hints to RQ's code base. Thanks @lowercase00!\n* Fixed a bug where exceptions are logged twice. Thanks @selwin!\n* Don't delete `job.worker_name` after job is finished. Thanks @eswolinsky3241!\n\n### RQ 1.11.1 (2022-09-25)\n* `queue.enqueue_many()` now supports `on_success` and on `on_failure` arguments. Thanks @y4n9squared!\n* You can now pass `enqueue_at_front` to `Dependency()` objects to put dependent jobs at the front when they are enqueued. Thanks @jtfidje!\n* Fixed a bug where workers may wrongly acquire scheduler locks. Thanks @milesjwinter!\n* Jobs should not be enqueued if any one of it's dependencies is canceled. Thanks @selwin!\n* Fixed a bug when handling jobs that have been stopped. Thanks @ronlut!\n* Fixed a bug in handling Redis connections that don't allow `SETNAME` command. Thanks @yilmaz-burak!\n\n### RQ 1.11 (2022-07-31)\n* This will be the last RQ version that supports Python 3.5.\n* Allow jobs to be enqueued even when their dependencies fail via `Dependency(allow_failure=True)`. Thanks @mattchan-tencent, @caffeinatedMike and @selwin!\n* When stopped jobs are deleted, they should also be removed from FailedJobRegistry. Thanks @selwin!\n* `job.requeue()` now supports `at_front()` argument. Thanks @buroa!\n* Added ssl support for sentinel connections. Thanks @nevious!\n* `SimpleWorker` now works better on Windows. Thanks @caffeinatedMike!\n* Added `on_failure` and `on_success` arguments to @job decorator. Thanks @nepta1998!\n* Fixed a bug in dependency handling. Thanks @th3hamm0r!\n* Minor fixes and optimizations by @xavfernandez, @olaure, @kusaku.\n\n### RQ 1.10.1 (2021-12-07)\n* **BACKWARDS INCOMPATIBLE**: synchronous execution of jobs now correctly mimics async job execution. Exception is no longer raised when a job fails, job status will now be correctly set to `FAILED` and failure callbacks are now properly called when job is run synchronously. Thanks @ericman93!\n* Fixes a bug that could cause job keys to be left over when `result_ttl=0`. Thanks @selwin!\n* Allow `ssl_cert_reqs` argument to be passed to Redis. Thanks @mgcdanny!\n* Better compatibility with Python 3.10. Thanks @rpkak!\n* `job.cancel()` should also remove itself from registries. Thanks @joshcoden!\n* Pubsub threads are now launched in `daemon` mode. Thanks @mik3y!\n\n### RQ 1.10.0 (2021-09-09)\n* You can now enqueue jobs from CLI. Docs [here](https://python-rq.org/docs/#cli-enqueueing). Thanks @rpkak!\n* Added a new `CanceledJobRegistry` to keep track of canceled jobs. Thanks @selwin!\n* Added custom serializer support to various places in RQ. Thanks @joshcoden!\n* `cancel_job(job_id, enqueue_dependents=True)` allows you to cancel a job while enqueueing its dependents. Thanks @joshcoden!\n* Added `job.get_meta()` to fetch fresh meta value directly from Redis. Thanks @aparcar!\n* Fixes a race condition that could cause jobs to be incorrectly added to FailedJobRegistry. Thanks @selwin!\n* Requeueing a job now clears `job.exc_info`. Thanks @selwin!\n* Repo infrastructure improvements by @rpkak.\n* Other minor fixes by @cesarferradas and @bbayles.\n\n### RQ 1.9.0 (2021-06-30)\n* Added success and failure callbacks. You can now do `queue.enqueue(foo, on_success=do_this, on_failure=do_that)`. Thanks @selwin!\n* Added `queue.enqueue_many()` to enqueue many jobs in one go. Thanks @joshcoden!\n* Various improvements to CLI commands. Thanks @rpkak!\n* Minor logging improvements. Thanks @clavigne and @natbusa!\n\n### RQ 1.8.1 (2021-05-17)\n* Jobs that fail due to hard shutdowns are now retried. Thanks @selwin!\n* `Scheduler` now works with custom serializers. Thanks @alella!\n* Added support for click 8.0. Thanks @rpkak!\n* Enqueueing static methods are now supported. Thanks @pwws!\n* Job exceptions no longer get printed twice. Thanks @petrem!\n\n### RQ 1.8.0 (2021-03-31)\n* You can now declare multiple job dependencies. Thanks @skieffer and @thomasmatecki for laying the groundwork for multi dependency support in RQ.\n* Added `RoundRobinWorker` and `RandomWorker` classes to control how jobs are dequeued from multiple queues. Thanks @bielcardona!\n* Added `--serializer` option to `rq worker` CLI. Thanks @f0cker!\n* Added support for running asyncio tasks. Thanks @MyrikLD!\n* Added a new `STOPPED` job status so that you can differentiate between failed and manually stopped jobs. Thanks @dralley!\n* Fixed a serialization bug when used with job dependency feature. Thanks @jtfidje!\n* `clean_worker_registry()` now works in batches of 1,000 jobs to prevent modifying too many keys at once. Thanks @AxeOfMen and @TheSneak!\n* Workers will now wait and try to reconnect in case of Redis connection errors. Thanks @Asrst!\n\n### RQ 1.7.0 (2020-11-29)\n* Added `job.worker_name` attribute that tells you which worker is executing a job. Thanks @selwin!\n* Added `send_stop_job_command()` that tells a worker to stop executing a job. Thanks @selwin!\n* Added `JSONSerializer` as an alternative to the default `pickle` based serializer. Thanks @JackBoreczky!\n* Fixes `RQScheduler` running on Redis with `ssl=True`. Thanks @BobReid!\n\n### RQ 1.6.1 (2020-11-08)\n* Worker now properly releases scheduler lock when run in burst mode. Thanks @selwin!\n\n### RQ 1.6.0 (2020-11-08)\n* Workers now listen to external commands via pubsub. The first two features taking advantage of this infrastructure are `send_shutdown_command()` and `send_kill_horse_command()`. Thanks @selwin!\n* Added `job.last_heartbeat` property that's periodically updated when job is running. Thanks @theambient!\n* Now horses are killed by their parent group. This helps in cleanly killing all related processes if job uses multiprocessing. Thanks @theambient!\n* Fixed scheduler usage with Redis connections that uses custom parser classes. Thanks @selwin!\n* Scheduler now enqueue jobs in batches to prevent lock timeouts. Thanks @nikkonrom!\n* Scheduler now follows RQ worker's logging configuration. Thanks @christopher-dG!\n\n### RQ 1.5.2 (2020-09-10)\n* Scheduler now uses the class of connection that's used. Thanks @pacahon!\n* Fixes a bug that puts retried jobs in `FailedJobRegistry`. Thanks @selwin!\n* Fixed a deprecated import. Thanks @elmaghallawy!\n\n### RQ 1.5.1 (2020-08-21)\n* Fixes for Redis server version parsing. Thanks @selwin!\n* Retries can now be set through @job decorator. Thanks @nerok!\n* Log messages below logging.ERROR is now sent to stdout. Thanks @selwin!\n* Better logger name for RQScheduler. Thanks @atainter!\n* Better handling of exceptions thrown by horses. Thanks @theambient!\n\n### RQ 1.5.0 (2020-07-26)\n* Failed jobs can now be retried. Thanks @selwin!\n* Fixed scheduler on Python > 3.8.0. Thanks @selwin!\n* RQ is now aware of which version of Redis server it's running on. Thanks @aparcar!\n* RQ now uses `hset()` on redis-py >= 3.5.0. Thanks @aparcar!\n* Fix incorrect worker timeout calculation in SimpleWorker.execute_job(). Thanks @davidmurray!\n* Make horse handling logic more robust. Thanks @wevsty!\n\n### RQ 1.4.3 (2020-06-28)\n* Added `job.get_position()` and `queue.get_job_position()`. Thanks @aparcar!\n* Longer TTLs for worker keys to prevent them from expiring inside the worker lifecycle. Thanks @selwin!\n* Long job args/kwargs are now truncated during logging. Thanks @JhonnyBn!\n* `job.requeue()` now returns the modified job. Thanks @ericatkin!\n\n### RQ 1.4.2 (2020-05-26)\n* Reverted changes to `hmset` command which causes workers on Redis server < 4 to crash. Thanks @selwin!\n* Merged in more groundwork to enable jobs with multiple dependencies. Thanks @thomasmatecki!\n\n### RQ 1.4.1 (2020-05-16)\n* Default serializer now uses `pickle.HIGHEST_PROTOCOL` for backward compatibility reasons. Thanks @bbayles!\n* Avoid deprecation warnings on redis-py >= 3.5.0. Thanks @bbayles!\n\n### RQ 1.4.0 (2020-05-13)\n* Custom serializer is now supported. Thanks @solababs!\n* `delay()` now accepts `job_id` argument. Thanks @grayshirt!\n* Fixed a bug that may cause early termination of scheduled or requeued jobs. Thanks @rmartin48!\n* When a job is scheduled, always add queue name to a set containing active RQ queue names. Thanks @mdawar!\n* Added `--sentry-ca-certs` and `--sentry-debug` parameters to `rq worker` CLI. Thanks @kichawa!\n* Jobs cleaned up by `StartedJobRegistry` are given an exception info. Thanks @selwin!\n* Python 2.7 is no longer supported. Thanks @selwin!\n\n### RQ 1.3.0 (2020-03-09)\n* Support for infinite job timeout. Thanks @theY4Kman!\n* Added `__main__` file so you can now do `python -m rq.cli`. Thanks @bbayles!\n* Fixes an issue that may cause zombie processes. Thanks @wevsty!\n* `job_id` is now passed to logger during failed jobs. Thanks @smaccona!\n* `queue.enqueue_at()` and `queue.enqueue_in()` now supports explicit `args` and `kwargs` function invocation. Thanks @selwin!\n\n### RQ 1.2.2 (2020-01-31)\n* `Job.fetch()` now properly handles unpickleable return values. Thanks @selwin!\n\n### RQ 1.2.1 (2020-01-31)\n* `enqueue_at()` and `enqueue_in()` now sets job status to `scheduled`. Thanks @coolhacker170597!\n* Failed jobs data are now automatically expired by Redis. Thanks @selwin!\n* Fixes `RQScheduler` logging configuration. Thanks @FlorianPerucki!\n\n### RQ 1.2.0 (2020-01-04)\n* This release also contains an alpha version of RQ's builtin job scheduling mechanism. Thanks @selwin!\n* Various internal API changes in preparation to support multiple job dependencies. Thanks @thomasmatecki!\n* `--verbose` or `--quiet` CLI arguments should override `--logging-level`. Thanks @zyt312074545!\n* Fixes a bug in `rq info` where it doesn't show workers for empty queues. Thanks @zyt312074545!\n* Fixed `queue.enqueue_dependents()` on custom `Queue` classes. Thanks @van-ess0!\n* `RQ` and Python versions are now stored in job metadata. Thanks @eoranged!\n* Added `failure_ttl` argument to job decorator. Thanks @pax0r!\n\n### RQ 1.1.0 (2019-07-20)\n\n- Added `max_jobs` to `Worker.work` and `--max-jobs` to `rq worker` CLI. Thanks @perobertson!\n- Passing `--disable-job-desc-logging` to `rq worker` now does what it's supposed to do. Thanks @janierdavila!\n- `StartedJobRegistry` now properly handles jobs with infinite timeout. Thanks @macintoshpie!\n- `rq info` CLI command now cleans up registries when it first runs. Thanks @selwin!\n- Replaced the use of `procname` with `setproctitle`. Thanks @j178!\n\n\n### 1.0 (2019-04-06)\nBackward incompatible changes:\n\n- `job.status` has been removed. Use `job.get_status()` and `job.set_status()` instead. Thanks @selwin!\n\n- `FailedQueue` has been replaced with `FailedJobRegistry`:\n  * `get_failed_queue()` function has been removed. Please use `FailedJobRegistry(queue=queue)` instead.\n  * `move_to_failed_queue()` has been removed.\n  * RQ now provides a mechanism to automatically cleanup failed jobs. By default, failed jobs are kept for 1 year.\n  * Thanks @selwin!\n\n- RQ's custom job exception handling mechanism has also changed slightly:\n  * RQ's default exception handling mechanism (moving jobs to `FailedJobRegistry`) can be disabled by doing `Worker(disable_default_exception_handler=True)`.\n  * Custom exception handlers are no longer executed in reverse order.\n  * Thanks @selwin!\n\n- `Worker` names are now randomized. Thanks @selwin!\n\n- `timeout` argument on `queue.enqueue()` has been deprecated in favor of `job_timeout`. Thanks @selwin!\n\n- Sentry integration has been reworked:\n  * RQ now uses the new [sentry-sdk](https://pypi.org/project/sentry-sdk/) in place of the deprecated [Raven](https://pypi.org/project/raven/) library\n  * RQ will look for the more explicit `RQ_SENTRY_DSN` environment variable instead of `SENTRY_DSN` before instantiating Sentry integration\n  * Thanks @selwin!\n\n- Fixed `Worker.total_working_time` accounting bug. Thanks @selwin!\n\n\n### 0.13.0 (2018-12-11)\n- Compatibility with Redis 3.0. Thanks @dash-rai!\n- Added `job_timeout` argument to `queue.enqueue()`. This argument will eventually replace `timeout` argument. Thanks @selwin!\n- Added `job_id` argument to `BaseDeathPenalty` class. Thanks @loopbio!\n- Fixed a bug which causes long running jobs to timeout under `SimpleWorker`. Thanks @selwin!\n- You can now override worker's name from config file. Thanks @houqp!\n- Horses will now return exit code 1 if they don't terminate properly (e.g when Redis connection is lost). Thanks @selwin!\n- Added `date_format` and `log_format` arguments to `Worker` and `rq worker` CLI. Thanks @shikharsg!\n\n\n### 0.12.0 (2018-07-14)\n- Added support for Python 3.7. Since `async` is a keyword in Python 3.7,\n`Queue(async=False)` has been changed to `Queue(is_async=False)`. The `async`\nkeyword argument will still work, but raises a `DeprecationWarning`. Thanks @dchevell!\n\n\n### 0.11.0 (2018-06-01)\n- `Worker` now periodically sends heartbeats and checks whether child process is still alive while performing long running jobs. Thanks @Kriechi!\n- `Job.create` now accepts `timeout` in string format (e.g `1h`). Thanks @theodesp!\n- `worker.main_work_horse()` should exit with return code `0` even if job execution fails. Thanks @selwin!\n- `job.delete(delete_dependents=True)` will delete job along with its dependents. Thanks @olingerc!\n- Other minor fixes and documentation updates.\n\n\n### 0.10.0\n- `@job` decorator now accepts `description`, `meta`, `at_front` and `depends_on` kwargs. Thanks @jlucas91 and @nlyubchich!\n- Added the capability to fetch workers by queue using `Worker.all(queue=queue)` and `Worker.count(queue=queue)`.\n- Improved RQ's default logging configuration. Thanks @samuelcolvin!\n- `job.data` and `job.exc_info` are now stored in compressed format in Redis.\n\n\n### 0.9.2\n- Fixed an issue where `worker.refresh()` may fail when `birth_date` is not set. Thanks @vanife!\n\n\n### 0.9.1\n- Fixed an issue where `worker.refresh()` may fail when upgrading from previous versions of RQ.\n\n\n### 0.9.0\n- `Worker` statistics! `Worker` now keeps track of `last_heartbeat`, `successful_job_count`, `failed_job_count` and `total_working_time`. Thanks @selwin!\n- `Worker` now sends heartbeat during suspension check. Thanks @theodesp!\n- Added `queue.delete()` method to delete `Queue` objects entirely from Redis. Thanks @theodesp!\n- More robust exception string decoding. Thanks @stylight!\n- Added `--logging-level` option to command line scripts. Thanks @jiajunhuang!\n- Added millisecond precision to job timestamps. Thanks @samuelcolvin!\n- Python 2.6 is no longer supported. Thanks @samuelcolvin!\n\n\n### 0.8.2\n- Fixed an issue where `job.save()` may fail with unpickleable return value.\n\n\n### 0.8.1\n- Replace `job.id` with `Job` instance in local `_job_stack `. Thanks @katichev!\n- `job.save()` no longer implicitly calls `job.cleanup()`. Thanks @katichev!\n- Properly catch `StopRequested` `worker.heartbeat()`. Thanks @fate0!\n- You can now pass in timeout in days. Thanks @yaniv-g!\n- The core logic of sending job to `FailedQueue` has been moved to `rq.handlers.move_to_failed_queue`. Thanks @yaniv-g!\n- RQ cli commands now accept `--path` parameter. Thanks @kirill and @sjtbham!\n- Make `job.dependency` slightly more efficient. Thanks @liangsijian!\n- `FailedQueue` now returns jobs with the correct class. Thanks @amjith!\n\n\n### 0.8.0\n- Refactored APIs to allow custom `Connection`, `Job`, `Worker` and `Queue` classes via CLI. Thanks @jezdez!\n- `job.delete()` now properly cleans itself from job registries. Thanks @selwin!\n- `Worker` should no longer overwrite `job.meta`. Thanks @WeatherGod!\n- `job.save_meta()` can now be used to persist custom job data. Thanks @katichev!\n- Added Redis Sentinel support. Thanks @strawposter!\n- Make `Worker.find_by_key()` more efficient. Thanks @selwin!\n- You can now specify job `timeout` using strings such as `queue.enqueue(foo, timeout='1m')`. Thanks @luojiebin!\n- Better unicode handling. Thanks @myme5261314 and @jaywink!\n- Sentry should default to HTTP transport. Thanks @Atala!\n- Improve `HerokuWorker` termination logic. Thanks @samuelcolvin!\n\n\n### 0.7.1\n- Fixes a bug that prevents fetching jobs from `FailedQueue` (#765). Thanks @jsurloppe!\n- Fixes race condition when enqueueing jobs with dependency (#742). Thanks @th3hamm0r!\n- Skip a test that requires Linux signals on MacOS (#763). Thanks @jezdez!\n- `enqueue_job` should use Redis pipeline when available (#761). Thanks mtdewulf!\n\n\n### 0.7.0\n- Better support for Heroku workers (#584, #715)\n- Support for connecting using a custom connection class (#741)\n- Fix: connection stack in default worker (#479, #641)\n- Fix: `fetch_job` now checks that a job requested actually comes from the\n  intended queue (#728, #733)\n- Fix: Properly raise exception if a job dependency does not exist (#747)\n- Fix: Job status not updated when horse dies unexpectedly (#710)\n- Fix: `request_force_stop_sigrtmin` failing for Python 3 (#727)\n- Fix `Job.cancel()` method on failed queue (#707)\n- Python 3.5 compatibility improvements (#729)\n- Improved signal name lookup (#722)\n\n\n### 0.6.0\n- Jobs that depend on job with result_ttl == 0 are now properly enqueued.\n- `cancel_job` now works properly. Thanks @jlopex!\n- Jobs that execute successfully now no longer tries to remove itself from queue. Thanks @amyangfei!\n- Worker now properly logs Falsy return values. Thanks @liorsbg!\n- `Worker.work()` now accepts `logging_level` argument. Thanks @jlopex!\n- Logging related fixes by @redbaron4 and @butla!\n- `@job` decorator now accepts `ttl` argument. Thanks @javimb!\n- `Worker.__init__` now accepts `queue_class` keyword argument. Thanks @antoineleclair!\n- `Worker` now saves warm shutdown time. You can access this property from `worker.shutdown_requested_date`. Thanks @olingerc!\n- Synchronous queues now properly sets completed job status as finished. Thanks @ecarreras!\n- `Worker` now correctly deletes `current_job_id` after failed job execution. Thanks @olingerc!\n- `Job.create()` and `queue.enqueue_call()` now accepts `meta` argument. Thanks @tornstrom!\n- Added `job.started_at` property. Thanks @samuelcolvin!\n- Cleaned up the implementation of `job.cancel()` and `job.delete()`. Thanks @glaslos!\n- `Worker.execute_job()` now exports `RQ_WORKER_ID` and `RQ_JOB_ID` to OS environment variables. Thanks @mgk!\n- `rqinfo` now accepts `--config` option. Thanks @kfrendrich!\n- `Worker` class now has `request_force_stop()` and `request_stop()` methods that can be overridden by custom worker classes. Thanks @samuelcolvin!\n- Other minor fixes by @VicarEscaped, @kampfschlaefer, @ccurvey, @zfz, @antoineleclair,\n  @orangain, @nicksnell, @SkyLothar, @ahxxm and @horida.\n\n\n### 0.5.6\n\n- Job results are now logged on `DEBUG` level. Thanks @tbaugis!\n- Modified `patch_connection` so Redis connection can be easily mocked\n- Customer exception handlers are now called if Redis connection is lost. Thanks @jlopex!\n- Jobs can now depend on jobs in a different queue. Thanks @jlopex!\n\n\n### 0.5.5 (2015-08-25)\n\n- Add support for `--exception-handler` command line flag\n- Fix compatibility with click>=5.0\n- Fix maximum recursion depth problem for very large queues that contain jobs\n  that all fail\n\n\n### 0.5.4\n\n(July 8th, 2015)\n\n- Fix compatibility with raven>=5.4.0\n\n\n### 0.5.3\n\n(June 3rd, 2015)\n\n- Better API for instantiating Workers. Thanks @RyanMTB!\n- Better support for unicode kwargs. Thanks @nealtodd and @brownstein!\n- Workers now automatically cleans up job registries every hour\n- Jobs in `FailedQueue` now have their statuses set properly\n- `enqueue_call()` no longer ignores `ttl`. Thanks @mbodock!\n- Improved logging. Thanks @trevorprater!\n\n\n### 0.5.2\n\n(April 14th, 2015)\n\n- Support SSL connection to Redis (requires redis-py>=2.10)\n- Fix to prevent deep call stacks with large queues\n\n\n### 0.5.1\n\n(March 9th, 2015)\n\n- Resolve performance issue when queues contain many jobs\n- Restore the ability to specify connection params in config\n- Record `birth_date` and `death_date` on Worker\n- Add support for SSL URLs in Redis (and `REDIS_SSL` config option)\n- Fix encoding issues with non-ASCII characters in function arguments\n- Fix Redis transaction management issue with job dependencies\n\n\n### 0.5.0\n(Jan 30th, 2015)\n\n- RQ workers can now be paused and resumed using `rq suspend` and\n  `rq resume` commands. Thanks Jonathan Tushman!\n- Jobs that are being performed are now stored in `StartedJobRegistry`\n  for monitoring purposes. This also prevents currently active jobs from\n  being orphaned/lost in the case of hard shutdowns.\n- You can now monitor finished jobs by checking `FinishedJobRegistry`.\n  Thanks Nic Cope for helping!\n- Jobs with unmet dependencies are now created with `deferred` as their\n  status. You can monitor deferred jobs by checking `DeferredJobRegistry`.\n- It is now possible to enqueue a job at the beginning of queue using\n  `queue.enqueue(func, at_front=True)`. Thanks Travis Johnson!\n- Command line scripts have all been refactored to use `click`. Thanks Lyon Zhang!\n- Added a new `SimpleWorker` that does not fork when executing jobs.\n  Useful for testing purposes. Thanks Cal Leeming!\n- Added `--queue-class` and `--job-class` arguments to `rqworker` script.\n  Thanks David Bonner!\n- Many other minor bug fixes and enhancements.\n\n\n### 0.4.6\n(May 21st, 2014)\n\n- Raise a warning when RQ workers are used with Sentry DSNs using\n  asynchronous transports.  Thanks Wei, Selwin & Toms!\n\n\n### 0.4.5\n(May 8th, 2014)\n\n- Fix where rqworker broke on Python 2.6. Thanks, Marko!\n\n\n### 0.4.4\n(May 7th, 2014)\n\n- Properly declare redis dependency.\n- Fix a NameError regression that was introduced in 0.4.3.\n\n\n### 0.4.3\n(May 6th, 2014)\n\n- Make job and queue classes overridable. Thanks, Marko!\n- Don't require connection for @job decorator at definition time. Thanks, Sasha!\n- Syntactic code cleanup.\n\n\n### 0.4.2\n(April 28th, 2014)\n\n- Add missing depends_on kwarg to @job decorator.  Thanks, Sasha!\n\n\n### 0.4.1\n(April 22nd, 2014)\n\n- Fix bug where RQ 0.4 workers could not unpickle/process jobs from RQ < 0.4.\n\n\n### 0.4.0\n(April 22nd, 2014)\n\n- Emptying the failed queue from the command line is now as simple as running\n  `rqinfo -X` or `rqinfo --empty-failed-queue`.\n\n- Job data is unpickled lazily. Thanks, Malthe!\n\n- Removed dependency on the `times` library. Thanks, Malthe!\n\n- Job dependencies!  Thanks, Selwin.\n\n- Custom worker classes, via the `--worker-class=path.to.MyClass` command line\n  argument.  Thanks, Selwin.\n\n- `Queue.all()` and `rqinfo` now report empty queues, too.  Thanks, Rob!\n\n- Fixed a performance issue in `Queue.all()` when issued in large Redis DBs.\n  Thanks, Rob!\n\n- Birth and death dates are now stored as proper datetimes, not timestamps.\n\n- Ability to provide a custom job description (instead of using the default\n  function invocation hint).  Thanks, Ä°brahim.\n\n- Fix: temporary key for the compact queue is now randomly generated, which\n  should avoid name clashes for concurrent compact actions.\n\n- Fix: `Queue.empty()` now correctly deletes job hashes from Redis.\n\n\n### 0.3.13\n(December 17th, 2013)\n\n- Bug fix where the worker crashes on jobs that have their timeout explicitly\n  removed.  Thanks for reporting, @algrs.\n\n\n### 0.3.12\n(December 16th, 2013)\n\n- Bug fix where a worker could time out before the job was done, removing it\n  from any monitor overviews (#288).\n\n\n### 0.3.11\n(August 23th, 2013)\n\n- Some more fixes in command line scripts for Python 3\n\n\n### 0.3.10\n(August 20th, 2013)\n\n- Bug fix in setup.py\n\n\n### 0.3.9\n(August 20th, 2013)\n\n- Python 3 compatibility (Thanks, Alex!)\n\n- Minor bug fix where Sentry would break when func cannot be imported\n\n\n### 0.3.8\n(June 17th, 2013)\n\n- `rqworker` and `rqinfo` have a  `--url` argument to connect to a Redis url.\n\n- `rqworker` and `rqinfo` have a `--socket` option to connect to a Redis server\n  through a Unix socket.\n\n- `rqworker` reads `SENTRY_DSN` from the environment, unless specifically\n  provided on the command line.\n\n- `Queue` has a new API that supports paging `get_jobs(3, 7)`, which will\n  return at most 7 jobs, starting from the 3rd.\n\n\n### 0.3.7\n(February 26th, 2013)\n\n- Fixed bug where workers would not execute builtin functions properly.\n\n\n### 0.3.6\n(February 18th, 2013)\n\n- Worker registrations now expire.  This should prevent `rqinfo` from reporting\n  about ghosted workers.  (Thanks, @yaniv-aknin!)\n\n- `rqworker` will automatically clean up ghosted worker registrations from\n  pre-0.3.6 runs.\n\n- `rqworker` grew a `-q` flag, to be more silent (only warnings/errors are shown)\n\n\n### 0.3.5\n(February 6th, 2013)\n\n- `ended_at` is now recorded for normally finished jobs, too.  (Previously only\n  for failed jobs.)\n\n- Adds support for both `Redis` and `StrictRedis` connection types\n\n- Makes `StrictRedis` the default connection type if none is explicitly provided\n\n\n### 0.3.4\n(January 23rd, 2013)\n\n- Restore compatibility with Python 2.6.\n\n\n### 0.3.3\n(January 18th, 2013)\n\n- Fix bug where work was lost due to silently ignored unpickle errors.\n\n- Jobs can now access the current `Job` instance from within.  Relevant\n  documentation [here](http://python-rq.org/docs/jobs/).\n\n- Custom properties can be set by modifying the `job.meta` dict.  Relevant\n  documentation [here](http://python-rq.org/docs/jobs/).\n\n- Custom properties can be set by modifying the `job.meta` dict.  Relevant\n  documentation [here](http://python-rq.org/docs/jobs/).\n\n- `rqworker` now has an optional `--password` flag.\n\n- Remove `logbook` dependency (in favor of `logging`)\n\n\n### 0.3.2\n(September 3rd, 2012)\n\n- Fixes broken `rqinfo` command.\n\n- Improve compatibility with Python < 2.7.\n\n\n\n### 0.3.1\n(August 30th, 2012)\n\n- `.enqueue()` now takes a `result_ttl` keyword argument that can be used to\n  change the expiration time of results.\n\n- Queue constructor now takes an optional `async=False` argument to bypass the\n  worker (for testing purposes).\n\n- Jobs now carry status information.  To get job status information, like\n  whether a job is queued, finished, or failed, use the property `status`, or\n  one of the new boolean accessor properties `is_queued`, `is_finished` or\n  `is_failed`.\n\n- Jobs return values are always stored explicitly, even if they have to\n  explicit return value or return `None` (with given TTL of course).  This\n  makes it possible to distinguish between a job that explicitly returned\n  `None` and a job that isn't finished yet (see `status` property).\n\n- Custom exception handlers can now be configured in addition to, or to fully\n  replace, moving failed jobs to the failed queue.  Relevant documentation\n  [here](http://python-rq.org/docs/exceptions/) and\n  [here](http://python-rq.org/patterns/sentry/).\n\n- `rqworker` now supports passing in configuration files instead of the\n  many command line options: `rqworker -c settings` will source\n  `settings.py`.\n\n- `rqworker` now supports one-flag setup to enable Sentry as its exception\n  handler: `rqworker --sentry-dsn=\"http://public:secret@example.com/1\"`\n  Alternatively, you can use a settings file and configure `SENTRY_DSN\n  = 'http://public:secret@example.com/1'` instead.\n\n\n### 0.3.0\n(August 5th, 2012)\n\n- Reliability improvements\n\n    - Warm shutdown now exits immediately when Ctrl+C is pressed and worker is idle\n    - Worker does not leak worker registrations anymore when stopped gracefully\n\n- `.enqueue()` does not consume the `timeout` kwarg anymore.  Instead, to pass\n  RQ a timeout value while enqueueing a function, use the explicit invocation\n  instead:\n\n      ```python\n      q.enqueue(do_something, args=(1, 2), kwargs={'a': 1}, timeout=30)\n      ```\n\n- Add a `@job` decorator, which can be used to do Celery-style delayed\n  invocations:\n\n      ```python\n      from redis import StrictRedis\n      from rq.decorators import job\n\n      # Connect to Redis\n      redis = StrictRedis()\n\n      @job('high', timeout=10, connection=redis)\n      def some_work(x, y):\n          return x + y\n      ```\n\n  Then, in another module, you can call `some_work`:\n\n      ```python\n      from foo.bar import some_work\n\n      some_work.delay(2, 3)\n      ```\n\n\n### 0.2.2\n(August 1st, 2012)\n\n- Fix bug where return values that couldn't be pickled crashed the worker\n\n\n### 0.2.1\n(July 20th, 2012)\n\n- Fix important bug where result data wasn't restored from Redis correctly\n  (affected non-string results only).\n\n\n### 0.2.0\n(July 18th, 2012)\n\n- `q.enqueue()` accepts instance methods now, too.  Objects will be pickle'd\n  along with the instance method, so beware.\n- `q.enqueue()` accepts string specification of functions now, too.  Example:\n  `q.enqueue(\"my.math.lib.fibonacci\", 5)`.  Useful if the worker and the\n  submitter of work don't share code bases.\n- Job can be assigned custom attrs and they will be pickle'd along with the\n  rest of the job's attrs.  Can be used when writing RQ extensions.\n- Workers can now accept explicit connections, like Queues.\n- Various bug fixes.\n\n\n### 0.1.2\n(May 15, 2012)\n\n- Fix broken PyPI deployment.\n\n\n### 0.1.1\n(May 14, 2012)\n\n- Thread-safety by using context locals\n- Register scripts as console_scripts, for better portability\n- Various bugfixes.\n\n\n### 0.1.0:\n(March 28, 2012)\n\n- Initially released version.\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.1171875,
          "content": "FROM python:3.8\n\nWORKDIR /root\n\nCOPY . /tmp/rq\n\nRUN pip install /tmp/rq\n\nRUN rm -r /tmp/rq\n\nENTRYPOINT [\"rq\", \"worker\"]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.466796875,
          "content": "Copyright 2012 Vincent Driessen. All rights reserved.\n\nRedistribution and use in source and binary forms, with or without modification,\nare permitted provided that the following conditions are met:\n\n   1. Redistributions of source code must retain the above copyright notice,\n      this list of conditions and the following disclaimer.\n\n   2. Redistributions in binary form must reproduce the above copyright notice,\n      this list of conditions and the following disclaimer in the documentation\n      and/or other materials provided with the distribution.\n\nTHIS SOFTWARE IS PROVIDED BY VINCENT DRIESSEN ``AS IS'' AND ANY EXPRESS OR\nIMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\nMERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT\nSHALL VINCENT DRIESSEN OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,\nINCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\nPROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\nLIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE\nOR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF\nADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nThe views and conclusions contained in the software and documentation are those\nof the authors and should not be interpreted as representing official policies,\neither expressed or implied, of Vincent Driessen.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.6484375,
          "content": "all:\n\t@grep -Ee '^[a-z].*:' Makefile | cut -d: -f1 | grep -vF all\n\nclean:\n\trm -rf build/ dist/\n\ntest:\n\tdocker build -f tests/Dockerfile . -t rqtest && docker run -it --rm rqtest\n\nrelease: clean\n\t# Check if latest tag is the current head we're releasing\n\techo \"Latest tag = $$(git tag | sort -nr | head -n1)\"\n\techo \"HEAD SHA       = $$(git sha head)\"\n\techo \"Latest tag SHA = $$(git tag | sort -nr | head -n1 | xargs git sha)\"\n\t@test \"$$(git sha head)\" = \"$$(git tag | sort -nr | head -n1 | xargs git sha)\"\n\tmake force_release\n\nforce_release: clean\n\tgit push --tags\n\tpython setup.py sdist bdist_wheel\n\ttwine upload dist/*\n\nlint:\n\t@ ruff check --show-source rq tests\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 3.9453125,
          "content": "RQ (_Redis Queue_) is a simple Python library for queueing jobs and processing\nthem in the background with workers.  It is backed by Redis and it is designed\nto have a low barrier to entry.  It should be integrated in your web stack\neasily.\n\nRQ requires Redis >= 3.0.0.\n\n[![Build status](https://github.com/rq/rq/workflows/Test%20rq/badge.svg)](https://github.com/rq/rq/actions?query=workflow%3A%22Test+rq%22)\n[![PyPI](https://img.shields.io/pypi/pyversions/rq.svg)](https://pypi.python.org/pypi/rq)\n[![Coverage](https://codecov.io/gh/rq/rq/branch/master/graph/badge.svg)](https://codecov.io/gh/rq/rq)\n[![Code style: Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)\n\n\nFull documentation can be found [here][d].\n\n\n## Support RQ\n\nIf you find RQ useful, please consider supporting this project via [Tidelift](https://tidelift.com/subscription/pkg/pypi-rq?utm_source=pypi-rq&utm_medium=referral&utm_campaign=readme).\n\n\n## Getting started\n\nFirst, run a Redis server, of course:\n\n```console\n$ redis-server\n```\n\nTo put jobs on queues, you don't have to do anything special, just define\nyour typically lengthy or blocking function:\n\n```python\nimport requests\n\ndef count_words_at_url(url):\n    \"\"\"Just an example function that's called async.\"\"\"\n    resp = requests.get(url)\n    return len(resp.text.split())\n```\n\nThen, create an RQ queue:\n\n```python\nfrom redis import Redis\nfrom rq import Queue\n\nqueue = Queue(connection=Redis())\n```\n\nAnd enqueue the function call:\n\n```python\nfrom my_module import count_words_at_url\njob = queue.enqueue(count_words_at_url, 'http://nvie.com')\n```\n\nScheduling jobs are also similarly easy:\n\n```python\n# Schedule job to run at 9:15, October 10th\njob = queue.enqueue_at(datetime(2019, 10, 10, 9, 15), say_hello)\n\n# Schedule job to run in 10 seconds\njob = queue.enqueue_in(timedelta(seconds=10), say_hello)\n```\n\nRetrying failed jobs is also supported:\n\n```python\nfrom rq import Retry\n\n# Retry up to 3 times, failed job will be requeued immediately\nqueue.enqueue(say_hello, retry=Retry(max=3))\n\n# Retry up to 3 times, with configurable intervals between retries\nqueue.enqueue(say_hello, retry=Retry(max=3, interval=[10, 30, 60]))\n```\n\nFor a more complete example, refer to the [docs][d].  But this is the essence.\n\n\n### The worker\n\nTo start executing enqueued function calls in the background, start a worker\nfrom your project's directory:\n\n```console\n$ rq worker --with-scheduler\n*** Listening for work on default\nGot count_words_at_url('http://nvie.com') from default\nJob result = 818\n*** Listening for work on default\n```\n\nThat's about it.\n\n\n## Installation\n\nSimply use the following command to install the latest released version:\n\n    pip install rq\n\nIf you want the cutting edge version (that may well be broken), use this:\n\n    pip install git+https://github.com/rq/rq.git@master#egg=rq\n\n\n## Docs\n\nTo build and run the docs, install [jekyll](https://jekyllrb.com/docs/) and run:\n\n```shell\ncd docs\njekyll serve\n```\n\n## Related Projects\n\nIf you use RQ, Check out these below repos which might be useful in your rq based project.\n\n- [django-rq](https://github.com/rq/django-rq)\n- [rq-dashboard](https://github.com/Parallels/rq-dashboard)\n- [rqmonitor](https://github.com/pranavgupta1234/rqmonitor)\n- [Flask-RQ2](https://github.com/rq/Flask-RQ2)\n- [rq-scheduler](https://github.com/rq/rq-scheduler)\n- [rq-dashboard-fastAPI](https://github.com/Hannes221/rq-dashboard-fast)\n\n\n\n## Project history\n\nThis project has been inspired by the good parts of [Celery][1], [Resque][2]\nand [this snippet][3], and has been created as a lightweight alternative to the\nheaviness of Celery or other AMQP-based queueing implementations.\n\n\n[d]: http://python-rq.org/\n[m]: http://pypi.python.org/pypi/mailer\n[p]: http://docs.python.org/library/pickle.html\n[1]: http://docs.celeryq.dev/\n[2]: https://github.com/resque/resque\n[3]: https://github.com/fengsp/flask-snippets/blob/1f65833a4291c5b833b195a09c365aa815baea4e/utilities/rq.py\n"
        },
        {
          "name": "codecov.yml",
          "type": "blob",
          "size": 0.0361328125,
          "content": "ignore:\n  - setup.py\n  - \"*/tests/*\"\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 3.171875,
          "content": "[build-system]\nbuild-backend = \"hatchling.build\"\nrequires = [\n  \"hatchling\",\n]\n\n[project]\nname = \"rq\"\ndescription = \"RQ is a simple, lightweight, library for creating background jobs, and processing them.\"\nreadme = \"README.md\"\nlicense = \"BSD-2-Clause\"\nmaintainers = [\n    {name = \"Selwin Ong\"},\n]\nauthors = [\n    { name = \"Selwin Ong\", email = \"selwin.ong@gmail.com\" },\n    { name = \"Vincent Driessen\", email = \"vincent@3rdcloud.com\" },\n]\nrequires-python = \">=3.8\"\nclassifiers = [\n  \"Development Status :: 5 - Production/Stable\",\n  \"Intended Audience :: Developers\",\n  \"Intended Audience :: End Users/Desktop\",\n  \"Intended Audience :: Information Technology\",\n  \"Intended Audience :: Science/Research\",\n  \"Intended Audience :: System Administrators\",\n  \"License :: OSI Approved :: BSD License\",\n  \"Operating System :: MacOS\",\n  \"Operating System :: POSIX\",\n  \"Operating System :: Unix\",\n  \"Programming Language :: Python\",\n  \"Programming Language :: Python :: 3 :: Only\",\n  \"Programming Language :: Python :: 3.8\",\n  \"Programming Language :: Python :: 3.9\",\n  \"Programming Language :: Python :: 3.10\",\n  \"Programming Language :: Python :: 3.11\",\n  \"Programming Language :: Python :: 3.12\",\n  \"Topic :: Internet\",\n  \"Topic :: Scientific/Engineering\",\n  \"Topic :: Software Development :: Libraries :: Python Modules\",\n  \"Topic :: System :: Distributed Computing\",\n  \"Topic :: System :: Monitoring\",\n  \"Topic :: System :: Systems Administration\",\n]\ndynamic = [\n  \"version\",\n]\ndependencies = [\n  \"click>=5\",\n  \"redis>=3.5\",\n]\n[project.urls]\nchangelog = \"https://github.com/rq/rq/blob/master/CHANGES.md\"\ndocumentation = \"https://python-rq.org/docs/\"\nhomepage = \"https://python-rq.org/\"\nrepository = \"https://github.com/rq/rq/\"\n[project.scripts]\nrq = \"rq.cli:main\"\nrqinfo = \"rq.cli:info\"  # TODO [v2]: Remove\nrqworker = \"rq.cli:worker\"  # TODO [v2]: Remove\n\n[tool.hatch.version]\npath = \"rq/version.py\"\n\n[tool.hatch.build.targets.sdist]\ninclude = [\n    \"/docs\",\n    \"/rq\",\n    \"/tests\",\n    \"CHANGES.md\",\n    \"LICENSE\",\n    \"pyproject.toml\",\n    \"README.md\",\n    \"requirements.txt\",\n    \"tox.ini\",\n]\n\n[tool.hatch.envs.test]\ndependencies = [\n  \"coverage\",\n  \"mypy\",\n  \"packaging\",\n  \"psutil\",\n  \"pytest\",\n  \"pytest-cov\",\n  \"ruff\",\n  \"tox\",\n  \"types-greenlet\",\n  \"types-redis\",\n]\n[tool.hatch.envs.test.scripts]\ncov = \"pytest --cov=rq --cov-config=.coveragerc --cov-report=xml {args:tests}\"\ntyping = \"mypy --enable-incomplete-feature=Unpack rq\"\n\n[tool.mypy]\nallow_redefinition = true\npretty = true\nshow_error_codes = true\nshow_error_context = true\nwarn_redundant_casts = true\nwarn_unused_ignores = true\nwarn_unreachable = true\n\n[[tool.mypy.overrides]]\nmodule = \"setproctitle.*\"\nignore_missing_imports = true\n\n[tool.ruff]\n# Set what ruff should check for.\n# See https://beta.ruff.rs/docs/rules/ for a list of rules.\nlint.select = [\n    \"E\", # pycodestyle errors\n    \"F\", # pyflakes errors\n    \"I\", # import sorting\n    \"W\", # pycodestyle warnings\n]\nline-length = 120\ntarget-version = \"py38\"\n\n[tool.ruff.lint.isort]\nknown-first-party = [\"rq\"]\nsection-order = [\"future\", \"standard-library\", \"third-party\", \"first-party\", \"local-folder\"]\n\n[tool.ruff.format]\nquote-style = \"single\"\n\n[tool.pyright]\nreportOptionalMemberAccess = false\nreportOptionalOperand = false\n"
        },
        {
          "name": "rq",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "tox.ini",
          "type": "blob",
          "size": 0.8330078125,
          "content": "[tox]\nenvlist=py37,py38,py39,py310,py311\n\n[testenv]\ncommands=pytest --cov rq --cov-config=.coveragerc --durations=5 {posargs}\ndeps=\n    codecov\n    psutil\n    pytest\n    pytest-cov\npassenv=\n    RUN_SSL_TESTS\n\n; [testenv:lint]\n; basepython = python3.10\n; deps =\n;     ruff\n; commands =\n;     ruff check rq tests\n\n[testenv:py37]\nskipdist = True\nbasepython = python3.7\ndeps = {[testenv]deps}\n\n[testenv:py38]\nskipdist = True\nbasepython = python3.8\ndeps = {[testenv]deps}\n\n[testenv:py39]\nskipdist = True\nbasepython = python3.9\ndeps = {[testenv]deps}\n\n[testenv:py310]\nskipdist = True\nbasepython = python3.10\ndeps = {[testenv]deps}\n\n[testenv:py311]\nskipdist = True\nbasepython = python3.11\ndeps = {[testenv]deps}\n\n[testenv:ssl]\nskipdist = True\nbasepython = python3.10\ndeps=\n    pytest\n    psutil\npassenv=\n    RUN_SSL_TESTS\ncommands=pytest -m ssl_test {posargs}\n"
        }
      ]
    }
  ]
}