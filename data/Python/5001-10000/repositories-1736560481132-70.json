{
  "metadata": {
    "timestamp": 1736560481132,
    "page": 70,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjcw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "eriklindernoren/Keras-GAN",
      "stars": 9201,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0966796875,
          "content": "*/images/*.png\n*/images/*.jpg\n*/*.jpg\n*/*.png\n*.json\n*.h5\n*.hdf5\n.DS_Store\n*/datasets\n\n__pycache__\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0498046875,
          "content": "MIT License\n\nCopyright (c) 2017 Erik Linder-Nor√©n\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 8.6806640625,
          "content": "<p align=\"center\">\n    <img src=\"assets/keras_gan.png\" width=\"480\"\\>\n</p>\n\n**This repository has gone stale as I unfortunately do not have the time to maintain it anymore. If you would like to continue the development of it as a collaborator send me an email at eriklindernoren@gmail.com.**\n\n## Keras-GAN\nCollection of Keras implementations of Generative Adversarial Networks (GANs) suggested in research papers. These models are in some cases simplified versions of the ones ultimately described in the papers, but I have chosen to focus on getting the core ideas covered instead of getting every layer configuration right. Contributions and suggestions of GAN varieties to implement are very welcomed.\n\n<b>See also:</b> [PyTorch-GAN](https://github.com/eriklindernoren/PyTorch-GAN)\n\n## Table of Contents\n  * [Installation](#installation)\n  * [Implementations](#implementations)\n    + [Auxiliary Classifier GAN](#ac-gan)\n    + [Adversarial Autoencoder](#adversarial-autoencoder)\n    + [Bidirectional GAN](#bigan)\n    + [Boundary-Seeking GAN](#bgan)\n    + [Conditional GAN](#cgan)\n    + [Context-Conditional GAN](#cc-gan)\n    + [Context Encoder](#context-encoder)\n    + [Coupled GANs](#cogan)\n    + [CycleGAN](#cyclegan)\n    + [Deep Convolutional GAN](#dcgan)\n    + [DiscoGAN](#discogan)\n    + [DualGAN](#dualgan)\n    + [Generative Adversarial Network](#gan)\n    + [InfoGAN](#infogan)\n    + [LSGAN](#lsgan)\n    + [Pix2Pix](#pix2pix)\n    + [PixelDA](#pixelda)\n    + [Semi-Supervised GAN](#sgan)\n    + [Super-Resolution GAN](#srgan)\n    + [Wasserstein GAN](#wgan)\n    + [Wasserstein GAN GP](#wgan-gp)     \n\n## Installation\n    $ git clone https://github.com/eriklindernoren/Keras-GAN\n    $ cd Keras-GAN/\n    $ sudo pip3 install -r requirements.txt\n\n## Implementations   \n### AC-GAN\nImplementation of _Auxiliary Classifier Generative Adversarial Network_.\n\n[Code](acgan/acgan.py)\n\nPaper: https://arxiv.org/abs/1610.09585\n\n#### Example\n```\n$ cd acgan/\n$ python3 acgan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/acgan.gif\" width=\"640\"\\>\n</p>\n\n### Adversarial Autoencoder\nImplementation of _Adversarial Autoencoder_.\n\n[Code](aae/aae.py)\n\nPaper: https://arxiv.org/abs/1511.05644\n\n#### Example\n```\n$ cd aae/\n$ python3 aae.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/aae.png\" width=\"640\"\\>\n</p>\n\n### BiGAN\nImplementation of _Bidirectional Generative Adversarial Network_.\n\n[Code](bigan/bigan.py)\n\nPaper: https://arxiv.org/abs/1605.09782\n\n#### Example\n```\n$ cd bigan/\n$ python3 bigan.py\n```\n\n### BGAN\nImplementation of _Boundary-Seeking Generative Adversarial Networks_.\n\n[Code](bgan/bgan.py)\n\nPaper: https://arxiv.org/abs/1702.08431\n\n#### Example\n```\n$ cd bgan/\n$ python3 bgan.py\n```\n\n### CC-GAN\nImplementation of _Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks_.\n\n[Code](ccgan/ccgan.py)\n\nPaper: https://arxiv.org/abs/1611.06430\n\n#### Example\n```\n$ cd ccgan/\n$ python3 ccgan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/ccgan.png\" width=\"640\"\\>\n</p>\n\n### CGAN\nImplementation of _Conditional Generative Adversarial Nets_.\n\n[Code](cgan/cgan.py)\n\nPaper:https://arxiv.org/abs/1411.1784\n\n#### Example\n```\n$ cd cgan/\n$ python3 cgan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/cgan.gif\" width=\"640\"\\>\n</p>\n\n### Context Encoder\nImplementation of _Context Encoders: Feature Learning by Inpainting_.\n\n[Code](context_encoder/context_encoder.py)\n\nPaper: https://arxiv.org/abs/1604.07379\n\n#### Example\n```\n$ cd context_encoder/\n$ python3 context_encoder.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/context_encoder.png\" width=\"640\"\\>\n</p>\n\n### CoGAN\nImplementation of _Coupled generative adversarial networks_.\n\n[Code](cogan/cogan.py)\n\nPaper: https://arxiv.org/abs/1606.07536\n\n#### Example\n```\n$ cd cogan/\n$ python3 cogan.py\n```\n\n### CycleGAN\nImplementation of _Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks_.\n\n[Code](cyclegan/cyclegan.py)\n\nPaper: https://arxiv.org/abs/1703.10593\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/cyclegan.png\" width=\"640\"\\>\n</p>\n\n#### Example\n```\n$ cd cyclegan/\n$ bash download_dataset.sh apple2orange\n$ python3 cyclegan.py\n```   \n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/cyclegan_gif.gif\" width=\"640\"\\>\n</p>\n\n\n### DCGAN\nImplementation of _Deep Convolutional Generative Adversarial Network_.\n\n[Code](dcgan/dcgan.py)\n\nPaper: https://arxiv.org/abs/1511.06434\n\n#### Example\n```\n$ cd dcgan/\n$ python3 dcgan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/dcgan2.png\" width=\"640\"\\>\n</p>\n\n### DiscoGAN\nImplementation of _Learning to Discover Cross-Domain Relations with Generative Adversarial Networks_.\n\n[Code](discogan/discogan.py)\n\nPaper: https://arxiv.org/abs/1703.05192\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/discogan_architecture.png\" width=\"640\"\\>\n</p>\n\n#### Example\n```\n$ cd discogan/\n$ bash download_dataset.sh edges2shoes\n$ python3 discogan.py\n```   \n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/discogan.png\" width=\"640\"\\>\n</p>\n\n### DualGAN\nImplementation of _DualGAN: Unsupervised Dual Learning for Image-to-Image Translation_.\n\n[Code](dualgan/dualgan.py)\n\nPaper: https://arxiv.org/abs/1704.02510\n\n#### Example\n```\n$ cd dualgan/\n$ python3 dualgan.py\n```\n\n### GAN\nImplementation of _Generative Adversarial Network_ with a MLP generator and discriminator.\n\n[Code](gan/gan.py)\n\nPaper: https://arxiv.org/abs/1406.2661\n\n#### Example\n```\n$ cd gan/\n$ python3 gan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/gan_mnist5.gif\" width=\"640\"\\>\n</p>\n\n### InfoGAN\nImplementation of _InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets_.\n\n[Code](infogan/infogan.py)\n\nPaper: https://arxiv.org/abs/1606.03657\n\n#### Example\n```\n$ cd infogan/\n$ python3 infogan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/infogan.png\" width=\"640\"\\>\n</p>\n\n### LSGAN\nImplementation of _Least Squares Generative Adversarial Networks_.\n\n[Code](lsgan/lsgan.py)\n\nPaper: https://arxiv.org/abs/1611.04076\n\n#### Example\n```\n$ cd lsgan/\n$ python3 lsgan.py\n```\n\n### Pix2Pix\nImplementation of _Image-to-Image Translation with Conditional Adversarial Networks_.\n\n[Code](pix2pix/pix2pix.py)\n\nPaper: https://arxiv.org/abs/1611.07004\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/pix2pix_architecture.png\" width=\"640\"\\>\n</p>\n\n#### Example\n```\n$ cd pix2pix/\n$ bash download_dataset.sh facades\n$ python3 pix2pix.py\n```   \n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/pix2pix2.png\" width=\"640\"\\>\n</p>\n\n### PixelDA\nImplementation of _Unsupervised Pixel-Level Domain Adaptation with Generative Adversarial Networks_.\n\n[Code](pixelda/pixelda.py)\n\nPaper: https://arxiv.org/abs/1612.05424\n\n#### MNIST to MNIST-M Classification\nTrains a classifier on MNIST images that are translated to resemble MNIST-M (by performing unsupervised image-to-image domain adaptation). This model is compared to the naive solution of training a classifier on MNIST and evaluating it on MNIST-M. The naive model manages a 55% classification accuracy on MNIST-M while the one trained during domain adaptation gets a 95% classification accuracy.\n\n```\n$ cd pixelda/\n$ python3 pixelda.py\n```\n\n| Method       | Accuracy  |\n| ------------ |:---------:|\n| Naive        | 55%       |\n| PixelDA      | 95%       |\n\n### SGAN\nImplementation of _Semi-Supervised Generative Adversarial Network_.\n\n[Code](sgan/sgan.py)\n\nPaper: https://arxiv.org/abs/1606.01583\n\n#### Example\n```\n$ cd sgan/\n$ python3 sgan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/sgan.png\" width=\"640\"\\>\n</p>\n\n### SRGAN\nImplementation of _Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network_.\n\n[Code](srgan/srgan.py)\n\nPaper: https://arxiv.org/abs/1609.04802\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/superresgan.png\" width=\"640\"\\>\n</p>\n\n\n#### Example\n```\n$ cd srgan/\n<follow steps at the top of srgan.py>\n$ python3 srgan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/srgan.png\" width=\"640\"\\>\n</p>\n\n### WGAN\nImplementation of _Wasserstein GAN_ (with DCGAN generator and discriminator).\n\n[Code](wgan/wgan.py)\n\nPaper: https://arxiv.org/abs/1701.07875\n\n#### Example\n```\n$ cd wgan/\n$ python3 wgan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/wgan2.png\" width=\"640\"\\>\n</p>\n\n### WGAN GP\nImplementation of _Improved Training of Wasserstein GANs_.\n\n[Code](wgan_gp/wgan_gp.py)\n\nPaper: https://arxiv.org/abs/1704.00028\n\n#### Example\n```\n$ cd wgan_gp/\n$ python3 wgan_gp.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/imp_wgan.gif\" width=\"640\"\\>\n</p>\n"
        },
        {
          "name": "aae",
          "type": "tree",
          "content": null
        },
        {
          "name": "acgan",
          "type": "tree",
          "content": null
        },
        {
          "name": "assets",
          "type": "tree",
          "content": null
        },
        {
          "name": "bgan",
          "type": "tree",
          "content": null
        },
        {
          "name": "bigan",
          "type": "tree",
          "content": null
        },
        {
          "name": "ccgan",
          "type": "tree",
          "content": null
        },
        {
          "name": "cgan",
          "type": "tree",
          "content": null
        },
        {
          "name": "cogan",
          "type": "tree",
          "content": null
        },
        {
          "name": "context_encoder",
          "type": "tree",
          "content": null
        },
        {
          "name": "cyclegan",
          "type": "tree",
          "content": null
        },
        {
          "name": "dcgan",
          "type": "tree",
          "content": null
        },
        {
          "name": "discogan",
          "type": "tree",
          "content": null
        },
        {
          "name": "dualgan",
          "type": "tree",
          "content": null
        },
        {
          "name": "gan",
          "type": "tree",
          "content": null
        },
        {
          "name": "infogan",
          "type": "tree",
          "content": null
        },
        {
          "name": "lsgan",
          "type": "tree",
          "content": null
        },
        {
          "name": "pix2pix",
          "type": "tree",
          "content": null
        },
        {
          "name": "pixelda",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.1328125,
          "content": "keras\ngit+https://www.github.com/keras-team/keras-contrib.git\nmatplotlib\nnumpy\nscipy\npillow\n#urllib\n#skimage\nscikit-image\n#gzip\n#pickle\n"
        },
        {
          "name": "sgan",
          "type": "tree",
          "content": null
        },
        {
          "name": "srgan",
          "type": "tree",
          "content": null
        },
        {
          "name": "wgan",
          "type": "tree",
          "content": null
        },
        {
          "name": "wgan_gp",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}