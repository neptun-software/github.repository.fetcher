{
  "metadata": {
    "timestamp": 1736560675638,
    "page": 325,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjMzMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "hyperopt/hyperopt",
      "stars": 7309,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.740234375,
          "content": "distribute*\n*.pyc\n*.swp\n*egg-info*\nbuild/\ndist/\n.cache\nvenv\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nvenv\nenv/\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\n*.egg-info/\n.installed.cfg\n*.egg\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\ncoverage.xml\n*,cover\n\n# IDE\n.idea/\n.ipynb_checkpoints/\n\n# MacOS\n.DS_Store\n\n# Generated documentation folders\nsources/\nsite/\n\n.vscode\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.20703125,
          "content": "repos:\n-   repo: https://github.com/psf/black\n    rev: 24.10.0\n    hooks:\n    - id: black\n-   repo: https://github.com/asottile/pyupgrade\n    rev: v3.19.1\n    hooks:\n    - id: pyupgrade\n      args: [--py38-plus]\n"
        },
        {
          "name": "LICENSE.txt",
          "type": "blob",
          "size": 1.4619140625,
          "content": "LICENSE\n=======\n\nCopyright (c) 2013, James Bergstra\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n    * Redistributions in binary form must reproduce the above copyright\n      notice, this list of conditions and the following disclaimer in the\n      documentation and/or other materials provided with the distribution.\n    * Neither the name of hyperopt nor the names of its contributors may be\n      used to endorse or promote products derived from this software without\n      specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ''AS IS'' AND ANY\nEXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS BE LIABLE FOR ANY\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.0283203125,
          "content": "recursive-include hyperopt *\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 7.251953125,
          "content": "\n# Hyperopt: Distributed Hyperparameter Optimization\n\n<p align=\"center\">\n<img src=\"https://i.postimg.cc/TPmffWrp/hyperopt-new.png\" />\n</p>\n\n[![build](https://github.com/hyperopt/hyperopt/actions/workflows/build.yml/badge.svg)](https://github.com/hyperopt/hyperopt/actions/workflows/build.yml)\n[![pre-commit.ci status](https://results.pre-commit.ci/badge/github/hyperopt/hyperopt/master.svg)](https://results.pre-commit.ci/latest/github/hyperopt/hyperopt/master)\n[![PyPI version](https://badge.fury.io/py/hyperopt.svg)](https://badge.fury.io/py/hyperopt)\n[![Anaconda-Server Badge](https://anaconda.org/conda-forge/hyperopt/badges/version.svg)](https://anaconda.org/conda-forge/hyperopt)\n\n[Hyperopt](https://github.com/hyperopt/hyperopt) is a Python library for serial and parallel optimization over awkward\nsearch spaces, which may include real-valued, discrete, and conditional\ndimensions.\n\n## Getting started\n\nInstall hyperopt from PyPI\n\n```bash\npip install hyperopt\n```\n\nto run your first example\n\n```python\n# define an objective function\ndef objective(args):\n    case, val = args\n    if case == 'case 1':\n        return val\n    else:\n        return val ** 2\n\n# define a search space\nfrom hyperopt import hp\nspace = hp.choice('a',\n    [\n        ('case 1', 1 + hp.lognormal('c1', 0, 1)),\n        ('case 2', hp.uniform('c2', -10, 10))\n    ])\n\n# minimize the objective over the space\nfrom hyperopt import fmin, tpe, space_eval\nbest = fmin(objective, space, algo=tpe.suggest, max_evals=100)\n\nprint(best)\n# -> {'a': 1, 'c2': 0.01420615366247227}\nprint(space_eval(space, best))\n# -> ('case 2', 0.01420615366247227}\n```\n\n## Contributing\n\nIf you're a developer and wish to contribute, please follow these steps.\n\n### Setup (based on [this](https://scikit-learn.org/stable/developers/contributing.html#contributing-code))\n\n1. Create an account on GitHub if you do not already have one.\n\n2. Fork the project repository: click on the ‘Fork’ button near the top of the page. This creates a copy of the code under your account on the GitHub user account. For more details on how to fork a repository see [this guide](https://help.github.com/articles/fork-a-repo/).\n\n3. Clone your fork of the hyperopt repo from your GitHub account to your local disk:\n\n   ```bash\n   git clone https://github.com/<github username>/hyperopt.git\n   cd hyperopt\n   ```\n\n4. Create environment with:  \n   `$ python3 -m venv my_env` or `$ python -m venv my_env`\n   or with conda:  \n   `$ conda create -n my_env python=3`\n\n5. Activate the environment:  \n   `$ source my_env/bin/activate`  \n   or with conda:  \n   `$ conda activate my_env`\n\n6. Install dependencies for extras (you'll need these to run pytest):\n   Linux/UNIX:\n   `$ pip install -e '.[MongoTrials, SparkTrials, ATPE, dev]'`\n\n   or Windows:\n\n   ```cmd\n   pip install -e .[MongoTrials]\n   pip install -e .[SparkTrials]\n   pip install -e .[ATPE]\n   pip install -e .[dev]\n   ```\n\n7. Add the upstream remote. This saves a reference to the main hyperopt repository, which you can use to keep your repository synchronized with the latest changes:\n\n    `$ git remote add upstream https://github.com/hyperopt/hyperopt.git`\n\n    You should now have a working installation of hyperopt, and your git repository properly configured. The next steps now describe the process of modifying code and submitting a PR:\n\n8. Synchronize your master branch with the upstream master branch:\n\n    ```bash\n    git checkout master\n    git pull upstream master\n    ```\n\n9. Create a feature branch to hold your development changes:\n\n    `$ git checkout -b my_feature`\n\n    and start making changes. Always use a feature branch. It’s good practice to never work on the master branch!\n\n10. We recommend to use [Black](https://github.com/psf/black) to format your code before submitting a PR which is installed automatically in step 6.\n\n11. Then, once you commit ensure that git hooks are activated (Pycharm for example has the option to omit them). This can be done using [pre-commit](https://pre-commit.com/), which is installed automatically in step 6, as follows:\n\n    ```bash\n    pre-commit install\n    ```\n\n    This will run black automatically when you commit on all files you modified, failing if there are any files requiring to be blacked. In case black does not run execute the following:\n\n    ```bash\n    black {source_file_or_directory}\n    ```\n\n12. Develop the feature on your feature branch on your computer, using Git to do the version control. When you’re done editing, add changed files using git add and then git commit:\n\n    ```bash\n    git add modified_files\n    git commit -m \"my first hyperopt commit\"\n    ```\n\n13. The tests for this project use [PyTest](https://docs.pytest.org/en/latest/) and can be run by calling `pytest`.\n\n14. Record your changes in Git, then push the changes to your GitHub account with:\n\n    ```bash\n    git push -u origin my_feature\n    ```\n\nNote that dev dependencies require python 3.6+.\n\n## Algorithms\n\nCurrently three algorithms are implemented in hyperopt:\n\n- [Random Search](http://www.jmlr.org/papers/v13/bergstra12a.html?source=post_page---------------------------)\n- [Tree of Parzen Estimators (TPE)](https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf)\n- [Adaptive TPE](https://articulon.bradleyarsenault.me/article/learning-to-optimize)\n\nHyperopt has been designed to accommodate Bayesian optimization algorithms based on Gaussian processes and regression trees, but these are not currently implemented.\n\nAll algorithms can be parallelized in two ways, using:\n\n- [Apache Spark](https://spark.apache.org/)\n- [MongoDB](https://mongodb.com)\n\n## Documentation\n\n[Hyperopt documentation can be found here](http://hyperopt.github.io/hyperopt), but is partly still hosted on the wiki. Here are some quick links to the most relevant pages:\n\n- [Basic tutorial](https://github.com/hyperopt/hyperopt/wiki/FMin)\n- [Installation notes](https://github.com/hyperopt/hyperopt/wiki/Installation-Notes)\n- [Using mongodb](https://github.com/hyperopt/hyperopt/wiki/Parallelizing-Evaluations-During-Search-via-MongoDB)\n\n## Related Projects\n\n- [hyperopt-sklearn](https://github.com/hyperopt/hyperopt-sklearn)\n- [hyperopt-nnet](https://github.com/hyperopt/hyperopt-nnet)\n- [hyperas](https://github.com/maxpumperla/hyperas)\n- [hyperopt-convent](https://github.com/hyperopt/hyperopt-convnet)\n- [hyperopt-gpsmbo](https://github.com/hyperopt/hyperopt-gpsmbo/blob/master/hp_gpsmbo/hpsuggest.py)\n\n## Examples\n\nSee [projects using hyperopt](https://github.com/hyperopt/hyperopt/wiki/Hyperopt-in-Other-Projects) on the wiki.\n\n## Announcements mailing list\n\n[Announcements](https://groups.google.com/forum/#!forum/hyperopt-announce)\n\n## Discussion mailing list\n\n[Discussion](https://groups.google.com/forum/#!forum/hyperopt-discuss)\n\n## Cite\n\nIf you use this software for research, please cite the paper (http://proceedings.mlr.press/v28/bergstra13.pdf) as follows:\n\nBergstra, J., Yamins, D., Cox, D. D. (2013) Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures. TProc. of the 30th International Conference on Machine Learning (ICML 2013), June 2013, pp. I-115 to I-23.\n\n## Thanks\n\nThis project has received support from\n\n- National Science Foundation (IIS-0963668),\n- Banting Postdoctoral Fellowship program,\n- National Science and Engineering Research Council of Canada (NSERC),\n- D-Wave Systems, Inc.\n"
        },
        {
          "name": "RELEASE.txt",
          "type": "blob",
          "size": 0.357421875,
          "content": "1. Update the version number in hyperopt/__init__.py\n2. Remove old wheels: sudo rm -rf dist/*\n3. Build wheels for current version: sudo python3 setup.py sdist bdist_wheel\n4. git tag <version> -m \"message to identify, if needed\"\n5. git push origin <version>\n6. Upload to PyPI with twine: twine upload dist/*\n7. announce to hyperopt-announce (maybe also scikit-learn?)"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "hyperopt",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 2.3212890625,
          "content": "import re\n\nimport setuptools\n\nwith open(\"hyperopt/__init__.py\", encoding=\"utf8\") as f:\n    version = re.search(r\"__version__ = \\\"(.*?)\\\"\", f.read()).group(1)\n    if version is None:\n        raise ImportError(\"Could not find __version__ in hyperopt/__init__.py\")\n\nsetuptools.setup(\n    name=\"hyperopt\",\n    version=version,\n    packages=setuptools.find_packages(include=[\"hyperopt*\"]),\n    entry_points={\"console_scripts\": [\"hyperopt-mongo-worker=hyperopt.mongoexp:main\"]},\n    url=\"https://hyperopt.github.io/hyperopt\",\n    project_urls={\n        \"Source\": \"https://github.com/hyperopt/hyperopt\",\n    },\n    author=\"James Bergstra\",\n    author_email=\"james.bergstra@gmail.com\",\n    description=\"Distributed Asynchronous Hyperparameter Optimization\",\n    long_description=\"\",\n    classifiers=[\n        \"Development Status :: 3 - Alpha\",\n        \"Intended Audience :: Education\",\n        \"Intended Audience :: Science/Research\",\n        \"Intended Audience :: Developers\",\n        \"Environment :: Console\",\n        \"License :: OSI Approved :: BSD License\",\n        \"Operating System :: MacOS :: MacOS X\",\n        \"Operating System :: Microsoft :: Windows\",\n        \"Operating System :: POSIX\",\n        \"Operating System :: Unix\",\n        \"Programming Language :: Python\",\n        \"Programming Language :: Python :: 3\",\n        \"Programming Language :: Python :: 3 :: Only\",\n        \"Programming Language :: Python :: 3.8\",\n        \"Programming Language :: Python :: 3.9\",\n        \"Programming Language :: Python :: 3.10\",\n        \"Programming Language :: Python :: 3.11\",\n        \"Programming Language :: Python :: 3.12\",\n        \"Topic :: Scientific/Engineering\",\n        \"Topic :: Software Development\",\n    ],\n    platforms=[\"Linux\", \"OS-X\", \"Windows\"],\n    license=\"BSD\",\n    keywords=\"Bayesian optimization hyperparameter model selection\",\n    include_package_data=True,\n    requires_python=\">=3.8\",\n    install_requires=[\n        \"numpy>=1.17\",\n        \"scipy>=1.5.0\",\n        \"networkx>=2.2\",\n        \"tqdm\",\n        \"cloudpickle\",\n        \"importlib-resources>=1.3; python_version < '3.9'\",\n    ],\n    extras_require={\n        \"SparkTrials\": [\"pyspark\", \"py4j\"],\n        \"MongoTrials\": \"pymongo>=4.0.0\",\n        \"ATPE\": [\"lightgbm\", \"scikit-learn\"],\n        \"dev\": [\"black\", \"pre-commit\", \"pytest\"],\n    },\n    tests_require=[\"pytest\", \"packaging\"],\n    zip_safe=False,\n)\n"
        },
        {
          "name": "tutorial",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}