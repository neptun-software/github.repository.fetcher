{
  "metadata": {
    "timestamp": 1736561067656,
    "page": 856,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjg2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "lonePatient/awesome-pretrained-chinese-nlp-models",
      "stars": 5029,
      "defaultBranch": "main",
      "files": [
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.04296875,
          "content": "MIT License\n\nCopyright (c) 2021 Weitang Liu\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 331.4287109375,
          "content": "# Awesome Pretrained Chinese NLP Models[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)\n\n![](/resources/LLMS.png)\n<div align=\"center\"> \n    <a href=\"https://arxiv.org/pdf/2303.18223.pdf\">è®ºæ–‡: A Survey of Large Language Models</a>\n</div>\n\nåœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸä¸­ï¼Œé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆPretrained Language Modelsï¼‰å·²æˆä¸ºéå¸¸é‡è¦çš„åŸºç¡€æŠ€æœ¯ï¼Œæœ¬ä»“åº“ä¸»è¦æ”¶é›†ç›®å‰ç½‘ä¸Šå…¬å¼€çš„ä¸€äº›é«˜è´¨é‡ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹ã€ä¸­æ–‡å¤šæ¨¡æ€æ¨¡å‹ã€ä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹ç­‰å†…å®¹(æ„Ÿè°¢åˆ†äº«èµ„æºçš„å¤§ä½¬)ï¼Œå¹¶å°†æŒç»­æ›´æ–°......\n\n> å›½å†…ä¸‹è½½HuggingFaceä»“åº“æ¨¡å‹æ¨èä½¿ç”¨HuggingFaceé•œåƒåœ°å€: https://hf-mirror.com/\n\n# Expand Table of Contents\n\n+ [æ›´æ–°æ—¥å¿—](#æ›´æ–°)\n\n+ [é€šç”¨åŸºç¡€å¤§æ¨¡å‹](#Base-LLM)\n\n+ [å‚ç›´åŸºç¡€å¤§æ¨¡å‹](#Domain-Base-LLM)\n\n+ [é€šç”¨å¯¹è¯å¤§æ¨¡å‹](#ChatLLM)\n\n+ [å‚ç›´å¯¹è¯å¤§æ¨¡å‹](#Domain-ChatLLM)\n\n+ [å¤šæ¨¡æ€å¯¹è¯å¤§æ¨¡å‹](#MultiModal-ChatLLM)\n\n+ [æ¨ç†ç±»å¤§æ¨¡å‹](#ReasoningLLM)\n\n+ [å¤§æ¨¡å‹è¯„ä¼°åŸºå‡†](#å¤§æ¨¡å‹è¯„ä¼°åŸºå‡†)\n\n+ [åœ¨çº¿ä½“éªŒå¤§æ¨¡å‹](#åœ¨çº¿ä½“éªŒå¤§æ¨¡å‹)\n\n+ [å¼€æºæ¨¡å‹åº“å¹³å°](#å¼€æºæ¨¡å‹åº“å¹³å°)\n\n+ [å¼€æºæ•°æ®é›†åº“](#å¼€æºæ•°æ®é›†åº“)\n\n+ [å¼€æºä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†](#ä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†)\n\n+ [Embedding](#Embedding)\n  \n+ [Other-Awesome](#other-awesome)\n\n+ <details><summary>NLUç³»åˆ—</summary>\n  \n  - [BERT](#BERT)\n  - [RoBERTa](#RoBERTa)\n  - [ALBERT](#ALBERT)\n  - [NEZHA](#NEZHA)\n  - [XLNET](#XLNET)\n  - [MacBERT](#MacBERT)\n  - [WoBERT](#WoBERT)\n  - [ELECTRA](#ELECTRA)\n  - [ZEN](#ZEN)\n  - [ERNIE](#ERNIE)\n  - [ERNIE3](#ERNIE3)\n  - [RoFormer](#RoFormer)\n  - [StructBERT](#StructBERT)\n  - [Lattice-BERT](#Lattice-BERT)\n  - [Mengzi-BERT](#Mengzi-BERT)\n  - [ChineseBERT](#ChineseBERT)\n  - [TaCL](#TaCL) \n  - [MC-BERT](#MC-BERT)\n  - [äºŒéƒç¥](#äºŒéƒç¥)\n  - [PERT](#PERT)\n  - [MobileBERT](#MobileBERT)\n  - [GAU-Î±](#GAU-Î±)\n  - [DeBERTa](#DeBERTa)\n  - [GlyphBERT](#GlyphBERT)\n  - [CKBERT](#CKBERT)\n  - [LERT](#LERT)\n  - [RoCBert](#RoCBert)\n  - [m3e](#M3E)\n  - [LEALLA](#LEALLA)\n  \n\n</details>\n\n+ <details><summary>NLGç³»åˆ—</summary>\n  \n  - [GPT](#GPT)\n  - [GPT-3](#GPT-3)\n  - [NEZHA-GEN](#NEZHA-GEN)\n  - [CPM-Generate](#CPM-Generate)\n  - [T5](#T5)\n  - [T5-PEGASUS](#T5-PEGASUS)\n  - [Mengzi-T5](#Mengzi-T5)\n  - [ç›˜å¤Î±](#PanGu-Alpha)\n  - [EVA](#EVA)\n  - [BART](#BART)\n  - [é—»ä»²](#é—»ä»²)\n  - [ä½™å…ƒ](#ä½™å…ƒ)\n  - [RWKV](#RWKV)\n  - [Bloom](#Bloom)\n  - [PromptCLUE](#PromptCLUE)\n  - [ChatYuan](#ChatYuan)\n  - [SkyText](#SkyText)\n  - [ProphetNet](#ProphetNet)\n\n</details>\n\n+ <details><summary>NLU-NLGç³»åˆ—</summary>\n  \n  - [UniLM](#UniLM)\n  - [Simbert](#Simbert)\n  - [RoFormer-sim](#RoFormer-sim)\n  - [CPM-2](#CPM-2)\n  - [CPT](#CPT)\n  - [å‘¨æ–‡ç‹](#å‘¨æ–‡ç‹)\n  - [GLM](#GLM)\n  - [PLUG](#PLUG)\n  - [OPD](#OPD)\n\n  </details>\n\n+ <details><summary>Multi-Modal</summary>\n  \n  - [WenLan](#WenLan)\n  - [CogView](#CogView)\n  - [ç´«ä¸œå¤ªåˆ](#ç´«ä¸œå¤ªåˆ)\n  - [Mengzi-oscar](#Mengzi-oscar)\n  - [R2D2](#R2D2)\n  - [Chinese-CLIP](#Chinese-CLIP)\n  - [TaiYi-CLIP](#TaiYi-CLIP)\n  - [AltCLIP](#AltCLIP)\n  - [AltDiffusion](#AltDiffusion)\n  - [Taiyi-Stable-Diffusion](#Taiyi-Stable-Diffusion)\n  - [wukong](#wukong)\n  - [OFA](#OFA)\n  - [QA-CLIP](#QA-CLIP)\n\n</details>\n\n+ <details><summary>Table</summary>\n  \n  - [SDCUP](#SDCUP)\n\n</details>\n\n` å¤‡æ³¨`\n\n>ND:  Non-Causal Decoder or Prefix LM\n\n>CD:  Causal Decoder\n\n>ED:  Encoder-Decoder\n\n## Base-LLM\n\n> å¤§è§„æ¨¡åŸºç¡€æ¨¡å‹ï¼šè¡¨æ ¼ä¸­åªç½—åˆ—å‡ºå‚æ•°é‡`å¤§äº7B`ä»¥ä¸Šæ¨¡å‹ã€‚\n\n|         æ¨¡å‹          |       å¤§å°        | æ—¶é—´    | è¯­è¨€ | é¢†åŸŸ |                             ä¸‹è½½                             |                           é¡¹ç›®åœ°å€                           |                          æœºæ„/ä¸ªäºº                           | æ¶æ„ |                             æ–‡çŒ®                             | å¤‡æ³¨       |\n| :--------: | :------: | :-------: | :----: | :----: | :-----------: | :------: | :---------------: | :--: | :--------------: | ----- |\n| XVERSE-MoE | 255B/A36B | 2024-09 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/xverse/XVERSE-MoE-A36B) | [XVERSE-MoE-A36B](https://github.com/xverse-ai/XVERSE-MoE-A36B) | [xverse-ai](https://github.com/xverse-ai) | MoE  |      |\n| Qwen-2.5 | 0.5/1.5/3/7/14/32/72B | 2024-09 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/collections/Qwen/qwen25-66e81a666513e518adb90d9e) | [Qwen2.5](https://github.com/QwenLM/Qwen2.5) | [QwenLM](https://github.com/QwenLM) |  CD  | [Blog](https://qwenlm.github.io/blog/qwen2.5/) |      |\n| Tele-FLM | 52B/102B/1TB | 2024-07 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/CofeAI) |    /     | [CofeAI](https://huggingface.co/CofeAI) |  CD  | [Tele-FLM Technical Report](https://arxiv.org/pdf/2404.16645) |      \n| meta-llama-3.1 | 8/70/405B | 2024-07 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/meta-llama) | [llama3](https://github.com/meta-llama/llama3) | [meta-llama](https://github.com/meta-llama) |  CD  |      |      |\n| internlm2.5-Base |  7B  | 2024-07 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/internlm) | [InternLM](https://github.com/InternLM/InternLM)[![Star](https://camo.githubusercontent.com/f330929a514fa88e296d3f4aa78863614ccc13d6d1903e4d7b23fd85b69cddba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f496e7465726e4c4d2f496e7465726e4c4d2e7376673f7374796c653d736f6369616c266c6162656c3d53746172)](https://camo.githubusercontent.com/f330929a514fa88e296d3f4aa78863614ccc13d6d1903e4d7b23fd85b69cddba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f496e7465726e4c4d2f496e7465726e4c4d2e7376673f7374796c653d736f6369616c266c6162656c3d53746172) | [InternLM](https://github.com/InternLM) |  CD  | [ğŸ“œTechnical Report](https://arxiv.org/abs/2403.17297) |      |\n| MAP-NEO-Base | 2/7B | 2024-06 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/collections/m-a-p/neo-models-66395a5c9662bb58d5d70f04) | [MAP-NEO](https://github.com/multimodal-art-projection/MAP-NEO) | [multimodal-art-projection](https://github.com/multimodal-art-projection) |  CD  | [Paper](https://arxiv.org/abs/2405.19327) |      |\n| Nemotron-4-Base | 340B | 2024-06 | å¤šè¯­ | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/nvidia) |    /     | [NVIDIA](https://github.com/NVIDIA) |  CD  | [technical report](https://research.nvidia.com/publication/2024-06_nemotron-4-340b). |      |\n| Index-Base | 1.9B | 2024-06 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/IndexTeam/Index-1.9B-Chat) | [Index-1.9B](https://github.com/bilibili/Index-1.9B) | [bilibili](https://github.com/bilibili) |  CD  | [Report](https://github.com/bilibili/Index-1.9B/blob/main/Index-1.9B%20%E6%8A%80%E6%9C%AF%E6%8A%A5%E5%91%8A.pdf) |      |\n| Qwen2-Base | 0.5/2/5/7/72B | 2024-06 | å¤šè¯­ | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/Qwen) | [Qwen2](https://github.com/QwenLM/Qwen2) | [QwenLM](https://github.com/QwenLM) |  CD  | [Blog](https://qwenlm.github.io/) |      |\n| GLM-4-Base |  9B  | 2024-06 | å¤šè¯­ | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/THUDM) | [GLM-4](https://github.com/THUDM/GLM-4) | [THUDM](https://github.com/THUDM) |  /   |      |      |\n| Yi-1.5-Base | 6/9/34B | 2024-05 | ä¸­è‹±  | é€šç”¨  | [ğŸ¤—HF](https://huggingface.co/01-ai) | [Yi-1.5](https://github.com/01-ai/Yi-1.5) | [01-ai](https://github.com/01-ai) | CD  | [Paper](https://arxiv.org/abs/2403.04652) |     |\n| DeepSeek-V2-Base | A21B/236B | 2024-05 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/deepseek-ai/DeepSeek-V2) | [DeepSeek-V2](https://github.com/deepseek-ai/DeepSeek-V2) | [deepseek-ai](https://github.com/deepseek-ai) | MOE  | [Paper](https://github.com/deepseek-ai/DeepSeek-V2/blob/main/deepseek-v2-tech-report.pdf) |      |\n| Llama-3-Base | 8/70B | 2024-04 | å¤šè¯­ | é€šç”¨ | [ğŸ¤—HF](https://hf-mirror.com/meta-llama) | **[llama3](https://github.com/meta-llama/llama3)** | [Meta Llama](https://github.com/meta-llama) |  CD  |      |      |\n| Zhinao-Base |  7B  | 2024-04 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/qihoo360) [ ğŸ¤–](https://www.modelscope.cn/models/qihoo360/360Zhinao-7B-Base/summary) |    /     | [å¥‡è™ç§‘æŠ€](https://huggingface.co/qihoo360) |  CD  |      |      |\n| XVERSE-MoE | A4.2B/25.8B | 2024-04 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/xverse) | [XVERSE-MoE-A4.2B](https://github.com/xverse-ai/XVERSE-MoE-A4.2B) | [xverse-ai](https://github.com/xverse-ai) |  MoE  |  |\n| SoftTiger-Base | 13/70B | 2024-04 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/TigerResearch) |   [TigerBot](https://github.com/TigerResearch/TigerBot)   | [TigerResearch](https://github.com/TigerResearch) |  CD  |      |      |\n|   HammerLLM    |  1.4b  | 2024-04 | ä¸­è‹± | é€šç”¨ |  [ğŸ¤—HF](https://huggingface.co/DataHammer)   | [HammerLLM](https://github.com/Academic-Hammer/HammerLLM) | [DataHammer](https://github.com/Academic-Hammer)  |      |      |      |\n| Mengzi3-Base | 13B  | 2024-04 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/Langboat) | [Mengzi3](https://github.com/Langboat/Mengzi3) ![Star](https://img.shields.io/github/stars/Langboat/Mengzi3.svg?style=social&label=Star) | [Langboat](https://github.com/Langboat) |  CD  |      |      |\n| Breeze-Base |  7B  | 2024-02 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/MediaTek-Research) |    /     | [MediaTek Research](https://huggingface.co/MediaTek-Research) |      |      |      |\n|       TowerBase       |       7/13B       | 2024-02 | å¤šè¯­ | é€šç”¨ |           [[ğŸ¤—HF\\]](https://hf-mirror.com/Unbabel)            |                              /                               |           [Unbabel](https://hf-mirror.com/Unbabel)           |  CD  |                                                              |            |\n|     Qwen1.5-Base      | 0.5/1.8/4<br>7/14/32/72/110B | 2024-02 | ä¸­è‹± | é€šç”¨ |            [[ğŸ¤—HF\\]](https://huggingface.co/Qwen)             | [Qwen1.5](https://github.com/QwenLM/Qwen1.5)![Star](https://img.shields.io/github/stars/QwenLM/Qwen1.5.svg?style=social&label=Star) |              [Qwen](https://github.com/QwenLM)               |  /   |      [Blog](https://qwenlm.github.io/zh/blog/qwen1.5/)       |            |\n|  LongAlign-Base   |      6/7/13B      | 2024-02 | ä¸­è‹± | é€šç”¨ |            [[ğŸ¤—HF\\]](https://hf-mirror.com/THUDM)             | [LongAlign](https://github.com/THUDM/LongAlign)![Star](https://img.shields.io/github/stars/THUDM/LongAlign.svg?style=social&label=Star) |              [THUDM](https://github.com/THUDM)               |  /   |          [Paper](https://arxiv.org/abs/2401.18058)           |            |\n| Chinese-Mixtral-Base  |       8x7B        | 2024-02 | ä¸­è‹± | é€šç”¨ | [[Baidu\\]](https://pan.baidu.com/s/1nwJ8JkMTUrCkDEccg7C9Pw?pwd=33kb) [[ğŸ¤—HF\\]](https://huggingface.co/hfl/chinese-mixtral) | [Chinese-Mixtral](https://github.com/ymcui/Chinese-Mixtral)![Star](https://img.shields.io/github/stars/ymcui/Chinese-Mixtral.svg?style=social&label=Star) |            [Yiming Cui](https://github.com/ymcui)            | MOE  |                                                              |            |\n|   iFlytekSpark-Base   |        13B        | 2024-01 | ä¸­è‹± | é€šç”¨ | [mindspore](https://xihe.mindspore.cn/modelzoo/iflytek/introduce) |                              /                               |                         [ç§‘å¤§è®¯é£]()                         |  CD  |                                                              |            |\n|      Orion-Base       |        14B        | 2024-01 | å¤šè¯­ | é€šç”¨ |     [[ğŸ¤—HF\\]](https://huggingface.co/OrionStarAI) | [Orion](https://github.com/OrionStarAI/Orion)![Star](https://img.shields.io/github/stars/OrionStarAI/Orion.svg?style=social&label=Star) |        [OrionStarAI](https://github.com/OrionStarAI)         |  CD  | [Paper](https://github.com/OrionStarAI/Orion/blob/master/doc/Orion14B_v3.pdf) | RAG<br>Plugin |\n|      YaYi2-Base       |        30B        | 2023-12 | å¤šè¯­ | é€šç”¨ |     [[ğŸ¤—HF\\]](https://huggingface.co/wenge-research)     | [YAYI2](https://github.com/wenge-research/YAYI2)![Star](https://img.shields.io/github/stars/wenge-research/YAYI2.svg?style=social&label=Star) |     [wenge-research](https://github.com/wenge-research)      |  CD  |          [Paper](https://arxiv.org/abs/2312.14862)           |            |\n|     Aquila2-Base      |     7/34/70B      | 2023-12 | ä¸­è‹± | é€šç”¨ |          [[ğŸ¤—HF\\]](https://huggingface.co/BAAI)          | [Aquila2](https://github.com/FlagAI-Open/Aquila2) ![Star](https://img.shields.io/github/stars/FlagAI-Open/Aquila2.svg?style=social&label=Star) |           [FlagAI](https://github.com/FlagAI-Open)           |  CD  |                                                              |            |\n|      Alaya-Base       |        7B         | 2023-12 | ä¸­è‹± | é€šç”¨ |       [[ğŸ¤—HF\\]](https://huggingface.co/DataCanvas)       | [Alaya](https://github.com/DataCanvasIO/Alaya)![Star](https://img.shields.io/github/stars/DataCanvasIO/Alaya.svg?style=social&label=Star) |        [DataCanvas](https://github.com/DataCanvasIO)         |  CD  |                                                              |            |\n|       Qwen-Base       | 1.8/7<br/>14/72B | 2023-12 | ä¸­è‹± | é€šç”¨ |          [[ğŸ¤—HF\\]](https://huggingface.co/Qwen)          | [Qwen](https://github.com/QwenLM/Qwen) ![Star](https://img.shields.io/github/stars/QwenLM/Qwen.svg?style=social&label=Star) |             [é˜¿é‡Œäº‘](https://github.com/QwenLM)              |  CD  | [Paper](https://arxiv.org/abs/2309.16609) [Report](https://github.com/QwenLM/Qwen-7B/blob/main/tech_memo.md) [Report2](https://qianwen-res.oss-cn-beijing.aliyuncs.com/QWEN_TECHNICAL_REPORT.pdf) |            |\n|     DeepSeek-Base     |       7/67B       | 2023-11 | ä¸­è‹± | é€šç”¨ |            [[ğŸ¤—HF\\]](https://huggingface.co/deepseek-ai) | [DeepSeek-LLM](https://github.com/deepseek-ai/DeepSeek-LLM)![Star](https://img.shields.io/github/stars/deepseek-ai/DeepSeek-LLM.svg?style=social&label=Star) |        [deepseek-ai](https://github.com/deepseek-ai)         |  CD  |                                                              |            |\n|       Yuan-2.0        |     2/51<br/>102B     | 2023-11 | ä¸­è‹± | é€šç”¨ | [baidu](https://github.com/IEIT-Yuan/Yuan-2.0) [[ğŸ¤—HF\\]](https://hf-mirror.com/IEITYuan) | [Yuan-2.0](https://github.com/IEIT-Yuan/Yuan-2.0)![Star](https://img.shields.io/github/stars/IEIT-Yuan/Yuan-2.0.svg?style=social&label=Star) |          [IEIT-Yuan](https://github.com/IEIT-Yuan)           |  CD  |                                                              |            |\n|      Alaya-Base       |        7B         | 2023-11 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/DataCanvas/Alaya-7B-Base) | [Alaya](https://github.com/DataCanvasIO/Alaya)![Star](https://img.shields.io/github/stars/DataCanvasIO/Alaya.svg?style=social&label=Star) |       [DataCanvasIO](https://github.com/DataCanvasIO)        |  CD  |                                                              |            |\n|        Yi-Base        |       6/9/34B       | 2023-11 | ä¸­è‹± | é€šç”¨ |         [[ğŸ¤—HF\\]](https://huggingface.co/01-ai)          | [Yi](https://github.com/01-ai/Yi)![Star](https://img.shields.io/github/stars/01-ai/Yi.svg?style=social&label=Star) |              [01.AI](https://github.com/01-ai)               |  CD  |                                                              |            |\n|      XVERSE-Base      |     7/13<br/>65B | 2023-11 | å¤šè¯­ | é€šç”¨ |         [[ğŸ¤—HF\\]](https://huggingface.co/xverse)         | [XVERSE](https://github.com/xverse-ai/XVERSE-13B)![Star](https://img.shields.io/github/stars/xverse-ai/XVERSE-13B.svg?style=social&label=Star) |           [å…ƒè±¡ç§‘æŠ€](https://github.com/xverse-ai)           |  CD  |                                                              |            |\n|     Nanbeige-Base     |        16B        | 2023-11 | ä¸­è‹± | é€šç”¨ |        [[ğŸ¤—HF\\]](https://huggingface.co/Nanbeige)        | [Nanbeige](https://github.com/Nanbeige/Nanbeige)![Star](https://img.shields.io/github/stars/Nanbeige/Nanbeige.svg?style=social&label=Star) |       [Nanbeige LLM Lab](https://github.com/Nanbeige)        |  CD  |                                                              |            |\n|      LingoWhale       |        8B         | 2023-11 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/deeplang-ai/LingoWhale-8B) | [LingoWhale-8B](https://github.com/DeepLangAI/LingoWhale-8B/)![Star](https://img.shields.io/github/stars/DeepLangAI/LingoWhale-8B.svg?style=social&label=Star) |         [DeepLang AI](https://github.com/DeepLangAI)         |  CD  |                                                              |            |\n|     Skywork-base      |        13B        | 2023-10 | ä¸­æ–‡ | é€šç”¨ |            [[ğŸ¤—HF\\]](https://huggingface.co/Skywork)            | [Skywork](https://github.com/SkyworkAI/Skywork) ![Star](https://img.shields.io/github/stars/SkyworkAI/Skywork.svg?style=social&label=Star) |          [SkyworkAI](https://github.com/SkyworkAI)           |  CD  |          [Paper](https://arxiv.org/abs/2310.16713)           |            |\n|      BlueLM-Base      |        7B         | 2023-11 | ä¸­è‹± | é€šç”¨ |            [[ğŸ¤—HF\\]](https://huggingface.co/vivo-ai)            | [BlueLM](https://github.com/vivo-ai-lab/BlueLM)![Star](https://img.shields.io/github/stars/vivo-ai-lab/BlueLM.svg?style=social&label=Star) |        [vivo AI Lab](https://github.com/vivo-ai-lab)         |  CD  |                                                              |            |\n|     Chatglm3-base     |        6B         | 2023-10 | ä¸­è‹± | é€šç”¨ |             [[ğŸ¤—HF\\]](https://huggingface.co/THUDM)             | [ChatGLM3](https://github.com/THUDM/ChatGLM3)![Star](https://img.shields.io/github/stars/THUDM/ChatGLM3.svg?style=social&label=Star) |              [THUDM](https://github.com/THUDM)               |  ND  |                                                              |            |\n|      Ziya2-Base       |        13B        | 2023-10 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://modelscope.cn/models/Fengshenbang/Ziya2-13B-Base/summary) | [Fengshenbang-LM](https://github.com/IDEA-CCNL/Fengshenbang-LM) ![Star](https://img.shields.io/github/stars/IDEA-CCNL/Fengshenbang-LM.svg?style=social&label=Star) |          [IDEAç ”ç©¶é™¢](https://github.com/IDEA-CCNL)          |  CD  |                                                              |            |\n|       OpenBA-LM       |        15B        | 2023-09 | ä¸­è‹± | é€šç”¨ |       [[ğŸ¤—HF\\]](https://huggingface.co/OpenBA/OpenBA-LM)     | [OpenBA](https://github.com/OpenNLG/OpenBA)![Star](https://img.shields.io/github/stars/OpenNLG/OpenBA.svg?style=social&label=Star) |         [OpenNLG Group](https://github.com/OpenNLG)          |  ED  |          [Paper](https://arxiv.org/abs/2309.10706)           |            |\n|   TigerBot-Base-70B   |        80B        | 2023-09 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/TigerResearch/tigerbot-70b-base) | [TigerBot](https://github.com/TigerResearch/TigerBot)![Star](https://img.shields.io/github/stars/TigerResearch/TigerBot.svg?style=social&label=Star) |         [è™åšç§‘æŠ€](https://github.com/TigerResearch)         |  CD  | [Paper](https://github.com/TigerResearch/TigerBot/wiki/TigerBot%E2%80%9070B%E5%8F%91%E5%B8%83%EF%BC%81) |            |\n|          FLM          |       101B        | 2023-09 | ä¸­è‹± | é€šç”¨ |        [[ğŸ¤—HF\\]](https://huggingface.co/CofeAI/FLM-101B)        |                              /                               |           [CofeAI](https://huggingface.co/CofeAI)            |  CD  |                                                              |            |\n|        falcon         |     7/40<br/>180B     | 2023-09 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/tiiuae/) |                              /                               | [Technology Innovation Institute](https://github.com/tiiuae) |  CD  |                                                              |            |\n|       Baichuan2       |       7/13B       | 2023-09 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/baichuan-inc) | [Baichuan2](https://github.com/baichuan-inc/Baichuan2)![Star](https://img.shields.io/github/stars/baichuan-inc/Baichuan2.svg?style=social&label=Star) |         [ç™¾å·æ™ºèƒ½](https://github.com/baichuan-inc)          |  CD  |                                                              |            |\n|  Chinese-LLaMA-2-16K  |       7/13B       | 2023-08 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/ziqingyang/chinese-llama-2-7b-16k) | [Chinese-LLaMA-Alpaca-2](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2)  ![Star](https://img.shields.io/github/stars/ymcui/Chinese-LLaMA-Alpaca-2.svg?style=social&label=Star) |            [Yiming Cui](https://github.com/ymcui)            |  CD  |                                                              |            |\n|     YuLan-LLaMA-2     |        13B        | 2023-08 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/yulan-team/YuLan-LLaMA-2-13b) | [YuLan-Chat](https://github.com/RUC-GSAI/YuLan-Chat) ![Star](https://img.shields.io/github/stars/RUC-GSAI/YuLan-Chat.svg?style=social&label=Star) |         [ä¸­å›½äººæ°‘å¤§å­¦](https://github.com/RUC-GSAI)          |  CD  |                                                              |            |\n|    Aquila-Base-33B    |        33B        | 2023-08 | ä¸­è‹± | é€šç”¨ |                           [TODO]()                           | [Aquila](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/Aquila)![Star](https://img.shields.io/github/stars/FlagAI-Open/FlagAI.svg?style=social&label=Star) |           [FlagAI](https://github.com/FlagAI-Open)           |  CD  |                                                              |            |\n|   TigerBot-Base-13B   |        13B        | 2023-08 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/TigerResearch/tigerbot-13b-base) | [TigerBot](https://github.com/TigerResearch/TigerBot)![Star](https://img.shields.io/github/stars/TigerResearch/TigerBot.svg?style=social&label=Star) |         [è™åšç§‘æŠ€](https://github.com/TigerResearch)         |  CD  |                                                              |            |\n| Linly-Chinese-LLaMA-2 |       7/13B       | 2023-07 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/Linly-AI/Chinese-LLaMA-2-7B-hf) | [Linly](https://github.com/CVI-SZU/Linly) ![Star](https://img.shields.io/github/stars/CVI-SZU/Linly.svg?style=social&label=Star) |    [æ·±åœ³å¤§å­¦è®¡ç®—æœºè§†è§‰ç ”ç©¶æ‰€](https://github.com/CVI-SZU)    |  CD  |                                                              |            |\n|    Chinese-LLaMA-2    |        7B         | 2023-07 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/ziqingyang/chinese-llama-2-7b) | [Chinese-LLaMA-Alpaca-2](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2)![Star](https://img.shields.io/github/stars/ymcui/Chinese-LLaMA-Alpaca-2.svg?style=social&label=Star) |            [Yiming Cui](https://github.com/ymcui)            |  CD  |                                                              |            |\n|      Jiang-base       |        13B        | 2023-07 | ä¸­æ–‡ | é€šç”¨ |        [[ğŸ¤—HF\\]](https://huggingface.co/kdf/jiang-base)      |                              /                               |            [çŸ¥æœªæ™ºèƒ½](https://huggingface.co/kdf)            |  CD  |                                                              |            |\n|          bwx          |       7/13B       | 2023-07 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/BlueWhaleX/bwx-7B-hf) |                              /                               |        [è“é²¸å›½æ•°](https://huggingface.co/BlueWhaleX)         |  CD  |                                                              |            |\n|        Llama2         |     7/13<br/>70B | 2023-07 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/llamaste/Llama-2-7b) | [llama](https://github.com/facebookresearch/llama)![Star](https://img.shields.io/github/stars/facebookresearch/llama.svg?style=social&label=Star) |         [Meta](https://github.com/facebookresearch)          |  CD  | [Paper](https://scontent-hkg4-1.xx.fbcdn.net/v/t39.2365-6/10000000_663429262362723_1696968207443577320_n.pdf?_nc_cat=101&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=5ol-jUSglG4AX-br54S&_nc_ht=scontent-hkg4-1.xx&oh=00_AfDzh9f2kFTRk-FIieoySi12fhBjvJP4Bv-ZJTxRtdoXJg&oe=64BBB691) |            |\n|        PolyLM         |        13B        | 2023-07 | å¤šè¯­ | é€šç”¨ |    [[ğŸ¤—HF\\]](https://huggingface.co/DAMO-NLP-MT/polylm-13b)  | [PolyLM](https://modelscope.cn/models/damo/nlp_polylm_13b_text_generation/summary) |         [è¾¾æ‘©é™¢](https://huggingface.co/DAMO-NLP-MT)         |  CD  |        [Paper](https://arxiv.org/pdf/2307.06018.pdf)         |            |\n|     Baichuan-13B      |        13B        | 2023-07 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/baichuan-inc/Baichuan-13B-Base) | [Baichuan-13B](https://github.com/baichuan-inc/Baichuan-13B)![Star](https://img.shields.io/github/stars/baichuan-inc/Baichuan-13B.svg?style=social&label=Star) |         [ç™¾å·æ™ºèƒ½](https://github.com/baichuan-inc)          |  CD  |                                                              |            |\n|       TigerBot        |        7B         | 2023-07 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/TigerResearch/tigerbot-7b-base-v2) | [TigerBot](https://github.com/TigerResearch/TigerBot)![Star](https://img.shields.io/github/stars/TigerResearch/TigerBot.svg?style=social&label=Star) |         [è™åšç§‘æŠ€](https://github.com/TigerResearch)         |  CD  |                                                              |            |\n|     InternLM-base     |       7/20B       | 2023-07 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/internlm/internlm-7b) | [InternLM](https://github.com/InternLM/InternLM)![Star](https://img.shields.io/github/stars/InternLM/InternLM.svg?style=social&label=Star) |      [ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤](https://github.com/InternLM)       |  CD  | [report](https://github.com/InternLM/InternLM-techreport/tree/main) |            |\n|          MPT          |       7/30B       | 2023-06 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/mosaicml/mpt-7b) | [llm-foundry](https://github.com/mosaicml/llm-foundry)![Star](https://img.shields.io/github/stars/mosaicml/llm-foundry.svg?style=social&label=Star) |           [MosaicML](https://github.com/mosaicml)            |  CD  |                                                              |            |\n|       Baichuan        |        7B         | 2023-06 | ä¸­è‹± | é€šç”¨ |   [[ğŸ¤—HF\\]](https://huggingface.co/baichuan-inc/baichuan-7B) | [baichuan-7B](https://github.com/baichuan-inc/baichuan-7B)![Star](https://img.shields.io/github/stars/baichuan-inc/baichuan-7B.svg?style=social&label=Star) |         [ç™¾å·æ™ºèƒ½](https://github.com/baichuan-inc)          |  CD  |                                                              |            |\n|    Chinese-Falcon     |        7B         | 2023-06 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/Linly-AI/Chinese-Falcon-7B) | [Linly](https://github.com/CVI-SZU/Linly)![Star](https://img.shields.io/github/stars/CVI-SZU/Linly.svg?style=social&label=Star) |    [æ·±åœ³å¤§å­¦è®¡ç®—æœºè§†è§‰ç ”ç©¶æ‰€](https://github.com/CVI-SZU)    |  CD  |        [Blog](https://zhuanlan.zhihu.com/p/636994073)        |            |\n|        AtomGPT        |        13B        | 2023-06 | ä¸­è‹± | é€šç”¨ |   [[ğŸ¤—HF\\]](https://huggingface.co/AtomEchoAI/AtomGPT-index) | / |           [åŸå­å›å£°](https://github.com/AtomEcho)            |  CD  |                                                              |            |\n|        Aquila         |        7B         | 2023-06 | ä¸­è‹± | é€šç”¨ |     [[ğŸ¤—HF\\]](https://model.baai.ac.cn/model-detail/100098)     | [Aquila](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/Aquila)![Star](https://img.shields.io/github/stars/FlagAI-Open/FlagAI.svg?style=social&label=Star) |           [FlagAI](https://github.com/FlagAI-Open)           |  CD  |                                                              |            |\n|     Chinese-LLaMA     |        33B        | 2023-06 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/ziqingyang/chinese-llama-lora-33b) | [Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca)![Star](https://img.shields.io/github/stars/ymcui/Chinese-LLaMA-Alpaca.svg?style=social&label=Star) |            [Yiming Cui](https://github.com/ymcui)            |  CD  |                                                              |            |\n|       TigerBot        |        7B         | 2023-06 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/TigerResearch/tigerbot-7b-base) | [TigerBot](https://github.com/TigerResearch/TigerBot)![Star](https://img.shields.io/github/stars/TigerResearch/TigerBot.svg?style=social&label=Star) |         [è™åšç§‘æŠ€](https://github.com/TigerResearch)         |  CD  |                                                              |            |\n|    Panda-OpenLLaMA    |        7B         | 2023-05 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/chitanda/panda-7b-open-llama-preview-300pt) | [pandallm](https://github.com/dandelionsllm/pandallm)![Star](https://img.shields.io/github/stars/dandelionsllm/pandallm.svg?style=social&label=Star) |      [dandelionsllm](https://github.com/dandelionsllm)       |  CD  |                                                              |            |\n|         Panda         |       7/13B       | 2023-05 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/chitanda/llama-panda-zh-13b-delta) | [pandallm](https://github.com/dandelionsllm/pandallm)![Star](https://img.shields.io/github/stars/dandelionsllm/pandallm.svg?style=social&label=Star) |      [dandelionsllm](https://github.com/dandelionsllm)       |  CD  |                                                              |            |\n|       OpenLLaMA       |        13B        | 2023-05 | ä¸­è‹± | é€šç”¨ |    [[ğŸ¤—HF\\]](https://huggingface.co/Linly-AI/OpenLLaMA-13B)  | [Linly](https://github.com/CVI-SZU/Linly)![Star](https://img.shields.io/github/stars/CVI-SZU/Linly.svg?style=social&label=Star) |    [æ·±åœ³å¤§å­¦è®¡ç®—æœºè§†è§‰ç ”ç©¶æ‰€](https://github.com/CVI-SZU)    |  CD  |                                                              |            |\n|       BiLLa-LLM       |        7B         | 2023-05 | ä¸­è‹± | é€šç”¨ |    [[ğŸ¤—HF\\]](https://huggingface.co/Neutralzz/BiLLa-7B-LLM)  | [BiLLa](https://github.com/Neutralzz/BiLLa)![Star](https://img.shields.io/github/stars/Neutralzz/BiLLa.svg?style=social&label=Star) |          [Zhongli Li](https://github.com/Neutralzz)          |  CD  |                                                              |            |\n|   Ziya-LLaMA-Reward   |        7B         | 2023-05 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-7B-Reward) | [Fengshenbang-LM](https://github.com/IDEA-CCNL/Fengshenbang-LM)![Star](https://img.shields.io/github/stars/IDEA-CCNL/Fengshenbang-LM.svg?style=social&label=Star) |          [IDEAç ”ç©¶é™¢](https://github.com/IDEA-CCNL)          |  CD  |                                                              |            |\n|         YuYan         |        11B        | 2023-04 | ä¸­æ–‡ | é€šç”¨ |        [[ğŸ¤—HF\\]](https://huggingface.co/FUXI/yuyan-11b)      |                              /                               |           [ç½‘æ˜“ä¼ç¾²](https://huggingface.co/FUXI)            |  CD  |   [Paper](https://aclanthology.org/2022.naacl-industry.8/)   |            |\n|     Chinese-LLaMA     |        7/13/33B        | 2023-04 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/P01son/Linly-Chinese-LLaMA-33b-hf) | [Linly](https://github.com/CVI-SZU/Linly)![Star](https://img.shields.io/github/stars/CVI-SZU/Linly.svg?style=social&label=Star) |    [æ·±åœ³å¤§å­¦è®¡ç®—æœºè§†è§‰ç ”ç©¶æ‰€](https://github.com/CVI-SZU)    |  CD  |        [Blog](https://zhuanlan.zhihu.com/p/616748134)        |            |\n|   OpenChineseLLaMA    |        7B         | 2023-04 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/openlmlab/open-chinese-llama-7b-patch) | [OpenChineseLLaMA](https://github.com/OpenLMLab/OpenChineseLLaMA)![Star](https://img.shields.io/github/stars/OpenLMLab/OpenChineseLLaMA.svg?style=social&label=Star) |          [OpenLMLab](https://github.com/OpenLMLab)           |  CD  |                                                              |            |\n|       MOSS-003        |        16B        | 2023-04 | ä¸­è‹± | é€šç”¨ |    [[ğŸ¤—HF\\]](https://huggingface.co/fnlp/moss-moon-003-base)    | [MOSS](https://github.com/OpenLMLab/MOSS)![Star](https://img.shields.io/github/stars/OpenLMLab/MOSS.svg?style=social&label=Star) |           [å¤æ—¦å¤§å­¦](https://github.com/OpenLMLab)           |  CD  |                                                              |            |\n|      BBT-2-Text       |        13B        | 2023-04 | ä¸­æ–‡ | é€šç”¨ |       [ç”³è¯·](https://bbt.ssymmetry.com/model.html)       | [BBT-FinCUGE-Applications](https://github.com/ssymmetry/BBT-FinCUGE-Applications)![Star](https://img.shields.io/github/stars/ssymmetry/BBT-FinCUGE-Applications.svg?style=social&label=Star) |        [è¶…å¯¹ç§°](https://bbt.ssymmetry.com/model.html)        |  CD  |        [Paper](https://bbt.ssymmetry.com/thesis.html)        |            |\n|    BBT-2-Text     |        12B        | 2023-04 | ä¸­æ–‡ | é€šç”¨ |       [ç”³è¯·](https://bbt.ssymmetry.com/model.html)       | [BBT-FinCUGE-Applications](https://github.com/ssymmetry/BBT-FinCUGE-Applications)![Star](https://img.shields.io/github/stars/ssymmetry/BBT-FinCUGE-Applications.svg?style=social&label=Star) |        [è¶…å¯¹ç§°](https://bbt.ssymmetry.com/model.html)        |  CD  |        [Paper](https://bbt.ssymmetry.com/thesis.html)        |            |\n|     Chinese-LLaMA     |        13B        | 2023-04 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/ziqingyang/chinese-llama-lora-13b) | [Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca)![Star](https://img.shields.io/github/stars/ymcui/Chinese-LLaMA-Alpaca.svg?style=social&label=Star) |            [Yiming Cui](https://github.com/ymcui)            |  CD  |                                                              |            |\n|       flan-ul2        |        20B        | 2023-03 | å¤šè¯­ | é€šç”¨ |   [[ğŸ¤—HF\\]](https://huggingface.co/google/flan-ul2/tree/main)   | [ul2](https://github.com/google-research/google-research/tree/master/ul2) |            [Google](https://ai.google/research/)             |  ED  |       [Paper](https://arxiv.org/pdf/2205.05131v3.pdf)        |            |\n|        CPM-Bee        |        10B        | 2023-01 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/openbmb/cpm-bee-10b) | [CPM-Bee](https://github.com/OpenBMB/CPM-Bee)![Star](https://img.shields.io/github/stars/OpenBMB/CPM-Bee.svg?style=social&label=Star) |             [OpenBMB](https://live.openbmb.org/)             |  CD  |                                                              |            |\n|         BLOOM         |       176B        | 2022-11 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/bigscience/bloom) | [Megatron-DeepSpeed](https://github.com/bigscience-workshop/Megatron-DeepSpeed) ![Star](https://img.shields.io/github/stars/bigscience-workshop/Megatron-DeepSpeed.svg?style=social&label=Star) |     [BigScience](https://github.com/bigscience-workshop)     |  CD  |        [Paper](https://arxiv.org/pdf/2211.05100.pdf)         |            |\n|       *BLOOMZ*        |       176B        | 2022-11 | å¤šè¯­ | é€šç”¨ |     [[ğŸ¤—HF\\]](https://huggingface.co/bigscience/bloomz)     | [Megatron-DeepSpeed](https://github.com/bigscience-workshop/Megatron-DeepSpeed) ![Star](https://img.shields.io/github/stars/bigscience-workshop/Megatron-DeepSpeed.svg?style=social&label=Star) |     [BigScience](https://github.com/bigscience-workshop)     |  CD  |            [Paper](https://arxiv.org/abs/2211.01)            |            |\n|      flan-t5-xxl      |        11B        | 2022-11 | å¤šè¯­ | é€šç”¨ |      [[ğŸ¤—HF\\]](https://huggingface.co/google/flan-t5-xxl)    |        [t5x](https://github.com/google-research/t5x) ![Star](https://img.shields.io/github/stars/google-research/t5x.svg?style=social&label=Star)        |            [Google](https://ai.google/research/)             |  ED  |        [paper](https://arxiv.org/pdf/2210.11416.pdf)         |            |\n|       CPM-Ant+        |        10B        | 2022-10 | ä¸­è‹± | é€šç”¨ | [BMB](http://openbmb.oss-cn-hongkong.aliyuncs.com/model_center/cpm-ant-plus-10b/cpm-ant-plus-10b.zip) |       [CPM-Live](https://github.com/OpenBMB/CPM-Live) ![Star](https://img.shields.io/github/stars/OpenBMB/CPM-Live.svg?style=social&label=Star)       |             [OpenBMB](https://live.openbmb.org/)             |  CD  | [blog](https://www.openbmb.org/community/blogs/blogpage?id=98afef2ce45f4fe9a4bc15a66d7ccb92) |            |\n|          GLM          |       130B        | 2022-10 | ä¸­è‹± | é€šç”¨ | [ç”³è¯·](https://docs.google.com/forms/d/e/1FAIpQLSehr5Dh_i3TwACmFFi8QEgIVNYGmSPwV0GueIcsUev0NEfUug/viewform) | [GLM-130B](https://github.com/THUDM/GLM-130B)![Star](https://img.shields.io/github/stars/THUDM/GLM-130B.svg?style=social&label=Star) |             [æ¸…åå¤§å­¦](https://github.com/THUDM)             |  ND  |           [paper](http://arxiv.org/abs/2210.02414)           |            |\n|        CPM-Ant        |        10B        | 2022-09 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://openbmb.oss-cn-hongkong.aliyuncs.com/model_center/cpmlive-10b/cpm_live_10B.zip) |       [CPM-Live](https://github.com/OpenBMB/CPM-Live) ![Star](https://img.shields.io/github/stars/OpenBMB/CPM-Live.svg?style=social&label=Star)       |             [OpenBMB](https://live.openbmb.org/)             |  CD  | [blog](https://www.openbmb.org/community/blogs/blogpage?id=98afef2ce45f4fe9a4bc15a66d7ccb92) |            |\n|          GLM          |        10B        | 2022-09 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://lfs.aminer.cn/misc/cogview/glm-10b-chinese.zip) |             [GLM](https://github.com/THUDM/GLM) ![Star](https://img.shields.io/github/stars/THUDM/GLM.svg?style=social&label=Star)             |             [æ¸…åå¤§å­¦](https://github.com/THUDM)             |  ND  |          [paper](https://arxiv.org/abs/2103.10360)           |            |\n|         æº1.0         |       245B        | 2021-09 | ä¸­æ–‡ | é€šç”¨ |            [API](https://air.inspur.com/home)            |     [Yian-1.0](https://github.com/Shawn-Inspur/Yuan-1.0) ![Star](https://img.shields.io/github/stars/Shawn-Inspur/Yuan-1.0.svg?style=social&label=Star)     |             [æµªæ½®](https://air.inspur.com/home)              |  CD  |          [paper](https://arxiv.org/abs/2110.04725)           |            |\n|         CPM-2         |  10/11/<br/>200B | 2021-06 | ä¸­æ–‡ | é€šç”¨ | [ç”³è¯·](https://resource.wudao.baai.ac.cn/home?ind=2&name=WuDao%20WenYuan&id=1394901846484627456) | [CPM](https://github.com/TsinghuaAI/CPM)![Star](https://img.shields.io/github/stars/TsinghuaAI/CPM.svg?style=social&label=Star) |            [æ™ºæºç ”ç©¶é™¢](https://www.baai.ac.cn/)             |  ED  |          [paper](https://arxiv.org/abs/2106.10715)           |            |\n|      PanGu-Alpha      |        13/200B        | 2021-05 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://openi.pcl.ac.cn/PCL-Platform.Intelligence/PanGu-Alpha) | [PanGu-Alpha](https://openi.pcl.ac.cn/PCL-Platform.Intelligence/PanGu-Alpha) | [é¹åŸå®éªŒå®¤](https://openi.pcl.ac.cn/PCL-Platform.Intelligence) |  CD  |        [paper](https://arxiv.org/pdf/2104.12369.pdf)         |            |\n|         PLUG          |        27B        | 2021-04 | ä¸­æ–‡ | é€šç”¨ |       [ç”³è¯·](https://www.alice-mind.com/portal#/)        |      [AliceMind](https://github.com/alibaba/AliceMind)       |       [é˜¿é‡Œå·´å·´](https://www.alice-mind.com/portal#/)        |  ED  |                                                              |            |\n|         GPT-3         |        13/30B        | 2021-04 | ä¸­æ–‡ | é€šç”¨ |                           [TODO]()                           | [GPT-3](https://modelscope.cn/models/damo/nlp_gpt3_text-generation_13B/summary) |      [è¾¾æ‘©é™¢](https://modelscope.cn/organization/damo)       |  CD  |                                                              |            |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n## Domain-Base-LLM\n\n> å„ä¸ªå‚ç›´é¢†åŸŸå¼€æºåŸºç¡€æ¨¡å‹\n\n|       æ¨¡å‹        | å¤§å°  | æ—¶é—´    | è¯­è¨€ | é¢†åŸŸ |                             ä¸‹è½½                             |                           é¡¹ç›®åœ°å€                           |                          æœºæ„/ä¸ªäºº                           | æ¶æ„ |                             æ–‡çŒ®                             | å¤‡æ³¨ |\n| :---------------: | :---: | ------- | :--: | ---- | :---------------------------------------: | :---------------------: | :------------------------------: | :--: | :--------------------: | ---- |\n| Qwen-2.5 |        1.5/7B         | 2024-09 | ä¸­è‹± | ä»£ç  | [ğŸ¤—HF](https://huggingface.co/collections/Qwen/qwen25-coder-66eaa22e6f99801bf65b0c2f) | [Qwen2.5](https://github.com/QwenLM/Qwen2.5) | [QwenLM](https://github.com/QwenLM) |  CD  | [Blog](https://qwenlm.github.io/blog/qwen2.5/) |      |\n| Qwen-2.5 |       1.5/7/72B       | 2024-09 | ä¸­è‹± | æ•°å­¦ | [ğŸ¤—HF](https://huggingface.co/collections/Qwen/qwen25-math-66eaa240a1b7d5ee65f1da3e) | [Qwen2.5](https://github.com/QwenLM/Qwen2.5) | [QwenLM](https://github.com/QwenLM) |  CD  | [Blog](https://qwenlm.github.io/blog/qwen2.5/) |      |\n| Tongyi-Finance-Base |  14B  | 2023-11 | ä¸­æ–‡ | é‡‘è | [ModelScope](https://modelscope.cn/models/TongyiFinance/Tongyi-Finance-14B/summary) | [é€šä¹‰é‡‘è-14B](https://modelscope.cn/models/TongyiFinance/Tongyi-Finance-14B/summary) | [é€šä¹‰é‡‘èå¤§æ¨¡å‹](https://modelscope.cn/organization/TongyiFinance) |  CD  |      |      |\n| ChiMed-GPT | 13B | 2023-10 | ä¸­æ–‡ | åŒ»ç–— | [[ğŸ¤—HF\\]](https://huggingface.co/SYNLP/ChiMed-GPT-1.0) | [ChiMed-GPT](https://github.com/synlp/ChiMed-GPT) | [ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦](https://github.com/synlp) | CD | [Paper](https://arxiv.org/abs/2311.06025) |  |\n| CodeShell-base |  7B  | 2023-10 | ä¸­è‹± | ä»£ç  | [[ğŸ¤—HF\\]](https://huggingface.co/WisdomShell/CodeShell) | [codeshell](https://github.com/WisdomShell/codeshell)![Star](https://img.shields.io/github/stars/WisdomShell/codeshell.svg?style=social&label=Star) | [WisdomShell](https://github.com/WisdomShell) |  CD  |      |      |\n| WiNGPT-base |  7B  | 2023-09 | ä¸­æ–‡ | åŒ»å­¦ | [[ğŸ¤—HF\\]](https://huggingface.co/winninghealth/WiNGPT2-7B-Base) | [WiNGPT2](https://github.com/winninghealth/WiNGPT2)![Star](https://img.shields.io/github/stars/winninghealth/WiNGPT2.svg?style=social&label=Star) | [Winning Health AI Research](https://github.com/winninghealth) |  CD  |      |      |\n| XuanYuan | 70B  | 2023-09 | ä¸­æ–‡ | é‡‘è | [[ğŸ¤—HF\\]](https://huggingface.co/Duxiaoman-DI/XuanYuan-70B) | [XuanYuan](https://github.com/Duxiaoman-DI/XuanYuan) ![Star](https://img.shields.io/github/stars/Duxiaoman-DI/XuanYuan.svg?style=social&label=Star) | [åº¦å°æ»¡](https://github.com/Duxiaoman-DI) |  CD  | [Report](https://github.com/Duxiaoman-DI/XuanYuan/blob/main/xuanyuan_70b_report.md) |      |\n| CodeLLAma | 7/13/<br/>34B | 2023-08 | å¤šè¯­ | ä»£ç  | [[ğŸ¤—HF\\]](https://huggingface.co/codellama) | [codellama](https://github.com/facebookresearch/codellama)![Star](https://img.shields.io/github/stars/facebookresearch/codellama.svg?style=social&label=Star) | [Meta Research](https://github.com/facebookresearch) |  CD  | [Paper](https://arxiv.org/abs/2308.12950) |      |\n| educhat-base-002  | 7/13B | 2023-06 | ä¸­è‹± | æ•™è‚² | [[ğŸ¤—HF\\]](https://huggingface.co/butyuhao/educhat-base-002-13b) | [EduChat](https://github.com/icalk-nlp/EduChat)![Star](https://img.shields.io/github/stars/icalk-nlp/EduChat.svg?style=social&label=Star) |         [åä¸œå¸ˆèŒƒå¤§å­¦](https://github.com/icalk-nlp)         |  CD  |                                                              |      |\n|   AquilaCode-NV   |  7B   | 2023-06 | ä¸­è‹± | ä»£ç  |     [[ğŸ¤—HF\\]](https://model.baai.ac.cn/model-detail/100099)     | [Aquila](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/Aquila)![Star](https://img.shields.io/github/stars/FlagAI-Open/FlagAI.svg?style=social&label=Star) |          [FlagAI](https://github.com/FlagAI-Open)           |  CD  |                                                              |      |\n|   AquilaCode-TS   |  7B   | 2023-06 | ä¸­è‹± | ä»£ç  |     [[ğŸ¤—HF\\]](https://model.baai.ac.cn/model-detail/100099)     | [Aquila](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/Aquila)![Star](https://img.shields.io/github/stars/FlagAI-Open/FlagAI.svg?style=social&label=Star) |          [FlagAI](https://github.com/FlagAI-Open)           |  CD  |                                                              |      |\n|      LaWGPT       |  7B   | 2023-05 | ä¸­è‹± | æ³•å¾‹ |    [[ğŸ¤—HF\\]](https://huggingface.co/entity303/legal-lora-7b)    | [LawGPT](https://github.com/pengxiao-song/LaWGPT)![Star](https://img.shields.io/github/stars/pengxiao-song/LaWGPT.svg?style=social&label=Star) |      [Pengxiao Song](https://github.com/pengxiao-song)       |  CD  |                                                              |      |\n|     CodeGeeX      |  13B  | 2022-06 | å¤šè¯­ | ä»£ç  | [ç”³è¯·](https://models.aminer.cn/codegeex/download/request) |        [CodeGeeX](https://github.com/THUDM/CodeGeeX)         |             [æ¸…åå¤§å­¦](https://github.com/THUDM)             |  CD  |       [blog](https://models.aminer.cn/codegeex/blog/)        |      |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n## ChatLLM\n\n> å…·å¤‡é—®ç­”å’Œå¯¹è¯ç­‰åŠŸèƒ½çš„å¤§å‹è¯­è¨€æ¨¡å‹ã€‚\n>\n\n|           æ¨¡å‹           |    å¤§å°     | æ—¶é—´    | è¯­è¨€ | é¢†åŸŸ |                             ä¸‹è½½                             |                           é¡¹ç›®åœ°å€                           |                          æœºæ„/ä¸ªäºº                           | æ¶æ„ |                             æ–‡çŒ®                             |\n| :----------------------: | :---------: | ------- | :--: | :--: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :--: | :----------------------------------------------------------: |\n| Megrez-3B-Instruct |  3B  | 2024-12 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/Infinigence/Megrez-3B-Instruct) | [Infini-Megrez](https://github.com/infinigence/Infini-Megrez) | [infinigence](https://github.com/infinigence) |  CD  |      |\n| Athene-V2-Chat  | 72B  | 2024-11 | ä¸­è‹± |   é€šç”¨   | [ğŸ¤—HF](https://huggingface.co/Nexusflow/Athene-V2-Chat)  |    /     | [Nexusflow](https://huggingface.co/Nexusflow) |  CD  | [Blog](https://nexusflow.ai/blogs/athene-v2) |\n| Athene-V2-Agent | 72B  | 2024-11 | ä¸­è‹± | å·¥å…·è°ƒç”¨ | [ğŸ¤—HF](https://huggingface.co/Nexusflow/Athene-V2-Agent) |    /     | [Nexusflow](https://huggingface.co/Nexusflow) |  CD  | [Blog](https://nexusflow.ai/blogs/athene-v2) |\n| Hunyuan-Large | A52/389B | 2024-11 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/tencent/Tencent-Hunyuan-Large) | [Tencent-Hunyuan-Large](https://github.com/Tencent/Tencent-Hunyuan-Large) | [Tencent](https://github.com/Tencent) | MoE  | [Paper](https://arxiv.org/abs/2411.02265) |\n| Aya-Expanse | 8/32B | 2024-10 | å¤šè¯­ | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/collections/CohereForAI/c4ai-aya-expanse-671a83d6b2c07c692beab3c3) |    /     | [Cohere For AI](https://huggingface.co/CohereForAI) |  CD  |      |\n|   Granite 3.0   |  1/2/3/8B   | 2024-10 | å¤šè¯­ | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/collections/ibm-granite/granite-30-models-66fdb59bbb54785c3512114f) | [granite-3.0-language-models](https://github.com/ibm-granite/granite-3.0-language-models) | [ibm-granite](https://github.com/ibm-granite) |  CD  | [Paper](https://github.com/ibm-granite/granite-3.0-language-models/blob/main/paper.pdf) |\n| Granite 3.0-MoE | 1B/3B/A400M | 2024-10 | å¤šè¯­ | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/collections/ibm-granite/granite-30-models-66fdb59bbb54785c3512114f) | [granite-3.0-language-models](https://github.com/ibm-granite/granite-3.0-language-models) | [ibm-granite](https://github.com/ibm-granite) | MoE  | [Paper](https://github.com/ibm-granite/granite-3.0-language-models/blob/main/paper.pdf) |\n| TeleChat2 | 115B | 2024-09 | ä¸­è‹± | é€šç”¨ | ğŸ¤– [ModelScope](https://modelscope.cn/organization/TeleAI) | [TeleChat2](https://github.com/Tele-AI/TeleChat2) | [Tele-AI](https://github.com/Tele-AI) |  CD  |      |\n| Qwen-2.5 | 0.5/1.5/3/7/14/32/72B | 2024-09 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/collections/Qwen/qwen25-66e81a666513e518adb90d9e) | [Qwen2.5](https://github.com/QwenLM/Qwen2.5) | [QwenLM](https://github.com/QwenLM) |  CD  | [Blog](https://qwenlm.github.io/blog/qwen2.5/) |\n| XVERSE-MoE | 255B/A36B | 2024-09 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/xverse/XVERSE-MoE-A36B) | [XVERSE-MoE-A36B](https://github.com/xverse-ai/XVERSE-MoE-A36B) | [xverse-ai](https://github.com/xverse-ai) | MoE  |      |\n| DeepSeek-V2.5 | 236B/A21B | 2024-09 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/deepseek-ai/DeepSeek-V2-Chat-0628) | [DeepSeek-V2](https://github.com/deepseek-ai/DeepSeek-V2) | [deepseek-ai](https://github.com/deepseek-ai) | MOE  |          [Paper](https://arxiv.org/abs/2405.04434)           |\n|   MiniCPM3    |    4B     | 2024-09 | ä¸­è‹± | é€šç”¨ |      [ğŸ¤—HF](https://huggingface.co/openbmb/MiniCPM3-4B)       |       [MiniCPM](https://github.com/OpenBMB/MiniCPM)       |     [OpenBMB](https://github.com/OpenBMB)     |  CD  |      [MiniCPM Paper](https://arxiv.org/abs/2404.06395)       |\n| C4AI Command R+ 08-2024 | 104B | 2024-08 | å¤šè¯­ | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/CohereForAI) | / | [CohereForAI](https://huggingface.co/CohereForAI) | CD | |\n| JIUTIAN-Chat | 39/A13B | 2024-07 | ä¸­è‹± | é€šç”¨ | [ğŸ¤–MS](https://modelscope.cn/models/JiuTian-AI/JIUTIAN-139MoE-chat) | / | [ä¸­å›½ç§»åŠ¨JiuTian-AI](https://modelscope.cn/organization/JiuTian-AI) | MOE  |      |\n| meta-llama-3.1 | 8/70/405B | 2024-07 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/meta-llama)| [llama3](https://github.com/meta-llama/llama3) | [meta-llama](https://github.com/meta-llama) |  CD  |      |\n| internlm2.5-chat |  7B  | 2024-07 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/internlm) | [InternLM](https://github.com/InternLM/InternLM)[![Star](https://camo.githubusercontent.com/f330929a514fa88e296d3f4aa78863614ccc13d6d1903e4d7b23fd85b69cddba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f496e7465726e4c4d2f496e7465726e4c4d2e7376673f7374796c653d736f6369616c266c6162656c3d53746172)](https://camo.githubusercontent.com/f330929a514fa88e296d3f4aa78863614ccc13d6d1903e4d7b23fd85b69cddba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f496e7465726e4c4d2f496e7465726e4c4d2e7376673f7374796c653d736f6369616c266c6162656c3d53746172) | [InternLM](https://github.com/InternLM) |  CD  | [ğŸ“œTechnical Report](https://arxiv.org/abs/2403.17297) |\n| Mistral-large-insruct-2407 | 123B  | 2024-07 | å¤šè¯­ | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/mistralai/Mistral-Large-Instruct-2407) |                             /                             |  [Mistral AI](https://huggingface.co/mistralai)   |      |   [blog post](https://mistral.ai/news/mistral-large-2407/)   |\n|   DeepSeek-V2-Chat-0628    | 236B  | 2024-07 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/deepseek-ai/DeepSeek-V2-Chat-0628) | [DeepSeek-V2](https://github.com/deepseek-ai/DeepSeek-V2) |   [deepseek-ai](https://github.com/deepseek-ai)   | MOE  | [Paper](https://github.com/deepseek-ai/DeepSeek-V2/blob/main/deepseek-v2-tech-report.pdf) |\n|    C4ai-command-r-plus     | 104B  | 2024-07 | å¤šè¯­ | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/CohereForAI/c4ai-command-r-plus) |                             /                             | [CohereForAI](https://huggingface.co/CohereForAI) |  CD  |                                                              |\n|        Gemma-2-chat        | 9/27B | 2024-06 | å¤šè¯­ | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/collections/google/gemma-2-release-667d6600fd5220e7b967f315) |                             /                             |      [Google](https://huggingface.co/google)      |  CD  |                                                              |\n| MAP-NEO-Chat | 2/7B | 2024-06 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/collections/m-a-p/neo-models-66395a5c9662bb58d5d70f04) | [MAP-NEO](https://github.com/multimodal-art-projection/MAP-NEO) | [multimodal-art-projection](https://github.com/multimodal-art-projection) |  CD  | [Paper](https://arxiv.org/abs/2405.19327) |\n| GEB-Chat | 1.3B | 2024-06 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/GEB-AGI/geb-1.3b) |    /     | [GEB-AGI](https://huggingface.co/GEB-AGI) |  CD  | [Paper](https://arxiv.org/pdf/2406.09900) |\n| Nemotron-4-Chat | 340B | 2024-06 | å¤šè¯­ | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/nvidia) |    /     | [NVIDIA](https://github.com/NVIDIA) |  CD  | [technical report](https://research.nvidia.com/publication/2024-06_nemotron-4-340b). |\n| Index-Chat | 1.9B | 2024-06 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/IndexTeam/Index-1.9B-Chat) | [Index-1.9B](https://github.com/bilibili/Index-1.9B) | [bilibili](https://github.com/bilibili) |  CD  | [Report](https://github.com/bilibili/Index-1.9B/blob/main/Index-1.9B%20%E6%8A%80%E6%9C%AF%E6%8A%A5%E5%91%8A.pdf) |\n| Qwen2-MoE  |   57B/A14B    | 2024-06 | å¤šè¯­ | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/Qwen) | [Qwen2](https://github.com/QwenLM/Qwen2) | [QwenLM](https://github.com/QwenLM) | MoE  | [Blog](https://qwenlm.github.io/) |\n| Qwen2-Chat | 0.5/2/5/7/72B | 2024-06 | å¤šè¯­ | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/Qwen) | [Qwen2](https://github.com/QwenLM/Qwen2) | [QwenLM](https://github.com/QwenLM) |  CD  | [Blog](https://qwenlm.github.io/) |\n| GLM-4-Chat  |      9B      | 2024-06 | å¤šè¯­ | é€šç”¨ |          [ğŸ¤—HF](https://huggingface.co/THUDM)           |         [GLM-4](https://github.com/THUDM/GLM-4)         |     [THUDM](https://github.com/THUDM)      |  /   |   |\n| Skywork-MoE | 16/A22B/146B | 2024-06 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/Skywork/Skywork-MoE-Base) | [Skywork-MoE](https://github.com/SkyworkAI/Skywork-MoE) | [SkyworkAI](https://github.com/SkyworkAI)  | MoE  | [Tech Report](https://github.com/SkyworkAI/Skywork-MoE/blob/main/skywork-moe-tech-report.pdf) |\n| Yuan2.0 | 40/A3.7B | 2024-05 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/IEITYuan/Yuan2-M32-hf) | [Yuan2.0-M32](https://github.com/IEIT-Yuan/Yuan2.0-M32) | [IEIT-Yuan](https://github.com/IEIT-Yuan) | MOE  | [Paper](https://arxiv.org/abs/2405.17976) |\n| æ˜Ÿè¾°-Chat |  52B  | 2024-05 | ä¸­è‹± | é€šç”¨ |    [ğŸ¤—HF](https://hf-mirror.com/Tele-AI/TeleChat-52B)     | [TeleChat-52B](https://github.com/Tele-AI/TeleChat-52B) |    [Tele-AI](https://github.com/Tele-AI)    |  CD  |                                               |\n| LingLong  | 317M  | 2024-05 | ä¸­è‹± | é€šç”¨ |  [ğŸ¤—HF](https://hf-mirror.com/AlumiK/LingLong-317M-Chat)  |   [linglong](https://github.com/nkcs-iclab/linglong)    | [nkcs-iclab](https://github.com/nkcs-iclab) |  CD  |                                               |\n|  Sailor   |  14B  | 2024-05 | 7è¯­  | é€šç”¨ |    [ğŸ¤—HF](https://hf-mirror.com/sail/Sailor-14B-Chat)     |   [sailor-llm](https://github.com/sail-sg/sailor-llm)   |    [sail-sg](https://github.com/sail-sg)    |  CD  | [Paper](https://arxiv.org/pdf/2404.03608.pdf) |\n| Nanbeige2 | 8/16B | 2024-05 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://hf-mirror.com/Nanbeige/Nanbeige2-16B-Chat) |    [Nanbeige](https://github.com/Nanbeige/Nanbeige)     |   [Nanbeige](https://github.com/Nanbeige)   |  CD  |                                               |\n| Yi-1.5-Chat | 6/9/34B | 2024-05 | ä¸­è‹±  | é€šç”¨  | [ğŸ¤—HF](https://huggingface.co/01-ai) | [Yi-1.5](https://github.com/01-ai/Yi-1.5) | [01-ai](https://github.com/01-ai) | CD  | [Paper](https://arxiv.org/abs/2403.04652) |\n| DeepSeek-V2-Chat | A21B/236B | 2024-05 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/deepseek-ai/DeepSeek-V2-Chat) | [DeepSeek-V2](https://github.com/deepseek-ai/DeepSeek-V2) | [deepseek-ai](https://github.com/deepseek-ai) | MOE | [Paper](https://github.com/deepseek-ai/DeepSeek-V2/blob/main/deepseek-v2-tech-report.pdf) |\n| XVERSE-MoE | A4.2B/25.8B | 2024-05 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/xverse/XVERSE-MoE-A4.2B) | [XVERSE-MoE-A4.2B](https://github.com/xverse-ai/XVERSE-MoE-A4.2B) |[xverse-ai](https://github.com/xverse-ai)|MOE||\n| Llama3-zh | 8/70B | 2024-04 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/collections/xianbao/llama3-zh-662ba8503bdfe51948a28403) | / |/|CD|llama3ä¸­æ–‡åˆ—è¡¨|\n| Llama3-Chinese-Chat | 8B | 2024-04 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/shenzhi-wang/Llama3-8B-Chinese-Chat) | / |[Shenzhi Wang](https://huggingface.co/shenzhi-wang)|CD||\n| Llama-3-Chat | 8/70B | 2024-04 | å¤šè¯­ | é€šç”¨ | [ğŸ¤—HF](https://hf-mirror.com/meta-llama) | **[llama3](https://github.com/meta-llama/llama3)** |[Meta Llama](https://github.com/meta-llama)|CD||\n| Zhinao-Chat | 7B | 2024-04 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/qihoo360) [ ğŸ¤–](https://www.modelscope.cn/models/qihoo360/360Zhinao-7B-Base/summary) | / |[å¥‡è™ç§‘æŠ€](https://huggingface.co/qihoo360)|CD||\n| MiniCPM-MoE | 8x2B | 2024-04 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/openbmb/MiniCPM-MoE-8x2B) | [MiniCPM](https://github.com/OpenBMB/MiniCPM) |[OpenBMB](https://github.com/OpenBMB)|MoE||\n| Nanbeige2-Chat | 8B | 2024-04 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/Nanbeige/Nanbeige2-8B-Chat) | [Nanbeige](https://github.com/Nanbeige/Nanbeige) |[Nanbeige LLM Lab](https://github.com/Nanbeige)|CD||\n| Sailor | 7B | 2024-04 | å¤šè¯­ | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/sail/Sailor-4B-Chat) | [sailor-llm](https://github.com/sail-sg/sailor-llm) |[Sea AI Lab](https://github.com/sail-sg)|CD|[Paper](https://arxiv.org/pdf/2404.03608.pdf)|\n| Mengzi3-Chat | 13B  | 2024-04 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/Langboat) | [Mengzi3](https://github.com/Langboat/Mengzi3) ![Star](https://img.shields.io/github/stars/Langboat/Mengzi3.svg?style=social&label=Star) | [Langboat](https://github.com/Langboat) |  CD  |  |\n| Qwen-MoE | 2.7B | 2024-03 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/Qwen/Qwen1.5-MoE-A2.7B-Chat) | [Qwen1.5](https://github.com/QwenLM/Qwen1.5) ![Star](https://img.shields.io/github/stars/QwenLM/Qwen1.5.svg?style=social&label=Star) | [Qwen](https://github.com/QwenLM) | MoE | [Blog](https://qwenlm.github.io/zh/blog/qwen-moe/) |\n| Command-R | 35B | 2024-03 | å¤šè¯­ | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/CohereForAI) | / | [CohereForAI](https://huggingface.co/CohereForAI) | CD | |\n| Breeze-Instruct | 7B | 2024-02 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/MediaTek-Research) | / | [MediaTek Research](https://huggingface.co/MediaTek-Research) |  |  |\n| aya-101 | 13B | 2024-02 | å¤šè¯­ | é€šç”¨ | [ğŸ¤—HF](https://hf-mirror.com/CohereForAI/aya-101) | / | [Cohere For AI](https://hf-mirror.com/CohereForAI/aya-101/blob/main/(https://cohere.for.ai)) | CD | [Paper](https://arxiv.org/abs/2402.07827) |\n| ChemLLM | 7B | 2024-02 | å¤šè¯­ | é€šç”¨ | [ğŸ¤—HF](https://hf-mirror.com/CohereForAI/aya-101) | / | [AI4Chem](https://hf-mirror.com/AI4Chem) | CD | [Paper](https://arxiv.org/abs/2402.06852) |\n| TowerInstruct | 7/13B | 2024-02 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://hf-mirror.com/Unbabel) | / | [Unbabel](https://hf-mirror.com/Unbabel) | CD |  |\n| Qwen1.5-Chat | 0.5/1.8/4/<br/>7/14/32/72/110B | 2024-02 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/Qwen) | [Qwen1.5](https://github.com/QwenLM/Qwen1.5)![Star](https://img.shields.io/github/stars/QwenLM/Qwen1.5.svg?style=social&label=Star) | [Qwen](https://github.com/QwenLM) | / | [Blog](https://qwenlm.github.io/zh/blog/qwen1.5/) |\n| MiniCPM | 2B | 2024-02 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/openbmb) [ModelScope](https://modelscope.cn/organization/OpenBMB) | [MiniCPM](https://github.com/OpenBMB/MiniCPM)![Star](https://img.shields.io/github/stars/OpenBMB/MiniCPM.svg?style=social&label=Star) | [OpenBMB](https://github.com/OpenBMB) | / | [Report](https://shengdinghu.notion.site/MiniCPM-c805a17c5c8046398914e47f0542095a) |\n| **LongAlign-Chat** | 6/7/13B | 2024-02 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://hf-mirror.com/THUDM) | [LongAlign](https://github.com/THUDM/LongAlign)![Star](https://img.shields.io/github/stars/THUDM/LongAlign.svg?style=social&label=Star) | [THUDM](https://github.com/THUDM) | / | [Paper](https://arxiv.org/abs/2401.18058) |\n| Chinese-Mixtral-Chat | 8x7B | 2024-02 | ä¸­è‹± | é€šç”¨ | [[Baidu\\]](https://pan.baidu.com/s/1nwJ8JkMTUrCkDEccg7C9Pw?pwd=33kb) [[ğŸ¤—HF\\]](https://huggingface.co/hfl/chinese-mixtral) | [Chinese-Mixtral](https://github.com/ymcui/Chinese-Mixtral)![Star](https://img.shields.io/github/stars/ymcui/Chinese-Mixtral.svg?style=social&label=Star) | [Yiming Cui](https://github.com/ymcui) | MOE |  |\n| iFlytekSpark-Chat | 13B | 2024-01 | ä¸­è‹± | é€šç”¨ | [mindspore](https://xihe.mindspore.cn/modelzoo/iflytek/introduce) | / | [ç§‘å¤§è®¯é£]() | CD |  |\n| rwkv-5-world | 0.1/1/<br/>3/7B | 2023-01 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/BlinkDL) | [RWKV-LM](https://github.com/BlinkDL/RWKV-LM)![Star](https://img.shields.io/github/stars/BlinkDL/RWKV-LM.svg?style=social&label=Star) | [BlinkDL](https://github.com/BlinkDL) |  | [URL](https://wiki.rwkv.com/) |\n| Orion-Chat | 14B | 2024-01 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/OrionStarAI) | [Orion](https://github.com/OrionStarAI/Orion)![Star](https://img.shields.io/github/stars/OrionStarAI/Orion.svg?style=social&label=Star) | [OrionStarAI](https://github.com/OrionStarAI) | CD | [Paper](https://github.com/OrionStarAI/Orion/blob/master/doc/Orion14B_v3.pdf) |\n| internlm2-chat | 7/20B | 2024-01 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/internlm) | [InternLM](https://github.com/InternLM/InternLM)![Star](https://img.shields.io/github/stars/InternLM/InternLM.svg?style=social&label=Star) | [InternLM](https://github.com/InternLM) | CD | [Report](https://github.com/InternLM/InternLM/issues/new) |\n| Chinese-Mixtral | 8x7B | 2023-01 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/HIT-SCIR/Chinese-Mixtral-8x7B) | / | [HIT-SCIR](https://huggingface.co/HIT-SCIR) | CD-MOE |  |\n| Telechat | 7/12B | 2024-01 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://hf-mirror.com/Tele-AI) | [Telechat](https://github.com/Tele-AI/Telechat)x ![Star](https://img.shields.io/github/stars/Tele-AI/Telechat.svg?style=social&label=Star) | [Tele-AI](https://github.com/Tele-AI) | CD | [Report](https://arxiv.org/abs/2401.03804) |\n| kagentlms | 7/13B | 2024-01 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://hf-mirror.com/kwaikeg) | [KwaiAgents](https://github.com/KwaiKEG/KwaiAgents)![Star](https://img.shields.io/github/stars/KwaiKEG/KwaiAgents.svg?style=social&label=Star) | [KwaiKEG](https://github.com/KwaiKEG) |  |  |\n|  YaYi2-Chat  |   30B    | 2023-12 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/wenge-research) | [YAYI2](https://github.com/wenge-research/YAYI2)![Star](https://img.shields.io/github/stars/wenge-research/YAYI2.svg?style=social&label=Star) | [wenge-research](https://github.com/wenge-research) |  CD  | [Paper](https://arxiv.org/abs/2312.14862) |\n| SUS-Chat | 34/72B | 2023-12 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/SUSTech) | [SUS-Chat](https://github.com/SUSTech-IDEA/SUS-Chat)![Star](https://img.shields.io/github/stars/SUSTech-IDEA/SUS-Chat.svg?style=social&label=Star) | [SUSTech-IDEA](https://github.com/SUSTech-IDEA) | CD |  |\n| Aquila2-Chat | 7/34/70B | 2023-12 | ä¸­è‹± | é€šç”¨ |  [[ğŸ¤—HF\\]](https://huggingface.co/BAAI)   | [Aquila2](https://github.com/FlagAI-Open/Aquila2) ![Star](https://img.shields.io/github/stars/FlagAI-Open/Aquila2.svg?style=social&label=Star) |    [FlagAI](https://github.com/FlagAI-Open)     |  CD  |  |\n| Alaya-Chat | 7B | 2023-12 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/DataCanvas) | [Alaya](https://github.com/DataCanvasIO/Alaya)![Star](https://img.shields.io/github/stars/DataCanvasIO/Alaya.svg?style=social&label=Star) | [DataCanvas](https://github.com/DataCanvasIO) | CD |  |\n| Qwen-Chat | 1.8/7/<br/>14/72B | 2023-12 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/Qwen) | [Qwen](https://github.com/QwenLM/Qwen) ![Star](https://img.shields.io/github/stars/QwenLM/Qwen.svg?style=social&label=Star) | [é˜¿é‡Œäº‘](https://github.com/QwenLM) |  CD  | [Paper](https://arxiv.org/abs/2309.16609) [Report](https://github.com/QwenLM/Qwen-7B/blob/main/tech_memo.md) [Report2](https://qianwen-res.oss-cn-beijing.aliyuncs.com/QWEN_TECHNICAL_REPORT.pdf) |\n| DeepSeek-Chat | 7/67B | 2023-11 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/deepseek-ai) | [DeepSeek-LLM](https://github.com/deepseek-ai/DeepSeek-LLM)![Star](https://img.shields.io/github/stars/deepseek-ai/DeepSeek-LLM.svg?style=social&label=Star) | [deepseek-ai](https://github.com/deepseek-ai) | CD |  |\n| Yi-Chat | 6/34B | 2023-11 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/01-ai) | [Yi](https://github.com/01-ai/Yi) ![Star](https://img.shields.io/github/stars/01-ai/Yi.svg?style=social&label=Star) | [01.AI](https://github.com/01-ai) | CD |  |\n| Alaya-Chat | 7B | 2023-11 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/DataCanvas/Alaya-7B-Chat) | [Alaya](https://github.com/DataCanvasIO/Alaya)![Star](https://img.shields.io/github/stars/DataCanvasIO/Alaya.svg?style=social&label=Star) | [DataCanvasIO](https://github.com/DataCanvasIO) | CD |  |\n| OrionStar-Yi-Chat | 34B | 2023-11 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/OrionStarAI/OrionStar-Yi-34B-Chat) | [OrionStar-Yi-34B-Chat](https://github.com/OrionStarAI/OrionStar-Yi-34B-Chat)![Star](https://img.shields.io/github/stars/OrionStarAI/OrionStar-Yi-34B-Chat.svg?style=social&label=Star) | [OrionStarAI](https://github.com/OrionStarAI) | CD |  |\n| Nanbeige-Chat | 16B | 2023-11 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/Nanbeige) | [Nanbeige](https://github.com/Nanbeige/Nanbeige)![Star](https://img.shields.io/github/stars/Nanbeige/Nanbeige.svg?style=social&label=Star) | [Nanbeige LLM Lab](https://github.com/Nanbeige) | CD |  |\n| OpenChat 3.5 | 7B | 2023-11 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/openchat/openchat_3.5) | [openchat](https://github.com/imoneoi/openchat) | [OpenChat](https://github.com/imoneoi) | CD | [Paper](https://arxiv.org/pdf/2309.11235.pdf) |\n|          XVERSE-Chat    |     7/13B     | 2023-11 | å¤šè¯­ | é€šç”¨ |       [[ğŸ¤—HF\\]](https://huggingface.co/xverse)       | [XVERSE](https://github.com/xverse-ai/XVERSE-13B)![Star](https://img.shields.io/github/stars/xverse-ai/XVERSE-13B.svg?style=social&label=Star) |           [å…ƒè±¡ç§‘æŠ€](https://github.com/xverse-ai)           |  CD  |                                                              |\n| AndesGPT | 7B | 2023-11 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/OPPOResearchInstitute/AndesGPT-7B) | [AndesGPT-7B](https://github.com/OPPO-Mente-Lab/AndesGPT-7B) | [OPPO-Mente-Lab](https://github.com/OPPO-Mente-Lab) | CD |  |\n| SeaLLM-Chat | 13B  | 2023-11 | å¤šè¯­ | é€šç”¨ |    [[ğŸ¤—HF\\]](https://huggingface.co/SeaLLMs/SeaLLM-Chat-13b)    |        [SeaLLMs](https://github.com/SeaLLMs/SeaLLMs)         |        [SeaLLMs](https://github.com/SeaLLMs)        |  CD  |  |\n| BlueLM | 7B | 2023-11 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/vivo-ai) | [BlueLM](https://github.com/vivo-ai-lab/BlueLM)![Star](https://img.shields.io/github/stars/vivo-ai-lab/BlueLM.svg?style=social&label=Star) | [vivo AI Lab](https://github.com/vivo-ai-lab) | CD |  |\n| Skywork-chat | 13B  | 2023-10 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/Skywork) | [Skywork](https://github.com/SkyworkAI/Skywork) |   [SkyworkAI](https://github.com/SkyworkAI)   |  CD  | [Paper](https://arxiv.org/abs/2310.16713) |\n| Zephyr | 7B | 2023-10 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/HuggingFaceH4/zephyr-7b-beta) | [alignment-handbook](https://github.com/huggingface/alignment-handbook)![Star](https://img.shields.io/github/stars/huggingface/alignment-handbook.svg?style=social&label=Star) | [Hugging Face H4](https://huggingface.co/HuggingFaceH4) | CD | [Paper](https://arxiv.org/abs/2310.16944) |\n| Mistral | 7B | 2023-10 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/mistralai) | [mistral-src](https://github.com/mistralai/mistral-src)![Star](https://img.shields.io/github/stars/mistralai/mistral-src.svg?style=social&label=Star) | [Mistral AI](https://github.com/mistralai) | CD | [Paper](https://arxiv.org/abs/2310.06825) |\n| chatglm3 | 6B | 2023-10 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/THUDM) | [ChatGLM3](https://github.com/THUDM/ChatGLM3)![Star](https://img.shields.io/github/stars/THUDM/ChatGLM3.svg?style=social&label=Star) | [THUDM](https://github.com/THUDM) | ND |  |\n| Zhiyin-chat | 7B | 2023-10 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/HCCL-NLP/Zhiyin-7B-Chat) | [Zhiyin](https://github.com/HCCL-NLP/Zhiyin)![Star](https://img.shields.io/github/stars/HCCL-NLP/Zhiyin.svg?style=social&label=Star) | [ä¸­ç§‘é™¢å£°å­¦æ‰€](https://github.com/HCCL-NLP) | CD |  |\n|        Ziya2-Chat        |     13B     | 2023-10 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://modelscope.cn/models/Fengshenbang/Ziya2-13B-Chat/summary) | [Fengshenbang-LM](https://github.com/IDEA-CCNL/Fengshenbang-LM) |          [IDEAç ”ç©¶é™¢](https://github.com/IDEA-CCNL)          |  CD  |                                                              |\n|         Vulture          |   40/180B   | 2023-10 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/vilm/vulture-40b) |                              /                               |            [VILM-AI](https://huggingface.co/vilm)            |      |                           [TODO]()                           |\n|         Vulture          | 3/7/<br/>40/180B | 2023-09 | å¤šè¯­ | é€šç”¨ |             [[ğŸ¤—HF\\]](https://huggingface.co/vilm)              |                              /                               |                [VILM](https://www.vilm.org/)                 |  CD  |                                                              |\n|     Colossal-LLaMA-2     |     7B      | 2023-09 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/hpcai-tech/Colossal-LLaMA-2-7b-base) | [ColossalAI](https://github.com/hpcaitech/ColossalAI)![Star](https://img.shields.io/github/stars/hpcaitech/ColossalAI.svg?style=social&label=Star) |         [HPC-AI Tech](https://github.com/hpcaitech)          |  CD  | [Blog](https://www.hpc-ai.tech/blog/one-half-day-of-training-using-a-few-hundred-dollars-yields-similar-results-to-mainstream-large-models-open-source-and-commercial-free-domain-specific-llm-solution) |\n|       OpenBA-chat        |     15B     | 2023-09 | ä¸­è‹± | é€šç”¨ |                           [TODO]()                           | [OpenBA](https://github.com/OpenNLG/OpenBA)![Star](https://img.shields.io/github/stars/OpenNLG/OpenBA.svg?style=social&label=Star) |         [OpenNLG Group](https://github.com/OpenNLG)          |  ED  |          [Paper](https://arxiv.org/abs/2309.10706)           |\n|       WeMix-LLaMA2       |    7/70B    | 2023-09 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/Alpha-VLLM/WeMix-LLaMA2-7B) | [WeMix-LLM](https://github.com/Alpha-VLLM/WeMix-LLM)![Star](https://img.shields.io/github/stars/Alpha-VLLM/WeMix-LLM.svg?style=social&label=Star) |         [Alpha-VLLM](https://github.com/Alpha-VLLM)          |  CD  |                                                              |\n|      Stable Beluga       |  7/13/70B   | 2023-09 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/stabilityai/StableBeluga-7B) |                              /                               |       [Stability AI](https://github.com/Stability-AI)        |  CD  |                                                              |\n|      TigerBot-chat       |     70B     | 2023-09 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/TigerResearch/tigerbot-70b-chat) | [TigerBot](https://github.com/TigerResearch/TigerBot) ![Star](https://img.shields.io/github/stars/TigerResearch/TigerBot.svg?style=social&label=Star) |         [è™åšç§‘æŠ€](https://github.com/TigerResearch)         |  CD  | [Paper](https://github.com/TigerResearch/TigerBot/wiki/TigerBot%E2%80%9070B%E5%8F%91%E5%B8%83%EF%BC%81) |\n|     Openbuddy_llama      |     70B     | 2023-09 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/OpenBuddy/openbuddy-llama2-70b-v10.1-bf16) | [OpenBuddy](https://github.com/OpenBuddy/OpenBuddy)![Star](https://img.shields.io/github/stars/OpenBuddy/OpenBuddy.svg?style=social&label=Star) |          [OpenBuddy](https://github.com/OpenBuddy)           |  CD  |                                                              |\n|     falcon-180B-chat     |    180B     | 2023-09 | å¤šè¯­ | é€šç”¨ |    [[ğŸ¤—HF\\]](https://huggingface.co/tiiuae/falcon-180B-chat)    |                              /                               | [Technology Innovation Institute](https://github.com/tiiuae) |  CD  |                                                              |\n|        Baichuan2         |    7/13B    | 2023-09 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/baichuan-inc/Baichuan2-7B-Chat) | [Baichuan2](https://github.com/baichuan-inc/Baichuan2)![Star](https://img.shields.io/github/stars/baichuan-inc/Baichuan2.svg?style=social&label=Star) |         [ç™¾å·æ™ºèƒ½](https://github.com/baichuan-inc)          |  CD  |                                                              |\n|   Chinese-Alpaca-2-16K   |    7/13B    | 2023-09 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/ziqingyang/chinese-alpaca-2-7b-16k) | [Chinese-LLaMA-Alpaca-2](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2) |            [Yiming Cui](https://github.com/ymcui)            |  CD  |                                                              |\n|     InternLM-Chat-8k     |     7B      | 2023-08 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/internlm/internlm-chat-7b-8k)  | [InternLM](https://github.com/InternLM/InternLM)![Star](https://img.shields.io/github/stars/InternLM/InternLM.svg?style=social&label=Star) |      [ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤](https://github.com/InternLM)       |  CD  | [report](https://github.com/InternLM/InternLM-techreport/tree/main) |\n|    InternLM-Chat-v1.1    |     7B      | 2023-08 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/internlm/internlm-chat-7b-v1_1) | [InternLM](https://github.com/InternLM/InternLM)![Star](https://img.shields.io/github/stars/InternLM/InternLM.svg?style=social&label=Star) |      [ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤](https://github.com/InternLM)       |  CD  | [report](https://github.com/InternLM/InternLM-techreport/tree/main) |\n|       YuLan-Chat-2       |     13B     | 2023-08 | ä¸­è‹± | é€šç”¨ |  [[ğŸ¤—HF\\]](https://huggingface.co/yulan-team/YuLan-Chat-2-13b)  | [YuLan-Chat](https://github.com/RUC-GSAI/YuLan-Chat) |         [ä¸­å›½äººæ°‘å¤§å­¦](https://github.com/RUC-GSAI)          |  CD  |                                                              |\n|          falcon          |    7/40B    | 2023-06 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/tiiuae/falcon-7b) |         [[ğŸ¤—HF\\]](https://huggingface.co/tiiuae)         | [Technology Innovation Institute](https://github.com/tiiuae) |  CD  |                                                              |\n|          Toucan          |     7B      | 2023-08 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://1drv.ms/f/s!Ar5igoMgwOq4gdowvr5NQDHOQp2OxQ?e=dzYSuE) | [Toucan-LLM](https://github.com/kendryte/Toucan-LLM)![Star](https://img.shields.io/github/stars/kendryte/Toucan-LLM.svg?style=social&label=Star) |           [Kendryte](https://github.com/kendryte)            |  CD  |                                                              |\n|          Zhuzhi          |     6B      | 2023-08 | ä¸­è‹± | é€šç”¨ |    [[ğŸ¤—HF\\]](https://huggingface.co/emotibot-inc/Zhuzhi-6B)     | [Zhuzhi-6B](https://github.com/emotibot-inc/Zhuzhi-6B)![Star](https://img.shields.io/github/stars/emotibot-inc/Zhuzhi-6B.svg?style=social&label=Star) |         [ç«¹é—´æ™ºèƒ½](https://github.com/emotibot-inc)          |  ND  |                                                              |\n|           Atom           |     7B      | 2023-08 | ä¸­è‹± | é€šç”¨ |       [[ğŸ¤—HF\\]](https://huggingface.co/FlagAlpha/Atom-7B)       | [Llama2-Chinese](https://github.com/FlagAlpha/Llama2-Chinese)![Star](https://img.shields.io/github/stars/FlagAlpha/Llama2-Chinese.svg?style=social&label=Star) |          [FlagAlpha](https://github.com/FlagAlpha)           |  CD  |                                                              |\n|        openbuddy         | 3/7/<br/>13/40B | 2023-08 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://github.com/OpenBuddy/OpenBuddy/blob/main/models.md) | [OpenBuddy](https://github.com/OpenBuddy/OpenBuddy)![Star](https://img.shields.io/github/stars/OpenBuddy/OpenBuddy.svg?style=social&label=Star) |          [OpenBuddy](https://github.com/OpenBuddy)           |  CD  |                                                              |\n|     Aquila-Chat-33B      |     33B     | 2023-08 | ä¸­è‹± | é€šç”¨ |                           [TODO]()                           | [Aquila](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/Aquila)![Star](https://img.shields.io/github/stars/FlagAI-Open/FlagAI.svg?style=social&label=Star) |           [FlagAI](https://github.com/FlagAI-Open)           |  CD  |                                                              |\n|     vicuna-V1.5-16K      |    7/13B    | 2023-08 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/lmsys/vicuna-7b-v1.5-16k) | [FastChat](https://github.com/lm-sys/FastChat)![Star](https://img.shields.io/github/stars/lm-sys/FastChat.svg?style=social&label=Star) |             [lm-sys](https://github.com/lm-sys)              |  CD  |          [Paper](https://arxiv.org/abs/2306.05685)           |\n|       vicuna-V1.5        |    7/13B    | 2023-08 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/lmsys/vicuna-7b-v1.5) | [FastChat](https://github.com/lm-sys/FastChat)![Star](https://img.shields.io/github/stars/lm-sys/FastChat.svg?style=social&label=Star) |             [lm-sys](https://github.com/lm-sys)              |  CD  |          [Paper](https://arxiv.org/abs/2306.05685)           |\n|     Chinese-Alpaca-2     |     13B     | 2023-08 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/ziqingyang/chinese-alpaca-2-lora-13b) | [Chinese-LLaMA-Alpaca-2](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2) |            [Yiming Cui](https://github.com/ymcui)            |  CD  |                                                              |\n|      WizardLM-V1.0       |     70B     | 2023-08 | å¤šè¯­ | é€šç”¨ |  [[ğŸ¤—HF\\]](https://huggingface.co/WizardLM/WizardLM-70B-V1.0)   | [WizardLM](https://github.com/nlpxucan/WizardLM)![Star](https://img.shields.io/github/stars/nlpxucan/WizardLM.svg?style=social&label=Star) |           [operatorx](https://github.com/nlpxucan)           |  CD  |                                                              |\n|    TigerBot-chat-13B     |     13B     | 2023-07 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/TigerResearch/tigerbot-13b-chat) | [TigerBot](https://github.com/TigerResearch/TigerBot)![Star](https://img.shields.io/github/stars/TigerResearch/TigerBot.svg?style=social&label=Star) |         [è™åšç§‘æŠ€](https://github.com/TigerResearch)         |  CD  |                                                              |\n|          huozi           |     7B      | 2023-08 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/HIT-SCIR/huozi-7b-sft) | [huozi](https://github.com/HIT-SCIR/huozi)![Star](https://img.shields.io/github/stars/HIT-SCIR/huozi.svg?style=social&label=Star) |            [å“ˆå·¥å¤§](https://github.com/HIT-SCIR)             |  CD  |                                                              |\n|     Chinese-Alpaca-2     |     7B      | 2023-07 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/ziqingyang/chinese-alpaca-2-7b) | [Chinese-LLaMA-Alpaca-2](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2)![Star](https://img.shields.io/github/stars/ymcui/Chinese-LLaMA-Alpaca-2.svg?style=social&label=Star) |            [Yiming Cui](https://github.com/ymcui)            |  CD  |                                                              |\n|           AntX           |    7/13B    | 2023-07 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/AntX-ai/AntX-7B) |                              /                               |          [AntX.ai](https://huggingface.co/AntX-ai)           |  CD  |                                                              |\n|          BatGPT          |     15B     | 2023-07 | ä¸­è‹± | é€šç”¨ |   [[ğŸ¤—HF\\]](https://huggingface.co/MLP-lab/BatGPT-15B-sirius)   | [BatGPT](https://github.com/zcli-charlie/BatGPT)![Star](https://img.shields.io/github/stars/zcli-charlie/BatGPT.svg?style=social&label=Star) |        [ä¸Šæµ·äº¤é€šå¤§å­¦](https://huggingface.co/MLP-lab)        |  ND  |          [Paper](https://arxiv.org/abs/2307.00360)           |\n|      WizardLM-V1.2       |     13B     | 2023-07 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/WizardLM/WizardLM-13B-V1.2) | [WizardLM](https://github.com/nlpxucan/WizardLM)![Star](https://img.shields.io/github/stars/nlpxucan/WizardLM.svg?style=social&label=Star) |           [operatorx](https://github.com/nlpxucan)           |  CD  |          [Paper](https://arxiv.org/pdf/2304.12244)           |\n|   llama2-Chinese-chat    |     13B     | 2023-07 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://www.codewithgpu.com/m/file/llama2-13b-Chinese-chat) | [llama2-Chinese-chat](https://github.com/CrazyBoyM/llama2-Chinese-chat)![Star](https://img.shields.io/github/stars/CrazyBoyM/llama2-Chinese-chat.svg?style=social&label=Star) |            [Ke Bai](https://github.com/CrazyBoyM)            |  CD  |                                                              |\n|        Jiang-chat        |     13B     | 2023-07 | ä¸­æ–‡ | é€šç”¨ |        [[ğŸ¤—HF\\]](https://huggingface.co/kdf/jiang-chat)         |                              /                               |            [çŸ¥æœªæ™ºèƒ½](https://huggingface.co/kdf)            |  CD  |                                                              |\n|   Llama2-chinese-chat    |    7/13B    | 2023-07 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/FlagAlpha/Llama2-Chinese-7b-Chat) | [Llama2-Chinese](https://github.com/FlagAlpha/Llama2-Chinese)![Star](https://img.shields.io/github/stars/FlagAlpha/Llama2-Chinese.svg?style=social&label=Star) |          [FlagAlpha](https://github.com/FlagAlpha)           |  CD  |                                                              |\n|           LL7M           |     7B      | 2023-07 | å¤šè¯­ | é€šç”¨ |      [[ğŸ¤—HF\\]](https://huggingface.co/JosephusCheung/LL7M)      |                              /                               |    [Joseph Cheung](https://huggingface.co/JosephusCheung)    |  CD  |                                                              |\n|     Chinese-Llama-2      |     7B      | 2023-07 | ä¸­è‹± | é€šç”¨ |  [[ğŸ¤—HF\\]](https://huggingface.co/LinkSoul/Chinese-Llama-2-7b)  | [Chinese-Llama-2-7b](https://github.com/LinkSoul-AI/Chinese-Llama-2-7b)![Star](https://img.shields.io/github/stars/LinkSoul-AI/Chinese-Llama-2-7b.svg?style=social&label=Star) |        [LinkSoul-AI](https://github.com/LinkSoul-AI)         |  CD  |                                                              |\n|       Llama2-chat        |  7/13/70B   | 2023-07 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/llamaste/Llama-2-7b-chat) | [llama](https://github.com/facebookresearch/llama)![Star](https://img.shields.io/github/stars/facebookresearch/llama.svg?style=social&label=Star) |         [Meta](https://github.com/facebookresearch)          |  CD  | [Paper](https://scontent-hkg4-1.xx.fbcdn.net/v/t39.2365-6/10000000_663429262362723_1696968207443577320_n.pdf?_nc_cat=101&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=5ol-jUSglG4AX-br54S&_nc_ht=scontent-hkg4-1.xx&oh=00_AfDzh9f2kFTRk-FIieoySi12fhBjvJP4Bv-ZJTxRtdoXJg&oe=64BBB691) |\n|       PolyLM-chat        |     13B     | 2023-07 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/DAMO-NLP-MT/polylm-multialpaca-13b) | [PolyLM](https://modelscope.cn/models/damo/nlp_polylm_13b_text_generation/summary) |         [è¾¾æ‘©é™¢](https://huggingface.co/DAMO-NLP-MT)         |  CD  |        [Paper](https://arxiv.org/pdf/2307.06018.pdf)         |\n|    Baichuan-13B-chat     |     13B     | 2023-07 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/baichuan-inc/Baichuan-13B-Chat) | [Baichuan-13B](https://github.com/baichuan-inc/Baichuan-13B)![Star](https://img.shields.io/github/stars/baichuan-inc/Baichuan-13B.svg?style=social&label=Star) |         [ç™¾å·æ™ºèƒ½](https://github.com/baichuan-inc)          |  CD  |                                                              |\n|       vicuna-V1.3        |  7/13/33B   | 2023-07 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/lmsys/vicuna-7b-v1.3) | [FastChat](https://github.com/lm-sys/FastChat)![Star](https://img.shields.io/github/stars/lm-sys/FastChat.svg?style=social&label=Star) |             [lm-sys](https://github.com/lm-sys)              |  CD  |          [Paper](https://arxiv.org/abs/2306.05685)           |\n|      WizardLM-V1.0       |  7/13/30B   | 2023-07 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/WizardLM/WizardLM-7B-V1.0) | [WizardLM](https://github.com/nlpxucan/WizardLM)![Star](https://img.shields.io/github/stars/nlpxucan/WizardLM.svg?style=social&label=Star) |           [operatorx](https://github.com/nlpxucan)           |  CD  |          [Paper](https://arxiv.org/pdf/2304.12244)           |\n|     TigerBot-v2-sft      |     7B      | 2023-07 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/TigerResearch/tigerbot-7b-sft-v2) | [TigerBot](https://github.com/TigerResearch/TigerBot)![Star](https://img.shields.io/github/stars/TigerResearch/TigerBot.svg?style=social&label=Star) |         [è™åšç§‘æŠ€](https://github.com/TigerResearch)         |  CD  |                                                              |\n|      InternLM-chat       |    7/20B    | 2023-07 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/internlm/internlm-chat-7b) | [InternLM](https://github.com/InternLM/InternLM)![Star](https://img.shields.io/github/stars/InternLM/InternLM.svg?style=social&label=Star) |      [ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤](https://github.com/InternLM)       |  CD  | [report](https://github.com/InternLM/InternLM-techreport/tree/main) |\n|       vicunaæ±‰åŒ–ç‰ˆ       |     33B     | 2023-07 | ä¸­æ–‡ | é€šç”¨ | [baidu-hiks](https://pan.baidu.com/s/1EH19ablXVLYQP1f-IaPS-Q?pwd=hiks) | [chinese-StableVicuna](https://github.com/ziwang-com/chinese-StableVicuna)![Star](https://img.shields.io/github/stars/ziwang-com/chinese-StableVicuna.svg?style=social&label=Star) |         [ziwang-com](https://github.com/ziwang-com)          |  CD  |                                                              |\n|         CuteGPT          |     13B     | 2023-07 | ä¸­è‹± | é€šç”¨ |  [[ğŸ¤—HF\\]](https://huggingface.co/XuYipei/kw-cutegpt-13b-base)  | [CuteGPT](https://github.com/Abbey4799/CuteGPT)![Star](https://img.shields.io/github/stars/Abbey4799/CuteGPT.svg?style=social&label=Star) |         [å¤æ—¦å¤§å­¦çŸ¥è¯†å·¥åœº](http://kw.fudan.edu.cn/)          |  CD  |                                                              |\n|         MPT-chat         |    7/30B    | 2023-06 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/mosaicml/mpt-7b-chat) | [llm-foundry](https://github.com/mosaicml/llm-foundry)![Star](https://img.shields.io/github/stars/mosaicml/llm-foundry.svg?style=social&label=Star) |           [MosaicML](https://github.com/mosaicml)            |  CD  |                                                              |\n|         ChatGLM2         |     6B      | 2023-06 | ä¸­è‹± | é€šç”¨ |       [[ğŸ¤—HF\\]](https://huggingface.co/THUDM/chatglm2-6b)       | [ChatGLM2-6B](https://github.com/THUDM/ChatGLM2-6B)![Star](https://img.shields.io/github/stars/THUDM/ChatGLM2-6B.svg?style=social&label=Star) |             [æ¸…åå¤§å­¦](https://github.com/THUDM)             |  ND  |                                                              |\n|         BayLing          |    7/13B    | 2023-06 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/ICTNLP/bayling-13b-v1.1) | [BayLing](https://github.com/ictnlp/BayLing)![Star](https://img.shields.io/github/stars/ictnlp/BayLing.svg?style=social&label=Star) |           [ä¸­å›½ç§‘å­¦é™¢](https://github.com/ictnlp)            |  CD  |                                                              |\n|        ZhiXi-Diff        |     13B     | 2023-06 | ä¸­è‹± | é€šç”¨ |     [[ğŸ¤—HF\\]](https://huggingface.co/zjunlp/zhixi-13b-diff)     | [KnowLLM](https://github.com/zjunlp/KnowLM)![Star](https://img.shields.io/github/stars/zjunlp/KnowLM.svg?style=social&label=Star) |            [æµ™æ±Ÿå¤§å­¦](https://github.com/zjunlp)             |  CD  |                                                              |\n|          Anima           |     33B     | 2023-06 | ä¸­æ–‡ | é€šç”¨ |       [[ğŸ¤—HF\\]](https://huggingface.co/lyogavin/Anima33B)       | [Anima](https://github.com/lyogavin/Anima)![Star](https://img.shields.io/github/stars/lyogavin/Anima.svg?style=social&label=Star) |           [Gavin Li](https://github.com/lyogavin)            |  CD  |                                                              |\n|    OpenLLaMA-Chinese     |   3/7/13B   | 2023-06 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/FittenTech/openllama-chinese-13b) | [OpenLLaMA-Chinese](https://github.com/FittenTech/OpenLLaMA-Chinese)![Star](https://img.shields.io/github/stars/FittenTech/OpenLLaMA-Chinese.svg?style=social&label=Star) |         [FittenTech](https://github.com/FittenTech)          |  CD  |                                                              |\n| openbuddy-falcon-7b-v1.5 |     7B      | 2023-06 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/OpenBuddy/openbuddy-falcon-7b-v1.5-fp16) | [OpenBuddy](https://github.com/OpenBuddy/OpenBuddy)![Star](https://img.shields.io/github/stars/OpenBuddy/OpenBuddy.svg?style=social&label=Star) |          [OpenBuddy](https://github.com/OpenBuddy)           |  CD  |                                                              |\n|       AtomGPT_chat       |     13B     | 2023-06 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/AtomEchoAI/AtomGPT_8k_chat) | [AtomGPT](https://github.com/AtomEcho/AtomGPT)![Star](https://img.shields.io/github/stars/AtomEcho/AtomGPT.svg?style=social&label=Star) |           [åŸå­å›å£°](https://github.com/AtomEcho)            |  CD  |                                                              |\n|        AquilaChat        |     7B      | 2023-06 | ä¸­è‹± | é€šç”¨ |     [[ğŸ¤—HF\\]](https://model.baai.ac.cn/model-detail/100101)     | [Aquila](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/Aquila)![Star](https://img.shields.io/github/stars/FlagAI-Open/FlagAI.svg?style=social&label=Star) |           [FlagAI](https://github.com/FlagAI-Open)           |  CD  |                                                              |\n|        YuLan-Chat        |   13/65B    | 2023-06 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/RUCAIBox/YuLan-Chat-65b-delta) | [YuLan-Chat](https://github.com/RUC-GSAI/YuLan-Chat)![Star](https://img.shields.io/github/stars/RUC-GSAI/YuLan-Chat.svg?style=social&label=Star) |         [ä¸­å›½äººæ°‘å¤§å­¦](https://github.com/RUC-GSAI)          |  CD  |                                                              |\n|      Chinese-Alpaca      |     33B     | 2023-06 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/ziqingyang/chinese-alpaca-lora-33b) | [Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca)![Star](https://img.shields.io/github/stars/ymcui/Chinese-LLaMA-Alpaca.svg?style=social&label=Star) |            [Yiming Cui](https://github.com/ymcui)            |  CD  |                                                              |\n|       TigerBot-sft       |   7/180B    | 2023-06 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/TigerResearch/tigerbot-7b-sft) | [TigerBot](https://github.com/TigerResearch/TigerBot)![Star](https://img.shields.io/github/stars/TigerResearch/TigerBot.svg?style=social&label=Star) |         [è™åšç§‘æŠ€](https://github.com/TigerResearch)         |  CD  |                                                              |\n|         ChatYuan         |     7B      | 2023-06 | ä¸­è‹± | é€šç”¨ |   [[ğŸ¤—HF\\]](https://huggingface.co/tiansz/ChatYuan-7B-merge)    | [ChatYuan-7B](https://github.com/clue-ai/ChatYuan-7B)![Star](https://img.shields.io/github/stars/clue-ai/ChatYuan-7B.svg?style=social&label=Star) |             [ClueAI](https://github.com/clue-ai)             |  CD  |                                                              |\n|      Panda-Instruct      |     13B     | 2023-05 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/chitanda/llama-panda-zh-13b-coig-delta) | [pandallm](https://github.com/dandelionsllm/pandallm)![Star](https://img.shields.io/github/stars/dandelionsllm/pandallm.svg?style=social&label=Star) |      [dandelionsllm](https://github.com/dandelionsllm)       |  CD  |                                                              |\n|      Panda-Instruct      |     7B      | 2023-05 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/chitanda/llama-panda-zh-coig-7b-delta) | [pandallm](https://github.com/dandelionsllm/pandallm)![Star](https://img.shields.io/github/stars/dandelionsllm/pandallm.svg?style=social&label=Star) |      [dandelionsllm](https://github.com/dandelionsllm)       |  CD  |                                                              |\n|        BiLLa-SFT         |     7B      | 2023-05 | ä¸­è‹± | é€šç”¨ |    [[ğŸ¤—HF\\]](https://huggingface.co/Neutralzz/BiLLa-7B-SFT)     | [BiLLa](https://github.com/Neutralzz/BiLLa)![Star](https://img.shields.io/github/stars/Neutralzz/BiLLa.svg?style=social&label=Star) |          [Zhongli Li](https://github.com/Neutralzz)          |  CD  |                                                              |\n|      Ziya-LLaMA-v1       |     13B     | 2023-05 | ä¸­è‹± | é€šç”¨ |  [[ğŸ¤—HF\\]](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1)  | [Fengshenbang-LM](https://github.com/IDEA-CCNL/Fengshenbang-LM)![Star](https://img.shields.io/github/stars/IDEA-CCNL/Fengshenbang-LM.svg?style=social&label=Star) |          [IDEAç ”ç©¶é™¢](https://github.com/IDEA-CCNL)          |  CD  |  [Blog](https://mp.weixin.qq.com/s/IeXgq8blGoeVbpIlAUCAjA)   |\n|      BLOOMChat V1.0      |    176B     | 2023-05 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/sambanovasystems/BLOOMChat-176B-v1) |     [bloomchat](https://github.com/sambanova/bloomchat)      |          [SambaNova Systems](https://sambanova.ai/)          |  CD  | [Blog](https://sambanova.ai/blog/introducing-bloomchat-176b-the-multilingual-chat-based-llm/) |\n|          BiLLa           |     7B      | 2023-05 | ä¸­è‹± | é€šç”¨ |          [[ğŸ¤—HF\\]](https://github.com/Neutralzz/BiLLa)          | [BiLLa](https://github.com/Neutralzz/BiLLa)![Star](https://img.shields.io/github/stars/Neutralzz/BiLLa.svg?style=social&label=Star) |          [Zhongli Li](https://github.com/Neutralzz)          |  CD  |                                                              |\n|        Bactrian-X        |    7/13B    | 2023-05 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/MBZUAI/bactrian-x-13b-lora) | [bactrian-x](https://github.com/mbzuai-nlp/bactrian-x)![Star](https://img.shields.io/github/stars/mbzuai-nlp/bactrian-x.svg?style=social&label=Star) |           [MBZUAI](https://github.com/mbzuai-nlp)            |  CD  |                                                              |\n|       Bactrian-ZH        |     7B      | 2023-05 | ä¸­æ–‡ | é€šç”¨ |        [[ğŸ¤—HF\\]](https://huggingface.co/haonan-li)  | [bactrian-x](https://github.com/mbzuai-nlp/bactrian-x)![Star](https://img.shields.io/github/stars/mbzuai-nlp/bactrian-x.svg?style=social&label=Star) |           [MBZUAI](https://github.com/mbzuai-nlp)            |  CD  |                                                              |\n|         ChatFlow         |    7/13B    | 2023-05 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/Linly-AI/ChatFlow-13B) | [Linly](https://github.com/CVI-SZU/Linly)![Star](https://img.shields.io/github/stars/CVI-SZU/Linly.svg?style=social&label=Star) |    [æ·±åœ³å¤§å­¦è®¡ç®—æœºè§†è§‰ç ”ç©¶æ‰€](https://github.com/CVI-SZU)    |  CD  |                                                              |\n|        OpenBuddy         |    7/13B    | 2023-05 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://github.com/OpenBuddy/OpenBuddy/blob/main/models.md) | [OpenBuddy](https://github.com/OpenBuddy/OpenBuddy)![Star](https://img.shields.io/github/stars/OpenBuddy/OpenBuddy.svg?style=social&label=Star) |          [OpenBuddy](https://github.com/OpenBuddy)           |  CD  |                                                              |\n|      YuYan-dialogue      |     11B     | 2023-04 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/FUXI/yuyan-dialogue/tree/main) |                              /                               |           [ç½‘æ˜“ä¼ç¾²](https://huggingface.co/FUXI)            |  CD  |   [paper](https://aclanthology.org/2022.naacl-industry.8/)   |\n| Moss-moon-003-sft-plugin |     16B     | 2023-04 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/fnlp/moss-moon-003-sft-plugin) | [MOSS](https://github.com/OpenLMLab/MOSS)![Star](https://img.shields.io/github/stars/OpenLMLab/MOSS.svg?style=social&label=Star) |           [å¤æ—¦å¤§å­¦](https://github.com/OpenLMLab)           |  CD  |                                                              |\n|    moss-moon-003-sft     |     16B     | 2023-04 | ä¸­è‹± | é€šç”¨ |    [[ğŸ¤—HF\\]](https://huggingface.co/fnlp/moss-moon-003-sft)     | [MOSS](https://github.com/OpenLMLab/MOSS)![Star](https://img.shields.io/github/stars/OpenLMLab/MOSS.svg?style=social&label=Star) |           [å¤æ—¦å¤§å­¦](https://github.com/OpenLMLab)           |  CD  |                                                              |\n|       RWKV-4-Raven       |   3/7/14B   | 2023-04 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/BlinkDL/rwkv-4-raven/tree/main) | [ChatRWKV](https://github.com/BlinkDL/ChatRWKV)![Star](https://img.shields.io/github/stars/BlinkDL/ChatRWKV.svg?style=social&label=Star) |            [BlinkDL](https://github.com/BlinkDL)             | RNN  |        [Blog](https://zhuanlan.zhihu.com/p/618011122)        |\n|    Phoenix-inst-chat     |     7B      | 2023-04 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/FreedomIntelligence/phoenix-inst-chat-7b) | [LLMZoo](https://github.com/FreedomIntelligence/LLMZoo)![Star](https://img.shields.io/github/stars/FreedomIntelligence/LLMZoo.svg?style=social&label=Star) |    [é¦™æ¸¯ä¸­æ–‡å¤§å­¦](https://github.com/FreedomIntelligence)    |  CD  |                                                              |\n|       Phoenix-chat       |     7B      | 2023-04 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/FreedomIntelligence/phoenix-chat-7b) | [LLMZoo](https://github.com/FreedomIntelligence/LLMZoo)![Star](https://img.shields.io/github/stars/FreedomIntelligence/LLMZoo.svg?style=social&label=Star) |    [é¦™æ¸¯ä¸­æ–‡å¤§å­¦](https://github.com/FreedomIntelligence)    |  CD  |                                                              |\n|         ChatPLUG         |    3.7B     | 2023-04 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://modelscope.cn/models/damo/ChatPLUG-3.7B/summary) | [ChatPLUG](https://github.com/X-PLUG/ChatPLUG)![Star](https://img.shields.io/github/stars/X-PLUG/ChatPLUG.svg?style=social&label=Star) |            [é˜¿é‡Œå·´å·´](https://github.com/X-PLUG)             |  ED  |        [Paper](https://arxiv.org/pdf/2304.07849.pdf)         |\n|      Chinese-Alpaca      |     13B     | 2023-04 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/ziqingyang/chinese-alpaca-lora-13b) | [Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca)![Star](https://img.shields.io/github/stars/ymcui/Chinese-LLaMA-Alpaca.svg?style=social&label=Star) |            [Yiming Cui](https://github.com/ymcui)            |  CD  |                                                              |\n|       BELLE-LLAMA        |     13B     | 2023-04 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/BelleGroup/BELLE-LLaMA-EXT-13B) | [BELLE](https://github.com/LianjiaTech/BELLE)![Star](https://img.shields.io/github/stars/LianjiaTech/BELLE.svg?style=social&label=Star) |            [è´å£³](https://github.com/LianjiaTech)            |  CD  |                                                              |\n|       LLaMA-tuned        | 7/13/<br/>33/65B | 2023-04 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://drive.google.com/file/d/1x5JLae3akVkfFeDhSe3TEyUbPn_GNFyb/view?usp=share_link) | [LMFlow](https://github.com/OptimalScale/LMFlow)![Star](https://img.shields.io/github/stars/OptimalScale/LMFlow.svg?style=social&label=Star) |       [é¦™æ¸¯ç§‘æŠ€å¤§å­¦](https://github.com/OptimalScale)        |  CD  |                                                              |\n|      Chinese-Vicuna      |    7/13B    | 2023-03 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/Chinese-Vicuna/Chinese-Vicuna-lora-13b-belle-and-guanaco) | [Chinese-Vicuna](https://github.com/Facico/Chinese-Vicuna)![Star](https://img.shields.io/github/stars/Facico/Chinese-Vicuna.svg?style=social&label=Star) |             [Facico](https://github.com/Facico)              |  CD  |                                                              |\n|       ChatYuan-V2        |    0.7B     | 2023-03 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/ClueAI/ChatYuan-large-v2/tree/main) | [ChatYuan](https://github.com/clue-ai/ChatYuan)![Star](https://img.shields.io/github/stars/clue-ai/ChatYuan.svg?style=social&label=Star) |            [å…ƒè¯­æ™ºèƒ½](https://github.com/clue-ai)            |  ED  |                                                              |\n|      Chinese-Alpaca      |     7B      | 2023-03 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/ziqingyang/chinese-alpaca-lora-7b) | [Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca)![Star](https://img.shields.io/github/stars/ymcui/Chinese-LLaMA-Alpaca.svg?style=social&label=Star) |            [Yiming Cui](https://github.com/ymcui)            |  CD  |                                                              |\n|          Luotuo          |     7B      | 2023-03 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/silk-road/luotuo-lora-7b-0.3)  | [Chinese-alpaca-lora](https://github.com/LC1332/Chinese-alpaca-lora) |                         åä¸­å¸ˆèŒƒå¤§å­¦                         |  CD  |                                                              |\n|       BELLE-LLAMA        |     7B      | 2023-03 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/BelleGroup/BELLE-LLaMA-EXT-7B) | [BELLE](https://github.com/LianjiaTech/BELLE)![Star](https://img.shields.io/github/stars/LianjiaTech/BELLE.svg?style=social&label=Star) |            [è´å£³](https://github.com/LianjiaTech)            |  CD  |                                                              |\n|         ChatGLM          |     6B      | 2023-03 | ä¸­è‹± | é€šç”¨ |       [[ğŸ¤—HF\\]](https://huggingface.co/THUDM/chatglm-6b)        | [ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B)![Star](https://img.shields.io/github/stars/THUDM/ChatGLM-6B.svg?style=social&label=Star) |             [æ¸…åå¤§å­¦](https://github.com/THUDM)             |  ND  |                                                              |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n## Domain-ChatLLM\n\n> å¼€æºçš„å‚ç›´é¢†åŸŸå¯¹è¯å¤§æ¨¡å‹\n\n|           æ¨¡å‹           |  å¤§å°   | æ—¶é—´    | è¯­è¨€ |     é¢†åŸŸ     |                             ä¸‹è½½                             |                           é¡¹ç›®åœ°å€                           |                       æœºæ„/ä¸ªäºº                        | æ¶æ„ |                             æ–‡çŒ®                             |\n| :----------------------: | :-----: | ------- | :--: | :----------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------: | :--: | :----------------------------------------------------------: |\n|   Qwen-coder-2.5   | 0.5/1.5/14/32B | 2024-11 | ä¸­è‹± | ä»£ç  | [ğŸ¤—HF](https://huggingface.co/collections/Qwen/qwen25-coder-66eaa22e6f99801bf65b0c2f) |   [Qwen2.5-Coder](https://github.com/QwenLM/Qwen2.5-Coder)   |        [QwenLM](https://github.com/QwenLM)        |  CD  | [Paper](https://arxiv.org/abs/2409.12186) |\n| OpenCoder-Instruct |     1.5/8B     | 2024-11 | ä¸­è‹± | ä»£ç  | [ğŸ¤—HF](https://huggingface.co/collections/infly/opencoder-672cec44bbb86c39910fb55e) | [OpenCoder-llm](https://github.com/OpenCoder-llm/OpenCoder-llm) | [OpenCoder-llm](https://github.com/OpenCoder-llm) |  CD  | [Paper](https://arxiv.org/abs/2411.04905) |\n| ç ç®— | 2.7B | 2024-09 | ä¸­è‹± | ä»£ç  | [ğŸ¤—HF](https://huggingface.co/HIT-SCIR/Abacus) | [Abacus](https://github.com/HIT-SCIR/Abacus) | [HIT-SCIR](https://github.com/HIT-SCIR) |  CD  |      |\n| Qwen-2.5-code |        1.5/7B         | 2024-09 | ä¸­è‹± | ä»£ç  | [ğŸ¤—HF](https://huggingface.co/collections/Qwen/qwen25-coder-66eaa22e6f99801bf65b0c2f) | [Qwen2.5](https://github.com/QwenLM/Qwen2.5) | [QwenLM](https://github.com/QwenLM) |  CD  | [Blog](https://qwenlm.github.io/blog/qwen2.5/) |      |\n| Qwen-2.5-math |       1.5/7/72B       | 2024-09 | ä¸­è‹± | æ•°å­¦ | [ğŸ¤—HF](https://huggingface.co/collections/Qwen/qwen25-math-66eaa240a1b7d5ee65f1da3e) | [Qwen2.5](https://github.com/QwenLM/Qwen2.5) | [QwenLM](https://github.com/QwenLM) |  CD  | [Blog](https://qwenlm.github.io/blog/qwen2.5/) |      |\n|   Yi-Coder    |  1.5/9B   | 2024-09 | ä¸­è‹± | ä»£ç  | [ğŸ¤— Hugging Face](https://huggingface.co/01-ai/Yi-Coder-9B-Chat) â€¢ [ğŸ¤– ModelScope](https://www.modelscope.cn/models/01ai/Yi-Coder-9B-Chat) â€¢ [ğŸŸ£ wisemodel](https://wisemodel.cn/models/01.AI/Yi-Coder-9B-Chat) |       [Yi-Coder](https://github.com/01-ai/Yi-Coder)       |       [01-ai](https://github.com/01-ai)       |  CD  | [Paper](https://arxiv.org/abs/2403.04652) [Blog](https://01-ai.github.io/blog.html?post=en/2024-09-05-A-Small-but-Mighty-LLM-for-Code.md) |\n| CodeGeeX4 |  9B  | 2024-07 | å¤šè¯­ | ä»£ç  | [ğŸ¤—HF](https://huggingface.co/THUDM/codegeex4-all-9b) | **[CodeGeeX4](https://github.com/THUDM/CodeGeeX4)** | [THUDM](https://github.com/THUDM) |      |        |\n| DeepSeek-Coder-V2 | A16B/236B | 2024-06 | ä¸­è‹± | ä»£ç  | [ğŸ¤—HF](https://huggingface.co/deepseek-ai) | [DeepSeek-V2](https://github.com/deepseek-ai/DeepSeek-V2) | [deepseek-ai](https://github.com/deepseek-ai) | MoE  | [Paper](https://github.com/deepseek-ai/DeepSeek-V2/blob/main/deepseek-v2-tech-report.pdf) |\n|  AutoCoder  |   6.7/33B    | 2024-06 |  /   | ä»£ç  |    [ğŸ¤—HF](https://huggingface.co/Bin12345/AutoCoder)    |  [AutoCoder](https://github.com/bin123apple/AutoCoder)  | [Bin Lei](https://huggingface.co/Bin12345) |  CD  |          [Paper](https://arxiv.org/abs/2405.14906)           |\n| Codestral | 22B  | 2024-05 |  /   | ä»£ç  | [ğŸ¤—HF](https://hf-mirror.com/mistralai) |    /     | [mistralai](https://github.com/mistralai) |  /   | [Blog](https://mistral.ai/news/codestral/) |\n| CodeQwen1.5-Chat | 7B | 2024-04 | ä¸­è‹± | ä»£ç  | [ğŸ¤—HF](https://hf-mirror.com/Qwen/CodeQwen1.5-7B-Chat) | **[Qwen1.5](https://github.com/QwenLM/Qwen1.5)** |[Qwen](https://github.com/QwenLM)|CD|[Blog](https://qwenlm.github.io/blog/codeqwen1.5/)|\n| codegemma | 2/7B | 2024-04 | å¤šè¯­ | ä»£ç  | [ğŸ¤—HF](https://huggingface.co/google/codegemma-7b) | / |[Google](https://huggingface.co/google)|||\n| WaveCoder | 6.7B | 2024-04 | å¤šè¯­ | ä»£ç  | [ğŸ¤—HF](https://huggingface.co/microsoft/wavecoder-ds-6.7b) | [WaveCoder](https://github.com/microsoft/WaveCoder) |[microsoft](https://huggingface.co/microsoft)||[Paper](https://arxiv.org/abs/2312.14187)|\n| ChemDFM | 13B | 2024-03 | ä¸­è‹± | åŒ–å­¦ | [ğŸ¤—HF](https://huggingface.co/OpenDFM) | / | [OpenDFM](https://huggingface.co/OpenDFM) | CD | [Paper](https://arxiv.org/abs/2401.14818) |\n| starcoder2 | 3/7/15B | 2024-02 | ä¸­è‹± | ä»£ç  | [ğŸ¤—HF](https://huggingface.co/bigcode) | [starcoder2](https://github.com/bigcode-project/starcoder2) | [bigcode-project](https://github.com/bigcode-project) | CD | [Paper](https://drive.google.com/file/d/17iGn3c-sYNiLyRSY-A85QOzgzGnGiVI3/view) |\n| TuringMM-Chat | 34B | 2024-02 | ä¸­è‹± | æ•™è‚² | [ğŸ¤—HuggingFace](https://huggingface.co/lightyear-turing/TuringMM-34B-Chat) [ğŸ¤–ModelScope](https://modelscope.cn/models/lightyearturing/TuringMM-34B-Chat/summary) | / | [å…‰å¹´æ— é™](https://modelscope.cn/models/lightyearturing/TuringMM-34B-Chat/summary) | CD |  |\n| deepseek-moe | 16B | 2024-01 | ä¸­è‹± | ä»£ç  | [[ğŸ¤—HF\\]](https://huggingface.co/deepseek-ai) | [DeepSeekMoE](https://github.com/deepseek-ai/DeepSeek-MoE)![Star](https://img.shields.io/github/stars/deepseek-ai/DeepSeek-MoE.svg?style=social&label=Star) | [DeepSeek](https://github.com/deepseek-ai) | CD-MOE |  |\n| Code Millenials | 1/3/<br/>13/34B | 2023-01 | å¤šè¯­ | ä»£ç  | [[ğŸ¤—HF\\]](https://huggingface.co/budecosystem) | [code-millenials](https://github.com/BudEcosystem/code-millenials)![Star](https://img.shields.io/github/stars/BudEcosystem/code-millenials.svg?style=social&label=Star) | [BudEcosystem](https://github.com/BudEcosystem) | CD |  |\n| WizardCoder | 15/33B | 2024-01 | å¤šè¯­ | ä»£ç  | [[ğŸ¤—HF\\]](https://hf-mirror.com/WizardLM) | [WizardLM](https://github.com/nlpxucan/WizardLM)![Star](https://img.shields.io/github/stars/nlpxucan/WizardLM.svg?style=social&label=Star) | [operatorx](https://github.com/nlpxucan) |  CD  | [Paper](https://arxiv.org/abs/2306.08568) |\n| DeepSeek-Coder | 1/7/33B | 2023-11 | ä¸­è‹± | ä»£ç  | [[ğŸ¤—HF\\]](https://huggingface.co/deepseek-ai) | [DeepSeek-Coder](https://github.com/deepseek-ai/DeepSeek-Coder)![Star](https://img.shields.io/github/stars/deepseek-ai/DeepSeek-Coder.svg?style=social&label=Star) | [deepseek-ai](https://github.com/deepseek-ai) |  | [Blog](https://mp.weixin.qq.com/s/BPW-kMeQNmVPpgvTlbXU1A) |\n| Phind | 34B | 2023-10 | å¤šè¯­ | ä»£ç  | [[ğŸ¤—HF\\]](https://huggingface.co/Phind) | / | [Phind](Phind) | CD | [Blog](https://www.phind.com/blog/phind-model-beats-gpt4-fast) [zh](https://mp.weixin.qq.com/s/fSVPRjNpWPVrLVA59PrIBA) |\n| Tongyi-Finance-Chat | 14B | 2023-11 | ä¸­æ–‡ | é‡‘è | [ModelScope](https://modelscope.cn/models/TongyiFinance/Tongyi-Finance-14B-Chat/summary) | [é€šä¹‰é‡‘è-14B-Chat](https://modelscope.cn/models/TongyiFinance/Tongyi-Finance-14B-Chat/summary) | [é€šä¹‰é‡‘èå¤§æ¨¡å‹](https://modelscope.cn/organization/TongyiFinance) | CD |  |\n| Skywork-math | 13B | 2023-10 | ä¸­æ–‡ | æ•°å­¦ | [[ğŸ¤—HF\\]](https://huggingface.co/Skywork) | [Skywork](https://github.com/SkyworkAI/Skywork)![Star](https://img.shields.io/github/stars/SkyworkAI/Skywork.svg?style=social&label=Star) | [SkyworkAI](https://github.com/SkyworkAI) | CD | [Paper](https://arxiv.org/abs/2310.16713) |\n| XuanYuan-Chat | 70B | 2023-10 | ä¸­è‹± | é‡‘è | [[ğŸ¤—HF\\]](https://huggingface.co/Duxiaoman-DI/XuanYuan-70B-Chat) | [XuanYuan](https://github.com/Duxiaoman-DI/XuanYuan)![Star](https://img.shields.io/github/stars/Duxiaoman-DI/XuanYuan.svg?style=social&label=Star) | [Duxiaomanåº¦å°æ»¡](https://github.com/Duxiaoman-DI) | CD |  |\n| zhilu | 13B | 2023-10 | ä¸­è‹± | é‡‘è | [[ğŸ¤—HF\\]](https://huggingface.co/SYSU-MUCFC-FinTech-Research-Center) | / | [SYSU-MUCFC-FinTech-Research-Center](https://huggingface.co/SYSU-MUCFC-FinTech-Research-Center) | CD |  |\n| TestGPT | 7B | 2023-10 | ä¸­æ–‡ | æµ‹è¯• | [[ğŸ¤—HF\\]](https://huggingface.co/codefuse-ai/TestGPT-7B) | [Test-Agent](https://github.com/codefuse-ai/Test-Agent)![Star](https://img.shields.io/github/stars/codefuse-ai/Test-Agent.svg?style=social&label=Star) | [codefuse-ai](https://github.com/codefuse-ai) | CD |  |\n| cross | 7/13B | 2023-10 | å¤šè¯­ | æ•°å­¦ | [[ğŸ¤—HF\\]](https://huggingface.co/Mathoctopus) | / | [Mathoctopus](https://huggingface.co/Mathoctopus) | CD |  |\n| CodeFuse | 13/14/<br/>15/34B | 2023-10 | ä¸­æ–‡ | ä»£ç  | [[ğŸ¤—HF\\]](https://huggingface.co/codefuse-ai) | [MFTCoder](https://github.com/codefuse-ai/MFTCoder)![Star](https://img.shields.io/github/stars/codefuse-ai/MFTCoder.svg?style=social&label=Star) | [codefuse-ai](https://github.com/codefuse-ai) | CD |  |\n| Taiyi | 7B | 2023-10 | ä¸­è‹± | åŒ»å­¦ | [[ğŸ¤—HF\\]](https://huggingface.co/DUTIR-BioNLP/Taiyi-LLM) | [Taiyi-LLM](https://github.com/DUTIR-BioNLP/Taiyi-LLM)![Star](https://img.shields.io/github/stars/DUTIR-BioNLP/Taiyi-LLM.svg?style=social&label=Star) | [DUTIR-BioNLP](https://github.com/DUTIR-BioNLP) | CD |  |\n| CodeShell-chat | 7B | 2023-10 | ä¸­è‹± | ä»£ç  | [[ğŸ¤—HF\\]](https://huggingface.co/WisdomShell/CodeShell-7B-Chat) | [codeshell](https://github.com/WisdomShell/codeshell)![Star](https://img.shields.io/github/stars/WisdomShell/codeshell.svg?style=social&label=Star) | [WisdomShell](https://github.com/WisdomShell) | CD |  |\n| DISC-LawLLM | 13B | 2023-09 | ä¸­æ–‡ | æ³•å¾‹ | [[ğŸ¤—HF\\]](https://huggingface.co/ShengbinYue/DISC-LawLLM) | / | [ShengbinYue](https://huggingface.co/ShengbinYue) | CD | [Report](https://arxiv.org/abs/2309.11325) |\n| WiNGPT-chat | 7B | 2023-09 | ä¸­æ–‡ | åŒ»å­¦ | [[ğŸ¤—HF\\]](https://huggingface.co/winninghealth/WiNGPT2-7B-Chat) | [WiNGPT2](https://github.com/winninghealth/WiNGPT2)![Star](https://img.shields.io/github/stars/winninghealth/WiNGPT2.svg?style=social&label=Star) | [Winning Health AI Research](https://github.com/winninghealth) | CD |  |\n| ziya-coding | 15/34B | 2023-09 | ä¸­è‹± | ä»£ç  | [[ğŸ¤—HF\\]](https://huggingface.co/IDEA-CCNL/Ziya-Coding-34B-v1.0) | [Fengshenbang-LM](https://github.com/IDEA-CCNL/Fengshenbang-LM) |          [IDEAç ”ç©¶é™¢](https://github.com/IDEA-CCNL)          | CD |  |\n| AgriGPT | 6/13b | 2023-09 | ä¸­æ–‡ | å†œä¸š | [[ğŸ¤—HF\\]](https://huggingface.co/AgriGPTs/AgriGPT-13B) | [AgriGPTs](https://github.com/AgriGPTs/AgriGPTs)![Star](https://img.shields.io/github/stars/AgriGPTs/AgriGPTs.svg?style=social&label=Star) | [AgriGPTs](https://github.com/AgriGPTs) |  |  |\n| XuanYuan-chat | 70B  | 2023-09 | ä¸­æ–‡ | é‡‘è | [TODO]() | [XuanYuan](https://github.com/Duxiaoman-DI/XuanYuan) | [åº¦å°æ»¡](https://github.com/Duxiaoman-DI) |  CD  | [Report](https://github.com/Duxiaoman-DI/XuanYuan/blob/main/xuanyuan_70b_report.md) |\n| å¤«å­â€¢æ˜å¯Ÿ | 6B | 2023-09 | ä¸­æ–‡ | å¸æ³• | [[ğŸ¤—HF\\]](https://huggingface.co/SDUIRLab/fuzi.mingcha-v1.0) | [fuzi.mingcha](https://github.com/irlab-sdu/fuzi.mingcha)![Star](https://img.shields.io/github/stars/irlab-sdu/fuzi.mingcha.svg?style=social&label=Star) | [å±±ä¸œå¤§å­¦](https://github.com/irlab-sdu) | ND |  |\n| ä»²æ™¯ | 13B | 2023-09 | ä¸­æ–‡ | åŒ»å­¦ | [[ğŸ¤—HF\\]](https://huggingface.co/Suprit) | [Zhongjing](https://github.com/SupritYoung/Zhongjing)![Star](https://img.shields.io/github/stars/SupritYoung/Zhongjing.svg?style=social&label=Star) | [Songhua Yang](https://github.com/SupritYoung) | CD | [Paper](https://arxiv.org/abs/2308.03549) |\n| CodeFuse | 13/34B | 2023-09 | ä¸­è‹± | ä»£ç  | [[ğŸ¤—HF\\]](https://huggingface.co/codefuse-ai/CodeFuse-13B) | [MFTCoder](https://github.com/codefuse-ai/MFTCoder)![Star](https://img.shields.io/github/stars/codefuse-ai/MFTCoder.svg?style=social&label=Star) | [codefuse-ai](https://github.com/codefuse-ai) | CD |  |\n| EcomGPT | 7B | 2023-09 | ä¸­è‹± | ç”µå•† | [TODO]() | [EcomGPT](https://github.com/Alibaba-NLP/EcomGPT)![Star](https://img.shields.io/github/stars/Alibaba-NLP/EcomGPT.svg?style=social&label=Star) | [Alibaba](https://github.com/Alibaba-NLP) |  |  |\n| DISC-MedLLM | 13B | 2023-08 | ä¸­æ–‡ | åŒ»ç–— | [[ğŸ¤—HF\\]](https://huggingface.co/Flmc/DISC-MedLLM) | [DISC-MedLLM](https://github.com/FudanDISC/DISC-MedLLM)![Star](https://img.shields.io/github/stars/FudanDISC/DISC-MedLLM.svg?style=social&label=Star) | [FudanDISC](https://github.com/FudanDISC) | CD | [Paper](https://arxiv.org/abs/2308.14346) |\n| K2 | 7B | 2023-08 | ä¸­è‹± | ç§‘å­¦ | [[ğŸ¤—HF\\]](https://huggingface.co/daven3/k2_fp_delta) | [k2](https://github.com/davendw49/k2)![Star](https://img.shields.io/github/stars/davendw49/k2.svg?style=social&label=Star) | [daven](https://github.com/davendw49) | CD |  |\n| CodeLLAma | 7/13/34B | 2023-08 | å¤šè¯­ | ä»£ç  | [[ğŸ¤—HF\\]](https://huggingface.co/codellama) | [codellama](https://github.com/facebookresearch/codellama)![Star](https://img.shields.io/github/stars/facebookresearch/codellama.svg?style=social&label=Star) | [Meta Research](https://github.com/facebookresearch) | CD | [Paper](https://arxiv.org/abs/2308.12950) |\n| sqlcoder | 15B | 2023-08 | ä¸­è‹± | ä»£ç  | [[ğŸ¤—HF\\]](https://huggingface.co/defog/sqlcoder) | [sqlcoder](https://github.com/defog-ai/sqlcoder)![Star](https://img.shields.io/github/stars/defog-ai/sqlcoder.svg?style=social&label=Star) | [Defog.ai](https://github.com/defog-ai) | CD |  |\n| æ™ºæµ·-å½•é—® |  7B  | 2023-08 | ä¸­æ–‡ | æ³•å¾‹ | [[ğŸ¤—HF\\]](https://pan.baidu.com/s/16lwM2rPnSq9u-UbtWbZgig) | [wisdomInterrogatory](https://github.com/zhihaiLLM/wisdomInterrogatory)![Star](https://img.shields.io/github/stars/zhihaiLLM/wisdomInterrogatory.svg?style=social&label=Star) | [zhihaiLLM](https://github.com/zhihaiLLM) |  CD  |      |\n| WizardMath-V1.0 | 7/13/70B | 2023-08 | å¤šè¯­ | æ•°å­¦ | [[ğŸ¤—HF\\]](https://huggingface.co/WizardLM/WizardMath-7B-V1.0) | [WizardLM](https://github.com/nlpxucan/WizardLM)![Star](https://img.shields.io/github/stars/nlpxucan/WizardLM.svg?style=social&label=Star) | [operatorx](https://github.com/nlpxucan) | CD |  |\n| QiaoBan | 7B | 2023-08 | ä¸­æ–‡ | æƒ…æ„Ÿ | [[ğŸ¤—HF\\]](https://huggingface.co/tomxyz/qiaoban_bc) | [QiaoBen](https://github.com/HIT-SCIR-SC/QiaoBan)![Star](https://img.shields.io/github/stars/HIT-SCIR-SC/QiaoBan.svg?style=social&label=Star) | [å“ˆå°”æ»¨å·¥ä¸šå¤§å­¦](https://github.com/HIT-SCIR-SC) |  |  |\n| HuangDi | 13B | 2023-08 | ä¸­æ–‡ | ä¸­åŒ» | [[ğŸ¤—HF\\]](https://pan.baidu.com/s/1Mzlk5FREpTPa4M7KnMooqQ?pwd=erit) | [HuangDI](https://github.com/Zlasejd/HuangDI)![Star](https://img.shields.io/github/stars/Zlasejd/HuangDI.svg?style=social&label=Star) | [Zlasejd](https://github.com/Zlasejd) | CD |  |\n| ZhongJing |  | 2023-08 | ä¸­æ–‡ | ä¸­åŒ» | [TODO]() | [CMLM-ZhongJing](https://github.com/pariskang/CMLM-ZhongJing)![Star](https://img.shields.io/github/stars/pariskang/CMLM-ZhongJing.svg?style=social&label=Star) | [å¤æ—¦å¤§å­¦](pariskang) |  |  |\n| TCMLLM | 6B | 2023-08 | ä¸­æ–‡ | ä¸­åŒ» | [[ğŸ¤—HF\\]](https://pan.baidu.com/s/1QFx-206Ww9Xt-7_Z0RF85g) | [TCMLLM](https://github.com/2020MEAI/TCMLLM)![Star](https://img.shields.io/github/stars/2020MEAI/TCMLLM.svg?style=social&label=Star) | [2020MEAI](https://github.com/2020MEAI) | ND |  |\n| AutoAudit | 7B | 2023-07 | ä¸­æ–‡ | å®‰å…¨ | [[ğŸ¤—HF\\]](https://github.com/ddzipp/AutoAudit/blob/main) | [AutoAudit](https://github.com/ddzipp/AutoAudit)![Star](https://img.shields.io/github/stars/ddzipp/AutoAudit.svg?style=social&label=Star) | [Jiaying Li](https://github.com/ddzipp) | CD |  |\n| Lychee | 10B | 2023-07 | ä¸­æ–‡ | æ³•å¾‹ | [[ğŸ¤—HF\\]](https://huggingface.co/law-llm/law-glm-10b) | [lychee_law](https://github.com/davidpig/lychee_law)![Star](https://img.shields.io/github/stars/davidpig/lychee_law.svg?style=social&label=Star) | [davidpig](https://github.com/davidpig) | ND |  |\n| IvyGPT | 6B | 2023-07 | ä¸­æ–‡ | åŒ»å­¦ | [[ğŸ¤—HF\\]](https://huggingface.co/wangrongsheng/IvyGPT-35) | [IvyGPT](https://github.com/WangRongsheng/IvyGPT)![Star](https://img.shields.io/github/stars/WangRongsheng/IvyGPT.svg?style=social&label=Star) | [WangRongsheng](https://github.com/WangRongsheng) |  |  |\n| MING | 7B | 2023-07 | ä¸­æ–‡ | åŒ»å­¦ | [[ğŸ¤—HF\\]](https://huggingface.co/BlueZeros/MING-7B) | [MING](https://github.com/MediaBrain-SJTU/MING)![Star](https://img.shields.io/github/stars/MediaBrain-SJTU/MING.svg?style=social&label=Star) | [ä¸Šæµ·äº¤é€šå¤§å­¦](https://github.com/MediaBrain-SJTU) | CD |  |\n| Mozi | 7B | 2023-07 | ä¸­è‹± | ç§‘æŠ€ | [[ğŸ¤—HF\\]](https://huggingface.co/DataHammer/mozi_llama_7b) | [science-llm](https://github.com/gmftbyGMFTBY/science-llm)![Star](https://img.shields.io/github/stars/gmftbyGMFTBY/science-llm.svg?style=social&label=Star) | [GMFTBY](https://github.com/gmftbyGMFTBY) | CD |  |\n| StarGLM | 6B | 2023-07 | ä¸­æ–‡ | å¤©æ–‡ | [[ğŸ¤—HF\\]](https://github.com/Yu-Yang-Li/StarGLM) | [StarGLM](https://github.com/Yu-Yang-Li/StarGLM)![Star](https://img.shields.io/github/stars/Yu-Yang-Li/StarGLM.svg?style=social&label=Star) | [LI YUYANG](https://github.com/Yu-Yang-Li) | ND |  |\n| TransGPT | 7B | 2023-07 | ä¸­è‹± | äº¤é€š | [[ğŸ¤—HF\\]](https://huggingface.co/DUOMO-Lab/TransGPT-v0) | [TransGPT](https://github.com/DUOMO/TransGPT)![Star](https://img.shields.io/github/stars/DUOMO/TransGPT.svg?style=social&label=Star) | [åŒ—äº¬äº¤é€šå¤§å­¦](https://github.com/DUOMO) | CD |  |\n| CodeGeeX2 | 6B | 2023-07 | ä¸­è‹± | ä»£ç  | [[ğŸ¤—HF\\]](https://huggingface.co/THUDM/codegeex2-6b) | [CodeGeeX2](https://github.com/THUDM/CodeGeeX2)![Star](https://img.shields.io/github/stars/THUDM/CodeGeeX2.svg?style=social&label=Star) | [æ¸…åå¤§å­¦](https://github.com/THUDM) | ND |  |\n|           Yayi-llama2           |   7/13B    | 2023-07 | ä¸­è‹± | èˆ†æƒ… |    [[ğŸ¤—HF\\]](https://huggingface.co/wenge-research/yayi-7b-llama2)    | [Yayi](https://github.com/wenge-research/YaYi)![Star](https://img.shields.io/github/stars/wenge-research/YaYi.svg?style=social&label=Star) |     [ä¸­ç§‘é—»æ­Œ](https://github.com/wenge-research)      |  CD  | |\n| Ziya-Writing |   13B    | 2023-07 | ä¸­è‹± | å†™ä½œ | [[ğŸ¤—HF\\]](https://huggingface.co/IDEA-CCNL/Ziya-Writing-LLaMa-13B-v1) | [Fengshenbang-LM](https://github.com/IDEA-CCNL/Fengshenbang-LM) | [IDEAç ”ç©¶é™¢](https://github.com/IDEA-CCNL)  |  CD  |  |\n| MindChat | 13B | 2023-07 | ä¸­æ–‡ | å¿ƒç† | [[ğŸ¤—HF\\]](https://modelscope.cn/models/X-D-Lab/MindChat-Baichuan-13B/summary) | [MindChat](https://github.com/X-D-Lab/MindChat)![Star](https://img.shields.io/github/stars/X-D-Lab/MindChat.svg?style=social&label=Star) | [åä¸œç†å·¥å¤§å­¦](https://github.com/X-D-Lab) | CD |  |\n|     ShenNong-TCM-LLM     |   7B    | 2023-07 | ä¸­è‹± |     åŒ»å­¦     |                           [[ğŸ¤—HF\\]]()                           | [ShenNong-TCM-LLM](https://github.com/michael-wzhu/ShenNong-TCM-LLM)![Star](https://img.shields.io/github/stars/michael-wzhu/ShenNong-TCM-LLM.svg?style=social&label=Star) |    [michael-wzhu](https://github.com/michael-wzhu)     |  CD  |                                                              |\n|         ailawyer         |   13B   | 2023-07 | ä¸­è‹± |     æ³•å¾‹     |        [[ğŸ¤—HF\\]](https://huggingface.co/openkg/ailawyer)        | [JurisLMs](https://github.com/seudl/JurisLMs)![Star](https://img.shields.io/github/stars/seudl/JurisLMs.svg?style=social&label=Star) |        [openkg](https://huggingface.co/openkg)         |  CD  |                                                              |\n|     educhat      | 7B/13B  | 2023-06 | ä¸­è‹± |     æ•™è‚²     | [[ğŸ¤—HF\\]](https://huggingface.co/ecnu-icalk/educhat-sft-002-13b) | [EduChat](https://github.com/icalk-nlp/EduChat)![Star](https://img.shields.io/github/stars/icalk-nlp/EduChat.svg?style=social&label=Star) |      [åä¸œå¸ˆèŒƒå¤§å­¦](https://github.com/icalk-nlp)      |  CD  |                                                              |\n|        Sunsimiao         |   7B    | 2023-06 | ä¸­è‹± |     åŒ»å­¦     | [[ğŸ¤—HF\\]](https://modelscope.cn/models/AI-ModelScope/Sunsimiao/files) | [Sunsimiao](https://github.com/X-D-Lab/Sunsimiao)![Star](https://img.shields.io/github/stars/X-D-Lab/Sunsimiao.svg?style=social&label=Star) |       [åä¸œç†å·¥å¤§å­¦](https://github.com/X-D-Lab)       |  CD  |                                                              |\n|       Media LLaMA        |   7B    | 2023-06 | ä¸­æ–‡ |    åª’ä½“    | [baidu](https://pan.baidu.com/s/1tEuj0SvwJK4czQPCE6gI9w?pwd=onfo) | [Media-LLaMA](https://github.com/IMOSR/Media-LLaMA)![Star](https://img.shields.io/github/stars/IMOSR/Media-LLaMA.svg?style=social&label=Star) |       [æ™ºåª’å¼€æºç ”ç©¶é™¢](https://github.com/IMOSR)       |  CD  |                                                              |\n|          PULSE           |  7/14B  | 2023-06 | ä¸­æ–‡ |     åŒ»å­¦     | [[ğŸ¤—HF\\]](https://huggingface.co/OpenMEDLab/PULSE-7bv5) | [PULSE](https://github.com/openmedlab/PULSE)![Star](https://img.shields.io/github/stars/openmedlab/PULSE.svg?style=social&label=Star) |      [OpenMEDLab](https://github.com/OpenMEDLab)       |  CD  |                                                              |\n|         ChatLaw          | 13/33B  | 2023-06 | ä¸­æ–‡ |     æ³•å¾‹     | [[ğŸ¤—HF\\]](https://huggingface.co/JessyTsu1/ChatLaw-13B) | [ChatLaw](https://github.com/PKU-YuanGroup/ChatLaw)![Star](https://img.shields.io/github/stars/PKU-YuanGroup/ChatLaw.svg?style=social&label=Star) |      [åŒ—äº¬å¤§å­¦](https://github.com/PKU-YuanGroup)      |  CD  |                                                              |\n|          BaoLuo          |   6B    | 2023-06 | ä¸­æ–‡ |     æ³•å¾‹     | [[ğŸ¤—HF\\]](https://huggingface.co/xuanxuanzl/BaoLuo-LawAssistant-sftglm-6b) | [BaoLuo-LawAssisant](https://github.com/xuanxuanzl/BaoLuo-LawAssistant)![Star](https://img.shields.io/github/stars/xuanxuanzl/BaoLuo-LawAssistant.svg?style=social&label=Star) |         [LeiZi](https://github.com/xuanxuanzl)         |  ND  |                                                              |\n|         CoLLaMA          |   7B    | 2023-06 | ä¸­è‹± |     ä»£ç      |      [[ğŸ¤—HF\\]](https://huggingface.co/DaliahX/CoLLaMA-7b)       | [CoLLaMA](https://github.com/Denilah/CoLLaMA)![Star](https://img.shields.io/github/stars/Denilah/CoLLaMA.svg?style=social&label=Star) |         [Denilah](https://github.com/Denilah)          |  CD  |                                                              |\n|         TechGPT          |   7B    | 2023-06 | ä¸­è‹± |     æ•™è‚²     |       [[ğŸ¤—HF\\]](https://huggingface.co/neukg/TechGPT-7B)        | [TechGPT](https://github.com/neukg/TechGPT)![Star](https://img.shields.io/github/stars/neukg/TechGPT.svg?style=social&label=Star) |          [ä¸œåŒ—å¤§å­¦](https://github.com/neukg)          |  CD  |                                                              |\n|           Yayi           |   7B    | 2023-06 | ä¸­è‹± | èˆ†æƒ… |    [[ğŸ¤—HF\\]](https://huggingface.co/wenge-research/yayi-7b)     | [Yayi](https://github.com/wenge-research/YaYi)![Star](https://img.shields.io/github/stars/wenge-research/YaYi.svg?style=social&label=Star) |     [ä¸­ç§‘é—»æ­Œ](https://github.com/wenge-research)      |  CD  |                                                              |\n|          MeChat          |   6B    | 2023-06 | ä¸­æ–‡ |     åŒ»å­¦     |      [[ğŸ¤—HF\\]](https://huggingface.co/qiuhuachuan/MeChat)       | [smile](https://github.com/qiuhuachuan/smile)![Star](https://img.shields.io/github/stars/qiuhuachuan/smile.svg?style=social&label=Star) |     [qiuhuachuan](https://github.com/qiuhuachuan)      |  ND  |                                                              |\n|       ziya-medical       |   13b   | 2023-06 | ä¸­è‹± |     åŒ»å­¦     | [[ğŸ¤—HF\\]](https://huggingface.co/shibing624/ziya-llama-13b-medical-lora) | [MedicalGPT](https://github.com/shibing624/MedicalGPT)![Star](https://img.shields.io/github/stars/shibing624/MedicalGPT.svg?style=social&label=Star) |        [Ming Xu](https://github.com/shibing624)        |  CD  |                                                              |\n|          Taoli           |   7B    | 2023-06 | ä¸­è‹± |     æ•™è‚²     |                          [å¾…å¼€æº]()                          | [taoli](https://github.com/blcuicall/taoli)![Star](https://img.shields.io/github/stars/blcuicall/taoli.svg?style=social&label=Star) |      [åŒ—äº¬è¯­è¨€å¤§å­¦](https://github.com/blcuicall)      |  CD  |                                                              |\n|       Lawyer-llama       |   13B   | 2023-06 | ä¸­è‹± |     æ³•å¾‹     | [[ğŸ¤—HF\\]](https://huggingface.co/pkupie/lawyer-llama-13b-beta1.0) | [lawyer-llama](https://github.com/AndrewZhe/lawyer-llama)![Star](https://img.shields.io/github/stars/AndrewZhe/lawyer-llama.svg?style=social&label=Star) |      [Quzhe Huang](https://github.com/AndrewZhe)       |  CD  |                                                              |\n|       QiZhen-CaMA        |   13B   | 2023-06 | ä¸­è‹± |     åŒ»å­¦     | [[ğŸ¤—HF\\]](https://pan.baidu.com/s/1KQIF-dUsL7Nrj8UeNuFUiw?pwd=ivgg) | [QiZhenGPT](https://github.com/CMKRG/QiZhenGPT)![Star](https://img.shields.io/github/stars/CMKRG/QiZhenGPT.svg?style=social&label=Star) |          [æµ™æ±Ÿå¤§å­¦](https://github.com/CMKRG)          |  CD  |                                                              |\n|         æ‰é¹Š-2.0         |   6B    | 2023-06 | ä¸­æ–‡ |     åŒ»å­¦     |       [[ğŸ¤—HF\\]](https://huggingface.co/scutcyr/BianQue-2)       | [BianQue](https://github.com/scutcyr/BianQue)![Star](https://img.shields.io/github/stars/scutcyr/BianQue.svg?style=social&label=Star) |       [åå—ç†å·¥å¤§å­¦](https://github.com/scutcyr)       |  ND  |                                                              |\n|         SoulChat         |   6B    | 2023-06 | ä¸­æ–‡ |     å¿ƒç†     |       [[ğŸ¤—HF\\]](https://huggingface.co/scutcyr/SoulChat)        | [SoulChat](https://github.com/scutcyr/SoulChat)![Star](https://img.shields.io/github/stars/scutcyr/SoulChat.svg?style=social&label=Star) |       [åå—ç†å·¥å¤§å­¦](https://github.com/scutcyr)       |  ND  |                                                              |\n|          HanFei          |   7B    | 2023-05 | ä¸­æ–‡ |     æ³•å¾‹     | [baidu-d6t5](https://pan.baidu.com/s/1PkRXUo9sNRQmoXHcW7Aeeg?pwd=d6t5) | [HanFei](https://github.com/siat-nlp/HanFei)![Star](https://img.shields.io/github/stars/siat-nlp/HanFei.svg?style=social&label=Star) |  [ä¸­å›½ç§‘å­¦é™¢æ·±åœ³å…ˆè¿›é™¢](https://github.com/siat-nlp)   |  CD  |                                                              |\n|      QiZhen      |   6B    | 2023-05 | ä¸­è‹± |     åŒ»å­¦     | [[baidu\\]](https://pan.baidu.com/s/1KQIF-dUsL7Nrj8UeNuFUiw?pwd=ivgg) | [QiZhenGPT](https://github.com/CMKRG/QiZhenGPT)![Star](https://img.shields.io/github/stars/CMKRG/QiZhenGPT.svg?style=social&label=Star) |          [æµ™æ±Ÿå¤§å­¦](https://github.com/CMKRG)          |  CD  |                                                              |\n|     ChatMed-Consult      |   7B    | 2023-05 | ä¸­è‹± |     åŒ»å­¦     |  [[ğŸ¤—HF\\]](https://huggingface.co/michaelwzhu/ChatMed-Consult)  | [ChatMed](https://github.com/michael-wzhu/ChatMed)![Star](https://img.shields.io/github/stars/michael-wzhu/ChatMed.svg?style=social&label=Star) |    [michael-wzhu](https://github.com/michael-wzhu)     |  CD  |                                                              |\n|      LaWGPT-beta1.1      |   7B    | 2023-05 | ä¸­è‹± |     æ³•å¾‹     |  [[ğŸ¤—HF\\]](https://huggingface.co/entity303/lawgpt-lora-7b-v2)  | [LawGPT](https://github.com/pengxiao-song/LaWGPT)![Star](https://img.shields.io/github/stars/pengxiao-song/LaWGPT.svg?style=social&label=Star) |   [Pengxiao Song](https://github.com/pengxiao-song)    |  CD  |                                                              |\n|        Cornucopia        |   7B    | 2023-05 | ä¸­è‹± |     é‡‘è     | [[ğŸ¤—HF\\]](https://huggingface.co/yuyangmu125/lora-llama-fin-Linly-zh) | [Cornucopia-LLaMA-Fin-Chinese](https://github.com/jerry1993-tech/Cornucopia-LLaMA-Fin-Chinese)![Star](https://img.shields.io/github/stars/jerry1993-tech/Cornucopia-LLaMA-Fin-Chinese.svg?style=social&label=Star) |     [yuyangmu](https://github.com/jerry1993-tech)      |  CD  |                                                              |\n|        HuatuoGPT         |   7B    | 2023-05 | ä¸­æ–‡ |     åŒ»å­¦     | [[ğŸ¤—HF\\]](https://huggingface.co/FreedomIntelligence/HuatuoGPT-v1) | [HuatuoGPT](https://github.com/FreedomIntelligence/HuatuoGPT) | [é¦™æ¸¯ä¸­æ–‡å¤§å­¦](https://github.com/FreedomIntelligence) |  CD  |        [Paper](https://arxiv.org/pdf/2305.15075.pdf)         |\n|         LexiLaw          |   6B    | 2023-05 | ä¸­æ–‡ |     æ³•å¾‹     |         [[ğŸ¤—HF\\]](https://github.com/CSHaitao/LexiLaw)          |        [LexiLaw](https://github.com/CSHaitao/LexiLaw)        |        [Haitao Li](https://github.com/CSHaitao)        |  ND  |          [Paper](https://arxiv.org/abs/2305.12002)           |\n|         XuanYuan         |  176B   | 2023-05 | ä¸­æ–‡ |     é‡‘è     |    [ç”³è¯·](https://huggingface.co/xyz-nlp/XuanYuan2.0)    | [XuanYuan](https://github.com/Duxiaoman-DI/XuanYuan)![Star](https://img.shields.io/github/stars/Duxiaoman-DI/XuanYuan.svg?style=social&label=Star) |       [åº¦å°æ»¡](https://github.com/Duxiaoman-DI)        |  CD  |          [Paper](https://arxiv.org/abs/2305.12002)           |\n|          LawGPT          |   6B    | 2023-05 | ä¸­æ–‡ |     æ³•å¾‹     |     [[ğŸ¤—HF\\]](https://github.com/LiuHC0428/LAW-GPT) | [LAW-GPT](https://github.com/LiuHC0428/LAW-GPT)![Star](https://img.shields.io/github/stars/LiuHC0428/LAW-GPT.svg?style=social&label=Star) |      [hongchengliu](https://github.com/LiuHC0428)      |  N   |                                                              |\n|         æ‰é¹Š-1.0         |  0.7B   | 2023-04 | ä¸­æ–‡ |     åŒ»å­¦     |      [[ğŸ¤—HF\\]](https://huggingface.co/scutcyr/BianQue-1.0)      |        [BianQue](https://github.com/scutcyr/BianQue)         |         [scutcyr](https://github.com/scutcyr)          |  ED  |                                                              |\n|       ChatGLM-Med        |   6B    | 2023-04 | ä¸­æ–‡ |     åŒ»å­¦     | [[ğŸ¤—HF\\]](https://drive.google.com/drive/folders/1ZQSN56DloRGQ-Qj7IwzY4jV3ZHKMe9Bc) | [Med-ChatGLM](https://github.com/SCIR-HI/Med-ChatGLM)![Star](https://img.shields.io/github/stars/SCIR-HI/Med-ChatGLM.svg?style=social&label=Star) |      [å“ˆå°”æ»¨å·¥ä¸šå¤§å­¦](https://github.com/SCIR-HI)      |  ED  |                                                              |\n|         BenTsao          |   7B    | 2023-04 | ä¸­æ–‡ |     åŒ»å­¦     | [[ğŸ¤—HF\\]](https://huggingface.co/thinksoso/lora-llama-med) | [Huatuo-Llama-Med-Chinese](https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese)![Star](https://img.shields.io/github/stars/SCIR-HI/Huatuo-Llama-Med-Chinese.svg?style=social&label=Star) |      [å“ˆå°”æ»¨å·¥ä¸šå¤§å­¦](https://github.com/SCIR-HI)      |  CD  |                                                              |\n|        DoctorGLM         |   6B    | 2023-04 | ä¸­æ–‡ |     åŒ»å­¦     |                          [TODO]()                          | [DoctorGLM](https://github.com/xionghonglin/DoctorGLM)![Star](https://img.shields.io/github/stars/xionghonglin/DoctorGLM.svg?style=social&label=Star) |    [xionghonglin](https://github.com/xionghonglin)     |  ND  |                                                              |\n|         Firefly          |   1/2/7B   | 2023-04 | ä¸­æ–‡ |     æ–‡åŒ–     | [[ğŸ¤—HF\\]](https://huggingface.co/YeungNLP/firefly-bloom-7b1-qlora-sft) | [Firefly](https://github.com/yangjianxin1/Firefly)![Star](https://img.shields.io/github/stars/yangjianxin1/Firefly.svg?style=social&label=Star) |    [Yang JianXin](https://github.com/yangjianxin1)     |  CD  |                                                              |\n|         ChatRWKV         |   7B    | 2023-01 | ä¸­è‹± |     å°è¯´     | [[ğŸ¤—HF\\]](https://huggingface.co/BlinkDL/rwkv-4-pile-7b/tree/main) | [ChatRWKV](https://github.com/BlinkDL/ChatRWKV)![Star](https://img.shields.io/github/stars/BlinkDL/ChatRWKV.svg?style=social&label=Star) |         [BlinkDL](https://github.com/BlinkDL)          | RNN  |        [Blog](https://zhuanlan.zhihu.com/p/609154637)        |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n## MultiModal-ChatLLM\n\n> æ”¶é›†åŒ…å«ä¸­æ–‡çš„å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼Œå…·å¤‡å¯¹è¯ç­‰åŠŸèƒ½ã€‚\n\n|           æ¨¡å‹           | å¤§å°  |  æ—¶é—´   |                           è¯­è¨€æ¨¡å‹                           |                          éè¯­è¨€æ¨¡å‹                          | è¯­è¨€ |   é¢†åŸŸ    |                             ä¸‹è½½                             |                           é¡¹ç›®åœ°å€                           |                        æœºæ„/ä¸ªäºº                         |                             æ–‡çŒ®                             |\n| :----------------------: | :---: | :-----: | :----------------------------------------------------------: | :----------------------------------------------------------: | :--: | :-------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :------------------------------------------------------: | :----------------------------------------------------------: |\n| QVQ-72B-Preview | 72B  | 2024-12 |    /     |    /     | ä¸­è‹± | æ–‡è§†å›¾ | [ğŸ¤— HF](https://huggingface.co/collections/Qwen/qvq-676448c820912236342b9888) | [Qwen2-VL](https://github.com/QwenLM/Qwen2-VL) | [QwenLM](https://github.com/QwenLM) | [Blog](https://qwenlm.github.io/zh/blog/qvq-72b-preview/) |\n| Megrez-3B-Omni |     3B     | 2024-12 | Megrez-3B-Instruct | SigLip-400M/Qwen2-Audio/whisper-large-v3 | ä¸­è‹± | æ–‡éŸ³å›¾ | [ğŸ¤— HF](https://huggingface.co/Infinigence/Megrez-3B-Omni) | [Infini-Megrez-Omni](https://github.com/infinigence/Infini-Megrez-Omni) | [infinigence](https://github.com/infinigence) |                                           |\n|  DeepSeek-VL2  | 1/2.8/4.5B | 2024-12 |         /          |                    /                     |      |  æ–‡å›¾  |  [ğŸ¤— HF](https://huggingface.co/deepseek-ai/deepseek-vl2)  | [DeepSeek-VL2](https://github.com/deepseek-ai/DeepSeek-VL2)  | [deepseek-ai](https://github.com/deepseek-ai) | [Paper](https://arxiv.org/abs/2412.10302) |\n| InternVL 2.5 | 2/4/8/26/38/78B | 2024-12 | Qwen-2.5 | InternVit | å¤šè¯­ | æ–‡å›¾ | [ğŸ¤— HF](https://huggingface.co/collections/OpenGVLab/internvl-25-673e1019b66e2218f68d7c1c) | [InternVL](https://github.com/OpenGVLab/InternVL) | [OpenGVLab](https://github.com/OpenGVLab) | [blog](https://internvl.github.io/blog/) |\n| Pixtral-Large-Instruct | 124B | 2024-11 | [Mistral-Large-Instruct-2407](https://huggingface.co/mistralai/Mistral-Large-Instruct-2407) | / | å¤šè¯­ | æ–‡å›¾ | [ğŸ¤— Huggingface](https://huggingface.co/mistralai/Pixtral-Large-Instruct-2411) | / | [mistralai](https://huggingface.co/mistralai) | [Pixtral Large blog post](https://mistral.ai/news/pixtral-large/) |\n| fish-agent | 3B | 2024-11 | Qwen-2.5 | / | å¤šè¯­ | æ–‡éŸ³ | [ğŸ¤— Huggingface](https://huggingface.co/fishaudio) | [fish-speech](https://github.com/fishaudio/fish-speech) | [fishaudio](https://github.com/fishaudio) |  |\n| GLM-4-Voice | 9B | 2024-10 | [GLM-4-9B](https://github.com/THUDM/GLM-4) | [Whisper](https://github.com/openai/whisper) | ä¸­è‹± | æ–‡éŸ³ | [ğŸ¤— Huggingface](https://huggingface.co/THUDM/glm-4-voice-9b) | [GLM-4-Voice](https://github.com/THUDM/GLM-4-Voice) | [THUDM](https://github.com/THUDM) |  |\n| Pangea | 7B | 2024-10 | [Qwen2-7B-Instruct](https://huggingface.co/Qwen/Qwen2-7B-Instruct) | [LLaVA-NeXT](https://github.com/LLaVA-VL/LLaVA-NeXT) | å¤šè¯­ | å›¾æ–‡ | [ğŸ¤—HF](https://huggingface.co/neulab/Pangea-7B) | [Pangea](https://github.com/neulab/Pangea) | [neulab](https://github.com/neulab) | [Paper](https://arxiv.org/abs/2410.16153) |\n| GOT-OCR-2.0 | / | 2024-09 | Qwen | / | ä¸­è‹± | å›¾æ–‡ | [ğŸ¤—HF](https://huggingface.co/stepfun-ai/GOT-OCR2_0) | [GOT-OCR2.0](https://github.com/Ucas-HaoranWei/GOT-OCR2.0) | [**StepFun-AI**](https://huggingface.co/stepfun-ai) | [Paper](https://arxiv.org/abs/2409.01704) |\n| Ovis-1.6 | 9B | 2024-09 | Gemma2-9B-It | Siglip-400M | ä¸­è‹± | å›¾æ–‡ | [ğŸ¤—](https://huggingface.co/AIDC-AI/Ovis1.6-Gemma2-9B) | [Ovis](https://github.com/AIDC-AI/Ovis) | [AIDC-AI](https://github.com/AIDC-AI) | [Paper](https://arxiv.org/abs/2405.20797) |\n| Qwen2-VL | 2/7/72B | 2024-08 | / | / | å¤šè¯­ | å›¾æ–‡è§† | [ğŸ¤—](https://huggingface.co/Qwen/Qwen2-VL-7B-Instruct) [ğŸ¤–](https://modelscope.cn/models/qwen/Qwen2-VL-7B-Instruct) | [Qwen2-VL](https://github.com/QwenLM/Qwen2-VL) | [QwenLM](https://github.com/QwenLM) |  |\n| CogVideoX | 2/5B | 2024-08 | / | / | ä¸­è‹± | æ–‡è§† | [ğŸ¤— link](https://huggingface.co/THUDM/CogVideoX-2b) | [CogVideo](https://github.com/THUDM/CogVideo) | [THUDM](https://github.com/THUDM) |  |\n| MiniCPM-V 2.6 | 8B | 2024-08 |  Qwen2-7B  | SigLip-400M | ä¸­è‹± | æ–‡å›¾è§† | [ğŸ¤— link](https://huggingface.co/openbmb/MiniCPM-V-2_6) | [MiniCPM-V](https://github.com/OpenBMB/MiniCPM-V) | [OpenBMB](https://github.com/OpenBMB) |  |\n| InternVL2 | 1/2/4/8/26/40/76B | 2024-07 |  Qwen2/internlm2/llama3  | [InternViT](https://huggingface.co/OpenGVLab/InternViT-6B-448px-V1-5) | ä¸­è‹± | æ–‡å›¾ | [ğŸ¤— link](https://huggingface.co/collections/OpenGVLab/internvl-20-667d3961ab5eb12c7ed1463e) [ğŸ¤– link](https://modelscope.cn/organization/OpenGVLab) | [InternVL](https://github.com/OpenGVLab/InternVL) | [OpenGVLab](https://github.com/OpenGVLab) | [report](https://arxiv.org/abs/2404.16821) |\n| Qwen2-Audio | 8.2B | 2024-07 |  Qwen2   | Whisper-large-V3 | ä¸­è‹± | æ–‡éŸ³ | [ğŸ¤—HF](https://huggingface.co/Qwen/Qwen-Audio) | [Qwen2-Audio](https://github.com/QwenLM/Qwen2-Audio) | [QwenLM](https://github.com/QwenLM) | [report](https://arxiv.org/abs/2407.10759) |\n| **Kolors** | / | 2024-07 | ChatGLM3-Base | / | ä¸­è‹± | æ–‡å›¾ | [ğŸ¤—HF](https://huggingface.co/Kwai-Kolors/Kolors) | [Kolors](https://github.com/Kwai-Kolors/Kolors) | [Kwai-Kolors](https://github.com/Kwai-Kolors) | [Paper](https://github.com/Kwai-Kolors/Kolors/blob/master/imgs/Kolors_paper.pdf) |\n| ChatTTS | / | 2024-06 | / | / | ä¸­è‹± | æ–‡éŸ³ | [ğŸ¤—HF](https://huggingface.co/2Noise/ChatTTS) | [ChatTTS](https://github.com/2noise/ChatTTS) | [2noise](https://github.com/2noise) | / |\n| GLM-4V | 9B | 2024-06 | GLM-4 | / | å¤šè¯­ | æ–‡å›¾ | [ğŸ¤—HF](https://huggingface.co/THUDM/glm-4v-9b) | [GLM-4](https://github.com/THUDM/GLM-4) | [THUDM](https://github.com/THUDM) | / |\n| HunyuanDiT | 1.5B | 2024-05 | multilingual T5 encoder | CLIP | ä¸­è‹± | æ–‡å›¾ | [ğŸ¤—](https://hf-mirror.com/Tencent-Hunyuan/HunyuanDiT) | **[HunyuanDiT](https://github.com/Tencent/HunyuanDiT)** | [Tencent](https://github.com/Tencent) | [Paper](https://arxiv.org/abs/2405.08748) |\n| **CogVLM2** |  | 2024-05 | Meta-Llama-3-8B-Instruct | / | ä¸­è‹± | æ–‡å›¾ | [ğŸ¤—](https://hf-mirror.com/THUDM/cogvlm2-llama3-chat-19B) | [CogVLM](https://github.com/THUDM/CogVLM) | [Skip to content](https://github.com/THUDM#start-of-content) |  |\n| 360VL | 8/70B | 2024-05 | LLama3 | CLIP-ViT | ä¸­è‹± | æ–‡å›¾ | [ğŸ¤—](https://hf-mirror.com/qihoo360) | [360VL](https://github.com/360CVGroup/360VL) | [360CVGroup](https://github.com/360CVGroup) |  |\n| **XVERSE-V** | 13B | 2024-05 | **XVERSE-13B-Chat** | **clip-vit-large-patch14-224** | ä¸­è‹± | æ–‡å›¾ | [ğŸ¤–](https://modelscope.cn/models/xverse/XVERSE-V-13B/summary) | [XVERSE-V-13B](https://github.com/xverse-ai/XVERSE-V-13B) | [xverse-ai](https://github.com/xverse-ai) |  |\n| MiniCPM-V 2.0 | 2.8B | 2024-04 | [MiniCPM-2.4B](https://github.com/OpenBMB/MiniCPM/) | SigLip-400M | ä¸­è‹± | æ–‡å›¾ | [ğŸ¤—](https://huggingface.co/openbmb/OmniLMM-12B/) [ğŸ¤–](http://120.92.209.146:8081/) | **[MiniCPM-V](https://github.com/OpenBMB/MiniCPM-V)** | [OpenBMB](https://github.com/OpenBMB) | [Blog](https://openbmb.vercel.app/minicpm-v-2) |\n| **Qwen-Audio** | 7B | 2024-03 | [Qwen-7B](https://github.com/QwenLM/Qwen) | [Whisper-large-v2](https://github.com/openai/whisper) | ä¸­è‹± | æ–‡éŸ³ | [ğŸ¤—HF](https://huggingface.co/Qwen/Qwen-Audio) | [Qwen-Audio](https://github.com/QwenLM/Qwen-Audio) ![Star](https://img.shields.io/github/stars/QwenLM/Qwen-Audio.svg?style=social&label=Star) | [Qwen](https://github.com/QwenLM) | [Paper](http://arxiv.org/abs/2311.07919) |\n| DeepSeek-VL | 1.3/7B | 2024-03 | DeepSeek | SigLip/SAM | ä¸­è‹± | å›¾æ–‡ | [ğŸ¤—HF](https://huggingface.co/deepseek-ai/deepseek-vl-7b-chat) | [DeepSeek-VL](https://github.com/deepseek-ai/DeepSeek-VL)![Star](https://img.shields.io/github/stars/deepseek-ai/DeepSeek-VL.svg?style=social&label=Star) | [deepseek-ai](https://github.com/deepseek-ai) | [Paper](https://arxiv.org/abs/2403.05525) |\n| **OmniLMM** | 3/12B | 2024-02 | MiniCPM | SigLip | ä¸­è‹± | å›¾æ–‡ | [ğŸ¤—HF](https://huggingface.co/openbmb/MiniCPM-V) | [OmniLMM](https://github.com/OpenBMB/OmniLMM)![Star](https://img.shields.io/github/stars/OpenBMB/OmniLMM.svg?style=social&label=Star) | [[OpenBMB](https://github.com/OpenBMB)](https://github.com/01-ai) |  |\n| **MiniCPM-V** | 3B | 2024-02 | MiniCPM-2.4B | SigLip-400M | ä¸­è‹± | å›¾æ–‡ | [ğŸ¤—HF](https://huggingface.co/openbmb/MiniCPM-V) | [OmniLMM](https://github.com/OpenBMB/OmniLMM)![Star](https://img.shields.io/github/stars/OpenBMB/OmniLMM.svg?style=social&label=Star) | [[OpenBMB](https://github.com/OpenBMB)](https://github.com/01-ai) |  |\n| Yi-VL | 6/34B | 2024-01 | Yi | [CLIP-VIT](https://huggingface.co/laion/CLIP-ViT-H-14-laion2B-s32B-b79K) | ä¸­è‹± | å›¾æ–‡ | [[ğŸ¤—HF\\]](https://huggingface.co/01-ai) | [Yi](https://github.com/01-ai/Yi)![Star](https://img.shields.io/github/stars/01-ai/Yi.svg?style=social&label=Star) | [01-ai](https://github.com/01-ai) |  |\n| Lyrics | 14B | 2023-12 | / | / | ä¸­è‹± | å›¾æ–‡ | [[ğŸ¤—HF\\]](https://huggingface.co/IDEA-CCNL/Ziya-Visual-Lyrics-14B) | [Fengshenbang-LM](https://github.com/IDEA-CCNL/Fengshenbang-LM) | [IDEAç ”ç©¶é™¢](https://github.com/IDEA-CCNL) |  |\n| Qwen-Audio | 7B | 2023-12 | [Qwen-7B](https://github.com/QwenLM/Qwen) | [Whisper-large-v2](https://github.com/openai/whisper) | ä¸­è‹± | æ–‡éŸ³ | [[ğŸ¤—HF\\]](https://huggingface.co/Qwen) | [Qwen-Audio](https://github.com/QwenLM/Qwen-Audio)![Star](https://img.shields.io/github/stars/QwenLM/Qwen-Audio.svg?style=social&label=Star) | [Qwen](https://github.com/QwenLM) | [Paper](http://arxiv.org/abs/2311.07919) |\n| SPHINX | 13B | 2023-10 | / | / | ä¸­è‹± | å›¾æ–‡ | [[ğŸ¤—HF\\]](https://huggingface.co/Alpha-VLLM/SPHINX) | [LLaMA2-Accessory](https://github.com/Alpha-VLLM/LLaMA2-Accessory)![Star](https://img.shields.io/github/stars/Alpha-VLLM/LLaMA2-Accessory.svg?style=social&label=Star) | [Alpha-VLLM](https://github.com/Alpha-VLLM) |  |\n| Skywork-MM | 13B | 2023-10 | / | / | ä¸­è‹± | å›¾æ–‡ | [[ğŸ¤—HF\\]](https://huggingface.co/Skywork) | [Skywork](https://github.com/SkyworkAI/Skywork) | [SkyworkAI](https://github.com/SkyworkAI) | [Paper](https://github.com/will-singularity/Skywork-MM/blob/main/skywork_mm.pdf) |\n| CogVLM | 7/14B | 2023-10 | Qwen | ViT | ä¸­è‹± | å›¾æ–‡ | [[ğŸ¤—HF\\]](https://huggingface.co/CausalLM) | / | [CausalLM](https://huggingface.co/CausalLM) |  |\n|           fuyu           |  8B   | 2023-10 |                              /                               |                              /                               | ä¸­è‹± |   å›¾æ–‡    |         [[ğŸ¤—HF\\]](https://huggingface.co/adept/fuyu-8b)         |                              /                               |      [Adept AI Labs](https://huggingface.co/adept)       |          [Blog](https://www.adept.ai/blog/fuyu-8b)           |\n|       Ziya-Visual        |  14B  | 2023-10 |                            LLaMA                             |                         InstructBLIP                         | ä¸­è‹± |   å›¾æ–‡    | [[ğŸ¤—HF\\]](https://huggingface.co/IDEA-CCNL/Ziya-Visual-14B-Chat) | [Fengshenbang-LM](https://github.com/IDEA-CCNL/Fengshenbang-LM)![Star](https://img.shields.io/github/stars/IDEA-CCNL/Fengshenbang-LM.svg?style=social&label=Star) |        [IDEAç ”ç©¶é™¢](https://github.com/IDEA-CCNL)        |          [Paper](https://arxiv.org/abs/2310.08166)           |\n|          CogVLM          |  17B  | 2023-10 |                         EVA2-CLIP-E                          |                         Vicuna-v1.5                          | ä¸­è‹± |   å›¾æ–‡    |                           [TODO]()                           | [CogVLM](https://github.com/THUDM/CogVLM)![Star](https://img.shields.io/github/stars/THUDM/CogVLM.svg?style=social&label=Star) |            [THUDM](https://github.com/THUDM)             | [Paper](https://github.com/THUDM/CogVLM/blob/main/assets/cogvlm-paper.pdf) |\n|         idefics          | 9/80B | 2023-10 |     [LLaMA](https://huggingface.co/huggyllama/llama-65b)     | [CLIP-ViT](https://huggingface.co/laion/CLIP-ViT-H-14-laion2B-s32B-b79K) | ä¸­è‹± |   å›¾æ–‡    |  [[ğŸ¤—HF\\]](https://huggingface.co/HuggingFaceM4/idefics-9b)   |                              /                               |  [HuggingFaceM4](https://huggingface.co/HuggingFaceM4)   | [log](https://github.com/huggingface/m4-logs/blob/master/memos/README.md) |\n|    InternLM-XComposer    |  7B   | 2023-10 |  [InternLM](https://github.com/InternLM/InternLM/tree/main)  |                           EVA-CLIP                           | ä¸­è‹± |   å›¾æ–‡    | [[ğŸ¤—HF\\]](https://huggingface.co/internlm/internlm-xcomposer-vl-7b) | [InternLM-XComposer](https://github.com/InternLM/InternLM-XComposer)![Star](https://img.shields.io/github/stars/InternLM/InternLM-XComposer.svg?style=social&label=Star) |         [InternLM](https://github.com/InternLM)          |        [Report](https://arxiv.org/pdf/2309.15112.pdf)        |\n|        WeMix-LLM         |  13B  | 2023-09 |                            LLama2                            |                              /                               | ä¸­è‹± |   å›¾æ–‡    | [[ğŸ¤—HF\\]](https://huggingface.co/Alpha-VLLM/WeMix-LLaMA2-13B-MM) | [WeMix-LLM](https://github.com/Alpha-VLLM/WeMix-LLM)![Star](https://img.shields.io/github/stars/Alpha-VLLM/WeMix-LLM.svg?style=social&label=Star) |       [Alpha-VLLM](https://github.com/Alpha-VLLM)        |                                                              |\n|          Vally           | 7/13B | 2023-08 |                  BelleGroup/BELLE-LLaMA-EXT                  |            OFA-Sys/chinese-clip-vit-large-patch14            | ä¸­è‹± |   å›¾æ–‡    | [[ğŸ¤—HF\\]](https://huggingface.co/Zhaoziwang/chinese_valley7b_v1) [[ğŸ¤—HF\\]](https://huggingface.co/Zhaoziwang/chinese_valley13b_v1) | [Valley](https://github.com/RupertLuo/Valley)![Star](https://img.shields.io/github/stars/RupertLuo/Valley.svg?style=social&label=Star) |          [ç½—ç‘ç’](https://github.com/RupertLuo)          |          [Paper](https://arxiv.org/abs/2306.07207)           |\n|         SALMONN          |   /   | 2023-08 |                              /                               |                              /                               | ä¸­è‹± |   è¯­éŸ³    |                           [TODO]()                           | [SALMONN](https://github.com/bytedance/SALMONN)![Star](https://img.shields.io/github/stars/bytedance/SALMONN.svg?style=social&label=Star) |        [Bytedance](https://github.com/bytedance)         |                                                              |\n|         IDEFICS          | 9/80B | 2023-08 |     [llama](https://huggingface.co/huggyllama/llama-65b)     | [CLIP-ViT](https://huggingface.co/laion/CLIP-ViT-H-14-laion2B-s32B-b79K) | ä¸­è‹± | å›¾æ–‡-é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/HuggingFaceM4/idefics-9b) | [m4-logs](https://github.com/huggingface/m4-logs)![Star](https://img.shields.io/github/stars/huggingface/m4-logs.svg?style=social&label=Star) |  [HuggingFaceM4](https://huggingface.co/HuggingFaceM4)   |      [Paper](https://huggingface.co/papers/2306.16527)       |\n|         Qwen-VL          |  7B   | 2023-08 |         [Qwen-7B](https://github.com/QwenLM/Qwen-7B)         | [Openclip ViT-bigG](https://github.com/mlfoundations/open_clip) | ä¸­è‹± |   é€šç”¨    |         [[ğŸ¤—HF\\]](https://huggingface.co/Qwen/Qwen-VL)          | [Qwen-VL](https://github.com/QwenLM/Qwen-VL)![Star](https://img.shields.io/github/stars/QwenLM/Qwen-VL.svg?style=social&label=Star) |           [é˜¿é‡Œäº‘](https://github.com/QwenLM)            |                                                              |\n|       Qwen-VL-chat       |  7B   | 2023-08 |         [Qwen-7B](https://github.com/QwenLM/Qwen-7B)         | [Openclip ViT-bigG](https://github.com/mlfoundations/open_clip) | ä¸­è‹± |   é€šç”¨    |       [[ğŸ¤—HF\\]](https://huggingface.co/Qwen/Qwen-VL-Chat)       | [Qwen-VL](https://github.com/QwenLM/Qwen-VL)![Star](https://img.shields.io/github/stars/QwenLM/Qwen-VL.svg?style=social&label=Star) |           [é˜¿é‡Œäº‘](https://github.com/QwenLM)            |                                                              |\n|          LLasM           |  7B   | 2023-07 | [Chinese-Llama2](https://github.com/LinkSoul-AI/Chinese-Llama-2-7b) |                       whisper-large-v2                       | ä¸­è‹± |   è¯­éŸ³    |    [[ğŸ¤—HF\\]](https://huggingface.co/LinkSoul/LLaSM-Cllama2)     | [LLaSM](https://github.com/LinkSoul-AI/LLaSM)![Star](https://img.shields.io/github/stars/LinkSoul-AI/LLaSM.svg?style=social&label=Star) |        [åŒ—äº¬çµç](https://github.com/LinkSoul-AI)        |                                                              |\n|      Chinese-LLaVA       |  7B   | 2023-07 | [Chinese-Llama2](https://github.com/LinkSoul-AI/Chinese-Llama-2-7b) |                           Clip-vit                           | ä¸­è‹± |   è§†è§‰    | [[ğŸ¤—HF\\]](https://huggingface.co/LinkSoul/Chinese-LLaVA-Cllama2) | [Chinese-LLaVA](https://github.com/LinkSoul-AI/Chinese-LLaVA)![Star](https://img.shields.io/github/stars/LinkSoul-AI/Chinese-LLaVA.svg?style=social&label=Star) |        [åŒ—äº¬çµç](https://github.com/LinkSoul-AI)        |                                                              |\n|        RemoteGLM         |  6B   | 2023-07 |                         VisualGLM-6B                         |                         VisualGLM-6B                         | ä¸­æ–‡ |   é¥æ„Ÿ    |                           [TODO]()                           | [RemoteGLM](https://github.com/lzw-lzw/RemoteGLM)![Star](https://img.shields.io/github/stars/lzw-lzw/RemoteGLM.svg?style=social&label=Star) |          [lzw-lzw](https://github.com/lzw-lzw)           |                                                              |\n|        VisualCLA         |  7B   | 2023-07 | [Chinese-Alpaca-Plus](https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/%E6%A8%A1%E5%9E%8B%E5%90%88%E5%B9%B6%E4%B8%8E%E8%BD%AC%E6%8D%A2) | [CLIP-ViT-L/14](https://huggingface.co/openai/clip-vit-large-patch14) | ä¸­æ–‡ |   è§†è§‰    | [[ğŸ¤—HF\\]](https://pan.baidu.com/s/1bBF5QHoZxHRnWeTPHL19CQ?pwd=xxbg) | [Visual-Chinese-LLaMA-Alpaca](https://github.com/airaria/Visual-Chinese-LLaMA-Alpaca)![Star](https://img.shields.io/github/stars/airaria/Visual-Chinese-LLaMA-Alpaca.svg?style=social&label=Star) |        [Ziqing Yang](https://github.com/airaria)         |                                                              |\n|          yuren           |  7B   | 2023-07 | [baichuan-7B](https://huggingface.co/baichuan-inc/baichuan-7B) | [CLIP](https://huggingface.co/laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K) | ä¸­è‹± |   è§†è§‰    |   [[ğŸ¤—HF\\]](https://huggingface.co/pleisto/yuren-baichuan-7b)   | [yuren-baichuan-7b](https://github.com/pleisto/yuren-baichuan-7b)![Star](https://img.shields.io/github/stars/pleisto/yuren-baichuan-7b.svg?style=social&label=Star) |          [Pleisto](https://github.com/pleisto)           |                                                              |\n|       VisCPM-Chat        |  10B  | 2023-06 |                           CPM-Bee                            |                           Q-Former                           | ä¸­è‹± |   è§†è§‰    |      [[ğŸ¤—HF\\]](https://huggingface.co/openbmb/VisCPM-Chat)      | [VisCPM](https://github.com/OpenBMB/VisCPM)![Star](https://img.shields.io/github/stars/OpenBMB/VisCPM.svg?style=social&label=Star) |          [OpenBMB](https://github.com/OpenBMB)           |                                                              |\n|       VisCPM-Paint       |  10B  | 2023-06 |                           CPM-Bee                            | [Stable Diffusion 2.1](https://github.com/Stability-AI/stablediffusion) | ä¸­è‹± |   è§†è§‰    |     [[ğŸ¤—HF\\]](https://huggingface.co/openbmb/VisCPM-Paint)      | [VisCPM](https://github.com/OpenBMB/VisCPM)![Star](https://img.shields.io/github/stars/OpenBMB/VisCPM.svg?style=social&label=Star) |          [OpenBMB](https://github.com/OpenBMB)           |                                                              |\n|        XrayPULSE         |  7B   | 2023-06 |         [PULSE](https://github.com/openmedlab/PULSE)         |       [MedCLIP](https://github.com/RyanWangZf/MedCLIP)       | ä¸­æ–‡ |   åŒ»å­¦    | [[ğŸ¤—HF\\]](https://drive.google.com/file/d/1VsO61-3DFuK4ysGPvoD4_JZaRFKvAJR_/view?usp=drive_link) | [XrayPULSE](https://github.com/openmedlab/XrayPULSE)![Star](https://img.shields.io/github/stars/openmedlab/XrayPULSE.svg?style=social&label=Star) |       [OpenMEDLab](https://github.com/OpenMEDLab)        |                                                              |\n|         SEEChat          |  6B   | 2023-06 |        [ChatGLM](https://github.com/THUDM/ChatGLM-6B)        |                           CLIP-ViT                           | ä¸­æ–‡ |     /     |        [[ğŸ¤—HF\\]](https://github.com/360CVGroup/SEEChat)         | [SEEChat](https://github.com/360CVGroup/SEEChat)![Star](https://img.shields.io/github/stars/360CVGroup/SEEChat.svg?style=social&label=Star) |           [360](https://github.com/360CVGroup)           |                                                              |\n| Ziya-BLIP2-14B-Visual-v1 |  14B  | 2023-06 | [LLaMA-13B](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1) |                            BLIP2                             | ä¸­è‹± |   é€šç”¨    | [[ğŸ¤—HF\\]](https://huggingface.co/IDEA-CCNL/Ziya-BLIP2-14B-Visual-v1) | [Fengshenbang-LM](https://github.com/IDEA-CCNL/Fengshenbang-LM)![Star](https://img.shields.io/github/stars/IDEA-CCNL/Fengshenbang-LM.svg?style=social&label=Star) |        [IDEAç ”ç©¶é™¢](https://github.com/IDEA-CCNL)        |                                                              |\n|    Video-LLaMA-BiLLA     |  7B   | 2023-05 | [BiLLa-7B]([BiLLa-7B](https://huggingface.co/Neutralzz/BiLLa-7B-SFT)) |    [MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4)     | ä¸­è‹± |   é€šç”¨    | [[ğŸ¤—HF\\]](https://huggingface.co/DAMO-NLP-SG/Video-LLaMA-Series/resolve/main/finetune-billa7b-zh.pth) | [Video-LLaMA](https://github.com/DAMO-NLP-SG/Video-LLaMA)![Star](https://img.shields.io/github/stars/DAMO-NLP-SG/Video-LLaMA.svg?style=social&label=Star) |    [è¾¾æ‘©é™¢å¤šè¯­è¨€NLP](https://github.com/DAMO-NLP-SG)     |          [Paper](https://arxiv.org/abs/2306.02858)           |\n|     Video-LLaMA-Ziya     |  13B  | 2023-05 | [Ziya-13B](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1) |    [MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4)     | ä¸­è‹± |   é€šç”¨    | [[ğŸ¤—HF\\]](https://huggingface.co/DAMO-NLP-SG/Video-LLaMA-Series/resolve/main/finetune-ziya13b-zh.pth) | [Video-LLaMA](https://github.com/DAMO-NLP-SG/Video-LLaMA)![Star](https://img.shields.io/github/stars/DAMO-NLP-SG/Video-LLaMA.svg?style=social&label=Star) |    [è¾¾æ‘©é™¢å¤šè¯­è¨€NLP](https://github.com/DAMO-NLP-SG)     |          [Paper](https://arxiv.org/abs/2306.02858)           |\n|         XrayGLM          |  6B   | 2023-05 |      [ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B)       |      [BLIP2-Qformer](https://arxiv.org/abs/2301.12597)       | ä¸­è‹± |   åŒ»å­¦    | [[ğŸ¤—HF\\]](https://huggingface.co/wangrongsheng/XrayGLM-300) | [XrayGLM](https://github.com/WangRongsheng/XrayGLM)![Star](https://img.shields.io/github/stars/WangRongsheng/XrayGLM.svg?style=social&label=Star) | [æ¾³é—¨ç†å·¥å¤§å­¦](https://www.mpu.edu.mo/esca/zh/index.php) |                                                              |\n|          X-LLM           |       | 2023-05 |        [ChatGLM](https://github.com/THUDM/ChatGLM-6B)        |          [ViT-g](https://arxiv.org/abs/2106.04560)           | ä¸­æ–‡ |     /     |                           [TODO]()                           | [X-LLM](https://github.com/phellonchen/X-LLM)![Star](https://img.shields.io/github/stars/phellonchen/X-LLM.svg?style=social&label=Star) |     [ä¸­ç§‘é™¢è‡ªåŠ¨åŒ–æ‰€](https://github.com/phellonchen)     |        [Paper](https://arxiv.org/pdf/2305.04160.pdf)         |\n|        VisualGLM         |  6B   | 2023-05 |      [ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B)       |      [BLIP2-Qformer](https://arxiv.org/abs/2301.12597)       | ä¸­è‹± |   è§†è§‰    |      [[ğŸ¤—HF\\]](https://huggingface.co/THUDM/visualglm-6b)       | [VisualGLM-6B](https://github.com/THUDM/VisualGLM-6B)![Star](https://img.shields.io/github/stars/THUDM/VisualGLM-6B.svg?style=social&label=Star) |           [æ¸…åå¤§å­¦](https://github.com/THUDM)           |                                                              |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n## ReasoningLLM\n\n> æ”¶é›†æ¨ç†èƒ½åŠ›æ¯”è¾ƒçªå‡ºçš„ä¸­æ–‡å¤§æ¨¡å‹\n\n|      æ¨¡å‹       | å¤§å° | æ—¶é—´    | è¯­è¨€ | é¢†åŸŸ |                             ä¸‹è½½                             |                           é¡¹ç›®åœ°å€                           |                 æœºæ„/ä¸ªäºº                 | ç»“æ„ |                      æ–‡                       |\n| :-------------: | :--: | ------- | :--: | :--: | :----------------------------------------------------------: | :----------------------------------------------------------: | :---------------------------------------: | :--: | :-------------------------------------------: |\n| HuatuoGPT-o1 | 7/8/70/72B | 2025-01 | ä¸­è‹± | åŒ»ç–— | [ğŸ¤—HF](https://huggingface.co/collections/FreedomIntelligence/huatuogpt-o1-677261a3711767cce7c64e13) | [HuatuoGPT-o1](https://github.com/FreedomIntelligence/HuatuoGPT-o1) | [FreedomIntelligence](https://github.com/FreedomIntelligence)/ |  CD  | [Paper](https://arxiv.org/pdf/2412.18925) |\n| QwQ-32B-Preview | 32B  | 2024-11 | ä¸­è‹± | é€šç”¨ |      [ğŸ¤—HF](https://huggingface.co/Qwen/QwQ-32B-Preview)      |                              /                               |    [QwenLM](https://github.com/QwenLM)    |  CD  |                                               |\n|    Marco-o1     |  7B  | 2024-11 | ä¸­è‹± | é€šç”¨ |        [ğŸ¤—HF](https://huggingface.co/AIDC-AI/Marco-o1)        |       [Marco-o1](https://github.com/AIDC-AI/Marco-o1)        |   [AIDC-AI](https://github.com/AIDC-AI)   |  CD  | [**Paper**](https://arxiv.org/abs/2411.14405) |\n| Skywork-01-Open |  8B  | 2024-11 | ä¸­è‹± | é€šç”¨ | [ğŸ¤—HF](https://huggingface.co/collections/Skywork/skywork-o1-open-67453df58e12f6c3934738d0) | [skywork-o1-prm-inference](https://github.com/SkyworkAI/skywork-o1-prm-inference) | [SkyworkAI](https://github.com/SkyworkAI) |  CD  | [Blog](https://nexusflow.ai/blogs/athene-v2)  |\n|     HK-01aw     |  8B  | 2024-11 | ä¸­æ–‡ | æ³•å¾‹ |       [ğŸ¤—HF](https://huggingface.co/HKAIR-Lab/HK-O1aw)        |       [HK-O1aw](https://github.com/HKAIR-Lab/HK-O1aw)        | [HKAIR-Lab](https://github.com/HKAIR-Lab) |  CD  |                                               |\n| QVQ-72B-Preview | 72B  | 2024-12 | ä¸­è‹± | å¤šæ¨¡ | [ğŸ¤— HF](https://huggingface.co/collections/Qwen/qvq-676448c820912236342b9888) | [Qwen2-VL](https://github.com/QwenLM/Qwen2-VL) | [QwenLM](https://github.com/QwenLM) |  |[Blog](https://qwenlm.github.io/zh/blog/qvq-72b-preview/)|\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n## ä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†\n\n> æ”¶é›†åŒ…å«ä¸­æ–‡çš„æŒ‡ä»¤æ•°æ®é›†ï¼Œç”¨äºå¾®è°ƒè¯­è¨€æ¨¡å‹ã€‚\n\n|            åç§°            | å¤§å°  | æ—¶é—´    | è¯­è¨€ |                             ä¸‹è½½                             |                           é¡¹ç›®åœ°å€                           |                             ä½œè€…                             |                     å¤‡æ³¨                      |\n| :------------------------: | :---: | ------- | :--: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :-------------------------------------------: |\n|         FinCorpus          |  50G  | 2023-09 | ä¸­æ–‡ | [dataset](https://huggingface.co/datasets/Duxiaoman-DI/FinCorpus) |     [XuanYuan](https://github.com/Duxiaoman-DI/XuanYuan)     |          [åº¦å°æ»¡](https://github.com/Duxiaoman-DI)           |                   é‡‘èé¢†åŸŸ                    |\n|        TransGPT-sft        | 346k  | 2023-07 | ä¸­æ–‡ | [dataset](https://huggingface.co/datasets/DUOMO-Lab/TransGPT-sft) |        [TransGPT](https://github.com/DUOMO/TransGPT)         |           [åŒ—äº¬äº¤é€šå¤§å­¦](https://github.com/DUOMO)           |                                               |\n|        TransGPT-pt         |  58k  | 2023-07 | ä¸­æ–‡ | [dataset](https://huggingface.co/datasets/DUOMO-Lab/TransGPT-pt) |        [TransGPT](https://github.com/DUOMO/TransGPT)         |           [åŒ—äº¬äº¤é€šå¤§å­¦](https://github.com/DUOMO)           |                                               |\n|  ShareGPT-Chinese-English  |  90K  | 2023-07 | ä¸­è‹± | [dataset](https://huggingface.co/datasets/shareAI/ShareGPT-Chinese-English-90k) | [llama2-Chinese-chat](https://github.com/CrazyBoyM/llama2-Chinese-chat)![Star](https://img.shields.io/github/stars/CrazyBoyM/llama2-Chinese-chat.svg?style=social&label=Star) |            [Ke Bai](https://github.com/CrazyBoyM)            |                                               |\n|  educhat-sft-002-data-osm  | 400w  | 2023-06 | ä¸­è‹± | [dataset](https://huggingface.co/datasets/ecnu-icalk/educhat-sft-002-data-osm) |       [EduChat](https://github.com/icalk-nlp/EduChat)        |         [åä¸œå¸ˆèŒƒå¤§å­¦](https://github.com/icalk-nlp)         |                     æ•™è‚²                      |\n|       chatgpt-corpus       |  3M   | 2023-06 | ä¸­æ–‡ |     [dataset](https://github.com/PlexPt/chatgpt-corpus)      |  [chatgpt-corpus](https://github.com/PlexPt/chatgpt-corpus)  |              [plex](https://github.com/PlexPt)               |                                               |\n|           Simle            | 350k  | 2023-06 | ä¸­æ–‡ | [dataset](https://github.com/qiuhuachuan/smile/tree/main/data) |        [smile](https://github.com/qiuhuachuan/smile)         |        [qiuhuachuan](https://github.com/qiuhuachuan)         |                   å¿ƒç†å¥åº·                    |\n|           QiZhen           |  20k  | 2023-06 | ä¸­æ–‡ | [dataset](https://github.com/CMKRG/QiZhenGPT/blob/main/data/train/sft-20k.json) |       [QiZhenGPT](https://github.com/CMKRG/QiZhenGPT)        |             [æµ™æ±Ÿå¤§å­¦](https://github.com/CMKRG)             |                     åŒ»å­¦                      |\n|         BayLing-80         |  80   | 2023-06 | ä¸­è‹± | [dataset](https://github.com/ictnlp/BayLing/blob/main/data/BayLing-80) |         [BayLing](https://github.com/ictnlp/BayLing)         |           [ä¸­å›½ç§‘å­¦é™¢](https://github.com/ictnlp)            |                   å¤šè½®æŒ‡ä»¤                    |\n|      Tigerbot-dataset      | 120k  | 2023-06 | ä¸­è‹± |     [dataset](https://github.com/TigerResearch/TigerBot)     |    [TigerBot](https://github.com/TigerResearch/TigerBot)     |         [è™åšç§‘æŠ€](https://github.com/TigerResearch)         |                                               |\n|        lawyer-llama        |   /   | 2023-05 | ä¸­æ–‡ | [dataset](https://github.com/AndrewZhe/lawyer-llama/tree/main/data) |  [lawyer-llama](https://github.com/AndrewZhe/lawyer-llama)   |         [Quzhe Huang](https://github.com/AndrewZhe)          |                     æ³•å¾‹                      |\n|         Bactrian-X         |  67K  | 2023-05 | å¤šè¯­ | [dataset](https://huggingface.co/datasets/MBZUAI/Bactrian-X) |    [bactrian-x](https://github.com/mbzuai-nlp/bactrian-x)    |           [MBZUAI](https://github.com/mbzuai-nlp)            |                                               |\n|      CrimeKgAssitant       |  52k  | 2023-05 | ä¸­æ–‡ |       [dataset](https://github.com/LiuHC0428/LAW-GPT)        |       [LAW-GPT](https://github.com/LiuHC0428/LAW-GPT)        |         [hongchengliu](https://github.com/LiuHC0428)         |                     æ³•å¾‹                      |\n|     moss-002-sft-data      | 1.1M  | 2023-04 | ä¸­è‹± | [dataset](https://huggingface.co/datasets/fnlp/moss-002-sft-data) |          [MOSS](https://github.com/OpenLMLab/MOSS)           |           [å¤æ—¦å¤§å­¦](https://github.com/OpenLMLab)           |                                               |\n|     moss-003-sft-data      | 1.1M  | 2023-04 | ä¸­è‹± | [dataset](https://github.com/OpenLMLab/MOSS/tree/main/SFT_data/conversations/conversation_without_plugins) |          [MOSS](https://github.com/OpenLMLab/MOSS)           |           [å¤æ—¦å¤§å­¦](https://github.com/OpenLMLab)           |                                               |\n|  moss-003-sft-plugin-data  | 300K  | 2023-04 | ä¸­è‹± | [dataset](https://github.com/OpenLMLab/MOSS/tree/main/SFT_data/conversations/conversation_with_plugins) |          [MOSS](https://github.com/OpenLMLab/MOSS)           |           [å¤æ—¦å¤§å­¦](https://github.com/OpenLMLab)           |                                               |\n|       Safety-Prompts       | 100K  | 2023-04 | ä¸­æ–‡ |    [dataset](https://github.com/thu-coai/Safety-Prompts)     | [Safety-Prompts](https://github.com/thu-coai/Safety-Prompts) |           [æ¸…åå¤§å­¦](https://github.com/thu-coai)            |   [è¯„æµ‹å¹³å°](http://115.182.62.166:18000/)    |\n|           OASST1           |   /   | 2023-04 | å¤šè¯­ | [dataset](https://huggingface.co/datasets/OpenAssistant/oasst1) | [Open-Assistant](https://github.com/LAION-AI/Open-Assistant) |    [OpenAssistant](https://huggingface.co/OpenAssistant)     |                                               |\n|         ShareChat          |  90K  | 2023-04 | ä¸­è‹± |     [dataset](https://paratranz.cn/projects/6725/files)      |       [ShareChat](https://paratranz.cn/projects/6725)        |         [czhko](https://paratranz.cn/projects/6725)          |                                               |\n|         GPT-4-LLM          |  52K  | 2023-04 | ä¸­æ–‡ | [dataset](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/blob/main/data/alpaca_gpt4_data_zh.json) | [GPT-4-LLM](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM) | [Instruction-Tuning-with-GPT-4](https://github.com/Instruction-Tuning-with-GPT-4) |   [paper](https://arxiv.org/abs/2304.03277)   |\n|            COIG            | 200K  | 2023-04 | ä¸­æ–‡ |     [dataset](https://huggingface.co/datasets/BAAI/COIG)     |   [FlagInstruct](https://github.com/FlagOpen/FlagInstruct)   |             [BAAI](https://huggingface.co/BAAI)              | [paper](https://arxiv.org/pdf/2304.07987.pdf) |\n|           RedGPT           |  50k  | 2023-04 | ä¸­æ–‡ |       [dataset](https://github.com/ziliwangnlp/RedGPT)       |       [RedGPT](https://github.com/ziliwangnlp/RedGPT)        |          [MiniGPT](https://github.com/ziliwangnlp)           |                                               |\n|        shareGPT_cn         |  20k  | 2023-04 | ä¸­æ–‡ | [dataset](https://huggingface.co/datasets/shareAI/shareGPT_cn) | [shareGPT_cn](https://huggingface.co/datasets/shareAI/shareGPT_cn) |          [shareAI](https://huggingface.co/shareAI)           |                                               |\n|    generated_chat_0.4M     | 0.4M  | 2023-04 | ä¸­æ–‡ | [dataset](https://huggingface.co/datasets/BelleGroup/generated_chat_0.4M) |        [BELLE](https://github.com/LianjiaTech/BELLE)         |      [Ke Technologies](https://github.com/LianjiaTech)       |                   è§’è‰²å¯¹è¯                    |\n|    multiturn_chat_0.8M     | 0.8M  | 2023-04 | ä¸­æ–‡ | [dataset](https://huggingface.co/datasets/BelleGroup/multiturn_chat_0.8M) |        [BELLE](https://github.com/LianjiaTech/BELLE)         |      [Ke Technologies](https://github.com/LianjiaTech)       |                   å¤šè½®ä»»åŠ¡                    |\n|     school_math_0.25M      | 0.25M | 2023-04 | ä¸­æ–‡ | [dataset](https://huggingface.co/datasets/BelleGroup/school_math_0.25M) |        [BELLE](https://github.com/LianjiaTech/BELLE)         |      [Ke Technologies](https://github.com/LianjiaTech)       |                    æ•°å­¦é¢˜                     |\n|         Zhihu-KOL          |   /   | 2023-03 | ä¸­æ–‡ | [ dataset](https://huggingface.co/datasets/wangrui6/Zhihu-KOL) |      [Zhihu-KOL](https://github.com/wangrui6/Zhihu-KOL)      |         [Rui Wang](https://huggingface.co/wangrui6)          |                                               |\n|      InstructionWild       | 104k  | 2023-03 | ä¸­è‹± | [dataset](https://github.com/XueFuzhao/InstructionWild/tree/main/data) | [InstructionWild](https://github.com/XueFuzhao/InstructionWild) |          [Xue Fuzhao](https://github.com/XueFuzhao)          |                                               |\n|         Alpaca-CoT         |  /.   | 2023-03 | ä¸­è‹± | [dataset](https://huggingface.co/datasets/QingyiSi/Alpaca-CoT/tree/main) |    [Alpaca-CoT](https://github.com/PhoebusSi/Alpaca-CoT)     |         [Qingyi Si](https://huggingface.co/QingyiSi)         |                                               |\n|       GuanacoDataset       |   /   | 2023-03 | å¤šè¯­ | [dataset](https://huggingface.co/datasets/JosephusCheung/GuanacoDataset) |      [guanaco-model](https://guanaco-model.github.io/)       |         [Guanaco](https://github.com/Guanaco-Model)          |                                               |\n| Traditional-Chinese-alpaca |  52K  | 2023-03 | ä¸­æ–‡ | [dataset](https://github.com/ntunlplab/traditional-chinese-alpaca/tree/main/data) | [Traditional-Chinese Alpaca](https://github.com/ntunlplab/traditional-chinese-alpaca) |         [NTU NLP Lab](https://github.com/ntunlplab)          |                    gptç¿»è¯‘                    |\n|   alpaca_chinese_dataset   |   /   | 2023-03 | ä¸­æ–‡ |                         [dataset]()                          | [alpaca_chinese_dataset](https://github.com/hikariming/alpaca_chinese_dataset) |            [akou](https://github.com/hikariming)             |                   äººå·¥æ ¡éªŒ                    |\n|   alpaca-chinese-dataset   |   /   | 2023-03 | ä¸­æ–‡ | [dataset](https://github.com/carbonz0/alpaca-chinese-dataset) | [alpaca-chinese-dataset](https://github.com/carbonz0/alpaca-chinese-dataset) |            [carbonz](https://github.com/carbonz0)            |                   æœºå™¨ç¿»è¯‘                    |\n|        train_2M_CN         |  2M   | 2023-03 | ä¸­æ–‡ | [dataset](https://huggingface.co/datasets/BelleGroup/train_2M_CN) |        [BELLE](https://github.com/LianjiaTech/BELLE)         |      [Ke Technologies](https://github.com/LianjiaTech)       |                                               |\n|        train_1M_CN         |  1M   | 2023-03 | ä¸­æ–‡ | [dataset](https://huggingface.co/datasets/BelleGroup/train_1M_CN) |        [BELLE](https://github.com/LianjiaTech/BELLE)         |      [Ke Technologies](https://github.com/LianjiaTech)       |                                               |\n|       train_0.5M_CN        | 0.5M  | 2023-03 | ä¸­æ–‡ | [dataset](https://huggingface.co/datasets/BelleGroup/train_0.5M_CN) |        [BELLE](https://github.com/LianjiaTech/BELLE)         |      [Ke Technologies](https://github.com/LianjiaTech)       |                                               |\n|   HC3 äººç±»-ChatGPT é—®ç­”    |   /   | 2023-03 | ä¸­æ–‡ | [dataset](https://www.modelscope.cn/datasets/simpleai/HC3-Chinese/summary) | [chatgpt-comparison-detection](https://github.com/Hello-SimpleAI/chatgpt-comparison-detection) |        [SimpleAI](https://github.com/Hello-SimpleAI)         |                                               |\n|     firefly-train-1.1M     | 1.1M  | 2023-03 | ä¸­æ–‡ | [dataset](https://huggingface.co/datasets/YeungNLP/firefly-train-1.1M) |      [Firefly](https://github.com/yangjianxin1/Firefly)      |       [Jianxin Yang](https://github.com/yangjianxin1)        |                                               |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### Embedding\n\n> MTEBæ’è¡Œæ¦œ:  https://huggingface.co/spaces/mteb/leaderboard [é•œåƒ](https://hf-mirror.com/spaces/mteb/leaderboard)\n\n|           æ¨¡å‹           |  å¤§å°   | æ—¶é—´    | è¯­è¨€ |     é¢†åŸŸ     |                             ä¸‹è½½                             |                           é¡¹ç›®åœ°å€                           |                       æœºæ„/ä¸ªäºº                        |                             æ–‡                             |\n| :----------------------: | :-----: | ------- | :--: | :----------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------: | :----------------------------------------------------------: |\n| JinaColBERT V2 | large | 2024-08 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/jinaai/jina-colbert-v2) | / | [Jina AI](https://huggingface.co/jinaai) | [Paper](https://arxiv.org/abs/2408.16672) |\n| Conan-embedding-v1 | large | 2024-08 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/TencentBAC/Conan-embedding-v1) | / | [TencentABC](https://huggingface.co/TencentBAC) | [Paper](https://arxiv.org/abs/2408.15710) |\n| xiaobu-v2 | large | 2024-07 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/lier007/xiaobu-embedding-v2) | / | [lier007](https://huggingface.co/lier007) |  |\n| zpoint_large | Large | 2024-06 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/iampanda/zpoint_large_embedding_zh) | / | [**yang**](https://huggingface.co/iampanda) |  |\n| BCE | 279M | 2024-01 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/maidalun1020/bce-embedding-base_v1) | [BCEmbedding](https://github.com/netease-youdao/BCEmbedding) | [netease-youdao](https://github.com/netease-youdao) |  |\n| Cohere | Base | 2023-09 | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/Cohere) | / | [Cohere](https://huggingface.co/Cohere) | [Blog](https://txt.cohere.com/introducing-embed-v3/) |\n| jina | Base | 2023-10 | ä¸­è‹± | é€šç”¨ | [[ğŸ¤—HF\\]](https://huggingface.co/jinaai/jina-embeddings-v2-base-zh) | / | [Jina AI](https://huggingface.co/jinaai) |  |\n| Dmeta | **400MB** | 2024-02 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://hf-mirror.com/DMetaSoul/Dmeta-embedding) | / | [DMetaSoul](https://hf-mirror.com/DMetaSoul) |  |\n| bge-m3 |  | 2024-02 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://hf-mirror.com/BAAI) | / | [BAAI](https://hf-mirror.com/BAAI) | [Paper](https://arxiv.org/pdf/2402.03216.pdf) |\n| tao-8k |  | 2023-11 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://hf-mirror.com/amu) |  | [amu](https://hf-mirror.com/amu) |  |\n| bge | s/b/l | 2023-10 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://hf-mirror.com/BAAI) | / | [BAAI](https://hf-mirror.com/BAAI) |  |\n| gte-zh | s/b/l | 2023-08 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://hf-mirror.com/DMetaSoul/Dmeta-embedding) | / | Alibaba DAMO | [Paper](arXiv:2308.03281) |\n| m3e | s/b/l | 2023-06 | ä¸­æ–‡ | é€šç”¨ | [[ğŸ¤—HF\\]](https://hf-mirror.com/moka-ai) | / | [Moka-AI](https://hf-mirror.com/moka-ai) |  |\n| LaBSE |  |  | å¤šè¯­ | é€šç”¨ | [[ğŸ¤—HF\\]](https://hf-mirror.com/sentence-transformers/LaBSE) | / | [Sentence Transformers](https://hf-mirror.com/sentence-transformers) | |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n## å¤§æ¨¡å‹è¯„ä¼°åŸºå‡†\n\n### 1. C-Eval ![Star](https://img.shields.io/github/stars/SJTU-LIT/ceval.svg?style=social&label=Star)\n\nC-Eval æ˜¯ä¸€ä¸ªå…¨é¢çš„ä¸­æ–‡åŸºç¡€æ¨¡å‹è¯„ä¼°å¥—ä»¶ã€‚å®ƒåŒ…å«äº†13948ä¸ªå¤šé¡¹é€‰æ‹©é¢˜ï¼Œæ¶µç›–äº†52ä¸ªä¸åŒçš„å­¦ç§‘å’Œå››ä¸ªéš¾åº¦çº§åˆ«ï¼ŒæŸ¥çœ‹[è®ºæ–‡](https://arxiv.org/abs/2305.08322)äº†è§£æ›´å¤šç»†èŠ‚ã€‚\n\n[[å®˜æ–¹ç½‘ç«™](https://cevalbenchmark.com/)]   [[Github](https://github.com/SJTU-LIT/ceval)]  [[è®ºæ–‡](https://arxiv.org/abs/2305.08322)] \n\n### 2. FlagEval ![Star](https://img.shields.io/github/stars/FlagOpen/FlagEval.svg?style=social&label=Star)\n\nFlagEvalæ˜¯ä¸€ä¸ªé¢å‘AIåŸºç¡€æ¨¡å‹çš„è¯„æµ‹å·¥å…·åŒ…ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ¢ç´¢å’Œé›†åˆç§‘å­¦ã€å…¬æ­£ã€å¼€æ”¾çš„åŸºç¡€æ¨¡å‹è¯„æµ‹åŸºå‡†ã€æ–¹æ³•åŠå·¥å…·ï¼Œå¯¹å¤šé¢†åŸŸï¼ˆå¦‚è¯­è¨€ã€è¯­éŸ³ã€è§†è§‰åŠå¤šæ¨¡æ€ï¼‰çš„åŸºç¡€æ¨¡å‹è¿›è¡Œå¤šç»´åº¦ï¼ˆå¦‚å‡†ç¡®æ€§ã€æ•ˆç‡ã€é²æ£’æ€§ç­‰ï¼‰çš„è¯„æµ‹ã€‚æˆ‘ä»¬å¸Œæœ›é€šè¿‡å¯¹åŸºç¡€æ¨¡å‹çš„è¯„æµ‹ï¼ŒåŠ æ·±å¯¹åŸºç¡€æ¨¡å‹çš„ç†è§£ï¼Œä¿ƒè¿›ç›¸å…³çš„æŠ€æœ¯åˆ›æ–°åŠäº§ä¸šåº”ç”¨ã€‚\n\n[[å®˜æ–¹ç½‘ç«™](https://cevalbenchmark.com/)]   [[Github](https://github.com/FlagOpen/FlagEval)] \n\n### 3. SuperCLUElyb ![Star](https://img.shields.io/github/stars/CLUEbenchmark/SuperCLUElyb.svg?style=social&label=Star)\n\nSuperCLUEç…çŠæ¦œï¼Œè¿™æ˜¯ä¸€ä¸ªä¸­æ–‡é€šç”¨å¤§æ¨¡å‹å¯¹æˆ˜è¯„ä»·åŸºå‡†ï¼Œå®ƒä»¥ä¼—åŒ…çš„æ–¹å¼æä¾›åŒ¿åã€éšæœºçš„å¯¹æˆ˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å‘å¸ƒäº†åˆæ­¥çš„ç»“æœå’ŒåŸºäºEloè¯„çº§ç³»ç»Ÿçš„æ’è¡Œæ¦œï¼ŒEloè¯„çº§æ˜¯å›½é™…è±¡æ£‹å’Œå…¶ä»–ç«æŠ€æ¸¸æˆä¸­å¹¿æ³›ä½¿ç”¨çš„è¯„çº§ç³»ç»Ÿã€‚æˆ‘ä»¬é‚€è¯·æ•´ä¸ªç¤¾åŒºåŠ å…¥è¿™é¡¹å·¥ä½œï¼Œè´¡çŒ®æ–°çš„æ¨¡å‹ï¼Œå¹¶é€šè¿‡æé—®å’ŒæŠ•ç¥¨é€‰å‡ºä½ æœ€å–œæ¬¢çš„ç­”æ¡ˆæ¥è¯„ä¼°å®ƒä»¬ã€‚\n\n[[å®˜æ–¹ç½‘ç«™](https://www.superclueai.com/)]   [[Github](https://github.com/CLUEbenchmark/SuperCLUElyb)]\n\n### 4. XiezhiBenchmark ![Star](https://img.shields.io/github/stars/mikegu721/xiezhibenchmark.svg?style=social&label=Star)\n\nè¯¥åŸºå‡†åŒ…æ‹¬æ¥è‡ª13ä¸ªä¸åŒå­¦ç§‘çš„516ä¸ªå­¦ç§‘çš„220,000ä¸ªå¤šé¡¹é€‰æ‹©é¢˜ï¼Œä»¥åŠ15,000ä¸ªæ¥è‡ªå•ä¸€å­¦ç§‘å’Œå¤šä¸ªå­¦ç§‘çš„é—®é¢˜ã€‚æˆ‘ä»¬å¯¹47ä¸ªæœ€æ–°çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨Xiezhiä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜åœ¨ç§‘å­¦ã€å·¥ç¨‹ã€å†œå­¦ã€åŒ»å­¦å’Œè‰ºæœ¯ç­‰é¢†åŸŸï¼Œå¤§å‹è¯­è¨€æ¨¡å‹çš„è¡¨ç°è¶…è¿‡äº†äººç±»çš„å¹³å‡æ°´å¹³ï¼Œä½†åœ¨ç»æµå­¦ã€æ³•å­¦ã€æ•™è‚²å­¦ã€æ–‡å­¦ã€å†å²å’Œç®¡ç†å­¦ç­‰é¢†åŸŸï¼Œäººç±»çš„è¡¨ç°ä»ç„¶è¿œè¿œè¶…è¿‡äº†å¤§å‹è¯­è¨€æ¨¡å‹ã€‚\n\n[[å®˜æ–¹ç½‘ç«™]()]   [[Github](https://github.com/mikegu721/xiezhibenchmark)] [[è®ºæ–‡](https://arxiv.org/abs/2306.05783)]\n\n### 5. Open LLM Leaderboard\n\nç”±HuggingFaceç»„ç»‡çš„ä¸€ä¸ªLLMè¯„æµ‹æ¦œå•ï¼Œç›®å‰å·²è¯„ä¼°äº†è¾ƒå¤šä¸»æµçš„å¼€æºLLMæ¨¡å‹ï¼Œä»¥è‹±æ–‡ä¸ºä¸»ã€‚ä¸»è¦ç›®æ ‡æ˜¯è·Ÿè¸ªã€æ’åå’Œè¯„ä¼°æœ€æ–°çš„å¤§è¯­è¨€æ¨¡å‹å’ŒèŠå¤©æœºå™¨äººï¼Œè®©æ‰€æœ‰äººæ–¹ä¾¿çš„è§‚å¯Ÿåˆ°å¼€æºç¤¾åŒºçš„è¿›å±•å’Œè¯„ä¼°è¿™äº›æ¨¡å‹ã€‚è¿™ä¸ªæ’è¡Œæ¦œæœ‰ä¸€ä¸ªå…³é”®ä¼˜åŠ¿ï¼Œç¤¾åŒºä¸­çš„ä»»ä½•æˆå‘˜éƒ½å¯ä»¥æäº¤æ¨¡å‹ï¼Œå¹¶åœ¨ Hugging Face çš„ GPU é›†ç¾¤ä¸Šè‡ªåŠ¨è¯„ä¼°ã€‚\n\n[[å®˜æ–¹ç½‘ç«™](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)] \n\n### 6. ä¸­æ–‡å¤§æ¨¡å‹å®‰å…¨è¯„æµ‹å¹³å° ![Star](https://img.shields.io/github/stars/thu-coai/Safety-Prompts.svg?style=social&label=Star)\n\nå¤§æ¨¡å‹å®‰å…¨æµ‹è¯„ä¾æ‰˜äºä¸€å¥—ç³»ç»Ÿçš„å®‰å…¨è¯„æµ‹æ¡†æ¶ï¼Œæ¶µç›–äº†ä»‡æ¨è¨€è®ºã€åè§æ­§è§†è¨€è®ºã€çŠ¯ç½ªè¿æ³•ã€éšç§ã€ä¼¦ç†é“å¾·ç­‰å…«å¤§ç±»åˆ«ï¼ŒåŒ…æ‹¬ç»†ç²’åº¦åˆ’åˆ†çš„40ä½™ä¸ªäºŒçº§å®‰å…¨ç±»åˆ«ã€‚\n\n[[å®˜æ–¹ç½‘ç«™](http://coai.cs.tsinghua.edu.cn/leaderboard/)]   [[Github](https://github.com/thu-coai/Safety-Prompts)] [[è®ºæ–‡](https://arxiv.org/abs/2304.10436)]\n\n### 7. OpenCompasså¤§è¯­è¨€æ¨¡å‹è¯„æµ‹ ![Star](https://img.shields.io/github/stars/open-compass/opencompass.svg?style=social&label=Star)\n\nOpenCompass æ˜¯ä¸€æ¬¾å¼€æºã€é«˜æ•ˆã€å…¨é¢çš„è¯„æµ‹å¤§æ¨¡å‹ä½“ç³»åŠå¼€æ”¾å¹³å°ã€‚æˆ‘ä»¬æä¾›å®Œæ•´å¼€æºå¯å¤ç°çš„è¯„æµ‹æ¡†æ¶ï¼Œæ”¯æŒå¤§è¯­è¨€æ¨¡å‹ã€å¤šæ¨¡æ€æ¨¡å‹å„ç±»æ¨¡å‹çš„ä¸€ç«™å¼è¯„æµ‹ã€‚åˆ©ç”¨åˆ†å¸ƒå¼æŠ€æœ¯ï¼Œå³ä½¿é¢å¯¹åƒäº¿å‚æ•°æ¨¡å‹ä¹Ÿèƒ½åœ¨æ•°å°æ—¶å†…å®Œæˆè¯„æµ‹ã€‚åŸºäºå¤šä¸ªä¸åŒç»´åº¦çš„é«˜è®¤å¯åº¦æ•°æ®é›†å¼€æ”¾å¤šæ ·åŒ–çš„è¯„æµ‹æ–¹å¼ï¼ŒåŒ…æ‹¬é›¶æ ·æœ¬è¯„æµ‹ã€å°æ ·æœ¬è¯„æµ‹å’Œæ€ç»´é“¾è¯„æµ‹ï¼Œå…¨æ–¹ä½é‡åŒ–æ¨¡å‹å„ä¸ªç»´åº¦èƒ½åŠ›ã€‚\n\n[[å®˜æ–¹ç½‘ç«™](https://opencompass.org.cn/)]   [[Github](https://github.com/open-compass/opencompass)]\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n## åœ¨çº¿ä½“éªŒå¤§æ¨¡å‹\n\n> **æ³¨**ï¼šéœ€è¦ç”³è¯·æˆ–è€…æ³¨å†Œæ–¹å¯ä½“éªŒ,æ›´å¤šè§[Github](https://github.com/wgwang/LLMs-In-China)\n\n### 1. ChatGPT--OpenAI\n\nOpenAIæ‰€æå‡ºçš„GPTç›¸å…³æ¨¡å‹ï¼Œä¹Ÿæ˜¯ç›®å‰æœ€ç«çš„å¤§è¯­è¨€æ¨¡å‹ï¼Œå‘å¸ƒç‰ˆæœ¬å·²ç»åˆ°äº†4.0.\n\n[[å®˜æ–¹ç½‘ç«™](https://chat.openai.com/chat)] \n\n### 2. New bing--å¾®è½¯\n\nNewBingæ˜¯å¾®è½¯åœ¨2023å¹´3æœˆæ¨å‡ºçš„ä¸€æ¬¾å…¨æ–°çš„æœç´¢å¼•æ“ï¼Œå®ƒåŸºäºOpenAIçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œå¹¶ç»“åˆäº†ChatGPTå’ŒDALLÂ·Eçš„æŠ€æœ¯ï¼Œä¸ºç”¨æˆ·æä¾›äº†ä¸€ä¸ªAIé©±åŠ¨çš„ç½‘ç»œåŠ©æ‰‹ã€‚\n\n[[å®˜æ–¹ç½‘ç«™](https://www.bing.com/)] \n\n### 3. æ–‡å¿ƒä¸€è¨€--ç™¾åº¦\n\nç™¾åº¦å…¨æ–°ä¸€ä»£çŸ¥è¯†å¢å¼ºå¤§è¯­è¨€æ¨¡å‹ï¼Œæ–‡å¿ƒå¤§æ¨¡å‹å®¶æ—çš„æ–°æˆå‘˜ï¼Œèƒ½å¤Ÿä¸äººå¯¹è¯äº’åŠ¨ï¼Œå›ç­”é—®é¢˜ï¼ŒååŠ©åˆ›ä½œï¼Œé«˜æ•ˆä¾¿æ·åœ°å¸®åŠ©äººä»¬è·å–ä¿¡æ¯ã€çŸ¥è¯†å’Œçµæ„Ÿã€‚\n\n[[å®˜æ–¹ç½‘ç«™](https://yiyan.baidu.com/welcome)] \n\n### 4. é€šä¹‰å¤§æ¨¡å‹--é˜¿é‡Œ\n\né˜¿é‡Œå¤§æ¨¡å‹ç»Ÿä¸€å“ç‰Œï¼Œè¦†ç›–è¯­è¨€ã€å¬è§‰ã€å¤šæ¨¡æ€ç­‰é¢†åŸŸè‡´åŠ›äºå®ç°æ¥è¿‘äººç±»æ™ºæ…§çš„é€šç”¨æ™ºèƒ½ï¼Œè®©AIä»â€œå•ä¸€æ„Ÿå®˜â€åˆ°â€œäº”å®˜å…¨å¼€â€\n\n[[å®˜æ–¹ç½‘ç«™](https://tongyi.aliyun.com/)] \n\n### 5. æ˜Ÿç«è®¤çŸ¥å¤§æ¨¡å‹--ç§‘å¤§è®¯é£\n\nç§‘å¤§è®¯é£æ¨å‡ºçš„æ–°ä¸€ä»£è®¤çŸ¥æ™ºèƒ½å¤§æ¨¡å‹ï¼Œæ‹¥æœ‰è·¨é¢†åŸŸçš„çŸ¥è¯†å’Œè¯­è¨€ç†è§£èƒ½åŠ›ï¼Œèƒ½å¤ŸåŸºäºè‡ªç„¶å¯¹è¯æ–¹å¼ç†è§£ä¸æ‰§è¡Œä»»åŠ¡ã€‚ä»æµ·é‡æ•°æ®å’Œå¤§è§„æ¨¡çŸ¥è¯†ä¸­æŒç»­è¿›åŒ–ï¼Œå®ç°ä»æå‡ºã€è§„åˆ’åˆ°è§£å†³é—®é¢˜çš„å…¨æµç¨‹é—­ç¯ã€‚\n\n[[å®˜æ–¹ç½‘ç«™](https://xinghuo.xfyun.cn/)] \n\n### 6. Claude--Anthropic\n\nClaudeï¼Œæ˜¯äººå·¥æ™ºèƒ½åˆåˆ›å…¬å¸Anthropic å‘å¸ƒçš„ä¸€æ¬¾ç±»ä¼¼ChatGPTçš„äº§å“ã€‚\n\n[[å®˜æ–¹ç½‘ç«™](https://www.anthropic.com/product)] \n\n### 7. ChatGLM--æ™ºè°±AI\n\nåŸºäºåƒäº¿åŸºåº§æ¨¡å‹ GLM-130Bï¼Œæ³¨å…¥ä»£ç é¢„è®­ç»ƒï¼Œé€šè¿‡æœ‰ç›‘ç£å¾®è°ƒç­‰æŠ€æœ¯å®ç°äººç±»æ„å›¾å¯¹é½ï¼Œå…·å¤‡é—®ç­”ã€å¤šè½®å¯¹è¯ã€ä»£ç ç”ŸæˆåŠŸèƒ½çš„ä¸­è‹±åŒè¯­å¤§æ¨¡å‹ã€‚\n\n[[å®˜æ–¹ç½‘ç«™](https://chatglm.cn/)] \n\n### 8. å¤©å·¥å¤§æ¨¡å‹--æ˜†ä»‘ä¸‡ç»´\n\nå¤©å·¥ä½œä¸ºä¸€æ¬¾å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ‹¥æœ‰å¼ºå¤§çš„è‡ªç„¶è¯­è¨€å¤„ç†å’Œæ™ºèƒ½äº¤äº’èƒ½åŠ›ï¼Œèƒ½å¤Ÿå®ç°æ™ºèƒ½é—®ç­”ã€èŠå¤©äº’åŠ¨ã€æ–‡æœ¬ç”Ÿæˆç­‰å¤šç§åº”ç”¨åœºæ™¯ï¼Œå¹¶ä¸”å…·æœ‰ä¸°å¯Œçš„çŸ¥è¯†å‚¨å¤‡ï¼Œæ¶µç›–ç§‘å­¦ã€æŠ€æœ¯ã€æ–‡åŒ–ã€è‰ºæœ¯ã€å†å²ç­‰é¢†åŸŸã€‚\n\n[[å®˜æ–¹ç½‘ç«™](https://tiangong.kunlun.com/)] \n\n### 9. åºåˆ—çŒ´å­å¤§æ¨¡å‹--å‡ºé—¨é—®é—®\n\nåºåˆ—çŒ´å­å¤§æ¨¡å‹æ˜¯ä¸€ä¸ªå…·æœ‰é•¿åºåˆ—ã€å¤šæ¨¡æ€ã€å•æ¨¡å‹ã€å¤§æ•°æ®ç­‰ç‰¹ç‚¹çš„è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ŒåŸºäºå…¶é€šç”¨çš„è¡¨ç¤ºèƒ½åŠ›ä¸æ¨ç†èƒ½åŠ›ï¼Œèƒ½å¤Ÿè¿›è¡Œå¤šè½®äº¤äº’ï¼Œæ‰“é€ æ›´ä¾¿æ·æµç•…çš„ç”¨æˆ·ä½“éªŒï¼Œæå¤§åœ°æé«˜äº†ç”Ÿäº§æ•ˆç‡å’Œæ•°æ®å¤„ç†èƒ½åŠ›ï¼Œè¢«å¹¿æ³›åº”ç”¨äºé—®ç­”ç³»ç»Ÿã€è‡ªç„¶è¯­è¨€å¤„ç†ã€æœºå™¨ç¿»è¯‘ã€æ–‡æœ¬æ‘˜è¦ç­‰é¢†åŸŸã€‚\n\n[[å®˜æ–¹ç½‘ç«™](https://openapi.mobvoi.com/largemodel-introduce)] \n\n### 10. MOSS--å¤æ—¦å¤§å­¦\n\nMOSSæ˜¯å¤æ—¦å¤§å­¦è‡ªç„¶è¯­è¨€å¤„ç†å®éªŒå®¤å‘å¸ƒçš„å›½å†…ç¬¬ä¸€ä¸ªå¯¹è¯å¼å¤§å‹è¯­è¨€æ¨¡å‹\n\n[[å®˜æ–¹ç½‘ç«™](https://moss.fastnlp.top/)] \n\n### 11. 360æ™ºè„‘å¤§æ¨¡--360\n\n360æ™ºè„‘çš„ç”Ÿæˆä¸åˆ›ä½œã€å¤šè½®å¯¹è¯ã€ä»£ç èƒ½åŠ›ã€é˜…è¯»ç†è§£ã€é€»è¾‘ä¸æ¨ç†ã€å¤šæ¨¡æ€ç­‰åå¤§æ ¸å¿ƒèƒ½åŠ›å¯è¦†ç›–å¤§æ¨¡å‹å…¨éƒ¨åº”ç”¨åœºæ™¯ã€‚\n\n[[å®˜æ–¹ç½‘ç«™](https://ai.360.cn/)] \n\n### 12. æ›¹æ¤GPTå¤§è¯­è¨€æ¨¡å‹--è¾¾è§‚æ•°æ®\n\nè¾¾è§‚æ•°æ®ç§¯ææ¢ç´¢å¤§è¯­è¨€æ¨¡å‹LLMçš„å®è·µï¼Œç ”å‘å›½äº§ç‰ˆGPTâ€œæ›¹æ¤â€ç³»ç»Ÿï¼Œä½œä¸ºå‚ç›´ã€ä¸“ç”¨ã€è‡ªä¸»å¯æ§çš„å›½äº§ç‰ˆChatGPTæ¨¡å‹ï¼Œä¸ä»…å®ç°ä¸“ä¸šé¢†åŸŸçš„AIGCæ™ºèƒ½åŒ–åº”ç”¨ï¼Œä¸”å¯å†…ç½®åœ¨å®¢æˆ·å„ç±»ä¸šåŠ¡ç³»ç»Ÿä¸­æä¾›ä¸“ç”¨æœåŠ¡\n\n[[å®˜æ–¹ç½‘ç«™](http://www.datagrand.com/products/aigc/)] \n\n### 13. æ—¥æ—¥æ–°--å•†æ±¤\n\nå•†æ±¤â€œæ—¥æ—¥æ–°SenseNovaâ€å¤§æ¨¡å‹ä½“ç³»ï¼Œæ­£å¼é—®ä¸–\n\nä¸ä»…å±•ç¤ºäº†å¤§æ¨¡å‹ä½“ç³»ä¸‹çš„è¯­è¨€å¤§æ¨¡å‹ï¼Œè¿˜å±•ç¤ºäº†AIæ–‡ç”Ÿå›¾åˆ›ä½œã€2D/3Dæ•°å­—äººç”Ÿæˆã€å¤§åœºæ™¯/å°ç‰©ä½“ç”Ÿæˆç­‰ä¸€ç³»åˆ—ç”Ÿæˆå¼AIæ¨¡å‹åŠåº”ç”¨ï¼Œè¿˜æ­å¼€äº†ä¾æ‰˜å•†æ±¤AIå¤§è£…ç½®SenseCoreå®ç°â€œå¤§æ¨¡å‹+å¤§ç®—åŠ›â€èåˆåˆ›æ–°çš„ç ”å‘ä½“ç³»ã€‚\n\n[[å®˜æ–¹ç½‘ç«™](https://techday.sensetime.com/list)] \n\n### 14. å¤©ç‡•å¤§æ¨¡å‹--APUS\n\nå¤©ç‡•å¤§æ¨¡å‹æ˜¯APUSå…¬å¸è‡ªç ”çš„å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆLMMï¼‰ï¼Œå…·å¤‡å¯¹æ–‡æœ¬ã€å›¾åƒã€è§†é¢‘ã€éŸ³é¢‘çš„ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼ˆè§†é¢‘å’ŒéŸ³é¢‘çš„èƒ½åŠ›å³å°†æ¨å‡ºï¼‰ã€‚\n\n[[å®˜æ–¹ç½‘ç«™](https://www.apusai.com/#/)] \n\n### 15. å…ƒä¹˜è±¡--æ™ºå­å¼•æ“\n\nå›¾æ–‡æœºå™¨äºº\n\n[[å®˜æ–¹ç½‘ç«™](https://chatimg.aixiaoqingxu.com/)] \n\n### 16. è¥¿æ¹–å¤§æ¨¡å‹--è¥¿æ¹–å¿ƒè¾°\n\n[[å®˜æ–¹ç½‘ç«™](https://xinchenai.com/)] \n\n### 17. Dongni--æ·±æ€è€ƒ\n\nAIå¤šæ¨¡æ€æœç´¢å¼•æ“\n\n[[å®˜æ–¹ç½‘ç«™](https://www.dongni.ai/#/)] \n\n### 18. å±±æµ·å¤§æ¨¡å‹--äº‘çŸ¥å£°\n\nåªéœ€ä¸€æ¬¡å¯¹è¯å³å¯è·å–ä¿¡æ¯ã€çŸ¥è¯†å’Œçµæ„Ÿï¼Œè§£å†³éœ€æ±‚ã€‚æ˜¯æ¯ä¸ªäººèº«è¾¹çš„åŠ©ç†ã€æœ‹å‹å’Œä¸“å®¶ã€‚\n\n[[å®˜æ–¹ç½‘ç«™](https://shanhai.unisound.com/)] \n\n### 19. MiniMaxå¤§æ¨¡å‹--MiniMax\n\nMiniMax æœ€æ–°ä¸€ä»£çš„ä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹å¸®åŠ©äººç±»é«˜æ•ˆå†™ä½œã€æ¿€å‘åˆ›æ„ã€è·å–çŸ¥è¯†ã€åšå‡ºå†³ç­–ç°å·²å¯¹ä¼ä¸šå¼€æ”¾APIä½“éªŒ\n\n[[å®˜æ–¹ç½‘ç«™](https://api.minimax.chat/)] \n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n## å¼€æºæ¨¡å‹åº“å¹³å°\n\n1. ğŸ¤—[HuggingFace](https://huggingface.co/): The AI community building the future.\n* æ¨¡å‹ä¸‹è½½åœ°å€: [https://huggingface.co/models](https://huggingface.co/models)\n\n2. [ModelScope](https://modelscope.cn/home): ModelScopeå¹³å°æ˜¯ä»¥æ¨¡å‹ä¸ºä¸­å¿ƒçš„æ¨¡å‹å¼€æºç¤¾åŒº\n* æ¨¡å‹ä¸‹è½½åœ°å€:[https://modelscope.cn/models](https://modelscope.cn/models)\n\n3. [flagopen](https://flagopen.baai.ac.cn/#/home): flagopené£æ™ºå¤§æ¨¡å‹æŠ€æœ¯å¼€æºä½“ç³»\n* æ¨¡å‹ä¸‹è½½åœ°å€: [https://model.baai.ac.cn/models](https://model.baai.ac.cn/models)\n\n4. [å§‹æ™ºAI](https://wisemodel.cn/home): ä¸­å›½AIå¼€æºåˆ›æ–°ç¤¾åŒº\n* æ¨¡å‹ä¸‹è½½åœ°å€: [https://wisemodel.cn/models](https://wisemodel.cn/models)\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n## å¼€æºæ•°æ®é›†åº“\n\n1. huggfaceingæ•°æ®é›†ä»“åº“: [https://huggingface.co/datasets](https://huggingface.co/datasets)\n* åŒ…å«äº†è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ã€è¯­éŸ³ã€å¤šæ¨¡æ€ç­‰æ•°æ®é›†ï¼Œå†…ç½®100å¤šä¸ªå¤šè¯­è¨€å…¬å…±æ•°æ®é›†ä¸‹è½½\n\n2. ModelScopeæ•°æ®é›†ä»“åº“:[https://modelscope.cn/datasets](https://modelscope.cn/datasets)\n* æä¾›äº†è¦†ç›–è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ã€è¯­éŸ³ã€å¤šæ¨¡æ€ç­‰æ•°æ®é›†ï¼Œæ›´æœ‰é˜¿é‡Œå·´å·´é›†å›¢è´¡çŒ®çš„ä¸“ä¸šé¢†åŸŸæ•°æ®é›†ï¼Œ\n\n3. flagopenæ•°æ®é›†ä»“åº“: [https://data.baai.ac.cn/data](https://data.baai.ac.cn/data)\n* å†…ç½®å…¬å…±æ•°æ®é›†ä¸‹è½½ï¼Œå¯ä¸‹200Gå¤§è§„æ¨¡é¢„è®­ç»ƒè¯­æ–™[WuDaoCorpora](https://data.baai.ac.cn/details/WuDaoCorporaText)\n\n4. cluebenchmarksæ•°æ®é›†ä»“åº“ï¼š[https://www.cluebenchmarks.com/dataSet_search.html](https://www.cluebenchmarks.com/dataSet_search.html)\n* å¤šä¸ªä¸­è‹±æ–‡NLPæ•°æ®é›†ï¼Œå¹¶å¯ç”³è¯·ä¸‹è½½100GBçš„é«˜è´¨é‡ä¸­æ–‡é¢„è®­ç»ƒè¯­æ–™[CLUECorpus2020](https://github.com/CLUEbenchmark/CLUECorpus2020)\n\n5. [MNBVC](https://github.com/esbatmop/MNBVC): Massive Never-ending BT Vast Chinese corpus\n* è¶…å¤§è§„æ¨¡ä¸­æ–‡è¯­æ–™é›†\n\n6. OpenDataLabæ•°æ®é›†ä»“åº“: [https://opendatalab.com/](https://opendatalab.com/)\n* OpenDataLab æ˜¯æœ‰å½±å“åŠ›çš„æ•°æ®å¼€æºå¼€æ”¾å¹³å°ï¼Œå…¬å¼€æ•°æ®é›†è§¦æ‰‹å¯åŠã€‚\n\n7. [OSCAR](https://oscar-project.org/): Open Super-large Crawled Aggregated coRpus, å¤šè¯­è¨€æ•°æ®é›†\n* æœ€æ–°ç‰ˆæœ¬åŒ…å«1.4Tçš„ä¸­æ–‡è¯­è¨€æ•°æ®é›†\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n## other-awesome\n\n####  1. Awesome-Chatgpt ![Star](https://img.shields.io/github/stars/awesome-chatgpt/awesome-chatgpt.svg?style=social&label=Star) [github](https://github.com/awesome-chatgpt/awesome-chatgpt)\n\næœ¬é¡¹ç›®æ—¨åœ¨æ”¶é›†å…³äºChatGPT çš„èµ„æºã€å·¥å…·ã€åº”ç”¨å’Œç”¨æ³•ç­‰ã€‚\n\n#### 2. Awesome-ChatGPT-Prompts ![Star](https://img.shields.io/github/stars/f/awesome-chatgpt-prompts.svg?style=social&label=Star) [github](https://github.com/f/awesome-chatgpt-prompts)\n\næœ¬é¡¹ç›®æ—¨åœ¨æ”¶é›†å…³äºChatGPT æ¨¡å‹ä½¿ç”¨çš„Promptsç¤ºä¾‹é›†ã€‚\n\n#### 3. Awesome-LLM ![Star](https://img.shields.io/github/stars/Hannibal046/Awesome-LLM.svg?style=social&label=Star) [github](https://github.com/Hannibal046/Awesome-LLM)\n\næœ¬é¡¹ç›®æ—¨åœ¨æ”¶é›†æœ‰å…³å¤§å‹è¯­è¨€æ¨¡å‹ç›¸å…³èµ„æ–™ï¼Œå°¤å…¶æ˜¯ ChatGPT çš„è®ºæ–‡çš„ç²¾é€‰åˆ—è¡¨ã€‚å®ƒè¿˜åŒ…å« LLM è®­ç»ƒæ¡†æ¶ã€éƒ¨ç½² LLM çš„å·¥å…·ã€æœ‰å…³ LLM çš„è¯¾ç¨‹å’Œæ•™ç¨‹ä»¥åŠæ‰€æœ‰å…¬å¼€å¯ç”¨çš„ LLM æ¨¡å‹å’Œ APIã€‚\n\n#### 4. Awesome-LangChain ![Star](https://img.shields.io/github/stars/kyrolabs/awesome-langchain.svg?style=social&label=Star) [github](https://github.com/kyrolabs/awesome-langchain)\n\næœ¬é¡¹ç›®æ—¨åœ¨æ”¶é›†ä¸LangChainæœ‰å…³åº”ç”¨åˆ—è¡¨ã€‚LangChainæ˜¯ä¸€ä¸ªæƒŠäººçš„æ¡†æ¶ï¼Œå¯ä»¥åœ¨çŸ­æ—¶é—´å†…å®Œæˆç›¸å…³LLMåº”ç”¨å¼€å‘ã€‚\n\n#### 5. Awesome-Open-Gpt ![Star](https://img.shields.io/github/stars/EwingYangs/awesome-open-gpt.svg?style=social&label=Star) [github](https://github.com/EwingYangs/awesome-open-gpt)\n\næœ¬é¡¹ç›®æ—¨åœ¨æ”¶é›†å…³äºGPTå¼€æºç²¾é€‰é¡¹ç›®çš„åˆé›†ï¼ˆ170+å…¨ç½‘æœ€å…¨)ï¼Œå…¶ä¸­åŒ…æ‹¬äº†ä¸€äº›GPTé•œåƒã€GPTå¢å¼ºã€GPTæ’ä»¶ã€GPTå·¥å…·ã€GPTå¹³æ›¿çš„èŠå¤©æœºå™¨äººã€å¼€æºå¤§è¯­è¨€æ¨¡å‹ç­‰ç­‰ã€‚\n\n#### 6. Awesome-Multimodal-Large-Language-Models ![Star](https://img.shields.io/github/stars/BradyFU/Awesome-Multimodal-Large-Language-Models.svg?style=social&label=Star) [github](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models)\n\næœ¬é¡¹ç›®æ˜¯å…³äºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰çš„ç²¾é€‰åˆ—è¡¨ï¼ŒåŒ…æ‹¬æ•°æ®é›†ã€å¤šæ¨¡æ€æ¨¡å‹ã€å¤šæ¨¡æ€è¯­å¢ƒå­¦ä¹ ã€å¤šæ¨¡æ€æ€ç»´é“¾ã€llm è¾…åŠ©è§†è§‰æ¨ç†ã€åŸºç¡€æ¨¡å‹ç­‰ã€‚æ­¤åˆ—è¡¨å°†å®æ—¶æ›´æ–°ã€‚âœ¨\n\n#### 7. Awesome-Transformer-Attention ![Star](https://img.shields.io/github/stars/cmhungsteve/Awesome-Transformer-Attention.svg?style=social&label=Star) [github](https://github.com/cmhungsteve/Awesome-Transformer-Attention)\n\næ­¤ repo åŒ…å« Vision Transformer & Attention çš„ç»¼åˆè®ºæ–‡åˆ—è¡¨ï¼ŒåŒ…æ‹¬è®ºæ–‡ã€ä»£ç å’Œç›¸å…³ç½‘ç«™ã€‚\n\n#### 8. Awesome-Prompt-Engineering ![Star](https://img.shields.io/github/stars/promptslab/Awesome-Prompt-Engineering.svg?style=social&label=Star) [github](https://github.com/promptslab/Awesome-Prompt-Engineering)\n\nThis repository contains a hand-curated resources for Prompt Engineering with a focus on Generative Pre-trained Transformer (GPT), ChatGPT, PaLM etc\n\n#### 9. Awesome-AITools ![Star](https://img.shields.io/github/stars/ikaijua/Awesome-AITools.svg?style=social&label=Star) [github](https://github.com/ikaijua/Awesome-AITools)\n\nè¿™ä¸ªä»“åº“æ•´ç†AIç›¸å…³çš„å®ç”¨å·¥å…·ã€‚\n\n#### 10. Awesome-Chinese-LLM ![Star](https://img.shields.io/github/stars/HqWu-HITCS/Awesome-Chinese-LLM.svg?style=social&label=Star) [github](https://github.com/HqWu-HITCS/Awesome-Chinese-LLM)\n\næœ¬é¡¹ç›®æ—¨åœ¨æ”¶é›†å’Œæ¢³ç†ä¸­æ–‡LLMç›¸å…³çš„å¼€æºæ¨¡å‹ã€åº”ç”¨ã€æ•°æ®é›†åŠæ•™ç¨‹ç­‰èµ„æ–™ï¼Œç›®å‰æ”¶å½•çš„èµ„æºå·²è¾¾100+ä¸ªï¼\n\n#### 11. Awesome-LLM4Tool ![Star](https://img.shields.io/github/stars/OpenGVLab/Awesome-LLM4Tool.svg?style=social&label=Star) [github](https://github.com/OpenGVLab/Awesome-LLM4Tool)\n\nAwesome-LLM4Tool is a curated list of the papers, repositories, tutorials, and anythings related to the large language models for tools.\n\n#### 12. Awesome LLM Security ![Star](https://img.shields.io/github/stars/corca-ai/awesome-llm-security.svg?style=social&label=Star) [github](https://github.com/corca-ai/awesome-llm-security)\n\nA curation of awesome tools, documents and projects about LLM Security.\n\n#### 13. Awesome AI Agents ![Star](https://img.shields.io/github/stars/e2b-dev/awesome-ai-agents.svg?style=social&label=Star) [github](https://github.com/e2b-dev/awesome-ai-agents)\n\nWelcome to our list of AI agents. We structured the list into two parts: Open source projects and Closed-source projects and companies\n\n#### 14. Awesome-LLM-Large-Language-Models-Notes ![Star](https://img.shields.io/github/stars/kyaiooiayk/Awesome-LLM-Large-Language-Models-Notes.svg?style=social&label=Star) [github](https://github.com/kyaiooiayk/Awesome-LLM-Large-Language-Models-Notes)\n\nLLM-Large-Language-Models-Notes\n\n#### 15. Awesome-Efficient-LLM ![Star](https://img.shields.io/github/stars/horseee/Awesome-Efficient-LLM.svg?style=social&label=Star) [github](https://github.com/horseee/Awesome-Efficient-LLM)\n\nA curated list for Efficient Large Language Modelsã€‚\n\n#### 16. Awesome Datasets for LLM Training ![Star](https://img.shields.io/github/stars/Zjh-819/LLMDataHub.svg?style=social&label=Star) [github](https://github.com/Zjh-819/LLMDataHub)\n\nA quick guide (especially) for trending instruction finetuning datasetsã€‚\n\n#### 17. Awesome-Align-LLM-Human ![Star](https://img.shields.io/github/stars/GaryYufei/AlignLLMHumanSurvey.svg?style=social&label=Star) [github](https://github.com/GaryYufei/AlignLLMHumanSurvey)\n\nA collection of papers and resources about aligning large language models (LLMs) with human.\n\n#### 18. Awesome RLHF (RL with Human Feedback) ![Star](https://img.shields.io/github/stars/opendilab/awesome-RLHF.svg?style=social&label=Star) [github](https://github.com/opendilab/awesome-RLHF)\n\nThis is a collection of research papers for Reinforcement Learning with Human Feedback (RLHF). And the repository will be continuously updated to track the frontier of RLHF.\n\n#### 19. Prompt-in-context-learning ![Star](https://img.shields.io/github/stars/EgoAlpha/prompt-in-context-learning.svg?style=social&label=Star) [github](https://github.com/EgoAlpha/prompt-in-context-learning)\n\nAn Open-Source Engineering Guide for Prompt-in-context-learning from EgoAlpha Lab.\n\n#### 20. Awesome Instruction Learning ![Star](https://img.shields.io/github/stars/RenzeLou/awesome-instruction-learning.svg?style=social&label=Star) [github](https://github.com/RenzeLou/awesome-instruction-learning)\n\nAn awesome reading list of Instruction Tuning (or, put it more comprehensively, Instruction Learning), including papers and datasets.\n\n#### 21. Awesome-Foundation-Models ![Star](https://img.shields.io/github/stars/uncbiag/Awesome-Foundation-Models.svg?style=social&label=Star) [github](https://github.com/uncbiag/Awesome-Foundation-Models)\n\nA foundation model is a large-scale pretrained model (e.g., BERT, DALL-E, GPT-3) that can be adapted to a wide range of downstream applications. This term was first popularized by the Stanford Institute for Human-Centered Artificial Intelligence. This repository maintains a curated list of foundation models for vision and language tasks. Research papers without code are not included.\n\n#### 22. Awesome-AI-Devtools ![Star](https://img.shields.io/github/stars/jamesmurdza/awesome-ai-devtools.svg?style=social&label=Star) [github](https://github.com/jamesmurdza/awesome-ai-devtools)\n\nThis is a curated list of AI-powered developer tools. These tools leverage AI to assist developers in tasks such as code completion, refactoring, debugging, documentation, and more.\n\n#### 23. Awesome-Autonomous-GPT ![Star](https://img.shields.io/github/stars/ScarletPan/awesome-autonomous-gpt.svg?style=social&label=Star) [github](https://github.com/ScarletPan/awesome-autonomous-gpt)\n\nA curated list of awesome projects and resources related to autonomous AI agents.\n\n#### 24. Awesome-Papers-Autonomous-Agent ![Star](https://img.shields.io/github/stars/lafmdp/Awesome-Papers-Autonomous-Agent.svg?style=social&label=Star) [github](https://github.com/lafmdp/Awesome-Papers-Autonomous-Agent)\n\nThis is a collection of recent papers focusing on autonomous agent. \n\n#### 25. Awesome-Code-LLM ![Star](https://img.shields.io/github/stars/codefuse-ai/Awesome-Code-LLM.svg?style=social&label=Star) [github](https://github.com/codefuse-ai/Awesome-Code-LLM)\n\na comprehensive review of LLM researches for code. \n\n#### 26. Awesome-LLM-Compression ![Star](https://img.shields.io/github/stars/HuangOwen/Awesome-LLM-Compression.svg?style=social&label=Star) [github](https://github.com/HuangOwen/Awesome-LLM-Compression)\n\nAwesome LLM compression research papers and tools to accelerate LLM training and inference.\n\n#### 27. Autonomous-Agents ![Star](https://img.shields.io/github/stars/tmgthb/Autonomous-Agents.svg?style=social&label=Star) [github](https://github.com/tmgthb/Autonomous-Agents)\n\nAutonomous Agents (LLMs). Updated daily.\n\n#### 28. Awesome-Large-Multimodal-Agents ![Star](https://img.shields.io/github/stars/jun0wanan/awesome-large-multimodal-agents.svg?style=social&label=Star) [github](https://github.com/jun0wanan/awesome-large-multimodal-agents)\n\nAwesome Large Multimodal Agents.\n\n#### 29. Awesome-LLM-Prompt-Optimization ![Star](https://img.shields.io/github/stars/jxzhangjhu/Awesome-LLM-Prompt-Optimization.svg?style=social&label=Star) [github](https://github.com/jxzhangjhu/Awesome-LLM-Prompt-Optimization)\n\nThis repo aims to record advanced papers of LLM prompt tuning and automatic optimization (after 2022).\n\n#### 30. Awesome-LLMs-Datasets ![Star](https://img.shields.io/github/stars/lmmlzn/Awesome-LLMs-Datasets.svg?style=social&label=Star) [github](http://github.com/lmmlzn/Awesome-LLMs-Datasets)\n\nä»£è¡¨æ€§LLMæ–‡æœ¬æ•°æ®é›†å¤§åˆ—è¡¨ï¼ŒåŒ…æ‹¬é¢„è®­ç»ƒè¯­æ–™åº“ã€å¾®è°ƒæŒ‡ä»¤æ•°æ®é›†ã€åå¥½æ•°æ®é›†ã€è¯„ä¼°æ•°æ®é›†å’Œä¼ ç»ŸNLPæ•°æ®é›†.\n\n#### 30. Awesome-RAG-Survey ![Star](https://img.shields.io/github/stars/hymie122/RAG-Survey.svg?style=social&label=Star) [github](https://github.com/hymie122/RAG-Survey)\n\nThis repo is constructed for collecting and categorizing papers about RAG according to our survey paper: Retrieval-Augmented Generation for AI-Generated Content: A Survey. Considering the rapid growth of this field, we will continue to update both paper and this repo.\n\n#### 31. Awesome-Tool-LLM ![Star](https://img.shields.io/github/stars/zorazrw/awesome-tool-llm.svg?style=social&label=Star) [github](https://github.com/zorazrw/awesome-tool-llm)\n\nLanguage models (LMs) are powerful yet mostly for text-generation tasks. Tools have substantially enhanced their performance for tasks that require complex skills.\n\n#### 32. LLM-Tool-Survey ![Star](https://img.shields.io/github/stars/quchangle1/LLM-Tool-Survey.svg?style=social&label=Star) [github](https://github.com/quchangle1/LLM-Tool-Survey)\n\nRecently, tool learning with large language models~(LLMs) has emerged as a promising paradigm for augmenting the capabilities of LLMs to tackle highly complex problems.\n\nThis is the collection of papers related to tool learning with LLMs. These papers are organized according to our survey paper \"Tool Learning with Large Language Models: A Survey\".\n\n#### 33. Awesome-Foundation-Model-Leaderboards ![Star](https://img.shields.io/github/stars/SAILResearch/awesome-foundation-model-leaderboards.svg?style=social&label=Star) [github](https://github.com/SAILResearch/awesome-foundation-model-leaderboards)\n\nAwesome Foundation Model Leaderboard is a curated list of awesome foundation model leaderboards (for an explanation of what a leaderboard is, please refer to this post), along with various development tools and evaluation organizations according to our survey:.\n\n#### 34. Awesome-LLM-KV-Cache ![Star](https://img.shields.io/github/stars/Zefan-Cai/Awesome-LLM-KV-Cache.svg?style=social&label=Star) [github](https://github.com/Zefan-Cai/Awesome-LLM-KV-Cache)\n\nAwesome-LLM-KV-Cache: A curated list of ğŸ“™Awesome LLM KV Cache Papers with Codes. This repository is for personal use of learning and classifying the burning KV Cache related papers!\n\n#### 35. Awesome-LLM-Strawberry ![Star](https://img.shields.io/github/stars/hijkzzz/Awesome-LLM-Strawberry.svg?style=social&label=Star) [github](https://github.com/hijkzzz/Awesome-LLM-Strawberry)\n\nThis is a collection of research papers & blogs for OpenAI Strawberry(o1) and Reasoning.\n\nAnd the repository will be continuously updated to track the frontier of LLM Reasoning.\n\n#### 36. Awesome-LLM-Resourses ![Star](https://img.shields.io/github/stars/WangRongsheng/awesome-LLM-resourses.svg?style=social&label=Star) [github](https://github.com/WangRongsheng/awesome-LLM-resourses)\n\nğŸ§‘â€ğŸš€ å…¨ä¸–ç•Œæœ€å¥½çš„LLMèµ„æ–™æ€»ç»“ | Summary of the world's best LLM resources.\n\n#### 37. Awesome-LLM-Reasoning-Openai-o1-Survey ![Star](https://img.shields.io/github/stars/wjn1996/Awesome-LLM-Reasoning-Openai-o1-Survey.svg?style=social&label=Star) [github](https://github.com/wjn1996/Awesome-LLM-Reasoning-Openai-o1-Survey)\n\nThe related works and background techniques about OpenAI o1, including LLM reasoning, self-play reinforcement learning, complex logic reasoning, scaling law, etc.\n\n#### 38. Awesome-LLM-Reasoning ![Star](https://img.shields.io/github/stars/atfortes/Awesome-LLM-Reasoning.svg?style=social&label=Star) [github](https://github.com/atfortes/Awesome-LLM-Reasoning)\n\nCurated collection of papers and resources on how to unlock the reasoning ability of LLMs and MLLMs.\n\n#### 39. Awesome-Computer-Use-Agents ![Star](https://img.shields.io/github/stars/ranpox/awesome-computer-use.svg?style=social&label=Star) [github](https://github.com/ranpox/awesome-computer-use)\n\nThis is a collection of resources for computer-use agents, including papers and blogs. The repository is currently under construction and will be continuously updated. We welcome contributions and feedback as we continue expanding this collection!\n\n#### 40. LLM_MultiAgents_Survey_Papers ![Star](https://img.shields.io/github/stars/taichengguo/LLM_MultiAgents_Survey_Papers.svg?style=social&label=Star) [github](https://github.com/taichengguo/LLM_MultiAgents_Survey_Papers)\n\nOur survey about LLM based Multi-Agents is available at: https://arxiv.org/abs/2402.01680\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n## NLUç³»åˆ—\n\n### BERT\n\n+ 2018 | BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding | Jacob Devlin, et al. | arXiv | [`PDF`](https://arxiv.org/abs/1810.04805)\n+ 2019 | Pre-Training with Whole Word Masking for Chinese BERT | Yiming Cui, et al. | arXiv | [`PDF`](https://arxiv.org/abs/1906.08101)\n\n| æ¨¡å‹            | ç‰ˆæœ¬  | TensorFlow                                                   | PyTorch                                                      | ä½œè€…                                                  | æºåœ°å€                                                       | åº”ç”¨é¢†åŸŸ     |\n| --------------- | ----- | ------------------------------------------------------------ | ------------------------------------------------------------ | ----------------------------------------------------- | ------------------------------------------------------------ | ------------ |\n| BERT-Base       | base  | [Google Drive](https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip) |                                                              | [Google Research](https://github.com/google-research) | [github](https://github.com/google-research/bert)            | é€šç”¨         |\n| BERT-wwm        | base  | <p>[Google Drive](https://drive.google.com/open?id=1RoTQsXp2hkQ1gSRVylRIJfQxJUgkfJMW)<br>[è®¯é£äº‘-07Xj](http://pan.iflytek.com/#/link/A2483AD206EF85FD91569B498A3C3879)</p> | [Google Drive](https://drive.google.com/open?id=1AQitrjbvCWc51SYiLN-cJq4e0WiNN4KY) | [Yiming Cui](https://github.com/ymcui)                | [github](https://github.com/ymcui/Chinese-BERT-wwm)          | é€šç”¨         |\n| BERT-wwm-ext    | base  | <p>[Google Drive](https://drive.google.com/open?id=1buMLEjdtrXE2c4G1rpsNGWEx7lUQ0RHi)<br>[è®¯é£äº‘-4cMG](http://pan.iflytek.com/#/link/653637473FFF242C3869D77026C9BDB5)</p> | [Google Drive](https://drive.google.com/open?id=1iNeYFhCBJWeUsIlnW_2K6SMwXkM4gLb_) | [Yiming Cui](https://github.com/ymcui)                | [github](https://github.com/ymcui/Chinese-BERT-wwm)          | é€šç”¨         |\n| bert-base-æ°‘äº‹  | base  | [é˜¿é‡Œäº‘](https://thunlp.oss-cn-qingdao.aliyuncs.com/bert/ms.zip) |                                                              | [THUNLP](https://github.com/thunlp)                   | [github](https://github.com/thunlp/OpenCLaP)                 | å¸æ³•         |\n| bert-base-åˆ‘äº‹  | base  | [é˜¿é‡Œäº‘](https://thunlp.oss-cn-qingdao.aliyuncs.com/bert/xs.zip) |                                                              | [THUNLP](https://github.com/thunlp)                   | [github](https://github.com/thunlp/OpenCLaP)                 | å¸æ³•         |\n| BAAI-JDAI-BERT  | base  | [äº¬ä¸œäº‘](https://jdai009.s3.cn-north-1.jdcloud-oss.com/jd-aig/open/models/nlp_baai/20190918/JDAI-BERT.tar.gz?AWSAccessKeyId=86FD402DD0CB693D629F6E62DC11E0E6&Expires=1634304356&Signature=dfnLvSzXeerRPSnMsZXSoEwdmkw%3D) |                                                              | [JDAI](https://github.com/jd-aig)                     | [github](https://github.com/jd-aig/nlp_baai/tree/master/pretrained_models_and_embeddings) | ç”µå•†å®¢æœå¯¹è¯ |\n| FinBERT         | base  | <p>[Google Drive](https://drive.google.com/file/d/193B4sT63mMeh4zfge0FJbbFY447KiJXp/view?usp=sharing)<br>[ç™¾åº¦ç½‘ç›˜-1cmp](https://pan.baidu.com/share/init?surl=D-pVJyW6bbJSre5RxotJkA)</p> | <p>[Google Drive](https://drive.google.com/file/d/1qW1YWtw3q9Q28QThrIY-rDU9Gl-SLIKO/view?usp=sharing)<br>[ç™¾åº¦ç½‘ç›˜-986f](https://pan.baidu.com/share/init?surl=y_O586GBmZZ7g4d2nOF0Vg)</p> | [Value Simplex](https://github.com/valuesimplex)      | [github](https://github.com/valuesimplex/FinBERT)            | é‡‘èç§‘æŠ€é¢†åŸŸ |\n| EduBERT         | base  | [å¥½æœªæ¥AI](https://ai.100tal.com/download/TAL-EduBERT-TF.zip) | [å¥½æœªæ¥AI](https://ai.100tal.com/download/TAL-EduBERT.zip)   | [tal-tech](https://github.com/tal-tech)               | [github](https://github.com/tal-tech/edu-bert)               | æ•™è‚²é¢†åŸŸ     |\n| guwenbert-base  | base  |                                                              | <p>[ç™¾åº¦ç½‘ç›˜-4jng](https://pan.baidu.com/s/1dw_08p7CVsz0jVj4jd58lQ)<br>[[ğŸ¤—HF\\]](https://huggingface.co/ethanyt/guwenbert-base)</p> | [Ethan](https://github.com/Ethan-yt)                  | [github](https://github.com/Ethan-yt/guwenbert)              | å¤æ–‡é¢†åŸŸ     |\n| guwenbert-large | large |                                                              | <p>[ç™¾åº¦ç½‘ç›˜-m5sz](https://pan.baidu.com/s/1TL9mBIlIv2rSvp61xCkeJQ)<br>[[ğŸ¤—HF\\]](https://huggingface.co/ethanyt/guwenbert-large)</p> | [Ethan](https://github.com/Ethan-yt)                  | [github](https://github.com/Ethan-yt/guwenbert)              | å¤æ–‡é¢†åŸŸ     |\n| BERT-CCPoem     | small |                                                              | [thunlp](https://thunlp.oss-cn-qingdao.aliyuncs.com/BERT_CCPoem_v1.zip) | [THUNLP-AIPoet](https://github.com/THUNLP-AIPoet)     | [github](https://github.com/THUNLP-AIPoet/BERT-CCPoem)       | å¤å…¸è¯—æ­Œ     |\n\nå¤‡æ³¨: \n\n> wwmå…¨ç§°ä¸º**Whole Word Masking **,ä¸€ä¸ªå®Œæ•´çš„è¯çš„éƒ¨åˆ†WordPieceå­è¯è¢«maskï¼Œåˆ™åŒå±è¯¥è¯çš„å…¶ä»–éƒ¨åˆ†ä¹Ÿä¼šè¢«mask\n\n> extè¡¨ç¤ºåœ¨æ›´å¤šæ•°æ®é›†ä¸‹è®­ç»ƒ\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### ChineseBERT\n\n+ 2021 | ChineseBERT: Chinese Pretraining Enhanced by Glyph and Pinyin Information | Zijun Sun, et al. | arXiv | [`PDF`](https://arxiv.org/pdf/2106.16038.pdf)\n\n| æ¨¡å‹        | ç‰ˆæœ¬  | TensorFlow | PyTorch                                                      | ä½œè€…                                      | æºåœ°å€                                             | åº”ç”¨é¢†åŸŸ |\n| ----------- | ----- | ---------- | ------------------------------------------------------------ | ----------------------------------------- | -------------------------------------------------- | -------- |\n| ChineseBERT | base  |            | [[ğŸ¤—HF\\]](https://huggingface.co/ShannonAI/ChineseBERT-base) | [ShannonAI](https://github.com/ShannonAI) | [github](https://github.com/ShannonAI/ChineseBert) | é€šç”¨     |\n| ChineseBERT | large |            | [[ğŸ¤—HF\\]](https://huggingface.co/ShannonAI/ChineseBERT-large) | [ShannonAI](https://github.com/ShannonAI) | [github](https://github.com/ShannonAI/ChineseBert) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### RoBERTa\n\n+ 2019 | RoBERTa: A Robustly Optimized BERT Pretraining Approach | Yinhan Liu, et al. | arXiv | [`PDF`](https://arxiv.org/pdf/1907.11692.pdf)\n\n| æ¨¡å‹                   | ç‰ˆæœ¬     | TensorFlow                                                   | PyTorch                                                      | ä½œè€…                                        | æºåœ°å€                                                       | åº”ç”¨é¢†åŸŸ |\n| ---------------------- | -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------- | ------------------------------------------------------------ | -------- |\n| RoBERTa-tiny-clue      | tiny     | [Google Drive](https://storage.googleapis.com/cluebenchmark/pretrained_models/RoBERTa-tiny-clue.zip) | [ç™¾åº¦ç½‘ç›˜-8qvb](https://pan.baidu.com/share/init?surl=hoR01GbhcmnDhZxVodeO4w) | [CLUE](https://github.com/CLUEbenchmark)    | [github](https://github.com/CLUEbenchmark/CLUEPretrainedModels) | é€šç”¨     |\n| RoBERTa-tiny-pair      | tiny     | [google drive](https://storage.googleapis.com/cluebenchmark/pretrained_models/RoBERTa-tiny-pair.zip) | [ç™¾åº¦ç½‘ç›˜-8qvb](https://pan.baidu.com/share/init?surl=hoR01GbhcmnDhZxVodeO4w) | [CLUE](https://github.com/CLUEbenchmark)    | [github](https://github.com/CLUEbenchmark/CLUEPretrainedModels) | é€šç”¨     |\n| RoBERTa-tiny3L768-clue | tiny     | [Google Drive](https://storage.googleapis.com/cluebenchmark/pretrained_models/RoBERTa-tiny3L768-clue.zip) |                                                              | [CLUE](https://github.com/CLUEbenchmark)    | [github](https://github.com/CLUEbenchmark/CLUEPretrainedModels) | é€šç”¨     |\n| RoBERTa-tiny3L312-clue | tiny     | [google drive](https://storage.googleapis.com/cluebenchmark/pretrained_models/RoBERTa-tiny3L312-clue.zip) | [ç™¾åº¦ç½‘ç›˜-8qvb](https://pan.baidu.com/share/init?surl=hoR01GbhcmnDhZxVodeO4w) | [CLUE](https://github.com/CLUEbenchmark)    | [github](https://github.com/CLUEbenchmark/CLUEPretrainedModels) | é€šç”¨     |\n| RoBERTa-large-pair     | large    | [Google Drive](https://storage.googleapis.com/cluebenchmark/pretrained_models/RoBERTa-large-pair.zip) | [ç™¾åº¦ç½‘ç›˜-8qvb](https://pan.baidu.com/share/init?surl=hoR01GbhcmnDhZxVodeO4w) | [CLUE](https://github.com/CLUEbenchmark)    | [github](https://github.com/CLUEbenchmark/CLUEPretrainedModels) | é€šç”¨     |\n| RoBERTa-large-clue     | large    | [google drive](https://storage.googleapis.com/cluebenchmark/pretrained_models/RoBERTa-large-clue.zip) | [ç™¾åº¦ç½‘ç›˜-8qvb](https://pan.baidu.com/share/init?surl=hoR01GbhcmnDhZxVodeO4w) | [CLUE](https://github.com/CLUEbenchmark)    | [github](https://github.com/CLUEbenchmark/CLUEPretrainedModels) | é€šç”¨     |\n| RBT3                   | 3å±‚base  | <p>[Google Drive](https://drive.google.com/file/d/1-rvV0nBDvRCASbRz8M9Decc3_8Aw-2yi/view?usp=drive_open)<br>[è®¯é£äº‘-b9nx](https://pan.iflytek.com/link/275E5B46185C982D4AF5AC295E1651B6)</p> | [Google Drive](https://drive.google.com/file/d/1_LqmIxm8Nz1Abvlqb8QFZaxYo-TInOed/view) | [Yiming Cui](https://github.com/ymcui)      | [github](https://github.com/ymcui/Chinese-BERT-wwm)          | é€šç”¨     |\n| RBTL3                  | 3å±‚large | <p>[Google Drive](https://drive.google.com/open?id=1Jzn1hYwmv0kXkfTeIvNT61Rn1IbRc-o8)<br>[è®¯é£äº‘-vySW](https://pan.iflytek.com/link/0DD18FAC080BAF75DBA28FB5C0047760)</p> | [Google Drive](https://drive.google.com/open?id=1eHM3l4fMo6DsQYGmey7UZGiTmQquHw25) | [Yiming Cui](https://github.com/ymcui)      | [github](https://github.com/ymcui/Chinese-BERT-wwm)          | é€šç”¨     |\n| RBTL4                  | 4å±‚large | [è®¯é£äº‘-e8dN](http://pan.iflytek.com/link/7B04C5BF09812DB241BBA973D649824C) |                                                              | [Yiming Cui](https://github.com/ymcui)      | [github](https://github.com/ymcui/Chinese-BERT-wwm)          | é€šç”¨     |\n| RBTL6                  | 6å±‚large | [è®¯é£äº‘-XNMA](http://pan.iflytek.com/link/B935B1F701A8FD352CAA74614126C4A2) |                                                              | [Yiming Cui](https://github.com/ymcui)      | [github](https://github.com/ymcui/Chinese-BERT-wwm)          | é€šç”¨     |\n| RoBERTa-wwm-ext        | base     | <p>[Google Drive](https://drive.google.com/open?id=1jMAKIJmPn7kADgD3yQZhpsqM-IRM1qZt)<br>[è®¯é£äº‘-Xe1p](http://pan.iflytek.com/#/link/98D11FAAF0F0DBCB094EE19CCDBC98BF)</p> | [Google Drive](https://drive.google.com/open?id=1eHM3l4fMo6DsQYGmey7UZGiTmQquHw25) | [Yiming Cui](https://github.com/ymcui)      | [github](https://github.com/ymcui/Chinese-BERT-wwm)          | é€šç”¨     |\n| RoBERTa-wwm-ext-large  | large    | <p>[Google Drive](https://drive.google.com/open?id=1dtad0FFzG11CBsawu8hvwwzU2R0FDI94)<br>[è®¯é£äº‘-u6gC](http://pan.iflytek.com/#/link/AC056611607108F33A744A0F56D0F6BE)</p> | [Google Drive](https://drive.google.com/open?id=1-2vEZfIFCdM1-vJ3GD6DlSyKT4eVXMKq) | [Yiming Cui](https://github.com/ymcui)      | [github](https://github.com/ymcui/Chinese-BERT-wwm)          | é€šç”¨     |\n| RoBERTa-base           | base     | <p>[Google Drive](https://drive.google.com/open?id=1ykENKV7dIFAqRRQbZIh0mSb7Vjc2MeFA)<br>[ç™¾åº¦ç½‘ç›˜](https://pan.baidu.com/s/1hAs7-VSn5HZWxBHQMHKkrg)</p> | <p>[Google Drive](https://drive.google.com/open?id=1H6f4tYlGXgug1DdhYzQVBuwIGAkAflwB)<br>[ç™¾åº¦ç½‘ç›˜](https://pan.baidu.com/s/1AGC76N7pZOzWuo8ua1AZfw)</p> | [brightmart](https://github.com/brightmart) | [github](https://github.com/brightmart/roberta_zh)           | é€šç”¨     |\n| RoBERTa-Large          | large    | <p>[Google Drive](https://drive.google.com/open?id=1W3WgPJWGVKlU9wpUYsdZuurAIFKvrl_Y)<br>[ç™¾åº¦ç½‘ç›˜](https://pan.baidu.com/s/1Rk_QWqd7-wBTwycr91bmug)</p> | [Google Drive](https://drive.google.com/open?id=1yK_P8VhWZtdgzaG0gJ3zUGOKWODitKXZ) | [brightmart](https://github.com/brightmart) | [github](https://github.com/brightmart/roberta_zh)           | é€šç”¨     |\n| RoBERTa-tiny           | tiny     | [[ğŸ¤—HF\\]](https://huggingface.co/uer)                    | [[ğŸ¤—HF\\]](https://huggingface.co/uer)                    | [DBIIR @ RUC](https://github.com/dbiir)     | [UER](https://github.com/dbiir/UER-py)                       | é€šç”¨     |\n| RoBERTa-mini           | mini     | [[ğŸ¤—HF\\]](https://huggingface.co/uer)                    | [[ğŸ¤—HF\\]](https://huggingface.co/uer)                    | [DBIIR @ RUC](https://github.com/dbiir)     | [UER](https://github.com/dbiir/UER-py)                       | é€šç”¨     |\n| RoBERTa-small          | small    | [[ğŸ¤—HF\\]](https://huggingface.co/uer)                    | [[ğŸ¤—HF\\]](https://huggingface.co/uer)                    | [DBIIR @ RUC](https://github.com/dbiir)     | [UER](https://github.com/dbiir/UER-py)                       | é€šç”¨     |\n| RoBERTa-medium         | medium   | [[ğŸ¤—HF\\]](https://huggingface.co/uer)                    | [[ğŸ¤—HF\\]](https://huggingface.co/uer)                    | [DBIIR @ RUC](https://github.com/dbiir)     | [UER](https://github.com/dbiir/UER-py)                       | é€šç”¨     |\n| RoBERTa-base           | base     | [[ğŸ¤—HF\\]](https://huggingface.co/uer)                    | [[ğŸ¤—HF\\]](https://huggingface.co/uer)                    | [DBIIR @ RUC](https://github.com/dbiir)     | [UER](https://github.com/dbiir/UER-py)                       | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### ALBERT\n\n+ 2019 | ALBERT: A Lite BERT For Self-Supervised Learning Of Language Representations | Zhenzhong Lan, et al. | arXiv | [`PDF`](https://arxiv.org/pdf/1909.11942.pdf)\n\n| æ¨¡å‹             | ç‰ˆæœ¬    | TensorFlow                                                   | PyTorch                                                      | ä½œè€…                                                  | æºåœ°å€                                              | åº”ç”¨é¢†åŸŸ |\n| ---------------- | ------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ----------------------------------------------------- | --------------------------------------------------- | -------- |\n| Albert_tiny      | tiny    | [Google Drive](https://storage.googleapis.com/albert_zh/albert_tiny_489k.zip) | [Google Drive](https://drive.google.com/open?id=1VBsUJ7R5eWF1VcUBQY6BEn1a9miEvlBr) | [brightmart](https://github.com/brightmart)           | [github](https://github.com/brightmart/albert_zh)   | é€šç”¨     |\n| Albert_base_zh   | base    | [Google Drive](https://storage.googleapis.com/albert_zh/albert_base_zh_additional_36k_steps.zip) | [Google Drive](https://drive.google.com/open?id=1HeijHGubWR-ElFnfxUf8IrRx7Ghm1S_Q) | [brightmart](https://github.com/brightmart)           | [github](https://github.com/brightmart/albert_zh)   | é€šç”¨     |\n| Albert_large_zh  | large   | [Google Drive](https://storage.googleapis.com/albert_zh/albert_large_zh.zip) | [Google Drive](https://drive.google.com/open?id=1TAuv7OiFN8qbkT6S_VbfVbhkhg2GUF3q) | [brightmart](https://github.com/brightmart)           | [github](https://github.com/brightmart/albert_zh)   | é€šç”¨     |\n| Albert_xlarge_zh | xlarge  | [Google Drive](https://storage.googleapis.com/albert_zh/albert_xlarge_zh_183k.zip) | [Google Drive](https://drive.google.com/open?id=1kMhogQRX0uGWIGdNhm7-3hsmHlrzY_gp) | [brightmart](https://github.com/brightmart)           | [github](https://github.com/brightmart/albert_zh)   | é€šç”¨     |\n| Albert_base      | base    | [Google Drive](https://storage.googleapis.com/albert_models/albert_base_zh.tar.gz) |                                                              | [Google Research](https://github.com/google-research) | [github](https://github.com/google-research/ALBERT) | é€šç”¨     |\n| Albert_large     | large   | [Google Drive](https://storage.googleapis.com/albert_models/albert_large_zh.tar.gz) |                                                              | [Google Research](https://github.com/google-research) | [github](https://github.com/google-research/ALBERT) | é€šç”¨     |\n| Albert_xlarge    | xlarge  | [Google Drive](https://storage.googleapis.com/albert_models/albert_xlarge_zh.tar.gz) |                                                              | [Google Research](https://github.com/google-research) | [github](https://github.com/google-research/ALBERT) | é€šç”¨     |\n| Albert_xxlarge   | xxlarge | [Google Drive](https://storage.googleapis.com/albert_models/albert_xxlarge_zh.tar.gz) |                                                              | [Google Research](https://github.com/google-research) | [github](https://github.com/google-research/ALBERT) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### NEZHA\n\n+ 2019 | NEZHA: Neural Contextualized Representation for Chinese Language Understanding | Junqiu Wei, et al. | arXiv | [`PDF`](https://arxiv.org/abs/1909.00204)\n\n| æ¨¡å‹                           | ç‰ˆæœ¬  | TensorFlow                                                   | PyTorch                                                      | ä½œè€…                                                    | æºåœ°å€                                                       | åº”ç”¨é¢†åŸŸ |\n| ------------------------------ | ----- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------- | ------------------------------------------------------------ | -------- |\n| NEZHA-base                     | base  | <p>[Google Drive](https://drive.google.com/drive/folders/1tFs-wMoXIY8zganI2hQgDBoDPqA8pSmh?usp=sharing)<br>[ç™¾åº¦ç½‘ç›˜-ntn3](https://pan.baidu.com/s/1UVQjy9v_Sv4cQd1ELdjqww)</p> | [lonePatient](https://github.com/lonePatient/NeZha_Chinese_PyTorch) | [HUAWEI](https://github.com/huawei-noah)                | [github](https://github.com/huawei-noah/Pretrained-Language-Model) | é€šç”¨     |\n| NEZHA-base-wwm                 | base  | <p>[Google Drive](https://drive.google.com/drive/folders/1bK6WbqAG-B6BX2d9RPprnh2MPK6zL0t_?usp=sharing)<br>[ç™¾åº¦ç½‘ç›˜-f68o](https://pan.baidu.com/s/1-YG8e5V2zKCnR3azsGZT1w)</p> | [lonePatient](https://github.com/lonePatient/NeZha_Chinese_PyTorch) | [HUAWEI](https://github.com/huawei-noah)                | [github](https://github.com/huawei-noah/Pretrained-Language-Model) | é€šç”¨     |\n| NEZHA-large                    | large | <p>[Google Drive](https://drive.google.com/drive/folders/1ZPPM5XtTTOrS_CDRak1t2nCBU-LFZ_zs?usp=sharing)<br>[ç™¾åº¦ç½‘ç›˜-7thu](https://pan.baidu.com/s/1R1Ew-Lu8oIP6QhWO6nqp5Q)</p> | [lonePatient](https://github.com/lonePatient/NeZha_Chinese_PyTorch) | [HUAWEI](https://github.com/huawei-noah)                | [github](https://github.com/huawei-noah/Pretrained-Language-Model) | é€šç”¨     |\n| NEZHA-large-wwm                | large | <p>[Google Drive](https://drive.google.com/drive/folders/1LOAUc9LXyogC2gmP_q1ojqj41Ez01aga?usp=sharing)<br>[ç™¾åº¦ç½‘ç›˜-ni4o](https://pan.baidu.com/s/1JK1RLIJd2wpuypku3stt8w)</p> | [lonePatient](https://github.com/lonePatient/NeZha_Chinese_PyTorch) | [HUAWEI](https://github.com/huawei-noah)                | [github](https://github.com/huawei-noah/Pretrained-Language-Model) | é€šç”¨     |\n| <p>WoNEZHA</br>(word-base)</p> | base  | [ç™¾åº¦ç½‘ç›˜-qgkq](https://pan.baidu.com/s/1ABKwUuIiMEEsRXxxlbyKmw) |                                                              | [ZhuiyiTechnology](https://github.com/ZhuiyiTechnology) | [github](https://github.com/ZhuiyiTechnology/WoBERT)         | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### MacBERT\n\n+ 2020 | Revisiting Pre-Trained Models for Chinese Natural Language Processing | Yiming Cui, et al. | arXiv | [`PDF`](https://arxiv.org/pdf/2004.13922.pdf)\n\n| æ¨¡å‹          | ç‰ˆæœ¬  | TensorFlow                                                   | PyTorch | ä½œè€…                                   | æºåœ°å€                                     | åº”ç”¨é¢†åŸŸ |\n| ------------- | ----- | ------------------------------------------------------------ | ------- | -------------------------------------- | ------------------------------------------ | -------- |\n| MacBERT-base  | base  | <p>[Google Drive](https://drive.google.com/file/d/1aV69OhYzIwj_hn-kO1RiBa-m8QAusQ5b/view?usp=sharing)<br>[è®¯é£äº‘-E2cP](http://pan.iflytek.com/#/link/CF2A1F9AEBF859650E8956854A994C1B)</p> |         | [Yiming Cui](https://github.com/ymcui) | [github](https://github.com/ymcui/MacBERT) | é€šç”¨     |\n| MacBERT-large | large | <p>[Google Drive](https://drive.google.com/file/d/1lWYxnk1EqTA2Q20_IShxBrCPc5VSDCkT/view?usp=sharing)<br>[è®¯é£äº‘-3Yg3](http://pan.iflytek.com/#/link/805D743F3826EC4F4EB5C774D34432AE)</p> |         | [Yiming Cui](https://github.com/ymcui) | [github](https://github.com/ymcui/MacBERT) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### WoBERT\n\n+ 2020 | æé€Ÿä¸æ‰ç‚¹ï¼šåŸºäºè¯é¢—ç²’åº¦çš„ä¸­æ–‡WoBERT | è‹å‰‘æ—. | spaces | [`Blog post`](https://kexue.fm/archives/7758)\n\n| æ¨¡å‹        | ç‰ˆæœ¬ | TensorFlow                                                   | PyTorch | ä½œè€…                                                    | æºåœ°å€                                               | åº”ç”¨é¢†åŸŸ |\n| ----------- | ---- | ------------------------------------------------------------ | ------- | ------------------------------------------------------- | ---------------------------------------------------- | -------- |\n| WoBERT      | base | [ç™¾åº¦ç½‘ç›˜-kim2](https://pan.baidu.com/s/1BrdFSx9_n1q2uWBiQrpalw) |         | [ZhuiyiTechnology](https://github.com/ZhuiyiTechnology) | [github](https://github.com/ZhuiyiTechnology/WoBERT) | é€šç”¨     |\n| WoBERT-plus | base | [ç™¾åº¦ç½‘ç›˜-aedw](https://pan.baidu.com/s/1Ltq3ltQsyBCj56zoOOvI9A) |         | [ZhuiyiTechnology](https://github.com/ZhuiyiTechnology) | [github](https://github.com/ZhuiyiTechnology/WoBERT) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### XLNET\n\n+ 2019 | XLNet: Generalized Autoregressive Pretraining for Language Understanding | Zhilin Yang, et al. | arXiv | [`PDF`](https://arxiv.org/abs/1906.08237)\n\n| æ¨¡å‹           | ç‰ˆæœ¬   | TensorFlow                                                   | PyTorch                                                      | ä½œè€…                                        | æºåœ°å€                                           | åº”ç”¨é¢†åŸŸ |\n| -------------- | ------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------- | ------------------------------------------------ | -------- |\n| XLNet-base     | base   | <p>[Google Drive](https://drive.google.com/open?id=1m9t-a4gKimbkP5rqGXXsEAEPhJSZ8tvx)<br>[è®¯é£äº‘-uCpe](http://pan.iflytek.com/#/link/32619C31BDEFAF2D82CB8C7F66F01D5C)</p> | [Google Drive](https://drive.google.com/open?id=1mPDgcMfpqAf2wk9Nl8OaMj654pYrWXaR) | [Yiming Cui](https://github.com/ymcui)      | [github](https://github.com/ymcui/Chinese-XLNet) | é€šç”¨     |\n| XLNet-mid      | middle | <p>[Google Drive](https://drive.google.com/open?id=1342uBc7ZmQwV6Hm6eUIN_OnBSz1LcvfA)<br>[è®¯é£äº‘-68En](http://pan.iflytek.com/#/link/ED7DF7ED04B871AFE8E4D97704B9134D)</p> | [Google Drive](https://drive.google.com/open?id=1u-UmsJGy5wkXgbNK4w9uRnC0RxHLXhxy) | [Yiming Cui](https://github.com/ymcui)      | [github](https://github.com/ymcui/Chinese-XLNet) | é€šç”¨     |\n| XLNet_zh_Large | large  | [ç™¾åº¦ç½‘ç›˜](https://pan.baidu.com/s/1dy0Z27DoZdMpSmoz1Q4G5A)  |                                                              | [brightmart](https://github.com/brightmart) | [github](https://github.com/brightmart/xlnet_zh) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### ELECTRA\n\n+ 2020 | ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators | Kevin Clark, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2003.10555)\n\n| æ¨¡å‹                  | ç‰ˆæœ¬  | TensorFlow                                                   | PyTorch | ä½œè€…                                     | æºåœ°å€                                             | åº”ç”¨é¢†åŸŸ |\n| --------------------- | ----- | ------------------------------------------------------------ | ------- | ---------------------------------------- | -------------------------------------------------- | -------- |\n| ELECTRA-180g-large    | large | <p>[Google Drive](https://drive.google.com/file/d/1P9yAuW0-HR7WvZ2r2weTnx3slo6f5u9q/view?usp=sharing)<br>[è®¯é£äº‘-Yfcy](http://pan.iflytek.com/#/link/7605874F5A11CD693C60EAB79005CCF3)</p> |         | [Yiming Cui](https://github.com/ymcui)   | [github](https://github.com/ymcui/Chinese-ELECTRA) | é€šç”¨     |\n| ELECTRA-180g-small-ex | small | <p>[Google Drive](https://drive.google.com/file/d/1NYJTKH1dWzrIBi86VSUK-Ml9Dsso_kuf/view?usp=sharing)<br>[è®¯é£äº‘-GUdp](http://pan.iflytek.com/#/link/3EFCF909FC5CFEA6F0EA7AA774C64CF0)</p> |         | [Yiming Cui](https://github.com/ymcui)   | [github](https://github.com/ymcui/Chinese-ELECTRA) | é€šç”¨     |\n| ELECTRA-180g-base     | base  | <p>[Google Drive](https://drive.google.com/file/d/1RlmfBgyEwKVBFagafYvJgyCGuj7cTHfh/view?usp=sharing)<br>[è®¯é£äº‘-Xcvm](http://pan.iflytek.com/#/link/38E14C9BDBE8E93F09DFE2198E308489)</p> |         | [Yiming Cui](https://github.com/ymcui)   | [github](https://github.com/ymcui/Chinese-ELECTRA) | é€šç”¨     |\n| ELECTRA-180g-small    | small | <p>[Google Drive](https://drive.google.com/file/d/177EVNTQpH2BRW-35-0LNLjV86MuDnEmu/view?usp=sharing)<br>[è®¯é£äº‘-qsHj](http://pan.iflytek.com/#/link/D1B8FE678FA5BC31AA43BD99AD09913E)</p> |         | [Yiming Cui](https://github.com/ymcui)   | [github](https://github.com/ymcui/Chinese-ELECTRA) | é€šç”¨     |\n| legal-ELECTRA-large   | large | <p>[Google Drive](https://drive.google.com/file/d/1jPyVi_t4QmTkFy7PD-m-hG-lQ8cIETzD/view?usp=sharing)<br>[è®¯é£äº‘-7f7b](http://pan.iflytek.com/#/link/CC111ED9B1D4AE7E26C69A520A6D8759)</p> |         | [Yiming Cui](https://github.com/ymcui)   | [github](https://github.com/ymcui/Chinese-ELECTRA) | å¸æ³•é¢†åŸŸ |\n| legal-ELECTRA-base    | base  | <p>[Google Drive](https://drive.google.com/file/d/12ZLaoFgpqGJxSi_9KiQV-jdVN4XRGMiD/view?usp=sharing)<br>[è®¯é£äº‘-7f7b](http://pan.iflytek.com/#/link/CC111ED9B1D4AE7E26C69A520A6D8759)</p> |         | [Yiming Cui](https://github.com/ymcui)   | [github](https://github.com/ymcui/Chinese-ELECTRA) | å¸æ³•é¢†åŸŸ |\n| legal-ELECTRA-small   | small | <p>[Google Drive](https://drive.google.com/file/d/1arQ5qNTNoc1OyMH8wBUKdTMy2QponIFY/view?usp=sharing)<br>[è®¯é£äº‘-7f7b](http://pan.iflytek.com/#/link/CC111ED9B1D4AE7E26C69A520A6D8759)</p> |         | [Yiming Cui](https://github.com/ymcui)   | [github](https://github.com/ymcui/Chinese-ELECTRA) | å¸æ³•é¢†åŸŸ |\n| ELECTRA-tiny          | tiny  | <p>[Google Drive](https://drive.google.com/file/d/1UP4byt4-kgenwST0KvyMYNbln6FfaSLp/view?usp=sharing)<br>[ç™¾åº¦ç½‘ç›˜-rs99](https://pan.baidu.com/share/init?surl=4b-IiCkjRg-6XIYPXnezZA)</p> |         | [CLUE](https://github.com/CLUEbenchmark) | [github](https://github.com/CLUEbenchmark/ELECTRA) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### ZEN\n\n+ 2019 | ZEN: Pre-training Chinese Text Encoder Enhanced by N-gram Representations | Shizhe Diao, et al. | arXiv | [`PDF`](https://arxiv.org/pdf/1911.00720.pdf)\n+ 2021 | ZEN 2.0: Continue Training and Adaption for N-gram Enhanced Text Encoders | Yan Song, et al. | arXiv | [`PDF`](https://arxiv.org/pdf/2105.01279.pdf)\n\n| æ¨¡å‹            | ç‰ˆæœ¬  | TensorFlow | PyTorch                                                      | ä½œè€…                                                         | æºåœ°å€                                                 | åº”ç”¨é¢†åŸŸ |\n| --------------- | ----- | ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------ | -------- |\n| ZEN-Base        | base  |            | <p>[Google Drive](https://drive.google.com/open?id=1oxNdYMQOpFe3QlttH98bAqg_FQiiVeMr)<br>[ç™¾åº¦ç½‘ç›˜](https://pan.baidu.com/s/1E2ylFnzGSkwBc8tY_OqZYg)</p> | [Sinovation Ventures AI Institute](https://github.com/sinovation) | [github](https://github.com/sinovation/ZEN)            | é€šç”¨     |\n| Erlangshen-ZEN2 | large |            | [[ğŸ¤—HF\\]](https://huggingface.co/IDEA-CCNL/Erlangshen-ZEN2-668M-Chinese) | [IDEA-CCNL](https://github.com/IDEA-CCNL)                    | [github](https://github.com/IDEA-CCNL/Fengshenbang-LM) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### ERNIE\n\n+ 2019 | ERNIE: Enhanced Representation through Knowledge Integration | Yu Sun, et al. | arXiv | [`PDF`](https://arxiv.org/abs/1904.09223)\n\n+ 2020 | SKEP: Sentiment Knowledge Enhanced Pre-training for Sentiment Analysis | Hao Tian, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2005.05635)\n\n+ 2020 | ERNIE-Gram: Pre-Training with Explicitly N-Gram Masked Language Modeling for Natural Language Understanding | Dongling Xiao, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2010.12148)\n\n| æ¨¡å‹                 | ç‰ˆæœ¬  | PaddlePaddle                                                 | PyTorch | ä½œè€…                                            | æºåœ°å€                                                       | åº”ç”¨é¢†åŸŸ |\n| -------------------- | ----- | ------------------------------------------------------------ | ------- | ----------------------------------------------- | ------------------------------------------------------------ | -------- |\n| ernie-1.0-base       | base  | [link](https://ernie-github.cdn.bcebos.com/model-ernie1.0.1.tar.gz) |         | [PaddlePaddle](https://github.com/PaddlePaddle) | [github](https://github.com/PaddlePaddle/ERNIE)              | é€šç”¨     |\n| ernie_1.0_skep_large | large | [link](https://senta.bj.bcebos.com/skep/ernie_1.0_skep_large_ch.tar.gz) |         | [Baidu](https://github.com/baidu)               | [github](https://github.com/baidu/Senta)                     | æƒ…æ„Ÿåˆ†æ |\n| ernie-gram           | base  | [link](https://ernie-github.cdn.bcebos.com/model-ernie-gram-zh.1.tar.gz) |         | [Baidu](https://github.com/baidu)               | [github](https://github.com/PaddlePaddle/ERNIE/tree/develop/ernie-gram) | é€šç”¨     |\n\nå¤‡æ³¨: \n\n> PaddlePaddleè½¬TensorFlowå¯å‚è€ƒ: [tensorflow_ernie](https://github.com/ArthurRizar/tensorflow_ernie)\n\n> PaddlePaddleè½¬PyTorchå¯å‚è€ƒ: [ERNIE-Pytorch](https://github.com/nghuyong/ERNIE-Pytorch)\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### ERNIE3\n\n+ 2021 | ERNIE 3.0: Large-scale Knowledge Enhanced Pre-training for Language Understanding and Generation | Yu Sun, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2107.02137)\n\n+ 2021 | ERNIE 3.0 Titan: Exploring Larger-scale Knowledge Enhanced Pre-training for Language Understanding and Generation | Shuohuan Wang, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2106.02241)\n\n| æ¨¡å‹             | ç‰ˆæœ¬                           | PaddlePaddle                                                 | PyTorch                                                      | ä½œè€…                                            | æºåœ°å€                                                       | åº”ç”¨é¢†åŸŸ |\n| ---------------- | ------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ----------------------------------------------- | ------------------------------------------------------------ | -------- |\n| ernie-3.0-base   | 12-layer, 768-hidden, 12-heads | [link](https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_base_zh.pdparams) | [[ğŸ¤—HF\\]](https://huggingface.co/nghuyong/ernie-3.0-base-zh) | [PaddlePaddle](https://github.com/PaddlePaddle) | [github](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/model_zoo/ernie-3.0) | é€šç”¨     |\n| ernie-3.0-medium | 6-layer, 768-hidden, 12-heads  | [link](https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_medium_zh.pdparams) | [[ğŸ¤—HF\\]](https://huggingface.co/nghuyong/ernie-3.0-medium-zh) | [PaddlePaddle](https://github.com/PaddlePaddle) | [github](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/model_zoo/ernie-3.0) | é€šç”¨     |\n| ernie-3.0-mini   | 6-layer, 384-hidden, 12-heads  | [link](https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_mini_zh.pdparams) | [[ğŸ¤—HF\\]](https://huggingface.co/nghuyong/ernie-3.0-mini-zh) | [PaddlePaddle](https://github.com/PaddlePaddle) | [github](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/model_zoo/ernie-3.0) | é€šç”¨     |\n| ernie-3.0-micro  | 4-layer, 384-hidden, 12-heads  | [link](https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_micro_zh.pdparams) | [[ğŸ¤—HF\\]](https://huggingface.co/nghuyong/ernie-3.0-micro-zh) | [PaddlePaddle](https://github.com/PaddlePaddle) | [github](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/model_zoo/ernie-3.0) | é€šç”¨     |\n| ernie-3.0-nano   | 4-layer, 312-hidden, 12-heads  | [link](https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_nano_zh.pdparams) | [[ğŸ¤—HF\\]](https://huggingface.co/nghuyong/ernie-3.0-nano-zh) | [PaddlePaddle](https://github.com/PaddlePaddle) | [github](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/model_zoo/ernie-3.0) | é€šç”¨     |\n\n> PaddlePaddleè½¬PyTorchå¯å‚è€ƒ: [ERNIE-Pytorch](https://github.com/nghuyong/ERNIE-Pytorch)\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n\n### RoFormer\n\n+ 2021 | RoFormer: Enhanced Transformer with Rotary Position Embedding | Jianlin Su, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2104.09864)\n\n+ 2021 | Transformerå‡çº§ä¹‹è·¯ï¼š2ã€åšé‡‡ä¼—é•¿çš„æ—‹è½¬å¼ä½ç½®ç¼–ç  | è‹å‰‘æ—. | spaces | [`Blog post`](https://kexue.fm/archives/8265)\n\n| æ¨¡å‹          | ç‰ˆæœ¬       | TensorFlow                                                   | PyTorch | ä½œè€…                                                    | æºåœ°å€                                                    | åº”ç”¨é¢†åŸŸ |\n| ------------- | ---------- | ------------------------------------------------------------ | ------- | ------------------------------------------------------- | --------------------------------------------------------- | -------- |\n| roformer      | base(L12)  | [ç™¾åº¦ç½‘ç›˜-xy9x](https://pan.baidu.com/s/1fiss862YsGCwf2HvU_Jm-g) |         | [ZhuiyiTechnology](https://github.com/ZhuiyiTechnology) | [github](https://github.com/ZhuiyiTechnology/roformer)    | é€šç”¨     |\n| roformer      | small(L6)  | [ç™¾åº¦ç½‘ç›˜-gy97](https://pan.baidu.com/s/1iIXgZHHCgrYGXVRRSSCVPg) |         | [ZhuiyiTechnology](https://github.com/ZhuiyiTechnology) | [github](https://github.com/ZhuiyiTechnology/roformer)    | é€šç”¨     |\n| roformer-char | base(L12)  | [ç™¾åº¦ç½‘ç›˜-bt94](https://pan.baidu.com/s/1Q1pq8F4Fsl6bTipUAkqeDQ) |         | [ZhuiyiTechnology](https://github.com/ZhuiyiTechnology) | [github](https://github.com/ZhuiyiTechnology/roformer)    | é€šç”¨     |\n| roformerV2    | small(L6)  | [ç™¾åº¦ç½‘ç›˜-ttn4](https://pan.baidu.com/s/1huUrC9P60Afggo8AfiUcmA)[è¿½ä¸€](https://open.zhuiyi.ai/releases/nlp/models/zhuiyi/chinese_roformer-v2-char_L-6_H-384_A-6.zip) |         | [ZhuiyiTechnology](https://github.com/ZhuiyiTechnology) | [github](https://github.com/ZhuiyiTechnology/roformer-v2) | é€šç”¨     |\n| roformerV2    | base(L12)  | [ç™¾åº¦ç½‘ç›˜-pfoh](https://pan.baidu.com/s/1qcnN4LVKVe0-mnHlkN3-6Q)[è¿½ä¸€](https://open.zhuiyi.ai/releases/nlp/models/zhuiyi/chinese_roformer-v2-char_L-12_H-768_A-12.zip) |         | [ZhuiyiTechnology](https://github.com/ZhuiyiTechnology) | [github](https://github.com/ZhuiyiTechnology/roformer-v2) | é€šç”¨     |\n| roformerV2    | large(L24) | [ç™¾åº¦ç½‘ç›˜-npfv](https://pan.baidu.com/s/1QiJWSZrGxn8vek-8myvL6w)[è¿½ä¸€](https://open.zhuiyi.ai/releases/nlp/models/zhuiyi/chinese_roformer-v2-char_L-24_H-1024_A-16.zip) |         | [ZhuiyiTechnology](https://github.com/ZhuiyiTechnology) | [github](https://github.com/ZhuiyiTechnology/roformer-v2) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### StructBERT\n\n+ 2019 | StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding | Wei Wang, et al. | arXiv | [`PDF`](https://arxiv.org/abs/1908.04577)\n\n| æ¨¡å‹       | ç‰ˆæœ¬       | TensorFlow | PyTorch                                                      | ä½œè€…                                  | æºåœ°å€                                                       | åº”ç”¨é¢†åŸŸ |\n| ---------- | ---------- | ---------- | ------------------------------------------------------------ | ------------------------------------- | ------------------------------------------------------------ | -------- |\n| StructBERT | large(L24) |            | [é˜¿é‡Œäº‘](https://alice-open.oss-cn-zhangjiakou.aliyuncs.com/StructBERT/ch_model) | [Alibaba](https://github.com/alibaba) | [github](https://github.com/alibaba/AliceMind/tree/main/StructBERT) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### Lattice-BERT\n\n+ 2021 | Lattice-BERT: Leveraging Multi-Granularity Representations in Chinese Pre-trained Language Models | Yuxuan Lai, et al. | arXiv | [`PDF`](https://arxiv.org/pdf/2104.07204.pdf)\n\n| æ¨¡å‹        | ç‰ˆæœ¬      | TensorFlow | PyTorch                                                      | ä½œè€…                                  | æºåœ°å€                                                       | åº”ç”¨é¢†åŸŸ |\n| ----------- | --------- | ---------- | ------------------------------------------------------------ | ------------------------------------- | ------------------------------------------------------------ | -------- |\n| LatticeBERT | tiny(L4)  |            | [é˜¿é‡Œäº‘](https://alice-open.oss-cn-zhangjiakou.aliyuncs.com/LatticeBERT/chinese_labert-tiny-std-512.tar.gz) | [Alibaba](https://github.com/alibaba) | [github](https://github.com/alibaba/AliceMind/tree/main/LatticeBERT) | é€šç”¨     |\n| LatticeBERT | small(L6) |            | [é˜¿é‡Œäº‘](https://alice-open.oss-cn-zhangjiakou.aliyuncs.com/LatticeBERT/chinese_labert-lite-std-512.tar.gz) | [Alibaba](https://github.com/alibaba) | [github](https://github.com/alibaba/AliceMind/tree/main/LatticeBERT) | é€šç”¨     |\n| LatticeBERT | base(L12) |            | [é˜¿é‡Œäº‘](https://alice-open.oss-cn-zhangjiakou.aliyuncs.com/LatticeBERT/chinese_labert-base-std-512.tar.gz) | [Alibaba](https://github.com/alibaba) | [github](https://github.com/alibaba/AliceMind/tree/main/LatticeBERT) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### Mengzi-BERT\n\n+ 2021 | Mengzi: Towards Lightweight yet Ingenious Pre-trained Models for Chinese | Zhuosheng Zhang, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2110.06696)\n\n| æ¨¡å‹            | ç‰ˆæœ¬      | TensorFlow | PyTorch                                                      | ä½œè€…                                    | æºåœ°å€                                       | åº”ç”¨é¢†åŸŸ |\n| --------------- | --------- | ---------- | ------------------------------------------------------------ | --------------------------------------- | -------------------------------------------- | -------- |\n| Mengzi-BERT     | base(L12) |            | [[ğŸ¤—HF\\]](https://huggingface.co/Langboat/mengzi-bert-base) | [Langboat](https://github.com/Langboat) | [github](https://github.com/Langboat/Mengzi) | é€šç”¨     |\n| Mengzi-BERT-fin | base(L12) |            | [[ğŸ¤—HF\\]](https://huggingface.co/Langboat/mengzi-bert-base-fin) | [Langboat](https://github.com/Langboat) | [github](https://github.com/Langboat/Mengzi) | é‡‘èè´¢ç» |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### Bloom\n\n+ 2022 | Bloom: BigScience Large Open-science Open-access Multilingual Language Model | huggingface bigscience | - | [`BLOG`](https://bigscience.huggingface.co/blog/bloom)\n\n| æ¨¡å‹         | ç‰ˆæœ¬    | TensorFlow | PyTorch                                                     | ä½œè€…                                        | æºåœ°å€                                                | åº”ç”¨é¢†åŸŸ |\n| ------------ | ------- | ---------- | ----------------------------------------------------------- | ------------------------------------------- | ----------------------------------------------------- | -------- |\n| bloom-6b4-zh | 6B(L30) |            | [[ğŸ¤—HF\\]](https://huggingface.co/Langboat/bloom-6b4-zh) | [Langboat](https://huggingface.co/Langboat) | [github](https://github.com/huggingface/transformers) | é€šç”¨     |\n\n> æ³¨ï¼šä½œè€…å¦æœ‰bloom-389m-zhåˆ°bloom-2b5-zhç­‰å¤šä¸ªä¸­æ–‡æ¨¡å‹\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### TaCL\n\n+ 2021 | TaCL: Improving BERT Pre-training with Token-aware Contrastive Learning | Yixuan Su, et al. | arXiv | [`PDF`](https://arxiv.org/pdf/2111.04198.pdf)\n\n| æ¨¡å‹ | ç‰ˆæœ¬      | TensorFlow | PyTorch                                                      | ä½œè€…                                  | æºåœ°å€                                    | åº”ç”¨é¢†åŸŸ |\n| ---- | --------- | ---------- | ------------------------------------------------------------ | ------------------------------------- | ----------------------------------------- | -------- |\n| TaCL | base(L12) |            | [[ğŸ¤—HF\\]](https://huggingface.co/cambridgeltl/tacl-bert-base-chinese) | [yxuansu](https://github.com/yxuansu) | [github](https://github.com/yxuansu/TaCL) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### MC-BERT\n\n+ 2021 | MC-BERT: Conceptualized Representation Learning for Chinese Biomedical Text Mining | alibaba-research | arXiv | [`PDF`](https://arxiv.org/pdf/2008.10813.pdf)\n\n| æ¨¡å‹    | ç‰ˆæœ¬      | TensorFlow | PyTorch                                                      | ä½œè€…                                                    | æºåœ°å€                                                    | åº”ç”¨é¢†åŸŸ |\n| ------- | --------- | ---------- | ------------------------------------------------------------ | ------------------------------------------------------- | --------------------------------------------------------- | -------- |\n| MC-BERT | base(L12) |            | [link](https://drive.google.com/open?id=1ccXRvaeox5XCNP_aSk_ttLBY695Erlok) | [alibaba-research](https://github.com/alibaba-research) | [github](https://github.com/alibaba-research/ChineseBLUE) | ç”Ÿç‰©åŒ»ç–— |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### äºŒéƒç¥\n\n| æ¨¡å‹       | ç‰ˆæœ¬       | ç±»å‹ | TensorFlow | PyTorch                                                      | ä½œè€…                                      | æºåœ°å€                                                 | åº”ç”¨é¢†åŸŸ |\n| ---------- | ---------- | ---- | ---------- | ------------------------------------------------------------ | ----------------------------------------- | ------------------------------------------------------ | -------- |\n| Erlangshen | large(L24) | bert |            | [[ğŸ¤—HF\\]](https://huggingface.co/IDEA-CCNL/Erlangshen-1.3B) | [IDEA-CCNL](https://github.com/IDEA-CCNL) | [github](https://github.com/IDEA-CCNL/Fengshenbang-LM) | ä¸­æ–‡é€šç”¨ |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### PERT\n\n+ 2022 | PERT: Pre-Training BERT with Permuted Language Model | Yiming Cui, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2203.06906)\n\n| æ¨¡å‹       | ç‰ˆæœ¬       | TensorFlow                                                   | PyTorch                                                      | ä½œè€…                                   | æºåœ°å€                                  | åº”ç”¨é¢†åŸŸ |\n| ---------- | ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ | -------------------------------------- | --------------------------------------- | -------- |\n| PERT-base  | base(12L)  | [ç™¾åº¦ç½‘ç›˜-rcsw](https://pan.baidu.com/s/1yDHkYKmdaJkliTGHWQtdFA?pwd=rcsw) | [[ğŸ¤—HF\\]](https://huggingface.co/hfl/chinese-pert-base)  | [Yiming Cui](https://github.com/ymcui) | [github](https://github.com/ymcui/PERT) | é€šç”¨     |\n| PERT-large | large(24L) | [ç™¾åº¦ç½‘ç›˜-e9hs](https://pan.baidu.com/s/1MG44TRIgqV6m_StfB_yBqQ?pwd=e9hs) | [[ğŸ¤—HF\\]](https://huggingface.co/hfl/chinese-pert-large) | [Yiming Cui](https://github.com/ymcui) | [github](https://github.com/ymcui/PERT) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### MobileBERT\n\n+ 2020 | MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices | Zhiqing Sun, et al. | arXiv | [`PDF`](https://arxiv.org/pdf/2004.02984.pdf)\n\n| æ¨¡å‹                        | ç‰ˆæœ¬  | TensorFlow                                                   | PyTorch | ä½œè€…                                   | æºåœ°å€                                                | åº”ç”¨é¢†åŸŸ |\n| --------------------------- | ----- | ------------------------------------------------------------ | ------- | -------------------------------------- | ----------------------------------------------------- | -------- |\n| Chinese-MobileBERT-base-f2  | base  | [ç™¾åº¦ç½‘ç›˜-56bj](https://pan.baidu.com/s/16g1LgXXAV01I-cFgPdeOow?pwd=56bj) |         | [Yiming Cui](https://github.com/ymcui) | [github](https://github.com/ymcui/Chinese-MobileBERT) | é€šç”¨     |\n| Chinese-MobileBERT-base-f4  | base  | [ç™¾åº¦ç½‘ç›˜-v2v7](https://pan.baidu.com/s/16SGBJhWFYru47EEyTZJljA?pwd=v2v7) |         | [Yiming Cui](https://github.com/ymcui) | [github](https://github.com/ymcui/Chinese-MobileBERT) | é€šç”¨     |\n| Chinese-MobileBERT-large-f2 | large | [ç™¾åº¦ç½‘ç›˜-6m5a](https://pan.baidu.com/s/1Kp7n8lQJOtevzMovKSa3kw?pwd=6m5a) |         | [Yiming Cui](https://github.com/ymcui) | [github](https://github.com/ymcui/Chinese-MobileBERT) | é€šç”¨     |\n| Chinese-MobileBERT-large-f4 | large | [ç™¾åº¦ç½‘ç›˜-3h9b](https://pan.baidu.com/s/19xz9kH1HmM2Og0Aqn7l6vA?pwd=3h9b) |         | [Yiming Cui](https://github.com/ymcui) | [github](https://github.com/ymcui/Chinese-MobileBERT) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### GAU-Î±\n\n+ 2022 | GAU-Î±: (FLASH) Transformer Quality in Linear Time | Weizhe Hua, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2202.10447.pdf) | [`blog`](https://spaces.ac.cn/archives/9052)\n\n| æ¨¡å‹                              | ç‰ˆæœ¬ | TensorFlow                                                   | PyTorch | ä½œè€…                                                    | æºåœ°å€                                                  | åº”ç”¨é¢†åŸŸ |\n| --------------------------------- | ---- | ------------------------------------------------------------ | ------- | ------------------------------------------------------- | ------------------------------------------------------- | -------- |\n| chinese_GAU-alpha-char_L-24_H-768 | base | [ä¸‹è½½](https://open.zhuiyi.ai/releases/nlp/models/zhuiyi/chinese_GAU-alpha-char_L-24_H-768.zip) |         | [ZhuiyiTechnology](https://github.com/ZhuiyiTechnology) | [github](https://github.com/ZhuiyiTechnology/GAU-alpha) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### DeBERTa\n\n+ 2020 | DeBERTa: Decoding-enhanced BERT with Disentangled Attention | Pengcheng He, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2006.03654) |\n\n| æ¨¡å‹              | ç‰ˆæœ¬   | TensorFlow | PyTorch                                                      | ä½œè€…                                      | æºåœ°å€                                                 | åº”ç”¨é¢†åŸŸ |\n| ----------------- | ------ | ---------- | ------------------------------------------------------------ | ----------------------------------------- | ------------------------------------------------------ | -------- |\n| DeBERTa-v2-Large  | large  |            | [[ğŸ¤—HF\\]](https://huggingface.co/IDEA-CCNL/Erlangshen-DeBERTa-v2-320M-Chinese) | [IDEA-CCNL](https://github.com/IDEA-CCNL) | [github](https://github.com/IDEA-CCNL/Fengshenbang-LM) | é€šç”¨     |\n| DeBERTa-v2-xLarge | xlarge |            | [[ğŸ¤—HF\\]](https://huggingface.co/IDEA-CCNL/Erlangshen-DeBERTa-v2-710M-Chinese) | [IDEA-CCNL](https://github.com/IDEA-CCNL) | [github](https://github.com/IDEA-CCNL/Fengshenbang-LM) | é€šç”¨     |\n| DeBERTa-v2        | base   |            | [[ğŸ¤—HF\\]](https://huggingface.co/IDEA-CCNL/Erlangshen-DeBERTa-v2-186M-Chinese-SentencePiece) | [IDEA-CCNL](https://github.com/IDEA-CCNL) | [github](https://github.com/IDEA-CCNL/Fengshenbang-LM) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### GlyphBERT\n\n+ 2021 | GlyphCRM: Bidirectional Encoder Representation for Chinese Character with its Glyph | Yuxin li, et al. | arXiv | [`PDF`](https://arxiv.org/pdf/2107.00395.pdf) |\n\n| æ¨¡å‹          | ç‰ˆæœ¬ | TensorFlow | PyTorch                                                 | ä½œè€…                                      | æºåœ°å€                                           | åº”ç”¨é¢†åŸŸ |\n| ------------- | ---- | ---------- | ------------------------------------------------------- | ----------------------------------------- | ------------------------------------------------ | -------- |\n| GlyphCRM-base | base |            | [[ğŸ¤—HF\\]](https://huggingface.co/HIT-TMG/GlyphBERT) | [HITsz-TMG](https://github.com/HITsz-TMG) | [github](https://github.com/HITsz-TMG/GlyphBERT) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### CKBERT\n\n+ 2022 | Revisiting and Advancing Chinese Natural Language Understanding with Accelerated Heterogeneous Knowledge Pre-training | Zhang, Taolin, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2210.05287)\n\n| æ¨¡å‹                | ç‰ˆæœ¬  | TensorFlow | PyTorch                                                      | ä½œè€…                                  | æºåœ°å€                                       | åº”ç”¨é¢†åŸŸ |\n| ------------------- | ----- | ---------- | ------------------------------------------------------------ | ------------------------------------- | -------------------------------------------- | -------- |\n| pai-ckbert-base-zh  | base  |            | [[ğŸ¤—HF\\]](https://huggingface.co/alibaba-pai/pai-ckbert-base-zh) | [Alibaba](https://github.com/alibaba) | [github](https://huggingface.co/alibaba-pai) | é€šç”¨     |\n| pai-ckbert-large-zh | large |            | [[ğŸ¤—HF\\]](https://huggingface.co/alibaba-pai/pai-ckbert-large-zh) | [Alibaba](https://github.com/alibaba) | [github](https://huggingface.co/alibaba-pai) | é€šç”¨     |\n| pai-ckbert-huge-zh  | huge  |            | [[ğŸ¤—HF\\]](https://huggingface.co/alibaba-pai/pai-ckbert-huge-zh) | [Alibaba](https://github.com/alibaba) | [github](https://huggingface.co/alibaba-pai) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### LERT\n\n+ 2022 | LERT: A Linguistically-motivated Pre-trained Language Model | Yiming Cui et al. | arXiv | [`PDF`](https://arxiv.org/abs/2211.05344)\n\n| æ¨¡å‹               | ç‰ˆæœ¬ | TensorFlow                                                   | PyTorch                                                      | ä½œè€…                                   | æºåœ°å€                                  | åº”ç”¨é¢†åŸŸ |\n| ------------------ | ---- | ------------------------------------------------------------ | ------------------------------------------------------------ | -------------------------------------- | --------------------------------------- | -------- |\n| Chinese-LERT-small | 15m  | [ç™¾åº¦ç½‘ç›˜-4vuy](https://pan.baidu.com/s/1fBk3em8a5iCMwPLJEBq2pQ?pwd=4vuy) | [[ğŸ¤—HF\\]](https://huggingface.co/hfl/chinese-lert-small) | [Yiming Cui](https://github.com/ymcui) | [github](https://github.com/ymcui/LERT) | é€šç”¨     |\n| Chinese-LERT-base  | 400m | [ç™¾åº¦ç½‘ç›˜-9jgi](https://pan.baidu.com/s/1_yb1jCDJ4s2P8OrF_5E_Tg?pwd=9jgi) | [[ğŸ¤—HF\\]](https://huggingface.co/hfl/chinese-lert-base)  | [Yiming Cui](https://github.com/ymcui) | [github](https://github.com/ymcui/LERT) | é€šç”¨     |\n| Chinese-LERT-large | 1.2G | [ç™¾åº¦ç½‘ç›˜-s82t](https://pan.baidu.com/s/1pxsS3almc90DPvMXH6BMYQ?pwd=s82t) | [[ğŸ¤—HF\\]](https://huggingface.co/hfl/chinese-lert-large) | [Yiming Cui](https://github.com/ymcui) | [github](https://github.com/ymcui/LERT) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### RoCBert\n\n+ 2022 | RoCBert: Robust Chinese Bert with Multimodal Contrastive Pretraining | Hui Su et al. | ACL | [`PDF`](https://aclanthology.org/2022.acl-long.65.pdf)\n\n| æ¨¡å‹    | ç‰ˆæœ¬ | TensorFlow | PyTorch                                                      | ä½œè€…                                    | æºåœ°å€                                       | åº”ç”¨é¢†åŸŸ |\n| ------- | ---- | ---------- | ------------------------------------------------------------ | --------------------------------------- | -------------------------------------------- | -------- |\n| rocbert | base |            | [[ğŸ¤—HF\\]](https://huggingface.co/weiweishi/roc-bert-base-zh) | [Weiwe Shi](https://github.com/sww9370) | [github](https://github.com/sww9370/RoCBert) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### M3E\n\n| æ¨¡å‹      | ç‰ˆæœ¬  | PyTorch                                               | ä½œè€…                                      | æºåœ°å€                                                       | å¤‡æ³¨         |\n| --------- | ----- | ----------------------------------------------------- | ----------------------------------------- | ------------------------------------------------------------ | ------------ |\n| m3e-base  | base  | [m3e-base](https://huggingface.co/moka-ai/m3e-base)   | [Moka-AI](https://huggingface.co/moka-ai) | [uniem](https://github.com/wangyuxinwhy/uniem)![Star](https://img.shields.io/github/stars/wangyuxinwhy/uniem.svg?style=social&label=Star) | æ–‡æœ¬åµŒå…¥æ¨¡å‹ |\n| M3e-small | Small | [m3e-small](https://huggingface.co/moka-ai/m3e-small) | [Moka-AI](https://huggingface.co/moka-ai) | [uniem](https://github.com/wangyuxinwhy/uniem)![Star](https://img.shields.io/github/stars/wangyuxinwhy/uniem.svg?style=social&label=Star) | æ–‡æœ¬åµŒå…¥æ¨¡å‹ |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### LEALLA\n\n+ 2023 | LEALLA: Learning Lightweight Language-agnostic Sentence Embeddings with Knowledge Distillation | Zhuoyuan Mao et al. | EACL | [`PDF`](https://arxiv.org/abs/2302.08387)\n\n| æ¨¡å‹         | ç‰ˆæœ¬  | PyTorch                                                      | ä½œè€…            | æºåœ°å€ | å¤‡æ³¨         |\n| ------------ | ----- | ------------------------------------------------------------ | --------------- | ------ | ------------ |\n| LEALLA-base  | base  | [LEALLA-base](https://huggingface.co/setu4993/LEALLA-base)   | Google Research | /      | æ–‡æœ¬åµŒå…¥æ¨¡å‹ |\n| LEALLA-large | large | [LEALLA-large](https://huggingface.co/setu4993/LEALLA-large) | Google Research | /      | æ–‡æœ¬åµŒå…¥æ¨¡å‹ |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n## NLGç³»åˆ—\n\n### GPT\n\n+ 2019 | Improving Language Understandingby Generative Pre-Training | Alec Radford, et al. | arXiv | [`PDF`](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)\n\n+ 2019 | Language Models are Unsupervised Multitask Learners | Alec Radford, et al. | arXiv | [`PDF`](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)\n\n| æ¨¡å‹                | ç‰ˆæœ¬      | TensorFlow                                                   | PyTorch                                                      | ä½œè€…                                                    | æºåœ°å€                                                       | åº”ç”¨é¢†åŸŸ |\n| ------------------- | --------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------- | ------------------------------------------------------------ | -------- |\n| GPT2                | 30äº¿è¯­æ–™  |                                                              | <p>[Google Drive](https://drive.google.com/file/d/1mT_qCQg4AWnAXTwKfsyyRWCRpgPrBJS3)<br>[ç™¾åº¦ç½‘ç›˜-ffz6](https://pan.baidu.com/s/1yiuTHXUr2DpyBqmFYLJH6A)</p> | [Caspar ZHANG](https://github.com/imcaspar)             | [gpt2-ml](https://github.com/imcaspar/gpt2-ml)               | é€šç”¨     |\n| GPT2                | 15äº¿è¯­æ–™  |                                                              | <p>[Google Drive](https://drive.google.com/file/d/1IzWpQ6I2IgfV7CldZvFJnZ9byNDZdO4n)<br>[ç™¾åº¦ç½‘ç›˜-q9vr](https://pan.baidu.com/s/1TA_3e-u2bXg_hcx_NwVbGw)</p> | [Caspar ZHANG](https://github.com/imcaspar)             | [gpt2-ml](https://github.com/imcaspar/gpt2-ml)               | é€šç”¨     |\n| CDial-GPTLCCC-base  | base      |                                                              | [[ğŸ¤—HF\\]](https://huggingface.co/thu-coai/CDial-GPT_LCCC-base) | [thu-coai](https://github.com/thu-coai)                 | [CDial-GPT](https://github.com/thu-coai/CDial-GPT)           | ä¸­æ–‡å¯¹è¯ |\n| CDial-GPT2LCCC-base | base      |                                                              | [[ğŸ¤—HF\\]](https://huggingface.co/thu-coai/CDial-GPT2_LCCC-base) | [thu-coai](https://github.com/thu-coai)                 | [CDial-GPT](https://github.com/thu-coai/CDial-GPT)           | ä¸­æ–‡å¯¹è¯ |\n| CDial-GPTLCCC-large | large     |                                                              | [[ğŸ¤—HF\\]](https://huggingface.co/thu-coai/CDial-GPT_LCCC-large) | [thu-coai](https://github.com/thu-coai)                 | [CDial-GPT](https://github.com/thu-coai/CDial-GPT)           | ä¸­æ–‡å¯¹è¯ |\n| GPT2-dialogue       | base      |                                                              | <p>[Google Drive](https://drive.google.com/drive/folders/1Ogz3eapvtvdY4VUcY9AEwMbNRivLKhri?usp=sharing)</br>[ç™¾åº¦ç½‘ç›˜-osi6](https://pan.baidu.com/s/1qDZ24VKLBU9GKARX9Ev65g)</p> | [yangjianxin1](https://github.com/yangjianxin1)         | [GPT2-chitchat](https://github.com/yangjianxin1/GPT2-chitchat) | é—²èŠå¯¹è¯ |\n| GPT2-mmi            | base      |                                                              | <p>[Google Drive](https://drive.google.com/drive/folders/1oWgKXP6VG_sT_2VMrm0xL4uOqfYwzgUP?usp=sharing)</br>[ç™¾åº¦ç½‘ç›˜-1j88](https://pan.baidu.com/s/1ubXGuEvY8KmwEjIVTJVLww)</p> | [yangjianxin1](https://github.com/yangjianxin1)         | [GPT2-chitchat](https://github.com/yangjianxin1/GPT2-chitchat) | é—²èŠå¯¹è¯ |\n| GPT2-æ•£æ–‡æ¨¡å‹       | base      |                                                              | <p>[Google Drive](https://drive.google.com/drive/folders/1rJC4niJKMVwixUQkuL9k5teLRnEYTmUf?usp=sharing)</br>[ç™¾åº¦ç½‘ç›˜-fpyu](https://pan.baidu.com/s/1nbrW5iw34GRhoTin8uU2tQ)</p> | [Zeyao Du](https://github.com/Morizeyao)                | [GPT2-Chinese](https://github.com/Morizeyao/GPT2-Chinese)    | æ•£æ–‡     |\n| GPT2-è¯—è¯æ¨¡å‹       | base      |                                                              | <p>[Google Drive](https://drive.google.com/drive/folders/1Z6nF1nrgTkrZcRLHedQHXb4_M9I7yQPN?usp=sharing)</br>[ç™¾åº¦ç½‘ç›˜-7fev](https://pan.baidu.com/s/1Hy0OQ5xZcTLer9MQZW8o3g)</p> | [Zeyao Du](https://github.com/Morizeyao)                | [GPT2-Chinese](https://github.com/Morizeyao/GPT2-Chinese)    | è¯—è¯     |\n| GPT2-å¯¹è”æ¨¡å‹       | base      |                                                              | <p>[Google Drive](https://drive.google.com/drive/folders/1ZnsvS7oHRVueNKj_SeEhiQt86aze3ojj?usp=sharing)</br>[ç™¾åº¦ç½‘ç›˜-i5n0](https://pan.baidu.com/s/1j9yVQwjlXZq58wOyXK4lcg)</p> | [Zeyao Du](https://github.com/Morizeyao)                | [GPT2-Chinese](https://github.com/Morizeyao/GPT2-Chinese)    | å¯¹è”     |\n| roformer-gpt        | base(L12) | [ç™¾åº¦ç½‘ç›˜-2nnn](https://pan.baidu.com/s/11YTnWLX0ThQr2P2yW0P7GA) |                                                              | [ZhuiyiTechnology](https://github.com/ZhuiyiTechnology) | [github](https://github.com/ZhuiyiTechnology/roformer)       | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### GPT-3\n\n+ 2019 | Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context | Zihang Dai, et al. | arXiv | [`PDF`](https://arxiv.org/abs/1901.02860)\n\n+ 2020 | Language Models are Few-Shot Learners | Tom B. Brown, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2005.14165)\n\n| æ¨¡å‹                   | ç‰ˆæœ¬            | ä»‹ç»                                 | PyTorch                                                      | ä½œè€…                              | æºåœ°å€                                                    | åº”ç”¨é¢†åŸŸ |\n| ---------------------- | --------------- | ------------------------------------ | ------------------------------------------------------------ | --------------------------------- | --------------------------------------------------------- | -------- |\n| Chinese-Transformer-XL | 29äº¿å‚æ•°(GPT-3) | [é¡¹ç›®é¦–é¡µ](https://gpt-3.aminer.cn/) | [æ¨¡å‹ä¸‹è½½](http://dorc-model-team.ks3-cn-beijing.ksyun.com/ren-zhi/my-model/mp_rank_00_model_states.pt) | [THUDM](https://github.com/THUDM) | [github](https://github.com/THUDM/Chinese-Transformer-XL) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### NEZHA-Gen\n\n+ 2019 | NEZHA: Neural Contextualized Representation for Chinese Language Understanding | Junqiu Wei, et al. | arXiv | [`PDF`](https://arxiv.org/abs/1909.00204)\n\n+ 2019 | Improving Language Understandingby Generative Pre-Training | Alec Radford, et al. | arXiv | [`PDF`](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)\n\n| æ¨¡å‹      | ç‰ˆæœ¬ | TensorFlow                                                   | PyTorch | ä½œè€…                                     | æºåœ°å€                                                       | åº”ç”¨é¢†åŸŸ |\n| --------- | ---- | ------------------------------------------------------------ | ------- | ---------------------------------------- | ------------------------------------------------------------ | -------- |\n| NEZHA-Gen | base | <p>[Google Drive](https://drive.google.com/drive/folders/1i4f_8LhaVDNjnGlLXNJ0rNgBP0E4L6V0?usp=sharing)<br>[ç™¾åº¦ç½‘ç›˜-rb5m](https://pan.baidu.com/s/1Bgle8TpcxHyuUz_jAXOBWw)</p> |         | [HUAWEI](https://github.com/huawei-noah) | [github](https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/NEZHA-Gen-TensorFlow) | é€šç”¨     |\n| NEZHA-Gen | base | <p>[Google Drive](https://drive.google.com/drive/folders/1B5-jxUlzhoKwFVMQ-nkqqbmJQgr1lRAp?usp=sharing)<br>[ç™¾åº¦ç½‘ç›˜-ytim](https://pan.baidu.com/s/1me6_BGYHbWFdTi80vRQ2Lg)</p> |         | [HUAWEI](https://github.com/huawei-noah) | [github](https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/NEZHA-Gen-TensorFlow) | è¯—æ­Œ     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### CPM-Generate\n\n+ 2020 | CPM: A Large-scale Generative Chinese Pre-trained Language Model | Zhengyan Zhang, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2012.00413)\n\n| æ¨¡å‹ | ç‰ˆæœ¬     | èµ„æº                                | PyTorch                                          | ä½œè€…                                         | æºåœ°å€                                               | åº”ç”¨é¢†åŸŸ |\n| ---- | -------- | ----------------------------------- | ------------------------------------------------ | -------------------------------------------- | ---------------------------------------------------- | -------- |\n| CPM  | 26äº¿å‚æ•° | [é¡¹ç›®é¦–é¡µ](https://cpm.baai.ac.cn/) | [æ¨¡å‹ä¸‹è½½](https://cpm.baai.ac.cn/download.html) | [Tsinghua AI](https://github.com/TsinghuaAI) | [github](https://github.com/TsinghuaAI/CPM-Generate) | é€šç”¨     |\n\nå¤‡æ³¨: \n\n> PyTorchè½¬TensorFlowå¯å‚è€ƒ: [CPM-LM-TF2](https://github.com/qhduan/CPM-LM-TF2)\n\n> PyTorchè½¬PaddlePaddleå¯å‚è€ƒ: [CPM-Generate-Paddle](https://github.com/jm12138/CPM-Generate-Paddle)\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### T5\n\n+ 2019 | Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer | Colin Raffel, et al. | arXiv | [`PDF`](https://arxiv.org/abs/1910.10683)\n\n| æ¨¡å‹ | ç‰ˆæœ¬  | TensorFlow                                                   | PyTorch                                                      | ä½œè€…                                    | æºåœ°å€                                 | åº”ç”¨é¢†åŸŸ |\n| ---- | ----- | ------------------------------------------------------------ | ------------------------------------------------------------ | --------------------------------------- | -------------------------------------- | -------- |\n| T5   | small | [[ğŸ¤—HF\\]](https://huggingface.co/uer/t5-small-chinese-cluecorpussmall) | [[ğŸ¤—HF\\]](https://huggingface.co/uer/t5-small-chinese-cluecorpussmall) | [DBIIR @ RUC](https://github.com/dbiir) | [UER](https://github.com/dbiir/UER-py) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### T5-PEGASUS\n\n+ 2019 | Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer | Colin Raffel, et al. | arXiv | [`PDF`](https://arxiv.org/abs/1910.10683)\n\n+ 2019 | PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization | Jingqing Zhang, et al. | arXiv | [`PDF`](https://arxiv.org/pdf/1912.08777.pdf)\n\n+ 2021 | T5 PEGASUSï¼šå¼€æºä¸€ä¸ªä¸­æ–‡ç”Ÿæˆå¼é¢„è®­ç»ƒæ¨¡å‹ | è‹å‰‘æ—. | spaces | [`Blog post`](https://spaces.ac.cn/archives/8209)\n\n| æ¨¡å‹       | ç‰ˆæœ¬  | Keras                                                        | PyTorch | ä½œè€…                                                    | æºåœ°å€                                                   | åº”ç”¨é¢†åŸŸ |\n| ---------- | ----- | ------------------------------------------------------------ | ------- | ------------------------------------------------------- | -------------------------------------------------------- | -------- |\n| T5 PEGASUS | base  | [ç™¾åº¦ç½‘ç›˜-3sfn](https://pan.baidu.com/s/1lQ9Dt9wZDO3IgiCL9tP-Ug) |         | [ZhuiyiTechnology](https://github.com/ZhuiyiTechnology) | [github](https://github.com/ZhuiyiTechnology/t5-pegasus) | é€šç”¨     |\n| T5 PEGASUS | small | [ç™¾åº¦ç½‘ç›˜-qguk](https://pan.baidu.com/s/1bXRVWnDyAck9VfSO9_1oJQ) |         | [ZhuiyiTechnology](https://github.com/ZhuiyiTechnology) | [github](https://github.com/ZhuiyiTechnology/t5-pegasus) | é€šç”¨     |\n\n>  Kerasè½¬PyTorchå¯å‚è€ƒ: [t5-pegasus-pytorch](https://github.com/renmada/t5-pegasus-pytorch)\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### Mengzi-T5\n\n+ 2021 | Mengzi: Towards Lightweight yet Ingenious Pre-trained Models for Chinese | Zhuosheng Zhang, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2110.06696)\n\n| æ¨¡å‹      | ç‰ˆæœ¬      | TensorFlow | PyTorch                                                      | ä½œè€…                                    | æºåœ°å€                                       | åº”ç”¨é¢†åŸŸ |\n| --------- | --------- | ---------- | ------------------------------------------------------------ | --------------------------------------- | -------------------------------------------- | -------- |\n| Mengzi-T5 | base(L12) |            | [[ğŸ¤—HF\\]](https://huggingface.co/Langboat/mengzi-t5-base) | [Langboat](https://github.com/Langboat) | [github](https://github.com/Langboat/Mengzi) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### PanGu-Alpha\n\n+ 2021 | PanGu-Î±: Large-scale Autoregressive Pretrained Chinese Language Models with Auto-parallel Computation | Wei Zeng, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2104.12369)\n\n| æ¨¡å‹                   | ç‰ˆæœ¬ | èµ„æº                                                         | ä¸‹è½½åœ°å€                                                     | ä½œè€…                                                         | æºåœ°å€                                                       | åº”ç”¨é¢†åŸŸ |\n| ---------------------- | ---- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | -------- |\n| ç›˜å¤Î±-2.6B             | 2.6G | [é¡¹ç›®é¦–é¡µ](https://git.openi.org.cn/PCL-Platform.Intelligence/PanGu-Alpha/src/branch/master) | [æ¨¡å‹ä¸‹è½½](https://git.openi.org.cn/PCL-Platform.Intelligence/PanGu-Alpha/src/branch/master) | [PCL-Platform.Intelligence](https://git.openi.org.cn/PCL-Platform.Intelligence) | [github](https://git.openi.org.cn/PCL-Platform.Intelligence/PanGu-Alpha) | é€šç”¨     |\n| ç›˜å¤Î±-13B              | 12G  | [é¡¹ç›®é¦–é¡µ](https://git.openi.org.cn/PCL-Platform.Intelligence/PanGu-Alpha/src/branch/master) | [æ¨¡å‹ä¸‹è½½](https://git.openi.org.cn/PCL-Platform.Intelligence/PanGu-Alpha/src/branch/master) | [PCL-Platform.Intelligence](https://git.openi.org.cn/PCL-Platform.Intelligence) | [github](https://git.openi.org.cn/PCL-Platform.Intelligence/PanGu-Alpha) | é€šç”¨     |\n| ç›˜å¤Î±-2.6B pytorchç‰ˆæœ¬ | 2.6G | [é¡¹ç›®é¦–é¡µ](https://git.openi.org.cn/PCL-Platform.Intelligence/PanGu-Alpha-GPU/src/branch/master/panguAlpha_pytorch) | [æ¨¡å‹ä¸‹è½½](https://git.openi.org.cn/PCL-Platform.Intelligence/PanGu-Alpha-GPU/src/branch/master/panguAlpha_pytorch#user-content-%E6%A8%A1%E5%9E%8B%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD) | [PCL-Platform.Intelligence](https://git.openi.org.cn/PCL-Platform.Intelligence) | [github](https://git.openi.org.cn/PCL-Platform.Intelligence/PanGu-Alpha-GPU) | é€šç”¨     |\n| ç›˜å¤Î±-13B pytorchç‰ˆæœ¬  | 12G  | [é¡¹ç›®é¦–é¡µ](https://git.openi.org.cn/PCL-Platform.Intelligence/PanGu-Alpha-GPU/src/branch/master/panguAlpha_pytorch) | [æ¨¡å‹ä¸‹è½½](https://git.openi.org.cn/PCL-Platform.Intelligence/PanGu-Alpha-GPU/src/branch/master/panguAlpha_pytorch#user-content-%E6%A8%A1%E5%9E%8B%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD) | [PCL-Platform.Intelligence](https://git.openi.org.cn/PCL-Platform.Intelligence) | [github](https://git.openi.org.cn/PCL-Platform.Intelligence/PanGu-Alpha-GPU) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### EVA\n\n+ 2021 | EVA: An Open-Domain Chinese Dialogue System with Large-Scale Generative Pre-Training | Hao Zhou, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2108.01547)\n\n| æ¨¡å‹          | ç‰ˆæœ¬     | ä»‹ç»                                            | æ¨¡å‹ä¸‹è½½                                                     | ä½œè€…                                    | æºåœ°å€                                    | åº”ç”¨é¢†åŸŸ       | å¤‡æ³¨             |\n| ------------- | -------- | ----------------------------------------------- | ------------------------------------------------------------ | --------------------------------------- | ----------------------------------------- | -------------- | ---------------- |\n| EVA           | 28äº¿å‚æ•° | [é¡¹ç›®é¦–é¡µ](https://wudaoai.cn/model/detail/EVA) | [æ¨¡å‹ä¸‹è½½](https://wudaoai.cn/model/download?resourceId=1428554651225075712&filename=eva-ckpt.tar.gz) | [thu-coai](https://github.com/thu-coai) | [github](https://github.com/thu-coai/EVA) | ä¸­æ–‡å¼€æ”¾åŸŸå¯¹è¯ | éœ€è¦ç™»é™†æ‰èƒ½ä¸‹è½½ |\n| EVA2.0-xLarge | xlarge   | [é¡¹ç›®é¦–é¡µ](https://wudaoai.cn/model/detail/EVA) | [[ğŸ¤—HF\\]](https://huggingface.co/thu-coai/EVA2.0-xlarge) | [thu-coai](https://github.com/thu-coai) | [github](https://github.com/thu-coai/EVA) | ä¸­æ–‡å¼€æ”¾åŸŸå¯¹è¯ |                  |\n| EVA2.0-large  | large    | [é¡¹ç›®é¦–é¡µ](https://wudaoai.cn/model/detail/EVA) | [[ğŸ¤—HF\\]](https://huggingface.co/thu-coai/EVA2.0-large)  | [thu-coai](https://github.com/thu-coai) | [github](https://github.com/thu-coai/EVA) | ä¸­æ–‡å¼€æ”¾åŸŸå¯¹è¯ |                  |\n| EVA2.0-base   | base     | [é¡¹ç›®é¦–é¡µ](https://wudaoai.cn/model/detail/EVA) | [[ğŸ¤—HF\\]](https://huggingface.co/thu-coai/EVA2.0-base)   | [thu-coai](https://github.com/thu-coai) | [github](https://github.com/thu-coai/EVA) | ä¸­æ–‡å¼€æ”¾åŸŸå¯¹è¯ |                  |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>-\n\n### BART\n\n+ 2019 | BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension | Mike Lewis, et al. | arxiv | [`PDF`](https://arxiv.org/abs/1910.13461)\n\n| æ¨¡å‹       | ç‰ˆæœ¬  | TensorFlow | PyTorch                                                      | ä½œè€…                                  | æºåœ°å€                                   | åº”ç”¨é¢†åŸŸ |\n| ---------- | ----- | ---------- | ------------------------------------------------------------ | ------------------------------------- | ---------------------------------------- | -------- |\n| BART-base  | base  |            | [[ğŸ¤—HF\\]](https://huggingface.co/fnlp/bart-base-chinese) | [fastNLP](https://github.com/fastnlp) | [github](https://github.com/fastnlp/CPT) | ä¸­æ–‡é€šç”¨ |\n| BART-large | large |            | [[ğŸ¤—HF\\]](https://huggingface.co/fnlp/bart-large-chinese) | [fastNLP](https://github.com/fastnlp) | [github](https://github.com/fastnlp/CPT) | ä¸­æ–‡é€šç”¨ |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### é—»ä»²\n\n| æ¨¡å‹     | ç‰ˆæœ¬       | ç±»å‹ | TensorFlow | PyTorch                                                      | ä½œè€…                                      | æºåœ°å€                                                 | åº”ç”¨é¢†åŸŸ |\n| -------- | ---------- | ---- | ---------- | ------------------------------------------------------------ | ----------------------------------------- | ------------------------------------------------------ | -------- |\n| Wenzhong | large(L24) | GPT2 |            | [[ğŸ¤—HF\\]](https://huggingface.co/IDEA-CCNL/Wenzhong-3.5B) | [IDEA-CCNL](https://github.com/IDEA-CCNL) | [github](https://github.com/IDEA-CCNL/Fengshenbang-LM) | ä¸­æ–‡é€šç”¨ |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### ä½™å…ƒ\n\n| æ¨¡å‹   | ç‰ˆæœ¬       | ç±»å‹ | TensorFlow | PyTorch                                                     | ä½œè€…                                      | æºåœ°å€                                                 | åº”ç”¨é¢†åŸŸ |\n| ------ | ---------- | ---- | ---------- | ----------------------------------------------------------- | ----------------------------------------- | ------------------------------------------------------ | -------- |\n| Yuyuan | large(L24) | GPT2 |            | [[ğŸ¤—HF\\]](https://huggingface.co/IDEA-CCNL/Yuyuan-3.5B) | [IDEA-CCNL](https://github.com/IDEA-CCNL) | [github](https://github.com/IDEA-CCNL/Fengshenbang-LM) | åŒ»å­¦é¢†åŸŸ |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### RWKV\n\n+ 2021 | An Attention Free Transformer | Shuangfei Zhai, et al. | arxiv | [`PDF`](https://arxiv.org/abs/2105.14103)\n+ 2022 | The RWKV Language Model . | [github](https://github.com/BlinkDL/RWKV-LM)\n\n| æ¨¡å‹ | ç‰ˆæœ¬      | ç±»å‹ | TensorFlow | PyTorch                                                      | ä½œè€…                                  | æºåœ°å€                                         | åº”ç”¨é¢†åŸŸ |\n| ---- | --------- | ---- | ---------- | ------------------------------------------------------------ | ------------------------------------- | ---------------------------------------------- | -------- |\n| RWKV | base(L12) |      |            | [github](https://github.com/BlinkDL/AI-Writer/releases)      | [PENG Bo](https://github.com/BlinkDL) | [github](https://github.com/BlinkDL/AI-Writer) | å°è¯´     |\n| RWKV | 7B        |      |            | [[ğŸ¤—HF\\]](https://huggingface.co/BlinkDL/rwkv-4-pile-7b) | [PENG Bo](https://github.com/BlinkDL) | [github](https://github.com/BlinkDL/ChatRWKV)  | å°è¯´     |\n| RWKV | 14B       |      |            | [[ğŸ¤—HF\\]](https://huggingface.co/BlinkDL/rwkv-4-pile-7b/tree/main) | [PENG Bo](https://github.com/BlinkDL) | [github](https://github.com/BlinkDL/ChatRWKV)  | å°è¯´     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### PromptCLUE\n\n| æ¨¡å‹             | ç‰ˆæœ¬      | TensorFlow | PyTorch                                                      | ä½œè€…                                    | æºåœ°å€                                          | åº”ç”¨é¢†åŸŸ |\n| ---------------- | --------- | ---------- | ------------------------------------------------------------ | --------------------------------------- | ----------------------------------------------- | -------- |\n| PromptCLUE       | base(L12) |            | [[ğŸ¤—HF\\]](https://huggingface.co/ClueAI/PromptCLUE-base) | [ClueAI](https://huggingface.co/ClueAI) | [github](https://github.com/clue-ai/PromptCLUE) | é€šç”¨     |\n| PromptCLUE-v1-5  | base(L12) |            | [[ğŸ¤—HF\\]](https://huggingface.co/ClueAI/PromptCLUE-base-v1-5) | [ClueAI](https://huggingface.co/ClueAI) | [github](https://github.com/clue-ai/PromptCLUE) | é€šç”¨     |\n| PromptCLUE-large | large     |            | [APIåœ¨çº¿è°ƒç”¨](https://www.clueai.cn/)                        | [ClueAI](https://huggingface.co/ClueAI) | [github](https://github.com/clue-ai/PromptCLUE) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### ChatYuan\n\n| æ¨¡å‹              | ç‰ˆæœ¬  | ç±»å‹ | TensorFlow | PyTorch                                                      | ä½œè€…                                 | æºåœ°å€                                        | åº”ç”¨é¢†åŸŸ   |\n| ----------------- | ----- | ---- | ---------- | ------------------------------------------------------------ | ------------------------------------ | --------------------------------------------- | ---------- |\n| ChatYuan          | large | T5   |            | [[ğŸ¤—HF\\]](https://huggingface.co/ClueAI/ChatYuan-large-v1) | [ClueAI](https://github.com/clue-ai) | [github](https://github.com/clue-ai/ChatYuan) | åŠŸèƒ½å‹å¯¹è¯ |\n| ChatYuan-large-v2 | large | T5   |            | [[ğŸ¤—HF\\]](https://huggingface.co/ClueAI/ChatYuan-large-v2) | [ClueAI](https://github.com/clue-ai) | [github](https://github.com/clue-ai/ChatYuan) | åŠŸèƒ½å‹å¯¹è¯ |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### SkyText\n\n| æ¨¡å‹    | ç‰ˆæœ¬  | ç±»å‹ | TensorFlow | PyTorch                                               | ä½œè€…                                          | æºåœ°å€                                                   | åº”ç”¨é¢†åŸŸ |\n| ------- | ----- | ---- | ---------- | ----------------------------------------------------- | --------------------------------------------- | -------------------------------------------------------- | -------- |\n| SkyText | large | GPT3 |            | [[ğŸ¤—HF\\]](https://huggingface.co/SkyWork/SkyText) | [SkyWorkAIGC](https://github.com/SkyWorkAIGC) | [github](https://github.com/SkyWorkAIGC/SkyText-CN-GPT3) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### ProphetNet\n\n+ 2020 | Prophetnet: Predicting future n-gram for sequence-to-sequence pre-training | Qi, Weizhen, et al. | arxiv | [`PDF`](https://arxiv.org/pdf/2001.04063.pdf)\n+ 2021 | ProphetNet-X: Large-Scale Pre-training Models for English, Chinese, Multi-lingual, Dialog, and Code Generation | Qi, Weizhen, et al. | arxiv | [`PDF`](https://arxiv.org/abs/2104.08006)\n\n| æ¨¡å‹                 | ç‰ˆæœ¬ | ç±»å‹ | TensorFlow | PyTorch                                                      | ä½œè€…                                      | æºåœ°å€                                                       | åº”ç”¨é¢†åŸŸ |\n| -------------------- | ---- | ---- | ---------- | ------------------------------------------------------------ | ----------------------------------------- | ------------------------------------------------------------ | -------- |\n| ProphetNet-Zh        |      |      |            | [link](https://msraprophetnet.blob.core.windows.net/prophetnet/release_checkpoints/prophetnet_zh.pt) | [microsoft](https://github.com/microsoft) | [github](https://github.com/microsoft/ProphetNet/tree/master/ProphetNet) | é€šç”¨     |\n| ProphetNet-Dialog-Zh |      |      |            | [link](https://msraprophetnet.blob.core.windows.net/prophetnet/release_checkpoints/prophetnet_dialog_zh.pt) | [microsoft](https://github.com/microsoft) | [github](https://github.com/microsoft/ProphetNet/tree/master/ProphetNet) | å¯¹è¯     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n## NLU-NLGç³»åˆ—\n\n### UniLM\n\n+ 2019 | Unified Language Model Pre-training for Natural Language Understanding and Generation | Li Dong, et al. | arXiv | [`PDF`](https://arxiv.org/abs/1905.03197)\n\n| æ¨¡å‹  | ç‰ˆæœ¬ | TensorFlow                                                   | PyTorch                                                      | ä½œè€…                                                    | æºåœ°å€                                              | åº”ç”¨é¢†åŸŸ |\n| ----- | ---- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------- | --------------------------------------------------- | -------- |\n| Unilm | base | [ç™¾åº¦ç½‘ç›˜-tblr](https://pan.baidu.com/s/1HgxIkBl5Yfwrzs1K1B6NFA) | [ç™¾åº¦ç½‘ç›˜-etwf](https://pan.baidu.com/s/1DHJGOFJ5cce5N5g4aBDiMQ) | [YunwenTechnology](https://github.com/YunwenTechnology) | [github](https://github.com/YunwenTechnology/Unilm) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### Simbert \n\n+ 2020 | é±¼ä¸ç†ŠæŒå…¼å¾—ï¼šèåˆæ£€ç´¢å’Œç”Ÿæˆçš„SimBERTæ¨¡å‹ | è‹å‰‘æ—. | spaces | [`Blog post`](https://kexue.fm/archives/7427)\n\n| æ¨¡å‹          | ç‰ˆæœ¬  | TensorFlow                                                   | PyTorch | ä½œè€…                                                    | æºåœ°å€                                                       | åº”ç”¨é¢†åŸŸ |\n| ------------- | ----- | ------------------------------------------------------------ | ------- | ------------------------------------------------------- | ------------------------------------------------------------ | -------- |\n| SimBERT Tiny  | tiny  | [ç™¾åº¦ç½‘ç›˜-1tp7](https://pan.baidu.com/s/1z_agqTuBTuyHANwrS-gPcg) |         | [ZhuiyiTechnology](https://github.com/ZhuiyiTechnology) | [github](https://github.com/ZhuiyiTechnology/pretrained-models) | é€šç”¨     |\n| SimBERT Small | small | [ç™¾åº¦ç½‘ç›˜-nu67](https://pan.baidu.com/s/1kq_EQDI0gpiZBLFd_AxwrA) |         | [ZhuiyiTechnology](https://github.com/ZhuiyiTechnology) | [github](https://github.com/ZhuiyiTechnology/pretrained-models) | é€šç”¨     |\n| SimBERT Base  | base  | [ç™¾åº¦ç½‘ç›˜-6xhq](https://pan.baidu.com/s/1uGfQmX1Kxcv_cXTVsvxTsQ) |         | [ZhuiyiTechnology](https://github.com/ZhuiyiTechnology) | [github](https://github.com/ZhuiyiTechnology/pretrained-models) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### RoFormer-sim\n\n+ 2021 | SimBERTv2æ¥äº†ï¼èåˆæ£€ç´¢å’Œç”Ÿæˆçš„RoFormer-Simæ¨¡å‹ | è‹å‰‘æ—. | spaces | [`Blog post`](https://kexue.fm/archives/8454)\n\n| æ¨¡å‹            | ç‰ˆæœ¬      | TensorFlow                                                   | PyTorch | ä½œè€…                                                    | æºåœ°å€                                                     | åº”ç”¨é¢†åŸŸ |\n| --------------- | --------- | ------------------------------------------------------------ | ------- | ------------------------------------------------------- | ---------------------------------------------------------- | -------- |\n| roformer-sim    | base(L12) | [ç™¾åº¦ç½‘ç›˜-2cgz](https://pan.baidu.com/s/1f1FB288nv1a6jYjsNCordg) |         | [ZhuiyiTechnology](https://github.com/ZhuiyiTechnology) | [github](https://github.com/ZhuiyiTechnology/roformer-sim) | é€šç”¨     |\n| roformer-sim    | small(L6) | [ç™¾åº¦ç½‘ç›˜-h68q](https://pan.baidu.com/s/1r0eJ7shGwQ0RzV9BTFFW4g) |         | [ZhuiyiTechnology](https://github.com/ZhuiyiTechnology) | [github](https://github.com/ZhuiyiTechnology/roformer-sim) | é€šç”¨     |\n| roformer-sim-v2 | base(L12) | [ç™¾åº¦ç½‘ç›˜-w15n](https://pan.baidu.com/s/1Igh3tSvSu_ahDZmGaOlVoA) |         | [ZhuiyiTechnology](https://github.com/ZhuiyiTechnology) | [github](https://github.com/ZhuiyiTechnology/roformer-sim) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### å‘¨æ–‡ç‹\n\n| æ¨¡å‹        | ç‰ˆæœ¬       | ç±»å‹     | TensorFlow | PyTorch                                                      | ä½œè€…                                      | æºåœ°å€                                                 | åº”ç”¨é¢†åŸŸ |\n| ----------- | ---------- | -------- | ---------- | ------------------------------------------------------------ | ----------------------------------------- | ------------------------------------------------------ | -------- |\n| Zhouwenwang | base(L12)  | roformer |            | [[ğŸ¤—HF\\]](https://huggingface.co/IDEA-CCNL/Zhouwenwang-110M) | [IDEA-CCNL](https://github.com/IDEA-CCNL) | [github](https://github.com/IDEA-CCNL/Fengshenbang-LM) | ä¸­æ–‡é€šç”¨ |\n| Zhouwenwang | large(L24) | roformer |            | [[ğŸ¤—HF\\]](https://huggingface.co/IDEA-CCNL/Zhouwenwang-1.3B) | [IDEA-CCNL](https://github.com/IDEA-CCNL) | [github](https://github.com/IDEA-CCNL/Fengshenbang-LM) | ä¸­æ–‡é€šç”¨ |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### CPM-2\n\n+ 2021 | CPM-2: Large-scale Cost-effective Pre-trained Language Models | Zhengyan Zhang, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2106.10715)\n\n| æ¨¡å‹  | ç‰ˆæœ¬       | ä»‹ç»                                | æ¨¡å‹ä¸‹è½½                                                     | ä½œè€…                                        | æºåœ°å€                                        | åº”ç”¨é¢†åŸŸ | å¤‡æ³¨             |\n| ----- | ---------- | ----------------------------------- | ------------------------------------------------------------ | ------------------------------------------- | --------------------------------------------- | -------- | ---------------- |\n| CPM-2 | 110äº¿å‚æ•°  | [é¡¹ç›®é¦–é¡µ](https://wudaoai.cn/home) | [æ¨¡å‹ä¸‹è½½](https://resource.wudaoai.cn/home?ind=2&name=WuDao%20WenYuan&id=1394901846484627456) | [BAAI-WuDao](https://github.com/BAAI-WuDao) | [github](https://github.com/BAAI-WuDao/Model) | é€šç”¨     | éœ€è¦ç”³è¯·æ‰èƒ½ä¸‹è½½ |\n| CPM-2 | 100äº¿å‚æ•°  | [é¡¹ç›®é¦–é¡µ](https://wudaoai.cn/home) | [æ¨¡å‹ä¸‹è½½](https://resource.wudaoai.cn/home?ind=2&name=WuDao%20WenYuan&id=1394901846484627456) | [BAAI-WuDao](https://github.com/BAAI-WuDao) | [github](https://github.com/BAAI-WuDao/Model) | ä¸­è‹±     | éœ€è¦ç”³è¯·æ‰èƒ½ä¸‹è½½ |\n| CPM-2 | 1980äº¿å‚æ•° | [é¡¹ç›®é¦–é¡µ](https://wudaoai.cn/home) | [æ¨¡å‹ä¸‹è½½](https://resource.wudaoai.cn/home?ind=2&name=WuDao%20WenYuan&id=1394901846484627456) | [BAAI-WuDao](https://github.com/BAAI-WuDao) | [github](https://github.com/BAAI-WuDao/Model) | ä¸­è‹±     | éœ€è¦ç”³è¯·æ‰èƒ½ä¸‹è½½ |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### CPT\n\n+ 2021 | CPT: A Pre-Trained Unbalanced Transformer for Both Chinese Language Understanding and Generation | Yunfan Shao, et al. | arxiv | [`PDF`](https://arxiv.org/pdf/2109.05729.pdf)\n\n| æ¨¡å‹      | ç‰ˆæœ¬       | TensorFlow | PyTorch                                              | ä½œè€…                                  | æºåœ°å€                                   | åº”ç”¨é¢†åŸŸ |\n| --------- | ---------- | ---------- | ---------------------------------------------------- | ------------------------------------- | ---------------------------------------- | -------- |\n| CPT-base  | base(L12)  |            | [[ğŸ¤—HF\\]](https://huggingface.co/fnlp/cpt-base)  | [fastNLP](https://github.com/fastnlp) | [github](https://github.com/fastnlp/CPT) | é€šç”¨     |\n| CPT-large | large(L24) |            | [[ğŸ¤—HF\\]](https://huggingface.co/fnlp/cpt-large) | [fastNLP](https://github.com/fastnlp) | [github](https://github.com/fastnlp/CPT) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### GLM\n\n+ 2022 | GLM: General Language Model Pretraining with Autoregressive Blank Infilling | Zhengxiao Du, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2103.10360)\n+ 2022 | GLM-130B: An Open Bilingual Pre-trained Model | Aohan Zeng, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2210.02414)\n\n| æ¨¡å‹     | ç‰ˆæœ¬    | TensorFlow | PyTorch                                                      | ä½œè€…                                        | æºåœ°å€                                      | åº”ç”¨é¢†åŸŸ |\n| -------- | ------- | ---------- | ------------------------------------------------------------ | ------------------------------------------- | ------------------------------------------- | -------- |\n| GLM      | large   |            | [[ğŸ¤—HF\\]](https://huggingface.co/BAAI/glm-large-chinese) | [THUDM](https://github.com/THUDM)           | [github](https://github.com/THUDM/glm)      | é€šç”¨     |\n| GLM      | xxlarge |            | [[ğŸ¤—HF\\]](https://huggingface.co/BAAI/glm-10b-chinese)   | [THUDM](https://github.com/THUDM)           | [github](https://github.com/THUDM/glm)      | é€šç”¨     |\n| GLM-130B | 130B    |            | [ç”³è¯·åœ°å€1](https://models.aminer.cn/glm/zh-CN/download/GLM-130B)[ç”³è¯·åœ°å€2](https://docs.google.com/forms/d/e/1FAIpQLSehr5Dh_i3TwACmFFi8QEgIVNYGmSPwV0GueIcsUev0NEfUug/viewform) | [THUDM](https://models.aminer.cn/glm-130b/) | [github](https://github.com/THUDM/GLM-130B) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### PLUG\n\n+ 2019 | StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding | Wei Wang, et al. | arXiv | [`PDF`](https://arxiv.org/abs/1908.04577)\n+ 2020 | PALM: Pre-training an Autoencoding&Autoregressive Language Model for Context-conditioned Generation | Bin Bi, et al. | ACL| [`PDF`](https://aclanthology.org/2020.emnlp-main.700/)\n\n| æ¨¡å‹ | ç‰ˆæœ¬ | æ¨¡å‹ä¸‹è½½                                                  | ä½œè€…                                  | æºåœ°å€                                                       | åº”ç”¨é¢†åŸŸ |\n| ---- | ---- | --------------------------------------------------------- | ------------------------------------- | ------------------------------------------------------------ | -------- |\n| PLUG | 27B  | [AliceMind-éœ€è¦ç”³è¯·](https://www.alice-mind.com/portal#/) | [Alibaba](https://github.com/alibaba) | [github](https://github.com/alibaba/AliceMind/tree/main/StructBERT) | é€šç”¨     |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### OPD\n\n+ 2022 | å¾…å®š | , et al. | arXiv | [`PDF`]()\n\n| æ¨¡å‹ | ç‰ˆæœ¬ | ä»‹ç»                                                   | æ¨¡å‹ä¸‹è½½                                               | ä½œè€…                                    | æºåœ°å€                                    | åº”ç”¨é¢†åŸŸ       | å¤‡æ³¨             |\n| ---- | ---- | ------------------------------------------------------ | ------------------------------------------------------ | --------------------------------------- | ----------------------------------------- | -------------- | ---------------- |\n| OPD  | 6.3B | [é¡¹ç›®é¦–é¡µ](http://coai.cs.tsinghua.edu.cn/static/opd/) | [æ¨¡å‹ä¸‹è½½](http://coai.cs.tsinghua.edu.cn/static/opd/) | [thu-coai](https://github.com/thu-coai) | [github](https://github.com/thu-coai/OPD) | ä¸­æ–‡å¼€æ”¾åŸŸå¯¹è¯ | éœ€è¦ç”³è¯·æ‰èƒ½ä¸‹è½½ |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n## Multi-Modal\n\n### WenLan\n\n+ 2021 | WenLan: Bridging Vision and Language by Large-Scale Multi-Modal Pre-Training | Yuqi Huo, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2103.06561)\n\n| æ¨¡å‹          | ç‰ˆæœ¬     | ä»‹ç»                                              | æ¨¡å‹ä¸‹è½½                                                     | ä½œè€…                                        | æºåœ°å€                                         | åº”ç”¨é¢†åŸŸ     | å¤‡æ³¨             |\n| ------------- | -------- | ------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------- | ---------------------------------------------- | ------------ | ---------------- |\n| BriVL(WenLan) | 10äº¿å‚æ•° | [é¡¹ç›®é¦–é¡µ](https://wudaoai.cn/model/detail/BriVL) | [æ¨¡å‹ä¸‹è½½](https://wudaoai.cn/model/download?resourceId=1425655534320660480&filename=BriVL-1.0-1B-zh.tar) | [BAAI-WuDao](https://github.com/BAAI-WuDao) | [github](https://github.com/BAAI-WuDao/BriVlL) | ä¸­æ–‡é€šç”¨å›¾æ–‡ | éœ€è¦ç™»é™†æ‰èƒ½ä¸‹è½½ |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### CogView\n\n+ 2021 | CogView: Mastering Text-to-Image Generation via Transformers | Ming Ding, et al. | arXiv | [`PDF`](https://arxiv.org/pdf/2105.13290.pdf)\n\n| æ¨¡å‹    | ç‰ˆæœ¬     | ä»‹ç»                                                | æ¨¡å‹ä¸‹è½½                                            | ä½œè€…                               | æºåœ°å€                                     | åº”ç”¨é¢†åŸŸ           | å¤‡æ³¨             |\n| ------- | -------- | --------------------------------------------------- | --------------------------------------------------- | ---------------------------------- | ------------------------------------------ | ------------------ | ---------------- |\n| CogView | 40äº¿å‚æ•° | [é¡¹ç›®é¦–é¡µ](https://wudaoai.cn/model/detail/CogView) | [æ¨¡å‹ä¸‹è½½](https://wudaoai.cn/model/detail/CogView) | [THUDM ](https://github.com/THUDM) | [github](https://github.com/THUDM/CogView) | ä¸­æ–‡å¤šæ¨¡æ€ç”Ÿæˆæ¨¡å‹ | éœ€è¦ç™»é™†æ‰èƒ½ä¸‹è½½ |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### ç´«ä¸œå¤ªåˆ\n\n\n| æ¨¡å‹                        | ç‰ˆæœ¬     | ä»‹ç»                                                         | æ¨¡å‹ä¸‹è½½                                                     | ä½œè€…                                             | æºåœ°å€                                                      | åº”ç”¨é¢†åŸŸ          | å¤‡æ³¨                                             |\n| --------------------------- | -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------ | ----------------------------------------------------------- | ----------------- | ------------------------------------------------ |\n| ç´«ä¸œå¤ªåˆ- light_vision_text |          | [é¡¹ç›®é¦–é¡µ](https://gitee.com/zidongtaichu/multi-modal-models/tree/master/light_vision_text) | [æ¨¡å‹ä¸‹è½½](https://gitee.com/zidongtaichu/multi-modal-models/tree/master/light_vision_text) | [ä¸­ç§‘é™¢è‡ªåŠ¨åŒ–æ‰€](https://gitee.com/zidongtaichu) | [github](https://gitee.com/zidongtaichu/multi-modal-models) | ä¸­æ–‡å›¾åƒ-æ–‡æœ¬é¢†åŸŸ | ç´«ä¸œå¤ªåˆå¤šæ¨¡æ€å¤§æ¨¡å‹ä¸­çš„å›¾åƒ-æ–‡æœ¬é¢„è®­ç»ƒæ¨¡å‹      |\n| ç´«ä¸œå¤ªåˆ-text[GPT]          | 32äº¿å‚æ•° | [é¡¹ç›®é¦–é¡µ](https://gitee.com/zidongtaichu/multi-modal-models/tree/master/text) | [ç™¾åº¦ç½‘ç›˜-nos5](https://pan.baidu.com/s/1Wsu5OVlQBNai24NhNiaqRw) | [ä¸­ç§‘é™¢è‡ªåŠ¨åŒ–æ‰€](https://gitee.com/zidongtaichu) | [github](https://gitee.com/zidongtaichu/multi-modal-models) | ä¸­æ–‡é€šç”¨          | ç´«ä¸œå¤ªåˆå¤šæ¨¡æ€å¤§æ¨¡å‹ä¸­çš„æ–‡æœ¬é¢„è®­ç»ƒæ¨¡å‹           |\n| ç´«ä¸œå¤ªåˆ-vision             |          | [é¡¹ç›®é¦–é¡µ](https://gitee.com/zidongtaichu/multi-modal-models/tree/master/vision) | [æ¨¡å‹ä¸‹è½½](https://gitee.com/zidongtaichu/multi-modal-models/tree/master/vision) | [ä¸­ç§‘é™¢è‡ªåŠ¨åŒ–æ‰€](https://gitee.com/zidongtaichu) | [github](https://gitee.com/zidongtaichu/multi-modal-models) | è§†è§‰é¢†åŸŸ          | ç´«ä¸œå¤ªåˆå¤šæ¨¡æ€å¤§æ¨¡å‹ä¸­çš„è§†è§‰é¢„è®­ç»ƒæ¨¡å‹           |\n| ç´«ä¸œå¤ªåˆ-speech             |          | [é¡¹ç›®é¦–é¡µ](https://gitee.com/zidongtaichu/multi-modal-models/tree/master/speech) | [æ¨¡å‹ä¸‹è½½](https://gitee.com/zidongtaichu/multi-modal-models/tree/master/speech) | [ä¸­ç§‘é™¢è‡ªåŠ¨åŒ–æ‰€](https://gitee.com/zidongtaichu) | [github](https://gitee.com/zidongtaichu/multi-modal-models) | è¯­éŸ³é¢†åŸŸ          | ç´«ä¸œå¤ªåˆå¤šæ¨¡æ€å¤§æ¨¡å‹ä¸­çš„è¯­éŸ³æ£€æµ‹ä¸è¯†åˆ«å¤šä»»åŠ¡æ¨¡å‹ |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### Mengzi-oscar\n\n+ 2021 | Mengzi: Towards Lightweight yet Ingenious Pre-trained Models for Chinese | Zhuosheng Zhang, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2110.06696)\n\n| æ¨¡å‹         | ç‰ˆæœ¬      | TensorFlow | PyTorch                                                      | ä½œè€…                                    | æºåœ°å€                                       | åº”ç”¨é¢†åŸŸ        |\n| ------------ | --------- | ---------- | ------------------------------------------------------------ | --------------------------------------- | -------------------------------------------- | --------------- |\n| Mengzi-oscar | base(L12) |            | [[ğŸ¤—HF\\]](https://huggingface.co/Langboat/mengzi-oscar-base) | [Langboat](https://github.com/Langboat) | [github](https://github.com/Langboat/Mengzi) | ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡ |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### R2D2\n\n+ 2022 | Zero and R2D2: A Large-scale Chinese Cross-modal Benchmark and A Vision-Language Framework | Chunyu Xie, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2205.03860)\n\n| æ¨¡å‹      | ç‰ˆæœ¬  | TensorFlow | PyTorch                                                      | ä½œè€…                                  | æºåœ°å€                                    | é¦–é¡µ                         | åº”ç”¨é¢†åŸŸ        |\n| --------- | ----- | ---------- | ------------------------------------------------------------ | ------------------------------------- | ----------------------------------------- | ---------------------------- | --------------- |\n| R2D2ViT-L | large |            | [Google](https://drive.google.com/file/d/18Fd3vGvj0Dz8rPlxROxugjZaF8Z4jf7g/view) | [yuxie11](https://github.com/yuxie11) | [github](https://github.com/yuxie11/R2D2) | [zero](https://zero.so.com/) | ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡ |\n| PRD2ViT-L | large |            | [Google](https://drive.google.com/file/d/15zDdam7_-YT0suA3Wc226vvxcyBxWZ_O/view?usp=sharing) | [yuxie11](https://github.com/yuxie11) | [github](https://github.com/yuxie11/R2D2) | [zero](https://zero.so.com/) | ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡ |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### Chinese-CLIP\n\n+ 2021 | Learning Transferable Visual Models From Natural Language Supervision | Alec Radford, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2103.00020)\n+ 2022 | Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese | An Yang, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2211.01335)\n\n| æ¨¡å‹                             | ç‰ˆæœ¬ | TensorFlow | PyTorch                                                      | ä½œè€…                                  | æºåœ°å€                                            | åº”ç”¨é¢†åŸŸ        |\n| -------------------------------- | ---- | ---------- | ------------------------------------------------------------ | ------------------------------------- | ------------------------------------------------- | --------------- |\n| CN-CLIP<sub>RN50</sub>           | 77M  |            | [aliyuncs](https://clip-cn-beijing.oss-cn-beijing.aliyuncs.com/checkpoints/clip_cn_rn50.pt) | [OFA-Sys](https://github.com/OFA-Sys) | [github](https://github.com/OFA-Sys/Chinese-CLIP) | ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡ |\n| CN-CLIP<sub>ViT-B/16</sub>       | 188M |            | [aliyuncs](https://clip-cn-beijing.oss-cn-beijing.aliyuncs.com/checkpoints/clip_cn_vit-b-16.pt) | [OFA-Sys](https://github.com/OFA-Sys) | [github](https://github.com/OFA-Sys/Chinese-CLIP) | ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡ |\n| CN-CLIP<sub>ViT-L/14</sub>       | 406M |            | [aliyuncs](https://clip-cn-beijing.oss-cn-beijing.aliyuncs.com/checkpoints/clip_cn_vit-l-14.pt) | [OFA-Sys](https://github.com/OFA-Sys) | [github](https://github.com/OFA-Sys/Chinese-CLIP) | ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡ |\n| CN-CLIP<sub>ViT-L/14@336px</sub> | 407M |            | [aliyuncs](https://clip-cn-beijing.oss-cn-beijing.aliyuncs.com/checkpoints/clip_cn_vit-l-14-336.pt) | [OFA-Sys](https://github.com/OFA-Sys) | [github](https://github.com/OFA-Sys/Chinese-CLIP) | ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡ |\n| CN-CLIP<sub>ViT-H/14</sub>       | 958M |            | [aliyuncs](https://clip-cn-beijing.oss-cn-beijing.aliyuncs.com/checkpoints/clip_cn_vit-h-14.pt) | [OFA-Sys](https://github.com/OFA-Sys) | [github](https://github.com/OFA-Sys/Chinese-CLIP) | ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡ |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### TaiYi-CLIP\n\n+ 2021 | Learning Transferable Visual Models From Natural Language Supervision | Alec Radford, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2103.00020)\n+ 2022 | Fengshenbang 1.0: Being the Foundation of Chinese Cognitive Intelligence | Junjie Wang, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2209.02970)\n\n| æ¨¡å‹                                  | ç‰ˆæœ¬ | TensorFlow | PyTorch                                                      | ä½œè€…                                      | æºåœ°å€                                                 | åº”ç”¨é¢†åŸŸ        |\n| ------------------------------------- | ---- | ---------- | ------------------------------------------------------------ | ----------------------------------------- | ------------------------------------------------------ | --------------- |\n| Taiyi-CLIP-Roberta-large-326M-Chinese | base |            | [[ğŸ¤—HF\\]](https://huggingface.co/IDEA-CCNL/Taiyi-CLIP-Roberta-large-326M-Chinese) | [IDEA-CCNL](https://github.com/IDEA-CCNL) | [github](https://github.com/IDEA-CCNL/Fengshenbang-LM) | ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡ |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### AltCLIP\n\n+ 2022 | AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities | Chen, Zhongzhi, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2211.06679)\n\n| æ¨¡å‹    | ç‰ˆæœ¬  | TensorFlow | PyTorch                                            | ä½œè€…                                     | æºåœ°å€                                                       | åº”ç”¨é¢†åŸŸ        |\n| ------- | ----- | ---------- | -------------------------------------------------- | ---------------------------------------- | ------------------------------------------------------------ | --------------- |\n| AltCLIP | 3.22G |            | [[ğŸ¤—HF\\]](https://huggingface.co/BAAI/AltCLIP) | [FlagAI](https://github.com/FlagAI-Open) | [github](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltCLIP) | ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡ |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### AltDiffusion\n\n+ 2022 | AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities | Chen, Zhongzhi, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2211.06679)\n+ 2022 | High-Resolution Image Synthesis With Latent Diffusion Models | Rombach, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2112.10752)\n\n| æ¨¡å‹         | ç‰ˆæœ¬ | TensorFlow | PyTorch                                                 | ä½œè€…                                     | æºåœ°å€                                                       | åº”ç”¨é¢†åŸŸ        |\n| ------------ | ---- | ---------- | ------------------------------------------------------- | ---------------------------------------- | ------------------------------------------------------------ | --------------- |\n| AltDiffusion | 8.0G |            | [[ğŸ¤—HF\\]](https://huggingface.co/BAAI/AltDiffusion) | [FlagAI](https://github.com/FlagAI-Open) | [github](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltDiffusion) | ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡ |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### Taiyi-Stable-Diffusion\n\n+ 2022 | Fengshenbang 1.0: Being the Foundation of Chinese Cognitive Intelligence | Junjie Wang, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2209.02970)\n+ 2022 | High-Resolution Image Synthesis With Latent Diffusion Models | Rombach, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2112.10752)\n\n| æ¨¡å‹                   | ç‰ˆæœ¬ | TensorFlow | PyTorch                                                      | ä½œè€…                                      | æºåœ°å€                                                 | åº”ç”¨é¢†åŸŸ        |\n| ---------------------- | ---- | ---------- | ------------------------------------------------------------ | ----------------------------------------- | ------------------------------------------------------ | --------------- |\n| Taiyi-Stable-Diffusion | 1B   |            | [[ğŸ¤—HF\\]](https://huggingface.co/IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-v0.1) | [IDEA-CCNL](https://github.com/IDEA-CCNL) | [github](https://github.com/IDEA-CCNL/Fengshenbang-LM) | ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡ |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### wukong\n\n+ 2022 | Wukong: A 100 Million Large-scale Chinese Cross-modal Pre-training Benchmark | Jiaxi Gu, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2202.06767)\n\n| æ¨¡å‹   | ç‰ˆæœ¬ | TensorFlow | PyTorch                                                      | ä½œè€…                                     | æºåœ°å€                                                       | åº”ç”¨é¢†åŸŸ        |\n| ------ | ---- | ---------- | ------------------------------------------------------------ | ---------------------------------------- | ------------------------------------------------------------ | --------------- |\n| CLIP   |      |            | [url](https://wukong-dataset.github.io/wukong-dataset/benchmark.html) | [HUAWEI](https://github.com/huawei-noah) | [github](https://github.com/huawei-noah/Pretrained-Language-Model) | ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡ |\n| FILIP  |      |            | [url](https://wukong-dataset.github.io/wukong-dataset/benchmark.html) | [HUAWEI](https://github.com/huawei-noah) | [github](https://github.com/huawei-noah/Pretrained-Language-Model) | ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡ |\n| wukong |      |            | [url](https://wukong-dataset.github.io/wukong-dataset/benchmark.html) | [HUAWEI](https://github.com/huawei-noah) | [github](https://github.com/huawei-noah/Pretrained-Language-Model) | ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡ |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### OFA\n\n+ 2022 | OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework | Peng Wang, et al. | arXiv | [`PDF`](https://arxiv.org/pdf/2202.03052.pdf)\n\n| æ¨¡å‹        | ç‰ˆæœ¬ | TensorFlow | PyTorch                                                      | ä½œè€…                                            | æºåœ°å€                                                | åº”ç”¨é¢†åŸŸ        |\n| ----------- | ---- | ---------- | ------------------------------------------------------------ | ----------------------------------------------- | ----------------------------------------------------- | --------------- |\n| OFA         |      |            | [link](https://github.com/OFA-Sys/OFA/blob/main/checkpoints_cn.md) | [OFA-Sys](https://github.com/OFA-Sys)           | [github](https://github.com/OFA-Sys/OFA)              | ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡ |\n| OFA-Chinese |      |            | [[ğŸ¤—HF\\]](https://huggingface.co/YeungNLP/ofa-cn-base-muge-v2) | [Yang JianXin](https://github.com/yangjianxin1) | [github](https://github.com/yangjianxin1/OFA-Chinese) | ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡ |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### QA-CLIP\n\n| æ¨¡å‹            | ç‰ˆæœ¬ | è§†è§‰æ¶æ„ | PyTorch                                                      | ä½œè€…                                     | æºåœ°å€                                                       | åº”ç”¨é¢†åŸŸ        |\n| --------------- | ---- | -------- | ------------------------------------------------------------ | ---------------------------------------- | ------------------------------------------------------------ | --------------- |\n| QA-CLIPRN50     | 77M  | ResNet50 | [[ğŸ¤—HF\\]](https://huggingface.co/TencentARC/QA-CLIP/resolve/main/QA-CLIP-RN50.pt) | [è…¾è®¯](https://github.com/TencentARC-QQ) | [QA-CLIP](https://github.com/TencentARC-QQ/QA-CLIP)![Star](https://img.shields.io/github/stars/TencentARC-QQ/QA-CLIP.svg?style=social&label=Star) | ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡ |\n| QA-CLIPViT-B/16 | 188M | ViT-B/16 | [[ğŸ¤—HF\\]](https://huggingface.co/TencentARC/QA-CLIP/resolve/main/QA-CLIP-base.pt) | [è…¾è®¯](https://github.com/TencentARC-QQ) | [QA-CLIP](https://github.com/TencentARC-QQ/QA-CLIP)![Star](https://img.shields.io/github/stars/TencentARC-QQ/QA-CLIP.svg?style=social&label=Star) | ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡ |\n| QA-CLIPViT-L/14 | 406M | ViT-L/14 | [[ğŸ¤—HF\\]](https://huggingface.co/TencentARC/QA-CLIP/resolve/main/QA-CLIP-large.pt) | [è…¾è®¯](https://github.com/TencentARC-QQ) | [QA-CLIP](https://github.com/TencentARC-QQ/QA-CLIP)![Star](https://img.shields.io/github/stars/TencentARC-QQ/QA-CLIP.svg?style=social&label=Star) | ä¸­æ–‡å¤šæ¨¡æ€-å›¾æ–‡ |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n## Table\n\n### SDCUP\n\n+ 2021 | Improving Text-to-SQL with Schema Dependency Learning | Binyuan Hui, et al. | arXiv | [`PDF`](https://arxiv.org/abs/2103.04399)\n\n| æ¨¡å‹  | ç‰ˆæœ¬  | TensorFlow | PyTorch                                                      | ä½œè€…                                  | æºåœ°å€                                                       | åº”ç”¨é¢†åŸŸ |\n| ----- | ----- | ---------- | ------------------------------------------------------------ | ------------------------------------- | ------------------------------------------------------------ | -------- |\n| sdcup | base  |            | [é˜¿é‡Œäº‘](http://alice-open.oss-cn-zhangjiakou.aliyuncs.com/SDCUP/sdcup_base_model.bin-50000) | [Alibaba](https://github.com/alibaba) | [github](https://github.com/alibaba/AliceMind/tree/main/SDCUP) | ä¸­æ–‡è¡¨æ ¼ |\n| sdcup | large |            | [é˜¿é‡Œäº‘](http://alice-open.oss-cn-zhangjiakou.aliyuncs.com/SDCUP/sdcup_large_model.bin-60000) | [Alibaba](https://github.com/alibaba) | [github](https://github.com/alibaba/AliceMind/tree/main/SDCUP) | ä¸­æ–‡è¡¨æ ¼ |\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n\n## æ›´æ–°\n\n* 2025ã€‚01.02 å¢åŠ [Huatuo-o1](#ReasoningLLM)\n* 2024.12.25 å¢åŠ [QVQ-72B]\n* 2024.12.16 å¢åŠ [Megrez-3B-Omni, DeepSeek-VL2]\n* 2024.11.29 å¢åŠ [QwQ-32B-Preview,Marco-o1 ,Skywork-01-Open,HK-01aw](#ReasoningLLM)\n* 2024.11.15 å¢åŠ [Qwen-2.5-coder, OpenCoder](#Domain-ChatLLM)\n* 2024.11.05 å¢åŠ [Hunyuan-Large](#Chat-LLM)\n* 2024.10.26 å¢åŠ [GLM-4-Voice,Pangea,Aya-Expanse]()\n* 2024.10.22 å¢åŠ [Granite 3.0](#Chat-LLM),ä¸€å¥—å…¨æ–°çš„è½»é‡çº§ã€å¤šè¯­ç§æ”¯æŒçš„è¯­è¨€æ¨¡å‹ï¼Œä¸“ä¸ºæ¨ç†ã€ç¼–ç¨‹å’Œå·¥å…·ä½¿ç”¨è®¾è®¡ï¼Œå¯åœ¨è®¡ç®—èµ„æºå—é™çš„ç¯å¢ƒä¸­è¿è¡Œï¼Œé€‚åˆä¼ä¸šä½¿ç”¨å’Œå®šåˆ¶\n* 2024.09.19 å¢åŠ [Qwen2.5](#Chat-LLM)\n* 2024.09.08 å¢åŠ [DeepSeekV2.5, MiniCPM3, Yi-Coder](#Chat-LLM)\n* 2024.08.30 å¢åŠ [C4AI Command R+ 08-2024,Qwen2-VL](#Chat-LLM)\n* 2024.07.26 å¢åŠ [JIUTIAN-Chat,Tele-FLM]()\n* 2024.07.24 å¢åŠ [Meta-llama3.1](#Chat-LLM)\n* 2024.07.05 å¢åŠ [CodeGeeX4](#Domain-ChatLLM)\n* 2024.07.04 å¢åŠ [internlm2.5](#Chat-LLM)\n* 2024.06.19 å¢åŠ [MAP-NEO-Chat](#Chat-LLM)ï¼ŒMAP-NEO is a fully open-sourced Large Language Model that includes the pretraining data, a data processing pipeline (Matrix), pretraining scripts, and alignment code.\n* 2024.06.18 å¢åŠ [DeepSeek-Coder-V2ã€Nemotron-4](#Chat-LLM)\n* 2024.06.14 å¢åŠ [Index-Chat](#Chat-LLM)\n* 2024.06.08 å¢åŠ [Qwen2,ChatTTS](#Chat-LLM)\n* 2024.06.03 å¢åŠ [GLM-4ã€Skywork-MoE](#Chat-LLM)\n* 2024.05.30 å¢åŠ [Yuan2.0-M32: Mixture of Experts with Attention Router](#ChatLLM)\n* 2024.05.20 å¢åŠ [CogVLM2,360VL,HunyuanDiT,æ˜Ÿè¾°-Chat]\n* 2024.05.13 å¢åŠ [Yi-1.5]\n* 2024.05.07 å¢åŠ [XVERSE-V,DeepSeek-V2,XVERSE-MoE]\n* 2024.04.27 å¢åŠ [Qwen1.5-110B, Llama3-zh](#Chat-LLM)\n* 2024.04.14 å¢åŠ [MiniCPM-V2ã€WaveCoderã€codegemmaã€Sailorã€Nanbeige2-Chatã€MiniCPM-MoEã€Zhinao-Chat]()\n* 2024.04.12 å¢åŠ [XVERSE-MoE](#LLM)\n* 2024.04.08 å¢åŠ [SoftTigerã€HammerLLM](#LLM)\n* 2024.04.06 å¢åŠ [Qwen1.5-32B](#ChatLLM)\n* 2024.04.04 å¢åŠ [Mengzi3](#ChatLLM)\n* 2024.03.29 å¢åŠ [Qwen-Audioã€Qwen-MoE](#ChatLLM)\n* 2024.03.13 å¢åŠ [Command-R](#ChatLLM)\n* 2024.03.01 å¢åŠ [Breeze-Instruct, starcoder2](#ChatLLM)\n* 2024.02.18 å¢åŠ [aya-101ã€chemLLM](#ChatLLM)\n* 2024.02.06 å¢åŠ [Qwen1.5](#ChatLLM)\n* 2024.02.02 å¢åŠ [MiniCPM, TuringMM-Chat](#ChatLLM)\n* 2024.02.01 å¢åŠ [LongAlign-Chatï¼ŒChinese-Mixtral-Chat](#ChatLLM)\n* 2024.01.31 å¢åŠ [iFlytekSpark-Chatï¼Œrwkv-5-world](#ChatLLM)\n* 2024.01.23 å¢åŠ [Yi-VL-6/34B](#MultiModal-ChatLLM)\n* 2024.01.22 å¢åŠ [orion-4B](#ChatLLM)\n* 2024.01.19 å¢åŠ [internlm2-chatï¼ŒChinese-Mixtral](#ChatLLM)\n* 2024.01.10 å¢åŠ [Telechatï¼ŒCode Millenials](#ChatLLM)\n* 2024.01.09 å¢åŠ [kagentlms](#ChatLLM),å…·æœ‰Agentsçš„è§„åˆ’ã€åæ€ã€å·¥å…·ä½¿ç”¨ç­‰èƒ½åŠ›çš„ç³»åˆ—å¤§æ¨¡å‹\n* 2024.01.05 å¢åŠ [WizardCoder-33B-V1.1](#Domain-ChatLLM)\n* 2023.12.27 å¢åŠ [YaYi-30B-Chat](#ChatLLM)\n* 2023.12.05 å¢åŠ [SUS-Chat-34Bã€Aquila2-Chat-70Bã€Alaya-Chat-7B](#ChatLLM)\n* 2023.12.01 å¢åŠ [Qwen-Base-1.8/72B](#Base-LLM),[Qwen-Chat-1.8/72B](#ChatLLM),[Qwen-Audio](#MultiModal-ChatLLM)\n* 2023.11.30 å¢åŠ [Yuan-2.0ã€DeepSeek-Base](#Base-LLM),[DeepSeek-Chat](#ChatLLM)\n* 2023.11.20 å¢åŠ [Alaya-Chat-7Bã€OrionStar-Yi-Chat-34B](#ChatLLM)\n* 2023.11.11 å¢åŠ [XVERSE-65Bã€Nanbeige-Chat-16Bã€OpenChat 3.5](#ChatLLM)\n* 2023.11.03 å¢åŠ [SPHINXã€Tongyi-Financeã€Phindã€DeepSeek-Coder](#ChatLLM)\n* 2023.11.02 å¢åŠ [AndesGPT-7Bã€SeaLLMã€BlueLM](#ChatLLM)\n* 2023.10.31 å¢åŠ [Zephyr-7Bã€Mistral-7b](#ChatLLM)\n* 2023.10.25 å¢åŠ [zhiyinã€zhilu]()\n* 2023.10.20 å¢åŠ [crossã€taiyiã€fuyuã€Ziya-visualã€CodeShellã€CogVLM]()\n* 2023.10.17 å¢åŠ [Ziya2-13B-Baseã€Ziya2-13B-Chat](#ChatLLM)\n* 2023.10.12 å¢åŠ [AquilaChat2-7/13Bã€AquilaChat2-16Kã€Vulture-180B](#ChatLLM)\n* 2023.10.04 å¢åŠ [DISC-LawLLMã€WiNGPTã€ziya-codingã€Vultureã€AgriGPT](#ChatLLM)\n* 2023.09.25 å¢åŠ [Colossal-LLaMA-2-7B](#ChatLLM),ç›¸è¾ƒäºåŸå§‹LLaMA-2ï¼Œåœ¨æˆåŠŸæå‡ä¸­æ–‡èƒ½åŠ›çš„åŸºç¡€ä¸Šï¼Œè¿›ä¸€æ­¥æå‡å…¶è‹±æ–‡èƒ½åŠ›ï¼Œæ€§èƒ½å¯ä¸å¼€æºç¤¾åŒºåŒè§„æ¨¡é¢„è®­ç»ƒSOTAæ¨¡å‹åª²ç¾ã€‚\n* 2023.09.20 å¢åŠ [InternLM-20Bã€OpenBA](#ChatLLM),InternLM-20Bå·²å‘å¸ƒï¼ŒåŒ…æ‹¬åŸºç¡€ç‰ˆå’Œå¯¹è¯ç‰ˆã€‚OpenBAæ˜¯ä¸€ä¸ªä»å¤´å¼€å§‹é¢„è®­ç»ƒçš„å¼€æº15BåŒè¯­éå¯¹ç§°ç«¯åˆ°ç«¯æ¨¡å‹ã€‚\n* 2023.09.08 å¢åŠ [FLM-101Bã€falcon-180Bã€Openbuddy-70Bã€TigerBot-70B](#ChatLLM)\n* 2023.09.06 å¢åŠ [Baichuan2](#ChatLLM),Baichuan 2 æ˜¯ç™¾å·æ™ºèƒ½æ¨å‡ºçš„æ–°ä¸€ä»£å¼€æºå¤§è¯­è¨€æ¨¡å‹ï¼Œé‡‡ç”¨ 2.6 ä¸‡äº¿ Tokens çš„é«˜è´¨é‡è¯­æ–™è®­ç»ƒã€‚\n* 2023.09.01 å¢åŠ [DISC-MedLLMã€YuLan-Chat-2ã€Chinese-Alpaca-2-16K](#ChatLLM),[Vally](#MultiModal-ChatLLM)\n* 2023.08.29 å¢åŠ [CodeLLAmaã€Atom](#ChatLLM),[IDEFICS](#MultiModal-ChatLLM)\n* 2023.08.25 å¢åŠ [sqlcoder](#ChatLLM),ä¸€ä¸ª SOTA å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œ SQLCoder å°†è‡ªç„¶è¯­è¨€é—®é¢˜è½¬æ¢ä¸º SQL æŸ¥è¯¢ã€‚åœ¨å¼€å‘è€…çš„å¼€æºè¯„ä¼°æ¡†æ¶ SQLEval ä¸­ï¼ŒSQLCoder çš„æ€§èƒ½æ˜æ˜¾ä¼˜äºæ‰€æœ‰ä¸»è¦çš„å¼€æºæ¨¡å‹ï¼Œå¹¶ä¸”ä¼˜äº OpenAI çš„ GPT-3.5ã€‚\n* 2023.08.23 å¢åŠ [Qwen-VL](#MultiModal-ChatLLM),Qwen-VL æ˜¯é˜¿é‡Œäº‘ç ”å‘çš„å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLarge Vision Language Model, LVLMï¼‰ã€‚Qwen-VL å¯ä»¥ä»¥å›¾åƒã€æ–‡æœ¬ã€æ£€æµ‹æ¡†ä½œä¸ºè¾“å…¥ï¼Œå¹¶ä»¥æ–‡æœ¬å’Œæ£€æµ‹æ¡†ä½œä¸ºè¾“å‡ºã€‚\n* 2023.08.21 å¢åŠ [æ™ºæµ·-å½•é—®](#ChatLLM),æ™ºæµ·-å½•é—®(wisdomInterrogatory)æ˜¯ç”±æµ™æ±Ÿå¤§å­¦ã€é˜¿é‡Œå·´å·´è¾¾æ‘©é™¢ä»¥åŠåé™¢è®¡ç®—ä¸‰å®¶å•ä½å…±åŒè®¾è®¡ç ”å‘çš„æ³•å¾‹å¤§æ¨¡å‹ã€‚\n* 2023.08.15 å¢åŠ [WizardMath](#ChatLLM),\n* 2023.08.09 å¢åŠ [TigerBot-13B](#ChatLLM),åœ¨Llama-2çš„åŸºç¡€ä¸Šä»¥è™åšç§¯ç´¯çš„æŠ€æœ¯å’Œæ•°æ®ç»§ç»­è®­ç»ƒï¼Œä¸ä½†ä¿æŒäº†Llama-2å‡ºè‰²çš„è‹±æ–‡èƒ½åŠ›ï¼Œæ›´æ˜¯åœ¨ä¸­æ–‡èƒ½åŠ›ä¸Šå¡«è¡¥äº†Llama-2çš„ä¸è¶³ï¼Œå„é¡¹ä¸»æµä¸­æ–‡ä»»åŠ¡ä¸­è¶…è¿‡Llama-2çš„49%ï¼Œåœ¨å¼€æºåŒç±»æ¨¡å‹ä¸­å…·æœ‰ç«äº‰åŠ›ã€‚\n* 2023.08.07 å¢åŠ [XVERSE-13B](#ChatLLM),XVERSE-13B,å®ƒæ”¯æŒ40å¤šç§è¯­è¨€ã€8192ä¸Šä¸‹æ–‡é•¿åº¦ã€‚åœ¨å¤šé¡¹ä¸­è‹±æ–‡æµ‹è¯„ä¸­ï¼Œæ€§èƒ½è¶…è¿‡äº†åŒå°ºå¯¸ï¼ˆ130äº¿å‚æ•°ï¼‰çš„LLama2ã€Baichuanç­‰ã€‚\n* 2023.08.03 å¢åŠ [é€šä¹‰åƒé—®](#ChatLLM),é€šä¹‰åƒé—®-7Bï¼ˆQwen-7Bï¼‰æ˜¯é˜¿é‡Œäº‘ç ”å‘çš„é€šä¹‰åƒé—®å¤§æ¨¡å‹ç³»åˆ—çš„70äº¿å‚æ•°è§„æ¨¡çš„æ¨¡å‹ã€‚\n* 2023.07.31 å¢åŠ [LLasMã€Chinese-LLaVA](#MultiModal-ChatLLM)å¤šæ¨¡æ€å¤§æ¨¡å‹\n* 2023.07.31 å¢åŠ [Chinese-Llama-2](#ChatLLM).åŸç‰ˆLlama-2çš„åŸºç¡€ä¸Šæ‰©å……å¹¶ä¼˜åŒ–äº†ä¸­æ–‡è¯è¡¨ï¼Œä½¿ç”¨äº†120Gå¤§è§„æ¨¡ä¸­æ–‡æ•°æ®è¿›è¡Œå¢é‡é¢„è®­ç»ƒï¼Œç›¸å…³æ¨¡å‹æ”¯æŒ4Kä¸Šä¸‹æ–‡å¹¶å¯é€šè¿‡NTKæ–¹æ³•æœ€é«˜æ‰©å±•è‡³18K+\n* 2023.07.29 å¢åŠ [BatGPTï¼ŒMoziï¼ŒStarGLM](#ChatLLM).\n* 2023.07.27 å¢åŠ [WizardLM-v1.2](#ChatLLM).\n* 2023.07.25 å¢åŠ ç›¸å…³[Awesomeåˆ—è¡¨](#other-awesome)\n* 2023.07.24 å¢åŠ [Llama2-chinese-chatã€Jiang-chat](#ChatLLM)ç­‰å¯¹è¯è¯­è¨€æ¨¡å‹ã€‚\n* 2023.07.19 å¢åŠ [LLaMA2](#LLM),Meta å‘å¸ƒäº†å¤§å®¶æœŸå¾…å·²ä¹…çš„å…è´¹å¯å•†ç”¨ç‰ˆæœ¬ Llama 2ã€‚\n* 2023.07.16 å¢åŠ [PolyLM](#LLM),PolyLMæ˜¯ä¸€ä¸ªé€šæ™“å¤šè¯­è¨€è¯­è¨€çš„å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥åº”ç”¨äºå¯¹è¯é—®ç­”ã€æ–‡æœ¬ç”Ÿæˆã€æœºå™¨ç¿»è¯‘å’Œæƒ…æ„Ÿåˆ†æç­‰é¢†åŸŸï¼Œèƒ½å¤Ÿè‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„å¤šè¯­è¨€æ–‡æœ¬ã€‚\n* 2023.07.11 å¢åŠ [Baichuan-13B](#LLM),baichuan-13Bæ˜¯ç”±ç™¾å·æ™ºèƒ½å¼€å‘çš„ä¸€ä¸ªå¼€æºå¯å•†ç”¨çš„å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚\n* 2023.07.10 å¢åŠ WizardLM-13B-V1.1\n* 2023.07.09 å¢åŠ VisualCLAå¤šæ¨¡æ€å¤§æ¨¡å‹\n* 2023.07.04 å¢åŠ [ä¹¦ç”ŸÂ·æµ¦è¯­](#ChatLLM),ä¹¦ç”ŸÂ·æµ¦è¯­å¤§æ¨¡å‹ï¼ŒåŒ…å«é¢å‘å®ç”¨åœºæ™¯çš„70äº¿å‚æ•°åŸºç¡€æ¨¡å‹ä¸å¯¹è¯æ¨¡å‹.\n* 2023.07.04 å¢åŠ [yuren](#MultiModal-ChatLLM),[vicuna,CuteGPT,ailawyer](#ChatLLM)\n* 2023.06.30 å¢åŠ [VisCPM](#MultiModal-ChatLLM),VisCPM æ˜¯ä¸€ä¸ªå¼€æºçš„å¤šæ¨¡æ€å¤§æ¨¡å‹ç³»åˆ—ï¼Œæ”¯æŒä¸­è‹±åŒè¯­çš„å¤šæ¨¡æ€å¯¹è¯èƒ½åŠ›ï¼ˆVisCPM-Chatæ¨¡å‹ï¼‰å’Œæ–‡åˆ°å›¾ç”Ÿæˆèƒ½åŠ›ï¼ˆVisCPM-Paintæ¨¡å‹ï¼‰ï¼Œåœ¨ä¸­æ–‡å¤šæ¨¡æ€å¼€æºæ¨¡å‹ä¸­è¾¾åˆ°æœ€ä½³æ°´å¹³ã€‚\n* 2023.06.28 å¢åŠ [PULSE](#ChatLLM),PULSE-ä¸­æ–‡åŒ»ç–—å¤§è¯­è¨€æ¨¡å‹ã€‚\n* 2023.06.26 å¢åŠ [CoLLaMA](#ChatLLM),CoLLaMAæ˜¯åŸºäºä»£ç çš„å¤šè¯­è¨€å¤§æ¨¡å‹ã€‚\n* 2023.06.25 å¢åŠ [ChatGLM2-6B](#ChatLLM),ChatGLM2-6B æ˜¯å¼€æºä¸­è‹±åŒè¯­å¯¹è¯æ¨¡å‹ ChatGLM-6B çš„ç¬¬äºŒä»£ç‰ˆæœ¬ã€‚\n* 2023.06.24 å¢åŠ [TechGPT](#ChatLLM),TechGPTæ˜¯â€œä¸œåŒ—å¤§å­¦çŸ¥è¯†å›¾è°±ç ”ç©¶ç»„â€å‘å¸ƒçš„å‚ç›´é¢†åŸŸå¤§è¯­è¨€æ¨¡å‹ã€‚\n* 2023.06.20 å¢åŠ [Yayiã€BayLing](#ChatLLM),ç™¾è†ï¼ˆBayLingï¼‰æ˜¯ä¸€ä¸ªå¼ºåŒ–äº†è¯­è¨€å¯¹é½çš„æŒ‡ä»¤è·Ÿéšå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹;Yayiå¤§æ¨¡å‹ åœ¨ç™¾ä¸‡çº§äººå·¥æ„é€ çš„é«˜è´¨é‡é¢†åŸŸæ•°æ®ä¸Šè¿›è¡ŒæŒ‡ä»¤å¾®è°ƒå¾—åˆ°ï¼Œè®­ç»ƒæ•°æ®è¦†ç›–åª’ä½“å®£ä¼ ã€èˆ†æƒ…åˆ†æã€å…¬å…±å®‰å…¨ã€é‡‘èé£æ§ã€åŸå¸‚æ²»ç†ç­‰äº”å¤§é¢†åŸŸã€‚\n* 2023.06.19 å¢åŠ [panda](#ChatLLM),Pandaæ˜¯æµ·å¤–ä¸­æ–‡å¼€æºå¤§è¯­è¨€æ¨¡å‹ã€‚\n* 2023.06.18 å¢åŠ [ZhiXi](#ChatLLM),ZhiXiåŸºäºLlamaçš„é’ˆå¯¹çŸ¥è¯†æŠ½å–çš„å¤§æ¨¡å‹ã€‚\n* 2023.06.15 å¢åŠ [Baichuan-7B](#LLM),baichuan-7Bæ˜¯ç”±ç™¾å·æ™ºèƒ½å¼€å‘çš„ä¸€ä¸ªå¼€æºå¯å•†ç”¨çš„å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚\n* 2023.06.14 å¢åŠ [Chinese-Falcon](#LLM),Chinese-Falcon æ¨¡å‹åœ¨ Falcon åŸºç¡€ä¸Šæ‰©å……ä¸­æ–‡è¯è¡¨ï¼Œåœ¨ä¸­è‹±æ–‡æ•°æ®ä¸Šå¢é‡é¢„è®­ç»ƒã€‚ æ¨¡å‹ä»¥ Apache License 2.0 åè®®å¼€æºï¼Œæ”¯æŒå•†ä¸šç”¨é€”ã€‚ã€‚\n* 2023.06.13 å¢åŠ [OpenLLaMA-Chinese](#ChatLLM),OpenLLaMA-Chineseæ˜¯å…è´¹çš„ä¸­æ–‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ŒåŸºäºOpenLLaMAï¼Œå¯ç”¨äºéå•†ä¸šå’Œå•†ä¸šç›®çš„ã€‚\n* 2023.06.09 å¢åŠ [QA-CLIP](#QA-CLIP),[M3E](#M3E),[Aquila](#LLM),QA-CLIPæ˜¯ä¸­æ–‡CLIPæ¨¡å‹,M3Eæ˜¯æ–‡æœ¬åµŒå…¥æ¨¡å‹,Aquilaæ˜¯è¯­è¨€å¤§æ¨¡å‹ã€‚\n* 2023.06.08 å¢åŠ [YuLan](#ChatLLM),YuLanæ˜¯ç”±ä¸­å›½äººåå¤§å­¦å¼€æºçš„åŒè¯­è¨€ä»»åŠ¡å¤§æ¨¡å‹,å¼€æº13Bå’Œ65Bå¤§å°ã€‚\n* 2023.06.08 å¢åŠ [Chinese-Alpaca-33B](#ChatLLM),[Chinese-LLaMA-33B](#LLM)ï¼Œä¸­æ–‡LLaMA/Alpaca-33Bã€‚\n* 2023.06.07 å¢åŠ [Tigerbot](#ChatLLM),TigerBotæ˜¯ä¸€æ¬¾å›½äº§è‡ªç ”çš„å¤šè¯­è¨€ä»»åŠ¡å¤§æ¨¡å‹,å¼€æº7Bå’Œ180Bå¤§å°ã€‚\n* 2023.06.06 å¢åŠ [Video-LLaMA](#MultiModal-ChatLLM),[BiLLa](#ChatLLM),Video-LLaMAæ˜¯ä¸€ä¸ªç”¨äºè§†é¢‘ç†è§£çš„æŒ‡ä»¤è°ƒæ•´çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ŒBiLLaæ˜¯å¼€æºçš„æ¨ç†èƒ½åŠ›å¢å¼ºçš„ä¸­è‹±åŒè¯­LLaMAæ¨¡å‹ã€‚\n* 2023.05.26 å¢åŠ [XuanYuan](#ChatLLM),[XrayGLM](#MultiModal-ChatLLM),XuanYuanæ˜¯å›½å†…é¦–ä¸ªå¼€æºçš„åƒäº¿çº§ä¸­æ–‡å¯¹è¯å¤§æ¨¡å‹,XrayGLMæ˜¯ä¸­æ–‡åŒ»å­¦é¢†åŸŸå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ã€‚\n* 2023.05.21 å¢åŠ [ziya,BLOOMChat](#ChatLLM),Ziya-LLaMA-13B-v1æ‹¥æœ‰130äº¿å‚æ•°ï¼Œä»LLaMA-13Bå¼€å§‹é‡æ–°æ„å»ºä¸­æ–‡è¯è¡¨ï¼Œè¿›è¡Œåƒäº¿tokené‡çº§çš„å·²çŸ¥çš„æœ€å¤§è§„æ¨¡ç»§ç»­é¢„è®­ç»ƒï¼Œä½¿æ¨¡å‹å…·å¤‡åŸç”Ÿä¸­æ–‡èƒ½åŠ›.\n* 2023.05.18 å¢åŠ [VisualGLM-6B](#MultiModal-ChatLLM),VisualGLM-6B æ˜¯ä¸€ä¸ªå¼€æºçš„ï¼Œæ”¯æŒå›¾åƒã€ä¸­æ–‡å’Œè‹±æ–‡çš„å¤šæ¨¡æ€å¯¹è¯è¯­è¨€æ¨¡å‹ã€‚\n* 2023.05.16 å¢åŠ [BiLLa](#ChatLLM),å¼€æºä¸­è‹±æ–‡åŒè¯­å¤§æ¨¡å‹ã€‚\n* 2023.05.12 å¢åŠ [Bactrian-X](#ChatLLM),å¼€æºå¤šè¯­è¨€å¤§æ¨¡å‹ã€‚\n* 2023.05.08 å¢åŠ [OpenBuddy](#ChatLLM),ä¸€æ¬¾å¼ºå¤§çš„å¼€æºå¤šè¯­è¨€èŠå¤©æœºå™¨äººæ¨¡å‹ã€‚\n* 2023.04.26 æ›´æ–°[LLaMA-zhã€YuYan](#LLM),å¢åŠ LLama-zhã€Yuyanã€æ‰é¹Šç­‰LLMå’ŒchatLLmæ¨¡å‹\n* 2023.04.25 å¢åŠ [BBT](#LLM)ï¼ŒåŸºäºTransformerå’ŒDecoder-Onlyçš„æ¶æ„å¼€å‘äº†BigBang Transformerã€Œä¹¾å…ƒã€å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚\n* 2023.04.21 å¢åŠ [MOSS](#ChatLLM),æ›´æ–°å¤æ—¦å¤§å­¦å¼€æºçš„MOSSæ¨¡å‹ä»¥åŠå¯¹åº”çš„æ•°æ®é›†ã€‚\n* 2023.04.20 å¢åŠ [Phoenix](#ChatLLM),åŸºäºBLOOMZ-mtæ¨¡å‹å¾®è°ƒå¾—åˆ°çš„å¤§è¯­è¨€æ¨¡å‹ã€‚\n* 2023.04.19 å¢åŠ [ChatPLUG](#ChatLLM)ï¼Œè¯¥æ¨¡å‹åŸºäºPLUGï¼Œä½¿ç”¨äº¿çº§äº’è”ç½‘ç¤¾äº¤æ•°æ®ã€ç™¾ç§‘æ•°æ®é¢„è®­ç»ƒå’Œç™¾ä¸‡çº§é«˜è´¨é‡å¯¹è¯æ•°æ®è¿›è¡Œinstructionå¾®è°ƒå¾—åˆ°ã€‚\n* 2023.04.18 å¢åŠ [COIG](#ä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†)æ•°æ®é›†ï¼Œç”¨ä¸åŒæ–¹æ³•æ„å»ºä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†çš„é¡¹ç›®ï¼Œæ”¶é›†äº†å¤§çº¦20ä¸‡ä¸ªä¸­æ–‡æŒ‡ä»¤æ ·æœ¬ã€‚\n* 2023.04.13 æ›´æ–°[ChatLLM](#ChatLLM)ï¼Œå¢åŠ HuaTuo,Med_ChatGLMä¸¤ä¸ªåŒ»å­¦æ¨¡å‹ã€‚\n* 2023.04.09 æ›´æ–°[ä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†](#ä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†)[ChatLLM](#ChatLLM)ï¼Œå¢åŠ ä¸ªæ€§è§’è‰²å¯¹è¯æ•°æ®é›†ã€chinese-alpaca-13bæ¨¡å‹ã€‚\n* 2023.04.03 æ›´æ–°[ä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†](#ä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†)[ChatLLM](#ChatLLM)ï¼Œå¢åŠ BELLE-13bæ¨¡å‹ï¼Œmath-0.25ï¼Œmultiturn-0.8æ•°æ®é›†ã€‚\n* 2023.04.02 æ›´æ–°[ChatLLM](#ChatLLM)åˆ—è¡¨ï¼Œå¢åŠ ç”±é¦™æ¸¯ç§‘æŠ€å¤§å­¦å¼€æºçš„7B/13B/33B/65Bä¸­æ–‡å¤§å‹è¯­è¨€æ¨¡å‹\n* 2023.03.30 å¢åŠ Chinese-Vicunaæ¨¡å‹ï¼ŒTraditional-Chinese-alpacaæ•°æ®é›†\n* 2023.03.29 å¢åŠ [OFA](#OFA),ä¸­æ–‡å¤šæ¨¡æ€ç»Ÿä¸€é¢„è®­ç»ƒæ¨¡å‹,OFAæ˜¯é˜¿é‡Œå·´å·´å‘å¸ƒçš„å¤šæ¨¡æ€ç»Ÿä¸€é¢„è®­ç»ƒæ¨¡å‹.\n* 2023.03.29 æ›´æ–°[ä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†](#ä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†)ï¼Œå¢åŠ InstructionWildæ•°æ®é›†ã€‚\n* 2023.03.23 å¢åŠ [ä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†](#ä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†)ï¼Œå¹¶åˆå§‹åŒ–ä¸‰ä¸ªå·²å…¬å¼€æ•°æ®é›†ã€‚\n* 2023.03.20 å¢åŠ [BELLE](#ChatLLM),å¼€æºä¸­æ–‡å¯¹è¯å¤§æ¨¡å‹-70äº¿å‚æ•°,åŸºäºStanford Alpacaï¼Œå¯¹ä¸­æ–‡åšäº†ä¼˜åŒ–ï¼Œæ¨¡å‹è°ƒä¼˜ä»…ä½¿ç”¨ç”±ChatGPTç”Ÿäº§çš„æ•°æ®.\n* 2023.03.14 å¢åŠ [ChatLLM](#ChatLLM)åˆ—è¡¨ï¼Œä¸»è¦æ”¶é›†å…·å¤‡é—®ç­”è·Ÿå¯¹è¯ç­‰åŠŸèƒ½çš„å¤§å‹è¯­è¨€æ¨¡å‹,å¹¶å¢åŠ ChatGLMæ¨¡å‹ã€‚\n* 2023.03.11 å¢åŠ [ProphetNet](#ProphetNet),æå‡ºäº†ä¸€ç§æ–°çš„è‡ªç›‘ç£å­¦ä¹ ç›®æ ‡â€”â€”åŒæ—¶é¢„æµ‹å¤šä¸ªæœªæ¥å­—ç¬¦ï¼Œåœ¨åºåˆ—åˆ°åºåˆ—çš„å¤šä¸ªè‡ªç„¶è¯­è¨€ç”Ÿæˆä»»åŠ¡éƒ½å–å¾—äº†ä¼˜å¼‚æ€§èƒ½ã€‚\n* 2023.03.10 å¢åŠ [RoCBert](#RoCBert),åˆ©ç”¨å¯¹æŠ—å­¦ä¹ ç”Ÿæˆæ›´å¤šå™ªå£°æ•°æ®ï¼Œç”¨æ¥è¿›è¡Œä¸­æ–‡BERTæ¨¡å‹çš„è®­ç»ƒï¼Œå¾—åˆ°é²æ£’æ€§æ›´å¼ºçš„ä¸­æ–‡BERTæ¨¡å‹ã€‚\n* 2023.03.03 æ›´æ–°[LLM](#LLM),æ–°å¢å¤šè¯­è¨€æ¨¡å‹`Flan-ul2`å’Œ`Flan-t5-xxl`\n* 2023.02.21 å¢åŠ [LLM](#LLM),å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹åˆ—è¡¨ï¼Œåªç½—åˆ—å‡ºå‚æ•°é‡å¤§äº10Bä»¥ä¸Šæ¨¡å‹ï¼Œå…¶ä½™é‡çº§æ¨¡å‹ï¼Œå¯å‚è€ƒå¯¹åº”çš„é¡¹ç›®åœ°å€ã€‚\n* 2023.01.14 å¢åŠ [SkyText](#SkyText),SkyTextæ˜¯ç”±å¥‡ç‚¹æ™ºæºå‘å¸ƒçš„ä¸­æ–‡GPT3é¢„è®­ç»ƒå¤§æ¨¡å‹ï¼Œå¯ä»¥è¿›è¡ŒèŠå¤©ã€é—®ç­”ã€ä¸­è‹±äº’è¯‘ç­‰ä¸åŒçš„ä»»åŠ¡.\n* 2023.01.14 å¢åŠ [ChatYuan](#ChatYuan),ChatYuanæ¨¡å‹å¯ä»¥ç”¨äºé—®ç­”ã€ç»“åˆä¸Šä¸‹æ–‡åšå¯¹è¯ã€åšå„ç§ç”Ÿæˆä»»åŠ¡ï¼ŒåŒ…æ‹¬åˆ›æ„æ€§å†™ä½œï¼Œä¹Ÿèƒ½å›ç­”ä¸€äº›åƒæ³•å¾‹ã€æ–°å† ç­‰é¢†åŸŸé—®é¢˜ã€‚\n* 2022.12.10 å¢åŠ [PromptCLUE](#PromptCLUE),å…¨ä¸­æ–‡ä»»åŠ¡é›¶æ ·æœ¬å­¦ä¹ æ¨¡å‹,åŸºäº1000äº¿tokenä¸­æ–‡è¯­æ–™ä¸Šé¢„è®­ç»ƒï¼Œå¹¶ä¸”åœ¨æ•°ç™¾ç§ä»»åŠ¡ä¸Šè¿›è¡ŒPromptä»»åŠ¡å¼è®­ç»ƒã€‚\n* 2022.12.01 å¢åŠ [wukong](#wukong),åŸºäºä¸€ä¸ªåä¸ºã€Œæ‚Ÿç©ºã€çš„å¤§å‹ä¸­æ–‡è·¨æ¨¡æ€æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«æ¥è‡ªç½‘ç»œçš„ 1 äº¿ä¸ªå›¾æ–‡å¯¹ï¼Œé¢„è®­ç»ƒçš„å¤šæ¨¡æ€æ¨¡å‹ã€‚\n* 2022.11.30 å¢åŠ [AltDiffusion](#AltDiffusion)ï¼Œä½¿ç”¨ AltCLIP ä½œä¸ºtext encoderï¼ŒåŸºäº Stable Diffusion è®­ç»ƒäº†ä¸­è‹±åŒè¯­Diffusionæ¨¡å‹(AltDiffusion)\n* 2022.11.30 å¢åŠ [AltCLIP](#AltCLIP),ä¸€ä¸ªç®€å•é«˜æ•ˆçš„æ–¹æ³•å»è®­ç»ƒæ›´åŠ ä¼˜ç§€çš„åŒè¯­CLIPæ¨¡å‹,åä¸ºAltCLIPã€‚AltCLIPåŸºäº OpenAI CLIP è®­ç»ƒã€‚\n* 2022.11.30 å¢åŠ [Taiyi-Stable-Diffusion](#Taiyi-Stable-Diffusion),é¦–ä¸ªå¼€æºçš„ä¸­è‹±åŒè¯­Stable Diffusionæ¨¡å‹ï¼ŒåŸºäº0.2äº¿ç­›é€‰è¿‡çš„ä¸­æ–‡å›¾æ–‡å¯¹è®­ç»ƒã€‚\n* 2022.11.9 å¢åŠ [OPD](#OPD),OPDæ˜¯ä¸€ä¸ªä¸­æ–‡å¼€æ”¾åŸŸå¯¹è¯é¢„è®­ç»ƒæ¨¡å‹ï¼Œæ‹¥æœ‰63äº¿å‚æ•°ï¼Œåœ¨70GBé«˜è´¨é‡å¯¹è¯æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒè€Œæˆ.`å¤§è§„æ¨¡` & `é«˜æ€§èƒ½`\n* 2022.11.8 æ›´æ–°[Chinese-CLIP](#Chinese-CLIP),Chinese-CLIPæ˜¯ä¸­æ–‡å¤šæ¨¡æ€å›¾æ–‡è¡¨å¾æ¨¡å‹ï¼Œæ›´æ–°åChinese-CLIPæ‰©å……åˆ°5ä¸ªæ¨¡å‹è§„æ¨¡ï¼ŒåŒæ—¶å¢åŠ äº†æŠ€æœ¯æŠ¥å‘Šè®ºæ–‡ä»¥åŠæ£€ç´¢demoï¼ŒåŒæ—¶åœ¨è¾¾æ‘©é™¢ModelScopeå¹³å°åŒæ­¥é›†æˆã€‚\n* 2022.10.31 å¢åŠ [LERT](#LERT),ä¸ºäº†éªŒè¯é€šè¿‡æ˜¾å¼æ³¨å…¥è¯­è¨€å­¦çŸ¥è¯†é¢„è®­ç»ƒæ¨¡å‹èƒ½å¦è·å¾—è¿›ä¸€æ­¥æ€§èƒ½æå‡ï¼ŒHFLæå‡ºäº†ä¸€ç§**è¯­è¨€å­¦ä¿¡æ¯å¢å¼ºçš„é¢„è®­ç»ƒæ¨¡å‹LERT**ï¼Œèåˆäº†å¤šç§è¯­è¨€å­¦çŸ¥è¯†ã€‚å¤§é‡å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨åŒç­‰è®­ç»ƒæ•°æ®è§„æ¨¡ä¸‹ï¼ŒLERTèƒ½å¤Ÿå¸¦æ¥æ˜¾è‘—æ€§èƒ½æå‡ã€‚\n* 2022.10.14 å¢åŠ [CKBERT](#CKBERT)ï¼Œä¸­æ–‡çŸ¥è¯†åº“å¢å¼ºBERTé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚\n* 2022.10.01 å¢åŠ [GlyphBERT](#GlyphBERT), GlyphBERTæ˜¯ä¸€ä¸ªåŒ…å«äº†æ±‰å­—å­—å½¢ç‰¹å¾ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹ã€‚å®ƒé€šè¿‡å°†è¾“å…¥çš„å­—ç¬¦æ¸²æŸ“æˆå›¾åƒå¹¶è®¾è®¡æˆå¤šé€šé“ä½ç½®ç‰¹å¾å›¾çš„å½¢å¼ï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªä¸¤å±‚ æ®‹å·®å·ç§¯ç¥ç»ç½‘ç»œæ¨¡å—æ¥æå–å­—ç¬¦çš„å›¾åƒç‰¹å¾è¿›è¡Œè®­ç»ƒã€‚\n* 2022.09.30 å¢åŠ [DeBERTa](#DeBERTa)ï¼Œä¸€ä¸ªä¸­æ–‡ç‰ˆçš„DeBERTa-v2ï¼Œæˆ‘ä»¬ç”¨æ‚Ÿé“è¯­æ–™åº“(180Gç‰ˆæœ¬)è¿›è¡Œé¢„è®­ç»ƒï¼Œåœ¨é¢„è®­ç»ƒé˜¶æ®µä¸­ä½¿ç”¨äº†å°ç¥æ¡†æ¶ã€‚\n* 2022.09.30 å¢åŠ [TaiYi-CLIP](#TaiYi-CLIP),é¦–ä¸ªå¼€æºçš„ä¸­æ–‡CLIPæ¨¡å‹ï¼Œ1.23äº¿å›¾æ–‡å¯¹ä¸Šè¿›è¡Œé¢„è®­ç»ƒçš„æ–‡æœ¬ç«¯RoBERTa-largeã€‚\n* 2022.09.27 å¢åŠ [PLUG](#PLUG),PLUGé›†è¯­è¨€ç†è§£ä¸ç”Ÿæˆèƒ½åŠ›äºä¸€èº«ï¼Œæ”¯æŒæ–‡æœ¬ç”Ÿæˆã€é—®ç­”ã€è¯­ä¹‰ç†è§£ç­‰å¤šç±»ä¸‹æ¸¸ä»»åŠ¡ï¼ŒPLUGå¼€æºå°†åŠ©åŠ›å¼€å‘è€…åœ¨è¯­è¨€ç†è§£å’Œè¯­è¨€ç”Ÿæˆä¸Šåšå‡ºæ›´å¤šå»¶æ‹“ã€‚\n* 2022.09.11 å¢åŠ [bloom-6b4](#Bloom),å¤šè¯­è¨€é¢„è®­ç»ƒbloomç³»åˆ—ç”Ÿæˆæ¨¡å‹7b1å‚æ•°(https://huggingface.co/bigscience/bloom-7b1 )çš„ä¸­æ–‡vocabæå–ï¼Œbloomç³»åˆ—å¦æœ‰æœ€å¤§176Bæ¨¡å‹(https://huggingface.co/bigscience/bloom).\n* 2022.09.11 å¢åŠ [GLM-130B](#GLM),æå‡ºäº†å¼€æºçš„åŒè¯­é¢„è®­ç»ƒç”Ÿæˆæ¨¡å‹ GLM(General Language Model)ã€‚\n* 2022.09.11 å¢åŠ [PanGu-Î±: Large-scale Autoregressive Pretrained Chinese Language Models with Auto-parallel Computation](#PanGu-Alpha) 2.6Bå’Œ13B ç”Ÿæˆæ¨¡å‹pytorchç‰ˆ\n* 2022.06.29 å¢åŠ [ERNIE 3.0](#ERNIE3),å¤§è§„æ¨¡çŸ¥è¯†å¢å¼ºé¢„è®­ç»ƒè¯­è¨€ç†è§£å’Œç”Ÿæˆ.\n* 2022.06.22 å¢åŠ [Zero and R2D2: A Large-scale Chinese Cross-modal Benchmark and A Vision-Language Framework](#R2D2)ï¼ŒåŸºäºå¤§è§„æ¨¡ä¸­æ–‡è·¨æ¨¡æ€åŸºå‡†æ•°æ®é›†Zeroï¼Œè®­ç»ƒè§†è§‰è¯­è¨€é¢„è®­ç»ƒæ¡†æ¶ R2D2ï¼Œç”¨äºå¤§è§„æ¨¡è·¨æ¨¡æ€å­¦ä¹ ã€‚\n* 2022.06.15 å¢åŠ [GLM: General Language Model Pretraining with Autoregressive Blank Infilling](#GLM),æå‡ºäº†ä¸€ç§æ–°çš„é€šç”¨è¯­è¨€æ¨¡å‹ GLM(General Language Model)ã€‚ ä½¿ç”¨è‡ªå›å½’å¡«ç©ºç›®æ ‡è¿›è¡Œé¢„è®­ç»ƒï¼Œå¯ä»¥é’ˆå¯¹å„ç§è‡ªç„¶è¯­è¨€ç†è§£å’Œç”Ÿæˆä»»åŠ¡è¿›è¡Œå¾®è°ƒã€‚\n* 2022.05.16 å¢åŠ [GAU-Î±](#GAU-Î±),ä¸»è¦æå‡ºäº†ä¸€ä¸ªèåˆäº†Attentionå±‚å’ŒFFNå±‚çš„æ–°è®¾è®¡GAUï¼ˆGated Attention Unitï¼Œé—¨æ§æ³¨æ„åŠ›å•å…ƒï¼‰ï¼Œå®ƒæ˜¯æ–°æ¨¡å‹æ›´å¿«ã€æ›´çœã€æ›´å¥½çš„å…³é”®ï¼Œæ­¤å¤–å®ƒä½¿å¾—æ•´ä¸ªæ¨¡å‹åªæœ‰ä¸€ç§å±‚ï¼Œä¹Ÿæ˜¾å¾—æ›´ä¸ºä¼˜é›…ã€‚\n* 2022.03.27 å¢åŠ [RoFormer-V2](#RoFormer),RoFormerå‡çº§ç‰ˆï¼Œä¸»è¦é€šè¿‡ç»“æ„çš„ç®€åŒ–æ¥æå‡é€Ÿåº¦ï¼Œå¹¶é€šè¿‡æ— ç›‘ç£é¢„è®­ç»ƒå’Œæœ‰ç›‘ç£é¢„è®­ç»ƒçš„ç»“åˆæ¥æå‡æ•ˆæœï¼Œä»è€Œè¾¾åˆ°äº†é€Ÿåº¦ä¸æ•ˆæœçš„â€œåŒèµ¢â€ã€‚\n* 2022.03.02 å¢åŠ [MobileBERT](#MobileBERT),MobileBERTæ˜¯BERT-largeæ¨¡å‹æ›´â€œè‹—æ¡â€çš„ç‰ˆæœ¬ï¼Œä½¿ç”¨äº†ç“¶é¢ˆç»“æ„ï¼ˆbottleneckï¼‰å¹¶ä¸”å¯¹è‡ªæ³¨æ„åŠ›å’Œå‰é¦ˆç¥ç»ç½‘ç»œä¹‹é—´çš„å¹³è¡¡åšäº†ç»†è‡´çš„è®¾è®¡ã€‚\n* 2022.02.24 å¢åŠ [PERT: Pre-Training BERT with Permuted Language Model](#PERT),ä¸€ç§åŸºäºä¹±åºè¯­è¨€æ¨¡å‹çš„é¢„è®­ç»ƒæ¨¡å‹ï¼ˆPERTï¼‰ï¼Œåœ¨ä¸å¼•å…¥æ©ç æ ‡è®°[MASK]çš„æƒ…å†µä¸‹è‡ªç›‘ç£åœ°å­¦ä¹ æ–‡æœ¬è¯­ä¹‰ä¿¡æ¯ã€‚\n* 2021.12.06 å¢åŠ [SDCUP: Improving Text-to-SQL with Schema Dependency Learning](#SDCUP),è¾¾æ‘©é™¢æ·±åº¦è¯­è¨€æ¨¡å‹ä½“ç³» AliceMind å‘å¸ƒä¸­æ–‡ç¤¾åŒºé¦–ä¸ªè¡¨æ ¼é¢„è®­ç»ƒæ¨¡å‹ SDCUPã€‚\n* 2021.11.27 å¢åŠ [RWKV](#RWKV)ä¸­æ–‡é¢„è®­ç»ƒç”Ÿæˆæ¨¡å‹,ç±»ä¼¼ GPT-2,æ¨¡å‹å‚è€ƒåœ°å€ï¼š[RWKV-LM](https://github.com/BlinkDL/RWKV-LM)\n* 2021.11.27 å¢åŠ IDEAç ”ç©¶é™¢å¼€æºçš„å°ç¥æ¦œç³»åˆ—è¯­è¨€æ¨¡å‹ï¼ŒåŒ…å«[äºŒéƒç¥](#äºŒéƒç¥)ã€[å‘¨æ–‡ç‹](#å‘¨æ–‡ç‹)ã€[é—»ä»²](#é—»ä»²)ã€[ä½™å…ƒ](#ä½™å…ƒ)ã€‚\n* 2021.11.25 å¢åŠ [MC-BERT: Conceptualized Representation Learning for Chinese Biomedical Text Mining](#MC-BERT), ç”Ÿç‰©åŒ»å­¦é¢†åŸŸçš„ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹.\n* 2021.11.24 å¢åŠ [TaCL: Improving BERT Pre-training with Token-aware Contrastive Learning](#TaCL), Token-awareå¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒæ¨¡å‹.\n* 2021.10.18 å¢åŠ [Mengzi: Towards Lightweight yet Ingenious Pre-trained Models for Chinese](#Mengzi-BERT),åŸºäºè¯­è¨€å­¦ä¿¡æ¯èå…¥å’Œè®­ç»ƒåŠ é€Ÿç­‰æ–¹æ³•ç ”å‘äº† Mengzi ç³»åˆ—æ¨¡å‹.\n* 2021.10.14 å¢åŠ [ä¸­æ–‡ç‰ˆBART](#BART),è®­ç»ƒæ¯”è¾ƒå¯é çš„ä¸­æ–‡ç‰ˆBARTï¼Œä¸ºä¸­æ–‡ç”Ÿæˆç±»ä»»åŠ¡å¦‚æ‘˜è¦ç­‰æä¾›Baseline.\n* 2021.10.14 å¢åŠ [CPT: A Pre-Trained Unbalanced Transformer for Both Chinese Language Understanding and Generation](#CPT),CPTï¼šå…¼é¡¾ç†è§£å’Œç”Ÿæˆçš„ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹.\n* 2021.10.13 å¢åŠ [ç´«ä¸œå¤ªåˆå¤šæ¨¡æ€å¤§æ¨¡å‹](#ç´«ä¸œå¤ªåˆ): å…¨çƒé¦–ä¸ªå¤šæ¨¡æ€å›¾æ–‡éŸ³é¢„è®­ç»ƒæ¨¡å‹,å®ç°äº†è§†è§‰-æ–‡æœ¬-è¯­éŸ³ä¸‰æ¨¡æ€ç»Ÿä¸€è¡¨ç¤ºï¼Œæ„å»ºäº†ä¸‰æ¨¡æ€é¢„è®­ç»ƒå¤§æ¨¡å‹ã€‚\n* 2021.09.19 å¢åŠ [CogView: Mastering Text-to-Image Generation via Transformers](#CogView),ä¸–ç•Œæœ€å¤§çš„ä¸­æ–‡å¤šæ¨¡æ€ç”Ÿæˆæ¨¡å‹,æ¨¡å‹æ”¯æŒæ–‡ç”Ÿæˆå›¾ä¸ºåŸºç¡€çš„å¤šé¢†åŸŸä¸‹æ¸¸ä»»åŠ¡.\n* 2021.09.10 å¢åŠ [WenLan: Bridging Vision and Language by Large-Scale Multi-Modal Pre-Training](#WenLan)ï¼Œé¦–ä¸ªä¸­æ–‡é€šç”¨å›¾æ–‡å¤šæ¨¡æ€å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ã€‚\n* 2021.09.10 å¢åŠ [EVA: An Open-Domain Chinese Dialogue System with Large-Scale Generative Pre-Training](#EVA)ï¼Œä¸€ä¸ªå¼€æ”¾é¢†åŸŸçš„ä¸­æ–‡å¯¹è¯é¢„è®­ç»ƒæ¨¡å‹ã€‚\n* 2021.08.19 å¢åŠ [Chinese-Transformer-XL](#GPT-3)ï¼šåŸºäºä¸­æ–‡é¢„è®­ç»ƒè¯­æ–™WuDaoCorpusï¼ˆ290Gï¼‰è®­ç»ƒçš„GPT-3æ¨¡å‹ã€‚\n* 2021.08.16 å¢åŠ [CPM-2: Large-scale Cost-effective Pre-trained Language Models](#CPM-2)\n* 2021.08.16 å¢åŠ [Lattice-BERT: Leveraging Multi-Granularity Representations in Chinese Pre-trained Language Models](#Lattice-BERT)\n* 2021.07.19 å¢åŠ [roformer-sim-v2](#RoFormer-sim)ï¼šåˆ©ç”¨æ ‡æ³¨æ•°æ®å¢å¼ºç‰ˆæœ¬\n* 2021.07.15 å¢åŠ [BERT-CCPoem](#BERT)ï¼šå¤å…¸è¯—æ­Œè¯­æ–™è®­ç»ƒçš„BERT\n* 2021.07.06 å¢åŠ [ChineseBERTï¼šChinese Pretraining Enhanced by Glyph and Pinyin Information](#BERT)\n* 2021.06.22 å¢åŠ [StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding](#StructBERT)\n* 2021.06.14 å¢åŠ [RoFormerï¼šEnhanced Transformer with Rotary Position Embedding](#RoFormer)\n* 2021.05.25 å¢åŠ [ERNIE-Gram: Pre-Training with Explicitly N-Gram Masked Language Modeling for Natural Language Understanding ]((#ERNIE))\n* 2021.04.28 å¢åŠ [PanGu-Î±: Large-scale Autoregressive Pretrained Chinese Language Models with Auto-parallel Computation ](#PanGu-Alpha)\n* 2021.03.16 å¢åŠ [T5-PEGASUS: å¼€æºä¸€ä¸ªä¸­æ–‡ç”Ÿæˆå¼é¢„è®­ç»ƒæ¨¡å‹](#T5-PEGASUS)\n* 2021.03.09 å¢åŠ UERç³»åˆ—æ¨¡å‹\n* 2021.03.04 å¢åŠ [WoBERT: åŸºäºè¯é¢—ç²’åº¦çš„ä¸­æ–‡](#WoBERT)\n* 2020.11.11 åˆå§‹åŒ–BERTç³»åˆ—æ¨¡å‹[BERT](#BERT)\n\n<p align=\"right\">[<a href=\"#top\">Back to Top</a>]</p>\n\n### Contributors\n\n<a href=\"https://github.com/eryajf/learn-github/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=lonePatient/awesome-pretrained-chinese-nlp-models\" />\n</a>\n\n### Misc\n#### &#8627; Stargazers\n[![Stargazers repo roster for ](https://reporoster.com/stars/lonePatient/awesome-pretrained-chinese-nlp-models)](https://github.com/lonePatient/awesome-pretrained-chinese-nlp-models/stargazers)\n\n#### &#8627; Forkers\n[![Forkers repo roster for](https://reporoster.com/forks/lonePatient/awesome-pretrained-chinese-nlp-models)](https://github.com/lonePatient/awesome-pretrained-chinese-nlp-models/network/members)\n\n#### &#8627; Star History\n\n<div align=\"center\">\n[![Star History Chart](https://api.star-history.com/svg?repos=lonePatient/awesome-pretrained-chinese-nlp-models&type=Date)](https://star-history.com/#lonePatient/awesome-pretrained-chinese-nlp-models&Date)\n\n</div>\n\n![Visitor Count](https://profile-counter.glitch.me/lonepatient/count.svg)\n"
        },
        {
          "name": "resources",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}