{
  "metadata": {
    "timestamp": 1736560535015,
    "page": 138,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "facebookresearch/demucs",
      "stars": 8552,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.15234375,
          "content": "*.egg-info\n__pycache__\nSession.vim\n/build\n/dist\n/lab\n/metadata\n/notebooks\n/outputs\n/release\n/release_models\n/separated\n/tests\n/trash\n/misc\n/mdx\n.mypy_cache\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.2763671875,
          "content": "# Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to make participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, sex characteristics, gender identity and expression,\nlevel of experience, education, socio-economic status, nationality, personal\nappearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\n  advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\n  address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies within all project spaces, and it also applies when\nan individual is representing the project or its community in public spaces.\nExamples of representing a project or community include using an official\nproject e-mail address, posting via an official social media account, or acting\nas an appointed representative at an online or offline event. Representation of\na project may be further defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the project team at <opensource-conduct@fb.com>. All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see\nhttps://www.contributor-covenant.org/faq\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 0.728515625,
          "content": "# Contributing to Demucs\n\n## Pull Requests\n\nIn order to accept your pull request, we need you to submit a CLA. You only need\nto do this once to work on any of Facebook's open source projects.\n\nComplete your CLA here: <https://code.facebook.com/cla>\n\nDemucs is the implementation of a research paper.\nTherefore, we do not plan on accepting many pull requests for new features.\nWe certainly welcome them for bug fixes.\n\n\n## Issues\n\nWe use GitHub issues to track public bugs. Please ensure your description is\nclear and has sufficient instructions to be able to reproduce the issue.\n\n\n## License\nBy contributing to this repository, you agree that your contributions will be licensed\nunder the LICENSE file in the root directory of this source tree.\n"
        },
        {
          "name": "Demucs.ipynb",
          "type": "blob",
          "size": 4.0380859375,
          "content": "{\n \"cells\": [\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {\n    \"colab_type\": \"text\",\n    \"id\": \"Be9yoh-ILfRr\"\n   },\n   \"source\": [\n    \"# Hybrid Demucs\\n\",\n    \"\\n\",\n    \"Feel free to use the Colab version:\\n\",\n    \"https://colab.research.google.com/drive/1dC9nVxk3V_VPjUADsnFu8EiT-xnU1tGH?usp=sharing\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"colab\": {\n     \"base_uri\": \"https://localhost:8080/\",\n     \"height\": 139\n    },\n    \"colab_type\": \"code\",\n    \"executionInfo\": {\n     \"elapsed\": 12277,\n     \"status\": \"ok\",\n     \"timestamp\": 1583778134659,\n     \"user\": {\n      \"displayName\": \"Marllus Lustosa\",\n      \"photoUrl\": \"https://lh3.googleusercontent.com/a-/AOh14GgLl2RbW64ZyWz3Y8IBku0zhHCMnt7fz7fEl0LTdA=s64\",\n      \"userId\": \"14811735256675200480\"\n     },\n     \"user_tz\": 180\n    },\n    \"id\": \"kOjIPLlzhPfn\",\n    \"outputId\": \"c75f17ec-b576-4105-bc5b-c2ac9c1018a3\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"!pip install -U demucs\\n\",\n    \"# or for local development, if you have a clone of Demucs\\n\",\n    \"# pip install -e .\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"colab\": {},\n    \"colab_type\": \"code\",\n    \"id\": \"5lYOzKKCKAbJ\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"# You can use the `demucs` command line to separate tracks\\n\",\n    \"!demucs test.mp3\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# You can also load directly the pretrained models,\\n\",\n    \"# for instance for the MDX 2021 winning model of Track A:\\n\",\n    \"from demucs import pretrained\\n\",\n    \"model = pretrained.get_model('mdx')\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Because `model` is a bag of 4 models, you cannot directly call it on your data,\\n\",\n    \"# but the `apply_model` will know what to do of it.\\n\",\n    \"import torch\\n\",\n    \"from demucs.apply import apply_model\\n\",\n    \"x = torch.randn(1, 2, 44100 * 10)  # ten seconds of white noise for the demo\\n\",\n    \"out = apply_model(model, x)[0]     # shape is [S, C, T] with S the number of sources\\n\",\n    \"\\n\",\n    \"# So let see, where is all the white noise content is going ?\\n\",\n    \"for name, source in zip(model.sources, out):\\n\",\n    \"    print(name, source.std() / x.std())\\n\",\n    \"# The outputs are quite weird to be fair, not what I would have expected.\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# now let's take a single model from the bag, and let's test it on a pure cosine\\n\",\n    \"freq = 440  # in Hz\\n\",\n    \"sr = model.samplerate\\n\",\n    \"t = torch.arange(10 * sr).float() / sr\\n\",\n    \"x = torch.cos(2 * 3.1416 * freq * t).expand(1, 2, -1)\\n\",\n    \"sub_model = model.models[3]\\n\",\n    \"out = sub_model(x)[0]\\n\",\n    \"\\n\",\n    \"# Same question where does it go?\\n\",\n    \"for name, source in zip(model.sources, out):\\n\",\n    \"    print(name, source.std() / x.std())\\n\",\n    \"    \\n\",\n    \"# Well now it makes much more sense, all the energy is going\\n\",\n    \"# in the `other` source.\\n\",\n    \"# Feel free to try lower pitch (try 80 Hz) to see what happens !\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# For training or more fun, refer to the Demucs README on our repo\\n\",\n    \"# https://github.com/facebookresearch/demucs/tree/main/demucs\"\n   ]\n  }\n ],\n \"metadata\": {\n  \"accelerator\": \"GPU\",\n  \"colab\": {\n   \"authorship_tag\": \"ABX9TyM9xpVr1M86NRcjtQ7g9tCx\",\n   \"collapsed_sections\": [],\n   \"name\": \"Demucs.ipynb\",\n   \"provenance\": []\n  },\n  \"kernelspec\": {\n   \"display_name\": \"Python 3\",\n   \"language\": \"python\",\n   \"name\": \"python3\"\n  },\n  \"language_info\": {\n   \"codemirror_mode\": {\n    \"name\": \"ipython\",\n    \"version\": 3\n   },\n   \"file_extension\": \".py\",\n   \"mimetype\": \"text/x-python\",\n   \"name\": \"python\",\n   \"nbconvert_exporter\": \"python\",\n   \"pygments_lexer\": \"ipython3\",\n   \"version\": \"3.8.8\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 1\n}\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0615234375,
          "content": "MIT License\n\nCopyright (c) Meta Platforms, Inc. and affiliates.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE."
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.294921875,
          "content": "recursive-exclude env *\nrecursive-include conf *.yaml\ninclude Makefile\ninclude LICENSE\ninclude demucs.png\ninclude outputs.tar.gz\ninclude test.mp3\ninclude requirements.txt\ninclude requirements_minimal.txt\ninclude mypy.ini\ninclude demucs/py.typed\ninclude demucs/remote/*.txt\ninclude demucs/remote/*.yaml\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 1.046875,
          "content": "all: linter tests\n\nlinter:\n\tflake8 demucs\n\tmypy demucs\n\ntests: test_train test_eval\n\ntest_train: tests/musdb\n\t_DORA_TEST_PATH=/tmp/demucs python3 -m dora run --clear \\\n\t\tdset.musdb=./tests/musdb dset.segment=4 dset.shift=2 epochs=2 model=demucs \\\n\t\tdemucs.depth=2 demucs.channels=4 test.sdr=false misc.num_workers=0 test.workers=0 \\\n\t\ttest.shifts=0\n\ntest_eval:\n\tpython3 -m demucs -n demucs_unittest test.mp3\n\tpython3 -m demucs -n demucs_unittest --two-stems=vocals test.mp3\n\tpython3 -m demucs -n demucs_unittest --mp3 test.mp3\n\tpython3 -m demucs -n demucs_unittest --flac --int24 test.mp3\n\tpython3 -m demucs -n demucs_unittest --int24 --clip-mode clamp test.mp3\n\tpython3 -m demucs -n demucs_unittest --segment 8 test.mp3\n\tpython3 -m demucs.api -n demucs_unittest --segment 8 test.mp3\n\tpython3 -m demucs --list-models\n\ntests/musdb:\n\ttest -e tests || mkdir tests\n\tpython3 -c 'import musdb; musdb.DB(\"tests/tmp\", download=True)'\n\tmusdbconvert tests/tmp tests/musdb\n\ndist:\n\tpython3 setup.py sdist\n\nclean:\n\trm -r dist build *.egg-info\n\n.PHONY: linter dist test_train test_eval\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 18.029296875,
          "content": "# Demucs Music Source Separation\n\n[![Support Ukraine](https://img.shields.io/badge/Support-Ukraine-FFD500?style=flat&labelColor=005BBB)](https://opensource.fb.com/support-ukraine)\n![tests badge](https://github.com/facebookresearch/demucs/workflows/tests/badge.svg)\n![linter badge](https://github.com/facebookresearch/demucs/workflows/linter/badge.svg)\n\n\n**Important:** As I am no longer working at Meta, **this repository is not maintained anymore**.\nI've created a fork at [github.com/adefossez/demucs](https://github.com/adefossez/demucs). Note that this project is not actively maintained anymore\nand only important bug fixes will be processed on the new repo. Please do not open issues for feature request or if Demucs doesn't work perfectly for your use case :)\n\nThis is the 4th release of Demucs (v4), featuring Hybrid Transformer based source separation.\n**For the classic Hybrid Demucs (v3):** [Go this commit][demucs_v3].\nIf you are experiencing issues and want the old Demucs back, please file an issue, and then you can get back to Demucs v3 with\n`git checkout v3`. You can also go [Demucs v2][demucs_v2].\n\n\nDemucs is a state-of-the-art music source separation model, currently capable of separating\ndrums, bass, and vocals from the rest of the accompaniment.\nDemucs is based on a U-Net convolutional architecture inspired by [Wave-U-Net][waveunet].\nThe v4 version features [Hybrid Transformer Demucs][htdemucs], a hybrid spectrogram/waveform separation model using Transformers.\nIt is based on [Hybrid Demucs][hybrid_paper] (also provided in this repo), with the innermost layers\nreplaced by a cross-domain Transformer Encoder. This Transformer uses self-attention within each domain,\nand cross-attention across domains.\nThe model achieves a SDR of 9.00 dB on the MUSDB HQ test set. Moreover, when using sparse attention\nkernels to extend its receptive field and per source fine-tuning, we achieve state-of-the-art 9.20 dB of SDR.\n\nSamples are available [on our sample page](https://ai.honu.io/papers/htdemucs/index.html).\nCheckout [our paper][htdemucs] for more information.\nIt has been trained on the [MUSDB HQ][musdb] dataset + an extra training dataset of 800 songs.\nThis model separates drums, bass and vocals and other stems for any song.\n\n\nAs Hybrid Transformer Demucs is brand new, it is not activated by default, you can activate it in the usual\ncommands described hereafter with `-n htdemucs_ft`.\nThe single, non fine-tuned model is provided as `-n htdemucs`, and the retrained baseline\nas `-n hdemucs_mmi`. The Sparse Hybrid Transformer model decribed in our paper is not provided as its\nrequires custom CUDA code that is not ready for release yet.\nWe are also releasing an experimental 6 sources model, that adds a `guitar` and `piano` source.\nQuick testing seems to show okay quality for `guitar`, but a lot of bleeding and artifacts for the `piano` source.\n\n\n<p align=\"center\">\n<img src=\"./demucs.png\" alt=\"Schema representing the structure of Hybrid Transformer Demucs,\n    with a dual U-Net structure, one branch for the temporal domain,\n    and one branch for the spectral domain. There is a cross-domain Transformer between the Encoders and Decoders.\"\nwidth=\"800px\"></p>\n\n\n\n## Important news if you are already using Demucs\n\nSee the [release notes](./docs/release.md) for more details.\n\n- 22/02/2023: added support for the [SDX 2023 Challenge](https://www.aicrowd.com/challenges/sound-demixing-challenge-2023),\n    see the dedicated [doc page](./docs/sdx23.md)\n- 07/12/2022: Demucs v4 now on PyPI. **htdemucs** model now used by default. Also releasing\n    a 6 sources models (adding `guitar` and `piano`, although the latter doesn't work so well at the moment).\n- 16/11/2022: Added the new **Hybrid Transformer Demucs v4** models.\n\tAdding support for the [torchaudio implementation of HDemucs](https://pytorch.org/audio/stable/tutorials/hybrid_demucs_tutorial.html).\n- 30/08/2022: added reproducibility and ablation grids, along with an updated version of the paper.\n- 17/08/2022: Releasing v3.0.5: Set split segment length to reduce memory. Compatible with pyTorch 1.12.\n- 24/02/2022: Releasing v3.0.4: split into two stems (i.e. karaoke mode).\n    Export as float32 or int24.\n- 17/12/2021: Releasing v3.0.3: bug fixes  (thanks @keunwoochoi), memory drastically\n    reduced on GPU (thanks @famzah) and new multi-core evaluation on CPU (`-j` flag).\n- 12/11/2021: Releasing **Demucs v3** with hybrid domain separation. Strong improvements\n\ton all sources. This is the model that won Sony MDX challenge.\n- 11/05/2021: Adding support for MusDB-HQ and arbitrary wav set, for the MDX challenge. For more information\non joining the challenge with Demucs see [the Demucs MDX instructions](docs/mdx.md)\n\n\n## Comparison with other models\n\nWe provide hereafter a summary of the different metrics presented in the paper.\nYou can also compare Hybrid Demucs (v3), [KUIELAB-MDX-Net][kuielab], [Spleeter][spleeter], Open-Unmix, Demucs (v1), and Conv-Tasnet on one of my favorite\nsongs on my [soundcloud playlist][soundcloud].\n\n### Comparison of accuracy\n\n`Overall SDR` is the mean of the SDR for each of the 4 sources, `MOS Quality` is a rating from 1 to 5\nof the naturalness and absence of artifacts given by human listeners (5 = no artifacts), `MOS Contamination`\nis a rating from 1 to 5 with 5 being zero contamination by other sources. We refer the reader to our [paper][hybrid_paper],\nfor more details.\n\n| Model                        | Domain      | Extra data?       | Overall SDR | MOS Quality | MOS Contamination |\n|------------------------------|-------------|-------------------|-------------|-------------|-------------------|\n| [Wave-U-Net][waveunet]       | waveform    | no                | 3.2         | -           | -                 |\n| [Open-Unmix][openunmix]      | spectrogram | no                | 5.3         | -           | -                 |\n| [D3Net][d3net]               | spectrogram | no                | 6.0         | -           | -                 |\n| [Conv-Tasnet][demucs_v2]     | waveform    | no                | 5.7         | -           |                   |\n| [Demucs (v2)][demucs_v2]     | waveform    | no                | 6.3         | 2.37        | 2.36              |\n| [ResUNetDecouple+][decouple] | spectrogram | no                | 6.7         | -           | -                 |\n| [KUIELAB-MDX-Net][kuielab]   | hybrid      | no                | 7.5         | **2.86**    | 2.55              |\n| [Band-Spit RNN][bandsplit]   | spectrogram | no                | **8.2**     | -           | -                 |\n| **Hybrid Demucs (v3)**       | hybrid      | no                | 7.7         | **2.83**    | **3.04**          |\n| [MMDenseLSTM][mmdenselstm]   | spectrogram | 804 songs         | 6.0         | -           | -                 |\n| [D3Net][d3net]               | spectrogram | 1.5k songs        | 6.7         | -           | -                 |\n| [Spleeter][spleeter]         | spectrogram | 25k songs         | 5.9         | -           | -                 |\n| [Band-Spit RNN][bandsplit]   | spectrogram | 1.7k (mixes only) | **9.0**     | -           | -                 |\n| **HT Demucs f.t. (v4)**      | hybrid      | 800 songs         | **9.0**     | -           | -                 |\n\n\n\n## Requirements\n\nYou will need at least Python 3.8. See `requirements_minimal.txt` for requirements for separation only,\nand `environment-[cpu|cuda].yml` (or `requirements.txt`) if you want to train a new model.\n\n### For Windows users\n\nEverytime you see `python3`, replace it with `python.exe`. You should always run commands from the\nAnaconda console.\n\n### For musicians\n\nIf you just want to use Demucs to separate tracks, you can install it with\n\n```bash\npython3 -m pip install -U demucs\n```\n\nFor bleeding edge versions, you can install directly from this repo using\n```bash\npython3 -m pip install -U git+https://github.com/facebookresearch/demucs#egg=demucs\n```\n\nAdvanced OS support are provided on the following page, **you must read the page for your OS before posting an issues**:\n- **If you are using Windows:** [Windows support](docs/windows.md).\n- **If you are using macOS:** [macOS support](docs/mac.md).\n- **If you are using Linux:** [Linux support](docs/linux.md).\n\n### For machine learning scientists\n\nIf you have anaconda installed, you can run from the root of this repository:\n\n```bash\nconda env update -f environment-cpu.yml  # if you don't have GPUs\nconda env update -f environment-cuda.yml # if you have GPUs\nconda activate demucs\npip install -e .\n```\n\nThis will create a `demucs` environment with all the dependencies installed.\n\nYou will also need to install [soundstretch/soundtouch](https://www.surina.net/soundtouch/soundstretch.html): on macOS you can do `brew install sound-touch`,\nand on Ubuntu `sudo apt-get install soundstretch`. This is used for the\npitch/tempo augmentation.\n\n\n### Running in Docker\n\nThanks to @xserrat, there is now a Docker image definition ready for using Demucs. This can ensure all libraries are correctly installed without interfering with the host OS. See his repo [Docker Facebook Demucs](https://github.com/xserrat/docker-facebook-demucs) for more information.\n\n\n### Running from Colab\n\nI made a Colab to easily separate track with Demucs. Note that\ntransfer speeds with Colab are a bit slow for large media files,\nbut it will allow you to use Demucs without installing anything.\n\n[Demucs on Google Colab](https://colab.research.google.com/drive/1dC9nVxk3V_VPjUADsnFu8EiT-xnU1tGH?usp=sharing)\n\n### Web Demo\n\nIntegrated to [Hugging Face Spaces](https://huggingface.co/spaces) with [Gradio](https://github.com/gradio-app/gradio). See demo: [![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/akhaliq/demucs)\n\n### Graphical Interface\n\n@CarlGao4 has released a GUI for Demucs: [CarlGao4/Demucs-Gui](https://github.com/CarlGao4/Demucs-Gui). Downloads for Windows and macOS is available [here](https://github.com/CarlGao4/Demucs-Gui/releases). Use [FossHub mirror](https://fosshub.com/Demucs-GUI.html) to speed up your download.\n\n@Anjok07 is providing a self contained GUI in [UVR (Ultimate Vocal Remover)](https://github.com/facebookresearch/demucs/issues/334) that supports Demucs.\n\n### Other providers\n\nAudiostrip is providing free online separation with Demucs on their website [https://audiostrip.co.uk/](https://audiostrip.co.uk/).\n\n[MVSep](https://mvsep.com/) also provides free online separation, select `Demucs3 model B` for the best quality.\n\n[Neutone](https://neutone.space/) provides a realtime Demucs model in their free VST/AU plugin that can be used in your favorite DAW.\n\n\n## Separating tracks\n\nIn order to try Demucs, you can just run from any folder (as long as you properly installed it)\n\n```bash\ndemucs PATH_TO_AUDIO_FILE_1 [PATH_TO_AUDIO_FILE_2 ...]   # for Demucs\n# If you used `pip install --user` you might need to replace demucs with python3 -m demucs\npython3 -m demucs --mp3 --mp3-bitrate BITRATE PATH_TO_AUDIO_FILE_1  # output files saved as MP3\n        # use --mp3-preset to change encoder preset, 2 for best quality, 7 for fastest\n# If your filename contain spaces don't forget to quote it !!!\ndemucs \"my music/my favorite track.mp3\"\n# You can select different models with `-n` mdx_q is the quantized model, smaller but maybe a bit less accurate.\ndemucs -n mdx_q myfile.mp3\n# If you only want to separate vocals out of an audio, use `--two-stems=vocals` (You can also set to drums or bass)\ndemucs --two-stems=vocals myfile.mp3\n```\n\n\nIf you have a GPU, but you run out of memory, please use `--segment SEGMENT` to reduce length of each split. `SEGMENT` should be changed to a integer describing the length of each segment in seconds.\nA segment length of at least 10 is recommended (the bigger the number is, the more memory is required, but quality may increase). Note that the Hybrid Transformer models only support a maximum segment length of 7.8 seconds.\nCreating an environment variable `PYTORCH_NO_CUDA_MEMORY_CACHING=1` is also helpful. If this still does not help, please add `-d cpu` to the command line. See the section hereafter for more details on the memory requirements for GPU acceleration.\n\nSeparated tracks are stored in the `separated/MODEL_NAME/TRACK_NAME` folder. There you will find four stereo wav files sampled at 44.1 kHz: `drums.wav`, `bass.wav`,\n`other.wav`, `vocals.wav` (or `.mp3` if you used the `--mp3` option).\n\nAll audio formats supported by `torchaudio` can be processed (i.e. wav, mp3, flac, ogg/vorbis on Linux/macOS, etc.). On Windows, `torchaudio` has limited support, so we rely on `ffmpeg`, which should support pretty much anything.\nAudio is resampled on the fly if necessary.\nThe output will be a wav file encoded as int16.\nYou can save as float32 wav files with `--float32`, or 24 bits integer wav with `--int24`.\nYou can pass `--mp3` to save as mp3 instead, and set the bitrate (in kbps) with `--mp3-bitrate` (default is 320).\n\nIt can happen that the output would need clipping, in particular due to some separation artifacts.\nDemucs will automatically rescale each output stem so as to avoid clipping. This can however break\nthe relative volume between stems. If instead you prefer hard clipping, pass `--clip-mode clamp`.\nYou can also try to reduce the volume of the input mixture before feeding it to Demucs.\n\n\nOther pre-trained models can be selected with the `-n` flag.\nThe list of pre-trained models is:\n- `htdemucs`: first version of Hybrid Transformer Demucs. Trained on MusDB + 800 songs. Default model.\n- `htdemucs_ft`: fine-tuned version of `htdemucs`, separation will take 4 times more time\n    but might be a bit better. Same training set as `htdemucs`.\n- `htdemucs_6s`: 6 sources version of `htdemucs`, with `piano` and `guitar` being added as sources.\n    Note that the `piano` source is not working great at the moment.\n- `hdemucs_mmi`: Hybrid Demucs v3, retrained on MusDB + 800 songs.\n- `mdx`: trained only on MusDB HQ, winning model on track A at the [MDX][mdx] challenge.\n- `mdx_extra`: trained with extra training data (**including MusDB test set**), ranked 2nd on the track B\n    of the [MDX][mdx] challenge.\n- `mdx_q`, `mdx_extra_q`: quantized version of the previous models. Smaller download and storage\n    but quality can be slightly worse.\n- `SIG`: where `SIG` is a single model from the [model zoo](docs/training.md#model-zoo).\n\nThe `--two-stems=vocals` option allows separating vocals from the rest of the accompaniment (i.e., karaoke mode).\n`vocals` can be changed to any source in the selected model.\nThis will mix the files after separating the mix fully, so this won't be faster or use less memory.\n\nThe `--shifts=SHIFTS` performs multiple predictions with random shifts (a.k.a the *shift trick*) of the input and average them. This makes prediction `SHIFTS` times\nslower. Don't use it unless you have a GPU.\n\nThe `--overlap` option controls the amount of overlap between prediction windows. Default is 0.25 (i.e. 25%) which is probably fine.\nIt can probably be reduced to 0.1 to improve a bit speed.\n\n\nThe `-j` flag allow to specify a number of parallel jobs (e.g. `demucs -j 2 myfile.mp3`).\nThis will multiply by the same amount the RAM used so be careful!\n\n### Memory requirements for GPU acceleration\n\nIf you want to use GPU acceleration, you will need at least 3GB of RAM on your GPU for `demucs`. However, about 7GB of RAM will be required if you use the default arguments. Add `--segment SEGMENT` to change size of each split. If you only have 3GB memory, set SEGMENT to 8 (though quality may be worse if this argument is too small). Creating an environment variable `PYTORCH_NO_CUDA_MEMORY_CACHING=1` can help users with even smaller RAM such as 2GB (I separated a track that is 4 minutes but only 1.5GB is used), but this would make the separation slower.\n\nIf you do not have enough memory on your GPU, simply add `-d cpu` to the command line to use the CPU. With Demucs, processing time should be roughly equal to 1.5 times the duration of the track.\n\n## Calling from another Python program\n\nThe main function provides an `opt` parameter as a simple API. You can just pass the parsed command line as this parameter: \n```python\n# Assume that your command is `demucs --mp3 --two-stems vocals -n mdx_extra \"track with space.mp3\"`\n# The following codes are same as the command above:\nimport demucs.separate\ndemucs.separate.main([\"--mp3\", \"--two-stems\", \"vocals\", \"-n\", \"mdx_extra\", \"track with space.mp3\"])\n\n# Or like this\nimport demucs.separate\nimport shlex\ndemucs.separate.main(shlex.split('--mp3 --two-stems vocals -n mdx_extra \"track with space.mp3\"'))\n```\n\nTo use more complicated APIs, see [API docs](docs/api.md)\n\n## Training Demucs\n\nIf you want to train (Hybrid) Demucs, please follow the [training doc](docs/training.md).\n\n## MDX Challenge reproduction\n\nIn order to reproduce the results from the Track A and Track B submissions, checkout the [MDX Hybrid Demucs submission repo][mdx_submission].\n\n\n\n## How to cite\n\n```\n@inproceedings{rouard2022hybrid,\n  title={Hybrid Transformers for Music Source Separation},\n  author={Rouard, Simon and Massa, Francisco and D{\\'e}fossez, Alexandre},\n  booktitle={ICASSP 23},\n  year={2023}\n}\n\n@inproceedings{defossez2021hybrid,\n  title={Hybrid Spectrogram and Waveform Source Separation},\n  author={D{\\'e}fossez, Alexandre},\n  booktitle={Proceedings of the ISMIR 2021 Workshop on Music Source Separation},\n  year={2021}\n}\n```\n\n## License\n\nDemucs is released under the MIT license as found in the [LICENSE](LICENSE) file.\n\n[hybrid_paper]: https://arxiv.org/abs/2111.03600\n[waveunet]: https://github.com/f90/Wave-U-Net\n[musdb]: https://sigsep.github.io/datasets/musdb.html\n[openunmix]: https://github.com/sigsep/open-unmix-pytorch\n[mmdenselstm]: https://arxiv.org/abs/1805.02410\n[demucs_v2]: https://github.com/facebookresearch/demucs/tree/v2\n[demucs_v3]: https://github.com/facebookresearch/demucs/tree/v3\n[spleeter]: https://github.com/deezer/spleeter\n[soundcloud]: https://soundcloud.com/honualx/sets/source-separation-in-the-waveform-domain\n[d3net]: https://arxiv.org/abs/2010.01733\n[mdx]: https://www.aicrowd.com/challenges/music-demixing-challenge-ismir-2021\n[kuielab]: https://github.com/kuielab/mdx-net-submission\n[decouple]: https://arxiv.org/abs/2109.05418\n[mdx_submission]: https://github.com/adefossez/mdx21_demucs\n[bandsplit]: https://arxiv.org/abs/2209.15174\n[htdemucs]: https://arxiv.org/abs/2211.08553\n"
        },
        {
          "name": "conf",
          "type": "tree",
          "content": null
        },
        {
          "name": "demucs.png",
          "type": "blob",
          "size": 331.341796875,
          "content": null
        },
        {
          "name": "demucs",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "environment-cpu.yml",
          "type": "blob",
          "size": 0.412109375,
          "content": "name: demucs\n\nchannels:\n  - pytorch\n  - conda-forge\n\ndependencies:\n  - python>=3.8,<3.10\n  - ffmpeg>=4.2\n  - pytorch>=1.8.1\n  - torchaudio>=0.8\n  - tqdm>=4.36\n  - pip\n  - pip:\n    - diffq>=0.2\n    - dora-search\n    - einops\n    - hydra-colorlog>=1.1\n    - hydra-core>=1.1\n    - julius>=0.2.3\n    - lameenc>=1.2\n    - openunmix\n    - musdb>=0.4.0\n    - museval>=0.4.0\n    - soundfile\n    - submitit\n    - treetable>=0.2.3\n\n"
        },
        {
          "name": "environment-cuda.yml",
          "type": "blob",
          "size": 0.4306640625,
          "content": "name: demucs\n\nchannels:\n  - pytorch\n  - conda-forge\n\ndependencies:\n  - python>=3.8,<3.10\n  - ffmpeg>=4.2\n  - pytorch>=1.8.1\n  - torchaudio>=0.8\n  - cudatoolkit>=10\n  - tqdm>=4.36\n  - pip\n  - pip:\n    - diffq>=0.2\n    - dora-search\n    - einops\n    - hydra-colorlog>=1.1\n    - hydra-core>=1.1\n    - julius>=0.2.3\n    - lameenc>=1.2\n    - openunmix\n    - musdb>=0.4.0\n    - museval>=0.4.0\n    - soundfile\n    - submitit\n    - treetable>=0.2.3\n"
        },
        {
          "name": "hubconf.py",
          "type": "blob",
          "size": 0.3544921875,
          "content": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n# All rights reserved.\n#\n# This source code is licensed under the license found in the\n# LICENSE file in the root directory of this source tree.\n\ndependencies = ['dora-search', 'julius', 'lameenc', 'openunmix', 'pyyaml',\n                'torch', 'torchaudio', 'tqdm']\n\nfrom demucs.pretrained import get_model\n\n"
        },
        {
          "name": "mypy.ini",
          "type": "blob",
          "size": 0.1337890625,
          "content": "[mypy]\n\n[mypy-treetable,torchaudio.*,diffq,yaml,tqdm,lameenc,musdb,museval,openunmix.*,einops,xformers.*]\nignore_missing_imports = True\n\n"
        },
        {
          "name": "outputs.tar.gz",
          "type": "blob",
          "size": 1.8408203125,
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.306640625,
          "content": "# please make sure you have already a pytorch install that is cuda enabled!\ndora-search>=0.1.12\ndiffq>=0.2.1\neinops\nflake8\nhydra-colorlog>=1.1\nhydra-core>=1.1\njulius>=0.2.3\nlameenc>=1.2\nmuseval\nmypy\nopenunmix\npyyaml\nsubmitit\ntorch>=1.8.1\ntorchaudio>=0.8,<2.1\ntqdm\ntreetable\nsoundfile>=0.10.3;sys_platform==\"win32\"\n"
        },
        {
          "name": "requirements_minimal.txt",
          "type": "blob",
          "size": 0.173828125,
          "content": "# please make sure you have already a pytorch install that is cuda enabled!\ndora-search\neinops\njulius>=0.2.3\nlameenc>=1.2\nopenunmix\npyyaml\ntorch>=1.8.1\ntorchaudio>=0.8,<2.1\ntqdm\n"
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.0859375,
          "content": "[pep8]\nmax-line-length = 100\n\n[flake8]\nmax-line-length = 100\n\n[yapf]\ncolumn_limit = 100\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 2.0283203125,
          "content": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n# All rights reserved.\n#\n# This source code is licensed under the license found in the\n# LICENSE file in the root directory of this source tree.\n# author: adefossez\n# Inspired from https://github.com/kennethreitz/setup.py\n\nfrom pathlib import Path\n\nfrom setuptools import setup\n\n\nNAME = 'demucs'\nDESCRIPTION = 'Music source separation in the waveform domain.'\n\nURL = 'https://github.com/facebookresearch/demucs'\nEMAIL = 'defossez@fb.com'\nAUTHOR = 'Alexandre Défossez'\nREQUIRES_PYTHON = '>=3.8.0'\n\nHERE = Path(__file__).parent\n\n# Get version without explicitely loading the module.\nfor line in open('demucs/__init__.py'):\n    line = line.strip()\n    if '__version__' in line:\n        context = {}\n        exec(line, context)\n        VERSION = context['__version__']\n\n\ndef load_requirements(name):\n    required = [i.strip() for i in open(HERE / name)]\n    required = [i for i in required if not i.startswith('#')]\n    return required\n\n\nREQUIRED = load_requirements('requirements_minimal.txt')\nALL_REQUIRED = load_requirements('requirements.txt')\n\ntry:\n    with open(HERE / \"README.md\", encoding='utf-8') as f:\n        long_description = '\\n' + f.read()\nexcept FileNotFoundError:\n    long_description = DESCRIPTION\n\nsetup(\n    name=NAME,\n    version=VERSION,\n    description=DESCRIPTION,\n    long_description=long_description,\n    long_description_content_type='text/markdown',\n    author=AUTHOR,\n    author_email=EMAIL,\n    python_requires=REQUIRES_PYTHON,\n    url=URL,\n    packages=['demucs'],\n    extras_require={\n        'dev': ALL_REQUIRED,\n    },\n    install_requires=REQUIRED,\n    include_package_data=True,\n    entry_points={\n        'console_scripts': ['demucs=demucs.separate:main'],\n    },\n    license='MIT License',\n    classifiers=[\n        # Trove classifiers\n        # Full list: https://pypi.python.org/pypi?%3Aaction=list_classifiers\n        'License :: OSI Approved :: MIT License',\n        'Topic :: Multimedia :: Sound/Audio',\n        'Topic :: Scientific/Engineering :: Artificial Intelligence',\n    ],\n)\n"
        },
        {
          "name": "test.mp3",
          "type": "blob",
          "size": 783.671875,
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}