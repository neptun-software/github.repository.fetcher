{
  "metadata": {
    "timestamp": 1736560848503,
    "page": 550,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjU1MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "je-suis-tm/quant-trading",
      "stars": 6172,
      "defaultBranch": "master",
      "files": [
        {
          "name": "Awesome Oscillator backtest.py",
          "type": "blob",
          "size": 10.5166015625,
          "content": "# coding: utf-8\n\n#details of awesome oscillator can be found here\n# https://www.tradingview.com/wiki/Awesome_Oscillator_(AO)\n#basically i use awesome oscillator to compare with macd oscillator\n#lets see which one makes more money\n#there is not much difference between two of em\n#this time i use exponential smoothing on macd\n#for awesome oscillator, i use simple moving average instead\n#the rules are quite simple\n#these two are momentum trading strategy\n#they compare the short moving average with long moving average\n#if the difference is positive\n#we long the asset, vice versa\n#awesome oscillator has slightly more conditions for signals\n#we will see about it later\n#for more details about macd\n# https://github.com/je-suis-tm/quant-trading/blob/master/MACD%20oscillator%20backtest.py\n\n\n# In[1]:\n#need to get fix yahoo finance package first\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport fix_yahoo_finance as yf\n\n\n# In[2]:\n\n#this part is macd\n#i will not go into details as i have another session called macd\n#the only difference is that i use ewma function to apply exponential smoothing technique\ndef ewmacd(signals,ma1,ma2):\n    \n    signals['macd ma1']=signals['Close'].ewm(span=ma1).mean()    \n    signals['macd ma2']=signals['Close'].ewm(span=ma2).mean()   \n    \n    return signals\n    \ndef signal_generation(df,method,ma1,ma2):\n    \n    signals=method(df,ma1,ma2)\n    signals['macd positions']=0\n    signals['macd positions'][ma1:]=np.where(signals['macd ma1'][ma1:]>=signals['macd ma2'][ma1:],1,0)\n    signals['macd signals']=signals['macd positions'].diff()\n    signals['macd oscillator']=signals['macd ma1']-signals['macd ma2']\n    \n    return signals\n\n\n# In[3]:\n    \n#for awesome oscillator\n#moving average is based on the mean of high and low instead of close price\ndef awesome_ma(signals):\n    \n    signals['awesome ma1'],signals['awesome ma2']=0,0\n    signals['awesome ma1']=((signals['High']+signals['Low'])/2).rolling(window=5).mean()\n    signals['awesome ma2']=((signals['High']+signals['Low'])/2).rolling(window=34).mean()\n    \n    return signals\n\n\n#awesome signal generation,AWESOME!\ndef awesome_signal_generation(df,method):\n    \n    signals=method(df)\n    signals.reset_index(inplace=True)\n    signals['awesome signals']=0\n    signals['awesome oscillator']=signals['awesome ma1']-signals['awesome ma2']  \n    signals['cumsum']=0\n\n\n    for i in range(2,len(signals)):\n\n        #awesome oscillator has an extra way to generate signals\n        #its called saucer\n        #A Bearish Saucer setup occurs when the AO is below the Zero Line\n        #in another word, awesome oscillator is negative\n        #A Bearish Saucer entails two consecutive green bars (with the second bar being higher than the first bar) being followed by a red bar.\n        #in another word, green bar refers to open price is higher than close price\n    \n        if (signals['Open'][i]>signals['Close'][i] and \n        signals['Open'][i-1]<signals['Close'][i-1] and \n        signals['Open'][i-2]<signals['Close'][i-2] and\n        signals['awesome oscillator'][i-1]>signals['awesome oscillator'][i-2] and\n        signals['awesome oscillator'][i-1]<0 and \n        signals['awesome oscillator'][i]<0):\n            signals.at[i,'awesome signals']=1\n\n\n        #this is bullish saucer\n        #vice versa\n        \n        if (signals['Open'][i]<signals['Close'][i] and \n        signals['Open'][i-1]>signals['Close'][i-1] and \n        signals['Open'][i-2]>signals['Close'][i-2] and\n        signals['awesome oscillator'][i-1]<signals['awesome oscillator'][i-2] and\n        signals['awesome oscillator'][i-1]>0 and\n        signals['awesome oscillator'][i]>0):\n            signals.at[i,'awesome signals']=-1\n\n\n        #this part is the same as macd signal generation\n        #nevertheless, we have extra rules to get signals ahead of moving average\n        #if we get signals before moving average generate any signal\n        #we will ignore signals generated by moving average then\n        #as it is delayed and probably deliver fewer profit than previous signals\n        #we use cumulated sum to see if there has been created any open positions\n        #if so, we will take a pass\n        \n        if signals['awesome ma1'][i]>signals['awesome ma2'][i]:\n            signals.at[i,'awesome signals']=1\n            signals['cumsum']=signals['awesome signals'].cumsum()\n            if signals['cumsum'][i]>1:\n                signals.at[i,'awesome signals']=0\n            \n        if signals['awesome ma1'][i]<signals['awesome ma2'][i]:\n            signals.at[i,'awesome signals']=-1\n            signals['cumsum']=signals['awesome signals'].cumsum()\n            if signals['cumsum'][i]<0:\n                signals.at[i,'awesome signals']=0\n    \n    signals['cumsum']=signals['awesome signals'].cumsum()\n    \n    return signals\n\n\n# In[4]:\n    \n#we plot the results to compare\n#basically the same as macd\n#im not gonna explain much\ndef plot(new,ticker):\n    \n    #positions\n    fig=plt.figure()\n    ax=fig.add_subplot(211)\n\n    new['Close'].plot(label=ticker)\n    ax.plot(new.loc[new['awesome signals']==1].index,new['Close'][new['awesome signals']==1],label='AWESOME LONG',lw=0,marker='^',c='g')\n    ax.plot(new.loc[new['awesome signals']==-1].index,new['Close'][new['awesome signals']==-1],label='AWESOME SHORT',lw=0,marker='v',c='r')\n\n    plt.legend(loc='best')\n    plt.grid(True)\n    plt.title('Positions')\n\n    bx=fig.add_subplot(212,sharex=ax)\n    new['Close'].plot(label=ticker)\n    bx.plot(new.loc[new['macd signals']==1].index,new['Close'][new['macd signals']==1],label='MACD LONG',lw=0,marker='^',c='g')\n    bx.plot(new.loc[new['macd signals']==-1].index,new['Close'][new['macd signals']==-1],label='MACD SHORT',lw=0,marker='v',c='r')\n\n    plt.legend(loc='best')\n    plt.grid(True)\n    plt.show()\n\n    \n    #oscillator\n    fig=plt.figure()\n    cx=fig.add_subplot(211)\n\n    c=np.where(new['Open']>new['Close'],'r','g')\n    cx.bar(range(len(new)),new['awesome oscillator'],color=c,label='awesome oscillator')\n\n    plt.grid(True)\n    plt.legend(loc='best')\n    plt.title('Oscillator')\n\n    dx=fig.add_subplot(212,sharex=cx)\n\n    new['macd oscillator'].plot(kind='bar',label='macd oscillator')\n\n    plt.grid(True)\n    plt.legend(loc='best')\n    plt.xlabel('')\n    plt.xticks([])\n    plt.show()\n\n\n\n    #moving average\n    fig=plt.figure()\n    ex=fig.add_subplot(211)\n\n    new['awesome ma1'].plot(label='awesome ma1')\n    new['awesome ma2'].plot(label='awesome ma2',linestyle=':')\n\n    plt.legend(loc='best')\n    plt.grid(True)\n    plt.xticks([])\n    plt.xlabel('')\n    plt.title('Moving Average')\n\n    fig=plt.figure()\n    fx=fig.add_subplot(212,sharex=bx)\n    \n    new['macd ma1'].plot(label='macd ma1')\n    new['macd ma2'].plot(label='macd ma2',linestyle=':')\n\n    plt.legend(loc='best')\n    plt.grid(True)\n    plt.show()\n\n\n# In[5]:\n    \n#normally i dont include backtesting stats\n#for the comparison, i am willing to make an exception\n#capital0 is intial capital\n#positions defines how much shares we buy for every single trade\ndef portfolio(signals):\n        \n    capital0=5000\n    positions=100\n\n    portfolio=pd.DataFrame()\n    portfolio['Close']=signals['Close']\n    \n    #cumsum is used to calculate the change of value while holding shares\n    portfolio['awesome holding']=signals['cumsum']*portfolio['Close']*positions\n    portfolio['macd holding']=signals['macd positions']*portfolio['Close']*positions\n\n    #basically cash is initial capital minus the profit we make from every trade\n    #note that we have to use cumulated sum to add every profit into our cash\n    portfolio['awesome cash']=capital0-(signals['awesome signals']*portfolio['Close']*positions).cumsum()\n    portfolio['macd cash']=capital0-(signals['macd signals']*portfolio['Close']*positions).cumsum()\n\n    portfolio['awesome asset']=portfolio['awesome holding']+portfolio['awesome cash']\n    portfolio['macd asset']=portfolio['macd holding']+portfolio['macd cash']\n\n    portfolio['awesome return']=portfolio['awesome asset'].pct_change()\n    portfolio['macd return']=portfolio['macd asset'].pct_change()\n    \n    return portfolio\n\n\n# In[6]:\n\n#lets plot how two strategies increase our asset value\ndef profit(portfolio):\n        \n    gx=plt.figure()\n    gx.add_subplot(111)\n\n    portfolio['awesome asset'].plot()\n    portfolio['macd asset'].plot()\n\n    plt.legend(loc='best')\n    plt.grid(True)\n    plt.title('Awesome VS MACD')\n    plt.show()\n\n\n# In[7]:\n\n#i use a function to calculate maximum drawdown\n#the idea is simple\n#for every day, we take the current asset value\n#to compare with the previous highest asset value\n#we get our daily drawdown\n#it is supposed to be negative if it is not the maximum for this period so far\n#we implement a temporary variable to store the minimum value\n#which is called maximum drawdown\n#for each daily drawdown that is smaller than our temporary value\n#we update the temp until we finish our traversal\n#in the end we return the maximum drawdown\ndef mdd(series):\n\n    temp=0\n    for i in range(1,len(series)):\n        if temp>(series[i]/max(series[:i])-1):\n            temp=(series[i]/max(series[:i])-1)\n\n    return temp\n\n\ndef stats(portfolio):\n    \n    stats=pd.DataFrame([0])\n\n    #lets calculate some sharpe ratios\n    #note that i set risk free return at 0 for simplicity\n    #alternatively we can use snp500 as a benchmark\n    stats['awesome sharpe']=(portfolio['awesome asset'].iloc[-1]/5000-1)/np.std(portfolio['awesome return'])\n    stats['macd sharpe']=(portfolio['macd asset'].iloc[-1]/5000-1)/np.std(portfolio['macd return'])\n\n    stats['awesome mdd']=mdd(portfolio['awesome asset'])\n    stats['macd mdd']=mdd(portfolio['macd asset'])\n\n    #ta-da!\n    print(stats)\n\n\n# In[8]:   \n\ndef main():\n    \n    #awesome oscillator uses 5 lags as short ma\n    #34 lags as long ma\n    #for the consistent comparison\n    #i apply the same to macd oscillator\n    ma1=5\n    ma2=34\n\n    #downloading\n    stdate=input('start date in format yyyy-mm-dd:')\n    eddate=input('end date in format yyyy-mm-dd:')\n    ticker=input('ticker:')\n    df=yf.download(ticker,start=stdate,end=eddate)\n\n    #slicing the downloaded dataset\n    #if the dataset is too large\n    #backtesting plot would look messy\n    slicer=int(input('slicing:'))\n    signals=signal_generation(df,ewmacd,ma1,ma2)\n    sig=awesome_signal_generation(signals,awesome_ma)\n    new=sig[slicer:]\n    plot(new,ticker)\n    \n    portfo=portfolio(sig)\n    profit(portfo)\n    \n    stats(portfo)\n    \n    #from my tests\n    #macd has demonstrated a higher sharpe ratio\n    #it executes fewer trades but brings more profits\n    #however its maximum drawdown is higher than awesome oscillator\n    #which one is better?\n    #it depends on your risk averse level\n\nif __name__ == '__main__':\n    main()\n"
        },
        {
          "name": "Bollinger Bands Pattern Recognition backtest.py",
          "type": "blob",
          "size": 8.2255859375,
          "content": "\n# coding: utf-8\n\n# In[1]:\n\n#bollinger bands is a simple indicator\n#just moving average plus moving standard deviation\n#but pattern recognition is a differenct case\n#visualization is easy for human to identify the pattern\n#but for the machines, we gotta find a different approach\n#when we talk about pattern recognition these days\n#people always respond with machine learning\n#why machine learning when u can use arithmetic approach \n#which is much faster and simpler?\n\n#there are many patterns for recognition\n#top m, bottom w, head-shoulder top, head-shoulder bottom, elliott waves\n#in this content, we only discuss bottom w\n#top m is just the reverse of bottom w\n#rules of bollinger bands and bottom w can be found in the following link:\n# https://www.tradingview.com/wiki/Bollinger_Bands_(BB)\n\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport copy\nimport numpy as np\n\n\n# In[2]:\nos.chdir('d:/')\n\n\n# In[3]:\n\n#first step is to calculate moving average and moving standard deviation\n#we plus/minus two standard deviations on moving average\n#we get our upper, mid, lower bands\ndef bollinger_bands(df):\n    \n    data=copy.deepcopy(df)\n    data['std']=data['price'].rolling(window=20,min_periods=20).std()\n    data['mid band']=data['price'].rolling(window=20,min_periods=20).mean()\n    data['upper band']=data['mid band']+2*data['std']\n    data['lower band']=data['mid band']-2*data['std']\n    \n    return data\n\n\n# In[4]:\n\n\n#the signal generation is a bit tricky\n#there are four conditions to satisfy\n#for the shape of w, there are five nodes\n#from left to right, top to bottom, l,k,j,m,i\n#when we generate signals\n#the iteration node is the top right node i, condition 4\n#first, we find the middle node j, condition 2\n#next, we identify the first bottom node k, condition 1\n#after that, we point out the first top node l\n#l is not any of those four conditions\n#we just use it for pattern visualization\n#finally, we locate the second bottom node m, condition 3\n#plz refer to the following link for my poor visualization\n# https://github.com/je-suis-tm/quant-trading/blob/master/preview/bollinger%20bands%20bottom%20w%20pattern.png\ndef signal_generation(data,method):\n    \n    #according to investopedia\n    #for a double bottom pattern\n    #we should use 3-month horizon which is 75\n    period=75\n    \n    #alpha denotes the difference between price and bollinger bands\n    #if alpha is too small, its unlikely to trigger a signal\n    #if alpha is too large, its too easy to trigger a signal\n    #which gives us a higher probability to lose money\n    #beta denotes the scale of bandwidth\n    #when bandwidth is larger than beta, it is expansion period\n    #when bandwidth is smaller than beta, it is contraction period\n    alpha=0.0001\n    beta=0.0001\n    \n    df=method(data)\n    df['signals']=0\n    \n    #as usual, cumsum denotes the holding position\n    #coordinates store five nodes of w shape\n    #later we would use these coordinates to draw a w shape\n    df['cumsum']=0\n    df['coordinates']=''\n    \n    for i in range(period,len(df)):\n        \n        #moveon is a process control\n        #if moveon==true, we move on to verify the next condition\n        #if false, we move on to the next iteration\n        #threshold denotes the value of node k\n        #we would use it for the comparison with node m\n        #plz refer to condition 3\n        moveon=False\n        threshold=0.0\n        \n        #bottom w pattern recognition\n        #there is another signal generation method called walking the bands\n        #i personally think its too late for following the trend\n        #after confirmation of several breakthroughs\n        #maybe its good for stop and reverse\n        #condition 4\n        if (df['price'][i]>df['upper band'][i]) and \\\n        (df['cumsum'][i]==0):\n            \n            for j in range(i,i-period,-1):                \n                \n                #condition 2\n                if (np.abs(df['mid band'][j]-df['price'][j])<alpha) and \\\n                (np.abs(df['mid band'][j]-df['upper band'][i])<alpha):\n                    moveon=True\n                    break\n            \n            if moveon==True:\n                moveon=False\n                for k in range(j,i-period,-1):\n                    \n                    #condition 1\n                    if (np.abs(df['lower band'][k]-df['price'][k])<alpha):\n                        threshold=df['price'][k]\n                        moveon=True\n                        break\n                        \n            if moveon==True:\n                moveon=False\n                for l in range(k,i-period,-1):\n                    \n                    #this one is for plotting w shape\n                    if (df['mid band'][l]<df['price'][l]):\n                        moveon=True\n                        break\n                    \n            if moveon==True:\n                moveon=False        \n                for m in range(i,j,-1):\n                    \n                    #condition 3\n                    if (df['price'][m]-df['lower band'][m]<alpha) and \\\n                    (df['price'][m]>df['lower band'][m]) and \\\n                    (df['price'][m]<threshold):\n                        df.at[i,'signals']=1\n                        df.at[i,'coordinates']='%s,%s,%s,%s,%s'%(l,k,j,m,i)\n                        df['cumsum']=df['signals'].cumsum()\n                        moveon=True\n                        break\n        \n        #clear our positions when there is contraction on bollinger bands\n        #contraction on the bandwidth is easy to understand\n        #when price momentum exists, the price would move dramatically for either direction\n        #which greatly increases the standard deviation\n        #when the momentum vanishes, we clear our positions\n        \n        #note that we put moveon in the condition\n        #just in case our signal generation time is contraction period\n        #but we dont wanna clear positions right now\n        if (df['cumsum'][i]!=0) and \\\n        (df['std'][i]<beta) and \\\n        (moveon==False):\n            df.at[i,'signals']=-1\n            df['cumsum']=df['signals'].cumsum()\n            \n    return df\n\n\n# In[5]:\n\n#visualization\ndef plot(new):\n    \n    #as usual we could cut the dataframe into a small slice\n    #for a tight and neat figure\n    #a and b denotes entry and exit of a trade\n    a,b=list(new[new['signals']!=0].iloc[:2].index)\n    \n    newbie=new[a-85:b+30]\n    newbie.set_index(pd.to_datetime(newbie['date'],format='%Y-%m-%d %H:%M:%S'),inplace=True)\n\n   \n    fig=plt.figure(figsize=(10,5))\n    ax=fig.add_subplot(111)\n    \n    #plotting positions on price series and bollinger bands\n    ax.plot(newbie['price'],label='price')\n    ax.fill_between(newbie.index,newbie['lower band'],newbie['upper band'],alpha=0.2,color='#45ADA8')\n    ax.plot(newbie['mid band'],linestyle='--',label='moving average',c='#132226')\n    ax.plot(newbie['price'][newbie['signals']==1],marker='^',markersize=12, \\\n            lw=0,c='g',label='LONG')\n    ax.plot(newbie['price'][newbie['signals']==-1],marker='v',markersize=12, \\\n            lw=0,c='r',label='SHORT')\n    \n    #plotting w shape\n    #we locate the coordinates then find the exact date as index\n    temp=newbie['coordinates'][newbie['signals']==1]\n    indexlist=list(map(int,temp[temp.index[0]].split(',')))\n    ax.plot(newbie['price'][pd.to_datetime(new['date'].iloc[indexlist])], \\\n            lw=5,alpha=0.7,c='#FE4365',label='double bottom pattern')\n    \n    #add some captions\n    plt.text((newbie.loc[newbie['signals']==1].index[0]), \\\n             newbie['lower band'][newbie['signals']==1],'Expansion',fontsize=15,color='#563838')\n    plt.text((newbie.loc[newbie['signals']==-1].index[0]), \\\n             newbie['lower band'][newbie['signals']==-1],'Contraction',fontsize=15,color='#563838')\n    \n    plt.legend(loc='best')\n    plt.title('Bollinger Bands Pattern Recognition')\n    plt.ylabel('price')\n    plt.grid(True)\n    plt.show()\n\n\n# In[6]:\n\n#ta-da\ndef main():\n    \n    #again, i download data from histdata.com\n    #and i take the average of bid and ask price\n    df=pd.read_csv('gbpusd.csv')\n    \n    signals=signal_generation(df,bollinger_bands)\n\n    new=copy.deepcopy(signals)\n    plot(new)\n\n#how to calculate stats could be found from my other code called Heikin-Ashi\n# https://github.com/je-suis-tm/quant-trading/blob/master/heikin%20ashi%20backtest.py\n\n\nif __name__ == '__main__':\n    main()\n"
        },
        {
          "name": "Dual Thrust backtest.py",
          "type": "blob",
          "size": 9.3408203125,
          "content": "# -*- coding: utf-8 -*-\r\n\"\"\"\r\nCreated on Mon Mar 19 15:22:38 2018\r\n@author: Administrator\r\n\r\n\"\"\"\r\n# In[1]:\r\n\r\n#dual thrust is an opening range breakout strategy\r\n#it is very similar to London Breakout\r\n#please check London Breakout if u have any questions\r\n# https://github.com/je-suis-tm/quant-trading/blob/master/London%20Breakout%20backtest.py\r\n#Initially we set up upper and lower thresholds based on previous days open, close, high and low \r\n#When the market opens and the price exceeds thresholds, we would take long/short positions prior to upper/lower thresholds \r\n#However, there is no stop long/short position in this strategy\r\n#We clear all positions at the end of the day\r\n#rules of dual thrust can be found in the following link\r\n# https://www.quantconnect.com/tutorials/dual-thrust-trading-algorithm/\r\n\r\nimport os\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\n# In[2]:\r\n\r\nos.chdir('D:/')\r\n\r\n\r\n# In[3]:\r\n\r\n\r\n#data frequency convertion from minute to intra daily\r\n#as we are doing backtesting, we have already got all the datasets we need\r\n#we can create a table to store all open, close, high and low prices\r\n#and calculate the range before we get to signal generation\r\n#otherwise, we would have to put this part inside the loop\r\n#it would greatly increase the time complexity\r\n#however, in real time trading, we do not have futures price\r\n#we have to store all past information in sql db\r\n#we have to calculate the range from db before the market opens\r\n\r\ndef min2day(df,column,year,month,rg):\r\n    \r\n    #lets create a dictionary \r\n    #we use keys to classify different info we need\r\n    memo={'date':[],'open':[],'close':[],'high':[],'low':[]}\r\n    \r\n    #no matter which month\r\n    #the maximum we can get is 31 days\r\n    #thus, we only need to run a traversal on 31 days\r\n    #nevertheless, not everyday is a workday\r\n    #assuming our raw data doesnt contain weekend prices\r\n    #we use try function to make sure we get the info of workdays without errors\r\n    #note that i put date at the end of the loop\r\n    #the date appendix doesnt depend on our raw data\r\n    #it only relies on the range function above\r\n    #we could accidentally append weekend date if we put it at the beginning of try function\r\n    #not until the program cant find price in raw data will the program stop\r\n    #by that time, we have already appended weekend date\r\n    #we wanna make sure the length of all lists in dictionary are the same\r\n    #so that we can construct a structured table in the next step\r\n    for i in range(1,32):\r\n    \r\n        try:\r\n            temp=df['%s-%s-%s 3:00:00'%(year,month,i):'%s-%s-%s 12:00:00'%(year,month,i)][column]\r\n\r\n            memo['open'].append(temp[0])\r\n            memo['close'].append(temp[-1])\r\n            memo['high'].append(max(temp))\r\n            memo['low'].append(min(temp))\r\n            memo['date'].append('%s-%s-%s'%(year,month,i))\r\n       \r\n\r\n        except Exception:\r\n            pass\r\n        \r\n    intraday=pd.DataFrame(memo)\r\n    intraday.set_index(pd.to_datetime(intraday['date']),inplace=True)\r\n    \r\n    \r\n    #preparation\r\n    intraday['range1']=intraday['high'].rolling(rg).max()-intraday['close'].rolling(rg).min()\r\n    intraday['range2']=intraday['close'].rolling(rg).max()-intraday['low'].rolling(rg).min()\r\n    intraday['range']=np.where(intraday['range1']>intraday['range2'],intraday['range1'],intraday['range2'])\r\n    \r\n    return intraday\r\n\r\n\r\n#signal generation\r\n#even replace assignment with pandas.at\r\n#it still takes a while for us to get the result\r\n#any optimization suggestion besides using numpy array?\r\ndef signal_generation(df,intraday,param,column,rg):\r\n    \r\n    #as the lags of days have been set to 5  \r\n    #we should start our backtesting after 4 workdays of current month\r\n    #cumsum is to control the holding of underlying asset\r\n    #sigup and siglo are the variables to store the upper/lower threshold  \r\n    #upper and lower are for the purpose of tracking sigup and siglo\r\n    signals=df[df.index>=intraday['date'].iloc[rg-1]]\r\n    signals['signals']=0\r\n    signals['cumsum']=0\r\n    signals['upper']=0.0\r\n    signals['lower']=0.0\r\n    sigup=float(0)\r\n    siglo=float(0)\r\n    \r\n    #for traversal on time series\r\n    #the tricky part is the slicing\r\n    #we have to either use [i:i] or pd.Series\r\n    #first we set up thresholds at the beginning of london market\r\n    #which is est 3am\r\n    #if the price exceeds either threshold\r\n    #we will take long/short positions  \r\n    \r\n    for i in signals.index:\r\n        \r\n        #note that intraday and dataframe have different frequencies\r\n        #obviously different metrics for indexes\r\n        #we use variable date for index convertion\r\n        date='%s-%s-%s'%(i.year,i.month,i.day)\r\n        \r\n        \r\n        #market opening\r\n        #set up thresholds\r\n        if (i.hour==3 and i.minute==0):\r\n            sigup=float(param*intraday['range'][date]+pd.Series(signals[column])[i])\r\n            siglo=float(-(1-param)*intraday['range'][date]+pd.Series(signals[column])[i])\r\n\r\n        #thresholds got breached\r\n        #signals generating\r\n        if (sigup!=0 and pd.Series(signals[column])[i]>sigup):\r\n            signals.at[i,'signals']=1\r\n        if (siglo!=0 and pd.Series(signals[column])[i]<siglo):\r\n            signals.at[i,'signals']=-1\r\n\r\n\r\n        #check if signal has been generated\r\n        #if so, use cumsum to verify that we only generate one signal for each situation\r\n        if pd.Series(signals['signals'])[i]!=0:\r\n            signals['cumsum']=signals['signals'].cumsum()        \r\n            if (pd.Series(signals['cumsum'])[i]>1 or pd.Series(signals['cumsum'])[i]<-1):\r\n                signals.at[i,'signals']=0\r\n               \r\n            #if the price goes from below the lower threshold to above the upper threshold during the day\r\n            #we reverse our positions from short to long\r\n            if (pd.Series(signals['cumsum'])[i]==0):\r\n                if (pd.Series(signals[column])[i]>sigup):\r\n                    signals.at[i,'signals']=2\r\n                if (pd.Series(signals[column])[i]<siglo):\r\n                    signals.at[i,'signals']=-2\r\n                    \r\n        #by the end of london market, which is est 12pm\r\n        #we clear all opening positions\r\n        #the whole part is very similar to London Breakout strategy\r\n        if i.hour==12 and i.minute==0:\r\n            sigup,siglo=float(0),float(0)\r\n            signals['cumsum']=signals['signals'].cumsum()\r\n            signals.at[i,'signals']=-signals['cumsum'][i:i]\r\n            \r\n        #keep track of trigger levels\r\n        signals.at[i,'upper']=sigup\r\n        signals.at[i,'lower']=siglo\r\n\r\n    return signals\r\n\r\n#plotting the positions\r\ndef plot(signals,intraday,column):\r\n        \r\n    #we have to do a lil bit slicing to make sure we can see the plot clearly\r\n    #the only reason i go to -3 is that day we execute a trade    \r\n    #give one hour before and after market trading hour for as x axis  \r\n    date=pd.to_datetime(intraday['date']).iloc[-3]      \r\n    signew=signals['%s-%s-%s 02:00:00'%(date.year,date.month,date.day):'%s-%s-%s 13:00:00'%(date.year,date.month,date.day)]\r\n    \r\n    fig=plt.figure(figsize=(10,5))\r\n    ax=fig.add_subplot(111)    \r\n    \r\n    #mostly the same as other py files\r\n    #the only difference is to create an interval for signal generation\r\n    ax.plot(signew.index,signew[column],label=column)\r\n    ax.fill_between(signew.loc[signew['upper']!=0].index,signew['upper'][signew['upper']!=0],signew['lower'][signew['upper']!=0],alpha=0.2,color='#355c7d')\r\n    ax.plot(signew.loc[signew['signals']==1].index,signew[column][signew['signals']==1],lw=0,marker='^',markersize=10,c='g',label='LONG')\r\n    ax.plot(signew.loc[signew['signals']==-1].index,signew[column][signew['signals']==-1],lw=0,marker='v',markersize=10,c='r',label='SHORT')\r\n\r\n    #change legend text color\r\n    lgd=plt.legend(loc='best').get_texts()\r\n    for text in lgd:\r\n        text.set_color('#6C5B7B')\r\n\r\n    #add some captions\r\n    plt.text('%s-%s-%s 03:00:00'%(date.year,date.month,date.day),signew['upper']['%s-%s-%s 03:00:00'%(date.year,date.month,date.day)],'Upper Bound',color='#C06C84')\r\n    plt.text('%s-%s-%s 03:00:00'%(date.year,date.month,date.day),signew['lower']['%s-%s-%s 03:00:00'%(date.year,date.month,date.day)],'Lower Bound',color='#C06C84')\r\n    \r\n    plt.ylabel(column)\r\n    plt.xlabel('Date')\r\n    plt.title('Dual Thrust')\r\n    plt.grid(True)\r\n    plt.show()\r\n\r\n\r\n\r\n# In[4]:\r\ndef main():\r\n    \r\n    #similar to London Breakout\r\n    #my raw data comes from the same website\r\n    # http://www.histdata.com/download-free-forex-data/?/excel/1-minute-bar-quotes\r\n    #just take the mid price of whatever currency pair you want\r\n\r\n    df=pd.read_csv('gbpusd.csv')\r\n    df.set_index(pd.to_datetime(df['date']),inplace=True)\r\n\r\n    #rg is the lags of days\r\n    #param is the parameter of trigger range, it should be smaller than one\r\n    #normally ppl use 0.5 to give long and short 50/50 chance to trigger\r\n    rg=5\r\n    param=0.5\r\n\r\n    #these three variables are for the frequency convertion from minute to intra daily\r\n    year=df.index[0].year\r\n    month=df.index[0].month\r\n    column='price'\r\n    \r\n    intraday=min2day(df,column,year,month,rg)\r\n    signals=signal_generation(df,intraday,param,column,rg)\r\n    plot(signals,intraday,column)\r\n\r\n#how to calculate stats could be found from my other code called Heikin-Ashi\r\n# https://github.com/je-suis-tm/quant-trading/blob/master/heikin%20ashi%20backtest.py\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n"
        },
        {
          "name": "Heikin-Ashi backtest.py",
          "type": "blob",
          "size": 14.7197265625,
          "content": "# -*- coding: utf-8 -*-\r\n\"\"\"\r\nCreated on Thu Feb 15 20:48:35 2018\r\n\r\n@author: Administrator\r\n\"\"\"\r\n\r\n\r\n# In[1]:\r\n\r\n\r\n#heikin ashi is a Japanese way to filter out the noise for momentum trading\r\n#it can prevent the occurrence of sideway chops\r\n#basically we do a few transformations on four key benchmarks - Open, Close, High, Low\r\n#apply some unique rules on ha Open, Close, High, Low to trade\r\n#details of heikin ashi indicators and rules can be found in the following link\r\n# https://quantiacs.com/Blog/Intro-to-Algorithmic-Trading-with-Heikin-Ashi.aspx\r\n\r\n#need to get yfinance package first\r\n#it changes its name from fix_yahoo_finance to yfinance, lol\r\n\r\n\r\n# In[2]:\r\n\r\n\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\nimport yfinance as yf\r\nimport numpy as np\r\nimport scipy.integrate\r\nimport scipy.stats\r\n\r\n\r\n# In[3]:\r\n\r\n\r\n\r\n#Heikin Ashi has a unique method to filter out the noise\r\n#its open, close, high, low require a different approach\r\n#please refer to the website mentioned above\r\ndef heikin_ashi(data):\r\n    \r\n    df=data.copy()\r\n    \r\n    df.reset_index(inplace=True)\r\n        \r\n    #heikin ashi close\r\n    df['HA close']=(df['Open']+df['Close']+df['High']+df['Low'])/4\r\n\r\n    #initialize heikin ashi open\r\n    df['HA open']=float(0)\r\n    df['HA open'][0]=df['Open'][0]\r\n\r\n    #heikin ashi open\r\n    for n in range(1,len(df)):\r\n        df.at[n,'HA open']=(df['HA open'][n-1]+df['HA close'][n-1])/2\r\n        \r\n    #heikin ashi high/low\r\n    temp=pd.concat([df['HA open'],df['HA close'],df['Low'],df['High']],axis=1)\r\n    df['HA high']=temp.apply(max,axis=1)\r\n    df['HA low']=temp.apply(min,axis=1)\r\n\r\n    del df['Adj Close']\r\n    del df['Volume']\r\n    \r\n    return df\r\n\r\n\r\n# In[4]:\r\n\r\n\r\n#setting up signal generations\r\n#trigger conditions can be found from the website mentioned above\r\n#they kinda look like marubozu candles\r\n#there s a short strategy as well\r\n#the trigger condition of short strategy is the reverse of long strategy\r\n#you have to satisfy all four conditions to long/short\r\n#nevertheless, the exit signal only has three conditions\r\ndef signal_generation(df,method,stls):\r\n        \r\n    data=method(df)\r\n    \r\n    data['signals']=0\r\n\r\n    #i use cumulated sum to check how many positions i have longed\r\n    #i would ignore the exit signal prior if not holding positions\r\n    #i also keep tracking how many long positions i have got\r\n    #long signals cannot exceed the stop loss limit\r\n    data['cumsum']=0\r\n\r\n    for n in range(1,len(data)):\r\n        \r\n        #long triggered\r\n        if (data['HA open'][n]>data['HA close'][n] and data['HA open'][n]==data['HA high'][n] and\r\n            np.abs(data['HA open'][n]-data['HA close'][n])>np.abs(data['HA open'][n-1]-data['HA close'][n-1]) and\r\n            data['HA open'][n-1]>data['HA close'][n-1]):\r\n            \r\n            data.at[n,'signals']=1\r\n            data['cumsum']=data['signals'].cumsum()\r\n\r\n\r\n            #accumulate too many longs\r\n            if data['cumsum'][n]>stls:\r\n                data.at[n,'signals']=0\r\n        \r\n        #exit positions\r\n        elif (data['HA open'][n]<data['HA close'][n] and data['HA open'][n]==data['HA low'][n] and \r\n        data['HA open'][n-1]<data['HA close'][n-1]):\r\n            \r\n            data.at[n,'signals']=-1\r\n            data['cumsum']=data['signals'].cumsum()\r\n        \r\n\r\n            #clear all longs\r\n            #if there are no long positions in my portfolio\r\n            #ignore the exit signal\r\n            if data['cumsum'][n]>0:\r\n                data.at[n,'signals']=-1*(data['cumsum'][n-1])\r\n\r\n            if data['cumsum'][n]<0:\r\n                data.at[n,'signals']=0\r\n                \r\n    return data\r\n\r\n\r\n# In[5]:\r\n\r\n\r\n#since matplotlib remove the candlestick\r\n#plus we dont wanna install mpl_finance\r\n#we implement our own version\r\n#simply use fill_between to construct the bar\r\n#use line plot to construct high and low\r\ndef candlestick(df,ax=None,titlename='',highcol='High',lowcol='Low',\r\n                opencol='Open',closecol='Close',xcol='Date',\r\n                colorup='r',colordown='g',**kwargs):  \r\n    \r\n    #bar width\r\n    #use 0.6 by default\r\n    dif=[(-3+i)/10 for i in range(7)]\r\n    \r\n    if not ax:\r\n        ax=plt.figure(figsize=(10,5)).add_subplot(111)\r\n    \r\n    #construct the bars one by one\r\n    for i in range(len(df)):\r\n        \r\n        #width is 0.6 by default\r\n        #so 7 data points required for each bar\r\n        x=[i+j for j in dif]\r\n        y1=[df[opencol].iloc[i]]*7\r\n        y2=[df[closecol].iloc[i]]*7\r\n\r\n        barcolor=colorup if y1[0]>y2[0] else colordown\r\n        \r\n        #no high line plot if open/close is high\r\n        if df[highcol].iloc[i]!=max(df[opencol].iloc[i],df[closecol].iloc[i]):\r\n            \r\n            #use generic plot to viz high and low\r\n            #use 1.001 as a scaling factor\r\n            #to prevent high line from crossing into the bar\r\n            plt.plot([i,i],\r\n                     [df[highcol].iloc[i],\r\n                      max(df[opencol].iloc[i],\r\n                          df[closecol].iloc[i])*1.001],c='k',**kwargs)\r\n    \r\n        #same as high\r\n        if df[lowcol].iloc[i]!=min(df[opencol].iloc[i],df[closecol].iloc[i]):             \r\n            \r\n            plt.plot([i,i],\r\n                     [df[lowcol].iloc[i],\r\n                      min(df[opencol].iloc[i],\r\n                          df[closecol].iloc[i])*0.999],c='k',**kwargs)\r\n        \r\n        #treat the bar as fill between\r\n        plt.fill_between(x,y1,y2,\r\n                         edgecolor='k',\r\n                         facecolor=barcolor,**kwargs)\r\n\r\n    #only show 5 xticks\r\n    plt.xticks(range(0,len(df),len(df)//5),df[xcol][0::len(df)//5].dt.date)\r\n    plt.title(titlename)\r\n    \r\n    \r\n#plotting the backtesting result\r\ndef plot(df,ticker):    \r\n    \r\n    df.set_index(df['Date'],inplace=True)\r\n    \r\n    #first plot is Heikin-Ashi candlestick\r\n    #use candlestick function and set Heikin-Ashi O,C,H,L\r\n    ax1=plt.subplot2grid((200,1), (0,0), rowspan=120,ylabel='HA price')\r\n    candlestick(df,ax1,titlename='',highcol='HA high',lowcol='HA low',\r\n                opencol='HA open',closecol='HA close',xcol='Date',\r\n                colorup='r',colordown='g')\r\n    plt.grid(True)\r\n    plt.xticks([])\r\n    plt.title('Heikin-Ashi')\r\n\r\n\r\n    #the second plot is the actual price with long/short positions as up/down arrows\r\n    ax2=plt.subplot2grid((200,1), (120,0), rowspan=80,ylabel='price',xlabel='')\r\n    df['Close'].plot(ax=ax2,label=ticker)\r\n\r\n    #long/short positions are attached to the real close price of the stock\r\n    #set the line width to zero\r\n    #thats why we only observe markers\r\n    ax2.plot(df.loc[df['signals']==1].index,df['Close'][df['signals']==1],marker='^',lw=0,c='g',label='long')\r\n    ax2.plot(df.loc[df['signals']<0].index,df['Close'][df['signals']<0],marker='v',lw=0,c='r',label='short')\r\n\r\n    plt.grid(True)\r\n    plt.legend(loc='best')\r\n    plt.show()\r\n\r\n\r\n\r\n# In[6]:\r\n\r\n\r\n#backtesting\r\n#initial capital 10k to calculate the actual pnl  \r\n#100 shares to buy of every position\r\ndef portfolio(data,capital0=10000,positions=100):   \r\n        \r\n    #cumsum column is created to check the holding of the position\r\n    data['cumsum']=data['signals'].cumsum()\r\n\r\n    portfolio=pd.DataFrame()\r\n    portfolio['holdings']=data['cumsum']*data['Close']*positions\r\n    portfolio['cash']=capital0-(data['signals']*data['Close']*positions).cumsum()\r\n    portfolio['total asset']=portfolio['holdings']+portfolio['cash']\r\n    portfolio['return']=portfolio['total asset'].pct_change()\r\n    portfolio['signals']=data['signals']\r\n    portfolio['date']=data['Date']\r\n    portfolio.set_index('date',inplace=True)\r\n\r\n    return portfolio\r\n\r\n\r\n# In[7]:\r\n\r\n\r\n#plotting the asset value change of the portfolio\r\ndef profit(portfolio):\r\n        \r\n    fig=plt.figure()\r\n    bx=fig.add_subplot(111)\r\n    \r\n    portfolio['total asset'].plot(label='Total Asset')\r\n    \r\n    #long/short position markers related to the portfolio\r\n    #the same mechanism as the previous one\r\n    #replace close price with total asset value\r\n    bx.plot(portfolio['signals'].loc[portfolio['signals']==1].index,portfolio['total asset'][portfolio['signals']==1],lw=0,marker='^',c='g',label='long')\r\n    bx.plot(portfolio['signals'].loc[portfolio['signals']<0].index,portfolio['total asset'][portfolio['signals']<0],lw=0,marker='v',c='r',label='short')\r\n    \r\n    plt.legend(loc='best')\r\n    plt.grid(True)\r\n    plt.xlabel('Date')\r\n    plt.ylabel('Asset Value')\r\n    plt.title('Total Asset')\r\n    plt.show()\r\n\r\n\r\n# In[8]:\r\n\r\n\r\n#omega ratio is a variation of sharpe ratio\r\n#the risk free return is replaced by a given threshold\r\n#in this case, the return of benchmark\r\n#integral is needed to calculate the return above and below the threshold\r\n#you can use summation to do approximation as well\r\n#it is a more reasonable ratio to measure the risk adjusted return\r\n#normal distribution doesnt explain the fat tail of returns\r\n#so i use student T cumulated distribution function instead \r\n#to make our life easier, i do not use empirical distribution\r\n#the cdf of empirical distribution is much more complex\r\n#check wikipedia for more details\r\n# https://en.wikipedia.org/wiki/Omega_ratio\r\ndef omega(risk_free,degree_of_freedom,maximum,minimum):\r\n\r\n    y=scipy.integrate.quad(lambda g:1-scipy.stats.t.cdf(g,degree_of_freedom),risk_free,maximum)\r\n    x=scipy.integrate.quad(lambda g:scipy.stats.t.cdf(g,degree_of_freedom),minimum,risk_free)\r\n\r\n    z=(y[0])/(x[0])\r\n\r\n    return z\r\n\r\n\r\n#sortino ratio is another variation of sharpe ratio\r\n#the standard deviation of all returns is substituted with standard deviation of negative returns\r\n#sortino ratio measures the impact of negative return on return\r\n#i am also using student T probability distribution function instead of normal distribution\r\n#check wikipedia for more details\r\n# https://en.wikipedia.org/wiki/Sortino_ratio\r\ndef sortino(risk_free,degree_of_freedom,growth_rate,minimum):\r\n\r\n    v=np.sqrt(np.abs(scipy.integrate.quad(lambda g:((risk_free-g)**2)*scipy.stats.t.pdf(g,degree_of_freedom),risk_free,minimum)))\r\n    s=(growth_rate-risk_free)/v[0]\r\n\r\n    return s\r\n\r\n\r\n#i use a function to calculate maximum drawdown\r\n#the idea is simple\r\n#for every day, we take the current asset value marked to market\r\n#to compare with the previous highest asset value\r\n#we get our daily drawdown\r\n#it is supposed to be negative if the current one is not the highest\r\n#we implement a temporary variable to store the minimum negative value\r\n#which is called maximum drawdown\r\n#for each daily drawdown that is smaller than our temporary value\r\n#we update the temp until we finish our traversal\r\n#in the end we return the maximum drawdown\r\ndef mdd(series):\r\n\r\n    minimum=0\r\n    for i in range(1,len(series)):\r\n        if minimum>(series[i]/max(series[:i])-1):\r\n            minimum=(series[i]/max(series[:i])-1)\r\n\r\n    return minimum\r\n\r\n\r\n# In[9]:\r\n    \r\n\r\n#stats calculation\r\ndef stats(portfolio,trading_signals,stdate,eddate,capital0=10000):\r\n\r\n    stats=pd.DataFrame([0])\r\n\r\n    #get the min and max of return\r\n    maximum=np.max(portfolio['return'])\r\n    minimum=np.min(portfolio['return'])    \r\n\r\n    #growth_rate denotes the average growth rate of portfolio \r\n    #use geometric average instead of arithmetic average for percentage growth\r\n    growth_rate=(float(portfolio['total asset'].iloc[-1]/capital0))**(1/len(trading_signals))-1\r\n\r\n    #calculating the standard deviation\r\n    std=float(np.sqrt((((portfolio['return']-growth_rate)**2).sum())/len(trading_signals)))\r\n\r\n    #use S&P500 as benchmark\r\n    benchmark=yf.download('^GSPC',start=stdate,end=eddate)\r\n\r\n    #return of benchmark\r\n    return_of_benchmark=float(benchmark['Close'].iloc[-1]/benchmark['Open'].iloc[0]-1)\r\n\r\n    #rate_of_benchmark denotes the average growth rate of benchmark \r\n    #use geometric average instead of arithmetic average for percentage growth\r\n    rate_of_benchmark=(return_of_benchmark+1)**(1/len(trading_signals))-1\r\n\r\n    del benchmark\r\n\r\n    #backtesting stats\r\n    #CAGR stands for cumulated average growth rate\r\n    stats['CAGR']=stats['portfolio return']=float(0)\r\n    stats['CAGR'][0]=growth_rate\r\n    stats['portfolio return'][0]=portfolio['total asset'].iloc[-1]/capital0-1\r\n    stats['benchmark return']=return_of_benchmark\r\n    stats['sharpe ratio']=(growth_rate-rate_of_benchmark)/std\r\n    stats['maximum drawdown']=mdd(portfolio['total asset'])\r\n\r\n    #calmar ratio is sorta like sharpe ratio\r\n    #the standard deviation is replaced by maximum drawdown\r\n    #it is the measurement of return after worse scenario adjustment\r\n    #check wikipedia for more details\r\n    # https://en.wikipedia.org/wiki/Calmar_ratio\r\n    stats['calmar ratio']=growth_rate/stats['maximum drawdown']\r\n    stats['omega ratio']=omega(rate_of_benchmark,len(trading_signals),maximum,minimum)\r\n    stats['sortino ratio']=sortino(rate_of_benchmark,len(trading_signals),growth_rate,minimum)\r\n\r\n    #note that i use stop loss limit to limit the numbers of longs\r\n    #and when clearing positions, we clear all the positions at once\r\n    #so every long is always one, and short cannot be larger than the stop loss limit\r\n    stats['numbers of longs']=trading_signals['signals'].loc[trading_signals['signals']==1].count()\r\n    stats['numbers of shorts']=trading_signals['signals'].loc[trading_signals['signals']<0].count()\r\n    stats['numbers of trades']=stats['numbers of shorts']+stats['numbers of longs']  \r\n\r\n    #to get the total length of trades\r\n    #given that cumsum indicates the holding of positions\r\n    #we can get all the possible outcomes when cumsum doesnt equal zero\r\n    #then we count how many non-zero positions there are\r\n    #we get the estimation of total length of trades\r\n    stats['total length of trades']=trading_signals['signals'].loc[trading_signals['cumsum']!=0].count()\r\n    stats['average length of trades']=stats['total length of trades']/stats['numbers of trades']\r\n    stats['profit per trade']=float(0)\r\n    stats['profit per trade'].iloc[0]=(portfolio['total asset'].iloc[-1]-capital0)/stats['numbers of trades'].iloc[0]\r\n\r\n    del stats[0]\r\n    print(stats)\r\n\r\n\r\n# In[10]:\r\n\r\ndef main():\r\n    \r\n    #initializing\r\n\r\n    #stop loss positions, the maximum long positions we can get\r\n    #without certain constraints, you will long indefinites times \r\n    #as long as the market condition triggers the signal\r\n    #in a whipsaw condition, it is suicidal\r\n    stls=3\r\n    ticker='NVDA'\r\n    stdate='2015-04-01'\r\n    eddate='2018-02-15'\r\n\r\n    #slicer is used for plotting\r\n    #a three year dataset with 750 data points would be too much\r\n    slicer=700\r\n\r\n    #downloading data\r\n    df=yf.download(ticker,start=stdate,end=eddate)\r\n\r\n    trading_signals=signal_generation(df,heikin_ashi,stls)\r\n\r\n    viz=trading_signals[slicer:]\r\n    plot(viz,ticker)\r\n\r\n    portfolio_details=portfolio(viz)\r\n    profit(portfolio_details)\r\n\r\n    stats(portfolio_details,trading_signals,stdate,eddate)\r\n\r\n    #note that this is the only py file with complete stats calculation\r\n    \r\n    \r\n    \r\nif __name__ == '__main__':\r\n    main()\r\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "London Breakout backtest.py",
          "type": "blob",
          "size": 10.44921875,
          "content": "# coding: utf-8\n\n# In[1]:\n\n#this is to London, the greatest city in the world\n#i was a Londoner, proud of being Londoner, how i love the city!\n#to St Paul, Tate Modern, Millennium Bridge and so much more!\n\n#okay, lets get down to business\n#the idea of london break out strategy is to take advantage of fx trading hour\n#basically fx trading is 24 hour non stop for weekdays\n#u got tokyo, before tokyo closes, u got london\n#in the afternoon, u got new york, when new york closes, its sydney\n#and several hours later, tokyo starts again\n#however, among these three major players\n#london is where the majority trades are executed\n#not sure if it will stay the same after brexit actually takes place\n#what we intend to do is look at the last trading hour before london starts\n#we set up our thresholds based on that hours high and low\n#when london market opens, we examine the first 30 minutes\n#if it goes way above or below thresholds\n#we long or short certain currency pairs\n#and we clear our positions based on target and stop loss we set\n#if they havent reach the trigger condition by the end of trading hour\n#we exit our trades and close all positions\n\n#it sounds easy in practise\n#just a simple prediction of london fx market based on tokyo market\n#but the code of london breakout is extremely time consuming\n#first, we need to get one minute frequency dataset for backtest\n#i would recommend this website\n# http://www.histdata.com/download-free-forex-data/?/excel/1-minute-bar-quotes\n#we can get as many as free datasets of various currency pairs we want\n#before our backtesting, we should cleanse the raw data\n#what we get from the website is one minute frequency bid-ask price\n#i take the average of em and add a header called price\n#i save it on local disk then read it via python\n#please note that this website uses new york time zone utc -5\n#for non summer daylight saving time\n#london market starts at gmt 8 am\n#which is est 3 am\n#daylight saving time is another story\n#what a stupid idea it is\nimport os\nos.chdir('d:/')\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# In[2]:\n\ndef london_breakout(df):\n    \n    df['signals']=0\n\n    #cumsum is the cumulated sum of signals\n    #later we would use it to control our positions\n    df['cumsum']=0\n\n    #upper and lower are our thresholds\n    df['upper']=0.0\n    df['lower']=0.0\n\n    return df\n\n\ndef signal_generation(df,method):\n    \n    #tokyo_price is a list to store average price of\n    #the last trading hour of tokyo market\n    #we use max, min to define the real threshold later\n    tokyo_price=[]\n\n    #risky_stop is a parameter set by us\n    #it is to reduce the risk exposure to volatility\n    #i am using 100 basis points\n    #for instance, we have defined our upper and lower thresholds\n    #however, when london market opens\n    #the price goes skyrocketing \n    #say 200 basis points above upper threshold\n    #i personally wouldnt get in the market as its too risky\n    #also, my stop loss and target is 50 basis points\n    #just half of my risk interval\n    #i will use this variable for later stop loss set up\n    risky_stop=0.01\n\n    #this is another parameter set by us\n    #it is about how long opening volatility would wear off\n    #for me, 30 minutes after the market opening is the boundary\n    #as long as its under 30 minutes after the market opening\n    #if the price reaches threshold level, i will trade on signals\n    open_minutes=30\n\n    #this is the price when we execute a trade\n    #we need to save it to set up the stop loss\n    executed_price=float(0)\n    \n    signals=method(df)\n    signals['date']=pd.to_datetime(signals['date'])\n    \n    #this is the core part\n    #the time complexity for this part is extremely high\n    #as there are too many constraints\n    #if u have a better idea to optimize it\n    #plz let me know\n\n    for i in range(len(signals)):\n        \n        #as mentioned before\n        #the dataset use eastern standard time\n        #so est 2am is the last hour before london starts\n        #we try to append all the price into the list called threshold\n        if signals['date'][i].hour==2:\n            tokyo_price.append(signals['price'][i])\n            \n        #est 3am which is gmt 8am\n        #thats when london market starts\n        #good morning city of london and canary wharf!\n        #right at this moment\n        #we get max and min of the price of tokyo trading hour\n        #we set up the threshold as the way it is\n        #alternatively, we can put 10 basis points above and below thresholds\n        #we also use upper and lower list to keep track of our thresholds\n        #and now we clear the list called threshold\n        elif signals['date'][i].hour==3 and signals['date'][i].minute==0:\n\n            upper=max(tokyo_price)\n            lower=min(tokyo_price)\n\n            signals.at[i,'upper']=upper\n            signals.at[i,'lower']=lower\n\n            tokyo_price=[]\n            \n        #prior to 30 minutes i have mentioned before\n        #as long as its under 30 minutes after market opening\n        #signals will be generated once conditions are met\n        #this is a relatively risky way\n        #alternatively, we can set the signal generation time at a fixed point\n        #when its gmt 8 30 am, we check the conditions to see if there is any signal\n        elif signals['date'][i].hour==3 and signals['date'][i].minute<open_minutes:\n\n            #again, we wanna keep track of thresholds during signal generation periods\n            signals.at[i,'upper']=upper\n            signals.at[i,'lower']=lower\n            \n            #this is the condition of signals generation\n            #when the price is above upper threshold\n            #we set signals to 1 which implies long\n            if signals['price'][i]-upper>0:\n                signals.at[i,'signals']=1\n\n                #we use cumsum to check the cumulated sum of signals\n                #we wanna make sure that\n                #only the first price above upper threshold triggers the signal\n                #also, if it goes skyrocketing\n                #say 200 basis points above, which is 100 above our risk tolerance\n                #we set it as a false alarm\n                signals['cumsum']=signals['signals'].cumsum()\n\n                if signals['price'][i]-upper>risky_stop:\n                    signals.at[i,'signals']=0\n\n                elif signals['cumsum'][i]>1:\n                    signals.at[i,'signals']=0\n\n                else:\n\n                    #we also need to store the price when we execute a trade\n                    #its for stop loss calculation\n                    executed_price=signals['price'][i]\n\n            #vice versa    \n            if signals['price'][i]-lower<0:\n                signals.at[i,'signals']=-1\n\n                signals['cumsum']=signals['signals'].cumsum()\n\n                if lower-signals['price'][i]>risky_stop:\n                    signals.at[i,'signals']=0\n\n                elif signals['cumsum'][i]<-1:\n                    signals.at[i,'signals']=0\n\n                else:\n                    executed_price=signals['price'][i]\n                    \n        #when its gmt 5 pm, london market closes\n        #we use cumsum to see if there is any position left open\n        #we take -cumsum as a signal\n        #if there is no open position, -0 is still 0\n        elif signals['date'][i].hour==12:\n            signals['cumsum']=signals['signals'].cumsum()\n            signals.at[i,'signals']=-signals['cumsum'][i]\n            \n        #during london trading hour after opening but before closing\n        #we still use cumsum to check our open positions\n        #if there is any open position\n        #we set our condition at original executed price +/- half of the risk interval\n        #when it goes above or below our risk tolerance\n        #we clear positions to claim profit or loss\n        else:\n            signals['cumsum']=signals['signals'].cumsum()\n            \n            if signals['cumsum'][i]!=0:\n                if signals['price'][i]>executed_price+risky_stop/2:\n                    signals.at[i,'signals']=-signals['cumsum'][i]\n                    \n                if signals['price'][i]<executed_price-risky_stop/2:\n                    signals.at[i,'signals']=-signals['cumsum'][i]\n    \n    return signals\n\n\n\ndef plot(new):\n    \n    #the first plot is price with LONG/SHORT positions\n    fig=plt.figure()\n    ax=fig.add_subplot(111)\n\n    new['price'].plot(label='price')\n\n    ax.plot(new.loc[new['signals']==1].index,new['price'][new['signals']==1],lw=0,marker='^',c='g',label='LONG')\n    ax.plot(new.loc[new['signals']==-1].index,new['price'][new['signals']==-1],lw=0,marker='v',c='r',label='SHORT')\n      \n    #this is the part where i add some vertical line to indicate market beginning and ending\n    date=new.index[0].strftime('%Y-%m-%d')\n    plt.axvline('%s 03:00:00'%(date),linestyle=':',c='k')\n    plt.axvline('%s 12:00:00'%(date),linestyle=':',c='k')\n\n\n    plt.legend(loc='best')\n    plt.title('London Breakout')\n    plt.ylabel('price')\n    plt.xlabel('Date')\n    plt.grid(True)\n    plt.show()\n\n\n    #lets look at the market opening and break it down into 110 minutes\n    #we wanna observe how the price goes beyond the threshold\n\n    f='%s 02:50:00'%(date)\n    l='%s 03:30:00'%(date)\n    news=signals[f:l]\n    fig=plt.figure()\n    bx=fig.add_subplot(111)\n\n    bx.plot(news.loc[news['signals']==1].index,news['price'][news['signals']==1],lw=0,marker='^',markersize=10,c='g',label='LONG')\n    bx.plot(news.loc[news['signals']==-1].index,news['price'][news['signals']==-1],lw=0,marker='v',markersize=10,c='r',label='SHORT')\n\n    #i only need to plot non zero thresholds\n    #zero is the value outta market opening period \n    bx.plot(news.loc[news['upper']!=0].index,news['upper'][news['upper']!=0],lw=0,marker='.',markersize=7,c='#BC8F8F',label='upper threshold')\n    bx.plot(news.loc[news['lower']!=0].index,news['lower'][news['lower']!=0],lw=0,marker='.',markersize=5,c='#FF4500',label='lower threshold')\n    bx.plot(news['price'],label='price')\n\n\n    plt.grid(True)\n    plt.ylabel('price')\n    plt.xlabel('time interval')\n    plt.xticks([])\n    plt.title('%s Market Opening'%date)\n    plt.legend(loc='best')\n    plt.show()\n    \n    \n# In[3]:\ndef main():\n    \n    df=pd.read_csv('gbpusd.csv')\n\n    signals=signal_generation(df,london_breakout)\n\n    new=signals\n    new.set_index(pd.to_datetime(signals['date']),inplace=True)\n    date=new.index[0].strftime('%Y-%m-%d')\n    new=new['%s'%date]\n\n    plot(new)\n\n#how to calculate stats could be found from my other code called Heikin-Ashi\n# https://github.com/je-suis-tm/quant-trading/blob/master/heikin%20ashi%20backtest.py\n\nif __name__ == '__main__':\n    main()\n"
        },
        {
          "name": "MACD Oscillator backtest.py",
          "type": "blob",
          "size": 3.9853515625,
          "content": "# -*- coding: utf-8 -*-\r\n\"\"\"\r\nCreated on Tue Feb  6 11:57:46 2018\r\n\r\n@author: Administrator\r\n\"\"\"\r\n\r\n# In[1]:\r\n\r\n#need to get fix yahoo finance package first\r\n\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport pandas as pd\r\nimport fix_yahoo_finance as yf\r\n\r\n\r\n\r\n# In[2]:\r\n\r\n#simple moving average\r\ndef macd(signals):\r\n    \r\n    \r\n    signals['ma1']=signals['Close'].rolling(window=ma1,min_periods=1,center=False).mean()\r\n    signals['ma2']=signals['Close'].rolling(window=ma2,min_periods=1,center=False).mean()\r\n    \r\n    return signals\r\n\r\n\r\n\r\n# In[3]:\r\n\r\n#signal generation\r\n#when the short moving average is larger than long moving average, we long and hold\r\n#when the short moving average is smaller than long moving average, we clear positions\r\n#the logic behind this is that the momentum has more impact on short moving average\r\n#we can subtract short moving average from long moving average\r\n#the difference between is sometimes positive, it sometimes becomes negative\r\n#thats why it is named as moving average converge/diverge oscillator\r\ndef signal_generation(df,method):\r\n    \r\n    signals=method(df)\r\n    signals['positions']=0\r\n\r\n    #positions becomes and stays one once the short moving average is above long moving average\r\n    signals['positions'][ma1:]=np.where(signals['ma1'][ma1:]>=signals['ma2'][ma1:],1,0)\r\n\r\n    #as positions only imply the holding\r\n    #we take the difference to generate real trade signal\r\n    signals['signals']=signals['positions'].diff()\r\n\r\n    #oscillator is the difference between two moving average\r\n    #when it is positive, we long, vice versa\r\n    signals['oscillator']=signals['ma1']-signals['ma2']\r\n\r\n    return signals\r\n\r\n\r\n\r\n# In[4]:\r\n\r\n#plotting the backtesting result\r\ndef plot(new, ticker):\r\n    \r\n    #the first plot is the actual close price with long/short positions\r\n    fig=plt.figure()\r\n    ax=fig.add_subplot(111)\r\n    \r\n    new['Close'].plot(label=ticker)\r\n    ax.plot(new.loc[new['signals']==1].index,new['Close'][new['signals']==1],label='LONG',lw=0,marker='^',c='g')\r\n    ax.plot(new.loc[new['signals']==-1].index,new['Close'][new['signals']==-1],label='SHORT',lw=0,marker='v',c='r')\r\n\r\n    plt.legend(loc='best')\r\n    plt.grid(True)\r\n    plt.title('Positions')\r\n    \r\n    plt.show()\r\n    \r\n    #the second plot is long/short moving average with oscillator\r\n    #note that i use bar chart for oscillator\r\n    fig=plt.figure()\r\n    cx=fig.add_subplot(211)\r\n\r\n    new['oscillator'].plot(kind='bar',color='r')\r\n\r\n    plt.legend(loc='best')\r\n    plt.grid(True)\r\n    plt.xticks([])\r\n    plt.xlabel('')\r\n    plt.title('MACD Oscillator')\r\n\r\n    bx=fig.add_subplot(212)\r\n\r\n    new['ma1'].plot(label='ma1')\r\n    new['ma2'].plot(label='ma2',linestyle=':')\r\n    \r\n    plt.legend(loc='best')\r\n    plt.grid(True)\r\n    plt.show()\r\n\r\n    \r\n# In[5]:\r\n\r\ndef main():\r\n    \r\n    #input the long moving average and short moving average period\r\n    #for the classic MACD, it is 12 and 26\r\n    #once a upon a time you got six trading days in a week\r\n    #so it is two week moving average versus one month moving average\r\n    #for now, the ideal choice would be 10 and 21\r\n    \r\n    global ma1,ma2,stdate,eddate,ticker,slicer\r\n\r\n    #macd is easy and effective\r\n    #there is just one issue\r\n    #entry signal is always late\r\n    #watch out for downward EMA spirals!\r\n    ma1=int(input('ma1:'))\r\n    ma2=int(input('ma2:'))\r\n    stdate=input('start date in format yyyy-mm-dd:')\r\n    eddate=input('end date in format yyyy-mm-dd:')\r\n    ticker=input('ticker:')\r\n\r\n    #slicing the downloaded dataset\r\n    #if the dataset is too large, backtesting plot would look messy\r\n    #you get too many markers cluster together\r\n    slicer=int(input('slicing:'))\r\n\r\n    #downloading data\r\n    df=yf.download(ticker,start=stdate,end=eddate)\r\n    \r\n    new=signal_generation(df,macd)\r\n    new=new[slicer:]\r\n    plot(new, ticker)\r\n\r\n\r\n#how to calculate stats could be found from my other code called Heikin-Ashi\r\n# https://github.com/je-suis-tm/quant-trading/blob/master/heikin%20ashi%20backtest.py\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n"
        },
        {
          "name": "Monte Carlo project",
          "type": "tree",
          "content": null
        },
        {
          "name": "Oil Money project",
          "type": "tree",
          "content": null
        },
        {
          "name": "Options Straddle backtest.py",
          "type": "blob",
          "size": 10.888671875,
          "content": "\n# coding: utf-8\n\n# In[1]:\n\n#after a long while of struggle, i finally decided to write something on options strategy\n#the biggest issue of options trading is to find the backtesting data\n#the most difficult part is options greeks\n#after all, data is the new black gold\n#here are a couple of websites u can try your luck\n#currently they offer free trial for a limited period\n# http://base2.optionsdatamine.com/page.php\n# https://www.historicaloptiondata.com/\n#in order to save u guys from the hassle, I also include a small dataset of stoxx 50 index\n#the dataset has 3 spreadsheets, the spot spreadsheet refers to spot price of stoxx 50\n#aug spreadsheet refers to options settle at august 2019\n#jul spreadsheet refers to options settle at july 2019\n# https://github.com/je-suis-tm/quant-trading/tree/master/data\n\n#if you dont know what options straddle is\n#i recommend u to read a tutorial from fidelity\n#who else can explain the concept of options than one of the largest mutual funds\n# https://www.fidelity.com/learning-center/investment-products/options/options-strategy-guide/long-straddle\n#in simple words, options are a financial derivative \n#that enables u to trade underlying asset at certain price in the future\n#and options straddle enable you to profit from a certain level of volatility\n#in this script, we are only gonna talk about long straddle\n#basically long straddle implies buy call option and put option of same strike price and same strike date\n#preferably at the same option price as well\n#otherwise asymmetric option price means there is more one-sided risk than the other\n#you may wanna consider strangle or strap/strip in this case\n#short straddle is literally shorting call option and put option of the same strike price and the same strike date\n#preferably at the same option price as well\n#long straddle has unlimited profit for upside movement and limited loss\n#short straddle has unlimited loss for upside movement and limited profit\n#short straddle is commonly used in a sideway market\n#long straddle is commonly used in event driven strategy\n\n#for instance, brexit on 30th of October 2019, its do or die, no ifs and buts\n#if bojo delivers a no-deal Brexit, uk sterling gonna sink\n#or he secures a new deal without backstop from macron and merkel\n#even though unlikely, uk sterling gonna spike\n#or he has to postpone and look like an idiot, uk sterling still gonna surge\n#either way, there will be a lot of volatility around that particular date\n#to secure a profit from either direction, that is when options straddle kick in\n\n#but hey, options are 3 dimensional\n#apart from strike date, option price, which strike price should we pick\n#well, that is a one million us dollar question\n#who says quantitative trading is about algos and calculus?\n#this is when u need to consult with some economists to get a base case\n#their fundamental analysis will determine your best/worst scenario\n#therefore, u can pick a good strike price to maximize your profit\n#or the simplest way is to find a strike price closer to the current spot price\n\n#nevertheless, as u can see in our stoxx 50 dataset\n#not all strike price offer both call and put options\n#and even if they offer both, the price of options may be very different\n#there could be more upside/downside from the market consensus\n#we can pick the options which offer both call and put options\n#and we only trade when both option prices are converging\n#and please don’t arrogantly believe that you outsmart the rest of the players in the market\n#all the information you have obtained from any tips may have already been priced in\n#finding a good pair of call and put options at the same strike price,\n#the same strike date and almost the same price is tough\n\n#to make our life easier, we only consider european options with cash settlement in this script\n\nimport os\nos.chdir('d:/')\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport re\n\n\n# In[2]:\n\n#as we have gathered all the available call and put options\n#this function will only extract strike price existing in both call and put options\n#this is a fundamental requirement of options straddle\n\ndef find_strike_price(df):\n    \n    temp=[re.search('\\d{4}',i).group() for i in df.columns]\n    target=[]\n\n    for i in set(temp):\n        if temp.count(i)>1:\n            target.append(i)\n            \n    return target\n\n\n\n# In[3]:\n\n#this function is merely data cleansing\n#merging option price information with spot price\n\ndef straddle(options,spot,contractsize,strikeprice):\n        \n    option=options[[i for i in options.columns if strikeprice in i]] \n    \n    df=pd.merge(spot,option,left_index=True,right_index=True)\n\n    temp=[]\n    for i in df.columns:\n        if 'C'+strikeprice in i:\n            temp.append('call')\n        elif 'P'+strikeprice in i:\n            temp.append('put')\n        elif 'Index' in i:\n            temp.append('spot')\n        else:\n            temp.append(i)\n\n    df.columns=temp\n    \n    #we multiply contract size with spot price here\n    #it makes our life a lot easier later with visualization\n\n    df['spot']=df['spot'].apply(lambda x:x*contractsize)\n    \n    return df\n\n\n\n# In[4]:\n\n#signal generation is actually very simple\n#just find the option pair at the closest price we can\n\ndef signal_generation(df,threshold):\n    \n    df['signals']=np.where(\n        np.abs(\n            df['call']-df['put'])<threshold,\n        1,0)  \n\n    return df\n\n\n# In[5]:\n\n#ploting the payoff diagram\ndef plot(df,strikeprice,contractsize):\n    \n    #finding trading signal\n    #if no signal is found\n    #we declare no suitable entry point for options straddle\n    \n    ind=df[df['signals']!=0].index\n\n    if ind.empty:\n        print('Strike Price at',strikeprice,'\\nNo trades available.\\n')\n        return \n    \n    #calculate how much profit we can gain outta this\n    \n    profit=np.abs(\n        df['spot'].iloc[-1]-int(strikeprice)*contractsize\n    )-df['call'][ind[0]]-df['put'][ind[0]]\n\n    y=[]\n    \n    #we use these two variables to plot how much we can profit at different spot price\n    \n    begin=round(int(strikeprice)*contractsize-5*(df['call'][ind[0]]+df['put'][ind[0]]),0)\n    end=round(int(strikeprice)*contractsize+5*(df['call'][ind[0]]+df['put'][ind[0]]),0)+1\n    \n    x=list(np.arange(int(begin),int(end)))\n    \n    #as u can see from the pic\n    # https://github.com/je-suis-tm/quant-trading/blob/master/preview/options%20straddle%20payoff%20diagram.png\n    #we only make money (green color) if the spot price is outside of a range\n    #group1 and group2 are variables that indicate which range our line plot gets red/green color\n    #they keep track of the indices that we switch from profit to loss or from loss to profit\n    #as indices are always positive, we initialize them to negative values\n\n    group1,group2=-10,-10\n    for j in x:\n        temp=np.abs(j-int(strikeprice)*contractsize)-(df['call'][ind[0]]+df['put'][ind[0]])\n        y.append(temp)\n        if temp<0 and group1<0:\n            group1=x.index(j)\n        if temp>0 and group1>0 and group2<0:\n            group2=x.index(j)\n        \n\n    ax=plt.figure(figsize=(10,5)).add_subplot(111)\n    ax.spines['bottom'].set_position(('data',0))\n    ax.spines['right'].set_visible(False)\n    ax.spines['top'].set_visible(False)\n    \n    #pnl in different colors, red is loss, green is profit\n    \n    plt.plot(x[:group1],y[:group1],c='#57bc90',lw=5)\n    plt.plot(x[group2:],y[group2:],c='#57bc90',lw=5)\n    plt.plot(x[group1:group2],y[group1:group2],c='#ec576b',lw=5)\n    \n    #ploting strike price\n    \n    plt.plot([int(strikeprice)*contractsize,\n              int(strikeprice)*contractsize],\n              [0,-(df['call'][ind[0]]+df['put'][ind[0]])],\n              linestyle=':',lw=3,c='#ec576b',alpha=0.5)\n    \n    #ploting spot price\n    \n    plt.axvline(df['spot'].iloc[-1],lw=5,\n                linestyle='--',c='#e5e338',alpha=0.5)\n    \n    #adding annotations\n    \n    plt.annotate('Strike Price',\n                 xy=(int(strikeprice)*contractsize,\n                     0),\n                 xytext=(int(strikeprice)*contractsize,\n                     df['call'][ind[0]]+df['put'][ind[0]]),\n                 arrowprops=dict(arrowstyle='simple',\n                                 facecolor='#c5c1c0',),\n                 va='center',ha='center'\n                 )\n \n    plt.annotate('Lower Breakeven Point',\n                 xy=(int(strikeprice)*contractsize-(df['call'][ind[0]]+df['put'][ind[0]]),\n                     0),\n                 xytext=(int(strikeprice)*contractsize-1.5*(df['call'][ind[0]]+df['put'][ind[0]]),\n                         -df['call'][ind[0]]-df['put'][ind[0]]),\n                 arrowprops=dict(arrowstyle='simple',\n                                 facecolor='#c5c1c0'),\n                 va='center',ha='center'\n                 )\n \n    plt.annotate('Upper Breakeven Point',\n                 xy=(int(strikeprice)*contractsize+(df['call'][ind[0]]+df['put'][ind[0]]),\n                     0),\n                 xytext=(int(strikeprice)*contractsize+1.5*(df['call'][ind[0]]+df['put'][ind[0]]),\n                         -df['call'][ind[0]]-df['put'][ind[0]]),\n                 arrowprops=dict(arrowstyle='simple',\n                                 facecolor='#c5c1c0'),\n                 va='center',ha='center'\n                 )\n\n    plt.annotate('Spot Price',\n                 xy=(df['spot'].iloc[-1],\n                     2*(df['call'][ind[0]]+df['put'][ind[0]])),\n                 xytext=(df['spot'].iloc[-1]*1.003,\n                         2*(df['call'][ind[0]]+df['put'][ind[0]])),\n                 arrowprops=dict(arrowstyle='simple',\n                                 facecolor='#c5c1c0'),\n                 va='center',ha='left'\n                 )\n    \n    #limit x ticks to 3 for a tidy look\n    \n    plt.locator_params(axis='x',nbins=3)\n    \n    plt.title(f'Long Straddle Options Strategy\\nP&L {round(profit,2)}')\n    plt.ylabel('Profit & Loss')\n    plt.xlabel('Price',labelpad=50)\n    plt.show()\n\n\n# In[6]:\n\n#for stoxx 50 options, the contract size is 10 ticks per euro\n\ncontractsize=10\n\n#the threshold determines the price disparity between call and put options\n#the same call and put option price for the same strike price and the same strike date\n#only exists in an ideal world, in reality, it is like royal flush\n#when the price difference of call and put is smaller than 2 euros\n#we consider them identically the same option price\n\nthreshold=2\n\n\n# In[7]:\n\ndef main():\n    \n    data=pd.ExcelFile('stoxx50.xlsx')\n    \n    aug=data.parse('aug')\n    aug.set_index('Dates',inplace=True)\n    aug.index=pd.to_datetime(aug.index)\n    \n    spot=data.parse('spot')\n    spot.set_index('Dates',inplace=True)\n    spot.index=pd.to_datetime(spot.index)\n    \n    target=find_strike_price(aug)\n    \n    #we iterate through all the available option pairs\n    #to find the optimal strike price to maximize our profit\n    \n    for strikeprice in target:\n      \n        df=straddle(aug,spot,contractsize,strikeprice)\n        \n        signal=signal_generation(df,threshold)\n        \n        plot(signal,strikeprice,contractsize)\n\n\n# In[8]:\n\n\nif __name__ == '__main__':\n    main()\n\n\n"
        },
        {
          "name": "Ore Money project",
          "type": "tree",
          "content": null
        },
        {
          "name": "Pair trading backtest.py",
          "type": "blob",
          "size": 12.2490234375,
          "content": "# -*- coding: utf-8 -*-\r\n\"\"\"\r\nCreated on Tue Feb  6 11:57:46 2018\r\n\r\n@author: Administrator\r\n\"\"\"\r\n\r\n\r\n# In[1]:\r\n\r\n\r\n#grazie a my mentor Prof Giampiero M Gallo\r\n#ex-professor in statistics currently a governor in Italy\r\n#neither Lega Nord nor Movimento 5 Stelle but Partito Democratico\r\n#and his mentor Robert Engle, the nobel laureate!\r\n#for their tremendous contributions to VECM\r\n\r\n\r\n# In[2]:\r\n\r\n\r\n#pair trading is also called mean reversion trading\r\n#we find two cointegrated assets, normally a stock and an ETF index\r\n#or two stocks in the same industry or any pair that passes the test\r\n#we run an cointegration test on the historical data\r\n#we set the trigger condition for both stocks\r\n#theoretically these two stocks cannot drift too far from each other\r\n#its like a drunk man with a dog\r\n#the invisible dog leash would keep both assets in check\r\n#when one stock is getting too bullish\r\n#we short the bullish one and long the bearish one, vice versa\r\n#sooner or later, the dog would converge to the drunk man\r\n#nevertheless, the backtest is based on historical datasets\r\n#in real stock market, market conditions are dynamic\r\n#two assets may seem cointegrated for the past two years\r\n#they can completely diverge after one company launch a new product or whatsoever\r\n#i am talking about nvidia and amd, two gpu companies\r\n#after bitcoin mining boom and machine learning hype\r\n#stock price of nvidia went skyrocketing\r\n#on the contrary amd didnt change much \r\n#the cointegrated relationship just broke up\r\n#so be extremely cautious with cointegration\r\n#there is no such thing as riskless statistical arbitrage\r\n#always check the cointegration status before trading execution\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport pandas as pd\r\nimport yfinance as yf\r\nimport statsmodels.api as sm\r\n\r\n\r\n# In[3]:\r\n\r\n\r\n#use Engle-Granger two-step method to test cointegration\r\n#the underlying method is straight forward and easy to implement\r\n#a more important thing is the method is invented by the mentor of my mentor!!!\r\n#the latest statsmodels package should ve included johansen test which is more common\r\n#check sm.tsa.var.vecm.coint_johansen\r\n#the malaise of two-step is the order of the cointegration\r\n#unlike johansen test, two-step method can only detect the first order\r\n#check the following material for further details\r\n# https://warwick.ac.uk/fac/soc/economics/staff/gboero/personal/hand2_cointeg.pdf\r\ndef EG_method(X,Y,show_summary=False):\r\n    \r\n    #step 1\r\n    #estimate long run equilibrium\r\n    model1=sm.OLS(Y,sm.add_constant(X)).fit()\r\n    epsilon=model1.resid\r\n    \r\n    if show_summary:\r\n        print('\\nStep 1\\n')\r\n        print(model1.summary())\r\n    \r\n    #check p value of augmented dickey fuller test\r\n    #if p value is no larger than 5%, stationary test is passed\r\n    if sm.tsa.stattools.adfuller(epsilon)[1]>0.05:\r\n        return False,model1\r\n    \r\n    #take first order difference of X and Y plus the lagged residual from step 1\r\n    X_dif=sm.add_constant(pd.concat([X.diff(),epsilon.shift(1)],axis=1).dropna())\r\n    Y_dif=Y.diff().dropna()        \r\n    \r\n    #step 2\r\n    #estimate error correction model\r\n    model2=sm.OLS(Y_dif,X_dif).fit()\r\n    \r\n    if show_summary:\r\n        print('\\nStep 2\\n')\r\n        print(model2.summary())\r\n    \r\n    #adjustment coefficient must be negative\r\n    if list(model2.params)[-1]>0:\r\n        return False,model1\r\n    else:\r\n        return True,model1\r\n\r\n\r\n# In[4]:\r\n\r\n\r\n#first we verify the status of cointegration by checking historical datasets\r\n#bandwidth determines the number of data points for consideration\r\n#bandwidth is 250 by default, around one year's data points\r\n#if the status is valid, we check the signals\r\n#when z stat gets above the upper bound\r\n#we long the bearish one and short the bullish one, vice versa\r\ndef signal_generation(asset1,asset2,method,bandwidth=250):    \r\n    \r\n    signals=pd.DataFrame()\r\n    signals['asset1']=asset1['Close']\r\n    signals['asset2']=asset2['Close']\r\n    \r\n    #signals only imply holding\r\n    signals['signals1']=0    \r\n    signals['signals2']=0\r\n    \r\n    #initialize\r\n    prev_status=False\r\n    signals['z']=np.nan\r\n    signals['z upper limit']=np.nan\r\n    signals['z lower limit']=np.nan\r\n    signals['fitted']=np.nan    \r\n    signals['residual']=np.nan\r\n    \r\n    #signal processing\r\n    for i in range(bandwidth,len(signals)):\r\n        \r\n        #cointegration test\r\n        coint_status,model=method(signals['asset1'].iloc[i-bandwidth:i],\r\n                                  signals['asset2'].iloc[i-bandwidth:i])\r\n                \r\n        #cointegration breaks\r\n        #clear existing positions\r\n        if prev_status and not coint_status:           \r\n            if signals.at[signals.index[i-1],'signals1']!=0:\r\n                signals.at[signals.index[i],'signals1']=0\r\n                signals.at[signals.index[i],'signals2']=0\r\n                signals['z'].iloc[i:]=np.nan\r\n                signals['z upper limit'].iloc[i:]=np.nan\r\n                signals['z lower limit'].iloc[i:]=np.nan\r\n                signals['fitted'].iloc[i:]=np.nan    \r\n                signals['residual'].iloc[i:]=np.nan\r\n        \r\n        #cointegration starts\r\n        #set the trigger conditions\r\n        #this is no forward bias\r\n        #just to minimize the calculation done in pandas\r\n        if not prev_status and coint_status:\r\n            \r\n            #predict the price to compute the residual       \r\n            signals['fitted'].iloc[i:]=model.predict(sm.add_constant(signals['asset1'].iloc[i:]))\r\n            signals['residual'].iloc[i:]=signals['asset2'].iloc[i:]-signals['fitted'].iloc[i:]\r\n            \r\n            #normalize the residual to get z stat\r\n            #z should be a white noise following N(0,1)\r\n            signals['z'].iloc[i:]=(signals['residual'].iloc[i:]-np.mean(model.resid))/np.std(model.resid)\r\n                        \r\n            #create thresholds\r\n            #conventionally one sigma is the threshold\r\n            #two sigma reaches 95% which is relatively difficult to trigger\r\n            signals['z upper limit'].iloc[i:]=signals['z'].iloc[i]+np.std(model.resid)\r\n            signals['z lower limit'].iloc[i:]=signals['z'].iloc[i]-np.std(model.resid)\r\n        \r\n        #as z stat cannot exceed both upper and lower bounds at the same time\r\n        #the lines below hold\r\n        if coint_status and signals['z'].iloc[i]>signals['z upper limit'].iloc[i]:            \r\n             signals.at[signals.index[i],'signals1']=1            \r\n        if coint_status and signals['z'].iloc[i]<signals['z lower limit'].iloc[i]:            \r\n             signals.at[signals.index[i],'signals1']=-1\r\n                \r\n        prev_status=coint_status    \r\n    \r\n    #signals only imply holding\r\n    #we take the first order difference to obtain the execution signal\r\n    signals['positions1']=signals['signals1'].diff()\r\n    \r\n    #only need to generate trading signal of one asset\r\n    #the other one should be the opposite direction\r\n    signals['signals2']=-signals['signals1']\r\n    signals['positions2']=signals['signals2'].diff()   \r\n    \r\n    return signals\r\n\r\n\r\n# In[5]:\r\n\r\n\r\n#position visualization\r\ndef plot(data,ticker1,ticker2):    \r\n   \r\n    fig=plt.figure(figsize=(10,5))\r\n    bx=fig.add_subplot(111)   \r\n    bx2=bx.twinx()\r\n    \r\n    #viz two different assets\r\n    asset1_price,=bx.plot(data.index,data['asset1'],\r\n                          c='#113aac',alpha=0.7)\r\n    asset2_price,=bx2.plot(data.index,data['asset2'],\r\n                          c='#907163',alpha=0.7)\r\n\r\n    #viz positions\r\n    asset1_long,=bx.plot(data.loc[data['positions1']==1].index,\r\n                data['asset1'][data['positions1']==1],\r\n                lw=0,marker='^',markersize=8,\r\n                c='g',alpha=0.7)\r\n    asset1_short,=bx.plot(data.loc[data['positions1']==-1].index,\r\n                data['asset1'][data['positions1']==-1],\r\n                lw=0,marker='v',markersize=8,\r\n                c='r',alpha=0.7)\r\n    asset2_long,=bx2.plot(data.loc[data['positions2']==1].index,\r\n                 data['asset2'][data['positions2']==1],\r\n                 lw=0,marker='^',markersize=8,\r\n                 c='g',alpha=0.7)\r\n    asset2_short,=bx2.plot(data.loc[data['positions2']==-1].index,\r\n                 data['asset2'][data['positions2']==-1],\r\n                 lw=0,marker='v',markersize=8,\r\n                 c='r',alpha=0.7)\r\n\r\n    #set labels\r\n    bx.set_ylabel(ticker1,)\r\n    bx2.set_ylabel(ticker2,rotation=270)\r\n    bx.yaxis.labelpad=15\r\n    bx2.yaxis.labelpad=15\r\n    bx.set_xlabel('Date')\r\n    bx.xaxis.labelpad=15\r\n\r\n    plt.legend([asset1_price,asset2_price,asset1_long,asset1_short],\r\n               [ticker1,ticker2,\r\n               'LONG','SHORT'],\r\n               loc='lower left')\r\n\r\n    plt.title('Pair Trading')\r\n    plt.xlabel('Date')\r\n    plt.grid(True)\r\n    plt.show()\r\n  \r\n\r\n\r\n# In[6]:\r\n\r\n\r\n#visualize overall portfolio performance\r\ndef portfolio(data):\r\n\r\n    #initial capital to calculate the actual pnl\r\n    capital0=20000\r\n\r\n    #shares to buy of each position\r\n    #this is no forward bias\r\n    #just ensure we have enough €€€ to purchase shares when the price peaks\r\n    positions1=capital0//max(data['asset1'])\r\n    positions2=capital0//max(data['asset2'])\r\n\r\n    #cumsum1 column is created to check the holding of the position\r\n    data['cumsum1']=data['positions1'].cumsum()\r\n\r\n    #since there are two assets, we calculate each asset separately\r\n    #in the end we aggregate them into one portfolio\r\n    portfolio=pd.DataFrame()\r\n    portfolio['asset1']=data['asset1']\r\n    portfolio['holdings1']=data['cumsum1']*data['asset1']*positions1\r\n    portfolio['cash1']=capital0-(data['positions1']*data['asset1']*positions1).cumsum()\r\n    portfolio['total asset1']=portfolio['holdings1']+portfolio['cash1']\r\n    portfolio['return1']=portfolio['total asset1'].pct_change()\r\n    portfolio['positions1']=data['positions1']\r\n    \r\n    data['cumsum2']=data['positions2'].cumsum()\r\n    portfolio['asset2']=data['asset2']\r\n    portfolio['holdings2']=data['cumsum2']*data['asset2']*positions2\r\n    portfolio['cash2']=capital0-(data['positions2']*data['asset2']*positions2).cumsum()\r\n    portfolio['total asset2']=portfolio['holdings2']+portfolio['cash2']\r\n    portfolio['return2']=portfolio['total asset2'].pct_change()\r\n    portfolio['positions2']=data['positions2']\r\n \r\n    portfolio['z']=data['z']\r\n    portfolio['total asset']=portfolio['total asset1']+portfolio['total asset2']\r\n    portfolio['z upper limit']=data['z upper limit']\r\n    portfolio['z lower limit']=data['z lower limit']\r\n    \r\n    #plotting the asset value change of the portfolio\r\n    fig=plt.figure(figsize=(10,5))\r\n    ax=fig.add_subplot(111)\r\n    ax2=ax.twinx()\r\n \r\n    total_asset_performance,=ax.plot(portfolio['total asset'],c='#46344e')\r\n    z_stats,=ax2.plot(portfolio['z'],c='#4f4a41',alpha=0.2)\r\n \r\n    threshold=ax2.fill_between(portfolio.index,portfolio['z upper limit'],\r\n                       portfolio['z lower limit'],\r\n                       alpha=0.2,color='#ffb48f')\r\n     \r\n    #due to the opposite direction of trade for 2 assets\r\n    #we will not plot positions on asset performance    \r\n    ax.set_ylabel('Asset Value')\r\n    ax2.set_ylabel('Z Statistics',rotation=270)\r\n    ax.yaxis.labelpad=15\r\n    ax2.yaxis.labelpad=15\r\n    ax.set_xlabel('Date')\r\n    ax.xaxis.labelpad=15\r\n    \r\n    plt.legend([z_stats,threshold,total_asset_performance],\r\n               ['Z Statistics', 'Z Statistics +-1 Sigma',\r\n                'Total Asset Performance'],loc='best')\r\n\r\n    plt.grid(True)   \r\n    plt.title('Total Asset')\r\n    plt.show()\r\n\r\n    return portfolio\r\n\r\n\r\n# In[7]:\r\n\r\n\r\ndef main():\r\n    \r\n    #the sample i am using are NVDA and AMD from 2013 to 2014\r\n    stdate='2013-01-01'\r\n    eddate='2014-12-31'\r\n    ticker1='NVDA'\r\n    ticker2='AMD'\r\n\r\n    #extract data\r\n    asset1=yf.download(ticker1,start=stdate,end=eddate)\r\n    asset2=yf.download(ticker2,start=stdate,end=eddate)  \r\n\r\n    #create signals\r\n    signals=signal_generation(asset1,asset2,EG_method)\r\n\r\n    #only viz the part where trading signals occur\r\n    ind=signals['z'].dropna().index[0]\r\n\r\n    #viz positions\r\n    plot(signals[ind:],ticker1,ticker2)    \r\n\r\n    #viz portfolio performance\r\n    portfolio_details=portfolio(signals[ind:])\r\n    \r\n    #the performance metrics of investment could be found in another strategy called Heikin-Ashi\r\n    # https://github.com/je-suis-tm/quant-trading/blob/master/heikin%20ashi%20backtest.py\r\n\r\n\r\n# In[8]:\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n\r\n"
        },
        {
          "name": "Parabolic SAR backtest.py",
          "type": "blob",
          "size": 4.619140625,
          "content": "# coding: utf-8\n\n# In[1]:\n\n\n#parabolic stop and reverse is very useful for trend following\n#sar is an indicator below the price when its an uptrend \n#and above the price when its a downtrend\n#it is very painful to calculate sar, though\n#and many explanations online including wiki cannot clearly explain the process\n#hence, the good idea would be to read info on wikipedia\n#and download an excel spreadsheet made by joeu2004\n#formulas are always more straight forward than descriptions\n#links are shown below\n# https://en.wikipedia.org/wiki/Parabolic_SAR\n# https://www.box.com/s/gbtrjuoktgyag56j6lv0\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport fix_yahoo_finance as yf\nimport pandas as pd\n\n\n# In[2]:\n\n#the calculation of sar\n#as rules are very complicated\n#plz check the links above to understand more about it\n\ndef parabolic_sar(new):\n    \n    #this is common accelerating factors for forex and commodity\n    #for equity, af for each step could be set to 0.01\n    initial_af=0.02\n    step_af=0.02\n    end_af=0.2\n    \n    \n    new['trend']=0\n    new['sar']=0.0\n    new['real sar']=0.0\n    new['ep']=0.0\n    new['af']=0.0\n\n    #initial values for recursive calculation\n    new['trend'][1]=1 if new['Close'][1]>new['Close'][0] else -1\n    new['sar'][1]=new['High'][0] if new['trend'][1]>0 else new['Low'][0]\n    new.at[1,'real sar']=new['sar'][1]\n    new['ep'][1]=new['High'][1] if new['trend'][1]>0 else new['Low'][1]\n    new['af'][1]=initial_af\n\n    #calculation\n    for i in range(2,len(new)):\n        \n        temp=new['sar'][i-1]+new['af'][i-1]*(new['ep'][i-1]-new['sar'][i-1])\n        if new['trend'][i-1]<0:\n            new.at[i,'sar']=max(temp,new['High'][i-1],new['High'][i-2])\n            temp=1 if new['sar'][i]<new['High'][i] else new['trend'][i-1]-1\n        else:\n            new.at[i,'sar']=min(temp,new['Low'][i-1],new['Low'][i-2])\n            temp=-1 if new['sar'][i]>new['Low'][i] else new['trend'][i-1]+1\n        new.at[i,'trend']=temp\n    \n        \n        if new['trend'][i]<0:\n            temp=min(new['Low'][i],new['ep'][i-1]) if new['trend'][i]!=-1 else new['Low'][i]\n        else:\n            temp=max(new['High'][i],new['ep'][i-1]) if new['trend'][i]!=1 else new['High'][i]\n        new.at[i,'ep']=temp\n    \n    \n        if np.abs(new['trend'][i])==1:\n            temp=new['ep'][i-1]\n            new.at[i,'af']=initial_af\n        else:\n            temp=new['sar'][i]\n            if new['ep'][i]==new['ep'][i-1]:\n                new.at[i,'af']=new['af'][i-1]\n            else:\n                new.at[i,'af']=min(end_af,new['af'][i-1]+step_af)\n        new.at[i,'real sar']=temp\n       \n        \n    return new\n\n# In[3]:\n\n#generating signals\n#idea is the same as macd oscillator\n#check the website below to learn more\n# https://github.com/je-suis-tm/quant-trading/blob/master/MACD%20oscillator%20backtest.py\n\ndef signal_generation(df,method):\n    \n        new=method(df)\n\n        new['positions'],new['signals']=0,0\n        new['positions']=np.where(new['real sar']<new['Close'],1,0)\n        new['signals']=new['positions'].diff()\n        \n        return new\n\n    \n\n\n\n# In[4]:\n\n#plotting of sar and trading positions\n#still similar to macd\n\ndef plot(new,ticker):\n    \n    fig=plt.figure()\n    ax=fig.add_subplot(111)\n    \n    new['Close'].plot(lw=3,label='%s'%ticker)\n    new['real sar'].plot(linestyle=':',label='Parabolic SAR',color='k')\n    ax.plot(new.loc[new['signals']==1].index,new['Close'][new['signals']==1],marker='^',color='g',label='LONG',lw=0,markersize=10)\n    ax.plot(new.loc[new['signals']==-1].index,new['Close'][new['signals']==-1],marker='v',color='r',label='SHORT',lw=0,markersize=10)\n    \n    plt.legend()\n    plt.grid(True)\n    plt.title('Parabolic SAR')\n    plt.ylabel('price')\n    plt.show()\n\n\n# In[5]:\n\ndef main():\n    \n    #download data via fix yahoo finance library\n    stdate=('2016-01-01')\n    eddate=('2018-01-01')\n    ticker=('EA')\n\n    #slice is used for plotting\n    #a two year dataset with 500 variables would be too much for a figure\n    slicer=450\n\n    df=yf.download(ticker,start=stdate,end=eddate)\n    \n    #delete adj close and volume\n    #as we dont need them\n    del df['Adj Close']\n    del df['Volume']\n\n    #no need to iterate over timestamp index\n    df.reset_index(inplace=True)\n\n    new=signal_generation(df,parabolic_sar)\n\n    #convert back to time series for plotting\n    #so that we get a date x axis\n    new.set_index(new['date'],inplace=True)\n\n    #shorten our plotting horizon and plot\n    new=new[slicer:]\n    plot(new,ticker) \n\n#how to calculate stats could be found from my other code called Heikin-Ashi\n# https://github.com/je-suis-tm/quant-trading/blob/master/heikin%20ashi%20backtest.py\n\n\n# In[6]:\n\nif __name__ == '__main__':\n    main()\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 30.81640625,
          "content": "# Quant-trading\n\n&nbsp;\n\n## Intro\n\n&nbsp;\n\n> We’re right 50.75 percent of the time... but we’re 100 percent right 50.75 percent of the time, you can make billions that way. <br><br>\n> --- Robert Mercer, co-CEO of Renaissance Technologies\n\n> If you trade a lot, you only need to be right 51 percent of the time, we need a smaller edge on each trade. <br><br>\n> --- Elwyn Berlekamp, co-Founder of Combinatorial Game Theory\n\n###### *The quotes above come from a book by Gregory Zuckerman, a book every quant must read, THE MAN WHO SOLVED THE MARKET.*\n\n&nbsp;\n\nMost scripts inside this repository are technical indicator automated trading. These scripts include various types of momentum trading, opening range breakout, reversal of support & resistance and statistical arbitrage strategies. Yet, quantitative trading is not only about technical analysis. It can refer to computational finance to exploit derivative price mismatch, pattern recognition on alternative datasets to generate alphas or low latency order execution in the market microstructure. Hence, there are a few ongoing projects inside this repository. These projects are mostly quantamental analysis on some strange ideas I come up with to beat the market (or so I thought). There is no HFT strategy simply because ultra high frequency data are very expensive to acquire (even consider platforms like Quantopian or Quandl). Additionally, please note that, all scripts are historical data backtesting/forward testing (basically via Python, not C++, maybe Julia in the near future). The assumption is that all trades are frictionless. No slippage, no surcharge, no illiquidity. Last but not least, all scripts contain a global function named main so that you can embed the scripts directly into you trading system (although too lazy to write docstring).\n\n### Table of Contents\n\n&nbsp;\n\n#### Options Strategy\n\n* <a href=https://github.com/je-suis-tm/quant-trading#12-options-straddle>Options Straddle</a>\n* <a href=https://github.com/je-suis-tm/quant-trading#15-vix-calculator>VIX Calculator</a>\n\n&nbsp;\n\n#### Quantamental Analysis\n\n* <a href=https://github.com/je-suis-tm/quant-trading#11-monte-carlo-project>Monte Carlo Project</a>\n\n* <a href=https://github.com/je-suis-tm/quant-trading#6-oil-money-project>Oil Money Project</a>\n\n* <a href=https://github.com/je-suis-tm/quant-trading#2-pair-trading>Pair Trading</a> \n\n* <a href=https://github.com/je-suis-tm/quant-trading#13-portfolio-optimization-project>Portfolio Optimization Project</a>\n\n* <a href=https://github.com/je-suis-tm/quant-trading#14-smart-farmers-project>Smart Farmers Project</a>\n\n* <a href=https://github.com/je-suis-tm/quant-trading#16-wisdom-of-crowds-project>Wisdom of Crowd Project</a>\n\n&nbsp;\n\n#### Technical Indicators\n\n* <a href=https://github.com/je-suis-tm/quant-trading#5-awesome-oscillator>Awesome Oscillator</a> \n\n* <a href=https://github.com/je-suis-tm/quant-trading#9-bollinger-bands-pattern-recognition>Bollinger Bands Pattern Recognition</a> \n\n* <a href=https://github.com/je-suis-tm/quant-trading#7-dual-thrust>Dual Thrust</a> \n\n* <a href=https://github.com/je-suis-tm/quant-trading#3-heikin-ashi-candlestick>Heikin-Ashi Candlestick</a> \n\n* <a href=https://github.com/je-suis-tm/quant-trading#4-london-breakout>London Breakout</a> \n\n* <a href=https://github.com/je-suis-tm/quant-trading#1-macd-oscillator>MACD Oscillator</a> \n\n* <a href=https://github.com/je-suis-tm/quant-trading#8-parabolic-sar>Parabolic SAR</a> \n\n* <a href=https://github.com/je-suis-tm/quant-trading#10-relative-strength-index-pattern-recognition>Relative Strength Index Pattern Recognition</a>\n\n* <a href=https://github.com/je-suis-tm/quant-trading#17-shooting-star>Shooting Star</a>\n\n&nbsp;\n\n### Data Source\n\n* Bloomberg/Eikon\n\n* <a href=https://github.com/je-suis-tm/web-scraping/blob/master/CME3.py>CME</a>/<a href=https://github.com/je-suis-tm/web-scraping/blob/master/LME.py>LME</a>\n\n* <a href=https://www.histdata.com/>Histdata</a>/<a href=https://fxhistoricaldata.com>FX Historical Data</a>\n\n* <a href=https://github.com/je-suis-tm/web-scraping/blob/master/Macrotrends.py>Macrotrends</a>\n\n* <a href=https://stooq.com>Stooq</a>/<a href=https://www.quandl.com>Quandl</a>\n\n* <a href=https://github.com/je-suis-tm/web-scraping/blob/master/WallStreetBets.py>Reddit WallStreetBets</a>\n\n* <a href=https://github.com/je-suis-tm/web-scraping>Web Scraping</a>\n\n* <a href=https://finance.yahoo.com>Yahoo Finance</a>/<a href=https://pypi.org/project/fix-yahoo-finance>fix_yahoo_finance package</a>/<a href=https://pypi.org/project/yfinance>yfinance package</a> \n\n<br>\n\n## Strategies:\n\n### 1. MACD oscillator\n\nMACD oscillator is trading strategy 101. MACD refers to Moving Average Convergence/Divergence. It is a momentum trading strategy which holds the belief that upward/downward momentum has more impact on short term moving average than long term moving average. It only takes 5 minutes for any bloke with no background in finance to trade with MACD signals. Regarding the simplicity of MACD oscillator, it is the most common strategy among the non-professionals in the market. In behavioral economics, the more people believe in the strategy, the more effective the strategy becomes (not always true, e.g. 2008). Therefore, we should not underestimate the power of MACD oscillator.\n\nFor the strategy itself, we compute long term moving average and short term moving average on the close price of a given stock. To generate the trading signal, we implement a comparison between the moving averages of different time horizons. When short term moving average is above long term moving average, we long the given stock accordingly. Vice versa.\n\n*Click <a href=https://github.com/je-suis-tm/quant-trading/blob/master/MACD%20Oscillator%20backtest.py>here</a> to be redirected to the script.*\n\n![alt text](https://github.com/je-suis-tm/quant-trading/blob/master/preview/macd%20positions.png)\n\n![alt text](https://github.com/je-suis-tm/quant-trading/blob/master/preview/macd%20oscillator.png)\n\n### 2. Pair trading\n\nPair trading is the basic form of statistics arbitrage. It relies on the assumption that two cointegrated stocks would not drift too far away from each other. First step, we select two stocks and run <a href=https://en.wikipedia.org/wiki/Error_correction_model#Engle_and_Granger_2-step_approach>Engle-Granger two step analysis</a>. Once the criteria of cointegration is met, we standardize the residual and set one sigma away (two tailed) as the threshold. After that, we compute the current standardized residual of the selected stocks accordingly. When the standardized residual exceeds the threshold, it generates the trading signal. The simple rule is we always long the cheap stock and short the expensive stock. \n\nThe core idea of pair trading is <a href=https://en.wikipedia.org/wiki/Cointegration>cointegration</a>. Metaphorically speaking, cointegration is like a couple in a clingy relationship where two parties are crazy-glued together. Yet, most relationships break sooner or later, and only the very few can make it to the marriage (from a statistics perspective, not being pessimistic). Hence, it is important to frequently check on the status quo of cointegration before any pair trading order execution (the same applies to relationships).\n\n*Click <a href=https://github.com/je-suis-tm/quant-trading/blob/master/Pair%20trading%20backtest.py>here</a> to be redirected to the script.*\n\n![alt text](https://github.com/je-suis-tm/quant-trading/blob/master/preview/pair%20trading%20positions.png)\n\n![alt text](https://github.com/je-suis-tm/quant-trading/blob/master/preview/pair%20trading%20asset.png)\n\n### 3. Heikin-Ashi candlestick\n\nHeikin-Ashi, the exotic name actually referring to 'Average Bar' in Japanese, is an alternative style of candlestick chart. The sophisticated rules of Heiki-Ashi are designed to filter out the noise for momentum trading. Hence, Heikin-Ashi shows more consecutive bars in contrast to the standard candlestick, which makes price momentum and reverse points more distinguishable in figures. Arguably it should outperform the standard candlestick in sideways and choppy markets. \n\nFor the strategy itself, initially we make a few transformations on four vital benchmarks - Open, Close, High, Low. The next step is to apply unique Heikin-Ashi rules on Heikin-Ashi Open, Close, High, Low to generate trading signals. The downside of Heikin-Ashi (or any momentum trading strategies) is the slow response. Thus, we should set up the stop loss position accordingly so that we don't get caught up in any flash crash.\n\nThe rules of Heikin-Ashi can be found in <a href=https://quantiacs.com/Blog/Intro-to-Algorithmic-Trading-with-Heikin-Ashi.aspx>Quantiacs</a>.\n\n*Click <a href=https://github.com/je-suis-tm/quant-trading/blob/master/Heikin-Ashi%20backtest.py>here</a> to be redirected to the script.*\n\n![alt text](https://github.com/je-suis-tm/quant-trading/blob/master/preview/heikin-ashi%20positions.png)\n\n![alt text](https://github.com/je-suis-tm/quant-trading/blob/master/preview/heikin-ashi%20asset%20value.png)\n\n### 4. London Breakout\n\nTo one of my favourite cities in the world! Proud to be a Londoner!\n\nLondon Breakout is an intra daily opening range breakout strategy. Basically, it is a fascinating information arbitrage across different markets in different time zones. FX market runs 24/7 globally. For instance, you cannot long the stock of Ford in ASX simply because Ford is listed in NYSE. As FX market is decentralised, you can long any currency pair in any market as long as the market is open. That leaves a door to take a peek at the activity in a closed foreign FX market before the opening of domestic FX market.\n\nBack to London Breakout, London and Tokyo are two of the largest FX markets in the world. Tokyo FX trading hour is GMT 0:00 a.m. - GMT 8:59am. London FX trading hour (no summer daylight saving) begins at GMT 8:00 a.m. Even though there is an hour of overlap, the crucial timeframe of London Breakout is GMT 7:00 a.m. - GMT 7:59 a.m. a.k.a. the last trading hour before the opening of London market. The price movement of the crucial timeframe incorporates the information of all the overnight activities of financial market (from the perspective of the current time zone).\n\nFor the strategy itself, we establish upper and lower thresholds prior to the high and low of the crucial timeframe. Once London FX market opens, we spend the first couple of minutes to check if the price would breach the preset boundaries. If it is above threshold, we long the currency pair accordingly. Vice versa. Nevertheless, we should set up a limit to prevent us from trading in the case of abnormal opening volatility. Normally, we clear our positions based on our target stop loss or stop profit respectively. By the end of the trading hour (still from the perspective of the current time zone), if there are any open positions, we clear them out.\n\n*Click <a href=https://github.com/je-suis-tm/quant-trading/blob/master/London%20Breakout%20backtest.py>here</a> to be redirected to the script.*\n\n![alt text](https://github.com/je-suis-tm/quant-trading/blob/master/preview/london%20breakout%20positions.png)\n\n![alt text](https://github.com/je-suis-tm/quant-trading/blob/master/preview/london%20breakout%20thresholds.png)\n\n### 5. Awesome oscillator\n\nAwesome oscillator is an upgraded version of MACD oscillator. It is one of those momentum strategies focusing on the game of moving average. Instead of taking simple moving average on close price, awesome moving average is derived from the mean of high and low price. Similar to MACD oscillator, it takes both short term and long term moving averages to construct the oscillator.\n\nThere are various strategies for awesome oscillator to generate signals, such as traditional moving average divergence, twin peaks and saucer. Twin peaks is just one of the many names of bottom W pattern. The pattern recognition will be covered in another chapter so the main focus of this chapter is saucer. Saucer is slightly more complex to implement than the traditional divergence. In return, saucer has the power to beat the slow response of the traditional divergence. Generally speaking, a faster response may sound awesome, but it does not guarantee a less risky outcome or a more profitable outcome. Hence, we will take MACD oscillator as a control group, to test if awesome oscillator can actually outperform MACD oscillator.\n\nThe rules of awesome oscillator could be found in <a href=https://www.tradingview.com/wiki/Awesome_Oscillator_(AO)>TradingView</a>.\n\n*Click <a href=https://github.com/je-suis-tm/quant-trading/blob/master/Awesome%20Oscillator%20backtest.py>here</a> to be redirected to the script.*\n\n![alt text](https://github.com/je-suis-tm/quant-trading/blob/master/preview/awesome%20positions.png)\n\n![alt text](https://github.com/je-suis-tm/quant-trading/blob/master/preview/awesome%20oscillator.png)\n\n![alt text](https://github.com/je-suis-tm/quant-trading/blob/master/preview/awesome%20ma.png)\n\n![alt text](https://github.com/je-suis-tm/quant-trading/blob/master/preview/awesome%20asset.png)\n\n### 6. Oil Money project\n\nThis project is inspired by an <a href=https://www.bloomberg.com/news/articles/2018-05-20/crude-oil-s-surge-is-putting-the-petro-back-in-petrocurrencies>article</a> on oil-backed foreign exchange. Amid the bullish outlook for crude oil, the currency exchange of oil producing countries would also bounce back. Does this statement really hold? \n\nAccording to the article by Bloomberg (or many other similar research), researchers examine the correlation between petrocurrency and oil price, instead of the causality. But correlation does not equal to causality. Correlation could be a coincidence of a math game. We simply cannot draw the conclusion that oil price moves the currency. Some researchers even use bootstrapping which greatly destroys the autocorrelation of a time series. Thus, it is vital to apply academic analysis and computer simulation on some petrocurrencies to test the causality of oil.\n\n*For more details, please refer to the <a href=https://github.com/je-suis-tm/quant-trading/blob/master/Oil%20Money%20project/README.md>read me page</a> of a separate directory or <a href=https://je-suis-tm.github.io/quant-trading/oil-money>quant trading section</a> on my personal blog.*\n\n![alt text](https://github.com/je-suis-tm/quant-trading/blob/master/Oil%20Money%20project/preview/oil%20production%20bubble%20map.png)\n\n### 7. Dual Thrust\n\nIf you search dual thrust on google, you will end up with results of rocket engine. Don't panic yet, you can rest assured that dual thrust strategy is nowhere near rocket science. It is just an opening range breakout strategy developed by the founder of Universal Technical Systems. The mathematics involved in this strategy is merely primary school level.\n\nInitially we establish upper and lower thresholds based on previous days' open, close, high and low. When the market opens and the price exceeds certain thresholds, we would take long/short positions prior to upper/lower thresholds. The strategy is quite useful in intra daily trading. However, there is no stop loss/profit position in this strategy. We reverse our positions when the price goes from one threshold to the other. We need to clear all positions by the end of the day.\n\nRules of dual thrust can be found in <a href=https://www.quantconnect.com/tutorials/dual-thrust-trading-algorithm>QuantConnect</a>.\n\n*Click <a href=https://github.com/je-suis-tm/quant-trading/blob/master/Dual%20Thrust%20backtest.py>here</a> to be redirected to the script.*\n\n![alt text](https://github.com/je-suis-tm/quant-trading/blob/master/preview/dual%20thrust%20positions.png)\n\n### 8. Parabolic SAR\n\nParabolic SAR is an indicator to identify stop and reverse of a trend. Usually, Parabolic SAR is presented as dotted line either above or below the price in charts. When the price is an uptrend, SAR curve would sit below the price. When the price is downtrend, SAR curve would rise above the price. Parabolic SAR is always considered as a symbol of resistance to the price momentum. When SAR curve and the price curve cross over, it is when trade orders are supposed to be executed. \n\nThe building of this strategy seems very simple, but the construction of the indicator is extremely painful due to the involvement of recursive calculation. Illustration on how to compute Parabolic SAR can be found in <a href=https://en.wikipedia.org/wiki/Parabolic_SAR>Wikipedia</a> but it is not very well explained. To get a clear idea of the calculation, my personal recommendation is to take a look at the <a href=https://www.box.com/s/gbtrjuoktgyag56j6lv0>spreadsheet</a> made by joeu2004.\n\nIt is worth mentioning that SAR and RSI (which will be featured in a later chapter) shares the same founder, Welles Wilder. The guy is a real legend who used to work as mechanical engineer and real estate developer and later became a technical analyst. His book on technical trading system is a must-read for anyone that wants to elevate quant trading system to the next level.\n\n*Click <a href=https://github.com/je-suis-tm/quant-trading/blob/master/Parabolic%20SAR%20backtest.py>here</a> to be redirected to the script.*\n\n![alt text](https://github.com/je-suis-tm/quant-trading/blob/master/preview/parabolic%20sar%20positions.png)\n\n### 9. Bollinger Bands Pattern Recognition\n\nBollinger Bands is a very simple but powerful indicator. There are three bands of this indicator. The mid band is the moving average on the price series (usually takes 20 lags). The upper and lower bands are two moving standard deviations away from the mid band. Bollinger Bands can be used to test for various types of strategies. \n\nFor volatility trading, contraction and expansion of the band width are crucial elements. Any distinct momentum clustering (it can take form of either upward or downward) would result in a Bollinger Bands expansion. And the oscillation in a horizontal channel would result in a Bollinger Bands contraction. \n\nFor momentum trading, the phenomenon of 'walking the band' indicates the resistance and support level of the underlying asset. In a strong trend, the price constantly attempts to touch or break through the upper/lower band along with Bollinger Bands moving towards the same direction.\n\nFor pattern recognition, Bollinger Bands has the capability of testing bottom W, top M, head-shoulder patterns, etc. With upper and lower bands served as an interval, it is easier to identify the hidden pattern in the historical data.\n\nMore details of Bollinger Bands can be found in <a href=https://www.tradingview.com/wiki/Bollinger_Bands_(BB)>TradingView</a>.\n\n*Click <a href=https://github.com/je-suis-tm/quant-trading/blob/master/Bollinger%20Bands%20Pattern%20Recognition%20backtest.py>here</a> to be redirected to the script.*\n\n![alt text](https://github.com/je-suis-tm/quant-trading/blob/master/preview/bollinger%20bands%20positions.png)\n\n### 10. Relative Strength Index Pattern Recognition\n\nRSI (Relative Strength Index) is also a popular indicator. It reflects the current strength/weakness of the stock price momentum. The calculation is pretty straight forward. We use 14 days of smoothed moving average (or other moving average methods) to separately calculate the intra daily uptrend and downtrend. We denote uptrend moving average divided by downtrend moving average as the relative strength. We normalize the relative strength by 100 which becomes an index called RSI. It is commonly believed that RSI above 70 is overbought and RSI below 30 is oversold. This is the simplest way to trade on RSI (as shown in the pictures below). Nonetheless, there could be divergence between RSI momentum and price momentum which will not be covered in the script. The effectiveness of any divergence strategy on RSI is rather debatable.\n\n![alt text](https://github.com/je-suis-tm/quant-trading/blob/master/preview/rsi%20positions.png)\n\n![alt text](https://github.com/je-suis-tm/quant-trading/blob/master/preview/rsi%20oscillator.png)\n\nIf you are looking for something slightly more complex, well, we can apply pattern recognition technique to RSI as well. Unlike strategy No.9 Bollinger Bands, we can directly look at the patterns of RSI itself instead of the price. Since we have tested double bottom pattern in Bollinger Bands, we would test head-shoulder pattern on RSI this time.\n\nFor details of head-shoulder pattern, please refer to <a href=https://www.investopedia.com/terms/h/head-shoulders.asp>Investopedia</a>.\n\n*Click <a href=https://github.com/je-suis-tm/quant-trading/blob/master/RSI%20Pattern%20Recognition%20backtest.py>here</a> to be redirected to the script.*\n\n![alt text](https://github.com/je-suis-tm/quant-trading/blob/master/preview/rsi%20pattern%20positions.png)\n\n![alt text](https://github.com/je-suis-tm/quant-trading/blob/master/preview/rsi%20pattern%20oscillator.png)\n\n### 11. Monte Carlo project\n\nMonte Carlo, my first thought on these two words is the grand casino, where you meet Famke Janssen in tuxedo and introduce yourself, 'Bond, James Bond'. Indeed, the simulation is named after the infamous casino. It actually refers to the computer simulation of massive amount of random events. This unconventional mathematical method is extremely powerful in the study of stochastic process. \n\nHere comes the argument on Linkedin that caught my eyes the other day. \"Stock price can be seemed as a Wiener Process. Hence, we can use Monte Carlo simulation to predict the stock price.\" said a data science blog. Well, in order to be a Wiener Process, we have to assume the stock price is continuous in time. In reality, the market closes. The overnight volatility exists. But that is not the biggest issue here. The biggest issue is, can we really use Monte Carlo simulation to predict the stock price, even a range or its direction?\n\n*For more details, please refer to the <a href=https://github.com/je-suis-tm/quant-trading/blob/master/Monte%20Carlo%20project/README.md>read me</a> page of a separate directory or <a href=https://je-suis-tm.github.io/quant-trading/monte-carlo>quant trading</a> section on my personal blog.*\n\n![alt text](https://raw.githubusercontent.com/je-suis-tm/quant-trading/master/Monte%20Carlo%20project/preview/ge%20simulation2.png)\n\n### 12. Options Straddle\n\nHere marks the debut of options strategy in this repository. Straddle refers to the shape of compasses in the payoff diagram of the strategy. A long straddle involves buying a call option and a put option at the same strike price, the same expiration date and preferably the same price. In reality, the same price is not always feasible (call options price higher implies higher upside risk, vice versa). It is recommended to trade when the price disparity between call and put options is converging.\n\nLong straddle is commonly seen in event driven strategy, e.g. political referendum, company earning release. It profits from the uncertainty of both-side risk. For upside risk, the potential profit is unlimited. The potential loss does not come from the downside risk (there is limited gain from downside risk). Instead, it comes from the stagnant price due to insufficient volatility. In this case, short straddle is more suitable for sideways choppy market.\n\nThe crucial element of options straddle is the selection of the strike price. As the price of options contains the market consensus, the only way to maximize the profit is to find the optimal strike price to shrink the loss bandwidth. This is where the economists kick in and offer base case outlook plus best/worst scenarios. In contrast to the common misunderstanding of quantitative trading, Option Greeks are no silver bullet. Quantitative combined with fundamental in one, so-called quantamental, makes the portfolio impeccable.\n\n*Click <a href=https://github.com/je-suis-tm/quant-trading/blob/master/Options%20Straddle%20backtest.py>here</a> to be redirected to the script.*\n\n![alt text](https://github.com/je-suis-tm/quant-trading/blob/master/preview/options%20straddle%20payoff%20diagram.png)\n\n### 13. Portfolio Optimization project\n\nModern portfolio theory was introduced in 1952 by Nobel laureate Harry Markowitz. It is part of investment class 101. But I watched a video by <a href=https://www.wolfram.com/training/videos/FIN015>Wolfram</a> recently. It challenged the traditional approach and introduced graph theory to asset diversification. There are plenty of quant shops deploying fancy mathematic tools to solve the market. The real question for us is, as fancy as it sounds, does graph theory work on portfolio optimization?\n\n![alt text](https://github.com/je-suis-tm/graph-theory/blob/master/Portfolio%20Optimization%20project/preview/outta%20sample%20mean%20variance.png)\n\n*This project is documented in the repository of <a href=https://github.com/je-suis-tm/graph-theory>Graph Theory</a>. For more details, please refer to the <a href=https://github.com/je-suis-tm/graph-theory/blob/master/Portfolio%20Optimization%20project/README.md>read me</a> page of a separate directory or <a href=https://je-suis-tm.github.io/graph-theory/portfolio-optimization>graph theory</a> section on my personal blog.*\n\n### 14. Smart Farmers project\n\nI know a lot of you have complained that this repository isn’t quantitative enough. You are yelling for the ultimate weapon of math destruction such as Poisson process or Jensen’s inequality. Well, the objective of quantitative trading is churning out more :euro: rather than deploying an elegant closed form equation. If you crave for intellectual challenge in mathematics, you are always welcome to check out my <a href=https://github.com/je-suis-tm/graph-theory>Graph Theory</a> repository. Nevertheless, I believe the birth of this project will meet your picky demand. Buon appetito :yum:\n\n:tangerine: :pineapple: :melon: :corn: and :sweet_potato: are something we have been taking for granted. Up until COVID-19, we finally come to senses that farmers are one of our low-paid essential workers. This project is dedicated to the optimal allocation of agricultural resources. By trading agricultural market, we are able to eliminate the inefficiency in the crop market. Ideally no food will be wasted and farmers will be fairly compensated. \n\nThe project per se intends to leverage convex optimization to approximate farmers’ plantation planning for different crops. Assuming farmers are Homo Economicus, their end game is to maximize the profit regarding the price impact from supply and demand. Their decision is constrained by arable land area and biological features of crops. We develop this smart model accordingly to acquire a head start in trading :rice: :coffee: and :chocolate_bar:\n\n![alt text](https://github.com/je-suis-tm/quant-trading/blob/master/Smart%20Farmers%20project/preview/oil%20palm%20vs%20palm%20oil.png)\n\n*For more details, please refer to the <a href=https://github.com/je-suis-tm/quant-trading/tree/master/Smart%20Farmers%20project/README.md>read me page</a> of a separate directory or <a href=https://je-suis-tm.github.io/quant-trading/smart-farmers>quant trading section</a> on my personal blog.*\n\n### 15. VIX Calculator\n\nVIX is the fear gauge of S&P 500 index. By using <a href=https://www.mathopenref.com/calcriemann.html>Riemann sum</a> and <a href=https://www.emathhelp.net/notes/calculus-1/taylor-formula>Taylor series expansion</a>, we are able to convert a continuous fair price variance swap to a discrete options volatility index, which is called VIX. VIX is determined by two components, 3-week-ahead weekly S&P 500 options and one-month-ahead monthly S&P 500 options. It is de facto market anticipated volatility of S&P 500 index in 30 days. So far it has been applied to some stock exchange indices and some forex pairs. Since VIX is such a great risk management tool, why don’t we apply it to any asset with options contract? The objective of this script is to create a VIX calculator for any commodity options within any given length of forecast time horizon.\n\n![alt text](https://github.com/je-suis-tm/quant-trading/blob/master/preview/vix%20calculator.PNG)\n\n*Click <a href=https://github.com/je-suis-tm/quant-trading/blob/master/VIX%20Calculator.py>here</a> to be redirected to the script.*\n\n### 16. Wisdom of Crowds Project\n\nEvery now and then, we read some bulge brackets hit the headline, “XXX will reach 99999€ in 20YY”. Some forecasts hit the bull’s eye but most projections are as accurate as astrology. Price prediction can be easily influenced by the cognitive bias. In the financial market, there is merit to the idea that <a href=https://www.investopedia.com/terms/c/consensusestimate.asp>consensus estimate</a> is the best oracle. By harnessing the power of ensemble learning, we are about to leverage <a href=https://github.com/je-suis-tm/machine-learning/blob/master/Wisdom%20of%20Crowds%20project/dawid%20skene.ipynb>Dawid-Skene model</a> and <a href=https://github.com/je-suis-tm/machine-learning/blob/master/Wisdom%20of%20Crowds%20project/platt%20burges.ipynb>Platt-Burges model</a> to eliminate the idiosyncratic noise associate with each individual judgement. The end game is to reveal the underlying intrinsic value generated by the collective knowledge of research analysts from different investment banks. Is wisdom of crowds a crystal ball for trading? \n\n![alt text](https://github.com/je-suis-tm/machine-learning/blob/master/Wisdom%20of%20Crowds%20project/preview/y1%20forecast%20bias.png)\n\n*This project is documented in the repository of <a href=https://github.com/je-suis-tm/machine-learning>Machine Learning</a>. For more details, please refer to the <a href=https://github.com/je-suis-tm/machine-learning/blob/master/Wisdom%20of%20Crowds%20project/README.md>read me</a> page of a separate directory or <a href=https://je-suis-tm.github.io/machine-learning/wisdom-of-crowds>machine learning</a> section on my personal blog.*\n\n### 17. Shooting Star\n\n> Can we pretend that airplanes in the night sky are like shooting stars? I could really use a wish right now!<br><br>\n> --- Hayley Williams, Lead Vocalist of Paramore\n\nShooting star, such a poetic name, is merely a simple candlestick pattern. It has a long upper shadow, little lower shadow and a small real body, which resonates the shape of a shooting star. Similar to a real comet, shooting star is a jinxed signal. It indicates the beginning of a bearish momentum after a price uptrend. However, the definition of a shooting star in mathematics is sophisticated. Not many candlesticks can suffice the rigid criteria of shooting star. In practice, people relax the constraint on shooting star in order to trigger the signal.\n\nA sibling of shooting star is called hammer which is effectively a vertical flipped shooting star with bullish outlook. The close price of a hammer is supposed to be higher than the open price. Another sibling of shooting star is called inverted hammer. Inverted hammer shares the same shape with shooting star, but inverted hammer comes with higher close price than open price and usually is an omen of price hike. Nonetheless, there is no \"inverted shooting star\". As malicious as it sounds, the official name is called hanging man...\n\n*Click <a href=https://github.com/je-suis-tm/quant-trading/blob/master/Shooting%20Star%20backtest.py>here</a> to be redirected to the script.*\n\n![alt text](https://github.com/je-suis-tm/quant-trading/blob/master/preview/shooting%20star%20positions.png)\n\n<br>\n\n#### STAY TUNED\n"
        },
        {
          "name": "RSI Pattern Recognition backtest.py",
          "type": "blob",
          "size": 14.3046875,
          "content": "# coding: utf-8\n\n# In[1]:\n\n#relative strength index(rsi) is another popular indicator for technical analysis\n#actually i believe its kinda bull shit\n#normally i read stuff on trading view wiki\n#its not like i work there and try to promote it\n#trading view wiki is a very detailed encyclopedia for different indicators\n#plz refer to the following link for more details\n# https://www.tradingview.com/wiki/Relative_Strength_Index_(RSI)\n\n#on trading view wiki, there are a couple of strategies to use rsi\n#the simplest one is overbought/oversold\n#that is what this script is about\n#we just set upper/lower boundaries capped at 30/70 for rsi\n#if rsi exceeds the bound, we bet the stock would go under price correction\n\n#another one is called divergence\n#rsi goes up and price actually goes down\n#the inventor of rsi called wilder believes bearish rsi divergence creates a selling opportunity \n#but his protege cardwell believes bearish divergence only occurs in a bullish trend\n#so their ideas basically contradict to each other\n#i would undoubtedly give up on this bs divergence strategy\n\n#the last one is called failure swing\n#its kinda like a double bottom pattern in price itself\n#except this strategy is a pattern recognition on rsi\n#since i have written bottom w pattern for bollinger bands\n#i would not do it here\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport fix_yahoo_finance as yf\n\n\n# In[2]:\n\n#smoothed moving average\n#for details plz refer to wikipedia\n# https://en.wikipedia.org/wiki/Moving_average#Modified_moving_average\ndef smma(series,n):\n    \n    output=[series[0]]\n    \n    for i in range(1,len(series)):\n        temp=output[-1]*(n-1)+series[i]\n        output.append(temp/n)\n        \n    return output\n\n\n# In[3]:\n\n#calculating rsi is very simple\n#except there are several versions of moving average for rsi\n#simple moving average, exponentially weighted moving average, etc\n#in this script, we use smoothed moving average(the authentic way)\ndef rsi(data,n=14):\n    \n    delta=data.diff().dropna()\n    \n    up=np.where(delta>0,delta,0)\n    down=np.where(delta<0,-delta,0)\n    \n    rs=np.divide(smma(up,n),smma(down,n))\n    \n    output=100-100/(1+rs)\n    \n    return output[n-1:]\n\n\n# In[4]:\n\n#signal generation\n#it is really easy\n#when rsi goes above 70, we short the stock\n#we bet the stock price would fall\n#vice versa\ndef signal_generation(df,method,n=14):\n    \n    df['rsi']=0.0\n    df['rsi'][n:]=method(df['Close'],n=14)\n    \n    df['positions']=np.select([df['rsi']<30,df['rsi']>70], \\\n                              [1,-1],default=0)\n    df['signals']=df['positions'].diff()\n    \n    return df[n:]\n\n\n# In[5]:\n\n#plotting\ndef plot(new,ticker):\n    \n    #the first plot is the actual close price with long/short positions\n    fig=plt.figure(figsize=(10,10))\n    ax=fig.add_subplot(211)\n    \n    new['Close'].plot(label=ticker)\n    ax.plot(new.loc[new['signals']==1].index,\n            new['Close'][new['signals']==1],\n            label='LONG',lw=0,marker='^',c='g')\n    ax.plot(new.loc[new['signals']==-1].index,\n            new['Close'][new['signals']==-1],\n            label='SHORT',lw=0,marker='v',c='r')\n\n    \n    plt.legend(loc='best')\n    plt.grid(True)\n    plt.title('Positions')\n    plt.xlabel('Date')\n    plt.ylabel('price')\n    \n    plt.show()\n    \n    #the second plot is rsi with overbought/oversold interval capped at 30/70\n    bx=plt.figure(figsize=(10,10)).add_subplot(212,sharex=ax)\n    new['rsi'].plot(label='relative strength index',c='#522e75')\n    bx.fill_between(new.index,30,70,alpha=0.5,color='#f22f08')\n    \n    bx.text(new.index[-45],75,'overbought',color='#594346',size=12.5)\n    bx.text(new.index[-45],25,'oversold',color='#594346',size=12.5)\n    \n    plt.xlabel('Date')\n    plt.ylabel('value')\n    plt.title('RSI')\n    plt.legend(loc='best')\n    plt.grid(True)\n    plt.show()\n\n\n# In[6]:\n\n#pattern recognition\n#do u really think i would write such an easy script?\n#dont be naive, here is another way of using rsi\n#unlike double bottom pattern for bollinger bands\n#this is head-shoulder pattern directly on rsi instead of price\n#well, it is actually named head and shoulders\n#but i refused to do free marketing for the shampoo\n#cuz that shampoo doesnt work at all!\n#the details of head-shoulder pattern could be found in this link\n# https://www.investopedia.com/terms/h/head-shoulders.asp\n\n#any way, this pattern recognition is similar to the one in bollinger bands\n#plz refer to bollinger bands for a detailed explanation\n# https://github.com/je-suis-tm/quant-trading/blob/master/Bollinger%20Bands%20Pattern%20Recognition%20backtest.py\ndef pattern_recognition(df,method,lag=14):\n    \n    df['rsi']=0.0\n    df['rsi'][lag:]=method(df['Close'],lag)    \n    \n    #as usual, period is defined as the horizon for finding the pattern\n    period=25    \n    \n    #delta is the threshold of the difference between two prices\n    #if the difference is smaller than delta\n    #we can conclude two prices are not significantly different from each other\n    #the significant level is defined as delta\n    delta=0.2\n    \n    #these are the multipliers of delta\n    #we wanna make sure there is head and shoulders are significantly larger than other nodes\n    #the significant level is defined as head/shoulder multiplier*delta\n    head=1.1\n    shoulder=1.1\n    \n    df['signals']=0\n    df['cumsum']=0\n    df['coordinates']=''\n    \n    #now these are the parameters set by us based on experience\n    #entry_rsi is the rsi when we enter a trade\n    #we would exit the trade based on two conditions\n    #one is that we hold the stock for more than five days\n    #the variable for five days is called exit_days\n    #we use a variable called counter to keep track of it\n    #two is that rsi has increased more than 4 since the entry\n    #the variable for 4 is called exit_rsi\n    #when either condition is triggered, we exit the trade\n    #this is a lazy way to exit the trade\n    #cuz i dont wanna import indicators from other scripts\n    #i would suggest people to use other indicators such as macd or bollinger bands\n    #exiting trades based on rsi is definitely inefficient and unprofitable\n    entry_rsi=0.0\n    counter=0\n    exit_rsi=4\n    exit_days=5\n    \n    #signal generation\n    #plz refer to the following link for pattern visualization\n    # https://github.com/je-suis-tm/quant-trading/blob/master/preview/rsi%20head-shoulder%20pattern.png\n    #the idea is to start with the first node i\n    #we look backwards and find the head node j with maximum value in pattern finding period\n    #between node i and node j, we find a node k with its value almost the same as node i\n    #started from node j to left, we find a node l with its value almost the same as node i\n    #between the left beginning and node l, we find a node m with its value almost the same as node i\n    #after that, we find the shoulder node n with maximum value between node m and node l\n    #finally, we find the shoulder node o with its value almost the same as node n\n    for i in range(period+lag,len(df)):\n        \n        #this is pretty much the same idea as in bollinger bands\n        #except we have two variables\n        #one for shoulder and one for the bottom nodes\n        moveon=False\n        top=0.0\n        bottom=0.0\n        \n        #we have to make sure no holding positions\n        #and the close price is not the maximum point of pattern finding horizon\n        if (df['cumsum'][i]==0) and  \\\n        (df['Close'][i]!=max(df['Close'][i-period:i])):\n            \n            #get the head node j with maximum value in pattern finding period\n            #note that dataframe is in datetime index\n            #we wanna convert the result of idxmax to a numerical index number\n            j=df.index.get_loc(df['Close'][i-period:i].idxmax())\n            \n            #if the head node j is significantly larger than node i\n            #we would move on to the next phrase\n            if (np.abs(df['Close'][j]-df['Close'][i])>head*delta):\n                bottom=df['Close'][i]\n                moveon=True\n            \n            #we try to find node k between node j and node i\n            #if node k is not significantly different from node i\n            #we would move on to the next phrase\n            if moveon==True:\n                moveon=False\n                for k in range(j,i):    \n                    if (np.abs(df['Close'][k]-bottom)<delta):\n                        moveon=True\n                        break\n            \n            #we try to find node l between node j and the end of pattern finding horizon\n            #note that we start from node j to the left\n            #cuz we need to find another bottom node m later which would start from the left beginning\n            #this way we can make sure we would find a shoulder node n between node m and node l\n            #if node l is not significantly different from node i\n            #we would move on to the next phrase\n            if moveon==True:\n                moveon=False\n                for l in range(j,i-period+1,-1):\n                    if (np.abs(df['Close'][l]-bottom)<delta):\n                        moveon=True\n                        break\n                    \n            #we try to find node m between node l and the end of pattern finding horizon\n            #this time we start from left to right as usual\n            #if node m is not significantly different from node i\n            #we would move on to the next phrase\n            if moveon==True:\n                moveon=False        \n                for m in range(i-period,l):\n                    if (np.abs(df['Close'][m]-bottom)<delta):\n                        moveon=True\n                        break\n            \n            #get the shoulder node n with maximum value between node m and node l\n            #note that dataframe is in datetime index\n            #we wanna convert the result of idxmax to a numerical index number\n            #if node n is significantly larger than node i and significantly smaller than node j\n            #we would move on to the next phrase\n            if moveon==True:\n                moveon=False        \n                n=df.index.get_loc(df['Close'][m:l].idxmax())\n                if (df['Close'][n]-bottom>shoulder*delta) and \\\n                (df['Close'][j]-df['Close'][n]>shoulder*delta):\n                    top=df['Close'][n]\n                    moveon=True\n                    \n            #we try to find shoulder node o between node k and node i\n            #if node o is not significantly different from node n\n            #we would set up the signals and coordinates for visualization\n            #we also need to refresh cumsum and entry_rsi for exiting the trade\n            #note that moveon is still set as True\n            #it would help the algo to ignore this round of iteration for exiting the trade\n            if moveon==True:        \n                for o in range(k,i):\n                    if (np.abs(df['Close'][o]-top)<delta):\n                        df.at[df.index[i],'signals']=-1\n                        df.at[df.index[i],'coordinates']='%s,%s,%s,%s,%s,%s,%s'%(m,n,l,j,k,o,i)\n                        df['cumsum']=df['signals'].cumsum()\n                        entry_rsi=df['rsi'][i]\n                        moveon=True\n                        break\n        \n        #each time we have a holding position\n        #counter would steadily increase\n        #if either of the exit conditions is met\n        #we exit the trade with long position\n        #and we refresh counter, entry_rsi and cumsum\n        #you may wonder why do we need cumsum?\n        #well, this is for holding positions in case you wanna check on portfolio performance\n        if entry_rsi!=0 and moveon==False:\n            counter+=1\n            if (df['rsi'][i]-entry_rsi>exit_rsi) or \\\n            (counter>exit_days):\n                df.at[df.index[i],'signals']=1\n                df['cumsum']=df['signals'].cumsum()\n                counter=0\n                entry_rsi=0\n            \n    return df\n\n\n#visualize the pattern\ndef pattern_plot(new,ticker):\n    \n    #this part is to get a small slice of dataframe\n    #so we can get a clear view of head-shoulder pattern\n    a,b=list(new[new['signals']!=0].iloc[2:4].index)\n    \n    #extract coordinates for head-shoulder pattern visualization\n    temp=list(map(int,new['coordinates'][a].split(',')))\n    indexlist=list(map(lambda x:new.index[x],temp))\n    \n    #slicing\n    c=new.index.get_loc(b)\n    newbie=new[temp[0]-30:c+20]\n    \n    #first plot is always price with positions\n    ax=plt.figure(figsize=(10,10)).add_subplot(211)\n        \n    newbie['Close'].plot(label=ticker)\n    ax.plot(newbie['Close'][newbie['signals']==1],marker='^',markersize=12, \\\n            lw=0,c='g',label='LONG')\n    ax.plot(newbie['Close'][newbie['signals']==-1],marker='v',markersize=12, \\\n            lw=0,c='r',label='SHORT')\n    \n    plt.legend(loc=0)\n    plt.title('Positions')\n    plt.xlabel('Date')\n    plt.ylabel('price')\n    plt.grid(True)\n    plt.show()\n    \n    #second plot is head-shoulder pattern on rsi\n    bx=plt.figure(figsize=(10,10)).add_subplot(212,sharex=ax)\n    \n    newbie['rsi'].plot(label='relative strength index',c='#f4ed71')\n    \n    #we plot the overbought/oversold interval, positions and pattern\n    bx.fill_between(newbie.index,30,70,alpha=0.6,label='overbought/oversold range',color='#000d29')\n    bx.plot(newbie['rsi'][indexlist], \\\n            lw=3,alpha=0.7,marker='o', \\\n            markersize=6,c='#8d2f23',label='head-shoulder pattern')\n    bx.plot(newbie['rsi'][newbie['signals']==1],marker='^',markersize=12, \\\n            lw=0,c='g',label='LONG')\n    bx.plot(newbie['rsi'][newbie['signals']==-1],marker='v',markersize=12, \\\n            lw=0,c='r',label='SHORT')\n\n    #put some captions on head and shoulders\n    for i in [(1,'Shoulder'),(3,'Head'),(5,'Shoulder')]:\n        plt.text(indexlist[i[0]], newbie['rsi'][indexlist[i[0]]]+2, \\\n             '%s'%i[1],fontsize=10,color='#e4ebf2', \\\n             horizontalalignment='center', \\\n            verticalalignment='center')\n        \n    plt.title('RSI')\n    plt.legend(loc=1)\n    plt.xlabel('Date')\n    plt.ylabel('value')\n    plt.grid(True)\n    plt.show()\n    \n    \n# In[7]:\n\n\ndef main():\n    \n    ticker='FCAU'\n    startdate='2016-01-01'\n    enddate='2018-01-01'\n    df=yf.download(ticker,start=startdate,end=enddate)\n    new=signal_generation(df,rsi,n=14)\n\n    plot(new,ticker)\n\n\n#how to calculate stats could be found from my other code called Heikin-Ashi\n# https://github.com/je-suis-tm/quant-trading/blob/master/heikin%20ashi%20backtest.py\n\nif __name__ == '__main__':\n    main()\n\n"
        },
        {
          "name": "Shooting Star backtest.py",
          "type": "blob",
          "size": 7.31640625,
          "content": "\n# coding: utf-8\n\n# In[1]:\n\n\n#shooting star is my friend's fav indicator\n#the name is poetic and romantic\n#it is merely a vertical flipped hammer\n#hammer and shooting star could be confusing\n#since both of them can be inverted\n#i memorize them via a simple tune\n#if u see thor (with hammer),price shall soar\n#if u see star (shooting star),price shall fall\n#details of shooting star can be found in investopedia\n# https://www.investopedia.com/terms/s/shootingstar.asp\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport yfinance\n\n\n# In[2]:\n\n\n#criteria of shooting star\ndef shooting_star(data,lower_bound,body_size):\n\n    df=data.copy()\n\n    #open>close,red color\n    df['condition1']=np.where(df['Open']>=df['Close'],1,0)\n\n    #a candle with little or no lower wick\n    df['condition2']=np.where(\n        (df['Close']-df['Low'])<lower_bound*abs(\n            df['Close']-df['Open']),1,0)\n\n    #a candle with a small lower body\n    df['condition3']=np.where(abs(\n        df['Open']-df['Close'])<abs(\n        np.mean(df['Open']-df['Close']))*body_size,1,0)\n\n    #a long upper wick that is at least two times the size of the lower body\n    df['condition4']=np.where(\n        (df['High']-df['Open'])>=2*(\n            df['Open']-df['Close']),1,0)\n\n    #price uptrend\n    df['condition5']=np.where(\n        df['Close']>=df['Close'].shift(1),1,0)\n    df['condition6']=np.where(\n        df['Close'].shift(1)>=df['Close'].shift(2),1,0)\n\n    #the next candle's high must stay \n    #below the high of the shooting star \n    df['condition7']=np.where(\n        df['High'].shift(-1)<=df['High'],1,0)\n\n    #the next candle's close below \n    #the close of the shooting star\n    df['condition8']=np.where(\n        df['Close'].shift(-1)<=df['Close'],1,0)\n    \n    return df\n\n\n# In[3]:\n\n\n#signal generation\n#there are eight criteria according to investopedia\ndef signal_generation(df,method,\n                      lower_bound=0.2,body_size=0.5,\n                      stop_threshold=0.05,\n                      holding_period=7):\n\n    #get shooting star conditions\n    data=method(df,lower_bound,body_size)\n\n    #shooting star should suffice all conditions\n    #in practise,you may find the definition too rigid\n    #its important to relax a bit on the body size\n    data['signals']=data['condition1']*data[\n        'condition2']*data['condition3']*data[\n        'condition4']*data['condition5']*data[\n        'condition6']*data['condition7']*data[\n        'condition8']\n\n    #shooting star is a short signal\n    data['signals']=-data['signals']\n    \n    #find exit position\n    idxlist=data[data['signals']==-1].index\n    for ind in idxlist:\n\n        #entry point\n        entry_pos=data['Close'].loc[ind]\n\n        stop=False\n        counter=0\n        while not stop:\n            ind+=1\n            counter+=1\n\n            #set stop loss/profit at +-5%\n            if abs(data['Close'].loc[\n                ind]/entry_pos-1)>stop_threshold:\n                stop=True\n                data['signals'].loc[ind]=1\n\n            #set maximum holding period at 7 workdays\n            if counter>=holding_period:\n                stop=True\n                data['signals'].loc[ind]=1\n\n    #create positions\n    data['positions']=data['signals'].cumsum()\n    \n    return data\n\n\n# In[4]:\n\n\n#since matplotlib remove the candlestick\n#plus we dont wanna install mpl_finance\n#we implement our own version\n#simply use fill_between to construct the bar\n#use line plot to construct high and low\ndef candlestick(df,ax=None,highlight=None,titlename='',\n                highcol='High',lowcol='Low',\n                opencol='Open',closecol='Close',xcol='Date',\n                colorup='r',colordown='g',highlightcolor='y',\n                **kwargs):  \n    \n    #bar width\n    #use 0.6 by default\n    dif=[(-3+i)/10 for i in range(7)]\n    \n    if not ax:\n        ax=plt.figure(figsize=(10,5)).add_subplot(111)\n    \n    #construct the bars one by one\n    for i in range(len(df)):\n        \n        #width is 0.6 by default\n        #so 7 data points required for each bar\n        x=[i+j for j in dif]\n        y1=[df[opencol].iloc[i]]*7\n        y2=[df[closecol].iloc[i]]*7\n\n        barcolor=colorup if y1[0]>y2[0] else colordown\n        \n        #no high line plot if open/close is high\n        if df[highcol].iloc[i]!=max(df[opencol].iloc[i],df[closecol].iloc[i]):\n            \n            #use generic plot to viz high and low\n            #use 1.001 as a scaling factor\n            #to prevent high line from crossing into the bar\n            plt.plot([i,i],\n                     [df[highcol].iloc[i],\n                      max(df[opencol].iloc[i],\n                          df[closecol].iloc[i])*1.001],c='k',**kwargs)\n    \n        #same as high\n        if df[lowcol].iloc[i]!=min(df[opencol].iloc[i],df[closecol].iloc[i]):             \n            \n            plt.plot([i,i],\n                     [df[lowcol].iloc[i],\n                      min(df[opencol].iloc[i],\n                          df[closecol].iloc[i])*0.999],c='k',**kwargs)\n        \n        #treat the bar as fill between\n        plt.fill_between(x,y1,y2,\n                         edgecolor='k',\n                         facecolor=barcolor,**kwargs)\n        \n        if highlight:\n            if df[highlight].iloc[i]==-1:\n                plt.fill_between(x,y1,y2,\n                         edgecolor='k',\n                         facecolor=highlightcolor,**kwargs)\n\n    #only show 5 xticks\n    plt.xticks([])\n    plt.grid(True)\n    plt.title(titlename)\n\n\n# In[5]:\n\n\n#plotting the backtesting result\ndef plot(data,name):   \n    \n    #first plot is candlestick to showcase\n    ax1=plt.subplot2grid((250,1),(0,0),\n                         rowspan=120,\n                         ylabel='Candlestick')\n    candlestick(data,ax1,\n                highlight='signals',\n                highlightcolor='#FFFF00')\n\n    #the second plot is the actual price \n    #with long/short positions as up/down arrows\n    ax2=plt.subplot2grid((250,1),(130,0),\n                         rowspan=120,\n                         ylabel='£ per share',\n                         xlabel='Date')\n    ax2.plot(data.index,\n             data['Close'],\n             label=name)\n\n    #long/short positions are attached to \n    #the real close price of the stock\n    #set the line width to zero\n    #thats why we only observe markers\n    ax2.plot(data.loc[data['signals']==-1].index,\n             data['Close'].loc[data['signals']==-1],\n             marker='v',lw=0,c='r',label='short',\n             markersize=10)\n    ax2.plot(data.loc[data['signals']==1].index,\n             data['Close'].loc[data['signals']==1],\n             marker='^',lw=0,c='g',label='long',\n             markersize=10)\n\n    #only show five tickers\n    plt.xticks(range(0,len(data),len(data)//5),\n               data['Date'][0::len(data)//5].dt.date)\n    \n    plt.grid(True)\n    plt.legend(loc='lower left')\n    plt.tight_layout(pad=0.1)\n    plt.show()\n\n\n# In[6]:\n\n\ndef main():\n    \n    #initializing\n    stdate='2000-01-01'\n    eddate='2021-11-04'\n    name='Vodafone'\n    ticker='VOD.L'\n\n    df=yfinance.download(ticker,start=stdate,end=eddate)\n    df.reset_index(inplace=True)\n    df['Date']=pd.to_datetime(df['Date'])\n\n    #signal generation\n    new=signal_generation(df,shooting_star)\n\n    #get subset for better viz to highlight shooting star\n    subset=new.loc[5268:5283].copy()\n    subset.reset_index(inplace=True,drop=True)\n\n    #viz\n    plot(subset,name)\n\n\n# In[7]:\n\n\nif __name__ == '__main__':\n    main()\n\n"
        },
        {
          "name": "Smart Farmers project",
          "type": "tree",
          "content": null
        },
        {
          "name": "VIX Calculator.py",
          "type": "blob",
          "size": 14.857421875,
          "content": "\n# coding: utf-8\n\n# In[1]:\n\n\n#check cboe white paper on the details of computation\n# http://www.cboe.com/micro/vix/vixwhite.pdf\n#check this awesome article on the connection between vix and variance swap\n# https://berentlunde.netlify.app/post/the-fear-index-vix-and-variance-swaps\n#check this paper on the variance swap\n# https://www.researchgate.net/publication/246869706_More_Than_You_Ever_Wanted_to_Know_About_Volatility_Swaps\nimport pandas as pd\nimport datetime as dt\nimport dateutil\nimport decimal\nimport os\nimport numpy as np\nos.chdir('K:/ecole/github/televerser/données')\n\n\n# In[2]:\n\n\n#fill weekend and holiday missing cmt rate\ndef cmt_rate_fill_date(cmt_rate):\n\n    #get missing date as well\n    complete_date=pd.date_range(cmt_rate['Date'].min(),cmt_rate['Date'].max())\n\n    #reindex to fill missing date\n    cmt_rate=cmt_rate.pivot(index='Date',columns='maturity',values='value')\n    cmt_rate=cmt_rate.reindex(complete_date)\n\n    #cleanse\n    cmt_rate.index.name='Date'\n    cmt_rate.reset_index(inplace=True)\n\n    #ffill\n    cmt_rate.fillna(method='ffill',inplace=True)\n\n    #revert to the original form\n    cmt_rate=cmt_rate.melt(id_vars='Date',value_vars=['1 Mo', '1 Yr', '10 Yr', '2 Mo', '2 Yr', '20 Yr', '3 Mo',\n           '3 Yr', '30 Yr', '5 Yr', '6 Mo', '7 Yr'])\n    \n    return cmt_rate\n\n\n# In[3]:\n\n\n#get settlement day in datetime format\n#you can scrape the following website of cme instead\n# f'https://www.cmegroup.com/CmeWS/mvc/ProductCalendar/Options/{futures_id}?optionTypeFilter=&optionTypeFilter='\n#however it has some conflicts with cme globex s own holiday calendar\n# https://www.cmegroup.com/tools-information/holiday-calendar.html\ndef get_settlement_day(current_day,time_horizon,\n                       expiration_day,expiration_hour,\n                       public_holidays):\n\n    #get month end at expiration hour\n    month_end=current_day+dateutil.relativedelta.relativedelta(day=31,hour=expiration_hour,\n                                                                    minute=0,second=0,\n                                                                   microsecond=0,\n                                                                    months=+time_horizon-1)\n\n    \n    #adjust to the nth last day of the month\n    settlement_day=month_end\n    \n    #use loop to skip non trading day\n    correct=False\n    \n    #count the month end if its a weekday\n    counter=1 if dt.datetime.weekday(settlement_day) in range(5) else 0\n    while not correct:\n        \n        #cannot be a weekend day or a federal holiday\n        if (dt.datetime.weekday(settlement_day) in range(5)) and \\\n        (str(settlement_day)[:10] not in public_holidays) and \\\n        counter>expiration_day-1:\n            correct=True\n        else:\n            settlement_day-=dt.timedelta(days=1)\n            \n            #weekday is counted even if its federal holiday\n            if (dt.datetime.weekday(settlement_day) in range(5)):\n                counter+=1\n        \n    return settlement_day\n\n\n# In[4]:\n\n\n#get time to expiration\n#instead of current day+settlement day+other days\n#we can directly use timedelta to obtain the result in minutes\n#no need to skip any holidays in this calculation\ndef get_time_to_expiration(current_day,time_horizon,\n                           expiration_day,expiration_hour,\n                           public_holidays):\n\n    #get settlement day\n    settlement_day=get_settlement_day(current_day,time_horizon,\n                                       expiration_day,expiration_hour,\n                                       public_holidays)\n\n    #convert seconds to minutes\n    #divided by minutes in a year\n    return (settlement_day-current_day).total_seconds()/60/525600\n\n\n# In[5]:\n\n\n#get forward level and strike price no larger than forward\ndef get_forward_strike(options,\n                       interest_rate,\n                       time_to_expiration):\n\n    #cleanse\n    options=options.sort_values('options-strikePrice')\n    find_forward=options.pivot(index='options-strikePrice',\n                         columns='options-optiontype',\n                        values='options-priorSettle')\n\n    #find the forward level with the least put call disparity\n    min_diff_ind=(find_forward['call']-find_forward['put']).apply(abs).idxmin()\n    min_diff=float(decimal.Decimal(find_forward['call'][min_diff_ind].astype(str))-decimal.Decimal(find_forward['put'][min_diff_ind].astype(str)))\n    forward=min_diff_ind+np.e**(interest_rate*time_to_expiration)*(min_diff)\n\n    #find the strike price no larger than forward level\n    strike=find_forward.index[find_forward.index<=forward][-1]\n    \n    return forward,strike\n\n\n# In[6]:\n\n\n#select out of money call options\n#with zero prior settle exclusion\ndef get_options_call_inclusion(options,strike):\n\n    options_call=options[options['options-optiontype']=='call']\n\n    #select outta money options\n    #cuz they are usually more liquid\n    options_call_otm=options_call[options_call['options-strikePrice']>strike]\n\n    #sort by strike price\n    options_call_otm=options_call_otm.sort_values('options-strikePrice')\n    options_call_otm.reset_index(inplace=True,drop=True)\n\n    #find all zero prior settle options\n    options_call_otm_zeros=options_call_otm[options_call_otm['options-priorSettle']==0]\n    options_call_otm_zeros.reset_index(inplace=True)\n\n    #as we dont have bid and ask\n    #we use prior settle instead\n    #once options with consecutive strike prices have zero prior settle\n    #any further out of money options would be excluded\n    if options_call_otm_zeros[options_call_otm_zeros['index'].diff()==1].empty:\n        ind=len(options_call_otm)\n    else:\n        ind=options_call_otm_zeros['index'][options_call_otm_zeros['index'].diff()==1].iloc[0]\n\n    #exclude all zero prior settle options\n    options_call_inclusion=options_call_otm[options_call_otm['options-priorSettle']!=0][:ind]\n\n    #cleanse\n    options_call_inclusion.reset_index(inplace=True,drop=True)\n    \n    return options_call_inclusion\n\n\n# In[7]:\n\n\n#select out of money put options\n#with zero prior settle exclusion\ndef get_options_put_inclusion(options,strike):\n\n    options_put=options[options['options-optiontype']=='put']\n\n    #select outta money options\n    #cuz they are usually more liquid\n    options_put_otm=options_put[options_put['options-strikePrice']<strike]\n\n    #sort by strike price\n    options_put_otm=options_put_otm.sort_values('options-strikePrice',\n                                                ascending=False)\n    options_put_otm.reset_index(inplace=True,drop=True)\n\n    #find all zero prior settle options\n    options_put_otm_zeros=options_put_otm[options_put_otm['options-priorSettle']==0]\n    options_put_otm_zeros.reset_index(inplace=True)\n\n    #as we dont have bid and ask\n    #we use prior settle instead\n    #once options with consecutive strike prices have zero prior settle\n    #any further out of money options would be excluded\n    if options_put_otm_zeros[options_put_otm_zeros['index'].diff()==1].empty:\n        ind=len(options_put_otm)\n    else:\n        ind=options_put_otm_zeros['index'][options_put_otm_zeros['index'].diff()==1].iloc[0]\n\n    #exclude all zero prior settle options\n    options_put_inclusion=options_put_otm[options_put_otm['options-priorSettle']!=0][:ind]\n\n    #cleanse\n    options_put_inclusion.reset_index(inplace=True,drop=True)\n    \n    return options_put_inclusion\n\n\n# In[8]:\n\n\n#compute sigma based upon variance swap formula\ndef compute_sigma(forward,strike,\n                  options_call_inclusion,\n                  options_put_inclusion,\n                  interest_rate,time_to_expiration):\n\n    contributions=0.0\n    for i in [options_call_inclusion,\n              options_put_inclusion]:\n        for j in i.index:\n            \n            #interval between strike prices\n            if j-1<0:\n                delta=abs(i['options-strikePrice'][j]-i['options-strikePrice'][j+1])\n            elif j+1==len(i):\n                delta=abs(i['options-strikePrice'][j]-i['options-strikePrice'][j-1])\n            else:\n                delta=abs(i['options-strikePrice'][j-1]-i['options-strikePrice'][j+1])/2\n\n            contributions+=i['options-priorSettle'][j]*np.exp(interest_rate*time_to_expiration)*delta/(i['options-strikePrice'][j])**2\n\n    #replace bid ask spread midpoint with prior settle\n    sigma=contributions*2/time_to_expiration-((forward/strike-1)**2)/time_to_expiration\n    \n    return sigma\n\n\n# In[9]:\n\n\n#weighted avg of vix\ndef compute_vix(time_to_expiration_front,\n                time_to_expiration_rear,\n                sigma_front,sigma_rear,\n                num_of_mins_timeframe,\n                num_of_mins_year):\n\n    sum1=time_to_expiration_front*sigma_front*(time_to_expiration_rear*num_of_mins_year-num_of_mins_timeframe)/(time_to_expiration_rear*num_of_mins_year-time_to_expiration_front*num_of_mins_year)\n    sum2=time_to_expiration_rear*sigma_rear*(num_of_mins_timeframe-time_to_expiration_front*num_of_mins_year)/(time_to_expiration_rear*num_of_mins_year-time_to_expiration_front*num_of_mins_year)\n    vix=((sum1+sum2)*num_of_mins_year/num_of_mins_timeframe)**0.5*100\n    \n    return vix\n\n\n# In[10]:\n\n\n#aggregate all functions into one\ndef vix_calculator(df,cmt_rate,calendar,\n                   options_id,tradedate,\n                   timeframe_front,timeframe_rear,\n                   expiration_hour,expiration_day,\n                   num_of_mins_timeframe,num_of_mins_year):\n    \n    #us federal holidays\n    federal_holidays=calendar['DATE'].tolist()\n    \n    #daily treasury yield curve rate\n    interest_rate_front=cmt_rate['value'][cmt_rate['maturity']==f'{timeframe_front} Mo'][cmt_rate['Date']==tradedate].item()/100\n    interest_rate_rear=cmt_rate['value'][cmt_rate['maturity']==f'{timeframe_rear} Mo'][cmt_rate['Date']==tradedate].item()/100\n\n    #find current options\n    currentoptions=df[df['options-id']==options_id][df['tradeDate']==tradedate].copy()\n\n    #determine next term and near term contracts\n    nextterm=dt.datetime.strptime(tradedate,'%Y-%m-%d')+dt.timedelta(days=30*timeframe_rear)\n    nearterm=dt.datetime.strptime(tradedate,'%Y-%m-%d')+dt.timedelta(days=30*timeframe_front)\n\n    #determine rear month and front month\n    rearmonth=pd.to_datetime(f'{nextterm.year}-{nextterm.month}-1')\n    frontmonth=pd.to_datetime(f'{nearterm.year}-{nearterm.month}-1')\n\n    #create dataframe copies\n    options_rear=currentoptions[currentoptions['futures-expirationDate']==rearmonth].copy()\n    options_front=currentoptions[currentoptions['futures-expirationDate']==frontmonth].copy()\n\n    #take futures updated datetime as the current one\n    current_day_front=options_front['futures-updated'].iloc[0]\n    current_day_rear=options_rear['futures-updated'].iloc[0]\n\n    #get time to expiration\n    time_to_expiration_front=get_time_to_expiration(current_day_front,\n                                                    timeframe_front,\n                                                    expiration_day,\n                                                    expiration_hour,\n                                                    federal_holidays)\n\n    time_to_expiration_rear=get_time_to_expiration(current_day_rear,\n                                                    timeframe_rear,\n                                                    expiration_day,\n                                                    expiration_hour,\n                                                    federal_holidays)\n\n    #get forward level and strike price no larger than forward\n    forward_front,strike_front=get_forward_strike(options_front,\n                                                  interest_rate_front,\n                                                  time_to_expiration_front)\n\n    forward_rear,strike_rear=get_forward_strike(options_rear,\n                                                  interest_rate_rear,\n                                                  time_to_expiration_rear)\n\n    #prepare options for calculation\n    options_call_front_inclusion=get_options_call_inclusion(\n        options_front,strike_front)\n\n    options_call_rear_inclusion=get_options_call_inclusion(\n        options_rear,strike_rear)\n\n    options_put_front_inclusion=get_options_put_inclusion(\n        options_front,strike_front)\n\n    options_put_rear_inclusion=get_options_put_inclusion(\n        options_rear,strike_rear)\n\n    #use put call avg \n    #if strike price exists in the out of money dataset\n    for i in [options_call_front_inclusion,\n              options_put_front_inclusion]:\n        if strike_front in i['options-strikePrice'].tolist():\n            i['opt'][i['options-strikePrice']==strike_front]=options_front['options-priorSettle'][options_front['options-strikePrice']==strike_front].mean()\n\n    for i in [options_call_rear_inclusion,\n              options_put_rear_inclusion]:\n        if strike_rear in i['options-strikePrice'].tolist():\n            i['opt'][i['options-strikePrice']==strike_rear]=options_rear['options-priorSettle'][options_rear['options-strikePrice']==strike_rear].mean()\n\n\n    #compute sigmas\n    sigma_front=compute_sigma(forward_front,strike_front,\n                      options_call_front_inclusion,\n                      options_put_front_inclusion,\n                      interest_rate_front,time_to_expiration_front)\n\n    sigma_rear=compute_sigma(forward_rear,strike_rear,\n                      options_call_rear_inclusion,\n                      options_put_rear_inclusion,\n                      interest_rate_rear,time_to_expiration_rear)\n\n    #enfin,vix!!!\n    vix=compute_vix(time_to_expiration_front,\n                    time_to_expiration_rear,\n                    sigma_front,sigma_rear,\n                    num_of_mins_timeframe,\n                    num_of_mins_year)\n    \n    return vix\n\n\n# In[11]:\n\n\n#compute 3 month ahead vix for henry hub european options\ndef main():\n\n    #read data\n    df=pd.read_csv('henry hub european options.csv')\n    calendar=pd.read_csv('cme holidays.csv')\n    cmt_rate=pd.read_csv('treasury yield curve rates.csv')\n\n    #datetime format\n    df['futures-expirationDate']=pd.to_datetime(df['futures-expirationDate'])\n    df['tradeDate']=pd.to_datetime(df['tradeDate'])\n    df['futures-updated']=pd.to_datetime(df['futures-updated'])\n    df['options-updated']=pd.to_datetime(df['options-updated'])\n    cmt_rate['Date']=pd.to_datetime(cmt_rate['Date'])\n\n    #fill weekend and holiday missing cmt rate\n    cmt_rate=cmt_rate_fill_date(cmt_rate)\n\n    #preset parameters\n    #check contractSpecs of the underlying asset\n    #in our case\n    # https://www.cmegroup.com/trading/energy/natural-gas/natural-gas_contractSpecs_options.html#optionProductId=1352\n    options_id=1352;tradedate='2020-11-12'\n    timeframe_front=2;timeframe_rear=3\n    expiration_hour=16;expiration_day=4\n    num_of_mins_timeframe=timeframe_rear*30*24*60\n    num_of_mins_year=365*24*60\n\n    #vix!!!\n    vix=vix_calculator(df,cmt_rate,calendar,\n                       options_id,tradedate,\n                       timeframe_front,timeframe_rear,\n                       expiration_hour,expiration_day,\n                       num_of_mins_timeframe,num_of_mins_year)\n\n    print(vix)\n\n\n# In[12]:\n\n\nif __name__ == '__main__':\n    main()\n\n"
        },
        {
          "name": "data",
          "type": "tree",
          "content": null
        },
        {
          "name": "preview",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}