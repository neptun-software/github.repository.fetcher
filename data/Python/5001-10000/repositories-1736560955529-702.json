{
  "metadata": {
    "timestamp": 1736560955529,
    "page": 702,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjcxMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "keras-rl/keras-rl",
      "stars": 5533,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.8447265625,
          "content": "# OS X\n.DS_Store\ndocs/site/*\n\n# Ubuntu\n*~\n\n# PyCharm\n.idea\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nenv/\nbuild/\ndownload/\nbin/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib64/\nparts/\nsdist/\ninclude/\nlib/\nman/\nlocal/\nvar/\nshare/\npip-selfcheck.json\n*.egg-info/\n.installed.cfg\n*.egg\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*,cover\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Weights & Biases\nwandb/"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 2.416015625,
          "content": "sudo: required\ndist: xenial\nlanguage: python\nmatrix:\n  include:\n    - python: 3.6\n      env: KERAS_BACKEND=theano\n    - python: 3.6\n      env: KERAS_BACKEND=tensorflow\n    - python: 2.7\n      env: KERAS_BACKEND=theano\n    - python: 2.7\n      env: KERAS_BACKEND=tensorflow\n    - python: 2.7\n      env: KERAS_BACKEND=tensorflow TEST_MODE=PEP8\n    - python: 2.7\n      env: KERAS_BACKEND=theano TEST_MODE=INTEGRATION\n    - python: 3.6\n      env: KERAS_BACKEND=theano TEST_MODE=INTEGRATION\n    - python: 2.7\n      env: KERAS_BACKEND=tensorflow TEST_MODE=INTEGRATION\n    - python: 3.6\n      env: KERAS_BACKEND=tensorflow TEST_MODE=INTEGRATION\ninstall:\n  # Adopted from https://github.com/fchollet/keras/blob/master/.travis.yml.\n  - if [[ \"$TRAVIS_PYTHON_VERSION\" == \"2.7\" ]]; then\n    wget https://repo.continuum.io/miniconda/Miniconda-latest-Linux-x86_64.sh -O miniconda.sh;\n    else\n    wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh;\n    fi\n  - bash miniconda.sh -b -p $HOME/miniconda\n  - export PATH=\"$HOME/miniconda/bin:$PATH\"\n  - hash -r\n  - conda config --set always_yes yes --set changeps1 no\n  - conda update -q conda\n  # Useful for debugging any issues with conda\n  - conda info -a\n\n  - conda create -q -n test-environment python=$TRAVIS_PYTHON_VERSION numpy matplotlib pandas pytest h5py\n  - source activate test-environment\n  - pip install pytest-xdist\n  # See https://github.com/pytest-dev/pytest-cov/issues/124 for details\n  - pip install pep8 pytest-pep8\n  - pip install tensorflow\n  # Bleeding-edge: pip install git+https://github.com/Theano/Theano.git\n  - pip install \"theano<1.0\"\n  - pip install gym\n  - pip install scipy\n  - pip install wandb\n  # Bleeding-edge: pip install git+https://github.com/fchollet/keras.git;\n  - pip install \"keras>=2.0.7\";\n  - python setup.py install\n\n# command to run tests.\nscript:\n  # Run keras backend init to initialize backend config.\n  - python -c \"import keras.backend\"\n  # Set up keras backend\n  - sed -i -e 's/\"backend\":[[:space:]]*\"[^\"]*/\"backend\":\\ \"'$KERAS_BACKEND'/g' ~/.keras/keras.json;\n  - echo -e \"Running tests with the following config:\\n$(cat ~/.keras/keras.json)\"\n  - if [[ \"$TEST_MODE\" == \"INTEGRATION\" ]]; then\n    PYTHONPATH=$PWD:$PYTHONPATH py.test tests/integration;\n    elif [[ \"$TEST_MODE\" == \"PEP8\" ]]; then\n    PYTHONPATH=$PWD:$PYTHONPATH py.test --pep8 -m pep8 -n0;\n    else\n    PYTHONPATH=$PWD:$PYTHONPATH py.test tests/;\n    fi\nafter_success:\n  - coveralls\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 0.873046875,
          "content": "# Contributing to Keras-RL\n\nNew contributors are very welcomed! If you're interested, please post a message on the [Gitter](https://gitter.im/keras-rl/Lobby).\n\nHere is a list of ways you can contribute to this repository:\n- Tackle an open issue on [Github](https://github.com/keras-rl/keras-rl/issues)\n- Improve documentation\n- Improve test coverage\n- Add examples\n- Implement new algorithms on Keras-RL (please get in touch on Gitter)\n- Link to your personal projects built on top of Keras-RL\n\n\n## How to run the tests\n\nTo run the tests locally, you'll first have to install the following dependencies:\n```bash\npip install pytest pytest-xdist pep8 pytest-pep8 pytest-cov python-coveralls\n```\nYou can then run all tests using this command:\n```bash\npy.test tests/.\n```\nIf you want to check if the files conform to the PEP8 style guidelines, run the following command:\n```bash\npy.test --pep8\n```\n"
        },
        {
          "name": "ISSUE_TEMPLATE.md",
          "type": "blob",
          "size": 0.89453125,
          "content": "Please make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question in the [Keras-RL Google group](https://groups.google.com/forum/#!forum/keras-rl-users) or [join the Keras-RL Gitter channel](https://gitter.im/keras-rl/Lobby) and ask there instead of filing a GitHub issue.\n\nThank you!\n\n- [ ] Check that you are up-to-date with the master branch of Keras-RL. You can update with:\n`pip install git+git://github.com/keras-rl/keras-rl.git --upgrade --no-deps`\n\n- [ ] Check that you are up-to-date with the master branch of Keras. You can update with:\n`pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps`\n\n- [ ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short). If you report an error, please include the error message and the backtrace.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.05859375,
          "content": "The MIT License (MIT)\n\nCopyright (c) 2016 Matthias Plappert\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 5.314453125,
          "content": "# Deep Reinforcement Learning for Keras\n\n[![Build Status](https://api.travis-ci.org/keras-rl/keras-rl.svg?branch=master)](https://travis-ci.org/keras-rl/keras-rl)\n[![Documentation](https://readthedocs.org/projects/keras-rl/badge/)](http://keras-rl.readthedocs.io/)\n[![License](https://img.shields.io/github/license/mashape/apistatus.svg?maxAge=2592000)](https://github.com/keras-rl/keras-rl/blob/master/LICENSE)\n[![Join the chat at https://gitter.im/keras-rl/Lobby](https://badges.gitter.im/keras-rl/Lobby.svg)](https://gitter.im/keras-rl/Lobby)\n\n<table>\n  <tr>\n    <td><img src=\"/assets/breakout.gif?raw=true\" width=\"200\"></td>\n    <td><img src=\"/assets/cartpole.gif?raw=true\" width=\"200\"></td>\n    <td><img src=\"/assets/pendulum.gif?raw=true\" width=\"200\"></td>\n  </tr>\n</table>\n\n## What is it?\n\n`keras-rl` implements some state-of-the art deep reinforcement learning algorithms in Python and seamlessly integrates with the deep learning library [Keras](http://keras.io).\n\nFurthermore, `keras-rl` works with [OpenAI Gym](https://gym.openai.com/) out of the box. This means that evaluating and playing around with different algorithms is easy.\n\nOf course you can extend `keras-rl` according to your own needs. You can use built-in Keras callbacks and metrics or define your own.\nEven more so, it is easy to implement your own environments and even algorithms by simply extending some simple abstract classes. Documentation is available [online](http://keras-rl.readthedocs.org).\n\n## What is included?\n\nAs of today, the following algorithms have been implemented:\n\n- [x] Deep Q Learning (DQN) [[1]](http://arxiv.org/abs/1312.5602), [[2]](https://www.nature.com/articles/nature14236)\n- [x] Double DQN [[3]](http://arxiv.org/abs/1509.06461)\n- [x] Deep Deterministic Policy Gradient (DDPG) [[4]](http://arxiv.org/abs/1509.02971)\n- [x] Continuous DQN (CDQN or NAF) [[6]](http://arxiv.org/abs/1603.00748)\n- [x] Cross-Entropy Method (CEM) [[7]](http://learning.mpi-sws.org/mlss2016/slides/2016-MLSS-RL.pdf), [[8]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.81.6579&rep=rep1&type=pdf)\n- [x] Dueling network DQN (Dueling DQN) [[9]](https://arxiv.org/abs/1511.06581)\n- [x] Deep SARSA [[10]](http://people.inf.elte.hu/lorincz/Files/RL_2006/SuttonBook.pdf)\n- [ ] Asynchronous Advantage Actor-Critic (A3C) [[5]](http://arxiv.org/abs/1602.01783)\n- [ ] Proximal Policy Optimization Algorithms (PPO) [[11]](https://arxiv.org/abs/1707.06347)\n\nYou can find more information on each agent in the [doc](http://keras-rl.readthedocs.io/en/latest/agents/overview/).\n\n## Installation\n\n- Install Keras-RL from Pypi (recommended):\n\n```\npip install keras-rl\n```\n\n- Install from Github source:\n\n```\ngit clone https://github.com/keras-rl/keras-rl.git\ncd keras-rl\npython setup.py install\n```\n\n## Examples\n\nIf you want to run the examples, you'll also have to install:\n\n- **gym** by OpenAI: [Installation instruction](https://github.com/openai/gym#installation)\n- **h5py**: simply run `pip install h5py`\n\nFor atari example you will also need:\n\n- **Pillow**: `pip install Pillow`\n- **gym[atari]**: Atari module for gym. Use `pip install gym[atari]`\n\nOnce you have installed everything, you can try out a simple example:\n\n```bash\npython examples/dqn_cartpole.py\n```\n\nThis is a very simple example and it should converge relatively quickly, so it's a great way to get started!\nIt also visualizes the game during training, so you can watch it learn. How cool is that?\n\nSome sample weights are available on [keras-rl-weights](https://github.com/matthiasplappert/keras-rl-weights).\n\nIf you have questions or problems, please file an issue or, even better, fix the problem yourself and submit a pull request!\n\n## External Projects\n\n- [Starcraft II Learning Environment](https://soygema.github.io/starcraftII_machine_learning/#0)\n\nYou're using Keras-RL on a project? Open a PR and share it!\n\n## Visualizing Training Metrics\n\nTo see graphs of your training progress and compare across runs, run `pip install wandb` and add the WandbLogger callback to your agent's `fit()` call:\n\n```python\nfrom rl.callbacks import WandbLogger\n\n...\n\nagent.fit(env, nb_steps=50000, callbacks=[WandbLogger()])\n```\n\nFor more info and options, see the [W&B docs](https://docs.wandb.com/getting-started).\n\n## Citing\n\nIf you use `keras-rl` in your research, you can cite it as follows:\n\n```bibtex\n@misc{plappert2016kerasrl,\n    author = {Matthias Plappert},\n    title = {keras-rl},\n    year = {2016},\n    publisher = {GitHub},\n    journal = {GitHub repository},\n    howpublished = {\\url{https://github.com/keras-rl/keras-rl}},\n}\n```\n\n## References\n\n1. _Playing Atari with Deep Reinforcement Learning_, Mnih et al., 2013\n2. _Human-level control through deep reinforcement learning_, Mnih et al., 2015\n3. _Deep Reinforcement Learning with Double Q-learning_, van Hasselt et al., 2015\n4. _Continuous control with deep reinforcement learning_, Lillicrap et al., 2015\n5. _Asynchronous Methods for Deep Reinforcement Learning_, Mnih et al., 2016\n6. _Continuous Deep Q-Learning with Model-based Acceleration_, Gu et al., 2016\n7. _Learning Tetris Using the Noisy Cross-Entropy Method_, Szita et al., 2006\n8. _Deep Reinforcement Learning (MLSS lecture notes)_, Schulman, 2016\n9. _Dueling Network Architectures for Deep Reinforcement Learning_, Wang et al., 2016\n10. _Reinforcement learning: An introduction_, Sutton and Barto, 2011\n11. _Proximal Policy Optimization Algorithms_, Schulman et al., 2017\n"
        },
        {
          "name": "assets",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "mkdocs.yml",
          "type": "blob",
          "size": 0.5927734375,
          "content": "site_name: Keras-RL Documentation\ntheme: readthedocs\ndocs_dir: docs/sources\nrepo_url: https://github.com/keras-rl/keras-rl\nsite_description: 'Documentation for Keras-RL, a library for Deep Reinforcement Learning with Keras.'\n#markdown_extensions: [mdx_math]\n#extra_javascript: ['https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML']\n\ndev_addr: '0.0.0.0:8000'\n\npages:\n- Home: index.md\n- Core: core.md\n- Agents:\n  - Overview: agents/overview.md\n  - DQNAgent: agents/dqn.md\n  - NAFAgent: agents/naf.md\n  - DDPGAgent: agents/ddpg.md\n  - SARSAAgent: agents/sarsa.md\n  - CEMAgent: agents/cem.md\n"
        },
        {
          "name": "pytest.ini",
          "type": "blob",
          "size": 1.025390625,
          "content": "# Configuration of py.test\n[pytest]\naddopts=-v\n        -n 2\n        --durations=10\n\n# Do not run tests in the build folder or in the virtualenv folder `venv`.\nnorecursedirs=build venv\n\n# PEP-8 The following are ignored:\n# E251 unexpected spaces around keyword / parameter equals\n# E225 missing whitespace around operator\n# E226 missing whitespace around arithmetic operator\n# W291 trailing whitespace\n# W293 blank line contains whitespace\n# E501 line too long (82 > 79 characters)\n# E402 module level import not at top of file - temporary measure to coninue adding ros python packaged in sys.path\n# E731 do not assign a lambda expression, use a def\n# E302 two blank lines between the functions\n# E231 missing whitespace after ,\n# E241 multiple spaces after ','\n# E261 at least two spaces before inline comment\n\n\npep8ignore=* E251 \\\n           * E225 \\\n           * E226 \\\n           * W291 \\\n           * W293 \\\n           * E501 \\\n           * E402 \\\n           * E731 \\\n           * E302 \\\n           * E231 \\\n           * E241 \\\n           * E261\n"
        },
        {
          "name": "rl",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.0390625,
          "content": "[metadata]\ndescription-file = README.md\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 0.4443359375,
          "content": "from setuptools import setup\nfrom setuptools import find_packages\n\n\nsetup(name='keras-rl',\n      version='0.4.2',\n      description='Deep Reinforcement Learning for Keras',\n      author='Matthias Plappert',\n      author_email='matthiasplappert@me.com',\n      url='https://github.com/keras-rl/keras-rl',\n      license='MIT',\n      install_requires=['keras>=2.0.7'],\n      extras_require={\n          'gym': ['gym'],\n      },\n      packages=find_packages())\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "utils",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}