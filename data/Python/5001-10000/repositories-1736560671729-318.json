{
  "metadata": {
    "timestamp": 1736560671729,
    "page": 318,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjMyMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "tensorlayer/TensorLayer",
      "stars": 7340,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".circleci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".codacy.yaml",
          "type": "blob",
          "size": 0.17578125,
          "content": "# https://support.codacy.com/hc/en-us/articles/115002130625-Codacy-Configuration-File\n---\nengines:\n  bandit:\n    enabled: false\nexclude_paths:\n- scripts/*\n- setup.py\n- docker/**/*\n"
        },
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.01953125,
          "content": "# dockerignore\n.git\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.4296875,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n*~\n\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\ndocs/test_build/\ndocs/build_test/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\nvenv_/\nvenv2/\nvenv3/\nvenv_doc/\nvenv_py2/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n\n\n# IDE Specific directories\n.DS_Store\n.idea\n.vscode/\n\n# TensorLayer Directories\ncheckpoints\ndata/\nlib_win/\n\n# Custom Scripts\nupdate_tl.bat\nupdate_tl.py\n\n# Data Files and ByteCode files\n*.gz\n*.npz\n"
        },
        {
          "name": ".pyup.yml",
          "type": "blob",
          "size": 1.693359375,
          "content": "############################################################################\n#     see https://pyup.io/docs/configuration/ for all available options    #\n############################################################################\n\n# configure updates globally\n# default: all\n# allowed: all, insecure, False\nupdate: all\n\n# configure dependency pinning globally\n# default: True\n# allowed: True, False\npin: False\n\n# set the default branch\n# default: empty, the default branch on GitHub\nbranch: master\n\n# update schedule\n# default: empty\n# allowed: \"every day\", \"every week\", ..\nschedule: \"every day\"\n\n# search for requirement files\n# default: True\n# allowed: True, False\nsearch: False\n\n# Specify requirement files by hand, default is empty\n# default: empty\n# allowed: list\nrequirements:\n    # Requirements for the library\n    - requirements/requirements.txt\n\n    # Requirements for the development\n    - requirements/requirements_tf_cpu.txt\n\n    # Requirements for the development\n    - requirements/requirements_tf_gpu.txt\n\n    # Not necessary, but recommended libraries\n    - requirements/requirements_extra.txt\n\n    # Requirements for contrib loggers\n    - requirements_contrib_loggers.txt\n\n    # Requirements for the db\n    - requirements/requirements_db.txt\n\n    # Requirements for the development\n    - requirements/requirements_dev.txt\n\n    # Requirements for building docs\n    - requirements/requirements_doc.txt\n\n    # Requirements for running unittests\n    - requirements/requirements_test.txt\n\n# configure the branch prefix the bot is using\n# default: pyup-\nbranch_prefix: pyup-\n\n# set a global prefix for PRs\n# default: empty\npr_prefix: \"PyUP - Dependency Update\"\n\n# allow to close stale PRs\n# default: True\nclose_prs: True\n"
        },
        {
          "name": ".readthedocs.yml",
          "type": "blob",
          "size": 0.1962890625,
          "content": "# https://docs.readthedocs.io/en/latest/yaml-config.html\n\nbuild:\n  image: latest\n\nformats:\n    - epub\n    - pdf\n\npython:\n    version: 3.6\n    \nrequirements_file: \n    requirements/requirements_doc.txt\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 4.8330078125,
          "content": "# https://docs.travis-ci.com/user/languages/python/\nlanguage: python\n\n# https://docs.travis-ci.com/user/caching/#pip-cache\ncache:\n  directories:\n    - $HOME/.cache/pip/wheels\n\naddons:\n  apt:\n    update: false\n\nbranches:\n  only:\n    - master\n    - TensorLayer-2.x\n    - /^\\d+\\.\\d+(\\.\\d+)?(\\S*)?$/\n\npython:\n#  - \"3.7\"\n  - \"3.5\"\n#  - \"2.7\"  # TensorLayer 2.0 does not support python2 now\n\nenv:\n\n  # Backward Compatibility in insured for release less than 1 year old.\n  # https://pypi.org/project/tensorflow/#history\n  matrix:\n    - _TF_VERSION=2.0.0-rc1\n#     - _TF_VERSION=1.12.0 # Remove on Oct 22, 2019\n#     - _TF_VERSION=1.11.0 # Remove on Sep 28, 2019\n#     - _TF_VERSION=1.10.1 # Remove on Aug 24, 2019\n#     - _TF_VERSION=1.9.0  # Remove on Jul 10, 2019\n#     - _TF_VERSION=1.8.0  # Remove on Apr 28, 2019\n#     - _TF_VERSION=1.7.1  # Remove on May 08, 2019\n#     - _TF_VERSION=1.7.0  # Remove on Mar 29, 2019\n#     - _TF_VERSION=1.6.0  # Remove on Mar 01, 2019\n\n  global:\n\n  - PYPI_USER='jonathandekhtiar'\n\n  # See https://docs.travis-ci.com/user/encryption-keys/ for more details about secure keys.\n\n  ### == PYPI_PASSWORD === ###\n  ## To update: travis encrypt PYPI_PASSWORD=################################\n  - secure: \"fGIRDjfzzP9DhdDshgh/+bWTZ5Y0jTD4aR+gsT1TyAyc6N4f3RRlx70xZZwYMdQ+XC3no/q4na8UzhhuSM0hCCM1EaQ78WF1c6+FBScf4vYGoYgyJ1am+4gu54JXt+4f0bd+s6jyYBafJALUJp5fqHoxCUXqzjrOqGBBU2+JbL71Aaj8yhQuK0VPPABexsQPQM312Gvzg7hy9dh63J0Q02PqINn+CTcwq3gLH9Oua58zWQ7TaT0cdy/hzAc6Yxy3ajo2W5NU+nKROaaG9W57sa7K/v1dshDFFFST2DdGxm9i7vvfPsq0OWM6qWLsec/4mXJWsmai2ygZEv+IhaABb10c7spd2nl7oHFj2UGmldtO5W0zLb1KkCPWDPilFt3lvHM+OS/YaibquL5/5+yGj0LsRJrVyWoMBA8idcQeH4dvTAfySeFpO42VNwW5ez9JaEOh7bBp7naAA8c/fbNJJ5YEW4MEmOZ9dwFTohNNDiN+oITSrcXBS+jukbfTOmtCeYNUker+4G2YwII9cxHXbZeIMrTq9AqTfOVTAYCFaFHKbpSc1+HCyF7n5ZfNC00kBaw93XUnLRzSNKe5Ir791momYL8HecMN3OAI77bz26/pHSfzJnLntq9qx2nLBTnqDuSq5/pHvdZ8hyt+hTDxvF7HJIVMhbnkjoLPxmn4k/I=\"\n\n  ### === GITHUB_PERSONAL_TOKEN === ###\n  ## To update: travis encrypt GITHUB_PERSONAL_TOKEN=################################\n  - secure: \"kMxg4WfTwhnYMD7WjYk71vgw7XlShPpANauKzfTL6oawDrpQRkBUai4uQwiL3kXVBuVv9rKKKZxxnyAm05iB5wGasPDhlFA1DPF0IbyU3pwQKlw2Xo5qtHdgxBnbms6JJ9z5b+hHCVg+LXYYeUw5qG01Osg5Ue6j1g2juQQHCod00FNuo3fe8ah/Y10Rem6CigH8ofosCrTvN2w1GaetJwVehRYf8JkPC6vQ+Yk8IIjHn2CaVJALbhuchVblxwH0NXXRen915BVBwWRQtsrvEVMXKu7A8sMHmvPz1u3rhXQfjpF2KeVOfy1ZnyiHcLE2HgAPuAGh4kxZAAA8ovmcaCbv8m64bm72BrQApSbt6OEtR9L1UeUwdEgi54FH1XFOHQ9dA6CpiGCyk3wAJZqO0/PkNYVLfb4gPLvnvBRwYBaPgUPvVNhidFu/oODENZmcf8g9ChtuC1GT70EYlVwhgDGqUY7/USZCEvIPe81UToqtIKgcgA+Is51XindumJVMiqTsjgdqeC/wZcw+y37TAjIvvXbtYxeqIKv9zh1JuZppqUhnf+OhI+HHFaY4iu7lQTs3C0WmoLskZAp9srwRtifnVFFkdYzngmPaSjWyko2qiS0cTdFJQB/ljqmnJdksacbv5OOa0Q4qZef/hW774nVx105FlkAIk70D2b5l2pA=\"\n\n  ### === GITHUB_PERSONAL_TOKEN === ###\n  ## To update: travis encrypt HYPERDASH_APIKEY=################################\n  - secure: \"ez9Ck1VpqWOd2PPu+CMWzd8R4aAIXbjKCk96PCKwWu8VXoHjaPkiy8Nn0LUzSlUg3nKdZmu2JSndwDMy3+lMLG7zE2WlGNY7MF5KM3GrvFpP3cxJQ6OuPcZcEH4j5KtBtNTrNqa8SWglqhc9mr66a92SD8Ydc4aMj6L9nbQvrsvVzIMmMy6weVlpBF35nweYCM8LxlsnqyPLleHPZo3o/k+hsTqQQbiMGjC78tqrGr56u7AjL2+D/m33+dfCGzFvMJFcpLQ5ldbcVU54i5e6V3xJ48P30QOGZaqG3fcpfZsyJEIWjykt6XFA8GfJjaVVbxdlr7zP7Vd9iWBuemnMEX3F9Cy/4x7LmX9PJfsVPC6FQnanDvsZSNO5hpmKe8BTpttJJvxgscOczV4jnI69OzqhSQeyChwtkqhIg1E/53XIO+uLJAAZsCkAco7tjGGXTKyv8ZlpSJwSqsLcmgpmQbfodCoMLcYenTxqKZv78e2B4tOPGQyS2bkSxAqhvAIam7RCq/yEvz5n2/mBFEGwP6OQFIdC7ypO2LyrOlLT7HJjCeYMeKSm+GOD3LW9oIy9QJZpG6N/zAAjnk9C2mYtWRQIBo4qdHjRvyDReevDexI8j0AXySblxREmQ7ZaT6KEDXXZSu5goTlaGm0g2HwAkKu9xYFV/bRtp6+i1mP7CQg=\"\n\nmatrix:\n  include:\n    - python: '3.6'\n      env:\n        - _DOC_AND_YAPF_TEST=True\n\ninstall:\n  - |\n    if [[ -v _DOC_AND_YAPF_TEST ]]; then\n        pip install tensorflow==2.0.0-rc1\n        pip install opencv-python\n        pip install yapf\n        pip install -e .[doc]\n    else\n        pip install tensorflow==$_TF_VERSION\n        pip install -e .[all_cpu_dev]\n    fi\n\nscript:\n  # units test\n  # https://docs.pytest.org/en/latest/\n  - rm setup.cfg\n  - |\n    if [[ -v _DOC_AND_YAPF_TEST ]]; then\n        mv setup.travis_doc.cfg setup.cfg\n    else\n        mv setup.travis.cfg setup.cfg\n    fi\n  - pytest\n\n\nbefore_deploy:\n  - python setup.py sdist\n  - python setup.py bdist_wheel\n  - python setup.py bdist_wheel --universal\n  - python setup.py egg_info\n\n\ndeploy:\n\n# Documentation: https://docs.travis-ci.com/user/deployment/pypi/\n- provider: pypi\n  user: '$PYPI_USER'\n  password: '$PYPI_PASSWORD'\n  skip_cleanup: true\n  on:\n    tags: true\n    python: '3.6'\n    condition: '$_TF_VERSION = 2.0.0-rc1'\n#     condition: '$_TF_VERSION = 1.11.0'\n\n# Documentation: https://docs.travis-ci.com/user/deployment/releases/\n- provider: releases\n  file:\n    - dist/*\n    - tensorlayer.egg-info/PKG-INFO\n  file_glob: true\n  skip_cleanup: true\n  api_key: '$GITHUB_PERSONAL_TOKEN'\n  on:\n    tags: true\n    python: '3.6'\n    condition: '$_TF_VERSION = 2.0.0-rc1'\n#     condition: '$_TF_VERSION = 1.11.0'\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 23.7041015625,
          "content": "# Changelog\n\nAll notable changes to this project will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/)\nand this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).\n\n<!--\n\n============== Guiding Principles ==============\n\n* Changelogs are for humans, not machines.\n* There should be an entry for every single version.\n* The same types of changes should be grouped.\n* Versions and sections should be linkable.\n* The latest version comes first.\n* The release date of each version is displayed.\n* Mention whether you follow Semantic Versioning.\n\n============== Types of changes (keep the order) ==============\n\n* `Added` for new features.\n* `Changed` for changes in existing functionality.\n* `Deprecated` for soon-to-be removed features.\n* `Removed` for now removed features.\n* `Fixed` for any bug fixes.\n* `Security` in case of vulnerabilities.\n* `Dependencies Update` in case of vulnerabilities.\n* `Contributors` to thank the contributors that worked on this PR.\n\n============== How To Update The Changelog for a New Release ==============\n\n** Always Keep The Unreleased On Top **\n\nTo release a new version, please update the changelog as followed:\n1. Rename the `Unreleased` Section to the Section Number\n2. Recreate an `Unreleased` Section on top\n3. Update the links at the very bottom\n\n======================= START: TEMPLATE TO KEEP IN CASE OF NEED ===================\n\n** DO NOT MODIFY THIS SECTION ! **\n\n## [Unreleased]\n\n### Added\n\n### Changed\n\n### Dependencies Update\n\n### Deprecated\n\n### Fixed\n\n### Removed\n\n### Security\n\n### Contributors\n\n** DO NOT MODIFY THIS SECTION ! **\n\n======================= END: TEMPLATE TO KEEP IN CASE OF NEED ===================\n\n-->\n\n<!-- YOU CAN EDIT FROM HERE -->\n\n## [Unreleased]\n\n### Added\n\n### Changed\n\n### Dependencies Update\n\n### Deprecated\n\n### Fixed\n\n### Removed\n\n### Security\n\n### Contributors\n\n## [2.2.4] - 2020-12-10\n\nTensorLayer 2.2.4 is a maintenance release.\n\n### Added\n\n### Changed\n\n### Dependencies Update\n\n### Deprecated\n\n### Fixed\n\n- Fix batchnorm(#1104)\n- Fix recurrent(#1106)\n\n### Removed\n\n### Security\n\n### Contributors\n- @zsdonghao\n- @Laicheng0830(#1104)\n- @Thinkre(#1106)\n\n## [2.2.3] - 2020-06-18\n\nTensorLayer 2.2.3 is a maintenance release.\nIt contains numerous bug fixes.\n\n### Added\n\n### Changed\n\n### Dependencies Update\n\n### Deprecated\n\n### Fixed\n\n- Fix VGG. (#1078, 1079, 1089)\n- Fix norm layer. (#1080)\n- Fix DeCov2d layer. (#1081)\n- Fix ModelLayer and LayerList doc. (#1083)\n- Fix bug in SAC. (#1085)\n- Fix refactoring: Deduplication. (#1086)\n- Fix maxpool, batchnorm Data format fixed, vgg forward. (#1089)\n- Fix package info. (#1090)\n\n### Removed\n\n### Security\n\n### Contributors\n- @zsdonghao\n- @tiancheng2000 (#1078 #1079 #1080 #1081)\n- @ChrisWu1997 (#1083)\n- @quantumiracle (#1085)\n- @marload (#1086)\n- @Gyx-One (#1089)\n- @Laicheng0830 (#1090)\n\n## [2.2.2] - 2020-04-26\n\nTensorLayer 2.2.2 is a maintenance release.\n\n### Added\n\n- Reinforcement learning(#1065)\n- Mish activation(#1068)\n\n### Changed\n\n### Dependencies Update\n\n### Deprecated\n\n### Fixed\n\n- Fix README.\n- Fix package info.\n\n### Removed\n\n### Security\n\n### Contributors\n\n- @zsdonghao\n- @quantumiracle(1065)\n- @Laicheng0830(#1068)\n\n## [2.2.1] - 2020-01-14\n\nTensorLayer 2.2.1 is a maintenance release.\nIt contains numerous bug fixes.\n\n### Added\n\n### Changed\n\n### Dependencies Update\n\n### Deprecated\n\n### Fixed\n\n- Fix README. (#1044)\n- Fix package info. (#1046)\n- Fix build test (Using YAPF 0.29) (#1057)\n\n### Removed\n\n### Security\n\n### Contributors\n\n- @luomai (#1044, #1046, #1057)\n\n## [2.2.0] - 2019-09-13\n\nTensorLayer 2.2.0 is a maintenance release.\nIt contains numerous API improvement and bug fixes.\nThis release is compatible with TensorFlow 2 RC1.\n\n### Added\n- Support nested layer customization (#PR 1015)\n- Support string dtype in InputLayer (#PR 1017)\n- Support Dynamic RNN in RNN (#PR 1023)\n- Add ResNet50 static model (#PR 1030)\n- Add performance test code in static model (#PR 1041)\n\n### Changed\n\n- `SpatialTransform2dAffine` auto `in_channels`\n- support TensorFlow 2.0.0-rc1\n- Update model weights property, now returns its copy (#PR 1010)\n\n### Fixed\n- RNN updates: remove warnings, fix if seq_len=0, unitest (#PR 1033)\n- BN updates: fix BatchNorm1d for 2D data, refactored (#PR 1040)\n\n### Dependencies Update\n\n### Deprecated\n\n### Fixed\n- Fix `tf.models.Model._construct_graph` for list of outputs, e.g. STN case (PR #1010)\n- Enable better `in_channels` exception raise. (PR #1015)\n- Set allow_pickle=True in np.load() (#PR 1021)\n- Remove `private_method` decorator (#PR 1025)\n- Copy original model's `trainable_weights` and `nontrainable_weights` when initializing `ModelLayer` (#PR 1026)\n- Copy original model's `trainable_weights` and `nontrainable_weights` when initializing `LayerList` (#PR 1029)\n- Remove redundant parts in `model.all_layers` (#PR 1029)\n- Replace `tf.image.resize_image_with_crop_or_pad` with `tf.image.resize_with_crop_or_pad` (#PR 1032)\n- Fix a bug in `ResNet50` static model (#PR 1041)\n\n### Removed\n\n### Security\n\n### Contributors\n\n- @zsdonghao\n- @luomai\n- @ChrisWu1997: #1010 #1015 #1025 #1030 #1040\n- @warshallrho: #1017 #1021 #1026 #1029 #1032 #1041\n- @ArnoldLIULJ: #1023\n- @JingqingZ: #1023\n\n## [2.1.0]\n\n### Changed\n- Add version_info in model.config. (PR #992)\n- Replace tf.nn.func with tf.nn.func.\\_\\_name\\_\\_ in model config. (PR #994)\n- Add Reinforcement learning tutorials. (PR #995)\n- Add RNN layers with simple rnn cell, GRU cell, LSTM cell. (PR #998)\n- Update Seq2seq (#998)\n- Add Seq2seqLuongAttention model (#998)\n\n### Fixed\n\n### Contributors\n- @warshallrho:  #992 #994\n- @quantumiracle: #995\n- @Tokarev-TT-33: #995\n- @initial-h: #995\n- @Officium: #995\n- @ArnoldLIULJ: #998\n- @JingqingZ: #998\n\n\n## [2.0.2] - 2019-6-5\n\n### Changed\n- change the format of network config, change related code and files; change layer act (PR #980)\n\n### Fixed\n- Fix dynamic model cannot track PRelu weights gradients problem (PR #982)\n- Raise .weights warning (commit)\n\n### Contributors\n- @warshallrho: #980\n- @1FengL: #982\n\n## [2.0.1] - 2019-5-17\n\n\nA maintain release.\n\n### Changed\n- remove `tl.layers.initialize_global_variables(sess)` (PR #931)\n- support `trainable_weights` (PR #966)\n\n### Added\n - Layer\n    - `InstanceNorm`, `InstanceNorm1d`, `InstanceNorm2d`, `InstanceNorm3d` (PR #963)\n\n* Reinforcement learning tutorials. (PR #995)\n\n### Changed\n- remove `tl.layers.initialize_global_variables(sess)` (PR #931)\n- update `tutorial_generate_text.py`, `tutorial_ptb_lstm.py`. remove `tutorial_ptb_lstm_state_is_tuple.py` (PR #958)\n- change `tl.layers.core`, `tl.models.core` (PR #966)\n- change `weights` into `all_weights`, `trainable_weights`, `nontrainable_weights`\n\n### Dependencies Update\n- nltk>=3.3,<3.4 => nltk>=3.3,<3.5 (PR #892)\n- pytest>=3.6,<3.11 => pytest>=3.6,<4.1 (PR #889)\n- yapf>=0.22,<0.25 => yapf==0.25.0 (PR #896)\n- imageio==2.5.0 progressbar2==3.39.3  scikit-learn==0.21.0 scikit-image==0.15.0 scipy==1.2.1 wrapt==1.11.1 pymongo==3.8.0 sphinx==2.0.1 wrapt==1.11.1 opencv-python==4.1.0.25 requests==2.21.0 tqdm==4.31.1\tlxml==4.3.3 pycodestyle==2.5.0 sphinx==2.0.1 yapf==0.27.0(PR #967)\n\n### Fixed\n- fix docs of models @zsdonghao #957\n- In `BatchNorm`, keep dimensions of mean and variance to suit `channels first` (PR #963)\n\n### Contributors\n- @warshallrho: #PR966\n- @zsdonghao: #931\n- @yd-yin: #963\n- @Tokarev-TT-33: # 995\n- @initial-h: # 995\n- @quantumiracle: #995\n- @Officium: #995\n- @1FengL: #958\n- @dvklopfenstein: #971\n\n\n## [2.0.0] - 2019-05-04\n\nTo many PR for this update, please check [here](https://github.com/tensorlayer/tensorlayer/releases/tag/2.0.0) for more details.\n\n### Changed\n* update for TensorLayer 2.0.0 alpha version (PR #952)\n* support TensorFlow 2.0.0-alpha\n* support both static and dynamic model building\n\n### Dependencies Update\n- tensorflow>=1.6,<1.13 => tensorflow>=2.0.0-alpha (PR #952)\n- h5py>=2.9 (PR #952)\n- cloudpickle>=0.8.1 (PR #952)\n- remove matplotlib\n\n### Contributors\n- @zsdonghao\n- @JingqingZ\n- @ChrisWu1997\n- @warshallrho\n\n\n## [1.11.1] - 2018-11-15\n\n### Changed\n* guide for pose estimation - flipping (PR #884)\n* cv2 transform support 2 modes (PR #885)\n\n### Dependencies Update\n- pytest>=3.6,<3.9 => pytest>=3.6,<3.10 (PR #874)\n- requests>=2.19,<2.20 => requests>=2.19,<2.21 (PR #874)\n- tqdm>=4.23,<4.28 => tqdm>=4.23,<4.29 (PR #878)\n- pytest>=3.6,<3.10 => pytest>=3.6,<3.11 (PR #886)\n- pytest-xdist>=1.22,<1.24 => pytest-xdist>=1.22,<1.25 (PR #883)\n- tensorflow>=1.6,<1.12 => tensorflow>=1.6,<1.13 (PR #886)\n\n### Contributors\n- @zsdonghao: #884 #885\n\n## [1.11.0] - 2018-10-18\n\n### Added\n- Layer:\n  - Release `GroupNormLayer` (PR #850)\n- Image affine transformation APIs\n  - `affine_rotation_matrix` (PR #857)\n  - `affine_horizontal_flip_matrix` (PR #857)\n  - `affine_vertical_flip_matrix` (PR #857)\n  - `affine_shift_matrix` (PR #857)\n  - `affine_shear_matrix` (PR #857)\n  - `affine_zoom_matrix` (PR #857)\n  - `affine_transform_cv2` (PR #857)\n  - `affine_transform_keypoints` (PR #857)\n- Affine transformation tutorial\n  - `examples/data_process/tutorial_fast_affine_transform.py` (PR #857)\n\n### Changed\n- BatchNormLayer: support `data_format`\n\n### Dependencies Update\n- matplotlib>=2.2,<2.3 => matplotlib>=2.2,<3.1 (PR #845)\n- pydocstyle>=2.1,<2.2 => pydocstyle>=2.1,<3.1 (PR #866)\n- scikit-learn>=0.19,<0.20 => scikit-learn>=0.19,<0.21 (PR #851)\n- sphinx>=1.7,<1.8 => sphinx>=1.7,<1.9 (PR #842)\n- tensorflow>=1.6,<1.11 => tensorflow>=1.6,<1.12 (PR #853)\n- tqdm>=4.23,<4.26 => tqdm>=4.23,<4.28 (PR #862 & #868)\n- yapf>=0.22,<0.24 => yapf>=0.22,<0.25 (PR #829)\n\n### Fixed\n- Correct offset calculation in `tl.prepro.transform_matrix_offset_center` (PR #855)\n\n### Contributors\n- @2wins: #850 #855\n- @DEKHTIARJonathan: #853\n- @zsdonghao: #857\n- @luomai: #857\n\n## [1.10.1] - 2018-09-07\n\n### Added\n- unittest `tests\\test_timeout.py` has been added to ensure the network creation process does not freeze.\n\n### Changed\n - remove 'tensorboard' param, replaced by 'tensorboard_dir' in `tensorlayer/utils.py` with customizable tensorboard directory (PR #819)\n\n### Removed\n- TL Graph API removed. Memory Leaks Issues with this API, will be fixed and integrated in TL 2.0 (PR #818)\n\n### Fixed\n- Issue #817 fixed: TL 1.10.0 - Memory Leaks and very slow network creation.\n\n### Dependencies Update\n- autopep8>=1.3,<1.4 => autopep8>=1.3,<1.5 (PR #815)\n- imageio>=2.3,<2.4 => imageio>=2.3,<2.5 (PR #823)\n- pytest>=3.6,<3.8 => pytest>=3.6,<3.9 (PR #823)\n- pytest-cov>=2.5,<2.6 => pytest-cov>=2.5,<2.7 (PR #820)\n\n### Contributors\n- @DEKHTIARJonathan: #815 #818 #820 #823\n- @ndiy: #819\n- @zsdonghao: #818\n\n\n## [1.10.0] - 2018-09-02\n\n### Added\n- API:\n  - Add `tl.model.vgg19` (PR #698)\n  - Add `tl.logging.contrib.hyperdash` (PR #739)\n  - Add `tl.distributed.trainer` (PR #700)\n  - Add `prefetch_buffer_size` to the `tl.distributed.trainer` (PR #766)\n  - Add `tl.db.TensorHub` (PR ＃751)\n  - Add `tl.files.save_graph` (PR ＃751)\n  - Add `tl.files.load_graph_` (PR ＃751)\n  - Add `tl.files.save_graph_and_params` (PR ＃751)\n  - Add `tl.files.load_graph_and_params` (PR ＃751)\n  - Add `tl.prepro.keypoint_random_xxx` (PR #787)\n- Documentation:\n  - Add binary, ternary and dorefa links (PR #711)\n  - Update input scale of VGG16 and VGG19 to 0~1 (PR #736)\n  - Update database (PR ＃751)\n- Layer:\n  - Release SwitchNormLayer (PR #737)\n  - Release QuanConv2d, QuanConv2dWithBN, QuanDenseLayer, QuanDenseLayerWithBN (PR#735)\n  - Update Core Layer to support graph (PR ＃751)\n  - All Pooling layers support `data_format` (PR #809)\n- Setup:\n  - Creation of installation flaggs `all_dev`, `all_cpu_dev`, and `all_gpu_dev` (PR #739)\n- Examples:\n  - change folder struction (PR #802)\n  - `tutorial_models_vgg19` has been introduced to show how to use `tl.model.vgg19` (PR #698).\n  - fix bug of `tutorial_bipedalwalker_a3c_continuous_action.py` (PR #734, Issue #732)\n  - `tutorial_models_vgg16` and `tutorial_models_vgg19` has been changed the input scale from [0,255] to [0,1](PR #710)\n  - `tutorial_mnist_distributed_trainer.py` and `tutorial_cifar10_distributed_trainer.py` are added to explain the uses of Distributed Trainer (PR #700)\n  - add `tutorial_quanconv_cifar10.py` and `tutorial_quanconv_mnist.py` (PR #735)\n  - add `tutorial_work_with_onnx.py`(PR #775)\n- Applications:\n  - [Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization](https://arxiv.org/abs/1703.06868) (PR #799)\n\n### Changed\n  - function minibatches changed to avoid wasting samples.(PR #762)\n  - all the input scale in both vgg16 and vgg19 has been changed the input scale from [0,255] to [0,1](PR #710)\n  - Dockerfiles merged and refactored into one file (PR #747)\n  - LazyImports move to the most **top level** imports as possible (PR #739)\n  - some new test functions have been added in `test_layers_convolution.py`, `test_layers_normalization.py`, `test_layers_core.py` (PR #735)\n  - documentation now uses mock imports reducing the number of dependencies to compile the documentation (PR #785)\n  - fixed and enforced pydocstyle D210, D200, D301, D207, D403, D204, D412, D402, D300, D208 (PR #784)\n\n### Deprecated\n  - `tl.logging.warn` has been deprecated in favor of `tl.logging.warning` (PR #739)\n\n### Removed\n  - `conv_layers()`  has been removed in both vgg16 and vgg19(PR #710)\n  - graph API (PR #818)\n\n### Fixed\n- import error caused by matplotlib on OSX (PR #705)\n- missing import in tl.prepro (PR #712)\n- Dockerfiles import error fixed - issue #733 (PR #747)\n- Fix a typo in `absolute_difference_error` in file: `tensorlayer/cost.py` - Issue #753 (PR #759)\n- Fix the bug of scaling the learning rate of trainer (PR #776)\n- log error instead of info when npz file not found. (PR #812)\n\n### Dependencies Update\n- numpy>=1.14,<1.15 => numpy>=1.14,<1.16 (PR #754)\n- pymongo>=3.6,<3.7 => pymongo>=3.6,<3.8 (PR #750)\n- pytest>=3.6,<3.7 => tqdm>=3.6,<3.8 (PR #798)\n- pytest-xdist>=1.22,<1.23 => pytest-xdist>=1.22,<1.24 (PR #805 and #806)\n- tensorflow>=1.8,<1.9 => tensorflow>=1.6,<1.11 (PR #739 and PR #798)\n- tqdm>=4.23,<4.25 => tqdm>=4.23,<4.26 (PR #798)\n- yapf>=0.21,<0.22 => yapf>=0.22,<0.24 (PR #798 #808)\n\n### Contributors\n- @DEKHTIARJonathan: #739 #747 #750 #754\n- @lgarithm: #705 #700\n- @OwenLiuzZ: #698 #710 #775 #776\n- @zsdonghao: #711 #712 #734 #736 #737 #700 #751 #809 #818\n- @luomai: #700 #751 #766 #802\n- @XJTUWYD: #735\n- @mutewall: #735\n- @thangvubk: #759\n- @JunbinWang: #796\n- @boldjoel: #787\n\n## [1.9.1] - 2018-07-30\n\n### Fixed\n- Issue with tensorflow 1.10.0 fixed\n\n## [1.9.0] - 2018-06-16\n\n### Added\n- API:\n  - `tl.alphas` and `tl.alphas_like` added following the tf.ones/zeros and tf.zeros_like/ones_like (PR #580)\n  - `tl.lazy_imports.LazyImport` to import heavy libraries only when necessary (PR #667)\n  - `tl.act.leaky_relu6` and `tl.layers.PRelu6Layer` have been deprecated (PR #686)\n  - `tl.act.leaky_twice_relu6` and `tl.layers.PTRelu6Layer` have been deprecated (PR #686)\n- CI Tool:\n  - [Stale Probot](https://github.com/probot/stale) added to clean stale issues (PR #573)\n  - [Changelog Probot](https://github.com/mikz/probot-changelog) Configuration added (PR #637)\n  - Travis Builds now handling a matrix of TF Version from TF==1.6.0 to TF==1.8.0 (PR #644)\n  - CircleCI added to build and upload Docker Containers for each PR merged and tag release (PR #648)\n- Decorator:\n  - `tl.decorators` API created including `deprecated_alias` and `private_method` (PR #660)\n  - `tl.decorators` API enriched with `protected_method` (PR #675)\n  - `tl.decorators` API enriched with `deprecated` directly raising warning and modifying documentation (PR #691)\n- Docker:\n  - Containers for each release and for each PR merged on master built (PR #648)\n  - Containers built in the following configurations (PR #648):\n    - py2 + cpu\n    - py2 + gpu\n    - py3 + cpu\n    - py3 + gpu\n- Documentation:\n  - Clean README.md (PR #677)\n  - Release semantic version added on index page (PR #633)\n  - Optimizers page added (PR #636)\n  - `AMSGrad` added on Optimizers page added (PR #636)\n- Layer:\n  - ElementwiseLambdaLayer added to use custom function to connect multiple layer inputs (PR #579)\n  - AtrousDeConv2dLayer added (PR #662)\n  - Fix bugs of using `tf.layers` in CNN (PR #686)\n- Optimizer:\n\n  - AMSGrad Optimizer added based on `On the Convergence of Adam and Beyond (ICLR 2018)` (PR #636)\n- Setup:\n\n  - Creation of installation flaggs `all`, `all_cpu`, and `all_gpu` (PR #660)\n- Test:\n  - `test_utils_predict.py` added to reproduce and fix issue #288 (PR #566)\n  - `Layer_DeformableConvolution_Test` added to reproduce issue #572 with deformable convolution (PR #573)\n  - `Array_Op_Alphas_Test` and `Array_Op_Alphas_Like_Test` added to test `tensorlayer/array_ops.py` file (PR #580)\n  - `test_optimizer_amsgrad.py` added to test `AMSGrad` optimizer (PR #636)\n  - `test_logging.py` added to insure robustness of the logging API (PR #645)\n  - `test_decorators.py` added (PR #660)\n  - `test_activations.py` added (PR #686)\n- Tutorials:\n  - `tutorial_tfslim` has been introduced to show how to use `SlimNetsLayer` (PR #560).\n  - add the following to all tutorials (PR #697):\n    ```python\n    tf.logging.set_verbosity(tf.logging.DEBUG)\n    tl.logging.set_verbosity(tl.logging.DEBUG)\n    ```\n\n### Changed\n- Tensorflow CPU & GPU dependencies moved to separated requirement files in order to allow PyUP.io to parse them (PR #573)\n- The document of LambdaLayer for linking it with ElementwiseLambdaLayer (PR #587)\n- RTD links point to stable documentation instead of latest used for development (PR #633)\n- TF Version older than 1.6.0 are officially unsupported and raises an exception (PR #644)\n- README.md Badges Updated with Support Python and Tensorflow Versions (PR #644)\n- TL logging API has been consistent with TF logging API and thread-safe (PR #645)\n- Relative Imports changed for absolute imports (PR #657)\n- `tl.files` refactored into a directory with numerous files (PR #657)\n- `tl.files.voc_dataset` fixed because of original Pascal VOC website was down (PR #657)\n- extra requirements hidden inside the library added in the project requirements (PR #657)\n- requirements files refactored in `requirements/` directory (PR #657)\n- README.md and other markdown files have been refactored and cleaned. (PR #639)\n- Ternary Convolution Layer added in unittest (PR #658)\n- Convolution Layers unittests have been cleaned & refactored (PR #658)\n- All the tests are now using a DEBUG level verbosity when run individualy (PR #660)\n- `tf.identity` as activation is **ignored**, thus reducing the size of the graph by removing useless operation (PR #667)\n- argument dictionaries are now checked and saved within the `Layer` Base Class (PR #667)\n- `Layer` Base Class now presenting methods to update faultlessly `all_layers`, `all_params`, and `all_drop` (PR #675)\n- Input Layers have been removed from `tl.layers.core` and added to `tl.layers.inputs` (PR #675)\n- Input Layers are now considered as true layers in the graph (they represent a placeholder), unittests have been updated (PR #675)\n- Layer API is simplified, with automatic feeding `prev_layer` into `self.inputs` (PR #675)\n- Complete Documentation Refactoring and Reorganization (namely Layer APIs) (PR #691)\n\n### Deprecated\n- `tl.layers.TimeDistributedLayer` argurment `args` is deprecated in favor of `layer_args` (PR #667)\n- `tl.act.leaky_relu` have been deprecated in favor of `tf.nn.leaky_relu` (PR #686)\n\n### Removed\n- `assert()` calls remove and replaced by `raise AssertionError()` (PR #667)\n- `tl.identity` is removed, not used anymore and deprecated for a long time (PR #667)\n- All Code specific to `TF.__version__ < \"1.6\"` have been removed (PR #675)\n\n### Fixed\n- Issue #498 - Deprecation Warning Fix in `tl.layers.RNNLayer` with `inspect` (PR #574)\n- Issue #498 - Deprecation Warning Fix in `tl.files` with truth value of an empty array is ambiguous (PR #575)\n- Issue #565 related to `tl.utils.predict` fixed - `np.hstack` problem in which the results for multiple batches are stacked along `axis=1` (PR #566)\n- Issue #572 with `tl.layers.DeformableConv2d` fixed (PR #573)\n- Issue #664 with `tl.layers.ConvLSTMLayer` fixed (PR #676)\n- Typo of the document of ElementwiseLambdaLayer (PR #588)\n- Error in `tl.layers.TernaryConv2d` fixed - self.inputs not defined (PR #658)\n- Deprecation warning fixed in `tl.layers.binary._compute_threshold()` (PR #658)\n- All references to `tf.logging` replaced by `tl.logging` (PR #661)\n- Duplicated code removed when bias was used (PR #667)\n- `tensorlayer.third_party.roi_pooling.roi_pooling.roi_pooling_ops` is now lazy loaded to prevent systematic error raised (PR #675)\n- Documentation not build in RTD due to old version of theme in docs directory fixed (PR #703)\n- Tutorial:\n  - `tutorial_word2vec_basic.py` saving issue #476 fixed (PR #635)\n  - All tutorials tested and errors have been fixed (PR #635)\n\n### Dependencies Update\n- Update pytest from 3.5.1 to 3.6.0 (PR #647)\n- Update progressbar2 from 3.37.1 to 3.38.0 (PR #651)\n- Update scikit-image from 0.13.1 to 0.14.0 (PR #656)\n- Update keras from 2.1.6 to 2.2.0 (PR #684)\n- Update requests from 2.18.4 to 2.19.0 (PR #695)\n\n### Contributors\n- @lgarithm: #563\n- @DEKHTIARJonathan: #573 #574 #575 #580 #633 #635 #636 #639 #644 #645 #648 #657 #667 #658 #659 #660 #661 #666 #667 #672 #675 #683 #686 #687 #690 #691 #692 #703\n- @2wins: #560 #566 #662\n- @One-sixth: #579\n- @zsdonghao: #587 #588 #639 #685 #697\n- @luomai: #639 #677\n- @dengyueyun666: #676\n\n## [1.8.5] - 2018-05-09\n\n### Added\n- Github Templates added (by @DEKHTIARJonathan)\n  - New issues Template\n  - New PR Template\n- Travis Deploy Automation on new Tag (by @DEKHTIARJonathan)\n  - Deploy to PyPI and create a new version.\n  - Deploy to Github Releases and upload the wheel files\n- PyUP.io has been added to ensure we are compatible with the latest libraries (by @DEKHTIARJonathan)\n- `deconv2d` now handling dilation_rate (by @zsdonghao)\n- Documentation unittest added (by @DEKHTIARJonathan)\n- `test_layers_core` has been added to ensure that `LayersConfig` is abstract.\n\n### Changed\n- All Tests Refactored - Now using unittests and runned with PyTest (by @DEKHTIARJonathan)\n- Documentation updated (by @zsdonghao)\n- Package Setup Refactored (by @DEKHTIARJonathan)\n- Dataset Downlaod now using library progressbar2 (by @DEKHTIARJonathan)\n- `deconv2d` function transformed into Class (by @zsdonghao)\n- `conv1d` function transformed into Class (by @zsdonghao)\n- super resolution functions transformed into Class (by @zsdonghao)\n- YAPF coding style improved and enforced (by @DEKHTIARJonathan)\n\n### Fixed\n- Backward Compatibility Restored with deprecation warnings (by @DEKHTIARJonathan)\n- Tensorflow Deprecation Fix (Issue #498):\n  - AverageEmbeddingInputlayer (by @zsdonghao)\n  - load_mpii_pose_dataset (by @zsdonghao)\n- maxPool2D initializer issue #551 (by @zsdonghao)\n- `LayersConfig` class has been enforced as abstract\n- Pooling Layer Issue #557 fixed (by @zsdonghao)\n\n### Dependencies Update\n- scipy>=1.0,<1.1 => scipy>=1.1,<1.2\n\n### Contributors\n@zsdonghao @luomai @DEKHTIARJonathan\n\n[Unreleased]: https://github.com/tensorlayer/tensorlayer/compare/2.0....master\n[2.2.4]: https://github.com/tensorlayer/tensorlayer/compare/2.2.3...2.2.4\n[2.2.3]: https://github.com/tensorlayer/tensorlayer/compare/2.2.2...2.2.3\n[2.2.2]: https://github.com/tensorlayer/tensorlayer/compare/2.2.1...2.2.2\n[2.2.1]: https://github.com/tensorlayer/tensorlayer/compare/2.2.0...2.2.1\n[2.2.0]: https://github.com/tensorlayer/tensorlayer/compare/2.1.0...2.2.0\n[2.1.0]: https://github.com/tensorlayer/tensorlayer/compare/2.0.2...2.1.0\n[2.0.2]: https://github.com/tensorlayer/tensorlayer/compare/2.0.1...2.0.2\n[2.0.1]: https://github.com/tensorlayer/tensorlayer/compare/2.0.0...2.0.1\n[2.0.0]: https://github.com/tensorlayer/tensorlayer/compare/1.11.1...2.0.0\n[1.11.1]: https://github.com/tensorlayer/tensorlayer/compare/1.11.0...1.11.1\n[1.11.0]: https://github.com/tensorlayer/tensorlayer/compare/1.10.1...1.11.0\n[1.10.1]: https://github.com/tensorlayer/tensorlayer/compare/1.10.0...1.10.1\n[1.10.0]: https://github.com/tensorlayer/tensorlayer/compare/1.9.1...1.10.0\n[1.9.1]: https://github.com/tensorlayer/tensorlayer/compare/1.9.0...1.9.1\n[1.9.0]: https://github.com/tensorlayer/tensorlayer/compare/1.8.5...1.9.0\n[1.8.5]: https://github.com/tensorlayer/tensorlayer/compare/1.8.4...1.8.5\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 7.474609375,
          "content": "# TensorLayer Contributor Guideline\n\n## Welcome to contribute!\nYou are more than welcome to contribute to TensorLayer! If you have any improvement, please send us your [pull requests](https://help.github.com/en/articles/about-pull-requests). You may implement your improvement on your [fork](https://help.github.com/en/articles/working-with-forks).\n\n## Checklist\n* Continuous integration\n* Build from sources\n* Unittest\n* Documentation\n* General intro to TensorLayer2\n* How to contribute a new `Layer`\n* How to contribute a new `Model`\n* How to contribute a new example/tutorial\n\n## Continuous integration\n\nWe appreciate contributions\neither by adding / improving examples or extending / fixing the core library.\nTo make your contributions, you would need to follow the [pep8](https://www.python.org/dev/peps/pep-0008/) coding style and [numpydoc](https://numpydoc.readthedocs.io/en/latest/) document style.\nWe rely on Continuous Integration (CI) for checking push commits.\nThe following tools are used to ensure that your commits can pass through the CI test:\n\n* [yapf](https://github.com/google/yapf) (format code), compulsory\n* [isort](https://github.com/timothycrosley/isort) (sort imports), optional\n* [autoflake](https://github.com/myint/autoflake) (remove unused imports), optional\n\nYou can simply run\n\n```bash\nmake format\n```\n\nto apply those tools before submitting your PR.\n\n## Build from sources\n\n```bash\n# First clone the repository and change the current directory to the newly cloned repository\ngit clone https://github.com/zsdonghao/tensorlayer2.git\ncd tensorlayer2\n\n# Install virtualenv if necessary\npip install virtualenv\n\n# Then create a virtualenv called `venv`\nvirtualenv venv\n\n# Activate the virtualenv\n\n## Linux:\nsource venv/bin/activate\n\n## Windows:\nvenv\\Scripts\\activate.bat\n\n# ============= IF TENSORFLOW IS NOT ALREADY INSTALLED ============= #\n\n# basic installation\npip install .\n\n# advanced: for a machine **without** an NVIDIA GPU\npip install -e \".[all_cpu_dev]\"\n\n# advanced: for a machine **with** an NVIDIA GPU\npip install -e \".[all_gpu_dev]\"\n```\n\n## Unittest\n\nLaunching the unittest for the whole repo:\n\n```bash\n# install pytest\npip install pytest\n\n# run pytest\npytest\n```\n\nRunning your unittest code on your implemented module only:\n\n```bash\n# install coverage\npip install coverage\n\ncd /path/to/your/unittest/code\n# For example: cd tests/layers/\n\n# run unittest\ncoverage run --source myproject.module -m unittest discover\n# For example: coverage run --source tensorlayer.layers -m unittest discover\n\n# generate html report\ncoverage html\n```\n\n## Documentation\nEven though you follow [numpydoc](https://numpydoc.readthedocs.io/en/latest/) document style when writing your code, \nthis does not ensure those lines appear on TensorLayer online documentation. \nYou need further modify corresponding RST files in `docs/modules`.\n\nFor example, to add your implemented new pooling layer into documentation, modify `docs/modules/layer.rst`. First, insert layer name under Layer list\n```rst\nLayer list\n----------\n\n.. autosummary::\n\n    NewPoolingLayer\n```\n\nSecond, find pooling layer part and add:\n```rst\n.. -----------------------------------------------------------\n..                     Pooling Layers\n.. -----------------------------------------------------------\n\nPooling Layers\n------------------------\n\nNew Pooling Layer\n^^^^^^^^^^^^^^^^^^^^^^^^^^\n.. autoclass:: NewPoolingLayer\n```\n\nFinally, test with local documentation:\n```bash\ncd ./docs\n\nmake clean\nmake html  \n# then view generated local documentation by ./html/index.html\n``` \n\n## General intro to TensorLayer2\n* TensorLayer2 is built on [TensorFlow2](https://www.tensorflow.org/alpha), so TensorLayer2 is purely eager, no sessions, no globals.\n* TensorLayer2 supports APIs to build static models and dynamic models. Therefore, all `Layers` should be compatible with the two modes.\n```python\n# An example of a static model\n# A static model has inputs and outputs with fixed shape.\ninputs = tl.layers.Input([32, 784])\ndense1 = tl.layers.Dense(n_units=800, act='relu', in_channels=784, name='dense1')(inputs)\ndense2 = tl.layers.Dense(n_units=10,  act='relu', in_channels=800, name='dense2')(dense1)\nmodel = tl.models.Model(inputs=inputs, outputs=dense2)\n\n# An example of a dynamic model\n# A dynamic model has more flexibility. The inputs and outputs may be different in different runs.\nclass CustomizeModel(tl.models.Model):\n    def __init__(self):\n        super(CustomizeModel, self).__init__()\n        self.dense1 = tl.layers.Dense(n_units=800, act='relu', in_channels=784, name='dense1')\n        self.dense2 = tl.layers.Dense(n_units=10,  act='relu', in_channels=800, name='dense2')\n\n    # a dynamic model allows more flexibility by customising forwarding.\n    def forward(self, x, bar=None):\n        d1 = self.dense1(x)\n        if bar:\n            return d1\n        else:\n            d2 = self.dense2(d1)\n            return d1, d2\n\nmodel = CustomizeModel()\n```\n* More examples can be found in [examples](examples/) and [tests/layers](tests/layers/). Note that not all of them are completed.\n\n## How to contribute a new `Layer`\n* A `NewLayer` should be a derived from the base class [`Layer`](tensorlayer/layers/core.py).\n* Member methods to be overrided:\n  - `__init__(self, args1, args2, inputs_shape=None, name=None)`: The constructor of the `NewLayer`, which should\n    - Call `super(NewLayer, self).__init__(name)` to construct the base.\n    - Define member variables based on the args1, args2 (or even more).\n    - If the `inputs_shape` is provided, call `self.build(inputs_shape)` and set `self._built=True`. Note that sometimes only `in_channels` should be enough to build the layer like [`Dense`](tensorlayer/layers/dense/base_dense.py).\n    - Logging by `logging.info(...)`.\n  - `__repr__(self)`: Return a printable representation of the `NewLayer`.\n  - `build(self, inputs_shape)`: Build the `NewLayer` by defining weights.\n  - `forward(self, inputs, **kwargs)`: Forward feeding the `NewLayer`. Note that the forward feeding of some `Layers` may be different during training and testing like [`Dropout`](tensorlayer/layers/dropout.py).\n* Unittest:\n  - Unittest should be done before a pull request. Unittest code can be written in [tests/](tests/)\n* Documents:\n  - Please write a description for each class and method in RST format. The description may include the functionality, arguments, references, examples of the `NewLayer`.\n* Examples: [`Dense`](tensorlayer/layers/dense/base_dense.py), [`Dropout`](tensorlayer/layers/dropout.py), [`Conv`](tensorlayer/layers/convolution/simplified_conv.py).\n\n## How to contribute a new `Model`\n* A `NewModel` should be derived from the base class [`Model`](tensorlayer/models/core.py) (if dynamic) or an instance of [`Model`](tensorlayer/models/core.py) (if static).\n* A static `NewModel` should have fixed inputs and outputs. Please check the example [`VGG_Static`](tensorlayer/models/vgg.py)\n* A dynamic `NewModel` has more flexiblility. Please check the example [`VGG16`](tensorlayer/models/vgg16.py)\n\n## How to contribute a new example/tutorial\n* A new example/tutorial should implement a complete workflow of deep learning which includes (but not limited)\n  - `Models` construction based on `Layers`.\n  - Data processing and loading.\n  - Training and testing.\n  - Forward feeding by calling the models.\n  - Loss function.\n  - Back propagation by `tf.GradientTape()`.\n  - Model saving and restoring.\n* Examples: [MNIST](examples/basic_tutorials/tutorial_mnist_mlp_static.py), [CIFAR10](examples/basic_tutorials/tutorial_cifar10_cnn_static.py), [FastText](examples/text_classification/tutorial_imdb_fasttext.py)\n"
        },
        {
          "name": "LICENSE.rst",
          "type": "blob",
          "size": 11.2431640625,
          "content": "License\n=======\n\nCopyright (c) 2016~2020 The TensorLayer contributors.  All rights reserved.\n\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2016, The TensorLayer Authors.\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n\nContact\n=======\nQuestions? Please contact hao.dong@pku.edu.cn\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.6982421875,
          "content": "default:\n\t@echo \"Usage:\"\n\t@echo \"\\tmake lint      # run pylint\"\n\t@echo \"\\tmake format    # run yapf, autoflake and isort\"\n\t@echo \"\\tmake install3  # install tensorlayer in current workspace with pip3\"\n\nlint:\n\tpylint examples/*.py\n\tpylint tensorlayer\n\ntest:\n\tpython3 tests/models/test_model_core.py\n\tpython3 tests/layers/test_layernode.py\n\tpython3 tests/files/test_utils_saveload.py\n\nformat:\n\tautoflake -ir examples\n\tautoflake -ir tensorlayer\n\tautoflake -ir tests\n\n\tisort -rc examples\n\tisort -rc tensorlayer\n\tisort -rc tests\n\n\tyapf -ir examples\n\tyapf -ir tensorlayer\n\tyapf -ir tests\n\ninstall3:\n\tpip3 install -U . --user\n\n\nTAG = tensorlayer-docs:snaphot\n\ndoc:\n\tdocker build --rm -t $(TAG) -f docker/docs/Dockerfile .\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 10.48046875,
          "content": "<a href=\"https://tensorlayer.readthedocs.io/\">\n    <div align=\"center\">\n        <img src=\"img/tl_transparent_logo.png\" width=\"50%\" height=\"30%\"/>\n    </div>\n</a>\n\n<!--- [![PyPI Version](https://badge.fury.io/py/tensorlayer.svg)](https://badge.fury.io/py/tensorlayer) --->\n<!--- ![PyPI - Python Version](https://img.shields.io/pypi/pyversions/tensorlayer.svg)) --->\n\n![GitHub last commit (branch)](https://img.shields.io/github/last-commit/tensorlayer/tensorlayer/master.svg)\n[![Supported TF Version](https://img.shields.io/badge/TensorFlow-2.0.0%2B-brightgreen.svg)](https://github.com/tensorflow/tensorflow/releases)\n[![Documentation Status](https://readthedocs.org/projects/tensorlayer/badge/)](https://tensorlayer.readthedocs.io/)\n[![Build Status](https://travis-ci.org/tensorlayer/tensorlayer.svg?branch=master)](https://travis-ci.org/tensorlayer/tensorlayer)\n[![Downloads](http://pepy.tech/badge/tensorlayer)](http://pepy.tech/project/tensorlayer)\n[![Downloads](https://pepy.tech/badge/tensorlayer/week)](https://pepy.tech/project/tensorlayer/week)\n[![Docker Pulls](https://img.shields.io/docker/pulls/tensorlayer/tensorlayer.svg)](https://hub.docker.com/r/tensorlayer/tensorlayer/)\n[![Codacy Badge](https://api.codacy.com/project/badge/Grade/d6b118784e25435498e7310745adb848)](https://www.codacy.com/app/tensorlayer/tensorlayer)\n\n<!---  [![CircleCI](https://circleci.com/gh/tensorlayer/tensorlayer/tree/master.svg?style=svg)](https://circleci.com/gh/tensorlayer/tensorlayer/tree/master) --->\n\n<!---  [![Documentation Status](https://readthedocs.org/projects/tensorlayercn/badge/)](https://tensorlayercn.readthedocs.io/)\n<!---  [![PyUP Updates](https://pyup.io/repos/github/tensorlayer/tensorlayer/shield.svg)](https://pyup.io/repos/github/tensorlayer/tensorlayer/) --->\n\n# Please click [TensorLayerX](https://github.com/tensorlayer/tensorlayerx) 🔥🔥🔥\n\n[TensorLayer](https://tensorlayer.readthedocs.io) is a novel TensorFlow-based deep learning and reinforcement learning library designed for researchers and engineers. It provides an extensive collection of customizable neural layers to build advanced AI models quickly, based on this, the community open-sourced mass [tutorials](https://github.com/tensorlayer/tensorlayer/blob/master/examples/reinforcement_learning/README.md) and [applications](https://github.com/tensorlayer). TensorLayer is awarded the 2017 Best Open Source Software by the [ACM Multimedia Society](https://twitter.com/ImperialDSI/status/923928895325442049). \nThis project can also be found at [OpenI](https://git.openi.org.cn/TensorLayer/tensorlayer3.0) and [Gitee](https://gitee.com/organizations/TensorLayer).\n\n# News\n\n- 🔥 [TensorLayerX](https://github.com/tensorlayer/tensorlayerx) is a Unified Deep Learning and Reinforcement Learning Framework for All Hardwares, Backends and OS. The current version supports TensorFlow, Pytorch, MindSpore, PaddlePaddle, OneFlow and Jittor as the backends, allowing users to run the code on different hardware like Nvidia-GPU and Huawei-Ascend.\n- TensorLayer is now in [OpenI](https://git.openi.org.cn/TensorLayer/tensorlayer3.0)\n- Reinforcement Learning Zoo: [Low-level APIs](https://github.com/tensorlayer/tensorlayer/tree/master/examples/reinforcement_learning) for professional usage, [High-level APIs](https://github.com/tensorlayer/RLzoo) for simple usage, and a corresponding [Springer textbook](http://springer.com/gp/book/9789811540943)\n- [Sipeed Maxi-EMC](https://github.com/sipeed/Maix-EMC): Run TensorLayer models on the **low-cost AI chip** (e.g., K210) (Alpha Version)\n\n<!-- 🔥 [NNoM](https://github.com/majianjia/nnom): Run TensorLayer quantized models on the **MCU** (e.g., STM32) (Coming Soon) -->\n\n# Design Features\n\nTensorLayer is a new deep learning library designed with simplicity, flexibility and high-performance in mind.\n\n- ***Simplicity*** : TensorLayer has a high-level layer/model abstraction which is effortless to learn. You can learn how deep learning can benefit your AI tasks in minutes through the massive [examples](https://github.com/tensorlayer/awesome-tensorlayer).\n- ***Flexibility*** : TensorLayer APIs are transparent and flexible, inspired by the emerging PyTorch library. Compared to the Keras abstraction, TensorLayer makes it much easier to build and train complex AI models.\n- ***Zero-cost Abstraction*** : Though simple to use, TensorLayer does not require you to make any compromise in the performance of TensorFlow (Check the following benchmark section for more details).\n\nTensorLayer stands at a unique spot in the TensorFlow wrappers. Other wrappers like Keras and TFLearn\nhide many powerful features of TensorFlow and provide little support for writing custom AI models. Inspired by PyTorch, TensorLayer APIs are simple, flexible and Pythonic,\nmaking it easy to learn while being flexible enough to cope with complex AI tasks.\nTensorLayer has a fast-growing community. It has been used by researchers and engineers all over the world, including those from  Peking University,\nImperial College London, UC Berkeley, Carnegie Mellon University, Stanford University, and companies like Google, Microsoft, Alibaba, Tencent, Xiaomi, and Bloomberg.\n\n# Multilingual Documents\n\nTensorLayer has extensive documentation for both beginners and professionals. The documentation is available in\nboth English and Chinese.\n\n[![English Documentation](https://img.shields.io/badge/documentation-english-blue.svg)](https://tensorlayer.readthedocs.io/)\n[![Chinese Documentation](https://img.shields.io/badge/documentation-%E4%B8%AD%E6%96%87-blue.svg)](https://tensorlayercn.readthedocs.io/)\n[![Chinese Book](https://img.shields.io/badge/book-%E4%B8%AD%E6%96%87-blue.svg)](http://www.broadview.com.cn/book/5059/)\n\nIf you want to try the experimental features on the the master branch, you can find the latest document\n[here](https://tensorlayer.readthedocs.io/en/latest/).\n\n# Extensive Examples\n\nYou can find a large collection of examples that use TensorLayer in [here](examples/) and the following space:\n\n<a href=\"https://github.com/tensorlayer/awesome-tensorlayer/blob/master/readme.md\" target=\"\\_blank\">\n\t<div align=\"center\">\n\t\t<img src=\"img/awesome-mentioned.png\" width=\"40%\"/>\n\t</div>\n</a>\n\n# Getting Start\n\nTensorLayer 2.0 relies on TensorFlow, numpy, and others. To use GPUs, CUDA and cuDNN are required.\n\nInstall TensorFlow:\n\n```bash\npip3 install tensorflow-gpu==2.0.0-rc1 # TensorFlow GPU (version 2.0 RC1)\npip3 install tensorflow # CPU version\n```\n\nInstall the stable release of TensorLayer:\n\n```bash\npip3 install tensorlayer\n```\n\nInstall the unstable development version of TensorLayer:\n\n```bash\npip3 install git+https://github.com/tensorlayer/tensorlayer.git\n```\n\nIf you want to install the additional dependencies, you can also run\n```bash\npip3 install --upgrade tensorlayer[all]              # all additional dependencies\npip3 install --upgrade tensorlayer[extra]            # only the `extra` dependencies\npip3 install --upgrade tensorlayer[contrib_loggers]  # only the `contrib_loggers` dependencies\n```\n\nIf you are TensorFlow 1.X users, you can use TensorLayer 1.11.0:\n\n```bash\n# For last stable version of TensorLayer 1.X\npip3 install --upgrade tensorlayer==1.11.0\n```\n\n<!---\n## Using Docker\n\nThe [TensorLayer containers](https://hub.docker.com/r/tensorlayer/tensorlayer/) are built on top of the official [TensorFlow containers](https://hub.docker.com/r/tensorflow/tensorflow/):\n\n### Containers with CPU support\n\n```bash\n# for CPU version and Python 2\ndocker pull tensorlayer/tensorlayer:latest\ndocker run -it --rm -p 8888:8888 -p 6006:6006 -e PASSWORD=JUPYTER_NB_PASSWORD tensorlayer/tensorlayer:latest\n\n# for CPU version and Python 3\ndocker pull tensorlayer/tensorlayer:latest-py3\ndocker run -it --rm -p 8888:8888 -p 6006:6006 -e PASSWORD=JUPYTER_NB_PASSWORD tensorlayer/tensorlayer:latest-py3\n```\n\n### Containers with GPU support\n\nNVIDIA-Docker is required for these containers to work: [Project Link](https://github.com/NVIDIA/nvidia-docker)\n\n```bash\n# for GPU version and Python 2\ndocker pull tensorlayer/tensorlayer:latest-gpu\nnvidia-docker run -it --rm -p 8888:8888 -p 6006:6006 -e PASSWORD=JUPYTER_NB_PASSWORD tensorlayer/tensorlayer:latest-gpu\n\n# for GPU version and Python 3\ndocker pull tensorlayer/tensorlayer:latest-gpu-py3\nnvidia-docker run -it --rm -p 8888:8888 -p 6006:6006 -e PASSWORD=JUPYTER_NB_PASSWORD tensorlayer/tensorlayer:latest-gpu-py3\n```\n--->\n\n# Performance Benchmark\n\nThe following table shows the training speeds of [VGG16](http://www.robots.ox.ac.uk/~vgg/research/very_deep/) using TensorLayer and native TensorFlow on a TITAN Xp.\n\n|   Mode    |       Lib       |  Data Format  | Max GPU Memory Usage(MB)  |Max CPU Memory Usage(MB) | Avg CPU Memory Usage(MB) | Runtime (sec) |\n| :-------: | :-------------: | :-----------: | :-----------------: | :-----------------: | :-----------------: | :-----------: |\n| AutoGraph | TensorFlow 2.0  | channel last  | 11833 |      2161         |        2136         |      74       |\n|           | TensorLayer 2.0 | channel last  | 11833 |      2187         |        2169         |      76       |\n|   Graph   |      Keras      | channel last  | 8677 |      2580         |        2576         |      101       |\n|   Eager   | TensorFlow 2.0  | channel last  | 8723 |      2052         |        2024         |      97       |\n|           | TensorLayer 2.0 | channel last  | 8723 |      2010         |        2007         |      95       |\n\n# Getting Involved\n\nPlease read the [Contributor Guideline](CONTRIBUTING.md) before submitting your PRs.\n\nWe suggest users to report bugs using Github issues. Users can also discuss how to use TensorLayer in the following slack channel.\n\n<br/>\n\n<a href=\"https://join.slack.com/t/tensorlayer/shared_invite/enQtODk1NTQ5NTY1OTM5LTQyMGZhN2UzZDBhM2I3YjYzZDBkNGExYzcyZDNmOGQzNmYzNjc3ZjE3MzhiMjlkMmNiMmM3Nzc4ZDY2YmNkMTY\" target=\"\\_blank\">\n\t<div align=\"center\">\n\t\t<img src=\"img/join_slack.png\" width=\"40%\"/>\n\t</div>\n</a>\n\n<br/>\n\n# Citing TensorLayer\n\nIf you find TensorLayer useful for your project, please cite the following papers：\n\n```\n@article{tensorlayer2017,\n    author  = {Dong, Hao and Supratak, Akara and Mai, Luo and Liu, Fangde and Oehmichen, Axel and Yu, Simiao and Guo, Yike},\n    journal = {ACM Multimedia},\n    title   = {{TensorLayer: A Versatile Library for Efficient Deep Learning Development}},\n    url     = {http://tensorlayer.org},\n    year    = {2017}\n}\n\n@inproceedings{tensorlayer2021,\n  title={Tensorlayer 3.0: A Deep Learning Library Compatible With Multiple Backends},\n  author={Lai, Cheng and Han, Jiarong and Dong, Hao},\n  booktitle={2021 IEEE International Conference on Multimedia \\& Expo Workshops (ICMEW)},\n  pages={1--3},\n  year={2021},\n  organization={IEEE}\n}\n```\n"
        },
        {
          "name": "README.rst",
          "type": "blob",
          "size": 8.6953125,
          "content": "|TENSORLAYER-LOGO|\n\n\n|Awesome| |Documentation-EN| |Documentation-CN| |Book-CN| |Downloads|\n\n|PyPI| |PyPI-Prerelease| |Commits-Since| |Python| |TensorFlow|\n\n|Travis| |Docker| |RTD-EN| |RTD-CN| |PyUP| |Docker-Pulls| |Code-Quality|\n\n\n|JOIN-SLACK-LOGO|\n\nTensorLayer is a novel TensorFlow-based deep learning and reinforcement\nlearning library designed for researchers and engineers. It provides a\nlarge collection of customizable neural layers / functions that are key\nto build real-world AI applications. TensorLayer is awarded the 2017\nBest Open Source Software by the `ACM Multimedia\nSociety <http://www.acmmm.org/2017/mm-2017-awardees/>`__.\n\nDesign Features\n=================\n\nTensorLayer is a new deep learning library designed with simplicity, flexibility and high-performance in mind.\n\n- **Simplicity** : TensorLayer has a high-level layer/model abstraction which is effortless to learn. You can learn how deep learning can benefit your AI tasks in minutes through the massive [examples](https://github.com/tensorlayer/awesome-tensorlayer).\n- **Flexibility** : TensorLayer APIs are transparent and flexible, inspired by the emerging PyTorch library. Compared to the Keras abstraction, TensorLayer makes it much easier to build and train complex AI models.\n- **Zero-cost Abstraction** : Though simple to use, TensorLayer does not require you to make any compromise in the performance of TensorFlow (Check the following benchmark section for more details).\n\nTensorLayer stands at a unique spot in the TensorFlow wrappers. Other wrappers like Keras and TFLearn\nhide many powerful features of TensorFlow and provide little support for writing custom AI models. Inspired by PyTorch, TensorLayer APIs are simple, flexible and Pythonic,\nmaking it easy to learn while being flexible enough to cope with complex AI tasks.\nTensorLayer has a fast-growing community. It has been used by researchers and engineers all over the world, including those from  Peking University,\nImperial College London, UC Berkeley, Carnegie Mellon University, Stanford University, and companies like Google, Microsoft, Alibaba, Tencent, Xiaomi, and Bloomberg.\n\nInstall\n=======\n\nTensorLayer has pre-requisites including TensorFlow, numpy, and others. For GPU support, CUDA and cuDNN are required.\nThe simplest way to install TensorLayer is to use the Python Package Index (PyPI):\n\n.. code:: bash\n\n    # for last stable version\n    pip install --upgrade tensorlayer\n\n    # for latest release candidate\n    pip install --upgrade --pre tensorlayer\n\n    # if you want to install the additional dependencies, you can also run\n    pip install --upgrade tensorlayer[all]              # all additional dependencies\n    pip install --upgrade tensorlayer[extra]            # only the `extra` dependencies\n    pip install --upgrade tensorlayer[contrib_loggers]  # only the `contrib_loggers` dependencies\n\nAlternatively, you can install the latest or development version by directly pulling from github:\n\n.. code:: bash\n\n    pip install https://github.com/tensorlayer/tensorlayer/archive/master.zip\n    # or\n    # pip install https://github.com/tensorlayer/tensorlayer/archive/<branch-name>.zip\n\nUsing Docker - a ready-to-use environment\n-----------------------------------------\n\nThe `TensorLayer\ncontainers <https://hub.docker.com/r/tensorlayer/tensorlayer/>`__ are\nbuilt on top of the official `TensorFlow\ncontainers <https://hub.docker.com/r/tensorflow/tensorflow/>`__:\n\nContainers with CPU support\n~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. code:: bash\n\n    # for CPU version and Python 2\n    docker pull tensorlayer/tensorlayer:latest\n    docker run -it --rm -p 8888:8888 -p 6006:6006 -e PASSWORD=JUPYTER_NB_PASSWORD tensorlayer/tensorlayer:latest\n\n    # for CPU version and Python 3\n    docker pull tensorlayer/tensorlayer:latest-py3\n    docker run -it --rm -p 8888:8888 -p 6006:6006 -e PASSWORD=JUPYTER_NB_PASSWORD tensorlayer/tensorlayer:latest-py3\n\nContainers with GPU support\n~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nNVIDIA-Docker is required for these containers to work: `Project\nLink <https://github.com/NVIDIA/nvidia-docker>`__\n\n.. code:: bash\n\n    # for GPU version and Python 2\n    docker pull tensorlayer/tensorlayer:latest-gpu\n    nvidia-docker run -it --rm -p 8888:88888 -p 6006:6006 -e PASSWORD=JUPYTER_NB_PASSWORD tensorlayer/tensorlayer:latest-gpu\n\n    # for GPU version and Python 3\n    docker pull tensorlayer/tensorlayer:latest-gpu-py3\n    nvidia-docker run -it --rm -p 8888:8888 -p 6006:6006 -e PASSWORD=JUPYTER_NB_PASSWORD tensorlayer/tensorlayer:latest-gpu-py3\n\nContribute\n==========\n\nPlease read the `Contributor\nGuideline <https://github.com/tensorlayer/tensorlayer/blob/master/CONTRIBUTING.md>`__\nbefore submitting your PRs.\n\nCite\n====\n\nIf you find this project useful, we would be grateful if you cite the\nTensorLayer papers.\n\n::\n\n    @article{tensorlayer2017,\n        author  = {Dong, Hao and Supratak, Akara and Mai, Luo and Liu, Fangde and Oehmichen, Axel and Yu, Simiao and Guo, Yike},\n        journal = {ACM Multimedia},\n        title   = {{TensorLayer: A Versatile Library for Efficient Deep Learning Development}},\n        url     = {http://tensorlayer.org},\n        year    = {2017}\n    }\n\n    @inproceedings{tensorlayer2021,\n      title={Tensorlayer 3.0: A Deep Learning Library Compatible With Multiple Backends},\n      author={Lai, Cheng and Han, Jiarong and Dong, Hao},\n      booktitle={2021 IEEE International Conference on Multimedia \\& Expo Workshops (ICMEW)},\n      pages={1--3},\n      year={2021},\n      organization={IEEE}\n\nLicense\n=======\n\nTensorLayer is released under the Apache 2.0 license.\n\n\n.. |TENSORLAYER-LOGO| image:: https://raw.githubusercontent.com/tensorlayer/tensorlayer/master/img/tl_transparent_logo.png\n   :target: https://tensorlayer.readthedocs.io/\n.. |JOIN-SLACK-LOGO| image:: https://raw.githubusercontent.com/tensorlayer/tensorlayer/master/img/join_slack.png\n   :target: https://join.slack.com/t/tensorlayer/shared_invite/enQtMjUyMjczMzU2Njg4LWI0MWU0MDFkOWY2YjQ4YjVhMzI5M2VlZmE4YTNhNGY1NjZhMzUwMmQ2MTc0YWRjMjQzMjdjMTg2MWQ2ZWJhYzc\n\n.. |Awesome| image:: https://awesome.re/mentioned-badge.svg\n   :target: https://github.com/tensorlayer/awesome-tensorlayer\n.. |Documentation-EN| image:: https://img.shields.io/badge/documentation-english-blue.svg\n   :target: https://tensorlayer.readthedocs.io/\n.. |Documentation-CN| image:: https://img.shields.io/badge/documentation-%E4%B8%AD%E6%96%87-blue.svg\n   :target: https://tensorlayercn.readthedocs.io/\n.. |Book-CN| image:: https://img.shields.io/badge/book-%E4%B8%AD%E6%96%87-blue.svg\n   :target: http://www.broadview.com.cn/book/5059/\n.. |Downloads| image:: http://pepy.tech/badge/tensorlayer\n   :target: http://pepy.tech/project/tensorlayer\n\n\n.. |PyPI| image:: http://ec2-35-178-47-120.eu-west-2.compute.amazonaws.com/github/release/tensorlayer/tensorlayer.svg?label=PyPI%20-%20Release\n   :target: https://pypi.org/project/tensorlayer/\n.. |PyPI-Prerelease| image:: http://ec2-35-178-47-120.eu-west-2.compute.amazonaws.com/github/release/tensorlayer/tensorlayer/all.svg?label=PyPI%20-%20Pre-Release\n   :target: https://pypi.org/project/tensorlayer/\n.. |Commits-Since| image:: http://ec2-35-178-47-120.eu-west-2.compute.amazonaws.com/github/commits-since/tensorlayer/tensorlayer/latest.svg\n   :target: https://github.com/tensorlayer/tensorlayer/compare/1.10.1...master\n.. |Python| image:: http://ec2-35-178-47-120.eu-west-2.compute.amazonaws.com/pypi/pyversions/tensorlayer.svg\n   :target: https://pypi.org/project/tensorlayer/\n.. |TensorFlow| image:: https://img.shields.io/badge/tensorflow-1.6.0+-blue.svg\n   :target: https://github.com/tensorflow/tensorflow/releases\n\n.. |Travis| image:: http://ec2-35-178-47-120.eu-west-2.compute.amazonaws.com/travis/tensorlayer/tensorlayer/master.svg?label=Travis\n   :target: https://travis-ci.org/tensorlayer/tensorlayer\n.. |Docker| image:: http://ec2-35-178-47-120.eu-west-2.compute.amazonaws.com/circleci/project/github/tensorlayer/tensorlayer/master.svg?label=Docker%20Build\n   :target: https://circleci.com/gh/tensorlayer/tensorlayer/tree/master\n.. |RTD-EN| image:: http://ec2-35-178-47-120.eu-west-2.compute.amazonaws.com/readthedocs/tensorlayer/latest.svg?label=ReadTheDocs-EN\n   :target: https://tensorlayer.readthedocs.io/\n.. |RTD-CN| image:: http://ec2-35-178-47-120.eu-west-2.compute.amazonaws.com/readthedocs/tensorlayercn/latest.svg?label=ReadTheDocs-CN\n   :target: https://tensorlayercn.readthedocs.io/\n.. |PyUP| image:: https://pyup.io/repos/github/tensorlayer/tensorlayer/shield.svg\n   :target: https://pyup.io/repos/github/tensorlayer/tensorlayer/\n.. |Docker-Pulls| image:: http://ec2-35-178-47-120.eu-west-2.compute.amazonaws.com/docker/pulls/tensorlayer/tensorlayer.svg\n   :target: https://hub.docker.com/r/tensorlayer/tensorlayer/\n.. |Code-Quality| image:: https://api.codacy.com/project/badge/Grade/d6b118784e25435498e7310745adb848\n   :target: https://www.codacy.com/app/tensorlayer/tensorlayer\n"
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "img",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 1.6845703125,
          "content": "[tool:pytest]\ntestpaths = tests/\n\n[flake8]\nmax-line-length = 120\nignore =\n    D301\n    E221 # Space before equal sign\n    E251 # Space after equal sign\nexclude =\n    .git,\n    venv,\n    __pycache__,\n    .pytest_cache,\n    tensorlayer.egg-info,\n    build,\n    dist,\n    img\n\n[yapf]\nbased_on_style=google\n\n# The number of columns to use for indentation.\nindent_width = 4\n\n# The column limit. (larger than usual)\ncolumn_limit=120\n\n# Place each dictionary entry onto its own line.\neach_dict_entry_on_separate_line = True\n\n# Put closing brackets on a separate line, dedented, if the bracketed\ndedent_closing_brackets=True\n\n# Do not split consecutive brackets. Only relevant when DEDENT_CLOSING_BRACKETS is set\ncoalesce_brackets = False\n\n# Align closing bracket with visual indentation.\nalign_closing_bracket_with_visual_indent = False\n\n# Split named assignments onto individual lines.\nsplit_before_named_assigns = False\n\n# If an argument / parameter list is going to be split, then split before the first argument.\nsplit_before_first_argument = True\n\n# Split before arguments if the argument list is terminated by a comma.\nsplit_arguments_when_comma_terminated = False\n\n# Insert a space between the ending comma and closing bracket of a list, etc.\nspace_between_ending_comma_and_closing_bracket = True\n\n# Join short lines into one line. E.g., single line if statements.\njoin_multiple_lines = True\n\n# Do not include spaces around selected binary operators.\n# Example: 1 + 2 * 3 - 4 / 5     =>     1 + 2*3 - 4/5\nno_spaces_around_selected_binary_operators = True\n\n# Allow lambdas to be formatted on more than one line.\nallow_multiline_lambdas = True\n\nSPLIT_PENALTY_FOR_ADDED_LINE_SPLIT = 10\nSPLIT_PENALTY_AFTER_OPENING_BRACKET = 500\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 5.455078125,
          "content": "#!/usr/bin/env python\nimport codecs\nimport os\nimport sys\n\nos.environ['TENSORLAYER_PACKAGE_BUILDING'] = 'True'\n\ntry:\n    from setuptools import find_packages, setup, Extension\n    from setuptools.command.build_ext import build_ext\n\nexcept ImportError:\n    from distutils.core import (setup, find_packages)\n\nfrom tensorlayer import (\n    __contact_emails__, __contact_names__, __description__, __download_url__, __homepage__, __keywords__, __license__,\n    __package_name__, __repository_url__, __version__\n)\n\n# =================== Reading Readme file as TXT files ===================\n\nif os.path.exists('README.rst'):\n    # codec is used for consistent encoding\n    long_description = codecs.open(\n        os.path.join(os.path.abspath(os.path.dirname(__file__)), 'README.rst'), 'r', 'utf-8'\n    ).read()\n\nelse:\n    long_description = 'See ' + __homepage__\n\n# ======================= Reading Requirements files as TXT files =======================\n\n\ndef req_file(filename, folder=\"requirements\"):\n    with open(os.path.join(folder, filename)) as f:\n        content = f.readlines()\n    # you may also want to remove whitespace characters\n    # Example: `\\n` at the end of each line\n    return [x.strip() for x in content]\n\n\n# ======================= Defining the requirements var =======================\n\ninstall_requires = req_file(\"requirements.txt\")\n\nextras_require = {\n    # User packages\n    'tf_cpu': req_file(\"requirements_tf_cpu.txt\"),\n    'tf_gpu': req_file(\"requirements_tf_gpu.txt\"),\n    'extra': req_file(\"requirements_extra.txt\"),\n\n    # Contrib Packages\n    'contrib_loggers': req_file(\"requirements_contrib_loggers.txt\"),\n\n    # Dev Packages\n    'test': req_file(\"requirements_test.txt\"),\n    'dev': req_file(\"requirements_dev.txt\"),\n    'doc': req_file(\"requirements_doc.txt\"),\n    'db': req_file(\"requirements_db.txt\"),\n}\n\nextras_require['all'] = sum([extras_require.get(key) for key in ['extra', 'contrib_loggers']], list())\n\nextras_require['all_cpu'] = sum([extras_require.get(key) for key in ['all', 'tf_cpu']], list())\nextras_require['all_gpu'] = sum([extras_require.get(key) for key in ['all', 'tf_gpu']], list())\n\nextras_require['all_dev'] = sum([extras_require.get(key) for key in ['all', 'db', 'dev', 'doc', 'test']], list())\nextras_require['all_cpu_dev'] = sum([extras_require.get(key) for key in ['all_dev', 'tf_cpu']], list())\nextras_require['all_gpu_dev'] = sum([extras_require.get(key) for key in ['all_dev', 'tf_gpu']], list())\n\ncmdclass = dict()\next_modules = []\n\n# Readthedocs requires TF 1.5.0 to build properly\nif 'READTHEDOCS' in os.environ:\n    ext_modules = [\n        Extension('install_requirements_for_rtd', []),\n    ]\n\n    class custom_build_ext(build_ext):\n\n        def build_extensions(self):\n            os.system('./scripts/install-requirements-for-rtd.sh %s' % os.path.dirname(sys.executable))\n\n    cmdclass = {'build_ext': custom_build_ext}\n\n# ======================= Define the package setup =======================\n\nsetup(\n    name=__package_name__,\n\n    # Versions should comply with PEP440.  For a discussion on single-sourcing\n    # the version across setup.py and the project code, see\n    # https://packaging.python.org/en/latest/single_source_version.html\n    version=__version__,\n    description=__description__,\n    long_description=long_description,\n\n    # The project's main homepage.\n    url=__repository_url__,\n    download_url=__download_url__,\n\n    # Author details\n    author=__contact_names__,\n    author_email=__contact_emails__,\n\n    # maintainer Details\n    maintainer=__contact_names__,\n    maintainer_email=__contact_emails__,\n\n    # The licence under which the project is released\n    license=__license__,\n    classifiers=[\n        'Development Status :: 5 - Production/Stable',\n\n        # Indicate who your project is intended for\n        'Intended Audience :: Developers',\n        'Intended Audience :: Science/Research',\n        'Intended Audience :: Information Technology',\n\n        # Indicate what your project relates to\n        'Topic :: Scientific/Engineering',\n        'Topic :: Scientific/Engineering :: Image Recognition',\n        'Topic :: Scientific/Engineering :: Artificial Intelligence',\n        'Topic :: Software Development :: Libraries',\n        'Topic :: Utilities',\n\n        # Pick your license as you wish (should match \"license\" above)\n        'License :: OSI Approved :: Apache Software License',\n\n        # Specify the Python versions you support here. In particular, ensure\n        # that you indicate whether you support Python 2, Python 3 or both.\n        'Programming Language :: Python :: 2',\n        'Programming Language :: Python :: 2.7',\n        'Programming Language :: Python :: 3',\n        'Programming Language :: Python :: 3.5',\n        'Programming Language :: Python :: 3.6',\n\n        # Additionnal Settings\n        'Environment :: Console',\n        'Natural Language :: English',\n        'Operating System :: OS Independent',\n    ],\n    keywords=__keywords__,\n    packages=find_packages(),\n\n    # List run-time dependencies here.  These will be installed by pip when\n    # your project is installed. For an analysis of \"install_requires\" vs pip's\n    # requirements files see:\n    # https://packaging.python.org/en/latest/requirements.html\n    install_requires=install_requires,\n    cmdclass=cmdclass,\n\n    # List additional groups of dependencies here (e.g. development\n    # dependencies). You can install these using the following syntax,\n    # $ pip install -e .[test]\n    extras_require=extras_require,\n    ext_modules=ext_modules,\n    scripts=[\n        'tl',\n    ],\n)\n"
        },
        {
          "name": "setup.travis.cfg",
          "type": "blob",
          "size": 3.4306640625,
          "content": "[tool:pytest]\ntestpaths = tests/\naddopts = --ignore=tests/test_documentation.py\n          --ignore=tests/test_yapf_format.py\n          --ignore=tests/pending/test_decorators.py\n          --ignore=tests/pending/test_documentation.py\n          --ignore=tests/pending/test_logging.py\n          --ignore=tests/pending/test_pydocstyle.py\n          --ignore=tests/pending/test_layers_padding.py\n          --ignore=tests/pending/test_timeout.py\n          --ignore=tests/pending/test_layers_super_resolution.py\n          --ignore=tests/pending/test_reuse_mlp.py\n          --ignore=tests/pending/test_layers_importer.py\n          --ignore=tests/pending/test_layers_time_distributed.py\n          --ignore=tests/pending/test_layers_spatial_transformer.py\n          --ignore=tests/pending/test_layers_stack.py\n          --ignore=tests/pending/test_mnist_simple.py\n          --ignore=tests/pending/test_tf_layers.py\n          --ignore=tests/pending/test_array_ops.py\n          --ignore=tests/pending/test_layers_basic.py\n          --ignore=tests/pending/test_models.py\n          --ignore=tests/pending/test_optimizer_amsgrad.py\n          --ignore=tests/pending/test_logging_hyperdash.py\n          --ignore=tests/pending/test_yapf_format.py\n          --ignore=tests/pending/test_layers_normalization.py\n          --ignore=tests/pending/test_utils_predict.py\n          --ignore=tests/pending/test_layers_flow_control.py\n          --ignore=tests/performance_test/vgg/tl2-autograph.py\n          --ignore=tests/performance_test/vgg/tf2-eager.py\n          --ignore=tests/performance_test/vgg/exp_config.py\n          --ignore=tests/performance_test/vgg/tl2-eager.py\n          --ignore=tests/performance_test/vgg/tf2-autograph.py\n          --ignore=tests/performance_test/vgg/keras_test.py\n          --ignore=tests/performance_test/vgg/pytorch_test.py\n          \n[flake8]\nmax-line-length = 120\nignore =\n    D301\n    E221 # Space before equal sign\n    E251 # Space after equal sign\nexclude =\n    .git,\n    venv,\n    __pycache__,\n    .pytest_cache,\n    tensorlayer.egg-info,\n    build,\n    dist,\n    img\n\n[yapf]\nbased_on_style=google\n\n# The number of columns to use for indentation.\nindent_width = 4\n\n# The column limit.\ncolumn_limit=120\n\n# Place each dictionary entry onto its own line.\neach_dict_entry_on_separate_line = True\n\n# Put closing brackets on a separate line, dedented, if the bracketed\ndedent_closing_brackets=True\n\n# Do not split consecutive brackets. Only relevant when DEDENT_CLOSING_BRACKETS is set\ncoalesce_brackets = False\n\n# Align closing bracket with visual indentation.\nalign_closing_bracket_with_visual_indent = False\n\n# Split named assignments onto individual lines.\nsplit_before_named_assigns = False\n\n# If an argument / parameter list is going to be split, then split before the first argument.\nsplit_before_first_argument = True\n\n# Split before arguments if the argument list is terminated by a comma.\nsplit_arguments_when_comma_terminated = False\n\n# Insert a space between the ending comma and closing bracket of a list, etc.\nspace_between_ending_comma_and_closing_bracket = True\n\n# Join short lines into one line. E.g., single line if statements.\njoin_multiple_lines = True\n\n# Do not include spaces around selected binary operators.\n# Example: 1 + 2 * 3 - 4 / 5     =>     1 + 2*3 - 4/5\nno_spaces_around_selected_binary_operators = True\n\n# Allow lambdas to be formatted on more than one line.\nallow_multiline_lambdas = True\n\nSPLIT_PENALTY_FOR_ADDED_LINE_SPLIT = 10\nSPLIT_PENALTY_AFTER_OPENING_BRACKET = 500\n"
        },
        {
          "name": "setup.travis_doc.cfg",
          "type": "blob",
          "size": 1.728515625,
          "content": "[tool:pytest]\ntestpaths = tests/\npython_files=*test_documentation*\n             *test_yapf_format*\n\n[flake8]\nmax-line-length = 120\nignore =\n    D301\n    E221 # Space before equal sign\n    E251 # Space after equal sign\nexclude =\n    .git,\n    venv,\n    __pycache__,\n    .pytest_cache,\n    tensorlayer.egg-info,\n    build,\n    dist,\n    img\n\n[yapf]\nbased_on_style=google\n\n# The number of columns to use for indentation.\nindent_width = 4\n\n# The column limit.\ncolumn_limit=120\n\n# Place each dictionary entry onto its own line.\neach_dict_entry_on_separate_line = True\n\n# Put closing brackets on a separate line, dedented, if the bracketed\ndedent_closing_brackets=True\n\n# Do not split consecutive brackets. Only relevant when DEDENT_CLOSING_BRACKETS is set\ncoalesce_brackets = False\n\n# Align closing bracket with visual indentation.\nalign_closing_bracket_with_visual_indent = False\n\n# Split named assignments onto individual lines.\nsplit_before_named_assigns = False\n\n# If an argument / parameter list is going to be split, then split before the first argument.\nsplit_before_first_argument = True\n\n# Split before arguments if the argument list is terminated by a comma.\nsplit_arguments_when_comma_terminated = False\n\n# Insert a space between the ending comma and closing bracket of a list, etc.\nspace_between_ending_comma_and_closing_bracket = True\n\n# Join short lines into one line. E.g., single line if statements.\njoin_multiple_lines = True\n\n# Do not include spaces around selected binary operators.\n# Example: 1 + 2 * 3 - 4 / 5     =>     1 + 2*3 - 4/5\nno_spaces_around_selected_binary_operators = True\n\n# Allow lambdas to be formatted on more than one line.\nallow_multiline_lambdas = True\n\nSPLIT_PENALTY_FOR_ADDED_LINE_SPLIT = 10\nSPLIT_PENALTY_AFTER_OPENING_BRACKET = 500"
        },
        {
          "name": "tensorlayer",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "tl",
          "type": "blob",
          "size": 0.490234375,
          "content": "#!/bin/bash\n\nSOURCE=\"${BASH_SOURCE[0]}\"\nwhile [ -h \"$SOURCE\" ]; do # resolve $SOURCE until the file is no longer a symlink\n  DIR=\"$( cd -P \"$( dirname \"$SOURCE\" )\" && pwd )\"\n  SOURCE=\"$(readlink \"$SOURCE\")\"\n  [[ $SOURCE != /* ]] && SOURCE=\"$DIR/$SOURCE\" # if $SOURCE was a relative symlink, we need to resolve it relative to the path where the symlink file was located\ndone\nDIR=\"$( cd -P \"$( dirname \"$SOURCE\" )\" && pwd )\"\n\nexport PYTHONPATH=\"${DIR}/src:${PYTHONPATH}\"\n\npython3 -m tensorlayer.cli \"$@\"\n"
        }
      ]
    }
  ]
}