{
  "metadata": {
    "timestamp": 1736560462349,
    "page": 44,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjUw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "DLR-RM/stable-baselines3",
      "stars": 9509,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.009765625,
          "content": ".gitignore"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.4140625,
          "content": "*.swp\n*.pyc\n*.pkl\n*.py~\n*.bak\n.pytest_cache\n.mypy_cache\n.DS_Store\n.idea\n.vscode\n.coverage\n.coverage.*\n__pycache__/\n_build/\n*.npz\n*.pth\n.pytype/\ngit_rewrite_commit_history.sh\n\n# Setuptools distribution and build folders.\n/dist/\n/build\nkeys/\n\n# Virtualenv\n/env\n/venv\n\n\n*.sublime-project\n*.sublime-workspace\n\n.idea\n\nlogs/\n\n.ipynb_checkpoints\nghostdriver.log\n\nhtmlcov\n\njunk\nsrc\n\n*.egg-info\n.cache\n*.lprof\n*.prof\n\nMUJOCO_LOG.TXT\n"
        },
        {
          "name": ".readthedocs.yml",
          "type": "blob",
          "size": 0.44921875,
          "content": "# Read the Docs configuration file\n# See https://docs.readthedocs.io/en/stable/config-file/v2.html for details\n\n# Required\nversion: 2\n\n# Build documentation in the docs/ directory with Sphinx\nsphinx:\n  configuration: docs/conf.py\n\n# Optionally build your docs in additional formats such as PDF and ePub\nformats: all\n\n# Set requirements using conda env\nconda:\n  environment: docs/conda_env.yml\n\nbuild:\n  os: ubuntu-24.04\n  tools:\n    python: \"mambaforge-23.11\"\n"
        },
        {
          "name": "CITATION.bib",
          "type": "blob",
          "size": 0.408203125,
          "content": "@article{stable-baselines3,\n  author  = {Antonin Raffin and Ashley Hill and Adam Gleave and Anssi Kanervisto and Maximilian Ernestus and Noah Dormann},\n  title   = {Stable-Baselines3: Reliable Reinforcement Learning Implementations},\n  journal = {Journal of Machine Learning Research},\n  year    = {2021},\n  volume  = {22},\n  number  = {268},\n  pages   = {1-8},\n  url     = {http://jmlr.org/papers/v22/20-1364.html}\n}\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 5.1162109375,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nWe as members, contributors, and leaders pledge to make participation in our\ncommunity a harassment-free experience for everyone, regardless of age, body\nsize, visible or invisible disability, ethnicity, sex characteristics, gender\nidentity and expression, level of experience, education, socioeconomic status,\nnationality, personal appearance, race, religion, or sexual identity\nand orientation.\n\nWe pledge to act and interact in ways that contribute to an open, welcoming,\ndiverse, inclusive, and healthy community.\n\n## Our Standards\n\nExamples of behavior that contributes to a positive environment for our\ncommunity include:\n\n* Demonstrating empathy and kindness toward other people\n* Being respectful of differing opinions, viewpoints, and experiences\n* Giving and gracefully accepting constructive feedback\n* Accepting responsibility and apologizing to those affected by our mistakes,\n  and learning from the experience\n* Focusing on what is best not just for us as individuals, but for the\n  overall community\n\nExamples of unacceptable behavior include:\n\n* The use of sexualized language or imagery, and sexual attention or\n  advances of any kind\n* Trolling, insulting or derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or email\n  address, without their explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Enforcement Responsibilities\n\nCommunity leaders are responsible for clarifying and enforcing our standards of\nacceptable behavior and will take appropriate and fair corrective action in\nresponse to any behavior that they deem inappropriate, threatening, offensive,\nor harmful.\n\nCommunity leaders have the right and responsibility to remove, edit, or reject\ncomments, commits, code, wiki edits, issues, and other contributions that are\nnot aligned to this Code of Conduct, and will communicate reasons for moderation\ndecisions when appropriate.\n\n## Scope\n\nThis Code of Conduct applies within all community spaces, and also applies when\nan individual is officially representing the community in public spaces.\nExamples of representing our community include using an official e-mail address,\nposting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported to the community leaders responsible for enforcement at\nantonin [dot] raffin [at] dlr [dot] de.\nAll complaints will be reviewed and investigated promptly and fairly.\n\nAll community leaders are obligated to respect the privacy and security of the\nreporter of any incident.\n\n## Enforcement Guidelines\n\nCommunity leaders will follow these Community Impact Guidelines in determining\nthe consequences for any action they deem in violation of this Code of Conduct:\n\n### 1. Correction\n\n**Community Impact**: Use of inappropriate language or other behavior deemed\nunprofessional or unwelcome in the community.\n\n**Consequence**: A private, written warning from community leaders, providing\nclarity around the nature of the violation and an explanation of why the\nbehavior was inappropriate. A public apology may be requested.\n\n### 2. Warning\n\n**Community Impact**: A violation through a single incident or series\nof actions.\n\n**Consequence**: A warning with consequences for continued behavior. No\ninteraction with the people involved, including unsolicited interaction with\nthose enforcing the Code of Conduct, for a specified period of time. This\nincludes avoiding interactions in community spaces as well as external channels\nlike social media. Violating these terms may lead to a temporary or\npermanent ban.\n\n### 3. Temporary Ban\n\n**Community Impact**: A serious violation of community standards, including\nsustained inappropriate behavior.\n\n**Consequence**: A temporary ban from any sort of interaction or public\ncommunication with the community for a specified period of time. No public or\nprivate interaction with the people involved, including unsolicited interaction\nwith those enforcing the Code of Conduct, is allowed during this period.\nViolating these terms may lead to a permanent ban.\n\n### 4. Permanent Ban\n\n**Community Impact**: Demonstrating a pattern of violation of community\nstandards, including sustained inappropriate behavior,  harassment of an\nindividual, or aggression toward or disparagement of classes of individuals.\n\n**Consequence**: A permanent ban from any sort of public interaction within\nthe community.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage],\nversion 2.0, available at\nhttps://www.contributor-covenant.org/version/2/0/code_of_conduct.html.\n\nCommunity Impact Guidelines were inspired by [Mozilla's code of conduct\nenforcement ladder](https://github.com/mozilla/diversity).\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see the FAQ at\nhttps://www.contributor-covenant.org/faq. Translations are available at\nhttps://www.contributor-covenant.org/translations.\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 3.7646484375,
          "content": "## Contributing to Stable-Baselines3\n\nIf you are interested in contributing to Stable-Baselines, your contributions will fall\ninto two categories:\n1. You want to propose a new Feature and implement it\n    - Create an issue about your intended feature, and we shall discuss the design and\n    implementation. Once we agree that the plan looks good, go ahead and implement it.\n2. You want to implement a feature or bug-fix for an outstanding issue\n    - Look at the outstanding issues here: https://github.com/DLR-RM/stable-baselines3/labels/help%20wanted\n    - Pick an issue or feature and comment on the task that you want to work on this feature.\n    - If you need more context on a particular issue, please ask, and we shall provide.\n\nOnce you finish implementing a feature or bug-fix, please send a Pull Request to\nhttps://github.com/DLR-RM/stable-baselines3\n\n\nIf you are not familiar with creating a Pull Request, here are some guides:\n- http://stackoverflow.com/questions/14680711/how-to-do-a-github-pull-request\n- https://help.github.com/articles/creating-a-pull-request/\n\n\n## Developing Stable-Baselines3\n\nTo develop Stable-Baselines3 on your machine, here are some tips:\n\n1. Clone a copy of Stable-Baselines3 from source:\n\n```bash\ngit clone https://github.com/DLR-RM/stable-baselines3\ncd stable-baselines3/\n```\n\n2. Install Stable-Baselines3 in develop mode, with support for building the docs and running tests:\n\n```bash\npip install -e .[docs,tests,extra]\n```\n\n## Codestyle\n\nWe use [black codestyle](https://github.com/psf/black) (max line length of 127 characters) together with [ruff](https://github.com/astral-sh/ruff) (isort rules) to sort the imports.\nFor the documentation, we use the default line length of 88 characters per line.\n\n**Please run `make format`** to reformat your code. You can check the codestyle using `make check-codestyle` and `make lint`.\n\nPlease document each function/method and [type](https://google.github.io/pytype/user_guide.html) them using the following template:\n\n```python\n\ndef my_function(arg1: type1, arg2: type2) -> returntype:\n    \"\"\"\n    Short description of the function.\n\n    :param arg1: describe what is arg1\n    :param arg2: describe what is arg2\n    :return: describe what is returned\n    \"\"\"\n    ...\n    return my_variable\n```\n\n## Pull Request (PR)\n\nBefore proposing a PR, please open an issue, where the feature will be discussed. This prevents from duplicated PR to be proposed and also ease the code review process.\n\nEach PR need to be reviewed and accepted by at least one of the maintainers (@hill-a, @araffin, @ernestum, @AdamGleave, @Miffyli or @qgallouedec).\nA PR must pass the Continuous Integration tests to be merged with the master branch.\n\n\n## Tests\n\nAll new features must add tests in the `tests/` folder ensuring that everything works fine.\nWe use [pytest](https://pytest.org/).\nAlso, when a bug fix is proposed, tests should be added to avoid regression.\n\nTo run tests with `pytest`:\n\n```\nmake pytest\n```\n\nType checking with `mypy`:\n\n```\nmake type\n```\n\nCodestyle check with `black`, and `ruff` (`isort` rules):\n\n```\nmake check-codestyle\nmake lint\n```\n\nTo run `type`, `format` and `lint` in one command:\n```\nmake commit-checks\n```\n\nBuild the documentation:\n\n```\nmake doc\n```\n\nCheck documentation spelling (you need to install `sphinxcontrib.spelling` package for that):\n\n```\nmake spelling\n```\n\n\n## Changelog and Documentation\n\nPlease do not forget to update the changelog (`docs/misc/changelog.rst`) and add documentation if needed.\nYou should add your username next to each changelog entry that you added. If this is your first contribution, please add your username at the bottom too.\nA README is present in the `docs/` folder for instructions on how to build the documentation.\n\n\nCredits: this contributing guide is based on the [PyTorch](https://github.com/pytorch/pytorch/) one.\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.8779296875,
          "content": "ARG PARENT_IMAGE\nFROM $PARENT_IMAGE\nARG PYTORCH_DEPS=cpuonly\nARG PYTHON_VERSION=3.10\nARG MAMBA_DOCKERFILE_ACTIVATE=1  # (otherwise python will not be found)\n\n# Install micromamba env and dependencies\nRUN micromamba install -n base -y python=$PYTHON_VERSION \\\n    pytorch $PYTORCH_DEPS -c conda-forge -c pytorch -c nvidia && \\\n    micromamba clean --all --yes\n\nENV CODE_DIR /home/$MAMBA_USER\n\n# Copy setup file only to install dependencies\nCOPY --chown=$MAMBA_USER:$MAMBA_USER ./setup.py ${CODE_DIR}/stable-baselines3/setup.py\nCOPY --chown=$MAMBA_USER:$MAMBA_USER ./stable_baselines3/version.txt ${CODE_DIR}/stable-baselines3/stable_baselines3/version.txt\n\nRUN cd ${CODE_DIR}/stable-baselines3 && \\\n    pip install -e .[extra,tests,docs] && \\\n    # Use headless version for docker\n    pip uninstall -y opencv-python && \\\n    pip install opencv-python-headless && \\\n    pip cache purge\n\nCMD /bin/bash\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0498046875,
          "content": "The MIT License\n\nCopyright (c) 2019 Antonin Raffin\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 1.43359375,
          "content": "SHELL=/bin/bash\nLINT_PATHS=stable_baselines3/ tests/ docs/conf.py setup.py\n\npytest:\n\t./scripts/run_tests.sh\n\nmypy:\n\tmypy ${LINT_PATHS}\n\nmissing-annotations:\n\tmypy --disallow-untyped-calls --disallow-untyped-defs --ignore-missing-imports stable_baselines3\n\n# missing docstrings\n# pylint -d R,C,W,E -e C0116 stable_baselines3 -j 4\n\ntype: mypy\n\nlint:\n\t# stop the build if there are Python syntax errors or undefined names\n\t# see https://www.flake8rules.com/\n\truff check ${LINT_PATHS} --select=E9,F63,F7,F82 --output-format=full\n\t# exit-zero treats all errors as warnings.\n\truff check ${LINT_PATHS} --exit-zero --output-format=concise\n\nformat:\n\t# Sort imports\n\truff check --select I ${LINT_PATHS} --fix\n\t# Reformat using black\n\tblack ${LINT_PATHS}\n\ncheck-codestyle:\n\t# Sort imports\n\truff check --select I ${LINT_PATHS}\n\t# Reformat using black\n\tblack --check ${LINT_PATHS}\n\ncommit-checks: format type lint\n\ndoc:\n\tcd docs && make html\n\nspelling:\n\tcd docs && make spelling\n\nclean:\n\tcd docs && make clean\n\n# Build docker images\n# If you do export RELEASE=True, it will also push them\ndocker: docker-cpu docker-gpu\n\ndocker-cpu:\n\t./scripts/build_docker.sh\n\ndocker-gpu:\n\tUSE_GPU=True ./scripts/build_docker.sh\n\n# PyPi package release\nrelease:\n\tpython -m build\n\ttwine upload dist/*\n\n# Test PyPi package release\ntest-release:\n\tpython -m build\n\ttwine upload --repository-url https://test.pypi.org/legacy/ dist/*\n\n.PHONY: clean spelling doc lint format check-codestyle commit-checks\n"
        },
        {
          "name": "NOTICE",
          "type": "blob",
          "size": 1.306640625,
          "content": "Large portion of the code of Stable-Baselines3 (in `common/`) were ported from Stable-Baselines, a fork of OpenAI Baselines,\nboth licensed under the MIT License:\n\nbefore the fork (June 2018):\nCopyright (c) 2017 OpenAI (http://openai.com)\n\nafter the fork (June 2018):\nCopyright (c) 2018-2019 Stable-Baselines Team\n\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 15.294921875,
          "content": "<!-- [![pipeline status](https://gitlab.com/araffin/stable-baselines3/badges/master/pipeline.svg)](https://gitlab.com/araffin/stable-baselines3/-/commits/master) -->\n[![CI](https://github.com/DLR-RM/stable-baselines3/workflows/CI/badge.svg)](https://github.com/DLR-RM/stable-baselines3/actions/workflows/ci.yml)\n[![Documentation Status](https://readthedocs.org/projects/stable-baselines/badge/?version=master)](https://stable-baselines3.readthedocs.io/en/master/?badge=master) [![coverage report](https://gitlab.com/araffin/stable-baselines3/badges/master/coverage.svg)](https://github.com/DLR-RM/stable-baselines3/actions/workflows/ci.yml)\n[![codestyle](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n\n\n# Stable Baselines3\n\n<img src=\"docs/\\_static/img/logo.png\" align=\"right\" width=\"40%\"/>\n\nStable Baselines3 (SB3) is a set of reliable implementations of reinforcement learning algorithms in PyTorch. It is the next major version of [Stable Baselines](https://github.com/hill-a/stable-baselines).\n\nYou can read a detailed presentation of Stable Baselines3 in the [v1.0 blog post](https://araffin.github.io/post/sb3/) or our [JMLR paper](https://jmlr.org/papers/volume22/20-1364/20-1364.pdf).\n\n\nThese algorithms will make it easier for the research community and industry to replicate, refine, and identify new ideas, and will create good baselines to build projects on top of. We expect these tools will be used as a base around which new ideas can be added, and as a tool for comparing a new approach against existing ones. We also hope that the simplicity of these tools will allow beginners to experiment with a more advanced toolset, without being buried in implementation details.\n\n**Note: Despite its simplicity of use, Stable Baselines3 (SB3) assumes you have some knowledge about Reinforcement Learning (RL).** You should not utilize this library without some practice. To that extent, we provide good resources in the [documentation](https://stable-baselines3.readthedocs.io/en/master/guide/rl.html) to get started with RL.\n\n## Main Features\n\n**The performance of each algorithm was tested** (see *Results* section in their respective page),\nyou can take a look at the issues [#48](https://github.com/DLR-RM/stable-baselines3/issues/48) and [#49](https://github.com/DLR-RM/stable-baselines3/issues/49) for more details.\n\nWe also provide detailed logs and reports on the [OpenRL Benchmark](https://wandb.ai/openrlbenchmark/sb3) platform.\n\n\n| **Features**                | **Stable-Baselines3** |\n| --------------------------- | ----------------------|\n| State of the art RL methods | :heavy_check_mark: |\n| Documentation               | :heavy_check_mark: |\n| Custom environments         | :heavy_check_mark: |\n| Custom policies             | :heavy_check_mark: |\n| Common interface            | :heavy_check_mark: |\n| `Dict` observation space support  | :heavy_check_mark: |\n| Ipython / Notebook friendly | :heavy_check_mark: |\n| Tensorboard support         | :heavy_check_mark: |\n| PEP8 code style             | :heavy_check_mark: |\n| Custom callback             | :heavy_check_mark: |\n| High code coverage          | :heavy_check_mark: |\n| Type hints                  | :heavy_check_mark: |\n\n\n### Planned features\n\nSince most of the features from the [original roadmap](https://github.com/DLR-RM/stable-baselines3/issues/1) have been implemented, there are no major changes planned for SB3, it is now *stable*.\nIf you want to contribute, you can search in the issues for the ones where [help is welcomed](https://github.com/DLR-RM/stable-baselines3/labels/help%20wanted) and the other [proposed enhancements](https://github.com/DLR-RM/stable-baselines3/labels/enhancement).\n\nWhile SB3 development is now focused on bug fixes and maintenance (doc update, user experience, ...), there is more active development going on in the associated repositories:\n- newer algorithms are regularly added to the [SB3 Contrib](https://github.com/Stable-Baselines-Team/stable-baselines3-contrib) repository\n- faster variants are developed in the [SBX (SB3 + Jax)](https://github.com/araffin/sbx) repository\n- the training framework for SB3, the RL Zoo, has an active [roadmap](https://github.com/DLR-RM/rl-baselines3-zoo/issues/299)\n\n## Migration guide: from Stable-Baselines (SB2) to Stable-Baselines3 (SB3)\n\nA migration guide from SB2 to SB3 can be found in the [documentation](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html).\n\n## Documentation\n\nDocumentation is available online: [https://stable-baselines3.readthedocs.io/](https://stable-baselines3.readthedocs.io/)\n\n## Integrations\n\nStable-Baselines3 has some integration with other libraries/services like Weights & Biases for experiment tracking or Hugging Face for storing/sharing trained models. You can find out more in the [dedicated section](https://stable-baselines3.readthedocs.io/en/master/guide/integrations.html) of the documentation.\n\n\n## RL Baselines3 Zoo: A Training Framework for Stable Baselines3 Reinforcement Learning Agents\n\n[RL Baselines3 Zoo](https://github.com/DLR-RM/rl-baselines3-zoo) is a training framework for Reinforcement Learning (RL).\n\nIt provides scripts for training, evaluating agents, tuning hyperparameters, plotting results and recording videos.\n\nIn addition, it includes a collection of tuned hyperparameters for common environments and RL algorithms, and agents trained with those settings.\n\nGoals of this repository:\n\n1. Provide a simple interface to train and enjoy RL agents\n2. Benchmark the different Reinforcement Learning algorithms\n3. Provide tuned hyperparameters for each environment and RL algorithm\n4. Have fun with the trained agents!\n\nGithub repo: https://github.com/DLR-RM/rl-baselines3-zoo\n\nDocumentation: https://rl-baselines3-zoo.readthedocs.io/en/master/\n\n## SB3-Contrib: Experimental RL Features\n\nWe implement experimental features in a separate contrib repository: [SB3-Contrib](https://github.com/Stable-Baselines-Team/stable-baselines3-contrib)\n\nThis allows SB3 to maintain a stable and compact core, while still providing the latest features, like Recurrent PPO (PPO LSTM), CrossQ, Truncated Quantile Critics (TQC), Quantile Regression DQN (QR-DQN) or PPO with invalid action masking (Maskable PPO).\n\nDocumentation is available online: [https://sb3-contrib.readthedocs.io/](https://sb3-contrib.readthedocs.io/)\n\n## Stable-Baselines Jax (SBX)\n\n[Stable Baselines Jax (SBX)](https://github.com/araffin/sbx) is a proof of concept version of Stable-Baselines3 in Jax, with recent algorithms like DroQ or CrossQ.\n\nIt provides a minimal number of features compared to SB3 but can be much faster (up to 20x times!): https://twitter.com/araffin2/status/1590714558628253698\n\n\n## Installation\n\n**Note:** Stable-Baselines3 supports PyTorch >= 2.3\n\n### Prerequisites\nStable Baselines3 requires Python 3.9+.\n\n#### Windows\n\nTo install stable-baselines on Windows, please look at the [documentation](https://stable-baselines3.readthedocs.io/en/master/guide/install.html#prerequisites).\n\n\n### Install using pip\nInstall the Stable Baselines3 package:\n```sh\npip install 'stable-baselines3[extra]'\n```\n\nThis includes an optional dependencies like Tensorboard, OpenCV or `ale-py` to train on atari games. If you do not need those, you can use:\n```sh\npip install stable-baselines3\n```\n\nPlease read the [documentation](https://stable-baselines3.readthedocs.io/) for more details and alternatives (from source, using docker).\n\n\n## Example\n\nMost of the code in the library tries to follow a sklearn-like syntax for the Reinforcement Learning algorithms.\n\nHere is a quick example of how to train and run PPO on a cartpole environment:\n```python\nimport gymnasium as gym\n\nfrom stable_baselines3 import PPO\n\nenv = gym.make(\"CartPole-v1\", render_mode=\"human\")\n\nmodel = PPO(\"MlpPolicy\", env, verbose=1)\nmodel.learn(total_timesteps=10_000)\n\nvec_env = model.get_env()\nobs = vec_env.reset()\nfor i in range(1000):\n    action, _states = model.predict(obs, deterministic=True)\n    obs, reward, done, info = vec_env.step(action)\n    vec_env.render()\n    # VecEnv resets automatically\n    # if done:\n    #   obs = env.reset()\n\nenv.close()\n```\n\nOr just train a model with a one liner if [the environment is registered in Gymnasium](https://gymnasium.farama.org/tutorials/gymnasium_basics/environment_creation/#registering-envs) and if [the policy is registered](https://stable-baselines3.readthedocs.io/en/master/guide/custom_policy.html):\n\n```python\nfrom stable_baselines3 import PPO\n\nmodel = PPO(\"MlpPolicy\", \"CartPole-v1\").learn(10_000)\n```\n\nPlease read the [documentation](https://stable-baselines3.readthedocs.io/) for more examples.\n\n\n## Try it online with Colab Notebooks !\n\nAll the following examples can be executed online using Google Colab notebooks:\n\n- [Full Tutorial](https://github.com/araffin/rl-tutorial-jnrr19)\n- [All Notebooks](https://github.com/Stable-Baselines-Team/rl-colab-notebooks/tree/sb3)\n- [Getting Started](https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/stable_baselines_getting_started.ipynb)\n- [Training, Saving, Loading](https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/saving_loading_dqn.ipynb)\n- [Multiprocessing](https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/multiprocessing_rl.ipynb)\n- [Monitor Training and Plotting](https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/monitor_training.ipynb)\n- [Atari Games](https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/atari_games.ipynb)\n- [RL Baselines Zoo](https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/rl-baselines-zoo.ipynb)\n- [PyBullet](https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/pybullet.ipynb)\n\n\n## Implemented Algorithms\n\n| **Name**         | **Recurrent**      | `Box`          | `Discrete`     | `MultiDiscrete` | `MultiBinary`  | **Multi Processing**              |\n| ------------------- | ------------------ | ------------------ | ------------------ | ------------------- | ------------------ | --------------------------------- |\n| ARS<sup>[1](#f1)</sup>   | :x: | :heavy_check_mark: | :heavy_check_mark: | :x: | :x: | :heavy_check_mark: |\n| A2C   | :x: | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark: |\n| CrossQ<sup>[1](#f1)</sup>   | :x: | :heavy_check_mark: | :x:                | :x:                 | :x:                | :heavy_check_mark: |\n| DDPG  | :x: | :heavy_check_mark: | :x:                | :x:                 | :x:                | :heavy_check_mark: |\n| DQN   | :x: | :x: | :heavy_check_mark: | :x:                 | :x:                | :heavy_check_mark: |\n| HER   | :x: | :heavy_check_mark: | :heavy_check_mark: | :x: | :x: | :heavy_check_mark: |\n| PPO   | :x: | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark:  | :heavy_check_mark: | :heavy_check_mark: |\n| QR-DQN<sup>[1](#f1)</sup>  | :x: | :x: | :heavy_check_mark: | :x:                 | :x:                | :heavy_check_mark: |\n| RecurrentPPO<sup>[1](#f1)</sup>   | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark:  | :heavy_check_mark: | :heavy_check_mark: |\n| SAC   | :x: | :heavy_check_mark: | :x:                | :x:                 | :x:                | :heavy_check_mark: |\n| TD3   | :x: | :heavy_check_mark: | :x:                | :x:                 | :x:                | :heavy_check_mark: |\n| TQC<sup>[1](#f1)</sup>   | :x: | :heavy_check_mark: | :x:                | :x:                 | :x: | :heavy_check_mark: |\n| TRPO<sup>[1](#f1)</sup>  | :x: | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark:  | :heavy_check_mark: | :heavy_check_mark: |\n| Maskable PPO<sup>[1](#f1)</sup>   | :x: | :x: | :heavy_check_mark: | :heavy_check_mark:  | :heavy_check_mark: | :heavy_check_mark:  |\n\n<b id=\"f1\">1</b>: Implemented in [SB3 Contrib](https://github.com/Stable-Baselines-Team/stable-baselines3-contrib) GitHub repository.\n\nActions `gymnasium.spaces`:\n * `Box`: A N-dimensional box that contains every point in the action space.\n * `Discrete`: A list of possible actions, where each timestep only one of the actions can be used.\n * `MultiDiscrete`: A list of possible actions, where each timestep only one action of each discrete set can be used.\n * `MultiBinary`: A list of possible actions, where each timestep any of the actions can be used in any combination.\n\n\n\n## Testing the installation\n### Install dependencies\n```sh\npip install -e .[docs,tests,extra]\n```\n### Run tests\nAll unit tests in stable baselines3 can be run using `pytest` runner:\n```sh\nmake pytest\n```\nTo run a single test file:\n```sh\npython3 -m pytest -v tests/test_env_checker.py\n```\nTo run a single test:\n```sh\npython3 -m pytest -v -k 'test_check_env_dict_action'\n```\n\nYou can also do a static type check using `mypy`:\n```sh\npip install mypy\nmake type\n```\n\nCodestyle check with `ruff`:\n```sh\npip install ruff\nmake lint\n```\n\n## Projects Using Stable-Baselines3\n\nWe try to maintain a list of projects using stable-baselines3 in the [documentation](https://stable-baselines3.readthedocs.io/en/master/misc/projects.html),\nplease tell us if you want your project to appear on this page ;)\n\n## Citing the Project\n\nTo cite this repository in publications:\n\n```bibtex\n@article{stable-baselines3,\n  author  = {Antonin Raffin and Ashley Hill and Adam Gleave and Anssi Kanervisto and Maximilian Ernestus and Noah Dormann},\n  title   = {Stable-Baselines3: Reliable Reinforcement Learning Implementations},\n  journal = {Journal of Machine Learning Research},\n  year    = {2021},\n  volume  = {22},\n  number  = {268},\n  pages   = {1-8},\n  url     = {http://jmlr.org/papers/v22/20-1364.html}\n}\n```\n\nNote: If you need to refer to a specific version of SB3, you can also use the [Zenodo DOI](https://doi.org/10.5281/zenodo.8123988).\n\n## Maintainers\n\nStable-Baselines3 is currently maintained by [Ashley Hill](https://github.com/hill-a) (aka @hill-a), [Antonin Raffin](https://araffin.github.io/) (aka [@araffin](https://github.com/araffin)), [Maximilian Ernestus](https://github.com/ernestum) (aka @ernestum), [Adam Gleave](https://github.com/adamgleave) (@AdamGleave), [Anssi Kanervisto](https://github.com/Miffyli) (@Miffyli) and [Quentin Gallouédec](https://gallouedec.com/) (@qgallouedec).\n\n**Important Note: We do not provide technical support, or consulting** and do not answer personal questions via email.\nPlease post your question on the [RL Discord](https://discord.com/invite/xhfNqQv), [Reddit](https://www.reddit.com/r/reinforcementlearning/), or [Stack Overflow](https://stackoverflow.com/) in that case.\n\n\n## How To Contribute\n\nTo any interested in making the baselines better, there is still some documentation that needs to be done.\nIf you want to contribute, please read [**CONTRIBUTING.md**](./CONTRIBUTING.md) guide first.\n\n## Acknowledgments\n\nThe initial work to develop Stable Baselines3 was partially funded by the project *Reduced Complexity Models* from the *Helmholtz-Gemeinschaft Deutscher Forschungszentren*, and by the EU's Horizon 2020 Research and Innovation Programme under grant number 951992 ([VeriDream](https://www.veridream.eu/)).\n\nThe original version, Stable Baselines, was created in the [robotics lab U2IS](http://u2is.ensta-paristech.fr/index.php?lang=en) ([INRIA Flowers](https://flowers.inria.fr/) team) at [ENSTA ParisTech](http://www.ensta-paristech.fr/en).\n\n\nLogo credits: [L.M. Tenkes](https://www.instagram.com/lucillehue/)\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 1.806640625,
          "content": "[tool.ruff]\n# Same as Black.\nline-length = 127\n# Assume Python 3.9\ntarget-version = \"py39\"\n\n[tool.ruff.lint]\n# See https://beta.ruff.rs/docs/rules/\nselect = [\"E\", \"F\", \"B\", \"UP\", \"C90\", \"RUF\"]\n# B028: Ignore explicit stacklevel`\n# RUF013: Too many false positives (implicit optional)\nignore = [\"B028\", \"RUF013\"]\n\n[tool.ruff.lint.per-file-ignores]\n# Default implementation in abstract methods\n\"./stable_baselines3/common/callbacks.py\" = [\"B027\"]\n\"./stable_baselines3/common/noise.py\" = [\"B027\"]\n# ClassVar, implicit optional check not needed for tests\n\"./tests/*.py\" = [\"RUF012\", \"RUF013\"]\n\n[tool.ruff.lint.mccabe]\n# Unlike Flake8, default to a complexity level of 10.\nmax-complexity = 15\n\n[tool.black]\nline-length = 127\n\n[tool.mypy]\nignore_missing_imports = true\nfollow_imports = \"silent\"\nshow_error_codes = true\nexclude = \"\"\"(?x)(\n    tests/test_logger.py$\n    | tests/test_train_eval_mode.py$\n  )\"\"\"\n\n[tool.pytest.ini_options]\n# Deterministic ordering for tests; useful for pytest-xdist.\nenv = [\"PYTHONHASHSEED=0\"]\n\nfilterwarnings = [\n    # A2C/PPO on GPU\n    \"ignore:You are trying to run (PPO|A2C) on the GPU\",\n    # Tensorboard warnings\n    \"ignore::DeprecationWarning:tensorboard\",\n    # Gymnasium warnings\n    \"ignore::UserWarning:gymnasium\",\n    # tqdm warning about rich being experimental\n    \"ignore:rich is experimental\",\n]\nmarkers = [\n    \"expensive: marks tests as expensive (deselect with '-m \\\"not expensive\\\"')\",\n]\n\n[tool.coverage.run]\ndisable_warnings = [\"couldnt-parse\"]\nbranch = false\nomit = [\n    \"tests/*\",\n    \"setup.py\",\n    # Require graphical interface\n    \"stable_baselines3/common/results_plotter.py\",\n    # Require ffmpeg\n    \"stable_baselines3/common/vec_env/vec_video_recorder.py\",\n]\n\n[tool.coverage.report]\nexclude_lines = [\n    \"pragma: no cover\",\n    \"raise NotImplementedError()\",\n    \"if typing.TYPE_CHECKING:\",\n]\n"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 5.251953125,
          "content": "import os\n\nfrom setuptools import find_packages, setup\n\nwith open(os.path.join(\"stable_baselines3\", \"version.txt\")) as file_handler:\n    __version__ = file_handler.read().strip()\n\n\nlong_description = \"\"\"\n\n# Stable Baselines3\n\nStable Baselines3 is a set of reliable implementations of reinforcement learning algorithms in PyTorch. It is the next major version of [Stable Baselines](https://github.com/hill-a/stable-baselines).\n\nThese algorithms will make it easier for the research community and industry to replicate, refine, and identify new ideas, and will create good baselines to build projects on top of. We expect these tools will be used as a base around which new ideas can be added, and as a tool for comparing a new approach against existing ones. We also hope that the simplicity of these tools will allow beginners to experiment with a more advanced toolset, without being buried in implementation details.\n\n\n## Links\n\nRepository:\nhttps://github.com/DLR-RM/stable-baselines3\n\nBlog post:\nhttps://araffin.github.io/post/sb3/\n\nDocumentation:\nhttps://stable-baselines3.readthedocs.io/en/master/\n\nRL Baselines3 Zoo:\nhttps://github.com/DLR-RM/rl-baselines3-zoo\n\nSB3 Contrib:\nhttps://github.com/Stable-Baselines-Team/stable-baselines3-contrib\n\n## Quick example\n\nMost of the library tries to follow a sklearn-like syntax for the Reinforcement Learning algorithms using Gym.\n\nHere is a quick example of how to train and run PPO on a cartpole environment:\n\n```python\nimport gymnasium\n\nfrom stable_baselines3 import PPO\n\nenv = gymnasium.make(\"CartPole-v1\", render_mode=\"human\")\n\nmodel = PPO(\"MlpPolicy\", env, verbose=1)\nmodel.learn(total_timesteps=10_000)\n\nvec_env = model.get_env()\nobs = vec_env.reset()\nfor i in range(1000):\n    action, _states = model.predict(obs, deterministic=True)\n    obs, reward, done, info = vec_env.step(action)\n    vec_env.render()\n    # VecEnv resets automatically\n    # if done:\n    #   obs = vec_env.reset()\n\n```\n\nOr just train a model with a one liner if [the environment is registered in Gymnasium](https://gymnasium.farama.org/tutorials/gymnasium_basics/environment_creation/) and if [the policy is registered](https://stable-baselines3.readthedocs.io/en/master/guide/custom_policy.html):\n\n```python\nfrom stable_baselines3 import PPO\n\nmodel = PPO(\"MlpPolicy\", \"CartPole-v1\").learn(10_000)\n```\n\n\"\"\"  # noqa:E501\n\n\nsetup(\n    name=\"stable_baselines3\",\n    packages=[package for package in find_packages() if package.startswith(\"stable_baselines3\")],\n    package_data={\"stable_baselines3\": [\"py.typed\", \"version.txt\"]},\n    install_requires=[\n        \"gymnasium>=0.29.1,<1.1.0\",\n        \"numpy>=1.20,<3.0\",\n        \"torch>=2.3,<3.0\",\n        # For saving models\n        \"cloudpickle\",\n        # For reading logs\n        \"pandas\",\n        # Plotting learning curves\n        \"matplotlib\",\n    ],\n    extras_require={\n        \"tests\": [\n            # Run tests and coverage\n            \"pytest\",\n            \"pytest-cov\",\n            \"pytest-env\",\n            \"pytest-xdist\",\n            # Type check\n            \"mypy\",\n            # Lint code and sort imports (flake8 and isort replacement)\n            \"ruff>=0.3.1\",\n            # Reformat\n            \"black>=24.2.0,<25\",\n        ],\n        \"docs\": [\n            \"sphinx>=5,<9\",\n            \"sphinx-autobuild\",\n            \"sphinx-rtd-theme>=1.3.0\",\n            # For spelling\n            \"sphinxcontrib.spelling\",\n            # Copy button for code snippets\n            \"sphinx_copybutton\",\n        ],\n        \"extra\": [\n            # For render\n            \"opencv-python\",\n            \"pygame\",\n            # Tensorboard support\n            \"tensorboard>=2.9.1\",\n            # Checking memory taken by replay buffer\n            \"psutil\",\n            # For progress bar callback\n            \"tqdm\",\n            \"rich\",\n            # For atari games,\n            \"ale-py>=0.9.0\",\n            \"pillow\",\n        ],\n    },\n    description=\"Pytorch version of Stable Baselines, implementations of reinforcement learning algorithms.\",\n    author=\"Antonin Raffin\",\n    url=\"https://github.com/DLR-RM/stable-baselines3\",\n    author_email=\"antonin.raffin@dlr.de\",\n    keywords=\"reinforcement-learning-algorithms reinforcement-learning machine-learning \"\n    \"gymnasium gym openai stable baselines toolbox python data-science\",\n    license=\"MIT\",\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    version=__version__,\n    python_requires=\">=3.9\",\n    # PyPI package information.\n    project_urls={\n        \"Code\": \"https://github.com/DLR-RM/stable-baselines3\",\n        \"Documentation\": \"https://stable-baselines3.readthedocs.io/\",\n        \"Changelog\": \"https://stable-baselines3.readthedocs.io/en/master/misc/changelog.html\",\n        \"SB3-Contrib\": \"https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\",\n        \"RL-Zoo\": \"https://github.com/DLR-RM/rl-baselines3-zoo\",\n        \"SBX\": \"https://github.com/araffin/sbx\",\n    },\n    classifiers=[\n        \"Programming Language :: Python :: 3\",\n        \"Programming Language :: Python :: 3.9\",\n        \"Programming Language :: Python :: 3.10\",\n        \"Programming Language :: Python :: 3.11\",\n        \"Programming Language :: Python :: 3.12\",\n    ],\n)\n\n# python setup.py sdist\n# python setup.py bdist_wheel\n# twine upload --repository-url https://test.pypi.org/legacy/ dist/*\n# twine upload dist/*\n"
        },
        {
          "name": "stable_baselines3",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}