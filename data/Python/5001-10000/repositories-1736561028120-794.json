{
  "metadata": {
    "timestamp": 1736561028120,
    "page": 794,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjgwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "QwenLM/Qwen-Agent",
      "stars": 5226,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.5712890625,
          "content": "env\n*.pyc\n__pycache__\n\n.idea\n.vscode\n.DS_Store\n*.ipynb_checkpoints\n\nqwen_agent/llm/gpt.py\nqwen_agent/llm/tools.py\nworkspace/*\n\nbenchmark/log/*\nbenchmark/output_data/*\nbenchmark/upload_file/*\nbenchmark/upload_file_clean/*\nbenchmark/eval_data/\nQwen-Agent\n\ndocqa/*\nlog/*\nlog.jsonl\n\nai_agent/debug.json\nai_agent/local_prompts/*\n**/debug.json\n**/debug.log*\ndebug.json\nai_agent/log.jsonl\nqwen_agent.egg-info/*\nbuild/*\ndist/*\n\nexamples/*.ipynb\n**/workspace/*\ntest/*\ntests/env.sh\nexamples/docqa_multi_agent.py\nexamples/docqa_multihp_agents.py\n**/workspace/*\ntest/*\ntests/env.sh\nexamples/data/*"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.8759765625,
          "content": "repos:\n  - repo: https://github.com/pycqa/flake8.git\n    rev: 5.0.4\n    hooks:\n      - id: flake8\n        args: [\"--max-line-length=300\"]  # TODO: Set to 120 and `pre-commit run --all-files`.\n  - repo: https://github.com/PyCQA/isort.git\n    rev: 5.11.5\n    hooks:\n      - id: isort\n        args: [\"--line-length\", \"120\"]\n  - repo: https://github.com/pre-commit/mirrors-yapf.git\n    rev: v0.32.0\n    hooks:\n      - id: yapf\n        args: [\"--style\", \"{based_on_style: google, column_limit: 120}\", \"-i\"]\n  - repo: https://github.com/pre-commit/pre-commit-hooks.git\n    rev: v4.3.0\n    hooks:\n      - id: trailing-whitespace\n      - id: check-yaml\n      - id: end-of-file-fixer\n      - id: requirements-txt-fixer\n      - id: double-quote-string-fixer\n      - id: check-merge-conflict\n      - id: fix-encoding-pragma\n        args: [\"--remove\"]\n      - id: mixed-line-ending\n        args: [\"--fix=lf\"]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 6.7353515625,
          "content": "Tongyi Qianwen LICENSE AGREEMENT\n\nTongyi Qianwen Release Date: August 3, 2023\n\nBy clicking to agree or by using or distributing any portion or element of the Tongyi Qianwen Materials, you will be deemed to have recognized and accepted the content of this Agreement, which is effective immediately.\n\n1. Definitions\n    a. This Tongyi Qianwen LICENSE AGREEMENT (this \"Agreement\") shall mean the terms and conditions for use, reproduction, distribution and modification of the Materials as defined by this Agreement.\n    b. \"We\"(or \"Us\") shall mean Alibaba Cloud.\n    c. \"You\" (or \"Your\") shall mean a natural person or legal entity exercising the rights granted by this Agreement and/or using the Materials for any purpose and in any field of use.\n    d. \"Third Parties\" shall mean individuals or legal entities that are not under common control with Us or You.\n    e. \"Tongyi Qianwen\" shall mean the large language models (including Qwen model and Qwen-Chat model), and software and algorithms, consisting of trained model weights, parameters (including optimizer states), machine-learning model code, inference-enabling code, training-enabling code, fine-tuning enabling code and other elements of the foregoing distributed by Us.\n    f. \"Materials\" shall mean, collectively, Alibaba Cloud's proprietary Tongyi Qianwen and Documentation (and any portion thereof) made available under this Agreement.\n    g. \"Source\" form shall mean the preferred form for making modifications, including but not limited to model source code, documentation source, and configuration files.\n    h. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation,\n and conversions to other media types.\n\n2. Grant of Rights\nYou are granted a non-exclusive, worldwide, non-transferable and royalty-free limited license under Alibaba Cloud's intellectual property or other rights owned by Us embodied in the Materials to use, reproduce, distribute, copy, create derivative works of, and make modifications to the Materials.\n\n3. Redistribution\nYou may reproduce and distribute copies of the Materials or derivative works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions:\n    a. You shall give any other recipients of the Materials or derivative works a copy of this Agreement;\n    b. You shall cause any modified files to carry prominent notices stating that You changed the files;\n    c. You shall retain in all copies of the Materials that You distribute the following attribution notices within a \"Notice\" text file distributed as a part of such copies: \"Tongyi Qianwen is licensed under the Tongyi Qianwen LICENSE AGREEMENT, Copyright (c) Alibaba Cloud. All Rights Reserved.\"; and\n    d. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such derivative works as a whole, provided Your use, reproduction, and distribution of the work otherwise complies with the terms and conditions of this Agreement.\n\n4. Restrictions\nIf you are commercially using the Materials, and your product or service has more than 100 million monthly active users, You shall request a license from Us. You cannot exercise your rights under this Agreement without our express authorization.\n\n5. Rules of use\n    a. The Materials may be subject to export controls or restrictions in China, the United States or other countries or regions. You shall comply with applicable laws and regulations in your use of the Materials.\n    b. You can not use the Materials or any output therefrom to improve any other large language model (excluding Tongyi Qianwen or derivative works thereof).\n\n6. Intellectual Property\n    a. We retain ownership of all intellectual property rights in and to the Materials and derivatives made by or for Us. Conditioned upon compliance with the terms and conditions of this Agreement, with respect to any derivative works and modifications of the Materials that are made by you, you are and will be the owner of such derivative works and modifications.\n    b. No trademark license is granted to use the trade names, trademarks, service marks, or product names of Us, except as required to fulfill notice requirements under this Agreement or as required for reasonable and customary use in describing and redistributing the Materials.\n    c. If you commence a lawsuit or other proceedings (including a cross-claim or counterclaim in a lawsuit) against Us or any entity alleging that the Materials or any output therefrom, or any part of the foregoing, infringe any intellectual property or other right owned or licensable by you, then all licences granted to you under this Agreement shall terminate as of the date such lawsuit or other proceeding is commenced or brought.\n\n7. Disclaimer of Warranty and Limitation of Liability\n\n    a. We are not obligated to support, update, provide training for, or develop any further version of the Tongyi Qianwen Materials or to grant any license thereto.\n    b. THE MATERIALS ARE PROVIDED \"AS IS\" WITHOUT ANY EXPRESS OR IMPLIED WARRANTY OF ANY KIND INCLUDING WARRANTIES OF MERCHANTABILITY, NONINFRINGEMENT, OR FITNESS FOR A PARTICULAR PURPOSE. WE MAKE NO WARRANTY AND ASSUME NO RESPONSIBILITY FOR THE SAFETY OR STABILITY OF THE MATERIALS AND ANY OUTPUT THEREFROM.\n    c. IN NO EVENT SHALL WE BE LIABLE TO YOU FOR ANY DAMAGES, INCLUDING, BUT NOT LIMITED TO ANY DIRECT, OR INDIRECT, SPECIAL OR CONSEQUENTIAL DAMAGES ARISING FROM YOUR USE OR INABILITY TO USE THE MATERIALS OR ANY OUTPUT OF IT, NO MATTER HOW ITâ€™S CAUSED.\n    d. You will defend, indemnify and hold harmless Us from and against any claim by any third party arising out of or related to your use or distribution of the Materials.\n\n8. Survival and Termination.\n    a. The term of this Agreement shall commence upon your acceptance of this Agreement or access to the Materials and will continue in full force and effect until terminated in accordance with the terms and conditions herein.\n    b. We may terminate this Agreement if you breach any of the terms or conditions of this Agreement. Upon termination of this Agreement, you must delete and cease use of the Materials. Sections 7 and 9 shall survive the termination of this Agreement.\n\n9. Governing Law and Jurisdiction.\n    a. This Agreement and any dispute arising out of or relating to it will be governed by the laws of China, without regard to conflict of law principles, and the UN Convention on Contracts for the International Sale of Goods does not apply to this Agreement.\n    b. The People's Courts in Hangzhou City shall have exclusive jurisdiction over any dispute arising out of this Agreement.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.0830078125,
          "content": "include qwen_agent/utils/qwen.tiktoken\nrecursive-include qwen_agent/tools/resource *\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 8.1572265625,
          "content": "[ä¸­æ–‡](https://github.com/QwenLM/Qwen-Agent/blob/main/README_CN.md) ï½œ English\n\n<p align=\"center\">\n    <img src=\"https://qianwen-res.oss-cn-beijing.aliyuncs.com/assets/qwen_agent/logo-qwen-agent.png\" width=\"400\"/>\n<p>\n<br>\n\nQwen-Agent is a framework for developing LLM applications based on the instruction following, tool usage, planning, and\nmemory capabilities of Qwen.\nIt also comes with example applications such as Browser Assistant, Code Interpreter, and Custom Assistant.\n\n# News\n* Dec 3, 2024: Upgrade GUI to Gradio 5 based. Note: GUI requires Python 3.10 or higher.\n* ğŸ”¥ğŸ”¥ğŸ”¥ Sep 18, 2024: Added [Qwen2.5-Math Demo](./examples/tir_math.py) to showcase the Tool-Integrated Reasoning capabilities of Qwen2.5-Math. Note: The python executor is not sandboxed and is intended for local testing only, not for production use.\n\n# Getting Started\n\n## Installation\n\n- Install the stable version from PyPI:\n```bash\npip install -U \"qwen-agent[gui,rag,code_interpreter,python_executor]\"\n# Or use `pip install -U qwen-agent` for the minimal requirements.\n# The optional requirements, specified in double brackets, are:\n#   [gui] for Gradio-based GUI support;\n#   [rag] for RAG support;\n#   [code_interpreter] for Code Interpreter support;\n#   [python_executor] for Tool-Integrated Reasoning with Qwen2.5-Math.\n```\n\n- Alternatively, you can install the latest development version from the source:\n```bash\ngit clone https://github.com/QwenLM/Qwen-Agent.git\ncd Qwen-Agent\npip install -e ./\"[gui,rag,code_interpreter,python_executor]\"\n# Or `pip install -e ./` for minimal requirements.\n```\n\n## Preparation: Model Service\n\nYou can either use the model service provided by Alibaba\nCloud's [DashScope](https://help.aliyun.com/zh/dashscope/developer-reference/quick-start), or deploy and use your own\nmodel service using the open-source Qwen models.\n\n- If you choose to use the model service offered by DashScope, please ensure that you set the environment\nvariable `DASHSCOPE_API_KEY` to your unique DashScope API key.\n\n- Alternatively, if you prefer to deploy and use your own model service, please follow the instructions provided in the README of Qwen2 for deploying an OpenAI-compatible API service.\nSpecifically, consult the [vLLM](https://github.com/QwenLM/Qwen2?tab=readme-ov-file#vllm) section for high-throughput GPU deployment or the [Ollama](https://github.com/QwenLM/Qwen2?tab=readme-ov-file#ollama) section for local CPU (+GPU) deployment.\n\n## Developing Your Own Agent\n\nQwen-Agent offers atomic components, such as LLMs (which inherit from `class BaseChatModel` and come with [function calling](https://github.com/QwenLM/Qwen-Agent/blob/main/examples/function_calling.py)) and Tools (which inherit\nfrom `class BaseTool`), along with high-level components like Agents (derived from `class Agent`).\n\nThe following example illustrates the process of creating an agent capable of reading PDF files and utilizing tools, as\nwell as incorporating a custom tool:\n\n```py\nimport pprint\nimport urllib.parse\nimport json5\nfrom qwen_agent.agents import Assistant\nfrom qwen_agent.tools.base import BaseTool, register_tool\n\n\n# Step 1 (Optional): Add a custom tool named `my_image_gen`.\n@register_tool('my_image_gen')\nclass MyImageGen(BaseTool):\n    # The `description` tells the agent the functionality of this tool.\n    description = 'AI painting (image generation) service, input text description, and return the image URL drawn based on text information.'\n    # The `parameters` tell the agent what input parameters the tool has.\n    parameters = [{\n        'name': 'prompt',\n        'type': 'string',\n        'description': 'Detailed description of the desired image content, in English',\n        'required': True\n    }]\n\n    def call(self, params: str, **kwargs) -> str:\n        # `params` are the arguments generated by the LLM agent.\n        prompt = json5.loads(params)['prompt']\n        prompt = urllib.parse.quote(prompt)\n        return json5.dumps(\n            {'image_url': f'https://image.pollinations.ai/prompt/{prompt}'},\n            ensure_ascii=False)\n\n\n# Step 2: Configure the LLM you are using.\nllm_cfg = {\n    # Use the model service provided by DashScope:\n    'model': 'qwen-max',\n    'model_server': 'dashscope',\n    # 'api_key': 'YOUR_DASHSCOPE_API_KEY',\n    # It will use the `DASHSCOPE_API_KEY' environment variable if 'api_key' is not set here.\n\n    # Use a model service compatible with the OpenAI API, such as vLLM or Ollama:\n    # 'model': 'Qwen2-7B-Chat',\n    # 'model_server': 'http://localhost:8000/v1',  # base_url, also known as api_base\n    # 'api_key': 'EMPTY',\n\n    # (Optional) LLM hyperparameters for generation:\n    'generate_cfg': {\n        'top_p': 0.8\n    }\n}\n\n# Step 3: Create an agent. Here we use the `Assistant` agent as an example, which is capable of using tools and reading files.\nsystem_instruction = '''You are a helpful assistant.\nAfter receiving the user's request, you should:\n- first draw an image and obtain the image url,\n- then run code `request.get(image_url)` to download the image,\n- and finally select an image operation from the given document to process the image.\nPlease show the image using `plt.show()`.'''\ntools = ['my_image_gen', 'code_interpreter']  # `code_interpreter` is a built-in tool for executing code.\nfiles = ['./examples/resource/doc.pdf']  # Give the bot a PDF file to read.\nbot = Assistant(llm=llm_cfg,\n                system_message=system_instruction,\n                function_list=tools,\n                files=files)\n\n# Step 4: Run the agent as a chatbot.\nmessages = []  # This stores the chat history.\nwhile True:\n    # For example, enter the query \"draw a dog and rotate it 90 degrees\".\n    query = input('user query: ')\n    # Append the user query to the chat history.\n    messages.append({'role': 'user', 'content': query})\n    response = []\n    for response in bot.run(messages=messages):\n        # Streaming output.\n        print('bot response:')\n        pprint.pprint(response, indent=2)\n    # Append the bot responses to the chat history.\n    messages.extend(response)\n```\n\nIn addition to using built-in agent implementations such as `class Assistant`, you can also develop your own agent implemetation by inheriting from `class Agent`.\n\nThe framework also provides a convenient GUI interface, supporting the rapid deployment of Gradio Demos for Agents.\nFor example, in the case above, you can quickly launch a Gradio Demo using the following code:\n\n```py\nfrom qwen_agent.gui import WebUI\nWebUI(bot).run()  # bot is the agent defined in the above code, we do not repeat the definition here for saving space.\n```\nNow you can chat with the Agent in the web UI. Please refer to the [examples](https://github.com/QwenLM/Qwen-Agent/blob/main/examples) directory for more usage examples.\n\n# FAQ\n\n## Do you have function calling (aka tool calling)?\n\nYes. The LLM classes provide [function calling](https://github.com/QwenLM/Qwen-Agent/blob/main/examples/function_calling.py). Additionally, some Agent classes also are built upon the function calling capability, e.g., FnCallAgent and ReActChat.\n\n## How to do question-answering over super-long documents involving 1M tokens?\n\nWe have released [a fast RAG solution](https://github.com/QwenLM/Qwen-Agent/blob/main/examples/assistant_rag.py), as well as [an expensive but competitive agent](https://github.com/QwenLM/Qwen-Agent/blob/main/examples/parallel_doc_qa.py), for doing question-answering over super-long documents. They have managed to outperform native long-context models on two challenging benchmarks while being more efficient, and perform perfectly in the single-needle \"needle-in-the-haystack\" pressure test involving 1M-token contexts. See the [blog](https://qwenlm.github.io/blog/qwen-agent-2405/) for technical details.\n\n<p align=\"center\">\n    <img src=\"https://qianwen-res.oss-cn-beijing.aliyuncs.com/assets/qwen_agent/qwen-agent-2405-blog-long-context-results.png\" width=\"400\"/>\n<p>\n\n# Application: BrowserQwen\n\nBrowserQwen is a browser assistant built upon Qwen-Agent. Please refer to its [documentation](https://github.com/QwenLM/Qwen-Agent/blob/main/browser_qwen.md) for details.\n\n# Disclaimer\n\nThe code interpreter is not sandboxed, and it executes code in your own environment. Please do not ask Qwen to perform dangerous tasks, and do not directly use the code interpreter for production purposes.\n"
        },
        {
          "name": "README_CN.md",
          "type": "blob",
          "size": 7.9228515625,
          "content": "ä¸­æ–‡ ï½œ [English](./README.md)\n\n<p align=\"center\">\n    <img src=\"https://qianwen-res.oss-cn-beijing.aliyuncs.com/assets/qwen_agent/logo-qwen-agent.png\" width=\"400\"/>\n<p>\n<br>\n\nQwen-Agentæ˜¯ä¸€ä¸ªå¼€å‘æ¡†æ¶ã€‚å¼€å‘è€…å¯åŸºäºæœ¬æ¡†æ¶å¼€å‘Agentåº”ç”¨ï¼Œå……åˆ†åˆ©ç”¨åŸºäºé€šä¹‰åƒé—®æ¨¡å‹ï¼ˆQwenï¼‰çš„æŒ‡ä»¤éµå¾ªã€å·¥å…·ä½¿ç”¨ã€è§„åˆ’ã€è®°å¿†èƒ½åŠ›ã€‚æœ¬é¡¹ç›®ä¹Ÿæä¾›äº†æµè§ˆå™¨åŠ©æ‰‹ã€ä»£ç è§£é‡Šå™¨ã€è‡ªå®šä¹‰åŠ©æ‰‹ç­‰ç¤ºä¾‹åº”ç”¨ã€‚\n\n# æ›´æ–°\n* Dec 3, 2024: GUI å‡çº§ä¸ºåŸºäº Gradio 5ã€‚æ³¨æ„ï¼šå¦‚æœéœ€è¦ä½¿ç”¨GUIï¼ŒPythonç‰ˆæœ¬éœ€è¦3.10åŠä»¥ä¸Šã€‚\n* ğŸ”¥ğŸ”¥ğŸ”¥Sep 18, 2024: æ–°å¢[Qwen2.5-Math Demo](./examples/tir_math.py)ä»¥å±•ç¤ºQwen2.5-MathåŸºäºå·¥å…·çš„æ¨ç†èƒ½åŠ›ã€‚æ³¨æ„ï¼šä»£ç æ‰§è¡Œå·¥å…·æœªè¿›è¡Œæ²™ç®±ä¿æŠ¤ï¼Œä»…é€‚ç”¨äºæœ¬åœ°æµ‹è¯•ï¼Œä¸å¯ç”¨äºç”Ÿäº§ã€‚\n\n# å¼€å§‹ä¸Šæ‰‹\n\n## å®‰è£…\n\n- ä» PyPI å®‰è£…ç¨³å®šç‰ˆæœ¬ï¼š\n```bash\npip install -U \"qwen-agent[rag,code_interpreter,python_executor,gui]\"\n# æˆ–è€…ï¼Œä½¿ç”¨ `pip install -U qwen-agent` æ¥å®‰è£…æœ€å°ä¾èµ–ã€‚\n# å¯ä½¿ç”¨åŒæ‹¬å·æŒ‡å®šå¦‚ä¸‹çš„å¯é€‰ä¾èµ–ï¼š\n#   [gui] ç”¨äºæä¾›åŸºäº Gradio çš„ GUI æ”¯æŒï¼›\n#   [rag] ç”¨äºæ”¯æŒ RAGï¼›\n#   [code_interpreter] ç”¨äºæä¾›ä»£ç è§£é‡Šå™¨ç›¸å…³æ”¯æŒï¼›\n#   [python_executor] ç”¨äºæ”¯æŒ Qwen2.5-Math åŸºäºå·¥å…·çš„æ¨ç†ã€‚\n```\n\n- æˆ–è€…ï¼Œä½ å¯ä»¥ä»æºç å®‰è£…æœ€æ–°çš„å¼€å‘ç‰ˆæœ¬ï¼š\n```bash\ngit clone https://github.com/QwenLM/Qwen-Agent.git\ncd Qwen-Agent\npip install -e ./\"[rag,code_interpreter,python_executor]\"\n# æˆ–è€…ï¼Œä½¿ç”¨ `pip install -e ./` å®‰è£…æœ€å°ä¾èµ–ã€‚\n```\n\nå¦‚æœéœ€è¦å†…ç½® GUI æ”¯æŒï¼Œè¯·é€‰æ‹©æ€§åœ°å®‰è£…å¯é€‰ä¾èµ–ï¼š\n```bash\npip install -U \"qwen-agent[gui,rag,code_interpreter]\"\n# æˆ–è€…é€šè¿‡æºç å®‰è£… `pip install -e ./\"[gui,rag,code_interpreter]\"`\n```\n\n## å‡†å¤‡ï¼šæ¨¡å‹æœåŠ¡\n\nQwen-Agentæ”¯æŒæ¥å…¥é˜¿é‡Œäº‘[DashScope](https://help.aliyun.com/zh/dashscope/developer-reference/quick-start)æœåŠ¡æä¾›çš„Qwenæ¨¡å‹æœåŠ¡ï¼Œä¹Ÿæ”¯æŒé€šè¿‡OpenAI APIæ–¹å¼æ¥å…¥å¼€æºçš„Qwenæ¨¡å‹æœåŠ¡ã€‚\n\n- å¦‚æœå¸Œæœ›æ¥å…¥DashScopeæä¾›çš„æ¨¡å‹æœåŠ¡ï¼Œåªéœ€é…ç½®ç›¸åº”çš„ç¯å¢ƒå˜é‡`DASHSCOPE_API_KEY`ä¸ºæ‚¨çš„DashScope API Keyã€‚\n\n- æˆ–è€…ï¼Œå¦‚æœæ‚¨å¸Œæœ›éƒ¨ç½²å¹¶ä½¿ç”¨æ‚¨è‡ªå·±çš„æ¨¡å‹æœåŠ¡ï¼Œè¯·æŒ‰ç…§Qwen2çš„READMEä¸­æä¾›çš„æŒ‡å¯¼è¿›è¡Œæ“ä½œï¼Œä»¥éƒ¨ç½²ä¸€ä¸ªå…¼å®¹OpenAIæ¥å£åè®®çš„APIæœåŠ¡ã€‚\nå…·ä½“æ¥è¯´ï¼Œè¯·å‚é˜…[vLLM](https://github.com/QwenLM/Qwen2?tab=readme-ov-file#vllm)ä¸€èŠ‚äº†è§£é«˜å¹¶å‘çš„GPUéƒ¨ç½²æ–¹å¼ï¼Œæˆ–è€…æŸ¥çœ‹[Ollama](https://github.com/QwenLM/Qwen2?tab=readme-ov-file#ollama)ä¸€èŠ‚äº†è§£æœ¬åœ°CPUï¼ˆ+GPUï¼‰éƒ¨ç½²ã€‚\n\n## å¿«é€Ÿå¼€å‘\n\næ¡†æ¶æä¾›äº†å¤§æ¨¡å‹ï¼ˆLLMï¼Œç»§æ‰¿è‡ª`class BaseChatModel`ï¼Œå¹¶æä¾›äº†[Function Calling](./examples/function_calling.py)åŠŸèƒ½ï¼‰å’Œå·¥å…·ï¼ˆToolï¼Œç»§æ‰¿è‡ª`class BaseTool`ï¼‰ç­‰åŸå­ç»„ä»¶ï¼Œä¹Ÿæä¾›äº†æ™ºèƒ½ä½“ï¼ˆAgentï¼‰ç­‰é«˜çº§æŠ½è±¡ç»„ä»¶ï¼ˆç»§æ‰¿è‡ª`class Agent`ï¼‰ã€‚\n\nä»¥ä¸‹ç¤ºä¾‹æ¼”ç¤ºäº†å¦‚ä½•å¢åŠ è‡ªå®šä¹‰å·¥å…·ï¼Œå¹¶å¿«é€Ÿå¼€å‘ä¸€ä¸ªå¸¦æœ‰è®¾å®šã€çŸ¥è¯†åº“å’Œå·¥å…·ä½¿ç”¨èƒ½åŠ›çš„æ™ºèƒ½ä½“ï¼š\n\n```py\nimport pprint\nimport urllib.parse\nimport json5\nfrom qwen_agent.agents import Assistant\nfrom qwen_agent.tools.base import BaseTool, register_tool\n\n\n# æ­¥éª¤ 1ï¼ˆå¯é€‰ï¼‰ï¼šæ·»åŠ ä¸€ä¸ªåä¸º `my_image_gen` çš„è‡ªå®šä¹‰å·¥å…·ã€‚\n@register_tool('my_image_gen')\nclass MyImageGen(BaseTool):\n    # `description` ç”¨äºå‘Šè¯‰æ™ºèƒ½ä½“è¯¥å·¥å…·çš„åŠŸèƒ½ã€‚\n    description = 'AI ç»˜ç”»ï¼ˆå›¾åƒç”Ÿæˆï¼‰æœåŠ¡ï¼Œè¾“å…¥æ–‡æœ¬æè¿°ï¼Œè¿”å›åŸºäºæ–‡æœ¬ä¿¡æ¯ç»˜åˆ¶çš„å›¾åƒ URLã€‚'\n    # `parameters` å‘Šè¯‰æ™ºèƒ½ä½“è¯¥å·¥å…·æœ‰å“ªäº›è¾“å…¥å‚æ•°ã€‚\n    parameters = [{\n        'name': 'prompt',\n        'type': 'string',\n        'description': 'æœŸæœ›çš„å›¾åƒå†…å®¹çš„è¯¦ç»†æè¿°',\n        'required': True\n    }]\n\n    def call(self, params: str, **kwargs) -> str:\n        # `params` æ˜¯ç”± LLM æ™ºèƒ½ä½“ç”Ÿæˆçš„å‚æ•°ã€‚\n        prompt = json5.loads(params)['prompt']\n        prompt = urllib.parse.quote(prompt)\n        return json5.dumps(\n            {'image_url': f'https://image.pollinations.ai/prompt/{prompt}'},\n            ensure_ascii=False)\n\n\n# æ­¥éª¤ 2ï¼šé…ç½®æ‚¨æ‰€ä½¿ç”¨çš„ LLMã€‚\nllm_cfg = {\n    # ä½¿ç”¨ DashScope æä¾›çš„æ¨¡å‹æœåŠ¡ï¼š\n    'model': 'qwen-max',\n    'model_server': 'dashscope',\n    # 'api_key': 'YOUR_DASHSCOPE_API_KEY',\n    # å¦‚æœè¿™é‡Œæ²¡æœ‰è®¾ç½® 'api_key'ï¼Œå®ƒå°†è¯»å– `DASHSCOPE_API_KEY` ç¯å¢ƒå˜é‡ã€‚\n\n    # ä½¿ç”¨ä¸ OpenAI API å…¼å®¹çš„æ¨¡å‹æœåŠ¡ï¼Œä¾‹å¦‚ vLLM æˆ– Ollamaï¼š\n    # 'model': 'Qwen2-7B-Chat',\n    # 'model_server': 'http://localhost:8000/v1',  # base_urlï¼Œä¹Ÿç§°ä¸º api_base\n    # 'api_key': 'EMPTY',\n\n    # ï¼ˆå¯é€‰ï¼‰ LLM çš„è¶…å‚æ•°ï¼š\n    'generate_cfg': {\n        'top_p': 0.8\n    }\n}\n\n# æ­¥éª¤ 3ï¼šåˆ›å»ºä¸€ä¸ªæ™ºèƒ½ä½“ã€‚è¿™é‡Œæˆ‘ä»¬ä»¥ `Assistant` æ™ºèƒ½ä½“ä¸ºä¾‹ï¼Œå®ƒèƒ½å¤Ÿä½¿ç”¨å·¥å…·å¹¶è¯»å–æ–‡ä»¶ã€‚\nsystem_instruction = '''ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„AIåŠ©æ‰‹ã€‚\nåœ¨æ”¶åˆ°ç”¨æˆ·çš„è¯·æ±‚åï¼Œä½ åº”è¯¥ï¼š\n- é¦–å…ˆç»˜åˆ¶ä¸€å¹…å›¾åƒï¼Œå¾—åˆ°å›¾åƒçš„urlï¼Œ\n- ç„¶åè¿è¡Œä»£ç `request.get`ä»¥ä¸‹è½½è¯¥å›¾åƒçš„urlï¼Œ\n- æœ€åä»ç»™å®šçš„æ–‡æ¡£ä¸­é€‰æ‹©ä¸€ä¸ªå›¾åƒæ“ä½œè¿›è¡Œå›¾åƒå¤„ç†ã€‚\nç”¨ `plt.show()` å±•ç¤ºå›¾åƒã€‚\nä½ æ€»æ˜¯ç”¨ä¸­æ–‡å›å¤ç”¨æˆ·ã€‚'''\ntools = ['my_image_gen', 'code_interpreter']  # `code_interpreter` æ˜¯æ¡†æ¶è‡ªå¸¦çš„å·¥å…·ï¼Œç”¨äºæ‰§è¡Œä»£ç ã€‚\nfiles = ['./examples/resource/doc.pdf']  # ç»™æ™ºèƒ½ä½“ä¸€ä¸ª PDF æ–‡ä»¶é˜…è¯»ã€‚\nbot = Assistant(llm=llm_cfg,\n                system_message=system_instruction,\n                function_list=tools,\n                files=files)\n\n# æ­¥éª¤ 4ï¼šä½œä¸ºèŠå¤©æœºå™¨äººè¿è¡Œæ™ºèƒ½ä½“ã€‚\nmessages = []  # è¿™é‡Œå‚¨å­˜èŠå¤©å†å²ã€‚\nwhile True:\n    # ä¾‹å¦‚ï¼Œè¾“å…¥è¯·æ±‚ \"ç»˜åˆ¶ä¸€åªç‹—å¹¶å°†å…¶æ—‹è½¬ 90 åº¦\"ã€‚\n    query = input('ç”¨æˆ·è¯·æ±‚: ')\n    # å°†ç”¨æˆ·è¯·æ±‚æ·»åŠ åˆ°èŠå¤©å†å²ã€‚\n    messages.append({'role': 'user', 'content': query})\n    response = []\n    for response in bot.run(messages=messages):\n        # æµå¼è¾“å‡ºã€‚\n        print('æœºå™¨äººå›åº”:')\n        pprint.pprint(response, indent=2)\n    # å°†æœºå™¨äººçš„å›åº”æ·»åŠ åˆ°èŠå¤©å†å²ã€‚\n    messages.extend(response)\n```\n\né™¤äº†ä½¿ç”¨æ¡†æ¶è‡ªå¸¦çš„æ™ºèƒ½ä½“å®ç°ï¼ˆå¦‚`class Assistant`ï¼‰ï¼Œæ‚¨ä¹Ÿå¯ä»¥é€šè¿‡ç»§æ‰¿`class Agent`æ¥è‡ªè¡Œå¼€å‘æ‚¨çš„æ™ºèƒ½ä½“å®ç°ã€‚\n\næ¡†æ¶è¿˜æä¾›äº†ä¾¿æ·çš„GUIæ¥å£ï¼Œæ”¯æŒä¸ºAgentå¿«é€Ÿéƒ¨ç½²Gradio Demoã€‚\nä¾‹å¦‚ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç å¿«é€Ÿå¯åŠ¨Gradio Demoï¼š\n\n```py\nfrom qwen_agent.gui import WebUI\nWebUI(bot).run()  # bot is the agent defined in the above code, we do not repeat the definition here for saving space.\n```\n\nç°åœ¨æ‚¨å¯ä»¥åœ¨Web UIä¸­å’ŒAgentå¯¹è¯äº†ã€‚æ›´å¤šä½¿ç”¨ç¤ºä¾‹ï¼Œè¯·å‚é˜…[examples](./examples)ç›®å½•ã€‚\n\n# FAQ\n\n## æ”¯æŒå‡½æ•°è°ƒç”¨ï¼ˆä¹Ÿç§°ä¸ºå·¥å…·è°ƒç”¨ï¼‰å—ï¼Ÿ\n\næ”¯æŒï¼ŒLLMç±»æä¾›äº†[å‡½æ•°è°ƒç”¨](https://github.com/QwenLM/Qwen-Agent/blob/main/examples/function_calling.py)çš„æ”¯æŒã€‚æ­¤å¤–ï¼Œä¸€äº›Agentç±»å¦‚FnCallAgentå’ŒReActChatä¹Ÿæ˜¯åŸºäºå‡½æ•°è°ƒç”¨åŠŸèƒ½æ„å»ºçš„ã€‚\n\n## å¦‚ä½•è®©AIåŸºäºè¶…é•¿æ–‡æ¡£è¿›è¡Œé—®ç­”ï¼Ÿ\n\næˆ‘ä»¬å·²å‘å¸ƒäº†ä¸€ä¸ª[å¿«é€Ÿçš„RAGè§£å†³æ–¹æ¡ˆ](https://github.com/QwenLM/Qwen-Agent/blob/main/examples/assistant_rag.py)ï¼Œä»¥åŠä¸€ä¸ªè™½è¿è¡Œæˆæœ¬è¾ƒé«˜ä½†[å‡†ç¡®åº¦è¾ƒé«˜çš„æ™ºèƒ½ä½“](https://github.com/QwenLM/Qwen-Agent/blob/main/examples/parallel_doc_qa.py)ï¼Œç”¨äºåœ¨è¶…é•¿æ–‡æ¡£ä¸­è¿›è¡Œé—®ç­”ã€‚å®ƒä»¬åœ¨ä¸¤ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œè¶…è¶Šäº†åŸç”Ÿçš„é•¿ä¸Šä¸‹æ–‡æ¨¡å‹ï¼ŒåŒæ—¶æ›´åŠ é«˜æ•ˆï¼Œå¹¶åœ¨æ¶‰åŠ100ä¸‡å­—è¯ä¸Šä¸‹æ–‡çš„â€œå¤§æµ·æé’ˆâ€å¼å•é’ˆæŸ¥è¯¢å‹åŠ›æµ‹è¯•ä¸­è¡¨ç°å®Œç¾ã€‚æ¬²äº†è§£æŠ€æœ¯ç»†èŠ‚ï¼Œè¯·å‚é˜…[åšå®¢](https://qwenlm.github.io/blog/qwen-agent-2405/)ã€‚\n\n<p align=\"center\">\n    <img src=\"https://qianwen-res.oss-cn-beijing.aliyuncs.com/assets/qwen_agent/qwen-agent-2405-blog-long-context-results.png\" width=\"400\"/>\n<p>\n\n# åº”ç”¨ï¼šBrowserQwen\n\nBrowserQwen æ˜¯ä¸€æ¬¾åŸºäº Qwen-Agent æ„å»ºçš„æµè§ˆå™¨åŠ©æ‰‹ã€‚å¦‚éœ€äº†è§£è¯¦æƒ…ï¼Œè¯·å‚é˜…å…¶[æ–‡æ¡£](browser_qwen_cn.md)ã€‚\n\n# å…è´£å£°æ˜\n\nä»£ç è§£é‡Šå™¨æœªè¿›è¡Œæ²™ç›’éš”ç¦»ï¼Œä¼šåœ¨éƒ¨ç½²ç¯å¢ƒä¸­æ‰§è¡Œä»£ç ã€‚è¯·é¿å…å‘Qwenå‘å‡ºå±é™©æŒ‡ä»¤ï¼Œåˆ‡å‹¿å°†è¯¥ä»£ç è§£é‡Šå™¨ç›´æ¥ç”¨äºç”Ÿäº§ç›®çš„ã€‚\n"
        },
        {
          "name": "assets",
          "type": "tree",
          "content": null
        },
        {
          "name": "benchmark",
          "type": "tree",
          "content": null
        },
        {
          "name": "browser_qwen.md",
          "type": "blob",
          "size": 4.37109375,
          "content": "# Example Application: BrowserQwen\n\nWe have also developed an example application based on Qwen-Agent: a **Chrome browser extension** called BrowserQwen,\nwhich has key features such as:\n\n- You can discuss with Qwen regarding the current webpage or PDF document.\n- It records the web pages and PDF/Word/PowerPoint materials that you have browsed. It helps you understand multiple\n  pages, summarize your browsing content, and automate writing tasks.\n- It comes with plugin integration, including **Code Interpreter** for math problem solving and data visualization.\n\n## BrowserQwen Demonstration\n\nYou can watch the following showcase videos to learn about the basic operations of BrowserQwen:\n\n- Long-form writing based on visited webpages and\n  PDFs. [video](https://qianwen-res.oss-cn-beijing.aliyuncs.com/assets/qwen_agent/showcase_write_article_based_on_webpages_and_pdfs.mp4)\n- Drawing a plot using code interpreter based on the given\n  information. [video](https://qianwen-res.oss-cn-beijing.aliyuncs.com/assets/qwen_agent/showcase_chat_with_docs_and_code_interpreter.mp4)\n- Uploading files, multi-turn conversation, and data analysis using code\n  interpreter. [video](https://qianwen-res.oss-cn-beijing.aliyuncs.com/assets/qwen_agent/showcase_code_interpreter_multi_turn_chat.mp4)\n\n### Workstation - Editor Mode\n\n**This mode is designed for creating long articles based on browsed web pages and PDFs.**\n\n<figure>\n    <img src=\"assets/screenshot-writing.png\">\n</figure>\n\n**It allows you to call plugins to assist in rich text creation.**\n\n<figure>\n    <img src=\"assets/screenshot-editor-movie.png\">\n</figure>\n\n### Workstation - Chat Mode\n\n**In this mode, you can engage in multi-webpage QA.**\n\n<figure >\n    <img src=\"assets/screenshot-multi-web-qa.png\">\n</figure>\n\n**Create data charts using the code interpreter.**\n\n<figure>\n    <img src=\"assets/screenshot-ci.png\">\n</figure>\n\n### Browser Assistant\n\n**Web page QA**\n\n<figure>\n    <img src=\"assets/screenshot-web-qa.png\">\n</figure>\n\n**PDF document QA**\n\n<figure>\n    <img src=\"assets/screenshot-pdf-qa.png\">\n</figure>\n\n## BrowserQwen User Guide\n\n### Step 1. Deploy Local Database Service\n\nOn your local machine (the machine where you can open the Chrome browser), you will need to deploy a database service to\nmanage your browsing history and conversation history.\n\nIf you are using DashScope's model service, then please execute the following command:\n\n```bash\n# Start the database service, specifying the model on DashScope by using the --llm flag.\n# The value of --llm can be one of the following, in increasing order of resource consumption:\n#   - qwen1.5-7b/14b/72b-chat (the same as the open-sourced Qwen1.5 7B/14B/72B Chat model)\n#   - qwen-turbo, qwen-plus, qwen-max (qwen-max is recommended)\n# \"YOUR_DASHSCOPE_API_KEY\" is a placeholder. The user should replace it with their actual key.\npython run_server.py --llm qwen-max --model_server dashscope --workstation_port 7864 --api_key YOUR_DASHSCOPE_API_KEY\n```\n\nIf you are using your own model service instead of DashScope, then please execute the following command:\n\n```bash\n# Specify the model service, and start the database service.\n# Example: Assuming Qwen1.5-72B-Chat is deployed at http://localhost:8000/v1 using vLLM, you can specify the model service as:\n#   --llm Qwen1.5-72B-Chat --model_server http://localhost:8000/v1 --api_key EMPTY\npython run_server.py --llm {MODEL} --model_server {API_BASE} --workstation_port 7864 --api_key {API_KEY}\n```\n\nNow you can access [http://127.0.0.1:7864/](http://127.0.0.1:7864/) to use the Workstation's Editor mode and Chat mode.\n\n### Step 2. Install Browser Assistant\n\nInstall the BrowserQwen Chrome extension:\n\n- Open the Chrome browser and enter `chrome://extensions/` in the address bar, then press Enter.\n- Make sure that the `Developer mode` in the top right corner is turned on, then click on `Load unpacked` to upload\n  the `browser_qwen` directory from this project and enable it.\n- Click the extension icon in the top right corner of the Chrome browser to pin BrowserQwen to the toolbar.\n\nNote that after installing the Chrome extension, you need to refresh the page for the extension to take effect.\n\nWhen you want Qwen to read the content of the current webpage:\n\n- Click the `Add to Qwen's Reading List` button on the screen to authorize Qwen to analyze the page in the background.\n- Click the Qwen icon in the browser's top right corner to start interacting with Qwen about the current page's content.\n"
        },
        {
          "name": "browser_qwen",
          "type": "tree",
          "content": null
        },
        {
          "name": "browser_qwen_cn.md",
          "type": "blob",
          "size": 4.150390625,
          "content": "# ç¤ºä¾‹åº”ç”¨ï¼šBrowserQwen\n\næˆ‘ä»¬åœ¨Qwen-Agentçš„åŸºç¡€ä¸Šå¼€å‘äº†ä¸€ä¸ªè¾ƒä¸ºå¤æ‚çš„Agentåº”ç”¨ï¼Œåä¸ºBrowserQwençš„**Chromeæµè§ˆå™¨æ‰©å±•**ï¼Œå®ƒå…·æœ‰ä»¥ä¸‹ä¸»è¦åŠŸèƒ½ï¼š\n\n- ä¸Qwenè®¨è®ºå½“å‰ç½‘é¡µæˆ–PDFæ–‡æ¡£çš„å†…å®¹ã€‚\n- BrowserQwenä¼šè®°å½•æ‚¨æµè§ˆè¿‡çš„ç½‘é¡µå’ŒPDF/Word/PPTææ–™ï¼Œå¸®åŠ©æ‚¨äº†è§£å¤šä¸ªé¡µé¢çš„å†…å®¹ã€æ€»ç»“æµè§ˆè¿‡çš„å†…å®¹ã€è‡ªåŠ¨åŒ–ç¹ççš„æ–‡å­—å·¥ä½œã€‚\n- é›†æˆå„ç§æ’ä»¶ï¼ŒåŒ…æ‹¬å¯ç”¨äºæ•°å­¦é—®é¢˜æ±‚è§£ã€æ•°æ®åˆ†æä¸å¯è§†åŒ–ã€å¤„ç†æ–‡ä»¶ç­‰çš„**ä»£ç è§£é‡Šå™¨**ï¼ˆ**Code Interpreter**ï¼‰ã€‚\n\n## BrowserQwen åŠŸèƒ½æ¼”ç¤º\n\nå¯æŸ¥çœ‹ä»¥ä¸‹å‡ ä¸ªæ¼”ç¤ºè§†é¢‘ï¼Œäº†è§£BrowserQwençš„æ ¸å¿ƒåŠŸèƒ½å’ŒåŸºæœ¬æ“ä½œï¼š\n\n- æ ¹æ®æµè§ˆè¿‡çš„ç½‘é¡µã€PDFsè¿›è¡Œé•¿æ–‡åˆ›ä½œ [video](https://qianwen-res.oss-cn-beijing.aliyuncs.com/assets/qwen_agent/showcase_write_article_based_on_webpages_and_pdfs.mp4)\n- æå–æµè§ˆå†…å®¹ä½¿ç”¨ä»£ç è§£é‡Šå™¨ç”»å›¾ [video](https://qianwen-res.oss-cn-beijing.aliyuncs.com/assets/qwen_agent/showcase_chat_with_docs_and_code_interpreter.mp4)\n- ä¸Šä¼ æ–‡ä»¶ã€å¤šè½®å¯¹è¯åˆ©ç”¨ä»£ç è§£é‡Šå™¨åˆ†ææ•°æ® [video](https://qianwen-res.oss-cn-beijing.aliyuncs.com/assets/qwen_agent/showcase_code_interpreter_multi_turn_chat.mp4)\n\n### å·¥ä½œå° - åˆ›ä½œæ¨¡å¼\n\n**æ ¹æ®æµè§ˆè¿‡çš„ç½‘é¡µã€PDFsç´ æè¿›è¡Œé•¿æ–‡åˆ›ä½œ**\n\n<figure>\n    <img src=\"assets/screenshot-writing.png\">\n</figure>\n\n**è°ƒç”¨æ’ä»¶è¾…åŠ©å¯Œæ–‡æœ¬åˆ›ä½œ**\n\n<figure>\n    <img src=\"assets/screenshot-editor-movie.png\">\n</figure>\n\n### å·¥ä½œå° - å¯¹è¯æ¨¡å¼\n\n**å¤šç½‘é¡µé—®ç­”**\n\n<figure >\n    <img src=\"assets/screenshot-multi-web-qa.png\">\n</figure>\n\n**ä½¿ç”¨ä»£ç è§£é‡Šå™¨ç»˜åˆ¶æ•°æ®å›¾è¡¨**\n\n<figure>\n    <img src=\"assets/screenshot-ci.png\">\n</figure>\n\n### æµè§ˆå™¨åŠ©æ‰‹\n\n**ç½‘é¡µé—®ç­”**\n\n<figure>\n    <img src=\"assets/screenshot-web-qa.png\">\n</figure>\n\n**PDFæ–‡æ¡£é—®ç­”**\n\n<figure>\n    <img src=\"assets/screenshot-pdf-qa.png\">\n</figure>\n\n## BrowserQwen ä½¿ç”¨è¯´æ˜\n\n### ç¬¬ä¸€æ­¥ - éƒ¨ç½²æœ¬åœ°æ•°æ®åº“æœåŠ¡\n\nåœ¨è¿™ä¸€æ­¥ï¼Œæ‚¨éœ€è¦åœ¨æ‚¨çš„æœ¬åœ°æœºå™¨ä¸Šï¼ˆå³æ‚¨å¯ä»¥æ‰“å¼€Chromeæµè§ˆå™¨çš„é‚£å°æœºå™¨ï¼‰ï¼Œéƒ¨ç½²ç»´æŠ¤ä¸ªäººæµè§ˆå†å²ã€å¯¹è¯å†å²çš„æ•°æ®åº“æœåŠ¡ã€‚\n\nå¦‚æœæ‚¨ä½¿ç”¨DashScopeæä¾›çš„æ¨¡å‹æœåŠ¡çš„è¯ï¼Œè¯·æ‰§è¡Œä»¥ä¸‹å‘½ä»¤å¯åŠ¨æ•°æ®åº“æœåŠ¡ï¼š\n\n```bash\n# å¯åŠ¨æ•°æ®åº“æœåŠ¡ï¼Œé€šè¿‡ --llm å‚æ•°æŒ‡å®šæ‚¨å¸Œæœ›é€šè¿‡DashScopeä½¿ç”¨çš„å…·ä½“æ¨¡å‹\n# å‚æ•° --llm å¯ä»¥æ˜¯å¦‚ä¸‹ä¹‹ä¸€ï¼ŒæŒ‰èµ„æºæ¶ˆè€—ä»å°åˆ°å¤§æ’åºï¼š\n#   - qwen1.5-7b/14b/72b-chat ï¼ˆä¸å¼€æºçš„Qwen1.5-7B/14B/72B-Chatç›¸åŒæ¨¡å‹ï¼‰\n#   - qwen-turbo, qwen-plus, qwen-max ï¼ˆæ¨èä½¿ç”¨qwen-maxï¼‰\n# æ‚¨éœ€è¦å°†YOUR_DASHSCOPE_API_KEYæ›¿æ¢ä¸ºæ‚¨çš„çœŸå®API-KEYã€‚\npython run_server.py --llm qwen-max --model_server dashscope --workstation_port 7864 --api_key YOUR_DASHSCOPE_API_KEY\n```\n\nå¦‚æœæ‚¨æ²¡æœ‰åœ¨ä½¿ç”¨DashScopeã€è€Œæ˜¯éƒ¨ç½²äº†è‡ªå·±çš„æ¨¡å‹æœåŠ¡çš„è¯ï¼Œè¯·æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š\n\n```bash\n# æŒ‡å®šæ¨¡å‹æœåŠ¡ï¼Œå¹¶å¯åŠ¨æ•°æ®åº“æœåŠ¡ã€‚\n# ç¤ºä¾‹: å‡è®¾Qwen1.5-72B-Chatå·²ç»é€šè¿‡vLLMéƒ¨ç½²äºhttp://localhost:8000/v1ï¼Œåˆ™å¯ç”¨ä»¥ä¸‹å‚æ•°æŒ‡å®šæ¨¡å‹æœåŠ¡ï¼š\n#   --llm Qwen1.5-72B-Chat --model_server http://localhost:8000/v1 --api_key EMPTY\npython run_server.py --llm {MODEL} --model_server {API_BASE} --workstation_port 7864 --api_key {API_KEY}\n```\n\nç°åœ¨æ‚¨å¯ä»¥è®¿é—® [http://127.0.0.1:7864/](http://127.0.0.1:7864/) æ¥ä½¿ç”¨å·¥ä½œå°ï¼ˆWorkstationï¼‰çš„åˆ›ä½œæ¨¡å¼ï¼ˆEditoræ¨¡å¼ï¼‰å’Œå¯¹è¯æ¨¡å¼ï¼ˆChatæ¨¡å¼ï¼‰äº†ã€‚\n\n### ç¬¬äºŒæ­¥ - å®‰è£…æµè§ˆå™¨åŠ©æ‰‹\n\nå®‰è£…BrowserQwençš„Chromeæ’ä»¶ï¼ˆåˆç§°Chromeæ‰©å±•ç¨‹åºï¼‰ï¼š\n\n1. æ‰“å¼€Chromeæµè§ˆå™¨ï¼Œåœ¨æµè§ˆå™¨çš„åœ°å€æ ä¸­è¾“å…¥ `chrome://extensions/` å¹¶æŒ‰ä¸‹å›è½¦é”®ï¼›\n2. ç¡®ä¿å³ä¸Šè§’çš„ `å¼€å‘è€…æ¨¡å¼` å¤„äºæ‰“å¼€çŠ¶æ€ï¼Œä¹‹åç‚¹å‡» `åŠ è½½å·²è§£å‹çš„æ‰©å±•ç¨‹åº` ä¸Šä¼ æœ¬é¡¹ç›®ä¸‹çš„ `browser_qwen` ç›®å½•å¹¶å¯ç”¨ï¼›\n3. å•å‡»è°·æ­Œæµè§ˆå™¨å³ä¸Šè§’```æ‰©å±•ç¨‹åº```å›¾æ ‡ï¼Œå°†BrowserQwenå›ºå®šåœ¨å·¥å…·æ ã€‚\n\næ³¨æ„ï¼Œå®‰è£…Chromeæ’ä»¶åï¼Œéœ€è¦åˆ·æ–°é¡µé¢ï¼Œæ’ä»¶æ‰èƒ½ç”Ÿæ•ˆã€‚\n\nå½“æ‚¨æƒ³è®©Qwené˜…è¯»å½“å‰ç½‘é¡µçš„å†…å®¹æ—¶ï¼š\n\n1. è¯·å…ˆç‚¹å‡»å±å¹•ä¸Šçš„ `Add to Qwen's Reading List` æŒ‰é’®ï¼Œä»¥æˆæƒQwenåœ¨åå°åˆ†ææœ¬é¡µé¢ã€‚\n2. å†å•å‡»æµè§ˆå™¨å³ä¸Šè§’æ‰©å±•ç¨‹åºæ çš„Qwenå›¾æ ‡ï¼Œä¾¿å¯ä»¥å’ŒQwenäº¤æµå½“å‰é¡µé¢çš„å†…å®¹äº†ã€‚\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "qwen_agent",
          "type": "tree",
          "content": null
        },
        {
          "name": "qwen_server",
          "type": "tree",
          "content": null
        },
        {
          "name": "run_server.py",
          "type": "blob",
          "size": 4.6396484375,
          "content": "import argparse\nimport json\nimport os\nimport signal\nimport subprocess\nimport sys\nfrom pathlib import Path\n\nfrom qwen_server.schema import GlobalConfig\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        '-m',\n        '--model_server',\n        type=str,\n        default='dashscope',\n        help='Set it to `dashscope` if you are using the model service provided by DashScope.'\n        ' Set it to the base_url (aka api_base) if using an OpenAI API-compatible service such as vLLM or Ollama.'\n        ' Default: dashscope',\n    )\n    parser.add_argument(\n        '-k',\n        '--api_key',\n        type=str,\n        default='',\n        help='You API key to DashScope or the OpenAI API-compatible model service.',\n    )\n    parser.add_argument(\n        '-l',\n        '--llm',\n        type=str,\n        default='qwen-plus',\n        help='Set it to one of {\"qwen-max\", \"qwen-plus\", \"qwen-turbo\"} if using DashScope.'\n        ' Set it to the model name using an OpenAI API-compatible model service.'\n        ' Default: qwen-plus',\n    )\n    parser.add_argument(\n        '-s',\n        '--server_host',\n        type=str,\n        default='127.0.0.1',\n        choices=['127.0.0.1', '0.0.0.0'],\n        help='Set to 0.0.0.0 if you want to allow other machines to access the server. Default: 127.0.0.1',\n    )\n    parser.add_argument(\n        '-t',\n        '--max_ref_token',\n        type=int,\n        default=4000,\n        help='Tokens reserved for the reference materials of retrieval-augmanted generation (RAG). Default: 4000',\n    )\n    parser.add_argument(\n        '-w',\n        '--workstation_port',\n        type=int,\n        default=7864,\n        help='The port of the creative writing workstation. Default: 7864',\n    )\n    args = parser.parse_args()\n    args.model_server = args.model_server.replace('0.0.0.0', '127.0.0.1')\n    return args\n\n\ndef update_config(server_config, args, server_config_path):\n    server_config.server.model_server = args.model_server\n    server_config.server.api_key = args.api_key\n    server_config.server.llm = args.llm\n    server_config.server.server_host = args.server_host\n    server_config.server.max_ref_token = args.max_ref_token\n    server_config.server.workstation_port = args.workstation_port\n\n    with open(server_config_path, 'w') as f:\n        try:\n            cfg = server_config.model_dump_json()\n        except AttributeError:  # for pydantic v1\n            cfg = server_config.json()\n        json.dump(json.loads(cfg), f, ensure_ascii=False, indent=4)\n    return server_config\n\n\ndef main():\n    args = parse_args()\n    server_config_path = Path(__file__).resolve().parent / 'qwen_server/server_config.json'\n    with open(server_config_path, 'r') as f:\n        server_config = json.load(f)\n        server_config = GlobalConfig(**server_config)\n    server_config = update_config(server_config, args, server_config_path)\n\n    os.makedirs(server_config.path.work_space_root, exist_ok=True)\n    os.makedirs(server_config.path.download_root, exist_ok=True)\n\n    os.makedirs(server_config.path.code_interpreter_ws, exist_ok=True)\n    code_interpreter_work_dir = str(Path(__file__).resolve().parent / server_config.path.code_interpreter_ws)\n\n    # TODO: Remove these two hacky code interpreter env vars.\n    os.environ['M6_CODE_INTERPRETER_WORK_DIR'] = code_interpreter_work_dir\n\n    from qwen_agent.utils.utils import append_signal_handler, get_local_ip, logger\n    logger.info(server_config)\n\n    if args.server_host == '0.0.0.0':\n        static_url = get_local_ip()\n    else:\n        static_url = args.server_host\n    static_url = f'http://{static_url}:{server_config.server.fast_api_port}/static'\n    os.environ['M6_CODE_INTERPRETER_STATIC_URL'] = static_url\n\n    servers = {\n        'database':\n            subprocess.Popen([\n                sys.executable,\n                os.path.join(os.getcwd(), 'qwen_server/database_server.py'),\n            ]),\n        'workstation':\n            subprocess.Popen([\n                sys.executable,\n                os.path.join(os.getcwd(), 'qwen_server/workstation_server.py'),\n            ]),\n        'assistant':\n            subprocess.Popen([\n                sys.executable,\n                os.path.join(os.getcwd(), 'qwen_server/assistant_server.py'),\n            ]),\n    }\n\n    def signal_handler(sig_num, _frame):\n        for v in servers.values():\n            v.terminate()\n        for k in list(servers.keys()):\n            del servers[k]\n        if sig_num == signal.SIGINT:\n            raise KeyboardInterrupt()\n\n    append_signal_handler(signal.SIGINT, signal_handler)\n    append_signal_handler(signal.SIGTERM, signal_handler)\n\n    for p in list(servers.values()):\n        p.wait()\n\n\nif __name__ == '__main__':\n    main()\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 2.9521484375,
          "content": "import re\n\nfrom setuptools import find_packages, setup\n\n\ndef get_version() -> str:\n    with open('qwen_agent/__init__.py', encoding='utf-8') as f:\n        version = re.search(\n            r'^__version__\\s*=\\s*[\\'\"]([^\\'\"]*)[\\'\"]',\n            f.read(),\n            re.MULTILINE,\n        ).group(1)\n    return version\n\n\ndef read_description() -> str:\n    with open('README.md', 'r', encoding='UTF-8') as f:\n        long_description = f.read()\n    return long_description\n\n\n# To update the package at PyPI:\n# ```bash\n# python setup.py sdist bdist_wheel\n# twine upload dist/*\n# ```\nsetup(\n    name='qwen-agent',\n    version=get_version(),\n    author='Qwen Team',\n    author_email='tujianhong.tjh@alibaba-inc.com',\n    description='Qwen-Agent: Enhancing LLMs with Agent Workflows, RAG, Function Calling, and Code Interpreter.',\n    long_description=read_description(),\n    long_description_content_type='text/markdown',\n    keywords=['LLM', 'Agent', 'Function Calling', 'RAG', 'Code Interpreter'],\n    packages=find_packages(exclude=['examples', 'examples.*', 'qwen_server', 'qwen_server.*']),\n    package_data={\n        'qwen_agent': [\n            'utils/qwen.tiktoken', 'tools/resource/*.ttf', 'tools/resource/*.py', 'gui/assets/*.css',\n            'gui/assets/*.jpeg'\n        ],\n    },\n\n    # Minimal dependencies for Function Calling:\n    install_requires=[\n        'dashscope>=1.11.0',\n        'eval_type_backport',\n        'json5',\n        'jsonlines',\n        'jsonschema',\n        'openai',\n        'pydantic>=2.3.0',\n        'requests',\n        'tiktoken',\n    ],\n    extras_require={\n        # Extra dependencies for RAG:\n        'rag': [\n            'charset-normalizer',\n            'rank_bm25',\n            'jieba',\n            'snowballstemmer',\n            'beautifulsoup4',\n            'pdfminer.six',\n            'pdfplumber',\n            'python-docx',\n            'python-pptx',\n            'pandas',\n            'tabulate',\n        ],\n\n        # Extra dependencies for Python Executor, which is primarily for solving math problems:\n        'python_executor': [\n            'pebble',\n            'multiprocess',\n            'timeout_decorator',\n            'python-dateutil',\n            'sympy',\n            'numpy',\n            'scipy',\n        ],\n\n        # Extra dependencies for Code Interpreter:\n        'code_interpreter': [\n            'anyio>=3.7.1',\n            'fastapi>=0.103.1',\n            'jupyter>=1.0.0',\n            'matplotlib',\n            'numpy',\n            'pandas',\n            'pillow',\n            'seaborn',\n            'sympy',\n            'uvicorn>=0.23.2',\n        ],\n\n        # Extra dependencies for Gradio-based GUI:\n        'gui': [\n            # Gradio has bad version compatibility. Therefore, we use `==` instead of `>=`.\n            'pydantic==2.9.2',\n            'pydantic-core==2.23.4',\n            'gradio>=5.0.0',\n            'gradio-client==1.4.0',\n            'modelscope_studio==1.0.0-beta.8',\n        ],\n    },\n    url='https://github.com/QwenLM/Qwen-Agent',\n)\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}