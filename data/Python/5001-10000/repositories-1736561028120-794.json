{
  "metadata": {
    "timestamp": 1736561028120,
    "page": 794,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjgwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "QwenLM/Qwen-Agent",
      "stars": 5226,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.5712890625,
          "content": "env\n*.pyc\n__pycache__\n\n.idea\n.vscode\n.DS_Store\n*.ipynb_checkpoints\n\nqwen_agent/llm/gpt.py\nqwen_agent/llm/tools.py\nworkspace/*\n\nbenchmark/log/*\nbenchmark/output_data/*\nbenchmark/upload_file/*\nbenchmark/upload_file_clean/*\nbenchmark/eval_data/\nQwen-Agent\n\ndocqa/*\nlog/*\nlog.jsonl\n\nai_agent/debug.json\nai_agent/local_prompts/*\n**/debug.json\n**/debug.log*\ndebug.json\nai_agent/log.jsonl\nqwen_agent.egg-info/*\nbuild/*\ndist/*\n\nexamples/*.ipynb\n**/workspace/*\ntest/*\ntests/env.sh\nexamples/docqa_multi_agent.py\nexamples/docqa_multihp_agents.py\n**/workspace/*\ntest/*\ntests/env.sh\nexamples/data/*"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.8759765625,
          "content": "repos:\n  - repo: https://github.com/pycqa/flake8.git\n    rev: 5.0.4\n    hooks:\n      - id: flake8\n        args: [\"--max-line-length=300\"]  # TODO: Set to 120 and `pre-commit run --all-files`.\n  - repo: https://github.com/PyCQA/isort.git\n    rev: 5.11.5\n    hooks:\n      - id: isort\n        args: [\"--line-length\", \"120\"]\n  - repo: https://github.com/pre-commit/mirrors-yapf.git\n    rev: v0.32.0\n    hooks:\n      - id: yapf\n        args: [\"--style\", \"{based_on_style: google, column_limit: 120}\", \"-i\"]\n  - repo: https://github.com/pre-commit/pre-commit-hooks.git\n    rev: v4.3.0\n    hooks:\n      - id: trailing-whitespace\n      - id: check-yaml\n      - id: end-of-file-fixer\n      - id: requirements-txt-fixer\n      - id: double-quote-string-fixer\n      - id: check-merge-conflict\n      - id: fix-encoding-pragma\n        args: [\"--remove\"]\n      - id: mixed-line-ending\n        args: [\"--fix=lf\"]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 6.7353515625,
          "content": "Tongyi Qianwen LICENSE AGREEMENT\n\nTongyi Qianwen Release Date: August 3, 2023\n\nBy clicking to agree or by using or distributing any portion or element of the Tongyi Qianwen Materials, you will be deemed to have recognized and accepted the content of this Agreement, which is effective immediately.\n\n1. Definitions\n    a. This Tongyi Qianwen LICENSE AGREEMENT (this \"Agreement\") shall mean the terms and conditions for use, reproduction, distribution and modification of the Materials as defined by this Agreement.\n    b. \"We\"(or \"Us\") shall mean Alibaba Cloud.\n    c. \"You\" (or \"Your\") shall mean a natural person or legal entity exercising the rights granted by this Agreement and/or using the Materials for any purpose and in any field of use.\n    d. \"Third Parties\" shall mean individuals or legal entities that are not under common control with Us or You.\n    e. \"Tongyi Qianwen\" shall mean the large language models (including Qwen model and Qwen-Chat model), and software and algorithms, consisting of trained model weights, parameters (including optimizer states), machine-learning model code, inference-enabling code, training-enabling code, fine-tuning enabling code and other elements of the foregoing distributed by Us.\n    f. \"Materials\" shall mean, collectively, Alibaba Cloud's proprietary Tongyi Qianwen and Documentation (and any portion thereof) made available under this Agreement.\n    g. \"Source\" form shall mean the preferred form for making modifications, including but not limited to model source code, documentation source, and configuration files.\n    h. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation,\n and conversions to other media types.\n\n2. Grant of Rights\nYou are granted a non-exclusive, worldwide, non-transferable and royalty-free limited license under Alibaba Cloud's intellectual property or other rights owned by Us embodied in the Materials to use, reproduce, distribute, copy, create derivative works of, and make modifications to the Materials.\n\n3. Redistribution\nYou may reproduce and distribute copies of the Materials or derivative works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions:\n    a. You shall give any other recipients of the Materials or derivative works a copy of this Agreement;\n    b. You shall cause any modified files to carry prominent notices stating that You changed the files;\n    c. You shall retain in all copies of the Materials that You distribute the following attribution notices within a \"Notice\" text file distributed as a part of such copies: \"Tongyi Qianwen is licensed under the Tongyi Qianwen LICENSE AGREEMENT, Copyright (c) Alibaba Cloud. All Rights Reserved.\"; and\n    d. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such derivative works as a whole, provided Your use, reproduction, and distribution of the work otherwise complies with the terms and conditions of this Agreement.\n\n4. Restrictions\nIf you are commercially using the Materials, and your product or service has more than 100 million monthly active users, You shall request a license from Us. You cannot exercise your rights under this Agreement without our express authorization.\n\n5. Rules of use\n    a. The Materials may be subject to export controls or restrictions in China, the United States or other countries or regions. You shall comply with applicable laws and regulations in your use of the Materials.\n    b. You can not use the Materials or any output therefrom to improve any other large language model (excluding Tongyi Qianwen or derivative works thereof).\n\n6. Intellectual Property\n    a. We retain ownership of all intellectual property rights in and to the Materials and derivatives made by or for Us. Conditioned upon compliance with the terms and conditions of this Agreement, with respect to any derivative works and modifications of the Materials that are made by you, you are and will be the owner of such derivative works and modifications.\n    b. No trademark license is granted to use the trade names, trademarks, service marks, or product names of Us, except as required to fulfill notice requirements under this Agreement or as required for reasonable and customary use in describing and redistributing the Materials.\n    c. If you commence a lawsuit or other proceedings (including a cross-claim or counterclaim in a lawsuit) against Us or any entity alleging that the Materials or any output therefrom, or any part of the foregoing, infringe any intellectual property or other right owned or licensable by you, then all licences granted to you under this Agreement shall terminate as of the date such lawsuit or other proceeding is commenced or brought.\n\n7. Disclaimer of Warranty and Limitation of Liability\n\n    a. We are not obligated to support, update, provide training for, or develop any further version of the Tongyi Qianwen Materials or to grant any license thereto.\n    b. THE MATERIALS ARE PROVIDED \"AS IS\" WITHOUT ANY EXPRESS OR IMPLIED WARRANTY OF ANY KIND INCLUDING WARRANTIES OF MERCHANTABILITY, NONINFRINGEMENT, OR FITNESS FOR A PARTICULAR PURPOSE. WE MAKE NO WARRANTY AND ASSUME NO RESPONSIBILITY FOR THE SAFETY OR STABILITY OF THE MATERIALS AND ANY OUTPUT THEREFROM.\n    c. IN NO EVENT SHALL WE BE LIABLE TO YOU FOR ANY DAMAGES, INCLUDING, BUT NOT LIMITED TO ANY DIRECT, OR INDIRECT, SPECIAL OR CONSEQUENTIAL DAMAGES ARISING FROM YOUR USE OR INABILITY TO USE THE MATERIALS OR ANY OUTPUT OF IT, NO MATTER HOW IT’S CAUSED.\n    d. You will defend, indemnify and hold harmless Us from and against any claim by any third party arising out of or related to your use or distribution of the Materials.\n\n8. Survival and Termination.\n    a. The term of this Agreement shall commence upon your acceptance of this Agreement or access to the Materials and will continue in full force and effect until terminated in accordance with the terms and conditions herein.\n    b. We may terminate this Agreement if you breach any of the terms or conditions of this Agreement. Upon termination of this Agreement, you must delete and cease use of the Materials. Sections 7 and 9 shall survive the termination of this Agreement.\n\n9. Governing Law and Jurisdiction.\n    a. This Agreement and any dispute arising out of or relating to it will be governed by the laws of China, without regard to conflict of law principles, and the UN Convention on Contracts for the International Sale of Goods does not apply to this Agreement.\n    b. The People's Courts in Hangzhou City shall have exclusive jurisdiction over any dispute arising out of this Agreement.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.0830078125,
          "content": "include qwen_agent/utils/qwen.tiktoken\nrecursive-include qwen_agent/tools/resource *\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 8.1572265625,
          "content": "[中文](https://github.com/QwenLM/Qwen-Agent/blob/main/README_CN.md) ｜ English\n\n<p align=\"center\">\n    <img src=\"https://qianwen-res.oss-cn-beijing.aliyuncs.com/assets/qwen_agent/logo-qwen-agent.png\" width=\"400\"/>\n<p>\n<br>\n\nQwen-Agent is a framework for developing LLM applications based on the instruction following, tool usage, planning, and\nmemory capabilities of Qwen.\nIt also comes with example applications such as Browser Assistant, Code Interpreter, and Custom Assistant.\n\n# News\n* Dec 3, 2024: Upgrade GUI to Gradio 5 based. Note: GUI requires Python 3.10 or higher.\n* 🔥🔥🔥 Sep 18, 2024: Added [Qwen2.5-Math Demo](./examples/tir_math.py) to showcase the Tool-Integrated Reasoning capabilities of Qwen2.5-Math. Note: The python executor is not sandboxed and is intended for local testing only, not for production use.\n\n# Getting Started\n\n## Installation\n\n- Install the stable version from PyPI:\n```bash\npip install -U \"qwen-agent[gui,rag,code_interpreter,python_executor]\"\n# Or use `pip install -U qwen-agent` for the minimal requirements.\n# The optional requirements, specified in double brackets, are:\n#   [gui] for Gradio-based GUI support;\n#   [rag] for RAG support;\n#   [code_interpreter] for Code Interpreter support;\n#   [python_executor] for Tool-Integrated Reasoning with Qwen2.5-Math.\n```\n\n- Alternatively, you can install the latest development version from the source:\n```bash\ngit clone https://github.com/QwenLM/Qwen-Agent.git\ncd Qwen-Agent\npip install -e ./\"[gui,rag,code_interpreter,python_executor]\"\n# Or `pip install -e ./` for minimal requirements.\n```\n\n## Preparation: Model Service\n\nYou can either use the model service provided by Alibaba\nCloud's [DashScope](https://help.aliyun.com/zh/dashscope/developer-reference/quick-start), or deploy and use your own\nmodel service using the open-source Qwen models.\n\n- If you choose to use the model service offered by DashScope, please ensure that you set the environment\nvariable `DASHSCOPE_API_KEY` to your unique DashScope API key.\n\n- Alternatively, if you prefer to deploy and use your own model service, please follow the instructions provided in the README of Qwen2 for deploying an OpenAI-compatible API service.\nSpecifically, consult the [vLLM](https://github.com/QwenLM/Qwen2?tab=readme-ov-file#vllm) section for high-throughput GPU deployment or the [Ollama](https://github.com/QwenLM/Qwen2?tab=readme-ov-file#ollama) section for local CPU (+GPU) deployment.\n\n## Developing Your Own Agent\n\nQwen-Agent offers atomic components, such as LLMs (which inherit from `class BaseChatModel` and come with [function calling](https://github.com/QwenLM/Qwen-Agent/blob/main/examples/function_calling.py)) and Tools (which inherit\nfrom `class BaseTool`), along with high-level components like Agents (derived from `class Agent`).\n\nThe following example illustrates the process of creating an agent capable of reading PDF files and utilizing tools, as\nwell as incorporating a custom tool:\n\n```py\nimport pprint\nimport urllib.parse\nimport json5\nfrom qwen_agent.agents import Assistant\nfrom qwen_agent.tools.base import BaseTool, register_tool\n\n\n# Step 1 (Optional): Add a custom tool named `my_image_gen`.\n@register_tool('my_image_gen')\nclass MyImageGen(BaseTool):\n    # The `description` tells the agent the functionality of this tool.\n    description = 'AI painting (image generation) service, input text description, and return the image URL drawn based on text information.'\n    # The `parameters` tell the agent what input parameters the tool has.\n    parameters = [{\n        'name': 'prompt',\n        'type': 'string',\n        'description': 'Detailed description of the desired image content, in English',\n        'required': True\n    }]\n\n    def call(self, params: str, **kwargs) -> str:\n        # `params` are the arguments generated by the LLM agent.\n        prompt = json5.loads(params)['prompt']\n        prompt = urllib.parse.quote(prompt)\n        return json5.dumps(\n            {'image_url': f'https://image.pollinations.ai/prompt/{prompt}'},\n            ensure_ascii=False)\n\n\n# Step 2: Configure the LLM you are using.\nllm_cfg = {\n    # Use the model service provided by DashScope:\n    'model': 'qwen-max',\n    'model_server': 'dashscope',\n    # 'api_key': 'YOUR_DASHSCOPE_API_KEY',\n    # It will use the `DASHSCOPE_API_KEY' environment variable if 'api_key' is not set here.\n\n    # Use a model service compatible with the OpenAI API, such as vLLM or Ollama:\n    # 'model': 'Qwen2-7B-Chat',\n    # 'model_server': 'http://localhost:8000/v1',  # base_url, also known as api_base\n    # 'api_key': 'EMPTY',\n\n    # (Optional) LLM hyperparameters for generation:\n    'generate_cfg': {\n        'top_p': 0.8\n    }\n}\n\n# Step 3: Create an agent. Here we use the `Assistant` agent as an example, which is capable of using tools and reading files.\nsystem_instruction = '''You are a helpful assistant.\nAfter receiving the user's request, you should:\n- first draw an image and obtain the image url,\n- then run code `request.get(image_url)` to download the image,\n- and finally select an image operation from the given document to process the image.\nPlease show the image using `plt.show()`.'''\ntools = ['my_image_gen', 'code_interpreter']  # `code_interpreter` is a built-in tool for executing code.\nfiles = ['./examples/resource/doc.pdf']  # Give the bot a PDF file to read.\nbot = Assistant(llm=llm_cfg,\n                system_message=system_instruction,\n                function_list=tools,\n                files=files)\n\n# Step 4: Run the agent as a chatbot.\nmessages = []  # This stores the chat history.\nwhile True:\n    # For example, enter the query \"draw a dog and rotate it 90 degrees\".\n    query = input('user query: ')\n    # Append the user query to the chat history.\n    messages.append({'role': 'user', 'content': query})\n    response = []\n    for response in bot.run(messages=messages):\n        # Streaming output.\n        print('bot response:')\n        pprint.pprint(response, indent=2)\n    # Append the bot responses to the chat history.\n    messages.extend(response)\n```\n\nIn addition to using built-in agent implementations such as `class Assistant`, you can also develop your own agent implemetation by inheriting from `class Agent`.\n\nThe framework also provides a convenient GUI interface, supporting the rapid deployment of Gradio Demos for Agents.\nFor example, in the case above, you can quickly launch a Gradio Demo using the following code:\n\n```py\nfrom qwen_agent.gui import WebUI\nWebUI(bot).run()  # bot is the agent defined in the above code, we do not repeat the definition here for saving space.\n```\nNow you can chat with the Agent in the web UI. Please refer to the [examples](https://github.com/QwenLM/Qwen-Agent/blob/main/examples) directory for more usage examples.\n\n# FAQ\n\n## Do you have function calling (aka tool calling)?\n\nYes. The LLM classes provide [function calling](https://github.com/QwenLM/Qwen-Agent/blob/main/examples/function_calling.py). Additionally, some Agent classes also are built upon the function calling capability, e.g., FnCallAgent and ReActChat.\n\n## How to do question-answering over super-long documents involving 1M tokens?\n\nWe have released [a fast RAG solution](https://github.com/QwenLM/Qwen-Agent/blob/main/examples/assistant_rag.py), as well as [an expensive but competitive agent](https://github.com/QwenLM/Qwen-Agent/blob/main/examples/parallel_doc_qa.py), for doing question-answering over super-long documents. They have managed to outperform native long-context models on two challenging benchmarks while being more efficient, and perform perfectly in the single-needle \"needle-in-the-haystack\" pressure test involving 1M-token contexts. See the [blog](https://qwenlm.github.io/blog/qwen-agent-2405/) for technical details.\n\n<p align=\"center\">\n    <img src=\"https://qianwen-res.oss-cn-beijing.aliyuncs.com/assets/qwen_agent/qwen-agent-2405-blog-long-context-results.png\" width=\"400\"/>\n<p>\n\n# Application: BrowserQwen\n\nBrowserQwen is a browser assistant built upon Qwen-Agent. Please refer to its [documentation](https://github.com/QwenLM/Qwen-Agent/blob/main/browser_qwen.md) for details.\n\n# Disclaimer\n\nThe code interpreter is not sandboxed, and it executes code in your own environment. Please do not ask Qwen to perform dangerous tasks, and do not directly use the code interpreter for production purposes.\n"
        },
        {
          "name": "README_CN.md",
          "type": "blob",
          "size": 7.9228515625,
          "content": "中文 ｜ [English](./README.md)\n\n<p align=\"center\">\n    <img src=\"https://qianwen-res.oss-cn-beijing.aliyuncs.com/assets/qwen_agent/logo-qwen-agent.png\" width=\"400\"/>\n<p>\n<br>\n\nQwen-Agent是一个开发框架。开发者可基于本框架开发Agent应用，充分利用基于通义千问模型（Qwen）的指令遵循、工具使用、规划、记忆能力。本项目也提供了浏览器助手、代码解释器、自定义助手等示例应用。\n\n# 更新\n* Dec 3, 2024: GUI 升级为基于 Gradio 5。注意：如果需要使用GUI，Python版本需要3.10及以上。\n* 🔥🔥🔥Sep 18, 2024: 新增[Qwen2.5-Math Demo](./examples/tir_math.py)以展示Qwen2.5-Math基于工具的推理能力。注意：代码执行工具未进行沙箱保护，仅适用于本地测试，不可用于生产。\n\n# 开始上手\n\n## 安装\n\n- 从 PyPI 安装稳定版本：\n```bash\npip install -U \"qwen-agent[rag,code_interpreter,python_executor,gui]\"\n# 或者，使用 `pip install -U qwen-agent` 来安装最小依赖。\n# 可使用双括号指定如下的可选依赖：\n#   [gui] 用于提供基于 Gradio 的 GUI 支持；\n#   [rag] 用于支持 RAG；\n#   [code_interpreter] 用于提供代码解释器相关支持；\n#   [python_executor] 用于支持 Qwen2.5-Math 基于工具的推理。\n```\n\n- 或者，你可以从源码安装最新的开发版本：\n```bash\ngit clone https://github.com/QwenLM/Qwen-Agent.git\ncd Qwen-Agent\npip install -e ./\"[rag,code_interpreter,python_executor]\"\n# 或者，使用 `pip install -e ./` 安装最小依赖。\n```\n\n如果需要内置 GUI 支持，请选择性地安装可选依赖：\n```bash\npip install -U \"qwen-agent[gui,rag,code_interpreter]\"\n# 或者通过源码安装 `pip install -e ./\"[gui,rag,code_interpreter]\"`\n```\n\n## 准备：模型服务\n\nQwen-Agent支持接入阿里云[DashScope](https://help.aliyun.com/zh/dashscope/developer-reference/quick-start)服务提供的Qwen模型服务，也支持通过OpenAI API方式接入开源的Qwen模型服务。\n\n- 如果希望接入DashScope提供的模型服务，只需配置相应的环境变量`DASHSCOPE_API_KEY`为您的DashScope API Key。\n\n- 或者，如果您希望部署并使用您自己的模型服务，请按照Qwen2的README中提供的指导进行操作，以部署一个兼容OpenAI接口协议的API服务。\n具体来说，请参阅[vLLM](https://github.com/QwenLM/Qwen2?tab=readme-ov-file#vllm)一节了解高并发的GPU部署方式，或者查看[Ollama](https://github.com/QwenLM/Qwen2?tab=readme-ov-file#ollama)一节了解本地CPU（+GPU）部署。\n\n## 快速开发\n\n框架提供了大模型（LLM，继承自`class BaseChatModel`，并提供了[Function Calling](./examples/function_calling.py)功能）和工具（Tool，继承自`class BaseTool`）等原子组件，也提供了智能体（Agent）等高级抽象组件（继承自`class Agent`）。\n\n以下示例演示了如何增加自定义工具，并快速开发一个带有设定、知识库和工具使用能力的智能体：\n\n```py\nimport pprint\nimport urllib.parse\nimport json5\nfrom qwen_agent.agents import Assistant\nfrom qwen_agent.tools.base import BaseTool, register_tool\n\n\n# 步骤 1（可选）：添加一个名为 `my_image_gen` 的自定义工具。\n@register_tool('my_image_gen')\nclass MyImageGen(BaseTool):\n    # `description` 用于告诉智能体该工具的功能。\n    description = 'AI 绘画（图像生成）服务，输入文本描述，返回基于文本信息绘制的图像 URL。'\n    # `parameters` 告诉智能体该工具有哪些输入参数。\n    parameters = [{\n        'name': 'prompt',\n        'type': 'string',\n        'description': '期望的图像内容的详细描述',\n        'required': True\n    }]\n\n    def call(self, params: str, **kwargs) -> str:\n        # `params` 是由 LLM 智能体生成的参数。\n        prompt = json5.loads(params)['prompt']\n        prompt = urllib.parse.quote(prompt)\n        return json5.dumps(\n            {'image_url': f'https://image.pollinations.ai/prompt/{prompt}'},\n            ensure_ascii=False)\n\n\n# 步骤 2：配置您所使用的 LLM。\nllm_cfg = {\n    # 使用 DashScope 提供的模型服务：\n    'model': 'qwen-max',\n    'model_server': 'dashscope',\n    # 'api_key': 'YOUR_DASHSCOPE_API_KEY',\n    # 如果这里没有设置 'api_key'，它将读取 `DASHSCOPE_API_KEY` 环境变量。\n\n    # 使用与 OpenAI API 兼容的模型服务，例如 vLLM 或 Ollama：\n    # 'model': 'Qwen2-7B-Chat',\n    # 'model_server': 'http://localhost:8000/v1',  # base_url，也称为 api_base\n    # 'api_key': 'EMPTY',\n\n    # （可选） LLM 的超参数：\n    'generate_cfg': {\n        'top_p': 0.8\n    }\n}\n\n# 步骤 3：创建一个智能体。这里我们以 `Assistant` 智能体为例，它能够使用工具并读取文件。\nsystem_instruction = '''你是一个乐于助人的AI助手。\n在收到用户的请求后，你应该：\n- 首先绘制一幅图像，得到图像的url，\n- 然后运行代码`request.get`以下载该图像的url，\n- 最后从给定的文档中选择一个图像操作进行图像处理。\n用 `plt.show()` 展示图像。\n你总是用中文回复用户。'''\ntools = ['my_image_gen', 'code_interpreter']  # `code_interpreter` 是框架自带的工具，用于执行代码。\nfiles = ['./examples/resource/doc.pdf']  # 给智能体一个 PDF 文件阅读。\nbot = Assistant(llm=llm_cfg,\n                system_message=system_instruction,\n                function_list=tools,\n                files=files)\n\n# 步骤 4：作为聊天机器人运行智能体。\nmessages = []  # 这里储存聊天历史。\nwhile True:\n    # 例如，输入请求 \"绘制一只狗并将其旋转 90 度\"。\n    query = input('用户请求: ')\n    # 将用户请求添加到聊天历史。\n    messages.append({'role': 'user', 'content': query})\n    response = []\n    for response in bot.run(messages=messages):\n        # 流式输出。\n        print('机器人回应:')\n        pprint.pprint(response, indent=2)\n    # 将机器人的回应添加到聊天历史。\n    messages.extend(response)\n```\n\n除了使用框架自带的智能体实现（如`class Assistant`），您也可以通过继承`class Agent`来自行开发您的智能体实现。\n\n框架还提供了便捷的GUI接口，支持为Agent快速部署Gradio Demo。\n例如上面的例子中，可以使用以下代码快速启动Gradio Demo：\n\n```py\nfrom qwen_agent.gui import WebUI\nWebUI(bot).run()  # bot is the agent defined in the above code, we do not repeat the definition here for saving space.\n```\n\n现在您可以在Web UI中和Agent对话了。更多使用示例，请参阅[examples](./examples)目录。\n\n# FAQ\n\n## 支持函数调用（也称为工具调用）吗？\n\n支持，LLM类提供了[函数调用](https://github.com/QwenLM/Qwen-Agent/blob/main/examples/function_calling.py)的支持。此外，一些Agent类如FnCallAgent和ReActChat也是基于函数调用功能构建的。\n\n## 如何让AI基于超长文档进行问答？\n\n我们已发布了一个[快速的RAG解决方案](https://github.com/QwenLM/Qwen-Agent/blob/main/examples/assistant_rag.py)，以及一个虽运行成本较高但[准确度较高的智能体](https://github.com/QwenLM/Qwen-Agent/blob/main/examples/parallel_doc_qa.py)，用于在超长文档中进行问答。它们在两个具有挑战性的基准测试中表现出色，超越了原生的长上下文模型，同时更加高效，并在涉及100万字词上下文的“大海捞针”式单针查询压力测试中表现完美。欲了解技术细节，请参阅[博客](https://qwenlm.github.io/blog/qwen-agent-2405/)。\n\n<p align=\"center\">\n    <img src=\"https://qianwen-res.oss-cn-beijing.aliyuncs.com/assets/qwen_agent/qwen-agent-2405-blog-long-context-results.png\" width=\"400\"/>\n<p>\n\n# 应用：BrowserQwen\n\nBrowserQwen 是一款基于 Qwen-Agent 构建的浏览器助手。如需了解详情，请参阅其[文档](browser_qwen_cn.md)。\n\n# 免责声明\n\n代码解释器未进行沙盒隔离，会在部署环境中执行代码。请避免向Qwen发出危险指令，切勿将该代码解释器直接用于生产目的。\n"
        },
        {
          "name": "assets",
          "type": "tree",
          "content": null
        },
        {
          "name": "benchmark",
          "type": "tree",
          "content": null
        },
        {
          "name": "browser_qwen.md",
          "type": "blob",
          "size": 4.37109375,
          "content": "# Example Application: BrowserQwen\n\nWe have also developed an example application based on Qwen-Agent: a **Chrome browser extension** called BrowserQwen,\nwhich has key features such as:\n\n- You can discuss with Qwen regarding the current webpage or PDF document.\n- It records the web pages and PDF/Word/PowerPoint materials that you have browsed. It helps you understand multiple\n  pages, summarize your browsing content, and automate writing tasks.\n- It comes with plugin integration, including **Code Interpreter** for math problem solving and data visualization.\n\n## BrowserQwen Demonstration\n\nYou can watch the following showcase videos to learn about the basic operations of BrowserQwen:\n\n- Long-form writing based on visited webpages and\n  PDFs. [video](https://qianwen-res.oss-cn-beijing.aliyuncs.com/assets/qwen_agent/showcase_write_article_based_on_webpages_and_pdfs.mp4)\n- Drawing a plot using code interpreter based on the given\n  information. [video](https://qianwen-res.oss-cn-beijing.aliyuncs.com/assets/qwen_agent/showcase_chat_with_docs_and_code_interpreter.mp4)\n- Uploading files, multi-turn conversation, and data analysis using code\n  interpreter. [video](https://qianwen-res.oss-cn-beijing.aliyuncs.com/assets/qwen_agent/showcase_code_interpreter_multi_turn_chat.mp4)\n\n### Workstation - Editor Mode\n\n**This mode is designed for creating long articles based on browsed web pages and PDFs.**\n\n<figure>\n    <img src=\"assets/screenshot-writing.png\">\n</figure>\n\n**It allows you to call plugins to assist in rich text creation.**\n\n<figure>\n    <img src=\"assets/screenshot-editor-movie.png\">\n</figure>\n\n### Workstation - Chat Mode\n\n**In this mode, you can engage in multi-webpage QA.**\n\n<figure >\n    <img src=\"assets/screenshot-multi-web-qa.png\">\n</figure>\n\n**Create data charts using the code interpreter.**\n\n<figure>\n    <img src=\"assets/screenshot-ci.png\">\n</figure>\n\n### Browser Assistant\n\n**Web page QA**\n\n<figure>\n    <img src=\"assets/screenshot-web-qa.png\">\n</figure>\n\n**PDF document QA**\n\n<figure>\n    <img src=\"assets/screenshot-pdf-qa.png\">\n</figure>\n\n## BrowserQwen User Guide\n\n### Step 1. Deploy Local Database Service\n\nOn your local machine (the machine where you can open the Chrome browser), you will need to deploy a database service to\nmanage your browsing history and conversation history.\n\nIf you are using DashScope's model service, then please execute the following command:\n\n```bash\n# Start the database service, specifying the model on DashScope by using the --llm flag.\n# The value of --llm can be one of the following, in increasing order of resource consumption:\n#   - qwen1.5-7b/14b/72b-chat (the same as the open-sourced Qwen1.5 7B/14B/72B Chat model)\n#   - qwen-turbo, qwen-plus, qwen-max (qwen-max is recommended)\n# \"YOUR_DASHSCOPE_API_KEY\" is a placeholder. The user should replace it with their actual key.\npython run_server.py --llm qwen-max --model_server dashscope --workstation_port 7864 --api_key YOUR_DASHSCOPE_API_KEY\n```\n\nIf you are using your own model service instead of DashScope, then please execute the following command:\n\n```bash\n# Specify the model service, and start the database service.\n# Example: Assuming Qwen1.5-72B-Chat is deployed at http://localhost:8000/v1 using vLLM, you can specify the model service as:\n#   --llm Qwen1.5-72B-Chat --model_server http://localhost:8000/v1 --api_key EMPTY\npython run_server.py --llm {MODEL} --model_server {API_BASE} --workstation_port 7864 --api_key {API_KEY}\n```\n\nNow you can access [http://127.0.0.1:7864/](http://127.0.0.1:7864/) to use the Workstation's Editor mode and Chat mode.\n\n### Step 2. Install Browser Assistant\n\nInstall the BrowserQwen Chrome extension:\n\n- Open the Chrome browser and enter `chrome://extensions/` in the address bar, then press Enter.\n- Make sure that the `Developer mode` in the top right corner is turned on, then click on `Load unpacked` to upload\n  the `browser_qwen` directory from this project and enable it.\n- Click the extension icon in the top right corner of the Chrome browser to pin BrowserQwen to the toolbar.\n\nNote that after installing the Chrome extension, you need to refresh the page for the extension to take effect.\n\nWhen you want Qwen to read the content of the current webpage:\n\n- Click the `Add to Qwen's Reading List` button on the screen to authorize Qwen to analyze the page in the background.\n- Click the Qwen icon in the browser's top right corner to start interacting with Qwen about the current page's content.\n"
        },
        {
          "name": "browser_qwen",
          "type": "tree",
          "content": null
        },
        {
          "name": "browser_qwen_cn.md",
          "type": "blob",
          "size": 4.150390625,
          "content": "# 示例应用：BrowserQwen\n\n我们在Qwen-Agent的基础上开发了一个较为复杂的Agent应用，名为BrowserQwen的**Chrome浏览器扩展**，它具有以下主要功能：\n\n- 与Qwen讨论当前网页或PDF文档的内容。\n- BrowserQwen会记录您浏览过的网页和PDF/Word/PPT材料，帮助您了解多个页面的内容、总结浏览过的内容、自动化繁琐的文字工作。\n- 集成各种插件，包括可用于数学问题求解、数据分析与可视化、处理文件等的**代码解释器**（**Code Interpreter**）。\n\n## BrowserQwen 功能演示\n\n可查看以下几个演示视频，了解BrowserQwen的核心功能和基本操作：\n\n- 根据浏览过的网页、PDFs进行长文创作 [video](https://qianwen-res.oss-cn-beijing.aliyuncs.com/assets/qwen_agent/showcase_write_article_based_on_webpages_and_pdfs.mp4)\n- 提取浏览内容使用代码解释器画图 [video](https://qianwen-res.oss-cn-beijing.aliyuncs.com/assets/qwen_agent/showcase_chat_with_docs_and_code_interpreter.mp4)\n- 上传文件、多轮对话利用代码解释器分析数据 [video](https://qianwen-res.oss-cn-beijing.aliyuncs.com/assets/qwen_agent/showcase_code_interpreter_multi_turn_chat.mp4)\n\n### 工作台 - 创作模式\n\n**根据浏览过的网页、PDFs素材进行长文创作**\n\n<figure>\n    <img src=\"assets/screenshot-writing.png\">\n</figure>\n\n**调用插件辅助富文本创作**\n\n<figure>\n    <img src=\"assets/screenshot-editor-movie.png\">\n</figure>\n\n### 工作台 - 对话模式\n\n**多网页问答**\n\n<figure >\n    <img src=\"assets/screenshot-multi-web-qa.png\">\n</figure>\n\n**使用代码解释器绘制数据图表**\n\n<figure>\n    <img src=\"assets/screenshot-ci.png\">\n</figure>\n\n### 浏览器助手\n\n**网页问答**\n\n<figure>\n    <img src=\"assets/screenshot-web-qa.png\">\n</figure>\n\n**PDF文档问答**\n\n<figure>\n    <img src=\"assets/screenshot-pdf-qa.png\">\n</figure>\n\n## BrowserQwen 使用说明\n\n### 第一步 - 部署本地数据库服务\n\n在这一步，您需要在您的本地机器上（即您可以打开Chrome浏览器的那台机器），部署维护个人浏览历史、对话历史的数据库服务。\n\n如果您使用DashScope提供的模型服务的话，请执行以下命令启动数据库服务：\n\n```bash\n# 启动数据库服务，通过 --llm 参数指定您希望通过DashScope使用的具体模型\n# 参数 --llm 可以是如下之一，按资源消耗从小到大排序：\n#   - qwen1.5-7b/14b/72b-chat （与开源的Qwen1.5-7B/14B/72B-Chat相同模型）\n#   - qwen-turbo, qwen-plus, qwen-max （推荐使用qwen-max）\n# 您需要将YOUR_DASHSCOPE_API_KEY替换为您的真实API-KEY。\npython run_server.py --llm qwen-max --model_server dashscope --workstation_port 7864 --api_key YOUR_DASHSCOPE_API_KEY\n```\n\n如果您没有在使用DashScope、而是部署了自己的模型服务的话，请执行以下命令：\n\n```bash\n# 指定模型服务，并启动数据库服务。\n# 示例: 假设Qwen1.5-72B-Chat已经通过vLLM部署于http://localhost:8000/v1，则可用以下参数指定模型服务：\n#   --llm Qwen1.5-72B-Chat --model_server http://localhost:8000/v1 --api_key EMPTY\npython run_server.py --llm {MODEL} --model_server {API_BASE} --workstation_port 7864 --api_key {API_KEY}\n```\n\n现在您可以访问 [http://127.0.0.1:7864/](http://127.0.0.1:7864/) 来使用工作台（Workstation）的创作模式（Editor模式）和对话模式（Chat模式）了。\n\n### 第二步 - 安装浏览器助手\n\n安装BrowserQwen的Chrome插件（又称Chrome扩展程序）：\n\n1. 打开Chrome浏览器，在浏览器的地址栏中输入 `chrome://extensions/` 并按下回车键；\n2. 确保右上角的 `开发者模式` 处于打开状态，之后点击 `加载已解压的扩展程序` 上传本项目下的 `browser_qwen` 目录并启用；\n3. 单击谷歌浏览器右上角```扩展程序```图标，将BrowserQwen固定在工具栏。\n\n注意，安装Chrome插件后，需要刷新页面，插件才能生效。\n\n当您想让Qwen阅读当前网页的内容时：\n\n1. 请先点击屏幕上的 `Add to Qwen's Reading List` 按钮，以授权Qwen在后台分析本页面。\n2. 再单击浏览器右上角扩展程序栏的Qwen图标，便可以和Qwen交流当前页面的内容了。\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "qwen_agent",
          "type": "tree",
          "content": null
        },
        {
          "name": "qwen_server",
          "type": "tree",
          "content": null
        },
        {
          "name": "run_server.py",
          "type": "blob",
          "size": 4.6396484375,
          "content": "import argparse\nimport json\nimport os\nimport signal\nimport subprocess\nimport sys\nfrom pathlib import Path\n\nfrom qwen_server.schema import GlobalConfig\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        '-m',\n        '--model_server',\n        type=str,\n        default='dashscope',\n        help='Set it to `dashscope` if you are using the model service provided by DashScope.'\n        ' Set it to the base_url (aka api_base) if using an OpenAI API-compatible service such as vLLM or Ollama.'\n        ' Default: dashscope',\n    )\n    parser.add_argument(\n        '-k',\n        '--api_key',\n        type=str,\n        default='',\n        help='You API key to DashScope or the OpenAI API-compatible model service.',\n    )\n    parser.add_argument(\n        '-l',\n        '--llm',\n        type=str,\n        default='qwen-plus',\n        help='Set it to one of {\"qwen-max\", \"qwen-plus\", \"qwen-turbo\"} if using DashScope.'\n        ' Set it to the model name using an OpenAI API-compatible model service.'\n        ' Default: qwen-plus',\n    )\n    parser.add_argument(\n        '-s',\n        '--server_host',\n        type=str,\n        default='127.0.0.1',\n        choices=['127.0.0.1', '0.0.0.0'],\n        help='Set to 0.0.0.0 if you want to allow other machines to access the server. Default: 127.0.0.1',\n    )\n    parser.add_argument(\n        '-t',\n        '--max_ref_token',\n        type=int,\n        default=4000,\n        help='Tokens reserved for the reference materials of retrieval-augmanted generation (RAG). Default: 4000',\n    )\n    parser.add_argument(\n        '-w',\n        '--workstation_port',\n        type=int,\n        default=7864,\n        help='The port of the creative writing workstation. Default: 7864',\n    )\n    args = parser.parse_args()\n    args.model_server = args.model_server.replace('0.0.0.0', '127.0.0.1')\n    return args\n\n\ndef update_config(server_config, args, server_config_path):\n    server_config.server.model_server = args.model_server\n    server_config.server.api_key = args.api_key\n    server_config.server.llm = args.llm\n    server_config.server.server_host = args.server_host\n    server_config.server.max_ref_token = args.max_ref_token\n    server_config.server.workstation_port = args.workstation_port\n\n    with open(server_config_path, 'w') as f:\n        try:\n            cfg = server_config.model_dump_json()\n        except AttributeError:  # for pydantic v1\n            cfg = server_config.json()\n        json.dump(json.loads(cfg), f, ensure_ascii=False, indent=4)\n    return server_config\n\n\ndef main():\n    args = parse_args()\n    server_config_path = Path(__file__).resolve().parent / 'qwen_server/server_config.json'\n    with open(server_config_path, 'r') as f:\n        server_config = json.load(f)\n        server_config = GlobalConfig(**server_config)\n    server_config = update_config(server_config, args, server_config_path)\n\n    os.makedirs(server_config.path.work_space_root, exist_ok=True)\n    os.makedirs(server_config.path.download_root, exist_ok=True)\n\n    os.makedirs(server_config.path.code_interpreter_ws, exist_ok=True)\n    code_interpreter_work_dir = str(Path(__file__).resolve().parent / server_config.path.code_interpreter_ws)\n\n    # TODO: Remove these two hacky code interpreter env vars.\n    os.environ['M6_CODE_INTERPRETER_WORK_DIR'] = code_interpreter_work_dir\n\n    from qwen_agent.utils.utils import append_signal_handler, get_local_ip, logger\n    logger.info(server_config)\n\n    if args.server_host == '0.0.0.0':\n        static_url = get_local_ip()\n    else:\n        static_url = args.server_host\n    static_url = f'http://{static_url}:{server_config.server.fast_api_port}/static'\n    os.environ['M6_CODE_INTERPRETER_STATIC_URL'] = static_url\n\n    servers = {\n        'database':\n            subprocess.Popen([\n                sys.executable,\n                os.path.join(os.getcwd(), 'qwen_server/database_server.py'),\n            ]),\n        'workstation':\n            subprocess.Popen([\n                sys.executable,\n                os.path.join(os.getcwd(), 'qwen_server/workstation_server.py'),\n            ]),\n        'assistant':\n            subprocess.Popen([\n                sys.executable,\n                os.path.join(os.getcwd(), 'qwen_server/assistant_server.py'),\n            ]),\n    }\n\n    def signal_handler(sig_num, _frame):\n        for v in servers.values():\n            v.terminate()\n        for k in list(servers.keys()):\n            del servers[k]\n        if sig_num == signal.SIGINT:\n            raise KeyboardInterrupt()\n\n    append_signal_handler(signal.SIGINT, signal_handler)\n    append_signal_handler(signal.SIGTERM, signal_handler)\n\n    for p in list(servers.values()):\n        p.wait()\n\n\nif __name__ == '__main__':\n    main()\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 2.9521484375,
          "content": "import re\n\nfrom setuptools import find_packages, setup\n\n\ndef get_version() -> str:\n    with open('qwen_agent/__init__.py', encoding='utf-8') as f:\n        version = re.search(\n            r'^__version__\\s*=\\s*[\\'\"]([^\\'\"]*)[\\'\"]',\n            f.read(),\n            re.MULTILINE,\n        ).group(1)\n    return version\n\n\ndef read_description() -> str:\n    with open('README.md', 'r', encoding='UTF-8') as f:\n        long_description = f.read()\n    return long_description\n\n\n# To update the package at PyPI:\n# ```bash\n# python setup.py sdist bdist_wheel\n# twine upload dist/*\n# ```\nsetup(\n    name='qwen-agent',\n    version=get_version(),\n    author='Qwen Team',\n    author_email='tujianhong.tjh@alibaba-inc.com',\n    description='Qwen-Agent: Enhancing LLMs with Agent Workflows, RAG, Function Calling, and Code Interpreter.',\n    long_description=read_description(),\n    long_description_content_type='text/markdown',\n    keywords=['LLM', 'Agent', 'Function Calling', 'RAG', 'Code Interpreter'],\n    packages=find_packages(exclude=['examples', 'examples.*', 'qwen_server', 'qwen_server.*']),\n    package_data={\n        'qwen_agent': [\n            'utils/qwen.tiktoken', 'tools/resource/*.ttf', 'tools/resource/*.py', 'gui/assets/*.css',\n            'gui/assets/*.jpeg'\n        ],\n    },\n\n    # Minimal dependencies for Function Calling:\n    install_requires=[\n        'dashscope>=1.11.0',\n        'eval_type_backport',\n        'json5',\n        'jsonlines',\n        'jsonschema',\n        'openai',\n        'pydantic>=2.3.0',\n        'requests',\n        'tiktoken',\n    ],\n    extras_require={\n        # Extra dependencies for RAG:\n        'rag': [\n            'charset-normalizer',\n            'rank_bm25',\n            'jieba',\n            'snowballstemmer',\n            'beautifulsoup4',\n            'pdfminer.six',\n            'pdfplumber',\n            'python-docx',\n            'python-pptx',\n            'pandas',\n            'tabulate',\n        ],\n\n        # Extra dependencies for Python Executor, which is primarily for solving math problems:\n        'python_executor': [\n            'pebble',\n            'multiprocess',\n            'timeout_decorator',\n            'python-dateutil',\n            'sympy',\n            'numpy',\n            'scipy',\n        ],\n\n        # Extra dependencies for Code Interpreter:\n        'code_interpreter': [\n            'anyio>=3.7.1',\n            'fastapi>=0.103.1',\n            'jupyter>=1.0.0',\n            'matplotlib',\n            'numpy',\n            'pandas',\n            'pillow',\n            'seaborn',\n            'sympy',\n            'uvicorn>=0.23.2',\n        ],\n\n        # Extra dependencies for Gradio-based GUI:\n        'gui': [\n            # Gradio has bad version compatibility. Therefore, we use `==` instead of `>=`.\n            'pydantic==2.9.2',\n            'pydantic-core==2.23.4',\n            'gradio>=5.0.0',\n            'gradio-client==1.4.0',\n            'modelscope_studio==1.0.0-beta.8',\n        ],\n    },\n    url='https://github.com/QwenLM/Qwen-Agent',\n)\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}