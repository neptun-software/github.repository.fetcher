{
  "metadata": {
    "timestamp": 1736560810385,
    "page": 506,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjUxMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "linyiLYi/street-fighter-ai",
      "stars": 6377,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.064453125,
          "content": "# Auto detect text files and perform LF normalization\n* text=auto\n"
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.6455078125,
          "content": "*.zip\n**/__pycache__/\n*.pyc\n\narchives/\nimages/\n/main/logs/monitoring/\n\n# Mac system files\n/007*\n*.DS_Store\n.DS_Store\n\n# Recorded videos\n/main/recordings/\n\n# Main scripts\n/main/*.py\n!/main/test.py\n!/main/train.py\n!/main/street_fighter_custom_wrapper.py\n\n# Game Data\n/data/*\n!/data/Champion.Level12.RyuVsBison.state\n!/data/data.json\n!/data/metadata.json\n!/data/scenario.json\n!/data/Gym Retro Integration.exe\n\n\n# Model Files\n/main/trained_models/*\n!/main/trained_models/ppo_ryu_2000000_steps_updated.*\n!/main/trained_models/ppo_ryu_2500000_steps_updated.*\n!/main/trained_models/ppo_ryu_3000000_steps_updated.*\n!/main/trained_models/ppo_ryu_7000000_steps_updated.*\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.05859375,
          "content": "Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 6.6484375,
          "content": "# SFighterAI\n\n[简体中文](README_CN.md) | English | [Español](README_ES.md)\n\nThis project is an AI agent trained using deep reinforcement learning to beat the final boss in the game \"Street Fighter II: Special Champion Edition\". The AI agent makes decisions based solely on the game screen's RGB pixel values. In the provided save state, the agent achieves a 100% win rate in the first round of the final level (overfitting occurs, see the [Running Tests](#running-tests) section for discussion).\n\n### File Structure\n\n```bash\n├───data\n├───main\n│   ├───logs\n│   ├───trained_models\n│   └───scripts\n├───utils\n│   └───scripts\n```\n\nThe game configuration files are stored in the `data/` folder, and the main project code is in the `main/` folder. Within `main/`, the `logs/` folder contains terminal/console outputs and data curves recording the training process (viewable with Tensorboard), while the `trained_models/` folder contains model weights from different stages. These weights can be used for running tests in `test.py` to observe the performance of the AI agent's learned strategies at different training stages.\n\n## Running Guide\n\nThis project is based on the Python programming language and primarily utilizes standard libraries like [OpenAI Gym Retro](https://retro.readthedocs.io/en/latest/getting_started.html) and [Stable-Baselines3](https://stable-baselines3.readthedocs.io/en/master/). The Python version used is 3.8.10, and it is recommended to use [Anaconda](https://www.anaconda.com) to configure the Python environment. The following setup process has been tested on Windows 11. Below are console/terminal/shell commands.\n\n### Environment Setup\n\n```bash\n# Create a conda environment named StreetFighterAI with Python version 3.8.10\nconda create -n StreetFighterAI python=3.8.10\nconda activate StreetFighterAI\n\n# Install Python libraries\ncd [parent_directory_of_project]/street-fighter-ai/main\npip install -r requirements.txt\n\n# Run script to locate gym-retro game folder\ncd ..\npython .\\utils\\print_game_lib_folder.py\n```\n\nAfter the console outputs the folder path, copy it to the file explorer and navigate to the corresponding path. This folder contains the game data files for \"Street Fighter II: Special Champion Edition\" within gym-retro, including the game ROM file and data configuration files. Copy the `Champion.Level12.RyuVsBison.state`, `data.json`, `metadata.json`, and `scenario.json` files from the `data/` folder of this project into the game data folder, replacing the original files (administrator privileges may be required). The `.state` file is a save state for the game's highest difficulty level, while the three `.json` files are gym-retro configuration files storing game information memory addresses (this project only uses [agent_hp] and [enemy_hp] for reading character health values in real-time).\n\nTo run the program, you will also need the game ROM file for \"Street Fighter II: Special Champion Edition\", which is not provided by gym-retro and must be obtained legally through other means. You can refer to this [link](https://wowroms.com/en/roms/sega-genesis-megadrive/street-fighter-ii-special-champion-edition-europe/26496.html).\n\nOnce you have legally obtained the game ROM file, copy it to the aforementioned gym-retro game data folder and rename it to `rom.md`. At this point, the environment setup is complete.\n\nNote 1: If you want to manually capture save states and find memory variables in the game, you can use the gym-retro integration ui. Copy `data/Gym Retro Integration.exe` to the parent menu (two levels up, `retro/` folder) of the aforementioned gym-retro game data folder.\n\nNote 2: If you want to record videos of the AI agent's gameplay, you will need to install [ffmpeg](https://ffmpeg.org/).\n\n```bash\nconda install ffmpeg\n```\n\n### <a name=\"running-tests\"></a>Running Tests\n\nOnce the environment is set up, you can run `test.py` in the `main/` folder to test and experience the AI agent's performance at different stages of training.\n\n```bash\ncd [parent_directory_of_project]/street-fighter-ai/main\npython test.py\n```\n\nModel weight files are stored in the `main/trained_models/` folder. The default model used in `test.py` is `ppo_ryu_2500000_steps_updated.zip`, which has good generalization and is capable of beating the final level of Street Fighter II: Special Champion Edition. If you want to see the performance of other models, you can change the `model_path` variable in `test.py` to the path of another model file. The observed performance of the models at various training stages is as follows:\n\n* ppo_ryu_2000000_steps_updated: Just beginning to overfit state, generalizable but not quite capable.\n* ppo_ryu_2500000_steps_updated: Approaching the final overfitted state, cannot dominate first round but partially generalizable. High chance of beating the final stage.\n* ppo_ryu_3000000_steps_updated: Near the final overfitted state, almost dominate first round but barely generalizable.\n* ppo_ryu_7000000_steps_updated: Overfitted, dominates first round but not generalizable. \n\n### Training the Model\n\nIf you want to train your own model, you can run `train.py` in the `main/` folder.\n\n```bash\ncd [parent_directory_of_project]/street-fighter-ai/main\npython train.py\n```\n\n### Viewing Training Curves\n\nThe project includes Tensorboard graphs of the training process. You can use Tensorboard to view detailed data. It is recommended to use the integrated Tensorboard plugin in VSCode to view the data directly. The traditional viewing method is listed below:\n\n```bash\ncd [parent_directory_of_project]/street-fighter-ai/main\ntensorboard --logdir=logs/\n```\n\nOpen the default Tensorboard service address `http://localhost:6006/` in your browser to view interactive graphs of the training process.\n\n## Acknowledgements\nThis project uses open-source libraries such as [OpenAI Gym Retro](https://retro.readthedocs.io/en/latest/getting_started.html), [Stable-Baselines3](https://stable-baselines3.readthedocs.io/en/master/). The contributions of all the developers to the open-source community are appreciated!\n\nTwo papers that had a significant impact on this project:\n\n[1] [DIAMBRA Arena A New Reinforcement Learning Platform for Research and Experimentation](https://arxiv.org/abs/2210.10595)\nThe valuable summary of the experience in setting hyperparameters for deep reinforcement learning models in fighting games in this paper was of great help to the training process of this project.\n\n[2] [Mitigating Cowardice for Reinforcement Learning](https://ieee-cog.org/2022/assets/papers/paper_111.pdf)\nThe \"penalty decay\" mechanism proposed in this paper effectively solved the \"cowardice\" problem (always avoiding opponents and not daring to even try attacking moves)."
        },
        {
          "name": "README_CN.md",
          "type": "blob",
          "size": 6.5166015625,
          "content": "# SFighterAI\n\n简体中文 | [English](README.md) | [Español](README_ES.md)\n\n本项目基于深度强化学习训练了一个用于通关《街头霸王·二：冠军特别版》（Street Fighter II Special Champion Edition）关底 BOSS 的智能 AI 代理。该智能代理完全基于游戏画面（RGB 像素值）进行决策，在该项目给定存档中最后一关的第一轮对局可以取得 100% 胜率（实际上出现了“过拟合”现象，详见[运行测试](#running-tests)部分的讨论）。\n\n### 文件结构\n\n```bash\n├───data\n├───main\n│   ├───logs\n│   ├───trained_models\n│   └───scripts\n├───utils\n│   └───scripts\n```\n\n游戏配置文件存储在 `data/` 文件夹下；项目的主要代码文件夹为 `main/`。其中，`logs/` 中包含了记录训练过程的终端文本和数据曲线（使用 Tensorboard 查看）；`trained_models/` 中包含了不同阶段的模型权重文件，可以用于在 `test.py` 中运行测试，观看智能代理在不同训练阶段学习到的对战策略的效果。\n\n## 运行指南\n\n本项目基于 Python 编程语言，主要使用了 [OpenAI Gym Retro](https://retro.readthedocs.io/en/latest/getting_started.html)、[Stable-Baselines3](https://stable-baselines3.readthedocs.io/en/master/) 等标准代码库。程序运行使用的 Python 版本为 3.8.10，建议使用 [Anaconda](https://www.anaconda.com) 配置 Python 环境。以下配置过程已在 Windows 11 系统上测试通过。以下为控制台/终端（Console/Terminal/Shell）指令。\n\n### 环境配置\n\n```bash\n# 创建 conda 环境，将其命名为 StreetFighterAI，Python 版本 3.8.10\nconda create -n StreetFighterAI python=3.8.10\nconda activate StreetFighterAI\n\n# 安装 Python 代码库\ncd [项目上级文件夹]/street-fighter-ai/main\npip install -r requirements.txt\n\n# 运行程序脚本定位 gym-retro 游戏文件夹位置\ncd ..\npython .\\utils\\print_game_lib_folder.py\n```\n\n控制台输出文件夹路径后，将其复制到文件资源管理器中，跳转到对应路径。该文件夹为 gym-retro 下《街头霸王·二：冠军特别版》的游戏数据文件夹，其中包含了游戏 ROM 文件和数据配置文件。将本项目中 `data/` 文件夹下的 `Champion.Level12.RyuVsBison.state`、`data.json`、`metadata.json`、`scenario.json` 四个文件复制到该文件夹中，覆盖原有文件（可能需要提供管理员权限）。其中 `.state` 文件为《街头霸王·二：冠军特别版》难度四最后一关开局的游戏存档，三个 `.json` 文件为 gym-retro 配置文件，存储了游戏信息的内存地址（本项目只用到了其中的 [agent_hp] 与 [enemey_hp]，用于实时读取游戏人物的生命值）。\n\n运行程序还需要《街头霸王·二：冠军特别版》（Street Fighter II Special Champion Edition）的游戏 ROM 文件（可以理解为游戏程序本身）。gym-retro 本身不提供游戏的 ROM 文件，需要自行通过合法途径获得。可以参考该[链接](https://wowroms.com/en/roms/sega-genesis-megadrive/street-fighter-ii-special-champion-edition-europe/26496.html)。\n\n通过合法途径自行获得游戏 ROM 文件后，将其复制到前述 gym-retro 的游戏数据文件夹下，并重命名为`rom.md`。至此，环境配置准备工作完成。\n\n注 1：如果想在游戏中手动抓取存档、寻找内存变量，可以使用 gym-retro integration ui，将`data/Gym Retro Integration.exe` 复制到前述 gym-retro 游戏数据文件夹下的上级菜单（上两级，`retro/` 文件夹下）即可。\n\n注 2：如果想要录制智能代理的对战视频，还需要安装 [ffmpeg](https://ffmpeg.org/)。\n```bash\nconda install ffmpeg\n```\n\n### <a name=\"running-tests\"></a>运行测试\n\n环境配置完成后，可以在 `main/` 文件夹下运行 `test.py` 进行测试，实际体验智能代理在不同训练阶段的表现。\n\n```bash\ncd [项目上级文件夹]/street-fighter-ai/main\npython test.py\n```\n\n模型权重文件存储在 `main/trained_models/` 文件夹下。其中 `ppo_ryu_2500000_steps_updated.zip` 是 `test.py` 默认使用的模型文件，该模型泛化性较好，有能力打通《街头霸王·二：冠军特别版》的最后一关。如果想要观看其他模型的表现，可以将 `test.py` 中的 `model_path` 变量修改为其他模型文件的路径。关于各训练阶段模型实际表现的观察描述如下：\n\n* ppo_ryu_2000000_steps_updated: 刚开始出现过拟合现象，具有泛化能力但实力不太强。\n* ppo_ryu_2500000_steps_updated: 接近最终过拟合状态，无法在最后一关第一轮中完全占据主导地位，但具有一定泛化能力。在最后一关三轮中有较高的获胜机会。\n* ppo_ryu_3000000_steps_updated: 接近最终过拟合状态，几乎可以在最后一关第一轮中占据主导地位，胜率接近 100%，但泛化能力较弱。\n* ppo_ryu_7000000_steps_updated: 过拟合，在最后一关第一轮中完全占据主导地位，胜率 100%，但泛化能力差。\n\n### 训练模型\n\n如果想要训练自己的模型，可以在 `main/` 文件夹下运行 `train.py`。\n\n```bash\ncd [项目上级文件夹]/street-fighter-ai/main\npython train.py\n```\n\n### 查看曲线\n\n项目中包含了训练过程的 Tensorboard 曲线图，可以使用 Tensorboard 查看其中的详细数据。推荐使用 VSCode 集成的 Tensorboard 插件直接查看（我爱你 VSCode！）。以下列出传统查看方法：\n\n```bash\ncd [项目上级文件夹]/street-fighter-ai/main\ntensorboard --logdir=logs/\n```\n\n在浏览器中打开 Tensorboard 服务默认地址 `http://localhost:6006/`，即可查看训练过程的交互式曲线图。\n\n## 鸣谢\n本项目使用了 [OpenAI Gym Retro](https://retro.readthedocs.io/en/latest/getting_started.html)、[Stable-Baselines3](https://stable-baselines3.readthedocs.io/en/master/) 等开源代码库。感谢各位程序工作者对开源社区的贡献！\n\n特别列出以下两篇对本项目启发作用很大的论文：\n\n[1] [DIAMBRA Arena A New Reinforcement Learning Platform for Research and Experimentation](https://arxiv.org/abs/2210.10595)\n这篇论文中关于格斗游戏深度强化学习模型超参数设置的经验总结非常有价值，对本项目的训练过程有很大的帮助。\n\n[2] [Mitigating Cowardice for Reinforcement Learning](https://ieee-cog.org/2022/assets/papers/paper_111.pdf)\n这篇论文中提出的“惩罚衰减”机制有效地解决了本次训练中智能代理在游戏中的“怯懈”（始终回避对手，不敢尝试攻击）问题，帮助非常大。\n"
        },
        {
          "name": "README_ES.md",
          "type": "blob",
          "size": 7.51953125,
          "content": "# SFighterAI\n\n[简体中文](README_CN.md) | [English](README.md) | Español\n\nEste proyecto es un agente de IA entrenado con aprendizaje por refuerzo profundo para vencer al jefe final en el juego \"Street Fighter II: Special Champion Edition\". El agente de IA toma decisiones basándose únicamente en los valores de los píxeles RGB de la pantalla del juego. En el estado guardado proporcionado, el agente logra una tasa de victorias del 100% en la primera ronda del nivel final (ocurre sobreajuste, consulte la sección [Ejecución de pruebas](#ejecución-de-pruebas) para ver la discusión).\n\n### Estructura de archivos\n\n```bash\n├───data\n├───main\n│   ├───logs\n│   ├───trained_models\n│   └───scripts\n├───utils\n│   └───scripts\n```\n\nLos archivos de configuración del juego se almacenan en la carpeta `data/`, y el código principal del proyecto se encuentra en la carpeta `main/`. Dentro de `main/`, la carpeta `logs/` contiene la salida de la terminal y las curvas de datos que registran el proceso de entrenamiento (se pueden ver con Tensorboard), mientras que la carpeta `trained_models/` contiene los pesos del modelo de diferentes etapas. Estos pesos se pueden utilizar para ejecutar pruebas en `test.py` y observar el rendimiento de las estrategias aprendidas por el agente de IA en diferentes etapas de entrenamiento.\n\n## Guía de ejecución\n\nEste proyecto se basa en el lenguaje de programación Python y utiliza principalmente bibliotecas estándar como [OpenAI Gym Retro](https://retro.readthedocs.io/en/latest/getting_started.html) y [Stable-Baselines3](https://stable-baselines3.readthedocs.io/en/master/). La versión de Python utilizada es 3.8.10, y se recomienda utilizar [Anaconda](https://www.anaconda.com) para configurar el entorno de Python. El siguiente proceso de configuración ha sido probado en Windows 11. A continuación se presentan comandos de la consola/terminal.\n\n### Configuración del entorno\n\n```bash\n# Crear un entorno conda llamado StreetFighterAI con la versión de Python 3.8.10\nconda create -n StreetFighterAI python=3.8.10\nconda activate StreetFighterAI\n\n# Instalar bibliotecas de Python\ncd [directorio_padre_del_proyecto]/street-fighter-ai/main\npip install -r requirements.txt\n\n# Ejecutar script para localizar la carpeta del juego gym-retro\ncd ..\npython .\\utils\\print_game_lib_folder.py\n```\n\nDespués de que la consola muestre la ruta de la carpeta, cópiela en el explorador de archivos y navegue hasta la ruta correspondiente. Esta carpeta contiene los archivos de datos del juego \"Street Fighter II: Special Champion Edition\" dentro de gym-retro, incluyendo el archivo de ROM del juego y los archivos de configuración de datos. Copie los archivos `Champion.Level12.RyuVsBison.state`, `data.json`, `metadata.json` y `scenario.json` de la carpeta `data/` de este proyecto en la carpeta de datos del juego, reemplazando los archivos originales (pueden requerirse privilegios de administrador). El archivo `.state` es un estado guardado para el nivel de dificultad más alto del juego, mientras que los tres archivos `.json` son archivos de configuración de gym-retro que almacenan las direcciones de memoria de la información del juego (este proyecto solo usa [agent_hp] y [enemy_hp] para leer los valores de salud de los personajes en tiempo real).\n\nPara ejecutar el programa, también necesitará el archivo de ROM del juego \"Street Fighter II: Special Champion Edition\", que no es proporcionado por gym-retro y debe obtenerse legalmente por otros medios. Puede consultar este [enlace](https://wowroms.com/en/roms/sega-genesis-megadrive/street-fighter-ii-special-champion-edition-europe/26496.html).\n\nUna vez que haya obtenido legalmente el archivo de ROM del juego, cópielo a la carpeta de datos del juego de gym-retro mencionada anteriormente y cámbiele el nombre a `rom.md`. En este punto, la configuración del entorno está completa.\n\nNota 1: Si desea ver la interfaz de usuario de integración gym-retro en el juego para capturar manualmente el estado guardado y buscar variables de memoria, puede usar la interfaz de integración gym-retro ui, copie `data/Gym Retro Integration.exe` a la carpeta de datos del juego de gym-retro mencionada anteriormente (dos niveles superiores, la carpeta `retro/`).\n\nNota 2: Si desea grabar videos del juego del agente de IA, deberá instalar [ffmpeg](https://ffmpeg.org/).\n\n```bash\nconda install ffmpeg\n```\n\n### Ejecución de pruebas\n\nUna vez configurado el entorno, puede ejecutar `test.py` en la carpeta `main/` para probar y experimentar el rendimiento del agente de IA en diferentes etapas de entrenamiento.\n\n```bash\ncd [directorio_padre_del_proyecto]/street-fighter-ai/main\npython test.py\n```\n\nLos archivos de peso del modelo se almacenan en la carpeta `main/trained_models/`. El modelo predeterminado utilizado en `test.py` es `ppo_ryu_2500000_steps_updated.zip`, que tiene una buena generalización y es capaz de vencer el último nivel de Street Fighter II: Special Champion Edition. Si desea ver el rendimiento de otros modelos, puede cambiar la variable `model_path` en `test.py` a la ruta de otro archivo de modelo. El rendimiento observado de los modelos en varias etapas de entrenamiento es el siguiente:\n\n* ppo_ryu_2000000_steps_updated: Comenzando a entrar en el estado de sobreajuste, generalizable pero no del todo capaz.\n* ppo_ryu_2500000_steps_updated: Acercándose al estado de sobreajuste final, no puede dominar la primera ronda pero parcialmente generalizable. Alta probabilidad de vencer la etapa final.\n* ppo_ryu_3000000_steps_updated: Cerca del estado de sobreajuste final, casi domina la primera ronda pero apenas generalizable.\n* ppo_ryu_7000000_steps_updated: Sobreajustado, domina la primera ronda pero no es generalizable.\n\n### Entrenamiento del modelo\n\nSi deseas entrenar tu propio modelo, puedes ejecutar `train.py`en la carpeta `main/`.\n\n```bash\ncd [directorio_padre_del_proyecto]/street-fighter-ai/main\npython train.py\n```\n\n### Visualización de las curvas de entrenamiento\n\nEl proyecto incluye gráficos de Tensorboard del proceso de entrenamiento. Puedes usar Tensorboard para ver datos detallados. Se recomienda usar el complemento integrado de Tensorboard en VSCode para ver los datos directamente. El método de visualización tradicional se muestra a continuación:\n\n```bash\ncd [directorio_padre_del_proyecto]/street-fighter-ai/main\ntensorboard --logdir=logs/\n```\n\nAbre la dirección predeterminada del servicio Tensorboard `http://localhost:6006/` en tu navegador para ver gráficos interactivos del proceso de entrenamiento.\n\n## Reconocimientos\nEste proyecto utiliza bibliotecas de código abierto como [OpenAI Gym Retro](https://retro.readthedocs.io/en/latest/getting_started.html), [Stable-Baselines3](https://stable-baselines3.readthedocs.io/en/master/). Se agradece la contribución de todos los desarrolladores a la comunidad de código abierto.\n\nDos artículos que tuvieron un impacto significativo en este proyecto:\n\n[1] [DIAMBRA Arena A New Reinforcement Learning Platform for Research and Experimentation](https://arxiv.org/abs/2210.10595)\nEl resumen valioso de la experiencia en la configuración de hiperparámetros para modelos de aprendizaje profundo por refuerzo en juegos de lucha en este artículo fue de gran ayuda para el proceso de entrenamiento de este proyecto.\n\n[2] [Mitigating Cowardice for Reinforcement Learning](https://ieee-cog.org/2022/assets/papers/paper_111.pdf)\nEl mecanismo de \"decaimiento de penalización\" propuesto en este artículo resolvió eficazmente el problema de \"cobardía\" (siempre evitando a los oponentes y sin atreverse a intentar movimientos de ataque)."
        },
        {
          "name": "chats",
          "type": "tree",
          "content": null
        },
        {
          "name": "data",
          "type": "tree",
          "content": null
        },
        {
          "name": "main",
          "type": "tree",
          "content": null
        },
        {
          "name": "utils",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}