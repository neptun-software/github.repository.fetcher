{
  "metadata": {
    "timestamp": 1736560631732,
    "page": 264,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI3MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "deep-floyd/IF",
      "stars": 7712,
      "defaultBranch": "develop",
      "files": [
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.0693359375,
          "content": "notebooks/pipes-DeepFloyd-IF.ipynb filter=lfs diff=lfs merge=lfs -text\n"
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.7724609375,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.idea\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\npip-wheel-metadata/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n.python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, deepfloyd_if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.568359375,
          "content": "repos:\n-   repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.2.0\n    hooks:\n    -   id: check-docstring-first\n    -   id: check-merge-conflict\n        stages:\n        - push\n    -   id: double-quote-string-fixer\n    -   id: end-of-file-fixer\n    -   id: fix-encoding-pragma\n    -   id: mixed-line-ending\n    -   id: trailing-whitespace\n-   repo: https://github.com/pycqa/flake8\n    rev: \"4.0.1\"\n    hooks:\n    -   id: flake8\n        args: ['--config=setup.cfg']\n-   repo: https://github.com/pre-commit/mirrors-autopep8\n    rev: v1.6.0\n    hooks:\n    -   id: autopep8\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 0.5146484375,
          "content": "v1.0.2rc\n-------\n\n- uses separated tokenizer_path to init tokenizer in T5Embedder\n\nv1.0.1\n------\n\n- renamed main model `IF-I-IF` --> `IF-I-XL`\n- moved dir `notebooks` to HF storage https://huggingface.co/DeepFloyd/IF-notebooks; lets keep new notebooks there;\n- added additional kaggle notebook (more free GPU resources) how to generate pictures 1k: [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://www.kaggle.com/code/shonenkov/deepfloyd-if-4-3b-generator-of-pictures)\n\nv1.0.0\n------\n\n- initial version\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.46875,
          "content": "Copyright (c) 2023 DeepFloyd, StabilityAI\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\n1. The above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\n2. All persons obtaining a copy or substantial portion of the Software,\na modified version of the Software (or substantial portion thereof), or\na derivative work based upon this Software (or substantial portion thereof)\nmust not delete, remove, disable, diminish, or circumvent any inference filters or\ninference filter mechanisms in the Software, or any portion of the Software that\nimplements any such filters or filter mechanisms.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "LICENSE-MODEL",
          "type": "blob",
          "size": 11.3427734375,
          "content": "DEEPFLOYD IF LICENSE AGREEMENT\n\nThis License Agreement (as may be amended in accordance with this License Agreement, “License”),\nbetween you, or your employer or other entity (if you are entering into this agreement on behalf\nof your employer or other entity) (“Licensee” or “you”) and Stability AI Ltd.. (“Stability AI” or “we”)\napplies to your use of any computer program, algorithm, source code, object code, or software that is made\navailable by Stability AI under this License (“Software”) and any specifications, manuals, documentation,\nand other written information provided by Stability AI related to the Software (“Documentation”).\nBy clicking “I Accept” below or by using the Software, you agree to the terms of this License.\nIf you do not agree to this License, then you do not have any rights to use the Software or\nDocumentation (collectively, the “Software Products”), and you must immediately cease using\nthe Software Products. If you are agreeing to be bound by the terms of this License on behalf\nof your employer or other entity, you represent and warrant to Stability AI that you have full legal\nauthority to bind your employer or such entity to this License. If you do not have the requisite authority,\nyou may not accept the License or access the Software Products on behalf of your employer or other entity.\n\n1. LICENSE GRANT\n\na. Subject to your compliance with the Documentation and Sections 2, 3, and 5, Stability AI grants\nyou a non-exclusive, worldwide, non-transferable, non-sublicensable, revocable, royalty free and limited\nlicense under Stability AI’s copyright interests to reproduce, distribute, and create derivative works of\nthe Software solely for your non-commercial research purposes. The foregoing license is personal to you,\nand you may not assign or sublicense this License or any other rights or obligations under this License\nwithout Stability AI’s prior written consent; any such assignment or sublicense will be void and will\nautomatically and immediately terminate this License.\n\nb. You may make a reasonable number of copies of the Documentation solely for use in connection with\nthe license to the Software granted above.\n\nc. The grant of rights expressly set forth in this Section 1 (License Grant) are the complete\ngrant of rights to you in the Software Products, and no other licenses are granted, whether by waiver,\nestoppel, implication, equity or otherwise. Stability AI and its licensors reserve all rights\nnot expressly granted by this License.\n\n\n2. RESTRICTIONS\n\nYou will not, and will not permit, assist or cause any third party to:\n\na. use, modify, copy, reproduce, create derivative works of, or distribute the Software Products\n(or any derivative works thereof, works incorporating the Software Products, or any data produced\nby the Software), in whole or in part, for (i) any commercial or production purposes,\n(ii) military purposes or in the service of nuclear technology, (iii) purposes of surveillance,\nincluding any research or development relating to surveillance, (iv) biometric processing,\n(v) in any manner that infringes, misappropriates, or otherwise violates any third-party rights,\nor (vi) in any manner that violates any applicable law and violating any privacy or security laws,\nrules, regulations, directives, or governmental requirements (including the General Data Privacy\nRegulation (Regulation (EU) 2016/679), the California Consumer Privacy Act, and any and all laws\ngoverning the processing of biometric information), as well as all amendments and successor laws\nto any of the foregoing;\n\nb. alter or remove copyright and other proprietary notices which appear on or in the Software Products;\n\nc. utilize any equipment, device, software, or other means to circumvent or remove any security or\nprotection used by Stability AI in connection with the Software, or to circumvent or remove any\nusage restrictions, or to enable functionality disabled by Stability AI; or\n\nd. offer or impose any terms on the Software Products that alter, restrict, or are inconsistent\nwith the terms of this License.\n\ne. 1) violate any applicable U.S. and non-U.S. export control and trade sanctions laws\n(“Export Laws”); 2) directly or indirectly export, re-export, provide, or otherwise\ntransfer Software Products: (a) to any individual, entity, or country prohibited by Export Laws; (b)\nto anyone on U.S. or non-U.S. government restricted parties lists; or (c) for any purpose prohibited\nby Export Laws, including nuclear, chemical or biological weapons, or missile technology applications;\n3) use or download Software Products if you or they are: (a) located in a comprehensively sanctioned\njurisdiction, (b) currently listed on any U.S. or non-U.S. restricted parties list, or (c) for any\npurpose prohibited by Export Laws; and (4) will not disguise your location through IP proxying or other methods.\n\n\n3. ATTRIBUTION\n\nTogether with any copies of the Software Products (as well as derivative works thereof or works\nincorporating the Software Products) that you distribute, you must provide (i) a copy of this License,\nand (ii) the following attribution notice: “DeepFloyd is licensed under the DeepFloyd License,\nCopyright (c) Stability AI Ltd. All Rights Reserved.”\n\n\n4. DISCLAIMERS\n\nTHE SOFTWARE PRODUCTS ARE PROVIDED “AS IS” and “WITH ALL FAULTS” WITH NO WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED. STABILITY AIEXPRESSLY DISCLAIMS ALL REPRESENTATIONS AND WARRANTIES, EXPRESS OR IMPLIED,\nWHETHER BY STATUTE, CUSTOM, USAGE OR OTHERWISE AS TO ANY MATTERS RELATED TO THE SOFTWARE PRODUCTS,\nINCLUDING BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE,\nTITLE, SATISFACTORY QUALITY, OR NON-INFRINGEMENT. STABILITY AI MAKES NO WARRANTIES OR REPRESENTATIONS\nTHAT THE SOFTWARE PRODUCTS WILL BE ERROR FREE OR FREE OF VIRUSES OR OTHER HARMFUL COMPONENTS,\nOR PRODUCE ANY PARTICULAR RESULTS.\n\n\n5. LIMITATION OF LIABILITY\n\nTO THE FULLEST EXTENT PERMITTED BY LAW, IN NO EVENT WILL STABILITY AI BE LIABLE TO YOU (A) UNDER\nANY THEORY OF LIABILITY, WHETHER BASED IN CONTRACT, TORT, NEGLIGENCE, STRICT LIABILITY, WARRANTY,\nOR OTHERWISE UNDER THIS LICENSE, OR (B) FOR ANY INDIRECT, CONSEQUENTIAL, EXEMPLARY, INCIDENTAL,\nPUNITIVE OR SPECIAL DAMAGES OR LOST PROFITS, EVEN IF STABILITY AI HAS BEEN ADVISED OF THE POSSIBILITY\nOF SUCH DAMAGES. THE SOFTWARE PRODUCTS, THEIR CONSTITUENT COMPONENTS, AND ANY OUTPUT\n(COLLECTIVELY, “SOFTWARE MATERIALS”) ARE NOT DESIGNED OR INTENDED FOR USE IN ANY APPLICATION OR\nSITUATION WHERE FAILURE OR FAULT OF THE SOFTWARE MATERIALS COULD REASONABLY BE ANTICIPATED TO LEAD\nTO SERIOUS INJURY OF ANY PERSON, INCLUDING POTENTIAL DISCRIMINATION OR VIOLATION OF AN INDIVIDUAL’S\nPRIVACY RIGHTS, OR TO SEVERE PHYSICAL, PROPERTY, OR ENVIRONMENTAL DAMAGE (EACH, A “HIGH-RISK USE”).\nIF YOU ELECT TO USE ANY OF THE SOFTWARE MATERIALS FOR A HIGH-RISK USE, YOU DO SO AT YOUR OWN RISK.\nYOU AGREE TO DESIGN AND IMPLEMENT APPROPRIATE DECISION-MAKING AND RISK-MITIGATION PROCEDURES AND\nPOLICIES IN CONNECTION WITH A HIGH-RISK USE SUCH THAT EVEN IF THERE IS A FAILURE OR FAULT IN ANY\nOF THE SOFTWARE MATERIALS, THE SAFETY OF PERSONS OR PROPERTY AFFECTED BY THE ACTIVITY STAYS AT A LEVEL\nTHAT IS REASONABLE, APPROPRIATE, AND LAWFUL FOR THE FIELD OF THE HIGH-RISK USE.\n\n\n6. INDEMNIFICATION\n\nYou will indemnify, defend and hold harmless Stability AI and our subsidiaries and affiliates,\nand each of our respective shareholders, directors, officers, employees, agents, successors,\nand assigns (collectively, the “Stability AI Parties”) from and against any losses, liabilities,\ndamages, fines, penalties, and expenses (including reasonable attorneys’ fees) incurred by any\nStability AI Party in connection with any claim, demand, allegation, lawsuit, proceeding, or\ninvestigation (collectively, “Claims”) arising out of or related to: (a) your access to or\nuse of the Software Products (as well as any results or data generated from such access or use),\nincluding any High-Risk Use (defined below); (b) your violation of this License; or (c)\nyour violation, misappropriation or infringement of any rights of another (including intellectual\nproperty or other proprietary rights and privacy rights). You will promptly notify the Stability AI\nParties of any such Claims, and cooperate with Stability AI Parties in defending such Claims.\nYou will also grant the Stability AI Parties sole control of the defense or settlement,\nat Stability AI’s sole option, of any Claims. This indemnity is in addition to, and not in lieu of,\nany other indemnities or remedies set forth in a written agreement between you and\nStability AI or the other Stability AI Parties.\n\n\n7. TERMINATION; SURVIVAL\n\na. This License will automatically terminate upon any breach by you of the terms of this License.\n\nb. We may terminate this License, in whole or in part, at any time upon notice (including electronic) to you.\n\nc. The following sections survive termination of this License: 2 (Restrictions), 3 (Attribution),\n4 (Disclaimers), 5 (Limitation on Liability), 6 (Indemnification) 7 (Termination; Survival),\n8 (Third Party Materials), 9 (Trademarks), 10 (Applicable Law; Dispute Resolution), and 11 (Miscellaneous).\n\n\n8. THIRD PARTY MATERIALS\n\nThe Software Products may contain third-party software or other components (including free and\nopen source software) (all of the foregoing, “Third Party Materials”), which are subject to\nthe license terms of the respective third-party licensors. Your dealings or correspondence\nwith third parties and your use of or interaction with any Third Party Materials are solely\nbetween you and the third party. Stability AI does not control or endorse, and makes\nno representations or warranties regarding, any Third Party Materials, and your access\nto and use of such Third Party Materials are at your own risk.\n\n\n9. TRADEMARKS\n\nLicensee has not been granted any trademark license as part of this License and may not use any name\nor mark associated with Stability AI without the prior written permission of Stability AI, except to\nthe extent necessary to make the reference required by the “ATTRIBUTION” section of this Agreement.\n\n\n10. APPLICABLE LAW; DISPUTE RESOLUTION\n\nThis License will be governed and construed under the laws of the State of California without regard\nto conflicts of law provisions. Any suit or proceeding arising out of or relating to this License\nwill be brought in the federal or state courts, as applicable, in San Mateo County, California,\nand each party irrevocably submits to the jurisdiction and venue of such courts.\n\n\n11. MISCELLANEOUS\n\nIf any provision or part of a provision of this License is unlawful, void or unenforceable,\nthat provision or part of the provision is deemed severed from this License, and will not affect\nthe validity and enforceability of any remaining provisions. The failure of Stability AI to exercise\nor enforce any right or provision of this License will not operate as a waiver of such right or provision.\nThis License does not confer any third-party beneficiary rights upon any other person or entity.\nThis License, together with the Documentation, contains the entire understanding between you and\nStability AI regarding the subject matter of this License, and supersedes all other written or\noral agreements and understandings between you and Stability AI regarding such subject matter.\nNo change or addition to any provision of this License will be binding unless it is in writing and\nsigned by an authorized representative of both you and Stability AI.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 15.2841796875,
          "content": "[![License](https://img.shields.io/badge/Code_License-Modified_MIT-blue.svg)](LICENSE)\n[![License](https://img.shields.io/badge/Weights_License-DeepFloyd_IF-orange.svg)](LICENSE-MODEL)\n[![Downloads](https://pepy.tech/badge/deepfloyd_if)](https://pepy.tech/project/deepfloyd_if)\n[![Discord](https://img.shields.io/badge/Discord-%237289DA.svg?logo=discord&logoColor=white)](https://discord.gg/umz62Mgr)\n[![Twitter](https://img.shields.io/badge/Twitter-%231DA1F2.svg?logo=twitter&logoColor=white)](https://twitter.com/deepfloydai)\n[![Linktree](https://img.shields.io/badge/Linktree-%2339E09B.svg?logo=linktree&logoColor=white)](http://linktr.ee/deepfloyd)\n\n# IF by [DeepFloyd Lab](https://deepfloyd.ai) at [StabilityAI](https://stability.ai/)\n\n<p align=\"center\">\n  <img src=\"./pics/nabla.jpg\" width=\"100%\">\n</p>\n\nWe introduce DeepFloyd IF, a novel state-of-the-art open-source text-to-image model with a high degree of photorealism and language understanding. DeepFloyd IF is a modular composed of a frozen text encoder and three cascaded pixel diffusion modules: a base model that generates 64x64 px image based on text prompt and two super-resolution models, each designed to generate images of increasing resolution: 256x256 px and 1024x1024 px. All stages of the model utilize a frozen text encoder based on the T5 transformer to extract text embeddings, which are then fed into a UNet architecture enhanced with cross-attention and attention pooling. The result is a highly efficient model that outperforms current state-of-the-art models, achieving a zero-shot FID score of 6.66 on the COCO dataset. Our work underscores the potential of larger UNet architectures in the first stage of cascaded diffusion models and depicts a promising future for text-to-image synthesis.\n\n<p align=\"center\">\n  <img src=\"./pics/deepfloyd_if_scheme.jpg\" width=\"100%\">\n</p>\n\n*Inspired by* [*Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding*](https://arxiv.org/pdf/2205.11487.pdf)\n\n## Minimum requirements to use all IF models:\n- 16GB vRAM for IF-I-XL (4.3B text to 64x64 base module) & IF-II-L (1.2B to 256x256 upscaler module)\n- 24GB vRAM for IF-I-XL (4.3B text to 64x64 base module) & IF-II-L (1.2B to 256x256 upscaler module) & Stable x4 (to 1024x1024 upscaler)\n- `xformers` and set env variable `FORCE_MEM_EFFICIENT_ATTN=1`\n\n\n## Quick Start\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/deepfloyd_if_free_tier_google_colab.ipynb)\n[![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/DeepFloyd/IF)\n\n```shell\npip install deepfloyd_if==1.0.2rc0\npip install xformers==0.0.16\npip install git+https://github.com/openai/CLIP.git --no-deps\n```\n\n## Local notebooks\n[![Jupyter Notebook](https://img.shields.io/badge/jupyter_notebook-%23FF7A01.svg?logo=jupyter&logoColor=white)](https://huggingface.co/DeepFloyd/IF-notebooks/blob/main/pipes-DeepFloyd-IF-v1.0.ipynb)\n[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://www.kaggle.com/code/shonenkov/deepfloyd-if-4-3b-generator-of-pictures)\n\nThe Dream, Style Transfer, Super Resolution or Inpainting modes are avaliable in a Jupyter Notebook [here](https://huggingface.co/DeepFloyd/IF-notebooks/blob/main/pipes-DeepFloyd-IF-v1.0.ipynb).\n\n\n\n## Integration with 🤗 Diffusers\n\nIF is also integrated with the 🤗 Hugging Face [Diffusers library](https://github.com/huggingface/diffusers/).\n\nDiffusers runs each stage individually allowing the user to customize the image generation process as well as allowing to inspect intermediate results easily.\n\n### Example\n\nBefore you can use IF, you need to accept its usage conditions. To do so:\n1. Make sure to have a [Hugging Face account](https://huggingface.co/join) and be loggin in\n2. Accept the license on the model card of [DeepFloyd/IF-I-XL-v1.0](https://huggingface.co/DeepFloyd/IF-I-XL-v1.0)\n3. Make sure to login locally. Install `huggingface_hub`\n```sh\npip install huggingface_hub --upgrade\n```\n\nrun the login function in a Python shell\n\n```py\nfrom huggingface_hub import login\n\nlogin()\n```\n\nand enter your [Hugging Face Hub access token](https://huggingface.co/docs/hub/security-tokens#what-are-user-access-tokens).\n\nNext we install `diffusers` and dependencies:\n\n```sh\npip install diffusers accelerate transformers safetensors\n```\n\nAnd we can now run the model locally.\n\nBy default `diffusers` makes use of [model cpu offloading](https://huggingface.co/docs/diffusers/optimization/fp16#model-offloading-for-fast-inference-and-memory-savings) to run the whole IF pipeline with as little as 14 GB of VRAM.\n\nIf you are using `torch>=2.0.0`, make sure to **delete all** `enable_xformers_memory_efficient_attention()`\nfunctions.\n\n```py\nfrom diffusers import DiffusionPipeline\nfrom diffusers.utils import pt_to_pil\nimport torch\n\n# stage 1\nstage_1 = DiffusionPipeline.from_pretrained(\"DeepFloyd/IF-I-XL-v1.0\", variant=\"fp16\", torch_dtype=torch.float16)\nstage_1.enable_xformers_memory_efficient_attention()  # remove line if torch.__version__ >= 2.0.0\nstage_1.enable_model_cpu_offload()\n\n# stage 2\nstage_2 = DiffusionPipeline.from_pretrained(\n    \"DeepFloyd/IF-II-L-v1.0\", text_encoder=None, variant=\"fp16\", torch_dtype=torch.float16\n)\nstage_2.enable_xformers_memory_efficient_attention()  # remove line if torch.__version__ >= 2.0.0\nstage_2.enable_model_cpu_offload()\n\n# stage 3\nsafety_modules = {\"feature_extractor\": stage_1.feature_extractor, \"safety_checker\": stage_1.safety_checker, \"watermarker\": stage_1.watermarker}\nstage_3 = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-x4-upscaler\", **safety_modules, torch_dtype=torch.float16)\nstage_3.enable_xformers_memory_efficient_attention()  # remove line if torch.__version__ >= 2.0.0\nstage_3.enable_model_cpu_offload()\n\nprompt = 'a photo of a kangaroo wearing an orange hoodie and blue sunglasses standing in front of the eiffel tower holding a sign that says \"very deep learning\"'\n\n# text embeds\nprompt_embeds, negative_embeds = stage_1.encode_prompt(prompt)\n\ngenerator = torch.manual_seed(0)\n\n# stage 1\nimage = stage_1(prompt_embeds=prompt_embeds, negative_prompt_embeds=negative_embeds, generator=generator, output_type=\"pt\").images\npt_to_pil(image)[0].save(\"./if_stage_I.png\")\n\n# stage 2\nimage = stage_2(\n    image=image, prompt_embeds=prompt_embeds, negative_prompt_embeds=negative_embeds, generator=generator, output_type=\"pt\"\n).images\npt_to_pil(image)[0].save(\"./if_stage_II.png\")\n\n# stage 3\nimage = stage_3(prompt=prompt, image=image, generator=generator, noise_level=100).images\nimage[0].save(\"./if_stage_III.png\")\n```\n\n There are multiple ways to speed up the inference time and lower the memory consumption even more with `diffusers`. To do so, please have a look at the Diffusers docs:\n\n- 🚀 [Optimizing for inference time](https://huggingface.co/docs/diffusers/api/pipelines/if#optimizing-for-speed)\n- ⚙️ [Optimizing for low memory during inference](https://huggingface.co/docs/diffusers/api/pipelines/if#optimizing-for-memory)\n\nFor more in-detail information about how to use IF, please have a look at [the IF blog post](https://huggingface.co/blog/if) and [the documentation](https://huggingface.co/docs/diffusers/main/en/api/pipelines/if) 📖.\n\nDiffusers dreambooth scripts also supports fine-tuning 🎨 [IF](https://huggingface.co/docs/diffusers/main/en/training/dreambooth#if).\nWith parameter efficient finetuning, you can add new concepts to IF with a single GPU and ~28 GB VRAM.\n\n## Run the code locally\n\n### Loading the models into VRAM\n\n```python\nfrom deepfloyd_if.modules import IFStageI, IFStageII, StableStageIII\nfrom deepfloyd_if.modules.t5 import T5Embedder\n\ndevice = 'cuda:0'\nif_I = IFStageI('IF-I-XL-v1.0', device=device)\nif_II = IFStageII('IF-II-L-v1.0', device=device)\nif_III = StableStageIII('stable-diffusion-x4-upscaler', device=device)\nt5 = T5Embedder(device=\"cpu\")\n```\n\n### I. Dream\nDream is the text-to-image mode of the IF model\n\n```python\nfrom deepfloyd_if.pipelines import dream\n\nprompt = 'ultra close-up color photo portrait of rainbow owl with deer horns in the woods'\ncount = 4\n\nresult = dream(\n    t5=t5, if_I=if_I, if_II=if_II, if_III=if_III,\n    prompt=[prompt]*count,\n    seed=42,\n    if_I_kwargs={\n        \"guidance_scale\": 7.0,\n        \"sample_timestep_respacing\": \"smart100\",\n    },\n    if_II_kwargs={\n        \"guidance_scale\": 4.0,\n        \"sample_timestep_respacing\": \"smart50\",\n    },\n    if_III_kwargs={\n        \"guidance_scale\": 9.0,\n        \"noise_level\": 20,\n        \"sample_timestep_respacing\": \"75\",\n    },\n)\n\nif_III.show(result['III'], size=14)\n```\n![](./pics/dream-III.jpg)\n\n## II. Zero-shot Image-to-Image Translation\n\n![](./pics/img_to_img_scheme.jpeg)\n\nIn Style Transfer mode, the output of your prompt comes out at the style of the `support_pil_img`\n```python\nfrom deepfloyd_if.pipelines import style_transfer\n\nresult = style_transfer(\n    t5=t5, if_I=if_I, if_II=if_II,\n    support_pil_img=raw_pil_image,\n    style_prompt=[\n        'in style of professional origami',\n        'in style of oil art, Tate modern',\n        'in style of plastic building bricks',\n        'in style of classic anime from 1990',\n    ],\n    seed=42,\n    if_I_kwargs={\n        \"guidance_scale\": 10.0,\n        \"sample_timestep_respacing\": \"10,10,10,10,10,10,10,10,0,0\",\n        'support_noise_less_qsample_steps': 5,\n    },\n    if_II_kwargs={\n        \"guidance_scale\": 4.0,\n        \"sample_timestep_respacing\": 'smart50',\n        \"support_noise_less_qsample_steps\": 5,\n    },\n)\nif_I.show(result['II'], 1, 20)\n```\n\n![Alternative Text](./pics/deep_floyd_if_image_2_image.gif)\n\n\n## III. Super Resolution\nFor super-resolution, users can run `IF-II` and `IF-III` or 'Stable x4' on an image that was not necessarely generated by IF (two cascades):\n\n```python\nfrom deepfloyd_if.pipelines import super_resolution\n\nmiddle_res = super_resolution(\n    t5,\n    if_III=if_II,\n    prompt=['woman with a blue headscarf and a blue sweaterp, detailed picture, 4k dslr, best quality'],\n    support_pil_img=raw_pil_image,\n    img_scale=4.,\n    img_size=64,\n    if_III_kwargs={\n        'sample_timestep_respacing': 'smart100',\n        'aug_level': 0.5,\n        'guidance_scale': 6.0,\n    },\n)\nhigh_res = super_resolution(\n    t5,\n    if_III=if_III,\n    prompt=[''],\n    support_pil_img=middle_res['III'][0],\n    img_scale=4.,\n    img_size=256,\n    if_III_kwargs={\n        \"guidance_scale\": 9.0,\n        \"noise_level\": 20,\n        \"sample_timestep_respacing\": \"75\",\n    },\n)\nshow_superres(raw_pil_image, high_res['III'][0])\n```\n\n![](./pics/if_as_upscaler.jpg)\n\n\n### IV. Zero-shot Inpainting\n\n```python\nfrom deepfloyd_if.pipelines import inpainting\n\nresult = inpainting(\n    t5=t5, if_I=if_I,\n    if_II=if_II,\n    if_III=if_III,\n    support_pil_img=raw_pil_image,\n    inpainting_mask=inpainting_mask,\n    prompt=[\n        'oil art, a man in a hat',\n    ],\n    seed=42,\n    if_I_kwargs={\n        \"guidance_scale\": 7.0,\n        \"sample_timestep_respacing\": \"10,10,10,10,10,0,0,0,0,0\",\n        'support_noise_less_qsample_steps': 0,\n    },\n    if_II_kwargs={\n        \"guidance_scale\": 4.0,\n        'aug_level': 0.0,\n        \"sample_timestep_respacing\": '100',\n    },\n    if_III_kwargs={\n        \"guidance_scale\": 9.0,\n        \"noise_level\": 20,\n        \"sample_timestep_respacing\": \"75\",\n    },\n)\nif_I.show(result['I'], 2, 3)\nif_I.show(result['II'], 2, 6)\nif_I.show(result['III'], 2, 14)\n```\n![](./pics/deep_floyd_if_inpainting.gif)\n\n### 🤗 Model Zoo 🤗\nThe link to download the weights as well as the model cards will be available soon on each model of the model zoo\n\n#### Original\n\n| Name                                                      | Cascade | Params | FID  | Batch size | Steps |\n|:----------------------------------------------------------|:-------:|:------:|:----:|:----------:|:-----:|\n| [IF-I-M](https://huggingface.co/DeepFloyd/IF-I-M-v1.0)    |    I    |  400M  | 8.86 |    3072    | 2.5M  |\n| [IF-I-L](https://huggingface.co/DeepFloyd/IF-I-L-v1.0)    |    I    |  900M  | 8.06 |    3200    | 3.0M  |\n| [IF-I-XL](https://huggingface.co/DeepFloyd/IF-I-XL-v1.0)* |    I    |  4.3B  | 6.66 |    3072    | 2.42M |\n| [IF-II-M](https://huggingface.co/DeepFloyd/IF-II-M-v1.0)  |   II    |  450M  |  -   |    1536    | 2.5M  |\n| [IF-II-L](https://huggingface.co/DeepFloyd/IF-II-L-v1.0)* |   II    |  1.2B  |  -   |    1536    | 2.5M  |\n| IF-III-L* _(soon)_                                        |   III   |  700M  |  -   |    3072    | 1.25M |\n\n *best modules\n\n### Quantitative Evaluation\n\n`FID = 6.66`\n\n![](./pics/fid30k_if.jpg)\n\n## License\n\nThe code in this repository is released under the bespoke license (see added [point two](https://github.com/deep-floyd/IF/blob/main/LICENSE#L13)).\n\nThe weights will be available soon via [the DeepFloyd organization at Hugging Face](https://huggingface.co/DeepFloyd) and have their own LICENSE.\n\n**Disclaimer:** *The initial release of the IF model is under a restricted research-purposes-only license temporarily to gather feedback, and after that we intend to release a fully open-source model in line with other Stability AI models.*\n\n## Limitations and Biases\n\nThe models available in this codebase have known limitations and biases. Please refer to [the model card](https://huggingface.co/DeepFloyd/IF-I-L-v1.0) for more information.\n\n\n## 🎓 DeepFloyd IF creators:\n\n- Alex Shonenkov [GitHub](https://github.com/shonenkov) | [Linktr](https://linktr.ee/shonenkovAI)\n- Misha Konstantinov [GitHub](https://github.com/zeroshot-ai) | [Twitter](https://twitter.com/_bra_ket)\n- Daria Bakshandaeva [GitHub](https://github.com/Gugutse) | [Twitter](https://twitter.com/_gugutse_)\n- Christoph Schuhmann [GitHub](https://github.com/christophschuhmann) | [Twitter](https://twitter.com/laion_ai)\n- Ksenia Ivanova [GitHub](https://github.com/ivksu) | [Twitter](https://twitter.com/susiaiv)\n- Nadiia Klokova [GitHub](https://github.com/vauimpuls) | [Twitter](https://twitter.com/vauimpuls)\n\n\n## 📄 Research Paper (Soon)\n\n## Acknowledgements\n\nSpecial thanks to [StabilityAI](http://stability.ai) and its CEO [Emad Mostaque](https://twitter.com/emostaque) for invaluable support, providing GPU compute and infrastructure to train the models (our gratitude goes to [Richard Vencu](https://github.com/rvencu)); thanks to [LAION](https://laion.ai) and [Christoph Schuhmann](https://github.com/christophschuhmann) in particular for contribution to the project and well-prepared datasets; thanks to [Huggingface](https://huggingface.co) teams for optimizing models' speed and memory consumption during inference, creating demos and giving cool advice!\n\n## 🚀 External Contributors 🚀\n- The Biggest Thanks [@Apolinário](https://github.com/apolinario), for ideas, consultations, help and support on all stages to make IF available in open-source; for writing a lot of documentation and instructions; for creating a friendly atmosphere in difficult moments 🦉;\n- Thanks, [@patrickvonplaten](https://github.com/patrickvonplaten), for improving loading time of unet models by 80%;\nfor integration Stable-Diffusion-x4 as native pipeline 💪;\n- Thanks, [@williamberman](https://github.com/williamberman) and [@patrickvonplaten](https://github.com/patrickvonplaten) for diffusers integration 🙌;\n- Thanks, [@hysts](https://github.com/hysts) and [@Apolinário](https://github.com/apolinario) for creating [the best gradio demo with IF](https://huggingface.co/spaces/DeepFloyd/IF) 🚀;\n- Thanks, [@Dango233](https://github.com/Dango233), for adapting IF with xformers memory efficient attention 💪;\n"
        },
        {
          "name": "deepfloyd_if",
          "type": "tree",
          "content": null
        },
        {
          "name": "pics",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements-dev.txt",
          "type": "blob",
          "size": 0.03515625,
          "content": "-r requirements-test.txt\npre-commit\n"
        },
        {
          "name": "requirements-test.txt",
          "type": "blob",
          "size": 0.037109375,
          "content": "-r requirements.txt\npytest\npytest-cov\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.22265625,
          "content": "tqdm\nnumpy\ntorch<2.0.0\ntorchvision\nomegaconf\nmatplotlib\nPillow>=9.2.0\nhuggingface_hub>=0.13.2\ntransformers~=4.25.1\naccelerate~=0.15.0\ndiffusers~=0.16.0\ntokenizers~=0.13.2\nsentencepiece~=0.1.97\nftfy~=6.1.1\nbeautifulsoup4~=4.11.1\n"
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.236328125,
          "content": "[pep8]\nmax-line-length = 120\nexclude = .tox,*migrations*,.json\n\n[flake8]\nmax-line-length = 120\nexclude = .tox,*migrations*,.json\n\n[autopep8-wrapper]\nexclude = .tox,*migrations*,.json\n\n[check-docstring-first]\nexclude = .tox,*migrations*,.json\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 1.970703125,
          "content": "# -*- coding: utf-8 -*-\nimport os\nimport re\nfrom setuptools import setup\n\n\ndef read(filename):\n    with open(os.path.join(os.path.dirname(__file__), filename)) as f:\n        file_content = f.read()\n    return file_content\n\n\ndef get_requirements():\n    requirements = []\n    for requirement in read('requirements.txt').splitlines():\n        if requirement.startswith('git+') or requirement.startswith('svn+') or requirement.startswith('hg+'):\n            parsed_requires = re.findall(r'#egg=([\\w\\d\\.]+)-([\\d\\.]+)$', requirement)\n            if parsed_requires:\n                package, version = parsed_requires[0]\n                requirements.append(f'{package}=={version}')\n            else:\n                print('WARNING! For correct matching dependency links need to specify package name and version'\n                      'such as <dependency url>#egg=<package_name>-<version>')\n        else:\n            requirements.append(requirement)\n    return requirements\n\n\ndef get_links():\n    return [\n        requirement for requirement in read('requirements.txt').splitlines()\n        if requirement.startswith('git+') or requirement.startswith('svn+') or requirement.startswith('hg+')\n    ]\n\n\ndef get_version():\n    \"\"\" Get version from the package without actually importing it. \"\"\"\n    init = read('deepfloyd_if/__init__.py')\n    for line in init.split('\\n'):\n        if line.startswith('__version__'):\n            return eval(line.split('=')[1])\n\n\nsetup(\n    name='deepfloyd_if',\n    version=get_version(),\n    author='DeepFloyd, StabilityAI',\n    author_email='shonenkov@gmail.com',\n    description='DeepFloyd-IF (Imagen Free)',\n    packages=['deepfloyd_if', 'deepfloyd_if/model', 'deepfloyd_if/modules', 'deepfloyd_if/pipelines',\n              'deepfloyd_if/resources'],\n    package_data={'deepfloyd_if/resources': ['*.png', '*.npy', '*.npz']},\n    install_requires=get_requirements(),\n    dependency_links=get_links(),\n    long_description=read('README.md'),\n    long_description_content_type='text/markdown',\n)\n"
        }
      ]
    }
  ]
}