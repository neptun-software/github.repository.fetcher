{
  "metadata": {
    "timestamp": 1736560703469,
    "page": 364,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjM3MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "kyutai-labs/moshi",
      "stars": 7126,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 3.2353515625,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\ncover/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\n.pybuilder/\ntarget/\ntarget-trunk/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n#   For a library or package, you might want to ignore these files since the code is\n#   intended to run in multiple environments; otherwise, check them in:\n# .python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# poetry\n#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.\n#   This is especially recommended for binary packages to ensure reproducibility, and is more\n#   commonly ignored for libraries.\n#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control\n#poetry.lock\n\n# pdm\n#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.\n#pdm.lock\n#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it\n#   in version control.\n#   https://pdm.fming.dev/#use-with-ide\n.pdm.toml\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# pytype static type analyzer\n.pytype/\n\n# Cython debug symbols\ncython_debug/\n\n# PyCharm\n#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can\n#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore\n#  and can be added to the global gitignore or merged into this file.  For a more nuclear\n#  option (not recommended) you can uncomment the following to ignore the entire idea folder.\n#.idea/\n\n# VsCode\n.vscode/\n\nCargo.lock\n*~\n*.safetensors\n*.wav\ntrace*.json\n*.flac\npkg\n*.nsys-rep\n*.sqlite\n*.pem\n*.tgz\n*.mp3\n*.ogg\n/moshi-demo/config.sh\nlog.*\nlaurent/cuda-test/check\nclient/node_modules\ntimings.json\nmlx-trace.json\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.8115234375,
          "content": "repos:\n  - repo: local\n    hooks:\n    - id: flake8-moshi\n      name: flake8 on moshi package\n      language: system\n      entry: bash -c 'cd moshi && flake8'\n      pass_filenames: false\n      always_run: true\n    - id: pyright-moshi\n      name: pyright on moshi package\n      language: system\n      entry: scripts/run_ci_when_installed.sh moshi 'cd moshi && pyright'\n      pass_filenames: false\n      always_run: true\n    - id: flake8-moshi_mlx\n      name: flake8 on moshi_mlx package\n      language: system\n      entry: bash -c 'cd moshi_mlx && flake8'\n      pass_filenames: false\n      always_run: true\n    - id: pyright-moshi_mlx\n      name: pyright on moshi_mlx package\n      language: system\n      entry: scripts/run_ci_when_installed.sh moshi_mlx 'cd moshi_mlx && pyright'\n      pass_filenames: false\n      always_run: true\n\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 3.0966796875,
          "content": "# Contributing to Moshi\n\n## Pull Requests\n\nMoshi is the implementation of a research paper.\nTherefore, we do not plan on accepting many pull requests for new features.\nHowever, we certainly welcome them for bug fixes.\n\n1. Fork the repo and create your branch from `main`.\n2. If you have changed APIs, update the documentation accordingly.\n3. Ensure pre-commit hooks pass properly, in particular the linting and typing.\n4. When changing the Rust code, run `cargo check`, `cargo clippy`, `cargo test`.\n5. Accept the Contributor License Agreement (see after).\n\nNote that in general, we will not accept refactoring of the code.\n\n\n## Contributor License Agreement (\"CLA\")\n\nIn order to accept your pull request, we need you to submit a Contributor License Agreement.\n\nIf you agree with the full CLA provided in the next paragraph, copy the following statement in your PR, changing your Github Handle:\n\n> I, {your GitHub handle}, confirm that I have read and understood the terms of the CLA of Kyutai-labs, as outlined in the repository's CONTRIBUTING.md, and I agree to be bound by these terms.\n\nThe full CLA is provided as follows:\n\n> I, {your GitHub handle}, hereby grant to Kyutai-labs a perpetual, worldwide, non-exclusive, royalty-free,\n> irrevocable license to use, modify, distribute, and sublicense my Contributions.\n\n> I understand and accept that Contributions are limited to modifications, improvements, or changes\n> to the project’s source code submitted via pull requests. I accept that Kyutai-labs has full discretion to\n> review, accept, reject, or request changes to any Contributions I submit, and that submitting\n> a pull request does not guarantee its inclusion in the project.\n\n> By submitting a Contribution, I grant Kyutai-labs a perpetual, worldwide license to use, modify,\n> reproduce, distribute, and create derivative works based on my Contributions.\n> I also agree to assign all patent rights for any inventions or improvements that arise from my Contributions,\n> giving the Kyutai-labs full rights to file for and enforce patents.\n> I understand that the Kyutai-labs may commercialize, relicense, or exploit the project and my Contributions without further notice or obligation to me.\n> I confirm that my Contributions are original and that I have the legal right to grant this license.\n> If my Contributions include third-party materials, I will ensure that I have the necessary permissions\n> and will disclose this information. I accept that once my Contributions are integrated, they may be altered or removed at the Kyutai-labs’s discretion.\n\n> I acknowledge that I am making these Contributions voluntarily and will not receive any compensation.\n> Furthermore, I understand that all Contributions, including mine, are provided on an \"as-is\" basis, with no warranties.\n> By submitting a pull request, I agree to be bound by these terms.\n\n## Issues\n\nPlease submit issues on our Github repository.\n\n## License\n\nBy contributing to Moshi, you agree that your contributions will be licensed\nunder the LICENSE-* files in the root directory of this source tree.\nIn particular, the rust code is licensed under APACHE, and the python code under MIT.\n"
        },
        {
          "name": "FAQ.md",
          "type": "blob",
          "size": 2.5078125,
          "content": "# FAQ\n\nHere is the answer to a number of frequently asked questions.\n\n### Will you release training code?\n\nWe will release some training / fine-tuning code, but we do not have any timeline yet. Please be patient.\n\n### Will you release the dataset?\n\nWe will not release the pre-training dataset.\n\n### Is Moshi multilingual?\n\nAt the moment no. Moshi only speaks English. It has some basic support for translating some sentences\nor words to other languages, but you shouldn't expect to use it fully in any other language than English.\n\n### Can I change Moshi's voice / personality?\n\nThis would require fine tuning, which is not currently supported.\n\n### Can Moshi run on a M1, or smaller GPUs?\n\nSadly we do not think this is currently possible. Quantizing beyond 4 bits lead to dramatic\ndecrease in quality, see [PR #58](https://github.com/kyutai-labs/moshi/pull/58).\nWhile we keep those limitations in mind for future versions, there is no immediate solution.\n\n### Can we run quantized Moshi with PyTorch?\n\nAt the moment no, we might look into adding this feature when we get the time. At the moment\nit is however possible to use the Rust backend, which should run in int8 with CUDA.\n\n### Moshi stopped talking after 5 min.\n\nThis is expected on the MLX and Rust implementation.\nWe only use a fixed buffer, and we do not discard past entries.\nThe PyTorch version should work for unlimited times, although this is mostly untested and we\nexpect the quality to degrade after a bit (we have no attention sink or other mechanism to improve the streaming\nbeyond the finite context used at training).\n\n### The server seems to be running but nothing happens on connect.\n\nFor diagnosis, look at your browser console if there is any error being\nreported.\n\nIf you see issues that look like the following:\n```\nUncaught (in promise) TypeError: Cannot read properties of undefined (reading 'addModule')\n```\nthis is likely caused by the http server being remote and audio being disabled\nfor http in such a case.\n\nTo get around this, tunnel the 8998 port from the remote server to the localhost\nvia ssh and access [localhost:8998](http://localhost:8998) via http normally\nafter that.\n\n### How to get the key.pem and cert.pem files required for serving over https?\n```bash\nopenssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -days 365 -nodes -subj \"/CN=localhost\"\n```\n\n### Can I run on a 12GB / 8 GB GPU ?\nFor a 12GB GPU, this is possible following instructions in [issue #54](https://github.com/kyutai-labs/moshi/issues/54).\nFor 8GB GPU, this is not possible at the moment.\n"
        },
        {
          "name": "LICENSE-APACHE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "LICENSE-MIT",
          "type": "blob",
          "size": 0.9990234375,
          "content": "Permission is hereby granted, free of charge, to any\nperson obtaining a copy of this software and associated\ndocumentation files (the \"Software\"), to deal in the\nSoftware without restriction, including without\nlimitation the rights to use, copy, modify, merge,\npublish, distribute, sublicense, and/or sell copies of\nthe Software, and to permit persons to whom the Software\nis furnished to do so, subject to the following\nconditions:\n\nThe above copyright notice and this permission notice\nshall be included in all copies or substantial portions\nof the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\nANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\nTO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\nPARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT\nSHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\nCLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR\nIN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\nDEALINGS IN THE SOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 13.30859375,
          "content": "# Moshi: a speech-text foundation model for real time dialogue\n\n![precommit badge](https://github.com/kyutai-labs/moshi/workflows/precommit/badge.svg)\n![rust ci badge](https://github.com/kyutai-labs/moshi/workflows/Rust%20CI/badge.svg)\n\n[[Read the paper]][moshi] [[Demo]](https://moshi.chat) [[Hugging Face]](https://huggingface.co/collections/kyutai/moshi-v01-release-66eaeaf3302bef6bd9ad7acd)\n\n [Moshi][moshi] is a speech-text foundation model and **full-duplex** spoken dialogue framework.\n It uses [Mimi][moshi], a state-of-the-art streaming neural audio codec. Mimi processes 24 kHz audio, down to a 12.5 Hz representation\n with a bandwidth of 1.1 kbps, in a fully streaming manner (latency of 80ms, the frame size),\n yet performs better than existing, non-streaming, codecs like\n [SpeechTokenizer](https://github.com/ZhangXInFD/SpeechTokenizer) (50 Hz, 4kbps), or [SemantiCodec](https://github.com/haoheliu/SemantiCodec-inference) (50 Hz, 1.3kbps).\n\n Moshi models **two streams of audio**: one corresponds to Moshi, and the other one to the user.\n At inference, the stream from the user is taken from the audio input,\nand the one for Moshi is sampled from the model's output. Along these two audio streams, Moshi predicts text tokens corresponding to its own speech, its **inner monologue**,\nwhich greatly improves the quality of its generation. A small Depth Transformer models inter codebook dependencies for a given time step,\nwhile a large, 7B parameter Temporal Transformer models the temporal dependencies. Moshi achieves a theoretical latency\nof 160ms (80ms for the frame size of Mimi + 80ms of acoustic delay), with a practical overall latency as low as 200ms on an L4 GPU.\n\n[Talk to Moshi](https://moshi.chat) now on our live demo.\n\n\n<p align=\"center\">\n<img src=\"./moshi.png\" alt=\"Schema representing the structure of Moshi. Moshi models two streams of audio:\n    one corresponds to Moshi, and the other one to the user. At inference, the audio stream of the user is taken from the audio input, and the audio stream for Moshi is sampled from the model's output. Along that, Moshi predicts text tokens corresponding to its own speech for improved accuracy. A small Depth Transformer models inter codebook dependencies for a given step.\"\nwidth=\"650px\"></p>\n\nMimi builds on previous neural audio codecs such as [SoundStream](https://arxiv.org/abs/2107.03312)\nand [EnCodec](https://github.com/facebookresearch/encodec), adding a Transformer both in the encoder and decoder,\nand adapting the strides to match an overall frame rate of 12.5 Hz. This allows Mimi to get closer to the\naverage frame rate of text tokens (~3-4 Hz), and limit the number of autoregressive steps in Moshi.\nSimilarly to SpeechTokenizer, Mimi uses a distillation loss so that the first codebook tokens match\na self-supervised representation from [WavLM](https://arxiv.org/abs/2110.13900), which allows modeling semantic and acoustic information with a single model. Interestingly, while Mimi is fully causal and streaming, it learns to match sufficiently well the non-causal\nrepresentation from WavLM, without introducing any delays. Finally, and similarly to [EBEN](https://arxiv.org/pdf/2210.14090),\nMimi uses **only an adversarial training loss**, along with feature matching, showing strong improvements in terms of\nsubjective quality despite its low bitrate.\n\n<p align=\"center\">\n<img src=\"./mimi.png\" alt=\"Schema representing the structure of Mimi, our proposed neural codec. Mimi contains a Transformer\nin both its encoder and decoder, and achieves a frame rate closer to that of text tokens. This allows us to reduce\nthe number of auto-regressive steps taken by Moshi, thus reducing the latency of the model.\"\nwidth=\"800px\"></p>\n\n\n\n## Organisation of the repository\n\nThere are three separate versions of the moshi inference stack in this repo.\n- The Python version using PyTorch is in the [`moshi/`](moshi/) directory.\n- The Python version using MLX for M series Macs is in the [`moshi_mlx/`](moshi_mlx/) directory.\n- The Rust version used in production is in the [`rust/`](rust/) directory.\n    This contains in particular a Mimi implementation in Rust, with Python bindings available\n    as `rustymimi`.\n\nFinally, the code for the live demo is provided in the [`client/`](client/) directory.\n\n\n## Models\n\nWe release three models:\n- our speech codec Mimi,\n- Moshi fine-tuned on a male synthetic voice (Moshiko),\n- Moshi fine-tuned on a female synthetic voice (Moshika).\n\nDepending on the backend, the file format and quantization available will vary. Here is the list\nof the HuggingFace repo with each model. Mimi is bundled in each of those, and always use the same checkpoint format.\n\n- Moshika for PyTorch (bf16): [kyutai/moshika-pytorch-bf16](https://huggingface.co/kyutai/moshika-pytorch-bf16).\n- Moshiko for PyTorch (bf16): [kyutai/moshiko-pytorch-bf16](https://huggingface.co/kyutai/moshiko-pytorch-bf16).\n- Moshika for MLX (int4, int8, bf16): [kyutai/moshika-mlx-q4](https://huggingface.co/kyutai/moshika-mlx-q4), [kyutai/moshika-mlx-q8](https://huggingface.co/kyutai/moshika-mlx-q8),  [kyutai/moshika-mlx-bf16](https://huggingface.co/kyutai/moshika-mlx-bf16).\n- Moshiko for MLX (int4, int8, bf16): [kyutai/moshiko-mlx-q4](https://huggingface.co/kyutai/moshiko-mlx-q4), [kyutai/moshiko-mlx-q8](https://huggingface.co/kyutai/moshiko-mlx-q8),  [kyutai/moshiko-mlx-bf16](https://huggingface.co/kyutai/moshiko-mlx-bf16).\n- Moshika for Rust/Candle (int8, bf16): [kyutai/moshika-candle-q8](https://huggingface.co/kyutai/moshika-candle-q8),  [kyutai/moshika-mlx-bf16](https://huggingface.co/kyutai/moshika-candle-bf16).\n- Moshiko for Rust/Candle (int8, bf16): [kyutai/moshiko-candle-q8](https://huggingface.co/kyutai/moshiko-candle-q8),  [kyutai/moshiko-mlx-bf16](https://huggingface.co/kyutai/moshiko-candle-bf16).\n\nAll models are released under the CC-BY 4.0 license.\n\n## Requirements\n\nYou will need at least Python 3.10, with 3.12 recommended. For specific requirements, please check the individual backends\ndirectories. You can install the PyTorch and MLX clients with the following:\n\n```bash\npip install moshi      # moshi PyTorch, from PyPI\npip install moshi_mlx  # moshi MLX, from PyPI, best with Python 3.12.\n# Or the bleeding edge versions for Moshi and Moshi-MLX.\npip install -e \"git+https://git@github.com/kyutai-labs/moshi.git#egg=moshi&subdirectory=moshi\"\npip install -e \"git+https://git@github.com/kyutai-labs/moshi.git#egg=moshi_mlx&subdirectory=moshi_mlx\"\n\npip install rustymimi  # mimi, rust implementation with Python bindings from PyPI\n```\n\nIf you are not using Python 3.12, you might get an error when installing\n`moshi_mlx` or `rustymimi` (which `moshi_mlx` depends on). Then, you will need to install the [Rust toolchain](https://rustup.rs/), or switch to Python 3.12.\n\nWhile we hope that the present codebase will work on Windows, we do not provide official support for it.\nWe have tested the MLX version on a MacBook Pro M3. At the moment, we do not support quantization\nfor the PyTorch version, so you will need a GPU with a significant amount of memory (24GB).\n\nFor using the Rust backend, you will need a recent version of the [Rust toolchain](https://rustup.rs/).\nTo compile GPU support, you will also need the [CUDA](https://developer.nvidia.com/cuda-toolkit) properly installed for your GPU, in particular with `nvcc`.\n\n## Python (PyTorch)\n\nThe PyTorch based API can be found in the `moshi` directory. It provides a streaming\nversion of the audio tokenizer (mimi) and the language model (moshi).\n\nIn order to run in interactive mode, you need to start a server which will\nrun the model, you can then use either the web UI or a command line client.\n\nStart the server with:\n```bash\npython -m moshi.server [--gradio-tunnel] [--hf-repo kyutai/moshika-pytorch-bf16]\n```\n\nAnd then access the web UI on [localhost:8998](http://localhost:8998).\nIf your GPU is on a distant machine this will not work as websites using http\nare not allowed to use the audio worklet api. There are two ways to get around\nthis:\n- Forward the remote 8998 port to your localhost using ssh `-L` flag. Then\n  connects to [localhost:8998](http://localhost:8998) as mentionned previously.\n- Use the `--gradio-tunnel` argument, this sets up a tunnel with a URL accessible from anywhere.\n  Keep in mind that this tunnel goes through the US and can add significant\n  latency (up to 500ms from Europe). You can use `--gradio-tunnel-token` to set a\n  fixed secret token and reuse the same address over time.\n\nYou can use `--hf-repo` to select a different pretrained model, by setting the proper Hugging Face repository.\n\nAccessing a server that is not localhost via http may cause issues with using\nthe microphone in the web UI (in some browsers this is only allowed using\nhttps).\n\nA local client is also available, as\n```bash\npython -m moshi.client [--url URL_TO_GRADIO]\n```\nHowever note that, unlike the web browser, this client is barebone: it does not perform any echo cancellation,\nnor does it try to compensate for a growing lag by skipping frames.\n\nFor more information, in particular on how to use the API directly, please\ncheckout [moshi/README.md](moshi/README.md).\n\n## Python (MLX) for local inference on macOS\n\nOnce you have installed `moshi_mlx`, you can run\n```bash\npython -m moshi_mlx.local -q 4   # weights quantized to 4 bits\npython -m moshi_mlx.local -q 8   # weights quantized to 8 bits\n# And using a different pretrained model:\npython -m moshi_mlx.local -q 4 --hf-repo kyutai/moshika-mlx-q4\npython -m moshi_mlx.local -q 8 --hf-repo kyutai/moshika-mlx-q8\n# be careful to always match the `-q` and `--hf-repo` flag.\n```\n\nThis command line interface is also barebone. It does not perform any echo cancellation,\nnor does it try to compensate for a growing lag by skipping frames.\n\nAlternatively you can run `python -m moshi_mlx.local_web` to use\nthe web UI, the connection is via http and will be at [localhost:8998](http://localhost:8998).\n\n\n## Rust\n\nIn order to run the Rust inference server, use the following command from within\nthe `rust` directory:\n\n```bash\ncargo run --features cuda --bin moshi-backend -r -- --config moshi-backend/config.json standalone\n```\n\nWhen using macOS, you can replace `--features cuda` with `--features metal`.\n\nAlternatively you can use `config-q8.json` rather than `config.json` to use the\nquantized q8 model. You can select a different pretrained model, e.g. Moshika,\nby changing the `\"hf_repo\"` key in either file.\n\nOnce the server has printed 'standalone worker listening', you can use the web\nUI. By default the Rust server uses https so it will be at\n[localhost:8998](https://localhost:8998).\n\nYou will get warnings about the site being unsafe. When using chrome you\ncan bypass these by selecting \"Details\" or \"Advanced\", then \"Visit this unsafe\nsite\" or \"Proceed to localhost (unsafe)\".\n\n## Clients\n\nWe recommend using the web UI as it provides additional echo cancellation that helps\nthe overall model quality. Note that most commands will directly serve this UI\nin the provided URL, and there is in general nothing more to do.\n\nAlternatively, we provide command line interfaces\nfor the Rust and Python versions, the protocol is the same as with the web UI so\nthere is nothing to change on the server side.\n\nFor reference, here is the list of clients for Moshi.\n\n### Rust Command Line\n\nFrom within the `rust` directory, run the following:\n```bash\ncargo run --bin moshi-cli -r -- tui --host localhost\n```\n\n### Python with PyTorch\n\n```bash\npython -m moshi.client\n```\n\n### Gradio Demo\n\nYou can launch a Gradio demo locally with the following command:\n\n```bash\npython -m moshi.client_gradio --url <moshi-server-url>\n```\n\nPrior to running the Gradio demo, please install `gradio-webrtc>=0.0.18`.\n\n### Docker Compose (CUDA only)\n\n```bash\ndocker compose up\n```\n\n* Requires [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html)\n\n### WebUI\n\nThe web UI can be built from this repo via the\nfollowing steps (these will require `npm` being installed).\n```bash\ncd client\nnpm install\nnpm run build\n```\n\nThe web UI can then be found in the `client/dist` directory.\n\n## Development\n\nIf you wish to install from a clone of this repository, maybe to further develop Moshi, you can do the following:\n```bash\n# From the root of the clone of the repo\npip install -e 'moshi[dev]'\npip install -e 'moshi_mlx[dev]'\npre-commit install\n```\n\nIf you wish to build locally `rustymimi` (assuming you have Rust properly installed):\n```bash\npip install maturin\nmaturin dev -r -m rust/mimi-pyo3/Cargo.toml\n```\n\n## FAQ\n\nCheckout the [Frequently Asked Questions](FAQ.md) section before opening an issue.\n\n\n## License\n\nThe present code is provided under the MIT license for the Python parts, and Apache license for the Rust backend.\nThe web client code is provided under the MIT license.\nNote that parts of this code is based on [AudioCraft](https://github.com/facebookresearch/audiocraft), released under\nthe MIT license.\n\nThe weights for the models are released under the CC-BY 4.0 license.\n\n## Citation\n\nIf you use either Mimi or Moshi, please cite the following paper,\n\n```\n@techreport{kyutai2024moshi,\n      title={Moshi: a speech-text foundation model for real-time dialogue},\n      author={Alexandre D\\'efossez and Laurent Mazar\\'e and Manu Orsini and\n      Am\\'elie Royer and Patrick P\\'erez and Herv\\'e J\\'egou and Edouard Grave and Neil Zeghidour},\n      year={2024},\n      eprint={2410.00037},\n      archivePrefix={arXiv},\n      primaryClass={eess.AS},\n      url={https://arxiv.org/abs/2410.00037},\n}\n```\n\n[moshi]: https://arxiv.org/abs/2410.00037\n"
        },
        {
          "name": "client",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker-compose.yml",
          "type": "blob",
          "size": 0.7509765625,
          "content": "version: \"3.8\"\n\nname: moshi\n\nservices:\n\n  moshi:\n    build:\n      context: ./moshi\n    expose:\n     - 8998/tcp\n    restart: unless-stopped\n    volumes:\n      - hf-cache:/root/.cache/huggingface\n    environment:\n      #- HF_REPO=kyutai/moshika-pytorch-bf16\n      - HF_REPO=kyutai/moshiko-pytorch-bf16\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              capabilities: [gpu]\n              count: all\n\n  tunnel:\n    image: cloudflare/cloudflared:latest\n    pull_policy: always\n    restart: unless-stopped\n    expose:\n      - 43337/tcp\n    environment:\n      TUNNEL_URL: http://moshi:8998\n      TUNNEL_METRICS: 0.0.0.0:43337\n    command: tunnel --no-autoupdate\n    depends_on:\n      - moshi\n\nvolumes:\n  hf-cache:\n"
        },
        {
          "name": "mimi.png",
          "type": "blob",
          "size": 566.2646484375,
          "content": null
        },
        {
          "name": "moshi.png",
          "type": "blob",
          "size": 511.912109375,
          "content": null
        },
        {
          "name": "moshi",
          "type": "tree",
          "content": null
        },
        {
          "name": "moshi_mlx",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements-dev.txt",
          "type": "blob",
          "size": 0.0400390625,
          "content": "pre-commit>=3.8\npyright>=1.1\nflake8>=7.1\n"
        },
        {
          "name": "rust",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}