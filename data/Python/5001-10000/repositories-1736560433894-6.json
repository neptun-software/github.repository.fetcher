{
  "metadata": {
    "timestamp": 1736560433894,
    "page": 6,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjEw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "lyhue1991/eat_tensorflow2_in_30_days",
      "stars": 9963,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.099609375,
          "content": ".DS_store\n.ipynb_checkpoints\n.ipynb_checkpoints/* \ndata/keras_model/\ndata/demomodule/\ndata/autograph/\n"
        },
        {
          "name": "1-1,结构化数据建模流程范例.md",
          "type": "blob",
          "size": 13.2119140625,
          "content": "# 1-1,结构化数据建模流程范例\n\n\n### 一，准备数据\n\n\ntitanic数据集的目标是根据乘客信息预测他们在Titanic号撞击冰山沉没后能否生存。\n\n结构化数据一般会使用Pandas中的DataFrame进行预处理。\n\n\n```python\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport tensorflow as tf \nfrom tensorflow.keras import models,layers\n\ndftrain_raw = pd.read_csv('./data/titanic/train.csv')\ndftest_raw = pd.read_csv('./data/titanic/test.csv')\ndftrain_raw.head(10)\n```\n\n![](./data/1-1-数据集展示.jpg)\n\n\n字段说明：\n\n* Survived:0代表死亡，1代表存活【y标签】\n* Pclass:乘客所持票类，有三种值(1,2,3) 【转换成onehot编码】\n* Name:乘客姓名 【舍去】\n* Sex:乘客性别 【转换成bool特征】\n* Age:乘客年龄(有缺失) 【数值特征，添加“年龄是否缺失”作为辅助特征】\n* SibSp:乘客兄弟姐妹/配偶的个数(整数值) 【数值特征】\n* Parch:乘客父母/孩子的个数(整数值)【数值特征】\n* Ticket:票号(字符串)【舍去】\n* Fare:乘客所持票的价格(浮点数，0-500不等) 【数值特征】\n* Cabin:乘客所在船舱(有缺失) 【添加“所在船舱是否缺失”作为辅助特征】\n* Embarked:乘客登船港口:S、C、Q(有缺失)【转换成onehot编码，四维度 S,C,Q,nan】\n\n\n\n利用Pandas的数据可视化功能我们可以简单地进行探索性数据分析EDA（Exploratory Data Analysis）。\n\nlabel分布情况\n\n```python\n%matplotlib inline\n%config InlineBackend.figure_format = 'png'\nax = dftrain_raw['Survived'].value_counts().plot(kind = 'bar',\n     figsize = (12,8),fontsize=15,rot = 0)\nax.set_ylabel('Counts',fontsize = 15)\nax.set_xlabel('Survived',fontsize = 15)\nplt.show()\n```\n\n![](./data/1-1-Label分布.jpg)\n\n\n年龄分布情况\n\n```python\n%matplotlib inline\n%config InlineBackend.figure_format = 'png'\nax = dftrain_raw['Age'].plot(kind = 'hist',bins = 20,color= 'purple',\n                    figsize = (12,8),fontsize=15)\n\nax.set_ylabel('Frequency',fontsize = 15)\nax.set_xlabel('Age',fontsize = 15)\nplt.show()\n```\n\n![](./data/1-1-年龄分布.jpg)\n\n\n年龄和label的相关性\n\n```python\n%matplotlib inline\n%config InlineBackend.figure_format = 'png'\nax = dftrain_raw.query('Survived == 0')['Age'].plot(kind = 'density',\n                      figsize = (12,8),fontsize=15)\ndftrain_raw.query('Survived == 1')['Age'].plot(kind = 'density',\n                      figsize = (12,8),fontsize=15)\nax.legend(['Survived==0','Survived==1'],fontsize = 12)\nax.set_ylabel('Density',fontsize = 15)\nax.set_xlabel('Age',fontsize = 15)\nplt.show()\n```\n\n![](./data/1-1-年龄相关性.jpg)\n\n\n下面为正式的数据预处理\n\n```python\ndef preprocessing(dfdata):\n\n    dfresult= pd.DataFrame()\n\n    #Pclass\n    dfPclass = pd.get_dummies(dfdata['Pclass'])\n    dfPclass.columns = ['Pclass_' +str(x) for x in dfPclass.columns ]\n    dfresult = pd.concat([dfresult,dfPclass],axis = 1)\n\n    #Sex\n    dfSex = pd.get_dummies(dfdata['Sex'])\n    dfresult = pd.concat([dfresult,dfSex],axis = 1)\n\n    #Age\n    dfresult['Age'] = dfdata['Age'].fillna(0)\n    dfresult['Age_null'] = pd.isna(dfdata['Age']).astype('int32')\n\n    #SibSp,Parch,Fare\n    dfresult['SibSp'] = dfdata['SibSp']\n    dfresult['Parch'] = dfdata['Parch']\n    dfresult['Fare'] = dfdata['Fare']\n\n    #Carbin\n    dfresult['Cabin_null'] =  pd.isna(dfdata['Cabin']).astype('int32')\n\n    #Embarked\n    dfEmbarked = pd.get_dummies(dfdata['Embarked'],dummy_na=True)\n    dfEmbarked.columns = ['Embarked_' + str(x) for x in dfEmbarked.columns]\n    dfresult = pd.concat([dfresult,dfEmbarked],axis = 1)\n\n    return(dfresult)\n\nx_train = preprocessing(dftrain_raw)\ny_train = dftrain_raw['Survived'].values\n\nx_test = preprocessing(dftest_raw)\ny_test = dftest_raw['Survived'].values\n\nprint(\"x_train.shape =\", x_train.shape )\nprint(\"x_test.shape =\", x_test.shape )\n\n```\n\n```\nx_train.shape = (712, 15)\nx_test.shape = (179, 15)\n```\n\n```python\n\n```\n\n### 二，定义模型\n\n\n使用Keras接口有以下3种方式构建模型：使用Sequential按层顺序构建模型，使用函数式API构建任意结构模型，继承Model基类构建自定义模型。\n\n此处选择使用最简单的Sequential，按层顺序模型。\n\n```python\ntf.keras.backend.clear_session()\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(20,activation = 'relu',input_shape=(15,)))\nmodel.add(layers.Dense(10,activation = 'relu' ))\nmodel.add(layers.Dense(1,activation = 'sigmoid' ))\n\nmodel.summary()\n```\n\n```\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 20)                320       \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                210       \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 11        \n=================================================================\nTotal params: 541\nTrainable params: 541\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n\n### 三，训练模型\n\n\n训练模型通常有3种方法，内置fit方法，内置train_on_batch方法，以及自定义训练循环。此处我们选择最常用也最简单的内置fit方法。\n\n```python\n# 二分类问题选择二元交叉熵损失函数\nmodel.compile(optimizer='adam',\n            loss='binary_crossentropy',\n            metrics=['AUC'])\n\nhistory = model.fit(x_train,y_train,\n                    batch_size= 64,\n                    epochs= 30,\n                    validation_split=0.2 #分割一部分训练数据用于验证\n                   )\n```\n\n```\nTrain on 569 samples, validate on 143 samples\nEpoch 1/30\n569/569 [==============================] - 1s 2ms/sample - loss: 3.5841 - AUC: 0.4079 - val_loss: 3.4429 - val_AUC: 0.4129\nEpoch 2/30\n569/569 [==============================] - 0s 102us/sample - loss: 2.6093 - AUC: 0.3967 - val_loss: 2.4886 - val_AUC: 0.4139\nEpoch 3/30\n569/569 [==============================] - 0s 68us/sample - loss: 1.8375 - AUC: 0.4003 - val_loss: 1.7383 - val_AUC: 0.4223\nEpoch 4/30\n569/569 [==============================] - 0s 83us/sample - loss: 1.2545 - AUC: 0.4390 - val_loss: 1.1936 - val_AUC: 0.4765\nEpoch 5/30\n569/569 [==============================] - ETA: 0s - loss: 1.4435 - AUC: 0.375 - 0s 90us/sample - loss: 0.9141 - AUC: 0.5192 - val_loss: 0.8274 - val_AUC: 0.5584\nEpoch 6/30\n569/569 [==============================] - 0s 110us/sample - loss: 0.7052 - AUC: 0.6290 - val_loss: 0.6596 - val_AUC: 0.6880\nEpoch 7/30\n569/569 [==============================] - 0s 90us/sample - loss: 0.6410 - AUC: 0.7086 - val_loss: 0.6519 - val_AUC: 0.6845\nEpoch 8/30\n569/569 [==============================] - 0s 93us/sample - loss: 0.6246 - AUC: 0.7080 - val_loss: 0.6480 - val_AUC: 0.6846\nEpoch 9/30\n569/569 [==============================] - 0s 73us/sample - loss: 0.6088 - AUC: 0.7113 - val_loss: 0.6497 - val_AUC: 0.6838\nEpoch 10/30\n569/569 [==============================] - 0s 79us/sample - loss: 0.6051 - AUC: 0.7117 - val_loss: 0.6454 - val_AUC: 0.6873\nEpoch 11/30\n569/569 [==============================] - 0s 96us/sample - loss: 0.5972 - AUC: 0.7218 - val_loss: 0.6369 - val_AUC: 0.6888\nEpoch 12/30\n569/569 [==============================] - 0s 92us/sample - loss: 0.5918 - AUC: 0.7294 - val_loss: 0.6330 - val_AUC: 0.6908\nEpoch 13/30\n569/569 [==============================] - 0s 75us/sample - loss: 0.5864 - AUC: 0.7363 - val_loss: 0.6281 - val_AUC: 0.6948\nEpoch 14/30\n569/569 [==============================] - 0s 104us/sample - loss: 0.5832 - AUC: 0.7426 - val_loss: 0.6240 - val_AUC: 0.7030\nEpoch 15/30\n569/569 [==============================] - 0s 74us/sample - loss: 0.5777 - AUC: 0.7507 - val_loss: 0.6200 - val_AUC: 0.7066\nEpoch 16/30\n569/569 [==============================] - 0s 79us/sample - loss: 0.5726 - AUC: 0.7569 - val_loss: 0.6155 - val_AUC: 0.7132\nEpoch 17/30\n569/569 [==============================] - 0s 99us/sample - loss: 0.5674 - AUC: 0.7643 - val_loss: 0.6070 - val_AUC: 0.7255\nEpoch 18/30\n569/569 [==============================] - 0s 97us/sample - loss: 0.5631 - AUC: 0.7721 - val_loss: 0.6061 - val_AUC: 0.7305\nEpoch 19/30\n569/569 [==============================] - 0s 73us/sample - loss: 0.5580 - AUC: 0.7792 - val_loss: 0.6027 - val_AUC: 0.7332\nEpoch 20/30\n569/569 [==============================] - 0s 85us/sample - loss: 0.5533 - AUC: 0.7861 - val_loss: 0.5997 - val_AUC: 0.7366\nEpoch 21/30\n569/569 [==============================] - 0s 87us/sample - loss: 0.5497 - AUC: 0.7926 - val_loss: 0.5961 - val_AUC: 0.7433\nEpoch 22/30\n569/569 [==============================] - 0s 101us/sample - loss: 0.5454 - AUC: 0.7987 - val_loss: 0.5943 - val_AUC: 0.7438\nEpoch 23/30\n569/569 [==============================] - 0s 100us/sample - loss: 0.5398 - AUC: 0.8057 - val_loss: 0.5926 - val_AUC: 0.7492\nEpoch 24/30\n569/569 [==============================] - 0s 79us/sample - loss: 0.5328 - AUC: 0.8122 - val_loss: 0.5912 - val_AUC: 0.7493\nEpoch 25/30\n569/569 [==============================] - 0s 86us/sample - loss: 0.5283 - AUC: 0.8147 - val_loss: 0.5902 - val_AUC: 0.7509\nEpoch 26/30\n569/569 [==============================] - 0s 67us/sample - loss: 0.5246 - AUC: 0.8196 - val_loss: 0.5845 - val_AUC: 0.7552\nEpoch 27/30\n569/569 [==============================] - 0s 72us/sample - loss: 0.5205 - AUC: 0.8271 - val_loss: 0.5837 - val_AUC: 0.7584\nEpoch 28/30\n569/569 [==============================] - 0s 74us/sample - loss: 0.5144 - AUC: 0.8302 - val_loss: 0.5848 - val_AUC: 0.7561\nEpoch 29/30\n569/569 [==============================] - 0s 77us/sample - loss: 0.5099 - AUC: 0.8326 - val_loss: 0.5809 - val_AUC: 0.7583\nEpoch 30/30\n569/569 [==============================] - 0s 80us/sample - loss: 0.5071 - AUC: 0.8349 - val_loss: 0.5816 - val_AUC: 0.7605\n\n```\n\n\n### 四，评估模型\n\n\n我们首先评估一下模型在训练集和验证集上的效果。\n\n```python\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\n\nimport matplotlib.pyplot as plt\n\ndef plot_metric(history, metric):\n    train_metrics = history.history[metric]\n    val_metrics = history.history['val_'+metric]\n    epochs = range(1, len(train_metrics) + 1)\n    plt.plot(epochs, train_metrics, 'bo--')\n    plt.plot(epochs, val_metrics, 'ro-')\n    plt.title('Training and validation '+ metric)\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(metric)\n    plt.legend([\"train_\"+metric, 'val_'+metric])\n    plt.show()\n```\n\n```python\nplot_metric(history,\"loss\")\n```\n\n![](./data/1-1-Loss曲线.jpg)\n\n```python\nplot_metric(history,\"AUC\")\n```\n\n![](./data/1-1-AUC曲线.jpg)\n\n\n我们再看一下模型在测试集上的效果.\n\n```python\nmodel.evaluate(x = x_test,y = y_test)\n```\n\n```\n[0.5191367897907448, 0.8122605]\n```\n\n```python\n\n```\n\n### 五，使用模型\n\n```python\n#预测概率\nmodel.predict(x_test[0:10])\n#model(tf.constant(x_test[0:10].values,dtype = tf.float32)) #等价写法\n```\n\n```\narray([[0.26501188],\n       [0.40970832],\n       [0.44285864],\n       [0.78408605],\n       [0.47650957],\n       [0.43849158],\n       [0.27426785],\n       [0.5962582 ],\n       [0.59476686],\n       [0.17882936]], dtype=float32)\n```\n\n```python\n#预测类别\nmodel.predict_classes(x_test[0:10])\n```\n\n```\narray([[0],\n       [0],\n       [0],\n       [1],\n       [0],\n       [0],\n       [0],\n       [1],\n       [1],\n       [0]], dtype=int32)\n```\n\n```python\n\n```\n\n### 六，保存模型\n\n\n可以使用Keras方式保存模型，也可以使用TensorFlow原生方式保存。前者仅仅适合使用Python环境恢复模型，后者则可以跨平台进行模型部署。\n\n推荐使用后一种方式进行保存。\n\n\n**1，Keras方式保存**\n\n```python\n# 保存模型结构及权重\n\nmodel.save('./data/keras_model.h5')  \n\ndel model  #删除现有模型\n\n# identical to the previous one\nmodel = models.load_model('./data/keras_model.h5')\nmodel.evaluate(x_test,y_test)\n```\n\n```\n[0.5191367897907448, 0.8122605]\n```\n\n```python\n# 保存模型结构\njson_str = model.to_json()\n\n# 恢复模型结构\nmodel_json = models.model_from_json(json_str)\n```\n\n```python\n#保存模型权重\nmodel.save_weights('./data/keras_model_weight.h5')\n\n# 恢复模型结构\nmodel_json = models.model_from_json(json_str)\nmodel_json.compile(\n        optimizer='adam',\n        loss='binary_crossentropy',\n        metrics=['AUC']\n    )\n\n# 加载权重\nmodel_json.load_weights('./data/keras_model_weight.h5')\nmodel_json.evaluate(x_test,y_test)\n```\n\n```\n[0.5191367897907448, 0.8122605]\n```\n\n\n**2，TensorFlow原生方式保存**\n\n```python\n# 保存权重，该方式仅仅保存权重张量\nmodel.save_weights('./data/tf_model_weights.ckpt',save_format = \"tf\")\n```\n\n```python\n# 保存模型结构与模型参数到文件,该方式保存的模型具有跨平台性便于部署\n\nmodel.save('./data/tf_model_savedmodel', save_format=\"tf\")\nprint('export saved model.')\n\nmodel_loaded = tf.keras.models.load_model('./data/tf_model_savedmodel')\nmodel_loaded.evaluate(x_test,y_test)\n```\n\n```\n[0.5191365896656527, 0.8122605]\n```\n\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n\n```python\n\n```\n"
        },
        {
          "name": "1-2,图片数据建模流程范例.md",
          "type": "blob",
          "size": 11.083984375,
          "content": "# 1-2,图片数据建模流程范例\n\n\n### 一，准备数据\n\n\ncifar2数据集为cifar10数据集的子集，只包括前两种类别airplane和automobile。\n\n训练集有airplane和automobile图片各5000张，测试集有airplane和automobile图片各1000张。\n\ncifar2任务的目标是训练一个模型来对飞机airplane和机动车automobile两种图片进行分类。\n\n我们准备的Cifar2数据集的文件结构如下所示。\n\n![](./data/cifar2.jpg)\n\n```python\n\n```\n\n在tensorflow中准备图片数据的常用方案有两种，第一种是使用tf.keras中的ImageDataGenerator工具构建图片数据生成器。\n\n第二种是使用tf.data.Dataset搭配tf.image中的一些图片处理方法构建数据管道。\n\n第一种方法更为简单，其使用范例可以参考以下文章。\n\n[《Keras图像数据预处理范例——Cifar2图片分类》](https://mp.weixin.qq.com/s?__biz=MzU3OTQzNTU2OA==&mid=2247484795&idx=1&sn=16947726702b87ee535aef0d6ae2db30&chksm=fd676824ca10e1321e77c5fa44339c0a79442cd8d7fbcc58697be166a4b0f990306848724692&mpshare=1&scene=1&srcid=1227ARPw2Ir8nVC4B84CjcIx&sharer_sharetime=1609043128020&sharer_shareid=808295d573831eb57288f1fc0ad3ac69&key=a58ea5adca8c8f06e4a7b7a15ed218f88cbee52ab3ee0fca3f2dd3f0797a36a6de26f8e75bd4787ddf97195c3959d94fe5060be0d3f9f6cd1eba11c0ad1ee37709088084d70034bd03efd43dacc32acd45a231c8359dd84ad73c28b11a9dc50556486b6e1e1ab89ad11da9621e5cdd858fcb53d91037d5116d638d12fced85b3&ascene=0&uin=MTYzMDEzMjAxMg%3D%3D&devicetype=iMac+MacBookAir7%2C2+OSX+OSX+10.14.6+build(18G6032)&version=11020113&lang=zh_CN&exportkey=A8nc9Ve3hcMzsggW3DOY8mU%3D&pass_ticket=JOjUjT6HXslkPfqXrPY1oG3qVEXbIIc1IAKdh8xjlrGyB8OtZ8JjRan45%2Ff%2Bknjb&wx_header=0)\n\n第二种方法是TensorFlow的原生方法，更加灵活，使用得当的话也可以获得更好的性能。\n\n我们此处介绍第二种方法。\n\n\n```python\nimport tensorflow as tf \nfrom tensorflow.keras import datasets,layers,models\n\nBATCH_SIZE = 100\n\ndef load_image(img_path,size = (32,32)):\n    label = tf.constant(1,tf.int8) if tf.strings.regex_full_match(img_path,\".*automobile.*\") \\\n            else tf.constant(0,tf.int8)\n    img = tf.io.read_file(img_path)\n    img = tf.image.decode_jpeg(img) #注意此处为jpeg格式\n    img = tf.image.resize(img,size)/255.0\n    return(img,label)\n\n```\n\n```python\n#使用并行化预处理num_parallel_calls 和预存数据prefetch来提升性能\nds_train = tf.data.Dataset.list_files(\"./data/cifar2/train/*/*.jpg\") \\\n           .map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE) \\\n           .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n           .prefetch(tf.data.experimental.AUTOTUNE)  \n\nds_test = tf.data.Dataset.list_files(\"./data/cifar2/test/*/*.jpg\") \\\n           .map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE) \\\n           .batch(BATCH_SIZE) \\\n           .prefetch(tf.data.experimental.AUTOTUNE)  \n\n```\n\n```python\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\n\n#查看部分样本\nfrom matplotlib import pyplot as plt \n\nplt.figure(figsize=(8,8)) \nfor i,(img,label) in enumerate(ds_train.unbatch().take(9)):\n    ax=plt.subplot(3,3,i+1)\n    ax.imshow(img.numpy())\n    ax.set_title(\"label = %d\"%label)\n    ax.set_xticks([])\n    ax.set_yticks([]) \nplt.show()\n\n```\n\n![](./data/1-2-图片预览.jpg)\n\n```python\nfor x,y in ds_train.take(1):\n    print(x.shape,y.shape)\n```\n\n```\n(100, 32, 32, 3) (100,)\n```\n\n```python\n\n```\n\n### 二，定义模型\n\n\n使用Keras接口有以下3种方式构建模型：使用Sequential按层顺序构建模型，使用函数式API构建任意结构模型，继承Model基类构建自定义模型。\n\n此处选择使用函数式API构建模型。\n\n```python\ntf.keras.backend.clear_session() #清空会话\n\ninputs = layers.Input(shape=(32,32,3))\nx = layers.Conv2D(32,kernel_size=(3,3))(inputs)\nx = layers.MaxPool2D()(x)\nx = layers.Conv2D(64,kernel_size=(5,5))(x)\nx = layers.MaxPool2D()(x)\nx = layers.Dropout(rate=0.1)(x)\nx = layers.Flatten()(x)\nx = layers.Dense(32,activation='relu')(x)\noutputs = layers.Dense(1,activation = 'sigmoid')(x)\n\nmodel = models.Model(inputs = inputs,outputs = outputs)\n\nmodel.summary()\n```\n\n```\nModel: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 30, 30, 32)        896       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 11, 11, 64)        51264     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n_________________________________________________________________\ndropout (Dropout)            (None, 5, 5, 64)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 1600)              0         \n_________________________________________________________________\ndense (Dense)                (None, 32)                51232     \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 33        \n=================================================================\nTotal params: 103,425\nTrainable params: 103,425\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n```python\n\n```\n\n### 三，训练模型\n\n\n训练模型通常有3种方法，内置fit方法，内置train_on_batch方法，以及自定义训练循环。此处我们选择最常用也最简单的内置fit方法。\n\n```python\nimport datetime\nimport os\n\nstamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\nlogdir = os.path.join('data', 'autograph', stamp)\n\n## 在 Python3 下建议使用 pathlib 修正各操作系统的路径\n# from pathlib import Path\n# stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n# logdir = str(Path('./data/autograph/' + stamp))\n\ntensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n\nmodel.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n        loss=tf.keras.losses.binary_crossentropy,\n        metrics=[\"accuracy\"]\n    )\n\nhistory = model.fit(ds_train,epochs= 10,validation_data=ds_test,\n                    callbacks = [tensorboard_callback],workers = 4)\n\n```\n\n```\nTrain for 100 steps, validate for 20 steps\nEpoch 1/10\n100/100 [==============================] - 16s 156ms/step - loss: 0.4830 - accuracy: 0.7697 - val_loss: 0.3396 - val_accuracy: 0.8475\nEpoch 2/10\n100/100 [==============================] - 14s 142ms/step - loss: 0.3437 - accuracy: 0.8469 - val_loss: 0.2997 - val_accuracy: 0.8680\nEpoch 3/10\n100/100 [==============================] - 13s 131ms/step - loss: 0.2871 - accuracy: 0.8777 - val_loss: 0.2390 - val_accuracy: 0.9015\nEpoch 4/10\n100/100 [==============================] - 12s 117ms/step - loss: 0.2410 - accuracy: 0.9040 - val_loss: 0.2005 - val_accuracy: 0.9195\nEpoch 5/10\n100/100 [==============================] - 13s 130ms/step - loss: 0.1992 - accuracy: 0.9213 - val_loss: 0.1949 - val_accuracy: 0.9180\nEpoch 6/10\n100/100 [==============================] - 14s 136ms/step - loss: 0.1737 - accuracy: 0.9323 - val_loss: 0.1723 - val_accuracy: 0.9275\nEpoch 7/10\n100/100 [==============================] - 14s 139ms/step - loss: 0.1531 - accuracy: 0.9412 - val_loss: 0.1670 - val_accuracy: 0.9310\nEpoch 8/10\n100/100 [==============================] - 13s 134ms/step - loss: 0.1299 - accuracy: 0.9525 - val_loss: 0.1553 - val_accuracy: 0.9340\nEpoch 9/10\n100/100 [==============================] - 14s 137ms/step - loss: 0.1158 - accuracy: 0.9556 - val_loss: 0.1581 - val_accuracy: 0.9340\nEpoch 10/10\n100/100 [==============================] - 14s 142ms/step - loss: 0.1006 - accuracy: 0.9617 - val_loss: 0.1614 - val_accuracy: 0.9345\n```\n\n```python\n\n```\n\n### 四，评估模型\n\n```python\n%load_ext tensorboard\n#%tensorboard --logdir ./data/keras_model\n```\n\n```python\nfrom tensorboard import notebook\nnotebook.list() \n```\n\n```python\n#在tensorboard中查看模型\nnotebook.start(\"--logdir ./data/keras_model\")\n```\n\n```python\n\n```\n\n![](./data/1-2-tensorboard.jpg)\n\n```python\nimport pandas as pd \ndfhistory = pd.DataFrame(history.history)\ndfhistory.index = range(1,len(dfhistory) + 1)\ndfhistory.index.name = 'epoch'\n\ndfhistory\n```\n\n![](./data/1-2-dfhistory.jpg)\n\n```python\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\n\nimport matplotlib.pyplot as plt\n\ndef plot_metric(history, metric):\n    train_metrics = history.history[metric]\n    val_metrics = history.history['val_'+metric]\n    epochs = range(1, len(train_metrics) + 1)\n    plt.plot(epochs, train_metrics, 'bo--')\n    plt.plot(epochs, val_metrics, 'ro-')\n    plt.title('Training and validation '+ metric)\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(metric)\n    plt.legend([\"train_\"+metric, 'val_'+metric])\n    plt.show()\n```\n\n```python\nplot_metric(history,\"loss\")\n```\n\n![](./data/1-2-Loss曲线.jpg)\n\n```python\nplot_metric(history,\"accuracy\")\n```\n\n![](./data/1-2-Accuracy曲线.jpg)\n\n```python\n#可以使用evaluate对数据进行评估\nval_loss,val_accuracy = model.evaluate(ds_test,workers=4)\nprint(val_loss,val_accuracy)\n\n```\n\n```\n0.16139143370091916 0.9345\n```\n\n\n### 五，使用模型\n\n\n可以使用model.predict(ds_test)进行预测。\n\n也可以使用model.predict_on_batch(x_test)对一个批量进行预测。\n\n```python\nmodel.predict(ds_test)\n```\n\n```\narray([[9.9996173e-01],\n       [9.5104784e-01],\n       [2.8648047e-04],\n       ...,\n       [1.1484033e-03],\n       [3.5589080e-02],\n       [9.8537153e-01]], dtype=float32)\n```\n\n```python\nfor x,y in ds_test.take(1):\n    print(model.predict_on_batch(x[0:20]))\n```\n\n```\ntf.Tensor(\n[[3.8065155e-05]\n [8.8236779e-01]\n [9.1433197e-01]\n [9.9921846e-01]\n [6.4052093e-01]\n [4.9970779e-03]\n [2.6735585e-04]\n [9.9842811e-01]\n [7.9198682e-01]\n [7.4823302e-01]\n [8.7208226e-03]\n [9.3951421e-03]\n [9.9790359e-01]\n [9.9998581e-01]\n [2.1642199e-05]\n [1.7915063e-02]\n [2.5839690e-02]\n [9.7538447e-01]\n [9.7393811e-01]\n [9.7333014e-01]], shape=(20, 1), dtype=float32)\n```\n\n\n\n\n```python\n\n```\n\n### 六，保存模型\n\n\n推荐使用TensorFlow原生方式保存模型。\n\n```python\n# 保存权重，该方式仅仅保存权重张量\nmodel.save_weights('./data/tf_model_weights.ckpt',save_format = \"tf\")\n```\n\n```python\n# 保存模型结构与模型参数到文件,该方式保存的模型具有跨平台性便于部署\n\nmodel.save('./data/tf_model_savedmodel', save_format=\"tf\")\nprint('export saved model.')\n\nmodel_loaded = tf.keras.models.load_model('./data/tf_model_savedmodel')\nmodel_loaded.evaluate(ds_test)\n```\n\n```\n[0.16139124035835267, 0.9345]\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n"
        },
        {
          "name": "1-3,文本数据建模流程范例.md",
          "type": "blob",
          "size": 12.9072265625,
          "content": "# 1-3,文本数据建模流程范例\n\n\n### 一，准备数据\n\n\nimdb数据集的目标是根据电影评论的文本内容预测评论的情感标签。\n\n训练集有20000条电影评论文本，测试集有5000条电影评论文本，其中正面评论和负面评论都各占一半。\n\n文本数据预处理较为繁琐，包括中文切词（本示例不涉及），构建词典，编码转换，序列填充，构建数据管道等等。\n\n\n\n在tensorflow中完成文本数据预处理的常用方案有两种，第一种是利用tf.keras.preprocessing中的Tokenizer词典构建工具和tf.keras.utils.Sequence构建文本数据生成器管道。\n\n第二种是使用tf.data.Dataset搭配.keras.layers.experimental.preprocessing.TextVectorization预处理层。\n\n第一种方法较为复杂，其使用范例可以参考以下文章。\n\nhttps://zhuanlan.zhihu.com/p/67697840\n\n第二种方法为TensorFlow原生方式，相对也更加简单一些。\n\n我们此处介绍第二种方法。\n\n\n![](./data/电影评论.jpg)\n\n```python\nimport numpy as np \nimport pandas as pd \nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras import models,layers,preprocessing,optimizers,losses,metrics\nfrom tensorflow.keras.layers.experimental.preprocessing import TextVectorization\nimport re,string\n\ntrain_data_path = \"./data/imdb/train.csv\"\ntest_data_path =  \"./data/imdb/test.csv\"\n\nMAX_WORDS = 10000  # 仅考虑最高频的10000个词\nMAX_LEN = 200  # 每个样本保留200个词的长度\nBATCH_SIZE = 20 \n\n\n#构建管道\ndef split_line(line):\n    arr = tf.strings.split(line,\"\\t\")\n    label = tf.expand_dims(tf.cast(tf.strings.to_number(arr[0]),tf.int32),axis = 0)\n    text = tf.expand_dims(arr[1],axis = 0)\n    return (text,label)\n\nds_train_raw =  tf.data.TextLineDataset(filenames = [train_data_path]) \\\n   .map(split_line,num_parallel_calls = tf.data.experimental.AUTOTUNE) \\\n   .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n   .prefetch(tf.data.experimental.AUTOTUNE)\n\nds_test_raw = tf.data.TextLineDataset(filenames = [test_data_path]) \\\n   .map(split_line,num_parallel_calls = tf.data.experimental.AUTOTUNE) \\\n   .batch(BATCH_SIZE) \\\n   .prefetch(tf.data.experimental.AUTOTUNE)\n\n\n#构建词典\ndef clean_text(text):\n    lowercase = tf.strings.lower(text)\n    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n    cleaned_punctuation = tf.strings.regex_replace(stripped_html,\n         '[%s]' % re.escape(string.punctuation),'')\n    return cleaned_punctuation\n\nvectorize_layer = TextVectorization(\n    standardize=clean_text,\n    split = 'whitespace',\n    max_tokens=MAX_WORDS-1, #有一个留给占位符\n    output_mode='int',\n    output_sequence_length=MAX_LEN)\n\nds_text = ds_train_raw.map(lambda text,label: text)\nvectorize_layer.adapt(ds_text)\nprint(vectorize_layer.get_vocabulary()[0:100])\n\n\n#单词编码\nds_train = ds_train_raw.map(lambda text,label:(vectorize_layer(text),label)) \\\n    .prefetch(tf.data.experimental.AUTOTUNE)\nds_test = ds_test_raw.map(lambda text,label:(vectorize_layer(text),label)) \\\n    .prefetch(tf.data.experimental.AUTOTUNE)\n\n```\n\n```\n[b'the', b'and', b'a', b'of', b'to', b'is', b'in', b'it', b'i', b'this', b'that', b'was', b'as', b'for', b'with', b'movie', b'but', b'film', b'on', b'not', b'you', b'his', b'are', b'have', b'be', b'he', b'one', b'its', b'at', b'all', b'by', b'an', b'they', b'from', b'who', b'so', b'like', b'her', b'just', b'or', b'about', b'has', b'if', b'out', b'some', b'there', b'what', b'good', b'more', b'when', b'very', b'she', b'even', b'my', b'no', b'would', b'up', b'time', b'only', b'which', b'story', b'really', b'their', b'were', b'had', b'see', b'can', b'me', b'than', b'we', b'much', b'well', b'get', b'been', b'will', b'into', b'people', b'also', b'other', b'do', b'bad', b'because', b'great', b'first', b'how', b'him', b'most', b'dont', b'made', b'then', b'them', b'films', b'movies', b'way', b'make', b'could', b'too', b'any', b'after', b'characters']\n```\n\n```python\n\n```\n\n### 二，定义模型\n\n\n使用Keras接口有以下3种方式构建模型：使用Sequential按层顺序构建模型，使用函数式API构建任意结构模型，继承Model基类构建自定义模型。\n\n此处选择使用继承Model基类构建自定义模型。\n\n```python\n# 演示自定义模型范例，实际上应该优先使用Sequential或者函数式API\ntf.keras.backend.clear_session()\n\nclass CnnModel(models.Model):\n    def __init__(self):\n        super(CnnModel, self).__init__()\n        \n    def build(self,input_shape):\n        self.embedding = layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN)\n        self.conv_1 = layers.Conv1D(16, kernel_size= 5,name = \"conv_1\",activation = \"relu\")\n        self.pool_1 = layers.MaxPool1D(name = \"pool_1\")\n        self.conv_2 = layers.Conv1D(128, kernel_size=2,name = \"conv_2\",activation = \"relu\")\n        self.pool_2 = layers.MaxPool1D(name = \"pool_2\")\n        self.flatten = layers.Flatten()\n        self.dense = layers.Dense(1,activation = \"sigmoid\")\n        super(CnnModel,self).build(input_shape)\n    \n    def call(self, x):\n        x = self.embedding(x)\n        x = self.conv_1(x)\n        x = self.pool_1(x)\n        x = self.conv_2(x)\n        x = self.pool_2(x)\n        x = self.flatten(x)\n        x = self.dense(x)\n        return(x)\n    \n    # 用于显示Output Shape\n    def summary(self):\n        x_input = layers.Input(shape = MAX_LEN)\n        output = self.call(x_input)\n        model = tf.keras.Model(inputs = x_input,outputs = output)\n        model.summary()\n    \nmodel = CnnModel()\nmodel.build(input_shape =(None,MAX_LEN))\nmodel.summary()\n\n```\n\n```python\n\n```\n\n```\nModel: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 200)]             0         \n_________________________________________________________________\nembedding (Embedding)        (None, 200, 7)            70000     \n_________________________________________________________________\nconv_1 (Conv1D)              (None, 196, 16)           576       \n_________________________________________________________________\npool_1 (MaxPooling1D)        (None, 98, 16)            0         \n_________________________________________________________________\nconv_2 (Conv1D)              (None, 97, 128)           4224      \n_________________________________________________________________\npool_2 (MaxPooling1D)        (None, 48, 128)           0         \n_________________________________________________________________\nflatten (Flatten)            (None, 6144)              0         \n_________________________________________________________________\ndense (Dense)                (None, 1)                 6145      \n=================================================================\nTotal params: 80,945\nTrainable params: 80,945\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n```python\n\n```\n\n### 三，训练模型\n\n\n训练模型通常有3种方法，内置fit方法，内置train_on_batch方法，以及自定义训练循环。此处我们通过自定义训练循环训练模型。\n\n```python\n#打印时间分割线\n@tf.function\ndef printbar():\n    today_ts = tf.timestamp()%(24*60*60)\n    \n    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\n    minite = tf.cast((today_ts%3600)//60,tf.int32)\n    second = tf.cast(tf.floor(today_ts%60),tf.int32)\n    \n    def timeformat(m):\n        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\n            return(tf.strings.format(\"0{}\",m))\n        else:\n            return(tf.strings.format(\"{}\",m))\n    \n    timestring = tf.strings.join([timeformat(hour),timeformat(minite),\n                timeformat(second)],separator = \":\")\n    tf.print(\"==========\"*8+timestring)\n\n    \n```\n\n```python\noptimizer = optimizers.Nadam()\nloss_func = losses.BinaryCrossentropy()\n\ntrain_loss = metrics.Mean(name='train_loss')\ntrain_metric = metrics.BinaryAccuracy(name='train_accuracy')\n\nvalid_loss = metrics.Mean(name='valid_loss')\nvalid_metric = metrics.BinaryAccuracy(name='valid_accuracy')\n\n\n@tf.function\ndef train_step(model, features, labels):\n    with tf.GradientTape() as tape:\n        predictions = model(features,training = True)\n        loss = loss_func(labels, predictions)\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n    train_loss.update_state(loss)\n    train_metric.update_state(labels, predictions)\n    \n\n@tf.function\ndef valid_step(model, features, labels):\n    predictions = model(features,training = False)\n    batch_loss = loss_func(labels, predictions)\n    valid_loss.update_state(batch_loss)\n    valid_metric.update_state(labels, predictions)\n\n\ndef train_model(model,ds_train,ds_valid,epochs):\n    for epoch in tf.range(1,epochs+1):\n        \n        for features, labels in ds_train:\n            train_step(model,features,labels)\n\n        for features, labels in ds_valid:\n            valid_step(model,features,labels)\n        \n        #此处logs模板需要根据metric具体情况修改\n        logs = 'Epoch={},Loss:{},Accuracy:{},Valid Loss:{},Valid Accuracy:{}' \n        \n        if epoch%1==0:\n            printbar()\n            tf.print(tf.strings.format(logs,\n            (epoch,train_loss.result(),train_metric.result(),valid_loss.result(),valid_metric.result())))\n            tf.print(\"\")\n        \n        train_loss.reset_states()\n        valid_loss.reset_states()\n        train_metric.reset_states()\n        valid_metric.reset_states()\n\ntrain_model(model,ds_train,ds_test,epochs = 6)\n\n```\n\n```\n================================================================================13:54:08\nEpoch=1,Loss:0.442317516,Accuracy:0.7695,Valid Loss:0.323672801,Valid Accuracy:0.8614\n\n================================================================================13:54:20\nEpoch=2,Loss:0.245737702,Accuracy:0.90215,Valid Loss:0.356488883,Valid Accuracy:0.8554\n\n================================================================================13:54:32\nEpoch=3,Loss:0.17360799,Accuracy:0.93455,Valid Loss:0.361132562,Valid Accuracy:0.8674\n\n================================================================================13:54:44\nEpoch=4,Loss:0.113476314,Accuracy:0.95975,Valid Loss:0.483677238,Valid Accuracy:0.856\n\n================================================================================13:54:57\nEpoch=5,Loss:0.0698405355,Accuracy:0.9768,Valid Loss:0.607856631,Valid Accuracy:0.857\n\n================================================================================13:55:15\nEpoch=6,Loss:0.0366807655,Accuracy:0.98825,Valid Loss:0.745884955,Valid Accuracy:0.854\n```\n\n\n### 四，评估模型\n\n\n通过自定义训练循环训练的模型没有经过编译，无法直接使用model.evaluate(ds_valid)方法\n\n```python\n\ndef evaluate_model(model,ds_valid):\n    for features, labels in ds_valid:\n         valid_step(model,features,labels)\n    logs = 'Valid Loss:{},Valid Accuracy:{}' \n    tf.print(tf.strings.format(logs,(valid_loss.result(),valid_metric.result())))\n    \n    valid_loss.reset_states()\n    train_metric.reset_states()\n    valid_metric.reset_states()\n\n    \n```\n\n```python\nevaluate_model(model,ds_test)\n```\n\n```\nValid Loss:0.745884418,Valid Accuracy:0.854\n```\n\n```python\n\n```\n\n### 五，使用模型\n\n\n可以使用以下方法:\n\n* model.predict(ds_test)\n* model(x_test)\n* model.call(x_test)\n* model.predict_on_batch(x_test)\n\n推荐优先使用model.predict(ds_test)方法，既可以对Dataset，也可以对Tensor使用。\n\n```python\nmodel.predict(ds_test)\n```\n\n```\narray([[0.7864823 ],\n       [0.9999901 ],\n       [0.99944776],\n       ...,\n       [0.8498302 ],\n       [0.13382755],\n       [1.        ]], dtype=float32)\n```\n\n```python\nfor x_test,_ in ds_test.take(1):\n    print(model(x_test))\n    #以下方法等价：\n    #print(model.call(x_test))\n    #print(model.predict_on_batch(x_test))\n```\n\n```\ntf.Tensor(\n[[7.8648227e-01]\n [9.9999011e-01]\n [9.9944776e-01]\n [3.7153201e-09]\n [9.4462049e-01]\n [2.3522753e-04]\n [1.2044354e-04]\n [9.3752089e-07]\n [9.9996352e-01]\n [9.3435925e-01]\n [9.8746723e-01]\n [9.9908626e-01]\n [4.1563155e-08]\n [4.1808244e-03]\n [8.0184749e-05]\n [8.3910513e-01]\n [3.5167937e-05]\n [7.2113985e-01]\n [4.5228912e-03]\n [9.9942589e-01]], shape=(20, 1), dtype=float32)\n```\n\n```python\n\n```\n\n### 六，保存模型\n\n\n推荐使用TensorFlow原生方式保存模型。\n\n```python\nmodel.save('./data/tf_model_savedmodel', save_format=\"tf\")\nprint('export saved model.')\n\nmodel_loaded = tf.keras.models.load_model('./data/tf_model_savedmodel')\nmodel_loaded.predict(ds_test)\n```\n\n```\narray([[0.7864823 ],\n       [0.9999901 ],\n       [0.99944776],\n       ...,\n       [0.8498302 ],\n       [0.13382755],\n       [1.        ]], dtype=float32)\n```\n\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n"
        },
        {
          "name": "1-4,时间序列数据建模流程范例.md",
          "type": "blob",
          "size": 19.5908203125,
          "content": "# 1-4,时间序列数据建模流程范例\n\n\n国内的新冠肺炎疫情从发现至今已经持续3个多月了，这场起源于吃野味的灾难给大家的生活造成了诸多方面的影响。\n\n有的同学是收入上的，有的同学是感情上的，有的同学是心理上的，还有的同学是体重上的。\n\n那么国内的新冠肺炎疫情何时结束呢？什么时候我们才可以重获自由呢？\n\n本篇文章将利用TensorFlow2.0建立时间序列RNN模型，对国内的新冠肺炎疫情结束时间进行预测。\n\n\n![](./data/疫情前后对比.png)\n\n\n### 一，准备数据\n\n<!-- #region -->\n\n\n本文的数据集取自tushare，数据集在本项目的 data目录下。\n\n![](./data/1-4-新增人数.png)\n\n<!-- #endregion -->\n\n```python\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport tensorflow as tf \nfrom tensorflow.keras import models,layers,losses,metrics,callbacks \n\n```\n\n```python\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\n\ndf = pd.read_csv(\"./data/covid-19.csv\",sep = \"\\t\")\ndf.plot(x = \"date\",y = [\"confirmed_num\",\"cured_num\",\"dead_num\"],figsize=(10,6))\nplt.xticks(rotation=60)\n\n```\n\n![](./data/1-4-累积曲线.png)\n\n```python\ndfdata = df.set_index(\"date\")\ndfdiff = dfdata.diff(periods=1).dropna()\ndfdiff = dfdiff.reset_index(\"date\")\n\ndfdiff.plot(x = \"date\",y = [\"confirmed_num\",\"cured_num\",\"dead_num\"],figsize=(10,6))\nplt.xticks(rotation=60)\ndfdiff = dfdiff.drop(\"date\",axis = 1).astype(\"float32\")\n\n```\n\n![](./data/1-4-新增曲线.png)\n\n```python\n#用某日前8天窗口数据作为输入预测该日数据\nWINDOW_SIZE = 8\n\ndef batch_dataset(dataset):\n    dataset_batched = dataset.batch(WINDOW_SIZE,drop_remainder=True)\n    return dataset_batched\n\nds_data = tf.data.Dataset.from_tensor_slices(tf.constant(dfdiff.values,dtype = tf.float32)) \\\n   .window(WINDOW_SIZE,shift=1).flat_map(batch_dataset)\n\nds_label = tf.data.Dataset.from_tensor_slices(\n    tf.constant(dfdiff.values[WINDOW_SIZE:],dtype = tf.float32))\n\n#数据较小，可以将全部训练数据放入到一个batch中，提升性能\nds_train = tf.data.Dataset.zip((ds_data,ds_label)).batch(38).cache()\n\n\n```\n\n### 二，定义模型\n\n\n使用Keras接口有以下3种方式构建模型：使用Sequential按层顺序构建模型，使用函数式API构建任意结构模型，继承Model基类构建自定义模型。\n\n此处选择使用函数式API构建任意结构模型。\n\n```python\n#考虑到新增确诊，新增治愈，新增死亡人数数据不可能小于0，设计如下结构\nclass Block(layers.Layer):\n    def __init__(self, **kwargs):\n        super(Block, self).__init__(**kwargs)\n    \n    def call(self, x_input,x):\n        x_out = tf.maximum((1+x)*x_input[:,-1,:],0.0)\n        return x_out\n    \n    def get_config(self):  \n        config = super(Block, self).get_config()\n        return config\n\n```\n\n```python\ntf.keras.backend.clear_session()\nx_input = layers.Input(shape = (None,3),dtype = tf.float32)\nx = layers.LSTM(3,return_sequences = True,input_shape=(None,3))(x_input)\nx = layers.LSTM(3,return_sequences = True,input_shape=(None,3))(x)\nx = layers.LSTM(3,return_sequences = True,input_shape=(None,3))(x)\nx = layers.LSTM(3,input_shape=(None,3))(x)\nx = layers.Dense(3)(x)\n\n#考虑到新增确诊，新增治愈，新增死亡人数数据不可能小于0，设计如下结构\n#x = tf.maximum((1+x)*x_input[:,-1,:],0.0)\nx = Block()(x_input,x)\nmodel = models.Model(inputs = [x_input],outputs = [x])\nmodel.summary()\n\n```\n\n```python\n\n```\n\n```\nModel: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, None, 3)]         0         \n_________________________________________________________________\nlstm (LSTM)                  (None, None, 3)           84        \n_________________________________________________________________\nlstm_1 (LSTM)                (None, None, 3)           84        \n_________________________________________________________________\nlstm_2 (LSTM)                (None, None, 3)           84        \n_________________________________________________________________\nlstm_3 (LSTM)                (None, 3)                 84        \n_________________________________________________________________\ndense (Dense)                (None, 3)                 12        \n_________________________________________________________________\nblock (Block)                (None, 3)                 0         \n=================================================================\nTotal params: 348\nTrainable params: 348\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n\n### 三，训练模型\n\n\n训练模型通常有3种方法，内置fit方法，内置train_on_batch方法，以及自定义训练循环。此处我们选择最常用也最简单的内置fit方法。\n\n注：循环神经网络调试较为困难，需要设置多个不同的学习率多次尝试，以取得较好的效果。\n\n```python\n#自定义损失函数，考虑平方差和预测目标的比值\nclass MSPE(losses.Loss):\n    def call(self,y_true,y_pred):\n        err_percent = (y_true - y_pred)**2/(tf.maximum(y_true**2,1e-7))\n        mean_err_percent = tf.reduce_mean(err_percent)\n        return mean_err_percent\n    \n    def get_config(self):\n        config = super(MSPE, self).get_config()\n        return config\n\n```\n\n```python\nimport os\nimport datetime\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\nmodel.compile(optimizer=optimizer,loss=MSPE(name = \"MSPE\"))\n\nstamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\nlogdir = os.path.join('data', 'autograph', stamp)\n\n## 在 Python3 下建议使用 pathlib 修正各操作系统的路径\n# from pathlib import Path\n# stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n# logdir = str(Path('./data/autograph/' + stamp))\n\ntb_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n#如果loss在100个epoch后没有提升，学习率减半。\nlr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\",factor = 0.5, patience = 100)\n#当loss在200个epoch后没有提升，则提前终止训练。\nstop_callback = tf.keras.callbacks.EarlyStopping(monitor = \"loss\", patience= 200)\ncallbacks_list = [tb_callback,lr_callback,stop_callback]\n\nhistory = model.fit(ds_train,epochs=500,callbacks = callbacks_list)\n\n```\n\n```\nEpoch 371/500\n1/1 [==============================] - 0s 61ms/step - loss: 0.1184\nEpoch 372/500\n1/1 [==============================] - 0s 64ms/step - loss: 0.1177\nEpoch 373/500\n1/1 [==============================] - 0s 56ms/step - loss: 0.1169\nEpoch 374/500\n1/1 [==============================] - 0s 50ms/step - loss: 0.1161\nEpoch 375/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.1154\nEpoch 376/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.1147\nEpoch 377/500\n1/1 [==============================] - 0s 62ms/step - loss: 0.1140\nEpoch 378/500\n1/1 [==============================] - 0s 93ms/step - loss: 0.1133\nEpoch 379/500\n1/1 [==============================] - 0s 85ms/step - loss: 0.1126\nEpoch 380/500\n1/1 [==============================] - 0s 68ms/step - loss: 0.1119\nEpoch 381/500\n1/1 [==============================] - 0s 52ms/step - loss: 0.1113\nEpoch 382/500\n1/1 [==============================] - 0s 54ms/step - loss: 0.1107\nEpoch 383/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.1100\nEpoch 384/500\n1/1 [==============================] - 0s 56ms/step - loss: 0.1094\nEpoch 385/500\n1/1 [==============================] - 0s 54ms/step - loss: 0.1088\nEpoch 386/500\n1/1 [==============================] - 0s 74ms/step - loss: 0.1082\nEpoch 387/500\n1/1 [==============================] - 0s 60ms/step - loss: 0.1077\nEpoch 388/500\n1/1 [==============================] - 0s 52ms/step - loss: 0.1071\nEpoch 389/500\n1/1 [==============================] - 0s 52ms/step - loss: 0.1066\nEpoch 390/500\n1/1 [==============================] - 0s 56ms/step - loss: 0.1060\nEpoch 391/500\n1/1 [==============================] - 0s 61ms/step - loss: 0.1055\nEpoch 392/500\n1/1 [==============================] - 0s 60ms/step - loss: 0.1050\nEpoch 393/500\n1/1 [==============================] - 0s 59ms/step - loss: 0.1045\nEpoch 394/500\n1/1 [==============================] - 0s 65ms/step - loss: 0.1040\nEpoch 395/500\n1/1 [==============================] - 0s 58ms/step - loss: 0.1035\nEpoch 396/500\n1/1 [==============================] - 0s 52ms/step - loss: 0.1031\nEpoch 397/500\n1/1 [==============================] - 0s 58ms/step - loss: 0.1026\nEpoch 398/500\n1/1 [==============================] - 0s 60ms/step - loss: 0.1022\nEpoch 399/500\n1/1 [==============================] - 0s 57ms/step - loss: 0.1017\nEpoch 400/500\n1/1 [==============================] - 0s 63ms/step - loss: 0.1013\nEpoch 401/500\n1/1 [==============================] - 0s 59ms/step - loss: 0.1009\nEpoch 402/500\n1/1 [==============================] - 0s 53ms/step - loss: 0.1005\nEpoch 403/500\n1/1 [==============================] - 0s 56ms/step - loss: 0.1001\nEpoch 404/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0997\nEpoch 405/500\n1/1 [==============================] - 0s 58ms/step - loss: 0.0993\nEpoch 406/500\n1/1 [==============================] - 0s 53ms/step - loss: 0.0990\nEpoch 407/500\n1/1 [==============================] - 0s 59ms/step - loss: 0.0986\nEpoch 408/500\n1/1 [==============================] - 0s 63ms/step - loss: 0.0982\nEpoch 409/500\n1/1 [==============================] - 0s 67ms/step - loss: 0.0979\nEpoch 410/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0976\nEpoch 411/500\n1/1 [==============================] - 0s 54ms/step - loss: 0.0972\nEpoch 412/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0969\nEpoch 413/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0966\nEpoch 414/500\n1/1 [==============================] - 0s 59ms/step - loss: 0.0963\nEpoch 415/500\n1/1 [==============================] - 0s 60ms/step - loss: 0.0960\nEpoch 416/500\n1/1 [==============================] - 0s 62ms/step - loss: 0.0957\nEpoch 417/500\n1/1 [==============================] - 0s 69ms/step - loss: 0.0954\nEpoch 418/500\n1/1 [==============================] - 0s 60ms/step - loss: 0.0951\nEpoch 419/500\n1/1 [==============================] - 0s 50ms/step - loss: 0.0948\nEpoch 420/500\n1/1 [==============================] - 0s 56ms/step - loss: 0.0946\nEpoch 421/500\n1/1 [==============================] - 0s 57ms/step - loss: 0.0943\nEpoch 422/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0941\nEpoch 423/500\n1/1 [==============================] - 0s 62ms/step - loss: 0.0938\nEpoch 424/500\n1/1 [==============================] - 0s 60ms/step - loss: 0.0936\nEpoch 425/500\n1/1 [==============================] - 0s 100ms/step - loss: 0.0933\nEpoch 426/500\n1/1 [==============================] - 0s 68ms/step - loss: 0.0931\nEpoch 427/500\n1/1 [==============================] - 0s 60ms/step - loss: 0.0929\nEpoch 428/500\n1/1 [==============================] - 0s 50ms/step - loss: 0.0926\nEpoch 429/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0924\nEpoch 430/500\n1/1 [==============================] - 0s 57ms/step - loss: 0.0922\nEpoch 431/500\n1/1 [==============================] - 0s 75ms/step - loss: 0.0920\nEpoch 432/500\n1/1 [==============================] - 0s 57ms/step - loss: 0.0918\nEpoch 433/500\n1/1 [==============================] - 0s 77ms/step - loss: 0.0916\nEpoch 434/500\n1/1 [==============================] - 0s 50ms/step - loss: 0.0914\nEpoch 435/500\n1/1 [==============================] - 0s 56ms/step - loss: 0.0912\nEpoch 436/500\n1/1 [==============================] - 0s 60ms/step - loss: 0.0911\nEpoch 437/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0909\nEpoch 438/500\n1/1 [==============================] - 0s 57ms/step - loss: 0.0907\nEpoch 439/500\n1/1 [==============================] - 0s 59ms/step - loss: 0.0905\nEpoch 440/500\n1/1 [==============================] - 0s 60ms/step - loss: 0.0904\nEpoch 441/500\n1/1 [==============================] - 0s 68ms/step - loss: 0.0902\nEpoch 442/500\n1/1 [==============================] - 0s 73ms/step - loss: 0.0901\nEpoch 443/500\n1/1 [==============================] - 0s 50ms/step - loss: 0.0899\nEpoch 444/500\n1/1 [==============================] - 0s 58ms/step - loss: 0.0898\nEpoch 445/500\n1/1 [==============================] - 0s 56ms/step - loss: 0.0896\nEpoch 446/500\n1/1 [==============================] - 0s 52ms/step - loss: 0.0895\nEpoch 447/500\n1/1 [==============================] - 0s 60ms/step - loss: 0.0893\nEpoch 448/500\n1/1 [==============================] - 0s 64ms/step - loss: 0.0892\nEpoch 449/500\n1/1 [==============================] - 0s 70ms/step - loss: 0.0891\nEpoch 450/500\n1/1 [==============================] - 0s 57ms/step - loss: 0.0889\nEpoch 451/500\n1/1 [==============================] - 0s 53ms/step - loss: 0.0888\nEpoch 452/500\n1/1 [==============================] - 0s 51ms/step - loss: 0.0887\nEpoch 453/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0886\nEpoch 454/500\n1/1 [==============================] - 0s 58ms/step - loss: 0.0885\nEpoch 455/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0883\nEpoch 456/500\n1/1 [==============================] - 0s 71ms/step - loss: 0.0882\nEpoch 457/500\n1/1 [==============================] - 0s 50ms/step - loss: 0.0881\nEpoch 458/500\n1/1 [==============================] - 0s 56ms/step - loss: 0.0880\nEpoch 459/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0879\nEpoch 460/500\n1/1 [==============================] - 0s 57ms/step - loss: 0.0878\nEpoch 461/500\n1/1 [==============================] - 0s 56ms/step - loss: 0.0878\nEpoch 462/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0879\nEpoch 463/500\n1/1 [==============================] - 0s 60ms/step - loss: 0.0879\nEpoch 464/500\n1/1 [==============================] - 0s 68ms/step - loss: 0.0888\nEpoch 465/500\n1/1 [==============================] - 0s 62ms/step - loss: 0.0875\nEpoch 466/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0873\nEpoch 467/500\n1/1 [==============================] - 0s 49ms/step - loss: 0.0872\nEpoch 468/500\n1/1 [==============================] - 0s 56ms/step - loss: 0.0872\nEpoch 469/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0871\nEpoch 470/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0871\nEpoch 471/500\n1/1 [==============================] - 0s 59ms/step - loss: 0.0870\nEpoch 472/500\n1/1 [==============================] - 0s 68ms/step - loss: 0.0871\nEpoch 473/500\n1/1 [==============================] - 0s 57ms/step - loss: 0.0869\nEpoch 474/500\n1/1 [==============================] - 0s 61ms/step - loss: 0.0870\nEpoch 475/500\n1/1 [==============================] - 0s 47ms/step - loss: 0.0868\nEpoch 476/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0868\nEpoch 477/500\n1/1 [==============================] - 0s 62ms/step - loss: 0.0866\nEpoch 478/500\n1/1 [==============================] - 0s 58ms/step - loss: 0.0867\nEpoch 479/500\n1/1 [==============================] - 0s 60ms/step - loss: 0.0865\nEpoch 480/500\n1/1 [==============================] - 0s 65ms/step - loss: 0.0866\nEpoch 481/500\n1/1 [==============================] - 0s 58ms/step - loss: 0.0864\nEpoch 482/500\n1/1 [==============================] - 0s 57ms/step - loss: 0.0865\nEpoch 483/500\n1/1 [==============================] - 0s 53ms/step - loss: 0.0863\nEpoch 484/500\n1/1 [==============================] - 0s 56ms/step - loss: 0.0864\nEpoch 485/500\n1/1 [==============================] - 0s 56ms/step - loss: 0.0862\nEpoch 486/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0863\nEpoch 487/500\n1/1 [==============================] - 0s 52ms/step - loss: 0.0861\nEpoch 488/500\n1/1 [==============================] - 0s 68ms/step - loss: 0.0862\nEpoch 489/500\n1/1 [==============================] - 0s 62ms/step - loss: 0.0860\nEpoch 490/500\n1/1 [==============================] - 0s 57ms/step - loss: 0.0861\nEpoch 491/500\n1/1 [==============================] - 0s 51ms/step - loss: 0.0859\nEpoch 492/500\n1/1 [==============================] - 0s 54ms/step - loss: 0.0860\nEpoch 493/500\n1/1 [==============================] - 0s 51ms/step - loss: 0.0859\nEpoch 494/500\n1/1 [==============================] - 0s 54ms/step - loss: 0.0860\nEpoch 495/500\n1/1 [==============================] - 0s 50ms/step - loss: 0.0858\nEpoch 496/500\n1/1 [==============================] - 0s 69ms/step - loss: 0.0859\nEpoch 497/500\n1/1 [==============================] - 0s 63ms/step - loss: 0.0857\nEpoch 498/500\n1/1 [==============================] - 0s 56ms/step - loss: 0.0858\nEpoch 499/500\n1/1 [==============================] - 0s 54ms/step - loss: 0.0857\nEpoch 500/500\n1/1 [==============================] - 0s 57ms/step - loss: 0.0858\n```\n\n```python\n\n```\n\n### 四，评估模型\n\n\n评估模型一般要设置验证集或者测试集，由于此例数据较少，我们仅仅可视化损失函数在训练集上的迭代情况。\n\n```python\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\n\nimport matplotlib.pyplot as plt\n\ndef plot_metric(history, metric):\n    train_metrics = history.history[metric]\n    epochs = range(1, len(train_metrics) + 1)\n    plt.plot(epochs, train_metrics, 'bo--')\n    plt.title('Training '+ metric)\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(metric)\n    plt.legend([\"train_\"+metric])\n    plt.show()\n\n```\n\n```python\nplot_metric(history,\"loss\")\n```\n\n![](./data/1-4-损失函数曲线.png)\n\n\n### 五，使用模型\n\n\n此处我们使用模型预测疫情结束时间，即 新增确诊病例为0 的时间。\n\n```python\n#使用dfresult记录现有数据以及此后预测的疫情数据\ndfresult = dfdiff[[\"confirmed_num\",\"cured_num\",\"dead_num\"]].copy()\ndfresult.tail()\n```\n\n![](./data/1-4-日期3月10.png)\n\n```python\n#预测此后100天的新增走势,将其结果添加到dfresult中\nfor i in range(100):\n    arr_predict = model.predict(tf.constant(tf.expand_dims(dfresult.values[-38:,:],axis = 0)))\n\n    dfpredict = pd.DataFrame(tf.cast(tf.floor(arr_predict),tf.float32).numpy(),\n                columns = dfresult.columns)\n    dfresult = dfresult.append(dfpredict,ignore_index=True)\n```\n\n```python\ndfresult.query(\"confirmed_num==0\").head()\n\n# 第55天开始新增确诊降为0，第45天对应3月10日，也就是10天后，即预计3月20日新增确诊降为0\n# 注：该预测偏乐观\n```\n\n![](./data/1-4-预测确诊.png)\n\n```python\n\n```\n\n```python\ndfresult.query(\"cured_num==0\").head()\n\n# 第164天开始新增治愈降为0，第45天对应3月10日，也就是大概4个月后，即7月10日左右全部治愈。\n# 注: 该预测偏悲观，并且存在问题，如果将每天新增治愈人数加起来，将超过累计确诊人数。\n```\n\n![](./data/1-4-预测治愈.png)\n\n```python\n\n```\n\n```python\ndfresult.query(\"dead_num==0\").head()\n\n# 第60天开始，新增死亡降为0，第45天对应3月10日，也就是大概15天后，即20200325\n# 该预测较为合理\n```\n\n![](./data/1-4-预测死亡.png)\n\n```python\n\n```\n\n### 六，保存模型\n\n\n推荐使用TensorFlow原生方式保存模型。\n\n```python\nmodel.save('./data/tf_model_savedmodel', save_format=\"tf\")\nprint('export saved model.')\n```\n\n```python\nmodel_loaded = tf.keras.models.load_model('./data/tf_model_savedmodel',compile=False)\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\nmodel_loaded.compile(optimizer=optimizer,loss=MSPE(name = \"MSPE\"))\nmodel_loaded.predict(ds_train)\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n"
        },
        {
          "name": "2-1,张量数据结构.md",
          "type": "blob",
          "size": 4.4248046875,
          "content": "# 2-1,张量数据结构\n\n程序 = 数据结构+算法。\n\nTensorFlow程序 = 张量数据结构 + 计算图算法语言\n\n张量和计算图是 TensorFlow的核心概念。\n\nTensorflow的基本数据结构是张量Tensor。张量即多维数组。Tensorflow的张量和numpy中的array很类似。\n\n从行为特性来看，有两种类型的张量，常量constant和变量Variable.\n\n常量的值在计算图中不可以被重新赋值，变量可以在计算图中用assign等算子重新赋值。\n\n\n### 一，常量张量\n\n\n张量的数据类型和numpy.array基本一一对应。\n\n```python\nimport numpy as np\nimport tensorflow as tf\n\ni = tf.constant(1) # tf.int32 类型常量\nl = tf.constant(1,dtype = tf.int64) # tf.int64 类型常量\nf = tf.constant(1.23) #tf.float32 类型常量\nd = tf.constant(3.14,dtype = tf.double) # tf.double 类型常量\ns = tf.constant(\"hello world\") # tf.string类型常量\nb = tf.constant(True) #tf.bool类型常量\n\n\nprint(tf.int64 == np.int64) \nprint(tf.bool == np.bool)\nprint(tf.double == np.float64)\nprint(tf.string == np.unicode) # tf.string类型和np.unicode类型不等价\n\n```\n\n```\nTrue\nTrue\nTrue\nFalse\n```\n\n\n不同类型的数据可以用不同维度(rank)的张量来表示。\n\n标量为0维张量，向量为1维张量，矩阵为2维张量。\n\n彩色图像有rgb三个通道，可以表示为3维张量。\n\n视频还有时间维，可以表示为4维张量。\n\n可以简单地总结为：有几层中括号，就是多少维的张量。\n\n```python\nscalar = tf.constant(True)  #标量，0维张量\n\nprint(tf.rank(scalar))\nprint(scalar.numpy().ndim)  # tf.rank的作用和numpy的ndim方法相同\n```\n\n```\ntf.Tensor(0, shape=(), dtype=int32)\n0\n```\n\n```python\nvector = tf.constant([1.0,2.0,3.0,4.0]) #向量，1维张量\n\nprint(tf.rank(vector))\nprint(np.ndim(vector.numpy()))\n```\n\n```\ntf.Tensor(1, shape=(), dtype=int32)\n1\n```\n\n```python\nmatrix = tf.constant([[1.0,2.0],[3.0,4.0]]) #矩阵, 2维张量\n\nprint(tf.rank(matrix).numpy())\nprint(np.ndim(matrix))\n```\n\n```\n2\n2\n```\n\n```python\ntensor3 = tf.constant([[[1.0,2.0],[3.0,4.0]],[[5.0,6.0],[7.0,8.0]]])  # 3维张量\nprint(tensor3)\nprint(tf.rank(tensor3))\n```\n\n```\ntf.Tensor(\n[[[1. 2.]\n  [3. 4.]]\n\n [[5. 6.]\n  [7. 8.]]], shape=(2, 2, 2), dtype=float32)\ntf.Tensor(3, shape=(), dtype=int32)\n```\n\n```python\ntensor4 = tf.constant([[[[1.0,1.0],[2.0,2.0]],[[3.0,3.0],[4.0,4.0]]],\n                        [[[5.0,5.0],[6.0,6.0]],[[7.0,7.0],[8.0,8.0]]]])  # 4维张量\nprint(tensor4)\nprint(tf.rank(tensor4))\n```\n\n```\ntf.Tensor(\n[[[[1. 1.]\n   [2. 2.]]\n\n  [[3. 3.]\n   [4. 4.]]]\n\n\n [[[5. 5.]\n   [6. 6.]]\n\n  [[7. 7.]\n   [8. 8.]]]], shape=(2, 2, 2, 2), dtype=float32)\ntf.Tensor(4, shape=(), dtype=int32)\n```\n\n\n可以用tf.cast改变张量的数据类型。\n\n可以用numpy方法将tensorflow中的张量转化成numpy中的张量。\n\n可以用shape方法查看张量的尺寸。\n\n```python\nh = tf.constant([123,456],dtype = tf.int32)\nf = tf.cast(h,tf.float32)\nprint(h.dtype, f.dtype)\n```\n\n```\n<dtype: 'int32'> <dtype: 'float32'>\n```\n\n```python\ny = tf.constant([[1.0,2.0],[3.0,4.0]])\nprint(y.numpy()) #转换成np.array\nprint(y.shape)\n```\n\n```\n[[1. 2.]\n [3. 4.]]\n(2, 2)\n```\n\n```python\nu = tf.constant(u\"你好 世界\")\nprint(u.numpy())  \nprint(u.numpy().decode(\"utf-8\"))\n```\n\n```\nb'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd \\xe4\\xb8\\x96\\xe7\\x95\\x8c'\n你好 世界\n```\n\n```python\n\n```\n### 二，变量张量\n\n\n模型中需要被训练的参数一般被设置成变量。\n\n```python\n# 常量值不可以改变，常量的重新赋值相当于创造新的内存空间\nc = tf.constant([1.0,2.0])\nprint(c)\nprint(id(c))\nc = c + tf.constant([1.0,1.0])\nprint(c)\nprint(id(c))\n```\n\n```\ntf.Tensor([1. 2.], shape=(2,), dtype=float32)\n5276289568\ntf.Tensor([2. 3.], shape=(2,), dtype=float32)\n5276290240\n```\n\n```python\n# 变量的值可以改变，可以通过assign, assign_add等方法给变量重新赋值\nv = tf.Variable([1.0,2.0],name = \"v\")\nprint(v)\nprint(id(v))\nv.assign_add([1.0,1.0])\nprint(v)\nprint(id(v))\n```\n```\n<tf.Variable 'v:0' shape=(2,) dtype=float32, numpy=array([1., 2.], dtype=float32)>\n5276259888\n<tf.Variable 'v:0' shape=(2,) dtype=float32, numpy=array([2., 3.], dtype=float32)>\n5276259888\n\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n\n\n"
        },
        {
          "name": "2-2,三种计算图.md",
          "type": "blob",
          "size": 6.490234375,
          "content": "# 2-2,三种计算图\n\n\n有三种计算图的构建方式：静态计算图，动态计算图，以及Autograph.\n\n在TensorFlow1.0时代，采用的是静态计算图，需要先使用TensorFlow的各种算子创建计算图，然后再开启一个会话Session，显式执行计算图。\n\n而在TensorFlow2.0时代，采用的是动态计算图，即每使用一个算子后，该算子会被动态加入到隐含的默认计算图中立即执行得到结果，而无需开启Session。\n\n使用动态计算图即Eager Excution的好处是方便调试程序，它会让TensorFlow代码的表现和Python原生代码的表现一样，写起来就像写numpy一样，各种日志打印，控制流全部都是可以使用的。\n\n使用动态计算图的缺点是运行效率相对会低一些。因为使用动态图会有许多次Python进程和TensorFlow的C++进程之间的通信。而静态计算图构建完成之后几乎全部在TensorFlow内核上使用C++代码执行，效率更高。此外静态图会对计算步骤进行一定的优化，剪去和结果无关的计算步骤。\n\n如果需要在TensorFlow2.0中使用静态图，可以使用@tf.function装饰器将普通Python函数转换成对应的TensorFlow计算图构建代码。运行该函数就相当于在TensorFlow1.0中用Session执行代码。使用tf.function构建静态图的方式叫做 Autograph.\n\n\n### 一，计算图简介\n\n\n计算图由节点(nodes)和线(edges)组成。\n\n节点表示操作符Operator，或者称之为算子，线表示计算间的依赖。\n\n实线表示有数据传递依赖，传递的数据即张量。\n\n虚线通常可以表示控制依赖，即执行先后顺序。\n\n![](./data/strjoin_graph.png)\n\n\n### 二，静态计算图\n\n\n在TensorFlow1.0中，使用静态计算图分两步，第一步定义计算图，第二步在会话中执行计算图。\n\n<!-- #region -->\n**TensorFlow 1.0静态计算图范例**\n\n```python\nimport tensorflow as tf\n\n#定义计算图\ng = tf.Graph()\nwith g.as_default():\n    #placeholder为占位符，执行会话时候指定填充对象\n    x = tf.placeholder(name='x', shape=[], dtype=tf.string)  \n    y = tf.placeholder(name='y', shape=[], dtype=tf.string)\n    z = tf.string_join([x,y],name = 'join',separator=' ')\n\n#执行计算图\nwith tf.Session(graph = g) as sess:\n    print(sess.run(fetches = z,feed_dict = {x:\"hello\",y:\"world\"}))\n   \n```\n<!-- #endregion -->\n\n**TensorFlow2.0 怀旧版静态计算图**\n\nTensorFlow2.0为了确保对老版本tensorflow项目的兼容性，在tf.compat.v1子模块中保留了对TensorFlow1.0那种静态计算图构建风格的支持。\n\n可称之为怀旧版静态计算图，已经不推荐使用了。\n\n```python\nimport tensorflow as tf\n\ng = tf.compat.v1.Graph()\nwith g.as_default():\n    x = tf.compat.v1.placeholder(name='x', shape=[], dtype=tf.string)\n    y = tf.compat.v1.placeholder(name='y', shape=[], dtype=tf.string)\n    z = tf.strings.join([x,y],name = \"join\",separator = \" \")\n\nwith tf.compat.v1.Session(graph = g) as sess:\n    # fetches的结果非常像一个函数的返回值，而feed_dict中的占位符相当于函数的参数序列。\n    result = sess.run(fetches = z,feed_dict = {x:\"hello\",y:\"world\"})\n    print(result)\n\n```\n\n```\nb'hello world'\n```\n\n\n### 三，动态计算图\n\n\n在TensorFlow2.0中，使用的是动态计算图和Autograph.\n\n在TensorFlow1.0中，使用静态计算图分两步，第一步定义计算图，第二步在会话中执行计算图。\n\n动态计算图已经不区分计算图的定义和执行了，而是定义后立即执行。因此称之为 Eager Excution.\n\nEager这个英文单词的原意是\"迫不及待的\"，也就是立即执行的意思。\n\n\n```python\n# 动态计算图在每个算子处都进行构建，构建后立即执行\n\nx = tf.constant(\"hello\")\ny = tf.constant(\"world\")\nz = tf.strings.join([x,y],separator=\" \")\n\ntf.print(z)\n```\n\n```\nhello world\n```\n\n```python\n# 可以将动态计算图代码的输入和输出关系封装成函数\n\ndef strjoin(x,y):\n    z =  tf.strings.join([x,y],separator = \" \")\n    tf.print(z)\n    return z\n\nresult = strjoin(tf.constant(\"hello\"),tf.constant(\"world\"))\nprint(result)\n```\n\n```\nhello world\ntf.Tensor(b'hello world', shape=(), dtype=string)\n```\n\n\n### 四，TensorFlow2.0的Autograph\n\n\n动态计算图运行效率相对较低。\n\n可以用@tf.function装饰器将普通Python函数转换成和TensorFlow1.0对应的静态计算图构建代码。\n\n在TensorFlow1.0中，使用计算图分两步，第一步定义计算图，第二步在会话中执行计算图。\n\n在TensorFlow2.0中，如果采用Autograph的方式使用计算图，第一步定义计算图变成了定义函数，第二步执行计算图变成了调用函数。\n\n不需要使用会话了，一些都像原始的Python语法一样自然。\n\n实践中，我们一般会先用动态计算图调试代码，然后在需要提高性能的的地方利用@tf.function切换成Autograph获得更高的效率。\n\n当然，@tf.function的使用需要遵循一定的规范，我们后面章节将重点介绍。\n\n\n```python\nimport tensorflow as tf\n\n# 使用autograph构建静态图\n\n@tf.function\ndef strjoin(x,y):\n    z =  tf.strings.join([x,y],separator = \" \")\n    tf.print(z)\n    return z\n\nresult = strjoin(tf.constant(\"hello\"),tf.constant(\"world\"))\n\nprint(result)\n```\n\n```\nhello world\ntf.Tensor(b'hello world', shape=(), dtype=string)\n```\n\n```python\nimport datetime\n\n# 创建日志\nimport os\nstamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\nlogdir = os.path.join('data', 'autograph', stamp)\n\n## 在 Python3 下建议使用 pathlib 修正各操作系统的路径\n# from pathlib import Path\n# stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n# logdir = str(Path('./data/autograph/' + stamp))\n\nwriter = tf.summary.create_file_writer(logdir)\n\n#开启autograph跟踪\ntf.summary.trace_on(graph=True, profiler=True) \n\n#执行autograph\nresult = strjoin(\"hello\",\"world\")\n\n#将计算图信息写入日志\nwith writer.as_default():\n    tf.summary.trace_export(\n        name=\"autograph\",\n        step=0,\n        profiler_outdir=logdir)\n```\n\n```python\n#启动 tensorboard在jupyter中的魔法命令\n%load_ext tensorboard\n```\n\n```python\n#启动tensorboard\n%tensorboard --logdir ./data/autograph/\n```\n\n![](./data/2-2-tensorboard计算图.jpg)\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n"
        },
        {
          "name": "2-3,自动微分机制.md",
          "type": "blob",
          "size": 4.5986328125,
          "content": "# 2-3,自动微分机制\n\n\n神经网络通常依赖反向传播求梯度来更新网络参数，求梯度过程通常是一件非常复杂而容易出错的事情。\n\n而深度学习框架可以帮助我们自动地完成这种求梯度运算。\n\nTensorflow一般使用梯度磁带tf.GradientTape来记录正向运算过程，然后反播磁带自动得到梯度值。\n\n这种利用tf.GradientTape求微分的方法叫做Tensorflow的自动微分机制。\n\n\n### 一，利用梯度磁带求导数\n\n```python\nimport tensorflow as tf\nimport numpy as np \n\n# f(x) = a*x**2 + b*x + c的导数\n\nx = tf.Variable(0.0,name = \"x\",dtype = tf.float32)\na = tf.constant(1.0)\nb = tf.constant(-2.0)\nc = tf.constant(1.0)\n\nwith tf.GradientTape() as tape:\n    y = a*tf.pow(x,2) + b*x + c\n    \ndy_dx = tape.gradient(y,x)\nprint(dy_dx)\n```\n\n```\ntf.Tensor(-2.0, shape=(), dtype=float32)\n```\n\n```python\n\n```\n\n```python\n# 对常量张量也可以求导，需要增加watch\n\nwith tf.GradientTape() as tape:\n    tape.watch([a,b,c])\n    y = a*tf.pow(x,2) + b*x + c\n    \ndy_dx,dy_da,dy_db,dy_dc = tape.gradient(y,[x,a,b,c])\nprint(dy_da)\nprint(dy_dc)\n\n```\n\n```\ntf.Tensor(0.0, shape=(), dtype=float32)\ntf.Tensor(1.0, shape=(), dtype=float32)\n```\n\n```python\n\n```\n\n```python\n# 可以求二阶导数\nwith tf.GradientTape() as tape2:\n    with tf.GradientTape() as tape1:   \n        y = a*tf.pow(x,2) + b*x + c\n    dy_dx = tape1.gradient(y,x)   \ndy2_dx2 = tape2.gradient(dy_dx,x)\n\nprint(dy2_dx2)\n```\n\n```\ntf.Tensor(2.0, shape=(), dtype=float32)\n```\n\n```python\n\n```\n\n```python\n# 可以在autograph中使用\n\n@tf.function\ndef f(x):   \n    a = tf.constant(1.0)\n    b = tf.constant(-2.0)\n    c = tf.constant(1.0)\n    \n    # 自变量转换成tf.float32\n    x = tf.cast(x,tf.float32)\n    with tf.GradientTape() as tape:\n        tape.watch(x)\n        y = a*tf.pow(x,2)+b*x+c\n    dy_dx = tape.gradient(y,x) \n    \n    return((dy_dx,y))\n\ntf.print(f(tf.constant(0.0)))\ntf.print(f(tf.constant(1.0)))\n```\n\n```\n(-2, 1)\n(0, 0)\n```\n\n```python\n\n```\n\n### 二，利用梯度磁带和优化器求最小值\n\n```python\n# 求f(x) = a*x**2 + b*x + c的最小值\n# 使用optimizer.apply_gradients\n\nx = tf.Variable(0.0,name = \"x\",dtype = tf.float32)\na = tf.constant(1.0)\nb = tf.constant(-2.0)\nc = tf.constant(1.0)\n\noptimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\nfor _ in range(1000):\n    with tf.GradientTape() as tape:\n        y = a*tf.pow(x,2) + b*x + c\n    dy_dx = tape.gradient(y,x)\n    optimizer.apply_gradients(grads_and_vars=[(dy_dx,x)])\n    \ntf.print(\"y =\",y,\"; x =\",x)\n```\n\n```\ny = 0 ; x = 0.999998569\n```\n\n```python\n\n```\n\n```python\n# 求f(x) = a*x**2 + b*x + c的最小值\n# 使用optimizer.minimize\n# optimizer.minimize相当于先用tape求gradient,再apply_gradient\n\nx = tf.Variable(0.0,name = \"x\",dtype = tf.float32)\n\n#注意f()无参数\ndef f():   \n    a = tf.constant(1.0)\n    b = tf.constant(-2.0)\n    c = tf.constant(1.0)\n    y = a*tf.pow(x,2)+b*x+c\n    return(y)\n\noptimizer = tf.keras.optimizers.SGD(learning_rate=0.01)   \nfor _ in range(1000):\n    optimizer.minimize(f,[x])   \n    \ntf.print(\"y =\",f(),\"; x =\",x)\n```\n\n```\ny = 0 ; x = 0.999998569\n```\n\n```python\n\n```\n\n```python\n# 在autograph中完成最小值求解\n# 使用optimizer.apply_gradients\n\nx = tf.Variable(0.0,name = \"x\",dtype = tf.float32)\noptimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n\n@tf.function\ndef minimizef():\n    a = tf.constant(1.0)\n    b = tf.constant(-2.0)\n    c = tf.constant(1.0)\n    \n    for _ in tf.range(1000): #注意autograph时使用tf.range(1000)而不是range(1000)\n        with tf.GradientTape() as tape:\n            y = a*tf.pow(x,2) + b*x + c\n        dy_dx = tape.gradient(y,x)\n        optimizer.apply_gradients(grads_and_vars=[(dy_dx,x)])\n        \n    y = a*tf.pow(x,2) + b*x + c\n    return y\n\ntf.print(minimizef())\ntf.print(x)\n```\n\n```\n0\n0.999998569\n```\n\n```python\n\n```\n\n```python\n# 在autograph中完成最小值求解\n# 使用optimizer.minimize\n\nx = tf.Variable(0.0,name = \"x\",dtype = tf.float32)\noptimizer = tf.keras.optimizers.SGD(learning_rate=0.01)   \n\n@tf.function\ndef f():   \n    a = tf.constant(1.0)\n    b = tf.constant(-2.0)\n    c = tf.constant(1.0)\n    y = a*tf.pow(x,2)+b*x+c\n    return(y)\n\n@tf.function\ndef train(epoch):  \n    for _ in tf.range(epoch):  \n        optimizer.minimize(f,[x])\n    return(f())\n\n\ntf.print(train(1000))\ntf.print(x)\n\n```\n\n```\n0\n0.999998569\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n"
        },
        {
          "name": "3-1,低阶API示范.md",
          "type": "blob",
          "size": 13.947265625,
          "content": "# 3-1,低阶API示范\n\n下面的范例使用TensorFlow的低阶API实现线性回归模型和DNN二分类模型。\n\n低阶API主要包括张量操作，计算图和自动微分。\n\n```python\nimport tensorflow as tf\n\n#打印时间分割线\n@tf.function\ndef printbar():\n    today_ts = tf.timestamp()%(24*60*60)\n\n    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\n    minite = tf.cast((today_ts%3600)//60,tf.int32)\n    second = tf.cast(tf.floor(today_ts%60),tf.int32)\n    \n    def timeformat(m):\n        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\n            return(tf.strings.format(\"0{}\",m))\n        else:\n            return(tf.strings.format(\"{}\",m))\n    \n    timestring = tf.strings.join([timeformat(hour),timeformat(minite),\n                timeformat(second)],separator = \":\")\n    tf.print(\"==========\"*8+timestring)\n\n```\n\n```python\n\n```\n\n### 一，线性回归模型\n\n\n**1，准备数据**\n\n```python\nimport numpy as np \nimport pandas as pd\nfrom matplotlib import pyplot as plt \nimport tensorflow as tf\n\n\n#样本数量\nn = 400\n\n# 生成测试用数据集\nX = tf.random.uniform([n,2],minval=-10,maxval=10) \nw0 = tf.constant([[2.0],[-3.0]])\nb0 = tf.constant([[3.0]])\nY = X@w0 + b0 + tf.random.normal([n,1],mean = 0.0,stddev= 2.0)  # @表示矩阵乘法,增加正态扰动\n\n```\n\n```python\n# 数据可视化\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\n\nplt.figure(figsize = (12,5))\nax1 = plt.subplot(121)\nax1.scatter(X[:,0],Y[:,0], c = \"b\")\nplt.xlabel(\"x1\")\nplt.ylabel(\"y\",rotation = 0)\n\nax2 = plt.subplot(122)\nax2.scatter(X[:,1],Y[:,0], c = \"g\")\nplt.xlabel(\"x2\")\nplt.ylabel(\"y\",rotation = 0)\nplt.show()\n\n```\n\n![](./data/3-1-01-回归数据可视化.png)\n\n```python\n# 构建数据管道迭代器\ndef data_iter(features, labels, batch_size=8):\n    num_examples = len(features)\n    indices = list(range(num_examples))\n    np.random.shuffle(indices)  #样本的读取顺序是随机的\n    for i in range(0, num_examples, batch_size):\n        indexs = indices[i: min(i + batch_size, num_examples)]\n        yield tf.gather(features,indexs), tf.gather(labels,indexs)\n        \n# 测试数据管道效果   \nbatch_size = 8\n(features,labels) = next(data_iter(X,Y,batch_size))\nprint(features)\nprint(labels)\n\n```\n\n```\ntf.Tensor(\n[[ 2.6161194   0.11071014]\n [ 9.79207    -0.70180416]\n [ 9.792343    6.9149055 ]\n [-2.4186516  -9.375019  ]\n [ 9.83749    -3.4637213 ]\n [ 7.3953056   4.374569  ]\n [-0.14686584 -0.28063297]\n [ 0.49001217 -9.739792  ]], shape=(8, 2), dtype=float32)\ntf.Tensor(\n[[ 9.334667 ]\n [22.058844 ]\n [ 3.0695205]\n [26.736238 ]\n [35.292133 ]\n [ 4.2943544]\n [ 1.6713585]\n [34.826904 ]], shape=(8, 1), dtype=float32)\n```\n\n\n**2，定义模型**\n\n```python\nw = tf.Variable(tf.random.normal(w0.shape))\nb = tf.Variable(tf.zeros_like(b0,dtype = tf.float32))\n\n# 定义模型\nclass LinearRegression:     \n    #正向传播\n    def __call__(self,x): \n        return x@w + b\n\n    # 损失函数\n    def loss_func(self,y_true,y_pred):  \n        return tf.reduce_mean((y_true - y_pred)**2/2)\n\nmodel = LinearRegression()\n```\n\n```python\n\n```\n\n**3，训练模型**\n\n```python\n# 使用动态图调试\ndef train_step(model, features, labels):\n    with tf.GradientTape() as tape:\n        predictions = model(features)\n        loss = model.loss_func(labels, predictions)\n    # 反向传播求梯度\n    dloss_dw,dloss_db = tape.gradient(loss,[w,b])\n    # 梯度下降法更新参数\n    w.assign(w - 0.001*dloss_dw)\n    b.assign(b - 0.001*dloss_db)\n    \n    return loss\n \n```\n\n```python\n# 测试train_step效果\nbatch_size = 10\n(features,labels) = next(data_iter(X,Y,batch_size))\ntrain_step(model,features,labels)\n\n```\n\n```\n<tf.Tensor: shape=(), dtype=float32, numpy=211.09982>\n```\n\n```python\ndef train_model(model,epochs):\n    for epoch in tf.range(1,epochs+1):\n        for features, labels in data_iter(X,Y,10):\n            loss = train_step(model,features,labels)\n\n        if epoch%50==0:\n            printbar()\n            tf.print(\"epoch =\",epoch,\"loss = \",loss)\n            tf.print(\"w =\",w)\n            tf.print(\"b =\",b)\n\ntrain_model(model,epochs = 200)\n\n```\n\n```\n================================================================================16:35:56\nepoch = 50 loss =  1.78806472\nw = [[1.97554708]\n [-2.97719598]]\nb = [[2.60692883]]\n================================================================================16:36:00\nepoch = 100 loss =  2.64588404\nw = [[1.97319281]\n [-2.97810626]]\nb = [[2.95525956]]\n================================================================================16:36:04\nepoch = 150 loss =  1.42576694\nw = [[1.96466208]\n [-2.98337793]]\nb = [[3.00264144]]\n================================================================================16:36:08\nepoch = 200 loss =  1.68992615\nw = [[1.97718477]\n [-2.983814]]\nb = [[3.01013041]]\n```\n\n```python\n\n```\n\n```python\n##使用autograph机制转换成静态图加速\n\n@tf.function\ndef train_step(model, features, labels):\n    with tf.GradientTape() as tape:\n        predictions = model(features)\n        loss = model.loss_func(labels, predictions)\n    # 反向传播求梯度\n    dloss_dw,dloss_db = tape.gradient(loss,[w,b])\n    # 梯度下降法更新参数\n    w.assign(w - 0.001*dloss_dw)\n    b.assign(b - 0.001*dloss_db)\n    \n    return loss\n\ndef train_model(model,epochs):\n    for epoch in tf.range(1,epochs+1):\n        for features, labels in data_iter(X,Y,10):\n            loss = train_step(model,features,labels)\n        if epoch%50==0:\n            printbar()\n            tf.print(\"epoch =\",epoch,\"loss = \",loss)\n            tf.print(\"w =\",w)\n            tf.print(\"b =\",b)\n\ntrain_model(model,epochs = 200)\n\n```\n\n```\n================================================================================16:36:35\nepoch = 50 loss =  0.894210339\nw = [[1.96927285]\n [-2.98914337]]\nb = [[3.00987792]]\n================================================================================16:36:36\nepoch = 100 loss =  1.58621466\nw = [[1.97566223]\n [-2.98550248]]\nb = [[3.00998402]]\n================================================================================16:36:37\nepoch = 150 loss =  2.2695992\nw = [[1.96664226]\n [-2.99248481]]\nb = [[3.01028705]]\n================================================================================16:36:38\nepoch = 200 loss =  1.90848124\nw = [[1.98000824]\n [-2.98888135]]\nb = [[3.01085401]]\n```\n\n```python\n\n```\n\n```python\n# 结果可视化\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\n\nplt.figure(figsize = (12,5))\nax1 = plt.subplot(121)\nax1.scatter(X[:,0],Y[:,0], c = \"b\",label = \"samples\")\nax1.plot(X[:,0],w[0]*X[:,0]+b[0],\"-r\",linewidth = 5.0,label = \"model\")\nax1.legend()\nplt.xlabel(\"x1\")\nplt.ylabel(\"y\",rotation = 0)\n\n\nax2 = plt.subplot(122)\nax2.scatter(X[:,1],Y[:,0], c = \"g\",label = \"samples\")\nax2.plot(X[:,1],w[1]*X[:,1]+b[0],\"-r\",linewidth = 5.0,label = \"model\")\nax2.legend()\nplt.xlabel(\"x2\")\nplt.ylabel(\"y\",rotation = 0)\n\nplt.show()\n```\n\n![](./data/3-1-2-回归结果可视化.png)\n\n```python\n\n```\n\n### 二，DNN二分类模型\n\n```python\n\n```\n\n**1，准备数据**\n\n```python\nimport numpy as np \nimport pandas as pd \nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\n\n#正负样本数量\nn_positive,n_negative = 2000,2000\n\n#生成正样本, 小圆环分布\nr_p = 5.0 + tf.random.truncated_normal([n_positive,1],0.0,1.0)\ntheta_p = tf.random.uniform([n_positive,1],0.0,2*np.pi) \nXp = tf.concat([r_p*tf.cos(theta_p),r_p*tf.sin(theta_p)],axis = 1)\nYp = tf.ones_like(r_p)\n\n#生成负样本, 大圆环分布\nr_n = 8.0 + tf.random.truncated_normal([n_negative,1],0.0,1.0)\ntheta_n = tf.random.uniform([n_negative,1],0.0,2*np.pi) \nXn = tf.concat([r_n*tf.cos(theta_n),r_n*tf.sin(theta_n)],axis = 1)\nYn = tf.zeros_like(r_n)\n\n#汇总样本\nX = tf.concat([Xp,Xn],axis = 0)\nY = tf.concat([Yp,Yn],axis = 0)\n\n\n#可视化\nplt.figure(figsize = (6,6))\nplt.scatter(Xp[:,0].numpy(),Xp[:,1].numpy(),c = \"r\")\nplt.scatter(Xn[:,0].numpy(),Xn[:,1].numpy(),c = \"g\")\nplt.legend([\"positive\",\"negative\"]);\n\n```\n\n![](./data/3-1-03-分类数据可视化.png)\n\n```python\n# 构建数据管道迭代器\ndef data_iter(features, labels, batch_size=8):\n    num_examples = len(features)\n    indices = list(range(num_examples))\n    np.random.shuffle(indices)  #样本的读取顺序是随机的\n    for i in range(0, num_examples, batch_size):\n        indexs = indices[i: min(i + batch_size, num_examples)]\n        yield tf.gather(features,indexs), tf.gather(labels,indexs)\n        \n# 测试数据管道效果   \nbatch_size = 10\n(features,labels) = next(data_iter(X,Y,batch_size))\nprint(features)\nprint(labels)\n```\n\n```\ntf.Tensor(\n[[ 0.03732629  3.5783494 ]\n [ 0.542919    5.035079  ]\n [ 5.860281   -2.4476354 ]\n [ 0.63657564  3.194231  ]\n [-3.5072308   2.5578873 ]\n [-2.4109735  -3.6621518 ]\n [ 4.0975413  -2.4172943 ]\n [ 1.9393908  -6.782317  ]\n [-4.7453732  -0.5176727 ]\n [-1.4057113  -7.9775257 ]], shape=(10, 2), dtype=float32)\ntf.Tensor(\n[[1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]], shape=(10, 1), dtype=float32)\n```\n\n```python\n\n```\n\n**2，定义模型**\n\n\n此处范例我们利用tf.Module来组织模型变量，关于tf.Module的较详细介绍参考本书第四章最后一节: Autograph和tf.Module。\n\n```python\nclass DNNModel(tf.Module):\n    def __init__(self,name = None):\n        super(DNNModel, self).__init__(name=name)\n        self.w1 = tf.Variable(tf.random.truncated_normal([2,4]),dtype = tf.float32)\n        self.b1 = tf.Variable(tf.zeros([1,4]),dtype = tf.float32)\n        self.w2 = tf.Variable(tf.random.truncated_normal([4,8]),dtype = tf.float32)\n        self.b2 = tf.Variable(tf.zeros([1,8]),dtype = tf.float32)\n        self.w3 = tf.Variable(tf.random.truncated_normal([8,1]),dtype = tf.float32)\n        self.b3 = tf.Variable(tf.zeros([1,1]),dtype = tf.float32)\n\n     \n    # 正向传播\n    @tf.function(input_signature=[tf.TensorSpec(shape = [None,2], dtype = tf.float32)])  \n    def __call__(self,x):\n        x = tf.nn.relu(x@self.w1 + self.b1)\n        x = tf.nn.relu(x@self.w2 + self.b2)\n        y = tf.nn.sigmoid(x@self.w3 + self.b3)\n        return y\n    \n    # 损失函数(二元交叉熵)\n    @tf.function(input_signature=[tf.TensorSpec(shape = [None,1], dtype = tf.float32),\n                              tf.TensorSpec(shape = [None,1], dtype = tf.float32)])  \n    def loss_func(self,y_true,y_pred):  \n        #将预测值限制在 1e-7 以上, 1 - 1e-7 以下，避免log(0)错误\n        eps = 1e-7\n        y_pred = tf.clip_by_value(y_pred,eps,1.0-eps)\n        bce = - y_true*tf.math.log(y_pred) - (1-y_true)*tf.math.log(1-y_pred)\n        return  tf.reduce_mean(bce)\n    \n    # 评估指标(准确率)\n    @tf.function(input_signature=[tf.TensorSpec(shape = [None,1], dtype = tf.float32),\n                              tf.TensorSpec(shape = [None,1], dtype = tf.float32)]) \n    def metric_func(self,y_true,y_pred):\n        y_pred = tf.where(y_pred>0.5,tf.ones_like(y_pred,dtype = tf.float32),\n                          tf.zeros_like(y_pred,dtype = tf.float32))\n        acc = tf.reduce_mean(1-tf.abs(y_true-y_pred))\n        return acc\n    \nmodel = DNNModel()\n```\n\n```python\n# 测试模型结构\nbatch_size = 10\n(features,labels) = next(data_iter(X,Y,batch_size))\n\npredictions = model(features)\n\nloss = model.loss_func(labels,predictions)\nmetric = model.metric_func(labels,predictions)\n\ntf.print(\"init loss:\",loss)\ntf.print(\"init metric\",metric)\n```\n\n```\ninit loss: 1.76568353\ninit metric 0.6\n```\n\n```python\nprint(len(model.trainable_variables))\n```\n\n```\n6\n```\n\n```python\n\n```\n\n**3，训练模型**\n\n```python\n##使用autograph机制转换成静态图加速\n\n@tf.function\ndef train_step(model, features, labels):\n    \n    # 正向传播求损失\n    with tf.GradientTape() as tape:\n        predictions = model(features)\n        loss = model.loss_func(labels, predictions) \n        \n    # 反向传播求梯度\n    grads = tape.gradient(loss, model.trainable_variables)\n    \n    # 执行梯度下降\n    for p, dloss_dp in zip(model.trainable_variables,grads):\n        p.assign(p - 0.001*dloss_dp)\n        \n    # 计算评估指标\n    metric = model.metric_func(labels,predictions)\n    \n    return loss, metric\n\n\ndef train_model(model,epochs):\n    for epoch in tf.range(1,epochs+1):\n        for features, labels in data_iter(X,Y,100):\n            loss,metric = train_step(model,features,labels)\n        if epoch%100==0:\n            printbar()\n            tf.print(\"epoch =\",epoch,\"loss = \",loss, \"accuracy = \", metric)\n        \n\ntrain_model(model,epochs = 600)\n```\n\n```\n================================================================================16:47:35\nepoch = 100 loss =  0.567795336 accuracy =  0.71\n================================================================================16:47:39\nepoch = 200 loss =  0.50955683 accuracy =  0.77\n================================================================================16:47:43\nepoch = 300 loss =  0.421476126 accuracy =  0.84\n================================================================================16:47:47\nepoch = 400 loss =  0.330618203 accuracy =  0.9\n================================================================================16:47:51\nepoch = 500 loss =  0.308296859 accuracy =  0.89\n================================================================================16:47:55\nepoch = 600 loss =  0.279367268 accuracy =  0.96\n```\n\n```python\n\n```\n\n```python\n# 结果可视化\nfig, (ax1,ax2) = plt.subplots(nrows=1,ncols=2,figsize = (12,5))\nax1.scatter(Xp[:,0],Xp[:,1],c = \"r\")\nax1.scatter(Xn[:,0],Xn[:,1],c = \"g\")\nax1.legend([\"positive\",\"negative\"]);\nax1.set_title(\"y_true\");\n\nXp_pred = tf.boolean_mask(X,tf.squeeze(model(X)>=0.5),axis = 0)\nXn_pred = tf.boolean_mask(X,tf.squeeze(model(X)<0.5),axis = 0)\n\nax2.scatter(Xp_pred[:,0],Xp_pred[:,1],c = \"r\")\nax2.scatter(Xn_pred[:,0],Xn_pred[:,1],c = \"g\")\nax2.legend([\"positive\",\"negative\"]);\nax2.set_title(\"y_pred\");\n\n```\n\n![](./data/3-1-04-分类结果可视化.png)\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n"
        },
        {
          "name": "3-2,中阶API示范.md",
          "type": "blob",
          "size": 9.875,
          "content": "# 3-2,中阶API示范\n\n下面的范例使用TensorFlow的中阶API实现线性回归模型和和DNN二分类模型。\n\nTensorFlow的中阶API主要包括各种模型层，损失函数，优化器，数据管道，特征列等等。\n\n```python\nimport tensorflow as tf\n\n#打印时间分割线\n@tf.function\ndef printbar():\n    today_ts = tf.timestamp()%(24*60*60)\n\n    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\n    minite = tf.cast((today_ts%3600)//60,tf.int32)\n    second = tf.cast(tf.floor(today_ts%60),tf.int32)\n    \n    def timeformat(m):\n        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\n            return(tf.strings.format(\"0{}\",m))\n        else:\n            return(tf.strings.format(\"{}\",m))\n    \n    timestring = tf.strings.join([timeformat(hour),timeformat(minite),\n                timeformat(second)],separator = \":\")\n    tf.print(\"==========\"*8+timestring)\n\n    \n```\n\n```python\n\n```\n\n### 一，线性回归模型\n\n\n**1，准备数据**\n\n```python\nimport numpy as np \nimport pandas as pd\nfrom matplotlib import pyplot as plt \nimport tensorflow as tf\nfrom tensorflow.keras import layers,losses,metrics,optimizers\n\n#样本数量\nn = 400\n\n# 生成测试用数据集\nX = tf.random.uniform([n,2],minval=-10,maxval=10) \nw0 = tf.constant([[2.0],[-3.0]])\nb0 = tf.constant([[3.0]])\nY = X@w0 + b0 + tf.random.normal([n,1],mean = 0.0,stddev= 2.0)  # @表示矩阵乘法,增加正态扰动\n\n```\n\n```python\n# 数据可视化\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\nplt.figure(figsize = (12,5))\nax1 = plt.subplot(121)\nax1.scatter(X[:,0],Y[:,0], c = \"b\")\nplt.xlabel(\"x1\")\nplt.ylabel(\"y\",rotation = 0)\n\nax2 = plt.subplot(122)\nax2.scatter(X[:,1],Y[:,0], c = \"g\")\nplt.xlabel(\"x2\")\nplt.ylabel(\"y\",rotation = 0)\nplt.show()\n\n```\n\n![](./data/3-2-01-回归数据可视化.png)\n\n```python\n#构建输入数据管道\nds = tf.data.Dataset.from_tensor_slices((X,Y)) \\\n     .shuffle(buffer_size = 100).batch(10) \\\n     .prefetch(tf.data.experimental.AUTOTUNE)  \n```\n\n```python\n\n```\n\n**2，定义模型**\n\n```python\nmodel = layers.Dense(units = 1) \nmodel.build(input_shape = (2,)) #用build方法创建variables\nmodel.loss_func = losses.mean_squared_error\nmodel.optimizer = optimizers.SGD(learning_rate=0.001)\n```\n\n```python\n\n```\n\n**3，训练模型**\n\n```python\n#使用autograph机制转换成静态图加速\n\n@tf.function\ndef train_step(model, features, labels):\n    with tf.GradientTape() as tape:\n        predictions = model(features)\n        loss = model.loss_func(tf.reshape(labels,[-1]), tf.reshape(predictions,[-1]))\n    grads = tape.gradient(loss,model.variables)\n    model.optimizer.apply_gradients(zip(grads,model.variables))\n    return loss\n\n# 测试train_step效果\nfeatures,labels = next(ds.as_numpy_iterator())\ntrain_step(model,features,labels)\n\n```\n\n```python\ndef train_model(model,epochs):\n    for epoch in tf.range(1,epochs+1):\n        loss = tf.constant(0.0)\n        for features, labels in ds:\n            loss = train_step(model,features,labels)\n        if epoch%50==0:\n            printbar()\n            tf.print(\"epoch =\",epoch,\"loss = \",loss)\n            tf.print(\"w =\",model.variables[0])\n            tf.print(\"b =\",model.variables[1])\ntrain_model(model,epochs = 200)\n\n```\n\n```\n================================================================================17:01:48\nepoch = 50 loss =  2.56481647\nw = [[1.99355531]\n [-2.99061537]]\nb = [3.09484935]\n================================================================================17:01:51\nepoch = 100 loss =  5.96198225\nw = [[1.98028314]\n [-2.96975136]]\nb = [3.09501529]\n================================================================================17:01:54\nepoch = 150 loss =  4.79625702\nw = [[2.00056171]\n [-2.98774862]]\nb = [3.09567738]\n================================================================================17:01:58\nepoch = 200 loss =  8.26704407\nw = [[2.00282311]\n [-2.99300027]]\nb = [3.09406662]\n```\n\n```python\n\n```\n\n```python\n# 结果可视化\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\n\nw,b = model.variables\n\nplt.figure(figsize = (12,5))\nax1 = plt.subplot(121)\nax1.scatter(X[:,0],Y[:,0], c = \"b\",label = \"samples\")\nax1.plot(X[:,0],w[0]*X[:,0]+b[0],\"-r\",linewidth = 5.0,label = \"model\")\nax1.legend()\nplt.xlabel(\"x1\")\nplt.ylabel(\"y\",rotation = 0)\n\n\n\nax2 = plt.subplot(122)\nax2.scatter(X[:,1],Y[:,0], c = \"g\",label = \"samples\")\nax2.plot(X[:,1],w[1]*X[:,1]+b[0],\"-r\",linewidth = 5.0,label = \"model\")\nax2.legend()\nplt.xlabel(\"x2\")\nplt.ylabel(\"y\",rotation = 0)\n\nplt.show()\n\n```\n\n![](./data/3-2-02-回归结果可视化.png)\n\n```python\n\n```\n\n### 二， DNN二分类模型\n\n```python\n\n```\n\n**1，准备数据**\n\n```python\nimport numpy as np \nimport pandas as pd \nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras import layers,losses,metrics,optimizers\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\n\n#正负样本数量\nn_positive,n_negative = 2000,2000\n\n#生成正样本, 小圆环分布\nr_p = 5.0 + tf.random.truncated_normal([n_positive,1],0.0,1.0)\ntheta_p = tf.random.uniform([n_positive,1],0.0,2*np.pi) \nXp = tf.concat([r_p*tf.cos(theta_p),r_p*tf.sin(theta_p)],axis = 1)\nYp = tf.ones_like(r_p)\n\n#生成负样本, 大圆环分布\nr_n = 8.0 + tf.random.truncated_normal([n_negative,1],0.0,1.0)\ntheta_n = tf.random.uniform([n_negative,1],0.0,2*np.pi) \nXn = tf.concat([r_n*tf.cos(theta_n),r_n*tf.sin(theta_n)],axis = 1)\nYn = tf.zeros_like(r_n)\n\n#汇总样本\nX = tf.concat([Xp,Xn],axis = 0)\nY = tf.concat([Yp,Yn],axis = 0)\n\n\n#可视化\nplt.figure(figsize = (6,6))\nplt.scatter(Xp[:,0].numpy(),Xp[:,1].numpy(),c = \"r\")\nplt.scatter(Xn[:,0].numpy(),Xn[:,1].numpy(),c = \"g\")\nplt.legend([\"positive\",\"negative\"]);\n\n```\n\n![](./data/3-1-03-分类数据可视化.png)\n\n```python\n#构建输入数据管道\nds = tf.data.Dataset.from_tensor_slices((X,Y)) \\\n     .shuffle(buffer_size = 4000).batch(100) \\\n     .prefetch(tf.data.experimental.AUTOTUNE) \n```\n\n```python\n\n```\n\n**2, 定义模型**\n\n```python\n\n```\n\n```python\nclass DNNModel(tf.Module):\n    def __init__(self,name = None):\n        super(DNNModel, self).__init__(name=name)\n        self.dense1 = layers.Dense(4,activation = \"relu\") \n        self.dense2 = layers.Dense(8,activation = \"relu\")\n        self.dense3 = layers.Dense(1,activation = \"sigmoid\")\n\n     \n    # 正向传播\n    @tf.function(input_signature=[tf.TensorSpec(shape = [None,2], dtype = tf.float32)])  \n    def __call__(self,x):\n        x = self.dense1(x)\n        x = self.dense2(x)\n        y = self.dense3(x)\n        return y\n    \nmodel = DNNModel()\nmodel.loss_func = losses.binary_crossentropy\nmodel.metric_func = metrics.binary_accuracy\nmodel.optimizer = optimizers.Adam(learning_rate=0.001)\n\n```\n\n```python\n# 测试模型结构\n(features,labels) = next(ds.as_numpy_iterator())\n\npredictions = model(features)\n\nloss = model.loss_func(tf.reshape(labels,[-1]),tf.reshape(predictions,[-1]))\nmetric = model.metric_func(tf.reshape(labels,[-1]),tf.reshape(predictions,[-1]))\n\ntf.print(\"init loss:\",loss)\ntf.print(\"init metric\",metric)\n\n```\n\n```\ninit loss: 1.13653195\ninit metric 0.5\n```\n\n```python\n\n```\n\n**3，训练模型**\n\n```python\n#使用autograph机制转换成静态图加速\n\n@tf.function\ndef train_step(model, features, labels):\n    with tf.GradientTape() as tape:\n        predictions = model(features)\n        loss = model.loss_func(tf.reshape(labels,[-1]), tf.reshape(predictions,[-1]))\n    grads = tape.gradient(loss,model.trainable_variables)\n    model.optimizer.apply_gradients(zip(grads,model.trainable_variables))\n    \n    metric = model.metric_func(tf.reshape(labels,[-1]), tf.reshape(predictions,[-1]))\n    \n    return loss,metric\n\n# 测试train_step效果\nfeatures,labels = next(ds.as_numpy_iterator())\ntrain_step(model,features,labels)\n```\n\n```\n(<tf.Tensor: shape=(), dtype=float32, numpy=1.2033114>,\n <tf.Tensor: shape=(), dtype=float32, numpy=0.47>)\n```\n\n```python\n\n```\n\n```python\ndef train_model(model,epochs):\n    for epoch in tf.range(1,epochs+1):\n        loss, metric = tf.constant(0.0),tf.constant(0.0)\n        for features, labels in ds:\n            loss,metric = train_step(model,features,labels)\n        if epoch%10==0:\n            printbar()\n            tf.print(\"epoch =\",epoch,\"loss = \",loss, \"accuracy = \",metric)\ntrain_model(model,epochs = 60)\n\n```\n\n```\n================================================================================17:07:36\nepoch = 10 loss =  0.556449413 accuracy =  0.79\n================================================================================17:07:38\nepoch = 20 loss =  0.439187407 accuracy =  0.86\n================================================================================17:07:40\nepoch = 30 loss =  0.259921253 accuracy =  0.95\n================================================================================17:07:42\nepoch = 40 loss =  0.244920313 accuracy =  0.9\n================================================================================17:07:43\nepoch = 50 loss =  0.19839409 accuracy =  0.92\n================================================================================17:07:45\nepoch = 60 loss =  0.126151696 accuracy =  0.95\n```\n\n```python\n\n```\n\n```python\n# 结果可视化\nfig, (ax1,ax2) = plt.subplots(nrows=1,ncols=2,figsize = (12,5))\nax1.scatter(Xp[:,0].numpy(),Xp[:,1].numpy(),c = \"r\")\nax1.scatter(Xn[:,0].numpy(),Xn[:,1].numpy(),c = \"g\")\nax1.legend([\"positive\",\"negative\"]);\nax1.set_title(\"y_true\");\n\nXp_pred = tf.boolean_mask(X,tf.squeeze(model(X)>=0.5),axis = 0)\nXn_pred = tf.boolean_mask(X,tf.squeeze(model(X)<0.5),axis = 0)\n\nax2.scatter(Xp_pred[:,0].numpy(),Xp_pred[:,1].numpy(),c = \"r\")\nax2.scatter(Xn_pred[:,0].numpy(),Xn_pred[:,1].numpy(),c = \"g\")\nax2.legend([\"positive\",\"negative\"]);\nax2.set_title(\"y_pred\");\n\n\n```\n\n![](./data/3-2-04-分类结果可视化.png)\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n"
        },
        {
          "name": "3-3,高阶API示范.md",
          "type": "blob",
          "size": 11.83984375,
          "content": "# 3-3,高阶API示范\n\n下面的范例使用TensorFlow的高阶API实现线性回归模型和DNN二分类模型。\n\nTensorFlow的高阶API主要为tf.keras.models提供的模型的类接口。\n\n\n使用Keras接口有以下3种方式构建模型：使用Sequential按层顺序构建模型，使用函数式API构建任意结构模型，继承Model基类构建自定义模型。\n\n此处分别演示使用Sequential按层顺序构建模型以及继承Model基类构建自定义模型。\n\n```python\nimport tensorflow as tf\n\n#打印时间分割线\n@tf.function\ndef printbar():\n    today_ts = tf.timestamp()%(24*60*60)\n\n    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\n    minite = tf.cast((today_ts%3600)//60,tf.int32)\n    second = tf.cast(tf.floor(today_ts%60),tf.int32)\n    \n    def timeformat(m):\n        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\n            return(tf.strings.format(\"0{}\",m))\n        else:\n            return(tf.strings.format(\"{}\",m))\n    \n    timestring = tf.strings.join([timeformat(hour),timeformat(minite),\n                timeformat(second)],separator = \":\")\n    tf.print(\"==========\"*8+timestring)\n\n    \n```\n\n### 一，线性回归模型\n\n\n此范例我们使用Sequential按层顺序构建模型，并使用内置model.fit方法训练模型【面向新手】。\n\n\n**1，准备数据**\n\n```python\nimport numpy as np \nimport pandas as pd\nfrom matplotlib import pyplot as plt \nimport tensorflow as tf\nfrom tensorflow.keras import models,layers,losses,metrics,optimizers\n\n#样本数量\nn = 400\n\n# 生成测试用数据集\nX = tf.random.uniform([n,2],minval=-10,maxval=10) \nw0 = tf.constant([[2.0],[-3.0]])\nb0 = tf.constant([[3.0]])\nY = X@w0 + b0 + tf.random.normal([n,1],mean = 0.0,stddev= 2.0)  # @表示矩阵乘法,增加正态扰动\n\n```\n\n```python\n# 数据可视化\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\nplt.figure(figsize = (12,5))\nax1 = plt.subplot(121)\nax1.scatter(X[:,0],Y[:,0], c = \"b\")\nplt.xlabel(\"x1\")\nplt.ylabel(\"y\",rotation = 0)\n\nax2 = plt.subplot(122)\nax2.scatter(X[:,1],Y[:,0], c = \"g\")\nplt.xlabel(\"x2\")\nplt.ylabel(\"y\",rotation = 0)\nplt.show()\n\n```\n\n![](./data/3-3-01-回归数据可视化.png)\n\n```python\n\n```\n\n**2，定义模型**\n\n```python\ntf.keras.backend.clear_session()\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(1,input_shape =(2,)))\nmodel.summary()\n```\n\n```\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 1)                 3         \n=================================================================\nTotal params: 3\nTrainable params: 3\nNon-trainable params: 0\n```\n\n```python\n\n```\n\n**3，训练模型**\n\n```python\n### 使用fit方法进行训练\n\nmodel.compile(optimizer=\"adam\",loss=\"mse\",metrics=[\"mae\"])\nmodel.fit(X,Y,batch_size = 10,epochs = 200)  \n\ntf.print(\"w = \",model.layers[0].kernel)\ntf.print(\"b = \",model.layers[0].bias)\n\n```\n\n```\nEpoch 197/200\n400/400 [==============================] - 0s 190us/sample - loss: 4.3977 - mae: 1.7129\nEpoch 198/200\n400/400 [==============================] - 0s 172us/sample - loss: 4.3918 - mae: 1.7117\nEpoch 199/200\n400/400 [==============================] - 0s 134us/sample - loss: 4.3861 - mae: 1.7106\nEpoch 200/200\n400/400 [==============================] - 0s 166us/sample - loss: 4.3786 - mae: 1.7092\nw =  [[1.99339032]\n [-3.00866461]]\nb =  [2.67018795]\n```\n\n```python\n# 结果可视化\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\n\nw,b = model.variables\n\nplt.figure(figsize = (12,5))\nax1 = plt.subplot(121)\nax1.scatter(X[:,0],Y[:,0], c = \"b\",label = \"samples\")\nax1.plot(X[:,0],w[0]*X[:,0]+b[0],\"-r\",linewidth = 5.0,label = \"model\")\nax1.legend()\nplt.xlabel(\"x1\")\nplt.ylabel(\"y\",rotation = 0)\n\nax2 = plt.subplot(122)\nax2.scatter(X[:,1],Y[:,0], c = \"g\",label = \"samples\")\nax2.plot(X[:,1],w[1]*X[:,1]+b[0],\"-r\",linewidth = 5.0,label = \"model\")\nax2.legend()\nplt.xlabel(\"x2\")\nplt.ylabel(\"y\",rotation = 0)\n\nplt.show()\n```\n\n![](./data/3-3-02-回归结果可视化.png)\n\n```python\n\n```\n\n### 二，DNN二分类模型\n\n\n此范例我们使用继承Model基类构建自定义模型，并构建自定义训练循环【面向专家】\n\n\n**1，准备数据**\n\n```python\nimport numpy as np \nimport pandas as pd \nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras import layers,losses,metrics,optimizers\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\n\n#正负样本数量\nn_positive,n_negative = 2000,2000\n\n#生成正样本, 小圆环分布\nr_p = 5.0 + tf.random.truncated_normal([n_positive,1],0.0,1.0)\ntheta_p = tf.random.uniform([n_positive,1],0.0,2*np.pi) \nXp = tf.concat([r_p*tf.cos(theta_p),r_p*tf.sin(theta_p)],axis = 1)\nYp = tf.ones_like(r_p)\n\n#生成负样本, 大圆环分布\nr_n = 8.0 + tf.random.truncated_normal([n_negative,1],0.0,1.0)\ntheta_n = tf.random.uniform([n_negative,1],0.0,2*np.pi) \nXn = tf.concat([r_n*tf.cos(theta_n),r_n*tf.sin(theta_n)],axis = 1)\nYn = tf.zeros_like(r_n)\n\n#汇总样本\nX = tf.concat([Xp,Xn],axis = 0)\nY = tf.concat([Yp,Yn],axis = 0)\n\n#样本洗牌\ndata = tf.concat([X,Y],axis = 1)\ndata = tf.random.shuffle(data)\nX = data[:,:2]\nY = data[:,2:]\n\n\n#可视化\nplt.figure(figsize = (6,6))\nplt.scatter(Xp[:,0].numpy(),Xp[:,1].numpy(),c = \"r\")\nplt.scatter(Xn[:,0].numpy(),Xn[:,1].numpy(),c = \"g\")\nplt.legend([\"positive\",\"negative\"]);\n\n```\n\n![](./data/3-3-03-分类数据可视化.png)\n\n```python\nds_train = tf.data.Dataset.from_tensor_slices((X[0:n*3//4,:],Y[0:n*3//4,:])) \\\n     .shuffle(buffer_size = 1000).batch(20) \\\n     .prefetch(tf.data.experimental.AUTOTUNE) \\\n     .cache()\n\nds_valid = tf.data.Dataset.from_tensor_slices((X[n*3//4:,:],Y[n*3//4:,:])) \\\n     .batch(20) \\\n     .prefetch(tf.data.experimental.AUTOTUNE) \\\n     .cache()\n\n```\n\n```python\n\n```\n\n**2，定义模型**\n\n```python\ntf.keras.backend.clear_session()\nclass DNNModel(models.Model):\n    def __init__(self):\n        super(DNNModel, self).__init__()\n        \n    def build(self,input_shape):\n        self.dense1 = layers.Dense(4,activation = \"relu\",name = \"dense1\") \n        self.dense2 = layers.Dense(8,activation = \"relu\",name = \"dense2\")\n        self.dense3 = layers.Dense(1,activation = \"sigmoid\",name = \"dense3\")\n        super(DNNModel,self).build(input_shape)\n \n    # 正向传播\n    @tf.function(input_signature=[tf.TensorSpec(shape = [None,2], dtype = tf.float32)])  \n    def call(self,x):\n        x = self.dense1(x)\n        x = self.dense2(x)\n        y = self.dense3(x)\n        return y\n\nmodel = DNNModel()\nmodel.build(input_shape =(None,2))\n\nmodel.summary()\n```\n\n```\nModel: \"dnn_model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense1 (Dense)               multiple                  12        \n_________________________________________________________________\ndense2 (Dense)               multiple                  40        \n_________________________________________________________________\ndense3 (Dense)               multiple                  9         \n=================================================================\nTotal params: 61\nTrainable params: 61\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n```python\n\n```\n\n**3，训练模型**\n\n```python\n\n```\n\n```python\n### 自定义训练循环\n\noptimizer = optimizers.Adam(learning_rate=0.01)\nloss_func = tf.keras.losses.BinaryCrossentropy()\n\ntrain_loss = tf.keras.metrics.Mean(name='train_loss')\ntrain_metric = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n\nvalid_loss = tf.keras.metrics.Mean(name='valid_loss')\nvalid_metric = tf.keras.metrics.BinaryAccuracy(name='valid_accuracy')\n\n\n@tf.function\ndef train_step(model, features, labels):\n    with tf.GradientTape() as tape:\n        predictions = model(features)\n        loss = loss_func(labels, predictions)\n    grads = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n\n    train_loss.update_state(loss)\n    train_metric.update_state(labels, predictions)\n\n@tf.function\ndef valid_step(model, features, labels):\n    predictions = model(features)\n    batch_loss = loss_func(labels, predictions)\n    valid_loss.update_state(batch_loss)\n    valid_metric.update_state(labels, predictions)\n    \n\ndef train_model(model,ds_train,ds_valid,epochs):\n    for epoch in tf.range(1,epochs+1):\n        for features, labels in ds_train:\n            train_step(model,features,labels)\n\n        for features, labels in ds_valid:\n            valid_step(model,features,labels)\n\n        logs = 'Epoch={},Loss:{},Accuracy:{},Valid Loss:{},Valid Accuracy:{}'\n        \n        if  epoch%100 ==0:\n            printbar()\n            tf.print(tf.strings.format(logs,\n            (epoch,train_loss.result(),train_metric.result(),valid_loss.result(),valid_metric.result())))\n        \n        train_loss.reset_states()\n        valid_loss.reset_states()\n        train_metric.reset_states()\n        valid_metric.reset_states()\n\ntrain_model(model,ds_train,ds_valid,1000)\n```\n\n```\n================================================================================17:35:02\nEpoch=100,Loss:0.194088802,Accuracy:0.923064,Valid Loss:0.215538561,Valid Accuracy:0.904368\n================================================================================17:35:22\nEpoch=200,Loss:0.151239693,Accuracy:0.93768847,Valid Loss:0.181166962,Valid Accuracy:0.920664132\n================================================================================17:35:43\nEpoch=300,Loss:0.134556711,Accuracy:0.944247484,Valid Loss:0.171530813,Valid Accuracy:0.926396072\n================================================================================17:36:04\nEpoch=400,Loss:0.125722557,Accuracy:0.949172914,Valid Loss:0.16731061,Valid Accuracy:0.929318547\n================================================================================17:36:24\nEpoch=500,Loss:0.120216407,Accuracy:0.952525079,Valid Loss:0.164817035,Valid Accuracy:0.931044817\n================================================================================17:36:44\nEpoch=600,Loss:0.116434008,Accuracy:0.954830289,Valid Loss:0.163089141,Valid Accuracy:0.932202339\n================================================================================17:37:05\nEpoch=700,Loss:0.113658346,Accuracy:0.956433,Valid Loss:0.161804497,Valid Accuracy:0.933092058\n================================================================================17:37:25\nEpoch=800,Loss:0.111522928,Accuracy:0.957467675,Valid Loss:0.160796657,Valid Accuracy:0.93379426\n================================================================================17:37:46\nEpoch=900,Loss:0.109816991,Accuracy:0.958205402,Valid Loss:0.159987748,Valid Accuracy:0.934343576\n================================================================================17:38:06\nEpoch=1000,Loss:0.10841465,Accuracy:0.958805501,Valid Loss:0.159325734,Valid Accuracy:0.934785843\n```\n\n```python\n\n```\n\n```python\n# 结果可视化\nfig, (ax1,ax2) = plt.subplots(nrows=1,ncols=2,figsize = (12,5))\nax1.scatter(Xp[:,0].numpy(),Xp[:,1].numpy(),c = \"r\")\nax1.scatter(Xn[:,0].numpy(),Xn[:,1].numpy(),c = \"g\")\nax1.legend([\"positive\",\"negative\"]);\nax1.set_title(\"y_true\");\n\nXp_pred = tf.boolean_mask(X,tf.squeeze(model(X)>=0.5),axis = 0)\nXn_pred = tf.boolean_mask(X,tf.squeeze(model(X)<0.5),axis = 0)\n\nax2.scatter(Xp_pred[:,0].numpy(),Xp_pred[:,1].numpy(),c = \"r\")\nax2.scatter(Xn_pred[:,0].numpy(),Xn_pred[:,1].numpy(),c = \"g\")\nax2.legend([\"positive\",\"negative\"]);\nax2.set_title(\"y_pred\");\n```\n\n![](./data/3-3-04-分类结果可视化.png)\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n"
        },
        {
          "name": "4-1,张量的结构操作.md",
          "type": "blob",
          "size": 14.8759765625,
          "content": "# 4-1,张量的结构操作\n\n张量的操作主要包括张量的结构操作和张量的数学运算。\n\n张量结构操作诸如：张量创建，索引切片，维度变换，合并分割。\n\n张量数学运算主要有：标量运算，向量运算，矩阵运算。另外我们会介绍张量运算的广播机制。\n\n本篇我们介绍张量的结构操作。\n\n\n### 一，创建张量\n\n\n张量创建的许多方法和numpy中创建array的方法很像。\n\n```python\nimport tensorflow as tf\nimport numpy as np \n```\n\n```python\na = tf.constant([1,2,3],dtype = tf.float32)\ntf.print(a)\n```\n\n```\n[1 2 3]\n```\n\n```python\nb = tf.range(1,10,delta = 2)\ntf.print(b)\n```\n\n```\n[1 3 5 7 9]\n```\n\n```python\nc = tf.linspace(0.0,2*3.14,100)\ntf.print(c)\n```\n\n```\n[0 0.0634343475 0.126868695 ... 6.15313148 6.21656609 6.28]\n```\n\n```python\nd = tf.zeros([3,3])\ntf.print(d)\n```\n\n```\n[[0 0 0]\n [0 0 0]\n [0 0 0]]\n```\n\n```python\na = tf.ones([3,3])\nb = tf.zeros_like(a,dtype= tf.float32)\ntf.print(a)\ntf.print(b)\n```\n\n```\n[[1 1 1]\n [1 1 1]\n [1 1 1]]\n[[0 0 0]\n [0 0 0]\n [0 0 0]]\n```\n\n```python\nb = tf.fill([3,2],5)\ntf.print(b)\n```\n\n```\n[[5 5]\n [5 5]\n [5 5]]\n```\n\n```python\n#均匀分布随机\ntf.random.set_seed(1.0)\na = tf.random.uniform([5],minval=0,maxval=10)\ntf.print(a)\n```\n\n```\n[1.65130854 9.01481247 6.30974197 4.34546089 2.9193902]\n```\n\n```python\n#正态分布随机\nb = tf.random.normal([3,3],mean=0.0,stddev=1.0)\ntf.print(b)\n```\n\n```\n[[0.403087884 -1.0880208 -0.0630953535]\n [1.33655667 0.711760104 -0.489286453]\n [-0.764221311 -1.03724861 -1.25193381]]\n```\n\n```python\n#正态分布随机，剔除2倍方差以外数据重新生成\nc = tf.random.truncated_normal((5,5), mean=0.0, stddev=1.0, dtype=tf.float32)\ntf.print(c)\n```\n\n```\n[[-0.457012236 -0.406867266 0.728577733 -0.892977774 -0.369404584]\n [0.323488563 1.19383323 0.888299048 1.25985599 -1.95951891]\n [-0.202244401 0.294496894 -0.468728036 1.29494202 1.48142183]\n [0.0810953453 1.63843894 0.556645 0.977199793 -1.17777884]\n [1.67368948 0.0647980496 -0.705142677 -0.281972528 0.126546144]]\n```\n\n```python\n# 特殊矩阵\nI = tf.eye(3,3) #单位矩阵\ntf.print(I)\ntf.print(\" \")\nt = tf.linalg.diag([1,2,3]) #对角阵\ntf.print(t)\n```\n\n```\n[[1 0 0]\n [0 1 0]\n [0 0 1]]\n \n[[1 0 0]\n [0 2 0]\n [0 0 3]]\n```\n\n```python\n\n```\n\n### 二 ，索引切片\n\n\n张量的索引切片方式和numpy几乎是一样的。切片时支持缺省参数和省略号。\n\n对于tf.Variable,可以通过索引和切片对部分元素进行修改。\n\n对于提取张量的连续子区域，也可以使用tf.slice.\n\n此外，对于不规则的切片提取,可以使用tf.gather,tf.gather_nd,tf.boolean_mask。\n\ntf.boolean_mask功能最为强大，它可以实现tf.gather,tf.gather_nd的功能，并且tf.boolean_mask还可以实现布尔索引。\n\n如果要通过修改张量的某些元素得到新的张量，可以使用tf.where，tf.scatter_nd。\n\n```python\ntf.random.set_seed(3)\nt = tf.random.uniform([5,5],minval=0,maxval=10,dtype=tf.int32)\ntf.print(t)\n```\n\n```\n[[4 7 4 2 9]\n [9 1 2 4 7]\n [7 2 7 4 0]\n [9 6 9 7 2]\n [3 7 0 0 3]]\n```\n\n```python\n#第0行\ntf.print(t[0])\n```\n\n```\n[4 7 4 2 9]\n```\n\n```python\n#倒数第一行\ntf.print(t[-1])\n```\n\n```\n[3 7 0 0 3]\n```\n\n```python\n#第1行第3列\ntf.print(t[1,3])\ntf.print(t[1][3])\n```\n\n```\n4\n4\n```\n\n```python\n#第1行至第3行\ntf.print(t[1:4,:])\ntf.print(tf.slice(t,[1,0],[3,5])) #tf.slice(input,begin_vector,size_vector)\n```\n\n```\n[[9 1 2 4 7]\n [7 2 7 4 0]\n [9 6 9 7 2]]\n[[9 1 2 4 7]\n [7 2 7 4 0]\n [9 6 9 7 2]]\n```\n\n```python\n#第1行至最后一行，第0列到最后一列每隔两列取一列\ntf.print(t[1:4,:4:2])\n```\n\n```\n[[9 2]\n [7 7]\n [9 9]]\n```\n\n```python\n#对变量来说，还可以使用索引和切片修改部分元素\nx = tf.Variable([[1,2],[3,4]],dtype = tf.float32)\nx[1,:].assign(tf.constant([0.0,0.0]))\ntf.print(x)\n```\n\n```\n[[1 2]\n [0 0]]\n```\n\n```python\na = tf.random.uniform([3,3,3],minval=0,maxval=10,dtype=tf.int32)\ntf.print(a)\n```\n\n```\n[[[7 3 9]\n  [9 0 7]\n  [9 6 7]]\n\n [[1 3 3]\n  [0 8 1]\n  [3 1 0]]\n\n [[4 0 6]\n  [6 2 2]\n  [7 9 5]]]\n```\n\n```python\n#省略号可以表示多个冒号\ntf.print(a[...,1])\n```\n\n```\n[[3 0 6]\n [3 8 1]\n [0 2 9]]\n```\n\n\n以上切片方式相对规则，对于不规则的切片提取,可以使用tf.gather,tf.gather_nd,tf.boolean_mask。\n\n考虑班级成绩册的例子，有4个班级，每个班级10个学生，每个学生7门科目成绩。可以用一个4×10×7的张量来表示。\n\n```python\nscores = tf.random.uniform((4,10,7),minval=0,maxval=100,dtype=tf.int32)\ntf.print(scores)\n```\n\n```\n[[[52 82 66 ... 17 86 14]\n  [8 36 94 ... 13 78 41]\n  [77 53 51 ... 22 91 56]\n  ...\n  [11 19 26 ... 89 86 68]\n  [60 72 0 ... 11 26 15]\n  [24 99 38 ... 97 44 74]]\n\n [[79 73 73 ... 35 3 81]\n  [83 36 31 ... 75 38 85]\n  [54 26 67 ... 60 68 98]\n  ...\n  [20 5 18 ... 32 45 3]\n  [72 52 81 ... 88 41 20]\n  [0 21 89 ... 53 10 90]]\n\n [[52 80 22 ... 29 25 60]\n  [78 71 54 ... 43 98 81]\n  [21 66 53 ... 97 75 77]\n  ...\n  [6 74 3 ... 53 65 43]\n  [98 36 72 ... 33 36 81]\n  [61 78 70 ... 7 59 21]]\n\n [[56 57 45 ... 23 15 3]\n  [35 8 82 ... 11 59 97]\n  [44 6 99 ... 81 60 27]\n  ...\n  [76 26 35 ... 51 8 17]\n  [33 52 53 ... 78 37 31]\n  [71 27 44 ... 0 52 16]]]\n```\n\n```python\n#抽取每个班级第0个学生，第5个学生，第9个学生的全部成绩\np = tf.gather(scores,[0,5,9],axis=1)\ntf.print(p)\n```\n\n```\n[[[52 82 66 ... 17 86 14]\n  [24 80 70 ... 72 63 96]\n  [24 99 38 ... 97 44 74]]\n\n [[79 73 73 ... 35 3 81]\n  [46 10 94 ... 23 18 92]\n  [0 21 89 ... 53 10 90]]\n\n [[52 80 22 ... 29 25 60]\n  [19 12 23 ... 87 86 25]\n  [61 78 70 ... 7 59 21]]\n\n [[56 57 45 ... 23 15 3]\n  [6 41 79 ... 97 43 13]\n  [71 27 44 ... 0 52 16]]]\n```\n\n```python\n#抽取每个班级第0个学生，第5个学生，第9个学生的第1门课程，第3门课程，第6门课程成绩\nq = tf.gather(tf.gather(scores,[0,5,9],axis=1),[1,3,6],axis=2)\ntf.print(q)\n```\n\n```\n[[[82 55 14]\n  [80 46 96]\n  [99 58 74]]\n\n [[73 48 81]\n  [10 38 92]\n  [21 86 90]]\n\n [[80 57 60]\n  [12 34 25]\n  [78 71 21]]\n\n [[57 75 3]\n  [41 47 13]\n  [27 96 16]]]\n```\n\n```python\n# 抽取第0个班级第0个学生，第2个班级的第4个学生，第3个班级的第6个学生的全部成绩\n#indices的长度为采样样本的个数，每个元素为采样位置的坐标\ns = tf.gather_nd(scores,indices = [(0,0),(2,4),(3,6)])\ns\n```\n\n```\n<tf.Tensor: shape=(3, 7), dtype=int32, numpy=\narray([[52, 82, 66, 55, 17, 86, 14],\n       [99, 94, 46, 70,  1, 63, 41],\n       [46, 83, 70, 80, 90, 85, 17]], dtype=int32)>\n```\n\n\n以上tf.gather和tf.gather_nd的功能也可以用tf.boolean_mask来实现。\n\n```python\n#抽取每个班级第0个学生，第5个学生，第9个学生的全部成绩\np = tf.boolean_mask(scores,[True,False,False,False,False,\n                            True,False,False,False,True],axis=1)\ntf.print(p)\n```\n\n```\n[[[52 82 66 ... 17 86 14]\n  [24 80 70 ... 72 63 96]\n  [24 99 38 ... 97 44 74]]\n\n [[79 73 73 ... 35 3 81]\n  [46 10 94 ... 23 18 92]\n  [0 21 89 ... 53 10 90]]\n\n [[52 80 22 ... 29 25 60]\n  [19 12 23 ... 87 86 25]\n  [61 78 70 ... 7 59 21]]\n\n [[56 57 45 ... 23 15 3]\n  [6 41 79 ... 97 43 13]\n  [71 27 44 ... 0 52 16]]]\n```\n\n```python\n#抽取第0个班级第0个学生，第2个班级的第4个学生，第3个班级的第6个学生的全部成绩\ns = tf.boolean_mask(scores,\n    [[True,False,False,False,False,False,False,False,False,False],\n     [False,False,False,False,False,False,False,False,False,False],\n     [False,False,False,False,True,False,False,False,False,False],\n     [False,False,False,False,False,False,True,False,False,False]])\ntf.print(s)\n```\n\n```\n[[52 82 66 ... 17 86 14]\n [99 94 46 ... 1 63 41]\n [46 83 70 ... 90 85 17]]\n```\n\n```python\n#利用tf.boolean_mask可以实现布尔索引\n\n#找到矩阵中小于0的元素\nc = tf.constant([[-1,1,-1],[2,2,-2],[3,-3,3]],dtype=tf.float32)\ntf.print(c,\"\\n\")\n\ntf.print(tf.boolean_mask(c,c<0),\"\\n\") \ntf.print(c[c<0]) #布尔索引，为boolean_mask的语法糖形式\n```\n\n```\n[[-1 1 -1]\n [2 2 -2]\n [3 -3 3]] \n\n[-1 -1 -2 -3] \n\n[-1 -1 -2 -3]\n```\n\n```python\n\n```\n\n以上这些方法仅能提取张量的部分元素值，但不能更改张量的部分元素值得到新的张量。\n\n如果要通过修改张量的部分元素值得到新的张量，可以使用tf.where和tf.scatter_nd。\n\ntf.where可以理解为if的张量版本，此外它还可以用于找到满足条件的所有元素的位置坐标。\n\ntf.scatter_nd的作用和tf.gather_nd有些相反，tf.gather_nd用于收集张量的给定位置的元素，\n\n而tf.scatter_nd可以将某些值插入到一个给定shape的全0的张量的指定位置处。\n\n```python\n#找到张量中小于0的元素,将其换成np.nan得到新的张量\n#tf.where和np.where作用类似，可以理解为if的张量版本\n\nc = tf.constant([[-1,1,-1],[2,2,-2],[3,-3,3]],dtype=tf.float32)\nd = tf.where(c<0,tf.fill(c.shape,np.nan),c) \nd\n```\n\n```\n<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\narray([[nan,  1., nan],\n       [ 2.,  2., nan],\n       [ 3., nan,  3.]], dtype=float32)>\n```\n\n```python\n\n```\n\n```python\n#如果where只有一个参数，将返回所有满足条件的位置坐标\nindices = tf.where(c<0)\nindices\n```\n\n```\n<tf.Tensor: shape=(4, 2), dtype=int64, numpy=\narray([[0, 0],\n       [0, 2],\n       [1, 2],\n       [2, 1]])>\n```\n\n```python\n#将张量的第[0,0]和[2,1]两个位置元素替换为0得到新的张量\nd = c - tf.scatter_nd([[0,0],[2,1]],[c[0,0],c[2,1]],c.shape)\nd\n```\n\n```\n<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\narray([[ 0.,  1., -1.],\n       [ 2.,  2., -2.],\n       [ 3.,  0.,  3.]], dtype=float32)>\n\n```\n\n```python\n#scatter_nd的作用和gather_nd有些相反\n#可以将某些值插入到一个给定shape的全0的张量的指定位置处。\nindices = tf.where(c<0)\ntf.scatter_nd(indices,tf.gather_nd(c,indices),c.shape)\n```\n\n```\n<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\narray([[-1.,  0., -1.],\n       [ 0.,  0., -2.],\n       [ 0., -3.,  0.]], dtype=float32)>\n```\n\n```python\n\n```\n\n### 三，维度变换\n\n\n维度变换相关函数主要有 tf.reshape, tf.squeeze, tf.expand_dims, tf.transpose.\n\ntf.reshape 可以改变张量的形状。\n\ntf.squeeze 可以减少维度。\n\ntf.expand_dims 可以增加维度。\n\ntf.transpose 可以交换维度。\n\n\n\ntf.reshape可以改变张量的形状，但是其本质上不会改变张量元素的存储顺序，所以，该操作实际上非常迅速，并且是可逆的。\n\n```python\na = tf.random.uniform(shape=[1,3,3,2],\n                      minval=0,maxval=255,dtype=tf.int32)\ntf.print(a.shape)\ntf.print(a)\n```\n\n```\nTensorShape([1, 3, 3, 2])\n[[[[135 178]\n   [26 116]\n   [29 224]]\n\n  [[179 219]\n   [153 209]\n   [111 215]]\n\n  [[39 7]\n   [138 129]\n   [59 205]]]]\n```\n\n```python\n# 改成 （3,6）形状的张量\nb = tf.reshape(a,[3,6])\ntf.print(b.shape)\ntf.print(b)\n```\n\n```\nTensorShape([3, 6])\n[[135 178 26 116 29 224]\n [179 219 153 209 111 215]\n [39 7 138 129 59 205]]\n```\n\n\n\n\n```python\n# 改回成 [1,3,3,2] 形状的张量\nc = tf.reshape(b,[1,3,3,2])\ntf.print(c)\n```\n\n```\n[[[[135 178]\n   [26 116]\n   [29 224]]\n\n  [[179 219]\n   [153 209]\n   [111 215]]\n\n  [[39 7]\n   [138 129]\n   [59 205]]]]\n```\n\n```python\n\n```\n\n如果张量在某个维度上只有一个元素，利用tf.squeeze可以消除这个维度。\n\n和tf.reshape相似，它本质上不会改变张量元素的存储顺序。\n\n张量的各个元素在内存中是线性存储的，其一般规律是，同一层级中的相邻元素的物理地址也相邻。\n\n```python\ns = tf.squeeze(a)\ntf.print(s.shape)\ntf.print(s)\n```\n\n```\nTensorShape([3, 3, 2])\n[[[135 178]\n  [26 116]\n  [29 224]]\n\n [[179 219]\n  [153 209]\n  [111 215]]\n\n [[39 7]\n  [138 129]\n  [59 205]]]\n```\n\n```python\nd = tf.expand_dims(s,axis=0) #在第0维插入长度为1的一个维度\nd\n```\n\n```\n<tf.Tensor: shape=(1, 3, 3, 2), dtype=int32, numpy=\narray([[[[135, 178],\n         [ 26, 116],\n         [ 29, 224]],\n\n        [[179, 219],\n         [153, 209],\n         [111, 215]],\n\n        [[ 39,   7],\n         [138, 129],\n         [ 59, 205]]]], dtype=int32)>\n```\n\n\ntf.transpose可以交换张量的维度，与tf.reshape不同，它会改变张量元素的存储顺序。\n\ntf.transpose常用于图片存储格式的变换上。\n\n```python\n# Batch,Height,Width,Channel\na = tf.random.uniform(shape=[100,600,600,4],minval=0,maxval=255,dtype=tf.int32)\ntf.print(a.shape)\n\n# 转换成 Channel,Height,Width,Batch\ns= tf.transpose(a,perm=[3,1,2,0])\ntf.print(s.shape)\n```\n\n```\nTensorShape([100, 600, 600, 4])\nTensorShape([4, 600, 600, 100])\n\n```\n\n```python\n\n```\n\n### 四，合并分割\n\n\n和numpy类似，可以用tf.concat和tf.stack方法对多个张量进行合并，可以用tf.split方法把一个张量分割成多个张量。\n\ntf.concat和tf.stack有略微的区别，tf.concat是连接，不会增加维度，而tf.stack是堆叠，会增加维度。\n\n```python\na = tf.constant([[1.0,2.0],[3.0,4.0]])\nb = tf.constant([[5.0,6.0],[7.0,8.0]])\nc = tf.constant([[9.0,10.0],[11.0,12.0]])\n\ntf.concat([a,b,c],axis = 0)\n```\n\n```\n<tf.Tensor: shape=(6, 2), dtype=float32, numpy=\narray([[ 1.,  2.],\n       [ 3.,  4.],\n       [ 5.,  6.],\n       [ 7.,  8.],\n       [ 9., 10.],\n       [11., 12.]], dtype=float32)>\n```\n\n```python\ntf.concat([a,b,c],axis = 1)\n```\n\n```\n<tf.Tensor: shape=(2, 6), dtype=float32, numpy=\narray([[ 1.,  2.,  5.,  6.,  9., 10.],\n       [ 3.,  4.,  7.,  8., 11., 12.]], dtype=float32)>\n```\n\n```python\ntf.stack([a,b,c])\n```\n\n```\n<tf.Tensor: shape=(3, 2, 2), dtype=float32, numpy=\narray([[[ 1.,  2.],\n        [ 3.,  4.]],\n\n       [[ 5.,  6.],\n        [ 7.,  8.]],\n\n       [[ 9., 10.],\n        [11., 12.]]], dtype=float32)>\n```\n\n```python\ntf.stack([a,b,c],axis=1)\n```\n\n```\n<tf.Tensor: shape=(2, 3, 2), dtype=float32, numpy=\narray([[[ 1.,  2.],\n        [ 5.,  6.],\n        [ 9., 10.]],\n\n       [[ 3.,  4.],\n        [ 7.,  8.],\n        [11., 12.]]], dtype=float32)>\n```\n\n```python\na = tf.constant([[1.0,2.0],[3.0,4.0]])\nb = tf.constant([[5.0,6.0],[7.0,8.0]])\nc = tf.constant([[9.0,10.0],[11.0,12.0]])\n\nc = tf.concat([a,b,c],axis = 0)\n```\n\ntf.split是tf.concat的逆运算，可以指定分割份数平均分割，也可以通过指定每份的记录数量进行分割。\n\n```python\n#tf.split(value,num_or_size_splits,axis)\ntf.split(c,3,axis = 0)  #指定分割份数，平均分割\n```\n\n```\n[<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n array([[1., 2.],\n        [3., 4.]], dtype=float32)>,\n <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n array([[5., 6.],\n        [7., 8.]], dtype=float32)>,\n <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n array([[ 9., 10.],\n        [11., 12.]], dtype=float32)>]\n```\n\n```python\ntf.split(c,[2,2,2],axis = 0) #指定每份的记录数量\n```\n\n```\n[<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n array([[1., 2.],\n        [3., 4.]], dtype=float32)>,\n <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n array([[5., 6.],\n        [7., 8.]], dtype=float32)>,\n <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n array([[ 9., 10.],\n        [11., 12.]], dtype=float32)>]\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n"
        },
        {
          "name": "4-2,张量的数学运算.md",
          "type": "blob",
          "size": 10.068359375,
          "content": "# 4-2,张量的数学运算\n\n张量的操作主要包括张量的结构操作和张量的数学运算。\n\n张量结构操作诸如：张量创建，索引切片，维度变换，合并分割。\n\n张量数学运算主要有：标量运算，向量运算，矩阵运算。另外我们会介绍张量运算的广播机制。\n\n本篇我们介绍张量的数学运算。\n\n```python\n\n```\n\n### 一，标量运算\n\n\n张量的数学运算符可以分为标量运算符、向量运算符、以及矩阵运算符。\n\n加减乘除乘方，以及三角函数，指数，对数等常见函数，逻辑比较运算符等都是标量运算符。\n\n标量运算符的特点是对张量实施逐元素运算。\n\n有些标量运算符对常用的数学运算符进行了重载。并且支持类似numpy的广播特性。\n\n许多标量运算符都在 tf.math模块下。\n\n```python\nimport tensorflow as tf \nimport numpy as np \n```\n\n```python\na = tf.constant([[1.0,2],[-3,4.0]])\nb = tf.constant([[5.0,6],[7.0,8.0]])\na+b  #运算符重载\n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[ 6.,  8.],\n       [ 4., 12.]], dtype=float32)>\n```\n\n```python\na-b \n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[ -4.,  -4.],\n       [-10.,  -4.]], dtype=float32)>\n```\n\n```python\na*b \n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[  5.,  12.],\n       [-21.,  32.]], dtype=float32)>\n```\n\n```python\na/b\n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[ 0.2       ,  0.33333334],\n       [-0.42857143,  0.5       ]], dtype=float32)>\n```\n\n```python\na**2\n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[ 1.,  4.],\n       [ 9., 16.]], dtype=float32)>\n```\n\n```python\na**(0.5)\n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[1.       , 1.4142135],\n       [      nan, 2.       ]], dtype=float32)>\n```\n\n```python\na%3 #mod的运算符重载，等价于m = tf.math.mod(a,3)\n```\n\n```\n<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 0], dtype=int32)>\n```\n\n```python\na//3  #地板除法\n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[ 0.,  0.],\n       [-1.,  1.]], dtype=float32)>\n```\n\n```python\n(a>=2)\n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=bool, numpy=\narray([[False,  True],\n       [False,  True]])>\n```\n\n```python\n(a>=2)&(a<=3)\n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=bool, numpy=\narray([[False,  True],\n       [False, False]])>\n```\n\n```python\n(a>=2)|(a<=3)\n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=bool, numpy=\narray([[ True,  True],\n       [ True,  True]])>\n```\n\n```python\na==5 #tf.equal(a,5)\n```\n\n```\n<tf.Tensor: shape=(3,), dtype=bool, numpy=array([False, False, False])>\n```\n\n```python\ntf.sqrt(a)\n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[1.       , 1.4142135],\n       [      nan, 2.       ]], dtype=float32)>\n```\n\n```python\na = tf.constant([1.0,8.0])\nb = tf.constant([5.0,6.0])\nc = tf.constant([6.0,7.0])\ntf.add_n([a,b,c])\n```\n\n```\n<tf.Tensor: shape=(2,), dtype=float32, numpy=array([12., 21.], dtype=float32)>\n```\n\n```python\ntf.print(tf.maximum(a,b))\n```\n\n```\n[5 8]\n```\n\n```python\ntf.print(tf.minimum(a,b))\n```\n\n```\n[1 6]\n```\n\n```python\nx = tf.constant([2.6,-2.7])\n\ntf.print(tf.math.round(x)) #保留整数部分，四舍五入\ntf.print(tf.math.floor(x)) #保留整数部分，向下归整\ntf.print(tf.math.ceil(x))  #保留整数部分，向上归整\n\n```\n\n```\n[3 -3]\n[2 -3]\n[3 -2]\n```\n\n```python\n\n```\n\n```python\n# 幅值裁剪\nx = tf.constant([0.9,-0.8,100.0,-20.0,0.7])\ny = tf.clip_by_value(x,clip_value_min=-1,clip_value_max=1)\nz = tf.clip_by_norm(x,clip_norm = 3)\ntf.print(y)\ntf.print(z)\n```\n\n```\n[0.9 -0.8 1 -1 0.7]\n[0.0264732055 -0.0235317405 2.94146752 -0.588293493 0.0205902718]\n```\n\n```python\n\n```\n\n```python\n\n```\n\n### 二，向量运算\n\n\n向量运算符只在一个特定轴上运算，将一个向量映射到一个标量或者另外一个向量。\n许多向量运算符都以reduce开头。\n\n```python\n#向量reduce\na = tf.range(1,10)\ntf.print(tf.reduce_sum(a))\ntf.print(tf.reduce_mean(a))\ntf.print(tf.reduce_max(a))\ntf.print(tf.reduce_min(a))\ntf.print(tf.reduce_prod(a))\n\n```\n\n```\n45\n5\n9\n1\n362880\n```\n\n```python\n#张量指定维度进行reduce\nb = tf.reshape(a,(3,3))\ntf.print(tf.reduce_sum(b, axis=1, keepdims=True))\ntf.print(tf.reduce_sum(b, axis=0, keepdims=True))\n```\n\n```\n[[6]\n [15]\n [24]]\n[[12 15 18]]\n```\n\n```python\n#bool类型的reduce\np = tf.constant([True,False,False])\nq = tf.constant([False,False,True])\ntf.print(tf.reduce_all(p))\ntf.print(tf.reduce_any(q))\n```\n\n```\n0\n1\n```\n\n```python\n#利用tf.foldr实现tf.reduce_sum\ns = tf.foldr(lambda a,b:a+b,tf.range(10)) \ntf.print(s)\n```\n\n```\n45\n```\n\n```python\n#cum扫描累积\na = tf.range(1,10)\ntf.print(tf.math.cumsum(a))\ntf.print(tf.math.cumprod(a))\n```\n\n```\n[1 3 6 ... 28 36 45]\n[1 2 6 ... 5040 40320 362880]\n```\n\n```python\n#arg最大最小值索引\na = tf.range(1,10)\ntf.print(tf.argmax(a))\ntf.print(tf.argmin(a))\n```\n\n```\n8\n0\n```\n\n```python\n#tf.math.top_k可以用于对张量排序\na = tf.constant([1,3,7,5,4,8])\n\nvalues,indices = tf.math.top_k(a,3,sorted=True)\ntf.print(values)\ntf.print(indices)\n\n#利用tf.math.top_k可以在TensorFlow中实现KNN算法\n```\n\n```\n[8 7 5]\n[5 2 3]\n```\n\n```python\n\n```\n\n```python\n\n```\n\n### 三，矩阵运算\n\n\n矩阵必须是二维的。类似tf.constant([1,2,3])这样的不是矩阵。\n\n矩阵运算包括：矩阵乘法，矩阵转置，矩阵逆，矩阵求迹，矩阵范数，矩阵行列式，矩阵求特征值，矩阵分解等运算。\n\n除了一些常用的运算外，大部分和矩阵有关的运算都在tf.linalg子包中。\n\n```python\n#矩阵乘法\na = tf.constant([[1,2],[3,4]])\nb = tf.constant([[2,0],[0,2]])\na@b  #等价于tf.matmul(a,b)\n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[2, 4],\n       [6, 8]], dtype=int32)>\n```\n\n```python\n#矩阵转置\na = tf.constant([[1,2],[3,4]])\ntf.transpose(a)\n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[1, 3],\n       [2, 4]], dtype=int32)>\n```\n\n```python\n#矩阵逆，必须为tf.float32或tf.double类型\na = tf.constant([[1.0,2],[3,4]],dtype = tf.float32)\ntf.linalg.inv(a)\n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[-2.0000002 ,  1.0000001 ],\n       [ 1.5000001 , -0.50000006]], dtype=float32)>\n```\n\n```python\n#矩阵求trace\na = tf.constant([[1.0,2],[3,4]],dtype = tf.float32)\ntf.linalg.trace(a)\n```\n\n```\n<tf.Tensor: shape=(), dtype=float32, numpy=5.0>\n```\n\n```python\n#矩阵求范数\na = tf.constant([[1.0,2],[3,4]])\ntf.linalg.norm(a)\n```\n\n```\n<tf.Tensor: shape=(), dtype=float32, numpy=5.477226>\n```\n\n```python\n#矩阵行列式\na = tf.constant([[1.0,2],[3,4]])\ntf.linalg.det(a)\n```\n\n```\n<tf.Tensor: shape=(), dtype=float32, numpy=-2.0>\n```\n\n```python\n#矩阵特征值\na = tf.constant([[1.0,2],[-5,4]])\ntf.linalg.eigvals(a)\n```\n\n```\n<tf.Tensor: shape=(2,), dtype=complex64, numpy=array([2.4999995+2.7838817j, 2.5      -2.783882j ], dtype=complex64)>\n```\n\n```python\n#矩阵QR分解, 将一个方阵分解为一个正交矩阵q和上三角矩阵r\n#QR分解实际上是对矩阵a实施Schmidt正交化得到q\n\na = tf.constant([[1.0,2.0],[3.0,4.0]],dtype = tf.float32)\nq,r = tf.linalg.qr(a)\ntf.print(q)\ntf.print(r)\ntf.print(q@r)\n```\n\n```\n[[-0.316227794 -0.948683321]\n [-0.948683321 0.316227734]]\n[[-3.1622777 -4.4271884]\n [0 -0.632455349]]\n[[1.00000012 1.99999976]\n [3 4]]\n```\n\n```python\n#矩阵svd分解\n#svd分解可以将任意一个矩阵分解为一个正交矩阵u,一个对角阵s和一个正交矩阵v.t()的乘积\n#svd常用于矩阵压缩和降维\n\na  = tf.constant([[1.0,2.0],[3.0,4.0],[5.0,6.0]], dtype = tf.float32)\ns,u,v = tf.linalg.svd(a)\ntf.print(u,\"\\n\")\ntf.print(s,\"\\n\")\ntf.print(v,\"\\n\")\ntf.print(u@tf.linalg.diag(s)@tf.transpose(v))\n\n#利用svd分解可以在TensorFlow中实现主成分分析降维\n\n```\n\n```\n[[0.229847744 -0.88346082]\n [0.524744868 -0.240782902]\n [0.819642067 0.401896209]] \n\n[9.52551842 0.51429987] \n\n[[0.619629562 0.784894466]\n [0.784894466 -0.619629562]] \n\n[[1.00000119 2]\n [3.00000095 4.00000048]\n [5.00000143 6.00000095]]\n```\n\n```python\n\n```\n\n```python\n\n```\n\n### 四，广播机制\n\n\nTensorFlow的广播规则和numpy是一样的:\n\n* 1、如果张量的维度不同，将维度较小的张量进行扩展，直到两个张量的维度都一样。\n* 2、如果两个张量在某个维度上的长度是相同的，或者其中一个张量在该维度上的长度为1，那么我们就说这两个张量在该维度上是相容的。\n* 3、如果两个张量在所有维度上都是相容的，它们就能使用广播。\n* 4、广播之后，每个维度的长度将取两个张量在该维度长度的较大值。\n* 5、在任何一个维度上，如果一个张量的长度为1，另一个张量长度大于1，那么在该维度上，就好像是对第一个张量进行了复制。\n\ntf.broadcast_to 以显式的方式按照广播机制扩展张量的维度。\n\n```python\na = tf.constant([1,2,3])\nb = tf.constant([[0,0,0],[1,1,1],[2,2,2]])\nb + a  #等价于 b + tf.broadcast_to(a,b.shape)\n```\n\n```\n<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\narray([[1, 2, 3],\n       [2, 3, 4],\n       [3, 4, 5]], dtype=int32)>\n```\n\n```python\ntf.broadcast_to(a,b.shape)\n```\n\n```\n<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\narray([[1, 2, 3],\n       [1, 2, 3],\n       [1, 2, 3]], dtype=int32)>\n```\n\n```python\n#计算广播后计算结果的形状，静态形状，TensorShape类型参数\ntf.broadcast_static_shape(a.shape,b.shape)\n```\n\n```\nTensorShape([3, 3])\n```\n\n```python\n#计算广播后计算结果的形状，动态形状，Tensor类型参数\nc = tf.constant([1,2,3])\nd = tf.constant([[1],[2],[3]])\ntf.broadcast_dynamic_shape(tf.shape(c),tf.shape(d))\n```\n\n```\n<tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 3], dtype=int32)>\n```\n\n```python\n#广播效果\nc+d #等价于 tf.broadcast_to(c,[3,3]) + tf.broadcast_to(d,[3,3])\n```\n\n```\n<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\narray([[2, 3, 4],\n       [3, 4, 5],\n       [4, 5, 6]], dtype=int32)>\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n\n```python\n\n```\n"
        },
        {
          "name": "4-3,AutoGraph的使用规范.md",
          "type": "blob",
          "size": 4.611328125,
          "content": "# 4-3,AutoGraph的使用规范\n\n有三种计算图的构建方式：静态计算图，动态计算图，以及Autograph。\n\nTensorFlow 2.0主要使用的是动态计算图和Autograph。\n\n动态计算图易于调试，编码效率较高，但执行效率偏低。\n\n静态计算图执行效率很高，但较难调试。\n\n而Autograph机制可以将动态图转换成静态计算图，兼收执行效率和编码效率之利。\n\n当然Autograph机制能够转换的代码并不是没有任何约束的，有一些编码规范需要遵循，否则可能会转换失败或者不符合预期。\n\n我们将着重介绍Autograph的编码规范和Autograph转换成静态图的原理。\n\n并介绍使用tf.Module来更好地构建Autograph。\n\n本篇我们介绍使用Autograph的编码规范。\n\n<!-- #region -->\n### 一，Autograph编码规范总结\n\n\n* 1，被@tf.function修饰的函数应尽可能使用TensorFlow中的函数而不是Python中的其他函数。例如使用tf.print而不是print，使用tf.range而不是range，使用tf.constant(True)而不是True.\n\n* 2，避免在@tf.function修饰的函数内部定义tf.Variable. \n\n* 3，被@tf.function修饰的函数不可修改该函数外部的Python列表或字典等数据结构变量。\n\n<!-- #endregion -->\n```python\n\n```\n\n### 二，Autograph编码规范解析\n\n\n **1，被@tf.function修饰的函数应尽量使用TensorFlow中的函数而不是Python中的其他函数。**\n\n```python\nimport numpy as np\nimport tensorflow as tf\n\n@tf.function\ndef np_random():\n    a = np.random.randn(3,3)\n    tf.print(a)\n    \n@tf.function\ndef tf_random():\n    a = tf.random.normal((3,3))\n    tf.print(a)\n```\n\n```python\n#np_random每次执行都是一样的结果。\nnp_random()\nnp_random()\n```\n\n```\narray([[ 0.22619201, -0.4550123 , -0.42587565],\n       [ 0.05429906,  0.2312667 , -1.44819738],\n       [ 0.36571796,  1.45578986, -1.05348983]])\narray([[ 0.22619201, -0.4550123 , -0.42587565],\n       [ 0.05429906,  0.2312667 , -1.44819738],\n       [ 0.36571796,  1.45578986, -1.05348983]])\n```\n\n```python\n#tf_random每次执行都会有重新生成随机数。\ntf_random()\ntf_random()\n```\n\n```\n[[-1.38956189 -0.394843668 0.420657277]\n [2.87235498 -1.33740318 -0.533843279]\n [0.918233037 0.118598573 -0.399486482]]\n[[-0.858178258 1.67509317 0.511889517]\n [-0.545829177 -2.20118237 -0.968222201]\n [0.733958483 -0.61904633 0.77440238]]\n```\n\n```python\n\n```\n\n**2，避免在@tf.function修饰的函数内部定义tf.Variable.**\n\n```python\n# 避免在@tf.function修饰的函数内部定义tf.Variable.\n\nx = tf.Variable(1.0,dtype=tf.float32)\n@tf.function\ndef outer_var():\n    x.assign_add(1.0)\n    tf.print(x)\n    return(x)\n\nouter_var() \nouter_var()\n\n```\n\n```python\n@tf.function\ndef inner_var():\n    x = tf.Variable(1.0,dtype = tf.float32)\n    x.assign_add(1.0)\n    tf.print(x)\n    return(x)\n\n#执行将报错\n#inner_var()\n#inner_var()\n\n```\n\n```\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-12-c95a7c3c1ddd> in <module>\n      7 \n      8 #执行将报错\n----> 9 inner_var()\n     10 inner_var()\n\n~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)\n    566         xla_context.Exit()\n    567     else:\n--> 568       result = self._call(*args, **kwds)\n    569 \n    570     if tracing_count == self._get_tracing_count():\n......\nValueError: tf.function-decorated function tried to create variables on non-first call.\n```\n\n\n**3,被@tf.function修饰的函数不可修改该函数外部的Python列表或字典等结构类型变量。**\n\n```python\ntensor_list = []\n\n#@tf.function #加上这一行切换成Autograph结果将不符合预期！！！\ndef append_tensor(x):\n    tensor_list.append(x)\n    return tensor_list\n\nappend_tensor(tf.constant(5.0))\nappend_tensor(tf.constant(6.0))\nprint(tensor_list)\n\n```\n\n```\n[<tf.Tensor: shape=(), dtype=float32, numpy=5.0>, <tf.Tensor: shape=(), dtype=float32, numpy=6.0>]\n```\n\n```python\ntensor_list = []\n\n@tf.function #加上这一行切换成Autograph结果将不符合预期！！！\ndef append_tensor(x):\n    tensor_list.append(x)\n    return tensor_list\n\n\nappend_tensor(tf.constant(5.0))\nappend_tensor(tf.constant(6.0))\nprint(tensor_list)\n\n```\n\n```\n[<tf.Tensor 'x:0' shape=() dtype=float32>]\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n"
        },
        {
          "name": "4-4,AutoGraph的机制原理.md",
          "type": "blob",
          "size": 6.359375,
          "content": "# 4-4,AutoGraph的机制原理\n\n有三种计算图的构建方式：静态计算图，动态计算图，以及Autograph。\n\nTensorFlow 2.0主要使用的是动态计算图和Autograph。\n\n动态计算图易于调试，编码效率较高，但执行效率偏低。\n\n静态计算图执行效率很高，但较难调试。\n\n而Autograph机制可以将动态图转换成静态计算图，兼收执行效率和编码效率之利。\n\n当然Autograph机制能够转换的代码并不是没有任何约束的，有一些编码规范需要遵循，否则可能会转换失败或者不符合预期。\n\n我们会介绍Autograph的编码规范和Autograph转换成静态图的原理。\n\n并介绍使用tf.Module来更好地构建Autograph。\n\n上篇我们介绍了Autograph的编码规范，本篇我们介绍Autograph的机制原理。\n\n\n\n### 一，Autograph的机制原理\n\n\n**当我们使用@tf.function装饰一个函数的时候，后面到底发生了什么呢？**\n\n例如我们写下如下代码。\n\n```python\nimport tensorflow as tf\nimport numpy as np \n\n@tf.function(autograph=True)\ndef myadd(a,b):\n    for i in tf.range(3):\n        tf.print(i)\n    c = a+b\n    print(\"tracing\")\n    return c\n```\n\n后面什么都没有发生。仅仅是在Python堆栈中记录了这样一个函数的签名。\n\n**当我们第一次调用这个被@tf.function装饰的函数时，后面到底发生了什么？**\n\n例如我们写下如下代码。\n\n```python\nmyadd(tf.constant(\"hello\"),tf.constant(\"world\"))\n```\n\n```\ntracing\n0\n1\n2\n```\n\n<!-- #region -->\n发生了2件事情，\n\n第一件事情是创建计算图。\n\n即创建一个静态计算图，跟踪执行一遍函数体中的Python代码，确定各个变量的Tensor类型，并根据执行顺序将算子添加到计算图中。\n在这个过程中，如果开启了autograph=True(默认开启),会将Python控制流转换成TensorFlow图内控制流。\n主要是将if语句转换成 tf.cond算子表达，将while和for循环语句转换成tf.while_loop算子表达，并在必要的时候添加\ntf.control_dependencies指定执行顺序依赖关系。\n\n相当于在 tensorflow1.0执行了类似下面的语句：\n\n```python\ng = tf.Graph()\nwith g.as_default():\n    a = tf.placeholder(shape=[],dtype=tf.string)\n    b = tf.placeholder(shape=[],dtype=tf.string)\n    cond = lambda i: i<tf.constant(3)\n    def body(i):\n        tf.print(i)\n        return(i+1)\n    loop = tf.while_loop(cond,body,loop_vars=[0])\n    loop\n    with tf.control_dependencies(loop):\n        c = tf.strings.join([a,b])\n    print(\"tracing\")\n```\n\n第二件事情是执行计算图。\n\n相当于在 tensorflow1.0中执行了下面的语句：\n\n```python\nwith tf.Session(graph=g) as sess:\n    sess.run(c,feed_dict={a:tf.constant(\"hello\"),b:tf.constant(\"world\")})\n```\n\n因此我们先看到的是第一个步骤的结果：即Python调用标准输出流打印\"tracing\"语句。\n\n然后看到第二个步骤的结果：TensorFlow调用标准输出流打印1,2,3。\n\n<!-- #endregion -->\n\n**当我们再次用相同的输入参数类型调用这个被@tf.function装饰的函数时，后面到底发生了什么？**\n\n例如我们写下如下代码。\n\n```python\nmyadd(tf.constant(\"good\"),tf.constant(\"morning\"))\n```\n\n```\n0\n1\n2\n```\n\n\n只会发生一件事情，那就是上面步骤的第二步，执行计算图。\n\n所以这一次我们没有看到打印\"tracing\"的结果。\n\n\n**当我们再次用不同的的输入参数类型调用这个被@tf.function装饰的函数时，后面到底发生了什么？**\n\n例如我们写下如下代码。\n\n```python\nmyadd(tf.constant(1),tf.constant(2))\n```\n\n```\ntracing\n0\n1\n2\n```\n\n\n由于输入参数的类型已经发生变化，已经创建的计算图不能够再次使用。\n\n需要重新做2件事情：创建新的计算图、执行计算图。\n\n所以我们又会先看到的是第一个步骤的结果：即Python调用标准输出流打印\"tracing\"语句。\n\n然后再看到第二个步骤的结果：TensorFlow调用标准输出流打印1,2,3。\n\n\n**需要注意的是，如果调用被@tf.function装饰的函数时输入的参数不是Tensor类型，则每次都会重新创建计算图。**\n\n例如我们写下如下代码。两次都会重新创建计算图。因此，一般建议调用@tf.function时应传入Tensor类型。\n\n```python\nmyadd(\"hello\",\"world\")\nmyadd(\"good\",\"morning\")\n```\n\n```\ntracing\n0\n1\n2\ntracing\n0\n1\n2\n```\n\n```python\n\n```\n\n```python\n\n```\n\n### 二，重新理解Autograph的编码规范\n\n\n了解了以上Autograph的机制原理，我们也就能够理解Autograph编码规范的3条建议了。\n\n1，被@tf.function修饰的函数应尽量使用TensorFlow中的函数而不是Python中的其他函数。例如使用tf.print而不是print.\n\n解释：Python中的函数仅仅会在跟踪执行函数以创建静态图的阶段使用，普通Python函数是无法嵌入到静态计算图中的，所以\n在计算图构建好之后再次调用的时候，这些Python函数并没有被计算，而TensorFlow中的函数则可以嵌入到计算图中。使用普通的Python函数会导致\n被@tf.function修饰前【eager执行】和被@tf.function修饰后【静态图执行】的输出不一致。\n\n2，避免在@tf.function修饰的函数内部定义tf.Variable. \n\n解释：如果函数内部定义了tf.Variable,那么在【eager执行】时，这种创建tf.Variable的行为在每次函数调用时候都会发生。但是在【静态图执行】时，这种创建tf.Variable的行为只会发生在第一步跟踪Python代码逻辑创建计算图时，这会导致被@tf.function修饰前【eager执行】和被@tf.function修饰后【静态图执行】的输出不一致。实际上，TensorFlow在这种情况下一般会报错。\n\n3，被@tf.function修饰的函数不可修改该函数外部的Python列表或字典等数据结构变量。\n\n解释：静态计算图是被编译成C++代码在TensorFlow内核中执行的。Python中的列表和字典等数据结构变量是无法嵌入到计算图中，它们仅仅能够在创建计算图时被读取，在执行计算图时是无法修改Python中的列表或字典这样的数据结构变量的。\n\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n\n```python\n\n```\n"
        },
        {
          "name": "4-5,AutoGraph和tf.Module.md",
          "type": "blob",
          "size": 10.263671875,
          "content": "# 4-5,AutoGraph和tf.Module\n\n\n有三种计算图的构建方式：静态计算图，动态计算图，以及Autograph。\n\nTensorFlow 2.0主要使用的是动态计算图和Autograph。\n\n动态计算图易于调试，编码效率较高，但执行效率偏低。\n\n静态计算图执行效率很高，但较难调试。\n\n而Autograph机制可以将动态图转换成静态计算图，兼收执行效率和编码效率之利。\n\n当然Autograph机制能够转换的代码并不是没有任何约束的，有一些编码规范需要遵循，否则可能会转换失败或者不符合预期。\n\n前面我们介绍了Autograph的编码规范和Autograph转换成静态图的原理。\n\n本篇我们介绍使用tf.Module来更好地构建Autograph。\n\n\n\n\n### 一，Autograph和tf.Module概述\n\n\n前面在介绍Autograph的编码规范时提到构建Autograph时应该避免在@tf.function修饰的函数内部定义tf.Variable. \n\n但是如果在函数外部定义tf.Variable的话，又会显得这个函数有外部变量依赖，封装不够完美。\n\n一种简单的思路是定义一个类，并将相关的tf.Variable创建放在类的初始化方法中。而将函数的逻辑放在其他方法中。\n\n这样一顿猛如虎的操作之后，我们会觉得一切都如同人法地地法天天法道道法自然般的自然。\n\n惊喜的是，TensorFlow提供了一个基类tf.Module，通过继承它构建子类，我们不仅可以获得以上的自然而然，而且可以非常方便地管理变量，还可以非常方便地管理它引用的其它Module，最重要的是，我们能够利用tf.saved_model保存模型并实现跨平台部署使用。\n\n实际上，tf.keras.models.Model,tf.keras.layers.Layer 都是继承自tf.Module的，提供了方便的变量管理和所引用的子模块管理的功能。\n\n**因此，利用tf.Module提供的封装，再结合TensoFlow丰富的低阶API，实际上我们能够基于TensorFlow开发任意机器学习模型(而非仅仅是神经网络模型)，并实现跨平台部署使用。**\n\n\n\n\n\n### 二，应用tf.Module封装Autograph\n\n\n定义一个简单的function。\n\n```python\nimport tensorflow as tf \nx = tf.Variable(1.0,dtype=tf.float32)\n\n#在tf.function中用input_signature限定输入张量的签名类型：shape和dtype\n@tf.function(input_signature=[tf.TensorSpec(shape = [], dtype = tf.float32)])    \ndef add_print(a):\n    x.assign_add(a)\n    tf.print(x)\n    return(x)\n```\n\n```python\nadd_print(tf.constant(3.0))\n#add_print(tf.constant(3)) #输入不符合张量签名的参数将报错\n```\n\n```\n4\n```\n\n\n下面利用tf.Module的子类化将其封装一下。\n\n```python\nclass DemoModule(tf.Module):\n    def __init__(self,init_value = tf.constant(0.0),name=None):\n        super(DemoModule, self).__init__(name=name)\n        with self.name_scope:  #相当于with tf.name_scope(\"demo_module\")\n            self.x = tf.Variable(init_value,dtype = tf.float32,trainable=True)\n\n     \n    @tf.function(input_signature=[tf.TensorSpec(shape = [], dtype = tf.float32)])  \n    def addprint(self,a):\n        with self.name_scope:\n            self.x.assign_add(a)\n            tf.print(self.x)\n            return(self.x)\n\n```\n\n```python\n#执行\ndemo = DemoModule(init_value = tf.constant(1.0))\nresult = demo.addprint(tf.constant(5.0))\n```\n\n```\n6\n```\n\n```python\n#查看模块中的全部变量和全部可训练变量\nprint(demo.variables)\nprint(demo.trainable_variables)\n```\n\n```\n(<tf.Variable 'demo_module/Variable:0' shape=() dtype=float32, numpy=6.0>,)\n(<tf.Variable 'demo_module/Variable:0' shape=() dtype=float32, numpy=6.0>,)\n```\n\n```python\n#查看模块中的全部子模块\ndemo.submodules\n```\n\n```python\n#使用tf.saved_model 保存模型，并指定需要跨平台部署的方法\ntf.saved_model.save(demo,\"./data/demo/1\",signatures = {\"serving_default\":demo.addprint})\n```\n\n```python\n#加载模型\ndemo2 = tf.saved_model.load(\"./data/demo/1\")\ndemo2.addprint(tf.constant(5.0))\n```\n\n```\n11\n```\n\n```python\n# 查看模型文件相关信息，红框标出来的输出信息在模型部署和跨平台使用时有可能会用到\n!saved_model_cli show --dir ./data/demo/1 --all\n```\n\n![](./data/查看模型文件信息.jpg)\n\n```python\n\n```\n\n在tensorboard中查看计算图，模块会被添加模块名demo_module,方便层次化呈现计算图结构。\n\n```python\nimport datetime\n\n# 创建日志\nstamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\nlogdir = './data/demomodule/%s' % stamp\nwriter = tf.summary.create_file_writer(logdir)\n\n#开启autograph跟踪\ntf.summary.trace_on(graph=True, profiler=True) \n\n#执行autograph\ndemo = DemoModule(init_value = tf.constant(0.0))\nresult = demo.addprint(tf.constant(5.0))\n\n#将计算图信息写入日志\nwith writer.as_default():\n    tf.summary.trace_export(\n        name=\"demomodule\",\n        step=0,\n        profiler_outdir=logdir)\n    \n```\n\n```python\n\n```\n\n```python\n#启动 tensorboard在jupyter中的魔法命令\n%reload_ext tensorboard\n```\n\n```python\nfrom tensorboard import notebook\nnotebook.list() \n```\n\n```python\nnotebook.start(\"--logdir ./data/demomodule/\")\n```\n\n![](./data/demomodule的计算图结构.jpg)\n\n```python\n\n```\n\n除了利用tf.Module的子类化实现封装，我们也可以通过给tf.Module添加属性的方法进行封装。\n\n```python\nmymodule = tf.Module()\nmymodule.x = tf.Variable(0.0)\n\n@tf.function(input_signature=[tf.TensorSpec(shape = [], dtype = tf.float32)])  \ndef addprint(a):\n    mymodule.x.assign_add(a)\n    tf.print(mymodule.x)\n    return (mymodule.x)\n\nmymodule.addprint = addprint\n```\n\n```python\nmymodule.addprint(tf.constant(1.0)).numpy()\n```\n\n```\n1.0\n```\n\n```python\nprint(mymodule.variables)\n```\n\n```\n(<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.0>,)\n```\n\n```python\n#使用tf.saved_model 保存模型\ntf.saved_model.save(mymodule,\"./data/mymodule\",\n    signatures = {\"serving_default\":mymodule.addprint})\n\n#加载模型\nmymodule2 = tf.saved_model.load(\"./data/mymodule\")\nmymodule2.addprint(tf.constant(5.0))\n```\n\n```\nINFO:tensorflow:Assets written to: ./data/mymodule/assets\n5\n```\n\n```python\n\n```\n\n### 三，tf.Module和tf.keras.Model，tf.keras.layers.Layer\n\n\ntf.keras中的模型和层都是继承tf.Module实现的，也具有变量管理和子模块管理功能。\n\n```python\nimport tensorflow as tf\nfrom tensorflow.keras import models,layers,losses,metrics\n```\n\n```python\nprint(issubclass(tf.keras.Model,tf.Module))\nprint(issubclass(tf.keras.layers.Layer,tf.Module))\nprint(issubclass(tf.keras.Model,tf.keras.layers.Layer))\n```\n\n```\nTrue\nTrue\nTrue\n```\n\n```python\ntf.keras.backend.clear_session() \n\nmodel = models.Sequential()\n\nmodel.add(layers.Dense(4,input_shape = (10,)))\nmodel.add(layers.Dense(2))\nmodel.add(layers.Dense(1))\nmodel.summary()\n```\n\n```\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 4)                 44        \n_________________________________________________________________\ndense_1 (Dense)              (None, 2)                 10        \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 3         \n=================================================================\nTotal params: 57\nTrainable params: 57\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n```python\nmodel.variables\n```\n\n```\n[<tf.Variable 'dense/kernel:0' shape=(10, 4) dtype=float32, numpy=\n array([[-0.06741005,  0.45534766,  0.5190817 , -0.01806331],\n        [-0.14258742, -0.49711505,  0.26030976,  0.18607801],\n        [-0.62806034,  0.5327399 ,  0.42206633,  0.29201728],\n        [-0.16602087, -0.18901917,  0.55159235, -0.01091868],\n        [ 0.04533798,  0.326845  , -0.582667  ,  0.19431782],\n        [ 0.6494713 , -0.16174704,  0.4062966 ,  0.48760796],\n        [ 0.58400524, -0.6280886 , -0.11265379, -0.6438277 ],\n        [ 0.26642334,  0.49275804,  0.20793378, -0.43889117],\n        [ 0.4092741 ,  0.09871006, -0.2073121 ,  0.26047975],\n        [ 0.43910992,  0.00199282, -0.07711256, -0.27966842]],\n       dtype=float32)>,\n <tf.Variable 'dense/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'dense_1/kernel:0' shape=(4, 2) dtype=float32, numpy=\n array([[ 0.5022683 , -0.0507431 ],\n        [-0.61540484,  0.9369011 ],\n        [-0.14412141, -0.54607415],\n        [ 0.2027781 , -0.4651153 ]], dtype=float32)>,\n <tf.Variable 'dense_1/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>,\n <tf.Variable 'dense_2/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[-0.244825 ],\n        [-1.2101456]], dtype=float32)>,\n <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n```\n\n```python\nmodel.layers[0].trainable = False #冻结第0层的变量,使其不可训练\nmodel.trainable_variables\n```\n\n```\n[<tf.Variable 'dense_1/kernel:0' shape=(4, 2) dtype=float32, numpy=\n array([[ 0.5022683 , -0.0507431 ],\n        [-0.61540484,  0.9369011 ],\n        [-0.14412141, -0.54607415],\n        [ 0.2027781 , -0.4651153 ]], dtype=float32)>,\n <tf.Variable 'dense_1/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>,\n <tf.Variable 'dense_2/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[-0.244825 ],\n        [-1.2101456]], dtype=float32)>,\n <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n```\n\n```python\nmodel.submodules\n```\n\n```\n(<tensorflow.python.keras.engine.input_layer.InputLayer at 0x144d8c080>,\n <tensorflow.python.keras.layers.core.Dense at 0x144daada0>,\n <tensorflow.python.keras.layers.core.Dense at 0x144d8c5c0>,\n <tensorflow.python.keras.layers.core.Dense at 0x144d7aa20>)\n```\n\n```python\nmodel.layers\n```\n\n```\n[<tensorflow.python.keras.layers.core.Dense at 0x144daada0>,\n <tensorflow.python.keras.layers.core.Dense at 0x144d8c5c0>,\n <tensorflow.python.keras.layers.core.Dense at 0x144d7aa20>]\n```\n\n```python\nprint(model.name)\nprint(model.name_scope())\n```\n\n```\nsequential\nsequential\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n"
        },
        {
          "name": "5-1,数据管道Dataset.md",
          "type": "blob",
          "size": 26.0615234375,
          "content": "# 5-1,数据管道Dataset\n\n如果需要训练的数据大小不大，例如不到1G，那么可以直接全部读入内存中进行训练，这样一般效率最高。\n\n但如果需要训练的数据很大，例如超过10G，无法一次载入内存，那么通常需要在训练的过程中分批逐渐读入。\n\n使用 tf.data API 可以构建数据输入管道，轻松处理大量的数据，不同的数据格式，以及不同的数据转换。\n\n```python\n\n```\n\n### 一，构建数据管道\n\n\n可以从 Numpy array, Pandas DataFrame, Python generator, csv文件, 文本文件, 文件路径, tfrecords文件等方式构建数据管道。\n\n其中通过Numpy array, Pandas DataFrame, 文件路径构建数据管道是最常用的方法。\n\n通过tfrecords文件方式构建数据管道较为复杂，需要对样本构建tf.Example后压缩成字符串写到tfrecords文件，读取后再解析成tf.Example。\n\n但tfrecords文件的优点是压缩后文件较小，便于网络传播，加载速度较快。\n\n\n**1,从Numpy array构建数据管道**\n\n```python\n# 从Numpy array构建数据管道\n\nimport tensorflow as tf\nimport numpy as np \nfrom sklearn import datasets \niris = datasets.load_iris()\n\n\nds1 = tf.data.Dataset.from_tensor_slices((iris[\"data\"],iris[\"target\"]))\nfor features,label in ds1.take(5):\n    print(features,label)\n\n```\n\n```\ntf.Tensor([5.1 3.5 1.4 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64)\ntf.Tensor([4.9 3.  1.4 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64)\ntf.Tensor([4.7 3.2 1.3 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64)\ntf.Tensor([4.6 3.1 1.5 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64)\ntf.Tensor([5.  3.6 1.4 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64)\n```\n\n```python\n\n```\n\n**2,从 Pandas DataFrame构建数据管道**\n\n```python\n# 从 Pandas DataFrame构建数据管道\nimport tensorflow as tf\nfrom sklearn import datasets \nimport pandas as pd\niris = datasets.load_iris()\ndfiris = pd.DataFrame(iris[\"data\"],columns = iris.feature_names)\nds2 = tf.data.Dataset.from_tensor_slices((dfiris.to_dict(\"list\"),iris[\"target\"]))\n\nfor features,label in ds2.take(3):\n    print(features,label)\n```\n\n```\n{'sepal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=5.1>, 'sepal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=3.5>, 'petal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=1.4>, 'petal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=0.2>} tf.Tensor(0, shape=(), dtype=int64)\n{'sepal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=4.9>, 'sepal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=3.0>, 'petal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=1.4>, 'petal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=0.2>} tf.Tensor(0, shape=(), dtype=int64)\n{'sepal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=4.7>, 'sepal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=3.2>, 'petal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=1.3>, 'petal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=0.2>} tf.Tensor(0, shape=(), dtype=int64)\n```\n\n```python\n\n```\n\n```python\n\n```\n\n**3,从Python generator构建数据管道**\n\n```python\n# 从Python generator构建数据管道\nimport tensorflow as tf\nfrom matplotlib import pyplot as plt \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# 定义一个从文件中读取图片的generator\nimage_generator = ImageDataGenerator(rescale=1.0/255).flow_from_directory(\n                    \"./data/cifar2/test/\",\n                    target_size=(32, 32),\n                    batch_size=20,\n                    class_mode='binary')\n\nclassdict = image_generator.class_indices\nprint(classdict)\n\ndef generator():\n    for features,label in image_generator:\n        yield (features,label)\n\nds3 = tf.data.Dataset.from_generator(generator,output_types=(tf.float32,tf.int32))\n```\n\n```python\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\nplt.figure(figsize=(6,6)) \nfor i,(img,label) in enumerate(ds3.unbatch().take(9)):\n    ax=plt.subplot(3,3,i+1)\n    ax.imshow(img.numpy())\n    ax.set_title(\"label = %d\"%label)\n    ax.set_xticks([])\n    ax.set_yticks([]) \nplt.show()\n```\n\n![](./data/5-1-cifar2预览.jpg)\n\n```python\n\n```\n\n**4,从csv文件构建数据管道**\n\n```python\n# 从csv文件构建数据管道\nds4 = tf.data.experimental.make_csv_dataset(\n      file_pattern = [\"./data/titanic/train.csv\",\"./data/titanic/test.csv\"],\n      batch_size=3, \n      label_name=\"Survived\",\n      na_value=\"\",\n      num_epochs=1,\n      ignore_errors=True)\n\nfor data,label in ds4.take(2):\n    print(data,label)\n```\n\n```\nOrderedDict([('PassengerId', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([540,  58, 764], dtype=int32)>), ('Pclass', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 3, 1], dtype=int32)>), ('Name', <tf.Tensor: shape=(3,), dtype=string, numpy=\narray([b'Frolicher, Miss. Hedwig Margaritha', b'Novel, Mr. Mansouer',\n       b'Carter, Mrs. William Ernest (Lucile Polk)'], dtype=object)>), ('Sex', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'female', b'male', b'female'], dtype=object)>), ('Age', <tf.Tensor: shape=(3,), dtype=float32, numpy=array([22. , 28.5, 36. ], dtype=float32)>), ('SibSp', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 0, 1], dtype=int32)>), ('Parch', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 0, 2], dtype=int32)>), ('Ticket', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'13568', b'2697', b'113760'], dtype=object)>), ('Fare', <tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 49.5   ,   7.2292, 120.    ], dtype=float32)>), ('Cabin', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'B39', b'', b'B96 B98'], dtype=object)>), ('Embarked', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'C', b'C', b'S'], dtype=object)>)]) tf.Tensor([1 0 1], shape=(3,), dtype=int32)\nOrderedDict([('PassengerId', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([845,  66, 390], dtype=int32)>), ('Pclass', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([3, 3, 2], dtype=int32)>), ('Name', <tf.Tensor: shape=(3,), dtype=string, numpy=\narray([b'Culumovic, Mr. Jeso', b'Moubarek, Master. Gerios',\n       b'Lehmann, Miss. Bertha'], dtype=object)>), ('Sex', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'male', b'male', b'female'], dtype=object)>), ('Age', <tf.Tensor: shape=(3,), dtype=float32, numpy=array([17.,  0., 17.], dtype=float32)>), ('SibSp', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 1, 0], dtype=int32)>), ('Parch', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 1, 0], dtype=int32)>), ('Ticket', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'315090', b'2661', b'SC 1748'], dtype=object)>), ('Fare', <tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 8.6625, 15.2458, 12.    ], dtype=float32)>), ('Cabin', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'', b'', b''], dtype=object)>), ('Embarked', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'S', b'C', b'C'], dtype=object)>)]) tf.Tensor([0 1 1], shape=(3,), dtype=int32)\n```\n\n```python\n\n```\n\n**5,从文本文件构建数据管道**\n\n```python\n# 从文本文件构建数据管道\n\nds5 = tf.data.TextLineDataset(\n    filenames = [\"./data/titanic/train.csv\",\"./data/titanic/test.csv\"]\n    ).skip(1) #略去第一行header\n\nfor line in ds5.take(5):\n    print(line)\n```\n\n```\ntf.Tensor(b'493,0,1,\"Molson, Mr. Harry Markland\",male,55.0,0,0,113787,30.5,C30,S', shape=(), dtype=string)\ntf.Tensor(b'53,1,1,\"Harper, Mrs. Henry Sleeper (Myna Haxtun)\",female,49.0,1,0,PC 17572,76.7292,D33,C', shape=(), dtype=string)\ntf.Tensor(b'388,1,2,\"Buss, Miss. Kate\",female,36.0,0,0,27849,13.0,,S', shape=(), dtype=string)\ntf.Tensor(b'192,0,2,\"Carbines, Mr. William\",male,19.0,0,0,28424,13.0,,S', shape=(), dtype=string)\ntf.Tensor(b'687,0,3,\"Panula, Mr. Jaako Arnold\",male,14.0,4,1,3101295,39.6875,,S', shape=(), dtype=string)\n```\n\n```python\n\n```\n\n**6,从文件路径构建数据管道**\n\n```python\nds6 = tf.data.Dataset.list_files(\"./data/cifar2/train/*/*.jpg\")\nfor file in ds6.take(5):\n    print(file)\n```\n\n```\ntf.Tensor(b'./data/cifar2/train/automobile/1263.jpg', shape=(), dtype=string)\ntf.Tensor(b'./data/cifar2/train/airplane/2837.jpg', shape=(), dtype=string)\ntf.Tensor(b'./data/cifar2/train/airplane/4264.jpg', shape=(), dtype=string)\ntf.Tensor(b'./data/cifar2/train/automobile/4241.jpg', shape=(), dtype=string)\ntf.Tensor(b'./data/cifar2/train/automobile/192.jpg', shape=(), dtype=string)\n```\n\n```python\nfrom matplotlib import pyplot as plt \ndef load_image(img_path,size = (32,32)):\n    label = 1 if tf.strings.regex_full_match(img_path,\".*/automobile/.*\") else 0\n    img = tf.io.read_file(img_path)\n    img = tf.image.decode_jpeg(img) #注意此处为jpeg格式\n    img = tf.image.resize(img,size)\n    return(img,label)\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\nfor i,(img,label) in enumerate(ds6.map(load_image).take(2)):\n    plt.figure(i)\n    plt.imshow((img/255.0).numpy())\n    plt.title(\"label = %d\"%label)\n    plt.xticks([])\n    plt.yticks([])\n```\n\n![](./data/5-1-car2.jpg)\n\n```python\n\n```\n\n**7,从tfrecords文件构建数据管道**\n\n```python\nimport os\nimport numpy as np\n\n# inpath：原始数据路径 outpath:TFRecord文件输出路径\ndef create_tfrecords(inpath,outpath): \n    writer = tf.io.TFRecordWriter(outpath)\n    dirs = os.listdir(inpath)\n    for index, name in enumerate(dirs):\n        class_path = inpath +\"/\"+ name+\"/\"\n        for img_name in os.listdir(class_path):\n            img_path = class_path + img_name\n            img = tf.io.read_file(img_path)\n            #img = tf.image.decode_image(img)\n            #img = tf.image.encode_jpeg(img) #统一成jpeg格式压缩\n            example = tf.train.Example(\n               features=tf.train.Features(feature={\n                    'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[index])),\n                    'img_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img.numpy()]))\n               }))\n            writer.write(example.SerializeToString())\n    writer.close()\n    \ncreate_tfrecords(\"./data/cifar2/test/\",\"./data/cifar2_test.tfrecords/\")\n\n```\n\n```python\nfrom matplotlib import pyplot as plt \n\ndef parse_example(proto):\n    description ={ 'img_raw' : tf.io.FixedLenFeature([], tf.string),\n                   'label': tf.io.FixedLenFeature([], tf.int64)} \n    example = tf.io.parse_single_example(proto, description)\n    img = tf.image.decode_jpeg(example[\"img_raw\"])   #注意此处为jpeg格式\n    img = tf.image.resize(img, (32,32))\n    label = example[\"label\"]\n    return(img,label)\n\nds7 = tf.data.TFRecordDataset(\"./data/cifar2_test.tfrecords\").map(parse_example).shuffle(3000)\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\nplt.figure(figsize=(6,6)) \nfor i,(img,label) in enumerate(ds7.take(9)):\n    ax=plt.subplot(3,3,i+1)\n    ax.imshow((img/255.0).numpy())\n    ax.set_title(\"label = %d\"%label)\n    ax.set_xticks([])\n    ax.set_yticks([]) \nplt.show()\n\n```\n\n![](./data/5-1-car9.jpg)\n\n```python\n\n```\n\n```python\n\n```\n\n### 二，应用数据转换\n\n\nDataset数据结构应用非常灵活，因为它本质上是一个Sequece序列，其每个元素可以是各种类型，例如可以是张量，列表，字典，也可以是Dataset。\n\nDataset包含了非常丰富的数据转换功能。\n\n* map: 将转换函数映射到数据集每一个元素。\n\n* flat_map: 将转换函数映射到数据集的每一个元素，并将嵌套的Dataset压平。\n\n* interleave: 效果类似flat_map,但可以将不同来源的数据夹在一起。\n\n* filter: 过滤掉某些元素。\n\n* zip: 将两个长度相同的Dataset横向铰合。\n\n* concatenate: 将两个Dataset纵向连接。\n\n* reduce: 执行归并操作。\n\n* batch : 构建批次，每次放一个批次。比原始数据增加一个维度。 其逆操作为unbatch。\n\n* padded_batch: 构建批次，类似batch, 但可以填充到相同的形状。\n\n* window :构建滑动窗口，返回Dataset of Dataset.\n\n* shuffle: 数据顺序洗牌。\n\n* repeat: 重复数据若干次，不带参数时，重复无数次。\n\n* shard: 采样，从某个位置开始隔固定距离采样一个元素。\n\n* take: 采样，从开始位置取前几个元素。\n\n\n```python\n#map:将转换函数映射到数据集每一个元素\n\nds = tf.data.Dataset.from_tensor_slices([\"hello world\",\"hello China\",\"hello Beijing\"])\nds_map = ds.map(lambda x:tf.strings.split(x,\" \"))\nfor x in ds_map:\n    print(x)\n```\n\n```\ntf.Tensor([b'hello' b'world'], shape=(2,), dtype=string)\ntf.Tensor([b'hello' b'China'], shape=(2,), dtype=string)\ntf.Tensor([b'hello' b'Beijing'], shape=(2,), dtype=string)\n```\n\n```python\n#flat_map:将转换函数映射到数据集的每一个元素，并将嵌套的Dataset压平。\n\nds = tf.data.Dataset.from_tensor_slices([\"hello world\",\"hello China\",\"hello Beijing\"])\nds_flatmap = ds.flat_map(lambda x:tf.data.Dataset.from_tensor_slices(tf.strings.split(x,\" \")))\nfor x in ds_flatmap:\n    print(x)\n```\n\n```\ntf.Tensor(b'hello', shape=(), dtype=string)\ntf.Tensor(b'world', shape=(), dtype=string)\ntf.Tensor(b'hello', shape=(), dtype=string)\ntf.Tensor(b'China', shape=(), dtype=string)\ntf.Tensor(b'hello', shape=(), dtype=string)\ntf.Tensor(b'Beijing', shape=(), dtype=string)\n```\n\n```python\n\n```\n\n```python\n# interleave: 效果类似flat_map,但可以将不同来源的数据夹在一起。\n\nds = tf.data.Dataset.from_tensor_slices([\"hello world\",\"hello China\",\"hello Beijing\"])\nds_interleave = ds.interleave(lambda x:tf.data.Dataset.from_tensor_slices(tf.strings.split(x,\" \")))\nfor x in ds_interleave:\n    print(x)\n    \n```\n\n```\ntf.Tensor(b'hello', shape=(), dtype=string)\ntf.Tensor(b'hello', shape=(), dtype=string)\ntf.Tensor(b'hello', shape=(), dtype=string)\ntf.Tensor(b'world', shape=(), dtype=string)\ntf.Tensor(b'China', shape=(), dtype=string)\ntf.Tensor(b'Beijing', shape=(), dtype=string)\n```\n\n```python\n\n```\n\n```python\n#filter:过滤掉某些元素。\n\nds = tf.data.Dataset.from_tensor_slices([\"hello world\",\"hello China\",\"hello Beijing\"])\n#找出含有字母a或B的元素\nds_filter = ds.filter(lambda x: tf.strings.regex_full_match(x, \".*[a|B].*\"))\nfor x in ds_filter:\n    print(x)\n    \n```\n\n```\ntf.Tensor(b'hello China', shape=(), dtype=string)\ntf.Tensor(b'hello Beijing', shape=(), dtype=string)\n```\n\n```python\n\n```\n\n```python\n#zip:将两个长度相同的Dataset横向铰合。\n\nds1 = tf.data.Dataset.range(0,3)\nds2 = tf.data.Dataset.range(3,6)\nds3 = tf.data.Dataset.range(6,9)\nds_zip = tf.data.Dataset.zip((ds1,ds2,ds3))\nfor x,y,z in ds_zip:\n    print(x.numpy(),y.numpy(),z.numpy())\n\n```\n\n```\n0 3 6\n1 4 7\n2 5 8\n```\n\n```python\n#condatenate:将两个Dataset纵向连接。\n\nds1 = tf.data.Dataset.range(0,3)\nds2 = tf.data.Dataset.range(3,6)\nds_concat = tf.data.Dataset.concatenate(ds1,ds2)\nfor x in ds_concat:\n    print(x)\n```\n\n```\ntf.Tensor(0, shape=(), dtype=int64)\ntf.Tensor(1, shape=(), dtype=int64)\ntf.Tensor(2, shape=(), dtype=int64)\ntf.Tensor(3, shape=(), dtype=int64)\ntf.Tensor(4, shape=(), dtype=int64)\ntf.Tensor(5, shape=(), dtype=int64)\n```\n\n```python\n#reduce:执行归并操作。\n\nds = tf.data.Dataset.from_tensor_slices([1,2,3,4,5.0])\nresult = ds.reduce(0.0,lambda x,y:tf.add(x,y))\nresult\n```\n\n```\n<tf.Tensor: shape=(), dtype=float32, numpy=15.0>\n```\n\n```python\n\n```\n\n```python\n#batch:构建批次，每次放一个批次。比原始数据增加一个维度。 其逆操作为unbatch。 \n\nds = tf.data.Dataset.range(12)\nds_batch = ds.batch(4)\nfor x in ds_batch:\n    print(x)\n```\n\n```\ntf.Tensor([0 1 2 3], shape=(4,), dtype=int64)\ntf.Tensor([4 5 6 7], shape=(4,), dtype=int64)\ntf.Tensor([ 8  9 10 11], shape=(4,), dtype=int64)\n```\n\n```python\n\n```\n\n```python\n#padded_batch:构建批次，类似batch, 但可以填充到相同的形状。\n\nelements = [[1, 2],[3, 4, 5],[6, 7],[8]]\nds = tf.data.Dataset.from_generator(lambda: iter(elements), tf.int32)\n\nds_padded_batch = ds.padded_batch(2,padded_shapes = [4,])\nfor x in ds_padded_batch:\n    print(x)    \n```\n\n```\ntf.Tensor(\n[[1 2 0 0]\n [3 4 5 0]], shape=(2, 4), dtype=int32)\ntf.Tensor(\n[[6 7 0 0]\n [8 0 0 0]], shape=(2, 4), dtype=int32)\n```\n\n```python\n\n```\n\n```python\n#window:构建滑动窗口，返回Dataset of Dataset.\n\nds = tf.data.Dataset.range(12)\n#window返回的是Dataset of Dataset,可以用flat_map压平\nds_window = ds.window(3, shift=1).flat_map(lambda x: x.batch(3,drop_remainder=True)) \nfor x in ds_window:\n    print(x)\n```\n\n```\ntf.Tensor([0 1 2], shape=(3,), dtype=int64)\ntf.Tensor([1 2 3], shape=(3,), dtype=int64)\ntf.Tensor([2 3 4], shape=(3,), dtype=int64)\ntf.Tensor([3 4 5], shape=(3,), dtype=int64)\ntf.Tensor([4 5 6], shape=(3,), dtype=int64)\ntf.Tensor([5 6 7], shape=(3,), dtype=int64)\ntf.Tensor([6 7 8], shape=(3,), dtype=int64)\ntf.Tensor([7 8 9], shape=(3,), dtype=int64)\ntf.Tensor([ 8  9 10], shape=(3,), dtype=int64)\ntf.Tensor([ 9 10 11], shape=(3,), dtype=int64)\n```\n\n```python\n\n```\n\n```python\n#shuffle:数据顺序洗牌。\n\nds = tf.data.Dataset.range(12)\nds_shuffle = ds.shuffle(buffer_size = 5)\nfor x in ds_shuffle:\n    print(x)\n    \n```\n\n```\ntf.Tensor(1, shape=(), dtype=int64)\ntf.Tensor(4, shape=(), dtype=int64)\ntf.Tensor(0, shape=(), dtype=int64)\ntf.Tensor(6, shape=(), dtype=int64)\ntf.Tensor(5, shape=(), dtype=int64)\ntf.Tensor(2, shape=(), dtype=int64)\ntf.Tensor(7, shape=(), dtype=int64)\ntf.Tensor(11, shape=(), dtype=int64)\ntf.Tensor(3, shape=(), dtype=int64)\ntf.Tensor(9, shape=(), dtype=int64)\ntf.Tensor(10, shape=(), dtype=int64)\ntf.Tensor(8, shape=(), dtype=int64)\n```\n\n```python\n\n```\n\n```python\n#repeat:重复数据若干次，不带参数时，重复无数次。\n\nds = tf.data.Dataset.range(3)\nds_repeat = ds.repeat(3)\nfor x in ds_repeat:\n    print(x)\n```\n\n```\ntf.Tensor(0, shape=(), dtype=int64)\ntf.Tensor(1, shape=(), dtype=int64)\ntf.Tensor(2, shape=(), dtype=int64)\ntf.Tensor(0, shape=(), dtype=int64)\ntf.Tensor(1, shape=(), dtype=int64)\ntf.Tensor(2, shape=(), dtype=int64)\ntf.Tensor(0, shape=(), dtype=int64)\ntf.Tensor(1, shape=(), dtype=int64)\ntf.Tensor(2, shape=(), dtype=int64)\n```\n\n```python\n#shard:采样，从某个位置开始隔固定距离采样一个元素。\n\nds = tf.data.Dataset.range(12)\nds_shard = ds.shard(3,index = 1)\n\nfor x in ds_shard:\n    print(x)\n```\n\n```\ntf.Tensor(1, shape=(), dtype=int64)\ntf.Tensor(4, shape=(), dtype=int64)\ntf.Tensor(7, shape=(), dtype=int64)\ntf.Tensor(10, shape=(), dtype=int64)\n```\n\n```python\n#take:采样，从开始位置取前几个元素。\n\nds = tf.data.Dataset.range(12)\nds_take = ds.take(3)\n\nlist(ds_take.as_numpy_iterator())\n\n```\n\n```\n[0, 1, 2]\n```\n\n```python\n\n```\n\n```python\n\n```\n\n### 三，提升管道性能\n\n\n训练深度学习模型常常会非常耗时。\n\n模型训练的耗时主要来自于两个部分，一部分来自**数据准备**，另一部分来自**参数迭代**。\n\n参数迭代过程的耗时通常依赖于GPU来提升。\n\n而数据准备过程的耗时则可以通过构建高效的数据管道进行提升。\n\n以下是一些构建高效数据管道的建议。\n\n* 1，使用 prefetch 方法让数据准备和参数迭代两个过程相互并行。\n\n* 2，使用 interleave 方法可以让数据读取过程多进程执行,并将不同来源数据夹在一起。\n\n* 3，使用 map 时设置num_parallel_calls 让数据转换过程多进程执行。\n\n* 4，使用 cache 方法让数据在第一个epoch后缓存到内存中，仅限于数据集不大情形。\n\n* 5，使用 map转换时，先batch, 然后采用向量化的转换方法对每个batch进行转换。\n\n```python\n\n```\n\n**1，使用 prefetch 方法让数据准备和参数迭代两个过程相互并行。**\n\n```python\nimport tensorflow as tf\n\n#打印时间分割线\n@tf.function\ndef printbar():\n    ts = tf.timestamp()\n    today_ts = ts%(24*60*60)\n\n    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\n    minite = tf.cast((today_ts%3600)//60,tf.int32)\n    second = tf.cast(tf.floor(today_ts%60),tf.int32)\n    \n    def timeformat(m):\n        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\n            return(tf.strings.format(\"0{}\",m))\n        else:\n            return(tf.strings.format(\"{}\",m))\n    \n    timestring = tf.strings.join([timeformat(hour),timeformat(minite),\n                timeformat(second)],separator = \":\")\n    tf.print(\"==========\"*8,end = \"\")\n    tf.print(timestring)\n    \n```\n\n```python\nimport time\n\n# 数据准备和参数迭代两个过程默认情况下是串行的。\n\n# 模拟数据准备\ndef generator():\n    for i in range(10):\n        #假设每次准备数据需要2s\n        time.sleep(2) \n        yield i \nds = tf.data.Dataset.from_generator(generator,output_types = (tf.int32))\n\n# 模拟参数迭代\ndef train_step():\n    #假设每一步训练需要1s\n    time.sleep(1) \n    \n```\n\n```python\n# 训练过程预计耗时 10*2+10*1 = 30s\nprintbar()\ntf.print(tf.constant(\"start training...\"))\nfor x in ds:\n    train_step()  \nprintbar()\ntf.print(tf.constant(\"end training...\"))\n```\n\n```python\n# 使用 prefetch 方法让数据准备和参数迭代两个过程相互并行。\n\n# 训练过程预计耗时 max(10*2,10*1) = 20s\nprintbar()\ntf.print(tf.constant(\"start training with prefetch...\"))\n\n# tf.data.experimental.AUTOTUNE 可以让程序自动选择合适的参数\nfor x in ds.prefetch(buffer_size = tf.data.experimental.AUTOTUNE):\n    train_step()  \n    \nprintbar()\ntf.print(tf.constant(\"end training...\"))\n\n```\n\n```python\n\n```\n\n**2，使用 interleave 方法可以让数据读取过程多进程执行,并将不同来源数据夹在一起。**\n\n```python\nds_files = tf.data.Dataset.list_files(\"./data/titanic/*.csv\")\nds = ds_files.flat_map(lambda x:tf.data.TextLineDataset(x).skip(1))\nfor line in ds.take(4):\n    print(line)\n```\n\n```\ntf.Tensor(b'493,0,1,\"Molson, Mr. Harry Markland\",male,55.0,0,0,113787,30.5,C30,S', shape=(), dtype=string)\ntf.Tensor(b'53,1,1,\"Harper, Mrs. Henry Sleeper (Myna Haxtun)\",female,49.0,1,0,PC 17572,76.7292,D33,C', shape=(), dtype=string)\ntf.Tensor(b'388,1,2,\"Buss, Miss. Kate\",female,36.0,0,0,27849,13.0,,S', shape=(), dtype=string)\ntf.Tensor(b'192,0,2,\"Carbines, Mr. William\",male,19.0,0,0,28424,13.0,,S', shape=(), dtype=string)\n```\n\n```python\nds_files = tf.data.Dataset.list_files(\"./data/titanic/*.csv\")\nds = ds_files.interleave(lambda x:tf.data.TextLineDataset(x).skip(1))\nfor line in ds.take(8):\n    print(line)\n```\n\n```\ntf.Tensor(b'181,0,3,\"Sage, Miss. Constance Gladys\",female,,8,2,CA. 2343,69.55,,S', shape=(), dtype=string)\ntf.Tensor(b'493,0,1,\"Molson, Mr. Harry Markland\",male,55.0,0,0,113787,30.5,C30,S', shape=(), dtype=string)\ntf.Tensor(b'405,0,3,\"Oreskovic, Miss. Marija\",female,20.0,0,0,315096,8.6625,,S', shape=(), dtype=string)\ntf.Tensor(b'53,1,1,\"Harper, Mrs. Henry Sleeper (Myna Haxtun)\",female,49.0,1,0,PC 17572,76.7292,D33,C', shape=(), dtype=string)\ntf.Tensor(b'635,0,3,\"Skoog, Miss. Mabel\",female,9.0,3,2,347088,27.9,,S', shape=(), dtype=string)\ntf.Tensor(b'388,1,2,\"Buss, Miss. Kate\",female,36.0,0,0,27849,13.0,,S', shape=(), dtype=string)\ntf.Tensor(b'701,1,1,\"Astor, Mrs. John Jacob (Madeleine Talmadge Force)\",female,18.0,1,0,PC 17757,227.525,C62 C64,C', shape=(), dtype=string)\ntf.Tensor(b'192,0,2,\"Carbines, Mr. William\",male,19.0,0,0,28424,13.0,,S', shape=(), dtype=string)\n```\n\n```python\n\n```\n\n**3，使用 map 时设置num_parallel_calls 让数据转换过程多进行执行。**\n\n```python\nds = tf.data.Dataset.list_files(\"./data/cifar2/train/*/*.jpg\")\ndef load_image(img_path,size = (32,32)):\n    label = 1 if tf.strings.regex_full_match(img_path,\".*/automobile/.*\") else 0\n    img = tf.io.read_file(img_path)\n    img = tf.image.decode_jpeg(img) #注意此处为jpeg格式\n    img = tf.image.resize(img,size)\n    return(img,label)\n```\n\n```python\n#单进程转换\nprintbar()\ntf.print(tf.constant(\"start transformation...\"))\n\nds_map = ds.map(load_image)\nfor _ in ds_map:\n    pass\n\nprintbar()\ntf.print(tf.constant(\"end transformation...\"))\n```\n\n```python\n#多进程转换\nprintbar()\ntf.print(tf.constant(\"start parallel transformation...\"))\n\nds_map_parallel = ds.map(load_image,num_parallel_calls = tf.data.experimental.AUTOTUNE)\nfor _ in ds_map_parallel:\n    pass\n\nprintbar()\ntf.print(tf.constant(\"end parallel transformation...\"))\n```\n\n```python\n\n```\n\n**4，使用 cache 方法让数据在第一个epoch后缓存到内存中，仅限于数据集不大情形。**\n\n```python\nimport time\n\n# 模拟数据准备\ndef generator():\n    for i in range(5):\n        #假设每次准备数据需要2s\n        time.sleep(2) \n        yield i \nds = tf.data.Dataset.from_generator(generator,output_types = (tf.int32))\n\n# 模拟参数迭代\ndef train_step():\n    #假设每一步训练需要0s\n    pass\n\n# 训练过程预计耗时 (5*2+5*0)*3 = 30s\nprintbar()\ntf.print(tf.constant(\"start training...\"))\nfor epoch in tf.range(3):\n    for x in ds:\n        train_step()  \n    printbar()\n    tf.print(\"epoch =\",epoch,\" ended\")\nprintbar()\ntf.print(tf.constant(\"end training...\"))\n\n```\n\n```python\nimport time\n\n# 模拟数据准备\ndef generator():\n    for i in range(5):\n        #假设每次准备数据需要2s\n        time.sleep(2) \n        yield i \n\n# 使用 cache 方法让数据在第一个epoch后缓存到内存中，仅限于数据集不大情形。\nds = tf.data.Dataset.from_generator(generator,output_types = (tf.int32)).cache()\n\n# 模拟参数迭代\ndef train_step():\n    #假设每一步训练需要0s\n    time.sleep(0) \n\n# 训练过程预计耗时 (5*2+5*0)+(5*0+5*0)*2 = 10s\nprintbar()\ntf.print(tf.constant(\"start training...\"))\nfor epoch in tf.range(3):\n    for x in ds:\n        train_step()  \n    printbar()\n    tf.print(\"epoch =\",epoch,\" ended\")\nprintbar()\ntf.print(tf.constant(\"end training...\"))\n```\n\n```python\n\n```\n\n**5，使用 map转换时，先batch, 然后采用向量化的转换方法对每个batch进行转换。**\n\n```python\n#先map后batch\nds = tf.data.Dataset.range(100000)\nds_map_batch = ds.map(lambda x:x**2).batch(20)\n\nprintbar()\ntf.print(tf.constant(\"start scalar transformation...\"))\nfor x in ds_map_batch:\n    pass\nprintbar()\ntf.print(tf.constant(\"end scalar transformation...\"))\n\n```\n\n```python\n#先batch后map\nds = tf.data.Dataset.range(100000)\nds_batch_map = ds.batch(20).map(lambda x:x**2)\n\nprintbar()\ntf.print(tf.constant(\"start vector transformation...\"))\nfor x in ds_batch_map:\n    pass\nprintbar()\ntf.print(tf.constant(\"end vector transformation...\"))\n\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n\n```python\n\n```\n"
        },
        {
          "name": "5-2,特征列feature_column.md",
          "type": "blob",
          "size": 8.7890625,
          "content": "# 5-2,特征列feature_column\n\n特征列 通常用于对结构化数据实施特征工程时候使用，图像或者文本数据一般不会用到特征列。\n\n\n### 一，特征列用法概述\n\n\n使用特征列可以将类别特征转换为one-hot编码特征，将连续特征构建分桶特征，以及对多个特征生成交叉特征等等。\n\n\n要创建特征列，请调用 tf.feature_column 模块的函数。该模块中常用的九个函数如下图所示，所有九个函数都会返回一个 Categorical-Column 或一个 \nDense-Column 对象，但却不会返回 bucketized_column，后者继承自这两个类。\n\n注意：所有的Catogorical Column类型最终都要通过indicator_column转换成Dense Column类型才能传入模型！\n\n\n![](./data/特征列9种.jpg)\n\n<!-- #region -->\n* numeric_column 数值列，最常用。\n\n\n* bucketized_column 分桶列，由数值列生成，可以由一个数值列出多个特征，one-hot编码。\n\n\n* categorical_column_with_identity 分类标识列，one-hot编码，相当于分桶列每个桶为1个整数的情况。\n\n\n* categorical_column_with_vocabulary_list 分类词汇列，one-hot编码，由list指定词典。\n\n\n* categorical_column_with_vocabulary_file 分类词汇列，由文件file指定词典。\n\n\n* categorical_column_with_hash_bucket 哈希列，整数或词典较大时采用。\n\n\n* indicator_column 指标列，由Categorical Column生成，one-hot编码\n\n\n* embedding_column 嵌入列，由Categorical Column生成，嵌入矢量分布参数需要学习。嵌入矢量维数建议取类别数量的 4 次方根。\n\n\n* crossed_column 交叉列，可以由除categorical_column_with_hash_bucket的任意分类列构成。\n<!-- #endregion -->\n\n### 二，特征列使用范例\n\n\n以下是一个使用特征列解决Titanic生存问题的完整范例。\n\n```python\nimport datetime\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras import layers,models\n\n\n#打印日志\ndef printlog(info):\n    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n    print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n    print(info+'...\\n\\n')\n\n\n    \n```\n\n```python\n#================================================================================\n# 一，构建数据管道\n#================================================================================\nprintlog(\"step1: prepare dataset...\")\n\n\ndftrain_raw = pd.read_csv(\"./data/titanic/train.csv\")\ndftest_raw = pd.read_csv(\"./data/titanic/test.csv\")\n\ndfraw = pd.concat([dftrain_raw,dftest_raw])\n\ndef prepare_dfdata(dfraw):\n    dfdata = dfraw.copy()\n    dfdata.columns = [x.lower() for x in dfdata.columns]\n    dfdata = dfdata.rename(columns={'survived':'label'})\n    dfdata = dfdata.drop(['passengerid','name'],axis = 1)\n    for col,dtype in dict(dfdata.dtypes).items():\n        # 判断是否包含缺失值\n        if dfdata[col].hasnans:\n            # 添加标识是否缺失列\n            dfdata[col + '_nan'] = pd.isna(dfdata[col]).astype('int32')\n            # 填充\n            if dtype not in [np.object,np.str,np.unicode]:\n                dfdata[col].fillna(dfdata[col].mean(),inplace = True)\n            else:\n                dfdata[col].fillna('',inplace = True)\n    return(dfdata)\n\ndfdata = prepare_dfdata(dfraw)\ndftrain = dfdata.iloc[0:len(dftrain_raw),:]\ndftest = dfdata.iloc[len(dftrain_raw):,:]\n\n\n\n# 从 dataframe 导入数据 \ndef df_to_dataset(df, shuffle=True, batch_size=32):\n    dfdata = df.copy()\n    if 'label' not in dfdata.columns:\n        ds = tf.data.Dataset.from_tensor_slices(dfdata.to_dict(orient = 'list'))\n    else: \n        labels = dfdata.pop('label')\n        ds = tf.data.Dataset.from_tensor_slices((dfdata.to_dict(orient = 'list'), labels))  \n    if shuffle:\n        ds = ds.shuffle(buffer_size=len(dfdata))\n    ds = ds.batch(batch_size)\n    return ds\n\nds_train = df_to_dataset(dftrain)\nds_test = df_to_dataset(dftest)\n```\n\n```python\n#================================================================================\n# 二，定义特征列\n#================================================================================\nprintlog(\"step2: make feature columns...\")\n\nfeature_columns = []\n\n# 数值列\nfor col in ['age','fare','parch','sibsp'] + [\n    c for c in dfdata.columns if c.endswith('_nan')]:\n    feature_columns.append(tf.feature_column.numeric_column(col))\n\n# 分桶列\nage = tf.feature_column.numeric_column('age')\nage_buckets = tf.feature_column.bucketized_column(age, \n             boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\nfeature_columns.append(age_buckets)\n\n# 类别列\n# 注意：所有的Catogorical Column类型最终都要通过indicator_column转换成Dense Column类型才能传入模型！！\nsex = tf.feature_column.indicator_column(\n      tf.feature_column.categorical_column_with_vocabulary_list(\n      key='sex',vocabulary_list=[\"male\", \"female\"]))\nfeature_columns.append(sex)\n\npclass = tf.feature_column.indicator_column(\n      tf.feature_column.categorical_column_with_vocabulary_list(\n      key='pclass',vocabulary_list=[1,2,3]))\nfeature_columns.append(pclass)\n\nticket = tf.feature_column.indicator_column(\n     tf.feature_column.categorical_column_with_hash_bucket('ticket',3))\nfeature_columns.append(ticket)\n\nembarked = tf.feature_column.indicator_column(\n      tf.feature_column.categorical_column_with_vocabulary_list(\n      key='embarked',vocabulary_list=['S','C','B']))\nfeature_columns.append(embarked)\n\n# 嵌入列\ncabin = tf.feature_column.embedding_column(\n    tf.feature_column.categorical_column_with_hash_bucket('cabin',32),2)\nfeature_columns.append(cabin)\n\n# 交叉列\npclass_cate = tf.feature_column.categorical_column_with_vocabulary_list(\n          key='pclass',vocabulary_list=[1,2,3])\n\ncrossed_feature = tf.feature_column.indicator_column(\n    tf.feature_column.crossed_column([age_buckets, pclass_cate],hash_bucket_size=15))\n\nfeature_columns.append(crossed_feature)\n\n```\n\n```python\n#================================================================================\n# 三，定义模型\n#================================================================================\nprintlog(\"step3: define model...\")\n\ntf.keras.backend.clear_session()\nmodel = tf.keras.Sequential([\n  layers.DenseFeatures(feature_columns), #将特征列放入到tf.keras.layers.DenseFeatures中!!!\n  layers.Dense(64, activation='relu'),\n  layers.Dense(64, activation='relu'),\n  layers.Dense(1, activation='sigmoid')\n])\n\n```\n\n```python\n#================================================================================\n# 四，训练模型\n#================================================================================\nprintlog(\"step4: train model...\")\n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nhistory = model.fit(ds_train,\n          validation_data=ds_test,\n          epochs=10)\n```\n\n```python\n#================================================================================\n# 五，评估模型\n#================================================================================\nprintlog(\"step5: eval model...\")\n\nmodel.summary()\n\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\n\nimport matplotlib.pyplot as plt\n\ndef plot_metric(history, metric):\n    train_metrics = history.history[metric]\n    val_metrics = history.history['val_'+metric]\n    epochs = range(1, len(train_metrics) + 1)\n    plt.plot(epochs, train_metrics, 'bo--')\n    plt.plot(epochs, val_metrics, 'ro-')\n    plt.title('Training and validation '+ metric)\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(metric)\n    plt.legend([\"train_\"+metric, 'val_'+metric])\n    plt.show()\n\nplot_metric(history,\"accuracy\")\n```\n\n```\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_features (DenseFeature multiple                  64        \n_________________________________________________________________\ndense (Dense)                multiple                  3008      \n_________________________________________________________________\ndense_1 (Dense)              multiple                  4160      \n_________________________________________________________________\ndense_2 (Dense)              multiple                  65        \n=================================================================\nTotal params: 7,297\nTrainable params: 7,297\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n\n![](./data/5-2-01-模型评估.jpg)\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n"
        },
        {
          "name": "5-3,激活函数activation.md",
          "type": "blob",
          "size": 3.2880859375,
          "content": "# 5-3,激活函数activation\n\n激活函数在深度学习中扮演着非常重要的角色，它给网络赋予了非线性，从而使得神经网络能够拟合任意复杂的函数。\n\n如果没有激活函数，无论多复杂的网络，都等价于单一的线性变换，无法对非线性函数进行拟合。\n\n目前，深度学习中最流行的激活函数为 relu, 但也有些新推出的激活函数，例如 swish、GELU 据称效果优于relu激活函数。\n\n激活函数的综述介绍可以参考下面两篇文章。\n\n[《一文概览深度学习中的激活函数》](https://zhuanlan.zhihu.com/p/98472075)\n\nhttps://zhuanlan.zhihu.com/p/98472075\n\n[《从ReLU到GELU,一文概览神经网络中的激活函数》](https://zhuanlan.zhihu.com/p/98863801)\n\nhttps://zhuanlan.zhihu.com/p/98863801\n\n\n\n### 一，常用激活函数\n\n\n* tf.nn.sigmoid：将实数压缩到0到1之间，一般只在二分类的最后输出层使用。主要缺陷为存在梯度消失问题，计算复杂度高，输出不以0为中心。\n\n![](./data/sigmoid.png)\n\n* tf.nn.softmax：sigmoid的多分类扩展，一般只在多分类问题的最后输出层使用。\n\n![](./data/softmax说明.jpg)\n\n* tf.nn.tanh：将实数压缩到-1到1之间，输出期望为0。主要缺陷为存在梯度消失问题，计算复杂度高。\n\n![](./data/tanh.png)\n\n* tf.nn.relu：修正线性单元，最流行的激活函数。一般隐藏层使用。主要缺陷是：输出不以0为中心，输入小于0时存在梯度消失问题(死亡relu)。\n\n![](./data/relu.png)\n\n* tf.nn.leaky_relu：对修正线性单元的改进，解决了死亡relu问题。\n\n![](./data/leaky_relu.png)\n\n* tf.nn.elu：指数线性单元。对relu的改进，能够缓解死亡relu问题。\n\n![](./data/elu.png)\n\n* tf.nn.selu：扩展型指数线性单元。在权重用tf.keras.initializers.lecun_normal初始化前提下能够对神经网络进行自归一化。不可能出现梯度爆炸或者梯度消失问题。需要和Dropout的变种AlphaDropout一起使用。\n\n![](./data/selu.png)\n\n* tf.nn.swish：自门控激活函数。谷歌出品，相关研究指出用swish替代relu将获得轻微效果提升。\n\n![](./data/swish.png)\n\n* gelu：高斯误差线性单元激活函数。在Transformer中表现最好。tf.nn模块尚没有实现该函数。\n\n![](./data/gelu.png)\n\n```python\n\n```\n\n### 二，在模型中使用激活函数\n\n\n在keras模型中使用激活函数一般有两种方式，一种是作为某些层的activation参数指定，另一种是显式添加layers.Activation激活层。\n\n```python\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras import layers,models\n\ntf.keras.backend.clear_session()\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(32,input_shape = (None,16),activation = tf.nn.relu)) #通过activation参数指定\nmodel.add(layers.Dense(10))\nmodel.add(layers.Activation(tf.nn.softmax))  # 显式添加layers.Activation激活层\nmodel.summary()\n\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n\n```python\n\n```\n"
        },
        {
          "name": "5-4,模型层layers.md",
          "type": "blob",
          "size": 10.763671875,
          "content": "# 5-4,模型层layers\n\n深度学习模型一般由各种模型层组合而成。\n\ntf.keras.layers内置了非常丰富的各种功能的模型层。例如，\n\nlayers.Dense,layers.Flatten,layers.Input,layers.DenseFeature,layers.Dropout\n\nlayers.Conv2D,layers.MaxPooling2D,layers.Conv1D\n\nlayers.Embedding,layers.GRU,layers.LSTM,layers.Bidirectional等等。\n\n如果这些内置模型层不能够满足需求，我们也可以通过编写tf.keras.Lambda匿名模型层或继承tf.keras.layers.Layer基类构建自定义的模型层。\n\n其中tf.keras.Lambda匿名模型层只适用于构造没有学习参数的模型层。\n\n```python\n\n```\n\n### 一，内置模型层\n\n\n一些常用的内置模型层简单介绍如下。\n\n**基础层**\n\n* Dense：密集连接层。参数个数 = 输入层特征数× 输出层特征数(weight)＋ 输出层特征数(bias)\n\n* Activation：激活函数层。一般放在Dense层后面，等价于在Dense层中指定activation。\n\n* Dropout：随机置零层。训练期间以一定几率将输入置0，一种正则化手段。\n\n* BatchNormalization：批标准化层。通过线性变换将输入批次缩放平移到稳定的均值和标准差。可以增强模型对输入不同分布的适应性，加快模型训练速度，有轻微正则化效果。一般在激活函数之前使用。\n\n* SpatialDropout2D：空间随机置零层。训练期间以一定几率将整个特征图置0，一种正则化手段，有利于避免特征图之间过高的相关性。\n\n* Input：输入层。通常使用Functional API方式构建模型时作为第一层。\n\n* DenseFeature：特征列接入层，用于接收一个特征列列表并产生一个密集连接层。\n\n* Flatten：压平层，用于将多维张量压成一维。\n\n* Reshape：形状重塑层，改变输入张量的形状。\n\n* Concatenate：拼接层，将多个张量在某个维度上拼接。\n\n* Add：加法层。\n\n* Subtract： 减法层。\n\n* Maximum：取最大值层。\n\n* Minimum：取最小值层。\n\n\n**卷积网络相关层**\n\n* Conv1D：普通一维卷积，常用于文本。参数个数 = 输入通道数×卷积核尺寸(如3)×卷积核个数\n\n* Conv2D：普通二维卷积，常用于图像。参数个数 = 输入通道数×卷积核尺寸(如3乘3)×卷积核个数\n\n* Conv3D：普通三维卷积，常用于视频。参数个数 = 输入通道数×卷积核尺寸(如3乘3乘3)×卷积核个数\n\n* SeparableConv2D：二维深度可分离卷积层。不同于普通卷积同时对区域和通道操作，深度可分离卷积先操作区域，再操作通道。即先对每个通道做独立卷积操作区域，再用1乘1卷积跨通道组合操作通道。参数个数 = 输入通道数×卷积核尺寸 + 输入通道数×1×1×输出通道数。深度可分离卷积的参数数量一般远小于普通卷积，效果一般也更好。\n\n* DepthwiseConv2D：二维深度卷积层。仅有SeparableConv2D前半部分操作，即只操作区域，不操作通道，一般输出通道数和输入通道数相同，但也可以通过设置depth_multiplier让输出通道为输入通道的若干倍数。输出通道数 = 输入通道数 × depth_multiplier。参数个数 = 输入通道数×卷积核尺寸× depth_multiplier。\n\n* Conv2DTranspose：二维卷积转置层，俗称反卷积层。并非卷积的逆操作，但在卷积核相同的情况下，当其输入尺寸是卷积操作输出尺寸的情况下，卷积转置的输出尺寸恰好是卷积操作的输入尺寸。\n\n* LocallyConnected2D: 二维局部连接层。类似Conv2D，唯一的差别是没有空间上的权值共享，所以其参数个数远高于二维卷积。\n\n* MaxPool2D: 二维最大池化层。也称作下采样层。池化层无可训练参数，主要作用是降维。\n\n* AveragePooling2D: 二维平均池化层。\n\n* GlobalMaxPool2D: 全局最大池化层。每个通道仅保留一个值。一般从卷积层过渡到全连接层时使用，是Flatten的替代方案。\n\n* GlobalAvgPool2D: 全局平均池化层。每个通道仅保留一个值。\n\n\n**循环网络相关层**\n\n* Embedding：嵌入层。一种比Onehot更加有效的对离散特征进行编码的方法。一般用于将输入中的单词映射为稠密向量。嵌入层的参数需要学习。\n\n* LSTM：长短记忆循环网络层。最普遍使用的循环网络层。具有携带轨道，遗忘门，更新门，输出门。可以较为有效地缓解梯度消失问题，从而能够适用长期依赖问题。设置return_sequences = True时可以返回各个中间步骤输出，否则只返回最终输出。\n\n* GRU：门控循环网络层。LSTM的低配版，不具有携带轨道，参数数量少于LSTM，训练速度更快。\n\n* SimpleRNN：简单循环网络层。容易存在梯度消失，不能够适用长期依赖问题。一般较少使用。\n\n* ConvLSTM2D：卷积长短记忆循环网络层。结构上类似LSTM，但对输入的转换操作和对状态的转换操作都是卷积运算。\n\n* Bidirectional：双向循环网络包装器。可以将LSTM，GRU等层包装成双向循环网络。从而增强特征提取能力。\n\n* RNN：RNN基本层。接受一个循环网络单元或一个循环单元列表，通过调用tf.keras.backend.rnn函数在序列上进行迭代从而转换成循环网络层。\n\n* LSTMCell：LSTM单元。和LSTM在整个序列上迭代相比，它仅在序列上迭代一步。可以简单理解LSTM即RNN基本层包裹LSTMCell。\n\n* GRUCell：GRU单元。和GRU在整个序列上迭代相比，它仅在序列上迭代一步。\n\n* SimpleRNNCell：SimpleRNN单元。和SimpleRNN在整个序列上迭代相比，它仅在序列上迭代一步。\n\n* AbstractRNNCell：抽象RNN单元。通过对它的子类化用户可以自定义RNN单元，再通过RNN基本层的包裹实现用户自定义循环网络层。\n\n* Attention：Dot-product类型注意力机制层。可以用于构建注意力模型。\n\n* AdditiveAttention：Additive类型注意力机制层。可以用于构建注意力模型。\n\n* TimeDistributed：时间分布包装器。包装后可以将Dense、Conv2D等作用到每一个时间片段上。\n\n```python\n\n```\n\n### 二，自定义模型层\n\n\n如果自定义模型层没有需要被训练的参数，一般推荐使用Lamda层实现。\n\n如果自定义模型层有需要被训练的参数，则可以通过对Layer基类子类化实现。\n\nLambda层由于没有需要被训练的参数，只需要定义正向传播逻辑即可，使用比Layer基类子类化更加简单。\n\nLambda层的正向逻辑可以使用Python的lambda函数来表达，也可以用def关键字定义函数来表达。\n\n```python\nimport tensorflow as tf\nfrom tensorflow.keras import layers,models,regularizers\n\nmypower = layers.Lambda(lambda x:tf.math.pow(x,2))\nmypower(tf.range(5))\n```\n\n```\n<tf.Tensor: shape=(5,), dtype=int32, numpy=array([ 0,  1,  4,  9, 16], dtype=int32)>\n```\n\n\nLayer的子类化一般需要重新实现初始化方法，Build方法和Call方法。下面是一个简化的线性层的范例，类似Dense.\n\n```python\nclass Linear(layers.Layer):\n    def __init__(self, units=32, **kwargs):\n        super(Linear, self).__init__(**kwargs)\n        self.units = units\n    \n    #build方法一般定义Layer需要被训练的参数。    \n    def build(self, input_shape): \n        self.w = self.add_weight(\"w\",shape=(input_shape[-1], self.units),\n                                 initializer='random_normal',\n                                 trainable=True) #注意必须要有参数名称\"w\",否则会报错\n        self.b = self.add_weight(\"b\",shape=(self.units,),\n                                 initializer='random_normal',\n                                 trainable=True)\n        super(Linear,self).build(input_shape) # 相当于设置self.built = True\n\n    #call方法一般定义正向传播运算逻辑，__call__方法调用了它。  \n    @tf.function\n    def call(self, inputs): \n        return tf.matmul(inputs, self.w) + self.b\n    \n    #如果要让自定义的Layer通过Functional API 组合成模型时可以被保存成h5模型，需要自定义get_config方法。\n    def get_config(self):  \n        config = super(Linear, self).get_config()\n        config.update({'units': self.units})\n        return config\n\n```\n\n```python\nlinear = Linear(units = 8)\nprint(linear.built)\n#指定input_shape，显式调用build方法，第0维代表样本数量，用None填充\nlinear.build(input_shape = (None,16)) \nprint(linear.built)\n```\n\n```\nFalse\nTrue\n```\n\n```python\nlinear = Linear(units = 8)\nprint(linear.built)\nlinear.build(input_shape = (None,16)) \nprint(linear.compute_output_shape(input_shape = (None,16)))\n```\n\n```\nFalse\n(None, 8)\n```\n\n```python\nlinear = Linear(units = 16)\nprint(linear.built)\n#如果built = False，调用__call__时会先调用build方法, 再调用call方法。\nlinear(tf.random.uniform((100,64))) \nprint(linear.built)\nconfig = linear.get_config()\nprint(config)\n```\n\n```\nFalse\nTrue\n{'name': 'linear_3', 'trainable': True, 'dtype': 'float32', 'units': 16}\n```\n\n```python\ntf.keras.backend.clear_session()\n\nmodel = models.Sequential()\n#注意该处的input_shape会被模型加工，无需使用None代表样本数量维\nmodel.add(Linear(units = 1,input_shape = (2,)))  \nprint(\"model.input_shape: \",model.input_shape)\nprint(\"model.output_shape: \",model.output_shape)\nmodel.summary()\n```\n\n```\nmodel.input_shape:  (None, 2)\nmodel.output_shape:  (None, 1)\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlinear (Linear)              (None, 1)                 3         \n=================================================================\nTotal params: 3\nTrainable params: 3\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n```python\nmodel.compile(optimizer = \"sgd\",loss = \"mse\",metrics=[\"mae\"])\nprint(model.predict(tf.constant([[3.0,2.0],[4.0,5.0]])))\n\n\n# 保存成 h5模型\nmodel.save(\"./data/linear_model.h5\",save_format = \"h5\")\nmodel_loaded_keras = tf.keras.models.load_model(\n    \"./data/linear_model.h5\",custom_objects={\"Linear\":Linear})\nprint(model_loaded_keras.predict(tf.constant([[3.0,2.0],[4.0,5.0]])))\n\n\n# 保存成 tf模型\nmodel.save(\"./data/linear_model\",save_format = \"tf\")\nmodel_loaded_tf = tf.keras.models.load_model(\"./data/linear_model\")\nprint(model_loaded_tf.predict(tf.constant([[3.0,2.0],[4.0,5.0]])))\n\n```\n\n```\n[[-0.04092304]\n [-0.06150477]]\n[[-0.04092304]\n [-0.06150477]]\nINFO:tensorflow:Assets written to: ./data/linear_model/assets\n[[-0.04092304]\n [-0.06150477]]\n```\n\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n"
        },
        {
          "name": "5-5,损失函数losses.md",
          "type": "blob",
          "size": 6.5712890625,
          "content": "# 5-5,损失函数losses\n\n一般来说，监督学习的目标函数由损失函数和正则化项组成。（Objective = Loss + Regularization）\n\n对于keras模型，目标函数中的正则化项一般在各层中指定，例如使用Dense的 kernel_regularizer 和 bias_regularizer等参数指定权重使用l1或者l2正则化项，此外还可以用kernel_constraint 和 bias_constraint等参数约束权重的取值范围，这也是一种正则化手段。\n\n损失函数在模型编译时候指定。对于回归模型，通常使用的损失函数是均方损失函数 mean_squared_error。\n\n对于二分类模型，通常使用的是二元交叉熵损失函数 binary_crossentropy。\n\n对于多分类模型，如果label是one-hot编码的，则使用类别交叉熵损失函数 categorical_crossentropy。如果label是类别序号编码的，则需要使用稀疏类别交叉熵损失函数 sparse_categorical_crossentropy。\n\n如果有需要，也可以自定义损失函数，自定义损失函数需要接收两个张量y_true,y_pred作为输入参数，并输出一个标量作为损失函数值。\n\n\n```python\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras import layers,models,losses,regularizers,constraints\n```\n\n### 一，损失函数和正则化项\n\n```python\ntf.keras.backend.clear_session()\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(64, input_dim=64,\n                kernel_regularizer=regularizers.l2(0.01), \n                activity_regularizer=regularizers.l1(0.01),\n                kernel_constraint = constraints.MaxNorm(max_value=2, axis=0))) \nmodel.add(layers.Dense(10,\n        kernel_regularizer=regularizers.l1_l2(0.01,0.01),activation = \"sigmoid\"))\nmodel.compile(optimizer = \"rmsprop\",\n        loss = \"binary_crossentropy\",metrics = [\"AUC\"])\nmodel.summary()\n\n```\n\n```\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 64)                4160      \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                650       \n=================================================================\nTotal params: 4,810\nTrainable params: 4,810\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n\n### 二，内置损失函数\n\n\n内置的损失函数一般有类的实现和函数的实现两种形式。\n\n如：CategoricalCrossentropy 和 categorical_crossentropy 都是类别交叉熵损失函数，前者是类的实现形式，后者是函数的实现形式。\n\n常用的一些内置损失函数说明如下。\n\n* mean_squared_error（均方误差损失，用于回归，简写为 mse, 类与函数实现形式分别为 MeanSquaredError 和 MSE）\n\n* mean_absolute_error (平均绝对值误差损失，用于回归，简写为 mae, 类与函数实现形式分别为 MeanAbsoluteError 和 MAE)\n\n* mean_absolute_percentage_error (平均百分比误差损失，用于回归，简写为 mape, 类与函数实现形式分别为 MeanAbsolutePercentageError 和 MAPE)\n\n* Huber(Huber损失，只有类实现形式，用于回归，介于mse和mae之间，对异常值比较鲁棒，相对mse有一定的优势)\n\n* binary_crossentropy(二元交叉熵，用于二分类，类实现形式为 BinaryCrossentropy)\n\n* categorical_crossentropy(类别交叉熵，用于多分类，要求label为onehot编码，类实现形式为 CategoricalCrossentropy)\n\n* sparse_categorical_crossentropy(稀疏类别交叉熵，用于多分类，要求label为序号编码形式，类实现形式为 SparseCategoricalCrossentropy)\n\n* hinge(合页损失函数，用于二分类，最著名的应用是作为支持向量机SVM的损失函数，类实现形式为 Hinge)\n\n* kld(相对熵损失，也叫KL散度，常用于最大期望算法EM的损失函数，两个概率分布差异的一种信息度量。类与函数实现形式分别为 KLDivergence 或 KLD)\n\n* cosine_similarity(余弦相似度，可用于多分类，类实现形式为 CosineSimilarity)\n\n```python\n\n```\n\n### 三，自定义损失函数\n\n\n自定义损失函数接收两个张量y_true,y_pred作为输入参数，并输出一个标量作为损失函数值。\n\n也可以对tf.keras.losses.Loss进行子类化，重写call方法实现损失的计算逻辑，从而得到损失函数的类的实现。\n\n下面是一个Focal Loss的自定义实现示范。Focal Loss是一种对binary_crossentropy的改进损失函数形式。\n\n它在样本不均衡和存在较多易分类的样本时相比binary_crossentropy具有明显的优势。\n\n它有两个可调参数，alpha参数和gamma参数。其中alpha参数主要用于衰减负样本的权重，gamma参数主要用于衰减容易训练样本的权重。\n\n从而让模型更加聚焦在正样本和困难样本上。这就是为什么这个损失函数叫做Focal Loss。\n\n详见《5分钟理解Focal Loss与GHM——解决样本不平衡利器》\n\nhttps://zhuanlan.zhihu.com/p/80594704\n\n\n$$focal\\_loss(y,p) = \\begin{cases}\n-\\alpha  (1-p)^{\\gamma}\\log(p) &\n\\text{if y = 1}\\\\\n-(1-\\alpha) p^{\\gamma}\\log(1-p) &\n\\text{if y = 0}\n\\end{cases} $$\n\n```python\ndef focal_loss(gamma=2., alpha=0.75):\n    \n    def focal_loss_fixed(y_true, y_pred):\n        bce = tf.losses.binary_crossentropy(y_true, y_pred)\n        p_t = (y_true * y_pred) + ((1 - y_true) * (1 - y_pred))\n        alpha_factor = y_true * alpha + (1 - y_true) * (1 - alpha)\n        modulating_factor = tf.pow(1.0 - p_t, gamma)\n        loss = tf.reduce_sum(alpha_factor * modulating_factor * bce,axis = -1 )\n        return loss\n    return focal_loss_fixed\n\n```\n\n```python\nclass FocalLoss(tf.keras.losses.Loss):\n    \n    def __init__(self,gamma=2.0,alpha=0.75,name = \"focal_loss\"):\n        self.gamma = gamma\n        self.alpha = alpha\n\n    def call(self,y_true,y_pred):\n        bce = tf.losses.binary_crossentropy(y_true, y_pred)\n        p_t = (y_true * y_pred) + ((1 - y_true) * (1 - y_pred))\n        alpha_factor = y_true * self.alpha + (1 - y_true) * (1 - self.alpha)\n        modulating_factor = tf.pow(1.0 - p_t, self.gamma)\n        loss = tf.reduce_sum(alpha_factor * modulating_factor * bce,axis = -1 )\n        return loss\n\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n\n```python\n\n```\n"
        },
        {
          "name": "5-6,评估指标metrics.md",
          "type": "blob",
          "size": 6.5732421875,
          "content": "# 5-6,评估指标metrics\n\n损失函数除了作为模型训练时候的优化目标，也能够作为模型好坏的一种评价指标。但通常人们还会从其它角度评估模型的好坏。\n\n这就是评估指标。通常损失函数都可以作为评估指标，如MAE,MSE,CategoricalCrossentropy等也是常用的评估指标。\n\n但评估指标不一定可以作为损失函数，例如AUC,Accuracy,Precision。因为评估指标不要求连续可导，而损失函数通常要求连续可导。\n\n编译模型时，可以通过列表形式指定多个评估指标。\n\n如果有需要，也可以自定义评估指标。\n\n自定义评估指标需要接收两个张量y_true,y_pred作为输入参数，并输出一个标量作为评估值。\n\n也可以对tf.keras.metrics.Metric进行子类化，重写初始化方法, update_state方法, result方法实现评估指标的计算逻辑，从而得到评估指标的类的实现形式。\n\n由于训练的过程通常是分批次训练的，而评估指标要跑完一个epoch才能够得到整体的指标结果。因此，类形式的评估指标更为常见。即需要编写初始化方法以创建与计算指标结果相关的一些中间变量，编写update_state方法在每个batch后更新相关中间变量的状态，编写result方法输出最终指标结果。\n\n如果编写函数形式的评估指标，则只能取epoch中各个batch计算的评估指标结果的平均值作为整个epoch上的评估指标结果，这个结果通常会偏离整个epoch数据一次计算的结果。\n\n\n\n### 一，常用的内置评估指标\n\n\n* MeanSquaredError（均方误差，用于回归，可以简写为MSE，函数形式为mse）\n\n* MeanAbsoluteError (平均绝对值误差，用于回归，可以简写为MAE，函数形式为mae)\n\n* MeanAbsolutePercentageError (平均百分比误差，用于回归，可以简写为MAPE，函数形式为mape)\n\n* RootMeanSquaredError (均方根误差，用于回归)\n\n* Accuracy (准确率，用于分类，可以用字符串\"Accuracy\"表示，Accuracy=(TP+TN)/(TP+TN+FP+FN)，要求y_true和y_pred都为类别序号编码)\n\n* Precision (精确率，用于二分类，Precision = TP/(TP+FP))\n\n* Recall (召回率，用于二分类，Recall = TP/(TP+FN))\n\n* TruePositives (真正例，用于二分类)\n\n* TrueNegatives (真负例，用于二分类)\n\n* FalsePositives (假正例，用于二分类)\n\n* FalseNegatives (假负例，用于二分类)\n\n* AUC(ROC曲线(TPR vs FPR)下的面积，用于二分类，直观解释为随机抽取一个正样本和一个负样本，正样本的预测值大于负样本的概率)\n\n* CategoricalAccuracy（分类准确率，与Accuracy含义相同，要求y_true(label)为onehot编码形式）\n\n* SparseCategoricalAccuracy (稀疏分类准确率，与Accuracy含义相同，要求y_true(label)为序号编码形式)\n\n* MeanIoU (Intersection-Over-Union，常用于图像分割)\n\n* TopKCategoricalAccuracy (多分类TopK准确率，要求y_true(label)为onehot编码形式)\n\n* SparseTopKCategoricalAccuracy (稀疏多分类TopK准确率，要求y_true(label)为序号编码形式)\n\n* Mean (平均值)\n\n* Sum (求和)\n\n```python\n\n```\n\n```python\n\n```\n\n### 二， 自定义评估指标\n\n\n我们以金融风控领域常用的KS指标为例，示范自定义评估指标。\n\nKS指标适合二分类问题，其计算方式为 KS=max(TPR-FPR).\n\n其中TPR=TP/(TP+FN) , FPR = FP/(FP+TN) \n\nTPR曲线实际上就是正样本的累积分布曲线(CDF)，FPR曲线实际上就是负样本的累积分布曲线(CDF)。\n\nKS指标就是正样本和负样本累积分布曲线差值的最大值。\n\n![](./data/KS_curve.png)\n\n```python\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras import layers,models,losses,metrics\n\n#函数形式的自定义评估指标\n@tf.function\ndef ks(y_true,y_pred):\n    y_true = tf.reshape(y_true,(-1,))\n    y_pred = tf.reshape(y_pred,(-1,))\n    length = tf.shape(y_true)[0]\n    t = tf.math.top_k(y_pred,k = length,sorted = False)\n    y_pred_sorted = tf.gather(y_pred,t.indices)\n    y_true_sorted = tf.gather(y_true,t.indices)\n    cum_positive_ratio = tf.truediv(\n        tf.cumsum(y_true_sorted),tf.reduce_sum(y_true_sorted))\n    cum_negative_ratio = tf.truediv(\n        tf.cumsum(1 - y_true_sorted),tf.reduce_sum(1 - y_true_sorted))\n    ks_value = tf.reduce_max(tf.abs(cum_positive_ratio - cum_negative_ratio)) \n    return ks_value\n```\n\n```python\ny_true = tf.constant([[1],[1],[1],[0],[1],[1],[1],[0],[0],[0],[1],[0],[1],[0]])\ny_pred = tf.constant([[0.6],[0.1],[0.4],[0.5],[0.7],[0.7],[0.7],\n                      [0.4],[0.4],[0.5],[0.8],[0.3],[0.5],[0.3]])\ntf.print(ks(y_true,y_pred))\n```\n\n```\n0.625\n```\n\n```python\n#类形式的自定义评估指标\nclass KS(metrics.Metric):\n    \n    def __init__(self, name = \"ks\", **kwargs):\n        super(KS,self).__init__(name=name,**kwargs)\n        self.true_positives = self.add_weight(\n            name = \"tp\",shape = (101,), initializer = \"zeros\")\n        self.false_positives = self.add_weight(\n            name = \"fp\",shape = (101,), initializer = \"zeros\")\n   \n    @tf.function\n    def update_state(self,y_true,y_pred):\n        y_true = tf.cast(tf.reshape(y_true,(-1,)),tf.bool)\n        y_pred = tf.cast(100*tf.reshape(y_pred,(-1,)),tf.int32)\n        \n        for i in tf.range(0,tf.shape(y_true)[0]):\n            if y_true[i]:\n                self.true_positives[y_pred[i]].assign(\n                    self.true_positives[y_pred[i]]+1.0)\n            else:\n                self.false_positives[y_pred[i]].assign(\n                    self.false_positives[y_pred[i]]+1.0)\n        return (self.true_positives,self.false_positives)\n    \n    @tf.function\n    def result(self):\n        cum_positive_ratio = tf.truediv(\n            tf.cumsum(self.true_positives),tf.reduce_sum(self.true_positives))\n        cum_negative_ratio = tf.truediv(\n            tf.cumsum(self.false_positives),tf.reduce_sum(self.false_positives))\n        ks_value = tf.reduce_max(tf.abs(cum_positive_ratio - cum_negative_ratio)) \n        return ks_value\n\n```\n\n```python\ny_true = tf.constant([[1],[1],[1],[0],[1],[1],[1],[0],[0],[0],[1],[0],[1],[0]])\ny_pred = tf.constant([[0.6],[0.1],[0.4],[0.5],[0.7],[0.7],\n                      [0.7],[0.4],[0.4],[0.5],[0.8],[0.3],[0.5],[0.3]])\n\nmyks = KS()\nmyks.update_state(y_true,y_pred)\ntf.print(myks.result())\n\n```\n\n```\n0.625\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n"
        },
        {
          "name": "5-7,优化器optimizers.md",
          "type": "blob",
          "size": 6.4384765625,
          "content": "# 5-7,优化器optimizers\n\n机器学习界有一群炼丹师，他们每天的日常是：\n\n拿来药材（数据），架起八卦炉（模型），点着六味真火（优化算法），就摇着蒲扇等着丹药出炉了。\n\n不过，当过厨子的都知道，同样的食材，同样的菜谱，但火候不一样了，这出来的口味可是千差万别。火小了夹生，火大了易糊，火不匀则半生半糊。\n\n机器学习也是一样，模型优化算法的选择直接关系到最终模型的性能。有时候效果不好，未必是特征的问题或者模型设计的问题，很可能就是优化算法的问题。\n\n深度学习优化算法大概经历了 SGD -> SGDM -> NAG ->Adagrad -> Adadelta(RMSprop) -> Adam -> Nadam 这样的发展历程。\n\n详见《一个框架看懂优化算法之异同 SGD/AdaGrad/Adam》\n\nhttps://zhuanlan.zhihu.com/p/32230623\n\n对于一般新手炼丹师，优化器直接使用Adam，并使用其默认参数就OK了。\n\n一些爱写论文的炼丹师由于追求评估指标效果，可能会偏爱前期使用Adam优化器快速下降，后期使用SGD并精调优化器参数得到更好的结果。\n\n此外目前也有一些前沿的优化算法，据称效果比Adam更好，例如LazyAdam, Look-ahead, RAdam, Ranger等.\n\n\n```python\n\n```\n\n### 一，优化器的使用\n\n\n优化器主要使用apply_gradients方法传入变量和对应梯度从而来对给定变量进行迭代，或者直接使用minimize方法对目标函数进行迭代优化。\n\n当然，更常见的使用是在编译时将优化器传入keras的Model,通过调用model.fit实现对Loss的的迭代优化。\n\n初始化优化器时会创建一个变量optimier.iterations用于记录迭代的次数。因此优化器和tf.Variable一样，一般需要在@tf.function外创建。\n\n```python\nimport tensorflow as tf\nimport numpy as np \n\n#打印时间分割线\n@tf.function\ndef printbar():\n    ts = tf.timestamp()\n    today_ts = ts%(24*60*60)\n\n    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\n    minite = tf.cast((today_ts%3600)//60,tf.int32)\n    second = tf.cast(tf.floor(today_ts%60),tf.int32)\n    \n    def timeformat(m):\n        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\n            return(tf.strings.format(\"0{}\",m))\n        else:\n            return(tf.strings.format(\"{}\",m))\n    \n    timestring = tf.strings.join([timeformat(hour),timeformat(minite),\n                timeformat(second)],separator = \":\")\n    tf.print(\"==========\"*8,end = \"\")\n    tf.print(timestring)\n    \n```\n\n```python\n# 求f(x) = a*x**2 + b*x + c的最小值\n\n# 使用optimizer.apply_gradients\n\nx = tf.Variable(0.0,name = \"x\",dtype = tf.float32)\noptimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n\n@tf.function\ndef minimizef():\n    a = tf.constant(1.0)\n    b = tf.constant(-2.0)\n    c = tf.constant(1.0)\n    \n    while tf.constant(True): \n        with tf.GradientTape() as tape:\n            y = a*tf.pow(x,2) + b*x + c\n        dy_dx = tape.gradient(y,x)\n        optimizer.apply_gradients(grads_and_vars=[(dy_dx,x)])\n        \n        #迭代终止条件\n        if tf.abs(dy_dx)<tf.constant(0.00001):\n            break\n            \n        if tf.math.mod(optimizer.iterations,100)==0:\n            printbar()\n            tf.print(\"step = \",optimizer.iterations)\n            tf.print(\"x = \", x)\n            tf.print(\"\")\n                \n    y = a*tf.pow(x,2) + b*x + c\n    return y\n\ntf.print(\"y =\",minimizef())\ntf.print(\"x =\",x)\n```\n\n```python\n\n```\n\n```python\n# 求f(x) = a*x**2 + b*x + c的最小值\n\n# 使用optimizer.minimize\n\nx = tf.Variable(0.0,name = \"x\",dtype = tf.float32)\noptimizer = tf.keras.optimizers.SGD(learning_rate=0.01)   \n\ndef f():   \n    a = tf.constant(1.0)\n    b = tf.constant(-2.0)\n    c = tf.constant(1.0)\n    y = a*tf.pow(x,2)+b*x+c\n    return(y)\n\n@tf.function\ndef train(epoch = 1000):  \n    for _ in tf.range(epoch):  \n        optimizer.minimize(f,[x])\n    tf.print(\"epoch = \",optimizer.iterations)\n    return(f())\n\ntrain(1000)\ntf.print(\"y = \",f())\ntf.print(\"x = \",x)\n\n```\n\n```python\n\n```\n\n```python\n# 求f(x) = a*x**2 + b*x + c的最小值\n# 使用model.fit\n\ntf.keras.backend.clear_session()\n\nclass FakeModel(tf.keras.models.Model):\n    def __init__(self,a,b,c):\n        super(FakeModel,self).__init__()\n        self.a = a\n        self.b = b\n        self.c = c\n    \n    def build(self):\n        self.x = tf.Variable(0.0,name = \"x\")\n        self.built = True\n    \n    def call(self,features):\n        loss  = self.a*(self.x)**2+self.b*(self.x)+self.c\n        return(tf.ones_like(features)*loss)\n    \ndef myloss(y_true,y_pred):\n    return tf.reduce_mean(y_pred)\n\nmodel = FakeModel(tf.constant(1.0),tf.constant(-2.0),tf.constant(1.0))\n\nmodel.build()\nmodel.summary()\n\nmodel.compile(optimizer = \n              tf.keras.optimizers.SGD(learning_rate=0.01),loss = myloss)\nhistory = model.fit(tf.zeros((100,2)),\n                    tf.ones(100),batch_size = 1,epochs = 10)  #迭代1000次\n\n```\n\n```python\ntf.print(\"x=\",model.x)\ntf.print(\"loss=\",model(tf.constant(0.0)))\n```\n\n```python\n\n```\n\n### 二，内置优化器\n\n\n深度学习优化算法大概经历了 SGD -> SGDM -> NAG ->Adagrad -> Adadelta(RMSprop) -> Adam -> Nadam 这样的发展历程。\n\n在keras.optimizers子模块中，它们基本上都有对应的类的实现。\n\n* SGD, 默认参数为纯SGD, 设置momentum参数不为0实际上变成SGDM, 考虑了一阶动量, 设置 nesterov为True后变成NAG，即 Nesterov Accelerated Gradient，在计算梯度时计算的是向前走一步所在位置的梯度。\n\n* Adagrad, 考虑了二阶动量，对于不同的参数有不同的学习率，即自适应学习率。缺点是学习率单调下降，可能后期学习速率过慢乃至提前停止学习。\n\n* RMSprop, 考虑了二阶动量，对于不同的参数有不同的学习率，即自适应学习率，对Adagrad进行了优化，通过指数平滑只考虑一定窗口内的二阶动量。\n\n* Adadelta, 考虑了二阶动量，与RMSprop类似，但是更加复杂一些，自适应性更强。\n\n* Adam, 同时考虑了一阶动量和二阶动量，可以看成RMSprop上进一步考虑了一阶动量。\n\n* Nadam, 在Adam基础上进一步考虑了 Nesterov Acceleration。\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n\n```python\n\n```\n\n```python\n\n```\n"
        },
        {
          "name": "5-8,回调函数callbacks.md",
          "type": "blob",
          "size": 5.2548828125,
          "content": "# 5-8,回调函数callbacks\n\ntf.keras的回调函数实际上是一个类，一般是在model.fit时作为参数指定，用于控制在训练过程开始或者在训练过程结束，在每个epoch训练开始或者训练结束，在每个batch训练开始或者训练结束时执行一些操作，例如收集一些日志信息，改变学习率等超参数，提前终止训练过程等等。\n\n同样地，针对model.evaluate或者model.predict也可以指定callbacks参数，用于控制在评估或预测开始或者结束时，在每个batch开始或者结束时执行一些操作，但这种用法相对少见。\n\n大部分时候，keras.callbacks子模块中定义的回调函数类已经足够使用了，如果有特定的需要，我们也可以通过对keras.callbacks.Callbacks实施子类化构造自定义的回调函数。\n\n所有回调函数都继承至 keras.callbacks.Callbacks基类，拥有params和model这两个属性。\n\n其中params 是一个dict，记录了训练相关参数 (例如 verbosity, batch size, number of epochs 等等)。\n\nmodel即当前关联的模型的引用。\n\n此外，对于回调类中的一些方法如on_epoch_begin,on_batch_end，还会有一个输入参数logs, 提供有关当前epoch或者batch的一些信息，并能够记录计算结果，如果model.fit指定了多个回调函数类，这些logs变量将在这些回调函数类的同名函数间依顺序传递。\n\n\n\n### 一，内置回调函数\n\n\n* BaseLogger： 收集每个epoch上metrics在各个batch上的平均值，对stateful_metrics参数中的带中间状态的指标直接拿最终值无需对各个batch平均，指标均值结果将添加到logs变量中。该回调函数被所有模型默认添加，且是第一个被添加的。\n\n* History： 将BaseLogger计算的各个epoch的metrics结果记录到history这个dict变量中，并作为model.fit的返回值。该回调函数被所有模型默认添加，在BaseLogger之后被添加。\n\n* EarlyStopping： 当被监控指标在设定的若干个epoch后没有提升，则提前终止训练。\n\n* TensorBoard： 为Tensorboard可视化保存日志信息。支持评估指标，计算图，模型参数等的可视化。\n\n* ModelCheckpoint： 在每个epoch后保存模型。\n\n* ReduceLROnPlateau：如果监控指标在设定的若干个epoch后没有提升，则以一定的因子减少学习率。\n\n* TerminateOnNaN：如果遇到loss为NaN，提前终止训练。\n\n* LearningRateScheduler：学习率控制器。给定学习率lr和epoch的函数关系，根据该函数关系在每个epoch前调整学习率。\n\n* CSVLogger：将每个epoch后的logs结果记录到CSV文件中。\n\n* ProgbarLogger：将每个epoch后的logs结果打印到标准输出流中。\n\n\n\n```python\n\n```\n\n### 二，自定义回调函数\n\n\n可以使用callbacks.LambdaCallback编写较为简单的回调函数，也可以通过对callbacks.Callback子类化编写更加复杂的回调函数逻辑。\n\n如果需要深入学习tf.Keras中的回调函数，不要犹豫阅读内置回调函数的源代码。\n\n```python\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras import layers,models,losses,metrics,callbacks\nimport tensorflow.keras.backend as K \n\n```\n\n```python\n# 示范使用LambdaCallback编写较为简单的回调函数\n\nimport json\njson_log = open('./data/keras_log.json', mode='wt', buffering=1)\njson_logging_callback = callbacks.LambdaCallback(\n    on_epoch_end=lambda epoch, logs: json_log.write(\n        json.dumps(dict(epoch = epoch,**logs)) + '\\n'),\n    on_train_end=lambda logs: json_log.close()\n)\n\n```\n\n```python\n# 示范通过Callback子类化编写回调函数（LearningRateScheduler的源代码）\n\nclass LearningRateScheduler(callbacks.Callback):\n    \n    def __init__(self, schedule, verbose=0):\n        super(LearningRateScheduler, self).__init__()\n        self.schedule = schedule\n        self.verbose = verbose\n\n    def on_epoch_begin(self, epoch, logs=None):\n        if not hasattr(self.model.optimizer, 'lr'):\n            raise ValueError('Optimizer must have a \"lr\" attribute.')\n        try:  \n            lr = float(K.get_value(self.model.optimizer.lr))\n            lr = self.schedule(epoch, lr)\n        except TypeError:  # Support for old API for backward compatibility\n            lr = self.schedule(epoch)\n        if not isinstance(lr, (tf.Tensor, float, np.float32, np.float64)):\n            raise ValueError('The output of the \"schedule\" function '\n                             'should be float.')\n        if isinstance(lr, ops.Tensor) and not lr.dtype.is_floating:\n            raise ValueError('The dtype of Tensor should be float')\n        K.set_value(self.model.optimizer.lr, K.get_value(lr))\n        if self.verbose > 0:\n            print('\\nEpoch %05d: LearningRateScheduler reducing learning '\n                 'rate to %s.' % (epoch + 1, lr))\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        logs['lr'] = K.get_value(self.model.optimizer.lr)\n\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n"
        },
        {
          "name": "6-1,构建模型的3种方法.md",
          "type": "blob",
          "size": 14.9130859375,
          "content": "# 6-1,构建模型的3种方法\n\n可以使用以下3种方式构建模型：使用Sequential按层顺序构建模型，使用函数式API构建任意结构模型，继承Model基类构建自定义模型。\n\n对于顺序结构的模型，优先使用Sequential方法构建。\n\n如果模型有多输入或者多输出，或者模型需要共享权重，或者模型具有残差连接等非顺序结构，推荐使用函数式API进行创建。\n\n如果无特定必要，尽可能避免使用Model子类化的方式构建模型，这种方式提供了极大的灵活性，但也有更大的概率出错。\n\n下面以IMDB电影评论的分类问题为例，演示3种创建模型的方法。\n\n```python\nimport numpy as np \nimport pandas as pd \nimport tensorflow as tf\nfrom tqdm import tqdm \nfrom tensorflow.keras import *\n\n\ntrain_token_path = \"./data/imdb/train_token.csv\"\ntest_token_path = \"./data/imdb/test_token.csv\"\n\nMAX_WORDS = 10000  # We will only consider the top 10,000 words in the dataset\nMAX_LEN = 200  # We will cut reviews after 200 words\nBATCH_SIZE = 20 \n\n# 构建管道\ndef parse_line(line):\n    t = tf.strings.split(line,\"\\t\")\n    label = tf.reshape(tf.cast(tf.strings.to_number(t[0]),tf.int32),(-1,))\n    features = tf.cast(tf.strings.to_number(tf.strings.split(t[1],\" \")),tf.int32)\n    return (features,label)\n\nds_train=  tf.data.TextLineDataset(filenames = [train_token_path]) \\\n   .map(parse_line,num_parallel_calls = tf.data.experimental.AUTOTUNE) \\\n   .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n   .prefetch(tf.data.experimental.AUTOTUNE)\n\nds_test=  tf.data.TextLineDataset(filenames = [test_token_path]) \\\n   .map(parse_line,num_parallel_calls = tf.data.experimental.AUTOTUNE) \\\n   .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n   .prefetch(tf.data.experimental.AUTOTUNE)\n\n```\n\n```python\n\n```\n\n### 一，Sequential按层顺序创建模型\n\n```python\ntf.keras.backend.clear_session()\n\nmodel = models.Sequential()\n\nmodel.add(layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN))\nmodel.add(layers.Conv1D(filters = 64,kernel_size = 5,activation = \"relu\"))\nmodel.add(layers.MaxPool1D(2))\nmodel.add(layers.Conv1D(filters = 32,kernel_size = 3,activation = \"relu\"))\nmodel.add(layers.MaxPool1D(2))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(1,activation = \"sigmoid\"))\n\nmodel.compile(optimizer='Nadam',\n            loss='binary_crossentropy',\n            metrics=['accuracy',\"AUC\"])\n\nmodel.summary()\n```\n\n![](./data/Sequential模型结构.png)\n\n```python\nimport datetime\nbaselogger = callbacks.BaseLogger(stateful_metrics=[\"AUC\"])\nlogdir = \"./data/keras_model/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\nhistory = model.fit(ds_train,validation_data = ds_test,\n        epochs = 6,callbacks=[baselogger,tensorboard_callback])\n\n```\n\n```python\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\n\nimport matplotlib.pyplot as plt\n\ndef plot_metric(history, metric):\n    train_metrics = history.history[metric]\n    val_metrics = history.history['val_'+metric]\n    epochs = range(1, len(train_metrics) + 1)\n    plt.plot(epochs, train_metrics, 'bo--')\n    plt.plot(epochs, val_metrics, 'ro-')\n    plt.title('Training and validation '+ metric)\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(metric)\n    plt.legend([\"train_\"+metric, 'val_'+metric])\n    plt.show()\n```\n\n```python\nplot_metric(history,\"AUC\")\n```\n\n```python\n\n```\n\n![](./data/6-1-fit模型.jpg)\n\n```python\n\n```\n\n```python\n\n```\n\n### 二，函数式API创建任意结构模型\n\n```python\ntf.keras.backend.clear_session()\n\ninputs = layers.Input(shape=[MAX_LEN])\nx  = layers.Embedding(MAX_WORDS,7)(inputs)\n\nbranch1 = layers.SeparableConv1D(64,3,activation=\"relu\")(x)\nbranch1 = layers.MaxPool1D(3)(branch1)\nbranch1 = layers.SeparableConv1D(32,3,activation=\"relu\")(branch1)\nbranch1 = layers.GlobalMaxPool1D()(branch1)\n\nbranch2 = layers.SeparableConv1D(64,5,activation=\"relu\")(x)\nbranch2 = layers.MaxPool1D(5)(branch2)\nbranch2 = layers.SeparableConv1D(32,5,activation=\"relu\")(branch2)\nbranch2 = layers.GlobalMaxPool1D()(branch2)\n\nbranch3 = layers.SeparableConv1D(64,7,activation=\"relu\")(x)\nbranch3 = layers.MaxPool1D(7)(branch3)\nbranch3 = layers.SeparableConv1D(32,7,activation=\"relu\")(branch3)\nbranch3 = layers.GlobalMaxPool1D()(branch3)\n\nconcat = layers.Concatenate()([branch1,branch2,branch3])\noutputs = layers.Dense(1,activation = \"sigmoid\")(concat)\n\nmodel = models.Model(inputs = inputs,outputs = outputs)\n\nmodel.compile(optimizer='Nadam',\n            loss='binary_crossentropy',\n            metrics=['accuracy',\"AUC\"])\n\nmodel.summary()\n\n```\n\n```\nModel: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 200)]        0                                            \n__________________________________________________________________________________________________\nembedding (Embedding)           (None, 200, 7)       70000       input_1[0][0]                    \n__________________________________________________________________________________________________\nseparable_conv1d (SeparableConv (None, 198, 64)      533         embedding[0][0]                  \n__________________________________________________________________________________________________\nseparable_conv1d_2 (SeparableCo (None, 196, 64)      547         embedding[0][0]                  \n__________________________________________________________________________________________________\nseparable_conv1d_4 (SeparableCo (None, 194, 64)      561         embedding[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling1d (MaxPooling1D)    (None, 66, 64)       0           separable_conv1d[0][0]           \n__________________________________________________________________________________________________\nmax_pooling1d_1 (MaxPooling1D)  (None, 39, 64)       0           separable_conv1d_2[0][0]         \n__________________________________________________________________________________________________\nmax_pooling1d_2 (MaxPooling1D)  (None, 27, 64)       0           separable_conv1d_4[0][0]         \n__________________________________________________________________________________________________\nseparable_conv1d_1 (SeparableCo (None, 64, 32)       2272        max_pooling1d[0][0]              \n__________________________________________________________________________________________________\nseparable_conv1d_3 (SeparableCo (None, 35, 32)       2400        max_pooling1d_1[0][0]            \n__________________________________________________________________________________________________\nseparable_conv1d_5 (SeparableCo (None, 21, 32)       2528        max_pooling1d_2[0][0]            \n__________________________________________________________________________________________________\nglobal_max_pooling1d (GlobalMax (None, 32)           0           separable_conv1d_1[0][0]         \n__________________________________________________________________________________________________\nglobal_max_pooling1d_1 (GlobalM (None, 32)           0           separable_conv1d_3[0][0]         \n__________________________________________________________________________________________________\nglobal_max_pooling1d_2 (GlobalM (None, 32)           0           separable_conv1d_5[0][0]         \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 96)           0           global_max_pooling1d[0][0]       \n                                                                 global_max_pooling1d_1[0][0]     \n                                                                 global_max_pooling1d_2[0][0]     \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 1)            97          concatenate[0][0]                \n==================================================================================================\nTotal params: 78,938\nTrainable params: 78,938\nNon-trainable params: 0\n__________________________________________________________________________________________________\n```\n\n\n![](./data/FunctionalAPI模型结构.png)\n\n```python\nimport datetime\nlogdir = \"./data/keras_model/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\nhistory = model.fit(ds_train,validation_data = ds_test,epochs = 6,callbacks=[tensorboard_callback])\n\n```\n\n```\nEpoch 1/6\n1000/1000 [==============================] - 32s 32ms/step - loss: 0.5527 - accuracy: 0.6758 - AUC: 0.7731 - val_loss: 0.3646 - val_accuracy: 0.8426 - val_AUC: 0.9192\nEpoch 2/6\n1000/1000 [==============================] - 24s 24ms/step - loss: 0.3024 - accuracy: 0.8737 - AUC: 0.9444 - val_loss: 0.3281 - val_accuracy: 0.8644 - val_AUC: 0.9350\nEpoch 3/6\n1000/1000 [==============================] - 24s 24ms/step - loss: 0.2158 - accuracy: 0.9159 - AUC: 0.9715 - val_loss: 0.3461 - val_accuracy: 0.8666 - val_AUC: 0.9363\nEpoch 4/6\n1000/1000 [==============================] - 24s 24ms/step - loss: 0.1492 - accuracy: 0.9464 - AUC: 0.9859 - val_loss: 0.4017 - val_accuracy: 0.8568 - val_AUC: 0.9311\nEpoch 5/6\n1000/1000 [==============================] - 24s 24ms/step - loss: 0.0944 - accuracy: 0.9696 - AUC: 0.9939 - val_loss: 0.4998 - val_accuracy: 0.8550 - val_AUC: 0.9233\nEpoch 6/6\n1000/1000 [==============================] - 26s 26ms/step - loss: 0.0526 - accuracy: 0.9865 - AUC: 0.9977 - val_loss: 0.6463 - val_accuracy: 0.8462 - val_AUC: 0.9138\n```\n\n```python\nplot_metric(history,\"AUC\")\n```\n\n![](./data/6-1-2-train.jpg)\n\n```python\n\n```\n\n### 三，Model子类化创建自定义模型\n\n```python\n# 先自定义一个残差模块，为自定义Layer\n\nclass ResBlock(layers.Layer):\n    def __init__(self, kernel_size, **kwargs):\n        super(ResBlock, self).__init__(**kwargs)\n        self.kernel_size = kernel_size\n    \n    def build(self,input_shape):\n        self.conv1 = layers.Conv1D(filters=64,kernel_size=self.kernel_size,\n                                   activation = \"relu\",padding=\"same\")\n        self.conv2 = layers.Conv1D(filters=32,kernel_size=self.kernel_size,\n                                   activation = \"relu\",padding=\"same\")\n        self.conv3 = layers.Conv1D(filters=input_shape[-1],\n                                   kernel_size=self.kernel_size,activation = \"relu\",padding=\"same\")\n        self.maxpool = layers.MaxPool1D(2)\n        super(ResBlock,self).build(input_shape) # 相当于设置self.built = True\n    \n    def call(self, inputs):\n        x = self.conv1(inputs)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = layers.Add()([inputs,x])\n        x = self.maxpool(x)\n        return x\n    \n    #如果要让自定义的Layer通过Functional API 组合成模型时可以序列化，需要自定义get_config方法。\n    def get_config(self):  \n        config = super(ResBlock, self).get_config()\n        config.update({'kernel_size': self.kernel_size})\n        return config\n```\n\n```python\n# 测试ResBlock\nresblock = ResBlock(kernel_size = 3)\nresblock.build(input_shape = (None,200,7))\nresblock.compute_output_shape(input_shape=(None,200,7))\n\n```\n\n```\nTensorShape([None, 100, 7])\n```\n\n```python\n# 自定义模型，实际上也可以使用Sequential或者FunctionalAPI\n\nclass ImdbModel(models.Model):\n    def __init__(self):\n        super(ImdbModel, self).__init__()\n        \n    def build(self,input_shape):\n        self.embedding = layers.Embedding(MAX_WORDS,7)\n        self.block1 = ResBlock(7)\n        self.block2 = ResBlock(5)\n        self.dense = layers.Dense(1,activation = \"sigmoid\")\n        super(ImdbModel,self).build(input_shape)\n    \n    def call(self, x):\n        x = self.embedding(x)\n        x = self.block1(x)\n        x = self.block2(x)\n        x = layers.Flatten()(x)\n        x = self.dense(x)\n        return(x)\n\n```\n\n```python\ntf.keras.backend.clear_session()\n\nmodel = ImdbModel()\nmodel.build(input_shape =(None,200))\nmodel.summary()\n\nmodel.compile(optimizer='Nadam',\n            loss='binary_crossentropy',\n            metrics=['accuracy',\"AUC\"])\n\n```\n\n```\nModel: \"imdb_model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        multiple                  70000     \n_________________________________________________________________\nres_block (ResBlock)         multiple                  19143     \n_________________________________________________________________\nres_block_1 (ResBlock)       multiple                  13703     \n_________________________________________________________________\ndense (Dense)                multiple                  351       \n=================================================================\nTotal params: 103,197\nTrainable params: 103,197\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n```python\n\n```\n\n![](./data/Model子类化模型结构.png)\n\n```python\n\n```\n\n```python\nimport datetime\n\nlogdir = \"./tflogs/keras_model/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\nhistory = model.fit(ds_train,validation_data = ds_test,\n                    epochs = 6,callbacks=[tensorboard_callback])\n\n```\n\n```\nEpoch 1/6\n1000/1000 [==============================] - 47s 47ms/step - loss: 0.5629 - accuracy: 0.6618 - AUC: 0.7548 - val_loss: 0.3422 - val_accuracy: 0.8510 - val_AUC: 0.9286\nEpoch 2/6\n1000/1000 [==============================] - 43s 43ms/step - loss: 0.2648 - accuracy: 0.8903 - AUC: 0.9576 - val_loss: 0.3276 - val_accuracy: 0.8650 - val_AUC: 0.9410\nEpoch 3/6\n1000/1000 [==============================] - 42s 42ms/step - loss: 0.1573 - accuracy: 0.9439 - AUC: 0.9846 - val_loss: 0.3861 - val_accuracy: 0.8682 - val_AUC: 0.9390\nEpoch 4/6\n1000/1000 [==============================] - 42s 42ms/step - loss: 0.0849 - accuracy: 0.9706 - AUC: 0.9950 - val_loss: 0.5324 - val_accuracy: 0.8616 - val_AUC: 0.9292\nEpoch 5/6\n1000/1000 [==============================] - 43s 43ms/step - loss: 0.0393 - accuracy: 0.9876 - AUC: 0.9986 - val_loss: 0.7693 - val_accuracy: 0.8566 - val_AUC: 0.9132\nEpoch 6/6\n1000/1000 [==============================] - 44s 44ms/step - loss: 0.0222 - accuracy: 0.9926 - AUC: 0.9994 - val_loss: 0.9328 - val_accuracy: 0.8584 - val_AUC: 0.9052\n```\n\n```python\nplot_metric(history,\"AUC\")\n```\n\n```python\n\n```\n\n![](./data/6-1-3-fit模型.jpg)\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n\n```python\n\n```\n"
        },
        {
          "name": "6-2,训练模型的3种方法.md",
          "type": "blob",
          "size": 17.7490234375,
          "content": "# 6-2,训练模型的3种方法\n\n模型的训练主要有内置fit方法、内置tran_on_batch方法、自定义训练循环。\n\n注：fit_generator方法在tf.keras中不推荐使用，其功能已经被fit包含。\n\n\n```python\nimport numpy as np \nimport pandas as pd \nimport tensorflow as tf\nfrom tensorflow.keras import * \n\n#打印时间分割线\n@tf.function\ndef printbar():\n    today_ts = tf.timestamp()%(24*60*60)\n\n    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\n    minite = tf.cast((today_ts%3600)//60,tf.int32)\n    second = tf.cast(tf.floor(today_ts%60),tf.int32)\n    \n    def timeformat(m):\n        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\n            return(tf.strings.format(\"0{}\",m))\n        else:\n            return(tf.strings.format(\"{}\",m))\n    \n    timestring = tf.strings.join([timeformat(hour),timeformat(minite),\n                timeformat(second)],separator = \":\")\n    tf.print(\"==========\"*8+timestring)\n    \n```\n\n```python\nMAX_LEN = 300\nBATCH_SIZE = 32\n(x_train,y_train),(x_test,y_test) = datasets.reuters.load_data()\nx_train = preprocessing.sequence.pad_sequences(x_train,maxlen=MAX_LEN)\nx_test = preprocessing.sequence.pad_sequences(x_test,maxlen=MAX_LEN)\n\nMAX_WORDS = x_train.max()+1\nCAT_NUM = y_train.max()+1\n\nds_train = tf.data.Dataset.from_tensor_slices((x_train,y_train)) \\\n          .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n          .prefetch(tf.data.experimental.AUTOTUNE).cache()\n   \nds_test = tf.data.Dataset.from_tensor_slices((x_test,y_test)) \\\n          .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n          .prefetch(tf.data.experimental.AUTOTUNE).cache()\n\n```\n\n```python\n\n```\n\n### 一，内置fit方法\n\n\n该方法功能非常强大, 支持对numpy array, tf.data.Dataset以及 Python generator数据进行训练。\n\n并且可以通过设置回调函数实现对训练过程的复杂控制逻辑。\n\n```python\ntf.keras.backend.clear_session()\ndef create_model():\n    \n    model = models.Sequential()\n    model.add(layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN))\n    model.add(layers.Conv1D(filters = 64,kernel_size = 5,activation = \"relu\"))\n    model.add(layers.MaxPool1D(2))\n    model.add(layers.Conv1D(filters = 32,kernel_size = 3,activation = \"relu\"))\n    model.add(layers.MaxPool1D(2))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(CAT_NUM,activation = \"softmax\"))\n    return(model)\n\ndef compile_model(model):\n    model.compile(optimizer=optimizers.Nadam(),\n                loss=losses.SparseCategoricalCrossentropy(),\n                metrics=[metrics.SparseCategoricalAccuracy(),metrics.SparseTopKCategoricalAccuracy(5)]) \n    return(model)\n \nmodel = create_model()\nmodel.summary()\nmodel = compile_model(model)\n\n```\n\n```\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 300, 7)            216874    \n_________________________________________________________________\nconv1d (Conv1D)              (None, 296, 64)           2304      \n_________________________________________________________________\nmax_pooling1d (MaxPooling1D) (None, 148, 64)           0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 146, 32)           6176      \n_________________________________________________________________\nmax_pooling1d_1 (MaxPooling1 (None, 73, 32)            0         \n_________________________________________________________________\nflatten (Flatten)            (None, 2336)              0         \n_________________________________________________________________\ndense (Dense)                (None, 46)                107502    \n=================================================================\nTotal params: 332,856\nTrainable params: 332,856\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n```python\nhistory = model.fit(ds_train,validation_data = ds_test,epochs = 10)\n```\n\n```python\n\n```\n\n```\nTrain for 281 steps, validate for 71 steps\nEpoch 1/10\n281/281 [==============================] - 11s 37ms/step - loss: 2.0231 - sparse_categorical_accuracy: 0.4636 - sparse_top_k_categorical_accuracy: 0.7450 - val_loss: 1.7346 - val_sparse_categorical_accuracy: 0.5534 - val_sparse_top_k_categorical_accuracy: 0.7560\nEpoch 2/10\n281/281 [==============================] - 9s 31ms/step - loss: 1.5079 - sparse_categorical_accuracy: 0.6091 - sparse_top_k_categorical_accuracy: 0.7901 - val_loss: 1.5475 - val_sparse_categorical_accuracy: 0.6109 - val_sparse_top_k_categorical_accuracy: 0.7792\nEpoch 3/10\n281/281 [==============================] - 9s 33ms/step - loss: 1.2204 - sparse_categorical_accuracy: 0.6823 - sparse_top_k_categorical_accuracy: 0.8448 - val_loss: 1.5455 - val_sparse_categorical_accuracy: 0.6367 - val_sparse_top_k_categorical_accuracy: 0.8001\nEpoch 4/10\n281/281 [==============================] - 9s 33ms/step - loss: 0.9382 - sparse_categorical_accuracy: 0.7543 - sparse_top_k_categorical_accuracy: 0.9075 - val_loss: 1.6780 - val_sparse_categorical_accuracy: 0.6398 - val_sparse_top_k_categorical_accuracy: 0.8032\nEpoch 5/10\n281/281 [==============================] - 10s 34ms/step - loss: 0.6791 - sparse_categorical_accuracy: 0.8255 - sparse_top_k_categorical_accuracy: 0.9513 - val_loss: 1.9426 - val_sparse_categorical_accuracy: 0.6376 - val_sparse_top_k_categorical_accuracy: 0.7956\nEpoch 6/10\n281/281 [==============================] - 9s 33ms/step - loss: 0.5063 - sparse_categorical_accuracy: 0.8762 - sparse_top_k_categorical_accuracy: 0.9716 - val_loss: 2.2141 - val_sparse_categorical_accuracy: 0.6291 - val_sparse_top_k_categorical_accuracy: 0.7947\nEpoch 7/10\n281/281 [==============================] - 10s 37ms/step - loss: 0.4031 - sparse_categorical_accuracy: 0.9050 - sparse_top_k_categorical_accuracy: 0.9817 - val_loss: 2.4126 - val_sparse_categorical_accuracy: 0.6264 - val_sparse_top_k_categorical_accuracy: 0.7947\nEpoch 8/10\n281/281 [==============================] - 10s 35ms/step - loss: 0.3380 - sparse_categorical_accuracy: 0.9205 - sparse_top_k_categorical_accuracy: 0.9881 - val_loss: 2.5366 - val_sparse_categorical_accuracy: 0.6242 - val_sparse_top_k_categorical_accuracy: 0.7974\nEpoch 9/10\n281/281 [==============================] - 10s 36ms/step - loss: 0.2921 - sparse_categorical_accuracy: 0.9299 - sparse_top_k_categorical_accuracy: 0.9909 - val_loss: 2.6564 - val_sparse_categorical_accuracy: 0.6242 - val_sparse_top_k_categorical_accuracy: 0.7983\nEpoch 10/10\n281/281 [==============================] - 9s 30ms/step - loss: 0.2613 - sparse_categorical_accuracy: 0.9334 - sparse_top_k_categorical_accuracy: 0.9947 - val_loss: 2.7365 - val_sparse_categorical_accuracy: 0.6220 - val_sparse_top_k_categorical_accuracy: 0.8005\n```\n\n```python\n\n```\n\n### 二，内置train_on_batch方法\n\n\n该内置方法相比较fit方法更加灵活，可以不通过回调函数而直接在批次层次上更加精细地控制训练的过程。\n\n```python\ntf.keras.backend.clear_session()\n\ndef create_model():\n    model = models.Sequential()\n\n    model.add(layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN))\n    model.add(layers.Conv1D(filters = 64,kernel_size = 5,activation = \"relu\"))\n    model.add(layers.MaxPool1D(2))\n    model.add(layers.Conv1D(filters = 32,kernel_size = 3,activation = \"relu\"))\n    model.add(layers.MaxPool1D(2))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(CAT_NUM,activation = \"softmax\"))\n    return(model)\n\ndef compile_model(model):\n    model.compile(optimizer=optimizers.Nadam(),\n                loss=losses.SparseCategoricalCrossentropy(),\n                metrics=[metrics.SparseCategoricalAccuracy(),metrics.SparseTopKCategoricalAccuracy(5)]) \n    return(model)\n \nmodel = create_model()\nmodel.summary()\nmodel = compile_model(model)\n\n```\n\n```\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 300, 7)            216874    \n_________________________________________________________________\nconv1d (Conv1D)              (None, 296, 64)           2304      \n_________________________________________________________________\nmax_pooling1d (MaxPooling1D) (None, 148, 64)           0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 146, 32)           6176      \n_________________________________________________________________\nmax_pooling1d_1 (MaxPooling1 (None, 73, 32)            0         \n_________________________________________________________________\nflatten (Flatten)            (None, 2336)              0         \n_________________________________________________________________\ndense (Dense)                (None, 46)                107502    \n=================================================================\nTotal params: 332,856\nTrainable params: 332,856\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n```python\ndef train_model(model,ds_train,ds_valid,epoches):\n\n    for epoch in tf.range(1,epoches+1):\n        model.reset_metrics()\n        \n        # 在后期降低学习率\n        if epoch == 5:\n            model.optimizer.lr.assign(model.optimizer.lr/2.0)\n            tf.print(\"Lowering optimizer Learning Rate...\\n\\n\")\n        \n        for x, y in ds_train:\n            train_result = model.train_on_batch(x, y)\n\n        for x, y in ds_valid:\n            valid_result = model.test_on_batch(x, y,reset_metrics=False)\n            \n        if epoch%1 ==0:\n            printbar()\n            tf.print(\"epoch = \",epoch)\n            print(\"train:\",dict(zip(model.metrics_names,train_result)))\n            print(\"valid:\",dict(zip(model.metrics_names,valid_result)))\n            print(\"\")\n```\n\n```python\ntrain_model(model,ds_train,ds_test,10)\n```\n\n```\n================================================================================13:09:19\nepoch =  1\ntrain: {'loss': 0.82411176, 'sparse_categorical_accuracy': 0.77272725, 'sparse_top_k_categorical_accuracy': 0.8636364}\nvalid: {'loss': 1.9265995, 'sparse_categorical_accuracy': 0.5743544, 'sparse_top_k_categorical_accuracy': 0.75779164}\n\n================================================================================13:09:27\nepoch =  2\ntrain: {'loss': 0.6006621, 'sparse_categorical_accuracy': 0.90909094, 'sparse_top_k_categorical_accuracy': 0.95454544}\nvalid: {'loss': 1.844159, 'sparse_categorical_accuracy': 0.6126447, 'sparse_top_k_categorical_accuracy': 0.7920748}\n\n================================================================================13:09:35\nepoch =  3\ntrain: {'loss': 0.36935613, 'sparse_categorical_accuracy': 0.90909094, 'sparse_top_k_categorical_accuracy': 0.95454544}\nvalid: {'loss': 2.163433, 'sparse_categorical_accuracy': 0.63312554, 'sparse_top_k_categorical_accuracy': 0.8045414}\n\n================================================================================13:09:42\nepoch =  4\ntrain: {'loss': 0.2304088, 'sparse_categorical_accuracy': 0.90909094, 'sparse_top_k_categorical_accuracy': 1.0}\nvalid: {'loss': 2.8911984, 'sparse_categorical_accuracy': 0.6344613, 'sparse_top_k_categorical_accuracy': 0.7978629}\n\nLowering optimizer Learning Rate...\n\n\n================================================================================13:09:51\nepoch =  5\ntrain: {'loss': 0.111194365, 'sparse_categorical_accuracy': 0.95454544, 'sparse_top_k_categorical_accuracy': 1.0}\nvalid: {'loss': 3.6431572, 'sparse_categorical_accuracy': 0.6295637, 'sparse_top_k_categorical_accuracy': 0.7978629}\n\n================================================================================13:09:59\nepoch =  6\ntrain: {'loss': 0.07741702, 'sparse_categorical_accuracy': 0.95454544, 'sparse_top_k_categorical_accuracy': 1.0}\nvalid: {'loss': 4.074161, 'sparse_categorical_accuracy': 0.6255565, 'sparse_top_k_categorical_accuracy': 0.794301}\n\n================================================================================13:10:07\nepoch =  7\ntrain: {'loss': 0.056113098, 'sparse_categorical_accuracy': 1.0, 'sparse_top_k_categorical_accuracy': 1.0}\nvalid: {'loss': 4.4461513, 'sparse_categorical_accuracy': 0.6273375, 'sparse_top_k_categorical_accuracy': 0.79652715}\n\n================================================================================13:10:17\nepoch =  8\ntrain: {'loss': 0.043448802, 'sparse_categorical_accuracy': 1.0, 'sparse_top_k_categorical_accuracy': 1.0}\nvalid: {'loss': 4.7687583, 'sparse_categorical_accuracy': 0.6224399, 'sparse_top_k_categorical_accuracy': 0.79741764}\n\n================================================================================13:10:26\nepoch =  9\ntrain: {'loss': 0.035002146, 'sparse_categorical_accuracy': 1.0, 'sparse_top_k_categorical_accuracy': 1.0}\nvalid: {'loss': 5.130505, 'sparse_categorical_accuracy': 0.6175423, 'sparse_top_k_categorical_accuracy': 0.794301}\n\n================================================================================13:10:34\nepoch =  10\ntrain: {'loss': 0.028303564, 'sparse_categorical_accuracy': 1.0, 'sparse_top_k_categorical_accuracy': 1.0}\nvalid: {'loss': 5.4559293, 'sparse_categorical_accuracy': 0.6148709, 'sparse_top_k_categorical_accuracy': 0.7947462}\n```\n\n```python\n\n```\n\n### 三，自定义训练循环\n\n\n自定义训练循环无需编译模型，直接利用优化器根据损失函数反向传播迭代参数，拥有最高的灵活性。\n\n```python\ntf.keras.backend.clear_session()\n\ndef create_model():\n    \n    model = models.Sequential()\n\n    model.add(layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN))\n    model.add(layers.Conv1D(filters = 64,kernel_size = 5,activation = \"relu\"))\n    model.add(layers.MaxPool1D(2))\n    model.add(layers.Conv1D(filters = 32,kernel_size = 3,activation = \"relu\"))\n    model.add(layers.MaxPool1D(2))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(CAT_NUM,activation = \"softmax\"))\n    return(model)\n\nmodel = create_model()\nmodel.summary()\n```\n\n```python\noptimizer = optimizers.Nadam()\nloss_func = losses.SparseCategoricalCrossentropy()\n\ntrain_loss = metrics.Mean(name='train_loss')\ntrain_metric = metrics.SparseCategoricalAccuracy(name='train_accuracy')\n\nvalid_loss = metrics.Mean(name='valid_loss')\nvalid_metric = metrics.SparseCategoricalAccuracy(name='valid_accuracy')\n\n@tf.function\ndef train_step(model, features, labels):\n    with tf.GradientTape() as tape:\n        predictions = model(features,training = True)\n        loss = loss_func(labels, predictions)\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n    train_loss.update_state(loss)\n    train_metric.update_state(labels, predictions)\n    \n\n@tf.function\ndef valid_step(model, features, labels):\n    predictions = model(features)\n    batch_loss = loss_func(labels, predictions)\n    valid_loss.update_state(batch_loss)\n    valid_metric.update_state(labels, predictions)\n    \n\ndef train_model(model,ds_train,ds_valid,epochs):\n    for epoch in tf.range(1,epochs+1):\n        \n        for features, labels in ds_train:\n            train_step(model,features,labels)\n\n        for features, labels in ds_valid:\n            valid_step(model,features,labels)\n\n        logs = 'Epoch={},Loss:{},Accuracy:{},Valid Loss:{},Valid Accuracy:{}'\n        \n        if epoch%1 ==0:\n            printbar()\n            tf.print(tf.strings.format(logs,\n            (epoch,train_loss.result(),train_metric.result(),valid_loss.result(),valid_metric.result())))\n            tf.print(\"\")\n            \n        train_loss.reset_states()\n        valid_loss.reset_states()\n        train_metric.reset_states()\n        valid_metric.reset_states()\n\ntrain_model(model,ds_train,ds_test,10)\n\n```\n\n```python\n\n```\n\n```\n================================================================================13:12:03\nEpoch=1,Loss:2.02051544,Accuracy:0.460253835,Valid Loss:1.75700927,Valid Accuracy:0.536954582\n\n================================================================================13:12:09\nEpoch=2,Loss:1.510795,Accuracy:0.610665798,Valid Loss:1.55349839,Valid Accuracy:0.616206586\n\n================================================================================13:12:17\nEpoch=3,Loss:1.19221532,Accuracy:0.696170092,Valid Loss:1.52315605,Valid Accuracy:0.651380241\n\n================================================================================13:12:23\nEpoch=4,Loss:0.90101546,Accuracy:0.766310394,Valid Loss:1.68327653,Valid Accuracy:0.648263574\n\n================================================================================13:12:30\nEpoch=5,Loss:0.655430496,Accuracy:0.831329346,Valid Loss:1.90872383,Valid Accuracy:0.641139805\n\n================================================================================13:12:37\nEpoch=6,Loss:0.492730737,Accuracy:0.877866864,Valid Loss:2.09966016,Valid Accuracy:0.63223511\n\n================================================================================13:12:44\nEpoch=7,Loss:0.391238362,Accuracy:0.904030263,Valid Loss:2.27431226,Valid Accuracy:0.625111282\n\n================================================================================13:12:51\nEpoch=8,Loss:0.327761739,Accuracy:0.922066331,Valid Loss:2.42568827,Valid Accuracy:0.617542326\n\n================================================================================13:12:58\nEpoch=9,Loss:0.285573095,Accuracy:0.930527747,Valid Loss:2.55942106,Valid Accuracy:0.612644672\n\n================================================================================13:13:05\nEpoch=10,Loss:0.255482465,Accuracy:0.936094403,Valid Loss:2.67789412,Valid Accuracy:0.612199485\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n\n```python\n\n```\n\n```python\n\n```\n"
        },
        {
          "name": "6-3,使用单GPU训练模型.md",
          "type": "blob",
          "size": 10.3564453125,
          "content": "# 6-3,使用单GPU训练模型\n\n深度学习的训练过程常常非常耗时，一个模型训练几个小时是家常便饭，训练几天也是常有的事情，有时候甚至要训练几十天。\n\n训练过程的耗时主要来自于两个部分，一部分来自数据准备，另一部分来自参数迭代。\n\n当数据准备过程还是模型训练时间的主要瓶颈时，我们可以使用更多进程来准备数据。\n\n当参数迭代过程成为训练时间的主要瓶颈时，我们通常的方法是应用GPU或者Google的TPU来进行加速。\n\n详见《用GPU加速Keras模型——Colab免费GPU使用攻略》\n\nhttps://zhuanlan.zhihu.com/p/68509398\n\n\n无论是内置fit方法，还是自定义训练循环，从CPU切换成单GPU训练模型都是非常方便的，无需更改任何代码。当存在可用的GPU时，如果不特意指定device，tensorflow会自动优先选择使用GPU来创建张量和执行张量计算。\n\n但如果是在公司或者学校实验室的服务器环境，存在多个GPU和多个使用者时，为了不让单个同学的任务占用全部GPU资源导致其他同学无法使用（tensorflow默认获取全部GPU的全部内存资源权限，但实际上只使用一个GPU的部分资源），我们通常会在开头增加以下几行代码以控制每个任务使用的GPU编号和显存大小，以便其他同学也能够同时训练模型。\n\n\n在Colab笔记本中：修改->笔记本设置->硬件加速器 中选择 GPU\n\n注：以下代码只能在Colab 上才能正确执行。\n\n可通过以下colab链接测试效果《tf_单GPU》：\n\nhttps://colab.research.google.com/drive/1r5dLoeJq5z01sU72BX2M5UiNSkuxsEFe\n\n```python\n%tensorflow_version 2.x\nimport tensorflow as tf\nprint(tf.__version__)\n```\n\n```python\nfrom tensorflow.keras import * \n\n#打印时间分割线\n@tf.function\ndef printbar():\n    today_ts = tf.timestamp()%(24*60*60)\n\n    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\n    minite = tf.cast((today_ts%3600)//60,tf.int32)\n    second = tf.cast(tf.floor(today_ts%60),tf.int32)\n    \n    def timeformat(m):\n        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\n            return(tf.strings.format(\"0{}\",m))\n        else:\n            return(tf.strings.format(\"{}\",m))\n    \n    timestring = tf.strings.join([timeformat(hour),timeformat(minite),\n                timeformat(second)],separator = \":\")\n    tf.print(\"==========\"*8+timestring)\n    \n```\n\n### 一，GPU设置\n\n```python\ngpus = tf.config.list_physical_devices(\"GPU\")\n\nif gpus:\n    gpu0 = gpus[0] #如果有多个GPU，仅使用第0个GPU\n    tf.config.experimental.set_memory_growth(gpu0, True) #设置GPU显存用量按需使用\n    # 或者也可以设置GPU显存为固定使用量(例如：4G)\n    #tf.config.experimental.set_virtual_device_configuration(gpu0,\n    #    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]) \n    tf.config.set_visible_devices([gpu0],\"GPU\") \n```\n\n比较GPU和CPU的计算速度\n\n```python\nprintbar()\nwith tf.device(\"/gpu:0\"):\n    tf.random.set_seed(0)\n    a = tf.random.uniform((10000,100),minval = 0,maxval = 3.0)\n    b = tf.random.uniform((100,100000),minval = 0,maxval = 3.0)\n    c = a@b\n    tf.print(tf.reduce_sum(tf.reduce_sum(c,axis = 0),axis=0))\nprintbar()\n```\n\n```\n================================================================================17:37:01\n2.24953778e+11\n================================================================================17:37:01\n```\n\n```python\nprintbar()\nwith tf.device(\"/cpu:0\"):\n    tf.random.set_seed(0)\n    a = tf.random.uniform((10000,100),minval = 0,maxval = 3.0)\n    b = tf.random.uniform((100,100000),minval = 0,maxval = 3.0)\n    c = a@b\n    tf.print(tf.reduce_sum(tf.reduce_sum(c,axis = 0),axis=0))\nprintbar()\n```\n\n```\n================================================================================17:37:34\n2.24953795e+11\n================================================================================17:37:40\n```\n\n```python\n\n```\n\n### 二，准备数据\n\n```python\nMAX_LEN = 300\nBATCH_SIZE = 32\n(x_train,y_train),(x_test,y_test) = datasets.reuters.load_data()\nx_train = preprocessing.sequence.pad_sequences(x_train,maxlen=MAX_LEN)\nx_test = preprocessing.sequence.pad_sequences(x_test,maxlen=MAX_LEN)\n\nMAX_WORDS = x_train.max()+1\nCAT_NUM = y_train.max()+1\n\nds_train = tf.data.Dataset.from_tensor_slices((x_train,y_train)) \\\n          .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n          .prefetch(tf.data.experimental.AUTOTUNE).cache()\n   \nds_test = tf.data.Dataset.from_tensor_slices((x_test,y_test)) \\\n          .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n          .prefetch(tf.data.experimental.AUTOTUNE).cache()\n          \n```\n\n```python\n\n```\n\n### 三，定义模型\n\n```python\ntf.keras.backend.clear_session()\n\ndef create_model():\n    \n    model = models.Sequential()\n\n    model.add(layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN))\n    model.add(layers.Conv1D(filters = 64,kernel_size = 5,activation = \"relu\"))\n    model.add(layers.MaxPool1D(2))\n    model.add(layers.Conv1D(filters = 32,kernel_size = 3,activation = \"relu\"))\n    model.add(layers.MaxPool1D(2))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(CAT_NUM,activation = \"softmax\"))\n    return(model)\n\nmodel = create_model()\nmodel.summary()\n\n```\n\n```\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 300, 7)            216874    \n_________________________________________________________________\nconv1d (Conv1D)              (None, 296, 64)           2304      \n_________________________________________________________________\nmax_pooling1d (MaxPooling1D) (None, 148, 64)           0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 146, 32)           6176      \n_________________________________________________________________\nmax_pooling1d_1 (MaxPooling1 (None, 73, 32)            0         \n_________________________________________________________________\nflatten (Flatten)            (None, 2336)              0         \n_________________________________________________________________\ndense (Dense)                (None, 46)                107502    \n=================================================================\nTotal params: 332,856\nTrainable params: 332,856\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n```python\n\n```\n\n### 四，训练模型\n\n```python\noptimizer = optimizers.Nadam()\nloss_func = losses.SparseCategoricalCrossentropy()\n\ntrain_loss = metrics.Mean(name='train_loss')\ntrain_metric = metrics.SparseCategoricalAccuracy(name='train_accuracy')\n\nvalid_loss = metrics.Mean(name='valid_loss')\nvalid_metric = metrics.SparseCategoricalAccuracy(name='valid_accuracy')\n\n@tf.function\ndef train_step(model, features, labels):\n    with tf.GradientTape() as tape:\n        predictions = model(features,training = True)\n        loss = loss_func(labels, predictions)\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n    train_loss.update_state(loss)\n    train_metric.update_state(labels, predictions)\n    \n@tf.function\ndef valid_step(model, features, labels):\n    predictions = model(features)\n    batch_loss = loss_func(labels, predictions)\n    valid_loss.update_state(batch_loss)\n    valid_metric.update_state(labels, predictions)\n    \n\ndef train_model(model,ds_train,ds_valid,epochs):\n    for epoch in tf.range(1,epochs+1):\n        \n        for features, labels in ds_train:\n            train_step(model,features,labels)\n\n        for features, labels in ds_valid:\n            valid_step(model,features,labels)\n\n        logs = 'Epoch={},Loss:{},Accuracy:{},Valid Loss:{},Valid Accuracy:{}'\n        \n        if epoch%1 ==0:\n            printbar()\n            tf.print(tf.strings.format(logs,\n            (epoch,train_loss.result(),train_metric.result(),valid_loss.result(),valid_metric.result())))\n            tf.print(\"\")\n            \n        train_loss.reset_states()\n        valid_loss.reset_states()\n        train_metric.reset_states()\n        valid_metric.reset_states()\n\ntrain_model(model,ds_train,ds_test,10)\n```\n\n```python\n\n```\n\n```\n================================================================================17:13:26\nEpoch=1,Loss:1.96735072,Accuracy:0.489200622,Valid Loss:1.64124215,Valid Accuracy:0.582813919\n\n================================================================================17:13:28\nEpoch=2,Loss:1.4640888,Accuracy:0.624805152,Valid Loss:1.5559175,Valid Accuracy:0.607747078\n\n================================================================================17:13:30\nEpoch=3,Loss:1.20681274,Accuracy:0.68581605,Valid Loss:1.58494771,Valid Accuracy:0.622439921\n\n================================================================================17:13:31\nEpoch=4,Loss:0.937500894,Accuracy:0.75361836,Valid Loss:1.77466083,Valid Accuracy:0.621994674\n\n================================================================================17:13:33\nEpoch=5,Loss:0.693960547,Accuracy:0.822199941,Valid Loss:2.00267363,Valid Accuracy:0.6197685\n\n================================================================================17:13:35\nEpoch=6,Loss:0.519614,Accuracy:0.870296121,Valid Loss:2.23463202,Valid Accuracy:0.613980412\n\n================================================================================17:13:37\nEpoch=7,Loss:0.408562034,Accuracy:0.901246965,Valid Loss:2.46969271,Valid Accuracy:0.612199485\n\n================================================================================17:13:39\nEpoch=8,Loss:0.339028627,Accuracy:0.920062363,Valid Loss:2.68585229,Valid Accuracy:0.615316093\n\n================================================================================17:13:41\nEpoch=9,Loss:0.293798745,Accuracy:0.92930305,Valid Loss:2.88995624,Valid Accuracy:0.613535166\n\n================================================================================17:13:43\nEpoch=10,Loss:0.263130337,Accuracy:0.936651051,Valid Loss:3.09705234,Valid Accuracy:0.612644672\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n"
        },
        {
          "name": "6-4,使用多GPU训练模型.md",
          "type": "blob",
          "size": 11.4375,
          "content": "# 6-4,使用多GPU训练模型\n\n如果使用多GPU训练模型，推荐使用内置fit方法，较为方便，仅需添加2行代码。\n\n在Colab笔记本中：修改->笔记本设置->硬件加速器 中选择 GPU\n\n注：以下代码只能在Colab 上才能正确执行。\n\n可通过以下colab链接测试效果《tf_多GPU》：\n\nhttps://colab.research.google.com/drive/1j2kp_t0S_cofExSN7IyJ4QtMscbVlXU-\n\n\n\nMirroredStrategy过程简介：\n\n* 训练开始前，该策略在所有 N 个计算设备上均各复制一份完整的模型；\n* 每次训练传入一个批次的数据时，将数据分成 N 份，分别传入 N 个计算设备（即数据并行）；\n* N 个计算设备使用本地变量（镜像变量）分别计算自己所获得的部分数据的梯度；\n* 使用分布式计算的 All-reduce 操作，在计算设备间高效交换梯度数据并进行求和，使得最终每个设备都有了所有设备的梯度之和；\n* 使用梯度求和的结果更新本地变量（镜像变量）；\n* 当所有设备均更新本地变量后，进行下一轮训练（即该并行策略是同步的）。\n\n```python\n%tensorflow_version 2.x\nimport tensorflow as tf\nprint(tf.__version__)\nfrom tensorflow.keras import * \n```\n\n```python\n#此处在colab上使用1个GPU模拟出两个逻辑GPU进行多GPU训练\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    # 设置两个逻辑GPU模拟多GPU训练\n    try:\n        tf.config.experimental.set_virtual_device_configuration(gpus[0],\n            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024),\n             tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n        print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n    except RuntimeError as e:\n        print(e)\n```\n\n### 一，准备数据\n\n```python\nMAX_LEN = 300\nBATCH_SIZE = 32\n(x_train,y_train),(x_test,y_test) = datasets.reuters.load_data()\nx_train = preprocessing.sequence.pad_sequences(x_train,maxlen=MAX_LEN)\nx_test = preprocessing.sequence.pad_sequences(x_test,maxlen=MAX_LEN)\n\nMAX_WORDS = x_train.max()+1\nCAT_NUM = y_train.max()+1\n\nds_train = tf.data.Dataset.from_tensor_slices((x_train,y_train)) \\\n          .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n          .prefetch(tf.data.experimental.AUTOTUNE).cache()\n   \nds_test = tf.data.Dataset.from_tensor_slices((x_test,y_test)) \\\n          .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n          .prefetch(tf.data.experimental.AUTOTUNE).cache()\n\n```\n\n### 二，定义模型\n\n```python\ntf.keras.backend.clear_session()\ndef create_model():\n    \n    model = models.Sequential()\n\n    model.add(layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN))\n    model.add(layers.Conv1D(filters = 64,kernel_size = 5,activation = \"relu\"))\n    model.add(layers.MaxPool1D(2))\n    model.add(layers.Conv1D(filters = 32,kernel_size = 3,activation = \"relu\"))\n    model.add(layers.MaxPool1D(2))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(CAT_NUM,activation = \"softmax\"))\n    return(model)\n\ndef compile_model(model):\n    model.compile(optimizer=optimizers.Nadam(),\n                loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n                metrics=[metrics.SparseCategoricalAccuracy(),metrics.SparseTopKCategoricalAccuracy(5)]) \n    return(model)\n```\n\n### 三，训练模型\n\n```python\n#增加以下两行代码\nstrategy = tf.distribute.MirroredStrategy()  \nwith strategy.scope(): \n    model = create_model()\n    model.summary()\n    model = compile_model(model)\n    \nhistory = model.fit(ds_train,validation_data = ds_test,epochs = 10)  \n```\n\n```\nWARNING:tensorflow:NCCL is not supported when using virtual GPUs, fallingback to reduction to one device\nINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 300, 7)            216874    \n_________________________________________________________________\nconv1d (Conv1D)              (None, 296, 64)           2304      \n_________________________________________________________________\nmax_pooling1d (MaxPooling1D) (None, 148, 64)           0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 146, 32)           6176      \n_________________________________________________________________\nmax_pooling1d_1 (MaxPooling1 (None, 73, 32)            0         \n_________________________________________________________________\nflatten (Flatten)            (None, 2336)              0         \n_________________________________________________________________\ndense (Dense)                (None, 46)                107502    \n=================================================================\nTotal params: 332,856\nTrainable params: 332,856\nNon-trainable params: 0\n_________________________________________________________________\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nTrain for 281 steps, validate for 71 steps\nEpoch 1/10\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n281/281 [==============================] - 15s 53ms/step - loss: 2.0270 - sparse_categorical_accuracy: 0.4653 - sparse_top_k_categorical_accuracy: 0.7481 - val_loss: 1.7517 - val_sparse_categorical_accuracy: 0.5481 - val_sparse_top_k_categorical_accuracy: 0.7578\nEpoch 2/10\n281/281 [==============================] - 4s 14ms/step - loss: 1.5206 - sparse_categorical_accuracy: 0.6045 - sparse_top_k_categorical_accuracy: 0.7938 - val_loss: 1.5715 - val_sparse_categorical_accuracy: 0.5993 - val_sparse_top_k_categorical_accuracy: 0.7983\nEpoch 3/10\n281/281 [==============================] - 4s 14ms/step - loss: 1.2178 - sparse_categorical_accuracy: 0.6843 - sparse_top_k_categorical_accuracy: 0.8547 - val_loss: 1.5232 - val_sparse_categorical_accuracy: 0.6327 - val_sparse_top_k_categorical_accuracy: 0.8112\nEpoch 4/10\n281/281 [==============================] - 4s 13ms/step - loss: 0.9127 - sparse_categorical_accuracy: 0.7648 - sparse_top_k_categorical_accuracy: 0.9113 - val_loss: 1.6527 - val_sparse_categorical_accuracy: 0.6296 - val_sparse_top_k_categorical_accuracy: 0.8201\nEpoch 5/10\n281/281 [==============================] - 4s 14ms/step - loss: 0.6606 - sparse_categorical_accuracy: 0.8321 - sparse_top_k_categorical_accuracy: 0.9525 - val_loss: 1.8791 - val_sparse_categorical_accuracy: 0.6158 - val_sparse_top_k_categorical_accuracy: 0.8219\nEpoch 6/10\n281/281 [==============================] - 4s 14ms/step - loss: 0.4919 - sparse_categorical_accuracy: 0.8799 - sparse_top_k_categorical_accuracy: 0.9725 - val_loss: 2.1282 - val_sparse_categorical_accuracy: 0.6037 - val_sparse_top_k_categorical_accuracy: 0.8112\nEpoch 7/10\n281/281 [==============================] - 4s 14ms/step - loss: 0.3947 - sparse_categorical_accuracy: 0.9051 - sparse_top_k_categorical_accuracy: 0.9814 - val_loss: 2.3033 - val_sparse_categorical_accuracy: 0.6046 - val_sparse_top_k_categorical_accuracy: 0.8094\nEpoch 8/10\n281/281 [==============================] - 4s 14ms/step - loss: 0.3335 - sparse_categorical_accuracy: 0.9207 - sparse_top_k_categorical_accuracy: 0.9863 - val_loss: 2.4255 - val_sparse_categorical_accuracy: 0.5993 - val_sparse_top_k_categorical_accuracy: 0.8099\nEpoch 9/10\n281/281 [==============================] - 4s 14ms/step - loss: 0.2919 - sparse_categorical_accuracy: 0.9304 - sparse_top_k_categorical_accuracy: 0.9911 - val_loss: 2.5571 - val_sparse_categorical_accuracy: 0.6020 - val_sparse_top_k_categorical_accuracy: 0.8126\nEpoch 10/10\n281/281 [==============================] - 4s 14ms/step - loss: 0.2617 - sparse_categorical_accuracy: 0.9342 - sparse_top_k_categorical_accuracy: 0.9937 - val_loss: 2.6700 - val_sparse_categorical_accuracy: 0.6077 - val_sparse_top_k_categorical_accuracy: 0.8148\nCPU times: user 1min 2s, sys: 8.59 s, total: 1min 10s\nWall time: 58.5 s\n```\n\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n"
        },
        {
          "name": "6-5,使用TPU训练模型.md",
          "type": "blob",
          "size": 10.7275390625,
          "content": "# 6-5,使用TPU训练模型\n\n如果想尝试使用Google Colab上的TPU来训练模型，也是非常方便，仅需添加6行代码。\n\n在Colab笔记本中：修改->笔记本设置->硬件加速器 中选择 TPU\n\n注：以下代码只能在Colab 上才能正确执行。\n\n可通过以下colab链接测试效果《tf_TPU》：\n\nhttps://colab.research.google.com/drive/1XCIhATyE1R7lq6uwFlYlRsUr5d9_-r1s\n\n\n```python\n%tensorflow_version 2.x\nimport tensorflow as tf\nprint(tf.__version__)\nfrom tensorflow.keras import * \n```\n\n### 一，准备数据\n\n```python\nMAX_LEN = 300\nBATCH_SIZE = 32\n(x_train,y_train),(x_test,y_test) = datasets.reuters.load_data()\nx_train = preprocessing.sequence.pad_sequences(x_train,maxlen=MAX_LEN)\nx_test = preprocessing.sequence.pad_sequences(x_test,maxlen=MAX_LEN)\n\nMAX_WORDS = x_train.max()+1\nCAT_NUM = y_train.max()+1\n\nds_train = tf.data.Dataset.from_tensor_slices((x_train,y_train)) \\\n          .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n          .prefetch(tf.data.experimental.AUTOTUNE).cache()\n   \nds_test = tf.data.Dataset.from_tensor_slices((x_test,y_test)) \\\n          .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n          .prefetch(tf.data.experimental.AUTOTUNE).cache()\n```\n\n### 二，定义模型\n\n```python\ntf.keras.backend.clear_session()\ndef create_model():\n    \n    model = models.Sequential()\n\n    model.add(layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN))\n    model.add(layers.Conv1D(filters = 64,kernel_size = 5,activation = \"relu\"))\n    model.add(layers.MaxPool1D(2))\n    model.add(layers.Conv1D(filters = 32,kernel_size = 3,activation = \"relu\"))\n    model.add(layers.MaxPool1D(2))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(CAT_NUM,activation = \"softmax\"))\n    return(model)\n\ndef compile_model(model):\n    model.compile(optimizer=optimizers.Nadam(),\n                loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n                metrics=[metrics.SparseCategoricalAccuracy(),metrics.SparseTopKCategoricalAccuracy(5)]) \n    return(model)\n```\n\n```python\n\n```\n\n### 三，训练模型\n\n```python\n#增加以下6行代码\nimport os\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\ntf.config.experimental_connect_to_cluster(resolver)\ntf.tpu.experimental.initialize_tpu_system(resolver)\nstrategy = tf.distribute.experimental.TPUStrategy(resolver)\nwith strategy.scope():\n    model = create_model()\n    model.summary()\n    model = compile_model(model)\n    \n```\n\n```\nWARNING:tensorflow:TPU system 10.26.134.242:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\nWARNING:tensorflow:TPU system 10.26.134.242:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\nINFO:tensorflow:Initializing the TPU system: 10.26.134.242:8470\nINFO:tensorflow:Initializing the TPU system: 10.26.134.242:8470\nINFO:tensorflow:Clearing out eager caches\nINFO:tensorflow:Clearing out eager caches\nINFO:tensorflow:Finished initializing TPU system.\nINFO:tensorflow:Finished initializing TPU system.\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 300, 7)            216874    \n_________________________________________________________________\nconv1d (Conv1D)              (None, 296, 64)           2304      \n_________________________________________________________________\nmax_pooling1d (MaxPooling1D) (None, 148, 64)           0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 146, 32)           6176      \n_________________________________________________________________\nmax_pooling1d_1 (MaxPooling1 (None, 73, 32)            0         \n_________________________________________________________________\nflatten (Flatten)            (None, 2336)              0         \n_________________________________________________________________\ndense (Dense)                (None, 46)                107502    \n=================================================================\nTotal params: 332,856\nTrainable params: 332,856\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n```python\nhistory = model.fit(ds_train,validation_data = ds_test,epochs = 10)\n```\n\n```\nTrain for 281 steps, validate for 71 steps\nEpoch 1/10\n281/281 [==============================] - 12s 43ms/step - loss: 3.4466 - sparse_categorical_accuracy: 0.4332 - sparse_top_k_categorical_accuracy: 0.7180 - val_loss: 3.3179 - val_sparse_categorical_accuracy: 0.5352 - val_sparse_top_k_categorical_accuracy: 0.7195\nEpoch 2/10\n281/281 [==============================] - 6s 20ms/step - loss: 3.3251 - sparse_categorical_accuracy: 0.5405 - sparse_top_k_categorical_accuracy: 0.7302 - val_loss: 3.3082 - val_sparse_categorical_accuracy: 0.5463 - val_sparse_top_k_categorical_accuracy: 0.7235\nEpoch 3/10\n281/281 [==============================] - 6s 20ms/step - loss: 3.2961 - sparse_categorical_accuracy: 0.5729 - sparse_top_k_categorical_accuracy: 0.7280 - val_loss: 3.3026 - val_sparse_categorical_accuracy: 0.5499 - val_sparse_top_k_categorical_accuracy: 0.7217\nEpoch 4/10\n281/281 [==============================] - 5s 19ms/step - loss: 3.2751 - sparse_categorical_accuracy: 0.5924 - sparse_top_k_categorical_accuracy: 0.7276 - val_loss: 3.2957 - val_sparse_categorical_accuracy: 0.5543 - val_sparse_top_k_categorical_accuracy: 0.7217\nEpoch 5/10\n281/281 [==============================] - 5s 19ms/step - loss: 3.2655 - sparse_categorical_accuracy: 0.6008 - sparse_top_k_categorical_accuracy: 0.7290 - val_loss: 3.3022 - val_sparse_categorical_accuracy: 0.5490 - val_sparse_top_k_categorical_accuracy: 0.7231\nEpoch 6/10\n281/281 [==============================] - 5s 19ms/step - loss: 3.2616 - sparse_categorical_accuracy: 0.6041 - sparse_top_k_categorical_accuracy: 0.7295 - val_loss: 3.3015 - val_sparse_categorical_accuracy: 0.5503 - val_sparse_top_k_categorical_accuracy: 0.7235\nEpoch 7/10\n281/281 [==============================] - 6s 21ms/step - loss: 3.2595 - sparse_categorical_accuracy: 0.6059 - sparse_top_k_categorical_accuracy: 0.7322 - val_loss: 3.3064 - val_sparse_categorical_accuracy: 0.5454 - val_sparse_top_k_categorical_accuracy: 0.7266\nEpoch 8/10\n281/281 [==============================] - 6s 21ms/step - loss: 3.2591 - sparse_categorical_accuracy: 0.6063 - sparse_top_k_categorical_accuracy: 0.7327 - val_loss: 3.3025 - val_sparse_categorical_accuracy: 0.5481 - val_sparse_top_k_categorical_accuracy: 0.7231\nEpoch 9/10\n281/281 [==============================] - 5s 19ms/step - loss: 3.2588 - sparse_categorical_accuracy: 0.6062 - sparse_top_k_categorical_accuracy: 0.7332 - val_loss: 3.2992 - val_sparse_categorical_accuracy: 0.5521 - val_sparse_top_k_categorical_accuracy: 0.7257\nEpoch 10/10\n281/281 [==============================] - 5s 18ms/step - loss: 3.2577 - sparse_categorical_accuracy: 0.6073 - sparse_top_k_categorical_accuracy: 0.7363 - val_loss: 3.2981 - val_sparse_categorical_accuracy: 0.5516 - val_sparse_top_k_categorical_accuracy: 0.7306\nCPU times: user 18.9 s, sys: 3.86 s, total: 22.7 s\nWall time: 1min 1s\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n\n```python\n\n```\n"
        },
        {
          "name": "6-6,使用tensorflow-serving部署模型.md",
          "type": "blob",
          "size": 7.48046875,
          "content": "# 6-6,使用tensorflow-serving部署模型\n\nTensorFlow训练好的模型以tensorflow原生方式保存成protobuf文件后可以用许多方式部署运行。\n\n例如：通过 tensorflow-js 可以用javascrip脚本加载模型并在浏览器中运行模型。\n\n通过 tensorflow-lite 可以在移动和嵌入式设备上加载并运行TensorFlow模型。\n\n通过 tensorflow-serving 可以加载模型后提供网络接口API服务，通过任意编程语言发送网络请求都可以获取模型预测结果。\n\n通过 tensorFlow for Java接口，可以在Java或者spark(scala)中调用tensorflow模型进行预测。\n\n我们主要介绍tensorflow serving部署模型、使用spark(scala)调用tensorflow模型的方法。\n\n```python\n\n```\n\n### 〇，tensorflow serving模型部署概述\n\n<!-- #region -->\n使用 tensorflow serving 部署模型要完成以下步骤。\n\n* (1) 准备protobuf模型文件。\n\n* (2) 安装tensorflow serving。\n\n* (3) 启动tensorflow serving 服务。\n\n* (4) 向API服务发送请求，获取预测结果。\n\n\n可通过以下colab链接测试效果《tf_serving》：\nhttps://colab.research.google.com/drive/1vS5LAYJTEn-H0GDb1irzIuyRB8E3eWc8\n\n<!-- #endregion -->\n\n```python\n%tensorflow_version 2.x\nimport tensorflow as tf\nprint(tf.__version__)\nfrom tensorflow.keras import * \n\n```\n\n### 一，准备protobuf模型文件\n\n我们使用tf.keras 训练一个简单的线性回归模型，并保存成protobuf文件。\n\n```python\nimport tensorflow as tf\nfrom tensorflow.keras import models,layers,optimizers\n\n## 样本数量\nn = 800\n\n## 生成测试用数据集\nX = tf.random.uniform([n,2],minval=-10,maxval=10) \nw0 = tf.constant([[2.0],[-1.0]])\nb0 = tf.constant(3.0)\n\nY = X@w0 + b0 + tf.random.normal([n,1],\n    mean = 0.0,stddev= 2.0) # @表示矩阵乘法,增加正态扰动\n\n## 建立模型\ntf.keras.backend.clear_session()\ninputs = layers.Input(shape = (2,),name =\"inputs\") #设置输入名字为inputs\noutputs = layers.Dense(1, name = \"outputs\")(inputs) #设置输出名字为outputs\nlinear = models.Model(inputs = inputs,outputs = outputs)\nlinear.summary()\n\n## 使用fit方法进行训练\nlinear.compile(optimizer=\"rmsprop\",loss=\"mse\",metrics=[\"mae\"])\nlinear.fit(X,Y,batch_size = 8,epochs = 100)  \n\ntf.print(\"w = \",linear.layers[1].kernel)\ntf.print(\"b = \",linear.layers[1].bias)\n\n## 将模型保存成pb格式文件\nexport_path = \"./data/linear_model/\"\nversion = \"1\"       #后续可以通过版本号进行模型版本迭代与管理\nlinear.save(export_path+version, save_format=\"tf\") \n```\n\n```python\n#查看保存的模型文件\n!ls {export_path+version}\n```\n\n```\nassets\tsaved_model.pb\tvariables\n```\n\n```python\n# 查看模型文件相关信息\n!saved_model_cli show --dir {export_path+str(version)} --all\n```\n\n```\nMetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n\nsignature_def['__saved_model_init_op']:\n  The given SavedModel SignatureDef contains the following input(s):\n  The given SavedModel SignatureDef contains the following output(s):\n    outputs['__saved_model_init_op'] tensor_info:\n        dtype: DT_INVALID\n        shape: unknown_rank\n        name: NoOp\n  Method name is: \n\nsignature_def['serving_default']:\n  The given SavedModel SignatureDef contains the following input(s):\n    inputs['inputs'] tensor_info:\n        dtype: DT_FLOAT\n        shape: (-1, 2)\n        name: serving_default_inputs:0\n  The given SavedModel SignatureDef contains the following output(s):\n    outputs['outputs'] tensor_info:\n        dtype: DT_FLOAT\n        shape: (-1, 1)\n        name: StatefulPartitionedCall:0\n  Method name is: tensorflow/serving/predict\nWARNING:tensorflow:From /tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\n\nDefined Functions:\n  Function Name: '__call__'\n    Option #1\n      Callable with:\n        Argument #1\n          inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs')\n        Argument #2\n          DType: bool\n          Value: False\n        Argument #3\n          DType: NoneType\n          Value: None\n    Option #2\n      Callable with:\n        Argument #1\n          inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs')\n        Argument #2\n          DType: bool\n          Value: True\n        Argument #3\n          DType: NoneType\n          Value: None\n\n  Function Name: '_default_save_signature'\n    Option #1\n      Callable with:\n        Argument #1\n          inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs')\n\n  Function Name: 'call_and_return_all_conditional_losses'\n    Option #1\n      Callable with:\n        Argument #1\n          inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs')\n        Argument #2\n          DType: bool\n          Value: True\n        Argument #3\n          DType: NoneType\n          Value: None\n    Option #2\n      Callable with:\n        Argument #1\n          inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs')\n        Argument #2\n          DType: bool\n          Value: False\n        Argument #3\n          DType: NoneType\n          Value: None\n```\n\n```python\n\n```\n\n### 二，安装 tensorflow serving\n\n\n安装 tensorflow serving 有2种主要方法：通过Docker镜像安装，通过apt安装。\n\n通过Docker镜像安装是最简单，最直接的方法，推荐采用。\n\nDocker可以理解成一种容器，其上面可以给各种不同的程序提供独立的运行环境。\n\n一般业务中用到tensorflow的企业都会有运维同学通过Docker 搭建 tensorflow serving.\n\n无需算法工程师同学动手安装，以下安装过程仅供参考。\n\n不同操作系统机器上安装Docker的方法可以参照以下链接。\n\nWindows: https://www.runoob.com/docker/windows-docker-install.html\n\nMacOs: https://www.runoob.com/docker/macos-docker-install.html\n\nCentOS: https://www.runoob.com/docker/centos-docker-install.html\n\n安装Docker成功后，使用如下命令加载 tensorflow/serving 镜像到Docker中\n\ndocker pull tensorflow/serving\n\n\n```python\n\n```\n\n### 三，启动 tensorflow serving 服务\n\n```python\n!docker run -t --rm -p 8501:8501 \\\n    -v \"/Users/.../data/linear_model/\" \\\n    -e MODEL_NAME=linear_model \\\n    tensorflow/serving & >server.log 2>&1\n```\n\n```python\n\n```\n\n### 四，向API服务发送请求\n\n\n可以使用任何编程语言的http功能发送请求，下面示范linux的 curl 命令发送请求，以及Python的requests库发送请求。\n\n```python\n!curl -d '{\"instances\": [[1.0, 2.0], [5.0,7.0]]}' \\\n    -X POST http://localhost:8501/v1/models/linear_model:predict\n```\n\n```\n{\n    \"predictions\": [[3.06546211], [6.02843142]\n    ]\n}\n```\n\n```python\nimport json,requests\n\ndata = json.dumps({\"signature_name\": \"serving_default\", \"instances\": [[1.0, 2.0], [5.0,7.0]]})\nheaders = {\"content-type\": \"application/json\"}\njson_response = requests.post('http://localhost:8501/v1/models/linear_model:predict', \n        data=data, headers=headers)\npredictions = json.loads(json_response.text)[\"predictions\"]\nprint(predictions)\n```\n\n```\n[[3.06546211], [6.02843142]]\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n\n```python\n\n```\n\n```python\n\n```\n"
        },
        {
          "name": "6-7,使用spark-scala调用tensorflow模型.md",
          "type": "blob",
          "size": 9.7265625,
          "content": "# 6-7,使用spark-scala调用tensorflow2.0训练好的模型\n\n本篇文章介绍在spark中调用训练好的tensorflow模型进行预测的方法。\n\n本文内容的学习需要一定的spark和scala基础。\n\n如果使用pyspark的话会比较简单，只需要在每个executor上用Python加载模型分别预测就可以了。\n\n但工程上为了性能考虑，通常使用的是scala版本的spark。\n\n本篇文章我们通过TensorFlow for Java 在spark中调用训练好的tensorflow模型。\n\n利用spark的分布式计算能力，从而可以让训练好的tensorflow模型在成百上千的机器上分布式并行执行模型推断。\n\n\n\n\n```python\n\n```\n\n### 〇，spark-scala调用tensorflow模型概述\n\n\n在spark(scala)中调用tensorflow模型进行预测需要完成以下几个步骤。\n\n（1）准备protobuf模型文件\n\n（2）创建spark(scala)项目，在项目中添加java版本的tensorflow对应的jar包依赖\n\n（3）在spark(scala)项目中driver端加载tensorflow模型调试成功\n\n（4）在spark(scala)项目中通过RDD在executor上加载tensorflow模型调试成功\n\n（5） 在spark(scala)项目中通过DataFrame在executor上加载tensorflow模型调试成功\n\n\n```python\n\n```\n\n### 一，准备protobuf模型文件\n\n\n我们使用tf.keras 训练一个简单的线性回归模型，并保存成protobuf文件。\n\n```python\n\n```\n\n```python\nimport tensorflow as tf\nfrom tensorflow.keras import models,layers,optimizers\n\n## 样本数量\nn = 800\n\n## 生成测试用数据集\nX = tf.random.uniform([n,2],minval=-10,maxval=10) \nw0 = tf.constant([[2.0],[-1.0]])\nb0 = tf.constant(3.0)\n\nY = X@w0 + b0 + tf.random.normal([n,1],mean = 0.0,stddev= 2.0)  # @表示矩阵乘法,增加正态扰动\n\n## 建立模型\ntf.keras.backend.clear_session()\ninputs = layers.Input(shape = (2,),name =\"inputs\") #设置输入名字为inputs\noutputs = layers.Dense(1, name = \"outputs\")(inputs) #设置输出名字为outputs\nlinear = models.Model(inputs = inputs,outputs = outputs)\nlinear.summary()\n\n## 使用fit方法进行训练\nlinear.compile(optimizer=\"rmsprop\",loss=\"mse\",metrics=[\"mae\"])\nlinear.fit(X,Y,batch_size = 8,epochs = 100)  \n\ntf.print(\"w = \",linear.layers[1].kernel)\ntf.print(\"b = \",linear.layers[1].bias)\n\n## 将模型保存成pb格式文件\nexport_path = \"./data/linear_model/\"\nversion = \"1\"       #后续可以通过版本号进行模型版本迭代与管理\nlinear.save(export_path+version, save_format=\"tf\") \n\n```\n\n```python\n\n```\n\n```python\n!ls {export_path+version}\n```\n\n```python\n# 查看模型文件相关信息\n!saved_model_cli show --dir {export_path+str(version)} --all\n```\n\n```python\n\n```\n\n模型文件信息中这些标红的部分都是后面有可能会用到的。\n\n![](./data/模型文件信息.png)\n\n```python\n\n```\n\n### 二，创建spark(scala)项目，在项目中添加java版本的tensorflow对应的jar包依赖\n\n```python\n\n```\n\n如果使用maven管理项目，需要添加如下 jar包依赖\n\n```\n<!-- https://mvnrepository.com/artifact/org.tensorflow/tensorflow -->\n<dependency>\n    <groupId>org.tensorflow</groupId>\n    <artifactId>tensorflow</artifactId>\n    <version>1.15.0</version>\n</dependency>\n```\n\n也可以从下面网址中直接下载 org.tensorflow.tensorflow的jar包\n\n以及其依赖的org.tensorflow.libtensorflow 和 org.tensorflowlibtensorflow_jni的jar包 放到项目中。\n\nhttps://mvnrepository.com/artifact/org.tensorflow/tensorflow/1.15.0\n\n\n```python\n\n```\n\n```python\n\n```\n\n### 三， 在spark(scala)项目中driver端加载tensorflow模型调试成功\n\n\n我们的示范代码在jupyter notebook中进行演示，需要安装toree以支持spark(scala)。\n\n<!-- #region -->\n```scala\nimport scala.collection.mutable.WrappedArray\nimport org.{tensorflow=>tf}\n\n//注：load函数的第二个参数一般都是“serve”，可以从模型文件相关信息中找到\n\nval bundle = tf.SavedModelBundle \n   .load(\"/Users/liangyun/CodeFiles/eat_tensorflow2_in_30_days/data/linear_model/1\",\"serve\")\n\n//注：在java版本的tensorflow中还是类似tensorflow1.0中静态计算图的模式，需要建立Session, 指定feed的数据和fetch的结果, 然后 run.\n//注：如果有多个数据需要喂入，可以连续使用多个feed方法\n//注：输入必须是float类型\n\nval sess = bundle.session()\nval x = tf.Tensor.create(Array(Array(1.0f,2.0f),Array(2.0f,3.0f)))\nval y =  sess.runner().feed(\"serving_default_inputs:0\", x)\n         .fetch(\"StatefulPartitionedCall:0\").run().get(0)\n\nval result = Array.ofDim[Float](y.shape()(0).toInt,y.shape()(1).toInt)\ny.copyTo(result)\n\nif(x != null) x.close()\nif(y != null) y.close()\nif(sess != null) sess.close()\nif(bundle != null) bundle.close()  \n\nresult\n\n```\n<!-- #endregion -->\n\n输出如下：\n\n```\nArray(Array(3.019596), Array(3.9878292))\n```\n\n\n![](./data/TfDriver.png)\n\n```python\n\n```\n\n### 四，在spark(scala)项目中通过RDD在executor上加载tensorflow模型调试成功\n\n\n下面我们通过广播机制将Driver端加载的TensorFlow模型传递到各个executor上，并在executor上分布式地调用模型进行推断。\n\n\n<!-- #region -->\n```scala\nimport org.apache.spark.sql.SparkSession\nimport scala.collection.mutable.WrappedArray\nimport org.{tensorflow=>tf}\n\nval spark = SparkSession\n    .builder()\n    .appName(\"TfRDD\")\n    .enableHiveSupport()\n    .getOrCreate()\n\nval sc = spark.sparkContext\n\n//在Driver端加载模型\nval bundle = tf.SavedModelBundle \n   .load(\"/Users/liangyun/CodeFiles/master_tensorflow2_in_20_hours/data/linear_model/1\",\"serve\")\n\n//利用广播将模型发送到executor上\nval broads = sc.broadcast(bundle)\n\n//构造数据集\nval rdd_data = sc.makeRDD(List(Array(1.0f,2.0f),Array(3.0f,5.0f),Array(6.0f,7.0f),Array(8.0f,3.0f)))\n\n//通过mapPartitions调用模型进行批量推断\nval rdd_result = rdd_data.mapPartitions(iter => {\n    \n    val arr = iter.toArray\n    val model = broads.value\n    val sess = model.session()\n    val x = tf.Tensor.create(arr)\n    val y =  sess.runner().feed(\"serving_default_inputs:0\", x)\n             .fetch(\"StatefulPartitionedCall:0\").run().get(0)\n\n    //将预测结果拷贝到相同shape的Float类型的Array中\n    val result = Array.ofDim[Float](y.shape()(0).toInt,y.shape()(1).toInt)\n    y.copyTo(result)\n    result.iterator\n    \n})\n\n\nrdd_result.take(5)\nbundle.close\n```\n<!-- #endregion -->\n\n```python\n\n```\n\n输出如下：\n\n```\nArray(Array(3.019596), Array(3.9264367), Array(7.8607616), Array(15.974984))\n```\n\n\n![](./data/TfRDD.png)\n\n```python\n\n```\n\n### 五， 在spark(scala)项目中通过DataFrame在executor上加载tensorflow模型调试成功\n\n\n除了可以在Spark的RDD数据上调用tensorflow模型进行分布式推断，\n\n我们也可以在DataFrame数据上调用tensorflow模型进行分布式推断。\n\n主要思路是将推断方法注册成为一个sparkSQL函数。\n\n<!-- #region -->\n```scala\nimport org.apache.spark.sql.SparkSession\nimport scala.collection.mutable.WrappedArray\nimport org.{tensorflow=>tf}\n\nobject TfDataFrame extends Serializable{\n    \n    \n    def main(args:Array[String]):Unit = {\n        \n        val spark = SparkSession\n        .builder()\n        .appName(\"TfDataFrame\")\n        .enableHiveSupport()\n        .getOrCreate()\n        val sc = spark.sparkContext\n        \n        \n        import spark.implicits._\n\n        val bundle = tf.SavedModelBundle \n           .load(\"/Users/liangyun/CodeFiles/master_tensorflow2_in_20_hours/data/linear_model/1\",\"serve\")\n\n        val broads = sc.broadcast(bundle)\n        \n        //构造预测函数，并将其注册成sparkSQL的udf\n        val tfpredict = (features:WrappedArray[Float])  => {\n            val bund = broads.value\n            val sess = bund.session()\n            val x = tf.Tensor.create(Array(features.toArray))\n            val y =  sess.runner().feed(\"serving_default_inputs:0\", x)\n                     .fetch(\"StatefulPartitionedCall:0\").run().get(0)\n            val result = Array.ofDim[Float](y.shape()(0).toInt,y.shape()(1).toInt)\n            y.copyTo(result)\n            val y_pred = result(0)(0)\n            y_pred\n        }\n        spark.udf.register(\"tfpredict\",tfpredict)\n        \n        //构造DataFrame数据集，将features放到一列中\n        val dfdata = sc.parallelize(List(Array(1.0f,2.0f),Array(3.0f,5.0f),Array(7.0f,8.0f))).toDF(\"features\")\n        dfdata.show \n        \n        //调用sparkSQL预测函数，增加一个新的列作为y_preds\n        val dfresult = dfdata.selectExpr(\"features\",\"tfpredict(features) as y_preds\")\n        dfresult.show \n        bundle.close\n    }\n}\n\n```\n\n<!-- #endregion -->\n\n<!-- #region -->\n```scala\nTfDataFrame.main(Array())\n```\n<!-- #endregion -->\n\n```\n+----------+\n|  features|\n+----------+\n|[1.0, 2.0]|\n|[3.0, 5.0]|\n|[7.0, 8.0]|\n+----------+\n\n+----------+---------+\n|  features|  y_preds|\n+----------+---------+\n|[1.0, 2.0]| 3.019596|\n|[3.0, 5.0]|3.9264367|\n|[7.0, 8.0]| 8.828995|\n+----------+---------+\n```\n\n\n以上我们分别在spark 的RDD数据结构和DataFrame数据结构上实现了调用一个tf.keras实现的线性回归模型进行分布式模型推断。\n\n在本例基础上稍作修改则可以用spark调用训练好的各种复杂的神经网络模型进行分布式模型推断。\n\n但实际上tensorflow并不仅仅适合实现神经网络，其底层的计算图语言可以表达各种数值计算过程。\n\n利用其丰富的低阶API，我们可以在tensorflow2.0上实现任意机器学习模型，\n\n结合tf.Module提供的便捷的封装功能，我们可以将训练好的任意机器学习模型导出成模型文件并在spark上分布式调用执行。\n\n这无疑为我们的工程应用提供了巨大的想象空间。\n\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 23.263671875,
          "content": "# How to eat TensorFlow2 in 30 days ?🔥🔥\n\nClick here for [Chinese Version（中文版）](#30天吃掉那只-tensorflow2)\n\n**《10天吃掉那只pyspark》**\n* 🚀 github项目地址: https://github.com/lyhue1991/eat_pyspark_in_10_days\n* 🐳 和鲸专栏地址: https://www.heywhale.com/home/column/5fe6aa955e24ed00302304e0 【代码可直接fork后云端运行，无需配置环境】\n\n\n**《20天吃掉那只Pytorch》**\n* 🚀 github项目地址: https://github.com/lyhue1991/eat_pytorch_in_20_days\n* 🐳 和鲸专栏地址: https://www.heywhale.com/home/column/5f2ac5d8af3980002cb1bc08 【代码可直接fork后云端运行，无需配置环境】\n\n\n**《30天吃掉那只TensorFlow2》**\n* 🚀 github项目地址: https://github.com/lyhue1991/eat_tensorflow2_in_30_days\n* 🐳 和鲸专栏地址: https://www.heywhale.com/home/column/5d8ef3c3037db3002d3aa3a0 【代码可直接fork后云端运行，无需配置环境】\n\n**极速通道** \n*  🚀 公众号 “**算法美食屋**” 后台回复暗号：\"**吃货来了**\"\n*  😋 获取以上3套教程的jupyter notebook 源码文件以及全部数据集的百度云盘下载链接。\n*   https://mp.weixin.qq.com/s/ymLtH5BqlWAkpOmCLQOYxw \n\n\n### 1. TensorFlow2 🍎 or Pytorch🔥\n\nConclusion first: \n\n**For the engineers, priority goes to TensorFlow2.**\n\n**For the students and researchers，first choice should be Pytorch.**\n\n**The best way is to master both of them if having sufficient time.**\n\n\nReasons:\n\n* 1. **Model implementation is the most important in the industry. Deployment supporting tensorflow models (not Pytorch) exclusively is the present situation in the majority of the Internet enterprises in China.** What's more, the industry prefers the models with higher availability; in most cases, they use well-validated modeling architectures with the minimized requirements of adjustment.\n\n\n* 2. **Fast iterative development and publication is the most important for the researchers since they need to test a lot of new models. Pytorch has advantages in accessing and debugging comparing with TensorFlow2.** Pytorch is most frequently used in academy since 2019 with a large amount of the cutting-edge results.\n\n\n* 3. Overall, TensorFlow2 and Pytorch are quite similar in programming nowadays, so mastering one helps learning the other. Mastering both framework provides you a lot more open-sourced models and helps you switching between them.\n\n```python\n\n```\n\n### 2. Keras🍏 and tf.keras 🍎\n\nConclusion first: \n\n**Keras will be discontinued in development after version 2.3.0, so use tf.keras.**\n\n\nKeras is a high-level API for the deep learning frameworks. It help the users to define and training DL networks with a more intuitive way.\n\nThe Keras libraries installed by pip implement this high-level API for the backends in tensorflow, theano, CNTK, etc.\n\ntf.keras is the high-level API just for Tensorflow, which is based on low-level APIs in Tensorflow.\n\nMost but not all of the functions in tf.keras are the same for those in Keras (which is compatible to many kinds of backend). tf.keras has a tighter combination to TensorFlow comparing to Keras.\n\nWith the acquisition by Google, Keras will not update after version 2.3.0 , thus the users should use tf.keras from now on, instead of using Keras installed by pip.\n\n```python\n\n```\n\n### 3. What Should You Know Before Reading This Book 📖?\n\n**It is suggested that the readers have foundamental knowledges of machine/deep learning and experience of modeling using Keras or TensorFlow 1.0.**\n\n**For those who have zero experience of machine/deep learning, it is strongly suggested to refer to [\"Deep Learning with Python\"](https://www.amazon.com/Deep-Learning-Python-Francois-Chollet/dp/1617294438/ref=sr_1_1?dchild=1&keywords=Deep+Learning+with+Python&qid=1586194568&sr=8-1) along with reading this book.**\n\n\n[\"Deep Learning with Python\"](https://www.amazon.com/Deep-Learning-Python-Francois-Chollet/dp/1617294438/ref=sr_1_1?dchild=1&keywords=Deep+Learning+with+Python&qid=1586194568&sr=8-1) is written by François Chollet, the inventor of Keras. This book is based on Keras and has no machine learning related prerequisites to the reader.\n\n\"Deep Learning with Python\" is easy to understand as it uses various examples to demonstrate. **No mathematical equation is in this book since it focuses on cultivating the intuitive to the deep learning.**\n\n\n```python\n\n```\n\n### 4. Writing Style 🍉 of This Book\n\n\n**This is a introduction reference book which is extremely friendly to human being. The lowest goal of the authors is to avoid giving up due to the difficulties, while \"Don't let the readers think\" is the highest target.**\n\nThis book is mainly based on the official documents of TensorFlow together with its functions.\n\nHowever, the authors made a thorough restructuring and a lot optimizations on the demonstrations.\n\nIt is different from the official documents, which is disordered and contains both tutorial and guidance with lack of systematic logic, that our book redesigns the content according to the difficulties, readers' searching habits, and the architecture of TensorFlow. We now make it progressive for TensorFlow studying with a clear path, and an easy access to the corresponding examples.\n\nIn contrast to the verbose demonstrating code, the authors of this book try to minimize the length of the examples to make it easy for reading and implementation. What's more, most of the code cells can be used in your project instantaneously.\n\n**Given the level of difficulty as 9 for learning Tensorflow through official documents, it would be reduced to 3 if learning through this book.**\n\nThis difference in difficulties could be demonstrated as the following figure:\n\n![](./data/30天吃掉那个TF2.0_en.jpg)\n\n\n```python\n\n```\n\n### 5. How to Learn With This Book ⏰\n\n**(1) Study Plan**\n\nThe authors wrote this book using the spare time, especially the two-month unexpected \"holiday\" of COVID-19. Most readers should be able to completely master all the content within 30 days.\n\nTime required everyday would be between 30 minutes to 2 hours.\n\nThis book could also be used as library examples to consult when implementing machine learning projects with TensorFlow2.\n\n**Click the blue captions to enter the corresponding chapter.**\n\n\n|Date |Contents                                                       | Difficulties   | Est. Time | Update Status|\n|----:|:--------------------------------------------------------------|-----------:|----------:|-----:|\n|&nbsp;|[**Chapter 1: Modeling Procedure of TensorFlow**](./english/Chapter1.md)    |⭐️   |   0hour   |✅    |\n|Day 1 |  [1-1 Example: Modeling Procedure for Structured Data](./english/Chapter1-1.md)    | ⭐️⭐️⭐️ |   1hour    |✅    |\n|Day 2 |[1-2 Example: Modeling Procedure for Images](./english/Chapter1-2.md)    | ⭐️⭐️⭐️⭐️  |   2hours    |✅    |\n|Day 3 |  [1-3 Example: Modeling Procedure for Texts](./english/Chapter1-3.md)   | ⭐️⭐️⭐️⭐️⭐️  |   2hours    |✅    |\n|Day 4 |  [1-4 Example: Modeling Procedure for Temporal Sequences](./english/Chapter1-4.md)   | ⭐️⭐️⭐️⭐️⭐️  |   2hours    |✅    |\n|&nbsp;    |[**Chapter 2: Key Concepts of TensorFlow**](./english/Chapter2.md)  | ⭐️  |  0hour |✅  |\n|Day 5 |  [2-1 Data Structure of Tensor](./english/Chapter2-1.md)  | ⭐️⭐️⭐️⭐️   |   1hour    |✅    |\n|Day 6 |  [2-2 Three Types of Graph](./english/Chapter2-2.md)  | ⭐️⭐️⭐️⭐️⭐️   |   2hours    |✅    |\n|Day 7 |  [2-3 Automatic Differentiate](./english/Chapter2-3.md)  | ⭐️⭐️⭐️   |   1hour    |✅    |\n|&nbsp; |[**Chapter 3: Hierarchy of TensorFlow**](./english/Chapter3.md) |   ⭐️  |  0hour   |✅  |\n|Day 8 |  [3-1 Low-level API: Demonstration](./english/Chapter3-1.md)   | ⭐️⭐️⭐️⭐️ |   1hour    |✅   |\n|Day 9 |  [3-2 Mid-level API: Demonstration](./english/Chapter3-2.md)   | ⭐️⭐️⭐️   |   1hour    |✅  |\n|Day 10 |  [3-3 High-level API: Demonstration](./english/Chapter3-3.md)  | ⭐️⭐️⭐️   |   1hour    |✅  |\n|&nbsp; |[**Chapter 4: Low-level API in TensorFlow**](./english/Chapter4.md) |⭐️    | 0hour|✅  |\n|Day 11|  [4-1 Structural Operations of the Tensor](./english/Chapter4-1.md)  | ⭐️⭐️⭐️⭐️⭐️   |   2hours    |✅   |\n|Day 12|  [4-2 Mathematical Operations of the Tensor](./english/Chapter4-2.md)   | ⭐️⭐️⭐️⭐️   |   1hour    |✅  |\n|Day 13|  [4-3 Rules of Using the AutoGraph](./english/Chapter4-3.md)| ⭐️⭐️⭐️   |   0.5hour    | ✅  |\n|Day 14|  [4-4 Mechanisms of the AutoGraph](./english/Chapter4-4.md)    | ⭐️⭐️⭐️⭐️⭐️   |   2hours    |✅  |\n|Day 15|  [4-5 AutoGraph and tf.Module](./english/Chapter4-5.md)  | ⭐️⭐️⭐️⭐️   |   1hour    |✅  |\n|&nbsp; |[**Chapter 5: Mid-level API in TensorFlow**](./english/Chapter5.md) |  ⭐️  | 0hour|✅ |\n|Day 16|  [5-1 Dataset](./english/Chapter5-1.md)   | ⭐️⭐️⭐️⭐️⭐️   |   2hours    |✅  |\n|Day 17|  [5-2 feature_column](./english/Chapter5-2.md)   | ⭐️⭐️⭐️⭐️   |   1hour    |✅  |\n|Day 18|  [5-3 activation](./english/Chapter5-3.md)    | ⭐️⭐️⭐️   |   0.5hour    |✅   |\n|Day 19|  [5-4 layers](./english/Chapter5-4.md)  | ⭐️⭐️⭐️   |   1hour    |✅  |\n|Day 20|  [5-5 losses](./english/Chapter5-5.md)    | ⭐️⭐️⭐️   |   1hour    |✅  |\n|Day 21|  [5-6 metrics](./english/Chapter5-6.md)    | ⭐️⭐️⭐️   |   1hour    |✅   |\n|Day 22|  [5-7 optimizers](./english/Chapter5-7.md)    | ⭐️⭐️⭐️   |   0.5hour    |✅   |\n|Day 23|  [5-8 callbacks](./english/Chapter5-8.md)   | ⭐️⭐️⭐️⭐️   |   1hour    |✅   |\n|&nbsp; |[**Chapter 6: High-level API in TensorFlow**](./english/Chapter6.md)|    ⭐️ | 0hour|✅  |\n|Day 24|  [6-1 Three Ways of Modeling](./english/Chapter6-1.md)   | ⭐️⭐️⭐️   |   1hour    |✅ |\n|Day 25|  [6-2 Three Ways of Training](./english/Chapter6-2.md)  | ⭐️⭐️⭐️⭐️   |   1hour    |✅   |\n|Day 26|  [6-3 Model Training Using Single GPU](./english/Chapter6-3.md)    | ⭐️⭐️   |   0.5hour    |✅   |\n|Day 27|  [6-4 Model Training Using Multiple GPUs](./english/Chapter6-4.md)    | ⭐️⭐️   |   0.5hour    |✅  |\n|Day 28|  [6-5 Model Training Using TPU](./english/Chapter6-5.md)   | ⭐️⭐️   |   0.5hour    |✅  |\n|Day 29| [6-6 Model Deploying Using tensorflow-serving](./english/Chapter6-6.md) | ⭐️⭐️⭐️⭐️| 1hour |✅   |\n|Day 30| [6-7 Call Tensorflow Model Using spark-scala](./english/Chapter6-7.md) | ⭐️⭐️⭐️⭐️⭐️|2hours|✅  |\n|&nbsp;| [Epilogue: A Story Between a Foodie and Cuisine](./english/Epilogue.md) | ⭐️|0hour|✅  |\n\n```python\n\n```\n\n**(2) Software environment for studying**\n\n\nAll the source codes are tested in jupyter. It is suggested to clone the repository to local machine and run them in jupyter for an interactive learning experience.\n\nThe authors would suggest to install jupytext that converts markdown files into ipynb, so the readers would be able to open markdown files in jupyter directly.\n\n```python\n#For the readers in mainland China, using gitee will allow cloning with a faster speed\n#!git clone https://gitee.com/Python_Ai_Road/eat_tensorflow2_in_30_days\n\n#It is suggested to install jupytext that converts and run markdown files as ipynb.\n#!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -U jupytext\n    \n#It is also suggested to install the latest version of TensorFlow to test the demonstrating code in this book\n#!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple  -U tensorflow\n```\n\n```python\nimport tensorflow as tf\n\n#Note: all the codes are tested under TensorFlow 2.1\ntf.print(\"tensorflow version:\",tf.__version__)\n\na = tf.constant(\"hello\")\nb = tf.constant(\"tensorflow2\")\nc = tf.strings.join([a,b],\" \")\ntf.print(c)\n```\n\n```\ntensorflow version: 2.1.0\nhello tensorflow2\n```\n\n```python\n\n```\n\n### 6. Contact and support the author 🎈🎈\n\n\n**If you find this book helpful and want to support the author, please give a star ⭐️ to this repository and don't forget to share it to your friends 😊** \n\nPlease leave comments in the WeChat official account \"算法美食屋\" (Machine Learning  cook house) if you want to communicate with the author about the content. The author will try best to reply given the limited time available.\n\n![image.png](./data/算法美食屋二维码.jpg)\n\n```python\n\n```\n# 30天吃掉那只 TensorFlow2\n\n📚 gitbook电子书地址： https://lyhue1991.github.io/eat_tensorflow2_in_30_days\n\n🚀 github项目地址：https://github.com/lyhue1991/eat_tensorflow2_in_30_days\n\n🐳 kesci专栏地址：https://www.kesci.com/home/column/5d8ef3c3037db3002d3aa3a0\n\n**极速通道** \n*  🚀 公众号 “**算法美食屋**” 后台回复暗号：\"**吃货来了**\"\n*  😋 获取教程的jupyter notebook 源码文件以及全部数据集的百度云盘下载链接。\n*  https://mp.weixin.qq.com/s/ymLtH5BqlWAkpOmCLQOYxw\n\n\n\n### 一，TensorFlow2 🍎 or Pytorch🔥\n\n先说结论:\n\n**如果是工程师，应该优先选TensorFlow2.**\n\n**如果是学生或者研究人员，应该优先选择Pytorch.**\n\n**如果时间足够，最好TensorFlow2和Pytorch都要学习掌握。**\n\n\n理由如下：\n\n* 1，**在工业界最重要的是模型落地，目前国内的大部分互联网企业只支持TensorFlow模型的在线部署，不支持Pytorch。** 并且工业界更加注重的是模型的高可用性，许多时候使用的都是成熟的模型架构，调试需求并不大。\n\n\n* 2，**研究人员最重要的是快速迭代发表文章，需要尝试一些较新的模型架构。而Pytorch在易用性上相比TensorFlow2有一些优势，更加方便调试。** 并且在2019年以来在学术界占领了大半壁江山，能够找到的相应最新研究成果更多。\n\n\n* 3，TensorFlow2和Pytorch实际上整体风格已经非常相似了，学会了其中一个，学习另外一个将比较容易。两种框架都掌握的话，能够参考的开源模型案例更多，并且可以方便地在两种框架之间切换。\n\n```python\n\n```\n\n### 二，Keras🍏 and  tf.keras 🍎\n\n先说结论：\n\n**Keras库在2.3.0版本后将不再更新，用户应该使用tf.keras。**\n\n\nKeras可以看成是一种深度学习框架的高阶接口规范，它帮助用户以更简洁的形式定义和训练深度学习网络。\n\n使用pip安装的Keras库同时在tensorflow,theano,CNTK等后端基础上进行了这种高阶接口规范的实现。\n\n而tf.keras是在TensorFlow中以TensorFlow低阶API为基础实现的这种高阶接口，它是Tensorflow的一个子模块。\n\ntf.keras绝大部分功能和兼容多种后端的Keras库用法完全一样，但并非全部，它和TensorFlow之间的结合更为紧密。\n\n随着谷歌对Keras的收购，Keras库2.3.0版本后也将不再进行更新，用户应当使用tf.keras而不是使用pip安装的Keras.\n\n```python\n\n```\n\n### 三，本书📖面向读者 👼\n\n\n**本书假定读者有一定的机器学习和深度学习基础，使用过Keras或者Tensorflow1.0或者Pytorch搭建训练过模型。**\n\n**对于没有任何机器学习和深度学习基础的同学，建议在学习本书时同步参考学习《Python深度学习》一书。**\n\n《Python深度学习》这本书是Keras之父Francois Chollet所著，该书假定读者无任何机器学习知识，以Keras为工具，\n\n使用丰富的范例示范深度学习的最佳实践，该书通俗易懂，**全书没有一个数学公式，注重培养读者的深度学习直觉。**。\n\n```python\n\n```\n\n### 四，本书写作风格 🍉\n\n\n**本书是一本对人类用户极其友善的TensorFlow2.0入门工具书，不刻意恶心读者是本书的底限要求，Don't let me think是本书的最高追求。**\n\n本书主要是在参考TensorFlow官方文档和函数doc文档基础上整理写成的。\n\n但本书在篇章结构和范例选取上做了大量的优化。\n\n不同于官方文档混乱的篇章结构，既有教程又有指南，缺少整体的编排逻辑。\n\n本书按照内容难易程度、读者检索习惯和TensorFlow自身的层次结构设计内容，循序渐进，层次清晰，方便按照功能查找相应范例。\n\n不同于官方文档冗长的范例代码，本书在范例设计上尽可能简约化和结构化，增强范例易读性和通用性，大部分代码片段在实践中可即取即用。\n\n**如果说通过学习TensorFlow官方文档掌握TensorFlow2.0的难度大概是9的话，那么通过学习本书掌握TensorFlow2.0的难度应该大概是3.**\n\n谨以下图对比一下TensorFlow官方教程与本教程的差异。\n\n![](./data/30天吃掉那个TF2.0.jpg)\n\n\n```python\n\n```\n\n### 五，本书学习方案 ⏰\n\n**1，学习计划**\n\n本书是作者利用工作之余和疫情放假期间大概2个月写成的，大部分读者应该在30天可以完全学会。\n\n预计每天花费的学习时间在30分钟到2个小时之间。\n\n当然，本书也非常适合作为TensorFlow的工具手册在工程落地时作为范例库参考。\n\n**点击学习内容蓝色标题即可进入该章节。**\n\n\n|日期 | 学习内容                                                       | 内容难度   | 预计学习时间 | 更新状态|\n|----:|:--------------------------------------------------------------|-----------:|----------:|-----:|\n|&nbsp;|[**一、TensorFlow的建模流程**](./一、TensorFlow的建模流程.md)    |⭐️   |   0hour   |✅    |\n|day1 |  [1-1,结构化数据建模流程范例](./1-1,结构化数据建模流程范例.md)    | ⭐️⭐️⭐️ |   1hour    |✅    |\n|day2 |[1-2,图片数据建模流程范例](./1-2,图片数据建模流程范例.md)    | ⭐️⭐️⭐️⭐️  |   2hour    |✅    |\n|day3 |  [1-3,文本数据建模流程范例](./1-3,文本数据建模流程范例.md)   | ⭐️⭐️⭐️⭐️⭐️  |   2hour    |✅    |\n|day4 |  [1-4,时间序列数据建模流程范例](./1-4,时间序列数据建模流程范例.md)   | ⭐️⭐️⭐️⭐️⭐️  |   2hour    |✅    |\n|&nbsp;    |[**二、TensorFlow的核心概念**](./二、TensorFlow的核心概念.md)  | ⭐️  |  0hour |✅  |\n|day5 |  [2-1,张量数据结构](./2-1,张量数据结构.md)  | ⭐️⭐️⭐️⭐️   |   1hour    |✅    |\n|day6 |  [2-2,三种计算图](./2-2,三种计算图.md)  | ⭐️⭐️⭐️⭐️⭐️   |   2hour    |✅    |\n|day7 |  [2-3,自动微分机制](./2-3,自动微分机制.md)  | ⭐️⭐️⭐️   |   1hour    |✅    |\n|&nbsp; |[**三、TensorFlow的层次结构**](./三、TensorFlow的层次结构.md) |   ⭐️  |  0hour   |✅  |\n|day8 |  [3-1,低阶API示范](./3-1,低阶API示范.md)   | ⭐️⭐️⭐️⭐️   |   1hour    |✅   |\n|day9 |  [3-2,中阶API示范](./3-2,中阶API示范.md)   | ⭐️⭐️⭐️   |  1hour    |✅  |\n|day10 |  [3-3,高阶API示范](./3-3,高阶API示范.md)  | ⭐️⭐️⭐️  |   1hour    |✅  |\n|&nbsp; |[**四、TensorFlow的低阶API**](./四、TensorFlow的低阶API.md) |⭐️    | 0hour|✅  |\n|day11|  [4-1,张量的结构操作](./4-1,张量的结构操作.md)  | ⭐️⭐️⭐️⭐️⭐️   |   2hour    |✅   |\n|day12|  [4-2,张量的数学运算](./4-2,张量的数学运算.md)   | ⭐️⭐️⭐️⭐️   |   1hour    |✅  |\n|day13|  [4-3,AutoGraph的使用规范](./4-3,AutoGraph的使用规范.md)| ⭐️⭐️⭐️   |   0.5hour    |✅  |\n|day14|  [4-4,AutoGraph的机制原理](./4-4,AutoGraph的机制原理.md)    | ⭐️⭐️⭐️⭐️⭐️   |   2hour    |✅  |\n|day15|  [4-5,AutoGraph和tf.Module](./4-5,AutoGraph和tf.Module.md)  | ⭐️⭐️⭐️⭐️   |   1hour    |✅  |\n|&nbsp; |[**五、TensorFlow的中阶API**](./五、TensorFlow的中阶API.md) |  ⭐️  | 0hour|✅ |\n|day16|  [5-1,数据管道Dataset](./5-1,数据管道Dataset.md)   | ⭐️⭐️⭐️⭐️⭐️   |   2hour    |✅  |\n|day17|  [5-2,特征列feature_column](./5-2,特征列feature_column.md)   | ⭐️⭐️⭐️⭐️   |   1hour    |✅  |\n|day18|  [5-3,激活函数activation](./5-3,激活函数activation.md)    | ⭐️⭐️⭐️   |   0.5hour    |✅   |\n|day19|  [5-4,模型层layers](./5-4,模型层layers.md)  | ⭐️⭐️⭐️   |   1hour    |✅  |\n|day20|  [5-5,损失函数losses](./5-5,损失函数losses.md)    | ⭐️⭐️⭐️   |   1hour    |✅  |\n|day21|  [5-6,评估指标metrics](./5-6,评估指标metrics.md)    | ⭐️⭐️⭐️   |   1hour    |✅   |\n|day22|  [5-7,优化器optimizers](./5-7,优化器optimizers.md)    | ⭐️⭐️⭐️   |   0.5hour    |✅   |\n|day23|  [5-8,回调函数callbacks](./5-8,回调函数callbacks.md)   | ⭐️⭐️⭐️⭐️   |   1hour    |✅   |\n|&nbsp; |[**六、TensorFlow的高阶API**](./六、TensorFlow的高阶API.md)|    ⭐️ | 0hour|✅  |\n|day24|  [6-1,构建模型的3种方法](./6-1,构建模型的3种方法.md)   | ⭐️⭐️⭐️   |   1hour    |✅ |\n|day25|  [6-2,训练模型的3种方法](./6-2,训练模型的3种方法.md)  | ⭐️⭐️⭐️⭐️   |   1hour    |✅   |\n|day26|  [6-3,使用单GPU训练模型](./6-3,使用单GPU训练模型.md)    | ⭐️⭐️   |   0.5hour    |✅   |\n|day27|  [6-4,使用多GPU训练模型](./6-4,使用多GPU训练模型.md)    | ⭐️⭐️   |   0.5hour    |✅  |\n|day28|  [6-5,使用TPU训练模型](./6-5,使用TPU训练模型.md)   | ⭐️⭐️   |   0.5hour    |✅  |\n|day29| [6-6,使用tensorflow-serving部署模型](./6-6,使用tensorflow-serving部署模型.md) | ⭐️⭐️⭐️⭐️| 1hour |✅   |\n|day30| [6-7,使用spark-scala调用tensorflow模型](./6-7,使用spark-scala调用tensorflow模型.md) | ⭐️⭐️⭐️⭐️⭐️|2hour|✅  |\n|&nbsp;| [后记：一个吃货和一道菜的故事](./后记：一个吃货和一道菜的故事.md) | ⭐️|0hour|✅  |\n\n\n```python\n\n```\n\n**2，学习环境**\n\n\n本书全部源码在jupyter中编写测试通过，建议通过git克隆到本地，并在jupyter中交互式运行学习。\n\n为了直接能够在jupyter中打开markdown文件，建议安装jupytext，将markdown转换成ipynb文件。\n\n**此外，本项目也与和鲸社区达成了合作，可以在和鲸专栏fork本项目，并直接在云笔记本上运行代码，避免环境配置痛苦。** \n\n🐳和鲸专栏地址：https://www.kesci.com/home/column/5d8ef3c3037db3002d3aa3a0\n\n```python\n#克隆本书源码到本地,使用码云镜像仓库国内下载速度更快\n#!git clone https://gitee.com/Python_Ai_Road/eat_tensorflow2_in_30_days\n\n#建议在jupyter notebook 上安装jupytext，以便能够将本书各章节markdown文件视作ipynb文件运行\n#!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -U jupytext\n    \n#建议在jupyter notebook 上安装最新版本tensorflow 测试本书中的代码\n#!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple  -U tensorflow\n```\n\n```python\nimport tensorflow as tf\n\n#注：本书全部代码在tensorflow 2.1版本测试通过\ntf.print(\"tensorflow version:\",tf.__version__)\n\na = tf.constant(\"hello\")\nb = tf.constant(\"tensorflow2\")\nc = tf.strings.join([a,b],\" \")\ntf.print(c)\n```\n\n```\ntensorflow version: 2.1.0\nhello tensorflow2\n```\n\n\n\n\n```python\n\n```\n\n### 六，鼓励和联系作者 🎈🎈\n\n\n**如果本书对你有所帮助，想鼓励一下作者，记得给本项目加一颗星星star⭐️，并分享给你的朋友们喔😊!** \n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![image.png](./data/算法美食屋二维码.jpg)\n\n```python\n\n```\n"
        },
        {
          "name": "README_eng.md",
          "type": "blob",
          "size": 11.4970703125,
          "content": "# How to eat TensorFlow2 in 30 days ?🔥🔥\n\nSwitching to Chinese version: [中文版](https://github.com/lyhue1991/eat_tensorflow2_in_30_days/tree/master) 🎈\n\n📚 URL to gitbook (Only in Chinese version for now):  https://lyhue1991.github.io/eat_tensorflow2_in_30_days\n\n🚀 URL to github repo (Chinese): https://github.com/lyhue1991/eat_tensorflow2_in_30_days/tree/master\n\n🚀 URL to github repo (English): https://github.com/lyhue1991/eat_tensorflow2_in_30_days/tree/english\n\n\n\n### 1. TensorFlow2 🍎 or Pytorch🔥\n\nConclusion first: \n\n**For the engineers, priority goes to TensorFlow2.**\n\n**For the students and researchers，first choice should be Pytorch.**\n\n**The best way is to master both of them if having sufficient time.**\n\n\nReasons:\n\n* 1. **Model implementation is the most important in the industry. Only deployment supports for tensorflow models （not Pytorch） is the present situation in the majority of the internet enterprises (in China).** What's more, the industry prefers the models with higher availability; in most cases, they use well-validated modeling architectures with the minimized requirements of adjustment.\n\n\n* 2. **Fast iterative development and publication is the most important for the researchers since they need to test a lot of new models. Pytorch has advantages in accessing and debugging comparing with TensorFlow2.** Pytorch is most frequently used in academy since 2019 with a large amount of the cutting-edge results.\n\n\n* 3. Overall, TensorFlow2 and Pytorch are quite similar in programming nowadays, so mastering one helps learning the other. Mastering both framework provides you a lot more open-sourced models and helps you switching between them.\n\n```python\n\n```\n\n### 2. Keras🍏 and tf.keras 🍎\n\nConclusion first: \n\n**Keras will be discontinued in development after version 2.3.0, so use tf.keras.**\n\n\nKeras is a high-level API for the deep learning frameworks. It help the users to define and training DL networks with a more intuitive way.\n\nThe Keras libraries installed by pip implement this high-level API for the backends in tensorflow, theano, CNTK, etc.\n\ntf.keras is the high-level API just for Tensorflow, which is based on low-level APIs in Tensorflow.\n\nMost but not all of the functions in tf.keras are the same for those in Keras (which is compatible to many kinds of backend). tf.keras has a tighter combination to TensorFlow comparing to Keras.\n\nWith the acquisition by Google, Keras will not update after version 2.3.0 , thus the users should use tf.keras from now on, instead of using Keras installed by pip.\n\n```python\n\n```\n\n### 3. What Should You Know Before Reading This Book 📖?\n\n**It is suggested that the readers have foundamental knowledges of machine/deep learning and experience of modeling using Keras or TensorFlow 1.0.**\n\n**For those who have zero experience of machine/deep learning, it is strongly suggested to refer to [\"Deep Learning with Python\"](https://www.amazon.com/Deep-Learning-Python-Francois-Chollet/dp/1617294438/ref=sr_1_1?dchild=1&keywords=Deep+Learning+with+Python&qid=1586194568&sr=8-1) along with reading this book.**\n\n\n[\"Deep Learning with Python\"](https://www.amazon.com/Deep-Learning-Python-Francois-Chollet/dp/1617294438/ref=sr_1_1?dchild=1&keywords=Deep+Learning+with+Python&qid=1586194568&sr=8-1) is written by François Chollet, the inventor of Keras. This book is based on Keras and has no machine learning related prerequisites to the reader.\n\n\"Deep Learning with Python\" is easy to understand as it uses various examples to demonstrate. **No mathematical equation is in this book since it focuses on cultivating the intuitive to the deep learning.**\n\n\n```python\n\n```\n\n### 4. Writing Style 🍉 of This Book\n\n\n**This is a introduction reference book which is extremely friendly to human being. The lowest goal of the authors is to avoid giving up due to the difficulties, while \"Don't let the readers think\" is the highest target.**\n\nThis book is mainly based on the official documents of TensorFlow together with its functions.\n\nHowever, the authors made a thorough restructuring and a lot optimizations on the demonstrations.\n\nIt is different from the official documents, which is disordered and contains both tutorial and guidance with lack of systematic logic, that our book redesigns the content according to the difficulties, readers' searching habits, and the architecture of TensorFlow. We now make it progressive for TensorFlow studying with a clear path, and an easy access to the corresponding examples.\n\nIn contrast to the verbose demonstrating code, the authors of this book try to minimize the length of the examples to make it easy for reading and implementation. What's more, most of the code cells can be used in your project instantaneously.\n\n**Given the level of difficulty as 9 for learning Tensorflow through official documents, it would be reduced to 3 if learning through this book.**\n\nThis difference could be demonstrated as the following figure:\n\n![](./data/30天吃掉那个TF2.0.jpg)\n\n\n```python\n\n```\n\n### 5. How to Learn With This Book ⏰\n\n**(1) Study Plan**\n\nThe authors wrote this book using the spare time, especially the two-month unexpected \"holiday\" of COVID-19. Most readers should be able to completely master all the content within 30 days.\n\nTime required everyday would be between 30 minutes to 2 hours.\n\nThis book could also be used as library examples to consult when implementing machine learning projects with TensorFlow2.\n\n**Click the blue captions to enter the corresponding chapter.**\n\n\n|Date |Contents                                                       | Difficulties   | Est. Time | Update Status|\n|----:|:--------------------------------------------------------------|-----------:|----------:|-----:|\n|&nbsp;|[**Chapter 1: Modeling Procedure of TensorFlow**](./english/Chapter1.md)    |⭐️   |   0hour   |✅    |\n|Day 1 |  [1-1 Example: Modeling Procedure for Structured Data](./english/Chapter1-1.md)    | ⭐️⭐️⭐️ |   1hour    |✅    |\n|Day 2 |[1-2 Example: Modeling Procedure for Images](./english/Chapter1-2.md)    | ⭐️⭐️⭐️⭐️  |   2hours    |✅    |\n|Day 3 |  [1-3 Example: Modeling Procedure for Texts](./english/Chapter1-3.md)   | ⭐️⭐️⭐️⭐️⭐️  |   2hours    |✅    |\n|Day 4 |  [1-4 Example: Modeling Procedure for Temporal Sequences](./english/Chapter1-4.md)   | ⭐️⭐️⭐️⭐️⭐️  |   2hours    |✅    |\n|&nbsp;    |[**Chapter 2: Key Concepts of TensorFlow**](./english/Chapter2.md)  | ⭐️  |  0hour |✅  |\n|Day 5 |  [2-1 Data Structure of Tensor](./english/Chapter2-1.md)  | ⭐️⭐️⭐️⭐️   |   1hour    |✅    |\n|Day 6 |  [2-2 Three Types of Graph](./english/Chapter2-2.md)  | ⭐️⭐️⭐️⭐️⭐️   |   2hours    |✅    |\n|Day 7 |  [2-3 Automatic Differentiate](./english/Chapter2-3.md)  | ⭐️⭐️⭐️   |   1hour    |✅    |\n|&nbsp; |[**Chapter 3: Hierarchy of TensorFlow**](./english/Chapter3.md) |   ⭐️  |  0hour   |✅  |\n|Day 8 |  [3-1 Low-level API: Demonstration](./english/Chapter3-1.md)   | ⭐️⭐️⭐️⭐️ |   1hour    |✅   |\n|Day 9 |  [3-2 Mid-level API: Demonstration](./english/Chapter3-2.md)   | ⭐️⭐️⭐️   |   1hour    |✅  |\n|Day 10 |  [3-3 High-level API: Demonstration](./english/Chapter3-3.md)  | ⭐️⭐️⭐️   |   1hour    |✅  |\n|&nbsp; |[**Chapter 4: Low-level API in TensorFlow**](./english/Chapter4.md) |⭐️    | 0hour|✅  |\n|Day 11|  [4-1 Structural Operations of the Tensor](./english/Chapter4-1.md)  | ⭐️⭐️⭐️⭐️⭐️   |   2hours    |✅   |\n|Day 12|  [4-2 Mathematical Operations of the Tensor](./english/Chapter4-2.md)   | ⭐️⭐️⭐️⭐️   |   1hour    |✅  |\n|Day 13|  [4-3 Rules of Using the AutoGraph](./english/Chapter4-3.md)| ⭐️⭐️⭐️   |   0.5hour    | ✅  |\n|Day 14|  [4-4 Mechanisms of the AutoGraph](./english/Chapter4-4.md)    | ⭐️⭐️⭐️⭐️⭐️   |   2hours    |✅  |\n|Day 15|  [4-5 AutoGraph and tf.Module](./english/Chapter4-5.md)  | ⭐️⭐️⭐️⭐️   |   1hour    |✅  |\n|&nbsp; |[**Chapter 5: Mid-level API in TensorFlow**](./english/Chapter5.md) |  ⭐️  | 0hour|✅ |\n|Day 16|  [5-1 Dataset](./english/Chapter5-1.md)   | ⭐️⭐️⭐️⭐️⭐️   |   2hours    |✅  |\n|Day 17|  [5-2 feature_column](./english/Chapter5-2.md)   | ⭐️⭐️⭐️⭐️   |   1hour    |✅  |\n|Day 18|  [5-3 activation](./english/Chapter5-3.md)    | ⭐️⭐️⭐️   |   0.5hour    |✅   |\n|Day 19|  [5-4 layers](./english/Chapter5-4.md)  | ⭐️⭐️⭐️   |   1hour    |✅  |\n|Day 20|  [5-5 losses](./english/Chapter5-5.md)    | ⭐️⭐️⭐️   |   1hour    |✅  |\n|Day 21|  [5-6 metrics](./english/Chapter5-6.md)    | ⭐️⭐️⭐️   |   1hour    |✅   |\n|Day 22|  [5-7 optimizers](./english/Chapter5-7.md)    | ⭐️⭐️⭐️   |   0.5hour    |✅   |\n|Day 23|  [5-8 callbacks](./english/Chapter5-8.md)   | ⭐️⭐️⭐️⭐️   |   1hour    |✅   |\n|&nbsp; |[**Chapter 6: High-level API in TensorFlow**](./english/Chapter6.md)|    ⭐️ | 0hour|✅  |\n|Day 24|  [6-1 Three Ways of Modeling](./english/Chapter6-1.md)   | ⭐️⭐️⭐️   |   1hour    |✅ |\n|Day 25|  [6-2 Three Ways of Training](./english/Chapter6-2.md)  | ⭐️⭐️⭐️⭐️   |   1hour    |✅   |\n|Day 26|  [6-3 Model Training Using Single GPU](./english/Chapter6-3.md)    | ⭐️⭐️   |   0.5hour    |✅   |\n|Day 27|  [6-4 Model Training Using Multiple GPUs](./english/Chapter6-4.md)    | ⭐️⭐️   |   0.5hour    |✅  |\n|Day 28|  [6-5 Model Training Using TPU](./english/Chapter6-5.md)   | ⭐️⭐️   |   0.5hour    |✅  |\n|Day 29| [6-6 Model Deploying Using tensorflow-serving](./english/Chapter6-6.md) | ⭐️⭐️⭐️⭐️| 1hour |✅   |\n|Day 30| [6-7 Call Tensorflow Model Using spark-scala](./english/Chapter6-7.md) | ⭐️⭐️⭐️⭐️⭐️|2hours|✅  |\n|&nbsp;| [Epilogue: A Story Between a Foodie and Cuisine](./english/Epilogue.md) | ⭐️|0hour|✅  |\n\n```python\n\n```\n\n**(2) Software environment for studying**\n\n\nAll the source codes are tested in jupyter. It is suggested to clone the repository to local machine and run them in jupyter for an interactive learning experience.\n\nThe authors would suggest to install jupytext that converts markdown files into ipynb, so the readers would be able to open markdown files in jupyter directly.\n\n```python\n#For the readers in mainland China, using gitee will allow cloning with a faster speed\n#!git clone https://gitee.com/Python_Ai_Road/eat_tensorflow2_in_30_days\n\n#It is suggested to install jupytext that converts and run markdown files as ipynb.\n#!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -U jupytext\n    \n#It is also suggested to install the latest version of TensorFlow to test the demonstrating code in this book\n#!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple  -U tensorflow\n```\n\n```python\nimport tensorflow as tf\n\n#Note: all the codes are tested under TensorFlow 2.1\ntf.print(\"tensorflow version:\",tf.__version__)\n\na = tf.constant(\"hello\")\nb = tf.constant(\"tensorflow2\")\nc = tf.strings.join([a,b],\" \")\ntf.print(c)\n```\n\n```\ntensorflow version: 2.1.0\nhello tensorflow2\n```\n\n```python\n\n```\n\n### 6. Contact and support the author 🎈🎈\n\n\n**If you find this book helpful and want to support the author, please give a star ⭐️ to this repository and don't forget to share it to your friends 😊** \n\nPlease leave comments in the WeChat official account \"Python与算法之美\" (Elegance of Python and Algorithms) if you want to communicate with the author about the content. The author will try best to reply given the limited time available.\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n```python\n\n```\n"
        },
        {
          "name": "SUMMARY_eng.md",
          "type": "blob",
          "size": 2.2392578125,
          "content": "# Summary\n\n* [Introduction](README.md)\n* [Chapter 1: Modeling Procedure of TensorFlow](./english/Chapter1.md)\n* [1-1 Example: Modeling Procedure for Structured Data](./english/Chapter1-1.md)\n* [1-2 Example: Modeling Procedure for Images](./english/Chapter1-2.md)\n* [1-3 Example: Modeling Procedure for Texts](./english/Chapter1-3.md)\n* [1-4 Example: Modeling Procedure for Temporal Sequences](./english/Chapter1-4.md)\n\n* [Chapter 2: Key Concepts of TensorFlow](./english/Chapter2.md)\n* [2-1 Data Structure of Tensor](./english/Chapter2-1.md)\n* [2-2 Three Types of Graph](./english/Chapter2-2.md)\n* [2-3 Automatic Differentiate](./english/Chapter2-3.md)\n\n* [Chapter 3: Hierarchy of TensorFlow](./english/Chapter3.md)\n* [3-1 Low-level API: Demonstration](./english/Chapter3-1.md)\n* [3-2 Mid-level API: Demonstration](./english/Chapter3-2.md)\n* [3-3 High-level API: Demonstration](./english/Chapter3-3.md)\n\n* [Chapter 4: Low-level API in TensorFlow](./english/Chapter4.md)\n* [4-1 Structural Operations of the Tensor](./english/Chapter4-1.md)\n* [4-2 Mathematical Operations of the Tensor](./english/Chapter4-2.md)\n* [4-3 Rules of Using the AutoGraph](./english/Chapter4-3.md)\n* [4-4 Mechanisms of the AutoGraph](./english/Chapter4-4.md)\n* [4-5 AutoGraph and tf.Module](./english/Chapter4-5.md)\n\n* [Chapter 5: Mid-level API in TensorFlow](./english/Chapter5.md)\n* [5-1 Dataset](./english/Chapter5-1.md)\n* [5-2 feature_column](./english/Chapter5-2.md)\n* [5-3 activation](./english/Chapter5-3.md)\n* [5-4 layers](./english/Chapter5-4.md)\n* [5-5 losses](./english/Chapter5-5.md)\n* [5-6 metrics](./english/Chapter5-6.md)\n* [5-7 optimizers](./english/Chapter5-7.md)\n* [5-8 callbacks](./english/Chapter5-8.md)\n\n* [Chapter 6: High-level API in TensorFlow](./english/Chapter6.md)\n* [6-1 Three Ways of Modeling](./english/Chapter6-1.md)\n* [6-2 Three Ways of Training](./english/Chapter6-2.md)\n* [6-3 Model Training Using Single GPU](./english/Chapter6-3.md)\n* [6-4 Model Training Using Multiple GPUs](./english/Chapter6-4.md)\n* [6-5 Model Training Using TPU](./english/Chapter6-5.md)\n* [6-6 Model Deploying Using tensorflow-serving](./english/Chapter6-6.md)\n* [6-7 Call Tensorflow Model Using spark-scala](./english/Chapter6-7.md)\n* [Epilogue：A Story Between a Foodie and Cuisine](./english/Epilogue.md)\n\n\n"
        },
        {
          "name": "data",
          "type": "tree",
          "content": null
        },
        {
          "name": "eat_tf2_ebook.md",
          "type": "blob",
          "size": 294.9453125,
          "content": "# 《30天吃掉那只 TensorFlow2.0 》开篇辞 🔥🔥\n\n\n📚 gitbook电子书地址： https://lyhue1991.github.io/eat_tensorflow2_in_30_days\n\n🚀 github项目地址：https://github.com/lyhue1991/eat_tensorflow2_in_30_d\n\n\n### 一，TensorFlow2 🍎 还是 Pytorch🔥\n\n先说结论:\n\n**如果是工程师，应该优先选TensorFlow2.**\n\n**如果是学生或者研究人员，应该优先选择Pytorch.**\n\n**如果时间足够，最好TensorFlow2和Pytorch都要学习掌握。**\n\n\n理由如下：\n\n* 1，**在工业界最重要的是模型落地，目前国内的大部分互联网企业只支持TensorFlow模型的在线部署，不支持Pytorch。** 并且工业界更加注重的是模型的高可用性，许多时候使用的都是成熟的模型架构，调试需求并不大。\n\n\n* 2，**研究人员最重要的是快速迭代发表文章，需要尝试一些较新的模型架构。而Pytorch在易用性上相比TensorFlow2有一些优势，更加方便调试。** 并且在2019年以来在学术界占领了大半壁江山，能够找到的相应最新研究成果更多。\n\n\n* 3，TensorFlow2和Pytorch实际上整体风格已经非常相似了，学会了其中一个，学习另外一个将比较容易。两种框架都掌握的话，能够参考的开源模型案例更多，并且可以方便地在两种框架之间切换。\n\n```python\n\n```\n\n### 二，Keras🍏 和 tf.keras 🍎\n\n先说结论：\n\n**Keras库在2.3.0版本后将不再更新，用户应该使用tf.keras。**\n\n\nKeras可以看成是一种深度学习框架的高阶接口规范，它帮助用户以更简洁的形式定义和训练深度学习网络。\n\n使用pip安装的Keras库同时在tensorflow,theano,CNTK等后端基础上进行了这种高阶接口规范的实现。\n\n而tf.keras是在TensorFlow中以TensorFlow低阶API为基础实现的这种高阶接口，它是Tensorflow的一个子模块。\n\ntf.keras绝大部分功能和兼容多种后端的Keras库用法完全一样，但并非全部，它和TensorFlow之间的结合更为紧密。\n\n随着谷歌对Keras的收购，Keras库2.3.0版本后也将不再进行更新，用户应当使用tf.keras而不是使用pip安装的Keras.\n\n### 三，本书📖面向读者 👼\n\n\n**本书假定读者有一定的机器学习和深度学习基础，使用过Keras或者Tensorflow1.0或者Pytorch搭建训练过模型。**\n\n**对于没有任何机器学习和深度学习基础的同学，建议在学习本书时同步参考学习《Python深度学习》一书。**\n\n《Python深度学习》这本书是Keras之父Francois Chollet所著，该书假定读者无任何机器学习知识，以Keras为工具，\n\n使用丰富的范例示范深度学习的最佳实践，该书通俗易懂，**全书没有一个数学公式，注重培养读者的深度学习直觉。**。\n\n该书电子版下载链接：https://pan.baidu.com/s/1-4q6VjLTb3ZxcefyNCbjSA 提取码：wtzo \n\n\n\n### 四，本书写作风格 🍉\n\n\n**本书是一本对人类用户极其友善的TensorFlow2.0入门工具书，不刻意恶心读者是本书的底限要求，Don't let me think是本书的最高追求。**\n\n本书主要是在参考TensorFlow官方文档和函数doc文档基础上整理写成的。\n\n但本书在篇章结构和范例选取上做了大量的优化。\n\n不同于官方文档混乱的篇章结构，既有教程又有指南，缺少整体的编排逻辑。\n\n本书按照内容难易程度、读者检索习惯和TensorFlow自身的层次结构设计内容，循序渐进，层次清晰，方便按照功能查找相应范例。\n\n不同于官方文档冗长的范例代码，本书在范例设计上尽可能简约化和结构化，增强范例易读性和通用性，大部分代码片段在实践中可即取即用。\n\n**如果说通过学习TensorFlow官方文档掌握TensorFlow2.0的难度大概是9的话，那么通过学习本书掌握TensorFlow2.0的难度应该大概是3.**\n\n谨以下图对比一下TensorFlow官方教程与本教程的差异。\n\n![](./data/30天吃掉那个TF2.0.jpg)\n\n\n\n### 五，本书学习方案 ⏰\n\n**1，学习计划**\n\n本书是作者利用工作之余和疫情放假期间大概2个月写成的，大部分读者应该在30天可以完全学会。\n\n预计每天花费的学习时间在30分钟到2个小时之间。\n\n当然，本书也非常适合作为TensorFlow的工具手册在工程落地时作为范例库参考。\n\n**点击学习内容蓝色标题即可进入该章节。**\n\n\n|日期 | 学习内容                                                       | 内容难度   | 预计学习时间 | 更新状态|\n|----:|:--------------------------------------------------------------|-----------:|----------:|-----:|\n|&nbsp;|[**一、TensorFlow的建模流程**](./一、TensorFlow的建模流程.md)    |⭐️   |   0hour   |✅    |\n|day1 |  [1-1,结构化数据建模流程范例](./1-1,结构化数据建模流程范例.md)    | ⭐️⭐️⭐️ |   1hour    |✅    |\n|day2 |[1-2,图片数据建模流程范例](./1-2,图片数据建模流程范例.md)    | ⭐️⭐️⭐️⭐️  |   2hour    |✅    |\n|day3 |  [1-3,文本数据建模流程范例](./1-3,文本数据建模流程范例.md)   | ⭐️⭐️⭐️⭐️⭐️  |   2hour    |✅    |\n|day4 |  [1-4,时间序列数据建模流程范例](./1-4,时间序列数据建模流程范例.md)   | ⭐️⭐️⭐️⭐️⭐️  |   2hour    |✅    |\n|&nbsp;    |[**二、TensorFlow的核心概念**](./二、TensorFlow的核心概念.md)  | ⭐️  |  0hour |✅  |\n|day5 |  [2-1,张量数据结构](./2-1,张量数据结构.md)  | ⭐️⭐️⭐️⭐️   |   1hour    |✅    |\n|day6 |  [2-2,三种计算图](./2-2,三种计算图.md)  | ⭐️⭐️⭐️⭐️⭐️   |   2hour    |✅    |\n|day7 |  [2-3,自动微分机制](./2-3,自动微分机制.md)  | ⭐️⭐️⭐️   |   1hour    |✅    |\n|&nbsp; |[**三、TensorFlow的层次结构**](./三、TensorFlow的层次结构.md) |   ⭐️  |  0hour   |✅  |\n|day8 |  [3-1,低阶API示范](./3-1,低阶API示范.md)   | ⭐️⭐️   |   0.5hour    |✅   |\n|day9 |  [3-2,中阶API示范](./3-2,中阶API示范.md)   | ⭐️⭐️⭐️   |   0.5hour    |✅  |\n|day10 |  [3-3,高阶API示范](./3-3,高阶API示范.md)  | ⭐️⭐️⭐️   |   0.5hour    |✅  |\n|&nbsp; |[**四、TensorFlow的低阶API**](./四、TensorFlow的低阶API.md) |⭐️    | 0hour|✅  |\n|day11|  [4-1,张量的结构操作](./4-1,张量的结构操作.md)  | ⭐️⭐️⭐️⭐️⭐️   |   2hour    |✅   |\n|day12|  [4-2,张量的数学运算](./4-2,张量的数学运算.md)   | ⭐️⭐️⭐️⭐️   |   1hour    |✅  |\n|day13|  [4-3,AutoGraph的使用规范](./4-3,AutoGraph的使用规范.md)| ⭐️⭐️⭐️   |   0.5hour    |✅  |\n|day14|  [4-4,AutoGraph的机制原理](./4-4,AutoGraph的机制原理.md)    | ⭐️⭐️⭐️⭐️⭐️   |   2hour    |✅  |\n|day15|  [4-5,AutoGraph和tf.Module](./4-5,AutoGraph和tf.Module.md)  | ⭐️⭐️⭐️⭐️   |   1hour    |✅  |\n|&nbsp; |[**五、TensorFlow的中阶API**](./五、TensorFlow的中阶API.md) |  ⭐️  | 0hour|✅ |\n|day16|  [5-1,数据管道Dataset](./5-1,数据管道Dataset.md)   | ⭐️⭐️⭐️⭐️⭐️   |   2hour    |✅  |\n|day17|  [5-2,特征列feature_column](./5-2,特征列feature_column.md)   | ⭐️⭐️⭐️⭐️   |   1hour    |✅  |\n|day18|  [5-3,激活函数activation](./5-3,激活函数activation.md)    | ⭐️⭐️⭐️   |   0.5hour    |✅   |\n|day19|  [5-4,模型层layers](./5-4,模型层layers.md)  | ⭐️⭐️⭐️   |   1hour    |✅  |\n|day20|  [5-5,损失函数losses](./5-5,损失函数losses.md)    | ⭐️⭐️⭐️   |   1hour    |✅  |\n|day21|  [5-6,评估指标metrics](./5-6,评估指标metrics.md)    | ⭐️⭐️⭐️   |   1hour    |✅   |\n|day22|  [5-7,优化器optimizers](./5-7,优化器optimizers.md)    | ⭐️⭐️⭐️   |   0.5hour    |✅   |\n|day23|  [5-8,回调函数callbacks](./5-8,回调函数callbacks.md)   | ⭐️⭐️⭐️⭐️   |   1hour    |✅   |\n|&nbsp; |[**六、TensorFlow的高阶API**](./六、TensorFlow的高阶API.md)|    ⭐️ | 0hour|✅  |\n|day24|  [6-1,构建模型的3种方法](./6-1,构建模型的3种方法.md)   | ⭐️⭐️⭐️   |   1hour    |✅ |\n|day25|  [6-2,训练模型的3种方法](./6-2,训练模型的3种方法.md)  | ⭐️⭐️⭐️⭐️   |   1hour    |✅   |\n|day26|  [6-3,使用单GPU训练模型](./6-3,使用单GPU训练模型.md)    | ⭐️⭐️   |   0.5hour    |✅   |\n|day27|  [6-4,使用多GPU训练模型](./6-4,使用多GPU训练模型.md)    | ⭐️⭐️   |   0.5hour    |✅  |\n|day28|  [6-5,使用TPU训练模型](./6-5,使用TPU训练模型.md)   | ⭐️⭐️   |   0.5hour    |✅  |\n|day29| [6-6,使用tensorflow-serving部署模型](./6-6,使用tensorflow-serving部署模型.md) | ⭐️⭐️⭐️⭐️| 1hour |✅   |\n|day30| [6-7,使用spark-scala调用tensorflow模型](./6-7,使用spark-scala调用tensorflow模型.md) | ⭐️⭐️⭐️⭐️⭐️|2hour|✅  |\n\n\n```python\n\n```\n\n**2，学习环境**\n\n\n本书全部源码在jupyter中编写测试通过，建议通过git克隆到本地，并在jupyter中交互式运行学习。\n\n为了直接能够在jupyter中打开markdown文件，建议安装jupytext，将markdown转换成ipnb。\n\n此外，也可以关注公众号”**Python与算法之美**“ ，后台回复关键字：**tf**，获取本书ipynb源码的下载链接。\n\n```python\n#克隆本书源码到本地\n#!git clone https://github.com/lyhue1991/eat_tensorflow2_in_30_days\n\n#建议在jupyter notebook 上安装jupytext，以便能够将本书各章节markdown文件视作ipynb文件运行\n#!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -U jupytext\n    \n#建议在jupyter notebook 上安装最新版本tensorflow 测试本书中的代码\n#!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple  -U tensorflow\n```\n\n```python\nimport tensorflow as tf\n\n#注：本书全部代码在tensorflow 2.1版本测试通过\ntf.print(\"tensorflow version:\",tf.__version__)\n\na = tf.constant(\"hello\")\nb = tf.constant(\"tensorflow2\")\nc = tf.strings.join([a,b],\" \")\ntf.print(c)\n```\n\n```\ntensorflow version: 2.1.0\nhello tensorflow2\n```\n\n\n### 六，鼓励和联系作者 🎈🎈\n\n**如果本书对你有所帮助，想鼓励一下作者，记得给本项目加一颗星星star⭐️，并分享给你的朋友们喔😊!** \n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"**Python与算法之美**\"下留言。作者时间和精力有限，会酌情予以回复。\n\n如果有想要获取本书的jupyter notebook源代码的小伙伴，也可以关注公众号，在后台回复关键字：**tf**，获取本书全部代码和数据集下载链接。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n```python\n\n```\n# 一、TensorFlow的建模流程\n\n\n尽管TensorFlow设计上足够灵活，可以用于进行各种复杂的数值计算。\n\n但通常人们使用TensorFlow来实现机器学习模型，尤其常用于实现神经网络模型。\n\n从原理上说可以使用张量构建计算图来定义神经网络，并通过自动微分机制训练模型。\n\n但为简洁起见，一般推荐使用TensorFlow的高层次keras接口来实现神经网络网模型。\n\n\n使用TensorFlow实现神经网络模型的一般流程包括：\n\n1，准备数据\n\n2，定义模型\n\n3，训练模型\n\n4，评估模型\n\n5，使用模型\n\n6，保存模型。\n\n\n**对新手来说，其中最困难的部分实际上是准备数据过程。** \n\n我们在实践中通常会遇到的数据类型包括结构化数据，图片数据，文本数据，时间序列数据。\n\n我们将分别以titanic生存预测问题，cifar2图片分类问题，imdb电影评论分类问题，国内新冠疫情结束时间预测问题为例，演示应用tensorflow对这四类数据的建模方法。\n\n\n\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![](./data/Python与算法之美logo.jpg)\n# 1-1,结构化数据建模流程范例\n\n\n### 一，准备数据\n\n\ntitanic数据集的目标是根据乘客信息预测他们在Titanic号撞击冰山沉没后能否生存。\n\n结构化数据一般会使用Pandas中的DataFrame进行预处理。\n\n\n```python\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport tensorflow as tf \nfrom tensorflow.keras import models,layers\n\ndftrain_raw = pd.read_csv('./data/titanic/train.csv')\ndftest_raw = pd.read_csv('./data/titanic/test.csv')\ndftrain_raw.head(10)\n```\n\n![](./data/1-1-数据集展示.jpg)\n\n\n字段说明：\n\n* Survived:0代表死亡，1代表存活【y标签】\n* Pclass:乘客所持票类，有三种值(1,2,3) 【转换成onehot编码】\n* Name:乘客姓名 【舍去】\n* Sex:乘客性别 【转换成bool特征】\n* Age:乘客年龄(有缺失) 【数值特征，添加“年龄是否缺失”作为辅助特征】\n* SibSp:乘客兄弟姐妹/配偶的个数(整数值) 【数值特征】\n* Parch:乘客父母/孩子的个数(整数值)【数值特征】\n* Ticket:票号(字符串)【舍去】\n* Fare:乘客所持票的价格(浮点数，0-500不等) 【数值特征】\n* Cabin:乘客所在船舱(有缺失) 【添加“所在船舱是否缺失”作为辅助特征】\n* Embarked:乘客登船港口:S、C、Q(有缺失)【转换成onehot编码，四维度 S,C,Q,nan】\n\n\n\n利用Pandas的数据可视化功能我们可以简单地进行探索性数据分析EDA（Exploratory Data Analysis）。\n\nlabel分布情况\n\n```python\n%matplotlib inline\n%config InlineBackend.figure_format = 'png'\nax = dftrain_raw['Survived'].value_counts().plot(kind = 'bar',\n     figsize = (12,8),fontsize=15,rot = 0)\nax.set_ylabel('Counts',fontsize = 15)\nax.set_xlabel('Survived',fontsize = 15)\nplt.show()\n```\n\n![](./data/1-1-Label分布.jpg)\n\n\n年龄分布情况\n\n```python\n%matplotlib inline\n%config InlineBackend.figure_format = 'png'\nax = dftrain_raw['Age'].plot(kind = 'hist',bins = 20,color= 'purple',\n                    figsize = (12,8),fontsize=15)\n\nax.set_ylabel('Frequency',fontsize = 15)\nax.set_xlabel('Age',fontsize = 15)\nplt.show()\n```\n\n![](./data/1-1-年龄分布.jpg)\n\n\n年龄和label的相关性\n\n```python\n%matplotlib inline\n%config InlineBackend.figure_format = 'png'\nax = dftrain_raw.query('Survived == 0')['Age'].plot(kind = 'density',\n                      figsize = (12,8),fontsize=15)\ndftrain_raw.query('Survived == 1')['Age'].plot(kind = 'density',\n                      figsize = (12,8),fontsize=15)\nax.legend(['Survived==0','Survived==1'],fontsize = 12)\nax.set_ylabel('Density',fontsize = 15)\nax.set_xlabel('Age',fontsize = 15)\nplt.show()\n```\n\n![](./data/1-1-年龄相关性.jpg)\n\n\n下面为正式的数据预处理\n\n```python\ndef preprocessing(dfdata):\n\n    dfresult= pd.DataFrame()\n\n    #Pclass\n    dfPclass = pd.get_dummies(dfdata['Pclass'])\n    dfPclass.columns = ['Pclass_' +str(x) for x in dfPclass.columns ]\n    dfresult = pd.concat([dfresult,dfPclass],axis = 1)\n\n    #Sex\n    dfSex = pd.get_dummies(dfdata['Sex'])\n    dfresult = pd.concat([dfresult,dfSex],axis = 1)\n\n    #Age\n    dfresult['Age'] = dfdata['Age'].fillna(0)\n    dfresult['Age_null'] = pd.isna(dfdata['Age']).astype('int32')\n\n    #SibSp,Parch,Fare\n    dfresult['SibSp'] = dfdata['SibSp']\n    dfresult['Parch'] = dfdata['Parch']\n    dfresult['Fare'] = dfdata['Fare']\n\n    #Carbin\n    dfresult['Cabin_null'] =  pd.isna(dfdata['Cabin']).astype('int32')\n\n    #Embarked\n    dfEmbarked = pd.get_dummies(dfdata['Embarked'],dummy_na=True)\n    dfEmbarked.columns = ['Embarked_' + str(x) for x in dfEmbarked.columns]\n    dfresult = pd.concat([dfresult,dfEmbarked],axis = 1)\n\n    return(dfresult)\n\nx_train = preprocessing(dftrain_raw)\ny_train = dftrain_raw['Survived'].values\n\nx_test = preprocessing(dftest_raw)\ny_test = dftest_raw['Survived'].values\n\nprint(\"x_train.shape =\", x_train.shape )\nprint(\"x_test.shape =\", x_test.shape )\n\n```\n\n```\nx_train.shape = (712, 15)\nx_test.shape = (179, 15)\n```\n\n```python\n\n```\n\n### 二，定义模型\n\n\n使用Keras接口有以下3种方式构建模型：使用Sequential按层顺序构建模型，使用函数式API构建任意结构模型，继承Model基类构建自定义模型。\n\n此处选择使用最简单的Sequential，按层顺序模型。\n\n```python\ntf.keras.backend.clear_session()\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(20,activation = 'relu',input_shape=(15,)))\nmodel.add(layers.Dense(10,activation = 'relu' ))\nmodel.add(layers.Dense(1,activation = 'sigmoid' ))\n\nmodel.summary()\n```\n\n```\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 20)                320       \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                210       \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 11        \n=================================================================\nTotal params: 541\nTrainable params: 541\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n\n### 三，训练模型\n\n\n训练模型通常有3种方法，内置fit方法，内置train_on_batch方法，以及自定义训练循环。此处我们选择最常用也最简单的内置fit方法。\n\n```python\n# 二分类问题选择二元交叉熵损失函数\nmodel.compile(optimizer='adam',\n            loss='binary_crossentropy',\n            metrics=['AUC'])\n\nhistory = model.fit(x_train,y_train,\n                    batch_size= 64,\n                    epochs= 30,\n                    validation_split=0.2 #分割一部分训练数据用于验证\n                   )\n```\n\n```\nTrain on 569 samples, validate on 143 samples\nEpoch 1/30\n569/569 [==============================] - 1s 2ms/sample - loss: 3.5841 - AUC: 0.4079 - val_loss: 3.4429 - val_AUC: 0.4129\nEpoch 2/30\n569/569 [==============================] - 0s 102us/sample - loss: 2.6093 - AUC: 0.3967 - val_loss: 2.4886 - val_AUC: 0.4139\nEpoch 3/30\n569/569 [==============================] - 0s 68us/sample - loss: 1.8375 - AUC: 0.4003 - val_loss: 1.7383 - val_AUC: 0.4223\nEpoch 4/30\n569/569 [==============================] - 0s 83us/sample - loss: 1.2545 - AUC: 0.4390 - val_loss: 1.1936 - val_AUC: 0.4765\nEpoch 5/30\n569/569 [==============================] - ETA: 0s - loss: 1.4435 - AUC: 0.375 - 0s 90us/sample - loss: 0.9141 - AUC: 0.5192 - val_loss: 0.8274 - val_AUC: 0.5584\nEpoch 6/30\n569/569 [==============================] - 0s 110us/sample - loss: 0.7052 - AUC: 0.6290 - val_loss: 0.6596 - val_AUC: 0.6880\nEpoch 7/30\n569/569 [==============================] - 0s 90us/sample - loss: 0.6410 - AUC: 0.7086 - val_loss: 0.6519 - val_AUC: 0.6845\nEpoch 8/30\n569/569 [==============================] - 0s 93us/sample - loss: 0.6246 - AUC: 0.7080 - val_loss: 0.6480 - val_AUC: 0.6846\nEpoch 9/30\n569/569 [==============================] - 0s 73us/sample - loss: 0.6088 - AUC: 0.7113 - val_loss: 0.6497 - val_AUC: 0.6838\nEpoch 10/30\n569/569 [==============================] - 0s 79us/sample - loss: 0.6051 - AUC: 0.7117 - val_loss: 0.6454 - val_AUC: 0.6873\nEpoch 11/30\n569/569 [==============================] - 0s 96us/sample - loss: 0.5972 - AUC: 0.7218 - val_loss: 0.6369 - val_AUC: 0.6888\nEpoch 12/30\n569/569 [==============================] - 0s 92us/sample - loss: 0.5918 - AUC: 0.7294 - val_loss: 0.6330 - val_AUC: 0.6908\nEpoch 13/30\n569/569 [==============================] - 0s 75us/sample - loss: 0.5864 - AUC: 0.7363 - val_loss: 0.6281 - val_AUC: 0.6948\nEpoch 14/30\n569/569 [==============================] - 0s 104us/sample - loss: 0.5832 - AUC: 0.7426 - val_loss: 0.6240 - val_AUC: 0.7030\nEpoch 15/30\n569/569 [==============================] - 0s 74us/sample - loss: 0.5777 - AUC: 0.7507 - val_loss: 0.6200 - val_AUC: 0.7066\nEpoch 16/30\n569/569 [==============================] - 0s 79us/sample - loss: 0.5726 - AUC: 0.7569 - val_loss: 0.6155 - val_AUC: 0.7132\nEpoch 17/30\n569/569 [==============================] - 0s 99us/sample - loss: 0.5674 - AUC: 0.7643 - val_loss: 0.6070 - val_AUC: 0.7255\nEpoch 18/30\n569/569 [==============================] - 0s 97us/sample - loss: 0.5631 - AUC: 0.7721 - val_loss: 0.6061 - val_AUC: 0.7305\nEpoch 19/30\n569/569 [==============================] - 0s 73us/sample - loss: 0.5580 - AUC: 0.7792 - val_loss: 0.6027 - val_AUC: 0.7332\nEpoch 20/30\n569/569 [==============================] - 0s 85us/sample - loss: 0.5533 - AUC: 0.7861 - val_loss: 0.5997 - val_AUC: 0.7366\nEpoch 21/30\n569/569 [==============================] - 0s 87us/sample - loss: 0.5497 - AUC: 0.7926 - val_loss: 0.5961 - val_AUC: 0.7433\nEpoch 22/30\n569/569 [==============================] - 0s 101us/sample - loss: 0.5454 - AUC: 0.7987 - val_loss: 0.5943 - val_AUC: 0.7438\nEpoch 23/30\n569/569 [==============================] - 0s 100us/sample - loss: 0.5398 - AUC: 0.8057 - val_loss: 0.5926 - val_AUC: 0.7492\nEpoch 24/30\n569/569 [==============================] - 0s 79us/sample - loss: 0.5328 - AUC: 0.8122 - val_loss: 0.5912 - val_AUC: 0.7493\nEpoch 25/30\n569/569 [==============================] - 0s 86us/sample - loss: 0.5283 - AUC: 0.8147 - val_loss: 0.5902 - val_AUC: 0.7509\nEpoch 26/30\n569/569 [==============================] - 0s 67us/sample - loss: 0.5246 - AUC: 0.8196 - val_loss: 0.5845 - val_AUC: 0.7552\nEpoch 27/30\n569/569 [==============================] - 0s 72us/sample - loss: 0.5205 - AUC: 0.8271 - val_loss: 0.5837 - val_AUC: 0.7584\nEpoch 28/30\n569/569 [==============================] - 0s 74us/sample - loss: 0.5144 - AUC: 0.8302 - val_loss: 0.5848 - val_AUC: 0.7561\nEpoch 29/30\n569/569 [==============================] - 0s 77us/sample - loss: 0.5099 - AUC: 0.8326 - val_loss: 0.5809 - val_AUC: 0.7583\nEpoch 30/30\n569/569 [==============================] - 0s 80us/sample - loss: 0.5071 - AUC: 0.8349 - val_loss: 0.5816 - val_AUC: 0.7605\n\n```\n\n\n### 四，评估模型\n\n\n我们首先评估一下模型在训练集和验证集上的效果。\n\n```python\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\n\nimport matplotlib.pyplot as plt\n\ndef plot_metric(history, metric):\n    train_metrics = history.history[metric]\n    val_metrics = history.history['val_'+metric]\n    epochs = range(1, len(train_metrics) + 1)\n    plt.plot(epochs, train_metrics, 'bo--')\n    plt.plot(epochs, val_metrics, 'ro-')\n    plt.title('Training and validation '+ metric)\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(metric)\n    plt.legend([\"train_\"+metric, 'val_'+metric])\n    plt.show()\n```\n\n```python\nplot_metric(history,\"loss\")\n```\n\n![](./data/1-1-Loss曲线.jpg)\n\n```python\nplot_metric(history,\"AUC\")\n```\n\n![](./data/1-1-AUC曲线.jpg)\n\n\n我们再看一下模型在测试集上的效果.\n\n```python\nmodel.evaluate(x = x_test,y = y_test)\n```\n\n```\n[0.5191367897907448, 0.8122605]\n```\n\n```python\n\n```\n\n### 五，使用模型\n\n```python\n#预测概率\nmodel.predict(x_test[0:10])\n#model(tf.constant(x_test[0:10].values,dtype = tf.float32)) #等价写法\n```\n\n```\narray([[0.26501188],\n       [0.40970832],\n       [0.44285864],\n       [0.78408605],\n       [0.47650957],\n       [0.43849158],\n       [0.27426785],\n       [0.5962582 ],\n       [0.59476686],\n       [0.17882936]], dtype=float32)\n```\n\n```python\n#预测类别\nmodel.predict_classes(x_test[0:10])\n```\n\n```\narray([[0],\n       [0],\n       [0],\n       [1],\n       [0],\n       [0],\n       [0],\n       [1],\n       [1],\n       [0]], dtype=int32)\n```\n\n```python\n\n```\n\n### 六，保存模型\n\n\n可以使用Keras方式保存模型，也可以使用TensorFlow原生方式保存。前者仅仅适合使用Python环境恢复模型，后者则可以跨平台进行模型部署。\n\n推荐使用后一种方式进行保存。\n\n\n**1，Keras方式保存**\n\n```python\n# 保存模型结构及权重\n\nmodel.save('./data/keras_model.h5')  \n\ndel model  #删除现有模型\n\n# identical to the previous one\nmodel = models.load_model('./data/keras_model.h5')\nmodel.evaluate(x_test,y_test)\n```\n\n```\n[0.5191367897907448, 0.8122605]\n```\n\n```python\n# 保存模型结构\njson_str = model.to_json()\n\n# 恢复模型结构\nmodel_json = models.model_from_json(json_str)\n```\n\n```python\n#保存模型权重\nmodel.save_weights('./data/keras_model_weight.h5')\n\n# 恢复模型结构\nmodel_json = models.model_from_json(json_str)\nmodel_json.compile(\n        optimizer='adam',\n        loss='binary_crossentropy',\n        metrics=['AUC']\n    )\n\n# 加载权重\nmodel_json.load_weights('./data/keras_model_weight.h5')\nmodel_json.evaluate(x_test,y_test)\n```\n\n```\n[0.5191367897907448, 0.8122605]\n```\n\n\n**2，TensorFlow原生方式保存**\n\n```python\n# 保存权重，该方式仅仅保存权重张量\nmodel.save_weights('./data/tf_model_weights.ckpt',save_format = \"tf\")\n```\n\n```python\n# 保存模型结构与模型参数到文件,该方式保存的模型具有跨平台性便于部署\n\nmodel.save('./data/tf_model_savedmodel', save_format=\"tf\")\nprint('export saved model.')\n\nmodel_loaded = tf.keras.models.load_model('./data/tf_model_savedmodel')\nmodel_loaded.evaluate(x_test,y_test)\n```\n\n```\n[0.5191365896656527, 0.8122605]\n```\n\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n```python\n\n```\n# 1-2,图片数据建模流程范例\n\n\n### 一，准备数据\n\n\ncifar2数据集为cifar10数据集的子集，只包括前两种类别airplane和automobile。\n\n训练集有airplane和automobile图片各5000张，测试集有airplane和automobile图片各1000张。\n\ncifar2任务的目标是训练一个模型来对飞机airplane和机动车automobile两种图片进行分类。\n\n我们准备的Cifar2数据集的文件结构如下所示。\n\n![](./data/cifar2.jpg)\n\n```python\n\n```\n\n在tensorflow中准备图片数据的常用方案有两种，第一种是使用tf.keras中的ImageDataGenerator工具构建图片数据生成器。\n\n第二种是使用tf.data.Dataset搭配tf.image中的一些图片处理方法构建数据管道。\n\n第一种方法更为简单，其使用范例可以参考以下文章。\n\nhttps://zhuanlan.zhihu.com/p/67466552\n\n第二种方法是TensorFlow的原生方法，更加灵活，使用得当的话也可以获得更好的性能。\n\n我们此处介绍第二种方法。\n\n\n```python\nimport tensorflow as tf \nfrom tensorflow.keras import datasets,layers,models\n\nBATCH_SIZE = 100\n\ndef load_image(img_path,size = (32,32)):\n    label = tf.constant(1,tf.int8) if tf.strings.regex_full_match(img_path,\".*/automobile/.*\") \\\n            else tf.constant(0,tf.int8)\n    img = tf.io.read_file(img_path)\n    img = tf.image.decode_jpeg(img) #注意此处为jpeg格式\n    img = tf.image.resize(img,size)/255.0\n    return(img,label)\n\n```\n\n```python\n#使用并行化预处理num_parallel_calls 和预存数据prefetch来提升性能\nds_train = tf.data.Dataset.list_files(\"./data/cifar2/train/*/*.jpg\") \\\n           .map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE) \\\n           .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n           .prefetch(tf.data.experimental.AUTOTUNE)  \n\nds_test = tf.data.Dataset.list_files(\"./data/cifar2/test/*/*.jpg\") \\\n           .map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE) \\\n           .batch(BATCH_SIZE) \\\n           .prefetch(tf.data.experimental.AUTOTUNE)  \n\n```\n\n```python\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\n\n#查看部分样本\nfrom matplotlib import pyplot as plt \n\nplt.figure(figsize=(8,8)) \nfor i,(img,label) in enumerate(ds_train.unbatch().take(9)):\n    ax=plt.subplot(3,3,i+1)\n    ax.imshow(img.numpy())\n    ax.set_title(\"label = %d\"%label)\n    ax.set_xticks([])\n    ax.set_yticks([]) \nplt.show()\n\n```\n\n![](./data/1-2-图片预览.jpg)\n\n```python\nfor x,y in ds_train.take(1):\n    print(x.shape,y.shape)\n```\n\n```\n(100, 32, 32, 3) (100,)\n```\n\n```python\n\n```\n\n### 二，定义模型\n\n\n使用Keras接口有以下3种方式构建模型：使用Sequential按层顺序构建模型，使用函数式API构建任意结构模型，继承Model基类构建自定义模型。\n\n此处选择使用函数式API构建模型。\n\n```python\ntf.keras.backend.clear_session() #清空会话\n\ninputs = layers.Input(shape=(32,32,3))\nx = layers.Conv2D(32,kernel_size=(3,3))(inputs)\nx = layers.MaxPool2D()(x)\nx = layers.Conv2D(64,kernel_size=(5,5))(x)\nx = layers.MaxPool2D()(x)\nx = layers.Dropout(rate=0.1)(x)\nx = layers.Flatten()(x)\nx = layers.Dense(32,activation='relu')(x)\noutputs = layers.Dense(1,activation = 'sigmoid')(x)\n\nmodel = models.Model(inputs = inputs,outputs = outputs)\n\nmodel.summary()\n```\n\n```\nModel: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 30, 30, 32)        896       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 11, 11, 64)        51264     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n_________________________________________________________________\ndropout (Dropout)            (None, 5, 5, 64)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 1600)              0         \n_________________________________________________________________\ndense (Dense)                (None, 32)                51232     \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 33        \n=================================================================\nTotal params: 103,425\nTrainable params: 103,425\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n```python\n\n```\n\n### 三，训练模型\n\n\n训练模型通常有3种方法，内置fit方法，内置train_on_batch方法，以及自定义训练循环。此处我们选择最常用也最简单的内置fit方法。\n\n```python\nimport datetime\n\nlogdir = \"./data/keras_model/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n\nmodel.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n        loss=tf.keras.losses.binary_crossentropy,\n        metrics=[\"accuracy\"]\n    )\n\nhistory = model.fit(ds_train,epochs= 10,validation_data=ds_test,\n                    callbacks = [tensorboard_callback],workers = 4)\n\n```\n\n```\nTrain for 100 steps, validate for 20 steps\nEpoch 1/10\n100/100 [==============================] - 16s 156ms/step - loss: 0.4830 - accuracy: 0.7697 - val_loss: 0.3396 - val_accuracy: 0.8475\nEpoch 2/10\n100/100 [==============================] - 14s 142ms/step - loss: 0.3437 - accuracy: 0.8469 - val_loss: 0.2997 - val_accuracy: 0.8680\nEpoch 3/10\n100/100 [==============================] - 13s 131ms/step - loss: 0.2871 - accuracy: 0.8777 - val_loss: 0.2390 - val_accuracy: 0.9015\nEpoch 4/10\n100/100 [==============================] - 12s 117ms/step - loss: 0.2410 - accuracy: 0.9040 - val_loss: 0.2005 - val_accuracy: 0.9195\nEpoch 5/10\n100/100 [==============================] - 13s 130ms/step - loss: 0.1992 - accuracy: 0.9213 - val_loss: 0.1949 - val_accuracy: 0.9180\nEpoch 6/10\n100/100 [==============================] - 14s 136ms/step - loss: 0.1737 - accuracy: 0.9323 - val_loss: 0.1723 - val_accuracy: 0.9275\nEpoch 7/10\n100/100 [==============================] - 14s 139ms/step - loss: 0.1531 - accuracy: 0.9412 - val_loss: 0.1670 - val_accuracy: 0.9310\nEpoch 8/10\n100/100 [==============================] - 13s 134ms/step - loss: 0.1299 - accuracy: 0.9525 - val_loss: 0.1553 - val_accuracy: 0.9340\nEpoch 9/10\n100/100 [==============================] - 14s 137ms/step - loss: 0.1158 - accuracy: 0.9556 - val_loss: 0.1581 - val_accuracy: 0.9340\nEpoch 10/10\n100/100 [==============================] - 14s 142ms/step - loss: 0.1006 - accuracy: 0.9617 - val_loss: 0.1614 - val_accuracy: 0.9345\n```\n\n```python\n\n```\n\n### 四，评估模型\n\n```python\n#%load_ext tensorboard\n#%tensorboard --logdir ./data/keras_model\n```\n\n```python\nfrom tensorboard import notebook\nnotebook.list() \n```\n\n```python\n#在tensorboard中查看模型\nnotebook.start(\"--logdir ./data/keras_model\")\n```\n\n```python\n\n```\n\n![](./data/1-2-tensorboard.jpg)\n\n```python\nimport pandas as pd \ndfhistory = pd.DataFrame(history.history)\ndfhistory.index = range(1,len(dfhistory) + 1)\ndfhistory.index.name = 'epoch'\n\ndfhistory\n```\n\n![](./data/1-2-dfhistory.jpg)\n\n```python\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\n\nimport matplotlib.pyplot as plt\n\ndef plot_metric(history, metric):\n    train_metrics = history.history[metric]\n    val_metrics = history.history['val_'+metric]\n    epochs = range(1, len(train_metrics) + 1)\n    plt.plot(epochs, train_metrics, 'bo--')\n    plt.plot(epochs, val_metrics, 'ro-')\n    plt.title('Training and validation '+ metric)\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(metric)\n    plt.legend([\"train_\"+metric, 'val_'+metric])\n    plt.show()\n```\n\n```python\nplot_metric(history,\"loss\")\n```\n\n![](./data/1-2-Loss曲线.jpg)\n\n```python\nplot_metric(history,\"accuracy\")\n```\n\n![](./data/1-2-Accuracy曲线.jpg)\n\n```python\n#可以使用evaluate对数据进行评估\nval_loss,val_accuracy = model.evaluate(ds_test,workers=4)\nprint(val_loss,val_accuracy)\n\n```\n\n```\n0.16139143370091916 0.9345\n```\n\n\n### 五，使用模型\n\n\n可以使用model.predict(ds_test)进行预测。\n\n也可以使用model.predict_on_batch(x_test)对一个批量进行预测。\n\n```python\nmodel.predict(ds_test)\n```\n\n```\narray([[9.9996173e-01],\n       [9.5104784e-01],\n       [2.8648047e-04],\n       ...,\n       [1.1484033e-03],\n       [3.5589080e-02],\n       [9.8537153e-01]], dtype=float32)\n```\n\n```python\nfor x,y in ds_test.take(1):\n    print(model.predict_on_batch(x[0:20]))\n```\n\n```\ntf.Tensor(\n[[3.8065155e-05]\n [8.8236779e-01]\n [9.1433197e-01]\n [9.9921846e-01]\n [6.4052093e-01]\n [4.9970779e-03]\n [2.6735585e-04]\n [9.9842811e-01]\n [7.9198682e-01]\n [7.4823302e-01]\n [8.7208226e-03]\n [9.3951421e-03]\n [9.9790359e-01]\n [9.9998581e-01]\n [2.1642199e-05]\n [1.7915063e-02]\n [2.5839690e-02]\n [9.7538447e-01]\n [9.7393811e-01]\n [9.7333014e-01]], shape=(20, 1), dtype=float32)\n```\n\n\n\n\n```python\n\n```\n\n### 六，保存模型\n\n\n推荐使用TensorFlow原生方式保存模型。\n\n```python\n# 保存权重，该方式仅仅保存权重张量\nmodel.save_weights('./data/tf_model_weights.ckpt',save_format = \"tf\")\n```\n\n```python\n# 保存模型结构与模型参数到文件,该方式保存的模型具有跨平台性便于部署\n\nmodel.save('./data/tf_model_savedmodel', save_format=\"tf\")\nprint('export saved model.')\n\nmodel_loaded = tf.keras.models.load_model('./data/tf_model_savedmodel')\nmodel_loaded.evaluate(ds_test)\n```\n\n```\n[0.16139124035835267, 0.9345]\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n# 1-3,文本数据建模流程范例\n\n\n### 一，准备数据\n\n\nimdb数据集的目标是根据电影评论的文本内容预测评论的情感标签。\n\n训练集有20000条电影评论文本，测试集有5000条电影评论文本，其中正面评论和负面评论都各占一半。\n\n文本数据预处理较为繁琐，包括中文切词（本示例不涉及），构建词典，编码转换，序列填充，构建数据管道等等。\n\n\n\n在tensorflow中完成文本数据预处理的常用方案有两种，第一种是利用tf.keras.preprocessing中的Tokenizer词典构建工具和tf.keras.utils.Sequence构建文本数据生成器管道。\n\n第二种是使用tf.data.Dataset搭配.keras.layers.experimental.preprocessing.TextVectorization预处理层。\n\n第一种方法较为复杂，其使用范例可以参考以下文章。\n\nhttps://zhuanlan.zhihu.com/p/67697840\n\n第二种方法为TensorFlow原生方式，相对也更加简单一些。\n\n我们此处介绍第二种方法。\n\n\n![](./data/电影评论.jpg)\n\n```python\nimport numpy as np \nimport pandas as pd \nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras import models,layers,preprocessing,optimizers,losses,metrics\nfrom tensorflow.keras.layers.experimental.preprocessing import TextVectorization\nimport re,string\n\ntrain_data_path = \"./data/imdb/train.csv\"\ntest_data_path =  \"./data/imdb/test.csv\"\n\nMAX_WORDS = 10000  # 仅考虑最高频的10000个词\nMAX_LEN = 200  # 每个样本保留200个词的长度\nBATCH_SIZE = 20 \n\n\n#构建管道\ndef split_line(line):\n    arr = tf.strings.split(line,\"\\t\")\n    label = tf.expand_dims(tf.cast(tf.strings.to_number(arr[0]),tf.int32),axis = 0)\n    text = tf.expand_dims(arr[1],axis = 0)\n    return (text,label)\n\nds_train_raw =  tf.data.TextLineDataset(filenames = [train_data_path]) \\\n   .map(split_line,num_parallel_calls = tf.data.experimental.AUTOTUNE) \\\n   .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n   .prefetch(tf.data.experimental.AUTOTUNE)\n\nds_test_raw = tf.data.TextLineDataset(filenames = [test_data_path]) \\\n   .map(split_line,num_parallel_calls = tf.data.experimental.AUTOTUNE) \\\n   .batch(BATCH_SIZE) \\\n   .prefetch(tf.data.experimental.AUTOTUNE)\n\n\n#构建词典\ndef clean_text(text):\n    lowercase = tf.strings.lower(text)\n    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n    cleaned_punctuation = tf.strings.regex_replace(stripped_html,\n         '[%s]' % re.escape(string.punctuation),'')\n    return cleaned_punctuation\n\nvectorize_layer = TextVectorization(\n    standardize=clean_text,\n    split = 'whitespace',\n    max_tokens=MAX_WORDS-1, #有一个留给占位符\n    output_mode='int',\n    output_sequence_length=MAX_LEN)\n\nds_text = ds_train_raw.map(lambda text,label: text)\nvectorize_layer.adapt(ds_text)\nprint(vectorize_layer.get_vocabulary()[0:100])\n\n\n#单词编码\nds_train = ds_train_raw.map(lambda text,label:(vectorize_layer(text),label)) \\\n    .prefetch(tf.data.experimental.AUTOTUNE)\nds_test = ds_test_raw.map(lambda text,label:(vectorize_layer(text),label)) \\\n    .prefetch(tf.data.experimental.AUTOTUNE)\n\n```\n\n```\n[b'the', b'and', b'a', b'of', b'to', b'is', b'in', b'it', b'i', b'this', b'that', b'was', b'as', b'for', b'with', b'movie', b'but', b'film', b'on', b'not', b'you', b'his', b'are', b'have', b'be', b'he', b'one', b'its', b'at', b'all', b'by', b'an', b'they', b'from', b'who', b'so', b'like', b'her', b'just', b'or', b'about', b'has', b'if', b'out', b'some', b'there', b'what', b'good', b'more', b'when', b'very', b'she', b'even', b'my', b'no', b'would', b'up', b'time', b'only', b'which', b'story', b'really', b'their', b'were', b'had', b'see', b'can', b'me', b'than', b'we', b'much', b'well', b'get', b'been', b'will', b'into', b'people', b'also', b'other', b'do', b'bad', b'because', b'great', b'first', b'how', b'him', b'most', b'dont', b'made', b'then', b'them', b'films', b'movies', b'way', b'make', b'could', b'too', b'any', b'after', b'characters']\n```\n\n```python\n\n```\n\n### 二，定义模型\n\n\n使用Keras接口有以下3种方式构建模型：使用Sequential按层顺序构建模型，使用函数式API构建任意结构模型，继承Model基类构建自定义模型。\n\n此处选择使用继承Model基类构建自定义模型。\n\n```python\n# 演示自定义模型范例，实际上应该优先使用Sequential或者函数式API\n\ntf.keras.backend.clear_session()\n\nclass CnnModel(models.Model):\n    def __init__(self):\n        super(CnnModel, self).__init__()\n        \n    def build(self,input_shape):\n        self.embedding = layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN)\n        self.conv_1 = layers.Conv1D(16, kernel_size= 5,name = \"conv_1\",activation = \"relu\")\n        self.pool = layers.MaxPool1D()\n        self.conv_2 = layers.Conv1D(128, kernel_size=2,name = \"conv_2\",activation = \"relu\")\n        self.flatten = layers.Flatten()\n        self.dense = layers.Dense(1,activation = \"sigmoid\")\n        super(CnnModel,self).build(input_shape)\n    \n    def call(self, x):\n        x = self.embedding(x)\n        x = self.conv_1(x)\n        x = self.pool(x)\n        x = self.conv_2(x)\n        x = self.pool(x)\n        x = self.flatten(x)\n        x = self.dense(x)\n        return(x)\n    \nmodel = CnnModel()\nmodel.build(input_shape =(None,MAX_LEN))\nmodel.summary()\n\n```\n\n```python\n\n```\n\n```\nModel: \"cnn_model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        multiple                  70000     \n_________________________________________________________________\nconv_1 (Conv1D)              multiple                  576       \n_________________________________________________________________\nmax_pooling1d (MaxPooling1D) multiple                  0         \n_________________________________________________________________\nconv_2 (Conv1D)              multiple                  4224      \n_________________________________________________________________\nflatten (Flatten)            multiple                  0         \n_________________________________________________________________\ndense (Dense)                multiple                  6145      \n=================================================================\nTotal params: 80,945\nTrainable params: 80,945\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n```python\n\n```\n\n### 三，训练模型\n\n\n训练模型通常有3种方法，内置fit方法，内置train_on_batch方法，以及自定义训练循环。此处我们通过自定义训练循环训练模型。\n\n```python\n#打印时间分割线\n@tf.function\ndef printbar():\n    ts = tf.timestamp()\n    today_ts = ts%(24*60*60)\n\n    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\n    minite = tf.cast((today_ts%3600)//60,tf.int32)\n    second = tf.cast(tf.floor(today_ts%60),tf.int32)\n    \n    def timeformat(m):\n        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\n            return(tf.strings.format(\"0{}\",m))\n        else:\n            return(tf.strings.format(\"{}\",m))\n    \n    timestring = tf.strings.join([timeformat(hour),timeformat(minite),\n                timeformat(second)],separator = \":\")\n    tf.print(\"==========\"*8,end = \"\")\n    tf.print(timestring)\n```\n\n```python\noptimizer = optimizers.Nadam()\nloss_func = losses.BinaryCrossentropy()\n\ntrain_loss = metrics.Mean(name='train_loss')\ntrain_metric = metrics.BinaryAccuracy(name='train_accuracy')\n\nvalid_loss = metrics.Mean(name='valid_loss')\nvalid_metric = metrics.BinaryAccuracy(name='valid_accuracy')\n\n\n@tf.function\ndef train_step(model, features, labels):\n    with tf.GradientTape() as tape:\n        predictions = model(features,training = True)\n        loss = loss_func(labels, predictions)\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n    train_loss.update_state(loss)\n    train_metric.update_state(labels, predictions)\n    \n\n@tf.function\ndef valid_step(model, features, labels):\n    predictions = model(features,training = False)\n    batch_loss = loss_func(labels, predictions)\n    valid_loss.update_state(batch_loss)\n    valid_metric.update_state(labels, predictions)\n\n\ndef train_model(model,ds_train,ds_valid,epochs):\n    for epoch in tf.range(1,epochs+1):\n        \n        for features, labels in ds_train:\n            train_step(model,features,labels)\n\n        for features, labels in ds_valid:\n            valid_step(model,features,labels)\n        \n        #此处logs模板需要根据metric具体情况修改\n        logs = 'Epoch={},Loss:{},Accuracy:{},Valid Loss:{},Valid Accuracy:{}' \n        \n        if epoch%1==0:\n            printbar()\n            tf.print(tf.strings.format(logs,\n            (epoch,train_loss.result(),train_metric.result(),valid_loss.result(),valid_metric.result())))\n            tf.print(\"\")\n        \n        train_loss.reset_states()\n        valid_loss.reset_states()\n        train_metric.reset_states()\n        valid_metric.reset_states()\n\ntrain_model(model,ds_train,ds_test,epochs = 6)\n\n```\n\n```\n================================================================================13:54:08\nEpoch=1,Loss:0.442317516,Accuracy:0.7695,Valid Loss:0.323672801,Valid Accuracy:0.8614\n\n================================================================================13:54:20\nEpoch=2,Loss:0.245737702,Accuracy:0.90215,Valid Loss:0.356488883,Valid Accuracy:0.8554\n\n================================================================================13:54:32\nEpoch=3,Loss:0.17360799,Accuracy:0.93455,Valid Loss:0.361132562,Valid Accuracy:0.8674\n\n================================================================================13:54:44\nEpoch=4,Loss:0.113476314,Accuracy:0.95975,Valid Loss:0.483677238,Valid Accuracy:0.856\n\n================================================================================13:54:57\nEpoch=5,Loss:0.0698405355,Accuracy:0.9768,Valid Loss:0.607856631,Valid Accuracy:0.857\n\n================================================================================13:55:15\nEpoch=6,Loss:0.0366807655,Accuracy:0.98825,Valid Loss:0.745884955,Valid Accuracy:0.854\n```\n\n\n### 四，评估模型\n\n\n通过自定义训练循环训练的模型没有经过编译，无法直接使用model.evaluate(ds_valid)方法\n\n```python\n\ndef evaluate_model(model,ds_valid):\n    for features, labels in ds_valid:\n         valid_step(model,features,labels)\n    logs = 'Valid Loss:{},Valid Accuracy:{}' \n    tf.print(tf.strings.format(logs,(valid_loss.result(),valid_metric.result())))\n    \n    valid_loss.reset_states()\n    train_metric.reset_states()\n    valid_metric.reset_states()\n\n    \n```\n\n```python\nevaluate_model(model,ds_test)\n```\n\n```\nValid Loss:0.745884418,Valid Accuracy:0.854\n```\n\n```python\n\n```\n\n### 五，使用模型\n\n\n可以使用以下方法:\n\n* model.predict(ds_test)\n* model(x_test)\n* model.call(x_test)\n* model.predict_on_batch(x_test)\n\n推荐优先使用model.predict(ds_test)方法，既可以对Dataset，也可以对Tensor使用。\n\n```python\nmodel.predict(ds_test)\n```\n\n```\narray([[0.7864823 ],\n       [0.9999901 ],\n       [0.99944776],\n       ...,\n       [0.8498302 ],\n       [0.13382755],\n       [1.        ]], dtype=float32)\n```\n\n```python\nfor x_test,_ in ds_test.take(1):\n    print(model(x_test))\n    #以下方法等价：\n    #print(model.call(x_test))\n    #print(model.predict_on_batch(x_test))\n```\n\n```\ntf.Tensor(\n[[7.8648227e-01]\n [9.9999011e-01]\n [9.9944776e-01]\n [3.7153201e-09]\n [9.4462049e-01]\n [2.3522753e-04]\n [1.2044354e-04]\n [9.3752089e-07]\n [9.9996352e-01]\n [9.3435925e-01]\n [9.8746723e-01]\n [9.9908626e-01]\n [4.1563155e-08]\n [4.1808244e-03]\n [8.0184749e-05]\n [8.3910513e-01]\n [3.5167937e-05]\n [7.2113985e-01]\n [4.5228912e-03]\n [9.9942589e-01]], shape=(20, 1), dtype=float32)\n```\n\n```python\n\n```\n\n### 六，保存模型\n\n\n推荐使用TensorFlow原生方式保存模型。\n\n```python\nmodel.save('./data/tf_model_savedmodel', save_format=\"tf\")\nprint('export saved model.')\n\nmodel_loaded = tf.keras.models.load_model('./data/tf_model_savedmodel')\nmodel_loaded.predict(ds_test)\n```\n\n```\narray([[0.7864823 ],\n       [0.9999901 ],\n       [0.99944776],\n       ...,\n       [0.8498302 ],\n       [0.13382755],\n       [1.        ]], dtype=float32)\n```\n\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n\n\n\n\n# 1-4,时间序列数据建模流程范例\n\n\n国内的新冠肺炎疫情从发现至今已经持续3个多月了，这场起源于吃野味的灾难给大家的生活造成了诸多方面的影响。\n\n有的同学是收入上的，有的同学是感情上的，有的同学是心理上的，还有的同学是体重上的。\n\n那么国内的新冠肺炎疫情何时结束呢？什么时候我们才可以重获自由呢？\n\n本篇文章将利用TensorFlow2.0建立时间序列RNN模型，对国内的新冠肺炎疫情结束时间进行预测。\n\n\n![](./data/疫情前后对比.png)\n\n\n### 一，准备数据\n\n\n本文的数据集取自tushare，获取该数据集的方法参考了以下文章。\n\n《https://zhuanlan.zhihu.com/p/109556102》\n\n![](./data/1-4-新增人数.png)\n\n\n\n```python\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport tensorflow as tf \nfrom tensorflow.keras import models,layers,losses,metrics,callbacks \n\n```\n\n```python\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\n\ndf = pd.read_csv(\"./data/covid-19.csv\",sep = \"\\t\")\ndf.plot(x = \"date\",y = [\"confirmed_num\",\"cured_num\",\"dead_num\"],figsize=(10,6))\nplt.xticks(rotation=60)\n\n```\n\n![](./data/1-4-累积曲线.png)\n\n```python\ndfdata = df.set_index(\"date\")\ndfdiff = dfdata.diff(periods=1).dropna()\ndfdiff = dfdiff.reset_index(\"date\")\n\ndfdiff.plot(x = \"date\",y = [\"confirmed_num\",\"cured_num\",\"dead_num\"],figsize=(10,6))\nplt.xticks(rotation=60)\ndfdiff = dfdiff.drop(\"date\",axis = 1).astype(\"float32\")\n\n```\n\n![](./data/1-4-新增曲线.png)\n\n```python\n#用某日前8天窗口数据作为输入预测该日数据\nWINDOW_SIZE = 8\n\ndef batch_dataset(dataset):\n    dataset_batched = dataset.batch(WINDOW_SIZE,drop_remainder=True)\n    return dataset_batched\n\nds_data = tf.data.Dataset.from_tensor_slices(tf.constant(dfdiff.values,dtype = tf.float32)) \\\n   .window(WINDOW_SIZE,shift=1).flat_map(batch_dataset)\n\nds_label = tf.data.Dataset.from_tensor_slices(\n    tf.constant(dfdiff.values[WINDOW_SIZE:],dtype = tf.float32))\n\n#数据较小，可以将全部训练数据放入到一个batch中，提升性能\nds_train = tf.data.Dataset.zip((ds_data,ds_label)).batch(38).cache()\n\n\n```\n\n### 二，定义模型\n\n\n使用Keras接口有以下3种方式构建模型：使用Sequential按层顺序构建模型，使用函数式API构建任意结构模型，继承Model基类构建自定义模型。\n\n此处选择使用函数式API构建任意结构模型。\n\n```python\n#考虑到新增确诊，新增治愈，新增死亡人数数据不可能小于0，设计如下结构\nclass Block(layers.Layer):\n    def __init__(self, **kwargs):\n        super(Block, self).__init__(**kwargs)\n    \n    def call(self, x_input,x):\n        x_out = tf.maximum((1+x)*x_input[:,-1,:],0.0)\n        return x_out\n    \n    def get_config(self):  \n        config = super(Block, self).get_config()\n        return config\n\n```\n\n```python\ntf.keras.backend.clear_session()\nx_input = layers.Input(shape = (None,3),dtype = tf.float32)\nx = layers.LSTM(3,return_sequences = True,input_shape=(None,3))(x_input)\nx = layers.LSTM(3,return_sequences = True,input_shape=(None,3))(x)\nx = layers.LSTM(3,return_sequences = True,input_shape=(None,3))(x)\nx = layers.LSTM(3,input_shape=(None,3))(x)\nx = layers.Dense(3)(x)\n\n#考虑到新增确诊，新增治愈，新增死亡人数数据不可能小于0，设计如下结构\n#x = tf.maximum((1+x)*x_input[:,-1,:],0.0)\nx = Block()(x_input,x)\nmodel = models.Model(inputs = [x_input],outputs = [x])\nmodel.summary()\n\n```\n\n```python\n\n```\n\n```\nModel: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, None, 3)]         0         \n_________________________________________________________________\nlstm (LSTM)                  (None, None, 3)           84        \n_________________________________________________________________\nlstm_1 (LSTM)                (None, None, 3)           84        \n_________________________________________________________________\nlstm_2 (LSTM)                (None, None, 3)           84        \n_________________________________________________________________\nlstm_3 (LSTM)                (None, 3)                 84        \n_________________________________________________________________\ndense (Dense)                (None, 3)                 12        \n_________________________________________________________________\nblock (Block)                (None, 3)                 0         \n=================================================================\nTotal params: 348\nTrainable params: 348\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n\n### 三，训练模型\n\n\n训练模型通常有3种方法，内置fit方法，内置train_on_batch方法，以及自定义训练循环。此处我们选择最常用也最简单的内置fit方法。\n\n注：循环神经网络调试较为困难，需要设置多个不同的学习率多次尝试，以取得较好的效果。\n\n```python\n#自定义损失函数，考虑平方差和预测目标的比值\nclass MSPE(losses.Loss):\n    def call(self,y_true,y_pred):\n        err_percent = (y_true - y_pred)**2/(tf.maximum(y_true**2,1e-7))\n        mean_err_percent = tf.reduce_mean(err_percent)\n        return mean_err_percent\n    \n    def get_config(self):\n        config = super(MSPE, self).get_config()\n        return config\n\n```\n\n```python\nimport datetime\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\nmodel.compile(optimizer=optimizer,loss=MSPE(name = \"MSPE\"))\n\nlogdir = \"./data/keras_model/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n\ntb_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n#如果loss在100个epoch后没有提升，学习率减半。\nlr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\",factor = 0.5, patience = 100)\n#当loss在200个epoch后没有提升，则提前终止训练。\nstop_callback = tf.keras.callbacks.EarlyStopping(monitor = \"loss\", patience= 200)\ncallbacks_list = [tb_callback,lr_callback,stop_callback]\n\nhistory = model.fit(ds_train,epochs=500,callbacks = callbacks_list)\n\n```\n\n```\nEpoch 371/500\n1/1 [==============================] - 0s 61ms/step - loss: 0.1184\nEpoch 372/500\n1/1 [==============================] - 0s 64ms/step - loss: 0.1177\nEpoch 373/500\n1/1 [==============================] - 0s 56ms/step - loss: 0.1169\nEpoch 374/500\n1/1 [==============================] - 0s 50ms/step - loss: 0.1161\nEpoch 375/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.1154\nEpoch 376/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.1147\nEpoch 377/500\n1/1 [==============================] - 0s 62ms/step - loss: 0.1140\nEpoch 378/500\n1/1 [==============================] - 0s 93ms/step - loss: 0.1133\nEpoch 379/500\n1/1 [==============================] - 0s 85ms/step - loss: 0.1126\nEpoch 380/500\n1/1 [==============================] - 0s 68ms/step - loss: 0.1119\nEpoch 381/500\n1/1 [==============================] - 0s 52ms/step - loss: 0.1113\nEpoch 382/500\n1/1 [==============================] - 0s 54ms/step - loss: 0.1107\nEpoch 383/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.1100\nEpoch 384/500\n1/1 [==============================] - 0s 56ms/step - loss: 0.1094\nEpoch 385/500\n1/1 [==============================] - 0s 54ms/step - loss: 0.1088\nEpoch 386/500\n1/1 [==============================] - 0s 74ms/step - loss: 0.1082\nEpoch 387/500\n1/1 [==============================] - 0s 60ms/step - loss: 0.1077\nEpoch 388/500\n1/1 [==============================] - 0s 52ms/step - loss: 0.1071\nEpoch 389/500\n1/1 [==============================] - 0s 52ms/step - loss: 0.1066\nEpoch 390/500\n1/1 [==============================] - 0s 56ms/step - loss: 0.1060\nEpoch 391/500\n1/1 [==============================] - 0s 61ms/step - loss: 0.1055\nEpoch 392/500\n1/1 [==============================] - 0s 60ms/step - loss: 0.1050\nEpoch 393/500\n1/1 [==============================] - 0s 59ms/step - loss: 0.1045\nEpoch 394/500\n1/1 [==============================] - 0s 65ms/step - loss: 0.1040\nEpoch 395/500\n1/1 [==============================] - 0s 58ms/step - loss: 0.1035\nEpoch 396/500\n1/1 [==============================] - 0s 52ms/step - loss: 0.1031\nEpoch 397/500\n1/1 [==============================] - 0s 58ms/step - loss: 0.1026\nEpoch 398/500\n1/1 [==============================] - 0s 60ms/step - loss: 0.1022\nEpoch 399/500\n1/1 [==============================] - 0s 57ms/step - loss: 0.1017\nEpoch 400/500\n1/1 [==============================] - 0s 63ms/step - loss: 0.1013\nEpoch 401/500\n1/1 [==============================] - 0s 59ms/step - loss: 0.1009\nEpoch 402/500\n1/1 [==============================] - 0s 53ms/step - loss: 0.1005\nEpoch 403/500\n1/1 [==============================] - 0s 56ms/step - loss: 0.1001\nEpoch 404/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0997\nEpoch 405/500\n1/1 [==============================] - 0s 58ms/step - loss: 0.0993\nEpoch 406/500\n1/1 [==============================] - 0s 53ms/step - loss: 0.0990\nEpoch 407/500\n1/1 [==============================] - 0s 59ms/step - loss: 0.0986\nEpoch 408/500\n1/1 [==============================] - 0s 63ms/step - loss: 0.0982\nEpoch 409/500\n1/1 [==============================] - 0s 67ms/step - loss: 0.0979\nEpoch 410/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0976\nEpoch 411/500\n1/1 [==============================] - 0s 54ms/step - loss: 0.0972\nEpoch 412/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0969\nEpoch 413/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0966\nEpoch 414/500\n1/1 [==============================] - 0s 59ms/step - loss: 0.0963\nEpoch 415/500\n1/1 [==============================] - 0s 60ms/step - loss: 0.0960\nEpoch 416/500\n1/1 [==============================] - 0s 62ms/step - loss: 0.0957\nEpoch 417/500\n1/1 [==============================] - 0s 69ms/step - loss: 0.0954\nEpoch 418/500\n1/1 [==============================] - 0s 60ms/step - loss: 0.0951\nEpoch 419/500\n1/1 [==============================] - 0s 50ms/step - loss: 0.0948\nEpoch 420/500\n1/1 [==============================] - 0s 56ms/step - loss: 0.0946\nEpoch 421/500\n1/1 [==============================] - 0s 57ms/step - loss: 0.0943\nEpoch 422/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0941\nEpoch 423/500\n1/1 [==============================] - 0s 62ms/step - loss: 0.0938\nEpoch 424/500\n1/1 [==============================] - 0s 60ms/step - loss: 0.0936\nEpoch 425/500\n1/1 [==============================] - 0s 100ms/step - loss: 0.0933\nEpoch 426/500\n1/1 [==============================] - 0s 68ms/step - loss: 0.0931\nEpoch 427/500\n1/1 [==============================] - 0s 60ms/step - loss: 0.0929\nEpoch 428/500\n1/1 [==============================] - 0s 50ms/step - loss: 0.0926\nEpoch 429/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0924\nEpoch 430/500\n1/1 [==============================] - 0s 57ms/step - loss: 0.0922\nEpoch 431/500\n1/1 [==============================] - 0s 75ms/step - loss: 0.0920\nEpoch 432/500\n1/1 [==============================] - 0s 57ms/step - loss: 0.0918\nEpoch 433/500\n1/1 [==============================] - 0s 77ms/step - loss: 0.0916\nEpoch 434/500\n1/1 [==============================] - 0s 50ms/step - loss: 0.0914\nEpoch 435/500\n1/1 [==============================] - 0s 56ms/step - loss: 0.0912\nEpoch 436/500\n1/1 [==============================] - 0s 60ms/step - loss: 0.0911\nEpoch 437/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0909\nEpoch 438/500\n1/1 [==============================] - 0s 57ms/step - loss: 0.0907\nEpoch 439/500\n1/1 [==============================] - 0s 59ms/step - loss: 0.0905\nEpoch 440/500\n1/1 [==============================] - 0s 60ms/step - loss: 0.0904\nEpoch 441/500\n1/1 [==============================] - 0s 68ms/step - loss: 0.0902\nEpoch 442/500\n1/1 [==============================] - 0s 73ms/step - loss: 0.0901\nEpoch 443/500\n1/1 [==============================] - 0s 50ms/step - loss: 0.0899\nEpoch 444/500\n1/1 [==============================] - 0s 58ms/step - loss: 0.0898\nEpoch 445/500\n1/1 [==============================] - 0s 56ms/step - loss: 0.0896\nEpoch 446/500\n1/1 [==============================] - 0s 52ms/step - loss: 0.0895\nEpoch 447/500\n1/1 [==============================] - 0s 60ms/step - loss: 0.0893\nEpoch 448/500\n1/1 [==============================] - 0s 64ms/step - loss: 0.0892\nEpoch 449/500\n1/1 [==============================] - 0s 70ms/step - loss: 0.0891\nEpoch 450/500\n1/1 [==============================] - 0s 57ms/step - loss: 0.0889\nEpoch 451/500\n1/1 [==============================] - 0s 53ms/step - loss: 0.0888\nEpoch 452/500\n1/1 [==============================] - 0s 51ms/step - loss: 0.0887\nEpoch 453/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0886\nEpoch 454/500\n1/1 [==============================] - 0s 58ms/step - loss: 0.0885\nEpoch 455/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0883\nEpoch 456/500\n1/1 [==============================] - 0s 71ms/step - loss: 0.0882\nEpoch 457/500\n1/1 [==============================] - 0s 50ms/step - loss: 0.0881\nEpoch 458/500\n1/1 [==============================] - 0s 56ms/step - loss: 0.0880\nEpoch 459/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0879\nEpoch 460/500\n1/1 [==============================] - 0s 57ms/step - loss: 0.0878\nEpoch 461/500\n1/1 [==============================] - 0s 56ms/step - loss: 0.0878\nEpoch 462/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0879\nEpoch 463/500\n1/1 [==============================] - 0s 60ms/step - loss: 0.0879\nEpoch 464/500\n1/1 [==============================] - 0s 68ms/step - loss: 0.0888\nEpoch 465/500\n1/1 [==============================] - 0s 62ms/step - loss: 0.0875\nEpoch 466/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0873\nEpoch 467/500\n1/1 [==============================] - 0s 49ms/step - loss: 0.0872\nEpoch 468/500\n1/1 [==============================] - 0s 56ms/step - loss: 0.0872\nEpoch 469/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0871\nEpoch 470/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0871\nEpoch 471/500\n1/1 [==============================] - 0s 59ms/step - loss: 0.0870\nEpoch 472/500\n1/1 [==============================] - 0s 68ms/step - loss: 0.0871\nEpoch 473/500\n1/1 [==============================] - 0s 57ms/step - loss: 0.0869\nEpoch 474/500\n1/1 [==============================] - 0s 61ms/step - loss: 0.0870\nEpoch 475/500\n1/1 [==============================] - 0s 47ms/step - loss: 0.0868\nEpoch 476/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0868\nEpoch 477/500\n1/1 [==============================] - 0s 62ms/step - loss: 0.0866\nEpoch 478/500\n1/1 [==============================] - 0s 58ms/step - loss: 0.0867\nEpoch 479/500\n1/1 [==============================] - 0s 60ms/step - loss: 0.0865\nEpoch 480/500\n1/1 [==============================] - 0s 65ms/step - loss: 0.0866\nEpoch 481/500\n1/1 [==============================] - 0s 58ms/step - loss: 0.0864\nEpoch 482/500\n1/1 [==============================] - 0s 57ms/step - loss: 0.0865\nEpoch 483/500\n1/1 [==============================] - 0s 53ms/step - loss: 0.0863\nEpoch 484/500\n1/1 [==============================] - 0s 56ms/step - loss: 0.0864\nEpoch 485/500\n1/1 [==============================] - 0s 56ms/step - loss: 0.0862\nEpoch 486/500\n1/1 [==============================] - 0s 55ms/step - loss: 0.0863\nEpoch 487/500\n1/1 [==============================] - 0s 52ms/step - loss: 0.0861\nEpoch 488/500\n1/1 [==============================] - 0s 68ms/step - loss: 0.0862\nEpoch 489/500\n1/1 [==============================] - 0s 62ms/step - loss: 0.0860\nEpoch 490/500\n1/1 [==============================] - 0s 57ms/step - loss: 0.0861\nEpoch 491/500\n1/1 [==============================] - 0s 51ms/step - loss: 0.0859\nEpoch 492/500\n1/1 [==============================] - 0s 54ms/step - loss: 0.0860\nEpoch 493/500\n1/1 [==============================] - 0s 51ms/step - loss: 0.0859\nEpoch 494/500\n1/1 [==============================] - 0s 54ms/step - loss: 0.0860\nEpoch 495/500\n1/1 [==============================] - 0s 50ms/step - loss: 0.0858\nEpoch 496/500\n1/1 [==============================] - 0s 69ms/step - loss: 0.0859\nEpoch 497/500\n1/1 [==============================] - 0s 63ms/step - loss: 0.0857\nEpoch 498/500\n1/1 [==============================] - 0s 56ms/step - loss: 0.0858\nEpoch 499/500\n1/1 [==============================] - 0s 54ms/step - loss: 0.0857\nEpoch 500/500\n1/1 [==============================] - 0s 57ms/step - loss: 0.0858\n```\n\n```python\n\n```\n\n### 四，评估模型\n\n\n评估模型一般要设置验证集或者测试集，由于此例数据较少，我们仅仅可视化损失函数在训练集上的迭代情况。\n\n```python\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\n\nimport matplotlib.pyplot as plt\n\ndef plot_metric(history, metric):\n    train_metrics = history.history[metric]\n    epochs = range(1, len(train_metrics) + 1)\n    plt.plot(epochs, train_metrics, 'bo--')\n    plt.title('Training '+ metric)\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(metric)\n    plt.legend([\"train_\"+metric])\n    plt.show()\n\n```\n\n```python\nplot_metric(history,\"loss\")\n```\n\n![](./data/1-4-损失函数曲线.png)\n\n\n### 五，使用模型\n\n\n此处我们使用模型预测疫情结束时间，即 新增确诊病例为0 的时间。\n\n```python\n#使用dfresult记录现有数据以及此后预测的疫情数据\ndfresult = dfdiff[[\"confirmed_num\",\"cured_num\",\"dead_num\"]].copy()\ndfresult.tail()\n```\n\n![](./data/1-4-日期3月10.png)\n\n```python\n#预测此后100天的新增走势,将其结果添加到dfresult中\nfor i in range(100):\n    arr_predict = model.predict(tf.constant(tf.expand_dims(dfresult.values[-38:,:],axis = 0)))\n\n    dfpredict = pd.DataFrame(tf.cast(tf.floor(arr_predict),tf.float32).numpy(),\n                columns = dfresult.columns)\n    dfresult = dfresult.append(dfpredict,ignore_index=True)\n```\n\n```python\ndfresult.query(\"confirmed_num==0\").head()\n\n# 第55天开始新增确诊降为0，第45天对应3月10日，也就是10天后，即预计3月20日新增确诊降为0\n# 注：该预测偏乐观\n```\n\n![](./data/1-4-预测确诊.png)\n\n```python\n\n```\n\n```python\ndfresult.query(\"cured_num==0\").head()\n\n# 第164天开始新增治愈降为0，第45天对应3月10日，也就是大概4个月后，即7月10日左右全部治愈。\n# 注: 该预测偏悲观，并且存在问题，如果将每天新增治愈人数加起来，将超过累计确诊人数。\n```\n\n![](./data/1-4-预测治愈.png)\n\n```python\n\n```\n\n```python\ndfresult.query(\"dead_num==0\").head()\n\n# 第60天开始，新增死亡降为0，第45天对应3月10日，也就是大概15天后，即20200325\n# 该预测较为合理\n```\n\n![](./data/1-4-预测死亡.png)\n\n```python\n\n```\n\n### 六，保存模型\n\n\n推荐使用TensorFlow原生方式保存模型。\n\n```python\nmodel.save('./data/tf_model_savedmodel', save_format=\"tf\")\nprint('export saved model.')\n```\n\n```python\nmodel_loaded = tf.keras.models.load_model('./data/tf_model_savedmodel',compile=False)\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\nmodel_loaded.compile(optimizer=optimizer,loss=MSPE(name = \"MSPE\"))\nmodel_loaded.predict(ds_train)\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n\n\n# 二、TensorFlow的核心概念\n\nTensorFlow™ 是一个采用 **数据流图**（data flow graphs），用于数值计算的开源软件库。节点（Nodes）在图中表示数学操作，图中的线（edges）则表示在节点间相互联系的多维数据数组，即张量（tensor）。它灵活的架构让你可以**在多种平台上展开计算**，例如台式计算机中的一个或多个CPU（或GPU），服务器，移动设备等等。TensorFlow 最初由Google大脑小组（隶属于Google机器智能研究机构）的研究员和工程师们开发出来，**用于机器学习和深度神经网络**方面的研究，但这个系统的通用性使其也可**广泛用于其他计算领域**。 \n\n\nTensorFlow的主要优点：\n\n* 灵活性：支持底层数值计算，C++自定义操作符\n\n* 可移植性：从服务器到PC到手机，从CPU到GPU到TPU\n\n* 分布式计算：分布式并行计算，可指定操作符对应计算设备\n\n\n俗话说，万丈高楼平地起，TensorFlow这座大厦也有它的地基。\n\nTensorflow底层最核心的概念是张量，计算图以及自动微分。\n\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![](./data/Python与算法之美logo.jpg)\n\n\n\n# 2-1,张量数据结构\n\n程序 = 数据结构+算法。\n\nTensorFlow程序 = 张量数据结构 + 计算图算法语言\n\n张量和计算图是 TensorFlow的核心概念。\n\nTensorflow的基本数据结构是张量Tensor。张量即多维数组。Tensorflow的张量和numpy中的array很类似。\n\n从行为特性来看，有两种类型的张量，常量constant和变量Variable.\n\n常量的值在计算图中不可以被重新赋值，变量可以在计算图中用assign等算子重新赋值。\n\n\n### 一，常量张量\n\n\n张量的数据类型和numpy.array基本一一对应。\n\n```python\nimport numpy as np\nimport tensorflow as tf\n\ni = tf.constant(1) # tf.int32 类型常量\nl = tf.constant(1,dtype = tf.int64) # tf.int64 类型常量\nf = tf.constant(1.23) #tf.float32 类型常量\nd = tf.constant(3.14,dtype = tf.double) # tf.double 类型常量\ns = tf.constant(\"hello world\") # tf.string类型常量\nb = tf.constant(True) #tf.bool类型常量\n\n\nprint(tf.int64 == np.int64) \nprint(tf.bool == np.bool)\nprint(tf.double == np.float64)\nprint(tf.string == np.unicode) # tf.string类型和np.unicode类型不等价\n\n```\n\n```\nTrue\nTrue\nTrue\nFalse\n```\n\n\n不同类型的数据可以用不同维度(rank)的张量来表示。\n\n标量为0维张量，向量为1维张量，矩阵为2维张量。\n\n彩色图像有rgb三个通道，可以表示为3维张量。\n\n视频还有时间维，可以表示为4维张量。\n\n可以简单地总结为：有几层中括号，就是多少维的张量。\n\n```python\nscalar = tf.constant(True)  #标量，0维张量\n\nprint(tf.rank(scalar))\nprint(scalar.numpy().ndim)  # tf.rank的作用和numpy的ndim方法相同\n```\n\n```\ntf.Tensor(0, shape=(), dtype=int32)\n0\n```\n\n```python\nvector = tf.constant([1.0,2.0,3.0,4.0]) #向量，1维张量\n\nprint(tf.rank(vector))\nprint(np.ndim(vector.numpy()))\n```\n\n```\ntf.Tensor(1, shape=(), dtype=int32)\n1\n```\n\n```python\nmatrix = tf.constant([[1.0,2.0],[3.0,4.0]]) #矩阵, 2维张量\n\nprint(tf.rank(matrix).numpy())\nprint(np.ndim(matrix))\n```\n\n```\n2\n2\n```\n\n```python\ntensor3 = tf.constant([[[1.0,2.0],[3.0,4.0]],[[5.0,6.0],[7.0,8.0]]])  # 3维张量\nprint(tensor3)\nprint(tf.rank(tensor3))\n```\n\n```\ntf.Tensor(\n[[[1. 2.]\n  [3. 4.]]\n\n [[5. 6.]\n  [7. 8.]]], shape=(2, 2, 2), dtype=float32)\ntf.Tensor(3, shape=(), dtype=int32)\n```\n\n```python\ntensor4 = tf.constant([[[[1.0,1.0],[2.0,2.0]],[[3.0,3.0],[4.0,4.0]]],\n                        [[[5.0,5.0],[6.0,6.0]],[[7.0,7.0],[8.0,8.0]]]])  # 4维张量\nprint(tensor4)\nprint(tf.rank(tensor4))\n```\n\n```\ntf.Tensor(\n[[[[1. 1.]\n   [2. 2.]]\n\n  [[3. 3.]\n   [4. 4.]]]\n\n\n [[[5. 5.]\n   [6. 6.]]\n\n  [[7. 7.]\n   [8. 8.]]]], shape=(2, 2, 2, 2), dtype=float32)\ntf.Tensor(4, shape=(), dtype=int32)\n```\n\n\n可以用tf.cast改变张量的数据类型。\n\n可以用numpy方法将tensorflow中的张量转化成numpy中的张量。\n\n可以用shape方法查看张量的尺寸。\n\n```python\nh = tf.constant([123,456],dtype = tf.int32)\nf = tf.cast(h,tf.float32)\nprint(h.dtype, f.dtype)\n```\n\n```\n<dtype: 'int32'> <dtype: 'float32'>\n```\n\n```python\ny = tf.constant([[1.0,2.0],[3.0,4.0]])\nprint(y.numpy()) #转换成np.array\nprint(y.shape)\n```\n\n```\n[[1. 2.]\n [3. 4.]]\n(2, 2)\n```\n\n```python\nu = tf.constant(u\"你好 世界\")\nprint(u.numpy())  \nprint(u.numpy().decode(\"utf-8\"))\n```\n\n```\nb'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd \\xe4\\xb8\\x96\\xe7\\x95\\x8c'\n你好 世界\n```\n\n```python\n\n```\n### 二，变量张量\n\n\n模型中需要被训练的参数一般被设置成变量。\n\n```python\n# 常量值不可以改变，常量的重新赋值相当于创造新的内存空间\nc = tf.constant([1.0,2.0])\nprint(c)\nprint(id(c))\nc = c + tf.constant([1.0,1.0])\nprint(c)\nprint(id(c))\n```\n\n```\ntf.Tensor([1. 2.], shape=(2,), dtype=float32)\n5276289568\ntf.Tensor([2. 3.], shape=(2,), dtype=float32)\n5276290240\n```\n\n```python\n# 变量的值可以改变，可以通过assign, assign_add等方法给变量重新赋值\nv = tf.Variable([1.0,2.0],name = \"v\")\nprint(v)\nprint(id(v))\nv.assign_add([1.0,1.0])\nprint(v)\nprint(id(v))\n```\n```\n<tf.Variable 'v:0' shape=(2,) dtype=float32, numpy=array([1., 2.], dtype=float32)>\n5276259888\n<tf.Variable 'v:0' shape=(2,) dtype=float32, numpy=array([2., 3.], dtype=float32)>\n5276259888\n\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n\n\n# 2-2,三种计算图\n\n\n有三种计算图的构建方式：静态计算图，动态计算图，以及Autograph.\n\n在TensorFlow1.0时代，采用的是静态计算图，需要先使用TensorFlow的各种算子创建计算图，然后再开启一个会话Session，显式执行计算图。\n\n而在TensorFlow2.0时代，采用的是动态计算图，即每使用一个算子后，该算子会被动态加入到隐含的默认计算图中立即执行得到结果，而无需开启Session。\n\n使用动态计算图即Eager Excution的好处是方便调试程序，它会让TensorFlow代码的表现和Python原生代码的表现一样，写起来就像写numpy一样，各种日志打印，控制流全部都是可以使用的。\n\n使用动态计算图的缺点是运行效率相对会低一些。因为使用动态图会有许多次Python进程和TensorFlow的C++进程之间的通信。而静态计算图构建完成之后几乎全部在TensorFlow内核上使用C++代码执行，效率更高。此外静态图会对计算步骤进行一定的优化，剪去和结果无关的计算步骤。\n\n如果需要在TensorFlow2.0中使用静态图，可以使用@tf.function装饰器将普通Python函数转换成对应的TensorFlow计算图构建代码。运行该函数就相当于在TensorFlow1.0中用Session执行代码。使用tf.function构建静态图的方式叫做 Autograph.\n\n\n### 一，计算图简介\n\n\n计算图由节点(nodes)和线(edges)组成。\n\n节点表示操作符Operator，或者称之为算子，线表示计算间的依赖。\n\n实线表示有数据传递依赖，传递的数据即张量。\n\n虚线通常可以表示控制依赖，即执行先后顺序。\n\n![](./data/strjoin_graph.png)\n\n\n### 二，静态计算图\n\n\n在TensorFlow1.0中，使用静态计算图分两步，第一步定义计算图，第二步在会话中执行计算图。\n\n\n**TensorFlow 1.0静态计算图范例**\n\n```python\nimport tensorflow as tf\n\n#定义计算图\ng = tf.Graph()\nwith g.as_default():\n    #placeholder为占位符，执行会话时候指定填充对象\n    x = tf.placeholder(name='x', shape=[], dtype=tf.string)  \n    y = tf.placeholder(name='y', shape=[], dtype=tf.string)\n    z = tf.string_join([x,y],name = 'join',separator=' ')\n\n#执行计算图\nwith tf.Session(graph = g) as sess:\n    print(sess.run(fetches = z,feed_dict = {x:\"hello\",y:\"world\"}))\n   \n```\n\n\n**TensorFlow2.0 怀旧版静态计算图**\n\nTensorFlow2.0为了确保对老版本tensorflow项目的兼容性，在tf.compat.v1子模块中保留了对TensorFlow1.0那种静态计算图构建风格的支持。\n\n可称之为怀旧版静态计算图，已经不推荐使用了。\n\n```python\nimport tensorflow as tf\n\ng = tf.compat.v1.Graph()\nwith g.as_default():\n    x = tf.compat.v1.placeholder(name='x', shape=[], dtype=tf.string)\n    y = tf.compat.v1.placeholder(name='y', shape=[], dtype=tf.string)\n    z = tf.strings.join([x,y],name = \"join\",separator = \" \")\n\nwith tf.compat.v1.Session(graph = g) as sess:\n    # fetches的结果非常像一个函数的返回值，而feed_dict中的占位符相当于函数的参数序列。\n    result = sess.run(fetches = z,feed_dict = {x:\"hello\",y:\"world\"})\n    print(result)\n\n```\n\n```\nb'hello world'\n```\n\n\n### 三，动态计算图\n\n\n在TensorFlow2.0中，使用的是动态计算图和Autograph.\n\n在TensorFlow1.0中，使用静态计算图分两步，第一步定义计算图，第二步在会话中执行计算图。\n\n动态计算图已经不区分计算图的定义和执行了，而是定义后立即执行。因此称之为 Eager Excution.\n\nEager这个英文单词的原意是\"迫不及待的\"，也就是立即执行的意思。\n\n\n```python\n# 动态计算图在每个算子处都进行构建，构建后立即执行\n\nx = tf.constant(\"hello\")\ny = tf.constant(\"world\")\nz = tf.strings.join([x,y],separator=\" \")\n\ntf.print(z)\n```\n\n```\nhello world\n```\n\n```python\n# 可以将动态计算图代码的输入和输出关系封装成函数\n\ndef strjoin(x,y):\n    z =  tf.strings.join([x,y],separator = \" \")\n    tf.print(z)\n    return z\n\nresult = strjoin(tf.constant(\"hello\"),tf.constant(\"world\"))\nprint(result)\n```\n\n```\nhello world\ntf.Tensor(b'hello world', shape=(), dtype=string)\n```\n\n\n### 四，TensorFlow2.0的Autograph\n\n\n动态计算图运行效率相对较低。\n\n可以用@tf.function装饰器将普通Python函数转换成和TensorFlow1.0对应的静态计算图构建代码。\n\n在TensorFlow1.0中，使用计算图分两步，第一步定义计算图，第二步在会话中执行计算图。\n\n在TensorFlow2.0中，如果采用Autograph的方式使用计算图，第一步定义计算图变成了定义函数，第二步执行计算图变成了调用函数。\n\n不需要使用会话了，一些都像原始的Python语法一样自然。\n\n实践中，我们一般会先用动态计算图调试代码，然后在需要提高性能的的地方利用@tf.function切换成Autograph获得更高的效率。\n\n当然，@tf.function的使用需要遵循一定的规范，我们后面章节将重点介绍。\n\n\n```python\nimport tensorflow as tf\n\n# 使用autograph构建静态图\n\n@tf.function\ndef strjoin(x,y):\n    z =  tf.strings.join([x,y],separator = \" \")\n    tf.print(z)\n    return z\n\nresult = strjoin(tf.constant(\"hello\"),tf.constant(\"world\"))\n\nprint(result)\n```\n\n```\nhello world\ntf.Tensor(b'hello world', shape=(), dtype=string)\n```\n\n```python\nimport datetime\n\n# 创建日志\nstamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\nlogdir = './data/autograph/%s' % stamp\nwriter = tf.summary.create_file_writer(logdir)\n\n#开启autograph跟踪\ntf.summary.trace_on(graph=True, profiler=True) \n\n#执行autograph\nresult = strjoin(\"hello\",\"world\")\n\n#将计算图信息写入日志\nwith writer.as_default():\n    tf.summary.trace_export(\n        name=\"autograph\",\n        step=0,\n        profiler_outdir=logdir)\n```\n\n```python\n#启动 tensorboard在jupyter中的魔法命令\n%load_ext tensorboard\n```\n\n```python\n#启动tensorboard\n%tensorboard --logdir ./data/autograph/\n```\n\n![](./data/2-2-tensorboard计算图.jpg)\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n\n\n# 2-3,自动微分机制\n\n\n神经网络通常依赖反向传播求梯度来更新网络参数，求梯度过程通常是一件非常复杂而容易出错的事情。\n\n而深度学习框架可以帮助我们自动地完成这种求梯度运算。\n\nTensorflow一般使用梯度磁带tf.GradientTape来记录正向运算过程，然后反播磁带自动得到梯度值。\n\n这种利用tf.GradientTape求微分的方法叫做Tensorflow的自动微分机制。\n\n\n### 一，利用梯度磁带求导数\n\n```python\nimport tensorflow as tf\nimport numpy as np \n\n# f(x) = a*x**2 + b*x + c的导数\n\nx = tf.Variable(0.0,name = \"x\",dtype = tf.float32)\na = tf.constant(1.0)\nb = tf.constant(-2.0)\nc = tf.constant(1.0)\n\nwith tf.GradientTape() as tape:\n    y = a*tf.pow(x,2) + b*x + c\n    \ndy_dx = tape.gradient(y,x)\nprint(dy_dx)\n```\n\n```\ntf.Tensor(-2.0, shape=(), dtype=float32)\n```\n\n```python\n\n```\n\n```python\n# 对常量张量也可以求导，需要增加watch\n\nwith tf.GradientTape() as tape:\n    tape.watch([a,b,c])\n    y = a*tf.pow(x,2) + b*x + c\n    \ndy_dx,dy_da,dy_db,dy_dc = tape.gradient(y,[x,a,b,c])\nprint(dy_da)\nprint(dy_dc)\n\n```\n\n```\ntf.Tensor(0.0, shape=(), dtype=float32)\ntf.Tensor(1.0, shape=(), dtype=float32)\n```\n\n```python\n\n```\n\n```python\n# 可以求二阶导数\nwith tf.GradientTape() as tape2:\n    with tf.GradientTape() as tape1:   \n        y = a*tf.pow(x,2) + b*x + c\n    dy_dx = tape1.gradient(y,x)   \ndy2_dx2 = tape2.gradient(dy_dx,x)\n\nprint(dy2_dx2)\n```\n\n```\ntf.Tensor(2.0, shape=(), dtype=float32)\n```\n\n```python\n\n```\n\n```python\n# 可以在autograph中使用\n\n@tf.function\ndef f(x):   \n    a = tf.constant(1.0)\n    b = tf.constant(-2.0)\n    c = tf.constant(1.0)\n    \n    # 自变量转换成tf.float32\n    x = tf.cast(x,tf.float32)\n    with tf.GradientTape() as tape:\n        tape.watch(x)\n        y = a*tf.pow(x,2)+b*x+c\n    dy_dx = tape.gradient(y,x) \n    \n    return((dy_dx,y))\n\ntf.print(f(tf.constant(0.0)))\ntf.print(f(tf.constant(1.0)))\n```\n\n```\n(-2, 1)\n(0, 0)\n```\n\n```python\n\n```\n\n### 二，利用梯度磁带和优化器求最小值\n\n```python\n# 求f(x) = a*x**2 + b*x + c的最小值\n# 使用optimizer.apply_gradients\n\nx = tf.Variable(0.0,name = \"x\",dtype = tf.float32)\na = tf.constant(1.0)\nb = tf.constant(-2.0)\nc = tf.constant(1.0)\n\noptimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\nfor _ in range(1000):\n    with tf.GradientTape() as tape:\n        y = a*tf.pow(x,2) + b*x + c\n    dy_dx = tape.gradient(y,x)\n    optimizer.apply_gradients(grads_and_vars=[(dy_dx,x)])\n    \ntf.print(\"y =\",y,\"; x =\",x)\n```\n\n```\ny = 0 ; x = 0.999998569\n```\n\n```python\n\n```\n\n```python\n# 求f(x) = a*x**2 + b*x + c的最小值\n# 使用optimizer.minimize\n# optimizer.minimize相当于先用tape求gradient,再apply_gradient\n\nx = tf.Variable(0.0,name = \"x\",dtype = tf.float32)\n\n#注意f()无参数\ndef f():   \n    a = tf.constant(1.0)\n    b = tf.constant(-2.0)\n    c = tf.constant(1.0)\n    y = a*tf.pow(x,2)+b*x+c\n    return(y)\n\noptimizer = tf.keras.optimizers.SGD(learning_rate=0.01)   \nfor _ in range(1000):\n    optimizer.minimize(f,[x])   \n    \ntf.print(\"y =\",f(),\"; x =\",x)\n```\n\n```\ny = 0 ; x = 0.999998569\n```\n\n```python\n\n```\n\n```python\n# 在autograph中完成最小值求解\n# 使用optimizer.apply_gradients\n\nx = tf.Variable(0.0,name = \"x\",dtype = tf.float32)\noptimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n\n@tf.function\ndef minimizef():\n    a = tf.constant(1.0)\n    b = tf.constant(-2.0)\n    c = tf.constant(1.0)\n    \n    for _ in tf.range(1000): #注意autograph时使用tf.range(1000)而不是range(1000)\n        with tf.GradientTape() as tape:\n            y = a*tf.pow(x,2) + b*x + c\n        dy_dx = tape.gradient(y,x)\n        optimizer.apply_gradients(grads_and_vars=[(dy_dx,x)])\n        \n    y = a*tf.pow(x,2) + b*x + c\n    return y\n\ntf.print(minimizef())\ntf.print(x)\n```\n\n```\n0\n0.999998569\n```\n\n```python\n\n```\n\n```python\n# 在autograph中完成最小值求解\n# 使用optimizer.minimize\n\nx = tf.Variable(0.0,name = \"x\",dtype = tf.float32)\noptimizer = tf.keras.optimizers.SGD(learning_rate=0.01)   \n\n@tf.function\ndef f():   \n    a = tf.constant(1.0)\n    b = tf.constant(-2.0)\n    c = tf.constant(1.0)\n    y = a*tf.pow(x,2)+b*x+c\n    return(y)\n\n@tf.function\ndef train(epoch):  \n    for _ in tf.range(epoch):  \n        optimizer.minimize(f,[x])\n    return(f())\n\n\ntf.print(train(1000))\ntf.print(x)\n\n```\n\n```\n0\n0.999998569\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n\n\n# 三、TensorFlow的层次结构\n\n\n本章我们介绍TensorFlow中5个不同的层次结构：即硬件层，内核层，低阶API，中阶API，高阶API。并以线性回归为例，直观对比展示在不同层级实现模型的特点。\n\nTensorFlow的层次结构从低到高可以分成如下五层。\n\n最底层为硬件层，TensorFlow支持CPU、GPU或TPU加入计算资源池。\n\n第二层为C++实现的内核，kernel可以跨平台分布运行。\n\n第三层为Python实现的操作符，提供了封装C++内核的低级API指令，主要包括各种张量操作算子、计算图、自动微分.\n如tf.Variable,tf.constant,tf.function,tf.GradientTape,tf.nn.softmax...\n如果把模型比作一个房子，那么第三层API就是【模型之砖】。\n\n第四层为Python实现的模型组件，对低级API进行了函数封装，主要包括各种模型层，损失函数，优化器，数据管道，特征列等等。\n如tf.keras.layers,tf.keras.losses,tf.keras.metrics,tf.keras.optimizers,tf.data.DataSet,tf.feature_column...\n如果把模型比作一个房子，那么第四层API就是【模型之墙】。\n\n第五层为Python实现的模型成品，一般为按照OOP方式封装的高级API，主要为tf.keras.models提供的模型的类接口。\n如果把模型比作一个房子，那么第五层API就是模型本身，即【模型之屋】。\n\n\n<img src=\"./data/tensorflow_structure.jpg\">\n\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![](./data/Python与算法之美logo.jpg)\n\n\n\n# 3-1,低阶API示范\n\n下面的范例使用TensorFlow的低阶API实现线性回归模型。\n\n低阶API主要包括张量操作，计算图和自动微分。\n\n```python\nimport tensorflow as tf\n\n#打印时间分割线\n@tf.function\ndef printbar():\n    ts = tf.timestamp()\n    today_ts = ts%(24*60*60)\n\n    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\n    minite = tf.cast((today_ts%3600)//60,tf.int32)\n    second = tf.cast(tf.floor(today_ts%60),tf.int32)\n    \n    def timeformat(m):\n        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\n            return(tf.strings.format(\"0{}\",m))\n        else:\n            return(tf.strings.format(\"{}\",m))\n    \n    timestring = tf.strings.join([timeformat(hour),timeformat(minite),\n                timeformat(second)],separator = \":\")\n    tf.print(\"==========\"*8,end = \"\")\n    tf.print(timestring)\n    \n```\n\n```python\n#样本数量\nn = 400\n\n# 生成测试用数据集\nX = tf.random.uniform([n,2],minval=-10,maxval=10) \nw0 = tf.constant([[2.0],[-1.0]])\nb0 = tf.constant(3.0)\nY = X@w0 + b0 + tf.random.normal([n,1],mean = 0.0,stddev= 2.0)  # @表示矩阵乘法,增加正态扰动\n\n```\n\n```python\n#使用动态图调试\n\nw = tf.Variable(tf.random.normal(w0.shape))\nb = tf.Variable(0.0)\n\ndef train(epoches):\n    for epoch in tf.range(1,epoches+1):\n        with tf.GradientTape() as tape:\n            #正向传播求损失\n            Y_hat = X@w + b\n            loss = tf.squeeze(tf.transpose(Y-Y_hat)@(Y-Y_hat))/(2.0*n)   \n\n        # 反向传播求梯度\n        dloss_dw,dloss_db = tape.gradient(loss,[w,b])\n        # 梯度下降法更新参数\n        w.assign(w - 0.001*dloss_dw)\n        b.assign(b - 0.001*dloss_db)\n        if epoch%1000 == 0:\n            printbar()\n            tf.print(\"epoch =\",epoch,\" loss =\",loss,)\n            tf.print(\"w =\",w)\n            tf.print(\"b =\",b)\n            tf.print(\"\")\n            \ntrain(5000)\n```\n\n![](./data/3-1-输出01.jpg)\n\n```python\n##使用autograph机制转换成静态图加速\n\nw = tf.Variable(tf.random.normal(w0.shape))\nb = tf.Variable(0.0)\n\n@tf.function\ndef train(epoches):\n    for epoch in tf.range(1,epoches+1):\n        with tf.GradientTape() as tape:\n            #正向传播求损失\n            Y_hat = X@w + b\n            loss = tf.squeeze(tf.transpose(Y-Y_hat)@(Y-Y_hat))/(2.0*n)   \n\n        # 反向传播求梯度\n        dloss_dw,dloss_db = tape.gradient(loss,[w,b])\n        # 梯度下降法更新参数\n        w.assign(w - 0.001*dloss_dw)\n        b.assign(b - 0.001*dloss_db)\n        if epoch%1000 == 0:\n            printbar()\n            tf.print(\"epoch =\",epoch,\" loss =\",loss,)\n            tf.print(\"w =\",w)\n            tf.print(\"b =\",b)\n            tf.print(\"\")\ntrain(5000)\n```\n\n![](./data/3-1-输出02.jpg)\n\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n\n\n# 3-2,中阶API示范\n\n下面的范例使用TensorFlow的中阶API实现线性回归模型。\n\nTensorFlow的中阶API主要包括各种模型层，损失函数，优化器，数据管道，特征列等等。\n\n```python\nimport tensorflow as tf\nfrom tensorflow.keras import layers,losses,metrics,optimizers\n\n\n#打印时间分割线\n@tf.function\ndef printbar():\n    ts = tf.timestamp()\n    today_ts = ts%(24*60*60)\n\n    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\n    minite = tf.cast((today_ts%3600)//60,tf.int32)\n    second = tf.cast(tf.floor(today_ts%60),tf.int32)\n    \n    def timeformat(m):\n        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\n            return(tf.strings.format(\"0{}\",m))\n        else:\n            return(tf.strings.format(\"{}\",m))\n    \n    timestring = tf.strings.join([timeformat(hour),timeformat(minite),\n                timeformat(second)],separator = \":\")\n    tf.print(\"==========\"*8,end = \"\")\n    tf.print(timestring)\n    \n```\n\n```python\n#样本数量\nn = 800\n\n# 生成测试用数据集\nX = tf.random.uniform([n,2],minval=-10,maxval=10) \nw0 = tf.constant([[2.0],[-1.0]])\nb0 = tf.constant(3.0)\nY = X@w0 + b0 + tf.random.normal([n,1],mean = 0.0,stddev= 2.0)  # @表示矩阵乘法,增加正态扰动\n\n#构建输入数据管道\nds = tf.data.Dataset.from_tensor_slices((X,Y)) \\\n     .shuffle(buffer_size = 1000).batch(100) \\\n     .prefetch(tf.data.experimental.AUTOTUNE)  \n\n#定义优化器\noptimizer = optimizers.SGD(learning_rate=0.001)\n\n```\n\n```python\nlinear = layers.Dense(units = 1)\nlinear.build(input_shape = (2,)) \n\n@tf.function\ndef train(epoches):\n    for epoch in tf.range(1,epoches+1):\n        L = tf.constant(0.0) #使用L记录loss值\n        for X_batch,Y_batch in ds:\n            with tf.GradientTape() as tape:\n                Y_hat = linear(X_batch)\n                loss = losses.mean_squared_error(tf.reshape(Y_hat,[-1]),tf.reshape(Y_batch,[-1]))\n            grads = tape.gradient(loss,linear.variables)\n            optimizer.apply_gradients(zip(grads,linear.variables))\n            L = loss\n        \n        if(epoch%100==0):\n            printbar()\n            tf.print(\"epoch =\",epoch,\"loss =\",L)\n            tf.print(\"w =\",linear.kernel)\n            tf.print(\"b =\",linear.bias)\n            tf.print(\"\")\n\ntrain(500)\n```\n\n![](./data/3-2-输出01.jpg)\n\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n\n\n# 3-3,高阶API示范\n\n下面的范例使用TensorFlow的高阶API实现线性回归模型。\n\nTensorFlow的高阶API主要为tf.keras.models提供的模型的类接口。\n\n\n使用Keras接口有以下3种方式构建模型：使用Sequential按层顺序构建模型，使用函数式API构建任意结构模型，继承Model基类构建自定义模型。\n\n此处分别演示使用Sequential按层顺序构建模型以及继承Model基类构建自定义模型。\n\n\n### 一，使用Sequential按层顺序构建模型【面向新手】\n\n```python\nimport tensorflow as tf\nfrom tensorflow.keras import models,layers,optimizers\n\n#样本数量\nn = 800\n\n# 生成测试用数据集\nX = tf.random.uniform([n,2],minval=-10,maxval=10) \nw0 = tf.constant([[2.0],[-1.0]])\nb0 = tf.constant(3.0)\n\nY = X@w0 + b0 + tf.random.normal([n,1],mean = 0.0,stddev= 2.0)  # @表示矩阵乘法,增加正态扰动\n```\n\n```python\ntf.keras.backend.clear_session()\n\nlinear = models.Sequential()\nlinear.add(layers.Dense(1,input_shape =(2,)))\nlinear.summary()\n```\n\n![](./data/3-3-序列结构.jpg)\n\n```python\n### 使用fit方法进行训练\n\nlinear.compile(optimizer=\"adam\",loss=\"mse\",metrics=[\"mae\"])\nlinear.fit(X,Y,batch_size = 20,epochs = 200)  \n\ntf.print(\"w = \",linear.layers[0].kernel)\ntf.print(\"b = \",linear.layers[0].bias)\n\n```\n\n![](./data/3-3-内置训练.jpg)\n\n```python\n\n```\n\n### 二，继承Model基类构建自定义模型【面向专家】\n\n```python\nimport tensorflow as tf\nfrom tensorflow.keras import models,layers,optimizers,losses,metrics\n\n\n#打印时间分割线\n@tf.function\ndef printbar():\n    ts = tf.timestamp()\n    today_ts = ts%(24*60*60)\n\n    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\n    minite = tf.cast((today_ts%3600)//60,tf.int32)\n    second = tf.cast(tf.floor(today_ts%60),tf.int32)\n    \n    def timeformat(m):\n        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\n            return(tf.strings.format(\"0{}\",m))\n        else:\n            return(tf.strings.format(\"{}\",m))\n    \n    timestring = tf.strings.join([timeformat(hour),timeformat(minite),\n                timeformat(second)],separator = \":\")\n    tf.print(\"==========\"*8,end = \"\")\n    tf.print(timestring)\n    \n```\n\n```python\n#样本数量\nn = 800\n\n# 生成测试用数据集\nX = tf.random.uniform([n,2],minval=-10,maxval=10) \nw0 = tf.constant([[2.0],[-1.0]])\nb0 = tf.constant(3.0)\n\nY = X@w0 + b0 + tf.random.normal([n,1],mean = 0.0,stddev= 2.0)  # @表示矩阵乘法,增加正态扰动\n\nds_train = tf.data.Dataset.from_tensor_slices((X[0:n*3//4,:],Y[0:n*3//4,:])) \\\n     .shuffle(buffer_size = 1000).batch(20) \\\n     .prefetch(tf.data.experimental.AUTOTUNE) \\\n     .cache()\n\nds_valid = tf.data.Dataset.from_tensor_slices((X[n*3//4:,:],Y[n*3//4:,:])) \\\n     .shuffle(buffer_size = 1000).batch(20) \\\n     .prefetch(tf.data.experimental.AUTOTUNE) \\\n     .cache()\n\n```\n\n```python\ntf.keras.backend.clear_session()\n\nclass MyModel(models.Model):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        \n    def build(self,input_shape):\n        self.dense1 = layers.Dense(1)   \n        super(MyModel,self).build(input_shape)\n    \n    def call(self, x):\n        y = self.dense1(x)\n        return(y)\n\nmodel = MyModel()\nmodel.build(input_shape =(None,2))\nmodel.summary()\n\n```\n\n![](./data/3-3-模型结构.jpg)\n\n```python\n### 自定义训练循环(专家教程)\n\n\noptimizer = optimizers.Adam()\nloss_func = losses.MeanSquaredError()\n\ntrain_loss = tf.keras.metrics.Mean(name='train_loss')\ntrain_metric = tf.keras.metrics.MeanAbsoluteError(name='train_mae')\n\nvalid_loss = tf.keras.metrics.Mean(name='valid_loss')\nvalid_metric = tf.keras.metrics.MeanAbsoluteError(name='valid_mae')\n\n\n@tf.function\ndef train_step(model, features, labels):\n    with tf.GradientTape() as tape:\n        predictions = model(features)\n        loss = loss_func(labels, predictions)\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n    train_loss.update_state(loss)\n    train_metric.update_state(labels, predictions)\n\n@tf.function\ndef valid_step(model, features, labels):\n    predictions = model(features)\n    batch_loss = loss_func(labels, predictions)\n    valid_loss.update_state(batch_loss)\n    valid_metric.update_state(labels, predictions)\n    \n\n@tf.function\ndef train_model(model,ds_train,ds_valid,epochs):\n    for epoch in tf.range(1,epochs+1):\n        for features, labels in ds_train:\n            train_step(model,features,labels)\n\n        for features, labels in ds_valid:\n            valid_step(model,features,labels)\n\n        logs = 'Epoch={},Loss:{},MAE:{},Valid Loss:{},Valid MAE:{}'\n        \n        if  epoch%100 ==0:\n            printbar()\n            tf.print(tf.strings.format(logs,\n            (epoch,train_loss.result(),train_metric.result(),valid_loss.result(),valid_metric.result())))\n            tf.print(\"w=\",model.layers[0].kernel)\n            tf.print(\"b=\",model.layers[0].bias)\n            tf.print(\"\")\n        \n        train_loss.reset_states()\n        valid_loss.reset_states()\n        train_metric.reset_states()\n        valid_metric.reset_states()\n\ntrain_model(model,ds_train,ds_valid,400)\n\n```\n\n![](./data/3-3-自定义训练.jpg)\n\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n\n\n# 四、TensorFlow的低阶API\n\nTensorFlow的低阶API主要包括张量操作，计算图和自动微分。\n\n如果把模型比作一个房子，那么低阶API就是【模型之砖】。\n\n在低阶API层次上，可以把TensorFlow当做一个增强版的numpy来使用。\n\nTensorFlow提供的方法比numpy更全面，运算速度更快，如果需要的话，还可以使用GPU进行加速。\n\n前面几章我们对低阶API已经有了一个整体的认识，本章我们将重点详细介绍张量操作和Autograph计算图。\n\n\n张量的操作主要包括张量的结构操作和张量的数学运算。\n\n张量结构操作诸如：张量创建，索引切片，维度变换，合并分割。\n\n张量数学运算主要有：标量运算，向量运算，矩阵运算。另外我们会介绍张量运算的广播机制。\n\nAutograph计算图我们将介绍使用Autograph的规范建议，Autograph的机制原理，Autograph和tf.Module.\n\n\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![](./data/Python与算法之美logo.jpg)\n\n\n\n# 4-1,张量的结构操作\n\n张量的操作主要包括张量的结构操作和张量的数学运算。\n\n张量结构操作诸如：张量创建，索引切片，维度变换，合并分割。\n\n张量数学运算主要有：标量运算，向量运算，矩阵运算。另外我们会介绍张量运算的广播机制。\n\n本篇我们介绍张量的结构操作。\n\n\n### 一，创建张量\n\n\n张量创建的许多方法和numpy中创建array的方法很像。\n\n```python\nimport tensorflow as tf\nimport numpy as np \n```\n\n```python\na = tf.constant([1,2,3],dtype = tf.float32)\ntf.print(a)\n```\n\n```\n[1 2 3]\n```\n\n```python\nb = tf.range(1,10,delta = 2)\ntf.print(b)\n```\n\n```\n[1 3 5 7 9]\n```\n\n```python\nc = tf.linspace(0.0,2*3.14,100)\ntf.print(c)\n```\n\n```\n[0 0.0634343475 0.126868695 ... 6.15313148 6.21656609 6.28]\n```\n\n```python\nd = tf.zeros([3,3])\ntf.print(d)\n```\n\n```\n[[0 0 0]\n [0 0 0]\n [0 0 0]]\n```\n\n```python\na = tf.ones([3,3])\nb = tf.zeros_like(a,dtype= tf.float32)\ntf.print(a)\ntf.print(b)\n```\n\n```\n[[1 1 1]\n [1 1 1]\n [1 1 1]]\n[[0 0 0]\n [0 0 0]\n [0 0 0]]\n```\n\n```python\nb = tf.fill([3,2],5)\ntf.print(b)\n```\n\n```\n[[5 5]\n [5 5]\n [5 5]]\n```\n\n```python\n#均匀分布随机\ntf.random.set_seed(1.0)\na = tf.random.uniform([5],minval=0,maxval=10)\ntf.print(a)\n```\n\n```\n[1.65130854 9.01481247 6.30974197 4.34546089 2.9193902]\n```\n\n```python\n#正态分布随机\nb = tf.random.normal([3,3],mean=0.0,stddev=1.0)\ntf.print(b)\n```\n\n```\n[[0.403087884 -1.0880208 -0.0630953535]\n [1.33655667 0.711760104 -0.489286453]\n [-0.764221311 -1.03724861 -1.25193381]]\n```\n\n```python\n#正态分布随机，剔除2倍方差以外数据重新生成\nc = tf.random.truncated_normal((5,5), mean=0.0, stddev=1.0, dtype=tf.float32)\ntf.print(c)\n```\n\n```\n[[-0.457012236 -0.406867266 0.728577733 -0.892977774 -0.369404584]\n [0.323488563 1.19383323 0.888299048 1.25985599 -1.95951891]\n [-0.202244401 0.294496894 -0.468728036 1.29494202 1.48142183]\n [0.0810953453 1.63843894 0.556645 0.977199793 -1.17777884]\n [1.67368948 0.0647980496 -0.705142677 -0.281972528 0.126546144]]\n```\n\n```python\n# 特殊矩阵\nI = tf.eye(3,3) #单位矩阵\ntf.print(I)\ntf.print(\" \")\nt = tf.linalg.diag([1,2,3]) #对角阵\ntf.print(t)\n```\n\n```\n[[1 0 0]\n [0 1 0]\n [0 0 1]]\n \n[[1 0 0]\n [0 2 0]\n [0 0 3]]\n```\n\n```python\n\n```\n\n### 二 ，索引切片\n\n\n张量的索引切片方式和numpy几乎是一样的。切片时支持缺省参数和省略号。\n\n对于tf.Variable,可以通过索引和切片对部分元素进行修改。\n\n对于提取张量的连续子区域，也可以使用tf.slice.\n\n此外，对于不规则的切片提取,可以使用tf.gather,tf.gather_nd,tf.boolean_mask。\n\ntf.boolean_mask功能最为强大，它可以实现tf.gather,tf.gather_nd的功能，并且tf.boolean_mask还可以实现布尔索引。\n\n如果要通过修改张量的某些元素得到新的张量，可以使用tf.where，tf.scatter_nd。\n\n```python\ntf.random.set_seed(3)\nt = tf.random.uniform([5,5],minval=0,maxval=10,dtype=tf.int32)\ntf.print(t)\n```\n\n```\n[[4 7 4 2 9]\n [9 1 2 4 7]\n [7 2 7 4 0]\n [9 6 9 7 2]\n [3 7 0 0 3]]\n```\n\n```python\n#第0行\ntf.print(t[0])\n```\n\n```\n[4 7 4 2 9]\n```\n\n```python\n#倒数第一行\ntf.print(t[-1])\n```\n\n```\n[3 7 0 0 3]\n```\n\n```python\n#第1行第3列\ntf.print(t[1,3])\ntf.print(t[1][3])\n```\n\n```\n4\n4\n```\n\n```python\n#第1行至第3行\ntf.print(t[1:4,:])\ntf.print(tf.slice(t,[1,0],[3,5])) #tf.slice(input,begin_vector,size_vector)\n```\n\n```\n[[9 1 2 4 7]\n [7 2 7 4 0]\n [9 6 9 7 2]]\n[[9 1 2 4 7]\n [7 2 7 4 0]\n [9 6 9 7 2]]\n```\n\n```python\n#第1行至最后一行，第0列到最后一列每隔两列取一列\ntf.print(t[1:4,:4:2])\n```\n\n```\n[[9 2]\n [7 7]\n [9 9]]\n```\n\n```python\n#对变量来说，还可以使用索引和切片修改部分元素\nx = tf.Variable([[1,2],[3,4]],dtype = tf.float32)\nx[1,:].assign(tf.constant([0.0,0.0]))\ntf.print(x)\n```\n\n```\n[[1 2]\n [0 0]]\n```\n\n```python\na = tf.random.uniform([3,3,3],minval=0,maxval=10,dtype=tf.int32)\ntf.print(a)\n```\n\n```\n[[[7 3 9]\n  [9 0 7]\n  [9 6 7]]\n\n [[1 3 3]\n  [0 8 1]\n  [3 1 0]]\n\n [[4 0 6]\n  [6 2 2]\n  [7 9 5]]]\n```\n\n```python\n#省略号可以表示多个冒号\ntf.print(a[...,1])\n```\n\n```\n[[3 0 6]\n [3 8 1]\n [0 2 9]]\n```\n\n\n以上切片方式相对规则，对于不规则的切片提取,可以使用tf.gather,tf.gather_nd,tf.boolean_mask。\n\n考虑班级成绩册的例子，有4个班级，每个班级10个学生，每个学生7门科目成绩。可以用一个4*10*7的张量来表示。\n\n```python\nscores = tf.random.uniform((4,10,7),minval=0,maxval=100,dtype=tf.int32)\ntf.print(scores)\n```\n\n```\n[[[52 82 66 ... 17 86 14]\n  [8 36 94 ... 13 78 41]\n  [77 53 51 ... 22 91 56]\n  ...\n  [11 19 26 ... 89 86 68]\n  [60 72 0 ... 11 26 15]\n  [24 99 38 ... 97 44 74]]\n\n [[79 73 73 ... 35 3 81]\n  [83 36 31 ... 75 38 85]\n  [54 26 67 ... 60 68 98]\n  ...\n  [20 5 18 ... 32 45 3]\n  [72 52 81 ... 88 41 20]\n  [0 21 89 ... 53 10 90]]\n\n [[52 80 22 ... 29 25 60]\n  [78 71 54 ... 43 98 81]\n  [21 66 53 ... 97 75 77]\n  ...\n  [6 74 3 ... 53 65 43]\n  [98 36 72 ... 33 36 81]\n  [61 78 70 ... 7 59 21]]\n\n [[56 57 45 ... 23 15 3]\n  [35 8 82 ... 11 59 97]\n  [44 6 99 ... 81 60 27]\n  ...\n  [76 26 35 ... 51 8 17]\n  [33 52 53 ... 78 37 31]\n  [71 27 44 ... 0 52 16]]]\n```\n\n```python\n#抽取每个班级第0个学生，第5个学生，第9个学生的全部成绩\np = tf.gather(scores,[0,5,9],axis=1)\ntf.print(p)\n```\n\n```\n[[[52 82 66 ... 17 86 14]\n  [24 80 70 ... 72 63 96]\n  [24 99 38 ... 97 44 74]]\n\n [[79 73 73 ... 35 3 81]\n  [46 10 94 ... 23 18 92]\n  [0 21 89 ... 53 10 90]]\n\n [[52 80 22 ... 29 25 60]\n  [19 12 23 ... 87 86 25]\n  [61 78 70 ... 7 59 21]]\n\n [[56 57 45 ... 23 15 3]\n  [6 41 79 ... 97 43 13]\n  [71 27 44 ... 0 52 16]]]\n```\n\n```python\n#抽取每个班级第0个学生，第5个学生，第9个学生的第1门课程，第3门课程，第6门课程成绩\nq = tf.gather(tf.gather(scores,[0,5,9],axis=1),[1,3,6],axis=2)\ntf.print(q)\n```\n\n```\n[[[82 55 14]\n  [80 46 96]\n  [99 58 74]]\n\n [[73 48 81]\n  [10 38 92]\n  [21 86 90]]\n\n [[80 57 60]\n  [12 34 25]\n  [78 71 21]]\n\n [[57 75 3]\n  [41 47 13]\n  [27 96 16]]]\n```\n\n```python\n# 抽取第0个班级第0个学生，第2个班级的第4个学生，第3个班级的第6个学生的全部成绩\n#indices的长度为采样样本的个数，每个元素为采样位置的坐标\ns = tf.gather_nd(scores,indices = [(0,0),(2,4),(3,6)])\ns\n```\n\n```\n<tf.Tensor: shape=(3, 7), dtype=int32, numpy=\narray([[52, 82, 66, 55, 17, 86, 14],\n       [99, 94, 46, 70,  1, 63, 41],\n       [46, 83, 70, 80, 90, 85, 17]], dtype=int32)>\n```\n\n\n以上tf.gather和tf.gather_nd的功能也可以用tf.boolean_mask来实现。\n\n```python\n#抽取每个班级第0个学生，第5个学生，第9个学生的全部成绩\np = tf.boolean_mask(scores,[True,False,False,False,False,\n                            True,False,False,False,True],axis=1)\ntf.print(p)\n```\n\n```\n[[[52 82 66 ... 17 86 14]\n  [24 80 70 ... 72 63 96]\n  [24 99 38 ... 97 44 74]]\n\n [[79 73 73 ... 35 3 81]\n  [46 10 94 ... 23 18 92]\n  [0 21 89 ... 53 10 90]]\n\n [[52 80 22 ... 29 25 60]\n  [19 12 23 ... 87 86 25]\n  [61 78 70 ... 7 59 21]]\n\n [[56 57 45 ... 23 15 3]\n  [6 41 79 ... 97 43 13]\n  [71 27 44 ... 0 52 16]]]\n```\n\n```python\n#抽取第0个班级第0个学生，第2个班级的第4个学生，第3个班级的第6个学生的全部成绩\ns = tf.boolean_mask(scores,\n    [[True,False,False,False,False,False,False,False,False,False],\n     [False,False,False,False,False,False,False,False,False,False],\n     [False,False,False,False,True,False,False,False,False,False],\n     [False,False,False,False,False,False,True,False,False,False]])\ntf.print(s)\n```\n\n```\n[[52 82 66 ... 17 86 14]\n [99 94 46 ... 1 63 41]\n [46 83 70 ... 90 85 17]]\n```\n\n```python\n#利用tf.boolean_mask可以实现布尔索引\n\n#找到矩阵中小于0的元素\nc = tf.constant([[-1,1,-1],[2,2,-2],[3,-3,3]],dtype=tf.float32)\ntf.print(c,\"\\n\")\n\ntf.print(tf.boolean_mask(c,c<0),\"\\n\") \ntf.print(c[c<0]) #布尔索引，为boolean_mask的语法糖形式\n```\n\n```\n[[-1 1 -1]\n [2 2 -2]\n [3 -3 3]] \n\n[-1 -1 -2 -3] \n\n[-1 -1 -2 -3]\n```\n\n```python\n\n```\n\n以上这些方法仅能提取张量的部分元素值，但不能更改张量的部分元素值得到新的张量。\n\n如果要通过修改张量的部分元素值得到新的张量，可以使用tf.where和tf.scatter_nd。\n\ntf.where可以理解为if的张量版本，此外它还可以用于找到满足条件的所有元素的位置坐标。\n\ntf.scatter_nd的作用和tf.gather_nd有些相反，tf.gather_nd用于收集张量的给定位置的元素，\n\n而tf.scatter_nd可以将某些值插入到一个给定shape的全0的张量的指定位置处。\n\n```python\n#找到张量中小于0的元素,将其换成np.nan得到新的张量\n#tf.where和np.where作用类似，可以理解为if的张量版本\n\nc = tf.constant([[-1,1,-1],[2,2,-2],[3,-3,3]],dtype=tf.float32)\nd = tf.where(c<0,tf.fill(c.shape,np.nan),c) \nd\n```\n\n```\n<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\narray([[nan,  1., nan],\n       [ 2.,  2., nan],\n       [ 3., nan,  3.]], dtype=float32)>\n```\n\n```python\n\n```\n\n```python\n#如果where只有一个参数，将返回所有满足条件的位置坐标\nindices = tf.where(c<0)\nindices\n```\n\n```\n<tf.Tensor: shape=(4, 2), dtype=int64, numpy=\narray([[0, 0],\n       [0, 2],\n       [1, 2],\n       [2, 1]])>\n```\n\n```python\n#将张量的第[0,0]和[2,1]两个位置元素替换为0得到新的张量\nd = c - tf.scatter_nd([[0,0],[2,1]],[c[0,0],c[2,1]],c.shape)\nd\n```\n\n```\n<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\narray([[ 0.,  1., -1.],\n       [ 2.,  2., -2.],\n       [ 3.,  0.,  3.]], dtype=float32)>\n\n```\n\n```python\n#scatter_nd的作用和gather_nd有些相反\n#可以将某些值插入到一个给定shape的全0的张量的指定位置处。\nindices = tf.where(c<0)\ntf.scatter_nd(indices,tf.gather_nd(c,indices),c.shape)\n```\n\n```\n<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\narray([[-1.,  0., -1.],\n       [ 0.,  0., -2.],\n       [ 0., -3.,  0.]], dtype=float32)>\n```\n\n```python\n\n```\n\n### 三，维度变换\n\n\n维度变换相关函数主要有 tf.reshape, tf.squeeze, tf.expand_dims, tf.transpose.\n\ntf.reshape 可以改变张量的形状。\n\ntf.squeeze 可以减少维度。\n\ntf.expand_dims 可以增加维度。\n\ntf.transpose 可以交换维度。\n\n\n\ntf.reshape可以改变张量的形状，但是其本质上不会改变张量元素的存储顺序，所以，该操作实际上非常迅速，并且是可逆的。\n\n```python\na = tf.random.uniform(shape=[1,3,3,2],\n                      minval=0,maxval=255,dtype=tf.int32)\ntf.print(a.shape)\ntf.print(a)\n```\n\n```\nTensorShape([1, 3, 3, 2])\n[[[[135 178]\n   [26 116]\n   [29 224]]\n\n  [[179 219]\n   [153 209]\n   [111 215]]\n\n  [[39 7]\n   [138 129]\n   [59 205]]]]\n```\n\n```python\n# 改成 （3,6）形状的张量\nb = tf.reshape(a,[3,6])\ntf.print(b.shape)\ntf.print(b)\n```\n\n```\nTensorShape([3, 6])\n[[135 178 26 116 29 224]\n [179 219 153 209 111 215]\n [39 7 138 129 59 205]]\n```\n\n\n\n\n```python\n# 改回成 [1,3,3,2] 形状的张量\nc = tf.reshape(b,[1,3,3,2])\ntf.print(c)\n```\n\n```\n[[[[135 178]\n   [26 116]\n   [29 224]]\n\n  [[179 219]\n   [153 209]\n   [111 215]]\n\n  [[39 7]\n   [138 129]\n   [59 205]]]]\n```\n\n```python\n\n```\n\n如果张量在某个维度上只有一个元素，利用tf.squeeze可以消除这个维度。\n\n和tf.reshape相似，它本质上不会改变张量元素的存储顺序。\n\n张量的各个元素在内存中是线性存储的，其一般规律是，同一层级中的相邻元素的物理地址也相邻。\n\n```python\ns = tf.squeeze(a)\ntf.print(s.shape)\ntf.print(s)\n```\n\n```\nTensorShape([3, 3, 2])\n[[[135 178]\n  [26 116]\n  [29 224]]\n\n [[179 219]\n  [153 209]\n  [111 215]]\n\n [[39 7]\n  [138 129]\n  [59 205]]]\n```\n\n```python\nd = tf.expand_dims(s,axis=0) #在第0维插入长度为1的一个维度\nd\n```\n\n```\n<tf.Tensor: shape=(1, 3, 3, 2), dtype=int32, numpy=\narray([[[[135, 178],\n         [ 26, 116],\n         [ 29, 224]],\n\n        [[179, 219],\n         [153, 209],\n         [111, 215]],\n\n        [[ 39,   7],\n         [138, 129],\n         [ 59, 205]]]], dtype=int32)>\n```\n\n\ntf.transpose可以交换张量的维度，与tf.reshape不同，它会改变张量元素的存储顺序。\n\ntf.transpose常用于图片存储格式的变换上。\n\n```python\n# Batch,Height,Width,Channel\na = tf.random.uniform(shape=[100,600,600,4],minval=0,maxval=255,dtype=tf.int32)\ntf.print(a.shape)\n\n# 转换成 Channel,Height,Width,Batch\ns= tf.transpose(a,perm=[3,1,2,0])\ntf.print(s.shape)\n```\n\n```\nTensorShape([100, 600, 600, 4])\nTensorShape([4, 600, 600, 100])\n\n```\n\n```python\n\n```\n\n### 四，合并分割\n\n\n和numpy类似，可以用tf.concat和tf.stack方法对多个张量进行合并，可以用tf.split方法把一个张量分割成多个张量。\n\ntf.concat和tf.stack有略微的区别，tf.concat是连接，不会增加维度，而tf.stack是堆叠，会增加维度。\n\n```python\na = tf.constant([[1.0,2.0],[3.0,4.0]])\nb = tf.constant([[5.0,6.0],[7.0,8.0]])\nc = tf.constant([[9.0,10.0],[11.0,12.0]])\n\ntf.concat([a,b,c],axis = 0)\n```\n\n```\n<tf.Tensor: shape=(6, 2), dtype=float32, numpy=\narray([[ 1.,  2.],\n       [ 3.,  4.],\n       [ 5.,  6.],\n       [ 7.,  8.],\n       [ 9., 10.],\n       [11., 12.]], dtype=float32)>\n```\n\n```python\ntf.concat([a,b,c],axis = 1)\n```\n\n```\n<tf.Tensor: shape=(2, 6), dtype=float32, numpy=\narray([[ 1.,  2.,  5.,  6.,  9., 10.],\n       [ 3.,  4.,  7.,  8., 11., 12.]], dtype=float32)>\n```\n\n```python\ntf.stack([a,b,c])\n```\n\n```\n<tf.Tensor: shape=(3, 2, 2), dtype=float32, numpy=\narray([[[ 1.,  2.],\n        [ 3.,  4.]],\n\n       [[ 5.,  6.],\n        [ 7.,  8.]],\n\n       [[ 9., 10.],\n        [11., 12.]]], dtype=float32)>\n```\n\n```python\ntf.stack([a,b,c],axis=1)\n```\n\n```\n<tf.Tensor: shape=(2, 3, 2), dtype=float32, numpy=\narray([[[ 1.,  2.],\n        [ 5.,  6.],\n        [ 9., 10.]],\n\n       [[ 3.,  4.],\n        [ 7.,  8.],\n        [11., 12.]]], dtype=float32)>\n```\n\n```python\na = tf.constant([[1.0,2.0],[3.0,4.0]])\nb = tf.constant([[5.0,6.0],[7.0,8.0]])\nc = tf.constant([[9.0,10.0],[11.0,12.0]])\n\nc = tf.concat([a,b,c],axis = 0)\n```\n\ntf.split是tf.concat的逆运算，可以指定分割份数平均分割，也可以通过指定每份的记录数量进行分割。\n\n```python\n#tf.split(value,num_or_size_splits,axis)\ntf.split(c,3,axis = 0)  #指定分割份数，平均分割\n```\n\n```\n[<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n array([[1., 2.],\n        [3., 4.]], dtype=float32)>,\n <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n array([[5., 6.],\n        [7., 8.]], dtype=float32)>,\n <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n array([[ 9., 10.],\n        [11., 12.]], dtype=float32)>]\n```\n\n```python\ntf.split(c,[2,2,2],axis = 0) #指定每份的记录数量\n```\n\n```\n[<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n array([[1., 2.],\n        [3., 4.]], dtype=float32)>,\n <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n array([[5., 6.],\n        [7., 8.]], dtype=float32)>,\n <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n array([[ 9., 10.],\n        [11., 12.]], dtype=float32)>]\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n\n\n# 4-2,张量的数学运算\n\n张量的操作主要包括张量的结构操作和张量的数学运算。\n\n张量结构操作诸如：张量创建，索引切片，维度变换，合并分割。\n\n张量数学运算主要有：标量运算，向量运算，矩阵运算。另外我们会介绍张量运算的广播机制。\n\n本篇我们介绍张量的数学运算。\n\n```python\n\n```\n\n### 一，标量运算\n\n\n张量的数学运算符可以分为标量运算符、向量运算符、以及矩阵运算符。\n\n加减乘除乘方，以及三角函数，指数，对数等常见函数，逻辑比较运算符等都是标量运算符。\n\n标量运算符的特点是对张量实施逐元素运算。\n\n有些标量运算符对常用的数学运算符进行了重载。并且支持类似numpy的广播特性。\n\n许多标量运算符都在 tf.math模块下。\n\n```python\nimport tensorflow as tf \nimport numpy as np \n```\n\n```python\na = tf.constant([[1.0,2],[-3,4.0]])\nb = tf.constant([[5.0,6],[7.0,8.0]])\na+b  #运算符重载\n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[ 6.,  8.],\n       [ 4., 12.]], dtype=float32)>\n```\n\n```python\na-b \n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[ -4.,  -4.],\n       [-10.,  -4.]], dtype=float32)>\n```\n\n```python\na*b \n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[  5.,  12.],\n       [-21.,  32.]], dtype=float32)>\n```\n\n```python\na/b\n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[ 0.2       ,  0.33333334],\n       [-0.42857143,  0.5       ]], dtype=float32)>\n```\n\n```python\na**2\n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[ 1.,  4.],\n       [ 9., 16.]], dtype=float32)>\n```\n\n```python\na**(0.5)\n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[1.       , 1.4142135],\n       [      nan, 2.       ]], dtype=float32)>\n```\n\n```python\na%3 #mod的运算符重载，等价于m = tf.math.mod(a,3)\n```\n\n```\n<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 0], dtype=int32)>\n```\n\n```python\na//3  #地板除法\n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[ 0.,  0.],\n       [-1.,  1.]], dtype=float32)>\n```\n\n```python\n(a>=2)\n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=bool, numpy=\narray([[False,  True],\n       [False,  True]])>\n```\n\n```python\n(a>=2)&(a<=3)\n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=bool, numpy=\narray([[False,  True],\n       [False, False]])>\n```\n\n```python\n(a>=2)|(a<=3)\n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=bool, numpy=\narray([[ True,  True],\n       [ True,  True]])>\n```\n\n```python\na==5 #tf.equal(a,5)\n```\n\n```\n<tf.Tensor: shape=(3,), dtype=bool, numpy=array([False, False, False])>\n```\n\n```python\ntf.sqrt(a)\n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[1.       , 1.4142135],\n       [      nan, 2.       ]], dtype=float32)>\n```\n\n```python\na = tf.constant([1.0,8.0])\nb = tf.constant([5.0,6.0])\nc = tf.constant([6.0,7.0])\ntf.add_n([a,b,c])\n```\n\n```\n<tf.Tensor: shape=(2,), dtype=float32, numpy=array([12., 21.], dtype=float32)>\n```\n\n```python\ntf.print(tf.maximum(a,b))\n```\n\n```\n[5 8]\n```\n\n```python\ntf.print(tf.minimum(a,b))\n```\n\n```\n[1 6]\n```\n\n```python\n\n```\n\n### 二，向量运算\n\n\n向量运算符只在一个特定轴上运算，将一个向量映射到一个标量或者另外一个向量。\n许多向量运算符都以reduce开头。\n\n```python\n#向量reduce\na = tf.range(1,10)\ntf.print(tf.reduce_sum(a))\ntf.print(tf.reduce_mean(a))\ntf.print(tf.reduce_max(a))\ntf.print(tf.reduce_min(a))\ntf.print(tf.reduce_prod(a))\n```\n\n```\n45\n5\n9\n1\n362880\n```\n\n```python\n#张量指定维度进行reduce\nb = tf.reshape(a,(3,3))\ntf.print(tf.reduce_sum(b, axis=1, keepdims=True))\ntf.print(tf.reduce_sum(b, axis=0, keepdims=True))\n```\n\n```\n[[6]\n [15]\n [24]]\n[[12 15 18]]\n```\n\n```python\n#bool类型的reduce\np = tf.constant([True,False,False])\nq = tf.constant([False,False,True])\ntf.print(tf.reduce_all(p))\ntf.print(tf.reduce_any(q))\n```\n\n```\n0\n1\n```\n\n```python\n#利用tf.foldr实现tf.reduce_sum\ns = tf.foldr(lambda a,b:a+b,tf.range(10)) \ntf.print(s)\n```\n\n```\n45\n```\n\n```python\n#cum扫描累积\na = tf.range(1,10)\ntf.print(tf.math.cumsum(a))\ntf.print(tf.math.cumprod(a))\n```\n\n```\n[1 3 6 ... 28 36 45]\n[1 2 6 ... 5040 40320 362880]\n```\n\n```python\n#arg最大最小值索引\na = tf.range(1,10)\ntf.print(tf.argmax(a))\ntf.print(tf.argmin(a))\n```\n\n```\n8\n0\n```\n\n```python\n#tf.math.top_k可以用于对张量排序\na = tf.constant([1,3,7,5,4,8])\n\nvalues,indices = tf.math.top_k(a,3,sorted=True)\ntf.print(values)\ntf.print(indices)\n\n#利用tf.math.top_k可以在TensorFlow中实现KNN算法\n```\n\n```\n[8 7 5]\n[5 2 3]\n```\n\n```python\n\n```\n\n### 三，矩阵运算\n\n\n矩阵必须是二维的。类似tf.constant([1,2,3])这样的不是矩阵。\n\n矩阵运算包括：矩阵乘法，矩阵转置，矩阵逆，矩阵求迹，矩阵范数，矩阵行列式，矩阵求特征值，矩阵分解等运算。\n\n除了一些常用的运算外，大部分和矩阵有关的运算都在tf.linalg子包中。\n\n```python\n#矩阵乘法\na = tf.constant([[1,2],[3,4]])\nb = tf.constant([[2,0],[0,2]])\na@b  #等价于tf.matmul(a,b)\n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[2, 4],\n       [6, 8]], dtype=int32)>\n```\n\n```python\n#矩阵转置\na = tf.constant([[1.0,2],[3,4]])\ntf.transpose(a)\n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[1., 3.],\n       [2., 4.]], dtype=float32)>\n```\n\n```python\n#矩阵逆，必须为tf.float32或tf.double类型\na = tf.constant([[1.0,2],[3.0,4]],dtype = tf.float32)\ntf.linalg.inv(a)\n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[-2.0000002 ,  1.0000001 ],\n       [ 1.5000001 , -0.50000006]], dtype=float32)>\n```\n\n```python\n#矩阵求trace\na = tf.constant([[1.0,2],[3,4]])\ntf.linalg.trace(a)\n```\n\n```\n<tf.Tensor: shape=(), dtype=float32, numpy=5.0>\n```\n\n```python\n#矩阵求范数\na = tf.constant([[1.0,2],[3,4]])\ntf.linalg.norm(a)\n```\n\n```\n<tf.Tensor: shape=(), dtype=float32, numpy=5.477226>\n```\n\n```python\n#矩阵行列式\na = tf.constant([[1.0,2],[3,4]])\ntf.linalg.det(a)\n```\n\n```\n<tf.Tensor: shape=(), dtype=float32, numpy=-2.0>\n```\n\n```python\n#矩阵特征值\ntf.linalg.eigvalsh(a)\n```\n\n```\n<tf.Tensor: shape=(2,), dtype=float32, numpy=array([-0.8541021,  5.854102 ], dtype=float32)>\n```\n\n```python\n#矩阵qr分解\na  = tf.constant([[1.0,2.0],[3.0,4.0]],dtype = tf.float32)\nq,r = tf.linalg.qr(a)\ntf.print(q)\ntf.print(r)\ntf.print(q@r)\n```\n\n```\n[[-0.316227794 -0.948683321]\n [-0.948683321 0.316227734]]\n[[-3.1622777 -4.4271884]\n [0 -0.632455349]]\n[[1.00000012 1.99999976]\n [3 4]]\n```\n\n```python\n#矩阵svd分解\na  = tf.constant([[1.0,2.0],[3.0,4.0]],dtype = tf.float32)\nv,s,d = tf.linalg.svd(a)\ntf.matmul(tf.matmul(s,tf.linalg.diag(v)),d)\n\n#利用svd分解可以在TensorFlow中实现主成分分析降维\n\n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[0.9999996, 1.9999996],\n       [2.9999998, 4.       ]], dtype=float32)>\n```\n\n```python\n\n```\n\n```python\n\n```\n\n### 四，广播机制\n\n\nTensorFlow的广播规则和numpy是一样的:\n\n* 1、如果张量的维度不同，将维度较小的张量进行扩展，直到两个张量的维度都一样。\n* 2、如果两个张量在某个维度上的长度是相同的，或者其中一个张量在该维度上的长度为1，那么我们就说这两个张量在该维度上是相容的。\n* 3、如果两个张量在所有维度上都是相容的，它们就能使用广播。\n* 4、广播之后，每个维度的长度将取两个张量在该维度长度的较大值。\n* 5、在任何一个维度上，如果一个张量的长度为1，另一个张量长度大于1，那么在该维度上，就好像是对第一个张量进行了复制。\n\ntf.broadcast_to 以显式的方式按照广播机制扩展张量的维度。\n\n```python\na = tf.constant([1,2,3])\nb = tf.constant([[0,0,0],[1,1,1],[2,2,2]])\nb + a  #等价于 b + tf.broadcast_to(a,b.shape)\n```\n\n```\n<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\narray([[1, 2, 3],\n       [2, 3, 4],\n       [3, 4, 5]], dtype=int32)>\n```\n\n```python\ntf.broadcast_to(a,b.shape)\n```\n\n```\n<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\narray([[1, 2, 3],\n       [1, 2, 3],\n       [1, 2, 3]], dtype=int32)>\n```\n\n```python\n#计算广播后计算结果的形状，静态形状，TensorShape类型参数\ntf.broadcast_static_shape(a.shape,b.shape)\n```\n\n```\nTensorShape([3, 3])\n```\n\n```python\n#计算广播后计算结果的形状，动态形状，Tensor类型参数\nc = tf.constant([1,2,3])\nd = tf.constant([[1],[2],[3]])\ntf.broadcast_dynamic_shape(tf.shape(c),tf.shape(d))\n```\n\n```\n<tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 3], dtype=int32)>\n```\n\n```python\n#广播效果\nc+d #等价于 tf.broadcast_to(c,[3,3]) + tf.broadcast_to(d,[3,3])\n```\n\n```\n<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[6.5760484, 7.8174157],\n       [6.8174157, 6.4239516]], dtype=float32)>\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n```python\n\n```\n# 4-3,AutoGraph的使用规范\n\n有三种计算图的构建方式：静态计算图，动态计算图，以及Autograph。\n\nTensorFlow 2.0主要使用的是动态计算图和Autograph。\n\n动态计算图易于调试，编码效率较高，但执行效率偏低。\n\n静态计算图执行效率很高，但较难调试。\n\n而Autograph机制可以将动态图转换成静态计算图，兼收执行效率和编码效率之利。\n\n当然Autograph机制能够转换的代码并不是没有任何约束的，有一些编码规范需要遵循，否则可能会转换失败或者不符合预期。\n\n我们将着重介绍Autograph的编码规范和Autograph转换成静态图的原理。\n\n并介绍使用tf.Module来更好地构建Autograph。\n\n本篇我们介绍使用Autograph的编码规范。\n\n\n### 一，Autograph编码规范总结\n\n\n* 1，被@tf.function修饰的函数应尽可能使用TensorFlow中的函数而不是Python中的其他函数。例如使用tf.print而不是print，使用tf.range而不是range，使用tf.constant(True)而不是True.\n\n* 2，避免在@tf.function修饰的函数内部定义tf.Variable. \n\n* 3，被@tf.function修饰的函数不可修改该函数外部的Python列表或字典等数据结构变量。\n\n\n```python\n\n```\n\n### 二，Autograph编码规范解析\n\n\n **1，被@tf.function修饰的函数应尽量使用TensorFlow中的函数而不是Python中的其他函数。**\n\n```python\nimport numpy as np\nimport tensorflow as tf\n\n@tf.function\ndef np_random():\n    a = np.random.randn(3,3)\n    tf.print(a)\n    \n@tf.function\ndef tf_random():\n    a = tf.random.normal((3,3))\n    tf.print(a)\n```\n\n```python\n#np_random每次执行都是一样的结果。\nnp_random()\nnp_random()\n```\n\n```\narray([[ 0.22619201, -0.4550123 , -0.42587565],\n       [ 0.05429906,  0.2312667 , -1.44819738],\n       [ 0.36571796,  1.45578986, -1.05348983]])\narray([[ 0.22619201, -0.4550123 , -0.42587565],\n       [ 0.05429906,  0.2312667 , -1.44819738],\n       [ 0.36571796,  1.45578986, -1.05348983]])\n```\n\n```python\n#tf_random每次执行都会有重新生成随机数。\ntf_random()\ntf_random()\n```\n\n```\n[[-1.38956189 -0.394843668 0.420657277]\n [2.87235498 -1.33740318 -0.533843279]\n [0.918233037 0.118598573 -0.399486482]]\n[[-0.858178258 1.67509317 0.511889517]\n [-0.545829177 -2.20118237 -0.968222201]\n [0.733958483 -0.61904633 0.77440238]]\n```\n\n```python\n\n```\n\n**2，避免在@tf.function修饰的函数内部定义tf.Variable.**\n\n```python\n# 避免在@tf.function修饰的函数内部定义tf.Variable.\n\nx = tf.Variable(1.0,dtype=tf.float32)\n@tf.function\ndef outer_var():\n    x.assign_add(1.0)\n    tf.print(x)\n    return(x)\n\nouter_var() \nouter_var()\n\n```\n\n```python\n@tf.function\ndef inner_var():\n    x = tf.Variable(1.0,dtype = tf.float32)\n    x.assign_add(1.0)\n    tf.print(x)\n    return(x)\n\n#执行将报错\n#inner_var()\n#inner_var()\n\n```\n\n```\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-12-c95a7c3c1ddd> in <module>\n      7 \n      8 #执行将报错\n----> 9 inner_var()\n     10 inner_var()\n\n~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)\n    566         xla_context.Exit()\n    567     else:\n--> 568       result = self._call(*args, **kwds)\n    569 \n    570     if tracing_count == self._get_tracing_count():\n......\nValueError: tf.function-decorated function tried to create variables on non-first call.\n```\n\n\n**3,被@tf.function修饰的函数不可修改该函数外部的Python列表或字典等结构类型变量。**\n\n```python\ntensor_list = []\n\n#@tf.function #加上这一行切换成Autograph结果将不符合预期！！！\ndef append_tensor(x):\n    tensor_list.append(x)\n    return tensor_list\n\nappend_tensor(tf.constant(5.0))\nappend_tensor(tf.constant(6.0))\nprint(tensor_list)\n\n```\n\n```\n[<tf.Tensor: shape=(), dtype=float32, numpy=5.0>, <tf.Tensor: shape=(), dtype=float32, numpy=6.0>]\n```\n\n```python\ntensor_list = []\n\n@tf.function #加上这一行切换成Autograph结果将不符合预期！！！\ndef append_tensor(x):\n    tensor_list.append(x)\n    return tensor_list\n\n\nappend_tensor(tf.constant(5.0))\nappend_tensor(tf.constant(6.0))\nprint(tensor_list)\n\n```\n\n```\n[<tf.Tensor 'x:0' shape=() dtype=float32>]\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n\n\n# 4-4,AutoGraph的机制原理\n\n有三种计算图的构建方式：静态计算图，动态计算图，以及Autograph。\n\nTensorFlow 2.0主要使用的是动态计算图和Autograph。\n\n动态计算图易于调试，编码效率较高，但执行效率偏低。\n\n静态计算图执行效率很高，但较难调试。\n\n而Autograph机制可以将动态图转换成静态计算图，兼收执行效率和编码效率之利。\n\n当然Autograph机制能够转换的代码并不是没有任何约束的，有一些编码规范需要遵循，否则可能会转换失败或者不符合预期。\n\n我们会介绍Autograph的编码规范和Autograph转换成静态图的原理。\n\n并介绍使用tf.Module来更好地构建Autograph。\n\n上篇我们介绍了Autograph的编码规范，本篇我们介绍Autograph的机制原理。\n\n\n\n### 一，Autograph的机制原理\n\n\n**当我们使用@tf.function装饰一个函数的时候，后面到底发生了什么呢？**\n\n例如我们写下如下代码。\n\n```python\nimport tensorflow as tf\nimport numpy as np \n\n@tf.function(autograph=True)\ndef myadd(a,b):\n    for i in tf.range(3):\n        tf.print(i)\n    c = a+b\n    print(\"tracing\")\n    return c\n```\n\n后面什么都没有发生。仅仅是在Python堆栈中记录了这样一个函数的签名。\n\n**当我们第一次调用这个被@tf.function装饰的函数时，后面到底发生了什么？**\n\n例如我们写下如下代码。\n\n```python\nmyadd(tf.constant(\"hello\"),tf.constant(\"world\"))\n```\n\n```\ntracing\n0\n1\n2\n```\n\n\n发生了2件事情，\n\n第一件事情是创建计算图。\n\n即创建一个静态计算图，跟踪执行一遍函数体中的Python代码，确定各个变量的Tensor类型，并根据执行顺序将算子添加到计算图中。\n在这个过程中，如果开启了autograph=True(默认开启),会将Python控制流转换成TensorFlow图内控制流。\n主要是将if语句转换成 tf.cond算子表达，将while和for循环语句转换成tf.while_loop算子表达，并在必要的时候添加\ntf.control_dependencies指定执行顺序依赖关系。\n\n相当于在 tensorflow1.0执行了类似下面的语句：\n\n```python\ng = tf.Graph()\nwith g.as_default():\n    a = tf.placeholder(shape=[],dtype=tf.string)\n    b = tf.placeholder(shape=[],dtype=tf.string)\n    cond = lambda i: i<tf.constant(3)\n    def body(i):\n        tf.print(i)\n        return(i+1)\n    loop = tf.while_loop(cond,body,loop_vars=[0])\n    loop\n    with tf.control_dependencies(loop):\n        c = tf.strings.join([a,b])\n    print(\"tracing\")\n```\n\n第二件事情是执行计算图。\n\n相当于在 tensorflow1.0中执行了下面的语句：\n\n```python\nwith tf.Session(graph=g) as sess:\n    sess.run(c,feed_dict={a:tf.constant(\"hello\"),b:tf.constant(\"world\")})\n```\n\n因此我们先看到的是第一个步骤的结果：即Python调用标准输出流打印\"tracing\"语句。\n\n然后看到第二个步骤的结果：TensorFlow调用标准输出流打印1,2,3。\n\n\n\n**当我们再次用相同的输入参数类型调用这个被@tf.function装饰的函数时，后面到底发生了什么？**\n\n例如我们写下如下代码。\n\n```python\nmyadd(tf.constant(\"good\"),tf.constant(\"morning\"))\n```\n\n```\n0\n1\n2\n```\n\n\n只会发生一件事情，那就是上面步骤的第二步，执行计算图。\n\n所以这一次我们没有看到打印\"tracing\"的结果。\n\n\n**当我们再次用不同的的输入参数类型调用这个被@tf.function装饰的函数时，后面到底发生了什么？**\n\n例如我们写下如下代码。\n\n```python\nmyadd(tf.constant(1),tf.constant(2))\n```\n\n```\ntracing\n0\n1\n2\n```\n\n\n由于输入参数的类型已经发生变化，已经创建的计算图不能够再次使用。\n\n需要重新做2件事情：创建新的计算图、执行计算图。\n\n所以我们又会先看到的是第一个步骤的结果：即Python调用标准输出流打印\"tracing\"语句。\n\n然后再看到第二个步骤的结果：TensorFlow调用标准输出流打印1,2,3。\n\n\n**需要注意的是，如果调用被@tf.function装饰的函数时输入的参数不是Tensor类型，则每次都会重新创建计算图。**\n\n例如我们写下如下代码。两次都会重新创建计算图。因此，一般建议调用@tf.function时应传入Tensor类型。\n\n```python\nmyadd(\"hello\",\"world\")\nmyadd(\"good\",\"morning\")\n```\n\n```\ntracing\n0\n1\n2\ntracing\n0\n1\n2\n```\n\n```python\n\n```\n\n```python\n\n```\n\n### 二，重新理解Autograph的编码规范\n\n\n了解了以上Autograph的机制原理，我们也就能够理解Autograph编码规范的3条建议了。\n\n1，被@tf.function修饰的函数应尽量使用TensorFlow中的函数而不是Python中的其他函数。例如使用tf.print而不是print.\n\n解释：Python中的函数仅仅会在跟踪执行函数以创建静态图的阶段使用，普通Python函数是无法嵌入到静态计算图中的，所以\n在计算图构建好之后再次调用的时候，这些Python函数并没有被计算，而TensorFlow中的函数则可以嵌入到计算图中。使用普通的Python函数会导致\n被@tf.function修饰前【eager执行】和被@tf.function修饰后【静态图执行】的输出不一致。\n\n2，避免在@tf.function修饰的函数内部定义tf.Variable. \n\n解释：如果函数内部定义了tf.Variable,那么在【eager执行】时，这种创建tf.Variable的行为在每次函数调用时候都会发生。但是在【静态图执行】时，这种创建tf.Variable的行为只会发生在第一步跟踪Python代码逻辑创建计算图时，这会导致被@tf.function修饰前【eager执行】和被@tf.function修饰后【静态图执行】的输出不一致。实际上，TensorFlow在这种情况下一般会报错。\n\n3，被@tf.function修饰的函数不可修改该函数外部的Python列表或字典等数据结构变量。\n\n解释：静态计算图是被编译成C++代码在TensorFlow内核中执行的。Python中的列表和字典等数据结构变量是无法嵌入到计算图中，它们仅仅能够在创建计算图时被读取，在执行计算图时是无法修改Python中的列表或字典这样的数据结构变量的。\n\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n```python\n\n```\n# 4-5,AutoGraph和tf.Module\n\n\n有三种计算图的构建方式：静态计算图，动态计算图，以及Autograph。\n\nTensorFlow 2.0主要使用的是动态计算图和Autograph。\n\n动态计算图易于调试，编码效率较高，但执行效率偏低。\n\n静态计算图执行效率很高，但较难调试。\n\n而Autograph机制可以将动态图转换成静态计算图，兼收执行效率和编码效率之利。\n\n当然Autograph机制能够转换的代码并不是没有任何约束的，有一些编码规范需要遵循，否则可能会转换失败或者不符合预期。\n\n前面我们介绍了Autograph的编码规范和Autograph转换成静态图的原理。\n\n本篇我们介绍使用tf.Module来更好地构建Autograph。\n\n\n\n\n### 一，Autograph和tf.Module概述\n\n\n前面在介绍Autograph的编码规范时提到构建Autograph时应该避免在@tf.function修饰的函数内部定义tf.Variable. \n\n但是如果在函数外部定义tf.Variable的话，又会显得这个函数有外部变量依赖，封装不够完美。\n\n一种简单的思路是定义一个类，并将相关的tf.Variable创建放在类的初始化方法中。而将函数的逻辑放在其他方法中。\n\n这样一顿猛如虎的操作之后，我们会觉得一切都如同人法地地法天天法道道法自然般的自然。\n\n惊喜的是，TensorFlow提供了一个基类tf.Module，通过继承它构建子类，我们不仅可以获得以上的自然而然，而且可以非常方便地管理变量，还可以非常方便地管理它引用的其它Module，最重要的是，我们能够利用tf.saved_model保存模型并实现跨平台部署使用。\n\n实际上，tf.keras.models.Model,tf.keras.layers.Layer 都是继承自tf.Module的，提供了方便的变量管理和所引用的子模块管理的功能。\n\n**因此，利用tf.Module提供的封装，再结合TensoFlow丰富的低阶API，实际上我们能够基于TensorFlow开发任意机器学习模型(而非仅仅是神经网络模型)，并实现跨平台部署使用。**\n\n\n\n\n\n### 二，应用tf.Module封装Autograph\n\n\n定义一个简单的function。\n\n```python\nimport tensorflow as tf \nx = tf.Variable(1.0,dtype=tf.float32)\n\n#在tf.function中用input_signature限定输入张量的签名类型：shape和dtype\n@tf.function(input_signature=[tf.TensorSpec(shape = [], dtype = tf.float32)])    \ndef add_print(a):\n    x.assign_add(a)\n    tf.print(x)\n    return(x)\n```\n\n```python\nadd_print(tf.constant(3.0))\n#add_print(tf.constant(3)) #输入不符合张量签名的参数将报错\n```\n\n```\n4\n```\n\n\n下面利用tf.Module的子类化将其封装一下。\n\n```python\nclass DemoModule(tf.Module):\n    def __init__(self,init_value = tf.constant(0.0),name=None):\n        super(DemoModule, self).__init__(name=name)\n        with self.name_scope:  #相当于with tf.name_scope(\"demo_module\")\n            self.x = tf.Variable(init_value,dtype = tf.float32,trainable=True)\n\n     \n    @tf.function(input_signature=[tf.TensorSpec(shape = [], dtype = tf.float32)])  \n    def addprint(self,a):\n        with self.name_scope:\n            self.x.assign_add(a)\n            tf.print(self.x)\n            return(self.x)\n\n```\n\n```python\n#执行\ndemo = DemoModule(init_value = tf.constant(1.0))\nresult = demo.addprint(tf.constant(5.0))\n```\n\n```\n6\n```\n\n```python\n#查看模块中的全部变量和全部可训练变量\nprint(demo.variables)\nprint(demo.trainable_variables)\n```\n\n```\n(<tf.Variable 'demo_module/Variable:0' shape=() dtype=float32, numpy=6.0>,)\n(<tf.Variable 'demo_module/Variable:0' shape=() dtype=float32, numpy=6.0>,)\n```\n\n```python\n#查看模块中的全部子模块\ndemo.submodules\n```\n\n```python\n#使用tf.saved_model 保存模型，并指定需要跨平台部署的方法\ntf.saved_model.save(demo,\"./data/demo/1\",signatures = {\"serving_default\":demo.addprint})\n```\n\n```python\n#加载模型\ndemo2 = tf.saved_model.load(\"./data/demo/1\")\ndemo2.addprint(tf.constant(5.0))\n```\n\n```\n11\n```\n\n```python\n# 查看模型文件相关信息，红框标出来的输出信息在模型部署和跨平台使用时有可能会用到\n!saved_model_cli show --dir ./data/demo/1 --all\n```\n\n![](./data/查看模型文件信息.jpg)\n\n```python\n\n```\n\n在tensorboard中查看计算图，模块会被添加模块名demo_module,方便层次化呈现计算图结构。\n\n```python\nimport datetime\n\n# 创建日志\nstamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\nlogdir = './data/demomodule/%s' % stamp\nwriter = tf.summary.create_file_writer(logdir)\n\n#开启autograph跟踪\ntf.summary.trace_on(graph=True, profiler=True) \n\n#执行autograph\ndemo = DemoModule(init_value = tf.constant(0.0))\nresult = demo.addprint(tf.constant(5.0))\n\n#将计算图信息写入日志\nwith writer.as_default():\n    tf.summary.trace_export(\n        name=\"demomodule\",\n        step=0,\n        profiler_outdir=logdir)\n    \n```\n\n```python\n\n```\n\n```python\n#启动 tensorboard在jupyter中的魔法命令\n%reload_ext tensorboard\n```\n\n```python\nfrom tensorboard import notebook\nnotebook.list() \n```\n\n```python\nnotebook.start(\"--logdir ./data/demomodule/\")\n```\n\n![](./data/demomodule的计算图结构.jpg)\n\n```python\n\n```\n\n除了利用tf.Module的子类化实现封装，我们也可以通过给tf.Module添加属性的方法进行封装。\n\n```python\nmymodule = tf.Module()\nmymodule.x = tf.Variable(0.0)\n\n@tf.function(input_signature=[tf.TensorSpec(shape = [], dtype = tf.float32)])  \ndef addprint(a):\n    mymodule.x.assign_add(a)\n    tf.print(mymodule.x)\n    return (mymodule.x)\n\nmymodule.addprint = addprint\n```\n\n```python\nmymodule.addprint(tf.constant(1.0)).numpy()\n```\n\n```\n1.0\n```\n\n```python\nprint(mymodule.variables)\n```\n\n```\n(<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.0>,)\n```\n\n```python\n#使用tf.saved_model 保存模型\ntf.saved_model.save(mymodule,\"./data/mymodule\",\n    signatures = {\"serving_default\":mymodule.addprint})\n\n#加载模型\nmymodule2 = tf.saved_model.load(\"./data/mymodule\")\nmymodule2.addprint(tf.constant(5.0))\n```\n\n```\nINFO:tensorflow:Assets written to: ./data/mymodule/assets\n5\n```\n\n```python\n\n```\n\n### 三，tf.Module和tf.keras.Model，tf.keras.layers.Layer\n\n\ntf.keras中的模型和层都是继承tf.Module实现的，也具有变量管理和子模块管理功能。\n\n```python\nimport tensorflow as tf\nfrom tensorflow.keras import models,layers,losses,metrics\n```\n\n```python\nprint(issubclass(tf.keras.Model,tf.Module))\nprint(issubclass(tf.keras.layers.Layer,tf.Module))\nprint(issubclass(tf.keras.Model,tf.keras.layers.Layer))\n```\n\n```\nTrue\nTrue\nTrue\n```\n\n```python\ntf.keras.backend.clear_session() \n\nmodel = models.Sequential()\n\nmodel.add(layers.Dense(4,input_shape = (10,)))\nmodel.add(layers.Dense(2))\nmodel.add(layers.Dense(1))\nmodel.summary()\n```\n\n```\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 4)                 44        \n_________________________________________________________________\ndense_1 (Dense)              (None, 2)                 10        \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 3         \n=================================================================\nTotal params: 57\nTrainable params: 57\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n```python\nmodel.variables\n```\n\n```\n[<tf.Variable 'dense/kernel:0' shape=(10, 4) dtype=float32, numpy=\n array([[-0.06741005,  0.45534766,  0.5190817 , -0.01806331],\n        [-0.14258742, -0.49711505,  0.26030976,  0.18607801],\n        [-0.62806034,  0.5327399 ,  0.42206633,  0.29201728],\n        [-0.16602087, -0.18901917,  0.55159235, -0.01091868],\n        [ 0.04533798,  0.326845  , -0.582667  ,  0.19431782],\n        [ 0.6494713 , -0.16174704,  0.4062966 ,  0.48760796],\n        [ 0.58400524, -0.6280886 , -0.11265379, -0.6438277 ],\n        [ 0.26642334,  0.49275804,  0.20793378, -0.43889117],\n        [ 0.4092741 ,  0.09871006, -0.2073121 ,  0.26047975],\n        [ 0.43910992,  0.00199282, -0.07711256, -0.27966842]],\n       dtype=float32)>,\n <tf.Variable 'dense/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'dense_1/kernel:0' shape=(4, 2) dtype=float32, numpy=\n array([[ 0.5022683 , -0.0507431 ],\n        [-0.61540484,  0.9369011 ],\n        [-0.14412141, -0.54607415],\n        [ 0.2027781 , -0.4651153 ]], dtype=float32)>,\n <tf.Variable 'dense_1/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>,\n <tf.Variable 'dense_2/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[-0.244825 ],\n        [-1.2101456]], dtype=float32)>,\n <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n```\n\n```python\nmodel.layers[0].trainable = False #冻结第0层的变量,使其不可训练\nmodel.trainable_variables\n```\n\n```\n[<tf.Variable 'dense_1/kernel:0' shape=(4, 2) dtype=float32, numpy=\n array([[ 0.5022683 , -0.0507431 ],\n        [-0.61540484,  0.9369011 ],\n        [-0.14412141, -0.54607415],\n        [ 0.2027781 , -0.4651153 ]], dtype=float32)>,\n <tf.Variable 'dense_1/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>,\n <tf.Variable 'dense_2/kernel:0' shape=(2, 1) dtype=float32, numpy=\n array([[-0.244825 ],\n        [-1.2101456]], dtype=float32)>,\n <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n```\n\n```python\nmodel.submodules\n```\n\n```\n(<tensorflow.python.keras.engine.input_layer.InputLayer at 0x144d8c080>,\n <tensorflow.python.keras.layers.core.Dense at 0x144daada0>,\n <tensorflow.python.keras.layers.core.Dense at 0x144d8c5c0>,\n <tensorflow.python.keras.layers.core.Dense at 0x144d7aa20>)\n```\n\n```python\nmodel.layers\n```\n\n```\n[<tensorflow.python.keras.layers.core.Dense at 0x144daada0>,\n <tensorflow.python.keras.layers.core.Dense at 0x144d8c5c0>,\n <tensorflow.python.keras.layers.core.Dense at 0x144d7aa20>]\n```\n\n```python\nprint(model.name)\nprint(model.name_scope())\n```\n\n```\nsequential\nsequential\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n\n\n# 五、TensorFlow的中阶API\n\nTensorFlow的中阶API主要包括: \n\n* 数据管道(tf.data)\n\n* 特征列(tf.feature_column)\n\n* 激活函数(tf.nn)\n\n* 模型层(tf.keras.layers)\n\n* 损失函数(tf.keras.losses)\n\n* 评估函数(tf.keras.metrics)\n\n* 优化器(tf.keras.optimizers)\n\n* 回调函数(tf.keras.callbacks)\n\n如果把模型比作一个房子，那么中阶API就是【模型之墙】。\n\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n```python\n\n```\n# 5-1,数据管道Dataset\n\n如果需要训练的数据大小不大，例如不到1G，那么可以直接全部读入内存中进行训练，这样一般效率最高。\n\n但如果需要训练的数据很大，例如超过10G，无法一次载入内存，那么通常需要在训练的过程中分批逐渐读入。\n\n使用 tf.data API 可以构建数据输入管道，轻松处理大量的数据，不同的数据格式，以及不同的数据转换。\n\n```python\n\n```\n\n### 一，构建数据管道\n\n\n可以从 Numpy array, Pandas DataFrame, Python generator, csv文件, 文本文件, 文件路径, tfrecords文件等方式构建数据管道。\n\n其中通过Numpy array, Pandas DataFrame, 文件路径构建数据管道是最常用的方法。\n\n通过tfrecords文件方式构建数据管道较为复杂，需要对样本构建tf.Example后压缩成字符串写到tfrecoreds文件，读取后再解析成tf.Example。\n\n但tfrecoreds文件的优点是压缩后文件较小，便于网络传播，加载速度较快。\n\n\n**1,从Numpy array构建数据管道**\n\n```python\n# 从Numpy array构建数据管道\n\nimport tensorflow as tf\nimport numpy as np \nfrom sklearn import datasets \niris = datasets.load_iris()\n\n\nds1 = tf.data.Dataset.from_tensor_slices((iris[\"data\"],iris[\"target\"]))\nfor features,label in ds1.take(5):\n    print(features,label)\n\n```\n\n```\ntf.Tensor([5.1 3.5 1.4 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64)\ntf.Tensor([4.9 3.  1.4 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64)\ntf.Tensor([4.7 3.2 1.3 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64)\ntf.Tensor([4.6 3.1 1.5 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64)\ntf.Tensor([5.  3.6 1.4 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64)\n```\n\n```python\n\n```\n\n**2,从 Pandas DataFrame构建数据管道**\n\n```python\n# 从 Pandas DataFrame构建数据管道\nimport tensorflow as tf\nfrom sklearn import datasets \nimport pandas as pd\niris = datasets.load_iris()\ndfiris = pd.DataFrame(iris[\"data\"],columns = iris.feature_names)\nds2 = tf.data.Dataset.from_tensor_slices((dfiris.to_dict(\"list\"),iris[\"target\"]))\n\nfor features,label in ds2.take(3):\n    print(features,label)\n```\n\n```\n{'sepal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=5.1>, 'sepal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=3.5>, 'petal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=1.4>, 'petal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=0.2>} tf.Tensor(0, shape=(), dtype=int64)\n{'sepal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=4.9>, 'sepal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=3.0>, 'petal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=1.4>, 'petal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=0.2>} tf.Tensor(0, shape=(), dtype=int64)\n{'sepal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=4.7>, 'sepal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=3.2>, 'petal length (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=1.3>, 'petal width (cm)': <tf.Tensor: shape=(), dtype=float32, numpy=0.2>} tf.Tensor(0, shape=(), dtype=int64)\n```\n\n```python\n\n```\n\n```python\n\n```\n\n**3,从Python generator构建数据管道**\n\n```python\n# 从Python generator构建数据管道\nimport tensorflow as tf\nfrom matplotlib import pyplot as plt \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# 定义一个从文件中读取图片的generator\nimage_generator = ImageDataGenerator(rescale=1.0/255).flow_from_directory(\n                    \"./data/cifar2/test/\",\n                    target_size=(32, 32),\n                    batch_size=20,\n                    class_mode='binary')\n\nclassdict = image_generator.class_indices\nprint(classdict)\n\ndef generator():\n    for features,label in image_generator:\n        yield (features,label)\n\nds3 = tf.data.Dataset.from_generator(generator,output_types=(tf.float32,tf.int32))\n```\n\n```python\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\nplt.figure(figsize=(6,6)) \nfor i,(img,label) in enumerate(ds3.unbatch().take(9)):\n    ax=plt.subplot(3,3,i+1)\n    ax.imshow(img.numpy())\n    ax.set_title(\"label = %d\"%label)\n    ax.set_xticks([])\n    ax.set_yticks([]) \nplt.show()\n```\n\n![](./data/5-1-cifar2预览.jpg)\n\n```python\n\n```\n\n**4,从csv文件构建数据管道**\n\n```python\n# 从csv文件构建数据管道\nds4 = tf.data.experimental.make_csv_dataset(\n      file_pattern = [\"./data/titanic/train.csv\",\"./data/titanic/test.csv\"],\n      batch_size=3, \n      label_name=\"Survived\",\n      na_value=\"\",\n      num_epochs=1,\n      ignore_errors=True)\n\nfor data,label in ds4.take(2):\n    print(data,label)\n```\n\n```\nOrderedDict([('PassengerId', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([540,  58, 764], dtype=int32)>), ('Pclass', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 3, 1], dtype=int32)>), ('Name', <tf.Tensor: shape=(3,), dtype=string, numpy=\narray([b'Frolicher, Miss. Hedwig Margaritha', b'Novel, Mr. Mansouer',\n       b'Carter, Mrs. William Ernest (Lucile Polk)'], dtype=object)>), ('Sex', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'female', b'male', b'female'], dtype=object)>), ('Age', <tf.Tensor: shape=(3,), dtype=float32, numpy=array([22. , 28.5, 36. ], dtype=float32)>), ('SibSp', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 0, 1], dtype=int32)>), ('Parch', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 0, 2], dtype=int32)>), ('Ticket', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'13568', b'2697', b'113760'], dtype=object)>), ('Fare', <tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 49.5   ,   7.2292, 120.    ], dtype=float32)>), ('Cabin', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'B39', b'', b'B96 B98'], dtype=object)>), ('Embarked', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'C', b'C', b'S'], dtype=object)>)]) tf.Tensor([1 0 1], shape=(3,), dtype=int32)\nOrderedDict([('PassengerId', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([845,  66, 390], dtype=int32)>), ('Pclass', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([3, 3, 2], dtype=int32)>), ('Name', <tf.Tensor: shape=(3,), dtype=string, numpy=\narray([b'Culumovic, Mr. Jeso', b'Moubarek, Master. Gerios',\n       b'Lehmann, Miss. Bertha'], dtype=object)>), ('Sex', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'male', b'male', b'female'], dtype=object)>), ('Age', <tf.Tensor: shape=(3,), dtype=float32, numpy=array([17.,  0., 17.], dtype=float32)>), ('SibSp', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 1, 0], dtype=int32)>), ('Parch', <tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 1, 0], dtype=int32)>), ('Ticket', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'315090', b'2661', b'SC 1748'], dtype=object)>), ('Fare', <tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 8.6625, 15.2458, 12.    ], dtype=float32)>), ('Cabin', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'', b'', b''], dtype=object)>), ('Embarked', <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'S', b'C', b'C'], dtype=object)>)]) tf.Tensor([0 1 1], shape=(3,), dtype=int32)\n```\n\n```python\n\n```\n\n**5,从文本文件构建数据管道**\n\n```python\n# 从文本文件构建数据管道\n\nds5 = tf.data.TextLineDataset(\n    filenames = [\"./data/titanic/train.csv\",\"./data/titanic/test.csv\"]\n    ).skip(1) #略去第一行header\n\nfor line in ds5.take(5):\n    print(line)\n```\n\n```\ntf.Tensor(b'493,0,1,\"Molson, Mr. Harry Markland\",male,55.0,0,0,113787,30.5,C30,S', shape=(), dtype=string)\ntf.Tensor(b'53,1,1,\"Harper, Mrs. Henry Sleeper (Myna Haxtun)\",female,49.0,1,0,PC 17572,76.7292,D33,C', shape=(), dtype=string)\ntf.Tensor(b'388,1,2,\"Buss, Miss. Kate\",female,36.0,0,0,27849,13.0,,S', shape=(), dtype=string)\ntf.Tensor(b'192,0,2,\"Carbines, Mr. William\",male,19.0,0,0,28424,13.0,,S', shape=(), dtype=string)\ntf.Tensor(b'687,0,3,\"Panula, Mr. Jaako Arnold\",male,14.0,4,1,3101295,39.6875,,S', shape=(), dtype=string)\n```\n\n```python\n\n```\n\n**6,从文件路径构建数据管道**\n\n```python\nds6 = tf.data.Dataset.list_files(\"./data/cifar2/train/*/*.jpg\")\nfor file in ds6.take(5):\n    print(file)\n```\n\n```\ntf.Tensor(b'./data/cifar2/train/automobile/1263.jpg', shape=(), dtype=string)\ntf.Tensor(b'./data/cifar2/train/airplane/2837.jpg', shape=(), dtype=string)\ntf.Tensor(b'./data/cifar2/train/airplane/4264.jpg', shape=(), dtype=string)\ntf.Tensor(b'./data/cifar2/train/automobile/4241.jpg', shape=(), dtype=string)\ntf.Tensor(b'./data/cifar2/train/automobile/192.jpg', shape=(), dtype=string)\n```\n\n```python\nfrom matplotlib import pyplot as plt \ndef load_image(img_path,size = (32,32)):\n    label = 1 if tf.strings.regex_full_match(img_path,\".*/automobile/.*\") else 0\n    img = tf.io.read_file(img_path)\n    img = tf.image.decode_jpeg(img) #注意此处为jpeg格式\n    img = tf.image.resize(img,size)\n    return(img,label)\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\nfor i,(img,label) in enumerate(ds6.map(load_image).take(2)):\n    plt.figure(i)\n    plt.imshow((img/255.0).numpy())\n    plt.title(\"label = %d\"%label)\n    plt.xticks([])\n    plt.yticks([])\n```\n\n![](./data/5-1-car2.jpg)\n\n```python\n\n```\n\n**7,从tfrecords文件构建数据管道**\n\n```python\nimport os\nimport numpy as np\n\n# inpath：原始数据路径 outpath:TFRecord文件输出路径\ndef create_tfrecords(inpath,outpath): \n    writer = tf.io.TFRecordWriter(outpath)\n    dirs = os.listdir(inpath)\n    for index, name in enumerate(dirs):\n        class_path = inpath +\"/\"+ name+\"/\"\n        for img_name in os.listdir(class_path):\n            img_path = class_path + img_name\n            img = tf.io.read_file(img_path)\n            #img = tf.image.decode_image(img)\n            #img = tf.image.encode_jpeg(img) #统一成jpeg格式压缩\n            example = tf.train.Example(\n               features=tf.train.Features(feature={\n                    'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[index])),\n                    'img_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img.numpy()]))\n               }))\n            writer.write(example.SerializeToString())\n    writer.close()\n    \ncreate_tfrecords(\"./data/cifar2/test/\",\"./data/cifar2_test.tfrecords/\")\n\n```\n\n```python\nfrom matplotlib import pyplot as plt \n\ndef parse_example(proto):\n    description ={ 'img_raw' : tf.io.FixedLenFeature([], tf.string),\n                   'label': tf.io.FixedLenFeature([], tf.int64)} \n    example = tf.io.parse_single_example(proto, description)\n    img = tf.image.decode_jpeg(example[\"img_raw\"])   #注意此处为jpeg格式\n    img = tf.image.resize(img, (32,32))\n    label = example[\"label\"]\n    return(img,label)\n\nds7 = tf.data.TFRecordDataset(\"./data/cifar2_test.tfrecords\").map(parse_example).shuffle(3000)\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\nplt.figure(figsize=(6,6)) \nfor i,(img,label) in enumerate(ds7.take(9)):\n    ax=plt.subplot(3,3,i+1)\n    ax.imshow((img/255.0).numpy())\n    ax.set_title(\"label = %d\"%label)\n    ax.set_xticks([])\n    ax.set_yticks([]) \nplt.show()\n\n```\n\n![](./data/5-1-car9.jpg)\n\n```python\n\n```\n\n```python\n\n```\n\n### 二，应用数据转换\n\n\nDataset数据结构应用非常灵活，因为它本质上是一个Sequece序列，其每个元素可以是各种类型，例如可以是张量，列表，字典，也可以是Dataset。\n\nDataset包含了非常丰富的数据转换功能。\n\n* map: 将转换函数映射到数据集每一个元素。\n\n* flat_map: 将转换函数映射到数据集的每一个元素，并将嵌套的Dataset压平。\n\n* interleave: 效果类似flat_map,但可以将不同来源的数据夹在一起。\n\n* filter: 过滤掉某些元素。\n\n* zip: 将两个长度相同的Dataset横向铰合。\n\n* concatenate: 将两个Dataset纵向连接。\n\n* reduce: 执行归并操作。\n\n* batch : 构建批次，每次放一个批次。比原始数据增加一个维度。 其逆操作为unbatch。\n\n* padded_batch: 构建批次，类似batch, 但可以填充到相同的形状。\n\n* window :构建滑动窗口，返回Dataset of Dataset.\n\n* shuffle: 数据顺序洗牌。\n\n* repeat: 重复数据若干次，不带参数时，重复无数次。\n\n* shard: 采样，从某个位置开始隔固定距离采样一个元素。\n\n* take: 采样，从开始位置取前几个元素。\n\n\n```python\n#map:将转换函数映射到数据集每一个元素\n\nds = tf.data.Dataset.from_tensor_slices([\"hello world\",\"hello China\",\"hello Beijing\"])\nds_map = ds.map(lambda x:tf.strings.split(x,\" \"))\nfor x in ds_map:\n    print(x)\n```\n\n```\ntf.Tensor([b'hello' b'world'], shape=(2,), dtype=string)\ntf.Tensor([b'hello' b'China'], shape=(2,), dtype=string)\ntf.Tensor([b'hello' b'Beijing'], shape=(2,), dtype=string)\n```\n\n```python\n#flat_map:将转换函数映射到数据集的每一个元素，并将嵌套的Dataset压平。\n\nds = tf.data.Dataset.from_tensor_slices([\"hello world\",\"hello China\",\"hello Beijing\"])\nds_flatmap = ds.flat_map(lambda x:tf.data.Dataset.from_tensor_slices(tf.strings.split(x,\" \")))\nfor x in ds_flatmap:\n    print(x)\n```\n\n```\ntf.Tensor(b'hello', shape=(), dtype=string)\ntf.Tensor(b'world', shape=(), dtype=string)\ntf.Tensor(b'hello', shape=(), dtype=string)\ntf.Tensor(b'China', shape=(), dtype=string)\ntf.Tensor(b'hello', shape=(), dtype=string)\ntf.Tensor(b'Beijing', shape=(), dtype=string)\n```\n\n```python\n\n```\n\n```python\n# interleave: 效果类似flat_map,但可以将不同来源的数据夹在一起。\n\nds = tf.data.Dataset.from_tensor_slices([\"hello world\",\"hello China\",\"hello Beijing\"])\nds_interleave = ds.interleave(lambda x:tf.data.Dataset.from_tensor_slices(tf.strings.split(x,\" \")))\nfor x in ds_interleave:\n    print(x)\n    \n```\n\n```\ntf.Tensor(b'hello', shape=(), dtype=string)\ntf.Tensor(b'hello', shape=(), dtype=string)\ntf.Tensor(b'hello', shape=(), dtype=string)\ntf.Tensor(b'world', shape=(), dtype=string)\ntf.Tensor(b'China', shape=(), dtype=string)\ntf.Tensor(b'Beijing', shape=(), dtype=string)\n```\n\n```python\n\n```\n\n```python\n#filter:过滤掉某些元素。\n\nds = tf.data.Dataset.from_tensor_slices([\"hello world\",\"hello China\",\"hello Beijing\"])\n#找出含有字母a或B的元素\nds_filter = ds.filter(lambda x: tf.strings.regex_full_match(x, \".*[a|B].*\"))\nfor x in ds_filter:\n    print(x)\n    \n```\n\n```\ntf.Tensor(b'hello China', shape=(), dtype=string)\ntf.Tensor(b'hello Beijing', shape=(), dtype=string)\n```\n\n```python\n\n```\n\n```python\n#zip:将两个长度相同的Dataset横向铰合。\n\nds1 = tf.data.Dataset.range(0,3)\nds2 = tf.data.Dataset.range(3,6)\nds3 = tf.data.Dataset.range(6,9)\nds_zip = tf.data.Dataset.zip((ds1,ds2,ds3))\nfor x,y,z in ds_zip:\n    print(x.numpy(),y.numpy(),z.numpy())\n\n```\n\n```\n0 3 6\n1 4 7\n2 5 8\n```\n\n```python\n#condatenate:将两个Dataset纵向连接。\n\nds1 = tf.data.Dataset.range(0,3)\nds2 = tf.data.Dataset.range(3,6)\nds_concat = tf.data.Dataset.concatenate(ds1,ds2)\nfor x in ds_concat:\n    print(x)\n```\n\n```\ntf.Tensor(0, shape=(), dtype=int64)\ntf.Tensor(1, shape=(), dtype=int64)\ntf.Tensor(2, shape=(), dtype=int64)\ntf.Tensor(3, shape=(), dtype=int64)\ntf.Tensor(4, shape=(), dtype=int64)\ntf.Tensor(5, shape=(), dtype=int64)\n```\n\n```python\n#reduce:执行归并操作。\n\nds = tf.data.Dataset.from_tensor_slices([1,2,3,4,5.0])\nresult = ds.reduce(0.0,lambda x,y:tf.add(x,y))\nresult\n```\n\n```\n<tf.Tensor: shape=(), dtype=float32, numpy=15.0>\n```\n\n```python\n\n```\n\n```python\n#batch:构建批次，每次放一个批次。比原始数据增加一个维度。 其逆操作为unbatch。 \n\nds = tf.data.Dataset.range(12)\nds_batch = ds.batch(4)\nfor x in ds_batch:\n    print(x)\n```\n\n```\ntf.Tensor([0 1 2 3], shape=(4,), dtype=int64)\ntf.Tensor([4 5 6 7], shape=(4,), dtype=int64)\ntf.Tensor([ 8  9 10 11], shape=(4,), dtype=int64)\n```\n\n```python\n\n```\n\n```python\n#padded_batch:构建批次，类似batch, 但可以填充到相同的形状。\n\nelements = [[1, 2],[3, 4, 5],[6, 7],[8]]\nds = tf.data.Dataset.from_generator(lambda: iter(elements), tf.int32)\n\nds_padded_batch = ds.padded_batch(2,padded_shapes = [4,])\nfor x in ds_padded_batch:\n    print(x)    \n```\n\n```\ntf.Tensor(\n[[1 2 0 0]\n [3 4 5 0]], shape=(2, 4), dtype=int32)\ntf.Tensor(\n[[6 7 0 0]\n [8 0 0 0]], shape=(2, 4), dtype=int32)\n```\n\n```python\n\n```\n\n```python\n#window:构建滑动窗口，返回Dataset of Dataset.\n\nds = tf.data.Dataset.range(12)\n#window返回的是Dataset of Dataset,可以用flat_map压平\nds_window = ds.window(3, shift=1).flat_map(lambda x: x.batch(3,drop_remainder=True)) \nfor x in ds_window:\n    print(x)\n```\n\n```\ntf.Tensor([0 1 2], shape=(3,), dtype=int64)\ntf.Tensor([1 2 3], shape=(3,), dtype=int64)\ntf.Tensor([2 3 4], shape=(3,), dtype=int64)\ntf.Tensor([3 4 5], shape=(3,), dtype=int64)\ntf.Tensor([4 5 6], shape=(3,), dtype=int64)\ntf.Tensor([5 6 7], shape=(3,), dtype=int64)\ntf.Tensor([6 7 8], shape=(3,), dtype=int64)\ntf.Tensor([7 8 9], shape=(3,), dtype=int64)\ntf.Tensor([ 8  9 10], shape=(3,), dtype=int64)\ntf.Tensor([ 9 10 11], shape=(3,), dtype=int64)\n```\n\n```python\n\n```\n\n```python\n#shuffle:数据顺序洗牌。\n\nds = tf.data.Dataset.range(12)\nds_shuffle = ds.shuffle(buffer_size = 5)\nfor x in ds_shuffle:\n    print(x)\n    \n```\n\n```\ntf.Tensor(1, shape=(), dtype=int64)\ntf.Tensor(4, shape=(), dtype=int64)\ntf.Tensor(0, shape=(), dtype=int64)\ntf.Tensor(6, shape=(), dtype=int64)\ntf.Tensor(5, shape=(), dtype=int64)\ntf.Tensor(2, shape=(), dtype=int64)\ntf.Tensor(7, shape=(), dtype=int64)\ntf.Tensor(11, shape=(), dtype=int64)\ntf.Tensor(3, shape=(), dtype=int64)\ntf.Tensor(9, shape=(), dtype=int64)\ntf.Tensor(10, shape=(), dtype=int64)\ntf.Tensor(8, shape=(), dtype=int64)\n```\n\n```python\n\n```\n\n```python\n#repeat:重复数据若干次，不带参数时，重复无数次。\n\nds = tf.data.Dataset.range(3)\nds_repeat = ds.repeat(3)\nfor x in ds_repeat:\n    print(x)\n```\n\n```\ntf.Tensor(0, shape=(), dtype=int64)\ntf.Tensor(1, shape=(), dtype=int64)\ntf.Tensor(2, shape=(), dtype=int64)\ntf.Tensor(0, shape=(), dtype=int64)\ntf.Tensor(1, shape=(), dtype=int64)\ntf.Tensor(2, shape=(), dtype=int64)\ntf.Tensor(0, shape=(), dtype=int64)\ntf.Tensor(1, shape=(), dtype=int64)\ntf.Tensor(2, shape=(), dtype=int64)\n```\n\n```python\n#shard:采样，从某个位置开始隔固定距离采样一个元素。\n\nds = tf.data.Dataset.range(12)\nds_shard = ds.shard(3,index = 1)\n\nfor x in ds_shard:\n    print(x)\n```\n\n```\ntf.Tensor(1, shape=(), dtype=int64)\ntf.Tensor(4, shape=(), dtype=int64)\ntf.Tensor(7, shape=(), dtype=int64)\ntf.Tensor(10, shape=(), dtype=int64)\n```\n\n```python\n#take:采样，从开始位置取前几个元素。\n\nds = tf.data.Dataset.range(12)\nds_take = ds.take(3)\n\nlist(ds_take.as_numpy_iterator())\n\n```\n\n```\n[0, 1, 2]\n```\n\n```python\n\n```\n\n```python\n\n```\n\n### 三，提升管道性能\n\n\n训练深度学习模型常常会非常耗时。\n\n模型训练的耗时主要来自于两个部分，一部分来自**数据准备**，另一部分来自**参数迭代**。\n\n参数迭代过程的耗时通常依赖于GPU来提升。\n\n而数据准备过程的耗时则可以通过构建高效的数据管道进行提升。\n\n以下是一些构建高效数据管道的建议。\n\n* 1，使用 prefetch 方法让数据准备和参数迭代两个过程相互并行。\n\n* 2，使用 interleave 方法可以让数据读取过程多进程执行,并将不同来源数据夹在一起。\n\n* 3，使用 map 时设置num_parallel_calls 让数据转换过程多进行执行。\n\n* 4，使用 cache 方法让数据在第一个epoch后缓存到内存中，仅限于数据集不大情形。\n\n* 5，使用 map转换时，先batch, 然后采用向量化的转换方法对每个batch进行转换。\n\n```python\n\n```\n\n**1，使用 prefetch 方法让数据准备和参数迭代两个过程相互并行。**\n\n```python\nimport tensorflow as tf\n\n#打印时间分割线\n@tf.function\ndef printbar():\n    ts = tf.timestamp()\n    today_ts = ts%(24*60*60)\n\n    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\n    minite = tf.cast((today_ts%3600)//60,tf.int32)\n    second = tf.cast(tf.floor(today_ts%60),tf.int32)\n    \n    def timeformat(m):\n        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\n            return(tf.strings.format(\"0{}\",m))\n        else:\n            return(tf.strings.format(\"{}\",m))\n    \n    timestring = tf.strings.join([timeformat(hour),timeformat(minite),\n                timeformat(second)],separator = \":\")\n    tf.print(\"==========\"*8,end = \"\")\n    tf.print(timestring)\n    \n```\n\n```python\nimport time\n\n# 数据准备和参数迭代两个过程默认情况下是串行的。\n\n# 模拟数据准备\ndef generator():\n    for i in range(10):\n        #假设每次准备数据需要2s\n        time.sleep(2) \n        yield i \nds = tf.data.Dataset.from_generator(generator,output_types = (tf.int32))\n\n# 模拟参数迭代\ndef train_step():\n    #假设每一步训练需要1s\n    time.sleep(1) \n    \n```\n\n```python\n# 训练过程预计耗时 10*2+10*1+ = 30s\nprintbar()\ntf.print(tf.constant(\"start training...\"))\nfor x in ds:\n    train_step()  \nprintbar()\ntf.print(tf.constant(\"end training...\"))\n```\n\n```python\n# 使用 prefetch 方法让数据准备和参数迭代两个过程相互并行。\n\n# 训练过程预计耗时 max(10*2,10*1) = 20s\nprintbar()\ntf.print(tf.constant(\"start training with prefetch...\"))\n\n# tf.data.experimental.AUTOTUNE 可以让程序自动选择合适的参数\nfor x in ds.prefetch(buffer_size = tf.data.experimental.AUTOTUNE):\n    train_step()  \n    \nprintbar()\ntf.print(tf.constant(\"end training...\"))\n\n```\n\n```python\n\n```\n\n**2，使用 interleave 方法可以让数据读取过程多进程执行,并将不同来源数据夹在一起。**\n\n```python\nds_files = tf.data.Dataset.list_files(\"./data/titanic/*.csv\")\nds = ds_files.flat_map(lambda x:tf.data.TextLineDataset(x).skip(1))\nfor line in ds.take(4):\n    print(line)\n```\n\n```\ntf.Tensor(b'493,0,1,\"Molson, Mr. Harry Markland\",male,55.0,0,0,113787,30.5,C30,S', shape=(), dtype=string)\ntf.Tensor(b'53,1,1,\"Harper, Mrs. Henry Sleeper (Myna Haxtun)\",female,49.0,1,0,PC 17572,76.7292,D33,C', shape=(), dtype=string)\ntf.Tensor(b'388,1,2,\"Buss, Miss. Kate\",female,36.0,0,0,27849,13.0,,S', shape=(), dtype=string)\ntf.Tensor(b'192,0,2,\"Carbines, Mr. William\",male,19.0,0,0,28424,13.0,,S', shape=(), dtype=string)\n```\n\n```python\nds_files = tf.data.Dataset.list_files(\"./data/titanic/*.csv\")\nds = ds_files.interleave(lambda x:tf.data.TextLineDataset(x).skip(1))\nfor line in ds.take(8):\n    print(line)\n```\n\n```\ntf.Tensor(b'181,0,3,\"Sage, Miss. Constance Gladys\",female,,8,2,CA. 2343,69.55,,S', shape=(), dtype=string)\ntf.Tensor(b'493,0,1,\"Molson, Mr. Harry Markland\",male,55.0,0,0,113787,30.5,C30,S', shape=(), dtype=string)\ntf.Tensor(b'405,0,3,\"Oreskovic, Miss. Marija\",female,20.0,0,0,315096,8.6625,,S', shape=(), dtype=string)\ntf.Tensor(b'53,1,1,\"Harper, Mrs. Henry Sleeper (Myna Haxtun)\",female,49.0,1,0,PC 17572,76.7292,D33,C', shape=(), dtype=string)\ntf.Tensor(b'635,0,3,\"Skoog, Miss. Mabel\",female,9.0,3,2,347088,27.9,,S', shape=(), dtype=string)\ntf.Tensor(b'388,1,2,\"Buss, Miss. Kate\",female,36.0,0,0,27849,13.0,,S', shape=(), dtype=string)\ntf.Tensor(b'701,1,1,\"Astor, Mrs. John Jacob (Madeleine Talmadge Force)\",female,18.0,1,0,PC 17757,227.525,C62 C64,C', shape=(), dtype=string)\ntf.Tensor(b'192,0,2,\"Carbines, Mr. William\",male,19.0,0,0,28424,13.0,,S', shape=(), dtype=string)\n```\n\n```python\n\n```\n\n**3，使用 map 时设置num_parallel_calls 让数据转换过程多进行执行。**\n\n```python\nds = tf.data.Dataset.list_files(\"./data/cifar2/train/*/*.jpg\")\ndef load_image(img_path,size = (32,32)):\n    label = 1 if tf.strings.regex_full_match(img_path,\".*/automobile/.*\") else 0\n    img = tf.io.read_file(img_path)\n    img = tf.image.decode_jpeg(img) #注意此处为jpeg格式\n    img = tf.image.resize(img,size)\n    return(img,label)\n```\n\n```python\n#单进程转换\nprintbar()\ntf.print(tf.constant(\"start transformation...\"))\n\nds_map = ds.map(load_image)\nfor _ in ds_map:\n    pass\n\nprintbar()\ntf.print(tf.constant(\"end transformation...\"))\n```\n\n```python\n#多进程转换\nprintbar()\ntf.print(tf.constant(\"start parallel transformation...\"))\n\nds_map_parallel = ds.map(load_image,num_parallel_calls = tf.data.experimental.AUTOTUNE)\nfor _ in ds_map_parallel:\n    pass\n\nprintbar()\ntf.print(tf.constant(\"end parallel transformation...\"))\n```\n\n```python\n\n```\n\n**4，使用 cache 方法让数据在第一个epoch后缓存到内存中，仅限于数据集不大情形。**\n\n```python\nimport time\n\n# 模拟数据准备\ndef generator():\n    for i in range(5):\n        #假设每次准备数据需要2s\n        time.sleep(2) \n        yield i \nds = tf.data.Dataset.from_generator(generator,output_types = (tf.int32))\n\n# 模拟参数迭代\ndef train_step():\n    #假设每一步训练需要0s\n    pass\n\n# 训练过程预计耗时 (5*2+5*0)*3 = 30s\nprintbar()\ntf.print(tf.constant(\"start training...\"))\nfor epoch in tf.range(3):\n    for x in ds:\n        train_step()  \n    printbar()\n    tf.print(\"epoch =\",epoch,\" ended\")\nprintbar()\ntf.print(tf.constant(\"end training...\"))\n\n```\n\n```python\nimport time\n\n# 模拟数据准备\ndef generator():\n    for i in range(5):\n        #假设每次准备数据需要2s\n        time.sleep(2) \n        yield i \n\n# 使用 cache 方法让数据在第一个epoch后缓存到内存中，仅限于数据集不大情形。\nds = tf.data.Dataset.from_generator(generator,output_types = (tf.int32)).cache()\n\n# 模拟参数迭代\ndef train_step():\n    #假设每一步训练需要0s\n    time.sleep(0) \n\n# 训练过程预计耗时 (5*2+5*0)+(5*0+5*0)*2 = 10s\nprintbar()\ntf.print(tf.constant(\"start training...\"))\nfor epoch in tf.range(3):\n    for x in ds:\n        train_step()  \n    printbar()\n    tf.print(\"epoch =\",epoch,\" ended\")\nprintbar()\ntf.print(tf.constant(\"end training...\"))\n```\n\n```python\n\n```\n\n**5，使用 map转换时，先batch, 然后采用向量化的转换方法对每个batch进行转换。**\n\n```python\n#先map后batch\nds = tf.data.Dataset.range(100000)\nds_map_batch = ds.map(lambda x:x**2).batch(20)\n\nprintbar()\ntf.print(tf.constant(\"start scalar transformation...\"))\nfor x in ds_map_batch:\n    pass\nprintbar()\ntf.print(tf.constant(\"end scalar transformation...\"))\n\n```\n\n```python\n#先batch后map\nds = tf.data.Dataset.range(100000)\nds_batch_map = ds.batch(20).map(lambda x:x**2)\n\nprintbar()\ntf.print(tf.constant(\"start vector transformation...\"))\nfor x in ds_batch_map:\n    pass\nprintbar()\ntf.print(tf.constant(\"end vector transformation...\"))\n\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n```python\n\n```\n# 5-2,特征列feature_column\n\n特征列 通常用于对结构化数据实施特征工程时候使用，图像或者文本数据一般不会用到特征列。\n\n\n### 一，特征列用法概述\n\n\n使用特征列可以将类别特征转换为one-hot编码特征，将连续特征构建分桶特征，以及对多个特征生成交叉特征等等。\n\n\n要创建特征列，请调用 tf.feature_column 模块的函数。该模块中常用的九个函数如下图所示，所有九个函数都会返回一个 Categorical-Column 或一个 \nDense-Column 对象，但却不会返回 bucketized_column，后者继承自这两个类。\n\n注意：所有的Catogorical Column类型最终都要通过indicator_column转换成Dense Column类型才能传入模型！\n\n\n![](./data/特征列9种.jpg)\n\n\n* numeric_column 数值列，最常用。\n\n\n* bucketized_column 分桶列，由数值列生成，可以由一个数值列出多个特征，one-hot编码。\n\n\n* categorical_column_with_identity 分类标识列，one-hot编码，相当于分桶列每个桶为1个整数的情况。\n\n\n* categorical_column_with_vocabulary_list 分类词汇列，one-hot编码，由list指定词典。\n\n\n* categorical_column_with_vocabulary_file 分类词汇列，由文件file指定词典。\n\n\n* categorical_column_with_hash_bucket 哈希列，整数或词典较大时采用。\n\n\n* indicator_column 指标列，由Categorical Column生成，one-hot编码\n\n\n* embedding_column 嵌入列，由Categorical Column生成，嵌入矢量分布参数需要学习。嵌入矢量维数建议取类别数量的 4 次方根。\n\n\n* crossed_column 交叉列，可以由除categorical_column_with_hash_bucket的任意分类列构成。\n\n\n### 二，特征列使用范例\n\n\n以下是一个使用特征列解决Titanic生存问题的完整范例。\n\n```python\nimport datetime\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras import layers,models\n\n\n#打印日志\ndef printlog(info):\n    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n    print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n    print(info+'...\\n\\n')\n\n\n    \n```\n\n```python\n#================================================================================\n# 一，构建数据管道\n#================================================================================\nprintlog(\"step1: prepare dataset...\")\n\n\ndftrain_raw = pd.read_csv(\"./data/titanic/train.csv\")\ndftest_raw = pd.read_csv(\"./data/titanic/test.csv\")\n\ndfraw = pd.concat([dftrain_raw,dftest_raw])\n\ndef prepare_dfdata(dfraw):\n    dfdata = dfraw.copy()\n    dfdata.columns = [x.lower() for x in dfdata.columns]\n    dfdata = dfdata.rename(columns={'survived':'label'})\n    dfdata = dfdata.drop(['passengerid','name'],axis = 1)\n    for col,dtype in dict(dfdata.dtypes).items():\n        # 判断是否包含缺失值\n        if dfdata[col].hasnans:\n            # 添加标识是否缺失列\n            dfdata[col + '_nan'] = pd.isna(dfdata[col]).astype('int32')\n            # 填充\n            if dtype not in [np.object,np.str,np.unicode]:\n                dfdata[col].fillna(dfdata[col].mean(),inplace = True)\n            else:\n                dfdata[col].fillna('',inplace = True)\n    return(dfdata)\n\ndfdata = prepare_dfdata(dfraw)\ndftrain = dfdata.iloc[0:len(dftrain_raw),:]\ndftest = dfdata.iloc[len(dftrain_raw):,:]\n\n\n\n# 从 dataframe 导入数据 \ndef df_to_dataset(df, shuffle=True, batch_size=32):\n    dfdata = df.copy()\n    if 'label' not in dfdata.columns:\n        ds = tf.data.Dataset.from_tensor_slices(dfdata.to_dict(orient = 'list'))\n    else: \n        labels = dfdata.pop('label')\n        ds = tf.data.Dataset.from_tensor_slices((dfdata.to_dict(orient = 'list'), labels))  \n    if shuffle:\n        ds = ds.shuffle(buffer_size=len(dfdata))\n    ds = ds.batch(batch_size)\n    return ds\n\nds_train = df_to_dataset(dftrain)\nds_test = df_to_dataset(dftest)\n```\n\n```python\n#================================================================================\n# 二，定义特征列\n#================================================================================\nprintlog(\"step2: make feature columns...\")\n\nfeature_columns = []\n\n# 数值列\nfor col in ['age','fare','parch','sibsp'] + [\n    c for c in dfdata.columns if c.endswith('_nan')]:\n    feature_columns.append(tf.feature_column.numeric_column(col))\n\n# 分桶列\nage = tf.feature_column.numeric_column('age')\nage_buckets = tf.feature_column.bucketized_column(age, \n             boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\nfeature_columns.append(age_buckets)\n\n# 类别列\n# 注意：所有的Catogorical Column类型最终都要通过indicator_column转换成Dense Column类型才能传入模型！！\nsex = tf.feature_column.indicator_column(\n      tf.feature_column.categorical_column_with_vocabulary_list(\n      key='sex',vocabulary_list=[\"male\", \"female\"]))\nfeature_columns.append(sex)\n\npclass = tf.feature_column.indicator_column(\n      tf.feature_column.categorical_column_with_vocabulary_list(\n      key='pclass',vocabulary_list=[1,2,3]))\nfeature_columns.append(pclass)\n\nticket = tf.feature_column.indicator_column(\n     tf.feature_column.categorical_column_with_hash_bucket('ticket',3))\nfeature_columns.append(ticket)\n\nembarked = tf.feature_column.indicator_column(\n      tf.feature_column.categorical_column_with_vocabulary_list(\n      key='embarked',vocabulary_list=['S','C','B']))\nfeature_columns.append(embarked)\n\n# 嵌入列\ncabin = tf.feature_column.embedding_column(\n    tf.feature_column.categorical_column_with_hash_bucket('cabin',32),2)\nfeature_columns.append(cabin)\n\n# 交叉列\npclass_cate = tf.feature_column.categorical_column_with_vocabulary_list(\n          key='pclass',vocabulary_list=[1,2,3])\n\ncrossed_feature = tf.feature_column.indicator_column(\n    tf.feature_column.crossed_column([age_buckets, pclass_cate],hash_bucket_size=15))\n\nfeature_columns.append(crossed_feature)\n\n```\n\n```python\n#================================================================================\n# 三，定义模型\n#================================================================================\nprintlog(\"step3: define model...\")\n\ntf.keras.backend.clear_session()\nmodel = tf.keras.Sequential([\n  layers.DenseFeatures(feature_columns), #将特征列放入到tf.keras.layers.DenseFeatures中!!!\n  layers.Dense(64, activation='relu'),\n  layers.Dense(64, activation='relu'),\n  layers.Dense(1, activation='sigmoid')\n])\n\n```\n\n```python\n#================================================================================\n# 四，训练模型\n#================================================================================\nprintlog(\"step4: train model...\")\n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nhistory = model.fit(ds_train,\n          validation_data=ds_test,\n          epochs=10)\n```\n\n```python\n#================================================================================\n# 五，评估模型\n#================================================================================\nprintlog(\"step5: eval model...\")\n\nmodel.summary()\n\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\n\nimport matplotlib.pyplot as plt\n\ndef plot_metric(history, metric):\n    train_metrics = history.history[metric]\n    val_metrics = history.history['val_'+metric]\n    epochs = range(1, len(train_metrics) + 1)\n    plt.plot(epochs, train_metrics, 'bo--')\n    plt.plot(epochs, val_metrics, 'ro-')\n    plt.title('Training and validation '+ metric)\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(metric)\n    plt.legend([\"train_\"+metric, 'val_'+metric])\n    plt.show()\n\nplot_metric(history,\"accuracy\")\n```\n\n```\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_features (DenseFeature multiple                  64        \n_________________________________________________________________\ndense (Dense)                multiple                  3008      \n_________________________________________________________________\ndense_1 (Dense)              multiple                  4160      \n_________________________________________________________________\ndense_2 (Dense)              multiple                  65        \n=================================================================\nTotal params: 7,297\nTrainable params: 7,297\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n\n![](./data/5-2-01-模型评估.jpg)\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n\n\n# 5-3,激活函数activation\n\n激活函数在深度学习中扮演着非常重要的角色，它给网络赋予了非线性，从而使得神经网络能够拟合任意复杂的函数。\n\n如果没有激活函数，无论多复杂的网络，都等价于单一的线性变换，无法对非线性函数进行拟合。\n\n目前，深度学习中最流行的激活函数为 relu, 但也有些新推出的激活函数，例如 swish、GELU 据称效果优于relu激活函数。\n\n激活函数的综述介绍可以参考下面两篇文章。\n\n[《一文概览深度学习中的激活函数》](https://zhuanlan.zhihu.com/p/98472075)\n\nhttps://zhuanlan.zhihu.com/p/98472075\n\n[《从ReLU到GELU,一文概览神经网络中的激活函数》](https://zhuanlan.zhihu.com/p/98863801)\n\nhttps://zhuanlan.zhihu.com/p/98863801\n\n\n\n### 一，常用激活函数\n\n\n* tf.nn.sigmoid：将实数压缩到0到1之间，一般只在二分类的最后输出层使用。主要缺陷为存在梯度消失问题，计算复杂度高，输出不以0为中心。\n\n![](./data/sigmoid.png)\n\n* tf.nn.softmax：sigmoid的多分类扩展，一般只在多分类问题的最后输出层使用。\n\n![](./data/softmax说明.jpg)\n\n* tf.nn.tanh：将实数压缩到-1到1之间，输出期望为0。主要缺陷为存在梯度消失问题，计算复杂度高。\n\n![](./data/tanh.png)\n\n* tf.nn.relu：修正线性单元，最流行的激活函数。一般隐藏层使用。主要缺陷是：输出不以0为中心，输入小于0时存在梯度消失问题(死亡relu)。\n\n![](./data/relu.png)\n\n* tf.nn.leaky_relu：对修正线性单元的改进，解决了死亡relu问题。\n\n![](./data/leaky_relu.png)\n\n* tf.nn.elu：指数线性单元。对relu的改进，能够缓解死亡relu问题。\n\n![](./data/elu.png)\n\n* tf.nn.selu：扩展型指数线性单元。在权重用tf.keras.initializers.lecun_normal初始化前提下能够对神经网络进行自归一化。不可能出现梯度爆炸或者梯度消失问题。需要和Dropout的变种AlphaDropout一起使用。\n\n![](./data/selu.png)\n\n* tf.nn.swish：自门控激活函数。谷歌出品，相关研究指出用swish替代relu将获得轻微效果提升。\n\n![](./data/swish.png)\n\n* gelu：高斯误差线性单元激活函数。在Transformer中表现最好。tf.nn模块尚没有实现该函数。\n\n![](./data/gelu.png)\n\n```python\n\n```\n\n### 二，在模型中使用激活函数\n\n\n在keras模型中使用激活函数一般有两种方式，一种是作为某些层的activation参数指定，另一种是显式添加layers.Activation激活层。\n\n```python\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras import layers,models\n\ntf.keras.backend.clear_session()\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(32,input_shape = (None,16),activation = tf.nn.relu)) #通过activation参数指定\nmodel.add(layers.Dense(10))\nmodel.add(layers.Activation(tf.nn.softmax))  # 显式添加layers.Activation激活层\nmodel.summary()\n\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n```python\n\n```\n# 5-4,模型层layers\n\n深度学习模型一般由各种模型层组合而成。\n\ntf.keras.layers内置了非常丰富的各种功能的模型层。例如，\n\nlayers.Dense,layers.Flatten,layers.Input,layers.DenseFeature,layers.Dropout\n\nlayers.Conv2D,layers.MaxPooling2D,layers.Conv1D\n\nlayers.Embedding,layers.GRU,layers.LSTM,layers.Bidirectional等等。\n\n如果这些内置模型层不能够满足需求，我们也可以通过编写tf.keras.Lambda匿名模型层或继承tf.keras.layers.Layer基类构建自定义的模型层。\n\n其中tf.keras.Lambda匿名模型层只适用于构造没有学习参数的模型层。\n\n```python\n\n```\n\n### 一，内置模型层\n\n```python\n\n```\n\n一些常用的内置模型层简单介绍如下。\n\n**基础层**\n\n* Dense：密集连接层。参数个数 = 输入层特征数× 输出层特征数(weight)＋ 输出层特征数(bias)\n\n* Activation：激活函数层。一般放在Dense层后面，等价于在Dense层中指定activation。\n\n* Dropout：随机置零层。训练期间以一定几率将输入置0，一种正则化手段。\n\n* BatchNormalization：批标准化层。通过线性变换将输入批次缩放平移到稳定的均值和标准差。可以增强模型对输入不同分布的适应性，加快模型训练速度，有轻微正则化效果。一般在激活函数之前使用。\n\n* SpatialDropout2D：空间随机置零层。训练期间以一定几率将整个特征图置0，一种正则化手段，有利于避免特征图之间过高的相关性。\n\n* Input：输入层。通常使用Functional API方式构建模型时作为第一层。\n\n* DenseFeature：特征列接入层，用于接收一个特征列列表并产生一个密集连接层。\n\n* Flatten：压平层，用于将多维张量压成一维。\n\n* Reshape：形状重塑层，改变输入张量的形状。\n\n* Concatenate：拼接层，将多个张量在某个维度上拼接。\n\n* Add：加法层。\n\n* Subtract： 减法层。\n\n* Maximum：取最大值层。\n\n* Minimum：取最小值层。\n\n\n**卷积网络相关层**\n\n* Conv1D：普通一维卷积，常用于文本。参数个数 = 输入通道数×卷积核尺寸(如3)×卷积核个数\n\n* Conv2D：普通二维卷积，常用于图像。参数个数 = 输入通道数×卷积核尺寸(如3乘3)×卷积核个数\n\n* Conv3D：普通三维卷积，常用于视频。参数个数 = 输入通道数×卷积核尺寸(如3乘3乘3)×卷积核个数\n\n* SeparableConv2D：二维深度可分离卷积层。不同于普通卷积同时对区域和通道操作，深度可分离卷积先操作区域，再操作通道。即先对每个通道做独立卷即先操作区域，再用1乘1卷积跨通道组合即再操作通道。参数个数 = 输入通道数×卷积核尺寸 + 输入通道数×1×1×输出通道数。深度可分离卷积的参数数量一般远小于普通卷积，效果一般也更好。\n\n* DepthwiseConv2D：二维深度卷积层。仅有SeparableConv2D前半部分操作，即只操作区域，不操作通道，一般输出通道数和输入通道数相同，但也可以通过设置depth_multiplier让输出通道为输入通道的若干倍数。输出通道数 = 输入通道数 × depth_multiplier。参数个数 = 输入通道数×卷积核尺寸× depth_multiplier。\n\n* Conv2DTranspose：二维卷积转置层，俗称反卷积层。并非卷积的逆操作，但在卷积核相同的情况下，当其输入尺寸是卷积操作输出尺寸的情况下，卷积转置的输出尺寸恰好是卷积操作的输入尺寸。\n\n* LocallyConnected2D: 二维局部连接层。类似Conv2D，唯一的差别是没有空间上的权值共享，所以其参数个数远高于二维卷积。\n\n* MaxPooling2D: 二维最大池化层。也称作下采样层。池化层无参数，主要作用是降维。\n\n* AveragePooling2D: 二维平均池化层。\n\n* GlobalMaxPool2D: 全局最大池化层。每个通道仅保留一个值。一般从卷积层过渡到全连接层时使用，是Flatten的替代方案。\n\n* GlobalAvgPool2D: 全局平均池化层。每个通道仅保留一个值。\n\n\n**循环网络相关层**\n\n* Embedding：嵌入层。一种比Onehot更加有效的对离散特征进行编码的方法。一般用于将输入中的单词映射为稠密向量。嵌入层的参数需要学习。\n\n* LSTM：长短记忆循环网络层。最普遍使用的循环网络层。具有携带轨道，遗忘门，更新门，输出门。可以较为有效地缓解梯度消失问题，从而能够适用长期依赖问题。设置return_sequences = True时可以返回各个中间步骤输出，否则只返回最终输出。\n\n* GRU：门控循环网络层。LSTM的低配版，不具有携带轨道，参数数量少于LSTM，训练速度更快。\n\n* SimpleRNN：简单循环网络层。容易存在梯度消失，不能够适用长期依赖问题。一般较少使用。\n\n* ConvLSTM2D：卷积长短记忆循环网络层。结构上类似LSTM，但对输入的转换操作和对状态的转换操作都是卷积运算。\n\n* Bidirectional：双向循环网络包装器。可以将LSTM，GRU等层包装成双向循环网络。从而增强特征提取能力。\n\n* RNN：RNN基本层。接受一个循环网络单元或一个循环单元列表，通过调用tf.keras.backend.rnn函数在序列上进行迭代从而转换成循环网络层。\n\n* LSTMCell：LSTM单元。和LSTM在整个序列上迭代相比，它仅在序列上迭代一步。可以简单理解LSTM即RNN基本层包裹LSTMCell。\n\n* GRUCell：GRU单元。和GRU在整个序列上迭代相比，它仅在序列上迭代一步。\n\n* SimpleRNNCell：SimpleRNN单元。和SimpleRNN在整个序列上迭代相比，它仅在序列上迭代一步。\n\n* AbstractRNNCell：抽象RNN单元。通过对它的子类化用户可以自定义RNN单元，再通过RNN基本层的包裹实现用户自定义循环网络层。\n\n* Attention：Dot-product类型注意力机制层。可以用于构建注意力模型。\n\n* AdditiveAttention：Additive类型注意力机制层。可以用于构建注意力模型。\n\n* TimeDistributed：时间分布包装器。包装后可以将Dense、Conv2D等作用到每一个时间片段上。\n\n```python\n\n```\n\n### 二，自定义模型层\n\n\n如果自定义模型层没有需要被训练的参数，一般推荐使用Lamda层实现。\n\n如果自定义模型层有需要被训练的参数，则可以通过对Layer基类子类化实现。\n\nLamda层由于没有需要被训练的参数，只需要定义正向传播逻辑即可，使用比Layer基类子类化更加简单。\n\nLamda层的正向逻辑可以使用Python的lambda函数来表达，也可以用def关键字定义函数来表达。\n\n```python\nimport tensorflow as tf\nfrom tensorflow.keras import layers,models,regularizers\n\nmypower = layers.Lambda(lambda x:tf.math.pow(x,2))\nmypower(tf.range(5))\n```\n\n```\n<tf.Tensor: shape=(5,), dtype=int32, numpy=array([ 0,  1,  4,  9, 16], dtype=int32)>\n```\n\n\nLayer的子类化一般需要重新实现初始化方法，Build方法和Call方法。下面是一个简化的线性层的范例，类似Dense.\n\n```python\nclass Linear(layers.Layer):\n    def __init__(self, units=32, **kwargs):\n        super(Linear, self).__init__(**kwargs)\n        self.units = units\n\n    #build方法一般定义Layer需要被训练的参数。    \n    def build(self, input_shape): \n        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n                                 initializer='random_normal',\n                                 trainable=True)\n        self.b = self.add_weight(shape=(self.units,),\n                                 initializer='random_normal',\n                                 trainable=True)\n        super(Linear,self).build(input_shape) # 相当于设置self.built = True\n\n    #call方法一般定义正向传播运算逻辑，__call__方法调用了它。    \n    def call(self, inputs): \n        return tf.matmul(inputs, self.w) + self.b\n    \n    #如果要让自定义的Layer通过Functional API 组合成模型时可以序列化，需要自定义get_config方法。\n    def get_config(self):  \n        config = super(Linear, self).get_config()\n        config.update({'units': self.units})\n        return config\n\n```\n\n```python\nlinear = Linear(units = 8)\nprint(linear.built)\n#指定input_shape，显式调用build方法，第0维代表样本数量，用None填充\nlinear.build(input_shape = (None,16)) \nprint(linear.built)\n```\n\n```\nFalse\nTrue\n```\n\n```python\nlinear = Linear(units = 8)\nprint(linear.built)\nlinear.build(input_shape = (None,16)) \nprint(linear.compute_output_shape(input_shape = (None,16)))\n```\n\n```\nFalse\n(None, 8)\n```\n\n```python\nlinear = Linear(units = 16)\nprint(linear.built)\n#如果built = False，调用__call__时会先调用build方法, 再调用call方法。\nlinear(tf.random.uniform((100,64))) \nprint(linear.built)\nconfig = linear.get_config()\nprint(config)\n```\n\n```\nFalse\nTrue\n{'name': 'linear_3', 'trainable': True, 'dtype': 'float32', 'units': 16}\n```\n\n```python\ntf.keras.backend.clear_session()\n\nmodel = models.Sequential()\n#注意该处的input_shape会被模型加工，无需使用None代表样本数量维\nmodel.add(Linear(units = 16,input_shape = (64,)))  \nprint(\"model.input_shape: \",model.input_shape)\nprint(\"model.output_shape: \",model.output_shape)\nmodel.summary()\n```\n\n```\nmodel.input_shape:  (None, 64)\nmodel.output_shape:  (None, 16)\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlinear (Linear)              (None, 16)                1040      \n=================================================================\nTotal params: 1,040\nTrainable params: 1,040\nNon-trainable params: 0\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n```python\n\n```\n# 5-5,损失函数losses\n\n一般来说，监督学习的目标函数由损失函数和正则化项组成。（Objective = Loss + Regularization）\n\n对于keras模型，目标函数中的正则化项一般在各层中指定，例如使用Dense的 kernel_regularizer 和 bias_regularizer等参数指定权重使用l1或者l2正则化项，此外还可以用kernel_constraint 和 bias_constraint等参数约束权重的取值范围，这也是一种正则化手段。\n\n损失函数在模型编译时候指定。对于回归模型，通常使用的损失函数是平方损失函数 mean_squared_error。\n\n对于二分类模型，通常使用的是二元交叉熵损失函数 binary_crossentropy。\n\n对于多分类模型，如果label是类别序号编码的，则使用类别交叉熵损失函数 categorical_crossentropy。如果label进行了one-hot编码，则需要使用稀疏类别交叉熵损失函数 sparse_categorical_crossentropy。\n\n如果有需要，也可以自定义损失函数，自定义损失函数需要接收两个张量y_true,y_pred作为输入参数，并输出一个标量作为损失函数值。\n\n\n```python\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras import layers,models,losses,regularizers,constraints\n```\n\n### 一，损失函数和正则化项\n\n```python\ntf.keras.backend.clear_session()\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(64, input_dim=64,\n                kernel_regularizer=regularizers.l2(0.01), \n                activity_regularizer=regularizers.l1(0.01),\n                kernel_constraint = constraints.MaxNorm(max_value=2, axis=0))) \nmodel.add(layers.Dense(10,\n        kernel_regularizer=regularizers.l1_l2(0.01,0.01),activation = \"sigmoid\"))\nmodel.compile(optimizer = \"rmsprop\",\n        loss = \"sparse_categorical_crossentropy\",metrics = [\"AUC\"])\nmodel.summary()\n\n```\n\n```\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 64)                4160      \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                650       \n=================================================================\nTotal params: 4,810\nTrainable params: 4,810\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n\n### 二，内置损失函数\n\n\n内置的损失函数一般有类的实现和函数的实现两种形式。\n\n如：CategoricalCrossentropy 和 categorical_crossentropy 都是类别交叉熵损失函数，前者是类的实现形式，后者是函数的实现形式。\n\n常用的一些内置损失函数说明如下。\n\n* mean_squared_error（平方差误差损失，用于回归，简写为 mse, 类实现形式为 MeanSquaredError 和 MSE）\n\n* mean_absolute_error (绝对值误差损失，用于回归，简写为 mae, 类实现形式为 MeanAbsoluteError 和 MAE)\n\n* mean_absolute_percentage_error (平均百分比误差损失，用于回归，简写为 mape, 类实现形式为 MeanAbsolutePercentageError 和 MAPE)\n\n* Huber(Huber损失，只有类实现形式，用于回归，介于mse和mae之间，对异常值比较鲁棒，相对mse有一定的优势)\n\n* binary_crossentropy(二元交叉熵，用于二分类，类实现形式为 BinaryCrossentropy)\n\n* categorical_crossentropy(类别交叉熵，用于多分类，要求label为onehot编码，类实现形式为 CategoricalCrossentropy)\n\n* sparse_categorical_crossentropy(稀疏类别交叉熵，用于多分类，要求label为序号编码形式，类实现形式为 SparseCategoricalCrossentropy)\n\n* hinge(合页损失函数，用于二分类，最著名的应用是作为支持向量机SVM的损失函数，类实现形式为 Hinge)\n\n* kld(相对熵损失，也叫KL散度，常用于最大期望算法EM的损失函数，两个概率分布差异的一种信息度量。类实现形式为 KLDivergence 或 KLD)\n\n* cosine_similarity(余弦相似度，可用于多分类，类实现形式为 CosineSimilarity)\n\n```python\n\n```\n\n### 三，自定义损失函数\n\n\n自定义损失函数接收两个张量y_true,y_pred作为输入参数，并输出一个标量作为损失函数值。\n\n也可以对tf.keras.losses.Loss进行子类化，重写call方法实现损失的计算逻辑，从而得到损失函数的类的实现。\n\n下面是一个Focal Loss的自定义实现示范。Focal Loss是一种对binary_crossentropy的改进损失函数形式。\n\n在类别不平衡和存在难以训练样本的情形下相对于二元交叉熵能够取得更好的效果。\n\n详见《如何评价Kaiming的Focal Loss for Dense Object Detection？》\n\nhttps://www.zhihu.com/question/63581984\n\n```python\ndef focal_loss(gamma=2., alpha=.25):\n    \n    def focal_loss_fixed(y_true, y_pred):\n        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n        loss = -tf.sum(alpha * tf.pow(1. - pt_1, gamma) * tf.log(1e-07+pt_1)) \\\n           -tf.sum((1-alpha) * tf.pow( pt_0, gamma) * tf.log(1. - pt_0 + 1e-07))\n        return loss\n    return focal_loss_fixed\n\n```\n\n```python\nclass FocalLoss(losses.Loss):\n    \n    def __init__(self,gamma=2.0,alpha=0.25):\n        self.gamma = gamma\n        self.alpha = alpha\n\n    def call(self,y_true,y_pred):\n        \n        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n        loss = -tf.sum(self.alpha * tf.pow(1. - pt_1, self.gamma) * tf.log(1e-07+pt_1)) \\\n           -tf.sum((1-self.alpha) * tf.pow( pt_0, self.gamma) * tf.log(1. - pt_0 + 1e-07))\n        return loss\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n```python\n\n```\n# 5-6,评估指标metrics\n\n损失函数除了作为模型训练时候的优化目标，也能够作为模型好坏的一种评价指标。但通常人们还会从其它角度评估模型的好坏。\n\n这就是评估指标。通常损失函数都可以作为评估指标，如MAE,MSE,CategoricalCrossentropy等也是常用的评估指标。\n\n但评估指标不一定可以作为损失函数，例如AUC,Accuracy,Precision。因为评估指标不要求连续可导，而损失函数通常要求连续可导。\n\n编译模型时，可以通过列表形式指定多个评估指标。\n\n如果有需要，也可以自定义评估指标。\n\n自定义评估指标需要接收两个张量y_true,y_pred作为输入参数，并输出一个标量作为评估值。\n\n也可以对tf.keras.metrics.Metric进行子类化，重写初始化方法, update_state方法, result方法实现评估指标的计算逻辑，从而得到评估指标的类的实现形式。\n\n由于训练的过程通常是分批次训练的，而评估指标要跑完一个epoch才能够得到整体的指标结果。因此，类形式的评估指标更为常见。即需要编写初始化方法以创建与计算指标结果相关的一些中间变量，编写update_state方法在每个batch后更新相关中间变量的状态，编写result方法输出最终指标结果。\n\n如果编写函数形式的评估指标，则只能取epoch中各个batch计算的评估指标结果的平均值作为整个epoch上的评估指标结果，这个结果通常会偏离拿整个epoch数据一次计算的结果。\n\n\n\n### 一，常用的内置评估指标\n\n\n* MeanSquaredError（平方差误差，用于回归，可以简写为MSE，函数形式为mse）\n\n* MeanAbsoluteError (绝对值误差，用于回归，可以简写为MAE，函数形式为mae)\n\n* MeanAbsolutePercentageError (平均百分比误差，用于回归，可以简写为MAPE，函数形式为mape)\n\n* RootMeanSquaredError (均方根误差，用于回归)\n\n* Accuracy (准确率，用于分类，可以用字符串\"Accuracy\"表示，Accuracy=(TP+TN)/(TP+TN+FP+FN)，要求y_true和y_pred都为类别序号编码)\n\n* Precision (精确率，用于二分类，Precision = TP/(TP+FP))\n\n* Recall (召回率，用于二分类，Recall = TP/(TP+FN))\n\n* TruePositives (真正例，用于二分类)\n\n* TrueNegatives (真负例，用于二分类)\n\n* FalsePositives (假正例，用于二分类)\n\n* FalseNegatives (假负例，用于二分类)\n\n* AUC(ROC曲线(TPR vs FPR)下的面积，用于二分类，直观解释为随机抽取一个正样本和一个负样本，正样本的预测值大于负样本的概率)\n\n* CategoricalAccuracy（分类准确率，与Accuracy含义相同，要求y_true(label)为onehot编码形式）\n\n* SparseCategoricalAccuracy (稀疏分类准确率，与Accuracy含义相同，要求y_true(label)为序号编码形式)\n\n* MeanIoU (Intersection-Over-Union，常用于图像分割)\n\n* TopKCategoricalAccuracy (多分类TopK准确率，要求y_true(label)为onehot编码形式)\n\n* SparseTopKCategoricalAccuracy (稀疏多分类TopK准确率，要求y_true(label)为序号编码形式)\n\n* Mean (平均值)\n\n* Sum (求和)\n\n```python\n\n```\n\n```python\n\n```\n\n### 二， 自定义评估指标\n\n\n我们以金融风控领域常用的KS指标为例，示范自定义评估指标。\n\nKS指标适合二分类问题，其计算方式为 KS=max(TPR-FPR).\n\n其中TPR=TP/(TP+FN) , FPR = FP/(FP+TN) \n\nTPR曲线实际上就是正样本的累积分布曲线(CDF)，FPR曲线实际上就是负样本的累积分布曲线(CDF)。\n\nKS指标就是正样本和负样本累积分布曲线差值的最大值。\n\n![](./data/KS_curve.png)\n\n```python\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras import layers,models,losses,metrics\n\n#函数形式的自定义评估指标\n@tf.function\ndef ks(y_true,y_pred):\n    y_true = tf.reshape(y_true,(-1,))\n    y_pred = tf.reshape(y_pred,(-1,))\n    length = tf.shape(y_true)[0]\n    t = tf.math.top_k(y_pred,k = length,sorted = False)\n    y_pred_sorted = tf.gather(y_pred,t.indices)\n    y_true_sorted = tf.gather(y_true,t.indices)\n    cum_positive_ratio = tf.truediv(\n        tf.cumsum(y_true_sorted),tf.reduce_sum(y_true_sorted))\n    cum_negative_ratio = tf.truediv(\n        tf.cumsum(1 - y_true_sorted),tf.reduce_sum(1 - y_true_sorted))\n    ks_value = tf.reduce_max(tf.abs(cum_positive_ratio - cum_negative_ratio)) \n    return ks_value\n```\n\n```python\ny_true = tf.constant([[1],[1],[1],[0],[1],[1],[1],[0],[0],[0],[1],[0],[1],[0]])\ny_pred = tf.constant([[0.6],[0.1],[0.4],[0.5],[0.7],[0.7],[0.7],\n                      [0.4],[0.4],[0.5],[0.8],[0.3],[0.5],[0.3]])\ntf.print(ks(y_true,y_pred))\n```\n\n```\n0.625\n```\n\n```python\n#类形式的自定义评估指标\nclass KS(metrics.Metric):\n    \n    def __init__(self, name = \"ks\", **kwargs):\n        super(KS,self).__init__(name=name,**kwargs)\n        self.true_positives = self.add_weight(\n            name = \"tp\",shape = (101,), initializer = \"zeros\")\n        self.false_positives = self.add_weight(\n            name = \"fp\",shape = (101,), initializer = \"zeros\")\n   \n    @tf.function\n    def update_state(self,y_true,y_pred):\n        y_true = tf.cast(tf.reshape(y_true,(-1,)),tf.bool)\n        y_pred = tf.cast(100*tf.reshape(y_pred,(-1,)),tf.int32)\n        \n        for i in tf.range(0,tf.shape(y_true)[0]):\n            if y_true[i]:\n                self.true_positives[y_pred[i]].assign(\n                    self.true_positives[y_pred[i]]+1.0)\n            else:\n                self.false_positives[y_pred[i]].assign(\n                    self.false_positives[y_pred[i]]+1.0)\n        return (self.true_positives,self.false_positives)\n    \n    @tf.function\n    def result(self):\n        cum_positive_ratio = tf.truediv(\n            tf.cumsum(self.true_positives),tf.reduce_sum(self.true_positives))\n        cum_negative_ratio = tf.truediv(\n            tf.cumsum(self.false_positives),tf.reduce_sum(self.false_positives))\n        ks_value = tf.reduce_max(tf.abs(cum_positive_ratio - cum_negative_ratio)) \n        return ks_value\n\n```\n\n```python\ny_true = tf.constant([[1],[1],[1],[0],[1],[1],[1],[0],[0],[0],[1],[0],[1],[0]])\ny_pred = tf.constant([[0.6],[0.1],[0.4],[0.5],[0.7],[0.7],\n                      [0.7],[0.4],[0.4],[0.5],[0.8],[0.3],[0.5],[0.3]])\n\nmyks = KS()\nmyks.update_state(y_true,y_pred)\ntf.print(myks.result())\n\n```\n\n```\n0.625\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n# 5-7,优化器optimizers\n\n机器学习界有一群炼丹师，他们每天的日常是：\n\n拿来药材（数据），架起八卦炉（模型），点着六味真火（优化算法），就摇着蒲扇等着丹药出炉了。\n\n不过，当过厨子的都知道，同样的食材，同样的菜谱，但火候不一样了，这出来的口味可是千差万别。火小了夹生，火大了易糊，火不匀则半生半糊。\n\n机器学习也是一样，模型优化算法的选择直接关系到最终模型的性能。有时候效果不好，未必是特征的问题或者模型设计的问题，很可能就是优化算法的问题。\n\n深度学习优化算法大概经历了 SGD -> SGDM -> NAG ->Adagrad -> Adadelta(RMSprop) -> Adam -> Nadam 这样的发展历程。\n\n详见《一个框架看懂优化算法之异同 SGD/AdaGrad/Adam》\n\nhttps://zhuanlan.zhihu.com/p/32230623\n\n对于一般新手炼丹师，优化器直接使用Adam，并使用其默认参数就OK了。\n\n一些爱写论文的炼丹师由于追求评估指标效果，可能会偏爱前期使用Adam优化器快速下降，后期使用SGD并精调优化器参数得到更好的结果。\n\n此外目前也有一些前沿的优化算法，据称效果比Adam更好，例如LazyAdam, Look-ahead, RAdam, Ranger等.\n\n\n```python\n\n```\n\n### 一，优化器的使用\n\n\n优化器主要使用apply_gradients方法传入变量和对应梯度从而来对给定变量进行迭代，或者直接使用minimize方法对目标函数进行迭代优化。\n\n当然，更常见的使用是在编译时将优化器传入keras的Model,通过调用model.fit实现对Loss的的迭代优化。\n\n初始化优化器时会创建一个变量optimier.iterations用于记录迭代的次数。因此优化器和tf.Variable一样，一般需要在@tf.function外创建。\n\n```python\nimport tensorflow as tf\nimport numpy as np \n\n#打印时间分割线\n@tf.function\ndef printbar():\n    ts = tf.timestamp()\n    today_ts = ts%(24*60*60)\n\n    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\n    minite = tf.cast((today_ts%3600)//60,tf.int32)\n    second = tf.cast(tf.floor(today_ts%60),tf.int32)\n    \n    def timeformat(m):\n        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\n            return(tf.strings.format(\"0{}\",m))\n        else:\n            return(tf.strings.format(\"{}\",m))\n    \n    timestring = tf.strings.join([timeformat(hour),timeformat(minite),\n                timeformat(second)],separator = \":\")\n    tf.print(\"==========\"*8,end = \"\")\n    tf.print(timestring)\n    \n```\n\n```python\n# 求f(x) = a*x**2 + b*x + c的最小值\n\n# 使用optimizer.apply_gradients\n\nx = tf.Variable(0.0,name = \"x\",dtype = tf.float32)\noptimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n\n@tf.function\ndef minimizef():\n    a = tf.constant(1.0)\n    b = tf.constant(-2.0)\n    c = tf.constant(1.0)\n    \n    while tf.constant(True): \n        with tf.GradientTape() as tape:\n            y = a*tf.pow(x,2) + b*x + c\n        dy_dx = tape.gradient(y,x)\n        optimizer.apply_gradients(grads_and_vars=[(dy_dx,x)])\n        \n        #迭代终止条件\n        if tf.abs(dy_dx)<tf.constant(0.00001):\n            break\n            \n        if tf.math.mod(optimizer.iterations,100)==0:\n            printbar()\n            tf.print(\"step = \",optimizer.iterations)\n            tf.print(\"x = \", x)\n            tf.print(\"\")\n                \n    y = a*tf.pow(x,2) + b*x + c\n    return y\n\ntf.print(\"y =\",minimizef())\ntf.print(\"x =\",x)\n```\n\n```python\n\n```\n\n```python\n# 求f(x) = a*x**2 + b*x + c的最小值\n\n# 使用optimizer.minimize\n\nx = tf.Variable(0.0,name = \"x\",dtype = tf.float32)\noptimizer = tf.keras.optimizers.SGD(learning_rate=0.01)   \n\ndef f():   \n    a = tf.constant(1.0)\n    b = tf.constant(-2.0)\n    c = tf.constant(1.0)\n    y = a*tf.pow(x,2)+b*x+c\n    return(y)\n\n@tf.function\ndef train(epoch = 1000):  \n    for _ in tf.range(epoch):  \n        optimizer.minimize(f,[x])\n    tf.print(\"epoch = \",optimizer.iterations)\n    return(f())\n\ntrain(1000)\ntf.print(\"y = \",f())\ntf.print(\"x = \",x)\n\n```\n\n```python\n\n```\n\n```python\n# 求f(x) = a*x**2 + b*x + c的最小值\n# 使用model.fit\n\ntf.keras.backend.clear_session()\n\nclass FakeModel(tf.keras.models.Model):\n    def __init__(self,a,b,c):\n        super(FakeModel,self).__init__()\n        self.a = a\n        self.b = b\n        self.c = c\n    \n    def build(self):\n        self.x = tf.Variable(0.0,name = \"x\")\n        self.built = True\n    \n    def call(self,features):\n        loss  = self.a*(self.x)**2+self.b*(self.x)+self.c\n        return(tf.ones_like(features)*loss)\n    \ndef myloss(y_true,y_pred):\n    return tf.reduce_mean(y_pred)\n\nmodel = FakeModel(tf.constant(1.0),tf.constant(-2.0),tf.constant(1.0))\n\nmodel.build()\nmodel.summary()\n\nmodel.compile(optimizer = \n              tf.keras.optimizers.SGD(learning_rate=0.01),loss = myloss)\nhistory = model.fit(tf.zeros((100,2)),\n                    tf.ones(100),batch_size = 1,epochs = 10)  #迭代1000次\n\n```\n\n```python\ntf.print(\"x=\",model.x)\ntf.print(\"loss=\",model(tf.constant(0.0)))\n```\n\n```python\n\n```\n\n### 二，内置优化器\n\n\n深度学习优化算法大概经历了 SGD -> SGDM -> NAG ->Adagrad -> Adadelta(RMSprop) -> Adam -> Nadam 这样的发展历程。\n\n在keras.optimizers子模块中，它们基本上都有对应的类的实现。\n\n* SGD, 默认参数为纯SGD, 设置momentum参数不为0实际上变成SGDM, 考虑了一阶动量, 设置 nesterov为True后变成NAG，即 Nesterov Acceleration Gradient，在计算梯度时计算的是向前走一步所在位置的梯度。\n\n* Adagrad, 考虑了二阶动量，对于不同的参数有不同的学习率，即自适应学习率。缺点是学习率单调下降，可能后期学习速率过慢乃至提前停止学习。\n\n* RMSprop, 考虑了二阶动量，对于不同的参数有不同的学习率，即自适应学习率，对Adagrad进行了优化，通过指数平滑只考虑一定窗口内的二阶动量。\n\n* Adadelta, 考虑了二阶动量，与RMSprop类似，但是更加复杂一些，自适应性更强。\n\n* Adam, 同时考虑了一阶动量和二阶动量，可以看成RMSprop上进一步考虑了Momentum。\n\n* Nadam, 在Adam基础上进一步考虑了 Nesterov Acceleration。\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n```python\n\n```\n\n```python\n\n```\n# 5-8,回调函数callbacks\n\ntf.keras的回调函数实际上是一个类，一般是在model.fit时作为参数指定，用于控制在训练过程开始或者在训练过程结束，在每个epoch训练开始或者训练结束，在每个batch训练开始或者训练结束时执行一些操作，例如收集一些日志信息，改变学习率等超参数，提前终止训练过程等等。\n\n同样地，针对model.evaluate或者model.predict也可以指定callbacks参数，用于控制在评估或预测开始或者结束时，在每个batch开始或者结束时执行一些操作，但这种用法相对少见。\n\n大部分时候，keras.callbacks子模块中定义的回调函数类已经足够使用了，如果有特定的需要，我们也可以通过对keras.callbacks.Callbacks实施子类化构造自定义的回调函数。\n\n所有回调函数都继承至 keras.callbacks.Callbacks基类，拥有params和model这两个属性。\n\n其中params 是一个dict，记录了 training parameters (eg. verbosity, batch size, number of epochs...).\n\nmodel即当前关联的模型的引用。\n\n此外，对于回调类中的一些方法如on_epoch_begin,on_batch_end，还会有一个输入参数logs, 提供有关当前epoch或者batch的一些信息，并能够记录计算结果，如果model.fit指定了多个回调函数类，这些logs变量将在这些回调函数类的同名函数间依顺序传递。\n\n\n\n### 一，内置回调函数\n\n\n* BaseLogger： 收集每个epoch上metrics在各个batch上的平均值，对stateful_metrics参数中的带中间状态的指标直接拿最终值无需对各个batch平均，指标均值结果将添加到logs变量中。该回调函数被所有模型默认添加，且是第一个被添加的。\n\n* History： 将BaseLogger计算的各个epoch的metrics结果记录到history这个dict变量中，并作为model.fit的返回值。该回调函数被所有模型默认添加，在BaseLogger之后被添加。\n\n* EarlyStopping： 当被监控指标在设定的若干个epoch后没有提升，则提前终止训练。\n\n* TensorBoard： 为Tensorboard可视化保存日志信息。支持评估指标，计算图，模型参数等的可视化。\n\n* ModelCheckpoint： 在每个epoch后保存模型。\n\n* ReduceLROnPlateau：如果监控指标在设定的若干个epoch后没有提升，则以一定的因子减少学习率。\n\n* TerminateOnNaN：如果遇到loss为NaN，提前终止训练。\n\n* LearningRateScheduler：学习率控制器。给定学习率lr和epoch的函数关系，根据该函数关系在每个epoch前调整学习率。\n\n* CSVLogger：将每个epoch后的logs结果记录到CSV文件中。\n\n* ProgbarLogger：将每个epoch后的logs结果打印到标准输出流中。\n\n\n\n```python\n\n```\n\n### 二，自定义回调函数\n\n\n可以使用callbacks.LambdaCallback编写较为简单的回调函数，也可以通过对callbacks.Callback子类化编写更加复杂的回调函数逻辑。\n\n如果需要深入学习tf.Keras中的回调函数，不要犹豫阅读内置回调函数的源代码。\n\n```python\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras import layers,models,losses,metrics,callbacks\nimport tensorflow.keras.backend as K \n\n```\n\n```python\n# 示范使用LambdaCallback编写较为简单的回调函数\n\nimport json\njson_log = open('./data/keras_log.json', mode='wt', buffering=1)\njson_logging_callback = callbacks.LambdaCallback(\n    on_epoch_end=lambda epoch, logs: json_log.write(\n        json.dumps(dict(epoch = epoch,**logs)) + '\\n'),\n    on_train_end=lambda logs: json_log.close()\n)\n\n```\n\n```python\n# 示范通过Callback子类化编写回调函数（LearningRateScheduler的源代码）\n\nclass LearningRateScheduler(callbacks.Callback):\n    \n    def __init__(self, schedule, verbose=0):\n        super(LearningRateScheduler, self).__init__()\n        self.schedule = schedule\n        self.verbose = verbose\n\n    def on_epoch_begin(self, epoch, logs=None):\n        if not hasattr(self.model.optimizer, 'lr'):\n            raise ValueError('Optimizer must have a \"lr\" attribute.')\n        try:  \n            lr = float(K.get_value(self.model.optimizer.lr))\n            lr = self.schedule(epoch, lr)\n        except TypeError:  # Support for old API for backward compatibility\n            lr = self.schedule(epoch)\n        if not isinstance(lr, (tf.Tensor, float, np.float32, np.float64)):\n            raise ValueError('The output of the \"schedule\" function '\n                             'should be float.')\n        if isinstance(lr, ops.Tensor) and not lr.dtype.is_floating:\n            raise ValueError('The dtype of Tensor should be float')\n        K.set_value(self.model.optimizer.lr, K.get_value(lr))\n        if self.verbose > 0:\n            print('\\nEpoch %05d: LearningRateScheduler reducing learning '\n                 'rate to %s.' % (epoch + 1, lr))\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        logs['lr'] = K.get_value(self.model.optimizer.lr)\n\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n# 六、TensorFlow的高阶API\n\nTensorFlow的高阶API主要是tensorflow.keras.models.\n\n本章我们主要详细介绍tensorflow.keras.models相关的以下内容。\n\n* 模型的构建（Sequential、functional API、Model子类化）\n\n* 模型的训练（内置fit方法、内置train_on_batch方法、自定义训练循环、单GPU训练模型、多GPU训练模型、TPU训练模型）\n\n* 模型的部署（tensorflow serving部署模型、使用spark(scala)调用tensorflow模型）\n\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n# 6-1,构建模型的3种方法\n\n可以使用以下3种方式构建模型：使用Sequential按层顺序构建模型，使用函数式API构建任意结构模型，继承Model基类构建自定义模型。\n\n对于顺序结构的模型，优先使用Sequential方法构建。\n\n如果模型有多输入或者多输出，或者模型需要共享权重，或者模型具有残差连接等非顺序结构，推荐使用函数式API进行创建。\n\n如果无特定必要，尽可能避免使用Model子类化的方式构建模型，这种方式提供了极大的灵活性，但也有更大的概率出错。\n\n下面以IMDB电影评论的分类问题为例，演示3种创建模型的方法。\n\n```python\nimport numpy as np \nimport pandas as pd \nimport tensorflow as tf\nfrom tqdm import tqdm \nfrom tensorflow.keras import *\n\n\ntrain_token_path = \"./data/imdb/train_token.csv\"\ntest_token_path = \"./data/imdb/test_token.csv\"\n\nMAX_WORDS = 10000  # We will only consider the top 10,000 words in the dataset\nMAX_LEN = 200  # We will cut reviews after 200 words\nBATCH_SIZE = 20 \n\n# 构建管道\ndef parse_line(line):\n    t = tf.strings.split(line,\"\\t\")\n    label = tf.reshape(tf.cast(tf.strings.to_number(t[0]),tf.int32),(-1,))\n    features = tf.cast(tf.strings.to_number(tf.strings.split(t[1],\" \")),tf.int32)\n    return (features,label)\n\nds_train=  tf.data.TextLineDataset(filenames = [train_token_path]) \\\n   .map(parse_line,num_parallel_calls = tf.data.experimental.AUTOTUNE) \\\n   .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n   .prefetch(tf.data.experimental.AUTOTUNE)\n\nds_test=  tf.data.TextLineDataset(filenames = [test_token_path]) \\\n   .map(parse_line,num_parallel_calls = tf.data.experimental.AUTOTUNE) \\\n   .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n   .prefetch(tf.data.experimental.AUTOTUNE)\n\n```\n\n```python\n\n```\n\n### 一，Sequential按层顺序创建模型\n\n```python\ntf.keras.backend.clear_session()\n\nmodel = models.Sequential()\n\nmodel.add(layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN))\nmodel.add(layers.Conv1D(filters = 64,kernel_size = 5,activation = \"relu\"))\nmodel.add(layers.MaxPool1D(2))\nmodel.add(layers.Conv1D(filters = 32,kernel_size = 3,activation = \"relu\"))\nmodel.add(layers.MaxPool1D(2))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(1,activation = \"sigmoid\"))\n\nmodel.compile(optimizer='Nadam',\n            loss='binary_crossentropy',\n            metrics=['accuracy',\"AUC\"])\n\nmodel.summary()\n```\n\n![](./data/Sequential模型结构.png)\n\n```python\nimport datetime\nbaselogger = callbacks.BaseLogger(stateful_metrics=[\"AUC\"])\nlogdir = \"./data/keras_model/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\nhistory = model.fit(ds_train,validation_data = ds_test,\n        epochs = 6,callbacks=[baselogger,tensorboard_callback])\n\n```\n\n```python\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\n\nimport matplotlib.pyplot as plt\n\ndef plot_metric(history, metric):\n    train_metrics = history.history[metric]\n    val_metrics = history.history['val_'+metric]\n    epochs = range(1, len(train_metrics) + 1)\n    plt.plot(epochs, train_metrics, 'bo--')\n    plt.plot(epochs, val_metrics, 'ro-')\n    plt.title('Training and validation '+ metric)\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(metric)\n    plt.legend([\"train_\"+metric, 'val_'+metric])\n    plt.show()\n```\n\n```python\nplot_metric(history,\"AUC\")\n```\n\n```python\n\n```\n\n![](./data/6-1-fit模型.jpg)\n\n```python\n\n```\n\n```python\n\n```\n\n### 二，函数式API创建任意结构模型\n\n```python\ntf.keras.backend.clear_session()\n\ninputs = layers.Input(shape=[MAX_LEN])\nx  = layers.Embedding(MAX_WORDS,7)(inputs)\n\nbranch1 = layers.SeparableConv1D(64,3,activation=\"relu\")(x)\nbranch1 = layers.MaxPool1D(3)(branch1)\nbranch1 = layers.SeparableConv1D(32,3,activation=\"relu\")(branch1)\nbranch1 = layers.GlobalMaxPool1D()(branch1)\n\nbranch2 = layers.SeparableConv1D(64,5,activation=\"relu\")(x)\nbranch2 = layers.MaxPool1D(5)(branch2)\nbranch2 = layers.SeparableConv1D(32,5,activation=\"relu\")(branch2)\nbranch2 = layers.GlobalMaxPool1D()(branch2)\n\nbranch3 = layers.SeparableConv1D(64,7,activation=\"relu\")(x)\nbranch3 = layers.MaxPool1D(7)(branch3)\nbranch3 = layers.SeparableConv1D(32,7,activation=\"relu\")(branch3)\nbranch3 = layers.GlobalMaxPool1D()(branch3)\n\nconcat = layers.Concatenate()([branch1,branch2,branch3])\noutputs = layers.Dense(1,activation = \"sigmoid\")(concat)\n\nmodel = models.Model(inputs = inputs,outputs = outputs)\n\nmodel.compile(optimizer='Nadam',\n            loss='binary_crossentropy',\n            metrics=['accuracy',\"AUC\"])\n\nmodel.summary()\n\n```\n\n```\nModel: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 200)]        0                                            \n__________________________________________________________________________________________________\nembedding (Embedding)           (None, 200, 7)       70000       input_1[0][0]                    \n__________________________________________________________________________________________________\nseparable_conv1d (SeparableConv (None, 198, 64)      533         embedding[0][0]                  \n__________________________________________________________________________________________________\nseparable_conv1d_2 (SeparableCo (None, 196, 64)      547         embedding[0][0]                  \n__________________________________________________________________________________________________\nseparable_conv1d_4 (SeparableCo (None, 194, 64)      561         embedding[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling1d (MaxPooling1D)    (None, 66, 64)       0           separable_conv1d[0][0]           \n__________________________________________________________________________________________________\nmax_pooling1d_1 (MaxPooling1D)  (None, 39, 64)       0           separable_conv1d_2[0][0]         \n__________________________________________________________________________________________________\nmax_pooling1d_2 (MaxPooling1D)  (None, 27, 64)       0           separable_conv1d_4[0][0]         \n__________________________________________________________________________________________________\nseparable_conv1d_1 (SeparableCo (None, 64, 32)       2272        max_pooling1d[0][0]              \n__________________________________________________________________________________________________\nseparable_conv1d_3 (SeparableCo (None, 35, 32)       2400        max_pooling1d_1[0][0]            \n__________________________________________________________________________________________________\nseparable_conv1d_5 (SeparableCo (None, 21, 32)       2528        max_pooling1d_2[0][0]            \n__________________________________________________________________________________________________\nglobal_max_pooling1d (GlobalMax (None, 32)           0           separable_conv1d_1[0][0]         \n__________________________________________________________________________________________________\nglobal_max_pooling1d_1 (GlobalM (None, 32)           0           separable_conv1d_3[0][0]         \n__________________________________________________________________________________________________\nglobal_max_pooling1d_2 (GlobalM (None, 32)           0           separable_conv1d_5[0][0]         \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 96)           0           global_max_pooling1d[0][0]       \n                                                                 global_max_pooling1d_1[0][0]     \n                                                                 global_max_pooling1d_2[0][0]     \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 1)            97          concatenate[0][0]                \n==================================================================================================\nTotal params: 78,938\nTrainable params: 78,938\nNon-trainable params: 0\n__________________________________________________________________________________________________\n```\n\n\n![](./data/FunctionalAPI模型结构.png)\n\n```python\nimport datetime\nlogdir = \"./data/keras_model/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\nhistory = model.fit(ds_train,validation_data = ds_test,epochs = 6,callbacks=[tensorboard_callback])\n\n```\n\n```\nEpoch 1/6\n1000/1000 [==============================] - 32s 32ms/step - loss: 0.5527 - accuracy: 0.6758 - AUC: 0.7731 - val_loss: 0.3646 - val_accuracy: 0.8426 - val_AUC: 0.9192\nEpoch 2/6\n1000/1000 [==============================] - 24s 24ms/step - loss: 0.3024 - accuracy: 0.8737 - AUC: 0.9444 - val_loss: 0.3281 - val_accuracy: 0.8644 - val_AUC: 0.9350\nEpoch 3/6\n1000/1000 [==============================] - 24s 24ms/step - loss: 0.2158 - accuracy: 0.9159 - AUC: 0.9715 - val_loss: 0.3461 - val_accuracy: 0.8666 - val_AUC: 0.9363\nEpoch 4/6\n1000/1000 [==============================] - 24s 24ms/step - loss: 0.1492 - accuracy: 0.9464 - AUC: 0.9859 - val_loss: 0.4017 - val_accuracy: 0.8568 - val_AUC: 0.9311\nEpoch 5/6\n1000/1000 [==============================] - 24s 24ms/step - loss: 0.0944 - accuracy: 0.9696 - AUC: 0.9939 - val_loss: 0.4998 - val_accuracy: 0.8550 - val_AUC: 0.9233\nEpoch 6/6\n1000/1000 [==============================] - 26s 26ms/step - loss: 0.0526 - accuracy: 0.9865 - AUC: 0.9977 - val_loss: 0.6463 - val_accuracy: 0.8462 - val_AUC: 0.9138\n```\n\n```python\nplot_metric(history,\"AUC\")\n```\n\n![](./data/6-1-2-train.jpg)\n\n```python\n\n```\n\n### 三，Model子类化创建自定义模型\n\n```python\n# 先自定义一个残差模块，为自定义Layer\n\nclass ResBlock(layers.Layer):\n    def __init__(self, kernel_size, **kwargs):\n        super(ResBlock, self).__init__(**kwargs)\n        self.kernel_size = kernel_size\n    \n    def build(self,input_shape):\n        self.conv1 = layers.Conv1D(filters=64,kernel_size=self.kernel_size,\n                                   activation = \"relu\",padding=\"same\")\n        self.conv2 = layers.Conv1D(filters=32,kernel_size=self.kernel_size,\n                                   activation = \"relu\",padding=\"same\")\n        self.conv3 = layers.Conv1D(filters=input_shape[-1],\n                                   kernel_size=self.kernel_size,activation = \"relu\",padding=\"same\")\n        self.maxpool = layers.MaxPool1D(2)\n        super(ResBlock,self).build(input_shape) # 相当于设置self.built = True\n    \n    def call(self, inputs):\n        x = self.conv1(inputs)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = layers.Add()([inputs,x])\n        x = self.maxpool(x)\n        return x\n    \n    #如果要让自定义的Layer通过Functional API 组合成模型时可以序列化，需要自定义get_config方法。\n    def get_config(self):  \n        config = super(ResBlock, self).get_config()\n        config.update({'kernel_size': self.kernel_size})\n        return config\n```\n\n```python\n# 测试ResBlock\nresblock = ResBlock(kernel_size = 3)\nresblock.build(input_shape = (None,200,7))\nresblock.compute_output_shape(input_shape=(None,200,7))\n\n```\n\n```\nTensorShape([None, 100, 7])\n```\n\n```python\n# 自定义模型，实际上也可以使用Sequential或者FunctionalAPI\n\nclass ImdbModel(models.Model):\n    def __init__(self):\n        super(ImdbModel, self).__init__()\n        \n    def build(self,input_shape):\n        self.embedding = layers.Embedding(MAX_WORDS,7)\n        self.block1 = ResBlock(7)\n        self.block2 = ResBlock(5)\n        self.dense = layers.Dense(1,activation = \"sigmoid\")\n        super(ImdbModel,self).build(input_shape)\n    \n    def call(self, x):\n        x = self.embedding(x)\n        x = self.block1(x)\n        x = self.block2(x)\n        x = layers.Flatten()(x)\n        x = self.dense(x)\n        return(x)\n\n```\n\n```python\ntf.keras.backend.clear_session()\n\nmodel = ImdbModel()\nmodel.build(input_shape =(None,200))\nmodel.summary()\n\nmodel.compile(optimizer='Nadam',\n            loss='binary_crossentropy',\n            metrics=['accuracy',\"AUC\"])\n\n```\n\n```\nModel: \"imdb_model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        multiple                  70000     \n_________________________________________________________________\nres_block (ResBlock)         multiple                  19143     \n_________________________________________________________________\nres_block_1 (ResBlock)       multiple                  13703     \n_________________________________________________________________\ndense (Dense)                multiple                  351       \n=================================================================\nTotal params: 103,197\nTrainable params: 103,197\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n```python\n\n```\n\n![](./data/Model子类化模型结构.png)\n\n```python\n\n```\n\n```python\nimport datetime\n\nlogdir = \"./tflogs/keras_model/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\nhistory = model.fit(ds_train,validation_data = ds_test,\n                    epochs = 6,callbacks=[tensorboard_callback])\n\n```\n\n```\nEpoch 1/6\n1000/1000 [==============================] - 47s 47ms/step - loss: 0.5629 - accuracy: 0.6618 - AUC: 0.7548 - val_loss: 0.3422 - val_accuracy: 0.8510 - val_AUC: 0.9286\nEpoch 2/6\n1000/1000 [==============================] - 43s 43ms/step - loss: 0.2648 - accuracy: 0.8903 - AUC: 0.9576 - val_loss: 0.3276 - val_accuracy: 0.8650 - val_AUC: 0.9410\nEpoch 3/6\n1000/1000 [==============================] - 42s 42ms/step - loss: 0.1573 - accuracy: 0.9439 - AUC: 0.9846 - val_loss: 0.3861 - val_accuracy: 0.8682 - val_AUC: 0.9390\nEpoch 4/6\n1000/1000 [==============================] - 42s 42ms/step - loss: 0.0849 - accuracy: 0.9706 - AUC: 0.9950 - val_loss: 0.5324 - val_accuracy: 0.8616 - val_AUC: 0.9292\nEpoch 5/6\n1000/1000 [==============================] - 43s 43ms/step - loss: 0.0393 - accuracy: 0.9876 - AUC: 0.9986 - val_loss: 0.7693 - val_accuracy: 0.8566 - val_AUC: 0.9132\nEpoch 6/6\n1000/1000 [==============================] - 44s 44ms/step - loss: 0.0222 - accuracy: 0.9926 - AUC: 0.9994 - val_loss: 0.9328 - val_accuracy: 0.8584 - val_AUC: 0.9052\n```\n\n```python\nplot_metric(history,\"AUC\")\n```\n\n```python\n\n```\n\n![](./data/6-1-3-fit模型.jpg)\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n```python\n\n```\n# 6-2,训练模型的3种方法\n\n模型的训练主要有内置fit方法、内置tran_on_batch方法、自定义训练循环。\n\n注：fit_generator方法在tf.keras中不推荐使用，其功能已经被fit包含。\n\n\n```python\nimport numpy as np \nimport pandas as pd \nimport tensorflow as tf\nfrom tensorflow.keras import * \n\n#打印时间分割线\n@tf.function\ndef printbar():\n    ts = tf.timestamp()\n    today_ts = ts%(24*60*60)\n\n    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\n    minite = tf.cast((today_ts%3600)//60,tf.int32)\n    second = tf.cast(tf.floor(today_ts%60),tf.int32)\n    \n    def timeformat(m):\n        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\n            return(tf.strings.format(\"0{}\",m))\n        else:\n            return(tf.strings.format(\"{}\",m))\n    \n    timestring = tf.strings.join([timeformat(hour),timeformat(minite),\n                timeformat(second)],separator = \":\")\n    tf.print(\"==========\"*8,end = \"\")\n    tf.print(timestring)\n    \n```\n\n```python\nMAX_LEN = 300\nBATCH_SIZE = 32\n(x_train,y_train),(x_test,y_test) = datasets.reuters.load_data()\nx_train = preprocessing.sequence.pad_sequences(x_train,maxlen=MAX_LEN)\nx_test = preprocessing.sequence.pad_sequences(x_test,maxlen=MAX_LEN)\n\nMAX_WORDS = x_train.max()+1\nCAT_NUM = y_train.max()+1\n\nds_train = tf.data.Dataset.from_tensor_slices((x_train,y_train)) \\\n          .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n          .prefetch(tf.data.experimental.AUTOTUNE).cache()\n   \nds_test = tf.data.Dataset.from_tensor_slices((x_test,y_test)) \\\n          .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n          .prefetch(tf.data.experimental.AUTOTUNE).cache()\n\n```\n\n```python\n\n```\n\n### 一，内置fit方法\n\n\n该方法功能非常强大, 支持对numpy array, tf.data.Dataset以及 Python generator数据进行训练。\n\n并且可以通过设置回调函数实现对训练过程的复杂控制逻辑。\n\n```python\ntf.keras.backend.clear_session()\ndef create_model():\n    \n    model = models.Sequential()\n    model.add(layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN))\n    model.add(layers.Conv1D(filters = 64,kernel_size = 5,activation = \"relu\"))\n    model.add(layers.MaxPool1D(2))\n    model.add(layers.Conv1D(filters = 32,kernel_size = 3,activation = \"relu\"))\n    model.add(layers.MaxPool1D(2))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(CAT_NUM,activation = \"softmax\"))\n    return(model)\n\ndef compile_model(model):\n    model.compile(optimizer=optimizers.Nadam(),\n                loss=losses.SparseCategoricalCrossentropy(),\n                metrics=[metrics.SparseCategoricalAccuracy(),metrics.SparseTopKCategoricalAccuracy(5)]) \n    return(model)\n \nmodel = create_model()\nmodel.summary()\nmodel = compile_model(model)\n\n```\n\n```\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 300, 7)            216874    \n_________________________________________________________________\nconv1d (Conv1D)              (None, 296, 64)           2304      \n_________________________________________________________________\nmax_pooling1d (MaxPooling1D) (None, 148, 64)           0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 146, 32)           6176      \n_________________________________________________________________\nmax_pooling1d_1 (MaxPooling1 (None, 73, 32)            0         \n_________________________________________________________________\nflatten (Flatten)            (None, 2336)              0         \n_________________________________________________________________\ndense (Dense)                (None, 46)                107502    \n=================================================================\nTotal params: 332,856\nTrainable params: 332,856\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n```python\nhistory = model.fit(ds_train,validation_data = ds_test,epochs = 10)\n```\n\n```python\n\n```\n\n```\nTrain for 281 steps, validate for 71 steps\nEpoch 1/10\n281/281 [==============================] - 11s 37ms/step - loss: 2.0231 - sparse_categorical_accuracy: 0.4636 - sparse_top_k_categorical_accuracy: 0.7450 - val_loss: 1.7346 - val_sparse_categorical_accuracy: 0.5534 - val_sparse_top_k_categorical_accuracy: 0.7560\nEpoch 2/10\n281/281 [==============================] - 9s 31ms/step - loss: 1.5079 - sparse_categorical_accuracy: 0.6091 - sparse_top_k_categorical_accuracy: 0.7901 - val_loss: 1.5475 - val_sparse_categorical_accuracy: 0.6109 - val_sparse_top_k_categorical_accuracy: 0.7792\nEpoch 3/10\n281/281 [==============================] - 9s 33ms/step - loss: 1.2204 - sparse_categorical_accuracy: 0.6823 - sparse_top_k_categorical_accuracy: 0.8448 - val_loss: 1.5455 - val_sparse_categorical_accuracy: 0.6367 - val_sparse_top_k_categorical_accuracy: 0.8001\nEpoch 4/10\n281/281 [==============================] - 9s 33ms/step - loss: 0.9382 - sparse_categorical_accuracy: 0.7543 - sparse_top_k_categorical_accuracy: 0.9075 - val_loss: 1.6780 - val_sparse_categorical_accuracy: 0.6398 - val_sparse_top_k_categorical_accuracy: 0.8032\nEpoch 5/10\n281/281 [==============================] - 10s 34ms/step - loss: 0.6791 - sparse_categorical_accuracy: 0.8255 - sparse_top_k_categorical_accuracy: 0.9513 - val_loss: 1.9426 - val_sparse_categorical_accuracy: 0.6376 - val_sparse_top_k_categorical_accuracy: 0.7956\nEpoch 6/10\n281/281 [==============================] - 9s 33ms/step - loss: 0.5063 - sparse_categorical_accuracy: 0.8762 - sparse_top_k_categorical_accuracy: 0.9716 - val_loss: 2.2141 - val_sparse_categorical_accuracy: 0.6291 - val_sparse_top_k_categorical_accuracy: 0.7947\nEpoch 7/10\n281/281 [==============================] - 10s 37ms/step - loss: 0.4031 - sparse_categorical_accuracy: 0.9050 - sparse_top_k_categorical_accuracy: 0.9817 - val_loss: 2.4126 - val_sparse_categorical_accuracy: 0.6264 - val_sparse_top_k_categorical_accuracy: 0.7947\nEpoch 8/10\n281/281 [==============================] - 10s 35ms/step - loss: 0.3380 - sparse_categorical_accuracy: 0.9205 - sparse_top_k_categorical_accuracy: 0.9881 - val_loss: 2.5366 - val_sparse_categorical_accuracy: 0.6242 - val_sparse_top_k_categorical_accuracy: 0.7974\nEpoch 9/10\n281/281 [==============================] - 10s 36ms/step - loss: 0.2921 - sparse_categorical_accuracy: 0.9299 - sparse_top_k_categorical_accuracy: 0.9909 - val_loss: 2.6564 - val_sparse_categorical_accuracy: 0.6242 - val_sparse_top_k_categorical_accuracy: 0.7983\nEpoch 10/10\n281/281 [==============================] - 9s 30ms/step - loss: 0.2613 - sparse_categorical_accuracy: 0.9334 - sparse_top_k_categorical_accuracy: 0.9947 - val_loss: 2.7365 - val_sparse_categorical_accuracy: 0.6220 - val_sparse_top_k_categorical_accuracy: 0.8005\n```\n\n```python\n\n```\n\n### 二，内置train_on_batch方法\n\n\n该内置方法相比较fit方法更加灵活，可以不通过回调函数而直接在批次层次上更加精细地控制训练的过程。\n\n```python\ntf.keras.backend.clear_session()\n\ndef create_model():\n    model = models.Sequential()\n\n    model.add(layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN))\n    model.add(layers.Conv1D(filters = 64,kernel_size = 5,activation = \"relu\"))\n    model.add(layers.MaxPool1D(2))\n    model.add(layers.Conv1D(filters = 32,kernel_size = 3,activation = \"relu\"))\n    model.add(layers.MaxPool1D(2))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(CAT_NUM,activation = \"softmax\"))\n    return(model)\n\ndef compile_model(model):\n    model.compile(optimizer=optimizers.Nadam(),\n                loss=losses.SparseCategoricalCrossentropy(),\n                metrics=[metrics.SparseCategoricalAccuracy(),metrics.SparseTopKCategoricalAccuracy(5)]) \n    return(model)\n \nmodel = create_model()\nmodel.summary()\nmodel = compile_model(model)\n\n```\n\n```\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 300, 7)            216874    \n_________________________________________________________________\nconv1d (Conv1D)              (None, 296, 64)           2304      \n_________________________________________________________________\nmax_pooling1d (MaxPooling1D) (None, 148, 64)           0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 146, 32)           6176      \n_________________________________________________________________\nmax_pooling1d_1 (MaxPooling1 (None, 73, 32)            0         \n_________________________________________________________________\nflatten (Flatten)            (None, 2336)              0         \n_________________________________________________________________\ndense (Dense)                (None, 46)                107502    \n=================================================================\nTotal params: 332,856\nTrainable params: 332,856\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n```python\ndef train_model(model,ds_train,ds_valid,epoches):\n\n    for epoch in tf.range(1,epoches+1):\n        model.reset_metrics()\n        \n        # 在后期降低学习率\n        if epoch == 5:\n            model.optimizer.lr.assign(model.optimizer.lr/2.0)\n            tf.print(\"Lowering optimizer Learning Rate...\\n\\n\")\n        \n        for x, y in ds_train:\n            train_result = model.train_on_batch(x, y)\n\n        for x, y in ds_valid:\n            valid_result = model.test_on_batch(x, y,reset_metrics=False)\n            \n        if epoch%1 ==0:\n            printbar()\n            tf.print(\"epoch = \",epoch)\n            print(\"train:\",dict(zip(model.metrics_names,train_result)))\n            print(\"valid:\",dict(zip(model.metrics_names,valid_result)))\n            print(\"\")\n```\n\n```python\ntrain_model(model,ds_train,ds_test,10)\n```\n\n```\n================================================================================13:09:19\nepoch =  1\ntrain: {'loss': 0.82411176, 'sparse_categorical_accuracy': 0.77272725, 'sparse_top_k_categorical_accuracy': 0.8636364}\nvalid: {'loss': 1.9265995, 'sparse_categorical_accuracy': 0.5743544, 'sparse_top_k_categorical_accuracy': 0.75779164}\n\n================================================================================13:09:27\nepoch =  2\ntrain: {'loss': 0.6006621, 'sparse_categorical_accuracy': 0.90909094, 'sparse_top_k_categorical_accuracy': 0.95454544}\nvalid: {'loss': 1.844159, 'sparse_categorical_accuracy': 0.6126447, 'sparse_top_k_categorical_accuracy': 0.7920748}\n\n================================================================================13:09:35\nepoch =  3\ntrain: {'loss': 0.36935613, 'sparse_categorical_accuracy': 0.90909094, 'sparse_top_k_categorical_accuracy': 0.95454544}\nvalid: {'loss': 2.163433, 'sparse_categorical_accuracy': 0.63312554, 'sparse_top_k_categorical_accuracy': 0.8045414}\n\n================================================================================13:09:42\nepoch =  4\ntrain: {'loss': 0.2304088, 'sparse_categorical_accuracy': 0.90909094, 'sparse_top_k_categorical_accuracy': 1.0}\nvalid: {'loss': 2.8911984, 'sparse_categorical_accuracy': 0.6344613, 'sparse_top_k_categorical_accuracy': 0.7978629}\n\nLowering optimizer Learning Rate...\n\n\n================================================================================13:09:51\nepoch =  5\ntrain: {'loss': 0.111194365, 'sparse_categorical_accuracy': 0.95454544, 'sparse_top_k_categorical_accuracy': 1.0}\nvalid: {'loss': 3.6431572, 'sparse_categorical_accuracy': 0.6295637, 'sparse_top_k_categorical_accuracy': 0.7978629}\n\n================================================================================13:09:59\nepoch =  6\ntrain: {'loss': 0.07741702, 'sparse_categorical_accuracy': 0.95454544, 'sparse_top_k_categorical_accuracy': 1.0}\nvalid: {'loss': 4.074161, 'sparse_categorical_accuracy': 0.6255565, 'sparse_top_k_categorical_accuracy': 0.794301}\n\n================================================================================13:10:07\nepoch =  7\ntrain: {'loss': 0.056113098, 'sparse_categorical_accuracy': 1.0, 'sparse_top_k_categorical_accuracy': 1.0}\nvalid: {'loss': 4.4461513, 'sparse_categorical_accuracy': 0.6273375, 'sparse_top_k_categorical_accuracy': 0.79652715}\n\n================================================================================13:10:17\nepoch =  8\ntrain: {'loss': 0.043448802, 'sparse_categorical_accuracy': 1.0, 'sparse_top_k_categorical_accuracy': 1.0}\nvalid: {'loss': 4.7687583, 'sparse_categorical_accuracy': 0.6224399, 'sparse_top_k_categorical_accuracy': 0.79741764}\n\n================================================================================13:10:26\nepoch =  9\ntrain: {'loss': 0.035002146, 'sparse_categorical_accuracy': 1.0, 'sparse_top_k_categorical_accuracy': 1.0}\nvalid: {'loss': 5.130505, 'sparse_categorical_accuracy': 0.6175423, 'sparse_top_k_categorical_accuracy': 0.794301}\n\n================================================================================13:10:34\nepoch =  10\ntrain: {'loss': 0.028303564, 'sparse_categorical_accuracy': 1.0, 'sparse_top_k_categorical_accuracy': 1.0}\nvalid: {'loss': 5.4559293, 'sparse_categorical_accuracy': 0.6148709, 'sparse_top_k_categorical_accuracy': 0.7947462}\n```\n\n```python\n\n```\n\n### 三，自定义训练循环\n\n\n自定义训练循环无需编译模型，直接利用优化器根据损失函数反向传播迭代参数，拥有最高的灵活性。\n\n```python\ntf.keras.backend.clear_session()\n\ndef create_model():\n    \n    model = models.Sequential()\n\n    model.add(layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN))\n    model.add(layers.Conv1D(filters = 64,kernel_size = 5,activation = \"relu\"))\n    model.add(layers.MaxPool1D(2))\n    model.add(layers.Conv1D(filters = 32,kernel_size = 3,activation = \"relu\"))\n    model.add(layers.MaxPool1D(2))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(CAT_NUM,activation = \"softmax\"))\n    return(model)\n\nmodel = create_model()\nmodel.summary()\n```\n\n```python\noptimizer = optimizers.Nadam()\nloss_func = losses.SparseCategoricalCrossentropy()\n\ntrain_loss = metrics.Mean(name='train_loss')\ntrain_metric = metrics.SparseCategoricalAccuracy(name='train_accuracy')\n\nvalid_loss = metrics.Mean(name='valid_loss')\nvalid_metric = metrics.SparseCategoricalAccuracy(name='valid_accuracy')\n\n@tf.function\ndef train_step(model, features, labels):\n    with tf.GradientTape() as tape:\n        predictions = model(features,training = True)\n        loss = loss_func(labels, predictions)\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n    train_loss.update_state(loss)\n    train_metric.update_state(labels, predictions)\n    \n\n@tf.function\ndef valid_step(model, features, labels):\n    predictions = model(features)\n    batch_loss = loss_func(labels, predictions)\n    valid_loss.update_state(batch_loss)\n    valid_metric.update_state(labels, predictions)\n    \n\ndef train_model(model,ds_train,ds_valid,epochs):\n    for epoch in tf.range(1,epochs+1):\n        \n        for features, labels in ds_train:\n            train_step(model,features,labels)\n\n        for features, labels in ds_valid:\n            valid_step(model,features,labels)\n\n        logs = 'Epoch={},Loss:{},Accuracy:{},Valid Loss:{},Valid Accuracy:{}'\n        \n        if epoch%1 ==0:\n            printbar()\n            tf.print(tf.strings.format(logs,\n            (epoch,train_loss.result(),train_metric.result(),valid_loss.result(),valid_metric.result())))\n            tf.print(\"\")\n            \n        train_loss.reset_states()\n        valid_loss.reset_states()\n        train_metric.reset_states()\n        valid_metric.reset_states()\n\ntrain_model(model,ds_train,ds_test,10)\n\n```\n\n```python\n\n```\n\n```\n================================================================================13:12:03\nEpoch=1,Loss:2.02051544,Accuracy:0.460253835,Valid Loss:1.75700927,Valid Accuracy:0.536954582\n\n================================================================================13:12:09\nEpoch=2,Loss:1.510795,Accuracy:0.610665798,Valid Loss:1.55349839,Valid Accuracy:0.616206586\n\n================================================================================13:12:17\nEpoch=3,Loss:1.19221532,Accuracy:0.696170092,Valid Loss:1.52315605,Valid Accuracy:0.651380241\n\n================================================================================13:12:23\nEpoch=4,Loss:0.90101546,Accuracy:0.766310394,Valid Loss:1.68327653,Valid Accuracy:0.648263574\n\n================================================================================13:12:30\nEpoch=5,Loss:0.655430496,Accuracy:0.831329346,Valid Loss:1.90872383,Valid Accuracy:0.641139805\n\n================================================================================13:12:37\nEpoch=6,Loss:0.492730737,Accuracy:0.877866864,Valid Loss:2.09966016,Valid Accuracy:0.63223511\n\n================================================================================13:12:44\nEpoch=7,Loss:0.391238362,Accuracy:0.904030263,Valid Loss:2.27431226,Valid Accuracy:0.625111282\n\n================================================================================13:12:51\nEpoch=8,Loss:0.327761739,Accuracy:0.922066331,Valid Loss:2.42568827,Valid Accuracy:0.617542326\n\n================================================================================13:12:58\nEpoch=9,Loss:0.285573095,Accuracy:0.930527747,Valid Loss:2.55942106,Valid Accuracy:0.612644672\n\n================================================================================13:13:05\nEpoch=10,Loss:0.255482465,Accuracy:0.936094403,Valid Loss:2.67789412,Valid Accuracy:0.612199485\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n```python\n\n```\n\n```python\n\n```\n# 6-3,使用单GPU训练模型\n\n深度学习的训练过程常常非常耗时，一个模型训练几个小时是家常便饭，训练几天也是常有的事情，有时候甚至要训练几十天。\n\n训练过程的耗时主要来自于两个部分，一部分来自数据准备，另一部分来自参数迭代。\n\n当数据准备过程还是模型训练时间的主要瓶颈时，我们可以使用更多进程来准备数据。\n\n当参数迭代过程成为训练时间的主要瓶颈时，我们通常的方法是应用GPU或者Google的TPU来进行加速。\n\n详见《用GPU加速Keras模型——Colab免费GPU使用攻略》\n\nhttps://zhuanlan.zhihu.com/p/68509398\n\n\n无论是内置fit方法，还是自定义训练循环，从CPU切换成单GPU训练模型都是非常方便的，无需更改任何代码。当存在可用的GPU时，如果不特意指定device，tensorflow会自动优先选择使用GPU来创建张量和执行张量计算。\n\n但如果是在公司或者学校实验室的服务器环境，存在多个GPU和多个使用者时，为了不让单个同学的任务占用全部GPU资源导致其他同学无法使用（tensorflow默认获取全部GPU的全部内存资源权限，但实际上只使用一个GPU的部分资源），我们通常会在开头增加以下几行代码以控制每个任务使用的GPU编号和显存大小，以便其他同学也能够同时训练模型。\n\n\n在Colab笔记本中：修改->笔记本设置->硬件加速器 中选择 GPU\n\n注：以下代码只能在Colab 上才能正确执行。\n\n可通过以下colab链接测试效果《tf_单GPU》：\n\nhttps://colab.research.google.com/drive/1r5dLoeJq5z01sU72BX2M5UiNSkuxsEFe\n\n```python\n%tensorflow_version 2.x\nimport tensorflow as tf\nprint(tf.__version__)\n```\n\n```python\nfrom tensorflow.keras import * \n\n#打印时间分割线\n@tf.function\ndef printbar():\n    ts = tf.timestamp()\n    today_ts = ts%(24*60*60)\n\n    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\n    minite = tf.cast((today_ts%3600)//60,tf.int32)\n    second = tf.cast(tf.floor(today_ts%60),tf.int32)\n    \n    def timeformat(m):\n        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\n            return(tf.strings.format(\"0{}\",m))\n        else:\n            return(tf.strings.format(\"{}\",m))\n    \n    timestring = tf.strings.join([timeformat(hour),timeformat(minite),\n                timeformat(second)],separator = \":\")\n    tf.print(\"==========\"*8,end = \"\")\n    tf.print(timestring)\n    \n```\n\n### 一，GPU设置\n\n```python\ngpus = tf.config.list_physical_devices(\"GPU\")\n\nif gpus:\n    gpu0 = gpus[0] #如果有多个GPU，仅使用第0个GPU\n    tf.config.experimental.set_memory_growth(gpu0, True) #设置GPU显存用量按需使用\n    # 或者也可以设置GPU显存为固定使用量(例如：4G)\n    #tf.config.experimental.set_virtual_device_configuration(gpu0,\n    #    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]) \n    tf.config.set_visible_devices([gpu0],\"GPU\") \n```\n\n比较GPU和CPU的计算速度\n\n```python\nprintbar()\nwith tf.device(\"/gpu:0\"):\n    tf.random.set_seed(0)\n    a = tf.random.uniform((10000,100),minval = 0,maxval = 3.0)\n    b = tf.random.uniform((100,100000),minval = 0,maxval = 3.0)\n    c = a@b\n    tf.print(tf.reduce_sum(tf.reduce_sum(c,axis = 0),axis=0))\nprintbar()\n```\n\n```\n================================================================================17:37:01\n2.24953778e+11\n================================================================================17:37:01\n```\n\n```python\nprintbar()\nwith tf.device(\"/cpu:0\"):\n    tf.random.set_seed(0)\n    a = tf.random.uniform((10000,100),minval = 0,maxval = 3.0)\n    b = tf.random.uniform((100,100000),minval = 0,maxval = 3.0)\n    c = a@b\n    tf.print(tf.reduce_sum(tf.reduce_sum(c,axis = 0),axis=0))\nprintbar()\n```\n\n```\n================================================================================17:37:34\n2.24953795e+11\n================================================================================17:37:40\n```\n\n```python\n\n```\n\n### 二，准备数据\n\n```python\nMAX_LEN = 300\nBATCH_SIZE = 32\n(x_train,y_train),(x_test,y_test) = datasets.reuters.load_data()\nx_train = preprocessing.sequence.pad_sequences(x_train,maxlen=MAX_LEN)\nx_test = preprocessing.sequence.pad_sequences(x_test,maxlen=MAX_LEN)\n\nMAX_WORDS = x_train.max()+1\nCAT_NUM = y_train.max()+1\n\nds_train = tf.data.Dataset.from_tensor_slices((x_train,y_train)) \\\n          .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n          .prefetch(tf.data.experimental.AUTOTUNE).cache()\n   \nds_test = tf.data.Dataset.from_tensor_slices((x_test,y_test)) \\\n          .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n          .prefetch(tf.data.experimental.AUTOTUNE).cache()\n          \n```\n\n```python\n\n```\n\n### 三，定义模型\n\n```python\ntf.keras.backend.clear_session()\n\ndef create_model():\n    \n    model = models.Sequential()\n\n    model.add(layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN))\n    model.add(layers.Conv1D(filters = 64,kernel_size = 5,activation = \"relu\"))\n    model.add(layers.MaxPool1D(2))\n    model.add(layers.Conv1D(filters = 32,kernel_size = 3,activation = \"relu\"))\n    model.add(layers.MaxPool1D(2))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(CAT_NUM,activation = \"softmax\"))\n    return(model)\n\nmodel = create_model()\nmodel.summary()\n\n```\n\n```\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 300, 7)            216874    \n_________________________________________________________________\nconv1d (Conv1D)              (None, 296, 64)           2304      \n_________________________________________________________________\nmax_pooling1d (MaxPooling1D) (None, 148, 64)           0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 146, 32)           6176      \n_________________________________________________________________\nmax_pooling1d_1 (MaxPooling1 (None, 73, 32)            0         \n_________________________________________________________________\nflatten (Flatten)            (None, 2336)              0         \n_________________________________________________________________\ndense (Dense)                (None, 46)                107502    \n=================================================================\nTotal params: 332,856\nTrainable params: 332,856\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n```python\n\n```\n\n### 四，训练模型\n\n```python\noptimizer = optimizers.Nadam()\nloss_func = losses.SparseCategoricalCrossentropy()\n\ntrain_loss = metrics.Mean(name='train_loss')\ntrain_metric = metrics.SparseCategoricalAccuracy(name='train_accuracy')\n\nvalid_loss = metrics.Mean(name='valid_loss')\nvalid_metric = metrics.SparseCategoricalAccuracy(name='valid_accuracy')\n\n@tf.function\ndef train_step(model, features, labels):\n    with tf.GradientTape() as tape:\n        predictions = model(features,training = True)\n        loss = loss_func(labels, predictions)\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n    train_loss.update_state(loss)\n    train_metric.update_state(labels, predictions)\n    \n@tf.function\ndef valid_step(model, features, labels):\n    predictions = model(features)\n    batch_loss = loss_func(labels, predictions)\n    valid_loss.update_state(batch_loss)\n    valid_metric.update_state(labels, predictions)\n    \n\ndef train_model(model,ds_train,ds_valid,epochs):\n    for epoch in tf.range(1,epochs+1):\n        \n        for features, labels in ds_train:\n            train_step(model,features,labels)\n\n        for features, labels in ds_valid:\n            valid_step(model,features,labels)\n\n        logs = 'Epoch={},Loss:{},Accuracy:{},Valid Loss:{},Valid Accuracy:{}'\n        \n        if epoch%1 ==0:\n            printbar()\n            tf.print(tf.strings.format(logs,\n            (epoch,train_loss.result(),train_metric.result(),valid_loss.result(),valid_metric.result())))\n            tf.print(\"\")\n            \n        train_loss.reset_states()\n        valid_loss.reset_states()\n        train_metric.reset_states()\n        valid_metric.reset_states()\n\ntrain_model(model,ds_train,ds_test,10)\n```\n\n```python\n\n```\n\n```\n================================================================================17:13:26\nEpoch=1,Loss:1.96735072,Accuracy:0.489200622,Valid Loss:1.64124215,Valid Accuracy:0.582813919\n\n================================================================================17:13:28\nEpoch=2,Loss:1.4640888,Accuracy:0.624805152,Valid Loss:1.5559175,Valid Accuracy:0.607747078\n\n================================================================================17:13:30\nEpoch=3,Loss:1.20681274,Accuracy:0.68581605,Valid Loss:1.58494771,Valid Accuracy:0.622439921\n\n================================================================================17:13:31\nEpoch=4,Loss:0.937500894,Accuracy:0.75361836,Valid Loss:1.77466083,Valid Accuracy:0.621994674\n\n================================================================================17:13:33\nEpoch=5,Loss:0.693960547,Accuracy:0.822199941,Valid Loss:2.00267363,Valid Accuracy:0.6197685\n\n================================================================================17:13:35\nEpoch=6,Loss:0.519614,Accuracy:0.870296121,Valid Loss:2.23463202,Valid Accuracy:0.613980412\n\n================================================================================17:13:37\nEpoch=7,Loss:0.408562034,Accuracy:0.901246965,Valid Loss:2.46969271,Valid Accuracy:0.612199485\n\n================================================================================17:13:39\nEpoch=8,Loss:0.339028627,Accuracy:0.920062363,Valid Loss:2.68585229,Valid Accuracy:0.615316093\n\n================================================================================17:13:41\nEpoch=9,Loss:0.293798745,Accuracy:0.92930305,Valid Loss:2.88995624,Valid Accuracy:0.613535166\n\n================================================================================17:13:43\nEpoch=10,Loss:0.263130337,Accuracy:0.936651051,Valid Loss:3.09705234,Valid Accuracy:0.612644672\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n\n\n# 6-4,使用多GPU训练模型\n\n如果使用多GPU训练模型，推荐使用内置fit方法，较为方便，仅需添加2行代码。\n\n在Colab笔记本中：修改->笔记本设置->硬件加速器 中选择 GPU\n\n注：以下代码只能在Colab 上才能正确执行。\n\n可通过以下colab链接测试效果《tf_多GPU》：\n\nhttps://colab.research.google.com/drive/1j2kp_t0S_cofExSN7IyJ4QtMscbVlXU-\n\n\n\nMirroredStrategy过程简介：\n\n* 训练开始前，该策略在所有 N 个计算设备上均各复制一份完整的模型；\n* 每次训练传入一个批次的数据时，将数据分成 N 份，分别传入 N 个计算设备（即数据并行）；\n* N 个计算设备使用本地变量（镜像变量）分别计算自己所获得的部分数据的梯度；\n* 使用分布式计算的 All-reduce 操作，在计算设备间高效交换梯度数据并进行求和，使得最终每个设备都有了所有设备的梯度之和；\n* 使用梯度求和的结果更新本地变量（镜像变量）；\n* 当所有设备均更新本地变量后，进行下一轮训练（即该并行策略是同步的）。\n\n```python\n%tensorflow_version 2.x\nimport tensorflow as tf\nprint(tf.__version__)\nfrom tensorflow.keras import * \n```\n\n```python\n#此处在colab上使用1个GPU模拟出两个逻辑GPU进行多GPU训练\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    # 设置两个逻辑GPU模拟多GPU训练\n    try:\n        tf.config.experimental.set_virtual_device_configuration(gpus[0],\n            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024),\n             tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n        print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n    except RuntimeError as e:\n        print(e)\n```\n\n### 一，准备数据\n\n```python\nMAX_LEN = 300\nBATCH_SIZE = 32\n(x_train,y_train),(x_test,y_test) = datasets.reuters.load_data()\nx_train = preprocessing.sequence.pad_sequences(x_train,maxlen=MAX_LEN)\nx_test = preprocessing.sequence.pad_sequences(x_test,maxlen=MAX_LEN)\n\nMAX_WORDS = x_train.max()+1\nCAT_NUM = y_train.max()+1\n\nds_train = tf.data.Dataset.from_tensor_slices((x_train,y_train)) \\\n          .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n          .prefetch(tf.data.experimental.AUTOTUNE).cache()\n   \nds_test = tf.data.Dataset.from_tensor_slices((x_test,y_test)) \\\n          .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n          .prefetch(tf.data.experimental.AUTOTUNE).cache()\n\n```\n\n### 二，定义模型\n\n```python\ntf.keras.backend.clear_session()\ndef create_model():\n    \n    model = models.Sequential()\n\n    model.add(layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN))\n    model.add(layers.Conv1D(filters = 64,kernel_size = 5,activation = \"relu\"))\n    model.add(layers.MaxPool1D(2))\n    model.add(layers.Conv1D(filters = 32,kernel_size = 3,activation = \"relu\"))\n    model.add(layers.MaxPool1D(2))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(CAT_NUM,activation = \"softmax\"))\n    return(model)\n\ndef compile_model(model):\n    model.compile(optimizer=optimizers.Nadam(),\n                loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n                metrics=[metrics.SparseCategoricalAccuracy(),metrics.SparseTopKCategoricalAccuracy(5)]) \n    return(model)\n```\n\n### 三，训练模型\n\n```python\n#增加以下两行代码\nstrategy = tf.distribute.MirroredStrategy()  \nwith strategy.scope(): \n    model = create_model()\n    model.summary()\n    model = compile_model(model)\n    \nhistory = model.fit(ds_train,validation_data = ds_test,epochs = 10)  \n```\n\n```\nWARNING:tensorflow:NCCL is not supported when using virtual GPUs, fallingback to reduction to one device\nINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 300, 7)            216874    \n_________________________________________________________________\nconv1d (Conv1D)              (None, 296, 64)           2304      \n_________________________________________________________________\nmax_pooling1d (MaxPooling1D) (None, 148, 64)           0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 146, 32)           6176      \n_________________________________________________________________\nmax_pooling1d_1 (MaxPooling1 (None, 73, 32)            0         \n_________________________________________________________________\nflatten (Flatten)            (None, 2336)              0         \n_________________________________________________________________\ndense (Dense)                (None, 46)                107502    \n=================================================================\nTotal params: 332,856\nTrainable params: 332,856\nNon-trainable params: 0\n_________________________________________________________________\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nTrain for 281 steps, validate for 71 steps\nEpoch 1/10\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n281/281 [==============================] - 15s 53ms/step - loss: 2.0270 - sparse_categorical_accuracy: 0.4653 - sparse_top_k_categorical_accuracy: 0.7481 - val_loss: 1.7517 - val_sparse_categorical_accuracy: 0.5481 - val_sparse_top_k_categorical_accuracy: 0.7578\nEpoch 2/10\n281/281 [==============================] - 4s 14ms/step - loss: 1.5206 - sparse_categorical_accuracy: 0.6045 - sparse_top_k_categorical_accuracy: 0.7938 - val_loss: 1.5715 - val_sparse_categorical_accuracy: 0.5993 - val_sparse_top_k_categorical_accuracy: 0.7983\nEpoch 3/10\n281/281 [==============================] - 4s 14ms/step - loss: 1.2178 - sparse_categorical_accuracy: 0.6843 - sparse_top_k_categorical_accuracy: 0.8547 - val_loss: 1.5232 - val_sparse_categorical_accuracy: 0.6327 - val_sparse_top_k_categorical_accuracy: 0.8112\nEpoch 4/10\n281/281 [==============================] - 4s 13ms/step - loss: 0.9127 - sparse_categorical_accuracy: 0.7648 - sparse_top_k_categorical_accuracy: 0.9113 - val_loss: 1.6527 - val_sparse_categorical_accuracy: 0.6296 - val_sparse_top_k_categorical_accuracy: 0.8201\nEpoch 5/10\n281/281 [==============================] - 4s 14ms/step - loss: 0.6606 - sparse_categorical_accuracy: 0.8321 - sparse_top_k_categorical_accuracy: 0.9525 - val_loss: 1.8791 - val_sparse_categorical_accuracy: 0.6158 - val_sparse_top_k_categorical_accuracy: 0.8219\nEpoch 6/10\n281/281 [==============================] - 4s 14ms/step - loss: 0.4919 - sparse_categorical_accuracy: 0.8799 - sparse_top_k_categorical_accuracy: 0.9725 - val_loss: 2.1282 - val_sparse_categorical_accuracy: 0.6037 - val_sparse_top_k_categorical_accuracy: 0.8112\nEpoch 7/10\n281/281 [==============================] - 4s 14ms/step - loss: 0.3947 - sparse_categorical_accuracy: 0.9051 - sparse_top_k_categorical_accuracy: 0.9814 - val_loss: 2.3033 - val_sparse_categorical_accuracy: 0.6046 - val_sparse_top_k_categorical_accuracy: 0.8094\nEpoch 8/10\n281/281 [==============================] - 4s 14ms/step - loss: 0.3335 - sparse_categorical_accuracy: 0.9207 - sparse_top_k_categorical_accuracy: 0.9863 - val_loss: 2.4255 - val_sparse_categorical_accuracy: 0.5993 - val_sparse_top_k_categorical_accuracy: 0.8099\nEpoch 9/10\n281/281 [==============================] - 4s 14ms/step - loss: 0.2919 - sparse_categorical_accuracy: 0.9304 - sparse_top_k_categorical_accuracy: 0.9911 - val_loss: 2.5571 - val_sparse_categorical_accuracy: 0.6020 - val_sparse_top_k_categorical_accuracy: 0.8126\nEpoch 10/10\n281/281 [==============================] - 4s 14ms/step - loss: 0.2617 - sparse_categorical_accuracy: 0.9342 - sparse_top_k_categorical_accuracy: 0.9937 - val_loss: 2.6700 - val_sparse_categorical_accuracy: 0.6077 - val_sparse_top_k_categorical_accuracy: 0.8148\nCPU times: user 1min 2s, sys: 8.59 s, total: 1min 10s\nWall time: 58.5 s\n```\n\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n# 6-5,使用TPU训练模型\n\n如果想尝试使用Google Colab上的TPU来训练模型，也是非常方便，仅需添加6行代码。\n\n在Colab笔记本中：修改->笔记本设置->硬件加速器 中选择 TPU\n\n注：以下代码只能在Colab 上才能正确执行。\n\n可通过以下colab链接测试效果《tf_TPU》：\n\nhttps://colab.research.google.com/drive/1XCIhATyE1R7lq6uwFlYlRsUr5d9_-r1s\n\n\n```python\n%tensorflow_version 2.x\nimport tensorflow as tf\nprint(tf.__version__)\nfrom tensorflow.keras import * \n```\n\n### 一，准备数据\n\n```python\nMAX_LEN = 300\nBATCH_SIZE = 32\n(x_train,y_train),(x_test,y_test) = datasets.reuters.load_data()\nx_train = preprocessing.sequence.pad_sequences(x_train,maxlen=MAX_LEN)\nx_test = preprocessing.sequence.pad_sequences(x_test,maxlen=MAX_LEN)\n\nMAX_WORDS = x_train.max()+1\nCAT_NUM = y_train.max()+1\n\nds_train = tf.data.Dataset.from_tensor_slices((x_train,y_train)) \\\n          .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n          .prefetch(tf.data.experimental.AUTOTUNE).cache()\n   \nds_test = tf.data.Dataset.from_tensor_slices((x_test,y_test)) \\\n          .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n          .prefetch(tf.data.experimental.AUTOTUNE).cache()\n```\n\n### 二，定义模型\n\n```python\ntf.keras.backend.clear_session()\ndef create_model():\n    \n    model = models.Sequential()\n\n    model.add(layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN))\n    model.add(layers.Conv1D(filters = 64,kernel_size = 5,activation = \"relu\"))\n    model.add(layers.MaxPool1D(2))\n    model.add(layers.Conv1D(filters = 32,kernel_size = 3,activation = \"relu\"))\n    model.add(layers.MaxPool1D(2))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(CAT_NUM,activation = \"softmax\"))\n    return(model)\n\ndef compile_model(model):\n    model.compile(optimizer=optimizers.Nadam(),\n                loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n                metrics=[metrics.SparseCategoricalAccuracy(),metrics.SparseTopKCategoricalAccuracy(5)]) \n    return(model)\n```\n\n```python\n\n```\n\n### 三，训练模型\n\n```python\n#增加以下6行代码\nimport os\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\ntf.config.experimental_connect_to_cluster(resolver)\ntf.tpu.experimental.initialize_tpu_system(resolver)\nstrategy = tf.distribute.experimental.TPUStrategy(resolver)\nwith strategy.scope():\n    model = create_model()\n    model.summary()\n    model = compile_model(model)\n    \n```\n\n```\nWARNING:tensorflow:TPU system 10.26.134.242:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\nWARNING:tensorflow:TPU system 10.26.134.242:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\nINFO:tensorflow:Initializing the TPU system: 10.26.134.242:8470\nINFO:tensorflow:Initializing the TPU system: 10.26.134.242:8470\nINFO:tensorflow:Clearing out eager caches\nINFO:tensorflow:Clearing out eager caches\nINFO:tensorflow:Finished initializing TPU system.\nINFO:tensorflow:Finished initializing TPU system.\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 300, 7)            216874    \n_________________________________________________________________\nconv1d (Conv1D)              (None, 296, 64)           2304      \n_________________________________________________________________\nmax_pooling1d (MaxPooling1D) (None, 148, 64)           0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 146, 32)           6176      \n_________________________________________________________________\nmax_pooling1d_1 (MaxPooling1 (None, 73, 32)            0         \n_________________________________________________________________\nflatten (Flatten)            (None, 2336)              0         \n_________________________________________________________________\ndense (Dense)                (None, 46)                107502    \n=================================================================\nTotal params: 332,856\nTrainable params: 332,856\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n```python\nhistory = model.fit(ds_train,validation_data = ds_test,epochs = 10)\n```\n\n```\nTrain for 281 steps, validate for 71 steps\nEpoch 1/10\n281/281 [==============================] - 12s 43ms/step - loss: 3.4466 - sparse_categorical_accuracy: 0.4332 - sparse_top_k_categorical_accuracy: 0.7180 - val_loss: 3.3179 - val_sparse_categorical_accuracy: 0.5352 - val_sparse_top_k_categorical_accuracy: 0.7195\nEpoch 2/10\n281/281 [==============================] - 6s 20ms/step - loss: 3.3251 - sparse_categorical_accuracy: 0.5405 - sparse_top_k_categorical_accuracy: 0.7302 - val_loss: 3.3082 - val_sparse_categorical_accuracy: 0.5463 - val_sparse_top_k_categorical_accuracy: 0.7235\nEpoch 3/10\n281/281 [==============================] - 6s 20ms/step - loss: 3.2961 - sparse_categorical_accuracy: 0.5729 - sparse_top_k_categorical_accuracy: 0.7280 - val_loss: 3.3026 - val_sparse_categorical_accuracy: 0.5499 - val_sparse_top_k_categorical_accuracy: 0.7217\nEpoch 4/10\n281/281 [==============================] - 5s 19ms/step - loss: 3.2751 - sparse_categorical_accuracy: 0.5924 - sparse_top_k_categorical_accuracy: 0.7276 - val_loss: 3.2957 - val_sparse_categorical_accuracy: 0.5543 - val_sparse_top_k_categorical_accuracy: 0.7217\nEpoch 5/10\n281/281 [==============================] - 5s 19ms/step - loss: 3.2655 - sparse_categorical_accuracy: 0.6008 - sparse_top_k_categorical_accuracy: 0.7290 - val_loss: 3.3022 - val_sparse_categorical_accuracy: 0.5490 - val_sparse_top_k_categorical_accuracy: 0.7231\nEpoch 6/10\n281/281 [==============================] - 5s 19ms/step - loss: 3.2616 - sparse_categorical_accuracy: 0.6041 - sparse_top_k_categorical_accuracy: 0.7295 - val_loss: 3.3015 - val_sparse_categorical_accuracy: 0.5503 - val_sparse_top_k_categorical_accuracy: 0.7235\nEpoch 7/10\n281/281 [==============================] - 6s 21ms/step - loss: 3.2595 - sparse_categorical_accuracy: 0.6059 - sparse_top_k_categorical_accuracy: 0.7322 - val_loss: 3.3064 - val_sparse_categorical_accuracy: 0.5454 - val_sparse_top_k_categorical_accuracy: 0.7266\nEpoch 8/10\n281/281 [==============================] - 6s 21ms/step - loss: 3.2591 - sparse_categorical_accuracy: 0.6063 - sparse_top_k_categorical_accuracy: 0.7327 - val_loss: 3.3025 - val_sparse_categorical_accuracy: 0.5481 - val_sparse_top_k_categorical_accuracy: 0.7231\nEpoch 9/10\n281/281 [==============================] - 5s 19ms/step - loss: 3.2588 - sparse_categorical_accuracy: 0.6062 - sparse_top_k_categorical_accuracy: 0.7332 - val_loss: 3.2992 - val_sparse_categorical_accuracy: 0.5521 - val_sparse_top_k_categorical_accuracy: 0.7257\nEpoch 10/10\n281/281 [==============================] - 5s 18ms/step - loss: 3.2577 - sparse_categorical_accuracy: 0.6073 - sparse_top_k_categorical_accuracy: 0.7363 - val_loss: 3.2981 - val_sparse_categorical_accuracy: 0.5516 - val_sparse_top_k_categorical_accuracy: 0.7306\nCPU times: user 18.9 s, sys: 3.86 s, total: 22.7 s\nWall time: 1min 1s\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n```python\n\n```\n# 6-6,使用tensorflow-serving部署模型\n\nTensorFlow训练好的模型以tensorflow原生方式保存成protobuf文件后可以用许多方式部署运行。\n\n例如：通过 tensorflow-js 可以用javascrip脚本加载模型并在浏览器中运行模型。\n\n通过 tensorflow-lite 可以在移动和嵌入式设备上加载并运行TensorFlow模型。\n\n通过 tensorflow-serving 可以加载模型后提供网络接口API服务，通过任意编程语言发送网络请求都可以获取模型预测结果。\n\n通过 tensorFlow for Java接口，可以在Java或者spark(scala)中调用tensorflow模型进行预测。\n\n我们主要介绍tensorflow serving部署模型、使用spark(scala)调用tensorflow模型的方法。\n\n```python\n\n```\n\n### 〇，tensorflow serving模型部署概述\n使用 tensorflow serving 部署模型要完成以下步骤。\n\n* (1) 准备protobuf模型文件。\n\n* (2) 安装tensorflow serving。\n\n* (3) 启动tensorflow serving 服务。\n\n* (4) 向API服务发送请求，获取预测结果。\n\n\n可通过以下colab链接测试效果《tf_serving》：\nhttps://colab.research.google.com/drive/1vS5LAYJTEn-H0GDb1irzIuyRB8E3eWc8\n\n\n\n```python\n%tensorflow_version 2.x\nimport tensorflow as tf\nprint(tf.__version__)\nfrom tensorflow.keras import * \n\n```\n\n### 一，准备protobuf模型文件\n\n我们使用tf.keras 训练一个简单的线性回归模型，并保存成protobuf文件。\n\n```python\nimport tensorflow as tf\nfrom tensorflow.keras import models,layers,optimizers\n\n## 样本数量\nn = 800\n\n## 生成测试用数据集\nX = tf.random.uniform([n,2],minval=-10,maxval=10) \nw0 = tf.constant([[2.0],[-1.0]])\nb0 = tf.constant(3.0)\n\nY = X@w0 + b0 + tf.random.normal([n,1],\n    mean = 0.0,stddev= 2.0) # @表示矩阵乘法,增加正态扰动\n\n## 建立模型\ntf.keras.backend.clear_session()\ninputs = layers.Input(shape = (2,),name =\"inputs\") #设置输入名字为inputs\noutputs = layers.Dense(1, name = \"outputs\")(inputs) #设置输出名字为outputs\nlinear = models.Model(inputs = inputs,outputs = outputs)\nlinear.summary()\n\n## 使用fit方法进行训练\nlinear.compile(optimizer=\"rmsprop\",loss=\"mse\",metrics=[\"mae\"])\nlinear.fit(X,Y,batch_size = 8,epochs = 100)  \n\ntf.print(\"w = \",linear.layers[1].kernel)\ntf.print(\"b = \",linear.layers[1].bias)\n\n## 将模型保存成pb格式文件\nexport_path = \"./data/linear_model/\"\nversion = \"1\"       #后续可以通过版本号进行模型版本迭代与管理\nlinear.save(export_path+version, save_format=\"tf\") \n```\n\n```python\n#查看保存的模型文件\n!ls {export_path+version}\n```\n\n```\nassets\tsaved_model.pb\tvariables\n```\n\n```python\n# 查看模型文件相关信息\n!saved_model_cli show --dir {export_path+str(version)} --all\n```\n\n```\nMetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n\nsignature_def['__saved_model_init_op']:\n  The given SavedModel SignatureDef contains the following input(s):\n  The given SavedModel SignatureDef contains the following output(s):\n    outputs['__saved_model_init_op'] tensor_info:\n        dtype: DT_INVALID\n        shape: unknown_rank\n        name: NoOp\n  Method name is: \n\nsignature_def['serving_default']:\n  The given SavedModel SignatureDef contains the following input(s):\n    inputs['inputs'] tensor_info:\n        dtype: DT_FLOAT\n        shape: (-1, 2)\n        name: serving_default_inputs:0\n  The given SavedModel SignatureDef contains the following output(s):\n    outputs['outputs'] tensor_info:\n        dtype: DT_FLOAT\n        shape: (-1, 1)\n        name: StatefulPartitionedCall:0\n  Method name is: tensorflow/serving/predict\nWARNING:tensorflow:From /tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\n\nDefined Functions:\n  Function Name: '__call__'\n    Option #1\n      Callable with:\n        Argument #1\n          inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs')\n        Argument #2\n          DType: bool\n          Value: False\n        Argument #3\n          DType: NoneType\n          Value: None\n    Option #2\n      Callable with:\n        Argument #1\n          inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs')\n        Argument #2\n          DType: bool\n          Value: True\n        Argument #3\n          DType: NoneType\n          Value: None\n\n  Function Name: '_default_save_signature'\n    Option #1\n      Callable with:\n        Argument #1\n          inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs')\n\n  Function Name: 'call_and_return_all_conditional_losses'\n    Option #1\n      Callable with:\n        Argument #1\n          inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs')\n        Argument #2\n          DType: bool\n          Value: True\n        Argument #3\n          DType: NoneType\n          Value: None\n    Option #2\n      Callable with:\n        Argument #1\n          inputs: TensorSpec(shape=(None, 2), dtype=tf.float32, name='inputs')\n        Argument #2\n          DType: bool\n          Value: False\n        Argument #3\n          DType: NoneType\n          Value: None\n```\n\n```python\n\n```\n\n### 二，安装 tensorflow serving\n\n\n安装 tensorflow serving 有2种主要方法：通过Docker镜像安装，通过apt安装。\n\n通过Docker镜像安装是最简单，最直接的方法，推荐采用。\n\nDocker可以理解成一种容器，其上面可以给各种不同的程序提供独立的运行环境。\n\n一般业务中用到tensorflow的企业都会有运维同学通过Docker 搭建 tensorflow serving.\n\n无需算法工程师同学动手安装，以下安装过程仅供参考。\n\n不同操作系统机器上安装Docker的方法可以参照以下链接。\n\nWindows: https://www.runoob.com/docker/windows-docker-install.html\n\nMacOs: https://www.runoob.com/docker/macos-docker-install.html\n\nCentOS: https://www.runoob.com/docker/centos-docker-install.html\n\n安装Docker成功后，使用如下命令加载 tensorflow/serving 镜像到Docker中\n\ndocker pull tensorflow/serving\n\n\n```python\n\n```\n\n### 三，启动 tensorflow serving 服务\n\n```python\n!docker run -t --rm -p 8501:8501 \\\n    -v \"/Users/.../data/linear_model/\" \\\n    -e MODEL_NAME=linear_model \\\n    tensorflow/serving & >server.log 2>&1\n```\n\n```python\n\n```\n\n### 四，向API服务发送请求\n\n\n可以使用任何编程语言的http功能发送请求，下面示范linux的 curl 命令发送请求，以及Python的requests库发送请求。\n\n```python\n!curl -d '{\"instances\": [1.0, 2.0, 5.0]}' \\\n    -X POST http://localhost:8501/v1/models/linear_model:predict\n```\n\n```\n{\n    \"predictions\": [[3.06546211], [5.01313448]\n    ]\n}\n```\n\n```python\nimport json,requests\n\ndata = json.dumps({\"signature_name\": \"serving_default\", \"instances\": [[1.0, 2.0], [5.0,7.0]]})\nheaders = {\"content-type\": \"application/json\"}\njson_response = requests.post('http://localhost:8501/v1/models/linear_model:predict', \n        data=data, headers=headers)\npredictions = json.loads(json_response.text)[\"predictions\"]\nprint(predictions)\n```\n\n```\n[[3.06546211], [6.02843142]]\n```\n\n```python\n\n```\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n\n```python\n\n```\n\n```python\n\n```\n# 6-7,使用spark-scala调用tensorflow2.0训练好的模型\n\n本篇文章介绍在spark中调用训练好的tensorflow模型进行预测的方法。\n\n本文内容的学习需要一定的spark和scala基础。\n\n如果使用pyspark的话会比较简单，只需要在每个excutor上用Python加载模型分别预测就可以了。\n\n但工程上为了性能考虑，通常使用的是scala版本的spark。\n\n本篇文章我们通过TensorFlow for Java 在spark中调用训练好的tensorflow模型。\n\n利用spark的分布式计算能力，从而可以让训练好的tensorflow模型在成百上千的机器上分布式并行执行模型推断。\n\n\n\n\n```python\n\n```\n\n### 〇，spark-scala调用tensorflow模型概述\n\n\n在spark(scala)中调用tensorflow模型进行预测需要完成以下几个步骤。\n\n（1）准备protobuf模型文件\n\n（2）创建spark(scala)项目，在项目中添加java版本的tensorflow对应的jar包依赖\n\n（3）在spark(scala)项目中driver端加载tensorflow模型调试成功\n\n（4）在spark(scala)项目中通过RDD在excutor上加载tensorflow模型调试成功\n\n（5） 在spark(scala)项目中通过DataFrame在excutor上加载tensorflow模型调试成功\n\n\n```python\n\n```\n\n### 一，准备protobuf模型文件\n\n\n我们使用tf.keras 训练一个简单的线性回归模型，并保存成protobuf文件。\n\n```python\n\n```\n\n```python\nimport tensorflow as tf\nfrom tensorflow.keras import models,layers,optimizers\n\n## 样本数量\nn = 800\n\n## 生成测试用数据集\nX = tf.random.uniform([n,2],minval=-10,maxval=10) \nw0 = tf.constant([[2.0],[-1.0]])\nb0 = tf.constant(3.0)\n\nY = X@w0 + b0 + tf.random.normal([n,1],mean = 0.0,stddev= 2.0)  # @表示矩阵乘法,增加正态扰动\n\n## 建立模型\ntf.keras.backend.clear_session()\ninputs = layers.Input(shape = (2,),name =\"inputs\") #设置输入名字为inputs\noutputs = layers.Dense(1, name = \"outputs\")(inputs) #设置输出名字为outputs\nlinear = models.Model(inputs = inputs,outputs = outputs)\nlinear.summary()\n\n## 使用fit方法进行训练\nlinear.compile(optimizer=\"rmsprop\",loss=\"mse\",metrics=[\"mae\"])\nlinear.fit(X,Y,batch_size = 8,epochs = 100)  \n\ntf.print(\"w = \",linear.layers[1].kernel)\ntf.print(\"b = \",linear.layers[1].bias)\n\n## 将模型保存成pb格式文件\nexport_path = \"./data/linear_model/\"\nversion = \"1\"       #后续可以通过版本号进行模型版本迭代与管理\nlinear.save(export_path+version, save_format=\"tf\") \n\n```\n\n```python\n\n```\n\n```python\n!ls {export_path+version}\n```\n\n```python\n# 查看模型文件相关信息\n!saved_model_cli show --dir {export_path+str(version)} --all\n```\n\n```python\n\n```\n\n模型文件信息中这些标红的部分都是后面有可能会用到的。\n\n![](./data/模型文件信息.png)\n\n```python\n\n```\n\n### 二，创建spark(scala)项目，在项目中添加java版本的tensorflow对应的jar包依赖\n\n```python\n\n```\n\n如果使用maven管理项目，需要添加如下 jar包依赖\n\n```\n<!-- https://mvnrepository.com/artifact/org.tensorflow/tensorflow -->\n<dependency>\n    <groupId>org.tensorflow</groupId>\n    <artifactId>tensorflow</artifactId>\n    <version>1.15.0</version>\n</dependency>\n```\n\n也可以从下面网址中直接下载 org.tensorflow.tensorflow的jar包\n\n以及其依赖的org.tensorflow.libtensorflow 和 org.tensorflowlibtensorflow_jni的jar包 放到项目中。\n\nhttps://mvnrepository.com/artifact/org.tensorflow/tensorflow/1.15.0\n\n\n```python\n\n```\n\n```python\n\n```\n\n### 三， 在spark(scala)项目中driver端加载tensorflow模型调试成功\n\n\n我们的示范代码在jupyter notebook中进行演示，需要安装toree以支持spark(scala)。\n\n\n```scala\nimport scala.collection.mutable.WrappedArray\nimport org.{tensorflow=>tf}\n\n//注：load函数的第二个参数一般都是“serve”，可以从模型文件相关信息中找到\n\nval bundle = tf.SavedModelBundle \n   .load(\"/Users/liangyun/CodeFiles/eat_tensorflow2_in_30_days/data/linear_model/1\",\"serve\")\n\n//注：在java版本的tensorflow中还是类似tensorflow1.0中静态计算图的模式，需要建立Session, 指定feed的数据和fetch的结果, 然后 run.\n//注：如果有多个数据需要喂入，可以连续用用多个feed方法\n//注：输入必须是float类型\n\nval sess = bundle.session()\nval x = tf.Tensor.create(Array(Array(1.0f,2.0f),Array(2.0f,3.0f)))\nval y =  sess.runner().feed(\"serving_default_inputs:0\", x)\n         .fetch(\"StatefulPartitionedCall:0\").run().get(0)\n\nval result = Array.ofDim[Float](y.shape()(0).toInt,y.shape()(1).toInt)\ny.copyTo(result)\n\nif(x != null) x.close()\nif(y != null) y.close()\nif(sess != null) sess.close()\nif(bundle != null) bundle.close()  \n\nresult\n\n```\n\n\n输出如下：\n\n```\nArray(Array(3.019596), Array(3.9878292))\n```\n\n\n![](./data/TfDriver.png)\n\n```python\n\n```\n\n### 四，在spark(scala)项目中通过RDD在excutor上加载tensorflow模型调试成功\n\n\n下面我们通过广播机制将Driver端加载的TensorFlow模型传递到各个excutor上，并在excutor上分布式地调用模型进行推断。\n\n\n\n```scala\nimport org.apache.spark.sql.SparkSession\nimport scala.collection.mutable.WrappedArray\nimport org.{tensorflow=>tf}\n\nval spark = SparkSession\n    .builder()\n    .appName(\"TfRDD\")\n    .enableHiveSupport()\n    .getOrCreate()\n\nval sc = spark.sparkContext\n\n//在Driver端加载模型\nval bundle = tf.SavedModelBundle \n   .load(\"/Users/liangyun/CodeFiles/master_tensorflow2_in_20_hours/data/linear_model/1\",\"serve\")\n\n//利用广播将模型发送到excutor上\nval broads = sc.broadcast(bundle)\n\n//构造数据集\nval rdd_data = sc.makeRDD(List(Array(1.0f,2.0f),Array(3.0f,5.0f),Array(6.0f,7.0f),Array(8.0f,3.0f)))\n\n//通过mapPartitions调用模型进行批量推断\nval rdd_result = rdd_data.mapPartitions(iter => {\n    \n    val arr = iter.toArray\n    val model = broads.value\n    val sess = model.session()\n    val x = tf.Tensor.create(arr)\n    val y =  sess.runner().feed(\"serving_default_inputs:0\", x)\n             .fetch(\"StatefulPartitionedCall:0\").run().get(0)\n\n    //将预测结果拷贝到相同shape的Float类型的Array中\n    val result = Array.ofDim[Float](y.shape()(0).toInt,y.shape()(1).toInt)\n    y.copyTo(result)\n    result.iterator\n    \n})\n\n\nrdd_result.take(5)\nbundle.close\n```\n\n\n```python\n\n```\n\n输出如下：\n\n```\nArray(Array(3.019596), Array(3.9264367), Array(7.8607616), Array(15.974984))\n```\n\n\n![](./data/TfRDD.png)\n\n```python\n\n```\n\n### 五， 在spark(scala)项目中通过DataFrame在excutor上加载tensorflow模型调试成功\n\n\n除了可以在Spark的RDD数据上调用tensorflow模型进行分布式推断，\n\n我们也可以在DataFrame数据上调用tensorflow模型进行分布式推断。\n\n主要思路是将推断方法注册成为一个sparkSQL函数。\n\n\n```scala\nimport org.apache.spark.sql.SparkSession\nimport scala.collection.mutable.WrappedArray\nimport org.{tensorflow=>tf}\n\nobject TfDataFrame extends Serializable{\n    \n    \n    def main(args:Array[String]):Unit = {\n        \n        val spark = SparkSession\n        .builder()\n        .appName(\"TfDataFrame\")\n        .enableHiveSupport()\n        .getOrCreate()\n        val sc = spark.sparkContext\n        \n        \n        import spark.implicits._\n\n        val bundle = tf.SavedModelBundle \n           .load(\"/Users/liangyun/CodeFiles/master_tensorflow2_in_20_hours/data/linear_model/1\",\"serve\")\n\n        val broads = sc.broadcast(bundle)\n        \n        //构造预测函数，并将其注册成sparkSQL的udf\n        val tfpredict = (features:WrappedArray[Float])  => {\n            val bund = broads.value\n            val sess = bund.session()\n            val x = tf.Tensor.create(Array(features.toArray))\n            val y =  sess.runner().feed(\"serving_default_inputs:0\", x)\n                     .fetch(\"StatefulPartitionedCall:0\").run().get(0)\n            val result = Array.ofDim[Float](y.shape()(0).toInt,y.shape()(1).toInt)\n            y.copyTo(result)\n            val y_pred = result(0)(0)\n            y_pred\n        }\n        spark.udf.register(\"tfpredict\",tfpredict)\n        \n        //构造DataFrame数据集，将features放到一列中\n        val dfdata = sc.parallelize(List(Array(1.0f,2.0f),Array(3.0f,5.0f),Array(7.0f,8.0f))).toDF(\"features\")\n        dfdata.show \n        \n        //调用sparkSQL预测函数，增加一个新的列作为y_preds\n        val dfresult = dfdata.selectExpr(\"features\",\"tfpredict(features) as y_preds\")\n        dfresult.show \n        bundle.close\n    }\n}\n\n```\n\n\n\n```scala\nTfDataFrame.main(Array())\n```\n\n\n```\n+----------+\n|  features|\n+----------+\n|[1.0, 2.0]|\n|[3.0, 5.0]|\n|[7.0, 8.0]|\n+----------+\n\n+----------+---------+\n|  features|  y_preds|\n+----------+---------+\n|[1.0, 2.0]| 3.019596|\n|[3.0, 5.0]|3.9264367|\n|[7.0, 8.0]| 8.828995|\n+----------+---------+\n```\n\n\n以上我们分别在spark 的RDD数据结构和DataFrame数据结构上实现了调用一个tf.keras实现的线性回归模型进行分布式模型推断。\n\n在本例基础上稍作修改则可以用spark调用训练好的各种复杂的神经网络模型进行分布式模型推断。\n\n但实际上tensorflow并不仅仅适合实现神经网络，其底层的计算图语言可以表达各种数值计算过程。\n\n利用其丰富的低阶API，我们可以在tensorflow2.0上实现任意机器学习模型，\n\n结合tf.Module提供的便捷的封装功能，我们可以将训练好的任意机器学习模型导出成模型文件并在spark上分布式调用执行。\n\n这无疑为我们的工程应用提供了巨大的想象空间。\n\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n\n![image.png](./data/Python与算法之美logo.jpg)\n"
        },
        {
          "name": "english",
          "type": "tree",
          "content": null
        },
        {
          "name": "push-to-github.py",
          "type": "blob",
          "size": 1.5859375,
          "content": "# -*- coding: utf-8 -*-\n# ## 推送主分支\n\n# !git config --global user.email \"lyhue1991@163.com\"\n# 出现一些类似 warning: LF will be replaced by CRLF in <file-name>. 可启用如下设置。\n# !git config --global core.autocrlf false\n# 配置打印历史commit的快捷命令\n# !git config --global alias.lg \"log --oneline --graph --all\"\n\n# !git init\n\n# !git add  ./data/*  ./english/* *.md *.py\n\n\n\n# !git rm --cached  .ipynb_checkpoints/* \n\n# !git commit -m \"revise some chapters\" \n\n# !git remote rm origin \n\n# !git remote add origin git@github.com:lyhue1991/eat_tensorflow2_in_30_days.git\n\n# !git remote add gitee https://gitee.com/Python_Ai_Road/eat_tensorflow2_in_30_days\n\n# +\n# #!git pull  origin master \n# -\n\n# !git push   origin master \n\n# !git push -f gitee master \n\n# ## 创建pages分支\n\n# !git checkout -b gh-pages\n\n# !git rm --cached -r *.md\n\n# !git clean -df\n# !rm -rf *.md\n\n# !cp -r _book/* .\n\n# !git add .\n\n# !git reset\n\n# !git pull origin gh-pages\n\n# !git commit -m 'add gh-pages'\n\n# !git push -u origin gh-pages\n\n# !git checkout pages\n\n# ## 更新命令\n\n# !git checkout master\n\n# !git add ./data/*  *.md *.py\n\n# !git commit -m \"revise readme\"\n\n# !git push -u origin master\n\n# !gitbook build\n\n# !git branch -D gh-pages \n\n# !git checkout -b gh-pages\n\n# !git rm --cached -r *.md\n\n# !git clean -df\n\n# !rm -rf *.md\n\n# !cp -r _book/* .\n\n# !git add .\n# !git commit -m \"add postscript\"\n\n# !git push -f origin gh-pages\n\n# !git checkout master\n\n\n# ### 创建english分支\n\n# !git checkout -b english\n\n# !git add ./data/*  *.md *.py\n\n# !git commit -m \"init branch\"\n\n# !git push origin english:english\n\n\n\n\n\n\n\n"
        },
        {
          "name": "一、TensorFlow的建模流程.md",
          "type": "blob",
          "size": 1.38671875,
          "content": "# 一、TensorFlow的建模流程\n\n\n尽管TensorFlow设计上足够灵活，可以用于进行各种复杂的数值计算。\n\n但通常人们使用TensorFlow来实现机器学习模型，尤其常用于实现神经网络模型。\n\n从原理上说可以使用张量构建计算图来定义神经网络，并通过自动微分机制训练模型。\n\n但为简洁起见，一般推荐使用TensorFlow的高层次keras接口来实现神经网络网模型。\n\n<!-- #region -->\n使用TensorFlow实现神经网络模型的一般流程包括：\n\n1，准备数据\n\n2，定义模型\n\n3，训练模型\n\n4，评估模型\n\n5，使用模型\n\n6，保存模型。\n\n\n**对新手来说，其中最困难的部分实际上是准备数据过程。** \n\n我们在实践中通常会遇到的数据类型包括结构化数据，图片数据，文本数据，时间序列数据。\n\n我们将分别以titanic生存预测问题，cifar2图片分类问题，imdb电影评论分类问题，国内新冠疫情结束时间预测问题为例，演示应用tensorflow对这四类数据的建模方法。\n\n\n<!-- #endregion -->\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![image.png](./data/算法美食屋二维码.jpg)\n"
        },
        {
          "name": "三、TensorFlow的层次结构.md",
          "type": "blob",
          "size": 1.7236328125,
          "content": "# 三、TensorFlow的层次结构\n\n\n本章我们介绍TensorFlow中5个不同的层次结构：即硬件层，内核层，低阶API，中阶API，高阶API。并以线性回归和DNN二分类模型为例，直观对比展示在不同层级实现模型的特点。\n\nTensorFlow的层次结构从低到高可以分成如下五层。\n\n最底层为硬件层，TensorFlow支持CPU、GPU或TPU加入计算资源池。\n\n第二层为C++实现的内核，kernel可以跨平台分布运行。\n\n第三层为Python实现的操作符，提供了封装C++内核的低级API指令，主要包括各种张量操作算子、计算图、自动微分.\n如tf.Variable,tf.constant,tf.function,tf.GradientTape,tf.nn.softmax...\n如果把模型比作一个房子，那么第三层API就是【模型之砖】。\n\n第四层为Python实现的模型组件，对低级API进行了函数封装，主要包括各种模型层，损失函数，优化器，数据管道，特征列等等。\n如tf.keras.layers,tf.keras.losses,tf.keras.metrics,tf.keras.optimizers,tf.data.DataSet,tf.feature_column...\n如果把模型比作一个房子，那么第四层API就是【模型之墙】。\n\n第五层为Python实现的模型成品，一般为按照OOP方式封装的高级API，主要为tf.keras.models提供的模型的类接口。\n如果把模型比作一个房子，那么第五层API就是模型本身，即【模型之屋】。\n\n\n<img src=\"./data/tensorflow_structure.jpg\">\n\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![image.png](./data/算法美食屋二维码.jpg)\n"
        },
        {
          "name": "二、TensorFlow的核心概念.md",
          "type": "blob",
          "size": 1.41796875,
          "content": "# 二、TensorFlow的核心概念\n\nTensorFlow™ 是一个采用 **数据流图**（data flow graphs），用于数值计算的开源软件库。节点（Nodes）在图中表示数学操作，图中的线（edges）则表示在节点间相互联系的多维数据数组，即张量（tensor）。它灵活的架构让你可以**在多种平台上展开计算**，例如台式计算机中的一个或多个CPU（或GPU），服务器，移动设备等等。TensorFlow 最初由Google大脑小组（隶属于Google机器智能研究机构）的研究员和工程师们开发出来，**用于机器学习和深度神经网络**方面的研究，但这个系统的通用性使其也可**广泛用于其他计算领域**。 \n\n\nTensorFlow的主要优点：\n\n* 灵活性：支持底层数值计算，C++自定义操作符\n\n* 可移植性：从服务器到PC到手机，从CPU到GPU到TPU\n\n* 分布式计算：分布式并行计算，可指定操作符对应计算设备\n\n\n俗话说，万丈高楼平地起，TensorFlow这座大厦也有它的地基。\n\nTensorflow底层最核心的概念是张量，计算图以及自动微分。\n\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![image.png](./data/算法美食屋二维码.jpg)\n"
        },
        {
          "name": "五、TensorFlow的中阶API.md",
          "type": "blob",
          "size": 0.7236328125,
          "content": "# 五、TensorFlow的中阶API\n\nTensorFlow的中阶API主要包括: \n\n* 数据管道(tf.data)\n\n* 特征列(tf.feature_column)\n\n* 激活函数(tf.nn)\n\n* 模型层(tf.keras.layers)\n\n* 损失函数(tf.keras.losses)\n\n* 评估函数(tf.keras.metrics)\n\n* 优化器(tf.keras.optimizers)\n\n* 回调函数(tf.keras.callbacks)\n\n如果把模型比作一个房子，那么中阶API就是【模型之墙】。\n\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![image.png](./data/算法美食屋二维码.jpg)\n\n```python\n\n```\n"
        },
        {
          "name": "六、TensorFlow的高阶API.md",
          "type": "blob",
          "size": 0.796875,
          "content": "# 六、TensorFlow的高阶API\n\nTensorFlow的高阶API主要是tensorflow.keras.models.\n\n本章我们主要详细介绍tensorflow.keras.models相关的以下内容。\n\n* 模型的构建（Sequential、functional API、Model子类化）\n\n* 模型的训练（内置fit方法、内置train_on_batch方法、自定义训练循环、单GPU训练模型、多GPU训练模型、TPU训练模型）\n\n* 模型的部署（tensorflow serving部署模型、使用spark(scala)调用tensorflow模型）\n\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![image.png](./data/算法美食屋二维码.jpg)\n"
        },
        {
          "name": "后记：一个吃货和一道菜的故事.md",
          "type": "blob",
          "size": 16.0146484375,
          "content": "# 一个吃货和一道菜的故事\n\n\n《30天吃掉那只TensorFlow2》这本书已经全部整理完稿。本篇文章算是这本书的一个后记。\n\n本文介绍了一个吃货与算法结缘的故事，并介绍了本书的写作过程。可供感兴趣的读者一乐。\n\n如果读者时间紧迫，可直接阅读本文第3部分和第4部分，了解书籍内容和获取方法。\n\n\n### 一，一个吃货转行算法的心路历程\n\n\n2015年6月，又是一个毕业季，一个吃货从北京吃饭大学毕业了。\n\n虽然是吃饭大学毕业，但他学的是理论物理，而理论物理不是一个适合找饭吃的专业。\n\n几经辗转，这个吃货在金融行业找到了一份量化程序员的工作，虽然收入低微，但是这个吃货梦想有一天可以找到能够稳定盈利的量化策略，通过交易赚钱让自己能够每天都有口好吃的。\n\n然而，资本市场波谲云诡，他尝试过许多交易策略，却没有找到能够稳定赚钱的\"圣杯\"，伙食也一天比一天变差了。\n\n在与K线的纠缠中，他慢慢地迷失了，虽然他知道每次亏钱都是靠实力输的，但是他不知道自己每次赚钱是凭借实力赚的还是凭运气赚的。他感到在金融交易这个行业很难清晰地看到自己的进步。\n\n付出了那么多的努力，搞了那么多模型，写了那么多策略，自己就真的有成长吗？在残酷的交易世界里，这些东西不能赚钱，不能够改善自己的伙食，又有什么价值呢？\n\n\n作为一个吃货，他无法忍受伙食变得越来越差。他决定换一个能够稳定地让伙食变得更好的行业。\n\n那个时候，随着AlphaGo战胜世界围棋冠军李世石的故事广为人知，在互联网领域有一个新兴岗位逐渐火热，那就是算法工程师。\n\n这个吃货心想，我也是做模型的，算法工程师也是做模型的，怎么伙食差别这么大，不行我要转行做算法工程师。\n\n然后吃货就开始准备了。吃货性格内向，不擅言谈，交际圈较小，身边没有认识做算法工程师的朋友。\n\n于是吃货从一些招聘网站上浏览了一些算法工程师的招聘信息，又在知乎等平台上浏览了一些关于转行算法工程师的相关帖子。\n\n\n他给自己制定了一个为期半年左右的学习计划。学习顺序大概如下：\n\n* 1，Python编程\n* 2，Numpy,Pandas,matplotlib数据分析\n* 3，beautifulSoup,requests网络爬虫 \n* 4，sklearn机器学习（同步学习《机器学习实战》，李航《统计学习方法》）\n* 5，tensorflow深度学习（同步学习吴恩达的《深度学习》视频课程）\n\n他决定第4阶段学的差不多就去找算法工程师的工作。\n\n（PS：实践表明，这个学习计划的第3部分是可以去除的。算法工程师通常不需要掌握爬虫技术，算法工程师训练模型所需要的数据一般来自于公司业务，直接从数据库中获取即可。）\n\n\n为了确保自己能够真正地学会，并能够清晰地看到自己的成长。这个吃货决定要让自己的学习留下点痕迹。\n\n同时，他又想，能不能在学习的同时改善一下自己的伙食呢？思来想去，最后他找到了一个方法，那就是每学完一个部分，就录制一个视频课程拿到网易云课堂上去卖。看能不能每个月多个三块五块的，以便改善一下伙食。\n\n**一个吃货，一旦决定为了改善自己的伙食想要做点什么，他的意志力是惊人的。**\n\n于是，大概有半年左右，这个吃货每天晚上和周末的时间都几乎花在了这几个课程的学习和输出上。网易云课堂上陆陆续续多了这个吃货的以下5门课程。\n\n\n**第一门课程：《Python编程ABC》**\n\n![](./data/Python编程ABC.png)\n\n吃货本来做量化交易掌握了一些Python编程基础，但不是很熟练，学习加整理这个课程大概花了半个月。\n\n考虑到自身水平有限，吃货怕没有一个人买，不敢卖高价，因此该课程标价1元，上线2年多，总共卖出108份。\n\n算下来还是不错的，每个月多个三块钱伙食费的理想还是基本实现了的，离五块钱还差一些。\n\n该课程尽管买的人不多，还是有几个评价的。\n\n![](./data/上当了.png)\n\n**第二门课程：《Python数据分析》**\n\n![](./data/Python数据分析.png)\n\nPython数据分析的3个标准套件：numpy,Pandas,matplotlib 掌握起来还是需要下点功夫的。\n\n吃货学习这几个库和整理最终的课程大概花了一个半月。考虑到这门课程做了比较久的时间，同时吃货感到自己的水平有了那么一丢丢进步了，Pandas玩的基本666的了，吃货决定这门课卖10块钱一份，看看能不能每个月多个5块10块的。\n\n这门课程上线2年多，总共卖出去35份。看来每个月多个10块的目标也是基本实现了的。这门课由于买的人非常少，所以目前还没有收到过评价。关起门来说，这门课的质量只能算是让人不忍心给差评吧。\n\n\n**第三门课程：《Python网络爬虫入门》**\n\n![](./data/Python网络爬虫入门.png)\n\n**第四门课程：《Python网络爬虫进阶》**\n\n![](./data/Python网络爬虫进阶.png)\n\nPython网络爬虫的基础还是不难的，但如果要熟练掌握各种反爬策略的突破以及对动态网页的抓取还是非常有挑战性的，\n\nPython爬虫的学习以及这两门课程的制作大概花费了吃货2个月的时间。\n\n其中的网络爬虫入门课程是免费课程，网络爬虫进阶课程售价30元。\n\n网络爬虫入门课程收获了不少好评，虽然没有赚到一毛钱，不能直接改善伙食，但吃货看了这些好评，感觉比吃了蜜还要甜。\n\n![](./data/内容非常棒.png)\n\n\n**第五门课程：《sklearn机器学习》**\n\n![](./data/sklearn机器学习.png)\n\n在做这门课程的时候，吃货同步学习了《机器学习实战》和《统计学习方法》的一些章节。包括学习和输出，大概花了吃货2个月左右时间。\n\n整体上，sklearn的基础使用和机器学习的基本概念的掌握还是不困难的。决策树和SVM的一些原理可能坑会比较多，需要花费较多时间梳理。\n\n吃货的这门课程售价68元，整体上评价较高，达到4.7颗星。\n\n![](./data/良心课程.png)\n\n实际上这门课程做到一半的时候，吃货决定裸辞，因为那时候大概是2018年3月份了，是招聘的黄金时期。经过了半年多的准备，吃货信心满满，感觉已经掌握了从Python基础到Python数据分析到Python机器学习的基本技能，应该能够摸到算法工程师的工作机会。\n\n吃货开始在Boss上和拉勾上投递简历，那时候正是算法岗需求most火爆的时期，吃货陆陆续续收到了一些二三线互联网公司的面试邀约。但陆续面了好几场，吃货发现自己总是会遇到一些如手写二分查找，手写快排算法，手写爬楼梯方法这样的问题。拿到这些问题后吃货一脸懵逼，在纸上抓破脑袋写下了几行import numpy as np,import pandas as pd 这样的东西，然后面试官就笑盈盈地跟吃货说，你回去等通知吧。\n\n于是，吃货一边白天面试，一边晚上回家整理白天遇到的这些问题，并重点针对一些常见的手写代码题进行了准备，掌握了一些像时间复杂度和动态规划这样基本的数据结构和算法知识。周末的时候，再继续录制《sklearn机器学习》这个课程。这样大概持续了半个多月，吃货开始收到一些offer. 很快，吃货跟一个offer确认了眼神，正式转行成为了一个互联网行业的搬砖工，伙食相比以前有了较大的改善，吃货的心里乐开了花。\n\n吃货后来在周末的时候也把这些面试的经验总结起来，放在了网易云课堂上。\n\n![](./data/面试指南.png)\n\n这个课程的评价比较两级分化，有人叫好，也有人吐槽说木有什么卵用。\n\n![](./data/太一般了.png)\n\n\n\n### 二，吃货为什么要写这本书？\n\n\n成为了一名互联网搬砖工后，吃货本想着在周末时间，把自己转行之前制定的学习计划的第5部分，即tensorflow深度学习（同步学习吴恩达的《深度学习》视频课程）这部分付诸实施。\n\n但搬砖工作非常辛苦，同时工作还需要吃货掌握一些其它的技能，例如linux基本操作，git基本操作，Hive数据库，mapreduce编程方法，xgboost和lightgbm建模方法等等。\n\n大概半年后，吃货才感到已经熟练掌握了当时工作所需要的主要技能，能够较为顺利地开发项目。到了周末的时候，吃货开始一边在网易云课堂上看吴恩达《深度学习》视频课程，一边学习使用tensorflow.\n\n\n![](./data/Ng的课程.png)\n\n\n吴恩达的这个系列的课程总体上非常不错，但略微偏理论一些，讲了较多的数学细节，吃货当时学的还是有些吃力的。大概用了半年的周末时间，才基本学习完成了这五门课，并梳理出来了5篇学习笔记。\n\n后来吃货向\"Python之禅\"公众号投稿了一篇文章《18式优雅你的Python》，号主志军大大在后来做抽奖送书的活动时就送了吃货一本书《Python深度学习》。这本书相比于吴恩达课程更加基础一些，该书假定读者无任何机器学习知识，以Keras为工具，使用丰富的范例演示深度学习的最佳实践。该书通俗易懂，全书没有一个数学公式，注重培养读者的深度学习直觉。吃货拿来该书，简直如获至宝，不到两个周末就吃完了，对深度学习在实践层面有了更为清晰的认识。\n\n同时，吃货还在学习tensorflow1.0，总体而言学得比较痛苦，官方文档讲的各种概念多而杂，静态图非常难以调试，tf.control_dependencies, tf.while_loop这些东西简直反人类，又是tf.estimator, 又是tflearn, 又是tf.keras，让人无所适从。吃货花费了非常多的时间，基本上才把tensorflow1.0常用的一些概念和工具梳理到一个适合人类理解的程度。\n\n但tensorflow不仁，以吃货为刍狗。就在吃货快要整理完这个tensorflow1.0教程的时候，tensorflow官方宣布将不久推出tensorflow2.0，默认使用动态图，并对API进行大幅度的调整。吃货当时心里的滋味，就好像一个男孩子追一个女生追了大半年，感觉基本摸清楚了这个女生的脾气和个性的时候，这个女生突然有一天对他说：\"你别追了，我要去做变性手术了，变成一个男孩子。\"\n\n\n于是，吃货转而开始学习Spark，整体而言，Spark的官方教程非常完善，网络上也有比较好的教程资源。吃货学起来非常顺利，不到2个月，就学习并整理了一份系统的Spark教程，放在了github仓库中。\n\n2019年10月1日，这是一个特别的日子。这一天既是祖国母亲的生日，也是tensorflow2.0的生日。在这一天tensorflow官方宣布发布tensorflow2.0的正式版本。吃货知道这个消息后非常开心，就好像一个花痴终于等到了花开一样。但是吃货当时正在做一个他搬砖以来遇到过的最复杂的一个spark大数据挖掘项目，周末的时间都投入到这个项目的攻坚中去了。吃货决定等这个项目基本完成后，重新学习并梳理一份tensorflow2的教程。\n\n大概在2020年初，吃货开始学习tensorflow2.0的官方文档。尽管tensorflow2.0宣称已经为改善用户体验做出了巨大的改进，really easy to use，但吃货学得并不轻松。tensorflow2.0官方文档和tensorflow1.0官方文档显然是出自同一批作者之手，他们一如既往地秉承着谷歌make things complicated的风格传统，用哈希表一般混乱的文档结构、无法运行的范例代码、复杂的函数嵌套调用关系、随意插入的不常用第三方库等技巧将读者的懵圈程度逐步推向高潮。\n\n在吃货看来，tensorflow2.0官方文档所有的问题可以抽象为一个问题：噪声太多。读者要从噪声如此之多的官方教程中提取出他想要的信息是非常的吃力的。如果把官方教程比作一盘菜，那么这盘菜虽然有许多营养物质，但也有许多的沙子，不小心咬到一口就硌得慌，甚至会觉得恶心得不行。吃货决定要做一盘营养丰富，且美味宜人的菜。\n\n吃货开始按照他想象中美味佳肴的样子来做这盘菜。周末本应适合去参加户外爬山活动，他对着电脑在做菜。放假回家的火车上，他对着电脑在做菜。春节到家后由于疫情影响不提倡窜门，他可以有更多时间开心地对着电脑做菜。疫情形势愈发严峻企业延迟复工，他回到北京一边隔离一边对着电脑在做菜。\n\n\n\n\n### 三，吃货写的这本书怎么样？\n\n\n前后用了约两个月，吃货的这本书基本写完了。吃货心想，该给它取个什么名字呢？\n\n嗯，有了，这是一本可以帮助大家改善伙食的书。大概可以连续吃30天，而且应该味道不错。\n\n就叫他《30天吃掉那只TensorFlow2》吧。\n\n从这本书的书名应该能够看出，作者是个吃货，而且是个很有毅力的吃货。\n\n这是一本怎么样的书呢？这是一本对人类用户极其友善的TensorFlow2.0入门工具书。\n\n为了尽可能降低信息噪声，这本书相比官方文档在篇章结构和范例选取上做了大量的优化。\n\n不同于官方文档混乱的篇章结构，既有教程又有指南，缺少整体的编排逻辑。\n\n这本书按照内容难易程度、读者检索习惯和TensorFlow自身的层次结构设计内容，循序渐进，层次清晰，方便按照功能查找相应范例。\n\n不同于官方文档冗长的范例代码，这本书在范例设计上尽可能简约化和结构化，增强范例易读性和通用性，大部分代码片段在实践中可即取即用。\n\n总之，这本书倾注了一个吃货对美食的全部向往和追求，如果你非常喜欢美食，并且想要学习TensorFlow2，那么这本书一定值得你品尝品尝。\n\n![](./data/书籍目录1.png)\n\n![](./data/书籍目录2.png)\n\n![](./data/书籍目录3.png)\n\n\n这本书在github上线1个月来，得到了不少小伙伴的反馈，提了一些issues，吃货针对相关问题进行了一些回答和对项目做了改进。\n\n同时这个项目也获得了100多颗星星，吃货看在眼里，美在心里，每天早上睡觉起来都会去github星球上数星星。\n\n![](./data/github截图.png)\n\n### 四，如何获取吃货写的这本书?\n\n\n这本书目前有4种形式获取。\n\n1，gitbook电子书。以网页链接呈现，同时可以在电脑和手机上用浏览器打开。\n\n电子书链接： https://lyhue1991.github.io/eat_tensorflow2_in_30_days\n\n2，github项目源码。包含全部数据集和md格式源码，可以在jupyter上安装jupytext后将md源码作为ipynb打开。\n\n项目链接：https://github.com/lyhue1991/eat_tensorflow2_in_30_days\n\n3，pdf格式电子书。\n\n4，ipynb格式项目源码。\n\n其中github项目源码和gitbook电子书将持续维护，后续可能也会增加一些新的范例。pdf版本电子书和ipynb项目源码可以在公众号\"**Python与算法之美**\"后台回复关键字: **tf** 进行获取。这两种形式获取的《eat tensorflow2 in 30 days》无法保证更新。\n\n阅读体验优先推荐使用gitbook电子书，具有目录查找和上下页翻页功能，字体大小和背景色可以根据个人喜好进行调整，颜值超高。\n\n![](./data/gitbook电子书.png)\n\n\n\n\n### 五，鼓励和联系这个吃货\n\n\n最后，想给大家讲一个吃货小王子的故事。\n\n>在很久很久以前，有一个小王子，住在一个只比他大一点点的星球上，他，想要一个朋友。\n\n>在昨天今天和明天，有一个吃货，住在一个只比他大一点点的github星球上，他，想要一颗星星。\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![image.png](./data/算法美食屋二维码.jpg)\n"
        },
        {
          "name": "四、TensorFlow的低阶API.md",
          "type": "blob",
          "size": 1.24609375,
          "content": "# 四、TensorFlow的低阶API\n\nTensorFlow的低阶API主要包括张量操作，计算图和自动微分。\n\n如果把模型比作一个房子，那么低阶API就是【模型之砖】。\n\n在低阶API层次上，可以把TensorFlow当做一个增强版的numpy来使用。\n\nTensorFlow提供的方法比numpy更全面，运算速度更快，如果需要的话，还可以使用GPU进行加速。\n\n前面几章我们对低阶API已经有了一个整体的认识，本章我们将重点详细介绍张量操作和Autograph计算图。\n\n\n张量的操作主要包括张量的结构操作和张量的数学运算。\n\n张量结构操作诸如：张量创建，索引切片，维度变换，合并分割。\n\n张量数学运算主要有：标量运算，向量运算，矩阵运算。另外我们会介绍张量运算的广播机制。\n\nAutograph计算图我们将介绍使用Autograph的规范建议，Autograph的机制原理，Autograph和tf.Module.\n\n\n\n如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n\n也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n\n![image.png](./data/算法美食屋二维码.jpg)\n"
        }
      ]
    }
  ]
}