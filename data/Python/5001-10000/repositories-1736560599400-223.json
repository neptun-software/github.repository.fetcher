{
  "metadata": {
    "timestamp": 1736560599400,
    "page": 223,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjIzMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "Yelp/elastalert",
      "stars": 8001,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 0.2109375,
          "content": "root = true\n\n[*]\nend_of_line = lf\ninsert_final_newline = true\ncharset = utf-8\n\n[*.py]\nindent_style = space\nindent_size = 4\n\n[Makefile]\nindent_style = tab\n\n[{*.json,*.yml,*.yaml}]\nindent_style = space\nindent_size = 2\n"
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.15625,
          "content": "config.yaml\n.tox/\n.coverage\n.idea/*\n.cache/\n__pycache__/\n*.pyc\nvirtualenv_run/\n*.egg-info/\ndist/\nvenv/\nenv/\ndocs/build/\nbuild/\n.pytest_cache/\nmy_rules\n*.swp\n*~\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.701171875,
          "content": "repos:\n-   repo: git://github.com/pre-commit/pre-commit-hooks\n    sha: v1.1.1\n    hooks:\n    -   id: trailing-whitespace\n    -   id: end-of-file-fixer\n    -   id: autopep8-wrapper\n        args:\n        - -i\n        - --ignore=E265,E309,E501\n    -   id: flake8\n    -   id: check-yaml\n    -   id: debug-statements\n    -   id: requirements-txt-fixer\n    -   id: name-tests-test\n-   repo: git://github.com/asottile/reorder_python_imports\n    sha: v0.3.5\n    hooks:\n    -   id: reorder-python-imports\n-   repo: git://github.com/Yelp/detect-secrets\n    sha: 0.9.1\n    hooks:\n    -   id: detect-secrets\n        args: ['--baseline', '.secrets.baseline']\n        exclude: .*tests/.*|.*yelp/testing/.*|\\.pre-commit-config\\.yaml\n"
        },
        {
          "name": ".secrets.baseline",
          "type": "blob",
          "size": 0.560546875,
          "content": "{\n  \"exclude_regex\": \".*tests/.*|.*yelp/testing/.*|\\\\.pre-commit-config\\\\.yaml\",\n  \"generated_at\": \"2018-07-06T22:54:22Z\",\n  \"plugins_used\": [\n    {\n      \"base64_limit\": 4.5,\n      \"name\": \"Base64HighEntropyString\"\n    },\n    {\n      \"hex_limit\": 3,\n      \"name\": \"HexHighEntropyString\"\n    },\n    {\n      \"name\": \"PrivateKeyDetector\"\n    }\n  ],\n  \"results\": {\n    \".travis.yml\": [\n      {\n        \"hashed_secret\": \"4f7a1ea04dafcbfee994ee1d08857b8aaedf8065\",\n        \"line_number\": 14,\n        \"type\": \"Base64 High Entropy String\"\n      }\n    ]\n  },\n  \"version\": \"0.9.1\"\n}\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 1.232421875,
          "content": "language: python\npython:\n- '3.6'\nenv:\n- TOXENV=docs\n- TOXENV=py36\ninstall:\n- pip install tox\n- >\n  if [[ -n \"${ES_VERSION}\" ]] ; then\n    wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-${ES_VERSION}.tar.gz\n    mkdir elasticsearch-${ES_VERSION} && tar -xzf elasticsearch-${ES_VERSION}.tar.gz -C elasticsearch-${ES_VERSION} --strip-components=1\n    ./elasticsearch-${ES_VERSION}/bin/elasticsearch &\n  fi\nscript:\n- >\n  if [[ -n \"${ES_VERSION}\" ]] ; then\n    wget -q --waitretry=1 --retry-connrefused --tries=30 -O - http://127.0.0.1:9200\n    make test-elasticsearch\n  else\n    make test\n  fi\njobs:\n  include:\n    - stage: 'Elasticsearch test'\n      env: TOXENV=py36 ES_VERSION=7.0.0-linux-x86_64\n    - env: TOXENV=py36 ES_VERSION=6.6.2\n    - env: TOXENV=py36 ES_VERSION=6.3.2\n    - env: TOXENV=py36 ES_VERSION=6.2.4\n    - env: TOXENV=py36 ES_VERSION=6.0.1\n    - env: TOXENV=py36 ES_VERSION=5.6.16\n\ndeploy:\n  provider: pypi\n  user: yelplabs\n  password:\n    secure: TpSTlFu89tciZzboIfitHhU5NhAB1L1/rI35eQTXstiqzYg2mweOuip+MPNx9AlX3Swg7MhaFYnSUvRqPljuoLjLD0EQ7BHLVSBFl92ukkAMTeKvM6LbB9HnGOwzmAvTR5coegk8IHiegudODWvnhIj4hp7/0EA+gVX7E55kEAw=\n  on:\n    tags: true\n    distributions: sdist bdist_wheel\n    repo: Yelp/elastalert\n    branch: master\n"
        },
        {
          "name": "Dockerfile-test",
          "type": "blob",
          "size": 0.23828125,
          "content": "FROM ubuntu:latest\n\nRUN apt-get update && apt-get upgrade -y\nRUN apt-get -y install build-essential python3.6 python3.6-dev python3-pip libssl-dev git\n\nWORKDIR /home/elastalert\n\nADD requirements*.txt ./\nRUN pip3 install -r requirements-dev.txt\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0927734375,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.515625,
          "content": ".PHONY: all production test docs clean\n\nall: production\n\nproduction:\n\t@true\n\ndocs:\n\ttox -e docs\n\ndev: $(LOCAL_CONFIG_DIR) $(LOGS_DIR) install-hooks\n\ninstall-hooks:\n\tpre-commit install -f --install-hooks\n\ntest:\n\ttox\n\ntest-elasticsearch:\n\ttox -- --runelasticsearch\n\ntest-docker:\n\tdocker-compose --project-name elastalert build tox\n\tdocker-compose --project-name elastalert run tox\n\nclean:\n\tmake -C docs clean\n\tfind . -name '*.pyc' -delete\n\tfind . -name '__pycache__' -delete\n\trm -rf virtualenv_run .tox .coverage *.egg-info build\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 15.8173828125,
          "content": "**ElastAlert is no longer maintained. Please use [ElastAlert2](https://github.com/jertel/elastalert2) instead.**\n\n\n[![Build Status](https://travis-ci.org/Yelp/elastalert.svg)](https://travis-ci.org/Yelp/elastalert)\n[![Join the chat at https://gitter.im/Yelp/elastalert](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/Yelp/elastalert?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\n## ElastAlert - [Read the Docs](http://elastalert.readthedocs.org).\n### Easy & Flexible Alerting With Elasticsearch\n\nElastAlert is a simple framework for alerting on anomalies, spikes, or other patterns of interest from data in Elasticsearch.\n\nElastAlert works with all versions of Elasticsearch.\n\nAt Yelp, we use Elasticsearch, Logstash and Kibana for managing our ever increasing amount of data and logs.\nKibana is great for visualizing and querying data, but we quickly realized that it needed a companion tool for alerting\non inconsistencies in our data. Out of this need, ElastAlert was created.\n\nIf you have data being written into Elasticsearch in near real time and want to be alerted when that data matches certain patterns, ElastAlert is the tool for you. If you can see it in Kibana, ElastAlert can alert on it.\n\n## Overview\n\nWe designed ElastAlert to be reliable, highly modular, and easy to set up and configure.\n\nIt works by combining Elasticsearch with two types of components, rule types and alerts.\nElasticsearch is periodically queried and the data is passed to the rule type, which determines when\na match is found. When a match occurs, it is given to one or more alerts, which take action based on the match.\n\nThis is configured by a set of rules, each of which defines a query, a rule type, and a set of alerts.\n\nSeveral rule types with common monitoring paradigms are included with ElastAlert:\n\n- Match where there are at least X events in Y time\" (``frequency`` type)\n- Match when the rate of events increases or decreases\" (``spike`` type)\n- Match when there are less than X events in Y time\" (``flatline`` type)\n- Match when a certain field matches a blacklist/whitelist\" (``blacklist`` and ``whitelist`` type)\n- Match on any event matching a given filter\" (``any`` type)\n- Match when a field has two different values within some time\" (``change`` type)\n- Match when a never before seen term appears in a field\" (``new_term`` type)\n- Match when the number of unique values for a field is above or below a threshold (``cardinality`` type)\n\nCurrently, we have built-in support for the following alert types:\n\n- Email\n- JIRA\n- OpsGenie\n- Commands\n- HipChat\n- MS Teams\n- Slack\n- Telegram\n- GoogleChat\n- AWS SNS\n- VictorOps\n- PagerDuty\n- PagerTree\n- Exotel\n- Twilio\n- Gitter\n- Line Notify\n- Zabbix\n\nAdditional rule types and alerts can be easily imported or written.\n\nIn addition to this basic usage, there are many other features that make alerts more useful:\n\n- Alerts link to Kibana dashboards\n- Aggregate counts for arbitrary fields\n- Combine alerts into periodic reports\n- Separate alerts by using a unique key field\n- Intercept and enhance match data\n\nTo get started, check out `Running ElastAlert For The First Time` in the [documentation](http://elastalert.readthedocs.org).\n\n## Running ElastAlert\nYou can either install the latest released version of ElastAlert using pip:\n\n```pip install elastalert```\n\nor you can clone the ElastAlert repository for the most recent changes:\n\n```git clone https://github.com/Yelp/elastalert.git```\n\nInstall the module:\n\n```pip install \"setuptools>=11.3\"```\n\n```python setup.py install```\n\nThe following invocation can be used to run ElastAlert after installing\n\n``$ elastalert [--debug] [--verbose] [--start <timestamp>] [--end <timestamp>] [--rule <filename.yaml>] [--config <filename.yaml>]``\n\n``--debug`` will print additional information to the screen as well as suppresses alerts and instead prints the alert body. Not compatible with `--verbose`.\n\n``--verbose`` will print additional information without suppressing alerts. Not compatible with `--debug.`\n\n``--start`` will begin querying at the given timestamp. By default, ElastAlert will begin querying from the present.\nTimestamp format is ``YYYY-MM-DDTHH-MM-SS[-/+HH:MM]`` (Note the T between date and hour).\nEg: ``--start 2014-09-26T12:00:00`` (UTC) or ``--start 2014-10-01T07:30:00-05:00``\n\n``--end`` will cause ElastAlert to stop querying at the given timestamp. By default, ElastAlert will continue\nto query indefinitely.\n\n``--rule`` will allow you to run only one rule. It must still be in the rules folder.\nEg: ``--rule this_rule.yaml``\n\n``--config`` allows you to specify the location of the configuration. By default, it is will look for config.yaml in the current directory.\n\n## Third Party Tools And Extras\n### Kibana plugin\n![img](https://raw.githubusercontent.com/bitsensor/elastalert-kibana-plugin/master/showcase.gif)\nAvailable at the [ElastAlert Kibana plugin repository](https://github.com/bitsensor/elastalert-kibana-plugin).\n\n### Docker\nA [Dockerized version](https://github.com/bitsensor/elastalert) of ElastAlert including a REST api is build from `master` to `bitsensor/elastalert:latest`.\n\n```bash\ngit clone https://github.com/bitsensor/elastalert.git; cd elastalert\ndocker run -d -p 3030:3030 \\\n    -v `pwd`/config/elastalert.yaml:/opt/elastalert/config.yaml \\\n    -v `pwd`/config/config.json:/opt/elastalert-server/config/config.json \\\n    -v `pwd`/rules:/opt/elastalert/rules \\\n    -v `pwd`/rule_templates:/opt/elastalert/rule_templates \\\n    --net=\"host\" \\\n    --name elastalert bitsensor/elastalert:latest\n```\n\n## Documentation\n\nRead the documentation at [Read the Docs](http://elastalert.readthedocs.org).\n\nTo build a html version of the docs locally\n\n```\npip install sphinx_rtd_theme sphinx\ncd docs\nmake html\n```\n\nView in browser at build/html/index.html\n\n## Configuration\n\nSee config.yaml.example for details on configuration.\n\n## Example rules\n\nExamples of different types of rules can be found in example_rules/.\n\n- ``example_spike.yaml`` is an example of the \"spike\" rule type, which allows you to alert when the rate of events, averaged over a time period,\nincreases by a given factor. This example will send an email alert when there are 3 times more events matching a filter occurring within the\nlast 2 hours than the number of events in the previous 2 hours.\n\n- ``example_frequency.yaml`` is an example of the \"frequency\" rule type, which will alert when there are a given number of events occuring\nwithin a time period. This example will send an email when 50 documents matching a given filter occur within a 4 hour timeframe.\n\n- ``example_change.yaml`` is an example of the \"change\" rule type, which will alert when a certain field in two documents changes. In this example,\nthe alert email is sent when two documents with the same 'username' field but a different value of the 'country_name' field occur within 24 hours\nof each other.\n\n- ``example_new_term.yaml`` is an example of the \"new term\" rule type, which alerts when a new value appears in a field or fields. In this example,\nan email is sent when a new value of (\"username\", \"computer\") is encountered in example login logs.\n\n## Frequently Asked Questions\n\n### My rule is not getting any hits?\n\nSo you've managed to set up ElastAlert, write a rule, and run it, but nothing happens, or it says ``0 query hits``. First of all, we recommend using the command ``elastalert-test-rule rule.yaml`` to debug. It will show you how many documents match your filters for the last 24 hours (or more, see ``--help``), and then shows you if any alerts would have fired. If you have a filter in your rule, remove it and try again. This will show you if the index is correct and that you have at least some documents. If you have a filter in Kibana and want to recreate it in ElastAlert, you probably want to use a query string. Your filter will look like\n\n```\nfilter:\n- query:\n    query_string:\n      query: \"foo: bar AND baz: abc*\"\n```\nIf you receive an error that Elasticsearch is unable to parse it, it's likely the YAML is not spaced correctly, and the filter is not in the right format. If you are using other types of filters, like ``term``, a common pitfall is not realizing that you may need to use the analyzed token. This is the default if you are using Logstash. For example,\n\n```\nfilter:\n- term:\n    foo: \"Test Document\"\n```\n\nwill not match even if the original value for ``foo`` was exactly \"Test Document\". Instead, you want to use ``foo.raw``. If you are still having trouble troubleshooting why your documents do not match, try running ElastAlert with ``--es_debug_trace /path/to/file.log``. This will log the queries made to Elasticsearch in full so that you can see exactly what is happening.\n\n### I got hits, why didn't I get an alert?\n\nIf you got logs that had ``X query hits, 0 matches, 0 alerts sent``, it depends on the ``type`` why you didn't get any alerts. If ``type: any``, a match will occur for every hit. If you are using ``type: frequency``, ``num_events`` must occur within ``timeframe`` of each other for a match to occur. Different rules apply for different rule types.\n\nIf you see ``X matches, 0 alerts sent``, this may occur for several reasons. If you set ``aggregation``, the alert will not be sent until after that time has elapsed. If you have gotten an alert for this same rule before, that rule may be silenced for a period of time. The default is one minute between alerts. If a rule is silenced, you will see ``Ignoring match for silenced rule`` in the logs.\n\nIf you see ``X alerts sent`` but didn't get any alert, it's probably related to the alert configuration. If you are using the ``--debug`` flag, you will not receive any alerts. Instead, the alert text will be written to the console. Use ``--verbose`` to achieve the same affects without preventing alerts. If you are using email alert, make sure you have it configured for an SMTP server. By default, it will connect to localhost on port 25. It will also use the word \"elastalert\" as the \"From:\" address. Some SMTP servers will reject this because it does not have a domain while others will add their own domain automatically. See the email section in the documentation for how to configure this.\n\n### Why did I only get one alert when I expected to get several?\n\nThere is a setting called ``realert`` which is the minimum time between two alerts for the same rule. Any alert that occurs within this time will simply be dropped. The default value for this is one minute. If you want to receive an alert for every single match, even if they occur right after each other, use\n\n```\nrealert:\n  minutes: 0\n```\n\nYou can of course set it higher as well.\n\n### How can I prevent duplicate alerts?\n\nBy setting ``realert``, you will prevent the same rule from alerting twice in an amount of time.\n\n```\nrealert:\n  days: 1\n```\n\nYou can also prevent duplicates based on a certain field by using ``query_key``. For example, to prevent multiple alerts for the same user, you might use\n\n```\nrealert:\n  hours: 8\nquery_key: user\n```\n\nNote that this will also affect the way many rule types work. If you are using ``type: frequency`` for example, ``num_events`` for a single value of ``query_key`` must occur before an alert will be sent. You can also use a compound of multiple fields for this key. For example, if you only wanted to receieve an alert once for a specific error and hostname, you could use\n\n```\nquery_key: [error, hostname]\n```\n\nInternally, this works by creating a new field for each document called ``field1,field2`` with a value of ``value1,value2`` and using that as the ``query_key``.\n\nThe data for when an alert will fire again is stored in Elasticsearch in the ``elastalert_status`` index, with a ``_type`` of ``silence`` and also cached in memory.\n\n### How can I change what's in the alert?\n\nYou can use the field ``alert_text`` to add custom text to an alert. By setting ``alert_text_type: alert_text_only``, it will be the entirety of the alert. You can also add different fields from the alert by using Python style string formatting and ``alert_text_args``. For example\n\n```\nalert_text: \"Something happened with {0} at {1}\"\nalert_text_type: alert_text_only\nalert_text_args: [\"username\", \"@timestamp\"]\n```\n\nYou can also limit the alert to only containing certain fields from the document by using ``include``.\n\n```\ninclude: [\"ip_address\", \"hostname\", \"status\"]\n```\n\n### My alert only contains data for one event, how can I see more?\n\nIf you are using ``type: frequency``, you can set the option ``attach_related: true`` and every document will be included in the alert. An alternative, which works for every type, is ``top_count_keys``. This will show the top counts for each value for certain fields. For example, if you have\n\n```\ntop_count_keys: [\"ip_address\", \"status\"]\n```\n\nand 10 documents matched your alert, it may contain something like\n\n```\nip_address:\n127.0.0.1: 7\n10.0.0.1: 2\n192.168.0.1: 1\n\nstatus:\n200: 9\n500: 1\n```\n\n### How can I make the alert come at a certain time?\n\nThe ``aggregation`` feature will take every alert that has occured over a period of time and send them together in one alert. You can use cron style syntax to send all alerts that have occured since the last once by using\n\n```\naggregation:\n  schedule: '2 4 * * mon,fri'\n```\n\n### I have lots of documents and it's really slow, how can I speed it up?\n\nThere are several ways to potentially speed up queries. If you are using ``index: logstash-*``, Elasticsearch will query all shards, even if they do not possibly contain data with the correct timestamp. Instead, you can use Python time format strings and set ``use_strftime_index``\n\n```\nindex: logstash-%Y.%m\nuse_strftime_index: true\n```\n\nAnother thing you could change is ``buffer_time``. By default, ElastAlert will query large overlapping windows in order to ensure that it does not miss any events, even if they are indexed in real time. In config.yaml, you can adjust ``buffer_time`` to a smaller number to only query the most recent few minutes.\n\n```\nbuffer_time:\n  minutes: 5\n```\n\nBy default, ElastAlert will download every document in full before processing them. Instead, you can have ElastAlert simply get a count of the number of documents that have occured in between each query. To do this, set ``use_count_query: true``. This cannot be used if you use ``query_key``, because ElastAlert will not know the contents of each documents, just the total number of them. This also reduces the precision of alerts, because all events that occur between each query will be rounded to a single timestamp.\n\nIf you are using ``query_key`` (a single key, not multiple keys) you can use ``use_terms_query``. This will make ElastAlert perform a terms aggregation to get the counts for each value of a certain field. Both ``use_terms_query`` and ``use_count_query`` also require ``doc_type`` to be set to the ``_type`` of the documents. They may not be compatible with all rule types.\n\n### Can I perform aggregations?\n\nThe only aggregation supported currently is a terms aggregation, by setting ``use_terms_query``.\n\n### I'm not using @timestamp, what do I do?\n\nYou can use ``timestamp_field`` to change which field ElastAlert will use as the timestamp. You can use ``timestamp_type`` to change it between ISO 8601 and unix timestamps. You must have some kind of timestamp for ElastAlert to work. If your events are not in real time, you can use ``query_delay`` and ``buffer_time`` to adjust when ElastAlert will look for documents.\n\n### I'm using flatline but I don't see any alerts\n\nWhen using ``type: flatline``, ElastAlert must see at least one document before it will alert you that it has stopped seeing them.\n\n### How can I get a \"resolve\" event?\n\nElastAlert does not currently support stateful alerts or resolve events.\n\n### Can I set a warning threshold?\n\nCurrently, the only way to set a warning threshold is by creating a second rule with a lower threshold.\n\n## License\n\nElastAlert is licensed under the Apache License, Version 2.0: http://www.apache.org/licenses/LICENSE-2.0\n\n### Read the documentation at [Read the Docs](http://elastalert.readthedocs.org).\n\n### Questions? Drop by #elastalert on Freenode IRC.\n"
        },
        {
          "name": "changelog.md",
          "type": "blob",
          "size": 11.3759765625,
          "content": "# Change Log\n\n# v0.2.4\n\n### Added\n- Added back customFields support for The Hive\n\n# v0.2.3\n\n### Added\n- Added back TheHive alerter without TheHive4py library\n\n# v0.2.2\n\n### Added\n- Integration with Kibana Discover app\n- Addied ability to specify opsgenie alert detailsÂ \n\n### Fixed\n- Fix some encoding issues with command alerter\n- Better error messages for missing config file\n- Fixed an issue with run_every not applying per-rule\n- Fixed an issue with rules not being removed\n- Fixed an issue with top count keys and nested query keys\n- Various documentation fixes\n- Fixed an issue with not being able to use spike aggregation\n\n### Removed\n- Remove The Hive alerter\n\n# v0.2.1\n\n### Fixed\n- Fixed an AttributeError introduced in 0.2.0\n\n# v0.2.0\n\n- Switched to Python 3\n\n### Added\n- Add rule loader class for customized rule loading\n- Added thread based rules and limit_execution\n- Run_every can now be customized per rule\n\n### Fixed\n- Various small fixes\n\n# v0.1.39\n\n### Added\n- Added spike alerts for metric aggregations\n- Allow SSL connections for Stomp\n- Allow limits on alert text length\n- Add optional min doc count for terms queries\n- Add ability to index into arrays for alert_text_args, etc\n\n### Fixed\n- Fixed bug involving --config flag with create-index\n- Fixed some settings not being inherited from the config properly\n- Some fixes for Hive alerter\n- Close SMTP connections properly\n- Fix timestamps in Pagerduty v2 payload\n- Fixed an bug causing aggregated alerts to mix up\n\n# v0.1.38\n\n### Added\n- Added PagerTree alerter\n- Added Line alerter\n- Added more customizable logging\n- Added new logic in test-rule to detemine the default timeframe\n\n### Fixed\n- Fixed an issue causing buffer_time to sometimes be ignored\n\n# v0.1.37\n\n### Added\n- Added more options for Opsgenie alerter\n- Added more pagerduty options\n- Added ability to add metadata to elastalert logs\n\n### Fixed\n- Fixed some documentation to be more clear\n- Stop requiring doc_type for metric aggregations\n- No longer puts quotes around regex terms in blacklists or whitelists\n\n# v0.1.36\n\n### Added\n- Added a prefix \"metric_\" to the key used for metric aggregations to avoid possible conflicts\n- Added option to skip Alerta certificate validation\n\n### Fixed\n- Fixed a typo in the documentation for spike rule\n\n# v0.1.35\n\n### Fixed\n- Fixed an issue preventing new term rule from working with terms query\n\n# v0.1.34\n\n### Added\n- Added prefix/suffix support for summary table\n- Added support for ignoring SSL validation in Slack\n- More visible exceptions during query parse failures\n\n### Fixed\n- Fixed top_count_keys when using compound query_key\n- Fixed num_hits sometimes being reported too low\n- Fixed an issue with setting ES_USERNAME via env\n- Fixed an issue when using test script with custom timestamps\n- Fixed a unicode error when using Telegram\n- Fixed an issue with jsonschema version conflict\n- Fixed an issue with nested timestamps in cardinality type\n\n# v0.1.33\n\n### Added\n- Added ability to pipe alert text to a command\n- Add --start and --end support for elastalert-test-rule\n- Added ability to turn blacklist/whitelist files into queries for better performance\n- Allow setting of OpsGenie priority\n- Add ability to query the adjacent index if timestamp_field not used for index timestamping\n- Add support for pagerduty v2\n- Add option to turn off .raw/.keyword field postfixing in new term rule\n- Added --use-downloaded feature for elastalert-test-rule\n\n### Fixed\n- Fixed a bug that caused num_hits in matches to sometimes be erroneously small\n- Fixed an issue with HTTP Post alerter that could cause it to hang indefinitely\n- Fixed some issues with string formatting for various alerters\n- Fixed a couple of incorrect parts of the documentation\n\n# v0.1.32\n\n### Added\n- Add support for setting ES url prefix via environment var\n- Add support for using native Slack fields in alerts\n\n### Fixed\n- Fixed a bug that would could scrolling queries to sometimes terminate early\n\n# v0.1.31\n\n### Added\n- Added ability to add start date to new term rule\n\n### Fixed\n- Fixed a bug in create_index which would try to delete a nonexistent index\n- Apply filters to new term rule all terms query\n- Support Elasticsearch 6 for new term rule\n- Fixed is_enabled not working on rule changes\n\n\n# v0.1.30\n\n### Added\n- Alerta alerter\n- Added support for transitioning JIRA issues\n- Option to recreate index in elastalert-create-index\n\n### Fixed\n- Update jira_ custom fields before each alert if they were modified\n- Use json instead of simplejson\n- Allow for relative path for smtp_auth_file\n- Fixed some grammar issues\n- Better code formatting of index mappings\n- Better formatting and size limit for HipChat HTML\n- Fixed gif link in readme for kibana plugin\n- Fixed elastalert-test-rule with Elasticsearch > 4\n- Added documentation for is_enabled option\n\n## v0.1.29\n\n### Added\n- Added a feature forget_keys to prevent realerting when using flatline with query_key\n- Added a new alert_text_type, aggregation_summary_only\n\n### Fixed\n- Fixed incorrect documentation about es_conn_timeout default\n\n## v0.1.28\n\n### Added\n- Added support for Stride formatting of simple HTML tags\n- Added support for custom titles in Opsgenie alerts\n- Added a denominator to percentage match based alerts\n\n### Fixed\n- Fixed a bug with Stomp alerter connections\n- Removed escaping of some characaters in Slack messages\n\n## v0.1.27\n\n# Added\n- Added support for a value other than <MISSING VALUE> in formatted alerts\n\n### Fixed\n- Fixed a failed creation of elastalert indicies when using Elasticsearch 6\n- Truncate Telegram alerts to avoid API errors\n\n## v0.1.26\n\n### Added\n- Added support for Elasticsearch 6\n- Added support for mentions in Hipchat\n\n### Fixed\n- Fixed an issue where a nested field lookup would crash if one of the intermediate fields was null\n\n## v0.1.25\n\n### Fixed\n- Fixed a bug causing new term rule to break unless you passed a start time\n- Add a slight clarification on the localhost:9200 reported in es_debug_trace\n\n## v0.1.24\n\n### Fixed\n- Pinned pytest\n- create-index reads index name from config.yaml\n- top_count_keys now works for context on a flatline rule type\n- Fixed JIRA behavior for issues with statuses that have spaces in the name\n\n## v0.1.22\n\n### Added\n- Added Stride alerter\n- Allow custom string formatters for aggregation percentage\n- Added a field to disable rules from config\n- Added support for subaggregations for the metric rule type\n\n### Fixed\n- Fixed a bug causing create-index to fail if missing config.yaml\n- Fixed a bug when using ES5 with query_key and top_count_keys\n- Allow enhancements to set and clear arbitrary JIRA fields\n- Fixed a bug causing timestamps to be formatted in scientific notation\n- Stop attempting to initialize alerters in debug mode\n- Changed default alert ordering so that JIRA tickets end up in other alerts\n- Fixed a bug when using Stomp alerter with complex query_key\n- Fixed a bug preventing hipchat room ID from being an integer\n- Fixed a bug causing duplicate alerts when using spike with alert_on_new_data\n- Minor fixes to summary table formatting\n- Fixed elastalert-test-rule when using new term rule type\n\n## v0.1.21\n\n### Fixed\n- Fixed an incomplete bug fix for preventing duplicate enhancement runs\n\n## v0.1.20\n\n### Added\n- Added support for client TLS keys\n\n### Fixed\n- Fixed the formatting of summary tables in Slack\n- Fixed ES_USE_SSL env variable\n- Fixed the unique value count printed by new_term rule type\n- Jira alerter no longer uses the non-existent json code formatter\n\n## v0.1.19\n\n### Added\n- Added support for populating JIRA fields via fields in the match\n- Added support for using a TLS certificate file for SMTP connections\n- Allow a custom suffix for non-analyzed Elasticsearch fields, like \".raw\" or \".keyword\"\n- Added match_time to Elastalert alert documents in Elasticsearch\n\n### Fixed\n- Fixed an error in the documentation for rule importing\n- Prevent enhancements from re-running on retried alerts\n- Fixed a bug when using custom timestamp formats and new term rule\n- Lowered jira_bump_after_inactivity default to 0 days\n\n## v0.1.18\n\n### Added\n- Added a new alerter \"post\" based on \"simple\" which makes POSTS JSON to HTTP endpoints\n- Added an option jira_bump_after_inacitivty to prevent ElastAlert commenting on active JIRA tickets\n\n### Removed\n- Removed \"simple\" alerter, replaced by \"post\"\n\n## v0.1.17\n\n### Added\n- Added a --patience flag to allow Elastalert to wait for Elasticsearch to become available\n- Allow custom PagerDuty alert titles via alert_subject\n\n## v0.1.16\n\n### Fixed\n- Fixed a bug where JIRA titles might not use query_key values\n- Fixed a bug where flatline alerts don't respect query_key for realert\n- Fixed a typo \"twilio_accout_sid\"\n\n### Added\n- Added support for env variables in kibana4 dashboard links\n- Added ca_certs option for custom CA support\n\n## v0.1.15\n\n### Fixed\n- Fixed a bug where Elastalert would crash on connection error during startup\n- Fixed some typos in documentation\n- Fixed a bug in metric bucket offset calculation\n- Fixed a TypeError in Service Now alerter\n\n### Added\n- Added support for compound compare key in change rules\n- Added support for absolute paths in rule config imports\n- Added Microsoft Teams alerter\n- Added support for markdown in Slack alerts\n- Added error codes to test script\n- Added support for lists in email_from_field\n\n\n## v0.1.14 - 2017-05-11\n\n### Fixed\n- Twilio alerter uses the from number appropriately\n- Fixed a TypeError in SNS alerter\n- Some changes to requirements.txt and setup.py\n- Fixed a TypeError in new term rule\n\n### Added\n- Set a custom pagerduty incident key\n- Preserve traceback in most exceptions\n\n## v0.1.12 - 2017-04-21\n\n### Fixed\n- Fixed a bug causing filters to be ignored when using Elasticsearch 5\n\n\n## v0.1.11 - 2017-04-19\n\n### Fixed\n- Fixed an issue that would cause filters starting with \"query\" to sometimes throw errors in ES5\n- Fixed a bug with multiple versions of ES on different rules\n- Fixed a possible KeyError when using use_terms_query with ES5\n\n## v0.1.10 - 2017-04-17\n\n### Fixed\n- Fixed an AttributeError occuring with older versions of Elasticsearch library\n- Made example rules more consistent and with unique names\n- Fixed an error caused by a typo when es_username is used\n\n## v0.1.9 - 2017-04-14\n\n### Added\n- Added a changelog\n- Added metric aggregation rule type\n- Added percentage match rule type\n- Added default doc style and improved the instructions\n- Rule names will default to the filename\n- Added import keyword in rules to include sections from other files\n- Added email_from_field option to derive the recipient from a field in the match\n- Added simple HTTP alerter\n- Added Exotel SMS alerter\n- Added a readme link to third party Kibana plugin\n- Added option to use env variables to configure some settings\n- Added duplicate hits count in log line\n\n### Fixed\n- Fixed a bug in change rule where a boolean false would be ignored\n- Clarify documentation on format of alert_text_args and alert_text_kw\n- Fixed a bug preventing new silence stashes from being loaded after a rule has previous alerted\n- Changed the default es_host in elastalert-test-rule to localhost\n- Fixed a bug preventing ES <5.0 formatted queries working in elastalert-test-rule\n- Fixed top_count_keys adding .raw on ES >5.0, uses .keyword instead\n- Fixed a bug causing compound aggregation keys not to work\n- Better error reporting for the Jira alerter\n- AWS request signing now refreshes credentials, uses boto3\n- Support multiple ES versions on different rules\n- Added documentation for percentage match rule type\n\n### Removed\n- Removed a feature that would disable writeback_es on errors, causing various issues\n"
        },
        {
          "name": "config.yaml.example",
          "type": "blob",
          "size": 3.2431640625,
          "content": "# This is the folder that contains the rule yaml files\n# Any .yaml file will be loaded as a rule\nrules_folder: example_rules\n\n# How often ElastAlert will query Elasticsearch\n# The unit can be anything from weeks to seconds\nrun_every:\n  minutes: 1\n\n# ElastAlert will buffer results from the most recent\n# period of time, in case some log sources are not in real time\nbuffer_time:\n  minutes: 15\n\n# The Elasticsearch hostname for metadata writeback\n# Note that every rule can have its own Elasticsearch host\nes_host: elasticsearch.example.com\n\n# The Elasticsearch port\nes_port: 9200\n\n# The AWS region to use. Set this when using AWS-managed elasticsearch\n#aws_region: us-east-1\n\n# The AWS profile to use. Use this if you are using an aws-cli profile.\n# See http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html\n# for details\n#profile: test\n\n# Optional URL prefix for Elasticsearch\n#es_url_prefix: elasticsearch\n\n# Connect with TLS to Elasticsearch\n#use_ssl: True\n\n# Verify TLS certificates\n#verify_certs: True\n\n# GET request with body is the default option for Elasticsearch.\n# If it fails for some reason, you can pass 'GET', 'POST' or 'source'.\n# See http://elasticsearch-py.readthedocs.io/en/master/connection.html?highlight=send_get_body_as#transport\n# for details\n#es_send_get_body_as: GET\n\n# Option basic-auth username and password for Elasticsearch\n#es_username: someusername\n#es_password: somepassword\n\n# Use SSL authentication with client certificates client_cert must be\n# a pem file containing both cert and key for client\n#verify_certs: True\n#ca_certs: /path/to/cacert.pem\n#client_cert: /path/to/client_cert.pem\n#client_key: /path/to/client_key.key\n\n# The index on es_host which is used for metadata storage\n# This can be a unmapped index, but it is recommended that you run\n# elastalert-create-index to set a mapping\nwriteback_index: elastalert_status\nwriteback_alias: elastalert_alerts\n\n# If an alert fails for some reason, ElastAlert will retry\n# sending the alert until this time period has elapsed\nalert_time_limit:\n  days: 2\n\n# Custom logging configuration\n# If you want to setup your own logging configuration to log into\n# files as well or to Logstash and/or modify log levels, use\n# the configuration below and adjust to your needs.\n# Note: if you run ElastAlert with --verbose/--debug, the log level of\n# the \"elastalert\" logger is changed to INFO, if not already INFO/DEBUG.\n#logging:\n#  version: 1\n#  incremental: false\n#  disable_existing_loggers: false\n#  formatters:\n#    logline:\n#      format: '%(asctime)s %(levelname)+8s %(name)+20s %(message)s'\n#\n#    handlers:\n#      console:\n#        class: logging.StreamHandler\n#        formatter: logline\n#        level: DEBUG\n#        stream: ext://sys.stderr\n#\n#      file:\n#        class : logging.FileHandler\n#        formatter: logline\n#        level: DEBUG\n#        filename: elastalert.log\n#\n#    loggers:\n#      elastalert:\n#        level: WARN\n#        handlers: []\n#        propagate: true\n#\n#      elasticsearch:\n#        level: WARN\n#        handlers: []\n#        propagate: true\n#\n#      elasticsearch.trace:\n#        level: WARN\n#        handlers: []\n#        propagate: true\n#\n#      '':  # root logger\n#        level: WARN\n#          handlers:\n#            - console\n#            - file\n#        propagate: false\n"
        },
        {
          "name": "docker-compose.yml",
          "type": "blob",
          "size": 0.2548828125,
          "content": "version: '2'\nservices:\n    tox:\n        build:\n            context: ./\n            dockerfile: Dockerfile-test\n        command: tox\n        container_name: elastalert_tox\n        working_dir: /home/elastalert\n        volumes:\n            - ./:/home/elastalert/\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "elastalert",
          "type": "tree",
          "content": null
        },
        {
          "name": "example_rules",
          "type": "tree",
          "content": null
        },
        {
          "name": "pytest.ini",
          "type": "blob",
          "size": 0.072265625,
          "content": "[pytest]\nmarkers =\n    elasticsearch: mark a test as using elasticsearch.\n"
        },
        {
          "name": "requirements-dev.txt",
          "type": "blob",
          "size": 0.111328125,
          "content": "-r requirements.txt\ncoverage==4.5.4\nflake8\npre-commit\npylint<1.4\npytest<3.3.0\nsetuptools\nsphinx_rtd_theme\ntox<2.0\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.3798828125,
          "content": "apscheduler>=3.3.0\naws-requests-auth>=0.3.0\nblist>=1.3.6\nboto3>=1.4.4\ncffi>=1.11.5\nconfigparser>=3.5.0\ncroniter>=0.3.16\nelasticsearch>=7.0.0\nenvparse>=0.2.0\nexotel>=0.1.3\njira>=1.0.10,<1.0.15\njsonschema>=3.0.2\nmock>=2.0.0\nprison>=0.1.2\npy-zabbix==1.1.3\nPyStaticConfiguration>=0.10.3\npython-dateutil>=2.6.0,<2.7.0\nPyYAML>=5.1\nrequests>=2.0.0\nstomp.py>=4.1.17\ntexttable>=0.8.8\ntwilio==6.0.0\n"
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.09765625,
          "content": "[flake8]\nexclude = .git,__pycache__,.tox,docs,virtualenv_run,modules,venv,env\nmax-line-length = 140\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 1.6201171875,
          "content": "# -*- coding: utf-8 -*-\nimport os\n\nfrom setuptools import find_packages\nfrom setuptools import setup\n\n\nbase_dir = os.path.dirname(__file__)\nsetup(\n    name='elastalert',\n    version='0.2.4',\n    description='Runs custom filters on Elasticsearch and alerts on matches',\n    author='Quentin Long',\n    author_email='qlo@yelp.com',\n    setup_requires='setuptools',\n    license='Copyright 2014 Yelp',\n    classifiers=[\n        'Programming Language :: Python :: 3.6',\n        'License :: OSI Approved :: Apache Software License',\n        'Operating System :: OS Independent',\n    ],\n    entry_points={\n        'console_scripts': ['elastalert-create-index=elastalert.create_index:main',\n                            'elastalert-test-rule=elastalert.test_rule:main',\n                            'elastalert-rule-from-kibana=elastalert.rule_from_kibana:main',\n                            'elastalert=elastalert.elastalert:main']},\n    packages=find_packages(),\n    package_data={'elastalert': ['schema.yaml', 'es_mappings/**/*.json']},\n    install_requires=[\n        'apscheduler>=3.3.0',\n        'aws-requests-auth>=0.3.0',\n        'blist>=1.3.6',\n        'boto3>=1.4.4',\n        'configparser>=3.5.0',\n        'croniter>=0.3.16',\n        'elasticsearch==7.0.0',\n        'envparse>=0.2.0',\n        'exotel>=0.1.3',\n        'jira>=2.0.0',\n        'jsonschema>=3.0.2',\n        'mock>=2.0.0',\n        'prison>=0.1.2',\n        'PyStaticConfiguration>=0.10.3',\n        'python-dateutil>=2.6.0,<2.7.0',\n        'PyYAML>=3.12',\n        'requests>=2.10.0',\n        'stomp.py>=4.1.17',\n        'texttable>=0.8.8',\n        'twilio>=6.0.0,<6.1',\n        'cffi>=1.11.5'\n    ]\n)\n"
        },
        {
          "name": "supervisord.conf.example",
          "type": "blob",
          "size": 0.76171875,
          "content": "[unix_http_server]\nfile=/var/run/elastalert_supervisor.sock\n\n[supervisord]\nlogfile=/var/log/elastalert_supervisord.log\nlogfile_maxbytes=1MB\nlogfile_backups=2\nloglevel=debug\nnodaemon=false\ndirectory=%(here)s\n\n[rpcinterface:supervisor]\nsupervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface\n\n[supervisorctl]\nserverurl=unix:///var/run/elastalert_supervisor.sock\n\n[program:elastalert]\n# running globally\ncommand =\n        python elastalert.py\n               --verbose\n# (alternative) using virtualenv\n# command=/path/to/venv/bin/elastalert --config /path/to/config.yaml --verbose \nprocess_name=elastalert\nautorestart=true\nstartsecs=15\nstopsignal=INT\nstopasgroup=true\nkillasgroup=true\nstderr_logfile=/var/log/elastalert_stderr.log\nstderr_logfile_maxbytes=5MB\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "tox.ini",
          "type": "blob",
          "size": 0.5947265625,
          "content": "[tox]\nproject = elastalert\nenvlist = py36,docs\n\n[testenv]\ndeps = -rrequirements-dev.txt\ncommands =\n    coverage run --source=elastalert/,tests/ -m pytest --strict {posargs}\n    coverage report -m\n    flake8 .\n\n[testenv:lint]\ndeps = {[testenv]deps}\n    pylint\ncommands =\n    pylint --rcfile=.pylintrc elastalert\n    pylint --rcfile=.pylintrc tests\n\n[testenv:devenv]\nenvdir = virtualenv_run\ncommands =\n\n[pytest]\nnorecursedirs = .* virtualenv_run docs build venv env\n\n[testenv:docs]\ndeps = {[testenv]deps}\n    sphinx==1.6.6\nchangedir = docs\ncommands = sphinx-build -b html -d build/doctrees -W source build/html\n"
        }
      ]
    }
  ]
}