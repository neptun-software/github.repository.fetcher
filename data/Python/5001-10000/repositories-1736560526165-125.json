{
  "metadata": {
    "timestamp": 1736560526165,
    "page": 125,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjEzMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "arogozhnikov/einops",
      "stars": 8632,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".devcontainer",
          "type": "tree",
          "content": null
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.43359375,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n\n# pycharm\n.idea\n\n# design-document\ndesign-einops.txt\n\n# logo and video generation\nlogo\n\n# any local explorations\n*.personal*\n\n# oneflow's output trash\nlog\n\n# this file is auto-generated\ndocs_src/index.md\n\n# vs code \n*.code-workspace\n\n# macos system files\n.DS_Store"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.2978515625,
          "content": "---\nrepos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    # Ruff version, synced with CI\n    rev: v0.6.5\n    hooks:\n      # Run the linter.\n      - id: ruff\n        types_or: [ python, pyi, jupyter ]\n      # Run the formatter.\n      - id: ruff-format\n        types_or: [ python, pyi, jupyter ]"
        },
        {
          "name": "CITATION.cff",
          "type": "blob",
          "size": 0.689453125,
          "content": "cff-version: 1.2.0\ntitle: einops\nmessage: >-\n  If you use this software, please cite it using the\n  metadata from this file.\ntype: software\nauthors:\n  - given-names: Alex\n    family-names: Rogozhnikov\nrepository-code: 'https://github.com/arogozhnikov/einops'\nabstract: >-\n  Flexible and powerful tensor operations for readable and reliable code (for pytorch, jax, TF and others)\nlicense: MIT\npreferred-citation:\n  type: article\n  authors:\n  - given-names: Alex\n    family-names: Rogozhnikov\n  journal: \"International Conference on Learning Representations\"\n  title: \"Einops: Clear and Reliable Tensor Manipulations with Einstein-like Notation\"\n  year: 2022\n  url: https://openreview.net/forum?id=oapKSVM2bc"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0478515625,
          "content": "MIT License\n\nCopyright (c) 2018 Alex Rogozhnikov\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 12.5419921875,
          "content": "\n<!--\n<a href='http://arogozhnikov.github.io/images/einops/einops_video.mp4' >\n<div align=\"center\">\n  <img src=\"http://arogozhnikov.github.io/images/einops/einops_video.gif\" alt=\"einops package examples\" />\n  <br>\n  <small><a href='http://arogozhnikov.github.io/images/einops/einops_video.mp4'>This video in high quality (mp4)</a></small>\n  <br><br>\n</div>\n</a>\n-->\n\n<!-- this link magically rendered as video on github readme, unfortunately not in docs -->\n\nhttps://user-images.githubusercontent.com/6318811/177030658-66f0eb5d-e136-44d8-99c9-86ae298ead5b.mp4\n\n\n\n\n# einops \n[![Run tests](https://github.com/arogozhnikov/einops/actions/workflows/run_tests.yml/badge.svg)](https://github.com/arogozhnikov/einops/actions/workflows/run_tests.yml)\n[![PyPI version](https://badge.fury.io/py/einops.svg)](https://badge.fury.io/py/einops)\n[![Documentation](https://img.shields.io/badge/documentation-link-blue.svg)](https://einops.rocks/)\n![Supported python versions](https://raw.githubusercontent.com/arogozhnikov/einops/main/docs/resources/python_badge.svg)\n\n\nFlexible and powerful tensor operations for readable and reliable code. <br />\nSupports numpy, pytorch, tensorflow, jax, and [others](#supported-frameworks).\n\n## Recent updates:\n\n- 0.8.0: tinygrad backend added, small fixes\n- 0.7.0: no-hassle `torch.compile`, support of [array api standard](https://data-apis.org/array-api/latest/API_specification/index.html) and more\n- 10'000ðŸŽ‰: github reports that more than 10k project use einops\n- einops 0.6.1: paddle backend added\n- einops 0.6 introduces [packing and unpacking](https://github.com/arogozhnikov/einops/blob/main/docs/4-pack-and-unpack.ipynb)\n- einops 0.5: einsum is now a part of einops\n- [Einops paper](https://openreview.net/pdf?id=oapKSVM2bcj) is accepted for oral presentation at ICLR 2022 (yes, it worth reading).\n  Talk recordings are [available](https://iclr.cc/virtual/2022/oral/6603)\n\n\n<details markdown=\"1\">\n<summary>Previous updates</summary>\n- flax and oneflow backend added\n- torch.jit.script is supported for pytorch layers\n- powerful EinMix added to einops. [Einmix tutorial notebook](https://github.com/arogozhnikov/einops/blob/main/docs/3-einmix-layer.ipynb) \n</details>\n\n<!--<div align=\"center\">\n  <img src=\"http://arogozhnikov.github.io/images/einops/einops_logo_350x350.png\" \n  alt=\"einops package logo\" width=\"250\" height=\"250\" />\n  <br><br>\n</div> -->\n\n\n## Tweets \n\n> In case you need convincing arguments for setting aside time to learn about einsum and einops...\n[Tim RocktÃ¤schel](https://twitter.com/_rockt/status/1230818967205425152)\n\n> Writing better code with PyTorch and einops ðŸ‘Œ\n[Andrej Karpathy](https://twitter.com/karpathy/status/1290826075916779520)\n\n> Slowly but surely, einops is seeping in to every nook and cranny of my code. If you find yourself shuffling around bazillion dimensional tensors, this might change your life\n[Nasim Rahaman](https://twitter.com/nasim_rahaman/status/1216022614755463169)\n\n[More testimonials](https://einops.rocks/pages/testimonials/)\n\n\n## Contents\n\n- [Installation](#Installation)\n- [Documentation](https://einops.rocks/)\n- [Tutorial](#Tutorials)\n- [API micro-reference](#API)\n- [Why use einops](#Why-use-einops-notation)\n- [Supported frameworks](#Supported-frameworks)\n- [Citing](#Citing)\n- [Repository](https://github.com/arogozhnikov/einops) and [discussions](https://github.com/arogozhnikov/einops/discussions)\n\n## Installation  <a name=\"Installation\"></a>\n\nPlain and simple:\n```bash\npip install einops\n```\n\n## Tutorials <a name=\"Tutorials\"></a>\n\nTutorials are the most convenient way to see `einops` in action\n\n- part 1: [einops fundamentals](https://github.com/arogozhnikov/einops/blob/main/docs/1-einops-basics.ipynb)\n- part 2: [einops for deep learning](https://github.com/arogozhnikov/einops/blob/main/docs/2-einops-for-deep-learning.ipynb)\n- part 3: [packing and unpacking](https://github.com/arogozhnikov/einops/blob/main/docs/4-pack-and-unpack.ipynb)\n- part 4: [improve pytorch code with einops](http://einops.rocks/pytorch-examples.html)\n\nKapil Sachdeva recorded a small [intro to einops](https://www.youtube.com/watch?v=xGy75Pjsqzo).\n\n## API <a name=\"API\"></a>\n\n`einops` has a minimalistic yet powerful API.\n\nThree core operations provided ([einops tutorial](https://github.com/arogozhnikov/einops/blob/main/docs/)\nshows those cover stacking, reshape, transposition, squeeze/unsqueeze, repeat, tile, concatenate, view and numerous reductions)\n\n```python\nfrom einops import rearrange, reduce, repeat\n# rearrange elements according to the pattern\noutput_tensor = rearrange(input_tensor, 't b c -> b c t')\n# combine rearrangement and reduction\noutput_tensor = reduce(input_tensor, 'b c (h h2) (w w2) -> b h w c', 'mean', h2=2, w2=2)\n# copy along a new axis\noutput_tensor = repeat(input_tensor, 'h w -> h w c', c=3)\n```\n\nLater additions to the family are `pack` and `unpack` functions (better than stack/split/concatenate):\n\n```python\nfrom einops import pack, unpack\n# pack and unpack allow reversibly 'packing' multiple tensors into one.\n# Packed tensors may be of different dimensionality:\npacked,  ps = pack([class_token_bc, image_tokens_bhwc, text_tokens_btc], 'b * c')\nclass_emb_bc, image_emb_bhwc, text_emb_btc = unpack(transformer(packed), ps, 'b * c')\n```\n\nFinally, einops provides einsum with a support of multi-lettered names:\n\n```python\nfrom einops import einsum, pack, unpack\n# einsum is like ... einsum, generic and flexible dot-product\n# but 1) axes can be multi-lettered  2) pattern goes last 3) works with multiple frameworks\nC = einsum(A, B, 'b t1 head c, b t2 head c -> b head t1 t2')\n```\n\n### EinMix\n\n`EinMix` is a generic linear layer, perfect for MLP Mixers and similar architectures.\n\n### Layers\n\nEinops provides layers (`einops` keeps a separate version for each framework) that reflect corresponding functions\n\n```python\nfrom einops.layers.torch      import Rearrange, Reduce\nfrom einops.layers.tensorflow import Rearrange, Reduce\nfrom einops.layers.flax       import Rearrange, Reduce\nfrom einops.layers.paddle     import Rearrange, Reduce\n```\n\n<details markdown=\"1\">\n<summary>Example of using layers within a pytorch model</summary>\nExample given for pytorch, but code in other frameworks is almost identical\n\n```python \nfrom torch.nn import Sequential, Conv2d, MaxPool2d, Linear, ReLU\nfrom einops.layers.torch import Rearrange\n\nmodel = Sequential(\n    ...,\n    Conv2d(6, 16, kernel_size=5),\n    MaxPool2d(kernel_size=2),\n    # flattening without need to write forward\n    Rearrange('b c h w -> b (c h w)'),\n    Linear(16*5*5, 120),\n    ReLU(),\n    Linear(120, 10),\n)\n```\n\nNo more flatten needed!\n\nAdditionally, torch layers as those are script-able and compile-able.\nOperations [are torch.compile-able](https://github.com/arogozhnikov/einops/wiki/Using-torch.compile-with-einops),\n but not script-able due to limitations of torch.jit.script.\n</details>\n\n\n\n\n## Naming <a name=\"Naming\"></a>\n\n`einops` stands for Einstein-Inspired Notation for operations \n(though \"Einstein operations\" is more attractive and easier to remember).\n\nNotation was loosely inspired by Einstein summation (in particular by `numpy.einsum` operation).\n\n## Why use `einops` notation?! <a name=\"Why-use-einops-notation\"></a>\n\n\n### Semantic information (being verbose in expectations)\n\n```python\ny = x.view(x.shape[0], -1)\ny = rearrange(x, 'b c h w -> b (c h w)')\n```\nWhile these two lines are doing the same job in *some* context,\nthe second one provides information about the input and output.\nIn other words, `einops` focuses on interface: *what is the input and output*, not *how* the output is computed.\n\nThe next operation looks similar:\n\n```python\ny = rearrange(x, 'time c h w -> time (c h w)')\n```\nbut it gives the reader a hint:\nthis is not an independent batch of images we are processing,\nbut rather a sequence (video).\n\nSemantic information makes the code easier to read and maintain.\n\n### Convenient checks\n\nReconsider the same example:\n\n```python\ny = x.view(x.shape[0], -1) # x: (batch, 256, 19, 19)\ny = rearrange(x, 'b c h w -> b (c h w)')\n```\nThe second line checks that the input has four dimensions,\nbut you can also specify particular dimensions.\nThat's opposed to just writing comments about shapes since comments don't prevent mistakes,\nnot tested, and without code review tend to be outdated\n```python\ny = x.view(x.shape[0], -1) # x: (batch, 256, 19, 19)\ny = rearrange(x, 'b c h w -> b (c h w)', c=256, h=19, w=19)\n```\n\n### Result is strictly determined\n\nBelow we have at least two ways to define the depth-to-space operation\n```python\n# depth-to-space\nrearrange(x, 'b c (h h2) (w w2) -> b (c h2 w2) h w', h2=2, w2=2)\nrearrange(x, 'b c (h h2) (w w2) -> b (h2 w2 c) h w', h2=2, w2=2)\n```\nThere are at least four more ways to do it. Which one is used by the framework?\n\nThese details are ignored, since *usually* it makes no difference,\nbut it can make a big difference (e.g. if you use grouped convolutions in the next stage),\nand you'd like to specify this in your code.\n\n\n### Uniformity\n\n```python\nreduce(x, 'b c (x dx) -> b c x', 'max', dx=2)\nreduce(x, 'b c (x dx) (y dy) -> b c x y', 'max', dx=2, dy=3)\nreduce(x, 'b c (x dx) (y dy) (z dz) -> b c x y z', 'max', dx=2, dy=3, dz=4)\n```\nThese examples demonstrated that we don't use separate operations for 1d/2d/3d pooling,\nthose are all defined in a uniform way.\n\nSpace-to-depth and depth-to space are defined in many frameworks but how about width-to-height? Here you go:\n\n```python\nrearrange(x, 'b c h (w w2) -> b c (h w2) w', w2=2)\n```\n\n\n### Framework independent behavior\n\nEven simple functions are defined differently by different frameworks\n\n```python\ny = x.flatten() # or flatten(x)\n```\n\nSuppose `x`'s shape was `(3, 4, 5)`, then `y` has shape ...\n\n- numpy, pytorch, cupy, chainer, jax: `(60,)`\n- keras, tensorflow.layers, gluon: `(3, 20)`\n\n`einops` works the same way in all frameworks.\n\n\n### Independence of framework terminology\n\nExample: `tile` vs `repeat` causes lots of confusion. To copy image along width:\n```python\nnp.tile(image, (1, 2))    # in numpy\nimage.repeat(1, 2)        # pytorch's repeat ~ numpy's tile\n```\n\nWith einops you don't need to decipher which axis was repeated:\n```python\nrepeat(image, 'h w -> h (tile w)', tile=2)  # in numpy\nrepeat(image, 'h w -> h (tile w)', tile=2)  # in pytorch\nrepeat(image, 'h w -> h (tile w)', tile=2)  # in tf\nrepeat(image, 'h w -> h (tile w)', tile=2)  # in jax\nrepeat(image, 'h w -> h (tile w)', tile=2)  # in cupy\n... (etc.)\n```\n\n[Testimonials](https://einops.rocks/pages/testimonials/) provide users' perspective on the same question.\n\n\n## Supported frameworks <a name=\"Supported-frameworks\"></a>\n\nEinops works with ...\n\n- [numpy](http://www.numpy.org/)\n- [pytorch](https://pytorch.org/)\n- [tensorflow](https://www.tensorflow.org/)\n- [jax](https://github.com/google/jax)\n- [cupy](https://github.com/cupy/cupy)\n- [flax](https://github.com/google/flax) (community)\n- [paddle](https://github.com/PaddlePaddle/Paddle) (community)\n- [oneflow](https://github.com/Oneflow-Inc/oneflow) (community)\n- [tinygrad](https://github.com/tinygrad/tinygrad) (community)\n\nAdditionally, einops can be used with any framework that supports\n[Python array API standard](https://data-apis.org/array-api/latest/API_specification/index.html),\nwhich includes\n\n- numpy >= 2.0\n- [MLX](https://github.com/ml-explore/mlx)\n- [pydata/sparse](https://github.com/pydata/sparse) >= 0.15\n- [quantco/ndonnx](https://github.com/Quantco/ndonnx)\n- recent releases of jax and cupy.\n- dask is supported via [array-api-compat](https://github.com/data-apis/array-api-compat)\n\n\n## Development\n\nDevcontainer is provided, this environment can be used locally, or on your server,\nor within github codespaces. \nTo start with devcontainers in vs code, clone repo, and click 'Reopen in Devcontainer'. \n\nStarting from the next version, einops will distribute tests as a part of package.\nTo run tests:\n\n```bash\n# pip install einops\npython -m einops.tests.run_tests numpy pytorch jax --pip-install\n```\n\n`numpy pytorch jax` is an example, any subset of testable frameworks can be provided.\nEvery framework is tested against numpy, so it is a requirement for tests.\n\nSpecifying `--pip-install` will install requirements in current virtualenv,\nand should be omitted if dependencies are installed locally.\n\nTo build/test docs:\n\n```bash\nhatch run docs:serve  # Serving on http://localhost:8000/\n```\n\n\n## Citing einops <a name=\"Citing\"></a>\n\nPlease use the following bibtex record\n\n```text\n@inproceedings{\n    rogozhnikov2022einops,\n    title={Einops: Clear and Reliable Tensor Manipulations with Einstein-like Notation},\n    author={Alex Rogozhnikov},\n    booktitle={International Conference on Learning Representations},\n    year={2022},\n    url={https://openreview.net/forum?id=oapKSVM2bcj}\n}\n```\n\n\n## Supported python versions\n\n`einops` works with python 3.8 or later.\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs_src",
          "type": "tree",
          "content": null
        },
        {
          "name": "einops",
          "type": "tree",
          "content": null
        },
        {
          "name": "mkdocs.yml",
          "type": "blob",
          "size": 1.3837890625,
          "content": "site_name: Einops\nrepo_name: arogozhnikov/einops\nrepo_url: https://github.com/arogozhnikov/einops\nsite_url: https://einops.rocks\ndocs_dir: docs_src\ntheme:\n  name: material\n  favicon: images/favicon.png\n  icon:\n    logo: fontawesome/solid/infinity\n    repo: octicons/mark-github-16\nnav:\n  - Introduction: index.md\n  - Tutorials:\n      - Einops Basics: 1-einops-basics.ipynb\n      - Einops for Deep Learning: 2-einops-for-deep-learning.ipynb\n      - Einops.pack and unpack: 4-pack-and-unpack.ipynb\n      - Einmix for great MLPs: 3-einmix-layer.ipynb\n      - Pytorch: pytorch-examples.html\n  - API Reference:\n      - asnumpy: api/asnumpy.md\n      - parse_shape: api/parse_shape.md\n      - rearrange: api/rearrange.md\n      - reduce: api/reduce.md\n      - repeat: api/repeat.md\n      - einsum: api/einsum.md\n      - pack and unpack: api/pack_unpack.md\n  - Testimonials: pages/testimonials.md\n  - Community/Ecosystem: pages/projects.md\nextra:\n  search:\n    language: en\nmarkdown_extensions:\n  - admonition\n  - codehilite\n  - pymdownx.arithmatex\n  - markdown.extensions.md_in_html\nplugins:\n  - search\n  - mkdocstrings:\n      handlers:\n        python:\n          options:\n            docstring_options:\n              warn_unknown_params: false\n  - mkdocs-jupyter\nextra_javascript:\n  - https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML\nextra_css:\n  - css/mkdocs.css\n  - css/codehilite.css"
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 3.14453125,
          "content": "[build-system]\nrequires = [\"hatchling>=1.10.0\"]\nbuild-backend = \"hatchling.build\"\n\n[project]\nname = \"einops\"\ndescription = \"A new flavour of deep learning operations\"\nreadme = \"README.md\"\nrequires-python = \">=3.8\" # in sync with target_version\n\nkeywords = [\n    'deep learning',\n    'neural networks',\n    'tensor manipulation',\n    'machine learning',\n    'scientific computations',\n    'einops',\n]\nlicense = { text = 'MIT' }\nclassifiers = [\n    'Intended Audience :: Science/Research',\n    'Programming Language :: Python :: 3',\n    'License :: OSI Approved :: MIT License',\n]\ndependencies = [\n    # no run-time or installation-time dependencies\n]\ndynamic = [\"version\"]\nauthors = [{ name = 'Alex Rogozhnikov' }]\n\n[project.urls]\nHomepage = 'https://github.com/arogozhnikov/einops'\n\n[tool.setuptools]\npackages = ['einops', 'einops.layers']\n\n[tool.hatch.version]\npath = \"einops/__init__.py\"\n\n[tool.hatch.build.targets.sdist]\nexclude = [\n    \"/.devcontainer\",\n    \"/.github\",\n    \"/.idea\",\n    \"/.pytest_cache\",\n    \"/build\",\n    \"/dist\",\n    \"/docs\",\n    \"/docs_src\",\n    \"/scripts\",\n    \"/log\",\n]\n\n[tool.hatch.build.targets.wheel]\n# should use packages from main section\n\n\n[tool.hatch.envs.docs]\ndependencies = [\n    \"mkdocs~=1.6.1\",\n    \"mkdocs-material~=9.5.34\",\n    \"mkdocstrings[python]~=0.26.1\",\n    \"mkdocs-jupyter~=0.25.0\",\n    # pygments is required by codehilite (highlighting in mkdocs)\n    \"pygments~=2.18.0\",\n]\n[tool.hatch.envs.docs.scripts]\n# For examples to build one has to run:\n# hatch run docs:build\nconvert = \"python scripts/convert_readme.py\"\nbuild = \"convert && mkdocs build --clean --strict {args}\"\nserve = \"convert && mkdocs serve --dev-addr localhost:8000 {args}\"\ndeploy = \"convert && mkdocs build --clean --strict && mkdocs gh-deploy\"\n# when mkdocs deployed from github actions, it requires --force. Reason unclear.\ndeploy_force = \"convert && mkdocs build --clean --strict && mkdocs gh-deploy --force\"\n\n\n[tool.hatch.envs.pypi.scripts]\n# hatch run pypi:deploy_test\ndeploy_test = \"hatch build --clean && hatch publish -r test\"\ndeploy = \"hatch build --clean && hatch publish\"\n\n\n\n[tool.pytest.ini_options]\n# suppressing irrelevant warnings from google's tensorflow and pb2 on m1 mac\n# should be removed in 2023\nfilterwarnings = [\n    \"ignore:Call to deprecated create function FieldDescriptor\",\n    \"ignore:Call to deprecated create function Descriptor\",\n    \"ignore:Call to deprecated create function EnumDescriptor\",\n    \"ignore:Call to deprecated create function EnumValueDescriptor\",\n    \"ignore:Call to deprecated create function FileDescriptor\",\n    \"ignore:Call to deprecated create function OneofDescriptor\",\n]\n\n\n[tool.ruff]\nline-length = 120\ntarget-version = 'py38'\n\ncache-dir = \"/tmp/ruff_cache\" # move cache out of workdir\n\n[tool.ruff.format]\ndocstring-code-format = false\n# do not reformat notebooks\nexclude = [\"*.ipynb\"]\n\n[tool.ruff.lint]\nselect = [\"E4\", \"E7\", \"E9\", \"F\", \"W\"]\n# this notebook is not really a notebook,\n# but a set of examples to be compared\nexclude = [\"*Pytorch.ipynb\"]\n\n\n[tool.ruff.lint.per-file-ignores]\n\"*.ipynb\" = [\n    \"E402\", # Module level import not at top of cell\n    \"F811\", # redefinition of unused\n    \"E702\", # Multiple statements on one line (semicolon)\n]\n"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}