{
  "metadata": {
    "timestamp": 1736560509588,
    "page": 104,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjExMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "pymc-devs/pymc",
      "stars": 8820,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.0166015625,
          "content": ".git\n.mypy_cache\n"
        },
        {
          "name": ".git-blame-ignore-revs",
          "type": "blob",
          "size": 0.1064453125,
          "content": "# Updated Apache v2 license header for year 2023 on entire codebase\n3ea470ac964f4bd5c7207ce08a583a2e6aa7ae8a\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.029296875,
          "content": "pymc/_version.py export-subst\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.564453125,
          "content": "*.pyc\n*.sw[op]\nexamples/*.png\nnb_examples/\nnb_tutorials/\nbuild/*\ndist/*\n*.egg-info/\n.ipynb_checkpoints\ntmtags\ntags\n.DS_Store\n.cache\n# IntelliJ IDE\n.idea\n*.iml\n\n# Sphinx\n_build\ndocs/_build\ndocs/build\ndocs/jupyter_execute\ndocs/.jupyter_cache\ndocs/**/generated/*\n\n# Merge tool\n*.orig\n\n# Docker development\n# notebooks/\n\n# air speed velocity (asv)\nbenchmarks/env/\nbenchmarks/html/\nbenchmarks/results/\n.pytest_cache/\n\n# Visual Studio / VSCode\n.vs/\n.vscode/\n.mypy_cache\n\npytestdebug.log\n.dir-locals.el\n.pycheckers\n\n# Codespaces\npythonenv*\nenv/\nvenv/\n.venv/\npixi.toml\npixi.lock\n.pixi/\n"
        },
        {
          "name": ".gitpod.yml",
          "type": "blob",
          "size": 2.0751953125,
          "content": "image: ghcr.io/pymc-devs/pymc-devcontainer:latest\ntasks:\n  - name: initialize\n    init: |\n      # General devcontainer initialization, e.g. pre-commit\n      _dev-init.sh\n\n      # Create an empty object for .vscode/settings.json if the file doesn't exist\n      mkdir -p .vscode\n      [ -f .vscode/settings.json ] || echo \"{}\" > .vscode/settings.json\n\n      # Add vscode settings\n      jq '\n            .[\"python.defaultInterpreterPath\"] = \"/opt/conda/bin/python\"\n      ' .vscode/settings.json | sponge .vscode/settings.json\n      jq '\n            .[\"terminal.integrated.defaultProfile.linux\"] = \"bash\"\n      ' .vscode/settings.json | sponge .vscode/settings.json\n      jq '\n            .[\"git.autofetch\"] = true\n      ' .vscode/settings.json | sponge .vscode/settings.json\n\n      # Install dependencies\n      sudo chown \"$(id -u):$(id -g)\" /opt/conda/conda-meta/history\n      (micromamba install --yes --name base --file conda-envs/environment-dev.yml; pip install -e .) &> /tmp/install-init.log &\n\n    command: |\n      # Reinitialize devcontainer for good measure\n      _dev-init.sh\n\n      # Install the pre-commit hooks in the background if not already installed\n      pre-commit install --install-hooks &> /tmp/pre-commit-init-output.log &\n\nvscode:\n  extensions:\n    - eamodio.gitlens\n    - ms-python.python\n    - ms-pyright.pyright\n    - ms-toolsai.jupyter\n    - donjayamanne.githistory\n\ngithub:\n  prebuilds:\n    # enable for master branch\n    master: true\n    # enable for other branches (defaults to false)\n    branches: true\n    # enable for pull requests coming from this repo (defaults to true)\n    pullRequests: true\n    # enable for pull requests coming from forks (defaults to false)\n    pullRequestsFromForks: false\n    # add a check to pull requests (defaults to true)\n    addCheck: true\n    # add a \"Review in Gitpod\" button as a comment to pull requests (defaults to false)\n    addComment: false\n    # add a \"Review in Gitpod\" button to the pull request's description (defaults to false)\n    addBadge: false\n    # add a label once the prebuild is ready to pull requests (defaults to false)\n    addLabel: false\n"
        },
        {
          "name": ".mailmap",
          "type": "blob",
          "size": 1.55078125,
          "content": "# Prevent git from showing duplicate names with commands like \"git shortlog\"\n# # See the manpage of git-shortlog for details.\n# # The syntax is:\n# # Name that should be used <email that should be used> Bad name <bad email>\n# #\n# # You can skip Bad name if it is the same as the one that should be used, and is unique.\n# #\n# # This file is up-to-date if the command git log --format=\"%aN <%aE>\" | sort -u\n# # gives no duplicates.\n\nChris Fonnesbeck <chris.fonnesbeck@vanderbilt.edu> Christopher Fonnesbeck <chris.fonnesbeck@vanderbilt.edu>\nChris Fonnesbeck <chris.fonnesbeck@vanderbilt.edu> <@fonnesbeck (Twitter)>\nChris Fonnesbeck <chris.fonnesbeck@vanderbilt.edu> <chris@Chipper.local>\nChris Fonnesbeck <chris.fonnesbeck@vanderbilt.edu> <fonnesbeck@Smoltz.local>\nChris Fonnesbeck <chris.fonnesbeck@vanderbilt.edu> <fonnesbeck@gmail.com>\nChris Fonnesbeck <chris.fonnesbeck@vanderbilt.edu> <fonnesbeck@me.com>\nChris Fonnesbeck <chris.fonnesbeck@vanderbilt.edu> <fonnesbeck@smoltz-wireless.otago.ac.nz>\nChris Fonnesbeck <chris.fonnesbeck@vanderbilt.edu> <fonnesbeck@smoltz.otago.ac.nz>\nChris Fonnesbeck <chris.fonnesbeck@vanderbilt.edu> Christopher Fonnesbeck <chris.fonnesbeck@vanderbilt.edu>\nChris Fonnesbeck <chris.fonnesbeck@vanderbilt.edu> Christopher Fonnesbeck <fonnescj@Honus.local>\nChris Fonnesbeck <chris.fonnesbeck@vanderbilt.edu> Christopher Fonnesbeck <fonnescj@honus.dhcp.mc.vanderbilt.edu>\nChris Fonnesbeck <chris.fonnesbeck@vanderbilt.edu> fonnesbeck <fonnesbeck@15d7aa0b-6f1a-0410-991a-d59f85d14984>\nThomas Wiecki <thomas.wiecki@gmail.com> twiecki <thomas.wiecki@gmail.com>\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 3.2958984375,
          "content": "ci:\n  autofix_prs: false\n\nexclude: ^(docs/logos|pymc/tests/data)/\nrepos:\n- repo: https://github.com/pre-commit/pre-commit-hooks\n  rev: v5.0.0\n  hooks:\n    -   id: check-merge-conflict\n    -   id: check-toml\n    -   id: check-yaml\n    -   id: debug-statements\n    -   id: end-of-file-fixer\n    -   id: no-commit-to-branch\n    -   id: requirements-txt-fixer\n        exclude: ^requirements-dev\\.txt$\n    -   id: trailing-whitespace\n- repo: https://github.com/pre-commit/pygrep-hooks\n  rev: v1.10.0\n  hooks:\n    - id: python-check-blanket-noqa\n    - id: python-check-blanket-type-ignore\n    - id: python-check-mock-methods\n    # - id: python-no-eval  # gets confused with all the `.eval()`\n    - id: python-no-log-warn\n    - id: python-use-type-annotations\n    - id: rst-backticks\n    - id: rst-directive-colons\n    - id: rst-inline-touching-normal\n    - id: text-unicode-replacement-char\n- repo: https://github.com/citation-file-format/cffconvert\n  rev: 054bda51dbe278b3e86f27c890e3f3ac877d616c\n  hooks:\n    - id: validate-cff\n- repo: https://github.com/sphinx-contrib/sphinx-lint\n  rev: v1.0.0\n  hooks:\n    - id: sphinx-lint\n      args: [\".\"]\n#- repo: https://github.com/lucianopaz/head_of_apache\n#  rev: \"0.0.3\"\n#  hooks:\n#    - id: head_of_apache\n#      args:\n#        - --author=The PyMC Developers\n#        - --exclude=docs/\n#        - --exclude=scripts/\n#        - --exclude=binder/\n#        - --exclude=versioneer.py\n- repo: https://github.com/astral-sh/ruff-pre-commit\n  rev: v0.8.4\n  hooks:\n    - id: ruff\n      args: [--fix, --show-fixes]\n    - id: ruff-format\n- repo: local\n  hooks:\n    - id: check-no-tests-are-ignored\n      additional_dependencies: [pandas,pyyaml]\n      entry: python scripts/check_all_tests_are_covered.py\n      files: ^.github/workflows/tests.yml$\n      language: python\n      name: Check no tests are ignored\n      pass_filenames: false\n    - id: pip-from-conda\n      additional_dependencies: [pyyaml]\n      entry: python scripts/generate_pip_deps_from_conda.py\n      files: ^conda-envs/environment-dev.yml$\n      language: python\n      name: Generate pip dependency from conda\n    - id: no-internal-links\n      name: Check no links that should be cross-references are in the docs\n      description: >-\n        'A quick check for the links in the intersphinx '\n        'mapping inside `docs/source/`'\n        'See docs/source/conf.py for more information.'\n      files: ^docs/source/\n      # Files that should be ignored:\n      # - index.md\n      # - 404.md\n      # - contributing/release_checklist.md\n      # The other files are under development and should be\n      # removed from the list once they are revised.\n      exclude: >\n          (?x)(index.md|\n               404.md|\n               contributing/release_checklist.md|\n               contributing/versioning_schemes_explanation.md|\n               learn/examples.md)\n      entry: >\n          (?x)(arviz-devs.github.io|\n               python.arviz.org|\n               pytensor.readthedocs.io|\n               pymc-experimental.readthedocs.io|\n               docs.pymc.io|\n               www.pymc.io|\n               numpy.org/doc|\n               pymc-examples.readthedocs.io|\n               myst-parser.readthedocs.io|\n               myst-nb.readthedocs.io|\n               docs.python.org|\n               xarray.pydata.org)\n      language: pygrep\n      types_or: [markdown, rst, jupyter]\n"
        },
        {
          "name": ".readthedocs.yml",
          "type": "blob",
          "size": 0.2294921875,
          "content": "version: 2\n\nsphinx:\n    configuration: docs/source/conf.py\n\npython:\n   install:\n   - method: pip\n     path: .\n\nconda:\n  environment: \"conda-envs/environment-docs.yml\"\n\nbuild:\n  os: \"ubuntu-22.04\"\n  tools:\n    python: \"mambaforge-4.10\"\n"
        },
        {
          "name": "ARCHITECTURE.md",
          "type": "blob",
          "size": 4.1298828125,
          "content": "# Architecture\nThis document describes the high-level architecture of PyMC.\n\n# Bird's Eye View\n[comment]: <> (https://drive.google.com/file/d/1lfEzokkNUJr_JIeSDQfha5a57pokz0qI)\n![Architecture](docs/Architecture.png)\nLets you define probabilistic graphs or models that can be easily used to compute log probabilities for posterior\ninference or to draw random samples for prior and posterior prediction.\n\nPyMC includes a few inference techniques, in particular:\n* Markov chain Monte Carlo\n* Variational Inference\n* Sequential Monte Carlo\n\nIt also contains numerous others pieces of functionality such as GraphviZ model visualization tools\nas well as various mathematical helper functions.\n\nThe most central pieces functionality of PyMC are shown visually below, as well as their\nrelation to other major packages. Not all modules are shown, either because\nthey are smaller or self explanatory in scope, or they're pending\ndeprecation\n\n## Functionality not in PyMC\nIt is easier to start with functionality that is not present in PyMC but\nrather deferred to outside libraries. If seeking to understand any\nof the topics below refer to that specific library\n\n### PyTensor\n* Gradient computation\n* Random number generation\n* Low level tensor operation definition\n* Low level operation graphs\n\n### ArviZ\n* Plotting e.g. Trace plots, rank plots, posterior plots\n* MCMC sampling diagnostics e.g. Rhat, Effective Sample Size.\n* Model comparison, particularly efficient leave-one-out cross-validation approximation\n* Inference Data structure\n\n\n# Modules\nThe codebase of PyMC is split among single Python file modules at the root\nlevel, as well as directories with Python code for logical groups of functionality.\nAdmittedly the split between single `.py` module or directory is not defined by a strict\ncriteria but tends to occur when single `.py` files would be \"too big\".\nWe will with the modules needed implement \"simple MCMC\" model shown below\nbefore detailing the remaining modules, such as Variational Inference, Ordinary Differential Equations,\nor Sequential Monte Carlo.\n\n```python\nwith pm.Model() as model:\n  theta = pm.Beta(\"theta\", alpha=1, beta=2)\n  p = pm.Beta(\"n\", p=theta, n=2, observed=[1,2])\n  inf_data = pm.sample()\n\n\n```\n\n## {mod}`pymc.model`\nContains primitives related model definition and methods used for evaluation of the model.\nIn no particular order they are\n\n* `ContextMeta`: The context manager that enables the `with pm.Model() as model` syntax\n* {class}`~pymc.Factor`: Defines the methods for the various logprobs for models\n* `ValueGrad` which handles the value and gradient and is the main connection point to PyTensor\n* `Deterministic` and `Potential`: Definitions for two pieces of functionality useful in some model definitions\n\n## distributions/\nContains multiple submodules that define distributions,  as well as logic that aids in distributions usage.\nImportant modules to note are\n\n* `distribution.py`: This contains parent class for all PyMC distributions.\n  Notably the `distribution.distribution` class contains the `observed` argument which in PyMC differentiates\n  a random variable distribution from a likelihood distribution.\n\n* `logprob.py`: This contains the log probability logic for the distributions themselves.\n  The log probability calculation is deferred to PyTensor\n\n* `dist_math.py`: Various convenience operators for distributions.\n  This includes mathematical operators such as `logpower` or `all_true`methods.\n  It also contains a suite of lognormal methods and transformation methods\n\n## /sampling.py\nInterface to posterior, prior predictive, and posterior sampling as well as various methods to identify and initialize\nstepper methods. Also contains logic to check for \"all continuous\" variables and initialize NUTS\n\n## step_methods/\nContains various step methods for various sampling algorithms, such as MCMC, and SMC. `step_methods.hmc` includes\nthe Hamiltonian Monte Carlo sampling methods as well as helper functions such as the integrators used for those methods\n\n## tests/\nAll tests for testing functionality of codebase. All modules prefixed with `test_` are tests themselves, whereas all\nother modules contain various supporting code such as fixtures, configurations, etc\n"
        },
        {
          "name": "CITATION.cff",
          "type": "blob",
          "size": 1.40625,
          "content": "cff-version: 1.2.0\nmessage: If you use this software, please cite it using the metadata from this file.\ntitle: PyMC\nauthors:\n  - name: PyMC-Devs\nrepository-code: \"https://github.com/pymc-devs/pymc\"\nurl: \"https://www.pymc.io\"\nabstract: Bayesian Modeling and Probabilistic Programming in Python\nlicense: Apache-2.0\n\npreferred-citation:\n  type: article\n  title: \"PyMC: a modern, and comprehensive probabilistic programming framework in Python\"\n  journal: PeerJ Comput. Sci.\n  database: peerj.com\n  issn: 2376-5992\n  languages:\n    - en\n  pages: e1516\n  volume: 9\n  url: \"https://peerj.com/articles/cs-1516\"\n  date-published: 2023-09-01\n  doi: 10.7717/peerj-cs.1516\n  authors:\n    - family-names: Abril-Pla\n      given-names: Oriol\n    - family-names: Andreani\n      given-names: Virgile\n    - family-names: Carroll\n      given-names: Colin\n    - family-names: Dong\n      given-names: Larry\n    - family-names: Fonnesbeck\n      given-names: Christopher J.\n    - family-names: Kochurov\n      given-names: Maxim\n    - family-names: Kumar\n      given-names: Ravin\n    - family-names: Lao\n      given-names: Junpeng\n    - family-names: Luhmann\n      given-names: Christian C.\n    - family-names: Martin\n      given-names: Osvaldo A.\n    - family-names: Osthege\n      given-names: Michael\n    - family-names: Vieira\n      given-names: Ricardo\n    - family-names: Wiecki\n      given-names: Thomas\n    - family-names: Zinkov\n      given-names: Robert\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.412109375,
          "content": "# PyMC Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to making participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, sex characteristics, gender identity and expression,\nlevel of experience, education, socio-economic status, nationality, personal\nappearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\n  advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\n  address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies both within project spaces and in public spaces\nwhen an individual is representing the project or its community. Examples of\nrepresenting a project or community include using an official project e-mail\naddress, posting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event. Representation of a project may be\nfurther defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting PyMC developer Christopher Fonnesbeck via email\n(fonnesbeck@gmail.com) or phone (615-955-0380). Alternatively, you\nmay also contact NumFOCUS Executive Director Leah Silen (512-222-5449), as PyMC\nis a member of NumFOCUS and subscribes to their code of conduct as a\nprecondition for continued membership. All complaints will be reviewed and\ninvestigated and will result in a response that is deemed necessary and\nappropriate to the circumstances. The project team is obligated to maintain\nconfidentiality with regard to the reporter of an incident. Further details of\nspecific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\n[homepage]: https://www.contributor-covenant.org\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 1.087890625,
          "content": "# Guidelines for Contributing\n\nThank you for being interested in contributing to PyMC. PyMC is an open source, collective effort, and everyone is welcome to contribute. There are many ways in which you can help make it better. Please check the latest information for contributing to the PyMC project on [this guidelines](https://docs.pymc.io/en/latest/contributing/index.html).\n\nQuick links\n-----------\n\n* [Pull request (PR) step-by-step ](https://docs.pymc.io/en/latest/contributing/pr_tutorial.html)\n* [Pull request (PR) checklist](https://docs.pymc.io/en/latest/contributing/pr_checklist.html)\n* [Python style guide with pre-commit](https://docs.pymc.io/en/latest/contributing/python_style.html)\n* [Running the test suite](https://docs.pymc.io/en/latest/contributing/running_the_test_suite.html)\n* [Running PyMC in Docker](https://docs.pymc.io/en/latest/contributing/docker_container.html)\n* [Submitting a bug report or feature request](https://github.com/pymc-devs/pymc/issues)\n\nFor a complete list visit [the contributing section of the documentation](https://docs.pymc.io/en/latest/contributing/index.html).\n"
        },
        {
          "name": "GOVERNANCE.md",
          "type": "blob",
          "size": 39.412109375,
          "content": "# Main Governance Document\n\n## The Project\n\nThe PyMC Project (The Project) is an open source software project\naffiliated with the 501c3 NumFOCUS Foundation. The goal of The Project is to\ndevelop open source software and deploy open and public websites and services\nfor reproducible, exploratory and interactive computing.\nThe main focus of The Project is in scientific and statistical computing.\nThe Software developed\nby The Project is released under OSI approved open source licenses,\ndeveloped openly and hosted in public GitHub repositories under the\n[pymc-devs GitHub organization](https://github.com/pymc-devs). Examples of\nProject Software include the PyMC library and its documentation, etc.\nThe Services run by The Project consist of public websites and web-services\nthat are hosted at [http://www.pymc.io](https://www.pymc.io) and subdomains.\n\nThe Project is developed by a team of distributed developers, called\nContributors. Contributors are individuals who have contributed code,\ndocumentation, designs or other work to one or more Project repositories,\nor who have done significant work to empower the Community,\nparticipating on [Discourse](https://discourse.pymc.io),\norganizing [PyMCon](https://pymcon.com) or helped on other platforms and events.\n**Anyone can be a Contributor.**\nContributors can be affiliated with any legal entity or none.\nThe foundation of Project participation is openness and transparency.\n\nThere have been over 250 Contributors to the Project, their contributions are listed in the\nlogs of the PyMC GitHub repositories as well as those of associated projects and venues.\n\nThe Project Community consists of all Contributors and Users of the Project.\nContributors work on behalf of and are responsible to the larger Project\nCommunity and we strive to keep the barrier between Contributors and Users as\nlow as possible.\n\nThe Project is formally affiliated with the 501c3\n[NumFOCUS Foundation](http://numfocus.org), which serves as its fiscal\nsponsor, may hold project trademarks and other intellectual property, helps\nmanage project donations and acts as a parent legal entity. NumFOCUS is the\nonly legal entity that has a formal relationship with the project (see\nInstitutional Partners section below).\n\n## Governance\n\nThis section outlines the governance and leadership model of The Project.\n\nThe foundations of Project governance are:\n\n- Openness & Transparency\n- Active Contribution\n- Institutional Neutrality\n\nTraditionally, Project leadership was provided by a BDFL (Chris Fonnesbeck) and\nsubset of Contributors, called Core Developers, whose active and consistent\ncontributions have been recognized by their receiving “commit rights” to the\nProject GitHub repositories. In general all Project decisions were made through\nconsensus among the Core Developers with input from the Community. The BDFL\ncould, but rarely chose to, override the Core Developers and make a final\ndecision on a matter.\n\nWhile this approach served us well, as the Project grew and faced more\nlegal and financial decisions and interacted with other institutions, we saw a\nneed for a more formal governance and organization model.\nWe view this governance model as the formalization of what we were already doing,\nrather than a change in direction.\n\n## Community and Team Architecture\nThe PyMC community is organized in an onion-like fashion.\nThe tiers relevant to the project governance are listed below sorted by\nincreasing responsibility. Due to the onion-like structure, members of a group are\nalso members of all the groups listed above:\n\n* Contributors\n* Recurring Contributors\n* Core Contributors\n* Steering Council\n* BDFL\n\nCore Contributors comprise what we understand as the PyMC Team.\nThe Team will generally act as a single unit, except for some specific\nquestions where dedicated teams will prevail.\nThe PyMC project currently has Developer, Documentation and Community teams.\nTeam members can be part of one, some or none of these dedicated teams.\nThe diagram below should help illustrate this idea.\n\n<img src=\"docs/community_diagram.png\" alt=\"community diagram\" width=\"600\" height=\"400\">\n\nAnyone working with The Project has the responsibility to personally uphold\nthe Code of Conduct. Core Contributors have the additional responsibility\nof _enforcing_ the Code of Conduct to maintain a safe community.\n\n## Recurring Contributors\nRecurring Contributors are those individuals who contribute recurrently to the\nproject and can provide valuable insight on the project.\nThey are therefore actively consulted and can participate in the same communication\nchannels as Core Contributors. However, unlike Core Contributors,\nRecurrent Contributors don't have voting, managing or writing rights.\n\nIn practice, this translates in participating from private team discussions\n(i.e. in Slack or live meetings) but not being able to vote Steering Council\nmembers nor having commit rights on GitHub.\n\nThe Recurrent Contributor position will often be an intermediate step for people\nin becoming Core Contributors once their contributions are frequent enough\nand during a sustained period of time.\nBut it is also an important role by itself for people who want to be part of\nthe project on a more advisory-like role, as they for example might not have\nthe time availability or don't want the responsibilities that come\nwith being a Core Contributor.\n\n### Recurring Contributor membership\nRecurring Contributors can nominate any Contributor to participate in the\nProject private communication channels (i.e. Slack public channel)\nand become a Recurring Contributor.\nFor the nomination to go forward, it has to be ratified by the Steering Council.\nFor a nomination to be rejected, clear reasoning behind the decision must be\nshared with the rest of the team. People whose nomination has been rejected can\nbe nominated at any time again in the future, three months after the previous\nnomination at the earliest. The nomination process is explained below\nin more detail in a section of its own.\n\nInterns and contractors are added to the team as Recurrent Contributors.\nWe consider the selection/hiring process to replace the nomination process.\nThis applies to Google summer of code interns or Google season of\ndocs contractors, but also to interns and contractors hired by\ntier 1 Institutional Partners who work mostly on PyMC.\n\n## Core Contributors\nCore Contributors are those individuals entrusted with the development and\nwell being of the Project due to their frequency of quality contributions over\na sustained period of time.\n\nThey are the main governing and decision body\nof the Project and are therefore given voting and managing rights to the Project\nservices (i.e. commit rights on GitHub or moderation rights on Discourse).\n\nTeam memberships for Core Contributors refer to their Core Contributor\nrole, as experienced and entrusted members of the team they are considered\nRecurrent Contributors for the rest of the teams and given permissions accordingly\n\nThe exact permissions of all Core Contributors may therefore not be the same\nand depend on their team memberships. Even if they have commit rights,\nCore Contributors should still have their pull requests reviewed by at least\none other Core Contributor before merging.\nIn rare circumstances, a Core Contributor may bypass this review\nif in their best judgement it is appropriate to do so,\nbut such expedited PR merges must be justifiable and\nultimately subject to review post hoc, if necessary.\nIf overstepping, Core Contributors can also be subject to a vote\nof no confidence (see below) and see their permissions revoked.\n\n### Core Contributor membership\nTo become a Core Contributor, one must already be a Recurring Contributor.\nCore Contributors can nominate any Recurring Contributor to become a\nCore Contributor. For the nomination to go forward, it has to be\nratified by the Steering Council.\nFor a nomination to be rejected, clear reasoning behind the decision must be\nshared with the rest of the team. People whose nomination has been rejected can\nbe nominated at any time again in the future, three months after the previous\nnomination at the earliest. The nomination process is explained below\nin more detail in a section of its own.\n\n### Current Core Contributors\nThe list of current core contributors is available at https://github.com/orgs/pymc-devs/teams/core-contributors\n\n## Steering Council\n\nThe Project will have a Steering Council that consists of Project Contributors\nwho have produced contributions that are substantial in quality and quantity,\nand sustained over at least one year. The overall role of the Council is to\nensure, through working with the BDFL and taking input from the Community, the\nlong-term well-being of the project, both technically and as a community.\n\nThe Steering Council will have between 4 and 7 members with at least one member\nper dedicated team.\nNo more than 2 Council Members can report to one person or company\n(including Institutional Partners) through employment or\ncontracting work (including the reportee, i.e. the reportee + 1 is the max).\n\n\nDuring the everyday project activities, council members participate in all\ndiscussions, code review and other project activities as peers with all other\nContributors and the Community. In these everyday activities, Council Members\ndo not have any special power or privilege through their membership on the\nCouncil. However, it is expected that because of the quality and quantity of\ntheir contributions and their expert knowledge of the Project Software and\nServices that Council Members will provide useful guidance, both technical and\nin terms of project direction, to potentially less experienced contributors.\n\nThe Steering Council and its Members play a special role in certain situations.\nIn particular, the Council may:\n\n- Make decisions about the overall scope, vision and direction of the\n  project.\n- Make decisions about strategic collaborations with other organizations or\n  individuals.\n- Make decisions about specific technical issues, features, bugs and pull\n  requests.\n- Make decisions about the Services that are run by The Project and manage\n  those Services for the benefit of the Project and Community.\n- Make decisions when regular community discussion doesn’t produce consensus\n  on an issue in a reasonable time frame.\n\n### Current Steering Council\n\nThe current Steering Council membership comprises:\n\n- Ricardo Vieira (dev, community - PyMC Labs)\n- Colin Carroll (dev)\n- Osvaldo Martin (dev, docs)\n- Jesse Grabowski (community, dev - PyMC Labs)\n\nNote that as explained in the [community architecture section](#community-and-team-architecture)\nand as indicated again in the description of the Steering Council above,\nCouncil members are first and foremost Core Contributors, and have no special\npower or privilege in everyday activities.\nTo emphasize that, Steering Council members are listed both in the current core\ncontributors section and in this section even if redundant.\n\n### Council membership\n\nTo become eligible for being a Steering Council Member an individual must be a\nCore Contributor who has produced contributions that are substantial in\nquality and quantity, and sustained over at least one year.\n\nSimilarly to when nominating new team members, when considering potential\nCouncil Members one should look at candidates with a\ncomprehensive view of their contributions. This will include but is not limited\nto code, code review, infrastructure work, forum and chat participation,\ncommunity help/building, education and outreach, design work, etc. We are\ndeliberately not setting arbitrary quantitative metrics (like “100 commits in\nthis repo”) to avoid encouraging behavior that plays to the metrics rather than\nthe project’s overall well-being. We want to encourage a diverse array of\nbackgrounds, viewpoints and talents in our team, which is why we explicitly do\nnot define code as the sole metric on which council membership will be\nevaluated. See the section on election process for more details.\n\nCouncil membership is assigned for a two year period, with no limit on how many\nperiods can be served.\n\nCouncil members can renounce at any time and are\nencouraged to do so if they foresee they won't be able to attend their\nresponsibilities for an extended interval of time.\n\nIf a Council member becomes inactive in the project for a period of six months,\nthey will be considered for removal from the Council. Before removal, inactive\nMember will be approached by the BDFL to see if they plan on returning to\nactive participation. If not they will be removed immediately, as they\nare effectively renouncing to their position.\nIf they plan on returning to active participation soon, they will be\ngiven a grace period of six months. If they don’t return to active participation\nwithin that time period they will be removed without\nfurther grace period. All former Council members can be considered for\nmembership again at any time in the future.\nRetired Council members will be listed on the project website, acknowledging\nthe period during which they were active in the Council.\n\nThe Council reserves the right to eject current Members, other than the BDFL,\nif they are deemed to be actively harmful to the project’s well-being, and\nattempts at communication and conflict resolution have failed. See\nthe section on votes of no-confidence for details on the process.\n\n### Private communications of the Council\n\nUnless specifically required, all Council discussions and activities will be\npublic and done in collaboration and discussion with the Project Team\nand also the Community when possible.\nThe Council will have a private mailing list that will be used\nsparingly and only when a specific matter requires privacy. When private\ncommunications and decisions are needed, the Council will do its best to\nsummarize those to the Team after eliding personal/private/sensitive\ninformation that should not be posted to the public internet.\n\n### Subcommittees\n\nThe Council can create subcommittees that provide leadership and guidance for\nspecific aspects of the project. Like the Council as a whole, subcommittees\nshould conduct their business in an open and public manner unless privacy is\nspecifically called for.\n\nEven if the BDFL does not sit on a specific subcommittee, they still retain\noverride authority on the subcommittee's decisions. However, it is expected that\nthey will appoint a delegate to oversee the subcommittee's decisions, and\nexplicit intervention from the BDFL will only be sought if the committee\ndisagrees with the delegate's decision and no resolution is possible within the\nsubcommittee. This is a different situation from a BDFL delegate for a specific\ndecision, or a recusal situation, in which the BDFL gives up their authority\nto someone else in full.\n\n## BDFL\n\nThe Project will have a BDFL (Benevolent Dictator for Life), who is currently\nChris Fonnesbeck. As Dictator, the BDFL has the authority to make all final\ndecisions for The Project. As Benevolent, the BDFL, in practice chooses to\ndefer that authority to the consensus of the community discussion channels and\nthe Steering Council. It is expected, and in the past has been the\ncase, that the BDFL will only rarely assert their final authority. Because\nrarely used, we refer to BDFL’s final authority as a “special” or “overriding”\nvote. When it does occur, the BDFL override typically happens in situations\nwhere there is a deadlock in the Steering Council or if the Steering Council\nasks the BDFL to make a decision on a specific matter. To ensure the\nbenevolence of the BDFL, The Project encourages others to fork the project if\nthey disagree with the overall direction the BDFL is taking. The BDFL is chair\nof the Steering Council (see below) and may delegate their authority on a\nparticular decision or set of decisions to any other Council member at their\ndiscretion.\n\nThe BDFL can appoint their successor, but it is expected that the Steering\nCouncil would be consulted on this decision. If the BDFL is unable to appoint a\nsuccessor, the Steering Council will make a suggestion or suggestions to the\nMain NumFOCUS Board. While the Steering Council and Main NumFOCUS Board will\nwork together closely on the BDFL selection process, the Main NUMFOCUS Board\nwill make the final decision.\n\n\n## Conflict of interest\n\nIt is expected that the BDFL, Council Members and Contributors will be\nemployed at a wide range of companies, universities and non-profit organizations.\nBecause of this, it is possible that Members will have conflict of interests.\nSuch conflict of interests include, but are not limited to:\n\n- Financial interests, such as investments, employment or contracting work,\n  outside of The Project that may influence their work on The Project.\n- Access to proprietary information of their employer that could potentially\n  leak into their work with The Project.\n\nAll members of the Council, BDFL included, shall disclose to the rest of the\nCouncil any conflict of interest they may have. Members with a conflict of\ninterest in a particular issue may participate in Council discussions on that\nissue, but must recuse themselves from voting on the issue. If the BDFL has\nrecused themselves for a particular decision, they will appoint a substitute\nBDFL for that decision.\n\n## Voting processes\n### Nomination process\n> Used when adding members to the team as recurrent or core contributors.\n\nA nomination process is triggered automatically whenever a team member\nrequests so on one of the team's communication channels\n(public Slack channels at the day of writing, preferably `#general`).\nNomination should be explicit regarding which roles and teams are\nsuggested, but the council makes the final decision on\ndedicated team membership.\nAgain, note that team members don't need to be part of any\ndedicated team to be recurrent nor core contributors.\n\nAfter this happens, the Steering Council will reach out to the candidate\nto see if they accept the nomination. If the nomination is accepted\nit will be considered by the Steering Council.\nAt their earliest convenience and no later than two weeks, the Steering\nCouncil will vote on the nominee using the process below on\nSteering Council decisions.\n\nVoting will be private to the Steering Council only with results published\non the nomination request.\nIn the case of a rejection, results must include the reasons behind\nthe decision (i.e. the time since starting to contribute is deemed\ntoo short for now).\n\n### Steering Council decisions\nBy and large we expect the decisions in PyMC to be made _ad hoc_\nand require little formal coordination and with the community at large.\nHowever, for controversial proposals and new team members the council can\nintervene to make the final decision in a group vote.\n\n#### Call for a vote\nCore Contributors can call for a vote to resolve a target issue\nthey feel has been stale for too long and for which\ninformal consensus appears unlikely.\nFor a vote to be called, the target issue or discussion post (i.e. on Discourse)\nmust be at least 1 month old.\n\nTo do so, they have to open a proposal issue ticket labeled \"Council Vote\".\nThe proposal issue should contain a link to the target issue and\na proposal on how to resolve it.\nProposals should include a statement making clear what it means to\n\"agree\" or to \"disagree\".\n\nBefore voting starts, at least 3 days will be left for Core Contributors\nto raise doubts about the proposal's phrasing, no extra discussion will\ntake place in the proposal issue.\nProposal issues should be locked from creation to prevent attracting\ndiscussion from people not familiar with the decision process.\n\nA vote is also called automatically whenever someone is nominated to\nbe added to the team.\n\nThe Steering Council can also call a vote on their own in order\nto eject a Core contributor.\n\nUpon ejecting a core contributor the council must publish an issue ticket,\nor public document detailing the\n* Violations\n* Evidence if available\n* Remediation plan (if necessary)\n* Signatures majority of council members to validate correctness and accuracy\n\n#### Voting\n\n* Each Council Member will vote either \"Yes\", \"No\", or \"Abstain\".\n* It is recommended that all Council Members expose their reasons when voting.\n  \"No\" votes, however, must list the reasons for disagreement.\n  Any \"No\" vote with no reason listed will be considered a \"Abstain\" vote.\n* An absence of vote is considered as \"Abstain\".\n* Voting will remain open for at least 3 days.\n* For the proposal to pass, at least 60% of the council must vote \"Yes\", and no more than 20% can vote \"No\".\n\nFor decisions about the project the Council will perform it directly\non the proposal issue. For decisions about people,\nsuch as electing or ejecting Team Members, the Council will vote privately.\nHowever the decision will be posted publicly in an issue ticket.\n\n### Vote of no confidence\nIn exceptional circumstances, Council Members as well as Core Contributors\nmay remove a sitting council member via a vote of no confidence.\nCore contributors can also call for a vote to remove the entire council\n-- in which case, Council Members do not vote.\nA no-confidence vote is triggered when a Core Contributor calls for one\npublicly on an appropriate project communication channel,\nand two other core team members second the proposal.\nThe initial call for a no-confidence vote must specify which type is intended.\n\nThe vote lasts for two weeks, and the people taking part in it vary:\n* If this is a single-member vote\n  all Core contributors (including council members) vote,\n  and the vote is deemed successful if at least two thirds of voters\n  express a lack of confidence.\n\n  Such votes can target removing from the Council\n  (while continuing to be a Core Contributor) or a Core Contributor removal,\n  which should be clear from the initial vote call. Council members\n  can be called for a Core Contributor removal.\n* If this is a whole-council vote, then it was necessarily called by\n  Core contributors (since Council members can’t remove the whole Council)\n  and only Core contributors vote.\n  The vote is deemed successful if at least two thirds of voters\n  express a lack of confidence.\n\nAfter voting:\n* If a single-member vote on a council member succeeds, then that member is\n  removed from the council and the resulting vacancy can be handled in the usual way.\n* If a single-member vote on a core contributor succeeds, their permissions are\n  revoked and would have to wait six months to be eligible for core contributor\n  nomination again.\n* If a whole-council vote succeeds, the council is dissolved\n  and a new council election is triggered immediately.\n  In such case, members of the dissolved council continue to be Core Contributors.\n\n### Election process\n> Used when choosing the steering council and it's subcommittees\n\nThe log of past election processes is kept on [Discourse](https://discourse.pymc.io/tag/elections)\n\n#### Nominations\n* Nominations are taken over a single Discourse topic (with at least the `elections` tag)\n  over the course of 2 weeks.\n* Only Core Contributors may nominate candidates for Council membership\n* Self Nominations are allowed\n* There are no limits to the number of people that can be nominated by a single Core Contributor\n* Once someone has been nominated, extra nominations are ignored. All candidates are treated equally\n  in the election independently of potential differences (i.e. number of likes) in their respective nominations.\n* At the conclusion of the 2 weeks, the list of nominations is posted on the ticket and this ticket is closed.\n\n#### Voting\n\n* Voting occurs over a period of at least 1 week, at the conclusion of the nominations.\n  Voting is blind and mediated by either an application or a third party like NumFOCUS.\n  Each voter can vote zero or more times, once per each candidate.\n  As this is not about ranking but about capabilities,\n  voters vote on a yes/abstain/no basis per candidate --\n  “Should this person be on the Steering Council?\n  Would I trust this person to lead PyMC?”.\n  The absence of vote is considered abstain.\n* Candidates are evaluated independently,\n  each candidate having 60% or more of yes votes and less or\n  equal than 20% of no votes is chosen.\n  If the number of chosen candidates matches the number or range set for the\n  council/subcommittee being chosen and all extra constrains are met,\n  all candidates are confirmed and the election process stops here.\n* In the event that not enough/too many candidates were confirmed or\n  the membership constraints were not met,\n  candidates are ranked by interpreting yes=+1, abstain=0 and no=-1.\n  * If too many candidates were confirmed,\n    the max number of candidates (7) with higher rank are elected.\n  * If not enough candidates were chosen,\n    the min number of candidates (4) with higher rank are elected.\n  * If membership constraints were not met, candidates are selected\n    progressively by rank if they meet the membership requirements.\n    If for example out of 7 candidates for the NumFOCUS subcommittee\n    only three are on the Steering Council and they were ranked 5th-7th,\n    in order to meet the membership constraints, the person ranked 4th\n    would not be elected, as their election would prevent membership\n    requirements from being met.\n* In the event of a tie there will be a runoff election for the tied candidates.\n  To avoid further ties and discriminate more among the tied candidates,\n  this vote will be held by Majority Judgment:\n  for each candidate, voters judge their suitability for office as either\n  \"Excellent\", \"Very Good\", \"Good\", \"Acceptable\", \"Poor\", or \"Reject\".\n  Multiple candidates may be given the same grade by a voter.\n  The candidate with the highest median grade is the winner.\n* If more than one candidate has the same highest median-grade,\n  the Majority Judgment winner is discovered by removing (one-by-one)\n  any grades equal in value to the shared median grade from\n  each tied candidate's total.\n  This is repeated until only one of the previously tied candidates\n  is currently found to have the highest median-grade.\n* If ties are still present after this second round, the winner will be chosen at random. First we make a alphanumerically sorted list of the names in the tie. Then we will draw one prior predictive sample from a `pm.Categorical` distribution over the elements in the list to determine the winner.\n* At the conclusion of voting, all the results will be posted. And at least 24 hours will be left to challenge the election result in case there were suspicions of irregularities or the process had not been correctly carried out.\n\n## Leaving the project\nAny contributor can also voluntarily leave the project by notifying the community through a public means or by notifying the entire council. When doing so, they can add themselves to the alumni section below if desired.\n\nPeople who leave the project voluntarily can rejoin at any time.\n\n## Team Organization\nAs stated previously, The Team will generally act as a single unit,\nexcept for some specific questions where dedicated teams will prevail.\nThese dedicated teams have no difference in how they are governed.\nDecisions should be reached by consensus within the team with the Steering\nCouncil and the BDFL acting if necessary.\n\nThe dedicated teams are work units with two main objectives: better\ndistributing the work related to The Project, and to better showcase all the different tasks\ninvolved in The Project to attract more diverse Contributors.\n\nThe PyMC project currently has Developer, Documentation and Community teams.\nTeam members can be part of one, some or none of these dedicated teams.\n\nTeam members are expected to participate and join these dedicated teams\norganically. That is, the Steering Council will take part actively\nin team assignments if they are part of a role change with the respective\nnomination.\n\n### Developer Team\nThe focus of the developer team is the probabilistic programming library\nand flagship of The Project, [PyMC](https://github.com/pymc-devs/pymc).\n\nFor current members of the developer team, refer to the recurrent and\ncore contributor membership sections.\n\n### Documentation Team\nThe focus of the documentation team is ensuring the PyMC library\nis well documented, building and maintaining the infrastructure needed\nfor that aim, and making sure there are resources to learn\nBayesian statistics with PyMC.\nIt is not the goal nor responsibility of the Documentation team to\nwrite all the documentation for the PyMC library.\n\nFor current members of the documentation team, refer to the recurrent and\ncore contributor membership sections.\n\n### Community team\nThe focus of the Community team is activities intended to nurture, energize, and grow the community of PyMC users and contributors.  These activities include moderation of and participation in the discussions on the PyMC Discourse, planning and organization of events such as PyMCon and sprints, and coordination of presence on various social networks.  These activities are not intended to be the sole responsibility of the Community team.  Instead, the Community team provides leadership in these efforts, but recruits other contributors and community members as needed, thus encourging participation and fostering a healthy, self-sustaining community.\n\nFor current members of the community team, refer to the recurrent and\ncore contributor membership sections.\n\n### \"No-team\" tasks\nAll tasks related to the project that are not specifically listed in the\ndescription of a dedicated team are the responsibility of the PyMC team\nas a whole. At the time of writing, this includes but is not limited to:\nenforcing this governance and the [PyMC code of conduct](https://github.com/pymc-devs/pymc/blob/main/CODE_OF_CONDUCT.md), developing project-related grants, soliciting of project sponsorships, decisions regarding the allocation of project-related funds, planning of the project roadmap, or triaging of GitHub issues.\n\n### Team structure in practice\nThis section describes how members of the PyMC team are given\npermissions to the relevant services based on their roles\nand dedicated team affiliations.\n\n#### GitHub\nTwo of the teams are currently structured about GitHub-centric tasks, so the\npermissions on GitHub repositories is mapped to team membership and role\nwithin the team. The team defines to which repositories the permissions\nare given, the role defines the type of permissions given:\n\nRole:\n- Recurring Contributors are given triage permissions\n- Core Contributors are given write permissions\n\nTeam:\n* Development team members are given permissions to the [pymc](https://github.com/pymc-devs/pymc)\n  and [pymc-experimental](https://github.com/pymc-devs/pymc-experimental) repository.\n* Documentation team members are given permissions to [pymc-examples](https://github.com/pymc-devs/pymc-examples)\n  and [resources](https://github.com/pymc-devs/resources) repositories.\n* Community team members are given permissions to [PyMCon](https://github.com/pymc-devs/pymcon), [PyMC Data Umbrella](https://github.com/pymc-devs/pymc-data-umbrella), and other event- and community-related repositories.\n\nIn addition, Council members are given administrative rights to all repositories within\nthe [pymc-devs](https://github.com/pymc-devs) organization.\n\n##### Communication Focused Repositories\nSome repositories on Github may be used primarily for internal knowledge store and communication, rather than content that is curated, published, or released _by the project_ for external users.\n\nThe permissions of such repositories will be set in order to allow the same participation and access levels we use on private project communication channels like Slack.\nTherefore, similarly to Slack, these repositories will be private and write permissions will be given to all recurrent contributors (that is, anyone with access to Slack).\n\n#### Discourse\nSimilar to the above section, Discourse permissions are also mapped to the community team\nand the two contributor roles.\n\nRole:\n- Recurring Contributors are given no special permissions\n- Core Contributors are added to the [PyMC_core](https://discourse.pymc.io/g/PyMC_core)\n  group independently of the teams they are part of.\n  Core Contributors in the community team are also added to the\n  [Community Team](https://discourse.pymc.io/g/Community_Team) group.\n\n#### Accounts and services ownership and administration\nThe PyMC Project also has accounts and hosts services on several platforms.\nSome examples of such platforms include (but are not limited to)\nGitHub, Discourse, PyPI, Discord, Twitter, ReadTheDocs, or Medium.\nAny service under the PyMC project should follow these rules,\neven if not explicitly listed above as an example.\n\nIf possible, all Council Members and relevant Core Contributors should have\nadministrative rights on those platforms. [SPEC 6](https://scientific-python.org/specs/spec-0006/)\nfrom the scientific python project has some recommendations on shared\ninfrastructure and credentials.\n\nIf none of the above were possible, administrative rights should be distributed among\nCouncil Members and relevant Core Contributors and establish a rotation\nof the administrative rights every 1-2 years.\n\n#### Permission examples\nThis section lists some imaginary contributors with their teams and roles to\nprovide examples on how to assign permissions:\n\n<details><summary>See permission examples</summary>\n\n- Arnau, recurrent contributor, community team\n  * No permissions on Discourse\n  * Added to all private communication channels\n  * Triage permissions on the pymcon, pymc-data-umbrella, and other \"event\" repositories\n\n- Berta, recurrent contributor, dev and doc teams\n  * No permissions on Discourse\n  * Added to all private communication channels\n  * Triage permissions on pymc, pymc-experimental, pymc-examples and resources repositories\n    of the pymc-devs organization\n\n- Carme, core contributor, doc team\n  * Added to the community PyMC_core group on Discourse\n  * Added to all private communication channels\n  * Write permissions on pymc-examples and resources repositories, triage permissions\n    to pymc and pymc-experimental repositories\n  * Administrative access to ReadTheDocs accounts\n\n- Dolors, core contributor, dev and community teams\n  * Added to the Community Team and PyMC_core Discourse groups.\n    Part of the rotation of administrative permissions on Discourse\n    (Discourse allows only 3 admins on our current plan).\n  * Added to all private communication channels\n  * Write permissions on pymc, pymc-experimental, pymcon, pymc-data-umbrella, and other \"event\" repositories, triage permissions\n    on pymc-examples and resources repositories\n\n- Eudald, core contributor, no dedicated team membership\n  * Added to the PyMC_core Discourse group\n  * Added to all private communication channels\n  * Triage permissions on all repositories\n  * Access to PyMC Gmail, Drive and grant application platforms (i.e. CZI Slack) as they are the main grant writing coordinator\n\n</details>\n\n## Institutional Partners and Funding\n\nThe PyMC Core Contributors (together with the BDFL and Steering Council)\nare the primary leadership for the project. No\noutside institution, individual or legal entity has the ability to own,\ncontrol, usurp or influence the project other than by participating in the\nProject as Contributors and Council Members. However, because institutions are\nthe primary funding mechanism for the project, it is important to formally\nacknowledge institutional participation in the project. These are Institutional\nPartners.\n\nAn Institutional Contributor is any individual Core Contributor who\ncontributes to the project as part of their official duties at an Institutional\nPartner. Likewise, an Institutional Council Member is any Project Steering\nCouncil Member who contributes to the project as part of their official duties\nat an Institutional Partner.\n\nWith these definitions, an Institutional Partner is any recognized legal entity\nin the United States or elsewhere that employs at least one Institutional\nContributor or Institutional Council Member. Institutional Partners can be\nfor-profit or non-profit entities.\n\nInstitutions become eligible to become an Institutional Partner by\nemploying individuals who actively contribute to The Project as part\nof their official duties. To state this another way, the only way for\nan Institutional Partner to influence the project is by actively\ncontributing to the open development of the project, on equal terms\nwith any other member of the community of Contributors and Council\nMembers. Merely using PyMC Software or Services in an\ninstitutional context does not allow an entity to become an\nInstitutional Partner. Financial gifts do not enable an entity to\nbecome an Institutional Partner (see Sponsors below for financial gift recognition).\nOnce an institution becomes eligible\nfor Institutional Partnership, the Steering Council must nominate and\napprove the Partnership.\n\nIf an existing Institutional Partner no longer has a contributing employee,\nthey will be given a one-year grace period for other employees to begin\ncontributing.\n\nAn Institutional Partner is free to pursue funding for their work on The\nProject through any legal means. This could involve a non-profit organization\nraising money from private foundations and donors or a for-profit company\nbuilding proprietary products and services that leverage Project Software and\nServices. Funding acquired by Institutional Partners to work on The Project is\ncalled Institutional Funding. However, no funding obtained by an Institutional\nPartner can override The Project BDFL and Steering Council. If a Partner has\nfunding to do PyMC work and the Council decides to not pursue that\nwork as a project, the Partner is free to pursue it on their own. However in\nthis situation, that part of the Partner’s work will not be under the\nPyMC banner and cannot use the Project trademarks in a way that\nsuggests a formal relationship.\n\nTo acknowledge institutional contributions, there are two level of Institutional\nPartners, with associated benefits:\n\n**Tier 1** = an institution with at least one Institutional Council Member\n\n- Acknowledged on the PyMC websites, in talks and T-shirts.\n- Ability to acknowledge their own funding sources on the PyMC\n  websites, in talks and T-shirts.\n- Unlimited participation in the annual Institutional Partners Workshop, held\n  during the (planned) annual PyMC Project Retreat. This allows the\n  Institutional Partner to invite as many of their own employees and funding\n  sources and collaborators as they want, even if they are not project\n  Contributors or Council Members.\n- Ability to influence the project through the participation of their Council\n  Member.\n- Council Members are invited to the bi-annual PyMC Developer Meeting.\n\n**Tier 2** = an institution with at least one Institutional Contributor\n\n- Same benefits as Tier 1 level Partners, but:\n- Only Institutional Contributors are invited to the Institutional Partners\n  Workshop and bi-annual PyMC Developer Meeting\n\nThe PyMC project currently recognizes PyMC Labs as a Tier 1 Institutional Partner,\nwith Thomas Wiecki and Adrian Seyboldt as their institutional contributors\nand council members.\n\n## Sponsors\nSponsors are organizations that provide significant funding to the PyMC project\ndirectly. Interested sponsors are encouraged to reach out\nto the Steering Council to arrange the sponsorship and recognition.\n\nThe PyMC project reserves the right to not approve a sponsorship if\nthe goals or culture of the prospective sponsor are deemed incompatible\nwith the goals of the project. In such case, like with any negative vote\nfrom the Steering Council, reasoning behind the decision will be provided.\n\nSponsors will be recognized by placing their logo on the PyMC website but will have\nno extra benefits related to The Project. Note that PyMCon sponsors may have\nextra benefits but those will be related to the conference, not the Project.\n\n## Team Alumni\n\n* Agustina Arroyuelo (GSoC 2018)\n* Anand Patil\n* Brandon T. Willard\n* David Huard\n* Demetri Pananos (GSoC 2019)\n* John Salvatier\n* Joseph Willard (GSoC 2019)\n* Juan Martín Loyola (GSoC 2019)\n* Rasul Karimov (GSoC 2020)\n* Sharan Yalburgi (GSoC 2018)\n* Taku Yoshioka\n* Tirth Patel (GSoC 2020)\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 12.5634765625,
          "content": "=======\nLicense\n=======\n\nPyMC is distributed under the Apache License, Version 2.0\nContains code from AePPL, which is distributed under the MIT License\n\nCopyright (c) 2006 Christopher J. Fonnesbeck (Academic Free License)\nCopyright (c) 2007-2008 Christopher J. Fonnesbeck, Anand Prabhakar Patil, David Huard (Academic Free License)\nCopyright (c) 2009-2022 The PyMC developers (see contributors to pymc-devs on GitHub)\n\nAll rights reserved.\n\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2020 The PyMC Developers\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n\nMIT License\n\nCopyright (c) 2021-2023 aesara-devs\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.0791015625,
          "content": "include requirements.txt\ninclude *.md *.rst\ninclude scripts/*.sh\ninclude LICENSE\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 1.43359375,
          "content": "# Makefile for Sphinx documentation\n#\n\n# You can set these variables from the command line.\nSPHINXBUILD   = sphinx-build\nSOURCEDIR     = docs/source\nBUILDDIR      = docs/build\n\nrtd: export READTHEDOCS=true\n\n# User-friendly check for sphinx-build\nifeq ($(shell which $(SPHINXBUILD) >/dev/null 2>&1; echo $$?), 1)\n$(error The '$(SPHINXBUILD)' command was not found. Make sure you have Sphinx installed, then set the SPHINXBUILD environment variable to point to the full path of the '$(SPHINXBUILD)' executable. Alternatively you can add the directory with the executable to your PATH. If you don't have Sphinx installed, grab it from http://sphinx-doc.org/)\nendif\n\n.PHONY: help clean html rtd view\n\nhelp:\n\t@echo \"Please use \\`make <target>' where <target> is one of\"\n\t@echo \"  html       to make standalone HTML files\"\n\t@echo \"  rtd        to build the website without any cache\"\n\t@echo \"  clean      to clean cache and intermediate files\"\n\t@echo \"  view       to open the built html files\"\n\nclean:\n\trm -rf $(BUILDDIR)/*\n\trm -rf $(SOURCEDIR)/api/generated\n\trm -rf $(SOURCEDIR)/api/**/generated\n\trm -rf $(SOURCEDIR)/api/**/classmethods\n\trm -rf docs/jupyter_execute\n\nhtml:\n\t$(SPHINXBUILD) $(SOURCEDIR) $(BUILDDIR) -b html\n\t@echo\n\t@echo \"Build finished. The HTML pages are in $(BUILDDIR).\"\n\nrtd: clean\n\t$(SPHINXBUILD) $(SOURCEDIR) $(BUILDDIR) -b html -E\n\t@echo\n\t@echo \"Build finished. The HTML pages are in $(BUILDDIR).\"\n\nview:\n\tpython -m webbrowser $(BUILDDIR)/index.html\n"
        },
        {
          "name": "README.rst",
          "type": "blob",
          "size": 14.1279296875,
          "content": ".. image:: https://cdn.rawgit.com/pymc-devs/pymc/main/docs/logos/svg/PyMC_banner.svg\n    :height: 100px\n    :alt: PyMC logo\n    :align: center\n\n|Build Status| |Coverage| |NumFOCUS_badge| |Binder| |Dockerhub| |DOIzenodo| |Conda Downloads|\n\nPyMC (formerly PyMC3) is a Python package for Bayesian statistical modeling\nfocusing on advanced Markov chain Monte Carlo (MCMC) and variational inference (VI)\nalgorithms. Its flexibility and extensibility make it applicable to a\nlarge suite of problems.\n\nCheck out the `PyMC overview <https://docs.pymc.io/en/latest/learn/core_notebooks/pymc_overview.html>`__,  or\none of `the many examples <https://www.pymc.io/projects/examples/en/latest/gallery.html>`__!\nFor questions on PyMC, head on over to our `PyMC Discourse <https://discourse.pymc.io/>`__ forum.\n\nFeatures\n========\n\n-  Intuitive model specification syntax, for example, ``x ~ N(0,1)``\n   translates to ``x = Normal('x',0,1)``\n-  **Powerful sampling algorithms**, such as the `No U-Turn\n   Sampler <http://www.jmlr.org/papers/v15/hoffman14a.html>`__, allow complex models\n   with thousands of parameters with little specialized knowledge of\n   fitting algorithms.\n-  **Variational inference**: `ADVI <http://www.jmlr.org/papers/v18/16-107.html>`__\n   for fast approximate posterior estimation as well as mini-batch ADVI\n   for large data sets.\n-  Relies on `PyTensor <https://pytensor.readthedocs.io/en/latest/>`__ which provides:\n    *  Computation optimization and dynamic C or JAX compilation\n    *  NumPy broadcasting and advanced indexing\n    *  Linear algebra operators\n    *  Simple extensibility\n-  Transparent support for missing value imputation\n\n\nLinear Regression Example\n==========================\n\n\nPlant growth can be influenced by multiple factors, and understanding these relationships is crucial for optimizing agricultural practices.\n\nImagine we conduct an experiment to predict the growth of a plant based on different environmental variables.\n\n.. code-block:: python\n\n   import pymc as pm\n\n   # Taking draws from a normal distribution\n   seed = 42\n   x_dist = pm.Normal.dist(shape=(100, 3))\n   x_data = pm.draw(x_dist, random_seed=seed)\n\n   # Independent Variables:\n   # Sunlight Hours: Number of hours the plant is exposed to sunlight daily.\n   # Water Amount: Daily water amount given to the plant (in milliliters).\n   # Soil Nitrogen Content: Percentage of nitrogen content in the soil.\n\n\n   # Dependent Variable:\n   # Plant Growth (y): Measured as the increase in plant height (in centimeters) over a certain period.\n\n\n   # Define coordinate values for all dimensions of the data\n   coords={\n    \"trial\": range(100),\n    \"features\": [\"sunlight hours\", \"water amount\", \"soil nitrogen\"],\n   }\n\n   # Define generative model\n   with pm.Model(coords=coords) as generative_model:\n      x = pm.Data(\"x\", x_data, dims=[\"trial\", \"features\"])\n\n      # Model parameters\n      betas = pm.Normal(\"betas\", dims=\"features\")\n      sigma = pm.HalfNormal(\"sigma\")\n\n      # Linear model\n      mu = x @ betas\n\n      # Likelihood\n      # Assuming we measure deviation of each plant from baseline\n      plant_growth = pm.Normal(\"plant growth\", mu, sigma, dims=\"trial\")\n\n\n   # Generating data from model by fixing parameters\n   fixed_parameters = {\n    \"betas\": [5, 20, 2],\n    \"sigma\": 0.5,\n   }\n   with pm.do(generative_model, fixed_parameters) as synthetic_model:\n      idata = pm.sample_prior_predictive(random_seed=seed) # Sample from prior predictive distribution.\n      synthetic_y = idata.prior[\"plant growth\"].sel(draw=0, chain=0)\n\n\n   # Infer parameters conditioned on observed data\n   with pm.observe(generative_model, {\"plant growth\": synthetic_y}) as inference_model:\n      idata = pm.sample(random_seed=seed)\n\n      summary = pm.stats.summary(idata, var_names=[\"betas\", \"sigma\"])\n      print(summary)\n\n\nFrom the summary, we can see that the mean of the inferred parameters are very close to the fixed parameters\n\n=====================  ======  =====  ========  =========  ===========  =========  ==========  ==========  =======\nParams                  mean     sd    hdi_3%    hdi_97%    mcse_mean    mcse_sd    ess_bulk    ess_tail    r_hat\n=====================  ======  =====  ========  =========  ===========  =========  ==========  ==========  =======\nbetas[sunlight hours]   4.972  0.054     4.866      5.066        0.001      0.001        3003        1257        1\nbetas[water amount]    19.963  0.051    19.872     20.062        0.001      0.001        3112        1658        1\nbetas[soil nitrogen]    1.994  0.055     1.899      2.107        0.001      0.001        3221        1559        1\nsigma                   0.511  0.037     0.438      0.575        0.001      0            2945        1522        1\n=====================  ======  =====  ========  =========  ===========  =========  ==========  ==========  =======\n\n.. code-block:: python\n\n   # Simulate new data conditioned on inferred parameters\n   new_x_data = pm.draw(\n      pm.Normal.dist(shape=(3, 3)),\n      random_seed=seed,\n   )\n   new_coords = coords | {\"trial\": [0, 1, 2]}\n\n   with inference_model:\n      pm.set_data({\"x\": new_x_data}, coords=new_coords)\n      pm.sample_posterior_predictive(\n         idata,\n         predictions=True,\n         extend_inferencedata=True,\n         random_seed=seed,\n      )\n\n   pm.stats.summary(idata.predictions, kind=\"stats\")\n\nThe new data conditioned on inferred parameters would look like:\n\n================ ======== ======= ======== =========\nOutput            mean     sd      hdi_3%   hdi_97%\n================ ======== ======= ======== =========\nplant growth[0]   14.229   0.515   13.325   15.272\nplant growth[1]   24.418   0.511   23.428   25.326\nplant growth[2]   -6.747   0.511   -7.740   -5.797\n================ ======== ======= ======== =========\n\n.. code-block:: python\n\n   # Simulate new data, under a scenario where the first beta is zero\n   with pm.do(\n    inference_model,\n    {inference_model[\"betas\"]: inference_model[\"betas\"] * [0, 1, 1]},\n   ) as plant_growth_model:\n      new_predictions = pm.sample_posterior_predictive(\n         idata,\n         predictions=True,\n         random_seed=seed,\n      )\n\n   pm.stats.summary(new_predictions, kind=\"stats\")\n\nThe new data, under the above scenario would look like:\n\n================ ======== ======= ======== =========\nOutput            mean     sd      hdi_3%   hdi_97%\n================ ======== ======= ======== =========\nplant growth[0]   12.149   0.515   11.193   13.135\nplant growth[1]   29.809   0.508   28.832   30.717\nplant growth[2]   -0.131   0.507   -1.121    0.791\n================ ======== ======= ======== =========\n\nGetting started\n===============\n\nIf you already know about Bayesian statistics:\n----------------------------------------------\n\n-  `API quickstart guide <https://www.pymc.io/projects/examples/en/latest/introductory/api_quickstart.html>`__\n-  The `PyMC tutorial <https://docs.pymc.io/en/latest/learn/core_notebooks/pymc_overview.html>`__\n-  `PyMC examples <https://www.pymc.io/projects/examples/en/latest/gallery.html>`__ and the `API reference <https://docs.pymc.io/en/stable/api.html>`__\n\nLearn Bayesian statistics with a book together with PyMC\n--------------------------------------------------------\n\n-  `Bayesian Analysis with Python  <http://bap.com.ar/>`__ (third edition) by Osvaldo Martin: Great introductory book.\n-  `Probabilistic Programming and Bayesian Methods for Hackers <https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers>`__: Fantastic book with many applied code examples.\n-  `PyMC port of the book \"Doing Bayesian Data Analysis\" by John Kruschke <https://github.com/cluhmann/DBDA-python>`__ as well as the `first edition <https://github.com/aloctavodia/Doing_bayesian_data_analysis>`__.\n-  `PyMC port of the book \"Statistical Rethinking A Bayesian Course with Examples in R and Stan\" by Richard McElreath <https://github.com/pymc-devs/resources/tree/master/Rethinking>`__\n-  `PyMC port of the book \"Bayesian Cognitive Modeling\" by Michael Lee and EJ Wagenmakers <https://github.com/pymc-devs/resources/tree/master/BCM>`__: Focused on using Bayesian statistics in cognitive modeling.\n\nAudio & Video\n-------------\n\n- Here is a `YouTube playlist <https://www.youtube.com/playlist?list=PL1Ma_1DBbE82OVW8Fz_6Ts1oOeyOAiovy>`__ gathering several talks on PyMC.\n- You can also find all the talks given at **PyMCon 2020** `here <https://discourse.pymc.io/c/pymcon/2020talks/15>`__.\n- The `\"Learning Bayesian Statistics\" podcast <https://www.learnbayesstats.com/>`__ helps you discover and stay up-to-date with the vast Bayesian community. Bonus: it's hosted by Alex Andorra, one of the PyMC core devs!\n\nInstallation\n============\n\nTo install PyMC on your system, follow the instructions on the `installation guide <https://www.pymc.io/projects/docs/en/latest/installation.html>`__.\n\nCiting PyMC\n===========\nPlease choose from the following:\n\n- |DOIpaper| *PyMC: A Modern and Comprehensive Probabilistic Programming Framework in Python*, Abril-Pla O, Andreani V, Carroll C, Dong L, Fonnesbeck CJ, Kochurov M, Kumar R, Lao J, Luhmann CC, Martin OA, Osthege M, Vieira R, Wiecki T, Zinkov R. (2023)\n- |DOIzenodo| A DOI for all versions.\n- DOIs for specific versions are shown on Zenodo and under `Releases <https://github.com/pymc-devs/pymc/releases>`_\n\n.. |DOIpaper| image:: https://img.shields.io/badge/DOI-10.7717%2Fpeerj--cs.1516-blue.svg\n     :target: https://doi.org/10.7717/peerj-cs.1516\n.. |DOIzenodo| image:: https://zenodo.org/badge/DOI/10.5281/zenodo.4603970.svg\n   :target: https://doi.org/10.5281/zenodo.4603970\n\nContact\n=======\n\nWe are using `discourse.pymc.io <https://discourse.pymc.io/>`__ as our main communication channel.\n\nTo ask a question regarding modeling or usage of PyMC we encourage posting to our Discourse forum under the `“Questions” Category <https://discourse.pymc.io/c/questions>`__. You can also suggest feature in the `“Development” Category <https://discourse.pymc.io/c/development>`__.\n\nYou can also follow us on these social media platforms for updates and other announcements:\n\n- `LinkedIn @pymc <https://www.linkedin.com/company/pymc/>`__\n- `YouTube @PyMCDevelopers <https://www.youtube.com/c/PyMCDevelopers>`__\n- `X @pymc_devs <https://x.com/pymc_devs>`__\n- `Mastodon @pymc@bayes.club <https://bayes.club/@pymc>`__\n\nTo report an issue with PyMC please use the `issue tracker <https://github.com/pymc-devs/pymc/issues>`__.\n\nFinally, if you need to get in touch for non-technical information about the project, `send us an e-mail <info@pymc-devs.org>`__.\n\nLicense\n=======\n\n`Apache License, Version\n2.0 <https://github.com/pymc-devs/pymc/blob/main/LICENSE>`__\n\n\nSoftware using PyMC\n===================\n\nGeneral purpose\n---------------\n\n- `Bambi <https://github.com/bambinos/bambi>`__: BAyesian Model-Building Interface (BAMBI) in Python.\n- `calibr8 <https://calibr8.readthedocs.io>`__: A toolbox for constructing detailed observation models to be used as likelihoods in PyMC.\n- `gumbi <https://github.com/JohnGoertz/Gumbi>`__: A high-level interface for building GP models.\n- `SunODE <https://github.com/aseyboldt/sunode>`__: Fast ODE solver, much faster than the one that comes with PyMC.\n- `pymc-learn <https://github.com/pymc-learn/pymc-learn>`__: Custom PyMC models built on top of pymc3_models/scikit-learn API\n\nDomain specific\n---------------\n\n- `Exoplanet <https://github.com/dfm/exoplanet>`__: a toolkit for modeling of transit and/or radial velocity observations of exoplanets and other astronomical time series.\n- `beat <https://github.com/hvasbath/beat>`__: Bayesian Earthquake Analysis Tool.\n- `CausalPy <https://github.com/pymc-labs/CausalPy>`__: A package focussing on causal inference in quasi-experimental settings.\n\nPlease contact us if your software is not listed here.\n\nPapers citing PyMC\n==================\n\nSee Google Scholar `here <https://scholar.google.com/scholar?cites=6357998555684300962>`__ and `here <https://scholar.google.com/scholar?cites=6936955228135731011>`__ for a continuously updated list.\n\nContributors\n============\n\nSee the `GitHub contributor\npage <https://github.com/pymc-devs/pymc/graphs/contributors>`__. Also read our `Code of Conduct <https://github.com/pymc-devs/pymc/blob/main/CODE_OF_CONDUCT.md>`__ guidelines for a better contributing experience.\n\nSupport\n=======\n\nPyMC is a non-profit project under NumFOCUS umbrella. If you want to support PyMC financially, you can donate `here <https://numfocus.salsalabs.org/donate-to-pymc3/index.html>`__.\n\nProfessional Consulting Support\n===============================\n\nYou can get professional consulting support from `PyMC Labs <https://www.pymc-labs.io>`__.\n\nSponsors\n========\n\n|NumFOCUS|\n\n|PyMCLabs|\n\n|Mistplay|\n\n|ODSC|\n\nThanks to our contributors\n==========================\n\n|contributors|\n\n.. |Binder| image:: https://mybinder.org/badge_logo.svg\n   :target: https://mybinder.org/v2/gh/pymc-devs/pymc/main?filepath=%2Fdocs%2Fsource%2Fnotebooks\n.. |Build Status| image:: https://github.com/pymc-devs/pymc/workflows/pytest/badge.svg\n   :target: https://github.com/pymc-devs/pymc/actions\n.. |Coverage| image:: https://codecov.io/gh/pymc-devs/pymc/branch/main/graph/badge.svg\n   :target: https://codecov.io/gh/pymc-devs/pymc\n.. |Dockerhub| image:: https://img.shields.io/docker/automated/pymc/pymc.svg\n   :target: https://hub.docker.com/r/pymc/pymc\n.. |NumFOCUS_badge| image:: https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A\n   :target: http://www.numfocus.org/\n.. |NumFOCUS| image:: https://github.com/pymc-devs/brand/blob/main/sponsors/sponsor_logos/sponsor_numfocus.png?raw=true\n   :target: http://www.numfocus.org/\n.. |PyMCLabs| image:: https://github.com/pymc-devs/brand/blob/main/sponsors/sponsor_logos/sponsor_pymc_labs.png?raw=true\n   :target: https://pymc-labs.io\n.. |Mistplay| image:: https://github.com/pymc-devs/brand/blob/main/sponsors/sponsor_logos/sponsor_mistplay.png?raw=true\n   :target: https://www.mistplay.com/\n.. |ODSC| image:: https://github.com/pymc-devs/brand/blob/main/sponsors/sponsor_logos/odsc/sponsor_odsc.png?raw=true\n   :target: https://odsc.com/california/?utm_source=pymc&utm_medium=referral\n.. |contributors| image:: https://contrib.rocks/image?repo=pymc-devs/pymc\n   :target: https://github.com/pymc-devs/pymc/graphs/contributors\n.. |Conda Downloads| image:: https://anaconda.org/conda-forge/pymc/badges/downloads.svg\n   :target: https://anaconda.org/conda-forge/pymc\n"
        },
        {
          "name": "RELEASE-NOTES.md",
          "type": "blob",
          "size": 79.1943359375,
          "content": "# Release Notes\n\n:warning: Moving forward we're no longer updating the `RELEASE-NOTES.md` document. :warning:\n\n:warning: Instead, please check the release notes in the [GitHub Releases](https://github.com/pymc-devs/pymc/releases). :warning:\n\n## PyMC 4.0.0 (2022-06-03)\n\n**If you want a description of the highlights of this release, check out the [release announcement](https://www.pymc.io/blog/v4_announcement.html) on our [new website](https://www.pymc.io)**.\nFeel free to read it, print it out, and give it to people on the street -- because _everybody_ has to know PyMC 4.0 is officially out 🍾\n\n### Do not miss 🚨\n\n  - ⚠️ The project was renamed to \"PyMC\". Now the library is installed as \"pip install pymc\" and imported like `import pymc as pm`. See this [migration guide](https://www.pymc-labs.io/blog-posts/the-quickest-migration-guide-ever-from-pymc3-to-pymc-v40/) for more details.\n  - ⚠️ Theano-PyMC has been replaced with Aesara, so all external references to `theano` and `tt` need to be replaced with `aesara` and `at`, respectively (see [4471](https://github.com/pymc-devs/pymc/pull/4471)).\n  - ⚠️ Support for JAX and JAX samplers, also allows sampling on GPUs. [This benchmark](https://www.pymc-labs.io/blog-posts/pymc-stan-benchmark/) shows speed-ups of up to 11x.\n  - ⚠️ Random seeding behavior changed (see [#5787](https://github.com/pymc-devs/pymc/pull/5787))!\n    - Sampling results will differ from those of v3 when passing the same `random_seed` as before. They will be consistent across subsequent v4 releases unless mentioned otherwise.\n    - Sampling functions no longer respect user-specified global seeding! Always pass `random_seed` to ensure reproducible behavior.\n    - `random_seed` now accepts RandomState and Generators besides integers.\n  - ⚠️ The GLM submodule was removed, please use [Bambi](https://bambinos.github.io/bambi/) instead.\n  - ⚠️ PyMC now requires SciPy version `>= 1.4.1` (see [#4857](https://github.com/pymc-devs/pymc/pull/4857)).\n\n#### v3 features not yet working in v4 ⏳\n\n⚠️  We plan to get these working again, but at this point their inner workings have not been refactored.\n  - MvNormalRandomWalk, MvStudentTRandomWalk, GARCH11 and EulerMaruyama distributions (see [#4642](https://github.com/pymc-devs/pymc/issues/4642))\n  - Nested Mixture distributions (see [#5533](https://github.com/pymc-devs/pymc/issues/5533))\n  - `pm.sample_posterior_predictive_w` (see [#4807](https://github.com/pymc-devs/pymc/issues/4807))\n  - Partially observed Multivariate distributions (see [#5260](https://github.com/pymc-devs/pymc/issues/5260))\n\n### New features 🥳\n\n- **Distributions**:\n  - Univariate censored distributions are now available via `pm.Censored`. [#5169](https://github.com/pymc-devs/pymc/pull/5169)\n  - The `CAR` distribution has been added to allow for use of conditional autoregressions which often are used in spatial and network models.\n  - Added a `logcdf` implementation for the Kumaraswamy distribution (see [#4706](https://github.com/pymc-devs/pymc/pull/4706)).\n  - The `OrderedMultinomial` distribution has been added for use on ordinal data which are _aggregated_ by trial, like multinomial observations, whereas `OrderedLogistic` only accepts ordinal data in a _disaggregated_ format, like categorical observations (see [#4773](https://github.com/pymc-devs/pymc/pull/4773)).\n  - The `Polya-Gamma` distribution has been added (see [#4531](https://github.com/pymc-devs/pymc/pull/4531)). To make use of this distribution, the [`polyagamma>=1.3.1`](https://pypi.org/project/polyagamma/) library must be installed and available in the user's environment.\n  - `pm.DensityDist` can now accept an optional `logcdf` keyword argument to pass in a function to compute the cumulative density function of the distribution (see [5026](https://github.com/pymc-devs/pymc/pull/5026)).\n  - `pm.DensityDist` can now accept an optional `moment` keyword argument to pass in a function to compute the moment of the distribution (see [5026](https://github.com/pymc-devs/pymc/pull/5026)).\n\n  - Added an alternative parametrization, `logit_p` to `pm.Binomial` and `pm.Categorical` distributions (see [5637](https://github.com/pymc-devs/pymc/pull/5637)).\n\n- **Model dimensions**:\n\n  - The dimensionality of model variables can now be parametrized through either of `shape` or `dims` (see [#4696](https://github.com/pymc-devs/pymc/pull/4696)):\n    - With `shape` the length of dimensions must be given numerically or as scalar Aesara `Variables`. Numeric entries in `shape` restrict the model variable to the exact length and re-sizing is no longer possible.\n    - `dims` keeps model variables re-sizeable (for example through `pm.Data`) and leads to well defined coordinates in `InferenceData` objects.\n    - An `Ellipsis` (`...`) in the last position of `shape` or `dims` can be used as short-hand notation for implied dimensions.\n  - New features for `pm.Data` containers:\n    - With `pm.Data(..., mutable=False)`, or by using `pm.ConstantData()` one can now create `TensorConstant` data variables. These can be more performant and compatible in situations where a variable doesn't need to be changed via `pm.set_data()`. See [#5295](https://github.com/pymc-devs/pymc/pull/5295). If you do need to change the variable, use `pm.Data(..., mutable=True)`, or `pm.MutableData()`.\n    - New named dimensions can be introduced to the model via `pm.Data(..., dims=...)`. For mutable data variables (see above) the lengths of these dimensions are symbolic, so they can be re-sized via `pm.set_data()`.\n    - `pm.Data` now passes additional kwargs to `aesara.shared`/`at.as_tensor`. [#5098](https://github.com/pymc-devs/pymc/pull/5098).\n  - The length of `dims` in the model is now tracked symbolically through `Model.dim_lengths` (see [#4625](https://github.com/pymc-devs/pymc/pull/4625)).\n\n- **Sampling**:\n  - A small change to the mass matrix tuning methods jitter+adapt_diag (the default) and adapt_diag improves performance early on during tuning for some models. [#5004](https://github.com/pymc-devs/pymc/pull/5004)\n  - New experimental mass matrix tuning method jitter+adapt_diag_grad. [#5004](https://github.com/pymc-devs/pymc/pull/5004)\n  - Support for samplers written in JAX:\n    - Adding support for [numpyro](https://github.com/pyro-ppl/numpyro)'s NUTS sampler via `pymc.sampling_jax.sample_numpyro_nuts()`\n    - Adding support for [blackjax](https://github.com/blackjax-devs/blackjax)'s NUTS sampler via `pymc.sampling_jax.sample_blackjax_nuts()` (see [#5477](ihttps://github.com/pymc-devs/pymc/pull/5477))\n    - `pymc.sampling_jax` samplers support `log_likelihood`, `observed_data`, and `sample_stats` in returned `InferenceData` object (see [#5189](https://github.com/pymc-devs/pymc/pull/5189))\n    - Adding support for `pm.Deterministic` in `pymc.sampling_jax` (see [#5182](https://github.com/pymc-devs/pymc/pull/5182))\n\n- **Miscellaneous**:\n  - The new `pm.find_constrained_prior` function can be used to find optimized prior parameters of a distribution under some\n  constraints (e.g lower and upper bound). See [#5231](https://github.com/pymc-devs/pymc/pull/5231).\n  - Nested models now inherit the parent model's coordinates. [#5344](https://github.com/pymc-devs/pymc/pull/5344)\n  - `softmax` and `log_softmax` functions added to `math` module (see [#5279](https://github.com/pymc-devs/pymc/pull/5279)).\n  - Added the low level `compile_forward_sampling_function` method to compile the aesara function responsible for generating forward samples (see [#5759](https://github.com/pymc-devs/pymc/pull/5759)).\n\n### Expected breaking changes 💔\n\n- `pm.sample(return_inferencedata=True)` is now the default (see [#4744](https://github.com/pymc-devs/pymc/pull/4744)).\n- ArviZ `plots` and `stats` *wrappers* were removed. The functions are now just available by their original names (see [#4549](https://github.com/pymc-devs/pymc/pull/4471) and `3.11.2` release notes).\n- `pm.sample_posterior_predictive(vars=...)` kwarg was removed in favor of `var_names` (see [#4343](https://github.com/pymc-devs/pymc/pull/4343)).\n- `ElemwiseCategorical` step method was removed (see [#4701](https://github.com/pymc-devs/pymc/pull/4701))\n- `LKJCholeskyCov`'s `compute_corr` keyword argument is now set to `True` by default (see[#5382](https://github.com/pymc-devs/pymc/pull/5382))\n-  Alternative `sd` keyword argument has been removed from all distributions. `sigma` should be used instead (see [#5583](https://github.com/pymc-devs/pymc/pull/5583)).\n\n_Read on if you're a developer. Or curious. Or both._\n\n### Unexpected breaking changes (action needed) 😲\n\n#### Very important ⚠️\n  - `pm.Bound` interface no longer accepts a callable class as argument, instead it requires an instantiated distribution (created via the `.dist()` API) to be passed as an argument. In addition, Bound no longer returns a class instance but works as a normal PyMC distribution. Finally, it is no longer possible to do predictive random sampling from Bounded variables. Please, consult the new documentation for details on how to use Bounded variables (see [4815](https://github.com/pymc-devs/pymc/pull/4815)).\n  - BART has received various updates ([5091](https://github.com/pymc-devs/pymc3/pull/5091), [5177](https://github.com/pymc-devs/pymc3/pull/5177), [5229](https://github.com/pymc-devs/pymc3/pull/5229), [4914](https://github.com/pymc-devs/pymc3/pull/4914)) but was removed from the main package in [#5566](https://github.com/pymc-devs/pymc/pull/5566). It is now available from [pymc-experimental](https://github.com/pymc-devs/pymc-experimental).\n  - Removed `AR1`. `AR` of order 1 should be used instead. (see [5734](https://github.com/pymc-devs/pymc/pull/5734)).\n  - The `pm.EllipticalSlice` sampler was removed (see [#5756](https://github.com/pymc-devs/pymc/issues/5756)).\n  - `BaseStochasticGradient` was removed (see [#5630](https://github.com/pymc-devs/pymc/pull/5630))\n  - `pm.Distribution(...).logp(x)` is now `pm.logp(pm.Distribution(...), x)`.\n  - `pm.Distribution(...).logcdf(x)` is now `pm.logcdf(pm.Distribution(...), x)`.\n  - `pm.Distribution(...).random(size=x)` is now `pm.draw(pm.Distribution(...), draws=x)`.\n  - `pm.draw_values(...)` and `pm.generate_samples(...)` were removed.\n  - `pm.fast_sample_posterior_predictive` was removed.\n  - `pm.sample_prior_predictive`, `pm.sample_posterior_predictive` and `pm.sample_posterior_predictive_w` now return an `InferenceData` object by default, instead of a dictionary (see [#5073](https://github.com/pymc-devs/pymc/pull/5073)).\n  - `pm.sample_prior_predictive` no longer returns transformed variable values by default. Pass them by name in `var_names` if you want to obtain these draws (see [4769](https://github.com/pymc-devs/pymc/pull/4769)).\n  - `pm.sample(trace=...)` no longer accepts `MultiTrace` or `len(.) > 0` traces ([see 5019#](https://github.com/pymc-devs/pymc/pull/5019)).\n  - Setting of initial values:\n    - Setting initial values through `pm.Distribution(testval=...)` is now `pm.Distribution(initval=...)`.\n    - `Model.update_start_values(...)` was removed. Initial values can be set in the `Model.initial_values` dictionary directly.\n    - Test values can no longer be set through `pm.Distribution(testval=...)` and must be assigned manually.\n  - `transforms` module is no longer accessible at the root level. It is accessible at `pymc.distributions.transforms` (see[#5347](https://github.com/pymc-devs/pymc/pull/5347)).\n  - `logp`, `dlogp`, and `d2logp` and `nojac` variations were removed. Use `Model.compile_logp`, `compile_dlgop` and `compile_d2logp` with `jacobian` keyword instead.\n  - `pm.DensityDist` no longer accepts the `logp` as its first position argument. It is now an optional keyword argument. If you pass a callable as the first positional argument, a `TypeError` will be raised (see [5026](https://github.com/pymc-devs/pymc/pull/5026)).\n  - `pm.DensityDist` now accepts distribution parameters as positional arguments. Passing them as a dictionary in the `observed` keyword argument is no longer supported and will raise an error (see [5026](https://github.com/pymc-devs/pymc/pull/5026)).\n  - The signature of the `logp` and `random` functions that can be passed into a `pm.DensityDist` has been changed (see [5026](https://github.com/pymc-devs/pymc/pull/5026)).\n\n#### Important:\n  - Signature and default parameters changed for several distributions:\n    - `pm.StudentT` now requires either `sigma` or `lam` as kwarg (see [#5628](https://github.com/pymc-devs/pymc/pull/5628))\n    - `pm.StudentT` now requires `nu` to be specified (no longer defaults to 1) (see [#5628](https://github.com/pymc-devs/pymc/pull/5628))\n    - `pm.AsymmetricLaplace` positional arguments re-ordered (see [#5628](https://github.com/pymc-devs/pymc/pull/5628))\n    - `pm.AsymmetricLaplace` now requires `mu` to be specified (no longer defaults to 0) (see [#5628](https://github.com/pymc-devs/pymc/pull/5628))\n    - `ZeroInflatedPoisson` `theta` parameter was renamed to `mu` (see [#5584](https://github.com/pymc-devs/pymc/pull/5584)).\n    - `pm.GaussianRandomWalk` initial distribution defaults to zero-centered normal with sigma=100 instead of flat (see[#5779](https://github.com/pymc-devs/pymc/pull/5779))\n    - `pm.AR` initial distribution defaults to unit normal instead of flat (see[#5779](https://github.com/pymc-devs/pymc/pull/5779))\n\n  - `logpt`, `logpt_sum`, `logp_elemwiset` and `nojac` variations were removed. Use `Model.logpt(jacobian=True/False, sum=True/False)` instead.\n  - `dlogp_nojact` and `d2logp_nojact` were removed. Use `Model.dlogpt` and `d2logpt` with `jacobian=False` instead.\n  - `model.makefn` is now called `Model.compile_fn`, and `model.fn` was removed.\n  - Methods starting with `fast_*`, such as `Model.fast_logp`, were removed. Same applies to `PointFunc` classes\n  - `Model(model=...)` kwarg was removed\n  - `Model(theano_config=...)` kwarg was removed\n  - `Model.size` property was removed (use `Model.ndim` instead).\n\n  - `dims` and `coords` handling:\n    - `Model.RV_dims` and `Model.coords` are now read-only properties. To modify the `coords` dictionary use `Model.add_coord`.\n    - `dims` or coordinate values that are `None` will be auto-completed (see [#4625](https://github.com/pymc-devs/pymc/pull/4625)).\n    - Coordinate values passed to `Model.add_coord` are always converted to tuples (see [#5061](https://github.com/pymc-devs/pymc/pull/5061)).\n\n  - `Transform.forward` and `Transform.backward` signatures changed.\n\n  - Changes to the Gaussian Process (GP) submodule (see [5055](https://github.com/pymc-devs/pymc/pull/5055)):\n    - The `gp.prior(..., shape=...)` kwarg was renamed to `size`.\n    - Multiple methods including `gp.prior` now require explicit kwargs.\n    - For all implementations, `gp.Latent`, `gp.Marginal` etc., `cov_func` and `mean_func` are required kwargs.\n    - In Windows test conda environment the `mkl` version is fixed to version 2020.4, and `mkl-service` is fixed to `2.3.0`.  This was required for `gp.MarginalKron` to function properly.\n    - `gp.MvStudentT` uses rotated samples from `StudentT` directly now, instead of sampling from `pm.Chi2` and then from `pm.Normal`.\n    - The \"jitter\" parameter, or the diagonal noise term added to Gram matrices such that the Cholesky is numerically stable, is now exposed to the user instead of hard-coded.  See the function `gp.util.stabilize`.\n    - The `is_observed` arguement for `gp.Marginal*` implementations has been deprecated.\n    - In the gp.utils file, the `kmeans_inducing_points` function now passes through `kmeans_kwargs` to scipy's k-means function.\n    - The function `replace_with_values` function has been added to `gp.utils`.\n    - `MarginalSparse` has been renamed `MarginalApprox`.\n\n  - Removed `MixtureSameFamily`. `Mixture` is now capable of handling batched multivariate components (see [#5438](https://github.com/pymc-devs/pymc/pull/5438)).\n\n### Documentation\n- Switched to the [pydata-sphinx-theme](https://pydata-sphinx-theme.readthedocs.io/en/latest/)\n- Updated our documentation tooling to use [MyST](https://myst-parser.readthedocs.io/en/latest/), [MyST-NB](https://myst-nb.readthedocs.io/en/latest/), sphinx-design, notfound.extension,\n  sphinx-copybutton and sphinx-remove-toctrees.\n- Separated the builds of the example notebooks and of the versioned docs.\n- Restructured the documentation to facilitate learning paths\n- Updated API docs to document objects at the path users should use to import them\n\n### Maintenance\n- ⚠️ Fixed old-time bug in Slice sampler that resulted in biased samples (see [#5816](https://github.com/pymc-devs/pymc/pull/5816)).\n- Removed float128 dtype support (see [#4514](https://github.com/pymc-devs/pymc/pull/4514)).\n- Logp method of `Uniform` and `DiscreteUniform` no longer depends on `pymc.distributions.dist_math.bound` for proper evaluation (see [#4541](https://github.com/pymc-devs/pymc/pull/4541)).\n- We now include `cloudpickle` as a required dependency, and no longer depend on `dill` (see [#4858](https://github.com/pymc-devs/pymc/pull/4858)).\n- The `incomplete_beta` function in `pymc.distributions.dist_math` was replaced by `aesara.tensor.betainc` (see [4857](https://github.com/pymc-devs/pymc/pull/4857)).\n- `math.log1mexp` and `math.log1mexp_numpy` will expect negative inputs in the future. A `FutureWarning` is now raised unless `negative_input=True` is set (see [#4860](https://github.com/pymc-devs/pymc/pull/4860)).\n- Changed name of `Lognormal` distribution to `LogNormal` to harmonize CamelCase usage for distribution names.\n- Attempt to iterate over MultiTrace will raise NotImplementedError.\n- Removed silent normalisation of `p` parameters in Categorical and Multinomial distributions (see [#5370](https://github.com/pymc-devs/pymc/pull/5370)).\n\n## PyMC 3.11.2 (14 March 2021)\n\n### New Features\n+ `pm.math.cartesian` can now handle inputs that are themselves >1D (see [#4482](https://github.com/pymc-devs/pymc/pull/4482)).\n+ Statistics and plotting functions that were removed in `3.11.0` were brought back, albeit with deprecation warnings if an old naming scheme is used (see [#4536](https://github.com/pymc-devs/pymc/pull/4536)). In order to future proof your code, rename these function calls:\n  + `pm.traceplot` → `pm.plot_trace`\n  + `pm.compareplot` → `pm.plot_compare` (here you might need to rename some columns in the input according to the [`arviz.plot_compare` documentation](https://arviz-devs.github.io/arviz/api/generated/arviz.plot_compare.html))\n  + `pm.autocorrplot` → `pm.plot_autocorr`\n  + `pm.forestplot` → `pm.plot_forest`\n  + `pm.kdeplot` → `pm.plot_kde`\n  + `pm.energyplot` → `pm.plot_energy`\n  + `pm.densityplot` → `pm.plot_density`\n  + `pm.pairplot` → `pm.plot_pair`\n\n### Maintenance\n- ⚠ Our memoization mechanism wasn't robust against hash collisions ([#4506](https://github.com/pymc-devs/pymc/issues/4506)), sometimes resulting in incorrect values in, for example, posterior predictives. The `pymc.memoize` module was removed and replaced with `cachetools`.  The `hashable` function and `WithMemoization` class were moved to `pymc.util` (see [#4525](https://github.com/pymc-devs/pymc/pull/4525)).\n- `pm.make_shared_replacements` now retains broadcasting information which fixes issues with Metropolis samplers (see [#4492](https://github.com/pymc-devs/pymc/pull/4492)).\n\n**Release manager** for 3.11.2: Michael Osthege ([@michaelosthege](https://github.com/michaelosthege))\n\n## PyMC 3.11.1 (12 February 2021)\n\n### New Features\n- Automatic imputations now also work with `ndarray` data, not just `pd.Series` or `pd.DataFrame` (see[#4439](https://github.com/pymc-devs/pymc/pull/4439)).\n- `pymc.sampling_jax.sample_numpyro_nuts` now returns samples from transformed random variables, rather than from the unconstrained representation (see [#4427](https://github.com/pymc-devs/pymc/pull/4427)).\n\n### Maintenance\n- We upgraded to `Theano-PyMC v1.1.2` which [includes bugfixes](https://github.com/pymc-devs/aesara/compare/rel-1.1.0...rel-1.1.2) for...\n  - ⚠ a problem with `tt.switch` that affected the behavior of several distributions, including at least the following special cases (see [#4448](https://github.com/pymc-devs/pymc/pull/4448))\n    1.  `Bernoulli` when all the observed values were the same (e.g., `[0, 0, 0, 0, 0]`).\n    2.  `TruncatedNormal` when `sigma` was constant and `mu` was being automatically broadcasted to match the shape of observations.\n  - Warning floods and compiledir locking (see [#4444](https://github.com/pymc-devs/pymc/pull/4444))\n- `math.log1mexp_numpy` no longer raises RuntimeWarning when given very small inputs. These were commonly observed during NUTS sampling (see [#4428](https://github.com/pymc-devs/pymc/pull/4428)).\n- `ScalarSharedVariable` can now be used as an input to other RVs directly (see [#4445](https://github.com/pymc-devs/pymc/pull/4445)).\n- `pm.sample` and `pm.find_MAP` no longer change the `start` argument (see [#4458](https://github.com/pymc-devs/pymc/pull/4458)).\n- Fixed `Dirichlet.logp` method to work with unit batch or event shapes (see [#4454](https://github.com/pymc-devs/pymc/pull/4454)).\n- Bugfix in logp and logcdf methods of `Triangular` distribution (see [#4470](https://github.com/pymc-devs/pymc/pull/4470)).\n\n**Release manager** for 3.11.1: Michael Osthege ([@michaelosthege](https://github.com/michaelosthege))\n\n## PyMC3 3.11.0 (21 January 2021)\n\nThis release breaks some APIs w.r.t. `3.10.0`. It also brings some dreadfully awaited fixes, so be sure to go through the (breaking) changes below.\n\n### Breaking Changes\n- ⚠ Many plotting and diagnostic functions that were just aliasing ArviZ functions were removed (see [4397](https://github.com/pymc-devs/pymc/pull/4397/files#)). This includes `pm.summary`, `pm.traceplot`, `pm.ess` and many more!\n- ⚠ We now depend on `Theano-PyMC` version `1.1.0` exactly (see [#4405](https://github.com/pymc-devs/pymc/pull/4405)). Major refactorings were done in `Theano-PyMC` 1.1.0. If you implement custom `Op`s or interact with Theano in any way yourself, make sure to read the [Theano-PyMC 1.1.0 release notes](https://github.com/pymc-devs/Theano-PyMC/releases/tag/rel-1.1.0).\n- ⚠ Python 3.6 support was dropped (by no longer testing) and Python 3.9 was added (see [#4332](https://github.com/pymc-devs/pymc/pull/4332)).\n- ⚠ Changed shape behavior: __No longer collapse length 1 vector shape into scalars.__ (see [#4206](https://github.com/pymc-devs/pymc/issue/4206) and [#4214](https://github.com/pymc-devs/pymc/pull/4214))\n  - __Applies to random variables and also the `.random(size=...)` kwarg!__\n  - To create scalar variables you must now use `shape=None` or `shape=()`.\n  - __`shape=(1,)` and `shape=1` now become vectors.__ Previously they were collapsed into scalars\n  - 0-length dimensions are now ruled illegal for random variables and raise a `ValueError`.\n- In `sample_prior_predictive` the `vars` kwarg was removed in favor of `var_names` (see [#4327](https://github.com/pymc-devs/pymc/pull/4327)).\n- Removed `theanof.set_theano_config` because it illegally changed Theano's internal state (see [#4329](https://github.com/pymc-devs/pymc/pull/4329)).\n\n\n### New Features\n- Option to set `check_bounds=False` when instantiating `pymc.Model()`. This turns off bounds checks that ensure that input parameters of distributions are valid. For correctly specified models, this is unnecessary as all parameters get automatically transformed so that all values are valid. Turning this off should lead to faster sampling (see [#4377](https://github.com/pymc-devs/pymc/pull/4377)).\n- `OrderedProbit` distribution added (see [#4232](https://github.com/pymc-devs/pymc/pull/4232)).\n- `plot_posterior_predictive_glm` now works with `arviz.InferenceData` as well (see [#4234](https://github.com/pymc-devs/pymc/pull/4234))\n- Add `logcdf` method to all univariate discrete distributions (see [#4387](https://github.com/pymc-devs/pymc/pull/4387)).\n- Add `random` method to `MvGaussianRandomWalk` (see [#4388](https://github.com/pymc-devs/pymc/pull/4388))\n- `AsymmetricLaplace` distribution added (see [#4392](https://github.com/pymc-devs/pymc/pull/4392)).\n- `DirichletMultinomial` distribution added (see [#4373](https://github.com/pymc-devs/pymc/pull/4373)).\n- Added a new `predict` method to `BART` to compute out of sample predictions (see [#4310](https://github.com/pymc-devs/pymc/pull/4310)).\n\n### Maintenance\n- Fixed bug whereby partial traces returns after keyboard interrupt during parallel sampling had fewer draws than would've been available [#4318](https://github.com/pymc-devs/pymc/pull/4318)\n- Make `sample_shape` same across all contexts in `draw_values` (see [#4305](https://github.com/pymc-devs/pymc/pull/4305)).\n- The notebook gallery has been moved to https://github.com/pymc-devs/pymc-examples (see [#4348](https://github.com/pymc-devs/pymc/pull/4348)).\n- `math.logsumexp` now matches `scipy.special.logsumexp` when arrays contain infinite values (see [#4360](https://github.com/pymc-devs/pymc/pull/4360)).\n- Fixed mathematical formulation in `MvStudentT` random method. (see [#4359](https://github.com/pymc-devs/pymc/pull/4359))\n- Fix issue in `logp` method of `HyperGeometric`. It now returns `-inf` for invalid parameters (see [4367](https://github.com/pymc-devs/pymc/pull/4367))\n- Fixed `MatrixNormal` random method to work with parameters as random variables. (see [#4368](https://github.com/pymc-devs/pymc/pull/4368))\n- Update the `logcdf` method of several continuous distributions to return -inf for invalid parameters and values, and raise an informative error when multiple values cannot be evaluated in a single call. (see [4393](https://github.com/pymc-devs/pymc/pull/4393) and [#4421](https://github.com/pymc-devs/pymc/pull/4421))\n- Improve numerical stability in `logp` and `logcdf` methods of `ExGaussian` (see [#4407](https://github.com/pymc-devs/pymc/pull/4407))\n- Issue UserWarning when doing prior or posterior predictive sampling with models containing Potential factors (see [#4419](https://github.com/pymc-devs/pymc/pull/4419))\n- Dirichlet distribution's `random` method is now optimized and gives outputs in correct shape (see [#4416](https://github.com/pymc-devs/pymc/pull/4407))\n- Attempting to sample a named model with SMC will now raise a `NotImplementedError`. (see [#4365](https://github.com/pymc-devs/pymc/pull/4365))\n\n**Release manager** for 3.11.0: Eelke Spaak ([@Spaak](https://github.com/Spaak))\n\n## PyMC3 3.10.0 (7 December 2020)\n\nThis is a major release with many exciting new features. The biggest change is that we now rely on our own fork of [Theano-PyMC](https://github.com/pymc-devs/Theano-PyMC). This is in line with our [big announcement about our commitment to PyMC3 and Theano](https://pymc-devs.medium.com/the-future-of-pymc-or-theano-is-dead-long-live-theano-d8005f8a0e9b).\n\nWhen upgrading, make sure that `Theano-PyMC` and not `Theano` are installed (the imports remain unchanged, however). If not, you can uninstall `Theano`:\n```\nconda remove theano\n```\n\nAnd to install:\n```\nconda install -c conda-forge theano-pymc\n```\n\nOr, if you are using pip (not recommended):\n```\npip uninstall theano\n```\nAnd to install:\n```\npip install theano-pymc\n```\n\nThis new version of `Theano-PyMC` comes with an experimental JAX backend which, when combined with the new and experimental JAX samplers in PyMC3, can greatly speed up sampling in your model. As this is still very new, please do not use it in production yet but do test it out and let us know if anything breaks and what results you are seeing, especially speed-wise.\n\n### New features\n- New experimental JAX samplers in `pymc.sample_jax` (see [notebook](https://docs.pymc.io/notebooks/GLM-hierarchical-jax.html) and [#4247](https://github.com/pymc-devs/pymc/pull/4247)). Requires JAX and either TFP or numpyro.\n- Add MLDA, a new stepper for multilevel sampling. MLDA can be used when a hierarchy of approximate posteriors of varying accuracy is available, offering improved sampling efficiency especially in high-dimensional problems and/or where gradients are not available (see [#3926](https://github.com/pymc-devs/pymc/pull/3926))\n- Add Bayesian Additive Regression Trees (BARTs) [#4183](https://github.com/pymc-devs/pymc/pull/4183))\n- Added `pymc.gp.cov.Circular` kernel for Gaussian Processes on circular domains, e.g. the unit circle (see [#4082](https://github.com/pymc-devs/pymc/pull/4082)).\n- Added a new `MixtureSameFamily` distribution to handle mixtures of arbitrary dimensions in vectorized form for improved speed (see [#4185](https://github.com/pymc-devs/pymc/issues/4185)).\n- `sample_posterior_predictive_w` can now feed on `xarray.Dataset` - e.g. from `InferenceData.posterior`. (see [#4042](https://github.com/pymc-devs/pymc/pull/4042))\n- Change SMC metropolis kernel to independent metropolis kernel [#4115](https://github.com/pymc-devs/pymc/pull/4115))\n- Add alternative parametrization to NegativeBinomial distribution in terms of n and p (see [#4126](https://github.com/pymc-devs/pymc/issues/4126))\n- Added semantically meaningful `str` representations to PyMC3 objects for console, notebook, and GraphViz use (see [#4076](https://github.com/pymc-devs/pymc/pull/4076), [#4065](https://github.com/pymc-devs/pymc/pull/4065), [#4159](https://github.com/pymc-devs/pymc/pull/4159), [#4217](https://github.com/pymc-devs/pymc/pull/4217), [#4243](https://github.com/pymc-devs/pymc/pull/4243), and [#4260](https://github.com/pymc-devs/pymc/pull/4260)).\n- Add Discrete HyperGeometric Distribution (see [#4249](https://github.com/pymc-devs/pymc/pull/#4249))\n\n### Maintenance\n- Switch the dependency of Theano to our own fork, [Theano-PyMC](https://github.com/pymc-devs/Theano-PyMC).\n- Removed non-NDArray (Text, SQLite, HDF5) backends and associated tests.\n- Use dill to serialize user defined logp functions in `DensityDist`. The previous serialization code fails if it is used in notebooks on Windows and Mac. `dill` is now a required dependency. (see [#3844](https://github.com/pymc-devs/pymc/issues/3844)).\n- Fixed numerical instability in ExGaussian's logp by preventing `logpow` from returning `-inf` (see [#4050](https://github.com/pymc-devs/pymc/pull/4050)).\n- Numerically improved stickbreaking transformation - e.g. for the `Dirichlet` distribution. [#4129](https://github.com/pymc-devs/pymc/pull/4129)\n- Enabled the `Multinomial` distribution to handle batch sizes that have more than 2 dimensions. [#4169](https://github.com/pymc-devs/pymc/pull/4169)\n- Test model logp before starting any MCMC chains (see [#4211](https://github.com/pymc-devs/pymc/pull/4211))\n- Fix bug in `model.check_test_point` that caused the `test_point` argument to be ignored. (see [PR #4211](https://github.com/pymc-devs/pymc/pull/4211#issuecomment-727142721))\n- Refactored MvNormal.random method with better handling of sample, batch and event shapes. [#4207](https://github.com/pymc-devs/pymc/pull/4207)\n- The `InverseGamma` distribution now implements a `logcdf`. [#3944](https://github.com/pymc-devs/pymc/pull/3944)\n- Make starting jitter methods for nuts sampling more robust by resampling values that lead to non-finite probabilities. A new optional argument `jitter-max-retries` can be passed to `pm.sample()` and `pm.init_nuts()` to control the maximum number of retries per chain. [4298](https://github.com/pymc-devs/pymc/pull/4298)\n\n### Documentation\n- Added a new notebook demonstrating how to incorporate sampling from a conjugate Dirichlet-multinomial posterior density in conjunction with other step methods (see [#4199](https://github.com/pymc-devs/pymc/pull/4199)).\n- Mentioned the way to do any random walk with `theano.tensor.cumsum()` in `GaussianRandomWalk` docstrings (see [#4048](https://github.com/pymc-devs/pymc/pull/4048)).\n\n**Release manager** for 3.10.0: Eelke Spaak ([@Spaak](https://github.com/Spaak))\n\n## PyMC3 3.9.3 (11 August 2020)\n\n### New features\n- Introduce optional arguments to `pm.sample`: `mp_ctx` to control how the processes for parallel sampling are started, and `pickle_backend` to specify which library is used to pickle models in parallel sampling when the multiprocessing context is not of type `fork` (see [#3991](https://github.com/pymc-devs/pymc/pull/3991)).\n- Add sampler stats `process_time_diff`, `perf_counter_diff` and `perf_counter_start`, that record wall and CPU times for each NUTS and HMC sample (see [ #3986](https://github.com/pymc-devs/pymc/pull/3986)).\n- Extend `keep_size` argument handling for `sample_posterior_predictive` and `fast_sample_posterior_predictive`, to work on ArviZ `InferenceData` and xarray `Dataset` input values (see [PR #4006](https://github.com/pymc-devs/pymc/pull/4006) and issue [#4004](https://github.com/pymc-devs/pymc/issues/4004)).\n- SMC-ABC: add the Wasserstein and energy distance functions. Refactor API, the distance, sum_stats and epsilon arguments are now passed `pm.Simulator` instead of `pm.sample_smc`. Add random method to `pm.Simulator`. Add option to save the simulated data. Improved LaTeX representation [#3996](https://github.com/pymc-devs/pymc/pull/3996).\n- SMC-ABC: Allow use of potentials by adding them to the prior term. [#4016](https://github.com/pymc-devs/pymc/pull/4016).\n\n### Maintenance\n- Fix an error on Windows and Mac where error message from unpickling models did not show up in the notebook, or where sampling froze when a worker process crashed (see [#3991](https://github.com/pymc-devs/pymc/pull/3991)).\n- Require Theano >= 1.0.5 (see [#4032](https://github.com/pymc-devs/pymc/pull/4032)).\n\n### Documentation\n- Notebook on [multilevel modeling](https://docs.pymc.io/notebooks/multilevel_modeling.html) has been rewritten to showcase ArviZ and xarray usage for inference result analysis (see [#3963](https://github.com/pymc-devs/pymc/pull/3963)).\n\n_NB: The `docs/*` folder is still removed from the tarball due to an upload size limit on PyPi._\n\n**Release manager** for 3.9.3: Kyle Beauchamp ([@kyleabeauchamp](https://github.com/kyleabeauchamp))\n\n## PyMC3 3.9.2 (24 June 2020)\n\n### Maintenance\n- Warning added in GP module when `input_dim` is lower than the number of columns in `X` to compute the covariance function (see [#3974](https://github.com/pymc-devs/pymc/pull/3974)).\n- Pass the `tune` argument from `sample` when using `advi+adapt_diag_grad` (see issue [#3965](https://github.com/pymc-devs/pymc/issues/3965), fixed by [#3979](https://github.com/pymc-devs/pymc/pull/3979)).\n- Add simple test case for new coords and dims feature in `pm.Model` (see [#3977](https://github.com/pymc-devs/pymc/pull/3977)).\n- Require ArviZ >= 0.9.0 (see [#3977](https://github.com/pymc-devs/pymc/pull/3977)).\n- Fixed issue [#3962](https://github.com/pymc-devs/pymc/issues/3962) by making a change in the `_random()` method of `GaussianRandomWalk` class (see PR [#3985](https://github.com/pymc-devs/pymc/pull/3985)). Further testing revealed a new issue which is being tracked by [#4010](https://github.com/pymc-devs/pymc/issues/4010).\n\n_NB: The `docs/*` folder is still removed from the tarball due to an upload size limit on PyPi._\n\n**Release manager** for 3.9.2: Alex Andorra ([@AlexAndorra](https://github.com/AlexAndorra))\n\n## PyMC3 3.9.1 (16 June 2020)\nThe `v3.9.0` upload to PyPI didn't include a tarball, which is fixed in this release.\nThough we had to temporarily remove the `docs/*` folder from the tarball due to a size limit.\n\n**Release manager** for 3.9.1: Michael Osthege ([@michaelosthege](https://github.com/michaelosthege))\n\n## PyMC3 3.9.0 (16 June 2020)\n\n### New features\n- Use [fastprogress](https://github.com/fastai/fastprogress) instead of tqdm [#3693](https://github.com/pymc-devs/pymc/pull/3693).\n- `DEMetropolis` can now tune both `lambda` and `scaling` parameters, but by default neither of them are tuned. See [#3743](https://github.com/pymc-devs/pymc/pull/3743) for more info.\n- `DEMetropolisZ`, an improved variant of `DEMetropolis` brings better parallelization and higher efficiency with fewer chains with a slower initial convergence. This implementation is experimental. See [#3784](https://github.com/pymc-devs/pymc/pull/3784) for more info.\n- Notebooks that give insight into `DEMetropolis`, `DEMetropolisZ` and the `DifferentialEquation` interface are now located in the [Tutorials/Deep Dive](https://docs.pymc.io/nb_tutorials/index.html) section.\n- Add `fast_sample_posterior_predictive`, a vectorized alternative to `sample_posterior_predictive`.  This alternative is substantially faster for large models.\n- GP covariance functions can now be exponentiated by a scalar. See PR [#3852](https://github.com/pymc-devs/pymc/pull/3852)\n- `sample_posterior_predictive` can now feed on `xarray.Dataset` - e.g. from `InferenceData.posterior`. (see [#3846](https://github.com/pymc-devs/pymc/pull/3846))\n- `SamplerReport` (`MultiTrace.report`) now has properties `n_tune`, `n_draws`, `t_sampling` for increased convenience (see [#3827](https://github.com/pymc-devs/pymc/pull/3827))\n- `pm.sample(..., return_inferencedata=True)` can now directly return the trace as `arviz.InferenceData` (see [#3911](https://github.com/pymc-devs/pymc/pull/3911))\n- `pm.sample` now has support for adapting dense mass matrix using `QuadPotentialFullAdapt` (see [#3596](https://github.com/pymc-devs/pymc/pull/3596), [#3705](https://github.com/pymc-devs/pymc/pull/3705), [#3858](https://github.com/pymc-devs/pymc/pull/3858), and [#3893](https://github.com/pymc-devs/pymc/pull/3893)). Use `init=\"adapt_full\"` or `init=\"jitter+adapt_full\"` to use.\n- `Moyal` distribution added (see [#3870](https://github.com/pymc-devs/pymc/pull/3870)).\n- `pm.LKJCholeskyCov` now automatically computes and returns the unpacked Cholesky decomposition, the correlations and the standard deviations of the covariance matrix (see [#3881](https://github.com/pymc-devs/pymc/pull/3881)).\n- `pm.Data` container can now be used for index variables, i.e with integer data and not only floats (issue [#3813](https://github.com/pymc-devs/pymc/issues/3813), fixed by [#3925](https://github.com/pymc-devs/pymc/pull/3925)).\n- `pm.Data` container can now be used as input for other random variables (issue [#3842](https://github.com/pymc-devs/pymc/issues/3842), fixed by [#3925](https://github.com/pymc-devs/pymc/pull/3925)).\n- Allow users to specify coordinates and dimension names instead of numerical shapes when specifying a model. This makes interoperability with ArviZ easier. ([see #3551](https://github.com/pymc-devs/pymc/pull/3551))\n- Plots and Stats API sections now link to ArviZ documentation [#3927](https://github.com/pymc-devs/pymc/pull/3927)\n- Add `SamplerReport` with properties `n_draws`, `t_sampling` and `n_tune` to SMC. `n_tune` is always 0 [#3931](https://github.com/pymc-devs/pymc/issues/3931).\n- SMC-ABC: add option to define summary statistics, allow to sample from more complex models, remove redundant distances [#3940](https://github.com/pymc-devs/pymc/issues/3940)\n\n### Maintenance\n- Tuning results no longer leak into sequentially sampled `Metropolis` chains (see #3733 and #3796).\n- We'll deprecate the `Text` and `SQLite` backends and the `save_trace`/`load_trace` functions, since this is now done with ArviZ. (see [#3902](https://github.com/pymc-devs/pymc/pull/3902))\n- ArviZ `v0.8.3` is now the minimum required version\n- In named models, `pm.Data` objects now get model-relative names (see [#3843](https://github.com/pymc-devs/pymc/pull/3843)).\n- `pm.sample` now takes 1000 draws and 1000 tuning samples by default, instead of 500 previously (see [#3855](https://github.com/pymc-devs/pymc/pull/3855)).\n- Moved argument division out of `NegativeBinomial` `random` method. Fixes [#3864](https://github.com/pymc-devs/pymc/issues/3864) in the style of [#3509](https://github.com/pymc-devs/pymc/pull/3509).\n- The Dirichlet distribution now raises a ValueError when it's initialized with <= 0 values (see [#3853](https://github.com/pymc-devs/pymc/pull/3853)).\n- Dtype bugfix in `MvNormal` and `MvStudentT` (see [3836](https://github.com/pymc-devs/pymc/pull/3836)).\n- End of sampling report now uses `arviz.InferenceData` internally and avoids storing\n  pointwise log likelihood (see [#3883](https://github.com/pymc-devs/pymc/pull/3883)).\n- The multiprocessing start method on MacOS is now set to \"forkserver\", to avoid crashes (see issue [#3849](https://github.com/pymc-devs/pymc/issues/3849), solved by [#3919](https://github.com/pymc-devs/pymc/pull/3919)).\n- The AR1 logp now uses the precision of the whole AR1 process instead of just the innovation precision (see issue [#3892](https://github.com/pymc-devs/pymc/issues/3892), fixed by [#3899](https://github.com/pymc-devs/pymc/pull/3899)).\n- Forced the `Beta` distribution's `random` method to generate samples that are in the open interval $(0, 1)$, i.e. no value can be equal to zero or equal to one (issue [#3898](https://github.com/pymc-devs/pymc/issues/3898) fixed by [#3924](https://github.com/pymc-devs/pymc/pull/3924)).\n- Fixed an issue that happened on Windows, that was introduced by the clipped beta distribution rvs function ([#3924](https://github.com/pymc-devs/pymc/pull/3924)). Windows does not support the `float128` dtype, but we had assumed that it had to be available. The solution was to only support `float128` on Linux and Darwin systems (see issue [#3929](https://github.com/pymc-devs/pymc/issues/3849) fixed by [#3930](https://github.com/pymc-devs/pymc/pull/3930)).\n\n### Deprecations\n- Remove `sample_ppc` and `sample_ppc_w` that were deprecated in 3.6.\n- Deprecated `sd` has been replaced by `sigma` (already in version 3.7) in continuous, mixed and timeseries distributions and now raises `DeprecationWarning` when `sd` is used. (see [#3837](https://github.com/pymc-devs/pymc/pull/3837) and [#3688](https://github.com/pymc-devs/pymc/issues/3688)).\n- We'll deprecate the `Text` and `SQLite` backends and the `save_trace`/`load_trace` functions, since this is now done with ArviZ. (see [#3902](https://github.com/pymc-devs/pymc/pull/3902))\n- Dropped some deprecated kwargs and functions (see [#3906](https://github.com/pymc-devs/pymc/pull/3906))\n- Dropped the outdated 'nuts' initialization method for `pm.sample` (see [#3863](https://github.com/pymc-devs/pymc/pull/3863)).\n\n**Release manager** for 3.9.0: Michael Osthege ([@michaelosthege](https://github.com/michaelosthege))\n\n## PyMC3 3.8 (November 29 2019)\n\n### New features\n- Implemented robust u turn check in NUTS (similar to stan-dev/stan#2800). See PR [#3605]\n- Add capabilities to do inference on parameters in a differential equation with `DifferentialEquation`. See [#3590](https://github.com/pymc-devs/pymc/pull/3590) and [#3634](https://github.com/pymc-devs/pymc/pull/3634).\n- Distinguish between `Data` and `Deterministic` variables when graphing models with graphviz. PR [#3491](https://github.com/pymc-devs/pymc/pull/3491).\n- Sequential Monte Carlo - Approximate Bayesian Computation step method is now available. The implementation is in an experimental stage and will be further improved.\n- Added `Matern12` covariance function for Gaussian processes. This is the Matern kernel with nu=1/2.\n- Progressbar reports number of divergences in real time, when available [#3547](https://github.com/pymc-devs/pymc/pull/3547).\n- Sampling from variational approximation now allows for alternative trace backends [#3550].\n- Infix `@` operator now works with random variables and deterministics [#3619](https://github.com/pymc-devs/pymc/pull/3619).\n- [ArviZ](https://arviz-devs.github.io/arviz/) is now a requirement, and handles plotting, diagnostics, and statistical checks.\n- Can use GaussianRandomWalk in sample_prior_predictive and sample_prior_predictive [#3682](https://github.com/pymc-devs/pymc/pull/3682)\n- Now 11 years of S&P returns in data set[#3682](https://github.com/pymc-devs/pymc/pull/3682)\n\n### Maintenance\n- Moved math operations out of `Rice`, `TruncatedNormal`, `Triangular` and `ZeroInflatedNegativeBinomial` `random` methods. Math operations on values returned by `draw_values` might not broadcast well, and all the `size` aware broadcasting is left to `generate_samples`. Fixes [#3481](https://github.com/pymc-devs/pymc/issues/3481) and [#3508](https://github.com/pymc-devs/pymc/issues/3508)\n- Parallelization of population steppers (`DEMetropolis`) is now set via the `cores` argument. ([#3559](https://github.com/pymc-devs/pymc/pull/3559))\n- Fixed a bug in `Categorical.logp`. In the case of multidimensional `p`'s, the indexing was done wrong leading to incorrectly shaped tensors that consumed `O(n**2)` memory instead of `O(n)`. This fixes issue [#3535](https://github.com/pymc-devs/pymc/issues/3535)\n- Fixed a defect in `OrderedLogistic.__init__` that unnecessarily increased the dimensionality of the underlying `p`. Related to issue issue [#3535](https://github.com/pymc-devs/pymc/issues/3535) but was not the true cause of it.\n- SMC: stabilize covariance matrix [3573](https://github.com/pymc-devs/pymc/pull/3573)\n- SMC: is no longer a step method of `pm.sample` now it should be called using `pm.sample_smc` [3579](https://github.com/pymc-devs/pymc/pull/3579)\n- SMC: improve computation of the proposal scaling factor [3594](https://github.com/pymc-devs/pymc/pull/3594) and [3625](https://github.com/pymc-devs/pymc/pull/3625)\n- SMC: reduce number of logp evaluations [3600](https://github.com/pymc-devs/pymc/pull/3600)\n- SMC: remove `scaling` and `tune_scaling` arguments as is a better idea to always allow SMC to automatically compute the scaling factor [3625](https://github.com/pymc-devs/pymc/pull/3625)\n- Now uses `multiprocessong` rather than `psutil` to count CPUs, which results in reliable core counts on Chromebooks.\n- `sample_posterior_predictive` now preallocates the memory required for its output to improve memory usage. Addresses problems raised in this [discourse thread](https://discourse.pymc.io/t/memory-error-with-posterior-predictive-sample/2891/4).\n- Fixed a bug in `Categorical.logp`. In the case of multidimensional `p`'s, the indexing was done wrong leading to incorrectly shaped tensors that consumed `O(n**2)` memory instead of `O(n)`. This fixes issue [#3535](https://github.com/pymc-devs/pymc/issues/3535)\n- Fixed a defect in `OrderedLogistic.__init__` that unnecessarily increased the dimensionality of the underlying `p`. Related to issue issue [#3535](https://github.com/pymc-devs/pymc/issues/3535) but was not the true cause of it.\n- Wrapped `DensityDist.rand` with `generate_samples` to make it aware of the distribution's shape. Added control flow attributes to still be able to behave as in earlier versions, and to control how to interpret the `size` parameter in the `random` callable signature. Fixes [3553](https://github.com/pymc-devs/pymc/issues/3553)\n- Added `theano.gof.graph.Constant` to type checks done in `_draw_value` (fixes issue [3595](https://github.com/pymc-devs/pymc/issues/3595))\n- `HalfNormal` did not used to work properly in `draw_values`, `sample_prior_predictive`, or `sample_posterior_predictive` (fixes issue [3686](https://github.com/pymc-devs/pymc/pull/3686))\n- Random variable transforms were inadvertently left out of the API documentation. Added them. (See PR [3690](https://github.com/pymc-devs/pymc/pull/3690)).\n- Refactored `pymc.model.get_named_nodes_and_relations` to use the ancestors and descendents, in a way that is consistent with `theano`'s naming convention.\n- Changed the way in which `pymc.model.get_named_nodes_and_relations` computes nodes without ancestors to make it robust to changes in var_name orderings (issue [#3643](https://github.com/pymc-devs/pymc/issues/3643))\n\n## PyMC3 3.7 (May 29 2019)\n\n### New features\n\n- Add data container class (`Data`) that wraps the theano SharedVariable class and let the model be aware of its inputs and outputs.\n- Add function `set_data` to update variables defined as `Data`.\n- `Mixture` now supports mixtures of multidimensional probability distributions, not just lists of 1D distributions.\n- `GLM.from_formula` and `LinearComponent.from_formula` can extract variables from the calling scope. Customizable via the new `eval_env` argument. Fixing [#3382](https://github.com/pymc-devs/pymc/issues/3382).\n- Added the `distributions.shape_utils` module with functions used to help broadcast samples drawn from distributions using the `size` keyword argument.\n- Used `numpy.vectorize` in `distributions.distribution._compile_theano_function`. This enables `sample_prior_predictive` and `sample_posterior_predictive` to ask for tuples of samples instead of just integers. This fixes issue [#3422](https://github.com/pymc-devs/pymc/issues/3422).\n\n### Maintenance\n\n- All occurrences of `sd` as a parameter name have been renamed to `sigma`. `sd` will continue to function for backwards compatibility.\n- `HamiltonianMC` was ignoring certain arguments like `target_accept`, and not using the custom step size jitter function with expectation 1.\n- Made `BrokenPipeError` for parallel sampling more verbose on Windows.\n- Added the `broadcast_distribution_samples` function that helps broadcasting arrays of drawn samples, taking into account the requested `size` and the inferred distribution shape. This sometimes is needed by distributions that call several `rvs` separately within their `random` method, such as the `ZeroInflatedPoisson` (fixes issue [#3310](https://github.com/pymc-devs/pymc/issues/3310)).\n- The `Wald`, `Kumaraswamy`, `LogNormal`, `Pareto`, `Cauchy`, `HalfCauchy`, `Weibull` and `ExGaussian` distributions `random` method used a hidden `_random` function that was written with scalars in mind. This could potentially lead to artificial correlations between random draws. Added shape guards and broadcasting of the distribution samples to prevent this (Similar to issue [#3310](https://github.com/pymc-devs/pymc/issues/3310)).\n- Added a fix to allow the imputation of single missing values of observed data, which previously would fail (fixes issue [#3122](https://github.com/pymc-devs/pymc/issues/3122)).\n- The `draw_values` function was too permissive with what could be grabbed from inside `point`, which lead to an error when sampling posterior predictives of variables that depended on shared variables that had changed their shape after `pm.sample()` had been called (fix issue [#3346](https://github.com/pymc-devs/pymc/issues/3346)).\n- `draw_values` now adds the theano graph descendants of `TensorConstant` or `SharedVariables` to the named relationship nodes stack, only if these descendants are `ObservedRV` or `MultiObservedRV` instances (fixes issue [#3354](https://github.com/pymc-devs/pymc/issues/3354)).\n- Fixed bug in broadcast_distrution_samples, which did not handle correctly cases in which some samples did not have the size tuple prepended.\n- Changed `MvNormal.random`'s usage of `tensordot` for Cholesky encoded covariances. This lead to wrong axis broadcasting and seemed to be the cause for issue [#3343](https://github.com/pymc-devs/pymc/issues/3343).\n- Fixed defect in `Mixture.random` when multidimensional mixtures were involved. The mixture component was not preserved across all the elements of the dimensions of the mixture. This meant that the correlations across elements within a given draw of the mixture were partly broken.\n- Restructured `Mixture.random` to allow better use of vectorized calls to `comp_dists.random`.\n- Added tests for mixtures of multidimensional distributions to the test suite.\n- Fixed incorrect usage of `broadcast_distribution_samples` in `DiscreteWeibull`.\n- `Mixture`'s default dtype is now determined by `theano.config.floatX`.\n- `dist_math.random_choice` now handles nd-arrays of category probabilities, and also handles sizes that are not `None`. Also removed unused `k` kwarg from `dist_math.random_choice`.\n- Changed `Categorical.mode` to preserve all the dimensions of `p` except the last one, which encodes each category's probability.\n- Changed initialization of `Categorical.p`. `p` is now normalized to sum to `1` inside `logp` and `random`, but not during initialization. This could hide negative values supplied to `p` as mentioned in [#2082](https://github.com/pymc-devs/pymc/issues/2082).\n- `Categorical` now accepts elements of `p` equal to `0`. `logp` will return `-inf` if there are `values` that index to the zero probability categories.\n- Add `sigma`, `tau`, and `sd` to signature of `NormalMixture`.\n- Set default lower and upper values of -inf and inf for pm.distributions.continuous.TruncatedNormal. This avoids errors caused by their previous values of None (fixes issue [#3248](https://github.com/pymc-devs/pymc/issues/3248)).\n- Converted all calls to `pm.distributions.bound._ContinuousBounded` and `pm.distributions.bound._DiscreteBounded` to use only and all positional arguments (fixes issue [#3399](https://github.com/pymc-devs/pymc/issues/3399)).\n- Restructured `distributions.distribution.generate_samples` to use the `shape_utils` module. This solves issues [#3421](https://github.com/pymc-devs/pymc/issues/3421) and [#3147](https://github.com/pymc-devs/pymc/issues/3147) by using the `size` aware broadcating functions in `shape_utils`.\n- Fixed the `Multinomial.random` and `Multinomial.random_` methods to make them compatible with the new `generate_samples` function. In the process, a bug of the `Multinomial.random_` shape handling was discovered and fixed.\n- Fixed a defect found in `Bound.random` where the `point` dictionary was passed to `generate_samples` as an `arg` instead of in `not_broadcast_kwargs`.\n- Fixed a defect found in `Bound.random_` where `total_size` could end up as a `float64` instead of being an integer if given `size=tuple()`.\n- Fixed an issue in `model_graph` that caused construction of the graph of the model for rendering to hang: replaced a search over the powerset of the nodes with a breadth-first search over the nodes. Fix for [#3458](https://github.com/pymc-devs/pymc/issues/3458).\n- Removed variable annotations from `model_graph` but left type hints (Fix for [#3465](https://github.com/pymc-devs/pymc/issues/3465)). This means that we support `python>=3.5.4`.\n- Default `target_accept`for `HamiltonianMC` is now 0.65, as suggested in Beskos et. al. 2010 and Neal 2001.\n- Fixed bug in `draw_values` that lead to intermittent errors in python3.5. This happened with some deterministic nodes that were drawn but not added to `givens`.\n\n### Deprecations\n\n- `nuts_kwargs` and `step_kwargs` have been deprecated in favor of using the standard `kwargs` to pass optional step method arguments.\n- `SGFS` and `CSG` have been removed (Fix for [#3353](https://github.com/pymc-devs/pymc/issues/3353)). They have been moved to [pymc-experimental](https://github.com/pymc-devs/pymc-experimental).\n- References to `live_plot` and corresponding notebooks have been removed.\n- Function `approx_hessian` was removed, due to `numdifftools` becoming incompatible with current `scipy`. The function was already optional, only available to a user who installed `numdifftools` separately, and not hit on any common codepaths. [#3485](https://github.com/pymc-devs/pymc/pull/3485).\n- Deprecated `vars` parameter of `sample_posterior_predictive` in favor of `varnames`.\n-  References to `live_plot` and corresponding notebooks have been removed.\n- Deprecated `vars` parameters of `sample_posterior_predictive` and `sample_prior_predictive` in favor of `var_names`.  At least for the latter, this is more accurate, since the `vars` parameter actually took names.\n\n### Contributors sorted by number of commits\n    45  Luciano Paz\n    38  Thomas Wiecki\n    23  Colin Carroll\n    19  Junpeng Lao\n    15  Chris Fonnesbeck\n    13  Juan Martín Loyola\n    13  Ravin Kumar\n     8  Robert P. Goldman\n     5  Tim Blazina\n     4  chang111\n     4  adamboche\n     3  Eric Ma\n     3  Osvaldo Martin\n     3  Sanmitra Ghosh\n     3  Saurav Shekhar\n     3  chartl\n     3  fredcallaway\n     3  Demetri\n     2  Daisuke Kondo\n     2  David Brochart\n     2  George Ho\n     2  Vaibhav Sinha\n     1  rpgoldman\n     1  Adel Tomilova\n     1  Adriaan van der Graaf\n     1  Bas Nijholt\n     1  Benjamin Wild\n     1  Brigitta Sipocz\n     1  Daniel Emaasit\n     1  Hari\n     1  Jeroen\n     1  Joseph Willard\n     1  Juan Martin Loyola\n     1  Katrin Leinweber\n     1  Lisa Martin\n     1  M. Domenzain\n     1  Matt Pitkin\n     1  Peadar Coyle\n     1  Rupal Sharma\n     1  Tom Gilliss\n     1  changjiangeng\n     1  michaelosthege\n     1  monsta\n     1  579397\n\n## PyMC3 3.6 (Dec 21 2018)\n\nThis will be the last release to support Python 2.\n\n### New features\n\n- Track the model log-likelihood as a sampler stat for NUTS and HMC samplers\n  (accessible as `trace.get_sampler_stats('model_logp')`) (#3134)\n- Add Incomplete Beta function `incomplete_beta(a, b, value)`\n- Add log CDF functions to continuous distributions: `Beta`, `Cauchy`, `ExGaussian`, `Exponential`, `Flat`, `Gumbel`, `HalfCauchy`, `HalfFlat`, `HalfNormal`, `Laplace`, `Logistic`, `LogNormal`, `Normal`, `Pareto`, `StudentT`, `Triangular`, `Uniform`, `Wald`, `Weibull`.\n- Behavior of `sample_posterior_predictive` is now to produce posterior predictive samples, in order, from all values of the `trace`. Previously, by default it would produce 1 chain worth of samples, using a random selection from the `trace` (#3212)\n- Show diagnostics for initial energy errors in HMC and NUTS.\n- PR #3273 has added the `distributions.distribution._DrawValuesContext` context\n  manager. This is used to store the values already drawn in nested `random`\n  and `draw_values` calls, enabling `draw_values` to draw samples from the\n  joint probability distribution of RVs and not the marginals. Custom\n  distributions that must call `draw_values` several times in their `random`\n  method, or that invoke many calls to other distribution's `random` methods\n  (e.g. mixtures) must do all of these calls under the same `_DrawValuesContext`\n  context manager instance. If they do not, the conditional relations between\n  the distribution's parameters could be broken, and `random` could return\n  values drawn from an incorrect distribution.\n- `Rice` distribution is now defined with either the noncentrality parameter or the shape parameter (#3287).\n\n### Maintenance\n\n- Big rewrite of documentation (#3275)\n- Fixed Triangular distribution `c` attribute handling in `random` and updated sample codes for consistency (#3225)\n- Refactor SMC and properly compute marginal likelihood (#3124)\n- Removed use of deprecated `ymin` keyword in matplotlib's `Axes.set_ylim` (#3279)\n- Fix for #3210. Now `distribution.draw_values(params)`, will draw the `params` values from their joint probability distribution and not from combinations of their marginals (Refer to PR #3273).\n- Removed dependence on pandas-datareader for retrieving Yahoo Finance data in examples (#3262)\n- Rewrote `Multinomial._random` method to better handle shape broadcasting (#3271)\n- Fixed `Rice` distribution, which inconsistently mixed two parametrizations (#3286).\n- `Rice` distribution now accepts multiple parameters and observations and is usable with NUTS (#3289).\n- `sample_posterior_predictive` no longer calls `draw_values` to initialize the shape of the ppc trace. This called could lead to `ValueError`'s when sampling the ppc from a model with `Flat` or `HalfFlat` prior distributions (Fix issue #3294).\n- Added explicit conversion to `floatX` and `int32` for the continuous and discrete probability distribution parameters (addresses issue #3223).\n\n\n### Deprecations\n\n- Renamed `sample_ppc()` and `sample_ppc_w()` to `sample_posterior_predictive()` and `sample_posterior_predictive_w()`, respectively.\n\n## PyMC3 3.5 (July 21 2018)\n\n### New features\n\n- Add documentation section on survival analysis and censored data models\n- Add `check_test_point` method to `pm.Model`\n- Add `Ordered` Transformation and `OrderedLogistic` distribution\n- Add `Chain` transformation\n- Improve error message `Mass matrix contains zeros on the diagonal. Some derivatives might always be zero` during tuning of `pm.sample`\n- Improve error message `NaN occurred in optimization.` during ADVI\n- Save and load traces without `pickle` using `pm.save_trace` and `pm.load_trace`\n- Add `Kumaraswamy` distribution\n- Add `TruncatedNormal` distribution\n- Rewrite parallel sampling of multiple chains on py3. This resolves long standing issues when transferring large traces to the main process, avoids pickling issues on UNIX, and allows us to show a progress bar for all chains. If parallel sampling is interrupted, we now return partial results.\n- Add `sample_prior_predictive` which allows for efficient sampling from the unconditioned model.\n- SMC: remove experimental warning, allow sampling using `sample`, reduce autocorrelation from final trace.\n- Add `model_to_graphviz` (which uses the optional dependency `graphviz`) to plot a directed graph of a PyMC3 model using plate notation.\n- Add beta-ELBO variational inference as in beta-VAE model (Christopher P. Burgess et al. NIPS, 2017)\n- Add `__dir__` to `SingleGroupApproximation` to improve autocompletion in interactive environments\n\n### Fixes\n\n- Fixed grammar in divergence warning, previously `There were 1 divergences ...` could be raised.\n- Fixed `KeyError` raised when only subset of variables are specified to be recorded in the trace.\n- Removed unused `repeat=None` arguments from all `random()` methods in distributions.\n- Deprecated the `sigma` argument in `MarginalSparse.marginal_likelihood` in favor of `noise`\n- Fixed unexpected behavior in `random`. Now the `random` functionality is more robust and will work better for `sample_prior` when that is implemented.\n- Fixed `scale_cost_to_minibatch` behaviour, previously this was not working and always `False`\n\n## PyMC3 3.4.1 (April 18 2018)\n\n### New features\n\n- Add `logit_p` keyword to `pm.Bernoulli`, so that users can specify the logit of the success probability. This is faster and more stable than using `p=tt.nnet.sigmoid(logit_p)`.\n- Add `random` keyword to `pm.DensityDist` thus enabling users to pass custom random method which in turn makes sampling from a `DensityDist` possible.\n- Effective sample size computation is updated. The estimation uses Geyer's initial positive sequence, which no longer truncates the autocorrelation series inaccurately. `pm.diagnostics.effective_n` now can reports N_eff>N.\n- Added `KroneckerNormal` distribution and a corresponding `MarginalKron` Gaussian Process implementation for efficient inference, along with lower-level functions such as `cartesian` and `kronecker` products.\n- Added `Coregion` covariance function.\n- Add new 'pairplot' function, for plotting scatter or hexbin matrices of sampled parameters. Optionally it can plot divergences.\n- Plots of discrete distributions in the docstrings\n- Add logitnormal distribution\n- Densityplot: add support for discrete variables\n- Fix the Binomial likelihood in `.glm.families.Binomial`, with the flexibility of specifying the `n`.\n- Add `offset` kwarg to `.glm`.\n- Changed the `compare` function to accept a dictionary of model-trace pairs instead of two separate lists of models and traces.\n- add test and support for creating multivariate mixture and mixture of mixtures\n- `distribution.draw_values`, now is also able to draw values from conditionally dependent RVs, such as autotransformed RVs (Refer to PR #2902).\n\n### Fixes\n\n- `VonMises` does not overflow for large values of kappa. i0 and i1 have been removed and we now use log_i0 to compute the logp.\n- The bandwidth for KDE plots is computed using a modified version of Scott's rule. The new version uses entropy instead of standard deviation. This works better for multimodal distributions. Functions using KDE plots has a new argument `bw` controlling the bandwidth.\n- fix PyMC3 variable is not replaced if provided in more_replacements (#2890)\n- Fix for issue #2900. For many situations, named node-inputs do not have a `random` method, while some intermediate node may have it. This meant that if the named node-input at the leaf of the graph did not have a fixed value, `theano` would try to compile it and fail to find inputs, raising a `theano.gof.fg.MissingInputError`. This was fixed by going through the theano variable's owner inputs graph, trying to get intermediate named-nodes values if the leafs had failed.\n- In `distribution.draw_values`, some named nodes could be `theano.tensor.TensorConstant`s or `theano.tensor.sharedvar.SharedVariable`s. Nevertheless, in `distribution._draw_value`, these would be passed to `distribution._compile_theano_function` as if they were `theano.tensor.TensorVariable`s. This could lead to the following exceptions `TypeError: ('Constants not allowed in param list', ...)` or `TypeError: Cannot use a shared variable (...)`. The fix was to not add `theano.tensor.TensorConstant` or `theano.tensor.sharedvar.SharedVariable` named nodes into the `givens` dict that could be used in `distribution._compile_theano_function`.\n- Exponential support changed to include zero values.\n\n### Deprecations\n\n- DIC and BPIC calculations have been removed\n- df_summary have been removed, use summary instead\n- `njobs` and `nchains` kwarg are deprecated in favor of `cores` and `chains` for `sample`\n- `lag` kwarg in `pm.stats.autocorr` and `pm.stats.autocov` is deprecated.\n\n\n## PyMC3 3.3 (January 9, 2018)\n\n### New features\n\n- Improve NUTS initialization `advi+adapt_diag_grad` and add `jitter+adapt_diag_grad` (#2643)\n- Added `MatrixNormal` class for representing vectors of multivariate normal variables\n- Implemented `HalfStudentT` distribution\n- New benchmark suite added (see http://pandas.pydata.org/speed/pymc/)\n- Generalized random seed types\n- Update loo, new improved algorithm (#2730)\n- New CSG (Constant Stochastic Gradient) approximate posterior sampling algorithm (#2544)\n- Michael Osthege added support for population-samplers and implemented differential evolution metropolis (`DEMetropolis`).  For models with correlated dimensions that can not use gradient-based samplers, the `DEMetropolis` sampler can give higher effective sampling rates. (also see [PR#2735](https://github.com/pymc-devs/pymc/pull/2735))\n- Forestplot supports multiple traces (#2736)\n- Add new plot, densityplot (#2741)\n- DIC and BPIC calculations have been deprecated\n- Refactor HMC and implemented new warning system (#2677, #2808)\n\n### Fixes\n\n- Fixed `compareplot` to use `loo` output.\n- Improved `posteriorplot` to scale fonts\n- `sample_ppc_w` now broadcasts\n- `df_summary` function renamed to `summary`\n- Add test for `model.logp_array` and `model.bijection` (#2724)\n- Fixed `sample_ppc` and `sample_ppc_w` to iterate all chains(#2633, #2748)\n- Add Bayesian R2 score (for GLMs) `stats.r2_score` (#2696) and test (#2729).\n- SMC works with transformed variables (#2755)\n- Speedup OPVI (#2759)\n- Multiple minor fixes and improvements in the docs (#2775, #2786, #2787, #2789, #2790, #2794, #2799, #2809)\n\n### Deprecations\n\n- Old (`minibatch-`)`advi` is removed (#2781)\n\n\n## PyMC3 3.2 (October 10, 2017)\n\n### New features\n\nThis version includes two major contributions from our Google Summer of Code 2017 students:\n\n* Maxim Kochurov extended and refactored the variational inference module. This primarily adds two important classes, representing operator variational inference (`OPVI`) objects and `Approximation` objects. These make it easier to extend existing `variational` classes, and to derive inference from `variational` optimizations, respectively. The `variational` module now also includes normalizing flows (`NFVI`).\n* Bill Engels added an extensive new Gaussian processes (`gp`) module. Standard GPs can be specified using either `Latent` or `Marginal` classes, depending on the nature of the underlying function. A Student-T process `TP` has been added. In order to accommodate larger datasets, approximate marginal Gaussian processes (`MarginalSparse`) have been added.\n\nDocumentation has been improved as the result of the project's monthly \"docathons\".\n\nAn experimental stochastic gradient Fisher scoring (`SGFS`) sampling step method has been added.\n\nThe API for `find_MAP` was enhanced.\n\nSMC now estimates the marginal likelihood.\n\nAdded `Logistic` and `HalfFlat` distributions to set of continuous distributions.\n\nBayesian fraction of missing information (`bfmi`) function added to `stats`.\n\nEnhancements to `compareplot` added.\n\nQuadPotential adaptation has been implemented.\n\nScript added to build and deploy documentation.\n\nMAP estimates now available for transformed and non-transformed variables.\n\nThe `Constant` variable class has been deprecated, and will be removed in 3.3.\n\nDIC and BPIC calculations have been sped up.\n\nArrays are now accepted as arguments for the `Bound` class.\n\n`random` method was added to the `Wishart` and `LKJCorr` distributions.\n\nProgress bars have been added to LOO and WAIC calculations.\n\nAll example notebooks updated to reflect changes in API since 3.1.\n\nParts of the test suite have been refactored.\n\n### Fixes\n\nFixed sampler stats error in NUTS for non-RAM backends\n\nMatplotlib is  no longer a hard dependency, making it easier to use in settings where installing Matplotlib is problematic. PyMC3 will only complain if plotting is attempted.\n\nSeveral bugs in the Gaussian process covariance were fixed.\n\nAll chains are now used to calculate WAIC and LOO.\n\nAR(1) log-likelihood function has been fixed.\n\nSlice sampler fixed to sample from 1D conditionals.\n\nSeveral docstring fixes.\n\n### Contributors\n\nThe following people contributed to this release (ordered by number of commits):\n\nMaxim Kochurov <maxim.v.kochurov@gmail.com>\nBill Engels <w.j.engels@gmail.com>\nChris Fonnesbeck <chris.fonnesbeck@vanderbilt.edu>\nJunpeng Lao <junpeng.lao@unifr.ch>\nAdrian Seyboldt <adrian.seyboldt@gmail.com>\nAustinRochford <arochford@monetate.com>\nOsvaldo Martin <aloctavodia@gmail.com>\nColin Carroll <colcarroll@gmail.com>\nHannes Vasyura-Bathke <hannes.bathke@gmx.net>\nThomas Wiecki <thomas.wiecki@gmail.com>\nmichaelosthege <thecakedev@hotmail.com>\nMarco De Nadai <me@marcodena.it>\nKyle Beauchamp <kyleabeauchamp@gmail.com>\nMassimo <mcavallaro@users.noreply.github.com>\nctm22396 <ctm22396@gmail.com>\nMax Horn <maexlich@gmail.com>\nHennadii Madan <madanh2014@gmail.com>\nHassan Naseri <h.nasseri@gmail.com>\nPeadar Coyle <peadarcoyle@googlemail.com>\nSaurav R. Tuladhar <saurav@fastmail.com>\nShashank Shekhar <shashank.f1@gmail.com>\nEric Ma <ericmjl@users.noreply.github.com>\nEd Herbst <ed.herbst@gmail.com>\ntsdlovell <dlovell@twosigma.com>\nzaxtax <zaxtax@users.noreply.github.com>\nDan Nichol <daniel.nichol@univ.ox.ac.uk>\nBenjamin Yetton <bdyetton@gmail.com>\njackhansom <jack.hansom@outlook.com>\nJack Tsai <jacksctsai@gmail.com>\nAndrés Asensio Ramos <aasensioramos@gmail.com>\n\n\n## PyMC3 3.1 (June 23, 2017)\n\n### New features\n\n* New user forum at http://discourse.pymc.io\n\n* [Gaussian Process submodule](http://pymc-devs.github.io/pymc/notebooks/GP-introduction.html)\n\n* Much improved variational inference support:\n\n  - [Add Operator Variational Inference (experimental).](http://pymc-devs.github.io/pymc/notebooks/bayesian_neural_network_opvi-advi.html)\n\n  - [Add Stein-Variational Gradient Descent as well as Amortized SVGD (experimental).](https://github.com/pymc-devs/pymc/pull/2183)\n\n  - [Add pm.Minibatch() to easily specify mini-batches.](http://pymc-devs.github.io/pymc/notebooks/bayesian_neural_network_opvi-advi.html#Minibatch-ADVI)\n\n  - Added various optimizers including ADAM.\n\n  - Stopping criterion implemented via callbacks.\n\n* sample() defaults changed: tuning is enabled for the first 500 samples which are then discarded from the trace as burn-in.\n\n* MvNormal supports Cholesky Decomposition now for increased speed and numerical stability.\n\n* Many optimizations and speed-ups.\n\n* NUTS implementation now matches current Stan implementation.\n\n* Add higher-order integrators for HMC.\n\n* [Add sampler statistics.](http://pymc-devs.github.io/pymc/notebooks/sampler-stats.html)\n\n* [Add live-trace to see samples in real-time.](http://pymc-devs.github.io/pymc/notebooks/live_sample_plots.html)\n\n* ADVI stopping criterion implemented.\n\n* Improved support for theano's floatX setting to enable GPU computations (work in progress).\n\n* MvNormal supports Cholesky Decomposition now for increased speed and numerical stability.\n\n* [Add Elliptical Slice Sampler.](http://pymc-devs.github.io/pymc/notebooks/GP-slice-sampling.html)\n\n* Added support for multidimensional minibatches\n\n* [Sampled posteriors can now be turned into priors for Bayesian updating with a new interpolated distribution.](https://github.com/pymc-devs/pymc/pull/2163)\n\n* Added `Approximation` class and the ability to convert a sampled trace into an approximation via its `Empirical` subclass.\n\n* `Model` can now be inherited from and act as a base class for user specified models (see pymc.models.linear).\n\n* Add MvGaussianRandomWalk and MvStudentTRandomWalk distributions.\n\n* GLM models do not need a left-hand variable anymore.\n\n* Refactored HMC and NUTS for better readability.\n\n* Add support for Python 3.6.\n\n### Fixes\n\n* Bound now works for discrete distributions as well.\n\n* Random sampling now returns the correct shape even for higher dimensional RVs.\n\n* Use theano Psi and GammaLn functions to enable GPU support for them.\n\n\n## PyMC3 3.0 (January 9, 2017)\n\nWe are proud and excited to release the first stable version of PyMC3, the product of more than [5 years](https://github.com/pymc-devs/pymc/commit/85c7e06b6771c0d99cbc09cb68885cda8f7785cb) of ongoing development and contributions from over 80 individuals. PyMC3 is a Python module for Bayesian modeling which focuses on modern Bayesian computational methods, primarily gradient-based (Hamiltonian) MCMC sampling and variational inference. Models are specified in Python, which allows for great flexibility. The main technological difference in PyMC3 relative to previous versions is the reliance on Theano for the computational backend, rather than on Fortran extensions.\n\n### New features\n\nSince the beta release last year, the following improvements have been implemented:\n\n* Added `variational` submodule, which features the automatic differentiation variational inference (ADVI) fitting method. Also supports mini-batch ADVI for large data sets. Much of this work was due to the efforts of Taku Yoshioka, and important guidance was provided by the Stan team (specifically Alp Kucukelbir and Daniel Lee).\n\n* Added model checking utility functions, including leave-one-out (LOO) cross-validation, BPIC, WAIC, and DIC.\n\n* Implemented posterior predictive sampling (`sample_ppc`).\n\n* Implemented auto-assignment of step methods by `sample` function.\n\n* Enhanced IPython Notebook examples, featuring more complete narratives accompanying code.\n\n* Extensive debugging of NUTS sampler.\n\n* Updated documentation to reflect changes in code since beta.\n\n* Refactored test suite for better efficiency.\n\n* Added von Mises, zero-inflated negative binomial, and Lewandowski, Kurowicka and Joe (LKJ) distributions.\n\n* Adopted `joblib` for managing parallel computation of chains.\n\n* Added contributor guidelines, contributor code of conduct and governance document.\n\n### Deprecations\n\n* Argument order of tau and sd was switched for distributions of the normal family:\n- `Normal()`\n- `LogNormal()`\n- `HalfNormal()`\n\nOld: `Normal(name, mu, tau)`\nNew: `Normal(name, mu, sd)` (supplying keyword arguments is unaffected).\n\n* `MvNormal` calling signature changed:\nOld: `MvNormal(name, mu, tau)`\nNew: `MvNormal(name, mu, cov)` (supplying keyword arguments is unaffected).\n\nWe on the PyMC3 core team would like to thank everyone for contributing and now feel that this is ready for the big time. We look forward to hearing about all the cool stuff you use PyMC3 for, and look forward to continued development on the package.\n\n### Contributors\n\nThe following authors contributed to this release:\n\nChris Fonnesbeck <chris.fonnesbeck@vanderbilt.edu>\nJohn Salvatier <jsalvatier@gmail.com>\nThomas Wiecki <thomas.wiecki@gmail.com>\nColin Carroll <colcarroll@gmail.com>\nMaxim Kochurov <maxim.v.kochurov@gmail.com>\nTaku Yoshioka <taku.yoshioka.4096@gmail.com>\nPeadar Coyle (springcoil) <peadarcoyle@googlemail.com>\nAustin Rochford <arochford@monetate.com>\nOsvaldo Martin <aloctavodia@gmail.com>\nShashank Shekhar <shashank.f1@gmail.com>\n\nIn addition, the following community members contributed to this release:\n\nA Kuz <for.akuz@gmail.com>\nA. Flaxman <abie@alum.mit.edu>\nAbraham Flaxman <abie@alum.mit.edu>\nAlexey Goldin <alexey.goldin@gmail.com>\nAnand Patil <anand.prabhakar.patil@gmail.com>\nAndrea Zonca <code@andreazonca.com>\nAndreas Klostermann <andreasklostermann@googlemail.com>\nAndres Asensio Ramos\nAndrew Clegg <andrew.clegg@pearson.com>\nAnjum48\nBenjamin Edwards <bedwards@cs.unm.edu>\nBoris Avdeev <borisaqua@gmail.com>\nBrian Naughton <briannaughton@gmail.com>\nByron Smith\nChad Heyne <chadheyne@gmail.com>\nCorey Farwell <coreyf@rwell.org>\nDavid Huard <david.huard@gmail.com>\nDavid Stück <dstuck@users.noreply.github.com>\nDeliciousHair <mshepit@gmail.com>\nDustin Tran\nEigenblutwurst <Hannes.Bathke@gmx.net>\nGideon Wulfsohn <gideon.wulfsohn@gmail.com>\nGil Raphaelli <g@raphaelli.com>\nGogs <gogitservice@gmail.com>\nIlan Man\nImri Sofer <imrisofer@gmail.com>\nJake Biesinger <jake.biesinger@gmail.com>\nJames Webber <jamestwebber@gmail.com>\nJohn McDonnell <john.v.mcdonnell@gmail.com>\nJon Sedar <jon.sedar@applied.ai>\nJordi Diaz\nJordi Warmenhoven <jordi.warmenhoven@gmail.com>\nKarlson Pfannschmidt <kiudee@mail.uni-paderborn.de>\nKyle Bishop <citizenphnix@gmail.com>\nKyle Meyer <kyle@kyleam.com>\nLin Xiao\nMack Sweeney <mackenzie.sweeney@gmail.com>\nMatthew Emmett <memmett@unc.edu>\nMichael Gallaspy <gallaspy.michael@gmail.com>\nNick <nalourie@example.com>\nOsvaldo Martin <aloctavodia@gmail.com>\nPatricio Benavente <patbenavente@gmail.com>\nRaymond Roberts\nRodrigo Benenson <rodrigo.benenson@gmail.com>\nSergei Lebedev <superbobry@gmail.com>\nSkipper Seabold <chris.fonnesbeck@vanderbilt.edu>\nThomas Kluyver <takowl@gmail.com>\nTobias Knuth <mail@tobiasknuth.de>\nVolodymyr Kazantsev\nWes McKinney <wesmckinn@gmail.com>\nZach Ploskey <zploskey@gmail.com>\nakuz <for.akuz@gmail.com>\nbrandon willard <brandonwillard@gmail.com>\ndstuck <dstuck88@gmail.com>\ningmarschuster <ingmar.schuster.linguistics@gmail.com>\njan-matthis <mail@jan-matthis.de>\njason <JasonTam22@gmailcom>\nkiudee <quietdeath@gmail.com>\nmaahnman <github@mm.maahn.de>\nmacgyver <neil.rabinowitz@merton.ox.ac.uk>\nmwibrow <mwibrow@gmail.com>\nolafSmits <o.smits@gmail.com>\npaul sorenson <paul@metrak.com>\nredst4r <redst4r@web.de>\nsanton <steven.anton@idanalytics.com>\nsgenoud <stevegenoud+github@gmail.com>\nstonebig <stonebig>\nTal Yarkoni <tyarkoni@gmail.com>\nx2apps <x2apps@yahoo.com>\nzenourn <daniel@zeno.co.nz>\n\n## PyMC3 3.0b (June 16th, 2015)\n\nProbabilistic programming allows for flexible specification of Bayesian statistical models in code. PyMC3 is a new, open-source probabilistic programmer framework with an intuitive, readable and concise, yet powerful, syntax that is close to the natural notation statisticians use to describe models. It features next-generation fitting techniques, such as the No U-Turn Sampler, that allow fitting complex models with thousands of parameters without specialized knowledge of fitting algorithms.\n\nPyMC3 has recently seen rapid development. With the addition of two new major features: automatic transforms and missing value imputation, PyMC3 has become ready for wider use. PyMC3 is now refined enough that adding features is easy, so we don't expect adding features in the future will require drastic changes. It has also become user friendly enough for a broader audience. Automatic transformations mean NUTS and find_MAP work with less effort, and friendly error messages mean its easy to diagnose problems with your model.\n\nThus, Thomas, Chris and I are pleased to announce that PyMC3 is now in Beta.\n\n### Highlights\n* Transforms now automatically applied to constrained distributions\n* Transforms now specified with a `transform=` argument on Distributions. `model.TransformedVar` is gone.\n* Transparent missing value imputation support added with MaskedArrays or pandas.DataFrame NaNs.\n* Bad default values now ignored\n* Profile theano functions using `model.profile(model.logpt)`\n\n### Contributors since 3.0a\n* A. Flaxman <abie@alum.mit.edu>\n* Andrea Zonca <code@andreazonca.com>\n* Andreas Klostermann <andreasklostermann@googlemail.com>\n* Andrew Clegg <andrew.clegg@pearson.com>\n* AustinRochford <arochford@monetate.com>\n* Benjamin Edwards <bedwards@cs.unm.edu>\n* Brian Naughton <briannaughton@gmail.com>\n* Chad Heyne <chadheyne@gmail.com>\n* Chris Fonnesbeck <fonnesbeck@gmail.com>\n* Corey Farwell <coreyf@rwell.org>\n* John Salvatier <jsalvatier@gmail.com>\n* Karlson Pfannschmidt <quietdeath@gmail.com>\n* Kyle Bishop <citizenphnix@gmail.com>\n* Kyle Meyer <kyle@kyleam.com>\n* Mack Sweeney <mackenzie.sweeney@gmail.com>\n* Osvaldo Martin <aloctavodia@gmail.com>\n* Raymond Roberts <rayvroberts@gmail.com>\n* Rodrigo Benenson <rodrigo.benenson@gmail.com>\n* Thomas Wiecki <thomas.wiecki@gmail.com>\n* Zach Ploskey <zploskey@gmail.com>\n* maahnman <github@mm.maahn.de>\n* paul sorenson <paul@metrak.com>\n* zenourn <daniel@zeno.co.nz>\n"
        },
        {
          "name": "benchmarks",
          "type": "tree",
          "content": null
        },
        {
          "name": "binder",
          "type": "tree",
          "content": null
        },
        {
          "name": "codecov.yml",
          "type": "blob",
          "size": 0.779296875,
          "content": "codecov:\n  require_ci_to_pass: yes\n  notify:\n    after_n_builds: 15  # This should be updated if number of test jobs changes\n\ncoverage:\n  precision: 2\n  round: down\n  range: \"70...100\"\n  status:\n    project:\n      default:\n        # basic\n        target: auto\n        threshold: 1%\n        base: auto\n    patch:\n      default:\n        # basic\n        target: 50%\n        threshold: 1%\n        base: auto\n\nignore:\n  - \"tests/*\"\n  - \"pymc/_version.py\"\n\ncomment:\n  layout: \"reach, diff, flags, files\"\n  behavior: default\n  require_changes: false  # if true: only post the comment if coverage changes\n  require_base: no        # [yes :: must have a base report to post]\n  require_head: yes       # [yes :: must have a head report to post]\n  branches: null          # branch names that can post comment\n"
        },
        {
          "name": "conda-envs",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "pymc",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 2.255859375,
          "content": "[build-system]\nrequires = [\"setuptools\", \"versioneer[toml]==0.29\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\nminversion = \"6.0\"\nxfail_strict = true\naddopts = [\"--color=yes\"]\n\n[tool.versioneer]\nVCS = \"git\"\nstyle = \"pep440\"\nversionfile_source = \"pymc/_version.py\"\nversionfile_build = \"pymc/_version.py\"\ntag_prefix = \"v\"\n\n[tool.mypy]\npython_version = \"3.10\"\nno_implicit_optional = false\nstrict_optional = true\nwarn_redundant_casts = false\ncheck_untyped_defs = false\ndisallow_untyped_calls = false\ndisallow_incomplete_defs = false\ndisallow_untyped_defs = false\ndisallow_untyped_decorators = false\nignore_missing_imports = true\nwarn_unused_ignores = false\n\n[tool.ruff]\nline-length = 100\ntarget-version = \"py310\"\nextend-exclude = [\"_version.py\"]\n\n[tool.ruff.format]\ndocstring-code-format = true\n\n[tool.ruff.lint]\nselect = [\"C4\", \"D\", \"E\", \"F\", \"I\", \"UP\", \"W\", \"RUF\", \"T20\", \"TID\"]\nignore = [\n  \"E501\",\n  \"F841\", # Local variable name is assigned to but never used\n  \"RUF001\", # String contains ambiguous character (such as Greek letters)\n  \"RUF002\", # Docstring contains ambiguous character (such as Greek letters)\n  \"RUF012\", # Mutable class attributes should be annotated with `typing.ClassVar`\n  \"D100\",  # Missing docstring in public module\n  \"D101\",  # Missing docstring in public class\n  \"D102\",  # Missing docstring in public method\n  \"D103\",  # Missing docstring in public function\n  \"D105\",  # Missing docstring in magic method\n]\n\n[tool.ruff.lint.pydocstyle]\nconvention = \"numpy\"\n\n[tool.ruff.lint.isort]\nlines-between-types = 1\n\n[tool.ruff.lint.extend-per-file-ignores]\n\"__init__.py\" = [\n  \"F401\", # Module imported but unused\n  \"F403\", # 'from module import *' used; unable to detect undefined names\n]\n\"docs/source/*\" = [\"D\"]\n\"pymc/__init__.py\" = [\n  \"E402\", # Module level import not at top of file\n]\n\"pymc/stats/__init__.py\" = [\n  \"E402\", # Module level import not at top of file\n]\n\"pymc/logprob/__init__.py\" = [\n  \"I001\", # Import block is un-sorted or un-formatted\n]\n\"tests/*\" = [\"D\"]\n\"scripts/run_mypy.py\" = [\n  \"T201\", # No print statements\n]\n\"*.ipynb\" = [\n  \"T201\", # No print statements\n]\n\n[tool.coverage.report]\nexclude_lines = [\n  \"pragma: nocover\",\n  \"raise NotImplementedError\",\n  \"if TYPE_CHECKING:\",\n]\n\n[tool.coverage.run]\nomit = [\"*examples*\"]\n"
        },
        {
          "name": "requirements-dev.txt",
          "type": "blob",
          "size": 0.6826171875,
          "content": "# This file is auto-generated by scripts/generate_pip_deps_from_conda.py, do not modify.\n# See that file for comments about the need/usage of each dependency.\n\narviz>=0.13.0\ncachetools>=4.2.1\ncloudpickle\ngit+https://github.com/pymc-devs/pymc-sphinx-theme\nh5py>=2.7\nipython>=7.16\njupyter-sphinx\nmcbackend>=0.4.0\nmypy==1.5.1\nmyst-nb<=1.0.0\nnumdifftools>=0.9.40\nnumpy>=1.25.0\nnumpydoc\npandas>=0.24.0\npolyagamma\npre-commit>=2.8.0\npytensor>=2.26.2,<2.27\npytest-cov>=2.5\npytest>=3.0\nrich>=13.7.1\nscipy>=1.4.1\nsphinx-copybutton\nsphinx-design\nsphinx-notfound-page\nsphinx-remove-toctrees\nsphinx>=1.5\nsphinxext-rediraffe\nthreadpoolctl>=3.1.0\ntypes-cachetools\ntyping-extensions>=3.7.4\nwatermark\nzarr>=2.5.0,<3\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.1708984375,
          "content": "arviz>=0.13.0\ncachetools>=4.2.1\ncloudpickle\nnumpy>=1.25.0\npandas>=0.24.0\npytensor>=2.26.1,<2.27\nrich>=13.7.1\nscipy>=1.4.1\nthreadpoolctl>=3.1.0,<4.0.0\ntyping-extensions>=3.7.4\n"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 2.5927734375,
          "content": "#   Copyright 2024 The PyMC Developers\n#\n#   Licensed under the Apache License, Version 2.0 (the \"License\");\n#   you may not use this file except in compliance with the License.\n#   You may obtain a copy of the License at\n#\n#       http://www.apache.org/licenses/LICENSE-2.0\n#\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\n\n\nfrom codecs import open\nfrom os.path import dirname, join, realpath\n\nimport versioneer\n\nfrom setuptools import find_packages, setup\n\nDESCRIPTION = \"Probabilistic Programming in Python: Bayesian Modeling and Probabilistic Machine Learning with PyTensor\"\nAUTHOR = \"PyMC Developers\"\nAUTHOR_EMAIL = \"pymc.devs@gmail.com\"\nURL = \"http://github.com/pymc-devs/pymc\"\nLICENSE = \"Apache License, Version 2.0\"\n\nclassifiers = [\n    \"Development Status :: 5 - Production/Stable\",\n    \"Programming Language :: Python\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 3.10\",\n    \"Programming Language :: Python :: 3.11\",\n    \"Programming Language :: Python :: 3.12\",\n    \"License :: OSI Approved :: Apache Software License\",\n    \"Intended Audience :: Science/Research\",\n    \"Topic :: Scientific/Engineering\",\n    \"Topic :: Scientific/Engineering :: Mathematics\",\n    \"Operating System :: OS Independent\",\n]\n\nPROJECT_ROOT = dirname(realpath(__file__))\n\n# Get the long description from the README file\nwith open(join(PROJECT_ROOT, \"README.rst\"), encoding=\"utf-8\") as buff:\n    LONG_DESCRIPTION = buff.read()\n\nREQUIREMENTS_FILE = join(PROJECT_ROOT, \"requirements.txt\")\n\nwith open(REQUIREMENTS_FILE) as f:\n    install_reqs = f.read().splitlines()\n\ntest_reqs = [\"pytest\", \"pytest-cov\"]\n\nif __name__ == \"__main__\":\n    setup(\n        name=\"pymc\",\n        version=versioneer.get_version(),\n        cmdclass=versioneer.get_cmdclass(),\n        maintainer=AUTHOR,\n        maintainer_email=AUTHOR_EMAIL,\n        description=DESCRIPTION,\n        license=LICENSE,\n        url=URL,\n        long_description=LONG_DESCRIPTION,\n        long_description_content_type=\"text/x-rst\",\n        packages=find_packages(exclude=[\"tests*\"]),\n        # because of an upload-size limit by PyPI, we're temporarily removing docs from the tarball.\n        # Also see MANIFEST.in\n        # package_data={'docs': ['*']},\n        classifiers=classifiers,\n        python_requires=\">=3.10\",\n        install_requires=install_reqs,\n        tests_require=test_reqs,\n    )\n"
        },
        {
          "name": "setupegg.py",
          "type": "blob",
          "size": 0.73046875,
          "content": "#   Copyright 2024 The PyMC Developers\n#\n#   Licensed under the Apache License, Version 2.0 (the \"License\");\n#   you may not use this file except in compliance with the License.\n#   You may obtain a copy of the License at\n#\n#       http://www.apache.org/licenses/LICENSE-2.0\n#\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\n\n#!/usr/bin/env python\n\"\"\"A setup.py script to use setuptools, which gives egg goodness, etc.\"\"\"\n\nwith open(\"setup.py\") as s:\n    exec(s.read())\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}