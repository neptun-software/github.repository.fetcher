{
  "metadata": {
    "timestamp": 1736560572947,
    "page": 188,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE5MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "FlagOpen/FlagEmbedding",
      "stars": 8195,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.921875,
          "content": "*.memmap\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n.idea/\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\npip-wheel-metadata/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\n../docs/_build/\n../docs/build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n.python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\nUntitled.ipynb\ntry.py\nupdate_model_card.py\nmodel_card.md\npic.py\npic2.py\n\n# Pyre type checker\n.pyre/\n\n# MacOS associated\n.DS_Store\n\n# results\nen_results\nzh_results"
        },
        {
          "name": "FlagEmbedding",
          "type": "tree",
          "content": null
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0400390625,
          "content": "MIT License\n\nCopyright (c) 2022 staoxiao\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "Manifest.in",
          "type": "blob",
          "size": 0.314453125,
          "content": "# Include the entire directory and its contents\nrecursive-include FlagEmbedding/FlagEmbedding/visual/eva_clip *\n\n# Include the specific file at the root level\ninclude bpe_simple_vocab_16e6.txt.gz\n\n# Include all JSON files inside the specified directory\nrecursive-include FlagEmbedding/visual/eva_clip/model_configs *.json\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 21.7041015625,
          "content": "[<img src=\"./imgs/FlagOpen.png\">](https://flagopen.baai.ac.cn/)\n\n<h1 align=\"center\">âš¡ï¸BGE: One-Stop Retrieval Toolkit For Search and RAG</h1>\n\n![bge_logo](./imgs/bge_logo.jpg)\n\n<p align=\"center\">\n    <a href=\"https://huggingface.co/collections/BAAI/bge-66797a74476eb1f085c7446d\">\n        <img alt=\"Build\" src=\"https://img.shields.io/badge/BGE_series-ğŸ¤—-yellow\">\n    </a>\n    <a href=\"https://github.com/FlagOpen/FlagEmbedding\">\n            <img alt=\"Build\" src=\"https://img.shields.io/badge/Contribution-Welcome-blue\">\n    </a>\n    <a href=\"https://github.com/FlagOpen/FlagEmbedding/blob/master/LICENSE\">\n        <img alt=\"License\" src=\"https://img.shields.io/badge/LICENSE-MIT-green\">\n    </a>\n    <a href=\"https://huggingface.co/C-MTEB\">\n        <img alt=\"Build\" src=\"https://img.shields.io/badge/C_MTEB-ğŸ¤—-yellow\">\n    </a>\n    <a href=\"https://github.com/FlagOpen/FlagEmbedding/tree/master/research/baai_general_embedding\">\n        <img alt=\"Build\" src=\"https://img.shields.io/badge/FlagEmbedding-1.3.0-red\">\n    </a>\n</p>\n<h4 align=\"center\">\n    <p>\n        <a href=#news>News</a> |\n        <a href=#installation>Installation</a> |\n        <a href=#quick-start>Quick Start</a> |\n        <a href=#community>Community</a> |\n        <a href=\"https://github.com/FlagOpen/FlagEmbedding/tree/master/research\">Projects</a> |\n        <a href=#model-list>Model List</a> |\n        <a href=\"#contributors\">Contributor</a> |\n        <a href=\"#citation\">Citation</a> |\n        <a href=\"#license\">License</a> \n    <p>\n</h4>\n\n\n[English](README.md) | [ä¸­æ–‡](https://github.com/FlagOpen/FlagEmbedding/blob/master/README_zh.md)\n\n\n\nBGE (BAAI General Embedding) focuses on retrieval-augmented LLMs, consisting of the following projects currently:\n\n![projects](./imgs/projects.png)\n\n- **Inference**: [Embedder](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/inference/embedder), [Reranker](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/inference/reranker)\n- **Finetune**: [Embedder](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune/embedder), [Reranker](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune/reranker)\n- **[Evaluation](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/evaluation)**\n- **[Dataset](https://github.com/FlagOpen/FlagEmbedding/tree/master/dataset)**\n- **[Tutorials](https://github.com/FlagOpen/FlagEmbedding/tree/master/Tutorials)**\n- **[research](https://github.com/FlagOpen/FlagEmbedding/tree/master/research)**\n\n## News\n\n- 05/12/2024: :book: We built the [BGE documentation](www.bge-model.com) for centralized BGE information and materials!\n- 10/29/2024: :earth_asia: We created WeChat group for BGE. Scan the [QR code](./imgs/BGE_WeChat_Group.png) to join the group chat! To get the first hand message about our updates and new release, or having any questions or ideas, join us now!\n- <img src=\"./imgs/BGE_WeChat_Group.png\" alt=\"bge_wechat_group\" class=\"center\" width=\"200\">\n\n- 10/22/2024:  :fire: We release another interesting model: [OmniGen](https://github.com/VectorSpaceLab/OmniGen), which is a unified image generation model supporting various tasks. OmniGen can accomplish complex image generation tasks without the need for additional plugins like ControlNet, IP-Adapter, or auxiliary models such as pose detection and face detection.\n- 9/10/2024: Introducing **MemoRAG**, a step forward towards RAG 2.0 on top of memory-inspired knowledge discovery (repo: https://github.com/qhjqhj00/MemoRAG, paper: https://arxiv.org/pdf/2409.05591v1) :fire:\n- 9/2/2024: Start to maintain the [tutorials](./Tutorials/). The contents within will be actively updated and eariched, stay tuned! :books:\n- 7/26/2024: Release a new embedding model [bge-en-icl](https://huggingface.co/BAAI/bge-en-icl), an embedding model that incorporates in-context learning capabilities, which, by providing task-relevant query-response examples, can encode semantically richer queries, further enhancing the semantic representation ability of the embeddings. :fire:\n- 7/26/2024: Release a new embedding model [bge-multilingual-gemma2](https://huggingface.co/BAAI/bge-multilingual-gemma2), a multilingual embedding model based on gemma-2-9b, which supports multiple languages and diverse downstream tasks, achieving new SOTA on multilingual benchmarks (MIRACL, MTEB-fr, and MTEB-pl). :fire:\n- 7/26/2024: Release a new lightweight reranker [bge-reranker-v2.5-gemma2-lightweight](https://huggingface.co/BAAI/bge-reranker-v2.5-gemma2-lightweight), a lightweight reranker based on gemma-2-9b, which supports token compression and layerwise lightweight operations, can still ensure good performance while saving a significant amount of resources. :fire:\n\n<details>\n  <summary>More</summary>\n<!-- ### More -->\n\n- 6/7/2024: Release a new benchmark [MLVU](https://github.com/JUNJIE99/MLVU), the first comprehensive benchmark specifically designed for long video understanding. MLVU features an extensive range of video durations, a diverse collection of video sources, and a set of evaluation tasks uniquely tailored for long-form video understanding. :fire:\n- 5/21/2024: Release a new benchmark [AIR-Bench](https://github.com/AIR-Bench/AIR-Bench) together with Jina AI, Zilliz, HuggingFace, and other partners. AIR-Bench focuses on a fair out-of-distribution evaluation for Neural IR & RAG. It generates the synthetic data for benchmarking w.r.t. diverse domains and languages. It is dynamic and will be updated on regular basis. [Leaderboard](https://huggingface.co/spaces/AIR-Bench/leaderboard) :fire:\n- 4/30/2024: Release [Llama-3-8B-Instruct-80K-QLoRA](https://huggingface.co/namespace-Pt/Llama-3-8B-Instruct-80K-QLoRA), extending the context length of Llama-3-8B-Instruct from 8K to 80K via QLoRA training on a few synthesized long-context data. The model achieves remarkable performance on various long-context benchmarks. [Code](https://github.com/FlagOpen/FlagEmbedding/tree/master/research/Long_LLM/longllm_qlora) :fire:\n- 3/18/2024: Release new [rerankers](https://github.com/FlagOpen/FlagEmbedding/tree/master/research/llm_reranker), built upon powerful M3 and LLM (GEMMA and MiniCPM, not so large actually :smiley:) backbones, supporitng multi-lingual processing and larger inputs, massive improvements of ranking performances on BEIR, C-MTEB/Retrieval, MIRACL, LlamaIndex Evaluation :fire:\n- 3/18/2024: Release [Visualized-BGE](https://github.com/FlagOpen/FlagEmbedding/tree/master/research/visual_bge), equipping BGE with visual capabilities. Visualized-BGE can be utilized to generate embeddings for hybrid image-text data. :fire:\n- 1/30/2024: Release **BGE-M3**, a new member to BGE model series! M3 stands for **M**ulti-linguality (100+ languages), **M**ulti-granularities (input length up to 8192), **M**ulti-Functionality (unification of dense, lexical, multi-vec/colbert retrieval). \nIt is the first embedding model which supports all three retrieval methods, achieving new SOTA on multi-lingual (MIRACL) and cross-lingual (MKQA) benchmarks.\n[Technical Report](https://arxiv.org/pdf/2402.03216.pdf) and [Code](https://github.com/FlagOpen/FlagEmbedding/tree/master/research/BGE_M3). :fire:\n- 1/9/2024: Release [Activation-Beacon](https://github.com/FlagOpen/FlagEmbedding/tree/master/research/Long_LLM/activation_beacon), an effective, efficient, compatible, and low-cost (training) method to extend the context length of LLM. [Technical Report](https://arxiv.org/abs/2401.03462) \n- 12/24/2023: Release **LLaRA**, a LLaMA-7B based dense retriever, leading to state-of-the-art performances on MS MARCO and BEIR. Model and code will be open-sourced. Please stay tuned. [Technical Report](https://arxiv.org/abs/2312.15503) and [Code](https://github.com/FlagOpen/FlagEmbedding/tree/master/research/LLARA)\n- 11/23/2023: Release [LM-Cocktail](https://github.com/FlagOpen/FlagEmbedding/tree/master/research/LM_Cocktail), a method to maintain general capabilities during fine-tuning by merging multiple language models. [Technical Report](https://arxiv.org/abs/2311.13534) \n- 10/12/2023: Release [LLM-Embedder](https://github.com/FlagOpen/FlagEmbedding/tree/master/research/llm_embedder), a unified embedding model to support diverse retrieval augmentation needs for LLMs. [Technical Report](https://arxiv.org/pdf/2310.07554.pdf)\n- 09/15/2023: The [technical report](https://arxiv.org/pdf/2309.07597.pdf) of BGE has been released \n- 09/15/2023: The [massive training data](https://data.baai.ac.cn/details/BAAI-MTP) of BGE has been released \n- 09/12/2023: New models: \n    - **New reranker model**: release cross-encoder models `BAAI/bge-reranker-base` and `BAAI/bge-reranker-large`, which are more powerful than embedding model. We recommend to use/fine-tune them to re-rank top-k documents returned by embedding models. \n    - **update embedding model**: release `bge-*-v1.5` embedding model to alleviate the issue of the similarity distribution, and enhance its retrieval ability without instruction.\n- 09/07/2023: Update [fine-tune code](https://github.com/FlagOpen/FlagEmbedding/tree/master/research/baai_general_embedding): Add script to mine hard negatives and support adding instruction during fine-tuning. \n- 08/09/2023: BGE Models are integrated into **Langchain**, you can use it like [this](#using-langchain); C-MTEB **leaderboard** is [available](https://huggingface.co/spaces/mteb/leaderboard).  \n- 08/05/2023: Release base-scale and small-scale models, **best performance among the models of the same size ğŸ¤—**  \n- 08/02/2023: Release `bge-large-*`(short for BAAI General Embedding) Models, **rank 1st on MTEB and C-MTEB benchmark!** :tada: :tada:   \n- 08/01/2023: We release the [Chinese Massive Text Embedding Benchmark](https://github.com/FlagOpen/FlagEmbedding/tree/master/research/C_MTEB) (**C-MTEB**), consisting of 31 test dataset.  \n  \n\n</details>\n\n## Installation\n### Using pip:\nIf you do not want to finetune the models, you can install the package without the finetune dependency:\n```\npip install -U FlagEmbedding\n```\nIf you want to finetune the models, you can install the package with the finetune dependency:\n```\npip install -U FlagEmbedding[finetune]\n```\n### Install from sources:\n\nClone the repository and install\n```\ngit clone https://github.com/FlagOpen/FlagEmbedding.git\ncd FlagEmbedding\n# If you do not need to finetune the models, you can install the package without the finetune dependency:\npip install  .\n# If you want to finetune the models, install the package with the finetune dependency:\n# pip install  .[finetune]\n```\nFor development in editable mode:\n```\n# If you do not need to finetune the models, you can install the package without the finetune dependency:\npip install -e .\n# If you want to finetune the models, install the package with the finetune dependency:\n# pip install -e .[finetune]\n```\n\n## Quick Start\nFirst, load one of the BGE embedding model:\n```\nfrom FlagEmbedding import FlagAutoModel\n\nmodel = FlagAutoModel.from_finetuned('BAAI/bge-base-en-v1.5',\n                                      query_instruction_for_retrieval=\"Represent this sentence for searching relevant passages:\",\n                                      use_fp16=True)\n```\nThen, feed some sentences to the model and get their embeddings:\n```\nsentences_1 = [\"I love NLP\", \"I love machine learning\"]\nsentences_2 = [\"I love BGE\", \"I love text retrieval\"]\nembeddings_1 = model.encode(sentences_1)\nembeddings_2 = model.encode(sentences_2)\n```\nOnce we get the embeddings, we can compute similarity by inner product:\n```\nsimilarity = embeddings_1 @ embeddings_2.T\nprint(similarity)\n```\n\nFor more details, you can refer to [embedder inference](./examples/inference/embedder), [reranker inference](./examples/inference/reranker), [embedder finetune](./examples/finetune/embedder), [reranker fintune](./examples/finetune/reranker), [evaluation](./examples/evaluation).\n\nIf you're unfamiliar with any of related concepts, please check out the [tutorial](./Tutorials/). If it's not there, let us know.\n\nFor more interesting topics related to BGE, take a look at [research](./research).\n\n## Community\n\nWe are actively maintaining the community of BGE and FlagEmbedding. Let us know if you have any suggessions or ideas!\n\nCurrently we are updating the [tutorials](./Tutorials/), we aim to create a comprehensive and detailed tutorial for beginners on text retrieval and RAG. Stay tuned!\n\nThe following contents are releasing in the upcoming weeks:\n\n- Evaluation\n- BGE-EN-ICL\n\n<details>\n  <summary>The whole tutorial roadmap</summary>\n    <img src=\"./Tutorials/tutorial_map.png\"/>\n</details>\n\n## Model List\n\n`bge` is short for `BAAI general embedding`.\n\n| Model                                                                     | Language |                                                             Description                                                             |                                query instruction for retrieval                                 |\n|:--------------------------------------------------------------------------|:--------:|:-----------------------------------------------------------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------------------:|\n| [BAAI/bge-en-icl](https://huggingface.co/BAAI/bge-en-icl) | English | A LLM-based embedding model with in-context learning capabilities, which can fully leverage the model's potential based on a few shot examples | Provide instructions and few-shot examples freely based on the given task. |\n| [BAAI/bge-multilingual-gemma2](https://huggingface.co/BAAI/bge-multilingual-gemma2) |    Multilingual     | A LLM-based multilingual embedding model, trained on a diverse range of languages and tasks. |        Provide instructions based on the given task.         |\n| [BAAI/bge-m3](https://huggingface.co/BAAI/bge-m3)                   |    Multilingual     | Multi-Functionality(dense retrieval, sparse retrieval, multi-vector(colbert)), Multi-Linguality, and Multi-Granularity(8192 tokens) |  |\n| [LM-Cocktail](https://huggingface.co/Shitao)                   |   English |                     fine-tuned models (Llama and BGE) which can be used to reproduce the results of LM-Cocktail                     |  |\n| [BAAI/llm-embedder](https://huggingface.co/BAAI/llm-embedder)             |   English |                         a unified embedding model to support diverse retrieval augmentation needs for LLMs                          | See [README](https://github.com/FlagOpen/FlagEmbedding/tree/master/research/llm_embedder) |\n| [BAAI/bge-reranker-v2-m3](https://huggingface.co/BAAI/bge-reranker-v2-m3) | Multilingual | a lightweight cross-encoder model, possesses strong multilingual capabilities, easy to deploy, with fast inference. |  |\n| [BAAI/bge-reranker-v2-gemma](https://huggingface.co/BAAI/bge-reranker-v2-gemma) | Multilingual | a cross-encoder model which is suitable for multilingual contexts, performs well in both English proficiency and multilingual capabilities. |  |\n| [BAAI/bge-reranker-v2-minicpm-layerwise](https://huggingface.co/BAAI/bge-reranker-v2-minicpm-layerwise) | Multilingual | a cross-encoder model which is suitable for multilingual contexts, performs well in both English and Chinese proficiency, allows freedom to select layers for output, facilitating accelerated inference. |  |\n| [BAAI/bge-reranker-v2.5-gemma2-lightweight](https://huggingface.co/BAAI/bge-reranker-v2.5-gemma2-lightweight) | Multilingual | a cross-encoder model which is suitable for multilingual contexts, performs well in both English and Chinese proficiency, allows freedom to select layers, compress ratio and compress layers for output, facilitating accelerated inference. |  |\n| [BAAI/bge-reranker-large](https://huggingface.co/BAAI/bge-reranker-large) |   Chinese and English |                                   a cross-encoder model which is more accurate but less efficient                                   |                                                                                                |\n| [BAAI/bge-reranker-base](https://huggingface.co/BAAI/bge-reranker-base)   |   Chinese and English |                                   a cross-encoder model which is more accurate but less efficient                                   |                                                                                                |\n| [BAAI/bge-large-en-v1.5](https://huggingface.co/BAAI/bge-large-en-v1.5)   |   English |                                      version 1.5 with more reasonable similarity distribution                                       |                  `Represent this sentence for searching relevant passages: `                   |\n| [BAAI/bge-base-en-v1.5](https://huggingface.co/BAAI/bge-base-en-v1.5)     |   English |                                      version 1.5 with more reasonable similarity distribution                                       |                  `Represent this sentence for searching relevant passages: `                   |\n| [BAAI/bge-small-en-v1.5](https://huggingface.co/BAAI/bge-small-en-v1.5)   |   English |                                      version 1.5 with more reasonable similarity distribution                                       |                  `Represent this sentence for searching relevant passages: `                   |\n| [BAAI/bge-large-zh-v1.5](https://huggingface.co/BAAI/bge-large-zh-v1.5)   |   Chinese |                                      version 1.5 with more reasonable similarity distribution                                       |                                     `ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š`                                      |\n| [BAAI/bge-base-zh-v1.5](https://huggingface.co/BAAI/bge-base-zh-v1.5)     |   Chinese |                                      version 1.5 with more reasonable similarity distribution                                       |                                     `ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š`                                      |\n| [BAAI/bge-small-zh-v1.5](https://huggingface.co/BAAI/bge-small-zh-v1.5)   |   Chinese |                                      version 1.5 with more reasonable similarity distribution                                       |                                     `ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š`                                      |\n| [BAAI/bge-large-en](https://huggingface.co/BAAI/bge-large-en)             |   English |                                             Embedding Model which map text into vector                                              |                  `Represent this sentence for searching relevant passages: `                   |\n| [BAAI/bge-base-en](https://huggingface.co/BAAI/bge-base-en)               |   English |                                    a base-scale model but with similar ability to `bge-large-en`                                    |                  `Represent this sentence for searching relevant passages: `                   |\n| [BAAI/bge-small-en](https://huggingface.co/BAAI/bge-small-en)             |   English |                                        a small-scale model but with competitive performance                                         |                  `Represent this sentence for searching relevant passages: `                   |\n| [BAAI/bge-large-zh](https://huggingface.co/BAAI/bge-large-zh)             |   Chinese |                                             Embedding Model which map text into vector                                              |                                     `ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š`                                      |\n| [BAAI/bge-base-zh](https://huggingface.co/BAAI/bge-base-zh)               |   Chinese |                                    a base-scale model but with similar ability to `bge-large-zh`                                    |                                     `ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š`                                      |\n| [BAAI/bge-small-zh](https://huggingface.co/BAAI/bge-small-zh)             |   Chinese |                                        a small-scale model but with competitive performance                                         |                                     `ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š`                                      |\n\n\n\n\n### Contributors:\nThank all our contributors for their efforts and warmly welcome new members to join in!\n\n<a href=\"https://github.com/FlagOpen/FlagEmbedding/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=FlagOpen/FlagEmbedding\" />\n</a>\n\n\n\n\n## Citation\n\nIf you find this repository useful, please consider giving a star :star: and citation\n\n```\n@misc{bge_m3,\n  title={BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation},\n  author={Chen, Jianlv and Xiao, Shitao and Zhang, Peitian and Luo, Kun and Lian, Defu and Liu, Zheng},\n  year={2023},\n  eprint={2309.07597},\n  archivePrefix={arXiv},\n  primaryClass={cs.CL}\n}\n\n@misc{cocktail,\n      title={LM-Cocktail: Resilient Tuning of Language Models via Model Merging}, \n      author={Shitao Xiao and Zheng Liu and Peitian Zhang and Xingrun Xing},\n      year={2023},\n      eprint={2311.13534},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n\n@misc{llm_embedder,\n      title={Retrieve Anything To Augment Large Language Models}, \n      author={Peitian Zhang and Shitao Xiao and Zheng Liu and Zhicheng Dou and Jian-Yun Nie},\n      year={2023},\n      eprint={2310.07554},\n      archivePrefix={arXiv},\n      primaryClass={cs.IR}\n}\n\n@misc{bge_embedding,\n      title={C-Pack: Packaged Resources To Advance General Chinese Embedding}, \n      author={Shitao Xiao and Zheng Liu and Peitian Zhang and Niklas Muennighoff},\n      year={2023},\n      eprint={2309.07597},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n```\n\n## License\nFlagEmbedding is licensed under the [MIT License](https://github.com/FlagOpen/FlagEmbedding/blob/master/LICENSE). \n\n"
        },
        {
          "name": "README_zh.md",
          "type": "blob",
          "size": 20.3642578125,
          "content": "![bge_logo](./imgs/bge_logo.jpg)\n\n<h1 align=\"center\">âš¡ï¸BGE: One-Stop Retrieval Toolkit For Search and RAG</h1>\n<p align=\"center\">\n    <a href=\"https://huggingface.co/collections/BAAI/bge-66797a74476eb1f085c7446d\">\n        <img alt=\"Build\" src=\"https://img.shields.io/badge/BGE_series-ğŸ¤—-yellow\">\n    </a>\n    <a href=\"https://github.com/FlagOpen/FlagEmbedding\">\n            <img alt=\"Build\" src=\"https://img.shields.io/badge/Contribution-Welcome-blue\">\n    </a>\n    <a href=\"https://github.com/FlagOpen/FlagEmbedding/blob/master/LICENSE\">\n        <img alt=\"License\" src=\"https://img.shields.io/badge/LICENSE-MIT-green\">\n    </a>\n    <a href=\"https://huggingface.co/C-MTEB\">\n        <img alt=\"Build\" src=\"https://img.shields.io/badge/C_MTEB-ğŸ¤—-yellow\">\n    </a>\n    <a href=\"https://github.com/FlagOpen/FlagEmbedding/tree/master/research/baai_general_embedding\">\n        <img alt=\"Build\" src=\"https://img.shields.io/badge/FlagEmbedding-1.1-red\">\n    </a>\n</p>\n\n\n<h4 align=\"center\">\n    <p>\n        <a href=#æ›´æ–°>æ›´æ–°</a> |\n        <a href=#å®‰è£…>å®‰è£…</a> |\n        <a href=#å¿«é€Ÿå¼€å§‹>å¿«é€Ÿå¼€å§‹</a> |\n        <a href=#ç¤¾åŒº>ç¤¾åŒº</a> |\n        <a href=\"https://github.com/FlagOpen/FlagEmbedding/tree/master/research\">é¡¹ç›®</a> |\n        <a href=\"#æ¨¡å‹åˆ—è¡¨\">æ¨¡å‹åˆ—è¡¨</a> |\n        <a href=#è´¡çŒ®è€…>è´¡çŒ®è€…</a> |\n        <a href=\"#citation\">Citation</a> |\n        <a href=\"#license\">License</a> \n    <p>\n</h4>\n\n[English](https://github.com/FlagOpen/FlagEmbedding/blob/master/README.md) | [ä¸­æ–‡](https://github.com/FlagOpen/FlagEmbedding/blob/master/README_zh.md)\n\nBGE (BAAI General Embedding) ä¸“æ³¨äºæ£€ç´¢å¢å¼ºllmé¢†åŸŸï¼Œç›®å‰åŒ…æ‹¬ä»¥ä¸‹é¡¹ç›®:\n\n![projects](./imgs/projects.png)\n\n- **æ¨ç†**: [Embedder](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/inference/embedder), [Reranker](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/inference/reranker)\n- **å¾®è°ƒ**: [Embedder](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune/embedder), [Reranker](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune/reranker)\n- **[è¯„ä¼°](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/evaluation)**\n- **[æ•°æ®é›†](https://github.com/FlagOpen/FlagEmbedding/tree/master/dataset)**\n- **[æ•™ç¨‹](https://github.com/FlagOpen/FlagEmbedding/tree/master/Tutorials)**\n- **[ç ”ç©¶](https://github.com/FlagOpen/FlagEmbedding/tree/master/research)**\n\n## æ›´æ–°\n\n- 10/29/2024: :earth_asia: æˆ‘ä»¬å»ºç«‹äº†[BGEæŠ€æœ¯äº¤æµç¾¤](./BGE_WeChat_Group.png)ï¼Œæ¬¢è¿æ‰«ç å…¥ç¾¤ï¼\n- <img src=\"./imgs/BGE_WeChat_Group.png\" alt=\"bge_wechat_group\" class=\"center\" width=\"200\">\n- 10/22/2024ï¼šæˆ‘ä»¬å‘å¸ƒäº†æ–°çš„æ¨¡å‹ï¼š[OmniGen](https://github.com/VectorSpaceLab/OmniGen)ï¼Œè¿™æ˜¯ä¸€ä¸ªæ”¯æŒå„ç§ä»»åŠ¡çš„ç»Ÿä¸€å›¾åƒç”Ÿæˆæ¨¡å‹ã€‚OmniGenå¯ä»¥åœ¨ä¸éœ€è¦é¢å¤–æ’ä»¶ï¼ˆå¦‚ControlNetã€IP-Adapterï¼‰æˆ–è¾…åŠ©æ¨¡å‹ï¼ˆå¦‚å§¿æ€æ£€æµ‹å’Œäººè„¸æ£€æµ‹ï¼‰çš„æƒ…å†µä¸‹å®Œæˆå¤æ‚çš„å›¾åƒç”Ÿæˆä»»åŠ¡ã€‚ :fire:\n- 9/10/2024ï¼šæˆ‘ä»¬æ¨å‡ºäº†**MemoRAG**ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºè®°å¿†å¯å‘çš„çŸ¥è¯†å‘ç°æŠ€æœ¯ï¼Œæ˜¯è¿ˆå‘ RAG 2.0 çš„å…³é”®ä¸€æ­¥ï¼ˆä»“åº“ï¼šhttps://github.com/qhjqhj00/MemoRAGï¼Œè®ºæ–‡ï¼šhttps://arxiv.org/pdf/2409.05591v1ï¼‰ :fire:\n- 9/2/2024: å¼€å§‹ç»´æŠ¤æ›´æ–°[æ•™ç¨‹](./Tutorials/)ï¼Œæ•™ç¨‹æ–‡ä»¶å¤¹ä¸­çš„å†…å®¹ä¼šåœ¨æœªæ¥ä¸æ–­ä¸°å¯Œï¼Œæ¬¢è¿æŒç»­å…³æ³¨ï¼ :books:\n- 7/26/2024ï¼šå‘å¸ƒ[bge-en-icl](https://huggingface.co/BAAI/bge-en-icl)ã€‚è¿™æ˜¯ä¸€ä¸ªç»“åˆäº†ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›çš„æ–‡æœ¬æ£€ç´¢æ¨¡å‹ï¼Œé€šè¿‡æä¾›ä¸ä»»åŠ¡ç›¸å…³çš„æŸ¥è¯¢-å›ç­”ç¤ºä¾‹ï¼Œå¯ä»¥ç¼–ç è¯­ä¹‰æ›´ä¸°å¯Œçš„æŸ¥è¯¢ï¼Œè¿›ä¸€æ­¥å¢å¼ºåµŒå…¥çš„è¯­ä¹‰è¡¨å¾èƒ½åŠ›ã€‚ :fire:\n- 7/26/2024: å‘å¸ƒ[bge-multilingual-gemma2](https://huggingface.co/BAAI/bge-multilingual-gemma2)ã€‚è¿™æ˜¯ä¸€ä¸ªåŸºäºgemma-2-9bçš„å¤šè¯­è¨€æ–‡æœ¬å‘é‡æ¨¡å‹ï¼ŒåŒæ—¶æ”¯æŒå¤šç§è¯­è¨€å’Œå¤šæ ·çš„ä¸‹æ¸¸ä»»åŠ¡ï¼Œåœ¨å¤šè¯­è¨€æ£€ç´¢æ•°æ®é›† MIRACL, MTEB-fr, MTEB-pl ä¸Šå–å¾—äº†è¿„ä»Šæœ€å¥½çš„å®éªŒç»“æœã€‚ :fire:\n- 7/26/2024ï¼šå‘å¸ƒæ–°çš„è½»é‡çº§é‡æ’å™¨[bge-reranker-v2.5-gemma2-lightweight](https://huggingface.co/BAAI/bge-reranker-v2.5-gemma2-lightweight)ã€‚è¿™æ˜¯ä¸€ä¸ªåŸºäºgemma-2-9bçš„è½»é‡çº§é‡æ’å™¨ï¼Œæ”¯æŒä»¤ç‰Œå‹ç¼©å’Œåˆ†å±‚è½»é‡æ“ä½œï¼Œåœ¨èŠ‚çœå¤§é‡èµ„æºçš„åŒæ—¶ï¼Œä»èƒ½ç¡®ä¿è‰¯å¥½çš„æ€§èƒ½ã€‚:fire:\n\n<details>\n  <summary>More</summary>\n\n- 6/7/2024: å‘å¸ƒé¦–ä¸ªä¸“ä¸ºé•¿è§†é¢‘ç†è§£è®¾è®¡çš„å…¨é¢è¯„æµ‹åŸºå‡†[MLVU](https://github.com/JUNJIE99/MLVU)ã€‚MLVUæ‹¥æœ‰ä¸°å¯Œçš„è§†é¢‘æ—¶é•¿èŒƒå›´ï¼Œå¤šæ ·åŒ–çš„è§†é¢‘æ¥æºï¼Œä»¥åŠå¤šä¸ªä¸“ä¸ºé•¿è§†é¢‘ç†è§£è®¾è®¡çš„è¯„ä¼°ä»»åŠ¡ã€‚ :fire:\n- 5/21/2024ï¼šè”åˆ Jina AIã€Zillizã€HuggingFace ç­‰æœºæ„å‘å¸ƒè¯„æµ‹åŸºå‡† [AIR-Bench](https://github.com/AIR-Bench/AIR-Bench)ï¼Œé’ˆå¯¹æ£€ç´¢ä»»åŠ¡å’Œ RAG åœºæ™¯è®¾è®¡ã€‚AIR-Bench é¦–æ¬¡æå‡ºåœ¨æ£€ç´¢ä»»åŠ¡ä¸­ä½¿ç”¨ LLMs è‡ªåŠ¨åŒ–ç”Ÿäº§è¯„ä¼°æ•°æ®ï¼Œé¿å…æ¨¡å‹è¿‡æ‹Ÿåˆæµ‹è¯•æ•°æ®ã€‚AIR-Bench ä¸éœ€è¦äººå·¥å‚ä¸æ ‡æ³¨æ•°æ®ï¼Œå› è€Œå¯ä»¥æ›´çµæ´»è¦†ç›–æ›´å¤šå‚ç›´é¢†åŸŸå’Œä¸åŒè¯­ç§ã€‚åŒæ—¶ AIR-Bench ä¼šå®šæœŸè¿›è¡Œæ›´æ–°ä»è€Œæ»¡è¶³ç¤¾åŒºä¸æ–­å˜åŒ–çš„è¯„æµ‹éœ€æ±‚ã€‚[Leaderboard](https://huggingface.co/spaces/AIR-Bench/leaderboard) :fire:\n- 4/30/2024: å‘å¸ƒ[Llama-3-8B-Instruct-80K-QLoRA](https://huggingface.co/namespace-Pt/Llama-3-8B-Instruct-80K-QLoRA), å…¶é€šè¿‡åœ¨å°‘é‡åˆæˆçš„é•¿æ–‡æœ¬æ•°æ®ä¸Šçš„QLoRAè®­ç»ƒï¼Œæœ‰æ•ˆåœ°å°†Llama-3-8B-Instructçš„ä¸Šä¸‹æ–‡é•¿åº¦ä»8Kæ‰©å±•åˆ°80Kã€‚è¯¦è§[ä»£ç ](https://github.com/FlagOpen/FlagEmbedding/tree/master/research/Long_LLM/longllm_qlora) :fire:\n- 3/18/2024: å‘å¸ƒæ–°çš„[rerankers](https://github.com/FlagOpen/FlagEmbedding/tree/master/research/llm_reranker), æ‹¥æœ‰æ›´å¥½çš„æ€§èƒ½åŒæ—¶æ”¯æŒå¤šè¯­è¨€å’Œé•¿æ–‡æœ¬ã€‚ :fire:\n- 3/18/2024: å‘å¸ƒ[Visualized-BGE](https://github.com/FlagOpen/FlagEmbedding/tree/master/research/visual_bge)ï¼Œè¯¥é¡¹ç›®é€šè¿‡å¼•å…¥image token embeddingèµ‹äºˆBGEè§†è§‰ç¼–ç èƒ½åŠ›ã€‚Visualized-BGEå¯ä»¥å¯¹æ··åˆå›¾æ–‡æ•°æ®è¿›è¡Œç¼–ç ï¼Œç”¨äºå¹¿æ³›çš„æ··åˆæ¨¡æ€æ£€ç´¢ä»»åŠ¡ã€‚ :fire:\n- 1/30/2024: å‘å¸ƒ**BGE-M3**, ç¬¬ä¸€ä¸ªå…·æœ‰å¤šåŠŸèƒ½ã€å¤šè¯­è¨€å’Œå¤šç²’åº¦ç‰¹æ€§çš„æ–‡æœ¬æ£€ç´¢æ¨¡å‹ï¼Œé«˜æ•ˆæ”¯æŒå¤šè¯­è¨€ï¼ˆ100+è¯­è¨€ï¼‰ã€é•¿æ–‡æœ¬ï¼ˆè‡³å¤š8192é•¿åº¦çš„è¾“å…¥æ–‡æœ¬ï¼‰ã€å’Œæ··åˆæ£€ç´¢ï¼ˆç¨ å¯†ã€ç¨€ç–ã€å¤šå‘é‡ï¼‰ã€‚ è¯¦è§[report](https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/BGE_M3/BGE_M3.pdf)å’Œ[ä»£ç ](https://github.com/FlagOpen/FlagEmbedding/tree/master/research/BGE_M3)  :fire:\n- 1/9/2024: å‘å¸ƒ[Activation-Beacon](https://github.com/FlagOpen/FlagEmbedding/tree/master/research/Long_LLM/activation_beacon), ä¸€ä¸ªæœ‰æ•ˆã€é«˜æ•ˆã€å…¼å®¹ã€ä½æˆæœ¬ï¼ˆè®­ç»ƒï¼‰çš„æ‰©å±•å¤§é¢„è¨€æ¨¡å‹ä¸Šä¸‹æ–‡é•¿åº¦çš„æ–¹æ³•ã€‚[æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/abs/2401.03462) \n- 12/24/2023: å‘å¸ƒ**LLaRA**, ä¸€ä¸ªåŸºäºLLaMA-7Bçš„ç¨ å¯†æ£€ç´¢æ¨¡å‹, MS MARCOä¸BEIRä¸Šå–å¾—äº†è¿„ä»Šæœ€å¥½çš„å®éªŒç»“æœ. æ¨¡å‹ä¸ä»£ç å°†ä¼šé™†ç»­å¼€æº. æ•¬è¯·å…³æ³¨. [æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/abs/2312.15503) å’Œ [ä»£ç ](https://github.com/FlagOpen/FlagEmbedding/tree/master/research/LLARA)\n- 11/23/2023: å‘å¸ƒ[LM-Cocktail](https://github.com/FlagOpen/FlagEmbedding/tree/master/research/LM_Cocktail), ä¸€ç§é€šè¿‡æ¨¡å‹èåˆåœ¨å¾®è°ƒæ—¶ä¿æŒåŸæœ‰æ¨¡å‹é€šç”¨èƒ½åŠ›çš„æ–¹æ³•. [æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/abs/2311.13534) \n- 10/12/2023: å‘å¸ƒ [LLM-Embedder](https://github.com/FlagOpen/FlagEmbedding/tree/master/research/llm_embedder), ä¸“ä¸ºå¤§è¯­è¨€æ¨¡å‹**å„ç§æ£€ç´¢å¢å¼ºä»»åŠ¡è®¾è®¡**çš„è‹±æ–‡å‘é‡æ¨¡å‹ã€‚[æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/pdf/2310.07554.pdf) \n- 09/15/2023: å‘å¸ƒ [æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/pdf/2309.07597.pdf) å’Œ [æ•°æ®é›†](https://data.baai.ac.cn/details/BAAI-MTP).\n- 09/12/2023: æ›´æ–°ï¼š\n    - **æ–°å¢é‡æ’æ¨¡å‹**ï¼šå¼€æºäº¤å‰ç¼–ç å™¨æ¨¡å‹bge-rerankerï¼Œå…·æœ‰æ¯”å‘é‡æ¨¡å‹æ›´å¼ºå¤§çš„æ’åºèƒ½åŠ›ã€‚éå¸¸å»ºè®®ä½¿ç”¨æˆ–è€…å¾®è°ƒå®ƒæ¥é‡æ–°æ’åºå‘é‡æ¨¡å‹è¿”å›çš„top-kæ–‡æ¡£ï¼Œæé«˜æœ€ç»ˆç»“æœçš„ç›¸å…³æ€§ã€‚\n    - **æ›´æ–°å‘é‡æ¨¡å‹**ï¼šå‘å¸ƒbge-*-v1.5å‘é‡æ¨¡å‹ï¼Œç¼“è§£ç›¸ä¼¼åº¦åˆ†å¸ƒé—®é¢˜ï¼Œæå‡æ— æŒ‡ä»¤æƒ…å†µä¸‹çš„æ£€ç´¢èƒ½åŠ›ï¼ˆä½†æ£€ç´¢ä»»åŠ¡ä»å»ºè®®ä½¿ç”¨æŒ‡ä»¤ï¼‰\n- 09/07/2023: æ›´æ–°[å¾®è°ƒä»£ç ](https://github.com/FlagOpen/FlagEmbedding/tree/master/research/baai_general_embedding): å¢åŠ éš¾è´Ÿæ ·æœ¬æŒ–æ˜è„šæœ¬ï¼Œå¢åŠ æŒ‡ä»¤å‚æ•°æ–¹ä¾¿åœ¨å¾®è°ƒä¸­æ·»åŠ æŒ‡ä»¤.\n- 08/09/2023: BGEæ¨¡å‹æ•´åˆå…¥Langchain, å¯ä»¥åœ¨langchainä¸­éå¸¸ç®€å•çš„[ä½¿ç”¨å®ƒ](#using-langchain); C-MTEBä¸­æ–‡æ¦œå•å·²[åœ¨çº¿æ›´æ–°](https://huggingface.co/spaces/mteb/leaderboard).  \n- 08/05/2023: å‘å¸ƒæ›´å°çš„æ¨¡å‹(base, small), **åœ¨åŒå°ºå¯¸æ¨¡å‹ä¸­å–å¾—æœ€å¥½çš„æ€§èƒ½ï¼ ğŸ¤—**\n- 08/02/2023: :tada: :tada: å‘å¸ƒä¸­è‹±æ–‡å‘é‡æ¨¡å‹BGE(BAAI General Embeddingçš„ç¼©å†™), **åœ¨MTEBå’ŒC-MTEBæ¦œå•ä¸Šå–å¾—æœ€å¥½çš„æ€§èƒ½** \n- 08/01/2023: å‘å¸ƒå¤§è§„æ¨¡ä¸­æ–‡æ–‡æœ¬å‘é‡[è¯„æµ‹æ¦œå•](https://github.com/FlagOpen/FlagEmbedding/tree/master/research/C_MTEB) (**C-MTEB**), å…¶åŒ…æ‹¬31ä¸ªæµ‹è¯•ä»»åŠ¡.   \n\n</details>\n\n\n## å®‰è£…\n### ä½¿ç”¨pip:\nå¦‚æœä½ ä¸æƒ³å¾®è°ƒæ¨¡å‹ï¼Œä½ å¯ä»¥ç›´æ¥å®‰è£…åŒ…ï¼Œä¸ç”¨finetuneä¾èµ–ï¼š\n```\npip install -U FlagEmbedding\n```\nå¦‚æœä½ æƒ³å¾®è°ƒæ¨¡å‹ï¼Œä½ å¯ä»¥ç”¨finetuneä¾èµ–å®‰è£…ï¼š\n```\npip install -U FlagEmbedding[finetune]\n```\n### ä»æºæ–‡ä»¶å®‰è£…éƒ¨ç½²:\n\nå…‹éš†å¹¶å®‰è£…FlagEmbeddingï¼š\n```\ngit clone https://github.com/FlagOpen/FlagEmbedding.git\ncd FlagEmbedding\n# å¦‚æœä½ ä¸æƒ³å¾®è°ƒæ¨¡å‹ï¼Œä½ å¯ä»¥ç›´æ¥å®‰è£…åŒ…ï¼Œä¸ç”¨finetuneä¾èµ–ï¼š\npip install  .\n# å¦‚æœä½ æƒ³å¾®è°ƒæ¨¡å‹ï¼Œä½ å¯ä»¥ç”¨finetuneä¾èµ–å®‰è£…ï¼š\n# pip install  .[finetune]\n```\nåœ¨å¯ç¼–è¾‘æ¨¡å¼ä¸‹å®‰è£…:\n```\n# å¦‚æœä½ ä¸æƒ³å¾®è°ƒæ¨¡å‹ï¼Œä½ å¯ä»¥ç›´æ¥å®‰è£…åŒ…ï¼Œä¸ç”¨finetuneä¾èµ–ï¼š\npip install -e .\n# å¦‚æœä½ æƒ³å¾®è°ƒæ¨¡å‹ï¼Œä½ å¯ä»¥ç”¨finetuneä¾èµ–å®‰è£…ï¼š\n# pip install -e .[finetune]\n```\n\n## å¿«é€Ÿå¼€å§‹\né¦–å…ˆï¼ŒåŠ è½½ä¸€ä¸ªBGEå‘é‡æ¨¡å‹ï¼š\n```\nfrom FlagEmbedding import FlagAutoModel\n\nmodel = FlagAutoModel.from_finetuned('BAAI/bge-base-en-v1.5',\n                                      query_instruction_for_retrieval=\"Represent this sentence for searching relevant passages:\",\n                                      use_fp16=True)\n```\nå°†è¯­å¥ä½œä¸ºæ¨¡å‹è¾“å…¥ï¼Œå¾—åˆ°å‘é‡ï¼š\n```\nsentences_1 = [\"I love NLP\", \"I love machine learning\"]\nsentences_2 = [\"I love BGE\", \"I love text retrieval\"]\nembeddings_1 = model.encode(sentences_1)\nembeddings_2 = model.encode(sentences_2)\n```\nå–å¾—å‘é‡åï¼Œé€šè¿‡å†…ç§¯è®¡ç®—ç›¸ä¼¼åº¦ï¼š\n```\nsimilarity = embeddings_1 @ embeddings_2.T\nprint(similarity)\n```\n\nå…³äºæ›´å¤šç»†èŠ‚ï¼Œå¯ä»¥å‚è€ƒ[embedderæ¨ç†](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/inference/embedder), [rerankeræ¨ç†](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/inference/reranker), [embedderå¾®è°ƒ](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune/embedder), [rerankerå¾®è°ƒ](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune/reranker), [è¯„ä¼°](https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/evaluation), [ç ”ç©¶](https://github.com/FlagOpen/FlagEmbedding/tree/master/research).\n\n## ç¤¾åŒº\n\næˆ‘ä»¬å°†æŒç»­ç»´æŠ¤BGEåŠFlagEmbeddingç¤¾åŒºï¼Œæœ‰ä»»ä½•æƒ³æ³•å»ºè®®éƒ½æ¬¢è¿å‘Šè¯‰æˆ‘ä»¬ï¼\n\nè¿‘æœŸä¼šæŒç»­æ›´æ–°[æ•™å­¦](./Tutorials/)ä¸­çš„å†…å®¹ï¼Œå¸Œæœ›ä¸ºæ–‡æœ¬æ£€ç´¢ä»¥åŠRAGæ‰“é€ å‡ºå®Œæ•´ä¸”è¯¦ç»†çš„æ•™å­¦ï¼Œæ¬¢è¿æŒç»­å…³æ³¨ï¼\n\nåœ¨æœªæ¥å°†ä¼šæ›´æ–°ä»¥ä¸‹å†…å®¹ï¼š\n\n- RAG\n\n<details>\n  <summary>æ•™ç¨‹è§„åˆ’</summary>\n    <img src=\"./Tutorials/tutorial_map.png\"/>\n</details>\n## æ¨¡å‹åˆ—è¡¨\n\n| Model                                                                     | Language |                                                             Description                                                             |                                       query instruction for retrieval                                       |\n|:--------------------------------------------------------------------------|:--------:|:-----------------------------------------------------------------------------------------------------------------------------------:|:-----------------------------------------------------------------------------------------------------------:|\n| [BAAI/bge-en-icl](https://huggingface.co/BAAI/bge-en-icl) | English | åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„å‘é‡æ¨¡å‹ï¼Œå…·æœ‰ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›ï¼Œèƒ½å¤ŸåŸºäºå°‘é‡ç¤ºä¾‹å……åˆ†å‘æŒ¥æ¨¡å‹çš„æ½œåŠ›ã€‚\t |                                             æ ¹æ®ç»™å®šçš„ä»»åŠ¡è‡ªç”±æä¾›æŒ‡ç¤ºå’Œå°‘æ•°ç¤ºä¾‹ã€‚                                             |\n| [BAAI/bge-multilingual-gemma2](https://huggingface.co/BAAI/bge-multilingual-gemma2) |    Multilingual     | åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„å¤šè¯­è¨€å‘é‡æ¨¡å‹ï¼Œåœ¨å¤šç§è¯­è¨€å’Œä»»åŠ¡ä¸Šè®­ç»ƒï¼Œé€‚åº”å¤šæ ·åŒ–çš„ä¸‹æ¸¸åœºæ™¯ã€‚ |                               æ ¹æ®ç»™å®šçš„ä»»åŠ¡è‡ªç”±æä¾›æŒ‡ç¤ºå’Œå°‘æ•°ç¤ºä¾‹ã€‚                                |\n| [BAAI/bge-m3](https://huggingface.co/BAAI/bge-m3)                   |    Multilingual     | å¤šåŠŸèƒ½ï¼ˆå‘é‡æ£€ç´¢ï¼Œç¨€ç–æ£€ç´¢ï¼Œå¤šè¡¨å¾æ£€ç´¢ï¼‰ã€å¤šè¯­è¨€ã€å¤šç²’åº¦ï¼ˆæœ€å¤§é•¿åº¦8192ï¼‰ |                                                                                                             |\n| [LM-Cocktail](https://huggingface.co/Shitao)                   |   English |   å¾®è°ƒçš„Llamaå’ŒBGEæ¨¡å‹ï¼Œå¯ä»¥ç”¨æ¥å¤ç°LM-Cocktailè®ºæ–‡çš„ç»“æœ    |                                                                                                             |\n| [BAAI/llm-embedder](https://huggingface.co/BAAI/llm-embedder)             |   English |         ä¸“ä¸ºå¤§è¯­è¨€æ¨¡å‹å„ç§æ£€ç´¢å¢å¼ºä»»åŠ¡è®¾è®¡çš„å‘é‡æ¨¡å‹         | è¯¦è§[README](https://github.com/FlagOpen/FlagEmbedding/tree/master/research/llm_embedder) |\n| [BAAI/bge-reranker-v2-m3](https://huggingface.co/BAAI/bge-reranker-v2-m3) | Multilingual | ä¸€ä¸ªè½»é‡çº§çš„äº¤å‰ç¼–ç å™¨æ¨¡å‹ï¼Œå…·æœ‰å¼ºå¤§çš„å¤šè¯­è¨€èƒ½åŠ›ï¼Œæ˜“äºéƒ¨ç½²ï¼Œå…·æœ‰å¿«é€Ÿçš„æ¨ç†èƒ½åŠ›ã€‚ |                                                                                                             |\n| [BAAI/bge-reranker-v2-gemma](https://huggingface.co/BAAI/bge-reranker-v2-gemma) | Multilingual | ä¸€ä¸ªæ”¯æŒå¤šè¯­è¨€çš„äº¤å‰ç¼–ç å™¨æ¨¡å‹ï¼Œåœ¨è‹±æ–‡å’Œå¤šè¯­è¨€èƒ½åŠ›æ–¹é¢å‡è¡¨ç°å‡ºè‰²ã€‚ |                                                                                                             |\n| [BAAI/bge-reranker-v2-minicpm-layerwise](https://huggingface.co/BAAI/bge-reranker-v2-minicpm-layerwise) | Multilingual | ä¸€ä¸ªæ”¯æŒå¤šè¯­è¨€çš„äº¤å‰ç¼–ç å™¨æ¨¡å‹ï¼Œåœ¨è‹±æ–‡å’Œä¸­æ–‡æ–¹é¢å‡è¡¨ç°è‰¯å¥½ï¼Œå…è®¸è‡ªç”±é€‰æ‹©è¾“å‡ºå±‚ï¼Œä»¥ä¾¿åŠ é€Ÿæ¨ç†ã€‚ |                                                                                                             |\n| [BAAI/bge-reranker-v2.5-gemma2-lightweight](https://huggingface.co/BAAI/bge-reranker-v2.5-gemma2-lightweight) | Multilingual | ä¸€ä¸ªæ”¯æŒå¤šè¯­è¨€çš„è·¨ç¼–ç å™¨æ¨¡å‹ï¼Œä¸ä»…åœ¨è‹±æ–‡å’Œä¸­æ–‡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œè¿˜å…è®¸è‡ªç”±é€‰æ‹©è¾“å‡ºå±‚ã€å‹ç¼©æ¯”ä¾‹å’Œå‹ç¼©å±‚ï¼Œä»è€Œä¾¿äºåŠ é€Ÿæ¨ç†ã€‚ |                                                                                                             |\n| [BAAI/bge-reranker-large](https://huggingface.co/BAAI/bge-reranker-large) |   Chinese and English |       äº¤å‰ç¼–ç å™¨æ¨¡å‹ï¼Œç²¾åº¦æ¯”å‘é‡æ¨¡å‹æ›´é«˜ä½†æ¨ç†æ•ˆç‡è¾ƒä½       |                                                                                                             |\n| [BAAI/bge-reranker-base](https://huggingface.co/BAAI/bge-reranker-base)   |   Chinese and English |       äº¤å‰ç¼–ç å™¨æ¨¡å‹ï¼Œç²¾åº¦æ¯”å‘é‡æ¨¡å‹æ›´é«˜ä½†æ¨ç†æ•ˆç‡è¾ƒä½       |                                                                                                             |\n| [BAAI/bge-large-en-v1.5](https://huggingface.co/BAAI/bge-large-en-v1.5)   |   English |                                      1.5ç‰ˆæœ¬ï¼Œç›¸ä¼¼åº¦åˆ†å¸ƒæ›´åŠ åˆç†                                       |                         `Represent this sentence for searching relevant passages: `                         |\n| [BAAI/bge-base-en-v1.5](https://huggingface.co/BAAI/bge-base-en-v1.5)     |   English |                                      1.5ç‰ˆæœ¬ï¼Œç›¸ä¼¼åº¦åˆ†å¸ƒæ›´åŠ åˆç†                                       |                         `Represent this sentence for searching relevant passages: `                         |\n| [BAAI/bge-small-en-v1.5](https://huggingface.co/BAAI/bge-small-en-v1.5)   |   English |                                      1.5ç‰ˆæœ¬ï¼Œç›¸ä¼¼åº¦åˆ†å¸ƒæ›´åŠ åˆç†                                       |                         `Represent this sentence for searching relevant passages: `                         |\n| [BAAI/bge-large-zh-v1.5](https://huggingface.co/BAAI/bge-large-zh-v1.5)   |   Chinese |                                      1.5ç‰ˆæœ¬ï¼Œç›¸ä¼¼åº¦åˆ†å¸ƒæ›´åŠ åˆç†                                       |                                            `ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š`                                            |\n| [BAAI/bge-base-zh-v1.5](https://huggingface.co/BAAI/bge-base-zh-v1.5)     |   Chinese |                                      1.5ç‰ˆæœ¬ï¼Œç›¸ä¼¼åº¦åˆ†å¸ƒæ›´åŠ åˆç†                                       |                                            `ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š`                                            |\n| [BAAI/bge-small-zh-v1.5](https://huggingface.co/BAAI/bge-small-zh-v1.5)   |   Chinese |                                      1.5ç‰ˆæœ¬ï¼Œç›¸ä¼¼åº¦åˆ†å¸ƒæ›´åŠ åˆç†                                       |                                            `ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š`                                            |\n| [BAAI/bge-large-en](https://huggingface.co/BAAI/bge-large-en)             |   English |                  å‘é‡æ¨¡å‹ï¼Œå°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡                  |                         `Represent this sentence for searching relevant passages: `                         |\n| [BAAI/bge-base-en](https://huggingface.co/BAAI/bge-base-en)               |   English |                     base-scale å‘é‡æ¨¡å‹                      |                         `Represent this sentence for searching relevant passages: `                         |\n| [BAAI/bge-small-en](https://huggingface.co/BAAI/bge-small-en)             |   English |                     base-scale å‘é‡æ¨¡å‹                      |                         `Represent this sentence for searching relevant passages: `                         |\n| [BAAI/bge-large-zh](https://huggingface.co/BAAI/bge-large-zh)             |   Chinese |                                             å‘é‡æ¨¡å‹ï¼Œå°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡                                 |                                            `ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š`                                            |\n| [BAAI/bge-base-zh](https://huggingface.co/BAAI/bge-base-zh)               |   Chinese |                                    base-scale å‘é‡æ¨¡å‹                                    |                                            `ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š`                                            |\n| [BAAI/bge-small-zh](https://huggingface.co/BAAI/bge-small-zh)             |   Chinese |                                        base-scale å‘é‡æ¨¡å‹                          |                                            `ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š`                                            |\n\n\n## è´¡çŒ®è€…:\n\nååˆ†æ„Ÿè°¢æ‰€æœ‰å‚ä¸FlagEmbeddingç¤¾åŒºæˆå‘˜çš„è´¡çŒ®ï¼Œä¹Ÿæ¬¢è¿æ–°çš„æˆå‘˜åŠ å…¥ï¼\n\n<a href=\"https://github.com/FlagOpen/FlagEmbedding/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=FlagOpen/FlagEmbedding\" />\n</a>\n\n\n\n## Citation\n\nå¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„å·¥ä½œæœ‰æ‰€å¸®åŠ©ï¼Œè¯·è€ƒè™‘ç‚¹ä¸ªæ˜Ÿ :star: å’Œå¼•ç”¨ä»¥ä¸‹è®ºæ–‡:\n```\n@misc{cocktail,\n      title={LM-Cocktail: Resilient Tuning of Language Models via Model Merging}, \n      author={Shitao Xiao and Zheng Liu and Peitian Zhang and Xingrun Xing},\n      year={2023},\n      eprint={2311.13534},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n\n@misc{llm_embedder,\n      title={Retrieve Anything To Augment Large Language Models}, \n      author={Peitian Zhang and Shitao Xiao and Zheng Liu and Zhicheng Dou and Jian-Yun Nie},\n      year={2023},\n      eprint={2310.07554},\n      archivePrefix={arXiv},\n      primaryClass={cs.IR}\n}\n\n@misc{bge_embedding,\n      title={C-Pack: Packaged Resources To Advance General Chinese Embedding}, \n      author={Shitao Xiao and Zheng Liu and Peitian Zhang and Niklas Muennighoff},\n      year={2023},\n      eprint={2309.07597},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n```\n\n## License\nFlagEmbeddingåŸºäº[MIT License](LICENSE)å¼€æºåè®®ã€‚\n\n\n\n"
        },
        {
          "name": "Tutorials",
          "type": "tree",
          "content": null
        },
        {
          "name": "dataset",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "imgs",
          "type": "tree",
          "content": null
        },
        {
          "name": "research",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 0.7841796875,
          "content": "from setuptools import setup, find_packages\n\nwith open(\"README.md\", mode=\"r\", encoding=\"utf-8\") as readme_file:\n    readme = readme_file.read()\n\nsetup(\n    name='FlagEmbedding',\n    version='1.3.3',\n    description='FlagEmbedding',\n    long_description=readme,\n    long_description_content_type=\"text/markdown\",\n    author_email='2906698981@qq.com',\n    url='https://github.com/FlagOpen/FlagEmbedding',\n    packages=find_packages(),\n    include_package_data=True,\n    install_requires=[\n        'torch>=1.6.0',\n        'transformers==4.44.2',\n        'datasets==2.19.0',\n        'accelerate>=0.20.1',\n        'sentence_transformers',\n        'peft',\n        'ir-datasets',\n        'sentencepiece',\n        'protobuf'\n    ],\n    extras_require={\n        'finetune': ['deepspeed', 'flash-attn'],\n    },\n)\n"
        }
      ]
    }
  ]
}