{
  "metadata": {
    "timestamp": 1736560874288,
    "page": 588,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjU5MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "chineseocr/chineseocr",
      "stars": 5977,
      "defaultBranch": "app",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.1337890625,
          "content": "# Python:\n*.py[cod]\n*.so\n*.egg\n*.egg-info\n*.pth\n*.pb\n*.h5\n*.pbtxt\n*.weights\ndist\nbuil\n.DS_Store*\n.ipynb_checkpoints\n__pycache__\ndarknet \n"
        },
        {
          "name": ".gitignore.swp",
          "type": "blob",
          "size": 12,
          "content": null
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.08203125,
          "content": "[submodule \"darknet\"]\n\tpath = darknet\n\turl = https://github.com/zergmk2/darknet.git\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.9931640625,
          "content": "FROM ubuntu\nMAINTAINER https://github.com/chineseocr/chineseocr\nLABEL version=\"1.0\"\nEXPOSE 8080\nRUN apt-get update\nRUN apt-get install  libsm6 libxrender1 libxext-dev gcc -y\n##下载Anaconda3 python 环境安装包 放置在chineseocr目录 url地址https://repo.anaconda.com/archive/Anaconda3-2019.03-Linux-x86_64.sh\nWORKDIR /chineseocr\nADD . /chineseocr\nRUN cd /chineseocr && sh -c '/bin/echo -e \"\\nyes\\n\\nyes\" | sh Anaconda3-2019.03-Linux-x86_64.sh'\nRUN echo -e \"\\ny\" | /root/anaconda3/bin/conda install python=3.6\nRUN /root/anaconda3/bin/pip install easydict opencv-contrib-python==3.4.2.16 Cython h5py pandas requests bs4 matplotlib lxml -U pillow keras==2.1.5 tensorflow==1.8 -i https://pypi.tuna.tsinghua.edu.cn/simple/\nRUN /root/anaconda3/bin/pip install web.py==0.40.dev0\nRUN echo -e \"\\ny\" | /root/anaconda3/bin/conda install pytorch-cpu torchvision-cpu -c pytorch\nRUN rm Anaconda3-2019.03-Linux-x86_64.sh\n#RUN cd /chineseocr/text/detector/utils && sh make-for-cpu.sh\n#RUN conda clean -p\n#RUN conda clean -t\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0419921875,
          "content": "MIT License\n\nCopyright (c) 2018 chineseocr\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 4.0009765625,
          "content": "## 本项目基于[yolo3](https://github.com/pjreddie/darknet.git) 与[crnn](https://github.com/meijieru/crnn.pytorch.git)  实现中文自然场景文字检测及识别\n\n###  darknet 优化版本：https://github.com/chineseocr/darknet-ocr.git \n# 训练代码（master分支）    \n\n# ocr训练数据集     \nocr ctc训练数据集(压缩包解码:chineseocr)         \n百度网盘地址:链接: https://pan.baidu.com/s/1UcUKUUELLwdM29zfbztzdw 提取码: atwn       \ngofile地址:http://gofile.me/4Nlqh/uT32hAjbx   密码 https://github.com/chineseocr/chineseocr   \n  \n# 实现功能\n- [x]  文字方向检测 0、90、180、270度检测（支持dnn/tensorflow） \n- [x]  支持(darknet/opencv dnn /keras)文字检测,支持darknet/keras训练\n- [x]  不定长OCR训练(英文、中英文) crnn\\dense ocr 识别及训练 ,新增pytorch转keras模型代码(tools/pytorch_to_keras.py)\n- [x]  支持darknet 转keras, keras转darknet, pytorch 转keras模型\n- [x]  身份证/火车票结构化数据识别 \n- [x]  新增CNN+ctc模型，支持DNN模块调用OCR，单行图像平均时间为0.02秒以下     \n- [ ]  CPU版本加速    \n- [ ]  支持基于用户字典OCR识别    \n- [ ]  新增语言模型修正OCR识别结果  \n- [ ]  支持树莓派实时识别方案  \n \n\n## 环境部署\n\nGPU部署 参考:setup.md     \nCPU部署 参考:setup-cpu.md   \n\n\n### 下载编译darknet(如果直接运用opencv dnn或者keras yolo3 可忽略darknet的编译)  \n```\ngit clone https://github.com/pjreddie/darknet.git \nmv darknet chineseocr/\n##编译对GPU、cudnn的支持 修改 Makefile\n#GPU=1\n#CUDNN=1\n#OPENCV=0\n#OPENMP=0\nmake \n```\n\n修改 darknet/python/darknet.py line 48    \nroot = '/root/'##chineseocr所在目录     \nlib = CDLL(root+\"chineseocr/darknet/libdarknet.so\", RTLD_GLOBAL)    \n\n\n## 下载模型文件   \n模型文件地址:\n* 百度网盘:https://pan.baidu.com/s/1gTW9gwJR6hlwTuyB6nCkzQ     \nother-links:http://gofile.me/4Nlqh/fNHlWzVWo      \n复制文件夹中的所有文件到models目录\n   \n## 模型转换（非必须）\npytorch ocr 转keras ocr     \n``` Bash\npython tools/pytorch_to_keras.py  -weights_path models/ocr-dense.pth -output_path models/ocr-dense-keras.h5\n```\ndarknet 转keras     \n``` Bash\npython tools/darknet_to_keras.py -cfg_path models/text.cfg -weights_path models/text.weights -output_path models/text.h5\n```\nkeras 转darknet      \n``` Bash\npython tools/keras_to_darknet.py -cfg_path models/text.cfg -weights_path models/text.h5 -output_path models/text.weights\n```\n\n## 模型选择  \n``` Bash\n参考config.py文件\n```  \n\n## 构建docker镜像 \n``` Bash\n##下载Anaconda3 python 环境安装包（https://repo.anaconda.com/archive/Anaconda3-2019.03-Linux-x86_64.sh） 放置在chineseocr目录下   \n##建立镜像   \ndocker build -t chineseocr .   \n##启动服务   \ndocker run -d -p 8080:8080 chineseocr /root/anaconda3/bin/python app.py\n\n```\n\n## web服务启动\n``` Bash\ncd chineseocr## 进入chineseocr目录\npython app.py 8080 ##8080端口号，可以设置任意端口\n```\n\n## 访问服务\nhttp://127.0.0.1:8080/ocr\n\n<img width=\"500\" height=\"300\" src=\"https://github.com/chineseocr/chineseocr/blob/master/test/demo.png\"/>\n\n\n\n## 识别结果展示\n\n<img width=\"500\" height=\"300\" src=\"https://github.com/chineseocr/chineseocr/blob/master/test/train-demo.png\"/>\n<img width=\"500\" height=\"300\" src=\"https://github.com/chineseocr/chineseocr/blob/master/test/idcard-demo.png\"/>\n<img width=\"500\" height=\"300\" src=\"https://github.com/chineseocr/chineseocr/blob/master/test/img-demo.png\"/>\n<img width=\"500\" height=\"300\" src=\"https://github.com/chineseocr/chineseocr/blob/master/test/line-demo.png\"/>\n\n\n\n## 参考\n1. yolo3 https://github.com/pjreddie/darknet.git   \n2. crnn  https://github.com/meijieru/crnn.pytorch.git              \n3. ctpn  https://github.com/eragonruan/text-detection-ctpn    \n4. CTPN  https://github.com/tianzhi0549/CTPN       \n5. keras yolo3 https://github.com/qqwweee/keras-yolo3.git    \n6. darknet keras 模型转换参考 参考：https://www.cnblogs.com/shouhuxianjian/p/10567201.html  \n7. 语言模型实现 https://github.com/lukhy/masr\n\n"
        },
        {
          "name": "app.py",
          "type": "blob",
          "size": 7.333984375,
          "content": "# -*- coding: utf-8 -*-\n\"\"\"\n@author: lywen\n\"\"\"\nimport os\nimport json\nimport time\nimport web\nimport numpy as np\nimport uuid\nfrom PIL import Image\nweb.config.debug  = True\n\nfilelock='file.lock'\nif os.path.exists(filelock):\n   os.remove(filelock)\n\nrender = web.template.render('templates', base='base')\nfrom config import *\nfrom apphelper.image import union_rbox,adjust_box_to_origin,base64_to_PIL\nfrom application import trainTicket,idcard \nif yoloTextFlag =='keras' or AngleModelFlag=='tf' or ocrFlag=='keras':\n    if GPU:\n        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(GPUID)\n        import tensorflow as tf\n        from keras import backend as K\n        config = tf.ConfigProto()\n        config.gpu_options.allocator_type = 'BFC'\n        config.gpu_options.per_process_gpu_memory_fraction = 0.3## GPU最大占用量\n        config.gpu_options.allow_growth = True##GPU是否可动态增加\n        K.set_session(tf.Session(config=config))\n        K.get_session().run(tf.global_variables_initializer())\n    \n    else:\n      ##CPU启动\n      os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''\n\nif yoloTextFlag=='opencv':\n    scale,maxScale = IMGSIZE\n    from text.opencv_dnn_detect import text_detect\nelif yoloTextFlag=='darknet':\n    scale,maxScale = IMGSIZE\n    from text.darknet_detect import text_detect\nelif yoloTextFlag=='keras':\n    scale,maxScale = IMGSIZE[0],2048\n    from text.keras_detect import  text_detect\nelse:\n     print( \"err,text engine in keras\\opencv\\darknet\")\n     \nfrom text.opencv_dnn_detect import angle_detect\n\nif ocr_redis:\n    ##多任务并发识别\n    from apphelper.redisbase import redisDataBase\n    ocr = redisDataBase().put_values\nelse:   \n    from crnn.keys import alphabetChinese,alphabetEnglish\n    if ocrFlag=='keras':\n        from crnn.network_keras import CRNN\n        if chineseModel:\n            alphabet = alphabetChinese\n            if LSTMFLAG:\n                ocrModel = ocrModelKerasLstm\n            else:\n                ocrModel = ocrModelKerasDense\n        else:\n            ocrModel = ocrModelKerasEng\n            alphabet = alphabetEnglish\n            LSTMFLAG = True\n            \n    elif ocrFlag=='torch':\n        from crnn.network_torch import CRNN\n        if chineseModel:\n            alphabet = alphabetChinese\n            if LSTMFLAG:\n                ocrModel = ocrModelTorchLstm\n            else:\n                ocrModel = ocrModelTorchDense\n                \n        else:\n            ocrModel = ocrModelTorchEng\n            alphabet = alphabetEnglish\n            LSTMFLAG = True\n    elif ocrFlag=='opencv':\n        from crnn.network_dnn import CRNN\n        ocrModel = ocrModelOpencv\n        alphabet = alphabetChinese\n    else:\n        print( \"err,ocr engine in keras\\opencv\\darknet\")\n     \n    nclass = len(alphabet)+1   \n    if ocrFlag=='opencv':\n        crnn = CRNN(alphabet=alphabet)\n    else:\n        crnn = CRNN( 32, 1, nclass, 256, leakyRelu=False,lstmFlag=LSTMFLAG,GPU=GPU,alphabet=alphabet)\n    if os.path.exists(ocrModel):\n        crnn.load_weights(ocrModel)\n    else:\n        print(\"download model or tranform model with tools!\")\n        \n    ocr = crnn.predict_job\n    \n   \nfrom main import TextOcrModel\n\nmodel =  TextOcrModel(ocr,text_detect,angle_detect)\n    \n\nbillList = ['通用OCR','火车票','身份证']\n\nclass OCR:\n    \"\"\"通用OCR识别\"\"\"\n\n    def GET(self):\n        post = {}\n        post['postName'] = 'ocr'##请求地址\n        post['height'] = 1000\n        post['H'] = 1000\n        post['width'] = 600\n        post['W'] = 600\n        post['billList'] = billList\n        return render.ocr(post)\n\n    def POST(self):\n        t = time.time()\n        data = web.data()\n        uidJob = uuid.uuid1().__str__()\n        \n        data = json.loads(data)\n        billModel = data.get('billModel','')\n        textAngle = data.get('textAngle',False)##文字检测\n        textLine = data.get('textLine',False)##只进行单行识别\n        \n        imgString = data['imgString'].encode().split(b';base64,')[-1]\n        img = base64_to_PIL(imgString)\n        if img is not None:\n            img = np.array(img)\n            \n        H,W = img.shape[:2]\n\n        while time.time()-t<=TIMEOUT:\n            if os.path.exists(filelock):\n                continue\n            else:\n                with open(filelock,'w') as f:\n                    f.write(uidJob)\n                                                \n                if textLine:\n                    ##单行识别\n                    partImg = Image.fromarray(img)\n                    text    = crnn.predict(partImg.convert('L'))\n                    res =[ {'text':text,'name':'0','box':[0,0,W,0,W,H,0,H]} ]\n                    os.remove(filelock)\n                    break\n                        \n                else:\n                    detectAngle = textAngle\n                    result,angle= model.model(img,\n                                                scale=scale,\n                                                maxScale=maxScale,\n                                                detectAngle=detectAngle,##是否进行文字方向检测，通过web传参控制\n                                                MAX_HORIZONTAL_GAP=100,##字符之间的最大间隔，用于文本行的合并\n                                                MIN_V_OVERLAPS=0.6,\n                                                MIN_SIZE_SIM=0.6,\n                                                TEXT_PROPOSALS_MIN_SCORE=0.1,\n                                                TEXT_PROPOSALS_NMS_THRESH=0.3,\n                                                TEXT_LINE_NMS_THRESH = 0.99,##文本行之间测iou值\n                                                LINE_MIN_SCORE=0.1,\n                                                leftAdjustAlph=0.01,##对检测的文本行进行向左延伸\n                                                rightAdjustAlph=0.01,##对检测的文本行进行向右延伸\n                                               )\n        \n        \n        \n                    if billModel=='' or billModel=='通用OCR' :\n                        result = union_rbox(result,0.2)\n                        res = [{'text':x['text'],\n                                'name':str(i),\n                                'box':{'cx':x['cx'],\n                                       'cy':x['cy'],\n                                       'w':x['w'],\n                                       'h':x['h'],\n                                       'angle':x['degree']\n        \n                                      }\n                               } for i,x in enumerate(result)]\n                        res = adjust_box_to_origin(img,angle, res)##修正box\n        \n                    elif billModel=='火车票':\n                        res = trainTicket.trainTicket(result)\n                        res = res.res\n                        res =[ {'text':res[key],'name':key,'box':{}} for key in res]\n        \n                    elif billModel=='身份证':\n        \n                        res = idcard.idcard(result)\n                        res = res.res\n                        res =[ {'text':res[key],'name':key,'box':{}} for key in res]\n                        \n                    os.remove(filelock)\n                    break\n            \n        \n        timeTake = time.time()-t\n         \n        return json.dumps({'res':res,'timeTake':round(timeTake,4)},ensure_ascii=False)\n        \n\nurls = ('/ocr','OCR',)\n\nif __name__ == \"__main__\":\n\n      app = web.application(urls, globals())\n      app.run()\n"
        },
        {
          "name": "apphelper",
          "type": "tree",
          "content": null
        },
        {
          "name": "application",
          "type": "tree",
          "content": null
        },
        {
          "name": "config.py",
          "type": "blob",
          "size": 2.3408203125,
          "content": "import os\npwd = os.getcwd()\n########################文字检测################################################\n##文字检测引擎 \nIMGSIZE = (608,608)## yolo3 输入图像尺寸\nyoloTextFlag = 'keras' ##keras,opencv,darknet，模型性能 keras>darknet>opencv\n############## keras yolo  ##############\nkeras_anchors = '8,11, 8,16, 8,23, 8,33, 8,48, 8,97, 8,139, 8,198, 8,283'\nclass_names = ['none','text',]\nkerasTextModel=os.path.join(pwd,\"models\",\"text.h5\")##keras版本模型权重文件\n############## keras yolo  ##############\n\n\n############## darknet yolo  ##############\n\ndarknetRoot = os.path.join(os.path.curdir,\"darknet\")## yolo 安装目录\nyoloCfg     = os.path.join(pwd,\"models\",\"text.cfg\")\nyoloWeights = os.path.join(pwd,\"models\",\"text.weights\")\nyoloData    = os.path.join(pwd,\"models\",\"text.data\")\n############## darknet yolo  ##############\n\n########################文字检测################################################\n\n## GPU选择及启动GPU序号\nGPU = True##OCR 是否启用GPU\nGPUID=0##调用GPU序号\n\n##vgg文字方向检测模型\nDETECTANGLE=True##是否进行文字方向检测\nAngleModelPb    = os.path.join(pwd,\"models\",\"Angle-model.pb\")\nAngleModelPbtxt = os.path.join(pwd,\"models\",\"Angle-model.pbtxt\")\nAngleModelFlag  = 'opencv'  ## opencv or tf\n\n######################OCR模型###################################################\nocr_redis = False##是否多任务执行OCR识别加速 如果多任务，则配置redis数据库，数据库账号参考apphelper/redisbase.py\n##是否启用LSTM crnn模型\n##OCR模型是否调用LSTM层\nLSTMFLAG = True\nocrFlag = 'torch'##ocr模型 支持 keras  torch opencv版本\n##模型选择 True:中英文模型 False:英文模型\nchineseModel = True## 中文模型或者纯英文模型\n##转换keras模型 参考tools目录\nocrModelKerasDense       = os.path.join(pwd,\"models\",\"ocr-dense.h5\")\nocrModelKerasLstm        = os.path.join(pwd,\"models\",\"ocr-lstm.h5\")\nocrModelKerasEng         = os.path.join(pwd,\"models\",\"ocr-english.h5\")\n\nocrModelTorchLstm        = os.path.join(pwd,\"models\",\"ocr-lstm.pth\")\nocrModelTorchDense       = os.path.join(pwd,\"models\",\"ocr-dense.pth\")\nocrModelTorchEng         = os.path.join(pwd,\"models\",\"ocr-english.pth\")\n\nocrModelOpencv           = os.path.join(pwd,\"models\",\"ocr.pb\")\n\n######################OCR模型###################################################\n\nTIMEOUT=30##超时时间\n"
        },
        {
          "name": "crnn",
          "type": "tree",
          "content": null
        },
        {
          "name": "darknet",
          "type": "commit",
          "content": null
        },
        {
          "name": "docker.sh",
          "type": "blob",
          "size": 0.1357421875,
          "content": "##拉取基础镜像\ndocker build -t chineseocr .\n##启动服务\ndocker run -d -p 8080:8080 chineseocr /root/anaconda3/bin/python app.py\n\n\n"
        },
        {
          "name": "main.py",
          "type": "blob",
          "size": 3.49609375,
          "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Sun Aug  4 01:01:37 2019\nmain \n@author: chineseocr\n\"\"\"\nfrom text.detector.detectors import TextDetector\nfrom apphelper.image import rotate_cut_img,sort_box\nimport numpy as np\nfrom PIL import Image\n\nclass TextOcrModel(object):\n    def __init__(self,ocrModel,textModel,angleModel):\n        self.ocrModel = ocrModel\n        self.textModel = textModel\n        self.angleModel = angleModel\n    \n    def detect_angle(self,img):\n        \"\"\"\n        detect text angle in [0,90,180,270]\n        @@img:np.array\n        \"\"\"\n        angle = self.angleModel(img)\n        if angle==90:\n            im = Image.fromarray(img).transpose(Image.ROTATE_90)\n            img = np.array(im)\n        elif angle==180:\n            im = Image.fromarray(img).transpose(Image.ROTATE_180)\n            img = np.array(im)\n        elif angle==270:\n            im = Image.fromarray(img).transpose(Image.ROTATE_270)\n            img = np.array(im)\n        \n        return img,angle\n    \n    def detect_box(self,img,scale=600,maxScale=900):\n        \"\"\"\n        detect text angle in [0,90,180,270]\n        @@img:np.array\n        \"\"\"\n        boxes,scores = self.textModel(img,scale,maxScale)\n        return boxes,scores\n    \n    def box_cluster(self,img,boxes,scores,**args):\n        \n        MAX_HORIZONTAL_GAP= args.get('MAX_HORIZONTAL_GAP',100)\n        MIN_V_OVERLAPS    = args.get('MIN_V_OVERLAPS',0.6)\n        MIN_SIZE_SIM      = args.get('MIN_SIZE_SIM',0.6)\n        textdetector = TextDetector(MAX_HORIZONTAL_GAP,MIN_V_OVERLAPS,MIN_SIZE_SIM)\n        \n        shape = img.shape[:2]\n        TEXT_PROPOSALS_MIN_SCORE     = args.get('TEXT_PROPOSALS_MIN_SCORE',0.7)\n        TEXT_PROPOSALS_NMS_THRESH    = args.get('TEXT_PROPOSALS_NMS_THRESH',0.3)\n        TEXT_LINE_NMS_THRESH         = args.get('TEXT_LINE_NMS_THRESH',0.3)\n        LINE_MIN_SCORE               = args.get('LINE_MIN_SCORE',0.8)\n        \n        boxes,scores = textdetector.detect(boxes,\n                                scores[:, np.newaxis],\n                                shape,\n                                TEXT_PROPOSALS_MIN_SCORE,\n                                TEXT_PROPOSALS_NMS_THRESH,\n                                TEXT_LINE_NMS_THRESH,\n                                LINE_MIN_SCORE\n                                )\n        return boxes,scores\n    \n    \n    def ocr_batch(self,img,boxes,leftAdjustAlph=0.0,rightAdjustAlph=0.0):\n        \"\"\"\n        batch for ocr\n        \"\"\"\n        im = Image.fromarray(img)\n        newBoxes = []\n        for index,box in enumerate(boxes):\n            partImg,box = rotate_cut_img(im,box,leftAdjustAlph,rightAdjustAlph)\n            box['img'] = partImg.convert('L')\n            newBoxes.append(box)\n            \n        res = self.ocrModel(newBoxes)\n        return res\n    \n    \n    def model(self,img,**args):\n        detectAngle        = args.get('detectAngle',False)\n        if detectAngle:\n            img,angle      = self.detect_angle(img)\n        else:\n            angle          = 0\n        scale              = args.get('scale',608)\n        maxScale           = args.get('maxScale',608)\n        boxes,scores       = self.detect_box(img,scale,maxScale)##文字检测\n        boxes,scores       = self.box_cluster(img,boxes,scores,**args)\n        boxes              = sort_box(boxes)\n        leftAdjustAlph     = args.get('leftAdjustAlph',0)\n        rightAdjustAlph    = args.get('rightAdjustAlph',0)\n       \n        res                = self.ocr_batch(img,boxes,leftAdjustAlph,rightAdjustAlph)\n        return res,angle\n        \n    \n"
        },
        {
          "name": "models",
          "type": "tree",
          "content": null
        },
        {
          "name": "ocrjob.py",
          "type": "blob",
          "size": 1.8115234375,
          "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Mon Jul 22 02:02:29 2019\njob\n@author: chineseocr\n\"\"\"\nfrom apphelper.redisbase import redisDataBase\nfrom config import *\nfrom crnn.keys import alphabetChinese,alphabetEnglish\n\nif ocrFlag=='keras':\n    if GPU:\n        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(GPUID)\n        import tensorflow as tf\n        from keras import backend as K\n        config = tf.ConfigProto()\n        config.gpu_options.allocator_type = 'BFC'\n        config.gpu_options.per_process_gpu_memory_fraction = 0.1## GPU最大占用量\n        config.gpu_options.allow_growth = True##GPU是否可动态增加\n        K.set_session(tf.Session(config=config))\n        K.get_session().run(tf.global_variables_initializer())\n\n    else:\n        ##CPU启动\n        os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''\n\nif ocrFlag=='keras':\n    from crnn.network_keras import CRNN\n    if chineseModel:\n        alphabet = alphabetChinese\n        if LSTMFLAG:\n            ocrModel = ocrModelKerasLstm\n        else:\n            ocrModel = ocrModelKerasDense\n    else:\n        ocrModel = ocrModelKerasEng\n        alphabet = alphabetEnglish\n        LSTMFLAG = True\n\nelse:\n    from crnn.network_torch import CRNN\n    if chineseModel:\n        alphabet = alphabetChinese\n        if LSTMFLAG:\n            ocrModel = ocrModelTorchLstm\n        else:\n            ocrModel = ocrModelTorchDense\n\n    else:\n        ocrModel = ocrModelTorchEng\n        alphabet = alphabetEnglish\n        LSTMFLAG = True\n\nnclass = len(alphabet)+1\n\nocr = CRNN( 32, 1, nclass, 256, leakyRelu=False,lstmFlag=LSTMFLAG,GPU=GPU,alphabet=alphabet)\nif os.path.exists(ocrModel):\n    ocr.load_weights(ocrModel)\nelse:\n    print(\"download model or tranform model with tools!\")\n\nif __name__=='__main__':\n    redisJob = redisDataBase()\n    while True:\n        redisJob.get_job(ocr.predict)\n\n"
        },
        {
          "name": "post-demo.py",
          "type": "blob",
          "size": 0.970703125,
          "content": "# -*- coding: utf-8 -*-\n\"\"\"\n@author: lywen\n后台通过接口调用服务，获取OCR识别结果\n\"\"\"\nimport base64\nimport requests\nimport json\ndef read_img_base64(p):\n    with open(p,'rb') as f:\n        imgString = base64.b64encode(f.read())\n    imgString=b'data:image/jpeg;base64,'+imgString\n    return imgString.decode()\n\ndef post(p,billModel='通用OCR'):\n    URL='http://127.0.0.1:8080/ocr'##url地址\n    imgString = read_img_base64(p)\n    headers = {}\n    param      = {'billModel':billModel,##目前支持三种 通用OCR/ 火车票/ 身份证/\n                  'imgString':imgString,\n                      'textAngle':True\n\n}\n    param = json.dumps(param)\n    if 1:\n            req          =  requests.post(URL,data= param,headers=None,timeout=50)\n            data         =  req.content.decode('utf-8')\n            data         =  json.loads(data)\n    else:\n            data =[]\n    print(data)\n\n    \nif __name__=='__main__':\n    p = 'test/idcard-demo.jpeg'\n    post(p,'身份证')\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.1455078125,
          "content": "scipy\nnumpy\njupyter\nipython\neasydict\nopencv-contrib-python\nCython\npillow\nh5py\nlmdb\nmahotas\npandas\nrequests\nweb.py==0.40.dev0\npika\nmatplotlib\nlxml\nbs4"
        },
        {
          "name": "run.py",
          "type": "blob",
          "size": 0.302734375,
          "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Mon Jul 22 02:26:46 2019\nrun ocr job\n@author: chineseocr\n\"\"\"\nimport os\nimport subprocess\njobNum = 4##任务并行数\nfor i in range(jobNum):\n         pid = os.system('nohup python ocrjob.py >/tmp/ocr-{}.log 2>&1 &'.format(i))\n         print(i,pid)\n"
        },
        {
          "name": "setup-cpu.md",
          "type": "blob",
          "size": 0.6044921875,
          "content": "##CPU 环境配置，支持linux\\macOs\nconda create -n chineseocr python=3.6 pip scipy numpy jupyter ipython ##运用conda 创建python环境\nsource activate chineseocr\ncd darknet/ && make && cd ..\npip install easydict opencv-contrib-python==4.0.0.21 Cython h5py lmdb mahotas pandas requests bs4 matplotlib lxml -i https://pypi.tuna.tsinghua.edu.cn/simple/\npip install -U pillow -i https://pypi.tuna.tsinghua.edu.cn/simple/\npip install web.py==0.40.dev0 redis\npip install keras==2.1.5 tensorflow==1.8\n## mac\nconda install pytorch torchvision -c pytorch\n## linux\n## conda install pytorch-cpu torchvision-cpu -c pytorch\n\n"
        },
        {
          "name": "setup.md",
          "type": "blob",
          "size": 0.65625,
          "content": "## 环境配置，支持linux\\macOs      \nconda create -n chineseocr python=3.6 pip scipy numpy jupyter ipython ##运用conda 创建python环境      \nsource activate chineseocr      \ngit submodule init && git submodule update      \npip install easydict opencv-contrib-python==4.0.0.21 Cython h5py lmdb mahotas pandas requests bs4 matplotlib lxml -i https://pypi.tuna.tsinghua.edu.cn/simple/        \npip install -U pillow -i https://pypi.tuna.tsinghua.edu.cn/simple/      \npip install keras==2.1.5 tensorflow==1.8 tensorflow-gpu==1.8      \npip install web.py==0.40.dev0      redis\nconda install pytorch torchvision -c pytorch          \n## pip install torch torchvision   \n"
        },
        {
          "name": "static",
          "type": "tree",
          "content": null
        },
        {
          "name": "templates",
          "type": "tree",
          "content": null
        },
        {
          "name": "test.ipynb",
          "type": "blob",
          "size": 9.18359375,
          "content": "{\n \"cells\": [\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 加载模型\\n\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"import os\\n\",\n    \"import json\\n\",\n    \"import time\\n\",\n    \"import web\\n\",\n    \"import numpy as np\\n\",\n    \"from PIL import Image\\n\",\n    \"from config import *\\n\",\n    \"from apphelper.image import union_rbox,adjust_box_to_origin,base64_to_PIL\\n\",\n    \"from application import trainTicket,idcard \\n\",\n    \"if yoloTextFlag =='keras' or AngleModelFlag=='tf' or ocrFlag=='keras':\\n\",\n    \"    if GPU:\\n\",\n    \"        os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = str(GPUID)\\n\",\n    \"        import tensorflow as tf\\n\",\n    \"        from keras import backend as K\\n\",\n    \"        config = tf.ConfigProto()\\n\",\n    \"        config.gpu_options.allocator_type = 'BFC'\\n\",\n    \"        config.gpu_options.per_process_gpu_memory_fraction = 0.3## GPU最大占用量\\n\",\n    \"        config.gpu_options.allow_growth = True##GPU是否可动态增加\\n\",\n    \"        K.set_session(tf.Session(config=config))\\n\",\n    \"        K.get_session().run(tf.global_variables_initializer())\\n\",\n    \"    \\n\",\n    \"    else:\\n\",\n    \"      ##CPU启动\\n\",\n    \"      os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = ''\\n\",\n    \"\\n\",\n    \"if yoloTextFlag=='opencv':\\n\",\n    \"    scale,maxScale = IMGSIZE\\n\",\n    \"    from text.opencv_dnn_detect import text_detect\\n\",\n    \"elif yoloTextFlag=='darknet':\\n\",\n    \"    scale,maxScale = IMGSIZE\\n\",\n    \"    from text.darknet_detect import text_detect\\n\",\n    \"elif yoloTextFlag=='keras':\\n\",\n    \"    scale,maxScale = IMGSIZE[0],2048\\n\",\n    \"    from text.keras_detect import  text_detect\\n\",\n    \"else:\\n\",\n    \"     print( \\\"err,text engine in keras\\\\opencv\\\\darknet\\\")\\n\",\n    \"     \\n\",\n    \"from text.opencv_dnn_detect import angle_detect\\n\",\n    \"\\n\",\n    \"if ocr_redis:\\n\",\n    \"    ##多任务并发识别\\n\",\n    \"    from helper.redisbase import redisDataBase\\n\",\n    \"    ocr = redisDataBase().put_values\\n\",\n    \"else:   \\n\",\n    \"    from crnn.keys import alphabetChinese,alphabetEnglish\\n\",\n    \"    if ocrFlag=='keras':\\n\",\n    \"        from crnn.network_keras import CRNN\\n\",\n    \"        if chineseModel:\\n\",\n    \"            alphabet = alphabetChinese\\n\",\n    \"            if LSTMFLAG:\\n\",\n    \"                ocrModel = ocrModelKerasLstm\\n\",\n    \"            else:\\n\",\n    \"                ocrModel = ocrModelKerasDense\\n\",\n    \"        else:\\n\",\n    \"            ocrModel = ocrModelKerasEng\\n\",\n    \"            alphabet = alphabetEnglish\\n\",\n    \"            LSTMFLAG = True\\n\",\n    \"            \\n\",\n    \"    elif ocrFlag=='torch':\\n\",\n    \"        from crnn.network_torch import CRNN\\n\",\n    \"        if chineseModel:\\n\",\n    \"            alphabet = alphabetChinese\\n\",\n    \"            if LSTMFLAG:\\n\",\n    \"                ocrModel = ocrModelTorchLstm\\n\",\n    \"            else:\\n\",\n    \"                ocrModel = ocrModelTorchDense\\n\",\n    \"                \\n\",\n    \"        else:\\n\",\n    \"            ocrModel = ocrModelTorchEng\\n\",\n    \"            alphabet = alphabetEnglish\\n\",\n    \"            LSTMFLAG = True\\n\",\n    \"    elif ocrFlag=='opencv':\\n\",\n    \"        from crnn.network_dnn import CRNN\\n\",\n    \"        ocrModel = ocrModelOpencv\\n\",\n    \"        alphabet = alphabetChinese\\n\",\n    \"    else:\\n\",\n    \"        print( \\\"err,ocr engine in keras\\\\opencv\\\\darknet\\\")\\n\",\n    \"     \\n\",\n    \"    nclass = len(alphabet)+1   \\n\",\n    \"    if ocrFlag=='opencv':\\n\",\n    \"        crnn = CRNN(alphabet=alphabet)\\n\",\n    \"    else:\\n\",\n    \"        crnn = CRNN( 32, 1, nclass, 256, leakyRelu=False,lstmFlag=LSTMFLAG,GPU=GPU,alphabet=alphabet)\\n\",\n    \"    if os.path.exists(ocrModel):\\n\",\n    \"        crnn.load_weights(ocrModel)\\n\",\n    \"    else:\\n\",\n    \"        print(\\\"download model or tranform model with tools!\\\")\\n\",\n    \"        \\n\",\n    \"    ocr = crnn.predict_job\\n\",\n    \"    \\n\",\n    \"   \\n\",\n    \"from main import TextOcrModel\\n\",\n    \"\\n\",\n    \"model =  TextOcrModel(ocr,text_detect,angle_detect)\\n\",\n    \"from apphelper.image import xy_rotate_box,box_rotate,solve\\n\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"import cv2\\n\",\n    \"import numpy as np\\n\",\n    \"def plot_box(img,boxes):\\n\",\n    \"    blue = (0, 0, 0) #18\\n\",\n    \"    tmp = np.copy(img)\\n\",\n    \"    for box in boxes:\\n\",\n    \"         cv2.rectangle(tmp, (int(box[0]),int(box[1])), (int(box[2]), int(box[3])), blue, 1) #19\\n\",\n    \"    \\n\",\n    \"    return Image.fromarray(tmp) \\n\",\n    \"\\n\",\n    \"def plot_boxes(img,angle, result,color=(0,0,0)):\\n\",\n    \"    tmp = np.array(img)\\n\",\n    \"    c = color\\n\",\n    \"    h,w = img.shape[:2]\\n\",\n    \"    thick = int((h + w) / 300)\\n\",\n    \"    i = 0\\n\",\n    \"    if angle in [90,270]:\\n\",\n    \"        imgW,imgH = img.shape[:2]\\n\",\n    \"        \\n\",\n    \"    else:\\n\",\n    \"        imgH,imgW= img.shape[:2]\\n\",\n    \"\\n\",\n    \"    for line in result:\\n\",\n    \"        cx =line['cx']\\n\",\n    \"        cy = line['cy']\\n\",\n    \"        degree =line['degree']\\n\",\n    \"        w  = line['w']\\n\",\n    \"        h = line['h']\\n\",\n    \"\\n\",\n    \"        x1,y1,x2,y2,x3,y3,x4,y4 = xy_rotate_box(cx, cy, w, h, degree/180*np.pi)\\n\",\n    \"        \\n\",\n    \"        x1,y1,x2,y2,x3,y3,x4,y4 = box_rotate([x1,y1,x2,y2,x3,y3,x4,y4],angle=(360-angle)%360,imgH=imgH,imgW=imgW)\\n\",\n    \"        cx  =np.mean([x1,x2,x3,x4])\\n\",\n    \"        cy  = np.mean([y1,y2,y3,y4])\\n\",\n    \"        cv2.line(tmp,(int(x1),int(y1)),(int(x2),int(y2)),c,1)\\n\",\n    \"        cv2.line(tmp,(int(x2),int(y2)),(int(x3),int(y3)),c,1)\\n\",\n    \"        cv2.line(tmp,(int(x3),int(y3)),(int(x4),int(y4)),c,1)\\n\",\n    \"        cv2.line(tmp,(int(x4),int(y4)),(int(x1),int(y1)),c,1)\\n\",\n    \"        mess=str(i)\\n\",\n    \"        cv2.putText(tmp, mess, (int(cx), int(cy)),0, 1e-3 * h, c, thick // 2)\\n\",\n    \"        i+=1\\n\",\n    \"    return Image.fromarray(tmp).convert('RGB')\\n\",\n    \"\\n\",\n    \"\\n\",\n    \"def plot_rboxes(img,boxes,color=(0,0,0)):\\n\",\n    \"    tmp = np.array(img)\\n\",\n    \"    c = color\\n\",\n    \"    h,w = img.shape[:2]\\n\",\n    \"    thick = int((h + w) / 300)\\n\",\n    \"    i = 0\\n\",\n    \"\\n\",\n    \"\\n\",\n    \"    for box in boxes:\\n\",\n    \"\\n\",\n    \"        x1,y1,x2,y2,x3,y3,x4,y4 = box\\n\",\n    \"        \\n\",\n    \"        \\n\",\n    \"        cx  =np.mean([x1,x2,x3,x4])\\n\",\n    \"        cy  = np.mean([y1,y2,y3,y4])\\n\",\n    \"        cv2.line(tmp,(int(x1),int(y1)),(int(x2),int(y2)),c,1)\\n\",\n    \"        cv2.line(tmp,(int(x2),int(y2)),(int(x3),int(y3)),c,1)\\n\",\n    \"        cv2.line(tmp,(int(x3),int(y3)),(int(x4),int(y4)),c,1)\\n\",\n    \"        cv2.line(tmp,(int(x4),int(y4)),(int(x1),int(y1)),c,1)\\n\",\n    \"        mess=str(i)\\n\",\n    \"        cv2.putText(tmp, mess, (int(cx), int(cy)),0, 1e-3 * h, c, thick // 2)\\n\",\n    \"        i+=1\\n\",\n    \"    return Image.fromarray(tmp).convert('RGB')\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"import time\\n\",\n    \"from PIL import Image\\n\",\n    \"p = './test/idcard-demo.jpeg'\\n\",\n    \"img = cv2.imread(p)\\n\",\n    \"\\n\",\n    \"h,w = img.shape[:2]\\n\",\n    \"timeTake = time.time()\\n\",\n    \"scale=608\\n\",\n    \"maxScale=2048\\n\",\n    \"\\n\",\n    \"result,angle= model.model(img,\\n\",\n    \"                                    detectAngle=True,##是否进行文字方向检测\\n\",\n    \"                                    scale=scale,\\n\",\n    \"                                    maxScale=maxScale,\\n\",\n    \"                                    MAX_HORIZONTAL_GAP=80,##字符之间的最大间隔，用于文本行的合并\\n\",\n    \"                                    MIN_V_OVERLAPS=0.6,\\n\",\n    \"                                    MIN_SIZE_SIM=0.6,\\n\",\n    \"                                    TEXT_PROPOSALS_MIN_SCORE=0.1,\\n\",\n    \"                                    TEXT_PROPOSALS_NMS_THRESH=0.7,\\n\",\n    \"                                    TEXT_LINE_NMS_THRESH = 0.9,##文本行之间测iou值\\n\",\n    \"                                     LINE_MIN_SCORE=0.1,                                             \\n\",\n    \"                                    leftAdjustAlph=0,##对检测的文本行进行向左延伸\\n\",\n    \"                                    rightAdjustAlph=0.1,##对检测的文本行进行向右延伸\\n\",\n    \"                                   )\\n\",\n    \"        \\n\",\n    \"timeTake = time.time()-timeTake\\n\",\n    \"\\n\",\n    \"print('It take:{}s'.format(timeTake))\\n\",\n    \"for line in result:\\n\",\n    \"    print(line['text'])\\n\",\n    \"plot_boxes(img,angle, result,color=(0,0,0))\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"boxes,scores  = model.detect_box(img,608,2048)\\n\",\n    \"plot_box(img,boxes)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": []\n  }\n ],\n \"metadata\": {\n  \"kernelspec\": {\n   \"display_name\": \"chineseocr\",\n   \"language\": \"python\",\n   \"name\": \"chineseocr\"\n  },\n  \"language_info\": {\n   \"codemirror_mode\": {\n    \"name\": \"ipython\",\n    \"version\": 3\n   },\n   \"file_extension\": \".py\",\n   \"mimetype\": \"text/x-python\",\n   \"name\": \"python\",\n   \"nbconvert_exporter\": \"python\",\n   \"pygments_lexer\": \"ipython3\",\n   \"version\": \"3.6.7\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 2\n}\n"
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "text",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}