{
  "metadata": {
    "timestamp": 1736560797879,
    "page": 490,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQ5MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "NicolasHug/Surprise",
      "stars": 6459,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".coveragerc",
          "type": "blob",
          "size": 0.0361328125,
          "content": "[report]\nomit = surprise/__main__.py\n"
        },
        {
          "name": ".git-blame-ignore-revs",
          "type": "blob",
          "size": 0.1279296875,
          "content": "# Big formatting PR (black, ufmt, etc.)\n# https://github.com/NicolasHug/Surprise/pull/420\n9750b8834efe8718eb4c7d577ac99f0981442cef\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.3828125,
          "content": "*.pyc\n*~\n*.swp\n\ndoc/build\n.ipynb_checkpoints/\n.cache/\n\nscikit_surprise.egg-info/\n\nbuild\ndist/\nsurprise/similarities.c\nsurprise/prediction_algorithms/matrix_factorization.c\nsurprise/prediction_algorithms/optimize_baselines.c\nsurprise/prediction_algorithms/slope_one.c\nsurprise/prediction_algorithms/co_clustering.c\n*.so\n.idea/*\n\nGemfile.lock\n_site\n\n.coverage\ntags\nsettings.json\n\n.pytest_cache\n"
        },
        {
          "name": ".readthedocs.yaml",
          "type": "blob",
          "size": 0.3388671875,
          "content": "# Read the Docs configuration file for Sphinx projects\n# See https://docs.readthedocs.io/en/stable/config-file/v2.html for details\n\n# Required\nversion: 2\n\nbuild:\n  os: ubuntu-22.04\n  tools:\n    python: \"3.12\"\n\nsphinx:\n  configuration: doc/source/conf.py\n\npython:\n  install:\n    - requirements: doc/requirements.txt\n    - method: pip\n      path: .\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 7.6142578125,
          "content": "VERSION 1.1.4\n=============\n\nDate: 05/2024\n\nEnhancements\n------------\n\n* Rely on `pyproject.toml` for packaging to avoid numpy and Cython build-time\n  dependency issues\n* Support Python 3.12\n\nVERSION 1.1.3\n=============\n\nDate: 23/09/2022\n\nBug Fixes\n---------\n\n* Fixed a serialization bug (introduced in 1.1.2) that would make `dump()` fail.\n\nVERSION 1.1.2\n=============\n\nDate: 29/08/2022\nThis version requires Python >= 3.8.\n\nEnhancements\n------------\n\n* Significantly improve performance of SVD (~5X) and SVDpp (~10X) - by [Hercules Smith](https://github.com/ProfHercules)\n* Minor improvements to similarity computations\n* Faster nearest neighbor search\n\nBug Fixes\n---------\n\n* Fixed 'rank_test_fcp' order in grid search's `cv_results`\n* Handle 0 ratings and avoid ZeroDivisionError in NMF\n* (Hopefully) fixes various numpy and Cython compatibility issues with different\n  Python versions (particularly 3.10)\n\nVERSION 1.1.1\n=============\n\nDate: 19/07/2020\n\nMostly doc typos and some minor bug fixes. Future versions (if any)\nwill not support Python 2 anymore.\n\nBug Fixes\n---------\n\n* 'mse' is now available in GridSearCV and RandomizedSearchCV\n* The Jester dataset link was updated\n* Fixed a potential race condition when creating dataset directories\n\n\nVERSION 1.1.0\n=============\n\nDate: 13/11/2019\n\n1.1.0 will be the last stable version with new features. Next versions will\nonly provide bug-fixes, but no new features. (And probably not support\nPython 2 at all).\n\nEnhancements\n------------\n\n* The prompt confirmation can now be disabled when downloading a dataset.\n* The MSE metric has been added.\n\nBug Fixes\n---------\n\n* Fixed a bug where msd and peasron would not properly set the similarity to\n  zero when ``min_support`` wasn't reached.\n\nAPI Changes\n-----------\n\n* Tools that were deprecated before (data.split(), GridSearch, evaluate) are\n  now removed.\n\nVERSION 1.0.6\n=============\n\nDate: 22/04/18\n\nEnhancements\n------------\n\n* Added new RandomizedSearchCV by [David Stevens](https://github.com/whensbrunch)\n* Added verbose option to algorithms using a similarity matrix or baseline\n  computation, to avoid unwanted printed messages.\n* When PredictionImpossible is raised, the prediction is now deferred to\n  default_prediction() method, which can be overridden is child classes. This\n  allows to not always set the default prediction to the average rating, which\n  can be useful for some algorithms (e.g. those working with implicit positive\n  feedback).\n* LeaveOneOut() now accepts a min_n_ratings parameter to make sure users in the\n  trainset have at least min_n_ratings ratings.\n* Dumping is now done with pickle's highest protocol which allows for larger\n  files.\n\nBug Fixes\n---------\n\n* Joblib parameter `n_jobs` now defaults to 1 (no use of multiprocessing).\n  Should fix issues with Windows users.\n* `cross_validate` now returns correct values for training measures (used to\n  return test measures instead).\n\nVERSION 1.0.5\n=============\n\nDate: 09/01/18\n\nEnhancements\n------------\n\n* Cross-validation tools have been entirely reworked. We can now rely on\n  powerful and flexible cross-validation iterators, inspired by scikit-learn's\n  API.\n* the evaluate() method has been replaced by cross-validate which is parallel\n  and can return measures on trainset as well as computation times.\n* GridSearch is now parallel, using joblib.\n* GridSearch now allows to refit an algorithm on the whole dataset.\n* default data directory can now be custom with env variable\n  SURPRISE_DATA_FOLDER\n* the fit() (and train()) methods now return self, which allows one-liners like\n  algo.fit(trainset).test(testset)\n* Algorithms using a random initialization (e.g. SVD, NMF, CoClustering) now\n  have a random_state parameter for seeding the RNG.\n* The getting started guide has been rewritten\n\nAPI Changes\n-----------\n\n* The train() method is now deprecated and replaced by the fit() method (same\n  signature). Calls to train() should still work as before.\n* Using data.split() or accessing the data.folds() generator is deprecated and\n  replaced by the use of the more powefull CV iterators.\n* evaluate() is deprecated and  replaced by model_selection.cross_validate(),\n  which is parallel.\n* GridSearch is deprecated and replaced by model_selection.GridSearchCV()\n\nVERSION 1.0.4\n=============\n\nDate: 20/09/17\n\nEnhancements\n------------\n\n* Added possibility to load a dataset from a pandas dataframe\n* Added Precision and Recall examples to the FAQ ([Maher Malaeb](https://github.com/mahermalaeb))\n* Added a kNN algorithm with normalization by z-score ([Hengji Liu](https://github.com/hengji-liu))\n* kNN algorithms now use heapq instead of list.sort() (computation time\n  enhancement for large datasets).\n\nFixes\n-----\n\n* Prediciont.__str__() when r_ui is None\n* GridSearch for dict parameters is now working as expected\n\nAPI Changes\n-----------\n\n* param_grid for GridSearch is now slightly different for dict parameters (see\n  note on [the\n  docs](https://surprise.readthedocs.io/en/stable/getting_started.html#tune-algorithm-parameters-with-gridsearch)).\n\nVERSION 1.0.3\n=============\n\nDate: 03/05/17\n\nEnhancements\n------------\n\n* Added FAQ in the doc\n* Added the possibility to retrieve the k nearest neighbors of a user or an\n  item.\n* Changed the dumping process a bit (see API changes). Plus, dumps can now be\n  loaded.\n* Added possibility to build a testset from the ratings of a training set\n* Added inner-to-raw id conversion in the Trainset class\n* The r_ui parameter of the predict() method is now optional\n\nFixes\n-----\n* Fixed verbosity of the evaluate function\n* Corrected prediction when only user (or only item) is unknown in SVD and NMF\n  algorithms. Thanks to kenoung!\n* Corrected factor vectors initialization of SVD algorithms. Thanks to\n  adideshp!\n\nAPI Changes\n-----------\n\n* The dump() method now dumps a list of predition (optional) and an algorithm\n  (optional as well). The algorithm is now a real algorithm object. The\n  trainset is not dumped anymore as it is already part of the algorithm anyway.\n* The dump() method is now part of the dump namespace, and not the global\n  namespace (so it is accessed by surprise.dump.dump)\n\nVERSION 1.0.2\n=============\n\nDate: 04/01/17\n\nJust a minor change so that README.md is converted to rst for better rendering\non PyPI.\n\nVERSION 1.0.1\n=============\n\nDate: 02/01/17\n\nEnhancements\n------------\n\n* Added the GridSearch feature, by [Maher](https://github.com/mahermalaeb)\n* Added a 'clip' option to the predict() method\n* Added NMF algorithm\n* Added entry point for better command line usage.\n* Added CoClustering algorithm.\n* Added SlopeOne algorithm.\n* Added Probabilistic Matrix Factorization as an option SVD\n* Cythonized Baseline Computation\n\nOther\n-----\n\n* Surprise is now a scikit!\n* Changed license to BSD\n* Six is now a dependency\n\nVERSION 1.0.0\n=============\n\nDate: 22/11/16\n\n* Changed name from recsys to surprise\n* Improved printing of accuracy measures.\n* Added version number.\n* Rewrote the the __main__.py\n\nVERSION 0.0.4\n=============\n\nDate: 15/11/16\n\nEnhancements\n------------\n\n* Added notebooks for comparing and evaluating algorithm performances\n* Better use of setup.py\n* Added a min_support parameter to the similarity measures.\n* Added a min_k parameter to the KNN algorithms.\n* The similarity matrix and baselines are now returned.\n* You can now train on a whole training set without test set.\n* The estimate method can return a tuple with prediction details.\n* Added SVD and SVD++ algorithms.\n* Removed all the x/y vs user/item stuff. That was useless for most algorithms.\n\n\nAPI Changes\n-----------\n\n* Removed the @property decorator for many iterators.\n* It's now up to the algorithms to decide if they can or cannot make a\n\tprediction.\n\nVERSION 0.0.3\n=============\n\nDate: 25/10/16\n\n* Added support for Python 2\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 2.3759765625,
          "content": "Contributing to Surprise\n========================\n\nDisclamer: please note that starting from version 1.1.0, only bugfixes and\ndocumentation improvements are considered. We will not accept new features.\n\nBefore submitting a new pull request, please make sure that:\n\n* Your code is [clean](https://www.youtube.com/watch?v=wf-BqAjZb8M),\n  [pythonic](https://www.youtube.com/watch?v=OSGv2VnC0go), well commented and\n  also well documented (see below for building the docs).\n* The tests are passing. Also, write some tests for the changes you're\n  proposing. If you're not willing to write tests, it's best not to submit a PR\n  (it's just a waste of time for everyone).\n* Your code follows [PEP 8](https://www.python.org/dev/peps/pep-0008/) as much\n  as possible. Coding style is automatically checked when tests are run. About\n  line length: it's best to respect to 80 columns constraint, but tests will\n  pass as long as the length is less than 88.\n* For new prediction algorithms or similarity metrics, please submit a\n  relevent benchmark outlining the performance of the new feature (in terms of\n  accuracy, computation time, etc.). You can take a look at\n  [`examples/benchmarks`](https://github.com/NicolasHug/Surprise/blob/master/examples/benchmark.py)\n  for inspiration.\n\nSet up\n------\n\nClone the repo then:\n\n    pip install -e .  # the --no-build-isolation flag might help\n\nAny change to the code should now be immediately reflected during execution. If\nyou're modifying Cython code (`.pyx` files), you'll need to compile the code in\norder to see the changes. This can be achieved by running the command above\nagain.\n\nRunning and writing tests\n-------------------------\n\nOur testing tool is [pytest](https://doc.pytest.org/en/latest/). Running the tests is as\nsimple as running\n\n    pytest\n\nin the root directory.\n\nFor writing new tests, check out pytest getting started guide and / or take\ninspiration from the current tests in the `tests` directory.\n\n\nBuilding the docs locally\n-------------------------\n\nThe docs can be compiled with\n\n    cd doc\n    pip install -r requirements.txt\n    make html\n\nYou can check the results in `doc/build/html`. Please make sure that the docs\ncompile without errors. Run `make clean` from time to time in order to avoid\nhidden warnings. You can check spelling mistakes by running\n\n    make spelling\n\nLegit words that are not recognized can be added in the\n`source/spelling_wordlist.txt` file.\n"
        },
        {
          "name": "LICENSE.md",
          "type": "blob",
          "size": 1.4599609375,
          "content": "Copyright (c) 2016, Nicolas Hug\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its contributors\n   may be used to endorse or promote products derived from this software\n   without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.181640625,
          "content": "include README.md\ninclude LICENSE.md\nrecursive-include doc *\nrecursive-include examples *\nrecursive-include surprise *.pyx\nrecursive-exclude surprise *.c\nrecursive-exclude surprise *.so\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 12.4609375,
          "content": "[![GitHub version](https://badge.fury.io/gh/nicolashug%2FSurprise.svg)](https://badge.fury.io/gh/nicolashug%2FSurprise)\n[![Documentation Status](https://readthedocs.org/projects/surprise/badge/?version=stable)](https://surprise.readthedocs.io/en/stable/?badge=stable)\n[![python versions](https://img.shields.io/badge/python-3.8+-blue.svg)](https://surpriselib.com)\n[![License](https://img.shields.io/badge/License-BSD%203--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause)\n[![DOI](https://joss.theoj.org/papers/10.21105/joss.02174/status.svg)](https://doi.org/10.21105/joss.02174)\n\n[![logo](./logo_black.svg)](https://surpriselib.com)\n\nOverview\n--------\n\n[Surprise](https://surpriselib.com) is a Python\n[scikit](https://projects.scipy.org/scikits.html) for building and analyzing\nrecommender systems that deal with explicit rating data.\n\n[Surprise](https://surpriselib.com) **was designed with the\nfollowing purposes in mind**:\n\n- Give users perfect control over their experiments. To this end, a strong\n  emphasis is laid on\n  [documentation](https://surprise.readthedocs.io/en/stable/index.html), which we\n  have tried to make as clear and precise as possible by pointing out every\n  detail of the algorithms.\n- Alleviate the pain of [Dataset\n  handling](https://surprise.readthedocs.io/en/stable/getting_started.html#load-a-custom-dataset).\n  Users can use both *built-in* datasets\n  ([Movielens](https://grouplens.org/datasets/movielens/),\n  [Jester](https://eigentaste.berkeley.edu/dataset/)), and their own *custom*\n  datasets.\n- Provide various ready-to-use [prediction\n  algorithms](https://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html)\n  such as [baseline\n  algorithms](https://surprise.readthedocs.io/en/stable/basic_algorithms.html),\n  [neighborhood\n  methods](https://surprise.readthedocs.io/en/stable/knn_inspired.html), matrix\n  factorization-based (\n  [SVD](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD),\n  [PMF](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#unbiased-note),\n  [SVD++](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVDpp),\n  [NMF](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.NMF)),\n  and [many\n  others](https://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html).\n  Also, various [similarity\n  measures](https://surprise.readthedocs.io/en/stable/similarities.html)\n  (cosine, MSD, pearson...) are built-in.\n- Make it easy to implement [new algorithm\n  ideas](https://surprise.readthedocs.io/en/stable/building_custom_algo.html).\n- Provide tools to [evaluate](https://surprise.readthedocs.io/en/stable/model_selection.html),\n  [analyse](https://nbviewer.jupyter.org/github/NicolasHug/Surprise/tree/master/examples/notebooks/KNNBasic_analysis.ipynb/)\n  and\n  [compare](https://nbviewer.jupyter.org/github/NicolasHug/Surprise/blob/master/examples/notebooks/Compare.ipynb)\n  the algorithms' performance. Cross-validation procedures can be run very\n  easily using powerful CV iterators (inspired by\n  [scikit-learn](https://scikit-learn.org/) excellent tools), as well as\n  [exhaustive search over a set of\n  parameters](https://surprise.readthedocs.io/en/stable/getting_started.html#tune-algorithm-parameters-with-gridsearchcv).\n\n\nThe name *SurPRISE* (roughly :) ) stands for *Simple Python RecommendatIon\nSystem Engine*.\n\nPlease note that surprise does not support implicit ratings or content-based\ninformation.\n\n\nGetting started, example\n------------------------\n\nHere is a simple example showing how you can (down)load a dataset, split it for\n5-fold cross-validation, and compute the MAE and RMSE of the\n[SVD](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD)\nalgorithm.\n\n\n```python\nfrom surprise import SVD\nfrom surprise import Dataset\nfrom surprise.model_selection import cross_validate\n\n# Load the movielens-100k dataset (download it if needed).\ndata = Dataset.load_builtin('ml-100k')\n\n# Use the famous SVD algorithm.\nalgo = SVD()\n\n# Run 5-fold cross-validation and print results.\ncross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n```\n\n**Output**:\n\n```\nEvaluating RMSE, MAE of algorithm SVD on 5 split(s).\n\n                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \nRMSE (testset)    0.9367  0.9355  0.9378  0.9377  0.9300  0.9355  0.0029  \nMAE (testset)     0.7387  0.7371  0.7393  0.7397  0.7325  0.7375  0.0026  \nFit time          0.62    0.63    0.63    0.65    0.63    0.63    0.01    \nTest time         0.11    0.11    0.14    0.14    0.14    0.13    0.02    \n```\n\n[Surprise](https://surpriselib.com) can do **much** more (e.g,\n[GridSearchCV](https://surprise.readthedocs.io/en/stable/getting_started.html#tune-algorithm-parameters-with-gridsearchcv))!\nYou'll find [more usage\nexamples](https://surprise.readthedocs.io/en/stable/getting_started.html) in the\n[documentation ](https://surprise.readthedocs.io/en/stable/index.html).\n\n\nBenchmarks\n----------\n\nHere are the average RMSE, MAE and total execution time of various algorithms\n(with their default parameters) on a 5-fold cross-validation procedure. The\ndatasets are the [Movielens](https://grouplens.org/datasets/movielens/) 100k and\n1M datasets. The folds are the same for all the algorithms. All experiments are\nrun on a laptop with an intel i5 11th Gen 2.60GHz. The code\nfor generating these tables can be found in the [benchmark\nexample](https://github.com/NicolasHug/Surprise/tree/master/examples/benchmark.py).\n\n| [Movielens 100k](http://grouplens.org/datasets/movielens/100k)                                                                         |   RMSE |   MAE | Time    |\n|:---------------------------------------------------------------------------------------------------------------------------------------|-------:|------:|:--------|\n| [SVD](http://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD)      |  0.934 | 0.737 | 0:00:06 |\n| [SVD++ (cache_ratings=False)](http://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVDpp)  |  0.919 | 0.721 | 0:01:39 |\n| [SVD++ (cache_ratings=True)](http://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVDpp)  |  0.919 | 0.721 | 0:01:22 |\n| [NMF](http://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.NMF)      |  0.963 | 0.758 | 0:00:06 |\n| [Slope One](http://surprise.readthedocs.io/en/stable/slope_one.html#surprise.prediction_algorithms.slope_one.SlopeOne)                 |  0.946 | 0.743 | 0:00:09 |\n| [k-NN](http://surprise.readthedocs.io/en/stable/knn_inspired.html#surprise.prediction_algorithms.knns.KNNBasic)                        |  0.98  | 0.774 | 0:00:08 |\n| [Centered k-NN](http://surprise.readthedocs.io/en/stable/knn_inspired.html#surprise.prediction_algorithms.knns.KNNWithMeans)           |  0.951 | 0.749 | 0:00:09 |\n| [k-NN Baseline](http://surprise.readthedocs.io/en/stable/knn_inspired.html#surprise.prediction_algorithms.knns.KNNBaseline)            |  0.931 | 0.733 | 0:00:13 |\n| [Co-Clustering](http://surprise.readthedocs.io/en/stable/co_clustering.html#surprise.prediction_algorithms.co_clustering.CoClustering) |  0.963 | 0.753 | 0:00:06 |\n| [Baseline](http://surprise.readthedocs.io/en/stable/basic_algorithms.html#surprise.prediction_algorithms.baseline_only.BaselineOnly)   |  0.944 | 0.748 | 0:00:02 |\n| [Random](http://surprise.readthedocs.io/en/stable/basic_algorithms.html#surprise.prediction_algorithms.random_pred.NormalPredictor)    |  1.518 | 1.219 | 0:00:01 |\n\n\n| [Movielens 1M](https://grouplens.org/datasets/movielens/1m)                                                                             |   RMSE |   MAE | Time    |\n|:----------------------------------------------------------------------------------------------------------------------------------------|-------:|------:|:--------|\n| [SVD](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD)      |  0.873 | 0.686 | 0:01:07 |\n| [SVD++ (cache_ratings=False)](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVDpp)  |  0.862 | 0.672 | 0:41:06 |\n| [SVD++ (cache_ratings=True)](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVDpp)  |  0.862 | 0.672 | 0:34:55 |\n| [NMF](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.NMF)      |  0.916 | 0.723 | 0:01:39 |\n| [Slope One](http://surprise.readthedocs.io/en/stable/slope_one.html#surprise.prediction_algorithms.slope_one.SlopeOne)                 |  0.907 | 0.715 | 0:02:31 |\n| [k-NN](http://surprise.readthedocs.io/en/stable/knn_inspired.html#surprise.prediction_algorithms.knns.KNNBasic)                        |  0.923 | 0.727 | 0:05:27 |\n| [Centered k-NN](http://surprise.readthedocs.io/en/stable/knn_inspired.html#surprise.prediction_algorithms.knns.KNNWithMeans)           |  0.929 | 0.738 | 0:05:43 |\n| [k-NN Baseline](http://surprise.readthedocs.io/en/stable/knn_inspired.html#surprise.prediction_algorithms.knns.KNNBaseline)            |  0.895 | 0.706 | 0:05:55 |\n| [Co-Clustering](http://surprise.readthedocs.io/en/stable/co_clustering.html#surprise.prediction_algorithms.co_clustering.CoClustering) |  0.915 | 0.717 | 0:00:31 |\n| [Baseline](http://surprise.readthedocs.io/en/stable/basic_algorithms.html#surprise.prediction_algorithms.baseline_only.BaselineOnly)   |  0.909 | 0.719 | 0:00:19 |\n| [Random](http://surprise.readthedocs.io/en/stable/basic_algorithms.html#surprise.prediction_algorithms.random_pred.NormalPredictor)    |  1.504 | 1.206 | 0:00:19 |\n\nInstallation\n------------\n\nWith pip (you'll need a C compiler. Windows users might prefer using conda):\n\n    $ pip install scikit-surprise\n\nWith conda:\n\n    $ conda install -c conda-forge scikit-surprise\n\nFor the latest version, you can also clone the repo and build the source\n(you'll first need [Cython](https://cython.org/) and\n[numpy](https://www.numpy.org/)):\n\n    $ git clone https://github.com/NicolasHug/surprise.git\n    $ cd surprise\n    $ pip install .\n\nLicense and reference\n---------------------\n\nThis project is licensed under the [BSD\n3-Clause](https://opensource.org/licenses/BSD-3-Clause) license, so it can be\nused for pretty much everything, including commercial applications.\n\nI'd love to know how Surprise is useful to you. Please don't hesitate to open\nan issue and describe how you use it!\n\nPlease make sure to cite the\n[paper](https://joss.theoj.org/papers/10.21105/joss.02174) if you use\nSurprise for your research:\n\n    @article{Hug2020,\n      doi = {10.21105/joss.02174},\n      url = {https://doi.org/10.21105/joss.02174},\n      year = {2020},\n      publisher = {The Open Journal},\n      volume = {5},\n      number = {52},\n      pages = {2174},\n      author = {Nicolas Hug},\n      title = {Surprise: A Python library for recommender systems},\n      journal = {Journal of Open Source Software}\n    }\n\nContributors\n------------\n\nThe following persons have contributed to [Surprise](https://surpriselib.com):\n\nashtou, Abhishek Bhatia, bobbyinfj, caoyi, Chieh-Han Chen,  Raphael-Dayan, Олег\nДемиденко, Charles-Emmanuel Dias, dmamylin, Lauriane Ducasse, Marc Feger,\nfranckjay, Lukas Galke, Tim Gates, Pierre-François Gimenez, Zachary Glassman,\nJeff Hale, Nicolas Hug, Janniks, jyesawtellrickson, Doruk Kilitcioglu, Ravi Raju\nKrishna, lapidshay, Hengji Liu, Ravi Makhija, Maher Malaeb, Manoj K, James\nMcNeilis, Naturale0, nju-luke, Pierre-Louis Pécheux, Jay Qi, Lucas Rebscher,\nCraig Rodrigues, Skywhat, Hercules Smith, David Stevens, Vesna Tanko,\nTrWestdoor, Victor Wang, Mike Lee Williams, Jay Wong, Chenchen Xu, YaoZh1918.\n\nThanks a lot :) !\n\nDevelopment Status\n------------------\n\nStarting from version 1.1.0 (September 2019), I will only maintain the package,\nprovide bugfixes, and perhaps sometimes perf improvements. I have less time to\ndedicate to it now, so I'm unabe to consider new features.\n\nFor bugs, issues or questions about [Surprise](https://surpriselib.com), please\navoid sending me emails; I will most likely not be able to answer). Please use\nthe GitHub [project page](https://github.com/NicolasHug/Surprise) instead, so\nthat others can also benefit from it.\n"
        },
        {
          "name": "TODO.md",
          "type": "blob",
          "size": 5.56640625,
          "content": "TODO\n====\n\n* remove offset from everywhere (Reader, Trainset, test(), predict()...). Make\n  a test to make sure that zero ratings are handled correctly. Right now we\n  store ratings as defaultdict(list) in ur and ir, so there's no problem. Maybe\n  it will change in the future, we would have to find a workaround.\n* rating_scale should be specified on dataset creation: load_from_file,\n  load_from_folds, load_from_df. Deprecate its use from rating but fall back to\n  it if it has only been specified here.\n* Dataset.binarize should change rating_scale to something else. Maybe 'unary'?\n* about clip: don't clip if rating_scale is 'unary'?\n* test(), cross_validate() and GridSearch.fit() should probably allow a\n  'predict_params' parameter?\n* What about a 'dont_clip' attribute in algorithms that could take precedence\n  over the clipping behaviour? What about just overriding predict() in the\n  child classes?\n\n\n* Document get_dataset_dir()...\n* make some filtering dataset tools, like remove users/items with less/more\n  than n ratings, binarize a dataset, etc...\n* then implement MFBPR and see how it goes\n* Allow incremental updates for some algorithms\n\nDone:\n-----\n\n* Grid search now has the refit param.\n* Grid search and cross_validate now allow return_train_score\n* Make all fit methods return self. Update docs on building custom algorithms\n* Update doc of MF algo to indicate how to retrieve latent factors.\n* all algorithms using random initialization now have a random_state parameter.\n* CV iterators:\n  - Write basic CV iterators\n  - evaluate -> rewrite to use CV iterators. Rename it into cross_validate.\n  - Same for GridSearch. Keep it in a model_selection module like scikit-learn\n    so that we can keep the old deprecated version. \n  - Make cross validation parallel with joblib\n  - Add deprecation warnings for evaluate and GridSearch()\n  - handle the cv_results attribute for grid search\n  - (re)write all verbose settings for gridsearch and cross_validate\n  - Change examples so they use CV iterators and the new gridsearch and\n    cross_validate\n  - indicate in docs that split(), folds(), evaluate() and gridsearch() are\n    deprecated\n  - Write comments, docstring and update all docs\n  - Update main and command-line usage doc in getting started.rst\n* Allow to change data folder from env variable\n* Complete FAQ\n* Change the dumping machinery to be more consistent \n* Allow to test on the trainset\n* make bibtex entry\n* Verbosity of gridsearch still prints stuff because of evaluate. Fix that.\n* Make the r_ui param of predict optional\n* Put some PredictionImpossible messages in every algo\n* allow a 'clip' option to the predict method? Also, describe r_min and r_max\n* configure entrypoints to use surprise directly from command line\n* Allow a 'biased' option in the SVD algo. If true, use baselines, if False,\n  don't. It should be pretty easy to do.\n* create option in __main__ to clean the .recsys directory. Actually, the\n  __main__ module should be entirely reviewed.\n* when dumping, we should dump all the algorithm parameter. Use __dict__ ?\n* do something about the generators Python 2 vs 3 (range, dict.items(), etc...)\n* should a Prediction output the raw id or the inner id? Right now it's the\n  inner id. Maybe sort this out when working on the comparison tools.\n* allow the perf dict returned by evaluate to accept keys with lower/upper\n  case for retarded users such as me.\n* Add a 'min_support' parameter to sim_options? Add a min_k to knns?\n* Do something about the user_based stuff. It should be better. Check knns BTW.\n* Do something about unknown users and unknown items, i.e. users or items that\n  have no rating in the trainset. Right now, the predict method checks if the\n  name starts with 'unknown' but this is shiiite because it's dependent on the\n  construct_trainset method, which is sometimes never called (so the raw2inner\n  stuff will come in play somehow). Plus, It should be up to the algorithms to\n  choose whether it can (or can't) make a prediction even if user or item is\n  unknown.\n* remove kwargs : done where useless.\n* say something quick about baseline computation (when not matrix facto) \n* Matrix facto algo\n* allow the 'estimate' method to return some details about prediction (such as\n  the number of neighbors for a KNN)\n* allow to train on a SINGLE file without test set, and let user query for some\n  predictions\n* write tuto for using only predict() (and not test)\n* maybe clean a little all the dataset machinery? Plus, are the\n  raw2inner_id_users and raw2inner_id_items worth keeping? May be for analysing\n  tools, I don't know right now. EDIT: yes, we need to keep them, simply\n  because the similarity computation can only work with integer as indexes\n  (numpy arrays).\n* sort out this warning issue coming from cython\n* say something about the sim > 0 in knns algos\n* get less restrictive requirements.txt\n* write the custom algorithm tutorial\n* improve test coverage\n* add the cool stickers on the readme just like scikit learn\n* set up travis\n* keep on testing\n* keep on documenting and commenting code\n* extensively test the reader class, + check that the doc is OK for reader\n* set up a nice API (looks ok now)\n* handle algo-specific or similarity-specific parameters (such as 'k' for knn,\n  regularization parameters, shrinkage paramaters, etc.) in an appropriate\n  manner, rather than pass them all to constructors... UPDATE: ok so using\n  kwargs like matplotlib.pyplot might be enough. should we create a\n  'Similarity' class?\n* clean the main and all the dataset handling stuff (still needs to be\n  polished)\n* rewrite this TODO in english\n* create a proper project structure\n* from camelCase to snake\\_case\n"
        },
        {
          "name": "doc",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "lint.sh",
          "type": "blob",
          "size": 0.5458984375,
          "content": "#!/bin/sh\n\nset -ex\n\nblack --version  # 22.6.0 (on Python 3.9)\nusort --version  # 1.0.4\nflake8 --version  # 5.0.4\n\nusort format surprise\nusort format tests\nusort format examples\nusort format setup.py\n\nblack surprise\nblack tests\nblack examples\nblack setup.py\n\nflake8 --max-line-length 88 --ignore E203,E402,W503,W504,F821,E501 surprise\nflake8 --max-line-length 88 --ignore E203,E402,W503,W504,F821,E501 tests\nflake8 --max-line-length 88 --ignore E203,E402,W503,W504,F821,E501 examples\nflake8 --max-line-length 88 --ignore E203,E402,W503,W504,F821,E501 setup.py\n"
        },
        {
          "name": "logo_black.svg",
          "type": "blob",
          "size": 7.07421875,
          "content": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!-- Generator: Adobe Illustrator 18.0.0, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->\n\n<svg\n   xmlns:dc=\"http://purl.org/dc/elements/1.1/\"\n   xmlns:cc=\"http://creativecommons.org/ns#\"\n   xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n   xmlns:svg=\"http://www.w3.org/2000/svg\"\n   xmlns=\"http://www.w3.org/2000/svg\"\n   xmlns:sodipodi=\"http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd\"\n   xmlns:inkscape=\"http://www.inkscape.org/namespaces/inkscape\"\n   version=\"1.1\"\n   id=\"Calque_1\"\n   x=\"0px\"\n   y=\"0px\"\n   viewBox=\"0 0 599.22321 141.5\"\n   enable-background=\"new 0 0 946 371\"\n   xml:space=\"preserve\"\n   sodipodi:docname=\"logo_black.svg\"\n   width=\"599.22321\"\n   height=\"141.5\"\n   inkscape:version=\"0.92.2 2405546, 2018-03-11\"><metadata\n   id=\"metadata41\"><rdf:RDF><cc:Work\n       rdf:about=\"\"><dc:format>image/svg+xml</dc:format><dc:type\n         rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\" /><dc:title></dc:title></cc:Work></rdf:RDF></metadata><defs\n   id=\"defs39\" /><sodipodi:namedview\n   pagecolor=\"#ffffff\"\n   bordercolor=\"#666666\"\n   borderopacity=\"1\"\n   objecttolerance=\"10\"\n   gridtolerance=\"10\"\n   guidetolerance=\"10\"\n   inkscape:pageopacity=\"0\"\n   inkscape:pageshadow=\"2\"\n   inkscape:window-width=\"1918\"\n   inkscape:window-height=\"1058\"\n   id=\"namedview37\"\n   showgrid=\"false\"\n   fit-margin-top=\"0\"\n   fit-margin-left=\"0\"\n   fit-margin-right=\"0\"\n   fit-margin-bottom=\"0\"\n   inkscape:zoom=\"0.35623679\"\n   inkscape:cx=\"-191.92493\"\n   inkscape:cy=\"47.1\"\n   inkscape:window-x=\"0\"\n   inkscape:window-y=\"20\"\n   inkscape:window-maximized=\"0\"\n   inkscape:current-layer=\"Calque_1\" />\n<g\n   id=\"texte_noir\"\n   transform=\"translate(-182.1,-91.1)\">\n\t<path\n   d=\"m 219.6,137.7 c -2.7,0 -4.4,1 -4.4,2.6 0,7.3 40.6,4.4 40.6,30.7 0,16.2 -13.9,26.6 -35.5,26.6 -14.4,0 -27.3,-3.7 -38.2,-11.2 l 9.7,-20 c 10.4,6.4 20.2,9.7 28.9,9.7 3,0 4.9,-0.9 4.9,-2.3 0,-6.9 -39.8,-3.9 -39.8,-30.3 0,-16.4 13.6,-27 34.5,-27 12.4,0 24.6,3.3 36.3,9.9 L 246,146.2 c -11.6,-5.7 -20.4,-8.5 -26.4,-8.5 z\"\n   id=\"path2\"\n   inkscape:connector-curvature=\"0\" />\n\t<path\n   d=\"m 301.9,177.3 c 6.4,0 11.3,-5 11.3,-13 v -46.1 h 26 v 46.1 c 0,21.2 -14.7,35 -37.4,35 -22.9,0 -38,-13.8 -38,-35 v -46.1 h 26 v 46.1 c 0,7.8 5.6,13 12.1,13 z\"\n   id=\"path4\"\n   inkscape:connector-curvature=\"0\" />\n\t<path\n   d=\"m 407.7,116.5 v 29 c -14.4,-2.1 -23.9,3 -23.9,13.3 v 37.3 h -32.2 v -78.2 h 32.2 v 11.4 c 5.4,-8.1 13.7,-12.8 23.9,-12.8 z\"\n   id=\"path6\"\n   inkscape:connector-curvature=\"0\" />\n\t<path\n   d=\"m 494,157.5 c 0,24.2 -12.1,39.8 -30.8,39.8 -7.4,0 -13.7,-3.3 -18.2,-9.2 v 35.8 h -28.3 v -106 H 445 v 7.9 c 4.4,-5.9 10.4,-9 17.5,-9 19.1,0 31.5,16 31.5,40.7 z m -28.5,-0.8 c 0,-9.2 -4,-15.2 -10.3,-15.2 -6.2,0 -10.2,6 -10.2,15.2 0,9.2 4,15.2 10.2,15.2 6.2,-0.1 10.3,-6.1 10.3,-15.2 z\"\n   id=\"path8\"\n   inkscape:connector-curvature=\"0\" />\n\t<path\n   d=\"m 559.8,116.5 v 29 c -14.4,-2.1 -23.9,3 -23.9,13.3 v 37.3 H 503.7 V 117.9 H 536 v 11.4 c 5.4,-8.1 13.7,-12.8 23.8,-12.8 z\"\n   id=\"path10\"\n   inkscape:connector-curvature=\"0\" />\n\t<path\n   stroke-miterlimit=\"10\"\n   d=\"m 574.5,217.4 c 0,-4.1 1.1,-7.1 3.4,-9.1 2.3,-2 5.9,-3 11,-3 5.1,0 8.8,1 11.1,3.1 2.3,2 3.5,5.1 3.5,9.1 0,8.1 -4.9,12.1 -14.6,12.1 -4.9,0 -8.5,-1 -10.9,-3 -2.4,-2 -3.5,-5.1 -3.5,-9.2 z m 0.7,-21.3 v -102 h 27.7 v 102.1 h -27.7 z\"\n   id=\"path12\"\n   inkscape:connector-curvature=\"0\"\n   style=\"fill:none;stroke:#000000;stroke-width:6;stroke-miterlimit:10\" />\n\t<path\n   d=\"m 653.1,137.7 c -2.7,0 -4.4,1 -4.4,2.6 0,7.3 40.6,4.4 40.6,30.7 0,16.2 -13.9,26.6 -35.5,26.6 -14.4,0 -27.3,-3.7 -38.2,-11.2 l 9.7,-20 c 10.4,6.4 20.2,9.7 28.9,9.7 3,0 4.9,-0.9 4.9,-2.3 0,-6.9 -39.8,-3.9 -39.8,-30.3 0,-16.4 13.6,-27 34.5,-27 12.4,0 24.6,3.3 36.3,9.9 l -10.6,19.9 c -11.5,-5.8 -20.4,-8.6 -26.4,-8.6 z\"\n   id=\"path14\"\n   inkscape:connector-curvature=\"0\" />\n\t<path\n   d=\"m 781.2,164.2 h -50.9 c 2.1,6.1 6.7,9.3 13,9.3 5.4,0 11,-2.4 15.9,-7 l 16.7,16.4 c -8.3,9.2 -20.3,14.3 -35.5,14.3 -26.7,0 -42.6,-15.7 -42.6,-39.9 0,-24.7 16.6,-40.6 41.8,-40.6 27.3,0.1 43.3,18.7 41.6,47.5 z m -41.3,-26 c -5.6,0 -9,4.6 -10.3,11.2 H 749 c 0.5,-6.5 -3.5,-11.2 -9.1,-11.2 z\"\n   id=\"path16\"\n   inkscape:connector-curvature=\"0\" />\n</g>\n<g\n   id=\"texte_blanc\"\n   display=\"none\"\n   style=\"display:none\"\n   transform=\"translate(-182.1,-91.1)\">\n\t<path\n   display=\"inline\"\n   d=\"m 219.6,137.7 c -2.7,0 -4.4,1 -4.4,2.6 0,7.3 40.6,4.4 40.6,30.7 0,16.2 -13.9,26.6 -35.5,26.6 -14.4,0 -27.3,-3.7 -38.2,-11.2 l 9.7,-20 c 10.4,6.4 20.2,9.7 28.9,9.7 3,0 4.9,-0.9 4.9,-2.3 0,-6.9 -39.8,-3.9 -39.8,-30.3 0,-16.4 13.6,-27 34.5,-27 12.4,0 24.6,3.3 36.3,9.9 L 246,146.2 c -11.6,-5.7 -20.4,-8.5 -26.4,-8.5 z\"\n   id=\"path19\"\n   inkscape:connector-curvature=\"0\"\n   style=\"display:inline;fill:#ffffff\" />\n\t<path\n   display=\"inline\"\n   d=\"m 301.9,177.3 c 6.4,0 11.3,-5 11.3,-13 v -46.1 h 26 v 46.1 c 0,21.2 -14.7,35 -37.4,35 -22.9,0 -38,-13.8 -38,-35 v -46.1 h 26 v 46.1 c 0,7.8 5.6,13 12.1,13 z\"\n   id=\"path21\"\n   inkscape:connector-curvature=\"0\"\n   style=\"display:inline;fill:#ffffff\" />\n\t<path\n   display=\"inline\"\n   d=\"m 407.7,116.5 v 29 c -14.4,-2.1 -23.9,3 -23.9,13.3 v 37.3 h -32.2 v -78.2 h 32.2 v 11.4 c 5.4,-8.1 13.7,-12.8 23.9,-12.8 z\"\n   id=\"path23\"\n   inkscape:connector-curvature=\"0\"\n   style=\"display:inline;fill:#ffffff\" />\n\t<path\n   display=\"inline\"\n   d=\"m 494,157.5 c 0,24.2 -12.1,39.8 -30.8,39.8 -7.4,0 -13.7,-3.3 -18.2,-9.2 v 35.8 h -28.3 v -106 H 445 v 7.9 c 4.4,-5.9 10.4,-9 17.5,-9 19.1,0 31.5,16 31.5,40.7 z m -28.5,-0.8 c 0,-9.2 -4,-15.2 -10.3,-15.2 -6.2,0 -10.2,6 -10.2,15.2 0,9.2 4,15.2 10.2,15.2 6.2,-0.1 10.3,-6.1 10.3,-15.2 z\"\n   id=\"path25\"\n   inkscape:connector-curvature=\"0\"\n   style=\"display:inline;fill:#ffffff\" />\n\t<path\n   display=\"inline\"\n   d=\"m 559.8,116.5 v 29 c -14.4,-2.1 -23.9,3 -23.9,13.3 v 37.3 H 503.7 V 117.9 H 536 v 11.4 c 5.4,-8.1 13.7,-12.8 23.8,-12.8 z\"\n   id=\"path27\"\n   inkscape:connector-curvature=\"0\"\n   style=\"display:inline;fill:#ffffff\" />\n\t<path\n   display=\"inline\"\n   stroke-miterlimit=\"10\"\n   d=\"m 574.5,217.4 c 0,-4.1 1.1,-7.1 3.4,-9.1 2.3,-2 5.9,-3 11,-3 5.1,0 8.8,1 11.1,3.1 2.3,2 3.5,5.1 3.5,9.1 0,8.1 -4.9,12.1 -14.6,12.1 -4.9,0 -8.5,-1 -10.9,-3 -2.4,-2 -3.5,-5.1 -3.5,-9.2 z m 0.7,-21.3 v -102 h 27.7 v 102.1 h -27.7 z\"\n   id=\"path29\"\n   inkscape:connector-curvature=\"0\"\n   style=\"display:inline;fill:none;stroke:#ffffff;stroke-width:6;stroke-miterlimit:10\" />\n\t<path\n   display=\"inline\"\n   d=\"m 653.1,137.7 c -2.7,0 -4.4,1 -4.4,2.6 0,7.3 40.6,4.4 40.6,30.7 0,16.2 -13.9,26.6 -35.5,26.6 -14.4,0 -27.3,-3.7 -38.2,-11.2 l 9.7,-20 c 10.4,6.4 20.2,9.7 28.9,9.7 3,0 4.9,-0.9 4.9,-2.3 0,-6.9 -39.8,-3.9 -39.8,-30.3 0,-16.4 13.6,-27 34.5,-27 12.4,0 24.6,3.3 36.3,9.9 l -10.6,19.9 c -11.5,-5.8 -20.4,-8.6 -26.4,-8.6 z\"\n   id=\"path31\"\n   inkscape:connector-curvature=\"0\"\n   style=\"display:inline;fill:#ffffff\" />\n\t<path\n   display=\"inline\"\n   d=\"m 781.2,164.2 h -50.9 c 2.1,6.1 6.7,9.3 13,9.3 5.4,0 11,-2.4 15.9,-7 l 16.7,16.4 c -8.3,9.2 -20.3,14.3 -35.5,14.3 -26.7,0 -42.6,-15.7 -42.6,-39.9 0,-24.7 16.6,-40.6 41.8,-40.6 27.3,0.1 43.3,18.7 41.6,47.5 z m -41.3,-26 c -5.6,0 -9,4.6 -10.3,11.2 H 749 c 0.5,-6.5 -3.5,-11.2 -9.1,-11.2 z\"\n   id=\"path33\"\n   inkscape:connector-curvature=\"0\"\n   style=\"display:inline;fill:#ffffff\" />\n</g>\n</svg>"
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 1.4326171875,
          "content": "[project]\nname = \"scikit-surprise\"\nauthors = [{ name = \"Nicolas Hug\", email = \"contact@nicolas-hug.com\" }]\ndescription = \"An easy-to-use library for recommender systems.\"\nrequires-python = \">=3.8\"\nkeywords = [ \"recommender\", \"recommendation system\" ]\nclassifiers = [\n  \"Development Status :: 5 - Production/Stable\",\n  \"Intended Audience :: Developers\",\n  \"Intended Audience :: Education\",\n  \"Intended Audience :: Science/Research\",\n  \"Topic :: Scientific/Engineering\",\n  \"License :: OSI Approved :: BSD License\",\n  \"Programming Language :: Python :: 3.8\",\n  \"Programming Language :: Python :: 3.9\",\n  \"Programming Language :: Python :: 3.10\",\n  \"Programming Language :: Python :: 3.11\",\n  \"Programming Language :: Python :: 3.12\",\n]\nlicense = { \"file\" = \"LICENSE.md\" }\ndependencies = [\n  # Lower bounds for deps are as in scikit-learn in May 2024, 1.6.dev0\n  \"joblib>=1.2.0\",\n  \"numpy>=1.19.5\",\n  \"scipy>=1.6.0\"\n]\ndynamic = [\"version\", \"readme\"]\n\n[project.scripts]\nsurprise = \"surprise.__main__:main\"\n\n[project.urls]\nhomepage = \"https://surpriselib.com\"\nrepository = \"https://github.com/NicolasHug/Surprise\"\n\n[build-system]\nrequires = [\"setuptools>=61.0.0\", \"wheel\", \"Cython>=3.0.10\", \"oldest-supported-numpy\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[tool.setuptools.dynamic]\nversion = { attr = \"surprise.__version__\"}\nreadme = { content-type = \"text/markdown\", file = [\n  \"README.md\",\n]}\n\n[tool.setuptools.packages.find]\nexclude = [\"tests*\", \"doc*\", \"examples*\",]\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 4.7939453125,
          "content": "from setuptools import Extension, setup\n\nimport numpy as np\nfrom Cython.Build import cythonize\n\n\"\"\"\nPrior to relying on PEP517/518 and using pyproject.toml, this setup.py used to\nbe an unintelligible mess. The main reason being that there were no clear\ndistinction between run-time and build-time dependencies, and since we didn't\nwant to make Cython a run-time dep, we had to enable a way to install the sdist\nfrom the .c files instead of from the .pyx file.\nAnyways. Now Cython is a build-time dep, not a run-time dep, since installing\nfrom the sdist happens in an isolated env.\n\nCreating the sdist still involves compiling the .pyx into .c because we're\nexecuting this file. This is unnecessary but it doesn't matter. The .c files are\nexcluded from the sdist (in MANIFEST.in) anyway.\n\nRelease instruction:\n\nUpdate changelog and contributors list. \n\nBasic local checks:\n- tests run correctly\n- doc compiles without warning (make clean first).\n\nCheck that the latest RTD build was OK: https://readthedocs.org/projects/surprise/builds/\n\nChange __version__ in __init__.py to new version name. Also update the hardcoded\nversion in build_sdist.yml, otherwise the GA jobs will fail.\n\nThe sdist is built on Python 3.8. It should be installable from all Python\nversions.\n- check the sdist building process. It will (unnecessarily) compily the .pyx\n  files and the .c files should be excluded from the archive.\n- check the install jobs. This will compile the .pyx files again as well as the\n  .c files. Look for compilation warnings.\n- check test jobs for warnings etc.\n\nDownload the sdist from the CI job then upload it to test pypi: twine upload\nblabla.tar.gz -r testpypi\n\nCheck that install works on testpypi, then upload to pypi and check again.\nto install from testpypi:\npip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple scikit-surprise  # noqa\nDoesn't hurt to check that the tests pass after installing from testpypi.\n\nIf not already done, sync gh-pages with the master's README\n\npush new release tag on github (commit last changes first if needed):\n    git tag vX.Y.Z\n    git push --tags\n\nCheck that RTD has updated 'stable' to the new release (may take a while).\n\nIn the mean time, upload to conda:\n    - Compute SHA256 hash of the new .tar.gz archive (or check it up on PyPI)\n    - update recipe/meta.yaml on feedstock fork consequently (only version and\n      sha should be changed.  Maybe add some import tests).\n    - Push changes, Then open pull request on conda-forge feedstock and merge it\n      when all checks are OK. Access the conda-forge feedstock it by the link on\n      GitHub 'forked from blah blah'.\n    - Check on https://anaconda.org/conda-forge/scikit-surprise that new\n      version is available for all platforms.\n\nThen, maybe, celebrate.\n\"\"\"\n\n# This prevents Cython from using deprecated numpy C APIs\ndefine_macros = [(\"NPY_NO_DEPRECATED_API\", \"NPY_1_7_API_VERSION\")]\n\n# We're using numpy C APIs in our Cython code so Cython will generate C code\n# that requires the numpy headers. We need to tell the compiler where to find\n# those headers.\n# If you remove this and compilation still works, don't get fooled: it's\n# probably only because the numpy headers are available in the default locations\n# like /usr/include/numpy/ so they get found. But that wouldn't necessarily be\n# the case on other users' machines building the sdist.\ninclude_dirs = [np.get_include()]\n\nextensions = [\n    Extension(\n        # name is where the .so will be placed, i.e. where the module will be\n        # importable from.\n        name=\"surprise.similarities\",\n        sources=[\"surprise/similarities.pyx\"],\n        include_dirs=include_dirs,\n        define_macros=define_macros,\n    ),\n    Extension(\n        name=\"surprise.prediction_algorithms.matrix_factorization\",\n        sources=[\"surprise/prediction_algorithms/matrix_factorization.pyx\"],\n        include_dirs=include_dirs,\n        define_macros=define_macros,\n    ),\n    Extension(\n        name=\"surprise.prediction_algorithms.optimize_baselines\",\n        sources=[\"surprise/prediction_algorithms/optimize_baselines.pyx\"],\n        include_dirs=include_dirs,\n        define_macros=define_macros,\n    ),\n    Extension(\n        name=\"surprise.prediction_algorithms.slope_one\",\n        sources=[\"surprise/prediction_algorithms/slope_one.pyx\"],\n        include_dirs=include_dirs,\n        define_macros=define_macros,\n    ),\n    Extension(\n        name=\"surprise.prediction_algorithms.co_clustering\",\n        sources=[\"surprise/prediction_algorithms/co_clustering.pyx\"],\n        include_dirs=include_dirs,\n        define_macros=define_macros,\n    ),\n]\n\nextensions = cythonize(\n    extensions,\n    compiler_directives={\n        \"language_level\": 3,\n        \"boundscheck\": False,\n        \"wraparound\": False,\n        \"initializedcheck\": False,\n        \"nonecheck\": False,\n    },\n)\n\nsetup(ext_modules=extensions)\n"
        },
        {
          "name": "surprise",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}