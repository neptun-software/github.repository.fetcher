{
  "metadata": {
    "timestamp": 1736560907400,
    "page": 633,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjY0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "microsoft/MMdnn",
      "stars": 5807,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.0166015625,
          "content": "*.sh text eol=lf\n"
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.330078125,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nenv/\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# SageMath parsed files\n*.sage.py\n\n# dotenv\n.env\n\n# virtualenv\n.venv\nvenv/\nENV/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n\n# visualization\nnode_modules/\npackage-lock.json\n*.log\n\n# tests temporary files\ntests/cache/\ntests/tmp/\n\n# Visual Studio\n.vs/\n.vscode/\n\n# JetBrains\n.idea/\n\n# macOS\n# Desktop Services Store files\n.DS_Store\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 1.9482421875,
          "content": "sudo: required\ndist: bionic\n\nos:\n  - linux\n\nlanguage: python\npython:\n  - \"3.6\"\nvirtualenv:\n  system_site_packages: true\n\nenv:\n  - TEST_PARSER=tensorflow\n  - TEST_PARSER=tensorflow_2\n  - TEST_PARSER=tensorflow_3\n  - TEST_PARSER=tensorflow_4\n  - TEST_PARSER=tensorflow_5\n  - TEST_PARSER=tensorflow_6\n  #- TEST_PARSER=tensorflow_7\n  - TEST_PARSER=tensorflow_frozen\n  - TEST_PARSER=pytorch\n  - TEST_PARSER=pytorch_2\n  - TEST_PARSER=pytorch_3\n  - TEST_PARSER=pytorch_4\n  - TEST_PARSER=pytorch_5\n  - TEST_PARSER=keras\n  - TEST_PARSER=keras_2\n  - TEST_PARSER=keras_3\n  - TEST_PARSER=keras_4\n  - TEST_PARSER=keras_5\n  - TEST_PARSER=cntk\n  - TEST_PARSER=cntk_2\n  - TEST_PARSER=caffe\n  - TEST_PARSER=caffe_2\n  - TEST_PARSER=caffe_3\n  #- TEST_PARSER=caffe_4\n  - TEST_PARSER=mxnet\n  - TEST_PARSER=mxnet_2\n  - TEST_PARSER=mxnet_3\n  #- TEST_PARSER=mxnet_4\n  - TEST_PARSER=mxnet_5\n  - TEST_PARSER=paddle\n  - TEST_PARSER=coreml\n  - TEST_PARSER=coreml_2\n  - TEST_PARSER=darknet\n\ncache:\n  directories:\n    - $HOME/.cache/pip\n\naddons:\n  apt:\n    update: false\n\nbefore_install:\n  - python -m pip install --upgrade pip\n  - sudo apt-get install -y --no-install-recommends caffe-cpu\n  - sudo apt-get install -y --no-install-recommends openmpi-bin\n  - sudo ln -s /usr/lib/x86_64-linux-gnu/libmpi_cxx.so.20 /usr/lib/x86_64-linux-gnu/libmpi_cxx.so.1\n  - sudo ln -s /usr/lib/x86_64-linux-gnu/libmpi.so.20 /usr/lib/x86_64-linux-gnu/libmpi.so.12\n\ninstall:\n  - python -m pip install -q -r $(python requirements/select_requirements.py)\n\nbefore_script:\n  - export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/lib/x86_64-linux-gnu\n\nafter_failure: true\n\nafter_success: true\n\nafter_script: true\n\nscript: bash test.sh $TEST_PARSER\n\nmatrix:\n  fast_finish: true\n\n  allow_failures:\n    - env: TEST_PARSER=paddle\n  \n  exclude:\n    - python: \"3.6\"\n      env: TEST_PARSER=paddle\n    - os: linux\n      env: TEST_PARSER=coreml\n    - os: linux\n      env: TEST_PARSER=coreml_2\n\nnotifications:\n  email:\n    on_success: never\n    on_failure: never\n"
        },
        {
          "name": "ISSUE_TEMPLATE.md",
          "type": "blob",
          "size": 0.2431640625,
          "content": "Platform (like ubuntu 16.04/win10):\n\nPython version:\n\nSource framework with version (like Tensorflow 1.4.1 with GPU):\n\nDestination framework with version (like CNTK 2.3 with GPU):\n\nPre-trained model path (webpath or webdisk path):\n\nRunning scripts:\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.134765625,
          "content": "    MIT License\n\n    Copyright (c) Microsoft Corporation. All rights reserved.\n\n    Permission is hereby granted, free of charge, to any person obtaining a copy\n    of this software and associated documentation files (the \"Software\"), to deal\n    in the Software without restriction, including without limitation the rights\n    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n    copies of the Software, and to permit persons to whom the Software is\n    furnished to do so, subject to the following conditions:\n\n    The above copyright notice and this permission notice shall be included in all\n    copies or substantial portions of the Software.\n\n    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n    SOFTWARE\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 12.8818359375,
          "content": "# ![MMdnn](https://ndqzpq.dm2304.livefilestore.com/y4mF9ON1vKrSy0ew9dM3Fw6KAvLzQza2nL9JiMSIfgfKLbqJPvuxwOC2VIur_Ycz4TvVpkibMkvKXrX-N9QOkyh0AaUW4qhWDak8cyM0UoLLxc57apyhfDaxflLlZrGqiJgzn1ztsxiaZMzglaIMhoo8kjPuZ5-vY7yoWXqJuhC1BDHOwgNPwIgzpxV1H4k1oQzmewThpAJ_w_fUHzianZtMw?width=35&height=35&cropmode=none) MMdnn\n\n[![PyPi Version](https://img.shields.io/pypi/v/mmdnn.svg)](https://pypi.org/project/mmdnn/)\n[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)\n[![Linux](https://travis-ci.org/Microsoft/MMdnn.svg?branch=master)](https://travis-ci.org/Microsoft/MMdnn)\n\nMMdnn is a comprehensive and cross-framework tool to convert, visualize and diagnose deep learning (DL) models.\nThe \"MM\" stands for model management, and \"dnn\" is the acronym of deep neural network.\n\nMajor features include:\n\n- <a href=\"#conversion\">**Model Conversion**</a>\n\n  - We implement a universal converter to convert DL models between frameworks, which means you can train a model with one framework and deploy it with another.\n\n- **Model Retraining**\n\n  - During the model conversion, we generate some code snippets to simplify later retraining or inference.\n\n- **Model Search & Visualization**\n\n  - We provide a [model collection](mmdnn/models/README.md) to help you find some popular models.\n  - We provide a <a href=\"#visualization\">model visualizer</a> to display the network architecture more intuitively.\n\n- **Model Deployment**\n\n  - We provide some guidelines to help you deploy DL models to another hardware platform.\n    - [Android](https://github.com/Microsoft/MMdnn/wiki/Deploy-your-TensorFlow-Lite-Model-in-Android)\n    - [Serving](https://github.com/Microsoft/MMdnn/wiki/Tensorflow-Serving-Via-Docker)\n    \n  - We provide a guide to help you accelerate inference with TensorRT.\n    - [TensorRT](https://github.com/Microsoft/MMdnn/wiki/Using-TensorRT-to-Accelerate-Inference)\n  \n\n## Related Projects\n\nTargeting at openness and advancing state-of-art technology, [Microsoft Research (MSR)](https://www.microsoft.com/en-us/research/group/systems-and-networking-research-group-asia/) and [Microsoft Software Technology Center (STC)](https://www.microsoft.com/en-us/ard/company/introduction.aspx) had also released few other open source projects:\n\n* [OpenPAI](https://github.com/Microsoft/pai) : an open source platform that provides complete AI model training and resource management capabilities, it is easy to extend and supports on-premise, cloud and hybrid environments in various scale.\n* [FrameworkController](https://github.com/Microsoft/frameworkcontroller) : an open source general-purpose Kubernetes Pod Controller that orchestrate all kinds of applications on Kubernetes by a single controller.\n* [NNI](https://github.com/Microsoft/nni) : a lightweight but powerful toolkit to help users automate Feature Engineering, Neural Architecture Search, Hyperparameter Tuning and Model Compression.\n* [NeuronBlocks](https://github.com/Microsoft/NeuronBlocks) : an NLP deep learning modeling toolkit that helps engineers to build DNN models like playing Lego. The main goal of this toolkit is to minimize developing cost for NLP deep neural network model building, including both training and inference stages.\n* [SPTAG](https://github.com/Microsoft/SPTAG) : Space Partition Tree And Graph (SPTAG) is an open source library for large scale vector approximate nearest neighbor search scenario.\n\nWe encourage researchers, developers and students to leverage these projects to boost their AI / Deep Learning productivity.\n\n## Installation\n\n### Install manually\n\nYou can get a stable version of MMdnn by\n\n```bash\npip install mmdnn\n```\nAnd make sure to have [Python](https://www.python.org/) installed\nor you can try the newest version by\n\n```bash\npip install -U git+https://github.com/Microsoft/MMdnn.git@master\n```\n\n### Install with docker image\n\nMMdnn provides a docker image, which packages MMdnn and Deep Learning frameworks that we support as well as other dependencies.\nYou can easily try the image with the following steps:\n\n1. Install Docker Community Edition(CE)\n\n    [_Learn more about how to install docker_](https://github.com/Microsoft/MMdnn/blob/master/docs/InstallDockerCE.md)\n\n1. Pull MMdnn docker image\n    ```bash\n    docker pull mmdnn/mmdnn:cpu.small\n    ```\n\n1. Run image in an interactive mode\n\n    ```bash\n    docker run -it mmdnn/mmdnn:cpu.small\n    ```\n\n## Features\n\n### <a name=\"conversion\">Model Conversion</a>\n\nAcross the industry and academia, there are a number of existing frameworks available for developers and researchers to design a model, where each framework has its own network structure definition and saving model format. The gaps between frameworks impede the inter-operation of the models.\n\n<img src=\"https://raw.githubusercontent.com/Microsoft/MMdnn/master/docs/supported.jpg\" width=\"633\" >\n\nWe provide a model converter to help developers convert models between frameworks through an intermediate representation format.\n\n#### Support frameworks\n\n> [Note] You can click the links to get detailed README of each framework.\n\n- [Caffe](https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/caffe/README.md)\n- [Microsoft Cognitive Toolkit (CNTK)](https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/cntk/README.md)\n- [CoreML](https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/coreml/README.md)\n- [Keras](https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/keras/README.md)\n- [MXNet](https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/mxnet/README.md)\n- [ONNX](https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/onnx/README.md) (Destination only)\n- [PyTorch](https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/pytorch/README.md)\n- [TensorFlow](https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/tensorflow/README.md) (Experimental) (We highly recommend you read the README of TensorFlow first)\n- [DarkNet](https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/darknet/README.md) (Source only, Experiment)\n\n#### Tested models\n\nThe model conversion between currently supported frameworks is tested on some **ImageNet** models.\n\nModels | Caffe | Keras | TensorFlow | CNTK | MXNet | PyTorch  | CoreML | ONNX\n:-----:|:-----:|:-----:|:----------:|:----:|:-----:|:--------:|:------:|:-----:|\n[VGG 19](https://arxiv.org/abs/1409.1556.pdf) | √ | √ | √ | √ | √ | √ | √ | √\n[Inception V1](https://arxiv.org/abs/1409.4842v1) | √ | √ | √ | √ | √ | √ | √ | √\n[Inception V3](https://arxiv.org/abs/1512.00567)  | √ | √ | √ | √ | √ | √ | √ | √\n[Inception V4](https://arxiv.org/abs/1512.00567)  | √ | √ | √ | o | √ | √ | √ | √\n[ResNet V1](https://arxiv.org/abs/1512.03385)                               |   ×   |   √   |     √      |   o  |   √   |    √ | √ | √\n[ResNet V2](https://arxiv.org/abs/1603.05027)                               |   √   |   √   |     √      |   √  |   √   | √ | √ | √\n[MobileNet V1](https://arxiv.org/pdf/1704.04861.pdf)                        |   ×   |   √   |     √      |   o  |   √   |    √       | √ | √ | √\n[MobileNet V2](https://arxiv.org/pdf/1704.04861.pdf)                        |   ×   |   √   |     √      |   o  |   √   |    √       | √ | √ | √\n[Xception](https://arxiv.org/pdf/1610.02357.pdf)                            |   √   |   √   |     √      |   o  |   ×   |    √ | √ | √ | √\n[SqueezeNet](https://arxiv.org/pdf/1602.07360)                              |   √   |   √   |     √      |   √  |   √   |    √ | √ | √ | √\n[DenseNet](https://arxiv.org/abs/1608.06993)                                |   √   |   √   |     √      |   √  |   √   |    √       | √ | √\n[NASNet](https://arxiv.org/abs/1707.07012)                                  |   x   |   √   |     √      |   o  |   √   | √ | √ | x\n[ResNext](https://arxiv.org/abs/1611.05431)                                 |   √   |   √   |     √      |   √  |   √   | √ | √ | √ | √ | √\n[voc FCN](https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf) |       |       |     √      |   √  |       |\nYolo3                                                                       |       |   √   |            |   √  |\n\n#### Usage\n\nOne command to achieve the conversion. Using TensorFlow **ResNet V2 152** to PyTorch as our example.\n\n```bash\n$ mmdownload -f tensorflow -n resnet_v2_152 -o ./\n$ mmconvert -sf tensorflow -in imagenet_resnet_v2_152.ckpt.meta -iw imagenet_resnet_v2_152.ckpt --dstNodeName MMdnn_Output -df pytorch -om tf_resnet_to_pth.pth\n```\n\nDone.\n\n#### On-going frameworks\n\n- Torch7 (help wanted)\n- Chainer (help wanted)\n\n#### On-going Models\n\n- Face Detection\n- Semantic Segmentation\n- Image Style Transfer\n- Object Detection\n- RNN\n\n---\n\n### <a name=\"visualization\">Model Visualization</a>\n\nWe provide a [local visualizer](mmdnn/visualization) to display the network architecture of a deep learning model.\nPlease refer to the [instruction](mmdnn/visualization/README.md).\n\n---\n\n## Examples\n\n### Official Tutorial\n\n- [Keras \"inception V3\" to CNTK](https://github.com/Microsoft/MMdnn/blob/master/docs/keras2cntk.md) and [related issue](https://github.com/Microsoft/MMdnn/issues/19)\n\n- [TensorFlow slim model \"ResNet V2 152\" to PyTorch](https://github.com/Microsoft/MMdnn/blob/master/docs/tf2pytorch.md)\n\n- [Mxnet model \"LResNet50E-IR\" to TensorFlow](https://github.com/Microsoft/MMdnn/issues/85) and [related issue](https://github.com/Microsoft/MMdnn/issues/135)\n\n### Users' Examples\n\n- [MXNet \"ResNet-152-11k\" to PyTorch](https://github.com/Microsoft/MMdnn/issues/6)\n\n- [Another Example of MXNet \"ResNet-152-11k\" to PyTorch](https://blog.paperspace.com/convert-full-imagenet-pre-trained-model-from-mxnet-to-pytorch/)\n\n- [MXNet \"ResNeXt\" to Keras](https://github.com/Microsoft/MMdnn/issues/58)\n\n- [TensorFlow \"ResNet-101\" to PyTorch](https://github.com/Microsoft/MMdnn/issues/22)\n\n- [TensorFlow \"mnist mlp model\" to CNTK](https://github.com/Microsoft/MMdnn/issues/11)\n\n- [TensorFlow \"Inception_v3\" to MXNet](https://github.com/Microsoft/MMdnn/issues/30)\n\n- [Caffe \"voc-fcn\" to TensorFlow](https://github.com/Microsoft/MMdnn/issues/29)\n\n- [Caffe \"AlexNet\" to TensorFlow](https://github.com/Microsoft/MMdnn/issues/10)\n\n- [Caffe \"inception_v4\" to TensorFlow](https://github.com/Microsoft/MMdnn/issues/26)\n\n- [Caffe \"VGG16_SOD\" to TensorFlow](https://github.com/Microsoft/MMdnn/issues/27)\n\n- [Caffe \"SqueezeNet v1.1\" to CNTK](https://github.com/Microsoft/MMdnn/issues/48)\n\n---\n\n## Contributing\n\nMost contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n### Intermediate Representation\n\nThe intermediate representation stores the **network architecture** in **protobuf binary** and **pre-trained weights** in **NumPy** native format.\n\n> [Note!] Currently the IR weights data is in NHWC (channel last) format.\n\nDetails are in [ops.txt](https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/common/IR/ops.pbtxt) and [graph.proto](https://github.com/Microsoft/MMdnn/blob/master/mmdnn/conversion/common/IR/graph.proto). New operators and any comments are welcome.\n\n### Frameworks\n\nWe are working on other frameworks conversion and visualization, such as PyTorch, CoreML and so on. We're investigating more RNN related operators. Any contributions and suggestions are welcome! Details in [Contribution Guideline](https://github.com/Microsoft/MMdnn/wiki/Contribution-Guideline).\n\n## Authors\n\nYu Liu (Peking University): Project Developer & Maintainer\n\nCheng CHEN (Microsoft Research Asia): Caffe, CNTK, CoreML Emitter, Keras, MXNet, TensorFlow\n\nJiahao YAO (Peking University): CoreML, MXNet Emitter, PyTorch Parser; HomePage\n\nRu ZHANG (Chinese Academy of Sciences): CoreML Emitter, DarkNet Parser, Keras, TensorFlow frozen graph Parser; Yolo and SSD models; Tests\n\nYuhao ZHOU (Shanghai Jiao Tong University): MXNet\n\nTingting QIN (Microsoft Research Asia): Caffe Emitter\n\nTong ZHAN (Microsoft): ONNX Emitter\n\nQianwen WANG (Hong Kong University of Science and Technology): Visualization\n\n## Acknowledgements\n\nThanks to [Saumitro Dasgupta](https://github.com/ethereon), the initial code of *caffe -> IR converting* is references to his project [caffe-tensorflow](https://github.com/ethereon/caffe-tensorflow).\n\n## License\nLicensed under the [MIT](LICENSE) license.\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 2.6923828125,
          "content": "<!-- BEGIN MICROSOFT SECURITY.MD V0.0.7 BLOCK -->\n\n## Security\n\nMicrosoft takes the security of our software products and services seriously, which includes all source code repositories managed through our GitHub organizations, which include [Microsoft](https://github.com/Microsoft), [Azure](https://github.com/Azure), [DotNet](https://github.com/dotnet), [AspNet](https://github.com/aspnet), [Xamarin](https://github.com/xamarin), and [our GitHub organizations](https://opensource.microsoft.com/).\n\nIf you believe you have found a security vulnerability in any Microsoft-owned repository that meets [Microsoft's definition of a security vulnerability](https://aka.ms/opensource/security/definition), please report it to us as described below.\n\n## Reporting Security Issues\n\n**Please do not report security vulnerabilities through public GitHub issues.**\n\nInstead, please report them to the Microsoft Security Response Center (MSRC) at [https://msrc.microsoft.com/create-report](https://aka.ms/opensource/security/create-report).\n\nIf you prefer to submit without logging in, send email to [secure@microsoft.com](mailto:secure@microsoft.com).  If possible, encrypt your message with our PGP key; please download it from the [Microsoft Security Response Center PGP Key page](https://aka.ms/opensource/security/pgpkey).\n\nYou should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Additional information can be found at [microsoft.com/msrc](https://aka.ms/opensource/security/msrc). \n\nPlease include the requested information listed below (as much as you can provide) to help us better understand the nature and scope of the possible issue:\n\n  * Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.)\n  * Full paths of source file(s) related to the manifestation of the issue\n  * The location of the affected source code (tag/branch/commit or direct URL)\n  * Any special configuration required to reproduce the issue\n  * Step-by-step instructions to reproduce the issue\n  * Proof-of-concept or exploit code (if possible)\n  * Impact of the issue, including how an attacker might exploit the issue\n\nThis information will help us triage your report more quickly.\n\nIf you are reporting for a bug bounty, more complete reports can contribute to a higher bounty award. Please visit our [Microsoft Bug Bounty Program](https://aka.ms/opensource/security/bounty) page for more details about our active programs.\n\n## Preferred Languages\n\nWe prefer all communications to be in English.\n\n## Policy\n\nMicrosoft follows the principle of [Coordinated Vulnerability Disclosure](https://aka.ms/opensource/security/cvd).\n\n<!-- END MICROSOFT SECURITY.MD BLOCK -->\n"
        },
        {
          "name": "_config.yml",
          "type": "blob",
          "size": 0.025390625,
          "content": "theme: jekyll-theme-cayman"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "mmdnn",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.1435546875,
          "content": "[metadata]\nlicense_files = LICENSE\n\n[bdist_wheel]\n# https://packaging.python.org/guides/distributing-packages-using-setuptools/#wheels\nuniversal=1\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 3.517578125,
          "content": "from __future__ import absolute_import\nfrom setuptools import setup, find_packages\nfrom io import open\n\n# Get the long description from the README file\nwith open('README.md', encoding='utf-8') as f:\n    long_description = f.read()\n\nsetup(\n    name='mmdnn',\n\n    # Versions should comply with PEP440.  For a discussion on single-sourcing\n    # the version across setup.py and the project code, see\n    # https://packaging.python.org/en/latest/single_source_version.html\n    version='0.3.1',\n\n    description='Deep learning model converter, visualization and editor.',\n    long_description=long_description,\n    long_description_content_type='text/markdown',\n\n    # The project's main homepage.\n    url='https://github.com/Microsoft/MMdnn',\n\n    # Author details\n    author = 'System Research Group, Microsoft Research Asia',\n    author_email='mmdnn_feedback@microsoft.com',\n\n    # Choose your license\n    license='MIT',\n\n    # See https://pypi.python.org/pypi?%3Aaction=list_classifiers\n    classifiers=[\n        # How mature is this project? Common values are\n        #   3 - Alpha\n        #   4 - Beta\n        #   5 - Production/Stable\n        'Development Status :: 3 - Alpha',\n\n        # Indicate who your project is intended for\n        'Intended Audience :: Developers',\n        'Intended Audience :: Education',\n        'Intended Audience :: Science/Research',\n        'Topic :: Scientific/Engineering :: Mathematics',\n        'Topic :: Software Development :: Libraries :: Python Modules',\n        'Topic :: Software Development :: Libraries',\n\n        # Pick your license as you wish (should match \"license\" above)\n        'License :: OSI Approved :: MIT License',\n\n        # Specify the Python versions you support here. In particular, ensure\n        # that you indicate whether you support Python 2, Python 3 or both.\n        'Programming Language :: Python :: 3'\n    ],\n\n    # What does your project relate to?\n    keywords='deep learning model converter visualization',\n\n    # You can just specify the packages manually here if your project is\n    # simple. Or you can use find_packages().\n    packages=find_packages(),\n\n    package_data={\n        'mmdnn':['visualization/public/*',\n                'visualization/*.json',\n                'visualization/*.js',\n                'visualization/*.html',\n                'visualization/*.css']\n    },\n\n    # Alternatively, if you want to distribute just a my_module.py, uncomment\n    # this:\n    #   py_modules=[\"my_module\"],\n\n    # List run-time dependencies here.  These will be installed by pip when\n    # your project is installed. For an analysis of \"install_requires\" vs pip's\n    # requirements files see:\n    # https://packaging.python.org/en/latest/requirements.html\n    install_requires=[\n        'numpy >= 1.15.0',\n        'protobuf >= 3.6.0',\n        'six >= 1.10.0',\n        'pillow >= 6.2.1',\n    ],\n\n    # To provide executable scripts, use entry points in preference to the\n    # \"scripts\" keyword. Entry points provide cross-platform support and allow\n    # pip to create the appropriate form of executable for the target platform.\n    entry_points={\n        'console_scripts': [\n            'mmconvert  = mmdnn.conversion._script.convert:_main',\n            'mmdownload = mmdnn.conversion._script.extractModel:_main',\n            'mmvismeta  = mmdnn.conversion.examples.tensorflow.vis_meta:_main',\n            'mmtoir     = mmdnn.conversion._script.convertToIR:_main',\n            'mmtocode   = mmdnn.conversion._script.IRToCode:_main',\n            'mmtomodel  = mmdnn.conversion._script.dump_code:_main',\n        ],\n    },\n)\n"
        },
        {
          "name": "test.sh",
          "type": "blob",
          "size": 0.8974609375,
          "content": "#!/bin/bash\n# Abort on Error\nset -e\n\nexport PING_SLEEP=60s\nexport WORKDIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" && pwd )\"\nexport BUILD_OUTPUT=$WORKDIR/build.out\n\ntouch $BUILD_OUTPUT\n\ndump_output() {\n   echo Tailing the last 500 lines of output:\n   tail -500 $BUILD_OUTPUT\n}\nerror_handler() {\n  echo ERROR: An error was encountered with the build.\n  dump_output\n  exit 1\n}\n\n# If an error occurs, run our error handler to output a tail of the build\ntrap 'error_handler' ERR\n\n# Set up a repeating loop to send some output to Travis.\n\nbash -c \"while true; do echo \\$(date) - building ...; sleep $PING_SLEEP; done\" &\nPING_LOOP_PID=$!\n\n# My build is using maven, but you could build anything with this, E.g.\npython -m pytest -s -q tests/test_$1.py >> $BUILD_OUTPUT 2>&1\n\n# The build finished without returning an error so dump a tail of the output\ndump_output\n\n# nicely terminate the ping output loop\nkill $PING_LOOP_PID\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}