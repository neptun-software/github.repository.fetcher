{
  "metadata": {
    "timestamp": 1736560782216,
    "page": 471,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQ4MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "likedan/Awesome-CoreML-Models",
      "stars": 6543,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.4208984375,
          "content": "# Xcode\n#\n# gitignore contributors: remember to update Global/Xcode.gitignore, Objective-C.gitignore & Swift.gitignore\n\n## Build generated\nbuild/\nDerivedData/\n\n## Various settings\n*.pbxuser\n!default.pbxuser\n*.mode1v3\n!default.mode1v3\n*.mode2v3\n!default.mode2v3\n*.perspectivev3\n!default.perspectivev3\nxcuserdata/\n\n## Other\n*.moved-aside\n*.xccheckout\n*.xcscmblueprint\n\n## Obj-C/Swift specific\n*.hmap\n*.ipa\n*.dSYM.zip\n*.dSYM\n\n## Playgrounds\ntimeline.xctimeline\nplayground.xcworkspace\n\n# Swift Package Manager\n#\n# Add this line if you want to avoid checking in source code from Swift Package Manager dependencies.\n# Packages/\n# Package.pins\n.build/\n\n# CocoaPods\n#\n# We recommend against adding the Pods directory to your .gitignore. However\n# you should judge for yourself, the pros and cons are mentioned at:\n# https://guides.cocoapods.org/using/using-cocoapods.html#should-i-check-the-pods-directory-into-source-control\n#\n# Pods/\n\n# Carthage\n#\n# Add this line if you want to avoid checking in source code from Carthage dependencies.\n# Carthage/Checkouts\n\nCarthage/Build\n\n# fastlane\n#\n# It is recommended to not store the screenshots in the git repo. Instead, use fastlane to re-generate the\n# screenshots whenever they are needed.\n# For more information about the recommended setup visit:\n# https://docs.fastlane.tools/best-practices/source-control/#source-control\n\nfastlane/report.xml\nfastlane/Preview.html\nfastlane/screenshots\nfastlane/test_output\n\n.idea/"
        },
        {
          "name": ".idea",
          "type": "tree",
          "content": null
        },
        {
          "name": "LICENSE.txt",
          "type": "blob",
          "size": 1.0556640625,
          "content": "The MIT License (MIT)\n\nCopyright (c) 2016 Vinicius Souza\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 14.4580078125,
          "content": "\n\n<!--\nTitle: Awesome Core ML Models\nDescription: A curated list of machine learning models in Core ML format.\nAuthor: Kedan Li\n-->\n<p align=\"center\">\n<img src=\"images/coreml.png\" width=\"329\" height=\"295\"/>\n</p>\n\n\nSince iOS 11, Apple released Core ML framework to help developers integrate machine learning models into applications. [The official documentation](https://developer.apple.com/documentation/coreml)\n\nWe've put up the largest collection of machine learning models in Core ML format, to help  iOS, macOS, tvOS, and watchOS developers experiment with machine learning techniques.\n\nIf you've converted a Core ML model, feel free to submit a [pull request](https://github.com/likedan/Awesome-CoreML-Models/compare).\n\nRecently, we've included visualization tools. And here's one [Netron](https://lutzroeder.github.io/Netron).\n\n[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](http://makeapullrequest.com)\n\n# Models\n\n## Image - Metadata/Text\n*Models that take image data as input and output useful information about the image.*\n* **TextDetection** - Detecting text using Vision built-in model in real-time. [Download]() | [Demo](https://github.com/tucan9389/TextDetection-CoreML) | [Reference](https://developer.apple.com/documentation/vision)\n* **PhotoAssessment** - Photo Assessment using Core ML and Metal. [Download](https://github.com/yulingtianxia/PhotoAssessment/blob/master/PhotoAssessment-Sample/Sources/NIMANasnet.mlmodel) | [Demo](https://github.com/yulingtianxia/PhotoAssessment) | [Reference](https://arxiv.org/abs/1709.05424)\n* **PoseEstimation** - Estimating human pose from a picture for mobile. [Download](https://github.com/edvardHua/PoseEstimationForMobile/tree/master/release) | [Demo](https://github.com/tucan9389/PoseEstimation-CoreML) | [Reference](https://github.com/edvardHua/PoseEstimationForMobile)\n* **MobileNet** - Detects the dominant objects present in an image. [Download](https://github.com/hollance/MobileNet-CoreML/raw/master/MobileNet.mlmodel) | [Demo](https://github.com/hollance/MobileNet-CoreML) | [Reference](https://arxiv.org/abs/1704.04861)\n* **Places CNN** - Detects the scene of an image from 205 categories such as bedroom, forest, coast etc. [Download](https://github.com/hollance/MobileNet-CoreML/raw/master/MobileNet.mlmodel) | [Demo](https://github.com/chenyi1989/CoreMLDemo) | [Reference](http://places.csail.mit.edu/index.html)\n* **Inception v3** - Detects the dominant objects present in an image. [Download](https://github.com/yulingtianxia/Core-ML-Sample/blob/master/CoreMLSample/Inceptionv3.mlmodel) | [Demo](https://github.com/yulingtianxia/Core-ML-Sample/) | [Reference](https://arxiv.org/abs/1512.00567)\n* **ResNet50** - Detects the dominant objects present in an image. [Download](https://github.com/ytakzk/CoreML-samples/blob/master/CoreML-samples/Resnet50.mlmodel) | [Demo](https://github.com/ytakzk/CoreML-samples) | [Reference](https://arxiv.org/abs/1512.03385)\n* **VGG16** - Detects the dominant objects present in an image. [Download](https://docs-assets.developer.apple.com/coreml/models/VGG16.mlmodel) | [Demo](https://github.com/alaphao/CoreMLExample) | [Reference](https://arxiv.org/abs/1409.1556)\n* **Car Recognition** - Predict the brand & model of a car. [Download](https://github.com/likedan/Core-ML-Car-Recognition/blob/master/Convert/CarRecognition.mlmodel) | [Demo](https://github.com/ytakzk/CoreML-samples) | [Reference](http://mmlab.ie.cuhk.edu.hk/datasets/comp_cars/index.html)\n* **YOLO** - Recognize what the objects are inside a given image and where they are in the image. [Download](https://github.com/hollance/YOLO-CoreML-MPSNNGraph/blob/master/TinyYOLO-CoreML/TinyYOLO-CoreML/TinyYOLO.mlmodel) | [Demo](https://github.com/hollance/YOLO-CoreML-MPSNNGraph) | [Reference](http://machinethink.net/blog/object-detection-with-yolo)\n* **AgeNet** - Predict a person's age from one's portrait. [Download](https://drive.google.com/file/d/0B1ghKa_MYL6mT1J3T1BEeWx4TWc/view?usp=sharing) | [Demo](https://github.com/cocoa-ai/FacesVisionDemo) | [Reference](http://www.openu.ac.il/home/hassner/projects/cnn_agegender/)\n* **GenderNet** - Predict a person's gender from one's portrait. [Download](https://drive.google.com/file/d/0B1ghKa_MYL6mYkNsZHlyc2ZuaFk/view?usp=sharing) | [Demo](https://github.com/cocoa-ai/FacesVisionDemo) | [Reference](http://www.openu.ac.il/home/hassner/projects/cnn_agegender/)\n* **MNIST** - Predict handwritten (drawn) digits from images. [Download](https://github.com/ph1ps/MNIST-CoreML/raw/master/MNISTPrediction/MNIST.mlmodel) | [Demo](https://github.com/ph1ps/MNIST-CoreML) | [Reference](http://yann.lecun.com/exdb/mnist/)\n* **EmotionNet** - Predict a person's emotion from one's portrait. [Download](https://drive.google.com/file/d/0B1ghKa_MYL6mTlYtRGdXNFlpWDQ/view?usp=sharing) | [Demo](https://github.com/cocoa-ai/FacesVisionDemo) | [Reference](http://www.openu.ac.il/home/hassner/projects/cnn_emotions/)\n* **SentimentVision** - Predict positive or negative sentiments from images. [Download](https://drive.google.com/open?id=0B1ghKa_MYL6mZ0dITW5uZlgyNTg) | [Demo](https://github.com/cocoa-ai/SentimentVisionDemo) | [Reference](http://www.sciencedirect.com/science/article/pii/S0262885617300355?via%3Dihub)\n* **Food101** - Predict the type of foods from images. [Download](https://drive.google.com/open?id=0B5TjkH3njRqnVjBPZGRZbkNITjA) | [Demo](https://github.com/ph1ps/Food101-CoreML) | [Reference](http://visiir.lip6.fr/explore)\n* **Oxford102** - Detect the type of flowers from images. [Download](https://drive.google.com/file/d/0B1ghKa_MYL6meDBHT2NaZGxkNzQ/view?usp=sharing) | [Demo](https://github.com/cocoa-ai/FlowersVisionDemo) | [Reference](http://jimgoo.com/flower-power/)\n* **FlickrStyle** - Detect the artistic style of images. [Download](https://drive.google.com/file/d/0B1ghKa_MYL6meDBHT2NaZGxkNzQ/view?usp=sharing) | [Demo](https://github.com/cocoa-ai/StylesVisionDemo) | [Reference](http://sergeykarayev.com/files/1311.3715v3.pdf)\n* **RN1015k500** - Predict the location where a picture was taken. [Download](https://s3.amazonaws.com/aws-bigdata-blog/artifacts/RN1015k500/RN1015k500.mlmodel) | [Demo](https://github.com/awslabs/MXNet2CoreML_iOS_sample_app) | [Reference](https://aws.amazon.com/blogs/ai/estimating-the-location-of-images-using-mxnet-and-multimedia-commons-dataset-on-aws-ec2)\n* **Nudity** - Classifies an image either as NSFW (nude) or SFW (not nude)\n [Download](https://drive.google.com/open?id=0B5TjkH3njRqncDJpdDB1Tkl2S2s) | [Demo](https://github.com/ph1ps/Nudity-CoreML) | [Reference](https://github.com/yahoo/open_nsfw)\n* **TextRecognition (ML Kit)** - Recognizing text using ML Kit built-in model in real-time. [Download]() | [Demo](https://github.com/tucan9389/TextRecognition-MLKit) | [Reference](https://firebase.google.com/docs/ml-kit/ios/recognize-text)\n* **ImageSegmentation** - Segment the pixels of a camera frame or image into a predefined set of classes. [Download](https://developer.apple.com/machine-learning/models/) | [Demo](https://github.com/tucan9389/ImageSegmentation-CoreML) | [Reference](https://github.com/tensorflow/models/tree/master/research/deeplab)\n* **DepthPrediction** - Predict the depth from a single image. [Download](https://developer.apple.com/machine-learning/models/) | [Demo](https://github.com/tucan9389/DepthPrediction-CoreML) | [Reference](https://github.com/iro-cp/FCRN-DepthPrediction)\n\n## Image - Image\n*Models that transform images.*\n* **HED** - Detect nested edges from a color image. [Download](https://github.com/s1ddok/HED-CoreML/blob/master/HED-CoreML/Models/HED_so.mlmodel) | [Demo](https://github.com/s1ddok/HED-CoreML) | [Reference](http://dl.acm.org/citation.cfm?id=2654889)\n* **AnimeScale2x** - Process a bicubic-scaled anime-style artwork [Download](https://github.com/imxieyi/waifu2x-ios/blob/master/waifu2x/models/anime_noise0_model.mlmodel) | [Demo](https://github.com/imxieyi/waifu2x-ios) | [Reference](https://arxiv.org/abs/1501.00092)\n\n## Text - Metadata/Text\n*Models that process text data*\n* **Sentiment Polarity** - Predict positive or negative sentiments from sentences. [Download](https://github.com/cocoa-ai/SentimentCoreMLDemo/raw/master/SentimentPolarity/Resources/SentimentPolarity.mlmodel) | [Demo](https://github.com/cocoa-ai/SentimentCoreMLDemo) | [Reference](http://boston.lti.cs.cmu.edu/classes/95-865-K/HW/HW3/)\n* **DocumentClassification** - Classify news articles into 1 of 5 categories. [Download](https://github.com/toddkramer/DocumentClassifier/blob/master/Sources/DocumentClassification.mlmodel) | [Demo](https://github.com/toddkramer/DocumentClassifier) | [Reference](https://github.com/toddkramer/DocumentClassifier/)\n* **iMessage Spam Detection** - Detect whether a message is spam. [Download](https://github.com/gkswamy98/imessage-spam-detection/blob/master/MessageClassifier.mlmodel) | [Demo](https://github.com/gkswamy98/imessage-spam-detection/tree/master) | [Reference](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/)\n* **NamesDT** - Gender Classification using DecisionTreeClassifier [Download](https://github.com/cocoa-ai/NamesCoreMLDemo/blob/master/Names/Resources/NamesDT.mlmodel) | [Demo](https://github.com/cocoa-ai/NamesCoreMLDemo) | [Reference](http://nlpforhackers.io/)\n* **Personality Detection** - Predict personality based on user documents (sentences). [Download](https://github.com/novinfard/profiler-sentiment-analysis/tree/master/ios_app/ProfilerSA/ML%20Models) | [Demo](https://github.com/novinfard/profiler-sentiment-analysis/) | [Reference](https://github.com/novinfard/profiler-sentiment-analysis/blob/master/dissertation-v6.pdf)\n* **BERT for Question answering** - Swift Core ML 3 implementation of BERT for Question answering [Download](https://github.com/huggingface/swift-coreml-transformers/blob/master/Resources/BERTSQUADFP16.mlmodel) | [Demo](https://github.com/huggingface/swift-coreml-transformers#-bert) | [Reference](https://github.com/huggingface/pytorch-transformers#run_squadpy-fine-tuning-on-squad-for-question-answering)\n* **GPT-2** - OpenAI GPT-2 Text generation (Core ML 3) [Download](https://github.com/huggingface/swift-coreml-transformers/blob/master/Resources/gpt2-512.mlmodel) | [Demo](https://github.com/huggingface/swift-coreml-transformers#-gpt-2) | [Reference](https://github.com/huggingface/pytorch-transformers)\n## Miscellaneous\n* **Exermote** - Predicts the exercise, when iPhone is worn on right upper arm. [Download](https://github.com/Lausbert/Exermote/tree/master/ExermoteInference) | [Demo](https://github.com/Lausbert/Exermote/tree/master/ExermoteInference) | [Reference](http://lausbert.com/2017/08/03/exermote/)\n* **GestureAI** - Recommend an artist based on given location and genre. [Download](https://goo.gl/avdMjD) | [Demo](https://github.com/akimach/GestureAI-CoreML-iOS) | [Reference](https://github.com/akimach/GestureAI-iOS/tree/master/GestureAI)\n* **Artists Recommendation** - Recommend an artist based on given location and genre. [Download](https://github.com/agnosticdev/Blog-Examples/blob/master/UsingCoreMLtoCreateASongRecommendationEngine/Artist.mlmodel) | [Demo]() | [Reference](https://www.agnosticdev.com/blog-entry/python/using-scikit-learn-and-coreml-create-music-recommendation-engine)\n* **ChordSuggester** - Predicts the most likely next chord based on the entered Chord Progression. [Download](https://github.com/carlosmbe/Mac-CoreML-Chord-Suggester/blob/main/MLChordSuggester.mlpackage.zip) | [Demo](https://github.com/carlosmbe/Mac-CoreML-Chord-Suggester/tree/main) | [Reference](https://medium.com/@huanlui/chordsuggester-i-3a1261d4ea9e)\n\n\n\n# Visualization Tools\n*Tools that help visualize CoreML Models*\n* [Netron](https://lutzroeder.github.io/Netron)\n\n# Supported formats\n*List of model formats that could be converted to Core ML with examples*\n* [Caffe](https://apple.github.io/coremltools/generated/coremltools.converters.caffe.convert.html)\n* [Keras](https://apple.github.io/coremltools/generated/coremltools.converters.keras.convert.html)\n* [XGBoost](https://apple.github.io/coremltools/generated/coremltools.converters.xgboost.convert.html)\n* [Scikit-learn](https://apple.github.io/coremltools/generated/coremltools.converters.sklearn.convert.html)\n* [MXNet](https://aws.amazon.com/blogs/ai/bring-machine-learning-to-ios-apps-using-apache-mxnet-and-apple-core-ml/)\n* [LibSVM](https://apple.github.io/coremltools/generated/coremltools.converters.libsvm.convert.html)\n* [Torch7](https://github.com/prisma-ai/torch2coreml)\n\n# The Gold\n*Collections of machine learning models that could be converted to Core ML*\n\n* [Caffe Model Zoo](https://github.com/BVLC/caffe/wiki/Model-Zoo) - Big list of models in Caffe format.\n* [TensorFlow Models](https://github.com/tensorflow/models) - Models for TensorFlow.\n* [TensorFlow Slim Models](https://github.com/tensorflow/models/tree/master/research/slim/README.md) - Another collection of TensorFlow Models.\n* [MXNet Model Zoo](https://mxnet.incubator.apache.org/model_zoo/) - Collection of MXNet models.\n\n*Individual machine learning models that could be converted to Core ML. We'll keep adjusting the list as they become converted.*\n* [LaMem](https://github.com/MiyainNYC/Visual-Memorability-through-Caffe) Score the memorability of pictures.\n* [ILGnet](https://github.com/BestiVictory/ILGnet) The aesthetic evaluation of images.\n* [Colorization](https://github.com/richzhang/colorization) Automatic colorization using deep neural networks.\n* [Illustration2Vec](https://github.com/rezoo/illustration2vec) Estimating a set of tags and extracting semantic feature vectors from given illustrations.\n* [CTPN](https://github.com/tianzhi0549/CTPN) Detecting text in natural image.\n* [Image Analogy](https://github.com/msracver/Deep-Image-Analogy) Find semantically-meaningful dense correspondences between two input images.\n* [iLID](https://github.com/twerkmeister/iLID) Automatic spoken language identification.\n* [Fashion Detection](https://github.com/liuziwei7/fashion-detection) Cloth detection from images.\n* [Saliency](https://github.com/imatge-upc/saliency-2016-cvpr) The prediction of salient areas in images has been traditionally addressed with hand-crafted features.\n* [Face Detection](https://github.com/DolotovEvgeniy/DeepPyramid) Detect face from image.\n* [mtcnn](https://github.com/CongWeilin/mtcnn-caffe) Joint Face Detection and Alignment.\n* [deephorizon](https://github.com/scottworkman/deephorizon) Single image horizon line estimation.\n\n# Contributing and License\n* [See the guide](https://github.com/likedan/Awesome-CoreML-Models/blob/master/.github/CONTRIBUTING.md)\n* Distributed under the MIT license. See LICENSE for more information.\n"
        },
        {
          "name": "content.json",
          "type": "blob",
          "size": 17.802734375,
          "content": "{\n      \"types\": [\n            \"image\",\n            \"image-image\",\n            \"text\",\n            \"miscellaneous\"\n      ],\n      \"models\": [\n            {\n                  \"name\": \"TextDetection\",\n                  \"description\": \"Detecting text using Vision built-in model in real-time.\",\n                  \"download_link\": \"\",\n                  \"demo_link\": \"https://github.com/tucan9389/TextDetection-CoreML\",\n                  \"reference_link\": \"https://developer.apple.com/documentation/vision\",\n                  \"type\": \"image\"\n            },\n            {\n                  \"name\": \"PhotoAssessment\",\n                  \"description\": \"Photo Assessment using Core ML and Metal.\",\n                  \"download_link\": \"https://github.com/yulingtianxia/PhotoAssessment/blob/master/PhotoAssessment-Sample/Sources/NIMANasnet.mlmodel\",\n                  \"demo_link\": \"https://github.com/yulingtianxia/PhotoAssessment\",\n                  \"reference_link\": \"https://arxiv.org/abs/1709.05424\",\n                  \"type\": \"image\"\n            },\n            {\n                  \"name\": \"PoseEstimation\",\n                  \"description\": \"Estimating human pose from a picture for mobile.\",\n                  \"download_link\": \"https://github.com/edvardHua/PoseEstimationForMobile/tree/master/release\",\n                  \"demo_link\": \"https://github.com/tucan9389/PoseEstimation-CoreML\",\n                  \"reference_link\": \"https://github.com/edvardHua/PoseEstimationForMobile\",\n                  \"type\": \"image\"\n            },\n            {\n                  \"name\": \"MobileNet\",\n                  \"description\": \"Detects the dominant objects present in an image.\",\n                  \"download_link\": \"https://github.com/hollance/MobileNet-CoreML/raw/master/MobileNet.mlmodel\",\n                  \"demo_link\": \"https://github.com/hollance/MobileNet-CoreML\",\n                  \"reference_link\": \"https://arxiv.org/abs/1704.04861\",\n                  \"type\": \"image\"\n            },\n            {\n                  \"name\": \"Places CNN\",\n                  \"description\": \"Detects the scene of an image from 205 categories such as bedroom, forest, coast etc.\",\n                  \"download_link\": \"https://github.com/hollance/MobileNet-CoreML/raw/master/MobileNet.mlmodel\",\n                  \"demo_link\": \"https://github.com/chenyi1989/CoreMLDemo\",\n                  \"reference_link\": \"http://places.csail.mit.edu/index.html\",\n                  \"type\": \"image\"\n            },\n            {\n                  \"name\": \"Inception v3\",\n                  \"description\": \"Detects the dominant objects present in an image.\",\n                  \"download_link\": \"https://github.com/yulingtianxia/Core-ML-Sample/blob/master/CoreMLSample/Inceptionv3.mlmodel\",\n                  \"demo_link\": \"https://github.com/yulingtianxia/Core-ML-Sample/\",\n                  \"reference_link\": \"https://arxiv.org/abs/1512.00567\",\n                  \"type\": \"image\"\n            },\n            {\n                  \"name\": \"ResNet50\",\n                  \"description\": \"Detects the dominant objects present in an image.\",\n                  \"download_link\": \"https://github.com/ytakzk/CoreML-samples/blob/master/CoreML-samples/Resnet50.mlmodel\",\n                  \"demo_link\": \"https://github.com/ytakzk/CoreML-samples\",\n                  \"reference_link\": \"https://arxiv.org/abs/1512.03385\",\n                  \"type\": \"image\"\n            },\n            {\n                  \"name\": \"VGG16\",\n                  \"description\": \"Detects the dominant objects present in an image.\",\n                  \"download_link\": \"https://docs-assets.developer.apple.com/coreml/models/VGG16.mlmodel\",\n                  \"demo_link\": \"https://github.com/alaphao/CoreMLExample\",\n                  \"reference_link\": \"https://arxiv.org/abs/1409.1556\",\n                  \"type\": \"image\"\n            },\n            {\n                  \"name\": \"Car Recognition\",\n                  \"description\": \"Predict the brand & model of a car.\",\n                  \"download_link\": \"https://github.com/likedan/Core-ML-Car-Recognition/blob/master/Convert/CarRecognition.mlmodel\",\n                  \"demo_link\": \"https://github.com/ytakzk/CoreML-samples\",\n                  \"reference_link\": \"http://mmlab.ie.cuhk.edu.hk/datasets/comp_cars/index.html\",\n                  \"type\": \"image\"\n            },\n            {\n                  \"name\": \"YOLO\",\n                  \"description\": \"Recognize what the objects are inside a given image and where they are in the image.\",\n                  \"download_link\": \"https://github.com/hollance/YOLO-CoreML-MPSNNGraph/blob/master/TinyYOLO-CoreML/TinyYOLO-CoreML/TinyYOLO.mlmodel\",\n                  \"demo_link\": \"https://github.com/hollance/YOLO-CoreML-MPSNNGraph\",\n                  \"reference_link\": \"http://machinethink.net/blog/object-detection-with-yolo\",\n                  \"type\": \"image\"\n            },\n            {\n                  \"name\": \"AgeNet\",\n                  \"description\": \"Predict a person's age from one's portrait.\",\n                  \"download_link\": \"https://drive.google.com/file/d/0B1ghKa_MYL6mT1J3T1BEeWx4TWc/view?usp=sharing\",\n                  \"demo_link\": \"https://github.com/cocoa-ai/FacesVisionDemo\",\n                  \"reference_link\": \"http://www.openu.ac.il/home/hassner/projects/cnn_agegender/\",\n                  \"type\": \"image\"\n            },\n            {\n                  \"name\": \"GenderNet\",\n                  \"description\": \"Predict a person's gender from one's portrait.\",\n                  \"download_link\": \"https://drive.google.com/file/d/0B1ghKa_MYL6mYkNsZHlyc2ZuaFk/view?usp=sharing\",\n                  \"demo_link\": \"https://github.com/cocoa-ai/FacesVisionDemo\",\n                  \"reference_link\": \"http://www.openu.ac.il/home/hassner/projects/cnn_agegender/\",\n                  \"type\": \"image\"\n            },\n            {\n                  \"name\": \"MNIST\",\n                  \"description\": \"Predict handwritten (drawn) digits from images.\",\n                  \"download_link\": \"https://github.com/ph1ps/MNIST-CoreML/raw/master/MNISTPrediction/MNIST.mlmodel\",\n                  \"demo_link\": \"https://github.com/ph1ps/MNIST-CoreML\",\n                  \"reference_link\": \"http://yann.lecun.com/exdb/mnist/\",\n                  \"type\": \"image\"\n            },\n            {\n                  \"name\": \"EmotionNet\",\n                  \"description\": \"Predict a person's emotion from one's portrait.\",\n                  \"download_link\": \"https://drive.google.com/file/d/0B1ghKa_MYL6mTlYtRGdXNFlpWDQ/view?usp=sharing\",\n                  \"demo_link\": \"https://github.com/cocoa-ai/FacesVisionDemo\",\n                  \"reference_link\": \"http://www.openu.ac.il/home/hassner/projects/cnn_emotions/\",\n                  \"type\": \"image\"\n            },\n            {\n                  \"name\": \"HED\",\n                  \"description\": \"Detect nested edges from a color image.\",\n                  \"download_link\": \"https://github.com/s1ddok/HED-CoreML/blob/master/HED-CoreML/Models/HED_so.mlmodel\",\n                  \"demo_link\": \"https://github.com/s1ddok/HED-CoreML\",\n                  \"reference_link\": \"http://dl.acm.org/citation.cfm?id=2654889\",\n                  \"type\": \"image-image\"\n            },\n            {\n                  \"name\": \"SentimentVision\",\n                  \"description\": \"Predict positive or negative sentiments from images.\",\n                  \"download_link\": \"https://drive.google.com/open?id=0B1ghKa_MYL6mZ0dITW5uZlgyNTg\",\n                  \"demo_link\": \"https://github.com/cocoa-ai/SentimentVisionDemo\",\n                  \"reference_link\": \"http://www.sciencedirect.com/science/article/pii/S0262885617300355?via%3Dihub\",\n                  \"type\": \"image\"\n            },\n            {\n                  \"name\": \"Food101\",\n                  \"description\": \"Predict the type of foods from images.\",\n                  \"download_link\": \"https://drive.google.com/open?id=0B5TjkH3njRqnVjBPZGRZbkNITjA\",\n                  \"demo_link\": \"https://github.com/ph1ps/Food101-CoreML\",\n                  \"reference_link\": \"http://visiir.lip6.fr/explore\",\n                  \"type\": \"image\"\n            },\n            {\n                  \"name\": \"Oxford102\",\n                  \"description\": \"Detect the type of flowers from images.\",\n                  \"download_link\": \"https://drive.google.com/file/d/0B1ghKa_MYL6meDBHT2NaZGxkNzQ/view?usp=sharing\",\n                  \"demo_link\": \"https://github.com/cocoa-ai/FlowersVisionDemo\",\n                  \"reference_link\": \"http://jimgoo.com/flower-power/\",\n                  \"type\": \"image\"\n            },\n            {\n                  \"name\": \"FlickrStyle\",\n                  \"description\": \"Detect the artistic style of images.\",\n                  \"download_link\": \"https://drive.google.com/file/d/0B1ghKa_MYL6meDBHT2NaZGxkNzQ/view?usp=sharing\",\n                  \"demo_link\": \"https://github.com/cocoa-ai/StylesVisionDemo\",\n                  \"reference_link\": \"http://sergeykarayev.com/files/1311.3715v3.pdf\",\n                  \"type\": \"image\"\n            },\n            {\n                  \"name\": \"RN1015k500\",\n                  \"description\": \"Predict the location where a picture was taken.\",\n                  \"download_link\": \"https://s3.amazonaws.com/aws-bigdata-blog/artifacts/RN1015k500/RN1015k500.mlmodel\",\n                  \"demo_link\": \"https://github.com/awslabs/MXNet2CoreML_iOS_sample_app\",\n                  \"reference_link\": \"https://aws.amazon.com/blogs/ai/estimating-the-location-of-images-using-mxnet-and-multimedia-commons-dataset-on-aws-ec2\",\n                  \"type\": \"image\"\n            },\n            {\n                  \"name\": \"Nudity\",\n                  \"description\": \"Classifies an image either as NSFW (nude) or SFW (not nude)\\n\",\n                  \"download_link\": \"https://drive.google.com/open?id=0B5TjkH3njRqncDJpdDB1Tkl2S2s\",\n                  \"demo_link\": \"https://github.com/ph1ps/Nudity-CoreML\",\n                  \"reference_link\": \"https://github.com/yahoo/open_nsfw\",\n                  \"type\": \"image\"\n            },\n            {\n                  \"name\": \"AnimeScale2x\",\n                  \"description\": \"Process a bicubic-scaled anime-style artwork\",\n                  \"download_link\": \"https://github.com/imxieyi/waifu2x-ios/blob/master/waifu2x/models/anime_noise0_model.mlmodel\",\n                  \"demo_link\": \"https://github.com/imxieyi/waifu2x-ios\",\n                  \"reference_link\": \"https://arxiv.org/abs/1501.00092\",\n                  \"type\": \"image-image\"\n            },\n            {\n                  \"name\": \"Sentiment Polarity\",\n                  \"description\": \"Predict positive or negative sentiments from sentences.\",\n                  \"download_link\": \"https://github.com/cocoa-ai/SentimentCoreMLDemo/raw/master/SentimentPolarity/Resources/SentimentPolarity.mlmodel\",\n                  \"demo_link\": \"https://github.com/cocoa-ai/SentimentCoreMLDemo\",\n                  \"reference_link\": \"http://boston.lti.cs.cmu.edu/classes/95-865-K/HW/HW3/\",\n                  \"type\": \"text\"\n            },\n            {\n                  \"name\": \"DocumentClassification\",\n                  \"description\": \"Classify news articles into 1 of 5 categories.\",\n                  \"download_link\": \"https://github.com/toddkramer/DocumentClassifier/blob/master/Sources/DocumentClassification.mlmodel\",\n                  \"demo_link\": \"https://github.com/toddkramer/DocumentClassifier\",\n                  \"reference_link\": \"https://github.com/toddkramer/DocumentClassifier/\",\n                  \"type\": \"text\"\n            },\n            {\n                  \"name\": \"iMessage Spam Detection\",\n                  \"description\": \"Detect whether a message is spam.\",\n                  \"download_link\": \"https://github.com/gkswamy98/imessage-spam-detection/blob/master/MessageClassifier.mlmodel\",\n                  \"demo_link\": \"https://github.com/gkswamy98/imessage-spam-detection/tree/master\",\n                  \"reference_link\": \"http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/\",\n                  \"type\": \"text\"\n            },\n            {\n                  \"name\": \"NamesDT\",\n                  \"description\": \"Gender Classification using DecisionTreeClassifier\",\n                  \"download_link\": \"https://github.com/cocoa-ai/NamesCoreMLDemo/blob/master/Names/Resources/NamesDT.mlmodel\",\n                  \"demo_link\": \"https://github.com/cocoa-ai/NamesCoreMLDemo\",\n                  \"reference_link\": \"http://nlpforhackers.io/\",\n                  \"type\": \"text\"\n            },\n            {\n                  \"name\": \"Exermote\",\n                  \"description\": \"Predicts the exercise, when iPhone is worn on right upper arm.\",\n                  \"download_link\": \"https://github.com/Lausbert/Exermote/tree/master/ExermoteInference\",\n                  \"demo_link\": \"https://github.com/Lausbert/Exermote/tree/master/ExermoteInference\",\n                  \"reference_link\": \"http://lausbert.com/2017/08/03/exermote/\",\n                  \"type\": \"miscellaneous\"\n            },\n            {\n                  \"name\": \"GestureAI\",\n                  \"description\": \"Recommend an artist based on given location and genre.\",\n                  \"download_link\": \"https://goo.gl/avdMjD\",\n                  \"demo_link\": \"https://github.com/akimach/GestureAI-CoreML-iOS\",\n                  \"reference_link\": \"https://github.com/akimach/GestureAI-iOS/tree/master/GestureAI\",\n                  \"type\": \"miscellaneous\"\n            },\n            {\n                  \"name\": \"Artists Recommendation\",\n                  \"description\": \"Recommend an artist based on given location and genre.\",\n                  \"download_link\": \"https://github.com/agnosticdev/Blog-Examples/blob/master/UsingCoreMLtoCreateASongRecommendationEngine/Artist.mlmodel\",\n                  \"demo_link\": \"\",\n                  \"reference_link\": \"https://www.agnosticdev.com/blog-entry/python/using-scikit-learn-and-coreml-create-music-recommendation-engine\",\n                  \"type\": \"miscellaneous\"\n            },\n            {\n                  \"name\": \"Personality Detection\",\n                  \"description\": \"Predict personality based on user documents (sentences).\",\n                  \"download_link\": \"https://github.com/novinfard/profiler-sentiment-analysis/tree/master/ios_app/ProfilerSA/ML%20Models\",\n                  \"demo_link\": \"https://github.com/novinfard/profiler-sentiment-analysis/\",\n                  \"reference_link\": \"https://github.com/novinfard/profiler-sentiment-analysis/blob/master/dissertation-v6.pdf\",\n                  \"type\": \"text\"\n            },\n            {\n                  \"name\": \"BERT for Question answering\",\n                  \"description\": \"Swift Core ML 3 implementation of BERT for Question answering\",\n                  \"download_link\": \"https://github.com/huggingface/swift-coreml-transformers/blob/master/Resources/BERTSQUADFP16.mlmodel\",\n                  \"demo_link\": \"https://github.com/huggingface/swift-coreml-transformers#-bert\",\n                  \"reference_link\": \"https://github.com/huggingface/pytorch-transformers#run_squadpy-fine-tuning-on-squad-for-question-answering\",\n                  \"type\": \"text\"\n            },\n            {\n                  \"name\": \"GPT-2\",\n                  \"description\": \"OpenAI GPT-2 Text generation (Core ML 3)\",\n                  \"download_link\": \"https://github.com/huggingface/swift-coreml-transformers/blob/master/Resources/gpt2-512.mlmodel\",\n                  \"demo_link\": \"https://github.com/huggingface/swift-coreml-transformers#-gpt-2\",\n                  \"reference_link\": \"https://github.com/huggingface/pytorch-transformers\",\n                  \"type\": \"text\"\n            },\n            {\n                  \"name\": \"TextRecognition (ML Kit)\",\n                  \"description\": \"Recognizing text using ML Kit built-in model in real-time.\",\n                  \"download_link\": \"\",\n                  \"demo_link\": \"https://github.com/tucan9389/TextRecognition-MLKit\",\n                  \"reference_link\": \"https://firebase.google.com/docs/ml-kit/ios/recognize-text\",\n                  \"type\": \"image\"\n            },\n            {\n                  \"name\": \"ESC-10\",\n                  \"description\": \"Recognize sounds from the ESC-10 sound dataset.\",\n                  \"download_link\": \"https://github.com/narner/ESC10-CoreML/blob/master/CreateML%20Project%20And%20Dataset/ESC-10%20Sound%20Classifier.mlproj/Models/ESC-10%20Sound%20Classifier.mlmodel\",\n                  \"demo_link\": \"https://github.com/narner/ESC10-CoreML/tree/master/ECS10-CoreML-Demo\",\n                  \"reference_link\": \"https://nicholas-arner.squarespace.com/blog/2019/10/29/classification-of-sound-files-on-ios-with-the-soundanalysis-framework\",\n                  \"type\": \"miscellaneous\"\n            },\n            {\n                  \"name\": \"ImageSegmentation\",\n                  \"description\": \"Segment the pixels of a camera frame or image into a predefined set of classes.\",\n                  \"download_link\": \"https://developer.apple.com/machine-learning/models/\",\n                  \"demo_link\": \"https://github.com/tucan9389/ImageSegmentation-CoreML\",\n                  \"reference_link\": \"https://github.com/tensorflow/models/tree/master/research/deeplab\",\n                  \"type\": \"image\"\n            },\n            {\n                  \"name\": \"DepthPrediction\",\n                  \"description\": \"Predict the depth from a single image.\",\n                  \"download_link\": \"https://developer.apple.com/machine-learning/models/\",\n                  \"demo_link\": \"https://github.com/tucan9389/DepthPrediction-CoreML\",\n                  \"reference_link\": \"https://github.com/iro-cp/FCRN-DepthPrediction\",\n                  \"type\": \"image\"\n            },\n            {\n                  \"name\": \"ChordSuggester\",\n                  \"description\": \"Predicts the most likely next chord based on the entered Chord Progression.\",\n                  \"download_link\": \"https://github.com/carlosmbe/Mac-CoreML-Chord-Suggester/blob/main/MLChordSuggester.mlpackage.zip\",\n                  \"demo_link\": \"https://github.com/carlosmbe/Mac-CoreML-Chord-Suggester\",\n                  \"reference_link\": \"https://medium.com/@huanlui/chordsuggester-i-3a1261d4ea9e\",\n                  \"type\": \"miscellaneous\"\n            }\n      ]\n}\n"
        },
        {
          "name": "generate_readme.py",
          "type": "blob",
          "size": 5.2236328125,
          "content": "import json\n\nwith open('content.json', 'r') as f:\n    data = json.load(f)\n\nmodel_metadata = {}\nfor type in data[\"types\"]:\n    model_metadata[type] = []\n\nfor model in data[\"models\"]:\n    model_metadata[model[\"type\"]].append(model)\n\ndef render_model_line(model):\n    return \"* **\" + model[\"name\"] + \"** - \" + model[\"description\"] + \" [Download](\" + model[\"download_link\"] + \") | [Demo](\" + model[\"demo_link\"] + \") | [Reference](\" + model[\"reference_link\"] + \")\\n\"\n\ncontent = \"\"\"\n\n<!--\nTitle: Awesome Core ML Models\nDescription: A curated list of machine learning models in Core ML format.\nAuthor: Kedan Li\n-->\n<p align=\"center\">\n<img src=\"images/coreml.png\" width=\"329\" height=\"295\"/>\n</p>\n\n\nSince iOS 11, Apple released Core ML framework to help developers integrate machine learning models into applications. [The official documentation](https://developer.apple.com/documentation/coreml)\n\nWe've put up the largest collection of machine learning models in Core ML format, to help  iOS, macOS, tvOS, and watchOS developers experiment with machine learning techniques.\n\nIf you've converted a Core ML model, feel free to submit a [pull request](https://github.com/likedan/Awesome-CoreML-Models/compare).\n\nRecently, we've included visualization tools. And here's one [Netron](https://lutzroeder.github.io/Netron).\n\n[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](http://makeapullrequest.com)\n\n# Models\n\n## Image - Metadata/Text\n*Models that takes image data as input and output useful information about the image.*\n\"\"\"\n\nfor model in model_metadata[\"image\"]:\n    content += render_model_line(model)\n\ncontent += \"\"\"\n\n## Image - Image\n*Models that transform image.*\n\"\"\"\n\nfor model in model_metadata[\"image-image\"]:\n    content += render_model_line(model)\n\ncontent += \"\"\"\n\n## Text - Metadata/Text\n*Models that process text data*\n\"\"\"\n\nfor model in model_metadata[\"text\"]:\n    content += render_model_line(model)\n\ncontent += \"## Miscellaneous\\n\"\n\nfor model in model_metadata[\"miscellaneous\"]:\n    content += render_model_line(model)\n\ncontent += \"\"\"\n\n# Visualization Tools\n*Tools that helps visualize CoreML Models*\n* [Netron](https://lutzroeder.github.io/Netron)\n\n# Supported formats\n*List of model formats that could be converted to Core ML with examples*\n* [Caffe](https://apple.github.io/coremltools/generated/coremltools.converters.caffe.convert.html)\n* [Keras](https://apple.github.io/coremltools/generated/coremltools.converters.keras.convert.html)\n* [XGBoost](https://apple.github.io/coremltools/generated/coremltools.converters.xgboost.convert.html)\n* [Scikit-learn](https://apple.github.io/coremltools/generated/coremltools.converters.sklearn.convert.html)\n* [MXNet](https://aws.amazon.com/blogs/ai/bring-machine-learning-to-ios-apps-using-apache-mxnet-and-apple-core-ml/)\n* [LibSVM](https://apple.github.io/coremltools/generated/coremltools.converters.libsvm.convert.html)\n* [Torch7](https://github.com/prisma-ai/torch2coreml)\n\n# The Gold\n*Collections of machine learning models that could be converted to Core ML*\n\n* [Caffe Model Zoo](https://github.com/BVLC/caffe/wiki/Model-Zoo) - Big list of models in Caffe format.\n* [TensorFlow Models](https://github.com/tensorflow/models) - Models for TensorFlow.\n* [TensorFlow Slim Models](https://github.com/tensorflow/models/tree/master/research/slim/README.md) - Another collection of TensorFlow Models.\n* [MXNet Model Zoo](https://mxnet.incubator.apache.org/model_zoo/) - Collection of MXNet models.\n\n*Individual machine learning models that could be converted to Core ML. We'll keep adjusting the list as they become converted.*\n* [LaMem](https://github.com/MiyainNYC/Visual-Memorability-through-Caffe) Score the memorability of pictures.\n* [ILGnet](https://github.com/BestiVictory/ILGnet) The aesthetic evaluation of images.\n* [Colorization](https://github.com/richzhang/colorization) Automatic colorization using deep neural networks.\n* [Illustration2Vec](https://github.com/rezoo/illustration2vec) Estimating a set of tags and extracting semantic feature vectors from given illustrations.\n* [CTPN](https://github.com/tianzhi0549/CTPN) Detecting text in natural image.\n* [Image Analogy](https://github.com/msracver/Deep-Image-Analogy) Find semantically-meaningful dense correspondences between two input images.\n* [iLID](https://github.com/twerkmeister/iLID) Automatic spoken language identification.\n* [Fashion Detection](https://github.com/liuziwei7/fashion-detection) Cloth detection from images.\n* [Saliency](https://github.com/imatge-upc/saliency-2016-cvpr) The prediction of salient areas in images has been traditionally addressed with hand-crafted features.\n* [Face Detection](https://github.com/DolotovEvgeniy/DeepPyramid) Detect face from image.\n* [mtcnn](https://github.com/CongWeilin/mtcnn-caffe) Joint Face Detection and Alignment.\n* [deephorizon](https://github.com/scottworkman/deephorizon) Single image horizon line estimation.\n\n# Contributing and License\n* [See the guide](https://github.com/likedan/Awesome-CoreML-Models/blob/master/.github/CONTRIBUTING.md)\n* Distributed under the MIT license. See LICENSE for more information.\n\"\"\"\n\nwith open(\"README.md\", 'w') as out:\n    out.write(content + '\\n')\n"
        },
        {
          "name": "images",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}