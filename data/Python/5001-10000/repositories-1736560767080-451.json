{
  "metadata": {
    "timestamp": 1736560767080,
    "page": 451,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQ2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "MingchaoZhu/DeepLearning",
      "stars": 6637,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.0302734375,
          "content": "*.txt linguist-language=python\n"
        },
        {
          "name": "11 实践方法论.pdf",
          "type": "blob",
          "size": 634.748046875,
          "content": null
        },
        {
          "name": "2 线性代数.pdf",
          "type": "blob",
          "size": 224.279296875,
          "content": null
        },
        {
          "name": "3 概率与信息论.pdf",
          "type": "blob",
          "size": 564.5341796875,
          "content": null
        },
        {
          "name": "4 数值计算.pdf",
          "type": "blob",
          "size": 110.6396484375,
          "content": null
        },
        {
          "name": "5 机器学习基础.pdf",
          "type": "blob",
          "size": 697.4541015625,
          "content": null
        },
        {
          "name": "6 深度前馈网络.pdf",
          "type": "blob",
          "size": 759.09375,
          "content": null
        },
        {
          "name": "7 深度学习中的正则化.pdf",
          "type": "blob",
          "size": 905.45703125,
          "content": null
        },
        {
          "name": "8 深度模型中的优化.pdf",
          "type": "blob",
          "size": 542.7041015625,
          "content": null
        },
        {
          "name": "9 卷积网络.pdf",
          "type": "blob",
          "size": 864.775390625,
          "content": null
        },
        {
          "name": "DL中文.pdf",
          "type": "blob",
          "size": 11712.677734375,
          "content": ""
        },
        {
          "name": "DL英文.pdf",
          "type": "blob",
          "size": 20616.2802734375,
          "content": ""
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0439453125,
          "content": "MIT License\n\nCopyright (c) 2020 Mingchao Zhu\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 8.2666015625,
          "content": "# Deep Learning\n\n《**深度学习**》是深度学习领域唯一的综合性图书，全称也叫做**深度学习 AI圣经(Deep Learning)**，由三位全球知名专家IanGoodfellow、YoshuaBengio、AaronCourville编著，全书囊括了数学及相关概念的背景知识，包括线性代数、概率论、信息论、数值优化以及机器学习中的相关内容。同时，它还介绍了工业界中实践者用到的深度学习技术，包括深度前馈网络、正则化、优化算法、卷积网络、序列建模和实践方法等，并且调研了诸如自然语言处理、语音识别、计算机视觉、在线推荐系统、生物信息学以及视频游戏方面的应用。最后，深度学习全书还提供了一些研究方向，涵盖的理论主题包括线性因子模型、自编码器、表示学习、结构化概率模型、蒙特卡罗方法、配分函数、近似推断以及深度生成模型，适用于相关专业的大学生或研究生使用。\n\n<img src=\"https://github.com/MingchaoZhu/DeepLearning/blob/master/docs/cover.jpg\" width=\"200\" height=\"300\" alt=\"深度学习封面\" align=center>\n\n可以下载《深度学习》的中文版 [pdf](https://github.com/MingchaoZhu/DeepLearning/releases/download/v0.0.1/DL_cn.pdf) 和英文版 [pdf](https://github.com/MingchaoZhu/DeepLearning/releases/download/v0.0.0/DL_en.pdf) 直接阅读。\n\n对于本项目的工作，你可以直接下载 [深度学习_原理与代码实现.pdf](https://github.com/MingchaoZhu/DeepLearning/releases/download/v1.1.1/default.pdf) (后面会对该书不断更新)\n\n---\n\n《深度学习》可以说是深度学习与人工智能的入门宝典，许多算法爱好者、机器学习培训班、互联网企业的面试，很多都参考这本书。但本书晦涩，加上官方没有提供代码实现，因此某些地方较难理解。本项目**基于数学推导和产生原理重新描述了书中的概念**，并用**Python** (numpy 库为主) 复现了书本内容 ( **源码级代码实现。推导过程和代码实现均放在了下载区的 pdf 文件中**，重要部分的实现代码也放入 **code 文件夹**中 )。\n\n然而我水平有限，但我真诚地希望这项工作可以帮助到更多人学习深度学习算法。我需要大家的建议和帮助。如果你在阅读中遇到有误或解释不清的地方，希望可以汇总你的建议，在 Issues 提出。如果你也想加入这项工作书写中或有其他问题，可以联系我的邮箱。如果你在你的工作或博客中用到了本书，还请可以注明引用链接。\n\n写的过程中参考了较多网上优秀的工作，所有参考资源保存在了`reference.txt`文件中。\n\n# 留言\n\n这份工作就是在写这一本 [深度学习_原理与代码实现.pdf](https://github.com/MingchaoZhu/DeepLearning/releases/download/v1.1.1/default.pdf)。正如你在 pdf 文件中所见到的，《深度学习》涉及到的每一个概念，都会去给它详细的描述、原理层面的推导，以及用代码的实现。代码实现不会调用 Tensorflow、PyTorch、MXNet 等任何深度学习框架，甚至包括 sklearn (pdf 里用到 sklearn 的部分都是用来验证代码无误)，一切代码都是从原理层面实现 (Python 的基础库 NumPy)，并有详细注释，与代码区上方的原理描述区一致，你可以结合原理和代码一起理解。\n\n这份工作的起因是我自身的热爱，但为完成这份工作我需要投入大量的时间精力，一般会写到凌晨两三点。推导、代码、作图都是慢慢打磨的，我会保证这份工作的质量。这份工作会一直更新完，已经上传的章节也会继续补充内容。如果你在阅读过程中遇到有想要描述的概念点或者错误点，请发邮件告知我。\n\n真的很感谢你的认可与推广。最后，请等待下一次更新。\n\n我是 朱明超，我的邮箱是：deityrayleigh@gmail.com\n\n# 更新说明\n\n2020/3/：\n\n```python\n1. 修改第五章决策树部分，补充 ID3 和 CART 的原理，代码实现以 CART 为主。\n2. 第七章添加 L1 和 L2 正则化最优解的推导 (即 L1稀疏解的原理)。\n3. 第七章添加集成学习方法的推导与代码实现，包括 Bagging (随机森林)、Boosting (Adaboost、GBDT、XGBoost)。\n4. 第八章添加牛顿法与拟牛顿法 (DFP、BFGS、L-BFGS) 的推导。\n5. 第十一章节添加贝叶斯线性回归、高斯过程回归 (GPR) 与贝叶斯优化的推导与代码实现。\n```\n后面每次的更新内容会统一放在 `update.txt` 文件中。\n\n# 章节目录与文件下载\n\n除了《深度学习》书中的概念点，**本项目也在各章节添加一些补充知识，例如第七章集成学习部分的 随机森林、Adaboost、GBDT、XGBoost 的原理剖析和代码实现等，又或者第十二章对当前一些主流方法的描述**。大的章节目录和 pdf 文件下载链接可以详见下表，而具体 pdf 文件中的实际目录请参考 `contents.txt`。你可以在下面的 pdf 链接中下载对应章节，也可以在 [releases](https://github.com/MingchaoZhu/DeepLearning/releases) 界面直接下载所有文件。\n\n| 中文章节 | 英文章节 | 下载<br />(含推导与代码实现) |\n| ------------ | ------------ | ------------ |\n| 第一章 前言 | 1 Introduction |  |\n| 第二章 线性代数 | 2 Linear Algebra | [pdf](https://github.com/MingchaoZhu/DeepLearning/raw/master/2%20%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0.pdf) |\n| 第三章 概率与信息论                 | 3 Probability and Information Theory | [pdf](https://github.com/MingchaoZhu/DeepLearning/raw/master/3%20%E6%A6%82%E7%8E%87%E4%B8%8E%E4%BF%A1%E6%81%AF%E8%AE%BA.pdf) |\n| 第四章 数值计算                     | 4 Numerical Computation | [pdf](https://github.com/MingchaoZhu/DeepLearning/raw/master/4%20%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97.pdf) |\n| 第五章 机器学习基础                 | 5 Machine Learning Basics | [pdf](https://github.com/MingchaoZhu/DeepLearning/raw/master/5%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.pdf) |\n| 第六章 深度前馈网络                 | 6 Deep Feedforward Networks | [pdf](https://github.com/MingchaoZhu/DeepLearning/raw/master/6%20%E6%B7%B1%E5%BA%A6%E5%89%8D%E9%A6%88%E7%BD%91%E7%BB%9C.pdf) |\n| 第七章 深度学习中的正则化           | 7 Regularization for Deep Learning | [pdf](https://github.com/MingchaoZhu/DeepLearning/raw/master/7%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%AD%A3%E5%88%99%E5%8C%96.pdf) |\n| 第八章 深度模型中的优化 | 8 Optimization for Training Deep Models | [pdf](https://github.com/MingchaoZhu/DeepLearning/raw/master/8%20%E6%B7%B1%E5%BA%A6%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E4%BC%98%E5%8C%96.pdf) |\n| 第九章 卷积网络 | 9 Convolutional Networks | [pdf](https://github.com/MingchaoZhu/DeepLearning/raw/master/9%20%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C.pdf) |\n| 第十章 序列建模：循环和递归网络 | 10 Sequence Modeling: Recurrent and Recursive Nets |  |\n| 第十一章 实践方法论                 | 11 Practical Methodology | [pdf](https://github.com/MingchaoZhu/DeepLearning/raw/master/11%20%E5%AE%9E%E8%B7%B5%E6%96%B9%E6%B3%95%E8%AE%BA.pdf) |\n| 第十二章 应用 | 12 Applications |  |\n| 第十三章 线性因子模型 | 13 Linear Factor Models |  |\n| 第十四章 自编码器                   | 14 Autoencoders |  |\n| 第十五章 表示学习                   | 15 Representation Learning |  |\n| 第十六章 深度学习中的结构化概率模型 | 16 Structured Probabilistic Models for Deep Learning |  |\n| 第十七章 蒙特卡罗方法 | 17 Monte Carlo Methods |  |\n| 第十八章 直面配分函数 | 18 Confronting the Partition Function |  |\n| 第十九章 近似推断                   | 19 Approximate Inference |  |\n| 第二十章 深度生成模型 | 20 Deep Generative Models |  |\n\n尚未上传的章节会在后续陆续上传。\n\n# 致谢\n\n感谢对本项目的认可和推广。\n\n+ 专知：https://mp.weixin.qq.com/s/dVD-vKJsMGqnBz2v4O-Q3Q\n+ GitHubDaily：https://m.weibo.cn/5722964389/4504392843690487\n+ 程序员遇见GitHub：https://mp.weixin.qq.com/s/EzFOnwpkv7mr2TSjPtVG9A\n+ 爱可可：https://m.weibo.cn/1402400261/4503389646699745\n\n# 赞助\n\n本项目书写耗费时间精力。如果本项目对你有帮助，可以请作者吃份冰淇淋：\n\n<img src=\"./docs/pay.jpg\" width=\"200\" height=\"200\" alt=\"支付\" align=center>\n"
        },
        {
          "name": "code",
          "type": "tree",
          "content": null
        },
        {
          "name": "contents.txt",
          "type": "blob",
          "size": 5.470703125,
          "content": "注：目录是基于《深度学习》的目录起的。基于本项目的内容，目录其实可以分的更细致，这里就分到目录的第三级为止。\n\n**目录**:\n\n- 第二章 线性代数\n  - 1 标量, 向量, 矩阵, 张量\n  - 2 矩阵转置\n  - 3 矩阵加法\n  - 4 矩阵乘法\n  - 5 单位矩阵\n  - 6 矩阵的逆\n  - 7 范数\n  - 8 特征值分解\n  - 9 奇异值分解\n  - 10 PCA (主成分分析)\n\n\n- 第三章 概率与信息论\n  - 1 概率\n    - 1.1 概率与随机变量\n    - 1.2 概率分布\n      - 1.2.1 概率质量函数\n      - 1.2.2 概率密度函数\n      - 1.2.3 累积分布函数\n    - 1.3 条件概率与条件独立\n    - 1.4 随机变量的度量\n    - 1.5 常用概率分布\n      - 1.5.1 伯努利分布 (两点分布)\n      - 1.5.2 范畴分布 (分类分布)\n      - 1.5.3 高斯分布 (正态分布)\n      - 1.5.4 多元高斯分布 (多元正态分布)\n      - 1.5.5 指数分布\n      - 1.5.6 拉普拉斯分布\n      - 1.5.7 Dirac 分布\n    - 1.6 常用函数的有用性质\n      - 1.6.1 logistic sigmoid 函数\n      - 1.6.2 softplus 函数\n  - 2 信息论\n  - 3 图模型\n    - 3.1 有向图模型\n      - 3.1.1 贝叶斯网的独立性\n    - 3.2 无向图模型\n      - 3.1.2 马尔可夫网的条件独立性\n\n\n- 第四章 数值计算\n  - 1 上溢和下溢\n  - 2 优化方法\n    - 2.1 梯度下降法\n    - 2.2 牛顿法\n    - 2.3 约束优化\n\n\n- 第五章 机器学习基础\n  - 1 学习算法\n    - 1.1 举例:线性回归 \n  - 2 容量、过拟合、欠拟合\n    - 2.1 泛化问题\n    - 2.2 容量\n  - 3 超参数与验证集\n  - 4 偏差和方差\n    - 4.1 偏差\n    - 4.2 方差\n    - 4.3 误差与偏差和方差的关系\n  - 5 最大似然估计\n  - 6 贝叶斯统计\n  - 7 最大后验估计\n    - 7.1 举例:线性回归\n  - 8 监督学习方法\n    - 8.1 概率监督学习\n    - 8.2 支持向量机\n      - 8.2.1 核技巧\n    - 8.3 k-近邻\n    - 8.4 决策树\n      - 8.4.1 特征选择\n      - 8.4.2 决策树生成\n      - 8.4.3 决策树正则化\n  - 9 无监督学习方法\n    - 9.1 主成分分析法\n    - 9.2 k-均值聚类\n\n\n- 第六章 深度前馈网络\n  - 1 深度前馈网络\n  - 2 DFN 相关设计\n    - 2.1 隐藏单元\n    - 2.2 输出单元\n    - 2.3 代价函数\n    - 2.4 架构设计\n  - 3 反向传播算法\n    - 3.1 单个神经元的训练\n    - 3.2 多层神经网络的训练\n      - 3.2.1 定义权重初始化方法\n      - 3.2.2 定义激活函数\n      - 3.2.3 定义优化方法\n      - 3.2.4 定义网络层的框架\n      - 3.2.5 定义代价函数\n      - 3.2.6 定义深度前馈网络\n  - 4 神经网络的万能近似定理\n  - 5 实例:学习 XOR\n\n\n- 第七章 深度学习中的正则化\n  - 1 参数范数惩罚\n    - 1.1 L2 正则化\n    - 1.2 L1 正则化\n    - 1.3 总结 (L2 正则化与L1 正则化的解)\n    - 1.4 作为约束的范数惩罚\n    - 1.5 欠约束问题\n  - 2 数据增强\n    - 2.1 数据集增强\n    - 2.2 噪声鲁棒性\n  - 3 训练方案\n    - 3.1 半监督学习\n    - 3.2 多任务学习\n    - 3.3 提前终止\n  - 4 模型表示\n    - 4.1 参数绑定与共享\n    - 4.2 稀疏表示\n    - 4.3 Bagging 及其他集成方法\n      - 4.3.1 Bagging 方法\n      - 4.3.2 随机森林\n      - 4.3.3 方法解决过拟合\n    - 4.4 Dropout\n  - 5 样本测试\n  - 6 补充材料\n    - 6.1 Boosting\n      - 6.1.1 前向分步加法模型\n      - 6.1.2 AdaBoost 算法\n      - 6.1.3 Boosting Tree 算法与 GBDT 算法\n      - 6.1.4 XGBoost 算法\n\n\n- 第八章 深度模型中的优化\n  - 1 基本优化算法\n    - 1.1 梯度\n      - 1.1.1 梯度下降\n      - 1.1.2 随机梯度下降\n    - 1.2 动量\n      - 1.2.1 Momentum 算法\n      - 1.2.2 NAG 算法\n    - 1.3 自适应学习率\n      - 1.3.1 AdaGrad 算法\n      - 1.3.2 RMSProp 算法\n      - 1.3.3 AdaDelta 算法\n      - 1.3.4 Adam 算法\n    - 1.4 二阶近似方法\n      - 1.4.1 牛顿法\n      - 1.4.2 拟牛顿法\n  - 2 优化策略\n    - 2.1 参数初始化\n  - 3 批标准化\n  - 4 坐标下降\n  - 5 Polyak 平均\n  - 6 监督预训练\n  - 7 设计有助于优化的模型\n\n\n- 第九章 卷积网络\n  - 1 卷积运算\n  - 2 池化\n  - 3 深度学习框架下的卷积\n    - 3.1 多个并行卷积\n    - 3.2 输入值与核\n    - 3.3 填充 (Padding)\n    - 3.4 卷积步幅 (Stride)\n  - 4 更多的卷积策略\n    - 4.1 深度可分离卷积 (Depthwise Separable Convolution)\n    - 4.2 分组卷积 (Group Convolution)\n    - 4.3 扩张卷积 (Dilated Convolution)\n  - 5 GEMM 转换\n  - 6 卷积网络的训练\n    - 6.1 卷积网络示意图\n    - 6.2 单层卷积层/池化层\n      - 6.2.1 卷积函数的导数及反向传播\n      - 6.2.2 池化函数的导数及后向传播\n    - 6.3 多层卷积层/池化层\n    - 6.4 Flatten 层 & 全连接层\n  - 7 平移等变\n  - 8 代表性的卷积神经网络\n    - 8.1 卷积神经网络 (LeNet)\n\n\n- 第十一章 实践方法论\n  - 1 实践方法论\n  - 2 性能度量指标\n    - 2.1 错误率与准确性\n    - 2.2 查准率、查全率与 F1 值\n      - 2.2.1 混淆矩阵\n      - 2.2.2 查准率和查全率的定义与关联\n      - 2.2.3 F1 值\n    - 2.3 PR 曲线\n    - 2.4 ROC 曲线与 AUC 值\n      - 2.4.1 ROC 曲线\n      - 2.4.2 AUC 值的计算方法\n    - 2.5 覆盖\n    - 2.6 指标性能的瓶颈\n  - 3 默认基准模型\n  - 4 确定是否收集更多数据\n  - 5 选择超参数\n    - 5.1 手动超参数调整\n    - 5.2 自动超参数优化算法\n      - 5.2.1 网格搜索 (Grid Search)\n      - 5.2.2 随机搜索 (Random Search)\n      - 5.2.3 基于模型的超参数优化 (Model-based Hyperparameter Optimization)\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "reference.txt",
          "type": "blob",
          "size": 3.1044921875,
          "content": "**参考文献**:\n\n- 全局参考\n  - https://github.com/exacity/deeplearningbook-chinese/\n\n- 线性代数\n  - https://github.com/npetrakis/YearOfML\n\n- 概率与信息论\n  - https://github.com/akhilvasvani/Probability-and-Information-Theory\n  - https://docs.scipy.org/doc/scipy/reference/stats.html\n  - https://www.joinquant.com/view/community/detail/be3d8bc42275ea491897ac13fbf5838f\n  - https://my.oschina.net/dillan/blog/134011\n  \n- 数值计算\n\n- 机器学习基础\n  - 《统计学习方法》\n  - 《机器学习》\n  - https://github.com/paruby/ml-basics\n  - https://github.com/akhilvasvani/machine-learning-basics\n  - https://blog.csdn.net/ajianyingxiaoqinghan/article/details/72897399\n\n- 深度前馈网络\n  - https://peterroelants.github.io/posts/cross-entropy-logistic/\n  - https://blog.csdn.net/weixin_36586536/article/details/80468426\n  - https://github.com/yg19930918/deep-learning-from-scratch-master\n  - https://www.cnblogs.com/34fj/p/9036369.html\n  - https://github.com/peterroelants/peterroelants.github.io\n\n- 深度学习中的正则化\n  - https://zhuanlan.zhihu.com/p/35893078\n  - https://www.jiqizhixin.com/articles/2017-06-23-5\n  - https://www.zybuluo.com/songying/note/1400484\n  - https://zhuanlan.zhihu.com/p/37120298\n  - https://kevinzakka.github.io/2016/09/14/batch_normalization/\n  - http://gitlinux.net/2018-10-29-xgboost/\n  - https://medium.com/swlh/boosting-and-bagging-explained-with-examples-5353a36eb78d\n  - http://www.ccs.neu.edu/home/vip/teach/MLcourse/4_boosting/slides/gradient_boosting.pdf\n  - https://blog.csdn.net/liangjun_feng/article/details/79603705\n  - https://blog.csdn.net/sinat_22594309/article/details/60957594\n  - https://www.zybuluo.com/yxd/note/611571\n  - http://freemind.pluskid.org/machine-learning/sparsity-and-some-basics-of-l1-regularization/#ed61992b37932e208ae114be75e42a3e6dc34cb3\n\n- 深度模型中的优化\n  - https://zhuanlan.zhihu.com/p/32626442\n  - https://github.com/exacity/deeplearningbook-chinese\n  - http://cthorey.github.io./backpropagation/\n  - http://www.ludoart.cn/2019/02/22/Optimization-Methods/\n  - https://blog.csdn.net/itplus/article/details/21897715\n  \n- 卷积神经网络\n  - https://www.slideshare.net/kuwajima/cnnbp\n  - https://github.com/exacity/simplified-deeplearning\n  - https://github.com/yg19930918/deep-learning-from-scratch-master\n  - https://adventuresinmachinelearning.com/keras-tutorial-cnn-11-lines/\n  - https://zhangting2020.github.io/2018/05/30/Transform-Invariance/\n  - https://zh.gluon.ai/chapter_convolutional-neural-networks/lenet.html\n  - https://zhuanlan.zhihu.com/p/32702031\n  - https://blog.csdn.net/marsjhao/article/details/73088850\n\n- 实践方法论\n  - https://github.com/masakazu-ishihata/BayesianOptimization\n  - https://github.com/bjzhao143/MLwithPython\n  - https://medium.com/inveterate-learner/deep-learning-book-chapter-11-c6ad1d3c3c08\n  - https://www.alexejgossmann.com/auc/\n  - https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification/\n  - https://www.yuque.com/books/share/f4031f65-70c1-4909-ba01-c47c31398466/kqbfug\n  - http://bridg.land/posts/gaussian-processes-1\n  - https://zhuanlan.zhihu.com/p/76269142\n \n"
        },
        {
          "name": "update.txt",
          "type": "blob",
          "size": 0.5205078125,
          "content": "**更新记录**:\n\n2020/3/：\n\n \t1. 修改第五章决策树部分，补充 ID3 和 CART 的原理，代码实现以 CART 为主。\n \t2. 第七章添加 L1 和 L2 正则化最优解的推导 (即 L1稀疏解的原理)。\n \t3. 第七章添加集成学习方法的推导与代码实现，包括 Bagging (随机森林)、Boosting (Adaboost、GBDT、XGBoost)\n \t4. 第八章添加牛顿法与拟牛顿法 (DFP、BFGS、L-BFGS) 的推导。\n \t5. 第十一章节添加高斯过程回归 (GPR) 与贝叶斯优化的推导与代码实现。\n\n"
        }
      ]
    }
  ]
}