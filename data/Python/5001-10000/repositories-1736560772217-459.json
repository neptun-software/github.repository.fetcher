{
  "metadata": {
    "timestamp": 1736560772217,
    "page": 459,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQ2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "jarun/buku",
      "stars": 6577,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".circleci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.265625,
          "content": "*.py[co]\n*.sw[po]\n.cache/\n.coverage\n.hypothesis\nbuku.egg-info\ndist\nbuild\nbuku.py\n.tox\n.history\n.vscode/launch.json\n/tests/test_bukuDb/places.sqlite*\n/tests/vcr_cassettes/test_search_and_open_all_in_browser.yaml\n/tests/vcr_cassettes/tests.test_bukuDb/\n/bookmarks.db\n/venv/\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 1.08984375,
          "content": "# See https://pre-commit.com for more information\n# See https://pre-commit.com/hooks.html for more hooks\nrepos:\n- repo: https://github.com/pre-commit/pre-commit-hooks\n  rev: v4.3.0\n  hooks:\n  - id: check-added-large-files\n- repo: https://github.com/pycqa/isort\n  rev: 5.10.1\n  hooks:\n  - id: isort\n    name: isort (python)\n    args: [--profile, black, --filter-files]\n- repo: https://github.com/macisamuele/language-formatters-pre-commit-hooks\n  rev: v2.4.0\n  hooks:\n  - id: pretty-format-yaml\n    args: [--autofix]\n- repo: https://github.com/akaihola/darker\n  rev: 1.5.1\n  hooks:\n  - id: darker\n    args: [--line-length, '139', --skip-string-normalization]\n- repo: https://github.com/PyCQA/pylint/\n  rev: v2.15.5\n  hooks:\n  - id: pylint\n    name: pylint\n    entry: pylint\n    language: system\n    types: [python]\n    args: [-rn, -sn, --rcfile=tests/.pylintrc]\n    # \"-rn\", # Only display messages\n    # \"-sn\", # Don't display the score\n    # based on\n    # https://pylint.pycqa.org/en/latest/user_guide/pre-commit-integration.html\n- repo: https://github.com/PyCQA/autoflake\n  rev: v1.7.7\n  hooks:\n  - id: autoflake\n"
        },
        {
          "name": ".readthedocs.yaml",
          "type": "blob",
          "size": 0.71875,
          "content": "# .readthedocs.yaml\n# Read the Docs configuration file\n# See https://docs.readthedocs.io/en/stable/config-file/v2.html for details\n\n# Required\nversion: 2\n\n# Set the version of Python and other tools you might need\nbuild:\n  os: ubuntu-20.04\n  tools:\n    python: '3.9'\n    # You can also specify other tool versions:\n    # nodejs: \"16\"\n    # rust: \"1.55\"\n    # golang: \"1.17\"\n\n# Build documentation in the docs/ directory with Sphinx\nsphinx:\n  configuration: docs/source/conf.py\n\n# If using Sphinx, optionally build your docs in additional formats such as PDF\n# formats:\n#    - pdf\n\n# Optionally declare the Python requirements required to build your docs\npython:\n  install:\n  - method: pip\n    path: .\n    extra_requirements:\n    - docs\n"
        },
        {
          "name": "CHANGELOG",
          "type": "blob",
          "size": 21.0751953125,
          "content": "buku v4.9\n2024-04-07\n\n- fixed profile detection for multiple Firefox installs (#711)\n- added option `--offline` to add a bookmark without web connection\n- added a mini-guide for quick keyboard access to the bookmarklet\n- support environment variable `NO_COLOR`\n- fixed HTML encoding detection (#713)\n- fixed Windows profile detection (#683)\n- support python 3.11 (support for python 3.7 removed)\n- fixed readline internal error on Windows (#704)\n\n-------------------------------------------------------------------------------\n\nbuku v4.8\n2023-02-18\n\n- support Vivaldi browser\n- better XBEL compatibility\n- check for empty search results in piped operations\n- remove python 3.6 support, add 3.10\n- API changes in bukudb (#660):\n  - bookmark data tuples returned from methods `get_rec_all()`\n    & `get_rec_by_id()`, now have user-friendly properties\n    (`id`, `url`, `title`, `desc`, `tags`/`taglist`, `immutable`;\n    as well as for raw DB fields â€“ `tags_raw`, `flags`)\n  - methods `get_rec_all()`, `list_using_id()`, `searchdb()`, `search_by_tag()`,\n    `search_keywords_and_filter_by_tags()` & `exclude_results_from_search()`\n    are now guaranteed to return a list (empty if no data is found)\n  - methods `get_rec_id()`, `get_max_id()` & `add_rec()` now return `None` as\n    the \"no ID\" value\n  - methods `add_rec()`, `update_rec()` & `edit_update_rec()` now treat the\n    value of `immutable` parameter as a boolean (the default/noop value for\n    update calls is `None`)\n  - a `FIELD_FILTER` dictionary is introduced that contains fields formatting\n    description; also, in `format_json()` (and `print_json_safe()`), the output\n    format now matches the one described in CLI help\n- IMPACT: If you have a local repo clone, remove .tox/ subfolder if it's there\n    before you run tests for the first time\n\n-------------------------------------------------------------------------------\n\nbuku v4.7\n2022-07-01\n\n- support XBEL export/import (#569)\n- support for Microsoft Edge bookmarks (#585)\n- block web fetch on import\n- many bukuserver fixes (#543, #545, #547, #548, #553, #554, #559)\n- import nested directory names as tags on html import (#539)\n- fix slow/failed markdown import (#538)\n- fix SSL certificate identification not working on macOS (#528)\n- import tags from markdown (#523)\n- fix broken pipe error with oil (#520)\n\n-------------------------------------------------------------------------------\n\nbuku v4.6\n2021-06-16\n\n- use textwrap to wrap comments and tags when printing in terminal\n- show listing start and end index over prompt in interactive mode\n- option `--nostdin`: don't wait for input (must be first arg) (#513)\n- user-friendly prompt message when watiing for input in non-tty mode\n- several test framework improvements\n\n-------------------------------------------------------------------------------\n\nbuku v4.5\n2020-12-29\n\n- Fix encryption and decryption (#480)\n- Fix Wayback Machine API query\n- Support wayland native copier `wl-copy`\n- Add bookmarklet for bukuserver (#385)\n- Delete by tag without prompting for each bookmark (#458)\n- Fix issue with utf-8 characters in bookmark titles (#456)\n- Fix reomve all tags from prompt (#467)\n- Example to fuzzy search and preview in Quickstart section\n- Replace debug option `-z` with `-g`\n- Support python 3.9, retire python 3.5\n\n-------------------------------------------------------------------------------\n\nbuku v4.4\n2020-06-16\n\n- optionally specify output file with `--json`\n- confirm auto-tag generation in chatty mode\n- unblock GUI browsers when running on WSL\n- handle up to 10 server redirects (#452)\n- fix issue with reverse proxy (#435)\n- use ImportError instead ModuleNotFoundError (#437)\n- import pyreadline on windows (#441)\n- auto-generated package refresh\n\n-------------------------------------------------------------------------------\n\nBuku v4.3\n2020-01-31\n\n- Project renamed to `buku` (small `b`)\n- Export tags in markdown format as comments\n- Tag support for Org import/export\n- Better Windows 10 support\n- Reverse proxy support for `bukuserver`\n- Config `OPEN_IN_NEW_TAB` for `bukuserver`\n- Documentation updated\n- Fix Firefox default profile detection\n- Fix export to DB failing after search\n- Fix broken prompt colors\n- User agent updated\n\n-------------------------------------------------------------------------------\n\nBuku v4.2.2\n2019-05-02\n\n- Fixes broken prompt due to PR #373\n\n-------------------------------------------------------------------------------\n\nBuku v4.2.1\n2019-04-30\n\n- A fix on top of v4.2 to address a packaging problem\n\n-------------------------------------------------------------------------------\n\nBuku v4.2\n2019-04-30\n\n- Disabled appending tags from page on update\n- Improved Windows color support using colorama (optional dep)\n- New format option to show only title and tag\n- Python 3.4 is EOL, support discontinued\n- Several fixes and code refactor\n\n-------------------------------------------------------------------------------\n\nBuku v4.1\n2019-01-15\n\nWhat's in?\n- Import firefox-exported json\n- Fix auto-import for firefox\n- Fix write to GNU Screen paste buffer\n- Some CVE fixes\n\n-------------------------------------------------------------------------------\n\nBuku v4.0\n2018-11-01\n\nWhat's in?\n- Show records in pages with option `-p` (works with `-n`, default 10)\n- Enhanced clipboard support: `xclip`, tmux, GNU Screen, Termux\n- Prompt key `O` works with search results along with GUI browser toggling\n- Search by taglist id with prompt key `g`\n- Multiple fixes\n\n-------------------------------------------------------------------------------\n\nBuku v3.9\n2018-08-30\n\nWhat's in?\n- Set number of search results per page (default 10)\n- Retrieve description and tags from page, if available\n- Visit cached version on Wayback Machine\n- Export works with all search options now\n- Changed user agent to Firefox on Ubuntu\n- Several dependencies made _required_ for installation\n- bukuserver will use Flask-Admin\n\n-------------------------------------------------------------------------------\n\nBuku v3.8\n2018-05-24\n\nWhat's in?\n- A self-hosted http server, bukuserver, that exposes core functionality\n    - browsable front-end on a local web host server\n    - flask default cli interface is used instead custom one\n    - handle not only API but also HTML request\n    - statistic page\n    - CRUD on bookmark\n    - replaces the earlier API module\n- Import complete folder hierarchy as tags during auto-import\n- Merge tags on import even if bookmark URL exists\n- Orgfile import/export\n- Show bookmarks to be deleted before deletion\n- Merge tags during import if bookmark exists\n- Escape regex metacharacters in regex input\n\n-------------------------------------------------------------------------------\n\nBuku v3.7\n2018-03-28\n\nWhat's in?\n- Exclude keywords in search (keyword filtering)\n- Search and filter by tags\n- Order search results by number of keyword matches\n- Copy URL to clipboard\n- Prompt shortcut 'O' to override text browsers\n- New official packagers: Fedora, Gentoo, OpenBSD, openSUSE\n\n-------------------------------------------------------------------------------\n\nBuku v3.6\n2018-01-09\n\nWhat's in?\n- Skip bookmark addition if edit is aborted\n- Use urllib3 for handling http connections everywhere\n- Fix auto-import on FreeBSD\n- Generate packages for openSUSE Leap 42.3, Fedora 27\n\n-------------------------------------------------------------------------------\n\nBuku v3.5\n2017-11-10\n\nWhat's in?\n- Buku now has its own user agent\n- Search works with field filters\n- Edit the last record with `-w=-1` (useful when adding bookmark from GUI)a\n- Support for Chromium browser\n- Colors disabled by default on cmd (Windows), option `--colors` has to be used\n- Get default Firefox profile name from profiles.ini\n- Bash scriptlet to autogen records for testing\n- Some optimization in add record and suggest tags\n- A fresh utility Pinku to import Pinboard bookmarks to Buku\n\n-------------------------------------------------------------------------------\n\nBuku v3.4\n2017-09-18\n\nWhat's in?\n- Export bookmarks (including specific tags) to Buku DB file using `--export`\n- Option `--import` can merge Buku DB files now, option `--merge` is retired\n- Option `--suggest` now works at prompt as well\n- Auto-import issue when Firefox is not installed fixed\n\n-------------------------------------------------------------------------------\n\nBuku v3.3.1\n2017-09-11\n\nThis is for all purposes the same as v3.3. We had to re-upload a new version to\nPyPi and hence the new tag. Functionality remains the same.\n\nThe tagline is changed to - `Powerful command-line bookmark manager.`\n\n-------------------------------------------------------------------------------\n\nBuku v3.3\n2017-09-11\n\nWhat's in?\n- Auto-import (`--ai`) bookmarks from Firefox and Google Chrome\n- Support custom colors (`--colors`)\n- Search multiple tags (with exclusion)\n- Timestamp (YYYYMonDD) tag in auto-imported bookmarks\n- Enable browser output for text browsers\n- Generate documentation in RTD using Sphinx (http://buku.readthedocs.io)\n- Integrated flake8 and pylint in Travis CI\n- Integrated PackageCore to auto-generate packages in Travis CI\n\n-------------------------------------------------------------------------------\n\nBuku v3.2\n2017-08-03\n\nWhat's in?\n- Option `--suggest` to list and choose similar tags when adding a bookmark\n- Ask for a unique tag when importing bookmarks\n- Ignore non-generic URLs when importing browser exported bookmarks\n\n-------------------------------------------------------------------------------\n\nBuku v3.1\n2017-06-30\n\nWhat's in?\n- Handle negative indices (like tail) with option `-p`\n- Support browsing bookmarks from prompt (key `o`)\n- Add program search keywords to history\n- Support XDG_DATA_HOME and HOME as env vars on all platforms\n- Replace %USERPROFILE% with %APPDATA% as install location on Windows\n\n-------------------------------------------------------------------------------\n\nBuku v3.0\n2017-04-26\n\nWhat's in?\n- Edit bookmarks in EDITOR at prompt\n- Import folder names as tags from browser HTML (thanks @mohammadKhalifa)\n- Append, overwrite, delete tags at prompt using >>, >, << (familiar, eh? ;))\n- Negative indices with `--print` (like `tail`)\n- Update in EDITOR along with `--immutable`\n- Request HTTP HEAD for immutable records\n- Interface revamp (title on top in bold, colour changes...)\n- Per-level colourful logs in colour mode\n- Changes in program OPTIONS\n  - `-t` stands for tag search (earlier `--title`)\n  - `-r` stands for regex search (earlier `--replace`)\n- Lots of new automated test cases (thanks @rachmadaniHaryono)\n- REST APIs for server-side apps (thanks @kishore-narendran)\n- Document, notify behaviour when not invoked from tty (thanks @The-Compiler)\n- Fix Firefox tab-opening issues on Windows (thanks @dertuxmalwieder)\n\n-------------------------------------------------------------------------------\n\nBuku v2.9\n2017-02-20\n\nModifications\n- New option `--write` to compose and edit bookmarks in text editor\n- Support positional arguments as search keywords\n- New option `--oa` to search and open results directly in browser\n- Autodetect Markdown mode by file extension during export, import\n- Shortened options:\n    - `--nc` replaces `--nocolor`\n    - `--np` replaces `--noprompt`\n    - `-V` replaces `--upstream`\n- Option `--markdown` removed as the mode is autodetected now\n\n-------------------------------------------------------------------------------\n\nBuku v2.8\n2017-01-11\n\nModifications\n- Multithreaded full DB refresh with delayed writes\n- Customize number of threads for full DB refresh (default 4)\n- Support search and update search results in a go\n- Support shortened URL expansion\n- Support multiple bookmarks with `--open`\n- Support `--nocolor` (for scripting, Windows users)\n- Support https_proxy with `--upstream` and `--shorten`\n- Remove trailing `/` from search tokens (like Google search)\n- Support `--version` to show program version\n- Fixed #109: Missing + when shortening URL\n- Performance optimizations, few module dependency removals\n\n-------------------------------------------------------------------------------\n\nBuku v2.7\n2016-11-30\n\nModifications\n- Continuous search at (redesigned) prompt\n- urllib3 for all HTTP operations\n- Use HTTP HEAD method for pdf and txt mime types\n- Add user agent (Firefox 50 on Ubuntu)\n- Support URL shortening\n- List bookmarks by tag index in tag list\n- Show tag usage count in tag list\n- Store tags in lowercase (use undocumented option `--fixtags` to fix old tags)\n- Support environment variable *https_proxy*\n- Support option `--immutable` to pin titles\n- Keyword `immutable` to search (`-S`) pinned titles\n- Show index in JSON output\n- New key *q* to quit prompt\n- Support deflate compression\n- Add option `--tacit` to reduce verbosity of some operations\n- **Removed** option `--st`, only `--stag` to search tags\n- Support custom DB file location (for library, not exposed to user)\n\n-------------------------------------------------------------------------------\n\nBuku v2.6\n2016-11-04\n\nModifications\n- Support Markdown import/export\n- Support regex search\n- New option `--upstream` to check latest upstream version\n- Fix search and delete behaviour\n- Lot of code reformatting, performance improvements\n- Use delayed commit wherever possible (e.g. bulk deletion cases)\n- When a range is specified, consider 0 as ALL\n- Added option to control verbosity in some APIs\n- In-source documentation update\n\n-------------------------------------------------------------------------------\n\nBuku v2.5\n2016-10-20\n\nModifications\n- Export specific tags to HTML\n- Fixed obvious issues on Windows\n- Open a random bookmark with option --open\n- Support lists and ranges with --print\n- Show a bookmark on tag append\n- Show only title with --format=3\n- PEP8 compliance fixes\n- Buku GUI integration documented\n\n-------------------------------------------------------------------------------\n\nBuku v2.4\n2016-09-12\n\nModifications\n- Exact word match support using regex (**default**)\n- New option --deep to scan matching substrings\n- Support DB index lists and ranges in update operation\n- Open a list or range of search results in browser\n- Open all search results in browser\n- A more concise prompt\n- PEP8 compliance (almost)\n- Tons of new test cases added (thanks @wheresmyjetpack)\n\n-------------------------------------------------------------------------------\n\nBuku v2.3\n2016-07-14\n\nModifications\n- Delete a range or a list of indices\n- Delete tag from tagset by bookmark index\n- Delete results of a particular search\n- Linked to rofi front-end script project for Buku\n- Use the logging framework for debug info instead of print\n- Fixed an issue with gzip stream decoding\n- Using only relative path to fetch resource on server\n- Fixed auto-completion errors with Zsh\n- A lot of code cleanup and globals removed, additional test cases\n\n-------------------------------------------------------------------------------\n\nBuku v2.2\n2016-06-12\n\nModifications\n- Export bookmarks to Firefox bookmarks formatted HTML\n- Merge Buku database\n- .deb package for Debian and Ubuntu family\n- Switch from PyCrypto to cryptography (thanks @asergi)\n- Append tags support\n- Filter tags for duplicates and sort alphabetically\n- Travis CI integration, more test cases (thanks @poikjhn)\n- Show DB index in bold in search results\n- Several performance optimizations\n\n-------------------------------------------------------------------------------\n\nBuku v2.1\n2016-05-28\n\nModifications\n- Import bookmarks from Firefox, Google Chrome or IE HTML bookmark exports\n- Support comments on bookmarks\n- Prettier output using symbols (`>` title, `+` comments, `#` tags)\n- New option (`--st`, `--stag`) to search by tag\n- New option (`--noprompt`) for noninteractive mode\n- New options (`--url` and `--tag`)\n- `--update` now handles each option (url, tag, title, comment) independently\n- Several messages removed or moved to debug\n\n-------------------------------------------------------------------------------\n\nBuku v2.0\n2016-05-15\n\nModifications\nTo begin with, 2.0 is a significant release with respect to options. `Buku` now has fewer options with more (and merged) functionality. Please go through the program help at least once to understand the changes.\n\n- Replace getopt with argparse for parsing arguments\n- Long options for each short option\n- Options changed\n    - insert: removed as automatic DB compaction serves the purpose (previously `-i`)\n    - iterations: removed as optional argument to `-l` and `-k` (previously `-t`)\n    - title: `-t` is now the short option to set title manually (previously `-m`)\n    - Special search keywords for ALL search (`-S`):\n        - tags: show all tags (previously `-g`)\n        - blank: show bookmarks with empty tags (previously `-e`)\n    - lock/unlock: now accepts number of hash iterations to generate key\n    - format: print formatting option changed to `-f` (previously `-x`)\n    - help: option added to show program help\n- Following options apply to ALL bookmarks without arguments\n    - `-u`, `--update`\n    - `-d`, `--delete`\n    - `-p`, `--print`\n- Shell-completion scripts for Bash, Fish and Zsh\n- Warn if URL is not HTTP(S)\n- More comprehensive help\n- Fix a bug with deletion when only one entry in DB\n- Some import dependencies removed or late loaded (if optional)\n- Handle exception if DB file is encrypted or invalid\n\n-------------------------------------------------------------------------------\n\nBuku v1.9\n2016-04-23\n\nModifications\n- **New location for database file** (refer to README or man page). The old database file, if exists, is migrated automatically.\n- **Removed options**\n    - `-P`: (print all) is now `-p 0`\n    - `-D`: (delete all) is now `-d 0`\n    - `-R`: (update all) is now `-u 0`\n    - `-w`: title web fetch is now the default behaviour, override with `-m title` option\n- **Change in search behaviour**\n    - `-s`: search bookmarks for ANY keyword in URL, title or tags\n    - `-S`: search bookmarks for ALL keywords in URL, title or tags\n- Update only title of a bookmark (`-u N`)\n- Set empty title (`-m none`)\n- Support HTTP(S) gzip compression\n- Optional JSON output for `-p` and `-s` options (thanks @CaptainQuirk)\n- Reformatted help and man page with general options on top\n- Optimize add and insert: ensure URL is not in DB already\n- Handle URLs passed with %xx escape\n- Retry with truncated resource path on HTTP error 500\n- Several code optimizations\n- Catchier errors and warnings\n- Version added to debug logs\n\n-------------------------------------------------------------------------------\n\nBuku v1.8\n2016-03-26\n\nModifications\n- Auto compact DB on single record removal\n- Handle piped input\n- Better tag management\n    - Tag modify or delete support\n    - Show unique tags alphabetically\n- Full DB refresh\n    - Fix stuff broken earlier\n    - Optimize to update titles only\n    - Update titles only if non-empty to preserve earlier data\n- Redirection\n    - Handle multiple redirections\n    - Detect redirection loop and break\n    - Show redirected link in bold\n- List all bookmarks with no title or tags (for manual bookkeeping)\n- Confirm full DB removal\n- Better comma (`,`) separator handling for tags\n- Help\n    - Place regular options before power options in program help\n    - Help added in man page for quick reference\n    - Additional examples for new features\n- Errors & warnings\n    - Error out if both encrypted and flat DB files exist\n    - Catchier error and warning messages\n\n-------------------------------------------------------------------------------\n\nBuku v1.7\n2016-03-15\n\nModifications\n- Add title manually using option `-m`\n- Unquote redirected URL\n- Quit on `Ctrl-d` at prompt\n- More dynamic shebang for python3\n\n-------------------------------------------------------------------------------\n\nBuku v1.6\n2016-01-22\n\nModifications\n- Stronger encryption: 256-bit salt, multi-hash key.\n- Allow user to specify number of iterations to generate key (check option `-t`).\n\n-------------------------------------------------------------------------------\n\nBuku v1.5\n2015-12-20\n\nModifications\n- Project name changed to `Buku` to avoid any copyright issues. This also means old users have to move the database file. Run:\n<pre>$ mkdir ~/.cache/buku/\n$ mv ~/.cache/markit/bookmarks.db ~/.cache/buku/bookmarks.db\n$ rm -rf ~/.cache/markit/bookmarks.db</pre>\n- Manual AES-256 encryption and decryption support (password protection) implemented. This adds dependency on PyCrypto module. Installation instructions updated in README.\n- Some typos fixed (thanks @GuilhermeHideki)\n\n-------------------------------------------------------------------------------\n\nMarkIt v1.4\n2015-11-13\n\nModifications\n- Refresh full bookmark database. Fetch titles from the web, retain tags.\n- Notify empty titles in red during online add or update.\n\n-------------------------------------------------------------------------------\n\nMarkIt v1.2\n2015-11-11\n\nModifications\n- Introduced `-S` search option to match ALL keywords in URL or title\n- Introduced `-x` option to show unformatted selective output (for creating batch scripts)\n- Added examples on batch add and update (refresh) scripts\n- Handle multiple title tags in page\n- Handle title data within another tag (e.g. head)\n- Show DB index in search results, removal and update confirmation message\n\n-------------------------------------------------------------------------------\n\nMarkIt v1.1\n2015-11-10\n\nModifications\n- Replace Unicode chars in title data before UTF-8 decoding (for parser to succeed).\n\n-------------------------------------------------------------------------------\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.58984375,
          "content": "FROM python:alpine\n\nMAINTAINER Ameya Shenoy \"shenoy.ameya@gmail.com\"\n\nENV BUKUSERVER_PORT=5001\n\nCOPY . /buku\n\nARG CRYPTOGRAPHY_DONT_BUILD_RUST=1\n\nRUN set -ex \\\n  && apk add --no-cache --virtual .build-deps \\\n    gcc \\\n    openssl-dev \\\n    musl-dev \\\n    libffi-dev \\\n  && pip install -U --no-cache-dir \\\n    pip \\\n    gunicorn \\\n    /buku[server] \\\n  && apk del .build-deps \\\n  && rm -rf /buku\n\nHEALTHCHECK --interval=1m --timeout=10s \\\n  CMD nc -z localhost ${BUKUSERVER_PORT} || exit 1\n\nENTRYPOINT gunicorn --bind 0.0.0.0:${BUKUSERVER_PORT} \"bukuserver.server:create_app()\"\nEXPOSE ${BUKUSERVER_PORT}\n\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 34.318359375,
          "content": "                    GNU GENERAL PUBLIC LICENSE\n                       Version 3, 29 June 2007\n\n Copyright (C) 2007 Free Software Foundation, Inc. <http://fsf.org/>\n Everyone is permitted to copy and distribute verbatim copies\n of this license document, but changing it is not allowed.\n\n                            Preamble\n\n  The GNU General Public License is a free, copyleft license for\nsoftware and other kinds of works.\n\n  The licenses for most software and other practical works are designed\nto take away your freedom to share and change the works.  By contrast,\nthe GNU General Public License is intended to guarantee your freedom to\nshare and change all versions of a program--to make sure it remains free\nsoftware for all its users.  We, the Free Software Foundation, use the\nGNU General Public License for most of our software; it applies also to\nany other work released this way by its authors.  You can apply it to\nyour programs, too.\n\n  When we speak of free software, we are referring to freedom, not\nprice.  Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthem if you wish), that you receive source code or can get it if you\nwant it, that you can change the software or use pieces of it in new\nfree programs, and that you know you can do these things.\n\n  To protect your rights, we need to prevent others from denying you\nthese rights or asking you to surrender the rights.  Therefore, you have\ncertain responsibilities if you distribute copies of the software, or if\nyou modify it: responsibilities to respect the freedom of others.\n\n  For example, if you distribute copies of such a program, whether\ngratis or for a fee, you must pass on to the recipients the same\nfreedoms that you received.  You must make sure that they, too, receive\nor can get the source code.  And you must show them these terms so they\nknow their rights.\n\n  Developers that use the GNU GPL protect your rights with two steps:\n(1) assert copyright on the software, and (2) offer you this License\ngiving you legal permission to copy, distribute and/or modify it.\n\n  For the developers' and authors' protection, the GPL clearly explains\nthat there is no warranty for this free software.  For both users' and\nauthors' sake, the GPL requires that modified versions be marked as\nchanged, so that their problems will not be attributed erroneously to\nauthors of previous versions.\n\n  Some devices are designed to deny users access to install or run\nmodified versions of the software inside them, although the manufacturer\ncan do so.  This is fundamentally incompatible with the aim of\nprotecting users' freedom to change the software.  The systematic\npattern of such abuse occurs in the area of products for individuals to\nuse, which is precisely where it is most unacceptable.  Therefore, we\nhave designed this version of the GPL to prohibit the practice for those\nproducts.  If such problems arise substantially in other domains, we\nstand ready to extend this provision to those domains in future versions\nof the GPL, as needed to protect the freedom of users.\n\n  Finally, every program is threatened constantly by software patents.\nStates should not allow patents to restrict development and use of\nsoftware on general-purpose computers, but in those that do, we wish to\navoid the special danger that patents applied to a free program could\nmake it effectively proprietary.  To prevent this, the GPL assures that\npatents cannot be used to render the program non-free.\n\n  The precise terms and conditions for copying, distribution and\nmodification follow.\n\n                       TERMS AND CONDITIONS\n\n  0. Definitions.\n\n  \"This License\" refers to version 3 of the GNU General Public License.\n\n  \"Copyright\" also means copyright-like laws that apply to other kinds of\nworks, such as semiconductor masks.\n\n  \"The Program\" refers to any copyrightable work licensed under this\nLicense.  Each licensee is addressed as \"you\".  \"Licensees\" and\n\"recipients\" may be individuals or organizations.\n\n  To \"modify\" a work means to copy from or adapt all or part of the work\nin a fashion requiring copyright permission, other than the making of an\nexact copy.  The resulting work is called a \"modified version\" of the\nearlier work or a work \"based on\" the earlier work.\n\n  A \"covered work\" means either the unmodified Program or a work based\non the Program.\n\n  To \"propagate\" a work means to do anything with it that, without\npermission, would make you directly or secondarily liable for\ninfringement under applicable copyright law, except executing it on a\ncomputer or modifying a private copy.  Propagation includes copying,\ndistribution (with or without modification), making available to the\npublic, and in some countries other activities as well.\n\n  To \"convey\" a work means any kind of propagation that enables other\nparties to make or receive copies.  Mere interaction with a user through\na computer network, with no transfer of a copy, is not conveying.\n\n  An interactive user interface displays \"Appropriate Legal Notices\"\nto the extent that it includes a convenient and prominently visible\nfeature that (1) displays an appropriate copyright notice, and (2)\ntells the user that there is no warranty for the work (except to the\nextent that warranties are provided), that licensees may convey the\nwork under this License, and how to view a copy of this License.  If\nthe interface presents a list of user commands or options, such as a\nmenu, a prominent item in the list meets this criterion.\n\n  1. Source Code.\n\n  The \"source code\" for a work means the preferred form of the work\nfor making modifications to it.  \"Object code\" means any non-source\nform of a work.\n\n  A \"Standard Interface\" means an interface that either is an official\nstandard defined by a recognized standards body, or, in the case of\ninterfaces specified for a particular programming language, one that\nis widely used among developers working in that language.\n\n  The \"System Libraries\" of an executable work include anything, other\nthan the work as a whole, that (a) is included in the normal form of\npackaging a Major Component, but which is not part of that Major\nComponent, and (b) serves only to enable use of the work with that\nMajor Component, or to implement a Standard Interface for which an\nimplementation is available to the public in source code form.  A\n\"Major Component\", in this context, means a major essential component\n(kernel, window system, and so on) of the specific operating system\n(if any) on which the executable work runs, or a compiler used to\nproduce the work, or an object code interpreter used to run it.\n\n  The \"Corresponding Source\" for a work in object code form means all\nthe source code needed to generate, install, and (for an executable\nwork) run the object code and to modify the work, including scripts to\ncontrol those activities.  However, it does not include the work's\nSystem Libraries, or general-purpose tools or generally available free\nprograms which are used unmodified in performing those activities but\nwhich are not part of the work.  For example, Corresponding Source\nincludes interface definition files associated with source files for\nthe work, and the source code for shared libraries and dynamically\nlinked subprograms that the work is specifically designed to require,\nsuch as by intimate data communication or control flow between those\nsubprograms and other parts of the work.\n\n  The Corresponding Source need not include anything that users\ncan regenerate automatically from other parts of the Corresponding\nSource.\n\n  The Corresponding Source for a work in source code form is that\nsame work.\n\n  2. Basic Permissions.\n\n  All rights granted under this License are granted for the term of\ncopyright on the Program, and are irrevocable provided the stated\nconditions are met.  This License explicitly affirms your unlimited\npermission to run the unmodified Program.  The output from running a\ncovered work is covered by this License only if the output, given its\ncontent, constitutes a covered work.  This License acknowledges your\nrights of fair use or other equivalent, as provided by copyright law.\n\n  You may make, run and propagate covered works that you do not\nconvey, without conditions so long as your license otherwise remains\nin force.  You may convey covered works to others for the sole purpose\nof having them make modifications exclusively for you, or provide you\nwith facilities for running those works, provided that you comply with\nthe terms of this License in conveying all material for which you do\nnot control copyright.  Those thus making or running the covered works\nfor you must do so exclusively on your behalf, under your direction\nand control, on terms that prohibit them from making any copies of\nyour copyrighted material outside their relationship with you.\n\n  Conveying under any other circumstances is permitted solely under\nthe conditions stated below.  Sublicensing is not allowed; section 10\nmakes it unnecessary.\n\n  3. Protecting Users' Legal Rights From Anti-Circumvention Law.\n\n  No covered work shall be deemed part of an effective technological\nmeasure under any applicable law fulfilling obligations under article\n11 of the WIPO copyright treaty adopted on 20 December 1996, or\nsimilar laws prohibiting or restricting circumvention of such\nmeasures.\n\n  When you convey a covered work, you waive any legal power to forbid\ncircumvention of technological measures to the extent such circumvention\nis effected by exercising rights under this License with respect to\nthe covered work, and you disclaim any intention to limit operation or\nmodification of the work as a means of enforcing, against the work's\nusers, your or third parties' legal rights to forbid circumvention of\ntechnological measures.\n\n  4. Conveying Verbatim Copies.\n\n  You may convey verbatim copies of the Program's source code as you\nreceive it, in any medium, provided that you conspicuously and\nappropriately publish on each copy an appropriate copyright notice;\nkeep intact all notices stating that this License and any\nnon-permissive terms added in accord with section 7 apply to the code;\nkeep intact all notices of the absence of any warranty; and give all\nrecipients a copy of this License along with the Program.\n\n  You may charge any price or no price for each copy that you convey,\nand you may offer support or warranty protection for a fee.\n\n  5. Conveying Modified Source Versions.\n\n  You may convey a work based on the Program, or the modifications to\nproduce it from the Program, in the form of source code under the\nterms of section 4, provided that you also meet all of these conditions:\n\n    a) The work must carry prominent notices stating that you modified\n    it, and giving a relevant date.\n\n    b) The work must carry prominent notices stating that it is\n    released under this License and any conditions added under section\n    7.  This requirement modifies the requirement in section 4 to\n    \"keep intact all notices\".\n\n    c) You must license the entire work, as a whole, under this\n    License to anyone who comes into possession of a copy.  This\n    License will therefore apply, along with any applicable section 7\n    additional terms, to the whole of the work, and all its parts,\n    regardless of how they are packaged.  This License gives no\n    permission to license the work in any other way, but it does not\n    invalidate such permission if you have separately received it.\n\n    d) If the work has interactive user interfaces, each must display\n    Appropriate Legal Notices; however, if the Program has interactive\n    interfaces that do not display Appropriate Legal Notices, your\n    work need not make them do so.\n\n  A compilation of a covered work with other separate and independent\nworks, which are not by their nature extensions of the covered work,\nand which are not combined with it such as to form a larger program,\nin or on a volume of a storage or distribution medium, is called an\n\"aggregate\" if the compilation and its resulting copyright are not\nused to limit the access or legal rights of the compilation's users\nbeyond what the individual works permit.  Inclusion of a covered work\nin an aggregate does not cause this License to apply to the other\nparts of the aggregate.\n\n  6. Conveying Non-Source Forms.\n\n  You may convey a covered work in object code form under the terms\nof sections 4 and 5, provided that you also convey the\nmachine-readable Corresponding Source under the terms of this License,\nin one of these ways:\n\n    a) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by the\n    Corresponding Source fixed on a durable physical medium\n    customarily used for software interchange.\n\n    b) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by a\n    written offer, valid for at least three years and valid for as\n    long as you offer spare parts or customer support for that product\n    model, to give anyone who possesses the object code either (1) a\n    copy of the Corresponding Source for all the software in the\n    product that is covered by this License, on a durable physical\n    medium customarily used for software interchange, for a price no\n    more than your reasonable cost of physically performing this\n    conveying of source, or (2) access to copy the\n    Corresponding Source from a network server at no charge.\n\n    c) Convey individual copies of the object code with a copy of the\n    written offer to provide the Corresponding Source.  This\n    alternative is allowed only occasionally and noncommercially, and\n    only if you received the object code with such an offer, in accord\n    with subsection 6b.\n\n    d) Convey the object code by offering access from a designated\n    place (gratis or for a charge), and offer equivalent access to the\n    Corresponding Source in the same way through the same place at no\n    further charge.  You need not require recipients to copy the\n    Corresponding Source along with the object code.  If the place to\n    copy the object code is a network server, the Corresponding Source\n    may be on a different server (operated by you or a third party)\n    that supports equivalent copying facilities, provided you maintain\n    clear directions next to the object code saying where to find the\n    Corresponding Source.  Regardless of what server hosts the\n    Corresponding Source, you remain obligated to ensure that it is\n    available for as long as needed to satisfy these requirements.\n\n    e) Convey the object code using peer-to-peer transmission, provided\n    you inform other peers where the object code and Corresponding\n    Source of the work are being offered to the general public at no\n    charge under subsection 6d.\n\n  A separable portion of the object code, whose source code is excluded\nfrom the Corresponding Source as a System Library, need not be\nincluded in conveying the object code work.\n\n  A \"User Product\" is either (1) a \"consumer product\", which means any\ntangible personal property which is normally used for personal, family,\nor household purposes, or (2) anything designed or sold for incorporation\ninto a dwelling.  In determining whether a product is a consumer product,\ndoubtful cases shall be resolved in favor of coverage.  For a particular\nproduct received by a particular user, \"normally used\" refers to a\ntypical or common use of that class of product, regardless of the status\nof the particular user or of the way in which the particular user\nactually uses, or expects or is expected to use, the product.  A product\nis a consumer product regardless of whether the product has substantial\ncommercial, industrial or non-consumer uses, unless such uses represent\nthe only significant mode of use of the product.\n\n  \"Installation Information\" for a User Product means any methods,\nprocedures, authorization keys, or other information required to install\nand execute modified versions of a covered work in that User Product from\na modified version of its Corresponding Source.  The information must\nsuffice to ensure that the continued functioning of the modified object\ncode is in no case prevented or interfered with solely because\nmodification has been made.\n\n  If you convey an object code work under this section in, or with, or\nspecifically for use in, a User Product, and the conveying occurs as\npart of a transaction in which the right of possession and use of the\nUser Product is transferred to the recipient in perpetuity or for a\nfixed term (regardless of how the transaction is characterized), the\nCorresponding Source conveyed under this section must be accompanied\nby the Installation Information.  But this requirement does not apply\nif neither you nor any third party retains the ability to install\nmodified object code on the User Product (for example, the work has\nbeen installed in ROM).\n\n  The requirement to provide Installation Information does not include a\nrequirement to continue to provide support service, warranty, or updates\nfor a work that has been modified or installed by the recipient, or for\nthe User Product in which it has been modified or installed.  Access to a\nnetwork may be denied when the modification itself materially and\nadversely affects the operation of the network or violates the rules and\nprotocols for communication across the network.\n\n  Corresponding Source conveyed, and Installation Information provided,\nin accord with this section must be in a format that is publicly\ndocumented (and with an implementation available to the public in\nsource code form), and must require no special password or key for\nunpacking, reading or copying.\n\n  7. Additional Terms.\n\n  \"Additional permissions\" are terms that supplement the terms of this\nLicense by making exceptions from one or more of its conditions.\nAdditional permissions that are applicable to the entire Program shall\nbe treated as though they were included in this License, to the extent\nthat they are valid under applicable law.  If additional permissions\napply only to part of the Program, that part may be used separately\nunder those permissions, but the entire Program remains governed by\nthis License without regard to the additional permissions.\n\n  When you convey a copy of a covered work, you may at your option\nremove any additional permissions from that copy, or from any part of\nit.  (Additional permissions may be written to require their own\nremoval in certain cases when you modify the work.)  You may place\nadditional permissions on material, added by you to a covered work,\nfor which you have or can give appropriate copyright permission.\n\n  Notwithstanding any other provision of this License, for material you\nadd to a covered work, you may (if authorized by the copyright holders of\nthat material) supplement the terms of this License with terms:\n\n    a) Disclaiming warranty or limiting liability differently from the\n    terms of sections 15 and 16 of this License; or\n\n    b) Requiring preservation of specified reasonable legal notices or\n    author attributions in that material or in the Appropriate Legal\n    Notices displayed by works containing it; or\n\n    c) Prohibiting misrepresentation of the origin of that material, or\n    requiring that modified versions of such material be marked in\n    reasonable ways as different from the original version; or\n\n    d) Limiting the use for publicity purposes of names of licensors or\n    authors of the material; or\n\n    e) Declining to grant rights under trademark law for use of some\n    trade names, trademarks, or service marks; or\n\n    f) Requiring indemnification of licensors and authors of that\n    material by anyone who conveys the material (or modified versions of\n    it) with contractual assumptions of liability to the recipient, for\n    any liability that these contractual assumptions directly impose on\n    those licensors and authors.\n\n  All other non-permissive additional terms are considered \"further\nrestrictions\" within the meaning of section 10.  If the Program as you\nreceived it, or any part of it, contains a notice stating that it is\ngoverned by this License along with a term that is a further\nrestriction, you may remove that term.  If a license document contains\na further restriction but permits relicensing or conveying under this\nLicense, you may add to a covered work material governed by the terms\nof that license document, provided that the further restriction does\nnot survive such relicensing or conveying.\n\n  If you add terms to a covered work in accord with this section, you\nmust place, in the relevant source files, a statement of the\nadditional terms that apply to those files, or a notice indicating\nwhere to find the applicable terms.\n\n  Additional terms, permissive or non-permissive, may be stated in the\nform of a separately written license, or stated as exceptions;\nthe above requirements apply either way.\n\n  8. Termination.\n\n  You may not propagate or modify a covered work except as expressly\nprovided under this License.  Any attempt otherwise to propagate or\nmodify it is void, and will automatically terminate your rights under\nthis License (including any patent licenses granted under the third\nparagraph of section 11).\n\n  However, if you cease all violation of this License, then your\nlicense from a particular copyright holder is reinstated (a)\nprovisionally, unless and until the copyright holder explicitly and\nfinally terminates your license, and (b) permanently, if the copyright\nholder fails to notify you of the violation by some reasonable means\nprior to 60 days after the cessation.\n\n  Moreover, your license from a particular copyright holder is\nreinstated permanently if the copyright holder notifies you of the\nviolation by some reasonable means, this is the first time you have\nreceived notice of violation of this License (for any work) from that\ncopyright holder, and you cure the violation prior to 30 days after\nyour receipt of the notice.\n\n  Termination of your rights under this section does not terminate the\nlicenses of parties who have received copies or rights from you under\nthis License.  If your rights have been terminated and not permanently\nreinstated, you do not qualify to receive new licenses for the same\nmaterial under section 10.\n\n  9. Acceptance Not Required for Having Copies.\n\n  You are not required to accept this License in order to receive or\nrun a copy of the Program.  Ancillary propagation of a covered work\noccurring solely as a consequence of using peer-to-peer transmission\nto receive a copy likewise does not require acceptance.  However,\nnothing other than this License grants you permission to propagate or\nmodify any covered work.  These actions infringe copyright if you do\nnot accept this License.  Therefore, by modifying or propagating a\ncovered work, you indicate your acceptance of this License to do so.\n\n  10. Automatic Licensing of Downstream Recipients.\n\n  Each time you convey a covered work, the recipient automatically\nreceives a license from the original licensors, to run, modify and\npropagate that work, subject to this License.  You are not responsible\nfor enforcing compliance by third parties with this License.\n\n  An \"entity transaction\" is a transaction transferring control of an\norganization, or substantially all assets of one, or subdividing an\norganization, or merging organizations.  If propagation of a covered\nwork results from an entity transaction, each party to that\ntransaction who receives a copy of the work also receives whatever\nlicenses to the work the party's predecessor in interest had or could\ngive under the previous paragraph, plus a right to possession of the\nCorresponding Source of the work from the predecessor in interest, if\nthe predecessor has it or can get it with reasonable efforts.\n\n  You may not impose any further restrictions on the exercise of the\nrights granted or affirmed under this License.  For example, you may\nnot impose a license fee, royalty, or other charge for exercise of\nrights granted under this License, and you may not initiate litigation\n(including a cross-claim or counterclaim in a lawsuit) alleging that\nany patent claim is infringed by making, using, selling, offering for\nsale, or importing the Program or any portion of it.\n\n  11. Patents.\n\n  A \"contributor\" is a copyright holder who authorizes use under this\nLicense of the Program or a work on which the Program is based.  The\nwork thus licensed is called the contributor's \"contributor version\".\n\n  A contributor's \"essential patent claims\" are all patent claims\nowned or controlled by the contributor, whether already acquired or\nhereafter acquired, that would be infringed by some manner, permitted\nby this License, of making, using, or selling its contributor version,\nbut do not include claims that would be infringed only as a\nconsequence of further modification of the contributor version.  For\npurposes of this definition, \"control\" includes the right to grant\npatent sublicenses in a manner consistent with the requirements of\nthis License.\n\n  Each contributor grants you a non-exclusive, worldwide, royalty-free\npatent license under the contributor's essential patent claims, to\nmake, use, sell, offer for sale, import and otherwise run, modify and\npropagate the contents of its contributor version.\n\n  In the following three paragraphs, a \"patent license\" is any express\nagreement or commitment, however denominated, not to enforce a patent\n(such as an express permission to practice a patent or covenant not to\nsue for patent infringement).  To \"grant\" such a patent license to a\nparty means to make such an agreement or commitment not to enforce a\npatent against the party.\n\n  If you convey a covered work, knowingly relying on a patent license,\nand the Corresponding Source of the work is not available for anyone\nto copy, free of charge and under the terms of this License, through a\npublicly available network server or other readily accessible means,\nthen you must either (1) cause the Corresponding Source to be so\navailable, or (2) arrange to deprive yourself of the benefit of the\npatent license for this particular work, or (3) arrange, in a manner\nconsistent with the requirements of this License, to extend the patent\nlicense to downstream recipients.  \"Knowingly relying\" means you have\nactual knowledge that, but for the patent license, your conveying the\ncovered work in a country, or your recipient's use of the covered work\nin a country, would infringe one or more identifiable patents in that\ncountry that you have reason to believe are valid.\n\n  If, pursuant to or in connection with a single transaction or\narrangement, you convey, or propagate by procuring conveyance of, a\ncovered work, and grant a patent license to some of the parties\nreceiving the covered work authorizing them to use, propagate, modify\nor convey a specific copy of the covered work, then the patent license\nyou grant is automatically extended to all recipients of the covered\nwork and works based on it.\n\n  A patent license is \"discriminatory\" if it does not include within\nthe scope of its coverage, prohibits the exercise of, or is\nconditioned on the non-exercise of one or more of the rights that are\nspecifically granted under this License.  You may not convey a covered\nwork if you are a party to an arrangement with a third party that is\nin the business of distributing software, under which you make payment\nto the third party based on the extent of your activity of conveying\nthe work, and under which the third party grants, to any of the\nparties who would receive the covered work from you, a discriminatory\npatent license (a) in connection with copies of the covered work\nconveyed by you (or copies made from those copies), or (b) primarily\nfor and in connection with specific products or compilations that\ncontain the covered work, unless you entered into that arrangement,\nor that patent license was granted, prior to 28 March 2007.\n\n  Nothing in this License shall be construed as excluding or limiting\nany implied license or other defenses to infringement that may\notherwise be available to you under applicable patent law.\n\n  12. No Surrender of Others' Freedom.\n\n  If conditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License.  If you cannot convey a\ncovered work so as to satisfy simultaneously your obligations under this\nLicense and any other pertinent obligations, then as a consequence you may\nnot convey it at all.  For example, if you agree to terms that obligate you\nto collect a royalty for further conveying from those to whom you convey\nthe Program, the only way you could satisfy both those terms and this\nLicense would be to refrain entirely from conveying the Program.\n\n  13. Use with the GNU Affero General Public License.\n\n  Notwithstanding any other provision of this License, you have\npermission to link or combine any covered work with a work licensed\nunder version 3 of the GNU Affero General Public License into a single\ncombined work, and to convey the resulting work.  The terms of this\nLicense will continue to apply to the part which is the covered work,\nbut the special requirements of the GNU Affero General Public License,\nsection 13, concerning interaction through a network will apply to the\ncombination as such.\n\n  14. Revised Versions of this License.\n\n  The Free Software Foundation may publish revised and/or new versions of\nthe GNU General Public License from time to time.  Such new versions will\nbe similar in spirit to the present version, but may differ in detail to\naddress new problems or concerns.\n\n  Each version is given a distinguishing version number.  If the\nProgram specifies that a certain numbered version of the GNU General\nPublic License \"or any later version\" applies to it, you have the\noption of following the terms and conditions either of that numbered\nversion or of any later version published by the Free Software\nFoundation.  If the Program does not specify a version number of the\nGNU General Public License, you may choose any version ever published\nby the Free Software Foundation.\n\n  If the Program specifies that a proxy can decide which future\nversions of the GNU General Public License can be used, that proxy's\npublic statement of acceptance of a version permanently authorizes you\nto choose that version for the Program.\n\n  Later license versions may give you additional or different\npermissions.  However, no additional obligations are imposed on any\nauthor or copyright holder as a result of your choosing to follow a\nlater version.\n\n  15. Disclaimer of Warranty.\n\n  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY\nAPPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT\nHOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY\nOF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,\nTHE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\nPURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM\nIS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF\nALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\n  16. Limitation of Liability.\n\n  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS\nTHE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY\nGENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE\nUSE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF\nDATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD\nPARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),\nEVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF\nSUCH DAMAGES.\n\n  17. Interpretation of Sections 15 and 16.\n\n  If the disclaimer of warranty and limitation of liability provided\nabove cannot be given local legal effect according to their terms,\nreviewing courts shall apply local law that most closely approximates\nan absolute waiver of all civil liability in connection with the\nProgram, unless a warranty or assumption of liability accompanies a\ncopy of the Program in return for a fee.\n\n                     END OF TERMS AND CONDITIONS\n\n            How to Apply These Terms to Your New Programs\n\n  If you develop a new program, and you want it to be of the greatest\npossible use to the public, the best way to achieve this is to make it\nfree software which everyone can redistribute and change under these terms.\n\n  To do so, attach the following notices to the program.  It is safest\nto attach them to the start of each source file to most effectively\nstate the exclusion of warranty; and each file should have at least\nthe \"copyright\" line and a pointer to where the full notice is found.\n\n    {one line to give the program's name and a brief idea of what it does.}\n    Copyright (C) {year}  {name of author}\n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation, either version 3 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nAlso add information on how to contact you by electronic and paper mail.\n\n  If the program does terminal interaction, make it output a short\nnotice like this when it starts in an interactive mode:\n\n    {project}  Copyright (C) {year}  {fullname}\n    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\n    This is free software, and you are welcome to redistribute it\n    under certain conditions; type `show c' for details.\n\nThe hypothetical commands `show w' and `show c' should show the appropriate\nparts of the General Public License.  Of course, your program's commands\nmight be different; for a GUI interface, you would use an \"about box\".\n\n  You should also get your employer (if you work as a programmer) or school,\nif any, to sign a \"copyright disclaimer\" for the program, if necessary.\nFor more information on this, and how to apply and follow the GNU GPL, see\n<http://www.gnu.org/licenses/>.\n\n  The GNU General Public License does not permit incorporating your program\ninto proprietary programs.  If your program is a subroutine library, you\nmay consider it more useful to permit linking proprietary applications with\nthe library.  If this is what you want to do, use the GNU Lesser General\nPublic License instead of this License.  But first, please read\n<http://www.gnu.org/philosophy/why-not-lgpl.html>.\n\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.2763671875,
          "content": "include CHANGELOG LICENSE README.md buku.1 requirements.txt\ninclude tests/test_bukuDb/Bookmarks\nrecursive-include tests *.py\nrecursive-include tests/test_bukuDb *.yaml\nrecursive-include auto-completion *\nrecursive-include bukuserver/templates *\nrecursive-include bukuserver/static *\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.4931640625,
          "content": "PREFIX ?= /usr/local\nBINDIR ?= $(DESTDIR)$(PREFIX)/bin\nMANDIR ?= $(DESTDIR)$(PREFIX)/share/man/man1\nDOCDIR ?= $(DESTDIR)$(PREFIX)/share/doc/buku\n\n.PHONY: all install uninstall\n\nall:\n\ninstall:\n\tinstall -m755 -d $(BINDIR)\n\tinstall -m755 -d $(MANDIR)\n\tinstall -m755 -d $(DOCDIR)\n\tgzip -c buku.1 > buku.1.gz\n\tinstall -m755 buku $(BINDIR)/buku\n\tinstall -m644 buku.1.gz $(MANDIR)\n\tinstall -m644 README.md $(DOCDIR)\n\trm -f buku.1.gz\n\nuninstall:\n\trm -f $(BINDIR)/buku\n\trm -f $(MANDIR)/buku.1.gz\n\trm -rf $(DOCDIR)\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 30.041015625,
          "content": "<h1 align=\"center\">buku</h1>\n\n<p align=\"center\">\n<a href=\"https://github.com/jarun/buku/releases/latest\"><img src=\"https://img.shields.io/github/release/jarun/buku.svg?maxAge=600\" alt=\"Latest release\" /></a>\n<a href=\"https://repology.org/project/buku/versions\"><img src=\"https://repology.org/badge/tiny-repos/buku.svg?header=repos\" alt=\"Availability\"></a>\n<a href=\"https://pypi.org/project/buku/\"><img src=\"https://img.shields.io/pypi/v/buku.svg?maxAge=600\" alt=\"PyPI\" /></a>\n<a href=\"https://circleci.com/gh/jarun/workflows/buku\"><img src=\"https://img.shields.io/circleci/project/github/jarun/buku.svg\" alt=\"Build Status\" /></a>\n<a href=\"https://buku.readthedocs.io/en/latest/?badge=latest\"><img src=\"https://readthedocs.org/projects/buku/badge/?version=latest\" alt=\"Docs Status\" /></a>\n<a href=\"https://en.wikipedia.org/wiki/Privacy-invasive_software\"><img src=\"https://img.shields.io/badge/privacy-âœ“-crimson\" alt=\"Privacy Awareness\" /></a>\n<a href=\"https://github.com/jarun/buku/blob/master/LICENSE\"><img src=\"https://img.shields.io/badge/license-GPLv3-yellowgreen.svg?maxAge=2592000\" alt=\"License\" /></a>\n</p>\n\n<p align=\"center\">\n<a href=\"https://asciinema.org/a/137065\"><img src=\"https://asciinema.org/a/137065.svg\" alt=\"buku in action!\" width=\"734\"/></a>\n</p>\n\n<p align=\"center\"><i>buku in action!</i></p>\n\n### Introduction\n\n`buku` is a powerful bookmark manager and a personal textual mini-web.\n\nFor those who prefer the GUI, `bukuserver` exposes a browsable front-end on a local web host server. See [bukuserver page](https://github.com/jarun/buku/tree/master/bukuserver#readme) for config and screenshots.\n\nWhen I started writing it, I couldn't find a flexible command-line solution with a private, portable, merge-able database along with seamless GUI integration. Hence, `buku`.\n\n`buku` can import bookmarks from browser(s) or fetch the title, tags and description of a URL from the web. Use your favourite editor to add, compose and update bookmarks. Search bookmarks instantly with multiple search options, including regex and a deep scan mode (handy with URLs).\n\nIt can look up broken links on the Wayback Machine. There's an Easter Egg to revisit random bookmarks.\n\nThere's no tracking, hidden history, obsolete records, usage analytics or homing.\n\nTo get started right away, jump to the [Quickstart](#quickstart) section. `buku` has one of the best documentation around. The man page comes with examples. For internal details, please refer to the [operational notes](https://github.com/jarun/buku/wiki/Operational-notes).\n\n`buku` is a library too! There are several related projects, including a browser plug-in.\n\n### Table of Contents\n\n- [Features](#features)\n- [Installation](#installation)\n  - [Dependencies](#dependencies)\n  - [From a package manager](#from-a-package-manager)\n  - [Release packages](#release-packages)\n  - [From source](#from-source)\n  - [Running standalone](#running-standalone)\n- [Shell completion](#shell-completion)\n- [Usage](#usage)\n  - [Command-line options](#command-line-options)\n  - [Colors](#colors)\n- [Quickstart](#quickstart)\n- [Examples](#examples)\n- [Automation](#automation)\n- [Troubleshooting](#troubleshooting)\n  - [Editor integration](#editor-integration)\n- [Collaborators](#collaborators)\n- [Contributions](#contributions)\n- [Related projects](#related-projects)\n- [In the Press](#in-the-press)\n\n### Features\n\n- Store bookmarks with auto-fetched title, tags and description\n- Auto-import from Firefox, Google Chrome, Chromium and MS Edge\n- Open bookmarks and search results in browser\n- Shorten, expand URLs\n- Browse cached page from the Wayback Machine\n- Text editor integration\n- Lightweight, clean interface, custom colors\n- Powerful search options (regex, substring...)\n- Continuous search with on the fly mode switch\n- Portable, merge-able database to sync between systems\n- Import/export bookmarks from/to HTML, XBEL, Markdown, RSS or Orgfile\n- Smart tag management using redirection (>>, >, <<)\n- Multi-threaded full DB refresh\n- Manual encryption support\n- Shell completion scripts, man page with examples\n- Privacy-aware (no unconfirmed user data collection)\n\n### Installation\n\n#### Dependencies\n\n| Feature | Dependency |\n| --- | --- |\n| Lang, SQLite | Python 3.8+ |\n| HTTPS | certifi, urllib3 |\n| Encryption | cryptography |\n| HTML | beautifulsoup4, html5lib |\n\nTo copy URL to clipboard `buku` uses `xsel` (or `xclip`) on Linux, `pbcopy` (default installed) on OS X, `clip` (default installed) on Windows, `termux-clipboard` on Termux (terminal emulation for Android), `wl-copy` on Wayland. If X11 is missing, GNU Screen or tmux copy-paste buffers are recognized.\n\n#### From a package manager\n\nTo install buku with all its dependencies from PyPI, run:\n\n    # pip3 install buku\n\nYou can also install `buku` from your package manager. If the version available is dated try an alternative installation method.\n\n<details><summary>Packaging status (expand)</summary>\n<p>\n<br>\n<a href=\"https://repology.org/project/buku/versions\"><img src=\"https://repology.org/badge/vertical-allrepos/buku.svg\" alt=\"Packaging status\"></a>\n</p>\nUnlisted packagers:\n<p>\n<br>\nâ— <a href=\"https://pypi.org/project/buku/\">PyPI</a> (<code>pip3 install buku</code>)<br>\nâ— Termux (<code>pip3 install buku</code>)<br>\n</p>\n</details>\n\n#### Release packages\n\nAuto-generated packages (with only the cli component) for Arch Linux, CentOS, Debian, Fedora, openSUSE Leap and Ubuntu are available with the [latest stable release](https://github.com/jarun/buku/releases/latest).\n\nNOTE: CentOS may not have the python3-beautifulsoup4 package in the repos. Install it using pip3.\n\n#### From source\n\nIf you have git installed, clone this repository. Otherwise download the [latest stable release](https://github.com/jarun/buku/releases/latest) or [development version](https://github.com/jarun/buku/archive/master.zip) (*risky*).\n\nInstall the dependencies. For example, on Ubuntu:\n\n    $ apt-get install ca-certificates python3-urllib3 python3-cryptography python3-bs4\n\nInstall the cli component to default location (`/usr/local`):\n\n    $ sudo make install\n\nTo remove, run:\n\n    $ sudo make uninstall\n\n`PREFIX` is supported, in case you want to install to a different location.\n\n#### Running standalone\n\n`buku` is a standalone utility. From the containing directory, run:\n\n    $ chmod +x buku\n    $ ./buku\n\n### Shell completion\n\nShell completion scripts for Bash, Fish and Zsh can be found in respective subdirectories of [auto-completion/](https://github.com/jarun/buku/blob/master/auto-completion). Please refer to your shell's manual for installation instructions.\n\n### Usage\n\n#### Command-line options\n\n```\nusage: buku [OPTIONS] [KEYWORD [KEYWORD ...]]\n\nBookmark manager like a text-based mini-web.\n\nPOSITIONAL ARGUMENTS:\n      KEYWORD              search keywords\n\nGENERAL OPTIONS:\n      -a, --add URL [+|-] [tag, ...]\n                           bookmark URL with comma-separated tags\n                           (prepend tags with '+' or '-' to use fetched tags)\n      -u, --update [...]   update fields of an existing bookmark\n                           accepts indices and ranges\n                           refresh title and desc if no edit options\n                           if no arguments:\n                           - update results when used with search\n                           - otherwise refresh all titles and desc\n      -w, --write [editor|index]\n                           edit and add a new bookmark in editor\n                           else, edit bookmark at index in EDITOR\n                           edit last bookmark, if index=-1\n                           if no args, edit new bookmark in EDITOR\n      -d, --delete [...]   remove bookmarks from DB\n                           accepts indices or a single range\n                           if no arguments:\n                           - delete results when used with search\n                           - otherwise delete all bookmarks\n      -h, --help           show this information and exit\n      -v, --version        show the program version and exit\n\nEDIT OPTIONS:\n      --url keyword        bookmark link\n      --tag [+|-] [...]    comma-separated tags\n                           clear bookmark tagset, if no arguments\n                           '+' appends to, '-' removes from tagset\n      --title [...]        bookmark title; if no arguments:\n                           -a: do not set title, -u: clear title\n      -c, --comment [...]  notes or description of the bookmark\n                           clears description, if no arguments\n      --immutable N        disable web-fetch during auto-refresh\n                           N=0: mutable (default), N=1: immutable\n      --swap N M           swap two records at specified indices\n\nSEARCH OPTIONS:\n      -s, --sany [...]     find records with ANY matching keyword\n                           this is the default search option\n      -S, --sall [...]     find records matching ALL the keywords\n                           special keywords -\n                           \"blank\": entries with empty title/tag\n                           \"immutable\": entries with locked title\n      --deep               match substrings ('pen' matches 'opens')\n      --markers            search for keywords in specific fields\n                           based on (optional) prefix markers:\n                           '.' - title, '>' - description, ':' - URL,\n                           '#' - tags (comma-separated, PARTIAL matches)\n                           '#,' - tags (comma-separated, EXACT matches)\n                           '*' - any field (same as no prefix)\n      -r, --sreg expr      run a regex search\n      -t, --stag [tag [,|+] ...] [- tag, ...]\n                           search bookmarks by tags\n                           use ',' to find entries matching ANY tag\n                           use '+' to find entries matching ALL tags\n                           excludes entries with tags after ' - '\n                           list all tags, if no search keywords\n      -x, --exclude [...]  omit records matching specified keywords\n      --random [N]         output random bookmarks out of the selection (default 1)\n      --order fields [...] comma-separated list of fields to order the output by\n                           (prepend with '+'/'-' to choose sort direction)\n\nENCRYPTION OPTIONS:\n      -l, --lock [N]       encrypt DB in N (default 8) # iterations\n      -k, --unlock [N]     decrypt DB in N (default 8) # iterations\n\nPOWER TOYS:\n      --ai                 auto-import bookmarks from web browsers\n                           Firefox, Chrome, Chromium, Vivaldi, Edge\n      -e, --export file    export bookmarks to Firefox format HTML\n                           export XBEL, if file ends with '.xbel'\n                           export Markdown, if file ends with '.md'\n                           format: [title](url) <!-- TAGS -->\n                           export Orgfile, if file ends with '.org'\n                           format: *[[url][title]] :tags:\n                           export rss feed if file ends with '.rss'\n                           export buku DB, if file ends with '.db'\n                           combines with search results, if opted\n      -i, --import file    import bookmarks from file\n                           supports .html .xbel .json .md .org .rss .db\n      -p, --print [...]    show record details by indices, ranges\n                           print all bookmarks, if no arguments\n                           -n shows the last n results (like tail)\n      -f, --format N       limit fields in -p or JSON search output\n                           N=1: URL; N=2: URL, tag; N=3: title;\n                           N=4: URL, title, tag; N=5: title, tag;\n                           N0 (10, 20, 30, 40, 50) omits DB index\n      -j, --json [file]    JSON formatted output for -p and search.\n                           prints to stdout if argument missing.\n                           otherwise writes to given file\n      --colors COLORS      set output colors in five-letter string\n      --nc                 disable color output\n      -n, --count N        show N results per page (default 10)\n      --np                 do not show the subprompt, run and exit\n      -o, --open [...]     browse bookmarks by indices and ranges\n                           open a random bookmark, if no arguments\n      --oa                 browse all search results immediately\n      --replace old new    replace old tag with new tag everywhere\n                           delete old tag, if new tag not specified\n      --url-redirect       when fetching an URL, use the resulting\n                           URL from following *permanent* redirects\n                           (when combined with --export, the old URL\n                           is included as additional metadata)\n      --tag-redirect [tag] when fetching an URL that causes permanent\n                           redirect, add a tag in specified pattern\n                           (using 'http:{}' if not specified)\n      --tag-error [tag]    when fetching an URL that causes an HTTP\n                           error, add a tag in specified pattern\n                           (using 'http:{}' if not specified)\n      --del-error [...]    when fetching an URL causes any (given)\n                           HTTP error, delete/do not add it\n      --export-on [...]    export records affected by the above\n                           options, including removed info\n                           (requires --update and --export; specific\n                           HTTP response filter can be provided)\n      --shorten index|URL  fetch shortened url from tny.im service\n      --expand index|URL   expand a tny.im shortened url\n      --cached index|URL   browse a cached page from Wayback Machine\n      --offline            add a bookmark without connecting to web\n      --suggest            show similar tags when adding bookmarks\n      --tacit              reduce verbosity, skip some confirmations\n      --nostdin            do not wait for input (must be first arg)\n      --threads N          max network connections in full refresh\n                           default N=4, min N=1, max N=10\n      -V                   check latest upstream version available\n      -g, --debug          show debug information and verbose logs\n\nSYMBOLS:\n      >                    url\n      +                    comment\n      #                    tags\n\nPROMPT KEYS:\n    1-N                    browse search result indices and/or ranges\n    R [N]                  print out N random search results\n                           (or random bookmarks if negative or N/A)\n    ^ id1 id2              swap two records at specified indices\n    O [id|range [...]]     open search results/indices in GUI browser\n                           toggle try GUI browser if no arguments\n    a                      open all results in browser\n    s keyword [...]        search for records with ANY keyword\n    S keyword [...]        search for records with ALL keywords\n    d                      match substrings ('pen' matches 'opened')\n    m                      search with markers - search string is split\n                           into keywords by prefix markers, which determine\n                           what field the keywords is searched in:\n                           '.', '>' or ':' - title, description or URL\n                           '#'/'#,' - tags (comma-separated, partial/full match)\n                           '*' - all fields (can be omitted in the 1st keyword)\n                           note: tag marker is not affected by 'd' (deep search)\n    v fields               change sorting order (default is '+index')\n                           multiple comma/space separated fields can be specified\n    r expression           run a regex search\n    t [tag, ...]           search by tags; show taglist, if no args\n    g taglist id|range [...] [>>|>|<<] [record id|range ...]\n                           append, set, remove (all or specific) tags\n                           search by taglist id(s) if records are omitted\n    n                      show next page of search results\n    o id|range [...]       browse bookmarks by indices and/or ranges\n    p id|range [...]       print bookmarks by indices and/or ranges\n    w [editor|id]          edit and add or update a bookmark\n    c id                   copy URL at search result index to clipboard\n    ?                      show this help\n    q, ^D, double Enter    exit buku\n```\n\n#### Colors\n\n`buku` supports custom colors. Visit the wiki page on how to [customize colors](https://github.com/jarun/buku/wiki/Customize-colors) for more details.\n\n### Quickstart\n\n1. Export `VISUAL` or `EDITOR` to point to your favourite editor. Note that `VISUAL` takes precedence over `EDITOR`.\n2. Create a sweeter shortcut with some convenience.\n\n       alias b='buku --suggest'\n3. Auto-import bookmarks from your browser(s). Please quit the relevant browsers beforehand to ensure the databases are not locked.\n\n       b --ai\n4. Manually add a bookmark (for hands-on).\n\n       b -w\n5. List your bookmarks with DB index.\n\n       b -p\n6. For GUI and browser integration (or to sync bookmarks with your favourite bookmark management service) refer to the wiki page on [System integration](https://github.com/jarun/buku/wiki/System-integration).\n7. Quick (bash/zsh) commands to fuzzy search with fzf and open the selection in Firefox:\n\n       firefox $(buku -p -f 10 | fzf)\n       firefox $(buku -p -f 40 | fzf | cut -f1)\n\n   POSIX script to show a preview of the bookmark as well:\n\n   ```sh\n   #!/usr/bin/env sh\n\n   url=$(buku -p -f4 | fzf -m --reverse --preview \"buku -p {1}\" --preview-window=wrap | cut -f2)\n\n   if [ -n \"$url\" ]; then\n       echo \"$url\" | xargs firefox\n   fi\n   ```\n\n### Examples\n\n1. **Edit and add** a bookmark from editor:\n\n       $ buku -w\n       $ buku -w 'gedit -w'\n       $ buku -w 'macvim -f' -a https://ddg.gg search engine, privacy\n    The first command picks editor from the environment variable `EDITOR`. The second command opens gedit in blocking mode. The third command opens macvim with option -f and the URL and tags populated in template.\n2. **Add** a simple bookmark:\n\n       $ buku --nostdin -a https://github.com/\n       2648. GitHub: Letâ€™s build from here Â· GitHub\n       > https://github.com/\n       + GitHub is where over 94 million developers shape the future of software, together. Contribute to the open source community, manage your Git repositories, review code like a pro, track bugs\n        and features, power your CI/CD and DevOps workflows, and secure code before you commit it.\n\n       $ buku --nostdin -a https://github.com/\n       [ERROR] URL [https://github.com/] already exists at index 2648\n\n      `>`: URL, `+`: comment, `#`: tags\n\n      Title, description and tags will be fetched from site. Buku only stores unique URLs and will raise error if the URL already present in the database:\n3. **Add** a bookmark with **tags** `search engine` and `privacy`, **comment** `Search engine with perks`, **fetch page title** from the web:\n\n       $ buku -a https://ddg.gg search engine, privacy -c Search engine with perks\n       336. DuckDuckGo\n       > https://ddg.gg\n       + Alternative search engine with perks\n       # privacy,search engine\n    where, `>`: URL, `+`: comment, `#`: tags\n4. **Add** a bookmark with tags `search engine` & `privacy` and **immutable custom title** `DDG`:\n\n       $ buku -a https://ddg.gg search engine, privacy --title 'DDG' --immutable 1\n       336. DDG (L)\n       > https://ddg.gg\n       # privacy,search engine\n    Note that URL must precede tags.\n5. **Add** a bookmark **without a title** (works for update too):\n\n       $ buku -a https://ddg.gg search engine, privacy --title\n6. **Edit and update** a bookmark from editor:\n\n       $ buku -w 15012014\n    This will open the existing bookmark's details in the editor for modifications. Environment variable `EDITOR` must be set.\n7. **Update** existing bookmark at index 15012014 with new URL, tags and comments, fetch title from the web:\n\n       $ buku -u 15012014 --url http://ddg.gg/ --tag web search, utilities -c Private search engine\n8. **Fetch and update only title** for bookmark at 15012014:\n\n       $ buku -u 15012014\n9. **Update only comment** for bookmark at 15012014:\n\n       $ buku -u 15012014 -c this is a new comment\n    Applies to --url, --title and --tag too.\n10. **Export** bookmarks tagged `tag 1` or `tag 2` to HTML, XBEL, Markdown, Orgfile or a new database:\n\n       $ buku -e bookmarks.html --stag tag 1, tag 2\n       $ buku -e bookmarks.xbel --stag tag 1, tag 2\n       $ buku -e bookmarks.md --stag tag 1, tag 2\n       $ buku -e bookmarks.org --stag tag 1, tag 2\n       $ buku -e bookmarks.db --stag tag 1, tag 2\n    All bookmarks are exported if search is not opted.\n11. **Import** bookmarks from HTML, XBEL, Markdown or Orgfile:\n\n        $ buku -i bookmarks.html\n        $ buku -i bookmarks.xbel\n        $ buku -i bookmarks.md\n        $ buku -i bookmarks.org\n        $ buku -i bookmarks.db\n12. **Delete only comment** for bookmark at 15012014:\n\n        $ buku -u 15012014 -c\n    Applies to --title and --tag too. URL cannot be deleted without deleting the bookmark.\n13. **Update** or refresh **full DB** with page titles from the web:\n\n        $ buku -u\n        $ buku -u --tacit (show only failures and exceptions)\n    This operation can update the title or description fields of non-immutable bookmarks by parsing the fetched page. Fields are updated only if the fetched fields are non-empty. Tags remain untouched.\n14. **Delete** bookmark at index 15012014:\n\n        $ buku -d 15012014\n        Index 15012020 moved to 15012014\n    The last index is moved to the deleted index to keep the DB compact. Add `--tacit` to delete without confirmation.\n15. **Delete all** bookmarks:\n\n        $ buku -d\n16. **Delete** a **range or list** of bookmarks:\n\n        $ buku -d 100-200\n        $ buku -d 100 15 200\n17. **Search** bookmarks for **ANY** of the keywords `kernel` and `debugging` in URL, title or tags:\n\n        $ buku kernel debugging\n        $ buku -s kernel debugging\n18. **Search** bookmarks with **ALL** the keywords `kernel` and `debugging` in URL, title or tags:\n\n        $ buku -S kernel debugging\n19. **Search** bookmarks **tagged** `general kernel concepts`:\n\n        $ buku --stag general kernel concepts\n20. **Search** for bookmarks matching **ANY** of the tags `kernel`, `debugging`, `general kernel concepts`:\n\n        $ buku --stag kernel, debugging, general kernel concepts\n21. **Search** for bookmarks matching **ALL** of the tags `kernel`, `debugging`, `general kernel concepts`:\n\n        $ buku --stag kernel + debugging + general kernel concepts\n22. **Search** for bookmarks matching any of the keywords `hello` or `world`, excluding the keywords `real` and `life`, matching both the tags `kernel` and `debugging`, but **excluding** the tags `general kernel concepts` and `books`:\n\n        $ buku hello world --exclude real life --stag 'kernel + debugging - general kernel concepts, books'\n23. **Search** for bookmarks with different tokens for each field, and print them out sorted by the tags (ascending) and URL (descending)\n\n        $ buku --order +tags,-url --markers --sall 'global substring' '.title substring' ':url substring' :https '> description substring' '#partial,tags:' '#,exact,tags' '*another global substring'\n24. List **all unique tags** alphabetically:\n\n        $ buku --stag\n25. Run a **search and update** the results:\n\n        $ buku -s kernel debugging -u --tag + linux kernel\n26. Run a **search and delete** the results:\n\n        $ buku -s kernel debugging -d\n27. **Encrypt or decrypt** DB with **custom number of iterations** (15) to generate key:\n\n        $ buku -l 15\n        $ buku -k 15\n    The same number of iterations must be specified for one lock & unlock instance. Default is 8, if omitted.\n28. **Show details** of bookmarks at index 15012014 and ranges 20-30, 40-50:\n\n        $ buku -p 20-30 15012014 40-50\n29. Show details of the **last 10 bookmarks**:\n\n        $ buku -p -10\n30. **Show all** bookmarks with real index from database:\n\n        $ buku -p\n        $ buku -p | more\n31. **Replace tag** 'old tag' with 'new tag':\n\n        $ buku --replace 'old tag' 'new tag'\n32. **Delete tag** 'old tag' from DB:\n\n        $ buku --replace 'old tag'\n33. **Append (or delete) tags** 'tag 1', 'tag 2' to (or from) existing tags of bookmark at index 15012014:\n\n        $ buku -u 15012014 --tag + tag 1, tag 2\n        $ buku -u 15012014 --tag - tag 1, tag 2\n34. **Open URL** at index 15012014 in browser:\n\n        $ buku -o 15012014\n35. List bookmarks with **no title or tags** for bookkeeping:\n\n        $ buku -S blank\n36. List bookmarks with **immutable title**:\n\n        $ buku -S immutable\n37. **Shorten URL** www.google.com and the URL at index 20:\n\n        $ buku --shorten www.google.com\n        $ buku --shorten 20\n38. **Append, remove tags at prompt** (taglist index to the left, bookmark index to the right):\n\n        // append tags at taglist indices 4 and 6-9 to existing tags in bookmarks at indices 5 and 2-3\n        buku (? for help) g 4 9-6 >> 5 3-2\n        // set tags at taglist indices 4 and 6-9 as tags in bookmarks at indices 5 and 2-3\n        buku (? for help) g 4 9-6 > 5 3-2\n        // remove all tags from bookmarks at indices 5 and 2-3\n        buku (? for help) g > 5 3-2\n        // remove tags at taglist indices 4 and 6-9 from tags in bookmarks at indices 5 and 2-3\n        buku (? for help) g 4 9-6 << 5 3-2\n39. List bookmarks with **colored output**:\n\n        $ buku --colors oKlxm -p\n40. Add a bookmark after following all permanent redirects, but only if the server doesn't respond with an error (and there's no network failure)\n\n        $ buku --add http://wikipedia.net --url-redirect --del-error\n        2. Wikipedia\n           > https://www.wikipedia.org/\n           + Wikipedia is a free online encyclopedia, created and edited by volunteers around the world and hosted by the Wikimedia Foundation.\n41. Add a bookmark with tag `http redirect` if the server responds with a permanent redirect, or tag shaped like `http 404` on an error response:\n\n        $ buku --add http://wikipedia.net/notfound --tag-redirect 'http redirect' --tag-error 'http {}'\n        [ERROR] [404] Not Found\n        3. Not Found\n           > http://wikipedia.net/notfound\n           # http 404,http redirect\n42. Update all bookmarks matching the search by updating the URL if the server responds with a permanent redirect, deleting the bookmark if the server responds with HTTP error 400, 401, 402, 403, 404 or 500, or adding a tag shaped like `http:{}` in case of any other HTTP error; then export those affected by such changes into an HTML file, marking deleted records as well as old URLs for those replaced by redirect.\n\n        $ buku -S ://wikipedia.net -u --url-redirect --tag-error --del-error 400-404,500 --export-on --export backup.html\n\n43. Print out a single **random** bookmark:\n\n        $ buku --random --print\n\n44. Print out 3 **random** bookmarks **ordered** by netloc (reversed), title and url:\n\n        $ buku --random 3 --order ,-netloc,title,+url --print\n\n45. Print out a single **random** bookmark matching **search** criteria, and **export** into a Markdown file (in DB order):\n\n        $ buku --random -S kernel debugging --export random.md\n\n46. Swap positions of records #4 and #5:\n\n        $ buku --swap 4 5\n\n47. More **help**:\n\n        $ buku -h\n        $ man buku\n\n### Automation\n\nInteractive workflows can be automated using expect. Issue [#368](https://github.com/jarun/buku/issues/368) has a working example on automating auto-import.\n\n### Troubleshooting\n\n#### Editor integration\n\nYou may encounter issues with GUI editors which maintain only one instance by default and return immediately from other instances. Use the appropriate editor option to block the caller when a new document is opened. See issue [#210](https://github.com/jarun/buku/issues/210) for gedit.\n\n### Collaborators\n\n- [Arun Prakash Jana](https://github.com/jarun)\n- [Alexey Gulenko](https://github.com/LeXofLeviafan)\n- [Rachmadani Haryono](https://github.com/rachmadaniHaryono)\n- [Johnathan Jenkins](https://github.com/shaggytwodope)\n- [SZ Lin](https://github.com/szlin)\n\nCopyright Â© 2015-2024 [Arun Prakash Jana](mailto:engineerarun@gmail.com)\n<br>\n<p><a href=\"https://gitter.im/jarun/buku\"><img src=\"https://img.shields.io/gitter/room/jarun/buku.svg?maxAge=2592000\" alt=\"gitter chat\" /></a></p>\n\n### Contributions\n\nMissing a feature? There's a rolling [ToDo List](https://github.com/jarun/buku/issues/484) with identified tasks. Contributions are welcome! Please follow the [PR guidelines](https://github.com/jarun/buku/wiki/PR-guidelines).\n\nSee also our documentation here <a href=\"http://buku.readthedocs.io/en/stable/?badge=stable\"><img src=\"https://img.shields.io/badge/docs-stable-brightgreen.svg?maxAge=2592000\" alt=\"Stable Docs\" /></a>\n\n### Related projects\n\n- [bukubrow](https://github.com/SamHH/bukubrow), WebExtension for browser integration\n- [oil](https://github.com/AndreiUlmeyda/oil), search-as-you-type cli front-end\n- [buku_run](https://github.com/carnager/buku_run), rofi front-end\n- [pinku](https://github.com/mosegontar/pinku), a Pinboard-to-buku import utility\n- [buku-dmenu](https://gitlab.com/benoliver999/buku-dmenu), a simple bash dmenu wrapper\n- [poku](https://github.com/shanedabes/poku), sync between Pocket and buku\n- [Ebuku](https://github.com/flexibeast/ebuku), Emacs interface to buku\n- [diigoku](https://github.com/dppdppd/diigoku), buku importer for Diigo\n- [BukuBot](https://git.xmpp-it.net/sch/BukuBot), Chat bot for XMPP with an extended visual interface\n\n\n### Videos\n\n- [Buku: Take Your Bookmarks Everywhere You Go](https://www.youtube.com/embed/9HzEHrUBQXE)\n- [Buku is a great open-source bookmark manager](https://www.youtube.com/embed/7VxgKMWm-J8)\n\n### In the Press\n\n- [2daygeek](http://www.2daygeek.com/buku-command-line-bookmark-manager-linux/)\n- [Hacker Milk](https://hackermilk.blogspot.com/2020/01/how-to-manage-your-browsers-bookmarks.html)\n- [It's F.O.S.S.](https://itsfoss.com/buku-command-line-bookmark-manager-linux/)\n- [LinOxide](https://linoxide.com/linux-how-to/buku-browser-bookmarks-linux/)\n- [LinuxUser Magazine 01/2017 Issue](http://www.linux-community.de/LU/2017/01/Das-Beste-aus-zwei-Welten)\n- [Make Tech Easier](https://www.maketecheasier.com/manage-browser-bookmarks-ubuntu-command-line/)\n- [One Thing Well](http://onethingwell.org/post/144952807044/buku)\n- [Open Source For You](https://opensourceforu.com/2018/05/buku-a-bookmark-manager-in-the-command-line/)\n- [ulno.net](https://ulno.net/blog/2017-07-19/of-bookmarks-tags-and-browsers/)\n"
        },
        {
          "name": "auto-completion",
          "type": "tree",
          "content": null
        },
        {
          "name": "buku",
          "type": "blob",
          "size": 223.466796875,
          "content": "#!/usr/bin/env python3\n#\n# Bookmark management utility\n#\n# Copyright Â© 2015-2024 Arun Prakash Jana <engineerarun@gmail.com>\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with buku.  If not, see <http://www.gnu.org/licenses/>.\nfrom __future__ import annotations  # for |\n\nimport argparse\nimport calendar\nimport codecs\nimport collections\nimport contextlib\nimport email.message\nimport json\nimport locale\nimport logging\nimport os\nimport platform\nimport random\nimport re\nimport shutil\nimport signal\nimport sqlite3\nimport struct\nimport subprocess\nimport sys\nimport tempfile\nimport textwrap\nimport threading\nimport time\nimport unicodedata\nimport webbrowser\nfrom enum import Enum\nfrom itertools import chain\nfrom functools import total_ordering\nfrom subprocess import DEVNULL, PIPE, Popen\nfrom typing import Any, Dict, List, Optional, Tuple, NamedTuple\nfrom collections.abc import Sequence, Set, Callable\nfrom warnings import warn\nimport xml.etree.ElementTree as ET\nfrom urllib.parse import urlparse  # urllib3.util.parse_url() encodes netloc\n\nimport urllib3\nfrom bs4 import BeautifulSoup\nfrom bs4.dammit import EncodingDetector\nfrom urllib3.util import Retry, make_headers\n\ntry:\n    from mypy_extensions import TypedDict\nexcept ImportError:\n    TypedDict = None  # type: ignore\n\n__version__ = '4.9'\n__author__ = 'Arun Prakash Jana <engineerarun@gmail.com>'\n__license__ = 'GPLv3'\n\n# Global variables\nINTERRUPTED = False  # Received SIGINT\nDELIM = ','  # Delimiter used to store tags in DB\nSKIP_MIMES = {'.pdf', '.txt'}\nPROMPTMSG = 'buku (? for help): '  # Prompt message string\n\nstrip_delim = lambda s, delim=DELIM, sub=' ': str(s).replace(delim, sub)\ntaglist = lambda ss: sorted(set(s.lower().strip() for s in ss if (s or '').strip()))\nlike_escape = lambda s, c='`': s.replace(c, c+c).replace('_', c+'_').replace('%', c+'%')\nsplit_by_marker = lambda s: re.split(r'\\s+(?=[.:>#*])', s)\n\ndef taglist_str(tag_str, convert=None):\n    tags = taglist(tag_str.split(DELIM))\n    return delim_wrap(DELIM.join(tags if not convert else taglist(convert(tags))))\n\ndef filter_from(values, subset, *, exclude=False):\n    subset, exclude = set(subset), bool(exclude)\n    return [x for x in values if (x in subset) != exclude]\n\n\n# Default format specifiers to print records\nID_STR = '%d. %s [%s]\\n'\nID_DB_STR = '%d. %s'\nMUTE_STR = '%s (L)\\n'\nURL_STR = '   > %s\\n'\nDESC_STR = '   + %s\\n'\nDESC_WRAP = '%s%s'\nTAG_STR = '   # %s\\n'\nTAG_WRAP = '%s%s'\n\n# Colormap for color output from \"googler\" project\nCOLORMAP = {k: '\\x1b[%sm' % v for k, v in {\n    'a': '30', 'b': '31', 'c': '32', 'd': '33',\n    'e': '34', 'f': '35', 'g': '36', 'h': '37',\n    'i': '90', 'j': '91', 'k': '92', 'l': '93',\n    'm': '94', 'n': '95', 'o': '96', 'p': '97',\n    'A': '30;1', 'B': '31;1', 'C': '32;1', 'D': '33;1',\n    'E': '34;1', 'F': '35;1', 'G': '36;1', 'H': '37;1',\n    'I': '90;1', 'J': '91;1', 'K': '92;1', 'L': '93;1',\n    'M': '94;1', 'N': '95;1', 'O': '96;1', 'P': '97;1',\n    'x': '0', 'X': '1', 'y': '7', 'Y': '7;1', 'z': '2',\n}.items()}\n\n# DB flagset values\n[FLAG_NONE, FLAG_IMMUTABLE] = [0x00, 0x01]\n\nFIELD_FILTER = {\n    1: ('id', 'url'),\n    2: ('id', 'url', 'tags'),\n    3: ('id', 'title'),\n    4: ('id', 'url', 'title', 'tags'),\n    5: ('id', 'title', 'tags'),\n    10: ('url',),\n    20: ('url', 'tags'),\n    30: ('title',),\n    40: ('url', 'title', 'tags'),\n    50: ('title', 'tags'),\n}\nALL_FIELDS = ('id', 'url', 'title', 'desc', 'tags')\nJSON_FIELDS = {'id': 'index', 'url': 'uri', 'desc': 'description'}\n\nUSER_AGENT = 'Mozilla/5.0 (X11; Linux x86_64; rv:124.0) Gecko/20100101 Firefox/124.0'\nMYHEADERS = None  # Default dictionary of headers\nMYPROXY = None  # Default proxy\nTEXT_BROWSERS = ['elinks', 'links', 'links2', 'lynx', 'w3m', 'www-browser']\nIGNORE_FF_BOOKMARK_FOLDERS = frozenset([\"placesRoot\", \"bookmarksMenuFolder\"])\nPERMANENT_REDIRECTS = {301, 308}\n\n# IntSet: TypeAlias = Set[int] | range      # TODO: use after dropping 3.9\n# Ints: TypeAlias = Sequence[int] | IntSet\n# IntOrInts: TypeAlias = int | Ints\n# T = TypeVar('T')\n# Values: TypeAlias = Sequence[T] | Set[T]\n# del T\n\n# Set up logging\nLOGGER = logging.getLogger()\nLOGDBG = LOGGER.debug\nLOGERR = LOGGER.error\n\n# Define the default path to ca-certificates\n# In Linux distros with openssl, it is /etc/ssl/certs/ca-certificates.crt\n# Fall back to use `certifi` otherwise\nif sys.platform.startswith('linux') and os.path.isfile('/etc/ssl/certs/ca-certificates.crt'):\n    CA_CERTS = '/etc/ssl/certs/ca-certificates.crt'\nelse:\n    import certifi\n    CA_CERTS = certifi.where()\n\n\nclass BukuCrypt:\n    \"\"\"Class to handle encryption and decryption of\n    the database file. Functionally a separate entity.\n\n    Involves late imports in the static functions but it\n    saves ~100ms each time. Given that encrypt/decrypt are\n    not done automatically and any one should be called at\n    a time, this doesn't seem to be an outrageous approach.\n    \"\"\"\n\n    # Crypto constants\n    BLOCKSIZE = 0x10000  # 64 KB blocks\n    SALT_SIZE = 0x20\n    CHUNKSIZE = 0x80000  # Read/write 512 KB chunks\n\n    @staticmethod\n    def get_filehash(filepath):\n        \"\"\"Get the SHA256 hash of a file.\n\n        Parameters\n        ----------\n        filepath : str\n            Path to the file.\n\n        Returns\n        -------\n        hash : bytes\n            Hash digest of file.\n        \"\"\"\n\n        from hashlib import sha256\n\n        with open(filepath, 'rb') as fp:\n            hasher = sha256()\n            buf = fp.read(BukuCrypt.BLOCKSIZE)\n            while len(buf) > 0:\n                hasher.update(buf)\n                buf = fp.read(BukuCrypt.BLOCKSIZE)\n\n            return hasher.digest()\n\n    @staticmethod\n    def encrypt_file(iterations, dbfile=None):\n        \"\"\"Encrypt the bookmarks database file.\n\n        Parameters\n        ----------\n        iterations : int\n            Number of iterations for key generation.\n        dbfile : str, optional\n            Custom database file path (including filename).\n        \"\"\"\n\n        try:\n            from getpass import getpass\n            from hashlib import sha256\n\n            from cryptography.hazmat.backends import default_backend\n            from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\n        except ImportError:\n            LOGERR('cryptography lib(s) missing')\n            sys.exit(1)\n\n        if iterations < 1:\n            LOGERR('Iterations must be >= 1')\n            sys.exit(1)\n\n        if not dbfile:\n            dbfile = os.path.join(BukuDb.get_default_dbdir(), 'bookmarks.db')\n        encfile = dbfile + '.enc'\n\n        db_exists = os.path.exists(dbfile)\n        enc_exists = os.path.exists(encfile)\n\n        if db_exists and not enc_exists:\n            pass\n        elif not db_exists:\n            LOGERR('%s missing. Already encrypted?', dbfile)\n            sys.exit(1)\n        else:\n            # db_exists and enc_exists\n            LOGERR('Both encrypted and flat DB files exist!')\n            sys.exit(1)\n\n        password = getpass()\n        passconfirm = getpass()\n        if not password or not passconfirm:\n            LOGERR('Empty password')\n            sys.exit(1)\n        if password != passconfirm:\n            LOGERR('Passwords do not match')\n            sys.exit(1)\n\n        try:\n            # Get SHA256 hash of DB file\n            dbhash = BukuCrypt.get_filehash(dbfile)\n        except Exception as e:\n            LOGERR(e)\n            sys.exit(1)\n\n        # Generate random 256-bit salt and key\n        salt = os.urandom(BukuCrypt.SALT_SIZE)\n        key = ('%s%s' % (password, salt.decode('utf-8', 'replace'))).encode('utf-8')\n        for _ in range(iterations):\n            key = sha256(key).digest()\n\n        iv = os.urandom(16)\n        encryptor = Cipher(\n            algorithms.AES(key),\n            modes.CBC(iv),\n            backend=default_backend()\n        ).encryptor()\n        filesize = os.path.getsize(dbfile)\n\n        try:\n            with open(dbfile, 'rb') as infp, open(encfile, 'wb') as outfp:\n                outfp.write(struct.pack('<Q', filesize))\n                outfp.write(salt)\n                outfp.write(iv)\n\n                # Embed DB file hash in encrypted file\n                outfp.write(dbhash)\n\n                while True:\n                    chunk = infp.read(BukuCrypt.CHUNKSIZE)\n                    if len(chunk) == 0:\n                        break\n                    if len(chunk) % 16 != 0:\n                        chunk = b'%b%b' % (chunk, b' ' * (16 - len(chunk) % 16))\n\n                    outfp.write(encryptor.update(chunk))\n\n                outfp.write(encryptor.finalize())\n\n            os.remove(dbfile)\n            print('File encrypted')\n            sys.exit(0)\n        except Exception as e:\n            with contextlib.suppress(FileNotFoundError):\n                os.remove(encfile)\n            LOGERR(e)\n            sys.exit(1)\n\n    @staticmethod\n    def decrypt_file(iterations, dbfile=None):\n        \"\"\"Decrypt the bookmarks database file.\n\n        Parameters\n        ----------\n        iterations : int\n            Number of iterations for key generation.\n        dbfile : str, optional\n            Custom database file path (including filename).\n            The '.enc' suffix must be omitted.\n        \"\"\"\n\n        try:\n            from getpass import getpass\n            from hashlib import sha256\n\n            from cryptography.hazmat.backends import default_backend\n            from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\n        except ImportError:\n            LOGERR('cryptography lib(s) missing')\n            sys.exit(1)\n\n        if iterations < 1:\n            LOGERR('Decryption failed')\n            sys.exit(1)\n\n        if not dbfile:\n            dbfile = os.path.join(BukuDb.get_default_dbdir(), 'bookmarks.db')\n        else:\n            dbfile = os.path.abspath(dbfile)\n            dbpath, filename = os.path.split(dbfile)\n\n        encfile = dbfile + '.enc'\n\n        enc_exists = os.path.exists(encfile)\n        db_exists = os.path.exists(dbfile)\n\n        if enc_exists and not db_exists:\n            pass\n        elif not enc_exists:\n            LOGERR('%s missing', encfile)\n            sys.exit(1)\n        else:\n            # db_exists and enc_exists\n            LOGERR('Both encrypted and flat DB files exist!')\n            sys.exit(1)\n\n        password = getpass()\n        if not password:\n            LOGERR('Decryption failed')\n            sys.exit(1)\n\n        try:\n            with open(encfile, 'rb') as infp:\n                size = struct.unpack('<Q', infp.read(struct.calcsize('Q')))[0]\n\n                # Read 256-bit salt and generate key\n                salt = infp.read(32)\n                key = ('%s%s' % (password, salt.decode('utf-8', 'replace'))).encode('utf-8')\n                for _ in range(iterations):\n                    key = sha256(key).digest()\n\n                iv = infp.read(16)\n                decryptor = Cipher(\n                    algorithms.AES(key),\n                    modes.CBC(iv),\n                    backend=default_backend(),\n                ).decryptor()\n\n                # Get original DB file's SHA256 hash from encrypted file\n                enchash = infp.read(32)\n\n                with open(dbfile, 'wb') as outfp:\n                    while True:\n                        chunk = infp.read(BukuCrypt.CHUNKSIZE)\n                        if len(chunk) == 0:\n                            break\n                        outfp.write(decryptor.update(chunk))\n                    outfp.write(decryptor.finalize())\n                    outfp.truncate(size)\n\n            # Match hash of generated file with that of original DB file\n            dbhash = BukuCrypt.get_filehash(dbfile)\n            if dbhash != enchash:\n                os.remove(dbfile)\n                LOGERR('Decryption failed')\n                sys.exit(1)\n            else:\n                os.remove(encfile)\n                print('File decrypted')\n        except struct.error:\n            with contextlib.suppress(FileNotFoundError):\n                os.remove(dbfile)\n            LOGERR('Tainted file')\n            sys.exit(1)\n        except Exception as e:\n            with contextlib.suppress(FileNotFoundError):\n                os.remove(dbfile)\n            LOGERR(e)\n            sys.exit(1)\n\n\n@total_ordering\nclass SortKey:\n    def __init__(self, value, ascending=True):\n        self.value, self.ascending = value, bool(ascending)\n\n    def __eq__(self, other):\n        other = (other.value if isinstance(other, SortKey) else other)\n        return self.value == other\n\n    def __lt__(self, other):\n        other = (other.value if isinstance(other, SortKey) else other)\n        return self.value != other and ((self.value < other) == self.ascending)\n\n    def __repr__(self):\n        return ('+' if self.ascending else '-') + repr(self.value)\n\n\nclass FetchResult(NamedTuple):\n    url: str                            # resulting URL after following PERMANENT redirects\n    title: str = ''\n    desc: str = ''\n    keywords: str = ''\n    mime: bool = False\n    bad: bool = False\n    fetch_status: Optional[int] = None  # None means no fetch occurred (e.g. due to a network error)\n\n    def tag_redirect(self, pattern: str = None) -> str:\n        return ('' if self.fetch_status not in PERMANENT_REDIRECTS else (pattern or 'http:{}').format(self.fetch_status))\n\n    def tag_error(self, pattern: str = None) -> str:\n        return ('' if (self.fetch_status or 0) < 400 else (pattern or 'http:{}').format(self.fetch_status))\n\n    def tags(self, *, keywords: bool = True, redirect: bool | str = False, error: bool | str = False) -> str:\n        _redirect = redirect and self.tag_redirect(None if redirect is True else redirect)\n        _error = error and self.tag_error(None if error is True else error)\n        return DELIM.join(taglist((keywords and self.keywords or '').split(DELIM) + [_redirect, _error]))\n\n\nclass BookmarkVar(NamedTuple):\n    \"\"\"Bookmark data named tuple\"\"\"\n    id: int\n    url: str\n    title: Optional[str] = None\n    tags_raw: str = ''\n    desc: str = ''\n    flags: int = FLAG_NONE\n\n    @property\n    def immutable(self) -> bool:\n        return bool(self.flags & FLAG_IMMUTABLE)\n\n    @property\n    def tags(self) -> str:\n        return self.tags_raw[1:-1]\n\n    @property\n    def taglist(self) -> List[str]:\n        return [x for x in self.tags_raw.split(',') if x]\n\n    @property\n    def netloc(self) -> str:\n        return get_netloc(self.url) or ''\n\nbookmark_vars = lambda xs: ((x if isinstance(x, BookmarkVar) else BookmarkVar(*x)) for x in xs)\n\n\nclass BukuDb:\n    \"\"\"Abstracts all database operations.\n\n    Attributes\n    ----------\n    conn : sqlite database connection.\n    cur : sqlite database cursor.\n    json : string\n        Empty string if results should be printed in JSON format to stdout.\n        Nonempty string if results should be printed in JSON format to file. The string has to be a valid path.\n        None if the results should be printed as human-readable plaintext.\n    field_filter : int\n        Indicates format for displaying bookmarks. Default is 0.\n    chatty : bool\n        Sets the verbosity of the APIs. Default is False.\n    \"\"\"\n\n    def __init__(\n            self, json: Optional[str] = None, field_filter: int = 0, chatty: bool = False,\n            dbfile: Optional[str] = None, colorize: bool = True) -> None:\n        \"\"\"Database initialization API.\n\n        Parameters\n        ----------\n        json : string\n            Empty string if results should be printed in JSON format to stdout.\n            Nonempty string if results should be printed in JSON format to file. The string has to be a valid path.\n            None if the results should be printed as human-readable plaintext.\n        field_filter : int\n            Indicates format for displaying bookmarks. Default is 0.\n        chatty : bool\n            Sets the verbosity of the APIs. Default is False.\n        colorize : bool\n            Indicates whether color should be used in output. Default is True.\n        \"\"\"\n\n        self.json = json\n        self.field_filter = field_filter\n        self.chatty = chatty\n        self.colorize = colorize\n        self.conn, self.cur = BukuDb.initdb(dbfile, self.chatty)\n        self.lock = threading.RLock()  # repeatable lock, only blocks *concurrent* access\n        self._to_export = None  # type: Optional[Dict[str, str | BookmarkVar]]\n        self._to_delete = None  # type: Optional[int | Sequence[int] | Set[int] | range]\n\n    @staticmethod\n    def get_default_dbdir():\n        \"\"\"Determine the directory path where dbfile will be stored.\n\n        If the platform is Windows, use %APPDATA%\n        else if $XDG_DATA_HOME is defined, use it\n        else if $HOME exists, use it\n        else use the current directory.\n\n        Returns\n        -------\n        str\n            Path to database file.\n        \"\"\"\n\n        data_home = os.environ.get('XDG_DATA_HOME')\n        if data_home is None:\n            if os.environ.get('HOME') is None:\n                if sys.platform == 'win32':\n                    data_home = os.environ.get('APPDATA')\n                    if data_home is None:\n                        return os.path.abspath('.')\n                else:\n                    return os.path.abspath('.')\n            else:\n                data_home = os.path.join(os.environ.get('HOME'), '.local', 'share')\n\n        return os.path.join(data_home, 'buku')\n\n    @staticmethod\n    def initdb(dbfile: Optional[str] = None, chatty: bool = False) -> Tuple[sqlite3.Connection, sqlite3.Cursor]:\n        \"\"\"Initialize the database connection.\n\n        Create DB file and/or bookmarks table if they don't exist.\n        Alert on encryption options on first execution.\n\n        Parameters\n        ----------\n        dbfile : str, optional\n            Custom database file path (including filename).\n        chatty : bool\n            If True, shows informative message on DB creation.\n\n        Returns\n        -------\n        tuple\n            (connection, cursor).\n        \"\"\"\n\n        if not dbfile:\n            dbpath = BukuDb.get_default_dbdir()\n            filename = 'bookmarks.db'\n            dbfile = os.path.join(dbpath, filename)\n        else:\n            dbfile = os.path.abspath(dbfile)\n            dbpath, filename = os.path.split(dbfile)\n\n        try:\n            if not os.path.exists(dbpath):\n                os.makedirs(dbpath)\n        except Exception as e:\n            LOGERR(e)\n            os._exit(1)\n\n        db_exists = os.path.exists(dbfile)\n        enc_exists = os.path.exists(dbfile + '.enc')\n\n        if db_exists and not enc_exists:\n            pass\n        elif enc_exists and not db_exists:\n            LOGERR('Unlock database first')\n            sys.exit(1)\n        elif db_exists and enc_exists:\n            LOGERR('Both encrypted and flat DB files exist!')\n            sys.exit(1)\n        elif chatty:\n            # not db_exists and not enc_exists\n            print('DB file is being created at %s.\\nYou should encrypt it.' % dbfile)\n\n        try:\n            # Create a connection\n            conn = sqlite3.connect(dbfile, check_same_thread=False)\n            conn.create_function('REGEXP', 2, regexp)\n            conn.create_function('NETLOC', 1, get_netloc)\n            cur = conn.cursor()\n\n            # Create table if it doesn't exist\n            # flags: designed to be extended in future using bitwise masks\n            # Masks:\n            #     0b00000001: set title immutable\n            cur.execute('CREATE TABLE if not exists bookmarks ('\n                        'id integer PRIMARY KEY, '\n                        'URL text NOT NULL UNIQUE, '\n                        'metadata text default \\'\\', '\n                        'tags text default \\',\\', '\n                        'desc text default \\'\\', '\n                        'flags integer default 0)')\n            conn.commit()\n        except Exception as e:\n            LOGERR('initdb(): %s', e)\n            sys.exit(1)\n\n        return (conn, cur)\n\n    def _fetch(self, query: str, *args, lock: bool = True) -> List[BookmarkVar]:\n        if not lock:\n            self.cur.execute(query, args)\n            return [BookmarkVar(*x) for x in self.cur.fetchall()]\n        with self.lock:\n            return self._fetch(query, *args, lock=False)\n\n    def _fetch_first(self, query: str, *args, lock: bool = True) -> Optional[BookmarkVar]:\n        rows = self._fetch(query + ' LIMIT 1', *args, lock=lock)\n        return rows[0] if rows else None\n\n    def _ordering(self, fields=['+id'], for_db=True) -> List[Tuple[str, bool]]:\n        \"\"\"Converts field list to ordering parameters (for DB query or entity list sorting).\n        Fields are listed in priority order, with '+'/'-' prefix signifying ASC/DESC; assuming ASC if not specified.\n        Other than names from DB, you can pass those from JSON export.\"\"\"\n        names = {'index': 'id', 'uri': 'url', 'description': 'desc', **({'title': 'metadata'} if for_db else {'metadata': 'title'})}\n        valid = list(names) + list(names.values()) + ['tags', 'netloc']\n        _fields = [(re.sub(r'^[+-]', '', s), not s.startswith('-')) for s in (fields or [])]\n        _fields = [(names.get(field, field), direction) for field, direction in _fields if field in valid]\n        return _fields or [('id', True)]\n\n    def _sort(self, records: List[BookmarkVar], fields=['+id'], ignore_case=True) -> List[BookmarkVar]:\n        text_fields = (set() if not ignore_case else {'url', 'desc', 'title', 'tags', 'netloc'})\n        get = lambda x, k: (getattr(x, k) if k not in text_fields else str(getattr(x, k) or '').lower())\n        order = self._ordering(fields, for_db=False)\n        return sorted(bookmark_vars(records), key=lambda x: [SortKey(get(x, k), ascending=asc) for k, asc in order])\n\n    def _order(self, fields=['+id'], ignore_case=True) -> str:\n        \"\"\"Converts field list to SQL 'ORDER BY' parameters. (See also BukuDb._ordering().)\"\"\"\n        text_fields = (set() if not ignore_case else {'url', 'desc', 'metadata', 'tags'})\n        get = lambda field: ('LOWER(NETLOC(url))' if field == 'netloc' else field if field not in text_fields else f'LOWER({field})')\n        return ', '.join(f'{get(field)} {\"ASC\" if direction else \"DESC\"}' for field, direction in self._ordering(fields))\n\n    def get_rec_all(self, *, lock: bool = True, order: List[str] = ['id']):\n        \"\"\"Get all the bookmarks in the database.\n\n        Parameters\n        ----------\n        lock : bool\n            Whether to restrict concurrent access (True by default).\n        order : list of str\n            Order description (fields from JSON export or DB, prepended with '+'/'-' for ASC/DESC).\n\n        Returns\n        -------\n        list\n            A list of tuples representing bookmark records.\n        \"\"\"\n\n        return self._fetch(f'SELECT * FROM bookmarks ORDER BY {self._order(order)}', lock=lock)\n\n    def get_rec_by_id(self, index: int, *, lock: bool = True) -> Optional[BookmarkVar]:\n        \"\"\"Get a bookmark from database by its ID.\n\n        Parameters\n        ----------\n        index : int\n            DB index of bookmark record.\n        lock : bool\n            Whether to restrict concurrent access (True by default).\n\n        Returns\n        -------\n        BookmarkVar or None\n            Bookmark data, or None if index is not found.\n        \"\"\"\n\n        return self._fetch_first('SELECT * FROM bookmarks WHERE id = ?', index, lock=lock)\n\n    def get_rec_all_by_ids(self, indices: Sequence[int] | Set[int] | range, *, lock: bool = True, order: List[str] = ['id']):  # Ints\n        \"\"\"Get all the bookmarks in the database.\n\n        Parameters\n        ----------\n        indices : int[] | int{} | range\n            DB indices of bookmark records.\n        lock : bool\n            Whether to restrict concurrent access (True by default).\n        order : list of str\n            Order description (fields from JSON export or DB, prepended with '+'/'-' for ASC/DESC).\n\n        Returns\n        -------\n        list\n            A list of tuples representing bookmark records.\n        \"\"\"\n\n        _order, placeholder = self._order(order), ', '.join(['?'] * len(indices))\n        return indices and self._fetch(f'SELECT * FROM bookmarks WHERE id IN ({placeholder}) ORDER BY {_order}',\n                                       *list(indices), lock=lock)\n\n    def get_rec_id(self, url: str, *, lock: bool = True):\n        \"\"\"Check if URL already exists in DB.\n\n        Parameters\n        ----------\n        url : str\n            A URL to search for in the DB.\n        lock : bool\n            Whether to restrict concurrent access (True by default).\n\n        Returns\n        -------\n        int\n            DB index, or None if URL not found in DB.\n        \"\"\"\n\n        row = self._fetch_first('SELECT * FROM bookmarks WHERE url = ?', url, lock=lock)\n        return row and row.id\n\n    def get_rec_ids(self, urls: Sequence[str] | Set[str], *, lock: bool = True):  # Values[str]\n        \"\"\"Check if URL already exists in DB.\n\n        Parameters\n        ----------\n        urls : str[] | str{}\n            URLs to search for in the DB.\n        lock : bool\n            Whether to restrict concurrent access (True by default).\n\n        Returns\n        -------\n        list\n            A list of DB indices.\n        \"\"\"\n\n        if not urls:\n            return []\n        if not lock:\n            placeholder = ', '.join(['?'] * len(urls))\n            self.cur.execute(f'SELECT id FROM bookmarks WHERE url IN ({placeholder})', list(urls))\n            return [x[0] for x in self.cur.fetchall()]\n        with self.lock:\n            return self.get_rec_ids(urls, lock=False)\n\n    def get_max_id(self, *, lock: bool = True) -> int:\n        \"\"\"Fetch the ID of the last record.\n\n        Parameters\n        ----------\n        lock : bool\n            Whether to restrict concurrent access (True by default).\n\n        Returns\n        -------\n        int\n            ID of the record if any record exists, else None.\n        \"\"\"\n\n        if not lock:\n            self.cur.execute('SELECT MAX(id) FROM bookmarks')\n            return self.cur.fetchall()[0][0]\n        with self.lock:\n            return self.get_max_id(lock=False)\n\n    def add_rec(\n            self,\n            url: str,\n            title_in: Optional[str] = None,\n            tags_in: Optional[str] = None,\n            desc: Optional[str] = None,\n            immutable: bool = False,\n            delay_commit: bool = False,\n            fetch: bool = True,\n            url_redirect: bool = False,\n            tag_redirect: bool | str = False,\n            tag_error: bool | str = False,\n            del_error: Optional[Set[int] | range] = None,\n            tags_fetch: bool = True,\n            tags_except: Optional[str] = None) -> int:  # Optional[IntSet]\n        \"\"\"Add a new bookmark.\n\n        Parameters\n        ----------\n        url : str\n            URL to bookmark.\n        title_in : str, optional\n            Title to add manually. Default is None.\n        tags_in : str, optional\n            Comma-separated tags to add manually, instead of fetching them. Default is None.\n        tags_except : str, optional\n            These are removed from the resulting tags list. Default is None.\n        tags_fetch : bool\n            True if tags parsed from the fetched page should be included. Default is True.\n        desc : str, optional\n            Description of the bookmark. Default is None.\n        immutable : bool\n            Indicates whether to disable title fetch from web. Default is False.\n        delay_commit : bool\n            True if record should not be committed to the DB,\n            leaving commit responsibility to caller. Default is False.\n        fetch : bool\n            Fetch page from web and parse for data. Required fetch-status params to take effect.\n        url_redirect : bool\n            Bookmark the URL produced after following all PERMANENT redirects.\n        tag_redirect : bool | str\n            Adds a tag by the given pattern if the url resolved to a PERMANENT\n            redirect. (True means the default pattern 'http:{}'.)\n        tag_error : bool | str\n            Adds a tag by the given pattern if the url resolved to a HTTP error.\n            (True means the default pattern 'http:{}'.)\n        del_error : int{} | range, optional\n            Do not add the bookmark if HTTP response status is in the given set or range.\n            Also prevents the bookmark from being added on a network error.\n\n        Returns\n        -------\n        int\n            DB index of new bookmark on success, None on failure.\n        \"\"\"\n\n        # Return error for empty URL\n        if not url:\n            LOGERR('Invalid URL')\n            return None\n\n        # Ensure that the URL does not exist in DB already\n        id = self.get_rec_id(url)\n        if id:\n            LOGERR('URL [%s] already exists at index %d', url, id)\n            return None\n\n        if fetch:\n            # Fetch data\n            result = fetch_data(url)\n            if result.bad:\n                print('Malformed URL\\n')\n            elif result.mime:\n                LOGDBG('HTTP HEAD requested')\n            elif not result.title and title_in is None:\n                print('No title\\n')\n            else:\n                LOGDBG('Title: [%s]', result.title)\n        else:\n            result = FetchResult(url, fetch_status=200)\n            LOGDBG('ptags: [%s]', result.tags(redirect=tag_redirect, error=tag_error))\n\n        url = (result.url if url_redirect else url)\n        title = (title_in if title_in is not None else result.title)\n\n        # Fix up tags, if broken\n        tags_exclude = set(taglist((tags_except or '').split(DELIM)))\n        tags_fetched = result.tags(keywords=tags_fetch, redirect=tag_redirect, error=tag_error)\n        tags = taglist_str((tags_in or '') + DELIM + tags_fetched,\n                           lambda ss: [s for s in ss if s not in tags_exclude])\n        LOGDBG('tags: [%s]', tags)\n\n        # Process description\n        desc = (desc if desc is not None else result.desc) or ''\n\n        try:\n            assert not del_error or result.fetch_status is not None, 'Network error'\n            assert not del_error or result.fetch_status not in del_error, f'HTTP error {result.fetch_status}'\n            flagset = FLAG_NONE\n            if immutable:\n                flagset |= FLAG_IMMUTABLE\n\n            qry = 'INSERT INTO bookmarks(URL, metadata, tags, desc, flags) VALUES (?, ?, ?, ?, ?)'\n            with self.lock:\n                self.cur.execute(qry, (url, title, tags, desc, flagset))\n                if not delay_commit:\n                    self.conn.commit()\n                if self.chatty:\n                    self.print_rec(self.cur.lastrowid)\n                return self.cur.lastrowid\n        except Exception as e:\n            LOGERR('add_rec(): %s', e)\n            return None\n\n    def append_tag_at_index(self, index, tags_in, delay_commit=False):\n        \"\"\"Append tags to bookmark tagset at index.\n\n        Parameters\n        ----------\n        index : int | int[] | int{} | range, optional\n            DB index of the record. 0 or empty indicates all records.\n        tags_in : str\n            Comma-separated tags to add manually.\n        delay_commit : bool\n            True if record should not be committed to the DB,\n            leaving commit responsibility to caller. Default is False.\n\n        Returns\n        -------\n        bool\n            True on success, False on failure.\n        \"\"\"\n\n        if tags_in is None or tags_in == DELIM:\n            return True\n        indices = (None if not index else [index] if isinstance(index, int) else index)\n\n        with self.lock:\n            if not indices:\n                resp = read_in('Append the tags to ALL bookmarks? (y/n): ')\n                if resp != 'y':\n                    return False\n\n                self.cur.execute('SELECT id, tags FROM bookmarks ORDER BY id ASC')\n            else:\n                placeholder = ', '.join(['?'] * len(indices))\n                self.cur.execute(f'SELECT id, tags FROM bookmarks WHERE id IN ({placeholder}) ORDER BY id ASC', tuple(indices))\n\n            resultset = self.cur.fetchall()\n            if resultset:\n                query = 'UPDATE bookmarks SET tags = ? WHERE id = ?'\n                for row in resultset:\n                    tags = row[1] + tags_in[1:]\n                    tags = parse_tags([tags])\n                    self.cur.execute(query, (tags, row[0],))\n                    if self.chatty and not delay_commit:\n                        self.print_rec(row[0])\n            else:\n                return False\n\n            if not delay_commit:\n                self.conn.commit()\n\n        return True\n\n    def delete_tag_at_index(self, index, tags_in, delay_commit=False, chatty=True):\n        \"\"\"Delete tags from bookmark tagset at index.\n\n        Parameters\n        ----------\n        index : int | int[] | int{} | range, optional\n            DB index of bookmark record. 0 or empty indicates all records.\n        tags_in : str\n            Comma-separated tags to delete manually.\n        delay_commit : bool\n            True if record should not be committed to the DB,\n            leaving commit responsibility to caller. Default is False.\n        chatty: bool\n            Skip confirmation when set to False.\n\n        Returns\n        -------\n        bool\n            True on success, False on failure.\n        \"\"\"\n\n        if tags_in is None or tags_in == DELIM:\n            return True\n\n        tags_to_delete = tags_in.strip(DELIM).split(DELIM)\n        indices = (None if not index else [index] if isinstance(index, int) else index)\n\n        if len(indices or []) != 1:\n            if not indices and chatty:\n                resp = read_in('Delete the tag(s) from ALL bookmarks? (y/n): ')\n                if resp != 'y':\n                    return False\n\n            query = \"UPDATE bookmarks SET tags = replace(tags, ?, ?) WHERE tags LIKE ? ESCAPE '`'\"\n            if indices:\n                query += ' AND id IN ({})'.format(', '.join(['?'] * len(indices)))\n\n            count = 0\n            with self.lock:\n                for tag in tags_to_delete:\n                    tag = delim_wrap(tag)\n                    args = (tag, DELIM, '%'+like_escape(tag, '`')+'%') + tuple(indices or [])\n                    self.cur.execute(query, args)\n                    count += self.cur.rowcount\n\n                if count > 0 and not delay_commit:\n                    self.conn.commit()\n                    if self.chatty:\n                        print('%d record(s) updated' % count)\n\n            return True\n\n        # Process a single index\n        # Use SELECT and UPDATE to handle multiple tags at once\n        with self.lock:\n            query = 'SELECT id, tags FROM bookmarks WHERE id = ? LIMIT 1'\n            self.cur.execute(query, list(indices))\n            resultset = self.cur.fetchall()\n            if not resultset:\n                return False\n\n            query = 'UPDATE bookmarks SET tags = ? WHERE id = ?'\n            for row in resultset:\n                tags = row[1]\n\n                for tag in tags_to_delete:\n                    tags = tags.replace(delim_wrap(tag), DELIM)\n\n                self.cur.execute(query, (parse_tags([tags]), row[0],))\n                if self.chatty and not delay_commit:\n                    self.print_rec(row[0])\n\n                if not delay_commit:\n                    self.conn.commit()\n\n        return True\n\n    def update_rec(\n            self,\n            index: Optional[int | Sequence[int] | Set[int] | range],  # Optional[IntOrInts]\n            url: Optional[str] = None,\n            title_in: Optional[str] = None,\n            tags_in: Optional[str] = None,\n            desc: Optional[str] = None,\n            immutable: Optional[bool] = None,\n            threads: int = 4,\n            url_redirect: bool = False,\n            tag_redirect: bool | str = False,\n            tag_error: bool | str = False,\n            del_error: Optional[Set[int] | range] = None,             # Optional[IntSet]\n            export_on: Optional[Set[int] | range] = None) -> bool:    # Optional[IntSet]\n        \"\"\"Update an existing record at (each) index.\n\n        Update all records if index is 0 or empty, and url is not specified.\n        URL is an exception because URLs are unique in DB.\n\n        Parameters\n        ----------\n        index : int | int[] | int{} | range, optional\n            DB index(es) of record(s). 0 or empty value indicates all records.\n        url : str, optional\n            Bookmark address.\n        title_in : str, optional\n            Title to add manually.\n        tags_in : str, optional\n            Comma-separated tags to add manually. Must start and end with comma.\n            Prefix with '+,' to append to current tags.\n            Prefix with '-,' to delete from current tags.\n        desc : str, optional\n            Description of bookmark.\n        immutable : bool, optional\n            Disable title fetch from web if True. Default is None (no change).\n        threads : int\n            Number of threads to use to refresh full DB. Default is 4.\n        url_redirect : bool\n            Update the URL to one produced after following all PERMANENT redirects.\n            (This could fail if the new URL is bookmarked already.)\n        tag_redirect : bool | str\n            Adds a tag by the given pattern if the url resolved to a PERMANENT\n            redirect. (True means the default pattern 'http:{}'.)\n        tag_error : bool | str\n            Adds a tag by the given pattern if the url resolved to a HTTP error.\n            (True means the default pattern 'http:{}'.)\n        del_error : int{} | range, optional\n            Delete the bookmark if HTTP response status is in the given set or range.\n            Does NOT cause deletion of the bookmark on a network error.\n        export_on : int{} | range, optional\n            Limit the export to URLs returning one of given HTTP codes; store old URLs.\n\n        Returns\n        -------\n        bool\n            True on success, False on failure. (Deletion by del_error counts as success.)\n        \"\"\"\n\n        arguments = []  # type: List[Any]\n        query = 'UPDATE bookmarks SET'\n        tag_modified = False\n        ret = True\n        indices = (None if not index else [index] if isinstance(index, int) else index)\n        index = indices and list(indices or [])[0]\n        single = len(indices or []) == 1\n        export_on, self._to_export = (export_on or set()), ({} if export_on else None)\n        tags_in = (tags_in or None if not tags_in or re.match('[+-],', tags_in) else delim_wrap(tags_in))\n\n        if url and not single:\n            LOGERR('All URLs cannot be same')\n            return False\n\n        if tags_in in ('+,', '-,'):\n            LOGERR('Please specify a tag')\n            return False\n\n        if indices and min(indices) > (self.get_max_id() or 0):  # none of the indices exist in DB?\n            return False\n\n        # Update description if passed as an argument\n        if desc is not None:\n            query += ' desc = ?,'\n            arguments += (desc,)\n\n        # Update immutable flag if passed as argument\n        if immutable is not None:\n            if immutable:\n                query += ' flags = flags | ?,'\n                arguments += (FLAG_IMMUTABLE,)\n            else:\n                query += ' flags = flags & ?,'\n                arguments += (~FLAG_IMMUTABLE,)\n\n        # Update title\n        #\n        # 1. If --title has no arguments, delete existing title\n        # 2. If --title has arguments, update existing title\n        # 3. If --title option is omitted at cmdline:\n        #    If URL is passed, update the title from web using the URL\n        # 4. If no other argument (url, tag, comment, immutable) passed,\n        #    update title from web using DB URL (if title is mutable)\n        fetch_title = {url, title_in, tags_in, desc, immutable} == {None}\n        network_test = url_redirect or tag_redirect or tag_error or del_error or export_on or fetch_title\n        if url and title_in is None:\n            network_test = False\n            _url = url or self.get_rec_by_id(index).url\n            result = fetch_data(_url)\n            if result.bad:\n                print('Malformed URL')\n            elif result.mime:\n                LOGDBG('HTTP HEAD requested')\n            elif not result.title:\n                print('No title')\n            else:\n                LOGDBG('Title: [%s]', result.title)\n\n            if result.desc and not desc:\n                query += ' desc = ?,'\n                arguments += (result.desc,)\n\n            if url_redirect and result.url != _url:\n                url = result.url\n\n            if result.fetch_status in export_on:  # storing the old URL\n                self._to_export[url or _url] = _url\n        else:\n            result = FetchResult(url, title_in)\n\n        if result.title is not None:\n            query += ' metadata = ?,'\n            arguments += (result.title,)\n\n        # Update URL if passed as argument\n        if url:\n            query += ' URL = ?,'\n            arguments += (url,)\n\n        if result.fetch_status in (del_error or []):\n            if result.fetch_status in export_on:  # storing the old record\n                self._to_export[url] = self.get_rec_by_id(index)\n            LOGERR('HTTP error %s', result.fetch_status)\n            return self.delete_rec(index)\n\n        if not indices and (arguments or tags_in):\n            resp = read_in('Update ALL bookmarks? (y/n): ')\n            if resp != 'y':\n                return False\n\n        if network_test:  # doing this before updates to backup records to-be-deleted in their original state\n            custom_tags = (tags_in if (tags_in or '').startswith(DELIM) else None)\n            ret = ret and self.refreshdb(indices, threads, url_redirect=url_redirect, tag_redirect=tag_redirect,\n                                         tag_error=tag_error, del_error=del_error, export_on=export_on,\n                                         update_title=fetch_title, custom_url=url, custom_tags=custom_tags, delay_delete=True)\n\n        # Update tags if passed as argument\n        _tags = result.tags(keywords=False, redirect=tag_redirect, error=tag_error)\n        if tags_in or _tags:\n            if not tags_in or tags_in.startswith('+,'):\n                tags = taglist_str((tags_in or '')[1:] + _tags)\n                chatty = self.chatty\n                self.chatty = False\n                ret = self.append_tag_at_index(indices, tags)\n                self.chatty = chatty\n                tag_modified = True\n            elif tags_in.startswith('-,'):\n                chatty = self.chatty\n                self.chatty = False\n                ret = self.delete_tag_at_index(indices, tags_in[1:])\n                if _tags:\n                    self.append_tag_at_index(indices, _tags)\n                self.chatty = chatty\n                tag_modified = True\n            elif not network_test:  # rely on custom_tags to avoid overwriting fetch-status tags\n                query += ' tags = ?,'\n                arguments += (taglist_str(tags_in + _tags),)\n\n        if not arguments:  # no arguments => nothing to update\n            if (tag_modified or network_test) and self.chatty:\n                self.print_rec(indices)\n            self.commit_delete()\n            return ret\n\n        query = query[:-1]\n        if indices:  # Only specified indices\n            query += ' WHERE id IN ({})'.format(', '.join(['?'] * len(indices)))\n            arguments += tuple(indices)\n\n        LOGDBG('update_rec query: \"%s\", args: %s', query, arguments)\n\n        with self.lock:\n            try:\n                self.cur.execute(query, arguments)\n                self.conn.commit()\n                if self.cur.rowcount > 0 and self.chatty:\n                    self.print_rec(index)\n                elif self.cur.rowcount == 0:\n                    if single:\n                        LOGERR('No matching index %d', index)\n                    else:\n                        LOGERR('No matches found')\n                    return False\n            except sqlite3.IntegrityError:\n                LOGERR('URL already exists')\n                return False\n            except sqlite3.OperationalError as e:\n                LOGERR(e)\n                return False\n            finally:\n                self.commit_delete()\n\n        return True\n\n    def refreshdb(\n            self,\n            index: Optional[int | Sequence[int] | Set[int] | range],  # Optional[IntOrInts]\n            threads: int,\n            url_redirect: bool = False,\n            tag_redirect: bool | str = False,\n            tag_error: bool | str = False,\n            del_error: Optional[Set[int] | range] = None,             # Optional[IntSet]\n            export_on: Optional[Set[int] | range] = None,             # Optional[IntSet]\n            update_title: bool = True,\n            custom_url: Optional[str] = None,\n            custom_tags: Optional[str] = None,\n            delay_delete: bool = False) -> bool:\n        \"\"\"Refresh ALL (or specified) records in the database.\n\n        Fetch title for each bookmark from the web and update the records.\n        Doesn't update the title if fetched title is empty.\n\n        Notes\n        -----\n            This API doesn't change DB index, URL or tags of a bookmark.\n            (Unless one or more fetch-status parameters are supplied.)\n            This API is verbose.\n\n        Parameters\n        ----------\n        index : int | int[] | int{} | range, optional\n            DB index(es) of record(s) to update. 0 or empty value indicates all records.\n        threads: int\n            Number of threads to use to refresh full DB. Default is 4.\n        url_redirect : bool\n            Update the URL to one produced after following all PERMANENT redirects.\n            (This could fail if the new URL is bookmarked already.)\n        tag_redirect : bool | str\n            Adds a tag by the given pattern if the url resolved to a PERMANENT\n            redirect. (True means the default pattern 'http:{}'.)\n        tag_error : bool | str\n            Adds a tag by the given pattern if the url resolved to a HTTP error.\n            (True means the default pattern 'http:{}'.)\n        del_error : int{} | range, optional\n            Delete the bookmark if HTTP response status is in the given set or range.\n        export_on : int{} | range, optional\n            Limit the export to URLs returning one of given HTTP codes; store old URLs.\n        update_title : bool\n            Update titles/descriptions. (Can be turned off for network testing.)\n        custom_url : str, optional\n            Override URL to fetch. (Use for network testing of a single record before updating it.)\n        custom_tags : str, optional\n            Overwrite all tags. (Use to combine network testing with tags overwriting.)\n        delay_delete : bool\n            Delay scheduled deletions by del_error. (Use for network testing during update.)\n\n        Returns\n        -------\n        bool\n            True on success, False on failure. (Deletion by del_error counts as success.)\n        \"\"\"\n\n        indices = (None if not index else [index] if isinstance(index, int) else index)\n        index = indices and list(indices)[0]\n        export_on, self._to_export = (export_on or set()), ({} if export_on else None)\n        self._to_delete = []\n\n        if not update_title and not (url_redirect or tag_redirect or tag_error or del_error or export_on):\n            LOGERR('Noop update request')\n            return False\n        if custom_url and len(indices or []) != 1:\n            LOGERR('custom_url is only supported for a singular index')\n            return False\n\n        with self.lock:\n            if not indices:\n                self.cur.execute('SELECT id, url, tags, flags FROM bookmarks ORDER BY id ASC')\n            else:\n                placeholder = ', '.join(['?'] * len(indices))\n                self.cur.execute(f'SELECT id, url, tags, flags FROM bookmarks WHERE id IN ({placeholder}) ORDER BY id ASC',\n                                 tuple(indices))\n\n            resultset = self.cur.fetchall()\n            recs = len(resultset)\n            if not recs:\n                LOGERR('No matching index or title immutable or empty DB')\n                return False\n\n        # Set up strings to be printed\n        if self.colorize:\n            bad_url_str = '\\x1b[1mIndex %d: Malformed URL\\x1b[0m\\n'\n            mime_str = '\\x1b[1mIndex %d: HTTP HEAD requested\\x1b[0m\\n'\n            blank_url_str = '\\x1b[1mIndex %d: No title\\x1b[0m\\n'\n            success_str = 'Title: [%s]\\n\\x1b[92mIndex %d: updated\\x1b[0m\\n'\n        else:\n            bad_url_str = 'Index %d: Malformed URL\\n'\n            mime_str = 'Index %d: HTTP HEAD requested\\n'\n            blank_url_str = 'Index %d: No title\\n'\n            success_str = 'Title: [%s]\\nIndex %d: updated\\n'\n\n        done = {'value': 0}  # count threads completed\n        processed = {'value': 0}  # count number of records processed\n\n        # An additional call to generate default headers\n        # gen_headers() is called within fetch_data()\n        # However, this initial call to setup headers\n        # ensures there is no race condition among the\n        # initial threads to setup headers\n        if not MYHEADERS:\n            gen_headers()\n\n        def refresh(thread_idx, cond):\n            \"\"\"Inner function to fetch titles and update records.\n\n            Parameters\n            ----------\n            thread_idx : int\n                Thread index/ID.\n            cond : threading condition object.\n            \"\"\"\n\n            _count = 0\n\n            while True:\n                query = 'UPDATE bookmarks SET'\n                arguments = []\n\n                with cond:\n                    if resultset:\n                        id, url, tags, flags = resultset.pop()\n                    else:\n                        break\n\n                result = fetch_data(custom_url or url, http_head=(flags & FLAG_IMMUTABLE) > 0)\n                _count += 1\n\n                with cond:\n                    if result.bad:\n                        print(bad_url_str % id)\n                        if custom_tags:\n                            self.cur.execute('UPDATE bookmarks SET tags = ? WHERE id = ?', (custom_tags, id))\n                        continue\n\n                    if result.fetch_status in (del_error or []):\n                        if result.fetch_status in export_on:\n                            self._to_export[url] = self.get_rec_by_id(id, lock=False)\n                        LOGERR('HTTP error %s', result.fetch_status)\n                        self._to_delete += [id]\n                        if result.mime and self.chatty:\n                            print(mime_str % id)\n                        if custom_tags:\n                            self.cur.execute('UPDATE bookmarks SET tags = ? WHERE id = ?', (custom_tags, id))\n                        continue\n\n                    if result.mime:\n                        if self.chatty:\n                            print(mime_str % id)\n                        if custom_tags:\n                            self.cur.execute('UPDATE bookmarks SET tags = ? WHERE id = ?', (custom_tags, id))\n                        continue\n\n                    if not result.title:\n                        LOGERR(blank_url_str, id)\n                    elif update_title:\n                        query += ' metadata = ?,'\n                        arguments += (result.title,)\n\n                    if update_title and result.desc:\n                        query += ' desc = ?,'\n                        arguments += (result.desc,)\n\n                    _url = url\n                    if url_redirect and result.url != url:\n                        query += ' url = ?,'\n                        arguments += (result.url,)\n                        _url = result.url\n\n                    if result.fetch_status in export_on:\n                        self._to_export[_url] = url\n\n                    _tags = result.tags(keywords=False, redirect=tag_redirect, error=tag_error)\n                    if _tags:\n                        query += ' tags = ?,'\n                        arguments += (taglist_str((custom_tags or tags) + DELIM + _tags),)\n                    elif custom_tags:\n                        query += ' tags = ?,'\n                        arguments += (taglist_str(custom_tags),)\n\n                    if not arguments:  # nothing to update\n                        continue\n\n                    query = query[:-1] + ' WHERE id = ?'\n                    arguments += (id,)\n                    LOGDBG('refreshdb query: \"%s\", args: %s', query, arguments)\n\n                    self.cur.execute(query, arguments)\n\n                    # Save after fetching 32 titles per thread\n                    if _count % 32 == 0:\n                        self.conn.commit()\n\n                    if self.chatty:\n                        print(success_str % (result.title, id))\n\n                if INTERRUPTED:\n                    break\n\n            LOGDBG('Thread %d: processed %d', threading.get_ident(), _count)\n            with cond:\n                done['value'] += 1\n                processed['value'] += _count\n                cond.notify()\n\n        with self.lock:  # preventing external concurrent access\n            cond = threading.Condition()\n            with cond:  # preventing concurrent access between workers\n                threads = min(threads, recs)\n\n                for i in range(threads):\n                    thread = threading.Thread(target=refresh, args=(i, cond))\n                    thread.start()\n\n                while done['value'] < threads:\n                    cond.wait()\n                    LOGDBG('%d threads completed', done['value'])\n\n                # Guard: records found == total records processed\n                if recs != processed['value']:\n                    LOGERR('Records: %d, processed: %d !!!', recs, processed['value'])\n\n            if delay_delete:\n                self.conn.commit()\n            else:\n                self.commit_delete()\n\n        return True\n\n    def commit_delete(self, apply: bool = True):\n        \"\"\"Commit delayed delete commands.\"\"\"\n        if apply and self._to_delete is not None:\n            with self.lock:\n                for id in sorted(set(self._to_delete), reverse=True):\n                    self.delete_rec(id, delay_commit=True, chatty=False)\n                self.conn.commit()\n        self._to_delete = None\n\n    def edit_update_rec(self, index, immutable=None):\n        \"\"\"Edit in editor and update a record.\n\n        Parameters\n        ----------\n        index : int\n            DB index of the record.\n            Last record, if index is -1.\n        immutable : bool, optional\n            Disable title fetch from web if True. Default is None (no change).\n\n        Returns\n        -------\n        bool\n            True if updated, else False.\n        \"\"\"\n\n        editor = get_system_editor()\n        if editor == 'none':\n            LOGERR('EDITOR must be set to use index with -w')\n            return False\n\n        if index == -1:\n            # Edit the last records\n            index = self.get_max_id()\n            if not index:\n                LOGERR('Empty database')\n                return False\n\n        rec = self.get_rec_by_id(index)\n        if not rec:\n            LOGERR('No matching index %d', index)\n            return False\n\n        # If reading from DB, show empty title and desc as empty lines. We have to convert because\n        # even in case of add with a blank title or desc, '' is used as initializer to show '-'.\n        result = edit_rec(editor, rec.url, rec.title or None, rec.tags_raw, rec.desc or None)\n        if result is not None:\n            url, title, tags, desc = result\n            return self.update_rec(index, url, title, tags, desc, immutable)\n\n        if immutable is not None:\n            return self.update_rec(index, immutable=immutable)\n\n        return False\n\n    def list_using_id(self, ids=[], order=['+id']):\n        \"\"\"List entries in the DB using the specified id list.\n\n        Parameters\n        ----------\n        ids : list of ids/ranges in string form\n        order : list of strings\n          Order description (fields from JSON export or DB, prepended with '+'/'-' for ASC/DESC).\n\n        Returns\n        -------\n        list\n        \"\"\"\n        q0 = 'SELECT * FROM bookmarks'\n        if ids:\n            q0 += ' WHERE id in ('\n            for idx in ids:\n                if '-' not in idx:\n                    q0 += idx + ','\n                else:\n                    val = idx.split('-')\n                    if val[0]:\n                        _range = list(map(int, val))\n                        _range[1] += 1\n                        part_ids = range(*_range)\n                    else:\n                        end = int(val[1])\n                        qtemp = 'SELECT id FROM bookmarks ORDER BY id DESC LIMIT {0}'.format(end)\n                        with self.lock:\n                            self.cur.execute(qtemp, [])\n                            part_ids = chain.from_iterable(self.cur.fetchall())\n                    q0 += ','.join(map(str, part_ids))\n            q0 = q0.strip(',')\n            q0 += ')'\n\n        try:\n            return self._fetch(q0 + f' ORDER BY {self._order(order)}')\n        except sqlite3.OperationalError as e:\n            LOGERR(e)\n            return []\n\n    def _search_tokens(self, keyword: str, deep=False, regex=False, markers=False):\n        \"\"\"Converts a keyword into a list of tokens, based on search parameters.\n        A token is a varied-length tuple of following values: (SQL field, deep, *SQL params).\"\"\"\n        deep = not regex and deep\n        if not markers or (re.sub(r'^\\*', '', keyword) and not re.match(r'^[.:>#]', keyword)):\n            s = (keyword if not markers else re.sub(r'^\\*', '', keyword))\n            if not s:\n                return []\n            tags = ([s] if regex and not markers else taglist(s.split(DELIM)))\n            return [('metadata', deep, s), ('url', deep, s), ('desc', deep, s)] + (tags and [('tags', deep, *tags)])\n        if re.match(r'^\\..', keyword):  # checking prefix + ensuring keyword[1:] is not empty\n            return [('metadata', deep, keyword[1:])]\n        if re.match(r'^:.', keyword):\n            return [('url', deep, keyword[1:])]\n        if re.match(r'^>.', keyword):\n            return [('desc', deep, keyword[1:])]\n        if re.match(r'^#,?[^,]', keyword):\n            tags = ([re.sub(r'^#,?', '', keyword)] if regex else taglist(keyword[1:].split(DELIM)))\n            return tags and [('tags', not keyword.startswith('#,'), *tags)]\n        return []\n\n    def _search_clause(self, tokens, regex=False) -> Tuple[str, List[str]]:\n        \"\"\"Converts a list of tokens into an SQL clause. (See also: BukuDb._search_tokens().)\n        If regex is True, the token is treated as a raw regex and the paired deep parameter is ignored.\"\"\"\n        border = lambda k, c: (',' if k == 'tags' else r'\\b' if c.isalnum() else '')\n\n        args, clauses = [], []\n        if regex:\n            for field, deep, param in tokens:\n                clauses += [field + ' REGEXP ?']\n                args += [param]\n        else:\n            for field, deep, *params in tokens:\n                _clauses = []\n                for param in params:\n                    if deep:\n                        _clauses += [field + \" LIKE ('%' || ? || '%')\"]\n                    else:\n                        _clauses += [field + ' REGEXP ?']\n                        param = border(field, param[0]) + re.escape(param) + border(field, param[-1])\n                    args += [param]\n                clauses += (_clauses if len(_clauses) < 2 else [f'({\" AND \".join(_clauses)})'])\n        return ' OR '.join(clauses), args\n\n    def searchdb(\n            self,\n            keywords: List[str],\n            all_keywords: bool = False,\n            deep: bool = False,\n            regex: bool = False,\n            markers: bool = False,\n            order: List[str] = ['+id'],\n    ) -> List[BookmarkVar]:\n        \"\"\"Search DB for entries where tags, URL, or title fields match keywords.\n\n        Parameters\n        ----------\n        keywords : list of str\n            Keywords to search.\n        order : list of str\n            Order description (fields from JSON export or DB, prepended with '+'/'-' for ASC/DESC).\n            Note: this applies to fields with the same number of matched keywords.\n        all_keywords : bool\n            False (default value) to return records matching ANY keyword.\n            True to return records matching ALL keywords. This also enables special\n            behaviour when keywords in (['blank'], ['immutable']).\n        deep : bool\n            True to search for matching substrings. Default is False.\n        markers : bool\n            True to use prefix markers for different fields. Default is False.\n        regex : bool\n            Match a regular expression if True. Default is False.\n            Overrides deep, all_keywords, and comma matching in tags with markers.\n\n        Returns\n        -------\n        list\n            List of search results.\n        \"\"\"\n        _order = self._order(order)\n        clauses, qargs = [], []\n        for keyword in keywords:\n            tokens = self._search_tokens(keyword, deep=deep, markers=markers)\n            clause, args = self._search_clause(tokens, regex=regex)\n            if clause and args:\n                clauses += [f'({clause})']\n                qargs += args\n        if not qargs:\n            return []\n\n        _count = lambda x: f'CASE WHEN {x} THEN 1 ELSE 0 END'\n        if regex:\n            query = ('SELECT id, url, metadata, tags, desc, flags\\nFROM (SELECT *, (' +\n                     '\\n    + '.join(map(_count, clauses)) +\n                     f') AS score\\n  FROM bookmarks WHERE score > 0 ORDER BY score DESC, {_order})')\n        elif all_keywords:\n            if keywords == ['blank']:\n                qargs, query = [DELIM], \"SELECT * FROM bookmarks WHERE metadata = '' OR tags = ?\"\n            elif keywords == ['immutable']:\n                qargs, query = [], 'SELECT * FROM bookmarks WHERE flags & 1 == 1'\n            else:\n                query = 'SELECT id, url, metadata, tags, desc, flags FROM bookmarks WHERE ' + '\\n  AND '.join(clauses)\n            query += f'\\nORDER BY {_order}'\n        elif not all_keywords:\n            query = ('SELECT id, url, metadata, tags, desc, flags\\nFROM (SELECT *, (' +\n                     '\\n    + '.join(map(_count, clauses)) +\n                     f') AS score\\n  FROM bookmarks WHERE score > 0 ORDER BY score DESC, {_order})')\n        else:\n            LOGERR('Invalid search option')\n            return []\n\n        LOGDBG('query: \"%s\", args: %s', query, qargs)\n\n        try:\n            return self._fetch(query, *qargs)\n        except sqlite3.OperationalError as e:\n            LOGERR(e)\n            return []\n\n    def search_by_tag(self, tags: Optional[str], order: List[str] = ['+id']) -> List[BookmarkVar]:\n        \"\"\"Search bookmarks for entries with given tags.\n\n        Parameters\n        ----------\n        tags : str\n            String of tags to search for.\n            Retrieves entries matching ANY tag if tags are\n            delimited with ','.\n            Retrieves entries matching ALL tags if tags are\n            delimited with '+'.\n        order : list of str\n            Order description (fields from JSON export or DB, prepended with '+'/'-' for ASC/DESC).\n            Note: this applies to fields with the same number of matched tags.\n\n        Returns\n        -------\n        list\n            List of search results.\n        \"\"\"\n\n        _order = self._order(order)\n        LOGDBG(tags)\n        if tags is None or tags == DELIM or tags == '':\n            return []\n\n        qargs, search_operator, excluded_tags = prep_tag_search(tags)\n        if search_operator is None:\n            LOGERR(\"Cannot use both '+' and ',' in same search\")\n            return []\n\n        LOGDBG('tags: %s', qargs)\n        LOGDBG('search_operator: %s', search_operator)\n        LOGDBG('excluded_tags: %s', excluded_tags)\n\n        if search_operator == 'AND':\n            query = ('SELECT id, url, metadata, tags, desc, flags FROM bookmarks WHERE (' +\n                     f' {search_operator} '.join(\"tags LIKE '%' || ? || '%'\" for tag in qargs) +\n                     ')' + ('' if not excluded_tags else ' AND tags NOT REGEXP ?') +\n                     f' ORDER BY {_order}')\n        else:\n            query = ('SELECT id, url, metadata, tags, desc, flags FROM (SELECT *, ' +\n                     ' + '.join(\"CASE WHEN tags LIKE '%' || ? || '%' THEN 1 ELSE 0 END\" for tag in qargs) +\n                     ' AS score FROM bookmarks WHERE score > 0' +\n                     ('' if not excluded_tags else ' AND tags NOT REGEXP ?') +\n                     f' ORDER BY score DESC, {_order})')\n        if excluded_tags:\n            qargs += [excluded_tags]\n\n        LOGDBG('query: \"%s\", args: %s', query, qargs)\n        return self._fetch(query, *qargs)\n\n    def search_keywords_and_filter_by_tags(\n            self,\n            keywords: List[str],\n            all_keywords: bool = False,\n            deep: bool = False,\n            regex: bool = False,\n            stag: Optional[List[str]] = None,\n            without: Optional[List[str]] = None,\n            markers: bool = False,\n            order: List[str] = ['+id']) -> List[BookmarkVar]:\n        \"\"\"Search bookmarks for entries with keywords and specified\n        criteria while filtering out entries with matching tags.\n\n        Parameters\n        ----------\n        keywords : list of str\n            Keywords to search.\n        without : list of str\n            Keywords to exclude; ignored if empty. Default is None.\n        all_keywords : bool\n            True to return records matching ALL keywords.\n            False to return records matching ANY keyword. (This is the default.)\n        deep : bool\n            True to search for matching substrings. Default is False\n        markers: bool\n            True to use prefix markers for different fields. Default is False.\n        regex : bool\n            Match a regular expression if True. Default is False.\n        stag : list of str\n            Strings of tags to search for. Default is None.\n            Retrieves entries matching ANY tag if tags are\n            delimited with ','.\n            Retrieves entries matching ALL tags if tags are\n            delimited with '+'.\n\n        Returns\n        -------\n        list\n            List of search results.\n        \"\"\"\n\n        results = self.searchdb(keywords, all_keywords=all_keywords, deep=deep, regex=regex, markers=markers, order=order)\n        results = (results if not stag else filter_from(results, self.search_by_tag(''.join(stag))))\n        return self.exclude_results_from_search(results, without, deep=deep, markers=markers)\n\n    def exclude_results_from_search(self, search_results, without, deep=False, markers=False):\n        \"\"\"Excludes records that match keyword search using without parameters\n\n        Parameters\n        ----------\n        search_results : list\n            List of search results.\n        without : list of str\n            Keywords to exclude. If empty, returning search_results unchanged.\n        deep : bool\n            True to search for matching substrings. Default is False.\n        markers: bool\n            True to use prefix markers for different fields. Default is False.\n\n        Returns\n        -------\n        list\n            List of search results.\n        \"\"\"\n\n        if not without:\n            return search_results\n        return filter_from(search_results, self.searchdb(without, deep=deep, markers=markers), exclude=True)\n\n    def swap_recs(self, index1: int, index2: int, *, lock: bool = True, delay_commit: bool = False):\n        \"\"\"Swaps two records with given indices\n\n        Parameters\n        ----------\n        index1 : int\n            Index of the 1st record to be exchanged.\n        index2 : int\n            Index of the 2nd record to be exchanged.\n        lock : bool\n            Whether to restrict concurrent access (True by default).\n        delay_commit : bool\n            True if record should not be committed to the DB,\n            leaving commit responsibility to caller. Default is False.\n\n        Returns\n        -------\n        bool\n            True on success, False on failure.\n        \"\"\"\n        if lock:\n            with self.lock:\n                return self.swap_recs(index1, index2, lock=False, delay_commit=delay_commit)\n\n        max_id = self.get_max_id()\n        if not max_id or index1 == index2 or not all(0 < x <= max_id for x in [index1, index2]):\n            return False\n\n        self.cur.executemany('UPDATE bookmarks SET id = ? WHERE id = ?',\n                             [(max_id+1, index1), (index1, index2), (index2, max_id+1)])\n        if not delay_commit:\n            self.conn.commit()\n        return True\n\n    def compactdb(self, index: int, delay_commit: bool = False):\n        \"\"\"When an entry at index is deleted, move the\n        last entry in DB to index, if index is lesser.\n\n        Parameters\n        ----------\n        index : int\n            DB index of deleted entry.\n        delay_commit : bool\n            True if record should not be committed to the DB,\n            leaving commit responsibility to caller. Default is False.\n        \"\"\"\n\n        # Return if the last index left in DB was just deleted\n        max_id = self.get_max_id()\n        if not max_id:\n            return\n\n        query1 = 'SELECT id, URL, metadata, tags, desc, flags FROM bookmarks WHERE id = ? LIMIT 1'\n        query2 = 'DELETE FROM bookmarks WHERE id = ?'\n        query3 = 'INSERT INTO bookmarks(id, URL, metadata, tags, desc, flags) VALUES (?, ?, ?, ?, ?, ?)'\n\n        # NOOP if the just deleted index was the last one\n        if max_id > index:\n            results = self._fetch(query1, max_id)\n            for row in results:\n                with self.lock:\n                    self.cur.execute(query2, (row.id,))\n                    self.cur.execute(query3, (index, row.url, row.title, row.tags_raw, row.desc, row.flags))\n                    if not delay_commit:\n                        self.conn.commit()\n                if self.chatty:\n                    print('Index %d moved to %d' % (row.id, index))\n\n    def delete_rec(\n            self,\n            index: int = None,\n            low: int = 0,\n            high: int = 0,\n            is_range: bool = False,\n            delay_commit: bool = False,\n            chatty: Optional[bool] = None,\n    ) -> bool:\n        \"\"\"Delete a single record or remove the table if index is 0.\n\n        Parameters\n        ----------\n        index : int, optional\n            DB index of deleted entry.\n        low : int\n            Actual lower index of range.\n        high : int\n            Actual higher index of range.\n        is_range : bool\n            A range is passed using low and high arguments.\n            An index is ignored if is_range is True.\n        delay_commit : bool\n            True if record should not be committed to the DB,\n            leaving commit responsibility to caller. Default is False.\n        chatty : Optional[bool]\n            Override for self.chatty\n\n        Raises\n        ------\n        TypeError\n            If any of index, low, or high variable is not integer.\n\n        Returns\n        -------\n        bool\n            True on success, False on failure.\n\n        Examples\n        --------\n        >>> from tempfile import NamedTemporaryFile\n        >>> import buku\n        >>> sdb = buku.BukuDb(dbfile=NamedTemporaryFile().name)  # single record database\n        >>> sdb.add_rec('https://example.com')\n        1\n        >>> sdb.delete_rec(1)\n        Index 1 deleted\n        True\n\n        Delete record with default range.\n\n        >>> sdb = buku.BukuDb(dbfile=NamedTemporaryFile().name)\n        >>> sdb.add_rec('https://example.com')\n        1\n        >>> sdb.delete_rec(is_range=True)  # doctest: +SKIP\n        Remove ALL bookmarks? (y/n): y\n        All bookmarks deleted\n        True\n\n        Running the function without any parameter will raise TypeError.\n\n        >>> sdb = buku.BukuDb(dbfile=NamedTemporaryFile().name)\n        >>> sdb.add_rec('https://example.com')\n        1\n        >>> sdb.delete_rec()\n        Traceback (most recent call last):\n        ...\n        TypeError: index, low, or high variable is not integer\n\n        Negative number on `high` and `low` parameters when is_range is True\n        will log error and return False\n\n        >>> edb = buku.BukuDb(dbfile=NamedTemporaryFile().name)\n        >>> edb.delete_rec(low=-1, high=-1, is_range=True)\n        False\n\n        Remove the table\n\n        >>> sdb = buku.BukuDb(dbfile=NamedTemporaryFile().name)\n        >>> sdb.delete_rec(0)  # doctest: +SKIP\n        Remove ALL bookmarks? (y/n): y\n        All bookmarks deleted\n        True\n        \"\"\"\n        chatty = (chatty if chatty is not None else self.chatty)\n        params = [low, high]\n        if not is_range:\n            params.append(index)\n        if any(map(lambda x: not isinstance(x, int), params)):\n            raise TypeError('index, low, or high variable is not integer')\n\n        if is_range:  # Delete a range of indices\n            if low < 0 or high < 0:\n                LOGERR('Negative range boundary')\n                return False\n\n            if low > high:\n                low, high = high, low\n\n            # If range starts from 0, delete all records\n            if low == 0:\n                return self.cleardb()\n\n            try:\n                if chatty:\n                    with self.lock:\n                        self.cur.execute('SELECT COUNT(*) from bookmarks where id '\n                                         'BETWEEN ? AND ?', (low, high))\n                        count = self.cur.fetchone()\n                    if count[0] < 1:\n                        print('Index %d-%d: 0 deleted' % (low, high))\n                        return False\n\n                    if self.print_rec(0, low, high, True) is True:\n                        resp = input('Delete these bookmarks? (y/n): ')\n                        if resp != 'y':\n                            return False\n\n                query = 'DELETE from bookmarks where id BETWEEN ? AND ?'\n                with self.lock:\n                    self.cur.execute(query, (low, high))\n                    print('Index %d-%d: %d deleted' % (low, high, self.cur.rowcount))\n                    if not self.cur.rowcount:\n                        return False\n\n                # Compact DB by ascending order of index to ensure\n                # the existing higher indices move only once\n                # Delayed commit is forced\n                with self.lock:\n                    for index in range(low, high + 1):\n                        self.compactdb(index, delay_commit=True)\n\n                    if not delay_commit:\n                        self.conn.commit()\n            except IndexError:\n                LOGERR('No matching index')\n                return False\n        elif index == 0:  # Remove the table\n            return self.cleardb()\n        else:  # Remove a single entry\n            try:\n                if chatty:\n                    with self.lock:\n                        self.cur.execute('SELECT COUNT(*) FROM bookmarks WHERE '\n                                         'id = ? LIMIT 1', (index,))\n                        count = self.cur.fetchone()\n                    if count[0] < 1:\n                        LOGERR('No matching index %d', index)\n                        return False\n\n                    if self.print_rec(index) is True:\n                        resp = input('Delete this bookmark? (y/n): ')\n                        if resp != 'y':\n                            return False\n\n                with self.lock:\n                    query = 'DELETE FROM bookmarks WHERE id = ?'\n                    self.cur.execute(query, (index,))\n                    if self.cur.rowcount == 1:\n                        print('Index %d deleted' % index)\n                        self.compactdb(index, delay_commit=True)\n                        if not delay_commit:\n                            self.conn.commit()\n                    else:\n                        LOGERR('No matching index %d', index)\n                        return False\n            except IndexError:\n                LOGERR('No matching index %d', index)\n                return False\n            except sqlite3.OperationalError as e:\n                LOGERR(e)\n                return False\n\n        return True\n\n    def delete_resultset(self, results):\n        \"\"\"Delete search results in descending order of DB index.\n\n        Indices are expected to be unique and in ascending order.\n\n        Notes\n        -----\n            This API forces a delayed commit.\n\n        Parameters\n        ----------\n        results : list of tuples\n            List of results to delete from DB.\n\n        Returns\n        -------\n        bool\n            True on success, False on failure.\n        \"\"\"\n        if self.chatty:\n            resp = read_in('Delete the search results? (y/n): ')\n            if resp != 'y':\n                return False\n\n        # delete records in reverse order\n        with self.lock:\n            for pos, row in reversed(list(enumerate(results))):\n                self.delete_rec(row[0], delay_commit=True)\n\n                # Commit at every 200th removal, counting from the end\n                if pos % 200 == 0:\n                    self.conn.commit()\n\n        return True\n\n    def delete_rec_all(self, delay_commit=False):\n        \"\"\"Removes all records in the Bookmarks table.\n\n        Parameters\n        ----------\n        delay_commit : bool\n            True if record should not be committed to the DB,\n            leaving commit responsibility to caller. Default is False.\n\n        Returns\n        -------\n        bool\n            True on success, False on failure.\n        \"\"\"\n\n        try:\n            with self.lock:\n                self.cur.execute('DELETE FROM bookmarks')\n                if not delay_commit:\n                    self.conn.commit()\n            return True\n        except Exception as e:\n            LOGERR('delete_rec_all(): %s', e)\n            return False\n\n    def cleardb(self):\n        \"\"\"Drops the bookmark table if it exists.\n\n        Returns\n        -------\n        bool\n            True on success, False on failure.\n        \"\"\"\n\n        resp = read_in('Remove ALL bookmarks? (y/n): ')\n        if resp != 'y':\n            print('No bookmarks deleted')\n            return False\n\n        if self.delete_rec_all():\n            with self.lock:\n                self.cur.execute('VACUUM')\n                self.conn.commit()\n            print('All bookmarks deleted')\n            return True\n\n        return False\n\n    def print_rec(self, index: Optional[int | Sequence[int] | Set[int] | range] = 0,  # Optional[IntOrInts]\n                  low: int = 0, high: int = 0, is_range: bool = False, order: List[str] = []) -> bool:\n        \"\"\"Print bookmark details at index or all bookmarks if index is 0.\n\n        A negative index behaves like tail, if title is blank show \"Untitled\".\n\n        Empty database check will run when `index` < 0 and `is_range` is False.\n\n        Parameters\n        -----------\n        index : int | int[] | int{} | range, optional\n            DB index(es) of record(s) to print. 0 or empty prints all records.\n            Negative value prints out last `index` rows.\n        low : int\n            Actual lower index of range.\n        high : int\n            Actual higher index of range.\n        is_range : bool\n            A range is passed using low and high arguments.\n            An index is ignored if is_range is True.\n        order : list of str\n            Order description (fields from JSON export or DB, prepended with '+'/'-' for ASC/DESC).\n\n        Returns\n        -------\n        bool\n            True on success, False on failure.\n\n        Examples\n        --------\n        >>> import buku\n        >>> from tempfile import NamedTemporaryFile\n        >>> edb = buku.BukuDb(dbfile=NamedTemporaryFile().name)  # empty database\n        >>> edb.print_rec()\n        True\n\n        Print negative index on empty database will log error and return False\n\n        >>> edb.print_rec(-3)\n        False\n\n        print non empty database with default argument.\n\n        >>> sdb = buku.BukuDb(dbfile=NamedTemporaryFile().name)  # single record database\n        >>> sdb.add_rec('https://example.com')\n        1\n        >>> assert sdb.print_rec()\n        1. Example Domain\n           > https://example.com\n        <BLANKLINE>\n\n        Negative number on `high` and `low` parameters when is_range is True\n        will log error and return False\n\n        >>> sdb.print_rec(low=-1, high=-1, is_range=True)\n        False\n        >>> edb.print_rec(low=-1, high=-1, is_range=True)\n        False\n        \"\"\"\n        if isinstance(index, range) and index.step == 1 and index.start != 0:  # low=0 triggers custom behaviour\n            return self.print_rec(None, is_range=True, low=index.start, high=index.stop-1, order=order)\n\n        if not is_range and isinstance(index, int) and index < 0:\n            # Show the last n records\n            _id = self.get_max_id()\n            if not _id:\n                LOGERR('Empty database')\n                return False\n\n            low = (1 if _id <= -index else _id + index + 1)\n            return self.print_rec(None, is_range=True, low=low, high=_id, order=order)\n\n        _order = self._order(order)\n        if is_range:\n            if low < 0 or high < 0:\n                LOGERR('Negative range boundary')\n                return False\n\n            if low > high:\n                low, high = high, low\n\n            try:\n                # If range starts from 0 print all records\n                with self.lock:\n                    if low == 0:\n                        query = f'SELECT * from bookmarks ORDER BY {_order}'\n                        resultset = self.cur.execute(query)\n                    else:\n                        query = f'SELECT * from bookmarks where id BETWEEN ? AND ? ORDER BY {_order}'\n                        resultset = self.cur.execute(query, (low, high))\n            except IndexError:\n                LOGERR('Index out of range')\n                return False\n        elif index:  # Show record at index\n            try:\n                if isinstance(index, int):\n                    results = self._fetch('SELECT * FROM bookmarks WHERE id = ? LIMIT 1', index)\n                else:\n                    placeholder = ', '.join(['?'] * len(index))\n                    results = self._fetch(f'SELECT * FROM bookmarks WHERE id IN ({placeholder}) ORDER BY {_order}', *index)\n            except IndexError:\n                results = None\n            if not results:\n                LOGERR('No matching index %s', index)\n                return False\n\n            single_record = len(results) == 1\n            if self.json is None:\n                print_rec_with_filter(results, self.field_filter)\n            elif self.json:\n                write_string_to_file(format_json(results, single_record, field_filter=self.field_filter), self.json)\n            else:\n                print_json_safe(results, single_record, field_filter=self.field_filter)\n\n            return True\n        else:  # Show all entries\n            with self.lock:\n                self.cur.execute(f'SELECT * FROM bookmarks ORDER BY {_order}')\n                resultset = self.cur.fetchall()\n\n        if not resultset:\n            LOGERR('0 records')\n            return True\n\n        if self.json is None:\n            print_rec_with_filter(resultset, self.field_filter)\n        elif self.json:\n            write_string_to_file(format_json(resultset, field_filter=self.field_filter), self.json)\n        else:\n            print_json_safe(resultset, field_filter=self.field_filter)\n\n        return True\n\n    def get_tag_all(self):\n        \"\"\"Get list of tags in DB.\n\n        Returns\n        -------\n        tuple\n            (list of unique tags sorted alphabetically,\n             dictionary of {tag: usage_count}).\n        \"\"\"\n\n        tags = []\n        unique_tags = []\n        dic = {}\n        qry = 'SELECT DISTINCT tags, COUNT(tags) FROM bookmarks GROUP BY tags'\n        with self.lock:\n            for row in self.cur.execute(qry):\n                tagset = row[0].strip(DELIM).split(DELIM)\n                for tag in tagset:\n                    if tag not in tags:\n                        dic[tag] = row[1]\n                        tags += (tag,)\n                    else:\n                        dic[tag] += row[1]\n\n        if not tags:\n            return tags, dic\n\n        if tags[0] == '':\n            unique_tags = sorted(tags[1:])\n        else:\n            unique_tags = sorted(tags)\n\n        return unique_tags, dic\n\n    def suggest_similar_tag(self, tagstr):\n        \"\"\"Show list of tags those go together in DB.\n\n        Parameters\n        ----------\n        tagstr : str\n            Original tag string.\n\n        Returns\n        -------\n        str\n            DELIM separated string of tags.\n        \"\"\"\n\n        tags = tagstr.split(',')\n        if not len(tags):\n            return tagstr\n\n        qry = 'SELECT DISTINCT tags FROM bookmarks WHERE tags LIKE ?'\n        tagset = set()\n        for tag in tags:\n            if tag == '':\n                continue\n\n            with self.lock:\n                self.cur.execute(qry, ('%' + delim_wrap(tag) + '%',))\n                results = self.cur.fetchall()\n            for row in results:\n                # update tagset with unique tags in row\n                tagset |= set(row[0].strip(DELIM).split(DELIM))\n\n        # remove user supplied tags from tagset\n        tagset.difference_update(tags)\n\n        if not len(tagset):\n            return tagstr\n\n        unique_tags = sorted(tagset)\n\n        print('similar tags:\\n')\n        for count, tag in enumerate(unique_tags):\n            print('%d. %s' % (count + 1, tag))\n\n        selected_tags = input('\\nselect: ').split()\n        print()\n        if not selected_tags:\n            return tagstr\n\n        tags = [tagstr]\n        for index in selected_tags:\n            try:\n                tags.append(delim_wrap(unique_tags[int(index) - 1]))\n            except Exception as e:\n                LOGERR(e)\n                continue\n\n        return parse_tags(tags)\n\n    def replace_tag(self, orig: str, new: List[str] = []):\n        \"\"\"Replace original tag by new tags in all records.\n\n        Remove original tag if new tag is empty.\n\n        Parameters\n        ----------\n        orig : str\n            Original tag.\n        new : list\n            Replacement tags.\n\n        Raises\n        -------\n        ValueError: Invalid input(s) provided.\n        RuntimeError: Tag deletion failed.\n\n        \"\"\"\n\n        if DELIM in orig:\n            raise ValueError(\"Original tag cannot contain delimiter ({}).\".format(DELIM))\n\n        orig = delim_wrap(orig)\n        newtags = taglist_str(DELIM.join(new))\n\n        if orig == newtags:\n            raise ValueError(\"Original and replacement tags are the same.\")\n\n        # Remove original tag from DB if new tagset reduces to delimiter\n        if newtags == DELIM:\n            if not self.delete_tag_at_index(0, orig, chatty=self.chatty):\n                raise RuntimeError(\"Tag deletion failed.\")\n\n        # Update bookmarks with original tag\n        with self.lock:\n            query = 'SELECT id, tags FROM bookmarks WHERE tags LIKE ?'\n            self.cur.execute(query, ('%' + orig + '%',))\n            results = self.cur.fetchall()\n            if results:\n                query = 'UPDATE bookmarks SET tags = ? WHERE id = ?'\n                for row in results:\n                    tags = row[1].replace(orig, newtags)\n                    tags = parse_tags([tags])\n                    self.cur.execute(query, (tags, row[0],))\n                    print('Index %d updated' % row[0])\n\n                self.conn.commit()\n\n    def get_tagstr_from_taglist(self, id_list, taglist):\n        \"\"\"Get a string of delimiter-separated (and enclosed) string\n        of tags from a dictionary of tags by matching ids.\n\n        The inputs are the outputs from BukuDb.get_tag_all().\n\n        Parameters\n        ----------\n        id_list : list\n            List of ids.\n        taglist : list\n            List of tags.\n        Returns\n        -------\n        str\n            Delimiter separated and enclosed list of tags.\n        \"\"\"\n\n        tags = DELIM\n\n        for id in id_list:\n            if is_int(id) and int(id) > 0:\n                tags += taglist[int(id) - 1] + DELIM\n            elif '-' in id:\n                vals = [int(x) for x in id.split('-')]\n                if vals[0] > vals[-1]:\n                    vals[0], vals[-1] = vals[-1], vals[0]\n\n                for _id in range(vals[0], vals[-1] + 1):\n                    tags += taglist[_id - 1] + DELIM\n\n        return tags\n\n    def set_tag(self, cmdstr, taglist):\n        \"\"\"Append, overwrite, remove tags using the symbols >>, > and << respectively.\n\n        Parameters\n        ----------\n        cmdstr : str\n            Command pattern.\n        taglist : list\n            List of tags.\n\n        Returns\n        -------\n        int\n            Number of indices updated on success, -1 on failure, -2 on no symbol found.\n        \"\"\"\n\n        if not cmdstr or not taglist:\n            return -1\n\n        flag = 0  # 0: invalid, 1: append, 2: overwrite, 3: remove\n        index = cmdstr.find('>>')\n        if index == -1:\n            index = cmdstr.find('>')\n            if index != -1:\n                flag = 2\n            else:\n                index = cmdstr.find('<<')\n                if index != -1:\n                    flag = 3\n        else:\n            flag = 1\n\n        if not flag:\n            return -2\n\n        tags = DELIM\n        id_list = cmdstr[:index].split()\n        try:\n            tags = self.get_tagstr_from_taglist(id_list, taglist)\n            if tags == DELIM and flag != 2:\n                return -1\n        except ValueError:\n            return -1\n\n        if flag != 2:\n            index += 1\n\n        with self.lock:\n            update_count = 0\n            query = 'UPDATE bookmarks SET tags = ? WHERE id = ?'\n            try:\n                db_id_list = cmdstr[index + 1:].split()\n                for id in db_id_list:\n                    if is_int(id) and int(id) > 0:\n                        if flag == 1:\n                            if self.append_tag_at_index(id, tags, True):\n                                update_count += 1\n                        elif flag == 2:\n                            tags = parse_tags([tags])\n                            self.cur.execute(query, (tags, id,))\n                            update_count += self.cur.rowcount\n                        else:\n                            self.delete_tag_at_index(id, tags, True)\n                            update_count += 1\n                    elif '-' in id:\n                        vals = [int(x) for x in id.split('-')]\n                        if vals[0] > vals[-1]:\n                            vals[0], vals[-1] = vals[-1], vals[0]\n\n                        for _id in range(vals[0], vals[-1] + 1):\n                            if flag == 1:\n                                if self.append_tag_at_index(_id, tags, True):\n                                    update_count += 1\n                            elif flag == 2:\n                                tags = parse_tags([tags])\n                                self.cur.execute(query, (tags, _id,))\n                                update_count += self.cur.rowcount\n                            else:\n                                if self.delete_tag_at_index(_id, tags, True):\n                                    update_count += 1\n                    else:\n                        return -1\n            except ValueError:\n                return -1\n            except sqlite3.IntegrityError:\n                return -1\n\n            try:\n                self.conn.commit()\n            except Exception as e:\n                LOGERR(e)\n                return -1\n\n        return update_count\n\n    def browse_by_index(self, index=0, low=0, high=0, is_range=False):\n        \"\"\"Open URL at index or range of indices in browser.\n\n        Parameters\n        ----------\n        index : int\n            Index to browse. 0 opens a random bookmark.\n        low : int\n            Actual lower index of range.\n        high : int\n            Higher index of range.\n        is_range : bool\n            A range is passed using low and high arguments.\n            If True, index is ignored. Default is False.\n\n        Returns\n        -------\n        bool\n            True on success, False on failure.\n        \"\"\"\n\n        if is_range:\n            if low < 0 or high < 0:\n                LOGERR('Negative range boundary')\n                return False\n\n            if low > high:\n                low, high = high, low\n\n            try:\n                # If range starts from 0 throw an error\n                if low <= 0:\n                    raise IndexError\n\n                qry = 'SELECT URL from bookmarks where id BETWEEN ? AND ?'\n                with self.lock:\n                    for row in self.cur.execute(qry, (low, high)):\n                        browse(row[0])\n                return True\n            except IndexError:\n                LOGERR('Index out of range')\n                return False\n\n        if index < 0:\n            LOGERR('Invalid index %d', index)\n            return False\n\n        if index == 0:\n            max_id = self.get_max_id()\n            if not max_id:\n                print('No bookmarks added yet ...')\n                return False\n\n            index = random.randint(1, max_id)\n            LOGDBG('Opening random index %d', index)\n\n        qry = 'SELECT URL FROM bookmarks WHERE id = ? LIMIT 1'\n        try:\n            with self.lock:\n                for row in self.cur.execute(qry, (index,)):\n                    browse(row[0])\n                    return True\n            LOGERR('No matching index %d', index)\n        except IndexError:\n            LOGERR('No matching index %d', index)\n\n        return False\n\n    def exportdb(self, filepath: str, resultset: Optional[List[BookmarkVar]] = None,\n                 order: List[str] = ['id'], pick: Optional[int] = None) -> bool:\n        \"\"\"Export DB bookmarks to file.\n        Exports full DB, if resultset is None.\n        Additionally, if run after a (batch) update with export_on, only export those records.\n\n        If destination file name ends with '.db', bookmarks are\n        exported to a buku database file.\n        If destination file name ends with '.md', bookmarks are\n        exported to a Markdown file.\n        If destination file name ends with '.org' bookmarks are\n        exported to an org file.\n        If destination file name ends with '.xbel' bookmarks are\n        exported to a XBEL file.\n        Otherwise, bookmarks are exported to a Firefox bookmarks.html\n        formatted file.\n\n        Parameters\n        ----------\n        filepath : str\n            Path to export destination file.\n        resultset : list of tuples\n            List of results to export. Use `None` to get current DB.\n            Ignored if run after a (batch) update with export_on.\n        order : list of str\n            Order description (fields from JSON export or DB, prepended with '+'/'-' for ASC/DESC).\n        pick : int, optional\n            Reduce the export to a random subset of up to given (positive) size. Default is None.\n\n\n        Returns\n        -------\n        bool\n            True on success, False on failure.\n        \"\"\"\n\n        count = 0\n\n        if not resultset:\n            resultset = self.get_rec_all(order=order)\n            if not resultset:\n                print('No records found')\n                return False\n\n        old = self._to_export or {}\n        if self._to_export is not None:\n            _resultset = dict(old)\n            _resultset.update({x.url: x for x in resultset if x.url in old})\n            resultset = self._sort(_resultset.values(), order)\n            self._to_export = None\n            if not resultset:\n                print('No records to export')\n                return False\n\n        if pick and pick < len(resultset):\n            resultset = self._sort(random.sample(resultset, pick), order)\n\n        if os.path.exists(filepath):\n            resp = read_in(filepath + ' exists. Overwrite? (y/n): ')\n            if resp != 'y':\n                return False\n\n            if filepath.endswith('.db'):\n                os.remove(filepath)\n\n        if filepath.endswith('.db'):\n            outdb = BukuDb(dbfile=filepath)\n            qry = 'INSERT INTO bookmarks(URL, metadata, tags, desc, flags) VALUES (?, ?, ?, ?, ?)'\n            for row in resultset:\n                _old = old.get(row.url)\n                _add = (f' (OLD URL = {_old})' if isinstance(_old, str) and _old != row.url else\n                        ' (DELETED)' if _old is row else '')\n                title = ((row.title or '') + _add if _add else row.title)\n                outdb.cur.execute(qry, (row.url, title, row.tags_raw, row.desc, row.flags))\n                count += 1\n            outdb.conn.commit()\n            outdb.close()\n            print('%s exported' % count)\n            return True\n\n        with open(filepath, mode='w', encoding='utf-8') as outfp:\n            res = {}  # type: Dict\n            if filepath.endswith('.md'):\n                res = convert_bookmark_set(resultset, 'markdown', old)\n                count += res['count']\n                outfp.write(res['data'])\n            elif filepath.endswith('.org'):\n                res = convert_bookmark_set(resultset, 'org', old)\n                count += res['count']\n                outfp.write(res['data'])\n            elif filepath.endswith('.xbel'):\n                res = convert_bookmark_set(resultset, 'xbel', old)\n                count += res['count']\n                outfp.write(res['data'])\n            elif filepath.endswith('.rss'):\n                res = convert_bookmark_set(resultset, 'rss', old)\n                count += res['count']\n                outfp.write(res['data'])\n            else:\n                res = convert_bookmark_set(resultset, 'html', old)\n                count += res['count']\n                outfp.write(res['data'])\n            print('%s exported' % count)\n            return True\n        return False\n\n    def traverse_bm_folder(self, sublist, unique_tag, folder_name, add_parent_folder_as_tag):\n        \"\"\"Traverse bookmark folders recursively and find bookmarks.\n\n        Parameters\n        ----------\n        sublist : list\n            List of child entries in bookmark folder.\n        unique_tag : str\n            Timestamp tag in YYYYMonDD format.\n        folder_name : str\n            Name of the parent folder.\n        add_parent_folder_as_tag : bool\n            True if bookmark parent folders should be added as tags else False.\n\n        Returns\n        -------\n        tuple\n            Bookmark record data.\n        \"\"\"\n\n        for item in sublist:\n            if item['type'] == 'folder':\n                next_folder_name = folder_name + DELIM + strip_delim(item['name'])\n                yield from self.traverse_bm_folder(\n                        item['children'],\n                        unique_tag,\n                        next_folder_name,\n                        add_parent_folder_as_tag)\n            elif item['type'] == 'url':\n                try:\n                    if is_nongeneric_url(item['url']):\n                        continue\n                except KeyError:\n                    continue\n\n                tags = ''\n                if add_parent_folder_as_tag:\n                    tags += folder_name\n                if unique_tag:\n                    tags += DELIM + unique_tag\n                yield (item['url'], item['name'], parse_tags([tags]), None, 0, True, False)\n\n    def load_chrome_database(self, path, unique_tag, add_parent_folder_as_tag):\n        \"\"\"Open Chrome Bookmarks JSON file and import data.\n\n        Parameters\n        ----------\n        path : str\n            Path to Google Chrome bookmarks file.\n        unique_tag : str\n            Timestamp tag in YYYYMonDD format.\n        add_parent_folder_as_tag : bool\n            True if bookmark parent folders should be added as tags else False.\n        \"\"\"\n\n        with open(path, 'r', encoding=\"utf8\") as datafile:\n            data = json.load(datafile)\n\n        roots = data['roots']\n        for entry in roots:\n            # Needed to skip 'sync_transaction_version' key from roots\n            if isinstance(roots[entry], str):\n                continue\n            for item in self.traverse_bm_folder(\n                    roots[entry]['children'],\n                    unique_tag,\n                    roots[entry]['name'],\n                    add_parent_folder_as_tag):\n                self.add_rec(*item)\n\n    def load_firefox_database(self, path, unique_tag, add_parent_folder_as_tag):\n        \"\"\"Connect to Firefox sqlite db and import bookmarks into BukuDb.\n\n        Parameters\n        ----------\n        path : str\n            Path to Firefox bookmarks sqlite database.\n        unique_tag : str\n            Timestamp tag in YYYYMonDD format.\n        add_parent_folder_as_tag : bool\n            True if bookmark parent folders should be added as tags else False.\n        \"\"\"\n\n        # Connect to input DB\n        conn = sqlite3.connect('file:%s?mode=ro' % path, uri=True)\n\n        cur = conn.cursor()\n        res = cur.execute('SELECT DISTINCT fk, parent, title FROM moz_bookmarks WHERE type=1')\n        # get id's and remove duplicates\n        for row in res.fetchall():\n            # get the url\n            res = cur.execute('SELECT url FROM moz_places where id={}'.format(row[0]))\n            url = res.fetchone()[0]\n            if is_nongeneric_url(url):\n                continue\n\n            # get tags\n            res = cur.execute('SELECT parent FROM moz_bookmarks WHERE '\n                              'fk={} AND title IS NULL'.format(row[0]))\n            bm_tag_ids = [tid for item in res.fetchall() for tid in item]\n\n            bookmark_tags = []\n            for bm_tag_id in bm_tag_ids:\n                res = cur.execute('SELECT title FROM moz_bookmarks WHERE id={}'.format(bm_tag_id))\n                bookmark_tags.append(res.fetchone()[0])\n\n            if add_parent_folder_as_tag:\n                # add folder name\n                parent_id = row[1]\n                while parent_id:\n                    res = cur.execute('SELECT title,parent FROM moz_bookmarks '\n                                      'WHERE id={}'.format(parent_id))\n                    parent = res.fetchone()\n                    if parent:\n                        title, parent_id = parent\n                        bookmark_tags.append(title)\n\n            if unique_tag:\n                # add timestamp tag\n                bookmark_tags.append(unique_tag)\n\n            formatted_tags = [DELIM + strip_delim(tag) for tag in bookmark_tags]\n            tags = parse_tags(formatted_tags)\n\n            # get the title\n            title = row[2] or ''\n\n            self.add_rec(url, title, tags, None, 0, True, False)\n        try:\n            cur.close()\n            conn.close()\n        except Exception as e:\n            LOGERR(e)\n\n    def load_edge_database(self, path, unique_tag, add_parent_folder_as_tag):\n        \"\"\"Open Edge Bookmarks JSON file and import data.\n\n        Parameters\n        ----------\n        path : str\n            Path to Microsoft Edge bookmarks file.\n        unique_tag : str\n            Timestamp tag in YYYYMonDD format.\n        add_parent_folder_as_tag : bool\n            True if bookmark parent folders should be added as tags else False.\n        \"\"\"\n\n        with open(path, 'r', encoding=\"utf8\") as datafile:\n            data = json.load(datafile)\n\n        roots = data['roots']\n        for entry in roots:\n            # Needed to skip 'sync_transaction_version' key from roots\n            if isinstance(roots[entry], str):\n                continue\n            for item in self.traverse_bm_folder(\n                    roots[entry]['children'],\n                    unique_tag,\n                    roots[entry]['name'],\n                    add_parent_folder_as_tag):\n                self.add_rec(*item)\n\n    def auto_import_from_browser(self, firefox_profile=None):\n        \"\"\"Import bookmarks from a browser default database file.\n\n        Supports Firefox, Google Chrome, Vivaldi, and Microsoft Edge.\n\n        Returns\n        -------\n        bool\n            True on success, False on failure.\n        \"\"\"\n\n        if sys.platform.startswith(('linux', 'freebsd', 'openbsd')):\n            gc_bm_db_path = '~/.config/google-chrome/Default/Bookmarks'\n            cb_bm_db_path = '~/.config/chromium/Default/Bookmarks'\n            vi_bm_db_path = '~/.config/vivaldi/Default/Bookmarks'\n            me_bm_db_path = '~/.config/microsoft-edge/Default/Bookmarks'\n            default_ff_folder = '~/.mozilla/firefox'\n        elif sys.platform == 'darwin':\n            gc_bm_db_path = '~/Library/Application Support/Google/Chrome/Default/Bookmarks'\n            cb_bm_db_path = '~/Library/Application Support/Chromium/Default/Bookmarks'\n            vi_bm_db_path = '~/Library/Application Support/Vivaldi/Default/Bookmarks'\n            me_bm_db_path = '~/Library/Application Support/Microsoft Edge/Default/Bookmarks'\n            default_ff_folder = '~/Library/Application Support/Firefox'\n        elif sys.platform == 'win32':\n            gc_bm_db_path = os.path.expandvars('%LOCALAPPDATA%/Google/Chrome/User Data/Default/Bookmarks')\n            cb_bm_db_path = os.path.expandvars('%LOCALAPPDATA%/Chromium/User Data/Default/Bookmarks')\n            vi_bm_db_path = os.path.expandvars('%LOCALAPPDATA%/Vivaldi/User Data/Default/Bookmarks')\n            me_bm_db_path = os.path.expandvars('%LOCALAPPDATA%/Microsoft/Edge/User Data/Default/Bookmarks')\n            default_ff_folder = os.path.expandvars('%APPDATA%/Mozilla/Firefox/')\n        else:\n            LOGERR('buku does not support {} yet'.format(sys.platform))\n            self.close_quit(1)\n            return  # clarifying execution interrupt for the linter\n\n        ff_bm_db_paths = get_firefox_db_paths(default_ff_folder, firefox_profile)\n\n        if self.chatty:\n            resp = input('Generate auto-tag (YYYYMonDD)? (y/n): ')\n            if resp == 'y':\n                newtag = gen_auto_tag()\n            else:\n                newtag = None\n            resp = input('Add parent folder names as tags? (y/n): ')\n        else:\n            newtag = None\n            resp = 'y'\n        add_parent_folder_as_tag = resp == 'y'\n\n        with self.lock:\n            resp = 'y'\n\n            chrome_based = {'Google Chrome': gc_bm_db_path, 'Chromium': cb_bm_db_path, 'Vivaldi': vi_bm_db_path}\n            for name, path in chrome_based.items():\n                try:\n                    if os.path.isfile(os.path.expanduser(path)):\n                        if self.chatty:\n                            resp = input(f'Import bookmarks from {name}? (y/n): ')\n                        if resp == 'y':\n                            bookmarks_database = os.path.expanduser(path)\n                            if not os.path.exists(bookmarks_database):\n                                raise FileNotFoundError\n                            self.load_chrome_database(bookmarks_database, newtag, add_parent_folder_as_tag)\n                except Exception as e:\n                    LOGERR(e)\n                    print(f'Could not import bookmarks from {name}')\n\n            try:\n                ff_bm_db_paths = {k: s for k, s in ff_bm_db_paths.items() if os.path.isfile(os.path.expanduser(s))}\n                for idx, (name, ff_bm_db_path) in enumerate(ff_bm_db_paths.items(), start=1):\n                    if self.chatty:\n                        profile = ('' if len(ff_bm_db_paths) < 2 else\n                                   f' profile {name} [{idx}/{len(ff_bm_db_paths)}]')\n                        resp = input(f'Import bookmarks from Firefox{profile}? (y/n): ')\n                    if resp == 'y':\n                        bookmarks_database = os.path.expanduser(ff_bm_db_path)\n                        if not os.path.exists(bookmarks_database):\n                            raise FileNotFoundError\n                        self.load_firefox_database(bookmarks_database, newtag, add_parent_folder_as_tag)\n                        break\n            except Exception as e:\n                LOGERR(e)\n                print('Could not import bookmarks from Firefox.')\n\n            try:\n                if os.path.isfile(os.path.expanduser(me_bm_db_path)):\n                    if self.chatty:\n                        resp = input('Import bookmarks from microsoft edge? (y/n): ')\n                    if resp == 'y':\n                        bookmarks_database = os.path.expanduser(me_bm_db_path)\n                        if not os.path.exists(bookmarks_database):\n                            raise FileNotFoundError\n                        self.load_edge_database(bookmarks_database, newtag, add_parent_folder_as_tag)\n            except Exception as e:\n                LOGERR(e)\n                print('Could not import bookmarks from microsoft-edge')\n\n            self.conn.commit()\n\n        if newtag:\n            print('\\nAuto-generated tag: %s' % newtag)\n\n    def importdb(self, filepath, tacit=False):\n        \"\"\"Import bookmarks from an HTML or a Markdown file.\n\n        Supports Firefox, Google Chrome, and IE exported HTML bookmarks.\n        Supports XBEL standard bookmarks.\n        Supports Markdown files with extension '.md, .org'.\n        Supports importing bookmarks from another buku database file.\n\n        Parameters\n        ----------\n        filepath : str\n            Path to file to import.\n        tacit : bool\n            If True, no questions asked and folder names are automatically\n            imported as tags from bookmarks HTML.\n            If True, automatic timestamp tag is NOT added.\n            Default is False.\n\n        Returns\n        -------\n        bool\n            True on success, False on failure.\n        \"\"\"\n\n        if filepath.endswith('.db'):\n            return self.mergedb(filepath)\n\n        newtag = None\n        append_tags_resp = 'y'\n        if not tacit:\n            if input('Generate auto-tag (YYYYMonDD)? (y/n): ') == 'y':\n                newtag = gen_auto_tag()\n            append_tags_resp = input('Append tags when bookmark exist? (y/n): ')\n\n        items = []\n        if filepath.endswith('.md'):\n            items = import_md(filepath=filepath, newtag=newtag)\n        elif filepath.endswith('org'):\n            items = import_org(filepath=filepath, newtag=newtag)\n        elif filepath.endswith('rss'):\n            items = import_rss(filepath=filepath, newtag=newtag)\n        elif filepath.endswith('json'):\n            if not tacit:\n                resp = input('Add parent folder names as tags? (y/n): ')\n            else:\n                resp = 'y'\n            add_bookmark_folder_as_tag = resp == 'y'\n            try:\n                with open(filepath, 'r', encoding='utf-8') as datafile:\n                    data = json.load(datafile)\n\n                items = import_firefox_json(data, add_bookmark_folder_as_tag, newtag)\n            except ValueError as e:\n                LOGERR(\"ff_json: JSON Decode Error: {}\".format(e))\n                return False\n            except Exception as e:\n                LOGERR(e)\n                return False\n        elif filepath.endswith('xbel'):\n            try:\n                with open(filepath, mode='r', encoding='utf-8') as infp:\n                    soup = BeautifulSoup(infp, 'html.parser')\n            except ImportError:\n                LOGERR('Beautiful Soup not found')\n                return False\n            except Exception as e:\n                LOGERR(e)\n                return False\n\n            add_parent_folder_as_tag = False\n            use_nested_folder_structure = False\n            if not tacit:\n                resp = input(\"\"\"Add bookmark's parent folder as tag?\na: add all parent folders of the bookmark\nn: don't add parent folder as tag\n(a/[n]): \"\"\")\n            else:\n                resp = 'y'\n\n            if resp == 'a':\n                add_parent_folder_as_tag = True\n                use_nested_folder_structure = True\n\n            items = import_xbel(soup, add_parent_folder_as_tag, newtag, use_nested_folder_structure)\n            infp.close()\n        else:\n            try:\n                with open(filepath, mode='r', encoding='utf-8') as infp:\n                    soup = BeautifulSoup(infp, 'html.parser')\n            except ImportError:\n                LOGERR('Beautiful Soup not found')\n                return False\n            except Exception as e:\n                LOGERR(e)\n                return False\n\n            add_parent_folder_as_tag = False\n            use_nested_folder_structure = False\n            if not tacit:\n                resp = input(\"\"\"Add bookmark's parent folder as tag?\ny: add single, direct parent folder\na: add all parent folders of the bookmark\nn: don't add parent folder as tag\n(y/a/[n]): \"\"\")\n            else:\n                resp = 'y'\n\n            if resp in ('y', 'a'):\n                add_parent_folder_as_tag = True\n                if resp == 'a':\n                    use_nested_folder_structure = True\n\n            items = import_html(soup, add_parent_folder_as_tag, newtag, use_nested_folder_structure)\n            infp.close()\n\n        with self.lock:\n            for item in items:\n                add_rec_res = self.add_rec(*item)\n                if not add_rec_res and append_tags_resp == 'y':\n                    rec_id = self.get_rec_id(item[0])\n                    self.append_tag_at_index(rec_id, item[2])\n\n            self.conn.commit()\n\n        if newtag:\n            print('\\nAuto-generated tag: %s' % newtag)\n\n        return True\n\n    def mergedb(self, path):\n        \"\"\"Merge bookmarks from another buku database file.\n\n        Parameters\n        ----------\n        path : str\n            Path to DB file to merge.\n\n        Returns\n        -------\n        bool\n            True on success, False on failure.\n        \"\"\"\n\n        try:\n            # Connect to input DB\n            indb_conn = sqlite3.connect('file:%s?mode=ro' % path, uri=True)\n\n            indb_cur = indb_conn.cursor()\n            indb_cur.execute('SELECT * FROM bookmarks')\n        except Exception as e:\n            LOGERR(e)\n            return False\n\n        resultset = indb_cur.fetchall()\n        if resultset:\n            with self.lock:\n                for row in bookmark_vars(resultset):\n                    self.add_rec(row.url, row.title, row.tags_raw, row.desc, row.flags, True, False)\n\n                self.conn.commit()\n\n        try:\n            indb_cur.close()\n            indb_conn.close()\n        except Exception:\n            pass\n\n        return True\n\n    def tnyfy_url(\n            self,\n            index: Optional[int] = None,\n            url: Optional[str] = None,\n            shorten: bool = True) -> Optional[str]:\n        \"\"\"Shorten a URL using Google URL shortener.\n\n        Parameters\n        ----------\n        index : int, optional (if URL is provided)\n            DB index of the bookmark with the URL to shorten. Default is None.\n        url : str, optional (if index is provided)\n            URL to shorten.\n        shorten : bool\n            True to shorten, False to expand. Default is False.\n\n        Returns\n        -------\n        str\n            Shortened url on success, None on failure.\n        \"\"\"\n\n        global MYPROXY\n\n        if not index and not url:\n            LOGERR('Either a valid DB index or URL required')\n            return None\n\n        if index:\n            with self.lock:\n                self.cur.execute('SELECT url FROM bookmarks WHERE id = ? LIMIT 1', (index,))\n                results = self.cur.fetchall()\n            if not results:\n                return None\n\n            url = results[0][0]\n\n        from urllib.parse import quote_plus as qp\n\n        url = url or ''\n        urlbase = 'https://tny.im/yourls-api.php?action='\n        if shorten:\n            _u = urlbase + 'shorturl&format=simple&url=' + qp(url)\n        else:\n            _u = urlbase + 'expand&format=simple&shorturl=' + qp(url)\n\n        if MYPROXY is None:\n            gen_headers()\n\n        ca_certs = os.getenv('BUKU_CA_CERTS', default=CA_CERTS)\n        if MYPROXY:\n            manager = urllib3.ProxyManager(\n                MYPROXY,\n                num_pools=1,\n                headers=MYHEADERS,\n                cert_reqs='CERT_REQUIRED',\n                ca_certs=ca_certs)\n        else:\n            manager = urllib3.PoolManager(num_pools=1,\n                                          headers={'User-Agent': USER_AGENT},\n                                          cert_reqs='CERT_REQUIRED',\n                                          ca_certs=ca_certs)\n\n        try:\n            r = manager.request(\n                'POST',\n                _u,\n                headers={\n                    'content-type': 'application/json',\n                    'User-Agent': USER_AGENT}\n            )\n        except Exception as e:\n            LOGERR(e)\n            manager.clear()\n            return None\n\n        if r.status != 200:\n            LOGERR('[%s] %s', r.status, r.reason)\n            return None\n\n        manager.clear()\n\n        return r.data.decode(errors='replace')\n\n    def browse_cached_url(self, arg):\n        \"\"\"Open URL at index or URL.\n\n        Parameters\n        ----------\n        arg : str\n            Index or url to browse\n\n        Returns\n        -------\n        str\n            Wayback Machine URL, None if not cached\n        \"\"\"\n\n        from urllib.parse import quote_plus\n\n        if is_int(arg):\n            rec = self.get_rec_by_id(int(arg))\n            if not rec:\n                LOGERR('No matching index %d', int(arg))\n                return None\n            url = rec[1]\n        else:\n            url = arg\n\n        # Try fetching cached page from Wayback Machine\n        api_url = 'https://archive.org/wayback/available?url=' + quote_plus(url)\n        manager = get_PoolManager()\n        resp = manager.request('GET', api_url)\n        respobj = json.loads(resp.data)\n        try:\n            if (\n                    len(respobj['archived_snapshots']) and\n                    respobj['archived_snapshots']['closest']['available'] is True):\n                manager.clear()\n                return respobj['archived_snapshots']['closest']['url']\n        except Exception:\n            pass\n        finally:\n            manager.clear()\n\n        LOGERR('Uncached')\n        return None\n\n    def fixtags(self):\n        \"\"\"Undocumented API to fix tags set in earlier versions.\n\n        Functionalities:\n\n        1. Remove duplicate tags\n        2. Sort tags\n        3. Use lower case to store tags\n        \"\"\"\n\n        to_commit = False\n        with self.lock:\n            self.cur.execute('SELECT id, tags FROM bookmarks ORDER BY id ASC')\n            resultset = self.cur.fetchall()\n            query = 'UPDATE bookmarks SET tags = ? WHERE id = ?'\n            for row in resultset:\n                oldtags = row[1]\n                if oldtags == DELIM:\n                    continue\n\n                tags = parse_tags([oldtags])\n                if tags == oldtags:\n                    continue\n\n                self.cur.execute(query, (tags, row[0],))\n                to_commit = True\n\n            if to_commit:\n                self.conn.commit()\n\n    def close(self):\n        \"\"\"Close a DB connection.\"\"\"\n\n        if self.conn is not None:\n            try:\n                self.cur.close()\n                self.conn.close()\n            except Exception:\n                # ignore errors here, we're closing down\n                pass\n\n    def close_quit(self, exitval=0):\n        \"\"\"Close a DB connection and exit.\n\n        Parameters\n        ----------\n        exitval : int\n            Program exit value.\n        \"\"\"\n\n        if self.conn is not None:\n            try:\n                self.cur.close()\n                self.conn.close()\n            except Exception:\n                # ignore errors here, we're closing down\n                pass\n        sys.exit(exitval)\n\n\nclass ExtendedArgumentParser(argparse.ArgumentParser):\n    \"\"\"Extend classic argument parser.\"\"\"\n\n    @staticmethod\n    def program_info(file=sys.stdout):\n        \"\"\"Print program info.\n\n        Parameters\n        ----------\n        file : file\n            File to write program info to. Default is sys.stdout.\n        \"\"\"\n        if sys.platform == 'win32' and file == sys.stdout:\n            file = sys.stderr\n\n        file.write('''\nSYMBOLS:\n      >                    url\n      +                    comment\n      #                    tags\n\nVersion %s\nCopyright Â© 2015-2024 %s\nLicense: %s\nWebpage: https://github.com/jarun/buku\n''' % (__version__, __author__, __license__))\n\n    @staticmethod\n    def prompt_help(file=sys.stdout):\n        \"\"\"Print prompt help.\n\n        Parameters\n        ----------\n        file : file\n            File to write program info to. Default is sys.stdout.\n        \"\"\"\n        file.write('''\nPROMPT KEYS:\n    1-N                    browse search result indices and/or ranges\n    R [N]                  print out N random search results\n                           (or random bookmarks if negative or N/A)\n    ^ id1 id2              swap two records at specified indices\n    O [id|range [...]]     open search results/indices in GUI browser\n                           toggle try GUI browser if no arguments\n    a                      open all results in browser\n    s keyword [...]        search for records with ANY keyword\n    S keyword [...]        search for records with ALL keywords\n    d                      match substrings ('pen' matches 'opened')\n    m                      search with markers - search string is split\n                           into keywords by prefix markers, which determine\n                           what field the keywords is searched in:\n                           '.', '>' or ':' - title, description or URL\n                           '#'/'#,' - tags (comma-separated, partial/full match)\n                           '*' - all fields (can be omitted in the 1st keyword)\n                           note: tag marker is not affected by 'd' (deep search)\n    v fields               change sorting order (default is '+index')\n                           multiple comma/space separated fields can be specified\n    r expression           run a regex search\n    t [tag, ...]           search by tags; show taglist, if no args\n    g taglist id|range [...] [>>|>|<<] [record id|range ...]\n                           append, set, remove (all or specific) tags\n                           search by taglist id(s) if records are omitted\n    n                      show next page of search results\n    o id|range [...]       browse bookmarks by indices and/or ranges\n    p id|range [...]       print bookmarks by indices and/or ranges\n    w [editor|id]          edit and add or update a bookmark\n    c id                   copy url at search result index to clipboard\n    ?                      show this help\n    q, ^D, double Enter    exit buku\n\n''')\n\n    @staticmethod\n    def is_colorstr(arg):\n        \"\"\"Check if a string is a valid color string.\n\n        Parameters\n        ----------\n        arg : str\n            Color string to validate.\n\n        Returns\n        -------\n        str\n            Same color string that was passed as an argument.\n\n        Raises\n        ------\n        ArgumentTypeError\n            If the arg is not a valid color string.\n        \"\"\"\n        try:\n            assert len(arg) == 5\n            for c in arg:\n                assert c in COLORMAP\n        except AssertionError as e:\n            raise argparse.ArgumentTypeError('%s is not a valid color string' % arg) from e\n        return arg\n\n    # Help\n    def print_help(self, file=sys.stdout):\n        \"\"\"Print help prompt.\n\n        Parameters\n        ----------\n        file : file\n            File to write program info to. Default is sys.stdout.\n        \"\"\"\n        super().print_help(file)\n        self.program_info(file)\n\n\n# ----------------\n# Helper functions\n# ----------------\n\n\nConverterResult = TypedDict('ConverterResult', {'data': str, 'count': int}) if TypedDict else Dict[str, Any]\n\n\ndef convert_tags_to_org_mode_tags(tags: str) -> str:\n    \"\"\"convert buku tags to org-mode compatible tags.\"\"\"\n    if tags != DELIM:\n        buku_tags = tags.split(DELIM)[1:-1]\n        buku_tags = [re.sub(r'[^a-zA-Z0-9_@]', ' ', tag) for tag in buku_tags]\n        buku_tags = [re.sub(r'\\s+', ' ', tag) for tag in buku_tags]\n        buku_tags = taglist(x.replace(' ', '_') for x in buku_tags)\n        if buku_tags:\n            return ' :{}:\\n'.format(':'.join(buku_tags))\n    return '\\n'\n\n\ndef convert_bookmark_set(\n        bookmark_set: List[BookmarkVar],\n        export_type: str,\n        old: Optional[Dict[str, str | BookmarkVar]] = None) -> ConverterResult:  # type: ignore\n    \"\"\"Convert list of bookmark set into multiple data format.\n\n    Parameters\n    ----------\n        bookmark_set: bookmark set\n        export_type: one of supported type: markdown, html, org, XBEL\n        old: cached values of deleted records/replaced URLs to save\n\n    Returns\n    -------\n        converted data and count of converted bookmark set\n    \"\"\"\n    import html\n    assert export_type in ['markdown', 'html', 'org', 'xbel', 'rss']\n    #  compatibility\n    resultset = bookmark_vars(bookmark_set)\n    old = old or {}\n\n    def title(row):\n        _old = old.get(row.url)\n        _add = (f' (OLD URL = {_old})' if isinstance(_old, str) and _old != row.url else\n                ' (DELETED)' if _old == row else '')\n        return (row.title or '') + _add\n\n    count = 0\n    out = ''\n    if export_type == 'markdown':\n        for row in resultset:\n            _title = title(row)\n            out += (f'- <{row.url}>' if not _title else f'- [{_title}]({row.url})')\n\n            if row.tags:\n                out += ' <!-- TAGS: {} -->\\n'.format(row.tags)\n            else:\n                out += '\\n'\n\n            count += 1\n    elif export_type == 'org':\n        for row in resultset:\n            _title = title(row)\n            out += (f'* [[{row.url}]]' if not _title else f'* [[{row.url}][{_title}]]')\n            out += convert_tags_to_org_mode_tags(row.tags_raw)\n            count += 1\n    elif export_type == 'xbel':\n        timestamp = str(int(time.time()))\n        out = (\n            '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n'\n            '<!DOCTYPE xbel PUBLIC \\\n\"+//IDN python.org//DTD XML Bookmark Exchange Language 1.0//EN//XML\" \\\n\"http://pyxml.sourceforge.net/topics/dtds/xbel.dtd\">\\n\\n'\n            '<xbel version=\"1.0\">\\n')\n\n        for row in resultset:\n            out += '    <bookmark href=\"%s\"' % (html.escape(row.url)).encode('ascii', 'xmlcharrefreplace').decode('utf-8')\n            if row.tags:\n                out += ' TAGS=\"' + html.escape(row.tags).encode('ascii', 'xmlcharrefreplace').decode('utf-8') + '\"'\n            out += '>\\n        <title>{}</title>\\n    </bookmark>\\n'\\\n                .format(html.escape(title(row)).encode('ascii', 'xmlcharrefreplace').decode('utf-8'))\n            count += 1\n\n        out += '</xbel>'\n    elif export_type == 'rss':\n        out = (\n            '<feed xmlns=\"http://www.w3.org/2005/Atom\">\\n'\n            '    <title>Bookmarks</title>\\n'\n            '    <generator uri=\"https://github.com/jarun/buku\">buku</generator>\\n'\n        )\n\n        for row in resultset:\n            out += '    <entry>\\n'\n            out += '        <title>' + title(row) + '</title>\\n'\n            _url = html.escape(row.url).encode('ascii', 'xmlcharrefreplace').decode('utf-8')\n            out += '        <link href=\"%s\" rel=\"alternate\" type=\"text/html\"/>\\n' % _url\n            out += '        <id>%s</id>\\n' % row.id\n            for tag in (t for t in row.tags.split(',') if t):\n                _tag = html.escape(tag).encode('ascii', 'xmlcharrefreplace').decode('utf-8')\n                out += '        <category term=\"%s\"/>\\n' % _tag\n            if row.desc:\n                _desc = html.escape(row.desc).encode('ascii', 'xmlcharrefreplace').decode('utf-8')\n                out += '        <content type=\"html\"> <![CDATA[ <p>%s</p> ]]> </content>\\n' % _desc\n            out += '    </entry>\\n'\n            count += 1\n\n        out += '</feed>'\n    elif export_type == 'html':\n        timestamp = str(int(time.time()))\n        out = (\n            '<!DOCTYPE NETSCAPE-Bookmark-file-1>\\n\\n'\n            '<META HTTP-EQUIV=\"Content-Type\" CONTENT=\"text/html; charset=UTF-8\">\\n'\n            '<TITLE>Bookmarks</TITLE>\\n'\n            '<H1>Bookmarks</H1>\\n\\n'\n            '<DL><p>\\n'\n            '    <DT><H3 ADD_DATE=\"{0}\" LAST_MODIFIED=\"{0}\" '\n            'PERSONAL_TOOLBAR_FOLDER=\"true\">buku bookmarks</H3>\\n'\n            '    <DL><p>\\n'.format(timestamp))\n\n        for row in resultset:\n            out += '        <DT><A HREF=\"%s\" ADD_DATE=\"%s\" LAST_MODIFIED=\"%s\"' % (row.url, timestamp, timestamp)\n            if row.tags:\n                out += ' TAGS=\"' + row.tags + '\"'\n            out += '>{}</A>\\n'.format(title(row))\n            if row.desc:\n                out += '        <DD>' + row.desc + '\\n'\n            count += 1\n\n        out += '    </DL><p>\\n</DL><p>'\n\n    return {'data': out, 'count': count}\n\n\ndef get_firefox_profile_names(path):\n    \"\"\"List folder and detect default Firefox profile names for all installs.\n\n    Returns\n    -------\n    profiles : [str]\n        All default Firefox profile names.\n    \"\"\"\n    from configparser import ConfigParser, NoOptionError\n\n    profiles = []\n    profile_path = os.path.expanduser(os.path.join(path, 'profiles.ini'))\n    if os.path.exists(profile_path):\n        config = ConfigParser()\n        config.read(profile_path)\n\n        install_names = [section for section in config.sections() if section.startswith('Install')]\n        for name in install_names:\n            try:\n                profiles += [config.get(name, 'default')]\n            except NoOptionError:\n                pass\n        if profiles:\n            return profiles\n\n        profiles_names = [section for section in config.sections() if section.startswith('Profile')]\n        for name in profiles_names:\n            try:\n                # If profile is default\n                if config.getboolean(name, 'default'):\n                    profiles += [config.get(name, 'path')]\n                    continue\n            except NoOptionError:\n                pass\n            try:\n                # alternative way to detect default profile\n                if config.get(name, 'name').lower() == \"default\":\n                    profiles += [config.get(name, 'path')]\n            except NoOptionError:\n                pass\n\n        return profiles\n\n    # There are no default profiles\n    LOGDBG('get_firefox_profile_names(): {} does not exist'.format(path))\n    return profiles\n\ndef get_firefox_db_paths(default_ff_folder, specified=None):\n    profiles = ([specified] if specified else get_firefox_profile_names(default_ff_folder))\n    _profile_path = lambda s: (s if os.path.isabs(s) else os.path.join(default_ff_folder, s))\n    return {s: os.path.join(_profile_path(s), 'places.sqlite') for s in profiles}\n\n\ndef walk(root):\n    \"\"\"Recursively iterate over JSON.\n\n    Parameters\n    ----------\n    root : JSON element\n        Base node of the JSON data.\n    \"\"\"\n\n    for element in root['children']:\n        if element['type'] == 'url':\n            url = element['url']\n            title = element['name']\n            yield (url, title, None, None, 0, True)\n        else:\n            walk(element)\n\n\ndef import_md(filepath: str, newtag: Optional[str]):\n    \"\"\"Parse bookmark Markdown file.\n\n    Parameters\n    ----------\n    filepath : str\n        Path to Markdown file.\n    newtag : str, optional\n        New tag for bookmarks in Markdown file.\n\n    Returns\n    -------\n    tuple\n        Parsed result.\n    \"\"\"\n    # Supported Markdown format: `[title](url) <!-- TAGS: tags -->` (or `<url> <!-- TAGS: tags -->`)\n    _named_link, _raw_link = r'\\[(?P<title>.*)\\]\\((?P<url>.+)\\)', r'\\<(?P<url_raw>[^!>][^>]*)\\>'\n    pattern = re.compile(r'(%s|%s)(\\s+<!-- TAGS: (?P<tags>.*) -->)?' % (_named_link, _raw_link))\n    with open(filepath, mode='r', encoding='utf-8') as infp:\n        for line in infp:\n            if match := pattern.search(line):\n                title = match.group('title') or ''\n                url = match.group('url') or match.group('url_raw')\n\n                if is_nongeneric_url(url):\n                    continue\n\n                tags = DELIM.join(s for s in [newtag, match.group('tags')] if s)\n                tags = parse_tags([tags])\n\n                yield (url, title, delim_wrap(tags), None, 0, True, False)\n\ndef import_rss(filepath: str, newtag: Optional[str]):\n    \"\"\"Parse bookmark RSS file.\n\n    Parameters\n    ----------\n    filepath : str\n        Path to RSS file.\n    newtag : str, optional\n        New tag for bookmarks in RSS file.\n\n    Returns\n    tuple\n        Parsed result.\n    \"\"\"\n\n    with open(filepath, mode='r', encoding='utf-8') as infp:\n        ns = {'atom': 'http://www.w3.org/2005/Atom'}\n        root = ET.fromstring(infp.read())\n        for entry in root.findall('atom:entry', ns):\n            title = entry.find('atom:title', ns).text\n            url = entry.find('atom:link', ns).attrib['href']\n            tags = ','.join([tag.attrib['term'] for tag in entry.findall('atom:category', ns)])\n            if newtag is not None:\n                tags = newtag + ',' + tags\n            desc = entry.find('atom:content', ns)\n            desc = desc.text if desc is not None else None\n            yield (url, title, delim_wrap(tags), desc, 0, True, False)\n\ndef import_org(filepath: str, newtag: Optional[str]):\n    \"\"\"Parse bookmark org file.\n\n    Parameters\n    ----------\n    filepath : str\n        Path to org file.\n    newtag : str, optional\n        New tag for bookmarks in org file.\n\n    Returns\n    -------\n    tuple\n        Parsed result.\n    \"\"\"\n    def get_org_tags(tag_string):\n        \"\"\"Extracts tags from Org\n\n        Parameters\n        ----------\n        tag_string: str\n             string of tags in Org-format\n\n        Syntax: Org splits tags with colons. If colons are part of a buku-tag, this is indicated by using\n                multiple colons in org. If a buku-tag starts or ends with a colon, this is indicated by a\n                preceding or trailing whitespace\n\n        Returns\n        -------\n        list\n            List of tags\n        \"\"\"\n        tag_list_raw = [s for s in re.split(r'(?<!\\:)\\:', tag_string) if s]\n        tag_list_cleaned = []\n        for i, tag in enumerate(tag_list_raw):\n            if tag.startswith(\":\"):\n                if tag_list_raw[i-1] == ' ':\n                    tag_list_cleaned.append(tag.strip())\n                else:\n                    new_item = tag_list_cleaned[-1] + tag\n                    del tag_list_cleaned[-1]\n                    tag_list_cleaned.append(new_item.strip())\n            elif tag != ' ':\n                tag_list_cleaned.append(tag.strip())\n        return tag_list_cleaned\n\n    # Supported OrgMode format: `[[url][title]] :tags:` (or `[[url]] :tags:`)\n    _url, _maybe_title = r'(?P<url>((?!\\]\\[).)+?)', r'(\\]\\[(?P<title>.+))?'\n    pattern = re.compile(r'\\[\\[%s%s\\]\\](?P<tags>\\s+:.*:)?' % (_url, _maybe_title))\n    with open(filepath, mode='r', encoding='utf-8') as infp:\n        for line in infp:\n            if match := pattern.search(line):\n                title = match.group('title') or ''\n                url = match.group('url')\n\n                if is_nongeneric_url(url):\n                    continue\n\n                tags = list(dict.fromkeys(get_org_tags(match.group('tags') or '')))\n                tags_string = DELIM.join(tags)\n                if newtag and newtag.lower() not in tags:\n                    tags_string = (newtag + DELIM) + tags_string\n\n                yield (url, title, delim_wrap(tags_string), None, 0, True, False)\n\ndef import_firefox_json(json, add_bookmark_folder_as_tag=False, unique_tag=None):\n    \"\"\"Open Firefox JSON export file and import data.\n    Ignore 'SmartBookmark'  and 'Separator'  entries.\n\n    Needed/used fields out of the JSON schema of the bookmarks:\n\n    title              : the name/title of the entry\n    tags               : ',' separated tags for the bookmark entry\n    typeCode           : 1 - uri, 2 - subfolder, 3 - separator\n    annos/{name,value} : following annotation entries are used\n        name : Places/SmartBookmark            : identifies smart folder, ignored\n        name : bookmarkPropereties/description :  detailed bookmark entry description\n    children           : for subfolders, recurse into the child entries\n\n    Parameters\n    ----------\n    path : str\n        Path to Firefox JSON bookmarks file.\n    unique_tag : str\n        Timestamp tag in YYYYMonDD format.\n    add_bookmark_folder_as_tag : bool\n        True if bookmark parent folder should be added as tags else False.\n    \"\"\"\n\n    class TypeCode(Enum):\n        \"\"\" Format\n            typeCode\n                1 : uri        (type=text/x-moz-place)\n                2 : subfolder  (type=text/x-moz-container)\n                3 : separator  (type=text/x-moz-separator)\n        \"\"\"\n        uri = 1\n        folder = 2\n        separator = 3\n\n    def is_smart(entry):\n        result = False\n        try:\n            d = [anno for anno in entry['annos'] if anno['name'] == \"Places/SmartBookmark\"]\n            result = bool(len(d))\n        except Exception:\n            result = False\n\n        return result\n\n    def extract_desc(entry):\n        try:\n            d = [\n                anno for anno in entry['annos']\n                if anno['name'] == \"bookmarkProperties/description\"\n            ]\n            return d[0]['value']\n        except Exception:\n            LOGDBG(\"ff_json: No description found for entry: {} {}\".format(entry['uri'], entry['title']))\n            return \"\"\n\n    def extract_tags(entry):\n        tags = []\n        try:\n            tags = entry['tags'].split(',')\n        except Exception:\n            LOGDBG(\"ff_json: No tags found for entry: {} {}\".format(entry['uri'], entry['title']))\n\n        return tags\n\n    def iterate_children(parent_folder, entry_list):\n        for bm_entry in entry_list:\n            entry_title = bm_entry['title'] if 'title' in bm_entry else \"<no title>\"\n\n            try:\n                typeCode = bm_entry['typeCode']\n            except Exception:\n                LOGDBG(\"ff_json: item without typeCode found, ignoring: {}\".format(entry_title))\n                continue\n\n            LOGDBG(\"ff_json: processing typeCode '{}', title '{}'\".format(typeCode, entry_title))\n            if TypeCode.uri.value == typeCode:\n                try:\n                    if is_smart(bm_entry):\n                        LOGDBG(\"ff_json: SmartBookmark found, ignoring: {}\".format(entry_title))\n                        continue\n\n                    if is_nongeneric_url(bm_entry['uri']):\n                        LOGDBG(\"ff_json: Non-Generic URL found, ignoring: {}\".format(entry_title))\n                        continue\n\n                    desc = extract_desc(bm_entry)\n                    bookmark_tags = extract_tags(bm_entry)\n\n                    # if parent_folder is not \"None\"\n                    if add_bookmark_folder_as_tag and parent_folder:\n                        bookmark_tags.append(parent_folder)\n\n                    if unique_tag:\n                        bookmark_tags.append(unique_tag)\n\n                    formatted_tags = [DELIM + tag for tag in bookmark_tags]\n                    tags = parse_tags(formatted_tags)\n\n                    LOGDBG(\"ff_json: Entry found: {}, {}, {}, {} \" .format(bm_entry['uri'], entry_title, tags, desc))\n                    yield (bm_entry['uri'], entry_title, tags, desc, 0, True, False)\n\n                except Exception as e:\n                    LOGERR(\"ff_json: Error parsing entry '{}' Exception '{}'\".format(entry_title, e))\n\n            elif TypeCode.folder.value == typeCode:\n\n                # ignore special bookmark folders\n                if 'root' in bm_entry and bm_entry['root'] in IGNORE_FF_BOOKMARK_FOLDERS:\n                    LOGDBG(\"ff_json: ignoring root folder: {}\" .format(entry_title))\n                    entry_title = None\n\n                if \"children\" in bm_entry:\n                    yield from iterate_children(entry_title, bm_entry['children'])\n                else:\n                    # if any of the properties does not exist, bail out silently\n                    LOGDBG(\"ff_json: No 'children' found in bookmark folder - skipping: {}\".format(entry_title))\n\n            elif TypeCode.separator.value == typeCode:\n                # ignore separator\n                pass\n            else:\n                LOGDBG(\"ff_json: Unknown typeCode found : {}\".format(typeCode))\n\n    if \"children\" in json:\n        main_entry_list = json['children']\n    else:\n        LOGDBG(\"ff_json: No children in Root entry found\")\n        return []\n\n    yield from iterate_children(None, main_entry_list)\n\ndef import_xbel(html_soup: BeautifulSoup, add_parent_folder_as_tag: bool, newtag: str, use_nested_folder_structure: bool = False):\n    \"\"\"Parse bookmark XBEL.\n\n    Parameters\n    ----------\n    html_soup : BeautifulSoup object\n        BeautifulSoup representation of bookmark HTML.\n    add_parent_folder_as_tag : bool\n        True if bookmark parent folders should be added as tags else False.\n    newtag : str\n        A new unique tag to add to imported bookmarks.\n    use_nested_folder_structure: bool\n        True if all bookmark parent folder should be added, not just direct parent else False\n        add_parent_folder_as_tag must be True for this flag to have an effect\n\n    Returns\n    -------\n    tuple\n        Parsed result.\n    \"\"\"\n\n    # compatibility\n    soup = html_soup\n\n    for tag in soup.findAll('bookmark'):\n        # Extract comment from <desc> tag\n        try:\n            if is_nongeneric_url(tag['href']):\n                continue\n        except KeyError:\n            continue\n\n        title_tag = tag.title.string\n\n        desc = None\n        comment_tag = tag.findNextSibling('desc')\n\n        if comment_tag:\n            desc = comment_tag.find(text=True, recursive=False)\n\n        if add_parent_folder_as_tag:\n            # add parent folder as tag\n            if use_nested_folder_structure:\n                # New method that would generalize for else case to\n                # structure of folders\n                # folder\n                #   title (folder name)\n                #   folder\n                #       title\n                #           bookmark (could be h3, and continue recursively)\n                parents = tag.find_parents('folder')\n                for parent in parents:\n                    header = parent.find_previous_sibling('title')\n                    if header:\n                        if tag.has_attr('tags'):\n                            tag['tags'] += (DELIM + header.text)\n                        else:\n                            tag['tags'] = header.text\n            else:\n                # could be its folder or not\n                possible_folder = tag.find_previous('title')\n                # get list of tags within that folder\n                tag_list = tag.parent.parent.find_parent('folder')\n\n                if ((possible_folder) and possible_folder.parent in list(tag_list.parents)):\n                    # then it's the folder of this bookmark\n                    if tag.has_attr('tags'):\n                        tag['tags'] += (DELIM + possible_folder.text)\n                    else:\n                        tag['tags'] = possible_folder.text\n\n        # add unique tag if opted\n        if newtag:\n            if tag.has_attr('tags'):\n                tag['tags'] += (DELIM + newtag)\n            else:\n                tag['tags'] = newtag\n\n        yield (\n            tag['href'], title_tag,\n            parse_tags([tag['tags']]) if tag.has_attr('tags') else None,\n            desc if not desc else desc.strip(), 0, True, False\n        )\n\ndef import_html(html_soup: BeautifulSoup, add_parent_folder_as_tag: bool, newtag: str, use_nested_folder_structure: bool = False):\n    \"\"\"Parse bookmark HTML.\n\n    Parameters\n    ----------\n    html_soup : BeautifulSoup object\n        BeautifulSoup representation of bookmark HTML.\n    add_parent_folder_as_tag : bool\n        True if bookmark parent folders should be added as tags else False.\n    newtag : str\n        A new unique tag to add to imported bookmarks.\n    use_nested_folder_structure: bool\n        True if all bookmark parent folder should be added, not just direct parent else False\n        add_parent_folder_as_tag must be True for this flag to have an effect\n\n    Returns\n    -------\n    tuple\n        Parsed result.\n    \"\"\"\n\n    # compatibility\n    soup = html_soup\n\n    for tag in soup.findAll('a'):\n        # Extract comment from <dd> tag\n        try:\n            if is_nongeneric_url(tag['href']):\n                continue\n        except KeyError:\n            continue\n\n        desc = None\n        comment_tag = tag.findNextSibling('dd')\n\n        if comment_tag:\n            desc = comment_tag.find(string=True, recursive=False)\n\n        if add_parent_folder_as_tag:\n            # add parent folder as tag\n            if use_nested_folder_structure:\n                # New method that would generalize for else case to\n                # structure of folders\n                # dt\n                #   h3 (folder name)\n                #   dl\n                #       dt\n                #           a (could be h3, and continue recursively)\n                parents = tag.find_parents('dl')\n                for parent in parents:\n                    header = parent.find_previous_sibling('h3')\n                    if header:\n                        if tag.has_attr('tags'):\n                            tag['tags'] += (DELIM + strip_delim(header.text))\n                        else:\n                            tag['tags'] = strip_delim(header.text)\n            else:\n                # could be its folder or not\n                possible_folder = tag.find_previous('h3')\n                # get list of tags within that folder\n                tag_list = tag.parent.parent.find_parent('dl')\n\n                if ((possible_folder) and possible_folder.parent in list(tag_list.parents)):\n                    # then it's the folder of this bookmark\n                    if tag.has_attr('tags'):\n                        tag['tags'] += (DELIM + strip_delim(possible_folder.text))\n                    else:\n                        tag['tags'] = strip_delim(possible_folder.text)\n\n        # add unique tag if opted\n        if newtag:\n            if tag.has_attr('tags'):\n                tag['tags'] += (DELIM + strip_delim(newtag))\n            else:\n                tag['tags'] = strip_delim(newtag)\n\n        yield (\n            tag['href'], tag.string,\n            parse_tags([tag['tags']]) if tag.has_attr('tags') else None,\n            desc if not desc else desc.strip(), 0, True, False\n        )\n\n\ndef get_netloc(url):\n    \"\"\"Get the netloc token, or None.\"\"\"\n\n    try:\n        netloc = urlparse(url).netloc\n        if not netloc and not urlparse(url).scheme:\n            # Try to prepend '//' and get netloc\n            netloc = urlparse('//' + url).netloc\n        return netloc or None\n    except Exception as e:\n        LOGERR('%s, URL: %s', e, url)\n        return None\n\n\ndef is_bad_url(url):\n    \"\"\"Check if URL is malformed.\n\n    .. Note:: This API is not bulletproof but works in most cases.\n\n    Parameters\n    ----------\n    url : str\n        URL to scan.\n\n    Returns\n    -------\n    bool\n        True if URL is malformed, False otherwise.\n    \"\"\"\n\n    netloc = get_netloc(url)\n    if not netloc:\n        return True\n\n    LOGDBG('netloc: %s', netloc)\n\n    # netloc cannot start or end with a '.'\n    if netloc.startswith('.') or netloc.endswith('.'):\n        return True\n\n    # netloc should have at least one '.'\n    return '.' not in netloc\n\n\ndef is_nongeneric_url(url):\n    \"\"\"Returns True for URLs which are non-http and non-generic.\n\n    Parameters\n    ----------\n    url : str\n        URL to scan.\n\n    Returns\n    -------\n    bool\n        True if URL is a non-generic URL, False otherwise.\n    \"\"\"\n\n    ignored_prefix = [\n        'about:',\n        'apt:',\n        'chrome://',\n        'file://',\n        'place:',\n        'vivaldi://',\n    ]\n\n    for prefix in ignored_prefix:\n        if url.startswith(prefix):\n            return True\n\n    return False\n\n\ndef is_ignored_mime(url):\n    \"\"\"Check if URL links to ignored MIME.\n\n    .. Note:: Only a 'HEAD' request is made for these URLs.\n\n    Parameters\n    ----------\n    url : str\n        URL to scan.\n\n    Returns\n    -------\n    bool\n        True if URL links to ignored MIME, False otherwise.\n    \"\"\"\n\n    for mime in SKIP_MIMES:\n        if url.lower().endswith(mime):\n            LOGDBG('matched MIME: %s', mime)\n            return True\n\n    return False\n\n\ndef is_unusual_tag(tagstr):\n    \"\"\"Identify unusual tags with word to comma ratio > 3.\n\n    Parameters\n    ----------\n    tagstr : str\n        tag string to check.\n\n    Returns\n    -------\n    bool\n        True if valid tag else False.\n    \"\"\"\n\n    if not tagstr:\n        return False\n\n    nwords = len(tagstr.split())\n    ncommas = tagstr.count(',') + 1\n\n    if nwords / ncommas > 3:\n        return True\n\n    return False\n\n\ndef parse_decoded_page(page):\n    \"\"\"Fetch title, description and keywords from decoded HTML page.\n\n    Parameters\n    ----------\n    page : str\n        Decoded HTML page.\n\n    Returns\n    -------\n    tuple\n        (title, description, keywords).\n    \"\"\"\n\n    title = ''\n    desc = ''\n    keys = ''\n\n    soup = BeautifulSoup(page, 'html5lib')\n\n    try:\n        title = soup.find('title').text.strip().replace('\\n', ' ')\n        if title:\n            title = re.sub(r'\\s{2,}', ' ', title)\n    except Exception as e:\n        LOGDBG(e)\n\n    description = (soup.find('meta', attrs={'name':'description'}) or\n                   soup.find('meta', attrs={'name':'Description'}) or\n                   soup.find('meta', attrs={'property':'description'}) or\n                   soup.find('meta', attrs={'property':'Description'}) or\n                   soup.find('meta', attrs={'name':'og:description'}) or\n                   soup.find('meta', attrs={'name':'og:Description'}) or\n                   soup.find('meta', attrs={'property':'og:description'}) or\n                   soup.find('meta', attrs={'property':'og:Description'}))\n    try:\n        if description:\n            desc = description.get('content').strip()\n            if desc:\n                desc = re.sub(r'\\s{2,}', ' ', desc)\n    except Exception as e:\n        LOGDBG(e)\n\n    keywords = (soup.find('meta', attrs={'name':'keywords'}) or\n                soup.find('meta', attrs={'name':'Keywords'}))\n    try:\n        if keywords:\n            keys = keywords.get('content').strip().replace('\\n', ' ')\n            keys = re.sub(r'\\s{2,}', ' ', re.sub(r'\\s*,\\s*', ',', keys))\n            if is_unusual_tag(keys):\n                if keys not in (title, desc):\n                    LOGDBG('keywords to description: %s', keys)\n                    if desc:\n                        desc = desc + '\\n## ' + keys\n                    else:\n                        desc = '* ' + keys\n\n                keys = ''\n    except Exception as e:\n        LOGDBG(e)\n\n    LOGDBG('title: %s', title)\n    LOGDBG('desc : %s', desc)\n    LOGDBG('keys : %s', keys)\n\n    return (title, desc, keys and keys.strip(DELIM))\n\n\ndef get_data_from_page(resp):\n    \"\"\"Detect HTTP response encoding and invoke parser with decoded data.\n\n    Parameters\n    ----------\n    resp : HTTP response\n        Response from GET request.\n\n    Returns\n    -------\n    tuple\n        (title, description, keywords).\n    \"\"\"\n\n    try:\n        charset = EncodingDetector.find_declared_encoding(resp.data, is_html=True)\n\n        if not charset and 'content-type' in resp.headers:\n            m = email.message.Message()\n            m['content-type'] = resp.headers['content-type']\n            if m.get_param('charset') is not None:\n                charset = m.get_param('charset')\n\n        if charset:\n            LOGDBG('charset: %s', charset)\n            title, desc, keywords = parse_decoded_page(resp.data.decode(charset, errors='replace'))\n        else:\n            title, desc, keywords = parse_decoded_page(resp.data.decode(errors='replace'))\n\n        return (title, desc, keywords)\n    except Exception as e:\n        LOGERR(e)\n        return (None, None, None)\n\n\ndef extract_auth(url):\n    \"\"\"Convert an url into an (auth, url) tuple [the returned URL will contain no auth part].\"\"\"\n    _url = urlparse(url)\n    if _url.username is None:  # no '@' in netloc\n        return None, url\n    auth = _url.username + ('' if _url.password is None else f':{_url.password}')\n    return auth, url.replace(auth + '@', '')\n\ndef gen_headers():\n    \"\"\"Generate headers for network connection.\"\"\"\n\n    global MYHEADERS, MYPROXY\n\n    MYHEADERS = {\n        'Accept-Encoding': 'gzip,deflate',\n        'User-Agent': USER_AGENT,\n        'Accept': '*/*',\n        'Cookie': '',\n        'DNT': '1'\n    }\n\n    MYPROXY = os.environ.get('https_proxy')\n    if MYPROXY:\n        try:\n            auth, MYPROXY = extract_auth(MYPROXY)\n        except Exception as e:\n            LOGERR(e)\n            return\n\n        # Strip username and password (if present) and update headers\n        if auth:\n            auth_headers = make_headers(basic_auth=auth)\n            MYHEADERS.update(auth_headers)\n\n        LOGDBG('proxy: [%s]', MYPROXY)\n\n\ndef get_PoolManager():\n    \"\"\"Creates a pool manager with proxy support, if applicable.\n\n    Returns\n    -------\n    ProxyManager or PoolManager\n        ProxyManager if https_proxy is defined, PoolManager otherwise.\n    \"\"\"\n    ca_certs = os.getenv('BUKU_CA_CERTS', default=CA_CERTS)\n    if MYPROXY:\n        return urllib3.ProxyManager(MYPROXY, num_pools=1, headers=MYHEADERS, timeout=15,\n                                    cert_reqs='CERT_REQUIRED', ca_certs=ca_certs)\n\n    return urllib3.PoolManager(\n        num_pools=1,\n        headers=MYHEADERS,\n        timeout=15,\n        cert_reqs='CERT_REQUIRED',\n        ca_certs=ca_certs)\n\n\ndef network_handler(\n        url: str,\n        http_head: bool = False\n) -> Tuple[str, str, str, int, int]:\n    \"\"\"Handle server connection and redirections.\n\n    Deprecated; use fetch_data() instead.\n\n    Returns\n    -------\n    tuple\n        (title, description, tags, recognized mime, bad url)\n    \"\"\"\n    warn('\\'buku.network_handler()\\' is deprecated; use \\'buku.fetch_data()\\' instead.', DeprecationWarning)\n    result = fetch_data(url, http_head)\n    return (result.title, result.desc, result.keywords, int(result.mime), int(result.bad))\n\n\ndef fetch_data(\n        url: str,\n        http_head: bool = False\n) -> FetchResult:\n    \"\"\"Handle server connection and redirections.\n\n    Parameters\n    ----------\n    url : str\n        URL to fetch.\n    http_head : bool\n        If True, send only HTTP HEAD request. Default is False.\n\n    Returns\n    -------\n    FetchResult\n        (url, title, desc, keywords, mime, bad, fetch_status)\n    \"\"\"\n\n    page_status = None\n    page_url = url\n    page_title = ''\n    page_desc = ''\n    page_keys = ''\n    exception = False\n\n    if is_nongeneric_url(url) or is_bad_url(url):\n        return FetchResult(url, bad=True)\n\n    if is_ignored_mime(url) or http_head:\n        method = 'HEAD'\n    else:\n        method = 'GET'\n\n    if not MYHEADERS:\n        gen_headers()\n\n    try:\n        manager = get_PoolManager()\n\n        while True:\n            resp = manager.request(method, url, retries=Retry(redirect=10))\n            page_status = resp.status\n\n            if resp.status == 200:\n                if method == 'GET':\n                    for retry in resp.retries.history:\n                        if retry.status not in PERMANENT_REDIRECTS:\n                            break\n                        page_status, page_url = retry.status, retry.redirect_location\n                    page_title, page_desc, page_keys = get_data_from_page(resp)\n            elif resp.status == 403 and url.endswith('/'):\n                # HTTP response Forbidden\n                # Handle URLs in the form of https://www.domain.com/\n                # which fail when trying to fetch resource '/'\n                # retry without trailing '/'\n\n                LOGDBG('Received status 403: retrying...')\n                # Remove trailing /\n                url = url[:-1]\n                resp.close()\n                continue\n            else:\n                page_title, page_desc, page_keys = get_data_from_page(resp)\n                LOGERR('[%s] %s', resp.status, resp.reason)\n\n            if resp:\n                resp.close()\n\n            break\n    except Exception as e:\n        LOGERR('fetch_data(): %s', e)\n        exception = True\n\n    if manager:\n        manager.clear()\n    if exception:\n        return FetchResult(url)\n    if method == 'HEAD':\n        return FetchResult(url, mime=True, fetch_status=page_status)\n\n    return FetchResult(page_url, title=page_title, desc=page_desc, keywords=page_keys, fetch_status=page_status)\n\n\ndef parse_tags(keywords=[], *, edit_input=False):\n    \"\"\"Format and get tag string from tokens.\n\n    Parameters\n    ----------\n    keywords : list\n        List of tags to parse. Default is empty list.\n    edit_input : bool\n        Whether the taglist is an edit input (i.e. may start with '+'/'-').\n        Defaults to False.\n\n    Returns\n    -------\n    str\n        Comma-delimited string of tags.\n    DELIM : str\n        If no keywords, returns the delimiter.\n    None\n        If keywords is None.\n    \"\"\"\n\n    if keywords is None:\n        return None\n\n    tagstr = ' '.join(s for s in keywords if s)\n    if not tagstr:\n        return DELIM\n\n    if edit_input and keywords[0] in ('+', '-'):\n        return keywords[0] + parse_tags(keywords[1:])\n\n    # Cleanse and get the tags\n    marker = tagstr.find(DELIM)\n    tags = DELIM\n\n    while marker >= 0:\n        token = tagstr[0:marker]\n        tagstr = tagstr[marker + 1:]\n        marker = tagstr.find(DELIM)\n        token = token.strip()\n        if token == '':\n            continue\n\n        tags += token + DELIM\n\n    tagstr = tagstr.strip()\n    if tagstr != '':\n        tags += tagstr + DELIM\n\n    LOGDBG('keywords: %s', keywords)\n    LOGDBG('parsed tags: [%s]', tags)\n\n    if tags == DELIM:\n        return tags\n\n    # sorted unique tags in lowercase, wrapped with delimiter\n    return taglist_str(tags)\n\n\ndef prep_tag_search(tags: str) -> Tuple[List[str], Optional[str], Optional[str]]:\n    \"\"\"Prepare list of tags to search and determine search operator.\n\n    Parameters\n    ----------\n    tags : str\n        String list of tags to search.\n\n    Returns\n    -------\n    tuple\n        (list of formatted tags to search,\n         a string indicating query search operator (either OR or AND),\n         a regex string of tags or None if ' - ' delimiter not in tags).\n    \"\"\"\n\n    exclude_only = False\n\n    # tags may begin with `- ` if only exclusion list is provided\n    if tags.startswith('- '):\n        tags = ' ' + tags\n        exclude_only = True\n\n    # tags may start with `+ ` etc., tricky test case\n    if tags.startswith(('+ ', ', ')):\n        tags = tags[2:]\n\n    # tags may end with ` -` etc., tricky test case\n    if tags.endswith((' -', ' +', ' ,')):\n        tags = tags[:-2]\n\n    # tag exclusion list can be separated by comma (,), so split it first\n    excluded_tags = None\n    if ' - ' in tags:\n        tags, excluded_tags = tags.split(' - ', 1)\n\n        excluded_taglist = [delim_wrap(re.escape(t.strip())) for t in excluded_tags.split(',')]\n        # join with pipe to construct regex string\n        excluded_tags = '|'.join(excluded_taglist)\n\n    if exclude_only:\n        search_operator = 'OR'\n        tags_ = ['']\n    else:\n        # do not allow combination of search logics in tag inclusion list\n        if ' + ' in tags and ',' in tags:\n            return [], None, None\n\n        search_operator = 'OR'\n        tag_delim = ','\n        if ' + ' in tags:\n            search_operator = 'AND'\n            tag_delim = ' + '\n\n        tags_ = [delim_wrap(t.strip()) for t in tags.split(tag_delim)]\n\n    return tags_, search_operator, excluded_tags\n\n\ndef gen_auto_tag():\n    \"\"\"Generate a tag in Year-Month-Date format.\n\n    Returns\n    -------\n    str\n        New tag as YYYYMonDD.\n    \"\"\"\n\n    t = time.localtime()\n    return '%d%s%02d' % (t.tm_year, calendar.month_abbr[t.tm_mon], t.tm_mday)\n\n\ndef edit_at_prompt(obj, nav, suggest=False):\n    \"\"\"Edit and add or update a bookmark.\n\n    Parameters\n    ----------\n    obj : BukuDb instance\n        A valid instance of BukuDb class.\n    nav : str\n        Navigation command argument passed at prompt by user.\n    suggest : bool\n        If True, suggest similar tags on new bookmark addition.\n    \"\"\"\n\n    if nav == 'w':\n        editor = get_system_editor()\n        if not is_editor_valid(editor):\n            return\n    elif is_int(nav[2:]):\n        obj.edit_update_rec(int(nav[2:]))\n        return\n    else:\n        editor = nav[2:]\n\n    result = edit_rec(editor, '', None, DELIM, None)\n    if result is not None:\n        url, title, tags, desc = result\n        if suggest:\n            tags = obj.suggest_similar_tag(tags)\n        obj.add_rec(url, title, tags, desc)\n\n\ndef show_taglist(obj):\n    \"\"\"Additional prompt to show unique tag list.\n\n    Parameters\n    ----------\n    obj : BukuDb instance\n        A valid instance of BukuDb class.\n    \"\"\"\n\n    unique_tags, dic = obj.get_tag_all()\n    if not unique_tags:\n        count = 0\n        print('0 tags')\n    else:\n        count = 1\n        for tag in unique_tags:\n            print('%6d. %s (%d)' % (count, tag, dic[tag]))\n            count += 1\n        print()\n\n\ndef prompt(obj, results, noninteractive=False, deep=False, listtags=False, suggest=False, num=10, markers=False, order=['+id']):\n    \"\"\"Show each matching result from a search and prompt.\n\n    Parameters\n    ----------\n    obj : BukuDb instance\n        A valid instance of BukuDb class.\n    results : list\n        Search result set from a DB query.\n    noninteractive : bool\n        If True, does not seek user input. Shows all results. Default is False.\n    deep : bool\n        Use deep search. Default is False.\n    markers : bool\n        Use search-with-markers. Default is False.\n    listtags : bool\n        If True, list all tags.\n    suggest : bool\n        If True, suggest similar tags on edit and add bookmark.\n    order : list of str\n        Order description (fields from JSON export or DB, prepended with '+'/'-' for ASC/DESC).\n    num : int\n        Number of results to show per page. Default is 10.\n    \"\"\"\n\n    if not isinstance(obj, BukuDb):\n        LOGERR('Not a BukuDb instance')\n        return\n    bdb = obj\n\n    new_results = bool(results)\n    nav = ''\n    cur_index = next_index = count = 0\n\n    if listtags:\n        show_taglist(obj)\n\n    try:\n        columns, _ = os.get_terminal_size()\n    except OSError:\n        columns = 0\n\n    if noninteractive:\n        try:\n            for row in results:\n                count += 1\n                print_single_rec(row, count, columns)\n        except Exception:\n            pass\n        return\n\n    skip_print = False\n    while True:\n        if (new_results or nav == 'n') and not skip_print:\n            count = next_index\n\n            if results:\n                total_results = len(results)\n                cur_index = next_index\n                if cur_index < total_results:\n                    next_index = min(cur_index + num, total_results)\n                    print()\n                    for row in results[cur_index:next_index]:\n                        count += 1\n                        print_single_rec(row, count, columns)\n                    print('%d-%d/%d' % (cur_index + 1, next_index, total_results))\n                else:\n                    print('No more results')\n                    new_results = False\n            else:\n                print('0 results')\n                new_results = False\n        skip_print = False\n\n        try:\n            nav = read_in(PROMPTMSG)\n            if not nav:\n                nav = read_in(PROMPTMSG)\n                if not nav:\n                    # Quit on double enter\n                    break\n            nav = nav.strip()\n        except EOFError:\n            return\n\n        # show the next set of results from previous search\n        if nav == 'n':\n            continue\n\n        if (m := re.match(r'^R(?: (-)?([0-9]+))?$', nav.rstrip())) and (n := int(m[2] or 1)) > 0:\n            skip_print = True\n            if results and not m[1]:  # from search results\n                picked = random.sample(results, min(n, len(results)))\n            else:                     # from all bookmarks\n                ids = range(1, 1 + (bdb.get_max_id() or 0))\n                picked = bdb.get_rec_all_by_ids(random.sample(ids, min(n, len(ids))))\n            for row in bdb._sort(picked, order):\n                print_single_rec(row, columns=columns)\n            continue\n\n        if (m := re.match(r'^\\^ ([1-9][0-9]*) ([1-9][0-9]*)$', nav.rstrip())):\n            index1, index2 = map(int, m.group(1, 2))\n            if bdb.swap_recs(index1, index2):\n                bdb.print_rec({index1, index2})\n            else:\n                print('Failed to swap records #%d and #%d' % (index1, index2))\n            continue\n\n        # search ANY match with new keywords\n        if nav.startswith('s '):\n            keywords = (nav[2:].split() if not markers else split_by_marker(nav[2:]))\n            results = bdb.searchdb(keywords, deep=deep, markers=markers, order=order)\n            new_results = True\n            cur_index = next_index = 0\n            continue\n\n        # search ALL match with new keywords\n        if nav.startswith('S '):\n            keywords = (nav[2:].split() if not markers else split_by_marker(nav[2:]))\n            results = bdb.searchdb(keywords, all_keywords=True, deep=deep, markers=markers, order=order)\n            new_results = True\n            cur_index = next_index = 0\n            continue\n\n        # regular expressions search with new keywords\n        if nav.startswith('r '):\n            keywords = (nav[2:].split() if not markers else split_by_marker(nav[2:]))\n            results = bdb.searchdb(keywords, all_keywords=True, regex=True, markers=markers, order=order)\n            new_results = True\n            cur_index = next_index = 0\n            continue\n\n        # tag search with new keywords\n        if nav.startswith('t '):\n            results = bdb.search_by_tag(nav[2:], order=order)\n            new_results = True\n            cur_index = next_index = 0\n            continue\n\n        # quit with 'q'\n        if nav == 'q':\n            return\n\n        # No new results fetched beyond this point\n        new_results = False\n\n        # toggle deep search with 'd', search-with-markers with 'm'\n        if nav == 'd':\n            deep = not deep\n            print('deep search', ('on' if deep else 'off'))\n            continue\n        if nav == 'm':\n            markers = not markers\n            print('search-with-markers', ('on' if markers else 'off'))\n            continue\n\n        if nav.startswith('v '):  # letters 's' and 'o' are taken already\n            _fields = {'metadata': 'title', **JSON_FIELDS}\n            _order = bdb._ordering(filter(None, re.split(r'[,\\s]+', nav[2:].strip())))\n            order = [('+' if asc else '-') + _fields.get(s, s) for s, asc in _order]\n            print('order', ', '.join(order))\n            continue\n\n        # Toggle GUI browser with 'O'\n        if nav == 'O':\n            browse.override_text_browser = not browse.override_text_browser\n            print('text browser override toggled')\n            continue\n\n        # Show help with '?'\n        if nav == '?':\n            ExtendedArgumentParser.prompt_help(sys.stdout)\n            continue\n\n        # Edit and add or update\n        if nav == 'w' or nav.startswith('w '):\n            edit_at_prompt(bdb, nav, suggest)\n            continue\n\n        # Append or overwrite tags\n        if nav.startswith('g '):\n            unique_tags, dic = obj.get_tag_all()\n            _count = bdb.set_tag(nav[2:], unique_tags)\n            if _count == -1:\n                print('Invalid input')\n            elif _count == -2:\n                try:\n                    tagid_list = nav[2:].split()\n                    tagstr = bdb.get_tagstr_from_taglist(tagid_list, unique_tags)\n                    tagstr = tagstr.strip(DELIM)\n                    results = bdb.search_by_tag(tagstr)\n                    new_results = True\n                    cur_index = next_index = 0\n                except Exception:\n                    print('Invalid input')\n            else:\n                print('%d updated' % _count)\n            continue\n\n        # Print bookmarks by DB index\n        if nav.startswith('p '):\n            try:\n                ids = parse_range(nav[2:].split(), maxidx=bdb.get_max_id() or 0)\n                ids and bdb.print_rec(ids, order=order)\n            except ValueError:\n                print('Invalid input')\n            continue\n\n        # Browse bookmarks by DB index\n        if nav.startswith('o '):\n            id_list = nav[2:].split()\n            try:\n                for id in id_list:\n                    if is_int(id):\n                        bdb.browse_by_index(int(id))\n                    elif '-' in id:\n                        vals = [int(x) for x in id.split('-')]\n                        bdb.browse_by_index(0, vals[0], vals[-1], True)\n                    else:\n                        print('Invalid input')\n            except ValueError:\n                print('Invalid input')\n            continue\n\n        # Copy URL to clipboard\n        if nav.startswith('c ') and nav[2:].isdigit():\n            index = int(nav[2:]) - 1\n            if index < 0 or index >= count:\n                print('No matching index')\n                continue\n            copy_to_clipboard(content=results[index + cur_index][1].encode('utf-8'))\n            continue\n\n        # open all results and re-prompt with 'a'\n        if nav == 'a':\n            for index in range(cur_index, next_index):\n                browse(results[index][1])\n            continue\n\n        # list tags with 't'\n        if nav == 't':\n            show_taglist(bdb)\n            continue\n\n        toggled = False\n        # Open in GUI browser\n        if nav.startswith('O '):\n            if not browse.override_text_browser:\n                browse.override_text_browser = True\n                toggled = True\n            nav = nav[2:]\n\n        # iterate over white-space separated indices\n        for nav in nav.split():\n            if is_int(nav):\n                index = int(nav) - 1\n                if index < 0 or index >= count:\n                    print('No matching index %s' % nav)\n                    continue\n                browse(results[index][1])\n            elif '-' in nav:\n                try:\n                    vals = [int(x) for x in nav.split('-')]\n                    if vals[0] > vals[-1]:\n                        vals[0], vals[-1] = vals[-1], vals[0]\n\n                    for _id in range(vals[0]-1, vals[-1]):\n                        if 0 <= _id < count:\n                            browse(results[_id][1])\n                        else:\n                            print('No matching index %d' % (_id + 1))\n                except ValueError:\n                    print('Invalid input')\n                    break\n            else:\n                print('Invalid input')\n                break\n\n        if toggled:\n            browse.override_text_browser = False\n\n\ndef copy_to_clipboard(content):\n    \"\"\"Copy content to clipboard\n\n    Parameters\n    ----------\n    content : str\n        Content to be copied to clipboard\n    \"\"\"\n\n    # try copying the url to clipboard using native utilities\n    copier_params = []\n    if sys.platform.startswith(('linux', 'freebsd', 'openbsd')):\n        if shutil.which('xsel') is not None:\n            copier_params = ['xsel', '-b', '-i']\n        elif shutil.which('xclip') is not None:\n            copier_params = ['xclip', '-selection', 'clipboard']\n        elif shutil.which('wl-copy') is not None:\n            copier_params = ['wl-copy']\n        # If we're using Termux (Android) use its 'termux-api'\n        # add-on to set device clipboard.\n        elif shutil.which('termux-clipboard-set') is not None:\n            copier_params = ['termux-clipboard-set']\n    elif sys.platform == 'darwin':\n        copier_params = ['pbcopy']\n    elif sys.platform == 'win32':\n        copier_params = ['clip']\n\n    if copier_params:\n        Popen(copier_params, stdin=PIPE, stdout=DEVNULL, stderr=DEVNULL).communicate(content)\n        return\n\n    # If native clipboard utilities are absent, try to use terminal multiplexers\n    # tmux\n    if os.getenv('TMUX_PANE'):\n        copier_params = ['tmux', 'set-buffer']\n        Popen(\n            copier_params + [content],\n            stdin=DEVNULL,\n            stdout=DEVNULL,\n            stderr=DEVNULL\n        ).communicate()\n        print('URL copied to tmux buffer.')\n        return\n\n    # GNU Screen paste buffer\n    if os.getenv('STY'):\n        copier_params = ['screen', '-X', 'readbuf', '-e', 'utf8']\n        tmpfd, tmppath = tempfile.mkstemp()\n        try:\n            with os.fdopen(tmpfd, 'wb') as fp:\n                fp.write(content)\n            copier_params.append(tmppath)\n            Popen(copier_params, stdin=DEVNULL, stdout=DEVNULL, stderr=DEVNULL).communicate()\n        finally:\n            os.unlink(tmppath)\n        return\n\n    print('Failed to locate suitable clipboard utility')\n    return\n\n\ndef print_rec_with_filter(records, field_filter=0):\n    \"\"\"Print records filtered by field.\n\n    User determines which fields in the records to display\n    by using the --format option.\n\n    Parameters\n    ----------\n    records : list or sqlite3.Cursor object\n        List of bookmark records to print\n    field_filter : int\n        Integer indicating which fields to print. Default is 0 (\"all fields\").\n    \"\"\"\n\n    try:\n        records = bookmark_vars(records)\n        fields = FIELD_FILTER.get(field_filter)\n        if fields:\n            pattern = '\\t'.join('%s' for k in fields)\n            for row in records:\n                print(pattern % tuple(getattr(row, k) for k in fields))\n        else:\n            try:\n                columns, _ = os.get_terminal_size()\n            except OSError:\n                columns = 0\n            for row in records:\n                print_single_rec(row, columns=columns)\n    except BrokenPipeError:\n        sys.stdout = os.fdopen(1)\n        sys.exit(1)\n\n\ndef print_single_rec(row: BookmarkVar, idx: int=0, columns: int=0):  # NOQA\n    \"\"\"Print a single DB record.\n\n    Handles both search results and individual record.\n\n    Parameters\n    ----------\n    row : tuple\n        Tuple representing bookmark record data.\n    idx : int\n        Search result index. If 0, print with DB index.\n        Default is 0.\n    columns : int\n        Number of columns to wrap comments to.\n        Default is 0.\n    \"\"\"\n\n    str_list = []\n    row = BookmarkVar(*row)  # ensuring named tuple\n\n    # Start with index and title\n    if idx != 0:\n        id_title_res = ID_STR % (idx, row.title or 'Untitled', row.id)\n    else:\n        id_title_res = ID_DB_STR % (row.id, row.title or 'Untitled')\n        # Indicate if record is immutable\n        if row.immutable:\n            id_title_res = MUTE_STR % (id_title_res,)\n        else:\n            id_title_res += '\\n'\n\n    try:\n        print(id_title_res, end='')\n        print(URL_STR % (row.url,), end='')\n        if columns == 0:\n            if row.desc:\n                print(DESC_STR % (row.desc,), end='')\n            if row.tags:\n                print(TAG_STR % (row.tags,), end='')\n            print()\n            return\n\n        INDENT = 5\n        ln_num = 1\n        fillwidth = columns - INDENT\n\n        for line in textwrap.wrap(row.desc.replace('\\n', ''), width=fillwidth):\n            if ln_num == 1:\n                print(DESC_STR % line, end='')\n                ln_num += 1\n            else:\n                print(DESC_WRAP % (' ' * INDENT, line))\n\n        ln_num = 1\n        for line in textwrap.wrap(row.tags.replace('\\n', ''), width=fillwidth):\n            if ln_num == 1:\n                print(TAG_STR % line, end='')\n                ln_num += 1\n            else:\n                print(TAG_WRAP % (' ' * INDENT, line))\n        print()\n    except UnicodeEncodeError:\n        str_list = []\n        str_list.append(id_title_res)\n        str_list.append(URL_STR % (row.url,))\n        if row.desc:\n            str_list.append(DESC_STR % (row.desc,))\n        if row.tags:\n            str_list.append(TAG_STR % (row.tags,))\n        sys.stdout.buffer.write((''.join(str_list) + '\\n').encode('utf-8'))\n    except BrokenPipeError:\n        sys.stdout = os.fdopen(1)\n        sys.exit(1)\n\n\ndef write_string_to_file(content: str, filepath: str):\n    \"\"\"Writes given content to file\n\n    Parameters\n    ----------\n    content : str\n    filepath : str\n\n    Returns\n    -------\n    None\n    \"\"\"\n    try:\n        with open(filepath, 'w', encoding='utf-8') as f:\n            f.write(content)\n    except Exception as e:\n        LOGERR(e)\n\n\ndef format_json(resultset, single_record=False, field_filter=0):\n    \"\"\"Return results in JSON format.\n\n    Parameters\n    ----------\n    resultset : list\n        Search results from DB query.\n    single_record : bool\n        If True, indicates only one record. Default is False.\n    field_filter : int\n        Indicates format for displaying bookmarks. Default is 0 (\"all fields\").\n\n    Returns\n    -------\n    json\n        Record(s) in JSON format.\n    \"\"\"\n\n    resultset = bookmark_vars(resultset)\n    fields = [(k, JSON_FIELDS.get(k, k)) for k in FIELD_FILTER.get(field_filter, ALL_FIELDS)]\n    marks = [{field: getattr(row, k) for k, field in fields} for row in resultset]\n    if single_record:\n        marks = marks[-1] if marks else {}\n\n    return json.dumps(marks, sort_keys=True, indent=4)\n\n\ndef print_json_safe(resultset, single_record=False, field_filter=0):\n    \"\"\"Prints json results and handles IOError\n\n    Parameters\n    ----------\n    resultset : list\n        Search results from DB query.\n    single_record : bool\n        If True, indicates only one record. Default is False.\n    field_filter : int\n        Indicates format for displaying bookmarks. Default is 0 (\"all fields\").\n\n    Returns\n    -------\n    None\n    \"\"\"\n\n    try:\n        print(format_json(resultset, single_record, field_filter))\n    except IOError:\n        try:\n            sys.stdout.close()\n        except IOError:\n            pass\n        try:\n            sys.stderr.close()\n        except IOError:\n            pass\n\n\ndef is_int(string):\n    \"\"\"Check if a string is a digit.\n\n    string : str\n        Input string to check.\n\n    Returns\n    -------\n    bool\n        True on success, False on exception.\n    \"\"\"\n\n    try:\n        int(string)\n        return True\n    except Exception:\n        return False\n\n\ndef browse(url):\n    \"\"\"Duplicate stdin, stdout and open URL in default browser.\n\n    .. Note:: Duplicates stdin and stdout in order to\n              suppress showing errors on the terminal.\n\n    Parameters\n    ----------\n    url : str\n        URL to open in browser.\n\n    Attributes\n    ----------\n    suppress_browser_output : bool\n        True if a text based browser is detected.\n        Must be initialized (as applicable) to use the API.\n    override_text_browser : bool\n        If True, tries to open links in a GUI based browser.\n    \"\"\"\n\n    if not urlparse(url).scheme:\n        # Prefix with 'http://' if no scheme\n        # Otherwise, opening in browser fails anyway\n        # We expect http to https redirection\n        # will happen for https-only websites\n        LOGERR('Scheme missing in URI, trying http')\n        url = 'http://' + url\n\n    browser = webbrowser.get()\n    if browse.override_text_browser:\n        browser_output = browse.suppress_browser_output\n        for name in [b for b in webbrowser._tryorder if b not in TEXT_BROWSERS]:\n            browser = webbrowser.get(name)\n            LOGDBG(browser)\n\n            # Found a GUI browser, suppress browser output\n            browse.suppress_browser_output = True\n            break\n    if sys.platform == 'win32':  # GUI apps have no terminal IO on Windows\n        browse.suppress_browser_output = False\n\n    if browse.suppress_browser_output:\n        _stderr = os.dup(2)\n        os.close(2)\n        _stdout = os.dup(1)\n        if \"microsoft\" not in platform.uname()[3].lower():\n            os.close(1)\n        fd = os.open(os.devnull, os.O_RDWR)\n        os.dup2(fd, 2)\n        os.dup2(fd, 1)\n    try:\n        if sys.platform != 'win32':\n            browser.open(url, new=2)\n        else:\n            # On Windows, the webbrowser module does not fork.\n            # Use threads instead.\n            def browserthread():\n                webbrowser.open(url, new=2)\n\n            t = threading.Thread(target=browserthread)\n            t.start()\n    except Exception as e:\n        LOGERR('browse(): %s', e)\n    finally:\n        if browse.suppress_browser_output:\n            os.close(fd)\n            os.dup2(_stderr, 2)\n            os.dup2(_stdout, 1)\n\n    if browse.override_text_browser:\n        browse.suppress_browser_output = browser_output\n\n\ndef check_upstream_release():\n    \"\"\"Check and report the latest upstream release version.\"\"\"\n\n    global MYPROXY\n\n    if MYPROXY is None:\n        gen_headers()\n\n    ca_certs = os.getenv('BUKU_CA_CERTS', default=CA_CERTS)\n    if MYPROXY:\n        manager = urllib3.ProxyManager(\n            MYPROXY,\n            num_pools=1,\n            headers=MYHEADERS,\n            cert_reqs='CERT_REQUIRED',\n            ca_certs=ca_certs\n        )\n    else:\n        manager = urllib3.PoolManager(num_pools=1,\n                                      headers={'User-Agent': USER_AGENT},\n                                      cert_reqs='CERT_REQUIRED',\n                                      ca_certs=ca_certs)\n\n    try:\n        r = manager.request(\n            'GET',\n            'https://api.github.com/repos/jarun/buku/releases?per_page=1',\n            headers={'User-Agent': USER_AGENT}\n        )\n    except Exception as e:\n        LOGERR(e)\n        return\n\n    if r.status == 200:\n        latest = json.loads(r.data.decode(errors='replace'))[0]['tag_name']\n        if latest == 'v' + __version__:\n            print('This is the latest release')\n        else:\n            print('Latest upstream release is %s' % latest)\n    else:\n        LOGERR('[%s] %s', r.status, r.reason)\n\n    manager.clear()\n\n\ndef regexp(expr, item):\n    \"\"\"Perform a regular expression search.\n\n    Parameters\n    ----------\n    expr : regex\n        Regular expression to search for.\n    item : str\n        Item on which to perform regex search.\n\n    Returns\n    -------\n    bool\n        True if result of search is not None, else False.\n    \"\"\"\n\n    if expr is None or item is None:\n        LOGDBG('expr: [%s], item: [%s]', expr, item)\n        return False\n\n    return re.search(expr, item, re.IGNORECASE) is not None\n\n\ndef delim_wrap(token):\n    \"\"\"Returns token string wrapped in delimiters.\n\n    Parameters\n    ----------\n    token : str\n        String item to wrap with DELIM.\n\n    Returns\n    -------\n    str\n        Token string wrapped by DELIM.\n    \"\"\"\n\n    if token is None or token.strip() == '':\n        return DELIM\n\n    if token[0] != DELIM:\n        token = DELIM + token\n\n    if token[-1] != DELIM:\n        token = token + DELIM\n\n    return token\n\n\ndef read_in(msg):\n    \"\"\"A wrapper to handle input() with interrupts disabled.\n\n    Parameters\n    ----------\n    msg : str\n        String to pass to to input().\n    \"\"\"\n\n    disable_sigint_handler()\n    message = None\n    try:\n        message = input(msg)\n    except KeyboardInterrupt:\n        print('Interrupted.')\n\n    enable_sigint_handler()\n    return message\n\n\ndef sigint_handler(signum, frame):\n    \"\"\"Custom SIGINT handler.\n\n    .. Note:: Neither signum nor frame are used in\n              this custom handler. However, they are\n              required parameters for signal handlers.\n\n    Parameters\n    ----------\n    signum : int\n        Signal number.\n    frame : frame object or None.\n    \"\"\"\n\n    global INTERRUPTED\n\n    INTERRUPTED = True\n    print('\\nInterrupted.', file=sys.stderr)\n\n    # Do a hard exit from here\n    os._exit(1)\n\nDEFAULT_HANDLER = signal.signal(signal.SIGINT, sigint_handler)\n\n\ndef disable_sigint_handler():\n    \"\"\"Disable signint handler.\"\"\"\n    signal.signal(signal.SIGINT, DEFAULT_HANDLER)\n\n\ndef enable_sigint_handler():\n    \"\"\"Enable sigint handler.\"\"\"\n    signal.signal(signal.SIGINT, sigint_handler)\n\n# ---------------------\n# Editor mode functions\n# ---------------------\n\n\ndef get_system_editor():\n    \"\"\"Returns default system editor is $EDITOR is set.\"\"\"\n\n    return os.environ.get('EDITOR', 'none')\n\n\ndef is_editor_valid(editor):\n    \"\"\"Check if the editor string is valid.\n\n    Parameters\n    ----------\n    editor : str\n        Editor string.\n\n    Returns\n    -------\n    bool\n        True if string is valid, else False.\n    \"\"\"\n\n    if editor == 'none':\n        LOGERR('EDITOR is not set')\n        return False\n\n    if editor == '0':\n        LOGERR('Cannot edit index 0')\n        return False\n\n    return True\n\n\ndef to_temp_file_content(url, title_in, tags_in, desc):\n    \"\"\"Generate temporary file content string.\n\n    Parameters\n    ----------\n    url : str\n        URL to open.\n    title_in : str\n        Title to add manually.\n    tags_in : str\n        Comma-separated tags to add manually.\n    desc : str\n        String description.\n\n    Returns\n    -------\n    str\n        Lines as newline separated string.\n\n    Raises\n    ------\n    AttributeError\n        when tags_in is None.\n    \"\"\"\n\n    strings = [('# Lines beginning with \"#\" will be stripped.\\n'\n                '# Add URL in next line (single line).'), ]\n\n    # URL\n    if url is not None:\n        strings += (url,)\n\n    # TITLE\n    strings += (('# Add TITLE in next line (single line). '\n                 'Leave blank to web fetch, \"-\" for no title.'),)\n    if title_in is None:\n        title_in = ''\n    elif title_in == '':\n        title_in = '-'\n    strings += (title_in,)\n\n    # TAGS\n    strings += ('# Add comma-separated TAGS in next line (single line).',)\n    strings += (tags_in.strip(DELIM),) if not None else ''\n\n    # DESC\n    strings += ('# Add COMMENTS in next line(s). Leave blank to web fetch, \"-\" for no comments.',)\n    if desc is None:\n        strings += ('\\n',)\n    elif desc == '':\n        strings += ('-',)\n    else:\n        strings += (desc,)\n    return '\\n'.join(strings)\n\n\ndef parse_temp_file_content(content):\n    \"\"\"Parse and return temporary file content.\n\n    Parameters\n    ----------\n    content : str\n        String of content.\n\n    Returns\n    -------\n    tuple\n        (url, title, tags, comments)\n\n        url: URL to open\n        title: string title to add manually\n        tags: string of comma-separated tags to add manually\n        comments: string description\n    \"\"\"\n\n    content = content.split('\\n')\n    content = [c for c in content if not c or c[0] != '#']\n    if not content or content[0].strip() == '':\n        print('Edit aborted')\n        return None\n\n    url = content[0]\n    title = None\n    if len(content) > 1:\n        title = content[1]\n\n    if title == '':\n        title = None\n    elif title == '-':\n        title = ''\n\n    tags = DELIM\n    if len(content) > 2:\n        tags = parse_tags([content[2]])\n\n    comments = []\n    if len(content) > 3:\n        comments = list(content[3:])\n        # need to remove all empty line that are at the end\n        # and not those in the middle of the text\n        for i in range(len(comments) - 1, -1, -1):\n            if comments[i].strip() != '':\n                break\n\n        if i == -1:\n            comments = []\n        else:\n            comments = comments[0:i+1]\n\n    comments = '\\n'.join(comments)\n    if comments == '':\n        comments = None\n    elif comments == '-':\n        comments = ''\n\n    return url, title, tags, comments\n\n\ndef edit_rec(editor, url, title_in, tags_in, desc):\n    \"\"\"Edit a bookmark record.\n\n    Parameters\n    ----------\n    editor : str\n        Editor to open.\n    URL : str\n        URL to open.\n    title_in : str\n        Title to add manually.\n    tags_in : str\n        Comma-separated tags to add manually.\n    desc : str\n        Bookmark description.\n\n    Returns\n    -------\n    tuple\n        Parsed results from parse_temp_file_content().\n    \"\"\"\n\n    temp_file_content = to_temp_file_content(url, title_in, tags_in, desc)\n\n    fd, tmpfile = tempfile.mkstemp(prefix='buku-edit-')\n    os.close(fd)\n\n    try:\n        with open(tmpfile, 'w+', encoding='utf-8') as fp:\n            fp.write(temp_file_content)\n            fp.flush()\n            LOGDBG('Edited content written to %s', tmpfile)\n\n        cmd = editor.split(' ')\n        cmd += (tmpfile,)\n        subprocess.call(cmd)\n\n        with open(tmpfile, 'r', encoding='utf-8') as f:\n            content = f.read()\n\n        os.remove(tmpfile)\n    except FileNotFoundError:\n        if os.path.exists(tmpfile):\n            os.remove(tmpfile)\n            LOGERR('Cannot open editor')\n        else:\n            LOGERR('Cannot open tempfile')\n        return None\n\n    parsed_content = parse_temp_file_content(content)\n    return parsed_content\n\n\ndef setup_logger(LOGGER):\n    \"\"\"Setup logger with color.\n\n    Parameters\n    ----------\n    LOGGER : logger object\n        Logger to colorize.\n    \"\"\"\n\n    def decorate_emit(fn):\n        def new(*args):\n            levelno = args[0].levelno\n\n            if levelno == logging.DEBUG:\n                color = '\\x1b[35m'\n            elif levelno == logging.ERROR:\n                color = '\\x1b[31m'\n            elif levelno == logging.WARNING:\n                color = '\\x1b[33m'\n            elif levelno == logging.INFO:\n                color = '\\x1b[32m'\n            elif levelno == logging.CRITICAL:\n                color = '\\x1b[31m'\n            else:\n                color = '\\x1b[0m'\n\n            args[0].msg = '{}[{}]\\x1b[0m {}'.format(color, args[0].levelname, args[0].msg)\n            return fn(*args)\n        return new\n\n    sh = logging.StreamHandler()\n    sh.emit = decorate_emit(sh.emit)\n    LOGGER.addHandler(sh)\n\n\ndef piped_input(argv, pipeargs=None):\n    \"\"\"Handle piped input.\n\n    Parameters\n    ----------\n    pipeargs : str\n    \"\"\"\n    if not sys.stdin.isatty():\n        pipeargs += argv\n        print('buku: waiting for input (unexpected? try --nostdin)')\n        for s in sys.stdin:\n            pipeargs += s.split()\n\n\ndef setcolors(args):\n    \"\"\"Get colors from user and separate into 'result' list for use in arg.colors.\n\n    Parameters\n    ----------\n    args : str\n        Color string.\n    \"\"\"\n    Colors = collections.namedtuple('Colors', ' ID_srch, ID_STR, URL_STR, DESC_STR, TAG_STR')\n    colors = Colors(*[COLORMAP[c] for c in args])\n    id_col = colors.ID_srch\n    id_str_col = colors.ID_STR\n    url_col = colors.URL_STR\n    desc_col = colors.DESC_STR\n    tag_col = colors.TAG_STR\n    result = [id_col, id_str_col, url_col, desc_col, tag_col]\n    return result\n\n\ndef unwrap(text):\n    \"\"\"Unwrap text.\"\"\"\n    lines = text.split('\\n')\n    result = ''\n    for i in range(len(lines) - 1):\n        result += lines[i]\n        if not lines[i]:\n            # Paragraph break\n            result += '\\n\\n'\n        elif lines[i + 1]:\n            # Next line is not paragraph break, add space\n            result += ' '\n    # Handle last line\n    result += lines[-1] if lines[-1] else '\\n'\n    return result\n\n\ndef check_stdout_encoding():\n    \"\"\"Make sure stdout encoding is utf-8.\n\n    If not, print error message and instructions, then exit with\n    status 1.\n\n    This function is a no-op on win32 because encoding on win32 is\n    messy, and let's just hope for the best. /s\n    \"\"\"\n    if sys.platform == 'win32':\n        return\n\n    # Use codecs.lookup to resolve text encoding alias\n    encoding = codecs.lookup(sys.stdout.encoding).name\n    if encoding != 'utf-8':\n        locale_lang, locale_encoding = locale.getlocale()\n        if locale_lang is None:\n            locale_lang = '<unknown>'\n        if locale_encoding is None:\n            locale_encoding = '<unknown>'\n        ioencoding = os.getenv('PYTHONIOENCODING', 'not set')\n        sys.stderr.write(unwrap(textwrap.dedent(\"\"\"\\\n        stdout encoding '{encoding}' detected. ddgr requires utf-8 to\n        work properly. The wrong encoding may be due to a non-UTF-8\n        locale or an improper PYTHONIOENCODING. (For the record, your\n        locale language is {locale_lang} and locale encoding is\n        {locale_encoding}; your PYTHONIOENCODING is {ioencoding}.)\n\n        Please set a UTF-8 locale (e.g., en_US.UTF-8) or set\n        PYTHONIOENCODING to utf-8.\n        \"\"\".format(\n            encoding=encoding,\n            locale_lang=locale_lang,\n            locale_encoding=locale_encoding,\n            ioencoding=ioencoding,\n        ))))\n        sys.exit(1)\n\n\ndef monkeypatch_textwrap_for_cjk():\n    \"\"\"Monkeypatch textwrap for CJK wide characters.\n    \"\"\"\n    try:\n        if textwrap.wrap.patched:\n            return\n    except AttributeError:\n        pass\n    psl_textwrap_wrap = textwrap.wrap\n\n    def textwrap_wrap(text, width=70, **kwargs):\n        width = max(width, 2)\n        # We first add a U+0000 after each East Asian Fullwidth or East\n        # Asian Wide character, then fill to width - 1 (so that if a NUL\n        # character ends up on a new line, we still have one last column\n        # to spare for the preceding wide character). Finally we strip\n        # all the NUL characters.\n        #\n        # East Asian Width: https://www.unicode.org/reports/tr11/\n        return [\n            line.replace('\\0', '')\n            for line in psl_textwrap_wrap(\n                ''.join(\n                    ch + '\\0' if unicodedata.east_asian_width(ch) in ('F', 'W') else ch\n                    for ch in unicodedata.normalize('NFC', text)\n                ),\n                width=width - 1,\n                **kwargs\n            )\n        ]\n\n    def textwrap_fill(text, width=70, **kwargs):\n        return '\\n'.join(textwrap_wrap(text, width=width, **kwargs))\n    textwrap.wrap = textwrap_wrap\n    textwrap.fill = textwrap_fill\n    textwrap.wrap.patched = True\n    textwrap.fill.patched = True\n\n\ndef parse_range(tokens: Optional[str | Sequence[str] | Set[str]],  # Optional[str | Values[str]]\n                valid: Optional[Callable[[int], bool]] = None,\n                maxidx: int = None) -> Optional[Set[int]]:\n    \"\"\"Convert a token or sequence/set of token into a set of indices.\n\n    Raises a ValueError on invalid token. Returns None if passed None as tokens.\n\n    Parameters\n    ----------\n    tokens : str | str[] | str{}, optional\n        String(s) containing an index (#), or a range (#-#), or a comma-separated list thereof.\n    valid : (int) -> bool, optional\n        Additional check for invalid indices (default is None).\n    maxidx : int, optional\n        When specified, negative indices are valid and parsed as tail-ranges.\n\n    Returns\n    -------\n    Optional[Set[int]]\n        None if tokens is None, otherwise parsed indices as unordered set.\n    \"\"\"\n    if tokens is None:\n        return None\n    result = set()\n    for token in ([tokens] if isinstance(tokens, str) else tokens):\n        for idx in token.split(','):\n            if is_int(idx):\n                result |= ({int(idx)} if not idx.startswith('-') or maxidx is None else\n                           set(range(maxidx, max(0, maxidx + int(idx)), -1)))\n            elif '-' in idx:\n                l, r = map(int, idx.split('-'))\n                if l > r:\n                    l, r = r, l\n                if maxidx is not None:\n                    r = min(r, maxidx)\n                result |= set(range(l, r + 1))\n            elif idx:\n                raise ValueError(f'Invalid token: {idx}')\n    if valid and any(not valid(idx) for idx in result):\n        raise ValueError('Not a valid range')\n    return result\n\n\n# main starts here\ndef main(argv=sys.argv[1:], *, program_name=os.path.basename(sys.argv[0])):\n    \"\"\"Main.\"\"\"\n    global ID_STR, ID_DB_STR, MUTE_STR, URL_STR, DESC_STR, DESC_WRAP, TAG_STR, TAG_WRAP, PROMPTMSG\n    # readline should not be loaded when buku is used as a library\n    import readline\n    if sys.platform == 'win32':\n        try:\n            import colorama\n            colorama.just_fix_windows_console()  # noop on non-Windows systems\n        except ImportError:\n            pass\n\n    title_in = None\n    tags_in = None\n    desc_in = None\n    pipeargs = []\n    colorstr_env = os.getenv('BUKU_COLORS')\n\n    if argv and argv[0] != '--nostdin':\n        try:\n            piped_input(argv, pipeargs)\n        except KeyboardInterrupt:\n            pass\n\n        # If piped input, set argument vector\n        if pipeargs:\n            argv = pipeargs\n\n    # Setup custom argument parser\n    argparser = ExtendedArgumentParser(\n        prog=program_name,\n        description='''Bookmark manager like a text-based mini-web.\n\nPOSITIONAL ARGUMENTS:\n      KEYWORD              search keywords''',\n        formatter_class=argparse.RawTextHelpFormatter,\n        usage='''buku [OPTIONS] [KEYWORD [KEYWORD ...]]''',\n        add_help=False)\n    hide = argparse.SUPPRESS\n\n    argparser.add_argument('keywords', nargs='*', metavar='KEYWORD', help=hide)\n\n    # ---------------------\n    # GENERAL OPTIONS GROUP\n    # ---------------------\n\n    general_grp = argparser.add_argument_group(\n        title='GENERAL OPTIONS',\n        description='''    -a, --add URL [+|-] [tag, ...]\n                         bookmark URL with comma-separated tags\n                         (prepend tags with '+' or '-' to use fetched tags)\n    -u, --update [...]   update fields of an existing bookmark\n                         accepts indices and ranges\n                         refresh title and desc if no edit options\n                         if no arguments:\n                         - update results when used with search\n                         - otherwise refresh all titles and desc\n    -w, --write [editor|index]\n                         edit and add a new bookmark in editor\n                         else, edit bookmark at index in EDITOR\n                         edit last bookmark, if index=-1\n                         if no args, edit new bookmark in EDITOR\n    -d, --delete [...]   remove bookmarks from DB\n                         accepts indices or a single range\n                         if no arguments:\n                         - delete results when used with search\n                         - otherwise delete all bookmarks\n    -h, --help           show this information and exit\n    -v, --version        show the program version and exit''')\n    addarg = general_grp.add_argument\n    addarg('-a', '--add', nargs='+', help=hide)\n    addarg('-u', '--update', nargs='*', help=hide)\n    addarg('-w', '--write', nargs='?', const=get_system_editor(), help=hide)\n    addarg('-d', '--delete', nargs='*', help=hide)\n    addarg('-h', '--help', action='store_true', help=hide)\n    addarg('-v', '--version', action='version', version=__version__, help=hide)\n\n    # ------------------\n    # EDIT OPTIONS GROUP\n    # ------------------\n\n    edit_grp = argparser.add_argument_group(\n        title='EDIT OPTIONS',\n        description='''    --url keyword        bookmark link\n    --tag [+|-] [...]    comma-separated tags\n                         clear bookmark tagset, if no arguments\n                         '+' appends to, '-' removes from tagset\n    --title [...]        bookmark title; if no arguments:\n                         -a: do not set title, -u: clear title\n    -c, --comment [...]  notes or description of the bookmark\n                         clears description, if no arguments\n    --immutable N        disable web-fetch during auto-refresh\n                         N=0: mutable (default), N=1: immutable\n    --swap N M           swap two records at specified indices''')\n    addarg = edit_grp.add_argument\n    addarg('--url', nargs=1, help=hide)\n    addarg('--tag', nargs='*', help=hide)\n    addarg('--title', nargs='*', help=hide)\n    addarg('-c', '--comment', nargs='*', help=hide)\n    addarg('--immutable', type=int, choices={0, 1}, help=hide)\n    addarg('--swap', nargs=2, type=int, help=hide)\n    _bool = lambda x: x if x is None else bool(x)\n    _immutable = lambda args: _bool(args.immutable)\n\n    # --------------------\n    # SEARCH OPTIONS GROUP\n    # --------------------\n\n    search_grp = argparser.add_argument_group(\n        title='SEARCH OPTIONS',\n        description='''    -s, --sany [...]     find records with ANY matching keyword\n                         this is the default search option\n    -S, --sall [...]     find records matching ALL the keywords\n                         special keywords -\n                         \"blank\": entries with empty title/tag\n                         \"immutable\": entries with locked title\n    --deep               match substrings ('pen' matches 'opens')\n    --markers            search for keywords in specific fields\n                         based on (optional) prefix markers:\n                         '.' - title, '>' - description, ':' - URL,\n                         '#' - tags (comma-separated, PARTIAL matches)\n                         '#,' - tags (comma-separated, EXACT matches)\n                         '*' - any field (same as no prefix)\n    -r, --sreg expr      run a regex search\n    -t, --stag [tag [,|+] ...] [- tag, ...]\n                         search bookmarks by tags\n                         use ',' to find entries matching ANY tag\n                         use '+' to find entries matching ALL tags\n                         excludes entries with tags after ' - '\n                         list all tags, if no search keywords\n    -x, --exclude [...]  omit records matching specified keywords\n    --random [N]         output random bookmarks out of the selection (default 1)\n    --order fields [...] comma-separated list of fields to order the output by\n                         (prepend with '+'/'-' to choose sort direction)''')\n    addarg = search_grp.add_argument\n    addarg('-s', '--sany', nargs='*', help=hide)\n    addarg('-S', '--sall', nargs='*', help=hide)\n    addarg('-r', '--sreg', nargs='*', help=hide)\n    addarg('--deep', action='store_true', help=hide)\n    addarg('--markers', action='store_true', help=hide)\n    addarg('-t', '--stag', nargs='*', help=hide)\n    addarg('-x', '--exclude', nargs='*', help=hide)\n    addarg('--random', nargs='?', type=int, const=1, help=hide)\n    addarg('--order', nargs='+', help=hide)\n\n    # ------------------------\n    # ENCRYPTION OPTIONS GROUP\n    # ------------------------\n\n    crypto_grp = argparser.add_argument_group(\n        title='ENCRYPTION OPTIONS',\n        description='''    -l, --lock [N]       encrypt DB in N (default 8) # iterations\n    -k, --unlock [N]     decrypt DB in N (default 8) # iterations''')\n    addarg = crypto_grp.add_argument\n    addarg('-k', '--unlock', nargs='?', type=int, const=8, help=hide)\n    addarg('-l', '--lock', nargs='?', type=int, const=8, help=hide)\n\n    # ----------------\n    # POWER TOYS GROUP\n    # ----------------\n\n    power_grp = argparser.add_argument_group(\n        title='POWER TOYS',\n        description='''    --ai                 auto-import bookmarks from web browsers\n                         Firefox, Chrome, Chromium, Vivaldi, Edge\n                         (Firefox profile can be specified using\n                         environment variable FIREFOX_PROFILE)\n    -e, --export file    export bookmarks to Firefox format HTML\n                         export XBEL, if file ends with '.xbel'\n                         export Markdown, if file ends with '.md'\n                         format: [title](url) <!-- TAGS -->\n                         export Orgfile, if file ends with '.org'\n                         format: *[[url][title]] :tags:\n                         export rss feed if file ends with '.rss'\n                         export buku DB, if file ends with '.db'\n                         combines with search results, if opted\n    -i, --import file    import bookmarks from file\n                         supports .html .xbel .json .md .org .rss .db\n    -p, --print [...]    show record details by indices, ranges\n                         print all bookmarks, if no arguments\n                         -n shows the last n results (like tail)\n    -f, --format N       limit fields in -p or JSON search output\n                         N=1: URL; N=2: URL, tag; N=3: title;\n                         N=4: URL, title, tag; N=5: title, tag;\n                         N0 (10, 20, 30, 40, 50) omits DB index\n    -j, --json [file]    JSON formatted output for -p and search.\n                         prints to stdout if argument missing.\n                         otherwise writes to given file\n    --colors COLORS      set output colors in five-letter string\n    --nc                 disable color output\n    -n, --count N        show N results per page (default 10)\n    --np                 do not show the subprompt, run and exit\n    -o, --open [...]     browse bookmarks by indices and ranges\n                         open a random bookmark, if no arguments\n    --oa                 browse all search results immediately\n    --replace old new    replace old tag with new tag everywhere\n                         delete old tag, if new tag not specified\n    --url-redirect       when fetching an URL, use the resulting\n                         URL from following *permanent* redirects\n                         (when combined with --export, the old URL\n                         is included as additional metadata)\n    --tag-redirect [tag] when fetching an URL that causes permanent\n                         redirect, add a tag in specified pattern\n                         (using 'http:{}' if not specified)\n    --tag-error [tag]    when fetching an URL that causes an HTTP\n                         error, add a tag in specified pattern\n                         (using 'http:{}' if not specified)\n    --del-error [...]    when fetching an URL causes any (given)\n                         HTTP error, delete/do not add it\n    --export-on [...]    export records affected by the above\n                         options, including removed info\n                         (requires --update and --export; specific\n                         HTTP response filter can be provided)\n    --shorten index|URL  fetch shortened url from tny.im service\n    --expand index|URL   expand a tny.im shortened url\n    --cached index|URL   browse a cached page from Wayback Machine\n    --offline            add a bookmark without connecting to web\n    --suggest            show similar tags when adding bookmarks\n    --tacit              reduce verbosity, skip some confirmations\n    --nostdin            do not wait for input (must be first arg)\n    --threads N          max network connections in full refresh\n                         default N=4, min N=1, max N=10\n    -V                   check latest upstream version available\n    -g, --debug          show debug information and verbose logs''')\n    addarg = power_grp.add_argument\n    addarg('--ai', action='store_true', help=hide)\n    addarg('-e', '--export', nargs=1, help=hide)\n    addarg('-i', '--import', nargs=1, dest='importfile', help=hide)\n    addarg('-p', '--print', nargs='*', help=hide)\n    addarg('-f', '--format', type=int, default=0, choices={1, 2, 3, 4, 5, 10, 20, 30, 40, 50}, help=hide)\n    addarg('-j', '--json', nargs='?', default=None, const='', help=hide)\n    addarg('--colors', dest='colorstr', type=argparser.is_colorstr, metavar='COLORS', help=hide)\n    addarg('--nc', action='store_true', help=hide)\n    addarg('-n', '--count', nargs='?', const=10, type=int, default=0, help=hide)\n    addarg('--np', action='store_true', help=hide)\n    addarg('-o', '--open', nargs='*', help=hide)\n    addarg('--oa', action='store_true', help=hide)\n    addarg('--replace', nargs='+', help=hide)\n    addarg('--url-redirect', action='store_true', help=hide)\n    addarg('--tag-redirect', nargs='?', const=True, default=False, help=hide)\n    addarg('--tag-error', nargs='?', const=True, default=False, help=hide)\n    addarg('--del-error', nargs='*', help=hide)\n    addarg('--export-on', nargs='*', help=hide)\n    addarg('--shorten', nargs=1, help=hide)\n    addarg('--expand', nargs=1, help=hide)\n    addarg('--cached', nargs=1, help=hide)\n    addarg('--offline', action='store_true', help=hide)\n    addarg('--suggest', action='store_true', help=hide)\n    addarg('--tacit', action='store_true', help=hide)\n    addarg('--nostdin', action='store_true', help=hide)\n    addarg('--threads', type=int, default=4, choices=range(1, 11), help=hide)\n    addarg('-V', dest='upstream', action='store_true', help=hide)\n    addarg('-g', '--debug', action='store_true', help=hide)\n    # Undocumented APIs\n    # Fix uppercase tags allowed in releases before v2.7\n    addarg('--fixtags', action='store_true', help=hide)\n    # App-use only, not for manual usage\n    addarg('--db', nargs=1, default=[None], help=hide)\n\n    # Parse the arguments\n    args = argparser.parse_args(argv)\n\n    # Show help and exit if help requested\n    if args.help:\n        argparser.print_help()\n        sys.exit(0)\n\n    # By default, buku uses ANSI colors. As Windows does not really use them,\n    # we'd better check for known working console emulators first. Currently,\n    # only ConEmu is supported. If the user does not use ConEmu, colors are\n    # disabled unless --colors or %BUKU_COLORS% is specified.\n    if sys.platform == 'win32' and os.environ.get('ConemuDir') is None:\n        if args.colorstr is None and colorstr_env is not None:\n            args.nc = True\n\n    # Handle NO_COLOR as well:\n    if os.environ.get('NO_COLOR') is not None:\n        args.nc = True\n\n    # Handle color output preference\n    if args.nc:\n        logging.basicConfig(format='[%(levelname)s] %(message)s')\n    else:\n        # Set colors\n        if colorstr_env is not None:\n            # Someone set BUKU_COLORS.\n            colorstr = colorstr_env\n        elif args.colorstr is not None:\n            colorstr = args.colorstr\n        else:\n            colorstr = 'oKlxm'\n\n        ID = setcolors(colorstr)[0] + '%d. ' + COLORMAP['x']\n        ID_DB_dim = COLORMAP['z'] + '[%s]\\n' + COLORMAP['x']\n        ID_STR = ID + setcolors(colorstr)[1] + '%s ' + COLORMAP['x'] + ID_DB_dim\n        ID_DB_STR = ID + setcolors(colorstr)[1] + '%s' + COLORMAP['x']\n        MUTE_STR = '%s \\x1b[2m(L)\\x1b[0m\\n'\n        URL_STR = COLORMAP['j'] + '   > ' + setcolors(colorstr)[2] + '%s\\n' + COLORMAP['x']\n        DESC_STR = COLORMAP['j'] + '   + ' + setcolors(colorstr)[3] + '%s\\n' + COLORMAP['x']\n        DESC_WRAP = COLORMAP['j'] + setcolors(colorstr)[3] + '%s%s' + COLORMAP['x']\n        TAG_STR = COLORMAP['j'] + '   # ' + setcolors(colorstr)[4] + '%s\\n' + COLORMAP['x']\n        TAG_WRAP = COLORMAP['j'] + setcolors(colorstr)[4] + '%s%s' + COLORMAP['x']\n\n        # Enable color in logs\n        setup_logger(LOGGER)\n\n        # Enable prompt with reverse video\n        PROMPTMSG = '\\001\\x1b[7\\002mbuku (? for help)\\001\\x1b[0m\\002 '\n\n    # Enable browser output in case of a text based browser\n    if os.getenv('BROWSER') in TEXT_BROWSERS:\n        browse.suppress_browser_output = False\n    else:\n        browse.suppress_browser_output = True\n\n    # Overriding text browsers is disabled by default\n    browse.override_text_browser = False\n\n    # Fallback to prompt if no arguments\n    if argv in ([], ['--nostdin']):\n        bdb = BukuDb()\n        prompt(bdb, None)\n        bdb.close_quit(0)\n\n    # Set up debugging\n    if args.debug:\n        LOGGER.setLevel(logging.DEBUG)\n        LOGDBG('buku v%s', __version__)\n        LOGDBG('Python v%s', ('%d.%d.%d' % sys.version_info[:3]))\n    else:\n        logging.disable(logging.WARNING)\n        urllib3.disable_warnings()\n\n    # Handle encrypt/decrypt options at top priority\n    if args.lock is not None:\n        BukuCrypt.encrypt_file(args.lock, dbfile=args.db[0])\n    elif args.unlock is not None:\n        BukuCrypt.decrypt_file(args.unlock, dbfile=args.db[0])\n\n    order = [s for ss in (args.order or []) for s in re.split(r'\\s*,\\s*', ss.strip()) if s]\n\n    # Set up title\n    if args.title is not None:\n        title_in = ' '.join(args.title)\n\n    # Set up tags\n    if args.tag is not None:\n        tags_in = args.tag or [DELIM]\n\n    # Set up comment\n    if args.comment is not None:\n        desc_in = ' '.join(args.comment)\n\n    # validating HTTP-code handling args\n    tag_redirect = args.tag_redirect\n    if isinstance(args.tag_redirect, str):\n        try:\n            args.tag_redirect.format(301)\n            tag_redirect = args.tag_redirect.strip() or True\n        except (IndexError, KeyError):\n            LOGERR('Invalid format of --tag-redirect (should use \"{}\" as placeholder)')\n            sys.exit(1)\n    tag_error = args.tag_error\n    if isinstance(args.tag_error, str):\n        try:\n            args.tag_error.format(301)\n            tag_error = args.tag_error.strip() or True\n        except (IndexError, KeyError):\n            LOGERR('Invalid format of --tag-error (should use \"{}\" as placeholder)')\n            sys.exit(1)\n    try:\n        del_error = (None if args.del_error is None else\n                     parse_range(args.del_error, lambda x: 400 <= x < 600) or range(400, 600))\n    except ValueError:\n        LOGERR('Invalid HTTP code(s) given for --del-error (should be within 4xx/5xx ranges)')\n        sys.exit(1)\n    try:\n        _default = (set() if not args.url_redirect and not tag_redirect else PERMANENT_REDIRECTS)\n        _default |= set([] if not tag_error else range(400, 600)) | set(del_error or [])\n        export_on = (None if args.export_on is None else\n                     parse_range(args.export_on, lambda x: 100 <= x < 600) or _default)\n    except ValueError:\n        LOGERR('Invalid HTTP code(s) given for --export-on')\n        sys.exit(1)\n\n    # Initialize the database and get handles, set verbose by default\n    bdb = BukuDb(\n        args.json,\n        args.format,\n        not args.tacit,\n        dbfile=args.db[0],\n        colorize=not args.nc\n    )\n\n    if args.swap:\n        index1, index2 = args.swap\n        if bdb.swap_recs(index1, index2):\n            bdb.print_rec({index1, index2})\n        else:\n            LOGERR('Failed to swap records #%d and #%d', index1, index2)\n        bdb.close_quit(0)\n\n    # Editor mode\n    if args.write is not None:\n        if not is_editor_valid(args.write):\n            bdb.close_quit(1)\n\n        if is_int(args.write):\n            if not bdb.edit_update_rec(int(args.write), _immutable(args)):\n                bdb.close_quit(1)\n        elif args.add is None:\n            # Edit and add a new bookmark\n            # Parse tags into a comma-separated string\n            tags = parse_tags(tags_in, edit_input=True)\n\n            result = edit_rec(args.write, '', title_in, tags, desc_in)\n            if result is not None:\n                url, title_in, tags, desc_in = result\n                if args.suggest:\n                    tags = bdb.suggest_similar_tag(tags)\n                bdb.add_rec(url, title_in, tags, desc_in, _immutable(args), False, not args.offline)\n\n    # Add record\n    if args.add is not None:\n        if args.url is not None and args.update is None:\n            LOGERR('Bookmark a single URL at a time')\n            bdb.close_quit(1)\n\n        # Parse tags into a comma-separated string\n        # --add may have URL followed by tags\n        keywords_except, keywords = [], args.add[1:]\n        # taglists are taken from --add (starting from 2nd value) and from --tags\n        # if taglist starts with '-', its contents are excluded from resulting tags\n        # if BOTH taglists is are either empty or start with '+'/'-', fetched tags are included\n        if keywords and keywords[0] == '-':\n            keywords, keywords_except = [], keywords[1:]\n        tags_add = (not keywords or keywords[0] == '+')\n        if tags_add:\n            keywords = keywords[1:]\n        if tags_in:\n            # note: need to add a delimiter as url+tags may not end with one\n            if tags_in[0] == '-':\n                keywords_except += [DELIM] + tags_in[1:]\n            elif tags_in[0] == '+':\n                keywords += [DELIM] + tags_in[1:]\n            else:\n                keywords += [DELIM] + tags_in\n                tags_add = False\n\n        tags, tags_except = parse_tags(keywords), parse_tags(keywords_except)\n        tags, tags_except = ((s if s and s != DELIM else None) for s in [tags, tags_except])\n        url = args.add[0]\n        edit_aborted = False\n\n        if args.write and not is_int(args.write):\n            result = edit_rec(args.write, url, title_in, tags, desc_in)\n            if result is not None:\n                url, title_in, tags, desc_in = result\n            else:\n                edit_aborted = True\n\n        if edit_aborted is False:\n            if args.suggest:\n                tags = bdb.suggest_similar_tag(tags)\n            network_test = args.url_redirect or tag_redirect or tag_error or del_error\n            fetch = not args.offline and (network_test or tags_add or title_in is None)\n            bdb.add_rec(url, title_in, tags, desc_in, _immutable(args), delay_commit=False, fetch=fetch,\n                        tags_fetch=tags_add, tags_except=tags_except, url_redirect=args.url_redirect,\n                        tag_redirect=tag_redirect, tag_error=tag_error, del_error=del_error)\n\n    # Search record\n    search_results, search_opted = None, True\n\n    if args.sany is not None:\n        if not args.sany:\n            LOGERR('no keyword')\n        else:\n            LOGDBG('args.sany')\n            # Apply tag filtering, if opted\n            search_results = bdb.search_keywords_and_filter_by_tags(\n                args.sany, deep=args.deep, stag=args.stag, markers=args.markers, without=args.exclude, order=order)\n    elif args.sall is not None:\n        if not args.sall:\n            LOGERR('no keyword')\n        else:\n            LOGDBG('args.sall')\n            search_results = bdb.search_keywords_and_filter_by_tags(\n                args.sall, all_keywords=True, deep=args.deep, stag=args.stag,\n                markers=args.markers, without=args.exclude, order=order)\n    elif args.sreg is not None:\n        if not args.sreg:\n            LOGERR('no expression')\n        else:\n            LOGDBG('args.sreg')\n            search_results = bdb.search_keywords_and_filter_by_tags(\n                args.sreg, regex=True, stag=args.stag, markers=args.markers, without=args.exclude, order=order)\n    elif args.keywords:\n        LOGDBG('args.keywords')\n        search_results = bdb.search_keywords_and_filter_by_tags(\n            args.keywords, deep=args.deep, stag=args.stag, markers=args.markers, without=args.exclude, order=order)\n    elif args.stag is not None:\n        if not args.stag:  # use sub-prompt to list all tags\n            prompt(bdb, None, noninteractive=args.np, listtags=True, suggest=args.suggest, order=order)\n        else:\n            LOGDBG('args.stag')\n            search_results = bdb.exclude_results_from_search(\n                bdb.search_by_tag(' '.join(args.stag), order=order), args.exclude, deep=args.deep, markers=args.markers)\n    elif args.exclude is not None:\n        LOGERR('No search criteria to exclude results from')\n    elif args.markers:\n        LOGERR('No search criteria to apply markers to')\n    else:\n        search_opted = False\n\n    # Add cmdline search options to readline history\n    if search_opted and len(args.keywords):\n        try:\n            readline.add_history(' '.join(args.keywords))\n        except Exception:\n            pass\n\n    check_stdout_encoding()\n    monkeypatch_textwrap_for_cjk()\n\n    update_search_results = False\n    if search_results:\n        if args.random and args.random < len(search_results):\n            search_results = bdb._sort(random.sample(search_results, args.random), order)\n        single_record = args.random == 1  # matching print_rec() behaviour\n\n        oneshot = args.np\n\n        # Open all results in browser right away if args.oa\n        # is specified. The has priority over delete/update.\n        # URLs are opened first and updated/deleted later.\n        if args.oa:\n            for row in search_results:\n                browse(row[1])\n\n        if (\n                (args.export is not None) or\n                (args.delete is not None and not args.delete) or\n                (args.update is not None and not args.update)):\n            oneshot = True\n\n        if args.json is None and not args.format and not args.random:\n            num = 10 if not args.count else args.count\n            prompt(bdb, search_results, noninteractive=oneshot, deep=args.deep, markers=args.markers, order=order, num=num)\n        elif args.json is None:\n            print_rec_with_filter(search_results, field_filter=args.format)\n        elif args.json:\n            write_string_to_file(format_json(search_results, single_record, field_filter=args.format), args.json)\n        else:\n            # Printing in JSON format is non-interactive\n            print_json_safe(search_results, single_record, field_filter=args.format)\n\n        # Export the results, if opted\n        if args.export and not (args.update is not None and export_on):\n            bdb.exportdb(args.export[0], search_results)\n\n        # In case of search and delete/update,\n        # prompt should be non-interactive\n        # delete gets priority over update\n        if args.delete is not None and not args.delete:\n            bdb.delete_resultset(search_results)\n        elif args.update is not None and not args.update:\n            update_search_results = True\n\n    # Update record\n    if args.update is not None:\n        url_in = (args.url[0] if args.url else None)\n\n        # Parse tags into a comma-separated string\n        tags = parse_tags(tags_in, edit_input=True)\n        tags = (None if tags == DELIM else tags)\n\n        # No arguments to --update, update all\n        if not args.update:\n            # Update all records only if search was not opted\n            if not search_opted:\n                _indices = []\n            elif search_results and update_search_results:\n                if not args.tacit:\n                    print('Updated results:\\n')\n\n                _indices = [x.id for x in search_results]\n            else:\n                _indices = None\n        else:\n            try:\n                _indices = parse_range(args.update, lambda x: x >= 0)\n            except ValueError:\n                LOGERR('Invalid index or range to update')\n                bdb.close_quit(1)\n            _indices = ([] if 0 in _indices else _indices)\n        if _indices is not None:\n            bdb.update_rec(_indices, url_in, title_in, tags, desc_in, _immutable(args), threads=args.threads,\n                           url_redirect=args.url_redirect, tag_redirect=tag_redirect,\n                           tag_error=tag_error, del_error=del_error, export_on=export_on)\n            if args.export and bdb._to_export is not None:\n                bdb.exportdb(args.export[0], order=order)\n\n    # Delete record\n    if args.delete is not None:\n        if not args.delete:\n            # Attempt delete-all only if search was not opted\n            if not search_opted:\n                bdb.cleardb()\n        elif len(args.delete) == 1 and '-' in args.delete[0]:\n            try:\n                vals = [int(x) for x in args.delete[0].split('-')]\n                if len(vals) == 2:\n                    bdb.delete_rec(0, vals[0], vals[1], True)\n            except ValueError:\n                LOGERR('Invalid index or range to delete')\n                bdb.close_quit(1)\n        else:\n            ids = []\n            # Select the unique indices\n            for idx in args.delete:\n                if idx not in ids:\n                    ids += (idx,)\n\n            try:\n                # Index delete order - highest to lowest\n                ids.sort(key=lambda x: int(x), reverse=True)\n                for idx in ids:\n                    bdb.delete_rec(int(idx))\n            except ValueError:\n                LOGERR('Invalid index or range or combination')\n                bdb.close_quit(1)\n\n    # Print record\n    if args.print is not None:\n        try:\n            max_id = bdb.get_max_id() or 0\n            id_range = list(parse_range(args.print, maxidx=max_id) or []) or range(1, 1 + max_id)\n        except ValueError:\n            LOGERR('Invalid index or range to print')\n            bdb.close_quit(1)\n        if args.random and args.random < len(id_range):\n            bdb.print_rec(random.sample(id_range, args.random), order=order)\n        elif not args.print:\n            if args.count:\n                search_results = bdb.list_using_id(order=order)\n                prompt(bdb, search_results, noninteractive=args.np, num=args.count, order=order)\n            else:\n                bdb.print_rec(None, order=order)\n        else:\n            if args.count:\n                search_results = bdb.list_using_id(args.print, order=order)\n                prompt(bdb, search_results, noninteractive=args.np, num=args.count, order=order)\n            else:\n                bdb.print_rec(id_range, order=order)\n\n    # Replace a tag in DB\n    if args.replace is not None:\n        if len(args.replace) == 1:\n            bdb.delete_tag_at_index(0, args.replace[0])\n        else:\n            try:\n                bdb.replace_tag(args.replace[0], [' '.join(args.replace[1:])])\n            except Exception as e:\n                LOGERR(str(e))\n                bdb.close_quit(1)\n\n    # Export bookmarks\n    if args.export and not search_opted and not export_on:\n        bdb.exportdb(args.export[0], order=order, pick=args.random)\n\n    # Import bookmarks\n    if args.importfile is not None:\n        bdb.importdb(args.importfile[0], args.tacit)\n\n    # Import bookmarks from browser\n    if args.ai:\n        bdb.auto_import_from_browser(firefox_profile=os.environ.get('FIREFOX_PROFILE'))\n\n    # Open URL in browser\n    if args.open is not None:\n        if not args.open:\n            bdb.browse_by_index(0)\n        else:\n            try:\n                for idx in args.open:\n                    if is_int(idx):\n                        bdb.browse_by_index(int(idx))\n                    elif '-' in idx:\n                        vals = [int(x) for x in idx.split('-')]\n                        bdb.browse_by_index(0, vals[0], vals[-1], True)\n            except ValueError:\n                LOGERR('Invalid index or range to open')\n                bdb.close_quit(1)\n\n    # Shorten URL\n    if args.shorten:\n        if is_int(args.shorten[0]):\n            shorturl = bdb.tnyfy_url(index=int(args.shorten[0]))\n        else:\n            shorturl = bdb.tnyfy_url(url=args.shorten[0])\n\n        if shorturl:\n            print(shorturl)\n\n    # Expand URL\n    if args.expand:\n        if is_int(args.expand[0]):\n            url = bdb.tnyfy_url(index=int(args.expand[0]), shorten=False)\n        else:\n            url = bdb.tnyfy_url(url=args.expand[0], shorten=False)\n\n        if url:\n            print(url)\n\n    # Try to fetch URL from Wayback Machine\n    if args.cached:\n        wbu = bdb.browse_cached_url(args.cached[0])\n        if wbu is not None:\n            browse(wbu)\n\n    # Report upstream version\n    if args.upstream:\n        check_upstream_release()\n\n    # Fix tags\n    if args.fixtags:\n        bdb.fixtags()\n\n    # Close DB connection and quit\n    bdb.close_quit(0)\n\nif __name__ == '__main__':\n    main()\n"
        },
        {
          "name": "buku.1",
          "type": "blob",
          "size": 31.390625,
          "content": ".TH \"BUKU\" \"1\" \"07 Apr 2024\" \"Version 4.9\" \"User Commands\"\n.SH NAME\nbuku \\- Bookmark manager like a text-based mini-web\n.SH SYNOPSIS\n.B buku [OPTIONS] [KEYWORD [KEYWORD ...]]\n.SH DESCRIPTION\n.B buku\nis a command-line utility to store, tag, search and organize bookmarks.\n.PP\n.B Features\n.PP\n  * Store bookmarks with auto-fetched title, tags and description\n  * Auto-import from Firefox, Google Chrome, Chromium, Vivaldi, and MS Edge\n  * Open bookmarks and search results in browser\n  * Shorten, expand URLs\n  * Browse cached page from the Wayback Machine\n  * Text editor integration\n  * Lightweight, clean interface, custom colors\n  * Powerful search options (regex, substring...)\n  * Continuous search with on the fly mode switch\n  * Portable, merge-able database to sync between systems\n  * Import/export bookmarks from/to HTML, XBEL, Markdown, RSS or Orgfile\n  * Smart tag management using redirection (>>, >, <<)\n  * Multithreaded full DB refresh\n  * Manual encryption support\n  * Shell completion scripts, man page with handy examples\n.SH OPERATIONAL NOTES\n.PP\n.IP 1. 4\nThe database file is stored in:\n  - \\fI$XDG_DATA_HOME/buku/bookmarks.db\\fR, if XDG_DATA_HOME is defined (first preference), or\n  - \\fI$HOME/.local/share/buku/bookmarks.db\\fR, if HOME is defined (second preference), or\n  - \\fI%APPDATA%\\\\buku\\\\bookmarks.db\\fR, if you are on Windows, or\n  - the current directory.\n.PP\n.IP 2. 4\nIf the URL contains characters like ';', '&' or brackets they may be interpreted specially by the shell. To avoid it, add the URL within single or double quotes ('/\").\n.PP\n.IP 3. 4\nURLs are unique in DB. The same URL cannot be added twice.\n.PP\n.IP 4. 4\nBookmarks with immutable titles are listed with '(L)' after the title.\n.PP\n.IP 5. 4\n\\fBTags\\fR:\n  - Comma (',') is the tag delimiter in DB. A tag cannot have comma(s) in it. Tags are filtered (for unique tags) and sorted. Tags are stored in lower case and can be replaced, appended or deleted.\n  - Page keywords having a word to comma ratio > 3 are appended to description rather than tags.\n  - Parent folder (and subfolder) names are converted to all-lowercase tags during bookmarks HTML import.\n  - Releases prior to v2.7 support both capital and lower cases in tags. From v2.7 all tags are stored in lowercase. An undocumented option --fixtags is introduced to modify the older tags. It also fixes another issue where the same tag appears multiple times in the tagset of a record. Run \\fBbuku --fixtags\\fR once.\n  - Tags can be edited from the prompt very easily using '>>' (append), '>' (overwrite) and '<<' (remove) symbols. The LHS of the operands denotes the indices and ranges of tags to apply (as listed by --tag or key 't' at prompt) and the RHS denotes the actual DB indices and ranges of the bookmarks to apply the change to.\n.PP\n.IP 6. 4\n\\fBUpdate\\fR operation:\n  - If --title, --tag or --comment is passed without argument, clear the corresponding field from DB.\n  - If --url is passed (and --title is omitted), update the title from web using the URL. Description is updated (if --comment is omitted). Tags remain untouched.\n  - If indices are passed without any other options (--url, --title, --tag, --comment and --immutable), read the URLs from DB and update titles, description and append tags from web. Bookmarks marked immutable are skipped.\n  - Can update bookmarks matching a search, when combined with any of the search options and no arguments to update are passed.\n  - Additionally, --swap allows to modify records order (standalone operation).\n.PP\n.IP 7. 4\n\\fBDelete\\fR operation:\n  - When a record is deleted, the last record is moved to the index.\n  - Delete doesn't work with range and indices provided together as arguments. It's an intentional decision to avoid extra sorting, in-range checks and to keep the auto-DB compaction functionality intact. On the same lines, indices are deleted in descending order.\n  - Can delete bookmarks matching a search, when combined with any of the search options and no arguments to delete are passed.\n.PP\n.IP 8. 4\n\\fBSearch\\fR works in mysterious ways:\n  - Case-insensitive.\n  - Matches words in URL, title and tags.\n  - --sany : match any of the keywords in URL, title, description or tags. Default search option.\n  - --sall : match all the keywords in URL, title, description or tags.\n  - --deep : match \\fBsubstrings\\fR (`match` matches `rematched`) in URL, title, description and tags.\n  - --markers : match each keyword to a \\fBspecific\\fR field, depending on its prefix.\n  - --sreg : match a regular expression (ignores --deep).\n  - --stag : search bookmarks by tags, or list all tags alphabetically with usage count (if no arguments). Delimit the list of tags in the query with `,` to search for bookmarks that match ANY of the listed tags. Delimit tags with `+` to search for bookmarks that match ALL of the listed tags. Note that `,` and `+` cannot be used together in the same search. Exclude bookmarks matching certain tags from the results by using ` - ` followed by the tags. Note that the ` - ` operator and the ` + ` delimiter must be space separated: ` - ` instead of `-` and ` + ` instead of `+`. This is to distinguish them from hyphenated tags (e.g., `some-tag-name`) and tags with '+'s (e.g., `some+tag+name`).\n  - Search for keywords along with tag filtering is possible. Two searches are issued (one for keywords and another for tags) and the intersection of the 2 sets is returned as the resultset.\n  - Search results are indexed incrementally. This index is different from actual database index of a bookmark record which is shown within '[]' after the title.\n  - Results for \\fIany\\fR keyword matches are ordered by the number of keyword matches - results matching more keywords (\\fImatch score\\fR) will appear earlier in the list. Results having the same number of matches will be ranked by their record DB index. If only one keyword is searched, results will be ordered by DB index, since all matching records will have the same \\fImatch score\\fR.\n  - Sorting order can be specified (for matches with same amount of matched keywords, if relevant). This option also works with regular printing/export.\n.PP\n.IP 9. 4\n\\fBImport\\fR:\n  - Auto-import looks in the default installation path and default user profile.\n  - URLs starting with `place:`, `file://` and `apt:` are ignored during import.\n  - Parent folder (and subfolder) names are automatically imported as tags if --tacit is used.\n  - Tags are merged even if bookmark URL exists when --tacit is used.\n  - JSON files exported from browser can be imported. Export to JSON is not supported.\n.PP\n.IP 10. 4\n\\fBEncryption\\fR is optional and manual. AES256 algorithm is used. To use encryption, the database file should be unlocked (-k) before using \\fBbuku\\fR and locked (-l) afterwards. Between these 2 operations, the database file lies unencrypted on the disk, and NOT in memory. Also, note that the database file is \\fBunencrypted on creation\\fR.\n.PP\n.IP 11. 4\n\\fBEditor\\fR support:\n  - A single bookmark can be edited before adding. The editor can be set using the environment variable *EDITOR* or by explicitly specifying the editor. The latter takes precedence. If -a is used along with -w, the details are populated in the editor template.\n  - In case of edit and update (a single bookmark), the existing record details are fetched from DB and populated in the editor template. The environment variable EDITOR must be set. Note that -u works independently of -w.\n  - All lines beginning with \"#\" will be stripped. Then line 1 will be treated as the URL, line 2 will be the title, line 3 will be comma separated tags, and the rest of the lines will be parsed as descriptions.\n.PP\n.IP 12. 4\n\\fBProxy\\fR support: please refer to the \\fBENVIRONMENT\\fR section.\n.PP\n.IP 13. 4\n\\fBAlternative DB file\\fR:\n  - The option --db (to specify an alternative database file location) is app-only. Manual usage is prone to issues arising from human error.\n  - Note that this option is useful if you want to store the db file in cloud synced location. Another mechanism could be to have the db file synced and create a symlink to it at the default location.\n.SH GENERAL OPTIONS\n.TP\n.BI \\-a \" \" \\--add \" URL [+|-] [tag, ...]\"\nBookmark\n.I URL\nalong with comma-separated tags. A tag can have multiple words. (These tags \\fBoverride\\fR fetched tags, unless preceded with '+' or '-'.)\n.TP\n.BI \\-u \" \" \\--update \" [...]\"\nUpdate fields of the bookmarks at specified indices in DB. If no arguments are specified, all titles and descriptions are refreshed from the web. Tags remain untouched. Works with update modifiers for the fields url, title, tag and comment. If only indices are passed without any edit options, titles and descriptions are fetched and updated (if not empty). Accepts hyphenated ranges and space-separated indices. Updates search results when used with search options, if no arguments.\n.TP\n.BI \\-w \" \" \\--write \" [editor|index]\"\nEdit a bookmark in\n.I editor\nbefore adding it. To edit and update an existing bookmark, the\n.I index\nshould be passed. In this case the environment variable EDITOR must be set. The last record is opened in EDITOR if index=-1.\n.TP\n.BI \\-d \" \" \\--delete \" [...]\"\nDelete bookmarks. Accepts space-separated list of indices (e.g. 5 6 23 4 110 45) or a single hyphenated range (e.g. 100-200). Note that range and list don't work together. Deletes search results when combined with search options, if no arguments.\n.TP\n.BI \\-v \" \" \\--version\nShow program version and exit.\n.TP\n.BI \\-h \" \" \\--help\nShow program help and exit.\n.SH EDIT OPTIONS\n.TP\n.BI \\--url \" [...]\"\nSpecify the URL, works with --update only. Fetches and updates title if --title is not used.\n.TP\n.BI \\--tag \" [+|-] [...]\"\nSpecify comma separated tags, works with --add, --update. Clears the tags, if no arguments passed. Appends or deletes tags, if list of tags is preceded by '+' or '-' respectively.\n.TP\n.BI \\--title \" [...]\"\nManually specify the title, works with --add, --update. Omits or clears the title, if no arguments passed.\n.TP\n.BI \\-c \" \" \\--comment \" [...]\"\nAdd notes or description of the bookmark, works with --add, --update. Clears the comment, if no arguments passed.\n.TP\n.BI \\--immutable \" N\"\nSet the title, description and tags of a bookmark immutable during autorefresh. Works with --add, --update. N=1 sets the immutable flag, N=0 removes it. If omitted, bookmarks are added with N=0.\n.TP\n.BI \\--swap \" N M\"\nSwap two records at specified indices. This is a standalone operation (cannot be invoked along with any other).\n.SH SEARCH OPTIONS\n.TP\n.BI \\-s \" \" \\--sany \" keyword [...]\"\nSearch bookmarks with ANY of the keyword(s) in URL, title or tags and show the results. Prompts to enter result number to open in browser. Note that the sequential result index is not the DB index. The DB index is shown within '[]' after the title.\n.br\nThis is the default search option for positional arguments if no other search option is specified.\n.TP\n.BI \\-S \" \" \\--sall \" keyword [...]\"\nSearch bookmarks with ALL keywords in URL, title or tags and show the results. Behaviour same as --sany.\n.br\nSpecial keywords:\n.br\n\"blank\": list entries with empty title/tag\n.br\n\"immutable\": list entries with locked title\n.br\nNOTE: To search the keywords, use --sany\n.TP\n.BI \\--deep\nSearch modifier to match substrings. Works with --sany, --sall.\n.TP\n.BI \\--markers\nSearch modifier to match specific fields based on (optional) prefix markers (i.e. beginning of the keyword):\n  - '.' : search in title\n  - '>' : search in description\n  - ':' : search in URL\n  - '#' : search in tags (comma-separated, \\fBpartial\\fR matches; not affected by --deep)\n  - '#,' : search in tags (comma-separated, \\fBexact\\fR matches; not affected by --deep)\n  - '*' : search in all fields (same as no prefix)\n.TP\n.BI \\-r \" \" \\--sreg \" expression\"\nScan for a regular expression match.\n.TP\n.BI \\-t \" \" \\--stag \" [tag [,|+] ...] [\\- tag, ...]\"\nSearch bookmarks by tags.\n.br\nUse ',' delimiter to find entries matching ANY of the tags\n.br\nUse ' + ' delimiter to find entries matching ALL of the tags. (Note that the ' + ' delimiter must be space separated)\n.br\nNOTE: Cannot combine ',' and '+' in the same search\n.br\nUse ' - ' to exclude bookmarks that match the tags that follow. (Note that the '-' operator must be space separated).\n.br\nList all tags alphabetically, if no arguments. The usage count (number of bookmarks having the tag) is shown within first brackets.\n.TP\n.BI \\-x \" \" \\--exclude \" keyword [...]\"\nExclude bookmarks matching the specified keywords. Works with --sany, --sall, --sreg and --stag.\n.TP\n.BI \\--random \" [N]\"\nOutput random bookmarks out of the selection (1 unless amount is specified).\n.TP\n.BI \\--order \" fields [...]\"\nOrder printed/exported records by the given fields (from DB or JSON) and/or netloc. You can specify sort direction for each by prepending '+'/'-' (default is '+').\n.SH ENCRYPTION OPTIONS\n.TP\n.BI \\-l \" \" \\--lock \" [N]\"\nEncrypt (lock) the DB file with\n.I N\n(> 0, default 8) hash passes to generate key.\n.TP\n.BI \\-k \" \" \\--unlock \" [N]\"\nDecrypt (unlock) the DB file with\n.I N\n(> 0, default 8) hash passes to generate key.\n.SH POWER OPTIONS\n.TP\n.BI \\--ai\nAuto-import bookmarks from Firefox, Google Chrome, Chromium, Vivaldi, and Edge browsers. (Firefox profile can be specified using environment variable FIREFOX_PROFILE.)\n.TP\n.BI \\-e \" \" \\--export \" file\"\nExport bookmarks to Firefox bookmarks formatted HTML. Works with all search options.\n.br\nXBEL is used if\n.I file\nhas extension '.xbel'.\n.br\nMarkdown is used if\n.I file\nhas extension '.md'. Markdown format: [title](url), 1 entry per line.\n.br\nOrgfile is used if\n.I file\nhas extension '.org' Orgfile format: * [[url][title]], 1 entry per line.\n.br\nRSS is used if\n.I file\nhas extension '.rss' RSS format: <entry> per bookmark with <title>, <link>, <category>, <content> elements\n.br\nA buku database is generated if\n.I file\nhas extension '.db'.\n.TP\n.BI \\-i \" \" \\--import \" file\"\nImport bookmarks from Firefox bookmarks formatted HTML.\n.I file\nis considered Firefox-exported JSON if it has '.json' extension, XBEL if it is '.xbel', Markdown (compliant with --export format) if it is '.md', Orgfile if the extension is '.org', RSS if the extension is '.rss' or another buku database if the extension is '.db'.\n.TP\n.BI \\-p \" \" \\--print \" [...]\"\nShow details (DB index, URL, title, tags and comment) of bookmark record by DB index. If no arguments, all records with actual index from DB are shown. Accepts hyphenated ranges and space-separated indices. A negative value (introduced for convenience) behaves like the tail utility, e.g., -n shows the details of the last n bookmarks.\n.TP\n.BI \\-f \" \" \\--format \" N\"\nShow selective monochrome output with specific fields. Works with --print. Search results honour the option when used along with --json. Useful for creating batch scripts.\n.br\n.I N\n= 1, show only URL.\n.br\n.I N\n= 2, show URL and tags in a single line.\n.br\n.I N\n= 3, show only title.\n.br\n.I N\n= 4, show URL, title and tags in a single line.\n.br\n.I N\n= 5, show title and tags in a single line.\n.br\nTo omit DB index from printed results, use N0, e.g., 10, 20, 30, 40, 50.\n.TP\n.BI \\-j \" \" \\--json\nOutput data formatted as JSON, works with --print output and search results.\n.TP\n.BI \\--colors \" COLORS\"\nSet output colors. Refer to the \\fBCOLORS\\fR section below for details.\n.TP\n.BI \\--nc\nDisable color output in all messages. Useful on terminals which can't handle ANSI color codes or scripted environments.\n.TP\n.BI \\-n \" \" \\--count \" N\"\nNumber of results to show per page (default 10).\n.TP\n.BI \\--np\nDo not show the prompt, run and exit.\n.TP\n.BI \\-o \" \" \\--open \" [...]\"\nOpen bookmarks by DB indices or ranges in browser. Open a random index if argument is omitted.\n.TP\n.BI \\--oa\nOpen all search results immediately in the browser. Works best with --np. When used along with --update or --delete, URLs are opened in the browser first and then modified or deleted.\n.TP\n.BI \\--replace \" old new\"\nReplace\n.I old\ntag with\n.I new\ntag if both are passed; delete\n.I old\ntag if\n.I new\ntag is not specified.\n.TP\n.BI \\--url-redirect\nwhen fetching an URL, use the resulting URL from following \\fBpermanent\\fR redirects (when combined with --export, the old URL is included as additional metadata).\n.TP\n.BI \\--tag-redirect \" [tag]\"\nwhen fetching an URL that causes permanent redirect, add a\n.I tag\nin specified pattern (using 'http:{}' if not specified).\n.TP\n.BI \\--tag-error \" [tag]\"\nwhen fetching an URL that causes an HTTP error, add a\n.I tag\nin specified pattern (using 'http:{}' if not specified).\n.TP\n.BI \\--del-error \" [...]\"\nwhen fetching an URL causes any (given) HTTP error, delete/do not add it. (Use a parameter like '404' or '400-404,500')\n.TP\n.BI \\--export-on \" [...]\"\nexport records affected by the above options, including removed info (requires --update and --export; specific HTTP response filter can be provided).\n.TP\n.BI \\--shorten \" index|URL\"\nShorten the URL at DB\n.I index\nor an independent\n.I URL\nusing the tny.im URL shortener service.\n.TP\n.BI \\--expand \" index|URL\"\nExpand the URL at DB\n.I index\nor an independent\n.I URL\nshortened using tny.im.\n.TP\n.BI \\--cached \" index|URL\"\nBrowse the latest cached version of the URL at DB\n.I index\nor an independent\n.I URL\nusing the Wayback Machine. Useful for viewing the content of bookmarks which are not live any more.\n.TP\n.BI \\--offline\nAdd a bookmark without connecting to the web.\n.TP\n.BI \\--suggest\nShow a list of similar tags to choose from when adding a new bookmark.\n.TP\n.BI \\--tacit\nShow lesser output. Reduces the verbosity of certain operations like add, update etc.\n.TP\n.BI \\--nostdin\nDo not attempt to read data from standard input e.g. when the program is not executed from a tty.\n.TP\n.BI \\--threads\nMaximum number of parallel network connection threads to use during full DB refresh. By default 4 connections are spawned.\n.I N\ncan range from 1 to 10.\n.TP\n.BI \\-V\nCheck the latest upstream version available. This is FYI. It is possible the latest upstream released version is still not available in your package manager as the process takes a while.\n.TP\n.BI \\-g \" \" \\--debug\nShow debug information and additional logs.\n.SH PROMPT KEYS\n.TP\n.BI \"1-N\"\nBrowse search results by indices and ranges.\n.TP\n.BI \"O\" \" [id|range [...]]\"\nTry to open search results or indices (when not in a search context) in a GUI browser. Toggle try to open urls in a GUI based browser (even if BROWSER is set) if no arguments. Toggling is useful when trying to open bookmarks by DB index.\n.TP\n.BI \"a\"\nOpen all search results in browser.\n.TP\n.BI \"s\" \" keyword [...]\"\nSearch for records with ANY keyword.\n.TP\n.BI \"S\" \" keyword [...]\"\nSearch for records with ALL keywords.\n.TP\n.BI \"d\"\nToggle deep search to match substrings ('pen' matches 'opened').\n.TP\n.BI \"r\" \" expression\"\nRun a regular expression search.\n.TP\n.BI \"t\" \" [...]\"\nSearch bookmarks by a tag. List all tags alphabetically, if no arguments.\n.TP\n.BI \"g\" \" taglist id|range [...] [>>|>|<<] [record id|range ...]\"\nAppend, set, remove specific or all tags by indices and/or ranges to bookmark indices and/or ranges (see \\fBEXAMPLES\\fR section below). Search by space-separated taglist id(s) and/or range if records are omitted.\n.TP\n.BI \"o\" \" id|range [...]\"\nBrowse bookmarks by indices and/or ranges.\n.TP\n.BI \"p\" \" id|range [...]\"\nPrint bookmarks by indices and/or ranges.\n.TP\n.BI \"w\" \" [editor|id]\"\nEdit and add or update a bookmark.\n.TP\n.BI \"c id\"\nCopy url at search result index to clipboard.\n.TP\n.BI \"?\"\nShow help on prompt keys.\n.TP\n.BI \"q, ^D, double Enter\"\nExit buku.\n.SH ENVIRONMENT\n.TP\n.BI \"Completion scripts\"\nShell completion scripts for Bash, Fish and Zsh can be found in:\n.br\n.I https://github.com/jarun/buku/blob/master/auto-completion\n.TP\n.BI BROWSER\nOverrides the default browser. Refer to:\n.br\n.I http://docs.python.org/library/webbrowser.html\n.TP\n.BI EDITOR\nIf defined, will be used as the editor to edit bookmarks with option --write.\n.TP\n.BI https_proxy\nIf defined, will be used to access http and https resources through the configured proxy. Supported format:\n.br\nhttp[s]://[username:password@]proxyhost:proxyport/\n.TP\n.BI \"GUI integration\"\n.B buku\ncan be integrated in a GUI environment with simple tweaks. Please refer to:\n.br\n.I https://github.com/jarun/buku/wiki/System-integration\n.SH COLORS\n\\fBbuku\\fR allows you to customize the color scheme via a five-letter string, reminiscent of BSD \\fBLSCOLORS\\fR. The five letters represent the colors of\n.IP - 2\nindex\n.PD 0 \\\" Change paragraph spacing to 0 in the list\n.IP - 2\ntitle\n.IP - 2\nURL\n.IP - 2\ndescription/comment/note\n.IP - 2\ntag\n.PD 1 \\\" Restore paragraph spacing\n.TP\nrespectively. The five-letter string is passed is as the argument to the \\fB--colors\\fR option, or as the value of the environment variable \\fBBUKU_COLORS\\fR.\n.TP\nWe offer the following colors/styles:\n.TS\ntab(;) box;\nl|l\n-|-\nl|l.\nLetter;Color/Style\na;black\nb;red\nc;green\nd;yellow\ne;blue\nf;magenta\ng;cyan\nh;white\ni;bright black\nj;bright red\nk;bright green\nl;bright yellow\nm;bright blue\nn;bright magenta\no;bright cyan\np;bright white\nA-H;bold version of the lowercase-letter color\nI-P;bold version of the lowercase-letter bright color\nx;normal\nX;bold\ny;reverse video\nY;bold reverse video\n.TE\n.TP\n.TP\nThe default colors string is \\fIoKlxm\\fR, which stands for\n.IP - 2\nbright cyan index\n.PD 0 \\\" Change paragraph spacing to 0 in the list\n.IP - 2\nbold bright green title\n.IP - 2\nbright yellow URL\n.IP - 2\nnormal description\n.IP - 2\nbright blue tag\n.PD 1 \\\" Restore paragraph spacing\n.TP\nNote that\n.IP - 2\nBright colors (implemented as \\\\x1b[90m - \\\\x1b[97m) may not be available in all color-capable terminal emulators;\n.IP - 2\nSome terminal emulators draw bold text in bright colors instead;\n.IP - 2\nSome terminal emulators only distinguish between bold and bright colors via a default-off switch.\n.TP\nPlease consult the manual of your terminal emulator as well as \\fIhttps://en.wikipedia.org/wiki/ANSI_escape_code\\fR for details.\n\n.SH EXAMPLES\n.PP\n.IP 1. 4\n\\fBEdit and add\\fR a bookmark from editor:\n.PP\n.EX\n.IP\n.B buku -w\n.br\n.B buku -w 'gedit -w'\n.br\n.B buku -w 'macvim -f' -a https://ddg.gg search engine, privacy\n.EE\n.PP\n.IP \"\" 4\nThe first command picks editor from the environment variable \\fIEDITOR\\fR. The second command opens gedit in blocking mode. The third command opens macvim with option -f and the URL and tags populated in template.\n.PP\n.IP 2. 4\n\\fBAdd\\fR a simple bookmark:\n.PP\n.EX\n.IP\n.B buku --nostdin -a https://github.com/\n.EE\n.PP\n.IP \"\" 4\nIn the output, >: url, +: comment, #: tags.\n.PP\n.IP 3. 4\n\\fBAdd\\fR a bookmark with \\fBtags\\fR 'search engine' and 'privacy', \\fBcomment\\fR 'Search engine with perks', \\fBfetch page title\\fR from the web:\n.PP\n.EX\n.IP\n.B buku -a https://ddg.gg search engine, privacy -c Search engine with perks\n.EE\n.PP\n.IP \"\" 4\nIn the output, >: url, +: comment, #: tags.\n.PP\n.IP 4. 4\n\\fBAdd\\fR a bookmark with tags 'search engine' & 'privacy' and \\fBimmutable custom title\\fR 'DDG':\n.PP\n.EX\n.IP\n.B buku -a https://ddg.gg search engine, privacy --title 'DDG' --immutable 1\n.EE\n.PP\n.IP \"\" 4\nNote that URL must precede tags.\n.PP\n.IP 5. 4\n\\fBAdd\\fR a bookmark \\fBwithout a title\\fR (works for update too):\n.PP\n.EX\n.IP\n.B buku -a https://ddg.gg search engine, privacy --title\n.EE\n.PP\n.IP 6. 4\n\\fBEdit and update\\fR a bookmark from editor:\n.PP\n.EX\n.IP\n.B buku -w 15012014\n.EE\n.PP\n.IP \"\" 4\nThis will open the existing bookmark's details in the editor for modifications. Environment variable \\fIEDITOR\\fR must be set.\n.PP\n.IP 7. 4\n\\fBUpdate\\fR existing bookmark at index 15012014 with new URL, tags and comments, fetch title from the web:\n.PP\n.EX\n.IP\n.B buku -u 15012014 --url http://ddg.gg/ --tag web search, utilities -c Private search engine\n.EE\n.PP\n.IP 8. 4\n\\fBFetch and update only title\\fR for bookmark at 15012014:\n.PP\n.EX\n.IP\n.B buku -u 15012014\n.EE\n.PP\n.IP 9. 4\n\\fBUpdate only comment\\fR for bookmark at 15012014:\n.PP\n.EX\n.IP\n.B buku -u 15012014 -c this is a new comment\n.EE\n.PP\n.IP \"\" 4\nApplies to --url, --title and --tag too.\n.PP\n.IP 10. 4\n\\fBExport\\fR bookmarks tagged 'tag 1' or 'tag 2' to HTML, XBEL, Markdown, Orgfile or a new database:\n.PP\n.EX\n.IP\n.B buku -e bookmarks.html --stag tag 1, tag 2\n.br\n.B buku -e bookmarks.xbel --stag tag 1, tag 2\n.br\n.B buku -e bookmarks.md --stag tag 1, tag 2\n.br\n.B buku -e bookmarks.org --stag tag 1, tag 2\n.br\n.B buku -e bookmarks.db --stag tag 1, tag 2\n.EE\n.PP\n.IP \"\" 4\nAll bookmarks are exported if search is not opted.\n.PP\n.IP 11. 4\n\\fBImport\\fR bookmarks from HTML, XBEL, Markdown or Orgfile:\n.PP\n.EX\n.IP\n.B buku -i bookmarks.html\n.br\n.B buku -i bookmarks.xbel\n.br\n.B buku -i bookmarks.md\n.br\n.B buku -i bookmarks.db\n.EE\n.PP\n.IP 12. 4\n\\fBDelete only comment\\fR for bookmark at 15012014:\n.PP\n.EX\n.IP\n.B buku -u 15012014 -c\n.EE\n.PP\n.IP \"\" 4\nApplies to --title and --tag too. URL cannot be deleted without deleting the bookmark.\n.PP\n.IP 13. 4\n\\fBUpdate\\fR or refresh \\fBfull DB\\fR with page titles from the web:\n.PP\n.EX\n.IP\n.B buku -u\n.br\n.B buku -u --tacit (show only failures and exceptions)\n.EE\n.PP\n.IP \"\" 4\nThis operation can update the title or description fields of non-immutable bookmarks by parsing the fetched page. Fields are updated only if the fetched fields are non-empty. Tags remain untouched.\n.PP\n.IP 14. 4\n\\fBDelete\\fR bookmark at index 15012014:\n.PP\n.EX\n.IP\n.B buku -d 15012014\n.EE\n.PP\n.IP \"\" 4\nThe last index is moved to the deleted index to keep the DB compact. Add --tacit to delete without confirmation.\n.PP\n.IP 15. 4\n\\fBDelete all\\fR bookmarks:\n.PP\n.EX\n.IP\n.B buku -d\n.EE\n.PP\n.IP 16. 4\n\\fBDelete\\fR a \\fBrange or list\\fR of bookmarks:\n.PP\n.EX\n.IP\n.B buku -d 100-200\n.br\n.B buku -d 100 15 200\n.EE\n.PP\n.IP 17. 4\n\\fBSearch\\fR bookmarks for \\fBANY\\fR of the keywords 'kernel' and 'debugging' in URL, title or tags:\n.PP\n.EX\n.IP\n.B buku kernel debugging\n.br\n.B buku -s kernel debugging\n.EE\n.PP\n.IP 18. 4\n\\fBSearch\\fR bookmarks with \\fBALL\\fR the keywords 'kernel' and 'debugging' in URL, title or tags:\n.PP\n.EX\n.IP\n.B buku -S kernel debugging\n.EE\n.PP\n.IP 19. 4\n\\fBSearch\\fR bookmarks \\fBtagged\\fR 'general kernel concepts':\n.PP\n.EX\n.IP\n.B buku --stag general kernel concepts\n.EE\n.PP\n.IP 20. 4\n\\fBSearch\\fR for bookmarks matching \\fBANY\\fR of the tags 'kernel', 'debugging', 'general kernel concepts':\n.PP\n.EX\n.IP\n.B buku --stag kernel, debugging, general kernel concepts\n.EE\n.PP\n.IP 21. 4\n\\fBSearch\\fR for bookmarks matching \\fBALL\\fR of the tags 'kernel', 'debugging', 'general kernel concepts':\n.PP\n.EX\n.IP\n.B buku --stag kernel + debugging + general kernel concepts\n.EE\n.PP\n.IP 22. 4\n\\fBSearch\\fR for bookmarks matching any of the keywords 'hello' or 'world', excluding the keywords 'real' and 'life', matching both the tags 'kernel' and 'debugging', but \\fBexcluding\\fR the tags 'general kernel concepts' and 'books':\n.PP\n.EX\n.IP\n.B buku hello world --exclude real life --stag 'kernel + debugging - general kernel concepts, books'\n.EE\n.PP\n.IP 23. 4\n\\fBSearch\\fR for bookmarks with different tokens for each field, and print them out sorted by the tags (ascending) and URL (descending)\n.PP\n.EX\n.IP\n.B buku --order +tags,-url --markers --sall 'global substring' '.title substring' ':url substring' :https '> description substring' '#partial,tags:' '#,exact,tags' '*another global substring'\n.EE\n.PP\n.IP 24. 4\nList \\fBall unique tags\\fR alphabetically:\n.PP\n.EX\n.IP\n.B buku --stag\n.EE\n.PP\n.IP 25. 4\nRun a \\fBsearch and update\\fR the results:\n.PP\n.EX\n.IP\n.B buku -s kernel debugging -u --tag + linux kernel\n.EE\n.PP\n.IP 26. 4\nRun a \\fBsearch and delete\\fR the results:\n.PP\n.EX\n.IP\n.B buku -s kernel debugging -d\n.EE\n.PP\n.IP 27. 4\n\\fBEncrypt or decrypt\\fR DB with \\fBcustom number of iterations\\fR (15) to generate key:\n.PP\n.EX\n.IP\n.B buku -l 15\n.br\n.B buku -k 15\n.EE\n.PP\n.IP \"\" 4\nThe same number of iterations must be specified for one lock & unlock instance. Default is 8, if omitted.\n.PP\n.IP 28. 4\n\\fBShow details\\fR of bookmarks at index 15012014 and ranges 20-30, 40-50:\n.PP\n.EX\n.IP\n.B buku -p 20-30 15012014 40-50\n.EE\n.PP\n.IP 29. 4\nShow details of the \\fBlast 10 bookmarks\\fR:\n.PP\n.EX\n.IP\n.B buku -p -10\n.EE\n.PP\n.IP 30. 4\n\\fBShow all\\fR bookmarks with real index from database:\n.PP\n.EX\n.IP\n.B buku -p\n.br\n.B buku -p | more\n.EE\n.PP\n.IP 31. 4\n\\fBReplace tag\\fR 'old tag' with 'new tag':\n.PP\n.EX\n.IP\n.B buku --replace 'old tag' 'new tag'\n.EE\n.PP\n.IP 32. 4\n\\fBDelete tag\\fR 'old tag' from DB:\n.PP\n.EX\n.IP\n.B buku --replace 'old tag'\n.EE\n.PP\n.IP 33. 4\n\\fBAppend (or delete) tags\\fR 'tag 1', 'tag 2' to (or from) existing tags of bookmark at index 15012014:\n.PP\n.EX\n.IP\n.B buku -u 15012014 --tag + tag 1, tag 2\n.br\n.B buku -u 15012014 --tag - tag 1, tag 2\n.EE\n.PP\n.IP 34. 4\n\\fBOpen URL\\fR at index 15012014 in browser:\n.PP\n.EX\n.IP\n.B buku -o 15012014\n.EE\n.PP\n.IP 35. 4\nList bookmarks with \\fBno title or tags\\fR for bookkeeping:\n.PP\n.EX\n.IP\n.B buku -S blank\n.EE\n.PP\n.IP 36. 4\nList bookmarks with \\fBimmutable title\\fR:\n.PP\n.EX\n.IP\n.B buku -S immutable\n.EE\n.PP\n.IP 37. 4\n\\fBShorten\\fR the URL www.google.com and the URL at index 20:\n.PP\n.EX\n.IP\n.B buku --shorten www.google.com\n.br\n.B buku --shorten 20\n.EE\n.PP\n.IP 38. 4\n\\fBAppend, remove tags at prompt\\fR (taglist index to the left, bookmark index to the right):\n.PP\n.EX\n.IP\n// append tags at taglist indices 4 and 6-9 to existing tags in bookmarks at indices 5 and 2-3\n.br\n.B buku (? for help) g 4 9-6 >> 5 3-2\n.br\n// set tags at taglist indices 4 and 6-9 as tags in bookmarks at indices 5 and 2-3\n.br\n.B buku (? for help) g 4 9-6 > 5 3-2\n.br\n// remove all tags from bookmarks at indices 5 and 2-3\n.br\n.B buku (? for help) g > 5 3-2\n.br\n// remove tags at taglist indices 4 and 6-9 from tags in bookmarks at indices 5 and 2-3\n.br\n.B buku (? for help) g 4 9-6 << 5 3-2\n.EE\n.PP\n.IP 39. 4\nList bookmarks with \\fBcolored output\\fR:\n.PP\n.EX\n.IP\n.B $ buku --colors oKlxm -p\n.EE\n.PP\n.IP 40. 4\nAdd a bookmark after following all permanent redirects, but only if the server doesn't respond with an error (and there's no network failure)\n.PP\n.EX\n.IP\n.B buku --add http://wikipedia.net --url-redirect --del-error\n.br\n2. Wikipedia\n.br\n   > https://www.wikipedia.org/\n.br\n   + Wikipedia is a free online encyclopedia, created and edited by volunteers around the world and hosted by the Wikimedia Foundation.\n.EE\n.PP\n.IP 41. 4\nAdd a bookmark with tag 'http redirect' if the server responds with a permanent redirect, or tag shaped like 'http 404' on an error response:\n.PP\n.EX\n.IP\n.B buku --add http://wikipedia.net/notfound --tag-redirect 'http redirect' --tag-error 'http {}'\n.br\n[ERROR] [404] Not Found\n.br\n3. Not Found\n.br\n   > http://wikipedia.net/notfound\n.br\n   # http 404,http redirect\n.EE\n.PP\n.IP 42. 4\nUpdate all bookmarks matching the search by updating the URL if the server responds with a permanent redirect, deleting the bookmark if the server responds with HTTP error 400, 401, 402, 403, 404 or 500, or adding a tag shaped like 'http:{}' in case of any other HTTP error; then export those affected by such changes into an HTML file, marking deleted records as well as old URLs for those replaced by redirect.\n.PP\n.EX\n.IP\n.B buku -S ://wikipedia.net -u --url-redirect --tag-error --del-error 400-404,500 --export-on --export backup.html\n.EE\n.PP\n.IP 43. 4\nPrint out a single \\fBrandom\\fR bookmark:\n.PP\n.EX\n.IP\n.B buku --random\n.EE\n.PP\n.IP 44. 4\nPrint out 3 \\fBrandom\\fR bookmarks \\fBordered\\fR by netloc (reversed), title and url:\n.PP\n.EX\n.IP\n.B buku --random 3 --order ,-netloc,title,+url\n.EE\n.PP\n.IP 45. 4\nPrint out a single \\fBrandom\\fR bookmark matching \\fBsearch\\fR criteria, and \\fBexport\\fR into a Markdown file (in DB order):\n.PP\n.EX\n.IP\n.B buku --random -S kernel debugging --export random.md\n.EE\n.PP\n.IP 46. 4\nSwap positions of records #4 and #5:\n.PP\n.EX\n.IP\n.B buku --swap 4 5\n.EE\n.PP\n\n\n.SH AUTHOR\nArun Prakash Jana <engineerarun@gmail.com>\n.SH HOME\n.I https://github.com/jarun/buku\n.SH WIKI\n.I https://github.com/jarun/buku/wiki\n.SH REPORTING BUGS\n.I https://github.com/jarun/buku/issues\n.SH LICENSE\nCopyright \\(co 2015-2024 Arun Prakash Jana <engineerarun@gmail.com>.\n.PP\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>.\n.br\nThis is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law.\n"
        },
        {
          "name": "bukuserver-runner",
          "type": "tree",
          "content": null
        },
        {
          "name": "bukuserver",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker-compose",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "mypy.ini",
          "type": "blob",
          "size": 0.0361328125,
          "content": "[mypy]\nignore_missing_imports = True\n"
        },
        {
          "name": "packagecore.yaml",
          "type": "blob",
          "size": 2.990234375,
          "content": "name: buku-cli\nmaintainer: Arun Prakash Jana <engineerarun@gmail.com>\nlicense: GPLv3\nsummary: Bookmark manager like a text-based mini-web.\nhomepage: https://github.com/jarun/buku\ncommands:\n  install:\n    - make PREFIX=\"/usr\" install DESTDIR=\"${BP_DESTDIR}\"\npackages:\n#  archlinux:\n#    builddeps:\n#      - make\n#    deps:\n#      - python\n#      - python-beautifulsoup4\n#      - python-certifi\n#      - python-cryptography\n#      - python-urllib3\n#    container: \"archlinux/base\"\n# centos no beautifulsoup4\n  centos7.5:\n    builddeps:\n      - make\n    deps:\n      - python\n#     - python-beautifulsoup4\n#     - python-certifi\n      - python-cryptography\n      - python-urllib3\n    commands:\n      pre:\n        - yum install epel-release\n  centos7.6:\n    builddeps:\n      - make\n    deps:\n      - python\n#     - python-beautifulsoup4\n#     - python-certifi\n      - python-cryptography\n      - python-urllib3\n  centos7.7:\n    builddeps:\n      - make\n    deps:\n      - python\n#     - python-beautifulsoup4\n#     - python-certifi\n      - python-cryptography\n      - python-urllib3\n  centos8.0:\n    builddeps:\n      - make\n    deps:\n      - python3\n#     - python3-beautifulsoup4\n#     - python3-certifi\n      - python3-cryptography\n      - python3-urllib3\n    commands:\n      precompile:\n        - dnf install python3 python3-cryptography python3-urllib3\n  debian9:\n    builddeps:\n      - make\n    deps:\n      - python3\n      - python3-bs4\n      - python3-certifi\n      - python3-cryptography\n      - python3-urllib3\n  debian10:\n    builddeps:\n      - make\n    deps:\n      - python3\n      - python3-bs4\n      - python3-certifi\n      - python3-cryptography\n      - python3-urllib3\n  fedora31:\n    builddeps:\n      - make\n    deps:\n      - python3\n      - python3-beautifulsoup4\n      - python3-certifi\n      - python3-cryptography\n      - python3-urllib3\n  fedora32:\n    builddeps:\n      - make\n    deps:\n      - python3\n      - python3-beautifulsoup4\n      - python3-certifi\n      - python3-cryptography\n      - python3-urllib3\n  opensuse15.1:\n    builddeps:\n      - make\n    deps:\n      - python3\n      - python3-beautifulsoup4\n      - python3-certifi\n      - python3-cryptography\n      - python3-urllib3\n  opensuse15.2:\n    builddeps:\n      - make\n    deps:\n      - python3\n      - python3-beautifulsoup4\n      - python3-certifi\n      - python3-cryptography\n      - python3-urllib3\n  opensuse.tumbleweed:\n    builddeps:\n      - make\n    deps:\n      - python3\n      - python3-beautifulsoup4\n      - python3-certifi\n      - python3-cryptography\n      - python3-urllib3\n  ubuntu16.04:\n    builddeps:\n      - make\n    deps:\n      - python3\n      - python3-bs4\n      - python3-certifi\n      - python3-cryptography\n      - python3-urllib3\n  ubuntu18.04:\n    builddeps:\n      - make\n    deps:\n      - python3\n      - python3-bs4\n      - python3-certifi\n      - python3-cryptography\n      - python3-urllib3\n  ubuntu20.04:\n    builddeps:\n      - make\n    deps:\n      - python3\n      - python3-bs4\n      - python3-certifi\n      - python3-cryptography\n      - python3-urllib3\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.2109375,
          "content": "# use setup.py for latest required package \nbeautifulsoup4>=4.4.1\ncertifi\ncryptography>=1.2.3\nhtml5lib>=1.0.1\nsetuptools\nurllib3>=1.23,<2\npyreadline3; sys_platform == 'win32'\ncolorama>=0.4.6; sys_platform == 'win32'\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 3.28125,
          "content": "#!/usr/bin/env python3\n\nimport os\nimport re\nimport shutil\n\nfrom setuptools import find_packages, setup\n\nif os.path.isfile('buku'):\n    shutil.copyfile('buku', 'buku.py')\n\nwith open('buku.py', encoding='utf-8') as f:\n    version = re.search('__version__ = \\'([^\\']+)\\'', f.read()).group(1)  # type: ignore\n\nwith open('README.md', encoding='utf-8') as f:\n    long_description = f.read()\n\ntests_require = [\n    'attrs>=17.4.0',\n    'beautifulsoup4>=4.6.0',\n    'Click>=7.0',\n    'flake8>=3.4.1',\n    'hypothesis>=6.0.0',\n    'mypy-extensions==0.4.1',\n    'py>=1.5.0',\n    'pylint>=1.7.2',\n    'pytest-cov',\n    'pytest-recording>=0.12.1',\n    'pytest-timeout',\n    'pytest>=6.2.1',\n    'PyYAML>=4.2b1',\n    'setuptools>=41.0.1',\n    'vcrpy>=1.13.0',\n    'lxml',\n    'flask_babel',\n]\n\n\nserver_require = [\n    \"arrow>=1.2.2\",\n    \"Flask-Admin>=1.6.1,<2\",\n    \"Flask-API>=3.0.post1\",\n    \"flask-paginate>=2022.1.8\",\n    \"Flask-WTF>=1.0.1\",\n    \"Flask>=2.2.2,<2.3\",\n    \"Jinja2>=3\",\n    \"werkzeug<2.4\",\n]\ninstall_requires = [\n    'beautifulsoup4>=4.4.1',\n    'certifi',\n    'cryptography>=1.2.3',\n    'html5lib>=1.0.1',\n    'urllib3>=1.23,<2',\n    'pyreadline3; sys_platform == \\'win32\\'',\n    'colorama>=0.4.6; sys_platform == \\'win32\\'',\n]\n\nsetup(\n    name='buku',\n    version=version,\n    description='Bookmark manager like a text-based mini-web.',\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    author='Arun Prakash Jana',\n    author_email='engineerarun@gmail.com',\n    url='https://github.com/jarun/buku',\n    license='GPLv3',\n    python_requires='>=3.8',  # requires pip>=9.0.0\n    platforms=['any'],\n    py_modules=['buku'],\n    install_requires=install_requires,\n    packages=find_packages(exclude=['tests']),\n    include_package_data=True,\n    entry_points={\n        'console_scripts': ['buku=buku:main', 'bukuserver=bukuserver.server:cli']\n    },\n    extras_require={\n        \"tests\": tests_require + server_require,\n        \"server\": server_require,\n        \"docs\": [\n            \"myst-parser>=0.17.0\",\n            \"sphinx-rtd-theme>=1.0.0\",\n            \"sphinx-autobuild>=2021.3.14\",\n        ],\n        \"packaging\": [\"twine>=1.11.0\"],\n    },\n    test_suite='tests',\n    tests_require=tests_require,\n    keywords='cli bookmarks tag utility',\n    project_urls={\n        \"Documentation\": \"https://buku.readthedocs.io/en/latest\",\n        \"Funding\": \"https://github.com/sponsors/jarun\",\n        \"Source\": \"https://github.com/jarun/buku\",\n        \"Tracker\": \"https://github.com/jarun/buku/issues\",\n    },\n    classifiers=[\n        'Development Status :: 5 - Production/Stable',\n        'Environment :: Console',\n        'Intended Audience :: Developers',\n        'Intended Audience :: End Users/Desktop',\n        'License :: OSI Approved :: GNU General Public License v3 (GPLv3)',\n        'Natural Language :: English',\n        'Operating System :: OS Independent',\n        'Programming Language :: Python :: 3',\n        'Programming Language :: Python :: 3 :: Only',\n        'Programming Language :: Python :: 3.9',\n        'Programming Language :: Python :: 3.10',\n        'Programming Language :: Python :: 3.11',\n        'Programming Language :: Python :: 3.12',\n        'Programming Language :: Python :: 3.13',\n        'Topic :: Internet :: WWW/HTTP :: Indexing/Search',\n        'Topic :: Utilities'\n    ]\n)\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "tox.bat",
          "type": "blob",
          "size": 0.0615234375,
          "content": "@if not defined BASEPYTHON set BASEPYTHON=python\r\n@tox.exe %*\r\n"
        },
        {
          "name": "tox.ini",
          "type": "blob",
          "size": 1.96875,
          "content": "[tox]\nenvlist = py39,py310,py311,py312,py313,pylint,flake8\n\n[flake8]\nmax-line-length = 139\nexclude =\n    .tox\n    build\n    venv\nignore =\n    # C901 func is too complex\n    C901,\n    # E126 continuation line over-indented for hanging indent\n    E126,\n    # E127 continuation line over-indented for visual indent\n    E127,\n    # E226 missing whitespace around arithmetic operator\n    E226,\n    # E231 missing whitespace after ','\n    E231,\n    # E302 expected 2 blank lines, found 1\n    E302,\n    # E305 expected 2 blank lines after class or function definition, found 1\n    E305,\n    # E731 do not assign a lambda expression, use a def\n    E731,\n    # W292 no newline at end of file\n    W292,\n    # W504 line break after binary operator\n    W504,\n    # E203 whitespace before :\n    E203,\n\n[pytest]\ntimeout = 10\ntimeout_method = thread\nmarkers =\n  non_tox: not run on tox\n  slow: slow tests\n  gui: GUI (functional) tests\n\n[testenv]\nusedevelop = true\ndeps = pytest\n\n[testenv:py39]\nextras = tests\ncommands =\n    pytest --cov buku -vv -m \"not non_tox\" {posargs}\n\n[testenv:py310]\nextras = tests\ncommands =\n    pytest --cov buku -vv -m \"not non_tox\" {posargs}\n\n[testenv:py311]\nextras = tests\ncommands =\n    pytest --cov buku -vv -m \"not non_tox\" {posargs}\n\n[testenv:py312]\nextras = tests\ncommands =\n    pytest --cov buku -vv -m \"not non_tox\" {posargs}\n\n[testenv:py313]\nextras = tests\ncommands =\n    pytest --cov buku -vv -m \"not non_tox\" {posargs}\n\n[testenv:quick]\nbasepython = {env:BASEPYTHON:py312}\nextras = tests\ncommands =\n    pytest --cov buku -vv -m \"not non_tox and not slow\" {posargs}\n\n[testenv:nogui]\nbasepython = {env:BASEPYTHON:py312}\nextras = tests\ncommands =\n    pytest --cov buku -vv -m \"not non_tox and not gui\" {posargs}\n\n[testenv:pylint]\nbasepython = {env:BASEPYTHON:py312}\ndeps =\n    pylint\n    .[tests]\ncommands =\n    pylint . --rc-file tests/.pylintrc --recursive yes --ignore-paths .tox/,build/,venv/\n\n[testenv:flake8]\nbasepython = {env:BASEPYTHON:py312}\ndeps = flake8\ncommands =\n    python -m flake8\n"
        }
      ]
    }
  ]
}