{
  "metadata": {
    "timestamp": 1736561009706,
    "page": 769,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjc3MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "david-gpu/srez",
      "stars": 5296,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.04296875,
          "content": "__pycache__/\ncheckpoint*/\ndataset/\ntrain*/\n\n"
        },
        {
          "name": "LICENSE.md",
          "type": "blob",
          "size": 1.0439453125,
          "content": "MIT License\n\nCopyright (c) 2016 David Garcia\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 2.9140625,
          "content": "# srez\n\nImage super-resolution through deep learning. This project uses deep learning to upscale 16x16 images by a 4x factor. The resulting 64x64 images display sharp features that are plausible based on the dataset that was used to train the neural net.\n\nHere's an random, non cherry-picked, example of what this network can do. From left to right, the first column is the 16x16 input image, the second one is what you would get from a standard bicubic interpolation, the third is the output generated by the neural net, and on the right is the ground truth.\n\n![Example output](srez_sample_output.png)\n\nAs you can see, the network is able to produce a very plausible reconstruction of the original face. As the dataset is mainly composed of well-illuminated faces looking straight ahead, the reconstruction is poorer when the face is at an angle, poorly illuminated, or partially occluded by eyeglasses or hands.\n\nThis particular example was produced after training the network for 3 hours on a GTX 1080 GPU, equivalent to 130,000 batches or about 10 epochs.\n\n# How it works\n\nIn essence the architecture is a DCGAN where the input to the generator network is the 16x16 image rather than a multinomial gaussian distribution.\n\nIn addition to that the loss function of the generator has a term that measures the L1 difference between the 16x16 input and downscaled version of the image produced by the generator.\n\nThe adversarial term of the loss function ensures the generator produces plausible faces, while the L1 term ensures that those faces resemble the low-res input data. We have found that this L1 term greatly accelerates the convergence of the network during the first batches and also appears to prevent the generator from getting stuck in a poor local solution.\n\nFinally, the generator network relies on ResNet modules as we've found them to train substantially faster than more old-fashioned architectures. The adversarial network is much simpler as the use of ResNet modules did not provide an advantage during our experimentation.\n\n# Requirements\n\nYou will need Python 3 with Tensorflow, numpy, scipy and [moviepy](http://zulko.github.io/moviepy/). See `requirements.txt` for details.\n\n## Dataset\n\nAfter you have the required software above you will also need the `Large-scale CelebFaces Attributes (CelebA) Dataset`. The model expects the `Align&Cropped Images` version. Extract all images to a subfolder named `dataset`. I.e. `srez/dataset/lotsoffiles.jpg`.\n\n# Training the model\n\nTraining with default settings: `python3 srez_main.py --run train`. The script will periodically output an example batch in PNG format onto the `srez/train` folder, and checkpoint data will be stored in the `srez/checkpoint` folder.\n\nAfter the network has trained you can also produce an animation showing the evolution of the output by running `python3 srez_main.py --run demo`.\n\n# About the author\n\n[LinkedIn profile of David Garcia](https://ca.linkedin.com/in/david-garcia-70913311).\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.078125,
          "content": "moviepy==0.2.2.11\nnumpy==1.11.1\nscipy==0.18.0\nsix==1.10.0\ntensorflow==0.10.0rc0\n"
        },
        {
          "name": "srez_demo.py",
          "type": "blob",
          "size": 0.7373046875,
          "content": "import moviepy.editor as mpe\nimport numpy as np\nimport numpy.random\nimport os.path\nimport scipy.misc\nimport tensorflow as tf\n\nFLAGS = tf.app.flags.FLAGS\n\ndef demo1(sess):\n    \"\"\"Demo based on images dumped during training\"\"\"\n\n    # Get images that were dumped during training\n    filenames = tf.gfile.ListDirectory(FLAGS.train_dir)\n    filenames = sorted(filenames)\n    filenames = [os.path.join(FLAGS.train_dir, f) for f in filenames if f[-4:]=='.png']\n\n    assert len(filenames) >= 1\n\n    fps        = 30\n\n    # Create video file from PNGs\n    print(\"Producing video file...\")\n    filename  = os.path.join(FLAGS.train_dir, 'demo1.mp4')\n    clip      = mpe.ImageSequenceClip(filenames, fps=fps)\n    clip.write_videofile(filename)\n    print(\"Done!\")\n    \n"
        },
        {
          "name": "srez_input.py",
          "type": "blob",
          "size": 1.92578125,
          "content": "import tensorflow as tf\n\nFLAGS = tf.app.flags.FLAGS\n\ndef setup_inputs(sess, filenames, image_size=None, capacity_factor=3):\n\n    if image_size is None:\n        image_size = FLAGS.sample_size\n    \n    # Read each JPEG file\n    reader = tf.WholeFileReader()\n    filename_queue = tf.train.string_input_producer(filenames)\n    key, value = reader.read(filename_queue)\n    channels = 3\n    image = tf.image.decode_jpeg(value, channels=channels, name=\"dataset_image\")\n    image.set_shape([None, None, channels])\n\n    # Crop and other random augmentations\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_saturation(image, .95, 1.05)\n    image = tf.image.random_brightness(image, .05)\n    image = tf.image.random_contrast(image, .95, 1.05)\n\n    wiggle = 8\n    off_x, off_y = 25-wiggle, 60-wiggle\n    crop_size = 128\n    crop_size_plus = crop_size + 2*wiggle\n    image = tf.image.crop_to_bounding_box(image, off_y, off_x, crop_size_plus, crop_size_plus)\n    image = tf.random_crop(image, [crop_size, crop_size, 3])\n\n    image = tf.reshape(image, [1, crop_size, crop_size, 3])\n    image = tf.cast(image, tf.float32)/255.0\n\n    if crop_size != image_size:\n        image = tf.image.resize_area(image, [image_size, image_size])\n\n    # The feature is simply a Kx downscaled version\n    K = 4\n    downsampled = tf.image.resize_area(image, [image_size//K, image_size//K])\n\n    feature = tf.reshape(downsampled, [image_size//K, image_size//K, 3])\n    label   = tf.reshape(image,       [image_size,   image_size,     3])\n\n    # Using asynchronous queues\n    features, labels = tf.train.batch([feature, label],\n                                      batch_size=FLAGS.batch_size,\n                                      num_threads=4,\n                                      capacity = capacity_factor*FLAGS.batch_size,\n                                      name='labels_and_features')\n\n    tf.train.start_queue_runners(sess=sess)\n      \n    return features, labels\n"
        },
        {
          "name": "srez_main.py",
          "type": "blob",
          "size": 6.2958984375,
          "content": "import srez_demo\nimport srez_input\nimport srez_model\nimport srez_train\n\nimport os.path\nimport random\nimport numpy as np\nimport numpy.random\n\nimport tensorflow as tf\n\nFLAGS = tf.app.flags.FLAGS\n\n# Configuration (alphabetically)\ntf.app.flags.DEFINE_integer('batch_size', 16,\n                            \"Number of samples per batch.\")\n\ntf.app.flags.DEFINE_string('checkpoint_dir', 'checkpoint',\n                           \"Output folder where checkpoints are dumped.\")\n\ntf.app.flags.DEFINE_integer('checkpoint_period', 10000,\n                            \"Number of batches in between checkpoints\")\n\ntf.app.flags.DEFINE_string('dataset', 'dataset',\n                           \"Path to the dataset directory.\")\n\ntf.app.flags.DEFINE_float('epsilon', 1e-8,\n                          \"Fuzz term to avoid numerical instability\")\n\ntf.app.flags.DEFINE_string('run', 'demo',\n                            \"Which operation to run. [demo|train]\")\n\ntf.app.flags.DEFINE_float('gene_l1_factor', .90,\n                          \"Multiplier for generator L1 loss term\")\n\ntf.app.flags.DEFINE_float('learning_beta1', 0.5,\n                          \"Beta1 parameter used for AdamOptimizer\")\n\ntf.app.flags.DEFINE_float('learning_rate_start', 0.00020,\n                          \"Starting learning rate used for AdamOptimizer\")\n\ntf.app.flags.DEFINE_integer('learning_rate_half_life', 5000,\n                            \"Number of batches until learning rate is halved\")\n\ntf.app.flags.DEFINE_bool('log_device_placement', False,\n                         \"Log the device where variables are placed.\")\n\ntf.app.flags.DEFINE_integer('sample_size', 64,\n                            \"Image sample size in pixels. Range [64,128]\")\n\ntf.app.flags.DEFINE_integer('summary_period', 200,\n                            \"Number of batches between summary data dumps\")\n\ntf.app.flags.DEFINE_integer('random_seed', 0,\n                            \"Seed used to initialize rng.\")\n\ntf.app.flags.DEFINE_integer('test_vectors', 16,\n                            \"\"\"Number of features to use for testing\"\"\")\n                            \ntf.app.flags.DEFINE_string('train_dir', 'train',\n                           \"Output folder where training logs are dumped.\")\n\ntf.app.flags.DEFINE_integer('train_time', 20,\n                            \"Time in minutes to train the model\")\n\ndef prepare_dirs(delete_train_dir=False):\n    # Create checkpoint dir (do not delete anything)\n    if not tf.gfile.Exists(FLAGS.checkpoint_dir):\n        tf.gfile.MakeDirs(FLAGS.checkpoint_dir)\n    \n    # Cleanup train dir\n    if delete_train_dir:\n        if tf.gfile.Exists(FLAGS.train_dir):\n            tf.gfile.DeleteRecursively(FLAGS.train_dir)\n        tf.gfile.MakeDirs(FLAGS.train_dir)\n\n    # Return names of training files\n    if not tf.gfile.Exists(FLAGS.dataset) or \\\n       not tf.gfile.IsDirectory(FLAGS.dataset):\n        raise FileNotFoundError(\"Could not find folder `%s'\" % (FLAGS.dataset,))\n\n    filenames = tf.gfile.ListDirectory(FLAGS.dataset)\n    filenames = sorted(filenames)\n    random.shuffle(filenames)\n    filenames = [os.path.join(FLAGS.dataset, f) for f in filenames]\n\n    return filenames\n\n\ndef setup_tensorflow():\n    # Create session\n    config = tf.ConfigProto(log_device_placement=FLAGS.log_device_placement)\n    sess = tf.Session(config=config)\n\n    # Initialize rng with a deterministic seed\n    with sess.graph.as_default():\n        tf.set_random_seed(FLAGS.random_seed)\n        \n    random.seed(FLAGS.random_seed)\n    np.random.seed(FLAGS.random_seed)\n\n    summary_writer = tf.train.SummaryWriter(FLAGS.train_dir, sess.graph)\n\n    return sess, summary_writer\n\ndef _demo():\n    # Load checkpoint\n    if not tf.gfile.IsDirectory(FLAGS.checkpoint_dir):\n        raise FileNotFoundError(\"Could not find folder `%s'\" % (FLAGS.checkpoint_dir,))\n\n    # Setup global tensorflow state\n    sess, summary_writer = setup_tensorflow()\n\n    # Prepare directories\n    filenames = prepare_dirs(delete_train_dir=False)\n\n    # Setup async input queues\n    features, labels = srez_input.setup_inputs(sess, filenames)\n\n    # Create and initialize model\n    [gene_minput, gene_moutput,\n     gene_output, gene_var_list,\n     disc_real_output, disc_fake_output, disc_var_list] = \\\n            srez_model.create_model(sess, features, labels)\n\n    # Restore variables from checkpoint\n    saver = tf.train.Saver()\n    filename = 'checkpoint_new.txt'\n    filename = os.path.join(FLAGS.checkpoint_dir, filename)\n    saver.restore(sess, filename)\n\n    # Execute demo\n    srez_demo.demo1(sess)\n\nclass TrainData(object):\n    def __init__(self, dictionary):\n        self.__dict__.update(dictionary)\n\ndef _train():\n    # Setup global tensorflow state\n    sess, summary_writer = setup_tensorflow()\n\n    # Prepare directories\n    all_filenames = prepare_dirs(delete_train_dir=True)\n\n    # Separate training and test sets\n    train_filenames = all_filenames[:-FLAGS.test_vectors]\n    test_filenames  = all_filenames[-FLAGS.test_vectors:]\n\n    # TBD: Maybe download dataset here\n\n    # Setup async input queues\n    train_features, train_labels = srez_input.setup_inputs(sess, train_filenames)\n    test_features,  test_labels  = srez_input.setup_inputs(sess, test_filenames)\n\n    # Add some noise during training (think denoising autoencoders)\n    noise_level = .03\n    noisy_train_features = train_features + \\\n                           tf.random_normal(train_features.get_shape(), stddev=noise_level)\n\n    # Create and initialize model\n    [gene_minput, gene_moutput,\n     gene_output, gene_var_list,\n     disc_real_output, disc_fake_output, disc_var_list] = \\\n            srez_model.create_model(sess, noisy_train_features, train_labels)\n\n    gene_loss = srez_model.create_generator_loss(disc_fake_output, gene_output, train_features)\n    disc_real_loss, disc_fake_loss = \\\n                     srez_model.create_discriminator_loss(disc_real_output, disc_fake_output)\n    disc_loss = tf.add(disc_real_loss, disc_fake_loss, name='disc_loss')\n    \n    (global_step, learning_rate, gene_minimize, disc_minimize) = \\\n            srez_model.create_optimizers(gene_loss, gene_var_list,\n                                         disc_loss, disc_var_list)\n\n    # Train model\n    train_data = TrainData(locals())\n    srez_train.train_model(train_data)\n\ndef main(argv=None):\n    # Training or showing off?\n\n    if FLAGS.run == 'demo':\n        _demo()\n    elif FLAGS.run == 'train':\n        _train()\n\nif __name__ == '__main__':\n  tf.app.run()\n"
        },
        {
          "name": "srez_model.py",
          "type": "blob",
          "size": 18.458984375,
          "content": "import numpy as np\nimport tensorflow as tf\n\nFLAGS = tf.app.flags.FLAGS\n\nclass Model:\n    \"\"\"A neural network model.\n\n    Currently only supports a feedforward architecture.\"\"\"\n    \n    def __init__(self, name, features):\n        self.name = name\n        self.outputs = [features]\n\n    def _get_layer_str(self, layer=None):\n        if layer is None:\n            layer = self.get_num_layers()\n        \n        return '%s_L%03d' % (self.name, layer+1)\n\n    def _get_num_inputs(self):\n        return int(self.get_output().get_shape()[-1])\n\n    def _glorot_initializer(self, prev_units, num_units, stddev_factor=1.0):\n        \"\"\"Initialization in the style of Glorot 2010.\n\n        stddev_factor should be 1.0 for linear activations, and 2.0 for ReLUs\"\"\"\n        stddev  = np.sqrt(stddev_factor / np.sqrt(prev_units*num_units))\n        return tf.truncated_normal([prev_units, num_units],\n                                    mean=0.0, stddev=stddev)\n\n    def _glorot_initializer_conv2d(self, prev_units, num_units, mapsize, stddev_factor=1.0):\n        \"\"\"Initialization in the style of Glorot 2010.\n\n        stddev_factor should be 1.0 for linear activations, and 2.0 for ReLUs\"\"\"\n\n        stddev  = np.sqrt(stddev_factor / (np.sqrt(prev_units*num_units)*mapsize*mapsize))\n        return tf.truncated_normal([mapsize, mapsize, prev_units, num_units],\n                                    mean=0.0, stddev=stddev)\n\n    def get_num_layers(self):\n        return len(self.outputs)\n\n    def add_batch_norm(self, scale=False):\n        \"\"\"Adds a batch normalization layer to this model.\n\n        See ArXiv 1502.03167v3 for details.\"\"\"\n\n        # TBD: This appears to be very flaky, often raising InvalidArgumentError internally\n        with tf.variable_scope(self._get_layer_str()):\n            out = tf.contrib.layers.batch_norm(self.get_output(), scale=scale)\n        \n        self.outputs.append(out)\n        return self\n\n    def add_flatten(self):\n        \"\"\"Transforms the output of this network to a 1D tensor\"\"\"\n\n        with tf.variable_scope(self._get_layer_str()):\n            batch_size = int(self.get_output().get_shape()[0])\n            out = tf.reshape(self.get_output(), [batch_size, -1])\n\n        self.outputs.append(out)\n        return self\n\n    def add_dense(self, num_units, stddev_factor=1.0):\n        \"\"\"Adds a dense linear layer to this model.\n\n        Uses Glorot 2010 initialization assuming linear activation.\"\"\"\n        \n        assert len(self.get_output().get_shape()) == 2, \"Previous layer must be 2-dimensional (batch, channels)\"\n\n        with tf.variable_scope(self._get_layer_str()):\n            prev_units = self._get_num_inputs()\n            \n            # Weight term\n            initw   = self._glorot_initializer(prev_units, num_units,\n                                               stddev_factor=stddev_factor)\n            weight  = tf.get_variable('weight', initializer=initw)\n\n            # Bias term\n            initb   = tf.constant(0.0, shape=[num_units])\n            bias    = tf.get_variable('bias', initializer=initb)\n\n            # Output of this layer\n            out     = tf.matmul(self.get_output(), weight) + bias\n\n        self.outputs.append(out)\n        return self\n\n    def add_sigmoid(self):\n        \"\"\"Adds a sigmoid (0,1) activation function layer to this model.\"\"\"\n\n        with tf.variable_scope(self._get_layer_str()):\n            prev_units = self._get_num_inputs()\n            out = tf.nn.sigmoid(self.get_output())\n        \n        self.outputs.append(out)\n        return self\n\n    def add_softmax(self):\n        \"\"\"Adds a softmax operation to this model\"\"\"\n\n        with tf.variable_scope(self._get_layer_str()):\n            this_input = tf.square(self.get_output())\n            reduction_indices = list(range(1, len(this_input.get_shape())))\n            acc = tf.reduce_sum(this_input, reduction_indices=reduction_indices, keep_dims=True)\n            out = this_input / (acc+FLAGS.epsilon)\n            #out = tf.verify_tensor_all_finite(out, \"add_softmax failed; is sum equal to zero?\")\n        \n        self.outputs.append(out)\n        return self\n\n    def add_relu(self):\n        \"\"\"Adds a ReLU activation function to this model\"\"\"\n\n        with tf.variable_scope(self._get_layer_str()):\n            out = tf.nn.relu(self.get_output())\n\n        self.outputs.append(out)\n        return self        \n\n    def add_elu(self):\n        \"\"\"Adds a ELU activation function to this model\"\"\"\n\n        with tf.variable_scope(self._get_layer_str()):\n            out = tf.nn.elu(self.get_output())\n\n        self.outputs.append(out)\n        return self\n\n    def add_lrelu(self, leak=.2):\n        \"\"\"Adds a leaky ReLU (LReLU) activation function to this model\"\"\"\n\n        with tf.variable_scope(self._get_layer_str()):\n            t1  = .5 * (1 + leak)\n            t2  = .5 * (1 - leak)\n            out = t1 * self.get_output() + \\\n                  t2 * tf.abs(self.get_output())\n            \n        self.outputs.append(out)\n        return self\n\n    def add_conv2d(self, num_units, mapsize=1, stride=1, stddev_factor=1.0):\n        \"\"\"Adds a 2D convolutional layer.\"\"\"\n\n        assert len(self.get_output().get_shape()) == 4 and \"Previous layer must be 4-dimensional (batch, width, height, channels)\"\n        \n        with tf.variable_scope(self._get_layer_str()):\n            prev_units = self._get_num_inputs()\n            \n            # Weight term and convolution\n            initw  = self._glorot_initializer_conv2d(prev_units, num_units,\n                                                     mapsize,\n                                                     stddev_factor=stddev_factor)\n            weight = tf.get_variable('weight', initializer=initw)\n            out    = tf.nn.conv2d(self.get_output(), weight,\n                                  strides=[1, stride, stride, 1],\n                                  padding='SAME')\n\n            # Bias term\n            initb  = tf.constant(0.0, shape=[num_units])\n            bias   = tf.get_variable('bias', initializer=initb)\n            out    = tf.nn.bias_add(out, bias)\n            \n        self.outputs.append(out)\n        return self\n\n    def add_conv2d_transpose(self, num_units, mapsize=1, stride=1, stddev_factor=1.0):\n        \"\"\"Adds a transposed 2D convolutional layer\"\"\"\n\n        assert len(self.get_output().get_shape()) == 4 and \"Previous layer must be 4-dimensional (batch, width, height, channels)\"\n\n        with tf.variable_scope(self._get_layer_str()):\n            prev_units = self._get_num_inputs()\n            \n            # Weight term and convolution\n            initw  = self._glorot_initializer_conv2d(prev_units, num_units,\n                                                     mapsize,\n                                                     stddev_factor=stddev_factor)\n            weight = tf.get_variable('weight', initializer=initw)\n            weight = tf.transpose(weight, perm=[0, 1, 3, 2])\n            prev_output = self.get_output()\n            output_shape = [FLAGS.batch_size,\n                            int(prev_output.get_shape()[1]) * stride,\n                            int(prev_output.get_shape()[2]) * stride,\n                            num_units]\n            out    = tf.nn.conv2d_transpose(self.get_output(), weight,\n                                            output_shape=output_shape,\n                                            strides=[1, stride, stride, 1],\n                                            padding='SAME')\n\n            # Bias term\n            initb  = tf.constant(0.0, shape=[num_units])\n            bias   = tf.get_variable('bias', initializer=initb)\n            out    = tf.nn.bias_add(out, bias)\n            \n        self.outputs.append(out)\n        return self\n\n    def add_residual_block(self, num_units, mapsize=3, num_layers=2, stddev_factor=1e-3):\n        \"\"\"Adds a residual block as per Arxiv 1512.03385, Figure 3\"\"\"\n\n        assert len(self.get_output().get_shape()) == 4 and \"Previous layer must be 4-dimensional (batch, width, height, channels)\"\n\n        # Add projection in series if needed prior to shortcut\n        if num_units != int(self.get_output().get_shape()[3]):\n            self.add_conv2d(num_units, mapsize=1, stride=1, stddev_factor=1.)\n\n        bypass = self.get_output()\n\n        # Residual block\n        for _ in range(num_layers):\n            self.add_batch_norm()\n            self.add_relu()\n            self.add_conv2d(num_units, mapsize=mapsize, stride=1, stddev_factor=stddev_factor)\n\n        self.add_sum(bypass)\n\n        return self\n\n    def add_bottleneck_residual_block(self, num_units, mapsize=3, stride=1, transpose=False):\n        \"\"\"Adds a bottleneck residual block as per Arxiv 1512.03385, Figure 3\"\"\"\n\n        assert len(self.get_output().get_shape()) == 4 and \"Previous layer must be 4-dimensional (batch, width, height, channels)\"\n\n        # Add projection in series if needed prior to shortcut\n        if num_units != int(self.get_output().get_shape()[3]) or stride != 1:\n            ms = 1 if stride == 1 else mapsize\n            #bypass.add_batch_norm() # TBD: Needed?\n            if transpose:\n                self.add_conv2d_transpose(num_units, mapsize=ms, stride=stride, stddev_factor=1.)\n            else:\n                self.add_conv2d(num_units, mapsize=ms, stride=stride, stddev_factor=1.)\n\n        bypass = self.get_output()\n\n        # Bottleneck residual block\n        self.add_batch_norm()\n        self.add_relu()\n        self.add_conv2d(num_units//4, mapsize=1,       stride=1,      stddev_factor=2.)\n\n        self.add_batch_norm()\n        self.add_relu()\n        if transpose:\n            self.add_conv2d_transpose(num_units//4,\n                                      mapsize=mapsize,\n                                      stride=1,\n                                      stddev_factor=2.)\n        else:\n            self.add_conv2d(num_units//4,\n                            mapsize=mapsize,\n                            stride=1,\n                            stddev_factor=2.)\n\n        self.add_batch_norm()\n        self.add_relu()\n        self.add_conv2d(num_units,    mapsize=1,       stride=1,      stddev_factor=2.)\n\n        self.add_sum(bypass)\n\n        return self\n\n    def add_sum(self, term):\n        \"\"\"Adds a layer that sums the top layer with the given term\"\"\"\n\n        with tf.variable_scope(self._get_layer_str()):\n            prev_shape = self.get_output().get_shape()\n            term_shape = term.get_shape()\n            #print(\"%s %s\" % (prev_shape, term_shape))\n            assert prev_shape == term_shape and \"Can't sum terms with a different size\"\n            out = tf.add(self.get_output(), term)\n        \n        self.outputs.append(out)\n        return self\n\n    def add_mean(self):\n        \"\"\"Adds a layer that averages the inputs from the previous layer\"\"\"\n\n        with tf.variable_scope(self._get_layer_str()):\n            prev_shape = self.get_output().get_shape()\n            reduction_indices = list(range(len(prev_shape)))\n            assert len(reduction_indices) > 2 and \"Can't average a (batch, activation) tensor\"\n            reduction_indices = reduction_indices[1:-1]\n            out = tf.reduce_mean(self.get_output(), reduction_indices=reduction_indices)\n        \n        self.outputs.append(out)\n        return self\n\n    def add_upscale(self):\n        \"\"\"Adds a layer that upscales the output by 2x through nearest neighbor interpolation\"\"\"\n\n        prev_shape = self.get_output().get_shape()\n        size = [2 * int(s) for s in prev_shape[1:3]]\n        out  = tf.image.resize_nearest_neighbor(self.get_output(), size)\n\n        self.outputs.append(out)\n        return self        \n\n    def get_output(self):\n        \"\"\"Returns the output from the topmost layer of the network\"\"\"\n        return self.outputs[-1]\n\n    def get_variable(self, layer, name):\n        \"\"\"Returns a variable given its layer and name.\n\n        The variable must already exist.\"\"\"\n\n        scope      = self._get_layer_str(layer)\n        collection = tf.get_collection(tf.GraphKeys.VARIABLES, scope=scope)\n\n        # TBD: Ugly!\n        for var in collection:\n            if var.name[:-2] == scope+'/'+name:\n                return var\n\n        return None\n\n    def get_all_layer_variables(self, layer):\n        \"\"\"Returns all variables in the given layer\"\"\"\n        scope = self._get_layer_str(layer)\n        return tf.get_collection(tf.GraphKeys.VARIABLES, scope=scope)\n\ndef _discriminator_model(sess, features, disc_input):\n    # Fully convolutional model\n    mapsize = 3\n    layers  = [64, 128, 256, 512]\n\n    old_vars = tf.all_variables()\n\n    model = Model('DIS', 2*disc_input - 1)\n\n    for layer in range(len(layers)):\n        nunits = layers[layer]\n        stddev_factor = 2.0\n\n        model.add_conv2d(nunits, mapsize=mapsize, stride=2, stddev_factor=stddev_factor)\n        model.add_batch_norm()\n        model.add_relu()\n\n    # Finalization a la \"all convolutional net\"\n    model.add_conv2d(nunits, mapsize=mapsize, stride=1, stddev_factor=stddev_factor)\n    model.add_batch_norm()\n    model.add_relu()\n\n    model.add_conv2d(nunits, mapsize=1, stride=1, stddev_factor=stddev_factor)\n    model.add_batch_norm()\n    model.add_relu()\n\n    # Linearly map to real/fake and return average score\n    # (softmax will be applied later)\n    model.add_conv2d(1, mapsize=1, stride=1, stddev_factor=stddev_factor)\n    model.add_mean()\n\n    new_vars  = tf.all_variables()\n    disc_vars = list(set(new_vars) - set(old_vars))\n\n    return model.get_output(), disc_vars\n\ndef _generator_model(sess, features, labels, channels):\n    # Upside-down all-convolutional resnet\n\n    mapsize = 3\n    res_units  = [256, 128, 96]\n\n    old_vars = tf.all_variables()\n\n    # See Arxiv 1603.05027\n    model = Model('GEN', features)\n\n    for ru in range(len(res_units)-1):\n        nunits  = res_units[ru]\n\n        for j in range(2):\n            model.add_residual_block(nunits, mapsize=mapsize)\n\n        # Spatial upscale (see http://distill.pub/2016/deconv-checkerboard/)\n        # and transposed convolution\n        model.add_upscale()\n        \n        model.add_batch_norm()\n        model.add_relu()\n        model.add_conv2d_transpose(nunits, mapsize=mapsize, stride=1, stddev_factor=1.)\n\n    # Finalization a la \"all convolutional net\"\n    nunits = res_units[-1]\n    model.add_conv2d(nunits, mapsize=mapsize, stride=1, stddev_factor=2.)\n    # Worse: model.add_batch_norm()\n    model.add_relu()\n\n    model.add_conv2d(nunits, mapsize=1, stride=1, stddev_factor=2.)\n    # Worse: model.add_batch_norm()\n    model.add_relu()\n\n    # Last layer is sigmoid with no batch normalization\n    model.add_conv2d(channels, mapsize=1, stride=1, stddev_factor=1.)\n    model.add_sigmoid()\n    \n    new_vars  = tf.all_variables()\n    gene_vars = list(set(new_vars) - set(old_vars))\n\n    return model.get_output(), gene_vars\n\ndef create_model(sess, features, labels):\n    # Generator\n    rows      = int(features.get_shape()[1])\n    cols      = int(features.get_shape()[2])\n    channels  = int(features.get_shape()[3])\n\n    gene_minput = tf.placeholder(tf.float32, shape=[FLAGS.batch_size, rows, cols, channels])\n\n    # TBD: Is there a better way to instance the generator?\n    with tf.variable_scope('gene') as scope:\n        gene_output, gene_var_list = \\\n                    _generator_model(sess, features, labels, channels)\n\n        scope.reuse_variables()\n\n        gene_moutput, _ = _generator_model(sess, gene_minput, labels, channels)\n    \n    # Discriminator with real data\n    disc_real_input = tf.identity(labels, name='disc_real_input')\n\n    # TBD: Is there a better way to instance the discriminator?\n    with tf.variable_scope('disc') as scope:\n        disc_real_output, disc_var_list = \\\n                _discriminator_model(sess, features, disc_real_input)\n\n        scope.reuse_variables()\n            \n        disc_fake_output, _ = _discriminator_model(sess, features, gene_output)\n\n    return [gene_minput,      gene_moutput,\n            gene_output,      gene_var_list,\n            disc_real_output, disc_fake_output, disc_var_list]\n\ndef _downscale(images, K):\n    \"\"\"Differentiable image downscaling by a factor of K\"\"\"\n    arr = np.zeros([K, K, 3, 3])\n    arr[:,:,0,0] = 1.0/(K*K)\n    arr[:,:,1,1] = 1.0/(K*K)\n    arr[:,:,2,2] = 1.0/(K*K)\n    dowscale_weight = tf.constant(arr, dtype=tf.float32)\n    \n    downscaled = tf.nn.conv2d(images, dowscale_weight,\n                              strides=[1, K, K, 1],\n                              padding='SAME')\n    return downscaled\n\ndef create_generator_loss(disc_output, gene_output, features):\n    # I.e. did we fool the discriminator?\n    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(disc_output, tf.ones_like(disc_output))\n    gene_ce_loss  = tf.reduce_mean(cross_entropy, name='gene_ce_loss')\n\n    # I.e. does the result look like the feature?\n    K = int(gene_output.get_shape()[1])//int(features.get_shape()[1])\n    assert K == 2 or K == 4 or K == 8    \n    downscaled = _downscale(gene_output, K)\n    \n    gene_l1_loss  = tf.reduce_mean(tf.abs(downscaled - features), name='gene_l1_loss')\n\n    gene_loss     = tf.add((1.0 - FLAGS.gene_l1_factor) * gene_ce_loss,\n                           FLAGS.gene_l1_factor * gene_l1_loss, name='gene_loss')\n    \n    return gene_loss\n\ndef create_discriminator_loss(disc_real_output, disc_fake_output):\n    # I.e. did we correctly identify the input as real or not?\n    cross_entropy_real = tf.nn.sigmoid_cross_entropy_with_logits(disc_real_output, tf.ones_like(disc_real_output))\n    disc_real_loss     = tf.reduce_mean(cross_entropy_real, name='disc_real_loss')\n    \n    cross_entropy_fake = tf.nn.sigmoid_cross_entropy_with_logits(disc_fake_output, tf.zeros_like(disc_fake_output))\n    disc_fake_loss     = tf.reduce_mean(cross_entropy_fake, name='disc_fake_loss')\n\n    return disc_real_loss, disc_fake_loss\n\ndef create_optimizers(gene_loss, gene_var_list,\n                      disc_loss, disc_var_list):    \n    # TBD: Does this global step variable need to be manually incremented? I think so.\n    global_step    = tf.Variable(0, dtype=tf.int64,   trainable=False, name='global_step')\n    learning_rate  = tf.placeholder(dtype=tf.float32, name='learning_rate')\n    \n    gene_opti = tf.train.AdamOptimizer(learning_rate=learning_rate,\n                                       beta1=FLAGS.learning_beta1,\n                                       name='gene_optimizer')\n    disc_opti = tf.train.AdamOptimizer(learning_rate=learning_rate,\n                                       beta1=FLAGS.learning_beta1,\n                                       name='disc_optimizer')\n\n    gene_minimize = gene_opti.minimize(gene_loss, var_list=gene_var_list, name='gene_loss_minimize', global_step=global_step)\n    \n    disc_minimize     = disc_opti.minimize(disc_loss, var_list=disc_var_list, name='disc_loss_minimize', global_step=global_step)\n    \n    return (global_step, learning_rate, gene_minimize, disc_minimize)\n"
        },
        {
          "name": "srez_sample_output.png",
          "type": "blob",
          "size": 188.884765625,
          "content": null
        },
        {
          "name": "srez_train.py",
          "type": "blob",
          "size": 3.5693359375,
          "content": "import numpy as np\nimport os.path\nimport scipy.misc\nimport tensorflow as tf\nimport time\n\nFLAGS = tf.app.flags.FLAGS\n\ndef _summarize_progress(train_data, feature, label, gene_output, batch, suffix, max_samples=8):\n    td = train_data\n\n    size = [label.shape[1], label.shape[2]]\n\n    nearest = tf.image.resize_nearest_neighbor(feature, size)\n    nearest = tf.maximum(tf.minimum(nearest, 1.0), 0.0)\n\n    bicubic = tf.image.resize_bicubic(feature, size)\n    bicubic = tf.maximum(tf.minimum(bicubic, 1.0), 0.0)\n\n    clipped = tf.maximum(tf.minimum(gene_output, 1.0), 0.0)\n\n    image   = tf.concat(2, [nearest, bicubic, clipped, label])\n\n    image = image[0:max_samples,:,:,:]\n    image = tf.concat(0, [image[i,:,:,:] for i in range(max_samples)])\n    image = td.sess.run(image)\n\n    filename = 'batch%06d_%s.png' % (batch, suffix)\n    filename = os.path.join(FLAGS.train_dir, filename)\n    scipy.misc.toimage(image, cmin=0., cmax=1.).save(filename)\n    print(\"    Saved %s\" % (filename,))\n\ndef _save_checkpoint(train_data, batch):\n    td = train_data\n\n    oldname = 'checkpoint_old.txt'\n    newname = 'checkpoint_new.txt'\n\n    oldname = os.path.join(FLAGS.checkpoint_dir, oldname)\n    newname = os.path.join(FLAGS.checkpoint_dir, newname)\n\n    # Delete oldest checkpoint\n    try:\n        tf.gfile.Remove(oldname)\n        tf.gfile.Remove(oldname + '.meta')\n    except:\n        pass\n\n    # Rename old checkpoint\n    try:\n        tf.gfile.Rename(newname, oldname)\n        tf.gfile.Rename(newname + '.meta', oldname + '.meta')\n    except:\n        pass\n\n    # Generate new checkpoint\n    saver = tf.train.Saver()\n    saver.save(td.sess, newname)\n\n    print(\"    Checkpoint saved\")\n\ndef train_model(train_data):\n    td = train_data\n\n    summaries = tf.merge_all_summaries()\n    td.sess.run(tf.initialize_all_variables())\n\n    lrval       = FLAGS.learning_rate_start\n    start_time  = time.time()\n    done  = False\n    batch = 0\n\n    assert FLAGS.learning_rate_half_life % 10 == 0\n\n    # Cache test features and labels (they are small)\n    test_feature, test_label = td.sess.run([td.test_features, td.test_labels])\n\n    while not done:\n        batch += 1\n        gene_loss = disc_real_loss = disc_fake_loss = -1.234\n\n        feed_dict = {td.learning_rate : lrval}\n\n        ops = [td.gene_minimize, td.disc_minimize, td.gene_loss, td.disc_real_loss, td.disc_fake_loss]\n        _, _, gene_loss, disc_real_loss, disc_fake_loss = td.sess.run(ops, feed_dict=feed_dict)\n        \n        if batch % 10 == 0:\n            # Show we are alive\n            elapsed = int(time.time() - start_time)/60\n            print('Progress[%3d%%], ETA[%4dm], Batch [%4d], G_Loss[%3.3f], D_Real_Loss[%3.3f], D_Fake_Loss[%3.3f]' %\n                  (int(100*elapsed/FLAGS.train_time), FLAGS.train_time - elapsed,\n                   batch, gene_loss, disc_real_loss, disc_fake_loss))\n\n            # Finished?            \n            current_progress = elapsed / FLAGS.train_time\n            if current_progress >= 1.0:\n                done = True\n            \n            # Update learning rate\n            if batch % FLAGS.learning_rate_half_life == 0:\n                lrval *= .5\n\n        if batch % FLAGS.summary_period == 0:\n            # Show progress with test features\n            feed_dict = {td.gene_minput: test_feature}\n            gene_output = td.sess.run(td.gene_moutput, feed_dict=feed_dict)\n            _summarize_progress(td, test_feature, test_label, gene_output, batch, 'out')\n            \n        if batch % FLAGS.checkpoint_period == 0:\n            # Save checkpoint\n            _save_checkpoint(td, batch)\n\n    _save_checkpoint(td, batch)\n    print('Finished training!')\n"
        }
      ]
    }
  ]
}