{
  "metadata": {
    "timestamp": 1736560524546,
    "page": 122,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjEzMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "lucidrains/denoising-diffusion-pytorch",
      "stars": 8678,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.787109375,
          "content": "# Generation results\nresults/\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\npip-wheel-metadata/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n.python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.041015625,
          "content": "MIT License\n\nCopyright (c) 2020 Phil Wang\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 12.2626953125,
          "content": "<img src=\"./images/denoising-diffusion.png\" width=\"500px\"></img>\n\n## Denoising Diffusion Probabilistic Model, in Pytorch\n\nImplementation of <a href=\"https://arxiv.org/abs/2006.11239\">Denoising Diffusion Probabilistic Model</a> in Pytorch. It is a new approach to generative modeling that may <a href=\"https://ajolicoeur.wordpress.com/the-new-contender-to-gans-score-matching-with-langevin-sampling/\">have the potential</a> to rival GANs. It uses denoising score matching to estimate the gradient of the data distribution, followed by Langevin sampling to sample from the true distribution.\n\nThis implementation was inspired by the official Tensorflow version <a href=\"https://github.com/hojonathanho/diffusion\">here</a>\n\nYoutube AI Educators - <a href=\"https://www.youtube.com/watch?v=W-O7AZNzbzQ\">Yannic Kilcher</a> | <a href=\"https://www.youtube.com/watch?v=344w5h24-h8\">AI Coffeebreak with Letitia</a> | <a href=\"https://www.youtube.com/watch?v=HoKDTa5jHvg\">Outlier</a>\n\n<a href=\"https://github.com/yiyixuxu/denoising-diffusion-flax\">Flax implementation</a> from <a href=\"https://github.com/yiyixuxu\">YiYi Xu</a>\n\n<a href=\"https://huggingface.co/blog/annotated-diffusion\">Annotated code</a> by Research Scientists / Engineers from <a href=\"https://huggingface.co/\">ðŸ¤— Huggingface</a>\n\nUpdate: Turns out none of the technicalities really matters at all | <a href=\"https://arxiv.org/abs/2208.09392\">\"Cold Diffusion\" paper</a> | <a href=\"https://muse-model.github.io/\">Muse</a>\n\n<img src=\"./images/sample.png\" width=\"500px\"><img>\n\n[![PyPI version](https://badge.fury.io/py/denoising-diffusion-pytorch.svg)](https://badge.fury.io/py/denoising-diffusion-pytorch)\n\n## Install\n\n```bash\n$ pip install denoising_diffusion_pytorch\n```\n\n## Usage\n\n```python\nimport torch\nfrom denoising_diffusion_pytorch import Unet, GaussianDiffusion\n\nmodel = Unet(\n    dim = 64,\n    dim_mults = (1, 2, 4, 8),\n    flash_attn = True\n)\n\ndiffusion = GaussianDiffusion(\n    model,\n    image_size = 128,\n    timesteps = 1000    # number of steps\n)\n\ntraining_images = torch.rand(8, 3, 128, 128) # images are normalized from 0 to 1\nloss = diffusion(training_images)\nloss.backward()\n\n# after a lot of training\n\nsampled_images = diffusion.sample(batch_size = 4)\nsampled_images.shape # (4, 3, 128, 128)\n```\n\nOr, if you simply want to pass in a folder name and the desired image dimensions, you can use the `Trainer` class to easily train a model.\n\n```python\nfrom denoising_diffusion_pytorch import Unet, GaussianDiffusion, Trainer\n\nmodel = Unet(\n    dim = 64,\n    dim_mults = (1, 2, 4, 8),\n    flash_attn = True\n)\n\ndiffusion = GaussianDiffusion(\n    model,\n    image_size = 128,\n    timesteps = 1000,           # number of steps\n    sampling_timesteps = 250    # number of sampling timesteps (using ddim for faster inference [see citation for ddim paper])\n)\n\ntrainer = Trainer(\n    diffusion,\n    'path/to/your/images',\n    train_batch_size = 32,\n    train_lr = 8e-5,\n    train_num_steps = 700000,         # total training steps\n    gradient_accumulate_every = 2,    # gradient accumulation steps\n    ema_decay = 0.995,                # exponential moving average decay\n    amp = True,                       # turn on mixed precision\n    calculate_fid = True              # whether to calculate fid during training\n)\n\ntrainer.train()\n```\n\nSamples and model checkpoints will be logged to `./results` periodically\n\n## Multi-GPU Training\n\nThe `Trainer` class is now equipped with <a href=\"https://huggingface.co/docs/accelerate/accelerator\">ðŸ¤— Accelerator</a>. You can easily do multi-gpu training in two steps using their `accelerate` CLI\n\nAt the project root directory, where the training script is, run\n\n```python\n$ accelerate config\n```\n\nThen, in the same directory\n\n```python\n$ accelerate launch train.py\n```\n\n## Miscellaneous\n\n### 1D Sequence\n\nBy popular request, a 1D Unet + Gaussian Diffusion implementation.\n\n```python\nimport torch\nfrom denoising_diffusion_pytorch import Unet1D, GaussianDiffusion1D, Trainer1D, Dataset1D\n\nmodel = Unet1D(\n    dim = 64,\n    dim_mults = (1, 2, 4, 8),\n    channels = 32\n)\n\ndiffusion = GaussianDiffusion1D(\n    model,\n    seq_length = 128,\n    timesteps = 1000,\n    objective = 'pred_v'\n)\n\ntraining_seq = torch.rand(64, 32, 128) # features are normalized from 0 to 1\n\nloss = diffusion(training_seq)\nloss.backward()\n\n# Or using trainer\n\ndataset = Dataset1D(training_seq)  # this is just an example, but you can formulate your own Dataset and pass it into the `Trainer1D` below\n\ntrainer = Trainer1D(\n    diffusion,\n    dataset = dataset,\n    train_batch_size = 32,\n    train_lr = 8e-5,\n    train_num_steps = 700000,         # total training steps\n    gradient_accumulate_every = 2,    # gradient accumulation steps\n    ema_decay = 0.995,                # exponential moving average decay\n    amp = True,                       # turn on mixed precision\n)\ntrainer.train()\n\n# after a lot of training\n\nsampled_seq = diffusion.sample(batch_size = 4)\nsampled_seq.shape # (4, 32, 128)\n\n```\n\n`Trainer1D` does not evaluate the generated samples in any way since the type of data is not known.\n\nYou could consider adding a suitable metric to the training loop yourself after doing an editable install of this package\n`pip install -e .`.\n\n## Citations\n\n```bibtex\n@inproceedings{NEURIPS2020_4c5bcfec,\n    author      = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},\n    booktitle   = {Advances in Neural Information Processing Systems},\n    editor      = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},\n    pages       = {6840--6851},\n    publisher   = {Curran Associates, Inc.},\n    title       = {Denoising Diffusion Probabilistic Models},\n    url         = {https://proceedings.neurips.cc/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf},\n    volume      = {33},\n    year        = {2020}\n}\n```\n\n```bibtex\n@InProceedings{pmlr-v139-nichol21a,\n    title       = {Improved Denoising Diffusion Probabilistic Models},\n    author      = {Nichol, Alexander Quinn and Dhariwal, Prafulla},\n    booktitle   = {Proceedings of the 38th International Conference on Machine Learning},\n    pages       = {8162--8171},\n    year        = {2021},\n    editor      = {Meila, Marina and Zhang, Tong},\n    volume      = {139},\n    series      = {Proceedings of Machine Learning Research},\n    month       = {18--24 Jul},\n    publisher   = {PMLR},\n    pdf         = {http://proceedings.mlr.press/v139/nichol21a/nichol21a.pdf},\n    url         = {https://proceedings.mlr.press/v139/nichol21a.html},\n}\n```\n\n```bibtex\n@inproceedings{kingma2021on,\n    title       = {On Density Estimation with Diffusion Models},\n    author      = {Diederik P Kingma and Tim Salimans and Ben Poole and Jonathan Ho},\n    booktitle   = {Advances in Neural Information Processing Systems},\n    editor      = {A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\n    year        = {2021},\n    url         = {https://openreview.net/forum?id=2LdBqxc1Yv}\n}\n```\n\n```bibtex\n@article{Karras2022ElucidatingTD,\n    title   = {Elucidating the Design Space of Diffusion-Based Generative Models},\n    author  = {Tero Karras and Miika Aittala and Timo Aila and Samuli Laine},\n    journal = {ArXiv},\n    year    = {2022},\n    volume  = {abs/2206.00364}\n}\n```\n\n```bibtex\n@article{Song2021DenoisingDI,\n    title   = {Denoising Diffusion Implicit Models},\n    author  = {Jiaming Song and Chenlin Meng and Stefano Ermon},\n    journal = {ArXiv},\n    year    = {2021},\n    volume  = {abs/2010.02502}\n}\n```\n\n```bibtex\n@misc{chen2022analog,\n    title   = {Analog Bits: Generating Discrete Data using Diffusion Models with Self-Conditioning},\n    author  = {Ting Chen and Ruixiang Zhang and Geoffrey Hinton},\n    year    = {2022},\n    eprint  = {2208.04202},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CV}\n}\n```\n\n```bibtex\n@article{Salimans2022ProgressiveDF,\n    title   = {Progressive Distillation for Fast Sampling of Diffusion Models},\n    author  = {Tim Salimans and Jonathan Ho},\n    journal = {ArXiv},\n    year    = {2022},\n    volume  = {abs/2202.00512}\n}\n```\n\n```bibtex\n@article{Ho2022ClassifierFreeDG,\n    title   = {Classifier-Free Diffusion Guidance},\n    author  = {Jonathan Ho},\n    journal = {ArXiv},\n    year    = {2022},\n    volume  = {abs/2207.12598}\n}\n```\n\n```bibtex\n@article{Sunkara2022NoMS,\n    title   = {No More Strided Convolutions or Pooling: A New CNN Building Block for Low-Resolution Images and Small Objects},\n    author  = {Raja Sunkara and Tie Luo},\n    journal = {ArXiv},\n    year    = {2022},\n    volume  = {abs/2208.03641}\n}\n```\n\n```bibtex\n@inproceedings{Jabri2022ScalableAC,\n    title   = {Scalable Adaptive Computation for Iterative Generation},\n    author  = {A. Jabri and David J. Fleet and Ting Chen},\n    year    = {2022}\n}\n```\n\n```bibtex\n@article{Cheng2022DPMSolverPlusPlus,\n    title   = {DPM-Solver++: Fast Solver for Guided Sampling of Diffusion Probabilistic Models},\n    author  = {Cheng Lu and Yuhao Zhou and Fan Bao and Jianfei Chen and Chongxuan Li and Jun Zhu},\n    journal = {NeuRips 2022 Oral},\n    year    = {2022},\n    volume  = {abs/2211.01095}\n}\n```\n\n```bibtex\n@inproceedings{Hoogeboom2023simpleDE,\n    title   = {simple diffusion: End-to-end diffusion for high resolution images},\n    author  = {Emiel Hoogeboom and Jonathan Heek and Tim Salimans},\n    year    = {2023}\n}\n```\n\n```bibtex\n@misc{https://doi.org/10.48550/arxiv.2302.01327,\n    doi     = {10.48550/ARXIV.2302.01327},\n    url     = {https://arxiv.org/abs/2302.01327},\n    author  = {Kumar, Manoj and Dehghani, Mostafa and Houlsby, Neil},\n    title   = {Dual PatchNorm},\n    publisher = {arXiv},\n    year    = {2023},\n    copyright = {Creative Commons Attribution 4.0 International}\n}\n```\n\n```bibtex\n@inproceedings{Hang2023EfficientDT,\n    title   = {Efficient Diffusion Training via Min-SNR Weighting Strategy},\n    author  = {Tiankai Hang and Shuyang Gu and Chen Li and Jianmin Bao and Dong Chen and Han Hu and Xin Geng and Baining Guo},\n    year    = {2023}\n}\n```\n\n```bibtex\n@misc{Guttenberg2023,\n    author  = {Nicholas Guttenberg},\n    url     = {https://www.crosslabs.org/blog/diffusion-with-offset-noise}\n}\n```\n\n```bibtex\n@inproceedings{Lin2023CommonDN,\n    title   = {Common Diffusion Noise Schedules and Sample Steps are Flawed},\n    author  = {Shanchuan Lin and Bingchen Liu and Jiashi Li and Xiao Yang},\n    year    = {2023}\n}\n```\n\n```bibtex\n@inproceedings{dao2022flashattention,\n    title   = {Flash{A}ttention: Fast and Memory-Efficient Exact Attention with {IO}-Awareness},\n    author  = {Dao, Tri and Fu, Daniel Y. and Ermon, Stefano and Rudra, Atri and R{\\'e}, Christopher},\n    booktitle = {Advances in Neural Information Processing Systems},\n    year    = {2022}\n}\n```\n\n```bibtex\n@article{Bondarenko2023QuantizableTR,\n    title   = {Quantizable Transformers: Removing Outliers by Helping Attention Heads Do Nothing},\n    author  = {Yelysei Bondarenko and Markus Nagel and Tijmen Blankevoort},\n    journal = {ArXiv},\n    year    = {2023},\n    volume  = {abs/2306.12929},\n    url     = {https://api.semanticscholar.org/CorpusID:259224568}\n}\n```\n\n```bibtex\n@article{Karras2023AnalyzingAI,\n    title   = {Analyzing and Improving the Training Dynamics of Diffusion Models},\n    author  = {Tero Karras and Miika Aittala and Jaakko Lehtinen and Janne Hellsten and Timo Aila and Samuli Laine},\n    journal = {ArXiv},\n    year    = {2023},\n    volume  = {abs/2312.02696},\n    url     = {https://api.semanticscholar.org/CorpusID:265659032}\n}\n```\n\n```bibtex\n@article{Li2024ImmiscibleDA,\n    title   = {Immiscible Diffusion: Accelerating Diffusion Training with Noise Assignment},\n    author  = {Yiheng Li and Heyang Jiang and Akio Kodaira and Masayoshi Tomizuka and Kurt Keutzer and Chenfeng Xu},\n    journal = {ArXiv},\n    year    = {2024},\n    volume  = {abs/2406.12303},\n    url     = {https://api.semanticscholar.org/CorpusID:270562607}\n}\n```\n\n```bibtex\n@article{Chung2024CFGMC,\n    title   = {CFG++: Manifold-constrained Classifier Free Guidance for Diffusion Models},\n    author  = {Hyungjin Chung and Jeongsol Kim and Geon Yeong Park and Hyelin Nam and Jong Chul Ye},\n    journal = {ArXiv},\n    year    = {2024},\n    volume  = {abs/2406.08070},\n    url     = {https://api.semanticscholar.org/CorpusID:270391454}\n}\n```\n\n```bibtex\n@inproceedings{Sadat2024EliminatingOA,\n    title   = {Eliminating Oversaturation and Artifacts of High Guidance Scales in Diffusion Models},\n    author  = {Seyedmorteza Sadat and Otmar Hilliges and Romann M. Weber},\n    year    = {2024},\n    url     = {https://api.semanticscholar.org/CorpusID:273098845}\n}\n```\n"
        },
        {
          "name": "denoising_diffusion_pytorch",
          "type": "tree",
          "content": null
        },
        {
          "name": "images",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 0.9794921875,
          "content": "from setuptools import setup, find_packages\n\nexec(open('denoising_diffusion_pytorch/version.py').read())\n\nsetup(\n  name = 'denoising-diffusion-pytorch',\n  packages = find_packages(),\n  version = __version__,\n  license='MIT',\n  description = 'Denoising Diffusion Probabilistic Models - Pytorch',\n  author = 'Phil Wang',\n  author_email = 'lucidrains@gmail.com',\n  url = 'https://github.com/lucidrains/denoising-diffusion-pytorch',\n  long_description_content_type = 'text/markdown',\n  keywords = [\n    'artificial intelligence',\n    'generative models'\n  ],\n  install_requires=[\n    'accelerate',\n    'einops',\n    'ema-pytorch>=0.4.2',\n    'numpy',\n    'pillow',\n    'pytorch-fid',\n    'scipy',\n    'torch>=2.0',\n    'torchvision',\n    'tqdm'\n  ],\n  classifiers=[\n    'Development Status :: 4 - Beta',\n    'Intended Audience :: Developers',\n    'Topic :: Scientific/Engineering :: Artificial Intelligence',\n    'License :: OSI Approved :: MIT License',\n    'Programming Language :: Python :: 3.6',\n  ],\n)\n"
        }
      ]
    }
  ]
}