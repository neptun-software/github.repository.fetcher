{
  "metadata": {
    "timestamp": 1736560440293,
    "page": 13,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjIw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "sqlalchemy/sqlalchemy",
      "stars": 9887,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".git-blame-ignore-revs",
          "type": "blob",
          "size": 0.6552734375,
          "content": "# This file contains a list of revisions that the SQLAlchemy maintainers\n# consider unimportant for git blame purposes because they are pure refactoring\n# changes and unlikely to be the cause of bugs. You can configure git to use\n# this file by configuring the 'blame.ignoreRevsFile' setting. For example:\n#\n#   $ git config --local blame.ignoreRevsFile .git-blame-ignore-revs\n#\n1e1a38e7801f410f244e4bbb44ec795ae152e04e  # initial blackification\n1e278de4cc9a4181e0747640a960e80efcea1ca9  # follow up mass style changes\n058c230cea83811c3bebdd8259988c5c501f4f7e  # Update black to v23.3.0 and flake8 to v6\n9b153ff18f12eab7b74a20ce53538666600f8bbf  # Update black to 24.1.1\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.5361328125,
          "content": "*.pyc\n*.pyd\n*.pyo\n*.egg\n/build/\n/dist/\n/doc/build/output/\n/doc/build/_build/\n/dogpile_data/\n*.orig\n*,cover\n/.tox\n/venv/\n.venv\n*.egg-info\n.coverage\ncoverage.xml\n.*,cover\n*.class\n*.so\n*.patch\nsqlnet.log\n/shard?_*.db\n/test.cfg\n/.cache/\n/.mypy_cache\n*.sw[o,p]\n*.rej\ntest/test_schema.db\n*test_schema.db\n.idea\n/Pipfile*\n/.pytest_cache/\n/pip-wheel-metadata/\n/.vscode/\n/.ipynb_checkpoints/\n*.ipynb\n/querytest.db\n/.pytest_cache\n/db_idents.txt\n.DS_Store\n.vs\n/scratch\n\n# cython complied files\n/lib/**/*.c\n/lib/**/*.cpp\n# cython annotated output\n/lib/**/*.html\n"
        },
        {
          "name": ".gitreview",
          "type": "blob",
          "size": 0.0830078125,
          "content": "[gerrit]\nhost=gerrit.sqlalchemy.org\nproject=sqlalchemy/sqlalchemy\ndefaultbranch=main\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 1.0234375,
          "content": "# See https://pre-commit.com for more information\n# See https://pre-commit.com/hooks.html for more hooks\nrepos:\n-   repo: https://github.com/python/black\n    rev: 24.10.0\n    hooks:\n    -   id: black\n\n-   repo: https://github.com/sqlalchemyorg/zimports\n    rev: v0.6.0\n    hooks:\n    -   id: zimports\n\n-   repo: https://github.com/pycqa/flake8\n    rev: 6.1.0\n    hooks:\n    -   id: flake8\n        additional_dependencies:\n          - flake8-import-order\n          - flake8-import-single==0.1.5\n          - flake8-builtins\n          - flake8-future-annotations>=0.0.5\n          - flake8-docstrings>=1.6.0\n          - flake8-unused-arguments\n          - flake8-rst-docstrings\n          # flake8-rst-docstrings dependency, leaving it here\n          # in case it requires a version pin\n          - pydocstyle\n          - pygments\n\n-   repo: local\n    hooks:\n    -   id: black-docs\n        name: Format docs code block with black\n        entry: python tools/format_docs_code.py -f\n        language: system\n        types: [rst]\n        exclude: README.*\n"
        },
        {
          "name": "AUTHORS",
          "type": "blob",
          "size": 0.48046875,
          "content": "SQLAlchemy was created by Michael Bayer.\n\nMajor contributing authors include:\n\n- Mike Bayer\n- Jason Kirtland\n- Michael Trier\n- Diana Clarke\n- Gaetan de Menten\n- Lele Gaifax\n- Jonathan Ellis\n- Gord Thompson\n- Federico Caselli\n- Philip Jenvey\n- Rick Morrison\n- Chris Withers\n- Ants Aasma\n- Sheila Allen\n- Paul Johnston\n- Tony Locke\n- Hajime Nakagami\n- Vraj Mohan\n- Robert Leftwich\n- Taavi Burns\n- Jonathan Vanasco\n- Jeff Widman\n- Scott Dugas\n- Dobes Vandermeer\n- Ville Skytta\n- Rodrigo Menezes\n"
        },
        {
          "name": "CHANGES.rst",
          "type": "blob",
          "size": 0.234375,
          "content": "=====\nMOVED\n=====\n\nFor an index of all changelogs, please see:\n\n* On the web: https://www.sqlalchemy.org/docs/latest/changelog/\n* In the source tree: `</doc/build/changelog/>`_\n* In the released distribution tree: /doc/changelog/index.html\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.07421875,
          "content": "Copyright 2005-2025 SQLAlchemy authors and contributors <see AUTHORS file>.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the \"Software\"), to deal in\nthe Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\nof the Software, and to permit persons to whom the Software is furnished to do\nso, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.65234375,
          "content": "# any kind of \"*\" pulls in __init__.pyc files,\n# so all extensions are explicit.\n\nrecursive-include doc *.html *.css *.txt *.js *.png *.py Makefile *.rst *.sty\nrecursive-include examples *.py *.xml\nrecursive-include test *.py *.dat *.testpatch\nrecursive-include tools *.py\n\n# for some reason in some environments stale Cython .c files\n# are being pulled in, these should never be in a dist\nexclude lib/sqlalchemy/**/*.c\nexclude lib/sqlalchemy/**/*.so\n\n# include the pxd extensions, which otherwise\n# don't come in if --with-cextensions isn't specified.\nrecursive-include lib *.pxd *.txt *.typed\n\ninclude README* AUTHORS LICENSE CHANGES* tox.ini\nprune doc/build/output\n"
        },
        {
          "name": "README.dialects.rst",
          "type": "blob",
          "size": 8.97265625,
          "content": "========================\nDeveloping new Dialects\n========================\n\n.. note::\n\n   When studying this file, it's probably a good idea to also\n   familiarize with the  README.unittests.rst file, which discusses\n   SQLAlchemy's usage and extension of the pytest test runner.\n\nWhile SQLAlchemy includes many dialects within the core distribution, the\ntrend for new dialects should be that they are published as external\nprojects.   SQLAlchemy has since version 0.5 featured a \"plugin\" system\nwhich allows external dialects to be integrated into SQLAlchemy using\nstandard setuptools entry points.  As of version 0.8, this system has\nbeen enhanced, so that a dialect can also be \"plugged in\" at runtime.\n\nOn the testing side, SQLAlchemy includes a \"dialect compliance\nsuite\" that is usable by third party libraries, in the source tree\nat ``lib/sqlalchemy/testing/suite``.   There's no need for a third party\ndialect to run through SQLAlchemy's full testing suite, as a large portion of\nthese tests do not have dialect-sensitive functionality.  The \"dialect\ncompliance suite\" should be viewed as the primary target for new dialects.\n\n\nDialect Layout\n===============\n\nThe file structure of a dialect is typically similar to the following:\n\n.. sourcecode:: text\n\n    sqlalchemy-<dialect>/\n                         setup.py\n                         setup.cfg\n                         sqlalchemy_<dialect>/\n                                              __init__.py\n                                              base.py\n                                              <dbapi>.py\n                                              requirements.py\n                         test/\n                                              __init__.py\n                                              conftest.py\n                                              test_suite.py\n                                              test_<dialect_specific_test>.py\n                                              ...\n\nAn example of this structure can be seen in the MS Access dialect at\nhttps://github.com/gordthompson/sqlalchemy-access .\n\nKey aspects of this file layout include:\n\n* setup.py - should specify setuptools entrypoints, allowing the\n  dialect to be usable from create_engine(), e.g.::\n\n        entry_points = {\n            \"sqlalchemy.dialects\": [\n                \"access.pyodbc = sqlalchemy_access.pyodbc:AccessDialect_pyodbc\",\n            ]\n        }\n\n  Above, the entrypoint ``access.pyodbc`` allow URLs to be used such as::\n\n    create_engine(\"access+pyodbc://user:pw@dsn\")\n\n* setup.cfg - this file contains the traditional contents such as\n  [tool:pytest] directives, but also contains new directives that are used\n  by SQLAlchemy's testing framework.  E.g. for Access:\n\n  .. sourcecode:: text\n\n    [tool:pytest]\n    addopts= --tb native -v -r fxX --maxfail=25 -p no:warnings\n    python_files=test/*test_*.py\n\n    [sqla_testing]\n    requirement_cls=sqlalchemy_access.requirements:Requirements\n    profile_file=test/profiles.txt\n\n    [db]\n    default=access+pyodbc://admin@access_test\n    sqlite=sqlite:///:memory:\n\n  Above, the ``[sqla_testing]`` section contains configuration used by\n  SQLAlchemy's test plugin.  The ``[tool:pytest]`` section\n  include directives to help with these runners.  When using pytest\n  the test/conftest.py file will bootstrap SQLAlchemy's plugin.\n\n* test/conftest.py - This script bootstraps SQLAlchemy's pytest plugin\n  into the pytest runner.  This\n  script can also be used to install your third party dialect into\n  SQLAlchemy without using the setuptools entrypoint system; this allows\n  your dialect to be present without any explicit setup.py step needed.\n  The other portion invokes SQLAlchemy's pytest plugin::\n\n    from sqlalchemy.dialects import registry\n    import pytest\n\n    registry.register(\"access.pyodbc\", \"sqlalchemy_access.pyodbc\", \"AccessDialect_pyodbc\")\n\n    pytest.register_assert_rewrite(\"sqlalchemy.testing.assertions\")\n\n    from sqlalchemy.testing.plugin.pytestplugin import *\n\n  Where above, the ``registry`` module, introduced in SQLAlchemy 0.8, provides\n  an in-Python means of installing the dialect entrypoint(s) without the use\n  of setuptools, using the ``registry.register()`` function in a way that\n  is similar to the ``entry_points`` directive we placed in our ``setup.py``.\n  (The ``pytest.register_assert_rewrite`` is there just to suppress a spurious\n  warning from pytest.)\n\n* requirements.py - The ``requirements.py`` file is where directives\n  regarding database and dialect capabilities are set up.\n  SQLAlchemy's tests are often annotated with decorators   that mark\n  tests as \"skip\" or \"fail\" for particular backends.  Over time, this\n  system   has been refined such that specific database and DBAPI names\n  are mentioned   less and less, in favor of @requires directives which\n  state a particular capability.   The requirement directive is linked\n  to target dialects using a ``Requirements`` subclass.   The custom\n  ``Requirements`` subclass is specified in the ``requirements.py`` file\n  and   is made available to SQLAlchemy's test runner using the\n  ``requirement_cls`` directive   inside the ``[sqla_testing]`` section.\n\n  For a third-party dialect, the custom ``Requirements`` class can\n  usually specify a simple yes/no answer for a particular system. For\n  example, a requirements file that specifies a database that supports\n  the RETURNING construct but does not support nullable boolean\n  columns might look like this::\n\n      # sqlalchemy_access/requirements.py\n\n      from sqlalchemy.testing.requirements import SuiteRequirements\n\n      from sqlalchemy.testing import exclusions\n\n\n      class Requirements(SuiteRequirements):\n          @property\n          def nullable_booleans(self):\n              \"\"\"Target database allows boolean columns to store NULL.\"\"\"\n              # Access Yes/No doesn't allow null\n              return exclusions.closed()\n\n          @property\n          def returning(self):\n              return exclusions.open()\n\n  The ``SuiteRequirements`` class in\n  ``sqlalchemy.testing.requirements`` contains a large number of\n  requirements rules, which attempt to have reasonable defaults. The\n  tests will report on those requirements found as they are run.\n\n  The requirements system can also be used when running SQLAlchemy's\n  primary test suite against the external dialect.  In this use case,\n  a ``--dburi`` as well as a ``--requirements`` flag are passed to SQLAlchemy's\n  test runner so that exclusions specific to the dialect take place:\n\n  .. sourcecode:: text\n\n    cd /path/to/sqlalchemy\n    pytest -v \\\n      --requirements sqlalchemy_access.requirements:Requirements \\\n      --dburi access+pyodbc://admin@access_test\n\n* test_suite.py - Finally, the ``test_suite.py`` module represents a\n  stub test suite, which pulls in the actual SQLAlchemy test suite.\n  To pull in the suite as a whole, it can   be imported in one step::\n\n      # test/test_suite.py\n\n      from sqlalchemy.testing.suite import *\n\n  That's all that's needed - the ``sqlalchemy.testing.suite`` package\n  contains an ever expanding series of tests, most of which should be\n  annotated with specific requirement decorators so that they can be\n  fully controlled.  In the case that the decorators are not covering\n  a particular test, a test can also be directly modified or bypassed.\n  In the example below, the Access dialect test suite overrides the\n  ``get_huge_int()`` test::\n\n      from sqlalchemy.testing.suite import *\n\n      from sqlalchemy.testing.suite import IntegerTest as _IntegerTest\n\n\n      class IntegerTest(_IntegerTest):\n\n          @testing.skip(\"access\")\n          def test_huge_int(self):\n              # bypass this test because Access ODBC fails with\n              # [ODBC Microsoft Access Driver] Optional feature not implemented.\n              return\n\nAsyncIO dialects\n----------------\n\nAs of version 1.4 SQLAlchemy supports also dialects that use\nasyncio drivers to interface with the database backend.\n\nSQLAlchemy's approach to asyncio drivers is that the connection and cursor\nobjects of the driver (if any) are adapted into a pep-249 compliant interface,\nusing the ``AdaptedConnection`` interface class. Refer to the internal asyncio\ndriver implementations such as that of ``asyncpg``, ``asyncmy`` and\n``aiosqlite`` for examples.\n\nGoing Forward\n==============\n\nThe third-party dialect can be distributed like any other Python\nmodule on PyPI. Links to prominent dialects can be featured within\nSQLAlchemy's own documentation; contact the developers (see AUTHORS)\nfor help with this.\n\nWhile SQLAlchemy includes many dialects built in, it remains to be\nseen if the project as a whole might move towards \"plugin\" model for\nall dialects, including all those currently built in.  Now that\nSQLAlchemy's dialect API is mature and the test suite is not far\nbehind, it may be that a better maintenance experience can be\ndelivered by having all dialects separately maintained and released.\n\nAs new versions of SQLAlchemy are released, the test suite and\nrequirements file will receive new tests and changes.  The dialect\nmaintainer would normally keep track of these changes and make\nadjustments as needed.\n\n"
        },
        {
          "name": "README.rst",
          "type": "blob",
          "size": 5.5849609375,
          "content": "SQLAlchemy\n==========\n\n|PyPI| |Python| |Downloads|\n\n.. |PyPI| image:: https://img.shields.io/pypi/v/sqlalchemy\n    :target: https://pypi.org/project/sqlalchemy\n    :alt: PyPI\n\n.. |Python| image:: https://img.shields.io/pypi/pyversions/sqlalchemy\n    :target: https://pypi.org/project/sqlalchemy\n    :alt: PyPI - Python Version\n\n.. |Downloads| image:: https://static.pepy.tech/badge/sqlalchemy/month\n    :target: https://pepy.tech/project/sqlalchemy\n    :alt: PyPI - Downloads\n\n\nThe Python SQL Toolkit and Object Relational Mapper\n\nIntroduction\n-------------\n\nSQLAlchemy is the Python SQL toolkit and Object Relational Mapper\nthat gives application developers the full power and\nflexibility of SQL. SQLAlchemy provides a full suite\nof well known enterprise-level persistence patterns,\ndesigned for efficient and high-performing database\naccess, adapted into a simple and Pythonic domain\nlanguage.\n\nMajor SQLAlchemy features include:\n\n* An industrial strength ORM, built\n  from the core on the identity map, unit of work,\n  and data mapper patterns.   These patterns\n  allow transparent persistence of objects\n  using a declarative configuration system.\n  Domain models\n  can be constructed and manipulated naturally,\n  and changes are synchronized with the\n  current transaction automatically.\n* A relationally-oriented query system, exposing\n  the full range of SQL's capabilities\n  explicitly, including joins, subqueries,\n  correlation, and most everything else,\n  in terms of the object model.\n  Writing queries with the ORM uses the same\n  techniques of relational composition you use\n  when writing SQL.  While you can drop into\n  literal SQL at any time, it's virtually never\n  needed.\n* A comprehensive and flexible system\n  of eager loading for related collections and objects.\n  Collections are cached within a session,\n  and can be loaded on individual access, all\n  at once using joins, or by query per collection\n  across the full result set.\n* A Core SQL construction system and DBAPI\n  interaction layer.  The SQLAlchemy Core is\n  separate from the ORM and is a full database\n  abstraction layer in its own right, and includes\n  an extensible Python-based SQL expression\n  language, schema metadata, connection pooling,\n  type coercion, and custom types.\n* All primary and foreign key constraints are\n  assumed to be composite and natural.  Surrogate\n  integer primary keys are of course still the\n  norm, but SQLAlchemy never assumes or hardcodes\n  to this model.\n* Database introspection and generation.  Database\n  schemas can be \"reflected\" in one step into\n  Python structures representing database metadata;\n  those same structures can then generate\n  CREATE statements right back out - all within\n  the Core, independent of the ORM.\n\nSQLAlchemy's philosophy:\n\n* SQL databases behave less and less like object\n  collections the more size and performance start to\n  matter; object collections behave less and less like\n  tables and rows the more abstraction starts to matter.\n  SQLAlchemy aims to accommodate both of these\n  principles.\n* An ORM doesn't need to hide the \"R\".   A relational\n  database provides rich, set-based functionality\n  that should be fully exposed.   SQLAlchemy's\n  ORM provides an open-ended set of patterns\n  that allow a developer to construct a custom\n  mediation layer between a domain model and\n  a relational schema, turning the so-called\n  \"object relational impedance\" issue into\n  a distant memory.\n* The developer, in all cases, makes all decisions\n  regarding the design, structure, and naming conventions\n  of both the object model as well as the relational\n  schema.   SQLAlchemy only provides the means\n  to automate the execution of these decisions.\n* With SQLAlchemy, there's no such thing as\n  \"the ORM generated a bad query\" - you\n  retain full control over the structure of\n  queries, including how joins are organized,\n  how subqueries and correlation is used, what\n  columns are requested.  Everything SQLAlchemy\n  does is ultimately the result of a developer-initiated \n  decision.\n* Don't use an ORM if the problem doesn't need one.\n  SQLAlchemy consists of a Core and separate ORM\n  component.   The Core offers a full SQL expression\n  language that allows Pythonic construction\n  of SQL constructs that render directly to SQL\n  strings for a target database, returning\n  result sets that are essentially enhanced DBAPI\n  cursors.\n* Transactions should be the norm.  With SQLAlchemy's\n  ORM, nothing goes to permanent storage until\n  commit() is called.  SQLAlchemy encourages applications\n  to create a consistent means of delineating\n  the start and end of a series of operations.\n* Never render a literal value in a SQL statement.\n  Bound parameters are used to the greatest degree\n  possible, allowing query optimizers to cache\n  query plans effectively and making SQL injection\n  attacks a non-issue.\n\nDocumentation\n-------------\n\nLatest documentation is at:\n\nhttps://www.sqlalchemy.org/docs/\n\nInstallation / Requirements\n---------------------------\n\nFull documentation for installation is at\n`Installation <https://www.sqlalchemy.org/docs/intro.html#installation>`_.\n\nGetting Help / Development / Bug reporting\n------------------------------------------\n\nPlease refer to the `SQLAlchemy Community Guide <https://www.sqlalchemy.org/support.html>`_.\n\nCode of Conduct\n---------------\n\nAbove all, SQLAlchemy places great emphasis on polite, thoughtful, and\nconstructive communication between users and developers.\nPlease see our current Code of Conduct at\n`Code of Conduct <https://www.sqlalchemy.org/codeofconduct.html>`_.\n\nLicense\n-------\n\nSQLAlchemy is distributed under the `MIT license\n<https://www.opensource.org/licenses/mit-license.php>`_.\n\n"
        },
        {
          "name": "README.unittests.rst",
          "type": "blob",
          "size": 15.4765625,
          "content": "=====================\nSQLALCHEMY UNIT TESTS\n=====================\n\nBasic Test Running\n==================\n\nTox is used to run the test suite fully.   For basic test runs against\na single Python interpreter::\n\n    tox\n\nAdvanced Tox Options\n====================\n\nFor more elaborate CI-style test running, the tox script provided will\nrun against various Python / database targets.   For a basic run against\nPython 3.11 using an in-memory SQLite database::\n\n    tox -e py311-sqlite\n\nThe tox runner contains a series of target combinations that can run\nagainst various combinations of databases.  The test suite can be\nrun against SQLite with \"backend\" tests also running against a PostgreSQL\ndatabase::\n\n    tox -e py311-sqlite-postgresql\n\nOr to run just \"backend\" tests against a MySQL database::\n\n    tox -e py311-mysql-backendonly\n\nRunning against backends other than SQLite requires that a database of that\nvendor be available at a specific URL.  See \"Setting Up Databases\" below\nfor details.\n\nThe pytest Engine\n=================\n\nThe tox runner is using pytest to invoke the test suite.   Within the realm of\npytest, SQLAlchemy itself is adding a large series of option and\ncustomizations to the pytest runner using plugin points, to allow for\nSQLAlchemy's multiple database support, database setup/teardown and\nconnectivity, multi process support, as well as lots of skip / database\nselection rules.\n\nRunning tests with pytest directly grants more immediate control over\ndatabase options and test selection.\n\nA generic pytest run looks like::\n\n    pytest - n4\n\nAbove, the full test suite will run against SQLite, using four processes.\nIf the \"-n\" flag is not used, the pytest-xdist is skipped and the tests will\nrun linearly, which will take a pretty long time.\n\nThe pytest command line is more handy for running subsets of tests and to\nquickly allow for custom database connections.  Example::\n\n    pytest --dburi=postgresql+psycopg2://scott:tiger@localhost/test  test/sql/test_query.py\n\nAbove will run the tests in the test/sql/test_query.py file (a pretty good\nfile for basic \"does this database work at all?\" to start with) against a\nrunning PostgreSQL database at the given URL.\n\nThe pytest frontend can also run tests against multiple kinds of databases at\nonce - a large subset of tests are marked as \"backend\" tests, which will be run\nagainst each available backend, and additionally lots of tests are targeted at\nspecific backends only, which only run if a matching backend is made available.\nFor example, to run the test suite against both PostgreSQL and MySQL at the\nsame time::\n\n    pytest -n4 --db postgresql --db mysql\n\n\nSetting Up Databases\n====================\n\nThe test suite identifies several built-in database tags that run against\na pre-set URL.  These can be seen using --dbs::\n\n    $ pytest --dbs\n    Available --db options (use --dburi to override)\n                aiomysql    mysql+aiomysql://scott:tiger@127.0.0.1:3306/test?charset=utf8mb4\n               aiosqlite    sqlite+aiosqlite:///:memory:\n          aiosqlite_file    sqlite+aiosqlite:///async_querytest.db\n                 asyncmy    mysql+asyncmy://scott:tiger@127.0.0.1:3306/test?charset=utf8mb4\n                 asyncpg    postgresql+asyncpg://scott:tiger@127.0.0.1:5432/test\n                 default    sqlite:///:memory:\n            docker_mssql    mssql+pymssql://scott:tiger^5HHH@127.0.0.1:1433/test\n                 mariadb    mariadb+mysqldb://scott:tiger@127.0.0.1:3306/test\n       mariadb_connector    mariadb+mariadbconnector://scott:tiger@127.0.0.1:3306/test\n                   mssql    mssql+pyodbc://scott:tiger^5HHH@mssql2017:1433/test?driver=ODBC+Driver+13+for+SQL+Server\n           mssql_pymssql    mssql+pymssql://scott:tiger@ms_2008\n                   mysql    mysql+mysqldb://scott:tiger@127.0.0.1:3306/test?charset=utf8mb4\n                  oracle    oracle+cx_oracle://scott:tiger@oracle18c\n         oracle_oracledb    oracle+oracledb://scott:tiger@oracle18c\n                  pg8000    postgresql+pg8000://scott:tiger@127.0.0.1:5432/test\n              postgresql    postgresql+psycopg2://scott:tiger@127.0.0.1:5432/test\n    postgresql_psycopg2cffi postgresql+psycopg2cffi://scott:tiger@127.0.0.1:5432/test\n                 psycopg    postgresql+psycopg://scott:tiger@127.0.0.1:5432/test\n                psycopg2    postgresql+psycopg2://scott:tiger@127.0.0.1:5432/test\n           psycopg_async    postgresql+psycopg_async://scott:tiger@127.0.0.1:5432/test\n                 pymysql    mysql+pymysql://scott:tiger@127.0.0.1:3306/test?charset=utf8mb4\n        pysqlcipher_file    sqlite+pysqlcipher://:test@/querytest.db.enc\n                  sqlite    sqlite:///:memory:\n             sqlite_file    sqlite:///querytest.db\n\nNote that a pyodbc URL **must be against a hostname / database name\ncombination, not a DSN name** when using the multiprocessing option; this is\nbecause the test suite needs to generate new URLs to refer to per-process\ndatabases that are created on the fly.\n\nWhat those mean is that if you have a database running that can be accessed\nby the above URL, you can run the test suite against it using ``--db <name>``.\n\nThe URLs are present in the ``setup.cfg`` file.   You can make your own URLs by\ncreating a new file called ``test.cfg`` and adding your own ``[db]`` section::\n\n    # test.cfg file\n    [db]\n    my_postgresql=postgresql+psycopg2://username:pass@hostname/dbname\n\nAbove, we can now run the tests with ``my_postgresql``::\n\n    pytest --db my_postgresql\n\nWe can also override the existing names in our ``test.cfg`` file, so that we can run\nwith the tox runner also::\n\n    # test.cfg file\n    [db]\n    postgresql=postgresql+psycopg2://username:pass@hostname/dbname\n\nNow when we run ``tox -e py311-postgresql``, it will use our custom URL instead\nof the fixed one in setup.cfg.\n\nDatabase Configuration\n======================\n\nStep one, the **database chosen for tests must be entirely empty**.  A lot\nof what SQLAlchemy tests is creating and dropping lots of tables\nas well as running database introspection to see what is there.  If there\nare pre-existing tables or other objects in the target database already,\nthese will get in the way.   A failed test run can also be followed by\n a run that includes the \"--dropfirst\" option, which will try to drop\nall existing tables in the target database.\n\nThe above paragraph changes somewhat when the multiprocessing option\nis used, in that separate databases will be created instead, however\nin the case of Postgresql, the starting database is used as a template,\nso the starting database must still be empty.  See below for example\nconfigurations using docker.\n\nThe test runner will by default create and drop tables within the default\ndatabase that's in the database URL, *unless* the multiprocessing option is in\nuse via the pytest \"-n\" flag, which invokes pytest-xdist.   The\nmultiprocessing option is **enabled by default** when using the tox runner.\nWhen multiprocessing is used, the SQLAlchemy testing framework will create a\nnew database for each process, and then tear it down after the test run is\ncomplete.    So it will be necessary for the database user to have access to\nCREATE DATABASE in order for this to work.   Additionally, as mentioned\nearlier, the database URL must be formatted such that it can be rewritten on\nthe fly to refer to these other databases, which means for pyodbc it must refer\nto a hostname/database name combination, not a DSN name.\n\nSeveral tests require alternate usernames or schemas to be present, which\nare used to test dotted-name access scenarios.  On some databases such\nas Oracle these are usernames, and others such as PostgreSQL\nand MySQL they are schemas.   The requirement applies to all backends\nexcept SQLite and Firebird.  The names are::\n\n    test_schema\n    test_schema_2 (only used on PostgreSQL and mssql)\n\nPlease refer to your vendor documentation for the proper syntax to create\nthese namespaces - the database user must have permission to create and drop\ntables within these schemas.  Its perfectly fine to run the test suite\nwithout these namespaces present, it only means that a handful of tests which\nexpect them to be present will fail.\n\nAdditional steps specific to individual databases are as follows::\n\n    POSTGRESQL: To enable unicode testing with JSONB, create the\n    database with UTF8 encoding::\n\n        postgres=# create database test with owner=scott encoding='utf8' template=template0;\n\n    To include tests for HSTORE and CITEXT for PostgreSQL versions lower than 13,\n    create the extensions; for PostgreSQL 13 and above, these\n    extensions are created automatically as part of the test suite if not\n    already present::\n\n        postgres=# \\c test;\n        You are now connected to database \"test\" as user \"postgresql\".\n        test=# create extension hstore;\n        CREATE EXTENSION\n        test=# create extension citext;\n        CREATE EXTENSION\n\n    Full-text search configuration should be set to English, else\n    several tests of ``.match()`` will fail. This can be set (if it isn't so\n    already) with:\n\n     ALTER DATABASE test SET default_text_search_config = 'pg_catalog.english'\n\n    For two-phase transaction support, the max_prepared_transactions\n    configuration variable must be set to a non-zero value in postgresql.conf.\n    See\n    https://www.postgresql.org/docs/current/runtime-config-resource.html#GUC-MAX-PREPARED-TRANSACTIONS\n    for further background.\n\n    ORACLE: a user named \"test_schema\" is created in addition to the default\n    user.\n\n    The primary database user needs to be able to create and drop tables,\n    synonyms, and constraints within the \"test_schema\" user.   For this\n    to work fully, including that the user has the \"REFERENCES\" role\n    in a remote schema for tables not yet defined (REFERENCES is per-table),\n    it is required that the test the user be present in the \"DBA\" role:\n\n        grant dba to scott;\n\n    MSSQL: Tests that involve multiple connections require Snapshot Isolation\n    ability implemented on the test database in order to prevent deadlocks that\n    will occur with record locking isolation. This feature is only available\n    with MSSQL 2005 and greater. You must enable snapshot isolation at the\n    database level and set the default cursor isolation with two SQL commands:\n\n     ALTER DATABASE MyDatabase SET ALLOW_SNAPSHOT_ISOLATION ON\n\n     ALTER DATABASE MyDatabase SET READ_COMMITTED_SNAPSHOT ON\n\nDocker Configurations\n---------------------\n\nThe SQLAlchemy test can run against database running in Docker containers.\nThis ensures that they are empty and that their configuration is not influenced\nby any local usage.\n\nThe following configurations are just examples that developers can use to\nquickly set up a local environment for SQLAlchemy development. They are **NOT**\nintended for production use!\n\n**PostgreSQL configuration**::\n\n    # create the container with the proper configuration for sqlalchemy\n    docker run --rm -e POSTGRES_USER='scott' -e POSTGRES_PASSWORD='tiger' -e POSTGRES_DB='test' -p 127.0.0.1:5432:5432 -d --name postgres postgres\n\n    # configure the database\n    sleep 10\n    docker exec -ti postgres psql -U scott -c 'CREATE SCHEMA test_schema; CREATE SCHEMA test_schema_2;CREATE EXTENSION hstore;CREATE EXTENSION citext;' test\n    # this last command is optional\n    docker exec -ti postgres sed -i 's/#max_prepared_transactions = 0/max_prepared_transactions = 10/g' /var/lib/postgresql/data/postgresql.conf\n\n    # To stop the container. It will also remove it.\n    docker stop postgres\n\n**MySQL configuration**::\n\n    # create the container with the proper configuration for sqlalchemy\n    docker run --rm -e MYSQL_USER='scott' -e MYSQL_PASSWORD='tiger' -e MYSQL_DATABASE='test' -e MYSQL_ROOT_PASSWORD='password' -p 127.0.0.1:3306:3306 -d --name mysql mysql --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci\n\n    # configure the database\n    sleep 20\n    docker exec -ti mysql mysql -u root -ppassword -w -e \"CREATE DATABASE test_schema CHARSET utf8mb4; GRANT ALL ON test_schema.* TO scott;\"\n\n    # To stop the container. It will also remove it.\n    docker stop mysql\n\n**MariaDB configuration**::\n\n    # create the container with the proper configuration for sqlalchemy\n    docker run --rm -e MARIADB_USER='scott' -e MARIADB_PASSWORD='tiger' -e MARIADB_DATABASE='test' -e MARIADB_ROOT_PASSWORD='password' -p 127.0.0.1:3306:3306 -d --name mariadb mariadb --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci\n\n    # configure the database\n    sleep 20\n    docker exec -ti mariadb mariadb -u root -ppassword -w -e \"CREATE DATABASE test_schema CHARSET utf8mb4; GRANT ALL ON test_schema.* TO scott;\"\n\n    # To stop the container. It will also remove it.\n    docker stop mariadb\n\n**MSSQL configuration**::\n\n    # create the container with the proper configuration for sqlalchemy\n    # it will use the Developer version\n    docker run --rm -e 'ACCEPT_EULA=Y' -e 'SA_PASSWORD=yourStrong(!)Password' -p 127.0.0.1:1433:1433 -d --name mssql mcr.microsoft.com/mssql/server\n\n    # configure the database\n    sleep 20\n    docker exec -it mssql /opt/mssql-tools/bin/sqlcmd -S localhost -U sa -P 'yourStrong(!)Password' -Q \"sp_configure 'contained database authentication', 1; RECONFIGURE; CREATE DATABASE test CONTAINMENT = PARTIAL; ALTER DATABASE test SET ALLOW_SNAPSHOT_ISOLATION ON; ALTER DATABASE test SET READ_COMMITTED_SNAPSHOT ON; CREATE LOGIN scott WITH PASSWORD = 'tiger^5HHH'; ALTER SERVER ROLE sysadmin ADD MEMBER scott;\"\n    docker exec -it mssql /opt/mssql-tools/bin/sqlcmd -S localhost -U sa -P 'yourStrong(!)Password' -d test -Q \"CREATE SCHEMA test_schema\"\n    docker exec -it mssql /opt/mssql-tools/bin/sqlcmd -S localhost -U sa -P 'yourStrong(!)Password' -d test -Q \"CREATE SCHEMA test_schema_2\"\n\n    # To stop the container. It will also remove it.\n    docker stop mssql\n\nNOTE: with this configuration the url to use is not the default one configured\nin setup, but ``mssql+pymssql://scott:tiger^5HHH@127.0.0.1:1433/test``.  It can\nbe used with pytest by using ``--db docker_mssql``.\n\n**Oracle configuration**::\n\n    # create the container with the proper configuration for sqlalchemy\n    docker run --rm --name oracle -p 127.0.0.1:1521:1521 -d -e ORACLE_PASSWORD=tiger -e ORACLE_DATABASE=test -e APP_USER=scott -e APP_USER_PASSWORD=tiger gvenzl/oracle-free:23-slim\n\n    # enter the database container and run the command\n    docker exec -ti oracle bash\n    >> sqlplus system/tiger@//localhost/FREEPDB1 <<EOF\n    CREATE USER test_schema IDENTIFIED BY tiger;\n    GRANT DBA TO SCOTT;\n    GRANT CREATE TABLE TO scott;\n    GRANT CREATE TABLE TO test_schema;\n    GRANT UNLIMITED TABLESPACE TO scott;\n    GRANT UNLIMITED TABLESPACE TO test_schema;\n    GRANT CREATE SESSION TO test_schema;\n    CREATE PUBLIC DATABASE LINK test_link CONNECT TO scott IDENTIFIED BY tiger USING 'FREEPDB1';\n    CREATE PUBLIC DATABASE LINK test_link2 CONNECT TO test_schema IDENTIFIED BY tiger USING 'FREEPDB1';\n    EOF\n\n    # To stop the container. It will also remove it.\n    docker stop oracle\n\nNOTE: with this configuration the url to use is\n``oracle+cx_oracle://scott:tiger@127.0.0.1:1521/?service_name=FREEPDB1``.  It can\nbe used with pytest by using ``--dburi oracle+cx_oracle://scott:tiger@127.0.0.1:1521/?service_name=FREEPDB1``.\n\nCONFIGURING LOGGING\n-------------------\nSQLAlchemy logs its activity and debugging through Python's logging package.\nAny log target can be directed to the console with command line options, such\nas::\n\n    $ ./pytest test/orm/test_unitofwork.py -s \\\n      --log-debug=sqlalchemy.pool --log-info=sqlalchemy.engine\n\nAbove we add the pytest \"-s\" flag so that standard out is not suppressed.\n\n\nDEVELOPING AND TESTING NEW DIALECTS\n-----------------------------------\n\nSee the file README.dialects.rst for detail on dialects.\n\n\n"
        },
        {
          "name": "doc",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "lib",
          "type": "tree",
          "content": null
        },
        {
          "name": "mypy_plugin.ini",
          "type": "blob",
          "size": 0.1591796875,
          "content": "[mypy]\nplugins = sqlalchemy.ext.mypy.plugin\nshow_error_codes = True\nmypy_path=./lib/\nstrict = True\nraise_exceptions=True\n\n[mypy-sqlalchemy.*]\nignore_errors = True\n"
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 6.65625,
          "content": "[build-system]\nbuild-backend = \"setuptools.build_meta\"\nrequires = [\n    \"setuptools>=61.0\",\n    \"cython>=3; platform_python_implementation == 'CPython'\", # Skip cython when using pypy\n]\n\n\n[project]\nname = \"SQLAlchemy\"\ndescription = \"Database Abstraction Library\"\nreadme = \"README.rst\"\nauthors = [{name = \"Mike Bayer\", email = \"mike_mp@zzzcomputing.com\"}]\nlicense = {text = \"MIT\"}\nclassifiers = [\n    \"Development Status :: 5 - Production/Stable\",\n    \"Intended Audience :: Developers\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Operating System :: OS Independent\",\n    \"Programming Language :: Python\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 3.9\",\n    \"Programming Language :: Python :: 3.10\",\n    \"Programming Language :: Python :: 3.11\",\n    \"Programming Language :: Python :: 3.12\",\n    \"Programming Language :: Python :: 3.13\",\n    \"Programming Language :: Python :: Implementation :: CPython\",\n    \"Programming Language :: Python :: Implementation :: PyPy\",\n    \"Topic :: Database :: Front-Ends\",\n]\nrequires-python = \">=3.9\"\ndependencies = [\n    \"typing-extensions >= 4.6.0\",\n]\ndynamic = [\"version\"]\n\n[project.urls]\nHomepage = \"https://www.sqlalchemy.org\"\nDocumentation = \"https://docs.sqlalchemy.org\"\nChangelog = \"https://docs.sqlalchemy.org/latest/changelog/index.html\"\n\"Source Code\" = \"https://github.com/sqlalchemy/sqlalchemy\"\n\"Issue Tracker\" = \"https://github.com/sqlalchemy/sqlalchemy/issues\"\nDiscussions = \"https://github.com/sqlalchemy/sqlalchemy/discussions\"\n\n[project.optional-dependencies]\nasyncio = [\"greenlet!=0.4.17\"]\nmypy = [\n    \"mypy >= 1.7\",\n    \"types-greenlet >= 2\"\n]\nmssql = [\"pyodbc\"]\nmssql-pymssql = [\"pymssql\"]\nmssql-pyodbc = [\"pyodbc\"]\nmysql = [\"mysqlclient>=1.4.0\"]\nmysql-connector = [\"mysql-connector-python\"]\nmariadb-connector = [\"mariadb>=1.0.1,!=1.1.2,!=1.1.5,!=1.1.10\"]\noracle = [\"cx_oracle>=8\"]\noracle-oracledb = [\"oracledb>=1.0.1\"]\npostgresql = [\"psycopg2>=2.7\"]\npostgresql-pg8000 = [\"pg8000>=1.29.3\"]\npostgresql-asyncpg = [\n    \"greenlet!=0.4.17\",  # same as \".[asyncio]\" if this syntax were supported\n    \"asyncpg\",\n]\npostgresql-psycopg2binary = [\"psycopg2-binary\"]\npostgresql-psycopg2cffi = [\"psycopg2cffi\"]\npostgresql-psycopg = [\"psycopg>=3.0.7,!=3.1.15\"]\npostgresql-psycopgbinary = [\"psycopg[binary]>=3.0.7,!=3.1.15\"]\npymysql = [\"pymysql\"]\naiomysql = [\n    \"greenlet!=0.4.17\",  # same as \".[asyncio]\" if this syntax were supported\n    \"aiomysql\",\n]\naioodbc = [\n    \"greenlet!=0.4.17\",  # same as \".[asyncio]\" if this syntax were supported\n    \"aioodbc\",\n]\nasyncmy = [\n    \"greenlet!=0.4.17\",  # same as \".[asyncio]\" if this syntax were supported\n    \"asyncmy>=0.2.3,!=0.2.4,!=0.2.6\",\n]\naiosqlite = [\n    \"greenlet!=0.4.17\",  # same as \".[asyncio]\" if this syntax were supported\n    \"aiosqlite\",\n]\nsqlcipher = [\"sqlcipher3_binary\"]\n\n# legacy pre-pep-685 names. These are ignored by pip >= 23.3.0\nmssql_pymssql = [\"sqlalchemy[mssql-pymssql]\"]\nmssql_pyodbc = [\"sqlalchemy[mssql-pyodbc]\"]\nmysql_connector = [\"sqlalchemy[mysql-connector]\"]\nmariadb_connector = [\"sqlalchemy[mariadb-connector]\"]\noracle_oracledb = [\"sqlalchemy[oracle-oracledb]\"]\npostgresql_pg8000 = [\"sqlalchemy[postgresql-pg8000]\"]\npostgresql_asyncpg = [\"sqlalchemy[postgresql-asyncpg]\"]\npostgresql_psycopg2binary = [\"sqlalchemy[postgresql-psycopg2binary]\"]\npostgresql_psycopg2cffi = [\"sqlalchemy[postgresql-psycopg2cffi]\"]\npostgresql_psycopg = [\"sqlalchemy[postgresql-psycopg]\"]\npostgresql_psycopgbinary = [\"sqlalchemy[postgresql-psycopgbinary]\"]\n\n[tool.setuptools]\ninclude-package-data = true\nlicense-files = [\"LICENSE\"]\n\n[tool.setuptools.packages.find]\nwhere = [\"lib\"]\nnamespaces = false\n\n[tool.setuptools.dynamic]\nversion = {attr = \"sqlalchemy.__version__\"}\n\n\n[tool.distutils.egg_info]\n# ref https://github.com/pypa/setuptools/discussions/3348#discussioncomment-6556887\ntag-build = \"dev\"\n\n\n[tool.black]\nline-length = 79\ntarget-version = ['py39']\n\n\n[tool.zimports]\nblack-line-length = 79\n\n\n[tool.slotscheck]\nexclude-modules = '''\n^sqlalchemy\\.(\n  testing\n  |ext\\.mypy  # see slotscheck/issues/178\n)\n'''\n\n\n# disable isort, for IDEs that just default isort to be turned on, e.g. vscode.\n# we use flake8-import-order for import sorting, using zimports to actually\n# reformat code.  isort is nicer in many ways but doesn't have our\n# \"import *\" fixer and also is not 100% compatible with flake8-import-order.\n[tool.isort]\nskip_glob=['*']\n\n\n[tool.pytest.ini_options]\naddopts = \"--tb native -v -r sfxX --maxfail=250 -p warnings -p logging --strict-markers\"\nnorecursedirs = \"examples build doc lib\"\npython_files = \"test_*.py\"\nminversion = \"6.2\"\nfilterwarnings = [\n    # NOTE: additional SQLAlchemy specific filters in\n    # sqlalchemy/testing/warnings.py.   SQLAlchemy modules cannot be named\n    # here as pytest loads them immediately, which breaks coverage as well\n    # as sys.path adjustments in conftest.py\n    \"error::DeprecationWarning:test\",\n    \"error::DeprecationWarning:sqlalchemy\",\n\n    # sqlite3 warnings due to test/dialect/test_sqlite.py->test_native_datetime,\n    # which is asserting that these deprecated-in-py312 handlers are functional\n    \"ignore:The default (date)?(time)?(stamp)? (adapter|converter):DeprecationWarning\",\n]\nmarkers = [\n    \"memory_intensive: memory / CPU intensive suite tests\",\n    \"mypy: mypy integration / plugin tests\",\n    \"timing_intensive: time-oriented tests that are sensitive to race conditions\",\n    \"backend: tests that should run on all backends; typically dialect-sensitive\",\n    \"sparse_backend: tests that should run on multiple backends, not necessarily all\",\n]\n\n\n[tool.pyright]\n\nreportPrivateUsage = \"none\"\nreportUnusedClass = \"none\"\nreportUnusedFunction = \"none\"\nreportTypedDictNotRequiredAccess = \"warning\"\n\n\n[tool.mypy]\nmypy_path = \"./lib/\"\nshow_error_codes = true\nincremental = true\n\n[[tool.mypy.overrides]]\n\nmodule = [\n    \"sqlalchemy.*\"\n]\n\nwarn_unused_ignores = true\nstrict = true\n\n[[tool.mypy.overrides]]\n\nmodule = [\"cython\", \"cython.*\"]\nignore_missing_imports = true\n\n[tool.cibuildwheel]\ntest-requires = \"pytest pytest-xdist\"\n# remove user site, otherwise the local checkout has precedence, disabling cyextensions\ntest-command = \"python -s -m pytest -c {project}/pyproject.toml -n4 -q --nomemory --notimingintensive --nomypy {project}/test\"\n\nbuild = \"*\"\n# python 3.6, 3.7 are no longer supported by sqlalchemy\n# pypy uses the universal wheel fallback, since it does not use any compiled extension\nskip = \"cp36-* cp37-* pp*\"\n# TODO: remove this skip once action support arm macs\ntest-skip = \"*-macosx_arm64\"\n\n[tool.cibuildwheel.macos]\narchs = [\"x86_64\", \"arm64\"]\n\n# On an Linux Intel runner with qemu installed, build Intel and ARM wheels\n# NOTE: this is overriden in the pipeline using the CIBW_ARCHS_LINUX env variable to speed up the build\n[tool.cibuildwheel.linux]\narchs = [\"x86_64\", \"aarch64\"]\n"
        },
        {
          "name": "reap_dbs.py",
          "type": "blob",
          "size": 0.615234375,
          "content": "\"\"\"Drop Oracle Database, SQL Server databases that are left over from a\nmultiprocessing test run.\n\nCurrently the cx_Oracle driver seems to sometimes not release a\nTCP connection even if close() is called, which prevents the provisioning\nsystem from dropping a database in-process.\n\nFor SQL Server, databases still remain in use after tests run and\nrunning a kill of all detected sessions does not seem to release the\ndatabase in process.\n\n\"\"\"\n\nimport logging\nimport sys\n\nfrom sqlalchemy.testing import provision\n\n\nlogging.basicConfig()\nlogging.getLogger(provision.__name__).setLevel(logging.INFO)\n\nprovision.reap_dbs(sys.argv[1])\n"
        },
        {
          "name": "regen_callcounts.tox.ini",
          "type": "blob",
          "size": 1.3251953125,
          "content": "[tox]\nenvlist = py{311,312}-sqla_{cext,nocext}-db_{sqlite,postgresql,mysql,oracle,mssql}\n\n[testenv]\ndeps=pytest\n     pytest-xdist\n     mock\n     db_postgresql: .[postgresql]\n     db_mysql: .[mysql]\n     db_oracle: .[oracle_oracledb]\n     db_mssql: .[mssql]\n\n\nallowlist_externals=sh\n\ncommands=\n    db_{mysql}: {env:BASECOMMAND} {env:MYSQL:} {posargs}\n    db_{postgresql}: {env:BASECOMMAND} {env:POSTGRESQL:} {posargs}\n    db_{sqlite}: {env:BASECOMMAND} {env:SQLITE:} {posargs}\n    db_{oracle}: {env:BASECOMMAND} {env:ORACLE:} {posargs}\n    db_{mssql}: {env:BASECOMMAND} {env:MSSQL:} {posargs}\n\npassenv=\n    ORACLE_HOME\n    NLS_LANG\n    TOX_POSTGRESQL\n    TOX_MYSQL\n    TOX_ORACLE\n    TOX_MSSQL\n    TOX_SQLITE\n    TOX_WORKERS\n\n# -E     : ignore PYTHON* environment variables (such as PYTHONPATH)\n# -s     : don't add user site directory to sys.path; also PYTHONNOUSERSITE\nsetenv=\n    BASECOMMAND=python -m pytest test/aaa_profiling -x --nomemory --force-write-profiles\n    PYTHONPATH=\n    PYTHONNOUSERSITE=1\n    sqla_nocext: DISABLE_SQLALCHEMY_CEXT=1\n    sqla_cext: REQUIRE_SQLALCHEMY_CEXT=1\n    db_sqlite: SQLITE={env:TOX_SQLITE:--db sqlite}\n    db_postgresql: POSTGRESQL={env:TOX_POSTGRESQL:--db postgresql}\n    db_mysql: MYSQL={env:TOX_MYSQL:--db mysql}\n    db_oracle: ORACLE={env:TOX_ORACLE:--db oracledb}\n    db_mssql: MSSQL={env:TOX_MSSQL:--db mssql}\n\n\n"
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 3.70703125,
          "content": "[flake8]\nshow-source = false\nenable-extensions = G\n\n# E203 is due to https://github.com/PyCQA/pycodestyle/issues/373\nignore =\n    A003,A005\n    D,\n    E203,E305,E701,E704,E711,E712,E721,E722,E741,\n    N801,N802,N806,\n    RST304,RST303,RST299,RST399,\n    W503,W504,W601\nextend-ignore =\n    # keep in extend ignore so that they can be enabled in a subset of files in the tox run\n    U100,U101\nexclude = .venv,.git,.tox,dist,doc,*egg,build\nimport-order-style = google\napplication-import-names = sqlalchemy,test\nper-file-ignores =\n    **/__init__.py:F401\n    test/*:FA100\n    test/typing/plain_files/*:F821,E501,FA100\n    test/ext/mypy/plugin_files/*:F821,E501,FA100\n    lib/sqlalchemy/events.py:F401\n    lib/sqlalchemy/schema.py:F401\n    lib/sqlalchemy/types.py:F401\n    lib/sqlalchemy/sql/expression.py:F401\n    lib/sqlalchemy/util/typing.py:F401\n\nunused-arguments-ignore-stub-functions=true\nunused-arguments-ignore-dunder=true\n\n[sqla_testing]\nrequirement_cls = test.requirements:DefaultRequirements\nprofile_file = test/profiles.txt\n\n# name of a \"loopback\" link set up on the oracle database.\n# to create this, suppose your DB is scott/tiger@free.  You'd create it\n# like:\n# create public database link test_link connect to scott identified by tiger\n# using 'free';\noracle_db_link = test_link\n# create public database link test_link2 connect to test_schema identified by tiger\n# using 'free';\noracle_db_link2 = test_link2\n\n# host name of a postgres database that has the postgres_fdw extension.\n# to create this run:\n# CREATE EXTENSION postgres_fdw;\n# GRANT USAGE ON FOREIGN DATA WRAPPER postgres_fdw TO public;\n# this can be localhost to create a loopback foreign table\n# postgres_test_db_link = localhost\n\n[db]\ndefault = sqlite:///:memory:\nsqlite = sqlite:///:memory:\nsqlite_numeric = sqlite+pysqlite_numeric:///:memory:\nsqlite_dollar = sqlite+pysqlite_dollar:///:memory:\naiosqlite = sqlite+aiosqlite:///:memory:\nsqlite_file = sqlite:///querytest.db\naiosqlite_file = sqlite+aiosqlite:///async_querytest.db\npysqlcipher_file = sqlite+pysqlcipher://:test@/querytest.db.enc\npostgresql = postgresql+psycopg2://scott:tiger@127.0.0.1:5432/test\npsycopg2 = postgresql+psycopg2://scott:tiger@127.0.0.1:5432/test\npsycopg = postgresql+psycopg://scott:tiger@127.0.0.1:5432/test\npsycopg_async = postgresql+psycopg_async://scott:tiger@127.0.0.1:5432/test\nasyncpg = postgresql+asyncpg://scott:tiger@127.0.0.1:5432/test\npg8000 = postgresql+pg8000://scott:tiger@127.0.0.1:5432/test\npostgresql_psycopg2cffi = postgresql+psycopg2cffi://scott:tiger@127.0.0.1:5432/test\nmysql = mysql+mysqldb://scott:tiger@127.0.0.1:3306/test?charset=utf8mb4\npymysql = mysql+pymysql://scott:tiger@127.0.0.1:3306/test?charset=utf8mb4\naiomysql = mysql+aiomysql://scott:tiger@127.0.0.1:3306/test?charset=utf8mb4\nasyncmy = mysql+asyncmy://scott:tiger@127.0.0.1:3306/test?charset=utf8mb4\nmariadb = mariadb+mysqldb://scott:tiger@127.0.0.1:3306/test\nmariadb_connector = mariadb+mariadbconnector://scott:tiger@127.0.0.1:3306/test\nmssql = mssql+pyodbc://scott:tiger^5HHH@mssql2022:1433/test?driver=ODBC+Driver+18+for+SQL+Server&TrustServerCertificate=yes&Encrypt=Optional\nmssql_async = mssql+aioodbc://scott:tiger^5HHH@mssql2022:1433/test?driver=ODBC+Driver+18+for+SQL+Server&TrustServerCertificate=yes&Encrypt=Optional\npymssql = mssql+pymssql://scott:tiger^5HHH@mssql2022:1433/test\ndocker_mssql = mssql+pyodbc://scott:tiger^5HHH@127.0.0.1:1433/test?driver=ODBC+Driver+18+for+SQL+Server&TrustServerCertificate=yes&Encrypt=Optional\noracle = oracle+cx_oracle://scott:tiger@oracle18c/xe\ncxoracle = oracle+cx_oracle://scott:tiger@oracle18c/xe\noracledb = oracle+oracledb://scott:tiger@oracle18c/xe\noracledb_async = oracle+oracledb_async://scott:tiger@oracle18c/xe\ndocker_oracle = oracle+cx_oracle://scott:tiger@127.0.0.1:1521/?service_name=FREEPDB1\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 2.2734375,
          "content": "from __future__ import annotations\n\nimport os\nimport platform\nfrom typing import cast\nfrom typing import TYPE_CHECKING\n\nfrom setuptools import setup\n\nif TYPE_CHECKING:\n    from setuptools import Extension\n\ntry:\n    from Cython.Build import build_ext as _cy_build_ext\n    from Cython.Distutils.extension import Extension as _cy_Extension\n\n    HAS_CYTHON = True\nexcept ImportError:\n    _cy_build_ext = _cy_Extension = None\n    HAS_CYTHON = False\n\nIS_CPYTHON = platform.python_implementation() == \"CPython\"\nDISABLE_EXTENSION = bool(os.environ.get(\"DISABLE_SQLALCHEMY_CEXT\"))\nREQUIRE_EXTENSION = bool(os.environ.get(\"REQUIRE_SQLALCHEMY_CEXT\"))\n\nif DISABLE_EXTENSION and REQUIRE_EXTENSION:\n    raise RuntimeError(\n        \"Cannot set both 'DISABLE_SQLALCHEMY_CEXT' and \"\n        \"'REQUIRE_SQLALCHEMY_CEXT' environment variables\"\n    )\n\n# when adding a cython module, also update the imports in _has_cython\n# it is tested in test_setup_defines_all_files\nCYTHON_MODULES = (\n    \"engine._processors_cy\",\n    \"engine._row_cy\",\n    \"engine._util_cy\",\n    \"sql._util_cy\",\n    \"util._collections_cy\",\n    \"util._immutabledict_cy\",\n)\n\nif HAS_CYTHON and IS_CPYTHON and not DISABLE_EXTENSION:\n    assert _cy_Extension is not None\n    assert _cy_build_ext is not None\n\n    cython_directives = {\"language_level\": \"3\"}\n\n    module_prefix = \"sqlalchemy.\"\n    source_prefix = \"lib/sqlalchemy/\"\n\n    ext_modules = cast(\n        \"list[Extension]\",\n        [\n            _cy_Extension(\n                f\"{module_prefix}{module}\",\n                sources=[f\"{source_prefix}{module.replace('.', '/')}.py\"],\n                cython_directives=cython_directives,\n                optional=not REQUIRE_EXTENSION,\n            )\n            for module in CYTHON_MODULES\n        ],\n    )\n\n    cmdclass = {\"build_ext\": _cy_build_ext}\n\nelif REQUIRE_EXTENSION:\n    reasons = []\n    if not HAS_CYTHON:\n        reasons.append(\"Cython is missing\")\n    if not IS_CPYTHON:\n        reasons.append(\"Not CPython, build is supported only on it\")\n    raise RuntimeError(\n        \"Cython extension build is required because REQUIRE_SQLALCHEMY_CEXT \"\n        f\"is set but it was deselected because: {'; '.join(reasons)}; \"\n        \"will not degrade to pure python install\"\n    )\n\nelse:\n    ext_modules = []\n    cmdclass = {}\n\nsetup(cmdclass=cmdclass, ext_modules=ext_modules)\n"
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "tox.ini",
          "type": "blob",
          "size": 10.7451171875,
          "content": "\n[tox]\nenvlist = py\n\n[greenletextras]\nextras=\n     asyncio\n     sqlite: aiosqlite\n     sqlite_file: aiosqlite\n     postgresql: postgresql_asyncpg\n     mysql: asyncmy\n     mysql: aiomysql\n     mssql: aioodbc\n\n     # not greenlet, but tends to not have packaging until the py version\n     # has been fully released\n     mssql: mssql_pymssql\n\n[testenv]\ncov_args=--cov=sqlalchemy --cov-report term --cov-append --cov-report xml --exclude-tag memory-intensive --exclude-tag timing-intensive -k \"not aaa_profiling\"\n\n# this needs to be set as of tox 4.4.0 *if* we have extras (e.g. .[aiosqlite])\n# inside of deps.  But we put them in extras now.\n# see https://github.com/tox-dev/tox/issues/2898\n# constrain_package_deps=false\n\nusedevelop=\n     cov: True\n\nextras=\n     py{3,39,310,311,312,313}: {[greenletextras]extras}\n\n     py{39,310}-sqlite_file: sqlcipher\n     postgresql: postgresql\n     postgresql: postgresql_pg8000\n     postgresql: postgresql_psycopg\n\n     mysql: mysql\n     mysql: pymysql\n     mysql: mariadb_connector\n\n     oracle: oracle\n     oracle: oracle_oracledb\n     mssql: mssql\n\ninstall_command=\n     # TODO: I can find no way to get pip / tox / anyone to have this\n     # --only-binary option local to the pymssql install, rather than global\n     # as it is here.\n     python -I -m pip install --only-binary=pymssql {opts} {packages}\n\ndeps=\n     pytest>=7.0.0,<8.2\n     # tracked by https://github.com/pytest-dev/pytest-xdist/issues/907\n     pytest-xdist!=3.3.0\n\n     py313: git+https://github.com/python-greenlet/greenlet.git\\#egg=greenlet\n\n     dbapimain-sqlite: git+https://github.com/omnilib/aiosqlite.git\\#egg=aiosqlite\n     dbapimain-sqlite: git+https://github.com/coleifer/sqlcipher3.git\\#egg=sqlcipher3\n\n     dbapimain-postgresql: git+https://github.com/psycopg/psycopg2.git\\#egg=psycopg2\n     dbapimain-postgresql: git+https://github.com/MagicStack/asyncpg.git\\#egg=asyncpg\n     dbapimain-postgresql: git+https://github.com/tlocke/pg8000.git\\#egg=pg8000\n     dbapimain-postgresql: git+https://github.com/psycopg/psycopg.git\\#egg=psycopg&subdirectory=psycopg\n     # dbapimain-postgresql: git+https://github.com/psycopg/psycopg.git\\#egg=psycopg-c&subdirectory=psycopg_c\n\n     dbapimain-mysql: git+https://github.com/PyMySQL/mysqlclient-python.git\\#egg=mysqlclient\n     dbapimain-mysql: git+https://github.com/PyMySQL/PyMySQL.git\\#egg=pymysql\n\n#    dbapimain-mysql: git+https://github.com/mariadb-corporation/mariadb-connector-python\\#egg=mariadb\n\n     dbapimain-oracle: git+https://github.com/oracle/python-cx_Oracle.git\\#egg=cx_Oracle\n\n     py313-mssql: git+https://github.com/mkleehammer/pyodbc.git\\#egg=pyodbc\n     dbapimain-mssql: git+https://github.com/mkleehammer/pyodbc.git\\#egg=pyodbc\n\n     cov: pytest-cov\n\nallowlist_externals=sh\n\n# PYTHONPATH - erased so that we use the build that's present\n# in .tox as the SQLAlchemy library to be imported\n#\n# PYTHONUSERSITE - this *MUST* be set so that the ./lib/ import\n# set up explicitly in test/conftest.py is *disabled*, again so that\n# when SQLAlchemy is built into the .tox area, we use that and not the\n# local checkout, at least when usedevelop=False\n#\n# BASECOMMAND - using an env variable here so we can use it\n# as a substitution in a command (see https://bitbucket.org/hpk42/tox/issues/307/)\n#\n# only use --dropfirst option if we're *not* using -n;\n# if -n is used, we're working in brand new DBs anyway, dropfirst\n# will collide on CI environments\nsetenv=\n    PYTHONPATH=\n    PYTHONNOUSERSITE=1\n    PYTEST_EXCLUDES=-m \"not memory_intensive and not mypy\"\n\n    PYTEST_COLOR={tty:--color=yes}\n    MYPY_COLOR={tty:--color-output}\n\n    BASECOMMAND=python -m pytest {env:PYTEST_COLOR} --rootdir {toxinidir} --log-info=sqlalchemy.testing\n\n    WORKERS={env:TOX_WORKERS:-n4  --max-worker-restart=5}\n\n    nocext: DISABLE_SQLALCHEMY_CEXT=1\n    cext: REQUIRE_SQLALCHEMY_CEXT=1\n    cov: COVERAGE={[testenv]cov_args}\n    backendonly: PYTEST_EXCLUDES=\"-m backend\"\n    memusage: PYTEST_EXCLUDES=\"-m memory_intensive\"\n\n    oracle: WORKERS={env:TOX_WORKERS:-n2  --max-worker-restart=5}\n    oracle: ORACLE={env:TOX_ORACLE:--db oracle}\n\n    oracle: EXTRA_ORACLE_DRIVERS={env:EXTRA_ORACLE_DRIVERS:--dbdriver cx_oracle --dbdriver oracledb --dbdriver oracledb_async}\n    py{313,314}-oracle: EXTRA_ORACLE_DRIVERS={env:EXTRA_ORACLE_DRIVERS:--dbdriver cx_oracle --dbdriver oracledb}\n\n    sqlite: SQLITE={env:TOX_SQLITE:--db sqlite}\n    sqlite_file: SQLITE={env:TOX_SQLITE_FILE:--db sqlite_file}\n\n    sqlite: EXTRA_SQLITE_DRIVERS={env:EXTRA_SQLITE_DRIVERS:--dbdriver sqlite --dbdriver pysqlite_numeric --dbdriver aiosqlite}\n    py{313,314}-sqlite: EXTRA_SQLITE_DRIVERS={env:EXTRA_SQLITE_DRIVERS:--dbdriver sqlite --dbdriver pysqlite_numeric}\n\n    sqlite-nogreenlet: EXTRA_SQLITE_DRIVERS={env:EXTRA_SQLITE_DRIVERS:--dbdriver sqlite --dbdriver pysqlite_numeric}\n\n    py{39}-sqlite_file: EXTRA_SQLITE_DRIVERS={env:EXTRA_SQLITE_DRIVERS:--dbdriver sqlite --dbdriver aiosqlite --dbdriver pysqlcipher}\n\n    # omit pysqlcipher for Python 3.10\n    py{3,310,311,312}-sqlite_file: EXTRA_SQLITE_DRIVERS={env:EXTRA_SQLITE_DRIVERS:--dbdriver sqlite --dbdriver aiosqlite}\n\n    postgresql: POSTGRESQL={env:TOX_POSTGRESQL:--db postgresql}\n\n    postgresql: EXTRA_PG_DRIVERS={env:EXTRA_PG_DRIVERS:--dbdriver psycopg2 --dbdriver asyncpg --dbdriver pg8000 --dbdriver psycopg --dbdriver psycopg_async}\n    postgresql-nogreenlet: EXTRA_PG_DRIVERS={env:EXTRA_PG_DRIVERS:--dbdriver psycopg2 --dbdriver pg8000 --dbdriver psycopg}\n\n    # limit driver list for memusage target\n    memusage: EXTRA_SQLITE_DRIVERS={env:EXTRA_SQLITE_DRIVERS:--dbdriver sqlite}\n    memusage: EXTRA_PG_DRIVERS={env:EXTRA_PG_DRIVERS:--dbdriver psycopg2}\n    # limit workers for memusage\n    memusage: WORKERS={env:TOX_WORKERS:-n2}\n\n    mysql: MYSQL={env:TOX_MYSQL:--db mysql}\n    mysql: EXTRA_MYSQL_DRIVERS={env:EXTRA_MYSQL_DRIVERS:--dbdriver mysqldb --dbdriver pymysql --dbdriver asyncmy --dbdriver aiomysql --dbdriver mariadbconnector}\n    mysql-nogreenlet: EXTRA_MYSQL_DRIVERS={env:EXTRA_MYSQL_DRIVERS:--dbdriver mysqldb --dbdriver pymysql --dbdriver mariadbconnector}\n\n    mssql: MSSQL={env:TOX_MSSQL:--db mssql}\n\n    mssql: EXTRA_MSSQL_DRIVERS={env:EXTRA_MSSQL_DRIVERS:--dbdriver pyodbc --dbdriver aioodbc --dbdriver pymssql}\n    py{313,314}-mssql: EXTRA_MSSQL_DRIVERS={env:EXTRA_MSSQL_DRIVERS:--dbdriver pyodbc  --dbdriver aioodbc}\n\n    mssql-nogreenlet: EXTRA_MSSQL_DRIVERS={env:EXTRA_MSSQL_DRIVERS:--dbdriver pyodbc --dbdriver pymssql}\n    py{313,314}-mssql-nogreenlet: EXTRA_MSSQL_DRIVERS={env:EXTRA_MSSQL_DRIVERS:--dbdriver pyodbc}\n\n    oracle,mssql,sqlite_file: IDENTS=--write-idents db_idents.txt\n\n# tox as of 2.0 blocks all environment variables from the\n# outside, unless they are here (or in TOX_TESTENV_PASSENV,\n# wildcards OK).  Need at least these\npassenv=\n    ORACLE_HOME\n    NLS_LANG\n    TOX_POSTGRESQL\n    TOX_POSTGRESQL_PY2K\n    TOX_MYSQL\n    TOX_MYSQL_PY2K\n    TOX_ORACLE\n    TOX_MSSQL\n    TOX_SQLITE\n    TOX_SQLITE_FILE\n    TOX_WORKERS\n    EXTRA_SQLITE_DRIVERS\n    EXTRA_PG_DRIVERS\n    EXTRA_MYSQL_DRIVERS\n    EXTRA_ORACLE_DRIVERS\n\ncommands=\n\n  # this line is only meaningful when usedevelop=True is enabled.  we use\n  # that flag for coverage mode.\n  nocext: sh -c \"rm -f lib/sqlalchemy/*.so\"\n  nogreenlet: pip uninstall -y greenlet\n  {env:BASECOMMAND} {env:WORKERS} {env:SQLITE:} {env:EXTRA_SQLITE_DRIVERS:} {env:POSTGRESQL:} {env:EXTRA_PG_DRIVERS:} {env:MYSQL:} {env:EXTRA_MYSQL_DRIVERS:} {env:ORACLE:} {env:EXTRA_ORACLE_DRIVERS:} {env:MSSQL:} {env:EXTRA_MSSQL_DRIVERS:} {env:IDENTS:} {env:PYTEST_EXCLUDES:} {env:COVERAGE:} {posargs}\n  oracle,mssql,sqlite_file: python reap_dbs.py db_idents.txt\n\n\n[testenv:pep484]\ndeps=\n     greenlet != 0.4.17\n     mypy >= 1.14.0\n     types-greenlet\ncommands =\n    mypy  {env:MYPY_COLOR} ./lib/sqlalchemy\n    # pyright changes too often with not-exactly-correct errors\n    # suddently appearing for it to be stable enough for CI\n    # pyright\n\nextras =\n     {[greenletextras]extras}\n\n[testenv:mypy]\ndeps=\n     pytest>=7.0.0rc1,<8\n     pytest-xdist\n     greenlet != 0.4.17\n     mypy >= 1.7.0,<1.11.0\n     patch==1.*\n     types-greenlet\nextras=\n     {[greenletextras]extras}\n\ncommands =\n    pytest {env:PYTEST_COLOR} -m mypy {posargs}\n\n[testenv:mypy-cov]\n\ndeps=\n     {[testenv:mypy]deps}\n     pytest-cov\n\nextras=\n     {[greenletextras]extras}\n\ncommands =\n    pytest {env:PYTEST_COLOR} -m mypy {env:COVERAGE} {posargs}\n\nsetenv=\n    COVERAGE={[testenv]cov_args}\n\n# thanks to https://julien.danjou.info/the-best-flake8-extensions/\n[testenv:lint]\nbasepython = python3\n\nextras=\n     {[greenletextras]extras}\n\ndeps=\n      flake8==6.1.0\n      flake8-import-order\n      flake8-builtins\n      flake8-future-annotations>=0.0.5\n      flake8-docstrings>=1.6.0\n      flake8-import-single==0.1.5\n      flake8-unused-arguments\n      flake8-rst-docstrings\n      # flake8-rst-docstrings dependency, leaving it here\n      # in case it requires a version pin\n      pydocstyle\n      pygments\n      black==24.10.0\n      slotscheck>=0.17.0\n\n      # required by generate_tuple_map_overloads\n      zimports\nallowlist_externals =\n    env\n    git\n    sh\ncommands =\n     flake8 ./lib/ ./test/ ./examples/ setup.py doc/build/conf.py {posargs}\n     # run flake8-unused-arguments only on some files / modules\n     flake8  --extend-ignore='' ./lib/sqlalchemy/ext/asyncio ./lib/sqlalchemy/orm/scoping.py\n     black --check ./lib/ ./test/ ./examples/ setup.py doc/build/conf.py\n     slotscheck -m sqlalchemy\n     python ./tools/format_docs_code.py --check\n     python ./tools/generate_tuple_map_overloads.py --check\n     python ./tools/generate_proxy_methods.py --check\n     python ./tools/sync_test_files.py --check\n     python ./tools/generate_sql_functions.py --check\n     python ./tools/normalize_file_headers.py --check\n     python ./tools/cython_imports.py --check\n     python ./tools/walk_packages.py\n\n\n# \"pep8\" env was renamed to \"lint\".\n# Kept for backwards compatibility until rename is completed elsewhere.\n[testenv:pep8]\nbasepython = {[testenv:lint]basepython}\ndeps = {[testenv:lint]deps}\nallowlist_externals = {[testenv:lint]allowlist_externals}\ncommands = {[testenv:lint]commands}\nextras = {[testenv:lint]extras}\n\n\n\n# command run in the github action when cext are active.\n[testenv:github-cext]\nextras=\n     {[greenletextras]extras}\n\ndeps = {[testenv]deps}\n       .[aiosqlite]\ncommands=\n  python -m pytest {env:PYTEST_COLOR} {env:WORKERS} {env:SQLITE:} {env:POSTGRESQL:} {env:MYSQL:} {env:ORACLE:} {env:MSSQL:} {env:IDENTS:} {env:PYTEST_EXCLUDES:} {env:COVERAGE:} {posargs}\n  oracle,mssql,sqlite_file: python reap_dbs.py db_idents.txt\n\n# command run in the github action when cext are not active.\n[testenv:github-nocext]\nextras=\n     {[greenletextras]extras}\n\ndeps = {[testenv]deps}\n       .[aiosqlite]\ncommands=\n  python -m pytest {env:PYTEST_COLOR} {env:WORKERS} {env:SQLITE:} {env:POSTGRESQL:} {env:MYSQL:} {env:ORACLE:} {env:MSSQL:} {env:IDENTS:} {env:PYTEST_EXCLUDES:} {env:COVERAGE:} {posargs}\n  oracle,mssql,sqlite_file: python reap_dbs.py db_idents.txt\n"
        }
      ]
    }
  ]
}