{
  "metadata": {
    "timestamp": 1736560620252,
    "page": 250,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI1MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "jianchang512/clone-voice",
      "stars": 7844,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.1669921875,
          "content": ".git/\r\n.github/\r\n.vscode/\r\ncache/\r\ndocker/\r\ntts/\r\n.dockerignore\r\n.gitignore\r\n.env\r\napp.log\r\nenvironment.yml\r\nrunapp.bat\r\nruntrain.bat\r\n# Ignore generated files\r\n**/*.pyc\r\n"
        },
        {
          "name": ".env",
          "type": "blob",
          "size": 0.0615234375,
          "content": "HTTP_PROXY=\nWEB_ADDRESS=127.0.0.1:9988\nENABLE_STS=0\nDEVICE=CUDA"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.5283203125,
          "content": ".idea/\n*.pyc\n*.pyd\n.DS_Store\n__pycache__\nscripts\n\nku\nbuild\ndist\ndocs\ninclude\nLib\nnotebooks\nrecipes\nshare\nvenv\ntests\ndev\nffmpeg.exe\nffprobe.exe\n*.zip\n*.rar\n\n*.exe\n*.log\npyvenv.cfg\nsetup.cfg\n*.pth\n*.pt\ncn1.wav\nsx1.wav\n\n*.spec\ntts/tts_models--multilingual--multi-dataset--xtts_v2\ntts/voice_conversion_models--multilingual--vctk--freevc24\ntts/wavlm\ntts/*.7z\ntts_cache/*\ntts/mymodels/xiaomi\ntts/1voice_conversion_models--multilingual--vctk--freevc24\n\nhubconf.py\nstatic/ttslist/*\nstatic/tmp/*.wav\nstatic/ttslist/*.wav\n*.pth\n*.out\n*.bin\n*.7z\n\ncache"
        },
        {
          "name": ".vscode",
          "type": "tree",
          "content": null
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 4.4599609375,
          "content": "æœ¬é¡¹ç›®æ‰€ç”¨æ¨¡å‹ä¸º[coqui.ai](https://coqui.ai/)å‡ºå“çš„xtts_v2ï¼Œæ¨¡å‹å¼€æºåè®®ä¸º[Coqui Public Model License 1.0.0](https://coqui.ai/cpml.txt),ä½¿ç”¨æœ¬é¡¹ç›®è¯·éµå¾ªè¯¥åè®®ï¼Œåè®®å…¨æ–‡è§ https://coqui.ai/cpml.txt\n\n\nThe model used in this project is xtts_v2 produced by [coqui.ai](https://coqui.ai/), and the model open source license is [Coqui Public Model License 1.0.0](https://coqui.ai/cpml.txt) , please follow this agreement when using this project. The full text of the agreement can be found at https://coqui.ai/cpml.txt\n\n----\n\n\nCoqui Public Model License 1.0.0\n\nhttps://coqui.ai/cpml.txt\n\nThis license allows only non-commercial use of a machine learning model and its outputs.\nAcceptance\n\nIn order to get any license under these terms, you must agree to them as both strict obligations and conditions to all your licenses.\nLicenses\n\nThe licensor grants you a copyright license to do everything you might do with the model that would otherwise infringe the licensor's copyright in it, for any non-commercial purpose. The licensor grants you a patent license that covers patent claims the licensor can license, or becomes able to license, that you would infringe by using the model in the form provided by the licensor, for any non-commercial purpose.\nNon-commercial Purpose\n\nNon-commercial purposes include any of the following uses of the model or its output, but only so far as you do not receive any direct or indirect payment arising from the use of the model or its output.\n\n    Personal use for research, experiment, and testing for the benefit of public knowledge, personal study, private entertainment, hobby projects, amateur pursuits, or religious observance.\n    Use by commercial or for-profit entities for testing, evaluation, or non-commercial research and development. Use of the model to train other models for commercial use is not a non-commercial purpose.\n    Use by any charitable organization for charitable purposes, or for testing or evaluation. Use for revenue-generating activity, including projects directly funded by government grants, is not a non-commercial purpose.\n\nNotices\n\nYou must ensure that anyone who gets a copy of any part of the model, or any modification of the model, or their output, from you also gets a copy of these terms or the URL for them above.\nNo Other Rights\n\nThese terms do not allow you to sublicense or transfer any of your licenses to anyone else, or prevent the licensor from granting licenses to anyone else. These terms do not imply any other licenses.\nPatent Defense\n\nIf you make any written claim that the model infringes or contributes to infringement of any patent, your licenses for the model granted under these terms ends immediately. If your company makes such a claim, your patent license ends immediately for work on behalf of your company.\nViolations\n\nThe first time you are notified in writing that you have violated any of these terms, or done anything with the model or its output that is not covered by your licenses, your licenses can nonetheless continue if you come into full compliance with these terms, and take practical steps to correct past violations, within 30 days of receiving notice. Otherwise, all your licenses end immediately.\nNo Liability\n\nAS FAR AS THE LAW ALLOWS, THE MODEL AND ITS OUTPUT COME AS IS, WITHOUT ANY WARRANTY OR CONDITION, AND THE LICENSOR WILL NOT BE LIABLE TO YOU FOR ANY DAMAGES ARISING OUT OF THESE TERMS OR THE USE OR NATURE OF THE MODEL OR ITS OUTPUT, UNDER ANY KIND OF LEGAL CLAIM. IF THIS PROVISION IS NOT ENFORCEABLE IN YOUR JURISDICTION, YOUR LICENSES ARE VOID.\nDefinitions\n\nThe licensor is the individual or entity offering these terms, and the model is the model the licensor makes available under these terms, including any documentation or similar information about the model.\n\nYou refers to the individual or entity agreeing to these terms.\n\nYour company is any legal entity, sole proprietorship, or other kind of organization that you work for, plus all organizations that have control over, are under the control of, or are under common control with that organization. Control means ownership of substantially all the assets of an entity, or the power to direct its management and policies by vote, contract, or otherwise. Control can be direct or indirect.\n\nYour licenses are all the licenses granted to you under these terms.\n\nUse means anything you do with the model or its output requiring one of your licenses.\nWe collect and process your personal information for visitor statistics and browsing behavior. ğŸª "
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 9.7412109375,
          "content": "[English README](./README_EN.md)  / [æåŠ©é¡¹ç›®](https://github.com/jianchang512/pyvideotrans/issues/80) / [Discord](https://discord.gg/7ZWbwKGMcx)\n\n# CVå£°éŸ³å…‹éš†å·¥å…·\n\n> æœ¬é¡¹ç›®æ‰€ç”¨æ¨¡å‹ä¸º[coqui.ai](https://coqui.ai/)å‡ºå“çš„xtts_v2ï¼Œæ¨¡å‹å¼€æºåè®®ä¸º[Coqui Public Model License 1.0.0](https://coqui.ai/cpml.txt),ä½¿ç”¨æœ¬é¡¹ç›®è¯·éµå¾ªè¯¥åè®®ï¼Œåè®®å…¨æ–‡è§ https://coqui.ai/cpml.txt\n\n\n è¿™æ˜¯ä¸€ä¸ªå£°éŸ³å…‹éš†å·¥å…·ï¼Œå¯ä½¿ç”¨ä»»ä½•äººç±»éŸ³è‰²ï¼Œå°†ä¸€æ®µæ–‡å­—åˆæˆä¸ºä½¿ç”¨è¯¥éŸ³è‰²è¯´è¯çš„å£°éŸ³ï¼Œæˆ–è€…å°†ä¸€ä¸ªå£°éŸ³ä½¿ç”¨è¯¥éŸ³è‰²è½¬æ¢ä¸ºå¦ä¸€ä¸ªå£°éŸ³ã€‚\n \n ä½¿ç”¨éå¸¸ç®€å•ï¼Œæ²¡æœ‰Nå¡GPUä¹Ÿå¯ä»¥ä½¿ç”¨ï¼Œä¸‹è½½é¢„ç¼–è¯‘ç‰ˆæœ¬ï¼ŒåŒå‡» app.exe æ‰“å¼€ä¸€ä¸ªwebç•Œé¢ï¼Œé¼ æ ‡ç‚¹ç‚¹å°±èƒ½ç”¨ã€‚\n \n æ”¯æŒ **ä¸­ã€è‹±ã€æ—¥ã€éŸ©ã€æ³•ã€å¾·ã€æ„ç­‰16ç§è¯­è¨€**ï¼Œå¯åœ¨çº¿ä»éº¦å…‹é£å½•åˆ¶å£°éŸ³ã€‚\n \n ä¸ºä¿è¯åˆæˆæ•ˆæœï¼Œå»ºè®®å½•åˆ¶æ—¶é•¿5ç§’åˆ°20ç§’ï¼Œå‘éŸ³æ¸…æ™°å‡†ç¡®ï¼Œä¸è¦å­˜åœ¨èƒŒæ™¯å™ªå£°ã€‚\n \n è‹±æ–‡æ•ˆæœå¾ˆæ£’ï¼Œä¸­æ–‡æ•ˆæœè¿˜å‡‘åˆã€‚\n\n\n> **[èµåŠ©å•†]**\n> \n> [![](https://github.com/user-attachments/assets/5348c86e-2d5f-44c7-bc1b-3cc5f077e710)](https://gpt302.saaslink.net/teRK8Y)\n>  [302.AI](https://gpt302.saaslink.net/teRK8Y)æ˜¯ä¸€ä¸ªæŒ‰éœ€ä»˜è´¹çš„ä¸€ç«™å¼AIåº”ç”¨å¹³å°ï¼Œå¼€æ”¾å¹³å°ï¼Œå¼€æºç”Ÿæ€, [302.AIå¼€æºåœ°å€](https://github.com/302ai)\n> \n> é›†åˆäº†æœ€æ–°æœ€å…¨çš„AIæ¨¡å‹å’Œå“ç‰Œ/æŒ‰éœ€ä»˜è´¹é›¶æœˆè´¹/ç®¡ç†å’Œä½¿ç”¨åˆ†ç¦»/æ‰€æœ‰AIèƒ½åŠ›å‡æä¾›API/æ¯å‘¨æ¨å‡º2-3ä¸ªæ–°åº”ç”¨\n\n\n# è§†é¢‘æ¼”ç¤º\n\n\nhttps://github.com/jianchang512/clone-voice/assets/3378335/4e63f2ac-cc68-4324-a4d9-ecf4d4f81acd\n\n\n\n![image](https://github.com/jianchang512/clone-voice/assets/3378335/5401a3f8-1623-452b-b0b3-cb2efe87e3d1)\n\n\n\n\n# windowé¢„ç¼–è¯‘ç‰ˆä½¿ç”¨æ–¹æ³•(å…¶ä»–ç³»ç»Ÿå¯æºç éƒ¨ç½²)\n\n1. [ç‚¹å‡»æ­¤å¤„æ‰“å¼€Releasesä¸‹è½½é¡µé¢](https://github.com/jianchang512/clone-voice/releases)ï¼Œä¸‹è½½é¢„ç¼–è¯‘ç‰ˆä¸»æ–‡ä»¶(1.7G) å’Œ æ¨¡å‹(3G)\n\n2. ä¸‹è½½åè§£å‹åˆ°æŸå¤„ï¼Œæ¯”å¦‚ E:/clone-voice ä¸‹\n\n3. åŒå‡» app.exe ï¼Œç­‰å¾…è‡ªåŠ¨æ‰“å¼€webçª—å£ï¼Œ**è¯·ä»”ç»†é˜…è¯»cmdçª—å£çš„æ–‡å­—æç¤º**,å¦‚æœ‰é”™è¯¯ï¼Œå‡ä¼šåœ¨æ­¤æ˜¾ç¤º\n\n4. æ¨¡å‹ä¸‹è½½åè§£å‹åˆ°è½¯ä»¶ç›®å½•ä¸‹çš„ `tts` æ–‡ä»¶å¤¹å†…ï¼Œè§£å‹åæ•ˆæœå¦‚å›¾ \n\n![image](https://github.com/jianchang512/clone-voice/assets/3378335/4b5a60eb-124d-404b-a748-c0a527482e90)\n\n5. è½¬æ¢æ“ä½œæ­¥éª¤\n\t\n\t- é€‰æ‹©ã€æ–‡å­—->å£°éŸ³ã€‘æŒ‰é’®ï¼Œåœ¨æ–‡æœ¬æ¡†ä¸­è¾“å…¥æ–‡å­—ã€æˆ–ç‚¹å‡»å¯¼å…¥srtå­—å¹•æ–‡ä»¶ï¼Œç„¶åç‚¹å‡»â€œç«‹å³å¼€å§‹â€ã€‚\n\t\n\t- é€‰æ‹©ã€å£°éŸ³->å£°éŸ³ã€‘æŒ‰é’®ï¼Œç‚¹å‡»æˆ–æ‹–æ‹½è¦è½¬æ¢çš„éŸ³é¢‘æ–‡ä»¶(mp3/wav/flac)ï¼Œç„¶åä»â€œè¦ä½¿ç”¨çš„å£°éŸ³æ–‡ä»¶â€ä¸‹æ‹‰æ¡†ä¸­é€‰æ‹©è¦å…‹éš†çš„éŸ³è‰²ï¼Œå¦‚æœæ²¡æœ‰æ»¡æ„çš„ï¼Œä¹Ÿå¯ä»¥ç‚¹å‡»â€œæœ¬åœ°ä¸Šä¼ â€æŒ‰é’®ï¼Œé€‰æ‹©å·²å½•åˆ¶å¥½çš„5-20sçš„wav/mp3/flacå£°éŸ³æ–‡ä»¶ã€‚æˆ–è€…ç‚¹å‡»â€œå¼€å§‹å½•åˆ¶â€æŒ‰é’®ï¼Œåœ¨çº¿å½•åˆ¶ä½ è‡ªå·±çš„å£°éŸ³5-20sï¼Œå½•åˆ¶å®Œæˆç‚¹å‡»ä½¿ç”¨ã€‚ç„¶åç‚¹å‡»â€œç«‹å³å¼€å§‹â€æŒ‰é’®\n\t\n6. å¦‚æœæœºå™¨æ‹¥æœ‰Nå¡GPUï¼Œå¹¶æ­£ç¡®é…ç½®äº†CUDAç¯å¢ƒï¼Œå°†è‡ªåŠ¨ä½¿ç”¨CUDAåŠ é€Ÿ\n\n\n\n# æºç éƒ¨ç½²(linux mac window)\n\n**æºç ç‰ˆéœ€è¦åœ¨ .env ä¸­ HTTP_PROXY=è®¾ç½®ä»£ç†(æ¯”å¦‚http://127.0.0.1:7890)ï¼Œè¦ä» https://huggingface.co https://github.com ä¸‹è½½æ¨¡å‹ï¼Œè€Œè¿™ä¸ªç½‘å€å›½å†…æ— æ³•è®¿é—®ï¼Œå¿…é¡»ä¿è¯ä»£ç†ç¨³å®šå¯é ï¼Œå¦åˆ™å¤§æ¨¡å‹ä¸‹è½½å¯èƒ½ä¸­é€”å¤±è´¥**\n\n0. è¦æ±‚ python 3.9->3.11, å¹¶ä¸”æå‰å®‰è£…å¥½ git-cmd å·¥å…·ï¼Œ[ä¸‹è½½åœ°å€](https://github.com/git-for-windows/git/releases/download/v2.44.0.windows.1/Git-2.44.0-64-bit.exe)\n1. åˆ›å»ºç©ºç›®å½•ï¼Œæ¯”å¦‚ E:/clone-voice, åœ¨è¿™ä¸ªç›®å½•ä¸‹æ‰“å¼€ cmd çª—å£ï¼Œæ–¹æ³•æ˜¯åœ°å€æ ä¸­è¾“å…¥ `cmd`, ç„¶åå›è½¦ã€‚\nä½¿ç”¨gitæ‹‰å–æºç åˆ°å½“å‰ç›®å½• ` git clone git@github.com:jianchang512/clone-voice.git . `\n2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ `python -m venv venv`\n3. æ¿€æ´»ç¯å¢ƒï¼Œwinä¸‹ `E:/clone-voice/venv/scripts/activate`ï¼Œ\n4. å®‰è£…ä¾èµ–: `pip install -r requirements.txt --no-deps`, \nwindows å’Œ linux å¦‚æœè¦å¯ç”¨cudaåŠ é€Ÿï¼Œç»§ç»­æ‰§è¡Œ `pip uninstall -y torch` å¸è½½ï¼Œç„¶åæ‰§è¡Œ`pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu121`ã€‚(å¿…é¡»æœ‰Nå¡å¹¶ä¸”é…ç½®å¥½CUDAç¯å¢ƒ)\n5. winä¸‹è§£å‹ ffmpeg.7zï¼Œå°†å…¶ä¸­çš„`ffmpeg.exe`å’Œ`app.py`åœ¨åŒä¸€ç›®å½•ä¸‹, linuxå’Œmac åˆ° [ffmpegå®˜ç½‘](https://ffmpeg.org/download.html)ä¸‹è½½å¯¹åº”ç‰ˆæœ¬ffmpegï¼Œè§£å‹å…¶ä¸­çš„`ffmpeg`ç¨‹åºåˆ°æ ¹ç›®å½•ä¸‹ï¼Œå¿…é¡»å°†å¯æ‰§è¡ŒäºŒè¿›åˆ¶æ–‡ä»¶ `ffmpeg` å’Œapp.pyæ”¾åœ¨åŒä¸€ç›®å½•ä¸‹ã€‚\n\n   ![image](https://github.com/jianchang512/clone-voice/assets/3378335/0c61c8b6-7f7e-475f-8984-47fb87ba58e8)\n\n6. **é¦–å…ˆè¿è¡Œ**  `python  code_dev.py `ï¼Œåœ¨æç¤ºåŒæ„åè®®æ—¶ï¼Œè¾“å…¥ `y`ï¼Œç„¶åç­‰å¾…æ¨¡å‹ä¸‹è½½å®Œæ¯•ã€‚\n   ![](./images/code_dev01.png)\n   ![](./images/code_dev02.png)\n   \n\tä¸‹è½½æ¨¡å‹éœ€è¦æŒ‚å…¨å±€ä»£ç†ï¼Œæ¨¡å‹éå¸¸å¤§ï¼Œå¦‚æœä»£ç†ä¸å¤Ÿç¨³å®šå¯é ï¼Œå¯èƒ½ä¼šé‡åˆ°å¾ˆå¤šé”™è¯¯ï¼Œå¤§éƒ¨åˆ†çš„é”™è¯¯å‡æ˜¯ä»£ç†é—®é¢˜å¯¼è‡´ã€‚\n\t\n\tå¦‚æœæ˜¾ç¤ºä¸‹è½½å¤šä¸ªæ¨¡å‹å‡æˆåŠŸäº†ï¼Œä½†æœ€åè¿˜æ˜¯æç¤ºâ€œDownloading WavLM modelâ€é”™è¯¯ï¼Œåˆ™éœ€è¦ä¿®æ”¹åº“åŒ…æ–‡ä»¶ `\\venv\\Lib\\site-packages\\aiohttp\\client.py`, åœ¨å¤§çº¦535è¡Œé™„è¿‘ï¼Œ`if proxy is not None:` ä¸Šé¢ä¸€è¡Œæ·»åŠ ä½ çš„ä»£ç†åœ°å€ï¼Œæ¯”å¦‚ `proxy=\"http://127.0.0.1:10809\"`.\n\n7. ä¸‹è½½å®Œæ¯•åï¼Œå†å¯åŠ¨ `python app.py`\n\n8. **ã€è®­ç»ƒè¯´æ˜ã€‘** å¦‚æœæƒ³è®­ç»ƒï¼Œæ‰§è¡Œ `python train.py`, è®­ç»ƒå‚æ•°åœ¨ `param.json`ä¸­è°ƒæ•´ï¼Œè°ƒæ•´åé‡æ–°æ‰§è¡Œè®­ç»ƒè„šæœ¬`python train.py`\n\n8. æ¯æ¬¡å¯åŠ¨éƒ½ä¼šè¿æ¥å¢™å¤–æ£€æµ‹æˆ–æ›´æ–°æ¨¡å‹ï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚å¦‚æœä¸æƒ³æ¯æ¬¡å¯åŠ¨éƒ½æ£€æµ‹æˆ–æ›´æ–°ï¼Œéœ€æ‰‹åŠ¨ä¿®æ”¹ä¾èµ–åŒ…ä¸‹æ–‡ä»¶ï¼Œæ‰“å¼€ \\venv\\Lib\\site-packages\\TTS\\utils\\manage.py ,å¤§çº¦ 389 è¡Œé™„è¿‘ï¼Œdef download_model æ–¹æ³•ä¸­ï¼Œæ³¨é‡Šæ‰å¦‚ä¸‹ä»£ç \n\n```\nif md5sum is not None:\n\tmd5sum_file = os.path.join(output_path, \"hash.md5\")\n\tif os.path.isfile(md5sum_file):\n\t    with open(md5sum_file, mode=\"r\") as f:\n\t\tif not f.read() == md5sum:\n\t\t    print(f\" > {model_name} has been updated, clearing model cache...\")\n\t\t    self.create_dir_and_download_model(model_name, model_item, output_path)\n\t\telse:\n\t\t    print(f\" > {model_name} is already downloaded.\")\n\telse:\n\t    print(f\" > {model_name} has been updated, clearing model cache...\")\n\t    self.create_dir_and_download_model(model_name, model_item, output_path)\n```\n\n9. æºç ç‰ˆå¯åŠ¨æ—¶å¯èƒ½é¢‘ç¹é‡åˆ°é”™è¯¯ï¼ŒåŸºæœ¬éƒ½æ˜¯ä»£ç†é—®é¢˜å¯¼è‡´æ— æ³•ä»å¢™å¤–ä¸‹è½½æ¨¡å‹æˆ–ä¸‹è½½ä¸­æ–­ä¸å®Œæ•´ã€‚å»ºè®®ä½¿ç”¨ç¨³å®šçš„ä»£ç†ï¼Œå…¨å±€å¼€å¯ã€‚å¦‚æœå§‹ç»ˆæ— æ³•å®Œæ•´ä¸‹è½½ï¼Œå»ºè®®ä½¿ç”¨é¢„ç¼–è¯‘ç‰ˆã€‚\n\n\n\n\n# å¸¸è§é—®é¢˜\n\n**æ¨¡å‹xttsä»…å¯ç”¨äºå­¦ä¹ ç ”ç©¶ï¼Œä¸å¯ç”¨äºå•†ä¸š**\n\n0. æºç ç‰ˆéœ€è¦åœ¨ .env ä¸­ HTTP_PROXY=è®¾ç½®ä»£ç†(æ¯”å¦‚http://127.0.0.1:7890)ï¼Œè¦ä» https://huggingface.co https://github.com ä¸‹è½½æ¨¡å‹ï¼Œè€Œè¿™ä¸ªç½‘å€å›½å†…æ— æ³•è®¿é—®ï¼Œå¿…é¡»ä¿è¯ä»£ç†ç¨³å®šå¯é ï¼Œå¦åˆ™å¤§æ¨¡å‹ä¸‹è½½å¯èƒ½ä¸­é€”å¤±è´¥\n\n1. å¯åŠ¨åéœ€è¦å†·åŠ è½½æ¨¡å‹ï¼Œä¼šæ¶ˆè€—ä¸€äº›æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…æ˜¾ç¤ºå‡º`http://127.0.0.1:9988`ï¼Œ å¹¶è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨é¡µé¢åï¼Œç¨ç­‰ä¸¤ä¸‰åˆ†é’Ÿåå†è¿›è¡Œè½¬æ¢\n\n2. åŠŸèƒ½æœ‰ï¼š\n\n\t\tæ–‡å­—åˆ°è¯­éŸ³:å³è¾“å…¥æ–‡å­—ï¼Œç”¨é€‰å®šçš„éŸ³è‰²ç”Ÿæˆå£°éŸ³ã€‚\n\t\t\n\t\tå£°éŸ³åˆ°å£°éŸ³ï¼šå³ä»æœ¬åœ°é€‰æ‹©ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼Œç”¨é€‰å®šçš„éŸ³è‰²ç”Ÿæˆå¦ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶.\n\t\t\n3. å¦‚æœæ‰“å¼€çš„cmdçª—å£å¾ˆä¹…ä¸åŠ¨ï¼Œéœ€è¦åœ¨ä¸Šé¢æŒ‰ä¸‹å›è½¦æ‰ç»§ç»­è¾“å‡ºï¼Œè¯·åœ¨cmdå·¦ä¸Šè§’å›¾æ ‡ä¸Šå•å‡»ï¼Œé€‰æ‹©â€œå±æ€§â€ï¼Œç„¶åå–æ¶ˆâ€œå¿«é€Ÿç¼–è¾‘â€å’Œâ€œæ’å…¥æ¨¡å¼â€çš„å¤é€‰æ¡†\n\n![](./images/3.png)\n![](./images/4.png)\n\n\n4. é¢„ç¼–è¯‘ç‰ˆ å£°éŸ³-å£°éŸ³çº¿ç¨‹å¯åŠ¨å¤±è´¥\n\n   é¦–å…ˆç¡®è®¤æ¨¡å‹å·²æ­£ç¡®ä¸‹è½½æ”¾ç½®ã€‚ttsæ–‡ä»¶å¤¹å†…æœ‰3ä¸ªæ–‡ä»¶å¤¹ï¼Œå¦‚ä¸‹å›¾\n   ![image](https://github.com/jianchang512/clone-voice/assets/3378335/4b5a60eb-124d-404b-a748-c0a527482e90)\n\n   å¦‚æœå·²æ­£ç¡®æ”¾ç½®äº†ï¼Œä½†ä»é”™è¯¯ï¼Œ[ç‚¹å‡»ä¸‹è½½ extra-to-tts_cache.zip](https://github.com/jianchang512/clone-voice/releases/download/v0.0.1/extra-to-tts_cache.zip) ï¼Œå°†è§£å‹åå¾—åˆ°çš„2ä¸ªæ–‡ä»¶ï¼Œå¤åˆ¶åˆ°è½¯ä»¶æ ¹ç›®å½•çš„ tts_cache æ–‡ä»¶å¤¹å†…\n\n   å¦‚æœä¸Šè¿°æ–¹æ³•æ— æ•ˆï¼Œåœ¨ .env æ–‡ä»¶ä¸­ HTTP_PROXYåå¡«å†™ä»£ç†åœ°å€æ¯”å¦‚ `HTTP_PROXY=http://127.0.0.1:7890`ï¼Œå¯è§£å†³è¯¥é—®é¢˜ï¼Œå¿…é¡»ç¡®ä¿ä»£ç†ç¨³å®šï¼Œå¡«å†™ç«¯å£æ­£ç¡®\n\n5. æç¤º â€œThe text length exceeds the character limit of 182/82 for languageâ€\n\n   è¿™æ˜¯å› ä¸ºç”±å¥å·åˆ†éš”çš„å¥å­å¤ªé•¿å¯¼è‡´çš„ï¼Œå»ºè®®å°†å¤ªé•¿çš„è¯­å¥ä½¿ç”¨å¥å·éš”å¼€ï¼Œè€Œä¸æ˜¯å¤§é‡ä½¿ç”¨é€—å·ï¼Œæˆ–è€…ä½ ä¹Ÿå¯ä»¥æ‰“å¼€ clone/character.jsonæ–‡ä»¶ï¼Œæ‰‹åŠ¨ä¿®æ”¹é™åˆ¶\n   \n6. æç¤º\"symbol not found __svml_cosf8_ha\"\n\næ‰“å¼€ç½‘é¡µ https://www.dll-files.com/svml_dispmd.dll.html ,ç‚¹å‡»çº¢è‰²\"Download\"ä¸‹è½½å­—æ ·ï¼Œä¸‹è½½åè§£å‹ï¼Œå°†é‡Œé¢çš„dllæ–‡ä»¶å¤åˆ¶ç²˜è´´åˆ°\"C:\\Windows\\System32\"\n   \n\n\n\n# CUDA åŠ é€Ÿæ”¯æŒ\n\n**å®‰è£…CUDAå·¥å…·** [è¯¦ç»†å®‰è£…æ–¹æ³•](https://juejin.cn/post/7318704408727519270)\n\nå¦‚æœä½ çš„ç”µè„‘æ‹¥æœ‰ Nvidia æ˜¾å¡ï¼Œå…ˆå‡çº§æ˜¾å¡é©±åŠ¨åˆ°æœ€æ–°ï¼Œç„¶åå»å®‰è£…å¯¹åº”çš„ \n   [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads)  å’Œ  [cudnn for CUDA11.X](https://developer.nvidia.com/rdp/cudnn-archive)ã€‚\n   \n   å®‰è£…å®Œæˆæˆï¼ŒæŒ‰`Win + R`,è¾“å…¥ `cmd`ç„¶åå›è½¦ï¼Œåœ¨å¼¹å‡ºçš„çª—å£ä¸­è¾“å…¥`nvcc --version`,ç¡®è®¤æœ‰ç‰ˆæœ¬ä¿¡æ¯æ˜¾ç¤ºï¼Œç±»ä¼¼è¯¥å›¾\n   ![image](https://github.com/jianchang512/pyvideotrans/assets/3378335/e68de07f-4bb1-4fc9-bccd-8f841825915a)\n\n   ç„¶åç»§ç»­è¾“å…¥`nvidia-smi`,ç¡®è®¤æœ‰è¾“å‡ºä¿¡æ¯ï¼Œå¹¶ä¸”èƒ½çœ‹åˆ°cudaç‰ˆæœ¬å·ï¼Œç±»ä¼¼è¯¥å›¾\n   ![image](https://github.com/jianchang512/pyvideotrans/assets/3378335/71f1d7d3-07f9-4579-b310-39284734006b)\n\n   è¯´æ˜å®‰è£…æ­£ç¡®ï¼Œå¯ä»¥cudaåŠ é€Ÿäº†ï¼Œå¦åˆ™éœ€é‡æ–°å®‰è£…\n\n\n\n# ç›¸å…³è”é¡¹ç›®\n\n[è§†é¢‘ç¿»è¯‘é…éŸ³å·¥å…·:ç¿»è¯‘å­—å¹•å¹¶é…éŸ³](https://github.com/jianchang512/pyvideotrans)\n\n[è¯­éŸ³è¯†åˆ«å·¥å…·:æœ¬åœ°ç¦»çº¿çš„è¯­éŸ³è¯†åˆ«è½¬æ–‡å­—å·¥å…·](https://github.com/jianchang512/stt)\n\n[äººå£°èƒŒæ™¯ä¹åˆ†ç¦»:æç®€çš„äººå£°å’ŒèƒŒæ™¯éŸ³ä¹åˆ†ç¦»å·¥å…·ï¼Œæœ¬åœ°åŒ–ç½‘é¡µæ“ä½œ](https://github.com/jianchang512/vocal-separate)\n\n\n# [Youtubeæ¼”ç¤ºè§†é¢‘](https://youtu.be/CC227GXOJLk)\n"
        },
        {
          "name": "README_EN.md",
          "type": "blob",
          "size": 7.98828125,
          "content": "[ç®€ä½“ä¸­æ–‡](./README.md) / [Discord](https://discord.gg/TMCM2PfHzQ) / [Buy me a coffee](https://ko-fi.com/jianchang512) / [Twitter](https://twitter.com/mortimer_wang)\n\n# CV Voice Clone Tool\n\n> The model used in this project is xtts_v2 produced by [coqui.ai](https://coqui.ai/), and the model open source license is [Coqui Public Model License 1.0.0](https://coqui.ai/cpml.txt) , please follow this agreement when using this project. The full text of the agreement can be found at https://coqui.ai/cpml.txt\n\n\n \n This is a voice cloning tool that can use any human voice to synthesize a piece of text into a voice using that voice, or to convert one voice into another using that voice. \n \n It's very easy to use, even without an N-series GPU. Download the precompiled version and double click on app.exe to open a web interface, and it can be used with a few mouse clicks. \n \n Supports **Chinese English Japanese Korean eg. total 16 languages**, and can record voices online through a microphone. \n \n To ensure the synthesized effect, it's recommended to record for 5 to 20 seconds, pronounce clearly and accurately, and don't have background noise. \n \n \n\n\n# Video Demonstration\n\n\n\nhttps://github.com/jianchang512/clone-voice/assets/3378335/813d46dd-7634-43d1-97ae-1531369c471f\n\n\n\n\n\n![image](https://github.com/jianchang512/clone-voice/assets/3378335/e4cfee2a-20f1-4395-b1b9-b3f7015502a2)\n\n\n\n\n# How to use the precompiled version under win (other systems can deploy source code)\n\n\n1. Download the 'precompiled version of the main file(1.7G) and Model(3G) separately from [Releases](https://github.com/jianchang512/clone-voice/releases) on the right. \n2. After downloading, unzip it to somewhere, for example E:/clone-voice. \n3. Double click app.exe, wait for the web window to open automatically, **Please read the text prompts in the CMD window carefully**, if there are errors, they will be displayed here.\n\n\n4. After the model download, unzip it to the tts folder under the software directory, the effect after unzipping is as shown in the picture\n\n\n![image](https://github.com/jianchang512/clone-voice/assets/3378335/4b5a60eb-124d-404b-a748-c0a527482e90)\n\n5. Conversion operation steps:\n\t\n\t- Enter the text in the text box, or import the SRT file, or select \"Voice-> Voice\", choose the voice wav format file you want to convert.\n\t\n\t- Then select the voice you want to use from the drop-down box under \"Voice wav file to use\", if you are not satisfied, you can also click the \"Upload locally\" button, select a recorded 5-20s wav voice file. Or click the \"Start recording\" button to record your own voice for 5-20 seconds online, after recording, click to use.\n\t\n\t- Click the \"Start Generating Now\" button and wait patiently for completion.\n\n6. If the machine has an N card GPU and CUDA environment is correctly configured, CUDA acceleration will be used automatically.\n\n\n# Source Code Deployment (linux mac window) / Example: window\n\n**If your area can't access google and huggingface, you'll need a global proxy because models need to be downloaded from github and huggingface**\n\n\n0. Required python 3.9-> 3.11, and enable a global proxy, ensure the proxy is stable\n1. Create an empty directory, such as E:/clone-voice, open a cmd window in this directory, the method is to type `cmd` in the address bar, then press Enter.\nand exec git pull source code `git clone git@github.com:jianchang512/clone-voice.git . `\n2. Create a virtual environment `python -m venv venv`\n3. Activate the environment `E:/clone-voice/venv/scripts/activate`, linux and Mac exec `source ./venv/bin/activate`\n4. Install dependencies: `pip install -r requirements.txt`\n5. Unzip the ffmpeg.7z to the project root directory;for Linux and Mac, download the corresponding version of ffmpeg from the [ffmpeg official website](https://ffmpeg.org/download.html), unzip it to the root directory, and make sure to place the executable file ffmepg directly in the root directory.\n\n    ![image](https://github.com/jianchang512/clone-voice/assets/3378335/0c61c8b6-7f7e-475f-8984-47fb87ba58e8)\n   \n6. **First run** `python code_dev.py`, enter `y` when prompted to accept the agreement, then wait for the model to be downloaded completely.\n   ![](./images/code_dev02.png)\n\n\n7. After downloading, restart `python app.py`.\n\n8. Every startup will connect to the foreign Internet to check or update the model, please be patient and wait. If you don't want to check or update every time you start, you need to manually modify the files under the dependent package, open \\venv\\Lib\\site-packages\\TTS\\utils\\manage.py, around line 389, def download_model method, comment out the following code.\n\n```\nif md5sum is not None:\n\tmd5sum_file = os.path.join(output_path, \"hash.md5\")\n\tif os.path.isfile(md5sum_file):\n\t    with open(md5sum_file, mode=\"r\") as f:\n\t\tif not f.read() == md5sum:\n\t\t    print(f\" > {model_name} has been updated, clearing model cache...\")\n\t\t    self.create_dir_and_download_model(model_name, model_item, output_path)\n\t\telse:\n\t\t    print(f\" > {model_name} is already downloaded.\")\n\telse:\n\t    print(f\" > {model_name} has been updated, clearing model cache...\")\n\t    self.create_dir_and_download_model(model_name, model_item, output_path)\n```\n\n9. The startup of the source code version may frequently encounter errors, which are basically due to proxy problems that prevent the download of models from the walls or the download is interrupted and not complete. It is recommended to use a stable proxy and open it globally. If you can't download completely all the time, it's recommended to use the precompiled version.\n\n\n# CUDA Acceleration Support\n\n**Installation of CUDA tools**\n\nIf your computer has Nvidia graphics card, upgrade the graphics card driver to the latest, then go to install the corresponding [CUDA Toolkit 11.8](https://developer.nvidia.com/cuda-downloads) and [cudnn for CUDA11.X](https://developer.nvidia.com/rdp/cudnn-archive).\n   \nWhen installation is complete, press `Win + R`, type `cmd` then press Enter, in the pop-up window type `nvcc --version`, confirm the version information display, similar to this image\n   ![image](https://github.com/jianchang512/pyvideotrans/assets/3378335/e68de07f-4bb1-4fc9-bccd-8f841825915a)\n   \nThen continue to type `nvidia-smi`, confirm there's output information, and you can see the cuda version number, similar to this image\n   ![image](https://github.com/jianchang512/pyvideotrans/assets/3378335/71f1d7d3-07f9-4579-b310-39284734006b)\n\nThat means the installation is correct, you can cuda accelerate now, otherwise you need to reinstall.\n\n\n\n# Precautions\n\nThe model xtts can only be used for study and research, not for commerical use\n\n0. The source code version requires global proxy, because it needs to download models from https://huggingface.co, and this website can't be accessed in China, the source code version may frequently encounter errors when starting, basically proxy problems lead to unable to download models from overseas or download interruption incomplete. It's recommended to use a stable proxy, open it globally. If you can't download completely all the time, it's recommended to use the precompiled version.\n\n1. It will consume some time to load the model coldly after starting, please wait patiently for `http://127.0.0.1:9988` to be displayed, and automatically open the browser page, wait for two or three minutes before converting.\n\n2. Functions include:\n\n\t\tText to voice: that is, enter the text, generate voice with the selected voice.\n\t\t\n\t\tVoice to Voice: that is, select an audio file from the local area, generate another audio file with the selected voice.\n\t\t\n3. If the cmd window opened for a long time doesn't move, you need to press Enter on it to continue output, please click on the icon in the upper left corner of cmd, select \"Properties\", then uncheck the \"Quick Edit\" and \"Insert Mode\" checkboxes\n\n\n\n4. â€œThe text length exceeds the character limit of 182/82 for languageâ€\n\n  This is because sentences separated by periods are too long. It is recommended to use periods to separate sentences that are too long, rather than excessive use of commas,\n\n\n\n# [Youtube Demo Video](https://youtu.be/NL5cIoJ9Gjo)\n"
        },
        {
          "name": "app.py",
          "type": "blob",
          "size": 16.8603515625,
          "content": "import datetime\nimport logging\nimport queue\nimport re\nimport threading\nimport time\nimport sys\nfrom flask import Flask, request, render_template, jsonify, send_file, send_from_directory\nimport os\nimport glob\nimport hashlib\nfrom logging.handlers import RotatingFileHandler\n\nimport clone\nfrom clone import cfg\nfrom clone.cfg import ROOT_DIR, TTS_DIR, VOICE_MODEL_EXITS, TMP_DIR, VOICE_DIR, TEXT_MODEL_EXITS, langlist\nfrom clone.logic import ttsloop, stsloop, create_tts, openweb, merge_audio_segments, get_subtitle_from_srt, updatecache\nfrom clone import logic\nimport shutil\nimport subprocess\nfrom dotenv import load_dotenv\nfrom waitress import serve\nload_dotenv()\n\nweb_address = os.getenv('WEB_ADDRESS', '127.0.0.1:9988')\nenable_sts = int(os.getenv('ENABLE_STS', '0'))\n\n\n\nupdatecache()\n\n# é…ç½®æ—¥å¿—\n# ç¦ç”¨ Werkzeug é»˜è®¤çš„æ—¥å¿—å¤„ç†å™¨\nlog = logging.getLogger('werkzeug')\nlog.handlers[:] = []\nlog.setLevel(logging.WARNING)\n\napp = Flask(__name__, static_folder=os.path.join(ROOT_DIR, 'static'), static_url_path='/static',\n            template_folder=os.path.join(ROOT_DIR, 'templates'))\n\nroot_log = logging.getLogger()  # Flaskçš„æ ¹æ—¥å¿—è®°å½•å™¨\nroot_log.handlers = []\nroot_log.setLevel(logging.WARNING)\n\napp.logger.setLevel(logging.WARNING)  # è®¾ç½®æ—¥å¿—çº§åˆ«ä¸º INFO\n# åˆ›å»º RotatingFileHandler å¯¹è±¡ï¼Œè®¾ç½®å†™å…¥çš„æ–‡ä»¶è·¯å¾„å’Œå¤§å°é™åˆ¶\nfile_handler = RotatingFileHandler(os.path.join(ROOT_DIR, 'app.log'), maxBytes=1024 * 1024, backupCount=5)\n# åˆ›å»ºæ—¥å¿—çš„æ ¼å¼\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n# è®¾ç½®æ–‡ä»¶å¤„ç†å™¨çš„çº§åˆ«å’Œæ ¼å¼\nfile_handler.setLevel(logging.WARNING)\nfile_handler.setFormatter(formatter)\n# å°†æ–‡ä»¶å¤„ç†å™¨æ·»åŠ åˆ°æ—¥å¿—è®°å½•å™¨ä¸­\napp.logger.addHandler(file_handler)\napp.jinja_env.globals.update(enumerate=enumerate)\n\n\n\n@app.route('/static/<path:filename>')\ndef static_files(filename):\n    return send_from_directory(app.config['STATIC_FOLDER'], filename)\n\n\n@app.route('/')\ndef index():\n    return render_template(\"index.html\",\n                           text_model=TEXT_MODEL_EXITS,\n                           voice_model=VOICE_MODEL_EXITS,\n                           version=clone.ver,\n                           mymodels=cfg.MYMODEL_OBJS,\n                           language=cfg.LANG,\n                           langlist=cfg.langlist,\n                           root_dir=ROOT_DIR.replace('\\\\', '/'))\n\n\n# ä¸Šä¼ éŸ³é¢‘\n@app.route('/upload', methods=['POST'])\n@app.route('/upload', methods=['POST'])\ndef upload():\n    try:\n        # è·å–ä¸Šä¼ çš„æ–‡ä»¶\n        audio_file = request.files['audio']\n        save_dir = request.form.get(\"save_dir\")\n        save_dir = VOICE_DIR if not save_dir else os.path.join(ROOT_DIR, f'static/{save_dir}')\n        app.logger.info(f\"[upload]{audio_file.filename=},{save_dir=}\")\n        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æ˜¯ WAV/mp3æ ¼å¼\n        noextname, ext = os.path.splitext(os.path.basename(audio_file.filename.lower()))\n        noextname = noextname.replace(' ', '')\n        if audio_file and ext in [\".wav\", \".mp3\", \".flac\"]:\n            # ä¿å­˜æ–‡ä»¶åˆ°æœåŠ¡å™¨æŒ‡å®šç›®å½•\n            name = f'{noextname}{ext}'\n            if os.path.exists(os.path.join(save_dir, f'{noextname}{ext}')):\n                name = f'{datetime.datetime.now().strftime(\"%m%d-%H%M%S\")}-{noextname}{ext}'\n            # mp3 or wav           \n            tmp_wav = os.path.join(TMP_DIR, \"tmp_\" + name)\n            audio_file.save(tmp_wav)\n            # save to wav\n            if ext != '.wav':\n                name = f\"{name[:-len(ext)]}.wav\"\n            savename = os.path.join(save_dir, name)\n            subprocess.run(['ffmpeg', '-hide_banner', '-y', '-i', tmp_wav, savename], check=True)\n            try:\n                os.unlink(tmp_wav)\n            except:\n                pass\n            # è¿”å›æˆåŠŸçš„å“åº”\n            return jsonify({'code': 0, 'msg': 'ok', \"data\": name})\n        else:\n            # è¿”å›é”™è¯¯çš„å“åº”\n            return jsonify({'code': 1, 'msg': 'not wav'})\n    except Exception as e:\n        app.logger.error(f'[upload]error: {e}')\n        return jsonify({'code': 2, 'msg': 'error'})\n\n\n# ä» voicelist ç›®å½•è·å–å¯ç”¨çš„ wav å£°éŸ³åˆ—è¡¨\n@app.route('/init')\ndef init():\n    wavs = glob.glob(f\"{VOICE_DIR}/*.wav\")\n    result = []\n    for it in wavs:\n        if os.path.getsize(it) > 0:\n            result.append(os.path.basename(it))\n    result.extend(cfg.MYMODEL_OBJS.keys())\n    return jsonify(result)\n\n\n# åˆ¤æ–­çº¿ç¨‹æ˜¯å¦å¯åŠ¨\n@app.route('/isstart', methods=['GET', 'POST'])\ndef isstart():\n    return jsonify(cfg.MYMODEL_OBJS)\n\n\n# å¤–éƒ¨æ¥å£\n@app.route('/apitts', methods=['GET', 'POST'])\ndef apitts():\n    '''\n    audio:åŸå§‹å£°éŸ³wav,ä½œä¸ºéŸ³è‰²å…‹éš†æº\n    voice:å·²æœ‰çš„å£°éŸ³åå­—ï¼Œå¦‚æœå­˜åœ¨ voiceåˆ™å…ˆä½¿ç”¨ï¼Œå¦åˆ™ä½¿ç”¨audio\n    text:æ–‡å­—ä¸€è¡Œ\n    languageï¼šè¯­è¨€ä»£ç \n    Returns:\n    '''\n    try:\n        langcodelist = [\"zh-cn\", \"en\", \"ja\", \"ko\", \"es\", \"de\", \"fr\", \"it\", \"tr\", \"ru\", \"pt\", \"pl\", \"nl\", \"ar\", \"hu\", \"cs\"]\n        text = request.form.get(\"text\",\"\").strip()\n        model = request.form.get(\"model\",\"\").strip()\n        text = text.replace(\"\\n\", ' . ')\n        language = request.form.get(\"language\", \"\").lower()\n        if language.startswith(\"zh\"):\n            language = \"zh-cn\"\n        if language not in langcodelist:\n            return jsonify({\"code\": 1, \"msg\": f\" {language} dont support language \"})\n\n        md5_hash = hashlib.md5()\n\n        audio_name = request.form.get('voice','')\n        voicename=\"\"\n        model=\"\"\n        # å­˜åœ¨ä¼ æ¥çš„å£°éŸ³æ–‡ä»¶åå­—\n        print(f'1,{text=},{model=},{audio_name=},{language=}')\n        if audio_name and audio_name.lower().endswith('.wav'):\n            voicename = os.path.join(VOICE_DIR, audio_name)\n            if not os.path.exists(voicename):\n                return jsonify({\"code\": 2, \"msg\": f\"{audio_name} ä¸å­˜åœ¨\"})\n            if os.path.isdir(voicename):\n                model=audio_name\n                voicename=\"\"\n        elif audio_name:\n            #å­˜åœ¨ï¼Œæ˜¯æ–°æ¨¡å‹\n            model=audio_name\n        elif not audio_name:  # ä¸å­˜åœ¨ï¼ŒåŸå£°å¤åˆ¶ clone è·å–ä¸Šä¼ çš„æ–‡ä»¶\n            audio_file = request.files['audio']\n            print(f'{audio_file.filename}')\n            # ä¿å­˜ä¸´æ—¶ä¸Šä¼ è¿‡æ¥çš„å£°éŸ³æ–‡ä»¶\n            audio_name = f'video_{audio_file.filename}.wav'\n            voicename = os.path.join(TMP_DIR, audio_name)\n            audio_file.save(voicename)\n        print(f'22={text=},{model=},{audio_name=},{language=}')\n        md5_hash.update(f\"{text}-{language}-{audio_name}-{model}\".encode('utf-8'))\n\n        app.logger.info(f\"[apitts]{voicename=}\")\n        if re.match(r'^[~`!@#$%^&*()_+=,./;\\':\\[\\]{}<>?\\\\|\"ï¼Œã€‚ï¼Ÿï¼›â€˜ï¼šâ€œâ€â€™ï½›ã€ã€‘ï½ï¼Â·ï¿¥ã€\\s\\n\\r -]*$', text):\n            return jsonify({\"code\": 3, \"msg\": \"lost text for translate\"})\n        if not text or not language:\n            return jsonify({\"code\": 4, \"msg\": \"text & language params lost\"})\n        app.logger.info(f\"[apitts]{text=},{language=}\")\n\n        # å­˜æ”¾ç»“æœ\n        # åˆæˆåçš„è¯­éŸ³æ–‡ä»¶, ä»¥wavæ ¼å¼å­˜æ”¾å’Œè¿”å›\n        filename = md5_hash.hexdigest() + \".wav\"\n        app.logger.info(f\"[apitts]{filename=}\")\n        # åˆæˆè¯­éŸ³\n        rs = create_tts(text=text,model=model, speed=1.0, voice=voicename, language=language, filename=filename)\n        # å·²æœ‰ç»“æœæˆ–é”™è¯¯ï¼Œç›´æ¥è¿”å›\n        if rs is not None:\n            print(f'{rs=}')\n            result = rs\n        else:\n            # å¾ªç¯ç­‰å¾… æœ€å¤š7200s\n            time_tmp = 0\n            while filename not in cfg.global_tts_result:\n                time.sleep(3)\n                time_tmp += 3\n                if time_tmp % 30 == 0:\n                    app.logger.info(f\"[apitts][tts]{time_tmp=},{filename=}\")\n                if time_tmp>3600:\n                    return jsonify({\"code\": 5, \"msg\": f'error:{text}'})\n                    \n\n            # å½“å‰è¡Œå·²å®Œæˆåˆæˆ\n            target_wav = os.path.normpath(os.path.join(TTS_DIR, filename))\n            if not os.path.exists(target_wav):\n                msg = {\"code\": 6, \"msg\": cfg.global_tts_result[filename] if filename in cfg.global_tts_result else \"error\"}\n            else:\n                \n                msg = {\"code\": 0, \"filename\": target_wav, 'name': filename}\n            app.logger.info(f\"[apitts][tts] {filename=},{msg=}\")\n            try:\n                cfg.global_tts_result.pop(filename)\n            except:\n                pass\n            result = msg\n            app.logger.info(f\"[apitts]{msg=}\")\n        if result['code'] == 0:\n            result['url'] = f'http://{web_address}/static/ttslist/{filename}'\n        return jsonify(result)\n    except Exception as e:\n        msg = f'{str(e)} {str(e.args)}'\n        app.logger.error(f\"[apitts]{msg}\")\n        return jsonify({'code': 7, 'msg': msg})\n\n\n# æ ¹æ®æ–‡æœ¬è¿”å›ttsç»“æœï¼Œè¿”å› name=æ–‡ä»¶åå­—ï¼Œfilename=æ–‡ä»¶ç»å¯¹è·¯å¾„\n# è¯·æ±‚ç«¯æ ¹æ®éœ€è¦è‡ªè¡Œé€‰æ‹©ä½¿ç”¨å“ªä¸ª\n# params\n# text:å¾…åˆæˆæ–‡å­—\n# voiceï¼šå£°éŸ³æ–‡ä»¶\n# language:è¯­è¨€ä»£ç \n@app.route('/tts', methods=['GET', 'POST'])\ndef tts():\n    # åŸå§‹å­—ç¬¦ä¸²\n    text = request.form.get(\"text\",\"\").strip()\n    voice = request.form.get(\"voice\",'')\n    speed = 1.0\n    try:\n        speed = float(request.form.get(\"speed\",1))\n    except:\n        pass\n    language = request.form.get(\"language\",'')\n    model = request.form.get(\"model\",\"\")\n    app.logger.info(f\"[tts][tts]recev {text=}\\n{voice=},{language=}\\n\")\n\n    if re.match(r'^[~`!@#$%^&*()_+=,./;\\':\\[\\]{}<>?\\\\|\"ï¼Œã€‚ï¼Ÿï¼›â€˜ï¼šâ€œâ€â€™ï½›ã€ã€‘ï½ï¼Â·ï¿¥ã€\\s\\n\\r -]*$', text):\n        return jsonify({\"code\": 1, \"msg\": \"no text\"})\n    if not text or not voice or not language:\n        return jsonify({\"code\": 1, \"msg\": \"text/voice/language params lost\"})\n\n    # åˆ¤æ–­æ˜¯å¦æ˜¯srt\n    text_list = get_subtitle_from_srt(text)\n    app.logger.info(f\"[tts][tts]{text_list=}\")\n    is_srt = True\n    # ä¸æ˜¯srtæ ¼å¼,åˆ™æŒ‰è¡Œåˆ†å‰²\n    if text_list is None:\n        is_srt = False\n        text_list = []\n        for it in text.split(\"\\n\"):\n            text_list.append({\"text\": it.strip()})\n        app.logger.info(f\"[tts][tts] its not srt\")\n\n    num = 0\n    while num < len(text_list):\n        t = text_list[num]\n        # æ¢è¡Œç¬¦æ”¹æˆ .\n        t['text'] = t['text'].replace(\"\\n\", ' . ')\n        md5_hash = hashlib.md5()\n        md5_hash.update(f\"{t['text']}-{voice}-{language}-{speed}-{model}\".encode('utf-8'))\n        filename = md5_hash.hexdigest() + \".wav\"\n        app.logger.info(f\"[tts][tts]{filename=}\")\n        # åˆæˆè¯­éŸ³\n        rs = create_tts(text=t['text'], model=model,speed=speed, voice=os.path.join(cfg.VOICE_DIR, voice), language=language, filename=filename)\n        # å·²æœ‰ç»“æœæˆ–é”™è¯¯ï¼Œç›´æ¥è¿”å›\n        if rs is not None:\n            text_list[num]['result'] = rs\n            num += 1\n            continue\n        # å¾ªç¯ç­‰å¾… æœ€å¤š7200s\n        time_tmp = 0\n        # ç”Ÿæˆçš„ç›®æ ‡éŸ³é¢‘\n        target_wav = os.path.normpath(os.path.join(TTS_DIR, filename))\n        msg=None\n        while filename not in cfg.global_tts_result and not os.path.exists(target_wav):\n            time.sleep(3)\n            time_tmp += 3\n            if time_tmp % 30 == 0:\n                app.logger.info(f\"[tts][tts]{time_tmp=},{filename=}\")\n            if time_tmp>3600:\n                msg={\"code\": 1, \"msg\":f'{filename} error'}\n                text_list[num]['result'] = msg\n                num+=1\n                break\n        if msg is not None:\n            continue\n                \n\n        # å½“å‰è¡Œå·²å®Œæˆåˆæˆ\n        if not os.path.exists(target_wav):\n            msg = {\"code\": 1, \"msg\": \"not exists\"}\n        else:\n            if speed != 1.0 and speed > 0 and speed <= 2.0:\n                # ç”Ÿæˆçš„åŠ é€ŸéŸ³é¢‘\n                speed_tmp = os.path.join(TMP_DIR, f'speed_{time.time()}.wav')\n                p = subprocess.run(\n                    ['ffmpeg', '-hide_banner', '-ignore_unknown', '-y', '-i', target_wav, '-af', f\"atempo={speed}\",\n                     os.path.normpath(speed_tmp)], encoding=\"utf-8\", capture_output=True)\n                if p.returncode != 0:\n                    return jsonify({\"code\": 1, \"msg\": str(p.stderr)})\n                shutil.copy2(speed_tmp, target_wav)\n            msg = {\"code\": 0, \"filename\": target_wav, 'name': filename}\n        app.logger.info(f\"[tts][tts] {filename=},{msg=}\")\n        try:\n            cfg.global_tts_result.pop(filename)\n        except:\n            pass\n        text_list[num]['result'] = msg\n        app.logger.info(f\"[tts][tts]{num=}\")\n        num += 1\n\n    filename, errors = merge_audio_segments(text_list, is_srt=is_srt)\n    app.logger.info(f\"[tts][tts]is srtï¼Œ{filename=},{errors=}\")\n    if filename and os.path.exists(filename) and os.path.getsize(filename) > 0:\n        res = {\"code\": 0, \"filename\": filename, \"name\": os.path.basename(filename), \"msg\": errors}\n    else:\n        res = {\"code\": 1, \"msg\": f\"error:{filename=},{errors=}\"}\n    app.logger.info(f\"[tts][tts]end result:{res=}\")\n    return jsonify(res)\n\n\n# s to s wav->wav\n# params\n# voice: å£°éŸ³æ–‡ä»¶\n# filename: ä¸Šä¼ çš„åŸå§‹å£°éŸ³\n\n@app.route('/sts', methods=['GET', 'POST'])\ndef sts():\n    try:\n        # ä¿å­˜æ–‡ä»¶åˆ°æœåŠ¡å™¨æŒ‡å®šç›®å½•\n        # ç›®æ ‡\n        voice = request.form.get(\"voice\",'')\n        filename = request.form.get(\"name\",'')\n        app.logger.info(f\"[sts][sts]sts {voice=},{filename=}\\n\")\n\n        if not voice:\n            return jsonify({\"code\": 1, \"msg\": \"voice params lost\"})\n\n        obj = {\"filename\": filename, \"voice\": voice}\n        # å‹å…¥é˜Ÿåˆ—ï¼Œå‡†å¤‡è½¬æ¢è¯­éŸ³\n        app.logger.info(f\"[sts][sts]push sts\")\n        cfg.q_sts.put(obj)\n        # å·²æœ‰ç»“æœæˆ–é”™è¯¯ï¼Œç›´æ¥è¿”å›\n        # å¾ªç¯ç­‰å¾… æœ€å¤š7200s\n        time_tmp = 0\n        while filename not in cfg.global_sts_result:\n            time.sleep(3)\n            time_tmp += 3\n            if time_tmp % 30 == 0:\n                app.logger.info(f\"{time_tmp=}ï¼Œ{filename=}\")\n\n        # å½“å‰è¡Œå·²å®Œæˆåˆæˆ\n        if cfg.global_sts_result[filename] != 1:\n            msg = {\"code\": 1, \"msg\": cfg.global_sts_result[filename]}\n            app.logger.error(f\"[sts][sts]errorï¼Œ{msg=}\")\n        else:\n            msg = {\"code\": 0, \"filename\": os.path.join(TTS_DIR, filename), 'name': filename}\n            app.logger.info(f\"[sts][sts]ok,{msg=}\")\n        cfg.global_sts_result.pop(filename)\n        return jsonify(msg)\n    except Exception as e:\n        app.logger.error(f\"[sts][sts]error:{str(e)}\")\n        return jsonify({'code': 2, 'msg': f'voice->voice:{str(e)}'})\n\n\n\n\n# å¯åŠ¨æˆ–å…³é—­æ¨¡å‹\n@app.route('/onoroff',methods=['GET','POST'])\ndef onoroff():\n    name = request.form.get(\"name\",'')\n    status_new = request.form.get(\"status_new\",'')\n    if status_new=='on':\n        if name not in cfg.MYMODEL_OBJS  or not cfg.MYMODEL_OBJS[name] or  isinstance(cfg.MYMODEL_OBJS[name],str):\n            try:\n                print(f'start {name}...')\n                res=logic.load_model(name)\n                print(f'{res=}')\n                return jsonify({\"code\":0,\"msg\":res})\n            except Exception as e:\n                return jsonify({\"code\":1,\"msg\":str(e)})\n        elif cfg.MYMODEL_OBJS[name] in ['error','no']:\n            return jsonify({\"code\":0,\"msg\":\"æ¨¡å‹å¯åŠ¨å‡ºé”™æˆ–ä¸å­˜åœ¨\"})\n        return jsonify({\"code\":0,\"msg\":\"å·²å¯åŠ¨\"})\n    else:\n        #å…³é—­\n        cfg.MYMODEL_OBJS[name]=None\n        #åˆ é™¤é˜Ÿåˆ—\n        cfg.MYMODEL_QUEUE[name]=None\n        return jsonify({\"code\":0,\"msg\":\"å·²åœæ­¢\"})\n\n@app.route('/checkupdate', methods=['GET', 'POST'])\ndef checkupdate():\n    return jsonify({'code': 0, \"msg\": cfg.updatetips})\n\n@app.route('/stsstatus', methods=['GET', 'POST'])\ndef stsstatus():\n    return jsonify({'code': 0, \"msg\": \"start\" if cfg.sts_status else \"stop\"})\n\n\n\nif __name__ == '__main__':\n\n    tts_thread = None\n    sts_thread = None\n    try:\n        if 'app.py' == sys.argv[0] and 'app.py' == os.path.basename(__file__):\n            print(langlist[\"lang1\"])\n\n        threading.Thread(target=logic.checkupdate).start()\n\n        # å¦‚æœå­˜åœ¨é»˜è®¤æ¨¡å‹åˆ™å¯åŠ¨\n        \n        if TEXT_MODEL_EXITS:\n            print(\"\\n\"+langlist['lang2'])\n            tts_thread = threading.Thread(target=ttsloop)\n            tts_thread.start()\n        else:\n            app.logger.error(\n                f\"\\n{langlist['lang3']}: {cfg.download_address}\\n\")\n            input(f\"\\n{langlist['lang3']}: {cfg.download_address}\\n\")\n            sys.exit()\n        \n        if enable_sts==1 and VOICE_MODEL_EXITS:\n            print(langlist['lang4'])\n            sts_thread = threading.Thread(target=stsloop)\n            sts_thread.start()\n        #else:\n        #    app.logger.error(\n        #        f\"\\n{langlist['lang5']}: {cfg.download_address}\\n\")\n        \n        print(langlist['lang7'])\n        try:\n            host = web_address.split(':')\n            threading.Thread(target=openweb, args=(web_address,)).start()\n            serve(app,host=host[0], port=int(host[1]))\n        finally:\n           print('exit')\n    except Exception as e:\n        print(\"error:\" + str(e))\n        app.logger.error(f\"[app]start error:{str(e)}\")\n        time.sleep(30)\n        sys.exit()\n"
        },
        {
          "name": "appdingzhi.py",
          "type": "blob",
          "size": 20.966796875,
          "content": "import datetime\nimport logging\nimport re\nimport threading\nimport time\nimport sys\nfrom flask import Flask, request, render_template, jsonify, send_file, send_from_directory\nimport os\nfrom gevent.pywsgi import WSGIServer, WSGIHandler\nimport glob\nimport hashlib\nfrom logging.handlers import RotatingFileHandler\n\nimport clone\nfrom clone import cfg\nfrom clone.cfg import ROOT_DIR, TTS_DIR, VOICE_MODEL_EXITS, TMP_DIR, VOICE_DIR, TEXT_MODEL_EXITS, langlist\nfrom clone.logic import ttsloop, stsloop, create_tts, openweb, merge_audio_segments, get_subtitle_from_srt, updatecache\nfrom clone import logic\nfrom gevent.pywsgi import LoggingLogAdapter\nimport shutil\nimport subprocess\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nweb_address = os.getenv('WEB_ADDRESS', '127.0.0.1:9988')\n\n\nclass CustomRequestHandler(WSGIHandler):\n    def log_request(self):\n        pass\n\n\n#updatecache()\n\n# é…ç½®æ—¥å¿—\n# ç¦ç”¨ Werkzeug é»˜è®¤çš„æ—¥å¿—å¤„ç†å™¨\nlog = logging.getLogger('werkzeug')\nlog.handlers[:] = []\nlog.setLevel(logging.WARNING)\n\napp = Flask(__name__, static_folder=os.path.join(ROOT_DIR, 'static'), static_url_path='/static',\n            template_folder=os.path.join(ROOT_DIR, 'templates'))\n\nroot_log = logging.getLogger()  # Flaskçš„æ ¹æ—¥å¿—è®°å½•å™¨\nroot_log.handlers = []\nroot_log.setLevel(logging.WARNING)\n\napp.logger.setLevel(logging.INFO)  # è®¾ç½®æ—¥å¿—çº§åˆ«ä¸º INFO\n# åˆ›å»º RotatingFileHandler å¯¹è±¡ï¼Œè®¾ç½®å†™å…¥çš„æ–‡ä»¶è·¯å¾„å’Œå¤§å°é™åˆ¶\nfile_handler = RotatingFileHandler(os.path.join(ROOT_DIR, 'app.log'), maxBytes=1024 * 1024, backupCount=5)\n# åˆ›å»ºæ—¥å¿—çš„æ ¼å¼\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n# è®¾ç½®æ–‡ä»¶å¤„ç†å™¨çš„çº§åˆ«å’Œæ ¼å¼\nfile_handler.setLevel(logging.INFO)\nfile_handler.setFormatter(formatter)\n# å°†æ–‡ä»¶å¤„ç†å™¨æ·»åŠ åˆ°æ—¥å¿—è®°å½•å™¨ä¸­\napp.logger.addHandler(file_handler)\n\n\n@app.route('/static/<path:filename>')\ndef static_files(filename):\n    return send_from_directory(app.config['STATIC_FOLDER'], filename)\n\n\n@app.route('/')\ndef index():\n    return render_template(\"index.html\",\n                           text_model=TEXT_MODEL_EXITS,\n                           voice_model=VOICE_MODEL_EXITS,\n                           version=clone.ver,\n                           language=cfg.LANG,\n                           root_dir=ROOT_DIR.replace('\\\\', '/'))\n\n@app.route('/txt')\ndef txt():\n    return render_template(\"txt.html\",\n                           text_model=True,#TEXT_MODEL_EXITS,\n                           version=clone.ver,\n                           language=cfg.LANG,\n                           root_dir=ROOT_DIR.replace('\\\\', '/'))\n\n\n\n# ä¸Šä¼ éŸ³é¢‘\n@app.route('/upload', methods=['POST'])\ndef upload():\n    try:\n        # è·å–ä¸Šä¼ çš„æ–‡ä»¶\n        audio_file = request.files['audio']\n        save_dir = request.form.get(\"save_dir\")\n        save_dir = VOICE_DIR if not save_dir else os.path.join(ROOT_DIR, f'static/{save_dir}')\n        app.logger.info(f\"[upload]{audio_file.filename=},{save_dir=}\")\n        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æ˜¯ WAV/mp3æ ¼å¼\n        noextname, ext = os.path.splitext(os.path.basename(audio_file.filename.lower()))\n        noextname = noextname.replace(' ', '')\n        if audio_file and ext in [\".wav\", \".mp3\", \".flac\"]:\n            # ä¿å­˜æ–‡ä»¶åˆ°æœåŠ¡å™¨æŒ‡å®šç›®å½•\n            name = f'{noextname}{ext}'\n            if os.path.exists(os.path.join(save_dir, f'{noextname}{ext}')):\n                name = f'{datetime.datetime.now().strftime(\"%m%d-%H%M%S\")}-{noextname}{ext}'\n            # mp3 or wav           \n            tmp_wav = os.path.join(TMP_DIR, \"tmp_\" + name)\n            audio_file.save(tmp_wav)\n            # save to wav\n            if ext != '.wav':\n                name = f\"{name[:-len(ext)]}.wav\"\n            savename = os.path.join(save_dir, name)\n            subprocess.run(['ffmpeg', '-hide_banner', '-y', '-i', tmp_wav, savename], check=True)\n            try:\n                os.unlink(tmp_wav)\n            except:\n                pass\n            # è¿”å›æˆåŠŸçš„å“åº”\n            return jsonify({'code': 0, 'msg': 'ok', \"data\": name})\n        else:\n            # è¿”å›é”™è¯¯çš„å“åº”\n            return jsonify({'code': 1, 'msg': 'not wav'})\n    except Exception as e:\n        app.logger.error(f'[upload]error: {e}')\n        return jsonify({'code': 2, 'msg': 'error'})\n\n\n# ä» voicelist ç›®å½•è·å–å¯ç”¨çš„ wav å£°éŸ³åˆ—è¡¨\n@app.route('/init')\ndef init():\n    wavs = glob.glob(f\"{VOICE_DIR}/*.wav\")\n    result = []\n    for it in wavs:\n        if os.path.getsize(it) > 0:\n            result.append(os.path.basename(it))\n    return jsonify(result)\n\n\n# åˆ¤æ–­çº¿ç¨‹æ˜¯å¦å¯åŠ¨\n@app.route('/isstart', methods=['GET', 'POST'])\ndef isstart():\n    total = cfg.tts_n + cfg.sts_n\n    return jsonify({\"code\": 0, \"msg\": total, \"tts\": cfg.langlist['lang15'] if cfg.tts_n < 1 else \"\",\n                    \"sts\": cfg.langlist['lang16'] if cfg.sts_n < 1 else \"\"})\n\n\n# å¤–éƒ¨æ¥å£\n@app.route('/apitts', methods=['GET', 'POST'])\ndef apitts():\n    '''\n    audio:åŸå§‹å£°éŸ³wav,ä½œä¸ºéŸ³è‰²å…‹éš†æº\n    voice:å·²æœ‰çš„å£°éŸ³åå­—ï¼Œå¦‚æœå­˜åœ¨ voiceåˆ™å…ˆä½¿ç”¨ï¼Œå¦åˆ™ä½¿ç”¨audio\n    text:æ–‡å­—ä¸€è¡Œ\n    languageï¼šè¯­è¨€ä»£ç \n    Returns:\n    '''\n    try:\n        langcodelist=[\"zh-cn\",\"en\",\"ja\",\"ko\",\"es\",\"de\",\"fr\",\"it\",\"tr\",\"ru\",\"pt\",\"pl\",\"nl\",\"ar\",\"hu\",\"cs\"]\n        text = request.form.get(\"text\").strip()\n        text = text.replace(\"\\n\", ' . ')\n        language = request.form.get(\"language\",\"\").lower()\n        if language.startswith(\"zh\"):\n            language=\"zh-cn\"\n        if language not in langcodelist:\n            return jsonify({\"code\":1,\"msg\":f\"dont support language {language}\"})\n\n        md5_hash = hashlib.md5()\n\n        audio_name = request.form.get('voice')\n        # å­˜åœ¨ä¼ æ¥çš„å£°éŸ³æ–‡ä»¶åå­—\n        if audio_name:\n            voicename = os.path.join(VOICE_DIR, audio_name)\n        else:  # è·å–ä¸Šä¼ çš„æ–‡ä»¶\n            audio_file = request.files['audio']\n            print(f'{audio_file.filename}')\n            # ä¿å­˜ä¸´æ—¶ä¸Šä¼ è¿‡æ¥çš„å£°éŸ³æ–‡ä»¶\n            audio_name = f'video_{audio_file.filename}.wav'\n            voicename = os.path.join(TMP_DIR, audio_name)\n            audio_file.save(voicename)\n        md5_hash.update(f\"{text}-{language}-{audio_name}\".encode('utf-8'))\n\n        app.logger.info(f\"[apitts]{voicename=}\")\n        if re.match(r'^[~`!@#$%^&*()_+=,./;\\':\\[\\]{}<>?\\\\|\"ï¼Œã€‚ï¼Ÿï¼›â€˜ï¼šâ€œâ€â€™ï½›ã€ã€‘ï½ï¼Â·ï¿¥ã€\\s\\n\\r -]*$', text):\n            return jsonify({\"code\": 1, \"msg\": \"lost text for translate\"})\n        if not text or not language:\n            return jsonify({\"code\": 1, \"msg\": \"text & language params lost\"})\n        app.logger.info(f\"[apitts]{text=},{language=}\")\n\n        # å­˜æ”¾ç»“æœ\n        # åˆæˆåçš„è¯­éŸ³æ–‡ä»¶, ä»¥wavæ ¼å¼å­˜æ”¾å’Œè¿”å›\n        filename = md5_hash.hexdigest() + \".wav\"\n        app.logger.info(f\"[apitts]{filename=}\")\n        # åˆæˆè¯­éŸ³\n        rs = create_tts(text=text, speed=1.0, voice=voicename, language=language, filename=filename)\n        # å·²æœ‰ç»“æœæˆ–é”™è¯¯ï¼Œç›´æ¥è¿”å›\n        if rs is not None:\n            result = rs\n        else:\n            # å¾ªç¯ç­‰å¾… æœ€å¤š7200s\n            time_tmp = 0\n            while filename not in cfg.global_tts_result:\n                time.sleep(3)\n                time_tmp += 3\n                if time_tmp % 30 == 0:\n                    app.logger.info(f\"[apitts][tts]{time_tmp=},{filename=}\")\n\n            # å½“å‰è¡Œå·²å®Œæˆåˆæˆ\n            if cfg.global_tts_result[filename] != 1:\n                msg = {\"code\": 1, \"msg\": cfg.global_tts_result[filename]}\n            else:\n                target_wav = os.path.normpath(os.path.join(TTS_DIR, filename))\n                msg = {\"code\": 0, \"filename\": target_wav, 'name': filename}\n            app.logger.info(f\"[apitts][tts] {filename=},{msg=}\")\n            cfg.global_tts_result.pop(filename)\n            result = msg\n            app.logger.info(f\"[apitts]{msg=}\")\n        if result['code'] == 0:\n            result['url'] = f'http://{web_address}/static/ttslist/{filename}'\n        return jsonify(result)\n    except Exception as e:\n        msg=f'{str(e)} {str(e.args)}'\n        app.logger.error(f\"[apitts]{msg}\")\n        return jsonify({'code': 2, 'msg': msg})\n\nchuliing={\"name\":\"\",\"line\":0,\"end\":False}\n\n# è·å–è¿›åº¦\n@app.route('/ttslistjindu',methods=['GET', 'POST'])\ndef ttslistjindu():\n    return jsonify(chuliing)\n\n# å…·ä½“èµ·ä¸€ä¸ªæ–°çº¿ç¨‹æ‰§è¡Œ\ndef detail_task(*pams):\n    global chuliing\n    chuliing={\"name\":\"\",\"line\":0,\"end\":False}\n    voice, src, dst, speed, language=pams\n  \n    # éå†æ‰€æœ‰txtæ–‡ä»¶\n    for t in os.listdir(src):\n        if not t.lower().endswith('.txt'):\n            continue\n        concat_txt=os.path.join(cfg.TTS_DIR, re.sub(r'[ \\s\\[\\]\\{\\}\\(\\)<>\\?\\, :]+','', t, re.I) + '.txt')\n        \n        app.logger.info(f'####å¼€å§‹å¤„ç†æ–‡ä»¶ï¼š{t}, æ¯è¡Œç»“æœä¿å­˜åœ¨:{concat_txt}')\n        with open(concat_txt,'w',encoding='utf-8') as f:\n            f.write(\"\")\n        #éœ€è¦ç­‰å¾…æ‰§è¡Œå®Œæ¯•çš„æ•°æ® [{}, {}]\n        waitlist=[]\n        #å·²æ‰§è¡Œå®Œæ¯•çš„ {1:{}, 2:{}}\n        result={}\n        with open(os.path.join(src,t),'r',encoding='utf-8') as f:\n            num=0\n            for line in f.readlines():\n                num+=1\n                line=line.strip()\n                if re.match(r'^[~`!@#$%^&*()_+=,./;\\':\\[\\]{}<>?\\\\|\"ï¼Œã€‚ï¼Ÿï¼›â€˜ï¼šâ€œâ€â€™ï½›ã€ã€‘ï½ï¼Â·ï¿¥ã€\\s\\n\\r -]*$', line):\n                    app.logger.info(f'\\tç¬¬{num}ä¸å­˜åœ¨æœ‰æ•ˆæ–‡å­—ï¼Œè·³è¿‡')\n                    continue                \n                md5_hash = hashlib.md5()\n                md5_hash.update(f\"{line}-{voice}-{language}-{speed}\".encode('utf-8'))\n                filename = md5_hash.hexdigest() + \".wav\"\n                app.logger.info(f'\\tå¼€å§‹åˆæˆç¬¬{num}è¡Œå£°éŸ³:{filename=}')\n                # åˆæˆè¯­éŸ³\n                rs = create_tts(text=line, speed=speed, voice=voice, language=language, filename=filename)\n                # å·²æœ‰ç»“æœæˆ–é”™è¯¯ï¼Œç›´æ¥è¿”å›\n                if rs is not None and rs['code']==1:\n                    app.logger.error(f'\\t{t}:æ–‡ä»¶å†…å®¹ç¬¬{num}è¡Œã€ {line} ã€‘å‡ºé”™äº†ï¼Œè·³è¿‡')\n                    continue\n                if rs is not None and rs['code']==0:\n                    #å·²å­˜åœ¨ç›´æ¥ä½¿ç”¨\n                    result[f'{num}']={\"filename\":filename, \"num\":num}\n                    chuliing['name']=t\n                    chuliing['line']=num\n                    app.logger.info(f'\\tç¬¬{num}è¡Œåˆæˆå®Œæ¯•:{filename=}')\n                    continue\n                waitlist.append({\"filename\":filename, \"num\":num, \"t\":t})\n        \n        #for it in waitlist:\n        time_tmp = 0\n        chuliing['name']=t\n        if len(waitlist)>0:\n            chuliing['line']=waitlist[0]['num']\n            while len(waitlist)>0:\n                it=waitlist.pop(0)\n                filename, num, t=it.values()\n                \n                #éœ€è¦ç­‰å¾…\n                if time_tmp>7200:\n                    continue\n                    \n                # å½“å‰è¡Œå·²å®Œæˆåˆæˆ\n                if filename in cfg.global_tts_result and cfg.global_tts_result[filename] != 1:\n                    #å‡ºé”™äº†\n                    app.logger.error(f'\\t{t}:æ–‡ä»¶å†…å®¹ç¬¬{num}è¡Œå‡ºé”™äº†,{cfg.global_tts_result[filename]}, è·³è¿‡')\n                    continue\n                if os.path.exists(os.path.join(cfg.TTS_DIR, filename)):\n                    chuliing['name']=t\n                    chuliing['line']=num\n                    app.logger.info(f'\\tç¬¬{num}è¡Œåˆæˆå®Œæ¯•:{filename}')\n                    #æˆåŠŸäº†\n                    result[f'{num}']={\"filename\":filename, \"num\":num}\n                    continue\n                #æœªå®Œæˆï¼Œæ’å…¥é‡æ–°å¼€\n                waitlist.append(it)\n                time_tmp+=1\n                time.sleep(1)\n        if len(result.keys())<1:\n            app.logger.error(f'\\tè¯¥æ–‡ä»¶åˆæˆå¤±è´¥ï¼Œæ²¡æœ‰ç”Ÿæˆä»»ä½•å£°éŸ³')\n            continue    \n        sorted_result = {k: result[k] for k in sorted(result, key=lambda x: int(x))}\n        for i, it in sorted_result.items():\n            theaudio = os.path.normpath(os.path.join(cfg.TTS_DIR, it['filename']))\n            with open(concat_txt, 'a', encoding='utf-8') as f:\n                f.write(f\"file '{theaudio}'\\n\")\n        \n        #å½“å‰txtæ‰§è¡Œå®Œæˆ åˆå¹¶éŸ³é¢‘\n        target_mp3=os.path.normpath((os.path.join(dst,f'{t}.mp3')))\n        p=subprocess.run(['ffmpeg',\"-hide_banner\", \"-ignore_unknown\", '-y', '-f', 'concat', '-safe', '0', '-i', concat_txt, target_mp3])\n        \n        if p.returncode!=0:\n            app.logger.error(f'\\tå¤„ç†æ–‡ä»¶:{t},å°†æ‰€æœ‰éŸ³é¢‘è¿æ¥ä¸€èµ·æ—¶å‡ºé”™')\n            continue\n        app.logger.info(f'\\tå·²ç”Ÿæˆå®Œæ•´éŸ³é¢‘:{target_mp3}')\n        if speed != 1.0 and speed > 0 and speed <= 2.0:\n            p= subprocess.run(['ffmpeg', '-hide_banner', '-ignore_unknown', '-y', '-i', target_mp3, '-af', f\"atempo={speed}\",f'{target_mp3}-speed{speed}.mp3'], encoding=\"utf-8\", capture_output=True)\n            if p.returncode != 0:\n                app.logger.error(f'\\tå¤„ç†æ–‡ä»¶{t}:å°†{target_mp3}éŸ³é¢‘æ”¹å˜é€Ÿåº¦{speed}å€æ—¶å¤±è´¥')\n                continue\n            os.unlink(target_mp3)\n            target_mp3=f'{target_mp3}-speed{speed}.mp3'\n        app.logger.info(f'\\tæ–‡ä»¶:{t} å¤„ç†å®Œæˆï¼Œmp3:{target_mp3}')\n    app.logger.info('æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæ¯•')\n    chuliing['end']=True    \n\n@app.route('/ttslist',methods=['GET', 'POST'])\ndef ttslist():\n    \n    voice = request.form.get(\"voice\")\n    src = request.form.get(\"src\")\n    dst = request.form.get(\"dst\")\n    speed = 1.0\n    try:\n        speed = float(request.form.get(\"speed\"))\n    except:\n        pass\n    language = request.form.get(\"language\")\n\n    #æ ¹æ®srcè·å–æ‰€æœ‰txt\n    src=os.path.normpath(src)\n    print(f'{src=},{dst=},{language=},{speed=},{voice=}')\n    if not src or not dst or not os.path.exists(src) or not os.path.exists(dst):\n        return jsonify({\"code\":1,\"msg\":\"å¿…é¡»æ­£ç¡®å¡«å†™txtæ‰€åœ¨ç›®å½•ä»¥åŠç›®æ ‡ç›®å½•çš„å®Œæ•´è·¯å¾„\"})\n\n    threading.Thread(target=detail_task, args=(voice, src, dst, speed, language)).start()    \n\n    return jsonify({\"code\":0,\"msg\":\"ok\"})\n\n\n\n\n\n\n\n# æ ¹æ®æ–‡æœ¬è¿”å›ttsç»“æœï¼Œè¿”å› name=æ–‡ä»¶åå­—ï¼Œfilename=æ–‡ä»¶ç»å¯¹è·¯å¾„\n# è¯·æ±‚ç«¯æ ¹æ®éœ€è¦è‡ªè¡Œé€‰æ‹©ä½¿ç”¨å“ªä¸ª\n# params\n# text:å¾…åˆæˆæ–‡å­—\n# voiceï¼šå£°éŸ³æ–‡ä»¶\n# language:è¯­è¨€ä»£ç \n@app.route('/tts', methods=['GET', 'POST'])\ndef tts():\n    # åŸå§‹å­—ç¬¦ä¸²\n    text = request.form.get(\"text\").strip()\n    voice = request.form.get(\"voice\")\n    speed = 1.0\n    try:\n        speed = float(request.form.get(\"speed\"))\n    except:\n        pass\n    language = request.form.get(\"language\")\n    app.logger.info(f\"[tts][tts]recev {text=}\\n{voice=},{language=}\\n\")\n\n    if re.match(r'^[~`!@#$%^&*()_+=,./;\\':\\[\\]{}<>?\\\\|\"ï¼Œã€‚ï¼Ÿï¼›â€˜ï¼šâ€œâ€â€™ï½›ã€ã€‘ï½ï¼Â·ï¿¥ã€\\s\\n\\r -]*$', text):\n        return jsonify({\"code\": 1, \"msg\": \"no text\"})\n    if not text or not voice or not language:\n        return jsonify({\"code\": 1, \"msg\": \"text/voice/language params lost\"})\n\n    # åˆ¤æ–­æ˜¯å¦æ˜¯srt\n    text_list = get_subtitle_from_srt(text)\n    app.logger.info(f\"[tts][tts]{text_list=}\")\n    is_srt = True\n    # ä¸æ˜¯srtæ ¼å¼,åˆ™æŒ‰è¡Œåˆ†å‰²\n    if text_list is None:\n        is_srt = False\n        text_list = []\n        for it in text.split(\"\\n\"):\n            text_list.append({\"text\": it.strip()})\n        app.logger.info(f\"[tts][tts] its not srt\")\n\n    num = 0\n    while num < len(text_list):\n        t = text_list[num]\n        # æ¢è¡Œç¬¦æ”¹æˆ .\n        t['text'] = t['text'].replace(\"\\n\", ' . ')\n        md5_hash = hashlib.md5()\n        md5_hash.update(f\"{t['text']}-{voice}-{language}-{speed}\".encode('utf-8'))\n        filename = md5_hash.hexdigest() + \".wav\"\n        app.logger.info(f\"[tts][tts]{filename=}\")\n        # åˆæˆè¯­éŸ³\n        rs = create_tts(text=t['text'], speed=speed, voice=voice, language=language, filename=filename)\n        # å·²æœ‰ç»“æœæˆ–é”™è¯¯ï¼Œç›´æ¥è¿”å›\n        if rs is not None:\n            text_list[num]['result'] = rs\n            num += 1\n            continue\n        # å¾ªç¯ç­‰å¾… æœ€å¤š7200s\n        time_tmp = 0\n        while filename not in cfg.global_tts_result:\n            time.sleep(3)\n            time_tmp += 3\n            if time_tmp % 30 == 0:\n                app.logger.info(f\"[tts][tts]{time_tmp=},{filename=}\")\n\n        # å½“å‰è¡Œå·²å®Œæˆåˆæˆ\n        if cfg.global_tts_result[filename] != 1:\n            msg = {\"code\": 1, \"msg\": cfg.global_tts_result[filename]}\n        else:\n            target_wav = os.path.normpath(os.path.join(TTS_DIR, filename))\n            if speed != 1.0 and speed > 0 and speed <= 2.0:\n                # ç”Ÿæˆçš„åŠ é€ŸéŸ³é¢‘\n                speed_tmp = os.path.join(TMP_DIR, f'speed_{time.time()}.wav')\n                p = subprocess.run(\n                    ['ffmpeg', '-hide_banner', '-ignore_unknown', '-y', '-i', target_wav, '-af', f\"atempo={speed}\",\n                     os.path.normpath(speed_tmp)], encoding=\"utf-8\", capture_output=True)\n                if p.returncode != 0:\n                    return jsonify({\"code\": 1, \"msg\": str(p.stderr)})\n                shutil.copy2(speed_tmp, target_wav)\n            msg = {\"code\": 0, \"filename\": target_wav, 'name': filename}\n        app.logger.info(f\"[tts][tts] {filename=},{msg=}\")\n        cfg.global_tts_result.pop(filename)\n        text_list[num]['result'] = msg\n        app.logger.info(f\"[tts][tts]{num=}\")\n        num += 1\n\n    filename, errors = merge_audio_segments(text_list, is_srt=is_srt)\n    app.logger.info(f\"[tts][tts]is srtï¼Œ{filename=},{errors=}\")\n    if filename and os.path.exists(filename) and os.path.getsize(filename) > 0:\n        res = {\"code\": 0, \"filename\": filename, \"name\": os.path.basename(filename), \"msg\": errors}\n    else:\n        res = {\"code\": 1, \"msg\": f\"error:{filename=},{errors=}\"}\n    app.logger.info(f\"[tts][tts]end result:{res=}\")\n    return jsonify(res)\n\n\n# s to s wav->wav\n# params\n# voice: å£°éŸ³æ–‡ä»¶\n# filename: ä¸Šä¼ çš„åŸå§‹å£°éŸ³\n\n@app.route('/sts', methods=['GET', 'POST'])\ndef sts():\n    try:\n        # ä¿å­˜æ–‡ä»¶åˆ°æœåŠ¡å™¨æŒ‡å®šç›®å½•\n        # ç›®æ ‡\n        voice = request.form.get(\"voice\")\n        filename = request.form.get(\"name\")\n        app.logger.info(f\"[sts][sts]sts {voice=},{filename=}\\n\")\n\n        if not voice:\n            return jsonify({\"code\": 1, \"msg\": \"voice params lost\"})\n\n        obj = {\"filename\": filename, \"voice\": voice}\n        # å‹å…¥é˜Ÿåˆ—ï¼Œå‡†å¤‡è½¬æ¢è¯­éŸ³\n        app.logger.info(f\"[sts][sts]push sts\")\n        cfg.q_sts.put(obj)\n        # å·²æœ‰ç»“æœæˆ–é”™è¯¯ï¼Œç›´æ¥è¿”å›\n        # å¾ªç¯ç­‰å¾… æœ€å¤š7200s\n        time_tmp = 0\n        while filename not in cfg.global_sts_result:\n            time.sleep(3)\n            time_tmp += 3\n            if time_tmp % 30 == 0:\n                app.logger.info(f\"{time_tmp=}ï¼Œ{filename=}\")\n\n        # å½“å‰è¡Œå·²å®Œæˆåˆæˆ\n        if cfg.global_sts_result[filename] != 1:\n            msg = {\"code\": 1, \"msg\": cfg.global_sts_result[filename]}\n            app.logger.error(f\"[sts][sts]errorï¼Œ{msg=}\")\n        else:\n            msg = {\"code\": 0, \"filename\": os.path.join(TTS_DIR, filename), 'name': filename}\n            app.logger.info(f\"[sts][sts]ok,{msg=}\")\n        cfg.global_sts_result.pop(filename)\n        return jsonify(msg)\n    except Exception as e:\n        app.logger.error(f\"[sts][sts]error:{str(e)}\")\n        return jsonify({'code': 2, 'msg': f'voice->voice:{str(e)}'})\n\n\n@app.route('/checkupdate', methods=['GET', 'POST'])\ndef checkupdate():\n    return jsonify({'code': 0, \"msg\": cfg.updatetips})\n\n\nif __name__ == '__main__':\n\n    tts_thread = None\n    sts_thread = None\n    try:\n        if 'app.py' == sys.argv[0] and 'app.py' == os.path.basename(__file__):\n            print(langlist[\"lang1\"])\n\n        # threading.Thread(target=logic.checkupdate).start()\n\n        if TEXT_MODEL_EXITS:\n            print(langlist['lang2'])\n            tts_thread = threading.Thread(target=ttsloop)\n            tts_thread.start()\n        else:\n            app.logger.error(f\"\\n{langlist['lang3']}: {cfg.download_address}\\n\")\n        \n        if VOICE_MODEL_EXITS:\n            print(langlist['lang4'])\n            sts_thread = threading.Thread(target=stsloop)\n            sts_thread.start()\n        else:\n            app.logger.info(\n                f\"\\n{langlist['lang5']}: {cfg.download_address}\\n\")\n        \n        if not VOICE_MODEL_EXITS and not TEXT_MODEL_EXITS:\n            print(f\"\\n{langlist['lang6']}: {cfg.download_address}\\n\")\n            input(\"Press Enter close\")\n            sys.exit()\n\n        print(\"===\")\n        http_server = None\n        try:\n            host = web_address.split(':')\n            print(f'{host=}')\n            http_server = WSGIServer((host[0], int(host[1])), app, handler_class=CustomRequestHandler)\n            print(f'@@@@@@@@@@@')\n            threading.Thread(target=openweb, args=(web_address,)).start()\n            http_server.serve_forever()\n        finally:\n            if http_server:\n                http_server.stop()\n            # è®¾ç½®äº‹ä»¶ï¼Œé€šçŸ¥çº¿ç¨‹é€€å‡º\n            cfg.exit_event.set()\n            # ç­‰å¾…åå°çº¿ç¨‹ç»“æŸ\n            if tts_thread:\n                tts_thread.join()\n            if sts_thread:\n                sts_thread.join()\n    except Exception as e:\n        print(\"error:\" + str(e))\n        app.logger.error(f\"[app]start error:{str(e)}\")\n        sys.exit()\n"
        },
        {
          "name": "change.md",
          "type": "blob",
          "size": 2.810546875,
          "content": "ffmpeg -y -i cn.mp4 -i cn.wav -map '0:v' -map '1:a' -c:v  libx264 -c:a aac cnout.mp4\nffmpeg -y -i en.mp4 -i en.wav -map 0:v -map 1:a -c:v  libx264 -c:a aac enout.mp4\n\n\n0.\n\\venv\\Lib\\site-packages\\TTS\\utils\\manage.py ,å¤§çº¦ 389 è¡Œé™„è¿‘ï¼Œdef download_model æ–¹æ³•ä¸­ï¼Œæ³¨é‡Šæ‰å¦‚ä¸‹ä»£ç \n\n\n1. tts/utils/manage.py 532 line _download_zip_file\n\n\tdef _download_zip_file:\n\t\tproxies=None\n        if os.environ.get('http_proxy') or os.environ.get('HTTP_PROXY'):\n            proxies = {\n                \"http\": os.environ.get('http_proxy') or os.environ.get('HTTP_PROXY'),\n                \"https\": os.environ.get('http_proxy') or os.environ.get('HTTP_PROXY')\n            }\n        r = requests.get(file_url, stream=True,proxies=proxies)\n\n\t@staticmethod\n    def _download_tar_file(file_url, output_folder, progress_bar):\n        \"\"\"Download the github releases\"\"\"\n        # download the file\n        proxies=None\n        if os.environ.get('http_proxy') or os.environ.get('HTTP_PROXY'):\n            proxies = {\n                \"http\": os.environ.get('http_proxy') or os.environ.get('HTTP_PROXY'),\n                \"https\": os.environ.get('http_proxy') or os.environ.get('HTTP_PROXY')\n            }\n        r = requests.get(file_url, stream=True,proxies=proxies)\n\n\n    def _download_model_files(file_urls, output_folder, progress_bar):\n        \"\"\"Download the github releases\"\"\"\n        proxies=None\n        if os.environ.get('http_proxy') or os.environ.get('HTTP_PROXY'):\n            proxies = {\n                \"http\": os.environ.get('http_proxy') or os.environ.get('HTTP_PROXY'),\n                \"https\": os.environ.get('http_proxy') or os.environ.get('HTTP_PROXY')\n            }\n\n2. tts/vc/modules/freevc/wavlm\n\n\tdef get_wavlm():\n\t\tprint(f\" > Downloading WavLM model to {output_path} ...\")\n        if os.environ.get('http_proxy') or os.environ.get('HTTP_PROXY'):\n            # åˆ›å»ºProxyHandlerå¯¹è±¡\n            proxy_support = urllib.request.ProxyHandler({\"http\": os.environ.get('http_proxy') or os.environ.get('HTTP_PROXY'),\"https\":os.environ.get('http_proxy') or os.environ.get('HTTP_PROXY')})\n\n            # åˆ›å»ºOpener\n            opener = urllib.request.build_opener(proxy_support)\n\n            # å®‰è£…Opener\n            urllib.request.install_opener(opener)\n\n        urllib.request.urlretrieve(model_uri, output_path)\n\n\n3. E:\\python\\tts\\venv\\Lib\\site-packages\\fsspec\\implementations\\http.py\n\n    async def _get_file(\n        self, rpath, lpath, chunk_size=5 * 2**20, callback=_DEFAULT_CALLBACK, **kwargs\n    ):\n        print(f'%%%%%%%%%%%%%%%%%%%{rpath=},{lpath=}')\n        import os\n        if os.path.exists(lpath) and os.path.getsize(lpath)>16000:\n            print('å­˜åœ¨')\n            return True\n\n\n\t\tproxy=os.environ.get('http_proxy') or os.environ.get('HTTP_PROXY')\n        async with session.get(self.encode_url(rpath), proxy=proxy if proxy else None,**kw) as r:"
        },
        {
          "name": "clone",
          "type": "tree",
          "content": null
        },
        {
          "name": "code_dev.py",
          "type": "blob",
          "size": 1.65234375,
          "content": "import torch\nimport os\nrootdir=os.getcwd()\nos.environ['TTS_HOME']=rootdir\n\nfrom TTS.api import TTS\nfrom dotenv import load_dotenv\nload_dotenv()\n\nprint(\"æºç éƒ¨ç½²éœ€è¦å…ˆè¿è¡Œè¯¥æ–‡ä»¶ï¼Œä»¥ä¾¿åŒæ„coqou-aiåè®®ï¼Œå½“å¼¹å‡ºåè®®æ—¶ï¼Œè¯·è¾“å…¥ y \\nåŒæ—¶éœ€è¦è¿æ¥å¢™å¤–ä¸‹è½½æˆ–æ›´æ–°æ¨¡å‹ï¼Œè¯·åœ¨ .env ä¸­ HTTP_PROXY=è®¾ç½®ä»£ç†åœ°å€\")\n\ndef updatecache():\n    # ç¦æ­¢æ›´æ–°ï¼Œé¿å…æ— ä»£ç†æ—¶æŠ¥é”™\n    file=os.path.join(rootdir,'tts_cache/cache')\n    if file:\n        import json,time\n        j=json.load(open(file,'r',encoding='utf-8'))\n        for i,it in enumerate(j):\n            if \"time\" in it and \"fn\" in it:\n                cache_file=os.path.join(rootdir,f'tts_cache/{it[\"fn\"]}')\n                if os.path.exists(cache_file) and os.path.getsize(cache_file)>17000000:\n                    it['time']=time.time()\n                    j[i]=it\n        json.dump(j,open(file,'w',encoding='utf-8'))\n\nupdatecache()\n\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n\n\n#ttsv2 = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n\ntts = TTS(model_name='voice_conversion_models/multilingual/vctk/freevc24').to(device)\n\n# test\n#tts.tts_to_file(text='æˆ‘æ˜¯ä¸­å›½äººï¼Œä½ å‘¢æˆ‘çš„å®è´ã€‚ä»Šå¤©å¤©æ°”çœ‹èµ·æ¥å¾ˆä¸é”™å•Š', speaker_wav='./cn1.wav',language='zh', file_path='hafalse2.wav', speed=2.0,split_sentences=False)\n\n#tts.tts_to_file(text='æˆ‘æ˜¯ä¸­å›½äººï¼Œä½ å‘¢æˆ‘çš„å®è´ã€‚ä»Šå¤©å¤©æ°”çœ‹èµ·æ¥å¾ˆä¸é”™å•Š', speaker_wav='./cn1.wav',language='zh', file_path='hafalse0.2.wav', speed=0.2,split_sentences=False)\n\n#target_wav is voice file \n# tts.voice_conversion_to_file(source_wav=\"./cn1.wav\", target_wav=\"./sx1.wav\", file_path=\"./out.wav\")\n\n\n\n"
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "environment.yml",
          "type": "blob",
          "size": 0.2294921875,
          "content": "name: clone-voice\r\nchannels:\r\n  - conda-forge\r\n  - pytorch\r\n  - nvidia\r\ndependencies:\r\n  - python=3.10\r\n\r\n  - pytorch==2.5.1\r\n  - pytorch-cuda==12.4\r\n\r\n  - ffmpeg==7.1.0\r\n\r\n  - pip:\r\n    - huggingface-hub\r\n    - -r ./requirements.txt\r\n"
        },
        {
          "name": "images",
          "type": "tree",
          "content": null
        },
        {
          "name": "models",
          "type": "tree",
          "content": null
        },
        {
          "name": "params.json",
          "type": "blob",
          "size": 0.0986328125,
          "content": "{\n\"port\":5003,\n\"out_path\":\"\",\n\"num_epochs\":4,\n\"batch_size\":2,\n\"grad_acumm\":1,\n\"max_audio_length\":10\n}"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 3.310546875,
          "content": "absl-py==2.0.0\naiofiles==23.2.1\naiohttp==3.9.1\naiosignal==1.3.1\naltair==5.2.0\naltgraph==0.17.4\nannotated-types==0.6.0\nanyascii==0.3.2\nanyio==4.3.0\nasgiref==3.7.2\nasync-timeout==4.0.3\nattrs==23.1.0\naudioread==3.0.1\nav==11.0.0\nBabel==2.14.0\nbangla==0.0.2\nblinker==1.7.0\nblis==0.7.11\nbnnumerizer==0.0.2\nbnunicodenormalizer==0.1.6\ncachetools==5.3.2\ncatalogue==2.0.10\ncertifi==2023.11.17\ncffi==1.16.0\ncharset-normalizer==3.3.2\nclick==8.1.7\ncloudpathlib==0.16.0\ncolorama==0.4.6\ncoloredlogs==15.0.1\nconfection==0.1.4\ncontourpy==1.2.0\ncoqpit==0.0.17\nctranslate2==4.0.0\ncutlet==0.3.0\ncycler==0.12.1\ncymem==2.0.8\nCython==3.0.7\ndateparser==1.1.8\ndecorator==5.1.1\ndocopt==0.6.2\neinops==0.7.0\nencodec==0.1.1\nexceptiongroup==1.2.0\nfastapi==0.110.0\nfaster-whisper==1.0.0\nffmpy==0.3.2\nfilelock==3.13.1\nFlask==3.0.0\nflatbuffers==23.5.26\nfonttools==4.47.0\nfrozenlist==1.4.1\nfsspec==2023.12.2\nfugashi==1.3.0\ng2pkk==0.1.2\ngevent==23.9.1\ngoogle-auth==2.25.2\ngoogle-auth-oauthlib==1.2.0\ngradio==4.19.2\ngradio_client==0.10.1\ngreenlet==3.0.3\ngrpcio==1.60.0\ngruut==2.2.3\ngruut-ipa==0.13.0\ngruut-lang-de==2.0.0\ngruut-lang-en==2.0.0\ngruut-lang-es==2.0.0\ngruut-lang-fr==2.0.2\nh11==0.14.0\nhangul-romanize==0.1.0\nhttpcore==1.0.4\nhttpx==0.27.0\nhuggingface-hub==0.20.1\nhumanfriendly==10.0\nidna==3.6\nimportlib_resources==6.1.2\ninflect==7.0.0\nitsdangerous==2.1.2\njaconv==0.3.4\njamo==0.4.1\njieba==0.42.1\nJinja2==3.1.2\njoblib==1.3.2\njsonlines==1.2.0\njsonschema==4.21.1\njsonschema-specifications==2023.12.1\nkiwisolver==1.4.5\nlangcodes==3.3.0\nlazy_loader==0.3\nlibrosa==0.10.0\nllvmlite==0.41.1\nMarkdown==3.5.1\nmarkdown-it-py==3.0.0\nMarkupSafe==2.1.3\nmatplotlib==3.8.2\nmdurl==0.1.2\nmojimoji==0.0.12\nmpmath==1.3.0\nmsgpack==1.0.7\nmultidict==6.0.4\nmurmurhash==1.0.10\nnetworkx==2.8.8\nnltk==3.8.1\nnum2words==0.5.13\nnumba==0.58.1\nnumpy==1.22.0\noauthlib==3.2.2\nonnxruntime==1.17.1\norjson==3.9.15\npackaging==23.2\npandas==1.5.3\npefile==2023.2.7\nPillow==10.1.0\nplatformdirs==4.1.0\npooch==1.8.0\npreshed==3.0.9\nprotobuf==4.23.4\npsutil==5.9.7\npyasn1==0.5.1\npyasn1-modules==0.3.0\npycparser==2.21\npydantic==2.5.2\npydantic_core==2.14.5\npydub==0.25.1\nPygments==2.17.2\npyinstaller==6.3.0\npyinstaller-hooks-contrib==2023.11\npynndescent==0.5.11\npyparsing==3.1.1\npypinyin==0.50.0\npyreadline3==3.4.1\npysbd==0.3.4\npython-crfsuite==0.9.10\npython-dateutil==2.8.2\npython-dotenv==1.0.0\npython-multipart==0.0.9\npytz==2023.3.post1\npywin32-ctypes==0.2.2\nPyYAML==6.0.1\nreferencing==0.33.0\nregex==2023.10.3\nrequests==2.31.0\nrequests-oauthlib==1.3.1\nrich==13.7.0\nrpds-py==0.18.0\nrsa==4.9\nruff==0.2.2\nsafetensors==0.4.1\nscikit-learn==1.3.2\nscipy==1.11.4\nsemantic-version==2.10.0\nshellingham==1.5.4\nsix==1.16.0\nsmart-open==6.4.0\nsniffio==1.3.1\nsoundfile==0.12.1\nsoxr==0.3.7\nspacy==3.7.2\nspacy-legacy==3.0.12\nspacy-loggers==1.0.5\nsrsly==2.4.8\nstarlette==0.36.3\nSudachiDict-core==20230927\nSudachiPy==0.6.8\nsympy==1.12\ntensorboard==2.15.1\ntensorboard-data-server==0.7.2\nthinc==8.2.2\nthreadpoolctl==3.2.0\ntokenizers==0.15.0\ntomlkit==0.12.0\ntoolz==0.12.1\ntqdm==4.66.1\ntrainer==0.0.36\ntransformers==4.36.2\nTTS @ git+https://github.com/coqui-ai/TTS.git@1936330adaad84812b0fafd2aa17cb7bba6edea9\ntyper==0.9.0\ntyping_extensions==4.9.0\ntzdata==2023.3\ntzlocal==5.2\numap-learn==0.5.5\nUnidecode==1.3.7\nunidic-lite==1.0.8\nurllib3==2.1.0\nuvicorn==0.27.1\nwaitress==3.0.0\nwasabi==1.1.2\nweasel==0.3.4\nwebsockets==11.0.3\nWerkzeug==3.0.1\nyarl==1.9.4\nzope.event==5.0\nzope.interface==6.1\n"
        },
        {
          "name": "runapp.bat",
          "type": "blob",
          "size": 0.056640625,
          "content": "@echo off\n\n%cd%\\venv\\scripts\\python.exe %cd%\\app.py\n\npause"
        },
        {
          "name": "runtrain.bat",
          "type": "blob",
          "size": 0.04296875,
          "content": "@echo off\n.\\venv\\scripts\\python.exe train.py"
        },
        {
          "name": "static",
          "type": "tree",
          "content": null
        },
        {
          "name": "templates",
          "type": "tree",
          "content": null
        },
        {
          "name": "test.py",
          "type": "blob",
          "size": 0.2265625,
          "content": "\nimport os\nimport re\n\n\ndef get_models(path):\n    objs={}\n    for it in os.listdir(path):\n        if re.match(r'^[0-9a-zA-Z_-]+$',it):\n            objs[it]=None\n    return objs\n\nprint(get_models(r'E:\\python\\tts\\tts\\mymodels\\xiaoyi'))"
        },
        {
          "name": "testapi.py",
          "type": "blob",
          "size": 0.2998046875,
          "content": "import requests\nimport os\n#\n# res=requests.post(\"http://127.0.0.1:9988/apitts\",data={\"text\":\"hello,everyone,you are my friend\",\"language\":\"en\"},files={\"audio\":open(\"./10.wav\",\"rb\")})\n# res=requests.get(\"http://127.0.0.1:9988/init\")\n#\n# print(res.text)\n\nfor t in os.listdir(\"f:/python/pyvideo\"):\n    print(t)"
        },
        {
          "name": "train.py",
          "type": "blob",
          "size": 16.1240234375,
          "content": "import argparse\nimport os\nimport sys\nimport tempfile\nimport threading\nimport webbrowser\nimport time\n\nimport gradio as gr\nimport librosa.display\nimport numpy as np\n\nimport os\nimport torch\nimport torchaudio\nimport traceback\nfrom utils.formatter import format_audio_list\nfrom utils.cfg import TTSMODEL_DIR\nfrom TTS.demos.xtts_ft_demo.utils.gpt_train import train_gpt\n\n\nfrom TTS.tts.configs.xtts_config import XttsConfig\nfrom TTS.tts.models.xtts import Xtts\nimport datetime\nimport shutil\nimport json\nimport random\nfrom dotenv import load_dotenv\nload_dotenv()\n\nproxy=os.getenv('HTTP_PROXY') or os.getenv('http_proxy')\nif proxy:\n    os.environ['HTTP_PROXY']=proxy\n    os.environ['HTTPS_PROXY']=proxy\n\nprint(f'{proxy=}')\n\n\n#datasetç›®å½•å\ndataset_name=f'dataset{int(random.random()*1000000)}'\n\ndef clear_gpu_cache():\n    # clear the GPU cache\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n\nXTTS_MODEL = None\ndef load_model(xtts_checkpoint, xtts_config, xtts_vocab):\n    global XTTS_MODEL\n    clear_gpu_cache()\n    if not xtts_checkpoint or not xtts_config or not xtts_vocab:\n        gr.Error('è®­ç»ƒå°šæœªç»“æŸï¼Œè¯·ç¨ç­‰')\n        return \"è®­ç»ƒå°šæœªç»“æŸï¼Œè¯·ç¨ç­‰\"\n    config = XttsConfig()\n    config.load_json(xtts_config)\n    XTTS_MODEL = Xtts.init_from_config(config)\n    print(\"Loading XTTS model! \")\n    XTTS_MODEL.load_checkpoint(config, checkpoint_path=xtts_checkpoint, vocab_path=xtts_vocab, use_deepspeed=False)\n    if torch.cuda.is_available():\n        XTTS_MODEL.cuda()\n\n    print(\"Model Loaded!\")\n    return \"æ¨¡å‹å·²åŠ è½½!\"\n\ndef run_tts(lang, tts_text, speaker_audio_file):\n    if XTTS_MODEL is None:\n        gr.Error(\"æ¨¡å‹è¿˜æœªè®­ç»ƒå®Œæ¯•æˆ–å°šæœªåŠ è½½ï¼Œè¯·ç¨ç­‰\")\n        return \"æ¨¡å‹è¿˜æœªè®­ç»ƒå®Œæ¯•æˆ–å°šæœªåŠ è½½ï¼Œè¯·ç¨ç­‰ !!\", None, None\n    if speaker_audio_file and not speaker_audio_file.endswith(\".wav\"):\n        speaker_audio_file+='.wav'\n    if not speaker_audio_file or  not os.path.exists(speaker_audio_file):\n        gr.Error('å¿…é¡»å¡«å†™å‚è€ƒéŸ³é¢‘')\n        return 'å¿…é¡»å¡«å†™å‚è€ƒéŸ³é¢‘',None,None\n    gpt_cond_latent, speaker_embedding = XTTS_MODEL.get_conditioning_latents(audio_path=speaker_audio_file, gpt_cond_len=XTTS_MODEL.config.gpt_cond_len, max_ref_length=XTTS_MODEL.config.max_ref_len, sound_norm_refs=XTTS_MODEL.config.sound_norm_refs)\n    out = XTTS_MODEL.inference(\n        text=tts_text,\n        language=lang,\n        gpt_cond_latent=gpt_cond_latent,\n        speaker_embedding=speaker_embedding,\n        temperature=XTTS_MODEL.config.temperature, # Add custom parameters here\n        length_penalty=XTTS_MODEL.config.length_penalty,\n        repetition_penalty=XTTS_MODEL.config.repetition_penalty,\n        top_k=XTTS_MODEL.config.top_k,\n        top_p=XTTS_MODEL.config.top_p,\n    )\n\n    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as fp:\n        out[\"wav\"] = torch.tensor(out[\"wav\"]).unsqueeze(0)\n        out_path = fp.name\n        torchaudio.save(out_path, out[\"wav\"], 24000)\n\n    return \"å·²åˆ›å»ºå¥½äº†å£°éŸ³ !\", out_path, speaker_audio_file\n\n\n\n\n# define a logger to redirect \nclass Logger:\n    def __init__(self, filename=\"log.out\"):\n        self.log_file = filename\n        self.terminal = sys.stdout\n        self.log = open(self.log_file, \"w\")\n\n    def write(self, message):\n        self.terminal.write(message)\n        self.log.write(message)\n\n    def flush(self):\n        self.terminal.flush()\n        self.log.flush()\n\n    def isatty(self):\n        return False\n\n# redirect stdout and stderr to a file\nsys.stdout = Logger()\nsys.stderr = sys.stdout\n\n\n# logging.basicConfig(stream=sys.stdout, level=logging.INFO)\nimport logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n    handlers=[\n        logging.StreamHandler(sys.stdout)\n    ]\n)\n\ndef read_logs():\n    sys.stdout.flush()\n    with open(sys.stdout.log_file, \"r\") as f:\n        return f.read()\n\ndef openweb(port):\n    time.sleep(10)\n    webbrowser.open(f\"http://127.0.0.1:{port}\")\n\nif __name__ == \"__main__\":\n    date=datetime.datetime.now()\n    param_file=os.path.join(os.getcwd(),'params.json')\n    if not os.path.exists(param_file):\n        print('ä¸å­˜åœ¨é…éŸ³æ–‡ä»¶ params.json')\n        sys.exit()\n    args=json.load(open(param_file,'r',encoding='utf-8'))\n    args['out_path']=TTSMODEL_DIR\n\n    with gr.Blocks(css=\"ul.options[role='listbox']{background:#ffffff}\",title=\"clone-voice trainer\") as demo:\n        if not proxy:\n            gr.Markdown(\"\"\"**æ²¡æœ‰é…ç½®ä»£ç†ï¼Œè®­ç»ƒä¸­å¯èƒ½å‡ºé”™ï¼Œå»ºè®®åœ¨.envæ–‡ä»¶ä¸­ `HTTP_PROXY=`åå¡«å†™ä»£ç†åœ°å€**\"\"\")\n        with gr.Tab(\"è®­ç»ƒå¹³å°\"):\n            with gr.Row() as r1:\n                model_name= gr.Textbox(\n                        label=\"è®­ç»ƒåæ¨¡å‹åç§°(é™è‹±æ–‡/æ•°å­—/ä¸‹åˆ’çº¿ï¼Œç¦æ­¢ç©ºæ ¼æˆ–ç‰¹æ®Šç¬¦å·):\",\n                        value=f\"model{date.day}{date.hour}{date.minute}\",\n                )\n                lang = gr.Dropdown(\n                    label=\"éŸ³é¢‘å‘å£°è¯­è¨€\",\n                    value=\"zh\",\n                    choices=[\n                        \"zh\",\n                        \"en\",\n                        \"es\",\n                        \"fr\",\n                        \"de\",\n                        \"it\",\n                        \"pt\",\n                        \"pl\",\n                        \"tr\",\n                        \"ru\",\n                        \"nl\",\n                        \"cs\",\n                        \"ar\",\n                        \"hu\",\n                        \"ko\",\n                        \"ja\"\n                    ],\n                )\n            with gr.Row() as r1:\n                upload_file = gr.File(\n                    file_count=\"multiple\",\n                    label=\"é€‰æ‹©è®­ç»ƒç´ æéŸ³é¢‘æ–‡ä»¶(å¯å¤šä¸ª)ï¼Œä»…å¯åŒ…å«åŒä¸€ä¸ªäººå£°ï¼Œå¹¶ä¸”æ— èƒŒæ™¯å™ªå£°(wav, mp3, and flac)\",\n                )\n                logs = gr.Textbox(\n                    label=\"æ—¥å¿—:\",\n                    interactive=False,\n                )\n                demo.load(read_logs, None, logs, every=1)\n\n            prompt_compute_btn = gr.Button(value=\"ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ éŸ³é¢‘æ–‡ä»¶åç‚¹å‡»å¼€å§‹æ•´ç†æ•°æ®\")\n            with gr.Row() as r1:\n                train_data = gr.Textbox(\n                    label=\"å¾…è®­ç»ƒæ•°æ®é›†/å¯ä¿®æ”¹è¯†åˆ«å‡ºçš„æ–‡å­—ä»¥ä¾¿æ•ˆæœæ›´å¥½:\",\n                    interactive=True,\n                    lines=20,\n                    placeholder=\"ç¬¬ä¸€æ­¥ç»“æŸåï¼Œä¼šè‡ªåŠ¨åœ¨æ­¤æ˜¾ç¤ºæ•´ç†å¥½çš„æ–‡å­—ï¼Œå¯ä¿®æ”¹é”™åˆ«å­—ï¼Œä»¥ä¾¿å–å¾—æ›´å¥½æ•ˆæœ\"\n                )\n                eval_data = gr.Textbox(\n                    label=\"éªŒè¯æ•°æ®é›†/å¯ä¿®æ”¹è¯†åˆ«å‡ºçš„æ–‡å­—ä»¥ä¾¿æ•ˆæœæ¦‚å¿µè‚¡æˆ–:\",\n                    interactive=True,\n                    lines=20,\n                    placeholder=\"ç¬¬ä¸€æ­¥ç»“æŸåï¼Œä¼šè‡ªåŠ¨åœ¨æ­¤æ˜¾ç¤ºæ•´ç†å¥½çš„æ–‡å­—ï¼Œå¯ä¿®æ”¹é”™åˆ«å­—ï¼Œä»¥ä¾¿å–å¾—æ›´å¥½æ•ˆæœ\"\n                )\n            with gr.Row() as r:\n                train_file=gr.Textbox(\n                    label=\"å¾…è®­ç»ƒæ•°æ®é›†csvæ–‡ä»¶:\",\n                    interactive=False,\n                    visible=False\n                    \n                )\n                eval_file=gr.Textbox(\n                    label=\"éªŒè¯æ•°æ®é›†csvæ–‡ä»¶:\",\n                    interactive=False,\n                    visible=False\n                )\n            \n            start_train_btn = gr.Button(value=\"ç¬¬äºŒæ­¥ï¼šä¿®æ”¹é”™åˆ«å­—å(æˆ–ä¸ä¿®æ”¹)ï¼Œç‚¹å‡»å¯åŠ¨è®­ç»ƒ\")\n            \n            with gr.Row():\n                with gr.Column() as col1:\n                    xtts_checkpoint = gr.Textbox(\n                        label=\"è®­ç»ƒåæ¨¡å‹ä¿å­˜è·¯å¾„:\",\n                        value=\"\",\n                        interactive=False,\n                        visible=False\n                    )\n                    xtts_config = gr.Textbox(\n                        label=\"è®­ç»ƒåæ¨¡å‹é…ç½®æ–‡ä»¶:\",\n                        value=\"\",\n                        interactive=False,\n                        visible=False\n                    )\n\n                    xtts_vocab = gr.Textbox(\n                        label=\"vocabæ–‡ä»¶:\",\n                        value=\"\",\n                        interactive=False,\n                        visible=False\n                    )\n            \n            with gr.Row():\n                with gr.Column() as col2:\n                    speaker_reference_audio = gr.Textbox(\n                        label=\"å‚è€ƒéŸ³é¢‘/ç¬¬äºŒæ­¥ç»“æŸåè‡ªåŠ¨å¡«å……:\",\n                        value=\"\",\n                        placeholder=f\"ç¬¬äºŒæ­¥ç»“æŸåå¯ä»¥åˆ°{os.path.join(args['out_path'], dataset_name,'wavs')}ç›®å½•ä¸‹ï¼Œæ‰¾åˆ°è´¨é‡æ›´å¥½éŸ³é¢‘æ›¿æ¢\"\n                    )\n                    tts_language = gr.Dropdown(\n                        label=\"æ–‡å­—è¯­è¨€\",\n                        value=\"zh\",\n                        choices=[\n                            \"zh\",\n                            \"en\",\n                            \"es\",\n                            \"fr\",\n                            \"de\",\n                            \"it\",\n                            \"pt\",\n                            \"pl\",\n                            \"tr\",\n                            \"ru\",\n                            \"nl\",\n                            \"cs\",\n                            \"ar\",\n                            \"hu\",\n                            \"ko\",\n                            \"ja\",\n                        ]\n                    )\n                    tts_text = gr.Textbox(\n                        label=\"è¾“å…¥è¦åˆæˆçš„æ–‡å­—.\",\n                        value=\"ä½ å¥½å•Šï¼Œæˆ‘äº²çˆ±çš„æœ‹å‹.\",\n                    )                   \n\n                with gr.Column() as col3:\n                    tts_output_audio = gr.Audio(label=\"ç”Ÿæˆçš„å£°éŸ³.\")\n                    reference_audio = gr.Audio(label=\"ä½œä¸ºå‚è€ƒçš„éŸ³é¢‘.\")\n            tts_btn = gr.Button(value=\"ç¬¬ä¸‰æ­¥ï¼šè‡ªåŠ¨å¡«å……å‚è€ƒéŸ³é¢‘åï¼Œç‚¹å‡»æµ‹è¯•æ¨¡å‹æ•ˆæœ\")\n            copy_label=gr.Label(label=\"\")\n            move_btn = gr.Button(value=\"ç¬¬å››æ­¥ï¼šæ•ˆæœå¦‚æœæ»¡æ„ï¼Œç‚¹å‡»å¤åˆ¶åˆ°clone-voiceä¸­ä½¿ç”¨å®ƒ\")\n            \n            \n\n            def train_model(language, train_text, eval_text,trainfile,evalfile):\n                clear_gpu_cache()\n                if not trainfile or not evalfile:\n                    gr.Error(\"è¯·ç­‰å¾…æ•°æ®å¤„ç†å®Œæ¯•ï¼Œç›®å‰ä¸å­˜åœ¨æœ‰æ•ˆçš„è®­ç»ƒæ•°æ®é›†!\")\n                    return \"è¯·ç­‰å¾…æ•°æ®å¤„ç†å®Œæ¯•ï¼Œç›®å‰ä¸å­˜åœ¨æœ‰æ•ˆçš„è®­ç»ƒæ•°æ®é›†!\",\"\", \"\", \"\", \"\"\n                try:\n                    with open(trainfile,'w',encoding='utf-8') as f:\n                        f.write(train_text.replace('\\r\\n','\\n'))\n                    with open(evalfile,'w',encoding='utf-8') as f:\n                        f.write(eval_text.replace('\\r\\n','\\n'))\n                    \n                    print(f'{trainfile=}')\n                    print(f'{evalfile=}')\n                    #sys.exit()\n                    # convert seconds to waveform frames\n                    max_audio_length = int(args['max_audio_length'] * 22050)\n                    config_path, original_xtts_checkpoint, vocab_file, exp_path, speaker_wav = train_gpt(language, args['num_epochs'], args['batch_size'], args['grad_acumm'], trainfile, evalfile, output_path=args['out_path'], max_audio_length=max_audio_length)\n                except:\n                    traceback.print_exc()\n                    error = traceback.format_exc()\n                    print(error)\n                    gr.Error(f\"è®­ç»ƒå‡ºé”™äº†: {error}\")\n                    return f\"è®­ç»ƒå‡ºé”™äº†: {error}\",\"\", \"\", \"\", \"\"\n\n                # copy original files to avoid parameters changes issues\n                shutil.copy2(config_path,exp_path)\n                shutil.copy2(vocab_file,exp_path)\n\n                ft_xtts_checkpoint = os.path.join(exp_path, \"best_model.pth\")\n                print(\"è®­ç»ƒå®Œæ¯•!\")\n                clear_gpu_cache()               \n                \n                msg=load_model(\n                    ft_xtts_checkpoint,\n                    config_path,\n                    vocab_file\n                )\n                gr.Info(\"è®­ç»ƒå®Œæ¯•ï¼Œå¯ä»¥æµ‹è¯•äº†\")\n                return \"è®­ç»ƒå®Œæ¯•ï¼Œå¯ä»¥æµ‹è¯•äº†\",config_path, vocab_file, ft_xtts_checkpoint, speaker_wav\n        \n            # å¤„ç†æ•°æ®é›†\n            def preprocess_dataset(audio_path, language,  progress=gr.Progress(track_tqdm=True)):\n                clear_gpu_cache()\n                out_path = os.path.join(args['out_path'], dataset_name)\n                os.makedirs(out_path, exist_ok=True)\n                \n                try:\n                    train_meta, eval_meta, audio_total_size = format_audio_list(audio_path, target_language=language, out_path=out_path, gradio_progress=progress)\n                except:\n                    traceback.print_exc()\n                    error = traceback.format_exc()\n                    gr.Error(f\"å¤„ç†è®­ç»ƒæ•°æ®å‡ºé”™äº†! \\n Error summary: {error}\")\n                    return \"\", \"\",\"\",\"\"\n\n                clear_gpu_cache()\n\n                # if audio total len is less than 2 minutes raise an error\n                if audio_total_size < 120:\n                    message = \"ç´ ææ€»æ—¶é•¿ä¸å¾—å°äº2åˆ†é’Ÿ!\"\n                    print(message)\n                    gr.Error(message)\n                    return \"\", \"\",\"\",\"\"\n\n                print(\"æ•°æ®å¤„ç†å®Œæ¯•ï¼Œå¼€å§‹è®­ç»ƒ!\")\n                \n                traindata=\"\"\n                evaldata=\"\"\n                with open(train_meta,'r',encoding=\"utf-8\") as f:\n                    traindata=f.read()\n                with open(eval_meta,'r',encoding=\"utf-8\") as f:\n                    evaldata=f.read()\n                return traindata,evaldata,train_meta,eval_meta\n                \n            \n            # å¤åˆ¶åˆ°clone\n            def move_to_clone(model_name,model_file,vocab,cfg,audio_file):\n                if not audio_file or not os.path.exists(audio_file):\n                    gr.Warning(\"å¿…é¡»å¡«å†™å‚è€ƒéŸ³é¢‘\")\n                    return \"å¿…é¡»å¡«å†™å‚è€ƒéŸ³é¢‘\"\n                gr.Info('å¼€å§‹å¤åˆ¶åˆ°cloneè‡ªå®šä¹‰æ¨¡å‹ä¸‹ï¼Œè¯·è€å¿ƒç­‰å¾…æç¤ºå®Œæˆ')\n                print(f'{model_name=}')\n                print(f'{model_file=}')\n                print(f'{vocab=}')\n                print(f'{cfg=}')\n                print(f'{audio_file=}')\n                model_dir=os.path.join(os.getcwd(),f'models/mymodels/{model_name}')\n                os.makedirs(model_dir,exist_ok=True)\n                shutil.copy2(model_file,os.path.join(model_dir,'model.pth'))\n                shutil.copy2(vocab,os.path.join(model_dir,'vocab.json'))\n                shutil.copy2(cfg,os.path.join(model_dir,'config.json'))\n                shutil.copy2(audio_file,os.path.join(model_dir,'base.wav'))\n                gr.Info('å·²å¤åˆ¶åˆ°cloneè‡ªå®šä¹‰æ¨¡å‹ç›®å½•ä¸‹äº†ï¼Œå¯ä»¥å»ä½¿ç”¨å’¯')\n                return \"å·²å¤åˆ¶åˆ°cloneè‡ªå®šä¹‰æ¨¡å‹ç›®å½•ä¸‹äº†ï¼Œå¯ä»¥å»ä½¿ç”¨å’¯\"\n            \n            move_btn.click(\n                fn=move_to_clone,\n                inputs=[\n                    model_name,\n                    xtts_checkpoint,\n                    xtts_vocab,\n                    xtts_config,\n                    speaker_reference_audio\n                ],\n                outputs=[\n                    copy_label\n                ]\n            )\n            \n            prompt_compute_btn.click(\n                fn=preprocess_dataset,\n                inputs=[\n                    upload_file,\n                    lang\n                ],\n                outputs=[\n                    train_data,eval_data,train_file,eval_file\n                ],\n            )\n            \n            start_train_btn.click(\n                fn=train_model,\n                inputs=[lang,train_data,eval_data,train_file,eval_file],\n                outputs=[copy_label,xtts_config, xtts_vocab, xtts_checkpoint, speaker_reference_audio]\n            )\n\n           \n\n            tts_btn.click(\n                fn=run_tts,\n                inputs=[\n                    tts_language,\n                    tts_text,\n                    speaker_reference_audio,\n                ],\n                outputs=[copy_label,tts_output_audio, reference_audio],\n            )\n            \n    threading.Thread(target=openweb,args=(args['port'],)).start()\n    demo.launch(\n        share=True,\n        debug=False,\n        server_port=args['port'],\n        server_name=\"0.0.0.0\"\n    )\n"
        },
        {
          "name": "tts",
          "type": "tree",
          "content": null
        },
        {
          "name": "tts_cache",
          "type": "tree",
          "content": null
        },
        {
          "name": "utils",
          "type": "tree",
          "content": null
        },
        {
          "name": "version.json",
          "type": "blob",
          "size": 0.041015625,
          "content": "{\n\"version\":\"v0.907\",\n\"version_num\":907\n}\n"
        },
        {
          "name": "xtts_demo.py",
          "type": "blob",
          "size": 11.748046875,
          "content": "import argparse\nimport os\nimport sys\nimport tempfile\n\nimport gradio as gr\nimport librosa.display\nimport numpy as np\n\nimport os\nimport torch\nimport torchaudio\nimport traceback\nfrom TTS.demos.xtts_ft_demo.utils.formatter import format_audio_list\nfrom TTS.demos.xtts_ft_demo.utils.gpt_train import train_gpt\n\nfrom TTS.demos.xtts_ft_demo.utils.cfg import TTSMODEL_DIR\n\nfrom TTS.tts.configs.xtts_config import XttsConfig\nfrom TTS.tts.models.xtts import Xtts\n\n\ndef clear_gpu_cache():\n    # clear the GPU cache\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n\nXTTS_MODEL = None\ndef load_model(xtts_checkpoint, xtts_config, xtts_vocab):\n    global XTTS_MODEL\n    clear_gpu_cache()\n    if not xtts_checkpoint or not xtts_config or not xtts_vocab:\n        return \"You need to run the previous steps or manually set the `XTTS checkpoint path`, `XTTS config path`, and `XTTS vocab path` fields !!\"\n    config = XttsConfig()\n    config.load_json(xtts_config)\n    XTTS_MODEL = Xtts.init_from_config(config)\n    print(\"Loading XTTS model! \")\n    XTTS_MODEL.load_checkpoint(config, checkpoint_path=xtts_checkpoint, vocab_path=xtts_vocab, use_deepspeed=False)\n    if torch.cuda.is_available():\n        XTTS_MODEL.cuda()\n\n    print(\"Model Loaded!\")\n    return \"Model Loaded!\"\n\ndef run_tts(lang, tts_text, speaker_audio_file):\n    if XTTS_MODEL is None or not speaker_audio_file:\n        return \"You need to run the previous step to load the model !!\", None, None\n\n    gpt_cond_latent, speaker_embedding = XTTS_MODEL.get_conditioning_latents(audio_path=speaker_audio_file, gpt_cond_len=XTTS_MODEL.config.gpt_cond_len, max_ref_length=XTTS_MODEL.config.max_ref_len, sound_norm_refs=XTTS_MODEL.config.sound_norm_refs)\n    out = XTTS_MODEL.inference(\n        text=tts_text,\n        language=lang,\n        gpt_cond_latent=gpt_cond_latent,\n        speaker_embedding=speaker_embedding,\n        temperature=XTTS_MODEL.config.temperature, # Add custom parameters here\n        length_penalty=XTTS_MODEL.config.length_penalty,\n        repetition_penalty=XTTS_MODEL.config.repetition_penalty,\n        top_k=XTTS_MODEL.config.top_k,\n        top_p=XTTS_MODEL.config.top_p,\n    )\n\n    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as fp:\n        out[\"wav\"] = torch.tensor(out[\"wav\"]).unsqueeze(0)\n        out_path = fp.name\n        torchaudio.save(out_path, out[\"wav\"], 24000)\n\n    return \"Speech generated !\", out_path, speaker_audio_file\n\n\n\n\n# define a logger to redirect \nclass Logger:\n    def __init__(self, filename=\"log.out\"):\n        self.log_file = filename\n        self.terminal = sys.stdout\n        self.log = open(self.log_file, \"w\")\n\n    def write(self, message):\n        self.terminal.write(message)\n        self.log.write(message)\n\n    def flush(self):\n        self.terminal.flush()\n        self.log.flush()\n\n    def isatty(self):\n        return False\n\n# redirect stdout and stderr to a file\nsys.stdout = Logger()\nsys.stderr = sys.stdout\n\n\n# logging.basicConfig(stream=sys.stdout, level=logging.INFO)\nimport logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n    handlers=[\n        logging.StreamHandler(sys.stdout)\n    ]\n)\n\ndef read_logs():\n    sys.stdout.flush()\n    with open(sys.stdout.log_file, \"r\") as f:\n        return f.read()\n\n\nif __name__ == \"__main__\":\n\n    parser = argparse.ArgumentParser(\n        description=\"\"\"XTTS fine-tuning demo\\n\\n\"\"\"\n        \"\"\"\n        Example runs:\n        set http_proxy=http://127.0.0.1:10809\n\n        python TTS/demos/xtts_ft_demo/xtts_demo.py --port \n        \"\"\",\n        formatter_class=argparse.RawTextHelpFormatter,\n    )\n    parser.add_argument(\n        \"--port\",\n        type=int,\n        help=\"Port to run the gradio demo. Default: 5003\",\n        default=5003,\n    )\n    parser.add_argument(\n        \"--out_path\",\n        type=str,\n        help=\"Output path (where data and checkpoints will be saved) Default: /tmp/xtts_ft/\",\n        default=TTSMODEL_DIR,\n    )\n\n    parser.add_argument(\n        \"--num_epochs\",\n        type=int,\n        help=\"Number of epochs to train. Default: 10\",\n        default=10,\n    )\n    parser.add_argument(\n        \"--batch_size\",\n        type=int,\n        help=\"Batch size. Default: 4\",\n        default=4,\n    )\n    parser.add_argument(\n        \"--grad_acumm\",\n        type=int,\n        help=\"Grad accumulation steps. Default: 1\",\n        default=1,\n    )\n    parser.add_argument(\n        \"--max_audio_length\",\n        type=int,\n        help=\"Max permitted audio size in seconds. Default: 11\",\n        default=10,\n    )\n\n    args = parser.parse_args()\n\n    with gr.Blocks() as demo:\n        with gr.Tab(\"å¼€å§‹è®­ç»ƒ\"):\n            model_name = gr.Textbox(\n                        label=\"ä¿å­˜æ¨¡å‹å(åªå…è®¸è‹±æ–‡/æ•°å­—/ä¸‹Såˆ’çº¿):\",\n                        value=\"\",\n            )\n            upload_file = gr.File(\n                file_count=\"multiple\",\n                label=\"é€‰æ‹©è®­ç»ƒç´ æéŸ³é¢‘æ–‡ä»¶ï¼Œä»…åŒ…å«åŒä¸€ä¸ªäººå£°ï¼Œæ— èƒŒæ™¯å™ªå£°(wav, mp3, and flac)\",\n            )\n            with gr.Row() as r1:\n                lang = gr.Dropdown(\n                    label=\"éŸ³é¢‘å‘å£°è¯­è¨€\",\n                    value=\"zh\",\n                    choices=[\n                        \"zh\",\n                        \"en\",\n                        \"es\",\n                        \"fr\",\n                        \"de\",\n                        \"it\",\n                        \"pt\",\n                        \"pl\",\n                        \"tr\",\n                        \"ru\",\n                        \"nl\",\n                        \"cs\",\n                        \"ar\",\n                        \"hu\",\n                        \"ko\",\n                        \"ja\"\n                    ],\n                )\n                progress_data = gr.Label(\n                    label=\"è¿›åº¦:\"\n                )\n            logs = gr.Textbox(\n                label=\"æ—¥å¿—:\",\n                interactive=False,\n            )\n            demo.load(read_logs, None, logs, every=1)\n\n            prompt_compute_btn = gr.Button(value=\"å¼€å§‹è®­ç»ƒ\")\n            def train_model(language, train_csv, eval_csv, num_epochs, batch_size, grad_acumm, output_path, max_audio_length):\n                clear_gpu_cache()\n                if not train_csv or not eval_csv:\n                    return \"ä¸å­˜åœ¨æœ‰æ•ˆçš„csvæ–‡ä»¶ !\", \"\", \"\", \"\", \"\"\n                try:\n                    # convert seconds to waveform frames\n                    max_audio_length = int(max_audio_length * 22050)\n                    config_path, original_xtts_checkpoint, vocab_file, exp_path, speaker_wav = train_gpt(language, num_epochs, batch_size, grad_acumm, train_csv, eval_csv, output_path=output_path, max_audio_length=max_audio_length)\n                except:\n                    traceback.print_exc()\n                    error = traceback.format_exc()\n                    return f\"è®­ç»ƒå‡ºé”™äº†: {error}\", \"\", \"\", \"\", \"\"\n\n                # copy original files to avoid parameters changes issues\n                os.system(f\"cp {config_path} {exp_path}\")\n                os.system(f\"cp {vocab_file} {exp_path}\")\n\n                ft_xtts_checkpoint = os.path.join(exp_path, \"model.pth\")\n                print(\"è®­ç»ƒå®Œæ¯•!\")\n                clear_gpu_cache()\n                return \"è®­ç»ƒå®Œæ¯•!\", config_path, vocab_file, ft_xtts_checkpoint, speaker_wav\n        \n            def preprocess_dataset(audio_path, language,  progress=gr.Progress(track_tqdm=True)):\n                clear_gpu_cache()\n                out_path = os.path.join(args.out_path, \"dataset\")\n                os.makedirs(out_path, exist_ok=True)\n                \n                try:\n                    train_meta, eval_meta, audio_total_size = format_audio_list(audio_path, target_language=language, out_path=out_path, gradio_progress=progress)\n                except:\n                    traceback.print_exc()\n                    error = traceback.format_exc()\n                    return f\"å¤„ç†è®­ç»ƒæ•°æ®å‡ºé”™äº†! \\n Error summary: {error}\", \"\", \"\",\"\",\"\"\n\n                clear_gpu_cache()\n\n                # if audio total len is less than 2 minutes raise an error\n                if audio_total_size < 120:\n                    message = \"ç´ ææ€»æ—¶é•¿ä¸å¾—å°äº2åˆ†é’Ÿ!\"\n                    print(message)\n                    return message, \"\", \"\",\"\",\"\"\n\n                print(\"æ•°æ®å¤„ç†å®Œæ¯•ï¼Œå¼€å§‹è®­ç»ƒ!\")\n                msg, config_path, vocab_file, ft_xtts_checkpoint, speaker_wav=train_model(language, train_meta, eval_meta, args.num_epochs, args.batch_size, args.grad_acumm, args.out_path, args.max_audio_length)\n                progress_data, xtts_config, xtts_vocab, xtts_checkpoint, speaker_reference_audio\n                msg=load_model(\n                    ft_xtts_checkpoint,\n                    config_path,\n                    vocab_file\n                )\n                \n                return msg, config_path, vocab_file, ft_xtts_checkpoint, speaker_wav\n\n        with gr.Tab(\"ä½¿ç”¨å·²è®­ç»ƒå¥½çš„æ¨¡å‹\"):\n            with gr.Row():\n                with gr.Column() as col1:\n                    xtts_checkpoint = gr.Textbox(\n                        label=\"XTTS checkpoint path:\",\n                        value=\"\",\n                    )\n                    xtts_config = gr.Textbox(\n                        label=\"XTTS config path:\",\n                        value=\"\",\n                    )\n\n                    xtts_vocab = gr.Textbox(\n                        label=\"XTTS vocab path:\",\n                        value=\"\",\n                    )\n                    progress_load = gr.Label(\n                        label=\"è¿›åº¦:\"\n                    )\n                    load_btn = gr.Button(value=\"Step 3 - Load Fine-tuned XTTS model\")\n\n                with gr.Column() as col2:\n                    speaker_reference_audio = gr.Textbox(\n                        label=\"å‚è€ƒéŸ³é¢‘:\",\n                        value=\"\",\n                    )\n                    tts_language = gr.Dropdown(\n                        label=\"Language\",\n                        value=\"zh\",\n                        choices=[\n                            \"zh\",\n                            \"en\",\n                            \"es\",\n                            \"fr\",\n                            \"de\",\n                            \"it\",\n                            \"pt\",\n                            \"pl\",\n                            \"tr\",\n                            \"ru\",\n                            \"nl\",\n                            \"cs\",\n                            \"ar\",\n                            \"hu\",\n                            \"ko\",\n                            \"ja\",\n                        ]\n                    )\n                    tts_text = gr.Textbox(\n                        label=\"è¾“å…¥è¦åˆæˆçš„æ–‡å­—.\",\n                        value=\"ä½ å¥½å•Šï¼Œäº²çˆ±çš„æœ‹å‹.\",\n                    )\n                    tts_btn = gr.Button(value=\"ç”Ÿæˆå£°éŸ³\")\n\n                with gr.Column() as col3:\n                    progress_gen = gr.Label(\n                        label=\"è¿›åº¦:\"\n                    )\n                    tts_output_audio = gr.Audio(label=\"ç”Ÿæˆçš„å£°éŸ³.\")\n                    reference_audio = gr.Audio(label=\"å‚è€ƒéŸ³é¢‘.\")\n\n            prompt_compute_btn.click(\n                fn=preprocess_dataset,\n                inputs=[\n                    upload_file,\n                    lang\n                ],\n                outputs=[\n                    progress_data, xtts_config, xtts_vocab, xtts_checkpoint, speaker_reference_audio\n                ],\n            )\n\n           \n\n            tts_btn.click(\n                fn=run_tts,\n                inputs=[\n                    tts_language,\n                    tts_text,\n                    speaker_reference_audio,\n                ],\n                outputs=[progress_gen, tts_output_audio, reference_audio],\n            )\n\n    demo.launch(\n        share=True,\n        debug=False,\n        server_port=args.port,\n        server_name=\"0.0.0.0\"\n    )\n"
        }
      ]
    }
  ]
}