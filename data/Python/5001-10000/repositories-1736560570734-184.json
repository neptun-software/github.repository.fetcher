{
  "metadata": {
    "timestamp": 1736560570734,
    "page": 184,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE5MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "autogluon/autogluon",
      "stars": 8236,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.7763671875,
          "content": "# Extra\n*.params\n*.states\n*.out\n*.swp\n.DS_Store\n.vscode\n*.npy\n*.npz\n*.json\n*.ag\n*.xml\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n.pytest_cache/\n*.py[cod]\n*$py.class\n*.swp\n.DS_Store\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nenv/\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\n*.lock\n*.dirlock\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\n\n# Flask stuff:\n# instance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# SageMath parsed files\n*.sage.py\n\n# dotenv\n.env\n\n# virtualenv\n.venv*\nvenv/\nENV/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mypy\n.mypy_cache/\n\n*.jpg*\n*.jpeg*\n.idea/*\ntrain/*\n\n!examples/mo_hpo/mo_hyperband_files/mo_hyperband_12_0.png\n\ntutorials/checkpoint/*\ntutorials/train/*\nexamples/image_classification/*.csv\ntests/unittests/*.zip\ntabular/tests/unittests/datasets\n\nautogluon/src/autogluon/version.py\ncommon/src/autogluon/common/version.py\ncore/src/autogluon/core/version.py\nfeatures/src/autogluon/features/version.py\ntimeseries/src/autogluon/timeseries/version.py\ntabular/src/autogluon/tabular/version.py\nmultimodal/src/autogluon/multimodal/version.py\neda/src/autogluon/eda/version.py\n\nAutogluonModels\nlightning_logs\nVERSION.minor\n"
        },
        {
          "name": "AWESOME.md",
          "type": "blob",
          "size": 41.46484375,
          "content": "Awesome AutoGluon\n-----------------\n\nThis page contains a moderated list of examples, tutorials, articles, and research papers about AutoGluon use cases.\nIt is inspired by [awesome-machine-learning](https://github.com/josephmisiti/awesome-machine-learning).\n\nWe will be happy to add your success story using AutoGluon to this list.\nSend us a pull request if you want to include your case here.\n\n## Videos & Tutorials\n\nTo get started, we recommend watching [AutoGluon 1.0: Shattering the AutoML Ceiling with Zero Lines of Code](https://www.youtube.com/watch?v=5tvp_Ihgnuk), our talk at AutoML Conf 2023.\n\n### Full Talk List\n\n| Title                                                                                                                                                              | Format    | Location                                                                                                                           | Date       |\n|--------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------|------------------------------------------------------------------------------------------------------------------------------------|------------|\n| :tv: [AutoGluon: Towards No-Code Automated Machine Learning](https://www.youtube.com/watch?v=SwPq9qjaN2Q)                                                          | Tutorial  | [AutoML 2024](https://2024.automl.cc/)                                                                                             | 2024/09/09 |\n| [AutoGluon: AutoML at Your Fingertips](https://suzhoum.github.io/icml-24-autogluon-talk/)                                                                          | Expo Talk | [ICML 2024](https://icml.cc/Expo/Conferences/2024/talk%20panel/36234)                                                              | 2024/07/21 |\n| [AutoGluon 1.0: AutoML at Your Fingertips](https://autogluon.github.io/neurips-autogluon-workshop/)                                                                | Tutorial  | [NeurIPS 2023](https://neurips.cc/Expo/Conferences/2023/workshop/78401)                                                            | 2023/12/10 |\n| :tv: [Leveraging Text, Images, and the Kitchen Sink to solve complex ML problems in 1 line of code](https://www.youtube.com/watch?v=fdfGb2jq-_c)                   | Tutorial  | [Fall AutoML School 2023](https://sites.google.com/view/automl-fall-school-2023/schedule/hands-on-autogluon?authuser=0)            | 2023/11/29 |\n| :tv: [AutoGluon 1.0: Shattering the AutoML Ceiling with Zero Lines of Code](https://www.youtube.com/watch?v=5tvp_Ihgnuk)                                           | Tutorial  | [AutoML 2023](https://2023.automl.cc/)                                                                                             | 2023/09/12 |\n| :sound: [AutoGluon: The Story](https://automlpodcast.com/episode/autogluon-the-story)                                                                              | Podcast   | [The AutoML Podcast](https://automlpodcast.com/)                                                                                   | 2023/09/05 |\n| :tv: [AutoGluon: AutoML for Tabular, Multimodal, and Time Series Data](https://youtu.be/Lwu15m5mmbs?si=jSaFJDqkTU27C0fa)                                           | Tutorial  | PyData Berlin                                                                                                                      | 2023/06/20 | \n| :tv: [Solving Complex ML Problems in a few Lines of Code with AutoGluon](https://www.youtube.com/watch?v=J1UQUCPB88I)                                              | Tutorial  | PyData Seattle                                                                                                                     | 2023/06/20 | \n| [AutoGluon: Empowering (Multimodal) AutoML for the Next 10 Million Users](https://autogluon.github.io/neurips2022-autogluon-workshop/)                             | Tutorial  | [NeurIPS 2022](https://nips.cc/Expo/Conferences/2022/workshop/63089)                                                               | 2022/11/28 |\n| :tv: [The AutoML Revolution](https://www.youtube.com/watch?v=VAAITEds-28)                                                                                          | Tutorial  | [Fall AutoML School 2022](https://sites.google.com/view/automl-fall-school-2022)                                                   | 2022/10/18 |\n| [Multimodal AutoML for Image, Text and Tabular Data](https://github.com/Innixma/kdd-2022-multimodal-automl-tutorial)                                               | Tutorial  | [KDD 2022](https://kdd.org/kdd2022/lectureTutorial.html)                                                                           | 2022/08/14 |\n| :tv: [Automating Machine Learning for the Rest of Us](https://www.youtube.com/watch?v=x-EEDBSl3OM)                                                                 | Keynote   | [AutoML 2022](https://2022.automl.cc/index.html)                                                                                   | 2022/07/25 |\n| :tv: [AutoGluon: re:MARS 2022 Keynote](https://www.youtube.com/watch?v=_wd0IJBTwbY&t=1277s)                                                                        | Keynote   | [Amazon re:MARS 2022](https://icml.cc/virtual/2020/workshop/5725)                                                                  | 2022/06/24 |\n| [Advancing the State of the Art in AutoML](https://developer.nvidia.com/blog/advancing-the-state-of-the-art-in-automl-now-10x-faster-with-nvidia-gpus-and-rapids/) | Talk      | [GTC 2021](https://developer.nvidia.com/blog/advancing-the-state-of-the-art-in-automl-now-10x-faster-with-nvidia-gpus-and-rapids/) | 2021/06/09 |\n| :tv: [AutoGluon and Distillation](https://icml.cc/virtual/2020/7045)                                                                                               | Keynote   | [ICML 2020, AutoML Workshop](https://icml.cc/virtual/2020/workshop/5725)                                                           | 2020/07/18 |\n\n### Articles\n- [AutoGluon-TimeSeries: Every Time Series Forecasting Model In One Library](https://towardsdatascience.com/autogluon-timeseries-every-time-series-forecasting-model-in-one-library-29a3bf6879db) (*Towards Data Science*, Jan 2024)\n- [AutoGluon-TimeSeries: Creating Powerful Ensemble Forecasts - Complete Tutorial](https://aihorizonforecast.substack.com/p/autogluon-timeseries-creating-powerful) (*AI Horizon Forecast*, Dec 2023)\n- [AutoGluon for tabular data: 3 lines of code to achieve top 1% in Kaggle competitions](https://aws.amazon.com/blogs/opensource/machine-learning-with-autogluon-an-open-source-automl-library/) (*AWS Open Source Blog*, Mar 2020)\n- [AutoGluon overview & example applications](https://towardsdatascience.com/autogluon-deep-learning-automl-5cdb4e2388ec?source=friends_link&sk=e3d17d06880ac714e47f07f39178fdf2) (*Towards Data Science*, Dec 2019)\n\n## Competition Solutions using AutoGluon\n\nAutoGluon is [widely adopted](https://www.kaggle.com/search?q=autogluon) on ML competition sites such as Kaggle. \nBelow is a sampling of competition solutions that use AutoGluon to achieve strong results.\n\n### Kaggle\n\n#### 2024\n\n| Placement                                | Competition Solution                                                                                                                                    | Author                                                                                                                                     | Date       | AutoGluon Details | Notes                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n|:-----------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------|:-----------|:------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| :2nd_place_medal: Rank 2/2392 (Top 0.1%) | [Regression with an Insurance Dataset](https://www.kaggle.com/competitions/playground-series-s4e12/discussion/554505)                                   | [SCRIPTCHEF](https://www.kaggle.com/noodl35)                                                                                               | 2024/12/31 | v1.2, Tabular     | Kaggle Playground Series S4E12. Also used in [9th](https://www.kaggle.com/competitions/playground-series-s4e12/discussion/554377) and [10th](https://www.kaggle.com/competitions/playground-series-s4e12/discussion/554332) place solutions!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n| :1st_place_medal: Rank 1/2687            | [Exploring Mental Health Data](https://www.kaggle.com/competitions/playground-series-s4e11/discussion/549160)                                           | [Mahdi Ravaghi](https://www.kaggle.com/ravaghi)                                                                                            | 2024/11/30 | v1.1, Tabular     | Kaggle Playground Series S4E11. Also used in [4th](https://www.kaggle.com/competitions/playground-series-s4e11/discussion/549197) and [13th](https://www.kaggle.com/competitions/playground-series-s4e11/discussion/549155) place solutions!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n| Rank 8/3859 (Top 0.3%)                   | [Loan Approval Prediction](https://www.kaggle.com/competitions/playground-series-s4e10/discussion/543772)                                               | [Mahdi Ravaghi](https://www.kaggle.com/ravaghi)                                                                                            | 2024/10/31 | v1.1, Tabular     | Kaggle Playground Series S4E10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n| :1st_place_medal: Rank 1/3066            | [Regression of Used Car Prices](https://www.kaggle.com/competitions/playground-series-s4e9/discussion/537052)                                           | [Mart Preusse](https://www.kaggle.com/martinapreusse)                                                                                      | 2024/09/30 | v1.1, Tabular     | Kaggle Playground Series S4E9. Also used in :2nd_place_medal: [2nd](https://www.kaggle.com/competitions/playground-series-s4e9/discussion/537349), :3rd_place_medal: [3rd](https://www.kaggle.com/competitions/playground-series-s4e9/discussion/537029), [4th](https://www.kaggle.com/competitions/playground-series-s4e9/discussion/536973), and [5th](https://www.kaggle.com/competitions/playground-series-s4e9/discussion/537173) place solutions!                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n| :1st_place_medal: Rank 1/1116            | [Kaggle AutoML Grand Prix (Overall)](https://www.kaggle.com/automl-grand-prix)                                                                          | [Alexander R.](https://www.kaggle.com/alexryzhkov), [Dmitry S.](https://www.kaggle.com/simakov), [Rinchin](https://www.kaggle.com/rinchin) | 2024/09/01 | v1.1, Tabular     | Teams using AutoGluon in the Grand Prix: :1st_place_medal: [1st](https://www.kaggle.com/competitions/playground-series-s4e8/discussion/523732), :2nd_place_medal: [2nd](https://www.kaggle.com/competitions/playground-series-s4e8/discussion/523656), :3rd_place_medal: [3rd](https://www.kaggle.com/competitions/playground-series-s4e9/discussion/532028), [4th](https://www.kaggle.com/competitions/playground-series-s4e8/discussion/524709), [6th](https://www.kaggle.com/competitions/playground-series-s4e9/discussion/532758), [7th](https://www.kaggle.com/competitions/playground-series-s4e9/discussion/532419), [8th](https://www.kaggle.com/competitions/playground-series-s4e9/discussion/532668), [9th](https://www.kaggle.com/competitions/playground-series-s4e6/discussion/509937), and [10th](https://www.kaggle.com/competitions/playground-series-s4e8/discussion/524752) place teams! |\n| :2nd_place_medal: Rank 2/247 (Top 1%)    | [Kaggle AutoML Grand Prix Episode 5](https://www.kaggle.com/competitions/playground-series-s4e9/discussion/532028)                                      | [Robert Hatch](https://www.kaggle.com/roberthatch)                                                                                         | 2024/09/01 | v1.1, Tabular     | Also used in :3rd_place_medal: [3rd](https://www.kaggle.com/competitions/playground-series-s4e9/discussion/531971), [4th](https://www.kaggle.com/competitions/playground-series-s4e9/discussion/532419), 6th, 7th, 9th, and 10th place solutions!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n| :1st_place_medal: Rank 1/2424            | [Binary Prediction of Poisonous Mushrooms](https://www.kaggle.com/competitions/playground-series-s4e8/discussion/531823)                                | [Optimistix](https://www.kaggle.com/optimistix)                                                                                            | 2024/08/31 | v1.1, Tabular     | Kaggle Playground Series S4E8. Also used in :2nd_place_medal: [2nd](https://www.kaggle.com/competitions/playground-series-s4e8/discussion/531368), :3rd_place_medal: [3rd](https://www.kaggle.com/competitions/playground-series-s4e8/discussion/531956), [4th](https://www.kaggle.com/competitions/playground-series-s4e8/discussion/531343), [6th](https://www.kaggle.com/competitions/playground-series-s4e8/discussion/531330), [8th](https://www.kaggle.com/competitions/playground-series-s4e8/discussion/531374), and [10th](https://www.kaggle.com/competitions/playground-series-s4e8/discussion/531424) place solutions!                                                                                                                                                                                                                                                                           |\n| :1st_place_medal: Rank 1/218             | [Kaggle AutoML Grand Prix Episode 4](https://www.kaggle.com/competitions/playground-series-s4e8/discussion/523656)                                      | [Lennart P.](https://twitter.com/lennartpurucker), [Nick E.](https://twitter.com/innixma) & [Arjun K.](https://github.com/Neonkraft)       | 2024/08/01 | v1.1, Tabular     | Also used in :2nd_place_medal: [2nd](https://www.kaggle.com/competitions/playground-series-s4e8/discussion/524752), :3rd_place_medal: [3rd](https://www.kaggle.com/competitions/playground-series-s4e8/discussion/524709), [4th](https://www.kaggle.com/competitions/playground-series-s4e8/discussion/523837), [5th](https://www.kaggle.com/competitions/playground-series-s4e8/discussion/523660), [6th](https://www.kaggle.com/competitions/playground-series-s4e8/discussion/524720), [7th](https://www.kaggle.com/competitions/playground-series-s4e8/discussion/523732), [8th](https://www.kaggle.com/competitions/playground-series-s4e8/discussion/524544), [9th](https://www.kaggle.com/competitions/playground-series-s4e8/discussion/524675), and [10th](https://www.kaggle.com/competitions/playground-series-s4e8/discussion/524430) place solutions!                                           |\n| :3rd_place_medal: Rank 3/2236 (Top 0.2%) | [Binary Classification of Insurance Cross Selling](https://www.kaggle.com/competitions/playground-series-s4e7/discussion/523661)                        | [Tilii](https://www.kaggle.com/tilii7)                                                                                                     | 2024/07/31 | v1.1, Tabular     | Kaggle Playground Series S4E7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n| Rank 4/207 (Top 2%)                      | [Kaggle AutoML Grand Prix Episode 3](https://www.kaggle.com/competitions/playground-series-s4e7/discussion/516265)                                      | [Lennart Purucker](https://twitter.com/lennartpurucker) & [Nick Erickson](https://twitter.com/innixma)                                     | 2024/07/01 | v1.1, Tabular     |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n| Rank 17/2684 (Top 1%)                    | [Classification with an Academic Success Dataset](https://www.kaggle.com/competitions/playground-series-s4e6/discussion/516047)                         | [Mart Preusse](https://www.kaggle.com/martinapreusse)                                                                                      | 2024/06/30 | v1.1, Tabular     | Kaggle Playground Series S4E6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n| :3rd_place_medal: Rank 3/542 (Top 0.6%)  | [WiDS Datathon 2024 Challenge #2](https://www.kaggle.com/competitions/widsdatathon2024-challenge2/discussion/511732)                                    | [olgaskv](https://www.kaggle.com/olgaskv)                                                                                                  | 2024/06/11 | v1.1, Tabular     |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n| :1st_place_medal: Rank 1/230             | [Kaggle AutoML Grand Prix Episode 2](https://www.kaggle.com/competitions/playground-series-s4e6/discussion/509631)                                      | [Lennart Purucker](https://twitter.com/lennartpurucker) & [Nick Erickson](https://twitter.com/innixma)                                     | 2024/06/01 | v1.1, Tabular     | Also used in [5th](https://www.kaggle.com/competitions/playground-series-s4e6/discussion/509937) place solution!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n| :1st_place_medal: Rank 1/2788            | [Regression with a Flood Prediction Dataset](https://www.kaggle.com/competitions/playground-series-s4e5/discussion/509043)                              | [Alexandre Daubas](https://www.kaggle.com/adaubas)                                                                                         | 2024/05/31 | v1.1, Tabular     | Kaggle Playground Series S4E5. Also used in :2nd_place_medal: [2nd](https://www.kaggle.com/competitions/playground-series-s4e5/discussion/509410), :3rd_place_medal: [3rd](https://www.kaggle.com/competitions/playground-series-s4e5/discussion/509042), and [4th](https://www.kaggle.com/competitions/playground-series-s4e5/discussion/509044) place solutions!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n| Rank 5/214 (Top 3%)                      | [Kaggle AutoML Grand Prix Episode 1](https://www.kaggle.com/competitions/playground-series-s4e5/discussion/500453)                                      | [James King](https://www.kaggle.com/jamesking76)                                                                                           | 2024/05/01 | v1.1, Tabular     | Also used in [8th](https://www.kaggle.com/competitions/playground-series-s4e5/discussion/509410) and [9th](https://www.kaggle.com/competitions/playground-series-s4e5/discussion/509042) place solutions!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n| :1st_place_medal: Rank 1/2606            | [Regression with an Abalone Dataset](https://www.kaggle.com/competitions/playground-series-s4e4/discussion/499174)                                      | [Johannes Heller](https://www.kaggle.com/stopwhispering)                                                                                   | 2024/04/30 | v1.0, Tabular     | Kaggle Playground Series S4E4. Also used in :2nd_place_medal: [2nd](https://www.kaggle.com/competitions/playground-series-s4e4/discussion/499698), :3rd_place_medal: [3rd](https://www.kaggle.com/competitions/playground-series-s4e4/discussion/499747), [4th](https://www.kaggle.com/competitions/playground-series-s4e4/discussion/499341), and [8th](https://www.kaggle.com/competitions/playground-series-s4e4/discussion/499258) place solutions!                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n| :3rd_place_medal: Rank 3/2303 (Top 0.2%) | [Steel Plate Defect Prediction](https://www.kaggle.com/competitions/playground-series-s4e3/discussion/488127)                                           | [Samvel Kocharyan](https://github.com/samvelkoch)                                                                                          | 2024/03/31 | v1.0, Tabular     | Kaggle Playground Series S4E3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n| :2nd_place_medal: Rank 2/93 (Top 2%)     | [Prediction Interval Competition I: Birth Weight](https://www.kaggle.com/competitions/prediction-interval-competition-i-birth-weight/discussion/496813) | [Oleksandr Shchur](https://shchur.github.io/)                                                                                              | 2024/03/21 | v1.0, Tabular     |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n| :2nd_place_medal: Rank 2/1542 (Top 0.2%) | [WiDS Datathon 2024 Challenge #1](https://www.kaggle.com/competitions/widsdatathon2024-challenge1/discussion/482285)                                    | [lazy_panda](https://www.kaggle.com/byteliberator)                                                                                         | 2024/03/01 | v1.0, Tabular     |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n| :2nd_place_medal: Rank 2/3746 (Top 0.1%) | [Multi-Class Prediction of Obesity Risk](https://www.kaggle.com/competitions/playground-series-s4e2/discussion/480939)                                  | [Kirderf](https://twitter.com/kirderf9)                                                                                                    | 2024/02/29 | v1.0, Tabular     | Kaggle Playground Series S4E2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n| :2nd_place_medal: Rank 2/3777 (Top 0.1%) | [Binary Classification with a Bank Churn Dataset](https://www.kaggle.com/competitions/playground-series-s4e1/discussion/472496)                         | [lukaszl](https://www.kaggle.com/lukaszl)                                                                                                  | 2024/01/31 | v1.0, Tabular     | Kaggle Playground Series S4E1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n\n#### Older Results\n\n| Placement                               | Competition Solution                                                                                                                                   | Author                                                                | Date       | AutoGluon Details | Notes                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n|:----------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------|:-----------|:------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Rank 4/1718 (Top 0.2%)                  | [Multi-Class Prediction of Cirrhosis Outcomes](https://www.kaggle.com/competitions/playground-series-s3e26/discussion/464863)                          | [Kirderf](https://twitter.com/kirderf9)                               | 2023/12/31 | v1.0, Tabular     | Kaggle Playground Series S3E26                                                                                                                                                                                                                                                                                                                                                                                                                        |\n| :2nd_place_medal: Rank 2/58 (Top 4%)    | [ML Olympiad - Water Quality Prediction](https://www.kaggle.com/competitions/ml-olympiad-waterqualityprediction/discussion/393393)                     | [Chris X](https://www.kaggle.com/docxian)                             | 2023/03/11 | v0.6.2, Tabular   |                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n| Rank 6/734 (Top 1%)                     | [Tabular Regression with a Gemstone Price Dataset](https://www.kaggle.com/competitions/playground-series-s3e8/discussion/392820)                       | [Kirderf](https://twitter.com/kirderf9)                               | 2023/03/06 | v0.6.2, Tabular   | Kaggle Playground Series S3E8                                                                                                                                                                                                                                                                                                                                                                                                                         |\n| Rank 9/703 (Top 1.3%)                   | [Tabular Regression with a Paris Housing Price Dataset](https://www.kaggle.com/competitions/playground-series-s3e6/discussion/389151)                  | [Brendan Moore](https://www.kaggle.com/brendanmoore14)                | 2023/02/20 | v0.6.2, Tabular   | Kaggle Playground Series S3E6                                                                                                                                                                                                                                                                                                                                                                                                                         |\n| :1st_place_medal: Rank 1/689            | [Tabular Regression with the California Housing Dataset](https://www.kaggle.com/competitions/playground-series-s3e1/discussion/377137)                 | [Kirderf](https://twitter.com/kirderf9)                               | 2023/01/09 | v0.6.1, Tabular   | Kaggle Playground Series S3E1                                                                                                                                                                                                                                                                                                                                                                                                                         |\n\n## Research Papers\n\nTo view a list of all AutoGluon research papers, please refer to our [citation guide](CITING.md).\n\n## AutoML Benchmarks using AutoGluon\n* [AMLB: An AutoML Benchmark](https://openml.github.io/automlbenchmark/)\n  * For a thorough comparison of AutoGluon and other modern AutoML systems, please refer to the 2024 JMLR paper [\"AMLB: An AutoML Benchmark\"](https://www.jmlr.org/papers/volume25/22-0493/22-0493.pdf) and the [2022 edition](https://arxiv.org/abs/2207.12560) where AutoGluon is shown to be the state-of-the-art among AutoML systems on tabular data.\n  * We encourage all users to benchmark AutoGluon & other AutoML frameworks on AMLB.\n  * This is our preferred benchmark as it is widely accepted and trusted within the AutoML community.\n\n## Papers using AutoGluon\n\nBelow is a sampling of some interesting papers that have cited AutoGluon.\n\n* (2023/04/28) [Benchmarking Automated Machine Learning Methods for Price Forecasting Applications](https://arxiv.org/abs/2304.14735)\n  * This paper compares various traditional and AutoML methods for price forecasting problems, with AutoGluon achieving the strongest results.\n"
        },
        {
          "name": "CI",
          "type": "tree",
          "content": null
        },
        {
          "name": "CITING.md",
          "type": "blob",
          "size": 5.4833984375,
          "content": "The AutoGluon developers and community are committed to open source, and that extends to our research.\nBelow you can find a list of our published work relating to AutoGluon along with guidelines for citing our work.\n\n## Scientific Publications\n- [AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data](https://arxiv.org/pdf/2003.06505.pdf) (*Arxiv*, 2020) ([BibTeX](#general-usage--autogluontabular))\n- [Fast, Accurate, and Simple Models for Tabular Data via Augmented Distillation](https://proceedings.neurips.cc/paper/2020/hash/62d75fb2e3075506e8837d8f55021ab1-Abstract.html) (*NeurIPS*, 2020) ([BibTeX](#tabular-distillation))\n- [Benchmarking Multimodal AutoML for Tabular Data with Text Fields](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/9bf31c7ff062936a96d3c8bd1f8f2ff3-Paper-round2.pdf) (*NeurIPS*, 2021) ([BibTeX](#autogluonmultimodal))\n- [XTab: Cross-table Pretraining for Tabular Transformers](https://proceedings.mlr.press/v202/zhu23k/zhu23k.pdf) (*ICML*, 2023)\n- [AutoGluon-TimeSeries: AutoML for Probabilistic Time Series Forecasting](https://arxiv.org/abs/2308.05566) (*AutoML Conf*, 2023) ([BibTeX](#autogluontimeseries))\n- [TabRepo: A Large Scale Repository of Tabular Model Evaluations and its AutoML Applications](https://arxiv.org/pdf/2311.02971.pdf) (*AutoML Conf*, 2024)\n- [AutoGluon-Multimodal (AutoMM): Supercharging Multimodal AutoML with Foundation Models](https://arxiv.org/pdf/2404.16233) (*AutoML Conf*, 2024) ([BibTeX](#autogluonmultimodal))\n\n## Citing AutoGluon\n\nPlease cite the core AutoGluon paper (AutoGluon-Tabular) as well as any module specific paper that is relevant.\n\n### General Usage & autogluon.tabular\n\nIf you use AutoGluon in a scientific publication, please cite the following paper (regardless of which module is being used):\n- Erickson, Nick, et al. [\"AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data.\"](https://arxiv.org/abs/2003.06505) arXiv preprint arXiv:2003.06505 (2020).\n\nBibTeX entry:\n\n```bibtex\n@article{agtabular,\n  title={AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data},\n  author={Erickson, Nick and Mueller, Jonas and Shirkov, Alexander and Zhang, Hang and Larroy, Pedro and Li, Mu and Smola, Alexander},\n  journal={arXiv preprint arXiv:2003.06505},\n  year={2020}\n}\n```\n\n### autogluon.multimodal\n\nIf you use AutoGluon's multimodal functionality in a scientific publication, please cite the following paper:\n\nZhiqiang, Tang, et al. [\"AutoGluon-Multimodal (AutoMM): Supercharging Multimodal AutoML with Foundation Models\"](https://arxiv.org/pdf/2404.16233), The International Conference on Automated Machine Learning (AutoML), 2024.\n\nBibTeX entry:\n\n```bibtex\n@article{tang2024autogluon,\n  title={AutoGluon-Multimodal (AutoMM): Supercharging Multimodal AutoML with Foundation Models},\n  author={Tang, Zhiqiang and Fang, Haoyang and Zhou, Su and Yang, Taojiannan and Zhong, Zihan and Hu, Tony and Kirchhoff, Katrin and Karypis, George},\n  journal={arXiv preprint arXiv:2404.16233},\n  year={2024}\n}\n```\n\nIf you use AutoGluon's TextPredictor, please cite the following paper:\n\nShi, Xingjian, et al. [\"Benchmarking Multimodal AutoML for Tabular Data with Text Fields.\"](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/9bf31c7ff062936a96d3c8bd1f8f2ff3-Paper-round2.pdf) Advances in Neural Information Processing Systems 35, Datasets and Benchmarks Track (2021).\n\n```bibtex\n@inproceedings{agmultimodaltext,\n  title={Benchmarking Multimodal AutoML for Tabular Data with Text Fields},\n  author={Shi, Xingjian and Mueller, Jonas and Erickson, Nick and Li, Mu and Smola, Alexander J},\n  journal={Advances in Neural Information Processing Systems Datasets and Benchmarks Track},\n  volume={35},\n  year={2021}\n}\n```\n\n### autogluon.timeseries\n\nIf you use AutoGluon's time series forecasting functionality in a scientific publication, please cite the following paper:\n```bibtex\n@inproceedings{agtimeseries,\n  title={{AutoGluon-TimeSeries}: {AutoML} for Probabilistic Time Series Forecasting},\n  author={Shchur, Oleksandr and Turkmen, Caner and Erickson, Nick and Shen, Huibin and Shirkov, Alexander and Hu, Tony and Wang, Yuyang},\n  booktitle={International Conference on Automated Machine Learning},\n  year={2023}\n}\n```\n\nIf you use the Chronos pretrained model, please cite:\n```bibtex\n@article{ansari2024chronos,\n  author  = {Ansari, Abdul Fatir and Stella, Lorenzo and Turkmen, Caner and Zhang, Xiyuan, and Mercado, Pedro and Shen, Huibin and Shchur, Oleksandr and Rangapuram, Syama Syndar and Pineda Arango, Sebastian and Kapoor, Shubham and Zschiegner, Jasper and Maddix, Danielle C. and Mahoney, Michael W. and Torkkola, Kari and Gordon Wilson, Andrew and Bohlke-Schneider, Michael and Wang, Yuyang},\n  title   = {Chronos: Learning the Language of Time Series},\n  journal = {arXiv preprint arXiv:2403.07815},\n  year    = {2024}\n}\n```\n\n### Tabular Distillation\n\nIf you are using AutoGluon Tabular's model distillation functionality, please cite the following paper:\n\nFakoor, Rasool, et al. [\"Fast, Accurate, and Simple Models for Tabular Data via Augmented Distillation.\"](https://proceedings.neurips.cc/paper/2020/hash/62d75fb2e3075506e8837d8f55021ab1-Abstract.html) Advances in Neural Information Processing Systems 33 (2020).\n\nBibTeX entry:\n\n```bibtex\n@article{agtabulardistill,\n  title={Fast, Accurate, and Simple Models for Tabular Data via Augmented Distillation},\n  author={Fakoor, Rasool and Mueller, Jonas W and Erickson, Nick and Chaudhari, Pratik and Smola, Alexander J},\n  journal={Advances in Neural Information Processing Systems},\n  volume={33},\n  year={2020}\n}\n```\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 0.3017578125,
          "content": "## Code of Conduct\nThis project has adopted the [Amazon Open Source Code of Conduct](https://aws.github.io/code-of-conduct).\nFor more information see the [Code of Conduct FAQ](https://aws.github.io/code-of-conduct-faq) or contact\nopensource-codeofconduct@amazon.com with any additional questions or comments.\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 7.7548828125,
          "content": "# Contributing Guidelines\n\nThank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional\ndocumentation, we greatly value feedback and contributions from our community.\n\nPlease read through this document before submitting any issues or pull requests to ensure we have all the necessary\ninformation to effectively respond to your bug report or contribution.\n\n\n## Reporting Bugs/Feature Requests\n\nWe welcome you to use the GitHub issue tracker to report bugs or suggest features.\n\nWhen filing an issue, please check [existing open](https://github.com/autogluon/autogluon/issues), or [recently closed](https://github.com/autogluon/autogluon/issues?utf8=%E2%9C%93&q=is%3Aissue%20is%3Aclosed%20), issues to make sure somebody else hasn't already\nreported the issue. Please try to include as much information as you can. Details like these are incredibly useful:\n\n* A reproducible test case or series of steps\n* The version of AutoGluon being used, the version of pytorch\n* Any modifications you've made relevant to the bug\n* Anything unusual about your environment or deployment\n\nIdeally, you can install AutoGluon and its dependencies in a fresh virtualenv to reproduce the bug.\n\n## Contributing via Pull Requests\nCode contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that:\n\n1. You are working against the latest source on the *master* branch.\n2. You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already.\n3. You open an issue to discuss any significant work - we would hate for your time to be wasted.\n\nTo send us a pull request, please:\n\n1. Fork the repository.\n2. Modify the source (see details below); please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change.\n3. Ensure local tests pass.\n4. Commit to your fork using clear commit messages.\n5. Send us a pull request, answering any default questions in the pull request interface.\n6. Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation.\n7. To spin up the platform tests, which test autogluon among macos and windows, comment on the PR with `/platform_tests`(You would need write permission to AutoGluon repo). It is recommended to run the platform tests only after you have passed the default CI.\n\nGitHub provides additional document on [forking a repository](https://help.github.com/articles/fork-a-repo/) and\n[creating a pull request](https://help.github.com/articles/creating-a-pull-request/).\n\n\n## Tips for Modifying the Source Code\n\n- Using a fresh virtualenv, install the package via [these instructions](https://auto.gluon.ai/dev/install.html).\nBe sure to select the *Source* option from the installation preferences.\n\n- We recommend developing on Linux as this is the only OS where all features are currently 100% functional. Avoid introducing changes that will only work on a particular OS, as we're currently working to support MacOSX and Windows. Changes to existing code that improve cross-platform compatibility are most welcome!\n\n- Use Python 3.8, 3.9, 3.10, or 3.11 for development, as these are the only versions where AutoGluon is fully functional.\n\n- Please try to avoid introducing additional dependencies on 3rd party packages. We are currently working to reduce the number of external dependencies of our package. For now, we recommend [lazy-import](https://github.com/autogluon/autogluon/blob/master/common/src/autogluon/common/utils/try_import.py) of external package if you are adding functionality that you believe will only be used by small fraction users.\n\n- All code should adhere to the [PEP8 style](https://www.python.org/dev/peps/pep-0008/).\n\n- After you have edited the code, ensure your changes pass the unit tests via:\n```\ncd common/\npytest\ncd ../core/\npytest\ncd ../features/\npytest\ncd ../tabular/\npytest\ncd ../multimodal/\npytest\ncd ../timeseries/\npytest\ncd ../eda/\nruff check --select I src tests && ruff format src tests && tox -e lint,format,typecheck,testenv\n```\n\n- We encourage you to add your own unit tests, but please ensure they run quickly (unit tests should train models on small data-subsample with the lowest values of training iterations and time-limits that suffice to evaluate the intended functionality). You can run a specific unit test within a specific file like this:\n```\npython3 -m pytest path_to_file::test_mytest\n```\nOr remove the ::test_mytest suffix to run all tests in the file:\n```\npython3 -m pytest path_to_file\n```\n\n- If using PyCharm, we highly recommend `pip install pytest-pycharm` to [improve ease of debugging inside of unit tests](https://stackoverflow.com/questions/14086067/debugging-pytest-post-mortem-exceptions-in-pycharm-pydev).\n\n- To otherwise test your code changes, we recommend running AutoGluon on multiple datasets and verifying the code runs correctly and the resulting accuracy of the trained models is not harmed by your change.  One easy way to test is to simply modify the scripts in [`examples/`](https://github.com/autogluon/autogluon/tree/master/examples), or the [tutorial notebooks](https://github.com/autogluon/autogluon/tree/master/docs/tutorials), which already provide datasets.\n\n- Remember to update all existing examples/tutorials/documentation affected by your code changes.\n\n- We also encourage you to contribute new tutorials or example scripts using AutoGluon for applications you think other users will be interested in. Please see [`docs/tutorials/`](https://github.com/autogluon/autogluon/tree/master/docs/tutorials) or [`examples/`](https://github.com/autogluon/autogluon/tree/master/examples). All tutorials should be Jupyter notebooks converted into markdown (.md) files by running the command `jupyter nbconvert --ClearOutputPreprocessor.enabled=True --to markdown tutorial.ipynb`. This command also clears out any output cells as our build system will rebuild the .ipynb files from the markdown file and execute the notebooks rendering the output on our website. This is especially important for major new functionality. You can also directly edit .md files in a Jupyter notebook via these steps: https://d2l.ai/chapter_appendix-tools-for-deep-learning/jupyter.html#markdown-files-in-jupyter\n\n- After you open your pull request, our CI system will run for little while to check your code and report found errors. Please check back and fix any errors encountered at this stage (you can retrigger a new CI check by pushing updated code to the same PR in a new commit).\n\n\n\n## Finding Contributions to Work On\nLooking at the existing issues is a great way to find something to contribute on. As our project uses the default GitHub issue labels (enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any ['help wanted'](https://github.com/autogluon/autogluon/labels/help%20wanted) issues is a great place to start.\n\n\n## Code of Conduct\nThis project has adopted the [Amazon Open Source Code of Conduct](https://aws.github.io/code-of-conduct).\nFor more information see the [Code of Conduct FAQ](https://aws.github.io/code-of-conduct-faq) or contact\nopensource-codeofconduct@amazon.com with any additional questions or comments.\n\n\n## Security Issue Notifications\nIf you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our [vulnerability reporting page](http://aws.amazon.com/security/vulnerability-reporting/). Please do **not** create a public github issue.\n\n\n## Licensing\n\nSee the [LICENSE](https://github.com/autogluon/autogluon/blob/master/LICENSE) file for our project's licensing. We will ask you to confirm the licensing of your contribution.\n\nWe may ask you to sign a [Contributor License Agreement (CLA)](http://en.wikipedia.org/wiki/Contributor_License_Agreement) for larger changes.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 9.904296875,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n"
        },
        {
          "name": "NOTICE",
          "type": "blob",
          "size": 0.111328125,
          "content": "AutoML for Text, Image, and Tabular Data\nCopyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved. \n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 9.2734375,
          "content": "\n\n<div align=\"center\">\n<img src=\"https://user-images.githubusercontent.com/16392542/77208906-224aa500-6aba-11ea-96bd-e81806074030.png\" width=\"350\">\n\n## Fast and Accurate ML in 3 Lines of Code\n\n[![Latest Release](https://img.shields.io/github/v/release/autogluon/autogluon)](https://github.com/autogluon/autogluon/releases)\n[![Conda Forge](https://img.shields.io/conda/vn/conda-forge/autogluon.svg)](https://anaconda.org/conda-forge/autogluon)\n[![Python Versions](https://img.shields.io/badge/python-3.9%20%7C%203.10%20%7C%203.11%20%7C%203.12-blue)](https://pypi.org/project/autogluon/)\n[![Downloads](https://pepy.tech/badge/autogluon/month)](https://pepy.tech/project/autogluon)\n[![GitHub license](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](./LICENSE)\n[![Discord](https://img.shields.io/discord/1043248669505368144?color=7289da&label=Discord&logo=discord&logoColor=ffffff)](https://discord.gg/wjUmjqAc2N)\n[![Twitter](https://img.shields.io/twitter/follow/autogluon?style=social)](https://twitter.com/autogluon)\n[![Continuous Integration](https://github.com/autogluon/autogluon/actions/workflows/continuous_integration.yml/badge.svg)](https://github.com/autogluon/autogluon/actions/workflows/continuous_integration.yml)\n[![Platform Tests](https://github.com/autogluon/autogluon/actions/workflows/platform_tests-command.yml/badge.svg?event=schedule)](https://github.com/autogluon/autogluon/actions/workflows/platform_tests-command.yml)\n\n[Installation](https://auto.gluon.ai/stable/install.html) | [Documentation](https://auto.gluon.ai/stable/index.html) | [Release Notes](https://auto.gluon.ai/stable/whats_new/index.html)\n\nAutoGluon automates machine learning tasks enabling you to easily achieve strong predictive performance in your applications.  With just a few lines of code, you can train and deploy high-accuracy machine learning and deep learning models on image, text, time series, and tabular data.\n</div>\n\n## 💾 Installation\n\nAutoGluon is supported on Python 3.9 - 3.12 and is available on Linux, MacOS, and Windows.\n\nYou can install AutoGluon with:\n\n```python\npip install autogluon\n```\n\nVisit our [Installation Guide](https://auto.gluon.ai/stable/install.html) for detailed instructions, including GPU support, Conda installs, and optional dependencies.\n\n## :zap: Quickstart\n\nBuild accurate end-to-end ML models in just 3 lines of code!\n\n```python\nfrom autogluon.tabular import TabularPredictor\npredictor = TabularPredictor(label=\"class\").fit(\"train.csv\")\npredictions = predictor.predict(\"test.csv\")\n```\n\n| AutoGluon Task      |                                                                                Quickstart                                                                                |                                                                                API                                                                                |\n|:--------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------:|\n| TabularPredictor    | [![Quick Start](https://img.shields.io/static/v1?label=&message=tutorial&color=grey)](https://auto.gluon.ai/stable/tutorials/tabular/tabular-quick-start.html) |                 [![API](https://img.shields.io/badge/api-reference-blue.svg)](https://auto.gluon.ai/stable/api/autogluon.tabular.TabularPredictor.html)                 |\n| MultiModalPredictor | [![Quick Start](https://img.shields.io/static/v1?label=&message=tutorial&color=grey)](https://auto.gluon.ai/stable/tutorials/multimodal/multimodal_prediction/multimodal-quick-start.html)            | [![API](https://img.shields.io/badge/api-reference-blue.svg)](https://auto.gluon.ai/stable/api/autogluon.multimodal.MultiModalPredictor.html) |\n| TimeSeriesPredictor | [![Quick Start](https://img.shields.io/static/v1?label=&message=tutorial&color=grey)](https://auto.gluon.ai/stable/tutorials/timeseries/forecasting-quick-start.html)            | [![API](https://img.shields.io/badge/api-reference-blue.svg)](https://auto.gluon.ai/stable/api/autogluon.timeseries.TimeSeriesPredictor.html) |\n\n## :mag: Resources\n\n### Hands-on Tutorials / Talks\n\nBelow is a curated list of recent tutorials and talks on AutoGluon. A comprehensive list is available [here](AWESOME.md#videos--tutorials).\n\n| Title                                                                                                                    | Format   | Location                                                                         | Date       |\n|--------------------------------------------------------------------------------------------------------------------------|----------|----------------------------------------------------------------------------------|------------|\n| :tv: [AutoGluon: Towards No-Code Automated Machine Learning](https://www.youtube.com/watch?v=SwPq9qjaN2Q)                | Tutorial | [AutoML 2024](https://2024.automl.cc/)                                           | 2024/09/09 |\n| :tv: [AutoGluon 1.0: Shattering the AutoML Ceiling with Zero Lines of Code](https://www.youtube.com/watch?v=5tvp_Ihgnuk) | Tutorial | [AutoML 2023](https://2023.automl.cc/)                                           | 2023/09/12 |\n| :sound: [AutoGluon: The Story](https://automlpodcast.com/episode/autogluon-the-story)                                    | Podcast  | [The AutoML Podcast](https://automlpodcast.com/)                                 | 2023/09/05 |\n| :tv: [AutoGluon: AutoML for Tabular, Multimodal, and Time Series Data](https://youtu.be/Lwu15m5mmbs?si=jSaFJDqkTU27C0fa) | Tutorial | PyData Berlin                                                                    | 2023/06/20 | \n| :tv: [Solving Complex ML Problems in a few Lines of Code with AutoGluon](https://www.youtube.com/watch?v=J1UQUCPB88I)    | Tutorial | PyData Seattle                                                                   | 2023/06/20 | \n| :tv: [The AutoML Revolution](https://www.youtube.com/watch?v=VAAITEds-28)                                                | Tutorial | [Fall AutoML School 2022](https://sites.google.com/view/automl-fall-school-2022) | 2022/10/18 |\n\n### Scientific Publications\n- [AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data](https://arxiv.org/pdf/2003.06505.pdf) (*Arxiv*, 2020) ([BibTeX](CITING.md#general-usage--autogluontabular))\n- [Fast, Accurate, and Simple Models for Tabular Data via Augmented Distillation](https://proceedings.neurips.cc/paper/2020/hash/62d75fb2e3075506e8837d8f55021ab1-Abstract.html) (*NeurIPS*, 2020) ([BibTeX](CITING.md#tabular-distillation))\n- [Benchmarking Multimodal AutoML for Tabular Data with Text Fields](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/9bf31c7ff062936a96d3c8bd1f8f2ff3-Paper-round2.pdf) (*NeurIPS*, 2021) ([BibTeX](CITING.md#autogluonmultimodal))\n- [XTab: Cross-table Pretraining for Tabular Transformers](https://proceedings.mlr.press/v202/zhu23k/zhu23k.pdf) (*ICML*, 2023)\n- [AutoGluon-TimeSeries: AutoML for Probabilistic Time Series Forecasting](https://arxiv.org/abs/2308.05566) (*AutoML Conf*, 2023) ([BibTeX](CITING.md#autogluontimeseries))\n- [TabRepo: A Large Scale Repository of Tabular Model Evaluations and its AutoML Applications](https://arxiv.org/pdf/2311.02971.pdf) (*Under Review*, 2024)\n\n### Articles\n- [AutoGluon-TimeSeries: Every Time Series Forecasting Model In One Library](https://towardsdatascience.com/autogluon-timeseries-every-time-series-forecasting-model-in-one-library-29a3bf6879db) (*Towards Data Science*, Jan 2024)\n- [AutoGluon for tabular data: 3 lines of code to achieve top 1% in Kaggle competitions](https://aws.amazon.com/blogs/opensource/machine-learning-with-autogluon-an-open-source-automl-library/) (*AWS Open Source Blog*, Mar 2020)\n- [AutoGluon overview & example applications](https://towardsdatascience.com/autogluon-deep-learning-automl-5cdb4e2388ec?source=friends_link&sk=e3d17d06880ac714e47f07f39178fdf2) (*Towards Data Science*, Dec 2019)\n\n### Train/Deploy AutoGluon in the Cloud\n- [AutoGluon Cloud](https://auto.gluon.ai/cloud/stable/index.html) (Recommended)\n- [AutoGluon on SageMaker AutoPilot](https://auto.gluon.ai/stable/tutorials/cloud_fit_deploy/autopilot-autogluon.html)\n- [AutoGluon on Amazon SageMaker](https://auto.gluon.ai/stable/tutorials/cloud_fit_deploy/cloud-aws-sagemaker-train-deploy.html)\n- [AutoGluon Deep Learning Containers](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#autogluon-training-containers) (Security certified & maintained by the AutoGluon developers)\n- [AutoGluon Official Docker Container](https://hub.docker.com/r/autogluon/autogluon)\n- [AutoGluon-Tabular on AWS Marketplace](https://aws.amazon.com/marketplace/pp/prodview-n4zf5pmjt7ism) (Not maintained by us)\n\n## :pencil: Citing AutoGluon\n\nIf you use AutoGluon in a scientific publication, please refer to our [citation guide](CITING.md).\n\n## :wave: How to get involved\n\nWe are actively accepting code contributions to the AutoGluon project. If you are interested in contributing to AutoGluon, please read the [Contributing Guide](https://github.com/autogluon/autogluon/blob/master/CONTRIBUTING.md) to get started.\n\n## :classical_building: License\n\nThis library is licensed under the Apache 2.0 License.\n"
        },
        {
          "name": "ROADMAP.md",
          "type": "blob",
          "size": 6.556640625,
          "content": "\n# AutoGluon Roadmap 2023\n\nIn 2023, our top priorities are:\n\n- [ ] Meta-Learning\n- [ ] Pre-Training\n- [ ] Exploratory Data Analysis\n- [ ] Enhanced Cloud Integration\n- [ ] Website Overhaul\n- [ ] Documentation & Tutorial Overhaul\n- [ ] Model Fairness Analysis\n- [ ] Enhanced Model Distillation\n- [ ] Model Compilation & Optimization\n- [ ] Distributed Model Training\n- [ ] Distributed Hyperparameter Tuning\n- [ ] Improved Large-scale Data Handling (100M+ Rows)\n- [ ] Improved Feature Type Inference\n- [ ] Enhanced Tabular GPU Support\n- [ ] Co-variate Shift Detection\n- [ ] Co-variate Shift Correction\n- [ ] Model Interpretability\n- [ ] Model Uncertainty\n- [ ] Model Monitoring\n- [ ] Advanced Custom Model Tutorial\n\n# AutoGluon Roadmap 2022\n\nIn 2022, our top priorities are:\n\n- [x] (v0.4) Windows OS Support\n- [x] (v0.4) Python 3.9 Support\n- [x] (v0.5) Time-Series Support (autogluon.timeseries)\n- [x] (v0.4) HuggingFace Integration\n- [x] (v0.5) TIMM Integration\n- [x] (v0.5) Improved Multi-modal Modeling (autogluon.multimodal)\n- [x] (v0.4) Cloud Training & Deployment\n- [x] (v0.4) Parallel Model Training\n- [x] (v0.6) Parallel Hyperparameter Tuning\n- [x] (v0.4) Semi-supervised Learning\n- [x] (v0.4) Automated Model Calibration via Temperature Scaling\n- [x] (v0.4) Online Inference Optimization\n- [x] (v0.5) Improved Large-scale Data Handling (10M+ Rows)\n- [x] (v0.6) Faster Feature Preprocessing\n- [x] (v0.6) Image Model Inference Optimization\n- [x] (v0.6) Text Model Inference Optimization\n\n## AutoGluon 0.6 Features, Released: November 2022\n\n[v0.6 Release Notes](https://github.com/autogluon/autogluon/releases/tag/v0.6.0)\n\n### Themes and Major Features\n\n- [x] Named Entity Recognition Support\n- [x] Object Detection Support in autogluon.multimodal\n- [x] Multimodal Matching Support\n- [x] Parallel Hyperparameter Tuning\n- [x] Image Model Inference Optimization (~10x faster for online inference)\n- [x] Text Model Inference Optimization (~10x faster for online inference)\n- [x] FT-Transformer model to Tabular\n- [x] Faster Feature Preprocessing (~25%)\n- [x] Few-shot learning with 11B-scale models on single GPU\n- [x] Prototype model compilation support to Tabular\n\n## AutoGluon 0.5 Features, Released: June 2022\n\n[v0.5 Release Notes](https://github.com/autogluon/autogluon/releases/tag/v0.5.0)\n\n### Themes and Major Features\n\n- [x] Time-Series Support (autogluon.timeseries)\n- [x] Improved Multi-modal Modeling (autogluon.multimodal)\n- [x] TIMM Integration\n- [x] imodels Integration\n\n## AutoGluon 0.4 Features, Released: March 2022\n\n[v0.4 Release Notes](https://github.com/autogluon/autogluon/releases/tag/v0.4.0)\n\n### Themes and Major Features\n\n- [x] Windows OS Support\n- [x] Python 3.9 Support\n- [x] HuggingFace Integration\n- [x] Torch Migration (Remove MXNet dependency)\n- [x] Parallel Model Training (2x training speed-up for bagging/stacking)\n- [x] Automated Feature Pruning/Selection\n- [x] Semi-supervised & Transductive Learning Support\n- [x] Automated Model Calibration via Temperature Scaling\n- [x] Cloud Training & Deployment Tutorials\n- [x] Feature Preprocessing Tutorial\n- [x] Documentation Overhaul\n- [x] Hyperparameter Tuning Overhaul\n- [x] Memory Usage Optimizations\n- [x] Various Performance Optimizations\n- [x] Various Bug Fixes\n\n# AutoGluon Roadmap 2021\n\nIn 2021, our top priorities are:\n\n- [x] Make AutoGluon the most versatile AutoML framework via dedicated multi-modal image-text-tabular support ([paper](https://arxiv.org/abs/2111.02705)).\n- [x] Modularization of the various components of AutoGluon.\n- [x] Model Training Speed Optimizations.\n- [x] Model Inference Speed Optimizations.\n- [x] Model Quality Optimizations.\n- [x] Integration with [NVIDIA RAPIDS](https://developer.nvidia.com/rapids) for accelerated GPU training.\n- [x] Integration with [Intel sklearnex](https://github.com/intel/scikit-learn-intelex) for accelerated CPU training.\n- [x] Improved documentation and tutorials.\n- [x] Training and Inference containers.\n\n### AutoGluon 0.3.1 Features, Released: August 2021\n\n[Release Notes](https://github.com/autogluon/autogluon/releases/tag/v0.3.1)\n\n### AutoGluon 0.3 Features, Released: August 2021\n\n[Release Notes](https://github.com/autogluon/autogluon/releases/tag/v0.3.0)\n\n### AutoGluon 0.2 Features, Released: April 2021\n\n[Release Notes](https://github.com/autogluon/autogluon/releases/tag/v0.2.0)\n\n### AutoGluon 0.1 Features, Released: March 2021\n\n[Release Notes](https://github.com/autogluon/autogluon/releases/tag/v0.1.0)\n\n# AutoGluon Roadmap 2020\n\nIn 2020, we plan to focus on improving code quality, extensibility, and robustness of the package.\n\nWe will work towards unifying the APIs of the separate tasks (Tabular, Image, Text) to simplify and streamline development and improve the user experience.\n\n### 2020 Releases\n\n- [v0.0.15 Release Notes](https://github.com/autogluon/autogluon/releases/tag/v0.0.15) (December 2020)\n- [v0.0.14 Release Notes](https://github.com/autogluon/autogluon/releases/tag/v0.0.14) (October 2020, Highlight: Added FastAI Neural Network Model)\n- [v0.0.13 Release Notes](https://github.com/autogluon/autogluon/releases/tag/v0.0.13) (August 2020, Highlight: Added model distillation ([paper](https://arxiv.org/abs/2006.14284)))\n- [v0.0.12 Release Notes](https://github.com/autogluon/autogluon/releases/tag/v0.0.12) (July 2020, Highlight: Added custom model support)\n- [v0.0.11 Release Notes](https://github.com/autogluon/autogluon/releases/tag/v0.0.11) (June 2020)\n- [v0.0.10 Release Notes](https://github.com/autogluon/autogluon/releases/tag/v0.0.10) (June 2020, Highlight: Implemented feature importance)\n- [v0.0.9 Release Notes](https://github.com/autogluon/autogluon/releases/tag/v0.0.9) (May 2020)\n- [v0.0.8 Release Notes](https://github.com/autogluon/autogluon/releases/tag/v0.0.8) (May 2020)\n- [v0.0.7 Release Notes](https://github.com/autogluon/autogluon/releases/tag/v0.0.7) (May 2020, Highlight: first addition of the `presets` argument)\n- [v0.0.6 Release Notes](https://github.com/autogluon/autogluon/releases/tag/v0.0.6) (March 2020, first release tagged on GitHub with release notes)\n- [v0.0.5 Release](https://pypi.org/project/autogluon/0.0.5/) (February 2020, used in the original [AutoGluon-Tabular paper](https://arxiv.org/abs/2003.06505))\n- [v0.0.4 Release](https://pypi.org/project/autogluon/0.0.4/) (January 2020)\n\n# AutoGluon Roadmap 2019\n\nIn 2019, we plan to release the initial open source version of AutoGluon, featuring Tabular, Text, and Image classification and regression tasks, along with Object Detection.\n\n### 2019 Releases\n\n- [v0.0.3 Release](https://pypi.org/project/autogluon/0.0.3/) (December 2019)\n- [v0.0.2 Release](https://pypi.org/project/autogluon/0.0.2/) (December 2019, Initial Open Source Release)\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.751953125,
          "content": "# Security Policy\n\n## Supported Versions\n\n| Version       | Supported          |\n| ------------- | ------------------ |\n| 1.1.1         | :white_check_mark: |\n| < 1.1.1       | :x:                |\n\n## How we do security\n\n\nAs much as possible, AutoGluon relies on automated tools to do security scanning. In particular, we support:\n\n1. Dependency Analysis: Using Dependabot\n2. Docker Scanning: Using Snyk\n3. Code Analysis: Using CodeGuru\n\n\n## Reporting a Vulnerability\n\nReport any security vulnerabilities to `autogluon-security@amazon.com`. This email directly links to the Autogluon security maintenance team. Once the security vulnerability is confirmed, we will work privately on a patch, aiming to produce a dedicated bugfix release as swiftly as complexity allows."
        },
        {
          "name": "VERSION",
          "type": "blob",
          "size": 0.0048828125,
          "content": "1.2.1"
        },
        {
          "name": "autogluon",
          "type": "tree",
          "content": null
        },
        {
          "name": "common",
          "type": "tree",
          "content": null
        },
        {
          "name": "core",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "eda",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "features",
          "type": "tree",
          "content": null
        },
        {
          "name": "full_install.bat",
          "type": "blob",
          "size": 0.3134765625,
          "content": "\npython -m pip install -e common/[tests]\npython -m pip install -e core/[all,tests]\npython -m pip install -e features/\npython -m pip install -e tabular/[all,tests]\npython -m pip install -e multimodal/[tests]\npython -m pip install -e timeseries/[all,tests]\npython -m pip install -e eda/\npython -m pip install -e autogluon/\n"
        },
        {
          "name": "full_install.sh",
          "type": "blob",
          "size": 1.1064453125,
          "content": "#!/usr/bin/env bash\nset -euo pipefail\n\nEDITABLE=\"true\"\n\nwhile test $# -gt 0\ndo\n    case \"$1\" in\n        --non-editable) EDITABLE=\"false\";;\n        *) echo \"Error: Unused argument: $1\" >&2\n           exit 1;;\n    esac\n    shift\ndone\n\n# Check if uv is installed\nif ! python -m pip show uv &> /dev/null; then\n    echo \"uv could not be found. Installing uv...\"\n    python -m pip install uv\nfi\n\n# Use uv to install packages\n# TODO: We should simplify this by having a single setup.py at project root, and let user call `pip install -e .`\nif [ \"$EDITABLE\" == \"true\" ]; then\n  # install common first to avoid bugs with parallelization\n  python -m uv pip install --refresh -e common/[tests]\n\n  # install the rest\n  python -m uv pip install -e core/[all,tests] -e features/ -e tabular/[all,tests] -e multimodal/[tests] -e timeseries/[all,tests] -e eda/ -e autogluon/\n\nelse\n  # install common first to avoid bugs with parallelization\n  python -m uv pip install --refresh common/[tests]\n\n  # install the rest\n  python -m uv pip install core/[all,tests] features/ tabular/[all,tests] multimodal/[tests] timeseries/[all,tests] eda/ autogluon/\nfi\n"
        },
        {
          "name": "multimodal",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.9072265625,
          "content": "[tool.ruff]\nline-length = 119\ntarget-version = \"py38\"\nextend-exclude = [\"__init__.py\"]\nlint.ignore = [\n    \"E501\",  # Line too long\n    \"E731\",  # Do not assign a `lambda` expression, use a `def`\n    \"E722\",  # Do not use bare `except`\n]\nlint.isort.known-first-party = [\"autogluon\"]\nlint.isort.known-third-party = [\n    \"gluonts\",\n    \"mxnet\",\n    \"networkx\",\n    \"numpy\",\n    \"pandas\",\n    \"psutil\",\n    \"pytest\",\n    \"scipy\",\n    \"sklearn\",\n    \"sktime\",\n    \"statsmodels\",\n    \"tqdm\",\n    \"Pillow\",\n    \"boto3\",\n    \"requests\",\n    \"timm\",\n    \"torch\",\n    \"torchvision\",\n    \"fairscale\",\n    \"scikit-image\",\n    \"smart_open\",\n    \"lightning\",\n    \"torchmetrics\",\n    \"transformers\",\n    \"nptyping\",\n    \"omegaconf\",\n    \"pytorch-metric-learning\",\n    \"nlpaug\",\n    \"nltk\",\n]\n\n\n[tool.codespell]\nskip = '.git,*.pdf,*.svg,*.ipynb,*.csv,kaggle_feedback_prize'\n#\nignore-words-list = 'mape,ans,2st,fo,nd,te,fpr,coo,rouge,SME,NoES'\n"
        },
        {
          "name": "release_instructions",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.1083984375,
          "content": "[pycodestyle]\nmax_line_length = 160\n\n[flake8]\nmax-line-length = 160\nper-file-ignores =\n    */__init__.py: F401\n"
        },
        {
          "name": "tabular",
          "type": "tree",
          "content": null
        },
        {
          "name": "timeseries",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}