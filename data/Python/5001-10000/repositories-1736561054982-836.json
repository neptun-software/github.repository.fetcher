{
  "metadata": {
    "timestamp": 1736561054982,
    "page": 836,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjg0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "mdbloice/Augmentor",
      "stars": 5090,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.033203125,
          "content": "*.ipynb linguist-detectable=false\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.2724609375,
          "content": "# OS generated files #\n######################\n.DS_Store\n.DS_Store?\n._*\n.Spotlight-V100\n.Trashes\nehthumbs.db\nThumbs.db\n# My additions\n*.pyc\n*.egg\n*.egg-info\n.idea/\ndist/\ndata/\nbuild/\nback/\n.cache/\n.pytest_cache/\n.tox/\n_build/\n_static/\n_templates/\n__pycache__/\n.ipynb_checkpoints/\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.8984375,
          "content": "language: python\nos:\n  - linux\npython:\n  - \"2.7\"\n  - \"3.5\"\n  - \"3.6\"\n  - \"3.7\"\n# command to install dependencies\ninstall:\n  # Install conda.\n  - if [[ \"$TRAVIS_PYTHON_VERSION\" == \"2.7\" ]]; then\n      wget https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh -O miniconda.sh;\n    else\n      wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh;\n    fi\n  - bash miniconda.sh -b -p $HOME/miniconda\n  - export OPATH=\"$PATH\" && export PATH=\"$HOME/miniconda/bin:$PATH\"\n  - conda create -q -y -n test-environment python=$TRAVIS_PYTHON_VERSION pytest\n  - source activate test-environment\n  # Attempt to install torchvision; on failure, revert back to pre-conda environment.\n  - conda install -q -y torchvision -c soumith || export PATH=\"$OPATH\"\n  # Install pandas\n  - conda install -q -y pandas\n  - pip install -r requirements.txt\n# command to run tests\nscript: py.test -v\n"
        },
        {
          "name": "Augmentor",
          "type": "tree",
          "content": null
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 0.232421875,
          "content": "# Contributing to Augmentor\n\nThanks for your interest in Augmentor.\n\nFor guidelines on how to contribute, either by fixing bugs through pull requests or filing bug reports, see [contribution-guide.org](http://www.contribution-guide.org/)!"
        },
        {
          "name": "DESCRIPTION.rst",
          "type": "blob",
          "size": 0.1298828125,
          "content": "Augmentor\n=========\n\nAn image augmentation library for machine learning. See `<http://augmentor.readthedocs.io/>`_ for documentation."
        },
        {
          "name": "LICENSE.md",
          "type": "blob",
          "size": 1.0478515625,
          "content": "MIT License\n\nCopyright (c) 2016 Marcus D. Bloice\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.0361328125,
          "content": "include README.md\ninclude LICENSE.md\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 24.4013671875,
          "content": "![AugmentorLogo](https://github.com/mdbloice/AugmentorFiles/blob/master/Misc/AugmentorLogo.png)\n\nAugmentor is an image augmentation library in Python for machine learning. It aims to be a standalone library that is platform and framework independent, which is more convenient, allows for finer grained control over augmentation, and implements the most real-world relevant augmentation techniques. It employs a stochastic approach using building blocks that allow for operations to be pieced together in a pipeline.\n\n[![PyPI](https://img.shields.io/badge/Augmentor-v0.2.10-blue.svg?maxAge=2592000)](https://pypi.python.org/pypi/Augmentor)\n[![Supported Python Versions](https://img.shields.io/badge/python-2.7%20%7C%203.5%20%7C%203.6%20%7C%203.7%20%7C%203.8%20%7C%203.9-blue.svg)](https://pypi.python.org/pypi/Augmentor)\n[![PyPI Install](https://github.com/mdbloice/Augmentor/actions/workflows/PyPI.yml/badge.svg)](https://github.com/mdbloice/Augmentor/actions/workflows/PyPI.yml)\n[![Pytest](https://github.com/mdbloice/Augmentor/actions/workflows/package-tests.yml/badge.svg)](https://github.com/mdbloice/Augmentor/actions/workflows/package-tests.yml)\n[![Documentation Status](https://readthedocs.org/projects/augmentor/badge/?version=master)](https://augmentor.readthedocs.io/en/master/?badge=master)\n[![License](http://img.shields.io/badge/license-MIT-brightgreen.svg?style=flat)](LICENSE.md)\n[![Project Status: Active â€“ The project has reached a stable, usable state and is being actively developed.](http://www.repostatus.org/badges/latest/active.svg)](http://www.repostatus.org/#active)\n[![Binder](https://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/4QuantOSS/Augmentor/master)\n\n## Installation\n\nAugmentor is written in Python. A Julia version of the package is also being developed as a sister project and is available [here](https://github.com/Evizero/Augmentor.jl).\n\nInstall using `pip` from the command line:\n\n```python\npip install Augmentor\n```\n\nSee the documentation for building from source. To upgrade from a previous version, use `pip install Augmentor --upgrade`.\n\n## Documentation\n\nComplete documentation can be found on Read the Docs: [https://augmentor.readthedocs.io](https://augmentor.readthedocs.io/en/stable/)\n\n## Quick Start Guide and Usage\nThe purpose of _Augmentor_ is to automate image augmentation (artificial data generation) in order to expand datasets as input for machine learning algorithms, especially neural networks and deep learning.\n\nThe package works by building an augmentation **pipeline** where you define a series of operations to perform on a set of images. Operations, such as rotations or transforms, are added one by one to create an augmentation pipeline: when complete, the pipeline can be executed and an augmented dataset is created.\n\nTo begin, instantiate a `Pipeline` object that points to a directory on your file system:\n\n```python\nimport Augmentor\np = Augmentor.Pipeline(\"/path/to/images\")\n```\n\nYou can then add operations to the Pipeline object `p` as follows:\n\n```python\np.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\np.zoom(probability=0.5, min_factor=1.1, max_factor=1.5)\n```\n\nEvery function requires you to specify a probability, which is used to decide if an operation is applied to an image as it is passed through the augmentation pipeline.\n\nOnce you have created a pipeline, you can sample from it like so:\n\n```python\np.sample(10000)\n```\n\nwhich will generate 10,000 augmented images based on your specifications. By default these will be written to the disk in a directory named `output` relative to the path specified when initialising the `p` pipeline object above.\n\nIf you wish to process each image in the pipeline exactly once, use `process()`:\n\n```python\np.process()\n```\n\nThis function might be useful for resizing a dataset for example. It would make sense to create a pipeline where all of its operations have their probability set to `1` when using the `process()` method.\n\n### Multi-threading\n\nAugmentor (version >=0.2.1) now uses multi-threading to increase the speed of generating images.\n\nThis *may* slow down some pipelines if the original images are very small. Set `multi_threaded` to ``False`` if slowdown is experienced:\n\n```python\np.sample(100, multi_threaded=False)\n```\n\nHowever, by default the `sample()` function uses multi-threading. This is currently only implemented when saving to disk. Generators will use multi-threading in the next version update.\n\n\n### Ground Truth Data\n\nImages can be passed through the pipeline in groups of two or more so that ground truth data can be identically augmented.\n\n| Original image and mask<sup>[3]</sup>                                                                               | Augmented original and mask images                                                                               |\n|---------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------|\n| ![OriginalMask](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/original-with-mask.png) | ![AugmentedMask](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/ground-truth.gif)   |\n\nTo augment ground truth data in parallel to any original data, add a ground truth directory to a pipeline using the [ground_truth()](https://augmentor.readthedocs.io/en/master/code.html#Augmentor.Pipeline.Pipeline.ground_truth) function:\n\n```python\np = Augmentor.Pipeline(\"/path/to/images\")\n# Point to a directory containing ground truth data.\n# Images with the same file names will be added as ground truth data\n# and augmented in parallel to the original data.\np.ground_truth(\"/path/to/ground_truth_images\")\n# Add operations to the pipeline as normal:\np.rotate(probability=1, max_left_rotation=5, max_right_rotation=5)\np.flip_left_right(probability=0.5)\np.zoom_random(probability=0.5, percentage_area=0.8)\np.flip_top_bottom(probability=0.5)\np.sample(50)\n```\n\n### Multiple Mask/Image Augmentation\n\nUsing the `DataPipeline` class (Augmentor version >= 0.2.3), images that have multiple associated masks can be augmented:\n\n| Multiple Mask Augmentation                                                                               |\n|----------------------------------------------------------------------------------------------------------|\n| ![MultipleMask](https://github.com/mdbloice/AugmentorFiles/blob/master/UsageGuide/merged-multi-mask.gif) |\n\nArbitrarily long lists of images can be passed through the pipeline in groups and augmented identically using the `DataPipeline` class. This is useful for ground truth images that have several masks, for example.\n\nIn the example below, the images and their masks are contained in the `images` data structure (as lists of lists), while their labels are contained in `y`:\n\n```python\np = Augmentor.DataPipeline(images, y)\np.rotate(1, max_left_rotation=5, max_right_rotation=5)\np.flip_top_bottom(0.5)\np.zoom_random(1, percentage_area=0.5)\n\naugmented_images, labels = p.sample(100)\n```\n\nThe `DataPipeline` returns images directly (`augmented_images` above), and does not save them to disk, nor does it read data from the disk. Images are passed directly to `DataPipeline` during initialisation.\n\nFor details of the `images` data structure and how to create it, see the [`Multiple-Mask-Augmentation.ipynb`](https://github.com/mdbloice/Augmentor/blob/master/notebooks/Multiple-Mask-Augmentation.ipynb) Jupyter notebook.\n\n### Generators for Keras and PyTorch\n\nIf you do not wish to save to disk, you can use a generator (in this case with Keras):\n\n```python\ng = p.keras_generator(batch_size=128)\nimages, labels = next(g)\n```\n\nwhich returns a batch of images of size 128 and their corresponding labels. Generators return data indefinitely, and can be used to train neural networks with augmented data on the fly.\n\nAlternatively, you can integrate it with PyTorch:\n\n```python\nimport torchvision\ntransforms = torchvision.transforms.Compose([\n    p.torch_transform(),\n    torchvision.transforms.ToTensor(),\n])\n```\n\n## Main Features\n\n### Elastic Distortions\n\nUsing elastic distortions, one image can be used to generate many images that are real-world feasible and label preserving:\n\n| Input Image                                                                                                                       |   | Augmented Images                                                                                                        |\n|-----------------------------------------------------------------------------------------------------------------------------------|---|-------------------------------------------------------------------------------------------------------------------------|\n| ![eight_hand_drawn_border](https://cloud.githubusercontent.com/assets/16042756/23697279/79850d52-03e7-11e7-9445-475316b702a3.png) | â†’ | ![eights_border](https://cloud.githubusercontent.com/assets/16042756/23697283/802698a6-03e7-11e7-94b7-f0b61977ef33.gif) |\n\nThe input image has a 1 pixel black border to emphasise that you are getting distortions without changing the size or aspect ratio of the original image, and without any black/transparent padding around the newly generated images.\n\nThe functionality can be more clearly seen here:\n\n| Original Image<sup>[1]</sup>                                                                      | Random distortions applied                                                                            |\n|---------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------|\n| ![Original](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/orig.png) | ![Distorted](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/distort.gif) |\n\n### Perspective Transforms\n\nThere are a total of 12 different types of perspective transform available. Four of the most common are shown below.\n\n| Tilt Left                                                                                               | Tilt Right                                                                                               | Tilt Forward                                                                                               | Tilt Backward                                                                                               |\n|---------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------|\n| ![TiltLeft](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/TiltLeft_s.png) | ![Original](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/TiltRight_s.png) | ![Original](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/TiltForward_s.png) | ![Original](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/TiltBackward_s.png) |\n\nThe remaining eight types of transform are as follows:\n\n| Skew Type 0                                                                                         | Skew Type 1                                                                                         | Skew Type 2                                                                                         | Skew Type 3                                                                                         |\n|-----------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------|\n| ![Skew0](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/Corner0_s.png) | ![Skew1](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/Corner1_s.png) | ![Skew2](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/Corner2_s.png) | ![Skew3](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/Corner3_s.png) |\n\n| Skew Type 4                                                                                         | Skew Type 5                                                                                         | Skew Type 6                                                                                         | Skew Type 7                                                                                         |\n|-----------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------|\n| ![Skew4](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/Corner4_s.png) | ![Skew5](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/Corner5_s.png) | ![Skew6](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/Corner6_s.png) | ![Skew7](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/Corner7_s.png) |\n\n### Size Preserving Rotations\n\nRotations by default preserve the file size of the original images:\n\n| Original Image                                                                                    | Rotated 10 degrees, automatically cropped                                                               |\n|---------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------|\n| ![Original](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/orig.png) | ![Rotate](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/rotate_aug_b.png) |\n\nCompared to rotations by other software:\n\n| Original Image                                                                                    | Rotated 10 degrees                                                                                |\n|---------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------|\n| ![Original](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/orig.png) | ![Rotate](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/rotate.png) |\n\n### Size Preserving Shearing\n\nShearing will also automatically crop the correct area from the sheared image, so that you have an image with no black space or padding.\n\n| Original image                                                                                    | Shear (x-axis) 20 degrees                                                                              | Shear (y-axis) 20 degrees                                                                              |\n|---------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------|\n| ![Original](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/orig.png) | ![ShearX](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/shear_x_aug.png) | ![ShearY](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/shear_y_aug.png) |\n\nCompare this to how this is normally done:\n\n| Original image                                                                                    | Shear (x-axis) 20 degrees                                                                          | Shear (y-axis) 20 degrees                                                                          |\n|---------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|\n| ![Original](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/orig.png) | ![ShearX](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/shear_x.png) | ![ShearY](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/shear_y.png) |\n\n### Cropping\n\nCropping can also be handled in a manner more suitable for machine learning image augmentation:\n\n| Original image                                                                                    | Random crops + resize operation                                                                          |\n|---------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------|\n| ![Original](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/orig.png) | ![Original](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/crop_resize.gif) |\n\n### Random Erasing\n\nRandom Erasing is a technique used to make models robust to occlusion. This may be useful for training neural networks used in object detection in navigation scenarios, for example.\n\n| Original image<sup>[2]</sup>                                                                                               | Random Erasing                                                                                                                        |\n|----------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------|\n| ![Original](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/city-road-street-italy-scaled.jpg) | ![Original](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/city-road-street-italy-animation.gif) |\n\nSee the [Pipeline.random_erasing()](https://augmentor.readthedocs.io/en/stable/code.html#Augmentor.Pipeline.Pipeline.random_erasing) documentation for usage.\n\n### Chaining Operations in a Pipeline\n\nWith only a few operations, a single image can be augmented to produce large numbers of new, label-preserving samples:\n\n| Original image                                                                                           | Distortions + mirroring                                                                                          |\n|----------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------|\n| ![Original](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/eight_200px.png) | ![DistortFlipFlop](https://raw.githubusercontent.com/mdbloice/AugmentorFiles/master/UsageGuide/flip_distort.gif) |\n\nIn the example above, we have applied three operations: first we randomly distort the image, then we flip it horizontally with a probability of 0.5 and then vertically with a probability of 0.5. We then sample from this pipeline 100 times to create 100 new data.\n\n```python\np.random_distortion(probability=1, grid_width=4, grid_height=4, magnitude=8)\np.flip_left_right(probability=0.5)\np.flip_top_bottom(probability=0.5)\np.sample(100)\n```\n\n## Tutorial Notebooks\n\n### Integration with Keras using Generators\nAugmentor can be used as a replacement for Keras' augmentation functionality. Augmentor can create a generator which produces augmented data indefinitely, according to the pipeline you have defined. See the following notebooks for details:\n\n- Reading images from a local directory, augmenting them at run-time, and using a generator to pass the augmented stream of images to a Keras convolutional neural network, see [`Augmentor_Keras.ipynb`](https://github.com/mdbloice/Augmentor/blob/master/notebooks/Augmentor_Keras.ipynb)\n- Augmenting data in-memory (in array format) and using a generator to pass these new images to the Keras neural network, see [`Augmentor_Keras_Array_Data.ipynb`](https://github.com/mdbloice/Augmentor/blob/master/notebooks/Augmentor_Keras_Array_Data.ipynb)\n\n### Per-Class Augmentation Strategies\nAugmentor allows for pipelines to be defined per class. That is, you can define different augmentation strategies on a class-by-class basis for a given classification problem.\n\nSee an example of this in the following Jupyter notebook: [`Per_Class_Augmentation_Strategy.ipynb`](https://github.com/mdbloice/Augmentor/blob/master/notebooks/Per_Class_Augmentation_Strategy.ipynb)\n\n## Complete Example\n\nLet's perform an augmentation task on a single image, demonstrating the pipeline and several features of Augmentor.\n\nFirst import the package and initialise a Pipeline object by pointing it to a directory containing your images:\n\n```python\nimport Augmentor\n\np = Augmentor.Pipeline(\"/home/user/augmentor_data_tests\")\n```\n\nNow you can begin adding operations to the pipeline object:\n\n```python\np.rotate90(probability=0.5)\np.rotate270(probability=0.5)\np.flip_left_right(probability=0.8)\np.flip_top_bottom(probability=0.3)\np.crop_random(probability=1, percentage_area=0.5)\np.resize(probability=1.0, width=120, height=120)\n```\n\nOnce you have added the operations you require, you can sample images from this pipeline:\n\n```python\np.sample(100)\n```\n\nSome sample output:\n\n| Input Image<sup>[3]</sup>                                                                                          |   | Augmented Images                                                                                                    |\n|--------------------------------------------------------------------------------------------------------------------|---|---------------------------------------------------------------------------------------------------------------------|\n| ![Original](https://cloud.githubusercontent.com/assets/16042756/23019262/b696e3a6-f441-11e6-958d-17f18f2cd35e.jpg) | â†’ | ![Augmented](https://cloud.githubusercontent.com/assets/16042756/23018832/cda6967e-f43f-11e6-9082-765c291f1fd6.gif) |\n\nThe augmented images may be useful for a boundary detection task, for example.\n\n## Licence and Acknowledgements\n\nAugmentor is made available under the terms of the MIT Licence. See [`Licence.md`](https://github.com/mdbloice/Augmentor/blob/master/LICENSE.md).\n\n[1] Checkerboard image obtained from Wikimedia Commons and is in the public domain: <https://commons.wikimedia.org/wiki/File:Checkerboard_pattern.svg>\n\n[2] Street view image is in the public domain: <http://stokpic.com/project/italian-city-street-with-shoppers/>\n\n[3] Skin lesion image obtained from the ISIC Archive:\n\n- Image id = 5436e3abbae478396759f0cf\n- Download: <https://isic-archive.com:443/api/v1/image/5436e3abbae478396759f0cf/download>\n\nYou can use `urllib` to obtain the skin lesion image in order to reproduce the augmented images above:\n\n```python\n>>> from urllib import urlretrieve\n>>> im_url = \"https://isic-archive.com:443/api/v1/image/5436e3abbae478396759f0cf/download\"\n>>> urlretrieve(im_url, \"ISIC_0000000.jpg\")\n('ISIC_0000000.jpg', <httplib.HTTPMessage instance at 0x7f7bd949a950>)\n```\n\nNote: For Python 3, use `from urllib.request import urlretrieve`.\n\nLogo created at [LogoMakr.com](https://logomakr.com)\n\n## Tests\nTo run the automated tests, clone the repository and run:\n\n```bash\n$ py.test -v\n```\n\nfrom the command line. To view the CI tests that are run after each commit, see <https://travis-ci.org/mdbloice/Augmentor>.\n\n## Asciicast\n\nClick the preview below to view a video demonstration of Augmentor in use:\n\n[![asciicast](https://asciinema.org/a/105368.png)](https://asciinema.org/a/105368?autoplay=1&speed=3)\n"
        },
        {
          "name": "binder",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "notebooks",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements-dev.txt",
          "type": "blob",
          "size": 0.0244140625,
          "content": "Pillow\ntqdm\nnumpy\npytest\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.0166015625,
          "content": "Pillow\ntqdm\nnumpy"
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.0625,
          "content": "[bdist_wheel]\nuniversal=1\n\n[metadata]\nlicense_file = LICENSE.md\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 1.685546875,
          "content": "from setuptools import setup\n\nsetup(\n    name='Augmentor',\n    packages=['Augmentor'],\n    version='0.2.12',\n    description='Image augmentation library for Machine Learning',\n    long_description='Image augmentation library for Machine Learning',\n    license='MIT',\n    author='Marcus D. Bloice',\n    author_email='marcus.bloice@medunigraz.at',\n    url='https://github.com/mdbloice/Augmentor',                            # URL to GitHub repo\n    # download_url='https://github.com/mdbloice/Augmentor/tarball/0.1.1',   # Get this using git tag\n    keywords=['image', 'augmentation', 'artificial', 'generation', 'machine', 'learning'],\n    include_package_data=True,  # This will include all files in MANIFEST.in in the package when installing.\n    classifiers=[\n        'Development Status :: 5 - Production/Stable',\n        'Intended Audience :: Developers',\n        'Natural Language :: English',\n        'License :: OSI Approved :: MIT License',\n        'Operating System :: OS Independent',\n        'Programming Language :: Python',\n        'Programming Language :: Python :: 2',\n        'Programming Language :: Python :: 2.7',\n        'Programming Language :: Python :: 3',\n        'Programming Language :: Python :: 3.5',\n        'Programming Language :: Python :: 3.6',\n        'Programming Language :: Python :: 3.7',\n        'Programming Language :: Python :: 3.8',\n        'Programming Language :: Python :: 3.9',\n        'Topic :: Software Development :: Libraries :: Python Modules',\n    ],\n    install_requires=[\n        'Pillow>=5.2.0',\n        'tqdm>=4.9.0',\n        #'future>=0.16.0',\n        'numpy>=1.11.0',\n        'futures>=3.2.0; python_version == \"2.7\"'\n    ]\n    # zip_safe=False # Check this later.\n)\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}