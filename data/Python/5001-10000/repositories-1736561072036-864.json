{
  "metadata": {
    "timestamp": 1736561072036,
    "page": 864,
    "hasNextPage": false,
    "endCursor": "Y3Vyc29yOjg2OA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "HIT-SCIR/ltp",
      "stars": 5014,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".config",
          "type": "tree",
          "content": null
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 2.1435546875,
          "content": "/data\n/target\nCargo.lock\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\npip-wheel-metadata/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n.python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n### VisualStudioCode\n.vscode/*\n!.vscode/settings.json\n!.vscode/tasks.json\n!.vscode/launch.json\n!.vscode/extensions.json\n*.code-workspace\n**/.vscode\n\n# JetBrains\n.idea/\n\n# Lightning-Hydra-Template\npython/core/configs/local/default.yaml\npython/core/data/\npython/core/logs/\npython/core/wandb/\npython/core/.env\npython/core/.autoenv\n\n.DS_Store\n/bindings\n/python/interface/models\n"
        },
        {
          "name": ".ruff.toml",
          "type": "blob",
          "size": 0.359375,
          "content": "# Enable flake8-bugbear (`B`) rules.\nselect = [\"E\", \"F\", \"B\"]\n\n# Never enforce `E501` (line length violations).\nignore = [\"E501\"]\n\n# Avoid trying to fix flake8-bugbear (`B`) violations.\nunfixable = [\"B\"]\n\n# Ignore `E402` (import violations) in all `__init__.py` files, and in `path/to/file.py`.\n[per-file-ignores]\n\"__init__.py\" = [\"E402\"]\n\"path/to/file.py\" = [\"E402\"]\n"
        },
        {
          "name": "CITATION.cff",
          "type": "blob",
          "size": 4.1806640625,
          "content": "cff-version: 1.2.0\ntitle: >-\n  N-LTP: An Open-source Neural Language Technology Platform for Chinese\nmessage: >-\n  If you use this software, please cite using the\n  following metadata.\ntype: software\nauthors:\n  - given-names: Wanxiang\n    family-names: Che\n    affiliation: SCIR\n    email: car@ir.hit.edu.cn\n  - given-names: Yunlong\n    family-names: Feng\n    affiliation: SCIR\n    email: ylfeng@ir.hit.edu.cn\n  - given-names: Libo\n    family-names: Qin\n    affiliation: SCIR\n    email: lbqin@ir.hit.edu.cn\n  - given-names: Ting\n    family-names: Liu\n    affiliation: Meta\n    email: tliu@ir.hit.edu.cn\ndoi: 10.18653/v1/2021.emnlp-demo.6\nurl: \"https://github.com/HIT-SCIR/ltp\"\nrepository-code: 'https://github.com/HIT-SCIR/ltp'\nabstract: >-\n  We introduce N-LTP, an open-source neural language technology platform supporting six fundamental Chinese NLP tasks: lexical analysis (Chinese word segmentation, part-of-speech tagging, and named entity recognition), syntactic parsing (dependency parsing), and semantic parsing (semantic dependency parsing and semantic role labeling). Unlike the existing state-of-the-art toolkits, such as Stanza, that adopt an independent model for each task, N-LTP adopts the multi-task framework by using a shared pre-trained model, which has the advantage of capturing the shared knowledge across relevant Chinese tasks. In addition, a knowledge distillation method (Clark et al., 2019) where the single-task model teaches the multi-task model is further introduced to encourage the multi-task model to surpass its single-task teacher. Finally, we provide a collection of easy-to-use APIs and a visualization tool to make users to use and view the processing results more easily and directly. To the best of our knowledge, this is the first toolkit to support six Chinese NLP fundamental tasks. Source code, documentation, and pre-trained models are available at https://github.com/HIT-SCIR/ltp.\nkeywords:\n  - 'neural network, natural language, Chinese, multi-task learning, knowledge distillation'\nversion: \"4.0\"\ndate-released: 2020-06-14\nidentifiers:\n  - type: url\n    value: \"https://github.com/HIT-SCIR/ltp\"\n    description: The GitHub repo url\npreferred-citation:\n  type: article\n  authors:\n  - given-names: Wanxiang\n    family-names: Che\n    affiliation: SCIR\n    email: car@ir.hit.edu.cn\n  - given-names: Yunlong\n    family-names: Feng\n    affiliation: SCIR\n    email: ylfeng@ir.hit.edu.cn\n  - given-names: Libo\n    family-names: Qin\n    affiliation: SCIR\n    email: lbqin@ir.hit.edu.cn\n  - given-names: Ting\n    family-names: Liu\n    affiliation: Meta\n    email: tliu@ir.hit.edu.cn\n  booktitle: \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\"\n  url: \"https://aclanthology.org/2021.emnlp-demo.6\"\n  doi: \"10.18653/v1/2021.emnlp-demo.6\"\n  publisher: \"Association for Computational Linguistics\"\n  month: 9\n  year: 2020\n  address: \"Online and Punta Cana, Dominican Republic\"\n  start: 42\n  end: 49\n  title: \"N-LTP: An Open-source Neural Language Technology Platform for Chinese\"\n  abstract: >-\n    We introduce N-LTP, an open-source neural language technology platform supporting six fundamental Chinese NLP tasks: lexical analysis (Chinese word segmentation, part-of-speech tagging, and named entity recognition), syntactic parsing (dependency parsing), and semantic parsing (semantic dependency parsing and semantic role labeling). Unlike the existing state-of-the-art toolkits, such as Stanza, that adopt an independent model for each task, N-LTP adopts the multi-task framework by using a shared pre-trained model, which has the advantage of capturing the shared knowledge across relevant Chinese tasks. In addition, a knowledge distillation method (Clark et al., 2019) where the single-task model teaches the multi-task model is further introduced to encourage the multi-task model to surpass its single-task teacher. Finally, we provide a collection of easy-to-use APIs and a visualization tool to make users to use and view the processing results more easily and directly. To the best of our knowledge, this is the first toolkit to support six Chinese NLP fundamental tasks. Source code, documentation, and pre-trained models are available at https://github.com/HIT-SCIR/ltp.\n"
        },
        {
          "name": "Cargo.toml",
          "type": "blob",
          "size": 0.1474609375,
          "content": "[workspace]\nmembers = [\n    \"rust/ltp\",\n    \"rust/ltp-cffi\",\n    \"python/extension\",\n]\n\n[profile.release]\nlto = true\ncodegen-units = 1\npanic = \"abort\"\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 2.16796875,
          "content": "\nhelp:  ## Show help\n\t@grep -E '^[.a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | awk 'BEGIN {FS = \":.*?## \"}; {printf \"\\033[36m%-30s\\033[0m %s\\n\", $$1, $$2}'\n\nsync: ## Merge changes from main branch to your current branch\n\tgit fetch --all\n\tgit merge main\n\nbdist: ## build ltp and ltp_extension\n\tpip wheel --no-deps -w dist python/core\n\tpip wheel --no-deps -w dist python/interface\n\tmaturin build --release -m python/extension/Cargo.toml --out dist\n\ncbindgen_header:\n\tmkdir -p bindings/c\n\tcbindgen --config rust/ltp-cffi/cbindgen.toml --crate ltp-cffi --output bindings/c/ltp.h\n\ncbindgen: cbindgen_header\n\tcargo build --release  --package ltp-cffi\n\tcp target/release/libltp.* bindings/c\n\ncbindgen_example: cbindgen\n\tgcc -L \"$(pwd)bindings/c\" -lltp -I \"$(pwd)bindings/c\" -o target/c_example rust/ltp-cffi/examples/example.c\n\t./target/c_example\n\ntrain_legacy:\n\tcargo run --package ltp --release --example cws -- train --train data/examples/cws/train.txt --eval data/examples/cws/val.txt --model=data/cws_model.bin\n\tcargo run --package ltp --release --example cws -- eval --eval data/examples/cws/test.txt --model=data/cws_model.bin\n\tcargo run --package ltp --release --example cws -- predict --input data/examples/cws/raw.txt --output data/examples/cws/output.txt --model=data/cws_model.bin\n\n\tcargo run --package ltp --release --example pos -- train --train data/examples/pos/train.txt --eval data/examples/pos/val.txt --model=data/pos_model.bin --vocab data/examples/pos/vocab.txt\n\tcargo run --package ltp --release --example pos -- eval --eval data/examples/pos/test.txt --model=data/pos_model.bin\n\tcargo run --package ltp --release --example pos -- predict --input data/examples/pos/raw.txt --output data/examples/pos/output.txt --model=data/pos_model.bin\n\n\tcargo run --package ltp --release --example ner -- train --train data/examples/ner/train.txt --eval data/examples/ner/val.txt --model=data/ner_model.bin --vocab data/examples/ner/vocab.txt\n\tcargo run --package ltp --release --example ner -- eval --eval data/examples/ner/test.txt --model=data/ner_model.bin\n\tcargo run --package ltp --release --example ner -- predict --input data/examples/ner/raw.txt --output data/examples/ner/output.txt --model=data/ner_model.bin\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 12.6953125,
          "content": "![CODE SIZE](https://img.shields.io/github/languages/code-size/HIT-SCIR/ltp)\n![CONTRIBUTORS](https://img.shields.io/github/contributors/HIT-SCIR/ltp)\n![LAST COMMIT](https://img.shields.io/github/last-commit/HIT-SCIR/ltp)\n\n| Language                             | version                                                                                                                                                                                                                                                                                                                 |\n| ------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| [Python](python/interface/README.md) | [![LTP](https://img.shields.io/pypi/v/ltp?label=LTP)](https://pypi.org/project/ltp) [![LTP-Core](https://img.shields.io/pypi/v/ltp-core?label=LTP-Core)](https://pypi.org/project/ltp-core) [![LTP-Extension](https://img.shields.io/pypi/v/ltp-extension?label=LTP-Extension)](https://pypi.org/project/ltp-extension) |\n| [Rust](rust/ltp/README.md)           | [![LTP](https://img.shields.io/crates/v/ltp?label=LTP)](https://crates.io/crates/ltp)                                                                                                                                                                                                                                   |\n\n# LTP 4\n\nLTP（Language Technology Platform） 提供了一系列中文自然语言处理工具，用户可以使用这些工具对于中文文本进行分词、词性标注、句法分析等等工作。\n\n## 引用\n\n如果您在工作中使用了 LTP，您可以引用这篇论文\n\n```bibtex\n@inproceedings{che-etal-2021-n,\n    title = \"N-{LTP}: An Open-source Neural Language Technology Platform for {C}hinese\",\n    author = \"Che, Wanxiang  and\n      Feng, Yunlong  and\n      Qin, Libo  and\n      Liu, Ting\",\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\",\n    month = nov,\n    year = \"2021\",\n    address = \"Online and Punta Cana, Dominican Republic\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.emnlp-demo.6\",\n    doi = \"10.18653/v1/2021.emnlp-demo.6\",\n    pages = \"42--49\",\n    abstract = \"We introduce N-LTP, an open-source neural language technology platform supporting six fundamental Chinese NLP tasks: lexical analysis (Chinese word segmentation, part-of-speech tagging, and named entity recognition), syntactic parsing (dependency parsing), and semantic parsing (semantic dependency parsing and semantic role labeling). Unlike the existing state-of-the-art toolkits, such as Stanza, that adopt an independent model for each task, N-LTP adopts the multi-task framework by using a shared pre-trained model, which has the advantage of capturing the shared knowledge across relevant Chinese tasks. In addition, a knowledge distillation method (Clark et al., 2019) where the single-task model teaches the multi-task model is further introduced to encourage the multi-task model to surpass its single-task teacher. Finally, we provide a collection of easy-to-use APIs and a visualization tool to make users to use and view the processing results more easily and directly. To the best of our knowledge, this is the first toolkit to support six Chinese NLP fundamental tasks. Source code, documentation, and pre-trained models are available at https://github.com/HIT-SCIR/ltp.\",\n}\n```\n\n**参考书：**\n由哈工大社会计算与信息检索研究中心（HIT-SCIR）的多位学者共同编著的《[自然语言处理：基于预训练模型的方法](https://item.jd.com/13344628.html)\n》（作者：车万翔、郭江、崔一鸣；主审：刘挺）一书现已正式出版，该书重点介绍了新的基于预训练模型的自然语言处理技术，包括基础知识、预训练词向量和预训练模型三大部分，可供广大 LTP 用户学习参考。\n\n### 更新说明\n\n- 4.2.0\n  - \\[结构性变化\\] 将 LTP 拆分成 2 个部分，维护和训练更方便，结构更清晰\n    - \\[Legacy 模型\\] 针对广大用户对于**推理速度**的需求，使用 Rust 重写了基于感知机的算法，准确率与 LTP3 版本相当，速度则是 LTP v3 的 **3.55** 倍，开启多线程更可获得 **17.17** 倍的速度提升，但目前仅支持分词、词性、命名实体三大任务\n    - \\[深度学习模型\\] 即基于 PyTorch 实现的深度学习模型，支持全部的 6 大任务（分词/词性/命名实体/语义角色/依存句法/语义依存）\n  - \\[其他改进\\] 改进了模型训练方法\n    - \\[共同\\] 提供了训练脚本和训练样例，使得用户能够更方便地使用私有的数据，自行训练个性化的模型\n    - \\[深度学习模型\\] 采用 hydra 对训练过程进行配置，方便广大用户修改模型训练参数以及对 LTP 进行扩展（比如使用其他包中的 Module）\n  - \\[其他变化\\] 分词、依存句法分析 (Eisner) 和 语义依存分析 (Eisner) 任务的解码算法使用 Rust 实现，速度更快\n  - \\[新特性\\] 模型上传至 [Huggingface Hub](https://huggingface.co/LTP)，支持自动下载，下载速度更快，并且支持用户自行上传自己训练的模型供 LTP 进行推理使用\n  - \\[破坏性变更\\] 改用 Pipeline API 进行推理，方便后续进行更深入的性能优化（如 SDP 和 SDPG 很大一部分是重叠的，重用可以加快推理速度），使用说明参见[Github 快速使用部分](https://github.com/hit-scir/ltp)\n- 4.1.0\n  - 提供了自定义分词等功能\n  - 修复了一些 bug\n- 4.0.0\n  - 基于 Pytorch 开发，原生 Python 接口\n  - 可根据需要自由选择不同速度和指标的模型\n  - 分词、词性、命名实体、依存句法、语义角色、语义依存 6 大任务\n\n## 快速使用\n\n### [Python](python/interface/README.md)\n\n```bash\n# 方法 1： 使用清华源安装 LTP\n# 1. 安装 PyTorch 和 Transformers 依赖\npip install -i https://pypi.tuna.tsinghua.edu.cn/simple torch transformers\n# 2. 安装 LTP\npip install -i https://pypi.tuna.tsinghua.edu.cn/simple ltp ltp-core ltp-extension\n\n# 方法 2： 先全局换源，再安装 LTP\n# 1. 全局换 TUNA 源\npip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n# 2. 安装 PyTorch 和 Transformers 依赖\npip install torch transformers\n# 3. 安装 LTP\npip install ltp ltp-core ltp-extension\n```\n\n**注：** 如果遇到任何错误，请尝试使用上述命令重新安装 ltp，如果依然报错，请在 Github issues 中反馈。\n\n```python\nimport torch\nfrom ltp import LTP\n\n# 默认 huggingface 下载，可能需要代理\n\nltp = LTP(\"LTP/small\")  # 默认加载 Small 模型\n                        # 也可以传入模型的路径，ltp = LTP(\"/path/to/your/model\")\n                        # /path/to/your/model 应当存在 config.json 和其他模型文件\n\n# 将模型移动到 GPU 上\nif torch.cuda.is_available():\n    # ltp.cuda()\n    ltp.to(\"cuda\")\n\n# 自定义词表\nltp.add_word(\"汤姆去\", freq=2)\nltp.add_words([\"外套\", \"外衣\"], freq=2)\n\n#  分词 cws、词性 pos、命名实体标注 ner、语义角色标注 srl、依存句法分析 dep、语义依存分析树 sdp、语义依存分析图 sdpg\noutput = ltp.pipeline([\"他叫汤姆去拿外衣。\"], tasks=[\"cws\", \"pos\", \"ner\", \"srl\", \"dep\", \"sdp\", \"sdpg\"])\n# 使用字典格式作为返回结果\nprint(output.cws)  # print(output[0]) / print(output['cws']) # 也可以使用下标访问\nprint(output.pos)\nprint(output.sdp)\n\n# 使用感知机算法实现的分词、词性和命名实体识别，速度比较快，但是精度略低\nltp = LTP(\"LTP/legacy\")\n# cws, pos, ner = ltp.pipeline([\"他叫汤姆去拿外衣。\"], tasks=[\"cws\", \"ner\"]).to_tuple() # error: NER 需要 词性标注任务的结果\ncws, pos, ner = ltp.pipeline([\"他叫汤姆去拿外衣。\"], tasks=[\"cws\", \"pos\", \"ner\"]).to_tuple()  # to tuple 可以自动转换为元组格式\n# 使用元组格式作为返回结果\nprint(cws, pos, ner)\n```\n\n**[详细说明](python/interface/docs/quickstart.rst)**\n\n### [Rust](rust/ltp/README.md)\n\n```rust\nuse std::fs::File;\nuse itertools::multizip;\nuse ltp::{CWSModel, POSModel, NERModel, ModelSerde, Format, Codec};\n\nfn main() -> Result<(), Box<dyn std::error::Error>> {\n  let file = File::open(\"data/legacy-models/cws_model.bin\")?;\n  let cws: CWSModel = ModelSerde::load(file, Format::AVRO(Codec::Deflate))?;\n  let file = File::open(\"data/legacy-models/pos_model.bin\")?;\n  let pos: POSModel = ModelSerde::load(file, Format::AVRO(Codec::Deflate))?;\n  let file = File::open(\"data/legacy-models/ner_model.bin\")?;\n  let ner: NERModel = ModelSerde::load(file, Format::AVRO(Codec::Deflate))?;\n\n  let words = cws.predict(\"他叫汤姆去拿外衣。\")?;\n  let pos = pos.predict(&words)?;\n  let ner = ner.predict((&words, &pos))?;\n\n  for (w, p, n) in multizip((words, pos, ner)) {\n    println!(\"{}/{}/{}\", w, p, n);\n  }\n\n  Ok(())\n}\n```\n\n## 模型性能以及下载地址\n\n|                                深度学习模型(🤗HF/🗜 压缩包)                                 | 分词  | 词性  | 命名实体 | 语义角色 | 依存句法 | 语义依存 | 速度(句/S) |\n| :----------------------------------------------------------------------------------------: | :---: | :---: | :------: | :------: | :------: | :------: | :--------: |\n|   [🤗Base](https://huggingface.co/LTP/base) [🗜Base](http://39.96.43.154/ltp/v4/base.tgz)   | 98.7  | 98.5  |   95.4   |   80.6   |   89.5   |   75.2   |   39.12    |\n| [🤗Base1](https://huggingface.co/LTP/base1) [🗜Base1](http://39.96.43.154/ltp/v4/base1.tgz) | 99.22 | 98.73 |  96.39   |  79.28   |  89.57   |  76.57   |   --.--    |\n| [🤗Base2](https://huggingface.co/LTP/base2) [🗜Base2](http://39.96.43.154/ltp/v4/base2.tgz) | 99.18 | 98.69 |  95.97   |  79.49   |  90.19   |  76.62   |   --.--    |\n| [🤗Small](https://huggingface.co/LTP/small) [🗜Small](http://39.96.43.154/ltp/v4/small.tgz) | 98.4  | 98.2  |   94.3   |   78.4   |   88.3   |   74.7   |   43.13    |\n|   [🤗Tiny](https://huggingface.co/LTP/tiny) [🗜Tiny](http://39.96.43.154/ltp/v4/tiny.tgz)   | 96.8  | 97.1  |   91.6   |   70.9   |   83.8   |   70.1   |   53.22    |\n\n|                                 感知机算法模型(🤗HF/🗜 压缩包)                                  | 分词  | 词性  | 命名实体 | 速度(句/s) |              备注              |\n| :--------------------------------------------------------------------------------------------: | :---: | :---: | :------: | :--------: | :----------------------------: |\n| [🤗Legacy](https://huggingface.co/LTP/legacy) [🗜Legacy](http://39.96.43.154/ltp/v4/legacy.tgz) | 97.93 | 98.41 |  94.28   |  21581.48  | [性能详情](rust/ltp/README.md) |\n\n**注：感知机算法速度为开启 16 线程速度**\n\n### 如何下载对应的模型\n\n```bash\n# 使用 HTTP 链接下载\n# 确保已安装 git-lfs (https://git-lfs.com)\ngit lfs install\ngit clone https://huggingface.co/LTP/base\n\n# 使用 ssh 下载\n# 确保已安装 git-lfs (https://git-lfs.com)\ngit lfs install\ngit clone git@hf.co:LTP/base\n\n# 下载压缩包\nwget http://39.96.43.154/ltp/v4/base.tgz\ntar -zxvf base.tgz -C base\n```\n\n### 如何使用下载的模型\n\n```python\nfrom ltp import LTP\n\n# 在路径中给出模型下载或解压后的路径\n# 例如：base 模型的文件夹路径为 \"path/to/base\"\n#      \"path/to/base\" 下应当存在 \"config.json\"\nltp = LTP(\"path/to/base\")\n```\n\n## 构建 Wheel 包\n\n```shell script\nmake bdist\n```\n\n## 其他语言绑定\n\n**感知机算法**\n\n- [Rust](rust/ltp)\n- [C/C++](rust/ltp-cffi)\n\n**深度学习算法**\n\n- [Rust](https://github.com/HIT-SCIR/libltp/tree/master/ltp-rs)\n- [C++](https://github.com/HIT-SCIR/libltp/tree/master/ltp-cpp)\n- [Java](https://github.com/HIT-SCIR/libltp/tree/master/ltp-java)\n\n## 作者信息\n\n- 车万翔 \\<\\<[car@ir.hit.edu.cn](mailto:car@ir.hit.edu.cn)>>\n- 冯云龙 \\<\\<[ylfeng@ir.hit.edu.cn](mailto:ylfeng@ir.hit.edu.cn)>>\n\n## 开源协议\n\n1. 语言技术平台面向国内外大学、中科院各研究所以及个人研究者免费开放源代码，但如上述机构和个人将该平台用于商业目的（如企业合作项目等）则需要付费。\n2. 除上述机构以外的企事业单位，如申请使用该平台，需付费。\n3. 凡涉及付费问题，请发邮件到 car@ir.hit.edu.cn 洽商。\n4. 如果您在 LTP 基础上发表论文或取得科研成果，请您在发表论文和申报成果时声明“使用了哈工大社会计算与信息检索研究中心研制的语言技术平台（LTP）”.\n   同时，发信给car@ir.hit.edu.cn，说明发表论文或申报成果的题目、出处等。\n"
        },
        {
          "name": "appveyor.yml",
          "type": "blob",
          "size": 0.798828125,
          "content": "branches:\n  only:\n    - 3.X\n\nenvironment:\n  P: \"c:/projects/libs\"\n\n# clone directory\nclone_folder: c:\\projects\\ltp\n\nos: Visual Studio 2015\n\nplatform:\n  - x86\n  - x64\n\nconfiguration:\n  - Debug\n  - Release\n\ninstall:\n  # by default, all script lines are interpreted as batch\n\nbuild:\n  project: ALL_BUILD.vcxproj # path to Visual Studio solution or project\n\n# scripts to run before build\nbefore_build:\n  - echo Running cmake...\n  - cd c:\\projects\\ltp\n  - cmake -G \"Visual Studio 14 2015 Win64\" -DCMAKE_INSTALL_PREFIX=%P%\n\nafter_build:\n  - cd c:\\projects\\ltp\n  - 7z a ltp-win-%PLATFORM%-%CONFIGURATION%.zip bin\\examples\\%CONFIGURATION%\\*_cmdline.exe bin\\%CONFIGURATION%\\ltp_test.exe lib\\%CONFIGURATION%\\*.dll\n\nartifacts:\n  - path: ltp-win-$(platform)-$(configuration).zip\n    name: ltp-win-$(platform)-$(configuration).zip\n"
        },
        {
          "name": "data",
          "type": "tree",
          "content": null
        },
        {
          "name": "python",
          "type": "tree",
          "content": null
        },
        {
          "name": "rust",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}