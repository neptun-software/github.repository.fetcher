{
  "metadata": {
    "timestamp": 1736561072036,
    "page": 864,
    "hasNextPage": false,
    "endCursor": "Y3Vyc29yOjg2OA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "HIT-SCIR/ltp",
      "stars": 5014,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".config",
          "type": "tree",
          "content": null
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 2.1435546875,
          "content": "/data\n/target\nCargo.lock\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\npip-wheel-metadata/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n.python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n### VisualStudioCode\n.vscode/*\n!.vscode/settings.json\n!.vscode/tasks.json\n!.vscode/launch.json\n!.vscode/extensions.json\n*.code-workspace\n**/.vscode\n\n# JetBrains\n.idea/\n\n# Lightning-Hydra-Template\npython/core/configs/local/default.yaml\npython/core/data/\npython/core/logs/\npython/core/wandb/\npython/core/.env\npython/core/.autoenv\n\n.DS_Store\n/bindings\n/python/interface/models\n"
        },
        {
          "name": ".ruff.toml",
          "type": "blob",
          "size": 0.359375,
          "content": "# Enable flake8-bugbear (`B`) rules.\nselect = [\"E\", \"F\", \"B\"]\n\n# Never enforce `E501` (line length violations).\nignore = [\"E501\"]\n\n# Avoid trying to fix flake8-bugbear (`B`) violations.\nunfixable = [\"B\"]\n\n# Ignore `E402` (import violations) in all `__init__.py` files, and in `path/to/file.py`.\n[per-file-ignores]\n\"__init__.py\" = [\"E402\"]\n\"path/to/file.py\" = [\"E402\"]\n"
        },
        {
          "name": "CITATION.cff",
          "type": "blob",
          "size": 4.1806640625,
          "content": "cff-version: 1.2.0\ntitle: >-\n  N-LTP: An Open-source Neural Language Technology Platform for Chinese\nmessage: >-\n  If you use this software, please cite using the\n  following metadata.\ntype: software\nauthors:\n  - given-names: Wanxiang\n    family-names: Che\n    affiliation: SCIR\n    email: car@ir.hit.edu.cn\n  - given-names: Yunlong\n    family-names: Feng\n    affiliation: SCIR\n    email: ylfeng@ir.hit.edu.cn\n  - given-names: Libo\n    family-names: Qin\n    affiliation: SCIR\n    email: lbqin@ir.hit.edu.cn\n  - given-names: Ting\n    family-names: Liu\n    affiliation: Meta\n    email: tliu@ir.hit.edu.cn\ndoi: 10.18653/v1/2021.emnlp-demo.6\nurl: \"https://github.com/HIT-SCIR/ltp\"\nrepository-code: 'https://github.com/HIT-SCIR/ltp'\nabstract: >-\n  We introduce N-LTP, an open-source neural language technology platform supporting six fundamental Chinese NLP tasks: lexical analysis (Chinese word segmentation, part-of-speech tagging, and named entity recognition), syntactic parsing (dependency parsing), and semantic parsing (semantic dependency parsing and semantic role labeling). Unlike the existing state-of-the-art toolkits, such as Stanza, that adopt an independent model for each task, N-LTP adopts the multi-task framework by using a shared pre-trained model, which has the advantage of capturing the shared knowledge across relevant Chinese tasks. In addition, a knowledge distillation method (Clark et al., 2019) where the single-task model teaches the multi-task model is further introduced to encourage the multi-task model to surpass its single-task teacher. Finally, we provide a collection of easy-to-use APIs and a visualization tool to make users to use and view the processing results more easily and directly. To the best of our knowledge, this is the first toolkit to support six Chinese NLP fundamental tasks. Source code, documentation, and pre-trained models are available at https://github.com/HIT-SCIR/ltp.\nkeywords:\n  - 'neural network, natural language, Chinese, multi-task learning, knowledge distillation'\nversion: \"4.0\"\ndate-released: 2020-06-14\nidentifiers:\n  - type: url\n    value: \"https://github.com/HIT-SCIR/ltp\"\n    description: The GitHub repo url\npreferred-citation:\n  type: article\n  authors:\n  - given-names: Wanxiang\n    family-names: Che\n    affiliation: SCIR\n    email: car@ir.hit.edu.cn\n  - given-names: Yunlong\n    family-names: Feng\n    affiliation: SCIR\n    email: ylfeng@ir.hit.edu.cn\n  - given-names: Libo\n    family-names: Qin\n    affiliation: SCIR\n    email: lbqin@ir.hit.edu.cn\n  - given-names: Ting\n    family-names: Liu\n    affiliation: Meta\n    email: tliu@ir.hit.edu.cn\n  booktitle: \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\"\n  url: \"https://aclanthology.org/2021.emnlp-demo.6\"\n  doi: \"10.18653/v1/2021.emnlp-demo.6\"\n  publisher: \"Association for Computational Linguistics\"\n  month: 9\n  year: 2020\n  address: \"Online and Punta Cana, Dominican Republic\"\n  start: 42\n  end: 49\n  title: \"N-LTP: An Open-source Neural Language Technology Platform for Chinese\"\n  abstract: >-\n    We introduce N-LTP, an open-source neural language technology platform supporting six fundamental Chinese NLP tasks: lexical analysis (Chinese word segmentation, part-of-speech tagging, and named entity recognition), syntactic parsing (dependency parsing), and semantic parsing (semantic dependency parsing and semantic role labeling). Unlike the existing state-of-the-art toolkits, such as Stanza, that adopt an independent model for each task, N-LTP adopts the multi-task framework by using a shared pre-trained model, which has the advantage of capturing the shared knowledge across relevant Chinese tasks. In addition, a knowledge distillation method (Clark et al., 2019) where the single-task model teaches the multi-task model is further introduced to encourage the multi-task model to surpass its single-task teacher. Finally, we provide a collection of easy-to-use APIs and a visualization tool to make users to use and view the processing results more easily and directly. To the best of our knowledge, this is the first toolkit to support six Chinese NLP fundamental tasks. Source code, documentation, and pre-trained models are available at https://github.com/HIT-SCIR/ltp.\n"
        },
        {
          "name": "Cargo.toml",
          "type": "blob",
          "size": 0.1474609375,
          "content": "[workspace]\nmembers = [\n    \"rust/ltp\",\n    \"rust/ltp-cffi\",\n    \"python/extension\",\n]\n\n[profile.release]\nlto = true\ncodegen-units = 1\npanic = \"abort\"\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 2.16796875,
          "content": "\nhelp:  ## Show help\n\t@grep -E '^[.a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | awk 'BEGIN {FS = \":.*?## \"}; {printf \"\\033[36m%-30s\\033[0m %s\\n\", $$1, $$2}'\n\nsync: ## Merge changes from main branch to your current branch\n\tgit fetch --all\n\tgit merge main\n\nbdist: ## build ltp and ltp_extension\n\tpip wheel --no-deps -w dist python/core\n\tpip wheel --no-deps -w dist python/interface\n\tmaturin build --release -m python/extension/Cargo.toml --out dist\n\ncbindgen_header:\n\tmkdir -p bindings/c\n\tcbindgen --config rust/ltp-cffi/cbindgen.toml --crate ltp-cffi --output bindings/c/ltp.h\n\ncbindgen: cbindgen_header\n\tcargo build --release  --package ltp-cffi\n\tcp target/release/libltp.* bindings/c\n\ncbindgen_example: cbindgen\n\tgcc -L \"$(pwd)bindings/c\" -lltp -I \"$(pwd)bindings/c\" -o target/c_example rust/ltp-cffi/examples/example.c\n\t./target/c_example\n\ntrain_legacy:\n\tcargo run --package ltp --release --example cws -- train --train data/examples/cws/train.txt --eval data/examples/cws/val.txt --model=data/cws_model.bin\n\tcargo run --package ltp --release --example cws -- eval --eval data/examples/cws/test.txt --model=data/cws_model.bin\n\tcargo run --package ltp --release --example cws -- predict --input data/examples/cws/raw.txt --output data/examples/cws/output.txt --model=data/cws_model.bin\n\n\tcargo run --package ltp --release --example pos -- train --train data/examples/pos/train.txt --eval data/examples/pos/val.txt --model=data/pos_model.bin --vocab data/examples/pos/vocab.txt\n\tcargo run --package ltp --release --example pos -- eval --eval data/examples/pos/test.txt --model=data/pos_model.bin\n\tcargo run --package ltp --release --example pos -- predict --input data/examples/pos/raw.txt --output data/examples/pos/output.txt --model=data/pos_model.bin\n\n\tcargo run --package ltp --release --example ner -- train --train data/examples/ner/train.txt --eval data/examples/ner/val.txt --model=data/ner_model.bin --vocab data/examples/ner/vocab.txt\n\tcargo run --package ltp --release --example ner -- eval --eval data/examples/ner/test.txt --model=data/ner_model.bin\n\tcargo run --package ltp --release --example ner -- predict --input data/examples/ner/raw.txt --output data/examples/ner/output.txt --model=data/ner_model.bin\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 12.6953125,
          "content": "![CODE SIZE](https://img.shields.io/github/languages/code-size/HIT-SCIR/ltp)\n![CONTRIBUTORS](https://img.shields.io/github/contributors/HIT-SCIR/ltp)\n![LAST COMMIT](https://img.shields.io/github/last-commit/HIT-SCIR/ltp)\n\n| Language                             | version                                                                                                                                                                                                                                                                                                                 |\n| ------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| [Python](python/interface/README.md) | [![LTP](https://img.shields.io/pypi/v/ltp?label=LTP)](https://pypi.org/project/ltp) [![LTP-Core](https://img.shields.io/pypi/v/ltp-core?label=LTP-Core)](https://pypi.org/project/ltp-core) [![LTP-Extension](https://img.shields.io/pypi/v/ltp-extension?label=LTP-Extension)](https://pypi.org/project/ltp-extension) |\n| [Rust](rust/ltp/README.md)           | [![LTP](https://img.shields.io/crates/v/ltp?label=LTP)](https://crates.io/crates/ltp)                                                                                                                                                                                                                                   |\n\n# LTP 4\n\nLTPï¼ˆLanguage Technology Platformï¼‰ æä¾›äº†ä¸€ç³»åˆ—ä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç†å·¥å…·ï¼Œç”¨æˆ·å¯ä»¥ä½¿ç”¨è¿™äº›å·¥å…·å¯¹äºä¸­æ–‡æ–‡æœ¬è¿›è¡Œåˆ†è¯ã€è¯æ€§æ ‡æ³¨ã€å¥æ³•åˆ†æç­‰ç­‰å·¥ä½œã€‚\n\n## å¼•ç”¨\n\nå¦‚æœæ‚¨åœ¨å·¥ä½œä¸­ä½¿ç”¨äº† LTPï¼Œæ‚¨å¯ä»¥å¼•ç”¨è¿™ç¯‡è®ºæ–‡\n\n```bibtex\n@inproceedings{che-etal-2021-n,\n    title = \"N-{LTP}: An Open-source Neural Language Technology Platform for {C}hinese\",\n    author = \"Che, Wanxiang  and\n      Feng, Yunlong  and\n      Qin, Libo  and\n      Liu, Ting\",\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\",\n    month = nov,\n    year = \"2021\",\n    address = \"Online and Punta Cana, Dominican Republic\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2021.emnlp-demo.6\",\n    doi = \"10.18653/v1/2021.emnlp-demo.6\",\n    pages = \"42--49\",\n    abstract = \"We introduce N-LTP, an open-source neural language technology platform supporting six fundamental Chinese NLP tasks: lexical analysis (Chinese word segmentation, part-of-speech tagging, and named entity recognition), syntactic parsing (dependency parsing), and semantic parsing (semantic dependency parsing and semantic role labeling). Unlike the existing state-of-the-art toolkits, such as Stanza, that adopt an independent model for each task, N-LTP adopts the multi-task framework by using a shared pre-trained model, which has the advantage of capturing the shared knowledge across relevant Chinese tasks. In addition, a knowledge distillation method (Clark et al., 2019) where the single-task model teaches the multi-task model is further introduced to encourage the multi-task model to surpass its single-task teacher. Finally, we provide a collection of easy-to-use APIs and a visualization tool to make users to use and view the processing results more easily and directly. To the best of our knowledge, this is the first toolkit to support six Chinese NLP fundamental tasks. Source code, documentation, and pre-trained models are available at https://github.com/HIT-SCIR/ltp.\",\n}\n```\n\n**å‚è€ƒä¹¦ï¼š**\nç”±å“ˆå·¥å¤§ç¤¾ä¼šè®¡ç®—ä¸ä¿¡æ¯æ£€ç´¢ç ”ç©¶ä¸­å¿ƒï¼ˆHIT-SCIRï¼‰çš„å¤šä½å­¦è€…å…±åŒç¼–è‘—çš„ã€Š[è‡ªç„¶è¯­è¨€å¤„ç†ï¼šåŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„æ–¹æ³•](https://item.jd.com/13344628.html)\nã€‹ï¼ˆä½œè€…ï¼šè½¦ä¸‡ç¿”ã€éƒ­æ±Ÿã€å´”ä¸€é¸£ï¼›ä¸»å®¡ï¼šåˆ˜æŒºï¼‰ä¸€ä¹¦ç°å·²æ­£å¼å‡ºç‰ˆï¼Œè¯¥ä¹¦é‡ç‚¹ä»‹ç»äº†æ–°çš„åŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ï¼ŒåŒ…æ‹¬åŸºç¡€çŸ¥è¯†ã€é¢„è®­ç»ƒè¯å‘é‡å’Œé¢„è®­ç»ƒæ¨¡å‹ä¸‰å¤§éƒ¨åˆ†ï¼Œå¯ä¾›å¹¿å¤§ LTP ç”¨æˆ·å­¦ä¹ å‚è€ƒã€‚\n\n### æ›´æ–°è¯´æ˜\n\n- 4.2.0\n  - \\[ç»“æ„æ€§å˜åŒ–\\] å°† LTP æ‹†åˆ†æˆ 2 ä¸ªéƒ¨åˆ†ï¼Œç»´æŠ¤å’Œè®­ç»ƒæ›´æ–¹ä¾¿ï¼Œç»“æ„æ›´æ¸…æ™°\n    - \\[Legacy æ¨¡å‹\\] é’ˆå¯¹å¹¿å¤§ç”¨æˆ·å¯¹äº**æ¨ç†é€Ÿåº¦**çš„éœ€æ±‚ï¼Œä½¿ç”¨ Rust é‡å†™äº†åŸºäºæ„ŸçŸ¥æœºçš„ç®—æ³•ï¼Œå‡†ç¡®ç‡ä¸ LTP3 ç‰ˆæœ¬ç›¸å½“ï¼Œé€Ÿåº¦åˆ™æ˜¯ LTP v3 çš„ **3.55** å€ï¼Œå¼€å¯å¤šçº¿ç¨‹æ›´å¯è·å¾— **17.17** å€çš„é€Ÿåº¦æå‡ï¼Œä½†ç›®å‰ä»…æ”¯æŒåˆ†è¯ã€è¯æ€§ã€å‘½åå®ä½“ä¸‰å¤§ä»»åŠ¡\n    - \\[æ·±åº¦å­¦ä¹ æ¨¡å‹\\] å³åŸºäº PyTorch å®ç°çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œæ”¯æŒå…¨éƒ¨çš„ 6 å¤§ä»»åŠ¡ï¼ˆåˆ†è¯/è¯æ€§/å‘½åå®ä½“/è¯­ä¹‰è§’è‰²/ä¾å­˜å¥æ³•/è¯­ä¹‰ä¾å­˜ï¼‰\n  - \\[å…¶ä»–æ”¹è¿›\\] æ”¹è¿›äº†æ¨¡å‹è®­ç»ƒæ–¹æ³•\n    - \\[å…±åŒ\\] æä¾›äº†è®­ç»ƒè„šæœ¬å’Œè®­ç»ƒæ ·ä¾‹ï¼Œä½¿å¾—ç”¨æˆ·èƒ½å¤Ÿæ›´æ–¹ä¾¿åœ°ä½¿ç”¨ç§æœ‰çš„æ•°æ®ï¼Œè‡ªè¡Œè®­ç»ƒä¸ªæ€§åŒ–çš„æ¨¡å‹\n    - \\[æ·±åº¦å­¦ä¹ æ¨¡å‹\\] é‡‡ç”¨ hydra å¯¹è®­ç»ƒè¿‡ç¨‹è¿›è¡Œé…ç½®ï¼Œæ–¹ä¾¿å¹¿å¤§ç”¨æˆ·ä¿®æ”¹æ¨¡å‹è®­ç»ƒå‚æ•°ä»¥åŠå¯¹ LTP è¿›è¡Œæ‰©å±•ï¼ˆæ¯”å¦‚ä½¿ç”¨å…¶ä»–åŒ…ä¸­çš„ Moduleï¼‰\n  - \\[å…¶ä»–å˜åŒ–\\] åˆ†è¯ã€ä¾å­˜å¥æ³•åˆ†æ (Eisner) å’Œ è¯­ä¹‰ä¾å­˜åˆ†æ (Eisner) ä»»åŠ¡çš„è§£ç ç®—æ³•ä½¿ç”¨ Rust å®ç°ï¼Œé€Ÿåº¦æ›´å¿«\n  - \\[æ–°ç‰¹æ€§\\] æ¨¡å‹ä¸Šä¼ è‡³ [Huggingface Hub](https://huggingface.co/LTP)ï¼Œæ”¯æŒè‡ªåŠ¨ä¸‹è½½ï¼Œä¸‹è½½é€Ÿåº¦æ›´å¿«ï¼Œå¹¶ä¸”æ”¯æŒç”¨æˆ·è‡ªè¡Œä¸Šä¼ è‡ªå·±è®­ç»ƒçš„æ¨¡å‹ä¾› LTP è¿›è¡Œæ¨ç†ä½¿ç”¨\n  - \\[ç ´åæ€§å˜æ›´\\] æ”¹ç”¨ Pipeline API è¿›è¡Œæ¨ç†ï¼Œæ–¹ä¾¿åç»­è¿›è¡Œæ›´æ·±å…¥çš„æ€§èƒ½ä¼˜åŒ–ï¼ˆå¦‚ SDP å’Œ SDPG å¾ˆå¤§ä¸€éƒ¨åˆ†æ˜¯é‡å çš„ï¼Œé‡ç”¨å¯ä»¥åŠ å¿«æ¨ç†é€Ÿåº¦ï¼‰ï¼Œä½¿ç”¨è¯´æ˜å‚è§[Github å¿«é€Ÿä½¿ç”¨éƒ¨åˆ†](https://github.com/hit-scir/ltp)\n- 4.1.0\n  - æä¾›äº†è‡ªå®šä¹‰åˆ†è¯ç­‰åŠŸèƒ½\n  - ä¿®å¤äº†ä¸€äº› bug\n- 4.0.0\n  - åŸºäº Pytorch å¼€å‘ï¼ŒåŸç”Ÿ Python æ¥å£\n  - å¯æ ¹æ®éœ€è¦è‡ªç”±é€‰æ‹©ä¸åŒé€Ÿåº¦å’ŒæŒ‡æ ‡çš„æ¨¡å‹\n  - åˆ†è¯ã€è¯æ€§ã€å‘½åå®ä½“ã€ä¾å­˜å¥æ³•ã€è¯­ä¹‰è§’è‰²ã€è¯­ä¹‰ä¾å­˜ 6 å¤§ä»»åŠ¡\n\n## å¿«é€Ÿä½¿ç”¨\n\n### [Python](python/interface/README.md)\n\n```bash\n# æ–¹æ³• 1ï¼š ä½¿ç”¨æ¸…åæºå®‰è£… LTP\n# 1. å®‰è£… PyTorch å’Œ Transformers ä¾èµ–\npip install -i https://pypi.tuna.tsinghua.edu.cn/simple torch transformers\n# 2. å®‰è£… LTP\npip install -i https://pypi.tuna.tsinghua.edu.cn/simple ltp ltp-core ltp-extension\n\n# æ–¹æ³• 2ï¼š å…ˆå…¨å±€æ¢æºï¼Œå†å®‰è£… LTP\n# 1. å…¨å±€æ¢ TUNA æº\npip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n# 2. å®‰è£… PyTorch å’Œ Transformers ä¾èµ–\npip install torch transformers\n# 3. å®‰è£… LTP\npip install ltp ltp-core ltp-extension\n```\n\n**æ³¨ï¼š** å¦‚æœé‡åˆ°ä»»ä½•é”™è¯¯ï¼Œè¯·å°è¯•ä½¿ç”¨ä¸Šè¿°å‘½ä»¤é‡æ–°å®‰è£… ltpï¼Œå¦‚æœä¾ç„¶æŠ¥é”™ï¼Œè¯·åœ¨ Github issues ä¸­åé¦ˆã€‚\n\n```python\nimport torch\nfrom ltp import LTP\n\n# é»˜è®¤ huggingface ä¸‹è½½ï¼Œå¯èƒ½éœ€è¦ä»£ç†\n\nltp = LTP(\"LTP/small\")  # é»˜è®¤åŠ è½½ Small æ¨¡å‹\n                        # ä¹Ÿå¯ä»¥ä¼ å…¥æ¨¡å‹çš„è·¯å¾„ï¼Œltp = LTP(\"/path/to/your/model\")\n                        # /path/to/your/model åº”å½“å­˜åœ¨ config.json å’Œå…¶ä»–æ¨¡å‹æ–‡ä»¶\n\n# å°†æ¨¡å‹ç§»åŠ¨åˆ° GPU ä¸Š\nif torch.cuda.is_available():\n    # ltp.cuda()\n    ltp.to(\"cuda\")\n\n# è‡ªå®šä¹‰è¯è¡¨\nltp.add_word(\"æ±¤å§†å»\", freq=2)\nltp.add_words([\"å¤–å¥—\", \"å¤–è¡£\"], freq=2)\n\n#  åˆ†è¯ cwsã€è¯æ€§ posã€å‘½åå®ä½“æ ‡æ³¨ nerã€è¯­ä¹‰è§’è‰²æ ‡æ³¨ srlã€ä¾å­˜å¥æ³•åˆ†æ depã€è¯­ä¹‰ä¾å­˜åˆ†ææ ‘ sdpã€è¯­ä¹‰ä¾å­˜åˆ†æå›¾ sdpg\noutput = ltp.pipeline([\"ä»–å«æ±¤å§†å»æ‹¿å¤–è¡£ã€‚\"], tasks=[\"cws\", \"pos\", \"ner\", \"srl\", \"dep\", \"sdp\", \"sdpg\"])\n# ä½¿ç”¨å­—å…¸æ ¼å¼ä½œä¸ºè¿”å›ç»“æœ\nprint(output.cws)  # print(output[0]) / print(output['cws']) # ä¹Ÿå¯ä»¥ä½¿ç”¨ä¸‹æ ‡è®¿é—®\nprint(output.pos)\nprint(output.sdp)\n\n# ä½¿ç”¨æ„ŸçŸ¥æœºç®—æ³•å®ç°çš„åˆ†è¯ã€è¯æ€§å’Œå‘½åå®ä½“è¯†åˆ«ï¼Œé€Ÿåº¦æ¯”è¾ƒå¿«ï¼Œä½†æ˜¯ç²¾åº¦ç•¥ä½\nltp = LTP(\"LTP/legacy\")\n# cws, pos, ner = ltp.pipeline([\"ä»–å«æ±¤å§†å»æ‹¿å¤–è¡£ã€‚\"], tasks=[\"cws\", \"ner\"]).to_tuple() # error: NER éœ€è¦ è¯æ€§æ ‡æ³¨ä»»åŠ¡çš„ç»“æœ\ncws, pos, ner = ltp.pipeline([\"ä»–å«æ±¤å§†å»æ‹¿å¤–è¡£ã€‚\"], tasks=[\"cws\", \"pos\", \"ner\"]).to_tuple()  # to tuple å¯ä»¥è‡ªåŠ¨è½¬æ¢ä¸ºå…ƒç»„æ ¼å¼\n# ä½¿ç”¨å…ƒç»„æ ¼å¼ä½œä¸ºè¿”å›ç»“æœ\nprint(cws, pos, ner)\n```\n\n**[è¯¦ç»†è¯´æ˜](python/interface/docs/quickstart.rst)**\n\n### [Rust](rust/ltp/README.md)\n\n```rust\nuse std::fs::File;\nuse itertools::multizip;\nuse ltp::{CWSModel, POSModel, NERModel, ModelSerde, Format, Codec};\n\nfn main() -> Result<(), Box<dyn std::error::Error>> {\n  let file = File::open(\"data/legacy-models/cws_model.bin\")?;\n  let cws: CWSModel = ModelSerde::load(file, Format::AVRO(Codec::Deflate))?;\n  let file = File::open(\"data/legacy-models/pos_model.bin\")?;\n  let pos: POSModel = ModelSerde::load(file, Format::AVRO(Codec::Deflate))?;\n  let file = File::open(\"data/legacy-models/ner_model.bin\")?;\n  let ner: NERModel = ModelSerde::load(file, Format::AVRO(Codec::Deflate))?;\n\n  let words = cws.predict(\"ä»–å«æ±¤å§†å»æ‹¿å¤–è¡£ã€‚\")?;\n  let pos = pos.predict(&words)?;\n  let ner = ner.predict((&words, &pos))?;\n\n  for (w, p, n) in multizip((words, pos, ner)) {\n    println!(\"{}/{}/{}\", w, p, n);\n  }\n\n  Ok(())\n}\n```\n\n## æ¨¡å‹æ€§èƒ½ä»¥åŠä¸‹è½½åœ°å€\n\n|                                æ·±åº¦å­¦ä¹ æ¨¡å‹(ğŸ¤—HF/ğŸ—œ å‹ç¼©åŒ…)                                 | åˆ†è¯  | è¯æ€§  | å‘½åå®ä½“ | è¯­ä¹‰è§’è‰² | ä¾å­˜å¥æ³• | è¯­ä¹‰ä¾å­˜ | é€Ÿåº¦(å¥/S) |\n| :----------------------------------------------------------------------------------------: | :---: | :---: | :------: | :------: | :------: | :------: | :--------: |\n|   [ğŸ¤—Base](https://huggingface.co/LTP/base) [ğŸ—œBase](http://39.96.43.154/ltp/v4/base.tgz)   | 98.7  | 98.5  |   95.4   |   80.6   |   89.5   |   75.2   |   39.12    |\n| [ğŸ¤—Base1](https://huggingface.co/LTP/base1) [ğŸ—œBase1](http://39.96.43.154/ltp/v4/base1.tgz) | 99.22 | 98.73 |  96.39   |  79.28   |  89.57   |  76.57   |   --.--    |\n| [ğŸ¤—Base2](https://huggingface.co/LTP/base2) [ğŸ—œBase2](http://39.96.43.154/ltp/v4/base2.tgz) | 99.18 | 98.69 |  95.97   |  79.49   |  90.19   |  76.62   |   --.--    |\n| [ğŸ¤—Small](https://huggingface.co/LTP/small) [ğŸ—œSmall](http://39.96.43.154/ltp/v4/small.tgz) | 98.4  | 98.2  |   94.3   |   78.4   |   88.3   |   74.7   |   43.13    |\n|   [ğŸ¤—Tiny](https://huggingface.co/LTP/tiny) [ğŸ—œTiny](http://39.96.43.154/ltp/v4/tiny.tgz)   | 96.8  | 97.1  |   91.6   |   70.9   |   83.8   |   70.1   |   53.22    |\n\n|                                 æ„ŸçŸ¥æœºç®—æ³•æ¨¡å‹(ğŸ¤—HF/ğŸ—œ å‹ç¼©åŒ…)                                  | åˆ†è¯  | è¯æ€§  | å‘½åå®ä½“ | é€Ÿåº¦(å¥/s) |              å¤‡æ³¨              |\n| :--------------------------------------------------------------------------------------------: | :---: | :---: | :------: | :--------: | :----------------------------: |\n| [ğŸ¤—Legacy](https://huggingface.co/LTP/legacy) [ğŸ—œLegacy](http://39.96.43.154/ltp/v4/legacy.tgz) | 97.93 | 98.41 |  94.28   |  21581.48  | [æ€§èƒ½è¯¦æƒ…](rust/ltp/README.md) |\n\n**æ³¨ï¼šæ„ŸçŸ¥æœºç®—æ³•é€Ÿåº¦ä¸ºå¼€å¯ 16 çº¿ç¨‹é€Ÿåº¦**\n\n### å¦‚ä½•ä¸‹è½½å¯¹åº”çš„æ¨¡å‹\n\n```bash\n# ä½¿ç”¨ HTTP é“¾æ¥ä¸‹è½½\n# ç¡®ä¿å·²å®‰è£… git-lfs (https://git-lfs.com)\ngit lfs install\ngit clone https://huggingface.co/LTP/base\n\n# ä½¿ç”¨ ssh ä¸‹è½½\n# ç¡®ä¿å·²å®‰è£… git-lfs (https://git-lfs.com)\ngit lfs install\ngit clone git@hf.co:LTP/base\n\n# ä¸‹è½½å‹ç¼©åŒ…\nwget http://39.96.43.154/ltp/v4/base.tgz\ntar -zxvf base.tgz -C base\n```\n\n### å¦‚ä½•ä½¿ç”¨ä¸‹è½½çš„æ¨¡å‹\n\n```python\nfrom ltp import LTP\n\n# åœ¨è·¯å¾„ä¸­ç»™å‡ºæ¨¡å‹ä¸‹è½½æˆ–è§£å‹åçš„è·¯å¾„\n# ä¾‹å¦‚ï¼šbase æ¨¡å‹çš„æ–‡ä»¶å¤¹è·¯å¾„ä¸º \"path/to/base\"\n#      \"path/to/base\" ä¸‹åº”å½“å­˜åœ¨ \"config.json\"\nltp = LTP(\"path/to/base\")\n```\n\n## æ„å»º Wheel åŒ…\n\n```shell script\nmake bdist\n```\n\n## å…¶ä»–è¯­è¨€ç»‘å®š\n\n**æ„ŸçŸ¥æœºç®—æ³•**\n\n- [Rust](rust/ltp)\n- [C/C++](rust/ltp-cffi)\n\n**æ·±åº¦å­¦ä¹ ç®—æ³•**\n\n- [Rust](https://github.com/HIT-SCIR/libltp/tree/master/ltp-rs)\n- [C++](https://github.com/HIT-SCIR/libltp/tree/master/ltp-cpp)\n- [Java](https://github.com/HIT-SCIR/libltp/tree/master/ltp-java)\n\n## ä½œè€…ä¿¡æ¯\n\n- è½¦ä¸‡ç¿” \\<\\<[car@ir.hit.edu.cn](mailto:car@ir.hit.edu.cn)>>\n- å†¯äº‘é¾™ \\<\\<[ylfeng@ir.hit.edu.cn](mailto:ylfeng@ir.hit.edu.cn)>>\n\n## å¼€æºåè®®\n\n1. è¯­è¨€æŠ€æœ¯å¹³å°é¢å‘å›½å†…å¤–å¤§å­¦ã€ä¸­ç§‘é™¢å„ç ”ç©¶æ‰€ä»¥åŠä¸ªäººç ”ç©¶è€…å…è´¹å¼€æ”¾æºä»£ç ï¼Œä½†å¦‚ä¸Šè¿°æœºæ„å’Œä¸ªäººå°†è¯¥å¹³å°ç”¨äºå•†ä¸šç›®çš„ï¼ˆå¦‚ä¼ä¸šåˆä½œé¡¹ç›®ç­‰ï¼‰åˆ™éœ€è¦ä»˜è´¹ã€‚\n2. é™¤ä¸Šè¿°æœºæ„ä»¥å¤–çš„ä¼äº‹ä¸šå•ä½ï¼Œå¦‚ç”³è¯·ä½¿ç”¨è¯¥å¹³å°ï¼Œéœ€ä»˜è´¹ã€‚\n3. å‡¡æ¶‰åŠä»˜è´¹é—®é¢˜ï¼Œè¯·å‘é‚®ä»¶åˆ° car@ir.hit.edu.cn æ´½å•†ã€‚\n4. å¦‚æœæ‚¨åœ¨ LTP åŸºç¡€ä¸Šå‘è¡¨è®ºæ–‡æˆ–å–å¾—ç§‘ç ”æˆæœï¼Œè¯·æ‚¨åœ¨å‘è¡¨è®ºæ–‡å’Œç”³æŠ¥æˆæœæ—¶å£°æ˜â€œä½¿ç”¨äº†å“ˆå·¥å¤§ç¤¾ä¼šè®¡ç®—ä¸ä¿¡æ¯æ£€ç´¢ç ”ç©¶ä¸­å¿ƒç ”åˆ¶çš„è¯­è¨€æŠ€æœ¯å¹³å°ï¼ˆLTPï¼‰â€.\n   åŒæ—¶ï¼Œå‘ä¿¡ç»™car@ir.hit.edu.cnï¼Œè¯´æ˜å‘è¡¨è®ºæ–‡æˆ–ç”³æŠ¥æˆæœçš„é¢˜ç›®ã€å‡ºå¤„ç­‰ã€‚\n"
        },
        {
          "name": "appveyor.yml",
          "type": "blob",
          "size": 0.798828125,
          "content": "branches:\n  only:\n    - 3.X\n\nenvironment:\n  P: \"c:/projects/libs\"\n\n# clone directory\nclone_folder: c:\\projects\\ltp\n\nos: Visual Studio 2015\n\nplatform:\n  - x86\n  - x64\n\nconfiguration:\n  - Debug\n  - Release\n\ninstall:\n  # by default, all script lines are interpreted as batch\n\nbuild:\n  project: ALL_BUILD.vcxproj # path to Visual Studio solution or project\n\n# scripts to run before build\nbefore_build:\n  - echo Running cmake...\n  - cd c:\\projects\\ltp\n  - cmake -G \"Visual Studio 14 2015 Win64\" -DCMAKE_INSTALL_PREFIX=%P%\n\nafter_build:\n  - cd c:\\projects\\ltp\n  - 7z a ltp-win-%PLATFORM%-%CONFIGURATION%.zip bin\\examples\\%CONFIGURATION%\\*_cmdline.exe bin\\%CONFIGURATION%\\ltp_test.exe lib\\%CONFIGURATION%\\*.dll\n\nartifacts:\n  - path: ltp-win-$(platform)-$(configuration).zip\n    name: ltp-win-$(platform)-$(configuration).zip\n"
        },
        {
          "name": "data",
          "type": "tree",
          "content": null
        },
        {
          "name": "python",
          "type": "tree",
          "content": null
        },
        {
          "name": "rust",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}