{
  "metadata": {
    "timestamp": 1736561065621,
    "page": 853,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjg2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "PeterDing/iScript",
      "stars": 5038,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.53125,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nenv/\nbin/\nbuild/\ndevelop-eggs/\ndist/\neggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\n*.egg-info/\n.installed.cfg\n*.egg\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.cache\nnosetests.xml\ncoverage.xml\n\n# Translations\n*.mo\n\n# Mr Developer\n.mr.developer.cfg\n.project\n.pydevproject\n\n# Rope\n.ropeproject\n\n# Django stuff:\n*.log\n*.pot\n\n# Sphinx documentation\ndocs/_build/\n\n"
        },
        {
          "name": "115.py",
          "type": "blob",
          "size": 16.3369140625,
          "content": "#!/usr/bin/env python2\n# vim: set fileencoding=utf8\n\nimport os\nimport sys\nfrom getpass import getpass\nimport requests\nimport urllib\nimport json\nimport re\nimport time\nimport argparse\nimport random\nimport sha\nimport select\n\n############################################################\n# wget exit status\nwget_es = {\n    0: \"No problems occurred.\",\n    2: \"User interference.\",\n    1<<8: \"Generic error code.\",\n    2<<8: \"Parse error - for instance, when parsing command-line \" \\\n        \"optio.wgetrc or .netrc...\",\n    3<<8: \"File I/O error.\",\n    4<<8: \"Network failure.\",\n    5<<8: \"SSL verification failure.\",\n    6<<8: \"Username/password authentication failure.\",\n    7<<8: \"Protocol errors.\",\n    8<<8: \"Server issued an error response.\"\n}\n############################################################\n\n# file extensions\nmediatype = [\n    \".wma\", \".wav\", \".mp3\", \".aac\", \".ra\", \".ram\", \".mp2\", \".ogg\", \".aif\",\n    \".mpega\", \".amr\", \".mid\", \".midi\", \".m4a\", \".m4v\", \".wmv\", \".rmvb\",\n    \".mpeg4\", \".mpeg2\", \".flv\", \".avi\", \".3gp\", \".mpga\", \".qt\", \".rm\",\n    \".wmz\", \".wmd\", \".wvx\", \".wmx\", \".wm\", \".swf\", \".mpg\", \".mp4\", \".mkv\",\n    \".mpeg\", \".mov\", \".mdf\", \".iso\", \".asf\"\n]\n\ns = '\\x1b[%d;%dm%s\\x1b[0m'       # terminual color template\n\ncookie_file = os.path.join(os.path.expanduser('~'), '.115.cookies')\n\nheaders = {\n    \"Accept\":\"Accept: application/json, text/javascript, */*; q=0.01\",\n    \"Accept-Encoding\":\"text/html\",\n    \"Accept-Language\":\"en-US,en;q=0.8,zh-CN;q=0.6,zh;q=0.4,zh-TW;q=0.2\",\n    \"Content-Type\":\"application/x-www-form-urlencoded; charset=UTF-8\",\n    \"Referer\":\"http://m.115.com/\",\n    \"X-Requested-With\": \"XMLHttpRequest\",\n    \"User-Agent\":\"Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.36 \"\\\n        \"(KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n}\n\nss = requests.session()\nss.headers.update(headers)\n\nclass pan115(object):\n    def __init__(self):\n        self.download = self.play if args.play else self.download\n\n    def init(self):\n        if os.path.exists(cookie_file):\n            try:\n                t = json.loads(open(cookie_file).read())\n                ss.cookies.update(t.get('cookies', t))\n                if not self.check_login():\n                    print s % (1, 91, '  !! cookie is invalid, please login\\n')\n                    sys.exit(1)\n                self.check_vip()\n            except:\n                g = open(cookie_file, 'w')\n                g.close()\n                print s % (1, 97, '  please login')\n                sys.exit(1)\n        else:\n            print s % (1, 91, '  !! cookie_file is missing, please login')\n            sys.exit(1)\n\n    def check_vip(self):\n        url = 'http://vip.115.com/?ac=mycouponcount'\n        r = ss.get(url).content\n\n        if '\"vip\":0' in r:\n            self.is_vip = False\n        else:\n            self.is_vip = True\n\n    def check_login(self):\n        #print s % (1, 97, '\\n  -- check_login')\n        url = 'http://msg.115.com/?ac=unread'\n        j = ss.get(url)\n        if '\"code\"' not in j.text:\n            #print s % (1, 92, '  -- check_login success\\n')\n            self.save_cookies()\n            return True\n        else:\n            print s % (1, 91, '  -- check_login fail\\n')\n            return False\n\n    def login(self, account, password):\n        print s % (1, 97, '\\n  -- login')\n\n        def get_ssopw(ssoext):\n            p = sha.new(password).hexdigest()\n            a = sha.new(account).hexdigest()\n            t = sha.new(p + a).hexdigest()\n            ssopw = sha.new(t + ssoext.upper()).hexdigest()\n            return ssopw\n\n        ssoext = str(int(time.time()*1000))\n        ssopw = get_ssopw(ssoext)\n\n        quote = urllib.quote\n        data = quote(\"login[ssoent]\")+\"=B1&\" + \\\n            quote(\"login[version]\")+\"=2.0&\" + \\\n            quote(\"login[ssoext]\")+\"=%s&\" % ssoext + \\\n            quote(\"login[ssoln]\")+\"=%s&\" % quote(account) + \\\n            quote(\"login[ssopw]\")+\"=%s&\" % ssopw + \\\n            quote(\"login[ssovcode]\")+\"=%s&\" % ssoext + \\\n            quote(\"login[safe]\")+\"=1&\" + \\\n            quote(\"login[time]\")+\"=1&\" + \\\n            quote(\"login[safe_login]\")+\"=1&\" + \\\n            \"goto=http://m.115.com/?ac=home\"\n\n        theaders = headers\n        theaders[\"Referer\"] = \"http://passport.115.com\\\n            /static/reg_login_130418/bridge.html?ajax_cb_key=bridge_%s\" \\\n            % int(time.time()*1000)\n\n        # Post!\n        # XXX : do not handle errors\n        params = {\n            'ct': 'login',\n            'ac': 'ajax',\n            'is_ssl': 1\n        }\n        url = 'http://passport.115.com'\n        ss.post(url, params=params, data=data, headers=theaders)\n        self.save_cookies()\n\n    def save_cookies(self):\n        with open(cookie_file, 'w') as g:\n            c = {'cookies': ss.cookies.get_dict()}\n            g.write(json.dumps(c, indent=4, sort_keys=True))\n\n    def get_dlink(self, pc):\n        params = {\n            \"pickcode\": pc.encode('utf8'),\n            \"_\": int(time.time()*1000),\n        }\n        url = 'http://web.api.115.com/files/download'\n        r = ss.get(url, params=params)\n        j = r.json()\n        dlink = j['file_url'].encode('utf8')\n        return dlink\n\n    def _get_play_purl(self, pickcode):\n        url = 'http://115.com/api/video/m3u8/%s.m3u8' % pickcode\n        r = ss.get(url)\n        c = r.content.strip()\n\n        if c:\n            purl = c.split()[-1]\n            if 'http' not in purl:\n                return None\n            else:\n                return purl\n        else:\n            return None\n\n    def get_infos(self, cid):\n        params = {\n            \"cid\": cid,\n            \"offset\": 0,\n            \"type\": \"\",\n            \"limit\": 10000,\n            \"format\": \"json\",\n            \"aid\": 1,\n            \"o\": \"file_name\",\n            \"asc\": 0,\n            \"show_dir\": 1\n        }\n\n        url = 'http://web.api.115.com/files'\n        j = ss.get(url, params=params).json()\n\n        dir_loop1 = [{'dir': j['path'][-1]['name'], 'cid': j['cid']}]\n        dir_loop2 = []\n        #base_dir = os.getcwd()\n        while dir_loop1:\n            for d in dir_loop1:\n                params['cid'] = d['cid']\n                j = ss.get(url, params=params).json()\n                if j['errNo'] == 0 and j['data']:\n                    if args.type_:\n                        j['data'] = [\n                            x for x in j['data'] \\\n                            if x.get('ns') \\\n                                or x['ico'].lower() == unicode(args.type_.lower())\n                        ]\n\n                    for i in j['data']:\n                        if i.get('ns'):\n                            item = {\n                                'dir': os.path.join(d['dir'], i['ns']),\n                                'cid': i['cid']\n                            }\n                            dir_loop2.append(item)\n\n                    if args.play:\n                        j['data'] = [\n                            i for i in j['data'] \\\n                            if i.get('sha') \\\n                                and os.path.splitext(i['n'])[-1].lower() \\\n                                in mediatype\n                        ]\n\n                    total_file = len([i for i in j['data'] if not i.get('ns')])\n                    if args.from_ - 1:\n                        j['data'] = j['data'][args.from_-1:] if args.from_ \\\n                                                                else j['data']\n                    nn = args.from_\n                    for i in j['data']:\n                        if not i.get('ns'):\n                            t = i['n']\n                            t =  os.path.join(d['dir'], t).encode('utf8')\n                            t =  os.path.join(os.getcwd(), t)\n                            infos = {\n                                'file': t,\n                                'dir_': os.path.split(t)[0],\n                                'dlink': self.get_dlink(i['pc']),\n                                'name': i['n'].encode('utf8'),\n                                #'purl': self._get_play_purl(\n                                #   i['pc'].encode('utf8')) \\\n                                #       if args.play and self.is_vip else None,\n                                'purl': self._get_play_purl(\n                                    i['pc'].encode('utf8')) \\\n                                        if args.play else None,\n                                'nn': nn,\n                                'total_file': total_file\n                            }\n                            nn += 1\n                            self.download(infos)\n                else:\n                    print s % (1, 91, '  error: get_infos')\n                    sys.exit(0)\n            dir_loop1 = dir_loop2\n            dir_loop2 = []\n\n\n    @staticmethod\n    def download(infos):\n        ## make dirs\n        if not os.path.exists(infos['dir_']):\n            os.makedirs(infos['dir_'])\n        else:\n            if os.path.exists(infos['file']):\n                return 0\n\n        num = random.randint(0, 7) % 8\n        col = s % (2, num + 90, infos['file'])\n        infos['nn'] = infos['nn'] if infos.get('nn') else 1\n        infos['total_file'] = infos['total_file'] \\\n            if infos.get('total_file') else 1\n        print '\\n  ++ 正在下载: #', \\\n            s % (1, 97, infos['nn']), \\\n            '/', s % (1, 97, infos['total_file']), \\\n            '#', col\n\n        if args.aria2c:\n            # 115 普通用户只能有4下载通道。\n            quiet = ' --quiet=true' if args.quiet else ''\n            taria2c = ' -x %s -s %s' % (args.aria2c, args.aria2c)\n            tlimit = ' --max-download-limit %s' \\\n                % args.limit if args.limit else ''\n            cmd = 'aria2c -c%s%s%s ' \\\n                '-m 0 ' \\\n                '-o \"%s.tmp\" -d \"%s\" ' \\\n                '--user-agent \"%s\" ' \\\n                '--header \"Referer:http://m.115.com/\" \"%s\"' \\\n                % (quiet, taria2c, tlimit, infos['name'], infos['dir_'],\\\n                    headers['User-Agent'], infos['dlink'])\n        else:\n            tlimit = ' --limit-rate %s' % args.limit if args.limit else ''\n            cmd = 'wget -c%s ' \\\n                '-O \"%s.tmp\" --user-agent \"%s\" ' \\\n                '--header \"Referer:http://m.115.com/\" \"%s\"' \\\n                % (tlimit, infos['file'], headers['User-Agent'],\n                   infos['dlink'])\n\n        status = os.system(cmd)\n        if status != 0:     # other http-errors, such as 302.\n            wget_exit_status_info = wget_es[status]\n            print('\\n\\n ---###   \\x1b[1;91mERROR\\x1b[0m ==> '\\\n                '\\x1b[1;91m%d (%s)\\x1b[0m   ###--- \\n\\n' \\\n                 % (status, wget_exit_status_info))\n            print s % (1, 91, '  ===> '), cmd\n            sys.exit(1)\n        else:\n            os.rename('%s.tmp' % infos['file'], infos['file'])\n\n    @staticmethod\n    def play(infos):\n        num = random.randint(0, 7) % 8\n        col = s % (2, num + 90, infos['name'])\n        infos['nn'] = infos['nn'] if infos.get('nn') else 1\n        infos['total_file'] = infos['total_file'] \\\n            if infos.get('total_file') else 1\n        print '\\n  ++ play: #', \\\n            s % (1, 97, infos['nn']), '/', \\\n            s % (1, 97, infos['total_file']), \\\n            '#', col\n\n        if not infos['purl']:\n            print s % (1, 91, '  |-- m3u8 is not ready, using dlink')\n            infos['purl'] = infos['dlink']\n\n        cmd = 'mpv --really-quiet --cache 8140 --cache-default 8140 ' \\\n            '--http-header-fields \"user-agent:%s\" '\\\n            '--http-header-fields \"Referer:http://m.115.com\" \"%s\"' \\\n            % (headers['User-Agent'], infos['purl'])\n\n        status = os.system(cmd)\n        timeout = 1\n        ii, _, _ = select.select([sys.stdin], [], [], timeout)\n        if ii:\n            sys.exit(0)\n        else:\n            pass\n\n    # TODO\n    def exists(self, filepath):\n        pass\n\n    # TODO\n    def upload(self, path, dir_):\n        pass\n\n    def addtask(self, u):\n        # get uid\n        url = 'http://my.115.com/?ct=ajax&ac=get_user_aq'\n        r = ss.get(url)\n        j = r.json()\n        uid = j['data']['uid']\n\n        # get sign, time\n        url = 'http://115.com/?ct=offline&ac=space'\n        r = ss.get(url)\n        j = r.json()\n        sign = j['sign']\n        tm = j['time']\n\n        # now, add task\n        data = {\n            'url': urllib.quote_plus(u),\n            'uid': uid,\n            'sign': sign,\n            'time': str(tm)\n        }\n        url = 'http://115.com/lixian/?ct=lixian&ac=add_task_url'\n        r = ss.post(url, data=data)\n        if not r.ok:\n            print s % (1, 91, '  !! Error at addtask')\n            print r.content\n            sys.exit(1)\n\n        j = r.json()\n        if j['info_hash']:\n            print s % (1, 92, '  ++ add task success.')\n        else:\n            print s % (2, 91, '  !! Error: %s' % j['error_msg'])\n            sys.exit()\n\n        data = {\n            'page': 1,\n            'uid': uid,\n            'sign': sign,\n            'time': str(tm)\n        }\n        url = 'http://115.com/lixian/?ct=lixian&ac=task_lists'\n        r = ss.post(url, data=data)\n        j = r.json()\n        percentDone = j['tasks'][0]['percentDone']\n        print s % (1, 97, '  ++ %s' % j['tasks'][0]['name'])\n        print s % (1, 92, '  %s%s Done' % (percentDone, '%'))\n\n    def do(self, pc):\n        dlink = self.get_dlink(pc)\n        name = re.search(r'/([^/]+?)\\?', dlink).group(1)\n        name = urllib.unquote_plus(name)\n        t = os.path.join(os.getcwd(), name)\n        infos = {\n            'file': t,\n            'dir_': os.path.split(t)[0],\n            'dlink': dlink,\n            #'purl': self._get_play_purl(pc) \\\n            #   if args.play and self.is_vip else None,\n            'purl': self._get_play_purl(pc) if args.play else None,\n            'name': name,\n            'nn': 1,\n            'total_file': 1\n        }\n        self.download(infos)\n\ndef main(argv):\n    if len(argv) <= 1:\n        sys.exit()\n\n    ######################################################\n    # for argparse\n    p = argparse.ArgumentParser(\n        description='download from 115.com reversely')\n    p.add_argument('xxx', type=str, nargs='*', \\\n        help='命令对象.')\n    p.add_argument('-a', '--aria2c', action='store', default=None, \\\n        type=int, help='aria2c分段下载数量')\n    p.add_argument('-p', '--play', action='store_true', \\\n        help='play with mpv')\n    p.add_argument('-q', '--quiet', action='store_true', \\\n                   help='quiet for download and play')\n    p.add_argument('-f', '--from_', action='store', \\\n        default=1, type=int, \\\n        help='从第几个开始下载，eg: -f 42')\n    p.add_argument('-t', '--type_', action='store', \\\n        default=None, type=str, \\\n        help='要下载的文件的后缀，eg: -t mp3')\n    p.add_argument('-l', '--limit', action='store', \\\n        default=None, type=str, help='下载速度限制，eg: -l 100k')\n    p.add_argument('-d', '--addtask', action='store_true', \\\n        help='加离线下载任务')\n    global args\n    args = p.parse_args(argv[1:])\n    xxx = args.xxx\n\n    if xxx[0] == 'login' or xxx[0] == 'g':\n        if len(xxx[1:]) < 1:\n            account = raw_input(s % (1, 97, ' account: '))\n            password = getpass(s % (1, 97, 'password: '))\n        elif len(xxx[1:]) == 1:\n            account = xxx[1]\n            password = getpass(s % (1, 97, '  password: '))\n        elif len(xxx[1:]) == 2:\n            account = xxx[1]\n            password = xxx[2]\n        else:\n            print s % (1, 91, '  login\\n  login account\\n  \\\n                                 login account password')\n\n        x = pan115()\n        x.login(account, password)\n        is_signin = x.check_login()\n        if is_signin:\n            print s % (1, 92, '  ++ login succeeds.')\n        else:\n            print s % (1, 91, '  login failes')\n\n    elif xxx[0] == 'signout':\n        g = open(cookie_file, 'w')\n        g.close()\n\n    else:\n        x = pan115()\n        x.init()\n        for url in xxx:\n            if 'pickcode' in url:\n                pc = re.search(r'pickcode=([\\d\\w]+)', url)\n                if pc:\n                    pc = pc.group(1)\n                    x.do(pc)\n                else:\n                    print s % (1, 91, '  can\\'t find pickcode.')\n            elif 'cid=' in url:\n                cid = re.search(r'cid=(\\d+)', url)\n                cid = cid.group(1) if cid else '0'\n                x.get_infos(cid)\n            elif args.addtask:\n                x.addtask(url)\n            else:\n                print s % (2, 91, '  请正确输入自己的115地址。')\n\nif __name__ == '__main__':\n    argv = sys.argv\n    main(argv)\n"
        },
        {
          "name": "91porn.py",
          "type": "blob",
          "size": 5.6357421875,
          "content": "#!/usr/bin/env python2\n# vim: set fileencoding=utf8\n\nimport os\nimport sys\nimport requests\nimport urlparse\nimport re\nimport argparse\nimport random\nimport select\nimport urllib2\n\n############################################################\n# wget exit status\nwget_es = {\n    0: \"No problems occurred.\",\n    2: \"User interference.\",\n    1<<8: \"Generic error code.\",\n    2<<8: \"Parse error - for instance, when parsing command-line \" \\\n        \"optio.wgetrc or .netrc...\",\n    3<<8: \"File I/O error.\",\n    4<<8: \"Network failure.\",\n    5<<8: \"SSL verification failure.\",\n    6<<8: \"Username/password authentication failure.\",\n    7<<8: \"Protocol errors.\",\n    8<<8: \"Server issued an error response.\"\n}\n############################################################\n\ns = '\\x1b[%d;%dm%s\\x1b[0m'       # terminual color template\n\nheaders = {\n    \"Accept\":\"text/html,application/xhtml+xml,application/xml; \" \\\n        \"q=0.9,image/webp,*/*;q=0.8\",\n    \"Accept-Encoding\":\"text/html\",\n    \"Accept-Language\":\"en-US,en;q=0.8,zh-CN;q=0.6,zh;q=0.4,zh-TW;q=0.2\",\n    \"Content-Type\":\"application/x-www-form-urlencoded\",\n    \"User-Agent\":\"Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.36 \" \\\n        \"(KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n}\n\nss = requests.session()\nss.headers.update(headers)\n\nclass nrop19(object):\n    def __init__(self, url=None):\n        self.url = url\n        self.download = self.play if args.play else self.download\n\n    def get_infos(self):\n        r = ss.get(self.url)\n        if r.ok:\n            n1 = re.search(r'so.addVariable\\(\\'file\\',\\'(\\d+)\\'', r.content)\n            n2 = re.search(r'so.addVariable\\(\\'seccode\\',\\'(.+?)\\'', r.content)\n            n3 = re.search(r'so.addVariable\\(\\'max_vid\\',\\'(\\d+)\\'', r.content)\n\n            if n1 and n2 and n3:\n                apiurl = 'http://%s/getfile.php' \\\n                    % urlparse.urlparse(self.url).hostname\n\n                params = {\n                    'VID': n1.group(1),\n                    'mp4': '1',\n                    'seccode': n2.group(1),\n                    'max_vid': n3.group(1),\n                }\n\n                #tapiurl = apiurl + '?' + \\\n                    #'&'.join(['='.join(item) for item in params.items()])\n                #print tapiurl\n\n                r = requests.get(apiurl, params=params)\n                if r.ok:\n                    dlink = re.search(\n                        r'file=(http.+?)&', r.content).group(1)\n                    dlink = urllib2.unquote(dlink)\n                    name = re.search(\n                        r'viewkey=([\\d\\w]+)', self.url).group(1)\n                    infos = {\n                        'name': '%s.mp4' % name,\n                        'file': os.path.join(os.getcwd(), '%s.mp4' % name),\n                        'dir_': os.getcwd(),\n                        'dlink': dlink,\n                    }\n                    if not args.get_url:\n                        self.download(infos)\n                    else:\n                        print dlink\n                else:\n                    print s % (1, 91, '  Error at get(apiurl)')\n            else:\n                print s % (1, 91, '  You are blocked')\n\n    def download(self, infos):\n        num = random.randint(0, 7) % 7\n        col = s % (2, num + 90, infos['file'])\n        print '\\n  ++ 正在下载: %s' % col\n\n        cookies = '; '.join(\n            ['%s=%s' % (i, ii) for i, ii in ss.cookies.items()])\n        if args.aria2c:\n            cmd = 'aria2c -c -x10 -s10 ' \\\n                '-o \"%s.tmp\" -d \"%s\" --header \"User-Agent: %s\" ' \\\n                '--header \"Cookie: %s\" \"%s\"' \\\n                % (infos['name'], infos['dir_'], \\\n                headers['User-Agent'], cookies, infos['dlink'])\n        else:\n            cmd = 'wget -c -O \"%s.tmp\" --header \"User-Agent: %s\" ' \\\n                '--header \"Cookie: %s\" \"%s\"' \\\n                % (infos['file'], headers['User-Agent'], cookies, infos['dlink'])\n\n        status = os.system(cmd)\n        if status != 0:     # other http-errors, such as 302.\n            wget_exit_status_info = wget_es[status]\n            print('\\n\\n ----###   \\x1b[1;91mERROR\\x1b[0m ==> '\\\n                '\\x1b[1;91m%d (%s)\\x1b[0m   ###--- \\n\\n' \\\n                % (status, wget_exit_status_info))\n            print s % (1, 91, '  ===> '), cmd\n            sys.exit(1)\n        else:\n            os.rename('%s.tmp' % infos['file'], infos['file'])\n\n    def play(self, infos):\n        num = random.randint(0, 7) % 7\n        col = s % (2, num + 90, infos['name'])\n        print '\\n  ++ play: %s' % col\n\n        cmd = 'mpv --really-quiet --cache 8140 --cache-default 8140 ' \\\n            '--http-header-fields \"user-agent:%s\" \"%s\"' \\\n            % (headers['User-Agent'], infos['dlink'])\n\n        os.system(cmd)\n        timeout = 1\n        ii, _, _ = select.select([sys.stdin], [], [], timeout)\n        if ii:\n            sys.exit(0)\n        else:\n            pass\n\n    def do(self):\n        self.get_infos()\n\ndef main(url):\n    if args.proxy:\n        ss.proxies = {\n            'http': args.proxy,\n            'https': args.proxy\n        }\n    x = nrop19(url)\n    x.do()\n\nif __name__ == '__main__':\n    p = argparse.ArgumentParser(\n        description='download from 91porn.com')\n    p.add_argument('url', help='url of 91porn.com')\n    p.add_argument('-a', '--aria2c', action='store_true', \\\n                help='download with aria2c')\n    p.add_argument('-p', '--play', action='store_true', \\\n                help='play with mpv')\n    p.add_argument('-u', '--get_url', action='store_true', \\\n                help='print download_url without download')\n    p.add_argument('--proxy', action='store', type=str, default=None, \\\n                help='print download_url without download')\n    args = p.parse_args()\n    main(args.url)\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0498046875,
          "content": "The MIT License (MIT)\n\nCopyright (c) 2014 PeterDing\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE."
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 41.73828125,
          "content": "# iScript\n\n## pan.baidu.com.py 已经重构，不再维护\n\n[**BaiduPCS-Py**](https://github.com/PeterDing/BaiduPCS-Py) 是 pan.baidu.com.py 的重构版，运行在 Python >= 3.6\n\n[![Join the chat at https://gitter.im/PeterDing/iScript](https://badges.gitter.im/PeterDing/iScript.svg)](https://gitter.im/PeterDing/iScript?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\n> *[L]* *[W]* *[LW]* 分别表示，在linux, windows, linux和windows 下通过测试。\n\n\n> ***windows用户可在babun (https://github.com/babun/babun) 下运行。***\n\n\n*[L]* - [leetcode_problems.py](#leetcode_problems.py) - 下载Leetcode的算法题  \n*[L]* - [xiami.py](#xiami.py) - 下载或播放高品质虾米音乐(xiami.com)  \n*[L]* - [pan.baidu.com.py](#pan.baidu.com.py) - 百度网盘的下载、离线下载、上传、播放、转存、文件操作  \n*[L]* - [bt.py](#bt.py) - magnet torrent 互转、及 过滤敏.感.词  \n*[L]* - [115.py](#115.py) - 115网盘的下载和播放  \n*[L]* -  [yunpan.360.cn.py](#yunpan.360.cn.py) - 360网盘的下载  \n*[L]* - [music.baidu.com.py](#music.baidu.com.py) - 下载或播放高品质百度音乐(music.baidu.com)  \n*[L]* - [music.163.com.py](#music.163.com.py) - 下载或播放高品质网易音乐(music.163.com)  \n*[L]* - [flv_cmd.py](#flv_cmd.py) - 基于在线服务的视频解析 client - 支持下载、播放  \n*[L]* - [tumblr.py](#tumblr.py) - 下载某个tumblr.com的所有图片、视频、音频  \n*[L]* - [unzip.py](#unzip.py) - 解决linux下unzip乱码的问题  \n*[L]* - [ed2k_search.py](#ed2k_search.py) - 基于 donkey4u.com 的emule搜索  \n*[L]* - [91porn.py](#91porn.py) - 下载或播放91porn  \n*[L]* - [ThunderLixianExporter.user.js](#ThunderLixianExporter.user.js) -  A fork of https://github.com/binux/ThunderLixianExporter - 增加了mpv和mplayer的导出。  \n\n---\n\n<a name=\"leetcode_problems.py\"></a>\n### leetcode_problems.py - 下载Leetcode的算法题\n\n#### 依赖\n\n```\npython2-requests (https://github.com/kennethreitz/requests)\n\npython2-lxml\n\n```\n\n#### 参数:\n\n```\n  --index           sort by index\n  --level           sort by level\n  --tag             sort by tag\n  --title           sort by title\n  --rm_blank        移除题中的空行\n  --line LINE       两题之间的空行\n  -r, --redownload  重新下载数据\n```\n\n下载的数据保持在 ./leecode_problems.pk\n转成的txt在 './leecode problems.txt'\n\n---\n\n<a name=\"xiami.py\"></a>\n### xiami.py - 下载或播放高品质虾米音乐(xiami.com)\n\n#### 1. 依赖\n\n```\nwget\n\npython2-requests (https://github.com/kennethreitz/requests)\n\npython2-mutagen (https://code.google.com/p/mutagen/)\n\nmpv (http://mpv.io)\n```\n\n#### 2. 使用说明\n\nxiami.py 是一个虾米音乐的命令行(CLI)客户端。提供登录、下载、播放、收藏的功能。\n\n**提供对[落网 luoo.net](http://www.luoo.net)的分析**\n\n初次使用需要登录 xm login  (原xiami账号)\n\n~~**支持淘宝账户**    xm logintaobao~~\n\n~~**对于淘宝账户，登录后只保存有关虾米的cookies，删除了有关淘宝的cookies**~~\n\n**淘宝登录加密算法无法破解，需要手动获取cookies (方法见下 手动添加cookie登录)**\n\n**vip账户**支持高品质音乐的下载和播放。\n\n**原虾米vip用户如果不能获得高品质音乐，请用关联的淘宝帐号登录。**\n\n下载的MP3默认添加id3 tags，保存在当前目录下。\n\ncookies保存在 ~/.Xiami.cookies。\n\n关于播放操作:\n\n> 在运行脚本的终端，输入1次Enter，关闭当前播放并播放下一个文件，连续输入2次Enter，关闭当前播放并退出。\n\n#### 命令:\n\n```\n# 虾米账号登录\ng\nlogin\nlogin username\nlogin username password\n\nsignout                      # 退出登录\n\nd 或 download url1 url2      # 下载\np 或 play  url1 url2         # 播放\ns 或 save  url1 url2         # 收藏\n```\n\n#### 参数:\n\n```\n-p, --play                 按顺序播放\n-pp                        按歌曲被播放的次数，从高到低播放\n-l, --low                  低品质mp3\n-d, --undescription        不加入disk的描述\n-f num, --from_ num        从第num个开始\n-t TAGS, --tags TAGS       收藏用的tags,用英文逗号分开, eg: -t piano,cello,guitar\n-n, --undownload           不下载,用于修改已存在的MP3的id3 tags\n```\n\n#### 3. 用法\n\nxm 是xiami.py的马甲 (alias xm='python2 /path/to/xiami.py')\n\n```\n# 登录\nxm g\nxm login\nxm login username\nxm login username password\n\n# 手动添加cookie登录\n1. 用浏览器登录后，按F12，然后访问 https://www.xiami.com/album/123456\n2. 选择‘网络’或network，找到 123456，在其中找到 Cookie: xxx\n3. 然后在终端运行 xm g \"xxx\"\n\n# 退出登录\nxm signout\n\n# 下载专辑\nxm d http://www.xiami.com/album/168709?spm=a1z1s.6928801.1561534521.114.ShN6mD\n\n# 下载单曲\nxm d http://www.xiami.com/song/2082998?spm=a1z1s.6659513.0.0.DT2j7T\n\n# 下载精选集\nxm d http://www.xiami.com/song/showcollect/id/30374035?spm=a1z1s.3061701.6856305.16.fvh75t\n\n# 下载该艺术家所有专辑, Top 20 歌曲, radio\nxm d http://www.xiami.com/artist/23460?spm=a1z1s.6928801.1561534521.115.ShW08b\n\n# 下载用户的收藏, 虾米推荐, radio, 推荐\nxm d http://www.xiami.com/u/141825?spm=a1z1s.3521917.0.0.zI0APP\n\n# 下载排行榜\nxm d http://www.xiami.com/chart/index/c/2?spm=a1z1s.2943549.6827465.6.VrEAoY\n\n# 下载 风格 genre, radio\nxm d http://www.xiami.com/genre/detail/gid/2?spm=a1z1s.3057857.6850221.1.g9ySan\nxm d http://www.xiami.com/genre/detail/sid/2970?spm=a1z1s.3057857.6850221.4.pkepgt\n\n# 下载 widget (虾米播播)\nxm d http://www.xiami.com/widget/player-multi?uid=4350663&sid=1774531852,378713,3294421,1771778464,378728,378717,378727,1773346501,&width=990&height=346&mainColor=e29833&backColor=60362a&widget_from=4350663\n\n# 下载落网期刊\n# 分析落网期刊的音乐后，在虾米上搜索并下载\nxm d http://www.luoo.net/music/706\n```\n\n#### 播放:\n\n```\n# url 是上面的\nxm p url\n```\n\n#### 收藏:\n\n```\nxm s http://www.xiami.com/album/168709?spm=a1z1s.6928801.1561534521.114.ShN6mD\nxm s -t 'tag1,tag 2,tag 3' http://www.xiami.com/song/2082998?spm=a1z1s.6659513.0.0.DT2j7T\nxm s http://www.xiami.com/song/showcollect/id/30374035?spm=a1z1s.3061701.6856305.16.fvh75t\nxm s http://www.xiami.com/artist/23460?spm=a1z1s.6928801.1561534521.115.ShW08b\n```\n\n#### 4. 参考:\n\n> http://kanoha.org/2011/08/30/xiami-absolute-address/\n\n\n> http://www.blackglory.me/xiami-vip-audition-with-no-quality-difference-between-downloading/\n\n\n> https://gist.github.com/lepture/1014329\n\n\n> 淘宝登录代码: https://github.com/ly0/xiami-tools\n\n---\n\n<a name=\"pan.baidu.com.py\"></a>\n### pan.baidu.com.py - 百度网盘的下载、离线下载、上传、播放、转存、文件操作\n\n**pan.baidu.com.py 已经重构，不再维护**\n\n[**BaiduPCS-Py**](https://github.com/PeterDing/BaiduPCS-Py) 是 pan.baidu.com.py 的重构版，运行在 Python >= 3.6\n\n#### 1. 依赖\n\n```\nwget\n\naria2  (~ 1.18)\n\naget-rs (https://github.com/PeterDing/aget-rs/releases)\n\npip2 install rsa pyasn1 requests requests-toolbelt\n\nmpv (http://mpv.io)\n\n# 可选依赖\nshadowsocks  # 用于加密上传。\n             # 用 python2 的 pip 安装\npip2 install shadowsocks\n\n# 除了用pip安装包，还可以手动:\nhttps://github.com/PeterDing/iScript/wiki/%E6%89%8B%E5%8A%A8%E8%A7%A3%E5%86%B3pan.baidu.com.py%E4%BE%9D%E8%B5%96%E5%8C%85\n```\n\n#### other\n\n[尝试解决百度网盘下载速度问题](https://github.com/PeterDing/iScript/wiki/解决百度网盘下载速度问题)\n\n#### 2. 使用说明\n\npan.baidu.com.py 是一个百度网盘的命令行客户端。\n\n初次使用需要登录 bp login\n\n**支持多帐号登录**\n\n**现在只支持[用cookie登录](#cookie_login)**\n\n**支持cookie登录**\n\n**支持加密上传**, 需要 shadowsocks\n\n**cd, ls 功能完全支持**\n\n**所有路径可以是 相对路径 或 绝对路径**\n\n他人分享的网盘连接，只支持单个的下载。\n\n下载工具默认为wget, 可用参数-a num选用aria2\n\n**支持用 aget 加速下载, 用法见下**\n\n下载的文件，保存在当前目录下。\n\n下载默认为非递归，递归下载加 -R\n\n搜索时，默认在 cwd\n\n搜索支持高亮\n\n上传模式默认是 c (续传)。\n\n**开启证实(verification) 用参数 -V**\n\n理论上，上传的单个文件最大支持 2T\n\ncookies保存在 ~/.bp.cookies\n\n上传数据保存在 ~/.bp.pickle\n\n关于播放操作:\n\n> 在运行脚本的终端，输入1次Enter，关闭当前播放并播放下一个文件，连续输入2次Enter，关闭当前播放并退出。\n\n<a name=\"cmd\"></a>\n#### 命令:\n\n**!!注意：**\n**命令参数中，所有网盘的路径和本地路径可以是 相对路径 或 绝对路径**\n\n```\n# 登录\ng\nlogin\nlogin username\nlogin username password\nlogin username cookie\n\n# 删除帐号\nuserdelete 或 ud\n\n# 切换帐号\nuserchange 或 uc\n\n# 帐号信息\nuser\n\n# 显示当前工作目录\ncwd\n\n# 切换当前工作目录\ncd path    # 支持 ./../...\n\n# 播放\np  或 play url1 url2 path1 path2\n\n# 上传\nu  或 upload localpath remotepath\n\n# 加密上传\nu localpath remotepath [-P password] -t ec -R\n\n# 转存\ns  或 save url remotepath [-s secret]\n\n# 下载\nd  或 download url1 url2 path1 path2           非递归下载 到当前本地目录\nd  或 download url1 url2 path1 path2 -R        递归下载 到当前本地目录\n# !! 注意:\n# d /path/to/download -R       递归下载 *download文件夹* 到当前本地目录\n# d /path/to/download/ -R      递归下载 *download文件夹中的文件* 到当前本地目录\n\n# 下载并解密\nd /path/to/download -R -t dc [-P password] [-m aes-256-cfb]\n\n# 解密已下载的文件\ndc path1 path2 -R [-P password] [-m aes-256-cfb]\n\n# 文件操作\nmd 或 mkdir path1 path2                           创建文件夹\nrn 或 rename path new_path                        重命名\nrm 或 remove path1 path2                          删除\nmv 或 move path1 path2 /path/to/directory         移动\ncp 或 copy path /path/to/directory_or_file        复制\ncp 或 copy path1 path2 /path/to/directory         复制\n\n# 使用正则表达式进行文件操作\nrnr 或 rnre foo bar dir1 dir2 -I re1 re2             重命名文件夹中的文件名\nrmr 或 rmre dir1 dir2 -E re1 re2                     删除文件夹下匹配到的文件\nmvr 或 mvre dir1 dir2 /path/to/dir -H head1 head2    移动文件夹下匹配到的文件\ncpr 或 cpre dir1 dir2 /path/to/dir -T tail1 tail2    复制文件夹下匹配到的文件\n# 递归加 -R\n# rmr, mvr, cpr 中 -t, -I, -E, -H, -T 至少要有一个，放在命令行末尾\n# -I, -E, -H, -T 后可跟多个匹配式\n# 可以用 -t 指定操作的文件类型\n    -t f # 文件\n    -t d # 文件夹\n# rnr 中 foo bar 都是 regex\n# -y, --yes   # 不显示警示，直接进行。  ！！注意，除非你知道你做什么，否则请不要使用。\nrmr / -I '.*' -y    # ！！ 删除网盘中的所有文件\n\n# 回复用bt.py做base64加密的文件\nrnr /path/to/decode1 /path/to/decode2 -t f,bd64\n\n# 搜索\n# directory 必须是绝对路径, 默认是 cwd\nf   或 find keyword1 keyword2 [directory]             非递归搜索\nff  keyword1 keyword2 [directory]                     非递归搜索 反序\nft  keyword1 keyword2 [directory]                     非递归搜索 by time\nftt keyword1 keyword2 [directory]                     非递归搜索 by time 反序\nfs  keyword1 keyword2 [directory]                     非递归搜索 by size\nfss keyword1 keyword2 [directory]                     非递归搜索 by size 反序\nfn  keyword1 keyword2 [directory]                     非递归搜索 by name\nfnn keyword1 keyword2 [directory]                     非递归搜索 by name 反序\n# 递归搜索加 -R\nf 'ice and fire' /doc -R\n# 搜索所有的账户加 -t all\nf keyword1 keyword2 [directory] -t all -R\nf keyword1 keyword2 [directory] -t f,all -R\n# directory 默认为 /\n# 关于-H, -T, -I, -E\n# -I, -E, -H, -T 后可跟多个匹配式, 需要放在命令行末尾\nf keyword1 keyword2 [directory] -H head -T tail -I \"re(gul.*) ex(p|g)ress$\"\nf keyword1 keyword2 [directory] -H head -T tail -E \"re(gul.*) ex(p|g)ress$\"\n# 搜索 加 通道(只支持 donwload, play, rnre, rm, mv)\nf keyword1 keyword2 [directory] \\| d -R              递归搜索后递归下载\nftt keyword1 keyword2 [directory] \\| p -R            递归搜索(by time 反序)后递归播放\nf keyword1 keyword2 [directory] \\| rnr foo bar -R    递归搜索后rename by regex\nf keyword1 keyword2 [directory] \\| rm -R -T tail     递归搜索后删除\nf keyword1 keyword2 [directory] \\| mv /path/to -R    递归搜索后移动\n\n# 列出文件\nl path1 path2                               ls by name\nll path1 path2                              ls by name 反序\nln path1 path2                              ls by name\nlnn path1 path2                             ls by name 反序\nlt path1 path2                              ls by time\nltt path1 path2                             ls by time 反序\nls path1 path2                              ls by size\nlss path1 path2                             ls by size 反序\nl /doc/books /videos\n# 以下是只列出文件或文件夹\nl path1 path2 -t f                         ls files\nl path1 path2 -t d                         ls directorys\n# 关于-H, -T, -I, -E\n# -I, -E, -H, -T 后可跟多个匹配式, 需要放在命令行末尾\nl path1 path2 -H head -T tail -I \"^re(gul.*) ex(p|g)ress$\"\nl path1 path2 -H head -T tail -E \"^re(gul.*) ex(p|g)ress$\"\n# 显示绝对路径\nl path1 path2 -v\n# 显示文件size, md5\nl path1 path2 -vv\n# 空文件夹\nl path1 path2 -t e,d\n# 非空文件夹\nl path1 path2 -t ne,d\n\n# 分享文件\nS 或 share path1 path2 为每个提供的文件路劲创建分享链接\nS 或 share [-P pawd 或 --passwd pawd] path1 path2 为每个提供的路径创建加密的分享链接\n\n# 查看文件占用空间\ndu path1 path2               文件夹下所有*文件(不包含下层文件夹)*总大小\ndu path1 path2 -R            文件夹下所有*文件(包含下层文件夹)*总大小\n                             如果下层文件多，会花一些时间\n# 相当于 l path1 path2 -t du [-R]\n# eg:\ndu /doc /videos -R\n\n# 离线下载\na 或 add http https ftp ed2k remotepath\na 或 add magnet remotepath [-t {m,i,d,p}]\na 或 add remote_torrent [-t {m,i,d,p}]   # 使用网盘中torrent\n\n# 离线任务操作\nj  或 job                               # 列出离线下载任务\njd 或 jobdump                           # 清除全部 *非正在下载中的任务*\njc 或 jobclear taskid1 taskid2          # 清除 *正在下载中的任务*\njca 或 jobclearall                      # 清除 *全部任务*\n```\n\n#### 参数:\n\n```\n-a num, --aria2c num                aria2c 分段下载数量: eg: -a 10\n-g num, --aget_s num                aget 分段下载数量: eg: -g 100\n-k num, --aget_k size               aget 分段大小: eg: -k 200K\n                                                       -k 1M\n                                                       -k 2M\n--appid num                         设置 app-id. 如果无法下载或下载慢, 尝试设置为 778750\n-o path, --outdir path              指定下周目录: eg: -o /path/to/directory\n-p, --play                          play with mpv\n-P password, --passwd password      分享密码，加密密码\n-y, --yes                           yes # 用于 rmre, mvre, cpre, rnre ！！慎用\n-q, --quiet                         无输出模式, 用于 download, play\n-V, --VERIFY                        verification\n-v, --view                          view detail\n                                    eg:\n                                    l -v        # 显示绝对路径\n                                    a magnet /path -v     # 离线下载并显示下载的文件\n                                    d -p url1 url2 -v  # 显示播放文件的完整路径\n                                    l path1 path2 -vv  # 显示文件的size, md5\n-s SECRET, --secret SECRET          提取密码\n-f number, --from_ number           从第几个开始(用于download, play)，eg: p /video -f 42\n-t ext, --type_ ext                 类型参数, 用 “,” 分隔\n                                    eg:\n                                    -t fs       # 换用下载服务器，用于下载、播放\n                                                # 如果wiki中的速度解决方法不管用，可以试试加该参数\n                                    d -t dc     # 下载并解密,覆盖加密文件(默认)\n                                    d -t dc,no  # 下载并解密,不覆盖加密文件\n                                    dc -t no    # 解密,不覆盖加密文件\n                                    d -t ie     # ignore error, 忽略除Ctrl-C以外的下载错误\n                                    d -t 8s     # 检测文件是否是“百度8秒”，如果是则不下载\n                                    p -t m3     # 播放流媒体(m3u8)\n                                    s -t c      # 连续转存 (如果转存出错，再次运行命令\n                                                # 可以从出错的地方开始，用于转存大量文件时)\n                                    l -t f      # 文件\n                                    l -t d      # 文件夹\n                                    l -t du     # 查看文件占用空间\n                                    l -t e,d    # 空文件夹\n                                    f -t all    # 搜索所有账户\n                                    a -t m,d,p,a\n                                    u -t ec     # encrypt, 加密上传, 默认加前缀\n                                    u -t ec,np  # encrypt, 加密上传, 不加前缀\n                                    u -t r      # 只进行 rapidupload\n                                    u -t e      # 如果云端已经存在则不上传(不比对md5)\n                                    u -t r,e\n                                    -t s        # shuffle，乱序\n-l amount, --limit amount           下载速度限制，eg: -l 100k\n-m {o,c}, --mode {o,c}              模式:  o # 重新上传.   c # 连续上传.\n                                    加密方法: https://github.com/shadowsocks/shadowsocks/wiki/Encryption\n-R, --recursive                     递归, 用于download, play, upload, ls, find, rmre, rnre, rmre, cpre\n-H HEADS, --head HEADS              匹配开头的字符，eg: -H Head1 Head2\n-T TAILS, --tail TAILS              匹配结尾的字符，eg: -T Tail1 Tail2\n-I INCLUDES, --include INCLUDES     不排除匹配到表达的文件名, 可以是正则表达式，eg: -I \".*.mp3\" \".*.avi\"\n-E EXCLUDES, --exclude EXCLUDES     排除匹配到表达的文件名, 可以是正则表达式，eg: -E \".*.html\" \".*.jpg\"\n-c {on, off}, --ls_color {on, off}  ls 颜色，默认是on\n\n# -t, -H, -T, -I, -E 都能用于 download, play, ls, find, rnre, rmre, cpre, mvre\n```\n\n#### 3. 用法\n\nbp 是pan.baidu.com.py的马甲 (alias bp='python2 /path/to/pan.baidu.com.py')\n\n#### 登录:\n\n```\nbp g\nbp login\nbp login username\nbp login username password\n\n# 多帐号登录\n# 一直用 bp login 即可\n```\n\n<a name=\"cookie_login\"></a>\n#### cookie 登录:\n\n1.  打开 chrome 隐身模式窗口  \n2.  在隐身模式窗口登录 pan.baidu.com  \n3.  在登录后的页面打开 chrome 开发者工具(怎么打开自行google)，选择 `Network` ，然后刷新页面。在刷新后的 `Network` 的 `Name` 列表中选中 `list?dir=…` 开头的一项，然后在右侧找到 `Cookie:` ，复制 `Cookie:` 后面的所有内容。  \n4.  用 `pan.baidu.com.py` 登录，`password / cookie:` 处粘贴上面复制的内容。（粘贴后是看不见的）。  \n5.  不要退出 pan.baidu.com，只是关闭隐身模式窗口就可以。  \n\n> 如果使用 cookie 登录，`username` 可以是任意的东西。\n\n#### 删除帐号:\n\n```\nbp ud\n```\n\n#### 切换帐号:\n\n```\nbp uc\n```\n\n#### 帐号信息:\n\n```\nbp user\n```\n\n#### 显示当前工作目录\n\n```\nbp cwd\n```\n\n#### 切换当前工作目录\n\n```\nbp cd         # 切换到 /\nbp cd path    # 支持 ./../...\nbp cd ..\nbp cd ../../Music\nbp cd ...\n```\n\n#### 下载:\n\n```\n## 下载、播放速度慢？\n如果无法下载或下载慢, 尝试设置参数 --appid 778750\nbp d /path/file --appid 778750\n\n# 下载当前工作目录 (递归)\nbp d . -R\n\n# 下载自己网盘中的*单个或多个文件*\nbp d http://pan.baidu.com/disk/home#dir/path=/path/to/filename1 http://pan.baidu.com/disk/home#dir/path=/path/to/filename2\n# or\nbp d /path/to/filename1 /path/to/filename2\n\n# 递归下载自己网盘中的*单个或多个文件夹*\nbp d -R http://pan.baidu.com/disk/home#dir/path=/path/to/directory1 http://pan.baidu.com/disk/home#dir/path=/path/to/directory2\n# or\nbp d -R /path/to/directory1 /path/to/directory2\n# 递归下载后缀为 .mp3 的文件\nbp d -R /path/to/directory1 /path/to/directory2 -T .mp3\n\n# 非递归下载\nbp d relative_path/to/directory1 /path/to/directory2\n\n# 下载别人分享的*单个文件*\nbp d http://pan.baidu.com/s/1o6psfnxx\nbp d 'http://pan.baidu.com/share/link?shareid=1622654699&uk=1026372002&fid=2112674284'\n\n# 下载别人加密分享的*单个文件*，密码参数-s\nbp d http://pan.baidu.com/s/1i3FVlw5 -s vuej\n\n# 用aria2 下载\nbp d http://pan.baidu.com/s/1i3FVlw5 -s vuej -a 5\nbp d /movie/her.mkv -a 4\nbp d url -s [secret] -a 10\n\n# 用 aget 下载\nbp d http://pan.baidu.com/s/1i3FVlw5 -s vuej -g 100\nbp d /movie/her.mkv -g 100 -k 200K\nbp d url -s [secret] -g 100 -k 100K\n如果下载速度很慢，可以试试加大 -g, 减小 -k, -k 一般在 100K ~ 300K 之间合适\n\n# 下载并解码\n## 默认加密方法为 aes-256-cfb\nbp d /path/to/encrypted_file -t dc [-P password]     # 覆盖加密文件 (默认)\nbp d /path/to/encrypted_file -t dc,no [-P password]  # 不覆盖加密文件\n## 设置加密方法\nbp d /path/to/encrypted_file -t dc [-P password] -m 'rc4-md5'\nbp d /path/to/directory -t dc [-P password] -m 'rc4-md5'\n```\n\n#### 解码已下载的加密文件:\n\n```\nbp dc /local/to/encrypted_file [-P password] -m 'aes-256-cfb'\nbp dc /local/to/encrypted_file [-P password]\nbp dc /local/to/directory [-P password]\n```\n\n#### 播放:\n\n```\nbp p /movie/her.mkv\nbp p http://pan.baidu.com/s/xxxxxxxxx -s [secret]\n\nbp cd /movie\nbp p movie -R     # 递归播放 /movie 中所有媒体文件\n\n# 播放流媒体(m3u8)\n上面的命令后加 -t m3\n清晰度与在浏览器上播放的一样.\n如果源文件是高清的(720P,1280P),那么流媒体会自动转为480P.\n```\n\n#### 离线下载:\n\n```\nbp a http://mirrors.kernel.org/archlinux/iso/latest/archlinux-2014.06.01-dual.iso /path/to/save\nbp a https://github.com/PeterDing/iScript/archive/master.zip /path/to/save\nbp a ftp://ftp.netscape.com/testfile /path/to/save\n\nbp a 'magnet:?xt=urn:btih:64b7700828fd44b37c0c045091939a2c0258ddc2' /path/to/save -v -t a\nbp a 'ed2k://|file|[美]徐中約《中国近代史》第六版原版PDF.rar|547821118|D09FC5F70DEA63E585A74FBDFBD7598F|/' /path/to/save\n\nbp a     /path/to/a.torrent -v -t m,i   # 使用网盘中torrent，下载到/path/to\n# 注意   ------------------\n                   ↓\n          网盘中的torrent\n```\n\n#### magnet离线下载 -- 文件选择:\n\n```\n-t m    # 视频文件 (默认), 如: mkv, avi ..etc\n-t i    # 图像文件, 如: jpg, png ..etc\n-t d    # 文档文件, 如: pdf, doc, docx, epub, mobi ..etc\n-t p    # 压缩文件, 如: rar, zip ..etc\n-t a    # 所有文件\nm, i, d, p, a 可以任意组合(用,分隔), 如: -t m,i,d   -t d,p   -t i,p\nremotepath 默认为 /\n\nbp a 'magnet:?xt=urn:btih:64b7700828fd44b37c0c045091939a2c0258ddc2' /path/to/save -v -t p,d\nbp a /download/a.torrent -v -t m,i,d    # 使用网盘中torrent，下载到/download\n```\n\n#### 离线任务操作:\n\n```\nbp j\nbp j 3482938 8302833\nbp jd\nbp jc taskid1 taskid2\nbp jc 1208382 58239221\nbp jca\n```\n\n#### 上传: (默认为非递归，递归加 -R)\n\n```\n# 支持文件类型选择\nbp u ~/Documents/*           # 默认上传所以文件\nbp u ~/Documents/* -t f      # 不上传文件夹\nbp u ~/Documents/* -t d      # 不上传文件\nbp u ~/Documents/* -t f,d    # 不上传文件和文件夹\n\nbp u ~/Documents/reading/三体\\ by\\ 刘慈欣.mobi /doc -m o\n# 上传模式:\n# -m o --> 重传\n# -m c --> 续传 (默认)\n# 递归加-R\n\nbp u ~/Videos/*.mkv /videos -t r\n# 只进行rapidupload\n\nbp u ~/Documents ~/Videos ~/Documents /backup -t e -R\n# 如果云端已经存在则不上传(不比对md5)\n# 用 -t e 时, -m o 无效\n\nbp u ~/Documents ~/Videos ~/Documents /backup -t r,e  # 以上两种模式\n```\n\n#### 加密上传: (默认为非递归，递归加 -R)\n\n```\nbp u ~/{p1,p2,p3} -t ec [-P password]  # 默认加密方法 'aes-256-cfb'\nbp u ~/{p1,p2,p3} -t ec [-P password] -m 'rc4-md5'\n\n# 注意:\n# 上传后的文件名会默认加上前缀 encrypted_\n# 不加前缀用 -t ec,np\n```\n\n#### 转存:\n\n```\nbp s url remotepath [-s secret]\n# url是他人分享的连接, 如: http://pan.baidu.com/share/link?shareid=xxxxxxx&uk=xxxxxxx, http://pan.baidu.com/s/xxxxxxxx\nbp s 'http://pan.baidu.com/share/link?shareid=xxxxxxx&uk=xxxxxxx' /path/to/save\nbp s http://pan.baidu.com/s/xxxxxxxx /path/to/save\nbp s http://pan.baidu.com/s/xxxxxxxx /path/to/save -s xxxx\nbp s http://pan.baidu.com/s/xxxxxxxx#dir/path=/path/to/anything /path/to/save -s xxxx\n\nbp s http://pan.baidu.com/inbox/i/xxxxxxxx /path/to/save\n\n# -t c 连续转存 (如果转存出错，再次运行命令可以从出错的地方开始，用于转存大量文件时)\nbp s 'http://pan.baidu.com/share/link?shareid=2705944270&uk=708312363' /path/to/save -t c\n# 注意：再次运行时，命令要一样。\n```\n\n#### 搜索:\n\n```\n# 默认搜索当前服务器工作目录 cwd\nbp f keyword1 keyword2\nbp f \"this is one keyword\" \"this is another keyword\" /path/to/search\n\nbp f ooxx -R\nbp f 三体 /doc/fiction -R\nbp f 晓波 /doc -R\n\nbp ff  keyword1 keyword2 /path/to/music       非递归搜索 反序\nbp ft  keyword1 keyword2 /path/to/doc         非递归搜索 by time\nbp ftt keyword1 keyword2 /path/to/other       非递归搜索 by time 反序\nbp fs  keyword1 keyword2                      非递归搜索 by size\nbp fss keyword1 keyword2                      非递归搜索 by size 反序\nbp fn  keyword1 keyword2                      非递归搜索 by name\nbp fnn keyword1 keyword2                      非递归搜索 by name 反序\n\n# 递归搜索加 -R\n# 关于-H, -T, -I, -E\nbp f mp3 /path/to/search -H \"[\" \"01\" -T \".tmp\" -I \".*-.*\" -R\n\n# 搜索所有的账户\nbp f iDoNotKnow [directory] -t all -R\nbp f archlinux ubuntu [directory] -t f,all -T .iso -R\n\n# 搜索 加 通道(只支持 donwload, play, rnre, rm, mv)\nbp f bioloy \\| d -R                          递归搜索后递归下载\nbp ftt ooxx \\| p -R -t f                     递归搜索(by time 反序)后递归播放\nbp f sound \\| rnr mp3 mp4 -R                 递归搜索后rename by regex\nbp f ccav \\| rm -R -T avi                    递归搜索后删除\nbp f 新闻联播（大结局） \\| mv /Favor -R      递归搜索后移动\n```\n\n#### 恢复用bt.py做base64加密的文件:\n\n```\nrnr /ooxx -t f,bd64\n!! 注意： /ooxx 中的所有文件都必须是被base64加密的，且加密段要有.base64后缀\n# 可以参考 by.py 的用法\n```\n\nls、重命名、移动、删除、复制、使用正则表达式进行文件操作:\n\n见[命令](#cmd)\n\n#### 4. 参考:\n\n> https://gist.github.com/HououinRedflag/6191023\n\n\n> https://github.com/banbanchs/pan-baidu-download/blob/master/bddown_core.py\n\n\n> https://github.com/houtianze/bypy\n\n\n> 3个方法解决百度网盘限速: https://www.runningcheese.com/baiduyun\n\n\n---\n\n<a name=\"bt.py\"></a>\n### bt.py - magnet torrent 互转、及 过滤敏.感.词\n\n#### 1. 依赖\n\n```\npython2-requests (https://github.com/kennethreitz/requests)\nbencode (https://github.com/bittorrent/bencode)\n```\n\n#### 2. 使用说明\n\nmagnet 和 torrent 的相互转换\n\n过滤敏.感.词功能用于净网时期的 baidu, xunlei\n\n在中国大陆使用代理可能有更好的效果：  \n使用代理有两种方法：  \n1. shadowsocks + proxychains  \n2. -p protocol://ip:port  \n\n~~8.30日后，无法使用。 见 http://tieba.baidu.com/p/3265467666~~\n\n[**百度云疑似解封，百度网盘内八秒视频部分恢复**](http://fuli.ba/baiduyunhuifuguankan.html)\n\n**!! 注意：过滤后生成的torrent在百度网盘只能用一次，如果需要再次使用，则需用 -n 改顶层目录名**\n\n磁力连接转种子，用的是\n\n```\nhttp://bt.box.n0808.com\nhttp://btcache.me\nhttp://www.sobt.org  # 302 --> http://www.win8down.com/url.php?hash=\nhttp://www.31bt.com\nhttp://178.73.198.210\nhttp://www.btspread.com  # link to http://btcache.me\nhttp://torcache.net\nhttp://zoink.it\nhttp://torrage.com   # 用torrage.com需要设置代理, eg: -p 127.0.0.1:8087\nhttp://torrentproject.se\nhttp://istoretor.com\nhttp://torrentbox.sx\nhttp://www.torrenthound.com\nhttp://www.silvertorrent.org\nhttp://magnet.vuze.com\n```\n\n如果有更好的种子库，请提交issue\n\n> 对于baidu, 加入离线任务后，需等待一段时间才会下载完成。\n\n#### 命令:\n\n```\n# magnet 2 torrent\nm 或 mt magnet_link1 magnet_link2 [-d /path/to/save]\nm -i /there/are/files -d new\n\n# torrent 2 magnet, 输出magnet\nt 或 tm path1 path2\n\n# 过滤敏.感.词\n# 有2种模式\n# -t n (默认)     用数字替换文件名\n# -t be64         用base64加密文件名，torrent用百度下载后，可用 pan.baidu.com.py rnr /path -t f,bd64 改回原名字\nc 或 ct magnet_link1 magnet_link2 /path/to/torrent1 /path/to/torrent2 [-d /path/to/save]\nc -i /there/are/files and_other_dir -d new    # 从文件或文件夹中寻找 magnet，再过滤\n# 过滤敏.感.词 - 将magnet或torrent转成不敏感的 torrent\n# /path/to/save 默认为 .\n\n# 用base64加密的文件名:\nc magnet_link1 magnet_link2 /path/to/torrent1 /path/to/torrent2 [-d /path/to/save] -t be64\n\n# 使用正则表达式过滤敏.感.词\ncr 或 ctre foo bar magnet_link1 /path/to/torrent1 [-d /path/to/save]\n# foo bar 都是 regex\n```\n\n#### 参数:\n\n```\n-p PROXY, --proxy PROXY                 proxy for torrage.com, eg: -p \"sooks5://127.0.0.1:8883\"\n-t TYPE_, --type_ TYPE_                 类型参数：\n                                        -t n (默认)     用数字替换文件名\n                                        -t be64         用base64加密文件名，torrent用百度下载后，可用 pan.baidu.com.py rnr /path -t f,bd64 改回原名字\n-d DIRECTORY, --directory DIRECTORY     指定torrents的保存路径, eg: -d /path/to/save\n-n NAME, --name NAME                    顶级文件夹名称, eg: -m thistopdirectory\n-i localpath1 localpath2, --import_from localpath1 localpath2      从本地文本文件导入magnet (用正则表达式匹配)\n```\n\n#### 3. 用法\n\nbt 是bt.py的马甲 (alias bt='python2 /path/to/bt.py')\n\n```\nbt mt magnet_link1 magnet_link2 [-d /path/to/save]\nbt tm path1 path2\nbt ct magnet_link1 path1 [-d /path/to/save]\n\nbt m magnet_link1 magnet_link2 [-d /path/to/save]\nbt t path1 path2\nbt c magnet_link1 path1 [-d /path/to/save]\n\n# 用torrage.com\nbt m magnet_link1 path1 -p 127.0.0.1:8087\nbt c magnet_link1 path1 -p 127.0.0.1:8087\n\n# 从文件或文件夹中寻找 magnet，再过滤\nbt c -i ~/Downloads -d new\n\n# 使用正则表达式过滤敏.感.词\nbt cr '.*(old).*' '\\1'  magnet_link\nbt cr 'old.iso' 'new.iso' /path/to/torrent\n\n# 用base64加密的文件名:\nbt c magnet_link -t be64\n```\n\n#### 4. 参考:\n\n> http://blog.chinaunix.net/uid-28450123-id-4051635.html\n\n\n> http://en.wikipedia.org/wiki/Torrent_file\n\n\n---\n\n<a name=\"115.py\"></a>\n### 115.py - 115网盘的下载和播放\n\n#### 1. 依赖\n\n```\nwget\n\naria2  (~ 1.18)\n\npython2-requests (https://github.com/kennethreitz/requests)\n\nmpv (http://mpv.io)\n\nmplayer # 我的linux上mpv播放wmv出错，换用mplayer\n```\n\n#### 2. 使用说明\n\n初次使用需要登录 pan115 login\n\n**脚本是用于下载自己的115网盘文件，不支持他人分享文件。**\n\n下载工具默认为wget, 可用参数-a选用aria2。\n\n**现在vip和非vip用户下载只能有1个通道，用aria2下载已经无意义。**\n\n对所有文件，默认执行下载(用wget)，如要播放媒体文件，加参数-p。\n\n**非vip用户下载太慢，已经不支持播放。 vip播放正常**\n\n下载的文件，保存在当前目录下。\n\ncookies保存在 ~/.115.cookies\n\n关于播放操作:\n\n> 在运行脚本的终端，输入1次Enter，关闭当前播放并播放下一个文件，连续输入2次Enter，关闭当前播放并退出。\n\n#### 参数:\n\n```\n-a, --aria2c                   download with aria2c\n-p, --play                     play with mpv\n-f number, --from_ number      从第几个开始下载，eg: -f 42\n-t ext, --type_ ext            要下载的文件的后缀，eg: -t mp3\n-l amount, --limit amount      下载速度限制，eg: -l 100k\n-d \"url\"                       增加离线下载 \"http/ftp/magnet/ed2k\"\n```\n\n#### 3. 用法\n\npan115 是115.py的马甲 (alias pan115='python2 /path/to/115.py')\n\n```\n# 登录\npan115 g\npan115 login\npan115 login username\npan115 login username password\n\n# 退出登录\npan115 signout\n\n# 递归下载自己网盘中的*文件夹*\npan115 http://115.com/?cid=xxxxxxxxxxxx&offset=0&mode=wangpan\n\n# 下载自己网盘中的*单个文件* -- 只能是115上可单独打开的文件，如pdf，视频\npan115 http://wenku.115.com/preview/?pickcode=xxxxxxxxxxxx\n\n# 下载用aria2, url 是上面的\npan115 -a url\n\n# 增加离线下载\npan115 -d \"magnet:?xt=urn:btih:757fc565c56462b28b4f9c86b21ac753500eb2a7&dn=archlinux-2014.04.01-dual.iso\"\n```\n\n#### 播放\n\n```\n# url 是上面的\npan115 -p url\n```\n\n#### 4. 参考:\n\n> http://passport.115.com/static/wap/js/common.js?v=1.6.39\n\n---\n\n<a name=\"yunpan.360.cn.py\"></a>\n### yunpan.360.cn.py - 360网盘的下载\n\n**！！！<u>脚本已不再维护</u>！！！**\n\n#### 1. 依赖\n\n```\nwget\n\naria2  (~ 1.18)\n\npython2-requests (https://github.com/kennethreitz/requests)\n```\n\n#### 2. 使用说明\n\n初次使用需要登录 yp login\n\n**!!!!!!  万恶的360不支持断点续传   !!!!!!**\n\n由于上面的原因，不能播放媒体文件。\n\n只支持自己的\\*文件夹\\*的递归下载。\n\n下载工具默认为wget, 可用参数-a选用aria2\n\n下载的文件，保存在当前目录下。\n\ncookies保存在 ~/.360.cookies\n\n#### 参数:\n\n```\n-a, --aria2c                   download with aria2c\n-f number, --from_ number      从第几个开始下载，eg: -f 42\n-t ext, --type_ ext            要下载的文件的后缀，eg: -t mp3\n-l amount, --limit amount      下载速度限制，eg: -l 100k\n```\n\n#### 3. 用法\n\nyp 是yunpan.360.cn.py的马甲 (alias yp='python2 /path/to/yunpan.360.cn.py')\n\n```\n# 登录\nyp g\nyp login\nyp login username\nyp login username password\n\n# 退出登录\nyp signout\n\n# 递归下载自己网盘中的*文件夹*\nyp http://c17.yunpan.360.cn/my/?sid=#/path/to/directory\nyp http://c17.yunpan.360.cn/my/?sid=#%2Fpath%3D%2Fpath%2Fto%2Fdirectory\n# or\nyp sid=/path/to/directory\nyp sid%3D%2Fpath%2Fto%2Fdirectory\n\n# 下载用aria2, url 是上面的\nyp -a url\n```\n\n#### 4. 参考:\n\n> https://github.com/Shu-Ji/gorthon/blob/master/_3rdapp/CloudDisk360/main.py\n\n---\n\n<a name=\"music.baidu.com.py\"></a>\n### music.baidu.com.py - 下载或播放高品质百度音乐(music.baidu.com)\n\n#### 1. 依赖\n\n```\nwget\n\npython2-mutagen (https://code.google.com/p/mutagen/)\n\nmpv (http://mpv.io)\n```\n\n#### 2. 使用说明\n\n默认执行下载，如要播放，加参数-p。\n\n#### 参数：\n\n```\n-f, --flac  download flac\n-i, --high  download 320, default\n-l, --low   download 128\n-p, --play  play with mpv\n```\n\n下载的MP3默认添加id3 tags，保存在当前目录下。\n\n关于播放操作:\n\n> 在运行脚本的终端，输入1次Enter，关闭当前播放并播放下一个文件，连续输入2次Enter，关闭当前播放并退出。\n\n#### 3. 用法\n\nbm 是music.baidu.com.py的马甲 (alias bm='python2 /path/to/music.baidu.com.py')\n\n```\n# 下载专辑\nbm http://music.baidu.com/album/115032005\n\n# 下载单曲\nbm http://music.baidu.com/song/117948039\n```\n\n#### 播放:\n\n```\n# url 是上面的\nbm -p url\n```\n\n#### 4. 参考:\n\n> http://v2ex.com/t/77685 # 第9楼\n\n---\n\n<a name=\"music.163.com.py\"></a>\n### music.163.com.py - 下载或播放高品质网易音乐(music.163.com)\n\n#### 1. 依赖\n\n```\nwget\n\npython2-requests (https://github.com/kennethreitz/requests)\n\npython2-mutagen (https://code.google.com/p/mutagen/)\n\nmpv (http://mpv.io)\n```\n\n#### 2. 使用说明\n\n**默认下载和播放高品质音乐，如果服务器没有高品质音乐则转到低品质音乐。**\n\n默认执行下载，如要播放，加参数-p。\n\n下载的MP3默认添加id3 tags，保存在当前目录下。\n\n关于播放操作:\n\n> 在运行脚本的终端，输入1次Enter，关闭当前播放并播放下一个文件，连续输入2次Enter，关闭当前播放并退出。\n\n#### 3. 用法\n\nnm 是music.163.com.py的马甲 (alias nm='python2 /path/to/music.163.com.py')\n\n```\n# 下载专辑\nnm http://music.163.com/#/album?id=18915\n\n# 下载单曲\nnm http://music.163.com/#/song?id=186114\n\n# 下载歌单\nnm http://music.163.com/#/playlist?id=12214308\n\n# 下载该艺术家所有专辑或 Top 50 歌曲\nnm http://music.163.com/#/artist?id=6452\n\n# 下载DJ节目\nnm http://music.163.com/#/dj?id=675051\n\n# 下载排行榜\nnm http://music.163.com/#/discover/toplist?id=11641012\n```\n\n#### 播放:\n\n```\n# url 是上面的\nnm -p url\n```\n\n#### 4. 参考:\n\n> https://github.com/yanunon/NeteaseCloudMusic/wiki/%E7%BD%91%E6%98%93%E4%BA%91%E9%9F%B3%E4%B9%90API%E5%88%86%E6%9E%90\n\n\n> http://s3.music.126.net/s/2/core.js\n\n---\n\n<a name=\"flv_cmd.py\"></a>\n### flv_cmd.py - 基于在线服务的视频解析 client - 支持下载、播放\n\n**！！！<u>脚本已不再维护</u>！！！**\n\n**请使用 youtube-dl or you-get**\n\n#### 1. 依赖\n\n```\nwget\n\npython2-requests (https://github.com/kennethreitz/requests)\n\nmpv (http://mpv.io)\n```\n\n#### 2. 使用说明\n\n~~flvxz.com 视频解析~~ 不能用。\n\nflvgo.com 视频解析\n\n**不提供视频合并操作**\n\n#### 支持的网站:\n\nhttp://flvgo.com/sites\n\n关于播放操作:\n\n> 在运行脚本的终端，输入1次Enter，关闭当前播放并播放下一个文件，连续输入2次Enter，关闭当前播放并退出。\n\n#### 3. 用法\n\nfl是flv_cmd.py的马甲 (alias fl='python2 /path/to/flv_cmd.py')\n\n#### 下载:\n\n```\nfl http://v.youku.com/v_show/id_XNTI2Mzg4NjAw.html\nfl http://www.tudou.com/albumplay/Lqfme5hSolM/tJ_Gl3POz7Y.html\n```\n\n#### 播放:\n\n```\n# url 是上面的\nfl url -p\n```\n\n#### 4. 相关脚本:\n\n> https://github.com/soimort/you-get\n\n\n> https://github.com/iambus/youku-lixian\n\n\n> https://github.com/rg3/youtube-dl\n\n---\n\n<a name=\"tumblr.py\"></a>\n### tumblr.py - 下载某个tumblr.com的所有图片、视频、音频\n\n#### 1. 依赖\n\n```\nwget\n\nmpv (http://mpv.io)\n\npython2-requests (https://github.com/kennethreitz/requests)\n```\n\n#### 2. 使用说明\n\n* 使用前需用在 http://www.tumblr.com/oauth/apps 加入一个app，证实后得到api_key，再在源码中填入，完成后则可使用。\n\n* 或者用 http://www.tumblr.com/docs/en/api/v2 提供的api_key ( fuiKNFp9vQFvjLNvx4sUwti4Yb5yGutBN4Xh10LXZhhRKjWlV4 )\n\n默认开10个进程，如需改变用参数-p [num]。\n\n下载的文件，保存在当前目录下。\n\n默认下载图片(原图)。\n\n支持连续下载，下载进度储存在下载文件夹内的 json.json。\n\n**正确退出程序使用 Ctrl-C**  \n**下载 更新的图片或其他 用 tumblr --update URL, 或 删除 json.json**  \n\n#### 参数:\n\n```\n-p PROCESSES, --processes PROCESSES      指定多进程数,默认为10个,最多为20个 eg: -p 20\n-c, --check           尝试修复未下载成功的图片\n-t TAG, --tag TAG     下载特定tag的图片, eg: -t beautiful\n\n-P, --play            play with mpv\n-A, --audio           download audios\n-V, --video           download videos\n-q, --quiet           quiet\n\n--update              下载新发布的东西\n--redownload          重新遍历所有的东西，如果有漏掉的东西则下载\n--proxy protocol://address:port     设置代理\n\n-f OFFSET, --offset OFFSET      从第offset个开始，只对 -V 有用。\n```\n\n#### 3. 用法\n\ntm是tumblr.py的马甲 (alias tm='python2 /path/to/tumblr.py')\n\n```\n# 下载图片\ntm http://sosuperawesome.tumblr.com\ntm http://sosuperawesome.tumblr.com -t beautiful\n\n# 下载图片(使用代理)\ntm http://sosuperawesome.tumblr.com -x socks5://127.0.0.1:1024\ntm http://sosuperawesome.tumblr.com -t beautiful -x socks5://127.0.0.1:1024\n\n# 下载单张图片\ntm http://sosuperawesome.tumblr.com/post/121467716523/murosvur-on-etsy\n\n# 下载视频\ntm url -V\ntm url -V -f 42\ntm url -V -t tag\n\n# 下载单个视频\ntm url/post/1234567890 -V\n\n# 播放视频\ntm url -VP\ntm url -VP -f 42\n\n# 下载音频\ntm url -A\ntm url -A -f 42\ntm url -A -t tag\n\n# 下载单个音频\ntm url/post/1234567890 -A\n\n# 播放音频\ntm url -AP\ntm url -AP -f 42\n\n# 播放音频(quiet)\ntm url -APq\n\n```\n\n---\n\n<a name=\"unzip.py\"></a>\n### unzip.py - 解决linux下unzip乱码的问题\n\n#### 用法\n\n```\npython2 unzip.py azipfile1.zip azipfile2.zip\npython2 unzip.py azipfile.zip -s secret\n# -s 密码\n```\n\n代码来自以下连接，我改了一点。\n\n> http://wangqige.com/the-solution-of-unzip-files-which-zip-under-windows/解决在Linux环境下解压zip的乱码问题\n\n---\n\n<a name=\"ed2k_search.py\"></a>\n### ed2k_search.py - 基于 donkey4u.com 的emule搜索\n\n#### 1. 依赖\n\n```\npython2\n```\n\n#### 2. 用法\n\ned 是ed2k_search.py的马甲 (alias ed='python2 /path/to/ed2k_search.py')\n\n```\ned this is a keyword\nor\ned \"this is a keyword\"\n```\n\n---\n\n<a name=\"91porn.py\"></a>\n### 91porn.py - 下载或播放91porn\n\n**警告: 18岁以下者，请自觉远离。**\n\n#### 1. 依赖\n\n```\nwget\n\naria2  (~ 1.18)\n\npython2-requests (https://github.com/kennethreitz/requests)\n\nmpv (http://mpv.io)\n```\n\n#### 2. 使用说明\n\n> youtube-dl 已支持91porn\n\n没有解决每个ip *10个/day* 限制\n\n下载工具默认为wget, 可用参数-a选用aria2\n\n默认执行下载，如要播放媒体文件，加参数-p。\n\n下载的文件，保存在当前目录下。\n\n关于播放操作:\n\n> 在运行脚本的终端，输入1次Enter，关闭当前播放并播放下一个文件，连续输入2次Enter，关闭当前播放并退出。\n\n#### 3. 用法\n\npn 是91porn.py的马甲 (alias pn='python2 /path/to/91porn.py')\n\n#### 下载：\n\n```\npn url # 91porn.com(或其镜像) 视频的url\n```\n\n#### 播放:\n\n```\npn -p url\n```\n\n显示下载链接，但不下载:\n\n```\npn -u url\n```\n\n#### 4. 参考\n\n> http://v2ex.com/t/110196 # 第16楼\n\n---\n\n<a name=\"ThunderLixianExporter.user.js\"></a>\n### ThunderLixianExporter.user.js - A fork of https://github.com/binux/ThunderLixianExporter\n\n**一个github.com/binux的迅雷离线导出脚本的fork。**\n\n增加了mpv和mplayer的导出。\n\n用法见: https://github.com/binux/ThunderLixianExporter\n"
        },
        {
          "name": "ThunderLixianExporter.user.js",
          "type": "blob",
          "size": 45.94140625,
          "content": "// ==UserScript==\n// @name       ThunderLixianExporter\n// @namespace  http://dynamic.cloud.vip.xunlei.com/\n// @version    0.75\n// @description  export thunder lixian url to aria2/wget\n// @match      http://dynamic.cloud.vip.xunlei.com/user_task*\n// @match      http://lixian.vip.xunlei.com/lx3_task.html*\n// @match      http://jiayuan.xunlei.com/lxhome/lx3_task.html*\n// @run-at document-end\n// @copyright  2012+, Binux <root@binux.me>\n// @updateURL http://s.binux.me/TLE/master/ThunderLixianExporter.meta.js\n// ==/UserScript==\n\nfunction tle_wrapper() {\n// vim: set et sw=2 ts=2 sts=2 ff=unix fenc=utf8:\n// Author: Binux<root@binux.me>\n//         http://binux.me\n// Created on Fri 20 Jul 2012 11:43:22 AM CST\n\nTLE = {};\n\nTLE.exporter = {\n  '复制链接': function(todown) {\n    //console.log(todown);\n    var str = '<ul style=\"max-height: 300px; overflow-y: scroll; overflow-x: hidden;\">';\n    $.each(todown.tasklist, function(n, task) {\n      $.each(task.filelist, function(l, file) {\n        if (!file.downurl) return;\n        str += '<li><a href=\"'+TLE.url_rewrite(file.downurl, TLE.safe_title(file.title))+'\" target=\"_blank\">'+file.title+'</a></li>';\n      });\n    });\n    str += \"</ul>\";\n    $(\"#TLE_text_pop\").tpl(\"TLE_text_tpl\", {'title': '复制选中的链接 &gt; <a href=\"'+\"data:text/html;charset=utf-8,\"+encodeURIComponent(str)+'\" target=\"_blank\">在新窗口中打开</a>', 'content': str}).show().pop({\n      onHide: function() { $(document.body).click(); },\n    });\n  },\n  'Aria2': function(todown) {\n    //console.log(todown);\n    var str = \"\";\n    $.each(todown.tasklist, function(n, task) {\n      $.each(task.filelist, function(l, file) {\n        if (!file.downurl) return;\n        var filepath = TLE.safe_title(file.title);\n        if (task.tasktype == 0 && task.filelist.length > 1)\n          filepath = TLE.safe_title(task.taskname) + \"/\" + TLE.safe_title(file.title.replace(/\\\\+\\*?/g,\"/\"));\n        str += \"aria2c -c -s10 -x10 --out \"+TLE.escape_command(filepath)+\" --header 'Cookie: gdriveid=\"+todown.gdriveid+\";' '\"+file.downurl+\"'\\n\";\n      });\n    });\n    TLE.text_pop(\"aria2 download command\", str);\n  },\n  'wget': function(todown) {\n    //console.log(todown);\n    var str = \"\";\n    $.each(todown.tasklist, function(n, task) {\n      $.each(task.filelist, function(l, file) {\n        if (!file.downurl) return;\n        str += \"wget -c -O \"+TLE.escape_command(TLE.safe_title(file.title))+\" --header 'Cookie: gdriveid=\"+todown.gdriveid+\";' '\"+file.downurl+\"'\\n\";\n      });\n    });\n    TLE.text_pop(\"wget download command\", str);\n  },\n  'mpv': function(todown) {\n    //console.log(todown);\n    var str = \"\";\n    $.each(todown.tasklist, function(n, task) {\n      $.each(task.filelist, function(l, file) {\n        if (!file.downurl) return;\n        str += \"mpv --really-quiet --cache 8140 --cache-default 8140 --http-header-fields 'Cookie: gdriveid=\"+todown.gdriveid+\";' '\"+file.downurl+\"'\\n\";\n      });\n    });\n    TLE.text_pop(\"play with mpv\", str);\n  },\n  'mplayer': function(todown) {\n    //console.log(todown);\n    var str = \"\";\n    $.each(todown.tasklist, function(n, task) {\n      $.each(task.filelist, function(l, file) {\n        if (!file.downurl) return;\n        str += \"mplayer -really-quiet -cache 8140 -http-header-fields 'Cookie: gdriveid=\"+todown.gdriveid+\";' '\"+file.downurl+\"'\\n\";\n      });\n    });\n    TLE.text_pop(\"play with mplayer\", str);\n  },\n  \"YAAW\": function(todown) {\n    if (TLE.getConfig(\"TLE_aria2_jsonrpc\")) {\n      show_tip(\"添加中...到YAAW界面查看是否添加成功\");\n      var aria2 = new ARIA2(TLE.getConfig(\"TLE_aria2_jsonrpc\"));\n      $.each(todown.tasklist, function(n, task) {\n        $.each(task.filelist, function(l, file) {\n          if (!file.downurl) return;\n          var filepath = TLE.safe_title(file.title);\n          if (task.tasktype == 0 && task.filelist.length > 1)\n            filepath = TLE.safe_title(task.taskname) + \"/\" + TLE.safe_title(file.title.replace(/\\\\+\\*?/g,\"/\"));\n          aria2.addUri(file.downurl, {out: filepath, header: 'Cookie: gdriveid='+todown.gdriveid});\n        });\n      });\n      hide_tip();\n    } else {\n      show_tip(\"尚未设置Aria2 JSONRPC地址\");\n      hide_tip();\n    };\n  },\n  'Aria2导出': function(todown) {\n    //console.log(todown);\n    var str = \"\";\n    $.each(todown.tasklist, function(n, task) {\n      $.each(task.filelist, function(l, file) {\n        if (!file.downurl) return;\n        var filepath = TLE.safe_title(file.title);\n        if (task.tasktype == 0 && task.filelist.length > 1)\n          filepath = TLE.safe_title(task.taskname) + \"/\" + TLE.safe_title(file.title.replace(/\\\\+\\*?/g,\"/\"));\n        str += file.downurl+'\\r\\n  out='+filepath+'\\r\\n  header=Cookie: gdriveid='+todown.gdriveid+'\\r\\n  continue=true\\r\\n  max-connection-per-server=5\\r\\n  split=10\\r\\n  parameterized-uri=true\\r\\n\\r\\n';\n      });\n    });\n    TLE.file_pop(\"Aria2导出文件下载\", str, \"aria2.down\");\n  },\n  'IDM导出': function(todown) {\n    //console.log(todown);\n    var str = \"\";\n    $.each(todown.tasklist, function(n, task) {\n      $.each(task.filelist, function(l, file) {\n        if (!file.downurl) return;\n        str += '<\\r\\n'+TLE.url_rewrite(file.downurl, TLE.safe_title(file.title))+'\\r\\ncookie: gdriveid='+todown.gdriveid+'\\r\\n>\\r\\n'\n      });\n    });\n    TLE.file_pop(\"IDM导出文件下载\", str, \"idm.ef2\");\n  },\n  'Orbit导出': function(todown) {\n    //console.log(todown);\n    var str = \"\";\n    $.each(todown.tasklist, function(n, task) {\n      $.each(task.filelist, function(l, file) {\n        if (!file.downurl) return;\n        str += TLE.url_rewrite(file.downurl, TLE.safe_title(file.title))+'|'+TLE.safe_title(file.title.replace(\"|\", \"_\"))+'||gdriveid='+todown.gdriveid+'\\r\\n'\n      });\n    });\n    TLE.file_pop(\"Orbit导出文件下载\", str, \"orbit.olt\");\n  },\n  'eagleget': function(todown) {\n    var ret = {tasks: []};\n    $.each(todown.tasklist, function(n, task) {\n      $.each(task.filelist, function(l, file) {\n        if (!file.downurl) return;\n        ret.tasks.push({\n          cookie: 'gdriveid='+todown.gdriveid,\n          fname: TLE.safe_title(file.title),\n          url: TLE.url_rewrite(file.downurl, TLE.safe_title(file.title))\n        });\n      });\n    });\n    TLE.file_pop(\"Eagleget导出文件下载(test)\", JSON.stringify(ret), \"eagleget.eg\");\n  },\n};\n\n(function(TLE) {\n  function get_taskinfo(p) {\n    var taskid = p.attr(\"taskid\");\n    var info = {};\n    p.find(\"input\").each(function(n, e) {\n      var key = e.getAttribute(\"id\").replace(taskid, \"\");\n      info[key] = e.getAttribute(\"value\");\n    });\n    return info;\n  };\n\n  function build_normal_taskinfo(info) {\n    var taskinfo = {\n      'taskname': info.taskname || info.cloud_taskname,\n      'f_url': info.f_url,\n      'cid': info.dcid || info.cloud_cid,\n      'size': parseInt(info.ysfilesize),\n      'tasktype': info.d_tasktype,\n      'status': info.d_status,\n    };\n    var filelist = [];\n    filelist.push({\n      'title': info.taskname || info.cloud_taskname,\n      'f_url': info.f_url,\n      'downurl': info.dl_url || info.cloud_dl_url,\n      'cid': info.dcid || info.cloud_cid,\n      'gcid': \"\",\n      'size': parseInt(info.ysfilesize),\n    });\n    taskinfo['filelist'] = filelist;\n\n    return taskinfo;\n  };\n  function build_bt_taskinfo(info, rdata) {\n    var taskinfo = {\n      'taskname': info.taskname,\n      'f_url': info.f_url,\n      'cid': info.dcid,\n      'size': parseInt(info.ysfilesize),\n      'tasktype': info.d_tasktype,\n      'status': info.d_status,\n    };\n    var filelist = [];\n    $.each(rdata, function(n, e) {\n      filelist.push({\n        'title': e.title,\n        'f_url': e.url,\n        'downurl': e.downurl,\n        'cid': e.cid,\n        'gcid': e.gcid,\n        'size': parseInt(e.filesize),\n      });\n    });\n    taskinfo['filelist'] = filelist;\n    return taskinfo;\n  };\n\n  TLE.safe_title = function safe_title(title) {\n    return title.replace(/[\\\\\\|\\:\\*\\\"\\?\\<\\>]/g,\"_\");\n  };\n\n  TLE.down = function(_this, _do) {\n    var p = $(_this).parents(\".rw_list\");\n    var info = get_taskinfo(p);\n    console.log(info);\n\n    if (info.d_tasktype == \"0\") { //bt task\n      show_tip(\"载入中...\");\n      $.getJSON(INTERFACE_URL+\"/fill_bt_list?tid=\"+info.input+\"&g_net=\"+G_section+\"&uid=\"+G_USERID+\"&callback=?\", function(data) {\n        hide_tip();\n        var todown = {};\n        todown.gdriveid = getCookie(\"gdriveid\");\n        todown.tasklist = {};\n        todown.tasklist[info.input] = build_bt_taskinfo(info, data['Result'][info.input]);\n        _do(todown);\n      });\n    } else {\n      var todown = {}\n      todown.gdriveid = getCookie(\"gdriveid\");\n      todown.tasklist = {};\n      todown.tasklist[info.input] = build_normal_taskinfo(info);\n      _do(todown);\n    };\n  };\n\n  TLE.batch_down = function(_this, _do) {\n    var ck = document.getElementsByName(\"ck\");\n    var bt_task_list = [];\n    var normal_task_list = [];\n    $.each(ck, function(n, e) {\n      if (e.checked == false) return;\n\n      var taskid = e.value;\n      var d_status = $(\"#d_status\"+taskid).val();\n      var d_tasktype = $(\"#d_tasktype\"+taskid).val();\n      var d_flag = $(\"#dflag\"+taskid).val();\n      if (d_flag != 4 && d_status == 2) {\n        if (d_tasktype == 0) {\n          bt_task_list.push(taskid);\n        } else {\n          normal_task_list.push(taskid);\n        };\n      };\n    });\n\n    if (bt_task_list.length) {\n      show_tip(\"载入中...\");\n      $.getJSON(INTERFACE_URL+\"/fill_bt_list?tid=\"+bt_task_list.join(\",\")+\"&g_net=\"+G_section+\"&uid=\"+G_USERID+\"&callback=?\", function(data) {\n        hide_tip();\n        var todown = {};\n        todown.gdriveid = getCookie(\"gdriveid\");\n        todown.tasklist = {};\n        $.each(data['Result'], function(n, e) {\n          var info = get_taskinfo($(\"#tr_c\"+n));\n          todown.tasklist[n] = build_bt_taskinfo(info, e);\n        });\n        $.each(normal_task_list, function(n, e) {\n          var info = get_taskinfo($(\"#tr_c\"+e));\n          todown.tasklist[e] = build_normal_taskinfo(info);\n        });\n        _do(todown);\n      });\n    } else {\n      var todown = {};\n      todown.gdriveid = getCookie(\"gdriveid\");\n      todown.tasklist = {};\n      $.each(normal_task_list, function(n, e) {\n        var info = get_taskinfo($(\"#tr_c\"+e));\n        todown.tasklist[e] = build_normal_taskinfo(info);\n      });\n      _do(todown);\n    };\n  };\n\n  TLE.bt_down = function(_this, _do) {\n    var ck = document.getElementsByName(\"bt_list_ck\");\n    var files = [];\n    $.each(ck, function(n, e) {\n      if (e.checked == false) return;\n      var fid = e.getAttribute(\"_i\");\n      var file = {\n        'title': $(\"#bt_taskname\"+fid).val(),\n        'url': $(\"#bturl\"+fid).val(),\n        'downurl': $(\"#btdownurl\"+fid).val(),\n        'cid': $(\"#btcid\"+fid).val(),\n        'gcid': $(\"#btgcid\"+fid).val(),\n        'filesize': $(\"#bt_filesize\"+fid).val(),\n      };\n      files.push(file);\n    });\n    var taskid = $(\"#view_bt_taskid\").val();\n    var info = get_taskinfo($(\"#tr_c\"+taskid));\n\n    var todown = {};\n    todown.gdriveid = getCookie(\"gdriveid\");\n    todown.tasklist = {};\n    todown.tasklist[taskid] = build_bt_taskinfo(info, files);\n    //console.log(todown);\n\n    _do(todown);\n\n    //console.log(\"bt_down\");\n  };\n\n  TLE.bt_down_one = function(_this, _do) {\n    var files = []\n    var fid = $(_this).parents(\".rw_list\").attr(\"i\");\n    var file = {\n      'title': $(\"#bt_taskname\"+fid).val(),\n      'url': $(\"#bturl\"+fid).val(),\n      'downurl': $(\"#btdownurl\"+fid).val(),\n      'cid': $(\"#btcid\"+fid).val(),\n      'gcid': $(\"#btgcid\"+fid).val(),\n      'filesize': $(\"#bt_filesize\"+fid).val(),\n    };\n    files.push(file);\n    var taskid = $(\"#view_bt_taskid\").val();\n    var info = get_taskinfo($(\"#tr_c\"+taskid));\n\n    var todown = {};\n    todown.gdriveid = getCookie(\"gdriveid\");\n    todown.tasklist = {};\n    todown.tasklist[taskid] = build_bt_taskinfo(info, files);\n    //console.log(todown);\n\n    _do(todown);\n\n    //console.log(\"bt_down\");\n  };\n\n  TLE.getbtn = function(_this) {\n    $(_this).parents(\".TLE_get_btnbox\").find(\".TLE_p_getbtn\").toggle();\n    close_rightmenu_layer();\n    return false;\n  };\n\n  TLE.text_pop = function(title, content) {\n    content = $('<div></div>').text(content).html()\n    content = '<textarea style=\"width: 100%; height: 260px;\">'+content+'</textarea>'\n    $(\"#TLE_text_pop\").tpl(\"TLE_text_tpl\", {'title': title, 'content': content}).show().pop({\n      onHide: function() { $(document.body).click(); },\n    });\n  };\n  TLE.file_pop = function(title, content, filename) {\n    var url = \"data:text/html;charset=utf-8,\"+encodeURIComponent(content);\n    var content = '<div style=\"width: 100%; height: 100px;\">'\n                    +'<div style=\"padding: 30px 0 0 30%;\">'\n                      +'<a href=\"'+url+'\" target=\"_blank\" title=\"右键另存为\" class=\"TLE_down_btn\" download=\"'+filename+'\"><span><em class=\"TLE_icdwlocal\">导出文件</em></span></a>'\n                      +(isChrome ? '' : '(右键另存为'+filename+')')\n                    +'</div>'\n                 +'</div>'\n    $(\"#TLE_text_pop\").tpl(\"TLE_text_tpl\", {'title': title, 'content': content}).show().pop({\n      onHide: function() { $(document.body).click(); },\n    });\n  };\n  TLE.window_pop = function(title, content) {\n    $(\"#TLE_text_pop\").tpl(\"TLE_text_tpl\", {'title': title, 'content': content}).show().pop({\n      onHide: function() { $(document.body).click(); },\n    });\n  };\n\n  TLE.multiple_server_fix = function(url) {\n    return \"'\"+url.replace(\"gdl\", \"'{gdl,dl.{f,g,h,i,twin}}'\")+\"'\";\n  }\n\n  function encode_utf8(s) {\n    return unescape( encodeURIComponent( s ) );\n  };\n  function to_hex(num) {\n    var s = num.toString(16);\n    if (s.length == 1)\n      return '0'+s;\n    else\n      return s;\n  };\n  var thunder_filename_mask = [0x61, 0x31, 0xe4, 0x5f, 0x00, 0x00, 0x00, 0x00];\n  function thunder_filename_encode(filename) {\n    var result = [\"01\", ];\n    $.each(encode_utf8(filename), function(i, n) {\n      result.push(to_hex(n.charCodeAt(0)^thunder_filename_mask[i%8]).toUpperCase())\n    });\n    while (result.length % 8 != 1) {\n      result.push(to_hex(thunder_filename_mask[(result.length-1)%8]).toUpperCase());\n    }\n    return result.join(\"\");\n  };\n\n  TLE.url_rewrite = function(url, filename) {\n    url = url.replace(/&n=\\w+/, \"&n=\"+thunder_filename_encode(filename));\n    return url;\n  };\n\n  var alpha = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\";\n  TLE.escape_command = function(str) {\n    var result = \"\";\n    for (var i = 0; i < str.length; i++) {\n      if (alpha.indexOf(str[i]) == -1)\n        result += \"\\\\\"+str[i];\n      else\n        result += str[i];\n    }\n    return result;\n  };\n\n  //setting\n  TLE.getConfig = function(key) {\n    if (window.localStorage) {\n      return window.localStorage.getItem(key) || \"\";\n    } else {\n      return getCookie(key);\n    }\n  };\n  TLE.setConfig = function(key, value) {\n    if (window.localStorage) {\n      window.localStorage.setItem(key, value);\n    } else {\n      setGdCookie(key, value, 86400*365);\n    }\n  };\n  //set default config\n  if (TLE.getConfig(\"TLE_exporter\") == \"\") {\n    var exporters = [];\n    for (var key in TLE.exporter) {\n      exporters.push(key);\n    };\n    TLE.setConfig(\"TLE_exporter\", exporters.join(\"|\"));\n  };\n\n  function init() {\n    //css\n    $(\"head\").append('<style>'\n          +'.TLE_get_btnbox {position:relative; float:left; z-index:11}'\n          +'.TLE_getbtn {position: absolute; top:24px; left:0; border:1px #6FB2F3 solid; background:#fff; width:115px;-moz-border-radius:3px;-webkit-border-radius:3px;border-radius:3px;-moz-box-shadow:2px 2px 3px #ddd;-webkit-box-shadow:2px 2px 3px #ddd;}'\n          +'.TLE_getbtn a {display:block; height:22px; line-height:22px; padding-left:18px}'\n          +'.TLE_getbtn a:hover {background:#E4EFF9 url(http://cloud.vip.xunlei.com/190/img/ic_dianbo.png) no-repeat 8px 8px; *background-position:8px 6px ; text-decoration:none}'\n          +'.TLE_get_btnbox .TLE_getlink {width:98px; height:22px; float:left; line-height:21px;*line-height:24px;display:block;color:#000000; margin-right:5px; overflow:hidden;background:url(http://cloud.vip.xunlei.com/190/img/bg_btnall.png?197) no-repeat  0 -390px}'\n          +'.TLE_get_btnbox .TLE_link_gettxt {float:left; display: inline ; width:53px; text-align:center; padding-left:24px; color:#000}'\n          +'.TLE_get_btnbox .TLE_link_gettxt:hover {text-decoration:none}'\n          +'.rwbox .rwset .TLE_link_getic {float:left; display:block; width:20px;height:22px;}'\n          +'.TLE_hiden {display: none; }'\n          +'.TLE_down_btn {background: url(http://cloud.vip.xunlei.com/190/img/lx/bg_rpx.png) no-repeat 0 999em; display: block; float: left; margin: 0 1px; overflow: hidden; color: white; height: 28px; padding-left: 8px; background-position: 0 -60px; text-decoration: none; }'\n          +'.TLE_down_btn span {background: url(http://cloud.vip.xunlei.com/190/img/lx/bg_rpx.png) no-repeat 0 999em; display: block; float: left; height: 28px; line-height: 27px; cursor: pointer; padding-right: 8px; background-position:100% -60px; }'\n          +'.TLE_down_btn:active {background-position:0 -28px; }'\n          +'.TLE_down_btn:active span {background-position:right -28px;}'\n          +'.TLE_icdwlocal { padding-left: 20px; display: inline-block; background: url(http://cloud.vip.xunlei.com/190/img/lx/bg_menu.png) no-repeat 0 999em; background-position: 0 -108px; }'\n\n          +'.rwbtn.ic_redownloca { display: none !important; }'\n          +'.menu { width: 700px !important; }'\n          // for thunder css\n          +'.rwset {width:530px;}'\n        +'</style>');\n    //pop\n    $(\"body\").append('<div id=\"TLE_text_pop\" class=\"pop_rwbox\" style=\"display: none;margin: 0;\"></div>');\n    $(\"body\").append('<textarea id=\"TLE_text_tpl\" style=\"display: none;\"></textarea>');\n    $(\"#TLE_text_tpl\").text('<div class=\"p_rw_pop\">'\n                            +'<div class=\"tt_box onlytitle\">'\n                              +'<h3>$[title]</h3>'\n                            +'</div>'\n                            +'<div class=\"psc_info\">'\n                              +'$[content]'\n                            +'</div>'\n                            +'<a href=\"#\" class=\"close\" title=\"关闭\">关闭</a>'\n                          +'</div>');\n    $(\"#setting_main_tpl\").text($(\"#setting_main_tpl\").text().replace(/(<\\/div>\\s+<div class=\"btnin\">)/,\n          '<div class=\"doline mag01\"></div>'\n            +'<h3 style=\"background-position: 0 -180px;\">Thunder Lixian Exporter 设定</h3>'\n            +'<ul>'\n              +'<li><b>启用以下导出器</b></li>'\n              +'<li>'+(function(){\n                var enabled_exporter = TLE.getConfig(\"TLE_exporter\").split(\"|\");\n                var str = '';\n                for (var name in TLE.exporter) {\n                  str += '<span class=\"rw_col\"><input type=\"checkbox\" class=\"TLE_setting_ck\" name=\"TLE_ck_'+name+'\" '+(enabled_exporter.indexOf(name) == -1 ? \"\" : \"checked\")+' />'+name+'</span>';\n                }\n                return str;\n              })()+'</li>'\n              +'<li><b>Aria2 JSON-RPC Path</b></li>'\n              +'<li>Path: <input type=\"text\" id=\"TLE_aria2_jsonrpc\" style=\"width: 350px\" value=\"'+TLE.getConfig(\"TLE_aria2_jsonrpc\")+'\"/></li>'\n            +'</ul>'\n          +'$1'));\n    var _set_notice_submit = set_notice_submit;\n    set_notice_submit = function(f) {\n      _set_notice_submit(f);\n      var enabled_exporter = [];\n      $(\".TLE_setting_ck\").each(function(n, e) {\n        if (e.checked) enabled_exporter.push(e.name.replace(/^TLE_ck_/, \"\"));\n      });\n      var config_str = (enabled_exporter.length == 0) ? \"_\" : enabled_exporter.join(\"|\");\n      var jsonrpc_path = $(\"#TLE_aria2_jsonrpc\").val();\n      if (TLE.getConfig(\"TLE_exporter\") != config_str || TLE.getConfig(\"TLE_aria2_jsonrpc\") != jsonrpc_path) {\n        TLE.setConfig(\"TLE_exporter\", config_str);\n        TLE.setConfig(\"TLE_aria2_jsonrpc\", jsonrpc_path);\n        TS2.show('设置已生效',1);\n        setTimeout(function(){\n          setting.hide();\n          location.reload(true);\n        }, 1*1000);\n      }\n    };\n\n    function exporter_anchors(type) {\n      var enabled_exporter = TLE.getConfig(\"TLE_exporter\").split(\"|\");\n      var str = '';\n      $.each(TLE.exporter, function(n, f) {\n        if (enabled_exporter.indexOf(n) == -1) return;\n        str+=('<a href=\"#\" title=\"'+n+'\" onmouseover=\"this.className=\\'sel_on\\'\" onmouseout=\"this.className=\\'\\'\" onclick=\"'+type+'(this, TLE.exporter[\\''+n+'\\'])\">'+n+'</a>');\n      });\n      return str;\n    }\n    //down\n    $(\".rwbtn.ic_redownloca\").each(function(n, e) {\n      $(e).after('<div class=\"TLE_get_btnbox\">'\n                  + '<span class=\"TLE_getlink\">'\n                    + '<a href=\"#\" class=\"TLE_link_gettxt TLE-down-text\" style=\"padding-left: 20px; width: 57px;\" onclick='+e.getAttribute(\"onclick\")+'>取回本地</a>'\n                    + '<a href=\"#\" class=\"TLE_link_getic TLE-down-btn\" onclick=\"return TLE.getbtn(this);\"></a>'\n                  + '</span>'\n                  + '<div class=\"TLE_p_getbtn TLE_getbtn\" style=\"display: none;\">'\n                    + exporter_anchors(\"TLE.down\")\n                  + '</div>'\n                + '</div>');\n    });\n\n    //batch_down\n    $(\"#li_task_down,#li_task_download\").after('<a href=\"#\" id=\"TLE_batch_down\" title=\"批量导出\" class=\"btn_m noit\"><span><em class=\"icdwlocal\">批量导出</em></span></a>')\n                      .parents(\".main_link\").append(\n                            '<div id=\"TLE_batch_getbtn\" class=\"TLE_getbtn\" style=\"top: 30px; display:none;\">'\n                            + exporter_anchors(\"TLE.batch_down\")\n                          + '</div>');\n    var _task_check_click = task_check_click;\n    task_check_click = function() {\n      _task_check_click();\n      if ($(\"#li_task_down,#li_task_download\").hasClass(\"noit\")) {\n        $(\"#TLE_batch_down\").addClass(\"noit\").unbind(\"click\");\n      } else {\n        $(\"#TLE_batch_down\").removeClass(\"noit\").unbind(\"click\").click(function() {\n          $(\"#TLE_batch_getbtn\").css(\"left\", $(\"#TLE_batch_down\").position().left);\n          $(\"#TLE_batch_getbtn\").toggle();\n          return false;\n        });\n      };\n      //console.log(\"task_check_click called\");\n    };\n    $('input[name=ck],input#ckbutton').click(task_check_click);\n\n    //bt_down\n    $(\"#view_bt_list_nav_tpl\").text($(\"#view_bt_list_nav_tpl\").text().replace('取回本地</em></span></a>',\n          '取回本地</em></span></a>'\n          +'<a href=\"#\" class=\"btn_m noit\" title=\"批量导出\" id=\"TLE_bt_down\"><span><em class=\"icdwlocal\">批量导出</em></span></a>'\n          +'<div id=\"TLE_bt_getbtn\" class=\"TLE_getbtn\" style=\"top: 30px; display:none;\">'\n            + exporter_anchors(\"TLE.bt_down\")\n          + '</div>'));\n    $(\"#view_bt_list_tpl\").text($(\"#view_bt_list_tpl\").text().replace('ic_redownloca\" title=\"\">取回本地</a>',\n        'ic_redownloca\" title=\"\">取回本地</a>'\n        +'<div class=\"TLE_get_btnbox\">'\n          + '<span class=\"TLE_getlink\">'\n            + '<a href=\"#\" class=\"TLE_link_gettxt TLE-down-text\" style=\"padding-left: 20px; width: 57px;\" onclick=\"thunder_download($[p.i],1);return false;\">取回本地</a>'\n            + '<a href=\"#\" class=\"TLE_link_getic TLE-down-btn\" onclick=\"return TLE.getbtn(this);\"></a>'\n          + '</span>'\n          + '<div class=\"TLE_p_getbtn TLE_getbtn\" style=\"display: none;\">'\n            + exporter_anchors(\"TLE.bt_down_one\")\n          + '</div>'\n        + '</div>'));\n    var _bt_view_nav = bt_view_nav;\n    bt_view_nav = function() {\n      _bt_view_nav();\n      if ($(\"#view_bt_list_nav_down\").hasClass(\"noit\")) {\n        $(\"#TLE_bt_down\").addClass(\"noit\").unbind(\"click\");\n      } else {\n        $(\"#TLE_bt_down\").removeClass(\"noit\").unbind(\"click\").click(function() {\n          $(\"#TLE_bt_getbtn\").css(\"left\", $(\"#TLE_bt_down\").position().left);\n          $(\"#TLE_bt_getbtn\").toggle();\n          return false;\n        });\n      };\n      $(\"#TLE_bt_getbtn\").hide();\n      //console.log(\"bt_view_nav called\");\n    };\n\n    //close menu binding\n    $(document.body).bind(\"click\",function(){\n      $(\"div.TLE_p_getbtn, #TLE_batch_getbtn, #TLE_bt_getbtn\").hide();\n    });\n    $(\"div.rw_list\").click(function(e){\n      $(\"div.TLE_p_getbtn, #TLE_batch_getbtn, #TLE_bt_getbtn\").hide();\n    });\n    $(\"div.TLE_get_btnbox\").click(function(e){e.stopPropagation();});\n  };\n\n  init();\n})(TLE);\n\nvar ARIA2 = (function() {\n  var jsonrpc_version = '2.0';\n\n  function get_auth(url) {\n    return url.match(/^(?:(?![^:@]+:[^:@\\/]*@)[^:\\/?#.]+:)?(?:\\/\\/)?(?:([^:@]*(?::[^:@]*)?)?@)?/)[1];\n  };\n\n  function request(jsonrpc_path, method, params) {\n    var request_obj = {\n      jsonrpc: jsonrpc_version,\n      method: method,\n      id: (new Date()).getTime().toString(),\n    };\n    if (params) request_obj['params'] = params;\n\n    var xhr = new XMLHttpRequest();\n    var auth = get_auth(jsonrpc_path);\n    jsonrpc_path = jsonrpc_path.replace(/^((?![^:@]+:[^:@\\/]*@)[^:\\/?#.]+:)?(\\/\\/)?(?:(?:[^:@]*(?::[^:@]*)?)?@)?(.*)/, '$1$2$3'); // auth string not allowed in url for firefox\n    xhr.open(\"POST\", jsonrpc_path+\"?tm=\"+(new Date()).getTime().toString(), true);\n    xhr.setRequestHeader(\"Content-Type\", \"application/x-www-form-urlencoded; charset=UTF-8\");\n    if (auth) xhr.setRequestHeader(\"Authorization\", \"Basic \"+btoa(auth));\n    xhr.send(JSON.stringify(request_obj));\n  };\n\n  return function(jsonrpc_path) {\n    this.jsonrpc_path = jsonrpc_path;\n    this.addUri = function (uri, options) {\n      request(this.jsonrpc_path, 'aria2.addUri', [[uri, ], options]);\n    };\n    return this;\n  }\n})();\n} // end of wrapper\n\nfunction tle_lx3_wrapper() {\nseajs.use(\"jquery\", function(){\n// vim: set et sw=2 ts=2 sts=2 ff=unix fenc=utf8:\n// Author: Binux<i@binux.me>\n//         http://binux.me\n// Created on 2013-12-27 23:00:34\n\nTLE = {};\n\nTLE.exporter = {\n  '复制链接': function(todown) {\n    //console.log(todown);\n    var str = '<ul style=\"max-height: 300px; overflow-y: scroll; overflow-x: hidden;\">';\n    $.each(todown.tasklist, function(n, task) {\n      $.each(task.filelist, function(l, file) {\n        if (!file.downurl) return;\n        str += '<li><a href=\"'+TLE.url_rewrite(file.downurl, TLE.safe_title(file.title))+'\" target=\"_blank\">'+file.title+'</a></li>';\n      });\n    });\n    str += \"</ul>\";\n    TLE.window_pop('复制选中的链接 &gt; <a href=\"'+\"data:text/html;charset=utf-8,\"+encodeURIComponent(str)+'\" target=\"_blank\">在新窗口中打开</a>', str);\n  },\n  'Aria2': function(todown) {\n    //console.log(todown);\n    var str = \"\";\n    $.each(todown.tasklist, function(n, task) {\n      $.each(task.filelist, function(l, file) {\n        if (!file.downurl) return;\n        var filepath = TLE.safe_title(file.title);\n        if (task.tasktype === 0 && task.filelist.length > 1)\n          filepath = TLE.safe_title(task.taskname) + \"/\" + TLE.safe_title(file.title.replace(/\\\\+\\*?/g,\"/\"));\n        str += \"aria2c -c -s10 -x10 --out \"+TLE.escape_command(filepath)+\" --header 'Cookie: gdriveid=\"+todown.gdriveid+\";' '\"+file.downurl+\"'\\n\";\n      });\n    });\n    TLE.text_pop(\"aria2 download command\", str);\n  },\n  'wget': function(todown) {\n    //console.log(todown);\n    var str = \"\";\n    $.each(todown.tasklist, function(n, task) {\n      $.each(task.filelist, function(l, file) {\n        if (!file.downurl) return;\n        str += \"wget -c -O \"+TLE.escape_command(TLE.safe_title(file.title))+\" --header 'Cookie: gdriveid=\"+todown.gdriveid+\";' '\"+file.downurl+\"'\\n\";\n      });\n    });\n    TLE.text_pop(\"wget download command\", str);\n  },\n  'mpv': function(todown) {\n    //console.log(todown);\n    var str = \"\";\n    $.each(todown.tasklist, function(n, task) {\n      $.each(task.filelist, function(l, file) {\n        if (!file.downurl) return;\n        str += \"mpv --really-quiet --cache 8140 --cache-default 8140 --http-header-fields 'Cookie: gdriveid=\"+todown.gdriveid+\";' '\"+file.downurl+\"'\\n\";\n      });\n    });\n    TLE.text_pop(\"play with mpv\", str);\n  },\n  'mplayer': function(todown) {\n    //console.log(todown);\n    var str = \"\";\n    $.each(todown.tasklist, function(n, task) {\n      $.each(task.filelist, function(l, file) {\n        if (!file.downurl) return;\n        str += \"mplayer -really-quiet -cache 8140 -http-header-fields 'Cookie: gdriveid=\"+todown.gdriveid+\";' '\"+file.downurl+\"'\\n\";\n      });\n    });\n    TLE.text_pop(\"play with mplayer\", str);\n  },\n  \"YAAW\": function(todown) {\n    if (TLE.getConfig(\"TLE_aria2_jsonrpc\")) {\n      TLE.tip(\"添加中...到YAAW界面查看是否添加成功\");\n      var aria2 = new ARIA2(TLE.getConfig(\"TLE_aria2_jsonrpc\"));\n      $.each(todown.tasklist, function(n, task) {\n        $.each(task.filelist, function(l, file) {\n          if (!file.downurl) return;\n          var filepath = TLE.safe_title(file.title);\n          if (task.tasktype === 0 && task.filelist.length > 1)\n            filepath = TLE.safe_title(task.taskname) + \"/\" + TLE.safe_title(file.title.replace(/\\\\+\\*?/g,\"/\"));\n          aria2.addUri(file.downurl, {out: filepath, header: 'Cookie: gdriveid='+todown.gdriveid});\n        });\n      });\n      TLE.hide_tip();\n    } else {\n      TLE.tip(\"尚未设置Aria2 JSONRPC地址\", 5);\n    }\n  },\n  'Aria2导出': function(todown) {\n    //console.log(todown);\n    var str = \"\";\n    $.each(todown.tasklist, function(n, task) {\n      $.each(task.filelist, function(l, file) {\n        if (!file.downurl) return;\n        var filepath = TLE.safe_title(file.title);\n        if (task.tasktype === 0 && task.filelist.length > 1)\n          filepath = TLE.safe_title(task.taskname) + \"/\" + TLE.safe_title(file.title.replace(/\\\\+\\*?/g,\"/\"));\n        str += file.downurl+'\\r\\n  out='+filepath+'\\r\\n  header=Cookie: gdriveid='+todown.gdriveid+'\\r\\n  continue=true\\r\\n  max-connection-per-server=5\\r\\n  split=10\\r\\n  parameterized-uri=true\\r\\n\\r\\n';\n      });\n    });\n    TLE.file_pop(\"Aria2导出文件下载\", str, \"aria2.down\");\n  },\n  'IDM导出': function(todown) {\n    //console.log(todown);\n    var str = \"\";\n    $.each(todown.tasklist, function(n, task) {\n      $.each(task.filelist, function(l, file) {\n        if (!file.downurl) return;\n        str += '<\\r\\n'+TLE.url_rewrite(file.downurl, TLE.safe_title(file.title))+'\\r\\ncookie: gdriveid='+todown.gdriveid+'\\r\\n>\\r\\n';\n      });\n    });\n    TLE.file_pop(\"IDM导出文件下载\", str, \"idm.ef2\");\n  },\n  'Orbit导出': function(todown) {\n    //console.log(todown);\n    var str = \"\";\n    $.each(todown.tasklist, function(n, task) {\n      $.each(task.filelist, function(l, file) {\n        if (!file.downurl) return;\n        str += TLE.url_rewrite(file.downurl, TLE.safe_title(file.title))+'|'+TLE.safe_title(file.title.replace(\"|\", \"_\"))+'||gdriveid='+todown.gdriveid+'\\r\\n';\n      });\n    });\n    TLE.file_pop(\"Orbit导出文件下载\", str, \"orbit.olt\");\n  },\n  'eagleget导出': function(todown) {\n    var ret = {tasks: []};\n    $.each(todown.tasklist, function(n, task) {\n      $.each(task.filelist, function(l, file) {\n        if (!file.downurl) return;\n        ret.tasks.push({\n          cookie: 'gdriveid='+todown.gdriveid,\n          fname: TLE.safe_title(file.title),\n          url: TLE.url_rewrite(file.downurl, TLE.safe_title(file.title))\n        });\n      });\n    });\n    TLE.file_pop(\"Eagleget导出文件下载(test)\", JSON.stringify(ret), \"eagleget.eg\");\n  },\n};\n\n(function(TLE) {\n  function get_taskinfo(taskid) {\n    return {\n      taskname: $(\"#tr_c\"+taskid+\" .title .w_title\").attr(\"title\"),\n      title: $(\"#tr_c\"+taskid+\" .title .w_title\").attr(\"title\"),\n      f_url: $(\"#f_url\"+taskid).val(),\n      downurl: $(\"#dl_url\"+taskid).val(),\n      cid: $(\"#dcid\"+taskid).val(),\n      gcid: $(\"#gcid\"+taskid).val(),\n      size: parseInt($(\"#ysfilesize\"+taskid).val()),\n      tasktype: parseInt($(\"#d_tasktype\"+taskid).val()),\n      status: $(\"#d_status\"+taskid).val(),\n    };\n  }\n  function get_bt_taskinfo(taskid) {\n    return {\n      title: $(\"#bt_taskname\"+taskid).val(),\n      f_url: $(\"#bturl\"+taskid).val(),\n      downurl: $(\"#btdownurl\"+taskid).val(),\n      cid: $(\"#btcid\"+taskid).val(),\n      gcid: $(\"#btgcid\"+taskid).val(),\n      size: $(\"#bt_filesize\"+taskid).val(),\n      status: $(\"#btd_status\"+taskid).val(),\n    };\n  }\n\n  function build_bt_taskinfo(info, rdata) {\n    var taskinfo = {\n      'taskname': info.taskname,\n      'f_url': info.f_url,\n      'cid': info.dcid,\n      'size': parseInt(info.ysfilesize),\n      'tasktype': parseInt(info.d_tasktype),\n      'status': info.d_status,\n    };\n    var filelist = [];\n    $.each(rdata, function(n, e) {\n      filelist.push({\n        'title': e.title,\n        'f_url': e.url,\n        'downurl': e.downurl,\n        'cid': e.cid,\n        'gcid': e.gcid,\n        'size': parseInt(e.filesize),\n      });\n    });\n    taskinfo['filelist'] = filelist;\n    return taskinfo;\n  };\n\n  TLE.safe_title = function safe_title(title) {\n    return title.replace(/[\\\\\\|\\:\\*\\\"\\?\\<\\>]/g,\"_\");\n  };\n\n  TLE.bt_down = function(_this, _do) {\n    var ck = document.getElementsByName(\"bt_list_ck\");\n    var files = [];\n    $.each(ck, function(n, e) {\n      if (e.checked == false) return;\n      var fid = e.getAttribute(\"_i\");\n      var file = {\n        'title': $(\"#bt_taskname\"+fid).val(),\n        'url': $(\"#bturl\"+fid).val(),\n        'downurl': $(\"#btdownurl\"+fid).val(),\n        'cid': $(\"#btcid\"+fid).val(),\n        'gcid': $(\"#btgcid\"+fid).val(),\n        'filesize': $(\"#bt_filesize\"+fid).val(),\n      };\n      files.push(file);\n    });\n    var taskid = $(\"#view_bt_taskid\").val();\n    var info = get_taskinfo($(\"#tr_c\"+taskid));\n\n    var todown = {};\n    todown.gdriveid = getCookie(\"gdriveid\") || $(\"#cok\").val();\n    todown.tasklist = {};\n    todown.tasklist[taskid] = build_bt_taskinfo(info, files);\n    //console.log(todown);\n\n    _do(todown);\n\n    //console.log(\"bt_down\");\n  };\n\n  TLE.text_pop = function(title, content) {\n    content = $('<div></div>').text(content).html()\n    content = '<textarea style=\"width: 100%; height: 260px;\">'+content+'</textarea>'\n    $(\"#TLE_text_pop\").tpl(\"TLE_text_tpl\", {'title': title, 'content': content}).show().pop({\n      //onHide: function() { $(document.body).click(); },\n    });\n  };\n  TLE.file_pop = function(title, content, filename) {\n    var url = \"data:text/html;charset=utf-8,\"+encodeURIComponent(content);\n    if (isChrome) {\n      $('<a href=\"'+url+'\" target=\"_blank\" style=\"display:none;\" download=\"'+filename+'\"></a>').appendTo('body').get(0).click();\n    } else {\n      var content = '<div style=\"width: 100%; height: 100px;\">'\n                      +'<div style=\"padding: 30px 0 0 30%;\">'\n                        +'<a href=\"'+url+'\" target=\"_blank\" title=\"右键另存为\" class=\"pop_btn\" download=\"'+filename+'\"><span><em class=\"TLE_icdwlocal\">导出文件</em></span></a>'\n                        +(isChrome ? '' : '(右键另存为'+filename+')')\n                      +'</div>'\n                   +'</div>'\n      $(\"#TLE_text_pop\").tpl(\"TLE_text_tpl\", {'title': title, 'content': content}).show().pop({\n        //onHide: function() { $(document.body).click(); },\n      });\n    }\n  };\n  TLE.window_pop = function(title, content) {\n    $(\"#TLE_text_pop\").tpl(\"TLE_text_tpl\", {'title': title, 'content': content}).show().pop({\n      //onHide: function() { $(document.body).click(); },\n    });\n  };\n  TLE.tip = function(content, time) {\n    TS2.show(content, time);\n  };\n  TLE.hide_tip = function() {\n    TS2.hide();\n  };\n\n  TLE.multiple_server_fix = function(url) {\n    return \"'\"+url.replace(\"gdl\", \"'{gdl,dl.{f,g,h,i,twin}}'\")+\"'\";\n  }\n\n  function encode_utf8(s) {\n    return unescape( encodeURIComponent( s ) );\n  };\n  function to_hex(num) {\n    var s = num.toString(16);\n    if (s.length == 1)\n      return '0'+s;\n    else\n      return s;\n  };\n  var thunder_filename_mask = [0x61, 0x31, 0xe4, 0x5f, 0x00, 0x00, 0x00, 0x00];\n  function thunder_filename_encode(filename) {\n    var result = [\"01\", ];\n    $.each(encode_utf8(filename), function(i, n) {\n      result.push(to_hex(n.charCodeAt(0)^thunder_filename_mask[i%8]).toUpperCase())\n    });\n    while (result.length % 8 != 1) {\n      result.push(to_hex(thunder_filename_mask[(result.length-1)%8]).toUpperCase());\n    }\n    return result.join(\"\");\n  };\n\n  TLE.url_rewrite = function(url, filename) {\n    url = url.replace(/&n=\\w+/, \"&n=\"+thunder_filename_encode(filename));\n    return url;\n  };\n\n  var alpha = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\";\n  TLE.escape_command = function(str) {\n    var result = \"\";\n    for (var i = 0; i < str.length; i++) {\n      if (alpha.indexOf(str[i]) == -1)\n        result += \"\\\\\"+str[i];\n      else\n        result += str[i];\n    }\n    return result;\n  };\n\n  //setting\n  TLE.getConfig = function(key) {\n    if (window.localStorage) {\n      return window.localStorage.getItem(key) || \"\";\n    } else {\n      return getCookie(key);\n    }\n  };\n  TLE.setConfig = function(key, value) {\n    if (window.localStorage) {\n      window.localStorage.setItem(key, value);\n    } else {\n      setGdCookie(key, value, 86400*365);\n    }\n  };\n  //set default config\n  if (TLE.getConfig(\"TLE_exporter\") == \"\") {\n    var exporters = [];\n    for (var key in TLE.exporter) {\n      exporters.push(key);\n    };\n    TLE.setConfig(\"TLE_exporter\", exporters.join(\"|\"));\n  };\n\n  function init() {\n    //css\n    $(\"head\").append('<style>'\n          +'#TLE_setting { padding: 10px 20px 20px 20px; }'\n          +'#TLE_setting span { padding-left: 1em; }'\n          +'#TLE_setting li { margin-top: 0.5em; }'\n          +'#TLE_exporter_select { padding: 10px 20px 20px 20px; }'\n          +'</style>');\n    //pop\n    $(\"body\").append('<div id=\"TLE_text_pop\" class=\"lixian_pop_wp pop_w400\" style=\"display:none;margin:0;\"></div>');\n    $(\"body\").append('<textarea id=\"TLE_text_tpl\" style=\"display: none;\"></textarea>');\n    $(\"#TLE_text_tpl\").text('<div class=\"lixian_pop\">'\n                            +'<div class=\"l_p_hd\">'\n                              +'<h3>$[title]</h3>'\n                            +'</div>'\n                            +'<div class=\"l_p_bd\">'\n                              +'$[content]'\n                            +'</div>'\n                            +'<a class=\"pop_close\" title=\"关闭浮层\" close=\"1\" id=\"close\">关闭浮层</a>'\n                          +'</div>');\n    //setting\n    $(\"#view_down_bar ul\").prepend('<li> <a href=\"#\" id=\"TLE_setting_anchor\">TLE设置</a></li>');\n    $(\"#TLE_setting_anchor\").on(\"click\", function() {\n      var content = '<div id=\"TLE_setting\"><ul>'\n                      +'<li><b>启用以下导出器</b></li>'\n                      +'<li>'+(function(){\n                        var enabled_exporter = TLE.getConfig(\"TLE_exporter\").split(\"|\");\n                        var str = '';\n                        for (var name in TLE.exporter) {\n                          str += '<span class=\"rw_col\"><input type=\"checkbox\" class=\"TLE_setting_ck\" name=\"TLE_ck_'+name+'\" '+(enabled_exporter.indexOf(name) == -1 ? \"\" : \"checked\")+' />'+name+'</span>';\n                        }\n                        return str;\n                      })()+'</li>'\n                      +'<li><b>Aria2 JSON-RPC Path</b></li>'\n                      +'<li>Path: <input type=\"text\" id=\"TLE_aria2_jsonrpc\" style=\"width: 350px\" value=\"'+TLE.getConfig(\"TLE_aria2_jsonrpc\")+'\"/></li>'\n                    +'</ul>'\n                  +'</div>'\n                +'</div>'\n                +'<div class=\"l_p_ft\"><div class=\"btn_area\"><a id=\"TLE_setting_ok\" class=\"pop_btn\">确定</a> <a close=\"1\" class=\"pop_btn pop_btn_cancel\">取消</a></div></div>';\n      $(\"#TLE_text_pop\").tpl(\"TLE_text_tpl\", {title: \"Thunder Lixian Exporter 设定\", content: content}).show().pop();\n      $(\"#TLE_setting_ok\").on(\"click\", function() {\n        var enabled_exporter = [];\n        $(\".TLE_setting_ck\").each(function(n, e) {\n          if (e.checked) enabled_exporter.push(e.name.replace(/^TLE_ck_/, \"\"));\n        });\n        var config_str = (enabled_exporter.length == 0) ? \"_\" : enabled_exporter.join(\"|\");\n        var jsonrpc_path = $(\"#TLE_aria2_jsonrpc\").val();\n        if (TLE.getConfig(\"TLE_exporter\") != config_str || TLE.getConfig(\"TLE_aria2_jsonrpc\") != jsonrpc_path) {\n          TLE.setConfig(\"TLE_exporter\", config_str);\n          TLE.setConfig(\"TLE_aria2_jsonrpc\", jsonrpc_path);\n        }\n        $(\"a.pop_close:visible\").click();\n        TLE.tip(\"配置已保存\", 5);\n      });\n    });\n    //download binding\n    function exporter_anchors() {\n      var enabled_exporter = TLE.getConfig(\"TLE_exporter\").split(\"|\");\n      var str = '';\n      $.each(TLE.exporter, function(n, f) {\n        if (enabled_exporter.indexOf(n) == -1) return;\n        str+=('<li><a href=\"#\" title=\"'+n+'\" onclick=\"TLE.exporter[\\''+n+'\\'](TLE.todown);return false;\">'+n+'</a></li>');\n      });\n      return str;\n    }\n    function show_exporter_selector() {\n      $(\"#TLE_text_pop\").tpl(\"TLE_text_tpl\", {title: \"您正在使用Thunder Lixian Exporter\",\n                             content: '<ul id=\"TLE_exporter_select\">'\n                             +exporter_anchors()\n                             +'</ul>'}).pop();\n    }\n\n    TLE.todown = {};\n    window.thunder_download = function(taskid, type) {\n      TLE.todown = {};\n      TLE.todown.gdriveid = getCookie(\"gdriveid\") || $(\"#cok\").val();\n      if (type === 1) {\n        // bt_down_one\n        var taskinfo = {\n          taskname: $(\"#bt_info_list .title .w\").text(),\n          f_url: null,\n          cid: null,\n          size: null,\n          tasktype: 0,\n          status: 2,\n        }\n        var filelist = [];\n        filelist.push(get_bt_taskinfo(taskid));\n        taskinfo['filelist'] = filelist;\n        TLE.todown.tasklist = {};\n        TLE.todown.tasklist['0'] = taskinfo;\n      } else {\n        // down\n        var taskinfo = get_taskinfo(taskid);\n        var filelist = [];\n        filelist.push(get_taskinfo(taskid));\n        taskinfo['filelist'] = filelist;\n        TLE.todown.tasklist = {};\n        TLE.todown.tasklist[taskid] = taskinfo;\n      }\n      show_exporter_selector();\n    }\n    window.bt_task_down = function(cid, taskid) {\n      // bt_down\n      batch_down_all_f([taskid, ]);\n    }\n    window.batch_down_all_f = function(taskids) {\n      // batch_down\n      if (!taskids) {\n        taskids = [];\n        $(\"span[name=ck][checked]\").each(function(n, e) {\n          taskids.push($(e).attr(\"value\"));\n        });\n      }\n\n      var bt_task_list = [], normal_task_list = [];\n      $.each(taskids, function(n, taskid) {\n        var d_status = $(\"#d_status\"+taskid).val();\n        var d_tasktype = parseInt($(\"#d_tasktype\"+taskid).val());\n        var d_flag = $(\"#dflag\"+taskid).val();\n        if (d_flag != 4 && d_status == 2) {\n          if (d_tasktype == 0) {\n            bt_task_list.push(taskid);\n          } else {\n            normal_task_list.push(taskid);\n          };\n        };\n      });\n\n      if (bt_task_list.length) {\n        TLE.tip(\"载入中...\");\n        $.getJSON(INTERFACE_URL+\"/fill_bt_list?tid=\"+bt_task_list.join(\",\")+\"&g_net=\"+G_section+\"&uid=\"+G_USERID+\"&callback=?\", function(data) {\n          TLE.hide_tip();\n          var todown = {};\n          todown.gdriveid = getCookie(\"gdriveid\") || $(\"#cok\").val();\n          todown.tasklist = {};\n          $.each(data['Result'], function(n, e) {\n            var taskinfo = get_taskinfo(n);\n            var filelist = [];\n            $.each(e, function(n, e) {\n              filelist.push({\n                title: e.title,\n                f_url: e.url,\n                downurl: e.downurl,\n                cid: e.cid,\n                gcid: e.gcid,\n                size: parseInt(e.filesize),\n              });\n            });\n            taskinfo.filelist = filelist;\n            todown.tasklist[n] = taskinfo;\n          });\n          $.each(normal_task_list, function(n, e) {\n            var taskinfo = get_taskinfo(e);\n            taskinfo['filelist'] = taskinfo;\n            todown.tasklist[e] = taskinfo;\n          });\n          TLE.todown = todown;\n          show_exporter_selector();\n        });\n      } else {\n        var todown = {};\n        todown.gdriveid = getCookie(\"gdriveid\") || $(\"#cok\").val();\n        todown.tasklist = {};\n        $.each(normal_task_list, function(n, e) {\n          var taskinfo = get_taskinfo(e);\n          taskinfo['filelist'] = taskinfo;\n          todown.tasklist[e] = taskinfo;\n        });\n        TLE.todown = todown;\n        show_exporter_selector();\n      };\n    };\n    window.batch_down_bt = function() {\n      var taskids = [];\n      $(\"span[name=bt_list_ck][checked]\").each(function(n, e) {\n        var taskid = $(e).attr(\"value\");\n        if ($(\"#btd_status\"+taskid).val() == 2)\n          taskids.push(taskid);\n      });\n\n      TLE.todown = {};\n      TLE.todown.gdriveid = getCookie(\"gdriveid\") || $(\"#cok\").val();\n      var taskinfo = {\n        taskname: $(\"#bt_info_list .title .w\").text(),\n        f_url: null,\n        cid: null,\n        size: null,\n        tasktype: 0,\n        status: 2,\n      }\n      var filelist = [];\n      $.each(taskids, function(n, e) {\n        filelist.push(get_bt_taskinfo(e));\n      });\n      taskinfo['filelist'] = filelist;\n      TLE.todown.tasklist = {};\n      TLE.todown.tasklist['0'] = taskinfo;\n      show_exporter_selector();\n    }\n  }\n\n  init();\n})(TLE);\n\nvar ARIA2 = (function() {\n  var jsonrpc_version = '2.0';\n\n  function get_auth(url) {\n    return url.match(/^(?:(?![^:@]+:[^:@\\/]*@)[^:\\/?#.]+:)?(?:\\/\\/)?(?:([^:@]*(?::[^:@]*)?)?@)?/)[1];\n  };\n\n  function request(jsonrpc_path, method, params) {\n    var request_obj = {\n      jsonrpc: jsonrpc_version,\n      method: method,\n      id: (new Date()).getTime().toString(),\n    };\n    if (params) request_obj['params'] = params;\n\n    var xhr = new XMLHttpRequest();\n    var auth = get_auth(jsonrpc_path);\n    jsonrpc_path = jsonrpc_path.replace(/^((?![^:@]+:[^:@\\/]*@)[^:\\/?#.]+:)?(\\/\\/)?(?:(?:[^:@]*(?::[^:@]*)?)?@)?(.*)/, '$1$2$3'); // auth string not allowed in url for firefox\n    xhr.open(\"POST\", jsonrpc_path+\"?tm=\"+(new Date()).getTime().toString(), false);\n    xhr.setRequestHeader(\"Content-Type\", \"application/x-www-form-urlencoded; charset=UTF-8\");\n    if (auth) xhr.setRequestHeader(\"Authorization\", \"Basic \"+btoa(auth));\n    xhr.send(JSON.stringify(request_obj));\n  };\n\n  return function(jsonrpc_path) {\n    this.jsonrpc_path = jsonrpc_path;\n    this.addUri = function (uri, options) {\n      request(this.jsonrpc_path, 'aria2.addUri', [[uri, ], options]);\n    };\n    return this;\n  }\n})();\n}); // end of seajs.use\n} // end of wrapper\n\nfunction onload(func) {\n    if (document.readyState === \"complete\") {\n      func();\n    } else {\n      window.addEventListener('load', func);\n    }\n}\nonload(function(){\n  var script = document.createElement('script');\n  script.id = \"TLE_script\";\n  if (location.host == \"dynamic.cloud.vip.xunlei.com\") {\n    script.appendChild(document.createTextNode('('+ tle_wrapper +')();'));\n  } else if (location.host == \"lixian.vip.xunlei.com\" || location.host == \"jiayuan.xunlei.com\") {\n    script.appendChild(document.createTextNode('('+ tle_lx3_wrapper +')();'));\n  }\n  (document.body || document.head || document.documentElement).appendChild(script);\n});\n"
        },
        {
          "name": "bt.py",
          "type": "blob",
          "size": 14.345703125,
          "content": "#!/usr/bin/env python2\n# vim: set fileencoding=utf8\n\nimport bencode\nimport os\nimport sys\nimport re\nfrom hashlib import sha1\nimport base64\nimport requests\nimport urlparse\nimport argparse\n\ns = '\\x1b[%d;%dm%s\\x1b[0m'       # terminual color template\nletters = [i for i in '.abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ' \\\n           + '0123456789']\n\n############################################################\nheaders = {\n    \"Connection\": \"keep-alive\",\n    \"Accept\":\"text/html,application/xhtml+xml,\\\n        application/xml;q=0.9,image/webp,*/*;q=0.8\",\n    \"Accept-Encoding\":\"gzip,deflate,sdch\",\n    \"Accept-Language\":\"en-US,en;q=0.8,zh-CN;\\\n        q=0.6,zh;q=0.4,zh-TW;q=0.2\",\n    \"User-Agent\":\"Mozilla/5.0 (X11; Linux x86_64) \\\n        AppleWebKit/537.36 (KHTML, like Gecko) \\\n        Chrome/40.0.2214.91 Safari/537.36\"\n}\n\nss = requests.session()\nss.headers.update(headers)\n\ndef save_img(url, ext):\n    path = os.path.join(os.path.expanduser('~'), 'vcode.%s' % ext)\n    with open(path, 'w') as g:\n        data = requests.get(url).content\n        g.write(data)\n    print \"  ++ 验证码已保存至\", s % (1, 97, path)\n    input_code = raw_input(s % (2, 92, \"  输入验证码: \"))\n    return input_code\n\nclass Bt(object):\n    def transfer(self, string, tpath, foo=None, bar=None):\n        self.dir_dict = {}\n        self.sub_dir_index = 0\n\n        dstring = bencode.bdecode(string)\n        files = []\n        file_index = 0\n\n        ## change files' name\n        if dstring['info'].get('files'):\n            for fl in dstring['info']['files']:\n                filename = fl['path'][-1]\n                if args.type_ == 'n':\n                    newfilename = re.sub(foo, bar, filename, re.I) \\\n                        if foo and bar else filename\n                    if filename != newfilename:\n                        print filename, s % (1, 92, '==>'), newfilename\n                        path = [self._get_sub_dir_index(i) \\\n                                for i in fl['path'][:-1]]  + [newfilename]\n                    else:\n                        ext = os.path.splitext(filename)[-1]\n                        ext = self._check_ext(ext)\n                        path = [self._get_sub_dir_index(i) \\\n                                for i in fl['path'][:-1]] \\\n                                + ['%s%s' % (file_index, ext)]\n                    file_index += 1\n                    fl['path'] = path\n\n                elif args.type_ == 'be64':\n                    fn, ext = os.path.splitext(filename)\n                    ext = self._check_ext(ext)\n                    tfn = '/'.join(fl['path'][:-1] + [fn])\n                    e_fn = base64.urlsafe_b64encode(tfn)\n                    fl['path'] = [e_fn + '.base64' + ext]\n\n                for item in fl.keys():\n                    #if item not in ['path', 'length', 'filehash', 'ed2k']:\n                    if item not in ['path', 'length', 'filehash']:\n                        del fl[item]\n\n                files.append(fl)\n            dstring['info']['files'] = files\n\n        ## change top directory\n        for i in dstring['info'].keys():\n            if i not in ['files', 'piece length', 'pieces', 'name', 'length']:\n                del dstring['info'][i]\n            elif 'name' in i:\n                if args.name:\n                    dstring['info'][i] = args.name\n\n        ## delete comment and creator\n        for i in dstring.keys():\n            if i not in ['creation date', 'announce', 'info', 'encoding']:\n                del dstring[i]\n\n        c = bencode.bencode(dstring)\n        with open(tpath, 'w') as g:\n            g.write(c)\n\n    def _get_sub_dir_index(self, dir_):\n        if not self.dir_dict.get(dir_):\n            self.dir_dict[dir_] = str(self.sub_dir_index)\n            self.sub_dir_index += 1\n            return self.dir_dict[dir_]\n        else:\n            return self.dir_dict[dir_]\n\n    def _check_ext(self, ext):\n        if len(ext) > 4:\n            return ''\n\n        for e in ext:\n            if e not in letters:\n                return ''\n\n        return ext\n\n    def get_torrent(self, hh):\n        print s % (1, 93, '\\n  ++ get torrent from web')\n\n        def do(url, data=None, timeout=None):\n            try:\n                proxies = {'http': args.proxy} if args.proxy else None\n                r = ss.get(url, proxies=proxies, timeout=timeout)\n                cnt = r.content\n                if r.ok and cnt and '<head>' not in cnt \\\n                    and '4:name' in cnt:\n                    print s % (1, 92, '  √ get torrent.')\n                    return cnt\n                else:\n                    print s % (1, 91, '  × not get.')\n                    return None\n            except:\n                return None\n\n        ## xunlei\n        print s % (1, 94, '  >> try:'), 'bt.box.n0808.com'\n        url = 'http://bt.box.n0808.com/%s/%s/%s.torrent' \\\n            % (hh[:2], hh[-2:], hh)\n        ss.headers['Referer'] = 'http://bt.box.n0808.com'\n        result = do(url)\n        if result: return result\n\n        ## https://torrage.com\n        if ss.headers.get('Referer'): del ss.headers['Referer']\n        print s % (1, 94, '  >> try:'), 'torrage.com'\n        url = 'http://torrage.com/torrent/%s.torrent' % hh\n        try:\n            result = do(url)\n            if result: return result\n        except:\n            pass\n\n        ## http://btcache.me\n        if ss.headers.get('Referer'): del ss.headers['Referer']\n        print s % (1, 94, '  >> try:'), 'btcache.me'\n        url = 'http://btcache.me/torrent/%s' % hh\n        r = ss.get(url)\n        key = re.search(r'name=\"key\" value=\"(.+?)\"', r.content)\n        if key:\n            url = 'http://btcache.me/captcha'\n            vcode = save_img(url, 'png')\n            data = {\n                \"key\": key.group(1),\n                \"captcha\": vcode\n            }\n            ss.headers['Referer'] = url\n            url = 'http://btcache.me/download'\n            result = do(url, data=data)\n            if result: return result\n        else:\n            print s % (1, 91, '  × not get.')\n\n        ## torrent stores\n        if ss.headers.get('Referer'): del ss.headers['Referer']\n        urls = [\n                #'http://www.sobt.org/Tool/downbt?info=%s',\n                'http://www.win8down.com/url.php?hash=%s&name=name',\n                #'http://www.31bt.com/Torrent/%s',\n                'http://178.73.198.210/torrent/%s',\n                'http://zoink.it/torrent/%s.torrent',\n                'http://torcache.net/torrent/%s.torrent',\n                'http://torrentproject.se/torrent/%s.torrent',\n                'http://istoretor.com/fdown.php?hash=%s',\n                'http://torrentbox.sx/torrent/%s',\n                'http://www.torrenthound.com/torrent/%s',\n                'http://www.silvertorrent.org/download.php?id=%s',\n        ]\n        for url in urls:\n            print s % (1, 94, '  >> try:'), urlparse.urlparse(url).hostname\n            url = url % hh\n            try:\n                result = do(url)\n                if result: return result\n            except:\n                print s % (1, 91, '  !! Error at connection')\n\n        ## with Vuze\n        #print s % (1, 94, '  >> try:'), 'magnet.vuze.com'\n        #if ss.headers.get('Referer'): del ss.headers['Referer']\n        #chh = base64.b32encode(binascii.unhexlify(hh))\n        #url = 'http://magnet.vuze.com/magnetLookup?hash=%s' % chh\n        #result = do(url)\n        #if result: return result\n\n        return False\n\n    def magnet2torrent(self, urls, dir_):\n        for url in urls:\n            hh = re.search(r'urn:btih:(\\w+)', url)\n            if hh:\n                hh = hh.group(1).upper()\n            else:\n                print s % (1, 91, '  !! magnet is wrong.'), url\n                continue\n            string = self.get_torrent(hh)\n            if string:\n                tpath = os.path.join(dir_, hh + '.torrent')\n                print s % (1, 97, '  ++ magnet to torrent:'), \\\n                    'magnet:?xt=urn:btih:%s' % hh\n                with open(tpath, 'w') as g:\n                    g.write(string)\n            else:\n                print s % (1, 91, '  !! Can\\'t get torrent from web.'), url\n\n    def torrent2magnet(self, paths):\n        def trans(tpath):\n            if tpath.lower().endswith('torrent'):\n                string = open(tpath).read()\n                try:\n                    dd = bencode.bdecode(string)\n                except Exception as e:\n                    print s % (1, 91, '  !! torrent is wrong:'), e\n                    return None\n                info = bencode.bencode(dd['info'])\n                hh = sha1(info).hexdigest()\n                print '# %s' % tpath\n                print 'magnet:?xt=urn:btih:%s' % hh, '\\n'\n\n        for path in paths:\n            if os.path.exists(path):\n                if os.path.isdir(path):\n                    for a, b, c in os.walk(path):\n                        for i in c:\n                            tpath = os.path.join(a, i)\n                            trans(tpath)\n                elif os.path.isfile(path):\n                    tpath = path\n                    trans(tpath)\n            else:\n                print s % (1, 91, '  !! file doesn\\'t existed'), \\\n                    s % (1, 93, '--'), path\n\n    def change(self, ups, dir_, foo=None, bar=None):\n        for up in ups:\n            path = up\n            if path.startswith('magnet:'):\n                hh = re.search(r'urn:btih:(\\w+)', path)\n                if hh:\n                    hh = hh.group(1).upper()\n                else:\n                    print s % (1, 91, '  !! magnet is wrong.'), path\n                string = self.get_torrent(hh)\n                if string:\n                    tpath = os.path.join(dir_, hh + '.torrent')\n                    print s % (1, 97, '  ++ transfer:'), \\\n                        'magnet:?xt=urn:btih:%s' % hh\n                    self.transfer(string, tpath, foo=foo, bar=bar)\n                else:\n                    print s % (1, 91, '  !! Can\\'t get torrent from web.'), path\n\n            elif os.path.exists(path):\n                if os.path.isdir(path):\n                    for a, b, c in os.walk(path):\n                        for i in c:\n                            ipath = os.path.join(a, i)\n                            if i.lower().endswith('torrent'):\n                                def do():\n                                    print s % (1, 97, '  ++ transfer:'), ipath\n                                    string = open(ipath).read()\n                                    tpath = os.path.join(dir_, 'change_' + i)\n                                    self.transfer(string, tpath, foo=foo,\n                                                  bar=bar)\n                                    # ??? paths.update(ipath)\n                                if os.getcwd() == os.path.abspath(dir_):\n                                    do()\n                                elif os.getcwd() != os.path.abspath(dir_) and \\\n                                    os.path.abspath(a) != os.path.abspath(dir_):\n                                    do()\n                elif os.path.isfile(path):\n                    if path.lower().endswith('torrent'):\n                        print s % (1, 97, '  ++ transfer:'), path\n                        string = open(path).read()\n                        tpath = os.path.join(dir_,\n                                             'change_' + os.path.basename(path))\n                        self.transfer(string, tpath, foo=foo, bar=bar)\n            else:\n                print s % (1, 91, '  !! file doesn\\'t existed'), \\\n                    s % (1, 93, '--'), path\n\ndef import_magnet(froms):\n    ml = []\n    m_re = re.compile(r'btih:([a-zA-Z0-9]{40})')\n\n    def get_magnet(cm):\n        ls = m_re.findall(cm)\n        ls = ['magnet:?xt=urn:btih:' + i for i in ls]\n        return ls\n\n    for path in froms:\n        if path[0] == '~':\n            path = os.path.expanduser(path)\n        else:\n            path = os.path.abspath(path)\n\n        if os.path.isfile(path):\n            cm = open(path).read()\n            ls = get_magnet(cm)\n            ml += ls\n        elif os.path.isdir(path):\n            for a, b, c in os.walk(path):\n                for i in c:\n                    p = os.path.join(a, i)\n                    cm = open(p).read()\n                    ls = get_magnet(cm)\n                    ml += ls\n        else:\n            print s % (1, 91, '  !! path is wrong:'), path\n\n    t = set(ml)\n    return list(t)\n\ndef main(argv):\n    ######################################################\n    # for argparse\n    p = argparse.ArgumentParser(\n        description='magnet torrent 互转，数字命名bt内容文件名' \\\n        ' 用法见 https://github.com/PeterDing/iScript')\n    p.add_argument('xxx', type=str, nargs='*',\n        help='命令对象.')\n    p.add_argument('-i', '--import_from', type=str, nargs='*',\n        help='import magnet from local.')\n    p.add_argument('-p', '--proxy', action='store',\n                   type=str, help='proxy for torrage.com, \\\n                                eg: -p \"sooks5://127.0.0.1:8883\"')\n    p.add_argument('-d', '--directory', action='store', default=None,\n        type=str, help='torrents保存的路径, eg: -d /path/to/save')\n    p.add_argument('-n', '--name', action='store', default=None,\n        type=str, help='顶级文件夹名称, eg: -n thistopdirectory')\n    p.add_argument('-t', '--type_', action='store',\n        default='n', type=str,\n        help='类型参数，eg: ')\n    global args\n    args = p.parse_args(argv[2:])\n    comd = argv[1]\n    xxx = args.xxx\n\n    dir_ = os.getcwd() if not args.directory \\\n                        else args.directory\n    if not os.path.exists(dir_):\n        os.mkdir(dir_)\n    if comd == 'm' or comd == 'mt':   # magnet to torrent\n        urls = xxx if not args.import_from \\\n                    else import_magnet(args.import_from)\n        x = Bt()\n        x.magnet2torrent(urls, dir_)\n\n    elif comd == 't' or comd == 'tm':   # torrent ot magnet\n        paths = xxx\n        x = Bt()\n        x.torrent2magnet(paths)\n\n    elif comd == 'c' or comd == 'ct':   # change\n        ups = xxx if not args.import_from \\\n                    else import_magnet(args.import_from)\n        x = Bt()\n        x.change(ups, dir_, foo=None, bar=None)\n\n    elif comd == 'cr' or comd == 'ctre':   # change\n        foo = xxx[0]\n        bar = xxx[1]\n        ups = xxx[2:] if not args.import_from \\\n                        else import_magnet(args.import_from)\n        x = Bt()\n        x.change(ups, dir_, foo=foo, bar=bar)\n\n    else:\n        print s % (2, 91, '  !! 命令错误\\n')\n\nif __name__ == '__main__':\n    argv = sys.argv\n    main(argv)\n"
        },
        {
          "name": "ed2k_search.py",
          "type": "blob",
          "size": 1.935546875,
          "content": "#!/usr/bin/env python2\n# vim: set fileencoding=utf8\n\nimport sys\nimport urllib\nimport re\nimport argparse\n\ns = '\\x1b[%d;%dm%s\\x1b[0m'       # terminual color template\n\nopener = urllib.urlopen\n\nclass ed2k_search(object):\n    def __init__(self, keyword=''):\n        self.url = \"http://donkey4u.com/search/%s?page=%s&mode=list\" \\\n            % (keyword, '%s')\n        print ''\n\n    def get_infos(self, url):\n        r = opener(url)\n        assert r\n        self.html = r.read()\n        html = re.search(r'<table class=\\'search_table\\'>.+?</table>',\n                         self.html, re.DOTALL).group()\n\n        sizes = re.findall(r'<td width=\\'70\\' align=\\'right\\'>(.+)', html)\n        seeds = re.findall(r'<td width=\\'100\\' align=\\'right\\'>(.+)', html)\n        links = re.findall(r'ed2k://.+?/', html)\n\n        infos = zip(sizes, seeds, links)\n\n        if infos:\n            self.display(infos)\n        else:\n            print s % (1, 91, '  !! You are not Lucky, geting nothing.')\n            sys.exit(1)\n\n    def display(self, infos):\n        template = '  size: ' + s % (1, 97, '%s') \\\n            + '  seed: ' + s % (1, 91, '%s') \\\n            + '\\n  ----------------------------' \\\n            + '\\n  ' + s % (2, 92, '%s') \\\n            + '\\n  ----------------------------\\n'\n\n        for i in infos:\n            t = template % i\n            print t\n\n    def do(self):\n        page = 1\n        while True:\n            url = self.url % page\n            self.get_infos(url)\n            nx = raw_input(s % (1, 93, '  next page?') + ' (N/y): ')\n            if nx in ('Y', 'y'):\n                page += 1\n                print ''\n            else:\n                sys.exit(1)\n\n\ndef main(xxx):\n    keyword = ' '.join(xxx)\n    x = ed2k_search(keyword)\n    x.do()\n\nif __name__ == '__main__':\n    p = argparse.ArgumentParser(\n        description='searching ed2k at donkey4u.com')\n    p.add_argument('xxx', type=str, nargs='*', help='keyword')\n    args = p.parse_args()\n    main(args.xxx)\n"
        },
        {
          "name": "flv_cmd.py",
          "type": "blob",
          "size": 5.37890625,
          "content": "#!/usr/bin/env python2\n# vim: set fileencoding=utf8\n\nimport re\nimport requests\nimport os\nimport sys\nimport argparse\nimport random\nfrom HTMLParser import HTMLParser\nimport urllib\nimport select\n\ns = '\\x1b[%d;%dm%s\\x1b[0m'       # terminual color template\nparser = HTMLParser()\n\n############################################################\n# wget exit status\nwget_es = {\n    0: \"No problems occurred.\",\n    2: \"User interference.\",\n    1<<8: \"Generic error code.\",\n    2<<8: \"Parse error - for instance, \\\n        when parsing command-line optio.wgetrc or .netrc...\",\n    3<<8: \"File I/O error.\",\n    4<<8: \"Network failure.\",\n    5<<8: \"SSL verification failure.\",\n    6<<8: \"Username/password authentication failure.\",\n    7<<8: \"Protocol errors.\",\n    8<<8: \"Server issued an error response.\"\n}\n############################################################\n\nheaders = {\n    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) \" \\\n        \"AppleWebKit/537.36 (KHTML, like Gecko) \" \\\n        \"Chrome/40.0.2214.91 Safari/537.36\",\n    \"Accept\": \"text/html,application/xhtml+xml,application/xml;\" \\\n        \"q=0.9,image/webp,*/*;q=0.8\",\n    \"Accept-Encoding\": \"gzip, deflate, sdch\",\n    \"Accept-Language\": \"en-US,en;q=0.8\",\n    \"Referer\": \"http://flvgo.com/download\"\n}\n\nss = requests.session()\nss.headers.update(headers)\n\ndef download(info):\n    if not os.path.exists(info['dir_']):\n        os.mkdir(info['dir_'])\n\n    #else:\n        #if os.path.exists(info['filename']):\n            #return 0\n\n    num = random.randint(0, 7) % 8\n    col = s % (2, num + 90, os.path.basename(info['filename']))\n    print '\\n  ++ 正在下载:', '#', \\\n        s % (1, 97, info['n']), '/', \\\n        s % (1, 97, info['amount']), \\\n        '#', col\n\n    print info['durl']\n    cmd = 'wget -c -nv --user-agent \"%s\" -O \"%s\" \"%s\"' \\\n        % (headers['User-Agent'], info['filename'], info['durl'])\n    status = os.system(cmd)\n\n    if status != 0:     # other http-errors, such as 302.\n        wget_exit_status_info = wget_es[status]\n        print('\\n\\n ----###   \\x1b[1;91mERROR\\x1b[0m ==> \\\n              \\x1b[1;91m%d (%s)\\x1b[0m   ###--- \\n\\n' \\\n              % (status, wget_exit_status_info))\n        print s % (1, 91, '  ===> '), cmd\n        sys.exit(1)\n\ndef play(info):\n    num = random.randint(0, 7) % 8\n    col = s % (2, num + 90, os.path.basename(info['filename']))\n    print '\\n  ++ play:', '#', \\\n        s % (1, 97, info['n']), '/', \\\n        s % (1, 97, info['amount']), \\\n        '#', col\n\n    cmd = 'mpv --really-quiet --cache 8140 --cache-default 8140 ' \\\n        '--http-header-fields \"User-Agent:%s\" ' \\\n        '\"%s\"' % (headers['User-Agent'], info['durl'])\n        #'\"%s\"' % parser.unescape(info['durl'])\n\n    os.system(cmd)\n    timeout = 1\n    ii, _, _ = select.select([sys.stdin], [], [], timeout)\n    if ii:\n        sys.exit(0)\n    else:\n        pass\n\ndef flvxz_parser(cn):\n    blocks = cn.split('playerContainer')[1:]\n    infos = {}\n    title = re.search(r'class=\"name\">(.+?)<', cn).group(1)\n    infos['title'] = title\n    infos['data'] = {}\n    for bc in blocks:\n        quality = re.search(r'视频格式：(\\w+)', bc).group(1)\n        size = sum([float(s) for s in re.findall(r'>([\\d.]+) MB<', bc)])\n        durls = re.findall(r'<td><a href=\"(.+?)\">', bc)\n        infos['data'][quality] = {\n            'size': size,\n            'durls': durls\n        }\n    return infos\n\ndef pickup(infos):\n    print s % (1, 97, infos['title'])\n    print s % (1, 97, '  ++ pick a quality:')\n    sizes = [(infos['data'][q]['size'], q) for q in infos['data']]\n    sizes.sort()\n    sizes.reverse()\n    for i in xrange(len(sizes)):\n        print s % (1, 91, '  %s' % (i+1)), \\\n            str(sizes[i][0]) + 'MB\\t', sizes[i][1]\n\n    p = raw_input(s % (1, 92, '  Enter') + ' (1): ')\n    if p == '':\n        return sizes[0][1]\n    if not p.isdigit():\n        print s % (1, 91, '  !! enter error')\n        sys.exit()\n    p = int(p)\n    if p <= len(infos['data']):\n        print s % (2, 92, '  -- %s' % sizes[p-1][1])\n        return sizes[p-1][1]\n    else:\n        print s % (1, 91, '  !! enter error')\n        sys.exit()\n\ndef getext(durl):\n    if durl.find('flv'):\n        return '.flv'\n    elif durl.find('mp4'):\n        return '.mp4'\n    elif durl.find('m3u8'):\n        return '.m3u8'\n    else:\n        return '.flv'\n\ndef main(purl):\n    apiurl = 'http://flvgo.com/download?url=%s' % urllib.quote(purl)\n    ss.get('http://flvgo.com')\n    cn = ss.get(apiurl).content\n    infos = flvxz_parser(cn)\n    title = infos['title']\n    quality = pickup(infos)\n    durls = infos['data'][quality]['durls']\n\n    yes = True if len(durls) > 1 else False\n    dir_ = os.path.join(os.getcwd(), infos['title']) if yes else os.getcwd()\n\n    n = args.from_ - 1\n    amount = len(durls)\n\n    for i in xrange(n, amount):\n        info = {\n            'title': title,\n            'filename': os.path.join(dir_, str(i+1) + getext(durls[i])),\n            'durl': durls[i],\n            'dir_': dir_,\n            'amount': amount,\n            'n': n\n        }\n        if args.play:\n            play(info)\n        else:\n            download(info)\n        n += 1\n\nif __name__ == '__main__':\n    p = argparse.ArgumentParser(description='flvxz')\n    p.add_argument('url', help='site url')\n    p.add_argument('-p', '--play', action='store_true', \\\n                help='play with mpv')\n    p.add_argument('-f', '--from_', action='store', \\\n        default=1, type=int, \\\n        help='从第几个开始下载，eg: -f 42')\n    args = p.parse_args()\n    main(args.url)\n"
        },
        {
          "name": "leetcode_problems.py",
          "type": "blob",
          "size": 4.048828125,
          "content": "#!/usr/bin/env python\n# -*- coding=utf-8 -*-\n\nimport sys\nimport re\nimport os\nimport argparse\nimport requests\nfrom lxml import html as lxml_html\n\ntry:\n    import html\nexcept ImportError:\n    import HTMLParser\n    html = HTMLParser.HTMLParser()\n\ntry:\n    import cPickle as pk\nexcept ImportError:\n    import pickle as pk\n\nclass LeetcodeProblems(object):\n    def get_problems_info(self):\n        leetcode_url = 'https://leetcode.com/problemset/algorithms'\n        res = requests.get(leetcode_url)\n        if not res.ok:\n            print('request error')\n            sys.exit()\n        cm = res.text\n        cmt = cm.split('tbody>')[-2]\n        indexs = re.findall(r'<td>(\\d+)</td>', cmt)\n        problem_urls = ['https://leetcode.com' + url \\\n                        for url in re.findall(\n                            r'<a href=\"(/problems/.+?)\"', cmt)]\n        levels = re.findall(r\"<td value='\\d*'>(.+?)</td>\", cmt)\n        tinfos = zip(indexs, levels, problem_urls)\n        assert (len(indexs) == len(problem_urls) == len(levels))\n        infos = []\n        for info in tinfos:\n            res = requests.get(info[-1])\n            if not res.ok:\n                print('request error')\n                sys.exit()\n            tree = lxml_html.fromstring(res.text)\n            title = tree.xpath('//meta[@property=\"og:title\"]/@content')[0]\n            description = tree.xpath('//meta[@property=\"description\"]/@content')\n            if not description:\n                description = tree.xpath('//meta[@property=\"og:description\"]/@content')[0]\n            else:\n                description = description[0]\n            description = html.unescape(description.strip())\n            tags = tree.xpath('//div[@id=\"tags\"]/following::a[@class=\"btn btn-xs btn-primary\"]/text()')\n            infos.append(\n                {\n                    'title': title,\n                    'level': info[1],\n                    'index': int(info[0]),\n                    'description': description,\n                    'tags': tags\n                }\n            )\n\n        with open('leecode_problems.pk', 'wb') as g:\n            pk.dump(infos, g)\n        return infos\n\n    def to_text(self, pm_infos):\n        if self.args.index:\n            key = 'index'\n        elif self.args.title:\n            key = 'title'\n        elif self.args.tag:\n            key = 'tags'\n        elif self.args.level:\n            key = 'level'\n        else:\n            key = 'index'\n\n        infos = sorted(pm_infos, key=lambda i: i[key])\n\n        text_template = '## {index} - {title}\\n' \\\n            '~{level}~  {tags}\\n' \\\n            '{description}\\n' + '\\n' * self.args.line\n        text = ''\n        for info in infos:\n            if self.args.rm_blank:\n                info['description'] = re.sub(r'[\\n\\r]+', r'\\n', info['description'])\n            text += text_template.format(**info)\n\n        with open('leecode problems.txt', 'w') as g:\n            g.write(text)\n\n    def run(self):\n        if os.path.exists('leecode_problems.pk') and not self.args.redownload:\n            with open('leecode_problems.pk', 'rb') as f:\n                pm_infos = pk.load(f)\n        else:\n            pm_infos = self.get_problems_info()\n\n        print('find %s problems.' % len(pm_infos))\n        self.to_text(pm_infos)\n\ndef handle_args(argv):\n    p = argparse.ArgumentParser(description='extract all leecode problems to location')\n    p.add_argument('--index', action='store_true', help='sort by index')\n    p.add_argument('--level', action='store_true', help='sort by level')\n    p.add_argument('--tag', action='store_true', help='sort by tag')\n    p.add_argument('--title', action='store_true', help='sort by title')\n    p.add_argument('--rm_blank', action='store_true', help='remove blank')\n    p.add_argument('--line', action='store', type=int, default=10, help='blank of two problems')\n    p.add_argument('-r', '--redownload', action='store_true', help='redownload data')\n    args = p.parse_args(argv[1:])\n    return args\n\ndef main(argv):\n    args = handle_args(argv)\n    x = LeetcodeProblems()\n    x.args = args\n    x.run()\n\nif __name__ == '__main__':\n    argv = sys.argv\n    main(argv)\n"
        },
        {
          "name": "music.163.com.py",
          "type": "blob",
          "size": 16.8330078125,
          "content": "#!/usr/bin/env python2\n# vim: set fileencoding=utf8\n\nimport re\nimport sys\nimport os\nimport random\nimport time\nimport json\nimport argparse\nimport urllib\nimport requests\nimport select\nimport md5\nfrom mutagen.id3 import ID3,TRCK,TIT2,TALB,TPE1,APIC,TDRC,COMM,TPOS,USLT\nfrom HTMLParser import HTMLParser\n\nparser = HTMLParser()\ns = u'\\x1b[%d;%dm%s\\x1b[0m'       # terminual color template\n\n############################################################\n# music.163.com api\n# {{{\nurl_song = \"http://music.163.com/api/song/detail?id=%s&ids=%s\"\nurl_album = \"http://music.163.com/api/album/%s\"\nurl_playlist = \"http://music.163.com/api/playlist/detail?id=%s&ids=%s\"\nurl_dj = \"http://music.163.com/api/dj/program/detail?id=%s&ids=%s\"\nurl_artist_albums = \"http://music.163.com\\\n    /api/artist/albums/%s?offset=0&limit=1000\"\nurl_artist_top_50_songs = \"http://music.163.com/artist?id=%s\"\n# }}}\n############################################################\n\n############################################################\n# wget exit status\nwget_es = {\n    0:\"No problems occurred.\",\n    2:\"User interference.\",\n    1<<8:\"Generic error code.\",\n    2<<8:\"Parse error - for instance, when parsing command-line ' \\\n        'optio.wgetrc or .netrc...\",\n    3<<8:\"File I/O error.\",\n    4<<8:\"Network failure.\",\n    5<<8:\"SSL verification failure.\",\n    6<<8:\"Username/password authentication failure.\",\n    7<<8:\"Protocol errors.\",\n    8<<8:\"Server issued an error response.\"\n}\n############################################################\n\nheaders = {\n    \"Accept\":\"text/html,application/xhtml+xml,application/xml; \" \\\n        \"q=0.9,image/webp,*/*;q=0.8\",\n    \"Accept-Encoding\":\"text/html\",\n    \"Accept-Language\":\"en-US,en;q=0.8,zh-CN;q=0.6,zh;q=0.4,zh-TW;q=0.2\",\n    \"Content-Type\":\"application/x-www-form-urlencoded\",\n    \"Referer\":\"http://music.163.com/\",\n    \"User-Agent\":\"Mozilla/5.0 (X11; Linux x86_64) \" \\\n        \"AppleWebKit/537.36 (KHTML, like Gecko) \" \\\n        \"Chrome/40.0.2214.91 Safari/537.36\"\n}\n\nss = requests.session()\nss.headers.update(headers)\n\ndef encrypted_id(id):\n    byte1 = bytearray('3go8&$8*3*3h0k(2)2')\n    byte2 = bytearray(id)\n    byte1_len = len(byte1)\n    for i in xrange(len(byte2)):\n        byte2[i] = byte2[i]^byte1[i%byte1_len]\n    m = md5.new()\n    m.update(byte2)\n    result = m.digest().encode('base64')[:-1]\n    result = result.replace('/', '_')\n    result = result.replace('+', '-')\n    return result\n\ndef modificate_text(text):\n    text = parser.unescape(text)\n    text = re.sub(r'//*', '-', text)\n    text = text.replace('/', '-')\n    text = text.replace('\\\\', '-')\n    text = re.sub(r'\\s\\s+', ' ', text)\n    return text\n\n# for FAT file system\ndef modificate_file_name_for_wget(file_name):\n    file_name = re.sub(r'\\s*:\\s*', u' - ', file_name)\n    file_name = file_name.replace('?', '')\n    file_name = file_name.replace('\"', '\\'')\n    return file_name\n\ndef z_index(size):\n    z = len(str(size))\n    return z\n\n########################################################\n\nclass neteaseMusic(object):\n    def __init__(self, url):\n        self.url = url\n        self.song_infos = []\n        self.dir_ = os.getcwd().decode('utf8')\n\n        self.playlist_id = ''\n        self.dj_id = ''\n        self.album_id = ''\n        self.artist_id = ''\n        self.song_id = ''\n        self.cover_id = ''\n        self.cover_data = ''\n        self.amount_songs = u'1'\n\n        self.download = self.play if args.play else self.download\n\n    def get_durl(self, i):\n        for q in ('hMusic', 'mMusic', 'lMusic'):\n            if i[q]:\n                dfsId = str(i[q]['dfsId'])\n                edfsId = encrypted_id(dfsId)\n                durl = u'http://p1.music.126.net/%s/%s.mp3' \\\n                    % (edfsId, dfsId)\n                return durl, q[0]\n        return None, None\n\n    def get_cover(self, info):\n        if info['album_name'] == self.cover_id:\n            return self.cover_data\n        else:\n            self.cover_id = info['album_name']\n            while True:\n                url = info['album_pic_url']\n                try:\n                    self.cover_data = requests.get(url).content\n                    if self.cover_data[:5] != '<?xml':\n                        return self.cover_data\n                except Exception as e:\n                    print s % (1, 91, '   \\\\\\n   \\\\-- Error, get_cover --'), e\n                    time.sleep(5)\n\n    def modified_id3(self, file_name, info):\n        id3 = ID3()\n        id3.add(TRCK(encoding=3, text=info['track']))\n        id3.add(TDRC(encoding=3, text=info['year']))\n        id3.add(TIT2(encoding=3, text=info['song_name']))\n        id3.add(TALB(encoding=3, text=info['album_name']))\n        id3.add(TPE1(encoding=3, text=info['artist_name']))\n        id3.add(TPOS(encoding=3, text=info['cd_serial']))\n        #id3.add(USLT(encoding=3, text=self.get_lyric(info['lyric_url'])))\n        #id3.add(TCOM(encoding=3, text=info['composer']))\n        #id3.add(TCON(encoding=3, text=u'genres'))\n        #id3.add(TSST(encoding=3, text=info['sub_title']))\n        #id3.add(TSRC(encoding=3, text=info['disc_code']))\n        id3.add(COMM(encoding=3, desc=u'Comment', \\\n            text=info['song_url']))\n        #id3.add(APIC(encoding=3, mime=u'image/jpg', type=3, \\\n            #desc=u'Front Cover', data=self.get_cover(info)))\n        id3.save(file_name)\n\n    def url_parser(self):\n        if 'playlist' in self.url:\n            self.playlist_id = re.search(\n                r'playlist.+?(\\d+)', self.url).group(1)\n            print(s % (2, 92, u'\\n  -- 正在分析歌单信息 ...'))\n            self.download_playlist()\n        elif 'toplist' in self.url:\n            t = re.search(r'toplist.+?(\\d+)', self.url)\n            if t:\n                self.playlist_id = t.group(1)\n            else:\n                self.playlist_id = '3779629'\n            print(s % (2, 92, u'\\n  -- 正在分析排行榜信息 ...'))\n            self.download_playlist()\n        elif 'album' in self.url:\n            self.album_id = re.search(\n                r'album.+?(\\d+)', self.url).group(1)\n            print(s % (2, 92, u'\\n  -- 正在分析专辑信息 ...'))\n            self.download_album()\n        elif 'artist' in self.url:\n            self.artist_id = re.search(\n                r'artist.+?(\\d+)', self.url).group(1)\n            code = raw_input('\\n  >> 输入 a 下载该艺术家所有专辑.\\n' \\\n                '  >> 输入 t 下载该艺术家 Top 50 歌曲.\\n  >> ')\n            if code == 'a':\n                print(s % (2, 92, u'\\n  -- 正在分析艺术家专辑信息 ...'))\n                self.download_artist_albums()\n            elif code == 't':\n                print(s % (2, 92, u'\\n  -- 正在分析艺术家 Top 50 信息 ...'))\n                self.download_artist_top_50_songs()\n            else:\n                print(s % (1, 92, u'  --> Over'))\n        elif 'song' in self.url:\n            self.song_id = re.search(\n                r'song.+?(\\d+)', self.url).group(1)\n            print(s % (2, 92, u'\\n  -- 正在分析歌曲信息 ...'))\n            self.download_song()\n        elif 'djradio' in self.url:\n            self.djradio_id = re.search(\n                r'id=(\\d+)', self.url).group(1)\n            print(s % (2, 92, u'\\n  -- 正在分析DJ节目信息 ...'))\n            self.download_djradio()\n        elif 'program' in self.url:\n            self.dj_id = re.search(\n                r'id=(\\d+)', self.url).group(1)\n            print(s % (2, 92, u'\\n  -- 正在分析DJ节目信息 ...'))\n            self.download_dj()\n        else:\n            print(s % (2, 91, u'   请正确输入music.163.com网址.'))\n\n    def get_song_info(self, i):\n        z = z_index(i['album']['size']) \\\n            if i['album'].get('size') else 1\n        song_info = {}\n        song_info['song_id'] = i['id']\n        song_info['song_url'] = u'http://music.163.com/song/%s' \\\n            % i['id']\n        song_info['track'] = str(i['position'])\n        song_info['durl'], song_info['mp3_quality'] = self.get_durl(i)\n        #song_info['album_description'] = album_description\n        #song_info['lyric_url'] = i['lyric']\n        #song_info['sub_title'] = i['sub_title']\n        #song_info['composer'] = i['composer']\n        #song_info['disc_code'] = i['disc_code']\n        #if not song_info['sub_title']: song_info['sub_title'] = u''\n        #if not song_info['composer']: song_info['composer'] = u''\n        #if not song_info['disc_code']: song_info['disc_code'] = u''\n        t = time.gmtime(int(i['album']['publishTime'])*0.001)\n        #song_info['year'] = unicode('-'.join([str(t.tm_year), \\\n            #str(t.tm_mon), str(t.tm_mday)]))\n        song_info['year'] = unicode('-'.join(\n            [str(t.tm_year), str(t.tm_mon), str(t.tm_mday)]\n        ))\n        song_info['song_name'] = modificate_text(i['name']).strip()\n        song_info['artist_name'] = modificate_text(i['artists'][0]['name'])\n        song_info['album_pic_url'] = i['album']['picUrl']\n        song_info['cd_serial'] = u'1'\n        song_info['album_name'] = modificate_text(i['album']['name'])\n        file_name = song_info[ 'track'].zfill(z) \\\n            + '.' + song_info['song_name'] \\\n            + ' - ' + song_info['artist_name'] \\\n            + '.mp3'\n        song_info['file_name'] = file_name\n        # song_info['low_mp3'] = i['mp3Url']\n        return song_info\n\n    def get_song_infos(self, songs):\n        for i in songs:\n            song_info = self.get_song_info(i)\n            self.song_infos.append(song_info)\n\n    def download_song(self, noprint=False, n=1):\n        j = ss.get(\n            url_song % (\n                self.song_id, urllib.quote('[%s]' % self.song_id)\n            )\n        ).json()\n        songs = j['songs']\n        if not noprint:\n            print(s % (2, 97, u'\\n  >> ' + u'1 首歌曲将要下载.')) \\\n                if not args.play else ''\n        self.get_song_infos(songs)\n        self.download(self.amount_songs, n)\n\n    def download_album(self):\n        j = ss.get(url_album % (self.album_id)).json()\n        songs = j['album']['songs']\n        d = modificate_text(\n            j['album']['name'] \\\n            + ' - ' + j['album']['artist']['name'])\n        dir_ = os.path.join(os.getcwd().decode('utf8'), d)\n        self.dir_ = modificate_file_name_for_wget(dir_)\n        self.amount_songs = unicode(len(songs))\n        print(s % (2, 97, \\\n                   u'\\n  >> ' + self.amount_songs + u' 首歌曲将要下载.')) \\\n            if not args.play else ''\n        self.get_song_infos(songs)\n        self.download(self.amount_songs)\n\n    def download_playlist(self):\n        j = ss.get(\n            url_playlist % (\n                self.playlist_id, urllib.quote('[%s]' % self.playlist_id)\n            )\n        ).json()\n        songs = j['result']['tracks']\n        d = modificate_text(\n            j['result']['name'] + ' - ' \\\n            + j['result']['creator']['nickname'])\n        dir_ = os.path.join(os.getcwd().decode('utf8'), d)\n        self.dir_ = modificate_file_name_for_wget(dir_)\n        self.amount_songs = unicode(len(songs))\n        print(s % (2, 97, u'\\n  >> ' \\\n                   + self.amount_songs + u' 首歌曲将要下载.')) \\\n            if not args.play else ''\n        self.get_song_infos(songs)\n        self.download(self.amount_songs)\n\n    def download_djradio(self):\n        html = ss.get(\n            'http://music.163.com/djradio?id=%s' \\\n            % self.djradio_id).content\n        dj_ids = re.findall(r'/program\\?id=(\\d+)', html)\n\n        for dj_id in dj_ids:\n            self.dj_id = dj_id\n            self.download_dj()\n            self.song_infos = []\n\n    def download_dj(self):\n        j = ss.get(\n            url_dj % (\n                self.dj_id, urllib.quote('[%s]' % self.dj_id)\n            )\n        ).json()\n        songs = j['program']['songs']\n        d = modificate_text(\n            j['program']['name'] + ' - ' \\\n            + j['program']['dj']['nickname'])\n        dir_ = os.path.join(os.getcwd().decode('utf8'), d)\n        self.dir_ = modificate_file_name_for_wget(dir_)\n        self.amount_songs = unicode(len(songs))\n        print(s % (2, 97, u'\\n  >> \\\n                   ' + self.amount_songs + u' 首歌曲将要下载.')) \\\n            if not args.play else None\n        self.get_song_infos(songs)\n        self.download(self.amount_songs)\n\n\n    def download_artist_albums(self):\n        ss.cookies.update({'appver': '1.5.2'})\n        j = ss.get(\n            url_artist_albums % self.artist_id).json()\n        for albuminfo in j['hotAlbums']:\n            self.album_id = albuminfo['id']\n            self.download_album()\n\n    def download_artist_top_50_songs(self):\n        html = ss.get(\n            url_artist_top_50_songs % self.artist_id).content\n        text = re.search(\n            r'<textarea style=\"display:none;\">(.+?)</textarea>', html).group(1)\n        j = json.loads(text)\n        songids = [i['id'] for i in j]\n        d = modificate_text(\n            j[0]['artists'][0]['name'] + ' - ' + 'Top 50')\n        dir_ = os.path.join(os.getcwd().decode('utf8'), d)\n        self.dir_ = modificate_file_name_for_wget(dir_)\n        self.amount_songs = unicode(len(songids))\n        print(s % (2, 97, u'\\n  >> \\\n                   ' + self.amount_songs + u' 首歌曲将要下载.')) \\\n            if not args.play else ''\n        n = 1\n        for sid in songids:\n            self.song_id = sid\n            self.song_infos = []\n            self.download_song(noprint=True, n=n)\n            n += 1\n\n    def display_infos(self, i):\n        q = {'h': 'High', 'm': 'Middle', 'l': 'Low'}\n        print '\\n  ----------------'\n        print '  >>', s % (2, 94, i['file_name'])\n        print '  >>', s % (2, 95, i['album_name'])\n        print '  >>', s % (2, 92, 'http://music.163.com/song/%s' \\\n                           % i['song_id'])\n        print '  >>', s % (2, 97, 'MP3-Quality'), ':', \\\n            s % (1, 92, str(q.get(i['mp3_quality'])))\n        print ''\n\n    def play(self, amount_songs, n=None):\n        for i in self.song_infos:\n            self.display_infos(i)\n            if not i['durl']:\n                continue\n            cmd = 'mpv --really-quiet --audio-display no %s' % i['durl']\n            os.system(cmd)\n            timeout = 1\n            ii, _, _ = select.select([sys.stdin], [], [], timeout)\n            if ii:\n                sys.exit(0)\n            else:\n                pass\n\n    def download(self, amount_songs, n=None):\n        dir_ = modificate_file_name_for_wget(self.dir_)\n        cwd = os.getcwd().decode('utf8')\n        if dir_ != cwd:\n            if not os.path.exists(dir_):\n                os.mkdir(dir_)\n        ii = 1\n        for i in self.song_infos:\n            num = random.randint(0, 100) % 7\n            col = s % (2, num + 90, i['file_name'])\n            t = modificate_file_name_for_wget(i['file_name'])\n            file_name = os.path.join(dir_, t)\n            if os.path.exists(file_name):  # if file exists, no get_durl\n                if args.undownload:\n                    self.modified_id3(file_name, i)\n                    ii += 1\n                    continue\n                else:\n                    ii += 1\n                    continue\n            if not args.undownload:\n                q = {'h': 'High', 'm': 'Middle', 'l': 'Low'}\n                mp3_quality = str(q.get(i['mp3_quality']))\n                if n == None:\n                    print(u'\\n  ++ 正在下载: #%s/%s# %s\\n' \\\n                          u'  ++ mp3_quality: %s' \\\n                        % (ii, amount_songs, col,\n                           s % (1, 91, mp3_quality)))\n                else:\n                    print(u'\\n  ++ 正在下载: #%s/%s# %s\\n' \\\n                          u'  ++ mp3_quality: %s' \\\n                        % (n, amount_songs, col,\n                           s % (1, 91, mp3_quality)))\n                if not i['durl']:\n                    continue\n\n                file_name_for_wget = file_name.replace('`', '\\`')\n                cmd = 'wget -c -nv -U \"%s\" -O \"%s.tmp\" %s' \\\n                    % (headers['User-Agent'], file_name_for_wget, i['durl'])\n                cmd = cmd.encode('utf8')\n                status = os.system(cmd)\n                if status != 0:     # other http-errors, such as 302.\n                    wget_exit_status_info = wget_es[status]\n                    print('\\n\\n ----###   \\x1b[1;91mERROR\\x1b[0m ==> \\x1b[1;91m%d ' \\\n                        '(%s)\\x1b[0m   ###--- \\n\\n' \\\n                          % (status, wget_exit_status_info))\n                    print s % (1, 91, '  ===> '), cmd\n                    sys.exit(1)\n                else:\n                    os.rename('%s.tmp' % file_name, file_name)\n\n            self.modified_id3(file_name, i)\n            ii += 1\n            time.sleep(0)\n\ndef main(url):\n    x = neteaseMusic(url)\n    x.url_parser()\n\nif __name__ == '__main__':\n    p = argparse.ArgumentParser(\n        description='downloading any music.163.com')\n    p.add_argument('url', help='any url of music.163.com')\n    p.add_argument('-p', '--play', action='store_true', \\\n        help='play with mpv')\n    p.add_argument('-c', '--undownload', action='store_true', \\\n        help='no download, using to renew id3 tags')\n    args = p.parse_args()\n    main(args.url)\n"
        },
        {
          "name": "music.baidu.com.py",
          "type": "blob",
          "size": 9.1689453125,
          "content": "#!/usr/bin/env python2\n# vim: set fileencoding=utf8\n\nimport re\nimport sys\nimport os\nimport random\nimport time\nimport json\nimport urllib2\nimport argparse\nimport select\n\nfrom mutagen.id3 import ID3,TRCK,TIT2,TALB,TPE1,APIC,TDRC,COMM,TCOM,TCON,TSST,WXXX,TSRC\nfrom HTMLParser import HTMLParser\nparser = HTMLParser()\ns = u'\\x1b[%d;%dm%s\\x1b[0m'       # terminual color template\n\nheaders = {\n    \"Accept\":\"text/html,application/xhtml+xml,application/xml; \\\n        q=0.9,image/webp,*/*;q=0.8\",\n    \"Accept-Encoding\":\"text/html\",\n    \"Accept-Language\":\"en-US,en;q=0.8,zh-CN;q=0.6,zh;q=0.4,zh-TW;q=0.2\",\n    \"Content-Type\":\"application/x-www-form-urlencoded\",\n    \"Referer\":\"http://www.baidu.com/\",\n    \"User-Agent\":\"Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.36 \\\n        (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n}\n\n############################################################\n# wget exit status\nwget_es = {\n    0:\"No problems occurred.\",\n    2:\"User interference.\",\n    1<<8:\"Generic error code.\",\n    2<<8:\"Parse error - for instance, when parsing command-line \\\n        optio.wgetrc or .netrc...\",\n    3<<8:\"File I/O error.\",\n    4<<8:\"Network failure.\",\n    5<<8:\"SSL verification failure.\",\n    6<<8:\"Username/password authentication failure.\",\n    7<<8:\"Protocol errors.\",\n    8<<8:\"Server issued an error response.\"\n}\n############################################################\n\ndef modificate_text(text):\n    text = parser.unescape(text)\n    text = re.sub(r'//*', '-', text)\n    text = text.replace('/', '-')\n    text = text.replace('\\\\', '-')\n    text = re.sub(r'\\s\\s+', ' ', text)\n    return text\n\ndef modificate_file_name_for_wget(file_name):\n    file_name = re.sub(r'\\s*:\\s*', u' - ', file_name)    # for FAT file system\n    file_name = file_name.replace('?', '')      # for FAT file system\n    file_name = file_name.replace('\"', '\\'')    # for FAT file system\n    return file_name\n\ndef z_index(song_infos):\n    size = len(song_infos)\n    z = len(str(size))\n    return z\n\nclass baidu_music(object):\n    def __init__(self, url):\n        self.url = url\n        self.song_infos = []\n        self.json_url = ''\n        self.dir_ = os.getcwd().decode('utf8')\n        self.template_wgets = 'wget -nv -U \"%s\" -O \"%s.tmp\" %s' % (headers['User-Agent'], '%s', '%s')\n        self.template_album = 'http://music.baidu.com/album/%s'\n        if args.flac:\n            self.template_api = 'http://music.baidu.com/data/music/fmlink?songIds=%s&type=flac'\n        elif args.low:\n            self.template_api = 'http://music.baidu.com/data/music/fmlink?songIds=%s&type=mp3'\n        elif args.high:\n            self.template_api = 'http://music.baidu.com/data/music/fmlink?songIds=%s&type=mp3&rate=320'\n        else:\n            self.template_api = 'http://music.baidu.com/data/music/fmlink?songIds=%s&type=mp3&rate=320'\n\n        self.album_id = ''\n        self.song_id = ''\n\n        self.download = self.play if args.play else self.download\n\n    def get_songidlist(self, song_id):\n        html = self.opener.open(self.template_album % song_id).read()\n        songidlist = re.findall(r'/song/(\\d+)', html)\n        return songidlist\n\n    def get_cover(self, url):\n        i = 1\n        while True:\n            cover_data = self.opener.open(url).read()\n            if cover_data[:5] != '<?xml':\n                return cover_data\n            if i >= 10:\n                print s % (1, 91, \"  |--> Error: can't get cover image\")\n                sys.exit(0)\n            i += 1\n\n    def modified_id3(self, file_name, info):\n        id3 = ID3()\n        id3.add(TRCK(encoding=3, text=info['track']))\n        id3.add(TIT2(encoding=3, text=info['song_name']))\n        id3.add(TALB(encoding=3, text=info['album_name']))\n        id3.add(TPE1(encoding=3, text=info['artist_name']))\n        id3.add(COMM(encoding=3, desc=u'Comment', text=info['song_url']))\n        id3.add(APIC(encoding=3, mime=u'image/jpg', type=3, desc=u'Cover', data=self.get_cover(info['album_pic_url'])))\n        id3.save(file_name)\n\n    def url_parser(self):\n        if '/album/' in self.url:\n            self.album_id = re.search(r'/album/(\\d+)', self.url).group(1)\n            #print(s % (2, 92, u'\\n  -- 正在分析专辑信息 ...'))\n            self.get_album_infos()\n        elif '/song/' in self.url:\n            self.song_id = re.search(r'/song/(\\d+)', self.url).group(1)\n            #print(s % (2, 92, u'\\n  -- 正在分析歌曲信息 ...'))\n            self.get_song_infos(self.song_id)\n        else:\n            print(s % (2, 91, u'   请正确输入baidu网址.'))\n        self.download()\n\n    def get_song_infos(self, song_id, track_number=''):\n        api_json = self.opener.open(self.template_api % song_id).read()\n        j = json.loads(api_json)\n        song_info = {}\n        song_info['song_id'] = unicode(j['data']['songList'][0]['songId'])\n        song_info['track'] = unicode(track_number)\n        song_info['song_url'] = u'http://music.baidu.com/song/' + song_info['song_id']\n        song_info['song_name'] = modificate_text(j['data']['songList'][0]['songName']).strip()\n        song_info['album_name'] = modificate_text(j['data']['songList'][0]['albumName']).strip()\n        song_info['artist_name'] = modificate_text(j['data']['songList'][0]['artistName']).strip()\n        song_info['album_pic_url'] = j['data']['songList'][0]['songPicRadio']\n        song_info['file_name'] = song_info['artist_name'] + ' - ' + song_info['song_name']\n        if song_info['track']:\n            song_info['file_name'] = song_info['track'].zfill(2) + '.' + song_info['file_name']\n        if args.flac:\n            song_info['file_name'] = song_info['file_name'] + '.flac'\n        else:\n            song_info['file_name'] = song_info['file_name'] + '.mp3'\n        song_info['durl'] = j['data']['songList'][0]['songLink']\n        self.song_infos.append(song_info)\n\n    def get_album_infos(self):\n        songidlist = self.get_songidlist(self.album_id)\n        track_number = 1\n        for i in songidlist:\n            self.get_song_infos(i, track_number)\n            track_number += 1\n        d = modificate_text(self.song_infos[0]['artist_name'] + ' - ' + self.song_infos[0]['album_name'])\n        self.dir_ = os.path.join(os.getcwd().decode('utf8'), d)\n\n    def display_infos(self, i):\n        print '\\n  ----------------'\n        print '  >>', s % (2, 94, i['file_name'])\n        print '  >>', s % (2, 95, i['album_name'])\n        print '  >>', s % (2, 92, 'http://music.baidu.com/song/%s' % i['song_id'])\n        print ''\n\n    def play(self):\n        for i in self.song_infos:\n            durl = i['durl']\n            self.display_infos(i)\n            os.system('mpv --really-quiet %s' % durl)\n            timeout = 1\n            ii, _, _ = select.select([sys.stdin], [], [], timeout)\n            if ii:\n                sys.exit(0)\n            else:\n                pass\n\n    def download(self):\n        dir_ = modificate_file_name_for_wget(self.dir_)\n        cwd = os.getcwd().decode('utf8')\n        csongs = len(self.song_infos)\n        if dir_ != cwd:\n            if not os.path.exists(dir_):\n                os.mkdir(dir_)\n        print(s % (2, 97, u'\\n  >> ' + str(csongs) + u' 首歌曲将要下载.'))\n        ii = 1\n        for i in self.song_infos:\n            t = modificate_file_name_for_wget(i['file_name'])\n            file_name = os.path.join(dir_, t)\n            if os.path.exists(file_name):  ## if file exists, no get_durl\n                ii += 1\n                print(u'\\n 文件已存在~')\n                continue\n            file_name_for_wget = file_name.replace('`', '\\`')\n            if 'zhangmenshiting.baidu.com' in i['durl'] or \\\n                'yinyueshiting.baidu.com' in i['durl']:\n                num = random.randint(0,100) % 7\n                col = s % (2, num + 90, i['file_name'])\n                print(u'\\n  ++ 正在下载: %s' % col)\n                wget = self.template_wgets % (file_name_for_wget, i['durl'])\n                wget = wget.encode('utf8')\n                status = os.system(wget)\n                if status != 0:     # other http-errors, such as 302.\n                    wget_exit_status_info = wget_es[status]\n                    print('\\n\\n ----### \\x1b[1;91mERROR\\x1b[0m ==> \\x1b[1;91m%d (%s)\\x1b[0m ###--- \\n\\n' % (status, wget_exit_status_info))\n                    print('  ===> ' + wget)\n                    break\n                else:\n                    os.rename('%s.tmp' % file_name, file_name)\n\n                self.modified_id3(file_name, i)\n                ii += 1\n                #time.sleep(10)\n            else:\n                print s % (1, 91, '  !! Oops, you are unlucky, the song is not from zhangmenshiting.baidu.com')\n                print i['durl']\n\ndef main(url):\n    x = baidu_music(url)\n    opener = urllib2.build_opener()\n    opener.addheaders = headers.items()\n    x.opener = opener\n    x.url_parser()\n\nif __name__ == '__main__':\n    p = argparse.ArgumentParser(description='downloading any music.baidu.com')\n    p.add_argument('url', help='any url of music.baidu.com')\n    p.add_argument('-f', '--flac', action='store_true', help='download flac')\n    p.add_argument('-i', '--high', action='store_true', help='download 320')\n    p.add_argument('-l', '--low', action='store_true', help='download 128')\n    p.add_argument('-p', '--play', action='store_true', \\\n        help='play with mpv')\n    args = p.parse_args()\n    main(args.url)\n"
        },
        {
          "name": "pan.baidu.com.py",
          "type": "blob",
          "size": 146.9794921875,
          "content": "#!/usr/bin/env python2\n# vim: set fileencoding=utf8\n\nimport os\nimport sys\nimport hashlib\nimport functools\nimport requests\nrequests.packages.urllib3.disable_warnings() # disable urllib3's warnings https://urllib3.readthedocs.org/en/latest/security.html#insecurerequestwarning\nfrom requests_toolbelt import MultipartEncoder\nimport urllib\nimport json\nimport cPickle as pk\nimport re\nimport time\nimport argparse\nfrom random import SystemRandom\nrandom = SystemRandom()\nimport select\nimport base64\nimport md5\nimport rsa\nfrom zlib import crc32\nimport cStringIO\nimport signal\n\n############################################################\n# Defines that should never be changed\nOneK = 1024\nOneM = OneK * OneK\nOneG = OneM * OneK\nOneT = OneG * OneK\nOneP = OneT * OneK\nOneE = OneP * OneK\n\n############################################################\n# Default values\nMinRapidUploadFileSize = 256 * OneK\nDefaultSliceSize = 10 * OneM\nMaxSliceSize = 2 * OneG\nMaxSlicePieces = 1024\nENoError = 0\n\nCIPHERS = [\n    \"aes-256-cfb\", \"aes-128-cfb\", \"aes-192-cfb\",\n    \"aes-256-ofb\", \"aes-128-ofb\", \"aes-192-ofb\",\n    \"aes-128-ctr\", \"aes-192-ctr\", \"aes-256-ctr\",\n    \"aes-128-cfb8\", \"aes-192-cfb8\", \"aes-256-cfb8\",\n    \"aes-128-cfb1\", \"aes-192-cfb1\", \"aes-256-cfb1\",\n    \"bf-cfb\", \"camellia-128-cfb\", \"camellia-192-cfb\",\n    \"camellia-256-cfb\", \"cast5-cfb\", \"chacha20\",\n    \"idea-cfb\", \"rc2-cfb\", \"rc4-md5\", \"salsa20\", \"seed-cfb\"\n]\n\n############################################################\n# wget exit status\nwget_es = {\n    0: \"No problems occurred.\",\n    2: \"User interference.\",\n    1<<8: \"Generic error code.\",\n    2<<8: \"Parse error - for instance, when parsing command-line \" \\\n        \"optio.wgetrc or .netrc...\",\n    3<<8: \"File I/O error.\",\n    4<<8: \"Network failure.\",\n    5<<8: \"SSL verification failure.\",\n    6<<8: \"Username/password authentication failure.\",\n    7<<8: \"Protocol errors.\",\n    8<<8: \"Server issued an error response.\"\n}\n############################################################\n\n# file extensions\nmediatype = [\n    \".wma\", \".wav\", \".mp3\", \".aac\", \".ra\", \".ram\", \".mp2\", \".ogg\", \\\n    \".aif\", \".mpega\", \".amr\", \".mid\", \".midi\", \".m4a\", \".m4v\", \".wmv\", \\\n    \".rmvb\", \".mpeg4\", \".mpeg2\", \".flv\", \".avi\", \".3gp\", \".mpga\", \".qt\", \\\n    \".rm\", \".wmz\", \".wmd\", \".wvx\", \".wmx\", \".wm\", \".swf\", \".mpg\", \".mp4\", \\\n    \".mkv\", \".mpeg\", \".mov\", \".mdf\", \".iso\", \".asf\", \".vob\"\n]\nimagetype = [\n    \".jpg\", \".jpeg\", \".gif\", \".bmp\", \".png\", \".jpe\", \".cur\", \".svg\", \\\n    \".svgz\", \".tif\", \".tiff\", \".ico\"\n]\ndoctype = [\n    \".doc\", \".docx\", \".xls\", \".xlsx\", \".ppt\", \".pptx\", \".vsd\", \".txt\", \".pdf\", \\\n    \".ods\", \".ots\", \".odt\", \".rtf\", \".dot\", \".dotx\", \".odm\", \".pps\", \".pot\", \\\n    \".xlt\", \".xltx\", \".csv\", \".ppsx\", \".potx\", \".epub\", \".apk\", \".exe\", \\\n    \".msi\", \".ipa\", \".torrent\", \".mobi\"\n]\narchivetype = [\n    \".7z\", \".a\", \".ace\", \".afa\", \".alz\", \".android\", \".apk\", \".ar\", \\\n    \".arc\", \".arj\", \".b1\", \".b1\", \".ba\", \".bh\", \".bz2\", \".cab\", \".cab\", \\\n    \".cfs\", \".chm\", \".cpio\", \".cpt\", \".cqm\", \".dar\", \".dd\", \".dgc\", \".dmg\", \\\n    \".ear\", \".ecc\", \".eqe\", \".exe\", \".f\", \".gca\", \".gz\", \".ha\", \".hki\", \\\n    \".html\", \".ice\", \".id\", \".infl\", \".iso\", \".jar\", \".kgb\", \".lbr\", \\\n    \".lha\", \".lqr\", \".lz\", \".lzh\", \".lzma\", \".lzo\", \".lzx\", \".mar\", \".ms\", \\\n    \".net\", \".package\", \".pak\", \".paq6\", \".paq7\", \".paq8\", \".par\", \".par2\", \\\n    \".partimg\", \".pea\", \".pim\", \".pit\", \".qda\", \".rar\", \".rk\", \".rz\", \\\n    \".s7z\", \".sda\", \".sea\", \".sen\", \".sfark\", \".sfx\", \".shar\", \".sit\", \\\n    \".sitx\", \".sqx\", \".tar\", \".tbz2\", \".tgz\", \".tlz\", \".tqt\", \".uc\", \\\n    \".uc0\", \".uc2\", \".uca\", \".ucn\", \".ue2\", \".uha\", \".ur2\", \".war\", \".web\", \\\n    \".wim\", \".x\", \".xar\", \".xp3\", \".xz\", \".yz1\", \".z\", \".zip\", \".zipx\", \\\n    \".zoo\", \".zpaq\", \".zz\"\n]\n\nPHONE_MODEL_DATABASE = [\n    \"1501_M02\",  # 360 F4\n    \"1503-M02\",  # 360 N4\n    \"1505-A01\",  # 360 N4S\n    \"303SH\",  # 夏普 Aquos Crystal Xx Mini 303SH\n    \"304SH\",  # 夏普 Aquos Crystal Xx SoftBank\n    \"305SH\",  # 夏普 Aquos Crystal Y\n    \"306SH\",  # 夏普 Aquos Crystal 306SH\n    \"360 Q5 Plus\",  # 360 Q5 Plus\n    \"360 Q5\",  # 360 Q5\n    \"402SH\",  # 夏普 Aquos Crystal X\n    \"502SH\",  # 夏普 Aquos Crystal Xx2\n    \"6607\",  # OPPO U3\n    \"A1001\",  # 一加手机1\n    \"ASUS_A001\",  # 华硕 ZenFone 3 Ultra\n    \"ASUS_A001\",  # 华硕 ZenFone 3 Ultra\n    \"ASUS_Z00ADB\",  # 华硕 ZenFone 2\n    \"ASUS_Z00UDB\",  # 华硕 Zenfone Selfie\n    \"ASUS_Z00XSB\",  # 华硕 ZenFone Zoom\n    \"ASUS_Z012DE\",  # 华硕 ZenFone 3\n    \"ASUS_Z012DE\",  # 华硕 ZenFone 3\n    \"ASUS_Z016D\",  # 华硕 ZenFone 3 尊爵\n    \"ATH-TL00H\",  # 华为 荣耀 7i\n    \"Aster T\",  # Vertu Aster T\n    \"BLN-AL10\",  # 华为 荣耀 畅玩6X\n    \"BND-AL10\",  # 荣耀7X\n    \"BTV-W09\",  # 华为 M3\n    \"CAM-UL00\",  # 华为 荣耀 畅玩5A\n    \"Constellation V\",  # Vertu Constellation V\n    \"D6683\",  # 索尼 Xperia Z3 Dual TD\n    \"DIG-AL00\",  # 华为 畅享 6S\n    \"E2312\",  # 索尼 Xperia M4 Aqua\n    \"E2363 \",  # 索尼 Xperia M4 Aqua Dual\n    \"E5363\",  # 索尼 Xperia C4\n    \"E5563\",  # 索尼 Xperia C5\n    \"E5663\",  # 索尼 Xperia M5\n    \"E5823\",  # 索尼 Xperia Z5 Compact\n    \"E6533\",  # 索尼 Xperia Z3+\n    \"E6683\",  # 索尼 Xperia Z5\n    \"E6883\",  # 索尼 Xperia Z5 Premium\n    \"EBEN M2\",  # 8848 M2\n    \"EDI-AL10\",  # 华为 荣耀 Note 8\n    \"EVA-AL00\",  # 华为 P9\n    \"F100A\",  # 金立 F100\n    \"F103B\",  # 金立 F103B\n    \"F3116\",  # 索尼 Xperia XA\n    \"F3216\",  # 索尼 Xperia XA Ultra\n    \"F5121 / F5122\",  # 索尼 Xperia X\n    \"F5321\",  # 索尼 Xperia X Compact\n    \"F8132\",  # 索尼 Xperia X Performance\n    \"F8332\",  # 索尼 Xperia XZ\n    \"FRD-AL00\",  # 华为 荣耀 8\n    \"FS8001\",  # 夏普 C1\n    \"FS8002\",  # 夏普 A1\n    \"G0111\",  # 格力手机 1\n    \"G0215\",  # 格力手机 2\n    \"G8142\",  # 索尼Xperia XZ Premium G8142\n    \"G8342\",  # 索尼Xperia XZ1\n    \"GIONEE S9\",  # 金立 S9\n    \"GN5001S\",  # 金立 金钢\n    \"GN5003\",  # 金立 大金钢\n    \"GN8002S\",  # 金立 M6 Plus\n    \"GN8003\",  # 金立 M6\n    \"GN9011\",  # 金立 S8\n    \"GN9012\",  # 金立 S6 Pro\n    \"GRA-A0\",  # Coolpad Cool Play 6C\n    \"H60-L11\",  # 华为 荣耀 6\n    \"HN3-U01\",  # 华为 荣耀 3\n    \"HTC D10w\",  # HTC Desire 10 Pro\n    \"HTC E9pw\",  # HTC One E9+\n    \"HTC M10u\",  # HTC 10\n    \"HTC M8St\",  # HTC One M8\n    \"HTC M9PT\",  # HTC One M9+\n    \"HTC M9e\",  # HTC One M9\n    \"HTC One A9\",  # HTC One A9\n    \"HTC U-1w\",  # HTC U Ultra\n    \"HTC X9u\",  # HTC One X9\n    \"HTC_M10h\",  # HTC 10 国际版\n    \"HUAWEI CAZ-AL00\",  # 华为 Nova\n    \"HUAWEI CRR-UL00\",  # 华为 Mate S\n    \"HUAWEI GRA-UL10\",  # 华为 P8\n    \"HUAWEI MLA-AL10\",  # 华为 麦芒 5\n    \"HUAWEI MT7-AL00\",  # 华为 mate 7\n    \"HUAWEI MT7-TL00\",  # 华为 Mate 7\n    \"HUAWEI NXT-AL10\",  # 华为 Mate 8\n    \"HUAWEI P7-L00\",  # 华为 P7\n    \"HUAWEI RIO-AL00\",  # 华为 麦芒 4\n    \"HUAWEI TAG-AL00\",  # 华为 畅享 5S\n    \"HUAWEI VNS-AL00\",  # 华为 G9\n    \"IUNI N1\",  # 艾优尼 N1\n    \"IUNI i1\",  # 艾优尼 i1\n    \"KFAPWI\",  # Amazon Kindle Fire HDX 8.9\n    \"KFSOWI\",  # Amazon Kindle Fire HDX 7\n    \"KFTHWI\",  # Amazon Kindle Fire HD\n    \"KIW-TL00H\",  # 华为 荣耀 畅玩5X\n    \"KNT-AL10\",  # 华为 荣耀 V8\n    \"L55t\",  # 索尼 Xperia Z3\n    \"L55u\",  # 索尼 Xperia Z3\n    \"LEX626\",  # 乐视 乐S3\n    \"LEX720\",  # 乐视 乐Pro3\n    \"LG-D858\",  # LG G3\n    \"LG-H818\",  # LG G4\n    \"LG-H848\",  # LG G5 SE\n    \"LG-H868\",  # LG G5\n    \"LG-H968\",  # LG V10\n    \"LON-AL00\",  # 华为 Mate 9 Pro\n    \"LON-AL00-PD\",  # 华为 Mate 9 Porsche Design\n    \"LT18i\",  # Sony Ericsson Xperia Arc S\n    \"LT22i\",  # Sony Ericsson Xperia P\n    \"LT26i\",  # Sony Ericsson Xperia S\n    \"LT26ii\",  # Sony Ericsson Xperia SL\n    \"LT26w\",  # Sony Ericsson Xperia Acro S\n    \"Le X520\",  # 乐视 乐2\n    \"Le X620\",  # 乐视 乐2Pro\n    \"Le X820\",  # 乐视 乐Max2\n    \"Lenovo A3580\",  # 联想 黄金斗士 A8 畅玩\n    \"Lenovo A7600-m\",  # 联想 黄金斗士 S8\n    \"Lenovo A938t\",  # 联想 黄金斗士 Note8\n    \"Lenovo K10e70\",  # 联想 乐檬K10\n    \"Lenovo K30-T\",  # 联想 乐檬 K3\n    \"Lenovo K32C36\",  # 联想 乐檬3\n    \"Lenovo K50-t3s\",  # 联想 乐檬 K3 Note\n    \"Lenovo K52-T38\",  # 联想 乐檬 K5 Note\n    \"Lenovo K52e78\",  # Lenovo K5 Note\n    \"Lenovo P2c72\",  # 联想 P2\n    \"Lenovo X3c50\",  # 联想 乐檬 X3\n    \"Lenovo Z90-3\",  # 联想 VIBE Shot大拍\n    \"M040\",  # 魅族 MX 2\n    \"M1 E\",  # 魅蓝 E\n    \"M2-801w\",  # 华为 M2\n    \"M2017\",  # 金立 M2017\n    \"M3\",  # EBEN M3\n    \"M355\",  # 魅族 MX 3\n    \"MHA-AL00\",  # 华为 Mate 9\n    \"MI 4LTE\",  # 小米手机4\n    \"MI 4S\",  # 小米手机4S\n    \"MI 5\",  # 小米手机5\n    \"MI 5s Plus\",  # 小米手机5s Plus\n    \"MI 5s\",  # 小米手机5s\n    \"MI MAX\",  # 小米Max\n    \"MI Note Pro\",  # 小米Note顶配版\n    \"MI PAD 2\",  # 小米平板 2\n    \"MIX\",  # 小米MIX\n    \"MLA-UL00\",  # 华为 G9 Plus\n    \"MP1503\",  # 美图 M6\n    \"MP1512\",  # 美图 M6s\n    \"MT27i\",  # Sony Ericsson Xperia Sola\n    \"MX4 Pro\",  # 魅族 MX 4 Pro\n    \"MX4\",  # 魅族 MX 4\n    \"MX5\",  # 魅族 MX 5\n    \"MX6\",  # 魅族 MX 6\n    \"Meitu V4s\",  # 美图 V4s\n    \"Meizu M3 Max\",  # 魅蓝max\n    \"Meizu U20\",  # 魅蓝U20\n    \"Mi 5\",\n    \"Mi 6\",\n    \"Mi A1\",  # MI androidone\n    \"Mi Note 2\",  # 小米Note2\n    \"MiTV2S-48\",  # 小米电视2s\n    \"Moto G (4)\",  # 摩托罗拉 G⁴ Plus\n    \"N1\",  # Nokia N1\n    \"NCE-AL00\",  # 华为 畅享 6\n    \"NTS-AL00\",  # 华为 荣耀 Magic\n    \"NWI-AL10\",  # nova2s\n    \"NX508J\",  # 努比亚 Z9\n    \"NX511J\",  # 努比亚 小牛4 Z9 Mini\n    \"NX512J\",  # 努比亚 大牛 Z9 Max\n    \"NX513J\",  # 努比亚 My 布拉格\n    \"NX513J\",  # 努比亚 布拉格S\n    \"NX523J\",  # 努比亚 Z11 Max\n    \"NX529J\",  # 努比亚 小牛5 Z11 Mini\n    \"NX531J\",  # 努比亚 Z11\n    \"NX549J\",  # 努比亚 小牛6 Z11 MiniS\n    \"NX563J\",  # 努比亚Z17\n    \"Nexus 4\",\n    \"Nexus 5X\",\n    \"Nexus 6\",\n    \"Nexus 6P\",\n    \"Nexus 7\",\n    \"Nexus 9\",\n    \"Nokia_X\",  # Nokia X\n    \"Nokia_XL_4G\",  # Nokia XL\n    \"ONE A2001\",  # 一加手机2\n    \"ONE E1001\",  # 一加手机X\n    \"ONEPLUS A5010\",  # 一加5T\n    \"OPPO A53\",  # OPPO A53\n    \"OPPO A59M\",  # OPPO A59\n    \"OPPO A59s\",  # OPPO A59s\n    \"OPPO R11\",\n    \"OPPO R7\",  # OPPO R7\n    \"OPPO R7Plus\",  # OPPO R7Plus\n    \"OPPO R7S\",  # OPPO R7S\n    \"OPPO R7sPlus\",  # OPPO R7sPlus\n    \"OPPO R9 Plustm A\",  # OPPO R9Plus\n    \"OPPO R9s Plus\",  # OPPO R9s Plus\n    \"OPPO R9s\",\n    \"OPPO R9s\",  # OPPO R9s\n    \"OPPO R9tm\",  # OPPO R9\n    \"PE-TL10\",  # 华为 荣耀 6 Plus\n    \"PLK-TL01H\",  # 华为 荣耀 7\n    \"Pro 5\",  # 魅族 Pro 5\n    \"Pro 6\",  # 魅族 Pro 6\n    \"Pro 6s\",  # 魅族 Pro 6s\n    \"RM-1010\",  # Nokia Lumia 638\n    \"RM-1018\",  # Nokia Lumia 530\n    \"RM-1087\",  # Nokia Lumia 930\n    \"RM-1090\",  # Nokia Lumia 535\n    \"RM-867\",  # Nokia Lumia 920\n    \"RM-875\",  # Nokia Lumia 1020\n    \"RM-887\",  # Nokia Lumia 720\n    \"RM-892\",  # Nokia Lumia 925\n    \"RM-927\",  # Nokia Lumia 929\n    \"RM-937\",  # Nokia Lumia 1520\n    \"RM-975\",  # Nokia Lumia 635\n    \"RM-977\",  # Nokia Lumia 630\n    \"RM-984\",  # Nokia Lumia 830\n    \"RM-996\",  # Nokia Lumia 1320\n    \"Redmi 3S\",  # 红米3s\n    \"Redmi 4\",  # 小米 红米4\n    \"Redmi 4A\",  # 小米 红米4A\n    \"Redmi Note 2\",  # 小米 红米Note2\n    \"Redmi Note 3\",  # 小米 红米Note3\n    \"Redmi Note 4\",  # 小米 红米Note4\n    \"Redmi Pro\",  # 小米 红米Pro\n    \"S3\",  # 佳域S3\n    \"SCL-TL00H\",  # 华为 荣耀 4A\n    \"SD4930UR\",  # Amazon Fire Phone\n    \"SH-03G\",  # 夏普 Aquos Zeta SH-03G\n    \"SH-04F\",  # 夏普 Aquos Zeta SH-04F\n    \"SHV31\",  # 夏普 Aquos Serie Mini SHV31\n    \"SM-A5100\",  # Samsung Galaxy A5\n    \"SM-A7100\",  # Samsung Galaxy A7\n    \"SM-A8000\",  # Samsung Galaxy A8\n    \"SM-A9000\",  # Samsung Galaxy A9\n    \"SM-A9100\",  # Samsung Galaxy A9 高配版\n    \"SM-C5000\",  # Samsung Galaxy C5\n    \"SM-C5010\",  # Samsung Galaxy C5 Pro\n    \"SM-C7000\",  # Samsung Galaxy C7\n    \"SM-C7010\",  # Samsung Galaxy C7 Pro\n    \"SM-C9000\",  # Samsung Galaxy C9 Pro\n    \"SM-G1600\",  # Samsung Galaxy Folder\n    \"SM-G5500\",  # Samsung Galaxy On5\n    \"SM-G6000\",  # Samsung Galaxy On7\n    \"SM-G7100\",  # Samsung Galaxy On7(2016)\n    \"SM-G7200\",  # Samsung Galasy Grand Max\n    \"SM-G9198\",  # Samsung 领世旗舰Ⅲ\n    \"SM-G9208\",  # Samsung Galaxy S6\n    \"SM-G9250\",  # Samsung Galasy S7 Edge\n    \"SM-G9280\",  # Samsung Galaxy S6 Edge+\n    \"SM-G9300\",  # Samsung Galaxy S7\n    \"SM-G9350\",  # Samsung Galaxy S7 Edge\n    \"SM-G9500\",  # Samsung Galaxy S8\n    \"SM-G9550\",  # Samsung Galaxy S8+\n    \"SM-G9600\",  # Samsung Galaxy S9\n    \"SM-G960F\",  # Galaxy S9 Dual SIM\n    \"SM-G9650\",  # Samsung Galaxy S9+\n    \"SM-G965F\",  # Galaxy S9+ Dual SIM\n    \"SM-J3109\",  # Samsung Galaxy J3\n    \"SM-J3110\",  # Samsung Galaxy J3 Pro\n    \"SM-J327A\",  # Samsung Galaxy J3 Emerge\n    \"SM-J5008\",  # Samsung Galaxy J5\n    \"SM-J7008\",  # Samsung Galaxy J7\n    \"SM-N9108V\",  # Samsung Galasy Note4\n    \"SM-N9200\",  # Samsung Galaxy Note5\n    \"SM-N9300\",  # Samsung Galaxy Note 7\n    \"SM-N935S\",  # Samsung Galaxy Note Fan Edition\n    \"SM-N9500\",  # Samsung Galasy Note8\n    \"SM-W2015\",  # Samsung W2015\n    \"SM-W2016\",  # Samsung W2016\n    \"SM-W2017\",  # Samsung W2017\n    \"SM705\",  # 锤子 T1\n    \"SM801\",  # 锤子 T2\n    \"SM901\",  # 锤子 M1\n    \"SM919\",  # 锤子 M1L\n    \"ST18i\",  # Sony Ericsson Xperia Ray\n    \"ST25i\",  # Sony Ericsson Xperia U\n    \"STV100-1\",  # 黑莓Priv\n    \"Signature Touch\",  # Vertu Signature Touch\n    \"TA-1000\",  # Nokia 6\n    \"TA-1000\",  # HMD Nokia 6\n    \"TA-1041\",  # Nokia 7\n    \"VERTU Ti\",  # Vertu Ti\n    \"VIE-AL10\",  # 华为 P9 Plus\n    \"VIVO X20\",\n    \"VIVO X20A\",\n    \"W909\",  # 金立 天鉴 W909\n    \"X500\",  # 乐视 乐1S\n    \"X608\",  # 乐视 乐1\n    \"X800\",  # 乐视 乐1Pro\n    \"X900\",  # 乐视 乐Max\n    \"XT1085\",  # 摩托罗拉 X\n    \"XT1570\",  # 摩托罗拉 X Style\n    \"XT1581\",  # 摩托罗拉 X 极\n    \"XT1585\",  # 摩托罗拉 Droid Turbo 2\n    \"XT1635\",  # 摩托罗拉 Z Play\n    \"XT1635-02\",  # 摩托罗拉 Z Play\n    \"XT1650\",  # 摩托罗拉 Z\n    \"XT1650-05\",  # 摩托罗拉 Z\n    \"XT1706\",  # 摩托罗拉 E³ POWER\n    \"YD201\",  # YotaPhone2\n    \"YD206\",  # YotaPhone2\n    \"YQ60\",  # 锤子 坚果\n    \"ZTE A2015\",  # 中兴 AXON 天机\n    \"ZTE A2017\",  # 中兴 AXON 天机 7\n    \"ZTE B2015\",  # 中兴 AXON 天机 MINI\n    \"ZTE BV0720\",  # 中兴 Blade A2\n    \"ZTE BV0730\",  # 中兴 Blade A2 Plus\n    \"ZTE C2016\",  # 中兴 AXON 天机 MAX\n    \"ZTE C2017\",  # 中兴 AXON 天机 7 MAX\n    \"ZTE G720C\",  # 中兴 星星2号\n    \"ZUK Z2121\",  # ZUK Z2 Pro\n    \"ZUK Z2131\",  # ZUK Z2\n    \"ZUK Z2151\",  # ZUK Edge\n    \"ZUK Z2155\",  # ZUK Edge L\n    \"m030\",  # 魅族mx\n    \"m1 metal\",  # 魅蓝metal\n    \"m1 note\",  # 魅蓝 Note\n    \"m1\",  # 魅蓝\n    \"m2 note\",  # 魅蓝 Note 2\n    \"m2\",  # 魅蓝 2\n    \"m3 note\",  # 魅蓝 Note 3\n    \"m3\",  # 魅蓝 3\n    \"m3s\",  # 魅蓝 3S\n    \"m9\",  # 魅族m9\n    \"marlin\",  # Google Pixel XL\n    \"sailfish\",  # Google Pixel\n    \"vivo V3Max\",  # vivo V3Max\n    \"vivo X6D\",  # vivo X6\n    \"vivo X6PlusD\",  # vivo X6Plus\n    \"vivo X6S\",  # vivo X6S\n    \"vivo X6SPlus\",  # vivo X6SPlus\n    \"vivo X7\",  # vivo X7\n    \"vivo X7Plus\",  # vivo X7Plus\n    \"vivo X9\",  # vivo X9\n    \"vivo X9Plus\",  # vivo X9Plus\n    \"vivo Xplay5A 金\",  # vivo Xplay5\n    \"vivo Xplay6\",  # vivo Xplay6\n    \"vivo Y66\",  # vivo Y66\n    \"vivo Y67\",  # vivo Y67\n    \"z1221\",  # ZUK Z1\n]\n\ns = '\\x1b[%s;%sm%s\\x1b[0m'       # terminual color template\n\ncookie_file = os.path.join(os.path.expanduser('~'), '.bp.cookies')\nupload_datas_path = os.path.join(os.path.expanduser('~'), '.bp.pickle')\nsave_share_path = os.path.join(os.path.expanduser('~'), '.bp.ss.pickle')\n\nheaders = {\n    \"Accept\": \"application/json, text/javascript, text/html, */*; q=0.01\",\n    \"Accept-Encoding\":\"gzip, deflate, sdch\",\n    \"Accept-Language\":\"en-US,en;q=0.8,zh-CN;q=0.6,zh;q=0.4,zh-TW;q=0.2\",\n    \"Referer\":\"http://pan.baidu.com/disk/home\",\n    \"X-Requested-With\": \"XMLHttpRequest\",\n    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.75 Safari/537.36\",\n    \"Connection\": \"keep-alive\",\n}\n\nNETDISK_UA = 'netdisk;8.12.9;;android-android;7.0;JSbridge3.0.0'\n\nss = requests.session()\nss.headers.update(headers)\n\ndef to_md5(buff):\n    assert isinstance(buff, (str, unicode))\n    if isinstance(buff, unicode):\n        buff = buff.encode('utf-8')\n    return hashlib.md5(buff).hexdigest()\n\n\ndef to_sha1(buff):\n    assert isinstance(buff, (str, unicode))\n    if isinstance(buff, unicode):\n        buff = buff.encode('utf-8')\n    return hashlib.sha1(buff).hexdigest()\n\n# 根据key计算出imei\ndef sum_IMEI(key):\n    hs = 53202347234687234\n    for k in key:\n        hs += (hs << 5) + ord(k)\n    hs %= int(1e15)\n    if hs < int(1e14):\n        hs += int(1e14)\n    return str(int(hs))\n\n# 根据key, 从 PHONE_MODEL_DATABASE 中取出手机型号\ndef get_phone_model(key):\n    if len(PHONE_MODEL_DATABASE) <= 0:\n        return \"S3\"\n    hs = 2134\n    for k in key:\n        hs += (hs << 4) + ord(k)\n    hs %= len(PHONE_MODEL_DATABASE)\n    return PHONE_MODEL_DATABASE[hs]\n\ndef import_shadowsocks():\n    try:\n        global encrypt\n        from shadowsocks import encrypt\n    except ImportError:\n        print s % (1, 93, '  !! you don\\'t install shadowsocks for python2.')\n        print s % (1, 97, '  install shadowsocks:')\n        print s % (1, 92, '  pip2 install shadowsocks')\n        sys.exit(1)\n\ndef get_abspath(pt):\n    if '~' == pt[0]:\n        path = os.path.expanduser(pt)\n    else:\n        path = os.path.abspath(pt)\n    if os.path.exists(path):\n        return path\n    else:\n        print s % (1, 91, '  !! path isn\\'t existed.'), pt\n        return None\n\ndef make_server_path(cwd, path):\n    def cd(cwd, part):\n        if part == '..':\n            cwd = os.path.dirname(cwd)\n        elif part == '.':\n            pass\n        elif part == '':\n            pass\n        elif part == '...':\n            cwd = os.path.dirname(cwd)\n            cwd = os.path.dirname(cwd)\n        else:\n            cwd = os.path.join(cwd, part)\n        return cwd\n\n    if not path or path[0] == '/':\n        return path\n    else:\n        parts = path.split('/')\n        for p in parts:\n            cwd = cd(cwd, p)\n        return cwd\n\ndef fast_pcs_server(j):\n    if 'fs' not in args.type_:\n        return j\n\n    do = lambda dlink: \\\n        re.sub(r'://[^/]+?/', '://c.pcs.baidu.com/', dlink)\n        #re.sub(r'://[^/]+?/', '://c.pcs.baidu.com/', dlink)\n\n    if isinstance(j, dict) and j.get('info') and len(j['info']) > 0:\n        for i in xrange(len(j['info'])):\n            if j['info'][i].get('dlink'):\n                j['info'][i]['dlink'] = do(j['info'][i]['dlink'])\n    else:\n        j = do(j)\n    return j\n\ndef is_wenxintishi(dlink):\n    while True:\n        try:\n            res = ss.head(dlink)\n            break\n        except requests.exceptions.ConnectionError:\n            time.sleep(2)\n    location = res.headers.get('location', '')\n    if 'wenxintishi' in location:\n        return True\n    else:\n        return False\n\n# https://stackoverflow.com/questions/1094841/reusable-library-to-get-human-readable-version-of-file-size\ndef sizeof_fmt(num):\n    for x in ['B','KB','MB','GB']:\n        if num < 1024.0:\n            return \"%3.1f%s\" % (num, x)\n        num /= 1024.0\n    return \"%3.1f%s\" % (num, 'TB')\n\ndef print_process_bar(point, total, slice_size,\n                      start_time=None, pre='', suf='', msg=''):\n    length = 20\n    nowpoint = point / (total + 0.0)\n    percent = round(100 * nowpoint, 1)\n    now = time.time()\n    speed = sizeof_fmt(slice_size / (now - start_time)) + '/s'\n    t = int(nowpoint*length)\n\n    msg = '\\r' + ' '.join([pre, '|%s%s|' % ('='*t, ' '*(length - t)), \\\n        str(percent) + '%', speed, msg, suf])\n    sys.stdout.write(msg)\n    sys.stdout.flush()\n    return now\n\n\ndef is_cookie(cookie):\n    return 'BDUSS=' in cookie and 'PANPSC=' in cookie and len(cookie) > 150\n\n\ndef parse_cookies(cookie):\n    cookies = {}\n    for c in cookie.split('; '):\n        k, v = c.split('=', 1)\n        cookies[k] = v\n    return cookies\n\n\nclass panbaiducom_HOME(object):\n    def __init__(self):\n        self._download_do = self._play_do if args.play else self._download_do\n        self.ondup = 'overwrite'\n        self.accounts = self._check_cookie_file()\n        self.dsign = None\n        self.timestamp = None\n        self.user_id = None\n\n        self.highlights = []\n        if any([args.tails, args.heads, args.includes]):\n            for tail in args.tails:\n                self.highlights.append({'text': tail.decode('utf8', 'ignore'),\n                                        'is_regex': 0})\n            for head in args.heads:\n                self.highlights.append({'text': head.decode('utf8', 'ignore'),\n                                        'is_regex': 0})\n            for include in args.includes:\n                self.highlights.append({'text': include.decode('utf8', 'ignore'),\n                                        'is_regex': 1})\n\n        if 'ec' in args.type_ or 'dc' in args.type_ or args.comd == 'dc':\n            import_shadowsocks()\n\n    def _request(self, method, url, action, **kwargs):\n        i = 0\n        while i < 3:\n            i += 1\n            response = ss.request(method, url, **kwargs)\n            if not (response.ok is True and response.status_code == 200):\n                continue\n            else:\n                return response\n\n        self.save_cookies()\n\n        print s % (1, 91, ' ! [{}] Server error'.format(action))\n        sys.exit()\n\n    @staticmethod\n    def _check_cookie_file():\n        def correct_do():\n            with open(cookie_file, 'wb') as g:\n                pk.dump({}, g)\n            print s % (1, 97, '  please login')\n            return\n\n        if not os.path.exists(cookie_file):\n            correct_do()\n            return {}\n\n        try:\n            j = pk.load(open(cookie_file))\n        except:\n            correct_do()\n            return {}\n\n        if type(j) != type({}):\n            correct_do()\n            return {}\n\n        for i in j:\n            if type(j[i]) != type({}):\n                del j[i]\n            else:\n                if not j[i].get('cookies'):\n                    del j[i]\n\n        return j\n\n    def init(self):\n        if self.accounts:\n            j = self.accounts\n            u = [u for u in j if j[u]['on']]\n            if u:\n                user = u[0]\n                self.user = user\n                self.cwd = j[user]['cwd'] if j[user].get('cwd') else '/'\n                self.user_id = j[user].get('user_id')\n                self.bduss = j[user]['cookies']['BDUSS']\n                ss.cookies.update(j[user]['cookies'])\n            else:\n                print s % (1, 91, '  !! no account is online, please login or userchange')\n                sys.exit(1)\n\n            if not self.check_login():\n                print s % (1, 91, '  !! cookie is invalid, please login.'), u[0]\n                del j[u[0]]\n                with open(cookie_file, 'w') as g:\n                    pk.dump(j, g)\n                sys.exit(1)\n\n            if not self.user_id:\n                info = self._user_info(self.bduss)\n                self.user_id = info['user']['id']\n        else:\n            print s % (1, 97, '  no account, please login')\n            sys.exit(1)\n\n    @staticmethod\n    def save_img(url, ext):\n        path = os.path.join(os.path.expanduser('~'), 'vcode.%s' % ext)\n        with open(path, 'w') as g:\n            res = ss.get(url)\n            data = res.content\n            g.write(data)\n        print \"  ++ 验证码已保存至\", s % (1, 97, path)\n        input_code = raw_input(s % (2, 92, \"  输入验证码: \"))\n        return input_code\n\n    def check_login(self):\n        # html_string = self._request('GET', 'http://pan.baidu.com/', 'check_login').content\n        info = self._meta(['/'])\n\n        if info and info['errno'] == 0:\n            return True\n        else:\n            print s % (1, 91, '  -- check_login fail\\n')\n            return False\n            #print s % (1, 92, '  -- check_login success\\n')\n            #self.get_dsign()\n            #self.save_cookies()\n\n    def login(self, username, password):\n        print s % (1, 97, '\\n  -- login')\n\n        if is_cookie(password):\n            cookies = parse_cookies(password)\n            ss.cookies.update(cookies)\n            return\n\n        # error_message: at _check_account_exception from\n        # https://github.com/ly0/baidupcsapi/blob/master/baidupcsapi/api.py\n        login_error_msg = {\n                '-1': '系统错误, 请稍后重试',\n                 '1': '输入的帐号格式不正确',\n                 '3': '验证码不存在或已过期,请重新输入',\n                 '4': '输入的帐号或密码有误',\n                 '5': '请重新登录',\n                 '6': '验证码输入错误',\n                '16': '帐号因安全问题已被限制登录',\n               '257': '需要验证码',\n            '100005': '系统错误, 请稍后重试',\n            '120016': '未知错误 120016',\n            '120019': '近期登录次数过多, 请先通过 passport.baidu.com 解除锁定',\n            '120021': '登录失败,重新登录',\n            '500010': '登录过于频繁,请24小时后再试',\n            '400031': '账号异常',\n            '401007': '手机号关联了其他帐号，请选择登录'\n        }\n\n        self._request('GET', 'http://www.baidu.com', 'login')\n\n        # Get token\n        # token = self._get_bdstoken()\n        resp = self._request('GET', 'https://passport.baidu.com/v2/api/?getapi&tpl=netdisk'\n                      '&apiver=v3&tt={}&class=login&logintype=basicLogin'.format(int(time.time())),\n                             'login')\n\n        _json = json.loads(resp.content.replace('\\'', '\"'))\n        if _json['errInfo']['no'] != \"0\":\n            print s % (1, 91, ' ! Can\\'t get token')\n            sys.exit(1)\n\n        token = _json['data']['token']\n        code_string = _json['data']['codeString']\n\n        # get publickey\n        # url = ('https://passport.baidu.com/v2/getpublickey?&token={}'\n               # '&tpl=netdisk&apiver=v3&tt={}').format(token, int(time.time()))\n        # r = ss.get(url)\n        # j = json.loads(r.content.replace('\\'', '\"'))\n        # pubkey = j['pubkey']\n        # key = rsa.PublicKey.load_pkcs1_openssl_pem(pubkey)\n        # password_encoded = base64.b64encode(rsa.encrypt(password, key))\n        # rsakey = j['key']\n\n        # Construct post body\n        verifycode = ''\n        while True:\n            data = {\n                \"staticpage\": \"http://pan.baidu.com/res/static/thirdparty/pass_v3_jump.html\",\n                \"charset\": \"utf-8\",\n                \"token\": token,\n                \"tpl\": \"netdisk\",\n                \"subpro\": \"\",\n                \"apiver\": \"v3\",\n                \"tt\": int(time.time()),\n                \"codestring\": code_string,\n                \"safeflg\": \"0\",\n                \"u\": \"http://pan.baidu.com/\",\n                \"isPhone\": \"\",\n                \"quick_user\": \"0\",\n                \"logintype\": \"basicLogin\",\n                \"logLoginType\": \"pc_loginBasic\",\n                \"idc\": \"\",\n                \"loginmerge\": \"true\",\n                \"username\": username,\n                \"password\": password,\n                \"verifycode\": verifycode,\n                \"mem_pass\": \"on\",\n                \"rsakey\": \"\",\n                \"crypttype\": \"\",\n                \"ppui_logintime\": \"2602\",\n                \"callback\": \"parent.bd__pcbs__ahhlgk\",\n            }\n\n            # Post!\n            # XXX : do not handle errors\n            url = 'https://passport.baidu.com/v2/api/?login'\n            r = ss.post(url, data=data)\n\n            # Callback for verify code if we need\n            #code_string = r.content[r.content.index('(')+1:r.content.index(')')]\n            errno = re.search(r'err_no=(\\d+)', r.content).group(1)\n            if ss.cookies.get('BDUSS'):\n                # ss.get(\"http://pan.baidu.com/disk/home\")\n                break\n            elif errno in ('257', '3', '6'):\n                print s % (1, 91, ' ! Error %s:' % errno), \\\n                    login_error_msg[errno]\n                t = re.search('codeString=(.+?)&', r.content)\n                code_string = t.group(1) if t else \"\"\n                vcurl = 'https://passport.baidu.com/cgi-bin/genimage?' + code_string\n                verifycode = self.save_img(vcurl, 'jpg') if code_string != \"\" else \"\"\n                data['codestring'] = code_string\n                data['verifycode'] = verifycode\n                #self.save_cookies()\n            else:\n                print s % (1, 91, ' ! Error %s:' % errno), \\\n                    login_error_msg.get(errno, \"unknow, please feedback to author\")\n                sys.exit(1)\n\n    def save_cookies(self, username=None, on=0, tocwd=False):\n        if not username: username = self.user\n        accounts = self.accounts\n        accounts[username] = accounts.get(username, {})\n        accounts[username]['cookies'] = \\\n            accounts[username].get('cookies', ss.cookies.get_dict())\n        accounts[username]['on'] = on\n        accounts[username]['user_id'] = self.user_id\n        quota = self._get_quota()\n        capacity = '%s/%s' % (sizeof_fmt(quota['used']), sizeof_fmt(quota['total']))\n        accounts[username]['capacity'] = capacity\n        if hasattr(self, 'cwd'):\n            if not accounts[username].get('cwd'):\n                accounts[username]['cwd'] = '/'\n            if tocwd: accounts[username]['cwd'] = self.cwd\n        else:\n            accounts[username]['cwd'] = '/'\n        for u in accounts:\n            if u != username and on:\n                accounts[u]['on'] = 0\n        with open(cookie_file, 'w') as g:\n            pk.dump(accounts, g)\n\n    def _get_bdstoken(self):\n        if hasattr(self, 'bdstoken'):\n            return self.bdstoken\n\n        resp = self._request('GET', 'http://pan.baidu.com/disk/home',\n                             '_get_bdstoken')\n\n        html_string = resp.content\n\n        mod = re.search(r'bdstoken[\\'\":\\s]+([0-9a-f]{32})', html_string)\n        if mod:\n            self.bdstoken = mod.group(1)\n            return self.bdstoken\n        else:\n            print s % (1, 91, ' ! Can\\'t get bdstoken')\n            sys.exit(1)\n\n        # self.bdstoken = md5.new(str(time.time())).hexdigest()\n\n    def _user_info(self, bduss):\n        timestamp = str(int(time.time()))\n        model = get_phone_model(bduss)\n        phoneIMEIStr = sum_IMEI(bduss)\n\n        data = {\n            'bdusstoken': bduss + '|null',\n            'channel_id': '',\n            'channel_uid': '',\n            'stErrorNums': '0',\n            'subapp_type': 'mini',\n            'timestamp': timestamp + '922',\n        }\n        data['_client_type'] = '2'\n        data['_client_version'] = '7.0.0.0'\n        data['_phone_imei'] = phoneIMEIStr\n        data['from'] = 'mini_ad_wandoujia'\n        data['model'] = model\n        data['cuid'] = to_md5(\n            bduss + '_' + data['_client_version'] + '_' + data['_phone_imei'] + '_' + data['from']\n        ).upper() + '|' + phoneIMEIStr[::-1]\n        data['sign'] = to_md5(\n            ''.join([k + '=' + data[k] for k in sorted(data.keys())]) + 'tiebaclient!!!'\n        ).upper()\n\n        headers = {\n            'Content-Type': 'application/x-www-form-urlencoded',\n            'Cookie': 'ka=open',\n            'net': '1',\n            'User-Agent': 'bdtb for Android 6.9.2.1',\n            'client_logid': timestamp + '416',\n            'Connection': 'Keep-Alive',\n        }\n\n        resp = requests.post('http://tieba.baidu.com/c/s/login', headers=headers, data=data)\n        info = resp.json()\n        return info\n\n    #def _sift(self, fileslist, name=None, size=None, time=None, head=None, tail=None, include=None, exclude=None):\n    def _sift(self, fileslist, **arguments):\n        \"\"\"\n        a filter for time, size, name, head, tail, include, exclude, shuffle\n        support regular expression\n        \"\"\"\n\n        # for shuffle\n        if 's' in args.type_:\n            random.shuffle(fileslist)\n            return fileslist\n\n        # for time\n        elif arguments.get('name'):\n            reverse = None\n            if arguments['name'] == 'reverse':\n                reverse = True\n            elif arguments['name'] == 'no_reverse':\n                reverse = False\n            fileslist = sorted(fileslist, key=lambda k: k['server_filename'],\n                               reverse=reverse)\n\n        # for size\n        elif arguments.get('size'):\n            reverse = None\n            if arguments['size'] == 'reverse':\n                reverse = True\n            elif arguments['size'] == 'no_reverse':\n                reverse = False\n            fileslist = sorted(fileslist, key=lambda k: k['size'],\n                               reverse=reverse)\n\n        # for time\n        elif arguments.get('time'):\n            reverse = None\n            if arguments['time'] == 'reverse':\n                reverse = True\n            elif arguments['time'] == 'no_reverse':\n                reverse = False\n            fileslist = sorted(fileslist, key=lambda k: k['server_mtime'],\n                               reverse=reverse)\n\n        # for head, tail, include, exclude\n        heads = args.heads\n        tails = args.tails\n        includes = args.includes\n        excludes = args.excludes\n        keys1, keys2, keys3, keys4 = [], [], [], []\n        if heads or tails or includes or excludes:\n            tdict = {\n                fileslist[i]['server_filename'] : i for i in xrange(len(fileslist))\n            }\n            for head in heads:\n                keys1 += [\n                    i for i in tdict.keys()\n                        if i.lower().startswith(\n                            head.decode('utf8', 'ignore').lower()\n                        )\n                ]\n            for tail in tails:\n                keys2 += [\n                    i for i in tdict.keys()\n                          if i.lower().endswith(\n                              tail.decode('utf8', 'ignore').lower()\n                          )\n                ]\n            for include in includes:\n                keys3 += [\n                    i for i in tdict.keys()\n                          if re.search(\n                              include.decode('utf8', 'ignore'), i, flags=re.I\n                          )\n                ]\n            for exclude in excludes:\n                keys4 += [\n                    i for i in tdict.keys()\n                          if not re.search(\n                              exclude.decode('utf8', 'ignore'), i, flags=re.I\n                          )\n                ]\n\n            # intersection\n            keys = [set(i) for i in [keys1, keys2, keys3, keys4] if i]\n            if len(keys) > 1:\n                tkeys = keys[0]\n                for i in keys:\n                    tkeys &= i\n                keys = tkeys\n            elif len(keys) == 1:\n                keys = keys[0]\n            elif len(keys) == 0:\n                keys = []\n                return []\n\n            indexs = [tdict[i] for i in keys]\n            indexs.sort()\n            fileslist = [fileslist[i] for i in indexs]\n\n        dirs = [i for i in fileslist if i['isdir']]\n        t, tt = [], []\n        if 'e' in args.type_:\n            for i in dirs:\n                d = i['path'].encode('utf8')\n                j = self._get_file_list('name', None, d, 1, all=False)\n                if not j['list']:\n                    t.append(i)\n                else:\n                    tt.append(i)\n        if 'e' in args.type_: dirs = t\n        if 'ne' in args.type_: dirs = tt\n        files = [i for i in fileslist if not i['isdir']]\n        if arguments.get('desc') == 1:\n            dirs.reverse()\n            files.reverse()\n\n        if 'f' in args.type_:\n            fileslist = files\n        elif 'd' in args.type_:\n            fileslist = dirs\n        else:\n            fileslist = dirs + files\n\n        return fileslist\n\n    def _get_path(self, url):\n        t = re.search(r'path=(.+?)(&|$)', url)\n        if t:\n            t = t.group(1)\n            t = urllib.unquote_plus(t)\n            t = urllib.unquote_plus(t)\n            return t\n        else:\n            return url\n\n    def _get_quota(self):\n        url = 'http://pan.baidu.com/api/quota'\n\n        resp = self._request('GET', url, '_get_quota')\n\n        j = resp.json()\n        if j['errno'] != 0:\n            print s % (1, 92, '  !! Error at _get_quota')\n            sys.exit(1)\n        else:\n            return j\n\n    def _get_file_list(self, order, desc, dir_, num, all=True):\n        t = {'Referer':'http://pan.baidu.com/disk/home'}\n        theaders = headers\n        theaders.update(t)\n\n        p = {\n            \"channel\": \"chunlei\",\n            \"clienttype\": 0,\n            \"web\": 1,\n            \"showempty\": 1,\n            \"num\": num,   ## max amount is 10000\n            \"t\": int(time.time()*1000),\n            \"dir\": dir_,\n            \"page\": 1,\n            \"desc\": 1,   ## reversely\n            \"order\": order, ## sort by name, or size, time\n            \"_\": int(time.time()*1000),\n            # \"bdstoken\": self._get_bdstoken(),\n        }\n        if not desc: del p['desc']\n        url = 'http://pan.baidu.com/api/list'\n\n        path_list = []\n        while True:\n            r = ss.get(url, params=p)\n            j = r.json()\n            if j['errno'] != 0:\n                print s % (1, 91, '  error: _get_file_list'), '--', j\n                sys.exit(1)\n            else:\n                path_ls = j['list']\n                path_list += path_ls\n\n            if not all: return j\n\n            if len(path_ls) == num:\n                p['page'] += 1\n            else:\n                j['list'] = path_list\n                return j\n\n    def _get_dsign(self):\n        # if self.dsign is not None:\n            # return None\n\n        url = 'http://pan.baidu.com/disk/home'\n        r = self._request('GET', url, '_get_dsign')\n        html = r.content\n\n        sign1 = re.search(r'\"sign1\":\"(.+?)\"', html).group(1)\n        sign3 = re.search(r'\"sign3\":\"(.+?)\"', html).group(1)\n        timestamp = re.search(r'\"timestamp\":(\\d+)', html).group(1)\n\n        # following javascript code from http://pan.baidu.com/disk/home\n        #yunData.sign2 = function s(j, r) {\n        #    var a = [];\n        #    var p = [];\n        #    var o = \\x22\\ x22;\n        #    var v = j.length;\n        #    for (var q = 0; q < 256; q++) {\n        #        a[q] = j.substr((q % v), 1).charCodeAt(0);\n        #        p[q] = q\n        #    }\n        #    for (var u = q = 0; q < 256; q++) {\n        #        u = (u + p[q] + a[q]) % 256;\n        #        var t = p[q];\n        #        p[q] = p[u];\n        #        p[u] = t\n        #    }\n        #    for (var i = u = q = 0; q < r.length; q++) {\n        #        i = (i + 1) % 256;\n        #        u = (u + p[i]) % 256;\n        #        var t = p[i];\n        #        p[i] = p[u];\n        #        p[u] = t;\n        #        k = p[((p[i] + p[u]) % 256)];\n        #        o += String.fromCharCode(r.charCodeAt(q) ^ k)\n        #    }\n        #    return o\n        #};\n\n        def sign2(j, r):\n            a = []\n            p = []\n            o = ''\n            v = len(j)\n\n            for q in xrange(256):\n                a.append(ord(j[q % v]))\n                p.append(q)\n\n            u = 0\n            for q in xrange(256):\n                u = (u + p[q] + a[q]) % 256\n                t = p[q]\n                p[q] = p[u]\n                p[u] = t\n\n            i = 0\n            u = 0\n            for q in xrange(len(r)):\n                i = (i + 1) % 256\n                u = (u + p[i]) % 256\n                t = p[i]\n                p[i] = p[u]\n                p[u] = t\n                k = p[((p[i] + p[u]) % 256)]\n                o += chr(ord(r[q]) ^ k)\n\n            return base64.b64encode(o)\n\n        self.dsign = sign2(sign3, sign1)\n        self.timestamp = timestamp\n\n    def _get_dlink(self, path):\n        bduss = self.bduss\n        uid = self.user_id\n\n        timestamp = str(int(time.time() * 1000))\n        devuid = '0|' + to_md5(bduss).upper()\n\n        enc = to_sha1(bduss)\n        rand = to_sha1(\n            enc + str(uid) + 'ebrcUYiuxaZv2XGu7KIYKxUrqfnOfpDF' + str(timestamp) + devuid\n        )\n\n        url = (\n            'https://pcs.baidu.com/rest/2.0/pcs/file?app_id=' + args.appid \\\n            + '&method=locatedownload&ver=2' \\\n            + '&path=' + urllib.quote(path) + '&time=' \\\n            + timestamp + '&rand=' + rand + '&devuid=' + devuid\n        )\n\n        headers = dict(ss.headers)\n        headers['User-Agent'] = 'netdisk;2.2.51.6;netdisk;10.0.63;PC;android-android'\n        resp = self._request('GET', url, '_get_dlink', headers=headers)\n        info = resp.json()\n        if info.get('urls'):\n            dlink = info['urls'][0]['url'].encode('utf8')\n            return dlink\n        else:\n            print s % (1, 91, '  !! Error at _get_dlink, can\\'t get dlink')\n            sys.exit(1)\n\n    def _get_dlink4(self, path):\n        # use app_id: 778750\n        # reference: [3个方法解决百度网盘限速](https://www.runningcheese.com/baiduyun)\n        dlink = ('http://c.pcs.baidu.com/rest/2.0/pcs/file?method=download'\n                 '&app_id={}&path={}&ver=2.0&clienttype=1').format(\n                    args.appid, urllib.quote(path))\n\n        dlink = fast_pcs_server(dlink)\n        return dlink\n\n    def _get_dlink3(self, fs_id):\n        while True:\n            dsign, timestamp = self._get_dsign()\n\n            params = {\n                \"channel\": \"chunlei\",\n                \"clienttype\": 0,\n                \"app_id\": \"250528\",\n                \"web\": 1,\n                # \"bdstoken\": self._get_bdstoken(),\n                \"sign\": self.dsign,\n                \"timestamp\": self.timestamp,\n                \"fidlist\": '[{}]'.format(fs_id),\n                \"type\": \"dlink\",\n            }\n\n            url = 'http://pan.baidu.com/api/download'\n            r = ss.get(url, params=params)\n            j = r.json()\n            print(j)\n            if j['errno'] == 0:\n                dlink = j['dlink'][0]['dlink'].encode('utf8')\n                # dlink = re.sub(r'prisign=.+?(&|$)', r'prisign=unknow\\1', dlink)\n                # dlink = dlink.replace('chkbd=0', 'chkbd=1')\n                # dlink = dlink.replace('chkv=0', 'chkv=1')\n                dlink = fast_pcs_server(dlink)\n                return dlink\n            else:\n                print s % (1, 91, '  !! Error at _get_dlink, can\\'t get dlink')\n                continue\n\n    def _get_dlink2(self, i):\n        j = self._meta([i['path'].encode('utf8')], dlink=1)\n        if j:\n            return j['info'][0]['dlink'].encode('utf8')\n        else:\n            print s % (1, 91, '  !! Error at _get_dlink2')\n            sys.exit(1)\n\n    def _get_m3u8(self, info):\n        p = {\n            \"method\": \"streaming\",\n            \"path\": info['path'].encode('utf8'),\n            \"type\": \"M3U8_AUTO_720\",\n            \"app_id\": \"250528\",\n            #\"bdstoken\": self._get_bdstoken(),\n        }\n\n        url = \"https://pcs.baidu.com/rest/2.0/pcs/file\"\n\n        r = ss.get(url, params=p, verify=VERIFY)\n        m3u8 = r.content\n        if '#EXTM3U' not in m3u8[:7]:\n            return None\n        #m3u8 = fast_pcs_server(m3u8)\n        return m3u8\n\n    def download(self, paths):\n        for path in paths:\n            path = self._get_path(path) if path[0] != '/' else path\n            path = make_server_path(self.cwd, path)\n            base_dir = '' if os.path.split(path)[0] == '/' \\\n                else os.path.split(path)[0]\n\n            meta = self._meta([path], dlink=0)\n            if meta:\n                if meta['info'][0]['isdir']:\n                    dir_loop = [path]\n                    for d in dir_loop:\n                        j = self._get_file_list('name', None, d, 10000)\n                        if j['list']:\n                            if args.recursive:\n                                for i in j['list']:\n                                    dir_loop.append(i['path'].encode('utf8')) \\\n                                        if i['isdir'] else None\n\n                            if args.play:\n                                j['list'] = [\n                                    i for i in j['list'] \\\n                                        if not i['isdir'] \\\n                                            and os.path.splitext(\n                                                i['server_filename']\n                                            )[-1].lower() in mediatype]\n                            if 's' in args.type_:\n                                j['list'] = self._sift(j['list'])\n\n                            if args.heads or args.tails or args.includes \\\n                                    or args.excludes:\n                                j['list'] = self._sift(j['list'])\n\n                            total_file = len([i for i in j['list'] \\\n                                              if not i['isdir']])\n\n                            if args.from_ - 1:\n                                j['list'] = j['list'][args.from_-1:] \\\n                                    if args.from_ else j['list']\n\n                            nn = args.from_\n                            for i in j['list']:\n                                if i['isdir']: continue\n\n                                t = i['path'].encode('utf8')\n                                t = t.replace(base_dir, '')\n                                t = t[1:] if t[0] == '/' else t\n                                t =  os.path.join(args.outdir, t)\n\n                                i['dlink'] = self._get_dlink(i['path'].encode('utf8'))\n\n                                infos = {\n                                    'file': t,\n                                    'path': i['path'].encode('utf8'),\n                                    'dir_': os.path.split(t)[0],\n                                    'dlink': i['dlink'].encode('utf8'),\n                                    'm3u8': self._get_m3u8(i) \\\n                                        if 'm3' in args.type_ else None,\n                                    'name': i['server_filename'].encode('utf8'),\n                                    'size': i['size'],\n                                    'nn': nn,\n                                    'total_file': total_file\n                                }\n                                nn += 1\n                                self._download_do(infos)\n                                if 'dc' in args.type_:\n                                    self.decrypt([infos['file']])\n\n                elif not meta['info'][0]['isdir']:\n                    t =  os.path.join(\n                        args.outdir, meta['info'][0]['server_filename'].encode('utf8')\n                    )\n                    infos = {\n                        'file': t,\n                        'path': meta['info'][0]['path'].encode('utf8'),\n                        'dir_': os.path.split(t)[0],\n                        'dlink': self._get_dlink(meta['info'][0]['path'].encode('utf8')),\n                        'm3u8': self._get_m3u8(meta['info'][0]) \\\n                            if 'm3' in args.type_ else None,\n                        # 'dlink': meta['info'][0]['dlink'].encode('utf8'),\n                        'name': meta['info'][0]['server_filename'].encode('utf8'),\n                        'size': meta['info'][0]['size'],\n                    }\n                    if args.play:\n                        if not os.path.splitext(infos['name'])[-1].lower() in mediatype:\n                            continue\n                    self._download_do(infos)\n                    if 'dc' in args.type_:\n                        self.decrypt([infos['file']])\n\n            else:\n                print s % (1, 91, '  !! path is not existed.\\n'), \\\n                    ' --------------\\n ', path\n\n    @staticmethod\n    def _download_do(infos):\n        ## make dirs\n        if not os.path.exists(infos['dir_']):\n            os.makedirs(infos['dir_'])\n        else:\n            if os.path.exists(infos['file']):\n                return\n\n        num = random.randint(0, 7) % 8\n        col = sizeof_fmt(infos['size']) + ' # ' + s % (2, num + 90, infos['path']) \\\n            if args.view else s % (2, num + 90, infos['name'])\n        infos['nn'] = infos['nn'] if infos.get('nn') else 1\n        infos['total_file'] = infos['total_file'] if infos.get('total_file') else 1\n        print '\\n  ++ download: #', s % (1, 97, infos['nn']), '/', \\\n            s % (1, 97, infos['total_file']), '#', col\n\n        if '8s' in args.type_ and is_wenxintishi(infos['dlink']):\n            print s % (1, 93, '  !! 百度8秒 !!')\n            return\n\n        cookie = 'Cookie: ' + '; '.join([\n            k + '=' + v for k, v in ss.cookies.get_dict().items()])\n\n        # Netdisk user agents:\n        #\n        # \"netdisk;6.7.1.9;PC;PC-Windows;10.0.17763;WindowsBaiduYunGuanJia\"\n        # \"netdisk;5.3.1.3;PC;PC-Windows;5.1.2600;WindowsBaiduYunGuanJia\"\n        # \"netdisk;7.15.1;HUAWEI+G750-T01;android-android;4.2.2\"\n        # \"netdisk;4.4.0.6;PC;PC-Windows;6.2.9200;WindowsBaiduYunGuanJia\"\n        # \"netdisk;5.3.1.3;PC;PC-Windows;5.1.2600;WindowsBaiduYunGuanJia\"\n        #\n        # 'LogStatistic'\n\n        # Recently all downloading requests using above user-agents are limited by baidu\n\n        # user_agent = headers['User-Agent']\n        user_agent = 'netdisk;2.2.51.6;netdisk;10.0.63;PC;android-android'\n\n        if args.aget_s:\n            quiet = ' --quiet=true' if args.quiet else ''\n            cmd = 'ag ' \\\n                '\"%s\" ' \\\n                '-o \"%s.tmp\" ' \\\n                '-H \"User-Agent: %s\" ' \\\n                '-H \"Connection: Keep-Alive\" ' \\\n                '-H \"%s\" ' \\\n                '-s %s -k %s' \\\n                % (infos['dlink'], infos['file'], user_agent, cookie, args.aget_s, args.aget_k)\n        elif args.aria2c:\n            quiet = ' --quiet=true' if args.quiet else ''\n            taria2c = ' -x %s -s %s' % (args.aria2c, args.aria2c)\n            tlimit = ' --max-download-limit %s' % args.limit if args.limit else ''\n            cmd = 'aria2c -c%s%s%s ' \\\n                '-o \"%s.tmp\" -d \"%s\" ' \\\n                '--user-agent \"%s\" ' \\\n                '--header \"Connection: Keep-Alive\" ' \\\n                '--header \"Accept-Encoding: gzip\" ' \\\n                '--header \"%s\" ' \\\n                '\"%s\"' \\\n                % (quiet, taria2c, tlimit, infos['name'],\n                   infos['dir_'], user_agent,\n                   cookie, infos['dlink'])\n        else:\n            if infos['size'] >= 100 * OneM:\n                print '\\x1b[1;91mWarning\\x1b[0m: '\\\n                    '\\x1b[1;91m%s\\x1b[0m\\n\\n' % \"File size is large, please use aget or aria2 to download\\naget: https://github.com/PeterDing/aget-rs\\naria2: https://github.com/aria2/aria2\"\n\n            quiet = ' -q' if args.quiet else ''\n            tlimit = ' --limit-rate %s' % args.limit if args.limit else ''\n            cmd = 'wget -c%s%s ' \\\n                '-O \"%s.tmp\" ' \\\n                '--header \"User-Agent: %s\" ' \\\n                '--header \"Connection: Keep-Alive\" ' \\\n                '--header \"Accept-Encoding: gzip\" ' \\\n                '--header \"%s\" ' \\\n                '\"%s\"' \\\n                % (quiet, tlimit, infos['file'],\n                   user_agent, cookie, infos['dlink'])\n\n        status = os.system(cmd)\n        exit = True\n        if 'ie' in args.type_:\n            if status == 2 and not args.aria2c:\n                pass\n            elif status == (7 << 8) and args.aria2c:\n                pass\n            else:\n                exit = False\n\n        content_length_matched = False\n        saved_path = '%s.tmp' % infos['file']\n        if os.path.exists(saved_path):\n            meta = os.stat(saved_path)\n            if meta.st_size == infos['size']:\n                content_length_matched = True\n\n        if status != 0 or not content_length_matched:     # other http-errors, such as 302.\n            #wget_exit_status_info = wget_es[status]\n            print('\\n\\n ---###   \\x1b[1;91mEXIT STATUS\\x1b[0m ==> '\\\n                '\\x1b[1;91m%d\\x1b[0m   ###--- \\n\\n' % status)\n            print s % (1, 91, '  ===> '), cmd\n            if exit: sys.exit(1)\n        else:\n            os.rename('%s.tmp' % infos['file'], infos['file'])\n\n    @staticmethod\n    def _play_do(infos):\n        num = random.randint(0, 7) % 8\n        col = sizeof_fmt(infos['size']) \\\n            + ' # ' \\\n            + s % (2, num + 90, infos['path']) \\\n                if args.view else s % (2, num + 90, infos['name'])\n        infos['nn'] = infos['nn'] if infos.get('nn') else 1\n        infos['total_file'] = infos['total_file'] \\\n                                if infos.get('total_file') else 1\n        print '\\n  ++ play%s: #' \\\n            % (s % (1, 92, ' m3u8') if infos.get('m3u8') else ''), \\\n            s % (1, 97, infos['nn']), '/', \\\n            s % (1, 97, infos['total_file']), '#', col\n        if is_wenxintishi(infos['dlink']):\n            print s % (1, 93, '  !! 百度8秒 !!')\n            return\n\n        if infos.get('m3u8'):\n            with open('/tmp/tmp_pan.baidu.com.py.m3u8', 'w') as g:\n                g.write(infos['m3u8'])\n            infos['dlink'] = '/tmp/tmp_pan.baidu.com.py.m3u8'\n\n        cookie = 'Cookie: ' + '; '.join([\n            k + '=' + v for k, v in ss.cookies.get_dict().items()])\n        user_agent = 'User-Agent: ' + headers['User-Agent']\n        quiet = ' --really-quiet' if args.quiet else ''\n        cmd = 'mpv%s --no-ytdl --http-header-fields=\"%s\",\"%s\" ' \\\n            % (quiet, user_agent, cookie)\n\n        if infos.get('m3u8'):\n            # https://github.com/mpv-player/mpv/issues/6928#issuecomment-532198445\n            cmd += ' --stream-lavf-o-append=\"protocol_whitelist=file,http,https,tcp,tls,crypto,hls,applehttp\" '\n\n        cmd += \"%s\" % infos['dlink']\n\n        os.system(cmd)\n        timeout = 1\n        ii, _, _ = select.select([sys.stdin], [], [], timeout)\n        if ii:\n            sys.exit(0)\n        else:\n            pass\n\n    def _make_dir(self, dir_):\n        p = {\n            \"a\": \"commit\",\n            \"channel\": \"chunlei\",\n            \"clienttype\": 0,\n            \"web\": 1,\n            \"bdstoken\": self._get_bdstoken()\n        }\n        data = {\n            \"path\": dir_,\n            \"isdir\": 1,\n            \"size\": \"\",\n            \"block_list\": [],\n            \"method\": \"post\"\n        }\n        url = 'http://pan.baidu.com/api/create'\n        r = ss.post(url, params=p, data=data)\n        j = r.json()\n        if j['errno'] != 0:\n            print s % (1, 91, '  !! Error at _make_dir'), j\n            sys.exit(1)\n        else:\n            return ENoError\n\n    def _meta(self, file_list, dlink=0):\n\n        p = {\n            # \"channel\": \"chunlei\",\n            # \"app_id\": \"250528\",\n            \"method\": \"filemetas\",\n            \"dlink\": dlink,\n            \"blocks\": 0,  # 0 or 1\n            # \"bdstoken\": self._get_bdstoken()\n        }\n\n        # ss.get('http://pan.baidu.com/disk/home')\n        url = 'http://pan.baidu.com/api/filemetas'\n        i = 0\n        j = {}\n        while True:\n            fl = file_list[i:i+100]\n            if fl:\n                data = {'target': json.dumps(fl)}\n                try:\n                    r = self._request('POST', url, '_meta', params=p, data=data)\n                    # r = ss.post(url, params=p, data=data)\n                    js = r.json()\n                    if js['errno'] == 0 and i == 0:\n                        if dlink:\n                            js = fast_pcs_server(js)\n                        j = js\n                    elif js['errno'] == 0:\n                        if dlink:\n                            js = fast_pcs_server(js)\n                        j['info'].append(js['info'])\n                    else:\n                        return False\n                except Exception:\n                    time.sleep(1)\n            else:\n                return j\n            i += 100\n\n    ################################################################\n    # for upload\n\n    def _rapidupload_file(self, lpath, rpath):\n        print '  |-- upload_function:', s % (1, 97, '_rapidupload_file')\n        slice_md5 = md5.new(open(lpath, 'rb').read(256 * OneK)).hexdigest()\n        with open(lpath, \"rb\") as f:\n            buf = f.read(OneM)\n            content_md5 = md5.new()\n            content_md5.update(buf)\n            crc = crc32(buf).conjugate()\n            while True:\n                buf = f.read(OneM)\n                if buf:\n                    crc = crc32(buf, crc).conjugate()\n                    content_md5.update(buf)\n                else:\n                    break\n            content_md5 = content_md5.hexdigest()\n            content_crc32 = crc.conjugate() & 0xffffffff\n\n        p = {\n            \"method\" : \"rapidupload\",\n            \"app_id\": \"250528\",\n            \"BDUSS\": ss.cookies['BDUSS']\n        }\n        data = {\n            \"path\": os.path.join(rpath, os.path.basename(lpath)),\n            \"content-length\" : self.__current_file_size,\n            \"content-md5\" : content_md5,\n            \"slice-md5\" : slice_md5,\n            \"content-crc32\" : content_crc32,\n            \"ondup\" : self.ondup\n        }\n\n        # WARNING: here needs netdist user-agent\n        theaders = dict(ss.headers)\n        theaders['User-Agent'] = NETDISK_UA\n\n        url = 'https://c.pcs.baidu.com/rest/2.0/pcs/file'\n        r = ss.post(url, params=p, data=data, verify=VERIFY, headers=theaders)\n        if r.ok:\n            return ENoError\n        else:\n            return r.json()\n\n    def _upload_one_file(self, lpath, rpath):\n        print '  |-- upload_function:', s % (1, 97, '_upload_one_file')\n        start_time = time.time()\n        p = {\n            \"method\": \"upload\",\n            \"app_id\": \"250528\",\n            \"ondup\": self.ondup,\n            \"dir\": rpath,\n            \"BDUSS\": ss.cookies['BDUSS'],\n        }\n\n        if self.toEncrypt:\n            fl = self._cipherer.encrypt(open(lpath, 'rb').read())\n            file = b'__' + bytes(DefaultSliceSize) + b'__' + fl\n            file = cStringIO.StringIO(file)\n            if 'np' not in args.type_:\n                p['filename'] = 'encrypted_' + os.path.basename(lpath)\n            else:\n                p['filename'] = os.path.basename(lpath)\n        else:\n            file = open(lpath, 'rb')\n            p['filename'] = os.path.basename(lpath)\n\n        files = {'file': ('file', file, '')}\n        data = MultipartEncoder(files)\n        theaders = headers\n        theaders['Content-Type'] = data.content_type\n        url = 'https://c.pcs.baidu.com/rest/2.0/pcs/file'\n        r = ss.post(url, params=p, data=data, verify=VERIFY, headers=theaders)\n        if r.ok:\n            t = self.__current_file_size\n            print_process_bar(t, t, t, start_time, pre='     ')\n            return ENoError\n        else:\n            return r.json()\n\n    def _combine_file(self, lpath, rpath):\n        p = {\n            \"method\": \"createsuperfile\",\n            \"app_id\": \"250528\",\n            \"ondup\": self.ondup,\n            \"BDUSS\": ss.cookies['BDUSS'],\n        }\n\n        if self.toEncrypt and 'np' not in args.type_:\n            p['path'] = os.path.join(rpath, 'encrypted_' + os.path.basename(lpath))\n        else:\n            p['path'] = os.path.join(rpath, os.path.basename(lpath))\n\n        data = {\n            'param': json.dumps(\n                {'block_list': self.upload_datas[lpath]['slice_md5s']}\n            )\n        }\n\n        # WARNING: here needs netdist user-agent\n        theaders = dict(ss.headers)\n        theaders['User-Agent'] = NETDISK_UA\n\n        url = 'https://c.pcs.baidu.com/rest/2.0/pcs/file'\n        r = ss.post(url, params=p, data=data, verify=VERIFY, headers=theaders)\n        if r.ok:\n            return ENoError\n        else:\n            return r.json()\n\n    def _upload_slice(self, piece=0, slice=DefaultSliceSize):\n        p = {\n            \"method\": \"upload\",\n            \"app_id\": \"250528\",\n            \"type\": \"tmpfile\",\n            \"BDUSS\": ss.cookies['BDUSS'],\n        }\n\n        if self.toEncrypt:\n            __slice_block = self._cipherer.encrypt(self.__slice_block)\n            if piece == 0:\n                __slice_block = b'__' +  bytes(slice) + b'__' + __slice_block\n        else:\n            __slice_block = self.__slice_block\n        self.__slice_md5 = md5.new(__slice_block).hexdigest()\n\n        fl = cStringIO.StringIO(__slice_block)\n        files = {'file': ('file', fl, '')}\n        data = MultipartEncoder(files)\n        theaders = dict(headers)\n        theaders['Content-Type'] = data.content_type\n        theaders['User-Agent'] = NETDISK_UA\n\n        url = 'https://c.pcs.baidu.com/rest/2.0/pcs/file'\n        r = ss.post(url, params=p, data=data, verify=VERIFY, headers=theaders)\n        j = r.json()\n        if self.__slice_md5 == j.get('md5'):\n            return ENoError\n        else:\n            return j\n\n    def _get_pieces_slice(self):\n        pieces = MaxSlicePieces\n        slice = DefaultSliceSize\n        n = 1\n        while True:\n            t = n * DefaultSliceSize * MaxSlicePieces\n            if self.__current_file_size <= t:\n                if self.__current_file_size % (n * DefaultSliceSize) == 0:\n                    pieces = self.__current_file_size / (n * DefaultSliceSize)\n                    slice = n * DefaultSliceSize\n                else:\n                    pieces = (self.__current_file_size / (n * DefaultSliceSize)) + 1\n                    slice = n * DefaultSliceSize\n                break\n            elif t > MaxSliceSize * MaxSlicePieces:\n                n += 1\n            else:\n                print s % (1, 91, '  !! file is too big, uploading is not supported.')\n                sys.exit(1)\n\n        return pieces, slice\n\n    def _get_upload_function(self, rapidupload_is_fail=False):\n        if self.__current_file_size > MinRapidUploadFileSize:\n            if not rapidupload_is_fail and not self.toEncrypt:\n                return '_rapidupload_file'\n            else:\n                if self.__current_file_size <= DefaultSliceSize:\n                    return '_upload_one_file'\n\n                elif self.__current_file_size <= MaxSliceSize * MaxSlicePieces:\n                    return '_upload_file_slices'\n                else:\n                    print s % (1, 91, '  !! Error: size of file is too big.')\n                    return 'None'\n        else:\n            return '_upload_one_file'\n\n    def _upload_file(self, lpath, rpath):\n        print s % (1, 94, '  ++ uploading:'), lpath\n\n        __current_file_size = os.path.getsize(lpath)\n        if __current_file_size == 0:\n            print s % (1, 91, '  |-- file is empty, missing.')\n            return\n\n        self.__current_file_size = __current_file_size\n        upload_function = self._get_upload_function()\n\n        if self.upload_datas.has_key(lpath):\n            if __current_file_size != self.upload_datas[lpath]['size']:\n                self.upload_datas[lpath]['is_over'] = False\n                self.upload_datas[lpath]['size'] = __current_file_size\n            self.upload_datas[lpath]['upload_function'] = upload_function\n        else:\n            self.upload_datas[lpath] = {\n                'is_over': False,\n                'upload_function': upload_function,\n                'size': __current_file_size,\n                'remotepaths': set()\n            }\n\n        if self.toEncrypt:\n            self._init_cipherer(toencrypt=True)\n            self.upload_datas[lpath]['is_over'] = False\n            #self.upload_datas[lpath]['remotepaths'] = set()\n            self.upload_datas[lpath]['slice_md5s'] = []\n\n        if 'e' in args.type_:\n            if 'ec' in args.type_ and not 'np' in args.type_:\n                path = os.path.join(rpath, 'encrypted_' + os.path.basename(lpath))\n            else:\n                path = os.path.join(rpath, os.path.basename(lpath))\n            meta = self._meta([path])\n            if meta:\n                self.upload_datas[lpath]['is_over'] = True\n                self.upload_datas[lpath]['remotepaths'].update([rpath])\n                #self.save_datas(upload_datas_path, self.upload_datas)\n                print s % (1, 93, '  |-- file exists at pan.baidu.com, not upload\\n')\n                return\n            else:\n                self.upload_datas[lpath]['is_over'] = False\n                pass\n\n        if args.mode == 'o':\n            self.upload_datas[lpath]['is_over'] = False\n            self.upload_datas[lpath]['slice_md5s'] = []\n\n        while True:\n            if not self.upload_datas[lpath]['is_over']:\n                m = self.upload_datas[lpath]['upload_function']\n                if m == '_upload_file_slices':\n                    #time.sleep(2)\n                    print '  |-- upload_function:', s % (1, 97, '_upload_file_slices')\n                    pieces, slice = self._get_pieces_slice()\n                    f = open(lpath, 'rb')\n                    current_piece_point = len(self.upload_datas[lpath]['slice_md5s'])\n                    f.seek(current_piece_point * slice)\n                    start_time = time.time()\n                    print_process_bar(\n                        f.tell(), __current_file_size, 0, start_time, \\\n                        pre='     ', msg='%s/%s' % (str(current_piece_point), \\\n                                                    str(pieces))\n                    )\n                    for piece in xrange(current_piece_point, pieces):\n                        self.__slice_block = f.read(slice)\n                        if self.__slice_block:\n                            while True:\n                                result = self._upload_slice(piece=piece, slice=slice)\n                                if result == ENoError:\n                                    break\n                                else:\n                                    print s % (1, 91, '\\n  |-- slice_md5 does\\'n match, retry.')\n                                    break\n\n                            if result != ENoError: break\n\n                            self.upload_datas[lpath]['slice_md5s'].append(self.__slice_md5)\n                            self.save_datas(upload_datas_path, self.upload_datas)\n                            start_time = print_process_bar(\n                                f.tell(), __current_file_size, slice, start_time, \\\n                                pre='     ', msg='%s/%s' % (str(piece+1), \\\n                                                            str(pieces))\n                            )\n                    f.close()\n\n                    if result != ENoError:\n                        self.upload_datas[lpath]['slice_md5s'] = []\n                        #continue\n                        break\n\n                    result = self._combine_file(lpath, rpath)\n                    if result == ENoError:\n                        self.upload_datas[lpath]['is_over'] = True\n                        self.upload_datas[lpath]['remotepaths'].update([rpath])\n                        self.upload_datas[lpath]['slice_md5s'] = []\n                        self.save_datas(upload_datas_path, self.upload_datas)\n                        print s % (1, 92, '\\n  |-- success.\\n')\n                        break\n                    else:\n                        print s % (1, 91, '\\n  !! Error at _combine_file:'), result\n                        break\n                        #sys.exit(1)\n\n                elif m == '_upload_one_file':\n                    #time.sleep(2)\n                    result = self._upload_one_file(lpath, rpath)\n                    if result == ENoError:\n                        self.upload_datas[lpath]['is_over'] = True\n                        self.upload_datas[lpath]['remotepaths'].update([rpath])\n                        self.save_datas(upload_datas_path, self.upload_datas)\n                        print s % (1, 92, '\\n  |-- success.\\n')\n                        break\n                    else:\n                        print s % (1, 91, '\\n  !! Error at _upload_one_file:'), result\n                        break\n                        #sys.exit(1)\n\n                elif m == '_rapidupload_file':\n                    #time.sleep(2)\n                    result = self._rapidupload_file(lpath, rpath)\n                    if result == ENoError:\n                        self.upload_datas[lpath]['is_over'] = True\n                        self.upload_datas[lpath]['remotepaths'].update([rpath])\n                        self.save_datas(upload_datas_path, self.upload_datas)\n                        print s % (1, 92, '  |-- RapidUpload: Success.\\n')\n                        break\n                    else:\n                        if 'r' in args.type_:   # only rapidupload\n                            print s % (1, 91, '  |-- can\\'t be RapidUploaded\\n')\n                            break\n                        print s % (1, 93, '  |-- can\\'t be RapidUploaded, ' \\\n                            'now trying normal uploading.')\n                        upload_function = self._get_upload_function(rapidupload_is_fail=True)\n                        self.upload_datas[lpath]['upload_function'] = upload_function\n                        if upload_function == '_upload_file_slices':\n                            if not self.upload_datas[lpath].has_key('slice_md5s'):\n                                self.upload_datas[lpath]['slice_md5s'] = []\n\n                else:\n                    print s % (1, 91, '  !! Error: size of file is too big.')\n                    break\n\n            else:\n                if args.mode == 'c':\n                    if rpath in self.upload_datas[lpath]['remotepaths']:\n                        print s % (1, 92, '  |-- file was uploaded.\\n')\n                        break\n                    else:\n                        self.upload_datas[lpath]['is_over'] = False\n                elif args.mode == 'o':\n                    print s % (1, 93, '  |-- reupload.')\n                    self.upload_datas[lpath]['is_over'] = False\n\n    def _upload_dir(self, lpath, rpath):\n        base_dir = os.path.split(lpath)[0]\n        for parent, directories, files in os.walk(lpath):\n            for file in files:\n                localpath = os.path.join(parent, file)\n                t = localpath.replace(base_dir + '/', '')\n                t = os.path.split(t)[0]\n                remotepath = os.path.join(rpath, t)\n                self._upload_file(localpath, remotepath)\n            if not args.recursive: break\n\n    def _init_cipherer(self, toencrypt=False):\n        method = args.mode\n        if method not in CIPHERS:\n            method = 'aes-256-cfb'\n        if not args.passwd:\n            print s % (1, 91, '  !! missing Password.\\n')\n            sys.exit(1)\n\n        self._cipherer = encrypt.Encryptor(args.passwd, method)\n\n    def upload(self, localpaths, remotepath):\n        remotepath = make_server_path(self.cwd, remotepath)\n        rpath = remotepath if remotepath[0] == '/' else '/' + remotepath\n        self.upload_datas = {}\n        if os.path.exists(upload_datas_path):\n            f = open(upload_datas_path, 'rb')\n            upload_datas = pk.load(f)\n            if upload_datas:\n                self.upload_datas = upload_datas\n\n        # initiate Crypter\n        if 'ec' in args.type_:\n            self.toEncrypt = True\n        else:\n            self.toEncrypt = False\n\n        for localpath in localpaths:\n            lpath = get_abspath(localpath)\n\n            if not lpath:\n                print s % (1, 91, '  !! Error: localpath doesn\\'t exist')\n                print s % (1, 91, '  ==>'), localpath\n                continue\n\n            if os.path.isdir(lpath) and 'f' not in args.type_:\n                self._upload_dir(lpath, rpath)\n            elif os.path.isfile(lpath) and 'd' not in args.type_:\n                self._upload_file(lpath, rpath)\n            else:\n                #print s % (1, 91, '  !! Error: localpath ?'), localpath\n                pass\n\n        self.save_datas(upload_datas_path, self.upload_datas)\n\n    def save_datas(self, path, infos):\n        g = open(path, 'wb')\n        pk.dump(infos, g)\n        g.close()\n\n    ##################################################################\n    # for saving shares\n\n    def _share_transfer(self, surl, info):\n        meta = self._meta([info['remotepath'].encode('utf8')])\n        if not meta:\n            self._make_dir(info['remotepath'].encode('utf8'))\n\n        if not info['isdir']:\n            remote_file_path = '/'.join(\n                [info['remotepath'], os.path.split(info['path'])[-1]] )\n            meta = self._meta([remote_file_path])\n            if meta:\n                j = {'errno': 'file has exist'}\n                return j\n\n        data = ('fsidlist=' \\\n                + urllib.quote_plus('[%s]' % info['fs_id']) \\\n                + '&path=' \\\n                + urllib.quote_plus(info['remotepath'].encode('utf8'))\n            )\n\n        url = ('https://pan.baidu.com/share/transfer?'\n               'shareid={}&from={}&bdstoken={}&channel=chunlei'\n               '&clienttype=0&web=1&app_id=250528'.format(\n                   self.shareid,\n                   self.uk,\n                   self._get_bdstoken()))\n\n        theaders = {\n            'Cookie': '; '.join(['{}={}'.format(k, v) for k, v in ss.cookies.get_dict().items()]),\n            'Origin': 'https://pan.baidu.com',\n            'Accept-Encoding': 'gzip, deflate, br',\n            'Accept-Language': 'zh-CN,zh;q=0.8,en;q=0.6,zh-TW;q=0.4',\n            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36',\n            'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',\n            'Accept': '*/*',\n            'Referer': surl,\n            'X-Requested-With': 'XMLHttpRequest',\n            'Connection': 'keep-alive',\n        }\n        r = ss.post(url, data=data, headers=theaders)\n        j = r.json()\n\n        #if j['errno'] == 0:\n            #return ENoError\n        #else:\n            #return j\n\n        return j\n\n    def _get_share_list(self, info):\n        p = {\n            \"app_id\": 250528,\n            \"channel\": \"chunlei\",\n            \"clienttype\": 0,\n            \"web\": 1,\n            \"num\": 10000,\n            \"dir\": info['path'].encode('utf8'),\n            \"t\": int(time.time()*1000),\n            \"uk\": self.uk,\n            \"shareid\": self.shareid,\n            #\"desc\": 1,   ## reversely\n            \"order\": \"name\", ## sort by name, or size, time\n            \"_\": int(time.time()*1000),\n            \"bdstoken\": self._get_bdstoken()\n        }\n        url = 'http://pan.baidu.com/share/list'\n        r = ss.get(url, params=p)\n        j = r.json()\n        if j['errno'] != 0:\n            print s % (1, 91, '  !! Error at _get_share_list')\n            sys.exit(1)\n        rpath = '/'.join(\n            [info['remotepath'], os.path.split(info['path'])[-1]]\n        )\n        for x in xrange(len(j['list'])):\n            j['list'][x]['remotepath'] = rpath\n\n        return j['list']\n\n    def _get_share_infos(self, url, remotepath, infos):\n        r = ss.get(url)\n        ss.cookies.update(r.cookies.get_dict())\n        html = r.content\n\n        info = panbaiducom.get_web_fileinfo(html, url)\n        self.uk = info['uk']\n        self.shareid = info['shareid']\n        self.bdstoken = info['bdstoken']\n\n        j = info['file_list']['list']\n        isdirs = [x['isdir'] for x in j]\n        paths = [x['path'] for x in j]\n        fs_ids = [x['fs_id'] for x in j]\n        z = zip(fs_ids, isdirs, paths)\n        if not infos:\n            infos = [\n                {\n                    'fs_id': a,\n                    'isdir': b,\n                    'path': c,\n                    'remotepath': remotepath \\\n                        if remotepath[-1] != '/' else remotepath[:-1]\n                } for a, b, c in z\n            ]\n\n        return infos\n\n    def save_share(self, url, remotepath, infos=None):\n        remotepath = make_server_path(self.cwd, remotepath)\n        infos = self._get_share_infos(url, remotepath, infos)\n        if 'c' in args.type_:\n            save_share_datas = {}\n            if os.path.exists(save_share_path):\n                f = open(save_share_path, 'rb')\n                save_share_datas = pk.load(f)\n                if save_share_datas:\n                    infos = save_share_datas[url]\n\n        while infos:\n            info = infos.pop(0)\n            while True:\n                print s % (1, 97, '  ++ transfer:'), info['path']\n\n                result = self._share_transfer(url, info)\n                if result['errno'] == 0:\n                    break\n                elif result['errno'] == 12 or result['errno'] == -33:\n                    if info['isdir']:\n                        print s % (1, 93, '  |-- over transferring limit.')\n                        infos += self._get_share_list(info)\n                        break\n                    else:\n                        print s % (1, 91, '  !! Error: can\\'t transfer file'), result\n                        break\n                elif result['errno'] == 'file has exist':\n                        print s % (1, 93, '  |-- file has exist.')\n                        break\n                else:\n                    print s % (1, 91, '  !! Error at save_share, errno:'), result\n                    time.sleep(5)\n\n            if 'c' in args.type_:\n                save_share_datas[url] = infos\n                self.save_datas(save_share_path, save_share_datas)\n\n    @staticmethod\n    def _secret_or_not(url):\n        surl = url.split('?')[0].split('/1')[1].strip('/')\n\n        ss.headers['Referer'] = 'https://pan.baidu.com'\n        r = ss.get(url, headers=headers)\n\n        if r.status_code != 200 and r.status_code != 302:\n            ss.headers['Cookie'] = ';'.join(['{}={}'.format(k, v) for k, v in ss.cookies.get_dict().items()])\n            r = ss.get(url, headers=headers, cookies=r.cookies)\n\n        if 'init' in r.url:\n            if not args.secret:\n                secret = raw_input(s % (2, 92, \"  请输入提取密码: \"))\n            else:\n                secret = args.secret\n\n            data = 'pwd=%s&vcode=&vcode_str=' % secret\n            url = (\n                'https://pan.baidu.com/share/verify?'\n                + 'surl=' + surl\n                + '&t=' + str(int(time.time()*1000))\n                + '&channel=chunlei'\n                + '&web=1'\n                + '&app_id=250528'\n                + '&bdstoken=null'\n                + '&clienttype=0'\n            )\n            theaders = {\n                'Accept-Encoding': 'gzip, deflate',\n                'Accept-Language': 'zh-CN,zh;q=0.8,en;q=0.6,zh-TW;q=0.4',\n                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.71 Safari/537.36',\n                'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',\n                'Accept': '*/*',\n                'X-Requested-With': 'XMLHttpRequest',\n                'Connection': 'keep-alive',\n                'Sec-Fetch-Mode': 'cors',\n                'Referer': 'https://pan.baidu.com/share/init?surl=' + surl\n            }\n            r = ss.post(url, data=data, headers=theaders)\n            if r.json()['errno']:\n                print s % (2, 91, \"  !! 提取密码错误, %s\\n\" % r.text)\n                sys.exit(1)\n            ss.cookies.update(r.cookies.get_dict())\n\n    #######################################################################\n    # for saveing inbox shares\n\n    def _share_inbox_transfer(self, info, burl):\n        meta = self._meta([info['remotepath'].encode('utf8')])\n        if not meta:\n            self._make_dir(info['remotepath'].encode('utf8'))\n\n        p = \"channel=chunlei&\" \\\n            + \"clienttype=0&\" \\\n            + \"web=1&\" \\\n            + \"path=%s&\" % urllib.quote_plus(\n                info['remotepath'].encode('utf8')\n            ) \\\n            + \"object_array=%s&\" % urllib.quote_plus(\n                '[\"%s\"]' % info['object_id'].encode('utf8')\n            ) \\\n            + \"fsid_array=%s&\" % urllib.quote_plus('[%s]' % info['fs_id']) \\\n            + \"session_id=%s&\" % self.session_id \\\n            + \"founder_uk=%s&\" % self.founder_uk \\\n            + \"bdstoken=%s\" % self._get_bdstoken()\n\n        url = 'http://pan.baidu.com/inbox/object/transfer?' + p\n        r = ss.get(url)\n        j = r.json()\n        if j['errno'] == 0:\n            return ENoError\n        else:\n            return j['errno']\n\n    def _get_share_inbox_list(self, info):\n        p = {\n            \"channel\": \"chunlei\",\n            \"clienttype\": 0,\n            \"web\": 1,\n            \"object_id\": info['object_id'],\n            \"object_status\": info['object_status'],\n            \"fs_id\": info['fs_id'],\n            \"path\": info['path'],\n            \"server_filename\": info['server_filename'],\n            \"size\": info['size'],\n            \"server_mtime\": info['server_mtime'],\n            \"server_ctime\": info['server_ctime'],\n            \"local_mtime\": info['local_mtime'],\n            \"local_ctime\": info['local_ctime'],\n            \"isdir\": info['isdir'],\n            \"category\": info['category'],\n            \"founder_uk\": self.founder_uk,\n            \"session_id\": self.session_id,\n            \"bdstoken\": self._get_bdstoken(),\n        }\n        if info.get('ori_path'): p.update({\"ori_path\": info['ori_path']})\n        if info.get('dir_ref'): p.update({\"dir_ref\": info['dir_ref']})\n        if info.get('md5'): p.update({\"md5\": \"\"})\n        if info.get('create_time'): p.update({\"create_time\": \"1402299935\"})\n        if info.get('update_time'): p.update({\"update_time\": \"1402299935\"})\n        if info.get('last_time'): p.update({\"last_time\": \"\"})\n\n        url = 'http://pan.baidu.com/inbox/object/unpanfileinfo'\n        r = ss.get(url, params=p)\n        j = r.json()\n        if j['errno'] != 0:\n            print s % (1, 91, '  !! Error at _get_share_inbox_list')\n            sys.exit(1)\n        rpath = '/'.join(\n            [info['remotepath'], os.path.split(info['path'])[-1]]\n        )\n        for x in xrange(len(j['list'])):\n            j['list'][x]['remotepath'] = rpath\n        return j['list']\n\n    def _get_share_inbox_infos(self, url, remotepath, infos):\n        r = ss.get(url)\n        html = r.content\n\n        self.founder_uk = re.search(r'FileUtils.founder_uk=(\\d+)', html).group(1)\n        self.session_id = re.search(r'FileUtils.session_id=\"(.+?)\"', html).group(1)\n        self.bdstoken = re.search(r'bdstoken=\"(.+?)\"', html).group(1)\n\n        p = {\n            \"session_id\": self.session_id,\n            \"founder_uk\": self.founder_uk,\n            \"channel\": \"chunlei\",\n            \"clienttype\": 0,\n            \"web\": 1,\n            \"bdstoken\": self._get_bdstoken(),\n        }\n        url = 'http://pan.baidu.com/inbox/object/unpanfileinfo'\n        r = ss.get(url, params=p)\n        j = r.json()\n        if j['errno'] == 0:\n            for x in xrange(len(j['list'])):\n                j['list'][x]['remotepath'] = remotepath\n            return j['list']\n        else:\n            print s % (1, 91, '  !! Error at _get_share_inbox_infos')\n            sys.exit()\n\n    def save_inbox_share(self, url, remotepath, infos=None):\n        ss.headers['Referer'] = 'http://pan.baidu.com'\n        remotepath = make_server_path(self.cwd, remotepath)\n        remotepath = remotepath if remotepath[-1] != '/' else remotepath[:-1]\n        infos = self._get_share_inbox_infos(url, remotepath, infos)\n        for info in infos:\n            print s % (1, 97, '  ++ transfer:'), info['path']\n            result = self._share_inbox_transfer(info, url)\n            if result == ENoError:\n                pass\n            elif result == 12:\n                print s % (1, 91, '  |-- file had existed.')\n                sys.exit()\n            elif result == 1 or result == -33 or result == -10:\n                if result == -10:\n                    print s % (1, 91, '  |-- _share_inbox_transfer, errno:') \\\n                        + ' -10, ' + 'category of pan is unsatisfied.'\n                elif result == -33:\n                    print s % (1, 91, '  |-- _share_inbox_transfer, errno:') \\\n                        + ' -33, ' + 'over transferring limit.'\n                if info['isdir']:\n                    infos += self._get_share_inbox_list(info)\n                #else:\n                    #print s % (1, 91, '  |-- Error: can\\'t transfer file')\n            else:\n                print s % (1, 91, '  |-- _share_inbox_transfer, errno:'), result\n                sys.exit(1)\n\n    #######################################################################\n    # for finding files\n\n    def _search(self, keyword, directory, page=1, num=1000):\n\n        p = {\n            'recursion': '',\n            'key': keyword,\n            'dir': directory,\n        }\n\n        if args.recursive: p['recursion'] = 1\n        url = 'http://pan.baidu.com/api/search'\n        r = self._request('GET', url, '_search', params=p)\n        j = r.json()\n        if j['errno'] == 0:\n            return j['list']\n        else:\n            print s % (1, 91, '  !! Error at _search'), j\n            sys.exit(1)\n\n    def _highlight_string_zones(self, string, highlights, highlight_color, \\\n                                background_color=None):\n        # string is unicoded\n        target = ['.' for i in xrange(len(string))]\n        for hl in highlights:\n            re_tp = hl['text'] if hl['is_regex'] else re.escape(hl['text'])\n            for m in re.finditer(re_tp, string, re.I):\n                for i in xrange(m.start(), m.end()):\n                    target[i] = ' '\n\n        highlight_zones = []\n        for m in re.finditer('\\s+', ''.join(target)):\n            highlight_zones.append(m.start())\n            highlight_zones.append(m.end())\n\n        string_zones = []\n        for i in xrange(len(highlight_zones)):\n            if i == 0:\n                string_zones.append(string[:highlight_zones[i]])\n                string_zones.append(\n                    string[highlight_zones[i]:highlight_zones[i+1]]\n                )\n            else:\n                try:\n                    string_zones.append(\n                        string[highlight_zones[i]:highlight_zones[i+1]]\n                    )\n                except:\n                    string_zones.append(string[highlight_zones[i]:])\n\n        if not string_zones: string_zones = [string]\n\n        t = ''\n        for i in xrange(0, len(string_zones), 2):\n            if background_color:\n                try:\n                    t += s % (\n                        2, background_color, string_zones[i].encode('utf8')\n                    ) \\\n                    + s % (\n                        2, highlight_color, string_zones[i+1].encode('utf8')\n                    )\n                except:\n                    t += s % (\n                        2, background_color, string_zones[i].encode('utf8')\n                    )\n            else:\n                try:\n                    t += string_zones[i].encode('utf8') \\\n                         + s % (\n                             2, highlight_color, string_zones[i+1].encode('utf8')\n                         )\n                except:\n                    t += string_zones[i].encode('utf8')\n\n        return t\n\n    def _find_display(self, info):\n        if 'f' in args.type_:\n            if info['isdir']:\n                return\n        elif 'd' in args.type_:\n            if not info['isdir']:\n                return\n\n        path = info['path']\n        if args.ls_color == 'on':\n            isdir = s % (1, 93, 'd') if info['isdir'] else s % (1, 97, '-')\n            size = s % (1, 91, sizeof_fmt(info['size']).rjust(8))\n            base_dir, filename = os.path.split(path)\n            base_dir = s % (2, 95, base_dir.encode('utf8')) \\\n                if base_dir != '/' else '/'\n\n            if info['isdir']:\n                filename = self._highlight_string_zones(\n                    filename, self.highlights, 93, background_color=94\n                )\n            else:\n                filename = self._highlight_string_zones(\n                    filename, self.highlights, 93\n                )\n\n            if args.view:\n                path = os.path.join(base_dir, filename)\n            else:\n                path = filename\n\n        elif args.ls_color == 'off':\n            isdir = 'd' if info['isdir'] else '-'\n            size = sizeof_fmt(info['size']).rjust(8)\n            if args.view:\n                path = path.encode('utf8')\n            else:\n                path = os.path.basename(path).encode('utf8')\n\n        if args.view > 1 and info.get('md5'):\n            smd5 = info['md5'].encode('utf8')\n            template = '%s %s %s %s %s' % (\n                isdir, size, info['size'], smd5, path\n            )\n        else:\n            template = '%s %s %s' % (isdir, size, path)\n\n        print template\n\n    def find(self, keywords, **arguments):\n        def do():\n            infos = []\n            for keyword in keywords:\n                infos += self._search(keyword, arguments.get('directory'))\n                kw = keyword.decode('utf8', 'ignore')\n                self.highlights.append({'text': kw, 'is_regex': 0})\n            infos = {i['fs_id']: i for i in infos}.values()\n            infos = self._sift(infos, **arguments)\n\n            if not infos: return\n            if not arguments.get('pipe'):\n                for info in infos:\n                    self._find_display(info)\n\n            # pipe to download, play, rnre, remove, move\n            def warn(comd, display=True):\n                if display:\n                    for info in infos:\n                        self._find_display(info)\n                print s % (1, 93, '  find above ↑')\n                ipt = raw_input(\n                    s % (\n                        1, 91, '  sure you want to %s all the files [y/n]: ' % comd\n                    )\n                ).lower() if not args.yes else 'y'\n                if ipt != 'y':\n                    print s % (1, 92, '  ++ aborted.')\n                    return False\n                else:\n                    return True\n\n            pipe = arguments.get('pipe')\n            if pipe:\n                comd = pipe[0]\n                if comd == 'd' or comd == 'download':\n                    if not warn('download', display=True): return\n                    paths = [i['path'].encode('utf8') for i in infos]\n                    self.download(paths)\n                elif comd == 'p' or comd == 'play':\n                    if not warn('play', display=True): return\n                    paths = [i['path'].encode('utf8') for i in infos]\n                    self._download_do = self._play_do\n                    args.play = True\n                    self.download(paths)\n                elif comd == 'rnr' or comd == 'rnre':\n                    if len(pipe) < 3:\n                        print s % (1, 91, '  !! rnre foo bar')\n                        sys.exit(1)\n\n                    foo = pipe[1]\n                    bar = pipe[2]\n                    self._rnre_do(foo, bar, infos)\n                elif comd == 'rm':\n                    if not warn('remove', display=True): return\n                    paths = [i['path'].encode('utf8') for i in infos]\n                    self.remove(paths)\n                elif comd == 'mv':\n                    if len(pipe) < 2:\n                        print s % (1, 91, '  !! mv /path/to')\n                        sys.exit(1)\n\n                    if not warn('move', display=True): return\n                    paths = [i['path'].encode('utf8') for i in infos]\n                    remotepath = pipe[1]\n                    self.move(paths, remotepath, check=False)\n                else:\n                    print s % (1, 91, '  !! command is supported by download, play, rnre, rm, mv')\n\n        if not args.view: args.view = 1\n        if 'all' in args.type_:\n            for user in self.accounts:\n                cookie = self.accounts[user]['cookies']\n                ss.cookies.clear()\n                ss.cookies.update(cookie)\n\n                if args.ls_color:\n                    print '\\n' + s % (1, 92, user) + ':' \\\n                        if self.accounts[user]['on'] \\\n                        else '\\n' + s % (1, 97, user) + ':'\n                else:\n                    print '\\n' + user + ':'\n\n                do()\n                #self.save_cookies(user, on=self.accounts[user]['on'])\n        else:\n            do()\n        sys.exit()\n\n    ##############################################################\n    # for ls\n\n    def _ls_display(self, infos, dir_=None):\n        if dir_:\n            print (dir_ + ':').encode('utf8')\n            for info in infos:\n                self._find_display(info)\n            print ''\n        else:\n            self._find_display(infos)\n\n    def _ls_directory(self, order, desc, path):\n        directorys = [path.decode('utf8', 'ignore')]\n        y = 1\n        sum_size = 0\n        for dir_ in directorys:\n            infos = self._get_file_list(\n                order, desc, dir_.encode('utf8'), 10000\n            )['list']\n            tinfos = infos\n            if args.heads or args.tails or args.includes or args.excludes \\\n                    or args.type_:\n                tinfos = self._sift(infos)\n            if 'du' not in args.type_:\n                self._ls_display(tinfos, dir_)\n            else:\n                sum_size += sum([i['size'] for i in tinfos])\n            if args.recursive:\n                subdirs = [i['path'] for i in infos if i['isdir']]\n                directorys[y:y] = subdirs\n                y += 1\n\n        if 'du' in args.type_:\n            print 'd', s % ( 1, 91, sizeof_fmt(sum_size)), \\\n                sum_size, directorys[0]\n\n    def ls(self, order, desc, paths):\n        if not paths: paths = [self.cwd]\n        for path in paths:\n            path = make_server_path(self.cwd, path)\n            meta = self._meta([path])\n            if meta:\n                if meta['info'][0]['isdir']:\n                    self._ls_directory(order, desc, path)\n                else:\n                    if 'du' in args.type_: args.view = True\n                    self._ls_display(meta['info'][0])\n            else:\n                print s % (1, 91, '  !! path is not existed.\\n'), \\\n                    ' --------------\\n ', path\n\n    ###############################################################\n    # for file operate\n\n    def _exist(self, list_):\n        meta = self._meta(list_)\n        if not meta:\n            print s % (1, 91, '  !! Error at _exist, some paths are not existed.'), \\\n                list_ if len(list_) <= 10 else ''\n            sys.exit(1)\n\n    def _filemanager(self, opera, data):\n        p = {\n            \"channel\": \"chunlei\",\n            \"clienttype\": 0,\n            \"web\": 1,\n            \"async\": \"2\",\n            \"opera\": opera,\n            \"bdstoken\": self._get_bdstoken(),\n        }\n        url = 'http://pan.baidu.com/api/filemanager'\n        r = ss.post(url, params=p, data=data)\n        j = r.json()\n        if j['errno'] == 0:\n            print s % (1, 92, '  ++ success.')\n        elif j['errno'] == 12:\n            print s % (1, 91, '  !! Error at filemanager:'), \"部分文件已存在于目标文件夹中\"\n        else:\n            print s % (1, 91, '  !! Error at filemanager'), j\n\n    def move(self, paths, remotepath, check=True):\n        paths = [ make_server_path(self.cwd, path) for path in paths ]\n        remotepath = make_server_path(self.cwd, remotepath)\n        if check: self._exist(paths)\n\n        meta = self._meta([remotepath])\n        if not meta:\n            self._make_dir(remotepath)\n        elif not meta['info'][0]['isdir']:\n            print s % (1, 91, '  !! Error at move:'), remotepath, \\\n                s % (1, 91, 'is a file.')\n            sys.exit(1)\n\n        t = [\n                {\n                    'path': i,\n                    'dest': remotepath,\n                    'newname': os.path.basename(i)\n                } for i in paths\n        ]\n        data = 'filelist=' + urllib.quote_plus(json.dumps(t))\n        self._filemanager('move', data)\n\n    def copy(self, paths, remotepath):\n        paths = [ make_server_path(self.cwd, path) for path in paths ]\n        remotepath = make_server_path(self.cwd, remotepath)\n        self._exist(paths)\n\n        t = None\n        if len(paths) != 1:\n            meta = self._meta([remotepath])\n            if not meta:\n                self._make_dir(remotepath)\n            elif not meta['info'][0]['isdir']:\n                print s % (1, 91, '  !! Error at move:'), remotepath, \\\n                    s % (1, 91, 'is a file.')\n                sys.exit(1)\n\n            t = [{\n                    'path': i,\n                    'dest': remotepath,\n                    'newname': os.path.basename(i)\n            } for i in paths]\n        else:\n            meta = self._meta([remotepath])\n            if not meta:\n                base_dir = os.path.split(remotepath)[0]\n                meta = self._meta([base_dir])\n                if not meta:\n                    self._make_dir(base_dir)\n                elif not meta['info'][0]['isdir']:\n                    print s % (1, 91, '  !! Error at move:'), remotepath, \\\n                        s % (1, 91, 'is a file.')\n                    sys.exit(1)\n                t = [{\n                        'path': i,\n                        'dest':base_dir,\n                        'newname': os.path.basename(remotepath)\n                } for i in paths]\n            elif not meta['info'][0]['isdir']:\n                print s % (1, 91, '  !! Error at move:'), remotepath, \\\n                    s % (1, 91, 'is a file.')\n                sys.exit(1)\n            else:\n                t = [{\n                        'path': i,\n                        'dest': remotepath,\n                        'newname': os.path.basename(i)\n                } for i in paths]\n\n        data = 'filelist=' + urllib.quote_plus(json.dumps(t))\n        self._filemanager('copy', data)\n\n    def remove(self, paths):\n        paths = [ make_server_path(self.cwd, path) for path in paths ]\n        self._exist(paths)\n\n        data = 'filelist=' + urllib.quote_plus(json.dumps(paths))\n        self._filemanager('delete', data)\n\n    def rename(self, path, remotepath):\n        path = make_server_path(self.cwd, path)\n        remotepath = make_server_path(self.cwd, remotepath)\n        self._exist([path])\n\n        meta = self._meta([remotepath])\n        if meta:\n            print s % (1, 91, '  !! Error at rename:'), remotepath, \\\n                s % (1, 91, 'is existed.')\n            sys.exit(1)\n\n        base_dir, newname = os.path.split(remotepath)\n        meta = self._meta([base_dir])\n        if not meta:\n            self._make_dir(base_dir)\n        elif not meta['info'][0]['isdir']:\n            print s % (1, 91, '  !! Error at rename:'), base_dir, \\\n                s % (1, 91, 'is a file.')\n            sys.exit(1)\n\n        t = [{\n                'path': path,\n                'dest': base_dir,\n                'newname': newname\n        }]\n        data = 'filelist=' + urllib.quote_plus(json.dumps(t))\n        self._filemanager('move', data)\n\n    ##############################################################\n    # for file operate with regex\n\n    def _rnre_do(self, foo, bar, infos):\n        self.highlights.append(\n            {'text': foo.decode('utf8', 'ignore'), 'is_regex': 1}\n        )\n        ls, lshl = [], []\n        for info in infos:\n            # no change directory if recursion\n            if args.recursive and info['isdir']: continue\n\n            base_dir, old_filename = os.path.split(info['path'])\n            if 'bd64' in args.type_:\n                told_filename, ext = os.path.splitext(old_filename)\n                if not told_filename.endswith('.base64'): continue\n                codestr = told_filename[:-7]\n                try:\n                    decode_old_filename = base64.urlsafe_b64decode(\n                        codestr.encode('utf8')\n                    ).decode('utf8', 'ignore') + ext\n                except Exception:\n                    decode_old_filename = old_filename\n\n                new_filename = decode_old_filename\n\n            else:\n                new_filename = re.sub(\n                    foo.decode('utf8', 'ignore'), \\\n                    bar.decode('utf8', 'ignore'), \\\n                    old_filename\n                )\n\n            if old_filename == new_filename: continue\n            old_path = info['path']\n            new_path = os.path.join(base_dir, new_filename).encode('utf8')\n\n            ls.append((old_path.encode('utf8'), new_path))\n\n            # hightlight\n            if info['isdir']:\n                old_filename_highlight = self._highlight_string_zones(\n                    old_filename,\n                    self.highlights,\n                    93,\n                    background_color=94\n                )\n            else:\n                old_filename_highlight = self._highlight_string_zones(\n                    old_filename,\n                    self.highlights,\n                    93\n                )\n            old_path_highlight = os.path.join(\n                base_dir.encode('utf8'), old_filename_highlight\n            )\n            lshl.append((old_path_highlight, new_path))\n\n        if not ls: return\n\n        print '\\n'.join([' '.join([o, s % (1, 92, '==>'), n]) for o, n in lshl])\n        print s % (1, 93, '  matched above ↑')\n\n        ipt = raw_input(s % (1, 91, '  sure you want to rename all the files [y/N]: ')).lower() \\\n            if not args.yes else 'y'\n        if ipt == 'y':\n            for o, n in ls:\n                print s % (1, 97, '  ++ rename:'), ' '.join([o, s % (1, 92, ' ==> '), n])\n                self.rename(o, n)\n        else:\n            print s % (1, 92, '  ++ aborted.')\n\n    def _rmcre_do(self, type, infos, todir=None):\n        if 'd' in args.type_:\n            infos = [i for i in infos if i['isdir']]\n        if 'f' in args.type_:\n            infos = [i for i in infos if not i['isdir']]\n\n        if not infos: return\n\n        pathshl = []\n        for i in infos:\n            base_dir, filename = os.path.split(i['path'])\n            if i['isdir']:\n                filename_highlight = self._highlight_string_zones(\n                    filename,\n                    self.highlights,\n                    93,\n                    background_color=94\n                )\n            else:\n                filename_highlight = self._highlight_string_zones(\n                    filename,\n                    self.highlights, 93\n                )\n            path = os.path.join(base_dir.encode('utf8'), filename_highlight)\n            pathshl.append(path)\n        print '\\n'.join(pathshl)\n        print s % (1, 93, '  matched above ↑')\n\n        ipt = raw_input(s % (1, 91, '  sure you want to %s all the files [y/N]: ' % type)).lower() \\\n            if not args.yes else 'y'\n        if ipt == 'y':\n            paths = [i['path'].encode('utf8') for i in infos]\n            if type == 'remove':\n                self.remove(paths)\n            if type == 'move':\n                self.move(paths, todir, check=False)\n            elif type == 'copy':\n                self.copy(paths, todir)\n        else:\n            print s % (1, 92, '  ++ aborted.')\n\n    def filemanager_re(self, type, dirs, todir=None, foo=None, bar=None):\n        tinfos = []\n        for path in dirs:\n            path = make_server_path(self.cwd, path)\n            meta = self._meta([path])\n            if meta:\n                if meta['info'][0]['isdir']:\n                    directorys = [path.decode('utf8', 'ignore')]\n                    y = 1\n                    for dir_ in directorys:\n                        infos = self._get_file_list(\n                            'name', None, dir_.encode('utf8'), 10000\n                        )['list']\n                        tinfos += infos\n                        if args.recursive:\n                            subdirs = [i['path'] for i in infos if i['isdir']]\n                            directorys[y:y] = subdirs\n                            y += 1\n                else:\n                    print s % (1, 91, '  !! path is a file.\\n'), \\\n                        ' --------------\\n ', path\n            else:\n                print s % (1, 91, '  !! path is not existed.\\n'), \\\n                    ' --------------\\n ', path\n\n        tinfos = self._sift(tinfos)\n        if tinfos:\n            if type == 'rename':\n                self._rnre_do(foo, bar, tinfos)\n            else:\n                todir = make_server_path(self.cwd, todir)\n                self._rmcre_do(type, tinfos, todir=todir)\n\n    ##############################################################\n    # for add_task\n\n    def _get_torrent_info(self, path):\n        p = {\n            \"bdstoken\": self._get_bdstoken(),\n            \"channel\": \"chunlei\",\n            \"clienttype\": 0,\n            \"web\": 1,\n            \"app_id\": 250528,\n            \"method\": \"query_sinfo\",\n            \"source_path\": path,\n            \"type\": 2,\n            \"t\": int(time.time()*1000),\n        }\n\n        url = 'http://pan.baidu.com/rest/2.0/services/cloud_dl'\n        r = ss.get(url, params=p)\n        j = r.json()\n        if j.get('error_code'):\n            print s % (1, 91, '  !! Error at _get_torrent_info:'), j['error_msg']\n            return None, None\n        else:\n            return j['torrent_info']['file_info'], j['torrent_info']['sha1']\n\n    def _get_magnet_info(self, url):\n        p = {\n            \"bdstoken\": self._get_bdstoken(),\n            \"channel\": \"chunlei\",\n            \"clienttype\": 0,\n            \"web\": 1,\n            \"app_id\": 250528,\n        }\n        data = {\n            \"method\": \"query_magnetinfo\",\n            \"app_id\": 250528,\n            \"source_url\": url,\n            \"save_path\": \"/\",\n            \"type\": 4,\n        }\n        url = 'http://pan.baidu.com/rest/2.0/services/cloud_dl'\n        r = ss.post(url, params=p, data=data)\n        j = r.json()\n        if j.get('error_code'):\n            print s % (1, 91, '  !! Error at _get_magnet_info:'), j['error_msg']\n            return None, None\n        else:\n            return j['magnet_info'], ''\n\n    def _get_selected_idx(self, infos):\n        types = args.type_\n        if not args.type_: return []\n        #if 'a' in types: return [str(i+1) for i in xrange(len(infos))]\n        if 'a' in types: return []\n\n        idx = []\n        if 'm' in types:\n            for i in xrange(len(infos)):\n                if os.path.splitext(infos[i]['file_name'])[-1].lower() in mediatype:\n                    idx.append(i+1)\n        if 'i' in types:\n            for i in xrange(len(infos)):\n                if os.path.splitext(infos[i]['file_name'])[-1].lower() in imagetype:\n                    idx.append(i+1)\n        if 'd' in types:\n            for i in xrange(len(infos)):\n                if os.path.splitext(infos[i]['file_name'])[-1].lower() in doctype:\n                    idx.append(i+1)\n        if 'p' in types:\n            for i in xrange(len(infos)):\n                if os.path.splitext(infos[i]['file_name'])[-1].lower() in archivetype:\n                    idx.append(i+1)\n        idx = list(set(idx))\n        idx.sort()\n        idx = [str(i) for i in idx]\n        if not idx: return None\n        return idx\n\n    def _add_bt(self, url, remotepath):\n        if url.startswith('magnet:'):\n            bt_info, ssh1 = self._get_magnet_info(url)\n            if not bt_info:\n                return\n\n        if url.startswith('/'):\n            bt_info, ssh1 = self._get_torrent_info(url)\n            if not bt_info:\n                return\n\n        selected_idx = self._get_selected_idx(bt_info)\n        if selected_idx == None:\n            print s % (1, 93, '  !! _get_selected_idx: match nothing.'), url\n            return\n\n        p = {\n            \"bdstoken\": self._get_bdstoken(),\n            \"channel\": \"chunlei\",\n            \"clienttype\": 0,\n            \"web\": 1,\n            \"app_id\": 250528,\n        }\n        data = {\n            \"method\": \"add_task\",\n            \"app_id\": 250528,\n            \"file_sha1\": ssh1,\n            \"save_path\": remotepath,\n            \"selected_idx\": \",\".join(selected_idx),\n            \"task_from\": 1,\n            \"t\": str(int(time.time())*1000),\n        }\n        if url.startswith('magnet:'):\n            data['source_url'] = url\n            data['type'] = 4\n        elif url.startswith('/'):\n            data['source_path'] = url\n            data['type'] = 2\n\n        apiurl = 'http://pan.baidu.com/rest/2.0/services/cloud_dl'\n        while True:\n            r = ss.post(apiurl, params=p, data=data)\n            j = r.json()\n            if j.get('error_code') == -19:\n                if data.get('vcode'):\n                    print s % (2, 91, '  × 错误验证码')\n                vcode = j['vcode']\n                input_code = panbaiducom_HOME.save_img(j['img'], 'jpg')\n                data.update({'input': input_code, 'vcode': vcode})\n            elif j.get('error_code') != -19 and j.get('error_code'):\n                print s % (1, 91, '  !! Error at _add_bt:'), j['error_msg']\n                return\n            else:\n                print ''\n                self.job([str(j['task_id'])])\n                if args.view:\n                    for i in selected_idx:\n                        size = sizeof_fmt(int(bt_info[int(i) - 1]['size'])).rjust(7)\n                        filepath = os.path.join(\n                            remotepath, bt_info[int(i) - 1]['file_name']\n                        )\n                        print s % (1, 91, size), filepath\n                return\n\n    def _add_task(self, url, remotepath):\n        p = {\n            \"bdstoken\": self._get_bdstoken(),\n            \"channel\": \"chunlei\",\n            \"clienttype\": 0,\n            \"web\": 1,\n            \"app_id\": 250528,\n        }\n        data = {\n            \"method\": \"add_task\",\n            \"app_id\": 250528,\n            \"save_path\": remotepath,\n            \"source_url\": url,\n            \"type\": 3,\n        }\n        apiurl = 'http://pan.baidu.com/rest/2.0/services/cloud_dl'\n        while True:\n            r = ss.post(apiurl, params=p, data=data)\n            j = r.json()\n            if j.get('error_code') == -19:\n                if data.get('vcode'):\n                    print s % (2, 91, '  × 错误验证码')\n                vcode = j['vcode']\n                input_code = panbaiducom_HOME.save_img(j['img'], 'jpg')\n                data.update({'input': input_code, 'vcode': vcode})\n            elif j.get('error_code'):\n                print s % (1, 91, '  !! Error at _add_task:'), j['error_msg']\n                return\n            else:\n                print ''\n                self.job([str(j['task_id'])])\n                return\n\n    def add_tasks(self, urls, remotepath):\n        remotepath = make_server_path(self.cwd, remotepath) + '/'\n        for url in urls:\n            if url.startswith('magnet:') or url.startswith('/'):\n                if url.startswith('/'):\n                    meta = self._meta([url])\n                    if not meta:\n                        print s % (1, 91, '  !! file is not existed.\\n'), \\\n                            ' --------------\\n ', url\n                        continue\n                    elif meta['info'][0]['isdir']:\n                        print s % (1, 91, '  !! file is a directory.\\n'), \\\n                            ' --------------\\n ', url\n                        continue\n                    remotepath = os.path.split(url)[0]\n                self._add_bt(url, remotepath)\n            elif url.startswith('http'):\n                self._add_task(url, remotepath)\n            elif url.startswith('ftp:'):\n                self._add_task(url, remotepath)\n            elif url.startswith('ed2k:'):\n                self._add_task(url, remotepath)\n            else:\n                print s % (1, 91, '  !! url is wrong:'), url\n\n    ############################################################\n    # for job, jobclear, jobdump, jobclearall\n\n    jobstatus = {\n        \"0\": \"下载成功\",\n        \"1\": \"下载进行中\",\n        \"2\": \"系统错误\",\n        \"3\": \"资源不存在\",\n        \"4\": \"下载超时\",\n        \"5\": \"资源存在但下载失败\",\n        \"6\": \"存储空间不足\",\n        \"7\": \"目标地址数据已存在\",\n        \"8\": \"任务取消.\",\n    }\n\n    def _task_display(self, infos):\n        cross_line = '—' * int(os.popen('tput cols').read())\n        template = '%s %s\\n' \\\n                   '%s %s\\n' \\\n                   '%s %s\\n' \\\n                   '%s %s\\n' \\\n                   '%s %s\\n' \\\n                   '%s %s\\n' \\\n                   '%s\\n' \\\n                   % (s % (2, 97, '    id:'), s % (1, 97, \"%s\"), \\\n                      s % (1, 97, 'status:'), s % (1, \"%s\", \"%s\"), \\\n                      s % (1, 97, '  done:'), s % (2, 93, \"%s\"), \\\n                      s % (2, 97, '  name:'), \"%s\", \\\n                      s % (2, 97, '  path:'), \"%s\", \\\n                      s % (2, 97, 'source:'), \"%s\", cross_line)\n\n        for i in infos:\n            if i['result'] == 0:\n                status_color = 92 if i['status'] == '0' else 91\n                print template % (\n                        i['id'].encode('utf8'),\n                        status_color,\n                        self.jobstatus.get(i['status'].encode('utf8'), '未知'),\n                        i['done'],\n                        i['name'].encode('utf8'),\n                        i['path'].encode('utf8'),\n                        i['source'].encode('utf8'),\n                    )\n            else:\n                print '%s %s\\n' \\\n                      '%s %s\\n' \\\n                      '------------------------------\\n' \\\n                      % (\n                          s % (2, 97, '     id:'),\n                          s % (1, 97, i['id'].encode('utf8', 'ignore')),\n                          #s % (2, 91, '  Error:'), s % (2, 97, '要查询的task_id不存在'))\n                          s % (2, 91, '  Error, info:'),\n                          i\n                      )\n\n    def _query_task(self, jobids):\n        p = {\n            \"bdstoken\": self._get_bdstoken(),\n            \"web\": 1,\n            \"app_id\": 250528,\n            \"clienttype\": 0,\n            \"channel\": \"chunlei\",\n            \"method\": \"query_task\",\n            \"task_ids\": \",\".join(jobids),\n            \"op_type\": 1,\n            \"t\": str(int(time.time()*1000)),\n        }\n\n        url = 'http://pan.baidu.com/rest/2.0/services/cloud_dl'\n        r = ss.get(url, params=p)\n        j = r.json()\n        if j.get('errno'):\n            print s % (1, 91, '  !! Error at _query_task:'), j\n            sys.exit(1)\n\n        infos = []\n        for i in jobids:\n            info = {}\n            info['id'] = i\n            if j['task_info'][i]['result'] == 0:\n                info['source'] = j['task_info'][i]['source_url']\n                info['name'] = j['task_info'][i]['task_name']\n                info['path'] = j['task_info'][i]['save_path']\n                info['status'] = j['task_info'][i]['status']\n                info['result'] = j['task_info'][i]['result']\n\n                file_size = int(j['task_info'][i]['file_size'])\n                finished_size = int(j['task_info'][i]['finished_size'])\n                done = finished_size - file_size\n                done = '100.0%   ' \\\n                    + '%s/%s' % (\n                    sizeof_fmt(finished_size),\n                    sizeof_fmt(file_size)) \\\n                        if done == 0 and finished_size \\\n                        else '%.2f' % (finished_size / (file_size + 0.001) * 100) \\\n                            + '%   ' \\\n                            + '%s/%s' % (\n                                sizeof_fmt(finished_size), sizeof_fmt(file_size)\n                            )\n                info['done'] = done\n\n                infos.append(info)\n            else:\n                info['result'] = j['task_info'][i]['result']\n                infos.append(info)\n\n        return infos\n\n    def _list_task(self):\n        p = {\n            \"bdstoken\": self._get_bdstoken(),\n            \"web\": 1,\n            \"app_id\": 250528,\n            \"clienttype\": 0,\n            \"channel\": \"chunlei\",\n            \"method\": \"list_task\",\n            \"need_task_info\": 1,\n            \"status\": 255,\n            \"start\": 0,\n            \"limit\": 1000,\n            \"t\": int(time.time()*1000),\n        }\n\n        url = 'http://pan.baidu.com/rest/2.0/services/cloud_dl'\n        r = ss.get(url, params=p)\n        j = r.json()\n        if j.get('error_code'):\n            print s % (1, 91, '  !! Error at _query_task:'), j\n            sys.exit(1)\n\n        jobids = [i['task_id'].encode('utf8') for i in j['task_info']]\n        return jobids\n\n    def job(self, jobids):\n        if jobids:\n            infos = self._query_task(jobids)\n            self._task_display(infos)\n        else:\n            jobids = self._list_task()\n            if not jobids:\n                print s % (1, 97, '  nothing')\n            else:\n                infos = self._query_task(jobids)\n                self._task_display(infos)\n\n    def jobdump(self):\n        p = {\n            \"bdstoken\": self._get_bdstoken(),\n            \"web\": 1,\n            \"app_id\": 250528,\n            \"clienttype\": 0,\n            \"channel\": \"chunlei\",\n            \"method\": \"clear_task\",\n            \"t\": int(time.time()*1000),\n        }\n\n        url = 'http://pan.baidu.com/rest/2.0/services/cloud_dl'\n        ss.get(url, params=p)\n        #r = ss.get(url, params=p)\n        #j = r.json()\n        #if j.get('total'):\n            #print s % (1, 92, '  ++ success.'), 'total:', j['total']\n        #else:\n            #print s % (1, 92, '  ++ no task.')\n\n    def jobclear(self, jobid):\n        p = {\n            \"bdstoken\": self._get_bdstoken(),\n            \"web\": 1,\n            \"app_id\": 250528,\n            \"clienttype\": 0,\n            \"channel\": \"chunlei\",\n            \"method\": \"cancel_task\",\n            \"task_id\": jobid,\n            \"t\": int(time.time()*1000),\n        }\n\n        url = 'http://pan.baidu.com/rest/2.0/services/cloud_dl'\n        r = ss.get(url, params=p)\n        j = r.json()\n        if j.get('error_code'):\n            print s % (1, 91, '  !! Error:'), j['error_msg'], 'id: %s' % jobid\n\n    def jobclearall(self):\n        self.jobdump()\n        jobids = self._list_task()\n        if jobids:\n            for jobid in jobids:\n                self.jobclear(jobid)\n\n    ############################################################\n    # for mkdir\n\n    def mkdir(self, paths):\n        for path in paths:\n            path = make_server_path(self.cwd, path)\n            print s % (1, 97, '  ++ mkdir:'), path\n            meta = self._meta([path])\n            if not meta:\n                result = self._make_dir(path)\n                if result == ENoError:\n                    print s % (1, 92, '  ++ success.')\n            else:\n                print s % (1, 91, '  !! Error: file exists.'), path\n\n\n    ############################################################\n    # for share\n    def _share(self, paths, pwd=None):\n        \"\"\"\n        创建一个文件的分享链接\n        :param fs_ids: 要分享的文件fid列表\n        :type fs_ids: list\n        :param pwd: 分享密码，没有则没有密码\n        :type pwd: str\n        :return: requests.Response 对象\n            .. note::\n                返回正确\n                    {\n                        \"errno\": 0,\n                        \"request_id\": 请求识别号,\n                        \"shareid\": 分享识别号,\n                        \"link\": \"分享地址\",\n                        \"shorturl\": \"段网址\",\n                        \"ctime\": 创建时间,\n                        \"premis\": false\n                    }\n        \"\"\"\n        meta = self._meta(paths)\n        fs_ids = [i['fs_id'] for i in meta['info']]\n\n        params = {\n            'app_id': 250528,\n            'channel': 'chunlei',\n            'clienttype': 0,\n            'web': 1,\n            'bdstoken': self._get_bdstoken(),\n        }\n\n        if pwd:\n            data = {\n                'fid_list': json.dumps(fs_ids),\n                'schannel': 4,\n                'channel_list': '[]',\n                'pwd': pwd,\n            }\n        else:\n            data = {\n                'fid_list': json.dumps(fs_ids),\n                'schannel': 0,\n                'channel_list': '[]'\n            }\n\n        url = 'http://pan.baidu.com/share/set'\n        r = ss.post(url, params=params, data=data)\n        j = r.json()\n\n        if not j.get('shorturl'):\n            print s % (1, 91, '  !! Error at _share'), j\n            sys.exit(1)\n        else:\n            print '\\n 链接地址:', s % (1, 92, j.get('shorturl').encode('utf8'))\n            if pwd: print '     密码:', s % (1, 91, pwd)\n            #if 0 == meta['info'][0]['isdir']:\n                #print 'MD5:%s' % (meta['info'][0]['md5'])\n            return ENoError\n\n    def share(self, paths, pwd):\n        paths = [ make_server_path(self.cwd, path) for path in paths ]\n        self._share(paths, pwd)\n\n    def decrypt(self, paths):\n        def init_decrypted_file(path):\n            open(path, 'w').close()\n\n        def store(path, decrypted_block):\n            with open(path, 'ab') as g:\n                g.write(decrypted_block)\n\n        def do(file):\n            init_decrypted_file(file + '.decrypt')\n            self._init_cipherer()\n            encrypted_file = open(file, 'rb')\n            block = encrypted_file.read(100)\n            encrypted_file.seek(0)\n            head = re.search(r'^__\\d+__', block)\n            if not head:\n                print s % (1, 91, '  |-- file isn\\'t encrypted.'), file\n                return\n            head = head.group()\n            head_len = len(head)\n            slice_size = int(re.search(r'__(\\d+)__', head).group(1))\n            piece = 0\n            while True:\n                if piece == 0:\n                    block = encrypted_file.read(head_len + slice_size)\n                    block = block[head_len:]\n                    piece = 1\n                else:\n                    block = encrypted_file.read(slice_size)\n                if block:\n                    decrypted_block = self._cipherer.decrypt(block)\n                    store(file + '.decrypt', decrypted_block)\n                else:\n                    break\n\n            if 'no' not in args.type_:  # no overwrite\n                os.rename(file + '.decrypt', file)\n\n        for pt in paths:\n            path = get_abspath(pt)\n            if not path: continue\n\n            if os.path.isdir(path):\n                for parent, directories, files in os.walk(path):\n                    for file in files:\n                        do(os.path.join(parent, file))\n                    if not args.recursive: break\n            elif os.path.isfile(path):\n                do(path)\n\n    def change_directory(self, path):\n        def cd_do(path):\n            meta = self._meta([path])\n            if meta:\n                if meta['info'][0]['isdir']:\n                    self.cwd = path\n                else:\n                    self.cwd = os.path.dirname(path)\n            else:\n                print s % (1, 93, '  !! path isn\\'t existed.'), path\n\n        if not path:\n            self.cwd = '/'\n        else:\n            path = path[0]\n            path = make_server_path(self.cwd, path)\n            cd_do(path)\n\nclass panbaiducom(object):\n    @staticmethod\n    def get_web_fileinfo(cm, url):\n        if 'shareview' in url:\n            info['uk']       = re.search(r'uk=\"(\\d+)\"', cm).group(1)\n            info['shareid']  = re.search(r'shareid=\"(\\d+)\"', cm).group(1)\n            info['bdstoken'] = re.search(r'bdstoken=\"(.+?)\"', cm).group(1)\n            t = re.search(r'list=JSON.parse\\(\"(\\[.+?\\])\"\\)', cm).group(1)\n            t = t.replace('\\\\\\\\', '!@#$%^'*10)\n            t = t.replace('\\\\', '')\n            t = t.replace('!@#$%^'*10, '\\\\')\n            info['fileinfo']  = t\n            info['timestamp'] = re.search(r'timestamp=\"(\\d+)\"', cm).group(1)\n            info['sign']      = re.search(r'downloadsign=\"(.+?)\"', cm).group(1)\n        else:\n            info_str = re.search(r'yunData.setData\\((.+?)\\);', cm).group(1)\n            info = json.loads(info_str)\n\n        return info\n\n    def get_params(self, path):\n        r = ss.get(path)\n        html = r.content\n\n        info = self.get_web_fileinfo(html, path)\n        self.uk = str(info['uk'])\n        self.shareid = str(info['shareid'])\n        self.timestamp = str(info['timestamp'])\n        self.sign = info['sign']\n        self.bdstoken = info['bdstoken']\n\n        self.params = {\n            \"bdstoken\": self.bdstoken,\n            \"uk\": self.uk,\n            \"shareid\": self.shareid,\n            \"timestamp\": self.timestamp,\n            \"sign\": self.sign,\n            \"channel\": \"chunlei\",\n            \"clienttype\": 0,\n            \"web\": 1\n        }\n\n        j = info['file_list']['list']\n\n        self.infos.update({\n            'name': j[0]['server_filename'].encode('utf8'),\n            'file': os.path.join(\n                args.outdir, j[0]['server_filename'].encode('utf8')\n            ),\n            'dir_': args.outdir,\n            'fs_id': j[0]['fs_id']\n            })\n\n    def get_vcode(self):\n        url = (\n            'https://pan.baidu.com/api/getvcode'\n            '?prod=pan'\n            '&t={}'\n            '&channel=chunlei'\n            '&web=1'\n            '&app_id=250528'\n            '&bdstoken={}'\n        ).format(random.random(), self.bdstoken)\n\n        r = ss.get(url)\n        j = r.json()\n        return j\n\n    def get_infos(self):\n        url = ('https://pan.baidu.com/api/sharedownload?'\n               'sign={}&timestamp={}&bdstoken={}'\n               '&channel=chunlei&clienttype=0&web=1').format(\n                   self.sign, self.timestamp, self.bdstoken)\n\n        data = {\n            'encrypt': '0',\n            'product': 'share',\n            'uk': self.uk,\n            'primaryid': self.shareid,\n            'fid_list': urllib.quote_plus('[%s]' % self.infos['fs_id']),\n            'path_list': '',\n            'vip': '0',\n        }\n\n        while True:\n            data_str = '&'.join(['{}={}'.format(k, v) for k, v in data.items()])\n            r = ss.post(url, data=data_str)\n            j = r.json()\n            errno = j['errno']\n            if errno == 0:\n                dlink = fast_pcs_server(j['list'][0]['dlink'].encode('utf8'))\n                self.infos['dlink'] = dlink\n                if args.play:\n                    panbaiducom_HOME._play_do(self.infos)\n                else:\n                    panbaiducom_HOME._download_do(self.infos)\n                break\n            elif errno == 118:\n                print s % (1, 91, '  !! 没有下载权限！, 请转存网盘后，从网盘地址下载')\n                sys.exit(1)\n            else:\n                j = self.get_vcode()\n                vcode = j['vcode']\n                input_code = panbaiducom_HOME.save_img(j['img'], 'jpg')\n                data.update({'vcode_input': input_code, 'vcode_str': vcode})\n\n    def get_infos2(self, path):\n        while True:\n            r = ss.get(path)\n            j = r.content.replace('\\\\', '')\n            name = re.search(r'server_filename\":\"(.+?)\"', j).group(1)\n            dlink = re.search(r'dlink\":\"(.+?)\"', j)\n            if dlink:\n                self.infos = {\n                    'name': name,\n                    'file': os.path.join(args.outdir, name),\n                    'dir_': args.outdir,\n                    'dlink': fast_pcs_server(dlink.group(1))\n                }\n                if args.play:\n                    panbaiducom_HOME._play_do(self.infos)\n                else:\n                    panbaiducom_HOME._download_do(self.infos)\n                break\n            else:\n                print s % (1, 91, '  !! Error at get_infos2, can\\'t get dlink')\n\n    def do(self, paths):\n        for path in paths:\n            self.infos = {}\n            panbaiducom_HOME._secret_or_not(path)\n            self.get_params(path)\n            self.get_infos()\n\n    def do2(self, paths):\n        for path in paths:\n            self.infos = {}\n            self.get_infos2(path)\n\n    def do4(self, paths):\n        for path in paths:\n            r = ss.get(path, allow_redirects=False)\n            t = re.search(r'fin=(.+?)(&|$)', r.headers['location']).group(1)\n            name = urllib.unquote_plus(t)\n            self.infos = {\n                'name': name,\n                'file': os.path.join(args.outdir, name),\n                'dir_': args.outdir,\n                'dlink': fast_pcs_server(path)\n            }\n\n            if args.play:\n                panbaiducom_HOME._play_do(self.infos)\n            else:\n                panbaiducom_HOME._download_do(self.infos)\n            break\n\ndef assert_download_tools():\n    for tool in ('wget', 'aget', 'aria2c'):\n        if ' ' in os.popen('which %s' % tool).read():\n            print s % (1, 91, '  !!! aria2 is not installed')\n\ndef sighandler(signum, frame):\n    print s % (1, 91, \"  !! Signal:\"), signum\n    if args.comd in ('u', 'upload'):\n        px.save_datas(upload_datas_path, px.upload_datas)\n\n    #print s % (1, 91, \"  !! Frame: %s\" % frame)\n    sys.exit(1)\n\ndef handle_signal():\n    signal.signal(signal.SIGBUS, sighandler)\n    signal.signal(signal.SIGHUP, sighandler)\n    # http://stackoverflow.com/questions/14207708/ioerror-errno-32-broken-pipe-python\n    signal.signal(signal.SIGPIPE, signal.SIG_DFL)\n    signal.signal(signal.SIGQUIT, sighandler)\n    signal.signal(signal.SIGSYS, sighandler)\n\n    signal.signal(signal.SIGABRT, sighandler)\n    signal.signal(signal.SIGFPE, sighandler)\n    signal.signal(signal.SIGILL, sighandler)\n    signal.signal(signal.SIGINT, sighandler)\n    signal.signal(signal.SIGSEGV, sighandler)\n    signal.signal(signal.SIGTERM, sighandler)\n\ndef handle_args(argv):\n    # for argparse\n    p = argparse.ArgumentParser(description='about pan.baidu.com.' \\\n        ' 用法见 https://github.com/PeterDing/iScript')\n    p.add_argument('xxx', type=str, nargs='*', help='命令对象.')\n    p.add_argument('-a', '--aria2c', action='store', default=None, \\\n        type=int, help='aria2c 分段下载数量')\n    p.add_argument('-g', '--aget_s', action='store', default=None, \\\n        type=int, help='aget 分段下载数量')\n    p.add_argument('-k', '--aget_k', action='store', default='200K', \\\n        type=str, help='aget 分段大小')\n    p.add_argument('--appid', action='store', default='778750', type=str, \\\n                   help='设置 app-id. 如果无法下载或下载慢, 尝试设置为 778750')\n    p.add_argument('-o', '--outdir', action='store', default=os.getcwd(), \\\n                   type=str, help='保存目录')\n    p.add_argument('-p', '--play', action='store_true', help='play with mpv')\n    p.add_argument('-v', '--view', action='count', help='view details')\n    p.add_argument('-V', '--VERIFY', action='store_true', help='verify')\n    p.add_argument('-y', '--yes', action='store_true', help='yes')\n    p.add_argument('-q', '--quiet', action='store_true', help='quiet for download and play')\n    p.add_argument('-s', '--secret', action='store', default=None, help='提取密码')\n    p.add_argument('-f', '--from_', action='store', \\\n        default=1, type=int, \\\n        help='从第几个开始下载，eg: -f 42')\n    p.add_argument('-t', '--type_', action='store', \\\n        default='', type=str, \\\n        help='类型参数，eg: ls -t f (文件(f)、文件夹(d))')\n    p.add_argument('-l', '--limit', action='store', \\\n        default=None, type=str, help='下载速度限制，eg: -l 100k')\n    p.add_argument('-P', '--passwd', action='store', \\\n        default=None, type=str, help='设置密码，eg: -P pawd')\n    # for upload\n    p.add_argument('-m', '--mode', action='store', \\\n        default='c', type=str, choices=['o', 'c'] + CIPHERS, \\\n        help='上传模式: o --> 重传. c --> 续传 .')\n    # for recurse, head, tail, include, exclude\n    p.add_argument('-R', '--recursive', action='store_true', help='递归 ls')\n    p.add_argument('-H', '--heads', nargs='*', default=[], \\\n        help='匹配开头list，不能是正则表达式, eg: -H Head1 Head2 ..')\n    p.add_argument('-T', '--tails', nargs='*', default=[], \\\n        help='匹配结尾list，不能是正则表达式, eg: -T Tail1 Tail2 ..')\n    p.add_argument('-I', '--includes', nargs='*', default=[], \\\n        help='不排除匹配list, 可以是正则表达式，eg: -I \"*.mp3\" \"^[\\d]+\" ..')\n    p.add_argument('-E', '--excludes', nargs='*', default=[], \\\n        help='排除匹配list, 可以是正则表达式，eg: -E \"*.html\" \"*.temp\" ..')\n    p.add_argument('-c', '--ls_color', action='store', default='on', \\\n        choices=['on', 'off'], type=str, help='ls 颜色，默认是on')\n    global args\n    global VERIFY\n    comd = argv[1]\n    args = p.parse_args(argv[2:])\n    if args.type_:\n        args.type_ = args.type_.split(',')\n    else:\n        args.type_ = []\n    VERIFY = args.VERIFY\n    if (comd == 'rnr' or comd == 'rnre') and 'bd64' not in args.type_:\n        if len(argv[2:]) < 3:\n            print s % (1, 91, \"  !! 参数错误\\n rnr foo bar /path/to\")\n            sys.exit(1)\n\n        args = p.parse_args(argv[4:])\n    xxx = args.xxx\n    args.comd = comd\n    return comd, xxx\n\ndef enter_password():\n    if not args.passwd:\n        from getpass import getpass\n        if 'ec' in args.type_:\n            while True:\n                pwd1 = getpass(s % (2, 97, 'Password: '))\n                pwd2 = getpass(s % (2, 97, 'verify Password: '))\n                if pwd1 == pwd2:\n                    args.passwd = pwd1\n                    break\n                else:\n                    print s % (2, 91, '! Passwords do not match.')\n        elif 'dc' in args.type_:\n            args.passwd = getpass(s % (2, 97, 'Password: '))\n\ndef handle_command(comd, xxx):\n    if comd == 'login' or comd == 'g':\n        from getpass import getpass\n        xh = panbaiducom_HOME()\n\n        if len(xxx) < 1:\n            username = raw_input(s % (1, 97, ' username: '))\n            password = getpass(s % (1, 97, ' password / cookie: '))\n        elif len(xxx) == 1:\n            username = xxx[0]\n            password = getpass(s % (1, 97, '  password / cookie: '))\n        elif len(xxx) == 2:\n            username = xxx[0]\n            password = xxx[1]\n        else:\n            print s % (1, 91, '  login\\n  login username\\n  login username password')\n\n        xh.login(username, password)\n        result = xh.check_login()\n        if result:\n            xh.save_cookies(username, on=1)\n            print s % (1, 92, '  ++ login succeeds.')\n        else:\n            print s % (1, 91, '  login failes')\n\n    elif comd == 'userdelete' or comd == 'ud' or \\\n        comd == 'userchange' or comd == 'uc' or \\\n        comd == 'user':\n        accounts = panbaiducom_HOME._check_cookie_file()\n        if accounts:\n            cu = zip(range(len(accounts)), sorted([u for u in accounts]))\n            for i, u in cu:\n                print s % (1, 92, i+1) if accounts[u]['on'] else s % (1, 91, i+1), \\\n                    accounts[u]['capacity'].ljust(15), \\\n                    s % (2, 92, u) if accounts[u]['on'] else s % (2, 97, u)\n            if comd == 'userdelete' or comd == 'ud': print s % (2, 97, 0), s % (2, 91, 'ALL')\n            elif comd == 'user': sys.exit()\n\n            ipts = raw_input(\n                'pick numbers: ' \\\n                if comd == 'userdelete' or comd == 'ud' \\\n                else 'pick a number: '\n            )\n            for ipt in ipts.split():\n                if not ipt.isdigit(): sys.exit()\n                u = cu[int(ipt) - 1][1] if int(ipt) else 'ALL'\n\n                if comd == 'userdelete' or comd == 'ud':\n                    if u != 'ALL':\n                        if accounts[u]['on'] and len(accounts) > 1:\n                            print s % (1, 91, '  !! %s is online. To delete the account, firstly switching to other account' % u)\n                            sys.exit()\n                        del accounts[u]\n                    else:\n                        with open(cookie_file, 'w') as g:\n                            pk.dump({}, g)\n                        sys.exit()\n\n                elif comd == 'userchange' or comd == 'uc':\n                    for i in accounts:\n                        if i != u:\n                            accounts[i]['on'] = 0\n                        else:\n                            accounts[i]['on'] = 1\n\n            with open(cookie_file, 'w') as g:\n                pk.dump(accounts, g)\n\n        else:\n            print s % (1, 97, '  please login')\n            sys.exit(1)\n\n    elif comd == 'u' or comd == 'upload':\n        if len(xxx) < 2:\n            print s % (1, 91, '  !! 参数错误\\n  upload localpath1 localpath2 .. remotepath\\n' \\\n                '  u localpath1 localpath2 .. remotepath')\n            sys.exit(1)\n        global px\n\n        enter_password()\n\n        px = panbaiducom_HOME()\n        px.init()\n        px.upload(xxx[:-1], xxx[-1])\n\n    elif comd == 'S' or comd == 'share':\n        if len(xxx) < 1:\n            print s % (1,91, ' !! S path1 path2 \\n share path1 path2 \\n ..')\n            sys.exit(1)\n\n        pwd = args.passwd\n        if pwd:\n            if not re.match(r'^[a-z0-9]{4}$', pwd):\n                from string import lowercase, digits\n                print s % (1, 91, '  !! passwd is wrong and will be randomly choiced.' \\\n                           '\\n  passwd is 4 symbols and choiced from %s%s' \\\n                           % (lowercase, digits))\n                pwd = ''.join(random.sample(lowercase + digits, 4))\n\n        paths = xxx\n        paths1 = []\n        for path in paths:\n            if path[0] == '/':\n                paths1.append(path)\n            else:\n                print s % (2, 91, '  !!! url 路径不正确.'), path\n        if paths1:\n            x = panbaiducom_HOME()\n            x.init()\n            x.share(paths1, pwd)\n\n    elif comd == 'd' or comd == 'download' \\\n        or comd == 'p' or comd == 'play':\n        if len(xxx) < 1:\n            print s % (1, 91, '  !! 参数错误\\n download path1 .. url1 ..\\n' \\\n                '  d url1 url2 ..')\n            sys.exit(1)\n\n        # login session\n        panbaiducom_HOME().init()\n\n        if comd == 'p' or comd == 'play':\n            args.play = True\n        else:\n            assert_download_tools()\n\n        enter_password()\n\n        paths  = xxx\n        paths1 = []\n        paths2 = []\n        paths3 = []\n        paths4 = []\n\n        for path in paths:\n            if '/disk/home' in path:\n                paths1.append(path)\n            elif 'baidu.com/pcloud/album/file' in path:\n                paths2.append(path)\n            elif 'yun.baidu.com' in path or 'pan.baidu.com' in path:\n                path = path.replace('wap/link', 'share/link')\n                paths3.append(path)\n            elif 'pcs.baidu.com' in path:\n                paths4.append(path)\n            else:\n                paths1.append(path)\n\n        if paths1:\n            x = panbaiducom_HOME()\n            x.init()\n            x.download(paths1)\n\n        if paths2:\n            xw = panbaiducom()\n            xw.do2(paths2)\n\n        if paths3:\n            xw = panbaiducom()\n            xw.do(paths3)\n\n        if paths4:\n            xw = panbaiducom()\n            xw.do4(paths4)\n\n    elif comd == 's' or comd == 'save':\n        if len(xxx) != 2:\n            print s % (1, 91, '  !! 参数错误\\n save url remotepath\\n' \\\n                ' s url remotepath')\n            sys.exit(1)\n        x = panbaiducom_HOME()\n        x.init()\n        path = x._get_path(xxx[0])\n        remotepath = xxx[1].decode('utf8', 'ignore')\n        infos = []\n        if path != '/' and path[0] == '/':\n            infos.append(\n                {\n                    'isdir': 1,\n                    'path': path.decode('utf8', 'ignore'),\n                    'remotepath': remotepath \\\n                        if remotepath[-1] != '/' \\\n                        else remotepath[:-1]\n                }\n            )\n        else:\n            infos = None\n\n        if '/inbox/' in xxx[0]:\n            url = xxx[0]\n            x.save_inbox_share(url, remotepath, infos=infos)\n        else:\n            url = re.search(r'(https?://.+?.baidu.com/.+?)(#|$)', xxx[0]).group(1)\n            url = url.replace('wap/link', 'share/link')\n            x._secret_or_not(url)\n            x.save_share(url, remotepath, infos=infos)\n\n    elif comd == 'f' or comd == 'find' or comd == 'ff' \\\n        or comd == 'ft' or comd == 'ftt' \\\n        or comd == 'fs' or comd == 'fss' \\\n        or comd == 'fn' or comd == 'fnn':\n        if len(xxx) < 1:\n            print s % (1, 91, '  !! 参数错误\\n find keyword1 keyword2 .. [directory]\\n' \\\n                ' f keyword1 keyword2 .. [directory]')\n            sys.exit(1)\n        x = panbaiducom_HOME()\n        x.init()\n\n        iii = xxx.index('|') if '|' in xxx else -1\n        fxxx = xxx[:iii] if iii != -1 else xxx\n        pxxx = xxx[iii+1:] if iii != -1 else None\n        if fxxx[-1][0] == '/':\n            keywords = fxxx[:-1]\n            directory = fxxx[-1]\n        else:\n            keywords = fxxx\n            directory = x.cwd\n\n        if comd == 'f' or comd == 'find':\n            x.find(keywords, directory=directory, pipe=pxxx)\n        elif comd == 'ff':\n            x.find(keywords, directory=directory, pipe=pxxx)\n        elif comd == 'ft':\n            x.find(keywords, time='no_reverse', directory=directory, pipe=pxxx)\n        elif comd == 'ftt':\n            x.find(keywords, time='reverse', directory=directory, pipe=pxxx)\n        elif comd == 'fs':\n            x.find(keywords, ize='no_reverse', directory=directory, pipe=pxxx)\n        elif comd == 'fss':\n            x.find(keywords, size='reverse', directory=directory, pipe=pxxx)\n        elif comd == 'fn':\n            x.find(keywords, name='no_reverse', directory=directory, pipe=pxxx)\n        elif comd == 'fnn':\n            x.find(keywords, name='reverse', directory=directory, pipe=pxxx)\n\n    elif comd == 'mv' or comd == 'move' \\\n        or comd == 'rm' or comd == 'remove' \\\n        or comd == 'cp' or comd == 'copy' \\\n        or comd == 'rn' or comd == 'rename' \\\n        or comd == 'l' or comd == 'll' \\\n        or comd == 'du' \\\n        or comd == 'ln' or comd == 'lnn'\\\n        or comd == 'ls' or comd == 'lss' \\\n        or comd == 'lt' or comd == 'ltt':\n        if len(xxx) < 1 and (comd[0] != 'l'):\n            print s % (1, 91, '  !! 参数错误\\n move path1 path2 .. /path/to/directory\\n' \\\n                ' mv path1 path2 .. /path/to/directory\\n' \\\n                ' remove path1 path2 ..\\n' \\\n                ' rm path1 path2 ..\\n' \\\n                ' rename path new_path\\n' \\\n                ' rn path new_path\\n' \\\n                ' rename path new_path\\n' \\\n                ' cp path1 path2 /copy/to/directory\\n' \\\n                ' cp path /copy/to/existed_directory/newname\\n' \\\n                ' l path1 path2 ..\\n' \\\n                ' ls path1 path2 ..\\n')\n            sys.exit(1)\n        #e = True if 'f' in ['f' for i in xxx if i[0] != '/'] else False\n        #if e and (comd[0] != 'l'):\n            #print s % (1, 91, '  !! path is incorrect.')\n            #sys.exit(1)\n        x = panbaiducom_HOME()\n        x.init()\n        if comd == 'mv' or comd == 'move':\n            x.move(xxx[:-1], xxx[-1])\n        elif comd == 'rm' or comd == 'remove':\n            x.remove(xxx)\n        elif comd == 'cp' or comd == 'copy':\n            x.copy(xxx[:-1], xxx[-1])\n        elif comd == 'rn' or comd == 'rename':\n            x.rename(xxx[0], xxx[1])\n        elif comd == 'l' or comd == 'ln':\n            x.ls('name', None, xxx)\n        elif comd == 'du':\n            args.type_.append('du')\n            x.ls('name', None, xxx)\n        elif comd == 'll' or comd == 'lnn':\n            x.ls('name', 1, xxx)\n        elif comd == 'lt':\n            x.ls('time', None, xxx)\n        elif comd == 'ltt':\n            x.ls('time', 1, xxx)\n        elif comd == 'ls':\n            x.ls('size', None, xxx)\n        elif comd == 'lss':\n            x.ls('size', 1, xxx)\n\n    elif comd == 'rnr' or comd == 'rnre' or \\\n        comd == 'cpr' or comd == 'cpre' or \\\n        comd == 'rmr' or comd == 'rmre' or \\\n        comd == 'mvr' or comd == 'mvre':\n\n        if comd == 'cpr' or comd == 'cpre' or \\\n            comd == 'rmr' or comd == 'rmre':\n            if not (args.includes or args.excludes or args.heads or args.tails or args.type_):\n                print s % (1, 91, '  !! missing -I or -E or -H or -T')\n                sys.exit(1)\n\n        if args.recursive \\\n                and (not 'f' in args.type_ and not 'd' in args.type_):\n            print s % (1, 91, '  !! you don\\'t choose \"-t f\" or \"-t d\", it will delete all files and directorys matched.')\n            ipt = raw_input(s % (1, 93, '  are your sure? [y/N] '))\n            if ipt != 'y':\n                print s % (1, 92, '  ++ aborted.')\n                sys.exit()\n\n        if comd == 'rnr' or comd == 'rnre':\n            if 'bd64' in args.type_:\n                foo, bar = '', ''\n                dirs = xxx\n            else:\n                foo = argv[2]\n                bar = argv[3]\n                dirs = xxx\n\n            #e = True if 'f' in ['f' for i in dirs if i[0] != '/'] else False\n            #if e:\n                #print s % (1, 91, '  !! path is incorrect.')\n                #sys.exit(1)\n\n            x = panbaiducom_HOME()\n            x.init()\n            x.filemanager_re('rename', dirs, foo=foo, bar=bar)\n\n        elif comd == 'rmr' or comd == 'rmre':\n            if len(xxx) < 1:\n                print s % (1, 91, '  !! 参数错误\\n rmr dir1 dir2 .. -I regex1 -E regex2 -H head -T tail')\n                sys.exit(1)\n\n            dirs = xxx\n            #e = True if 'f' in ['f' for i in dirs if i[0] != '/'] else False\n            #if e:\n                #print s % (1, 91, '  !! path is incorrect.')\n                #sys.exit(1)\n\n            x = panbaiducom_HOME()\n            x.init()\n            x.filemanager_re('remove', dirs)\n\n        elif comd == 'mvr' or comd == 'mvre':\n            if len(xxx) < 2:\n                print s % (1, 91, '  !! 参数错误\\n mvr dir1 dir2 .. /path/to/dir -I regex1 -E regex2 -H head -T tail')\n                sys.exit(1)\n\n            dirs = xxx\n            #e = True if 'f' in ['f' for i in dirs if i[0] != '/'] else False\n            #if e:\n                #print s % (1, 91, '  !! path is incorrect.')\n                #sys.exit(1)\n\n            x = panbaiducom_HOME()\n            x.init()\n            x.filemanager_re('move', dirs[:-1], todir=dirs[-1])\n\n        elif comd == 'cpr' or comd == 'cpre':\n            if len(xxx) < 2:\n                print s % (1, 91, '  !! 参数错误\\n cpr dir1 dir2 .. /path/to/dir -I regex1 -E regex2 -H head -T tail')\n                sys.exit(1)\n\n            dirs = xxx\n            #e = True if 'f' in ['f' for i in dirs if i[0] != '/'] else False\n            #if e:\n                #print s % (1, 91, '  !! path is incorrect.')\n                #sys.exit(1)\n\n            x = panbaiducom_HOME()\n            x.init()\n            x.filemanager_re('copy', dirs[:-1], todir=dirs[-1])\n\n    elif comd == 'a' or comd == 'add':\n        if len(xxx) < 1:\n            print s % (1, 91, '  !! 参数错误\\n add url1 url2 .. [directory]\\n' \\\n                ' a url1 url2 .. [directory]\\n' \\\n                ' a url1 url2 .. [directory] [-t {m,d,p,a}]')\n            sys.exit(1)\n\n        if not args.type_: args.type_.append('m') # default is mediatype\n\n        if len(xxx[-1]) < 4 \\\n            or xxx[-1][:4] not in ['magn', 'http', 'ed2k', 'ftp:']:\n            remotepath = xxx[-1]\n            urls = xxx[:-1]\n        else:\n            remotepath = '/'\n            urls = xxx\n\n        localtorrents = [i for i in xxx \\\n                         if i[:4] not in ['magn', 'http', 'ed2k', 'ftp:'] \\\n                            and i[-8:] == '.torrent']\n        if localtorrents:\n            remotepath = '/'\n            urls = localtorrents\n\n        x = panbaiducom_HOME()\n        x.init()\n        x.add_tasks(urls, remotepath)\n\n    elif comd == 'md' or comd == 'mkdir':\n        if len(xxx) < 1:\n            print s % (1, 91, '  !! 参数错误\\n mkdir path1 path2 ..\\n' \\\n                ' md path1 path2 ..')\n            sys.exit(1)\n        paths = xxx\n        #e =  True if 'f' in ['f' for i in xxx if i[0] != '/'] else False\n        #if e:\n            #print s % (1, 91, '  !! some path is wrong')\n            #sys.exit(1)\n        x = panbaiducom_HOME()\n        x.init()\n        x.mkdir(paths)\n\n    elif comd == 'j' or comd == 'job' \\\n        or comd == 'jd' or comd == 'jobdump' \\\n        or comd == 'jc' or comd == 'jobclear' \\\n        or comd == 'jca' or comd == 'jobclearall':\n        if xxx:\n            e =  True if 'f' in ['f' for i in xxx if not i.isdigit()] else False\n            if e:\n                print s % (1, 91, '  !! some job_ids are not number.')\n                sys.exit(1)\n\n        jobids = xxx if xxx else None\n        x = panbaiducom_HOME()\n        x.init()\n        if comd == 'j' or comd == 'job':\n            x.job(jobids)\n\n        elif comd == 'jd' or comd == 'jobdump':\n            x.jobdump()\n\n        elif comd == 'jc' or comd == 'jobclear':\n            if jobids:\n                for jobid in jobids:\n                    x.jobclear(jobid)\n            else:\n                print s % (1, 91, '  !! missing job_ids.')\n\n        elif comd == 'jca' or comd == 'jobclearall':\n            x.jobclearall()\n\n    elif comd == 'dc' or comd == 'decrypt':\n        if 'dc' not in args.type_: args.type_.append('dc')\n        enter_password()\n\n        x = panbaiducom_HOME()\n        x.init()\n        x.decrypt(xxx)\n\n    elif comd == 'cd':\n        x = panbaiducom_HOME()\n        x.init()\n\n        if len(xxx) > 1:\n            print s % (1, 91, '  !! 参数错误\\n cd path')\n            sys.exit(1)\n\n        x.change_directory(xxx)\n\n    elif comd == 'cwd':\n        xd = panbaiducom_HOME()\n        xd.init()\n        print xd.cwd\n\n    else:\n        print s % (2, 91, '  !! 命令错误\\n')\n\n    if 'x' in locals():\n        x.save_cookies(on=1, tocwd=True)\n    elif 'px' in globals():\n        px.save_cookies(on=1, tocwd=True)\n\n\n\ndef main(argv):\n    handle_signal()\n\n    usage = \"usage: https://github.com/PeterDing/iScript#pan.baidu.com.py\"\n    if len(argv) <= 1:\n        print usage\n        sys.exit()\n\n    comd, xxx = handle_args(argv)\n    handle_command(comd, xxx)\n\nif __name__ == '__main__':\n    argv = sys.argv\n    main(argv)\n"
        },
        {
          "name": "tumblr.py",
          "type": "blob",
          "size": 21.2138671875,
          "content": "#!/usr/bin/env python2\n# vim: set fileencoding=utf8\n\nfrom __future__ import unicode_literals\n\nimport os\nimport sys\nimport re\nimport json\nimport collections\nimport multiprocessing\nimport requests\nrequests.packages.urllib3.disable_warnings()\nimport argparse\nimport random\nimport time\nimport select\nimport signal\n\nAPI_KEY = 'fuiKNFp9vQFvjLNvx4sUwti4Yb5yGutBN4Xh10LXZhhRKjWlV4'\n\nPID_PATH = '/tmp/tumblr.py.pid'\n\n# statistic parameters\nNET_ERRORS = multiprocessing.Value('i', 0)\nUNCOMPLETION = multiprocessing.Value('i', 0)\nDOWNLOAD_ERRORS = multiprocessing.Value('i', 0)\nDOWNLOADS = multiprocessing.Value('i', 0)\nCOMPLETION = multiprocessing.Value('i', 0)\nOFFSET = multiprocessing.Value('i', 0)\n\n############################################################\n# wget exit status\nwget_es = {\n    0: \"No problems occurred.\",\n    2: \"User interference.\",\n    1<<8: \"Generic error code.\",\n    2<<8: \"Parse error - for instance, when parsing command-line \" \\\n        \"optio.wgetrc or .netrc...\",\n    3<<8: \"File I/O error.\",\n    4<<8: \"Network failure.\",\n    5<<8: \"SSL verification failure.\",\n    6<<8: \"Username/password authentication failure.\",\n    7<<8: \"Protocol errors.\",\n    8<<8: \"Server issued an error response.\"\n}\n############################################################\n\ns = '\\x1b[%d;%dm%s\\x1b[0m'       # terminual color template\n\nheaders = {\n    \"Accept\":\"text/html,application/xhtml+xml,application/xml; \" \\\n        \"q=0.9,image/webp,*/*;q=0.8\",\n    \"Accept-Encoding\":\"text/html\",\n    \"Accept-Language\":\"en-US,en;q=0.8,zh-CN;q=0.6,zh;q=0.4,zh-TW;q=0.2\",\n    \"Content-Type\":\"application/x-www-form-urlencoded\",\n    \"Referer\":\"https://api.tumblr.com/console//calls/blog/posts\",\n    \"User-Agent\":\"Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.36 \" \\\n        \"(KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n}\n\nss = requests.session()\nss.headers.update(headers)\n\nPROXY = None\n\nclass Error(Exception):\n    def __init__(self, msg):\n        self.msg = msg\n    def __str__(self):\n        return self.msg\n\ndef reset_statistic_params():\n    NET_ERRORS.value = 0\n    UNCOMPLETION.value = 0\n    DOWNLOAD_ERRORS.value = 0\n    DOWNLOADS.value = 0\n    COMPLETION.value = 0\n    OFFSET.value = 0\n\ndef play(urls, args):\n    for url in urls:\n        tumblr = Tumblr(args, url)\n        while True:\n            items = tumblr.get_item_generator()\n            if not items:\n                break\n            play_do(items, args.quiet)\n\ndef play_do(items, quiet):\n    for item in items:\n        num = random.randint(0, 7) % 8\n        col = s % (2, num + 90, item['durl'])\n        print '  ++ play:', col\n        quiet = ' --really-quiet' if quiet else ''\n        cmd = 'mpv%s --no-ytdl --cache-default 20480 --cache-secs 120 ' \\\n            '--http-header-fields \"User-Agent:%s\" ' \\\n            '\"%s\"' \\\n            % (quiet, headers['User-Agent'], item['durl'])\n\n        os.system(cmd)\n        timeout = 1\n        ii, _, _ = select.select([sys.stdin], [], [], timeout)\n        if ii:\n            sys.exit(0)\n        else:\n            pass\n\ndef remove_downloaded_items(items):\n    N = len(items)\n    for i in range(N):\n        item = items.pop()\n        filepath = os.path.join(item['dir_'], item['subdir'], item['filename'])\n        if not os.path.exists(filepath):\n            items.appendleft(item)\n\ndef download_run(item):\n    filepath = os.path.join(item['dir_'], item['subdir'], item['filename'])\n    # if os.path.exists(filepath):\n        # return None\n    # num = random.randint(0, 7) % 8\n    # col = s % (1, num + 90, filepath)\n    # print '  ++ download: %s' % col\n\n    if PROXY:\n        cmd = ' '.join([\n            'curl', '-s', '-x', '\"%s\"' % PROXY, '-o', '\"%s.tmp\"' % filepath,\n            '-H', '\"User-Agent: %s\"' % headers['User-Agent'],\n            '\"%s\"' % item['durl']\n        ])\n    else:\n        cmd = ' '.join([\n            'curl', '-s', '-o', '\"%s.tmp\"' % filepath,\n            '-H', '\"User-Agent: %s\"' % headers['User-Agent'],\n            '\"%s\"' % item['durl']\n        ])\n    status = os.system(cmd)\n    return status, filepath\n\ndef callback(filepath):\n    os.rename('%s.tmp' % filepath, filepath)\n\nclass Downloader(multiprocessing.Process):\n    def __init__(self, queue, lock):\n        super(Downloader, self).__init__()\n        self.queue = queue\n        self.daemon = True\n        self.lock = lock\n\n    def run(self):\n        while True:\n            item = self.queue.get()\n            self.queue.task_done()\n            if not item:\n                break\n            status = download_run(item)\n            if not status: # file was downloaded.\n                continue\n            status, filepath = status\n            if status != 0:\n                # print s % (1, 93, '[Error %s] at wget' % status), wget_es[status]\n                self.lock.acquire()\n                UNCOMPLETION.value += 1\n                DOWNLOAD_ERRORS.value += 1\n                self.lock.release()\n            else:\n                self.lock.acquire()\n                DOWNLOADS.value += 1\n                self.lock.release()\n                callback(filepath)\n\nclass TumblrAPI(object):\n    def _request(self, base_hostname, target, type, params):\n        api_url = '/'.join(['https://api.tumblr.com/v2/blog',\n                           base_hostname, target, type])\n        params['api_key'] = API_KEY\n        if PROXY:\n            proxies = {'http': PROXY, 'https': PROXY}\n        else:\n            proxies = None\n        while True:\n            try:\n                res = ss.get(api_url, params=params, proxies=proxies, timeout=10)\n                json_data = res.json()\n                break\n            except KeyboardInterrupt:\n                sys.exit()\n            except Exception as e:\n                NET_ERRORS.value += 1  # count errors\n                print s % (1, 93, '[Error at requests]:'), e, '\\n'\n                time.sleep(5)\n        if json_data['meta']['msg'].lower() != 'ok':\n            raise Error(s % (1, 91, json_data['meta']['msg']))\n\n        return json_data['response']\n\n    def _info(self, base_hostname):\n        return self._request(base_hostname, 'info', '', None)\n\n    def _photo(self, base_hostname, offset='', tag='', post_id='', to_items=True):\n        def make_items(raw_data):\n            items = collections.deque()\n            for i in raw_data['posts']:\n                index = 1\n                if i.get('photos'):\n                    for ii in i['photos']:\n                        durl = ii['original_size']['url'].replace('http:', 'https:')\n                        filename = os.path.join(\n                            '%s_%s.%s' % (i['id'], index, durl.split('.')[-1]))\n                        t = {\n                            'durl': durl,\n                            'filename': filename,\n                            'key': i['timestamp'],\n                            'subdir': 'photos',\n                        }\n                        index += 1\n                        items.append(t)\n            return items\n\n        params = {\n            'offset': offset,\n            'before': offset if tag else '',\n            'tag': tag,\n            'id': post_id,\n            'limit': 20 if not tag and not post_id else '',\n            'filter': 'text'\n        }\n        raw_data = self._request(base_hostname, 'posts', 'photo', params)\n        if to_items:\n            return make_items(raw_data)\n        else:\n            return raw_data\n\n    def _audio(self, base_hostname, offset='', tag='', post_id='', to_items=True):\n        def make_items(raw_data):\n            items = collections.deque()\n            for i in raw_data['posts']:\n                durl = i['audio_url'].replace('http:', 'https:')\n                filename = os.path.join(\n                    '%s_%s.%s' % (i['id'], i['track_name'], durl.split('.')[-1]))\n                t = {\n                    'durl': durl,\n                    'filename': filename,\n                    'timestamp': i['timestamp'] if tag else '',\n                    'subdir': 'audios'\n                }\n                items.append(t)\n            return items\n\n        params = {\n            'offset': offset,\n            'before': offset if tag else '',\n            'tag': tag,\n            'id': post_id,\n            'limit': 20 if not tag and not post_id else '',\n            'filter': 'text'\n        }\n        raw_data = self._request(base_hostname, 'posts', 'audio', params)\n        if to_items:\n            return make_items(raw_data)\n        else:\n            return raw_data\n\n    def _video(self, base_hostname, offset='', tag='', post_id='', to_items=True):\n        def make_items(raw_data):\n            items = collections.deque()\n            for i in raw_data['posts']:\n                if not i.get('video_url'):\n                    continue\n                durl = i['video_url'].replace('http:', 'https:')\n                filename = os.path.join(\n                    '%s.%s' % (i['id'], durl.split('.')[-1]))\n                t = {\n                    'durl': durl,\n                    'filename': filename,\n                    'timestamp': i['timestamp'] if tag else '',\n                    'subdir': 'videos'\n                }\n                items.append(t)\n            return items\n\n        params = {\n            'offset': offset,\n            'before': offset if tag else '',\n            'tag': tag,\n            'id': post_id,\n            'limit': 20 if not tag and not post_id else '',\n            'filter': 'text'\n        }\n        raw_data = self._request(base_hostname, 'posts', 'video', params)\n        if to_items:\n            return make_items(raw_data)\n        else:\n            return raw_data\n\nclass Tumblr(TumblrAPI):\n    def __init__(self, args, url):\n        self.args = args\n        self.offset = self.args.offset\n        self.make_items = self.parse_urls(url)\n\n    def save_json(self):\n        with open(self.json_path, 'w') as g:\n            g.write(json.dumps(\n                {'offset': self.offset}, indent=4, sort_keys=True))\n\n    def init_infos(self, base_hostname, target_type, tag=''):\n        self.infos = {'host': base_hostname}\n        if not tag:\n            dir_ = os.path.join(os.getcwd(), self.infos['host'])\n            json_path = os.path.join(dir_, 'json.json')\n\n            if not os.path.exists(dir_):\n                if not self.args.play:\n                    os.makedirs(dir_)\n            else:\n                if os.path.exists(json_path):\n                    self.offset = json.load(open(json_path))['offset'] - 60 \\\n                        if not self.args.update else self.args.offset\n                    if self.offset < 0: self.offset = 0\n        else:\n            dir_ = os.path.join(os.getcwd(), 'tumblr-%s' % tag)\n            json_path = os.path.join(dir_, 'json.json')\n\n            if not os.path.exists(dir_):\n                if not self.args.play:\n                    os.makedirs(dir_)\n                    self.offset = int(time.time())\n            else:\n                if os.path.exists(json_path):\n                    self.offset = json.load(open(json_path))['offset'] \\\n                        if not self.args.update else int(time.time())\n\n        self.infos['dir_'] = dir_\n        self.json_path = json_path\n        subdir = os.path.join(dir_, target_type)\n        if not os.path.exists(subdir) and not self.args.play:\n            os.makedirs(subdir)\n\n        if not self.args.play:\n            for fl in os.listdir(subdir):\n                if not fl.endswith('.tmp'):\n                    COMPLETION.value += 1\n                else:\n                    UNCOMPLETION.value += 1\n\n        if self.args.offset:\n            self.offset = self.args.offset\n\n        print s % (1, 92, '## begin:'), 'offset = %s,' % self.offset, base_hostname\n        print s % (1, 97, 'INFO:\\n') + \\\n            'D = Downloads, R = Repair_Need\\n' + \\\n            'C = Completion, NE = Net_Errors, O = Offset'\n\n    def download_photos_by_offset(self, base_hostname, post_id):\n        self.init_infos(base_hostname, 'photos')\n\n        def do():\n            items = self._photo(\n                base_hostname, offset=self.offset if not post_id else '', post_id=post_id)\n            if not items:\n                return []\n            self.offset += 20\n            self.save_json()\n            return items\n        return do\n\n    def download_photos_by_tag(self, base_hostname, tag):\n        self.init_infos(base_hostname, 'photos', tag=tag)\n\n        def do():\n            items = self._photo(base_hostname, tag=tag, before=self.offset)\n            if not items:\n                return []\n            self.offset = items[-1]['timestamp']\n            self.save_json()\n            return items\n        return do\n\n    def download_videos_by_offset(self, base_hostname, post_id):\n        self.init_infos(base_hostname, 'videos')\n\n        def do():\n            items = self._video(\n                base_hostname, offset=self.offset, post_id=post_id)\n            if not items:\n                return []\n            self.offset += 20\n            if not self.args.play:\n                self.save_json()\n            return items\n        return do\n\n    def download_videos_by_tag(self, base_hostname, tag):\n        self.init_infos(base_hostname, 'videos', tag)\n\n        def do():\n            items = self._video(\n                base_hostname, before=self.offset, tag=tag)\n            if not items:\n                return []\n            self.offset = items[-1]['timestamp']\n            if not self.args.play:\n                self.save_json()\n            return items\n        return do\n\n    def download_audios_by_offset(self, base_hostname, post_id):\n        self.init_infos(base_hostname, 'audios')\n\n        def do():\n            items = self._audio(\n                base_hostname, offset=self.offset if not post_id else '', post_id=post_id)\n            if not items:\n                return []\n            self.offset += 20\n            if not self.args.play:\n                self.save_json()\n            return items\n        return do\n\n    def download_audios_by_tag(self, base_hostname, tag):\n        self.init_infos(base_hostname, 'audios', tag)\n\n        def do():\n            items = self._audio(\n                base_hostname, before=self.offset, tag=tag)\n            if not self.infos['items']:\n                return []\n            self.offset = self.infos['items'][-1]['timestamp']\n            if not self.args.play:\n                self.save_json()\n            return items\n        return do\n\n    def download_photos(self, base_hostname, post_id='', tag=''):\n        if tag:\n            return self.download_photos_by_tag(base_hostname, tag)\n        else:\n            return self.download_photos_by_offset(base_hostname, post_id=post_id)\n\n    def download_videos(self, base_hostname, post_id='', tag=''):\n        if tag:\n            return self.download_videos_by_tag(base_hostname, tag)\n        else:\n            return self.download_videos_by_offset(base_hostname, post_id=post_id)\n\n    def download_audios(self, base_hostname, post_id='', tag=''):\n        if tag:\n            return self.download_audios_by_tag(base_hostname, tag)\n        else:\n            return self.download_audios_by_offset(base_hostname, post_id=post_id)\n\n    def fix_photos(self, base_hostname):\n        self.init_infos(base_hostname, 'photos')\n\n        t = os.listdir(os.path.join(self.infos['dir_'], 'photos'))\n        t = [i[:i.find('_')] for i in t if i.endswith('.tmp')]\n        self.post_ids = list(set(t))\n\n        def do():\n            if len(self.post_ids):\n                post_id = self.post_ids.pop()\n                return self._photo(base_hostname, post_id=post_id)\n            else:\n                return []\n        return do\n\n    def parse_urls(self, url):\n        _mod = re.search(r'(http://|https://|)(?P<hostname>.+\\.tumblr.com)', url)\n        if not _mod:\n            print s % (1, 91, '[Error]:'), 'url is illegal.', '\\n' + url.decode('utf8', 'ignore')\n            return lambda: []\n        base_hostname = _mod.group('hostname')\n        if self.args.check:\n            return self.fix_photos(base_hostname)\n\n        if re.search(r'post/(\\d+)', url):\n            post_id = re.search(r'post/(\\d+)', url).group(1)\n        else:\n            post_id = ''\n\n        if self.args.video:\n            return self.download_videos(base_hostname, post_id=post_id, tag=self.args.tag)\n        elif self.args.audio:\n            return self.download_audios(base_hostname, post_id=post_id, tag=self.args.tag)\n        else:\n            return self.download_photos(base_hostname, post_id=post_id, tag=self.args.tag)\n\n    def get_item_generator(self):\n        OFFSET.value = self.offset\n        items = self.make_items()\n        for item in items:\n            item['dir_'] = self.infos['dir_']\n        return items\n\ndef args_handler(argv):\n    p = argparse.ArgumentParser(\n        description='download from tumblr.com')\n    p.add_argument('xxx', type=str, nargs='*', help='命令对象.')\n    p.add_argument('-p', '--processes', action='store', type=int, default=10,\n                   help='指定多进程数,默认为10个,最多为20个 eg: -p 20')\n    p.add_argument('-f', '--offset', action='store', type=int, default=0,\n                   help='offset')\n    p.add_argument('-q', '--quiet', action='store_true',\n                   help='quiet')\n    p.add_argument('-c', '--check', action='store_true',\n                   help='尝试修复未下载成功的图片')\n    p.add_argument('-P', '--play', action='store_true',\n                   help='play with mpv')\n    p.add_argument('-V', '--video', action='store_true',\n                   help='download videos')\n    p.add_argument('-A', '--audio', action='store_true',\n                   help='download audios')\n    p.add_argument('-t', '--tag', action='store',\n                   default=None, type=str,\n                   help='下载特定tag的图片, eg: -t beautiful')\n    p.add_argument('--update', action='store_true',\n                   help='update new things')\n    p.add_argument('--redownload', action='store_true',\n                   help='redownload all things')\n    p.add_argument('-x', '--proxy', type=str,\n                   help='redownload all things')\n    args = p.parse_args(argv[1:])\n    xxx = args.xxx\n\n    if args.proxy:\n        if args.proxy[:4] not in ('http', 'sock'):\n            print s % (1, 91, '[Error]:'), 'proxy must have a protocol:// prefix'\n            sys.exit(1)\n        else:\n            global PROXY\n            PROXY = args.proxy\n\n    if args.redownload: args.update = True\n    return args, xxx\n\ndef print_msg(check):\n    time.sleep(2) # initial interval\n\n    while True:\n        msg = \"\\r%s, %s, %s, %s, %s \" % \\\n                (\n                    'D: ' + s % (1, 92, DOWNLOADS.value),\n                    'R: ' + s % (1, 93, UNCOMPLETION.value \\\n                        if not check \\\n                        else UNCOMPLETION.value - DOWNLOAD_ERRORS.value - DOWNLOADS.value),\n                    'C: ' + s % (1, 97, COMPLETION.value + DOWNLOADS.value),\n                    'NE: ' + s % (1, 91, NET_ERRORS.value),\n                    'O: %s' % OFFSET.value\n                )\n        sys.stdout.write(msg)\n        sys.stdout.flush()\n        time.sleep(2)\n\ndef sighandler(signum, frame):\n    # print s % (1, 91, \"\\n  !! Signal:\"), signum\n    # print s % (1, 91, \"  !! Frame: %s\" % frame)\n    sys.exit()\n\ndef handle_signal():\n    signal.signal(signal.SIGBUS, sighandler)\n    signal.signal(signal.SIGHUP, sighandler)\n    # http://stackoverflow.com/questions/14207708/ioerror-errno-32-broken-pipe-python\n    signal.signal(signal.SIGPIPE, signal.SIG_DFL)\n    signal.signal(signal.SIGQUIT, sighandler)\n    signal.signal(signal.SIGSYS, sighandler)\n\n    signal.signal(signal.SIGABRT, sighandler)\n    signal.signal(signal.SIGFPE, sighandler)\n    signal.signal(signal.SIGILL, sighandler)\n    signal.signal(signal.SIGINT, sighandler)\n    signal.signal(signal.SIGSEGV, sighandler)\n    signal.signal(signal.SIGTERM, sighandler)\n\ndef main(argv):\n    handle_signal()\n    args, xxx = args_handler(argv)\n\n    if args.play:\n        play(xxx, args)\n\n    lock = multiprocessing.Lock()\n    queue = multiprocessing.JoinableQueue(maxsize=args.processes)\n    thrs = []\n    for i in range(args.processes):\n        thr = Downloader(queue, lock)\n        thr.start()\n        thrs.append(thr)\n\n    # massage thread\n    msg_thr = multiprocessing.Process(target=print_msg, args=(args.check,))\n    msg_thr.daemon = True\n    msg_thr.start()\n\n    for url in xxx:\n        reset_statistic_params()\n        tumblr = Tumblr(args, url)\n        not_add = 0\n        while True:\n            items = tumblr.get_item_generator()\n            if not items:\n                break\n\n            # Check the downloaded items.\n            # It will be exited, if there is no new item to download\n            # in 5 loops, unless with --redownload\n            remove_downloaded_items(items)\n            if not args.redownload:\n                if not items:\n                    not_add += 1\n                    if not_add > 5:\n                        print s % (1, 93, '\\n[Warning]:'), \\\n                            'There is nothing new to download in 5 loops.\\n', \\\n                            'If you want to scan all resources, using --redownload\\n'  \\\n                            'or running the script again to next 5 loops.'\n                        break\n                    continue\n                else:\n                    not_add = 0\n\n            for item in items:\n                queue.put(item)\n\n    while not queue.empty():\n        time.sleep(2)\n\n    for i in range(args.processes):\n        queue.put(None)\n\n    queue.join()\n\n    for thr in thrs:\n        thr.join()\n\n    msg_thr.terminate()\n\nif __name__ == '__main__':\n    argv = sys.argv\n    main(argv)\n"
        },
        {
          "name": "unzip.py",
          "type": "blob",
          "size": 1.7109375,
          "content": "#!/usr/bin/env python2\n# -*- coding: utf-8 -*-\n\nimport os\nimport sys\nimport zipfile\nimport argparse\n\ns = '\\x1b[%d;%dm%s\\x1b[0m'       # terminual color template\n\ndef unzip(path):\n\n    file = zipfile.ZipFile(path,\"r\")\n    if args.secret:\n        file.setpassword(args.secret)\n\n    for name in file.namelist():\n        try:\n            utf8name=name.decode('gbk')\n            pathname = os.path.dirname(utf8name)\n        except:\n            utf8name=name\n            pathname = os.path.dirname(utf8name)\n\n        #print s % (1, 92, '  >> extracting:'), utf8name\n        #pathname = os.path.dirname(utf8name)\n        if not os.path.exists(pathname) and pathname != \"\":\n            os.makedirs(pathname)\n        data = file.read(name)\n        if not os.path.exists(utf8name):\n            try:\n                fo = open(utf8name, \"w\")\n                fo.write(data)\n                fo.close\n            except:\n                pass\n    file.close()\n\ndef main(argv):\n    ######################################################\n    # for argparse\n    p = argparse.ArgumentParser(description='解决unzip乱码')\n    p.add_argument('xxx', type=str, nargs='*', \\\n        help='命令对象.')\n    p.add_argument('-s', '--secret', action='store', \\\n        default=None, help='密码')\n    global args\n    args = p.parse_args(argv[1:])\n    xxx = args.xxx\n\n    for path in xxx:\n        if path.endswith('.zip'):\n            if os.path.exists(path):\n                print s % (1, 97, '  ++ unzip:'), path\n                unzip(path)\n            else:\n                print s % (1, 91, '  !! file doesn\\'t exist.'), path\n        else:\n            print s % (1, 91, '  !! file isn\\'t a zip file.'), path\n\nif __name__ == '__main__':\n    argv = sys.argv\n    main(argv)\n"
        },
        {
          "name": "xiami.py",
          "type": "blob",
          "size": 54.5908203125,
          "content": "#!/usr/bin/env python2\n# -*- coding: utf-8 -*-\n\nimport re\nimport sys\nfrom getpass import getpass\nimport os\nimport copy\nimport random\nimport time\nimport datetime\nimport json\nimport argparse\nimport requests\nimport urllib\nimport hashlib\nimport select\nfrom mutagen.id3 import ID3,TRCK,TIT2,TALB,TPE1,APIC,TDRC,COMM,TPOS,USLT\nfrom HTMLParser import HTMLParser\n\nurl_song = \"http://www.xiami.com/song/%s\"\nurl_album = \"http://www.xiami.com/album/%s\"\nurl_collect = \"http://www.xiami.com/collect/ajax-get-list\"\nurl_artist_albums = \"http://www.xiami.com/artist/album/id/%s/page/%s\"\nurl_artist_top_song = \"http://www.xiami.com/artist/top-%s\"\nurl_lib_songs = \"http://www.xiami.com/space/lib-song/u/%s/page/%s\"\nurl_recent = \"http://www.xiami.com/space/charts-recent/u/%s/page/%s\"\n\n# 电台来源:来源于\"收藏的歌曲\",\"收藏的专辑\",\"喜欢的艺人\",\"我收藏的精选集\"\nurl_radio_my = \"http://www.xiami.com/radio/xml/type/4/id/%s\"\n# 虾米猜, 基于你的虾米试听行为所建立的个性电台\nurl_radio_c = \"http://www.xiami.com/radio/xml/type/8/id/%s\"\n\n############################################################\n# wget exit status\nwget_es = {\n    0:\"No problems occurred.\",\n    2:\"User interference.\",\n    1<<8:\"Generic error code.\",\n    2<<8:\"Parse error - for instance, when parsing command-line ' \\\n        'optio.wgetrc or .netrc...\",\n    3<<8:\"File I/O error.\",\n    4<<8:\"Network failure.\",\n    5<<8:\"SSL verification failure.\",\n    6<<8:\"Username/password authentication failure.\",\n    7<<8:\"Protocol errors.\",\n    8<<8:\"Server issued an error response.\"\n}\n############################################################\n\nparser = HTMLParser()\ns = '\\x1b[%d;%dm%s\\x1b[0m'       # terminual color template\n\ncookie_file = os.path.join(os.path.expanduser('~'), '.Xiami.cookies')\n\nheaders = {\n    \"Accept\":\"text/html,application/xhtml+xml,application/xml; \" \\\n        \"q=0.9,image/webp,*/*;q=0.8\",\n    \"Accept-Encoding\":\"text/html\",\n    \"Accept-Language\":\"en-US,en;q=0.8,zh-CN;q=0.6,zh;q=0.4,zh-TW;q=0.2\",\n    \"Content-Type\":\"application/x-www-form-urlencoded\",\n    \"Referer\":\"http://www.xiami.com/\",\n    \"User-Agent\":\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36\"\\\n}\n\nHEADERS2 = {\n    'pragma': 'no-cache',\n    'accept-encoding': 'gzip, deflate, br',\n    'accept-language': 'zh-CN,zh;q=0.9,en;q=0.8,zh-TW;q=0.7',\n    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36',\n    'accept': 'text/javascript, application/javascript, application/ecmascript, application/x-ecmascript, */*; q=0.01',\n    'cache-control': 'no-cache',\n    'authority': 'www.xiami.com',\n    'x-requested-with': 'XMLHttpRequest',\n    'referer': 'https://www.xiami.com/play?ids=/song/playlist/id/',\n}\n\nss = requests.session()\nss.headers.update(headers)\n\n############################################################\n# Regular Expression Templates\nre_disc_description = r'disc (\\d+) \\[(.+?)\\]'\n############################################################\n\ndef decry(row, encryed_url):\n    url = encryed_url\n    urllen = len(url)\n    rows = int(row)\n\n    cols_base = urllen / rows  # basic column count\n    rows_ex = urllen % rows    # count of rows that have 1 more column\n\n    matrix = []\n    for r in xrange(rows):\n        length = cols_base + 1 if r < rows_ex else cols_base\n        matrix.append(url[:length])\n        url = url[length:]\n\n    url = ''\n    for i in xrange(urllen):\n        url += matrix[i % rows][i / rows]\n\n    return urllib.unquote(url).replace('^', '0')\n\ndef modificate_text(text):\n    text = parser.unescape(text)\n    text = re.sub(r'//*', '-', text)\n    text = text.replace('/', '-')\n    text = text.replace('\\\\', '-')\n    text = re.sub(r'\\s\\s+', ' ', text)\n    text = text.strip()\n    return text\n\ndef modificate_file_name_for_wget(file_name):\n    file_name = re.sub(r'\\s*:\\s*', u' - ', file_name)    # for FAT file system\n    file_name = file_name.replace('?', '')      # for FAT file system\n    file_name = file_name.replace('\"', '\\'')    # for FAT file system\n    file_name = file_name.replace('$', '\\\\$')    # for command, see issue #7\n    return file_name\n\ndef z_index(song_infos):\n    size = len(song_infos)\n    z = len(str(size))\n    return z\n\n########################################################\n\nclass Song(object):\n\n    def __init__(self):\n        self.__sure()\n        self.track = 0\n        self.year = 0\n        self.cd_serial = 0\n        self.disc_description = ''\n\n        # z = len(str(album_size))\n        self.z = 1\n\n    def __sure(self):\n        __dict__ = self.__dict__\n        if '__keys' not in __dict__:\n            __dict__['__keys'] = {}\n\n    def __getattr__(self, name):\n        __dict__ = self.__dict__\n        return __dict__['__keys'].get(name)\n\n    def __setattr__(self, name, value):\n        __dict__ = self.__dict__\n        __dict__['__keys'][name] = value\n\n    def __getitem__(self, key):\n        return getattr(self, key)\n\n    def __setitem__(self, key, value):\n        return setattr(self, key, value)\n\n    def feed(self, **kwargs):\n        for name, value in kwargs.items():\n            setattr(self, name, value)\n\n\nclass XiamiH5API(object):\n\n    URL = 'http://api.xiami.com/web'\n    PARAMS = {\n        'v': '2.0',\n        'app_key': '1',\n    }\n\n    def __init__(self):\n        self.cookies = {\n            'user_from': '2',\n            'XMPLAYER_addSongsToggler': '0',\n            'XMPLAYER_isOpen': '0',\n            '_xiamitoken': hashlib.md5(str(time.time())).hexdigest()\n        }\n        self.sess = requests.session()\n        self.sess.cookies.update(self.cookies)\n\n    def _request(self, url, method='GET', **kwargs):\n        try:\n            resp = self.sess.request(method, url, **kwargs)\n        except Exception, err:\n            print 'Error:', err\n            sys.exit()\n\n        return resp\n\n    def _make_params(self, **kwargs):\n        params = copy.deepcopy(self.PARAMS)\n        params.update(kwargs)\n        return params\n\n    def song(self, song_id):\n        params = self._make_params(id=song_id, r='song/detail')\n        url = self.URL\n        resp = self._request(url, params=params, headers=headers)\n\n        info = resp.json()['data']['song']\n        pic_url = re.sub('_\\d+\\.', '.', info['logo'])\n        song = Song()\n        song.feed(\n            song_id=info['song_id'],\n            song_name=info['song_name'],\n            album_id=info['album_id'],\n            album_name=info['album_name'],\n            artist_id=info['artist_id'],\n            artist_name=info['artist_name'],\n            singers=info['singers'],\n            album_pic_url=pic_url,\n            comment='http://www.xiami.com/song/' + str(info['song_id'])\n        )\n        return song\n\n    def album(self, album_id):\n        url = self.URL\n        params = self._make_params(id=album_id, r='album/detail')\n        resp = self._request(url, params=params, headers=headers)\n\n        info = resp.json()['data']\n        songs = []\n        album_id=info['album_id'],\n        album_name=info['album_name'],\n        artist_id = info['artist_id']\n        artist_name = info['artist_name']\n        pic_url = re.sub('_\\d+\\.', '.', info['album_logo'])\n        for track, info_n in enumerate(info['songs'], 1):\n            song = Song()\n            song.feed(\n                song_id=info_n['song_id'],\n                song_name=info_n['song_name'],\n                album_id=album_id,\n                album_name=album_name,\n                artist_id=artist_id,\n                artist_name=artist_name,\n                singers=info_n['singers'],\n                album_pic_url=pic_url,\n                track=track,\n                comment='http://www.xiami.com/song/' + str(info_n['song_id'])\n            )\n            songs.append(song)\n        return songs\n\n    def collect(self, collect_id):\n        url = self.URL\n        params = self._make_params(id=collect_id, r='collect/detail')\n        resp = self._request(url, params=params, headers=headers)\n\n        info = resp.json()['data']\n        collect_name = info['collect_name']\n        collect_id = info['list_id']\n        songs = []\n        for info_n in info['songs']:\n            pic_url = re.sub('_\\d+\\.', '.', info['album_logo'])\n            song = Song()\n            song.feed(\n                song_id=info_n['song_id'],\n                song_name=info_n['song_name'],\n                album_id=info_n['album_id'],\n                album_name=info_n['album_name'],\n                artist_id=info_n['artist_id'],\n                artist_name=info_n['artist_name'],\n                singers=info_n['singers'],\n                album_pic_url=pic_url,\n                comment='http://www.xiami.com/song/' + str(info_n['song_id'])\n            )\n            songs.append(song)\n        return collect_id, collect_name, songs\n\n    def artist_top_songs(self, artist_id, page=1, limit=20):\n        url = self.URL\n        params = self._make_params(id=artist_id, page=page, limit=limit, r='artist/hot-songs')\n        resp = self._request(url, params=params, headers=headers)\n\n        info = resp.json()['data']\n        for info_n in info['songs']:\n            song_id = info_n['song_id']\n            yield self.song(song_id)\n\n    def search_songs(self, keywords, page=1, limit=20):\n        url = self.URL\n        params = self._make_params(key=keywords, page=page, limit=limit, r='search/songs')\n        resp = self._request(url, params=params, headers=headers)\n\n        info = resp.json()['data']\n        for info_n in info['songs']:\n            pic_url = re.sub('_\\d+\\.', '.', info['album_logo'])\n            song = Song()\n            song.feed(\n                song_id=info_n['song_id'],\n                song_name=info_n['song_name'],\n                album_id=info_n['album_id'],\n                album_name=info_n['album_name'],\n                artist_id=info_n['artist_id'],\n                artist_name=info_n['artist_name'],\n                singers=info_n['singer'],\n                album_pic_url=pic_url,\n                comment='http://www.xiami.com/song/' + str(info_n['song_id'])\n            )\n            yield song\n\n    def get_song_id(self, *song_sids):\n        song_ids = []\n        for song_sid in song_sids:\n            if isinstance(song_sid, int) or song_sid.isdigit():\n                song_ids.append(int(song_sid))\n\n            url = 'https://www.xiami.com/song/playlist/id/{}/cat/json'.format(song_sid)\n            resp = self._request(url, headers=headers)\n            info = resp.json()\n            song_id = int(str(info['data']['trackList'][0]['song_id']))\n            song_ids.append(song_id)\n        return song_ids\n\n\nclass XiamiWebAPI(object):\n\n    URL = 'https://www.xiami.com/song/playlist/'\n\n    def __init__(self):\n        self.sess = requests.session()\n\n    def _request(self, url, method='GET', **kwargs):\n        try:\n            resp = self.sess.request(method, url, **kwargs)\n        except Exception, err:\n            print 'Error:', err\n            sys.exit()\n\n        return resp\n\n    def _make_song(self, info):\n        song = Song()\n\n        location=info['location']\n        row = location[0]\n        encryed_url = location[1:]\n        durl = decry(row, encryed_url)\n\n        song.feed(\n            song_id=info['song_id'],\n            song_sub_title=info['song_sub_title'],\n            songwriters=info['songwriters'],\n            singers=info['singers'],\n            song_name=parser.unescape(info['name']),\n\n            album_id=info['album_id'],\n            album_name=info['album_name'],\n\n            artist_id=info['artist_id'],\n            artist_name=info['artist_name'],\n\n            composer=info['composer'],\n            lyric_url='http:' + info['lyric_url'],\n\n            track=info['track'],\n            cd_serial=info['cd_serial'],\n            album_pic_url='http:' + info['album_pic'],\n            comment='http://www.xiami.com/song/' + str(info['song_id']),\n\n            length=info['length'],\n            play_count=info['playCount'],\n\n            location=info['location'],\n            location_url=durl\n        )\n        return song\n\n    def _find_z(self, album):\n        zs = []\n        song = album[0]\n\n        for i, song in enumerate(album[:-1]):\n            next_song = album[i+1]\n\n            cd_serial = song.cd_serial\n            next_cd_serial = next_song.cd_serial\n\n            if cd_serial != next_cd_serial:\n                z = len(str(song.track))\n                zs.append(z)\n\n        z = len(str(song.track))\n        zs.append(z)\n\n        for song in album:\n            song.z = zs[song.cd_serial - 1]\n\n    def song(self, song_id):\n        url = self.URL + 'id/%s/cat/json' % song_id\n        resp = self._request(url, headers=HEADERS2)\n\n        # there is no song\n        if not resp.json().get('data'):\n            return None\n\n        info = resp.json()['data']['trackList'][0]\n        song = self._make_song(info)\n        return song\n\n    def songs(self, *song_ids):\n        url = self.URL + 'id/%s/cat/json' % '%2C'.join(song_ids)\n        resp = self._request(url, headers=HEADERS2)\n\n        # there is no song\n        if not resp.json().get('data'):\n            return None\n\n        info = resp.json()['data']\n        songs = []\n        for info_n in info['trackList']:\n            song = self._make_song(info_n)\n            songs.append(song)\n        return songs\n\n    def album(self, album_id):\n        url = self.URL + 'id/%s/type/1/cat/json' % album_id\n        resp = self._request(url, headers=HEADERS2)\n\n        # there is no album\n        if not resp.json().get('data'):\n            return None\n\n        info = resp.json()['data']\n        songs = []\n        for info_n in info['trackList']:\n            song = self._make_song(info_n)\n            songs.append(song)\n\n        self._find_z(songs)\n        return songs\n\n    def collect(self, collect_id):\n        url = self.URL + 'id/%s/type/3/cat/json' % collect_id\n        resp = self._request(url, headers=HEADERS2)\n\n        info = resp.json()['data']\n        songs = []\n        for info_n in info['trackList']:\n            song = self._make_song(info_n)\n            songs.append(song)\n        return songs\n\n    def search_songs(self, keywords):\n        url = 'https://www.xiami.com/search?key=%s&_=%s' % (\n            urllib.quote(keywords), int(time.time() * 1000))\n        resp = self._request(url, headers=headers)\n\n        html = resp.content\n        song_ids = re.findall(r'song/(\\w+)\"', html)\n        songs = self.songs(*song_ids)\n        return songs\n\n\nclass xiami(object):\n    def __init__(self):\n        self.dir_ = os.getcwdu()\n        self.template_record = 'https://www.xiami.com/count/playrecord?sid={song_id}&ishq=1&t={time}&object_id={song_id}&object_name=default&start_point=120&_xiamitoken={token}'\n\n        self.collect_id = ''\n        self.album_id = ''\n        self.artist_id = ''\n        self.song_id = ''\n        self.user_id = ''\n        self.cover_id = ''\n        self.cover_data = ''\n\n        self.html = ''\n        self.disc_description_archives = {}\n\n        self.download = self.play if args.play else self.download\n        self._is_play = bool(args.play)\n\n        self._api = XiamiWebAPI()\n\n    def init(self):\n        if os.path.exists(cookie_file):\n            try:\n                cookies = json.load(open(cookie_file))\n                ss.cookies.update(cookies.get('cookies', cookies))\n                if not self.check_login():\n                    print s % (1, 91, '  !! cookie is invalid, please login\\n')\n                    sys.exit(1)\n            except:\n                open(cookie_file, 'w').close()\n                print s % (1, 97, '  please login')\n                sys.exit(1)\n        else:\n            print s % (1, 91, '  !! cookie_file is missing, please login')\n            sys.exit(1)\n\n    def check_login(self):\n        #print s % (1, 97, '\\n  -- check_login')\n        url = 'http://www.xiami.com/task/signin'\n        r = self._request(url)\n        if r.content:\n            #print s % (1, 92, '  -- check_login success\\n')\n            # self.save_cookies()\n            return True\n        else:\n            print s % (1, 91, '  -- login fail, please check email and password\\n')\n            return False\n\n    def _request(self, url, headers=None, params=None, data=None, method='GET', timeout=30, retry=2):\n        for _ in range(retry):\n            try:\n                headers = headers or ss.headers\n                resp = ss.request(method, url, headers=headers, params=params, data=data, timeout=timeout)\n            except Exception, err:\n                continue\n\n            if not resp.ok:\n                raise Exception(\"response is not ok, status_code = %s\" % resp.status_code)\n\n            # save cookies\n            self.save_cookies()\n\n            return resp\n        raise err\n\n    # manually, add cookies\n    # you must know how to get the cookie\n    def add_cookies(self, cookies):\n        _cookies = {}\n        for item in cookies.strip('; ').split('; '):\n            k, v = item.split('=', 1)\n            _cookies[k] = v\n        self.save_cookies(_cookies)\n        ss.cookies.update(_cookies)\n\n    def login(self, email, password):\n        print s % (1, 97, '\\n  -- login')\n\n        #validate = self.get_validate()\n        data = {\n            'email': email,\n            'password': password,\n            #'validate': validate,\n            'remember': 1,\n            'LoginButton': '登录'\n        }\n\n        hds = {\n            'Origin': 'http://www.xiami.com',\n            'Accept-Encoding': 'gzip, deflate',\n            'Accept-Language': 'en-US,en;q=0.8',\n            'Upgrade-Insecure-Requests': '1',\n            'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.116 Safari/537.36',\n            'Content-Type': 'application/x-www-form-urlencoded',\n            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n            'Cache-Control': 'max-age=1',\n            'Referer': 'http://www.xiami.com/web/login',\n            'Connection': 'keep-alive',\n            '_xiamitoken': hashlib.md5(str(time.time())).hexdigest()\n        }\n\n        url = 'https://login.xiami.com/web/login'\n\n        for i in xrange(2):\n            res = self._request(url, headers=hds, data=data)\n            if ss.cookies.get('member_auth'):\n                return True\n            else:\n                if 'checkcode' not in res.content:\n                    return False\n                validate = self.get_validate(res.content)\n                data['validate'] = validate\n\n        return False\n\n    # {{{ code from https://github.com/ly0/xiami-tools/blob/master/xiami.py\n    def login_taobao(self, username, password):\n        print s % (1, 97, '\\n  -- login taobao')\n\n        p = {\n            \"lang\": \"zh_cn\",\n            \"appName\": \"xiami\",\n            \"appEntrance\": \"taobao\",\n            \"cssLink\": \"\",\n            \"styleType\": \"vertical\",\n            \"bizParams\": \"\",\n            \"notLoadSsoView\": \"\",\n            \"notKeepLogin\": \"\",\n            \"appName\": \"xiami\",\n            \"appEntrance\": \"taobao\",\n            \"cssLink\": \"https://h.alipayobjects.com/static/applogin/\" \\\n                        \"assets/login/mini-login-form-min.css\",\n            \"styleType\": \"vertical\",\n            \"bizParams\": \"\",\n            \"notLoadSsoView\": \"true\",\n            \"notKeepLogin\": \"true\",\n            \"rnd\": str(random.random()),\n        }\n        url = 'https://passport.alipay.com/mini_login.htm'\n        r = ss.get(url, params=p, verify=True)\n        cm = r.content\n\n        data = {\n            \"loginId\": username,\n            \"password\": password,\n            \"appName\": \"xiami\",\n            \"appEntrance\": \"taobao\",\n            \"hsid\": re.search(r'\"hsid\" value=\"(.+?)\"', cm).group(1),\n            \"cid\": re.search(r'\"cid\" value=\"(.+?)\"', cm).group(1),\n            \"rdsToken\": re.search(r'\"rdsToken\" value=\"(.+?)\"', cm).group(1),\n            \"umidToken\": re.search(r'\"umidToken\" value=\"(.+?)\"', cm).group(1),\n            \"_csrf_token\": re.search(r'\"_csrf_token\" value=\"(.+?)\"', cm).group(1),\n            \"checkCode\": \"\",\n        }\n        url = 'https://passport.alipay.com/newlogin/login.do?fromSite=0'\n        theaders = headers\n        theaders['Referer'] = 'https://passport.alipay.com/mini_login.htm'\n\n        while True:\n            r = ss.post(url, data=data, headers=theaders, verify=True)\n            j = r.json()\n\n            if j['content']['status'] == -1:\n                if 'titleMsg' not in j['content']['data']: continue\n                err_msg = j['content']['data']['titleMsg']\n                if err_msg == u'请输入验证码' or err_msg == u'验证码错误，请重新输入':\n                    captcha_url = 'http://pin.aliyun.com/get_img?' \\\n                        'identity=passport.alipay.com&sessionID=%s' % data['cid']\n                    tr = self._request(captcha_url, headers=theaders)\n                    path = os.path.join(os.path.expanduser('~'), 'vcode.jpg')\n                    with open(path, 'w') as g:\n                        img = tr.content\n                        g.write(img)\n                    print \"  ++ 验证码已经保存至\", s % (2, 91, path)\n                    captcha = raw_input(\n                        (s % (2, 92, '  ++ %s: ' % err_msg)).encode('utf8'))\n                    data['checkCode'] = captcha\n                    continue\n\n            if not j['content']['data'].get('st'):\n                print s % (2, 91, \"  !! 输入的 username 或 password 有误.\")\n                sys.exit(1)\n\n            url = 'http://www.xiami.com/accounts/back?st=%s' \\\n                % j['content']['data']['st']\n            self._request(url, headers=theaders)\n\n            self.save_cookies()\n            return\n    # }}}\n\n    def get_validate(self, cn):\n        #url = 'https://login.xiami.com/coop/checkcode?forlogin=1&%s' \\\n            #% int(time.time())\n        url = re.search(r'src=\"(http.+checkcode.+?)\"', cn).group(1)\n        path = os.path.join(os.path.expanduser('~'), 'vcode.png')\n        with open(path, 'w') as g:\n            data = self._request(url).content\n            g.write(data)\n        print \"  ++ 验证码已经保存至\", s % (2, 91, path)\n        validate = raw_input(s % (2, 92, '  请输入验证码: '))\n        return validate\n\n    def save_cookies(self, cookies=None):\n        if not cookies:\n            cookies = ss.cookies.get_dict()\n        with open(cookie_file, 'w') as g:\n            json.dump(cookies, g)\n\n    def get_durl(self, id_):\n        while True:\n            try:\n                if not args.low:\n                    url = 'http://www.xiami.com/song/gethqsong/sid/%s'\n                    j = self._request(url % id_).json()\n                    t = j['location']\n                else:\n                    url = 'http://www.xiami.com/song/playlist/id/%s'\n                    cn = self._request(url % id_).text\n                    t = re.search(r'location>(.+?)</location', cn).group(1)\n                if not t: return None\n                row = t[0]\n                encryed_url = t[1:]\n                durl = decry(row, encryed_url)\n                return durl\n            except Exception, e:\n                print s % (1, 91, '  |-- Error, get_durl --'), e\n                time.sleep(5)\n\n    # FIXME, this request alway returns 405\n    def record(self, song_id, album_id):\n        return\n        #  token = ss.cookies.get('_xiamitoken', '')\n        #  t = int(time.time() * 1000)\n        #  self._request(self.template_record.format(\n            #  song_id=song_id, album_id=album_id, token=token, time=t))\n\n    def get_cover(self, info):\n        if info['album_name'] == self.cover_id:\n            return self.cover_data\n        else:\n            self.cover_id = info['album_name']\n            while True:\n                url = info['album_pic_url']\n                try:\n                    self.cover_data = self._request(url).content\n                    if self.cover_data[:5] != '<?xml':\n                        return self.cover_data\n                except Exception, e:\n                    print s % (1, 91, '   \\\\\\n   \\\\-- Error, get_cover --'), e\n                    time.sleep(5)\n\n    def get_lyric(self, info):\n        def lyric_parser(data):\n            # get ' ' from http://img.xiami.net/lyric/1_13772259457649.lrc\n            if len(data) < 10:\n                return None\n\n            if re.search(r'\\[\\d\\d:\\d\\d', data):\n                title = ' title: %s\\n' % info['song_name'].encode('utf8')\n                album = ' album: %s\\n' % info['album_name'].encode('utf8')\n                artist = 'artist: %s\\n' % info['artist_name'].encode('utf8')\n\n                tdict = {}\n                for line in data.split('\\n'):\n                    if re.search(r'^\\[\\d\\d:', line):\n                        cn = re.sub(r'\\[\\d{2}:\\d{2}\\.\\d{2}\\]', '', line)\n                        time_tags = re.findall(r'\\[\\d{2}:\\d{2}\\.\\d{2}\\]', line)\n                        for tag in time_tags: tdict[tag] = cn + '\\n'\n                time_tags = tdict.keys()\n                time_tags.sort()\n                data = ''.join([title, album, artist,\n                                '\\n------------------\\n\\n'] + \\\n                               [tdict[tag] for tag in time_tags])\n                return data\n            else:\n                # for http://img.xiami.net/lyric/upload/19/1770983119_1356864643.lrc\n                return data\n\n        url = 'http://www.xiami.com/song/playlist/id/%s' % info['song_id']\n        xml = self._request(url).content\n        t = re.search('<lyric>(http.+?)</lyric>', xml)\n        if not t: return None\n        lyric_url = t.group(1)\n        data = self._request(lyric_url).content.replace('\\r\\n', '\\n')\n        data = lyric_parser(data)\n        if data:\n            return data.decode('utf8', 'ignore')\n        else:\n            return None\n\n    def get_disc_description(self, album_url, info):\n        if not self.html:\n            self.html = self._request(album_url).text\n            t = re.findall(re_disc_description, self.html)\n            t = dict([(a, modificate_text(parser.unescape(b))) \\\n                      for a, b in t])\n            self.disc_description_archives = dict(t)\n        if self.disc_description_archives.has_key(info['cd_serial']):\n            disc_description = self.disc_description_archives[info['cd_serial']]\n            return u'(%s)' % disc_description\n        else:\n            return u''\n\n    def modified_id3(self, file_name, info):\n        id3 = ID3()\n        id3.add(TRCK(encoding=3, text=str(info['track'])))\n        id3.add(TDRC(encoding=3, text=str(info['year'])))\n        id3.add(TIT2(encoding=3, text=info['song_name']))\n        id3.add(TALB(encoding=3, text=info['album_name']))\n        id3.add(TPE1(encoding=3, text=info['artist_name']))\n        id3.add(TPOS(encoding=3, text=str(info['cd_serial'])))\n        lyric_data = self.get_lyric(info)\n        id3.add(USLT(encoding=3, text=lyric_data)) if lyric_data else None\n        #id3.add(TCOM(encoding=3, text=info['composer']))\n        #id3.add(WXXX(encoding=3, desc=u'xiami_song_url', text=info['song_url']))\n        #id3.add(TCON(encoding=3, text=u'genre'))\n        #id3.add(TSST(encoding=3, text=info['sub_title']))\n        #id3.add(TSRC(encoding=3, text=info['disc_code']))\n        id3.add(COMM(encoding=3, desc=u'Comment', \\\n            text=info['comment']))\n        id3.add(APIC(encoding=3, mime=u'image/jpeg', type=3, \\\n            desc=u'Front Cover', data=self.get_cover(info)))\n        id3.save(file_name)\n\n    def url_parser(self, urls):\n        for url in urls:\n            if '/collect/' in url:\n                self.collect_id = re.search(r'/collect/(\\w+)', url).group(1)\n                #print(s % (2, 92, u'\\n  -- 正在分析精选集信息 ...'))\n                self.download_collect()\n\n            elif '/album/' in url:\n                self.album_id = re.search(r'/album/(\\w+)', url).group(1)\n                #print(s % (2, 92, u'\\n  -- 正在分析专辑信息 ...'))\n                self.download_album()\n\n            elif '/artist/' in url or 'i.xiami.com' in url:\n                def get_artist_id(url):\n                    html = self._request(url).text\n                    artist_id = re.search(r'artist_id = \\'(\\w+)\\'', html).group(1)\n                    return artist_id\n\n                self.artist_id = re.search(r'/artist/(\\w+)', url).group(1) \\\n                    if '/artist/' in url else get_artist_id(url)\n                code = raw_input('  >> a  # 艺术家所有专辑.\\n' \\\n                    '  >> r  # 艺术家 radio\\n' \\\n                    '  >> t  # 艺术家top 20歌曲.\\n  >> ')\n                if code == 'a':\n                    #print(s % (2, 92, u'\\n  -- 正在分析艺术家专辑信息 ...'))\n                    self.download_artist_albums()\n                elif code == 't':\n                    #print(s % (2, 92, u'\\n  -- 正在分析艺术家top20信息 ...'))\n                    self.download_artist_top_20_songs()\n                elif code == 'r':\n                    self.download_artist_radio()\n                else:\n                    print(s % (1, 92, u'  --> Over'))\n\n            elif '/song/' in url:\n                self.song_id = re.search(r'/song/(\\w+)', url).group(1)\n                #print(s % (2, 92, u'\\n  -- 正在分析歌曲信息 ...'))\n                self.download_song()\n\n            elif '/u/' in url:\n                self.user_id = re.search(r'/u/(\\w+)', url).group(1)\n                code = raw_input(\n                    '  >> m   # 该用户歌曲库.\\n'\n                    '  >> c   # 最近在听\\n'\n                    '  >> s   # 分享的音乐\\n'\n                    '  >> r   # 歌曲试听排行 - 一周\\n'\n                    '  >> rt  # 歌曲试听排行 - 全部 \\n'\n                    '  >> rm  # 私人电台:来源于\"收藏的歌曲\",\"收藏的专辑\",'\n                    '           \"喜欢的艺人\",\"收藏的精选集\"\\n'\n                    '  >> rc  # 虾米猜:基于试听行为所建立的个性电台\\n  >> ')\n                if code == 'm':\n                    #print(s % (2, 92, u'\\n  -- 正在分析用户歌曲库信息 ...'))\n                    self.download_user_songs(url_lib_songs, u'收藏的歌曲')\n                elif code == 'c':\n                    self.download_user_songs(url_recent, u'最近在听的歌曲')\n                elif code == 's':\n                    url_shares = 'http://www.xiami.com' \\\n                        '/space/feed/u/%s/type/3/page/%s' % (self.user_id, '%s')\n                    self.download_user_shares(url_shares)\n                elif code == 'r':\n                    url = 'http://www.xiami.com/space/charts/u/%s/c/song/t/week' % self.user_id\n                    self.download_ranking_songs(url, 'week')\n                elif code == 'rt':\n                    url = 'http://www.xiami.com/space/charts/u/%s/c/song/t/all' % self.user_id\n                    self.download_ranking_songs(url, 'all')\n                elif code == 'rm':\n                    #print(s % (2, 92, u'\\n  -- 正在分析该用户的虾米推荐 ...'))\n                    url_rndsongs = url_radio_my\n                    self.download_user_radio(url_rndsongs)\n                elif code == 'rc':\n                    url_rndsongs = url_radio_c\n                    self.download_user_radio(url_rndsongs)\n                else:\n                    print(s % (1, 92, u'  --> Over'))\n\n            elif '/chart/' in url:\n                self.chart_id = re.search(r'/c/(\\d+)', url).group(1) \\\n                    if '/c/' in url else 101\n                type_ = re.search(r'/type/(\\d+)', url).group(1) \\\n                    if '/type/' in url else 0\n                self.download_chart(type_)\n\n            elif '/genre/' in url:\n                if '/gid/' in url:\n                    self.genre_id = re.search(r'/gid/(\\d+)', url).group(1)\n                    url_genre = 'http://www.xiami.com' \\\n                        '/genre/songs/gid/%s/page/%s'\n                elif '/sid/' in url:\n                    self.genre_id = re.search(r'/sid/(\\d+)', url).group(1)\n                    url_genre = 'http://www.xiami.com' \\\n                        '/genre/songs/sid/%s/page/%s'\n                else:\n                    print s % (1, 91, '  !! Error: missing genre id at url')\n                    sys.exit(1)\n\n                code = raw_input('  >> t  # 风格推荐\\n' \\\n                    '  >> r  # 风格radio\\n  >> ')\n                if code == 't':\n                    self.download_genre(url_genre)\n                elif code == 'r':\n                    self.download_genre_radio(url_genre)\n\n            elif 'luoo.net' in url:\n                self.hack_luoo(url)\n\n            elif 'sid=' in url:\n                _mod = re.search(r'sid=([\\w+,]+\\w)', url)\n                if _mod:\n                    song_ids = _mod.group(1).split(',')\n                    self.download_songs(song_ids)\n\n            else:\n                print s % (2, 91, u'   请正确输入虾米网址.')\n\n    def make_file_name(self, song, cd_serial_auth=False):\n        z = song['z']\n        file_name = str(song['track']).zfill(z) + '.' \\\n            + song['song_name'] \\\n            + ' - ' + song['artist_name'] + '.mp3'\n        if cd_serial_auth:\n            song['file_name'] = ''.join([\n                '[Disc-',\n                str(song['cd_serial']),\n                ' # ' + song['disc_description'] \\\n                    if song['disc_description'] else '', '] ',\n                file_name])\n        else:\n            song['file_name'] = file_name\n\n    def get_songs(self, album_id, song_id=None):\n        songs = self._api.album(album_id)\n\n        if not songs:\n            return []\n\n        cd_serial_auth = int(songs[-1]['cd_serial']) > 1\n        for song in songs:\n            self.make_file_name(song, cd_serial_auth=cd_serial_auth)\n\n        songs = [i for i in songs if i['song_id'] == song_id] \\\n                 if song_id else songs\n        return songs\n\n    def get_song(self, song_id):\n        song = self._api.song(song_id)\n\n        if not song:\n            return []\n\n        self.make_file_name(song)\n        return [song]\n\n    def download_song(self):\n        songs = self.get_song(self.song_id)\n        print(s % (2, 97, u'\\n  >> ' + u'1 首歌曲将要下载.')) \\\n            if not args.play else ''\n        #self.song_infos = [song_info]\n        self.download(songs)\n\n    def download_songs(self, song_ids):\n        for song_id in song_ids:\n            self.song_id = song_id\n            songs = self.get_song(self.song_id)\n            self.download(songs)\n\n    def download_album(self):\n        songs = self.get_songs(self.album_id)\n        if not songs:\n            return\n\n        song = songs[0]\n\n        d = song['album_name'] + ' - ' + song['artist_name']\n        dir_ = os.path.join(os.getcwdu(), d)\n        self.dir_ = modificate_file_name_for_wget(dir_)\n\n        amount_songs = unicode(len(songs))\n        songs = songs[args.from_ - 1:]\n        print(s % (2, 97, u'\\n  >> ' + amount_songs + u' 首歌曲将要下载.')) \\\n            if not args.play else ''\n        self.download(songs, amount_songs, args.from_)\n\n    def download_collect(self):\n        page = 1\n        song_ids = []\n        while True:\n            params = {\n                'id': self.collect_id,\n                'p': page,\n                'limit': 50,\n            }\n            infos = self._request(url_collect, params=params).json()\n            for info in infos['result']['data']:\n                song_ids.append(str(info['song_id']))\n\n            if infos['result']['total_page'] == page:\n                break\n            page += 1\n\n        html = self._request('http://www.xiami.com/collect/%s' % self.collect_id).text\n        html = html.split('<div id=\"wall\"')[0]\n        collect_name = re.search(r'<title>(.+?)<', html).group(1)\n        d = collect_name\n        dir_ = os.path.join(os.getcwdu(), d)\n        self.dir_ = modificate_file_name_for_wget(dir_)\n        amount_songs = unicode(len(song_ids))\n        song_ids = song_ids[args.from_ - 1:]\n        print(s % (2, 97, u'\\n  >> ' + amount_songs + u' 首歌曲将要下载.')) \\\n            if not args.play else ''\n        n = args.from_\n        for i in song_ids:\n            songs = self.get_song(i)\n            self.download(songs, amount_songs, n)\n            self.html = ''\n            self.disc_description_archives = {}\n            n += 1\n\n    def download_artist_albums(self):\n        ii = 1\n        album_ids = []\n        while True:\n            html = self._request(\n                url_artist_albums % (self.artist_id, str(ii))).text\n            t = re.findall(r'/album/(\\w+)\"', html)\n            if album_ids == t: break\n            album_ids = t\n            if album_ids:\n                for i in album_ids:\n                    print '  ++ http://www.xiami.com/album/%s' % i\n                    self.album_id = i\n                    self.download_album()\n                    self.html = ''\n                    self.disc_description_archives = {}\n            else:\n                break\n            ii += 1\n\n    def download_artist_top_20_songs(self):\n        html = self._request(url_artist_top_song % self.artist_id).text\n        song_ids = re.findall(r'/music/send/id/(\\d+)', html)\n        artist_name = re.search(\n            r'<p><a href=\"/artist/\\w+\">(.+?)<', html).group(1)\n        d = modificate_text(artist_name + u' - top 20')\n        dir_ = os.path.join(os.getcwdu(), d)\n        self.dir_ = modificate_file_name_for_wget(dir_)\n        amount_songs = unicode(len(song_ids))\n        print(s % (2, 97, u'\\n  >> ' + amount_songs + u' 首歌曲将要下载.')) \\\n            if not args.play else ''\n        n = 1\n        for i in song_ids:\n            songs = self.get_song(i)\n            self.download(songs, amount_songs, n)\n            self.html = ''\n            self.disc_description_archives = {}\n            n += 1\n\n    def download_artist_radio(self):\n        html = self._request(url_artist_top_song % self.artist_id).text\n        artist_name = re.search(\n            r'<p><a href=\"/artist/\\w+\">(.+?)<', html).group(1)\n        d = modificate_text(artist_name + u' - radio')\n        dir_ = os.path.join(os.getcwdu(), d)\n        self.dir_ = modificate_file_name_for_wget(dir_)\n\n        url_artist_radio = \"http://www.xiami.com/radio/xml/type/5/id/%s\" \\\n            % self.artist_id\n        n = 1\n        while True:\n            xml = self._request(url_artist_radio).text\n            song_ids = re.findall(r'<song_id>(\\d+)', xml)\n            for i in song_ids:\n                songs = self.get_song(i)\n                self.download(songs, n=n)\n                self.html = ''\n                self.disc_description_archives = {}\n                n += 1\n\n    def download_user_songs(self, url, desc):\n        dir_ = os.path.join(os.getcwdu(),\n            u'虾米用户 %s %s' % (self.user_id, desc))\n        self.dir_ = modificate_file_name_for_wget(dir_)\n        ii = 1\n        n = 1\n        while True:\n            html = self._request(url % (self.user_id, str(ii))).text\n            song_ids = re.findall(r'/song/(.+?)\"', html)\n            if song_ids:\n                for i in song_ids:\n                    songs = self.get_song(i)\n                    self.download(songs, n)\n                    self.html = ''\n                    self.disc_description_archives = {}\n                    n += 1\n            else:\n                break\n            ii += 1\n\n    def download_user_shares(self, url_shares):\n        d = modificate_text(u'%s 的分享' % self.user_id)\n        dir_ = os.path.join(os.getcwdu(), d)\n        self.dir_ = modificate_file_name_for_wget(dir_)\n        page = 1\n        while True:\n            html = self._request(url_shares % page).text\n            shares = re.findall(r'play.*\\(\\'\\d+\\'\\)', html)\n            for share in shares:\n                if 'album' in share:\n                    self.album_id = re.search(r'\\d+', share).group()\n                    self.download_album()\n                else:\n                    self.song_id = re.search(r'\\d+', share).group()\n                    self.download_song()\n            if not shares: break\n            page += 1\n\n    def download_ranking_songs(self, url, tp):\n        d = modificate_text(u'%s 的试听排行 - %s' % (self.user_id, tp))\n        dir_ = os.path.join(os.getcwdu(), d)\n        self.dir_ = modificate_file_name_for_wget(dir_)\n        page = 1\n        n = 1\n        while True:\n            html = self._request(url + '/page/' + str(page)).text\n            song_ids = re.findall(r\"play\\('(\\d+)'\", html)\n            if not song_ids:\n                break\n            for song_id in song_ids:\n                songs = self.get_song(song_id)\n                self.download(songs, n=n)\n                self.html = ''\n                self.disc_description_archives = {}\n                n += 1\n            page += 1\n\n    def download_user_radio(self, url_rndsongs):\n        d = modificate_text(u'%s 的虾米推荐' % self.user_id)\n        dir_ = os.path.join(os.getcwdu(), d)\n        self.dir_ = modificate_file_name_for_wget(dir_)\n        n = 1\n        while True:\n            xml = self._request(url_rndsongs % self.user_id).text\n            song_ids = re.findall(r'<song_id>(\\d+)', xml)\n            for i in song_ids:\n                songs = self.get_song(i)\n                self.download(songs, n=n)\n                self.html = ''\n                self.disc_description_archives = {}\n                n += 1\n\n    def download_chart(self, type_):\n        html = self._request('http://www.xiami.com/chart/index/c/%s' \\\n                      % self.chart_id).text\n        title = re.search(r'<title>(.+?)</title>', html).group(1)\n        d = modificate_text(title)\n        dir_ = os.path.join(os.getcwdu(), d)\n        self.dir_ = modificate_file_name_for_wget(dir_)\n\n        html = self._request(\n            'http://www.xiami.com/chart/data?c=%s&limit=200&type=%s' \\\n            % (self.chart_id, type_)).text\n        song_ids = re.findall(r'/song/(\\d+)', html)\n        n = 1\n        for i in song_ids:\n            songs = self.get_song(i)\n            self.download(songs, n=n)\n            self.html = ''\n            self.disc_description_archives = {}\n            n += 1\n\n    def download_genre(self, url_genre):\n        html = self._request(url_genre % (self.genre_id, 1)).text\n        if '/gid/' in url_genre:\n            t = re.search(\n                r'/genre/detail/gid/%s\".+?title=\"(.+?)\"' \\\n                % self.genre_id, html).group(1)\n        elif '/sid/' in url_genre:\n            t = re.search(\n                r'/genre/detail/sid/%s\" title=\"(.+?)\"' \\\n                % self.genre_id, html).group(1)\n        d = modificate_text(u'%s - 代表曲目 - xiami' % t)\n        dir_ = os.path.join(os.getcwdu(), d)\n        self.dir_ = modificate_file_name_for_wget(dir_)\n\n        n = 1\n        page = 2\n        while True:\n            song_ids = re.findall(r'/song/(\\d+)', html)\n            if not song_ids: break\n            for i in song_ids:\n                songs = self.get_song(i)\n                self.download(songs, n=n)\n                self.html = ''\n                self.disc_description_archives = {}\n                n += 1\n            html = self._request(url_genre % (self.chart_id, page)).text\n            page += 1\n\n    def download_genre_radio(self, url_genre):\n        html = self._request(url_genre % (self.genre_id, 1)).text\n        if '/gid/' in url_genre:\n            t = re.search(\n                r'/genre/detail/gid/%s\".+?title=\"(.+?)\"' \\\n                % self.genre_id, html).group(1)\n            url_genre_radio = \"http://www.xiami.com/radio/xml/type/12/id/%s\" \\\n                % self.genre_id\n        elif '/sid/' in url_genre:\n            t = re.search(\n                r'/genre/detail/sid/%s\" title=\"(.+?)\"' \\\n                % self.genre_id, html).group(1)\n            url_genre_radio = \"http://www.xiami.com/radio/xml/type/13/id/%s\" \\\n                % self.genre_id\n        d = modificate_text(u'%s - radio - xiami' % t)\n        dir_ = os.path.join(os.getcwdu(), d)\n        self.dir_ = modificate_file_name_for_wget(dir_)\n\n        n = 1\n        while True:\n            xml = self._request(url_genre_radio).text\n            song_ids = re.findall(r'<song_id>(\\d+)', xml)\n            for i in song_ids:\n                songs = self.get_song(i)\n                self.download(songs, n=n)\n                self.html = ''\n                self.disc_description_archives = {}\n                n += 1\n\n    def hack_luoo(self, url):\n        # parse luoo.net\n        theaders = headers\n        theaders.pop('Referer')\n        r = requests.get(url)\n        if not r.ok:\n            return None\n        cn = r.content\n        songs_info = re.findall(r'<p class=\"name\">(.+?)</p>\\s+'\n                                r'<p class=\"artist\">(?:Artist:|艺人：)(.+?)</p>\\s+'\n                                r'<p class=\"album\">(?:Album:|专辑：)(.+?)</p>', cn)\n\n        # search song at xiami\n        for name, artist, album in songs_info:\n            name = name.strip()\n            artist = artist.strip()\n            album = album.strip()\n\n            songs = self._api.search_songs(name + ' ' + artist)\n            if not songs:\n                print s % (1, 93, '  !! no find:'), ' - '.join([name, artist, album])\n                continue\n\n            self.make_file_name(songs[0])\n            self.download(songs[:1], n=1)\n\n    def display_infos(self, i, nn, n, durl):\n        length = datetime.datetime.fromtimestamp(i['length']).strftime('%M:%S')\n        print n, '/', nn\n        print s % (2, 94, i['file_name'])\n        print s % (2, 95, i['album_name'])\n        print s % (2, 93, length)\n        print 'http://www.xiami.com/song/%s' % i['song_id']\n        print 'http://www.xiami.com/album/%s' % i['album_id']\n        print durl\n        if i['durl_is_H'] == 'h':\n            print s % (1, 97, 'MP3-Quality:'), s % (1, 92, 'High')\n        else:\n            print s % (1, 97, 'MP3-Quality:'), s % (1, 91, 'Low')\n        print '—' * int(os.popen('tput cols').read())\n\n    def get_mp3_quality(self, durl):\n        if 'm3.file.xiami.com' in durl \\\n                or 'm6.file.xiami.com' in durl \\\n                or '_h.mp3' in durl \\\n                or 'm320.xiami.net' in durl:\n            return 'h'\n        else:\n            return 'l'\n\n    def play(self, songs, nn=u'1', n=1):\n        if args.play == 2:\n            songs = sorted(songs, key=lambda k: k['play_count'], reverse=True)\n\n        for i in songs:\n            self.record(i['song_id'], i['album_id'])\n            durl = self.get_durl(i['song_id'])\n            if not durl:\n                print s % (2, 91, '  !! Error: can\\'t get durl'), i['song_name']\n                continue\n\n            cookies = '; '.join(['%s=%s' % (k, v) for k, v in ss.cookies.items()])\n            mp3_quality = self.get_mp3_quality(durl)\n            i['durl_is_H'] = mp3_quality\n            self.display_infos(i, nn, n, durl)\n            n = int(n) + 1\n            cmd = 'mpv --really-quiet ' \\\n                '--cache 8146 ' \\\n                '--user-agent \"%s\" ' \\\n                '--http-header-fields \"Referer: http://img.xiami.com' \\\n                '/static/swf/seiya/1.4/player.swf?v=%s\",' \\\n                '\"Cookie: %s\" ' \\\n                '\"%s\"' \\\n                % (headers['User-Agent'], int(time.time()*1000), cookies, durl)\n            os.system(cmd)\n            timeout = 1\n            ii, _, _ = select.select([sys.stdin], [], [], timeout)\n            if ii:\n                sys.exit(0)\n            else:\n                pass\n\n    def download(self, songs, amount_songs=u'1', n=1):\n        dir_ = modificate_file_name_for_wget(self.dir_)\n        cwd = os.getcwd()\n        if dir_ != cwd:\n            if not os.path.exists(dir_):\n                os.mkdir(dir_)\n\n\n        ii = 1\n        for i in songs:\n            num = random.randint(0, 100) % 8\n            col = s % (2, num + 90, i['file_name'])\n            t = modificate_file_name_for_wget(i['file_name'])\n            file_name = os.path.join(dir_, t)\n            if os.path.exists(file_name):  ## if file exists, no get_durl\n                if args.undownload:\n                    self.modified_id3(file_name, i)\n                    ii += 1\n                    n += 1\n                    continue\n                else:\n                    ii += 1\n                    n += 1\n                    continue\n\n            if not args.undownload:\n                if n == None:\n                    print(u'\\n  ++ download: #%s/%s# %s' \\\n                        % (ii, amount_songs, col))\n                else:\n                    print(u'\\n  ++ download: #%s/%s# %s' \\\n                        % (n, amount_songs, col))\n                    n += 1\n\n                durl = self.get_durl(i['song_id'])\n                if not durl:\n                    print s % (2, 91, '  |-- Error: can\\'t get durl')\n                    continue\n\n                mp3_quality = self.get_mp3_quality(durl)\n                if mp3_quality == 'h':\n                    print '  |--', s % (1, 97, 'MP3-Quality:'), s % (1, 91, 'High')\n                else:\n                    print '  |--', s % (1, 97, 'MP3-Quality:'), s % (1, 91, 'Low')\n\n                cookies = '; '.join(['%s=%s' % (k, v) for k, v in ss.cookies.items()])\n                file_name_for_wget = file_name.replace('`', '\\`')\n                quiet = ' -q' if args.quiet else ' -nv'\n                cmd = 'wget -c%s ' \\\n                    '-U \"%s\" ' \\\n                    '--header \"Referer:http://img.xiami.com' \\\n                    '/static/swf/seiya/1.4/player.swf?v=%s\" ' \\\n                    '--header \"Cookie: member_auth=%s\" ' \\\n                    '-O \"%s.tmp\" %s' \\\n                    % (quiet, headers['User-Agent'], int(time.time()*1000), cookies, file_name_for_wget, durl)\n                cmd = cmd.encode('utf8')\n                status = os.system(cmd)\n                if status != 0:     # other http-errors, such as 302.\n                    wget_exit_status_info = wget_es[status]\n                    print('\\n\\n ----###   \\x1b[1;91mERROR\\x1b[0m ==> \\x1b[1;91m%d ' \\\n                        '(%s)\\x1b[0m   ###--- \\n\\n' % (status, wget_exit_status_info))\n                    print s % (1, 91, '  ===> '), cmd\n                    sys.exit(1)\n                else:\n                    os.rename('%s.tmp' % file_name, file_name)\n\n            self.modified_id3(file_name, i)\n            ii += 1\n            time.sleep(5)\n\n    def _save_do(self, id_, type, tags):\n        data = {\n            \"tags\": tags,\n            \"type\": type,\n            \"id\": id_,\n            \"desc\": \"\",\n            \"grade\": \"\",\n            \"share\": 0,\n            \"shareTo\": \"all\",\n            \"_xiamitoken\": ss.cookies['_xiamitoken'],\n        }\n        url = 'https://www.xiami.com/ajax/addtag'\n        r = self._request(url, data=data, method='POST')\n        j = r.json()\n        if j['status'] == 'ok':\n            return 0\n        else:\n            return j['status']\n\n    def save(self, urls):\n        tags = args.tags\n        for url in urls:\n            if '/collect/' in url:\n                collect_id = re.search(r'/collect/(\\w+)', url).group(1)\n                print s % (1, 97, u'\\n  ++ save collect:'), \\\n                    'http://www.xiami.com/song/collect/' + collect_id\n                result = self._save_do(collect_id, 4, tags)\n\n            elif '/album/' in url:\n                album_id = re.search(r'/album/(\\w+)', url).group(1)\n                album = self._api.album(album_id)\n                album_id = album[0].album_id\n                print s % (1, 97, u'\\n  ++ save album:'), \\\n                    'http://www.xiami.com/album/' + str(album_id)\n                result = self._save_do(album_id, 5, tags)\n\n            elif '/artist/' in url:\n                artist_id = re.search(r'/artist/(\\w+)', url).group(1)\n                print s % (1, 97, u'\\n  ++ save artist:'), \\\n                    'http://www.xiami.com/artist/' + artist_id\n                result = self._save_do(artist_id, 6, tags)\n\n            elif '/song/' in url:\n                song_id = re.search(r'/song/(\\w+)', url).group(1)\n                song = self._api.song(song_id)\n                song_id = song.song_id\n                print s % (1, 97, u'\\n  ++ save song:'), \\\n                    'http://www.xiami.com/song/' + str(song_id)\n                result = self._save_do(song_id, 3, tags)\n\n            elif '/u/' in url:\n                user_id = re.search(r'/u/(\\d+)', url).group(1)\n                print s % (1, 97, u'\\n  ++ save user:'), \\\n                    'http://www.xiami.com/u/' + user_id\n                result = self._save_do(user_id, 1, tags)\n\n            else:\n                result = -1\n                print(s % (2, 91, u'   请正确输入虾米网址.'))\n\n            if result == 0:\n                print s % (1, 92, '  ++ success.\\n')\n            else:\n                print s % (1, 91, '  !! Error at _save_do.'), result, '\\n'\n\ndef main(argv):\n    if len(argv) < 2:\n        sys.exit()\n\n    ######################################################\n    # for argparse\n    p = argparse.ArgumentParser(description='downloading any xiami.com')\n    p.add_argument('xxx', type=str, nargs='*', \\\n        help='命令对象.')\n    p.add_argument('-p', '--play', action='count', \\\n        help='play with mpv')\n    p.add_argument('-l', '--low', action='store_true', \\\n        help='low mp3')\n    p.add_argument('-q', '--quiet', action='store_true', \\\n        help='quiet for download')\n    p.add_argument('-f', '--from_', action='store', \\\n        default=1, type=int, \\\n        help='从第几个开始下载，eg: -f 42')\n    p.add_argument('-d', '--undescription', action='store_true', \\\n        help='no add disk\\'s distribution')\n    p.add_argument('-t', '--tags', action='store', \\\n        type=str, default='', help='tags. eg: piano,cello')\n    p.add_argument('-n', '--undownload', action='store_true', \\\n        help='no download, using to renew id3 tags')\n    global args\n    args = p.parse_args(argv[2:])\n    comd = argv[1]\n    xxx = args.xxx\n\n    if comd == 'login' or comd == 'g':\n        # or comd == 'logintaobao' or comd == 'gt':\n        # taobao has updated login algorithms which is hard to hack\n        # so remove it.\n        if len(xxx) < 1:\n            email = raw_input(s % (1, 97, '  username: ') \\\n                if comd == 'logintaobao' or comd == 'gt' \\\n                else s % (1, 97, '     email: '))\n            cookies = getpass(s % (1, 97, '  cookies: '))\n        elif len(xxx) == 1:\n            # for add_member_auth\n            if '; ' in xxx[0]:\n                email = None\n                cookies = xxx[0]\n            else:\n                email = xxx[0]\n                cookies = getpass(s % (1, 97, '  cookies: '))\n        elif len(xxx) == 2:\n            email = xxx[0]\n            cookies = xxx[1]\n        else:\n            msg = ('login: \\n'\n                   'login cookies')\n            print s % (1, 91, msg)\n            return\n\n        x = xiami()\n        x.add_cookies(cookies)\n        is_signin = x.check_login()\n        if is_signin:\n            print s % (1, 92, '  ++ login succeeds.')\n        else:\n            print s % (1, 91, '  login failes')\n\n    elif comd == 'signout':\n        g = open(cookie_file, 'w')\n        g.close()\n\n    elif comd == 'd' or comd == 'download':\n        urls = xxx\n        x = xiami()\n        x.init()\n        x.url_parser(urls)\n\n    elif comd == 'p' or comd == 'play':\n        if not args.play: args.play = 1\n        urls = xxx\n        x = xiami()\n        x.init()\n        x.url_parser(urls)\n\n    elif comd == 's' or comd == 'save':\n        urls = xxx\n        x = xiami()\n        x.init()\n        x.save(urls)\n\n    else:\n        print s % (2, 91, u'  !! 命令错误\\n')\n\nif __name__ == '__main__':\n    argv = sys.argv\n    main(argv)\n"
        },
        {
          "name": "yunpan.360.cn.py",
          "type": "blob",
          "size": 12.1416015625,
          "content": "#!/usr/bin/env python2\n# vim: set fileencoding=utf8\n\nimport os\nimport sys\nfrom getpass import getpass\nimport requests\nimport urllib\nimport json\nimport re\nimport time\nimport argparse\nimport random\nimport md5\n\n############################################################\n# wget exit status\nwget_es = {\n    0: \"No problems occurred.\",\n    2: \"User interference.\",\n    1<<8: \"Generic error code.\",\n    2<<8: \"Parse error - for instance, when parsing command-line \" \\\n        \"optio.wgetrc or .netrc...\",\n    3<<8: \"File I/O error.\",\n    4<<8: \"Network failure.\",\n    5<<8: \"SSL verification failure.\",\n    6<<8: \"Username/password authentication failure.\",\n    7<<8: \"Protocol errors.\",\n    8<<8: \"Server issued an error response.\"\n}\n############################################################\n\ns = '\\x1b[%d;%dm%s\\x1b[0m'       # terminual color template\n\ncookie_file = os.path.join(os.path.expanduser('~'), '.360.cookies')\n\nheaders = {\n    \"Accept\":\"text/html,application/xhtml+xml,application/xml; \" \\\n        \"q=0.9,image/webp,*/*;q=0.8\",\n    \"Accept-Encoding\":\"text/html\",\n    \"Accept-Language\":\"en-US,en;q=0.8,zh-CN;q=0.6,zh;q=0.4,zh-TW;q=0.2\",\n    \"Content-Type\":\"application/x-www-form-urlencoded\",\n    \"Referer\":\"http://yunpan.360.cn/\",\n    \"X-Requested-With\":\"XMLHttpRequest\",\n    \"User-Agent\":\"Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.36 \"\\\n        \"(KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"\n}\n\nss = requests.session()\nss.headers.update(headers)\n\nclass yunpan360(object):\n    def init(self):\n        if os.path.exists(cookie_file):\n            try:\n                t = json.loads(open(cookie_file).read())\n                ss.cookies.update(t.get('cookies', t))\n                if not self.check_login():\n                    print s % (1, 91, '  !! cookie is invalid, please login\\n')\n                    sys.exit(1)\n            except:\n                g = open(cookie_file, 'w')\n                g.close()\n                print s % (1, 97, '  please login')\n                sys.exit(1)\n        else:\n            print s % (1, 91, '  !! cookie_file is missing, please login')\n            sys.exit(1)\n\n    def get_path(self, url):\n        url = urllib.unquote_plus(url)\n        f = re.search(r'#(.+?)(&|$)', url)\n        if f:\n            return f.group(1)\n        else:\n            return '/'\n\n    def check_login(self):\n        #print s % (1, 97, '\\n  -- check_login')\n        url = 'http://yunpan.360.cn/user/login?st=774'\n        r = ss.get(url)\n        self.save_cookies()\n\n        if r.ok:\n            #print s % (1, 92, '  -- check_login success\\n')\n\n            # get apihost\n            self.apihost = re.search(r'http://(.+?)/', r.url).group(1).encode('utf8')\n            self.save_cookies()\n            return True\n        else:\n            print s % (1, 91, '  -- check_login fail\\n')\n            return False\n\n    def login(self, username, password):\n        print s % (1, 97, '\\n  -- login')\n\n        # get token\n        params = {\n            \"o\": \"sso\",\n            \"m\": \"getToken\",\n            \"func\": \"QHPass.loginUtils.tokenCallback\",\n            \"userName\": username,\n            \"rand\": random.random()\n        }\n        url = 'https://login.360.cn'\n        r = ss.get(url, params=params)\n        token = re.search(r'token\":\"(.+?)\"', r.content).group(1)\n\n        # now loin\n        params = {\n            \"o\": \"sso\",\n            \"m\": \"login\",\n            \"requestScema\": \"http\",\n            \"from\": \"pcw_cloud\",\n            \"rtype\": \"data\",\n            \"func\": \"QHPass.loginUtils.loginCallback\",\n            \"userName\": username,\n            \"pwdmethod\": 1,\n            \"isKeepAlive\": 0,\n            \"token\": token,\n            \"captFlag\": 1,\n            \"captId\": \"i360\",\n            \"captCode\": \"\",\n            \"lm\": 0,\n            \"validatelm\": 0,\n            \"password\": md5.new(password).hexdigest(),\n            \"r\": int(time.time()*1000)\n        }\n        url = 'https://login.360.cn'\n        ss.get(url, params=params)\n        self.save_cookies()\n\n    def save_cookies(self):\n        with open(cookie_file, 'w') as g:\n            c = {'cookies': ss.cookies.get_dict()}\n            g.write(json.dumps(c, indent=4, sort_keys=True))\n\n    def get_dlink(self, i):\n        data = 'nid=%s&fname=%s&' % (i['nid'].encode('utf8'), \\\n            urllib.quote_plus(i['path'].encode('utf8')))\n        apiurl = 'http://%s/file/download' % self.apihost\n        r = ss.post(apiurl, data=data)\n        j = r.json()\n        if j['errno'] == 0:\n            dlink = j['data']['download_url'].encode('utf8')\n            return dlink\n\n    def fix_json(self, ori):\n        # 万恶的 360，返回的json尽然不合法。\n        jdata = re.search(r'data:\\s*\\[.+?\\]', ori).group()\n        jlist = re.split(r'\\}\\s*,\\s*\\{', jdata)\n        jlist = [l for l in jlist if l.strip()]\n        j = []\n        for item in jlist:\n            nid = re.search(r',nid: \\'(\\d+)\\'', item)\n            path = re.search(r',path: \\'(.+?)\\',nid', item)\n            name = re.search(r'oriName: \\'(.+?)\\',path', item)\n            isdir = 'isDir: ' in item\n            if nid:\n                t = {\n                    'nid': nid.group(1),\n                    'path': path.group(1).replace(\"\\\\'\", \"'\"),\n                    'name': name.group(1).replace(\"\\\\'\", \"'\"),\n                    'isdir': 1 if isdir else 0\n                }\n                j.append(t)\n        return j\n\n    def get_infos(self):\n        apiurl = 'http://%s/file/list' % self.apihost\n        data = \"type\" + \"=2\" + \"&\" \\\n            \"t\" + \"=%s\" % random.random() + \"&\" \\\n            \"order\" + \"=asc\" + \"&\" \\\n            \"field\" + \"=file_name\" + \"&\" \\\n            \"path\" + \"=%s\" + \"&\" \\\n            \"page\" + \"=0\" + \"&\" \\\n            \"page_size\" + \"=10000\" + \"&\" \\\n            \"ajax\" + \"=1\"\n\n        dir_loop = [self.path]\n        base_dir = os.path.split(self.path[:-1])[0] if self.path[-1] == '/' \\\n            and self.path != '/' else os.path.split(self.path)[0]\n        for d in dir_loop:\n            data = data % urllib.quote_plus(d)\n            r = ss.post(apiurl, data=data)\n            j = self.fix_json(r.text.strip())\n            if j:\n                if args.type_:\n                    j = [x for x in j if x['isdir'] \\\n                        or x['name'][-len(args.type_):] \\\n                        == unicode(args.type_)]\n                total_file = len([i for i in j if not i['isdir']])\n                if args.from_ - 1:\n                    j = j[args.from_-1:] if args.from_ else j\n                nn = args.from_\n                for i in j:\n                    if i['isdir']:\n                        dir_loop.append(i['path'].encode('utf8'))\n                    else:\n                        t = i['path'].encode('utf8')\n                        t = t.replace(base_dir, '')\n                        t = t[1:] if t[0] == '/' else t\n                        t =  os.path.join(os.getcwd(), t)\n                        infos = {\n                            'file': t,\n                            'dir_': os.path.split(t)[0],\n                            'dlink': self.get_dlink(i),\n                            'name': i['name'].encode('utf8'),\n                            'apihost': self.apihost,\n                            'nn': nn,\n                            'total_file': total_file\n                        }\n                        nn += 1\n                        self.download(infos)\n            else:\n                print s % (1, 91, '  error: get_infos')\n                sys.exit(0)\n\n    @staticmethod\n    def download(infos):\n        #### !!!! 注意：360不支持断点续传\n\n        ## make dirs\n        if not os.path.exists(infos['dir_']):\n            os.makedirs(infos['dir_'])\n        else:\n            if os.path.exists(infos['file']):\n                return 0\n\n        num = random.randint(0, 7) % 8\n        col = s % (2, num + 90, infos['file'])\n        infos['nn'] = infos['nn'] if infos.get('nn') else 1\n        infos['total_file'] = infos['total_file'] if infos.get('total_file') else 1\n        print '\\n  ++ 正在下载: #', s % (1, 97, infos['nn']), '/', s % (1, 97, infos['total_file']), '#', col\n\n        cookie = '; '.join(['%s=%s' % (x, y) for x, y in ss.cookies.items()]).encode('utf8')\n        if args.aria2c:\n            if args.limit:\n                cmd = 'aria2c -c -s10 -x10 ' \\\n                    '--max-download-limit %s ' \\\n                    '-o \"%s.tmp\" -d \"%s\" ' \\\n                    '--user-agent \"%s\" ' \\\n                    '--header \"Cookie:%s\" ' \\\n                    '--header \"Referer:http://%s/\" \"%s\"' \\\n                    % (args.limit, infos['name'], infos['dir_'],\\\n                        headers['User-Agent'], cookie, infos['apihost'], infos['dlink'])\n            else:\n                cmd = 'aria2c -c -s10 -x10 ' \\\n                    '-o \"%s.tmp\" -d \"%s\" --user-agent \"%s\" ' \\\n                    '--header \"Cookie:%s\" ' \\\n                    '--header \"Referer:http://%s/\" \"%s\"' \\\n                    % (infos['name'], infos['dir_'], headers['User-Agent'], \\\n                        cookie, infos['apihost'], infos['dlink'])\n        else:\n            if args.limit:\n                cmd = 'wget -c --limit-rate %s ' \\\n                    '-O \"%s.tmp\" --user-agent \"%s\" ' \\\n                    '--header \"Cookie:%s\" ' \\\n                    '--header \"Referer:http://%s/\" \"%s\"' \\\n                    % (args.limit, infos['file'], headers['User-Agent'], \\\n                        cookie, infos['apihost'], infos['dlink'])\n            else:\n                cmd = 'wget -c -O \"%s.tmp\" --user-agent \"%s\" ' \\\n                    '--header \"Cookie:%s\" ' \\\n                    '--header \"Referer:http://%s/\" \"%s\"' \\\n                    % (infos['file'], headers['User-Agent'], \\\n                       cookie, infos['apihost'], infos['dlink'])\n\n        status = os.system(cmd)\n        if status != 0:     # other http-errors, such as 302.\n            wget_exit_status_info = wget_es[status]\n            print('\\n\\n ---###   \\x1b[1;91mERROR\\x1b[0m ==> '\\\n                '\\x1b[1;91m%d (%s)\\x1b[0m   ###--- \\n\\n' \\\n                 % (status, wget_exit_status_info))\n            print s % (1, 91, '  ===> '), cmd\n            sys.exit(1)\n        else:\n            os.rename('%s.tmp' % infos['file'], infos['file'])\n\n    def exists(self, filepath):\n        pass\n\n    def upload(self, path, dir_):\n        pass\n\n    def addtask(self):\n        pass\n\n    def do(self):\n        self.get_infos()\n\ndef main(argv):\n    if len(argv) <= 1:\n        sys.exit()\n\n    ######################################################\n    # for argparse\n    p = argparse.ArgumentParser(description='download from yunpan.360.com')\n    p.add_argument('xxx', type=str, nargs='*', \\\n        help='命令对象.')\n    p.add_argument('-a', '--aria2c', action='store_true', \\\n        help='download with aria2c')\n    p.add_argument('-p', '--play', action='store_true', \\\n        help='play with mpv')\n    p.add_argument('-f', '--from_', action='store', \\\n        default=1, type=int, \\\n        help='从第几个开始下载，eg: -f 42')\n    p.add_argument('-t', '--type_', action='store', \\\n        default=None, type=str, \\\n        help='要下载的文件的后缀，eg: -t mp3')\n    p.add_argument('-l', '--limit', action='store', \\\n        default=None, type=str, help='下载速度限制，eg: -l 100k')\n    global args\n    args = p.parse_args(argv[1:])\n    xxx = args.xxx\n\n    if xxx[0] == 'login' or xxx[0] == 'g':\n        if len(xxx[1:]) < 1:\n            username = raw_input(s % (1, 97, '  username: '))\n            password = getpass(s % (1, 97, '  password: '))\n        elif len(xxx[1:]) == 1:\n            username = xxx[1]\n            password = getpass(s % (1, 97, '  password: '))\n        elif len(xxx[1:]) == 2:\n            username = xxx[1]\n            password = xxx[2]\n        else:\n            print s % (1, 91, '  login\\n  login username\\n  login username password')\n\n        x = yunpan360()\n        x.login(username, password)\n        is_signin = x.check_login()\n        if is_signin:\n            print s % (1, 92, '  ++ login succeeds.')\n        else:\n            print s % (1, 91, '  login failes')\n\n    elif xxx[0] == 'signout':\n        g = open(cookie_file, 'w')\n        g.close()\n\n    else:\n        urls = xxx\n        x = yunpan360()\n        x.init()\n        for url in urls:\n            x.path = x.get_path(url)\n            x.do()\n\nif __name__ == '__main__':\n    argv = sys.argv\n    main(argv)\n"
        }
      ]
    }
  ]
}