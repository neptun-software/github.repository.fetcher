{
  "metadata": {
    "timestamp": 1736560856858,
    "page": 562,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjU3MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "jarun/googler",
      "stars": 6125,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0185546875,
          "content": "build/\ndist/\n*.bak\n"
        },
        {
          "name": "CHANGELOG",
          "type": "blob",
          "size": 13.7373046875,
          "content": "googler 4.3.2\n2021-01-21\n\n- Fix html class of result nodes (#393, fixes #392)\n- Do not sabotage stdin of url_handler (#386)\n\n-------------------------------------------------------------------------------\n\ngoogler 4.3.1\n2020-10-10\n\n- several important parser fixes\n- retire Python v3.5, add v3.9\n\n-------------------------------------------------------------------------------\n\ngoogler 4.3\n2020-10-10\n\n- fix recent break due to server-side changes\n- option `-e`/`--exclude` to exclude site from results\n- option `-g`/`--geoloc` to specify geolocation\n- replace uuid1 with uuid4 in request\n\n-------------------------------------------------------------------------------\n\ngoogler 4.2\n2020-07-28\n\n- support GUI platform browsers on WSL\n- support Wayland native copier `wl-copy`\n- program options `--ipv4`, `--ipv6`; ipv4 preferred by default\n- deduplicate results\n- fix sitelinks parsing\n- combine consecutive whitespaces\n- fix extraction of matched keywords\n- fix match highlighting\n- no additional blank line for empty abstracts\n- undocumented debug option `--parse` to parse dumped HTML\n\n-------------------------------------------------------------------------------\n\ngoogler 4.1\n2020-04-30\n\nWhat's in?\n- search Google Videos\n- options `--from` and `--to` to specify date range for search\n- update parser to handle new layout for Google News results\n- strip trailing comma from metadata\n- add auto-generated packages for new distros, remove obsolete\n\n-------------------------------------------------------------------------------\n\ngoogler 4.0\n2019-11-27\n\nWhat's in?\n- Switch to modern UA and fix parser to handle new result format\n- Text-wrapping\n\n-------------------------------------------------------------------------------\n\ngoogler 3.9\n2019-05-30\n\nWhat's in?\n- fix issue - `googler` showing \"No results.\"\n- show matched keywords in bold in result abstracts\n- option `--colorize` for more control on colors\n- better support for colors on Windows\n- switch to CircleCI from Travis\n- option `--noua` is deprecated (noop) and will be removed in future\n\n-------------------------------------------------------------------------------\n\ngoogler 3.8\n2019-03-27\n\nWhat's in?\n- A complete parser rewrite\n- Visual redesign of the output format\n- Text-wrapping for CJK wide characters\n- Refresh current page on URL expansion toggle\n- Available on Raspbian testing and Chocolatey\n- Several important fixes\n\n-------------------------------------------------------------------------------\n\ngoogler 3.7.1\n2018-10-10\n\nWhat's in?\n- Custom user agent\n- Fix to unescape auto-completions\n\n-------------------------------------------------------------------------------\n\ngoogler 3.7\n2018-09-16\n\nWhat's in?\n- Support xclip as a clipboard utility on *nix\n- Support GNU Screen and tmux as clipboard fallback\n- Support Termux clipboard on Android\n\n-------------------------------------------------------------------------------\n\ngoogler 3.6\n2018-05-23\n\nWhat's in?\n- Decode auto-completion info as per charset in response header\n- Ignore trailing `/` in proxy\n- Some heath sites added to googler @t\n- User agent updated to Firefox 60\n- Availability on Fedora and openSUSE\n- More auto-generated packages\n\n-------------------------------------------------------------------------------\n\ngoogler 3.5\n2018-02-16\n\nWhat's in?\n- URL folding to show only domain name\n- Omniprompt key `c` to copy URL to clipboard\n- Support env var `DISABLE_PROMPT_COLOR` to disable prompt color (see #203)\n\nNote: Python 3.3 reached EOL, will not be supported anymore.\n\n-------------------------------------------------------------------------------\n\ngoogler 3.4\n2017-10-02\n\nWhat's in?\n- Support custom URL handler script or cli utility (option `--url-handler`)\n- Support text browser override with GUI browser (omniprompt key `O`)\n- A stunning project logo! (designed by @zmwangx)\n\n-------------------------------------------------------------------------------\n\ngoogler 3.3\n2017-08-17\n\nWhat's in?\n- Search auto-completion (using completion scripts)\n- Python 3.6 support\n- Automated release package builds using PackageCore\n\n-------------------------------------------------------------------------------\n\ngoogler 3.2\n2017-07-07\n\nWhat's in?\n- Basic authentication with `--proxy`\n- Option `--unfilter` to include similar results\n- New googler @ts : Manga Reader, Mac Rumors, OMG! Ubuntu!\n- Fix: skip certain card results with `--noua`\n- options `--json` and `--exact` decoupled\n\n-------------------------------------------------------------------------------\n\ngoogler 3.1\n2017-04-28\n\nWhat's in?\n- Search result metadata (e.g. IMDB rating)\n- Multi-site search\n- Browse numeric ranges at omniprompt\n- googler@ - Financial Times, The Pirate Bay added\n\n-------------------------------------------------------------------------------\n\ngoogler 3.0\n2017-03-12\n\nModifications\n- Introducing [googler @t](https://github.com/jarun/googler#googler-t) add-on!\n- Open multiple indices from omniprompt\n- Open all indices from omniprompt\n- Option `--enable-browser-output` is now `--show-browser-logs`\n- Multiple bug fixes\n\n-------------------------------------------------------------------------------\n\ngoogler 2.9\n2016-12-18\n\n**NOTICE**\n- `googler` is on Debian and Ubuntu official releases now. In addition, there's\na PPA in place to install the latest program releases from.\n\nModifications\n- Omniprompt option to search exact keywords on auto-correction\n- Push cmdline arguments to readline history (simplifies editing the keywords)\n- Added check to ensure UTF-8 encoding\n- Support 3 HTTP redirections before failing to connect\n- Support environment variable https_proxy\n- Python 3.5.3 compliance for TLS 1.2\n- Removed deb package generation scripts\n\n-------------------------------------------------------------------------------\n\ngoogler 2.8\n2016-10-04\n\nModifications\n- Add option --notweak to disable TCP optimizations and forced TLS 1.2.\n- Limited self-upgrade options to -U or --upgrade. Removed --update.\n\n-------------------------------------------------------------------------------\n\ngoogler v2.7\n2016-08-28\n\nModifications\n- Show google services abstract with User Agent disabled.\n- In-place self-upgrade mechanism.\n- Fix integration with text-based browsers.\n- Set process title to googler if setproctitle is installed.\n\n-------------------------------------------------------------------------------\n\ngoogler v2.6\n2016-07-06\n\nModifications\n- Option `--noua` to disable UA (default - enabled).\n- Logging and auto-completion script changes.\n\n-------------------------------------------------------------------------------\n\ngoogler v2.5.1\n2016-06-13\n\nModifications\n- Enable TCP/IP optimizations only for Linux. This fails on OS X.\n\nNOTE: The optimizations do not work on Linux 2.4 and earlier either.\n\n-------------------------------------------------------------------------------\n\ngoogler v2.5\n2016-06-12\n\n**NOTICE:**\n- Python 2.x support is discontinued.\n- googler is now available on [Debian Sid](https://packages.debian.org/unstable/main/googler)\n\nModifications\n- Invoking `googler` without search keywords shows omniprompt\n- Introduced options -h and --help to show program help and exit\n- Support cookie\n- Use TLS 1.2 (Python 3.4 and above)\n- Omniprompt key to unfilter filtered similar results\n- HTTPS proxy support (non-TLS 1.2 supported)\n- News time shown in cyan by default\n- Tons of code, logging and debug improvements (thanks Zhiming)\n\n-------------------------------------------------------------------------------\n\ngoogler v2.4.1\n2016-05-22\n\n**NOTICE:** Python 2.x support is deprecated now. While it's still\npossible to use Python 2.x by editing the shebang, we have found\nissues with Python 2.x (e.g. readline doesn't work) which don't\nhave a satisfactory solution without impacting other features.\nPython 2.x support will be completely removed in the next version.\n\nModifications\n- Sitelinks support\n- Customizable colours\n- Context in News results\n- .deb package for Debian and Ubuntu family\n- Basic support for terminal emulators having ANSI escape sequence support on Windows\n- New omniprompt option -f to jump to first results page\n- New omniprompt key -o to open the current search in browser\n- Shorter omniprompt\n- Non-interactive mode to fetch results and exit\n- JSON output support\n- A complete re-write of the HTML parser\n\n-------------------------------------------------------------------------------\n\ngoogler v2.3\n2016-04-23\n\nModifications\n- Google Site Search support (option -w)\n- Auto-completion scripts for Zsh, Bash and Fish shells\n- All Google top level domains supported\n- Show time for news\n- Integrated omniprompt help\n- Move to argparse\n  - Additional long options easier to remember\n- Graceful SIGINT handler\n- Add version to debug logs\nAND ...\n- An *awesssome* asciinema recording for the README from Zhiming\n\n-------------------------------------------------------------------------------\n\ngoogler v2.2\n2016-03-12\n\nModifications\n- Show quotes in text and title\n- Option to disable automatic spelling correction\n- User agent identifier added for all requests\n- Improved concise omniprompt with color inversion to work as a page separator\n- Set column size to auto when sys.stderr is not a tty\n- Decode HTTPS response in UTF-8\n- Dynamically detect python version using /usr/bin/env\n- Handle EOF (Ctrl-d) at omniprompt\n\nImprovements\n- Refactored code\n  - Modularized code for repetitive logic\n  - Unnecessary code removal\n- Dump full HTML response in debug mode\n- Homebrew integration\n- Travis integration\n- A better readme in 100% markdown and ToC with references\n\n-------------------------------------------------------------------------------\n\ngoogler v2.1\n2016-02-01\n\nModifications\n- Project renamed to googler, same as the utility\n- Gzip compression to fetch data\n- Improved continuous search (works without the `g` key at prompt now. Check\n  Example 10 in README for exceptions)\n- Skip Google News, Images links and ads\n- Show skipped link count\n\n-------------------------------------------------------------------------------\n\ngoogle-cli v2.0\n2016-01-09\n\nModifications\n- IMPORTANT fix for issue #19: Google replaced \"li\" with \"div\" as search result\n  separator. Users must update to this release or latest dev version for\n  google-cli to work.\n- Handle formatting on Mac OS X in emacs eshell (or any terminal envornment\n  where number of columns returned is 0).\n- PEP 8 style adaptation. Thanks @shaggytwodope!\n\n-------------------------------------------------------------------------------\n\ngoogle-cli v1.9\n2015-11-13\n\nModifications\n- Skip results without any URL (Google custom results like time, define etc.).\n- Use readline library to support arrow keys in input.\n- Support installation on OSX. Thanks @ibaaj.\n- Pre-check negative index before attempting to open URL.\n- Handle exception: \"socket.gaierror: [Errno -2] Name or service not known\"\n  due to connection throttle on low-bandwidth.\n- Print correct Exception in case of connection timeout.\n\n-------------------------------------------------------------------------------\n\ngoogle-cli v1.8\n2015-10-11\n\nModification\n- Added timeout to HTTPSConnection()\n- Redirected stdout and stderr to suppress all warning & error messages when\n  opening results in Firefox\n\n-------------------------------------------------------------------------------\n\ngoogle-cli v1.7\n2015-10-07\n\nModification\n- Added support for redirection and piping\n- Used stderr instead of stdin to determine console geometry\n\n-------------------------------------------------------------------------------\n\ngoogle-cli v1.6\n2015-09-12\n\nModification\n- Changed incremental search key from s to g keeping in mind that users may use\n  g as the alias for googler.\n\nFix\n- Handle httplib.BadStatusLine exception. This happens if the connection is\n  closed due to inactivity. Now googler will reconnect and re-issue the search.\n\n-------------------------------------------------------------------------------\n\ngoogle-cli v1.5\n2015-09-04\n\nNew capabilities\n- Incremental search support from the same running instance\n- Utility name changed to googler to void any copyright infringements\n\n-------------------------------------------------------------------------------\n\ngoogle-cli v1.2\n2015-09-03\n\nNew capabilities\n- Open result in browser using index number (thanks jeremija)\n- Google News support\n- Time limit search by hours\n- Country specific search (28 top-level domains added)\n- Add switch to enable debug logs\n\nRemoval\n- Removed file type specific search option -f in favour of filetype:mime Google\n  keyword\n\nFixes\n- Convert %22 to \" (double quote) in URLs\n- Inputs other than n, p or number (+ Enter) exit\n- Fix failure to open URL with \" (double quotes) in browser\n- Fix version information in manpage\n- Get rid of Google Chrome debug/error messages in console when opening URL\n\n-------------------------------------------------------------------------------\n\ngoogle-cli v1.1\n2015-08-25\n\nNew capabilities\n- Add Python 3.x support\n- Add UTF-8 request and response\n[both the contributions are from Narrat]\n\nNOTE: The next change in queue is to support opening the URLs in browser. As we\ncan see during preliminary tests, there are several issues around Google Chrome\nand its mods. This release works as a stable release before we hop on.\n\n-------------------------------------------------------------------------------\n\ngoogle-cli v1.0\n2015-08-22\n\nNew capabilities\n- HTTPS support\n- Navigate as in regular google search\n- File type in search as an option\n- Time limited search (day, week, month, year)\n- Show full text snippet of search results\n- Unicode in URL support\n- Honour -j even if -n is not used and open the result in browser\n- Skip browser to show result in console for empty URL, e.g., first result of\n  'define hello'\n- Handle google redirections (error 302)\n- Throw error in case of google error due to unusual activity from IP\n\nFixes\n- Adapt to new google HTML response\n- Fixed character encoding problem in URL e.g. double quotes (%22) changed to\n  %2522\n\n-------------------------------------------------------------------------------\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 34.3232421875,
          "content": "                    GNU GENERAL PUBLIC LICENSE\n                       Version 3, 29 June 2007\n\n Copyright (C) 2007 Free Software Foundation, Inc. <http://fsf.org/>\n Everyone is permitted to copy and distribute verbatim copies\n of this license document, but changing it is not allowed.\n\n                            Preamble\n\n  The GNU General Public License is a free, copyleft license for\nsoftware and other kinds of works.\n\n  The licenses for most software and other practical works are designed\nto take away your freedom to share and change the works.  By contrast,\nthe GNU General Public License is intended to guarantee your freedom to\nshare and change all versions of a program--to make sure it remains free\nsoftware for all its users.  We, the Free Software Foundation, use the\nGNU General Public License for most of our software; it applies also to\nany other work released this way by its authors.  You can apply it to\nyour programs, too.\n\n  When we speak of free software, we are referring to freedom, not\nprice.  Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthem if you wish), that you receive source code or can get it if you\nwant it, that you can change the software or use pieces of it in new\nfree programs, and that you know you can do these things.\n\n  To protect your rights, we need to prevent others from denying you\nthese rights or asking you to surrender the rights.  Therefore, you have\ncertain responsibilities if you distribute copies of the software, or if\nyou modify it: responsibilities to respect the freedom of others.\n\n  For example, if you distribute copies of such a program, whether\ngratis or for a fee, you must pass on to the recipients the same\nfreedoms that you received.  You must make sure that they, too, receive\nor can get the source code.  And you must show them these terms so they\nknow their rights.\n\n  Developers that use the GNU GPL protect your rights with two steps:\n(1) assert copyright on the software, and (2) offer you this License\ngiving you legal permission to copy, distribute and/or modify it.\n\n  For the developers' and authors' protection, the GPL clearly explains\nthat there is no warranty for this free software.  For both users' and\nauthors' sake, the GPL requires that modified versions be marked as\nchanged, so that their problems will not be attributed erroneously to\nauthors of previous versions.\n\n  Some devices are designed to deny users access to install or run\nmodified versions of the software inside them, although the manufacturer\ncan do so.  This is fundamentally incompatible with the aim of\nprotecting users' freedom to change the software.  The systematic\npattern of such abuse occurs in the area of products for individuals to\nuse, which is precisely where it is most unacceptable.  Therefore, we\nhave designed this version of the GPL to prohibit the practice for those\nproducts.  If such problems arise substantially in other domains, we\nstand ready to extend this provision to those domains in future versions\nof the GPL, as needed to protect the freedom of users.\n\n  Finally, every program is threatened constantly by software patents.\nStates should not allow patents to restrict development and use of\nsoftware on general-purpose computers, but in those that do, we wish to\navoid the special danger that patents applied to a free program could\nmake it effectively proprietary.  To prevent this, the GPL assures that\npatents cannot be used to render the program non-free.\n\n  The precise terms and conditions for copying, distribution and\nmodification follow.\n\n                       TERMS AND CONDITIONS\n\n  0. Definitions.\n\n  \"This License\" refers to version 3 of the GNU General Public License.\n\n  \"Copyright\" also means copyright-like laws that apply to other kinds of\nworks, such as semiconductor masks.\n\n  \"The Program\" refers to any copyrightable work licensed under this\nLicense.  Each licensee is addressed as \"you\".  \"Licensees\" and\n\"recipients\" may be individuals or organizations.\n\n  To \"modify\" a work means to copy from or adapt all or part of the work\nin a fashion requiring copyright permission, other than the making of an\nexact copy.  The resulting work is called a \"modified version\" of the\nearlier work or a work \"based on\" the earlier work.\n\n  A \"covered work\" means either the unmodified Program or a work based\non the Program.\n\n  To \"propagate\" a work means to do anything with it that, without\npermission, would make you directly or secondarily liable for\ninfringement under applicable copyright law, except executing it on a\ncomputer or modifying a private copy.  Propagation includes copying,\ndistribution (with or without modification), making available to the\npublic, and in some countries other activities as well.\n\n  To \"convey\" a work means any kind of propagation that enables other\nparties to make or receive copies.  Mere interaction with a user through\na computer network, with no transfer of a copy, is not conveying.\n\n  An interactive user interface displays \"Appropriate Legal Notices\"\nto the extent that it includes a convenient and prominently visible\nfeature that (1) displays an appropriate copyright notice, and (2)\ntells the user that there is no warranty for the work (except to the\nextent that warranties are provided), that licensees may convey the\nwork under this License, and how to view a copy of this License.  If\nthe interface presents a list of user commands or options, such as a\nmenu, a prominent item in the list meets this criterion.\n\n  1. Source Code.\n\n  The \"source code\" for a work means the preferred form of the work\nfor making modifications to it.  \"Object code\" means any non-source\nform of a work.\n\n  A \"Standard Interface\" means an interface that either is an official\nstandard defined by a recognized standards body, or, in the case of\ninterfaces specified for a particular programming language, one that\nis widely used among developers working in that language.\n\n  The \"System Libraries\" of an executable work include anything, other\nthan the work as a whole, that (a) is included in the normal form of\npackaging a Major Component, but which is not part of that Major\nComponent, and (b) serves only to enable use of the work with that\nMajor Component, or to implement a Standard Interface for which an\nimplementation is available to the public in source code form.  A\n\"Major Component\", in this context, means a major essential component\n(kernel, window system, and so on) of the specific operating system\n(if any) on which the executable work runs, or a compiler used to\nproduce the work, or an object code interpreter used to run it.\n\n  The \"Corresponding Source\" for a work in object code form means all\nthe source code needed to generate, install, and (for an executable\nwork) run the object code and to modify the work, including scripts to\ncontrol those activities.  However, it does not include the work's\nSystem Libraries, or general-purpose tools or generally available free\nprograms which are used unmodified in performing those activities but\nwhich are not part of the work.  For example, Corresponding Source\nincludes interface definition files associated with source files for\nthe work, and the source code for shared libraries and dynamically\nlinked subprograms that the work is specifically designed to require,\nsuch as by intimate data communication or control flow between those\nsubprograms and other parts of the work.\n\n  The Corresponding Source need not include anything that users\ncan regenerate automatically from other parts of the Corresponding\nSource.\n\n  The Corresponding Source for a work in source code form is that\nsame work.\n\n  2. Basic Permissions.\n\n  All rights granted under this License are granted for the term of\ncopyright on the Program, and are irrevocable provided the stated\nconditions are met.  This License explicitly affirms your unlimited\npermission to run the unmodified Program.  The output from running a\ncovered work is covered by this License only if the output, given its\ncontent, constitutes a covered work.  This License acknowledges your\nrights of fair use or other equivalent, as provided by copyright law.\n\n  You may make, run and propagate covered works that you do not\nconvey, without conditions so long as your license otherwise remains\nin force.  You may convey covered works to others for the sole purpose\nof having them make modifications exclusively for you, or provide you\nwith facilities for running those works, provided that you comply with\nthe terms of this License in conveying all material for which you do\nnot control copyright.  Those thus making or running the covered works\nfor you must do so exclusively on your behalf, under your direction\nand control, on terms that prohibit them from making any copies of\nyour copyrighted material outside their relationship with you.\n\n  Conveying under any other circumstances is permitted solely under\nthe conditions stated below.  Sublicensing is not allowed; section 10\nmakes it unnecessary.\n\n  3. Protecting Users' Legal Rights From Anti-Circumvention Law.\n\n  No covered work shall be deemed part of an effective technological\nmeasure under any applicable law fulfilling obligations under article\n11 of the WIPO copyright treaty adopted on 20 December 1996, or\nsimilar laws prohibiting or restricting circumvention of such\nmeasures.\n\n  When you convey a covered work, you waive any legal power to forbid\ncircumvention of technological measures to the extent such circumvention\nis effected by exercising rights under this License with respect to\nthe covered work, and you disclaim any intention to limit operation or\nmodification of the work as a means of enforcing, against the work's\nusers, your or third parties' legal rights to forbid circumvention of\ntechnological measures.\n\n  4. Conveying Verbatim Copies.\n\n  You may convey verbatim copies of the Program's source code as you\nreceive it, in any medium, provided that you conspicuously and\nappropriately publish on each copy an appropriate copyright notice;\nkeep intact all notices stating that this License and any\nnon-permissive terms added in accord with section 7 apply to the code;\nkeep intact all notices of the absence of any warranty; and give all\nrecipients a copy of this License along with the Program.\n\n  You may charge any price or no price for each copy that you convey,\nand you may offer support or warranty protection for a fee.\n\n  5. Conveying Modified Source Versions.\n\n  You may convey a work based on the Program, or the modifications to\nproduce it from the Program, in the form of source code under the\nterms of section 4, provided that you also meet all of these conditions:\n\n    a) The work must carry prominent notices stating that you modified\n    it, and giving a relevant date.\n\n    b) The work must carry prominent notices stating that it is\n    released under this License and any conditions added under section\n    7.  This requirement modifies the requirement in section 4 to\n    \"keep intact all notices\".\n\n    c) You must license the entire work, as a whole, under this\n    License to anyone who comes into possession of a copy.  This\n    License will therefore apply, along with any applicable section 7\n    additional terms, to the whole of the work, and all its parts,\n    regardless of how they are packaged.  This License gives no\n    permission to license the work in any other way, but it does not\n    invalidate such permission if you have separately received it.\n\n    d) If the work has interactive user interfaces, each must display\n    Appropriate Legal Notices; however, if the Program has interactive\n    interfaces that do not display Appropriate Legal Notices, your\n    work need not make them do so.\n\n  A compilation of a covered work with other separate and independent\nworks, which are not by their nature extensions of the covered work,\nand which are not combined with it such as to form a larger program,\nin or on a volume of a storage or distribution medium, is called an\n\"aggregate\" if the compilation and its resulting copyright are not\nused to limit the access or legal rights of the compilation's users\nbeyond what the individual works permit.  Inclusion of a covered work\nin an aggregate does not cause this License to apply to the other\nparts of the aggregate.\n\n  6. Conveying Non-Source Forms.\n\n  You may convey a covered work in object code form under the terms\nof sections 4 and 5, provided that you also convey the\nmachine-readable Corresponding Source under the terms of this License,\nin one of these ways:\n\n    a) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by the\n    Corresponding Source fixed on a durable physical medium\n    customarily used for software interchange.\n\n    b) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by a\n    written offer, valid for at least three years and valid for as\n    long as you offer spare parts or customer support for that product\n    model, to give anyone who possesses the object code either (1) a\n    copy of the Corresponding Source for all the software in the\n    product that is covered by this License, on a durable physical\n    medium customarily used for software interchange, for a price no\n    more than your reasonable cost of physically performing this\n    conveying of source, or (2) access to copy the\n    Corresponding Source from a network server at no charge.\n\n    c) Convey individual copies of the object code with a copy of the\n    written offer to provide the Corresponding Source.  This\n    alternative is allowed only occasionally and noncommercially, and\n    only if you received the object code with such an offer, in accord\n    with subsection 6b.\n\n    d) Convey the object code by offering access from a designated\n    place (gratis or for a charge), and offer equivalent access to the\n    Corresponding Source in the same way through the same place at no\n    further charge.  You need not require recipients to copy the\n    Corresponding Source along with the object code.  If the place to\n    copy the object code is a network server, the Corresponding Source\n    may be on a different server (operated by you or a third party)\n    that supports equivalent copying facilities, provided you maintain\n    clear directions next to the object code saying where to find the\n    Corresponding Source.  Regardless of what server hosts the\n    Corresponding Source, you remain obligated to ensure that it is\n    available for as long as needed to satisfy these requirements.\n\n    e) Convey the object code using peer-to-peer transmission, provided\n    you inform other peers where the object code and Corresponding\n    Source of the work are being offered to the general public at no\n    charge under subsection 6d.\n\n  A separable portion of the object code, whose source code is excluded\nfrom the Corresponding Source as a System Library, need not be\nincluded in conveying the object code work.\n\n  A \"User Product\" is either (1) a \"consumer product\", which means any\ntangible personal property which is normally used for personal, family,\nor household purposes, or (2) anything designed or sold for incorporation\ninto a dwelling.  In determining whether a product is a consumer product,\ndoubtful cases shall be resolved in favor of coverage.  For a particular\nproduct received by a particular user, \"normally used\" refers to a\ntypical or common use of that class of product, regardless of the status\nof the particular user or of the way in which the particular user\nactually uses, or expects or is expected to use, the product.  A product\nis a consumer product regardless of whether the product has substantial\ncommercial, industrial or non-consumer uses, unless such uses represent\nthe only significant mode of use of the product.\n\n  \"Installation Information\" for a User Product means any methods,\nprocedures, authorization keys, or other information required to install\nand execute modified versions of a covered work in that User Product from\na modified version of its Corresponding Source.  The information must\nsuffice to ensure that the continued functioning of the modified object\ncode is in no case prevented or interfered with solely because\nmodification has been made.\n\n  If you convey an object code work under this section in, or with, or\nspecifically for use in, a User Product, and the conveying occurs as\npart of a transaction in which the right of possession and use of the\nUser Product is transferred to the recipient in perpetuity or for a\nfixed term (regardless of how the transaction is characterized), the\nCorresponding Source conveyed under this section must be accompanied\nby the Installation Information.  But this requirement does not apply\nif neither you nor any third party retains the ability to install\nmodified object code on the User Product (for example, the work has\nbeen installed in ROM).\n\n  The requirement to provide Installation Information does not include a\nrequirement to continue to provide support service, warranty, or updates\nfor a work that has been modified or installed by the recipient, or for\nthe User Product in which it has been modified or installed.  Access to a\nnetwork may be denied when the modification itself materially and\nadversely affects the operation of the network or violates the rules and\nprotocols for communication across the network.\n\n  Corresponding Source conveyed, and Installation Information provided,\nin accord with this section must be in a format that is publicly\ndocumented (and with an implementation available to the public in\nsource code form), and must require no special password or key for\nunpacking, reading or copying.\n\n  7. Additional Terms.\n\n  \"Additional permissions\" are terms that supplement the terms of this\nLicense by making exceptions from one or more of its conditions.\nAdditional permissions that are applicable to the entire Program shall\nbe treated as though they were included in this License, to the extent\nthat they are valid under applicable law.  If additional permissions\napply only to part of the Program, that part may be used separately\nunder those permissions, but the entire Program remains governed by\nthis License without regard to the additional permissions.\n\n  When you convey a copy of a covered work, you may at your option\nremove any additional permissions from that copy, or from any part of\nit.  (Additional permissions may be written to require their own\nremoval in certain cases when you modify the work.)  You may place\nadditional permissions on material, added by you to a covered work,\nfor which you have or can give appropriate copyright permission.\n\n  Notwithstanding any other provision of this License, for material you\nadd to a covered work, you may (if authorized by the copyright holders of\nthat material) supplement the terms of this License with terms:\n\n    a) Disclaiming warranty or limiting liability differently from the\n    terms of sections 15 and 16 of this License; or\n\n    b) Requiring preservation of specified reasonable legal notices or\n    author attributions in that material or in the Appropriate Legal\n    Notices displayed by works containing it; or\n\n    c) Prohibiting misrepresentation of the origin of that material, or\n    requiring that modified versions of such material be marked in\n    reasonable ways as different from the original version; or\n\n    d) Limiting the use for publicity purposes of names of licensors or\n    authors of the material; or\n\n    e) Declining to grant rights under trademark law for use of some\n    trade names, trademarks, or service marks; or\n\n    f) Requiring indemnification of licensors and authors of that\n    material by anyone who conveys the material (or modified versions of\n    it) with contractual assumptions of liability to the recipient, for\n    any liability that these contractual assumptions directly impose on\n    those licensors and authors.\n\n  All other non-permissive additional terms are considered \"further\nrestrictions\" within the meaning of section 10.  If the Program as you\nreceived it, or any part of it, contains a notice stating that it is\ngoverned by this License along with a term that is a further\nrestriction, you may remove that term.  If a license document contains\na further restriction but permits relicensing or conveying under this\nLicense, you may add to a covered work material governed by the terms\nof that license document, provided that the further restriction does\nnot survive such relicensing or conveying.\n\n  If you add terms to a covered work in accord with this section, you\nmust place, in the relevant source files, a statement of the\nadditional terms that apply to those files, or a notice indicating\nwhere to find the applicable terms.\n\n  Additional terms, permissive or non-permissive, may be stated in the\nform of a separately written license, or stated as exceptions;\nthe above requirements apply either way.\n\n  8. Termination.\n\n  You may not propagate or modify a covered work except as expressly\nprovided under this License.  Any attempt otherwise to propagate or\nmodify it is void, and will automatically terminate your rights under\nthis License (including any patent licenses granted under the third\nparagraph of section 11).\n\n  However, if you cease all violation of this License, then your\nlicense from a particular copyright holder is reinstated (a)\nprovisionally, unless and until the copyright holder explicitly and\nfinally terminates your license, and (b) permanently, if the copyright\nholder fails to notify you of the violation by some reasonable means\nprior to 60 days after the cessation.\n\n  Moreover, your license from a particular copyright holder is\nreinstated permanently if the copyright holder notifies you of the\nviolation by some reasonable means, this is the first time you have\nreceived notice of violation of this License (for any work) from that\ncopyright holder, and you cure the violation prior to 30 days after\nyour receipt of the notice.\n\n  Termination of your rights under this section does not terminate the\nlicenses of parties who have received copies or rights from you under\nthis License.  If your rights have been terminated and not permanently\nreinstated, you do not qualify to receive new licenses for the same\nmaterial under section 10.\n\n  9. Acceptance Not Required for Having Copies.\n\n  You are not required to accept this License in order to receive or\nrun a copy of the Program.  Ancillary propagation of a covered work\noccurring solely as a consequence of using peer-to-peer transmission\nto receive a copy likewise does not require acceptance.  However,\nnothing other than this License grants you permission to propagate or\nmodify any covered work.  These actions infringe copyright if you do\nnot accept this License.  Therefore, by modifying or propagating a\ncovered work, you indicate your acceptance of this License to do so.\n\n  10. Automatic Licensing of Downstream Recipients.\n\n  Each time you convey a covered work, the recipient automatically\nreceives a license from the original licensors, to run, modify and\npropagate that work, subject to this License.  You are not responsible\nfor enforcing compliance by third parties with this License.\n\n  An \"entity transaction\" is a transaction transferring control of an\norganization, or substantially all assets of one, or subdividing an\norganization, or merging organizations.  If propagation of a covered\nwork results from an entity transaction, each party to that\ntransaction who receives a copy of the work also receives whatever\nlicenses to the work the party's predecessor in interest had or could\ngive under the previous paragraph, plus a right to possession of the\nCorresponding Source of the work from the predecessor in interest, if\nthe predecessor has it or can get it with reasonable efforts.\n\n  You may not impose any further restrictions on the exercise of the\nrights granted or affirmed under this License.  For example, you may\nnot impose a license fee, royalty, or other charge for exercise of\nrights granted under this License, and you may not initiate litigation\n(including a cross-claim or counterclaim in a lawsuit) alleging that\nany patent claim is infringed by making, using, selling, offering for\nsale, or importing the Program or any portion of it.\n\n  11. Patents.\n\n  A \"contributor\" is a copyright holder who authorizes use under this\nLicense of the Program or a work on which the Program is based.  The\nwork thus licensed is called the contributor's \"contributor version\".\n\n  A contributor's \"essential patent claims\" are all patent claims\nowned or controlled by the contributor, whether already acquired or\nhereafter acquired, that would be infringed by some manner, permitted\nby this License, of making, using, or selling its contributor version,\nbut do not include claims that would be infringed only as a\nconsequence of further modification of the contributor version.  For\npurposes of this definition, \"control\" includes the right to grant\npatent sublicenses in a manner consistent with the requirements of\nthis License.\n\n  Each contributor grants you a non-exclusive, worldwide, royalty-free\npatent license under the contributor's essential patent claims, to\nmake, use, sell, offer for sale, import and otherwise run, modify and\npropagate the contents of its contributor version.\n\n  In the following three paragraphs, a \"patent license\" is any express\nagreement or commitment, however denominated, not to enforce a patent\n(such as an express permission to practice a patent or covenant not to\nsue for patent infringement).  To \"grant\" such a patent license to a\nparty means to make such an agreement or commitment not to enforce a\npatent against the party.\n\n  If you convey a covered work, knowingly relying on a patent license,\nand the Corresponding Source of the work is not available for anyone\nto copy, free of charge and under the terms of this License, through a\npublicly available network server or other readily accessible means,\nthen you must either (1) cause the Corresponding Source to be so\navailable, or (2) arrange to deprive yourself of the benefit of the\npatent license for this particular work, or (3) arrange, in a manner\nconsistent with the requirements of this License, to extend the patent\nlicense to downstream recipients.  \"Knowingly relying\" means you have\nactual knowledge that, but for the patent license, your conveying the\ncovered work in a country, or your recipient's use of the covered work\nin a country, would infringe one or more identifiable patents in that\ncountry that you have reason to believe are valid.\n\n  If, pursuant to or in connection with a single transaction or\narrangement, you convey, or propagate by procuring conveyance of, a\ncovered work, and grant a patent license to some of the parties\nreceiving the covered work authorizing them to use, propagate, modify\nor convey a specific copy of the covered work, then the patent license\nyou grant is automatically extended to all recipients of the covered\nwork and works based on it.\n\n  A patent license is \"discriminatory\" if it does not include within\nthe scope of its coverage, prohibits the exercise of, or is\nconditioned on the non-exercise of one or more of the rights that are\nspecifically granted under this License.  You may not convey a covered\nwork if you are a party to an arrangement with a third party that is\nin the business of distributing software, under which you make payment\nto the third party based on the extent of your activity of conveying\nthe work, and under which the third party grants, to any of the\nparties who would receive the covered work from you, a discriminatory\npatent license (a) in connection with copies of the covered work\nconveyed by you (or copies made from those copies), or (b) primarily\nfor and in connection with specific products or compilations that\ncontain the covered work, unless you entered into that arrangement,\nor that patent license was granted, prior to 28 March 2007.\n\n  Nothing in this License shall be construed as excluding or limiting\nany implied license or other defenses to infringement that may\notherwise be available to you under applicable patent law.\n\n  12. No Surrender of Others' Freedom.\n\n  If conditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License.  If you cannot convey a\ncovered work so as to satisfy simultaneously your obligations under this\nLicense and any other pertinent obligations, then as a consequence you may\nnot convey it at all.  For example, if you agree to terms that obligate you\nto collect a royalty for further conveying from those to whom you convey\nthe Program, the only way you could satisfy both those terms and this\nLicense would be to refrain entirely from conveying the Program.\n\n  13. Use with the GNU Affero General Public License.\n\n  Notwithstanding any other provision of this License, you have\npermission to link or combine any covered work with a work licensed\nunder version 3 of the GNU Affero General Public License into a single\ncombined work, and to convey the resulting work.  The terms of this\nLicense will continue to apply to the part which is the covered work,\nbut the special requirements of the GNU Affero General Public License,\nsection 13, concerning interaction through a network will apply to the\ncombination as such.\n\n  14. Revised Versions of this License.\n\n  The Free Software Foundation may publish revised and/or new versions of\nthe GNU General Public License from time to time.  Such new versions will\nbe similar in spirit to the present version, but may differ in detail to\naddress new problems or concerns.\n\n  Each version is given a distinguishing version number.  If the\nProgram specifies that a certain numbered version of the GNU General\nPublic License \"or any later version\" applies to it, you have the\noption of following the terms and conditions either of that numbered\nversion or of any later version published by the Free Software\nFoundation.  If the Program does not specify a version number of the\nGNU General Public License, you may choose any version ever published\nby the Free Software Foundation.\n\n  If the Program specifies that a proxy can decide which future\nversions of the GNU General Public License can be used, that proxy's\npublic statement of acceptance of a version permanently authorizes you\nto choose that version for the Program.\n\n  Later license versions may give you additional or different\npermissions.  However, no additional obligations are imposed on any\nauthor or copyright holder as a result of your choosing to follow a\nlater version.\n\n  15. Disclaimer of Warranty.\n\n  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY\nAPPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT\nHOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY\nOF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,\nTHE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\nPURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM\nIS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF\nALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\n  16. Limitation of Liability.\n\n  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS\nTHE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY\nGENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE\nUSE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF\nDATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD\nPARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),\nEVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF\nSUCH DAMAGES.\n\n  17. Interpretation of Sections 15 and 16.\n\n  If the disclaimer of warranty and limitation of liability provided\nabove cannot be given local legal effect according to their terms,\nreviewing courts shall apply local law that most closely approximates\nan absolute waiver of all civil liability in connection with the\nProgram, unless a warranty or assumption of liability accompanies a\ncopy of the Program in return for a fee.\n\n                     END OF TERMS AND CONDITIONS\n\n            How to Apply These Terms to Your New Programs\n\n  If you develop a new program, and you want it to be of the greatest\npossible use to the public, the best way to achieve this is to make it\nfree software which everyone can redistribute and change under these terms.\n\n  To do so, attach the following notices to the program.  It is safest\nto attach them to the start of each source file to most effectively\nstate the exclusion of warranty; and each file should have at least\nthe \"copyright\" line and a pointer to where the full notice is found.\n\n    <one line to give the program's name and a brief idea of what it does.>\n    Copyright (C) <year>  <name of author>\n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation, either version 3 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nAlso add information on how to contact you by electronic and paper mail.\n\n  If the program does terminal interaction, make it output a short\nnotice like this when it starts in an interactive mode:\n\n    <program>  Copyright (C) <year>  <name of author>\n    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\n    This is free software, and you are welcome to redistribute it\n    under certain conditions; type `show c' for details.\n\nThe hypothetical commands `show w' and `show c' should show the appropriate\nparts of the General Public License.  Of course, your program's commands\nmight be different; for a GUI interface, you would use an \"about box\".\n\n  You should also get your employer (if you work as a programmer) or school,\nif any, to sign a \"copyright disclaimer\" for the program, if necessary.\nFor more information on this, and how to apply and follow the GNU GPL, see\n<http://www.gnu.org/licenses/>.\n\n  The GNU General Public License does not permit incorporating your program\ninto proprietary programs.  If your program is a subroutine library, you\nmay consider it more useful to permit linking proprietary applications with\nthe library.  If this is what you want to do, use the GNU Lesser General\nPublic License instead of this License.  But first, please read\n<http://www.gnu.org/philosophy/why-not-lgpl.html>.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.8359375,
          "content": "PREFIX ?= /usr/local\nBINDIR = $(DESTDIR)$(PREFIX)/bin\nMANDIR = $(DESTDIR)$(PREFIX)/share/man/man1\nDOCDIR = $(DESTDIR)$(PREFIX)/share/doc/googler\n\n.PHONY: all install uninstall disable-self-upgrade\n\nall:\n\ninstall:\n\tinstall -m755 -d $(BINDIR)\n\tinstall -m755 -d $(MANDIR)\n\tinstall -m755 -d $(DOCDIR)\n\tgzip -c googler.1 > googler.1.gz\n\tinstall -m755 googler $(BINDIR)\n\tinstall -m644 googler.1.gz $(MANDIR)\n\tinstall -m644 README.md $(DOCDIR)\n\trm -f googler.1.gz\n\nuninstall:\n\trm -f $(BINDIR)/googler\n\trm -f $(MANDIR)/googler.1.gz\n\trm -rf $(DOCDIR)\n\n# Disable the self-upgrade mechanism entirely. Intended for packagers.\n#\n# We assume that sed(1) has the -i option, which is not POSIX but seems common\n# enough in modern implementations.\ndisable-self-upgrade:\n\tsed -i.bak 's/^ENABLE_SELF_UPGRADE_MECHANISM = True$$/ENABLE_SELF_UPGRADE_MECHANISM = False/' googler\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 22.46875,
          "content": "<h1 align=\"center\"><img src=\"https://cdn.rawgit.com/jarun/googler/master/googler.svg\" alt=\"googler\" /></h1>\n\n<p align=\"center\">\n<a href=\"https://github.com/jarun/googler/releases/latest\"><img src=\"https://img.shields.io/github/release/jarun/googler.svg?maxAge=600\" alt=\"Latest release\" /></a>\n<a href=\"https://repology.org/project/googler/versions\"><img src=\"https://repology.org/badge/tiny-repos/googler.svg\" alt=\"Availability\"></a>\n<a href=\"https://github.com/jarun/googler/blob/master/LICENSE\"><img src=\"https://img.shields.io/badge/license-GPLv3-yellowgreen.svg?maxAge=2592000\" alt=\"License\" /></a>\n<a href=\"https://github.com/jarun/googler/actions\"><img src=\"https://github.com/jarun/googler/workflows/ci/badge.svg?branch=master\" alt=\"Build Status\" /></a>\n</p>\n\n<p align=\"center\">\n<a href=\"https://asciinema.org/a/85019\"><img src=\"https://i.imgur.com/EbZof9q.png\" alt=\"Asciicast\" width=\"734\"/></a>\n</p>\n\n`googler` is a power tool to Google (web, news, videos and site search) from the command-line. It shows the title, URL and abstract for each result, which can be directly opened in a browser from the terminal. Results are fetched in pages (with page navigation). Supports sequential searches in a single `googler` instance.\n\n`googler` was initially written to cater to headless servers without X. You can integrate it with a text-based browser. However, it has grown into a very handy and flexible utility that delivers much more. For example, fetch any number of results or start anywhere, limit search by any duration, define aliases to google search any number of websites, switch domains easily... all of this in a very clean interface without ads or stray URLs. The shell completion scripts make sure you don't need to remember any options.\n\n`googler` isn't affiliated to Google in any way.\n\nHere are some usage examples:\n\n1. Google **hello world**:\n\n        $ googler hello world\n\n2. Fetch **15 results** updated within the last **14 months**, starting from the **3<sup>rd</sup> result** for the keywords **jungle book** in **site** imdb.com:\n\n        $ googler -n 15 -s 3 -t m14 -w imdb.com jungle book\n\n    Or instead of the last 14 months, look for results specifically between Apr 4, 2016 and Dec 31, 2016:\n\n        $ googler -n 15 -s 3 --from 04/04/2016 --to 12/31/2016 -w imdb.com jungle book\n\n3. Read recent **news** on gadgets:\n\n        $ googler -N gadgets\n\n4. Fetch results on IPL cricket from **Google India** server in **English**:\n\n        $ googler -c in -l en IPL cricket\n\n5. Search for **videos** on PyCon 2020:\n\n        $ googler -V PyCon 2020\n\n6. Search **quoted text**:\n\n        $ googler it\\'s a \\\"beautiful world\\\" in spring\n\n7. Search for a **specific file type**:\n\n        $ googler instrumental filetype:mp3\n\n8. Disable **automatic spelling correction**, e.g. fetch results for `googler` instead of `google`:\n\n        $ googler -x googler\n\n9. **I'm feeling lucky** search:\n\n        $ googler -j leather jackets\n\n10. **Website specific** search:\n\n        $ googler -w amazon.com -w ebay.com digital camera\n\n    Site specific search continues at omniprompt.\n\n11. Positional arguments are joined (with delimiting whitespace) to form the final query, so you can be creative with your aliases. For instance, always **exclude** seoarticlefactory.com from search results:\n\n        $ alias googler='googler \" -site:seoarticlefactory.com\"'\n        $ googler '<hugely popular keyword filled with SEO garbage>'\n\n12. Alias to find **definitions of words**:\n\n        alias define='googler -n 2 define'\n\n13. Look up `n`, `p`, `o`, `O`, `q`, `g keywords` or a result index at the **omniprompt**: as the omniprompt recognizes these keys or index strings as commands, you need to prefix them with `g`, e.g.,\n\n        g n\n        g g keywords\n        g 1\n\n14. Input and output **redirection**:\n\n        $ googler -C hello world < input > output\n    Note that `-C` is required to avoid printing control characters (for colored output).\n\n15. **Pipe** output:\n\n        $ googler -C hello world | tee output\n\n16. Use a **custom color scheme**, e.g., a warm color scheme designed for Solarized Dark ([screenshot](https://i.imgur.com/6L8VlfS.png)):\n\n        $ googler --colors bjdxxy google\n        $ GOOGLER_COLORS=bjdxxy googler google\n\n17. Tunnel traffic through an **HTTPS proxy**, e.g., a local Privoxy instance listening on port 8118:\n\n        $ googler --proxy localhost:8118 google\n\n    By default the environment variable `https_proxy` is used, if defined.\n\n18. Quote multiple search keywords to auto-complete (using completion script):\n\n        $ googler 'hello w<TAB>\n\n19. More **help**:\n\n        $ googler -h\n        $ man googler\n\nMore fun stuff you can try with `googler`:\n\n- [googler on the iPad](https://github.com/jarun/googler/wiki/googler-on-the-iPad)\n- [Print content of results to terminal or listen to it](https://github.com/jarun/googler/wiki/Print-content-of-results-to-terminal-or-listen-to-it)\n- [Terminal Reading Mode or Reader View](https://github.com/jarun/googler/wiki/Terminal-Reading-Mode-or-Reader-View)\n- [Stream YouTube videos on desktop](https://github.com/jarun/googler/wiki/Search-and-stream-videos-from-the-terminal)\n- [Search error on StackOverflow from terminal](https://github.com/jarun/googler/wiki/Search-error-on-StackOverflow-from-terminal)\n\n### Table of contents\n\n- [Features](#features)\n- [Installation](#installation)\n    - [Dependencies](#dependencies)\n    - [From a package manager](#from-a-package-manager)\n        - [Tips for packagers](#tips-for-packagers)\n    - [Release packages](#release-packages)\n    - [From source](#from-source)\n    - [Running standalone](#running-standalone)\n    - [Downloading a single file](#downloading-a-single-file)\n- [Shell completion](#shell-completion)\n- [Usage](#usage)\n    - [Cmdline options](#cmdline-options)\n    - [Configuration file](#configuration-file)\n    - [googler @t](#googler-t)\n    - [Text-based browser integration](#text-based-browser-integration)\n    - [Colors](#colors)\n    - [Domain-only URL](#domain-only-url)\n    - [Windows Subsystem for Linux (WSL)](#windows-subsystem-for-linux-wsl)\n- [Troubleshooting](#troubleshooting)\n- [Notes](#notes)\n- [Contributions](#contributions)\n- [Developers](#developers)\n\n### Features\n\n- Google Search, Google Site Search, Google News, Google Videos\n- Fast and clean (no ads, stray URLs or clutter), custom color\n- Navigate result pages from omniprompt, open URLs in browser\n- Effortless keyword-based site search with googler @t add-on\n- Search and option completion scripts for Bash, Zsh and Fish\n- Fetch n results in a go, start at the n<sup>th</sup> result\n- Disable automatic spelling correction and search exact keywords\n- Specify duration, country/domain (default: worldwide/.com), language\n- Google keywords (e.g. `filetype:mime`, `site:somesite.com`) support\n- Open the first result directly in browser (as in *I'm Feeling Lucky*)\n- Non-stop searches: fire new searches at omniprompt without exiting\n- HTTPS proxy, User Agent, TLS 1.2 (default) support\n- Comprehensive documentation, man page with handy usage examples\n- Minimal dependencies\n\n### Installation\n\n#### Dependencies\n\n`googler` requires Python 3.6 or later. Only the latest patch release of each minor version is supported.\n\nTo copy url to clipboard at the omniprompt, `googler` looks for `xsel` or `xclip` or `termux-clipboard-set` (in the same order) on Linux, `pbcopy` (default installed) on macOS and `clip` (default installed) on Windows. It also supports GNU Screen and tmux copy-paste buffers in the absence of X11.\n\n#### From a package manager\n\nInstall `googler` from your package manager. If the version available is dated try an alternative installation method.\n\n<details><summary>Packaging status (expand)</summary>\n<p>\n<br>\n<a href=\"https://repology.org/project/googler/versions\"><img src=\"https://repology.org/badge/vertical-allrepos/googler.svg\" alt=\"Packaging status\"></a>\n</p>\nUnlisted packagers:\n<p>\n<br>\n <a href=\"https://snapcraft.io/googler\">Snap Store</a> (<code>snap install googler</code>)<br>\n</p>\n</details>\n\n##### Tips for packagers\n\n`googler` v2.7 and later ships with an in-place self-upgrade mechanism which you may want to disable. To do this, run\n\n    $ make disable-self-upgrade\n\nbefore installation.\n\n#### Release packages\n\nPackages for Arch Linux, CentOS, Debian, Fedora, openSUSE and Ubuntu are available with the [latest stable release](https://github.com/jarun/googler/releases/latest).\n\n#### From source\n\nIf you have git installed, clone this repository. Otherwise download the [latest stable release](https://github.com/jarun/googler/releases/latest) or [development version](https://github.com/jarun/googler/archive/master.zip).\n\nTo install to the default location (`/usr/local`):\n\n    $ sudo make install\n\nTo remove `googler` and associated docs, run\n\n    $ sudo make uninstall\n\n`PREFIX` is supported, in case you want to install to a different location.\n\n#### Running standalone\n\n`googler` is a standalone executable (and can run even on environments like Termux). From the containing directory:\n\n    $ ./googler\n\n#### Downloading a single file\n\n`googler` is a single standalone script, so you could download just a single file if you'd like to.\n\nTo install the latest stable version, run\n\n    $ sudo curl -o /usr/local/bin/googler https://raw.githubusercontent.com/jarun/googler/v4.3.2/googler && sudo chmod +x /usr/local/bin/googler\n\nYou could then let googler upgrade itself by running\n\n    $ sudo googler -u\n\nSimilarly, if you want to install from git master (*risky*), run\n\n    $ sudo curl -o /usr/local/bin/googler https://raw.githubusercontent.com/jarun/googler/master/googler && sudo chmod +x /usr/local/bin/googler\n\nand upgrade by running\n\n    $ sudo googler -u --include-git\n\n### Shell completion\n\nSearch keyword and option completion scripts for Bash, Fish and Zsh can be found in respective subdirectories of [`auto-completion/`](auto-completion). Please refer to your shell's manual for installation instructions.\n\n### Usage\n\n#### Cmdline options\n\n```\nusage: googler [-h] [-s N] [-n N] [-N] [-V] [-c TLD] [-l LANG] [-g CC] [-x]\n               [--colorize [{auto,always,never}]] [-C] [--colors COLORS] [-j] [-t dN] [--from FROM]\n               [--to TO] [-w SITE] [-e SITE] [--unfilter] [-p PROXY] [--notweak] [--json]\n               [--url-handler UTIL] [--show-browser-logs] [--np] [-4] [-6] [-u] [--include-git] [-v] [-d]\n               [KEYWORD [KEYWORD ...]]\n\nGoogle from the command-line.\n\npositional arguments:\n  KEYWORD               search keywords\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -s N, --start N       start at the Nth result\n  -n N, --count N       show N results (default 10)\n  -N, --news            show results from news section\n  -V, --videos          show results from videos section\n  -c TLD, --tld TLD     country-specific search with top-level domain .TLD, e.g., 'in' for India\n  -l LANG, --lang LANG  display in language LANG\n  -g CC, --geoloc CC    country-specific geolocation search with country code CC, e.g. 'in' for India.\n                        Country codes are the same as top-level domains\n  -x, --exact           disable automatic spelling correction\n  --colorize [{auto,always,never}]\n                        whether to colorize output; defaults to 'auto', which enables color when stdout\n                        is a tty device; using --colorize without an argument is equivalent to\n                        --colorize=always\n  -C, --nocolor         equivalent to --colorize=never\n  --colors COLORS       set output colors (see man page for details)\n  -j, --first, --lucky  open the first result in web browser and exit\n  -t dN, --time dN      time limit search [h5 (5 hrs), d5 (5 days), w5 (5 weeks), m5 (5 months), y5 (5\n                        years)]\n  --from FROM           starting date/month/year of date range; must use American date format with\n                        slashes, e.g., 2/24/2020, 2/2020, 2020; can be used in conjunction with --to,\n                        and overrides -t, --time\n  --to TO               ending date/month/year of date range; see --from\n  -w SITE, --site SITE  search a site using Google\n  -e SITE, --exclude SITE\n                        exclude site from results\n  --unfilter            do not omit similar results\n  -p PROXY, --proxy PROXY\n                        tunnel traffic through an HTTP proxy; PROXY is of the form\n                        [http://][user:password@]proxyhost[:port]\n  --notweak             disable TCP optimizations and forced TLS 1.2\n  --json                output in JSON format; implies --noprompt\n  --url-handler UTIL    custom script or cli utility to open results\n  --show-browser-logs   do not suppress browser output (stdout and stderr)\n  --np, --noprompt      search and exit, do not prompt\n  -4, --ipv4            only connect over IPv4 (by default, IPv4 is preferred but IPv6 is used as a\n                        fallback)\n  -6, --ipv6            only connect over IPv6\n  -u, --upgrade         perform in-place self-upgrade\n  --include-git         when used with --upgrade, get latest git master\n  -v, --version         show program's version number and exit\n  -d, --debug           enable debugging\n\nomniprompt keys:\n  n, p                  fetch the next or previous set of search results\n  index                 open the result corresponding to index in browser\n  f                     jump to the first page\n  o [index|range|a ...] open space-separated result indices, numeric ranges\n                        (sitelinks unsupported in ranges), or all, in browser\n                        open the current search in browser, if no arguments\n  O [index|range|a ...] like key 'o', but try to open in a GUI browser\n  g keywords            new Google search for 'keywords' with original options\n                        should be used to search omniprompt keys and indices\n  c index               copy url to clipboard\n  u                     toggle url expansion\n  q, ^D, double Enter   exit googler\n  ?                     show omniprompt help\n  *                     other inputs issue a new search with original options\n```\n\n#### Configuration file\n\n`googler` doesn't have any! This is to retain the speed of the utility and avoid OS-specific differences. Users can enjoy the advantages of config files using aliases (with the exception of the color scheme, which can be additionally customized through an environment variable; see [Colors](#colors)). There's no need to memorize options.\n\nFor example, the following alias for bash/zsh/ksh/etc.\n\n    alias g='googler -n 7 -c ru -l ru'\n\nfetches 7 results from the Google Russia server, with preference towards results in Russian.\n\nThe alias serves both the purposes of using config files:\n\n- Persistent settings: when the user invokes `g`, it expands to the preferred settings.\n- Override settings: thanks to the way Python `argparse` works, `googler` is written so that the settings in alias are completely overridden by any options passed from cli. So when the same user runs `g -l de -c de -n 12 hello world`, 12 results are returned from the Google Germany server, with preference towards results in German.\n\n#### googler @t\n\n`googler @t` is a convenient add-on to Google Site Search with unique keywords. While `googler` has an integrated option to search a site, we simplified it further with aliases. The file [googler_at](https://github.com/jarun/googler/blob/master/auto-completion/googler_at/googler_at) contains a list of website search aliases. To source it, run:\n\n    $ source googler_at\nor,\n\n    $ . googler_at\nWith `googler @t`, here's how you search Wikipedia for `hexspeak`:\n\n    $ @w hexspeak\nOh yes! You can combine other `googler` options too! To make life easier, you can also configure your shell to source the file when it starts.\n\nAll the aliases start with the `@` symbol (hence the name `googler @t`) and there is minimum chance they will conflict with any shell commands. Feel free to add your own aliases to the file and contribute back the interesting ones.\n\n#### Text-based browser integration\n\n`googler` works out of the box with several text-based browsers if the `BROWSER` environment variable is set. For instance,\n\n    $ export BROWSER=w3m\n\nor for one-time use,\n\n    $ BROWSER=w3m googler query\n\nDue to certain graphical browsers spewing messages to the console, `googler` suppresses browser output by default unless `BROWSER` is set to one of the known text-based browsers: currently `elinks`, `links`, `lynx`, `w3m` or `www-browser`. If you use a different text-based browser, you will need to explicitly enable browser output with the `--show-browser-logs` option. If you believe your browser is popular enough, please submit an issue or pull request and we will consider whitelisting it. See the man page for more details on `--show-browser-logs`.\n\nIf you need to use a GUI browser with `BROWSER` set, use the omniprompt key `O`. `googler` will try to ignore text-based browsers and invoke a GUI browser. Browser logs are always suppressed with `O`.\n\n#### Colors\n\n`googler` allows you to customize the color scheme via a six-letter string, reminiscent of BSD `LSCOLORS`. The six letters represent the colors of\n\n- indices\n- titles\n- URLs\n- metadata/publishing info (Google News only)\n- abstracts\n- prompts\n\nrespectively. The six-letter string is passed in either as the argument to the `--colors` option, or as the value of the environment variable `GOOGLER_COLORS`.\n\nWe offer the following colors/styles:\n\nLetter | Color/Style\n------ | -----------\na      | black\nb      | red\nc      | green\nd      | yellow\ne      | blue\nf      | magenta\ng      | cyan\nh      | white\ni      | bright black\nj      | bright red\nk      | bright green\nl      | bright yellow\nm      | bright blue\nn      | bright magenta\no      | bright cyan\np      | bright white\nA-H    | bold version of the lowercase-letter color\nI-P    | bold version of the lowercase-letter bright color\nx      | normal\nX      | bold\ny      | reverse video\nY      | bold reverse video\n\nThe default colors string is `GKlgxy`, which stands for\n\n- bold bright cyan indices\n- bold bright green titles\n- bright yellow URLs\n- cyan metadata/publishing info\n- normal abstracts\n- reverse video prompts\n\nNote that\n\n- Bright colors (implemented as `\\x1b[90m``\\x1b[97m`) may not be available in all color-capable terminal emulators;\n- Some terminal emulators draw bold text in bright colors instead;\n- Some terminal emulators only distinguish between bold and bright colors via a default-off switch.\n\nPlease consult the manual of your terminal emulator as well as the [Wikipedia article](https://en.wikipedia.org/wiki/ANSI_escape_code) on ANSI escape sequences.\n\n#### Domain-only URL\n\nTo show the domain names in search results instead of the expanded URL (and use lesser space), set the environment variable `DISABLE_URL_EXPANSION`.\n\n#### Windows Subsystem for Linux (WSL)\n\nOn WSL, GUI browsers on the Windows side cannot be detected by default. You need to explicitly set the `BROWSER` environment variable to the path of a Windows executable. For instance, you can put the following in your shell's rc:\n\n    $ export BROWSER='/mnt/c/Program Files (x86)/Google/Chrome/Application/chrome.exe'\n\n### Troubleshooting\n\n1. In some instances `googler` may show fewer number of results than you expect, e.g., if you fetch a single result (`-n 1`) it may not show any results. The reason is Google shows some Google service (e.g. Youtube) results, map locations etc. depending on your geographical data, which `googler` tries to omit. In some cases Google (the web-service) doesn't show exactly 10 results (default) on a search. We chose to omit these results as far as possible. While this can be fixed, it would need more processing (and more time). You can just navigate forward to fetch the next set of results.\n\n2. By default `googler` applies some TCP optimizations and forces TLS 1.2 (on Python 3.4 and above). If you are facing connection issues, try disabling both using the `--notweak` switch.\n\n3. Google News service is not available if the language is `dk` (Denmark), `fi` (Finland) or `is` (Iceland). Use `-l en`. Please refer to #187 for more information.\n\n4. Some users have reported problems with a colored omniprompt (refer to issue [#203](https://github.com/jarun/googler/issues/203)) with iTerm2 on macOS. To force a plain omniprompt:\n\n       export DISABLE_PROMPT_COLOR=1\n\n### Notes\n\n1. Initially I raised a pull request but I could see that the last change was made 7 years earlier. In addition, there is no GitHub activity from the original author [Henri Hakkinen](https://github.com/henux) in past year. I have created this independent repo for the project with the name `googler`. I retained the original copyright information (though `googler` is organically different now).\n\n2. Google provides a search API which returns the results in JSON format. However, as per my understanding from the [official docs](https://developers.google.com/custom-search/json-api/v1/overview), the API issues the queries against an existing instance of a custom search engine and is limited by 100 search queries per day for free. In addition, I have reservations in paying if they ever change their plan or restrict the API in other ways. So I refrained from coupling with Google plans & policies or exposing my trackable personal custom search API key and identifier for the public. I retained the browser-way of doing it by fetching html, which is a open and free specification.\n\n3. You can find a rofi script for `googler` [here](http://hastebin.com/fonowacija.bash). Written by an anonymous user, untested and we don't maintain it.\n\n4. The Albert Launcher python plugins repo\n([awesome-albert-plugins](https://github.com/bergercookie/awesome-albert-plugins))\nincludes suggestions-enabled search plugins for a variety of websites using\ngoogler. Refer to the latter for demos and usage instructions.\n\n### Contributions\n\nPull requests are welcome. Please visit [#209](https://github.com/jarun/googler/issues/209) for a list of TODOs.\n<br>\n<p><a href=\"https://gitter.im/jarun/googler\"><img src=\"https://img.shields.io/gitter/room/jarun/googler.svg?maxAge=2592000\" alt=\"gitter chat\" /></a></p>\n\n### Developers\n\n1. Copyright  2008 Henri Hakkinen\n2. Copyright  2015-2021 [Arun Prakash Jana](https://github.com/jarun)\n3. [Zhiming Wang](https://github.com/zmwangx)\n4. [Johnathan Jenkins](https://github.com/shaggytwodope)\n5. [SZ Lin](https://github.com/szlin)\n\nSpecial thanks to [jeremija](https://github.com/jeremija) and [Narrat](https://github.com/Narrat) for their contributions.\n\n### Logo\n\nLogo copyright  2017 Zhiming Wang.\n\nYou may freely redistribute it alongside the code, or use it when describing or linking to this project. You should NOT create modified versions of it, make it the logo or icon of your project (except personal forks and/or forks with the goal of upstreaming), or otherwise use it without written permission.\n"
        },
        {
          "name": "auto-completion",
          "type": "tree",
          "content": null
        },
        {
          "name": "googler",
          "type": "blob",
          "size": 133.3564453125,
          "content": "#!/usr/bin/env python3\n#\n# Copyright  2008 Henri Hakkinen\n# Copyright  2015-2021 Arun Prakash Jana <engineerarun@gmail.com>\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport argparse\nimport atexit\nimport base64\nimport collections\nimport codecs\nimport functools\nimport gzip\nimport html.entities\nimport html.parser\nimport http.client\nfrom http.client import HTTPSConnection\nimport locale\nimport logging\nimport os\nimport platform\nimport shutil\nimport signal\nimport socket\nimport ssl\nimport subprocess\nfrom subprocess import Popen, PIPE, DEVNULL\nimport sys\nimport textwrap\nimport unicodedata\nimport urllib.parse\nimport uuid\nimport webbrowser\n\n# Python optional dependency compatibility layer\ntry:\n    import readline\nexcept ImportError:\n    pass\n\ntry:\n    import setproctitle\n    setproctitle.setproctitle('googler')\nexcept (ImportError, Exception):\n    pass\n\nfrom typing import (\n    Any,\n    Dict,\n    Generator,\n    Iterable,\n    Iterator,\n    List,\n    Match,\n    Optional,\n    Sequence,\n    Tuple,\n    Union,\n    cast,\n)\n\n# Basic setup\n\nlogging.basicConfig(format='[%(levelname)s] %(message)s')\nlogger = logging.getLogger()\n\n\ndef sigint_handler(signum, frame):\n    print('\\nInterrupted.', file=sys.stderr)\n    sys.exit(1)\n\ntry:\n    signal.signal(signal.SIGINT, sigint_handler)\nexcept ValueError:\n    # signal only works in main thread\n    pass\n\n\n# Constants\n\n_VERSION_ = '4.3.2'\n_EPOCH_ = '20210115'\n\nCOLORMAP = {k: '\\x1b[%sm' % v for k, v in {\n    'a': '30', 'b': '31', 'c': '32', 'd': '33',\n    'e': '34', 'f': '35', 'g': '36', 'h': '37',\n    'i': '90', 'j': '91', 'k': '92', 'l': '93',\n    'm': '94', 'n': '95', 'o': '96', 'p': '97',\n    'A': '30;1', 'B': '31;1', 'C': '32;1', 'D': '33;1',\n    'E': '34;1', 'F': '35;1', 'G': '36;1', 'H': '37;1',\n    'I': '90;1', 'J': '91;1', 'K': '92;1', 'L': '93;1',\n    'M': '94;1', 'N': '95;1', 'O': '96;1', 'P': '97;1',\n    'x': '0', 'X': '1', 'y': '7', 'Y': '7;1',\n}.items()}\n\nUSER_AGENT = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36'\n\ntext_browsers = ['elinks', 'links', 'lynx', 'w3m', 'www-browser']\n\n# Self-upgrade parameters\n#\n# Downstream packagers are recommended to turn off the entire self-upgrade\n# mechanism through\n#\n#     make disable-self-upgrade\n#\n# before running `make install'.\n\nENABLE_SELF_UPGRADE_MECHANISM = True\nAPI_REPO_BASE = 'https://api.github.com/repos/jarun/googler'\nRAW_DOWNLOAD_REPO_BASE = 'https://raw.githubusercontent.com/jarun/googler'\n\ndebugger = False\n\n\n# Monkeypatch textwrap for CJK wide characters.\n\ndef monkeypatch_textwrap_for_cjk():\n    try:\n        if textwrap.wrap.patched:\n            return\n    except AttributeError:\n        pass\n    psl_textwrap_wrap = textwrap.wrap\n\n    def textwrap_wrap(text, width=70, **kwargs):\n        if width <= 2:\n            width = 2\n        # We first add a U+0000 after each East Asian Fullwidth or East\n        # Asian Wide character, then fill to width - 1 (so that if a NUL\n        # character ends up on a new line, we still have one last column\n        # to spare for the preceding wide character). Finally we strip\n        # all the NUL characters.\n        #\n        # East Asian Width: https://www.unicode.org/reports/tr11/\n        return [\n            line.replace('\\0', '')\n            for line in psl_textwrap_wrap(\n                ''.join(\n                    ch + '\\0' if unicodedata.east_asian_width(ch) in ('F', 'W') else ch\n                    for ch in unicodedata.normalize('NFC', text)\n                ),\n                width=width - 1,\n                **kwargs\n            )\n        ]\n\n    def textwrap_fill(text, width=70, **kwargs):\n        return '\\n'.join(textwrap_wrap(text, width=width, **kwargs))\n\n    textwrap.wrap = textwrap_wrap\n    textwrap.fill = textwrap_fill\n    textwrap.wrap.patched = True\n    textwrap.fill.patched = True\n\n\nmonkeypatch_textwrap_for_cjk()\n\n\nCoordinateType = Tuple[int, int]\n\n\nclass TrackedTextwrap:\n    \"\"\"\n    Implements a text wrapper that tracks the position of each source\n    character, and can correctly insert zero-width sequences at given\n    offsets of the source text.\n\n    Wrapping result should be the same as that from PSL textwrap.wrap\n    with default settings except expand_tabs=False.\n    \"\"\"\n\n    def __init__(self, text: str, width: int):\n        self._original = text\n\n        # Do the job of replace_whitespace first so that we can easily\n        # match text to wrapped lines later. Note that this operation\n        # does not change text length or offsets.\n        whitespace = \"\\t\\n\\v\\f\\r \"\n        whitespace_trans = str.maketrans(whitespace, \" \" * len(whitespace))\n        text = text.translate(whitespace_trans)\n\n        self._lines = textwrap.wrap(\n            text, width, expand_tabs=False, replace_whitespace=False\n        )\n\n        # self._coords track the (row, column) coordinate of each source\n        # character in the result text. It is indexed by offset in\n        # source text.\n        self._coords = []  # type: List[CoordinateType]\n        offset = 0\n        try:\n            if not self._lines:\n                # Source text only has whitespaces. We add an empty line\n                # in order to produce meaningful coordinates.\n                self._lines = [\"\"]\n            for row, line in enumerate(self._lines):\n                assert text[offset : offset + len(line)] == line\n                col = 0\n                for _ in line:\n                    self._coords.append((row, col))\n                    offset += 1\n                    col += 1\n                # All subsequent dropped whitespaces map to the last, imaginary column\n                # (the EOL character if you wish) of the current line.\n                while offset < len(text) and text[offset] == \" \":\n                    self._coords.append((row, col))\n                    offset += 1\n            # One past the final character (think of it as EOF) should\n            # be treated as a valid offset.\n            self._coords.append((row, col))\n        except AssertionError:\n            raise RuntimeError(\n                \"TrackedTextwrap: the impossible happened at offset {} of text {!r}\".format(\n                    offset, self._original\n                )\n            )\n\n    # seq should be a zero-width sequence, e.g., an ANSI escape sequence.\n    # May raise IndexError if offset is out of bounds.\n    def insert_zero_width_sequence(self, seq: str, offset: int) -> None:\n        row, col = self._coords[offset]\n        line = self._lines[row]\n        self._lines[row] = line[:col] + seq + line[col:]\n\n        # Shift coordinates of all characters after the given character\n        # on the same line.\n        shift = len(seq)\n        offset += 1\n        while offset < len(self._coords) and self._coords[offset][0] == row:\n            _, col = self._coords[offset]\n            self._coords[offset] = (row, col + shift)\n            offset += 1\n\n    @property\n    def original(self) -> str:\n        return self._original\n\n    @property\n    def lines(self) -> List[str]:\n        return self._lines\n\n    @property\n    def wrapped(self) -> str:\n        return \"\\n\".join(self._lines)\n\n    # May raise IndexError if offset is out of bounds.\n    def get_coordinate(self, offset: int) -> CoordinateType:\n        return self._coords[offset]\n\n\n### begin dim (DOM implementation with CSS support) ###\n### https://github.com/zmwangx/dim/blob/master/dim.py ###\n\nimport html\nimport re\nfrom collections import OrderedDict\nfrom enum import Enum\nfrom html.parser import HTMLParser\n\n\nSelectorGroupLike = Union[str, \"SelectorGroup\", \"Selector\"]\n\n\nclass Node(object):\n    \"\"\"\n    Represents a DOM node.\n\n    Parts of JavaScript's DOM ``Node`` API and ``Element`` API are\n    mirrored here, with extensions. In particular, ``querySelector`` and\n    ``querySelectorAll`` are mirrored.\n\n    Notable properties and methods: :meth:`attr()`, :attr:`classes`,\n    :attr:`html`, :attr:`text`, :meth:`ancestors()`,\n    :meth:`descendants()`, :meth:`select()`, :meth:`select_all()`,\n    :meth:`matched_by()`,\n\n    Attributes:\n        tag      (:class:`Optional`\\\\[:class:`str`])\n        attrs    (:class:`Dict`\\\\[:class:`str`, :class:`str`])\n        parent   (:class:`Optional`\\\\[:class:`Node`])\n        children (:class:`List`\\\\[:class:`Node`])\n    \"\"\"\n\n    # Meant to be reimplemented by subclasses.\n    def __init__(self) -> None:\n        self.tag = None  # type: Optional[str]\n        self.attrs = {}  # type: Dict[str, str]\n        self.parent = None  # type: Optional[Node]\n        self.children = []  # type: List[Node]\n\n        # Used in DOMBuilder.\n        self._partial = False\n        self._namespace = None  # type: Optional[str]\n\n    # HTML representation of the node. Meant to be implemented by\n    # subclasses.\n    def __str__(self) -> str:  # pragma: no cover\n        raise NotImplementedError\n\n    def select(self, selector: SelectorGroupLike) -> Optional[\"Node\"]:\n        \"\"\"DOM ``querySelector`` clone. Returns one match (if any).\"\"\"\n        selector = self._normalize_selector(selector)\n        for node in self._select_all(selector):\n            return node\n        return None\n\n    def query_selector(self, selector: SelectorGroupLike) -> Optional[\"Node\"]:\n        \"\"\"Alias of :meth:`select`.\"\"\"\n        return self.select(selector)\n\n    def select_all(self, selector: SelectorGroupLike) -> List[\"Node\"]:\n        \"\"\"DOM ``querySelectorAll`` clone. Returns all matches in a list.\"\"\"\n        selector = self._normalize_selector(selector)\n        return list(self._select_all(selector))\n\n    def query_selector_all(self, selector: SelectorGroupLike) -> List[\"Node\"]:\n        \"\"\"Alias of :meth:`select_all`.\"\"\"\n        return self.select_all(selector)\n\n    def matched_by(\n        self, selector: SelectorGroupLike, root: Optional[\"Node\"] = None\n    ) -> bool:\n        \"\"\"\n        Checks whether this node is matched by `selector`.\n\n        See :meth:`SelectorGroup.matches()`.\n        \"\"\"\n        selector = self._normalize_selector(selector)\n        return selector.matches(self, root=root)\n\n    @staticmethod\n    def _normalize_selector(selector: SelectorGroupLike) -> \"SelectorGroup\":\n        if isinstance(selector, str):\n            return SelectorGroup.from_str(selector)\n        if isinstance(selector, SelectorGroup):\n            return selector\n        if isinstance(selector, Selector):\n            return SelectorGroup([selector])\n        raise ValueError(\"not a selector or group of selectors: %s\" % repr(selector))\n\n    def _select_all(self, selector: \"SelectorGroup\") -> Generator[\"Node\", None, None]:\n        for descendant in self.descendants():\n            if selector.matches(descendant, root=self):\n                yield descendant\n\n    def child_nodes(self) -> List[\"Node\"]:\n        return self.children\n\n    def first_child(self) -> Optional[\"Node\"]:\n        if self.children:\n            return self.children[0]\n        else:\n            return None\n\n    def first_element_child(self) -> Optional[\"Node\"]:\n        for child in self.children:\n            if isinstance(child, ElementNode):\n                return child\n        return None\n\n    def last_child(self) -> Optional[\"Node\"]:\n        if self.children:\n            return self.children[-1]\n        else:\n            return None\n\n    def last_element_child(self) -> Optional[\"Node\"]:\n        for child in reversed(self.children):\n            if isinstance(child, ElementNode):\n                return child\n        return None\n\n    def next_sibling(self) -> Optional[\"Node\"]:\n        \"\"\".. note:: Not O(1), use with caution.\"\"\"\n        next_siblings = self.next_siblings()\n        if next_siblings:\n            return next_siblings[0]\n        else:\n            return None\n\n    def next_siblings(self) -> List[\"Node\"]:\n        parent = self.parent\n        if not parent:\n            return []\n        try:\n            index = parent.children.index(self)\n            return parent.children[index + 1 :]\n        except ValueError:  # pragma: no cover\n            raise ValueError(\"node is not found in children of its parent\")\n\n    def next_element_sibling(self) -> Optional[\"ElementNode\"]:\n        \"\"\".. note:: Not O(1), use with caution.\"\"\"\n        for sibling in self.next_siblings():\n            if isinstance(sibling, ElementNode):\n                return sibling\n        return None\n\n    def previous_sibling(self) -> Optional[\"Node\"]:\n        \"\"\".. note:: Not O(1), use with caution.\"\"\"\n        previous_siblings = self.previous_siblings()\n        if previous_siblings:\n            return previous_siblings[0]\n        else:\n            return None\n\n    def previous_siblings(self) -> List[\"Node\"]:\n        \"\"\"\n        Compared to the natural DOM order, the order of returned nodes\n        are reversed. That is, the adjacent sibling (if any) is the\n        first in the returned list.\n        \"\"\"\n        parent = self.parent\n        if not parent:\n            return []\n        try:\n            index = parent.children.index(self)\n            if index > 0:\n                return parent.children[index - 1 :: -1]\n            else:\n                return []\n        except ValueError:  # pragma: no cover\n            raise ValueError(\"node is not found in children of its parent\")\n\n    def previous_element_sibling(self) -> Optional[\"ElementNode\"]:\n        \"\"\".. note:: Not O(1), use with caution.\"\"\"\n        for sibling in self.previous_siblings():\n            if isinstance(sibling, ElementNode):\n                return sibling\n        return None\n\n    def ancestors(\n        self, *, root: Optional[\"Node\"] = None\n    ) -> Generator[\"Node\", None, None]:\n        \"\"\"\n        Ancestors are generated in reverse order of depth, stopping at\n        `root`.\n\n        A :class:`RuntimeException` is raised if `root` is not in the\n        ancestral chain.\n        \"\"\"\n        if self is root:\n            return\n        ancestor = self.parent\n        while ancestor is not root:\n            if ancestor is None:\n                raise RuntimeError(\"provided root node not found in ancestral chain\")\n            yield ancestor\n            ancestor = ancestor.parent\n        if root:\n            yield root\n\n    def descendants(self) -> Generator[\"Node\", None, None]:\n        \"\"\"Descendants are generated in depth-first order.\"\"\"\n        for child in self.children:\n            yield child\n            yield from child.descendants()\n\n    def attr(self, attr: str) -> Optional[str]:\n        \"\"\"Returns the attribute if it exists on the node, otherwise ``None``.\"\"\"\n        return self.attrs.get(attr)\n\n    @property\n    def html(self) -> str:\n        \"\"\"\n        HTML representation of the node.\n\n        (For a :class:`TextNode`, :meth:`html` returns the escaped version of the\n        text.\n        \"\"\"\n        return str(self)\n\n    def outer_html(self) -> str:\n        \"\"\"Alias of :attr:`html`.\"\"\"\n        return self.html\n\n    def inner_html(self) -> str:\n        \"\"\"HTML representation of the node's children.\"\"\"\n        return \"\".join(child.html for child in self.children)\n\n    @property\n    def text(self) -> str:  # pragma: no cover\n        \"\"\"This property is expected to be implemented by subclasses.\"\"\"\n        raise NotImplementedError\n\n    def text_content(self) -> str:\n        \"\"\"Alias of :attr:`text`.\"\"\"\n        return self.text\n\n    @property\n    def classes(self) -> List[str]:\n        return self.attrs.get(\"class\", \"\").split()\n\n    def class_list(self) -> List[str]:\n        return self.classes\n\n\nclass ElementNode(Node):\n    \"\"\"\n    Represents an element node.\n\n    Note that tag and attribute names are case-insensitive; attribute\n    values are case-sensitive.\n    \"\"\"\n\n    def __init__(\n        self,\n        tag: str,\n        attrs: Iterable[Tuple[str, Optional[str]]],\n        *,\n        parent: Optional[\"Node\"] = None,\n        children: Optional[Sequence[\"Node\"]] = None\n    ) -> None:\n        Node.__init__(self)\n        self.tag = tag.lower()  # type: str\n        self.attrs = OrderedDict((attr.lower(), val or \"\") for attr, val in attrs)\n        self.parent = parent\n        self.children = list(children or [])\n\n    def __repr__(self) -> str:\n        s = \"<\" + self.tag\n        if self.attrs:\n            s += \" attrs=%s\" % repr(list(self.attrs.items()))\n        if self.children:\n            s += \" children=%s\" % repr(self.children)\n        s += \">\"\n        return s\n\n    # https://ipython.readthedocs.io/en/stable/api/generated/IPython.lib.pretty.html\n    def _repr_pretty_(self, p: Any, cycle: bool) -> None:  # pragma: no cover\n        if cycle:\n            raise RuntimeError(\"cycle detected in DOM tree\")\n        p.text(\"<\\x1b[1m%s\\x1b[0m\" % self.tag)\n        if self.attrs:\n            p.text(\" attrs=%s\" % repr(list(self.attrs.items())))\n        if self.children:\n            p.text(\" children=[\")\n            if len(self.children) == 1 and isinstance(self.first_child(), TextNode):\n                p.text(\"\\x1b[4m%s\\x1b[0m\" % repr(self.first_child()))\n            else:\n                with p.indent(2):\n                    for child in self.children:\n                        p.break_()\n                        if hasattr(child, \"_repr_pretty_\"):\n                            child._repr_pretty_(p, False)  # type: ignore\n                        else:\n                            p.text(\"\\x1b[4m%s\\x1b[0m\" % repr(child))\n                        p.text(\",\")\n                p.break_()\n            p.text(\"]\")\n        p.text(\">\")\n\n    def __str__(self) -> str:\n        \"\"\"HTML representation of the node.\"\"\"\n        s = \"<\" + self.tag\n        for attr, val in self.attrs.items():\n            s += ' %s=\"%s\"' % (attr, html.escape(val))\n        if self.children:\n            s += \">\"\n            s += \"\".join(str(child) for child in self.children)\n            s += \"</%s>\" % self.tag\n        else:\n            if _tag_is_void(self.tag):\n                s += \"/>\"\n            else:\n                s += \"></%s>\" % self.tag\n        return s\n\n    @property\n    def text(self) -> str:\n        \"\"\"The concatenation of all descendant text nodes.\"\"\"\n        return \"\".join(child.text for child in self.children)\n\n\nclass TextNode(str, Node):\n    \"\"\"\n    Represents a text node.\n\n    Subclasses :class:`Node` and :class:`str`.\n    \"\"\"\n\n    def __new__(cls, text: str) -> \"TextNode\":\n        s = str.__new__(cls, text)  # type: ignore\n        s.parent = None\n        return s  # type: ignore\n\n    def __init__(self, text: str) -> None:\n        Node.__init__(self)\n\n    def __repr__(self) -> str:\n        return \"<%s>\" % str.__repr__(self)\n\n    # HTML-escaped form of the text node. use text() for unescaped\n    # version.\n    def __str__(self) -> str:\n        return html.escape(self)\n\n    def __eq__(self, other: object) -> bool:\n        \"\"\"\n        Two text nodes are equal if and only if they are the same node.\n\n        For string comparison, use :attr:`text`.\n        \"\"\"\n        return self is other\n\n    def __ne__(self, other: object) -> bool:\n        \"\"\"\n        Two text nodes are non-equal if they are not the same node.\n\n        For string comparison, use :attr:`text`.\n        \"\"\"\n        return self is not other\n\n    @property\n    def text(self) -> str:\n        return str.__str__(self)\n\n\nclass DOMBuilderException(Exception):\n    \"\"\"\n    Exception raised when :class:`DOMBuilder` detects a bad state.\n\n    Attributes:\n        pos (:class:`Tuple`\\\\[:class:`int`, :class:`int`]):\n            Line number and offset in HTML input.\n        why (:class:`str`):\n            Reason of the exception.\n    \"\"\"\n\n    def __init__(self, pos: Tuple[int, int], why: str) -> None:\n        self.pos = pos\n        self.why = why\n\n    def __str__(self) -> str:  # pragma: no cover\n        return \"DOM builder aborted at %d:%d: %s\" % (self.pos[0], self.pos[1], self.why)\n\n\nclass DOMBuilder(HTMLParser):\n    \"\"\"\n    HTML parser / DOM builder.\n\n    Subclasses :class:`html.parser.HTMLParser`.\n\n    Consume HTML and builds a :class:`Node` tree. Once finished, use\n    :attr:`root` to access the root of the tree.\n\n    This parser cannot parse malformed HTML with tag mismatch.\n    \"\"\"\n\n    def __init__(self) -> None:\n        super().__init__(convert_charrefs=True)\n        # _stack is the stack for nodes. Each node is pushed to the\n        # stack when its start tag is processed, and remains on the\n        # stack until its parent node is completed (end tag processed),\n        # at which point the node is attached to the parent node as a\n        # child and popped from the stack.\n        self._stack = []  # type: List[Node]\n        # _namespace_stack is another stack tracking the parsing\n        # context, which is generally the default namespace (None) but\n        # changes when parsing foreign objects (e.g. 'svg' when parsing\n        # an <svg>). The top element is always the current parsing\n        # context, so popping works differently from _stack: an element\n        # is popped as soon as the corresponding end tag is processed.\n        self._namespace_stack = [None]  # type: List[Optional[str]]\n\n    def handle_starttag(\n        self, tag: str, attrs: Sequence[Tuple[str, Optional[str]]]\n    ) -> None:\n        node = ElementNode(tag, attrs)\n        node._partial = True\n        self._stack.append(node)\n        namespace = (\n            tag.lower()\n            if _tag_encloses_foreign_namespace(tag)\n            else self._namespace_stack[-1]  # Inherit parent namespace\n        )\n        node._namespace = namespace\n        self._namespace_stack.append(namespace)\n        # For void elements (not in a foreign context), immediately\n        # invoke the end tag handler (see handle_startendtag()).\n        if not namespace and _tag_is_void(tag):\n            self.handle_endtag(tag)\n\n    def handle_endtag(self, tag: str) -> None:\n        tag = tag.lower()\n        children = []\n        while self._stack and not self._stack[-1]._partial:\n            children.append(self._stack.pop())\n        if not self._stack:\n            raise DOMBuilderException(self.getpos(), \"extra end tag: %s\" % repr(tag))\n        parent = self._stack[-1]\n        if parent.tag != tag:\n            raise DOMBuilderException(\n                self.getpos(),\n                \"expecting end tag %s, got %s\" % (repr(parent.tag), repr(tag)),\n            )\n        parent.children = list(reversed(children))\n        parent._partial = False\n        for child in children:\n            child.parent = parent\n        self._namespace_stack.pop()\n\n    # Make parser behavior for explicitly and implicitly void elements\n    # (e.g., <hr> vs <hr/>) consistent. The former triggers\n    # handle_starttag only, whereas the latter triggers\n    # handle_startendtag (which by default triggers both handle_starttag\n    # and handle_endtag). See https://bugs.python.org/issue25258.\n    #\n    # An exception is foreign elements, which aren't considered void\n    # elements but can be explicitly marked as self-closing according to\n    # the HTML spec (e.g. <path/> is valid but <path> is not).\n    # Therefore, both handle_starttag and handle_endtag must be called,\n    # and handle_endtag should not be triggered from within\n    # handle_starttag in that case.\n    #\n    # Note that for simplicity we do not check whether the foreign\n    # element in question is allowed to be self-closing by spec. (The\n    # SVG spec unfortunately doesn't provide a readily available list of\n    # such elements.)\n    #\n    # https://html.spec.whatwg.org/multipage/syntax.html#foreign-elements\n    def handle_startendtag(\n        self, tag: str, attrs: Sequence[Tuple[str, Optional[str]]]\n    ) -> None:\n        if self._namespace_stack[-1] or _tag_encloses_foreign_namespace(tag):\n            self.handle_starttag(tag, attrs)\n            self.handle_endtag(tag)\n        else:\n            self.handle_starttag(tag, attrs)\n\n    def handle_data(self, text: str) -> None:\n        if not self._stack:\n            # Ignore text nodes before the first tag.\n            return\n        self._stack.append(TextNode(text))\n\n    @property\n    def root(self) -> \"Node\":\n        \"\"\"\n        Finishes processing and returns the root node.\n\n        Raises :class:`DOMBuilderException` if there is no root tag or\n        root tag is not closed yet.\n        \"\"\"\n        if not self._stack:\n            raise DOMBuilderException(self.getpos(), \"no root tag\")\n        if self._stack[0]._partial:\n            raise DOMBuilderException(self.getpos(), \"root tag not closed yet\")\n        return self._stack[0]\n\n\ndef parse_html(html: str, *, ParserClass: type = DOMBuilder) -> \"Node\":\n    \"\"\"\n    Parses HTML string, builds DOM, and returns root node.\n\n    The parser may raise :class:`DOMBuilderException`.\n\n    Args:\n        html: input HTML string\n        ParserClass: :class:`DOMBuilder` or a subclass\n\n    Returns:\n        Root note of the parsed tree. If the HTML string contains\n        multiple top-level elements, only the first is returned and the\n        rest are lost.\n    \"\"\"\n    builder = ParserClass()  # type: DOMBuilder\n    builder.feed(html)\n    builder.close()\n    return builder.root\n\n\nclass SelectorParserException(Exception):\n    \"\"\"\n    Exception raised when the selector parser fails to parse an input.\n\n    Attributes:\n        s (:class:`str`):\n            The input string to be parsed.\n        cursor (:class:`int`):\n            Cursor position where the failure occurred.\n        why (:class:`str`):\n            Reason of the failure.\n    \"\"\"\n\n    def __init__(self, s: str, cursor: int, why: str) -> None:\n        self.s = s\n        self.cursor = cursor\n        self.why = why\n\n    def __str__(self) -> str:  # pragma: no cover\n        return \"selector parser aborted at character %d of %s: %s\" % (\n            self.cursor,\n            repr(self.s),\n            self.why,\n        )\n\n\nclass SelectorGroup:\n    \"\"\"\n    Represents a group of CSS selectors.\n\n    A group of CSS selectors is simply a comma-separated list of\n    selectors. [#]_ See :class:`Selector` documentation for the scope of\n    support.\n\n    Typically, a :class:`SelectorGroup` is constructed from a string\n    (e.g., ``th.center, td.center``) using the factory function\n    :meth:`from_str`.\n\n    .. [#] https://www.w3.org/TR/selectors-3/#grouping\n    \"\"\"\n\n    def __init__(self, selectors: Iterable[\"Selector\"]) -> None:\n        self._selectors = list(selectors)\n\n    def __repr__(self) -> str:\n        return \"<SelectorGroup %s>\" % repr(str(self))\n\n    def __str__(self) -> str:\n        return \", \".join(str(selector) for selector in self._selectors)\n\n    def __len__(self) -> int:\n        return len(self._selectors)\n\n    def __getitem__(self, index: int) -> \"Selector\":\n        return self._selectors[index]\n\n    def __iter__(self) -> Iterator[\"Selector\"]:\n        return iter(self._selectors)\n\n    @classmethod\n    def from_str(cls, s: str) -> \"SelectorGroup\":\n        \"\"\"\n        Parses input string into a group of selectors.\n\n        :class:`SelectorParserException` is raised on invalid input. See\n        :class:`Selector` documentation for the scope of support.\n\n        Args:\n            s: input string\n\n        Returns:\n            Parsed group of selectors.\n        \"\"\"\n        i = 0\n        selectors = []\n        while i < len(s):\n            selector, i = Selector.from_str(s, i)\n            selectors.append(selector)\n        if not selectors:\n            raise SelectorParserException(s, i, \"selector group is empty\")\n        return cls(selectors)\n\n    def matches(self, node: \"Node\", root: Optional[\"Node\"] = None) -> bool:\n        \"\"\"\n        Decides whether the group of selectors matches `node`.\n\n        The group of selectors matches `node` as long as one of the\n        selectors matches `node`.\n\n        If `root` is provided and child and/or descendant combinators\n        are involved, parent/ancestor lookup terminates at `root`.\n        \"\"\"\n        return any(selector.matches(node, root=root) for selector in self)\n\n\nclass Selector:\n    \"\"\"\n    Represents a CSS selector.\n\n    Recall that a CSS selector is a chain of one or more *sequences of\n    simple selectors* separated by *combinators*. [#selectors-3]_ This\n    concept is represented as a cons list of sequences of simple\n    selectors (in right to left order). This class in fact holds a\n    single sequence, with an optional combinator and reference to the\n    previous sequence.\n\n    For instance, ``main#main p.important.definition >\n    a.term[id][href]`` would be parsed into (schematically) the\n    following structure::\n\n        \">\" tag='a' classes=('term') attrs=([id], [href]) ~>\n        \" \" tag='p' classes=('important', 'definition') ~>\n        tag='main' id='main'\n\n    Each line is held in a separate instance of :class:`Selector`,\n    linked together by the :attr:`previous` attribute.\n\n    Supported grammar (from selectors level 3 [#selectors-3]_):\n\n    - Type selectors;\n    - Universal selectors;\n    - Class selectors;\n    - ID selectors;\n    - Attribute selectors;\n    - Combinators.\n\n    Unsupported grammar:\n\n    - Pseudo-classes;\n    - Pseudo-elements;\n    - Namespace prefixes (``ns|``, ``*|``, ``|``) in any part of any\n      selector.\n\n    Rationale:\n\n    - Pseudo-classes have too many variants, a few of which even\n      complete with an admittedly not-so-complex minilanguage. These add\n      up to a lot of code.\n    - Pseudo-elements are useless outside rendering contexts, hence out of\n      scope.\n    - Namespace support is too niche to be worth the parsing headache.\n      *Using namespace prefixes may confuse the parser!*\n\n    Note that the parser only loosely follows the spec and priotizes\n    ease of parsing (which includes readability and *writability* of\n    regexes), so some invalid selectors may be accepted (in fact, false\n    positives abound, but accepting valid inputs is a much more\n    important goal than rejecting invalid inputs for this library), and\n    some valid selectors may be rejected (but as long as you stick to\n    the scope outlined above and common sense you should be fine; the\n    false negatives shouldn't be used by actual human beings anyway).\n\n    In particular, whitespace character is simplified to ``\\\\s`` (ASCII\n    mode) despite CSS spec not counting U+000B (VT) as whitespace,\n    identifiers are simplified to ``[\\\\w-]+`` (ASCII mode), and strings\n    (attribute selector values can be either identifiers or strings)\n    allow escaped quotes (i.e., ``\\\\'`` inside single-quoted strings and\n    ``\\\\\"`` inside double-quoted strings) but everything else is\n    interpreted literally. The exact specs for CSS identifiers and\n    strings can be found at [#]_.\n\n    Certain selectors and combinators may be implemented in the parser\n    but not implemented in matching and/or selection APIs.\n\n    .. [#selectors-3] https://www.w3.org/TR/selectors-3/\n    .. [#] https://www.w3.org/TR/CSS21/syndata.html\n\n    Attributes:\n        tag (:class:`Optional`\\\\[:class:`str`]):\n            Type selector.\n        classes (:class:`List`\\\\[:class:`str`]):\n            Class selectors.\n        id (:class:`Optional`\\\\[:class:`str`]):\n            ID selector.\n        attrs (:class:`List`\\\\[:class:`AttributeSelector`]):\n            Attribute selectors.\n        combinator (:class:`Optional`\\\\[:class:`Combinator`]):\n            Combinator with the previous sequence of simple selectors in\n            chain.\n        previous (:class:`Optional`\\\\[:class:`Selector`]):\n            Reference to the previous sequence of simple selectors in\n            chain.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        tag: Optional[str] = None,\n        classes: Optional[Sequence[str]] = None,\n        id: Optional[str] = None,\n        attrs: Optional[Sequence[\"AttributeSelector\"]] = None,\n        combinator: Optional[\"Combinator\"] = None,\n        previous: Optional[\"Selector\"] = None\n    ) -> None:\n        self.tag = tag.lower() if tag else None\n        self.classes = list(classes or [])\n        self.id = id\n        self.attrs = list(attrs or [])\n        self.combinator = combinator\n        self.previous = previous\n\n    def __repr__(self) -> str:\n        return \"<Selector %s>\" % repr(str(self))\n\n    def __str__(self) -> str:\n        sequences = []\n        delimiters = []\n        seq = self\n        while True:\n            sequences.append(seq._sequence_str_())\n            if seq.previous:\n                if seq.combinator == Combinator.DESCENDANT:\n                    delimiters.append(\" \")\n                elif seq.combinator == Combinator.CHILD:\n                    delimiters.append(\" > \")\n                elif seq.combinator == Combinator.NEXT_SIBLING:\n                    delimiters.append(\" + \")\n                elif seq.combinator == Combinator.SUBSEQUENT_SIBLING:\n                    delimiters.append(\" ~ \")\n                else:  # pragma: no cover\n                    raise RuntimeError(\n                        \"unimplemented combinator: %s\" % repr(self.combinator)\n                    )\n                seq = seq.previous\n            else:\n                delimiters.append(\"\")\n                break\n        return \"\".join(\n            delimiter + sequence\n            for delimiter, sequence in zip(reversed(delimiters), reversed(sequences))\n        )\n\n    # Format a single sequence of simple selectors, without combinator.\n    def _sequence_str_(self) -> str:\n        s = \"\"\n        if self.tag:\n            s += self.tag\n        if self.classes:\n            s += \"\".join(\".%s\" % class_ for class_ in self.classes)\n        if self.id:\n            s += \"#%s\" % self.id\n        if self.attrs:\n            s += \"\".join(str(attr) for attr in self.attrs)\n        return s if s else \"*\"\n\n    @classmethod\n    def from_str(cls, s: str, cursor: int = 0) -> Tuple[\"Selector\", int]:\n        \"\"\"\n        Parses input string into selector.\n\n        This factory function only parses out one selector (up to a\n        comma or EOS), so partial consumption is allowed --- an optional\n        `cursor` is taken as input (0 by default) and the moved cursor\n        (either after the comma or at EOS) is returned as part of the\n        output.\n\n        :class:`SelectorParserException` is raised on invalid input. See\n        :class:`Selector` documentation for the scope of support.\n\n        If you need to completely consume a string representing\n        (potentially) a group of selectors, use\n        :meth:`SelectorGroup.from_str()`.\n\n        Args:\n            s:      input string\n            cursor: initial cursor position on `s`\n\n        Returns:\n            A tuple containing the parsed selector and the moved the\n            cursor (either after a comma-delimiter, or at EOS).\n        \"\"\"\n        # Simple selectors.\n        TYPE_SEL = re.compile(r\"[\\w-]+\", re.A)\n        UNIVERSAL_SEL = re.compile(r\"\\*\")\n        ATTR_SEL = re.compile(\n            r\"\"\"\\[\n            \\s*(?P<attr>[\\w-]+)\\s*\n            (\n                (?P<op>[~|^$*]?=)\\s*\n                (\n                    (?P<val_identifier>[\\w-]+)|\n                    (?P<val_string>\n                        (?P<quote>['\"])\n                        (?P<val_string_inner>.*?)\n                        (?<!\\\\)(?P=quote)\n                    )\n                )\\s*\n            )?\n            \\]\"\"\",\n            re.A | re.X,\n        )\n        CLASS_SEL = re.compile(r\"\\.([\\w-]+)\", re.A)\n        ID_SEL = re.compile(r\"#([\\w-]+)\", re.A)\n        PSEUDO_CLASS_SEL = re.compile(r\":[\\w-]+(\\([^)]+\\))?\", re.A)\n        PSEUDO_ELEM_SEL = re.compile(r\"::[\\w-]+\", re.A)\n\n        # Combinators\n        DESCENDANT_COM = re.compile(r\"\\s+\")\n        CHILD_COM = re.compile(r\"\\s*>\\s*\")\n        NEXT_SIB_COM = re.compile(r\"\\s*\\+\\s*\")\n        SUB_SIB_COM = re.compile(r\"\\s*~\\s*\")\n\n        # Misc\n        WHITESPACE = re.compile(r\"\\s*\")\n        END_OF_SELECTOR = re.compile(r\"\\s*($|,)\")\n\n        tag = None\n        classes = []\n        id = None\n        attrs = []\n        combinator = None\n\n        selector = None\n        previous_combinator = None\n\n        i = cursor\n\n        # Skip leading whitespace\n        m = WHITESPACE.match(s, i)\n        if m:\n            i = m.end()\n\n        while i < len(s):\n            # Parse one simple selector.\n            #\n            # PEP 572 (assignment expressions; the one that burned Guido\n            # so much that he resigned as BDFL) would have been nice; it\n            # would have saved us from all the regex match\n            # reassignments, and worse still, the casts, since mypy\n            # complains about getting Optional[Match[str]] instead of\n            # Match[str].\n            if TYPE_SEL.match(s, i):\n                if tag:\n                    raise SelectorParserException(s, i, \"multiple type selectors found\")\n                m = cast(Match[str], TYPE_SEL.match(s, i))\n                tag = m.group()\n            elif UNIVERSAL_SEL.match(s, i):\n                m = cast(Match[str], UNIVERSAL_SEL.match(s, i))\n            elif ATTR_SEL.match(s, i):\n                m = cast(Match[str], ATTR_SEL.match(s, i))\n\n                attr = m.group(\"attr\")\n                op = m.group(\"op\")\n                val_identifier = m.group(\"val_identifier\")\n                quote = m.group(\"quote\")\n                val_string_inner = m.group(\"val_string_inner\")\n                if val_identifier is not None:\n                    val = val_identifier\n                elif val_string_inner is not None:\n                    val = val_string_inner.replace(\"\\\\\" + quote, quote)\n                else:\n                    val = None\n\n                if op is None:\n                    type = AttributeSelectorType.BARE\n                elif op == \"=\":\n                    type = AttributeSelectorType.EQUAL\n                elif op == \"~=\":\n                    type = AttributeSelectorType.TILDE\n                elif op == \"|=\":\n                    type = AttributeSelectorType.PIPE\n                elif op == \"^=\":\n                    type = AttributeSelectorType.CARET\n                elif op == \"$=\":\n                    type = AttributeSelectorType.DOLLAR\n                elif op == \"*=\":\n                    type = AttributeSelectorType.ASTERISK\n                else:  # pragma: no cover\n                    raise SelectorParserException(\n                        s,\n                        i,\n                        \"unrecognized operator %s in attribute selector\" % repr(op),\n                    )\n\n                attrs.append(AttributeSelector(attr, val, type))\n            elif CLASS_SEL.match(s, i):\n                m = cast(Match[str], CLASS_SEL.match(s, i))\n                classes.append(m.group(1))\n            elif ID_SEL.match(s, i):\n                if id:\n                    raise SelectorParserException(s, i, \"multiple id selectors found\")\n                m = cast(Match[str], ID_SEL.match(s, i))\n                id = m.group(1)\n            elif PSEUDO_CLASS_SEL.match(s, i):\n                raise SelectorParserException(s, i, \"pseudo-classes not supported\")\n            elif PSEUDO_ELEM_SEL.match(s, i):\n                raise SelectorParserException(s, i, \"pseudo-elements not supported\")\n            else:\n                raise SelectorParserException(\n                    s, i, \"expecting simple selector, found none\"\n                )\n            i = m.end()\n\n            # Try to parse a combinator, or end the selector.\n            if CHILD_COM.match(s, i):\n                m = cast(Match[str], CHILD_COM.match(s, i))\n                combinator = Combinator.CHILD\n            elif NEXT_SIB_COM.match(s, i):\n                m = cast(Match[str], NEXT_SIB_COM.match(s, i))\n                combinator = Combinator.NEXT_SIBLING\n            elif SUB_SIB_COM.match(s, i):\n                m = cast(Match[str], SUB_SIB_COM.match(s, i))\n                combinator = Combinator.SUBSEQUENT_SIBLING\n            elif END_OF_SELECTOR.match(s, i):\n                m = cast(Match[str], END_OF_SELECTOR.match(s, i))\n                combinator = None\n            # Need to parse descendant combinator at the very end\n            # because it could be a prefix to all previous cases.\n            elif DESCENDANT_COM.match(s, i):\n                m = cast(Match[str], DESCENDANT_COM.match(s, i))\n                combinator = Combinator.DESCENDANT\n            else:\n                continue\n            i = m.end()\n\n            if combinator and i == len(s):\n                raise SelectorParserException(s, i, \"unexpected end at combinator\")\n\n            selector = cls(\n                tag=tag,\n                classes=classes,\n                id=id,\n                attrs=attrs,\n                combinator=previous_combinator,\n                previous=selector,\n            )\n            previous_combinator = combinator\n\n            # End of selector.\n            if combinator is None:\n                break\n\n            tag = None\n            classes = []\n            id = None\n            attrs = []\n            combinator = None\n\n        if not selector:\n            raise SelectorParserException(s, i, \"selector is empty\")\n\n        return selector, i\n\n    def matches(self, node: \"Node\", root: Optional[\"Node\"] = None) -> bool:\n        \"\"\"\n        Decides whether the selector matches `node`.\n\n        Each sequence of simple selectors in the selector's chain must\n        be matched for a positive.\n\n        If `root` is provided and child and/or descendant combinators\n        are involved, parent/ancestor lookup terminates at `root`.\n        \"\"\"\n        if self.tag:\n            if not node.tag or node.tag != self.tag:\n                return False\n        if self.id:\n            if node.attrs.get(\"id\") != self.id:\n                return False\n        if self.classes:\n            classes = node.classes\n            for class_ in self.classes:\n                if class_ not in classes:\n                    return False\n        if self.attrs:\n            for attr_selector in self.attrs:\n                if not attr_selector.matches(node):\n                    return False\n\n        if not self.previous:\n            return True\n\n        if self.combinator == Combinator.DESCENDANT:\n            return any(\n                self.previous.matches(ancestor, root=root)\n                for ancestor in node.ancestors()\n            )\n        elif self.combinator == Combinator.CHILD:\n            if node is root or node.parent is None:\n                return False\n            else:\n                return self.previous.matches(node.parent)\n        elif self.combinator == Combinator.NEXT_SIBLING:\n            sibling = node.previous_element_sibling()\n            if not sibling:\n                return False\n            else:\n                return self.previous.matches(sibling)\n        elif self.combinator == Combinator.SUBSEQUENT_SIBLING:\n            return any(\n                self.previous.matches(sibling, root=root)\n                for sibling in node.previous_siblings()\n                if isinstance(sibling, ElementNode)\n            )\n        else:  # pragma: no cover\n            raise RuntimeError(\"unimplemented combinator: %s\" % repr(self.combinator))\n\n\nclass AttributeSelector:\n    \"\"\"\n    Represents an attribute selector.\n\n    Attributes:\n        attr (:class:`str`)\n        val  (:class:`Optional`\\\\[:class:`str`])\n        type (:class:`AttributeSelectorType`)\n    \"\"\"\n\n    def __init__(\n        self, attr: str, val: Optional[str], type: \"AttributeSelectorType\"\n    ) -> None:\n        self.attr = attr.lower()\n        self.val = val\n        self.type = type\n\n    def __repr__(self) -> str:\n        return \"<AttributeSelector %s>\" % repr(str(self))\n\n    def __str__(self) -> str:\n        if self.type == AttributeSelectorType.BARE:\n            fmt = \"[{attr}{val:.0}]\"\n        elif self.type == AttributeSelectorType.EQUAL:\n            fmt = \"[{attr}={val}]\"\n        elif self.type == AttributeSelectorType.TILDE:\n            fmt = \"[{attr}~={val}]\"\n        elif self.type == AttributeSelectorType.PIPE:\n            fmt = \"[{attr}|={val}]\"\n        elif self.type == AttributeSelectorType.CARET:\n            fmt = \"[{attr}^={val}]\"\n        elif self.type == AttributeSelectorType.DOLLAR:\n            fmt = \"[{attr}$={val}]\"\n        elif self.type == AttributeSelectorType.ASTERISK:\n            fmt = \"[{attr}*={val}]\"\n        return fmt.format(attr=self.attr, val=repr(self.val))\n\n    def matches(self, node: \"Node\") -> bool:\n        val = node.attrs.get(self.attr)\n        if val is None:\n            return False\n        if self.type == AttributeSelectorType.BARE:\n            return True\n        elif self.type == AttributeSelectorType.EQUAL:\n            return val == self.val\n        elif self.type == AttributeSelectorType.TILDE:\n            return self.val in val.split()\n        elif self.type == AttributeSelectorType.PIPE:\n            return val == self.val or val.startswith(\"%s-\" % self.val)\n        elif self.type == AttributeSelectorType.CARET:\n            return bool(self.val and val.startswith(self.val))\n        elif self.type == AttributeSelectorType.DOLLAR:\n            return bool(self.val and val.endswith(self.val))\n        elif self.type == AttributeSelectorType.ASTERISK:\n            return bool(self.val and self.val in val)\n        else:  # pragma: no cover\n            raise RuntimeError(\"unimplemented attribute selector: %s\" % repr(self.type))\n\n\n# Enum: basis for poor man's algebraic data type.\nclass AttributeSelectorType(Enum):\n    \"\"\"\n    Attribute selector types.\n\n    Members correspond to the following forms of attribute selector:\n\n    - :attr:`BARE`: ``[attr]``;\n    - :attr:`EQUAL`: ``[attr=val]``;\n    - :attr:`TILDE`: ``[attr~=val]``;\n    - :attr:`PIPE`: ``[attr|=val]``;\n    - :attr:`CARET`: ``[attr^=val]``;\n    - :attr:`DOLLAR`: ``[attr$=val]``;\n    - :attr:`ASTERISK`: ``[attr*=val]``.\n    \"\"\"\n\n    # [attr]\n    BARE = 1\n    # [attr=val]\n    EQUAL = 2\n    # [attr~=val]\n    TILDE = 3\n    # [attr|=val]\n    PIPE = 4\n    # [attr^=val]\n    CARET = 5\n    # [attr$=val]\n    DOLLAR = 6\n    # [attr*=val]\n    ASTERISK = 7\n\n\nclass Combinator(Enum):\n    \"\"\"\n    Combinator types.\n\n    Members correspond to the following combinators:\n\n    - :attr:`DESCENDANT`: ``A B``;\n    - :attr:`CHILD`: ``A > B``;\n    - :attr:`NEXT_SIBLING`: ``A + B``;\n    - :attr:`SUBSEQUENT_SIBLING`: ``A ~ B``.\n    \"\"\"\n\n    # ' '\n    DESCENDANT = 1\n    # >\n    CHILD = 2\n    # +\n    NEXT_SIBLING = 3\n    # ~\n    SUBSEQUENT_SIBLING = 4\n\n\ndef _tag_is_void(tag: str) -> bool:\n    \"\"\"\n    Checks whether the tag corresponds to a void element.\n\n    https://www.w3.org/TR/html5/syntax.html#void-elements\n    https://html.spec.whatwg.org/multipage/syntax.html#void-elements\n    \"\"\"\n    return tag.lower() in (\n        \"area\",\n        \"base\",\n        \"br\",\n        \"col\",\n        \"embed\",\n        \"hr\",\n        \"img\",\n        \"input\",\n        \"link\",\n        \"meta\",\n        \"param\",\n        \"source\",\n        \"track\",\n        \"wbr\",\n    )\n\n\ndef _tag_encloses_foreign_namespace(tag: str) -> bool:\n    \"\"\"\n    Checks whether the tag encloses a foreign namespace (MathML or SVG).\n\n    https://html.spec.whatwg.org/multipage/syntax.html#foreign-elements\n    \"\"\"\n    return tag.lower() in (\"math\", \"svg\")\n\n\n### end dim ###\n\n\n# Global helper functions\n\ndef open_url(url):\n    \"\"\"Open an URL in the user's default web browser.\n\n    The string attribute ``open_url.url_handler`` can be used to open URLs\n    in a custom CLI script or utility. A subprocess is spawned with url as\n    the parameter in this case instead of the usual webbrowser.open() call.\n\n    Whether the browser's output (both stdout and stderr) are suppressed\n    depends on the boolean attribute ``open_url.suppress_browser_output``.\n    If the attribute is not set upon a call, set it to a default value,\n    which means False if BROWSER is set to a known text-based browser --\n    elinks, links, lynx, w3m or 'www-browser'; or True otherwise.\n\n    The string attribute ``open_url.override_text_browser`` can be used to\n    ignore env var BROWSER as well as some known text-based browsers and\n    attempt to open url in a GUI browser available.\n    Note: If a GUI browser is indeed found, this option ignores the program\n          option `show-browser-logs`\n    \"\"\"\n    logger.debug('Opening %s', url)\n\n    # Custom URL handler gets max priority\n    if hasattr(open_url, 'url_handler'):\n        subprocess.run([open_url.url_handler, url])\n        return\n\n    browser = webbrowser.get()\n    if open_url.override_text_browser:\n        browser_output = open_url.suppress_browser_output\n        for name in [b for b in webbrowser._tryorder if b not in text_browsers]:\n            browser = webbrowser.get(name)\n            logger.debug(browser)\n\n            # Found a GUI browser, suppress browser output\n            open_url.suppress_browser_output = True\n            break\n\n    if open_url.suppress_browser_output:\n        _stderr = os.dup(2)\n        os.close(2)\n        _stdout = os.dup(1)\n        # Patch for GUI browsers on WSL\n        if \"microsoft\" not in platform.uname()[3].lower():\n            os.close(1)\n        fd = os.open(os.devnull, os.O_RDWR)\n        os.dup2(fd, 2)\n        os.dup2(fd, 1)\n    try:\n        browser.open(url, new=2)\n    finally:\n        if open_url.suppress_browser_output:\n            os.close(fd)\n            os.dup2(_stderr, 2)\n            os.dup2(_stdout, 1)\n\n    if open_url.override_text_browser:\n        open_url.suppress_browser_output = browser_output\n\n\ndef printerr(msg):\n    \"\"\"Print message, verbatim, to stderr.\n\n    ``msg`` could be any stringifiable value.\n    \"\"\"\n    print(msg, file=sys.stderr)\n\n\ndef unwrap(text):\n    \"\"\"Unwrap text.\"\"\"\n    lines = text.split('\\n')\n    result = ''\n    for i in range(len(lines) - 1):\n        result += lines[i]\n        if not lines[i]:\n            # Paragraph break\n            result += '\\n\\n'\n        elif lines[i + 1]:\n            # Next line is not paragraph break, add space\n            result += ' '\n    # Handle last line\n    result += lines[-1] if lines[-1] else '\\n'\n    return result\n\n\ndef check_stdout_encoding():\n    \"\"\"Make sure stdout encoding is utf-8.\n\n    If not, print error message and instructions, then exit with\n    status 1.\n\n    This function is a no-op on win32 because encoding on win32 is\n    messy, and let's just hope for the best. /s\n    \"\"\"\n    if sys.platform == 'win32':\n        return\n\n    # Use codecs.lookup to resolve text encoding alias\n    encoding = codecs.lookup(sys.stdout.encoding).name\n    if encoding != 'utf-8':\n        locale_lang, locale_encoding = locale.getlocale()\n        if locale_lang is None:\n            locale_lang = '<unknown>'\n        if locale_encoding is None:\n            locale_encoding = '<unknown>'\n        ioencoding = os.getenv('PYTHONIOENCODING', 'not set')\n        sys.stderr.write(unwrap(textwrap.dedent(\"\"\"\\\n        stdout encoding '{encoding}' detected. googler requires utf-8 to\n        work properly. The wrong encoding may be due to a non-UTF-8\n        locale or an improper PYTHONIOENCODING. (For the record, your\n        locale language is {locale_lang} and locale encoding is\n        {locale_encoding}; your PYTHONIOENCODING is {ioencoding}.)\n\n        Please set a UTF-8 locale (e.g., en_US.UTF-8) or set\n        PYTHONIOENCODING to utf-8.\n        \"\"\".format(\n            encoding=encoding,\n            locale_lang=locale_lang,\n            locale_encoding=locale_encoding,\n            ioencoding=ioencoding,\n        ))))\n        sys.exit(1)\n\n\ndef time_it(description=None):\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapped(*args, **kwargs):\n            # Only profile in debug mode.\n            if not logger.isEnabledFor(logging.DEBUG):\n                return func(*args, **kwargs)\n\n            import time\n            mark = time.perf_counter()\n            ret = func(*args, **kwargs)\n            duration = time.perf_counter() - mark\n            logger.debug('%s completed in \\x1b[33m%.3fs\\x1b[0m', description or func.__name__, duration)\n            return ret\n\n        return wrapped\n\n    return decorator\n\n\n# Classes\n\nclass HardenedHTTPSConnection(HTTPSConnection):\n    \"\"\"Overrides HTTPSConnection.connect to specify TLS version\n\n    NOTE: TLS 1.2 is supported from Python 3.4\n    \"\"\"\n\n    def __init__(self, host, address_family=0, **kwargs):\n        HTTPSConnection.__init__(self, host, **kwargs)\n        self.address_family = address_family\n\n    def connect(self, notweak=False):\n        sock = self.create_socket_connection()\n\n        # Optimizations not available on OS X\n        if not notweak and sys.platform.startswith('linux'):\n            try:\n                sock.setsockopt(socket.SOL_TCP, socket.TCP_DEFER_ACCEPT, 1)\n                sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_QUICKACK, 1)\n                sock.setsockopt(socket.SOL_SOCKET, socket.SO_RCVBUF, 524288)\n            except OSError:\n                # Doesn't work on Windows' Linux subsystem (#179)\n                logger.debug('setsockopt failed')\n\n        if getattr(self, '_tunnel_host', None):\n            self.sock = sock\n        elif not notweak:\n            # Try to use TLS 1.2\n            ssl_context = None\n            if hasattr(ssl, 'PROTOCOL_TLS_CLIENT'):\n                # Since Python 3.6\n                ssl_context = ssl.SSLContext(ssl.PROTOCOL_TLS_CLIENT)\n                ssl_context.check_hostname = False\n                ssl_context.verify_mode = ssl.CERT_NONE\n            elif hasattr(ssl, 'PROTOCOL_TLS'):\n                # Since Python 3.5.3\n                ssl_context = ssl.SSLContext(ssl.PROTOCOL_TLS)\n                if hasattr(ssl_context, \"minimum_version\"):\n                    # Python 3.7 with OpenSSL 1.1.0g or later\n                    ssl_context.minimum_version = ssl.TLSVersion.TLSv1_2\n                else:\n                    ssl_context.options |= (ssl.OP_NO_SSLv2 | ssl.OP_NO_SSLv3 |\n                                            ssl.OP_NO_TLSv1 | ssl.OP_NO_TLSv1_1)\n            elif hasattr(ssl, 'PROTOCOL_TLSv1_2'):\n                # Since Python 3.4\n                ssl_context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)\n            if ssl_context:\n                self.sock = ssl_context.wrap_socket(sock)\n                return\n\n        # Fallback\n        HTTPSConnection.connect(self)\n\n    # Adapted from socket.create_connection.\n    # https://github.com/python/cpython/blob/bce4ddafdd188cc6deb1584728b67b9e149ca6a4/Lib/socket.py#L771-L813\n    def create_socket_connection(self):\n        err = None\n        results = socket.getaddrinfo(self.host, self.port, self.address_family, socket.SOCK_STREAM)\n        # Prefer IPv4 if address family isn't explicitly specified.\n        if self.address_family == 0:\n            results = sorted(results, key=lambda res: 1 if res[0] == socket.AF_INET else 2)\n        for af, socktype, proto, canonname, sa in results:\n            sock = None\n            try:\n                sock = socket.socket(af, socktype, proto)\n                if self.timeout is not None:\n                    sock.settimeout(self.timeout)\n                if self.source_address:\n                    sock.bind(self.source_address)\n                sock.connect(sa)\n                # Break explicitly a reference cycle\n                err = None\n                self.address_family = af\n                logger.debug('Opened socket to %s:%d',\n                             sa[0] if af == socket.AF_INET else ('[%s]' % sa[0]),\n                             sa[1])\n                return sock\n\n            except socket.error as _:\n                err = _\n                if sock is not None:\n                    sock.close()\n\n        if err is not None:\n            try:\n                raise err\n            finally:\n                # Break explicitly a reference cycle\n                err = None\n        else:\n            raise socket.error(\"getaddrinfo returns an empty list\")\n\n\nclass GoogleUrl(object):\n    \"\"\"\n    This class constructs the Google Search/News URL.\n\n    This class is modelled on urllib.parse.ParseResult for familiarity,\n    which means it supports reading of all six attributes -- scheme,\n    netloc, path, params, query, fragment -- of\n    urllib.parse.ParseResult, as well as the geturl() method.\n\n    However, the attributes (properties) and methods listed below should\n    be the preferred methods of access to this class.\n\n    Parameters\n    ----------\n    opts : dict or argparse.Namespace, optional\n        See the ``opts`` parameter of `update`.\n\n    Other Parameters\n    ----------------\n    See \"Other Parameters\" of `update`.\n\n    Attributes\n    ----------\n    hostname : str\n        Read-write property.\n    keywords : str or list of strs\n        Read-write property.\n    news : bool\n        Read-only property.\n    videos : bool\n        Read-only property.\n    url : str\n        Read-only property.\n\n    Methods\n    -------\n    full()\n    relative()\n    update(opts=None, **kwargs)\n    set_queries(**kwargs)\n    unset_queries(*args)\n    next_page()\n    prev_page()\n    first_page()\n\n    \"\"\"\n\n    def __init__(self, opts=None, **kwargs):\n        self.scheme = 'https'\n        # self.netloc is a calculated property\n        self.path = '/search'\n        self.params = ''\n        # self.query is a calculated property\n        self.fragment = ''\n\n        self._tld = None\n        self._num = 10\n        self._start = 0\n        self._keywords = []\n        self._sites = None\n        self._exclude = None\n\n        self._query_dict = {\n            'ie': 'UTF-8',\n            'oe': 'UTF-8',\n            #'gbv': '1',  # control the presence of javascript on the page, 1=no js, 2=js\n            'sei': base64.encodebytes(uuid.uuid4().bytes).decode(\"ascii\").rstrip('=\\n').replace('/', '_'),\n        }\n\n        # In preloaded HTML parsing mode, set keywords to something so\n        # that we are not tripped up by require_keywords.\n        if opts.html_file and not opts.keywords:\n            opts.keywords = ['<debug>']\n\n        self.update(opts, **kwargs)\n\n    def __str__(self):\n        return self.url\n\n    @property\n    def url(self):\n        \"\"\"The full Google URL you want.\"\"\"\n        return self.full()\n\n    @property\n    def hostname(self):\n        \"\"\"The hostname.\"\"\"\n        return self.netloc\n\n    @hostname.setter\n    def hostname(self, hostname):\n        self.netloc = hostname\n\n    @property\n    def keywords(self):\n        \"\"\"The keywords, either a str or a list of strs.\"\"\"\n        return self._keywords\n\n    @keywords.setter\n    def keywords(self, keywords):\n        self._keywords = keywords\n\n    @property\n    def news(self):\n        \"\"\"Whether the URL is for Google News.\"\"\"\n        return 'tbm' in self._query_dict and self._query_dict['tbm'] == 'nws'\n\n    @property\n    def videos(self):\n        \"\"\"Whether the URL is for Google Videos.\"\"\"\n        return 'tbm' in self._query_dict and self._query_dict['tbm'] == 'vid'\n\n    def full(self):\n        \"\"\"Return the full URL.\n\n        Returns\n        -------\n        str\n\n        \"\"\"\n        url = (self.scheme + ':') if self.scheme else ''\n        url += '//' + self.netloc + self.relative()\n        return url\n\n    def relative(self):\n        \"\"\"Return the relative URL (without scheme and authority).\n\n        Authority (see RFC 3986 section 3.2), or netloc in the\n        terminology of urllib.parse, basically means the hostname\n        here. The relative URL is good for making HTTP(S) requests to a\n        known host.\n\n        Returns\n        -------\n        str\n\n        \"\"\"\n        rel = self.path\n        if self.params:\n            rel += ';' + self.params\n        if self.query:\n            rel += '?' + self.query\n        if self.fragment:\n            rel += '#' + self.fragment\n        return rel\n\n    def update(self, opts=None, **kwargs):\n        \"\"\"Update the URL with the given options.\n\n        Parameters\n        ----------\n        opts : dict or argparse.Namespace, optional\n            Carries options that affect the Google Search/News URL. The\n            list of currently recognized option keys with expected value\n            types:\n\n                duration: str (GooglerArgumentParser.is_duration)\n                exact: bool\n                keywords: str or list of strs\n                lang: str\n                news: bool\n                videos: bool\n                num: int\n                site: str\n                start: int\n                tld: str\n                unfilter: bool\n\n        Other Parameters\n        ----------------\n        kwargs\n            The `kwargs` dict extends `opts`, that is, options can be\n            specified either way, in `opts` or as individual keyword\n            arguments.\n\n        \"\"\"\n\n        if opts is None:\n            opts = {}\n        if hasattr(opts, '__dict__'):\n            opts = opts.__dict__\n        opts.update(kwargs)\n\n        qd = self._query_dict\n        if opts.get('duration'):\n            qd['tbs'] = 'qdr:%s' % opts['duration']\n        if 'exact' in opts:\n            if opts['exact']:\n                qd['nfpr'] = 1\n            else:\n                qd.pop('nfpr', None)\n        if opts.get('from') or opts.get('to'):\n            cd_min = opts.get('from') or ''\n            cd_max = opts.get('to') or ''\n            qd['tbs'] = 'cdr:1,cd_min:%s,cd_max:%s' % (cd_min, cd_max)\n        if 'keywords' in opts:\n            self._keywords = opts['keywords']\n        if 'lang' in opts and opts['lang']:\n            qd['hl'] = opts['lang']\n        if 'geoloc' in opts and opts['geoloc']:\n            qd['gl'] = opts['geoloc']\n        if 'news' in opts and opts['news']:\n            qd['tbm'] = 'nws'\n        elif 'videos' in opts and opts['videos']:\n            qd['tbm'] = 'vid'\n        else:\n            qd.pop('tbm', None)\n        if 'num' in opts:\n            self._num = opts['num']\n        if 'sites' in opts:\n            self._sites = opts['sites']\n        if 'exclude' in opts:\n            self._exclude = opts['exclude']\n        if 'start' in opts:\n            self._start = opts['start']\n        if 'tld' in opts:\n            self._tld = opts['tld']\n        if 'unfilter' in opts and opts['unfilter']:\n            qd['filter'] = 0\n\n    def set_queries(self, **kwargs):\n        \"\"\"Forcefully set queries outside the normal `update` mechanism.\n\n        Other Parameters\n        ----------------\n        kwargs\n            Arbitrary key value pairs to be set in the query string. All\n            keys and values should be stringifiable.\n\n            Note that certain keys, e.g., ``q``, have their values\n            constructed on the fly, so setting those has no actual\n            effect.\n\n        \"\"\"\n        for k, v in kwargs.items():\n            self._query_dict[k] = v\n\n    def unset_queries(self, *args):\n        \"\"\"Forcefully unset queries outside the normal `update` mechanism.\n\n        Other Parameters\n        ----------------\n        args\n            Arbitrary keys to be unset. No exception is raised if a key\n            does not exist in the first place.\n\n            Note that certain keys, e.g., ``q``, are always included in\n            the resulting URL, so unsetting those has no actual effect.\n\n        \"\"\"\n        for k in args:\n            self._query_dict.pop(k, None)\n\n    def next_page(self):\n        \"\"\"Navigate to the next page.\"\"\"\n        self._start += self._num\n\n    def prev_page(self):\n        \"\"\"Navigate to the previous page.\n\n        Raises\n        ------\n        ValueError\n            If already at the first page (``start=0`` in the current\n            query string).\n\n        \"\"\"\n        if self._start == 0:\n            raise ValueError('Already at the first page.')\n        self._start = (self._start - self._num) if self._start > self._num else 0\n\n    def first_page(self):\n        \"\"\"Navigate to the first page.\n\n        Raises\n        ------\n        ValueError\n            If already at the first page (``start=0`` in the current\n            query string).\n\n        \"\"\"\n        if self._start == 0:\n            raise ValueError('Already at the first page.')\n        self._start = 0\n\n    # Data source: https://web.archive.org/web/20170615200243/https://en.wikipedia.org/wiki/List_of_Google_domains\n    # Scraper script: https://gist.github.com/zmwangx/b976e83c14552fe18b71\n    TLD_TO_DOMAIN_MAP = {\n        'ac': 'google.ac',      'ad': 'google.ad',      'ae': 'google.ae',\n        'af': 'google.com.af',  'ag': 'google.com.ag',  'ai': 'google.com.ai',\n        'al': 'google.al',      'am': 'google.am',      'ao': 'google.co.ao',\n        'ar': 'google.com.ar',  'as': 'google.as',      'at': 'google.at',\n        'au': 'google.com.au',  'az': 'google.az',      'ba': 'google.ba',\n        'bd': 'google.com.bd',  'be': 'google.be',      'bf': 'google.bf',\n        'bg': 'google.bg',      'bh': 'google.com.bh',  'bi': 'google.bi',\n        'bj': 'google.bj',      'bn': 'google.com.bn',  'bo': 'google.com.bo',\n        'br': 'google.com.br',  'bs': 'google.bs',      'bt': 'google.bt',\n        'bw': 'google.co.bw',   'by': 'google.by',      'bz': 'google.com.bz',\n        'ca': 'google.ca',      'cat': 'google.cat',    'cc': 'google.cc',\n        'cd': 'google.cd',      'cf': 'google.cf',      'cg': 'google.cg',\n        'ch': 'google.ch',      'ci': 'google.ci',      'ck': 'google.co.ck',\n        'cl': 'google.cl',      'cm': 'google.cm',      'cn': 'google.cn',\n        'co': 'google.com.co',  'cr': 'google.co.cr',   'cu': 'google.com.cu',\n        'cv': 'google.cv',      'cy': 'google.com.cy',  'cz': 'google.cz',\n        'de': 'google.de',      'dj': 'google.dj',      'dk': 'google.dk',\n        'dm': 'google.dm',      'do': 'google.com.do',  'dz': 'google.dz',\n        'ec': 'google.com.ec',  'ee': 'google.ee',      'eg': 'google.com.eg',\n        'es': 'google.es',      'et': 'google.com.et',  'fi': 'google.fi',\n        'fj': 'google.com.fj',  'fm': 'google.fm',      'fr': 'google.fr',\n        'ga': 'google.ga',      'ge': 'google.ge',      'gf': 'google.gf',\n        'gg': 'google.gg',      'gh': 'google.com.gh',  'gi': 'google.com.gi',\n        'gl': 'google.gl',      'gm': 'google.gm',      'gp': 'google.gp',\n        'gr': 'google.gr',      'gt': 'google.com.gt',  'gy': 'google.gy',\n        'hk': 'google.com.hk',  'hn': 'google.hn',      'hr': 'google.hr',\n        'ht': 'google.ht',      'hu': 'google.hu',      'id': 'google.co.id',\n        'ie': 'google.ie',      'il': 'google.co.il',   'im': 'google.im',\n        'in': 'google.co.in',   'io': 'google.io',      'iq': 'google.iq',\n        'is': 'google.is',      'it': 'google.it',      'je': 'google.je',\n        'jm': 'google.com.jm',  'jo': 'google.jo',      'jp': 'google.co.jp',\n        'ke': 'google.co.ke',   'kg': 'google.kg',      'kh': 'google.com.kh',\n        'ki': 'google.ki',      'kr': 'google.co.kr',   'kw': 'google.com.kw',\n        'kz': 'google.kz',      'la': 'google.la',      'lb': 'google.com.lb',\n        'lc': 'google.com.lc',  'li': 'google.li',      'lk': 'google.lk',\n        'ls': 'google.co.ls',   'lt': 'google.lt',      'lu': 'google.lu',\n        'lv': 'google.lv',      'ly': 'google.com.ly',  'ma': 'google.co.ma',\n        'md': 'google.md',      'me': 'google.me',      'mg': 'google.mg',\n        'mk': 'google.mk',      'ml': 'google.ml',      'mm': 'google.com.mm',\n        'mn': 'google.mn',      'ms': 'google.ms',      'mt': 'google.com.mt',\n        'mu': 'google.mu',      'mv': 'google.mv',      'mw': 'google.mw',\n        'mx': 'google.com.mx',  'my': 'google.com.my',  'mz': 'google.co.mz',\n        'na': 'google.com.na',  'ne': 'google.ne',      'nf': 'google.com.nf',\n        'ng': 'google.com.ng',  'ni': 'google.com.ni',  'nl': 'google.nl',\n        'no': 'google.no',      'np': 'google.com.np',  'nr': 'google.nr',\n        'nu': 'google.nu',      'nz': 'google.co.nz',   'om': 'google.com.om',\n        'pa': 'google.com.pa',  'pe': 'google.com.pe',  'pg': 'google.com.pg',\n        'ph': 'google.com.ph',  'pk': 'google.com.pk',  'pl': 'google.pl',\n        'pn': 'google.co.pn',   'pr': 'google.com.pr',  'ps': 'google.ps',\n        'pt': 'google.pt',      'py': 'google.com.py',  'qa': 'google.com.qa',\n        'ro': 'google.ro',      'rs': 'google.rs',      'ru': 'google.ru',\n        'rw': 'google.rw',      'sa': 'google.com.sa',  'sb': 'google.com.sb',\n        'sc': 'google.sc',      'se': 'google.se',      'sg': 'google.com.sg',\n        'sh': 'google.sh',      'si': 'google.si',      'sk': 'google.sk',\n        'sl': 'google.com.sl',  'sm': 'google.sm',      'sn': 'google.sn',\n        'so': 'google.so',      'sr': 'google.sr',      'st': 'google.st',\n        'sv': 'google.com.sv',  'td': 'google.td',      'tg': 'google.tg',\n        'th': 'google.co.th',   'tj': 'google.com.tj',  'tk': 'google.tk',\n        'tl': 'google.tl',      'tm': 'google.tm',      'tn': 'google.tn',\n        'to': 'google.to',      'tr': 'google.com.tr',  'tt': 'google.tt',\n        'tw': 'google.com.tw',  'tz': 'google.co.tz',   'ua': 'google.com.ua',\n        'ug': 'google.co.ug',   'uk': 'google.co.uk',   'uy': 'google.com.uy',\n        'uz': 'google.co.uz',   'vc': 'google.com.vc',  've': 'google.co.ve',\n        'vg': 'google.vg',      'vi': 'google.co.vi',   'vn': 'google.com.vn',\n        'vu': 'google.vu',      'ws': 'google.ws',      'za': 'google.co.za',\n        'zm': 'google.co.zm',   'zw': 'google.co.zw',\n    }\n\n    @property\n    def netloc(self):\n        \"\"\"The hostname.\"\"\"\n        try:\n            return 'www.' + self.TLD_TO_DOMAIN_MAP[self._tld]\n        except KeyError:\n            return 'www.google.com'\n\n    @property\n    def query(self):\n        \"\"\"The query string.\"\"\"\n        qd = {}\n        qd.update(self._query_dict)\n        if self._num != 10:  # Skip sending the default\n            qd['num'] = self._num\n        if self._start:  # Skip sending the default\n            qd['start'] = self._start\n\n        # Construct the q query\n        q = ''\n        keywords = self._keywords\n        sites = self._sites\n        exclude = self._exclude\n        if keywords:\n            if isinstance(keywords, list):\n                q += '+'.join(urllib.parse.quote_plus(kw) for kw in keywords)\n            else:\n                q += urllib.parse.quote_plus(keywords)\n        if sites:\n            q += '+OR'.join('+site:' + urllib.parse.quote_plus(site) for site in sites)\n        if exclude:\n            q += ''.join('+-site:' + urllib.parse.quote_plus(e) for e in exclude)\n        qd['q'] = q\n        return '&'.join('%s=%s' % (k, qd[k]) for k in sorted(qd.keys()))\n\n\nclass GoogleConnectionError(Exception):\n    pass\n\n\nclass GoogleConnection(object):\n    \"\"\"\n    This class facilitates connecting to and fetching from Google.\n\n    Parameters\n    ----------\n    See http.client.HTTPSConnection for documentation of the\n    parameters.\n\n    Raises\n    ------\n    GoogleConnectionError\n\n    Attributes\n    ----------\n    host : str\n        The currently connected host. Read-only property. Use\n        `new_connection` to change host.\n\n    Methods\n    -------\n    new_connection(host=None, port=None, timeout=45)\n    renew_connection(timeout=45)\n    fetch_page(url)\n    close()\n\n    \"\"\"\n\n    def __init__(self, host, port=None, address_family=0, timeout=45, proxy=None, notweak=False):\n        self._host = None\n        self._port = None\n        self._address_family = address_family\n        self._proxy = proxy\n        self._notweak = notweak\n        self._conn = None\n        self.new_connection(host, port=port, timeout=timeout)\n        self.cookie = ''\n\n    @property\n    def host(self):\n        \"\"\"The host currently connected to.\"\"\"\n        return self._host\n\n    @time_it()\n    def new_connection(self, host=None, port=None, timeout=45):\n        \"\"\"Close the current connection (if any) and establish a new one.\n\n        Parameters\n        ----------\n        See http.client.HTTPSConnection for documentation of the\n        parameters. Renew the connection (i.e., reuse the current host\n        and port) if host is None or empty.\n\n        Raises\n        ------\n        GoogleConnectionError\n\n        \"\"\"\n        if self._conn:\n            self._conn.close()\n\n        if not host:\n            host = self._host\n            port = self._port\n        self._host = host\n        self._port = port\n        host_display = host + (':%d' % port if port else '')\n\n        proxy = self._proxy\n\n        if proxy:\n            proxy_user_passwd, proxy_host_port = parse_proxy_spec(proxy)\n\n            logger.debug('Connecting to proxy server %s', proxy_host_port)\n            self._conn = HardenedHTTPSConnection(proxy_host_port,\n                                                 address_family=self._address_family, timeout=timeout)\n\n            logger.debug('Tunnelling to host %s' % host_display)\n            connect_headers = {}\n            if proxy_user_passwd:\n                connect_headers['Proxy-Authorization'] = 'Basic %s' % base64.b64encode(\n                    proxy_user_passwd.encode('utf-8')\n                ).decode('utf-8')\n            self._conn.set_tunnel(host, port=port, headers=connect_headers)\n\n            try:\n                self._conn.connect(self._notweak)\n            except Exception as e:\n                msg = 'Failed to connect to proxy server %s: %s.' % (proxy, e)\n                raise GoogleConnectionError(msg)\n        else:\n            logger.debug('Connecting to new host %s', host_display)\n            self._conn = HardenedHTTPSConnection(host, port=port,\n                                                 address_family=self._address_family, timeout=timeout)\n            try:\n                self._conn.connect(self._notweak)\n            except Exception as e:\n                msg = 'Failed to connect to %s: %s.' % (host_display, e)\n                raise GoogleConnectionError(msg)\n\n    def renew_connection(self, timeout=45):\n        \"\"\"Renew current connection.\n\n        Equivalent to ``new_connection(timeout=timeout)``.\n\n        \"\"\"\n        self.new_connection(timeout=timeout)\n\n    @time_it()\n    def fetch_page(self, url):\n        \"\"\"Fetch a URL.\n\n        Allows one reconnection and multiple redirections before failing\n        and raising GoogleConnectionError.\n\n        Parameters\n        ----------\n        url : str\n            The URL to fetch, relative to the host.\n\n        Raises\n        ------\n        GoogleConnectionError\n            When not getting HTTP 200 even after the allowed one\n            reconnection and/or one redirection, or when Google is\n            blocking query due to unusual activity.\n\n        Returns\n        -------\n        str\n            Response payload, gunzipped (if applicable) and decoded (in UTF-8).\n\n        \"\"\"\n        try:\n            self._raw_get(url)\n        except (http.client.HTTPException, OSError) as e:\n            logger.debug('Got exception: %s.', e)\n            logger.debug('Attempting to reconnect...')\n            self.renew_connection()\n            try:\n                self._raw_get(url)\n            except http.client.HTTPException as e:\n                logger.debug('Got exception: %s.', e)\n                raise GoogleConnectionError(\"Failed to get '%s'.\" % url)\n\n        resp = self._resp\n        redirect_counter = 0\n        while resp.status != 200 and redirect_counter < 3:\n            if resp.status in {301, 302, 303, 307, 308}:\n                redirection_url = resp.getheader('location', '')\n                if 'sorry/IndexRedirect?' in redirection_url or 'sorry/index?' in redirection_url:\n                    msg = \"Connection blocked due to unusual activity.\\n\"\n                    if self._conn.address_family == socket.AF_INET6:\n                        msg += textwrap.dedent(\"\"\"\\\n                        You are connecting over IPv6 which is likely the problem. Try to make\n                        sure the machine has a working IPv4 network interface configured.\n                        See also the -4, --ipv4 option of googler.\\n\"\"\")\n                    msg += textwrap.dedent(\"\"\"\\\n                    THIS IS NOT A BUG, please do NOT report it as a bug unless you have specific\n                    information that may lead to the development of a workaround.\n                    You IP address is temporarily or permanently blocked by Google and requires\n                    reCAPTCHA-solving to use the service, which googler is not capable of.\n                    Possible causes include issuing too many queries in a short time frame, or\n                    operating from a shared / low reputation IP with a history of abuse.\n                    Please do NOT use googler for automated scraping.\"\"\")\n                    msg = \" \".join(msg.splitlines())\n                    raise GoogleConnectionError(msg)\n                self._redirect(redirection_url)\n                resp = self._resp\n                redirect_counter += 1\n            else:\n                break\n\n        if resp.status != 200:\n            raise GoogleConnectionError('Got HTTP %d: %s' % (resp.status, resp.reason))\n\n        payload = resp.read()\n        try:\n            return gzip.decompress(payload).decode('utf-8')\n        except OSError:\n            # Not gzipped\n            return payload.decode('utf-8')\n\n    def _redirect(self, url):\n        \"\"\"Redirect to and fetch a new URL.\n\n        Like `_raw_get`, the response is stored in ``self._resp``. A new\n        connection is made if redirecting to a different host or local proxy is enabled.\n\n        Parameters\n        ----------\n        url : str\n            If absolute and points to a different host, make a new\n            connection.\n\n        Raises\n        ------\n        GoogleConnectionError\n\n        \"\"\"\n        logger.debug('Redirecting to URL %s', url)\n        segments = urllib.parse.urlparse(url)\n\n        host = segments.netloc\n        if host != self._host or self._proxy is not None:\n            self.new_connection(host)\n\n        relurl = urllib.parse.urlunparse(('', '') + segments[2:])\n        try:\n            self._raw_get(relurl)\n        except http.client.HTTPException as e:\n            logger.debug('Got exception: %s.', e)\n            raise GoogleConnectionError(\"Failed to get '%s'.\" % url)\n\n    def _raw_get(self, url):\n        \"\"\"Make a raw HTTP GET request.\n\n        No status check (which implies no redirection). Response can be\n        accessed from ``self._resp``.\n\n        Parameters\n        ----------\n        url : str\n            URL relative to the host, used in the GET request.\n\n        Raises\n        ------\n        http.client.HTTPException\n\n        \"\"\"\n        logger.debug('Fetching URL %s', url)\n        self._conn.request('GET', url, None, {\n            'Accept': 'text/html',\n            'Accept-Encoding': 'gzip',\n            'User-Agent': USER_AGENT,\n            'Cookie': self.cookie,\n            'Connection': 'keep-alive',\n            'DNT': '1',\n        })\n        self._resp = self._conn.getresponse()\n        if self.cookie == '':\n            complete_cookie = self._resp.getheader('Set-Cookie')\n            # Cookie won't be available if already blocked\n            if complete_cookie is not None:\n                self.cookie = complete_cookie[:complete_cookie.find(';')]\n                logger.debug('Cookie: %s' % self.cookie)\n\n    def close(self):\n        \"\"\"Close the connection (if one is active).\"\"\"\n        if self._conn:\n            self._conn.close()\n\n\nclass GoogleParser(object):\n\n    def __init__(self, html, *, news=False, videos=False):\n        self.news = news\n        self.videos = videos\n        self.autocorrected = False\n        self.showing_results_for = None\n        self.filtered = False\n        self.results = []\n        self.parse(html)\n\n    @time_it()\n    def parse(self, html):\n        tree = parse_html(html)\n\n        if debugger:\n            printerr('\\x1b[1mInspect the DOM through the \\x1b[4mtree\\x1b[24m variable.\\x1b[0m')\n            printerr('')\n            try:\n                import IPython\n                IPython.embed()\n            except ImportError:\n                import pdb\n                pdb.set_trace()\n\n        # Google changed their news structure around September 2021\n        # Changing the parser breaks the non-news functionality\n        # So it might be easier to just set these dynamically here.\n\n        # The Title is a dot-separated string in the format:\n        #     - NewsAgency.Title.(Abstract).NewsAge\n        #       (NewsAgency can have dot(s) within)\n        # Abstract has the NewsAgency.\n        # Metadata is same as the actual news Title.\n        # So we set Title as Metadata, append NewsAge to Abstract and\n        # clear Metadata to avoid showing the same Title and Metadata\n        if self.news:\n            div_selector = 'div[data-hveid]'\n            title_selector = 'div'\n            h3_selector = 'div'\n        else:\n            div_selector = 'div.g'\n            title_selector = 'div.tF2Cxc > div'\n            h3_selector = 'h3'\n\n        # cw is short for collapse_whitespace.\n        cw = lambda s: re.sub(r'[ \\t\\n\\r]+', ' ', s) if s is not None else s\n\n        index = 0\n        for div_g in tree.select_all(div_selector):\n            if div_g.select('.hp-xpdbox'):\n                # Skip smart cards.\n                continue\n            try:\n                if div_g.select('.st'):\n                    # Old class structure, stopped working some time in\n                    # September 2020, but kept just in case.\n                    h3 = div_g.select('div.r h3')\n                    if h3:\n                        title = h3.text\n                        a = h3.parent\n                    else:\n                        h3 = div_g.select('h3.r')\n                        a = h3.select('a')\n                        title = a.text\n                        mime = div_g.select('.mime')\n                        if mime:\n                            title = mime.text + ' ' + title\n                    abstract_node = div_g.select('.st')\n                    metadata_node = div_g.select('.f')\n                else:\n                    # Current structure as of October 2020.\n                    # Note that a filetype tag (e.g. PDF) is now pretty\n                    # damn hard to parse with confidence (that it'll\n                    # survive the slighest further change), so we don't.\n\n                    # As of January 15th 2021, the html class is not rc anymore, it's tF2Cxc.\n                    # This approach is not very resilient to changes by Google, but it works for now.\n                    # title_node, details_node, *_ = div_g.select_all('div.rc > div')\n                    title_node, details_node, *_ = div_g.select_all(title_selector)\n                    if 'yuRUbf' not in title_node.classes:\n                        logger.debug('unexpected title node class(es): expected %r, got %r',\n                                     'yuRUbf', ' '.join(title_node.classes))\n                    if 'IsZvec' not in details_node.classes:\n                        logger.debug('unexpected details node class(es): expected %r, got %r',\n                                     'IsZvec', ' '.join(details_node.classes))\n                    a = title_node.select('a')\n                    h3 = a.select(h3_selector)\n                    title = h3.text\n\n                    if self.news:\n                        newstitle = title.split('.')\n                        #title = newstitle[1]\n\n                    abstract_node = details_node.select('span')\n                    metadata_node = details_node.select('.f, span ~ div')\n                url = self.unwrap_link(a.attr('href'))\n                matched_keywords = []\n                abstract = ''\n                # BFS descendant nodes. Necessary to locate matches (b,\n                # em) while skipping metadata (.f).\n                abstract_nodes = collections.deque([abstract_node])\n                while abstract_nodes:\n                    node = abstract_nodes.popleft()\n                    if 'f' in node.classes:\n                        # .f is handled as metadata instead.\n                        continue\n                    if node.tag in ['b', 'em']:\n                        matched_keywords.append({'phrase': node.text, 'offset': len(abstract)})\n                        abstract += node.text\n                        continue\n                    if not node.children:\n                        abstract += node.text\n                        continue\n                    for child in node.children:\n                        abstract_nodes.append(child)\n\n                if self.news:\n                    abstract = abstract + \" - \" + newstitle[-1]\n\n                metadata = None\n                try:\n                    # Sometimes there are multiple metadata fields\n                    # associated with a single entry, e.g. \"Released\",\n                    # \"Producer(s)\", \"Genre\", etc. for a song (sample\n                    # query: \"never gonna give you up\"). These need to\n                    # be delimited when displayed.\n                    metadata_fields = metadata_node.select_all('div > div.wFMWsc')\n                    if metadata_fields:\n                        metadata = ' | '.join(field.text for field in metadata_fields)\n                    elif not metadata_node.select('a') and not metadata_node.select('g-expandable-container'):\n                        metadata = metadata_node.text\n                    if metadata:\n                        metadata = (\n                            metadata\n                            .replace('\\u200e', '')\n                            .replace(' - ', ', ')\n                            .replace(' \\u2014 ', ', ')\n                            .strip().rstrip(',')\n                        )\n                except AttributeError:\n                    pass\n\n                if self.news:\n                    title = metadata\n                    metadata = \"\"\n\n            except (AttributeError, ValueError):\n                continue\n            sitelinks = []\n            for td in div_g.select_all('td'):\n                try:\n                    a = td.select('a')\n                    sl_title = a.text\n                    sl_url = self.unwrap_link(a.attr('href'))\n                    sl_abstract = td.select('div.s.st, div.s .st').text\n                    sitelink = Sitelink(cw(sl_title), sl_url, cw(sl_abstract))\n                    if sitelink not in sitelinks:\n                        sitelinks.append(sitelink)\n                except (AttributeError, ValueError):\n                    continue\n            # cw cannot be applied to abstract here since it may screw\n            # up offsets of matches. Instead, each relevant node's text\n            # is whitespace-collapsed before being appended to abstract.\n            # We then hope for the best.\n            result = Result(index + 1, cw(title), url, abstract,\n                            metadata=cw(metadata), sitelinks=sitelinks, matches=matched_keywords)\n            if result not in self.results:\n                self.results.append(result)\n                index += 1\n\n        if not self.results:\n            for card in tree.select_all('g-card'):\n                a = card.select('a[href]')\n                if not a:\n                    continue\n                url = self.unwrap_link(a.attr('href'))\n                text_nodes = []\n                for node in a.descendants():\n                    if isinstance(node, TextNode) and node.strip():\n                        text_nodes.append(node.text)\n                if len(text_nodes) != 4:\n                    continue\n                publisher, title, abstract, publishing_time = text_nodes\n                metadata = '%s, %s' % (publisher, publishing_time)\n                index += 1\n                self.results.append(Result(index, cw(title), url, cw(abstract), metadata=cw(metadata)))\n\n        # Showing results for ...\n        # Search instead for ...\n        spell_orig = tree.select(\"span.spell_orig\")\n        if spell_orig:\n            showing_results_for_link = next(\n                filter(lambda el: el.tag == \"a\", spell_orig.previous_siblings()), None\n            )\n            if showing_results_for_link:\n                self.autocorrected = True\n                self.showing_results_for = showing_results_for_link.text\n\n        # No results found for ...\n        # Results for ...:\n        alt_query_infobox = tree.select('#topstuff')\n        if alt_query_infobox:\n            bolds = alt_query_infobox.select_all('div b')\n            if len(bolds) == 2:\n                self.showing_results_for = bolds[1].text\n\n        # In order to show you the most relevant results, we have\n        # omitted some entries very similar to the N already displayed.\n        # ...\n        self.filtered = tree.select('p#ofr') is not None\n\n    # Unwraps /url?q=http://...&sa=...\n    # TODO: don't unwrap if URL isn't in this form.\n    @staticmethod\n    def unwrap_link(link):\n        qs = urllib.parse.urlparse(link).query\n        try:\n            url = urllib.parse.parse_qs(qs)['q'][0]\n        except KeyError:\n            return link\n        else:\n            if \"://\" in url:\n                return url\n            else:\n                # Google's internal services link, e.g.,\n                # /search?q=google&..., which cannot be unwrapped into\n                # an actual URL.\n                raise ValueError(link)\n\n\nclass Sitelink(object):\n    \"\"\"Container for a sitelink.\"\"\"\n\n    def __init__(self, title, url, abstract):\n        self.title = title\n        self.url = url\n        self.abstract = abstract\n        self.index = ''\n\n    def __eq__(self, other):\n        return (\n            self.title == other.title and\n            self.url == other.url and\n            self.abstract == other.abstract\n        )\n\n    def __hash__(self):\n        return hash((self.title, self.url, self.abstract))\n\n\nColors = collections.namedtuple('Colors', 'index, title, url, metadata, abstract, prompt, reset')\n\n\nclass Result(object):\n    \"\"\"\n    Container for one search result, with output helpers.\n\n    Parameters\n    ----------\n    index : int or str\n    title : str\n    url : str\n    abstract : str\n    metadata : str, optional\n        Only applicable to Google News results, with publisher name and\n        publishing time.\n    sitelinks : list, optional\n        List of ``SiteLink`` objects.\n\n    Attributes\n    ----------\n    index : str\n    title : str\n    url : str\n    abstract : str\n    metadata : str or None\n    sitelinks : list\n    matches : list\n\n    Class Variables\n    ---------------\n    colors : str\n\n    Methods\n    -------\n    print()\n    jsonizable_object()\n    urltable()\n\n    \"\"\"\n\n    # Class variables\n    colors = None\n    urlexpand = True\n\n    def __init__(self, index, title, url, abstract, metadata=None, sitelinks=None, matches=None):\n        index = str(index)\n        self.index = index\n        self.title = title\n        self.url = url\n        self.abstract = abstract\n        self.metadata = metadata\n        self.sitelinks = [] if sitelinks is None else sitelinks\n        self.matches = [] if matches is None else matches\n\n        self._urltable = {index: url}\n        subindex = 'a'\n        for sitelink in self.sitelinks:\n            fullindex = index + subindex\n            sitelink.index = fullindex\n            self._urltable[fullindex] = sitelink.url\n            subindex = chr(ord(subindex) + 1)\n\n    def __eq__(self, other):\n        return (\n            self.title == other.title and\n            self.url == other.url and\n            self.abstract == other.abstract and\n            self.metadata == other.metadata and\n            self.sitelinks == other.sitelinks and\n            self.matches == other.matches\n        )\n\n    def __hash__(self):\n        sitelinks_hashable = tuple(self.sitelinks) if self.sitelinks is not None else None\n        matches_hashable = tuple(self.matches) if self.matches is not None else None\n        return hash(self.title, self.url, self.abstract, self.metadata, sitelinks_hashable, matches_hashable)\n\n    def _print_title_and_url(self, index, title, url, indent=0):\n        colors = self.colors\n\n        if not self.urlexpand:\n            url = '[' + urllib.parse.urlparse(url).netloc + ']'\n\n        if colors:\n            # Adjust index to print result index clearly\n            print(\" %s%s%-3s%s\" % (' ' * indent, colors.index, index + '.', colors.reset), end='')\n            if not self.urlexpand:\n                print(' ' + colors.title + title + colors.reset + ' ' + colors.url + url + colors.reset)\n            else:\n                print(' ' + colors.title + title + colors.reset)\n                print(' ' * (indent + 5) + colors.url + url + colors.reset)\n        else:\n            if self.urlexpand:\n                print(' %s%-3s %s' % (' ' * indent, index + '.', title))\n                print(' %s%s' % (' ' * (indent + 4), url))\n            else:\n                print(' %s%-3s %s %s' % (' ' * indent, index + '.', title, url))\n\n    def _print_metadata_and_abstract(self, abstract, metadata=None, matches=None, indent=0):\n        colors = self.colors\n        try:\n            columns, _ = os.get_terminal_size()\n        except OSError:\n            columns = 0\n\n        if metadata:\n            if colors:\n                print(' ' * (indent + 5) + colors.metadata + metadata + colors.reset)\n            else:\n                print(' ' * (indent + 5) + metadata)\n\n        if abstract:\n            fillwidth = (columns - (indent + 6)) if columns > indent + 6 else len(abstract)\n            wrapped_abstract = TrackedTextwrap(abstract, fillwidth)\n            if colors:\n                # Highlight matches.\n                for match in matches or []:\n                    offset = match['offset']\n                    span = len(match['phrase'])\n                    wrapped_abstract.insert_zero_width_sequence('\\x1b[1m', offset)\n                    wrapped_abstract.insert_zero_width_sequence('\\x1b[0m', offset + span)\n\n            if colors:\n                print(colors.abstract, end='')\n            for line in wrapped_abstract.lines:\n                print('%s%s' % (' ' * (indent + 5), line))\n            if colors:\n                print(colors.reset, end='')\n\n        print('')\n\n    def print(self):\n        \"\"\"Print the result entry.\"\"\"\n        self._print_title_and_url(self.index, self.title, self.url)\n        self._print_metadata_and_abstract(self.abstract, metadata=self.metadata, matches=self.matches)\n\n        for sitelink in self.sitelinks:\n            self._print_title_and_url(sitelink.index, sitelink.title, sitelink.url, indent=4)\n            self._print_metadata_and_abstract(sitelink.abstract, indent=4)\n\n    def jsonizable_object(self):\n        \"\"\"Return a JSON-serializable dict representing the result entry.\"\"\"\n        obj = {\n            'title': self.title,\n            'url': self.url,\n            'abstract': self.abstract\n        }\n        if self.metadata:\n            obj['metadata'] = self.metadata\n        if self.sitelinks:\n            obj['sitelinks'] = [sitelink.__dict__ for sitelink in self.sitelinks]\n        if self.matches:\n            obj['matches'] = self.matches\n        return obj\n\n    def urltable(self):\n        \"\"\"Return a index-to-URL table for the current result.\n\n        Normally, the table contains only a single entry, but when the result\n        contains sitelinks, all sitelinks are included in this table.\n\n        Returns\n        -------\n        dict\n            A dict mapping indices (strs) to URLs (also strs). Indices of\n            sitelinks are the original index appended by lowercase letters a,\n            b, c, etc.\n\n        \"\"\"\n        return self._urltable\n\n    @staticmethod\n    def collapse_whitespace(s):\n        return re.sub(r'[ \\t\\n\\r]+', ' ', s)\n\n\nclass GooglerCmdException(Exception):\n    pass\n\n\nclass NoKeywordsException(GooglerCmdException):\n    pass\n\n\ndef require_keywords(method):\n    # Require keywords to be set before we run a GooglerCmd method. If\n    # no keywords have been set, raise a NoKeywordsException.\n    @functools.wraps(method)\n    def enforced_method(self, *args, **kwargs):\n        if not self.keywords:\n            raise NoKeywordsException('No keywords.')\n        method(self, *args, **kwargs)\n\n    return enforced_method\n\n\ndef no_argument(method):\n    # Normalize a do_* method of GooglerCmd that takes no argument to\n    # one that takes an arg, but issue a warning when an nonempty\n    # argument is given.\n    @functools.wraps(method)\n    def enforced_method(self, arg):\n        if arg:\n            method_name = arg.__name__\n            command_name = method_name[3:] if method_name.startswith('do_') else method_name\n            logger.warning(\"Argument to the '%s' command ignored.\", command_name)\n        method(self)\n\n    return enforced_method\n\n\nclass GooglerCmd(object):\n    \"\"\"\n    Command line interpreter and executor class for googler.\n\n    Inspired by PSL cmd.Cmd.\n\n    Parameters\n    ----------\n    opts : argparse.Namespace\n        Options and/or arguments.\n\n    Attributes\n    ----------\n    options : argparse.Namespace\n        Options that are currently in effect. Read-only attribute.\n    keywords : str or list or strs\n        Current keywords. Read-only attribute\n\n    Methods\n    -------\n    fetch()\n    display_results(prelude='\\n', json_output=False)\n    fetch_and_display(prelude='\\n', json_output=False, interactive=True)\n    read_next_command()\n    help()\n    cmdloop()\n    \"\"\"\n\n    # Class variables\n    colors = None\n    re_url_index = re.compile(r\"\\d+(a-z)?\")\n\n    def __init__(self, opts):\n        super().__init__()\n\n        self._opts = opts\n\n        self._google_url = GoogleUrl(opts)\n\n        if opts.html_file:\n            # Preloaded HTML parsing mode, do not initialize connection.\n            self._preload_from_file = opts.html_file\n            self._conn = None\n        else:\n            self._preload_from_file = None\n            proxy = opts.proxy if hasattr(opts, 'proxy') else None\n            self._conn = GoogleConnection(self._google_url.hostname,\n                                        address_family=opts.address_family,\n                                        proxy=proxy,\n                                        notweak=opts.notweak)\n            atexit.register(self._conn.close)\n\n        self.results = []\n        self._autocorrected = None\n        self._showing_results_for = None\n        self._results_filtered = False\n        self._urltable = {}\n\n        self.promptcolor = True if os.getenv('DISABLE_PROMPT_COLOR') is None else False\n\n        self.no_results_instructions_shown = False\n\n    @property\n    def options(self):\n        \"\"\"Current options.\"\"\"\n        return self._opts\n\n    @property\n    def keywords(self):\n        \"\"\"Current keywords.\"\"\"\n        return self._google_url.keywords\n\n    @require_keywords\n    def fetch(self):\n        \"\"\"Fetch a page and parse for results.\n\n        Results are stored in ``self.results``.\n\n        Raises\n        ------\n        GoogleConnectionError\n\n        See Also\n        --------\n        fetch_and_display\n\n        \"\"\"\n        # This method also sets self._results_filtered and\n        # self._urltable.\n        if self._preload_from_file:\n            with open(self._preload_from_file, encoding='utf-8') as fp:\n                page = fp.read()\n        else:\n            page = self._conn.fetch_page(self._google_url.relative())\n            if logger.isEnabledFor(logging.DEBUG):\n                import tempfile\n                fd, tmpfile = tempfile.mkstemp(prefix='googler-response-', suffix='.html')\n                os.close(fd)\n                with open(tmpfile, 'w', encoding='utf-8') as fp:\n                    fp.write(page)\n                logger.debug(\"Response body written to '%s'.\", tmpfile)\n\n        parser = GoogleParser(page, news=self._google_url.news, videos=self._google_url.videos)\n\n        self.results = parser.results\n        self._autocorrected = parser.autocorrected\n        self._showing_results_for = parser.showing_results_for\n        self._results_filtered = parser.filtered\n        self._urltable = {}\n        for r in self.results:\n            self._urltable.update(r.urltable())\n\n    def warn_no_results(self):\n        printerr('No results.')\n        if self.no_results_instructions_shown:\n            return\n\n        try:\n            import json\n            import urllib.error\n            import urllib.request\n            info_json_url = '%s/master/info.json' % RAW_DOWNLOAD_REPO_BASE\n            logger.debug('Fetching %s for project status...', info_json_url)\n            try:\n                with urllib.request.urlopen(info_json_url, timeout=5) as response:\n                    try:\n                        info = json.load(response)\n                    except Exception:\n                        logger.error('Failed to decode project status from %s', info_json_url)\n                        raise RuntimeError\n            except urllib.error.HTTPError as e:\n                logger.error('Failed to fetch project status from %s: HTTP %d', info_json_url, e.code)\n                raise RuntimeError\n            epoch = info.get('epoch')\n            if epoch > _EPOCH_:\n                printerr('Your version of googler is broken due to Google-side changes.')\n                tracking_issue = info.get('tracking_issue')\n                fixed_on_master = info.get('fixed_on_master')\n                fixed_in_release = info.get('fixed_in_release')\n                if fixed_in_release:\n                    printerr('A new version, %s, has been released to address the changes.' % fixed_in_release)\n                    printerr('Please upgrade to the latest version.')\n                elif fixed_on_master:\n                    printerr('The fix has been pushed to master, pending a release.')\n                    printerr('Please download the master version https://git.io/googler or wait for a release.')\n                else:\n                    printerr('The issue is tracked at https://github.com/jarun/googler/issues/%s.' % tracking_issue)\n                return\n        except RuntimeError:\n            pass\n\n        printerr('If you believe this is a bug, please review '\n                 'https://git.io/googler-no-results before submitting a bug report.')\n        self.no_results_instructions_shown = True\n\n    @require_keywords\n    def display_results(self, prelude='\\n', json_output=False):\n        \"\"\"Display results stored in ``self.results``.\n\n        Parameters\n        ----------\n        See `fetch_and_display`.\n\n        \"\"\"\n        if json_output:\n            # JSON output\n            import json\n            results_object = [r.jsonizable_object() for r in self.results]\n            print(json.dumps(results_object, indent=2, sort_keys=True, ensure_ascii=False))\n        else:\n            # Regular output\n            if not self.results:\n                self.warn_no_results()\n            else:\n                sys.stderr.write(prelude)\n                for r in self.results:\n                    r.print()\n\n    @require_keywords\n    def showing_results_for_alert(self, interactive=True):\n        colors = self.colors\n        if self._showing_results_for:\n            if colors:\n                # Underline the query\n                actual_query = '\\x1b[4m' + self._showing_results_for + '\\x1b[24m'\n            else:\n                actual_query = self._showing_results_for\n            if self._autocorrected:\n                if interactive:\n                    info = 'Showing results for %s; enter \"x\" for an exact search.' % actual_query\n                else:\n                    info = 'Showing results for %s; use -x, --exact for an exact search.' % actual_query\n            else:\n                info = 'No results found; showing results for %s.' % actual_query\n            if interactive:\n                printerr('')\n            if colors:\n                printerr(colors.prompt + info + colors.reset)\n            else:\n                printerr('** ' + info)\n\n    @require_keywords\n    def fetch_and_display(self, prelude='\\n', json_output=False, interactive=True):\n        \"\"\"Fetch a page and display results.\n\n        Results are stored in ``self.results``.\n\n        Parameters\n        ----------\n        prelude : str, optional\n            A string that is written to stderr before showing actual results,\n            usually serving as a separator. Default is an empty line.\n        json_output : bool, optional\n            Whether to dump results in JSON format. Default is False.\n        interactive : bool, optional\n            Whether to show contextual instructions, when e.g. Google\n            has filtered the results. Default is True.\n\n        Raises\n        ------\n        GoogleConnectionError\n\n        See Also\n        --------\n        fetch\n        display_results\n\n        \"\"\"\n        self.fetch()\n        self.showing_results_for_alert()\n        self.display_results(prelude=prelude, json_output=json_output)\n        if self._results_filtered:\n            colors = self.colors\n            info = 'Enter \"unfilter\" to show similar results Google omitted.'\n            if colors:\n                printerr(colors.prompt + info + colors.reset)\n            else:\n                printerr('** ' + info)\n            printerr('')\n\n    def read_next_command(self):\n        \"\"\"Show omniprompt and read user command line.\n\n        Command line is always stripped, and each consecutive group of\n        whitespace is replaced with a single space character. If the\n        command line is empty after stripping, when ignore it and keep\n        reading. Exit with status 0 if we get EOF or an empty line\n        (pre-strip, that is, a raw <enter>) twice in a row.\n\n        The new command line (non-empty) is stored in ``self.cmd``.\n\n        \"\"\"\n        colors = self.colors\n        message = 'googler (? for help)'\n        prompt = (colors.prompt + message + colors.reset + ' ') if (colors and self.promptcolor) else (message + ': ')\n        enter_count = 0\n        while True:\n            try:\n                cmd = input(prompt)\n            except EOFError:\n                sys.exit(0)\n\n            if not cmd:\n                enter_count += 1\n                if enter_count == 2:\n                    # Double <enter>\n                    sys.exit(0)\n            else:\n                enter_count = 0\n\n            cmd = ' '.join(cmd.split())\n            if cmd:\n                self.cmd = cmd\n                break\n\n    @staticmethod\n    def help():\n        GooglerArgumentParser.print_omniprompt_help(sys.stderr)\n        printerr('')\n\n    @require_keywords\n    @no_argument\n    def do_first(self):\n        try:\n            self._google_url.first_page()\n        except ValueError as e:\n            print(e, file=sys.stderr)\n            return\n\n        self.fetch_and_display()\n\n    def do_google(self, arg):\n        # Update keywords and reconstruct URL\n        self._opts.keywords = arg\n        self._google_url = GoogleUrl(self._opts)\n        self.fetch_and_display()\n\n    @require_keywords\n    @no_argument\n    def do_next(self):\n        # If > 5 results are being fetched each time,\n        # block next when no parsed results in current fetch\n        if not self.results and self._google_url._num > 5:\n            printerr('No results.')\n        else:\n            self._google_url.next_page()\n            self.fetch_and_display()\n\n    @require_keywords\n    def do_open(self, *args):\n        if not args:\n            open_url(self._google_url.full())\n            return\n\n        for nav in args:\n            if nav == 'a':\n                for key, value in sorted(self._urltable.items()):\n                    open_url(self._urltable[key])\n            elif nav in self._urltable:\n                open_url(self._urltable[nav])\n            elif '-' in nav:\n                try:\n                    vals = [int(x) for x in nav.split('-')]\n                    if (len(vals) != 2):\n                        printerr('Invalid range %s.' % nav)\n                        continue\n\n                    if vals[0] > vals[1]:\n                        vals[0], vals[1] = vals[1], vals[0]\n\n                    for _id in range(vals[0], vals[1] + 1):\n                        if str(_id) in self._urltable:\n                            open_url(self._urltable[str(_id)])\n                        else:\n                            printerr('Invalid index %s.' % _id)\n                except ValueError:\n                    printerr('Invalid range %s.' % nav)\n            else:\n                printerr('Invalid index %s.' % nav)\n\n    @require_keywords\n    @no_argument\n    def do_previous(self):\n        try:\n            self._google_url.prev_page()\n        except ValueError as e:\n            print(e, file=sys.stderr)\n            return\n\n        self.fetch_and_display()\n\n    @require_keywords\n    @no_argument\n    def do_exact(self):\n        # Reset start to 0 when exact is applied.\n        self._google_url.update(start=0, exact=True)\n        self.fetch_and_display()\n\n    @require_keywords\n    @no_argument\n    def do_unfilter(self):\n        # Reset start to 0 when unfilter is applied.\n        self._google_url.update(start=0)\n        self._google_url.set_queries(filter=0)\n        self.fetch_and_display()\n\n    def copy_url(self, idx):\n        try:\n            try:\n                content = self._urltable[idx].encode('utf-8')\n            except KeyError:\n                printerr('Invalid index.')\n                return\n\n            # try copying the url to clipboard using native utilities\n            copier_params = []\n            if sys.platform.startswith(('linux', 'freebsd', 'openbsd')):\n                if shutil.which('xsel') is not None:\n                    copier_params = ['xsel', '-b', '-i']\n                elif shutil.which('xclip') is not None:\n                    copier_params = ['xclip', '-selection', 'clipboard']\n                elif shutil.which('wl-copy') is not None:\n                    copier_params = ['wl-copy']\n                elif shutil.which('termux-clipboard-set') is not None:\n                    copier_params = ['termux-clipboard-set']\n            elif sys.platform == 'darwin':\n                copier_params = ['pbcopy']\n            elif sys.platform == 'win32':\n                copier_params = ['clip']\n\n            if copier_params:\n                Popen(copier_params, stdin=PIPE, stdout=DEVNULL, stderr=DEVNULL).communicate(content)\n                return\n\n            # If native clipboard utilities are absent, try to use terminal multiplexers\n            # tmux\n            if os.getenv('TMUX_PANE'):\n                copier_params = ['tmux', 'set-buffer']\n                Popen(copier_params + [content], stdin=DEVNULL, stdout=DEVNULL, stderr=DEVNULL).communicate()\n                return\n\n            # GNU Screen paste buffer\n            if os.getenv('STY'):\n                import tempfile\n                copier_params = ['screen', '-X', 'readbuf', '-e', 'utf8']\n                tmpfd, tmppath = tempfile.mkstemp()\n                try:\n                    with os.fdopen(tmpfd, 'wb') as fp:\n                        fp.write(content)\n                    copier_params.append(tmppath)\n                    Popen(copier_params, stdin=DEVNULL, stdout=DEVNULL, stderr=DEVNULL).communicate()\n                finally:\n                    os.unlink(tmppath)\n                return\n\n            printerr('failed to locate suitable clipboard utility')\n        except Exception:\n            raise NoKeywordsException\n\n    def cmdloop(self):\n        \"\"\"Run REPL.\"\"\"\n        if self.keywords:\n            self.fetch_and_display()\n        else:\n            printerr('Please initiate a query.')\n\n        while True:\n            self.read_next_command()\n            # TODO: Automatic dispatcher\n            #\n            # We can't write a dispatcher for now because that could\n            # change behaviour of the prompt. However, we have already\n            # laid a lot of ground work for the dispatcher, e.g., the\n            # `no_argument' decorator.\n            try:\n                cmd = self.cmd\n                if cmd == 'f':\n                    self.do_first('')\n                elif cmd.startswith('g '):\n                    self.do_google(cmd[2:])\n                elif cmd == 'n':\n                    self.do_next('')\n                elif cmd == 'o':\n                    self.do_open()\n                elif cmd.startswith('o '):\n                    self.do_open(*cmd[2:].split())\n                elif cmd.startswith('O '):\n                    open_url.override_text_browser = True\n                    self.do_open(*cmd[2:].split())\n                    open_url.override_text_browser = False\n                elif cmd == 'p':\n                    self.do_previous('')\n                elif cmd == 'q':\n                    break\n                elif cmd == 'x':\n                    self.do_exact('')\n                elif cmd == 'unfilter':\n                    self.do_unfilter('')\n                elif cmd == '?':\n                    self.help()\n                elif cmd in self._urltable:\n                    open_url(self._urltable[cmd])\n                elif self.keywords and cmd.isdigit() and int(cmd) < 100:\n                    printerr('Index out of bound. To search for the number, use g.')\n                elif cmd == 'u':\n                    Result.urlexpand = not Result.urlexpand\n                    self.display_results()\n                elif cmd.startswith('c ') and self.re_url_index.match(cmd[2:]):\n                    self.copy_url(cmd[2:])\n                else:\n                    self.do_google(cmd)\n            except NoKeywordsException:\n                printerr('Initiate a query first.')\n\n\nclass GooglerArgumentParser(argparse.ArgumentParser):\n    \"\"\"Custom argument parser for googler.\"\"\"\n\n    # Print omniprompt help\n    @staticmethod\n    def print_omniprompt_help(file=None):\n        file = sys.stderr if file is None else file\n        file.write(textwrap.dedent(\"\"\"\n        omniprompt keys:\n          n, p                  fetch the next or previous set of search results\n          index                 open the result corresponding to index in browser\n          f                     jump to the first page\n          o [index|range|a ...] open space-separated result indices, numeric ranges\n                                (sitelinks unsupported in ranges), or all, in browser\n                                open the current search in browser, if no arguments\n          O [index|range|a ...] like key 'o', but try to open in a GUI browser\n          g keywords            new Google search for 'keywords' with original options\n                                should be used to search omniprompt keys and indices\n          c index               copy url to clipboard\n          u                     toggle url expansion\n          q, ^D, double Enter   exit googler\n          ?                     show omniprompt help\n          *                     other inputs issue a new search with original options\n        \"\"\"))\n\n    # Print information on googler\n    @staticmethod\n    def print_general_info(file=None):\n        file = sys.stderr if file is None else file\n        file.write(textwrap.dedent(\"\"\"\n        Version %s\n        Copyright  2008 Henri Hakkinen\n        Copyright  2015-2021 Arun Prakash Jana <engineerarun@gmail.com>\n        Zhiming Wang <zmwangx@gmail.com>\n        License: GPLv3\n        Webpage: https://github.com/jarun/googler\n        \"\"\" % _VERSION_))\n\n    # Augment print_help to print more than synopsis and options\n    def print_help(self, file=None):\n        super().print_help(file)\n        self.print_omniprompt_help(file)\n        self.print_general_info(file)\n\n    # Automatically print full help text on error\n    def error(self, message):\n        sys.stderr.write('%s: error: %s\\n\\n' % (self.prog, message))\n        self.print_help(sys.stderr)\n        self.exit(2)\n\n    # Type guards\n    @staticmethod\n    def positive_int(arg):\n        \"\"\"Try to convert a string into a positive integer.\"\"\"\n        try:\n            n = int(arg)\n            assert n > 0\n            return n\n        except (ValueError, AssertionError):\n            raise argparse.ArgumentTypeError('%s is not a positive integer' % arg)\n\n    @staticmethod\n    def nonnegative_int(arg):\n        \"\"\"Try to convert a string into a nonnegative integer.\"\"\"\n        try:\n            n = int(arg)\n            assert n >= 0\n            return n\n        except (ValueError, AssertionError):\n            raise argparse.ArgumentTypeError('%s is not a non-negative integer' % arg)\n\n    @staticmethod\n    def is_duration(arg):\n        \"\"\"Check if a string is a valid duration accepted by Google.\n\n        A valid duration is of the form dNUM, where d is a single letter h\n        (hour), d (day), w (week), m (month), or y (year), and NUM is a\n        non-negative integer.\n        \"\"\"\n        try:\n            if arg[0] not in ('h', 'd', 'w', 'm', 'y') or int(arg[1:]) < 0:\n                raise ValueError\n        except (TypeError, IndexError, ValueError):\n            raise argparse.ArgumentTypeError('%s is not a valid duration' % arg)\n        return arg\n\n    @staticmethod\n    def is_date(arg):\n        \"\"\"Check if a string is a valid date/month/year accepted by Google.\"\"\"\n        if re.match(r'^(\\d+/){0,2}\\d+$', arg):\n            return arg\n        else:\n            raise argparse.ArgumentTypeError('%s is not a valid date/month/year; '\n                                             'use the American date format with slashes')\n\n    @staticmethod\n    def is_colorstr(arg):\n        \"\"\"Check if a string is a valid color string.\"\"\"\n        try:\n            assert len(arg) == 6\n            for c in arg:\n                assert c in COLORMAP\n        except AssertionError:\n            raise argparse.ArgumentTypeError('%s is not a valid color string' % arg)\n        return arg\n\n\n# Self-upgrade mechanism\n\ndef system_is_windows():\n    \"\"\"Checks if the underlying system is Windows (Cygwin included).\"\"\"\n    return sys.platform in {'win32', 'cygwin'}\n\n\ndef get_latest_ref(include_git=False):\n    \"\"\"Helper for download_latest_googler.\"\"\"\n    import urllib.request\n\n    if include_git:\n        # Get SHA of latest commit on master\n        request = urllib.request.Request('%s/commits/master' % API_REPO_BASE,\n                                         headers={'Accept': 'application/vnd.github.v3.sha'})\n        response = urllib.request.urlopen(request)\n        if response.status != 200:\n            raise http.client.HTTPException(response.reason)\n        return response.read().decode('utf-8')\n    else:\n        # Get name of latest tag\n        request = urllib.request.Request('%s/releases?per_page=1' % API_REPO_BASE,\n                                         headers={'Accept': 'application/vnd.github.v3+json'})\n        response = urllib.request.urlopen(request)\n        if response.status != 200:\n            raise http.client.HTTPException(response.reason)\n        import json\n        return json.loads(response.read().decode('utf-8'))[0]['tag_name']\n\n\ndef download_latest_googler(include_git=False):\n    \"\"\"Download latest googler to a temp file.\n\n    By default, the latest released version is downloaded, but if\n    `include_git` is specified, then the latest git master is downloaded\n    instead.\n\n    Parameters\n    ----------\n    include_git : bool, optional\n        Download from git master. Default is False.\n\n    Returns\n    -------\n    (git_ref, path): tuple\n         A tuple containing the git reference (either name of the latest\n         tag or SHA of the latest commit) and path to the downloaded\n         file.\n\n    \"\"\"\n    # Download googler to a tempfile\n    git_ref = get_latest_ref(include_git=include_git)\n    googler_download_url = '%s/%s/googler' % (RAW_DOWNLOAD_REPO_BASE, git_ref)\n    printerr('Downloading %s' % googler_download_url)\n    request = urllib.request.Request(googler_download_url,\n                                     headers={'Accept-Encoding': 'gzip'})\n    import tempfile\n    fd, path = tempfile.mkstemp()\n    atexit.register(lambda: os.remove(path) if os.path.exists(path) else None)\n    os.close(fd)\n    with open(path, 'wb') as fp:\n        with urllib.request.urlopen(request) as response:\n            if response.status != 200:\n                raise http.client.HTTPException(response.reason)\n            payload = response.read()\n            try:\n                fp.write(gzip.decompress(payload))\n            except OSError:\n                fp.write(payload)\n    return git_ref, path\n\n\ndef self_replace(path):\n    \"\"\"Replace the current script with a specified file.\n\n    Both paths (the specified path and path to the current script) are\n    resolved to absolute, symlink-free paths. Upon replacement, the\n    owner and mode signatures of the current script are preserved. The\n    caller needs to have the necessary permissions.\n\n    Replacement won't happen if the specified file is the same\n    (content-wise) as the current script.\n\n    Parameters\n    ----------\n    path : str\n        Path to the replacement file.\n\n    Returns\n    -------\n    bool\n        True if replaced, False if skipped (specified file is the same\n        as the current script).\n\n    \"\"\"\n    if system_is_windows():\n        raise NotImplementedError('Self upgrade not supported on Windows.')\n\n    import filecmp\n    import shutil\n\n    path = os.path.realpath(path)\n    self_path = os.path.realpath(__file__)\n\n    if filecmp.cmp(path, self_path):\n        return False\n\n    self_stat = os.stat(self_path)\n    os.chown(path, self_stat.st_uid, self_stat.st_gid)\n    os.chmod(path, self_stat.st_mode)\n\n    shutil.move(path, self_path)\n    return True\n\n\ndef self_upgrade(include_git=False):\n    \"\"\"Perform in-place self-upgrade.\n\n    Parameters\n    ----------\n    include_git : bool, optional\n        See `download_latest_googler`. Default is False.\n\n    \"\"\"\n    git_ref, path = download_latest_googler(include_git=include_git)\n    if self_replace(path):\n        printerr('Upgraded to %s.' % git_ref)\n    else:\n        printerr('Already up to date.')\n\n\ndef check_new_version():\n    try:\n        from distutils.version import StrictVersion as Version\n    except ImportError:\n        # distutils not available (thanks distros), use a concise poor\n        # man's version parser.\n        class Version(tuple):\n            def __new__(cls, version_str):\n                def parseint(s):\n                    try:\n                        return int(s)\n                    except ValueError:\n                        return 0\n                return tuple.__new__(cls, [parseint(s) for s in version_str.split('.')])\n\n    import pathlib\n    import tempfile\n    import time\n    cache = pathlib.Path(tempfile.gettempdir()) / 'googler-latest-version'\n    latest_version_str = None\n    # Try to load latest version string from cached location, if it\n    # exists and is fresh enough.\n    try:\n        if cache.is_file() and time.time() - cache.stat().st_mtime < 86400:\n            latest_version_str = cache.read_text().strip()\n    except OSError:\n        pass\n    if not latest_version_str:\n        try:\n            latest_version_str = get_latest_ref().lstrip('v')\n            cache.write_text(latest_version_str)\n        except Exception:\n            pass\n    if not latest_version_str:\n        return\n    # Try to fetch latest version string from GitHub.\n    try:\n        current_version = Version(_VERSION_)\n        latest_version = Version(latest_version_str)\n    except ValueError:\n        return\n    if latest_version > current_version:\n        print('\\x1b[33;1mThe latest release of googler is v%s, please upgrade.\\x1b[0m'\n              % latest_version_str,\n              file=sys.stderr)\n\n\n# Miscellaneous functions\n\ndef python_version():\n    return '%d.%d.%d' % sys.version_info[:3]\n\n\ndef https_proxy_from_environment():\n    return os.getenv('https_proxy')\n\n\ndef parse_proxy_spec(proxyspec):\n    if '://' in proxyspec:\n        pos = proxyspec.find('://')\n        scheme = proxyspec[:pos]\n        proxyspec = proxyspec[pos+3:]\n        if scheme.lower() != 'http':\n            # Only support HTTP proxies.\n            #\n            # In particular, we don't support HTTPS proxies since we\n            # only speak plain HTTP to the proxy server, so don't give\n            # users a false sense of security.\n            raise NotImplementedError('Unsupported proxy scheme %s.' % scheme)\n\n    if '@' in proxyspec:\n        pos = proxyspec.find('@')\n        user_passwd = urllib.parse.unquote(proxyspec[:pos])\n        # Remove trailing '/' if any\n        host_port = proxyspec[pos+1:].rstrip('/')\n    else:\n        user_passwd = None\n        host_port = proxyspec.rstrip('/')\n\n    if ':' not in host_port:\n        # Use port 1080 as default, following curl.\n        host_port += ':1080'\n\n    return user_passwd, host_port\n\n\ndef set_win_console_mode():\n    # VT100 control sequences are supported on Windows 10 Anniversary Update and later.\n    # https://docs.microsoft.com/en-us/windows/console/console-virtual-terminal-sequences\n    # https://docs.microsoft.com/en-us/windows/console/setconsolemode\n    if platform.release() == '10':\n        STD_OUTPUT_HANDLE = -11\n        STD_ERROR_HANDLE = -12\n        ENABLE_VIRTUAL_TERMINAL_PROCESSING = 0x0004\n        try:\n            from ctypes import windll, wintypes, byref\n            kernel32 = windll.kernel32\n            for nhandle in (STD_OUTPUT_HANDLE, STD_ERROR_HANDLE):\n                handle = kernel32.GetStdHandle(nhandle)\n                old_mode = wintypes.DWORD()\n                if not kernel32.GetConsoleMode(handle, byref(old_mode)):\n                    raise RuntimeError('GetConsoleMode failed')\n                new_mode = old_mode.value | ENABLE_VIRTUAL_TERMINAL_PROCESSING\n                if not kernel32.SetConsoleMode(handle, new_mode):\n                    raise RuntimeError('SetConsoleMode failed')\n            # Note: No need to restore at exit. SetConsoleMode seems to\n            # be limited to the calling process.\n        except Exception:\n            pass\n\n\n# Query autocompleter\n\n# This function is largely experimental and could raise any exception;\n# you should be prepared to catch anything. When it works though, it\n# returns a list of strings the prefix could autocomplete to (however,\n# it is not guaranteed that they start with the specified prefix; for\n# instance, they won't if the specified prefix ends in a punctuation\n# mark.)\ndef completer_fetch_completions(prefix):\n    import html\n    import json\n    import re\n    import urllib.request\n\n    # One can pass the 'hl' query param to specify the language. We\n    # ignore that for now.\n    api_url = ('https://www.google.com/complete/search?client=psy-ab&q=%s' %\n               urllib.parse.quote(prefix, safe=''))\n    # A timeout of 3 seconds seems to be overly generous already.\n    resp = urllib.request.urlopen(api_url, timeout=3)\n    charset = resp.headers.get_content_charset()\n    logger.debug('Completions charset: %s', charset)\n    respobj = json.loads(resp.read().decode(charset))\n\n    # The response object, once parsed as JSON, should look like\n    #\n    # ['git',\n    #  [['git<b>hub</b>', 0],\n    #   ['git', 0],\n    #   ['git<b>lab</b>', 0],\n    #   ['git<b> stash</b>', 0]],\n    #  {'q': 'oooAhRzoChqNmMbNaaDKXk1YY4k', 't': {'bpc': False, 'tlw': False}}]\n    #\n    # Note the each result entry need not have two members; e.g., for\n    # 'gi', there is an entry ['gi<b>f</b>', 0, [131]].\n    HTML_TAG = re.compile(r'<[^>]+>')\n    return [html.unescape(HTML_TAG.sub('', entry[0])) for entry in respobj[1]]\n\n\ndef completer_run(prefix):\n    if prefix:\n        completions = completer_fetch_completions(prefix)\n        if completions:\n            print('\\n'.join(completions))\n    sys.exit(0)\n\n\ndef parse_args(args=None, namespace=None):\n    \"\"\"Parse googler arguments/options.\n\n    Parameters\n    ----------\n    args : list, optional\n        Arguments to parse. Default is ``sys.argv``.\n    namespace : argparse.Namespace\n        Namespace to write to. Default is a new namespace.\n\n    Returns\n    -------\n    argparse.Namespace\n        Namespace with parsed arguments / options.\n\n    \"\"\"\n\n    colorstr_env = os.getenv('GOOGLER_COLORS')\n\n    argparser = GooglerArgumentParser(description='Google from the command-line.')\n    addarg = argparser.add_argument\n    addarg('-s', '--start', type=argparser.nonnegative_int, default=0,\n           metavar='N', help='start at the Nth result')\n    addarg('-n', '--count', dest='num', type=argparser.positive_int,\n           default=10, metavar='N', help='show N results (default 10)')\n    addarg('-N', '--news', action='store_true',\n           help='show results from news section')\n    addarg('-V', '--videos', action='store_true',\n           help='show results from videos section')\n    addarg('-c', '--tld', metavar='TLD',\n           help=\"\"\"country-specific search with top-level domain .TLD, e.g., 'in'\n           for India\"\"\")\n    addarg('-l', '--lang', metavar='LANG', help='display in language LANG')\n    addarg('-g', '--geoloc', metavar='CC',\n           help=\"\"\"country-specific geolocation search with country code CC, e.g.\n           'in' for India. Country codes are the same as top-level domains\"\"\")\n    addarg('-x', '--exact', action='store_true',\n           help='disable automatic spelling correction')\n    addarg('--colorize', nargs='?', choices=['auto', 'always', 'never'],\n           const='always', default='auto',\n           help=\"\"\"whether to colorize output; defaults to 'auto', which enables\n           color when stdout is a tty device; using --colorize without an argument\n           is equivalent to --colorize=always\"\"\")\n    addarg('-C', '--nocolor', action='store_true',\n           help='equivalent to --colorize=never')\n    addarg('--colors', dest='colorstr', type=argparser.is_colorstr,\n           default=colorstr_env if colorstr_env else 'GKlgxy', metavar='COLORS',\n           help='set output colors (see man page for details)')\n    addarg('-j', '--first', '--lucky', dest='lucky', action='store_true',\n           help='open the first result in web browser and exit')\n    addarg('-t', '--time', dest='duration', type=argparser.is_duration,\n           metavar='dN', help='time limit search '\n           '[h5 (5 hrs), d5 (5 days), w5 (5 weeks), m5 (5 months), y5 (5 years)]')\n    addarg('--from', type=argparser.is_date,\n           help=\"\"\"starting date/month/year of date range; must use American date\n           format with slashes, e.g., 2/24/2020, 2/2020, 2020; can be used in\n           conjunction with --to, and overrides -t, --time\"\"\")\n    addarg('--to', type=argparser.is_date,\n           help='ending date/month/year of date range; see --from')\n    addarg('-w', '--site', dest='sites', action='append', metavar='SITE',\n           help='search a site using Google')\n    addarg('-e', '--exclude', dest='exclude', action='append', metavar='SITE',\n           help='exclude site from results')\n    addarg('--unfilter', action='store_true', help='do not omit similar results')\n    addarg('-p', '--proxy', default=https_proxy_from_environment(),\n           help=\"\"\"tunnel traffic through an HTTP proxy;\n           PROXY is of the form [http://][user:password@]proxyhost[:port]\"\"\")\n    addarg('--noua', action='store_true', help=argparse.SUPPRESS)\n    addarg('--notweak', action='store_true',\n           help='disable TCP optimizations and forced TLS 1.2')\n    addarg('--json', action='store_true',\n           help='output in JSON format; implies --noprompt')\n    addarg('--url-handler', metavar='UTIL',\n           help='custom script or cli utility to open results')\n    addarg('--show-browser-logs', action='store_true',\n           help='do not suppress browser output (stdout and stderr)')\n    addarg('--np', '--noprompt', dest='noninteractive', action='store_true',\n           help='search and exit, do not prompt')\n    addarg('-4', '--ipv4', action='store_const', dest='address_family',\n           const=socket.AF_INET, default=0,\n           help=\"\"\"only connect over IPv4\n           (by default, IPv4 is preferred but IPv6 is used as a fallback)\"\"\")\n    addarg('-6', '--ipv6', action='store_const', dest='address_family',\n           const=socket.AF_INET6, default=0,\n           help='only connect over IPv6')\n    addarg('keywords', nargs='*', metavar='KEYWORD', help='search keywords')\n    if ENABLE_SELF_UPGRADE_MECHANISM and not system_is_windows():\n        addarg('-u', '--upgrade', action='store_true',\n               help='perform in-place self-upgrade')\n        addarg('--include-git', action='store_true',\n               help='when used with --upgrade, get latest git master')\n    addarg('-v', '--version', action='version', version=_VERSION_)\n    addarg('-d', '--debug', action='store_true', help='enable debugging')\n    # Hidden option for interacting with DOM in an IPython/pdb shell\n    addarg('-D', '--debugger', action='store_true', help=argparse.SUPPRESS)\n    # Hidden option for parsing dumped HTML\n    addarg('--parse', dest='html_file', help=argparse.SUPPRESS)\n    addarg('--complete', help=argparse.SUPPRESS)\n\n    parsed = argparser.parse_args(args, namespace)\n    if parsed.nocolor:\n        parsed.colorize = 'never'\n\n    return parsed\n\n\ndef main():\n    try:\n        opts = parse_args()\n\n        # Set logging level\n        if opts.debug:\n            logger.setLevel(logging.DEBUG)\n            logger.debug('googler version %s', _VERSION_)\n            logger.debug('Python version %s', python_version())\n            logger.debug('Platform: %s', platform.platform())\n            check_new_version()\n\n        if opts.debugger:\n            global debugger\n            debugger = True\n\n        # Handle query completer\n        if opts.complete is not None:\n            completer_run(opts.complete)\n\n        # Handle self-upgrade\n        if hasattr(opts, 'upgrade') and opts.upgrade:\n            self_upgrade(include_git=opts.include_git)\n            sys.exit(0)\n\n        check_stdout_encoding()\n\n        if opts.keywords:\n            try:\n                # Add cmdline args to readline history\n                readline.add_history(' '.join(opts.keywords))\n            except Exception:\n                pass\n\n        # Set colors\n        if opts.colorize == 'always':\n            colorize = True\n        elif opts.colorize == 'auto':\n            colorize = sys.stdout.isatty()\n        else:  # opts.colorize == 'never'\n            colorize = False\n\n        if colorize:\n            colors = Colors(*[COLORMAP[c] for c in opts.colorstr], reset=COLORMAP['x'])\n        else:\n            colors = None\n        Result.colors = colors\n        Result.urlexpand = True if os.getenv('DISABLE_URL_EXPANSION') is None else False\n        GooglerCmd.colors = colors\n\n        # Try to enable ANSI color support in cmd or PowerShell on Windows 10\n        if sys.platform == 'win32' and sys.stdout.isatty() and colorize:\n            set_win_console_mode()\n\n        if opts.url_handler is not None:\n            open_url.url_handler = opts.url_handler\n        else:\n            # Set text browser override to False\n            open_url.override_text_browser = False\n\n            # Handle browser output suppression\n            if opts.show_browser_logs or (os.getenv('BROWSER') in text_browsers):\n                open_url.suppress_browser_output = False\n            else:\n                open_url.suppress_browser_output = True\n\n        if opts.noua:\n            logger.warning('--noua option has been deprecated and has no effect (see #284)')\n\n        repl = GooglerCmd(opts)\n\n        # Non-interactive mode\n        if opts.json or opts.lucky or opts.noninteractive or opts.html_file:\n            repl.fetch()\n            if opts.lucky:\n                if repl.results:\n                    open_url(repl.results[0].url)\n                else:\n                    print('No results.', file=sys.stderr)\n            else:\n                repl.showing_results_for_alert(interactive=False)\n                repl.display_results(json_output=opts.json)\n            sys.exit(0)\n\n        # Interactive mode\n        repl.cmdloop()\n    except Exception as e:\n        # With debugging on, let the exception through for a traceback;\n        # otherwise, only print the exception error message.\n        if logger.isEnabledFor(logging.DEBUG):\n            raise\n        else:\n            logger.error(e)\n            sys.exit(1)\n\nif __name__ == '__main__':\n    main()\n"
        },
        {
          "name": "googler.1",
          "type": "blob",
          "size": 11.486328125,
          "content": ".TH \"GOOGLER\" \"1\" \"21 Jan 2021\" \"Version 4.3.2\" \"User Commands\"\n.SH NAME\ngoogler \\- Google from the command-line\n.SH SYNOPSIS\n.B googler [OPTIONS] [KEYWORD [KEYWORD ...]]\n.SH DESCRIPTION\n.B googler\nis a command-line tool to search Google (web, news, videos and site search) from the terminal. Google site search works too. \\fBgoogler\\fR shows the title, URL and text context for each result. Results are fetched in pages. Next or previous page navigation is possible using keyboard shortcuts. Results are indexed and a result URL can be opened in a browser using the index number. There is no configuration file as aliases serve the same purpose for this utility. Supports sequential searches in a single instance.\n.PP\n.B Features\n.PP\n  * Google Search, Google Site Search, Google News\n  * Fast and clean (no ads, stray URLs or clutter), custom color\n  * Navigate result pages from omniprompt, open URLs in browser\n  * Effortless keyword-based site search with googler @t add-on\n  * Search and option completion scripts for Bash, Zsh and Fish\n  * Fetch n results in a go, start at the n<sup>th</sup> result\n  * Disable automatic spelling correction and search exact keywords\n  * Specify duration, country/domain (default: worldwide/.com), language\n  * Google keywords (e.g. \\fIfiletype:mime\\fR, \\fIsite:somesite.com\\fR) support\n  * Open the first result directly in browser (as in I'm Feeling Lucky)\n  * Non-stop searches: fire new searches at omniprompt without exiting\n  * HTTPS proxy, User Agent, TLS 1.2 (default) support\n  * Comprehensive documentation, man page with handy usage examples\n  * Minimal dependencies\n.SH OPTIONS\n.TP\n.BI \"-h, --help\"\nShow help text and exit.\n.TP\n.BI \"-s, --start=\" N\nStart at the \\fIN\\fRth result.\n.TP\n.BI \"-n, --count=\" N\nShow \\fIN\\fR results (default 10).\n.TP\n.BI \"-N, --news\"\nShow results from news section.\n.TP\n.BI \"-c, --tld=\" TLD\nCountry-specific search with top-level domain \\fI.TLD\\fR, e.g., \\fBin\\fR for India.\n.TP\n.BI \"-l, --lang=\" LANG\nSearch for the language \\fILANG\\fR, e.g., \\fBfi\\fR for Finnish.\n.TP\n.BI \"-g, --geoloc=\" CC\nCountry-specific geolocation search with country code CC, e.g. 'in' for India. Country codes are the same as top-level domains.\n.TP\n.B \"-x, --exact\"\nDisable automatic spelling correction. Search exact keywords.\n.TP\n.B \"-C, --nocolor\"\nDisable color output.\n.TP\n.BI \"--colors=\" COLORS\nSet output colors. Refer to the \\fBCOLORS\\fR section below for details.\n.TP\n.B \"-j, --first, --lucky\"\nOpen the first result in a web browser; implies \\fB--noprompt\\fR. Feeling Lucky?\n.TP\n.BI \"-t, --time=\" dN\nTime limit search [h5 (5 hrs), d5 (5 days), w5 (5 weeks), m5 (5 months), y5 (5 years)].\n.TP\n.BI \"-w, --site=\" SITE\nSearch a site using Google.\n.TP\n.BI \"-e, --exclude=\" EXCLUDE\nExclude site from results.\n.TP\n.BI \"--unfilter\"\nDo not omit similar results.\n.TP\n.BI \"-p, --proxy=\" PROXY\nTunnel traffic through an HTTP proxy. \\fIPROXY\\fR is of the form \\fI[http://][user:password@]proxyhost[:port]\\fR. The proxy server must support HTTP CONNECT tunneling and must not block port 443 for the relevant Google hosts. If a proxy is not explicitly given, the \\fIhttps_proxy\\fR environment variable (if available) is used instead.\n.TP\n.BI \"--noua\"\nDisable user agent. Results are fetched faster.\n.TP\n.BI \"--notweak\"\nDisable TCP optimizations. Negotiate Transport Layer Security protocol instead of forcing TLS 1.2 (on Python 3.4 and above). Should be used only in case of connection issues.\n.TP\n.BI \"--json\"\nOutput in JSON format; implies \\fB--noprompt\\fR.\n.TP\n.BI \"--url-handler=\" UTIL\nCustom script or command-line utility to open urls with.\n.TP\n.BI \"--show-browser-logs\"\nDo not suppress browser output when opening result in browser; that is, connect stdout and stderr of the browser to googler's stdout and stderr instead of /dev/null. By default, browser output is suppressed (due to certain graphical browsers spewing messages to console) unless the \\fBBROWSER\\fR environment variable is a known text-based browser: elinks, links, lynx, w3m or www-browser.\n.TP\n.BI \"--np, --noprompt\"\nPerform search and exit; do not prompt for further interactions.\n.TP\n.BI \"-u, --upgrade\"\nPerform in-place self-upgrade. By default, the latest stable version is used. However, the latest git master is used instead if \\fB--include-git\\fR is also supplied. This mechanism is not available on Windows (including Cygwin), and if you installed \\fBgoogler\\fR with a package manager, this mechanism may have been disabled by your packager at packaging or install time.\n.TP\n.BI \"--include-git\"\nSee \\fB--upgrade\\fR.\n.TP\n.BI \"-v, --version\"\nShow version number and exit.\n.TP\n.BI \"-d, --debug\"\nEnable debugging.\n.SH OMNIPROMPT KEYS\n.TP\n.BI \"n, p\"\nFetch the next or previous set of search results.\n.TP\n.BI \"index\"\nOpen the result corresponding to index in browser.\n.TP\n.BI \"f\"\nJump to the first page.\n.TP\n.BI o \" [index|range|a ...]\"\nOpen space-separated result indices, numeric ranges (sitelinks unsupported in ranges) or all indices, if 'a' is specified, in the browser. Open the current search in the browser, if no arguments.\n.TP\n.BI O \" [index|range|a ...]\"\nWorks similar to key 'o', but tries to ignore text-based browsers (even if BROWSER is set) and open links in a GUI browser.\n.TP\n.BI g \" keywords\"\nInitiate a new Google search for \\fIkeywords\\fR with original options. This key should be used to search omniprompt keys (including itself) and indices.\n.TP\n.BI \"c index\"\nCopy url to clipboard.\n.TP\n.BI \"u\"\nToggle url expansion.\n.TP\n.BI \"q, ^D, double Enter\"\nExit googler.\n.TP\n.BI \"?\"\nShow omniprompt help.\n.TP\n.BI *\nAny other string initiates a new search with original options.\n.SH GOOGLER @T\n\\fBgoogler @t\\fR is a convenient add-on to Google Site Search with unique keywords. While \\fBgoogler\\fR has an integrated option to search a site, it could be simplified further with aliases. The file \\fIgoogler_at\\fR (https://github.com/jarun/googler/blob/master/auto-completion/googler_at/googler_at) contains a list of website search aliases. To source it, run:\n.PP\n.IP \"\" 4\n.B source googler_at\n.PP\nor\n.PP\n.IP \"\" 4\n.B . googler_at\n.PP\nWith \\fBgoogler @t\\fR, the following command searches Wikipedia for \\fIhexspeak\\fR:\n.PP\n.IP \"\" 4\n.B @w hexspeak\n.PP\nOther \\fBgoogler\\fR options can be combined. The shell can be configured to be source the file at start-up for further convenience.\n.PP\nAll the aliases start with the \\fB@\\fR symbol (hence the name \\fBgoogler @t\\fR) and there is minimum chance they will conflict with any shell commands. Users can add new aliases to the file.\n.SH COLORS\n\\fBgoogler\\fR allows you to customize the color scheme via a six-letter string, reminiscent of BSD \\fBLSCOLORS\\fR. The six letters represent the colors of\n.IP - 2\nindices\n.PD 0 \\\" Change paragraph spacing to 0 in the list\n.IP - 2\ntitles\n.IP - 2\nURLs\n.IP - 2\nmetadata/publishing info (Google News only)\n.IP - 2\nabstracts\n.IP - 2\nprompts\n.PD 1 \\\" Restore paragraph spacing\n.TP\nrespectively. The six-letter string is passed in either as the argument to the \\fB--colors\\fR option, or as the value of the environment variable \\fBGOOGLER_COLORS\\fR.\n.TP\nWe offer the following colors/styles:\n.TS\ntab(;) box;\nl|l\n-|-\nl|l.\nLetter;Color/Style\na;black\nb;red\nc;green\nd;yellow\ne;blue\nf;magenta\ng;cyan\nh;white\ni;bright black\nj;bright red\nk;bright green\nl;bright yellow\nm;bright blue\nn;bright magenta\no;bright cyan\np;bright white\nA-H;bold version of the lowercase-letter color\nI-P;bold version of the lowercase-letter bright color\nx;normal\nX;bold\ny;reverse video\nY;bold reverse video\n.TE\n.TP\n.TP\nThe default colors string is \\fIGKlgxy\\fR, which stands for\n.IP - 2\nbold bright cyan indices\n.PD 0 \\\" Change paragraph spacing to 0 in the list\n.IP - 2\nbold bright green titles\n.IP - 2\nbright yellow URLs\n.IP - 2\ncyan metadata/publishing info\n.IP - 2\nnormal abstracts\n.IP - 2\nreverse video prompts\n.PD 1 \\\" Restore paragraph spacing\n.TP\nNote that\n.IP - 2\nBright colors (implemented as \\\\x1b[90m - \\\\x1b[97m) may not be available in all color-capable terminal emulators;\n.IP - 2\nSome terminal emulators draw bold text in bright colors instead;\n.IP - 2\nSome terminal emulators only distinguish between bold and bright colors via a default-off switch.\n.TP\nPlease consult the manual of your terminal emulator as well as \\fIhttps://en.wikipedia.org/wiki/ANSI_escape_code\\fR for details.\n.SH ENVIRONMENT\n.TP\n.BI BROWSER\nOverrides the default browser. Ref:\n.I http://docs.python.org/library/webbrowser.html\n.TP\n.BI GOOGLER_COLORS\nRefer to the \\fBCOLORS\\fR section.\n.TP\n.BI DISABLE_PROMPT_COLOR\nForce a plain omniprompt if you are facing issues with colors at the prompt.\n.TP\n.BI https_proxy\nRefer to the \\fB--proxy\\fR option.\n.TP\n.BI DISABLE_URL_EXPANSION\nShow the domain names in search results instead of the expanded URL.\n.SH EXAMPLES\n.PP\n.IP 1. 4\nGoogle \\fBhello world\\fR:\n.PP\n.EX\n.IP\n.B googler hello world\n.EE\n.PP\n.IP 2. 4\nFetch \\fB15 results\\fR updated within the last \\fB14 months\\fR, starting from the \\fB3rd result\\fR for the keywords \\fBjungle book\\fR in \\fBsite\\fR imdb.com:\n.PP\n.EX\n.IP\n.B googler -n 15 -s 3 -t m14 -w imdb.com jungle book\n.EE\n.PP\n.IP 3. 4\nRead recent \\fBnews\\fR on gadgets:\n.PP\n.EX\n.IP\n.B googler -N gadgets\n.EE\n.PP\n.IP 4. 4\nFetch results on IPL cricket from \\fBGoogle India\\fR server in \\fBEnglish\\fR:\n.PP\n.EX\n.IP\n.B googler -c in -l en IPL cricket\n.EE\n.PP\n.IP 5. 4\nSearch \\fBquoted text\\fR:\n.PP\n.EX\n.IP\n.B googler it\\(rs's a \\(rs\\(dqbeautiful world\\(rs\\(dq in spring\n.EE\n.PP\n.IP 6. 4\nSearch for a \\fBspecific file type\\fR:\n.PP\n.EX\n.IP\n.B googler instrumental filetype:mp3\n.EE\n.PP\n.IP 7. 4\nDisable \\fBautomatic spelling correction\\fR, e.g. fetch results for \\fIgoogler\\fR instead of \\fIgoogle\\fR:\n.PP\n.EX\n.IP\n.B googler -x googler\n.EE\n.PP\n.IP 8. 4\n\\fBI'm feeling lucky\\fR search:\n.PP\n.EX\n.IP\n.B googler -j leather jackets\n.EE\n.PP\n.IP 9. 4\n\\fBWebsite specific\\fR search:\n.PP\n.EX\n.IP\n.B googler -w amazon.com -w ebay.com digital camera\n.EE\n.PP\n.IP \"\" 4\nSite specific search continues at omniprompt.\n.EE\n.PP\n.IP 10. 4\nAlias to find \\fBdefinitions of words\\fR:\n.PP\n.EX\n.IP\n.B alias define='googler -n 2 define'\n.EE\n.PP\n.IP 11. 4\nLook up \\fBn\\fR, \\fBp\\fR, \\fBo\\fR, \\fBO\\fR, \\fBq\\fR, \\fBg keywords\\fR or a result index at the \\fBomniprompt\\fR: as the omniprompt recognizes these keys or index strings as commands, you need to prefix them with \\fBg\\fR, e.g.,\n.PP\n.EX\n.PD 0\n.IP\n.B g n\n.IP\n.B g g keywords\n.IP\n.B g 1\n.PD\n.EE\n.PP\n.IP 12. 4\nInput and output \\fBredirection\\fR:\n.PP\n.EX\n.IP\n.B googler -C hello world < input > output\n.EE\n.PP\n.IP \"\" 4\nNote that \\fI-C\\fR is required to avoid printing control characters (for colored output).\n.IP 13. 4\n\\fBPipe\\fR output:\n.PP\n.EX\n.IP\n.B googler -C hello world | tee output\n.EE\n.IP 14. 4\nUse a \\fBcustom color scheme\\fR, e.g., one warm color scheme designed for Solarized Dark:\n.PP\n.EX\n.IP\n.B googler --colors bjdxxy google\n.IP\n.B GOOGLER_COLORS=bjdxxy googler google\n.EE\n.IP 15. 4\nTunnel traffic through an \\fBHTTPS proxy\\fR, e.g., a local Privoxy instance listening on port 8118:\n.PP\n.EX\n.IP\n.B googler --proxy localhost:8118 google\n.EE\n.PP\n.IP \"\" 4\nBy default the environment variable \\fIhttps_proxy\\fR is used, if defined.\n.IP 16. 4\nQuote multiple search keywords to auto-complete (using completion script):\n.PP\n.EX\n.IP\n.B googler 'hello w<TAB>\n.EE\n.SH AUTHORS\nHenri Hakkinen\n.br\nArun Prakash Jana <engineerarun@gmail.com>\n.br\nZhiming Wang <zmwangx@gmail.com>\n.SH HOME\n.I https://github.com/jarun/googler\n.SH REPORTING BUGS\n.I https://github.com/jarun/googler/issues\n.SH LICENSE\nCopyright \\(co 2008 Henri Hakkinen\n.br\nCopyright \\(co 2015-2021 Arun Prakash Jana <engineerarun@gmail.com>\n.PP\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>.\n.br\nThis is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law.\n"
        },
        {
          "name": "googler.svg",
          "type": "blob",
          "size": 21.4423828125,
          "content": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<svg width=\"512px\" height=\"128px\" viewBox=\"0 0 512 128\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n    <!-- Generator: Sketch 46.2 (44496) - http://www.bohemiancoding.com/sketch -->\n    <title>googler-light</title>\n    <desc>Created with Sketch.</desc>\n    <defs></defs>\n    <g id=\"no-background-(light)\" stroke=\"none\" stroke-width=\"1\" fill=\"none\" fill-rule=\"evenodd\">\n        <g id=\"googler-logo-(no-background-at-all)\">\n            <rect id=\"Bounds\" x=\"0\" y=\"0\" width=\"512\" height=\"128\"></rect>\n            <g id=\"$-googler\" transform=\"translate(34.000000, 29.000000)\">\n                <rect id=\"cursor\" fill=\"#93A1A1\" x=\"430.5\" y=\"0\" width=\"17.0100002\" height=\"56.1300011\"></rect>\n                <g id=\"googler\" transform=\"translate(65.000000, 1.000000)\">\n                    <path d=\"M30.21875,32.9765625 C30.21875,31.0494695 29.9192738,29.3307367 29.3203125,27.8203125 C28.7213512,26.3098883 27.8880262,25.0403697 26.8203125,24.0117188 C25.7525988,22.9830678 24.4830803,22.1953152 23.0117188,21.6484375 C21.5403572,21.1015598 19.9453211,20.828125 18.2265625,20.828125 C16.4557203,20.828125 14.8802152,21.1276012 13.5,21.7265625 C12.1197848,22.3255238 10.9609422,23.1653592 10.0234375,24.2460938 C9.08593281,25.3268283 8.36979414,26.6093676 7.875,28.09375 C7.38020586,29.5781324 7.1328125,31.2057203 7.1328125,32.9765625 C7.1328125,34.7474047 7.38020586,36.3749926 7.875,37.859375 C8.36979414,39.3437574 9.08593281,40.6262967 10.0234375,41.7070312 C10.9609422,42.7877658 12.1197848,43.6276012 13.5,44.2265625 C14.8802152,44.8255238 16.4557203,45.125 18.2265625,45.125 C19.9453211,45.125 21.5403572,44.8515652 23.0117188,44.3046875 C24.4830803,43.7578098 25.7525988,42.9700572 26.8203125,41.9414062 C27.8880262,40.9127553 28.7213512,39.6432367 29.3203125,38.1328125 C29.9192738,36.6223883 30.21875,34.9036555 30.21875,32.9765625 Z M8.4609375,60.2421875 C10.2578215,60.9973996 12.1458234,61.5507795 14.125,61.9023438 C16.1041766,62.253908 18.0442613,62.4296875 19.9453125,62.4296875 C21.6901129,62.4296875 23.2070248,62.2018252 24.4960938,61.7460938 C25.7851627,61.2903623 26.8528604,60.6393271 27.6992188,59.7929688 C28.5455771,58.9466104 29.1770813,57.9375059 29.59375,56.765625 C30.0104187,55.5937441 30.21875,54.2916738 30.21875,52.859375 L30.21875,44.8125 C28.6562422,46.7656348 26.8528748,48.269526 24.8085938,49.3242188 C22.7643127,50.3789115 20.4401172,50.90625 17.8359375,50.90625 C15.4140504,50.90625 13.1744895,50.4960979 11.1171875,49.6757812 C9.05988555,48.8554646 7.28255957,47.677091 5.78515625,46.140625 C4.28775293,44.604159 3.1093793,42.7291777 2.25,40.515625 C1.3906207,38.3020723 0.9609375,35.7890766 0.9609375,32.9765625 C0.9609375,30.1640484 1.3906207,27.6510527 2.25,25.4375 C3.1093793,23.2239473 4.28775293,21.348966 5.78515625,19.8125 C7.28255957,18.276034 9.05988555,17.0976604 11.1171875,16.2773438 C13.1744895,15.4570271 15.4140504,15.046875 17.8359375,15.046875 C20.4401172,15.046875 22.8163955,15.6262963 24.9648438,16.7851562 C27.113292,17.9440162 28.9947836,19.5781145 30.609375,21.6875 L30.609375,18.5625 C30.609375,17.5729117 30.7981752,16.8828145 31.1757812,16.4921875 C31.5533873,16.1015605 32.1848914,15.90625 33.0703125,15.90625 L39.28125,15.90625 C40.1666711,15.90625 40.7981752,16.1015605 41.1757812,16.4921875 C41.5533873,16.8828145 41.7421875,17.5729117 41.7421875,18.5625 C41.7421875,19.5520883 41.5533873,20.2421855 41.1757812,20.6328125 C40.7981752,21.0234395 40.1666711,21.21875 39.28125,21.21875 L36.078125,21.21875 L36.078125,53.3671875 C36.078125,55.7109492 35.7200557,57.8007721 35.0039062,59.6367188 C34.2877568,61.4726654 33.2395902,63.0221291 31.859375,64.2851562 C30.4791598,65.5481834 28.7864684,66.5182258 26.78125,67.1953125 C24.7760316,67.8723992 22.4974086,68.2109375 19.9453125,68.2109375 C17.6796762,68.2109375 15.4010531,68.015627 13.109375,67.625 C10.8176969,67.234373 8.64323945,66.6484414 6.5859375,65.8671875 C5.88280898,65.5807277 5.42057402,65.1510445 5.19921875,64.578125 C4.97786348,64.0052055 5.03645664,63.2239633 5.375,62.234375 C5.71354336,61.2447867 6.14973691,60.5937516 6.68359375,60.28125 C7.21745059,59.9687484 7.80989258,59.9557277 8.4609375,60.2421875 Z\" id=\"g\" fill=\"#4285F4\"></path>\n                    <path d=\"M48.6875,33.953125 C48.6875,31.1926945 49.1757764,28.6601678 50.1523438,26.3554688 C51.1289111,24.0507697 52.4765539,22.0586021 54.1953125,20.3789062 C55.9140711,18.6992104 57.9518111,17.3906297 60.3085938,16.453125 C62.6653764,15.5156203 65.2239445,15.046875 67.984375,15.046875 C70.7448055,15.046875 73.3033736,15.5156203 75.6601562,16.453125 C78.0169389,17.3906297 80.0546789,18.6992104 81.7734375,20.3789062 C83.4921961,22.0586021 84.8398389,24.0507697 85.8164062,26.3554688 C86.7929736,28.6601678 87.28125,31.1926945 87.28125,33.953125 C87.28125,36.7135555 86.7929736,39.2460822 85.8164062,41.5507812 C84.8398389,43.8554803 83.4921961,45.8476479 81.7734375,47.5273438 C80.0546789,49.2070396 78.0169389,50.5156203 75.6601562,51.453125 C73.3033736,52.3906297 70.7448055,52.859375 67.984375,52.859375 C65.2239445,52.859375 62.6653764,52.3906297 60.3085938,51.453125 C57.9518111,50.5156203 55.9140711,49.2070396 54.1953125,47.5273438 C52.4765539,45.8476479 51.1289111,43.8554803 50.1523438,41.5507812 C49.1757764,39.2460822 48.6875,36.7135555 48.6875,33.953125 Z M54.859375,33.953125 C54.859375,35.8541762 55.1783822,37.6054607 55.8164062,39.2070312 C56.4544303,40.8086018 57.3463484,42.1953066 58.4921875,43.3671875 C59.6380266,44.5390684 61.0182211,45.4505176 62.6328125,46.1015625 C64.2474039,46.7526074 66.0312402,47.078125 67.984375,47.078125 C69.9375098,47.078125 71.7213461,46.7526074 73.3359375,46.1015625 C74.9505289,45.4505176 76.3307234,44.5390684 77.4765625,43.3671875 C78.6224016,42.1953066 79.5143197,40.8086018 80.1523438,39.2070312 C80.7903678,37.6054607 81.109375,35.8541762 81.109375,33.953125 C81.109375,32.0520738 80.7903678,30.3007893 80.1523438,28.6992188 C79.5143197,27.0976482 78.6224016,25.7109434 77.4765625,24.5390625 C76.3307234,23.3671816 74.9505289,22.4557324 73.3359375,21.8046875 C71.7213461,21.1536426 69.9375098,20.828125 67.984375,20.828125 C66.0312402,20.828125 64.2474039,21.1536426 62.6328125,21.8046875 C61.0182211,22.4557324 59.6380266,23.3671816 58.4921875,24.5390625 C57.3463484,25.7109434 56.4544303,27.0976482 55.8164062,28.6992188 C55.1783822,30.3007893 54.859375,32.0520738 54.859375,33.953125 Z\" id=\"o\" fill=\"#EA4335\"></path>\n                    <path d=\"M96.6875,33.953125 C96.6875,31.1926945 97.1757764,28.6601678 98.1523438,26.3554688 C99.1289111,24.0507697 100.476554,22.0586021 102.195312,20.3789062 C103.914071,18.6992104 105.951811,17.3906297 108.308594,16.453125 C110.665376,15.5156203 113.223945,15.046875 115.984375,15.046875 C118.744805,15.046875 121.303374,15.5156203 123.660156,16.453125 C126.016939,17.3906297 128.054679,18.6992104 129.773438,20.3789062 C131.492196,22.0586021 132.839839,24.0507697 133.816406,26.3554688 C134.792974,28.6601678 135.28125,31.1926945 135.28125,33.953125 C135.28125,36.7135555 134.792974,39.2460822 133.816406,41.5507812 C132.839839,43.8554803 131.492196,45.8476479 129.773438,47.5273438 C128.054679,49.2070396 126.016939,50.5156203 123.660156,51.453125 C121.303374,52.3906297 118.744805,52.859375 115.984375,52.859375 C113.223945,52.859375 110.665376,52.3906297 108.308594,51.453125 C105.951811,50.5156203 103.914071,49.2070396 102.195312,47.5273438 C100.476554,45.8476479 99.1289111,43.8554803 98.1523438,41.5507812 C97.1757764,39.2460822 96.6875,36.7135555 96.6875,33.953125 Z M102.859375,33.953125 C102.859375,35.8541762 103.178382,37.6054607 103.816406,39.2070312 C104.45443,40.8086018 105.346348,42.1953066 106.492188,43.3671875 C107.638027,44.5390684 109.018221,45.4505176 110.632812,46.1015625 C112.247404,46.7526074 114.03124,47.078125 115.984375,47.078125 C117.93751,47.078125 119.721346,46.7526074 121.335938,46.1015625 C122.950529,45.4505176 124.330723,44.5390684 125.476562,43.3671875 C126.622402,42.1953066 127.51432,40.8086018 128.152344,39.2070312 C128.790368,37.6054607 129.109375,35.8541762 129.109375,33.953125 C129.109375,32.0520738 128.790368,30.3007893 128.152344,28.6992188 C127.51432,27.0976482 126.622402,25.7109434 125.476562,24.5390625 C124.330723,23.3671816 122.950529,22.4557324 121.335938,21.8046875 C119.721346,21.1536426 117.93751,20.828125 115.984375,20.828125 C114.03124,20.828125 112.247404,21.1536426 110.632812,21.8046875 C109.018221,22.4557324 107.638027,23.3671816 106.492188,24.5390625 C105.346348,25.7109434 104.45443,27.0976482 103.816406,28.6992188 C103.178382,30.3007893 102.859375,32.0520738 102.859375,33.953125 Z\" id=\"o\" fill=\"#FBBC05\"></path>\n                    <path d=\"M174.21875,32.9765625 C174.21875,31.0494695 173.919274,29.3307367 173.320312,27.8203125 C172.721351,26.3098883 171.888026,25.0403697 170.820312,24.0117188 C169.752599,22.9830678 168.48308,22.1953152 167.011719,21.6484375 C165.540357,21.1015598 163.945321,20.828125 162.226562,20.828125 C160.45572,20.828125 158.880215,21.1276012 157.5,21.7265625 C156.119785,22.3255238 154.960942,23.1653592 154.023438,24.2460938 C153.085933,25.3268283 152.369794,26.6093676 151.875,28.09375 C151.380206,29.5781324 151.132812,31.2057203 151.132812,32.9765625 C151.132812,34.7474047 151.380206,36.3749926 151.875,37.859375 C152.369794,39.3437574 153.085933,40.6262967 154.023438,41.7070312 C154.960942,42.7877658 156.119785,43.6276012 157.5,44.2265625 C158.880215,44.8255238 160.45572,45.125 162.226562,45.125 C163.945321,45.125 165.540357,44.8515652 167.011719,44.3046875 C168.48308,43.7578098 169.752599,42.9700572 170.820312,41.9414062 C171.888026,40.9127553 172.721351,39.6432367 173.320312,38.1328125 C173.919274,36.6223883 174.21875,34.9036555 174.21875,32.9765625 Z M152.460938,60.2421875 C154.257821,60.9973996 156.145823,61.5507795 158.125,61.9023438 C160.104177,62.253908 162.044261,62.4296875 163.945312,62.4296875 C165.690113,62.4296875 167.207025,62.2018252 168.496094,61.7460938 C169.785163,61.2903623 170.85286,60.6393271 171.699219,59.7929688 C172.545577,58.9466104 173.177081,57.9375059 173.59375,56.765625 C174.010419,55.5937441 174.21875,54.2916738 174.21875,52.859375 L174.21875,44.8125 C172.656242,46.7656348 170.852875,48.269526 168.808594,49.3242188 C166.764313,50.3789115 164.440117,50.90625 161.835938,50.90625 C159.41405,50.90625 157.174489,50.4960979 155.117188,49.6757812 C153.059886,48.8554646 151.28256,47.677091 149.785156,46.140625 C148.287753,44.604159 147.109379,42.7291777 146.25,40.515625 C145.390621,38.3020723 144.960938,35.7890766 144.960938,32.9765625 C144.960938,30.1640484 145.390621,27.6510527 146.25,25.4375 C147.109379,23.2239473 148.287753,21.348966 149.785156,19.8125 C151.28256,18.276034 153.059886,17.0976604 155.117188,16.2773438 C157.174489,15.4570271 159.41405,15.046875 161.835938,15.046875 C164.440117,15.046875 166.816396,15.6262963 168.964844,16.7851562 C171.113292,17.9440162 172.994784,19.5781145 174.609375,21.6875 L174.609375,18.5625 C174.609375,17.5729117 174.798175,16.8828145 175.175781,16.4921875 C175.553387,16.1015605 176.184891,15.90625 177.070312,15.90625 L183.28125,15.90625 C184.166671,15.90625 184.798175,16.1015605 185.175781,16.4921875 C185.553387,16.8828145 185.742188,17.5729117 185.742188,18.5625 C185.742188,19.5520883 185.553387,20.2421855 185.175781,20.6328125 C184.798175,21.0234395 184.166671,21.21875 183.28125,21.21875 L180.078125,21.21875 L180.078125,53.3671875 C180.078125,55.7109492 179.720056,57.8007721 179.003906,59.6367188 C178.287757,61.4726654 177.23959,63.0221291 175.859375,64.2851562 C174.47916,65.5481834 172.786468,66.5182258 170.78125,67.1953125 C168.776032,67.8723992 166.497409,68.2109375 163.945312,68.2109375 C161.679676,68.2109375 159.401053,68.015627 157.109375,67.625 C154.817697,67.234373 152.643239,66.6484414 150.585938,65.8671875 C149.882809,65.5807277 149.420574,65.1510445 149.199219,64.578125 C148.977863,64.0052055 149.036457,63.2239633 149.375,62.234375 C149.713543,61.2447867 150.149737,60.5937516 150.683594,60.28125 C151.217451,59.9687484 151.809893,59.9557277 152.460938,60.2421875 Z\" id=\"g\" fill=\"#4285F4\"></path>\n                    <path d=\"M209.601562,6.0625 L198.9375,6.0625 C198.052079,6.0625 197.420575,5.86718945 197.042969,5.4765625 C196.665363,5.08593555 196.476562,4.39583828 196.476562,3.40625 C196.476562,2.41666172 196.665363,1.72656445 197.042969,1.3359375 C197.420575,0.945310547 198.052079,0.75 198.9375,0.75 L213,0.75 C213.885421,0.75 214.516925,0.945310547 214.894531,1.3359375 C215.272137,1.72656445 215.460938,2.41666172 215.460938,3.40625 L215.460938,46.6875 L228,46.6875 C228.885421,46.6875 229.516925,46.8828105 229.894531,47.2734375 C230.272137,47.6640645 230.460938,48.3541617 230.460938,49.34375 C230.460938,50.3333383 230.272137,51.0234355 229.894531,51.4140625 C229.516925,51.8046895 228.885421,52 228,52 L197.375,52 C196.489579,52 195.858075,51.8046895 195.480469,51.4140625 C195.102863,51.0234355 194.914062,50.3333383 194.914062,49.34375 C194.914062,48.3541617 195.102863,47.6640645 195.480469,47.2734375 C195.858075,46.8828105 196.489579,46.6875 197.375,46.6875 L209.601562,46.6875 L209.601562,6.0625 Z\" id=\"l\" fill=\"#34A853\"></path>\n                    <path d=\"M247.875,35.3984375 C248.083334,39.3307488 249.170563,42.2799381 251.136719,44.2460938 C253.102874,46.2122494 255.908836,47.1953125 259.554688,47.1953125 C262.184909,47.1953125 264.736967,46.8958363 267.210938,46.296875 C269.684908,45.6979137 271.820304,44.8776094 273.617188,43.8359375 C274.450525,43.3671852 275.147133,43.328123 275.707031,43.71875 C276.26693,44.109377 276.716144,44.72135 277.054688,45.5546875 C277.419273,46.388025 277.497397,47.1367154 277.289062,47.8007812 C277.080728,48.4648471 276.546879,49.018227 275.6875,49.4609375 C274.67187,49.9557316 273.545579,50.4114563 272.308594,50.828125 C271.071608,51.2447937 269.756517,51.6028631 268.363281,51.9023438 C266.970045,52.2018244 265.531257,52.4361971 264.046875,52.6054688 C262.562493,52.7747404 261.065112,52.859375 259.554688,52.859375 C256.69009,52.859375 254.151053,52.4231814 251.9375,51.5507812 C249.723947,50.6783811 247.861987,49.4283936 246.351562,47.8007812 C244.841138,46.1731689 243.688806,44.1940221 242.894531,41.8632812 C242.100256,39.5325404 241.703125,36.895848 241.703125,33.953125 C241.703125,31.1145691 242.16536,28.5299596 243.089844,26.1992188 C244.014328,23.8684779 245.296867,21.8763104 246.9375,20.2226562 C248.578133,18.5690021 250.537749,17.2929732 252.816406,16.3945312 C255.095063,15.4960893 257.601549,15.046875 260.335938,15.046875 C263.226577,15.046875 265.778635,15.4960893 267.992188,16.3945312 C270.20574,17.2929732 272.074211,18.5364504 273.597656,20.125 C275.121101,21.7135496 276.299475,23.6015516 277.132812,25.7890625 C277.96615,27.9765734 278.460937,30.3723828 278.617188,32.9765625 C278.617188,33.8619836 278.428387,34.4869773 278.050781,34.8515625 C277.673175,35.2161477 277.041671,35.3984375 276.15625,35.3984375 L247.875,35.3984375 Z M260.335938,20.7109375 C257.080713,20.7109375 254.417979,21.5247314 252.347656,23.1523438 C250.277333,24.7799561 248.91667,27.039048 248.265625,29.9296875 L272.132812,29.9296875 C271.585935,26.9869645 270.348968,24.7148518 268.421875,23.1132812 C266.494782,21.5117107 263.799496,20.7109375 260.335938,20.7109375 Z\" id=\"e\" fill=\"#EA4335\"></path>\n                    <path d=\"M298.335938,21.21875 L293.375,21.21875 C292.489579,21.21875 291.858075,21.0234395 291.480469,20.6328125 C291.102863,20.2421855 290.914062,19.5520883 290.914062,18.5625 C290.914062,17.5729117 291.102863,16.8828145 291.480469,16.4921875 C291.858075,16.1015605 292.489579,15.90625 293.375,15.90625 L301.34375,15.90625 C302.229171,15.90625 302.860675,16.1015605 303.238281,16.4921875 C303.615887,16.8828145 303.804688,17.5729117 303.804688,18.5625 L303.804688,26.453125 C304.768234,24.7083246 305.868483,23.1328195 307.105469,21.7265625 C308.342454,20.3203055 309.664055,19.1224008 311.070312,18.1328125 C312.47657,17.1432242 313.934888,16.3815131 315.445312,15.8476562 C316.955737,15.3137994 318.453118,15.046875 319.9375,15.046875 C321.96876,15.046875 323.869783,15.5677031 325.640625,16.609375 C326.395837,17.0520855 326.877603,17.5989551 327.085938,18.25 C327.294272,18.9010449 327.216148,19.7083285 326.851562,20.671875 C326.486977,21.6093797 326.024742,22.2734355 325.464844,22.6640625 C324.904945,23.0546895 324.2474,23.028648 323.492188,22.5859375 C322.190098,21.882809 320.822924,21.53125 319.390625,21.53125 C318.218744,21.53125 317.02735,21.7460916 315.816406,22.1757812 C314.605463,22.6054709 313.433599,23.2044232 312.300781,23.9726562 C311.167963,24.7408893 310.113286,25.6653592 309.136719,26.7460937 C308.160151,27.8268283 307.300785,29.0182227 306.558594,30.3203125 C305.816403,31.6224023 305.236981,33.0156176 304.820312,34.5 C304.403644,35.9843824 304.195312,37.5208254 304.195312,39.109375 L304.195312,46.6875 L317.359375,46.6875 C318.244796,46.6875 318.8763,46.8828105 319.253906,47.2734375 C319.631512,47.6640645 319.820312,48.3541617 319.820312,49.34375 C319.820312,50.3333383 319.631512,51.0234355 319.253906,51.4140625 C318.8763,51.8046895 318.244796,52 317.359375,52 L292.203125,52 C291.317704,52 290.6862,51.8046895 290.308594,51.4140625 C289.930988,51.0234355 289.742188,50.3333383 289.742188,49.34375 C289.742188,48.3541617 289.930988,47.6640645 290.308594,47.2734375 C290.6862,46.8828105 291.317704,46.6875 292.203125,46.6875 L298.335938,46.6875 L298.335938,21.21875 Z\" id=\"r\" fill=\"#93A1A1\"></path>\n                </g>\n                <path d=\"M19.4921875,26.125 C20.8724027,26.2812508 22.2395766,26.4830717 23.59375,26.7304688 C24.9479234,26.9778658 26.2239523,27.3229145 27.421875,27.765625 C28.3854215,28.1302102 29.2708293,28.5664037 30.078125,29.0742188 C30.8854207,29.5820338 31.5820283,30.1940068 32.1679688,30.9101562 C32.7539092,31.6263057 33.2096338,32.4596307 33.5351562,33.4101562 C33.8606787,34.3606818 34.0234375,35.4609313 34.0234375,36.7109375 C34.0234375,38.4296961 33.7044303,39.9921805 33.0664062,41.3984375 C32.4283822,42.8046945 31.4908916,44.0156199 30.2539062,45.03125 C29.0169209,46.0468801 27.500009,46.8476533 25.703125,47.4335938 C23.906241,48.0195342 21.8359492,48.3385414 19.4921875,48.390625 L19.4921875,55.34375 C19.4921875,56.2552129 19.2773459,56.906248 18.8476562,57.296875 C18.4179666,57.687502 17.721359,57.8828125 16.7578125,57.8828125 C15.794266,57.8828125 15.0976584,57.687502 14.6679688,57.296875 C14.2382791,56.906248 14.0234375,56.2552129 14.0234375,55.34375 L14.0234375,47.9609375 C12.3567625,47.6223941 10.8528713,47.0950557 9.51171875,46.3789062 C8.17056621,45.6627568 6.95313047,44.757818 5.859375,43.6640625 L5.859375,45.8515625 C5.859375,46.7630254 5.6445334,47.4140605 5.21484375,47.8046875 C4.7851541,48.1953145 4.02344297,48.390625 2.9296875,48.390625 C1.83593203,48.390625 1.0742209,48.1953145 0.64453125,47.8046875 C0.214841602,47.4140605 0,46.7630254 0,45.8515625 L0,36.4765625 C0,35.5650996 0.214841602,34.9140645 0.64453125,34.5234375 C1.0742209,34.1328105 1.83593203,33.9375 2.9296875,33.9375 C3.50260703,33.9375 3.94531094,34.067707 4.2578125,34.328125 C4.57031406,34.588543 4.83072813,34.9921848 5.0390625,35.5390625 C5.79427461,37.4921973 6.90103438,39.0286402 8.359375,40.1484375 C9.81771563,41.2682348 11.7057176,42.0234355 14.0234375,42.4140625 L14.0234375,31.515625 C12.6171805,31.3333324 11.256517,31.1119805 9.94140625,30.8515625 C8.62629551,30.5911445 7.38281836,30.2265648 6.2109375,29.7578125 C5.32551641,29.4192691 4.51823281,29.0026066 3.7890625,28.5078125 C3.05989219,28.0130184 2.42838809,27.4270867 1.89453125,26.75 C1.36067441,26.0729133 0.944011914,25.2916711 0.64453125,24.40625 C0.345050586,23.5208289 0.1953125,22.5052141 0.1953125,21.359375 C0.1953125,19.6145746 0.546871484,18.0716213 1.25,16.7304688 C1.95312852,15.3893162 2.9231709,14.2630254 4.16015625,13.3515625 C5.3971416,12.4400996 6.85546035,11.7500023 8.53515625,11.28125 C10.2148521,10.8124977 12.0442609,10.578125 14.0234375,10.578125 L14.0234375,4.2890625 C14.0234375,3.37759961 14.2382791,2.72656445 14.6679688,2.3359375 C15.0976584,1.94531055 15.794266,1.75 16.7578125,1.75 C17.721359,1.75 18.4179666,1.94531055 18.8476562,2.3359375 C19.2773459,2.72656445 19.4921875,3.37759961 19.4921875,4.2890625 L19.4921875,11.0859375 C20.8724027,11.4505227 22.1354109,11.9648404 23.28125,12.6289062 C24.4270891,13.2929721 25.4557246,14.0416625 26.3671875,14.875 L26.3671875,13.1171875 C26.3671875,12.2057246 26.5820291,11.5546895 27.0117188,11.1640625 C27.4414084,10.7734355 28.2031195,10.578125 29.296875,10.578125 C30.3906305,10.578125 31.1523416,10.7734355 31.5820312,11.1640625 C32.0117209,11.5546895 32.2265625,12.2057246 32.2265625,13.1171875 L32.2265625,20.5390625 C32.2265625,21.4505254 32.0117209,22.1015605 31.5820312,22.4921875 C31.1523416,22.8828145 30.3906305,23.078125 29.296875,23.078125 C28.4114539,23.078125 27.7864602,22.7395867 27.421875,22.0625 C26.5885375,20.4739504 25.5078191,19.2304732 24.1796875,18.3320312 C22.8515559,17.4335893 21.2890715,16.8151059 19.4921875,16.4765625 L19.4921875,26.125 Z M19.4921875,42.7265625 C22.2786598,42.5963535 24.3684826,41.9843805 25.7617188,40.890625 C27.1549549,39.7968695 27.8515625,38.4036543 27.8515625,36.7109375 C27.8515625,35.7734328 27.5520863,35.0247424 26.953125,34.4648438 C26.3541637,33.9049451 25.5468801,33.4557309 24.53125,33.1171875 C23.8281215,32.8828113 23.0533896,32.6940111 22.2070312,32.5507812 C21.3606729,32.4075514 20.455734,32.270834 19.4921875,32.140625 L19.4921875,42.7265625 Z M14.0234375,16.2421875 C11.6015504,16.2942711 9.72005879,16.7630164 8.37890625,17.6484375 C7.03775371,18.5338586 6.3671875,19.7708254 6.3671875,21.359375 C6.3671875,22.2187543 6.64713262,22.9088516 7.20703125,23.4296875 C7.76692988,23.9505234 8.54166172,24.3671859 9.53125,24.6796875 C10.1562531,24.8880219 10.8463504,25.057291 11.6015625,25.1875 C12.3567746,25.317709 13.1640582,25.447916 14.0234375,25.578125 L14.0234375,16.2421875 Z\" id=\"$\" fill=\"#93A1A1\"></path>\n            </g>\n        </g>\n    </g>\n</svg>"
        },
        {
          "name": "info.json",
          "type": "blob",
          "size": 0.115234375,
          "content": "{\n    \"epoch\": \"20210115\",\n    \"tracking_issue\": 392,\n    \"fixed_on_master\": true,\n    \"fixed_in_release\": \"v4.3.2\"\n}\n"
        },
        {
          "name": "packagecore.yaml",
          "type": "blob",
          "size": 1.3076171875,
          "content": "name: googler\nmaintainer: Arun Prakash Jana <engineerarun@gmail.com>\nlicense: GPLv3\nsummary: Google from the command-line.\nhomepage: https://github.com/jarun/googler\ncommands:\n  install:\n    - make PREFIX=\"/usr\" install DESTDIR=\"${BP_DESTDIR}\"\npackages:\n#  archlinux:\n#    builddeps:\n#      - make\n#    deps:\n#      - python\n  centos7.5:\n    builddeps:\n      - make\n    deps:\n      - python\n  centos7.6:\n    builddeps:\n      - make\n    deps:\n      - python\n  centos7.7:\n    builddeps:\n      - make\n    deps:\n      - python\n  centos8.0:\n    builddeps:\n      - make\n    deps:\n      - python3\n    commands:\n      precompile:\n        - dnf install python3\n  debian9:\n    builddeps:\n      - make\n    deps:\n      - python3\n  debian10:\n    builddeps:\n      - make\n    deps:\n      - python3\n  fedora31:\n    builddeps:\n      - make\n    deps:\n      - python3\n  fedora32:\n    builddeps:\n      - make\n    deps:\n      - python3\n  opensuse15.1:\n    builddeps:\n      - make\n    deps:\n      - python3\n  opensuse15.2:\n    builddeps:\n      - make\n    deps:\n      - python3\n  opensuse.tumbleweed:\n    builddeps:\n      - make\n    deps:\n      - python3\n  ubuntu16.04:\n    builddeps:\n      - make\n    deps:\n      - python3\n  ubuntu18.04:\n    builddeps:\n      - make\n    deps:\n      - python3\n  ubuntu20.04:\n    builddeps:\n      - make\n    deps:\n      - python3\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}