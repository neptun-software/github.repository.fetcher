{
  "metadata": {
    "timestamp": 1736560956085,
    "page": 703,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjcxMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "TeamWiseFlow/wiseflow",
      "stars": 5524,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.1630859375,
          "content": "# 默认忽略的文件\n/shelf/\n/workspace.xml\n.DS_Store\n.idea/\n__pycache__\n.env\n.venv/\npb/pb_data/\npb/pocketbase\ncore/docker_dir/\ncore/work_dir/\ntest/webpage_samples/"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 5.3486328125,
          "content": "# V0.3.6\n- 改用 Crawl4ai 作为底层爬虫框架，其实Crawl4ai 和 Crawlee 的获取效果差别不大，二者也都是基于 Playwright ，但 Crawl4ai 的 html2markdown 功能很实用，而这对llm 信息提取作用很大，另外 Crawl4ai 的架构也更加符合我的思路；\n- 在 Crawl4ai 的 html2markdown 基础上，增加了 deep scraper，进一步把页面的独立链接与正文进行区分，便于后一步 llm 的精准提取。由于html2markdown和deep scraper已经将原始网页数据做了很好的清理，极大降低了llm所受的干扰和误导，保证了最终结果的质量，同时也减少了不必要的 token 消耗；\n\n   *列表页面和文章页面的区分是所有爬虫类项目都头痛的地方，尤其是现代网页往往习惯在文章页面的侧边栏和底部增加大量推荐阅读，使得二者几乎不存在文本统计上的特征差异。*\n   *这一块我本来想用视觉大模型进行 layout 分析，但最终实现起来发现获取不受干扰的网页截图是一件会极大增加程序复杂度并降低处理效率的事情……*\n  \n- 重构了提取策略、llm 的 prompt 等；\n\n  *有关 prompt 我想说的是，我理解好的 prompt 是清晰的工作流指导，每一步都足够明确，明确到很难犯错。但我不太相信过于复杂的 prompt 的价值，这个很难评估，如果你有更好的方案，欢迎提供 PR*\n\n- 引入视觉大模型，自动在提取前对高权重（目前由 Crawl4ai 评估权重）图片进行识别，并补充相关信息到页面文本中；\n- 继续减少 requirement.txt 的依赖项，目前不需要 json_repair了（实践中也发现让 llm 按 json 格式生成，还是会明显增加处理时间和失败率，因此我现在采用更简单的方式，同时增加对处理结果的后处理）\n- pb info 表单的结构做了小调整，增加了 web_title 和 reference 两项。\n- @ourines 贡献了 install_pocketbase.sh 脚本 (docker运行方案被暂时移除了，感觉大家用起来也不是很方便……)\n\n\n- Switched to Crawl4ai as the underlying web crawling framework. Although Crawl4ai and Crawlee both rely on Playwright with similar fetching results, Crawl4ai's html2markdown feature is quite practical for LLM information extraction. Additionally, Crawl4ai's architecture better aligns with my design philosophy.\n- Built upon Crawl4ai's html2markdown, we added a deep scraper to further differentiate standalone links from the main content, facilitating more precise LLM extraction. The preprocessing done by html2markdown and deep scraper significantly cleans up raw web data, minimizing interference and misleading information for LLMs, ensuring higher quality outcomes while reducing unnecessary token consumption.\n\n  *Distinguishing between list pages and article pages is a common challenge in web scraping projects, especially when modern webpages often include extensive recommended readings in sidebars and footers of articles, making it difficult to differentiate them through text statistics.*\n  *Initially, I considered using large visual models for layout analysis, but found that obtaining undistorted webpage screenshots greatly increases program complexity and reduces processing efficiency...*\n\n- Restructured extraction strategies and LLM prompts;\n\n  *Regarding prompts, I believe that a good prompt serves as clear workflow guidance, with each step being explicit enough to minimize errors. However, I am skeptical about the value of overly complex prompts, which are hard to evaluate. If you have better solutions, feel free to submit a PR.*\n\n- Introduced large visual models to automatically recognize high-weight images (currently evaluated by Crawl4ai) before extraction and append relevant information to the page text;\n- Continued to reduce dependencies in requirement.txt; json_repair is no longer needed (in practice, having LLMs generate JSON format still noticeably increases processing time and failure rates, so I now adopt a simpler approach with additional post-processing of results)\n- Made minor adjustments to the pb info form structure, adding web_title and reference fields.\n- @ourines contributed the install_pocketbase.sh script (the Docker running solution has been temporarily removed as it wasn't very convenient for users...)\n\n# V0.3.5\n- 引入 Crawlee(playwrigt模块)，大幅提升通用爬取能力，适配实际项目场景；\n  \n  Introduce Crawlee (playwright module), significantly enhancing general crawling capabilities and adapting to real-world task;\n\n- 完全重写了信息提取模块，引入“爬-查一体”策略，你关注的才是你想要的；\n\n  Completely rewrote the information extraction module, introducing an \"integrated crawl-search\" strategy, focusing on what you care about;\n\n- 新策略下放弃了 gne、jieba 等模块，去除了安装包；\n\n  Under the new strategy, modules such as gne and jieba have been abandoned, reducing the installation package size;\n\n- 重写了 pocketbase 的表单结构；\n  \n  Rewrote the PocketBase form structure;\n\n- llm wrapper引入异步架构、自定义页面提取器规范优化（含 微信公众号文章提取优化）；\n\n  llm wrapper introduces asynchronous architecture, customized page extractor specifications optimization (including WeChat official account article extraction optimization);\n\n- 进一步简化部署操作步骤。\n\n  Further simplified deployment steps.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 10.1005859375,
          "content": "Apache License\n\nVersion 2.0, January 2004\n\nhttp://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION,\nAND DISTRIBUTION\n\n   1. Definitions.\n\n      \n\n\"License\" shall mean the terms and conditions for use, reproduction, and distribution\nas defined by Sections 1 through 9 of this document.\n\n      \n\n\"Licensor\" shall mean the copyright owner or entity authorized by the copyright\nowner that is granting the License.\n\n      \n\n\"Legal Entity\" shall mean the union of the acting entity and all other entities\nthat control, are controlled by, or are under common control with that entity.\nFor the purposes of this definition, \"control\" means (i) the power, direct\nor indirect, to cause the direction or management of such entity, whether\nby contract or otherwise, or (ii) ownership of fifty percent (50%) or more\nof the outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \n\n\"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions\ngranted by this License.\n\n      \n\n\"Source\" form shall mean the preferred form for making modifications, including\nbut not limited to software source code, documentation source, and configuration\nfiles.\n\n      \n\n\"Object\" form shall mean any form resulting from mechanical transformation\nor translation of a Source form, including but not limited to compiled object\ncode, generated documentation, and conversions to other media types.\n\n      \n\n\"Work\" shall mean the work of authorship, whether in Source or Object form,\nmade available under the License, as indicated by a copyright notice that\nis included in or attached to the work (an example is provided in the Appendix\nbelow).\n\n      \n\n\"Derivative Works\" shall mean any work, whether in Source or Object form,\nthat is based on (or derived from) the Work and for which the editorial revisions,\nannotations, elaborations, or other modifications represent, as a whole, an\noriginal work of authorship. For the purposes of this License, Derivative\nWorks shall not include works that remain separable from, or merely link (or\nbind by name) to the interfaces of, the Work and Derivative Works thereof.\n\n      \n\n\"Contribution\" shall mean any work of authorship, including the original version\nof the Work and any modifications or additions to that Work or Derivative\nWorks thereof, that is intentionally submitted to Licensor for inclusion in\nthe Work by the copyright owner or by an individual or Legal Entity authorized\nto submit on behalf of the copyright owner. For the purposes of this definition,\n\"submitted\" means any form of electronic, verbal, or written communication\nsent to the Licensor or its representatives, including but not limited to\ncommunication on electronic mailing lists, source code control systems, and\nissue tracking systems that are managed by, or on behalf of, the Licensor\nfor the purpose of discussing and improving the Work, but excluding communication\nthat is conspicuously marked or otherwise designated in writing by the copyright\nowner as \"Not a Contribution.\"\n\n      \n\n\"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf\nof whom a Contribution has been received by Licensor and subsequently incorporated\nwithin the Work.\n\n2. Grant of Copyright License. Subject to the terms and conditions of this\nLicense, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive,\nno-charge, royalty-free, irrevocable copyright license to reproduce, prepare\nDerivative Works of, publicly display, publicly perform, sublicense, and distribute\nthe Work and such Derivative Works in Source or Object form.\n\n3. Grant of Patent License. Subject to the terms and conditions of this License,\neach Contributor hereby grants to You a perpetual, worldwide, non-exclusive,\nno-charge, royalty-free, irrevocable (except as stated in this section) patent\nlicense to make, have made, use, offer to sell, sell, import, and otherwise\ntransfer the Work, where such license applies only to those patent claims\nlicensable by such Contributor that are necessarily infringed by their Contribution(s)\nalone or by combination of their Contribution(s) with the Work to which such\nContribution(s) was submitted. If You institute patent litigation against\nany entity (including a cross-claim or counterclaim in a lawsuit) alleging\nthat the Work or a Contribution incorporated within the Work constitutes direct\nor contributory patent infringement, then any patent licenses granted to You\nunder this License for that Work shall terminate as of the date such litigation\nis filed.\n\n4. Redistribution. You may reproduce and distribute copies of the Work or\nDerivative Works thereof in any medium, with or without modifications, and\nin Source or Object form, provided that You meet the following conditions:\n\n(a) You must give any other recipients of the Work or Derivative Works a copy\nof this License; and\n\n(b) You must cause any modified files to carry prominent notices stating that\nYou changed the files; and\n\n(c) You must retain, in the Source form of any Derivative Works that You distribute,\nall copyright, patent, trademark, and attribution notices from the Source\nform of the Work, excluding those notices that do not pertain to any part\nof the Derivative Works; and\n\n(d) If the Work includes a \"NOTICE\" text file as part of its distribution,\nthen any Derivative Works that You distribute must include a readable copy\nof the attribution notices contained within such NOTICE file, excluding those\nnotices that do not pertain to any part of the Derivative Works, in at least\none of the following places: within a NOTICE text file distributed as part\nof the Derivative Works; within the Source form or documentation, if provided\nalong with the Derivative Works; or, within a display generated by the Derivative\nWorks, if and wherever such third-party notices normally appear. The contents\nof the NOTICE file are for informational purposes only and do not modify the\nLicense. You may add Your own attribution notices within Derivative Works\nthat You distribute, alongside or as an addendum to the NOTICE text from the\nWork, provided that such additional attribution notices cannot be construed\nas modifying the License.\n\nYou may add Your own copyright statement to Your modifications and may provide\nadditional or different license terms and conditions for use, reproduction,\nor distribution of Your modifications, or for any such Derivative Works as\na whole, provided Your use, reproduction, and distribution of the Work otherwise\ncomplies with the conditions stated in this License.\n\n5. Submission of Contributions. Unless You explicitly state otherwise, any\nContribution intentionally submitted for inclusion in the Work by You to the\nLicensor shall be under the terms and conditions of this License, without\nany additional terms or conditions. Notwithstanding the above, nothing herein\nshall supersede or modify the terms of any separate license agreement you\nmay have executed with Licensor regarding such Contributions.\n\n6. Trademarks. This License does not grant permission to use the trade names,\ntrademarks, service marks, or product names of the Licensor, except as required\nfor reasonable and customary use in describing the origin of the Work and\nreproducing the content of the NOTICE file.\n\n7. Disclaimer of Warranty. Unless required by applicable law or agreed to\nin writing, Licensor provides the Work (and each Contributor provides its\nContributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\nKIND, either express or implied, including, without limitation, any warranties\nor conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR\nA PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness\nof using or redistributing the Work and assume any risks associated with Your\nexercise of permissions under this License.\n\n8. Limitation of Liability. In no event and under no legal theory, whether\nin tort (including negligence), contract, or otherwise, unless required by\napplicable law (such as deliberate and grossly negligent acts) or agreed to\nin writing, shall any Contributor be liable to You for damages, including\nany direct, indirect, special, incidental, or consequential damages of any\ncharacter arising as a result of this License or out of the use or inability\nto use the Work (including but not limited to damages for loss of goodwill,\nwork stoppage, computer failure or malfunction, or any and all other commercial\ndamages or losses), even if such Contributor has been advised of the possibility\nof such damages.\n\n9. Accepting Warranty or Additional Liability. While redistributing the Work\nor Derivative Works thereof, You may choose to offer, and charge a fee for,\nacceptance of support, warranty, indemnity, or other liability obligations\nand/or rights consistent with this License. However, in accepting such obligations,\nYou may act only on Your own behalf and on Your sole responsibility, not on\nbehalf of any other Contributor, and only if You agree to indemnify, defend,\nand hold each Contributor harmless for any liability incurred by, or claims\nasserted against, such Contributor by reason of your accepting any such warranty\nor additional liability. END OF TERMS AND CONDITIONS\n\nAPPENDIX: How to apply the Apache License to your work.\n\nTo apply the Apache License to your work, attach the following boilerplate\nnotice, with the fields enclosed by brackets \"[]\" replaced with your own identifying\ninformation. (Don't include the brackets!) The text should be enclosed in\nthe appropriate comment syntax for the file format. We also recommend that\na file or class name and description of purpose be included on the same \"printed\npage\" as the copyright notice for easier identification within third-party\narchives.\n\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\n\nyou may not use this file except in compliance with the License.\n\nYou may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\n\ndistributed under the License is distributed on an \"AS IS\" BASIS,\n\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\nSee the License for the specific language governing permissions and\n\nlimitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 14.5732421875,
          "content": "# 首席情报官（Wiseflow）\n\n**[English](README_EN.md) | [日本語](README_JP.md) | [한국어](README_KR.md)**\n\n🚀 **首席情报官**（Wiseflow）是一个敏捷的信息挖掘工具，可以从各种给定信源中依靠大模型的思考与分析能力精准抓取特定信息，全程无需人工参与。\n\n**我们缺的不是信息，而是从海量信息中过滤噪音，从而让有价值的信息显露出来**\n\n🌱看看AI情报官是如何帮您节省时间，过滤无关信息，并整理关注要点的吧！🌱\n\nhttps://github.com/user-attachments/assets/fc328977-2366-4271-9909-a89d9e34a07b\n\n## 🔥 虽迟但到, V0.3.6来了\n\nV0.3.6 是 V0.3.5的效果改进版本，针对诸多社区反馈进行了改进，建议所有用户升级。\n\n  - 改用 Crawl4ai 作为底层爬虫框架，其实Crawl4ai 和 Crawlee 的获取效果差别不大，二者也都是基于 Playwright ，但 Crawl4ai 的 html2markdown 功能很实用，而这对llm 信息提取作用很大，另外 Crawl4ai 的架构也更加符合我的思路；\n  - 在 Crawl4ai 的 html2markdown 基础上，增加了 deep scraper，进一步把页面的独立链接与正文进行区分，便于后一步 llm 的精准提取。由于html2markdown和deep scraper已经将原始网页数据做了很好的清理，极大降低了llm所受的干扰和误导，保证了最终结果的质量，同时也减少了不必要的 token 消耗；\n\n     *列表页面和文章页面的区分是所有爬虫类项目都头痛的地方，尤其是现代网页往往习惯在文章页面的侧边栏和底部增加大量推荐阅读，使得二者几乎不存在文本统计上的特征差异。*\n     *这一块我本来想用视觉大模型进行 layout 分析，但最终实现起来发现获取不受干扰的网页截图是一件会极大增加程序复杂度并降低处理效率的事情……*\n  \n  - 重构了提取策略、llm 的 prompt 等；\n\n    *有关 prompt 我想说的是，我理解好的 prompt 是清晰的工作流指导，每一步都足够明确，明确到很难犯错。但我不太相信过于复杂的 prompt 的价值，这个很难评估，如果你有更好的方案，欢迎提供 PR*\n\n  - 引入视觉大模型，自动在提取前对高权重（目前由 Crawl4ai 评估权重）图片进行识别，并补充相关信息到页面文本中；\n  - 继续减少 requirement.txt 的依赖项，目前不需要 json_repair了（实践中也发现让 llm 按 json 格式生成，还是会明显增加处理时间和失败率，因此我现在采用更简单的方式，同时增加对处理结果的后处理）\n  - pb info 表单的结构做了小调整，增加了 web_title 和 reference 两项。\n  - @ourines 贡献了 install_pocketbase.sh 脚本 (docker运行方案被暂时移除了，感觉大家用起来也不是很方便……)\n  - @ibaoger 贡献了 windows 下的pocketbase 安装脚本\n  - @tusik 贡献了异步 llm wrapper\n\n**升级V0.3.6 版本依然需要重构 pocketbase 数据库，请删除pb/pb_data 文件夹后重新执行**\n\n**V0.3.6版本 .env 中需要把SECONDARY_MODEL替换为VL_MODEL，请参考最新的 [env_sample](./env_sample)**\n  \n### V0.3.6 测试报告\n\n我们在四个现实案例任务以及共计六个真实网页 sample 中横向测试并比较了由 siliconflow 提供的deepseekV2.5、Qwen2.5-32B-Instruct、Qwen2.5-14B-Instruct、Qwen2.5-72B-Instruct 模型的表现情况，\n测试结果请参考 [report](./test/reports/wiseflow_report_v036_bigbrother666/README.md)\n\n同时我们也将测试脚本进行开源，欢迎大家踊跃提交更多测试结果，wiseflow 是一个开源项目，希望通过大家共同的贡献，打造“人人可用的信息爬取工具”！\n\n具体请参考 [test/README.md](./test/README.md) \n\n现阶段，**提交测试结果等同于提交项目代码**，同样会被接纳为contributor，甚至受邀参加商业化项目！\n\n\n🌟**V0.3.x 计划**\n\n- 尝试支持微信公众号免wxbot订阅（V0.3.7）；\n- 引入对 RSS 信息源和搜索引擎的支持（V0.3.8）;\n- 尝试部分支持社交平台（V0.3.9）。\n\n伴随着上述三个版本，我会持续改进 deep scraper 以及 llm 提取策略，也欢迎大家持续反馈应用场景和抽取效果不理想的信源地址，欢迎在 [issue #136](https://github.com/TeamWiseFlow/wiseflow/issues/136) 中进行反馈。\n\n\n## ✋ wiseflow 与传统的爬虫工具、AI搜索、知识库（RAG）项目有何不同？\n\nwiseflow自2024年6月底发布 V0.3.0版本来受到了开源社区的广泛关注，甚至吸引了不少自媒体的主动报道，在此首先表示感谢！\n\n但我们也注意到部分关注者对 wiseflow 的功能定位存在一些理解偏差，如下表格通过与传统爬虫工具、AI搜索、知识库（RAG）类项目的对比，代表了我们目前对于 wiseflow 产品最新定位思考。\n\n|          | 与 **首席情报官（Wiseflow）** 的比较说明| \n|-------------|-----------------|\n| **爬虫类工具** | 首先 wiseflow 是基于爬虫工具的项目，但传统的爬虫工具在信息提取方面需要人工的提供明确的 Xpath 等信息……这不仅阻挡了普通用户，同时也毫无通用性可言，对于不同网站（包括已有网站升级后）都需要人工重做分析，更新程序。wiseflow致力于使用 LLM 自动化网页的分析和提取工作，用户只要告诉程序他的关注点即可。 如果以 Crawl4ai 为例对比说明，Crawl4ai 是会使用 llm 进行信息提取的爬虫，而wiseflow 则是会使用爬虫工具的llm信息提取器。|\n| **AI搜索** |  AI搜索主要的应用场景是**具体问题的即时问答**，举例：”XX公司的创始人是谁“、“xx品牌下的xx产品哪里有售” ，用户要的是**一个答案**；wiseflow主要的应用场景是**某一方面信息的持续采集**，比如XX公司的关联信息追踪，XX品牌市场行为的持续追踪……在这些场景下，用户能提供关注点（某公司、某品牌）、甚至能提供信源（站点 url 等），但无法提出具体搜索问题，用户要的是**一系列相关信息**| \n| **知识库（RAG）类项目** | 知识库（RAG）类项目一般是基于已有信息的下游任务，并且一般面向的是私有知识（比如企业内的操作手册、产品手册、政府部门的文件等）；wiseflow 目前并未整合下游任务，同时面向的是互联网上的公开信息，如果从“智能体”的角度来看，二者属于为不同目的而构建的智能体，RAG 类项目是“（内部）知识助理智能体”，而 wiseflow 则是“（外部）信息采集智能体”|\n\n**wiseflow 0.4.x 版本将关注下游任务的集成， 引入 LLM 驱动的轻量级知识图谱，帮助用户从 infos 中建立洞察。**\n\n## 📥 安装与使用\n\n### 1. 克隆代码仓库\n\n🌹 点赞、fork是好习惯 🌹\n\n**windows 用户请提前下载 git bash 工具，并在 bash 中执行如下命令** [bash下载链接](https://git-scm.com/downloads/win)\n\n```bash\ngit clone https://github.com/TeamWiseFlow/wiseflow.git\n```\n\n### 2. 执行根目录下的 install_pocketbase 脚本\n\nlinux/macos 用户请执行 \n\n```bash\nchmod +x install_pocketbase\n./install_pocketbase\n```\n\n**windows 用户请执行 [install_pocketbase.ps1](./install_pocketbase.ps1) 脚本**\n\nwiseflow 0.3.x版本使用 pocketbase 作为数据库，你当然也可以手动下载 pocketbase 客户端 (记得下载0.23.4版本，并放入 [pb](./pb) 目录下) 以及手动完成superuser的创建(记得存入.env文件)\n\n具体可以参考 [pb/README.md](/pb/README.md)\n\n### 3. 继续配置 core/.env 文件\n\n🌟 **这里与之前版本不同**，V0.3.5开始需要把 .env 放置在 [core](./core) 文件夹中。\n\n#### 3.1 大模型相关配置\n\nwiseflow 是 LLM 原生应用，请务必保证为程序提供稳定的 LLM 服务。\n\n🌟 **wiseflow 并不限定模型服务提供来源，只要服务兼容 openAI SDK 即可，包括本地部署的 ollama、Xinference 等服务**\n\n#### 推荐1：使用硅基流动（siliconflow）提供的 MaaS 服务\n\nsiliconflow（硅基流动）提供大部分主流开源模型的在线 MaaS 服务，凭借着自身的加速推理技术积累，其服务速度和价格方面都有很大优势。使用 siliconflow 的服务时，.env的配置可以参考如下：\n\n```bash\nexport LLM_API_KEY=Your_API_KEY\nexport LLM_API_BASE=\"https://api.siliconflow.cn/v1\"\nexport PRIMARY_MODEL=\"Qwen/Qwen2.5-32B-Instruct\"\nexport VL_MODEL=\"OpenGVLab/InternVL2-26B\"\n```\n      \n😄 如果您愿意，可以使用我的[siliconflow邀请链接](https://cloud.siliconflow.cn?referrer=clx6wrtca00045766ahvexw92)，这样我也可以获得更多token奖励 🌹\n\n#### 推荐2：使用 AiHubMix 代理的openai、claude、gemini 等海外闭源商业模型服务\n\n如果您的信源多为非中文页面，且也不要求提取出的 info 为中文，那么更推荐您使用 openai、claude、gemini 等海外闭源商业模型。您可以尝试第三方代理 **AiHubMix**，支持国内网络环境直连、支付宝便捷支付，免去封号风险。\n使用 AiHubMix 的模型时，.env的配置可以参考如下：\n\n```bash\nexport LLM_API_KEY=Your_API_KEY\nexport LLM_API_BASE=\"https://aihubmix.com/v1\" # 具体参考 https://doc.aihubmix.com/\nexport PRIMARY_MODEL=\"gpt-4o\"\nexport VL_MODEL=\"gpt-4o\"\n```\n\n😄 欢迎使用 [AiHubMix邀请链接](https://aihubmix.com?aff=Gp54) 注册 🌹\n\n#### 本地部署大模型服务\n\n以 Xinference 为例，.env 配置可以参考如下：\n\n```bash\n# LLM_API_KEY='' 本地服务无需这一项，请注释掉或删除\nexport LLM_API_BASE='http://127.0.0.1:9997'\nexport PRIMARY_MODEL=启动的模型 ID\nexport VL_MODEL=启动的模型 ID\n```\n\n#### 3.2 pocketbase 账号密码配置\n\n```bash\nexport PB_API_AUTH=\"test@example.com|1234567890\" \n```\n\n这里pocketbase 数据库的 superuser 用户名和密码，记得用 | 分隔 (如果 install_pocketbase.sh 脚本执行成功，这一项应该已经存在了)\n\n#### 3.3 其他可选配置\n\n下面的都是可选配置：\n- #VERBOSE=\"true\" \n\n  是否开启观测模式，开启的话会把 debug 信息记录在 logger 文件上（默认仅输出在 console 上）；\n\n- #PROJECT_DIR=\"work_dir\" \n\n    项目运行数据目录，不配置的话，默认在  `core/work_dir` ，注意：目前整个 core 目录是挂载到 container 下的，所以意味着你可以直接访问这里。\n\n- #PB_API_BASE=\"\" \n\n  只有当你的 pocketbase 不运行在默认ip 或端口下才需要配置，默认情况下忽略就行。\n\n- #LLM_CONCURRENT_NUMBER=8 \n\n  用于控制 llm 的并发请求数量，不设定默认是1（开启前请确保 llm provider 支持设定的并发，本地大模型慎用，除非你对自己的硬件基础有信心）\n  \n  感谢 @tusik 贡献的异步 llm wrapper\n\n### 4. 运行程序\n\n✋ V0.3.5版本架构和依赖与之前版本有较大不同，请务必重新拉取代码，删除（或重建）pb_data\n\n推荐使用 conda 构建虚拟环境（当然你也可以忽略这一步，或者使用其他 python 虚拟环境方案）\n\n```bash\nconda create -n wiseflow python=3.10\nconda activate wiseflow\n```\n\n之后运行\n\n```bash\ncd wiseflow\ncd core\npip install -r requirements.txt\nchmod +x run.sh\n./run_task.sh # if you just want to scan sites one-time (no loop), use ./run.sh\n```\n\n🌟 这个脚本会自动判断 pocketbase 是否已经在运行，如果未运行，会自动拉起。但是请注意，当你 ctrl+c 或者 ctrl+z 终止进程时，pocketbase 进程不会被终止，直到你关闭terminal。\n\nrun_task.sh 会周期性执行爬取-提取任务（启动时会立即先执行一次，之后每隔一小时启动一次）, 如果仅需执行一次，可以使用 run.sh 脚本。\n\n### 5. **关注点和定时扫描信源添加**\n    \n启动程序后，打开pocketbase Admin dashboard UI (http://127.0.0.1:8090/_/)\n    \n#### 5.1 打开 focus_point 表单\n\n通过这个表单可以指定你的关注点，LLM会按此提炼、过滤并分类信息。\n    \n字段说明：\n- focuspoint, 关注点描述（必填），如”上海小升初信息“、”加密货币价格“\n- explanation，关注点的详细解释或具体约定，如 “仅限上海市官方发布的初中升学信息”、“BTC、ETH 的现价、涨跌幅数据“等\n- activated, 是否激活。如果关闭则会忽略该关注点，关闭后可再次开启。\n\n注意：focus_point 更新设定（包括 activated 调整）后，**需要重启程序才会生效。**\n\n#### 5.2 打开 sites表单\n\n通过这个表单可以指定自定义信源，系统会启动后台定时任务，在本地执行信源扫描、解析和分析。\n\nsites 字段说明：\n- url, 信源的url，信源无需给定具体文章页面，给文章列表页面即可。\n- per_hours, 扫描频率，单位为小时，类型为整数（1~24范围，我们建议扫描频次不要超过一天一次，即设定为24）\n- activated, 是否激活。如果关闭则会忽略该信源，关闭后可再次开启。\n\n**sites 的设定调整，无需重启程序。**\n\n\n## 📚 如何在您自己的程序中使用 wiseflow 抓取出的数据\n\n1、参考 [dashbord](dashboard) 部分源码二次开发。\n\n注意 wiseflow 的 core 部分并不需要 dashboard，目前产品也未集成 dashboard，如果您有dashboard需求，请下载 [V0.2.1版本](https://github.com/TeamWiseFlow/wiseflow/releases/tag/V0.2.1)\n\n2、直接从 Pocketbase 中获取数据\n\nwiseflow 所有抓取数据都会即时存入 pocketbase，因此您可以直接操作 pocketbase 数据库来获取数据。\n\nPocketBase作为流行的轻量级数据库，目前已有 Go/Javascript/Python 等语言的SDK。\n   - Go : https://pocketbase.io/docs/go-overview/\n   - Javascript : https://pocketbase.io/docs/js-overview/\n   - python : https://github.com/vaphes/pocketbase\n\n## 🛡️ 许可协议\n\n本项目基于 [Apache2.0](LICENSE) 开源。\n\n商用合作，请联系 **Email：zm.zhao@foxmail.com**\n\n- 商用客户请联系我们报备登记，产品承诺永远免费。\n\n\n## 📬 联系方式\n\n有任何问题或建议，欢迎通过 [issue](https://github.com/TeamWiseFlow/wiseflow/issues) 留言。\n\n\n## 🤝 本项目基于如下优秀的开源项目：\n\n- crawl4ai（Open-source LLM Friendly Web Crawler & Scraper） https://github.com/unclecode/crawl4ai\n- python-pocketbase (pocketBase client SDK for python) https://github.com/vaphes/pocketbase\n\n本项目开发受 [GNE](https://github.com/GeneralNewsExtractor/GeneralNewsExtractor)、[AutoCrawler](https://github.com/kingname/AutoCrawler) 、[SeeAct](https://github.com/OSU-NLP-Group/SeeAct) 启发。\n\n## Citation\n\n如果您在相关工作中参考或引用了本项目的部分或全部，请注明如下信息：\n\n```\nAuthor：Wiseflow Team\nhttps://github.com/TeamWiseFlow/wiseflow\nLicensed under Apache2.0\n```\n"
        },
        {
          "name": "README_EN.md",
          "type": "blob",
          "size": 16.611328125,
          "content": "# Chief Intelligence Officer (Wiseflow)\n\n**[简体中文](README.md) | [日本語](README_JP.md) | [한국어](README_KR.md)**\n\n🚀 **Chief Intelligence Officer** (Wiseflow) is an agile information mining tool that can precisely extract specific information from various given sources by leveraging the thinking and analytical capabilities of large models, requiring no human intervention throughout the process.\n\n**What we lack is not information, but the ability to filter out noise from massive information, thereby revealing valuable information.**\n\n🌱 See how AI Intelligence Officer helps you save time, filter irrelevant information, and organize key points of interest! 🌱\n\nhttps://github.com/user-attachments/assets/fc328977-2366-4271-9909-a89d9e34a07b\n\n## 🔥 V0.3.6 is Here\n\nV0.3.6 is an enhanced version of V0.3.5, incorporating numerous improvements based on community feedback. We recommend all users to upgrade.\n\n- Switched to Crawl4ai as the underlying web crawling framework. Although Crawl4ai and Crawlee both rely on Playwright with similar fetching results, Crawl4ai's html2markdown feature is quite practical for LLM information extraction. Additionally, Crawl4ai's architecture better aligns with my design philosophy.\n- Built upon Crawl4ai's html2markdown, we added a deep scraper to further differentiate standalone links from the main content, facilitating more precise LLM extraction. The preprocessing done by html2markdown and deep scraper significantly cleans up raw web data, minimizing interference and misleading information for LLMs, ensuring higher quality outcomes while reducing unnecessary token consumption.\n\n  *Distinguishing between list pages and article pages is a common challenge in web scraping projects, especially when modern webpages often include extensive recommended readings in sidebars and footers of articles, making it difficult to differentiate them through text statistics.*\n  *Initially, I considered using large visual models for layout analysis, but found that obtaining undistorted webpage screenshots greatly increases program complexity and reduces processing efficiency...*\n\n- Restructured extraction strategies and LLM prompts;\n\n  *Regarding prompts, I believe that a good prompt serves as clear workflow guidance, with each step being explicit enough to minimize errors. However, I am skeptical about the value of overly complex prompts, which are hard to evaluate. If you have better solutions, feel free to submit a PR.*\n\n- Introduced large visual models to automatically recognize high-weight images (currently evaluated by Crawl4ai) before extraction and append relevant information to the page text;\n- Continued to reduce dependencies in requirement.txt; json_repair is no longer needed (in practice, having LLMs generate JSON format still noticeably increases processing time and failure rates, so I now adopt a simpler approach with additional post-processing of results)\n- Made minor adjustments to the pb info form structure, adding web_title and reference fields.\n- @ourines contributed the install_pocketbase.sh script (the Docker running solution has been temporarily removed as it wasn't very convenient for users...)\n- @ibaoger contributed the install_pocketbase.ps1 script for windows users\n- @tusik contributed the asynchronous llm wrapper\n\n**Upgrading to V0.3.6 requires restructuring the PocketBase database. Please delete the pb/pb_data folder and re-run the setup**\n\n**In V0.3.6, replace SECONDARY_MODEL with VL_MODEL in the .env file. Refer to the latest [env_sample](./env_sample)**\n\n### V0.3.6 Test Report\n\nWe conducted horizontal tests across four real-world tasks and six real web samples using deepseekV2.5, Qwen2.5-32B-Instruct, Qwen2.5-14B-Instruct, and Qwen2.5-72B-Instruct models provided by siliconflow. For detailed test results, please refer to [report](./test/reports/wiseflow_report_v036_bigbrother666/README.md).\n\nWe have also open-sourced our testing scripts. We welcome everyone to submit more test results. Wiseflow is an open-source project aiming to create an \"information retrieval tool accessible to everyone\"!\n\nRefer to [test/README.md](./test/README.md)\n\nAt this stage, **submitting test results is equivalent to contributing code**, and contributors may even be invited to participate in commercial projects!\n\n\n🌟**V0.3.x Roadmap**\n\n- Attempt to support WeChat Official Account subscription without wxbot (V0.3.7);\n- Introduce support for RSS feeds and search engines (V0.3.8);\n- Attempt partial support for social platforms (V0.3.9).\n\nThroughout these versions, I will continuously improve the deep scraper and LLM extraction strategies. We welcome continuous feedback on application scenarios and sources where extraction performance is unsatisfactory. Please provide feedback in [issue #136](https://github.com/TeamWiseFlow/wiseflow/issues/136).\n\n\n## ✋ How is wiseflow Different from Traditional Crawler Tools, AI Search, and Knowledge Base (RAG) Projects?\n\nSince the release of version V0.3.0 in late June 2024, wiseflow has received widespread attention from the open-source community, attracting even some self-media reports. First of all, we would like to express our gratitude!\n\nHowever, we have also noticed some misunderstandings about the functional positioning of wiseflow among some followers. The following table, through comparison with traditional crawler tools, AI search, and knowledge base (RAG) projects, represents our current thinking on the latest product positioning of wiseflow.\n\n|          | Comparison with **Chief Intelligence Officer (Wiseflow)** | \n|-------------|-----------------|\n| **Crawler Tools** | First of all, wiseflow is a project based on a web crawler tool, but traditional crawler tools require manual provision of explicit Xpath information for data extraction... This not only blocks ordinary users but also lacks universality. For different websites (including existing websites after upgrades), manual re-analysis and program updates are required. wiseflow is committed to using LLM to automate the analysis and extraction of web pages. Users only need to tell the program their focus points. Taking Crawl4ai as an example for comparison, Crawl4ai is a crawler that uses LLM for information extraction, while wiseflow is an LLM information extractor that uses crawler tools. |\n| **AI Search** | AI search is mainly used for **instant question-and-answer** scenarios, such as \"Who is the founder of XX company?\" or \"Where can I buy the xx product under the xx brand?\" Users want **a single answer**; wiseflow is mainly used for **continuous information collection** in certain areas, such as tracking related information of XX company, continuously tracking market behavior of XX brand, etc. In these scenarios, users can provide focus points (a company, a brand) or even information sources (site URLs, etc.), but cannot pose specific search questions. Users want **a series of related information**.| \n| **Knowledge Base (RAG) Projects** | Knowledge base (RAG) projects are generally based on downstream tasks of existing information and usually face private knowledge (such as operation manuals, product manuals, government documents within enterprises, etc.); wiseflow currently does not integrate downstream tasks and faces public information on the internet. From the perspective of \"agents,\" the two belong to agents built for different purposes. RAG projects are \"internal knowledge assistant agents,\" while wiseflow is an \"external information collection agent.\"|\n\n**The wiseflow 0.4.x version will focus on the integration of downstream tasks, introducing an LLM-driven lightweight knowledge graph to help users gain insights from infos.**\n\n## 📥 Installation and Usage\n\n### 1. Clone the Code Repository\n\n🌹 Starring and forking are good habits 🌹\n\n**windows users please download git bash tool first** [link](https://git-scm.com/downloads/win)\n\n```bash\ngit clone https://github.com/TeamWiseFlow/wiseflow.git\n```\n\n### 2. Execute the install_pocketbase script in the root directory\n\nlinux/macos users please execute \n\n```bash\nchmod +x install_pocketbase\n./install_pocketbase\n```\n\n**windows users please execute [install_pocketbase.ps1](./install_pocketbase.ps1) script**\n\nWiseflow 0.3.x uses pocketbase as its database. You can also manually download the pocketbase client (remember to download version 0.23.4 and place it in the [pb](./pb) directory) and manually create the superuser (remember to save it in the .env file).\n\nFor details, please refer to [pb/README.md](/pb/README.md)\n\n### 3. Continue Configuring the core/.env File\n\n🌟 **This is different from previous versions** - starting from V0.3.5, the .env file needs to be placed in the [core](./core) folder.\n\n#### 3.1 Large Language Model Configuration\n\nWiseflow is a LLM native application, so please ensure you provide stable LLM service for the program.\n\n🌟 **Wiseflow does not restrict the source of model services - as long as the service is compatible with the openAI SDK, including locally deployed services like ollama, Xinference, etc.**\n\n#### Recommendation 1: Use MaaS Service Provided by Siliconflow\n\nSiliconflow provides online MaaS services for most mainstream open-source models. With its accumulated acceleration inference technology, its service has great advantages in both speed and price. When using siliconflow's service, the .env configuration can refer to the following:\n\n```bash\nexport LLM_API_KEY=Your_API_KEY\nexport LLM_API_BASE=\"https://api.siliconflow.cn/v1\"\nexport PRIMARY_MODEL=\"Qwen/Qwen2.5-32B-Instruct\"\nexport VL_MODEL=\"OpenGVLab/InternVL2-26B\"\n```\n      \n😄 If you'd like, you can use my [siliconflow referral link](https://cloud.siliconflow.cn?referrer=clx6wrtca00045766ahvexw92), which will help me earn more token rewards 🌹\n\n#### Recommendation 2: Use AiHubMix Proxy for Closed-Source Commercial Models like OpenAI, Claude, Gemini\n\nIf your information sources are mostly non-Chinese pages and you don't require the extracted info to be in Chinese, then it's recommended to use closed-source commercial models like OpenAI, Claude, Gemini. You can try the third-party proxy **AiHubMix**, seamlessly access a wide range of leading AI models like OpenAI, Claude, Google, Llama, and more with just one API.\n\nWhen using AiHubMix models, the .env configuration can refer to the following:\n\n```bash\nexport LLM_API_KEY=Your_API_KEY\nexport LLM_API_BASE=\"https://aihubmix.com/v1\" # refer to https://doc.aihubmix.com/\nexport PRIMARY_MODEL=\"gpt-4o\"\nexport VL_MODEL=\"gpt-4o\"\n```\n\n😄 Welcome to register using the [AiHubMix referral link](https://aihubmix.com?aff=Gp54) 🌹\n\n#### Use Local Large Language Model Service\n\nTaking Xinference as an example, the .env configuration can refer to the following:\n\n```bash\n# LLM_API_KEY='' no need for local service, please comment out or delete\nexport LLM_API_BASE='http://127.0.0.1:9997'\nexport PRIMARY_MODEL=launched_model_id\nexport VL_MODEL=launched_model_id\n```\n\n#### 3.2 Pocketbase Account and Password Configuration\n\n```bash\nexport PB_API_AUTH=\"test@example.com|1234567890\" \n```\n\nThis is where you set the superuser username and password for the pocketbase database, remember to separate them with | (if the install_pocketbase.sh script executed successfully, this should already exist)\n\n#### 3.3 Other Optional Configurations\n\nThe following are all optional configurations:\n- #VERBOSE=\"true\" \n\n  Whether to enable observation mode. When enabled, debug information will be recorded in the logger file (by default only output to console);\n\n- #PROJECT_DIR=\"work_dir\" \n\n    Project runtime data directory. If not configured, defaults to `core/work_dir`. Note: Currently the entire core directory is mounted under the container, meaning you can access it directly.\n\n- #PB_API_BASE=\"\" \n\n  Only needs to be configured if your pocketbase is not running on the default IP or port. Under default circumstances, you can ignore this.\n\n- #LLM_CONCURRENT_NUMBER=8 \n\n Used to control the number of concurrent LLM requests. Default is 1 if not set (before enabling, please ensure your LLM provider supports the configured concurrency. Use local large models with caution unless you are confident in your hardware capabilities)\n  \n  Thanks to @tusik for contributing the asynchronous LLM wrapper\n\n### 4. Running the Program\n\n✋ The V0.3.5 version architecture and dependencies are significantly different from previous versions. Please make sure to re-pull the code, delete (or rebuild) pb_data\n\nIt is recommended to use conda to build a virtual environment (of course you can skip this step, or use other Python virtual environment solutions)\n\n```bash\nconda create -n wiseflow python=3.10\nconda activate wiseflow\n```\n\nthen\n\n```bash\ncd wiseflow\ncd core\npip install -r requirements.txt\nchmod +x run.sh\n./run_task.sh # if you just want to scan sites one-time (no loop), use ./run.sh\n```\n\n🌟 This script will automatically determine if pocketbase is already running. If not, it will automatically start. However, please note that when you terminate the process with ctrl+c or ctrl+z, the pocketbase process will not be terminated until you close the terminal.\n\nrun_task.sh will periodically execute crawling-extraction tasks (it will execute immediately at startup, then every hour after that). If you only need to execute once, you can use the run.sh script.\n\n### 5. **Adding Focus Points and Scheduled Scanning of Information Sources**\n    \nAfter starting the program, open the pocketbase Admin dashboard UI (http://127.0.0.1:8090/_/)\n    \n#### 5.1 Open the focus_point Form\n\nThrough this form, you can specify your focus points, and LLM will refine, filter, and categorize information accordingly.\n    \nField description:\n- focuspoint, focus point description (required), such as \"Shanghai elementary to junior high school information,\" \"cryptocurrency prices\"\n- explanation, detailed explanation or specific conventions of the focus point, such as \"Only official junior high school admission information released by Shanghai\" or \"Current price, price change data of BTC, ETH\"\n- activated, whether to activate. If closed, this focus point will be ignored, and it can be re-enabled later.\n\nNote: After updating the focus_point settings (including activated adjustments), **the program needs to be restarted for the changes to take effect.**\n\n#### 5.2 Open the sites Form\n\nThrough this form, you can specify custom information sources. The system will start background scheduled tasks to scan, parse, and analyze the information sources locally.\n\nsites field description:\n- url, the URL of the information source. The information source does not need to be given a specific article page, just the article list page.\n- per_hours, scanning frequency, in hours, integer type (1~24 range, we recommend not exceeding once a day, i.e., set to 24)\n- activated, whether to activate. If closed, this information source will be ignored, and it can be re-enabled later.\n\n**Adjustments to sites settings do not require restarting the program.**\n\n\n## 📚 How to Use the Data Crawled by wiseflow in Your Own Program\n\n1. Refer to the [dashboard](dashboard) part of the source code for secondary development.\n\nNote that the core part of wiseflow does not require a dashboard, and the current product does not integrate a dashboard. If you need a dashboard, please download [V0.2.1 version](https://github.com/TeamWiseFlow/wiseflow/releases/tag/V0.2.1)\n\n2. Directly obtain data from Pocketbase\n\nAll crawled data by wiseflow will be instantly stored in pocketbase, so you can directly operate the pocketbase database to obtain data.\n\nPocketBase, as a popular lightweight database, currently has SDKs for Go/Javascript/Python and other languages.\n   - Go : https://pocketbase.io/docs/go-overview/\n   - Javascript : https://pocketbase.io/docs/js-overview/\n   - python : https://github.com/vaphes/pocketbase\n\n## 🛡️ License\n\nThis project is open-source under the [Apache2.0](LICENSE) license.\n\nFor cooperation, please contact **Email: zm.zhao@foxmail.com**\n\n- Commercial customers, please contact us for registration. The product promises to be forever free.\n\n\n## 📬 Contact\n\nIf you have any questions or suggestions, please feel free to leave a message via [issue](https://github.com/TeamWiseFlow/wiseflow/issues).\n\n\n## 🤝 This Project is Based on the Following Excellent Open-Source Projects:\n\n- crawl4ai（Open-source LLM Friendly Web Crawler & Scraper） https://github.com/unclecode/crawl4ai\n- python-pocketbase (pocketBase client SDK for python) https://github.com/vaphes/pocketbase\n\nAlso inspired by [GNE](https://github.com/GeneralNewsExtractor/GeneralNewsExtractor)  [AutoCrawler](https://github.com/kingname/AutoCrawler)  [SeeAct](https://github.com/OSU-NLP-Group/SeeAct) .\n\n## Citation\n\nIf you reference or cite part or all of this project in your related work, please specify the following information:\n\n```\nAuthor: Wiseflow Team\nhttps://github.com/TeamWiseFlow/wiseflow\nLicensed under Apache2.0\n```"
        },
        {
          "name": "README_JP.md",
          "type": "blob",
          "size": 20.99609375,
          "content": "# 首席情報官（Wiseflow）\n\n**[English](README_EN.md) | [简体中文](README.md) | [한국어](README_KR.md)**\n\n🚀 **首席情報官**（Wiseflow）は、大規模言語モデルの思考・分析能力を活用して、様々な情報源から特定の情報を正確に抽出できる俊敏な情報マイニングツールです。プロセス全体で人間の介入を必要としません。\n\n**私たちが欠けているのは情報ではなく、大量の情報からノイズをフィルタリングし、価値ある情報を明らかにすることです**\n\n🌱首席情報官がどのようにあなたの時間を節約し、無関係な情報をフィルタリングし、関心のあるポイントを整理するのかを見てみましょう！🌱\n\nhttps://github.com/user-attachments/assets/fc328977-2366-4271-9909-a89d9e34a07b\n\n## 🔥 遅れましたが、V0.3.6が到着しました\n\nV0.3.6はV0.3.5の効果改善版で、多くのコミュニティからのフィードバックに基づいて改良が行われました。すべてのユーザーにアップグレードすることをお勧めします。\n\n  - Crawl4aiを基盤クローリングフレームワークとして採用しました。実際、Crawl4aiとCrawleeの取得結果には大きな違いはありませんが、両者ともPlaywrightに基づいています。しかし、Crawl4aiのhtml2markdown機能が非常に便利で、これはLLM情報抽出に大いに役立ちます。さらに、Crawl4aiのアーキテクチャは私の考え方により適合しています。\n  - Crawl4aiのhtml2markdown機能を基に、deep scraperを追加し、ページ内の独立リンクと本文を区別するようにしました。これにより、次のステップでのLLMによる正確な抽出が容易になります。html2markdownとdeep scraperは元のウェブページデータを十分にクリーニングし、LLMに対する干渉や誤導を大幅に低減し、最終結果の品質を保証するとともに、不要なトークン消費を削減します。\n\n     *リストページと記事ページの区別は、すべてのクローリングプロジェクトにとって頭痛の種です。特に現代のウェブページでは、記事ページのサイドバーとフッターに大量の関連コンテンツが含まれているため、テキスト統計上の特徴的な違いを見つけるのは困難です。*\n     *この部分については、視覚的大規模モデルを使用してレイアウト分析を行うことを検討しましたが、干渉のないウェブページスクリーンショットを取得することは、プログラムの複雑さを大幅に増加させ、処理効率を低下させることがわかりました……*\n\n  - 抽出戦略やLLMのプロンプトを再構築しました。\n\n    *プロンプトについて補足説明すると、私は良いプロンプトは明確な作業フロー指示であるべきだと考えています。各ステップが十分に明確で、間違いを犯すのが難しいものです。しかし、過度に複雑なプロンプトの価値については懐疑的です。評価が難しく、もしより良いソリューションがある場合はPRをお願いします*\n\n  - 視覚的大規模モデルを導入し、抽出前に高ウェイト（現在はCrawl4aiによって評価）の画像を自動的に認識し、関連情報をページテキストに追加します。\n  - requirement.txtの依存関係をさらに削減し、json_repairは必要なくなった（実際の運用中、LLMがJSON形式で生成すると、処理時間と失敗率が明らかに増加することがわかったため、よりシンプルな方法を採用し、処理結果の後処理を強化）\n  - pb infoフォームの構造を微調整し、web_titleとreferenceの2項目を追加しました。\n  - @ourines がinstall_pocketbase.shスクリプトを貢献しました (Docker実行方案は一時的に削除されました、使い勝手が良くなかったため……)\n  - @ibaoger がinstall_pocketbase.ps1スクリプトを貢献しました（WindowsユーザーのためのDocker実行方案は一時的に削除されました、使い勝手が良くなかったため……）\n  - @tusik が非同期 llm wrapper を貢献しました\n**V0.3.6バージョンへのアップグレードにはpocketbaseデータベースの再構築が必要です。pb/pb_dataフォルダを削除した後、再度実行してください**\n\n**V0.3.6バージョンでは.envファイルのSECONDARY_MODELをVL_MODELに置き換えてください。最新の[env_sample](./env_sample)を参照してください**\n  \n### V0.3.6テスト報告書\n\nsiliconflowが提供するdeepseekV2.5、Qwen2.5-32B-Instruct、Qwen2.5-14B-Instruct、Qwen2.5-72B-Instructの4つのモデルの性能を4つの現実的なタスクと合計6つの実際のウェブページサンプルで横断的にテストおよび比較しました。\nテスト結果については[report](./test/reports/wiseflow_report_v036_bigbrother666/README.md)を参照してください。\n\nまた、テストスクリプトもオープンソース化しており、より多くのテスト結果を提出していただけます。wiseflowはオープンソースプロジェクトであり、皆さんの共同の貢献により「誰でも使える情報収集ツール」を目指しています！\n\n詳細は[test/README.md](./test/README.md)を参照してください。\n\n現時点では、**テスト結果の提出はプロジェクトコードの提出と同じ**であり、貢献者として受け入れられ、商業プロジェクトへの招待も期待できます！\n\n\n🌟**V0.3.x プラン**\n\n- WeChat公式アカウントのwxbotなしでの購読をサポートする（V0.3.7）；\n- RSS情報源と検索エンジンのサポートを導入する（V0.3.8）;\n- 部分的なソーシャルプラットフォームのサポートを試みる（V0.3.9）。\n\nこれらのバージョンに伴い、deep scraperおよびLLM抽出戦略を継続的に改善します。アプリケーションシナリオや抽出効果が不十分な情報源のURLについて引き続きフィードバックをお寄せください。[issue #136](https://github.com/TeamWiseFlow/wiseflow/issues/136)でフィードバックをお願いします。\n\n\n## ✋ wiseflow と従来のクローラーツール、AI検索、知識ベース（RAG）プロジェクトの違いは何ですか？\n\nwiseflowは2024年6月末にV0.3.0バージョンをリリースして以来、オープンソースコミュニティから広く注目を集めており、さらに多くのメディアが自発的に報道してくれました。ここでまず感謝の意を表します！\n\nしかし、私たちは一部の関心者がwiseflowの機能ポジションについていくつかの理解のズレを持っていることに気づきました。以下の表は、従来のクローラーツール、AI検索、知識ベース（RAG）類プロジェクトとの比較を通じて、wiseflowの最新の製品ポジションについての私たちの考えを表しています。\n\n|          | **首席情報官（Wiseflow）** との比較説明| \n|-------------|-----------------|\n| **クローラーツール** | まず、wiseflowはクローラーツールを基にしたプロジェクトですが、従来のクローラーツールは情報抽出において明確なXpathなどの情報を手動で提供する必要があります...これは一般ユーザーを阻むだけでなく、汎用性もありません。異なるウェブサイト（既存のウェブサイトのアップグレード後を含む）に対して、手動で再分析し、プログラムを更新する必要があります。wiseflowはLLMを使用してウェブページの分析と抽出を自動化することに努めており、ユーザーはプログラムに自分の関心点を伝えるだけで済みます。Crawl4aiを例として比較すると、Crawl4aiはLLMを使用して情報抽出を行うクローラーであり、wiseflowはクローラーツールを使用するLLM情報抽出ツールです。 |\n| **AI検索** | AI検索の主なアプリケーションシナリオは**具体的な問題の即時回答**です。例：「XX社の創設者は誰ですか」、「xxブランドのxx製品はどこで販売されていますか」。ユーザーが求めているのは**一つの答え**です；wiseflowの主なアプリケーションシナリオは**ある方面の情報の継続的な収集**です。例えば、XX社の関連情報の追跡、XXブランドの市場行動の継続的な追跡……これらのシナリオでは、ユーザーは関心事（ある会社、あるブランド）、さらには情報源（サイトURLなど）を提供できますが、具体的な検索問題を提起することはできません。ユーザーが求めているのは**一連の関連情報**です| \n| **知識ベース（RAG）類プロジェクト** | 知識ベース（RAG）類プロジェクトは通常、既存の情報に基づく下流タスクであり、一般的にプライベート知識（例えば、企業内の操作マニュアル、製品マニュアル、政府部門の文書など）を対象としています；wiseflowは現在、下流タスクを統合しておらず、インターネット上の公開情報を対象としています。「エージェント」の観点から見ると、両者は異なる目的のために構築されたエージェントであり、RAG類プロジェクトは「（内部）知識アシスタントエージェント」であり、wiseflowは「（外部）情報収集エージェント」です|\n\n**wiseflow 0.4.x バージョンは、ダウンストリームタスクの統合に焦点を当て、LLM 駆動の軽量なナレッジグラフを導入し、ユーザーが infos から洞察を得るのを支援します。**\n\n## 📥 インストールと使用\n\n### 1. コードリポジトリのクローン\n\n🌹 いいね、forkは良い習慣です 🌹\n\n**Windowsユーザーは事前にGit Bashツールをダウンロードしてください** [リンク](https://git-scm.com/downloads/win)\n\n```bash\ngit clone https://github.com/TeamWiseFlow/wiseflow.git\n```\n\n### 2. ルートディレクトリのinstall_pocketbase スクリプトを実行\n\nlinux/macosユーザーは以下を実行してください\n\n```bash\nchmod +x install_pocketbase\n./install_pocketbase\n```\n\n**Windowsユーザーは[install_pocketbase.ps1](./install_pocketbase.ps1)スクリプトを実行してください**\n\nWiseflow 0.3.xはデータベースとしてpocketbaseを使用しています。pocketbaseクライアント（バージョン0.23.4をダウンロードして[pb](./pb)ディレクトリに配置することを忘れないでください）を手動でダウンロードし、スーパーユーザーを手動で作成することもできます（.envファイルに保存することを忘れないでください）。\n\n詳細については、[pb/README.md](/pb/README.md)を参照してください。\n\n### 3. core/.envファイルの設定を続行\n\n🌟 **これは以前のバージョンとは異なります** - V0.3.5以降、.envファイルは[core](./core)フォルダに配置する必要があります。\n\n#### 3.1 大規模言語モデルの設定\n\nWiseflowは LLMネイティブアプリケーションですので、プログラムに安定したLLMサービスを提供するようにしてください。\n\n🌟 **Wiseflowはモデルサービスのソースを制限しません - サービスがopenAI SDKと互換性があれば、ollama、Xinferenceなどのローカルにデプロイされたサービスを含め、すべて使用可能です**\n\n#### 推奨1：Siliconflowが提供するMaaSサービスを使用\n\nSiliconflowは、主流のオープンソースモデルのほとんどにオンラインMaaSサービスを提供しています。蓄積された推論加速技術により、そのサービスは速度と価格の両面で大きな利点があります。siliconflowのサービスを使用する場合、.envの設定は以下を参考にしてください：\n\n```bash\nexport LLM_API_KEY=Your_API_KEY\nexport LLM_API_BASE=\"https://api.siliconflow.cn/v1\"\nexport PRIMARY_MODEL=\"Qwen/Qwen2.5-32B-Instruct\"\nexport VL_MODEL=\"OpenGVLab/InternVL2-26B\"\n```\n      \n😄 よろしければ、私の[siliconflow紹介リンク](https://cloud.siliconflow.cn?referrer=clx6wrtca00045766ahvexw92)をご利用ください。これにより、私もより多くのトークン報酬を獲得できます 🌹\n\n#### 推奨2：OpenAI、Claude、Geminiなどのクローズドソース商用モデルにはAiHubMixプロキシを使用\n\n情報ソースが主に非中国語のページで、抽出された情報が中国語である必要がない場合は、OpenAI、Claude、Geminiなどのクローズドソース商用モデルの使用をお勧めします。サードパーティプロキシの**AiHubMix**を試すことができます。OpenAI、Claude、Google、Llamaなど、主要なAIモデルに1つのAPIで簡単にアクセスできます。\n\nAiHubMixモデルを使用する場合、.envの設定は以下を参考にしてください：\n\n```bash\nexport LLM_API_KEY=Your_API_KEY\nexport LLM_API_BASE=\"https://aihubmix.com/v1\" # referhttps://doc.aihubmix.com/\nexport PRIMARY_MODEL=\"gpt-4o\"\nexport VL_MODEL=\"gpt-4o\"\n```\n😄 [AiHubMixの紹介リンク](https://aihubmix.com?aff=Gp54)からご登録いただけますと幸いです 🌹\n\n#### ローカル大規模言語モデルサービスのデプロイ\n\nXinferenceを例にすると、.envの設定は以下を参考にできます：\n\n```bash\n# LLM_API_KEY='' no need for local service, please comment out or delete\nexport LLM_API_BASE='http://127.0.0.1:9997'\nexport PRIMARY_MODEL=launched_model_id\nexport VL_MODEL=launched_model_id\n```\n\n#### 3.2 Pocketbaseのアカウントとパスワードの設定\n\n```bash\nexport PB_API_AUTH=\"test@example.com|1234567890\" \n```\n\nこれはpocketbaseデータベースのスーパーユーザー名とパスワードを設定する場所です。|で区切ることを忘れないでください（install_pocketbase.shスクリプトが正常に実行された場合、これは既に存在しているはずです）\n\n#### 3.3 その他のオプション設定\n\n以下はすべてオプションの設定です：\n- #VERBOSE=\"true\" \n\n  観察モードを有効にするかどうか。有効にすると、デバッグ情報がloggerファイルに記録されます（デフォルトではコンソールにのみ出力）。\n\n- #PROJECT_DIR=\"work_dir\" \n\n    プロジェクトの実行時データディレクトリ。設定しない場合、デフォルトで`core/work_dir`になります。注意：現在、core全体のディレクトリがコンテナにマウントされているため、直接アクセスできます。\n\n- #PB_API_BASE=\"\" \n\n  pocketbaseがデフォルトのIPまたはポートで実行されていない場合にのみ設定が必要です。デフォルトの状況では、これを無視できます。\n\n- #LLM_CONCURRENT_NUMBER=8 \n\n  llm の同時リクエスト数を制御するために使用されます。デフォルトは1です（llm provider が設定された同時性をサポートしていることを確認してください。ローカル大規模モデルはハードウェアベースに自分がない限り慎重に使用してください）\n  \n  @tusik に感謝します\n\n### 4. プログラムの実行\n\n✋ V0.3.5バージョンのアーキテクチャと依存関係は以前のバージョンと大きく異なります。必ずコードを再取得し、pb_dataを削除（または再構築）してください。\n\ncondaを使用して仮想環境を構築することをお勧めします（もちろん、このステップをスキップするか、他のPython仮想環境ソリューションを使用することもできます）\n\n```bash\nconda create -n wiseflow python=3.10\nconda activate wiseflow\n```\n\nその後\n\n```bash\ncd wiseflow\ncd core\npip install -r requirements.txt\nchmod +x run.sh\n./run_task.sh # if you just want to scan sites one-time (no loop), use ./run.sh\n```\n\n🌟 このスクリプトは、pocketbaseが既に実行されているかどうかを自動的に判断します。実行されていない場合は自動的に起動します。ただし、ctrl+cまたはctrl+zでプロセスを終了した場合、ターミナルを閉じるまでpocketbaseプロセスは終了しないことに注意してください。\n\nrun_task.shは定期的にクローリング・抽出タスクを実行します（起動時に即座に実行され、その後1時間ごとに実行されます）。1回だけ実行する必要がある場合は、run.shスクリプトを使用できます。\n\n\n### 5. **関心事と定期的なスキャン情報源の追加**\n    \nプログラムを起動した後、pocketbase Admin dashboard UI (http://127.0.0.1:8090/_/) を開きます\n    \n#### 5.1 focus_point フォームを開く\n\nこのフォームを使用して、あなたの関心事を指定できます。LLMはこれに基づいて情報を抽出、フィルタリング、分類します。\n    \nフィールド説明：\n- focuspoint, 関心事の説明（必須）、例えば「上海の小学校から中学校への情報」、「暗号通貨価格」\n- explanation，関心事の詳細な説明または具体的な約束、例えば「上海市公式発表の中学校進学情報のみ」、「BTC、ETHの現在価格、変動率データ」など\n- activated, 有効化するかどうか。無効にするとこの関心事は無視され、無効にした後再び有効にできます。\n\n注意：focus_pointの更新設定（activatedの調整を含む）後、**プログラムを再起動する必要があります。**\n\n#### 5.2 sitesフォームを開く\n\nこのフォームを使用して、カスタム情報源を指定できます。システムはバックグラウンドで定期的なタスクを開始し、ローカルで情報源のスキャン、解析、分析を実行します。\n\nsitesフィールド説明：\n- url, 情報源のurlで、情報源は具体的な記事ページを指定する必要はありません。記事リストページを指定するだけで十分です。\n- per_hours, スキャン頻度で、単位は時間、整数型（1~24の範囲、スキャン頻度は1日1回を超えないように、つまり24に設定することをお勧めします）\n- activated, 有効化するかどうか。無効にするとこの情報源は無視され、無効にした後再び有効にできます。\n\n**sitesの設定調整は、プログラムを再起動する必要はありません。**\n\n\n## 📚 あなた自身のプログラムでwiseflowがクロールしたデータをどのように使用するか\n\n1、[dashbord](dashboard) 部分のソースコードを参考に二次開発してください。\n\nwiseflowのcore部分はdashboardを必要としません。現在の製品はdashboardを統合していません。もしdashboardが必要な場合、[V0.2.1バージョン](https://github.com/TeamWiseFlow/wiseflow/releases/tag/V0.2.1)をダウンロードしてください\n\n2、直接Pocketbaseからデータを取得します\n\nwiseflowがクロールしたすべてのデータは即座にpocketbaseに保存されるため、直接pocketbaseデータベースを操作してデータを取得できます。\n\nPocketBaseは人気のある軽量データベースで、現在Go/Javascript/Pythonなどの言語のSDKがあります。\n   - Go : https://pocketbase.io/docs/go-overview/\n   - Javascript : https://pocketbase.io/docs/js-overview/\n   - python : https://github.com/vaphes/pocketbase\n\n## 🛡️ ライセンス\n\n本プロジェクトは [Apache2.0](LICENSE) オープンソースライセンスに基づいています。\n\n商用およびカスタムコラボレーションについては、**Email：zm.zhao@foxmail.com** までお問い合わせください\n\n- 商用顧客は私たちに報告登録をお願いします。製品は永遠に無料で提供されることを約束します。\n\n\n## 📬 連絡先\n\n何か質問や提案があれば、[issue](https://github.com/TeamWiseFlow/wiseflow/issues) でメッセージを残してください。\n\n\n## 🤝 本プロジェクトは以下の優れたオープンソースプロジェクトに基づいています：\n\n- crawl4ai（Open-source LLM Friendly Web Crawler & Scraper） https://github.com/unclecode/crawl4ai\n- python-pocketbase (pocketBase client SDK for python) https://github.com/vaphes/pocketbase\n\nまた、[GNE](https://github.com/GeneralNewsExtractor/GeneralNewsExtractor)、[AutoCrawler](https://github.com/kingname/AutoCrawler)、[SeeAct](https://github.com/OSU-NLP-Group/SeeAct)  からもインスピレーションを受けています。\n\n## Citation\n\nもしあなたが関連する作業で本プロジェクトの一部または全部を参照または引用した場合、以下の情報を記載してください：\n\n```\nAuthor：Wiseflow Team\nhttps://github.com/TeamWiseFlow/wiseflow\nLicensed under Apache2.0\n```"
        },
        {
          "name": "README_KR.md",
          "type": "blob",
          "size": 19.341796875,
          "content": "# 수석 정보 책임자 (Wiseflow)\n\n**[English](README_EN.md) | [日本語](README_JP.md) | [简体中文](README.md)**\n\n🚀 **수석 정보 책임자** (Wiseflow)는 대규모 언어 모델의 사고 및 분석 능력을 활용하여 다양한 정보원에서 특정 정보를 정확하게 추출할 수 있는 민첩한 정보 마이닝 도구입니다. 전체 과정에서 인간의 개입이 필요하지 않습니다.\n\n**우리가 부족한 것은 정보가 아니라, 방대한 정보 속에서 노이즈를 필터링하여 가치 있는 정보를 드러내는 것입니다.**\n\n🌱 수석 정보 책임자가 어떻게 시간을 절약하고, 관련 없는 정보를 필터링하며, 관심 사항을 정리하는지 살펴보세요! 🌱\n\nhttps://github.com/user-attachments/assets/fc328977-2366-4271-9909-a89d9e34a07b\n\n## 🔥 늦었지만 도착했습니다, V0.3.6가 출시되었습니다\n\nV0.3.6은 V0.3.5의 개선 버전으로, 많은 커뮤니티 피드백을 반영하여 업그레이드를 권장드립니다.\n\n  - Crawl4ai를 기본 크롤링 프레임워크로 변경하였습니다. 사실 Crawl4ai와 Crawlee는 Playwright 기반이며 얻는 결과가 비슷하지만, Crawl4ai의 html2markdown 기능이 매우 유용하며 이는 llm 정보 추출에 큰 도움이 됩니다. 또한 Crawl4ai의 아키텍처가 저의 생각과 더 잘 맞습니다.\n  - Crawl4ai의 html2markdown 기능을 바탕으로 deep scraper를 추가하여 페이지의 독립 링크와 본문을 구분함으로써 llm의 정확한 추출을 용이하게 하였습니다. html2markdown과 deep scraper가 원본 웹 페이지 데이터를 잘 정리하여 llm이 받는 간섭과 오도를 크게 줄이고 최종 결과의 품질을 보장하며 불필요한 token 소비도 줄였습니다.\n\n     *리스트 페이지와 문서 페이지의 구분은 모든 크롤링 프로젝트에서 어려운 문제입니다. 특히 현대 웹 페이지는 종종 문서 페이지의 사이드바와 하단에 많은 추천 읽기 항목을 추가하여 두 가지가 텍스트 통계적 특징 차이 없이 혼동됩니다.*\n     *이 부분에서는 시각 대형 모델을 사용하여 레이아웃 분석을 고려했으나, 간섭받지 않는 웹 페이지 스크린샷을 얻는 것이 프로그램 복잡성을 크게 증가시키고 처리 효율성을 낮추는 것으로 나타났습니다.*\n\n  - 추출 전략과 llm의 prompt를 재구성하였습니다.\n\n    *좋은 prompt는 명확한 작업 지침이며 각 단계가 충분히 명확해야 실수를 하기 어렵습니다. 하지만 너무 복잡한 prompt의 가치는 평가하기 어렵습니다. 더 나은 방법이 있으시다면 PR을 환영합니다.*\n\n  - 시각 대형 모델을 도입하여 Crawl4ai가 높은 가중치(현재 Crawl4ai가 평가)를 부여한 이미지를 자동으로 인식하고 관련 정보를 페이지 텍스트에 추가합니다.\n  - requirement.txt 의 의존성 항목을 계속 줄였으며, 이제 json_repair가 필요하지 않습니다. (실제로 llm이 JSON 형식으로 생성하는 것은 처리 시간을 증가시키고 실패율을 높이므로 더 간단한 방식을 채택하고 처리 결과 후처리를 강화하였습니다.)\n  - pb info 양식 구조를 약간 조정하여 web_title과 reference 항목을 추가했습니다.\n  - @ourines 님이 install_pocketbase.sh 스크립트를 기여하셨습니다. (Docker 실행 방안은 일시적으로 제거되었으며 사용이 편리하지 않아서……)\n  - @ibaoger 님이 install_pocketbase.ps1 스크립트를 기여하셨습니다.\n  - @tusik 님이 비동기 llm wrapper를 기여하셨습니다.\n**V0.3.6 버전으로 업그레이드하려면 pocketbase 데이터베이스를 다시 구성해야 합니다. pb/pb_data 폴더를 삭제한 후 다시 실행해 주세요.**\n\n**V0.3.6 버전에서는 .env에서 SECONDARY_MODEL을 VL_MODEL로 변경해야 합니다. 최신 [env_sample](./env_sample)을 참고해 주세요.**\n  \n### V0.3.6 테스트 보고서\n\nsiliconflow의 deepseekV2.5, Qwen2.5-32B-Instruct, Qwen2.5-14B-Instruct, Qwen2.5-72B-Instruct 모델의 성능을 네 가지 실제 사례 및 여섯 개의 실제 웹 페이지 샘플에서 횡断적으로 테스트하고 비교하였습니다.\n테스트 결과는 [report](./test/reports/wiseflow_report_v036_bigbrother666/README.md)를 참조해 주세요.\n\n또한 테스트 스크립트도 오픈소스로 제공되며 더 많은 테스트 결과를 제출해 주시길 바랍니다. wiseflow는 오픈소스 프로젝트로서 모두의 공헌으로 \"누구나 사용할 수 있는 정보 수집 도구\"를 만들고자 합니다!\n\n참고: [test/README.md](./test/README.md)\n\n현재, **테스트 결과 제출은 프로젝트 코드 제출과 동일하며** 기여자로 인정되며 상업 프로젝트 참여 초청까지 받을 수도 있습니다!\n\n\n🌟**V0.3.x 계획**\n\n- WeChat 공개 계정 wxbot 없이 구독 지원 (V0.3.7);\n- RSS 정보 소스 및 검색 엔진 지원 도입 (V0.3.8);\n- 일부 사회적 플랫폼 지원 시도 (V0.3.9).\n\n이 세 가지 버전 동안 deep scraper 및 llm 추출 전략을 지속적으로 개선할 예정입니다. 또한 적용 장면과 추출 효과가 이상적인 정보 원본 주소를 지속적으로 피드백해 주시길 바랍니다. [issue #136](https://github.com/TeamWiseFlow/wiseflow/issues/136)에서 피드백을 남겨주세요.\n\n\n## ✋ wiseflow는 전통적인 크롤러 도구, AI 검색, 지식 베이스(RAG) 프로젝트와 어떻게 다를까요?\n\nwiseflow는 2024년 6월 말 V0.3.0 버전 출시 이후 오픈소스 커뮤니티의 광범위한 관심을 받았으며, 심지어 많은 자체 미디어의 자발적인 보도까지 이끌어냈습니다. 이에 먼저 감사의 말씀을 전합니다!\n\n그러나 우리는 일부 관심 있는 분들이 wiseflow의 기능 위치에 대해 일부 이해 오류가 있음을 알게 되었습니다. 아래 표는 전통적인 크롤러 도구, AI 검색, 지식 베이스(RAG) 프로젝트와의 비교를 통해 wiseflow 제품의 최신 위치에 대한 우리의 생각을 나타냅니다.\n\n|          | **수석 정보 책임자 (Wiseflow)**와의 비교 설명                                                                                                                                                                                                                                                                                                                                                      | \n|-------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| **크롤러 도구** | 먼저, wiseflow는 크롤러 도구를 기반으로 한 프로젝트이지만, 전통적인 크롤러 도구는 정보 추출을 위해 명시적인 Xpath 등의 정보를 수동으로 제공해야 합니다... 이는 일반 사용자를 막을 뿐만 아니라 범용성도 없습니다. 다양한 웹사이트(기존 웹사이트 업그레이드 후 포함)에 대해 수동으로 재분석하고 프로그램을 업데이트해야 합니다. wiseflow는 LLM을 사용하여 웹 페이지의 분석과 추출을 자동화하는 데 주력하고 있으며, 사용자는 프로그램에 자신의 관심사를 알리기만 하면 됩니다. Crawl4ai를 예로 들어 비교하자면, Crawl4ai는 LLM을 사용하여 정보를 추출하는 크롤러이고, wiseflow는 크롤러 도구를 사용하는 LLM 정보 추출기입니다.  |\n| **AI 검색** | AI 검색의 주요 응용 시나리오는 **구체적인 문제의 즉각적인 질문 및 답변**입니다. 예: \"XX 회사의 창립자는 누구인가\", \"xx 브랜드의 xx 제품은 어디서 구매할 수 있는가\". 사용자는 **하나의 답변**을 원합니다. wiseflow의 주요 응용 시나리오는 **특정 측면의 정보 지속적 수집**입니다. 예: XX 회사의 관련 정보 추적, XX 브랜드의 시장 행동 지속 추적 등. 이러한 시나리오에서 사용자는 관심사 (특정 회사, 특정 브랜드) 및 신뢰할 수 있는 소스 (사이트 URL 등)를 제공할 수 있지만, 구체적인 검색 질문을 제시할 수 없습니다. 사용자는 **일련의 관련 정보**를 원합니다.                                  |\n| **지식 베이스 (RAG) 프로젝트** | 지식 베이스 (RAG) 프로젝트는 일반적으로 기존 정보를 기반으로 한 하류 작업을 기반으로 하며, 일반적으로 개인 지식 (예: 기업 내 운영 매뉴얼, 제품 매뉴얼, 정부 부서의 문서 등)을 대상으로 합니다. wiseflow는 현재 하류 작업을 통합하지 않으며, 인터넷상의 공개 정보를 대상으로 합니다. \"에이전트\"의 관점에서 볼 때, 둘은 서로 다른 목적으로 구축된 에이전트입니다. RAG 프로젝트는 \"내부 지식 보조 에이전트\"이며, wiseflow는 \"외부 정보 수집 에이전트\"입니다.                                                                                                      |\n\n**wiseflow 0.4.x 버전은 다운스트림 작업의 통합에 초점을 맞추고, LLM 기반의 경량 지식 그래프를 도입하여 사용자가 infos에서 통찰력을 얻을 수 있도록 돕습니다.**\n\n## 📥 설치 및 사용\n\n### 1. 코드 저장소 복제\n\n🌹 좋아요, fork는 좋은 습관입니다 🌹\n\n**windows 사용자는 먼저 git bash 도구를 다운로드해야 합니다** [링크](https://git-scm.com/downloads/win)\n\n```bash\ngit clone https://github.com/TeamWiseFlow/wiseflow.git\n```\n\n### 2. 루트 디렉토리에서 install_pocketbase 스크립트 실행\n\nfor linux/macos users:\n\n```bash\nchmod +x install_pocketbase\n./install_pocketbase\n```\n\n**windows users please execute [install_pocketbase.ps1](./install_pocketbase.ps1) script**\n\nWiseflow 0.3.x는 데이터베이스로 pocketbase를 사용합니다. pocketbase 클라이언트를 수동으로 다운로드할 수도 있습니다(버전 0.23.4를 다운로드하여 [pb](./pb) 디렉토리에 배치하는 것을 잊지 마세요). 그리고 수퍼유저를 수동으로 생성할 수 있습니다(.env 파일에 저장하는 것을 잊지 마세요).\n\n자세한 내용은 [pb/README.md](/pb/README.md)를 참조하세요.\n\n### 3. core/.env 파일 구성 계속하기\n\n🌟 **이전 버전과 다릅니다** - V0.3.5부터 .env 파일은 [core](./core) 폴더에 위치해야 합니다.\n\n#### 3.1 대규모 언어 모델 구성\n\nWiseflow는 LLM 네이티브 애플리케이션이므로 프로그램에 안정적인 LLM 서비스를 제공하도록 해주세요.\n\n🌟 **Wiseflow는 모델 서비스의 출처를 제한하지 않습니다 - ollama, Xinference 등 로컬에 배포된 서비스를 포함하여 openAI SDK와 호환되는 서비스라면 모두 사용할 수 있습니다**\n\n#### 추천 1: Siliconflow가 제공하는 MaaS 서비스 사용\n\nSiliconflow는 대부분의 주류 오픈소스 모델에 대한 온라인 MaaS 서비스를 제공합니다. 축적된 추론 가속화 기술로 속도와 가격 모두에서 큰 장점이 있습니다. siliconflow의 서비스를 사용할 때 .env 구성은 다음을 참조할 수 있습니다:\n\n```bash\nexport LLM_API_KEY=Your_API_KEY\nexport LLM_API_BASE=\"https://api.siliconflow.cn/v1\"\nexport PRIMARY_MODEL=\"Qwen/Qwen2.5-32B-Instruct\"\nexport VL_MODEL=\"OpenGVLab/InternVL2-26B\"\n```\n      \n😄 원하신다면 제 [siliconflow 추천 링크](https://cloud.siliconflow.cn?referrer=clx6wrtca00045766ahvexw92)를 사용하실 수 있습니다. 이를 통해 제가 더 많은 토큰 보상을 받을 수 있습니다 🌹\n\n#### 추천 2: OpenAI, Claude, Gemini와 같은 폐쇄형 상용 모델에는 AiHubMix 프록시 사용\n\n정보 소스가 대부분 비한국어 페이지이고 추출된 정보가 한국어일 필요가 없다면, OpenAI, Claude, Gemini와 같은 폐쇄형 상용 모델을 사용하는 것이 좋습니다. 서드파티 프록시인 **AiHubMix**를 시도해볼 수 있습니다. 하나의 API로 OpenAI, Claude, Google, Llama 등 주요 AI 모델에 원활하게 접근할 수 있습니다.\n\nAiHubMix 모델을 사용할 때 .env 구성은 다음을 참조할 수 있습니다:\n\n```bash\nexport LLM_API_KEY=Your_API_KEY\nexport LLM_API_BASE=\"https://aihubmix.com/v1\" # refer https://doc.aihubmix.com/\nexport PRIMARY_MODEL=\"gpt-4o\"\nexport VL_MODEL=\"gpt-4o\"\n```\n\n😄 Welcome to register using the [AiHubMix referral link](https://aihubmix.com?aff=Gp54) 🌹\n\n#### 로컬 대규모 언어 모델 서비스 배포\n\nXinference를 예로 들면, .env 구성은 다음을 참조할 수 있습니다:\n\n```bash\n# LLM_API_KEY='' no need for local service, please comment out or delete\nexport LLM_API_BASE='http://127.0.0.1:9997'\nexport PRIMARY_MODEL=launched_model_id\nexport VL_MODEL=launched_model_id\n```\n\n#### 3.2 Pocketbase Account and Password Configuration\n\n```bash\nexport PB_API_AUTH=\"test@example.com|1234567890\" \n```\n\n여기서 pocketbase 데이터베이스의 슈퍼유저 사용자 이름과 비밀번호를 설정합니다. |로 구분하는 것을 잊지 마세요 (install_pocketbase.sh 스크립트가 성공적으로 실행되었다면 이미 존재할 것입니다)\n\n#### 3.3 기타 선택적 구성\n\n다음은 모두 선택적 구성입니다:\n- #VERBOSE=\"true\" \n\n  관찰 모드를 활성화할지 여부. 활성화되면 디버그 정보가 로거 파일에 기록됩니다(기본적으로 콘솔에만 출력);\n\n- #PROJECT_DIR=\"work_dir\" \n\n    프로젝트 런타임 데이터 디렉토리. 구성하지 않으면 기본값은 `core/work_dir`입니다. 참고: 현재 전체 core 디렉토리가 컨테이너에 마운트되어 있어 직접 접근할 수 있습니다.\n\n- #PB_API_BASE=\"\" \n\n  pocketbase가 기본 IP 또는 포트에서 실행되지 않는 경우에만 구성이 필요합니다. 기본 상황에서는 이를 무시할 수 있습니다.\n  \n- #LLM_CONCURRENT_NUMBER=8 \n\n  llm 동시 요청 수를 제어하는 데 사용됩니다. 설정하지 않으면 기본값은 1입니다(활성화하기 전에 llm 제공자가 설정된 동시성을 지원하는지 확인하세요. 로컬 대규모 모델은 하드웨어 기반에 자신이 있지 않는 한 신중하게 사용하세요)\n  \n  @tusik이 기여한 비동기 llm wrapper에 감사드립니다\n\n### 4. 프로그램 실행\n\n✋ V0.3.5 버전의 아키텍처와 종속성은 이전 버전과 크게 다릅니다. 코드를 다시 가져오고, pb_data를 삭제(또는 재구축)하도록 하세요\n\n가상 환경을 구축하기 위해 conda를 사용하는 것을 권장합니다(물론 이 단계를 건너뛰거나 다른 Python 가상 환경 솔루션을 사용할 수 있습니다)\n\n```bash\nconda create -n wiseflow python=3.10\nconda activate wiseflow\n```\n\n그런 다음\n\n```bash\ncd wiseflow\ncd core\npip install -r requirements.txt\nchmod +x run.sh\n./run_task.sh # if you just want to scan sites one-time (no loop), use ./run.sh\n```\n\n🌟 이 스크립트는 pocketbase가 이미 실행 중인지 자동으로 확인합니다. 실행 중이 아닌 경우 자동으로 시작됩니다. 단, ctrl+c 또는 ctrl+z로 프로세스를 종료할 때 터미널을 닫을 때까지 pocketbase 프로세스는 종료되지 않는다는 점에 유의하세요.\n\nrun_task.sh는 주기적으로 크롤링-추출 작업을 실행합니다(시작 시 즉시 실행되고 그 후 매시간마다 실행됨). 한 번만 실행하면 되는 경우 run.sh 스크립트를 사용할 수 있습니다.\n\n### 5. **관심사 및 정기 스캔 정보 소스 추가**\n\n프로그램을 시작한 후, pocketbase Admin dashboard UI (http://127.0.0.1:8090/_/)를 여세요.\n\n#### 5.1 focus_point 폼 열기\n\n이 폼을 통해 귀하의 관심사를 지정할 수 있으며, LLM은 이를 기반으로 정보를 추출, 필터링 및 분류합니다.\n\n필드 설명:\n- focuspoint, 관심사 설명 (필수), 예: \"상하이 초등학교 졸업 정보\", \"암호화폐 가격\"\n- explanation, 관심사의 상세 설명 또는 구체적인 약속, 예: \"상하이 공식 발표 중학교 입학 정보만 포함\", \"BTC, ETH의 현재 가격, 등락률 데이터\" 등\n- activated, 활성화 여부. 비활성화되면 해당 관심사는 무시되며, 비활성화 후 다시 활성화할 수 있습니다.\n\n주의: focus_point 업데이트 설정 (activated 조정 포함) 후, **프로그램을 다시 시작해야 적용됩니다.**\n\n#### 5.2 sites 폼 열기\n\n이 폼을 통해 사용자 정의 정보 소스를 지정할 수 있으며, 시스템은 백그라운드 정기 작업을 시작하여 로컬에서 정보 소스를 스캔, 구문 분석 및 분석합니다.\n\nsites 필드 설명:\n- url, 정보 소스의 URL, 정보 소스는 구체적인 기사 페이지를 제공할 필요가 없으며, 기사 목록 페이지만 제공하면 됩니다.\n- per_hours, 스캔 빈도, 단위는 시간, 정수 형식 (1~24 범위, 스캔 빈도를 하루에 한 번 이상으로 설정하지 않는 것을 권장합니다. 즉, 24로 설정).\n- activated, 활성화 여부. 비활성화되면 해당 정보 소스는 무시되며, 비활성화 후 다시 활성화할 수 있습니다.\n\n**sites 설정 조정은 프로그램을 다시 시작할 필요가 없습니다.**\n\n## 📚 wiseflow가 크롤링한 데이터를 귀하의 프로그램에서 사용하는 방법\n\n1. [dashbord](dashboard) 부분 소스 코드를 참조하여 2차 개발을 수행하세요.\n\nwiseflow의 core 부분은 dashboard를 필요로 하지 않으며, 현재 제품은 dashboard를 통합하지 않았습니다. dashboard가 필요한 경우, [V0.2.1 버전](https://github.com/TeamWiseFlow/wiseflow/releases/tag/V0.2.1)을 다운로드하세요.\n\n2. pocketbase에서 직접 데이터를 가져오세요.\n\nwiseflow가 크롤링한 모든 데이터는 즉시 pocketbase에 저장되므로, pocketbase 데이터베이스를 직접 조작하여 데이터를 가져올 수 있습니다.\n\nPocketBase는 인기 있는 경량 데이터베이스로, 현재 Go/Javascript/Python 등 언어의 SDK를 제공합니다.\n   - Go : https://pocketbase.io/docs/go-overview/\n   - Javascript : https://pocketbase.io/docs/js-overview/\n   - python : https://github.com/vaphes/pocketbase\n\n## 🛡️ 라이선스 계약\n\n이 프로젝트는 [Apache2.0](LICENSE) 오픈소스 라이선스를 기반으로 합니다.\n\n상업적 및 맞춤형 협력은 **Email: zm.zhao@foxmail.com**으로 문의하세요.\n\n- 상업용 고객은 등록을 위해 연락해 주세요. 제품은 영원히 무료로 제공됩니다.\n\n## 📬 연락처\n\n문의 사항이나 제안이 있으면 [issue](https://github.com/TeamWiseFlow/wiseflow/issues)를 통해 문의하세요.\n\n## 🤝 이 프로젝트는 다음과 같은 우수한 오픈소스 프로젝트를 기반으로 합니다:\n\n- crawl4ai（Open-source LLM Friendly Web Crawler & Scraper） https://github.com/unclecode/crawl4ai\n- python-pocketbase (pocketBase 클라이언트 SDK for python) https://github.com/vaphes/pocketbase\n\n또한 [GNE](https://github.com/GeneralNewsExtractor/GeneralNewsExtractor), [AutoCrawler](https://github.com/kingname/AutoCrawler), [SeeAct](https://github.com/OSU-NLP-Group/SeeAct) 에서 영감을 받았습니다.\n\n## Citation\n\n이 프로젝트의 일부 또는 전체를 관련 작업에서 참조하거나 인용하는 경우, 다음 정보를 명시하세요:\n\n```\nAuthor: Wiseflow Team\nhttps://github.com/TeamWiseFlow/wiseflow\nLicensed under Apache2.0\n```"
        },
        {
          "name": "core",
          "type": "tree",
          "content": null
        },
        {
          "name": "dashboard",
          "type": "tree",
          "content": null
        },
        {
          "name": "env_sample",
          "type": "blob",
          "size": 0.8759765625,
          "content": "export LLM_API_KEY=\"\"\nexport LLM_API_BASE=\"https://api.siliconflow.cn/v1\"\nexport PRIMARY_MODEL=\"Qwen/Qwen2.5-32B-Instruct\"\n#If your source pages are relatively simple with small amounts of information per page, considering cost and time (mainly time), Qwen2.5-32B-Instruct is recommended\n#If your source pages contain more links, have complex layouts, and you don't want to miss any information, DeepSeek-V2.5 is recommended\nexport VL_MODEL=\"OpenGVLab/InternVL2-26B\"\nexport PB_API_AUTH=\"test@example.com|1234567890\" ##your pb superuser account and password\n\n##belowing is optional, go as you need\n#export VERBOSE=\"true\" ##for detail log info. If not need, remove this item.\nexport PROJECT_DIR=\"work_dir\"\n#export PB_API_BASE=\"\" ##only use if your pb not run on 127.0.0.1:8090\n#export LLM_CONCURRENT_NUMBER=8 ##for concurrent llm requests, make sure your llm provider supports it(leave default is 1)"
        },
        {
          "name": "install_pocketbase.ps1",
          "type": "blob",
          "size": 4.0693359375,
          "content": "# 1. Check if pocketbase exists\nfunction Check-PocketBase {\n    if (Test-Path \".\\pb\\pocketbase.exe\") {\n        Write-Host \"Detected ./pb/pocketbase already exists, please delete it manually and try again\" -ForegroundColor Red\n        exit 1\n    }\n    \n    if (-not (Test-Path \".\\pb\")) {\n        New-Item -ItemType Directory -Path \".\\pb\"\n    }\n}\n\n# 2. Get available versions\nfunction Get-PocketBaseVersions {\n    Write-Host \"Fetching available versions...\" -ForegroundColor Green\n    $response = Invoke-RestMethod -Uri \"https://api.github.com/repos/pocketbase/pocketbase/releases\"\n    $global:VERSIONS = $response | ForEach-Object { $_.tag_name }\n    $global:LATEST_VERSION = $VERSIONS[0]\n}\n\n# 3. Select version with arrow keys\nfunction Select-PocketBaseVersion {\n    Clear-Host\n    $current = 0\n    $total = $VERSIONS.Count\n    \n    while ($true) {\n        Clear-Host\n        Write-Host \"Available versions (Use ↑↓ arrows to select, Enter to confirm):\" -ForegroundColor Yellow\n        Write-Host \"----------------------------------------\"\n        \n        for ($i = 0; $i -lt $total; $i++) {\n            if ($i -eq $current) {\n                Write-Host (\"-> \" + $VERSIONS[$i]) -ForegroundColor Green\n            } else {\n                Write-Host (\"   \" + $VERSIONS[$i])\n            }\n        }\n        \n        $key = $host.UI.RawUI.ReadKey(\"NoEcho,IncludeKeyDown\")\n        \n        switch ($key.VirtualKeyCode) {\n            38 { # Up arrow\n                if ($current -gt 0) { $current-- }\n            }\n            40 { # Down arrow\n                if ($current -lt ($total - 1)) { $current++ }\n            }\n            13 { # Enter\n                $global:SELECTED_VERSION = $VERSIONS[$current]\n                Write-Host \"`nSelected version: $SELECTED_VERSION\" -ForegroundColor Green\n                return\n            }\n        }\n    }\n}\n\n# 4. Download PocketBase\nfunction Download-PocketBase {\n    $versionNum = $SELECTED_VERSION -replace '^v'\n    $fileName = \"pocketbase_${versionNum}_windows_amd64.zip\"\n    $downloadUrl = \"https://github.com/pocketbase/pocketbase/releases/download/$SELECTED_VERSION/$fileName\"\n    $outputPath = \".\\pb\\pocketbase.zip\"\n    \n    Write-Host \"Downloading PocketBase $SELECTED_VERSION...\" -ForegroundColor Green\n    Invoke-WebRequest -Uri $downloadUrl -OutFile $outputPath\n    \n    Write-Host \"Extracting files...\" -ForegroundColor Green\n    Expand-Archive -Path $outputPath -DestinationPath \".\\pb\" -Force\n    Remove-Item $outputPath\n}\n\n# 5. Configure admin account\nfunction Configure-AdminAccount {\n    Write-Host \"`nConfiguring admin account\" -ForegroundColor Yellow\n    \n    do {\n        $email = Read-Host \"Enter admin email\"\n    } while (-not ($email -match \"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\"))\n    \n    do {\n        $password = Read-Host \"Enter admin password (min 8 chars)\" -AsSecureString\n        $BSTR = [System.Runtime.InteropServices.Marshal]::SecureStringToBSTR($password)\n        $passwordText = [System.Runtime.InteropServices.Marshal]::PtrToStringAuto($BSTR)\n    } while ($passwordText.Length -lt 8)\n    \n    $global:ADMIN_EMAIL = $email\n    $global:ADMIN_PASSWORD = $passwordText\n}\n\n# 6. Configure environment file\nfunction Configure-Environment {\n    if (-not (Test-Path \".\\core\\.env\")) {\n        Copy-Item \"env_sample\" -Destination \".\\core\\.env\"\n        Write-Host \"Created new .env file from template\" -ForegroundColor Green\n    } else {\n        Write-Host \"Found existing .env file\" -ForegroundColor Yellow\n    }\n    \n    $envContent = Get-Content \".\\core\\.env\"\n    $envContent = $envContent -replace 'export PB_API_AUTH=\"[^\"]*\"', \"export PB_API_AUTH=`\"$ADMIN_EMAIL|$ADMIN_PASSWORD`\"\"\n    Set-Content \".\\core\\.env\" $envContent\n    \n    Write-Host \"Updated PB_API_AUTH in .env with new credentials\" -ForegroundColor Green\n}\n\n# Main execution\nfunction Main {\n    Write-Host \"Starting PocketBase installation...\" -ForegroundColor Cyan\n    Check-PocketBase\n    Get-PocketBaseVersions\n    Select-PocketBaseVersion\n    Download-PocketBase\n    Configure-AdminAccount\n    Configure-Environment\n    Write-Host \"PocketBase installation completed!\" -ForegroundColor Green\n}\n\n# Run the script\nMain"
        },
        {
          "name": "install_pocketbase.sh",
          "type": "blob",
          "size": 6.9599609375,
          "content": "#!/bin/bash\n\n# 1. Check if pocketbase exists\ncheck_pocketbase() {\n    if [ -f \"./pb/pocketbase\" ]; then\n        echo \"Detected ./pb/pocketbase already exists, please delete it manually and try again\"\n        exit 1\n    fi\n    \n    # Create directory if it doesn't exist\n    if [ ! -d \"./pb\" ]; then\n        mkdir -p ./pb\n    fi\n}\n\n# 2. Get available versions\nget_versions() {\n    echo \"Fetching available versions...\"\n    VERSIONS=($(curl -s https://api.github.com/repos/pocketbase/pocketbase/releases | grep '\"tag_name\":' | sed -E 's/.*\"([^\"]+)\".*/\\1/'))\n    LATEST_VERSION=${VERSIONS[0]}\n}\n\n# 3. Select version with arrow keys\nselect_version() {\n    # Clear screen\n    clear\n    \n    # Array to store versions\n    local versions=(\"${VERSIONS[@]}\")\n    local current=0\n    local key\n    local total=${#versions[@]}\n    \n    while true; do\n        # Clear screen\n        clear\n        echo \"Available versions (Use ↑↓ arrows to select, Enter to confirm):\"\n        echo \"----------------------------------------\"\n        \n        # Display versions\n        for i in \"${!versions[@]}\"; do\n            if [ $i -eq $current ]; then\n                echo -e \"\\033[32m-> ${versions[$i]}\\033[0m\"\n            else\n                echo \"   ${versions[$i]}\"\n            fi\n        done\n        \n        # Read a single character\n        read -rsn1 key\n        \n        # Special key sequences\n        if [[ $key = $'\\x1b' ]]; then\n            read -rsn2 key\n            case $key in\n                '[A') # Up arrow\n                    ((current--))\n                    [ $current -lt 0 ] && current=$((total - 1))\n                    ;;\n                '[B') # Down arrow\n                    ((current++))\n                    [ $current -ge $total ] && current=0\n                    ;;\n            esac\n        elif [[ $key = \"\" ]]; then # Enter key\n            SELECTED_VERSION=${versions[$current]}\n            break\n        fi\n    done\n    \n    echo -e \"\\nSelected version: $SELECTED_VERSION\"\n}\n\n# 4. Download corresponding system version\ndownload_pocketbase() {\n    # Detect OS and architecture\n    OS=$(uname -s | tr '[:upper:]' '[:lower:]')\n    ARCH=$(uname -m)\n    \n    # Remove 'v' prefix from version number\n    VERSION_NUM=${SELECTED_VERSION#v}\n    \n    case \"$OS\" in\n        \"darwin\") \n            case \"$ARCH\" in\n                \"x86_64\") FILENAME=\"pocketbase_${VERSION_NUM}_darwin_amd64.zip\" ;;\n                \"arm64\") FILENAME=\"pocketbase_${VERSION_NUM}_darwin_arm64.zip\" ;;\n            esac\n            ;;\n        \"linux\")\n            case \"$ARCH\" in\n                \"x86_64\") FILENAME=\"pocketbase_${VERSION_NUM}_linux_amd64.zip\" ;;\n                \"aarch64\") FILENAME=\"pocketbase_${VERSION_NUM}_linux_arm64.zip\" ;;\n            esac\n            ;;\n        *)\n            echo \"Unsupported operating system\"\n            exit 1\n            ;;\n    esac\n\n    # Download and extract\n    DOWNLOAD_URL=\"https://github.com/pocketbase/pocketbase/releases/download/${SELECTED_VERSION}/${FILENAME}\"\n    echo \"Downloading: $DOWNLOAD_URL\"\n    \n    # Download with retry mechanism\n    MAX_RETRIES=3\n    RETRY_COUNT=0\n    \n    while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do\n        if curl -L \"$DOWNLOAD_URL\" -o \"./pb/${FILENAME}\" --fail --silent --show-error; then\n            if [ -f \"./pb/${FILENAME}\" ] && [ -s \"./pb/${FILENAME}\" ]; then\n                echo \"Download completed successfully\"\n                break\n            fi\n        fi\n        \n        RETRY_COUNT=$((RETRY_COUNT + 1))\n        if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then\n            echo \"Download failed, retrying ($RETRY_COUNT/$MAX_RETRIES)...\"\n            sleep 2\n        else\n            echo \"Download failed after $MAX_RETRIES attempts\"\n            exit 1\n        fi\n    done\n    \n    # Extract only the pocketbase executable\n    cd ./pb || exit 1\n    \n    if ! unzip -j -o \"${FILENAME}\" \"pocketbase\" > /dev/null 2>&1; then\n        echo \"Failed to extract pocketbase executable\"\n        cd ..\n        exit 1\n    fi\n    \n    rm \"${FILENAME}\"  # Remove the zip file\n    \n    if [ ! -f \"pocketbase\" ]; then\n        echo \"pocketbase executable not found after extraction\"\n        cd ..\n        exit 1\n    fi\n    \n    chmod +x pocketbase\n    cd ..\n    \n    echo \"Successfully installed pocketbase\"\n}\n\n# Validate email format\nvalidate_email() {\n    local email=$1\n    if [[ ! \"$email\" =~ ^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}$ ]]; then\n        return 1\n    fi\n    return 0\n}\n\n# Validate password requirements\nvalidate_password() {\n    local password=$1\n    # Check minimum length of 8 characters\n    if [ ${#password} -lt 8 ]; then\n        return 1\n    fi\n    return 0\n}\n\n# 5. Configure admin account\nconfigure_admin() {\n    local valid_input=false\n    \n    while [ \"$valid_input\" = false ]; do\n        # Get email\n        while true; do\n            echo \"Please set superuser email:\"\n            read EMAIL\n            \n            if validate_email \"$EMAIL\"; then\n                break\n            else\n                echo \"Invalid email format. Please try again.\"\n            fi\n        done\n        \n        # Get password\n        while true; do\n            echo \"Please set superuser password (minimum 8 characters):\"\n            read -s PASSWORD\n            echo\n            \n            if validate_password \"$PASSWORD\"; then\n                # Confirm password\n                echo \"Please confirm password:\"\n                read -s PASSWORD_CONFIRM\n                echo\n                \n                if [ \"$PASSWORD\" = \"$PASSWORD_CONFIRM\" ]; then\n                    valid_input=true\n                    break\n                else\n                    echo \"Passwords do not match. Please try again.\"\n                fi\n            else\n                echo \"Password must be at least 8 characters long. Please try again.\"\n            fi\n        done\n    done\n\n    cd ./pb\n    ./pocketbase migrate up\n    \n    # Try to create superuser\n    if ! ./pocketbase --dev superuser create \"$EMAIL\" \"$PASSWORD\"; then\n        echo \"Failed to create superuser. Please check the error message above.\"\n        exit 1\n    fi\n    cd ..\n    \n    echo \"Superuser created successfully!\"\n}\n\n# 6. Configure environment file\nconfigure_env() {\n    # Create .env if it doesn't exist\n    if [ ! -f \"./core/.env\" ]; then\n        # mkdir -p ./core\n        cp env_sample ./core/.env\n        echo \"Created new .env file from template\"\n    else\n        echo \"Found existing .env file\"\n    fi\n    \n    # Update authentication info in environment file using sed\n    if [ \"$(uname)\" = \"Darwin\" ]; then\n        # macOS version\n        sed -i '' 's/export PB_API_AUTH=\"[^\"]*\"/export PB_API_AUTH=\"'$EMAIL'|'$PASSWORD'\"/' \"./core/.env\"\n    else\n        # Linux version\n        sed -i 's/export PB_API_AUTH=\"[^\"]*\"/export PB_API_AUTH=\"'$EMAIL'|'$PASSWORD'\"/' \"./core/.env\"\n    fi\n    \n    echo \"Updated PB_API_AUTH in .env with new credentials\"\n}\n\nmain() {\n    echo \"Starting PocketBase installation...\"\n    check_pocketbase\n    get_versions\n    select_version\n    download_pocketbase\n    configure_admin\n    configure_env\n    echo \"PocketBase installation completed!\"\n}\n\nmain"
        },
        {
          "name": "pb",
          "type": "tree",
          "content": null
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "version",
          "type": "blob",
          "size": 0.005859375,
          "content": "v0.3.6"
        }
      ]
    }
  ]
}