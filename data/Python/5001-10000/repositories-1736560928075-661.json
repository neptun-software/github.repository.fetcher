{
  "metadata": {
    "timestamp": 1736560928075,
    "page": 661,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjY3MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "baichuan-inc/Baichuan-7B",
      "stars": 5680,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 7.130859375,
          "content": "##### Project Specification #####\n**/test\n**/ceval_output\n\n##### Python.gitignore #####\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\nwheelhouse/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n*.whl\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\ncover/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\ndocs/build/\ndocs/source/_build/\n\n# PyBuilder\n.pybuilder/\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n#   For a library or package, you might want to ignore these files since the code is\n#   intended to run in multiple environments; otherwise, check them in:\n.python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# poetry\n#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.\n#   This is especially recommended for binary packages to ensure reproducibility, and is more\n#   commonly ignored for libraries.\n#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control\n#poetry.lock\n\n# pdm\n#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.\n#pdm.lock\n#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it\n#   in version control.\n#   https://pdm.fming.dev/#use-with-ide\n.pdm.toml\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# ruff\n.ruff_cache/\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# pytype static type analyzer\n.pytype/\n\n# Cython debug symbols\ncython_debug/\n\n# PyCharm\n#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can\n#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore\n#  and can be added to the global gitignore or merged into this file.  For a more nuclear\n#  option (not recommended) you can uncomment the following to ignore the entire idea folder.\n.idea/\n\n\n##### macOS.gitignore #####\n# General\n.DS_Store\n.AppleDouble\n.LSOverride\n\n# Icon must end with two \\r\nIcon\n\n# Thumbnails\n._*\n\n# Files that might appear in the root of a volume\n.DocumentRevisions-V100\n.fseventsd\n.Spotlight-V100\n.TemporaryItems\n.Trashes\n.VolumeIcon.icns\n.com.apple.timemachine.donotpresent\n\n# Directories potentially created on remote AFP share\n.AppleDB\n.AppleDesktop\nNetwork Trash Folder\nTemporary Items\n.apdisk\n\n\n##### Linux.gitignore #####\n*~\n\n# Temporary files which can be created if a process still has a handle open of a deleted file\n.fuse_hidden*\n\n# KDE directory preferences\n.directory\n\n# Linux trash folder which might appear on any partition or disk\n.Trash-*\n\n# .nfs files are created when an open file is removed but is still being accessed\n.nfs*\n\n\n##### Windows.gitignore #####\n# Windows thumbnail cache files\nThumbs.db\nThumbs.db:encryptable\nehthumbs.db\nehthumbs_vista.db\n\n# Dump file\n*.stackdump\n\n# Folder config file\n[Dd]esktop.ini\n\n# Recycle Bin used on file shares\n$RECYCLE.BIN/\n\n# Windows Installer files\n*.cab\n*.msi\n*.msix\n*.msm\n*.msp\n\n# Windows shortcuts\n*.lnk\n\n\n##### Archives.gitignore #####\n# It's better to unpack these files and commit the raw source because\n# git has its own built in compression methods.\n*.7z\n*.jar\n*.rar\n*.zip\n*.gz\n*.gzip\n*.tgz\n*.bzip\n*.bzip2\n*.bz2\n*.xz\n*.lzma\n*.cab\n*.xar\n\n# Packing-only formats\n*.iso\n*.tar\n\n# Package management formats\n*.dmg\n*.xpi\n*.gem\n*.egg\n*.deb\n*.rpm\n*.msi\n*.msm\n*.msp\n*.txz\n\n\n##### Xcode.gitignore #####\n# Xcode\n#\n# gitignore contributors: remember to update Global/Xcode.gitignore, Objective-C.gitignore & Swift.gitignore\n\n## User settings\nxcuserdata/\n\n## Compatibility with Xcode 8 and earlier (ignoring not required starting Xcode 9)\n*.xcscmblueprint\n*.xccheckout\n\n## Compatibility with Xcode 3 and earlier (ignoring not required starting Xcode 4)\nbuild/\nDerivedData/\n*.moved-aside\n*.pbxuser\n!default.pbxuser\n*.mode1v3\n!default.mode1v3\n*.mode2v3\n!default.mode2v3\n*.perspectivev3\n!default.perspectivev3\n\n## Gcc Patch\n/*.gcno\n\n\n##### JetBrains.gitignore #####\n# Covers JetBrains IDEs: IntelliJ, RubyMine, PhpStorm, AppCode, PyCharm, CLion, Android Studio and WebStorm\n# Reference: https://intellij-support.jetbrains.com/hc/en-us/articles/206544839\n\n# User settings\n.idea/*\n\n# User-specific stuff\n.idea/**/workspace.xml\n.idea/**/tasks.xml\n.idea/**/usage.statistics.xml\n.idea/**/dictionaries\n.idea/**/shelf\n\n# Generated files\n.idea/**/contentModel.xml\n\n# Sensitive or high-churn files\n.idea/**/dataSources/\n.idea/**/dataSources.ids\n.idea/**/dataSources.local.xml\n.idea/**/sqlDataSources.xml\n.idea/**/dynamic.xml\n.idea/**/uiDesigner.xml\n.idea/**/dbnavigator.xml\n\n# Gradle\n.idea/**/gradle.xml\n.idea/**/libraries\n\n# Gradle and Maven with auto-import\n# When using Gradle or Maven with auto-import, you should exclude module files,\n# since they will be recreated, and may cause churn. Uncomment if using\n# auto-import.\n# .idea/artifacts\n# .idea/compiler.xml\n# .idea/jarRepositories.xml\n# .idea/modules.xml\n# .idea/*.iml\n# .idea/modules\n# *.iml\n# *.ipr\n\n# CMake\ncmake-build-*/\n\n# Mongo Explorer plugin\n.idea/**/mongoSettings.xml\n\n# File-based project format\n*.iws\n\n# IntelliJ\nout/\n\n# mpeltonen/sbt-idea plugin\n.idea_modules/\n\n# JIRA plugin\natlassian-ide-plugin.xml\n\n# Cursive Clojure plugin\n.idea/replstate.xml\n\n# Crashlytics plugin (for Android Studio and IntelliJ)\ncom_crashlytics_export_strings.xml\ncrashlytics.properties\ncrashlytics-build.properties\nfabric.properties\n\n# Editor-based Rest Client\n.idea/httpRequests\n\n# Android studio 3.1+ serialized cache file\n.idea/caches/build_file_checksums.ser\n\n\n##### VisualStudioCode.gitignore #####\n.vscode/*\n# !.vscode/settings.json\n# !.vscode/tasks.json\n# !.vscode/launch.json\n!.vscode/extensions.json\n*.code-workspace\n\n# Local History for Visual Studio Code\n.history/\n\n\n##### Vim.gitignore #####\n# Swap\n.*.s[a-v][a-z]\n!*.svg  # comment out if you don't need vector files\n.*.sw[a-p]\n.s[a-rt-v][a-z]\n.ss[a-gi-z]\n.sw[a-p]\n\n# Session\nSession.vim\nSessionx.vim\n\n# Temporary\n.netrwhist\n*~\n# Auto-generated tag files\ntags\n# Persistent undo\n[._]*.un~"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.080078125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [2023] [baichuan-inc]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 14.501953125,
          "content": "<!-- markdownlint-disable first-line-h1 -->\n<!-- markdownlint-disable html -->\n\n<div align=\"center\">\n<h1>\n  Baichuan-7B\n</h1>\n</div>\n\n<p align=\"center\">\nğŸ¤— <a href=\"https://huggingface.co/baichuan-inc/Baichuan-7B\" target=\"_blank\">Hugging Face</a> â€¢ ğŸ¤– <a href=\"https://modelscope.cn/organization/baichuan-inc\" target=\"_blank\">ModelScope</a> â€¢ ğŸ’¬ <a href=\"https://github.com/baichuan-inc/Baichuan-7B/blob/main/media/wechat.jpeg?raw=true\" target=\"_blank\">WeChat</a>\n</p>\n\n<div align=\"center\">\n\n[![license](https://img.shields.io/github/license/modelscope/modelscope.svg)](https://github.com/baichuan-inc/Baichuan-7B/blob/main/LICENSE)\n<h4 align=\"center\">\n    <p>\n        <b>ä¸­æ–‡</b> |\n        <a href=\"https://github.com/baichuan-inc/Baichuan-7B/blob/main/README_EN.md\">English</a>\n    <p>\n</h4>\n</div>\n\n# æ›´æ–°ä¿¡æ¯\n- [2023.09.06] æˆ‘ä»¬å‘å¸ƒäº†æ–°ä¸€ä»£å¼€æºæ¨¡å‹ [Baichuan 2](https://github.com/baichuan-inc/Baichuan2)ï¼ŒåŒ…å« 7Bã€13B å°ºå¯¸ ğŸ”¥ğŸ”¥ğŸ”¥\n\n# ä»‹ç»\n\nBaichuan-7B æ˜¯ç”±ç™¾å·æ™ºèƒ½å¼€å‘çš„ä¸€ä¸ªå¼€æºå¯å•†ç”¨çš„å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚åŸºäº Transformer ç»“æ„ï¼Œåœ¨å¤§çº¦ 1.2 ä¸‡äº¿ tokens ä¸Šè®­ç»ƒçš„ 70 äº¿å‚æ•°æ¨¡å‹ï¼Œæ”¯æŒä¸­è‹±åŒè¯­ï¼Œä¸Šä¸‹æ–‡çª—å£é•¿åº¦ä¸º 4096ã€‚åœ¨æ ‡å‡†çš„ä¸­æ–‡å’Œè‹±æ–‡ benchmarkï¼ˆC-Eval/MMLUï¼‰ä¸Šå‡å–å¾—åŒå°ºå¯¸æœ€å¥½çš„æ•ˆæœã€‚\n\n# å…¬å¼€benchmarkæ¦œå•\n\n## ä¸­æ–‡è¯„æµ‹\n\n### C-Eval\n\n[C-Eval æ•°æ®é›†](https://cevalbenchmark.com/index.html)æ˜¯ä¸€ä¸ªå…¨é¢çš„ä¸­æ–‡åŸºç¡€æ¨¡å‹è¯„æµ‹æ•°æ®é›†ï¼Œæ¶µç›–äº† 52 ä¸ªå­¦ç§‘å’Œå››ä¸ªéš¾åº¦çš„çº§åˆ«ã€‚æˆ‘ä»¬ä½¿ç”¨è¯¥æ•°æ®é›†çš„ dev é›†ä½œä¸º few-shot çš„æ¥æºï¼Œåœ¨ test é›†ä¸Šè¿›è¡Œäº† `5-shot` æµ‹è¯•ã€‚é€šè¿‡æ‰§è¡Œæ‰§è¡Œä¸‹é¢çš„å‘½ä»¤ï¼š\n\n```bash\ncd evaluation\npython evaluate_zh.py --model_name_or_path 'your/model/path'\n```\n\n### ç»“æœ\n\n|        Model 5-shot         | Average | Avg(Hard) | STEM  | Social Sciences | Humanities | Others |\n| :-------------------------: | :-----: | :-------: | :---: | :-------------: | :--------: | :----: |\n|            GPT-4            |  68.7   |   54.9    | 67.1  |      77.6       |    64.5    |  67.8  |\n|           ChatGPT           |  54.4   |   41.4    | 52.9  |      61.8       |    50.9    |  53.6  |\n|         Claude-v1.3         |  54.2   |   39.0    | 51.9  |      61.7       |    52.1    |  53.7  |\n|     Claude-instant-v1.0     |  45.9   |   35.5    | 43.1  |      53.8       |    44.2    |  45.4  |\n|          BLOOMZ-7B          |  35.7   |   25.8    | 31.3  |      43.5       |    36.6    |  35.6  |\n|         ChatGLM-6B          |  34.5   |   23.1    | 30.4  |      39.6       |    37.4    |  34.5  |\n|   Ziya-LLaMA-13B-pretrain   |  30.2   |   22.7    | 27.7  |      34.4       |    32.0    |  28.9  |\n|  moss-moon-003-base (16B)   |  27.4   |   24.5    | 27.0  |      29.1       |    27.2    |  26.9  |\n|         LLaMA-7B-hf         |  27.1   |   25.9    | 27.1  |      26.8       |    27.9    |  26.3  |\n|          Falcon-7B          |  25.8   |   24.3    | 25.8  |      26.0       |    25.8    |  25.6  |\n|      TigerBot-7B-base       |  25.7   |   27.0    | 27.3  |      24.7       |    23.4    |  26.1  |\n|    Aquila-7B<sup>*</sup>    |  25.5   |   25.2    | 25.6  |      24.6       |    25.2    |  26.6  |\n| Open-LLaMA-v2-pretrain (7B) |  24.0   |   22.5    | 23.1  |      25.3       |    25.2    |  23.2  |\n|          BLOOM-7B           |  22.8   |   20.2    | 21.8  |      23.3       |    23.9    |  23.3  |\n|       **Baichuan-7B**       |  42.8   |   31.5    | 38.2  |      52.0       |    46.2    |  39.3  |\n\n### Gaokao\n\n[Gaokao](https://github.com/OpenLMLab/GAOKAO-Bench) æ˜¯ä¸€ä¸ªä»¥ä¸­å›½é«˜è€ƒé¢˜ä½œä¸ºè¯„æµ‹å¤§è¯­è¨€æ¨¡å‹èƒ½åŠ›çš„æ•°æ®é›†ï¼Œç”¨ä»¥è¯„ä¼°æ¨¡å‹çš„è¯­è¨€èƒ½åŠ›å’Œé€»è¾‘æ¨ç†èƒ½åŠ›ã€‚\næˆ‘ä»¬åªä¿ç•™äº†å…¶ä¸­çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œéšæœºåˆ’åˆ†åå¯¹æ‰€æœ‰æ¨¡å‹è¿›è¡Œç»Ÿä¸€ `5-shot` æµ‹è¯•ã€‚\n\n### ç»“æœ\n\nä»¥ä¸‹æ˜¯æµ‹è¯•çš„ç»“æœã€‚\n\n|          Model          |  Average  |\n| :---------------------: | :-------: |\n|        BLOOMZ-7B        |   28.72   |\n|        LLaMA-7B         |   27.81   |\n|        BLOOM-7B         |   26.96   |\n|    TigerBot-7B-base     |   25.94   |\n|        Falcon-7B        |   23.98   |\n| Ziya-LLaMA-13B-pretrain |   23.17   |\n|       ChatGLM-6B        |   21.41   |\n| Open-LLaMA-v2-pretrain  |   21.41   |\n|  Aquila-7B<sup>*</sup>  |   24.39   |\n|     **Baichuan-7B**     | **36.24** |\n\n### AGIEval\n\n[AGIEval](https://github.com/microsoft/AGIEval) æ—¨åœ¨è¯„ä¼°æ¨¡å‹çš„è®¤çŸ¥å’Œè§£å†³é—®é¢˜ç›¸å…³çš„ä»»åŠ¡ä¸­çš„ä¸€èˆ¬èƒ½åŠ›ã€‚\næˆ‘ä»¬åªä¿ç•™äº†å…¶ä¸­çš„å››é€‰ä¸€å•é¡¹é€‰æ‹©é¢˜ï¼Œéšæœºåˆ’åˆ†åå¯¹æ‰€æœ‰æ¨¡å‹è¿›è¡Œäº†ç»Ÿä¸€ `5-shot` æµ‹è¯•ã€‚\n\n### ç»“æœ\n\n|          Model          |  Average  |\n| :---------------------: | :-------: |\n|        BLOOMZ-7B        |   30.27   |\n|        LLaMA-7B         |   28.17   |\n| Ziya-LLaMA-13B-pretrain |   27.64   |\n|        Falcon-7B        |   27.18   |\n|        BLOOM-7B         |   26.55   |\n|  Aquila-7B<sup>*</sup>  |   25.58   |\n|    TigerBot-7B-base     |   25.19   |\n|       ChatGLM-6B        |   23.49   |\n| Open-LLaMA-v2-pretrain  |   23.49   |\n|     **Baichuan-7B**     | **34.44** |\n\n<sup>*</sup>å…¶ä¸­ Aquila æ¨¡å‹æ¥æºäºæ™ºæºå®˜æ–¹ç½‘ç«™(<https://model.baai.ac.cn/model-detail/100098>) ä»…åšå‚è€ƒ\n\n## è‹±æ–‡æ¦œå•\n\né™¤äº†ä¸­æ–‡ä¹‹å¤–ï¼ŒBaichuan-7Bä¹Ÿæµ‹è¯•äº†æ¨¡å‹åœ¨è‹±æ–‡ä¸Šçš„æ•ˆæœï¼Œ[MMLU](https://arxiv.org/abs/2009.03300) æ˜¯åŒ…å« 57 ä¸ªå¤šé€‰ä»»åŠ¡çš„è‹±æ–‡è¯„æµ‹æ•°æ®é›†ï¼Œæ¶µç›–äº†åˆç­‰æ•°å­¦ã€ç¾å›½å†å²ã€è®¡ç®—æœºç§‘å­¦ã€æ³•å¾‹ç­‰ï¼Œéš¾åº¦è¦†ç›–é«˜ä¸­æ°´å¹³åˆ°ä¸“å®¶æ°´å¹³ï¼Œæ˜¯ç›®å‰ä¸»æµçš„LLMè¯„æµ‹æ•°æ®é›†ã€‚æˆ‘ä»¬é‡‡ç”¨äº†[å¼€æº](https://github.com/hendrycks/test) çš„è¯„æµ‹æ–¹æ¡ˆï¼Œæœ€ç»ˆ `5-shot` ç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼š\n\n### ç»“æœ\n\n|                Model                 | Humanities | Social Sciences |   STEM   |  Other   | Average  |\n| :----------------------------------: | :--------: | :-------------: | :------: | :------: | :------: |\n|        ChatGLM-6B<sup>0</sup>        |    35.4    |      41.0       |   31.3   |   40.5   |   36.9   |\n|        BLOOMZ-7B<sup>0</sup>         |    31.3    |      42.1       |   34.4   |   39.0   |   36.1   |\n|          mpt-7B<sup>1</sup>          |     -      |        -        |    -     |    -     |   35.6   |\n|         LLaMA-7B<sup>2</sup>         |    34.0    |      38.3       |   30.5   |   38.1   |   35.1   |\n|        Falcon-7B<sup>1</sup>         |     -      |        -        |    -     |    -     |   35.0   |\n| moss-moon-003-sft (16B)<sup>0</sup>  |    30.5    |      33.8       |   29.3   |   34.4   |   31.9   |\n|         BLOOM-7B<sup>0</sup>         |    25.0    |      24.4       |   26.5   |   26.4   |   25.5   |\n| moss-moon-003-base (16B)<sup>0</sup> |    24.2    |      22.8       |   22.4   |   24.4   |   23.6   |\n|     **Baichuan-7B<sup>0</sup>**      |  **38.4**  |    **48.9**     | **35.6** | **48.1** | **42.3** |\n\n<sup>0: é‡æ–°å¤ç°</sup><br/>\n<sup>1: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard</sup><br/>\n<sup>2: https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu</sup><br/>\n\n### å¤ç°æ–¹æ³•\n\n```bash\ngit clone https://github.com/hendrycks/test\ncd test\nwget https://people.eecs.berkeley.edu/~hendrycks/data.tar\ntar xf data.tar\nmkdir results\ncp ../evaluate_mmlu.py .\npython evaluate_mmlu.py -m /path/to/Baichuan-7B\n```\n\nå…¶ä¸­åœ¨ MMLU ä¸Š57ä¸ªä»»åŠ¡çš„å…·ä½“ç»†æŒ‡æ ‡å¦‚ä¸‹å›¾ï¼š\n<p align=\"center\">\n    <img src=\"media/MMLU-57-tasks.png\" width=\"90%\"/>\n</p>\n\nå…¶ä¸­å„ä¸ªå­¦ç§‘çš„æŒ‡æ ‡å¦‚ä¸‹å›¾ï¼š\n<p align=\"center\">\n    <img src=\"media/MMLU 21 Subjects.png\" width=\"90%\"/>\n</p>\n\n# æ¨ç†æ–¹æ³•\n\næ¨ç†ä»£ç å·²ç»åœ¨[å®˜æ–¹ Huggingface åº“](https://huggingface.co/baichuan-inc/Baichuan-7B)\n\n```python\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"baichuan-inc/Baichuan-7B\", trust_remote_code=True)\nmodel = AutoModelForCausalLM.from_pretrained(\"baichuan-inc/Baichuan-7B\", device_map=\"auto\", trust_remote_code=True)\ninputs = tokenizer('ç™»é¹³é›€æ¥¼->ç‹ä¹‹æ¶£\\nå¤œé›¨å¯„åŒ—->', return_tensors='pt')\ninputs = inputs.to('cuda:0')\npred = model.generate(**inputs, max_new_tokens=64,repetition_penalty=1.1)\nprint(tokenizer.decode(pred.cpu()[0], skip_special_tokens=True))\n\n```\n\n# æ•°æ®\n\n* åŸå§‹æ•°æ®åŒ…æ‹¬å¼€æºçš„ä¸­è‹±æ–‡æ•°æ®å’Œè‡ªè¡ŒæŠ“å–çš„ä¸­æ–‡äº’è”ç½‘æ•°æ®ï¼Œä»¥åŠéƒ¨åˆ†é«˜è´¨é‡çŸ¥è¯†æ€§æ•°æ®ã€‚\n* å‚è€ƒç›¸å…³æ•°æ®å·¥ä½œï¼Œé¢‘ç‡å’Œè´¨é‡æ˜¯æ•°æ®å¤„ç†ç¯èŠ‚é‡ç‚¹è€ƒè™‘çš„ä¸¤ä¸ªç»´åº¦ã€‚ æˆ‘ä»¬åŸºäºå¯å‘å¼è§„åˆ™å’Œè´¨é‡æ¨¡å‹æ‰“åˆ†ï¼Œå¯¹åŸå§‹æ•°æ®é›†è¿›è¡Œç¯‡ç« å’Œå¥å­ç²’åº¦çš„è¿‡æ»¤ã€‚åœ¨å…¨é‡æ•°æ®ä¸Šï¼Œåˆ©ç”¨å±€éƒ¨æ•æ„Ÿå“ˆå¸Œæ–¹æ³•ï¼Œå¯¹ç¯‡ç« å’Œå¥å­ç²’åº¦åšæ»¤é‡ã€‚\n\næ•´ä½“æµç¨‹å¦‚ä¸‹æ‰€ç¤ºï¼š\n<p align=\"center\">\n    <br>\n    <img src=\"media/data_process.png\" width=\"90%\"/>\n    <br>\n</p>\n\n* ç»è¿‡ä¸æ–­çš„è°ƒæ•´å’Œå¤šè½®æµ‹è¯•ï¼Œæœ€ç»ˆç¡®è®¤äº†ä¸€ä¸ªåœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸Šè¡¨ç°æœ€å¥½çš„ä¸­è‹±æ–‡é…æ¯”ã€‚\n* æˆ‘ä»¬ä½¿ç”¨äº†ä¸€ä¸ªåŸºäºè‡ªåŠ¨å­¦ä¹ çš„æ•°æ®æƒé‡ç­–ç•¥ï¼Œå¯¹ä¸åŒç±»åˆ«çš„æ•°æ®è¿›è¡Œé…æ¯”ã€‚\n\n# åˆ†è¯\n\næˆ‘ä»¬å‚è€ƒå­¦æœ¯ç•Œæ–¹æ¡ˆä½¿ç”¨ SentencePiece ä¸­çš„ Byte-Pair Encoding (BPE) ä½œä¸ºåˆ†è¯ç®—æ³•ï¼Œå¹¶ä¸”è¿›è¡Œäº†ä»¥ä¸‹çš„ä¼˜åŒ–ï¼š\n\n1. ç›®å‰å¤§éƒ¨åˆ†å¼€æºæ¨¡å‹ä¸»è¦åŸºäºè‹±æ–‡ä¼˜åŒ–ï¼Œå› æ­¤å¯¹ä¸­æ–‡è¯­æ–™å­˜åœ¨æ•ˆç‡è¾ƒä½çš„é—®é¢˜ã€‚æˆ‘ä»¬ä½¿ç”¨ 2000 ä¸‡æ¡ä»¥ä¸­è‹±ä¸ºä¸»çš„å¤šè¯­è¨€è¯­æ–™è®­ç»ƒåˆ†è¯æ¨¡å‹ï¼Œæ˜¾è‘—æå‡å¯¹äºä¸­æ–‡çš„å‹ç¼©ç‡ã€‚\n2. å¯¹äºæ•°å­¦é¢†åŸŸï¼Œæˆ‘ä»¬å‚è€ƒäº† LLaMA å’Œ Galactica ä¸­çš„æ–¹æ¡ˆï¼Œå¯¹æ•°å­—çš„æ¯ä¸€ä½å•ç‹¬åˆ†å¼€ï¼Œé¿å…å‡ºç°æ•°å­—ä¸ä¸€è‡´çš„é—®é¢˜ï¼Œå¯¹äºæå‡æ•°å­¦èƒ½åŠ›æœ‰é‡è¦å¸®åŠ©ã€‚\n3. å¯¹äºç½•è§å­—è¯ï¼ˆå¦‚ç‰¹æ®Šç¬¦å·ç­‰ï¼‰ï¼Œæ”¯æŒ UTF-8 characters çš„ byte ç¼–ç ï¼Œå› æ­¤åšåˆ°æœªçŸ¥å­—è¯çš„å…¨è¦†ç›–ã€‚\n4. æˆ‘ä»¬åˆ†æäº†ä¸åŒåˆ†è¯å™¨å¯¹è¯­æ–™çš„å‹ç¼©ç‡ï¼Œå¦‚ä¸‹è¡¨ï¼Œå¯è§æˆ‘ä»¬çš„åˆ†è¯å™¨æ˜æ˜¾ä¼˜äº LLaMA, Falcon ç­‰å¼€æºæ¨¡å‹ï¼Œå¹¶ä¸”å¯¹æ¯”å…¶ä»–ä¸­æ–‡åˆ†è¯å™¨åœ¨å‹ç¼©ç‡ç›¸å½“çš„æƒ…å†µä¸‹ï¼Œè®­ç»ƒå’Œæ¨ç†æ•ˆç‡æ›´é«˜ã€‚\n\n|     Model     | Baichuan-7B | LLaMA  | Falcon | mpt-7B | ChatGLM | moss-moon-003 |\n| :-----------: | :---------: | :----: | :----: | :----: | :-----: | :-----------: |\n| Compress Rate |    0.737    | 1.312  | 1.049  | 1.206  |  0.631  |     0.659     |\n|  Vocab Size   |   64,000    | 32,000 | 65,024 | 50,254 | 130,344 |    106,029    |\n\n# æ¨¡å‹ç»“æ„\n\næ•´ä½“æ¨¡å‹åŸºäºæ ‡å‡†çš„ Transformer ç»“æ„ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†å’Œ LLaMA ä¸€æ ·çš„æ¨¡å‹è®¾è®¡\n\n* ä½ç½®ç¼–ç ï¼š[rotary-embedding](https://arxiv.org/abs/2104.09864) æ˜¯ç°é˜¶æ®µè¢«å¤§å¤šæ¨¡å‹é‡‡ç”¨çš„ä½ç½®ç¼–ç æ–¹æ¡ˆï¼Œå…·æœ‰æ›´å¥½çš„å¤–å»¶æ•ˆæœã€‚è™½ç„¶è®­ç»ƒè¿‡ç¨‹ä¸­æœ€å¤§é•¿åº¦ä¸º4096ï¼Œä½†æ˜¯å®é™…æµ‹è¯•ä¸­æ¨¡å‹å¯ä»¥å¾ˆå¥½çš„æ‰©å±•åˆ° 5000 tokens ä»¥ä¸Šï¼Œå¦‚ä¸‹å›¾ï¼š\n\n<p align=\"center\">\n    <img src=\"media/long-context-ppl.png\" width=\"90%\"/>\n</p>\n\n* æ¿€æ´»å±‚ï¼šSwiGLU, Feedforward å˜åŒ–ä¸º 8/3 å€çš„éšå«å±‚å¤§å°ï¼Œå³ 11,008\n* Layer-Normalization: åŸºäº [RMSNorm](https://arxiv.org/abs/1910.07467) çš„ Pre-Normalization\n\n# è®­ç»ƒç¨³å®šæ€§å’Œåå\n\næˆ‘ä»¬åœ¨åŸæœ¬çš„ LLaMA æ¡†æ¶ä¸Šè¿›è¡Œè¯¸å¤šä¿®æ”¹ä»¥æå‡è®­ç»ƒæ—¶çš„ååï¼Œå…·ä½“åŒ…æ‹¬ï¼š\n\n1. ç®—å­ä¼˜åŒ–æŠ€æœ¯ï¼šé‡‡ç”¨æ›´é«˜æ•ˆç®—å­ï¼Œå¦‚ Flash-Attentionï¼ŒNVIDIA apex çš„ RMSNorm ç­‰ã€‚\n2. ç®—å­åˆ‡åˆ†æŠ€æœ¯ï¼šå°†éƒ¨åˆ†è®¡ç®—ç®—å­è¿›è¡Œåˆ‡åˆ†ï¼Œå‡å°å†…å­˜å³°å€¼ã€‚\n3. æ··åˆç²¾åº¦æŠ€æœ¯ï¼šé™ä½åœ¨ä¸æŸå¤±æ¨¡å‹ç²¾åº¦çš„æƒ…å†µä¸‹åŠ é€Ÿè®¡ç®—è¿‡ç¨‹ã€‚\n4. è®­ç»ƒå®¹ç¾æŠ€æœ¯ï¼šè®­ç»ƒå¹³å°å’Œè®­ç»ƒæ¡†æ¶è”åˆä¼˜åŒ–ï¼ŒIaaS + PaaS å®ç°åˆ†é’Ÿçº§çš„æ•…éšœå®šä½å’Œä»»åŠ¡æ¢å¤ã€‚\n5. é€šä¿¡ä¼˜åŒ–æŠ€æœ¯ï¼Œå…·ä½“åŒ…æ‹¬ï¼š\n   1. é‡‡ç”¨æ‹“æ‰‘æ„ŸçŸ¥çš„é›†åˆé€šä¿¡ç®—æ³•ï¼Œé¿å…ç½‘ç»œæ‹¥å¡é—®é¢˜ï¼Œæé«˜é€šä¿¡æ•ˆç‡ã€‚\n   2. æ ¹æ®å¡æ•°è‡ªé€‚åº”è®¾ç½® bucket sizeï¼Œæé«˜å¸¦å®½åˆ©ç”¨ç‡ã€‚\n   3. æ ¹æ®æ¨¡å‹å’Œé›†ç¾¤ç¯å¢ƒï¼Œè°ƒä¼˜é€šä¿¡åŸè¯­çš„è§¦å‘æ—¶æœºï¼Œä»è€Œå°†è®¡ç®—å’Œé€šä¿¡é‡å ã€‚\n\nåŸºäºä¸Šè¿°çš„å‡ ä¸ªä¼˜åŒ–æŠ€æœ¯ï¼Œæˆ‘ä»¬åœ¨åƒå¡ A800 æ˜¾å¡ä¸Šè¾¾åˆ°äº† 7B æ¨¡å‹ 182 TFLOPS çš„ååï¼ŒGPU å³°å€¼ç®—åŠ›åˆ©ç”¨ç‡é«˜è¾¾ 58.3%ã€‚\n\næœ€ç»ˆçš„losså¦‚ä¸‹å›¾ï¼š\n<p align=\"center\">\n    <img src=\"media/7b.loss.png\" width=\"90%\"/>\n</p>\n\n# è®­ç»ƒæ–¹æ³•\n\n## å®‰è£…ä¾èµ–\n\n```bash\npip install -r requirements.txt\n```\n\n## å‡†å¤‡æ•°æ®\n\nç”¨æˆ·å°†è®­ç»ƒè¯­æ–™æŒ‰æ€»rankæ•°çš„å€æ•°å‡åŒ€åˆ‡åˆ†æˆå¤šä¸ª UTF-8 æ–‡æœ¬æ–‡ä»¶ï¼Œæ”¾ç½®åœ¨è¯­æ–™ç›®å½•ï¼ˆé»˜è®¤ä¸º `data_dir` ï¼‰ä¸‹ã€‚å„ä¸ªrankè¿›ç¨‹å°†ä¼šè¯»å–è¯­æ–™ç›®å½•ä¸‹çš„ä¸åŒæ–‡ä»¶ï¼Œå…¨éƒ¨åŠ è½½åˆ°å†…å­˜åï¼Œå¼€å§‹åç»­è®­ç»ƒè¿‡ç¨‹ã€‚ä»¥ä¸Šæ˜¯ç®€åŒ–çš„ç¤ºèŒƒæµç¨‹ï¼Œå»ºè®®ç”¨æˆ·åœ¨æ­£å¼è®­ç»ƒä»»åŠ¡ä¸­ï¼Œæ ¹æ®éœ€æ±‚è°ƒæ•´æ•°æ®ç”Ÿäº§é€»è¾‘ã€‚\n\n## ä¸‹è½½ tokenizer æ¨¡å‹\n\nä¸‹è½½ tokenizer æ¨¡å‹æ–‡ä»¶ [tokenizer.model](https://huggingface.co/baichuan-inc/Baichuan-7B/blob/main/tokenizer.model) ï¼Œæ”¾ç½®åœ¨é¡¹ç›®ç›®å½•ä¸‹ã€‚\n\n## é…ç½® DeepSpeed\n\næœ¬ç¤ºèŒƒä»£ç é‡‡ç”¨ DeepSpeed æ¡†æ¶è¿›è¡Œè®­ç»ƒã€‚ç”¨æˆ·éœ€æ ¹æ®é›†ç¾¤æƒ…å†µï¼Œä¿®æ”¹ `config/hostfile` ï¼Œå¦‚æœæ˜¯å¤šæœºå¤šå¡ï¼Œéœ€è¦ä¿®æ”¹ ssh ä¸­å„ä¸ªèŠ‚ç‚¹çš„ IP é…ç½®ã€‚å…·ä½“å¯ä»¥å‚è§ DeepSpeed [å®˜æ–¹è¯´æ˜](https://www.deepspeed.ai/) ã€‚\n\n## æ‰§è¡Œè®­ç»ƒ\n\n```python\nscripts/train.sh\n```\n\n# åè®®\n\nå¯¹æœ¬ä»“åº“æºç çš„ä½¿ç”¨éµå¾ªå¼€æºè®¸å¯åè®® [Apache 2.0](https://github.com/baichuan-inc/Baichuan-7B/blob/main/LICENSE)ã€‚\n\nBaichuan-7B æ”¯æŒå•†ç”¨ã€‚å¦‚æœå°† Baichuan-7B æ¨¡å‹æˆ–å…¶è¡ç”Ÿå“ç”¨ä½œå•†ä¸šç”¨é€”ï¼Œè¯·æ‚¨æŒ‰ç…§å¦‚ä¸‹æ–¹å¼è”ç³»è®¸å¯æ–¹ï¼Œä»¥è¿›è¡Œç™»è®°å¹¶å‘è®¸å¯æ–¹ç”³è¯·ä¹¦é¢æˆæƒï¼šè”ç³»é‚®ç®±ï¼š<opensource@baichuan-inc.com>ï¼Œ å…·ä½“è®¸å¯åè®®å¯è§[ã€ŠBaichuan-7B æ¨¡å‹è®¸å¯åè®®ã€‹](https://huggingface.co/baichuan-inc/Baichuan-7B/resolve/main/baichuan-7B%20%E6%A8%A1%E5%9E%8B%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf)ã€‚\n\n# Third-Party Resources\n\n1. [LLaMA Efficient Tuning](https://github.com/hiyouga/LLaMA-Efficient-Tuning) æ”¯æŒBaichuan-7Bä½¿ç”¨Qloraè¿›è¡ŒFinetuneï¼Œæ”¯æŒRLHFï¼Œæ”¯æŒWebDemoã€‚ä½¿ç”¨ç»è¿‡sftçš„æ¨¡å‹è§ [hiyouga/baichuan-7b-sft](https://huggingface.co/hiyouga/baichuan-7b-sft)ã€‚\n2. [fireballoon/baichuan-vicuna-chinese-7b](https://huggingface.co/fireballoon/baichuan-vicuna-chinese-7b) ä½¿ç”¨ ShareGPT, ShareGPT-ZH, COT & COT-ZH, Leetcode, dummyç­‰åŒ…å«ä¸­è‹±æ–‡çš„æ•°æ®Finetuneåçš„æ¨¡å‹ï¼Œè®­ç»ƒä»£ç å‚è€ƒFastChatã€‚\n3. [fireballoon/baichuan-vicuna-7b](https://huggingface.co/fireballoon/baichuan-vicuna-7b) ä½¿ç”¨ShareGPT, COT å’Œ Leetcodeç­‰æ•°æ®æ··åˆFinetuneåçš„æ¨¡å‹ï¼Œè®­ç»ƒä»£ç å‚è€ƒFastChatã€‚\n4. [Efficient-Tuning-LLMs](https://github.com/jianzhnie/Efficient-Tuning-LLMs) æ”¯æŒBaichuan-7Bä½¿ç”¨Qloraè¿›è¡ŒFinetuneå’Œ4bit inferenceã€‚\n5. [fastllm](https://github.com/ztxz16/fastllm) fastllmæ˜¯çº¯c++å®ç°ï¼Œæ— ç¬¬ä¸‰æ–¹ä¾èµ–çš„å¤§æ¨¡å‹åº“ï¼Œæ”¯æŒBaichuan-7Båœ¨æ‰‹æœºç«¯è¿è¡Œã€‚\n6. [TheBloke/baichuan-7B-GPTQ](https://huggingface.co/TheBloke/baichuan-7B-GPTQ) å¯¹Baichuan-7Bçš„GPTQ 4bité‡åŒ–ã€‚\n\n# Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=baichuan-inc/Baichuan-7B&type=Date)](https://star-history.com/#baichuan-inc/Baichuan-7B&Date)\n"
        },
        {
          "name": "README_EN.md",
          "type": "blob",
          "size": 15.4560546875,
          "content": "<!-- markdownlint-disable first-line-h1 -->\n<!-- markdownlint-disable html -->\n\n<div align=\"center\">\n<h1>\n  Baichuan-7B\n</h1>\n</div>\n\n<p align=\"center\">\nğŸ¤— <a href=\"https://huggingface.co/baichuan-inc/Baichuan-7B\" target=\"_blank\">Hugging Face</a> â€¢ ğŸ¤– <a href=\"https://modelscope.cn/organization/baichuan-inc\" target=\"_blank\">ModelScope</a> â€¢ ğŸ’¬ <a href=\"https://github.com/baichuan-inc/Baichuan-7B/blob/main/media/wechat.jpeg?raw=true\" target=\"_blank\">WeChat</a>\n</p>\n\n[![license](https://img.shields.io/github/license/modelscope/modelscope.svg)](https://github.com/baichuan-inc/Baichuan-7B/blob/main/LICENSE)\n<h4 align=\"center\">\n    <p>\n        <b>English</b> |\n        <a href=\"https://github.com/baichuan-inc/Baichuan-7B/blob/main/README.md\">ä¸­æ–‡</a>\n    <p>\n</h4>\n</div>\n\n# Introduction\n\nBaichuan-7B is an open-source, large-scale pre-trained language model developed by Baichuan Intelligent Technology. Baichuan-7B is based on Transformer architecture, which contains 7 billion parameters and trained on approximately 1.2 trillion tokens. It supports both Chinese and English languages with a context window length of 4096. It has achieved the best performance among models of the same size on standard Chinese and English benchmarks (C-Eval, MMLU, etc).\n\n# Benchmark\n\n## Chinese Benchmarks\n\n### C-Eval\n\n[C-Eval](https://cevalbenchmark.com/index.html) is a comprehensive Chinese language models evaluation dataset, covering 52 subjects and four levels of difficulty. We used the dev set from this dataset as the source for few-shot learning and conducted a 5-shot test on the test set.\n\nChange OPENMODEL_PATH and CEVAL_DATA_PATH in evaluate_zh.py, corresponding to model's and C-Eval dataset's directories, then run:\n\n```bash\ncd evaluation\npython evaluate_zh.py --model_name_or_path 'your/model/path'\n```\n\n#### Results\n\n|        Model 5-shot         | Average | Avg(Hard) | STEM  | Social Sciences | Humanities | Others |\n| :-------------------------: | :-----: | :-------: | :---: | :-------------: | :--------: | :----: |\n|            GPT-4            |  68.7   |   54.9    | 67.1  |      77.6       |    64.5    |  67.8  |\n|           ChatGPT           |  54.4   |   41.4    | 52.9  |      61.8       |    50.9    |  53.6  |\n|         Claude-v1.3         |  54.2   |   39.0    | 51.9  |      61.7       |    52.1    |  53.7  |\n|     Claude-instant-v1.0     |  45.9   |   35.5    | 43.1  |      53.8       |    44.2    |  45.4  |\n|          BLOOMZ-7B          |  35.7   |   25.8    | 31.3  |      43.5       |    36.6    |  35.6  |\n|         ChatGLM-6B          |  34.5   |   23.1    | 30.4  |      39.6       |    37.4    |  34.5  |\n|   Ziya-LLaMA-13B-pretrain   |  30.2   |   22.7    | 27.7  |      34.4       |    32.0    |  28.9  |\n|  moss-moon-003-base (16B)   |  27.4   |   24.5    | 27.0  |      29.1       |    27.2    |  26.9  |\n|         LLaMA-7B-hf         |  27.1   |   25.9    | 27.1  |      26.8       |    27.9    |  26.3  |\n|          Falcon-7B          |  25.8   |   24.3    | 25.8  |      26.0       |    25.8    |  25.6  |\n|      TigerBot-7B-base       |  25.7   |   27.0    | 27.3  |      24.7       |    23.4    |  26.1  |\n|    Aquila-7B<sup>*</sup>    |  25.5   |   25.2    | 25.6  |      24.6       |    25.2    |  26.6  |\n| Open-LLaMA-v2-pretrain (7B) |  24.0   |   22.5    | 23.1  |      25.3       |    25.2    |  23.2  |\n|          BLOOM-7B           |  22.8   |   20.2    | 21.8  |      23.3       |    23.9    |  23.3  |\n|       **Baichuan-7B**       |  42.8   |   31.5    | 38.2  |      52.0       |    46.2    |  39.3  |\n\n### Gaokao\n\n[Gaokao](https://github.com/OpenLMLab/GAOKAO-Bench) is an evaluation dataset curated from questions used in Chinese College Entrance Examination, to evaluate the capabilities of large language models, assessing models' language ability and logical reasoning skills. We processed the dataset to only containing single-answer multiple choice questions, we conducted a 5-shot test on all models.\n\n#### Results\n\n|          Model          |  Average  |\n| :---------------------: | :-------: |\n|        BLOOMZ-7B        |   28.72   |\n|        LLaMA-7B         |   27.81   |\n|        BLOOM-7B         |   26.96   |\n|    TigerBot-7B-base     |   25.94   |\n|        Falcon-7B        |   23.98   |\n| Ziya-LLaMA-13B-pretrain |   23.17   |\n|       ChatGLM-6B        |   21.41   |\n| Open-LLaMA-v2-pretrain  |   21.41   |\n|  Aquila-7B<sup>*</sup>  |   24.39   |\n|     **Baichuan-7B**     | **36.24** |\n\n### AGIEval\n\n[AGIEval](https://github.com/microsoft/AGIEval) is a dataset aimed at evaluating models' general abilities in cognitive and problem-solving tasks.\nwe conducted a 5-shot test on all models.\n\n#### Results\n\n|          Model          |  Average  |\n| :---------------------: | :-------: |\n|        BLOOMZ-7B        |   30.27   |\n|        LLaMA-7B         |   28.17   |\n| Ziya-LLaMA-13B-pretrain |   27.64   |\n|        Falcon-7B        |   27.18   |\n|        BLOOM-7B         |   26.55   |\n|  Aquila-7B<sup>*</sup>  |   25.58   |\n|    TigerBot-7B-base     |   25.19   |\n|       ChatGLM-6B        |   23.49   |\n| Open-LLaMA-v2-pretrain  |   23.49   |\n|     **Baichuan-7B**     | **34.44** |\n\n<sup>*The Aquila-7b are not implemented on Huggingface yet so we derived the model from (https://model.baai.ac.cn/model-detail/100098), which may have not identical to their official result.</sup><br/>\n\n## English Benchmarks\n\nIn addition to Chinese, we also tested the performance of models in English. [MMLU](https://arxiv.org/abs/2009.03300) is an English evaluation dataset that includes 57 multiple-choice tasks, covering elementary mathematics, American history, computer science, law, etc. The difficulty spans from high school level to expert level, making it a mainstream evaluation dataset for Large Language Models (LLMs).\n\nWe adopt the public implementation of (https://github.com/hendrycks/test) and the final result is shown belowï¼š\n\n### Results on MMLU\n\n| Model                                | Humanities | Social Sciences |   STEM   |  Other   | Average  |\n| ------------------------------------ | ---------: | :-------------: | :------: | :------: | :------: |\n| ChatGLM-6B<sup>0</sup>               |       35.4 |      41.0       |   31.3   |   40.5   |   36.9   |\n| BLOOMZ-7B<sup>0</sup>                |       31.3 |      42.1       |   34.4   |   39.0   |   36.1   |\n| mpt-7B<sup>1</sup>                   |          - |        -        |    -     |    -     |   35.6   |\n| LLaMA-7B<sup>2</sup>                 |       34.0 |      38.3       |   30.5   |   38.1   |   35.1   |\n| Falcon-7B<sup>1</sup>                |          - |        -        |    -     |    -     |   35.0   |\n| moss-moon-003-sft (16B)<sup>0</sup>  |       30.5 |      33.8       |   29.3   |   34.4   |   31.9   |\n| BLOOM-7B<sup>0</sup>                 |       25.0 |      24.4       |   26.5   |   26.4   |   25.5   |\n| moss-moon-003-base (16B)<sup>0</sup> |       24.2 |      22.8       |   22.4   |   24.4   |   23.6   |\n| **Baichuan-7B<sup>0</sup>**          |   **38.4** |    **48.9**     | **35.6** | **48.1** | **42.3** |\n\n<sup>0: Our implementation</sup><br/>\n<sup>1: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard</sup><br/>\n<sup>2: https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu</sup><br/>\n\n### How to implement by yourself\n\n```bash\ngit clone https://github.com/hendrycks/test\ncd test\nwget https://people.eecs.berkeley.edu/~hendrycks/data.tar\ntar xf data.tar\nmkdir results\ncp ../evaluate_mmlu.py .\npython evaluate_mmlu.py -m /path/to/Baichuan-7B\n```\n\nSpecifically, the result of 57 MMLU tasks is:\n<p align=\"center\">\n    <img src=\"media/MMLU-57-tasks.png\" width=\"90%\"/>\n</p>\n\nAnd the comparison of 21 different subjects isï¼š\n<p align=\"center\">\n    <img src=\"media/MMLU 21 Subjects.png\" width=\"90%\"/>\n</p>\n\n# Inference\n\n```python\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"baichuan-inc/Baichuan-7B\", trust_remote_code=True)\nmodel = AutoModelForCausalLM.from_pretrained(\"baichuan-inc/Baichuan-7B\", device_map=\"auto\", trust_remote_code=True)\ninputs = tokenizer('Hamlet->Shakespeare\\nOne Hundred Years of Solitude->', return_tensors='pt')\ninputs = inputs.to('cuda:0')\npred = model.generate(**inputs, max_new_tokens=64)\nprint(tokenizer.decode(pred.cpu()[0], skip_special_tokens=True))\n\n```\n\n# Data\n\n* The original corpora includes open-source Chinese and English data, self-crawled Chinese internet data, and some high-quality knowledge-intensive data.\n* Referring to related data work, frequency and quality are two dimensions that are considered important in the data processing stage. We apply heuristic rules and quality model scoring to filter the original dataset at both the paragraph and sentence levels. Employing the Locality-Sensitive Hashing (LSH) method on the full dataset, we perform de-duplication at both the paragraph and sentence levels.\n\nThe whole data processing process is shown below:\n<p align=\"center\">\n    <br>\n    <img src=\"media/data_process.png\" width=\"90%\"/>\n    <br>\n</p>\n\n* After continuous adjustments and multiple rounds of testing, we finally determined the best Chinese to English ratio that are optimized on downstream tasks.\n* We used an automatic algorithm-based data sampling strategy to balance the weights of different data categories.\n\n# Tokenization\n\nWe use the byte pair encoding (BPE) from SentencePiece as the tokenization algorithm, along with the following optimizations:\n\n1. Most open-source models are primarily optimized for English, resulting in low efficiency for Chinese corpus. So we trained the tokenizer using 20 million multilingual corpora mainly composed of Chinese and English, significantly improving the compression rate for Chinese.\n2. To improve the ability for mathematics, we split all numbers into individual digits that is also adopted in LLaMA and Galactica, separately tokenizing each digit to avoid inconsistencies in numbers.\n3. For rare words (such as emoji and special symbols), we fallback unknown characters to byte encoding of UTF-8, thus achieving full coverage of unknown words.\n4. We analyzed the compression rate of different tokenizers on the corpus. As shown in the following table, our tokenizer significantly outperforms open-source models like LLaMA, Falcon, and others. Compared to other Chinese tokenizers with similar compression rates, it offers higher training and inference efficiency. \n\n|     Model     | Baichuan-7B | LLaMA  | Falcon | mpt-7B | ChatGLM | moss-moon-003 |\n| :-----------: | :---------: | :----: | :----: | :----: | :-----: | :-----------: |\n| Compress Rate |    0.737    | 1.312  | 1.049  | 1.206  |  0.631  |     0.659     |\n|  Vocab Size   |   64,000    | 32,000 | 65,024 | 50,254 | 130,344 |    106,029    |\n\n# Model Architecture\n\nThe overall model is based on the standard Transformer structure, and we have adopted a model design similar to that of LLaMA.\n\n* Positional Embeddings: [rotary-embedding](https://arxiv.org/abs/2104.09864) is the widely used positional encoding method, with better extrapolation effects. Although the maximum length during training is 4096, the model can be well extrapolated to 5000 tokens in inference time, as shown in the following diagram:\n\n<p align=\"center\">\n<img src=\"media/long-context-ppl.png\" width=\"90%\"/>\n</p>\n\n* Activationï¼šSwiGLU, and the dimension of the feedforward-layer is set to 11,008\n* Layer-Normalization: We use the Pre-Normalization method based on [RMSNorm](https://arxiv.org/abs/1910.07467)\n\n## Training stability and Throughput\n\nWe made numerous modifications to the original LLaMA framework to improve throughput during training, including:\n\n1. Operator optimization technology: We adopted more efficient operators, such as Flash-attention, NVIDIA apex's RMSNorm, etc.\n2. Tensor partitioning technology: We partitioned some computational operators to reduce peak memory usage.\n3. Mixed-precision technology: This accelerates the computational process without sacrificing model accuracy.\n4. Training failure recovery technology: The training platform and the training framework were jointly optimized. By combining IaaS and PaaS, we can locate faults and recover tasks within minutes.\n5. Communication optimization technology which includes:\n   1. Topology-aware collective communication algorithms to avoid network congestion and improve communication efficiency.\n   2. Adaptive setting of bucket size based on the number of cards to improve bandwidth utilization.\n   3. Tuning the trigger timing of communication primitives based on the model and the cluster environment, thereby overlapping computation and communication. \n\nBy using these optimization techniques, we achieved a throughput of 182 TFLOPS for the 7B model on thousand A800 GPUs, with a peak GPU computing power utilization rate of up to 58.3%.\n\nThe final loss of the model is shown belowï¼š\n<p align=\"center\">\n    <img src=\"media/7b.loss.png\" width=\"90%\"/>\n</p>\n\n# Training\n\n## Install requirements\n\n```bash\npip install -r requirements.txt\n```\n\n## Prepare pre-training datasets\n\nYou should divide the training corpus into multiple UTF-8 text files evenly according to the multiple of the total rank number, and place them in the corpus directory (default is `data_dir`). Each rank processor will read different files in the corpus directory, load them all into memory, and then start the subsequent training process. The above is a simplified demonstration process. It is recommended that users adjust the data production logic according to their needs in formal training tasks.\n\n## Download tokenizer\n\nYou can download our [tokenizer.model](https://huggingface.co/baichuan-inc/Baichuan-7B/blob/main/tokenizer.model) from the Huggingface, and place them in the root director.\n   \n## Config DeepSpeed\n\nThis demo code uses the DeepSpeed framework for training. Users should modify `config/hostfile` according to the cluster conditions.\n\n## Start training\n\n```bash\nscripts/train.sh\n```\n\n# License\n\nThe use of the source code in this repository is governed by the open source license [Apache 2.0](https://github.com/baichuan-inc/Baichuan-7B/blob/main/LICENSE) .\n\nThe use of the Baichuan-7B model weights, however, must follow the [ã€ŠBaichuan-7B æ¨¡å‹è®¸å¯åè®®ã€‹](https://huggingface.co/baichuan-inc/Baichuan-7B/resolve/main/baichuan-7B%20%E6%A8%A1%E5%9E%8B%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf) .\n\n# Third-Party Resources\n\n1. [LLaMA Efficient Tuning](https://github.com/hiyouga/LLaMA-Efficient-Tuning) supports Baichuan-7B to use Qlora for finetuning, supports RLHF, and supports WebDemo. For models that have gone through sft, see [hiyouga/baichuan-7b-sft](https://huggingface.co/hiyouga/baichuan-7b-sft).\n2. [fireballoon/baichuan-vicuna-chinese-7b](https://huggingface.co/fireballoon/baichuan-vicuna-chinese-7b) uses ShareGPT, ShareGPT-ZH, COT & COT-ZH, Leetcode, dummy, and other Chinese and English data for finetuning. For training code, refer to FastChat.\n3. [fireballoon/baichuan-vicuna-7b](https://huggingface.co/fireballoon/baichuan-vicuna-7b) uses ShareGPT, COT, and Leetcode, among other data, for mixed finetuning. For training code, refer to FastChat.\n4. [Efficient-Tuning-LLMs](https://github.com/jianzhnie/Efficient-Tuning-LLMs) supports Baichuan-7B to use Qlora for finetuning and 4bit inference.\n5. [fastllm](https://github.com/ztxz16/fastllm) is a large model library implemented purely in C++, with no third-party dependencies, and supports Baichuan-7B to run on mobile devices.\n6. [TheBloke/baichuan-7B-GPTQ](https://huggingface.co/TheBloke/baichuan-7B-GPTQ) is for the 4bit quantization of Baichuan-7B's GPTQ.\n\n# Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=baichuan-inc/Baichuan-7B&type=Date)](https://star-history.com/#baichuan-inc/Baichuan-7B&Date)\n"
        },
        {
          "name": "config",
          "type": "tree",
          "content": null
        },
        {
          "name": "evaluation",
          "type": "tree",
          "content": null
        },
        {
          "name": "media",
          "type": "tree",
          "content": null
        },
        {
          "name": "models",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.1015625,
          "content": "deepspeed==0.9.2\nnumpy==1.23.5\nsentencepiece==0.1.97\ntorch==2.0.0\ntransformers==4.29.1\nxformers==0.0.20\n"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "train.py",
          "type": "blob",
          "size": 5.1474609375,
          "content": "# Copyright 2023 Baichuan Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport json\nimport os\n\nimport argparse\nimport deepspeed\nimport deepspeed.comm as dist\nimport numpy as np\nimport sentencepiece as spm\nimport torch\n\nfrom models.configuration_baichuan import BaiChuanConfig\nfrom models.modeling_baichuan import BaiChuanForCausalLM\n\n\ndef get_argument_parser():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--data_dir\", type=str, default=\"data_dir\",\n                        help=\"Text files to do pre-train on\")\n\n    parser.add_argument(\"--tokenizer_path\", type=str,\n                        default=\"tokenizer.model\",\n                        help=\"Tokenizer model file path\")\n\n    parser.add_argument(\"--max_length\", type=int, default=4096,\n                        help=\"Max tokens per sentence in corpus\")\n\n    parser.add_argument(\"--steps_per_epoch\", type=int, default=4096,\n                        help=\"Step intervals to save checkpoint\")\n\n    parser.add_argument(\"--checkpoint_saving_path\", type=str,\n                        default=\"checkpoints\",\n                        help=\"Path to store checkpoint files\")\n\n    parser.add_argument(\"--local_rank\", type=int, default=-1,\n                        help=\"Reserved for deepspeed framework\")\n    return parser\n\n\narg_parser = get_argument_parser()\narg_parser = deepspeed.add_config_arguments(arg_parser)\nargs = arg_parser.parse_args()\ndeepspeed.init_distributed()\n\n\nclass DataEngine():\n    def __init__(self, data_dir, tokenizer_path, micro_batch_size, max_length):\n        self.MIN_TEXT_LEN = 20\n        self.EOS_TOKEN_ID = 2\n        self.data_dir = data_dir\n        self.sp = spm.SentencePieceProcessor()\n        self.sp.Load(tokenizer_path)\n        self.micro_batch_size = micro_batch_size\n        self.max_length = max_length\n        self.data = []\n        self.global_input_paths = [self.data_dir + \"/\" + x\n                                   for x in os.listdir(self.data_dir)]\n        self.local_input_paths = [x for i, x in\n                                  enumerate(self.global_input_paths)\n                                  if i % dist.get_world_size() == dist.get_rank()]\n\n    def load_data(self):\n        for file_path in self.local_input_paths:\n            data = []\n            with open(file_path, encoding=\"utf-8\", errors=\"ignore\") as f:\n                for line_id, line in enumerate(f):\n                    cc = self.sp.EncodeAsIds(line.strip()) + [self.EOS_TOKEN_ID]\n                    if len(cc) < self.MIN_TEXT_LEN:\n                        cc = []\n                    data.extend(cc)\n                    if len(data) >= self.micro_batch_size * (self.max_length + 1):\n                        index = self.micro_batch_size * (self.max_length + 1)\n                        self.data.append(data[:index])\n                        data = []\n        return\n\n    def get_data(self):\n        data = self.data.pop(0)\n        seq = np.asarray(data).reshape(self.micro_batch_size, self.max_length + 1)\n        data = torch.LongTensor(seq)\n        data = data.cuda(non_blocking=True)\n        return data\n\n\ndef prepare_data():\n    data_dir = args.data_dir\n    tokenizer_path = args.tokenizer_path\n    ds_config = json.load(open(args.deepspeed_config))\n    micro_batch_size = ds_config[\"train_micro_batch_size_per_gpu\"]\n    max_length = args.max_length\n    data_engine = DataEngine(data_dir, tokenizer_path, micro_batch_size, max_length)\n    data_engine.load_data()\n    return data_engine\n\n\ndef prepare_model():\n    with deepspeed.zero.Init(config_dict_or_path=args.deepspeed_config,\n                             enabled=True,\n                             mem_efficient_linear=False,\n                             mpu=None):\n        model = BaiChuanForCausalLM(BaiChuanConfig())\n\n    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n    model_engine, _, _, _ = deepspeed.initialize(args=args,\n                                                 model=model,\n                                                 optimizer=None,\n                                                 model_parameters=model_parameters)\n    return model_engine\n\n\ndef train(data_engine, model_engine):\n    model_engine.train()\n    step = 0\n    while step < args.steps_per_epoch:\n        data = data_engine.get_data()\n        loss = model_engine(data, labels=data).loss\n        model_engine.backward(loss)\n        model_engine.step()\n        step += 1\n    return\n\n\nif __name__ == \"__main__\":\n    data_engine = prepare_data()\n    model_engine = prepare_model()\n    epoch = 0\n    while True:\n        train(data_engine, model_engine)\n        epoch += 1\n        model_engine.save_checkpoint(f\"{args.checkpoint_saving_path}\",\n                                     tag=f\"Epoch-{epoch}\")\n"
        }
      ]
    }
  ]
}