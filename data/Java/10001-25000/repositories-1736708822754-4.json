{
  "metadata": {
    "timestamp": 1736708822754,
    "page": 4,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjEw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "apache/flink",
      "stars": 24388,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".asf.yaml",
          "type": "blob",
          "size": 0.392578125,
          "content": "github:\n  enabled_merge_buttons:\n    squash: true\n    merge: false\n    rebase: true\n  labels:\n    - flink\n    - big-data\n    - java\n    - scala\n    - python\n    - sql\n  collaborators:\n    - flinkbot\nnotifications:\n  commits:      commits@flink.apache.org\n  issues:       issues@flink.apache.org\n  pullrequests: issues@flink.apache.org\n  jobs:         builds@flink.apache.org\n  jira_options: link label\n"
        },
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 11.583984375,
          "content": "root = true\n\n[*]\ncharset = utf-8\nend_of_line = lf\ninsert_final_newline = true\nmax_line_length = 100\n# ij_formatter_off_tag = @formatter:off\n# ij_formatter_on_tag = @formatter:on\n# ij_formatter_tags_enabled = false\n# ij_smart_tabs = false\n# ij_wrap_on_typing = false\n\n[*.java]\nindent_size = 4\nindent_style = space\ntab_width = 4\nij_continuation_indent_size = 8\n# ij_java_align_consecutive_assignments = false\n# ij_java_align_consecutive_variable_declarations = false\n# ij_java_align_group_field_declarations = false\n# ij_java_align_multiline_annotation_parameters = false\n# ij_java_align_multiline_array_initializer_expression = false\n# ij_java_align_multiline_assignment = false\n# ij_java_align_multiline_binary_operation = false\n# ij_java_align_multiline_chained_methods = false\n# ij_java_align_multiline_extends_list = false\n# ij_java_align_multiline_for = true\n# ij_java_align_multiline_method_parentheses = false\n# ij_java_align_multiline_parameters = true\n# ij_java_align_multiline_parameters_in_calls = false\n# ij_java_align_multiline_parenthesized_expression = false\n# ij_java_align_multiline_records = true\n# ij_java_align_multiline_resources = true\n# ij_java_align_multiline_ternary_operation = false\n# ij_java_align_multiline_text_blocks = false\n# ij_java_align_multiline_throws_list = false\n# ij_java_align_subsequent_simple_methods = false\n# ij_java_align_throws_keyword = false\n# ij_java_annotation_parameter_wrap = off\n# ij_java_array_initializer_new_line_after_left_brace = false\n# ij_java_array_initializer_right_brace_on_new_line = false\n# ij_java_array_initializer_wrap = off\n# ij_java_assert_statement_colon_on_next_line = false\n# ij_java_assert_statement_wrap = off\n# ij_java_assignment_wrap = off\nij_java_binary_operation_sign_on_next_line = true\nij_java_binary_operation_wrap = normal\n# ij_java_blank_lines_after_anonymous_class_header = 0\n# ij_java_blank_lines_after_class_header = 0\n# ij_java_blank_lines_after_imports = 1\n# ij_java_blank_lines_after_package = 1\n# ij_java_blank_lines_around_class = 1\n# ij_java_blank_lines_around_field = 0\n# ij_java_blank_lines_around_field_in_interface = 0\n# ij_java_blank_lines_around_initializer = 1\n# ij_java_blank_lines_around_method = 1\n# ij_java_blank_lines_around_method_in_interface = 1\n# ij_java_blank_lines_before_class_end = 0\n# ij_java_blank_lines_before_imports = 1\n# ij_java_blank_lines_before_method_body = 0\n# ij_java_blank_lines_before_package = 0\n# ij_java_block_brace_style = end_of_line\n# ij_java_block_comment_at_first_column = true\nij_java_call_parameters_new_line_after_left_paren = true\n# ij_java_call_parameters_right_paren_on_new_line = false\nij_java_call_parameters_wrap = on_every_item\n# ij_java_case_statement_on_separate_line = true\n# ij_java_catch_on_new_line = false\n# ij_java_class_annotation_wrap = split_into_lines\n# ij_java_class_brace_style = end_of_line\nij_java_class_count_to_use_import_on_demand = 9999\n# ij_java_class_names_in_javadoc = 1\n# ij_java_do_not_indent_top_level_class_members = false\n# ij_java_do_not_wrap_after_single_annotation = false\n# ij_java_do_while_brace_force = never\n# ij_java_doc_add_blank_line_after_description = true\nij_java_doc_add_blank_line_after_param_comments = true\nij_java_doc_add_blank_line_after_return = true\n# ij_java_doc_add_p_tag_on_empty_lines = true\nij_java_doc_align_exception_comments = false\nij_java_doc_align_param_comments = false\nij_java_doc_do_not_wrap_if_one_line = true\nij_java_doc_enable_formatting = true\n# ij_java_doc_enable_leading_asterisks = true\nij_java_doc_indent_on_continuation = true\nij_java_doc_keep_empty_lines = true\n# ij_java_doc_keep_empty_parameter_tag = true\n# ij_java_doc_keep_empty_return_tag = true\n# ij_java_doc_keep_empty_throws_tag = true\n# ij_java_doc_keep_invalid_tags = true\n# ij_java_doc_param_description_on_new_line = false\nij_java_doc_preserve_line_breaks = false\n# ij_java_doc_use_throws_not_exception_tag = true\n# ij_java_else_on_new_line = false\n# ij_java_entity_dd_suffix = EJB\n# ij_java_entity_eb_suffix = Bean\n# ij_java_entity_hi_suffix = Home\n# ij_java_entity_lhi_prefix = Local\n# ij_java_entity_lhi_suffix = Home\n# ij_java_entity_li_prefix = Local\n# ij_java_entity_pk_class = java.lang.String\n# ij_java_entity_vo_suffix = VO\n# ij_java_enum_constants_wrap = off\n# ij_java_extends_keyword_wrap = off\n# ij_java_extends_list_wrap = off\n# ij_java_field_annotation_wrap = split_into_lines\n# ij_java_finally_on_new_line = false\n# ij_java_for_brace_force = never\n# ij_java_for_statement_new_line_after_left_paren = false\n# ij_java_for_statement_right_paren_on_new_line = false\n# ij_java_for_statement_wrap = off\n# ij_java_generate_final_locals = false\n# ij_java_generate_final_parameters = false\n# ij_java_if_brace_force = never\nij_java_imports_layout = org.apache.flink.**,|,org.apache.flink.shaded.**,|,*,|,javax.**,|,java.**,|,scala.**,|,$*\n# ij_java_indent_case_from_switch = true\n# ij_java_insert_inner_class_imports = false\n# ij_java_insert_override_annotation = true\n# ij_java_keep_blank_lines_before_right_brace = 2\n# ij_java_keep_blank_lines_between_package_declaration_and_header = 2\n# ij_java_keep_blank_lines_in_code = 2\n# ij_java_keep_blank_lines_in_declarations = 2\n# ij_java_keep_control_statement_in_one_line = true\n# ij_java_keep_first_column_comment = true\n# ij_java_keep_indents_on_empty_lines = false\n# ij_java_keep_line_breaks = true\n# ij_java_keep_multiple_expressions_in_one_line = false\n# ij_java_keep_simple_blocks_in_one_line = false\n# ij_java_keep_simple_classes_in_one_line = false\n# ij_java_keep_simple_lambdas_in_one_line = false\n# ij_java_keep_simple_methods_in_one_line = false\n# ij_java_label_indent_absolute = false\n# ij_java_label_indent_size = 0\n# ij_java_lambda_brace_style = end_of_line\nij_java_layout_static_imports_separately = true\n# ij_java_line_comment_add_space = false\n# ij_java_line_comment_at_first_column = true\n# ij_java_message_dd_suffix = EJB\n# ij_java_message_eb_suffix = Bean\n# ij_java_method_annotation_wrap = split_into_lines\n# ij_java_method_brace_style = end_of_line\nij_java_method_call_chain_wrap = on_every_item\nij_java_method_parameters_new_line_after_left_paren = true\n# ij_java_method_parameters_right_paren_on_new_line = false\nij_java_method_parameters_wrap = on_every_item\n# ij_java_modifier_list_wrap = false\nij_java_names_count_to_use_import_on_demand = 9999\n# ij_java_new_line_after_lparen_in_record_header = false\n# ij_java_packages_to_use_import_on_demand = java.awt.*,javax.swing.*\n# ij_java_parameter_annotation_wrap = off\n# ij_java_parentheses_expression_new_line_after_left_paren = false\n# ij_java_parentheses_expression_right_paren_on_new_line = false\n# ij_java_place_assignment_sign_on_next_line = false\n# ij_java_prefer_longer_names = true\n# ij_java_prefer_parameters_wrap = false\n# ij_java_record_components_wrap = normal\n# ij_java_repeat_synchronized = true\n# ij_java_replace_instanceof_and_cast = false\n# ij_java_replace_null_check = true\n# ij_java_replace_sum_lambda_with_method_ref = true\n# ij_java_resource_list_new_line_after_left_paren = false\n# ij_java_resource_list_right_paren_on_new_line = false\n# ij_java_resource_list_wrap = off\n# ij_java_rparen_on_new_line_in_record_header = false\n# ij_java_session_dd_suffix = EJB\n# ij_java_session_eb_suffix = Bean\n# ij_java_session_hi_suffix = Home\n# ij_java_session_lhi_prefix = Local\n# ij_java_session_lhi_suffix = Home\n# ij_java_session_li_prefix = Local\n# ij_java_session_si_suffix = Service\n# ij_java_space_after_closing_angle_bracket_in_type_argument = false\n# ij_java_space_after_colon = true\n# ij_java_space_after_comma = true\n# ij_java_space_after_comma_in_type_arguments = true\n# ij_java_space_after_for_semicolon = true\n# ij_java_space_after_quest = true\n# ij_java_space_after_type_cast = true\n# ij_java_space_before_annotation_array_initializer_left_brace = false\n# ij_java_space_before_annotation_parameter_list = false\n# ij_java_space_before_array_initializer_left_brace = false\n# ij_java_space_before_catch_keyword = true\n# ij_java_space_before_catch_left_brace = true\n# ij_java_space_before_catch_parentheses = true\n# ij_java_space_before_class_left_brace = true\n# ij_java_space_before_colon = true\n# ij_java_space_before_colon_in_foreach = true\n# ij_java_space_before_comma = false\n# ij_java_space_before_do_left_brace = true\n# ij_java_space_before_else_keyword = true\n# ij_java_space_before_else_left_brace = true\n# ij_java_space_before_finally_keyword = true\n# ij_java_space_before_finally_left_brace = true\n# ij_java_space_before_for_left_brace = true\n# ij_java_space_before_for_parentheses = true\n# ij_java_space_before_for_semicolon = false\n# ij_java_space_before_if_left_brace = true\n# ij_java_space_before_if_parentheses = true\n# ij_java_space_before_method_call_parentheses = false\n# ij_java_space_before_method_left_brace = true\n# ij_java_space_before_method_parentheses = false\n# ij_java_space_before_opening_angle_bracket_in_type_parameter = false\n# ij_java_space_before_quest = true\n# ij_java_space_before_switch_left_brace = true\n# ij_java_space_before_switch_parentheses = true\n# ij_java_space_before_synchronized_left_brace = true\n# ij_java_space_before_synchronized_parentheses = true\n# ij_java_space_before_try_left_brace = true\n# ij_java_space_before_try_parentheses = true\n# ij_java_space_before_type_parameter_list = false\n# ij_java_space_before_while_keyword = true\n# ij_java_space_before_while_left_brace = true\n# ij_java_space_before_while_parentheses = true\n# ij_java_space_inside_one_line_enum_braces = false\n# ij_java_space_within_empty_array_initializer_braces = false\n# ij_java_space_within_empty_method_call_parentheses = false\n# ij_java_space_within_empty_method_parentheses = false\n# ij_java_spaces_around_additive_operators = true\n# ij_java_spaces_around_assignment_operators = true\n# ij_java_spaces_around_bitwise_operators = true\n# ij_java_spaces_around_equality_operators = true\n# ij_java_spaces_around_lambda_arrow = true\n# ij_java_spaces_around_logical_operators = true\n# ij_java_spaces_around_method_ref_dbl_colon = false\n# ij_java_spaces_around_multiplicative_operators = true\n# ij_java_spaces_around_relational_operators = true\n# ij_java_spaces_around_shift_operators = true\n# ij_java_spaces_around_type_bounds_in_type_parameters = true\n# ij_java_spaces_around_unary_operator = false\n# ij_java_spaces_within_angle_brackets = false\n# ij_java_spaces_within_annotation_parentheses = false\n# ij_java_spaces_within_array_initializer_braces = false\n# ij_java_spaces_within_braces = false\n# ij_java_spaces_within_brackets = false\n# ij_java_spaces_within_cast_parentheses = false\n# ij_java_spaces_within_catch_parentheses = false\n# ij_java_spaces_within_for_parentheses = false\n# ij_java_spaces_within_if_parentheses = false\n# ij_java_spaces_within_method_call_parentheses = false\n# ij_java_spaces_within_method_parentheses = false\n# ij_java_spaces_within_parentheses = false\n# ij_java_spaces_within_switch_parentheses = false\n# ij_java_spaces_within_synchronized_parentheses = false\n# ij_java_spaces_within_try_parentheses = false\n# ij_java_spaces_within_while_parentheses = false\n# ij_java_special_else_if_treatment = true\n# ij_java_subclass_name_suffix = Impl\n# ij_java_ternary_operation_signs_on_next_line = false\n# ij_java_ternary_operation_wrap = off\n# ij_java_test_name_suffix = Test\n# ij_java_throws_keyword_wrap = off\n# ij_java_throws_list_wrap = off\n# ij_java_use_external_annotations = false\n# ij_java_use_fq_class_names = false\n# ij_java_use_relative_indents = false\n# ij_java_use_single_class_imports = true\nij_java_variable_annotation_wrap = normal\n# ij_java_visibility = public\n# ij_java_while_brace_force = never\n# ij_java_while_on_new_line = false\n# ij_java_wrap_comments = false\nij_java_wrap_first_method_in_call_chain = true\n# ij_java_wrap_long_lines = false\n\n[*.out]\ninsert_final_newline = false\n\n[*.xml]\nindent_style = tab\nindent_size = 4\n\n[*.py]\nindent_style = space\nindent_size = 4\n"
        },
        {
          "name": ".git-blame-ignore-revs",
          "type": "blob",
          "size": 0.119140625,
          "content": "c6997c97c575d334679915c328792b8a3067cfb5\n481ccff04f647505721541f45d0f99b1f67f11f4\n91d81c427aa6312841ca868d54e8ce6ea721cd60"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.3193359375,
          "content": ".eslintcache\n.cache\nscalastyle-output.xml\n.classpath\n.java-version\n.idea/*\n!.idea/vcs.xml\n!.idea/icon.png\n.vscode\n.metadata\n.settings\n.project\n.version.properties\nfilter.properties\nlogs.zip\n.mvn/wrapper/*.jar\n.mvn/maven.config\ntarget\ntmp\n*.class\n*.iml\n*.swp\n*.jar\n*.zip\n*.log\n*.pyc\n.DS_Store\nbuild-target\n**/dependency-reduced-pom.xml\nflink-runtime-web/web-dashboard/node/\nflink-runtime-web/web-dashboard/node_modules/\nflink-runtime-web/web-dashboard/web/\nflink-runtime-web/web-dashboard/.angular/\nflink-python/dist/\nflink-python/apache-flink-libraries/dist/\nflink-python/build/\nflink-python/apache-flink-libraries/build\nflink-python/pyflink.egg-info/\nflink-python/apache_flink.egg-info/\nflink-python/apache-flink-libraries/apache_flink_libraries.egg-info/\nflink-python/docs/_build\nflink-python/.tox/\nflink-python/dev/download\nflink-python/dev/.conda/\nflink-python/dev/log/\nflink-python/dev/.stage.txt\nflink-python/.eggs/\nflink-python/apache-flink-*.dev*/\nflink-python/apache-flink-libraries/apache_flink_libraries-*.dev*/\nflink-python/**/*.c\nflink-python/.idea/\nflink-python/**/*.so\natlassian-ide-plugin.xml\nout/\n/docs/api\n/docs/.bundle\n/docs/.rubydeps\n/docs/ruby2/.bundle\n/docs/ruby2/.rubydeps\n/docs/.jekyll-metadata\n*.ipr\n*.iws\ntools/flink\ntools/flink-*\ntools/releasing/release\ntools/japicmp-output\n/docs/go.mod\n/docs/go.sum\n/docs/.hugo_build.lock\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.1005859375,
          "content": "[submodule \"docs/themes/book\"]\n\tpath = docs/themes/book\n\turl = https://github.com/alex-shpak/hugo-book\n"
        },
        {
          "name": ".idea",
          "type": "tree",
          "content": null
        },
        {
          "name": ".mvn",
          "type": "tree",
          "content": null
        },
        {
          "name": ".scalafmt.conf",
          "type": "blob",
          "size": 2.1220703125,
          "content": "runner.dialect = scala212\n\n# Version is required to make sure IntelliJ picks the right version\nversion = 3.4.3\npreset = default\n\n# Max column\nmaxColumn = 100\n\n# This parameter simply says the .stripMargin method was not redefined by the user to assign\n# special meaning to indentation preceding the | character. Hence, that indentation can be modified.\nassumeStandardLibraryStripMargin = true\nalign.stripMargin = true\n\n# Align settings\nalign.preset = none\nalign.closeParenSite = false\nalign.openParenCallSite = false\ndanglingParentheses.defnSite = false\ndanglingParentheses.callSite = false\ndanglingParentheses.ctrlSite = true\ndanglingParentheses.tupleSite = false\nalign.openParenCallSite = false\nalign.openParenDefnSite = false\nalign.openParenTupleSite = false\n\n# Newlines\nnewlines.alwaysBeforeElseAfterCurlyIf = false\nnewlines.beforeCurlyLambdaParams = multiline # Newline before lambda params\nnewlines.afterCurlyLambdaParams = squash # No newline after lambda params\nnewlines.inInterpolation = \"avoid\"\nnewlines.avoidInResultType = true\noptIn.annotationNewlines = true\n\n# Scaladoc\ndocstrings.style = Asterisk # Javadoc style\ndocstrings.removeEmpty = true\ndocstrings.oneline = fold\ndocstrings.forceBlankLineBefore = true\n\n# Indentation\nindent.extendSite = 2 # This makes sure extend is not indented as the ctor parameters\n\n# Rewrites\nrewrite.rules = [AvoidInfix, Imports, RedundantBraces, SortModifiers]\n\n# Imports\nrewrite.imports.sort = scalastyle\nrewrite.imports.groups = [\n    [\"org.apache.flink\\\\..*\"],\n    [\"org.apache.flink.shaded\\\\..*\"],\n    [\".*\"],\n    [\"javax\\\\..*\"],\n    [\"java\\\\..*\"],\n    [\"scala\\\\..*\"]\n]\nrewrite.imports.contiguousGroups = no\nimportSelectors = singleline # Imports in a single line, like IntelliJ\n\n# Remove redundant braces in string interpolation.\nrewrite.redundantBraces.stringInterpolation = true\nrewrite.redundantBraces.defnBodies = false\nrewrite.redundantBraces.generalExpressions = false\nrewrite.redundantBraces.ifElseExpressions = false\nrewrite.redundantBraces.methodBodies = false\nrewrite.redundantBraces.includeUnitMethods = false\nrewrite.redundantBraces.maxBreaks = 1\n\n# Remove trailing commas\nrewrite.trailingCommas.style = \"never\"\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "NOTICE",
          "type": "blob",
          "size": 2.7763671875,
          "content": "Apache Flink\nCopyright 2014-2024 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\nThis project bundles the following dependencies under the MIT license.\nSee bundled license files for details.\n\n- AnchorJS v3.1.0 (https://github.com/bryanbraun/anchorjs) Copyright (c) 2016 Bryan Braun\n    -> in \"docs/static/js/anchor.min.js\"\n- font-awesome:4.6.3 (css) (https://fontawesome.com/) - Created by Dave Gandy\n    -> css in \"docs/static/font-awesome/css\"\n- chroma (css generated by Hugo) (https://github.com/alecthomas/chroma) Copyright (C) 2017 Alec Thomas\n    -> in \"docs/assets/github.css\"\n\nThis project bundles the following dependencies under the BSD license.\nSee bundled license files for details.\n\n- cloudpickle:2.2.0\n- net.sf.py4j:py4j:0.10.9.7\n\nThis project bundles the following dependencies under SIL OFL 1.1 license (https://opensource.org/licenses/OFL-1.1).\nSee bundled license files for details.\n\n- font-awesome:4.6.3 (Font) (https://fontawesome.com/) - Created by Dave Gandy\n    -> fonts in \"docs/static/font-awesome/fonts\"\n\nThe Apache Flink project contains or reuses code that is licensed under the ISC license from the following projects.\n\n- simplejmx (http://256stuff.com/sources/simplejmx/) Copyright (c) - Gray Watson\n\nPermission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby\ngranted, provided that this permission notice appear in all copies.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING\nALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL,\nDIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,\nWHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE\nUSE OR PERFORMANCE OF THIS SOFTWARE.\n\nThe Apache Flink project contains or reuses code that is licensed under the Apache 2.0 license from the following projects:\n- aws-sdk-java-s3 (https://github.com/aws/aws-sdk-java)\n\n  See: flink/flink-filesystems/flink-s3-fs-base/src/main/java/com/amazonaws/services/s3/model/transform/XmlResponsesSaxParser.java\n\nAWS SDK for Java\nCopyright 2010-2014 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n\nThis product includes software developed by\nAmazon Technologies, Inc (http://www.amazon.com/).\n\n**********************\nTHIRD PARTY COMPONENTS\n**********************\nThis software includes third party software subject to the following copyrights:\n- XML parsing and utility functions from JetS3t - Copyright 2006-2009 James Murty.\n- PKCS#1 PEM encoded private key parsing and utility functions from oauth.googlecode.com - Copyright 1998-2010 AOL Inc.\n\n\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 6.69140625,
          "content": "# Apache Flink\n\nApache Flink is an open source stream processing framework with powerful stream- and batch-processing capabilities.\n\nLearn more about Flink at [https://flink.apache.org/](https://flink.apache.org/)\n\n\n### Features\n\n* A streaming-first runtime that supports both batch processing and data streaming programs\n\n* Elegant and fluent APIs in Java\n\n* A runtime that supports very high throughput and low event latency at the same time\n\n* Support for *event time* and *out-of-order* processing in the DataStream API, based on the *Dataflow Model*\n\n* Flexible windowing (time, count, sessions, custom triggers) across different time semantics (event time, processing time)\n\n* Fault-tolerance with *exactly-once* processing guarantees\n\n* Natural back-pressure in streaming programs\n\n* Libraries for Graph processing (batch), Machine Learning (batch), and Complex Event Processing (streaming)\n\n* Custom memory management for efficient and robust switching between in-memory and out-of-core data processing algorithms\n\n* Compatibility layers for Apache Hadoop MapReduce\n\n* Integration with YARN, HDFS, HBase, and other components of the Apache Hadoop ecosystem\n\n\n### Streaming Example\n```java\n// pojo class WordWithCount\npublic class WordWithCount {\n    public String word;\n    public int count;\n\n    public WordWithCount() {}\n    \n    public WordWithCount(String word, int count) {\n        this.word = word;\n        this.count = count;\n    }\n}\n\n// main method\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nDataStreamSource<String> text = env.socketTextStream(host, port);\nDataStream<WordWithCount> windowCounts = text\n    .flatMap(\n        (FlatMapFunction<String, String>) (line, collector) \n            -> Arrays.stream(line.split(\"\\\\s\")).forEach(collector::collect)\n    ).returns(String.class)\n    .map(word -> new WordWithCount(word, 1)).returns(TypeInformation.of(WordWithCount.class))\n    .keyBy(wordWithCnt -> wordWithCnt.word)\n    .window(TumblingProcessingTimeWindows.of(Duration.ofSeconds(5)))\n    .sum(\"count\").returns(TypeInformation.of(WordWithCount.class));\n\nwindowCounts.print();\nenv.execute();\n}\n```\n\n### Batch Example\n```java\n// pojo class WordWithCount\npublic class WordWithCount {\n    public String word;\n    public int count;\n\n    public WordWithCount() {}\n\n    public WordWithCount(String word, int count) {\n        this.word = word;\n        this.count = count;\n    }\n}\n\n// main method\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nenv.setRuntimeMode(RuntimeExecutionMode.BATCH);\nFileSource<String> source = FileSource.forRecordStreamFormat(new TextLineInputFormat(), new Path(\"MyInput.txt\")).build();\nDataStreamSource<String> text = env.fromSource(source, WatermarkStrategy.noWatermarks(), \"MySource\");\nDataStream<WordWithCount> windowCounts = text\n        .flatMap((FlatMapFunction<String, String>) (line, collector) -> Arrays\n                .stream(line.split(\"\\\\s\"))\n                .forEach(collector::collect)).returns(String.class)\n        .map(word -> new WordWithCount(word, 1)).returns(TypeInformation.of(WordWithCount.class))\n        .keyBy(wordWintCount -> wordWintCount.word)\n        .sum(\"count\").returns(TypeInformation.of(WordWithCount.class));\n\nwindowCounts.print();\nenv.execute();\n```\n\n\n\n## Building Apache Flink from Source\n\nPrerequisites for building Flink:\n\n* Unix-like environment (we use Linux, Mac OS X, Cygwin, WSL)\n* Git\n* Maven (we require version 3.8.6)\n* Java 11\n\n```\ngit clone https://github.com/apache/flink.git\ncd flink\n./mvnw clean package -DskipTests # this will take up to 10 minutes\n```\n\nFlink is now installed in `build-target`.\n\n## Developing Flink\n\nThe Flink committers use IntelliJ IDEA to develop the Flink codebase.\nWe recommend IntelliJ IDEA for developing projects that involve Scala code.\n\nMinimal requirements for an IDE are:\n* Support for Java and Scala (also mixed projects)\n* Support for Maven with Java and Scala\n\n\n### IntelliJ IDEA\n\nThe IntelliJ IDE supports Maven out of the box and offers a plugin for Scala development.\n\n* IntelliJ download: [https://www.jetbrains.com/idea/](https://www.jetbrains.com/idea/)\n* IntelliJ Scala Plugin: [https://plugins.jetbrains.com/plugin/?id=1347](https://plugins.jetbrains.com/plugin/?id=1347)\n\nCheck out our [Setting up IntelliJ](https://nightlies.apache.org/flink/flink-docs-master/flinkDev/ide_setup.html#intellij-idea) guide for details.\n\n### Eclipse Scala IDE\n\n**NOTE:** From our experience, this setup does not work with Flink\ndue to deficiencies of the old Eclipse version bundled with Scala IDE 3.0.3 or\ndue to version incompatibilities with the bundled Scala version in Scala IDE 4.4.1.\n\n**We recommend to use IntelliJ instead (see above)**\n\n## Support\n\nDon’t hesitate to ask!\n\nContact the developers and community on the [mailing lists](https://flink.apache.org/community.html#mailing-lists) if you need any help.\n\n[Open an issue](https://issues.apache.org/jira/browse/FLINK) if you find a bug in Flink.\n\n\n## Documentation\n\nThe documentation of Apache Flink is located on the website: [https://flink.apache.org](https://flink.apache.org)\nor in the `docs/` directory of the source code.\n\n\n## Fork and Contribute\n\nThis is an active open-source project. We are always open to people who want to use the system or contribute to it.\nContact us if you are looking for implementation tasks that fit your skills.\nThis article describes [how to contribute to Apache Flink](https://flink.apache.org/contributing/how-to-contribute.html).\n\n## Externalized Connectors\n\nMost Flink connectors have been externalized to individual repos under the [Apache Software Foundation](https://github.com/apache):\n\n* [flink-connector-aws](https://github.com/apache/flink-connector-aws)\n* [flink-connector-cassandra](https://github.com/apache/flink-connector-cassandra)\n* [flink-connector-elasticsearch](https://github.com/apache/flink-connector-elasticsearch)\n* [flink-connector-gcp-pubsub](https://github.com/apache/flink-connector-gcp-pubsub)\n* [flink-connector-hbase](https://github.com/apache/flink-connector-hbase)\n* [flink-connector-jdbc](https://github.com/apache/flink-connector-jdbc)\n* [flink-connector-kafka](https://github.com/apache/flink-connector-kafka)\n* [flink-connector-mongodb](https://github.com/apache/flink-connector-mongodb)\n* [flink-connector-opensearch](https://github.com/apache/flink-connector-opensearch)\n* [flink-connector-prometheus](https://github.com/apache/flink-connector-prometheus)\n* [flink-connector-pulsar](https://github.com/apache/flink-connector-pulsar)\n* [flink-connector-rabbitmq](https://github.com/apache/flink-connector-rabbitmq)\n\n## About\n\nApache Flink is an open source project of The Apache Software Foundation (ASF).\nThe Apache Flink project originated from the [Stratosphere](http://stratosphere.eu) research project.\n"
        },
        {
          "name": "azure-pipelines.yml",
          "type": "blob",
          "size": 4.248046875,
          "content": "# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n#\n# This file defines an Azure Pipeline build for testing Flink. It is intended to be used\n# with a free Azure Pipelines account.\n# It has the following features:\n#  - default builds for pushes / pull requests\n#  - end-to-end tests\n#\n#\n# For the \"apache/flink\" repository, we are using the pipeline definition located in\n#   tools/azure-pipelines/build-apache-repo.yml\n# That file points to custom, self-hosted build agents for faster pull request build processing and \n# integration with Flinkbot.\n# The custom pipeline definition file is configured in the \"Pipeline settings\" screen\n# of the Azure Pipelines web ui.\n#\n\ntrigger:\n  branches:\n    include:\n    - '*'  # must quote since \"*\" is a YAML reserved character; we want a string\n\nresources:\n  containers:\n  # Container with SSL to have the same environment everywhere.\n  # see https://github.com/apache/flink-connector-shared-utils/tree/ci_utils\n  - container: flink-build-container\n    image: chesnay/flink-ci:java_8_11_17_21_maven_386_jammy\n    # On AZP provided machines, set this flag to allow writing coredumps in docker\n    options: --privileged\n\n# Define variables:\n# - See tools/azure-pipelines/jobs-template.yml for a short summary of the caching\n# - See https://stackoverflow.com/questions/60742105/how-can-i-access-a-secret-value-from-an-azure-pipelines-expression\n#   to understand why the secrets are handled like this\nvariables:\n  MAVEN_CACHE_FOLDER: $(Pipeline.Workspace)/.m2/repository\n  E2E_CACHE_FOLDER: $(Pipeline.Workspace)/e2e_cache\n  E2E_TARBALL_CACHE: $(Pipeline.Workspace)/e2e_artifact_cache\n  MAVEN_ARGS: '-Dmaven.repo.local=$(MAVEN_CACHE_FOLDER)'\n  PIPELINE_START_YEAR: $[format('{0:yyyy}', pipeline.startTime)]\n  CACHE_KEY: maven | $(Agent.OS) | **/pom.xml, !**/target/**\n  CACHE_FALLBACK_KEY: maven | $(Agent.OS)\n  DOCKER_IMAGES_CACHE_KEY: docker-images-cache | $(Agent.OS) | **/cache_docker_images.sh | flink-test-utils-parent/**/DockerImageVersions.java\n  DOCKER_IMAGES_CACHE_FOLDER: $(Pipeline.Workspace)/.docker-cache\n  FLINK_ARTIFACT_DIR: $(Pipeline.Workspace)/flink_artifact\n  SECRET_S3_BUCKET: $[variables.IT_CASE_S3_BUCKET]\n  SECRET_S3_ACCESS_KEY: $[variables.IT_CASE_S3_ACCESS_KEY]\n  SECRET_S3_SECRET_KEY: $[variables.IT_CASE_S3_SECRET_KEY]\n\n\nstages:\n  # CI / PR triggered stage:\n  - stage: ci\n    displayName: \"CI build (custom builders)\"\n    condition: not(eq(variables['MODE'], 'release'))\n    jobs:\n      - template: tools/azure-pipelines/jobs-template.yml\n        parameters: # see template file for a definition of the parameters.\n          stage_name: ci_build\n          test_pool_definition:\n            vmImage: 'ubuntu-22.04'\n          e2e_pool_definition:\n            vmImage: 'ubuntu-22.04'\n          environment: PROFILE=\"-Dflink.hadoop.version=2.10.2\"\n          run_end_to_end: false\n          container: flink-build-container\n          jdk: 11\n      - job: docs_404_check # run on a MSFT provided machine\n        pool:\n          vmImage: 'ubuntu-22.04'\n        steps:\n          - task: GoTool@0\n            inputs:\n              version: '1.18.1'\n          - script: ./tools/ci/docs.sh\n  # CI / Special stage for release, e.g. building PyFlink wheel packages, etc:\n  - stage: ci_release\n    displayName: \"CI build (release)\"\n    condition: and(eq(variables['Build.Reason'], 'Manual'), eq(variables['MODE'], 'release'))\n    jobs:\n      - template: tools/azure-pipelines/build-python-wheels.yml\n        parameters:\n          stage_name: cron_python_wheels\n          environment: PROFILE=\"-Dflink.hadoop.version=2.10.2\"\n          container: flink-build-container\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-annotations",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-architecture-tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-clients",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-connectors",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-container",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-core-api",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-core",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-datastream-api",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-datastream",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-dist-scala",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-dist",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-dstl",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-end-to-end-tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-external-resources",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-filesystems",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-formats",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-fs-tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-kubernetes",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-libraries",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-metrics",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-python",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-queryable-state",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-quickstart",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-rpc",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-runtime-web",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-runtime",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-state-backends",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-streaming-java",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-table",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-test-utils-parent",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-tests-java17",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-walkthroughs",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-yarn-tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink-yarn",
          "type": "tree",
          "content": null
        },
        {
          "name": "licenses",
          "type": "tree",
          "content": null
        },
        {
          "name": "mvnw",
          "type": "blob",
          "size": 10.91015625,
          "content": "#!/bin/sh\n# ----------------------------------------------------------------------------\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n# ----------------------------------------------------------------------------\n\n# ----------------------------------------------------------------------------\n# Apache Maven Wrapper startup batch script, version 3.3.2\n#\n# Required ENV vars:\n# ------------------\n#   JAVA_HOME - location of a JDK home dir\n#\n# Optional ENV vars\n# -----------------\n#   MAVEN_OPTS - parameters passed to the Java VM when running Maven\n#     e.g. to debug Maven itself, use\n#       set MAVEN_OPTS=-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=8000\n#   MAVEN_SKIP_RC - flag to disable loading of mavenrc files\n# ----------------------------------------------------------------------------\n\nif [ -z \"$MAVEN_SKIP_RC\" ]; then\n\n  if [ -f /usr/local/etc/mavenrc ]; then\n    . /usr/local/etc/mavenrc\n  fi\n\n  if [ -f /etc/mavenrc ]; then\n    . /etc/mavenrc\n  fi\n\n  if [ -f \"$HOME/.mavenrc\" ]; then\n    . \"$HOME/.mavenrc\"\n  fi\n\nfi\n\n# OS specific support.  $var _must_ be set to either true or false.\ncygwin=false\ndarwin=false\nmingw=false\ncase \"$(uname)\" in\nCYGWIN*) cygwin=true ;;\nMINGW*) mingw=true ;;\nDarwin*)\n  darwin=true\n  # Use /usr/libexec/java_home if available, otherwise fall back to /Library/Java/Home\n  # See https://developer.apple.com/library/mac/qa/qa1170/_index.html\n  if [ -z \"$JAVA_HOME\" ]; then\n    if [ -x \"/usr/libexec/java_home\" ]; then\n      JAVA_HOME=\"$(/usr/libexec/java_home)\"\n      export JAVA_HOME\n    else\n      JAVA_HOME=\"/Library/Java/Home\"\n      export JAVA_HOME\n    fi\n  fi\n  ;;\nesac\n\nif [ -z \"$JAVA_HOME\" ]; then\n  if [ -r /etc/gentoo-release ]; then\n    JAVA_HOME=$(java-config --jre-home)\n  fi\nfi\n\n# For Cygwin, ensure paths are in UNIX format before anything is touched\nif $cygwin; then\n  [ -n \"$JAVA_HOME\" ] \\\n    && JAVA_HOME=$(cygpath --unix \"$JAVA_HOME\")\n  [ -n \"$CLASSPATH\" ] \\\n    && CLASSPATH=$(cygpath --path --unix \"$CLASSPATH\")\nfi\n\n# For Mingw, ensure paths are in UNIX format before anything is touched\nif $mingw; then\n  [ -n \"$JAVA_HOME\" ] && [ -d \"$JAVA_HOME\" ] \\\n    && JAVA_HOME=\"$(\n      cd \"$JAVA_HOME\" || (\n        echo \"cannot cd into $JAVA_HOME.\" >&2\n        exit 1\n      )\n      pwd\n    )\"\nfi\n\nif [ -z \"$JAVA_HOME\" ]; then\n  javaExecutable=\"$(which javac)\"\n  if [ -n \"$javaExecutable\" ] && ! [ \"$(expr \"$javaExecutable\" : '\\([^ ]*\\)')\" = \"no\" ]; then\n    # readlink(1) is not available as standard on Solaris 10.\n    readLink=$(which readlink)\n    if [ ! \"$(expr \"$readLink\" : '\\([^ ]*\\)')\" = \"no\" ]; then\n      if $darwin; then\n        javaHome=\"$(dirname \"$javaExecutable\")\"\n        javaExecutable=\"$(cd \"$javaHome\" && pwd -P)/javac\"\n      else\n        javaExecutable=\"$(readlink -f \"$javaExecutable\")\"\n      fi\n      javaHome=\"$(dirname \"$javaExecutable\")\"\n      javaHome=$(expr \"$javaHome\" : '\\(.*\\)/bin')\n      JAVA_HOME=\"$javaHome\"\n      export JAVA_HOME\n    fi\n  fi\nfi\n\nif [ -z \"$JAVACMD\" ]; then\n  if [ -n \"$JAVA_HOME\" ]; then\n    if [ -x \"$JAVA_HOME/jre/sh/java\" ]; then\n      # IBM's JDK on AIX uses strange locations for the executables\n      JAVACMD=\"$JAVA_HOME/jre/sh/java\"\n    else\n      JAVACMD=\"$JAVA_HOME/bin/java\"\n    fi\n  else\n    JAVACMD=\"$(\n      \\unset -f command 2>/dev/null\n      \\command -v java\n    )\"\n  fi\nfi\n\nif [ ! -x \"$JAVACMD\" ]; then\n  echo \"Error: JAVA_HOME is not defined correctly.\" >&2\n  echo \"  We cannot execute $JAVACMD\" >&2\n  exit 1\nfi\n\nif [ -z \"$JAVA_HOME\" ]; then\n  echo \"Warning: JAVA_HOME environment variable is not set.\" >&2\nfi\n\n# traverses directory structure from process work directory to filesystem root\n# first directory with .mvn subdirectory is considered project base directory\nfind_maven_basedir() {\n  if [ -z \"$1\" ]; then\n    echo \"Path not specified to find_maven_basedir\" >&2\n    return 1\n  fi\n\n  basedir=\"$1\"\n  wdir=\"$1\"\n  while [ \"$wdir\" != '/' ]; do\n    if [ -d \"$wdir\"/.mvn ]; then\n      basedir=$wdir\n      break\n    fi\n    # workaround for JBEAP-8937 (on Solaris 10/Sparc)\n    if [ -d \"${wdir}\" ]; then\n      wdir=$(\n        cd \"$wdir/..\" || exit 1\n        pwd\n      )\n    fi\n    # end of workaround\n  done\n  printf '%s' \"$(\n    cd \"$basedir\" || exit 1\n    pwd\n  )\"\n}\n\n# concatenates all lines of a file\nconcat_lines() {\n  if [ -f \"$1\" ]; then\n    # Remove \\r in case we run on Windows within Git Bash\n    # and check out the repository with auto CRLF management\n    # enabled. Otherwise, we may read lines that are delimited with\n    # \\r\\n and produce $'-Xarg\\r' rather than -Xarg due to word\n    # splitting rules.\n    tr -s '\\r\\n' ' ' <\"$1\"\n  fi\n}\n\nlog() {\n  if [ \"$MVNW_VERBOSE\" = true ]; then\n    printf '%s\\n' \"$1\"\n  fi\n}\n\nBASE_DIR=$(find_maven_basedir \"$(dirname \"$0\")\")\nif [ -z \"$BASE_DIR\" ]; then\n  exit 1\nfi\n\nMAVEN_PROJECTBASEDIR=${MAVEN_BASEDIR:-\"$BASE_DIR\"}\nexport MAVEN_PROJECTBASEDIR\nlog \"$MAVEN_PROJECTBASEDIR\"\n\n##########################################################################################\n# Extension to allow automatically downloading the maven-wrapper.jar from Maven-central\n# This allows using the maven wrapper in projects that prohibit checking in binary data.\n##########################################################################################\nwrapperJarPath=\"$MAVEN_PROJECTBASEDIR/.mvn/wrapper/maven-wrapper.jar\"\nif [ -r \"$wrapperJarPath\" ]; then\n  log \"Found $wrapperJarPath\"\nelse\n  log \"Couldn't find $wrapperJarPath, downloading it ...\"\n\n  if [ -n \"$MVNW_REPOURL\" ]; then\n    wrapperUrl=\"$MVNW_REPOURL/org/apache/maven/wrapper/maven-wrapper/3.3.2/maven-wrapper-3.3.2.jar\"\n  else\n    wrapperUrl=\"https://repo.maven.apache.org/maven2/org/apache/maven/wrapper/maven-wrapper/3.3.2/maven-wrapper-3.3.2.jar\"\n  fi\n  while IFS=\"=\" read -r key value; do\n    # Remove '\\r' from value to allow usage on windows as IFS does not consider '\\r' as a separator ( considers space, tab, new line ('\\n'), and custom '=' )\n    safeValue=$(echo \"$value\" | tr -d '\\r')\n    case \"$key\" in wrapperUrl)\n      wrapperUrl=\"$safeValue\"\n      break\n      ;;\n    esac\n  done <\"$MAVEN_PROJECTBASEDIR/.mvn/wrapper/maven-wrapper.properties\"\n  log \"Downloading from: $wrapperUrl\"\n\n  if $cygwin; then\n    wrapperJarPath=$(cygpath --path --windows \"$wrapperJarPath\")\n  fi\n\n  if command -v wget >/dev/null; then\n    log \"Found wget ... using wget\"\n    [ \"$MVNW_VERBOSE\" = true ] && QUIET=\"\" || QUIET=\"--quiet\"\n    if [ -z \"$MVNW_USERNAME\" ] || [ -z \"$MVNW_PASSWORD\" ]; then\n      wget $QUIET \"$wrapperUrl\" -O \"$wrapperJarPath\" || rm -f \"$wrapperJarPath\"\n    else\n      wget $QUIET --http-user=\"$MVNW_USERNAME\" --http-password=\"$MVNW_PASSWORD\" \"$wrapperUrl\" -O \"$wrapperJarPath\" || rm -f \"$wrapperJarPath\"\n    fi\n  elif command -v curl >/dev/null; then\n    log \"Found curl ... using curl\"\n    [ \"$MVNW_VERBOSE\" = true ] && QUIET=\"\" || QUIET=\"--silent\"\n    if [ -z \"$MVNW_USERNAME\" ] || [ -z \"$MVNW_PASSWORD\" ]; then\n      curl $QUIET -o \"$wrapperJarPath\" \"$wrapperUrl\" -f -L || rm -f \"$wrapperJarPath\"\n    else\n      curl $QUIET --user \"$MVNW_USERNAME:$MVNW_PASSWORD\" -o \"$wrapperJarPath\" \"$wrapperUrl\" -f -L || rm -f \"$wrapperJarPath\"\n    fi\n  else\n    log \"Falling back to using Java to download\"\n    javaSource=\"$MAVEN_PROJECTBASEDIR/.mvn/wrapper/MavenWrapperDownloader.java\"\n    javaClass=\"$MAVEN_PROJECTBASEDIR/.mvn/wrapper/MavenWrapperDownloader.class\"\n    # For Cygwin, switch paths to Windows format before running javac\n    if $cygwin; then\n      javaSource=$(cygpath --path --windows \"$javaSource\")\n      javaClass=$(cygpath --path --windows \"$javaClass\")\n    fi\n    if [ -e \"$javaSource\" ]; then\n      if [ ! -e \"$javaClass\" ]; then\n        log \" - Compiling MavenWrapperDownloader.java ...\"\n        (\"$JAVA_HOME/bin/javac\" \"$javaSource\")\n      fi\n      if [ -e \"$javaClass\" ]; then\n        log \" - Running MavenWrapperDownloader.java ...\"\n        (\"$JAVA_HOME/bin/java\" -cp .mvn/wrapper MavenWrapperDownloader \"$wrapperUrl\" \"$wrapperJarPath\") || rm -f \"$wrapperJarPath\"\n      fi\n    fi\n  fi\nfi\n##########################################################################################\n# End of extension\n##########################################################################################\n\n# If specified, validate the SHA-256 sum of the Maven wrapper jar file\nwrapperSha256Sum=\"\"\nwhile IFS=\"=\" read -r key value; do\n  case \"$key\" in wrapperSha256Sum)\n    wrapperSha256Sum=$value\n    break\n    ;;\n  esac\ndone <\"$MAVEN_PROJECTBASEDIR/.mvn/wrapper/maven-wrapper.properties\"\nif [ -n \"$wrapperSha256Sum\" ]; then\n  wrapperSha256Result=false\n  if command -v sha256sum >/dev/null; then\n    if echo \"$wrapperSha256Sum  $wrapperJarPath\" | sha256sum -c >/dev/null 2>&1; then\n      wrapperSha256Result=true\n    fi\n  elif command -v shasum >/dev/null; then\n    if echo \"$wrapperSha256Sum  $wrapperJarPath\" | shasum -a 256 -c >/dev/null 2>&1; then\n      wrapperSha256Result=true\n    fi\n  else\n    echo \"Checksum validation was requested but neither 'sha256sum' or 'shasum' are available.\" >&2\n    echo \"Please install either command, or disable validation by removing 'wrapperSha256Sum' from your maven-wrapper.properties.\" >&2\n    exit 1\n  fi\n  if [ $wrapperSha256Result = false ]; then\n    echo \"Error: Failed to validate Maven wrapper SHA-256, your Maven wrapper might be compromised.\" >&2\n    echo \"Investigate or delete $wrapperJarPath to attempt a clean download.\" >&2\n    echo \"If you updated your Maven version, you need to update the specified wrapperSha256Sum property.\" >&2\n    exit 1\n  fi\nfi\n\nMAVEN_OPTS=\"$(concat_lines \"$MAVEN_PROJECTBASEDIR/.mvn/jvm.config\") $MAVEN_OPTS\"\n\n# For Cygwin, switch paths to Windows format before running java\nif $cygwin; then\n  [ -n \"$JAVA_HOME\" ] \\\n    && JAVA_HOME=$(cygpath --path --windows \"$JAVA_HOME\")\n  [ -n \"$CLASSPATH\" ] \\\n    && CLASSPATH=$(cygpath --path --windows \"$CLASSPATH\")\n  [ -n \"$MAVEN_PROJECTBASEDIR\" ] \\\n    && MAVEN_PROJECTBASEDIR=$(cygpath --path --windows \"$MAVEN_PROJECTBASEDIR\")\nfi\n\n# Provide a \"standardized\" way to retrieve the CLI args that will\n# work with both Windows and non-Windows executions.\nMAVEN_CMD_LINE_ARGS=\"$MAVEN_CONFIG $*\"\nexport MAVEN_CMD_LINE_ARGS\n\nWRAPPER_LAUNCHER=org.apache.maven.wrapper.MavenWrapperMain\n\n# shellcheck disable=SC2086 # safe args\nexec \"$JAVACMD\" \\\n  $MAVEN_OPTS \\\n  $MAVEN_DEBUG_OPTS \\\n  -classpath \"$MAVEN_PROJECTBASEDIR/.mvn/wrapper/maven-wrapper.jar\" \\\n  \"-Dmaven.multiModuleProjectDirectory=${MAVEN_PROJECTBASEDIR}\" \\\n  ${WRAPPER_LAUNCHER} $MAVEN_CONFIG \"$@\"\n"
        },
        {
          "name": "mvnw.cmd",
          "type": "blob",
          "size": 7.7177734375,
          "content": "@REM ----------------------------------------------------------------------------\r\n@REM Licensed to the Apache Software Foundation (ASF) under one\r\n@REM or more contributor license agreements.  See the NOTICE file\r\n@REM distributed with this work for additional information\r\n@REM regarding copyright ownership.  The ASF licenses this file\r\n@REM to you under the Apache License, Version 2.0 (the\r\n@REM \"License\"); you may not use this file except in compliance\r\n@REM with the License.  You may obtain a copy of the License at\r\n@REM\r\n@REM    http://www.apache.org/licenses/LICENSE-2.0\r\n@REM\r\n@REM Unless required by applicable law or agreed to in writing,\r\n@REM software distributed under the License is distributed on an\r\n@REM \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\r\n@REM KIND, either express or implied.  See the License for the\r\n@REM specific language governing permissions and limitations\r\n@REM under the License.\r\n@REM ----------------------------------------------------------------------------\r\n\r\n@REM ----------------------------------------------------------------------------\r\n@REM Apache Maven Wrapper startup batch script, version 3.3.2\r\n@REM\r\n@REM Required ENV vars:\r\n@REM JAVA_HOME - location of a JDK home dir\r\n@REM\r\n@REM Optional ENV vars\r\n@REM MAVEN_BATCH_ECHO - set to 'on' to enable the echoing of the batch commands\r\n@REM MAVEN_BATCH_PAUSE - set to 'on' to wait for a keystroke before ending\r\n@REM MAVEN_OPTS - parameters passed to the Java VM when running Maven\r\n@REM     e.g. to debug Maven itself, use\r\n@REM set MAVEN_OPTS=-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=8000\r\n@REM MAVEN_SKIP_RC - flag to disable loading of mavenrc files\r\n@REM ----------------------------------------------------------------------------\r\n\r\n@REM Begin all REM lines with '@' in case MAVEN_BATCH_ECHO is 'on'\r\n@echo off\r\n@REM set title of command window\r\ntitle %0\r\n@REM enable echoing by setting MAVEN_BATCH_ECHO to 'on'\r\n@if \"%MAVEN_BATCH_ECHO%\" == \"on\"  echo %MAVEN_BATCH_ECHO%\r\n\r\n@REM set %HOME% to equivalent of $HOME\r\nif \"%HOME%\" == \"\" (set \"HOME=%HOMEDRIVE%%HOMEPATH%\")\r\n\r\n@REM Execute a user defined script before this one\r\nif not \"%MAVEN_SKIP_RC%\" == \"\" goto skipRcPre\r\n@REM check for pre script, once with legacy .bat ending and once with .cmd ending\r\nif exist \"%USERPROFILE%\\mavenrc_pre.bat\" call \"%USERPROFILE%\\mavenrc_pre.bat\" %*\r\nif exist \"%USERPROFILE%\\mavenrc_pre.cmd\" call \"%USERPROFILE%\\mavenrc_pre.cmd\" %*\r\n:skipRcPre\r\n\r\n@setlocal\r\n\r\nset ERROR_CODE=0\r\n\r\n@REM To isolate internal variables from possible post scripts, we use another setlocal\r\n@setlocal\r\n\r\n@REM ==== START VALIDATION ====\r\nif not \"%JAVA_HOME%\" == \"\" goto OkJHome\r\n\r\necho. >&2\r\necho Error: JAVA_HOME not found in your environment. >&2\r\necho Please set the JAVA_HOME variable in your environment to match the >&2\r\necho location of your Java installation. >&2\r\necho. >&2\r\ngoto error\r\n\r\n:OkJHome\r\nif exist \"%JAVA_HOME%\\bin\\java.exe\" goto init\r\n\r\necho. >&2\r\necho Error: JAVA_HOME is set to an invalid directory. >&2\r\necho JAVA_HOME = \"%JAVA_HOME%\" >&2\r\necho Please set the JAVA_HOME variable in your environment to match the >&2\r\necho location of your Java installation. >&2\r\necho. >&2\r\ngoto error\r\n\r\n@REM ==== END VALIDATION ====\r\n\r\n:init\r\n\r\n@REM Find the project base dir, i.e. the directory that contains the folder \".mvn\".\r\n@REM Fallback to current working directory if not found.\r\n\r\nset MAVEN_PROJECTBASEDIR=%MAVEN_BASEDIR%\r\nIF NOT \"%MAVEN_PROJECTBASEDIR%\"==\"\" goto endDetectBaseDir\r\n\r\nset EXEC_DIR=%CD%\r\nset WDIR=%EXEC_DIR%\r\n:findBaseDir\r\nIF EXIST \"%WDIR%\"\\.mvn goto baseDirFound\r\ncd ..\r\nIF \"%WDIR%\"==\"%CD%\" goto baseDirNotFound\r\nset WDIR=%CD%\r\ngoto findBaseDir\r\n\r\n:baseDirFound\r\nset MAVEN_PROJECTBASEDIR=%WDIR%\r\ncd \"%EXEC_DIR%\"\r\ngoto endDetectBaseDir\r\n\r\n:baseDirNotFound\r\nset MAVEN_PROJECTBASEDIR=%EXEC_DIR%\r\ncd \"%EXEC_DIR%\"\r\n\r\n:endDetectBaseDir\r\n\r\nIF NOT EXIST \"%MAVEN_PROJECTBASEDIR%\\.mvn\\jvm.config\" goto endReadAdditionalConfig\r\n\r\n@setlocal EnableExtensions EnableDelayedExpansion\r\nfor /F \"usebackq delims=\" %%a in (\"%MAVEN_PROJECTBASEDIR%\\.mvn\\jvm.config\") do set JVM_CONFIG_MAVEN_PROPS=!JVM_CONFIG_MAVEN_PROPS! %%a\r\n@endlocal & set JVM_CONFIG_MAVEN_PROPS=%JVM_CONFIG_MAVEN_PROPS%\r\n\r\n:endReadAdditionalConfig\r\n\r\nSET MAVEN_JAVA_EXE=\"%JAVA_HOME%\\bin\\java.exe\"\r\nset WRAPPER_JAR=\"%MAVEN_PROJECTBASEDIR%\\.mvn\\wrapper\\maven-wrapper.jar\"\r\nset WRAPPER_LAUNCHER=org.apache.maven.wrapper.MavenWrapperMain\r\n\r\nset WRAPPER_URL=\"https://repo.maven.apache.org/maven2/org/apache/maven/wrapper/maven-wrapper/3.3.2/maven-wrapper-3.3.2.jar\"\r\n\r\nFOR /F \"usebackq tokens=1,2 delims==\" %%A IN (\"%MAVEN_PROJECTBASEDIR%\\.mvn\\wrapper\\maven-wrapper.properties\") DO (\r\n    IF \"%%A\"==\"wrapperUrl\" SET WRAPPER_URL=%%B\r\n)\r\n\r\n@REM Extension to allow automatically downloading the maven-wrapper.jar from Maven-central\r\n@REM This allows using the maven wrapper in projects that prohibit checking in binary data.\r\nif exist %WRAPPER_JAR% (\r\n    if \"%MVNW_VERBOSE%\" == \"true\" (\r\n        echo Found %WRAPPER_JAR%\r\n    )\r\n) else (\r\n    if not \"%MVNW_REPOURL%\" == \"\" (\r\n        SET WRAPPER_URL=\"%MVNW_REPOURL%/org/apache/maven/wrapper/maven-wrapper/3.3.2/maven-wrapper-3.3.2.jar\"\r\n    )\r\n    if \"%MVNW_VERBOSE%\" == \"true\" (\r\n        echo Couldn't find %WRAPPER_JAR%, downloading it ...\r\n        echo Downloading from: %WRAPPER_URL%\r\n    )\r\n\r\n    powershell -Command \"&{\"^\r\n\t\t\"$webclient = new-object System.Net.WebClient;\"^\r\n\t\t\"if (-not ([string]::IsNullOrEmpty('%MVNW_USERNAME%') -and [string]::IsNullOrEmpty('%MVNW_PASSWORD%'))) {\"^\r\n\t\t\"$webclient.Credentials = new-object System.Net.NetworkCredential('%MVNW_USERNAME%', '%MVNW_PASSWORD%');\"^\r\n\t\t\"}\"^\r\n\t\t\"[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12; $webclient.DownloadFile('%WRAPPER_URL%', '%WRAPPER_JAR%')\"^\r\n\t\t\"}\"\r\n    if \"%MVNW_VERBOSE%\" == \"true\" (\r\n        echo Finished downloading %WRAPPER_JAR%\r\n    )\r\n)\r\n@REM End of extension\r\n\r\n@REM If specified, validate the SHA-256 sum of the Maven wrapper jar file\r\nSET WRAPPER_SHA_256_SUM=\"\"\r\nFOR /F \"usebackq tokens=1,2 delims==\" %%A IN (\"%MAVEN_PROJECTBASEDIR%\\.mvn\\wrapper\\maven-wrapper.properties\") DO (\r\n    IF \"%%A\"==\"wrapperSha256Sum\" SET WRAPPER_SHA_256_SUM=%%B\r\n)\r\nIF NOT %WRAPPER_SHA_256_SUM%==\"\" (\r\n    powershell -Command \"&{\"^\r\n       \"Import-Module $PSHOME\\Modules\\Microsoft.PowerShell.Utility -Function Get-FileHash;\"^\r\n       \"$hash = (Get-FileHash \\\"%WRAPPER_JAR%\\\" -Algorithm SHA256).Hash.ToLower();\"^\r\n       \"If('%WRAPPER_SHA_256_SUM%' -ne $hash){\"^\r\n       \"  Write-Error 'Error: Failed to validate Maven wrapper SHA-256, your Maven wrapper might be compromised.';\"^\r\n       \"  Write-Error 'Investigate or delete %WRAPPER_JAR% to attempt a clean download.';\"^\r\n       \"  Write-Error 'If you updated your Maven version, you need to update the specified wrapperSha256Sum property.';\"^\r\n       \"  exit 1;\"^\r\n       \"}\"^\r\n       \"}\"\r\n    if ERRORLEVEL 1 goto error\r\n)\r\n\r\n@REM Provide a \"standardized\" way to retrieve the CLI args that will\r\n@REM work with both Windows and non-Windows executions.\r\nset MAVEN_CMD_LINE_ARGS=%*\r\n\r\n%MAVEN_JAVA_EXE% ^\r\n  %JVM_CONFIG_MAVEN_PROPS% ^\r\n  %MAVEN_OPTS% ^\r\n  %MAVEN_DEBUG_OPTS% ^\r\n  -classpath %WRAPPER_JAR% ^\r\n  \"-Dmaven.multiModuleProjectDirectory=%MAVEN_PROJECTBASEDIR%\" ^\r\n  %WRAPPER_LAUNCHER% %MAVEN_CONFIG% %*\r\nif ERRORLEVEL 1 goto error\r\ngoto end\r\n\r\n:error\r\nset ERROR_CODE=1\r\n\r\n:end\r\n@endlocal & set ERROR_CODE=%ERROR_CODE%\r\n\r\nif not \"%MAVEN_SKIP_RC%\"==\"\" goto skipRcPost\r\n@REM check for post script, once with legacy .bat ending and once with .cmd ending\r\nif exist \"%USERPROFILE%\\mavenrc_post.bat\" call \"%USERPROFILE%\\mavenrc_post.bat\"\r\nif exist \"%USERPROFILE%\\mavenrc_post.cmd\" call \"%USERPROFILE%\\mavenrc_post.cmd\"\r\n:skipRcPost\r\n\r\n@REM pause the script if MAVEN_BATCH_PAUSE is set to 'on'\r\nif \"%MAVEN_BATCH_PAUSE%\"==\"on\" pause\r\n\r\nif \"%MAVEN_TERMINATE_CMD%\"==\"on\" exit %ERROR_CODE%\r\n\r\ncmd /C exit /B %ERROR_CODE%\r\n"
        },
        {
          "name": "pom.xml",
          "type": "blob",
          "size": 87.5419921875,
          "content": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!--\nLicensed to the Apache Software Foundation (ASF) under one\nor more contributor license agreements.  See the NOTICE file\ndistributed with this work for additional information\nregarding copyright ownership.  The ASF licenses this file\nto you under the Apache License, Version 2.0 (the\n\"License\"); you may not use this file except in compliance\nwith the License.  You may obtain a copy of the License at\n  http://www.apache.org/licenses/LICENSE-2.0\nUnless required by applicable law or agreed to in writing,\nsoftware distributed under the License is distributed on an\n\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\nKIND, either express or implied.  See the License for the\nspecific language governing permissions and limitations\nunder the License.\n-->\n<project xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"\n\t\t xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">\n\n\t<parent>\n\t\t<groupId>org.apache</groupId>\n\t\t<artifactId>apache</artifactId>\n\t\t<version>20</version>\n\t</parent>\n\n\t<modelVersion>4.0.0</modelVersion>\n\n\t<groupId>org.apache.flink</groupId>\n\t<artifactId>flink-parent</artifactId>\n\t<version>2.0-SNAPSHOT</version>\n\n\t<name>Flink : </name>\n\t<packaging>pom</packaging>\n\t<url>https://flink.apache.org</url>\n\t<inceptionYear>2014</inceptionYear>\n\n\t<licenses>\n\t\t<license>\n\t\t\t<name>The Apache Software License, Version 2.0</name>\n\t\t\t<url>https://www.apache.org/licenses/LICENSE-2.0.txt</url>\n\t\t\t<distribution>repo</distribution>\n\t\t</license>\n\t</licenses>\n\n\t<scm>\n\t\t<url>https://github.com/apache/flink</url>\n\t\t<connection>git@github.com:apache/flink.git</connection>\n\t\t<developerConnection>scm:git:https://gitbox.apache.org/repos/asf/flink.git</developerConnection>\n\t</scm>\n\n\t<repositories>\n\t\t<repository>\n\t\t\t<id>repository.jboss.org</id>\n\t\t\t<url>https://repository.jboss.org/nexus/content/groups/public/</url>\n\t\t\t<snapshots>\n\t\t\t\t<enabled>false</enabled>\n\t\t\t</snapshots>\n\t\t\t<releases>\n\t\t\t\t<enabled>false</enabled>\n\t\t\t</releases>\n\t\t</repository>\n\t</repositories>\n\n\t<modules>\n\t\t<module>flink-annotations</module>\n\t\t<module>flink-architecture-tests</module>\n\t\t<module>flink-core-api</module>\n\t\t<module>flink-core</module>\n\t\t<module>flink-filesystems</module>\n\t\t<module>flink-rpc</module>\n\t\t<module>flink-runtime</module>\n\t\t<module>flink-runtime-web</module>\n\t\t<module>flink-streaming-java</module>\n\t\t<module>flink-connectors</module>\n\t\t<module>flink-formats</module>\n\t\t<module>flink-examples</module>\n\t\t<module>flink-clients</module>\n\t\t<module>flink-container</module>\n\t\t<module>flink-queryable-state</module>\n\t\t<module>flink-tests</module>\n\t\t<module>flink-end-to-end-tests</module>\n\t\t<module>flink-test-utils-parent</module>\n\t\t<module>flink-state-backends</module>\n\t\t<module>flink-dstl</module>\n\t\t<module>flink-libraries</module>\n\t\t<module>flink-table</module>\n\t\t<module>flink-quickstart</module>\n\t\t<module>flink-dist</module>\n\t\t<module>flink-dist-scala</module>\n\t\t<module>flink-metrics</module>\n\t\t<module>flink-yarn</module>\n\t\t<module>flink-yarn-tests</module>\n\t\t<module>flink-fs-tests</module>\n\t\t<module>flink-docs</module>\n\t\t<module>flink-python</module>\n\t\t<module>flink-walkthroughs</module>\n\t\t<module>flink-kubernetes</module>\n\t\t<module>flink-external-resources</module>\n\t\t<module>tools/ci/flink-ci-tools</module>\n\t\t<module>flink-datastream</module>\n\t\t<module>flink-datastream-api</module>\n\t</modules>\n\n\t<properties>\n\t\t<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n\t\t<project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>\n\t\t<flink.hadoop.version>2.10.2</flink.hadoop.version>\n\t\t<flink.XmxMax>3072m</flink.XmxMax>\n\t\t<!-- XmxMax / forkCountITCase -->\n\t\t<flink.XmxITCase>1536m</flink.XmxITCase>\n\t\t<!-- XmxMax / forkCountUnitTest -->\n\t\t<flink.XmxUnitTest>768m</flink.XmxUnitTest>\n\t\t<!-- Need to use a user property here because the surefire\n\t\t\t forkCount is not exposed as a property. With this we can set\n\t\t\t it on the \"mvn\" commandline in travis. -->\n\t\t<!-- Number of forkCounts for ITCase and UnitTest should take into account allocated memory\n\t\t\t to the jvm (-Xmx) and the available memory on the machine running the test -->\n\t\t<flink.forkCountITCase>2</flink.forkCountITCase>\n\t\t<flink.forkCountUnitTest>4</flink.forkCountUnitTest>\n\t\t<flink.reuseForks>true</flink.reuseForks>\n\t\t<flink.surefire.baseArgLine>-XX:+UseG1GC -Xms256m -XX:+IgnoreUnrecognizedVMOptions ${surefire.module.config}</flink.surefire.baseArgLine>\n\t\t<flink.shaded.version>19.0</flink.shaded.version>\n\t\t<flink.shaded.jackson.version>2.15.3</flink.shaded.jackson.version>\n\t\t<flink.shaded.jsonpath.version>2.7.0</flink.shaded.jsonpath.version>\n\t\t<flink.markBundledAsOptional>true</flink.markBundledAsOptional>\n\t\t<target.java.version>11</target.java.version>\n\t\t<slf4j.version>1.7.36</slf4j.version>\n\t\t<log4j.version>2.24.1</log4j.version>\n\t\t<!-- Overwrite default values from parent pom.\n\t\t\t IntelliJ IDEA is (sometimes?) using those values to choose target language level\n\t\t\t and thus is changing back to java 1.6 on each maven re-import -->\n\t\t<maven.compiler.source>${target.java.version}</maven.compiler.source>\n\t\t<maven.compiler.target>${target.java.version}</maven.compiler.target>\n\t\t<scala.macros.version>2.1.1</scala.macros.version>\n\t\t<!-- Default scala versions, must be overwritten by build profiles, so we set something\n\t\tinvalid here -->\n\t\t<scala.version>2.12.7</scala.version>\n\t\t<scala.binary.version>2.12</scala.binary.version>\n\t\t<chill.version>0.7.6</chill.version>\n\t\t<!-- keep FlinkTestcontainersConfigurator.configureZookeeperContainer in sync -->\n\t\t<zookeeper.version>3.7.2</zookeeper.version>\n\t\t<!-- Project `flink-benchmarks` uses zk testing server in `curator-test` for performance\n\t\tbenchmark, please confirm it will not affect the benchmarks when the version is bumped. -->\n\t\t<curator.version>5.4.0</curator.version>\n\t\t<avro.version>1.11.4</avro.version>\n\t\t<!-- Version for transitive Jackson dependencies that are not used within Flink itself.-->\n\t\t<jackson-bom.version>2.18.2</jackson-bom.version>\n\t\t<javax.activation.api.version>1.2.0</javax.activation.api.version>\n\t\t<jaxb.api.version>2.3.1</jaxb.api.version>\n\t\t<junit4.version>4.13.2</junit4.version>\n\t\t<junit5.version>5.10.1</junit5.version>\n\t\t<archunit.version>1.2.0</archunit.version>\n\t\t<mockito.version>5.14.2</mockito.version>\n\t\t<hamcrest.version>1.3</hamcrest.version>\n\t\t<assertj.version>3.23.1</assertj.version>\n\t\t<py4j.version>0.10.9.7</py4j.version>\n\t\t<beam.version>2.43.0</beam.version>\n\t\t<protoc.version>3.21.7</protoc.version>\n\t\t<okhttp.version>3.14.9</okhttp.version>\n\t\t<testcontainers.version>1.20.2</testcontainers.version>\n\t\t<lz4.version>1.8.0</lz4.version>\n\t\t<commons.io.version>2.15.1</commons.io.version>\n\t\t<japicmp.skip>false</japicmp.skip>\n\t\t<flink.convergence.phase>validate</flink.convergence.phase>\n\t\t<!--\n\t\t\tKeeping the MiniKDC version fixed instead of taking hadoop version dependency\n\t\t\tto support testing Kafka, ZK etc., modules that does not have Hadoop dependency\n\t\t\tStarting Hadoop 3, org.apache.kerby will be used instead of MiniKDC. We may have\n\t\t\tto revisit the impact at that time.\n\t\t-->\n\t\t<minikdc.version>3.2.4</minikdc.version>\n\t\t<hive.version>2.3.10</hive.version>\n\t\t<orc.version>1.5.6</orc.version>\n\t\t<japicmp.referenceVersion>1.20.0</japicmp.referenceVersion>\n\t\t<japicmp.outputDir>tools/japicmp-output</japicmp.outputDir>\n\t\t<checkstyle.version>10.18.2</checkstyle.version>\n\t\t<spotless.skip>false</spotless.skip>\n\t\t<spotless.version>2.43.0</spotless.version>\n\t\t<spotless.scalafmt.version>3.4.3</spotless.scalafmt.version>\n\t\t<spotless.delimiter>package</spotless.delimiter>\n\t\t<spotless.license.header>\n/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\t\t</spotless.license.header>\n\n\t\t<!-- This property should contain the add-opens/add-exports commands required for the tests\n\t\t     in the given module to pass.\n\t\t     It MUST be a space-separated list not containing any newlines,\n\t\t     of entries in the form '[-]{2}add-[opens|exports]=<module>/<package>=ALL-UNNAMED'.-->\n\t\t<surefire.module.config/>\n\n\t\t<surefire.excludedGroups.github-actions/>\n\t\t<surefire.excludedGroups.adaptive-scheduler/>\n\t\t<surefire.excludedGroups.jdk/>\n\n\t\t<!-- Can be set to any value to reproduce a specific build. -->\n\t\t<test.randomization.seed/>\n\t\t<test.unit.pattern>**/*Test.*</test.unit.pattern>\n\t\t<snappy.java.version>1.1.10.7</snappy.java.version>\n\t</properties>\n\n\t<dependencies>\n\n\t\t<dependency>\n\t\t\t<groupId>org.apache.flink</groupId>\n\t\t\t<artifactId>flink-shaded-force-shading</artifactId>\n\t\t\t<optional>${flink.markBundledAsOptional}</optional>\n\t\t</dependency>\n\n\t\t<!-- Root dependencies for all projects -->\n\n\t\t<!-- Logging API -->\n\t\t<dependency>\n\t\t\t<groupId>org.slf4j</groupId>\n\t\t\t<artifactId>slf4j-api</artifactId>\n\t\t</dependency>\n\n\t\t<!-- 'javax.annotation' classes like '@Nullable' -->\n\t\t<dependency>\n\t\t\t<groupId>com.google.code.findbugs</groupId>\n\t\t\t<artifactId>jsr305</artifactId>\n\t\t</dependency>\n\n\t\t<!-- test dependencies -->\n\t\t<dependency>\n\t\t\t<groupId>org.junit.jupiter</groupId>\n\t\t\t<artifactId>junit-jupiter</artifactId>\n\t\t\t<scope>test</scope>\n\t\t</dependency>\n\n\t\t<dependency>\n\t\t\t<groupId>org.junit.vintage</groupId>\n\t\t\t<artifactId>junit-vintage-engine</artifactId>\n\t\t\t<scope>test</scope>\n\t\t</dependency>\n\n\t\t<dependency>\n\t\t\t<groupId>org.assertj</groupId>\n\t\t\t<artifactId>assertj-core</artifactId>\n\t\t\t<scope>test</scope>\n\t\t</dependency>\n\n\t\t<dependency>\n\t\t\t<groupId>org.mockito</groupId>\n\t\t\t<artifactId>mockito-core</artifactId>\n\t\t\t<version>${mockito.version}</version>\n\t\t\t<type>jar</type>\n\t\t\t<scope>test</scope>\n\t\t</dependency>\n\n\t\t<dependency>\n\t\t\t<groupId>org.mockito</groupId>\n\t\t\t<artifactId>mockito-junit-jupiter</artifactId>\n\t\t\t<version>${mockito.version}</version>\n\t\t\t<type>jar</type>\n\t\t\t<scope>test</scope>\n\t\t</dependency>\n\n\t\t<dependency>\n\t\t\t<groupId>org.hamcrest</groupId>\n\t\t\t<artifactId>hamcrest-all</artifactId>\n\t\t\t<version>${hamcrest.version}</version>\n\t\t\t<type>jar</type>\n\t\t\t<scope>test</scope>\n\t\t</dependency>\n\n\t\t<dependency>\n\t\t\t<groupId>org.testcontainers</groupId>\n\t\t\t<artifactId>junit-jupiter</artifactId>\n\t\t\t<scope>test</scope>\n\t\t</dependency>\n\n\t\t<!-- tests will have log4j as the default logging framework available -->\n\n\t\t<dependency>\n\t\t\t<groupId>org.apache.logging.log4j</groupId>\n\t\t\t<artifactId>log4j-slf4j-impl</artifactId>\n\t\t\t<scope>test</scope>\n\t\t</dependency>\n\n\t\t<dependency>\n\t\t\t<groupId>org.apache.logging.log4j</groupId>\n\t\t\t<artifactId>log4j-api</artifactId>\n\t\t\t<scope>test</scope>\n\t\t</dependency>\n\n\t\t<dependency>\n\t\t\t<groupId>org.apache.logging.log4j</groupId>\n\t\t\t<artifactId>log4j-core</artifactId>\n\t\t\t<scope>test</scope>\n\t\t</dependency>\n\n\t\t<dependency>\n\t\t\t<!-- API bridge between log4j 1 and 2 -->\n\t\t\t<groupId>org.apache.logging.log4j</groupId>\n\t\t\t<artifactId>log4j-1.2-api</artifactId>\n\t\t\t<scope>test</scope>\n\t\t</dependency>\n\n\t</dependencies>\n\n\t<!-- this section defines the module versions that are used if nothing else is specified. -->\n\n\t<dependencyManagement>\n\t\t<!-- WARN:\n\t\t\tDO NOT put \tguava,\n\t\t\t\t\t\tprotobuf,\n\t\t\t\t\t\tasm,\n\t\t\t\t\t\tnetty\n\t\t\t\t\there. It will overwrite Hadoop's guava dependency (even though we handle it\n\t\t\tseparatly in the flink-shaded-hadoop-2 dependency).\n\t\t-->\n\t\t<dependencies>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.flink</groupId>\n\t\t\t\t<artifactId>flink-shaded-force-shading</artifactId>\n\t\t\t\t<version>${flink.shaded.version}</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.flink</groupId>\n\t\t\t\t<artifactId>flink-shaded-asm-9</artifactId>\n\t\t\t\t<version>9.6-${flink.shaded.version}</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.flink</groupId>\n\t\t\t\t<artifactId>flink-shaded-guava</artifactId>\n\t\t\t\t<version>32.1.3-jre-${flink.shaded.version}</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.flink</groupId>\n\t\t\t\t<artifactId>flink-shaded-jackson</artifactId>\n\t\t\t\t<version>${flink.shaded.jackson.version}-${flink.shaded.version}</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.flink</groupId>\n\t\t\t\t<artifactId>flink-shaded-jackson-module-jsonSchema</artifactId>\n\t\t\t\t<version>${flink.shaded.jackson.version}-${flink.shaded.version}</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.flink</groupId>\n\t\t\t\t<artifactId>flink-shaded-netty</artifactId>\n\t\t\t\t<version>4.1.100.Final-${flink.shaded.version}</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.flink</groupId>\n\t\t\t\t<artifactId>flink-shaded-netty-tcnative-dynamic</artifactId>\n\t\t\t\t<version>2.0.62.Final-${flink.shaded.version}</version>\n\t\t\t\t<scope>test</scope>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.hadoop</groupId>\n\t\t\t\t<artifactId>hadoop-common</artifactId>\n\t\t\t\t<version>${flink.hadoop.version}</version>\n\t\t\t\t<exclusions>\n\t\t\t\t\t<exclusion>\n\t\t\t\t\t\t<groupId>jdk.tools</groupId>\n\t\t\t\t\t\t<artifactId>jdk.tools</artifactId>\n\t\t\t\t\t</exclusion>\n\t\t\t\t\t<exclusion>\n\t\t\t\t\t\t<groupId>log4j</groupId>\n\t\t\t\t\t\t<artifactId>log4j</artifactId>\n\t\t\t\t\t</exclusion>\n\t\t\t\t\t<exclusion>\n\t\t\t\t\t\t<groupId>org.slf4j</groupId>\n\t\t\t\t\t\t<artifactId>slf4j-log4j12</artifactId>\n\t\t\t\t\t</exclusion>\n\t\t\t\t</exclusions>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.hadoop</groupId>\n\t\t\t\t<artifactId>hadoop-hdfs</artifactId>\n\t\t\t\t<version>${flink.hadoop.version}</version>\n\t\t\t\t<exclusions>\n\t\t\t\t\t<exclusion>\n\t\t\t\t\t\t<groupId>jdk.tools</groupId>\n\t\t\t\t\t\t<artifactId>jdk.tools</artifactId>\n\t\t\t\t\t</exclusion>\n\t\t\t\t\t<exclusion>\n\t\t\t\t\t\t<groupId>log4j</groupId>\n\t\t\t\t\t\t<artifactId>log4j</artifactId>\n\t\t\t\t\t</exclusion>\n\t\t\t\t\t<exclusion>\n\t\t\t\t\t\t<groupId>org.slf4j</groupId>\n\t\t\t\t\t\t<artifactId>slf4j-log4j12</artifactId>\n\t\t\t\t\t</exclusion>\n\t\t\t\t\t<exclusion>\n\t\t\t\t\t\t<groupId>ch.qos.reload4j</groupId>\n\t\t\t\t\t\t<artifactId>reload4j</artifactId>\n\t\t\t\t\t</exclusion>\n\t\t\t\t\t<exclusion>\n\t\t\t\t\t\t<groupId>org.slf4j</groupId>\n\t\t\t\t\t\t<artifactId>slf4j-reload4j</artifactId>\n\t\t\t\t\t</exclusion>\n\t\t\t\t</exclusions>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.hadoop</groupId>\n\t\t\t\t<artifactId>hadoop-mapreduce-client-core</artifactId>\n\t\t\t\t<version>${flink.hadoop.version}</version>\n\t\t\t\t<exclusions>\n\t\t\t\t\t<exclusion>\n\t\t\t\t\t\t<groupId>jdk.tools</groupId>\n\t\t\t\t\t\t<artifactId>jdk.tools</artifactId>\n\t\t\t\t\t</exclusion>\n\t\t\t\t\t<exclusion>\n\t\t\t\t\t\t<groupId>log4j</groupId>\n\t\t\t\t\t\t<artifactId>log4j</artifactId>\n\t\t\t\t\t</exclusion>\n\t\t\t\t\t<exclusion>\n\t\t\t\t\t\t<groupId>org.slf4j</groupId>\n\t\t\t\t\t\t<artifactId>slf4j-log4j12</artifactId>\n\t\t\t\t\t</exclusion>\n\t\t\t\t\t<exclusion>\n\t\t\t\t\t\t<groupId>ch.qos.reload4j</groupId>\n\t\t\t\t\t\t<artifactId>reload4j</artifactId>\n\t\t\t\t\t</exclusion>\n\t\t\t\t\t<exclusion>\n\t\t\t\t\t\t<groupId>org.slf4j</groupId>\n\t\t\t\t\t\t<artifactId>slf4j-reload4j</artifactId>\n\t\t\t\t\t</exclusion>\n\t\t\t\t</exclusions>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.hadoop</groupId>\n\t\t\t\t<artifactId>hadoop-yarn-common</artifactId>\n\t\t\t\t<version>${flink.hadoop.version}</version>\n\t\t\t\t<exclusions>\n\t\t\t\t\t<exclusion>\n\t\t\t\t\t\t<groupId>jdk.tools</groupId>\n\t\t\t\t\t\t<artifactId>jdk.tools</artifactId>\n\t\t\t\t\t</exclusion>\n\t\t\t\t\t<exclusion>\n\t\t\t\t\t\t<groupId>log4j</groupId>\n\t\t\t\t\t\t<artifactId>log4j</artifactId>\n\t\t\t\t\t</exclusion>\n\t\t\t\t\t<exclusion>\n\t\t\t\t\t\t<groupId>org.slf4j</groupId>\n\t\t\t\t\t\t<artifactId>slf4j-log4j12</artifactId>\n\t\t\t\t\t</exclusion>\n\t\t\t\t</exclusions>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.hadoop</groupId>\n\t\t\t\t<artifactId>hadoop-yarn-client</artifactId>\n\t\t\t\t<version>${flink.hadoop.version}</version>\n\t\t\t\t<exclusions>\n\t\t\t\t\t<exclusion>\n\t\t\t\t\t\t<groupId>jdk.tools</groupId>\n\t\t\t\t\t\t<artifactId>jdk.tools</artifactId>\n\t\t\t\t\t</exclusion>\n\t\t\t\t\t<exclusion>\n\t\t\t\t\t\t<groupId>log4j</groupId>\n\t\t\t\t\t\t<artifactId>log4j</artifactId>\n\t\t\t\t\t</exclusion>\n\t\t\t\t\t<exclusion>\n\t\t\t\t\t\t<groupId>org.slf4j</groupId>\n\t\t\t\t\t\t<artifactId>slf4j-log4j12</artifactId>\n\t\t\t\t\t</exclusion>\n\t\t\t\t</exclusions>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.flink</groupId>\n\t\t\t\t<artifactId>flink-shaded-zookeeper-3</artifactId>\n\t\t\t\t<version>${zookeeper.version}-${flink.shaded.version}</version>\n\t\t\t</dependency>\n\n\t\t\t<!-- This manages the 'javax.annotation' annotations (JSR305) -->\n\t\t\t<dependency>\n\t\t\t\t<groupId>com.google.code.findbugs</groupId>\n\t\t\t\t<artifactId>jsr305</artifactId>\n\t\t\t\t<version>1.3.9</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.slf4j</groupId>\n\t\t\t\t<artifactId>slf4j-api</artifactId>\n\t\t\t\t<version>${slf4j.version}</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.logging.log4j</groupId>\n\t\t\t\t<artifactId>log4j-slf4j-impl</artifactId>\n\t\t\t\t<version>${log4j.version}</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.logging.log4j</groupId>\n\t\t\t\t<artifactId>log4j-api</artifactId>\n\t\t\t\t<version>${log4j.version}</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.logging.log4j</groupId>\n\t\t\t\t<artifactId>log4j-core</artifactId>\n\t\t\t\t<version>${log4j.version}</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<!-- API bridge between log4j 1 and 2 -->\n\t\t\t\t<groupId>org.apache.logging.log4j</groupId>\n\t\t\t\t<artifactId>log4j-1.2-api</artifactId>\n\t\t\t\t<version>${log4j.version}</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.commons</groupId>\n\t\t\t\t<artifactId>commons-lang3</artifactId>\n\t\t\t\t<version>3.12.0</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.commons</groupId>\n\t\t\t\t<artifactId>commons-text</artifactId>\n\t\t\t\t<version>1.10.0</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.xerial.snappy</groupId>\n\t\t\t\t<artifactId>snappy-java</artifactId>\n\t\t\t\t<version>${snappy.java.version}</version>\n\t\t\t\t<exclusions>\n\t\t\t\t\t<exclusion>\n\t\t\t\t\t\t<!-- Causes unnecessary dependency convergence errors; see MENFORCER-437 -->\n\t\t\t\t\t\t<groupId>org.osgi</groupId>\n\t\t\t\t\t\t<artifactId>org.osgi.core</artifactId>\n\t\t\t\t\t</exclusion>\n\t\t\t\t</exclusions>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.lz4</groupId>\n\t\t\t\t<artifactId>lz4-java</artifactId>\n\t\t\t\t<version>${lz4.version}</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>com.github.oshi</groupId>\n\t\t\t\t<artifactId>oshi-core</artifactId>\n\t\t\t\t<version>6.1.5</version>\n\t\t\t</dependency>\n\n\t\t\t<!-- We no longer align the avro version with the version bundled in Hadoop.\n\t\t\t Users might need to downgrade the avro version for a particular Hadoop version. -->\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.avro</groupId>\n\t\t\t\t<artifactId>avro</artifactId>\n\t\t\t\t<version>${avro.version}</version>\n\t\t\t</dependency>\n\n\t\t\t<!-- For dependency convergence -->\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.hamcrest</groupId>\n\t\t\t\t<artifactId>hamcrest-core</artifactId>\n\t\t\t\t<version>${hamcrest.version}</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>net.bytebuddy</groupId>\n\t\t\t\t<artifactId>byte-buddy</artifactId>\n\t\t\t\t<version>1.15.11</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>net.bytebuddy</groupId>\n\t\t\t\t<artifactId>byte-buddy-agent</artifactId>\n\t\t\t\t<version>1.15.11</version>\n\t\t\t</dependency>\n\n\t\t\t<!-- For dependency convergence -->\n\t\t\t<dependency>\n\t\t\t\t<groupId>net.java.dev.jna</groupId>\n\t\t\t\t<artifactId>jna</artifactId>\n\t\t\t\t<version>5.12.1</version>\n\t\t\t</dependency>\n\n\t\t\t<!-- For dependency convergence -->\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.objenesis</groupId>\n\t\t\t\t<artifactId>objenesis</artifactId>\n\t\t\t\t<version>2.1</version>\n\t\t\t</dependency>\n\n\t\t\t<!-- For dependency convergence -->\n\t\t\t<dependency>\n\t\t\t\t<groupId>commons-logging</groupId>\n\t\t\t\t<artifactId>commons-logging</artifactId>\n\t\t\t\t<version>1.1.3</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>com.fasterxml.jackson</groupId>\n\t\t\t\t<artifactId>jackson-bom</artifactId>\n\t\t\t\t<type>pom</type>\n\t\t\t\t<scope>import</scope>\n\t\t\t\t<version>${jackson-bom.version}</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>com.squareup.okhttp3</groupId>\n\t\t\t\t<artifactId>okhttp</artifactId>\n\t\t\t\t<version>${okhttp.version}</version>\n\t\t\t</dependency>\n\t\t\t<dependency>\n\t\t\t\t<groupId>com.squareup.okhttp3</groupId>\n\t\t\t\t<artifactId>logging-interceptor</artifactId>\n\t\t\t\t<version>${okhttp.version}</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<!-- re-branded javax.activation:javax.activation-api that is provided by flink-dist\n\t\t\t\t \t(the package names are identical!) -->\n\t\t\t\t<groupId>jakarta.activation</groupId>\n\t\t\t\t<artifactId>jakarta.activation-api</artifactId>\n\t\t\t\t<version>1.2.1</version>\n\t\t\t\t<scope>provided</scope>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<!-- re-branded javax.xml.bind:jaxb-api that is provided by flink-dist\n\t\t\t\t\t(the package names are identical!) -->\n\t\t\t\t<groupId>jakarta.xml.bind</groupId>\n\t\t\t\t<artifactId>jakarta.xml.bind-api</artifactId>\n\t\t\t\t<version>2.3.2</version>\n\t\t\t\t<scope>provided</scope>\n\t\t\t</dependency>\n\n\t\t\t<!-- For dependency convergence -->\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.junit</groupId>\n\t\t\t\t<artifactId>junit-bom</artifactId>\n\t\t\t\t<version>${junit5.version}</version>\n\t\t\t\t<type>pom</type>\n\t\t\t\t<scope>import</scope>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>junit</groupId>\n\t\t\t\t<artifactId>junit</artifactId>\n\t\t\t\t<version>${junit4.version}</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.assertj</groupId>\n\t\t\t\t<artifactId>assertj-core</artifactId>\n\t\t\t\t<version>${assertj.version}</version>\n\t\t\t\t<scope>test</scope>\n\t\t\t</dependency>\n\n\t\t\t<!-- Make sure we use a consistent commons-cli version throughout the project -->\n\t\t\t<dependency>\n\t\t\t\t<groupId>commons-cli</groupId>\n\t\t\t\t<artifactId>commons-cli</artifactId>\n\t\t\t\t<version>1.5.0</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>commons-io</groupId>\n\t\t\t\t<artifactId>commons-io</artifactId>\n\t\t\t\t<version>${commons.io.version}</version>\n\t\t\t</dependency>\n\n\t\t\t<!-- commons collections needs to be pinned to this critical security fix version -->\n\t\t\t<dependency>\n\t\t\t\t<groupId>commons-collections</groupId>\n\t\t\t\t<artifactId>commons-collections</artifactId>\n\t\t\t\t<version>3.2.2</version>\n\t\t\t</dependency>\n\n\t\t\t<!--We have to bump the commons-configuration to version 1.7 because Hadoop uses per\n\t\t\tdefault 1.6. This version has the problem that it depends on commons-beanutils-core and\n\t\t\tcommons-digester. Commons-digester depends on commons-beanutils. Both dependencies are\n\t\t\tcontains classes of commons-collections. Since the dependency reduced pom does not\n\t\t\texclude commons-beanutils from commons-configuration, sbt would pull it in again. The\n\t\t\tsolution is setting the version of commons-configuration to 1.7 which also depends on\n\t\t\tcommon-beanutils. Consequently, the dependency reduced pom will also contain an\n\t\t\texclusion for commons-beanutils for commons-configuration. -->\n\t\t\t<dependency>\n\t\t\t\t<groupId>commons-configuration</groupId>\n\t\t\t\t<artifactId>commons-configuration</artifactId>\n\t\t\t\t<version>1.7</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>commons-codec</groupId>\n\t\t\t\t<artifactId>commons-codec</artifactId>\n\t\t\t\t<version>1.15</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.commons</groupId>\n\t\t\t\t<artifactId>commons-math3</artifactId>\n\t\t\t\t<version>3.6.1</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.commons</groupId>\n\t\t\t\t<artifactId>commons-compress</artifactId>\n\t\t\t\t<version>1.26.0</version>\n\t\t\t\t<exclusions>\n\t\t\t\t\t<exclusion>\n\t\t\t\t\t\t<!-- Causes unnecessary dependency convergence errors; see MENFORCER-437 -->\n\t\t\t\t\t\t<groupId>org.osgi</groupId>\n\t\t\t\t\t\t<artifactId>org.osgi.core</artifactId>\n\t\t\t\t\t</exclusion>\n\t\t\t\t</exclusions>\n\t\t\t</dependency>\n\n\t\t\t<!-- Managed dependency required for HBase in flink-connector-hbase -->\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.javassist</groupId>\n\t\t\t\t<artifactId>javassist</artifactId>\n\t\t\t\t<version>3.24.0-GA</version>\n\t\t\t</dependency>\n\n\t\t\t<!-- joda time is pulled in different versions by different transitive dependencies-->\n\t\t\t<dependency>\n\t\t\t\t<groupId>joda-time</groupId>\n\t\t\t\t<artifactId>joda-time</artifactId>\n\t\t\t\t<version>2.5</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.joda</groupId>\n\t\t\t\t<artifactId>joda-convert</artifactId>\n\t\t\t\t<version>1.7</version>\n\t\t\t</dependency>\n\n\t\t\t<!-- kryo used in different versions by Flink an chill -->\n\t\t\t<dependency>\n\t\t\t\t<groupId>com.esotericsoftware.kryo</groupId>\n\t\t\t\t<artifactId>kryo</artifactId>\n\t\t\t\t<version>2.24.0</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.scala-lang</groupId>\n\t\t\t\t<artifactId>scala-library</artifactId>\n\t\t\t\t<version>${scala.version}</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.scala-lang</groupId>\n\t\t\t\t<artifactId>scala-reflect</artifactId>\n\t\t\t\t<version>${scala.version}</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.scala-lang</groupId>\n\t\t\t\t<artifactId>scala-compiler</artifactId>\n\t\t\t\t<version>${scala.version}</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.scalatest</groupId>\n\t\t\t\t<artifactId>scalatest_${scala.binary.version}</artifactId>\n\t\t\t\t<version>3.0.0</version>\n\t\t\t\t<scope>test</scope>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.zookeeper</groupId>\n\t\t\t\t<artifactId>zookeeper</artifactId>\n\t\t\t\t<version>${zookeeper.version}</version>\n\t\t\t\t<exclusions>\n\t\t\t\t\t<exclusion>\n\t\t\t\t\t\t<groupId>log4j</groupId>\n\t\t\t\t\t\t<artifactId>log4j</artifactId>\n\t\t\t\t\t</exclusion>\n\t\t\t\t\t<exclusion>\n\t\t\t\t\t\t<groupId>org.slf4j</groupId>\n\t\t\t\t\t\t<artifactId>slf4j-log4j12</artifactId>\n\t\t\t\t\t</exclusion>\n\t\t\t\t\t<exclusion>\n\t\t\t\t\t\t<!-- Netty is an optional dependency, that we currently do not make use of. -->\n\t\t\t\t\t\t<groupId>io.netty</groupId>\n\t\t\t\t\t\t<artifactId>*</artifactId>\n\t\t\t\t\t</exclusion>\n\t\t\t\t\t<!-- jline is optional for ZK console shell -->\n\t\t\t\t\t<exclusion>\n\t\t\t\t\t\t<groupId>jline</groupId>\n\t\t\t\t\t\t<artifactId>jline</artifactId>\n\t\t\t\t\t</exclusion>\n\t\t\t\t</exclusions>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<!-- For dependency convergence\n\t\t\t\t\tOn Java 8- this dependency is bundled with the JDK\n\t\t\t\t\tOn Java 11+ this dependency is bundled in flink-dist -->\n\t\t\t\t<groupId>javax.xml.bind</groupId>\n\t\t\t\t<artifactId>jaxb-api</artifactId>\n\t\t\t\t<version>${jaxb.api.version}</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<!-- For dependency convergence\n\t\t\t\t\tOn Java 8- this dependency is bundled with the JDK\n\t\t\t\t\tOn Java 11+ this dependency is bundled in flink-dist -->\n\t\t\t\t<groupId>javax.activation</groupId>\n\t\t\t\t<artifactId>javax.activation-api</artifactId>\n\t\t\t\t<version>${javax.activation.api.version}</version>\n\t\t\t</dependency>\n\n\t\t\t<!-- We have to define the versions for httpcore and httpclient here such that a consistent\n\t\t\t version is used by the shaded hadoop jars and the flink-yarn-test project because of MNG-5899.\n\n\t\t\t See FLINK-6836 for more details -->\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.httpcomponents</groupId>\n\t\t\t\t<artifactId>httpcore</artifactId>\n\t\t\t\t<version>4.4.14</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.httpcomponents</groupId>\n\t\t\t\t<artifactId>httpclient</artifactId>\n\t\t\t\t<version>4.5.13</version>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.reflections</groupId>\n\t\t\t\t<artifactId>reflections</artifactId>\n\t\t\t\t<version>0.9.10</version>\n\t\t\t\t<scope>test</scope>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.flink</groupId>\n\t\t\t\t<artifactId>flink-test-utils-junit</artifactId>\n\t\t\t\t<version>${project.version}</version>\n\t\t\t\t<scope>test</scope>\n\t\t\t</dependency>\n\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.flink</groupId>\n\t\t\t\t<artifactId>flink-architecture-tests-base</artifactId>\n\t\t\t\t<version>${project.version}</version>\n\t\t\t\t<scope>test</scope>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.apache.flink</groupId>\n\t\t\t\t<artifactId>flink-architecture-tests-test</artifactId>\n\t\t\t\t<version>${project.version}</version>\n\t\t\t\t<scope>test</scope>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<!-- log4j2 has an optional dependency on disruptor which may affect other dependencies (like hive)\n\t\t\t\t\tpin the version here to make this behavior explicit -->\n\t\t\t\t<groupId>com.lmax</groupId>\n\t\t\t\t<artifactId>disruptor</artifactId>\n\t\t\t\t<version>3.4.2</version>\n\t\t\t</dependency>\n\t\t\t<dependency>\n\t\t\t\t<!-- Bumped for security purposes and making it work with Jackson dependencies (2.18.2) -->\n\t\t\t\t<groupId>org.yaml</groupId>\n\t\t\t\t<artifactId>snakeyaml</artifactId>\n\t\t\t\t<version>2.3</version>\n\t\t\t</dependency>\n\t\t\t<dependency>\n\t\t\t\t<groupId>io.netty</groupId>\n\t\t\t\t<artifactId>netty-bom</artifactId>\n\t\t\t\t<version>4.1.100.Final</version>\n\t\t\t\t<type>pom</type>\n\t\t\t\t<scope>import</scope>\n\t\t\t</dependency>\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.testcontainers</groupId>\n\t\t\t\t<artifactId>testcontainers-bom</artifactId>\n\t\t\t\t<version>${testcontainers.version}</version>\n\t\t\t\t<type>pom</type>\n\t\t\t\t<scope>import</scope>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>com.tngtech.archunit</groupId>\n\t\t\t\t<artifactId>archunit</artifactId>\n\t\t\t\t<version>${archunit.version}</version>\n\t\t\t\t<scope>test</scope>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>com.tngtech.archunit</groupId>\n\t\t\t\t<artifactId>archunit-junit5</artifactId>\n\t\t\t\t<version>${archunit.version}</version>\n\t\t\t\t<scope>test</scope>\n\t\t\t</dependency>\n\n\t\t\t<dependency>\n\t\t\t\t<groupId>org.mockito</groupId>\n\t\t\t\t<artifactId>mockito-subclass</artifactId>\n\t\t\t\t<version>${mockito.version}</version>\n\t\t\t\t<scope>test</scope>\n\t\t\t</dependency>\n\t\t</dependencies>\n\t</dependencyManagement>\n\n\t<profiles>\n\t\t<profile>\n\t\t\t<id>intellij</id>\n\t\t\t<activation>\n\t\t\t\t<property>\n\t\t\t\t\t<name>idea.version</name>\n\t\t\t\t</property>\n\t\t\t</activation>\n\t\t\t<properties>\n\t\t\t\t<!-- Set to false so that all required dependencies are put on the classpath,\n\t\t\t\t     since IntelliJ does not work against jars produced by the shade plugin\n\t\t\t\t     (which may bundled said classes). -->\n\t\t\t\t<flink.markBundledAsOptional>false</flink.markBundledAsOptional>\n\t\t\t</properties>\n\t\t</profile>\n\t\t<profile>\n\t\t\t<id>scala-2.12</id>\n\t\t\t<properties>\n\t\t\t\t<scala.version>2.12.7</scala.version>\n\t\t\t\t<scala.binary.version>2.12</scala.binary.version>\n\t\t\t</properties>\n\t\t\t<activation>\n\t\t\t\t<activeByDefault>true</activeByDefault>\n\t\t\t</activation>\n\t\t\t<build>\n\t\t\t\t<plugins>\n\t\t\t\t\t<!-- make sure we don't have any _2.10 or _2.11 dependencies when building\n\t\t\t\t\tfor Scala 2.12 -->\n\t\t\t\t\t<plugin>\n\t\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t\t<artifactId>maven-enforcer-plugin</artifactId>\n\t\t\t\t\t\t<executions>\n\t\t\t\t\t\t\t<execution>\n\t\t\t\t\t\t\t\t<id>enforce-versions</id>\n\t\t\t\t\t\t\t\t<goals>\n\t\t\t\t\t\t\t\t\t<goal>enforce</goal>\n\t\t\t\t\t\t\t\t</goals>\n\t\t\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t\t\t<rules>\n\t\t\t\t\t\t\t\t\t\t<bannedDependencies>\n\t\t\t\t\t\t\t\t\t\t\t<excludes combine.children=\"append\">\n\t\t\t\t\t\t\t\t\t\t\t\t<exclude>*:*_2.11</exclude>\n\t\t\t\t\t\t\t\t\t\t\t\t<exclude>*:*_2.10</exclude>\n\t\t\t\t\t\t\t\t\t\t\t</excludes>\n\t\t\t\t\t\t\t\t\t\t\t<message>Scala 2.10/2.11 dependencies are not allowed for Scala 2.12 builds. This can be caused by hard-coded scala versions, where the 'scala.binary.version' property should be used instead.</message>\n\t\t\t\t\t\t\t\t\t\t</bannedDependencies>\n\t\t\t\t\t\t\t\t\t</rules>\n\t\t\t\t\t\t\t\t</configuration>\n\t\t\t\t\t\t\t</execution>\n\t\t\t\t\t\t</executions>\n\t\t\t\t\t</plugin>\n\t\t\t\t</plugins>\n\t\t\t</build>\n\t\t</profile>\n\n\t\t<profile>\n\t\t\t<id>enable-adaptive-scheduler</id>\n\t\t\t<properties>\n\t\t\t\t<surefire.excludedGroups.adaptive-scheduler>org.apache.flink.testutils.junit.FailsWithAdaptiveScheduler</surefire.excludedGroups.adaptive-scheduler>\n\t\t\t</properties>\n\t\t\t<build>\n\t\t\t\t<plugins>\n\t\t\t\t\t<plugin>\n\t\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t\t<artifactId>maven-surefire-plugin</artifactId>\n\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t<systemProperties>\n\t\t\t\t\t\t\t\t<flink.tests.enable-adaptive-scheduler>true</flink.tests.enable-adaptive-scheduler>\n\t\t\t\t\t\t\t</systemProperties>\n\t\t\t\t\t\t\t<excludedGroups>\n\t\t\t\t\t\t\t\t${surefire.excludedGroups.github-actions},\n\t\t\t\t\t\t\t\t${surefire.excludedGroups.adaptive-scheduler},\n\t\t\t\t\t\t\t\t${surefire.excludedGroups.jdk}\n\t\t\t\t\t\t\t</excludedGroups>\n\t\t\t\t\t\t</configuration>\n\t\t\t\t\t</plugin>\n\t\t\t\t</plugins>\n\t\t\t</build>\n\t\t</profile>\n\n\t\t<profile>\n\t\t\t<id>github-actions</id>\n\t\t\t<properties>\n\t\t\t\t<surefire.excludedGroups.github-actions>org.apache.flink.testutils.junit.FailsInGHAContainerWithRootUser</surefire.excludedGroups.github-actions>\n\t\t\t</properties>\n\t\t\t<build>\n\t\t\t\t<pluginManagement>\n\t\t\t\t\t<plugins>\n\t\t\t\t\t\t<plugin>\n\t\t\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t\t\t<artifactId>maven-surefire-plugin</artifactId>\n\t\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t\t<excludedGroups>\n\t\t\t\t\t\t\t\t\t${surefire.excludedGroups.github-actions},\n\t\t\t\t\t\t\t\t\t${surefire.excludedGroups.adaptive-scheduler},\n\t\t\t\t\t\t\t\t\t${surefire.excludedGroups.jdk},\n\t\t\t\t\t\t\t\t</excludedGroups>\n\t\t\t\t\t\t\t</configuration>\n\t\t\t\t\t\t</plugin>\n\t\t\t\t\t</plugins>\n\t\t\t\t</pluginManagement>\n\t\t\t</build>\n\t\t</profile>\n\n\t\t<profile>\n\t\t\t<id>java11</id>\n\t\t\t<activation>\n\t\t\t\t<jdk>[11,)</jdk>\n\t\t\t</activation>\n\n\t\t\t<properties>\n\t\t\t\t<surefire.excludedGroups.jdk>org.apache.flink.testutils.junit.FailsOnJava11</surefire.excludedGroups.jdk>\n\t\t\t</properties>\n\n\t\t\t<build>\n\t\t\t\t<pluginManagement>\n\t\t\t\t\t<plugins>\n\t\t\t\t\t\t<plugin>\n\t\t\t\t\t\t\t<groupId>org.codehaus.mojo</groupId>\n\t\t\t\t\t\t\t<artifactId>build-helper-maven-plugin</artifactId>\n\t\t\t\t\t\t\t<version>1.7</version>\n\t\t\t\t\t\t</plugin>\n\t\t\t\t\t\t<plugin>\n\t\t\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t\t\t<artifactId>maven-surefire-plugin</artifactId>\n\t\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t\t<excludedGroups>\n\t\t\t\t\t\t\t\t\t${surefire.excludedGroups.github-actions},\n\t\t\t\t\t\t\t\t\t${surefire.excludedGroups.adaptive-scheduler},\n\t\t\t\t\t\t\t\t\t${surefire.excludedGroups.jdk},\n\t\t\t\t\t\t\t\t</excludedGroups>\n\t\t\t\t\t\t\t</configuration>\n\t\t\t\t\t\t</plugin>\n\t\t\t\t\t</plugins>\n\t\t\t\t</pluginManagement>\n\t\t\t</build>\n\t\t</profile>\n\n\t\t<profile>\n\t\t\t<id>java17</id>\n\t\t\t<activation>\n\t\t\t\t<jdk>[17,)</jdk>\n\t\t\t</activation>\n\n\t\t\t<properties>\n\t\t\t\t<!-- Bump Scala because 2.12.7 doesn't compile on Java 17. -->\n\t\t\t\t<scala.version>2.12.15</scala.version>\n\t\t\t\t<surefire.excludedGroups.jdk>org.apache.flink.testutils.junit.FailsOnJava17</surefire.excludedGroups.jdk>\n\t\t\t</properties>\n\n\t\t\t<build>\n\t\t\t\t<pluginManagement>\n\t\t\t\t\t<plugins>\n\t\t\t\t\t\t<plugin>\n\t\t\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t\t\t<artifactId>maven-surefire-plugin</artifactId>\n\t\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t\t<excludedGroups>\n\t\t\t\t\t\t\t\t\t${surefire.excludedGroups.github-actions},\n\t\t\t\t\t\t\t\t\t${surefire.excludedGroups.adaptive-scheduler},\n\t\t\t\t\t\t\t\t\t${surefire.excludedGroups.jdk},\n\t\t\t\t\t\t\t\t</excludedGroups>\n\t\t\t\t\t\t\t</configuration>\n\t\t\t\t\t\t</plugin>\n\t\t\t\t\t</plugins>\n\t\t\t\t</pluginManagement>\n\t\t\t</build>\n\t\t</profile>\n\n\t\t<profile>\n\t\t\t<id>java17-target</id>\n\n\t\t\t<modules>\n\t\t\t\t<module>flink-tests-java17</module>\n\t\t\t</modules>\n\n\t\t\t<build>\n\t\t\t\t<plugins>\n\t\t\t\t\t<plugin>\n\t\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t\t<artifactId>maven-compiler-plugin</artifactId>\n\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t<source>17</source>\n\t\t\t\t\t\t\t<target>17</target>\n\t\t\t\t\t\t\t<compilerArgs combine.children=\"append\">\n\t\t\t\t\t\t\t\t<arg>--add-exports=java.base/sun.net.util=ALL-UNNAMED</arg>\n\t\t\t\t\t\t\t\t<arg>--add-exports=java.management/sun.management=ALL-UNNAMED</arg>\n\t\t\t\t\t\t\t\t<arg>--add-exports=java.rmi/sun.rmi.registry=ALL-UNNAMED</arg>\n\t\t\t\t\t\t\t\t<arg>--add-exports=java.security.jgss/sun.security.krb5=ALL-UNNAMED</arg>\n\t\t\t\t\t\t\t</compilerArgs>\n\t\t\t\t\t\t</configuration>\n\t\t\t\t\t</plugin>\n\t\t\t\t</plugins>\n\t\t\t</build>\n\t\t</profile>\n\n\t\t<profile>\n\t\t\t<id>java21</id>\n\t\t\t<activation>\n\t\t\t\t<jdk>[21,)</jdk>\n\t\t\t</activation>\n\n\t\t\t<properties>\n\t\t\t\t<!-- Bump Scala because before 2.12.18 doesn't compile on Java 21. -->\n\t\t\t\t<scala.version>2.12.18</scala.version>\n\t\t\t</properties>\n\n\t\t\t<build>\n\t\t\t\t<pluginManagement>\n\t\t\t\t\t<plugins>\n\t\t\t\t\t\t<plugin>\n\t\t\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t\t\t<artifactId>maven-surefire-plugin</artifactId>\n\t\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t\t<excludedGroups>\n\t\t\t\t\t\t\t\t\t${surefire.excludedGroups.github-actions},\n\t\t\t\t\t\t\t\t\t${surefire.excludedGroups.adaptive-scheduler},\n\t\t\t\t\t\t\t\t\t${surefire.excludedGroups.jdk},\n\t\t\t\t\t\t\t\t</excludedGroups>\n\t\t\t\t\t\t\t</configuration>\n\t\t\t\t\t\t</plugin>\n\t\t\t\t\t</plugins>\n\t\t\t\t</pluginManagement>\n\t\t\t</build>\n\t\t</profile>\n\n\t\t<profile>\n\t\t\t<id>java21-target</id>\n\t\t\t<build>\n\t\t\t\t<plugins>\n\t\t\t\t\t<plugin>\n\t\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t\t<artifactId>maven-compiler-plugin</artifactId>\n\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t<source>21</source>\n\t\t\t\t\t\t\t<target>21</target>\n\t\t\t\t\t\t\t<compilerArgs combine.children=\"append\">\n\t\t\t\t\t\t\t\t<arg>--add-exports=java.base/sun.net.util=ALL-UNNAMED</arg>\n\t\t\t\t\t\t\t\t<arg>--add-exports=java.management/sun.management=ALL-UNNAMED</arg>\n\t\t\t\t\t\t\t\t<arg>--add-exports=java.rmi/sun.rmi.registry=ALL-UNNAMED</arg>\n\t\t\t\t\t\t\t\t<arg>--add-exports=java.security.jgss/sun.security.krb5=ALL-UNNAMED</arg>\n\t\t\t\t\t\t\t</compilerArgs>\n\t\t\t\t\t\t</configuration>\n\t\t\t\t\t</plugin>\n\t\t\t\t</plugins>\n\t\t\t</build>\n\t\t</profile>\n\n\t\t<profile>\n\t\t\t<id>fast</id>\n\t\t\t<activation>\n\t\t\t\t<property>\n\t\t\t\t\t<name>fast</name>\n\t\t\t\t</property>\n\t\t\t</activation>\n\t\t\t<build>\n\t\t\t\t<pluginManagement>\n\t\t\t\t\t<plugins>\n\t\t\t\t\t\t<plugin>\n\t\t\t\t\t\t\t<groupId>org.apache.rat</groupId>\n\t\t\t\t\t\t\t<artifactId>apache-rat-plugin</artifactId>\n\t\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t\t<skip>true</skip>\n\t\t\t\t\t\t\t</configuration>\n\t\t\t\t\t\t</plugin>\n\t\t\t\t\t\t<plugin>\n\t\t\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t\t\t<artifactId>maven-checkstyle-plugin</artifactId>\n\t\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t\t<skip>true</skip>\n\t\t\t\t\t\t\t</configuration>\n\t\t\t\t\t\t</plugin>\n\t\t\t\t\t\t<plugin>\n\t\t\t\t\t\t\t<groupId>com.diffplug.spotless</groupId>\n\t\t\t\t\t\t\t<artifactId>spotless-maven-plugin</artifactId>\n\t\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t\t<skip>true</skip>\n\t\t\t\t\t\t\t</configuration>\n\t\t\t\t\t\t</plugin>\n\t\t\t\t\t\t<plugin>\n\t\t\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t\t\t<artifactId>maven-enforcer-plugin</artifactId>\n\t\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t\t<skip>true</skip>\n\t\t\t\t\t\t\t</configuration>\n\t\t\t\t\t\t</plugin>\n\t\t\t\t\t\t<plugin>\n\t\t\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t\t\t<artifactId>maven-javadoc-plugin</artifactId>\n\t\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t\t<skip>true</skip>\n\t\t\t\t\t\t\t</configuration>\n\t\t\t\t\t\t</plugin>\n\t\t\t\t\t\t<plugin>\n\t\t\t\t\t\t\t<groupId>com.github.siom79.japicmp</groupId>\n\t\t\t\t\t\t\t<artifactId>japicmp-maven-plugin</artifactId>\n\t\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t\t<skip>true</skip>\n\t\t\t\t\t\t\t</configuration>\n\t\t\t\t\t\t</plugin>\n\t\t\t\t\t\t<plugin>\n\t\t\t\t\t\t\t<groupId>org.cyclonedx</groupId>\n\t\t\t\t\t\t\t<artifactId>cyclonedx-maven-plugin</artifactId>\n\t\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t\t<skip>true</skip>\n\t\t\t\t\t\t\t</configuration>\n\t\t\t\t\t\t</plugin>\n\t\t\t\t\t</plugins>\n\t\t\t\t</pluginManagement>\n\t\t\t</build>\n\t\t</profile>\n\n\t\t<profile>\n\t\t\t<id>check-convergence</id>\n\t\t\t<activation>\n\t\t\t\t<property>\n\t\t\t\t\t<name>check-convergence</name>\n\t\t\t\t</property>\n\t\t\t</activation>\n\t\t\t<build>\n\t\t\t\t<plugins>\n\t\t\t\t\t<plugin>\n\t\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t\t<artifactId>maven-enforcer-plugin</artifactId>\n\t\t\t\t\t\t<executions>\n\t\t\t\t\t\t\t<execution>\n\t\t\t\t\t\t\t\t<id>dependency-convergence</id>\n\t\t\t\t\t\t\t\t<phase>${flink.convergence.phase}</phase>\n\t\t\t\t\t\t\t</execution>\n\t\t\t\t\t\t</executions>\n\t\t\t\t\t</plugin>\n\t\t\t\t</plugins>\n\t\t\t</build>\n\t\t</profile>\n\n\t\t<profile>\n\t\t\t<id>spotbugs</id>\n\t\t\t<activation>\n\t\t\t\t<property>\n\t\t\t\t\t<name>spotbugs</name>\n\t\t\t\t</property>\n\t\t\t</activation>\n\t\t\t<build>\n\t\t\t\t<plugins>\n\t\t\t\t\t<plugin>\n\t\t\t\t\t\t<groupId>com.github.hazendaz.spotbugs</groupId>\n\t\t\t\t\t\t<artifactId>spotbugs-maven-plugin</artifactId>\n\t\t\t\t\t\t<version>3.0.6</version>\n\n\t\t\t\t\t\t<executions>\n\t\t\t\t\t\t\t<execution>\n\t\t\t\t\t\t\t\t<id>findbugs-run</id>\n\t\t\t\t\t\t\t\t<phase>compile</phase>\n\t\t\t\t\t\t\t\t<goals>\n\t\t\t\t\t\t\t\t\t<goal>check</goal>\n\t\t\t\t\t\t\t\t</goals>\n\t\t\t\t\t\t\t</execution>\n\t\t\t\t\t\t</executions>\n\n\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t<xmlOutput>true</xmlOutput>\n\t\t\t\t\t\t\t<threshold>Low</threshold>\n\t\t\t\t\t\t\t<effort>default</effort>\n\t\t\t\t\t\t\t<findbugsXmlOutputDirectory>${project.build.directory}/spotbugs</findbugsXmlOutputDirectory>\n\t\t\t\t\t\t\t<excludeFilterFile>${rootDir}/tools/maven/spotbugs-exclude.xml</excludeFilterFile>\n\t\t\t\t\t\t\t<failOnError>true</failOnError>\n\t\t\t\t\t\t</configuration>\n\t\t\t\t\t</plugin>\n\n\t\t\t\t\t<plugin>\n\t\t\t\t\t\t<groupId>org.codehaus.mojo</groupId>\n\t\t\t\t\t\t<artifactId>xml-maven-plugin</artifactId>\n\t\t\t\t\t\t<version>1.0.1</version>\n\t\t\t\t\t\t<executions>\n\t\t\t\t\t\t\t<execution>\n\t\t\t\t\t\t\t\t<phase>verify</phase>\n\t\t\t\t\t\t\t\t<goals>\n\t\t\t\t\t\t\t\t\t<goal>transform</goal>\n\t\t\t\t\t\t\t\t</goals>\n\t\t\t\t\t\t\t</execution>\n\t\t\t\t\t\t</executions>\n\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t<transformationSets>\n\t\t\t\t\t\t\t\t<transformationSet>\n\t\t\t\t\t\t\t\t\t<dir>${project.build.directory}/spotbugs</dir>\n\t\t\t\t\t\t\t\t\t<outputDir>${project.build.directory}/spotbugs</outputDir>\n\t\t\t\t\t\t\t\t\t<!-- A list of available stylesheets can be found here: https://github.com/findbugsproject/findbugs/tree/master/findbugs/src/xsl -->\n\t\t\t\t\t\t\t\t\t<stylesheet>plain.xsl</stylesheet>\n\n\t\t\t\t\t\t\t\t\t<fileMappers>\n\t\t\t\t\t\t\t\t\t\t<fileMapper\n\t\t\t\t\t\t\t\t\t\t\timplementation=\"org.codehaus.plexus.components.io.filemappers.FileExtensionMapper\">\n\t\t\t\t\t\t\t\t\t\t\t<targetExtension>.html</targetExtension>\n\t\t\t\t\t\t\t\t\t\t</fileMapper>\n\t\t\t\t\t\t\t\t\t</fileMappers>\n\t\t\t\t\t\t\t\t</transformationSet>\n\t\t\t\t\t\t\t</transformationSets>\n\t\t\t\t\t\t</configuration>\n\t\t\t\t\t\t<dependencies>\n\t\t\t\t\t\t\t<dependency>\n\t\t\t\t\t\t\t\t<groupId>com.github.hazendaz.spotbugs</groupId>\n\t\t\t\t\t\t\t\t<artifactId>spotbugs-maven-plugin</artifactId>\n\t\t\t\t\t\t\t\t<version>3.0.6</version>\n\t\t\t\t\t\t\t</dependency>\n\t\t\t\t\t\t</dependencies>\n\t\t\t\t\t</plugin>\n\t\t\t\t</plugins>\n\t\t\t</build>\n\t\t</profile>\n\n\t\t<profile>\n\t\t\t<!-- used for SNAPSHOT and regular releases -->\n\t\t\t<id>docs-and-source</id>\n\t\t\t<activation>\n\t\t\t\t<property>\n\t\t\t\t\t<name>docs-and-source</name>\n\t\t\t\t</property>\n\t\t\t</activation>\n\t\t\t<build>\n\t\t\t\t<plugins>\n\t\t\t\t\t<plugin>\n\t\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t\t<artifactId>maven-source-plugin</artifactId>\n\t\t\t\t\t\t<version>3.2.1</version>\n\t\t\t\t\t\t<executions>\n\t\t\t\t\t\t\t<execution>\n\t\t\t\t\t\t\t\t<id>attach-sources</id>\n\t\t\t\t\t\t\t\t<goals>\n\t\t\t\t\t\t\t\t\t<goal>jar-no-fork</goal>\n\t\t\t\t\t\t\t\t</goals>\n\t\t\t\t\t\t\t</execution>\n\t\t\t\t\t\t</executions>\n\t\t\t\t\t</plugin>\n\t\t\t\t\t<plugin>\n\t\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t\t<artifactId>maven-javadoc-plugin</artifactId>\n\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t<quiet>true</quiet>\n\t\t\t\t\t\t</configuration>\n\t\t\t\t\t\t<executions>\n\t\t\t\t\t\t\t<execution>\n\t\t\t\t\t\t\t\t<id>attach-javadocs</id>\n\t\t\t\t\t\t\t\t<goals>\n\t\t\t\t\t\t\t\t\t<goal>jar</goal>\n\t\t\t\t\t\t\t\t</goals>\n\t\t\t\t\t\t\t</execution>\n\t\t\t\t\t\t</executions>\n\t\t\t\t\t</plugin>\n\t\t\t\t</plugins>\n\t\t\t</build>\n\t\t</profile>\n\n\t\t<profile>\n\t\t\t<id>release</id>\n\t\t\t<activation>\n\t\t\t\t<property>\n\t\t\t\t\t<name>release</name>\n\t\t\t\t</property>\n\t\t\t</activation>\n\t\t\t<properties>\n\t\t\t\t<target.java.version>11</target.java.version>\n\t\t\t</properties>\n\t\t\t<build>\n\t\t\t\t<plugins>\n\t\t\t\t\t<plugin>\n\t\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t\t<artifactId>maven-gpg-plugin</artifactId>\n\t\t\t\t\t\t<version>1.4</version>\n\t\t\t\t\t\t<executions>\n\t\t\t\t\t\t\t<execution>\n\t\t\t\t\t\t\t\t<id>sign-artifacts</id>\n\t\t\t\t\t\t\t\t<phase>verify</phase>\n\t\t\t\t\t\t\t\t<goals>\n\t\t\t\t\t\t\t\t\t<goal>sign</goal>\n\t\t\t\t\t\t\t\t</goals>\n\t\t\t\t\t\t\t</execution>\n\t\t\t\t\t\t</executions>\n\t\t\t\t\t</plugin>\n\t\t\t\t\t<plugin>\n\t\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t\t<artifactId>maven-enforcer-plugin</artifactId>\n\t\t\t\t\t\t<executions>\n\t\t\t\t\t\t\t<execution>\n\t\t\t\t\t\t\t\t<id>enforce-maven</id>\n\t\t\t\t\t\t\t\t<goals>\n\t\t\t\t\t\t\t\t\t<goal>enforce</goal>\n\t\t\t\t\t\t\t\t</goals>\n\t\t\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t\t\t<rules>\n\t\t\t\t\t\t\t\t\t\t<!-- versions for certain build tools are enforced to match the CI setup -->\n\t\t\t\t\t\t\t\t\t\t<!-- the rules below should stay in sync with Flink Release wiki documentation and the CI scripts -->\n\t\t\t\t\t\t\t\t\t\t<requireJavaVersion>\n\t\t\t\t\t\t\t\t\t\t\t<version>[11.0.0,11.1.0)</version>\n\t\t\t\t\t\t\t\t\t\t</requireJavaVersion>\n\t\t\t\t\t\t\t\t\t</rules>\n\t\t\t\t\t\t\t\t</configuration>\n\t\t\t\t\t\t\t</execution>\n\t\t\t\t\t\t</executions>\n\t\t\t\t\t</plugin>\n\t\t\t\t\t<plugin>\n\t\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t\t<artifactId>maven-javadoc-plugin</artifactId>\n\t\t\t\t\t\t<executions>\n\t\t\t\t\t\t\t<execution>\n\t\t\t\t\t\t\t\t<id>attach-javadocs</id>\n\t\t\t\t\t\t\t\t<goals>\n\t\t\t\t\t\t\t\t\t<goal>jar</goal>\n\t\t\t\t\t\t\t\t</goals>\n\t\t\t\t\t\t\t</execution>\n\t\t\t\t\t\t</executions>\n\t\t\t\t\t</plugin>\n\t\t\t\t</plugins>\n\t\t\t\t<pluginManagement>\n\t\t\t\t\t<plugins>\n\t\t\t\t\t\t<plugin>\n\t\t\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t\t\t<artifactId>maven-release-plugin</artifactId>\n\t\t\t\t\t\t\t<version>2.1</version>\n\t\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t\t<mavenExecutorId>forked-path</mavenExecutorId>\n\t\t\t\t\t\t\t\t<useReleaseProfile>false</useReleaseProfile>\n\t\t\t\t\t\t\t\t<arguments>${arguments} -Psonatype-oss-release</arguments>\n\t\t\t\t\t\t\t</configuration>\n\t\t\t\t\t\t</plugin>\n\t\t\t\t\t</plugins>\n\t\t\t\t</pluginManagement>\n\t\t\t</build>\n\t\t</profile>\n\t</profiles>\n\n\t<build>\n\t\t<plugins>\n\t\t\t<!--\n\t\t\tWe need to include this here because some of our modules have transitive dependencies\n\t\t\ton jdbm1, which is of type \"bundle\". This only works if you include the\n\t\t\tmaven-bundle-plugin (see https://issues.apache.org/jira/browse/DIRSHARED-134). We need\n\t\t\tthe plugin in the root pom because Javadoc aggregation runs only in the root pom and\n\t\t\tnot the specific poms. Not having this here was the cause for FLINK-7702.\n\t\t\t-->\n\t\t\t<plugin>\n\t\t\t\t<groupId>org.apache.felix</groupId>\n\t\t\t\t<artifactId>maven-bundle-plugin</artifactId>\n\t\t\t\t<version>3.0.1</version>\n\t\t\t\t<inherited>true</inherited>\n\t\t\t\t<extensions>true</extensions>\n\t\t\t</plugin>\n\n\t\t\t<plugin>\n\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t<artifactId>maven-jar-plugin</artifactId>\n\t\t\t\t<version>2.4</version><!--$NO-MVN-MAN-VER$-->\n\t\t\t\t<configuration>\n\t\t\t\t\t<archive>\n\t\t\t\t\t\t<!-- Globally exclude maven metadata, because it may accidentally bundle files we don't intend to -->\n\t\t\t\t\t\t<addMavenDescriptor>false</addMavenDescriptor>\n\t\t\t\t\t\t<manifest>\n\t\t\t\t\t\t\t<addDefaultImplementationEntries>true</addDefaultImplementationEntries>\n\t\t\t\t\t\t\t<addDefaultSpecificationEntries>true</addDefaultSpecificationEntries>\n\t\t\t\t\t\t</manifest>\n\t\t\t\t\t</archive>\n\t\t\t\t</configuration>\n\t\t\t</plugin>\n\n\t\t\t<plugin>\n\t\t\t\t<!-- activate API compatibility checks -->\n\t\t\t\t<groupId>com.github.siom79.japicmp</groupId>\n\t\t\t\t<artifactId>japicmp-maven-plugin</artifactId>\n\t\t\t</plugin>\n\n\t\t\t<plugin>\n\t\t\t\t<groupId>org.apache.rat</groupId>\n\t\t\t\t<artifactId>apache-rat-plugin</artifactId>\n\t\t\t\t<version>0.13</version>\n\t\t\t\t<inherited>false</inherited>\n\t\t\t\t<executions>\n\t\t\t\t\t<execution>\n\t\t\t\t\t\t<phase>validate</phase>\n\t\t\t\t\t\t<goals>\n\t\t\t\t\t\t\t<goal>check</goal>\n\t\t\t\t\t\t</goals>\n\t\t\t\t\t</execution>\n\t\t\t\t</executions>\n\t\t\t\t<configuration>\n\t\t\t\t\t<consoleOutput>true</consoleOutput>\n\t\t\t\t\t<excludeSubProjects>false</excludeSubProjects>\n\t\t\t\t\t<numUnapprovedLicenses>0</numUnapprovedLicenses>\n\t\t\t\t\t<licenses>\n\t\t\t\t\t\t<!-- Enforce this license:\n\t\t\t\t\t\t\tLicensed to the Apache Software Foundation (ASF) under one\n\t\t\t\t\t\t\tor more contributor license agreements.  See the NOTICE file\n\t\t\t\t\t\t\tdistributed with this work for additional information\n\t\t\t\t\t\t\tregarding copyright ownership.  The ASF licenses this file\n\t\t\t\t\t\t\tto you under the Apache License, Version 2.0 (the\n\t\t\t\t\t\t\t\"License\"); you may not use this file except in compliance\n\t\t\t\t\t\t\twith the License.  You may obtain a copy of the License at\n\t\t\t\t\t\t\t  http://www.apache.org/licenses/LICENSE-2.0\n\t\t\t\t\t\t\tUnless required by applicable law or agreed to in writing,\n\t\t\t\t\t\t\tsoftware distributed under the License is distributed on an\n\t\t\t\t\t\t\t\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n\t\t\t\t\t\t\tKIND, either express or implied.  See the License for the\n\t\t\t\t\t\t\tspecific language governing permissions and limitations\n\t\t\t\t\t\t\tunder the License.\n\t\t\t\t\t\t-->\n\t\t\t\t\t\t<license implementation=\"org.apache.rat.analysis.license.SimplePatternBasedLicense\">\n\t\t\t\t\t\t\t<licenseFamilyCategory>AL2 </licenseFamilyCategory>\n\t\t\t\t\t\t\t<licenseFamilyName>Apache License 2.0</licenseFamilyName>\n\t\t\t\t\t\t\t<patterns>\n\t\t\t\t\t\t\t\t<pattern>Licensed to the Apache Software Foundation (ASF) under one</pattern>\n\t\t\t\t\t\t\t</patterns>\n\t\t\t\t\t\t</license>\n\t\t\t\t\t</licenses>\n\t\t\t\t\t<licenseFamilies>\n\t\t\t\t\t\t<licenseFamily implementation=\"org.apache.rat.license.SimpleLicenseFamily\">\n\t\t\t\t\t\t\t<familyName>Apache License 2.0</familyName>\n\t\t\t\t\t\t</licenseFamily>\n\t\t\t\t\t</licenseFamilies>\n\t\t\t\t\t<excludes>\n\t\t\t\t\t\t<!-- Additional files like .gitignore etc.-->\n\t\t\t\t\t\t<exclude>**/.*/**</exclude>\n\t\t\t\t\t\t<exclude>**/*.prefs</exclude>\n\t\t\t\t\t\t<exclude>**/*.log</exclude>\n\t\t\t\t\t\t<!-- External web libraries. -->\n\t\t\t\t\t\t<exclude>docs/**/jquery*</exclude>\n\t\t\t\t\t\t<exclude>docs/**/bootstrap*</exclude>\n\t\t\t\t\t\t<exclude>docs/themes/book/**</exclude>\n\t\t\t\t\t\t<exclude>docs/**/anchor*</exclude>\n\t\t\t\t\t\t<exclude>**/resources/**/font-awesome/**</exclude>\n\t\t\t\t\t\t<exclude>**/resources/**/jquery*</exclude>\n\t\t\t\t\t\t<exclude>**/resources/**/bootstrap*</exclude>\n\t\t\t\t\t\t<exclude>docs/resources/**</exclude>\n\t\t\t\t\t\t<exclude>docs/public/**</exclude>\n\t\t\t\t\t\t<exclude>docs/assets/github.css</exclude>\n\t\t\t\t\t\t<exclude>docs/static/flink-header-logo.svg</exclude>\n\t\t\t\t\t\t<exclude>docs/static/figs/*.svg</exclude>\n\t\t\t\t\t\t<exclude>docs/static/font-awesome/**</exclude>\n\t\t\t\t\t\t<exclude>docs/static/flink-header-logo.svg</exclude>\n\t\t\t\t\t\t<exclude>docs/static/figs/*.svg</exclude>\n\t\t\t\t\t\t<exclude>flink-clients/src/main/resources/web-docs/js/*d3.js</exclude>\n\n\t\t\t\t\t\t<!-- the licenses that are re-bundled -->\n\t\t\t\t\t\t<exclude>**/packaged_licenses/LICENSE.*.txt</exclude>\n\t\t\t\t\t\t<exclude>**/licenses/LICENSE*</exclude>\n\t\t\t\t\t\t<exclude>**/licenses-binary/LICENSE*</exclude>\n\n\t\t\t\t\t\t<!-- web dashboard config JSON files -->\n\t\t\t\t\t\t<exclude>flink-runtime-web/web-dashboard/package.json</exclude>\n\t\t\t\t\t\t<exclude>flink-runtime-web/web-dashboard/package-lock.json</exclude>\n\t\t\t\t\t\t<exclude>flink-runtime-web/web-dashboard/angular.json</exclude>\n\t\t\t\t\t\t<exclude>flink-runtime-web/web-dashboard/proxy.conf.json</exclude>\n\t\t\t\t\t\t<exclude>flink-runtime-web/web-dashboard/tsconfig.json</exclude>\n\t\t\t\t\t\t<exclude>flink-runtime-web/web-dashboard/tslint.json</exclude>\n\t\t\t\t\t\t<exclude>flink-runtime-web/web-dashboard/src/browserslist</exclude>\n\t\t\t\t\t\t<exclude>flink-runtime-web/web-dashboard/src/tsconfig.app.json</exclude>\n\t\t\t\t\t\t<exclude>flink-runtime-web/web-dashboard/src/tsconfig.spec.json</exclude>\n\t\t\t\t\t\t<exclude>flink-runtime-web/web-dashboard/src/tslint.json</exclude>\n\n\t\t\t\t\t\t<!-- web dashboard non-binary assets -->\n\t\t\t\t\t\t<exclude>flink-runtime-web/web-dashboard/src/assets/**</exclude>\n\n\t\t\t\t\t\t<!-- generated contents -->\n\t\t\t\t\t\t<exclude>flink-runtime-web/web-dashboard/web/**</exclude>\n\n\t\t\t\t\t\t<!-- downloaded and generated web libraries. -->\n\t\t\t\t\t\t<exclude>flink-runtime-web/web-dashboard/node_modules/**</exclude>\n\t\t\t\t\t\t<exclude>flink-runtime-web/web-dashboard/node/**</exclude>\n\n\t\t\t\t\t\t<!-- antlr grammar files -->\n\t\t\t\t\t\t<exclude>flink-table/flink-table-code-splitter/src/main/antlr4/**</exclude>\n\n\t\t\t\t\t\t<!-- Test Data. -->\n\t\t\t\t\t\t<exclude>**/src/test/resources/*-data</exclude>\n\t\t\t\t\t\t<exclude>flink-tests/src/test/resources/testdata/terainput.txt</exclude>\n                        <exclude>flink-formats/flink-avro/src/test/resources/flink_11-kryo_registrations</exclude>\n\t\t\t\t\t\t<exclude>flink-core/src/test/resources/kryo-serializer-config-snapshot-v1</exclude>\n\t\t\t\t\t\t<exclude>flink-core/src/test/resources/abstractID-with-toString-field</exclude>\n\t\t\t\t\t\t<exclude>flink-core/src/test/resources/abstractID-with-toString-field-set</exclude>\n\t\t\t\t\t\t<exclude>flink-formats/flink-avro/src/test/resources/avro/*.avsc</exclude>\n\t\t\t\t\t\t<exclude>out/test/flink-avro/avro/user.avsc</exclude>\n\t\t\t\t\t\t<exclude>flink-table/flink-sql-client/src/test/resources/**/*.out</exclude>\n\t\t\t\t\t\t<exclude>flink-table/flink-table-api-scala/src/test/resources/flink_11-kryo_registrations</exclude>\n\t\t\t\t\t\t<exclude>flink-table/flink-table-planner/src/test/resources/**/*.out</exclude>\n\t\t\t\t\t\t<exclude>flink-table/flink-table-planner/src/test/resources/json/*.json</exclude>\n\t\t\t\t\t\t<exclude>flink-table/flink-table-planner/src/test/resources/jsonplan/*.json</exclude>\n\t\t\t\t\t\t<exclude>flink-table/flink-table-planner/src/test/resources/lineage-graph/*.json</exclude>\n\t\t\t\t\t\t<exclude>flink-table/flink-table-planner/src/test/resources/restore-tests/**</exclude>\n\t\t\t\t\t\t<exclude>flink-yarn/src/test/resources/krb5.keytab</exclude>\n\t\t\t\t\t\t<exclude>flink-end-to-end-tests/test-scripts/test-data/**</exclude>\n\t\t\t\t\t\t<exclude>flink-end-to-end-tests/test-scripts/docker-hadoop-secure-cluster/hadoop/config/keystore.jks</exclude>\n\t\t\t\t\t\t<exclude>flink-connectors/flink-connector-hive/src/test/resources/**</exclude>\n\t\t\t\t\t\t<exclude>flink-connectors/flink-file-sink-common/src/test/resources/recoverable-serializer-migration/**</exclude>\n\t\t\t\t\t\t<exclude>flink-end-to-end-tests/flink-tpcds-test/tpcds-tool/answer_set/*</exclude>\n\t\t\t\t\t\t<exclude>flink-end-to-end-tests/flink-tpcds-test/tpcds-tool/query/*</exclude>\n\t\t\t\t\t\t<exclude>flink-table/flink-table-code-splitter/src/test/resources/**</exclude>\n\t\t\t\t\t\t<exclude>flink-tests/src/test/resources/avro/*.avsc</exclude>\n\t\t\t\t\t\t<exclude>flink-connectors/flink-connector-datagen-test/src/test/resources/avro/*.avsc</exclude>\n\t\t\t\t\t\t<exclude>flink-runtime-web/web-dashboard/dev/notice-template</exclude>\n\t\t\t\t\t\t<!-- ArchUnit violation stores  -->\n\t\t\t\t\t\t<exclude>**/archunit-violations/**</exclude>\n\n\t\t\t\t\t\t<!-- snapshots -->\n\t\t\t\t\t\t<exclude>**/src/test/resources/serializer-snapshot-*</exclude>\n\t\t\t\t\t\t<exclude>**/src/test/resources/**/serializer-snapshot</exclude>\n\t\t\t\t\t\t<exclude>**/src/test/resources/**/test-data</exclude>\n\t\t\t\t\t\t<exclude>**/src/test/resources/*-snapshot</exclude>\n\t\t\t\t\t\t<exclude>**/src/test/resources/*.snapshot</exclude>\n\t\t\t\t\t\t<exclude>**/src/test/resources/*-savepoint/**</exclude>\n\t\t\t\t\t\t<exclude>**/src/test/resources/*-savepoint-native/**</exclude>\n\t\t\t\t\t\t<exclude>**/src/test/resources/*-checkpoint/**</exclude>\n\t\t\t\t\t\t<exclude>flink-core/src/test/resources/serialized-kryo-serializer-1.3</exclude>\n\t\t\t\t\t\t<exclude>flink-core/src/test/resources/type-without-avro-serialized-using-kryo</exclude>\n\t\t\t\t\t\t<exclude>flink-formats/flink-avro/src/test/resources/flink-1.4-serializer-java-serialized</exclude>\n\n\t\t\t\t\t\t<exclude>flink-end-to-end-tests/flink-state-evolution-test/src/main/java/org/apache/flink/avro/generated/*</exclude>\n\t\t\t\t\t\t<exclude>flink-end-to-end-tests/flink-state-evolution-test/savepoints/*</exclude>\n\t\t\t\t\t\t<exclude>flink-formats/flink-avro/src/test/resources/testdata.avro</exclude>\n\t\t\t\t\t\t<exclude>flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/generated/*.java</exclude>\n\t\t\t\t\t\t<exclude>flink-formats/flink-avro-confluent-registry/src/test/resources/*.json</exclude>\n\t\t\t\t\t\t<exclude>flink-formats/flink-avro-confluent-registry/src/test/resources/*.avro</exclude>\n\t\t\t\t\t\t<exclude>flink-formats/flink-json/src/test/resources/*.txt</exclude>\n\t\t\t\t\t\t<exclude>flink-formats/flink-parquet/src/test/java/org/apache/flink/formats/parquet/generated/*.java</exclude>\n\t\t\t\t\t\t<exclude>flink-formats/flink-parquet/src/test/resources/avro/**</exclude>\n\t\t\t\t\t\t<exclude>flink-formats/flink-parquet/src/test/resources/protobuf/**</exclude>\n\t\t\t\t\t\t<exclude>flink-table/flink-sql-gateway/src/test/resources/*.txt</exclude>\n\t\t\t\t\t\t<!-- netty test file, still Apache License 2.0 but with a different header -->\n\t\t\t\t\t\t<exclude>flink-runtime/src/test/java/org/apache/flink/runtime/io/network/buffer/AbstractByteBufTest.java</exclude>\n\t\t\t\t\t\t<!-- Configuration Files. -->\n\t\t\t\t\t\t<exclude>**/flink-bin/conf/workers</exclude>\n\t\t\t\t\t\t<exclude>**/flink-bin/conf/masters</exclude>\n\t\t\t\t\t\t<!-- Administrative files in the main trunk. -->\n\t\t\t\t\t\t<exclude>**/README.md</exclude>\n\t\t\t\t\t\t<exclude>.github/**</exclude>\n\t\t\t\t\t\t<!-- Build files -->\n\t\t\t\t\t\t<exclude>**/*.iml</exclude>\n\t\t\t\t\t\t<exclude>flink-quickstart/**/testArtifact/goal.txt</exclude>\n\t\t\t\t\t\t<!-- Generated content -->\n\t\t\t\t\t\t<exclude>out/**</exclude>\n\t\t\t\t\t\t<exclude>**/target/**</exclude>\n\t\t\t\t\t\t<exclude>build-target/**</exclude>\n\t\t\t\t\t\t<exclude>docs/layouts/shortcodes/generated/**</exclude>\n\t\t\t\t\t\t<exclude>docs/themes/connectors/layouts/shortcodes/generated/**</exclude>\n\t\t\t\t\t\t<exclude>docs/static/generated/**</exclude>\n\t\t\t\t\t\t<!-- Tools: watchdog -->\n\t\t\t\t\t\t<exclude>tools/artifacts/**</exclude>\n\t\t\t\t\t\t<exclude>tools/flink*/**</exclude>\n\t\t\t\t\t\t<!-- Tools: japicmp output -->\n\t\t\t\t\t\t<exclude>tools/japicmp-output/**</exclude>\n\t\t\t\t\t\t<!-- artifacts created during release process -->\n\t\t\t\t\t\t<exclude>tools/releasing/release/**</exclude>\n\t\t\t\t\t\t<!-- PyCharm -->\n\t\t\t\t\t\t<exclude>**/.idea/**</exclude>\n\t\t\t\t\t\t<!-- Generated code via Avro -->\n\t\t\t\t\t\t<exclude>flink-end-to-end-tests/flink-confluent-schema-registry/src/main/java/example/avro/**</exclude>\n\t\t\t\t\t\t<exclude>flink-end-to-end-tests/flink-datastream-allround-test/src/main/java/org/apache/flink/streaming/tests/avro/**</exclude>\n\n\t\t\t\t\t\t<!-- flink-python -->\n\t\t\t\t\t\t<exclude>flink-python/lib/**</exclude>\n\t\t\t\t\t\t<exclude>flink-python/dev/download/**</exclude>\n\t\t\t\t\t\t<exclude>flink-python/docs/_build/**</exclude>\n\t\t\t\t\t\t<exclude>flink-python/docs/_static/switcher.json</exclude>\n\n\t\t\t\t\t\t<!-- AWS SDK config that does not support license headers -->\n\t\t\t\t\t\t<exclude>**/awssdk/global/handlers/execution.interceptors</exclude>\n\n\t\t\t\t\t\t<!-- The most recently published version configuration file -->\n\t\t\t\t\t\t<exclude>flink-test-utils-parent/flink-migration-test-utils/src/main/resources/most_recently_published_version</exclude>\n\t\t\t\t\t</excludes>\n\t\t\t\t</configuration>\n\t\t\t</plugin>\n\t\t\t<plugin>\n\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t<artifactId>maven-checkstyle-plugin</artifactId>\n\t\t\t</plugin>\n\t\t\t<plugin>\n\t\t\t\t<groupId>com.diffplug.spotless</groupId>\n\t\t\t\t<artifactId>spotless-maven-plugin</artifactId>\n\t\t\t</plugin>\n\t\t\t<plugin>\n\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t<artifactId>maven-compiler-plugin</artifactId>\n\t\t\t</plugin>\n\n\t\t\t<!--surefire for unit tests and integration tests-->\n\t\t\t<plugin>\n\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t<artifactId>maven-surefire-plugin</artifactId>\n\t\t\t\t<version>3.2.2</version>\n\t\t\t\t<configuration>\n\t\t\t\t\t<!-- enables TCP/IP communication between surefire and forked JVM-->\n\t\t\t\t\t<forkNode implementation=\"org.apache.maven.plugin.surefire.extensions.SurefireForkNodeFactory\"/>\n\t\t\t\t\t<reuseForks>${flink.reuseForks}</reuseForks>\n\t\t\t\t\t<trimStackTrace>false</trimStackTrace>\n\t\t\t\t\t<systemPropertyVariables combine.children=\"append\">\n\t\t\t\t\t\t<forkNumber>0${surefire.forkNumber}</forkNumber>\n\t\t\t\t\t\t<!-- $$ ensures that surefire resolves this to the current forkNumber,\n\t\t\t\t\t\t \tinstead of maven during initialization -->\n\t\t\t\t\t\t<mvn.forkNumber>$${surefire.forkNumber}</mvn.forkNumber>\n\t\t\t\t\t\t<hadoop.version>${flink.hadoop.version}</hadoop.version>\n\t\t\t\t\t\t<checkpointing.randomization>true</checkpointing.randomization>\n\t\t\t\t\t\t<buffer-debloat.randomization>true</buffer-debloat.randomization>\n\t\t\t\t\t\t<user.country>US</user.country>\n\t\t\t\t\t\t<user.language>en</user.language>\n\t\t\t\t\t\t<!-- force the use of the Changelog State Backend in tests on mini-cluster\n\t\t\t\t\t\t\ton: enable CheckpointingOptions.ENABLE_STATE_CHANGE_LOG on cluster level\n\t\t\t\t\t\t\trandom: enable it randomly, unless explicitly set\n\t\t\t\t\t\t\tunset: don't alter the configuration\n\t\t\t\t\t\t-->\n\t\t\t\t\t\t<checkpointing.changelog>random</checkpointing.changelog>\n\t\t\t\t\t\t<!-- Expose as property so that test utils that spawn JVMs can pick it up. -->\n\t\t\t\t\t\t<surefire.module.config>${surefire.module.config}</surefire.module.config>\n\t\t\t\t\t\t<project.basedir>${project.basedir}</project.basedir>\n\t\t\t\t\t\t<!--suppress MavenModelInspection -->\n\t\t\t\t\t\t<test.randomization.seed>${test.randomization.seed}</test.randomization.seed>\n\t\t\t\t\t\t<junit.jupiter.extensions.autodetection.enabled>true</junit.jupiter.extensions.autodetection.enabled>\n\t\t\t\t\t\t<!-- Enabled the parallel test execution feature. -->\n\t\t\t\t\t\t<!-- Tests and test classes can be enabled for concurrent execution using @Execution(ExecutionMode.CONCURRENT). -->\n\t\t\t\t\t\t<junit.jupiter.execution.parallel.enabled>true</junit.jupiter.execution.parallel.enabled>\n\t\t\t\t\t\t<!-- Tests are by default executed by a single thread; parallel execution is opt-in. -->\n\t\t\t\t\t\t<junit.jupiter.execution.parallel.mode.default>same_thread</junit.jupiter.execution.parallel.mode.default>\n\t\t\t\t\t\t<!-- Tests suites are by default executed by a single thread; parallel execution is opt-in. -->\n\t\t\t\t\t\t<junit.jupiter.execution.parallel.mode.classes.default>same_thread</junit.jupiter.execution.parallel.mode.classes.default>\n\t\t\t\t\t\t<!-- automatically adjust parallelism based on available cpu/processor cores-->\n\t\t\t\t\t\t<junit.jupiter.execution.parallel.config.strategy>dynamic</junit.jupiter.execution.parallel.config.strategy>\n\t\t\t\t\t</systemPropertyVariables>\n\t\t\t\t\t<!-- This is picked up by IntelliJ -->\n\t\t\t\t\t<argLine>${flink.surefire.baseArgLine}</argLine>\n\t\t\t\t</configuration>\n\t\t\t\t<executions>\n\t\t\t\t\t<!--execute all the unit tests-->\n\t\t\t\t\t<execution>\n\t\t\t\t\t\t<id>default-test</id>\n\t\t\t\t\t\t<phase>test</phase>\n\t\t\t\t\t\t<goals>\n\t\t\t\t\t\t\t<goal>test</goal>\n\t\t\t\t\t\t</goals>\n\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t<includes>\n\t\t\t\t\t\t\t\t<include>${test.unit.pattern}</include>\n\t\t\t\t\t\t\t</includes>\n\t\t\t\t\t\t\t<forkCount>${flink.forkCountUnitTest}</forkCount>\n\t\t\t\t\t\t\t<argLine>${flink.surefire.baseArgLine} -Xmx${flink.XmxUnitTest}</argLine>\n\t\t\t\t\t\t</configuration>\n\t\t\t\t\t</execution>\n\t\t\t\t\t<!--execute all the integration tests-->\n\t\t\t\t\t<execution>\n\t\t\t\t\t\t<id>integration-tests</id>\n\t\t\t\t\t\t<phase>integration-test</phase>\n\t\t\t\t\t\t<goals>\n\t\t\t\t\t\t\t<goal>test</goal>\n\t\t\t\t\t\t</goals>\n\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t<includes>\n\t\t\t\t\t\t\t\t<include>**/*.*</include>\n\t\t\t\t\t\t\t</includes>\n\t\t\t\t\t\t\t<excludes>\n\t\t\t\t\t\t\t\t<exclude>${test.unit.pattern}</exclude>\n\t\t\t\t\t\t\t\t<!-- Exclude classes generated by Scala that surefire rejects\n\t\t\t\t\t\t\t\t     e.g., 'org.apache.flink.api.scala.typeutils.Foo$Bar$Foobar'. -->\n\t\t\t\t\t\t\t\t<exclude>**/*$*</exclude>\n\t\t\t\t\t\t\t</excludes>\n\t\t\t\t\t\t\t<forkCount>${flink.forkCountITCase}</forkCount>\n\t\t\t\t\t\t\t<argLine>${flink.surefire.baseArgLine} -Xmx${flink.XmxITCase}</argLine>\n\t\t\t\t\t\t\t<reuseForks>false</reuseForks>\n\t\t\t\t\t\t</configuration>\n\t\t\t\t\t</execution>\n\t\t\t\t</executions>\n\t\t\t</plugin>\n\t\t\t<plugin>\n\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t<artifactId>maven-eclipse-plugin</artifactId>\n\t\t\t\t<version>2.8</version>\n\t\t\t\t<configuration>\n\t\t\t\t\t<classpathContainers>\n\t\t\t\t\t\t<classpathContainer>\n\t\t\t\t\t\t\torg.eclipse.jdt.launching.JRE_CONTAINER\n\t\t\t\t\t\t</classpathContainer>\n\t\t\t\t\t</classpathContainers>\n\t\t\t\t\t<downloadSources>true</downloadSources>\n\t\t\t\t\t<downloadJavadocs>true</downloadJavadocs>\n\t\t\t\t</configuration>\n\t\t\t</plugin>\n\n\t\t\t<plugin>\n\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t<artifactId>maven-enforcer-plugin</artifactId>\n\t\t\t\t<executions>\n\t\t\t\t\t<execution>\n\t\t\t\t\t\t<id>enforce-maven</id>\n\t\t\t\t\t\t<goals>\n\t\t\t\t\t\t\t<goal>enforce</goal>\n\t\t\t\t\t\t</goals>\n\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t<rules>\n\t\t\t\t\t\t\t\t<requireMavenVersion>\n\t\t\t\t\t\t\t\t\t<version>[3.8.6]</version>\n\t\t\t\t\t\t\t\t</requireMavenVersion>\n\t\t\t\t\t\t\t\t<requireJavaVersion>\n\t\t\t\t\t\t\t\t\t<version>${target.java.version}</version>\n\t\t\t\t\t\t\t\t</requireJavaVersion>\n\t\t\t\t\t\t\t</rules>\n\t\t\t\t\t\t</configuration>\n\t\t\t\t\t</execution>\n\t\t\t\t\t<execution>\n\t\t\t\t\t\t<id>ban-unsafe-snakeyaml</id>\n\t\t\t\t\t\t<goals>\n\t\t\t\t\t\t\t<goal>enforce</goal>\n\t\t\t\t\t\t</goals>\n\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t<rules>\n\t\t\t\t\t\t\t\t<bannedDependencies>\n\t\t\t\t\t\t\t\t\t<excludes>\n\t\t\t\t\t\t\t\t\t\t<exclude>org.yaml:snakeyaml:(,2.2]</exclude>\n\t\t\t\t\t\t\t\t\t</excludes>\n\t\t\t\t\t\t\t\t\t<includes>\n\t\t\t\t\t\t\t\t\t\t<!-- Snakeyaml is pulled in by many modules without using it in production,\n\t\t\t\t\t\t\t\t\t\t\tso there's no benefit in us investing time into bumping these. -->\n\t\t\t\t\t\t\t\t\t\t<include>org.yaml:snakeyaml:(,2.2]:*:test</include>\n\t\t\t\t\t\t\t\t\t</includes>\n\t\t\t\t\t\t\t\t\t<message>Older snakeyaml versions are not allowed due to security vulnerabilities.</message>\n\t\t\t\t\t\t\t\t</bannedDependencies>\n\t\t\t\t\t\t\t</rules>\n\t\t\t\t\t\t</configuration>\n\t\t\t\t\t</execution>\n\t\t\t\t\t<execution>\n\t\t\t\t\t\t<id>ban-unsafe-jackson</id>\n\t\t\t\t\t\t<goals>\n\t\t\t\t\t\t\t<goal>enforce</goal>\n\t\t\t\t\t\t</goals>\n\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t<rules>\n\t\t\t\t\t\t\t\t<bannedDependencies>\n\t\t\t\t\t\t\t\t\t<excludes>\n\t\t\t\t\t\t\t\t\t\t<exclude>com.fasterxml.jackson*:*:(,2.14.0]</exclude>\n\t\t\t\t\t\t\t\t\t</excludes>\n\t\t\t\t\t\t\t\t\t<message>Older jackson versions are not allowed due to security vulnerabilities.</message>\n\t\t\t\t\t\t\t\t</bannedDependencies>\n\t\t\t\t\t\t\t</rules>\n\t\t\t\t\t\t</configuration>\n\t\t\t\t\t</execution>\n\t\t\t\t\t<execution>\n\t\t\t\t\t\t<id>forbid-log4j-1</id>\n\t\t\t\t\t\t<goals>\n\t\t\t\t\t\t\t<goal>enforce</goal>\n\t\t\t\t\t\t</goals>\n\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t<rules>\n\t\t\t\t\t\t\t\t<bannedDependencies>\n\t\t\t\t\t\t\t\t\t<excludes>\n\t\t\t\t\t\t\t\t\t\t<exclude>log4j:log4j</exclude>\n\t\t\t\t\t\t\t\t\t\t<exclude>org.slf4j:slf4j-log4j12</exclude>\n\t\t\t\t\t\t\t\t\t\t<exclude>ch.qos.reload4j:reload4j</exclude>\n\t\t\t\t\t\t\t\t\t\t<exclude>org.slf4j:slf4j-reload4j</exclude>\n\t\t\t\t\t\t\t\t\t</excludes>\n\t\t\t\t\t\t\t\t\t<message>Log4j 1 and Reload4J dependencies are not allowed because they conflict with Log4j 2. If the dependency absolutely requires the Log4j 1 API, use 'org.apache.logging.log4j:log4j-1.2-api'.</message>\n\t\t\t\t\t\t\t\t</bannedDependencies>\n\t\t\t\t\t\t\t</rules>\n\t\t\t\t\t\t</configuration>\n\t\t\t\t\t</execution>\n\t\t\t\t\t<execution>\n\t\t\t\t\t\t<id>forbid-direct-akka-rpc-dependencies</id>\n\t\t\t\t\t\t<goals>\n\t\t\t\t\t\t\t<goal>enforce</goal>\n\t\t\t\t\t\t</goals>\n\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t<rules>\n\t\t\t\t\t\t\t\t<bannedDependencies>\n\t\t\t\t\t\t\t\t\t<excludes>\n\t\t\t\t\t\t\t\t\t\t<exclude>org.apache.flink:flink-rpc-akka</exclude>\n\t\t\t\t\t\t\t\t\t</excludes>\n\t\t\t\t\t\t\t\t\t<message>\n\t\t\t\t\t\t\t\t\t\tDirect dependencies on flink-rpc-akka are not allowed. Depend on flink-rpc-akka-loader instead, and use RpcSystem#load or the TestingRpcService.\n\t\t\t\t\t\t\t\t\t</message>\n\t\t\t\t\t\t\t\t</bannedDependencies>\n\t\t\t\t\t\t\t</rules>\n\t\t\t\t\t\t</configuration>\n\t\t\t\t\t</execution>\n\t\t\t\t\t<execution>\n\t\t\t\t\t\t<id>forbid-direct-table-planner-dependencies</id>\n\t\t\t\t\t\t<goals>\n\t\t\t\t\t\t\t<goal>enforce</goal>\n\t\t\t\t\t\t</goals>\n\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t<rules>\n\t\t\t\t\t\t\t\t<bannedDependencies>\n\t\t\t\t\t\t\t\t\t<excludes>\n\t\t\t\t\t\t\t\t\t\t<exclude>org.apache.flink:flink-table-planner_${scala.binary.version}</exclude>\n\t\t\t\t\t\t\t\t\t</excludes>\n\t\t\t\t\t\t\t\t\t<includes>\n\t\t\t\t\t\t\t\t\t\t<include>org.apache.flink:flink-table-planner_${scala.binary.version}:*:*:test</include>\n\t\t\t\t\t\t\t\t\t</includes>\n\t\t\t\t\t\t\t\t\t<message>\n\t\t\t\t\t\t\t\t\t\tDirect dependencies on flink-table-planner are not allowed.\n\t\t\t\t\t\t\t\t\t\tYou should depend on either Table API modules or flink-table-planner-loader.\n\t\t\t\t\t\t\t\t\t</message>\n\t\t\t\t\t\t\t\t</bannedDependencies>\n\t\t\t\t\t\t\t</rules>\n\t\t\t\t\t\t</configuration>\n\t\t\t\t\t</execution>\n\t\t\t\t\t<execution>\n\t\t\t\t\t\t<id>dependency-convergence</id>\n\t\t\t\t\t\t<!-- disabled by default as it interacts badly with shade-plugin -->\n\t\t\t\t\t\t<phase>none</phase>\n\t\t\t\t\t\t<goals>\n\t\t\t\t\t\t\t<goal>enforce</goal>\n\t\t\t\t\t\t</goals>\n\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t<rules>\n\t\t\t\t\t\t\t\t<dependencyConvergence/>\n\t\t\t\t\t\t\t</rules>\n\t\t\t\t\t\t</configuration>\n\t\t\t\t\t</execution>\n\t\t\t\t</executions>\n\t\t\t</plugin>\n\n\t\t\t<plugin>\n\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t<artifactId>maven-shade-plugin</artifactId>\n\t\t\t\t<configuration>\n\t\t\t\t\t<!-- This section contains the core configuration that is applied to every jar that we create.-->\n\t\t\t\t\t<filters combine.children=\"append\">\n\t\t\t\t\t\t<filter>\n\t\t\t\t\t\t\t<artifact>*</artifact>\n\t\t\t\t\t\t\t<excludes>\n\t\t\t\t\t\t\t\t<!-- Globally exclude log4j.properties from our JAR files. -->\n\t\t\t\t\t\t\t\t<exclude>log4j.properties</exclude>\n\t\t\t\t\t\t\t\t<exclude>log4j2.properties</exclude>\n\t\t\t\t\t\t\t\t<exclude>log4j-test.properties</exclude>\n\t\t\t\t\t\t\t\t<exclude>log4j2-test.properties</exclude>\n\t\t\t\t\t\t\t\t<!-- Do not copy the signatures in the META-INF folder.\n\t\t\t\t\t\t\t\tOtherwise, this might cause SecurityExceptions when using the JAR. -->\n\t\t\t\t\t\t\t\t<exclude>META-INF/*.SF</exclude>\n\t\t\t\t\t\t\t\t<exclude>META-INF/*.DSA</exclude>\n\t\t\t\t\t\t\t\t<exclude>META-INF/*.RSA</exclude>\n\t\t\t\t\t\t\t\t<!-- META-INF/maven can contain 2 things:\n\t\t\t\t\t\t\t\t\t- For archetypes, it contains an archetype-metadata.xml.\n\t\t\t\t\t\t\t\t\t- For other jars, it contains the pom for all dependencies under the respective <groupId>/<artifactId>/ directory.\n\n\t\t\t\t\t\t\t\t \tWe want to exclude the poms because they may be under an incompatible license,\n\t\t\t\t\t\t\t\t \thowever the archetype metadata is required and we need to keep that around.\n\n\t\t\t\t\t\t\t\t \tThis pattern excludes directories under META-INF/maven.\n\t\t\t\t\t\t\t\t \t('?*/**' does not work because '**' also matches zero directories;\n\t\t\t\t\t\t\t\t \teverything that matches '?*' also matches '?*/**')\n\n\t\t\t\t\t\t\t\t\tThe initial '**' allows the pattern to also work for multi-release jars that may contain such entries under\n\t\t\t\t\t\t\t\t\t'META-INF/versions/11/META-INF/maven/'.\n\t\t\t\t\t\t\t\t \t-->\n\t\t\t\t\t\t\t\t<exclude>**/META-INF/maven/?*/?*/**</exclude>\n\t\t\t\t\t\t\t</excludes>\n\t\t\t\t\t\t</filter>\n\t\t\t\t\t</filters>\n\t\t\t\t\t<transformers combine.children=\"append\">\n\t\t\t\t\t\t<!-- The service transformer is needed to merge META-INF/services files -->\n\t\t\t\t\t\t<transformer implementation=\"org.apache.maven.plugins.shade.resource.ServicesResourceTransformer\"/>\n\t\t\t\t\t\t<!-- The ApacheNoticeResourceTransformer collects and aggregates NOTICE files -->\n\t\t\t\t\t\t<transformer implementation=\"org.apache.maven.plugins.shade.resource.ApacheNoticeResourceTransformer\">\n\t\t\t\t\t\t\t<projectName>Apache Flink</projectName>\n\t\t\t\t\t\t\t<encoding>UTF-8</encoding>\n\t\t\t\t\t\t</transformer>\n\t\t\t\t\t</transformers>\n\t\t\t\t</configuration>\n\t\t\t\t<executions>\n\t\t\t\t\t<execution>\n\t\t\t\t\t\t<id>shade-flink</id>\n\t\t\t\t\t\t<phase>package</phase>\n\t\t\t\t\t\t<goals>\n\t\t\t\t\t\t\t<goal>shade</goal>\n\t\t\t\t\t\t</goals>\n\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t<shadeTestJar>false</shadeTestJar>\n\t\t\t\t\t\t\t<shadedArtifactAttached>false</shadedArtifactAttached>\n\t\t\t\t\t\t\t<createDependencyReducedPom>true</createDependencyReducedPom>\n\t\t\t\t\t\t\t<!-- Filters MUST be appended; merging filters does not work properly, see MSHADE-305 -->\n\t\t\t\t\t\t\t<filters combine.children=\"append\">\n\t\t\t\t\t\t\t\t<!-- drop entries into META-INF and NOTICE files for the dummy artifact -->\n\t\t\t\t\t\t\t\t<filter>\n\t\t\t\t\t\t\t\t\t<artifact>org.apache.flink:flink-shaded-force-shading</artifact>\n\t\t\t\t\t\t\t\t\t<excludes>\n\t\t\t\t\t\t\t\t\t\t<exclude>**</exclude>\n\t\t\t\t\t\t\t\t\t</excludes>\n\t\t\t\t\t\t\t\t</filter>\n\t\t\t\t\t\t\t\t<!-- io.netty:netty brings its own LICENSE.txt which we don't need -->\n\t\t\t\t\t\t\t\t<filter>\n\t\t\t\t\t\t\t\t\t<artifact>io.netty:netty</artifact>\n\t\t\t\t\t\t\t\t\t<excludes>\n\t\t\t\t\t\t\t\t\t\t<exclude>META-INF/LICENSE.txt</exclude>\n\t\t\t\t\t\t\t\t\t</excludes>\n\t\t\t\t\t\t\t\t</filter>\n\t\t\t\t\t\t\t</filters>\n\t\t\t\t\t\t\t<artifactSet>\n\t\t\t\t\t\t\t\t<includes>\n\t\t\t\t\t\t\t\t\t<!-- Unfortunately, the next line is necessary for now to force the execution\n\t\t\t\t\t\t\t\t\tof the Shade plugin upon all sub modules. This will generate effective poms,\n\t\t\t\t\t\t\t\t\ti.e. poms which do not contain properties which are derived from this root pom.\n\t\t\t\t\t\t\t\t\tIn particular, the Scala version properties are defined in the root pom and without\n\t\t\t\t\t\t\t\t\tshading, the root pom would have to be Scala suffixed and thereby all other modules.\n\t\t\t\t\t\t\t\t\t-->\n\t\t\t\t\t\t\t\t\t<include>org.apache.flink:flink-shaded-force-shading</include>\n\t\t\t\t\t\t\t\t</includes>\n\t\t\t\t\t\t\t</artifactSet>\n\t\t\t\t\t\t</configuration>\n\t\t\t\t\t</execution>\n\t\t\t\t</executions>\n\t\t\t</plugin>\n\n\t\t\t<!-- generate configuration docs -->\n\t\t\t<plugin>\n\t\t\t\t<groupId>org.commonjava.maven.plugins</groupId>\n\t\t\t\t<artifactId>directory-maven-plugin</artifactId>\n\t\t\t\t<version>0.1</version>\n\t\t\t\t<executions>\n\t\t\t\t\t<execution>\n\t\t\t\t\t\t<id>directories</id>\n\t\t\t\t\t\t<goals>\n\t\t\t\t\t\t\t<goal>directory-of</goal>\n\t\t\t\t\t\t</goals>\n\t\t\t\t\t\t<phase>initialize</phase>\n\t\t\t\t\t\t<configuration>\n\t\t\t\t\t\t\t<property>rootDir</property>\n\t\t\t\t\t\t\t<project>\n\t\t\t\t\t\t\t\t<groupId>org.apache.flink</groupId>\n\t\t\t\t\t\t\t\t<artifactId>flink-parent</artifactId>\n\t\t\t\t\t\t\t</project>\n\t\t\t\t\t\t</configuration>\n\t\t\t\t\t</execution>\n\t\t\t\t</executions>\n\t\t\t</plugin>\n\n\t\t\t<plugin>\n\t\t\t\t<groupId>org.cyclonedx</groupId>\n\t\t\t\t<artifactId>cyclonedx-maven-plugin</artifactId>\n\t\t\t\t<version>2.7.7</version>\n\t\t\t\t<executions>\n\t\t\t\t\t<execution>\n\t\t\t\t\t\t<phase>package</phase>\n\t\t\t\t\t\t<goals>\n\t\t\t\t\t\t\t<goal>makeBom</goal>\n\t\t\t\t\t\t</goals>\n\t\t\t\t\t</execution>\n\t\t\t\t</executions>\n\t\t\t</plugin>\n\t\t</plugins>\n\n\t\t<pluginManagement>\n\t\t\t<plugins>\n\t\t\t\t<plugin>\n\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t<artifactId>maven-compiler-plugin</artifactId>\n\t\t\t\t\t<version>3.8.0</version>\n\t\t\t\t\t<configuration>\n\t\t\t\t\t\t<source>${target.java.version}</source>\n\t\t\t\t\t\t<target>${target.java.version}</target>\n\t\t\t\t\t\t<!-- The semantics of this option are reversed, see MCOMPILER-209. -->\n\t\t\t\t\t\t<useIncrementalCompilation>false</useIncrementalCompilation>\n\t\t\t\t\t\t<compilerArgs>\n\t\t\t\t\t\t\t<!-- Prevents recompilation due to missing package-info.class, see MCOMPILER-205 -->\n\t\t\t\t\t\t\t<arg>-Xpkginfo:always</arg>\n\t\t\t\t\t\t\t<arg>--add-exports=java.base/sun.net.util=ALL-UNNAMED</arg>\n\t\t\t\t\t\t\t<arg>--add-exports=java.management/sun.management=ALL-UNNAMED</arg>\n\t\t\t\t\t\t\t<arg>--add-exports=java.rmi/sun.rmi.registry=ALL-UNNAMED</arg>\n\t\t\t\t\t\t\t<arg>--add-exports=java.security.jgss/sun.security.krb5=ALL-UNNAMED</arg>\n\t\t\t\t\t\t</compilerArgs>\n\t\t\t\t\t</configuration>\n\t\t\t\t</plugin>\n\n\t\t\t\t<plugin>\n\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t<artifactId>maven-clean-plugin</artifactId>\n\t\t\t\t\t<version>3.1.0</version>\n\t\t\t\t\t<configuration>\n\t\t\t\t\t\t<filesets>\n\t\t\t\t\t\t\t<fileset>\n\t\t\t\t\t\t\t\t<directory>${project.basedir}</directory>\n\t\t\t\t\t\t\t\t<includes>\n\t\t\t\t\t\t\t\t\t<include>dependency-reduced-pom.xml</include>\n\t\t\t\t\t\t\t\t</includes>\n\t\t\t\t\t\t\t</fileset>\n\t\t\t\t\t\t</filesets>\n\t\t\t\t\t</configuration>\n\t\t\t\t</plugin>\n\n\t\t\t\t<plugin>\n\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t<artifactId>maven-checkstyle-plugin</artifactId>\n\t\t\t\t\t<version>3.3.1</version>\n\t\t\t\t\t<dependencies>\n\t\t\t\t\t\t<dependency>\n\t\t\t\t\t\t\t<groupId>com.puppycrawl.tools</groupId>\n\t\t\t\t\t\t\t<artifactId>checkstyle</artifactId>\n\t\t\t\t\t\t\t<!-- Note: match version with docs/flinkDev/ide_setup.md -->\n\t\t\t\t\t\t\t<version>${checkstyle.version}</version>\n\t\t\t\t\t\t</dependency>\n\t\t\t\t\t</dependencies>\n\t\t\t\t\t<executions>\n\t\t\t\t\t\t<execution>\n\t\t\t\t\t\t\t<id>validate</id>\n\t\t\t\t\t\t\t<phase>validate</phase>\n\t\t\t\t\t\t\t<goals>\n\t\t\t\t\t\t\t\t<goal>check</goal>\n\t\t\t\t\t\t\t</goals>\n\t\t\t\t\t\t</execution>\n\t\t\t\t\t</executions>\n\t\t\t\t\t<configuration>\n\t\t\t\t\t\t<suppressionsLocation>/tools/maven/suppressions.xml</suppressionsLocation>\n\t\t\t\t\t\t<includeTestSourceDirectory>true</includeTestSourceDirectory>\n\t\t\t\t\t\t<configLocation>/tools/maven/checkstyle.xml</configLocation>\n\t\t\t\t\t\t<logViolationsToConsole>true</logViolationsToConsole>\n\t\t\t\t\t\t<failOnViolation>true</failOnViolation>\n\t\t\t\t\t</configuration>\n\t\t\t\t</plugin>\n\n\t\t\t\t<plugin>\n\t\t\t\t\t<groupId>com.diffplug.spotless</groupId>\n\t\t\t\t\t<artifactId>spotless-maven-plugin</artifactId>\n\t\t\t\t\t<version>${spotless.version}</version>\n\t\t\t\t\t<configuration>\n\t\t\t\t\t\t<java>\n\t\t\t\t\t\t\t<googleJavaFormat>\n\t\t\t\t\t\t\t\t<version>1.24.0</version>\n\t\t\t\t\t\t\t\t<style>AOSP</style>\n\t\t\t\t\t\t\t</googleJavaFormat>\n\n\t\t\t\t\t\t\t<!-- \\# refers to the static imports -->\n\t\t\t\t\t\t\t<importOrder>\n\t\t\t\t\t\t\t\t<order>org.apache.flink,org.apache.flink.shaded,,javax,java,scala,\\#</order>\n\t\t\t\t\t\t\t</importOrder>\n\n\t\t\t\t\t\t\t<removeUnusedImports />\n\t\t\t\t\t\t</java>\n\t\t\t\t\t</configuration>\n\t\t\t\t\t<executions>\n\t\t\t\t\t\t<execution>\n\t\t\t\t\t\t\t<id>spotless-check</id>\n\t\t\t\t\t\t\t<phase>validate</phase>\n\t\t\t\t\t\t\t<goals>\n\t\t\t\t\t\t\t\t<goal>check</goal>\n\t\t\t\t\t\t\t</goals>\n\t\t\t\t\t\t</execution>\n\t\t\t\t\t</executions>\n\t\t\t\t</plugin>\n\n\n\t\t\t\t<plugin>\n\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t<artifactId>maven-javadoc-plugin</artifactId>\n\t\t\t\t\t<version>3.8.0</version>\n\t\t\t\t\t<configuration>\n\t\t\t\t\t\t<quiet>true</quiet>\n\t\t\t\t\t\t<detectOfflineLinks>false</detectOfflineLinks>\n\t\t\t\t\t\t<release>11</release>\n\t\t\t\t\t\t<additionalJOptions>\n\t\t\t\t\t\t\t<additionalJOption>-Xdoclint:none</additionalJOption>\n\t\t\t\t\t\t\t<additionalJOption>--allow-script-in-comments</additionalJOption>\n\t\t\t\t\t\t\t<!-- Suppress the error that is accepted by JDK 8 but not by JDK 11. -->\n\t\t\t\t\t\t\t<additionalJOption>--ignore-source-errors</additionalJOption>\n\t\t\t\t\t\t</additionalJOptions>\n\t\t\t\t\t</configuration>\n\t\t\t\t</plugin>\n\n\t\t\t\t<plugin>\n\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t<artifactId>maven-enforcer-plugin</artifactId>\n\t\t\t\t\t<version>3.1.0</version>\n\t\t\t\t</plugin>\n\n\t\t\t\t<plugin>\n\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t<artifactId>maven-dependency-plugin</artifactId>\n\t\t\t\t\t<version>3.2.0</version>\n\t\t\t\t\t<configuration>\n\t\t\t\t\t\t<ignoredUsedUndeclaredDependencies combine.children=\"append\">\n\t\t\t\t\t\t\t<!-- allow using transitive Flink dependencies for brevity -->\n\t\t\t\t\t\t\t<dependency>org.apache.flink:*</dependency>\n\t\t\t\t\t\t\t<!-- False positive since we use hamcrest-all -->\n\t\t\t\t\t\t\t<dependency>org.hamcrest:hamcrest-core</dependency>\n\t\t\t\t\t\t</ignoredUsedUndeclaredDependencies>\n\t\t\t\t\t\t<ignoredUnusedDeclaredDependencies combine.children=\"append\">\n\t\t\t\t\t\t\t<!-- build dependency, required for shading; does not contain any classes -->\n\t\t\t\t\t\t\t<dependency>org.apache.flink:force-shading</dependency>\n\t\t\t\t\t\t\t<!-- compile dependencies; defined in root pom for brevity -->\n\t\t\t\t\t\t\t<dependency>com.google.code.findbugs:jsr305</dependency>\n\t\t\t\t\t\t\t<dependency>org.scala-lang:scala-compiler</dependency>\n\t\t\t\t\t\t\t<!-- logging dependencies; defined in root pom for brevity\n\t\t\t\t\t\t\t\t\tsome modules may not use any logging, but that's not a problem\n\t\t\t\t\t\t\t\t\timplementations are loaded via reflection and are always detected as unused -->\n\t\t\t\t\t\t\t<dependency>org.slf4j:slf4j-api</dependency>\n\t\t\t\t\t\t\t<!-- log4j1 -->\n\t\t\t\t\t\t\t<dependency>log4j:log4j</dependency>\n\t\t\t\t\t\t\t<dependency>org.slf4j:slf4j-log4j12</dependency>\n\t\t\t\t\t\t\t<!-- log4j2 -->\n\t\t\t\t\t\t\t<dependency>org.apache.logging.log4j:log4j-slf4j-impl</dependency>\n\t\t\t\t\t\t\t<dependency>org.apache.logging.log4j:log4j-api</dependency>\n\t\t\t\t\t\t\t<dependency>org.apache.logging.log4j:log4j-core</dependency>\n\t\t\t\t\t\t\t<dependency>org.apache.logging.log4j:log4j-1.2-api</dependency>\n\t\t\t\t\t\t\t<!-- test dependencies; defined in root pom for brevity -->\n\t\t\t\t\t\t\t<dependency>org.apache.flink:flink-test-utils-junit</dependency>\n\t\t\t\t\t\t\t<dependency>junit:junit</dependency>\n\t\t\t\t\t\t\t<dependency>org.mockito:mockito-core</dependency>\n\t\t\t\t\t\t\t<dependency>org.hamcrest:hamcrest-all</dependency>\n\t\t\t\t\t\t</ignoredUnusedDeclaredDependencies>\n\t\t\t\t\t</configuration>\n\t\t\t\t</plugin>\n\n\t\t\t\t<!-- Pin the version of the maven shade plugin -->\n\t\t\t\t<plugin>\n\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t<artifactId>maven-shade-plugin</artifactId>\n\t\t\t\t\t<version>3.5.3</version>\n\t\t\t\t</plugin>\n\t\t\t\t<!-- Pin the version of the maven remote resource plugin -->\n\t\t\t\t<plugin>\n\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t<artifactId>maven-remote-resources-plugin</artifactId>\n\t\t\t\t\t<version>3.2.0</version>\n\t\t\t\t</plugin>\n\n\t\t\t\t<plugin>\n\t\t\t\t\t<!-- Inherited from Apache parent, but not actually used. Disable to reduce noise. -->\n\t\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n\t\t\t\t\t<artifactId>maven-site-plugin</artifactId>\n\t\t\t\t\t<executions>\n\t\t\t\t\t\t<execution>\n\t\t\t\t\t\t\t<id>attach-descriptor</id>\n\t\t\t\t\t\t\t<phase>none</phase>\n\t\t\t\t\t\t</execution>\n\t\t\t\t\t</executions>\n\t\t\t\t</plugin>\n\n\t\t\t\t<!-- set scala maven plugin version -->\n\t\t\t\t<plugin>\n\t\t\t\t\t<groupId>net.alchim31.maven</groupId>\n\t\t\t\t\t<artifactId>scala-maven-plugin</artifactId>\n\t\t\t\t\t<version>3.2.2</version>\n\t\t\t\t\t<configuration>\n\t\t\t\t\t\t<args>\n\t\t\t\t\t\t\t<arg>-nobootcp</arg>\n\t\t\t\t\t\t</args>\n\t\t\t\t\t\t<jvmArgs>\n\t\t\t\t\t\t\t<arg>-Xss2m</arg>\n\t\t\t\t\t\t</jvmArgs>\n\t\t\t\t\t</configuration>\n\t\t\t\t</plugin>\n\n\t\t\t\t<!-- Configuration for the binary compatibility checker -->\n\t\t\t\t<plugin>\n\t\t\t\t\t<groupId>com.github.siom79.japicmp</groupId>\n\t\t\t\t\t<artifactId>japicmp-maven-plugin</artifactId>\n\t\t\t\t\t<version>0.17.1</version>\n\t\t\t\t\t<configuration>\n\t\t\t\t\t\t<oldVersion>\n\t\t\t\t\t\t\t<dependency>\n\t\t\t\t\t\t\t\t<groupId>org.apache.flink</groupId>\n\t\t\t\t\t\t\t\t<artifactId>${project.artifactId}</artifactId>\n\t\t\t\t\t\t\t\t<version>${japicmp.referenceVersion}</version>\n\t\t\t\t\t\t\t\t<type>${project.packaging}</type>\n\t\t\t\t\t\t\t</dependency>\n\t\t\t\t\t\t</oldVersion>\n\t\t\t\t\t\t<newVersion>\n\t\t\t\t\t\t\t<file>\n\t\t\t\t\t\t\t\t<path>${project.build.directory}/${project.artifactId}-${project.version}.${project.packaging}</path>\n\t\t\t\t\t\t\t</file>\n\t\t\t\t\t\t</newVersion>\n\t\t\t\t\t\t<parameter>\n\t\t\t\t\t\t\t<onlyModified>true</onlyModified>\n\t\t\t\t\t\t\t<includes>\n\t\t\t\t\t\t\t\t<include>@org.apache.flink.annotation.Public</include>\n\t\t\t\t\t\t\t\t<!-- The following line is un-commented by tools/releasing/update_japicmp_configuration.sh\n\t\t\t\t\t\t\t\t \tas part of the release process -->\n\t\t\t\t\t\t\t\t<!--<include>@org.apache.flink.annotation.PublicEvolving</include>-->\n\t\t\t\t\t\t\t</includes>\n\t\t\t\t\t\t\t<excludes>\n\t\t\t\t\t\t\t\t<exclude>@java.lang.Deprecated</exclude>\n\t\t\t\t\t\t\t\t<exclude>*.scala</exclude>\n\t\t\t\t\t\t\t\t<exclude>@org.apache.flink.annotation.Experimental</exclude>\n\t\t\t\t\t\t\t\t<exclude>@org.apache.flink.annotation.PublicEvolving</exclude>\n\t\t\t\t\t\t\t\t<exclude>@org.apache.flink.annotation.Internal</exclude>\n\t\t\t\t\t\t\t\t<!-- MARKER: start exclusions; these will be wiped by tools/releasing/update_japicmp_configuration.sh -->\n\t\t\t\t\t\t\t\t<!-- Mark these 2 methods to @Internal. Tracked under FLINK-34130, should be removed in 2.0 -->\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.configuration.Configuration#getBytes(java.lang.String,byte[])</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.configuration.Configuration#setBytes(java.lang.String,byte[])</exclude>\n\t\t\t\t\t\t\t\t<!-- FLIP-344: Remove parameter in RichFunction#open in 2.0 -->\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.common.functions.AbstractRichFunction#open(org.apache.flink.configuration.Configuration)</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.common.functions.RichCoGroupFunction</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.common.functions.RichCrossFunction</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.common.functions.RichFilterFunction</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.common.functions.RichFlatJoinFunction</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.common.functions.RichFlatMapFunction</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.common.functions.RichGroupCombineFunction</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.common.functions.RichGroupReduceFunction</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.common.functions.RichJoinFunction</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.common.functions.RichMapFunction</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.common.functions.RichMapPartitionFunction</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.common.functions.RichReduceFunction</exclude>\n\t\t\t\t\t\t\t\t<!-- FLINK-34085 Deprecated string config should be removed in 2.0 -->\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.configuration.ConfigConstants</exclude>\n\t\t\t\t\t\t\t\t<!-- FLINK-35886: WatermarksWithIdleness constructor was marked as deprecated -->\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.common.eventtime.WatermarksWithIdleness</exclude>\n\t\t\t\t\t\t\t\t<!-- FLINK-35812 move tuple interfaces into flink-core-api, should be removed in 2.0 -->\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.java.tuple.*</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.types.NullFieldException</exclude>\n\t\t\t\t\t\t\t\t<!-- FLINK-36225 Remove deprecated methods marked in FLIP-382 -->\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.common.functions.RuntimeContext#getAttemptNumber()</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.common.functions.RuntimeContext#getIndexOfThisSubtask()</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.common.functions.RuntimeContext#getJobId()</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.common.functions.RuntimeContext#getNumberOfParallelSubtasks()</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.common.functions.RuntimeContext#getTaskName()</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.common.functions.RuntimeContext#getTaskNameWithSubtasks()</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.connector.sink2.Sink$InitContextWrapper#getAttemptNumber()</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.connector.sink2.Sink$InitContextWrapper#getJobId()</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.connector.sink2.Sink$InitContextWrapper#getNumberOfParallelSubtasks()</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.connector.sink2.Sink$InitContextWrapper#getSubtaskId()</exclude>\n\t\t\t\t\t\t\t\t<!-- The following exclusions are due to classes being relocated from the flink-streaming-java\n\t\t\t\t\t\t\t\t\tmodule to the flink-runtime module. -->\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.functions.windowing.AllWindowFunction</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.datastream.CoGroupedStreams</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.datastream.ConnectedStreams</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.datastream.DataStream</exclude>\n\t\t\t\t\t\t\t\t<exclude>apache.flink.streaming.api.datastream.JoinedStreams</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.datastream.WindowedStream</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.environment.StreamExecutionEnvironment</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.datastream.AllWindowedStream</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.datastream.JoinedStreams</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.checkpoint.CheckpointedFunction</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.CheckpointingMode</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.datastream.DataStreamSink</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.datastream.DataStreamSource</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.datastream.KeyedStream</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.datastream.SideOutputDataStream</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.environment.CheckpointConfig</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.environment.LocalStreamEnvironment</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.environment.RemoteStreamEnvironment</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.functions.co.CoFlatMapFunction</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.functions.co.CoMapFunction</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.functions.sink.RichSinkFunction</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.functions.sink.SinkFunction</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.functions.source.SourceFunction</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.functions.windowing.WindowFunction</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.functions.source.RichSourceFunction</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.streaming.api.functions.source.ParallelSourceFunction</exclude>\n\t\t\t\t\t\t\t\t<!-- FLINK-33712 deprecated the RuntimeContext#getExecutionConfig; this will be removed in Flink 2.0. -->\n\t\t\t\t\t\t\t\t<exclude>\n\t\t\t\t\t\t\t\t\torg.apache.flink.api.common.functions.RuntimeContext#getExecutionConfig()\n\t\t\t\t\t\t\t\t</exclude>\n\t\t\t\t\t\t\t\t<!-- FLINK-3992 Do not implement deprecated Key interface in flink 2.0 -->\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.types.DoubleValue</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.types.FloatValue</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.types.NormalizableKey</exclude>\n\t\t\t\t\t\t\t\t<!-- FLINK-36366 Remove deprecate API in flink-core -->\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.common.io.SerializedOutputFormat</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.common.io.OutputFormat</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.common.io.FinalizeOnMaster</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.common.io.FileOutputFormat</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.common.io.BinaryOutputFormat</exclude>\n\t\t\t\t\t\t\t\t<!-- FLINK-5336 Remove IOReadableWritable from Path in flink-2.0. -->\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.core.fs.Path</exclude>\n\t\t\t\t\t\t\t\t<!-- The following exclusions are due to the flink-hadoop-compatibility_${scala.binary.version} module has renamed to flink-hadoop-compatibility. -->\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.java.hadoop.mapred.HadoopInputFormat</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.java.hadoop.mapred.HadoopOutputFormat</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.java.hadoop.mapreduce.HadoopInputFormat</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.java.hadoop.mapreduce.HadoopOutputFormat</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.java.typeutils.WritableTypeInfo</exclude>\n\t\t\t\t\t\t\t\t<!-- The following exclusions are due to classes being relocated from the flink-java\n\t\t\t\t\t\t\t\t\tmodule to the flink-core module. -->\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.java.utils.AbstractParameterTool</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.java.utils.ParameterTool</exclude>\n\t\t\t\t\t\t\t\t<!-- FLINK-36327 Remove dependency about flink-scala and flink-streaming-scala in table module in flink-2.0 -->\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.table.api.typeutils.*</exclude>\n\t\t\t\t\t\t\t\t<!-- FLINK-36245 Remove Sink.InitContext in flink-2.0. -->\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.connector.sink2.Sink</exclude>\n\t\t\t\t\t\t\t\t<!-- FLINK-36245 move SourceFunction to legacy package in flink-2.0. -->\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.walkthrough.common.source.TransactionSource</exclude>\n\t\t\t\t\t\t\t\t<!-- FLIP-467 Introduce Generalized Watermarks in flink-2.0. -->\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.connector.source.Source</exclude>\n\t\t\t\t\t\t\t\t<exclude>org.apache.flink.api.connector.source.SourceReaderContext</exclude>\n\t\t\t\t\t\t\t\t<!-- MARKER: end exclusions -->\n\t\t\t\t\t\t\t</excludes>\n\t\t\t\t\t\t\t<accessModifier>public</accessModifier>\n\t\t\t\t\t\t\t<breakBuildOnModifications>false</breakBuildOnModifications>\n\t\t\t\t\t\t\t<breakBuildOnBinaryIncompatibleModifications>true</breakBuildOnBinaryIncompatibleModifications>\n\t\t\t\t\t\t\t<breakBuildOnSourceIncompatibleModifications>true</breakBuildOnSourceIncompatibleModifications>\n\t\t\t\t\t\t\t<onlyBinaryIncompatible>false</onlyBinaryIncompatible>\n\t\t\t\t\t\t\t<includeSynthetic>true</includeSynthetic>\n\t\t\t\t\t\t\t<ignoreMissingClasses>false</ignoreMissingClasses>\n\t\t\t\t\t\t\t<skipPomModules>true</skipPomModules>\n\t\t\t\t\t\t\t<!-- Don't break build on newly added maven modules -->\n\t\t\t\t\t\t\t<ignoreNonResolvableArtifacts>true</ignoreNonResolvableArtifacts>\n\t\t\t\t\t\t\t<packagingSupporteds>\n\t\t\t\t\t\t\t\t<packagingSupported>jar</packagingSupported>\n\t\t\t\t\t\t\t</packagingSupporteds>\n\t\t\t\t\t\t</parameter>\n\t\t\t\t\t\t<projectBuildDir>${rootDir}/${japicmp.outputDir}/${project.artifactId}</projectBuildDir>\n\t\t\t\t\t\t<dependencies>\n\t\t\t\t\t\t\t<dependency>\n\t\t\t\t\t\t\t\t<groupId>org.apache.flink</groupId>\n\t\t\t\t\t\t\t\t<artifactId>flink-annotations</artifactId>\n\t\t\t\t\t\t\t\t<version>${project.version}</version>\n\t\t\t\t\t\t\t</dependency>\n\t\t\t\t\t\t</dependencies>\n\t\t\t\t\t</configuration>\n\t\t\t\t\t<executions>\n\t\t\t\t\t\t<execution>\n\t\t\t\t\t\t\t<phase>verify</phase>\n\t\t\t\t\t\t\t<goals>\n\t\t\t\t\t\t\t\t<goal>cmp</goal>\n\t\t\t\t\t\t\t</goals>\n\t\t\t\t\t\t</execution>\n\t\t\t\t\t</executions>\n\t\t\t\t</plugin>\n\n\t\t\t\t<plugin>\n\t\t\t\t\t<!-- run via \"mvn org.owasp:dependency-check-maven:aggregate\" -->\n\t\t\t\t\t<groupId>org.owasp</groupId>\n\t\t\t\t\t<artifactId>dependency-check-maven</artifactId>\n\t\t\t\t\t<version>5.0.0-M2</version>\n\t\t\t\t\t<configuration>\n\t\t\t\t\t\t<format>ALL</format>\n\t\t\t\t\t\t<skipSystemScope>true</skipSystemScope>\n\t\t\t\t\t\t<skipProvidedScope>true</skipProvidedScope>\n\t\t\t\t\t\t<excludes>\n\t\t\t\t\t\t\t<exclude>*flink-docs</exclude>\n\t\t\t\t\t\t\t<exclude>*flink-end-to-end-tests</exclude>\n\t\t\t\t\t\t\t<exclude>*flink-fs-tests*</exclude>\n\t\t\t\t\t\t\t<exclude>*flink-yarn-tests*</exclude>\n\t\t\t\t\t\t</excludes>\n\t\t\t\t\t</configuration>\n\t\t\t\t</plugin>\n\t\t\t</plugins>\n\t\t</pluginManagement>\n\t</build>\n\n</project>\n"
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}