{
  "metadata": {
    "timestamp": 1736708834907,
    "page": 26,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjMw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "brettwooldridge/HikariCP",
      "stars": 20167,
      "defaultBranch": "dev",
      "files": [
        {
          "name": ".circleci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 0.2724609375,
          "content": "# EditorConfig is awesome: http://EditorConfig.org\n\n# top-most EditorConfig file\nroot = true\n\n[**]\nend_of_line = lf\ninsert_final_newline = true\ncharset = utf-8\nindent_style = space\ntrim_trailing_whitespace = true\n\n[**.{java,xml}]\nindent_size = 3\n\n[**.{yaml,yml}]\nindent_size = 2\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.15625,
          "content": ".classpath\n.project\n.metadata\n\ntarget/\ndependency-reduced-pom.xml\n\n.DS_Store\n\n**/*.iml\n\n*.class\n*.jar\n*.war\n*.ear\n*.iml\n*.iws\n*.ipr\n\n.tm_*\n.idea/\n.gradle/\nout/\n"
        },
        {
          "name": ".settings",
          "type": "tree",
          "content": null
        },
        {
          "name": "CHANGES",
          "type": "blob",
          "size": 41.5947265625,
          "content": "HikariCP Changes\n\nChanges in 6.2.2\n\n * increase keepaliveTime variance from 10% to 20%\n\n * merged #2266 support duration values for configuration from properties, such as 10ms, 20s, 30m, 40h or 50d\n\nChanges in 6.2.1\n\n * change default keepaliveTime to 2 minutes\n\n * fix commons-compress dependency, make test scope\n\nChanges in 6.2.0\n\n * merged #2238 handle SQLTimeoutException without eviction. Users looking to preserve previous behavior\n   should provide an implementation of com.zaxxer.hikari.SQLExceptionOverride to the pool configuration.\n\n * added new enum value, Override.MUST_EVICT, available to implementations of com.zaxxer.hikari.SQLExceptionOverride\n\n * enhanced debug logging in circumstances where the pool falls to zero size and new connections to the database\n   continue to fail.\n\n * update test dependencies that were flagged as having vulnerabilities\n\nChanges in 6.1.0\n\n * fixed #1960 allow SQLExceptionOverride to adjudicate all exceptions for eviction\n\n * merged #1962 dropwizard 5 metrics are now supported via the setMetricRegistry() method in HikariConfig and in HikariDataSource\n\n * merged #2244 improve JavassistProxyFactory\n\n * merged #2243 fix inconsistency between isWrapperFor and unwrap\n\n * merged #1827 support loading properties file in unnamed resources module\n\n * merged #1842 don't clear isCommitStateDirty flag in setReadOnly\n\n * change default maxLifetime variance from 2.5% to 25% to further avoid mass connection die-off dips\n\nChanges in 6.0.0\n\n * fixed #2152 duplicate connection in try with resources clause caused close() being called twice on each connection\n\n * merged #2226 consistent handling of errorCode and sqlState in timeout exception\n\n * merged #2199 eliminate network call if state get is called after set\n\n * merged #2189 add support to get and set db credentials in an atomic operation\n\n * merged #2149 make Savepoint rollbacks mark the connection dirty\n\n * merged #2157 close connections marked as evicted instead of returning them to the pool\n\n * merged #2147 skip Connection::setNetworkTimeout if PoolBase::shutdownNetworkTimeoutExecutor is called\n\n * merged #2126 added Support For beginRequest and endRequest\n\n * small improvements and cleanup from pull request #2166\n\n * minor debug logging enhancements\n\nChanges in 5.1.0\n\n * fixed #1907 re-added automatic.module.name that was lost along the way\n\n * fixed #1986 evict connection exceptions with (SQLState HY000) error code 1105.\n\n * merged #2059 add support for char[] in DataSource properties\n\n * merged #1979 and #1993 mask any property that looks like a password in URLs\n\n * add pool stats to connection acquisition timeout exception\n\n * merged #2076 don't case metric registry before it is checked for null\n\n * merged #1820 allow minimum login timeout to be set as system property\n\n * merged #1952 add more isolation levels\n\n * merged #1660 remove redundant error log for poll initialization exception\n\nChanges in 5.0.1\n\n * Update log4j version to 2.17.1 to address Log4Shell vulnerability (although this is only used in tests, so it doesn't really impact users)\n\nChanges in 5.0.0\n\n * rewrote connection elide/add code to fix an unconfirmed but occasionally reported\n   race condition that results in the pool draining to 0 and not refilling.\n\nChanges in 4.0.3\n\n * fixed #1735 added system property to permit override of lower limit of connectionTimeout\n   and validation timeout\n\nChanges in 4.0.2\n\n * fixed regression caused by #1605 affecting block-until-filled semantic\n\nChanges in 4.0.1\n\n * fixed #1725 pom file change to be more gradle-friendly\n\n * fixed #1726 regression in micrometrics caused by lack of a strong reference to an\n   object\n\nChanges in 4.0.0\n\n * merged #1669 #1582 mark optional dependencies as 'require static' in module-info\n\n * merged #1700 remove micrometer metrics upon close\n\n * merged #1661 mark generated proxy classes final\n\n * merged #1681 allow alternate, more standard, JMX ObjectName, enabled by setting system\n   property 'hikaricp.jmx.register2.0=true'\n\n * merged #1605 fixes Java 11 issue where setMaximumPoolSize needs to be called before\n   setCorePoolSize in ThreadPoolExecutor\n\n * merged #1581 handle setting java 'short' property values from property files\n\n * merged #1699 add new configuration property 'keepaliveTime'\n\n * merged #1692 fix prometheus histogram metric tracker for multiple pools\n\nChanges in 3.4.5\n\n * fixed 1578 build change to ensure that proxies are generated using Java 8, otherwise we end\n   up with class references to Java 11 classes, which fail to load on Java 8.\n\nChanges in 3.4.4\n\n * Build HikariCP as a JEP 238 Multi-Release jar for increased compatability with Java 11 and\n   future modularized Java versions.\n\nChanges in 3.4.3\n\n * fixed 1534 check resultSet.getStatement() for null in ProxyDatabaseMetaData.\n\n * add additional debug logging around connection add.\n\n * add ThreadLocal removal attempt when bag item is removed.\n\nChanges in 3.4.2\n\n * fixed 1528 regression caused by pull request 1159 whereby fail-fast logic would exit upon all\n   errors even if it was configured to continue trying.\n\nChanges in 3.4.1\n\n * fix regression caused by 1337, which broke the ability to pass the isolation level by integer\n   value (string) instead of isolation level name.\n\nChanges in 3.4.0\n\n * merged 1265 alternative Prometheus metrics Histogram instead of locking Summary (which is\n   purportedly quite lock-heavy.\n\n * merged 1337 support accepting TRANSACTION_SQL_SERVER_SNAPSHOT_ISOLATION_LEVEL string for\n   isolation level.\n\n * merged 1331 user contribution: major refactor of metrics handling, hopefully without any\n   breakage.\n\n * add proxy class for DatabaseMetaData to intercept DatabaseMetaData.getConnection() call which was\n   leaking the raw database Connection object.\n\nChanges in 3.3.1\n\n * fixed 1287 set core pool size before max pool size\n\n * fixed 1308 treat a SQLTimeoutException as an evictable offense\n\n * do not default maxPoolSize to minIdle when only minIdle is specified\n\n * do not log warning about idleTimeout unless minimumIdle is less than maxPoolSize (because otherwise\n   it does not apply)\n\nChanges in 3.3.0\n\n * Revert change where Connection.isClosed() was called outside of setNetworkTimeout() block, opening\n   vulnerability to unacknowledged TCP traffic.\n\n * fixed 1186 limit number of items in the ConcurrentBag's ThreadLocal list to avoid OOM errors in some\n   borrow/requite patterns.\n\n * Merged changed to log uncaught (Throwable) exceptions during connection acquisition.\n\n * fixed 1161 fix logging formatting anchor.\n\n * fixed 1181, 1182 allow passing a Prometheus CollectorRegistry rather than always using the default\n   registry.\n\n * merged 1210 use orElseGet() to delay call until necessary with respect to the housekeeper thread\n   factory.\n\n * fixed 1074 capability to instantiate an object based on the String class name, usefull when you want\n   to set the MetricsTackerFactory from a property.\n\n * merged 1250 fix proxy classes generation reproducibility using a sorted LinkedHashSet\n\n * various clean-ups pointed out by sonarcloud.io\n\n * merged 1290 Class.newInstance() is deprecated as of Java 9. Usage should be replaced by calling\n   Class.getDeclaredConstructor().newInstance().\n\n * fixed #1305 ensure that ConcurrentBag.add() does not spin under high load, when waiting threads may never\n   reach 0.\n\n * fixes #1287 when system property blockUntilFilled is set, use multiple threads to fill the pool.\n\nChanges in 3.2.0\n\n * check connection closed condition before attempting to set network timeout to avoid spurios exceptions\n   in the log.\n\n * updated validation failure message to include recommendation to check maxLifetime value.\n\n * fixed 1141 do not throw SQLException when calling isClosed() or close() on a already closed unwrapped\n   Connection, as per JDBC specification.\n\n * fixed 1137 support changing user/password at runtime for DriverDataSource-wrapped driver connections.\n\n * fixed 1136 log loaded driver when using jdbcUrl.\n\n * pull 1135 extract sealed pool check into independent method.\n\n * fixed 1126 correct error in JavaDoc for HikariConfig.setInitializationFailTimeout().\n\n * fixed 1114 removed unreachable code.\n\nChanges in 3.1.0\n\n * Add get/setCatalog() to HikariConfigMXBean, allowing the catalog to be changed at runtime.\n   The catalog should only be changed while the pool is suspended, and after evicting existing\n   connections via HikariPoolMXBean.softEvictConnections().\n\nChanges in 3.0.0\n\n * Removed previously deprecated methods;\n     HikariConfig.copyState()\n     HikariConfig.getScheduledExecutorService()\n     HikariConfig.setScheduledExecutorService()\n     HikariConfig.isInitializationFailFast()\n     HikariConfig.setInitializationFailFast()\n     HikariConfig.isJdbc4ConnectionTest()\n     HikariConfig.setJdbc4ConnectionTest()\n\n     HikariDataSource.copyState()\n     HikariDataSource.getScheduledExecutorService()\n     HikariDataSource.setScheduledExecutorService()\n     HikariDataSource.suspendPool()\n     HikariDataSource.resumePool()\n     HikariDataSource.shutdown()\n     HikariDataSource.isInitializationFailFast()\n     HikariDataSource.setInitializationFailFast()\n     HikariDataSource.isJdbc4ConnectionTest()\n     HikariDataSource.setJdbc4ConnectionTest()\n\n * pull 1110 add currently configured maxConnections and minConnections to pool metrics.\n\n * pull 1100 remove hard-coded percentiles for Micrometer metrics.\n\n * pull 1108 maintain a strong reference to PoolStats for Micrometer gauges to prevent premature\n   garbage collection.\n\n * pull 1098 update to Micrometer 1.0.0.\n\nChanges in 2.7.8\n\n * fixed 1095 fix breakage caused by sealed configuration with respect to special handling for the\n   metricsRegistry and metricsTrackerFactory properties, which are allowed to be altered *once*\n   after the pool has started (even after the configuration is sealed).\n\n * pull 1089 allowing anonymous subclasses of MetricRegistry. Changed checks for metrics libraries\n   from a class name check to the assignableFrom() API.\n\nChanges in 2.7.7\n\n * fixed issue whereby configuration through the HikariConfigMXBean could not be altered due\n   to the sealed configuration change introduced in 2.7.5.\n\nChanges in 2.7.6\n\n * issue 1064 fixed regression where HikariConfig.copyStateTo() propagated the \"sealed\" status\n   of the source configuration to the target configuration -- preventing further changes.\n\nChanges in 2.7.5\n\n * issue 1061/pull 1062 fixed compatibility issue with requery.io caused by HikariCP's\n   proxied Statement class returning a driver-native ResultSet instance from getGeneratedKeys()\n   instead of returning a HikariCP proxied ResultSet.\n\n * pull 1058 enable quantiles on Prometheus metrics.\n\n * pull 1055 fixed incorrect JavaDoc for HikariConfigMXBean.getMinimumIdle() method.\n\n * issue 1045/pull 1047 added Automatic-Module-Name to jar manifest to ensure that the Java 8\n   library plays well with the Java 9 module system.\n\n * introduced the concept of a \"sealed\" configuration.  Once a pool is started, attempts to\n   alter its configuration outside of the HikariConfigMXBean will result in an IllegalStateException.\n\nChanges in 2.7.4\n\n * pull 1026 added support for SQL Server's specific isolation level (SNAPSHOT).\n\n * issue 926/pull 1022 HikariJNDIFactory should not throw a NamingException or else\n   cascading to other object factories cannot occur.\n\nChanges in 2.7.3\n\n * issue 1003 added PostgreSQL SQL State 0A000 to list of unrecoverable states calling\n   for eviction.\n\n * pull 1002 updated micrometer support due to API changes in their release candidate.\n\nChanges in 2.7.2\n\n * issue 983 fix logic that determines how many idle connections can be removed, without\n   violating the minimumIdle contract.\n\n * pull 987 add thread name to leak detection messages.\n\n * issue 982 fix classloader order, try the ThreadContext classloader before other\n   classloaders.\n\n * pull 977 log better messages when connection is evicted.\n\n * fallback to four digit random pool suffix when SecurityManager prevents writing\n   to system properties for the purpose of JVM-wide unique pool identifiers.\n\nChanges in 2.7.1\n\n * issue 968 Wrong label order in MicrometerMetricsTracker for the connection usage\n   metric.\n\n * issue 967 incorrect bitwise operator value in ConcurrentBag.requite method\n   intended to cause parkNanos() to be called every 256 iterations. Thanks to @ztkmkoo\n   for finding this.\n\nChanges in 2.4.13\n\n * backport more efficient contention handling in ConcurrentBag.requite from 2.6.x\n   branch.\n\n * issue 955 fix possible race condition when Statements are closed on different\n   threads from which they were created.\n\nChanges in 2.7.0\n\n * added support for micrometer metrics (currently Alpha-level support).\n\n * issue 905 mask JDBC password in URLs\n\n * issue 940 fix Prometheus metric collector for multiple data config\n\n * issue 941 add support for setting a default schema\n\n * issue 955 fix possible race condition when Statements are closed on different\n   threads from which they were created.\n\nChanges in 2.6.3\n\n * issue 878 load driver class from ThreadContext classloader if it is not found\n   via the regular classloader.\n\nChanges in 2.6.2\n\n * issue 890 add support for Prometheus metrics and multiple HikariCP pools.\n\n * issue 880 fix race condition caused by sorting collection while the condition of\n   sort can change.\n\n * issue 876 add support for using a Prometheus CollectorRegistry other than the\n   default one.\n\n * issue 867 support network timeout even for Connection.isValid().\n\n * issue 866 mark commit state dirty when Connection.getMetaData() is called.\n\nChanges in 2.6.1\n\n * issue 821 if a disconnection class exception is thrown during initial connection\n   setup, do not set the flag that indicates that checkDriverSupport() is complete.\n\n * issue 835 fix increased CPU consumption under heavy load caused by excessive\n   spinning in the ConcurrentBag.requite() method.\n\n * issue 817 updated behavior of new initializationFailTimeout, please see the\n   official documentation for details.\n\n * issue 742 add direct MXBean accessor methods to HikariDataSource for users who do\n   not want run run JMX.\n\nChanges in 2.6.0\n\n * Redesign of the contention code path resulting in doubling contended throughput; now\n   contended pool access retains 98% of the uncontended throughput.\n\n * issue 793 add new HikariConfig method, setScheduledExecutor(ScheduledExecutorService),\n   and deprecate method setScheduledExecutorService(ScheduledThreadPoolExecutor). It is\n   unfortunate that the deprecated method has the more accurate name, but its signature\n   cannot be changed without breaking binary compatibility.\n\n * issue 770 add a new property initializationFailTimeout, and deprecate configuration\n   property initializationFailFast.\n\n * issue 774 significantly improve spike load handling.\n\n * issues 518/769 add new metric for tracking how long physical connection acquisition is\n   taking.  DropWizard histogram name \"ConnectionCreation\", and Prometheus summary name\n   \"hikaricp_connection_creation_millis\".\n\n * issue 741 cancel HouseKeeper task on pool shutdown. If the ScheduledExecutor being used\n   did not belong to HikariCP, this task would remain scheduled after shutdown, causing a\n   memory leak.\n\n * issue 781 more technically accurate wording of pool startup and shutdown log messages.\n\nChanges in 2.5.1\n\n * issue 719 only reset lastConnectionFailure after a successful dataSource.getConnection()\n   call.\n\n * issue 716 do not scan deeper than 10 nested SQLExceptions, it's typically a trap ...\n   a chain that never terminates.\n\n * issue 714 fix possible issue with cross-thread visibility.  Change pool entry state from\n   AtomicInteger w/lazySet() to a volatile int with use of AtomicIntegerFieldUpdater.\n\nChanges in 2.5.0\n\n * Release 2.5.0 marks the start of a Java 8 HikariCP artifact.  The Java 7 artifact is\n   now called \"HikariCP-java7\".\n\n * HikariCP 2.5.0 and HikariCP-java7 2.4.8 have identical functionality.\n\nChanges in 2.4.12\n\n * issue 878 search for driverClass in both HikariCP class classloader and Thread Context\n   ClassLoader\n\nChanges in 2.4.11\n\n * issue 793 add new HikariConfig method, setScheduledExecutor(ScheduledExecutorService),\n   and deprecate method setScheduledExecutorService(ScheduledThreadPoolExecutor). It is\n   unfortunate that the deprecated method has the more accurate name, but its signature\n   cannot be changed without breaking binary compatibility.\n\n * issue 600 ignore Java 8 default methods when generating proxy classes for Java 7.\n\nChanges in 2.4.10\n\n * Redesign of the contention code path resulting in doubling contended throughput; now\n   contended pool access retains 98% of the uncontended throughput.\n\n * issue 770 add a new property initializationFailTimeout, and deprecate configuration\n   property initializationFailFast.\n\n * issue 774 significantly improve spike load handling.\n\n * issue 741 cancel HouseKeeper task on pool shutdown. If the ScheduledExecutor being used\n   did not belong to HikariCP, this task would remain scheduled after shutdown, causing a\n   memory leak.\n\nChanges in 2.4.9\n\n * issue 719 only reset lastConnectionFailure after a successful dataSource.getConnection()\n   call.\n\n * issue 716 do not scan deeper than 10 nested SQLExceptions, it's typically a trap ...\n   a chain that never terminates.\n\n * issue 714 fix possible issue with cross-thread visibility.  Change pool entry state from\n   AtomicInteger w/lazySet() to a volatile int with use of AtomicIntegerFieldUpdater.\n\nChanges in 2.4.8\n\n * Release 2.4.8 marks the start of a Java 7 HikariCP artifact, HikariCP-java7, representing\n   support for Java 7 entering maintenance mode.\n\n * Added Connection.commit() call to the fail-fast initialization for databases that\n   automatically start a new Connection in a transaction and throw an exception on close\n   if it is not committed.\n\n * feature 694: report if a previously reported leaked connection is returned to the pool\n\n * issue 689: log a warning if default transaction isolation level cannot be detected.\n   This can occur with pseudo-database drivers such as the one for JSonar\n\n * issue 674: fix regression caused by pull request #450 (overzealous optimisation)\n\nChanges in 2.4.7\n\n * Miscellaneous stability improvements.\n\n * Removed Oracle SQL state 61000, added specific error code (2399) to evict connections\n   when it is encountered.\n\n * issue 664: do not recycle PoolEntry objects that have closed their held connection.\n\n * issue 641, 643: reflection used method String.toUpperCase() without a Locale, which causes\n   problems in some locales such as Turkish.\n\n * pull 632: added support for Prometheus metrics tracker.\n\n * issue 650: detect Amazon Redshift connection refused error codes.\n\nChanges in 2.4.6\n\n * Added Oracle SQL error code 61000 (exceeded maximum connect time) to evict connections\n   when it is encountered.\n\n * issue 621: fix NPE in shutdown if invoked during initialization.\n\n * issue 606, 610: housekeeper thread was running before all class members were\n   initialized, causing an unrecoverable exception and disabling idle connection\n   retirement (maximumLifetime still applied).\n\nChanges in 2.4.5\n\n * issue 596: fix bug that occurs when minimumIdle is set to 0, but maximumPoolSize is\n   not explicitly set.\n\n * issue 594: fix incompatibility with various libraries caused by storing a non-String\n   object in System properties.\n\n * issue 593: improve logging when network timeout is not supported by the driver\n\n * issue 591: improve thread-safety of Statement proxies\n\nChanges in 2.4.4\n\n * Generate unique sequential pool names, even across container classloaders to avoid\n   JMX name collisions when registering pools.\n\n * Improve pool stability when running on computers using power-saving or sleep modes\n   where wake-up previously caused pool to grow to maximum size.\n\n * Improve pool stability under severe thread-starvation conditions.  Previous code\n   could interpret prolonged starvation (exceeding one minute) as non-contiguous clock\n   advancement, and reacted by soft-evicting connections (unnecessarily).\n\n * Added connection timeout rate to Dropwizard metrics (ConnectionTimeoutRate).\n\n * issue 563: Do not start the house-keeping thread until after pool initialisation\n   has succeeded.\n\n * issue 559: Ensure the pool refill after house-keeping does not enqueue more add\n   connection requests if there are already minimumIdle requests pending.\n\n * issue 555: include support for Java 8 interface 'default' methods during proxy\n   generation.\n\n * issue 547: decreased allowable minimum connectionTimeout and validationTimeout to\n   250ms.\n\n * issue 495: implemented iterator() method on custom FastList to support Tomcat\n   memory leak detection.\n\nChanges in 2.3.13\n\n * issue 512: reduce the number of calls made to Connection.getAutoCommit().\n\nChanges in 2.4.3\n\n * Improve pool shutdown behavior.  Stop active connection acquisition once the\n   shutdown sequence has initiated.\n\n * Improved detection and reporting of ambiguous pool configuration, when both the\n   connection URL and DataSource class names are specified.\n\nChanges in 2.4.2\n\n * Improve accuracy of timeouts for getConnection() calls by accounting for possibly\n   long delay aliveness tests.\n\n * Improve adherence to minimumIdle goal by closing idle connections starting from\n   longest idle time to shortest.  Additionally, stop when minimumIdle is reached even\n   if connections exceeding idleTimeout remain (but are still within maxLifetime).\n\n * Introduce larger variance into maxLifetime to avoid mass connection closing and\n   subsequent new connection creation load on the database.  Connections now have a\n   maximum lifetime between 97.5-100% of configured maxLifetime.  In the case of the\n   default 30 minute lifetime, this generates actual lifetimes with a maximum deviation\n   of 45 seconds.  Currently, no attempt is made to further avoid clustering that may\n   occur due to randomness.\n\n * Ongoing com.zaxxer.hikari.metrics refactors. This is not considered public API until\n   such time as we announce it. Caveat lector.\n\n * Performance improvements in the getConnection()/close() hot path.\n\n * issue 452: fixed race condition when creating an rapidly ramping connections in the\n   pool.\n\n * issue 415: removed use of java.beans classes to allow use of HikariCP with the\n   Zulu JRE compact3 profile.\n\n * issue 406: execute validation query during connection setup to make sure it is\n   valid SQL.\n\nChanges in 2.3.12\n\n * Fixed issue with proxy generation whereby the generated classes contain the\n   major version number for Java 8, which makes them incompatible with the Java 7\n   runtime.\n\nChanges in 2.4.1\n\n * issue 380: housekeeper was not being scheduled in the case of a user specified\n   ScheduledExecutorService instance.\n\n * issue 340: rollback change that elides setting the readonly property if the user\n   never explicitly configured it.  See discussion in the Github issue tracker.  Also\n   fixes binary ABI breakage between 2.3.9 and 2.4.0.\n\n * issue 379: stop closing idle connections, to keep minimumIdle connections in pool\n\n * issue 375: fixed InvalidPathException in HikariConfig\n\n * issue 362: fixed NullPointerException in closing connection (closing statements)\n\n * issue 357: allow altering the username & password through JMX at runtime\n\n * issue 349: handle integer Transaction isolation level\n\n * Throw SQLTransientConnectionException instead of SQLTimeoutException\n\n * for validating connection, if network time out is set, do not set query timeout too\n\n * ResultSet.getStatement() should return StatementProxy\n\nChanges in 2.4.0\n\n * Consolidated distribution into single JVM target (Java 7/8).  Java 6 support has\n   entered maintenance mode, bug fixes will continue on the 2.3.x branch.\n\n * Removed runtime dependency on Javassist by pre-generating proxy classes at build-time.\n\n * Significantly reduced overhead, and increased reliability, of ConcurrentBag.\n\n * Reduced garbage generation by 2-3x.\n\n * Add connection soft-eviction and replacement if backward system clock motion or\n   significant forward jumps (greater than 1 minute) are detected.\n\n * Pool configuration properties and DataSource methods previously marked as\n   @Deprecated have been removed.\n\n * Deprecated HikariDataSource.shutdown() in favor of close().\n\n * Improve shutdown performance.\n\n * Allow user specified ScheduledThreadPoolExecutor for housekeeping timer.  Useful\n   in applications with dozens or hundreds of pools in the same JVM.\n\n * Reduce overhead and accuracy of Dropwizard gauges.\n\nChanges in 2.3.7\n\n * Try harder at resolving the driver by various means when both driverClassName and jdbcUrl\n   have been specified.\n\n * Allow a specifically set DataSource instance to override other settings such as jdbcUrl,\n   dataSourceClassName, or driverClassName.\n\n * Fixed issue where, in the case of a driver-based configuration (jdbcUrl), we were not\n   initialising the network timeout Executor.\n\n * Fixed race condition uncovered during load-testing in which the connections in the pool\n   can spike to the maximum pool size when many connections reach their maxLifetime at the\n   same time.\n\nChanges in 2.3.6\n\n * Allow explicit definition of driverClassName to override DriverManager.getDriver(url)\n   located driver.\n\n * Fixed a rare issue where a Connection that is held out of the pool, and never used by\n   the holding thread, upon returning to the pool might be given to another thread without\n   an aliveness test.\n\nChanges in 2.3.5\n\n * Fixed regression caused by enhancement #279 that imposed a runtime dependency on\n   Dropwizard metrics.\n\nChanges in 2.3.4\n\n * Fixed class cast exception when setting the HealthCheckRegistry via JNDI lookup.\n\n * Allow Dropwizard MetricRegistry/HealthCheckRegistry to be set after pool startup --\n   one time only.\n\n * Make logger in BaseHikariPool non-static and use getClass() to log messages as the\n   implementation class rather than as BaseHikariPool.\n\n * Removed deprecation from connectionInitSql, it will be allowed.\n\n * Made suspect/resume lock non-static (should be be shared across pools).\n\n * Improved unwrap() behavior in the Hibernate HikariConnectionProvider.\n\n * Improved leak detection log\n\nChanges in 2.3.3\n\n * Fixed bad interaction with PostgeSQL JDBC driver whereby a SQLException thrown by\n   PostgreSQL where the getNextException() call returns the original exception and causes\n   an infinite loop in HikariCP (and eventual stack overflow).\n\n * Throw a typed Exception rather than a simple RuntimeException when pool initialization\n   fails.\n\n * Allow Dropwizard Metrics and HealthChecks to be configured by a JNDI lookup.\n\nChanges in 2.3.2\n\n * Add support for Dropwizard HealthChecks through the introduction of two initial health\n   checks: ConnectivityCheck and Connection99Percent.  See the Github project wiki for\n   documentation.\n\n * Allow a lower maxLifetime setting of 30 seconds (compared to previous 120 second limit)\n\n * Improve the message displayed when a connection leak is detected.\n\n * Fixed a bug where Connection.setNetworkTimeout() was called on an already closed connection\n   resulting in a warning log from the AS400 JDBC driver.\n\nChanges in 2.3.1\n\n * Work around a bug in the MySQL Connector/J implementation of Connection.setNetworkTimeout()\n   that results in non-deterministic asynchronous application of the timeout, resulting in an\n   NPE from the MySQL driver when setNetworkTimeout() is followed immediately by close().\n\n * Introduced a separate validationTimeout property, distict from connectionTimeout, to allow\n   greater control for some deployments that desire a long (or infinite) connectionTimeout\n   but expect the aliveness check to succeed for fail within a different (shorter) amount of\n   time.\n\nChanges in 2.3.0\n\n * Support pool suspend/resume to support certain failover scenarios.\n\n * Fix theoretical race in JDBC 4.0 detection support.\n\n * Improve shutdown() semantics to avoid exceptions as connections are forcefully\n   aborted.\n\n * Unregister Codahale metrics at shutdown, if metrics are enabled.\n\n * Major internal project layout restructuring to allow shared use of common code\n   between the Java 6/7 and Java 8 versions.\n\n * Fixed bug where two pools in the same VM (and ClassLoading domain), using drivers\n   with differing JDBC support levels, would fail unless both pools were using\n   connectionTestQuery.\n\n * Improved timeliness of maxLifetime evictions, while increasing performance of\n   getConnection() slightly as a side-effect.\n\n * Fixed bug in HikariDataSource unwrap() semantics.\n\n * Allow a lower leakDetectionThreshold of 2 seconds.\n\n * Fixed bug when using the HikariJNDIFactory that required the presence of\n   Codahale metrics.\n\n * Support initializationFailFast even when minimumIdle = 0\n\n * Log internal pool inconsistencies rather than throwing exceptions that might\n   disrupt internal executors.\n\n * Guard against poor or unreliable System.nanoTime() implementations.\n\nChanges in 2.2.5\n\n * Fixes for Java 6 compatibility.\n\n * Implement full transaction state tracking.  This allows HikariCP to bypass\n   the automatic rollback when connections are returned to the pool if the\n   transaction state is \"clean\".\n\n * Rename MBean closeIdleConnections() to softEvictConnections() and implement\n   \"evict on return\" semantics.\n\n * Fixed bug in code that sets HikariConfig values from a Properties instance\n   that prevented defaults from being read properly.\n\n * Fixed an obscure bug in connection creation with a driver that throws an\n   exception when setTransactionIsolation() is called with the value returned\n   by getTransactionIsolation().  We now bypass setTransactionIsolation() if\n   the user has not configured an isolation level (using the default).\n\n * Fix a bug where DataSource.loginTimeout() was always being set to 1 second.\n\n * Fix bug where some drivers return 0 from Connection.getNetworkTimeout(),\n   and yet throw SQLFeatureNotSupportedException when setNetworkTimeout() is\n   called. This broke they way that HikariCP had implemented JDBC 4.1 support\n   detection.\n\nChanges in 2.2.4\n\n * Generate proxy classes into the same protection domain as the HikariCP\n   loaded classes.  This solves issues with signed jars.\n\n * Improve accuracy of pool statistics available to JMX and logged at debug\n   level (at a slight performance cost).\n\n * Fixed issue where after a database down condition, and when minimumIdle is\n   set to 0, when the database connectivity is restored the connections could\n   ramp up to the maximum pool size.  Eventually, idleTimeout and maxLifetime\n   would restore normal pool conditions, but it was still undesirable behavior.\n\n * Improved connection timeout handling by using Connection.setNetworkTimeout()\n   if available (JDBC 4.1).\n\n * driverClassName is no longer a required property when jdbcUrl is specified.\n   Omitting this property only works for compliant drivers.\n\n * Add auto-detection of support for Statement.setQueryTimeout() used in the\n   alive check.  Fixes failures with test queries on the PostgreSQL driver\n   when not using JDBC4 isValid() alive checks.\n\n * The pool now defaults to fail-fast initialization.  If you need to start\n   your application without/before the database, you will need to explicitly\n   set initializationFailFast to false.\n\n * Dropwizard/Codahale metrics are now supported via the setMetricRegistry()\n   method in HikariConfig and in HikariDataSource.\n\n * Fixed issue with pool initialization of MySQL after default value of\n   initializationFailFast property was changed to false.\n\n * Further shadow runtime dependency on Codahale metrics from reflection\n   performed by Spring and other IoC containers.\n\n * Fix issue where network timeout was not properly restored to its default\n   value after modifying it for the duration of the addConnection() method.\n\nChanges in 2.1.0\n\n * Significant internal refactor supporting creation of new proxy instances\n   (throwaway) around Connections for each call to getConnection().  This\n   can avoid issues where a thread continues to try to use a connection\n   after it is closed [returned to the pool].\n\n * Allow HikariConfig(String propertyFileName) to load properties file from\n   classloader as a stream, with fall-back to the file-system.\n\n * Allow loading of properties file specified by -Dhikaricp.configurationFile\n   system property when using the default HikariConfig() or HikariDataSource()\n   constructors.\n\n * Fixed accounting issue with totalConnections when aborting connections\n   during shutdown, causing a warning message to be logged.\n\n * Fixed regression in Java 8 codeline that would prevent minimumIdle from\n   being set before maxPoolSize.\n\n * Fixed regression with Tomcat carping about ThreadLocal variables held after\n   web application restart\n\n * Change to make HikariConfig.getTransactionIsolation()/setTransactionIsolation()\n   follow proper bean semantics.\n\n * Fixed issue where connections created in the pool would skip the alive check\n   the first time they were used.\n\nChanges in 2.0.1\n\n * Split project into Java 6/7 and Java 8 components.\n\n * Fixed issue in JNDI object factory which would not allow JNDI-defined\n   DataSource properties to pass-thru to the pool.\n\n * Fixed issue where under certain conditions getConnection() could\n   timeout prematurely.\n\n * Fixed issue where user-defined pool name would be overridden by the\n   automatically generated name.\n\n * Fixed NPE when one of either username and password is defined, and the\n   other is null.\n\n * Fixed issue tracking the statements when there are mixed statement\n   types (Statement, PreparedStatement, etc.) open on the connection and\n   the number of unclosed statements exceeds 32.\n\n * Fixed issue where housekeeping threads would add idle connections\n   even when minimumIdle was 0.\n\n * Fixed issue where Wrapper.isWrapperFor() and Wrapper.unwrap() calls\n   did not recurse as per specification.\n\n * HikariDataSource now implements the Closable interface.\n\n * Integrated change to allow specifying a ThreadGroup for thread\n   creation is certain restricted environments.\n\nChanges in 1.4.0\n\n *) Fix bug that did not allow minIdle property to be set.\n\nChanges in 1.3.9\n\n *) Added pool name to housekeeping thread name to make thread dumps\n    more meaningful in containers with multiple pools.\n\n *) Improved shutdown semantics; make a concerted effort to close\n    idle connections and abort or close active connections.\n\n *) Performance enhancements.\n\nChanges in 1.3.8\n\n *) Fixed incorrect logic when using JDBC4 isValid() test for alive\n    status of connection.\n\nChanges in 1.3.7\n\n *) Added JNDI object factory (com.zaxxer.hikari.HikariJNDIFactory)\n    for Tomcat and other containers that prefer JNDI-registered DataSource\n    factories.\n\n *) Fix NPE that can occur when connections cannot be created and\n    callers to getConnection() timeout.\n\n *) Various bug fixes and minor enhancements.\n\nChanges in 1.3.6\n\n *) Include connection failure cause in calls to getConnection() that\n    timeout (due to connection failure).  Removed chatty logging.\n\n *) Java8 Compatibility fixes.\n\n *) Include pool name in logging messages.  Thanks for the contribution\n    @jaredstehler.\n\nChanges in 1.3.5\n\n *) Fixed a regression in the Javassist code generation.\n\n *) Various bug fixes and minor enhancements.\n\nChanges in 1.3.4\n\n *) Added new property isolateInternalQueries used to control whether\n    internal pool queries such as connection alive tests are isolated\n    in their own transaction.\n\n *) Added properties for DriverManager (driverClassName) and JDBC URL-based\n    (jdbcUrl) configuration.  1999 called and wants its JDBC driver back.\n\n *) Added new username and password properties to allow default authentication\n    for connections.\n\n *) Added support for the getConnection(username, password) method signature\n    to HikariDataSource.\n\n *) Added new property readOnly to control the default read-only status\n    of connections in the pool.\n\n *) Deprecated acquireIncrement property.\n\n *) Deprecated acquireRetries property.\n\n *) Deprecated acquireRetryDelay property.\n\n *) Deprecated minimumPoolSize property.\n\n *) Added new property minimumIdle used to control the minimum number of\n    idle connections the pool should try to maintain on a running basis.\n\n *) Added evictConnection(Connection) method to HikariDataSource to allow\n    special cases where users wish to forcibly eject a connection from\n    the pool.  To use used cautiously, read the JavaDoc before using.\n\n *) Various bug fixes and minor enhancements.\n\nChanges in 1.3.3\n\n *) Removed shared state contention that was causing excessive CPU cache-line\n    flushing.  Nearly 4x improvement in Connection acquisition/release\n    performance.\n\n *) Fixed issue with Tomcat carping about ThreadLocal variables held after\n    web application restart.\n\n *) Fixed issue where the maximum configured connections could be overrun\n    during large burst requests for connections.\n\nChanges in 1.3.2\n\n *) Java 6 compatibility.\n\n *) HikariDataSource now extends HikariConfig, so pool properties can be\n    set directly on a HikariDataSource without need to create a  HikariConfig.\n    The cost of doing so is a small runtime cost due to the fact that an\n    \"is initialized\" check must be performed on every invocation of\n    getConnection() due to lazy initialization of the pool.\n\n *) Added Sybase-specific disconnect error codes to SQLException snooping.\n\n *) Added HikariConfig.setCatalog() method to set DataSource catalog.\n\n *) Add DataSource.close() method that is synonymous  with shutdown().\n\n *) More performance improvements (never ending).\n\n *) Moved benchmarks to https://github.com/brettwooldridge/HikariCP-benchmark\n\nChanges in 1.3.0\n\n *) Pool is now backed by a custom lock-less ConcurrentBag that\n    provides superior performance to LinkedBlockingQueue and\n    LinkedTransferQueue for usage patterns of connection pools.\n\n *) Fixed bugs reported against the 1.2.9 release.\n\n *) Added more detailed logging for broken connections and failures\n    during new connection creation.\n\nChanges in 1.2.9\n\n *) Added a fail-fast option for pool initialization.  If enabled, a\n    RuntimeException will be thrown if there are errors during pool\n    initialization.\n\n *) Made the registration of the HikariCP MBeans optional.  They now\n    default to not being registered.  Registering them causes a minor\n    performance hit due to additional pool data collection in\n    HikariDataSource.getConnection().\n\n *) Added the SQLException message to the log entry when an exception\n    occurs during physical connection acquisition.\n\n *) Implemented an orderly shutdown of the pool via the shutdown() method\n    on HikariDataSource.\n\n *) Listened to \"Adele - Live At The Royal Albert Hall\" on endless loop.\n\nChanges in 1.2.8\n\n *) Fixed a critical bug introduced in 1.2.7 occurring when the number of\n    concurrently open statements exceeds sixteen.\n\nChanges in 1.2.7\n\n *) Finally achieved performance parity between the generated delegates\n    and the former method of instrumenting driver classes directly.\n\n *) Improved generated delegate code. Removed unnecessary casts, moved\n    to a static proxy factory rather than a singleton (performance win).\n\n *) Improved performance of FastStatementList (primary source of speed-up\n    to reach parity with former instrumentation code).\n\n *) Removed aliveness check on connection creation.\n\n *) Track connection isolation level and only reset if the state has\n    become \"dirty\".  Avoids unnecessary round trip to the DB during the\n    aliveness check.\n\n *) Added interface IConnectionCustomizer and related HikariConfig\n    property 'connectionCustomizerClassName' to allow users to specify\n    a connection customization implementation.\n\nChanges in 1.2.6\n\n *) Fixed regression that caused IndexOutOfBounds when multiple unclosed\n    Statements existed at the time of Connection.close().\n\n *) Fixed incorrect pom.xml dependency on Hibernate.\n\nChanges in 1.2.5\n\n *) Instrumentation mode (agent) removed due to narrowing gap between\n    delegation mode and instrumentation (and to simplify the code base).\n\n *) Added setDataSource() to HikariConfig to allow a DataSource instance\n    to be explicitly wrapped by the pool.  Only available when creating\n    HikariConfig programmatically or constructing HikariConfig from a\n    java.util.Properties instance.\n\n *) Fixed Hibernate threading issue (certain usage patterns) introduced\n    in 1.2.2.\n\n *) Fixed issue observed with PostgreSQL whereby the query that tests the\n    connection for \"aliveness\" also starts a transaction (when auto-commit\n    is false), thereby causing a later failure when we tried to set the\n    transaction isolation level.\n\n *) Fixed issue where idleTimeout could not be set to 0, thereby disabling\n    it. Incorrect value validation caused 0 to be rejected as a valid value.\n\nChanges in 1.2.4\n\n *) Fix another Hibernate-related issue whereby an NPE is encountered when\n    a thread that was not the thread that obtained a Connection tries to\n    interact with that Connection.\n\nChanges in 1.2.3\n\n *) Fix internal (but suppressed) exception during rollback of connections\n    returned to the pool with auto-commit turned off.\n\n *) Fix a reflection issue that causes Hibernate failures due to the\n    CallableStatement interface being incorrectly injected into statement\n    proxies that are PreparedStatement or Statement instances.\n\nChanges in 1.2.2\n\n *) Perform a rollback() on connections returned to the pool with\n    auto commit disabled.\n\n *) Add a constructor for HikariConfig that accepts a Properties\n    object.\n\n *) Speed improvements for delegate mode.\n\n *) Fix a bug where connection timeouts could not be disabled.\n\n *) Permit setting the DataSource logWriter either on the HikariDataSource\n    or via addDataSourceProperty() on the HikariConfig.\n\n *) Add transactionIsolation property to allow setting the default\n    transaction isolation level for connections.\n\nChanges in 1.2.1\n\n *) Clear SQL warnings before returning a connection to the user.\n\n *) Added asynchronous connection backfill strategy that triggers\n    when the pool becomes empty as a result of dispatching a\n    connection.\n\n *) Changed default acquireIncrement to 1, set minimum timeout of\n    100ms for acquiring a connection.\n\nChanges in 1.1.9\n\n *) Added connectionInitSql property to allow setting connection\n    properties when a new connection is created.\n\n *) Added setDataSourceProperties() setter to HikariConfig to\n    allow easier configuration though Spring.\n"
        },
        {
          "name": "KEYS.txt",
          "type": "blob",
          "size": 0.2197265625,
          "content": "# GPG Release Key Fingerprints\nBrett Wooldridge <brett.wooldridge@gmail.com> F3A9 0E6B 10E8 09F8 51AB  4FC5 4CC0 8E7F 47C3 EC76\nLeo Bayer        <lfbayer@gmail.com>          9579 802D C3E1 5DE9 C389  239F C0D4 8A11 9CE7 EE7B\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 10.0322265625,
          "content": "Apache License\nVersion 2.0, January 2004\nhttp://www.apache.org/licenses/\n\nTERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n1. Definitions.\n\n\"License\" shall mean the terms and conditions for use, reproduction, and\ndistribution as defined by Sections 1 through 9 of this document.\n\n\"Licensor\" shall mean the copyright owner or entity authorized by the copyright\nowner that is granting the License.\n\n\"Legal Entity\" shall mean the union of the acting entity and all other entities\nthat control, are controlled by, or are under common control with that entity.\nFor the purposes of this definition, \"control\" means (i) the power, direct or\nindirect, to cause the direction or management of such entity, whether by\ncontract or otherwise, or (ii) ownership of fifty percent (50%) or more of the\noutstanding shares, or (iii) beneficial ownership of such entity.\n\n\"You\" (or \"Your\") shall mean an individual or Legal Entity exercising\npermissions granted by this License.\n\n\"Source\" form shall mean the preferred form for making modifications, including\nbut not limited to software source code, documentation source, and configuration\nfiles.\n\n\"Object\" form shall mean any form resulting from mechanical transformation or\ntranslation of a Source form, including but not limited to compiled object code,\ngenerated documentation, and conversions to other media types.\n\n\"Work\" shall mean the work of authorship, whether in Source or Object form, made\navailable under the License, as indicated by a copyright notice that is included\nin or attached to the work (an example is provided in the Appendix below).\n\n\"Derivative Works\" shall mean any work, whether in Source or Object form, that\nis based on (or derived from) the Work and for which the editorial revisions,\nannotations, elaborations, or other modifications represent, as a whole, an\noriginal work of authorship. For the purposes of this License, Derivative Works\nshall not include works that remain separable from, or merely link (or bind by\nname) to the interfaces of, the Work and Derivative Works thereof.\n\n\"Contribution\" shall mean any work of authorship, including the original version\nof the Work and any modifications or additions to that Work or Derivative Works\nthereof, that is intentionally submitted to Licensor for inclusion in the Work\nby the copyright owner or by an individual or Legal Entity authorized to submit\non behalf of the copyright owner. For the purposes of this definition,\n\"submitted\" means any form of electronic, verbal, or written communication sent\nto the Licensor or its representatives, including but not limited to\ncommunication on electronic mailing lists, source code control systems, and\nissue tracking systems that are managed by, or on behalf of, the Licensor for\nthe purpose of discussing and improving the Work, but excluding communication\nthat is conspicuously marked or otherwise designated in writing by the copyright\nowner as \"Not a Contribution.\"\n\n\"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf\nof whom a Contribution has been received by Licensor and subsequently\nincorporated within the Work.\n\n2. Grant of Copyright License.\n\nSubject to the terms and conditions of this License, each Contributor hereby\ngrants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free,\nirrevocable copyright license to reproduce, prepare Derivative Works of,\npublicly display, publicly perform, sublicense, and distribute the Work and such\nDerivative Works in Source or Object form.\n\n3. Grant of Patent License.\n\nSubject to the terms and conditions of this License, each Contributor hereby\ngrants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free,\nirrevocable (except as stated in this section) patent license to make, have\nmade, use, offer to sell, sell, import, and otherwise transfer the Work, where\nsuch license applies only to those patent claims licensable by such Contributor\nthat are necessarily infringed by their Contribution(s) alone or by combination\nof their Contribution(s) with the Work to which such Contribution(s) was\nsubmitted. If You institute patent litigation against any entity (including a\ncross-claim or counterclaim in a lawsuit) alleging that the Work or a\nContribution incorporated within the Work constitutes direct or contributory\npatent infringement, then any patent licenses granted to You under this License\nfor that Work shall terminate as of the date such litigation is filed.\n\n4. Redistribution.\n\nYou may reproduce and distribute copies of the Work or Derivative Works thereof\nin any medium, with or without modifications, and in Source or Object form,\nprovided that You meet the following conditions:\n\nYou must give any other recipients of the Work or Derivative Works a copy of\nthis License; and\nYou must cause any modified files to carry prominent notices stating that You\nchanged the files; and\nYou must retain, in the Source form of any Derivative Works that You distribute,\nall copyright, patent, trademark, and attribution notices from the Source form\nof the Work, excluding those notices that do not pertain to any part of the\nDerivative Works; and\nIf the Work includes a \"NOTICE\" text file as part of its distribution, then any\nDerivative Works that You distribute must include a readable copy of the\nattribution notices contained within such NOTICE file, excluding those notices\nthat do not pertain to any part of the Derivative Works, in at least one of the\nfollowing places: within a NOTICE text file distributed as part of the\nDerivative Works; within the Source form or documentation, if provided along\nwith the Derivative Works; or, within a display generated by the Derivative\nWorks, if and wherever such third-party notices normally appear. The contents of\nthe NOTICE file are for informational purposes only and do not modify the\nLicense. You may add Your own attribution notices within Derivative Works that\nYou distribute, alongside or as an addendum to the NOTICE text from the Work,\nprovided that such additional attribution notices cannot be construed as\nmodifying the License.\nYou may add Your own copyright statement to Your modifications and may provide\nadditional or different license terms and conditions for use, reproduction, or\ndistribution of Your modifications, or for any such Derivative Works as a whole,\nprovided Your use, reproduction, and distribution of the Work otherwise complies\nwith the conditions stated in this License.\n\n5. Submission of Contributions.\n\nUnless You explicitly state otherwise, any Contribution intentionally submitted\nfor inclusion in the Work by You to the Licensor shall be under the terms and\nconditions of this License, without any additional terms or conditions.\nNotwithstanding the above, nothing herein shall supersede or modify the terms of\nany separate license agreement you may have executed with Licensor regarding\nsuch Contributions.\n\n6. Trademarks.\n\nThis License does not grant permission to use the trade names, trademarks,\nservice marks, or product names of the Licensor, except as required for\nreasonable and customary use in describing the origin of the Work and\nreproducing the content of the NOTICE file.\n\n7. Disclaimer of Warranty.\n\nUnless required by applicable law or agreed to in writing, Licensor provides the\nWork (and each Contributor provides its Contributions) on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied,\nincluding, without limitation, any warranties or conditions of TITLE,\nNON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are\nsolely responsible for determining the appropriateness of using or\nredistributing the Work and assume any risks associated with Your exercise of\npermissions under this License.\n\n8. Limitation of Liability.\n\nIn no event and under no legal theory, whether in tort (including negligence),\ncontract, or otherwise, unless required by applicable law (such as deliberate\nand grossly negligent acts) or agreed to in writing, shall any Contributor be\nliable to You for damages, including any direct, indirect, special, incidental,\nor consequential damages of any character arising as a result of this License or\nout of the use or inability to use the Work (including but not limited to\ndamages for loss of goodwill, work stoppage, computer failure or malfunction, or\nany and all other commercial damages or losses), even if such Contributor has\nbeen advised of the possibility of such damages.\n\n9. Accepting Warranty or Additional Liability.\n\nWhile redistributing the Work or Derivative Works thereof, You may choose to\noffer, and charge a fee for, acceptance of support, warranty, indemnity, or\nother liability obligations and/or rights consistent with this License. However,\nin accepting such obligations, You may act only on Your own behalf and on Your\nsole responsibility, not on behalf of any other Contributor, and only if You\nagree to indemnify, defend, and hold each Contributor harmless for any liability\nincurred by, or claims asserted against, such Contributor by reason of your\naccepting any such warranty or additional liability.\n\nEND OF TERMS AND CONDITIONS\n\nAPPENDIX: How to apply the Apache License to your work\n\nTo apply the Apache License to your work, attach the following boilerplate\nnotice, with the fields enclosed by brackets \"[]\" replaced with your own\nidentifying information. (Don't include the brackets!) The text should be\nenclosed in the appropriate comment syntax for the file format. We also\nrecommend that a file or class name and description of purpose be included on\nthe same \"printed page\" as the copyright notice for easier identification within\nthird-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 36.0458984375,
          "content": "<h1><img src=\"https://github.com/brettwooldridge/HikariCP/wiki/Hikari.png\"> HikariCP<sup><sup>&nbsp;It's Faster.</sup></sup><sub><sub><sup>Hi·ka·ri [hi·ka·'lē] &#40;<i>Origin: Japanese</i>): light; ray.</sup></sub></sub></h1><br>\n\n[![][Build Status img]][Build Status]\n[![][Coverage Status img]][Coverage Status]\n[![][license img]][license]\n[![][Maven Central img]][Maven Central]\n[![][Javadocs img]][Javadocs]\n[![][Librapay img]][Librapay]\n\nFast, simple, reliable.  HikariCP is a \"zero-overhead\" production ready JDBC connection pool.  At roughly 165Kb, the library is very light.  Read about [how we do it here](https://github.com/brettwooldridge/HikariCP/wiki/Down-the-Rabbit-Hole).\n\n&nbsp;&nbsp;&nbsp;<sup>**\"Simplicity is prerequisite for reliability.\"**<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- *Dr. Edsger Dijkstra*</sup>\n\n----------------------------------------------------\n\n> [!IMPORTANT]\n> In order to avoid a rare condition where the pool goes to zero and does not recover it is necessary to configure *TCP keepalive*. Some JDBC drivers support this via properties, for example ``tcpKeepAlive=true`` on PostgreSQL, but in any case it can also be configured at the OS-level. See [Setting OS TCP Keepalive](https://github.com/brettwooldridge/HikariCP/wiki/Setting-OS-TCP-Keepalive) and/or [TCP keepalive for a better PostgreSQL experience](https://www.cybertec-postgresql.com/en/tcp-keepalive-for-a-better-postgresql-experience/#setting-tcp-keepalive-parameters-on-the-operating-system).\n\n----------------------------------------------------\n\n### Index\n* [Artifacts](#artifacts)\n* [JMH Benchmarks](#checkered_flag-jmh-benchmarks)\n* [Analyses](#microscope-analyses)\n  * [Spike Demand Pool Comparison](#spike-demand-pool-comparison)\n  * [You're probably doing it wrong](#youre-probably-doing-it-wrong)\n  * [WIX Engineering Analysis](#wix-engineering-analysis)\n  * [Failure: Pools behaving badly](#failure-pools-behaving-badly)\n* [User Testimonials](#family-user-testimonials) <br>\n* [Configuration](#gear-configuration-knobs-baby) <br>\n  * [Essentials](#essentials)\n  * [Frequently used](#frequently-used)\n  * [Infrequently used](#infrequently-used)\n* [Initialization](#rocket-initialization)\n\n----------------------------------------------------\n\n### Artifacts\n\n_**Java 11+** maven artifact:_\n```xml\n<dependency>\n   <groupId>com.zaxxer</groupId>\n   <artifactId>HikariCP</artifactId>\n   <version>6.2.1</version>\n</dependency>\n```\n_Java 8 maven artifact (*deprecated*):_\n```xml\n<dependency>\n   <groupId>com.zaxxer</groupId>\n   <artifactId>HikariCP</artifactId>\n   <version>4.0.3</version>\n</dependency>\n```\n_Java 7 maven artifact (*deprecated*):_\n```xml\n<dependency>\n   <groupId>com.zaxxer</groupId>\n   <artifactId>HikariCP-java7</artifactId>\n   <version>2.4.13</version>\n</dependency>\n```\n_Java 6 maven artifact (*deprecated*):_\n```xml\n<dependency>\n   <groupId>com.zaxxer</groupId>\n   <artifactId>HikariCP-java6</artifactId>\n   <version>2.3.13</version>\n</dependency>\n```\nOr [download from here](http://search.maven.org/#search%7Cga%7C1%7Ccom.zaxxer.hikaricp).\n\n----------------------------------------------------\n\n### :checkered_flag: JMH Benchmarks\n\nMicrobenchmarks were created to isolate and measure the overhead of pools using the [JMH microbenchmark framework](http://openjdk.java.net/projects/code-tools/jmh/). You can checkout the [HikariCP benchmark project for details](https://github.com/brettwooldridge/HikariCP-benchmark) and review/run the benchmarks yourself.\n\n![](https://github.com/brettwooldridge/HikariCP/wiki/HikariCP-bench-2.6.0.png)\n\n * One *Connection Cycle* is defined as single ``DataSource.getConnection()``/``Connection.close()``.\n * One *Statement Cycle* is defined as single ``Connection.prepareStatement()``, ``Statement.execute()``, ``Statement.close()``.\n\n<sup>\n<sup>1</sup> Versions: HikariCP 2.6.0, commons-dbcp2 2.1.1, Tomcat 8.0.24, Vibur 16.1, c3p0 0.9.5.2, Java 8u111 <br/>\n<sup>2</sup> Intel Core i7-3770 CPU @ 3.40GHz <br/>\n<sup>3</sup> Uncontended benchmark: 32 threads/32 connections, Contended benchmark: 32 threads, 16 connections <br/>\n<sup>4</sup> Apache Tomcat fails to complete the Statement benchmark when the Tomcat <i>StatementFinalizer</i> is used <a href=\"https://raw.githubusercontent.com/wiki/brettwooldridge/HikariCP/markdown/Tomcat-Statement-Failure.md\">due to excessive garbage collection times</a><br/>\n<sup>5</sup> Apache DBCP fails to complete the Statement benchmark <a href=\"https://raw.githubusercontent.com/wiki/brettwooldridge/HikariCP/markdown/Dbcp2-Statement-Failure.md\">due to excessive garbage collection times</a>\n</sup>\n\n----------------------------------------------------\n### :microscope: Analyses\n\n#### Spike Demand Pool Comparison\n<a href=\"https://github.com/brettwooldridge/HikariCP/blob/dev/documents/Welcome-To-The-Jungle.md\"><img width=\"400\" align=\"right\" src=\"https://github.com/brettwooldridge/HikariCP/wiki/Spike-Hikari.png\"></a>\nAnalysis of HikariCP v2.6, in comparison to other pools, in relation to a unique \"spike demand\" load.\n\nThe customer's environment imposed a high cost of new connection acquisition, and a requirement for a dynamically-sized pool, but yet a need for responsiveness to request spikes.  Read about the spike demand handling [here](https://github.com/brettwooldridge/HikariCP/blob/dev/documents/Welcome-To-The-Jungle.md).\n<br/>\n<br/>\n#### You're [probably] doing it wrong\n<a href=\"https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing\"><img width=\"200\" align=\"right\" src=\"https://github.com/brettwooldridge/HikariCP/wiki/Postgres_Chart.png\"></a>\nAKA *\"What you probably didn't know about connection pool sizing\"*.  Watch a video from the Oracle Real-world Performance group, and learn about why database connections do not need to be so numerous as they often are. In fact, too many connections have a clear and demonstrable *negative* impact on performance; a 50x difference in the case of the Oracle demonstration.  [Read on to find out](https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing).\n<br/>\n#### WIX Engineering Analysis\n<a href=\"https://www.wix.engineering/blog/how-does-hikaricp-compare-to-other-connection-pools\"><img width=\"180\" align=\"left\" src=\"https://github.com/brettwooldridge/HikariCP/wiki/Wix-Engineering.png\"></a>\nWe'd like to thank the guys over at WIX for the unsolicited and deep write-up about HikariCP on their [engineering blog](https://www.wix.engineering/post/how-does-hikaricp-compare-to-other-connection-pools).  Take a look if you have time.\n<br/>\n<br/>\n<br/>\n#### Failure: Pools behaving badly\nRead our interesting [\"Database down\" pool challenge](https://github.com/brettwooldridge/HikariCP/wiki/Bad-Behavior:-Handling-Database-Down).\n\n----------------------------------------------------\n#### \"Imitation Is The Sincerest Form Of Plagiarism\" - <sub><sup>anonymous</sup></sub>\nOpen source software like HikariCP, like any product, competes in the free market.  We get it.  We understand that product advancements, once public, are often co-opted.  And we understand that ideas can arise from the zeitgeist; simultaneously and independently.  But the timeline of innovation, particularly in open source projects, is also clear and we want our users to understand the direction of flow of innovation in our space.  It could be demoralizing to see the result of hundreds of hours of thought and research co-opted so easily, and perhaps that is inherent in a free marketplace, but we are not demoralized.  *We are motivated; to widen the gap.*\n\n----------------------------------------------------\n### :family: User Testimonials\n\n[![](https://github.com/brettwooldridge/HikariCP/wiki/tweet3.png)](https://twitter.com/jkuipers)<br/>\n[![](https://github.com/brettwooldridge/HikariCP/wiki/tweet1.png)](https://twitter.com/steve_objectify)<br/>\n[![](https://github.com/brettwooldridge/HikariCP/wiki/tweet2.png)](https://twitter.com/brettemeyer)<br/>\n[![](https://github.com/brettwooldridge/HikariCP/wiki/tweet4.png)](https://twitter.com/dgomesbr/status/527521925401419776)\n\n------------------------------\n### :gear: Configuration (knobs, baby!)\nHikariCP comes with *sane* defaults that perform well in most deployments without additional tweaking. **Every property is optional, except for the \"essentials\" marked below.**\n\n<sup>&#128206;</sup>&nbsp;*HikariCP uses milliseconds for all time values.*\n\n&#128680;&nbsp;HikariCP relies on accurate timers for both performance and reliability. It is *imperative* that your server is synchronized with a time-source such as an NTP server. *Especially* if your server is running within a virtual machine.  Why? [Read more here](https://dba.stackexchange.com/a/171020). **Do not rely on hypervisor settings to \"synchronize\" the clock of the virtual machine. Configure time-source synchronization inside the virtual machine.**   If you come asking for support on an issue that turns out to be caused by lack time synchronization, you will be taunted publicly on Twitter.\n\n#### Essentials\n\n&#128292;``dataSourceClassName``<br/>\nThis is the name of the ``DataSource`` class provided by the JDBC driver.  Consult the\ndocumentation for your specific JDBC driver to get this class name, or see the [table](https://github.com/brettwooldridge/HikariCP#popular-datasource-class-names) below.\nNote XA data sources are not supported.  XA requires a real transaction manager like\n[bitronix](https://github.com/bitronix/btm). Note that you do not need this property if you are using\n``jdbcUrl`` for \"old-school\" DriverManager-based JDBC driver configuration.\n*Default: none*\n\n*- or -*\n\n&#128292;``jdbcUrl``<br/>\nThis property directs HikariCP to use \"DriverManager-based\" configuration.  We feel that DataSource-based\nconfiguration (above) is superior for a variety of reasons (see below), but for many deployments there is\nlittle significant difference.  **When using this property with \"old\" drivers, you may also need to set\nthe  ``driverClassName`` property, but try it first without.**  Note that if this property is used, you may\nstill use *DataSource* properties to configure your driver and is in fact recommended over driver parameters\nspecified in the URL itself.\n*Default: none*\n\n***\n\n&#128292;``username``<br/>\nThis property sets the default authentication username used when obtaining *Connections* from\nthe underlying driver.  Note that for DataSources this works in a very deterministic fashion by\ncalling ``DataSource.getConnection(*username*, password)`` on the underlying DataSource.  However,\nfor Driver-based configurations, every driver is different.  In the case of Driver-based, HikariCP\nwill use this ``username`` property to set a ``user`` property in the ``Properties`` passed to the\ndriver's ``DriverManager.getConnection(jdbcUrl, props)`` call.  If this is not what you need,\nskip this method entirely and call ``addDataSourceProperty(\"username\", ...)``, for example.\n*Default: none*\n\n&#128292;``password``<br/>\nThis property sets the default authentication password used when obtaining *Connections* from\nthe underlying driver. Note that for DataSources this works in a very deterministic fashion by\ncalling ``DataSource.getConnection(username, *password*)`` on the underlying DataSource.  However,\nfor Driver-based configurations, every driver is different.  In the case of Driver-based, HikariCP\nwill use this ``password`` property to set a ``password`` property in the ``Properties`` passed to the\ndriver's ``DriverManager.getConnection(jdbcUrl, props)`` call.  If this is not what you need,\nskip this method entirely and call ``addDataSourceProperty(\"pass\", ...)``, for example.\n*Default: none*\n\n#### Frequently used\n\n&#9989;``autoCommit``<br/>\nThis property controls the default auto-commit behavior of connections returned from the pool.\nIt is a boolean value.\n*Default: true*\n\n&#9203;``connectionTimeout``<br/>\nThis property controls the maximum number of milliseconds that a client (that's you) will wait\nfor a connection from the pool.  If this time is exceeded without a connection becoming\navailable, a SQLException will be thrown.  Lowest acceptable connection timeout is 250 ms.\n*Default: 30000 (30 seconds)*\n\n&#9203;``idleTimeout``<br/>\nThis property controls the maximum amount of time that a connection is allowed to sit idle in the\npool.  **This setting only applies when ``minimumIdle`` is defined to be less than ``maximumPoolSize``.**\nIdle connections will *not* be retired once the pool reaches ``minimumIdle`` connections.  Whether a\nconnection is retired as idle or not is subject to a maximum variation of +30 seconds, and average\nvariation of +15 seconds.  A connection will never be retired as idle *before* this timeout.  A value\nof 0 means that idle connections are never removed from the pool.  The minimum allowed value is 10000ms\n(10 seconds).\n*Default: 600000 (10 minutes)*\n\n&#9203;``keepaliveTime``<br/>\nThis property controls how frequently HikariCP will attempt to keep a connection alive, in order to prevent\nit from being timed out by the database or network infrastructure. This value must be less than the\n`maxLifetime` value. A \"keepalive\" will only occur on an idle connection. When the time arrives for a \"keepalive\"\nagainst a given connection, that connection will be removed from the pool, \"pinged\", and then returned to the\npool. The 'ping' is one of either: invocation of the JDBC4 `isValid()` method, or execution of the\n`connectionTestQuery`. Typically, the duration out-of-the-pool should be measured in single digit milliseconds\nor even sub-millisecond, and therefore should have little or no noticeable performance impact. The minimum\nallowed value is 30000ms (30 seconds), but a value in the range of minutes is most desirable.\n*Default: 120000 (2 minutes)*\n\n&#9203;``maxLifetime``<br/>\nThis property controls the maximum lifetime of a connection in the pool.  An in-use connection will\nnever be retired, only when it is closed will it then be removed.  On a connection-by-connection\nbasis, minor negative attenuation is applied to avoid mass-extinction in the pool.  **We strongly recommend\nsetting this value, and it should be several seconds shorter than any database or infrastructure imposed\nconnection time limit.**  A value of 0 indicates no maximum lifetime (infinite lifetime), subject of\ncourse to the ``idleTimeout`` setting.  The minimum allowed value is 30000ms (30 seconds).\n*Default: 1800000 (30 minutes)*\n\n&#128292;``connectionTestQuery``<br/>\n**If your driver supports JDBC4 we strongly recommend not setting this property.** This is for\n\"legacy\" drivers that do not support the JDBC4 ``Connection.isValid() API``.  This is the query that\nwill be executed just before a connection is given to you from the pool to validate that the\nconnection to the database is still alive. *Again, try running the pool without this property,\nHikariCP will log an error if your driver is not JDBC4 compliant to let you know.*\n*Default: none*\n\n&#128290;``minimumIdle``<br/>\nThis property controls the minimum number of *idle connections* that HikariCP tries to maintain\nin the pool.  If the idle connections dip below this value and total connections in the pool are less than ``maximumPoolSize``,\nHikariCP will make a best effort to add additional connections quickly and efficiently.\nHowever, for maximum performance and responsiveness to spike demands,\nwe recommend *not* setting this value and instead allowing HikariCP to act as a *fixed size* connection pool.\n*Default: same as maximumPoolSize*\n\n&#128290;``maximumPoolSize``<br/>\nThis property controls the maximum size that the pool is allowed to reach, including both\nidle and in-use connections.  Basically this value will determine the maximum number of\nactual connections to the database backend.  A reasonable value for this is best determined\nby your execution environment.  When the pool reaches this size, and no idle connections are\navailable, calls to getConnection() will block for up to ``connectionTimeout`` milliseconds\nbefore timing out.  Please read [about pool sizing](https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing).\n*Default: 10*\n\n&#128200;``metricRegistry``<br/>\nThis property is only available via programmatic configuration or IoC container.  This property\nallows you to specify an instance of a *Codahale/Dropwizard* ``MetricRegistry`` to be used by the\npool to record various metrics.  See the [Metrics](https://github.com/brettwooldridge/HikariCP/wiki/Dropwizard-Metrics)\nwiki page for details.\n*Default: none*\n\n&#128200;``healthCheckRegistry``<br/>\nThis property is only available via programmatic configuration or IoC container.  This property\nallows you to specify an instance of a *Codahale/Dropwizard* ``HealthCheckRegistry`` to be used by the\npool to report current health information.  See the [Health Checks](https://github.com/brettwooldridge/HikariCP/wiki/Dropwizard-HealthChecks)\nwiki page for details.\n*Default: none*\n\n&#128292;``poolName``<br/>\nThis property represents a user-defined name for the connection pool and appears mainly\nin logging and JMX management consoles to identify pools and pool configurations.\n*Default: auto-generated*\n\n#### Infrequently used\n\n&#9203;``initializationFailTimeout``<br/>\nThis property controls whether the pool will \"fail fast\" if the pool cannot be seeded with\nan initial connection successfully.  Any positive number is taken to be the number of\nmilliseconds to attempt to acquire an initial connection; the application thread will be\nblocked during this period.  If a connection cannot be acquired before this timeout occurs,\nan exception will be thrown.  This timeout is applied *after* the ``connectionTimeout``\nperiod.  If the value is zero (0), HikariCP will attempt to obtain and validate a connection.\nIf a connection is obtained, but fails validation, an exception will be thrown and the pool\nnot started.  However, if a connection cannot be obtained, the pool will start, but later\nefforts to obtain a connection may fail.  A value less than zero will bypass any initial\nconnection attempt, and the pool will start immediately while trying to obtain connections\nin the background.  Consequently, later efforts to obtain a connection may fail.\n*Default: 1*\n\n&#10062;``isolateInternalQueries``<br/>\nThis property determines whether HikariCP isolates internal pool queries, such as the\nconnection alive test, in their own transaction.  Since these are typically read-only\nqueries, it is rarely necessary to encapsulate them in their own transaction.  This\nproperty only applies if ``autoCommit`` is disabled.\n*Default: false*\n\n&#10062;``allowPoolSuspension``<br/>\nThis property controls whether the pool can be suspended and resumed through JMX.  This is\nuseful for certain failover automation scenarios.  When the pool is suspended, calls to\n``getConnection()`` will *not* timeout and will be held until the pool is resumed.\n*Default: false*\n\n&#10062;``readOnly``<br/>\nThis property controls whether *Connections* obtained from the pool are in read-only mode by\ndefault.  Note some databases do not support the concept of read-only mode, while others provide\nquery optimizations when the *Connection* is set to read-only.  Whether you need this property\nor not will depend largely on your application and database.\n*Default: false*\n\n&#10062;``registerMbeans``<br/>\nThis property controls whether or not JMX Management Beans (\"MBeans\") are registered or not.\n*Default: false*\n\n&#128292;``catalog``<br/>\nThis property sets the default *catalog* for databases that support the concept of catalogs.\nIf this property is not specified, the default catalog defined by the JDBC driver is used.\n*Default: driver default*\n\n&#128292;``connectionInitSql``<br/>\nThis property sets a SQL statement that will be executed after every new connection creation\nbefore adding it to the pool. If this SQL is not valid or throws an exception, it will be\ntreated as a connection failure and the standard retry logic will be followed.\n*Default: none*\n\n&#128292;``driverClassName``<br/>\nHikariCP will attempt to resolve a driver through the DriverManager based solely on the ``jdbcUrl``,\nbut for some older drivers the ``driverClassName`` must also be specified.  Omit this property unless\nyou get an obvious error message indicating that the driver was not found.\n*Default: none*\n\n&#128292;``transactionIsolation``<br/>\nThis property controls the default transaction isolation level of connections returned from\nthe pool.  If this property is not specified, the default transaction isolation level defined\nby the JDBC driver is used.  Only use this property if you have specific isolation requirements that are\ncommon for all queries.  The value of this property is the constant name from the ``Connection``\nclass such as ``TRANSACTION_READ_COMMITTED``, ``TRANSACTION_REPEATABLE_READ``, etc.\n*Default: driver default*\n\n&#9203;``validationTimeout``<br/>\nThis property controls the maximum amount of time that a connection will be tested for aliveness.\nThis value must be less than the ``connectionTimeout``.  Lowest acceptable validation timeout is 250 ms.\n*Default: 5000*\n\n&#9203;``leakDetectionThreshold``<br/>\nThis property controls the amount of time that a connection can be out of the pool before a\nmessage is logged indicating a possible connection leak.  A value of 0 means leak detection\nis disabled.  Lowest acceptable value for enabling leak detection is 2000 (2 seconds).\n*Default: 0*\n\n&#10145;``dataSource``<br/>\nThis property is only available via programmatic configuration or IoC container. This property\nallows you to directly set the instance of the ``DataSource`` to be wrapped by the pool, rather than\nhaving HikariCP construct it via reflection.  This can be useful in some dependency injection\nframeworks. When this property is specified, the ``dataSourceClassName`` property and all\nDataSource-specific properties will be ignored.\n*Default: none*\n\n&#128292;``schema``<br/>\nThis property sets the default *schema* for databases that support the concept of schemas.\nIf this property is not specified, the default schema defined by the JDBC driver is used.\n*Default: driver default*\n\n&#10145;``threadFactory``<br/>\nThis property is only available via programmatic configuration or IoC container. This property\nallows you to set the instance of the ``java.util.concurrent.ThreadFactory`` that will be used\nfor creating all threads used by the pool. It is needed in some restricted execution environments\nwhere threads can only be created through a ``ThreadFactory`` provided by the application container.\n*Default: none*\n\n&#10145;``scheduledExecutor``<br/>\nThis property is only available via programmatic configuration or IoC container. This property\nallows you to set the instance of the ``java.util.concurrent.ScheduledExecutorService`` that will\nbe used for various internally scheduled tasks.  If supplying HikariCP with a ``ScheduledThreadPoolExecutor``\ninstance, it is recommended that ``setRemoveOnCancelPolicy(true)`` is used.\n*Default: none*\n\n&#10145;``exceptionOverride``<br/>\nThis property is only available via programmatic configuration or IoC container. This property\nallows you to set an instance of a class, implementing the ``com.zaxxer.hikari.SQLExceptionOverride``\ninterface, that will be called before a connection is evicted from the pool due to specific exception\nconditions. Typically, when a ``SQLException`` is thrown, connections are evicted from the pool when\nspecific *SQLStates* or *ErrorCodes* are present. The ``adjudicate()`` method will be called on the\n``SQLExceptionOverride`` instance, which may return one of: ``Override.CONTINUE_EVICT``.\n``Override.DO_NOT_EVICT`` or ``Override.MUST_EVICT``. Except in very specific cases\n``Override.CONTINUE_EVICT`` should be returned, allowing the default evict/no-evict logic to execute.\n*Default: none*\n\n&#128292;``exceptionOverrideClassName``<br/>\nThis property allows you to specify the name of a user-supplied class implementing the\n``com.zaxxer.hikari.SQLExceptionOverride`` interface. An instance of the class will be instantiated\nby the pool to adjudicate connection evictions. See the above property ``exceptionOverride`` for a\nfull description.\n*Default: none*\n\n----------------------------------------------------\n\n#### Missing Knobs\n\nHikariCP has plenty of \"knobs\" to turn as you can see above, but comparatively less than some other pools.\nThis is a design philosophy.  The HikariCP design aesthetic is Minimalism.  In keeping with the\n*simple is better* or *less is more* design philosophy, some configuration axis are intentionally left out.\n\n#### Statement Cache\n\nMany connection pools, including Apache DBCP, Vibur, c3p0 and others offer ``PreparedStatement`` caching.\nHikariCP does not.  Why?\n\nAt the connection pool layer ``PreparedStatements`` can only be cached *per connection*.  If your application\nhas 250 commonly executed queries and a pool of 20 connections you are asking your database to hold on to\n5000 query execution plans -- and similarly the pool must cache this many ``PreparedStatements`` and their\nrelated graph of objects.\n\nMost major database JDBC drivers already have a Statement cache that can be configured, including PostgreSQL,\nOracle, Derby, MySQL, DB2, and many others.  JDBC drivers are in a unique position to exploit database specific\nfeatures, and nearly all of the caching implementations are capable of sharing execution plans *across connections*.\nThis means that instead of 5000 statements in memory and associated execution plans, your 250 commonly executed\nqueries result in exactly 250 execution plans in the database.  Clever implementations do not even retain\n``PreparedStatement`` objects in memory at the driver-level but instead merely attach new instances to existing plan IDs.\n\nUsing a statement cache at the pooling layer is an [anti-pattern](https://en.wikipedia.org/wiki/Anti-pattern),\nand will negatively impact your application performance compared to driver-provided caches.\n\n#### Log Statement Text / Slow Query Logging\n\nLike Statement caching, most major database vendors support statement logging through\nproperties of their own driver.  This includes Oracle, MySQL, Derby, MSSQL, and others.  Some\neven support slow query logging.  For those few databases that do not support it, several options are available.\nWe have received [a report that p6spy works well](https://github.com/brettwooldridge/HikariCP/issues/57#issuecomment-354647631),\nand also note the availability of [log4jdbc](https://github.com/arthurblake/log4jdbc) and [jdbcdslog-exp](https://code.google.com/p/jdbcdslog-exp/).\n\n#### Rapid Recovery\nPlease read the [Rapid Recovery Guide](https://github.com/brettwooldridge/HikariCP/wiki/Rapid-Recovery) for details on how to configure your driver and system for proper recovery from database restart and network partition events.\n\n----------------------------------------------------\n\n### :see_no_evil: Secret Properties\n\nHikariCP has several Java system properties that control various aspects of the pool. These properties are *completely unsupported*\nfor user manipulation. It is possible though unlikely that they may not exist in the future. This means: do not even think of opening\nan issue of any kind if you have modified these properties. You have been warned. *In fact, pretend you never heard anything about\n\"secret properties\".*\n\n| Property                                      | Description                                                                                                                                                                                                                                       |\n|:----------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| ``com.zaxxer.hikari.blockUntilFilled``        | When this property is set ``true`` *and* ``initializationFailTimeout`` is greater than 1, the pool will block during start until completely filled.                                                                                               |\n| ``com.zaxxer.hikari.enableRequestBoundaries`` | When this property is set ``true``, HikariCP will bracket connection acquisition and return with calls to ``Connection.beginRequest()`` and ``Connection.endRequest()``.                                                                          |\n| ``com.zaxxer.hikari.housekeeping.period``     | This property controls the frequency of the housekeeping thread, represented in milliseconds. Really, don't mess with this.                                                                                                                       |\n| ``com.zaxxer.hikari.useWeakReferences``       | When this property is set ``true`` it will force HikariCP to use ``WeakReference`` objects in the ``ConcurrentBag`` internal collection ThreadLocals and prevent the use of our ``FastList`` class, all to avoid TomCat warnings during redeploy. |\n\nSeriously, either don't use these properties or take on full responsibility for the consequences.\n\n### :rocket: Initialization\n\nYou can use the ``HikariConfig`` class like so<sup>1</sup>:\n```java\nHikariConfig config = new HikariConfig();\nconfig.setJdbcUrl(\"jdbc:mysql://localhost:3306/simpsons\");\nconfig.setUsername(\"bart\");\nconfig.setPassword(\"51mp50n\");\nconfig.addDataSourceProperty(\"cachePrepStmts\", \"true\");\nconfig.addDataSourceProperty(\"prepStmtCacheSize\", \"250\");\nconfig.addDataSourceProperty(\"prepStmtCacheSqlLimit\", \"2048\");\n\nHikariDataSource ds = new HikariDataSource(config);\n```\n&nbsp;<sup><sup>1</sup> MySQL-specific example, DO NOT COPY VERBATIM.</sup>\n\nor directly instantiate a ``HikariDataSource`` like so:\n```java\nHikariDataSource ds = new HikariDataSource();\nds.setJdbcUrl(\"jdbc:mysql://localhost:3306/simpsons\");\nds.setUsername(\"bart\");\nds.setPassword(\"51mp50n\");\n...\n```\nor property file based:\n```java\n// Examines both filesystem and classpath for .properties file\nHikariConfig config = new HikariConfig(\"/some/path/hikari.properties\");\nHikariDataSource ds = new HikariDataSource(config);\n```\nExample property file:\n```ini\ndataSourceClassName=org.postgresql.ds.PGSimpleDataSource\ndataSource.user=test\ndataSource.password=test\ndataSource.databaseName=mydb\ndataSource.portNumber=5432\ndataSource.serverName=localhost\n```\nor ``java.util.Properties`` based:\n```java\nProperties props = new Properties();\nprops.setProperty(\"dataSourceClassName\", \"org.postgresql.ds.PGSimpleDataSource\");\nprops.setProperty(\"dataSource.user\", \"test\");\nprops.setProperty(\"dataSource.password\", \"test\");\nprops.setProperty(\"dataSource.databaseName\", \"mydb\");\nprops.put(\"dataSource.logWriter\", new PrintWriter(System.out));\n\nHikariConfig config = new HikariConfig(props);\nHikariDataSource ds = new HikariDataSource(config);\n```\n\nThere is also a System property available, ``hikaricp.configurationFile``, that can be used to specify the\nlocation of a properties file.  If you intend to use this option, construct a ``HikariConfig`` or ``HikariDataSource``\ninstance using the default constructor and the properties file will be loaded.\n\n### Performance Tips\n[MySQL Performance Tips](https://github.com/brettwooldridge/HikariCP/wiki/MySQL-Configuration)\n\n### Popular DataSource Class Names\n\nWe recommended using ``dataSourceClassName`` instead of ``jdbcUrl``, but either is acceptable.  We'll say that again, *either is acceptable*.\n\n&#9888;&nbsp;*Note: Spring Boot auto-configuration users, you need to use ``jdbcUrl``-based configuration.*\n\n&#9888;&nbsp;The MySQL DataSource is known to be broken with respect to network timeout support. Use ``jdbcUrl`` configuration instead.\n\nHere is a list of JDBC *DataSource* classes for popular databases:\n\n| Database         | Driver       | *DataSource* class |\n|:---------------- |:------------ |:-------------------|\n| Apache Derby     | Derby        | org.apache.derby.jdbc.ClientDataSource |\n| Firebird         | Jaybird      | org.firebirdsql.ds.FBSimpleDataSource |\n| Google Spanner   | Spanner      | com.google.cloud.spanner.jdbc.JdbcDriver |\n| H2               | H2           | org.h2.jdbcx.JdbcDataSource |\n| HSQLDB           | HSQLDB       | org.hsqldb.jdbc.JDBCDataSource |\n| IBM DB2          | IBM JCC      | com.ibm.db2.jcc.DB2SimpleDataSource |\n| IBM Informix     | IBM Informix | com.informix.jdbcx.IfxDataSource |\n| MS SQL Server    | Microsoft    | com.microsoft.sqlserver.jdbc.SQLServerDataSource |\n| ~~MySQL~~        | Connector/J  | ~~com.mysql.jdbc.jdbc2.optional.MysqlDataSource~~ |\n| MariaDB          | MariaDB      | org.mariadb.jdbc.MariaDbDataSource |\n| Oracle           | Oracle       | oracle.jdbc.pool.OracleDataSource |\n| OrientDB         | OrientDB     | com.orientechnologies.orient.jdbc.OrientDataSource |\n| PostgreSQL       | pgjdbc-ng    | com.impossibl.postgres.jdbc.PGDataSource |\n| PostgreSQL       | PostgreSQL   | org.postgresql.ds.PGSimpleDataSource |\n| SAP MaxDB        | SAP          | com.sap.dbtech.jdbc.DriverSapDB |\n| SQLite           | xerial       | org.sqlite.SQLiteDataSource |\n| SyBase           | jConnect     | com.sybase.jdbc4.jdbc.SybDataSource |\n\n### Play Framework Plugin\n\nNote Play 2.4 now uses HikariCP by default.  A new plugin has come up for the the Play framework; [play-hikaricp](http://edulify.github.io/play-hikaricp.edulify.com/).  If you're using the excellent Play framework,  your application deserves HikariCP.  Thanks Edulify Team!\n\n### Clojure Wrapper\n\nA new Clojure wrapper has been created by [tomekw](https://github.com/tomekw) and can be [found here](https://github.com/tomekw/hikari-cp).\n\n### JRuby Wrapper\n\nA new JRuby wrapper has been created by [tomekw](https://github.com/tomekw) and can be [found here](https://github.com/tomekw/hucpa).\n\n----------------------------------------------------\n\n### Support <sup><sup>&#128172;</sup></sup>\n\nGoogle discussion group [HikariCP here](https://groups.google.com/d/forum/hikari-cp), growing [FAQ](https://github.com/brettwooldridge/HikariCP/wiki/FAQ).\n\n[![](https://raw.github.com/wiki/brettwooldridge/HikariCP/twitter.png)](https://twitter.com/share?text=Interesting%20JDBC%20Connection%20Pool&hashtags=HikariCP&url=https%3A%2F%2Fgithub.com%2Fbrettwooldridge%2FHikariCP)&nbsp;[![](https://raw.github.com/wiki/brettwooldridge/HikariCP/facebook.png)](http://www.facebook.com/plugins/like.php?href=https%3A%2F%2Fgithub.com%2Fbrettwooldridge%2FHikariCP&width&layout=standard&action=recommend&show_faces=true&share=false&height=80)\n\n### Wiki\n\nDon't forget the [Wiki](https://github.com/brettwooldridge/HikariCP/wiki) for additional information such as:\n * [FAQ](https://github.com/brettwooldridge/HikariCP/wiki/FAQ)\n * [Hibernate 4.x Configuration](https://github.com/brettwooldridge/HikariCP/wiki/Hibernate4)\n * [MySQL Configuration Tips](https://github.com/brettwooldridge/HikariCP/wiki/MySQL-Configuration)\n * etc.\n\n----------------------------------------------------\n\n### Requirements\n\n &#8658; Java 11+ (Java 6/7/8 artifacts are in maintenance mode)<br/>\n &#8658; slf4j library<br/>\n\n### Sponsors\nHigh-performance projects can never have too many tools!  We would like to thank the following companies:\n\nThanks to [ej-technologies](https://www.ej-technologies.com) for their excellent all-in-one profiler, [JProfiler](https://www.ej-technologies.com/products/jprofiler/overview.html).\n\nYourKit supports open source projects with its full-featured Java Profiler.  Click the YourKit logo below to learn more.<br/>\n[![](https://github.com/brettwooldridge/HikariCP/wiki/yklogo.png)](http://www.yourkit.com/java/profiler/index.jsp)<br/>\n\n\n### Contributions\n\nPlease perform changes and submit pull requests from the ``dev`` branch instead of ``master``.  Please set your editor to use spaces instead of tabs, and adhere to the apparent style of the code you are editing.  The ``dev`` branch is always more \"current\" than the ``master`` if you are looking to live life on the edge.\n\n[Build Status]:https://circleci.com/gh/brettwooldridge/HikariCP\n[Build Status img]:https://circleci.com/gh/brettwooldridge/HikariCP/tree/dev.svg?style=shield\n\n[Coverage Status]:https://codecov.io/gh/brettwooldridge/HikariCP\n[Coverage Status img]:https://codecov.io/gh/brettwooldridge/HikariCP/branch/dev/graph/badge.svg\n\n[license]:LICENSE\n[license img]:https://img.shields.io/badge/license-Apache%202-blue.svg\n\n[Maven Central]:https://maven-badges.herokuapp.com/maven-central/com.zaxxer/HikariCP\n[Maven Central img]:https://maven-badges.herokuapp.com/maven-central/com.zaxxer/HikariCP/badge.svg\n\n[Javadocs]:http://javadoc.io/doc/com.zaxxer/HikariCP\n[Javadocs img]:http://javadoc.io/badge/com.zaxxer/HikariCP.svg\n\n[Librapay]:https://liberapay.com/brettwooldridge\n[Librapay img]:https://img.shields.io/liberapay/patrons/brettwooldridge.svg?logo=liberapay\n"
        },
        {
          "name": "codecov.yml",
          "type": "blob",
          "size": 0.3662109375,
          "content": "codecov:\n  notify:\n    require_ci_to_pass: yes\n\ncoverage:\n  precision: 2\n  round: down\n  range: \"50..80\"\n\n  status:\n    project: yes\n    patch: yes\n    changes: no\n\nparsers:\n  gcov:\n    branch_detection:\n      conditional: yes\n      loop: yes\n      method: no\n      macro: no\n\ncomment:\n  layout: \"reach, diff, flags, files, footer\"\n  behavior: default\n  require_changes: no\n\n"
        },
        {
          "name": "documents",
          "type": "tree",
          "content": null
        },
        {
          "name": "install-jdk.sh",
          "type": "blob",
          "size": 9.763671875,
          "content": "#!/usr/bin/env bash\n\n#\n# Install JDK for Linux and Mac OS\n#\n# This script determines the most recent early-access build number,\n# downloads the JDK archive to the user home directory and extracts\n# it there.\n#\n# Exported environment variables (when sourcing this script)\n#\n#   JAVA_HOME is set to the extracted JDK directory\n#   PATH is prepended with ${JAVA_HOME}/bin\n#\n# (C) 2020 Christian Stein\n#\n# https://github.com/sormuras/bach/blob/master/install-jdk.sh\n#\n\nset -o errexit\n#set -o nounset # https://github.com/travis-ci/travis-ci/issues/5434\n#set -o xtrace\n\nfunction initialize() {\n    readonly script_name=\"$(basename \"${BASH_SOURCE[0]}\")\"\n    readonly script_version='2020-03-17'\n\n    dry=false\n    silent=false\n    verbose=false\n    emit_java_home=false\n\n    feature='ea'\n    license='GPL' # Force GPLv2+CE\n    os='?'\n    url='?'\n    workspace=\"${HOME}\"\n    target='?'\n    cacerts=false\n}\n\nfunction usage() {\ncat << EOF\nUsage: ${script_name} [OPTION]...\nDownload and extract latest-and-greatest JDK from https://jdk.java.net\n\nVersion: ${script_version}\nOptions:\n  -h|--help                 Displays this help\n  -d|--dry-run              Activates dry-run mode\n  -s|--silent               Displays no output\n  -e|--emit-java-home       Print value of \"JAVA_HOME\" to stdout (ignores silent mode)\n  -v|--verbose              Displays verbose output\n\n  -f|--feature 11|12|...|ea JDK feature release number, defaults to \"ea\"\n  -o|--os linux-x64|osx-x64 Operating system identifier\n  -u|--url \"https://...\"    Use custom JDK archive (provided as .tar.gz file)\n  -w|--workspace PATH       Working directory defaults to \\${HOME} [${HOME}]\n  -t|--target PATH          Target directory, defaults to first component of the tarball\n  -c|--cacerts              Link system CA certificates (currently only Debian/Ubuntu is supported)\nEOF\n}\n\nfunction script_exit() {\n    if [[ $# -eq 1 ]]; then\n        printf '%s\\n' \"$1\"\n        exit 0\n    fi\n\n    if [[ $# -eq 2 && $2 =~ ^[0-9]+$ ]]; then\n        printf '%b\\n' \"$1\"\n        exit \"$2\"\n    fi\n\n    script_exit 'Invalid arguments passed to script_exit()!' 2\n}\n\nfunction say() {\n    if [[ ${silent} != true ]]; then\n        echo \"$@\"\n    fi\n}\n\nfunction verbose() {\n    if [[ ${verbose} == true ]]; then\n        echo \"$@\"\n    fi\n}\n\nfunction parse_options() {\n    local option\n    while [[ $# -gt 0 ]]; do\n        option=\"$1\"\n        shift\n        case ${option} in\n            -h|-H|--help)\n                usage\n                exit 0\n                ;;\n            -v|-V|--verbose)\n                verbose=true\n                ;;\n            -s|-S|--silent)\n                silent=true\n                verbose \"Silent mode activated\"\n                ;;\n            -d|-D|--dry-run)\n                dry=true\n                verbose \"Dry-run mode activated\"\n                ;;\n            -e|-E|--emit-java-home)\n                emit_java_home=true\n                verbose \"Emitting JAVA_HOME\"\n                ;;\n            -f|-F|--feature)\n                feature=\"$1\"\n                verbose \"feature=${feature}\"\n                shift\n                ;;\n            -l|-L|--license)\n                # license=\"$1\"\n                say \"Ignoring license option: $1 -- using GPLv2+CE by default\"\n                verbose \"license=${license}\"\n                shift\n                ;;\n            -o|-O|--os)\n                os=\"$1\"\n                verbose \"os=${os}\"\n                shift\n                ;;\n            -u|-U|--url)\n                url=\"$1\"\n                verbose \"url=${url}\"\n                shift\n                ;;\n            -w|-W|--workspace)\n                workspace=\"$1\"\n                verbose \"workspace=${workspace}\"\n                shift\n                ;;\n            -t|-T|--target)\n                target=\"$1\"\n                verbose \"target=${target}\"\n                shift\n                ;;\n            -c|-C|--cacerts)\n                cacerts=true\n                verbose \"Linking system CA certificates\"\n                ;;\n            *)\n                script_exit \"Invalid argument was provided: ${option}\" 2\n                ;;\n        esac\n    done\n}\n\nfunction determine_latest_jdk() {\n    local number\n    local curl_result\n    local url\n\n    number=15\n    verbose \"Determine latest JDK feature release number, starting with ${number}\"\n    while [[ ${number} != 99 ]]\n    do\n      url=\"https://jdk.java.net/${number}\"\n      curl_result=$(curl -o /dev/null --silent --head --write-out %{http_code} ${url})\n      if [[ ${curl_result} -ge 400 ]]; then\n        break\n      fi\n      verbose \"  Found ${url} [${curl_result}]\"\n      latest_jdk=${number}\n      number=$[$number +1]\n    done\n\n    verbose \"Latest JDK feature release number is: ${latest_jdk}\"\n}\n\nfunction perform_sanity_checks() {\n    if [[ ${feature} == '?' ]] || [[ ${feature} == 'ea' ]]; then\n        feature=${latest_jdk}\n    fi\n    if [[ ${feature} -lt 9 ]] || [[ ${feature} -gt ${latest_jdk} ]]; then\n        script_exit \"Expected feature release number in range of 9 to ${latest_jdk}, but got: ${feature}\" 3\n    fi\n    if [[ -d \"$target\" ]]; then\n        script_exit \"Target directory must not exist, but it does: $(du -hs '${target}')\" 3\n    fi\n}\n\nfunction determine_url() {\n    local JAVA_NET=\"https://jdk.java.net/${feature}\"\n    local DOWNLOAD='https://download.java.net/java'\n\n    # An official GA build or an archived feature? Use predefined URL\n    case \"${feature}\" in\n        9) url=\"${DOWNLOAD}/GA/jdk9/9.0.4/binaries/openjdk-9.0.4_${os}_bin.tar.gz\"; return;;\n       10) url=\"${DOWNLOAD}/GA/jdk10/10.0.2/19aef61b38124481863b1413dce1855f/13/openjdk-10.0.2_${os}_bin.tar.gz\"; return;;\n       11) url=\"${DOWNLOAD}/GA/jdk11/9/GPL/openjdk-11.0.2_${os}_bin.tar.gz\"; return;;\n       12) url=\"${DOWNLOAD}/GA/jdk12.0.2/e482c34c86bd4bf8b56c0b35558996b9/10/GPL/openjdk-12.0.2_${os}_bin.tar.gz\"; return;;\n       13) url=\"${DOWNLOAD}/GA/jdk13.0.2/d4173c853231432d94f001e99d882ca7/8/GPL/openjdk-13.0.2_${os}_bin.tar.gz\"; return;;\n       14) url=\"${DOWNLOAD}/GA/jdk14/076bab302c7b4508975440c56f6cc26a/36/GPL/openjdk-14_${os}_bin.tar.gz\"; return;;\n    #  15) is still available from its EA/RC location determined below\n    esac\n\n    # EA or RC build? Grab URL from HTML source of jdk.java.net/${feature}\n    local candidates=$(wget --quiet --output-document - ${JAVA_NET} | grep -Eo 'href[[:space:]]*=[[:space:]]*\"[^\\\"]+\"' | grep -Eo '(http|https)://[^\"]+')\n    url=$(echo \"${candidates}\" | grep -Eo \"${DOWNLOAD}/.+/jdk${feature}/.*${license}/.*jdk-${feature}.+${os}_bin(.tar.gz|.zip)$\" || true)\n\n    if [[ -z ${url} ]]; then\n        script_exit \"Couldn't determine a download url for ${feature}-${license} on ${os}\" 1\n    fi\n}\n\nfunction prepare_variables() {\n    if [[ ${os} == '?' ]]; then\n        if [[ \"$OSTYPE\" == \"darwin\"* ]]; then\n          os='osx-x64'\n        else\n          os='linux-x64'\n        fi\n    fi\n    if [[ ${url} == '?' ]]; then\n        determine_latest_jdk\n        perform_sanity_checks\n        determine_url\n    else\n        feature='<overridden by custom url>'\n        license='<overridden by custom url>'\n        os='<overridden by custom url>'\n    fi\n    status=$(curl -o /dev/null --silent --head --write-out %{http_code} ${url})\n}\n\nfunction print_variables() {\ncat << EOF\nVariables:\n  feature = ${feature}\n       os = ${os}\n      url = ${url}\n   status = ${status}\nEOF\n}\n\nfunction download_and_extract_and_set_target() {\n    local quiet='--quiet'; if [[ ${verbose} == true ]]; then quiet=''; fi\n    local local=\"--directory-prefix ${workspace} --output-document=jdk.tar.gz\"\n    local remote='--timestamping --continue'\n    local wget_options=\"${quiet} ${local} ${remote}\"\n    local tar_options=\"--file jdk.tar.gz\"\n\n    say \"Downloading JDK from ${url}...\"\n    verbose \"Using wget options: ${wget_options}\"\n    wget ${wget_options} ${url}\n\n    if [[ ${os} == 'windows-x64' ]]; then\n        script_exit \"Extracting archives on Windows isn't supported, yet\" 4\n    fi\n\n    verbose \"Using tar options: ${tar_options}\"\n    if [[ ${target} == '?' ]]; then\n        tar --extract ${tar_options} -C \"${workspace}\"\n        if [[ \"$OSTYPE\" != \"darwin\"* ]]; then\n            target=\"${workspace}\"/$(tar --list ${tar_options} | grep 'bin/javac' | tr '/' '\\n' | tail -3 | head -1)\n        else\n            target=\"${workspace}\"/$(tar --list ${tar_options} | head -2 | tail -1 | cut -f 2 -d '/' -)/Contents/Home\n        fi\n        verbose \"Set target to: ${target}\"\n    else\n        echo \"Using custom target: ${target}\"\n        if [[ \"$OSTYPE\" != \"darwin\"* ]]; then\n            mkdir --parents \"${target}\"\n            tar --extract ${tar_options} -C \"${target}\" --strip-components=1\n        else\n            mkdir -p \"${target}\"\n            tar --extract ${tar_options} -C \"${target}\" --strip-components=4\n        fi\n    fi\n\n    if [[ ${verbose} == true ]]; then\n        echo \"Content of target directory:\"\n        ls \"${target}\"\n        echo \"Content of release file:\"\n        [[ ! -f \"${target}/release\" ]] || cat \"${target}/release\"\n    fi\n\n    # Link to system certificates\n    # https://openjdk.java.net/jeps/319\n    # https://bugs.openjdk.java.net/browse/JDK-8196141\n    if [[ ${cacerts} == true ]]; then\n        local directory=\"${target}/lib/security/cacerts\"\n        if [[ -f \"${directory}\" ]]; then\n            mv \"${directory}\" \"${directory}.jdk\"\n            ln -s /etc/ssl/certs/java/cacerts \"${directory}\"\n        else\n            verbose \"Directory ${directory} doesn't exist, didn't link system CA certificates.\"\n        fi\n    fi\n}\n\nfunction main() {\n    initialize\n    parse_options \"$@\"\n\n    say \"$script_name $script_version\"\n    prepare_variables\n\n    if [[ ${silent} == false ]]; then print_variables; fi\n    if [[ ${dry} == true ]]; then exit 0; fi\n\n    download_and_extract_and_set_target\n\n    export JAVA_HOME=$(cd \"${target}\"; pwd)\n    export PATH=${JAVA_HOME}/bin:$PATH\n\n    if [[ ${silent} == false ]]; then java -Xmx100m -version; fi\n    if [[ ${emit_java_home} == true ]]; then echo \"${JAVA_HOME}\"; fi\n}\n\nmain \"$@\"\n"
        },
        {
          "name": "logo.png",
          "type": "blob",
          "size": 8.4931640625,
          "content": null
        },
        {
          "name": "osx-toolchains.xml",
          "type": "blob",
          "size": 0.34375,
          "content": "<?xml version=\"1.0\" encoding=\"UTF8\"?>\n<toolchains>\n   <toolchain>\n      <type>paths</type>\n      <provides>\n         <id>java</id>\n      </provides>\n      <configuration>\n         <paths>\n            <path>/Library/Java/JavaVirtualMachines/jdk-11.0.11.jdk/Contents/Home/bin</path>\n         </paths>\n      </configuration>\n   </toolchain>\n</toolchains>\n"
        },
        {
          "name": "pom.xml",
          "type": "blob",
          "size": 26.958984375,
          "content": "<!--\n   Copyright (C) 2013, 2014 Brett Wooldridge\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n-->\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n   <modelVersion>4.0.0</modelVersion>\n\n   <properties>\n      <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n      <sureFireOptions11>--add-modules=ALL-MODULE-PATH</sureFireOptions11>\n      <sureFireForks11>false</sureFireForks11>\n      <!--java11.sourceDirectory>${project.basedir}/src/main/java11</java11.sourceDirectory -->\n      <!--java11.build.outputDirectory>${project.build.directory}/classes-java11</java11.build.outputDirectory -->\n      <artifact.classifier />\n\n      <!-- When releasing a new version, this property controls whether the staged artifacts will be automatically\n           released in Nexus. If this is set to false (-DautoReleaseStagedArtifacts=false), artifacts will need to\n           be manually released via the Nexus UI at https://oss.sonatype.org -->\n      <autoReleaseStagedArtifacts>true</autoReleaseStagedArtifacts>\n\n      <docker.maven.plugin.fabric8.version>0.45.0</docker.maven.plugin.fabric8.version>\n      <felix.bundle.plugin.version>5.1.1</felix.bundle.plugin.version>\n      <felix.version>7.0.5</felix.version>\n      <hibernate.version>5.4.24.Final</hibernate.version>\n      <javassist.version>3.29.2-GA</javassist.version>\n      <jndi.version>0.11.4.1</jndi.version>\n      <maven.release.version>3.0.1</maven.release.version>\n      <metrics.version>3.2.5</metrics.version>\n      <metrics5.version>5.0.0-rc17</metrics5.version>\n      <micrometer.version>1.5.10</micrometer.version>\n      <simpleclient.version>0.16.0</simpleclient.version>\n      <mockito.version>3.7.7</mockito.version>\n      <pax.exam.version>4.13.5</pax.exam.version>\n      <pax.url.version>2.5.4</pax.url.version>\n      <postgresql.version>42.7.4</postgresql.version>\n      <log4j.version>2.18.0</log4j.version>\n      <slf4j.version>1.7.36</slf4j.version>\n      <commons.csv.version>1.12.0</commons.csv.version>\n      <h2.version>2.3.232</h2.version>\n      <junit.version>4.13.2</junit.version>\n      <testcontainers.version>1.20.3</testcontainers.version>\n   </properties>\n\n   <groupId>com.zaxxer</groupId>\n   <artifactId>HikariCP</artifactId>\n   <version>6.2.2-SNAPSHOT</version>\n   <packaging>bundle</packaging>\n\n   <name>HikariCP</name>\n   <description>Ultimate JDBC Connection Pool</description>\n   <url>https://github.com/brettwooldridge/HikariCP</url>\n\n   <organization>\n      <name>Zaxxer.com</name>\n      <url>https://github.com/brettwooldridge</url>\n   </organization>\n\n   <scm>\n      <connection>scm:git:https://github.com/brettwooldridge/HikariCP.git</connection>\n      <developerConnection>scm:git:https://github.com/brettwooldridge/HikariCP.git</developerConnection>\n      <url>https://github.com/brettwooldridge/HikariCP</url>\n      <tag>HEAD</tag>\n   </scm>\n\n   <distributionManagement>\n      <snapshotRepository>\n         <id>ossrh</id>\n         <url>https://oss.sonatype.org/content/repositories/snapshots</url>\n      </snapshotRepository>\n   </distributionManagement>\n\n   <issueManagement>\n      <url>https://github.com/brettwooldridge/HikariCP/issues</url>\n   </issueManagement>\n\n   <licenses>\n      <license>\n         <name>The Apache Software License, Version 2.0</name>\n         <url>https://www.apache.org/licenses/LICENSE-2.0.txt</url>\n         <distribution>repo</distribution>\n      </license>\n   </licenses>\n\n   <developers>\n      <developer>\n         <name>Brett Wooldridge</name>\n         <email>brett.wooldridge@gmail.com</email>\n      </developer>\n   </developers>\n\n   <dependencies>\n      <dependency>\n         <groupId>org.slf4j</groupId>\n         <artifactId>slf4j-api</artifactId>\n         <version>${slf4j.version}</version>\n      </dependency>\n      <dependency>\n         <groupId>org.apache.logging.log4j</groupId>\n         <artifactId>log4j-api</artifactId>\n         <version>${log4j.version}</version>\n         <scope>test</scope>\n      </dependency>\n      <dependency>\n         <groupId>org.apache.logging.log4j</groupId>\n         <artifactId>log4j-core</artifactId>\n         <version>${log4j.version}</version>\n         <scope>test</scope>\n      </dependency>\n      <dependency>\n         <groupId>org.testcontainers</groupId>\n         <artifactId>postgresql</artifactId>\n         <version>${testcontainers.version}</version>\n         <scope>test</scope>\n      </dependency>\n      <dependency>\n         <groupId>org.apache.commons</groupId>\n         <artifactId>commons-compress</artifactId>\n         <version>[1.26.0,)</version>\n         <scope>test</scope>\n      </dependency>\n      <dependency>\n         <groupId>org.apache.commons</groupId>\n         <artifactId>commons-csv</artifactId>\n         <version>${commons.csv.version}</version>\n         <scope>test</scope>\n      </dependency>\n      <dependency>\n         <groupId>org.mockito</groupId>\n         <artifactId>mockito-core</artifactId>\n         <version>${mockito.version}</version>\n         <scope>test</scope>\n         <exclusions>\n            <exclusion>\n               <groupId>org.hamcrest</groupId>\n               <artifactId>hamcrest-core</artifactId>\n            </exclusion>\n         </exclusions>\n      </dependency>\n      <dependency>\n         <groupId>junit</groupId>\n         <artifactId>junit</artifactId>\n         <version>${junit.version}</version>\n         <scope>test</scope>\n      </dependency>\n      <dependency>\n         <groupId>org.javassist</groupId>\n         <artifactId>javassist</artifactId>\n         <version>${javassist.version}</version>\n         <optional>true</optional>\n      </dependency>\n      <dependency>\n         <groupId>io.micrometer</groupId>\n         <artifactId>micrometer-core</artifactId>\n         <version>${micrometer.version}</version>\n         <optional>true</optional>\n      </dependency>\n      <dependency>\n         <groupId>org.postgresql</groupId>\n         <artifactId>postgresql</artifactId>\n         <version>${postgresql.version}</version>\n         <scope>test</scope>\n      </dependency>\n      <dependency>\n         <groupId>org.hibernate</groupId>\n         <artifactId>hibernate-core</artifactId>\n         <version>${hibernate.version}</version>\n         <scope>provided</scope>\n         <optional>true</optional>\n         <exclusions>\n            <exclusion>\n               <artifactId>jboss-logging</artifactId>\n               <groupId>org.jboss.logging</groupId>\n            </exclusion>\n            <exclusion>\n               <artifactId>jboss-logging-annotations</artifactId>\n               <groupId>org.jboss.logging</groupId>\n            </exclusion>\n         </exclusions>\n      </dependency>\n      <dependency>\n         <groupId>io.dropwizard.metrics</groupId>\n         <artifactId>metrics-core</artifactId>\n         <version>${metrics.version}</version>\n         <scope>provided</scope>\n         <optional>true</optional>\n      </dependency>\n      <dependency>\n         <groupId>io.dropwizard.metrics</groupId>\n         <artifactId>metrics-healthchecks</artifactId>\n         <version>${metrics.version}</version>\n         <scope>provided</scope>\n         <optional>true</optional>\n      </dependency>\n      <dependency>\n         <groupId>io.dropwizard.metrics5</groupId>\n         <artifactId>metrics-core</artifactId>\n         <version>${metrics5.version}</version>\n         <scope>provided</scope>\n         <optional>true</optional>\n      </dependency>\n      <dependency>\n         <groupId>io.prometheus</groupId>\n         <artifactId>simpleclient</artifactId>\n         <version>${simpleclient.version}</version>\n         <scope>provided</scope>\n         <optional>true</optional>\n      </dependency>\n      <dependency>\n         <groupId>simple-jndi</groupId>\n         <artifactId>simple-jndi</artifactId>\n         <version>${jndi.version}</version>\n         <scope>test</scope>\n      </dependency>\n      <dependency>\n         <groupId>org.apache.logging.log4j</groupId>\n         <artifactId>log4j-slf4j-impl</artifactId>\n         <version>${log4j.version}</version>\n         <scope>test</scope>\n      </dependency>\n\n      <!-- OSGi test -->\n      <dependency>\n         <groupId>javax.inject</groupId>\n         <artifactId>javax.inject</artifactId>\n         <version>1</version>\n         <scope>test</scope>\n      </dependency>\n      <dependency>\n         <groupId>org.apache.felix</groupId>\n         <artifactId>org.apache.felix.framework</artifactId>\n         <version>${felix.version}</version>\n         <scope>test</scope>\n      </dependency>\n      <dependency>\n         <groupId>org.ops4j.pax.exam</groupId>\n         <artifactId>pax-exam-container-native</artifactId>\n         <version>${pax.exam.version}</version>\n         <scope>test</scope>\n      </dependency>\n      <dependency>\n         <groupId>org.ops4j.pax.exam</groupId>\n         <artifactId>pax-exam-junit4</artifactId>\n         <version>${pax.exam.version}</version>\n         <scope>test</scope>\n      </dependency>\n      <dependency>\n         <groupId>org.ops4j.pax.exam</groupId>\n         <artifactId>pax-exam-link-assembly</artifactId>\n         <version>${pax.exam.version}</version>\n         <scope>test</scope>\n      </dependency>\n      <dependency>\n         <groupId>org.ops4j.pax.exam</groupId>\n         <artifactId>pax-exam-link-mvn</artifactId>\n         <version>${pax.exam.version}</version>\n         <scope>test</scope>\n      </dependency>\n      <dependency>\n         <groupId>org.ops4j.pax.url</groupId>\n         <artifactId>pax-url-aether</artifactId>\n         <version>${pax.url.version}</version>\n         <scope>test</scope>\n      </dependency>\n      <dependency>\n         <groupId>org.ops4j.pax.url</groupId>\n         <artifactId>pax-url-reference</artifactId>\n         <version>${pax.url.version}</version>\n         <scope>test</scope>\n      </dependency>\n      <dependency>\n         <groupId>com.h2database</groupId>\n         <artifactId>h2</artifactId>\n         <version>${h2.version}</version>\n         <scope>test</scope>\n      </dependency>\n   </dependencies>\n\n   <build>\n      <resources>\n         <resource>\n            <directory>target/classes</directory>\n         </resource>\n      </resources>\n\n      <pluginManagement>\n         <plugins>\n            <plugin>\n               <groupId>org.apache.maven.plugins</groupId>\n               <artifactId>maven-clean-plugin</artifactId>\n               <version>3.2.0</version>\n            </plugin>\n\n            <plugin>\n               <groupId>org.apache.maven.plugins</groupId>\n               <artifactId>maven-compiler-plugin</artifactId>\n               <version>3.10.1</version>\n               <configuration>\n                  <source>11</source>\n                  <target>11</target>\n                  <compilerArgs>-Xlint</compilerArgs>\n               </configuration>\n            </plugin>\n\n            <plugin>\n               <groupId>org.apache.maven.plugins</groupId>\n               <artifactId>maven-deploy-plugin</artifactId>\n               <version>2.8.2</version>\n            </plugin>\n\n            <plugin>\n               <groupId>org.apache.maven.plugins</groupId>\n               <artifactId>maven-gpg-plugin</artifactId>\n               <version>3.0.1</version>\n            </plugin>\n\n            <plugin>\n               <groupId>org.apache.maven.plugins</groupId>\n               <artifactId>maven-release-plugin</artifactId>\n               <version>2.5.3</version>\n            </plugin>\n\n            <plugin>\n               <groupId>org.sonatype.plugins</groupId>\n               <artifactId>nexus-staging-maven-plugin</artifactId>\n               <version>1.6.12</version>\n            </plugin>\n\n            <plugin>\n               <groupId>org.apache.maven.plugins</groupId>\n               <artifactId>maven-surefire-plugin</artifactId>\n               <version>3.0.0-M8</version>\n               <configuration>\n                  <!-- Sets the VM argument line used when unit tests are run. -->\n                  <argLine>${surefireArgLine} ${sureFireOptions11}</argLine>\n                  <reuseForks>${sureFireForks11}</reuseForks>\n               </configuration>\n            </plugin>\n\n            <plugin>\n               <groupId>org.apache.maven.plugins</groupId>\n               <artifactId>maven-source-plugin</artifactId>\n               <version>3.0.1</version>\n               <configuration>\n                  <!-- outputDirectory>/absolute/path/to/the/output/directory</outputDirectory>\n                     <finalName>filename-of-generated-jar-file</finalName -->\n                  <attach>true</attach>\n               </configuration>\n               <executions>\n                  <execution>\n                     <id>attach-sources</id>\n                     <goals>\n                        <goal>jar-no-fork</goal>\n                     </goals>\n                  </execution>\n               </executions>\n            </plugin>\n\n            <plugin>\n               <groupId>org.apache.maven.plugins</groupId>\n               <artifactId>maven-javadoc-plugin</artifactId>\n               <version>3.6.0</version>\n               <configuration>\n                  <show>public</show>\n                  <excludePackageNames>\n                     com.zaxxer.hikari.hibernate:com.zaxxer.hikari.metrics.*:com.zaxxer.hikari.pool:com.zaxxer.hikari.util\n                  </excludePackageNames>\n                  <attach>true</attach>\n                  <maxmemory>1024m</maxmemory>\n               </configuration>\n               <executions>\n                  <execution>\n                     <id>bundle-sources</id>\n                     <phase>package</phase>\n                     <goals>\n                        <goal>jar</goal>\n                     </goals>\n                  </execution>\n               </executions>\n            </plugin>\n         </plugins>\n      </pluginManagement>\n\n      <plugins>\n         <plugin>\n            <groupId>org.apache.maven.plugins</groupId>\n            <artifactId>maven-enforcer-plugin</artifactId>\n            <version>3.4.1</version>\n            <executions>\n               <execution>\n                  <id>enforce-maven</id>\n                  <goals>\n                     <goal>enforce</goal>\n                  </goals>\n                  <configuration>\n                     <rules>\n                        <requireMavenVersion>\n                           <version>(3.0.0,)</version>\n                        </requireMavenVersion>\n                     </rules>\n                  </configuration>\n               </execution>\n            </executions>\n         </plugin>\n\n         <plugin>\n            <artifactId>maven-dependency-plugin</artifactId>\n            <version>2.8</version>\n            <executions>\n               <execution>\n                  <phase>generate-sources</phase>\n                  <goals>\n                     <goal>build-classpath</goal>\n                  </goals>\n                  <configuration>\n                     <outputProperty>maven.compile.classpath</outputProperty>\n                  </configuration>\n               </execution>\n            </executions>\n         </plugin>\n\n         <plugin>\n            <!-- Generate proxies -->\n            <groupId>org.codehaus.mojo</groupId>\n            <artifactId>exec-maven-plugin</artifactId>\n            <version>1.6.0</version>\n            <extensions>true</extensions>\n            <executions>\n               <execution>\n                  <phase>compile</phase>\n                  <!-- phase>generate-test-sources</phase -->\n                  <goals>\n                     <goal>exec</goal>\n                  </goals>\n               </execution>\n            </executions>\n            <configuration>\n               <executable>java</executable>\n               <arguments>\n                  <argument>-cp</argument>\n                  <argument>${project.build.outputDirectory}${path.separator}${maven.compile.classpath}</argument>\n                  <argument>com.zaxxer.hikari.util.JavassistProxyFactory</argument>\n                  <argument>${project.basedir}</argument>\n               </arguments>\n            </configuration>\n         </plugin>\n\n         <plugin>\n            <!-- The Docker Maven plugin is used to create docker image with the fat jar -->\n            <groupId>io.fabric8</groupId>\n            <artifactId>docker-maven-plugin</artifactId>\n            <version>${docker.maven.plugin.fabric8.version}</version>\n            <configuration>\n               <logDate>default</logDate>\n               <autoPull>true</autoPull>\n               <images>\n                  <!-- Postgres Image is used 'as-is' and iked into the service s linimage -->\n                  <image>\n                     <alias>db</alias>\n                     <name>postgres:16</name>\n                     <run>\n                        <env>\n                           <POSTGRES_PASSWORD>password</POSTGRES_PASSWORD>\n                        </env>\n                        <wait>\n                           <log>database system is ready to accept connections</log>\n                           <time>20000</time>\n                        </wait>\n                        <log>\n                           <prefix>DB</prefix>\n                           <color>yellow</color>\n                        </log>\n                     </run>\n                  </image>\n               </images>\n            </configuration>\n\n            <!-- Hooking into the lifecycle -->\n            <executions>\n               <execution>\n                  <id>start</id>\n                  <phase>pre-integration-test</phase>\n                  <goals>\n                     <goal>build</goal>\n                     <goal>start</goal>\n                  </goals>\n               </execution>\n               <execution>\n                  <id>stop</id>\n                  <phase>post-integration-test</phase>\n                  <goals>\n                     <goal>stop</goal>\n                  </goals>\n               </execution>\n            </executions>\n         </plugin>\n\n         <plugin>\n            <groupId>org.jacoco</groupId>\n            <artifactId>jacoco-maven-plugin</artifactId>\n            <version>0.8.8</version>\n            <executions>\n               <!-- Prepares the property pointing to the JaCoCo runtime agent which is passed as VM argument when Maven the Surefire plugin is executed. -->\n               <execution>\n                  <goals>\n                     <goal>prepare-agent</goal>\n                  </goals>\n                  <configuration>\n                     <!-- Sets the path to the file which contains the execution data. -->\n                     <destFile>${project.build.directory}/coverage-reports/jacoco.exec</destFile>\n                     <!-- Sets the name of the property containing the settings for JaCoCo runtime agent. -->\n                     <propertyName>surefireArgLine</propertyName>\n                     <excludes>\n                        <exclude>**/com/zaxxer/hikari/util/JavassistProxyFactory*</exclude>\n                        <exclude>**/com/zaxxer/hikari/pool/HikariProxy*</exclude>\n                        <exclude>**/com/zaxxer/hikari/metrics/**</exclude>\n                     </excludes>\n                  </configuration>\n               </execution>\n               <!-- Ensures that the code coverage report for unit tests is created after unit tests have been run. -->\n               <execution>\n                  <id>report</id>\n                  <phase>test</phase>\n                  <goals>\n                     <goal>report</goal>\n                  </goals>\n                  <configuration>\n                     <!-- Sets the path to the file which contains the execution data. -->\n                     <dataFile>${project.build.directory}/coverage-reports/jacoco.exec</dataFile>\n                     <excludes>\n                        <exclude>**/com/zaxxer/hikari/pool/HikariProxy*</exclude>\n                        <exclude>**/com/zaxxer/hikari/metrics/**</exclude>\n                     </excludes>\n                  </configuration>\n               </execution>\n            </executions>\n         </plugin>\n\n         <plugin>\n            <groupId>org.apache.maven.plugins</groupId>\n            <artifactId>maven-failsafe-plugin</artifactId>\n            <version>3.0.0-M3</version>\n            <executions>\n               <execution>\n                  <goals>\n                     <goal>integration-test</goal>\n                     <goal>verify</goal>\n                  </goals>\n               </execution>\n            </executions>\n         </plugin>\n\n         <plugin>\n            <groupId>org.apache.felix</groupId>\n            <artifactId>maven-bundle-plugin</artifactId>\n            <version>${felix.bundle.plugin.version}</version>\n            <extensions>true</extensions>\n            <configuration>\n               <classifier>${artifact.classifier}</classifier>\n               <instructions>\n                  <Automatic-Module-Name>${automatic.module.name}</Automatic-Module-Name>\n                  <!-- Multi-Release>true</Multi-Release-->\n                  <Bundle-Name>HikariCP</Bundle-Name>\n                  <Export-Package>\n                     com.zaxxer.hikari,\n                     com.zaxxer.hikari.hibernate,\n                     com.zaxxer.hikari.metrics,\n                     com.zaxxer.hikari.metrics.dropwizard,\n                     com.zaxxer.hikari.metrics.micrometer,\n                     com.zaxxer.hikari.metrics.prometheus\n                  </Export-Package>\n                  <Private-Package>com.zaxxer.hikari.*</Private-Package>\n                  <Include-Resource>{maven-resources}</Include-Resource>\n                  <_exportcontents>\n                     com.zaxxer.hikari.pool,\n                     com.zaxxer.hikari.util\n                  </_exportcontents>\n                  <Import-Package>\n                     javax.management,\n                     javax.naming,\n                     javax.naming.spi,\n                     javax.sql,\n                     javax.sql.rowset,\n                     javax.sql.rowset.serial,\n                     javax.sql.rowset.spi,\n                     com.codahale.metrics;resolution:=optional,\n                     com.codahale.metrics.health;resolution:=optional,\n                     io.dropwizard.metrics5;resolution:=optional,\n                     io.micrometer.core.instrument;resolution:=optional,\n                     org.slf4j;version=\"[1.6,2)\",\n                     org.hibernate;resolution:=optional,\n                     org.hibernate.cfg;resolution:=optional,\n                     org.hibernate.engine.jdbc.connections.spi;resolution:=optional,\n                     org.hibernate.service;resolution:=optional,\n                     org.hibernate.service.spi;resolution:=optional\n                  </Import-Package>\n                  <Bundle-SymbolicName>${project.groupId}.${project.artifactId}</Bundle-SymbolicName>\n                  <DynamicImport-Package>*</DynamicImport-Package>\n               </instructions>\n            </configuration>\n            <executions>\n               <!-- This execution makes sure that the manifest is available when the tests are executed -->\n               <execution>\n                  <goals>\n                     <goal>manifest</goal>\n                  </goals>\n               </execution>\n            </executions>\n         </plugin>\n      </plugins>\n   </build>\n\n   <profiles>\n      <profile>\n         <id>felix</id>\n         <activation>\n            <activeByDefault>true</activeByDefault>\n            <property>\n               <name>pax.exam.framework</name>\n               <value>felix</value>\n            </property>\n         </activation>\n         <properties>\n            <pax.exam.framework>felix</pax.exam.framework>\n            <pax.exam.logging>none</pax.exam.logging>\n         </properties>\n         <dependencies>\n            <dependency>\n               <groupId>org.apache.felix</groupId>\n               <artifactId>org.apache.felix.framework</artifactId>\n               <version>${felix.version}</version>\n               <scope>test</scope>\n            </dependency>\n         </dependencies>\n      </profile>\n\n      <profile>\n         <id>release</id>\n         <activation>\n            <property>\n               <name>performRelease</name>\n               <value>true</value>\n            </property>\n         </activation>\n         <build>\n            <plugins>\n               <plugin>\n                  <groupId>org.apache.maven.plugins</groupId>\n                  <artifactId>maven-source-plugin</artifactId>\n                  <version>3.3.0</version>\n                  <executions>\n                     <execution>\n                        <id>attach-sources</id>\n                        <goals>\n                           <goal>jar-no-fork</goal>\n                        </goals>\n                     </execution>\n                  </executions>\n               </plugin>\n\n               <plugin>\n                  <groupId>org.apache.maven.plugins</groupId>\n                  <artifactId>maven-javadoc-plugin</artifactId>\n                  <version>3.6.0</version>\n                  <executions>\n                     <execution>\n                        <id>attach-javadocs</id>\n                        <goals>\n                           <goal>jar</goal>\n                        </goals>\n                     </execution>\n                  </executions>\n               </plugin>\n\n               <!-- For release: mvn release:perform -Darguments=-Dgpg.passphrase=PASSPHRASE\n                      With gpg2 you don't need to pass the passphrase; the GPG agent will prompt for it. -->\n               <plugin>\n                  <groupId>org.apache.maven.plugins</groupId>\n                  <artifactId>maven-gpg-plugin</artifactId>\n                  <executions>\n                     <execution>\n                        <id>sign-artifacts</id>\n                        <phase>verify</phase>\n                        <goals>\n                           <goal>sign</goal>\n                        </goals>\n                     </execution>\n                  </executions>\n               </plugin>\n\n               <!-- nexus-staging-maven-plugin replaces the standard maven-deploy-plugin for releases and\n                    is useful for ensuring artifacts are all-or-nothing, as well as allowing artifacts to\n                    be reviewed before they're made public -->\n               <plugin>\n                  <groupId>org.sonatype.plugins</groupId>\n                  <artifactId>nexus-staging-maven-plugin</artifactId>\n                  <extensions>true</extensions>\n                  <configuration>\n                     <autoReleaseAfterClose>${autoReleaseStagedArtifacts}</autoReleaseAfterClose>\n                     <nexusUrl>https://oss.sonatype.org/</nexusUrl>\n                     <serverId>ossrh</serverId>\n                  </configuration>\n               </plugin>\n            </plugins>\n         </build>\n      </profile>\n   </profiles>\n</project>\n"
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}