{
  "metadata": {
    "timestamp": 1736708865556,
    "page": 72,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjgw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "apache/hadoop",
      "stars": 14880,
      "defaultBranch": "trunk",
      "files": [
        {
          "name": ".asf.yaml",
          "type": "blob",
          "size": 1.072265625,
          "content": "# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\ngithub:\n  ghp_path: /\n  ghp_branch: gh-pages\n  enabled_merge_buttons:\n    squash: true\n    merge: false\n    rebase: false\nnotifications:\n  commits:      common-commits@hadoop.apache.org\n  issues:       common-issues@hadoop.apache.org\n  pullrequests: common-issues@hadoop.apache.org\n  jira_options: comment link label"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.490234375,
          "content": "# Auto detect text files and perform LF normalization\n*        text=auto\n\n*.cs     text diff=csharp eol=lf\n*.java   text diff=java eol=lf\n*.html   text diff=html eol=lf\n*.py     text diff=python eol=lf\n*.pl     text diff=perl eol=lf\n*.pm     text diff=perl eol=lf\n*.css    text eol=lf\n*.js     text eol=lf\n*.sql    text eol=lf\n\n*.sh     text eol=lf\n\n*.bat    text eol=crlf\n*.cmd    text eol=crlf\n*.vcxproj text merge=union eol=crlf\n*.csproj text merge=union eol=crlf\n*.sln    text merge=union eol=crlf\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.9443359375,
          "content": "*.DS_Store\n*.iml\n*.ipr\n*.iws\n*.orig\n*.rej\n**/.keep\n*.sdf\n*.suo\n*.vcxproj.user\n*.patch\n*.diff\n.idea\n.vscode\n.svn\n.classpath\n.project\n.settings\ntarget\nbuild\ndependency-reduced-pom.xml\nmake-build-debug\n\n# Filesystem contract test options and credentials\nauth-keys.xml\nazure-auth-keys.xml\nazure-bfs-auth-keys.xml\n\n# External tool builders\n*/.externalToolBuilders\n*/maven-eclipse.xml\n\nhadoop-common-project/hadoop-kms/downloads/\nhadoop-hdfs-project/hadoop-hdfs/downloads\nhadoop-hdfs-project/hadoop-hdfs-httpfs/downloads\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-registry/src/main/tla/yarnregistry.toolbox\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui/src/main/webapp/dist\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui/src/main/webapp/tmp\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui/src/main/webapp/node\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui/src/main/webapp/node_modules\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui/src/main/webapp/bower_components\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui/src/main/webapp/.sass-cache\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui/src/main/webapp/connect.lock\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui/src/main/webapp/coverage/*\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui/src/main/webapp/libpeerconnection.log\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui/src/main/webapp/npm-debug.log\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui/src/main/webapp/testem.log\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui/dist\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui/tmp\nyarnregistry.pdf\npatchprocess/\n.history/\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui/src/main/webapp/package-lock.json\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-ui/src/main/webapp/yarn-error.log\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/placement/schema\nphantomjsdriver.log\n\n#robotframework outputs\nlog.html\noutput.xml\nreport.html\n\n\n.mvn\n"
        },
        {
          "name": ".yetus",
          "type": "tree",
          "content": null
        },
        {
          "name": "BUILDING.txt",
          "type": "blob",
          "size": 31.7431640625,
          "content": "Build instructions for Hadoop\n\n----------------------------------------------------------------------------------\nRequirements:\n\n* Unix System\n* JDK 1.8\n* Maven 3.3 or later\n* Boost 1.72 (if compiling native code)\n* Protocol Buffers 3.21.12 (if compiling native code)\n* CMake 3.19 or newer (if compiling native code)\n* Zlib devel (if compiling native code)\n* Cyrus SASL devel (if compiling native code)\n* One of the compilers that support thread_local storage: GCC 9.3.0 or later, Visual Studio,\n  Clang (community version), Clang (version for iOS 9 and later) (if compiling native code)\n* openssl devel (if compiling native hadoop-pipes and to get the best HDFS encryption performance)\n* Linux FUSE (Filesystem in Userspace) version 2.6 or above (if compiling fuse_dfs)\n* Doxygen ( if compiling libhdfspp and generating the documents )\n* Internet connection for first build (to fetch all Maven and Hadoop dependencies)\n* python (for releasedocs)\n* bats (for shell code testing)\n* Node.js / bower / Ember-cli (for YARN UI v2 building)\n\n----------------------------------------------------------------------------------\nThe easiest way to get an environment with all the appropriate tools is by means\nof the provided Docker config.\nThis requires a recent version of docker (1.4.1 and higher are known to work).\n\nOn Linux / Mac:\n    Install Docker and run this command:\n\n    $ ./start-build-env.sh\n\nThe prompt which is then presented is located at a mounted version of the source tree\nand all required tools for testing and building have been installed and configured.\n\nNote that from within this docker environment you ONLY have access to the Hadoop source\ntree from where you started. So if you need to run\n    dev-support/bin/test-patch /path/to/my.patch\nthen the patch must be placed inside the hadoop source tree.\n\nKnown issues:\n- On Mac with Boot2Docker the performance on the mounted directory is currently extremely slow.\n  This is a known problem related to boot2docker on the Mac.\n  See:\n    https://github.com/boot2docker/boot2docker/issues/593\n  This issue has been resolved as a duplicate, and they point to a new feature for utilizing NFS mounts\n  as the proposed solution:\n    https://github.com/boot2docker/boot2docker/issues/64\n  An alternative solution to this problem is to install Linux native inside a virtual machine\n  and run your IDE and Docker etc inside that VM.\n\n----------------------------------------------------------------------------------\nInstalling required packages for clean install of Ubuntu 18.04 LTS Desktop.\n(For Ubuntu 20.04, gcc/g++ and cmake bundled with Ubuntu can be used.\nRefer to  dev-support/docker/Dockerfile):\n\n* Open JDK 1.8\n  $ sudo apt-get update\n  $ sudo apt-get -y install openjdk-8-jdk\n* Maven\n  $ sudo apt-get -y install maven\n* Native libraries\n  $ sudo apt-get -y install build-essential autoconf automake libtool cmake zlib1g-dev pkg-config libssl-dev libsasl2-dev\n* GCC 9.3.0\n  $ sudo apt-get -y install software-properties-common\n  $ sudo add-apt-repository -y ppa:ubuntu-toolchain-r/test\n  $ sudo apt-get update\n  $ sudo apt-get -y install g++-9 gcc-9\n  $ sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-9 60 --slave /usr/bin/g++ g++ /usr/bin/g++-9\n* CMake 3.19\n  $ curl -L https://cmake.org/files/v3.19/cmake-3.19.0.tar.gz > cmake-3.19.0.tar.gz\n  $ tar -zxvf cmake-3.19.0.tar.gz && cd cmake-3.19.0\n  $ ./bootstrap\n  $ make -j$(nproc)\n  $ sudo make install\n* Protocol Buffers 3.21.12 (required to build native code)\n  $ curl -L https://github.com/protocolbuffers/protobuf/archive/refs/tags/v3.21.12.tar.gz > protobuf-3.21.12.tar.gz\n  $ tar -zxvf protobuf-3.21.12.tar.gz && cd protobuf-3.21.12\n  $ ./autogen.sh\n  $ ./configure\n  $ make -j$(nproc)\n  $ sudo make install\n* Boost\n  $ curl -L https://sourceforge.net/projects/boost/files/boost/1.72.0/boost_1_72_0.tar.bz2/download > boost_1_72_0.tar.bz2\n  $ tar --bzip2 -xf boost_1_72_0.tar.bz2 && cd boost_1_72_0\n  $ ./bootstrap.sh --prefix=/usr/\n  $ ./b2 --without-python\n  $ sudo ./b2 --without-python install\n\nOptional packages:\n\n* Snappy compression (only used for hadoop-mapreduce-client-nativetask)\n  $ sudo apt-get install libsnappy-dev\n* Intel ISA-L library for erasure coding\n  Please refer to https://01.org/intel%C2%AE-storage-acceleration-library-open-source-version\n  (OR https://github.com/01org/isa-l)\n* Bzip2\n  $ sudo apt-get install bzip2 libbz2-dev\n* Linux FUSE\n  $ sudo apt-get install fuse libfuse-dev\n* ZStandard compression\n  $ sudo apt-get install libzstd1-dev\n* PMDK library for storage class memory(SCM) as HDFS cache backend\n  Please refer to http://pmem.io/ and https://github.com/pmem/pmdk\n\n----------------------------------------------------------------------------------\nMaven main modules:\n\n  hadoop                                (Main Hadoop project)\n         - hadoop-project               (Parent POM for all Hadoop Maven modules.             )\n                                        (All plugins & dependencies versions are defined here.)\n         - hadoop-project-dist          (Parent POM for modules that generate distributions.)\n         - hadoop-annotations           (Generates the Hadoop doclet used to generate the Javadocs)\n         - hadoop-assemblies            (Maven assemblies used by the different modules)\n         - hadoop-maven-plugins         (Maven plugins used in project)\n         - hadoop-build-tools           (Build tools like checkstyle, etc.)\n         - hadoop-common-project        (Hadoop Common)\n         - hadoop-hdfs-project          (Hadoop HDFS)\n         - hadoop-yarn-project          (Hadoop YARN)\n         - hadoop-mapreduce-project     (Hadoop MapReduce)\n         - hadoop-tools                 (Hadoop tools like Streaming, Distcp, etc.)\n         - hadoop-dist                  (Hadoop distribution assembler)\n         - hadoop-client-modules        (Hadoop client modules)\n         - hadoop-minicluster           (Hadoop minicluster artifacts)\n         - hadoop-cloud-storage-project (Generates artifacts to access cloud storage like aws, azure, etc.)\n\n----------------------------------------------------------------------------------\nWhere to run Maven from?\n\n  It can be run from any module. The only catch is that if not run from trunk\n  all modules that are not part of the build run must be installed in the local\n  Maven cache or available in a Maven repository.\n\n----------------------------------------------------------------------------------\nMaven build goals:\n\n * Clean                     : mvn clean [-Preleasedocs]\n * Compile                   : mvn compile [-Pnative]\n * Run tests                 : mvn test [-Pnative] [-Pshelltest]\n * Create JAR                : mvn package\n * Run spotbugs              : mvn compile spotbugs:spotbugs\n * Run checkstyle            : mvn compile checkstyle:checkstyle\n * Install JAR in M2 cache   : mvn install\n * Deploy JAR to Maven repo  : mvn deploy\n * Run clover                : mvn test -Pclover\n * Run Rat                   : mvn apache-rat:check\n * Build javadocs            : mvn javadoc:javadoc\n * Build distribution        : mvn package [-Pdist][-Pdocs][-Psrc][-Pnative][-Dtar][-Preleasedocs][-Pyarn-ui]\n * Change Hadoop version     : mvn versions:set -DnewVersion=NEWVERSION\n\n Build options:\n\n  * Use -Pnative to compile/bundle native code\n  * Use -Pdocs to generate & bundle the documentation in the distribution (using -Pdist)\n  * Use -Psrc to create a project source TAR.GZ\n  * Use -Dtar to create a TAR with the distribution (using -Pdist)\n  * Use -Preleasedocs to include the changelog and release docs (requires Internet connectivity)\n  * Use -Pyarn-ui to build YARN UI v2. (Requires Internet connectivity)\n  * Use -DskipShade to disable client jar shading to speed up build times (in\n    development environments only, not to build release artifacts)\n\n YARN Application Timeline Service V2 build options:\n\n   YARN Timeline Service v.2 chooses Apache HBase as the primary backing storage. The supported\n   version of Apache HBase is 2.5.8.\n\n Snappy build options:\n\n   Snappy is a compression library that can be utilized by the native code.\n   It is currently an optional component, meaning that Hadoop can be built with\n   or without this dependency. Snappy library as optional dependency is only\n   used for hadoop-mapreduce-client-nativetask.\n\n  * Use -Drequire.snappy to fail the build if libsnappy.so is not found.\n    If this option is not specified and the snappy library is missing,\n    we silently build a version of libhadoop.so that cannot make use of snappy.\n    This option is recommended if you plan on making use of snappy and want\n    to get more repeatable builds.\n  * Use -Dsnappy.prefix to specify a nonstandard location for the libsnappy\n    header files and library files. You do not need this option if you have\n    installed snappy using a package manager.\n  * Use -Dsnappy.lib to specify a nonstandard location for the libsnappy library\n    files.  Similarly to snappy.prefix, you do not need this option if you have\n    installed snappy using a package manager.\n  * Use -Dbundle.snappy to copy the contents of the snappy.lib directory into\n    the final tar file. This option requires that -Dsnappy.lib is also given,\n    and it ignores the -Dsnappy.prefix option. If -Dsnappy.lib isn't given, the\n    bundling and building will fail.\n\n\n ZStandard build options:\n\n   ZStandard is a compression library that can be utilized by the native code.\n   It is currently an optional component, meaning that Hadoop can be built with\n   or without this dependency.\n\n  * Use -Drequire.zstd to fail the build if libzstd.so is not found.\n    If this option is not specified and the zstd library is missing.\n\n  * Use -Dzstd.prefix to specify a nonstandard location for the libzstd\n    header files and library files. You do not need this option if you have\n    installed zstandard using a package manager.\n\n  * Use -Dzstd.lib to specify a nonstandard location for the libzstd library\n    files.  Similarly to zstd.prefix, you do not need this option if you have\n    installed using a package manager.\n\n  * Use -Dbundle.zstd to copy the contents of the zstd.lib directory into\n    the final tar file. This option requires that -Dzstd.lib is also given,\n    and it ignores the -Dzstd.prefix option. If -Dzstd.lib isn't given, the\n    bundling and building will fail.\n\n OpenSSL build options:\n\n   OpenSSL includes a crypto library that can be utilized by the native code.\n   It is currently an optional component, meaning that Hadoop can be built with\n   or without this dependency.\n\n  * Use -Drequire.openssl to fail the build if libcrypto.so is not found.\n    If this option is not specified and the openssl library is missing,\n    we silently build a version of libhadoop.so that cannot make use of\n    openssl. This option is recommended if you plan on making use of openssl\n    and want to get more repeatable builds.\n  * Use -Dopenssl.prefix to specify a nonstandard location for the libcrypto\n    header files and library files. You do not need this option if you have\n    installed openssl using a package manager.\n  * Use -Dopenssl.lib to specify a nonstandard location for the libcrypto library\n    files. Similarly to openssl.prefix, you do not need this option if you have\n    installed openssl using a package manager.\n  * Use -Dbundle.openssl to copy the contents of the openssl.lib directory into\n    the final tar file. This option requires that -Dopenssl.lib is also given,\n    and it ignores the -Dopenssl.prefix option. If -Dopenssl.lib isn't given, the\n    bundling and building will fail.\n\n   Tests options:\n\n  * Use -DskipTests to skip tests when running the following Maven goals:\n    'package',  'install', 'deploy' or 'verify'\n  * -Dtest=<TESTCLASSNAME>,<TESTCLASSNAME#METHODNAME>,....\n  * -Dtest.exclude=<TESTCLASSNAME>\n  * -Dtest.exclude.pattern=**/<TESTCLASSNAME1>.java,**/<TESTCLASSNAME2>.java\n  * To run all native unit tests, use: mvn test -Pnative -Dtest=allNative\n  * To run a specific native unit test, use: mvn test -Pnative -Dtest=<test>\n  For example, to run test_bulk_crc32, you would use:\n  mvn test -Pnative -Dtest=test_bulk_crc32\n\n Intel ISA-L build options:\n\n   Intel ISA-L is an erasure coding library that can be utilized by the native code.\n   It is currently an optional component, meaning that Hadoop can be built with\n   or without this dependency. Note the library is used via dynamic module. Please\n   reference the official site for the library details.\n   https://01.org/intel%C2%AE-storage-acceleration-library-open-source-version\n   (OR https://github.com/01org/isa-l)\n\n  * Use -Drequire.isal to fail the build if libisal.so is not found.\n    If this option is not specified and the isal library is missing,\n    we silently build a version of libhadoop.so that cannot make use of ISA-L and\n    the native raw erasure coders.\n    This option is recommended if you plan on making use of native raw erasure\n    coders and want to get more repeatable builds.\n  * Use -Disal.prefix to specify a nonstandard location for the libisal\n    library files. You do not need this option if you have installed ISA-L to the\n    system library path.\n  * Use -Disal.lib to specify a nonstandard location for the libisal library\n    files.\n  * Use -Dbundle.isal to copy the contents of the isal.lib directory into\n    the final tar file. This option requires that -Disal.lib is also given,\n    and it ignores the -Disal.prefix option. If -Disal.lib isn't given, the\n    bundling and building will fail.\n\n Special plugins: OWASP's dependency-check:\n\n   OWASP's dependency-check plugin will scan the third party dependencies\n   of this project for known CVEs (security vulnerabilities against them).\n   It will produce a report in target/dependency-check-report.html. To\n   invoke, run 'mvn dependency-check:aggregate'. Note that this plugin\n   requires maven 3.1.1 or greater.\n\n PMDK library build options:\n\n   The Persistent Memory Development Kit (PMDK), formerly known as NVML, is a growing\n   collection of libraries which have been developed for various use cases, tuned,\n   validated to production quality, and thoroughly documented. These libraries are built\n   on the Direct Access (DAX) feature available in both Linux and Windows, which allows\n   applications directly load/store access to persistent memory by memory-mapping files\n   on a persistent memory aware file system.\n\n   It is currently an optional component, meaning that Hadoop can be built without\n   this dependency. Please Note the library is used via dynamic module. For getting\n   more details please refer to the official sites:\n   http://pmem.io/ and https://github.com/pmem/pmdk.\n\n  * -Drequire.pmdk is used to build the project with PMDK libraries forcibly. With this\n    option provided, the build will fail if libpmem library is not found. If this option\n    is not given, the build will generate a version of Hadoop with libhadoop.so.\n    And storage class memory(SCM) backed HDFS cache is still supported without PMDK involved.\n    Because PMDK can bring better caching write/read performance, it is recommended to build\n    the project with this option if user plans to use SCM backed HDFS cache.\n  * -Dpmdk.lib is used to specify a nonstandard location for PMDK libraries if they are not\n    under /usr/lib or /usr/lib64.\n  * -Dbundle.pmdk is used to copy the specified libpmem libraries into the distribution tar\n    package. This option requires that -Dpmdk.lib is specified. With -Dbundle.pmdk provided,\n    the build will fail if -Dpmdk.lib is not specified.\n\nControlling the redistribution of the protobuf-2.5 dependency\n\n    The protobuf 2.5.0 library is used at compile time to compile the class\n    org.apache.hadoop.ipc.ProtobufHelper; this class known to have been used by\n    external projects in the past. Protobuf 2.5 is not used directly in\n    the Hadoop codebase; alongside the move to Protobuf 3.x a private successor\n    class, org.apache.hadoop.ipc.internal.ShadedProtobufHelper is now used.\n\n    The hadoop-common module no longer exports its compile-time dependency on\n    protobuf-java-2.5.\n    Any application declaring a dependency on hadoop-commmon will no longer get\n    the artifact added to their classpath.\n    If is still required, then they must explicitly declare it:\n\n      <dependency>\n        <groupId>com.google.protobuf</groupId>\n        <artifactId>protobuf-java</artifactId>\n        <version>2.5.0</version>\n      </dependency>\n\n    In Hadoop builds the scope of the dependency can be set with the\n    option \"common.protobuf2.scope\".\n    This can be upgraded from \"provided\" to \"compile\" on the maven command line:\n\n           -Dcommon.protobuf2.scope=compile\n\n    If this is done then protobuf-java-2.5.0.jar will again be exported as a\n    hadoop-common dependency, and included in the share/hadoop/common/lib/\n    directory of any Hadoop distribution built.\n\n    Note that protobuf-java-2.5.0.jar is still placed in\n    share/hadoop/yarn/timelineservice/lib; this is needed by the hbase client\n    library.\n\n----------------------------------------------------------------------------------\nBuilding components separately\n\nIf you are building a submodule directory, all the hadoop dependencies this\nsubmodule has will be resolved as all other 3rd party dependencies. This is,\nfrom the Maven cache or from a Maven repository (if not available in the cache\nor the SNAPSHOT 'timed out').\nAn alternative is to run 'mvn install -DskipTests' from Hadoop source top\nlevel once; and then work from the submodule. Keep in mind that SNAPSHOTs\ntime out after a while, using the Maven '-nsu' will stop Maven from trying\nto update SNAPSHOTs from external repos.\n\n----------------------------------------------------------------------------------\nImporting projects to eclipse\n\nAt first, install artifacts including hadoop-maven-plugins at the top of the source tree.\n\n  $ mvn clean install -DskipTests -DskipShade\n\nThen, import to eclipse by specifying the root directory of the project via\n[File] > [Import] > [Maven] > [Existing Maven Projects].\n\n----------------------------------------------------------------------------------\nBuilding distributions:\n\nCreate binary distribution without native code and without Javadocs:\n\n  $ mvn package -Pdist -DskipTests -Dtar -Dmaven.javadoc.skip=true\n\nCreate binary distribution with native code:\n\n  $ mvn package -Pdist,native -DskipTests -Dtar\n\nCreate source distribution:\n\n  $ mvn package -Psrc -DskipTests\n\nCreate source and binary distributions with native code:\n\n  $ mvn package -Pdist,native,src -DskipTests -Dtar\n\nCreate a local staging version of the website (in /tmp/hadoop-site)\n\n  $ mvn site site:stage -Preleasedocs,docs -DstagingDirectory=/tmp/hadoop-site\n\nNote that the site needs to be built in a second pass after other artifacts.\n\n----------------------------------------------------------------------------------\nInstalling Hadoop\n\nLook for these HTML files after you build the document by the above commands.\n\n  * Single Node Setup:\n    hadoop-project-dist/hadoop-common/SingleCluster.html\n\n  * Cluster Setup:\n    hadoop-project-dist/hadoop-common/ClusterSetup.html\n\n----------------------------------------------------------------------------------\n\nHandling out of memory errors in builds\n\n----------------------------------------------------------------------------------\n\nIf the build process fails with an out of memory error, you should be able to fix\nit by increasing the memory used by maven which can be done via the environment\nvariable MAVEN_OPTS.\n\nHere is an example setting to allocate between 256 MB and 1.5 GB of heap space to\nMaven\n\nexport MAVEN_OPTS=\"-Xms256m -Xmx1536m\"\n\n----------------------------------------------------------------------------------\n\nBuilding on macOS (without Docker)\n\n----------------------------------------------------------------------------------\nInstalling required dependencies for clean install of macOS 10.14:\n\n* Install Xcode Command Line Tools\n  $ xcode-select --install\n* Install Homebrew\n  $ /usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"\n* Install OpenJDK 8\n  $ brew tap AdoptOpenJDK/openjdk\n  $ brew cask install adoptopenjdk8\n* Install maven and tools\n  $ brew install maven autoconf automake cmake wget\n* Install native libraries, only openssl is required to compile native code,\nyou may optionally install zlib, lz4, etc.\n  $ brew install openssl\n* Protocol Buffers 3.21.12 (required to compile native code)\n  $ curl -L https://github.com/protocolbuffers/protobuf/archive/refs/tags/v3.21.12.tar.gz > protobuf-3.21.12.tar.gz\n  $ tar -zxvf protobuf-3.21.12.tar.gz && cd protobuf-3.21.12\n  $ ./autogen.sh\n  $ ./configure\n  $ make\n  $ make check\n  $ make install\n  $ protoc --version\n\nNote that building Hadoop 3.1.1/3.1.2/3.2.0 native code from source is broken\non macOS. For 3.1.1/3.1.2, you need to manually backport YARN-8622. For 3.2.0,\nyou need to backport both YARN-8622 and YARN-9487 in order to build native code.\n\n----------------------------------------------------------------------------------\nBuilding command example:\n\n* Create binary distribution with native code but without documentation:\n  $ mvn package -Pdist,native -DskipTests -Dmaven.javadoc.skip \\\n    -Dopenssl.prefix=/usr/local/opt/openssl\n\nNote that the command above manually specified the openssl library and include\npath. This is necessary at least for Homebrewed OpenSSL.\n\n\n----------------------------------------------------------------------------------\n\nBuilding on CentOS 8\n\n----------------------------------------------------------------------------------\n\n\n* Install development tools such as GCC, autotools, OpenJDK and Maven.\n  $ sudo dnf group install --with-optional 'Development Tools'\n  $ sudo dnf install java-1.8.0-openjdk-devel maven\n\n* Install python2 for building documentation.\n  $ sudo dnf install python2\n\n* Install Protocol Buffers v3.21.12.\n  $ curl -L https://github.com/protocolbuffers/protobuf/archive/refs/tags/v3.21.12.tar.gz > protobuf-3.21.12.tar.gz\n  $ tar -zxvf protobuf-3.21.12.tar.gz && cd protobuf-3.21.12\n  $ ./autogen.sh\n  $ ./configure --prefix=/usr/local\n  $ make\n  $ sudo make install\n  $ cd ..\n\n* Install libraries provided by CentOS 8.\n  $ sudo dnf install libtirpc-devel zlib-devel lz4-devel bzip2-devel openssl-devel cyrus-sasl-devel libpmem-devel\n\n* Install GCC 9.3.0\n  $ sudo dnf -y install gcc-toolset-9-gcc gcc-toolset-9-gcc-c++\n  $ source /opt/rh/gcc-toolset-9/enable\n\n* Install CMake 3.19\n  $ curl -L https://cmake.org/files/v3.19/cmake-3.19.0.tar.gz > cmake-3.19.0.tar.gz\n  $ tar -zxvf cmake-3.19.0.tar.gz && cd cmake-3.19.0\n  $ ./bootstrap\n  $ make -j$(nproc)\n  $ sudo make install\n\n* Install boost.\n  $ curl -L -o boost_1_72_0.tar.bz2 https://sourceforge.net/projects/boost/files/boost/1.72.0/boost_1_72_0.tar.bz2/download\n  $ tar xjf boost_1_72_0.tar.bz2\n  $ cd boost_1_72_0\n  $ ./bootstrap.sh --prefix=/usr/local\n  $ ./b2\n  $ sudo ./b2 install\n\n* Install optional dependencies (snappy-devel).\n  $ sudo dnf --enablerepo=PowerTools install snappy-devel\n\n* Install optional dependencies (libzstd-devel).\n  $ sudo dnf install https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm\n  $ sudo dnf --enablerepo=epel install libzstd-devel\n\n* Install optional dependencies (isa-l).\n  $ sudo dnf --enablerepo=PowerTools install nasm\n  $ git clone https://github.com/intel/isa-l\n  $ cd isa-l/\n  $ ./autogen.sh\n  $ ./configure\n  $ make\n  $ sudo make install\n\n----------------------------------------------------------------------------------\n\nBuilding on Windows 10\n\n----------------------------------------------------------------------------------\nRequirements:\n\n* Windows 10\n* JDK 1.8\n* Maven 3.0 or later (maven.apache.org)\n* Boost 1.72 (boost.org)\n* Protocol Buffers 3.21.12 (https://github.com/protocolbuffers/protobuf/tags)\n* CMake 3.19 or newer (cmake.org)\n* Visual Studio 2019 (visualstudio.com)\n* Windows SDK 8.1 (optional, if building CPU rate control for the container executor. Get this from\n                   http://msdn.microsoft.com/en-us/windows/bg162891.aspx)\n* Zlib (zlib.net, if building native code bindings for zlib)\n* Git (preferably, get this from https://git-scm.com/download/win since the package also contains\n       Unix command-line tools that are needed during packaging).\n* Python (python.org, for generation of docs using 'mvn site')\n* Internet connection for first build (to fetch all Maven and Hadoop dependencies)\n\n----------------------------------------------------------------------------------\n\nBuilding guidelines:\n\nHadoop repository provides the Dockerfile for building Hadoop on Windows 10, located at\ndev-support/docker/Dockerfile_windows_10. It is highly recommended to use this and create the\nDocker image for building Hadoop on Windows 10, since you don't have to install anything else\nother than Docker and no additional steps are required in terms of aligning the environment with\nthe necessary paths etc.\n\nHowever, if you still prefer taking the route of not using Docker, this Dockerfile_windows_10 will\nstill be immensely useful as a raw guide for all the steps involved in creating the environment\nneeded to build Hadoop on Windows 10.\n\nBuilding using the Docker:\nWe first need to build the Docker image for building Hadoop on Windows 10. Run this command from\nthe root of the Hadoop repository.\n> docker build -t hadoop-windows-10-builder -f .\\dev-support\\docker\\Dockerfile_windows_10 .\\dev-support\\docker\\\n\nStart the container with the image that we just built.\n> docker run --rm -it hadoop-windows-10-builder\n\nYou can now clone the Hadoop repo inside this container and proceed with the build.\n\nNOTE:\nWhile one may perceive the idea of mounting the locally cloned (on the host filesystem) Hadoop\nrepository into the container (using the -v option), we have seen the build to fail owing to some\nfiles not being able to be located by Maven. Thus, we suggest cloning the Hadoop repository to a\nnon-mounted folder inside the container and proceed with the build. When the build is completed,\nyou may use the \"docker cp\" command to copy the built Hadoop tar.gz file from the docker container\nto the host filesystem. If you still would like to mount the Hadoop codebase, a workaround would\nbe to copy the mounted Hadoop codebase into another folder (which doesn't point to a mount) in the\ncontainer's filesystem and use this for building.\n\nHowever, we noticed no build issues when the Maven repository from the host filesystem was mounted\ninto the container. One may use this to greatly reduce the build time. Assuming that the Maven\nrepository is located at D:\\Maven\\Repository in the host filesystem, one can use the following\ncommand to mount the same onto the default Maven repository location while launching the container.\n> docker run --rm -v D:\\Maven\\Repository:C:\\Users\\ContainerAdministrator\\.m2\\repository -it hadoop-windows-10-builder\n\nBuilding:\n\nKeep the source code tree in a short path to avoid running into problems related\nto Windows maximum path length limitation (for example, C:\\hdc).\n\nThere is one support command file located in dev-support called win-paths-eg.cmd.\nIt should be copied somewhere convenient and modified to fit your needs.\n\nwin-paths-eg.cmd sets up the environment for use. You will need to modify this\nfile. It will put all of the required components in the command path,\nconfigure the bit-ness of the build, and set several optional components.\n\nSeveral tests require that the user must have the Create Symbolic Links\nprivilege.\n\nTo simplify the installation of Boost, Protocol buffers, OpenSSL and Zlib dependencies we can use\nvcpkg (https://github.com/Microsoft/vcpkg.git). Upon cloning the vcpkg repo, checkout the commit\n7ffa425e1db8b0c3edf9c50f2f3a0f25a324541d to get the required versions of the dependencies\nmentioned above.\n> git clone https://github.com/Microsoft/vcpkg.git\n> cd vcpkg\n> git checkout 7ffa425e1db8b0c3edf9c50f2f3a0f25a324541d\n> .\\bootstrap-vcpkg.bat\n> .\\vcpkg.exe install boost:x64-windows\n> .\\vcpkg.exe install protobuf:x64-windows\n> .\\vcpkg.exe install openssl:x64-windows\n> .\\vcpkg.exe install zlib:x64-windows\n\nSet the following environment variables -\n(Assuming that vcpkg was checked out at C:\\vcpkg)\n> set PROTOBUF_HOME=C:\\vcpkg\\installed\\x64-windows\n> set MAVEN_OPTS=-Xmx2048M -Xss128M\n\nAll Maven goals are the same as described above with the exception that\nnative code is built by enabling the 'native-win' Maven profile. -Pnative-win\nis enabled by default when building on Windows since the native components\nare required (not optional) on Windows.\n\nIf native code bindings for zlib are required, then the zlib headers must be\ndeployed on the build machine. Set the ZLIB_HOME environment variable to the\ndirectory containing the headers.\n\nset ZLIB_HOME=C:\\zlib-1.2.7\n\nAt runtime, zlib1.dll must be accessible on the PATH. Hadoop has been tested\nwith zlib 1.2.7, built using Visual Studio 2010 out of contrib\\vstudio\\vc10 in\nthe zlib 1.2.7 source tree.\n\nhttp://www.zlib.net/\n\n\nBuild command:\nThe following command builds all the modules in the Hadoop project and generates the tar.gz file in\nhadoop-dist/target upon successful build. Run these commands from an\n\"x64 Native Tools Command Prompt for VS 2019\" which can be found under \"Visual Studio 2019\" in the\nWindows start menu. If you're using the Docker image from Dockerfile_windows_10, you'll be\nlogged into \"x64 Native Tools Command Prompt for VS 2019\" automatically when you start the\ncontainer.\n\n> set classpath=\n> set PROTOBUF_HOME=C:\\vcpkg\\installed\\x64-windows\n> mvn clean package -Dhttps.protocols=TLSv1.2 -DskipTests -DskipDocs -Pnative-win,dist^\n    -Drequire.openssl -Drequire.test.libhadoop -Pyarn-ui -Dshell-executable=C:\\Git\\bin\\bash.exe^\n    -Dtar -Dopenssl.prefix=C:\\vcpkg\\installed\\x64-windows^\n    -Dcmake.prefix.path=C:\\vcpkg\\installed\\x64-windows^\n    -Dwindows.cmake.toolchain.file=C:\\vcpkg\\scripts\\buildsystems\\vcpkg.cmake -Dwindows.cmake.build.type=RelWithDebInfo^\n    -Dwindows.build.hdfspp.dll=off -Dwindows.no.sasl=on -Duse.platformToolsetVersion=v142\n\nBuilding the release tarball:\nAssuming that we're still running in the Docker container hadoop-windows-10-builder, run the\nfollowing command to create the Apache Hadoop release tarball -\n\n> set IS_WINDOWS=1\n> set MVN_ARGS=\"-Dshell-executable=C:\\Git\\bin\\bash.exe -Dhttps.protocols=TLSv1.2 -Pnative-win -Drequire.openssl -Dopenssl.prefix=C:\\vcpkg\\installed\\x64-windows -Dcmake.prefix.path=C:\\vcpkg\\installed\\x64-windows -Dwindows.cmake.toolchain.file=C:\\vcpkg\\scripts\\buildsystems\\vcpkg.cmake -Dwindows.cmake.build.type=RelWithDebInfo -Dwindows.build.hdfspp.dll=off -Duse.platformToolsetVersion=v142 -Dwindows.no.sasl=on -DskipTests -DskipDocs -Drequire.test.libhadoop\"\n> C:\\Git\\bin\\bash.exe C:\\hadoop\\dev-support\\bin\\create-release --mvnargs=%MVN_ARGS%\n\nNote:\nIf the building fails due to an issue with long paths, rename the Hadoop root directory to just a\nletter (like 'h') and rebuild -\n\n> C:\\Git\\bin\\bash.exe C:\\h\\dev-support\\bin\\create-release --mvnargs=%MVN_ARGS%\n\n----------------------------------------------------------------------------------\nBuilding distributions:\n\n * Build distribution with native code    : mvn package [-Pdist][-Pdocs][-Psrc][-Dtar][-Dmaven.javadoc.skip=true]\n\n----------------------------------------------------------------------------------\nRunning compatibility checks with checkcompatibility.py\n\nInvoke `./dev-support/bin/checkcompatibility.py` to run Java API Compliance Checker\nto compare the public Java APIs of two git objects. This can be used by release\nmanagers to compare the compatibility of a previous and current release.\n\nAs an example, this invocation will check the compatibility of interfaces annotated as Public or LimitedPrivate:\n\n./dev-support/bin/checkcompatibility.py --annotation org.apache.hadoop.classification.InterfaceAudience.Public --annotation org.apache.hadoop.classification.InterfaceAudience.LimitedPrivate --include \"hadoop.*\" branch-2.7.2 trunk\n\n----------------------------------------------------------------------------------\nChanging the Hadoop version declared returned by VersionInfo\n\nIf for compatibility reasons the version of Hadoop has to be declared as a 2.x release in the information returned by\norg.apache.hadoop.util.VersionInfo, set the property declared.hadoop.version to the desired version.\nFor example: mvn package -Pdist -Ddeclared.hadoop.version=2.11\n\nIf unset, the project version declared in the POM file is used.\n"
        },
        {
          "name": "LICENSE-binary",
          "type": "blob",
          "size": 23.203125,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n--------------------------------------------------------------------------------\nThis project bundles some components that are also licensed under the Apache\nLicense Version 2.0:\n\n\nhadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/nvd3-1.8.5.* (css and js files)\nhadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/checker/AbstractFuture.java\nhadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/checker/TimeoutFuture.java\n\nch.qos.reload4j:reload4j:1.2.22\ncom.aliyun:aliyun-java-sdk-core:4.5.10\ncom.aliyun:aliyun-java-sdk-kms:2.11.0\ncom.aliyun:aliyun-java-sdk-ram:3.1.0\ncom.aliyun:aliyun-java-sdk-sts:3.0.0\ncom.aliyun.oss:aliyun-sdk-oss:3.13.2\ncom.cedarsoftware:java-util:1.9.0\ncom.cedarsoftware:json-io:2.5.1\ncom.fasterxml.jackson.core:jackson-annotations:2.12.7\ncom.fasterxml.jackson.core:jackson-core:2.12.7\ncom.fasterxml.jackson.core:jackson-databind:2.12.7.1\ncom.fasterxml.jackson.jaxrs:jackson-jaxrs-base:2.12.7\ncom.fasterxml.jackson.jaxrs:jackson-jaxrs-json-provider:2.12.7\ncom.fasterxml.jackson.module:jackson-module-jaxb-annotations:2.12.7\ncom.fasterxml.uuid:java-uuid-generator:3.1.4\ncom.fasterxml.woodstox:woodstox-core:5.4.0\ncom.github.ben-manes.caffeine:caffeine:2.9.3\ncom.github.davidmoten:rxjava-extras:0.8.0.17\ncom.github.stephenc.jcip:jcip-annotations:1.0-1\ncom.google:guice:5.1.0\ncom.google:guice-servlet:5.1.0\ncom.google.api.grpc:proto-google-common-protos:1.0.0\ncom.google.code.gson:2.9.0\ncom.google.errorprone:error_prone_annotations:2.5.1\ncom.google.j2objc:j2objc-annotations:1.3\ncom.google.json-simple:json-simple:1.1.1\ncom.google.guava:failureaccess:1.0\ncom.google.guava:guava:20.0\ncom.google.guava:guava:32.0.1-jre\ncom.google.guava:listenablefuture:9999.0-empty-to-avoid-conflict-with-guava\ncom.microsoft.azure:azure-storage:7.0.0\ncom.nimbusds:nimbus-jose-jwt:9.37.2\ncom.zaxxer:HikariCP:4.0.3\ncommons-beanutils:commons-beanutils:1.9.4\ncommons-cli:commons-cli:1.9.0\ncommons-codec:commons-codec:1.15\norg.apache.commons:commons-collections4:4.4\ncommons-daemon:commons-daemon:1.0.13\ncommons-io:commons-io:2.16.1\ncommons-net:commons-net:3.9.0\nde.ruedigermoeller:fst:2.50\nio.grpc:grpc-api:1.69.0\nio.grpc:grpc-context:1.69.0\nio.grpc:grpc-core:1.69.0\nio.grpc:grpc-netty:1.69.0\nio.grpc:grpc-protobuf:1.69.0\nio.grpc:grpc-protobuf-lite:1.69.0\nio.grpc:grpc-stub:1.69.0\nio.netty:netty-all:4.1.116.Final\nio.netty:netty-buffer:4.1.116.Final\nio.netty:netty-codec:4.1.116.Final\nio.netty:netty-codec-dns:4.1.116.Final\nio.netty:netty-codec-haproxy:4.1.116.Final\nio.netty:netty-codec-http:4.1.116.Final\nio.netty:netty-codec-http2:4.1.116.Final\nio.netty:netty-codec-memcache:4.1.116.Final\nio.netty:netty-codec-mqtt:4.1.116.Final\nio.netty:netty-codec-redis:4.1.116.Final\nio.netty:netty-codec-smtp:4.1.116.Final\nio.netty:netty-codec-socks:4.1.116.Final\nio.netty:netty-codec-stomp:4.1.116.Final\nio.netty:netty-codec-xml:4.1.116.Final\nio.netty:netty-common:4.1.116.Final\nio.netty:netty-handler:4.1.116.Final\nio.netty:netty-handler-proxy:4.1.116.Final\nio.netty:netty-resolver:4.1.116.Final\nio.netty:netty-resolver-dns:4.1.116.Final\nio.netty:netty-transport:4.1.116.Final\nio.netty:netty-transport-rxtx:4.1.116.Final\nio.netty:netty-transport-sctp:4.1.116.Final\nio.netty:netty-transport-udt:4.1.116.Final\nio.netty:netty-transport-classes-epoll:4.1.116.Final\nio.netty:netty-transport-native-unix-common:4.1.116.Final\nio.netty:netty-transport-classes-kqueue:4.1.116.Final\nio.netty:netty-resolver-dns-classes-macos:4.1.116.Final\nio.netty:netty-transport-native-epoll:4.1.116.Final\nio.netty:netty-transport-native-kqueue:4.1.116.Final\nio.netty:netty-resolver-dns-native-macos:4.1.116.Final\nio.opencensus:opencensus-api:0.12.3\nio.opencensus:opencensus-contrib-grpc-metrics:0.12.3\nio.reactivex:rxjava:1.3.8\nio.reactivex:rxjava-string:1.1.1\nio.reactivex:rxnetty:0.4.20\nio.swagger:swagger-annotations:1.5.4\njavax.inject:javax.inject:1\nnet.java.dev.jna:jna:5.2.0\nnet.minidev:accessors-smart:1.2\norg.apache.avro:avro:1.11.4\norg.apache.avro:avro:1.11.3\norg.apache.commons:commons-compress:1.26.1\norg.apache.commons:commons-configuration2:2.10.1\norg.apache.commons:commons-csv:1.9.0\norg.apache.commons:commons-digester:1.8.1\norg.apache.commons:commons-lang3:3.12.0\norg.apache.commons:commons-math3:3.6.1\norg.apache.commons:commons-text:1.10.0\norg.apache.commons:commons-validator:1.6\norg.apache.curator:curator-client:5.2.0\norg.apache.curator:curator-framework:5.2.0\norg.apache.curator:curator-recipes:5.2.0\norg.apache.hbase:hbase-annotations:2.5.8\norg.apache.hbase:hbase-client:2.5.8\norg.apache.hbase:hbase-common:2.5.8\norg.apache.hbase:hbase-protocol:2.5.8\norg.apache.htrace:htrace-core:3.1.0-incubating\norg.apache.htrace:htrace-core4:4.1.0-incubating\norg.apache.httpcomponents:httpclient:4.5.13\norg.apache.httpcomponents:httpcore:4.4.13\norg.apache.kafka:kafka-clients:3.4.0\norg.apache.kerby:kerb-admin:2.0.3\norg.apache.kerby:kerb-client:2.0.3\norg.apache.kerby:kerb-common:2.0.3\norg.apache.kerby:kerb-core:2.0.3\norg.apache.kerby:kerb-crypto:2.0.3\norg.apache.kerby:kerb-identity:2.0.3\norg.apache.kerby:kerb-server:2.0.3\norg.apache.kerby:kerb-simplekdc:2.0.3\norg.apache.kerby:kerb-util:2.0.3\norg.apache.kerby:kerby-asn1:2.0.3\norg.apache.kerby:kerby-config:2.0.3\norg.apache.kerby:kerby-pkix:2.0.3\norg.apache.kerby:kerby-util:2.0.3\norg.apache.kerby:kerby-xdr:2.0.3\norg.apache.kerby:token-provider:2.0.3\norg.apache.sshd:sshd-common:2.11.0\norg.apache.sshd:sshd-core:2.11.0\norg.apache.sshd:sshd-sftp:2.11.0\norg.apache.solr:solr-solrj:8.11.2\norg.apache.yetus:audience-annotations:0.5.0\norg.apache.zookeeper:zookeeper:3.8.4\norg.codehaus.jettison:jettison:1.5.4\norg.eclipse.jetty:jetty-annotations:9.4.53.v20231009\norg.eclipse.jetty:jetty-http:9.4.53.v20231009\norg.eclipse.jetty:jetty-io:9.4.53.v20231009\norg.eclipse.jetty:jetty-jndi:9.4.53.v20231009\norg.eclipse.jetty:jetty-plus:9.4.53.v20231009\norg.eclipse.jetty:jetty-security:9.4.53.v20231009\norg.eclipse.jetty:jetty-server:9.4.53.v20231009\norg.eclipse.jetty:jetty-servlet:9.4.53.v20231009\norg.eclipse.jetty:jetty-util:9.4.53.v20231009\norg.eclipse.jetty:jetty-util-ajax:9.4.53.v20231009\norg.eclipse.jetty:jetty-webapp:9.4.53.v20231009\norg.eclipse.jetty:jetty-xml:9.4.53.v20231009\norg.eclipse.jetty.websocket:javax-websocket-client-impl:9.4.53.v20231009\norg.eclipse.jetty.websocket:javax-websocket-server-impl:9.4.53.v20231009\norg.ehcache:ehcache:3.8.2\norg.ini4j:ini4j:0.5.4\norg.lz4:lz4-java:1.7.1\norg.objenesis:objenesis:2.6\norg.xerial.snappy:snappy-java:1.1.10.4\norg.yaml:snakeyaml:2.0\norg.wildfly.openssl:wildfly-openssl:2.1.4.Final\nsoftware.amazon.awssdk:bundle:2.25.53\n\n\n--------------------------------------------------------------------------------\nThis product bundles various third-party components under other open source\nlicenses. This section summarizes those components and their licenses.\nSee licenses-binary/ for text of these licenses.\n\n\nBSD 2-Clause\n------------\n\nhadoop-common-project/hadoop-common/src/main/native/src/org/apache/hadoop/io/compress/lz4/{lz4.h,lz4.c,lz4hc.h,lz4hc.c}\nhadoop-hdfs-project/hadoop-hdfs-native-client/src/main/native/fuse-dfs/util/tree.h\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/native/container-executor/impl/compat/{fstatat|openat|unlinkat}.h\n\ncom.github.luben:zstd-jni:1.5.2-1\ndnsjava:dnsjava:3.6.1\norg.codehaus.woodstox:stax2-api:4.2.1\n\n\nBSD 3-Clause\n------------\n\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/bloom/*\nhadoop-common-project/hadoop-common/src/main/native/gtest/gtest-all.cc\nhadoop-common-project/hadoop-common/src/main/native/gtest/include/gtest/gtest.h\nhadoop-common-project/hadoop-common/src/main/native/src/org/apache/hadoop/util/bulk_crc32_x86.c\nhadoop-tools/hadoop-sls/src/main/html/js/thirdparty/d3.v3.js\nhadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/d3-3.5.17.min.js\nleveldb v1.13\n\ncom.google.protobuf:protobuf-java:2.5.0\ncom.google.protobuf:protobuf-java:3.25.3\ncom.google.re2j:re2j:1.1\ncom.jcraft:jsch:0.1.55\ncom.thoughtworks.paranamer:paranamer:2.3\njakarta.activation:jakarta.activation-api:1.2.1\norg.fusesource.leveldbjni:leveldbjni-all:1.8\norg.jline:jline:3.9.0\norg.hamcrest:hamcrest-core:1.3\norg.ow2.asm:asm:5.0.4\norg.ow2.asm:asm-commons:6.0\norg.ow2.asm:asm-tree:6.0\n\n\nMIT License\n-----------\n\nhadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/angular-1.6.4.min.js\nhadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/angular-nvd3-1.0.9.min.js\nhadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/angular-route-1.6.4.min.js\nhadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.4.1\nhadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/dataTables.bootstrap.css\nhadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/dataTables.bootstrap.js\nhadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/dust-full-2.0.0.min.js\nhadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/dust-helpers-1.1.1.min.js\nhadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/jquery-3.6.0.min.js\nhadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/jquery.dataTables.min.js\nhadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/moment.min.js\nhadoop-tools/hadoop-sls/src/main/html/js/thirdparty/bootstrap.min.js\nhadoop-tools/hadoop-sls/src/main/html/js/thirdparty/jquery.js\nhadoop-tools/hadoop-sls/src/main/html/css/bootstrap.min.css\nhadoop-tools/hadoop-sls/src/main/html/css/bootstrap-responsive.min.css\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/webapps/static/dt-1.11.5/*\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/webapps/static/jquery\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/webapps/static/jt/jquery.jstree.js\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/resources/TERMINAL\n\nbootstrap v3.3.6\nbroccoli-asset-rev v2.4.2\nbroccoli-funnel v1.0.1\ndatatables v1.11.5\nem-helpers v0.5.13\nem-table v0.1.6\nember v2.2.0\nember-array-contains-helper v1.0.2\nember-bootstrap v0.5.1\nember-cli v1.13.13\nember-cli-app-version v1.0.0\nember-cli-babel v5.1.6\nember-cli-content-security-policy v0.4.0\nember-cli-dependency-checker v1.2.0\nember-cli-htmlbars v1.0.2\nember-cli-htmlbars-inline-precompile v0.3.1\nember-cli-ic-ajax v0.2.1\nember-cli-inject-live-reload v1.4.0\nember-cli-jquery-ui v0.0.20\nember-cli-qunit v1.2.1\nember-cli-release v0.2.8\nember-cli-shims v0.0.6\nember-cli-sri v1.2.1\nember-cli-test-loader v0.2.1\nember-cli-uglify v1.2.0\nember-d3 v0.1.0\nember-data v2.1.0\nember-disable-proxy-controllers v1.0.1\nember-export-application-global v1.0.5\nember-load-initializers v0.1.7\nember-qunit v0.4.16\nember-qunit-notifications v0.1.0\nember-resolver v2.0.3\nember-spin-spinner v0.2.3\nember-truth-helpers v1.2.0\njquery v2.1.4\njquery-ui v1.11.4\nloader.js v3.3.0\nmomentjs v2.10.6\nqunit v1.19.0\nselect2 v4.0.0\nsnippet-ss v1.11.0\nspin.js v2.3.2\n\ncom.microsoft.azure:azure-cosmosdb:2.4.5\ncom.microsoft.azure:azure-cosmosdb-commons:2.4.5\ncom.microsoft.azure:azure-cosmosdb-direct:2.4.5\ncom.microsoft.azure:azure-cosmosdb-gateway:2.4.5\ncom.microsoft.azure:azure-data-lake-store-sdk:2.3.3\ncom.microsoft.azure:azure-keyvault-core:1.0.0\ncom.microsoft.sqlserver:mssql-jdbc:6.2.1.jre7\norg.bouncycastle:bcpkix-jdk18on:1.78.1\norg.bouncycastle:bcprov-jdk18on:1.78.1\norg.bouncycastle:bcutil-jdk18on:1.78.1\norg.checkerframework:checker-qual:3.8.0\norg.codehaus.mojo:animal-sniffer-annotations:1.24\norg.jruby.jcodings:jcodings:1.0.13\norg.jruby.joni:joni:2.1.2\norg.ojalgo:ojalgo:43.0\norg.slf4j:jul-to-slf4j:1.7.36\norg.slf4j:slf4j-api:1.7.36\norg.slf4j:slf4j-reload4j:1.7.36\n\n\nCDDL 1.1 + GPLv2 with classpath exception\n-----------------------------------------\n\ncom.github.pjfanning:jersey-json:1.22.0\ncom.sun.jersey:jersey-client:1.19.4\ncom.sun.jersey:jersey-core:1.19.4\ncom.sun.jersey:jersey-guice:1.19.4\ncom.sun.jersey:jersey-server:1.19.4\ncom.sun.jersey:jersey-servlet:1.19.4\ncom.sun.xml.bind:jaxb-impl:2.2.3-1\njavax.annotation:javax.annotation-api:1.3.2\njavax.cache:cache-api:1.1.1\njavax.servlet:javax.servlet-api:3.1.0\njavax.servlet.jsp:jsp-api:2.1\njavax.websocket:javax.websocket-api:1.0\njavax.ws.rs:jsr311-api:1.1.1\njavax.xml.bind:jaxb-api:2.2.11\n\n\nEclipse Public License 1.0\n--------------------------\n\njunit:junit:4.13.2\norg.jacoco:org.jacoco.agent:0.8.5\n\n\n\nHSQL License\n------------\n\norg.hsqldb:hsqldb:2.7.1\n\n\nJDOM License\n------------\n\norg.jdom:jdom2:2.0.6.1\n\n\nPublic Domain\n-------------\n\naopalliance:aopalliance:1.0\n"
        },
        {
          "name": "LICENSE.txt",
          "type": "blob",
          "size": 15.328125,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n--------------------------------------------------------------------------------\nThis product bundles various third-party components under other open source\nlicenses. This section summarizes those components and their licenses.\nSee licenses/ for text of these licenses.\n\n\nApache Software Foundation License 2.0\n--------------------------------------\n\nhadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/nvd3-1.8.5.* (css and js files)\nhadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/checker/AbstractFuture.java\nhadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/checker/TimeoutFuture.java\n\n\nBSD 2-Clause\n------------\n\nhadoop-common-project/hadoop-common/src/main/native/src/org/apache/hadoop/io/compress/lz4/{lz4.h,lz4.c,lz4hc.h,lz4hc.c}\nhadoop-hdfs-project/hadoop-hdfs-native-client/src/main/native/fuse-dfs/util/tree.h\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/native/container-executor/impl/compat/{fstatat|openat|unlinkat}.h\n\n\nBSD 3-Clause\n------------\n\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/bloom/*\nhadoop-common-project/hadoop-common/src/main/native/gtest/gtest-all.cc\nhadoop-common-project/hadoop-common/src/main/native/gtest/include/gtest/gtest.h\nhadoop-common-project/hadoop-common/src/main/native/src/org/apache/hadoop/util/bulk_crc32_x86.c\nhadoop-tools/hadoop-sls/src/main/html/js/thirdparty/d3.v3.js\nhadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/d3-3.5.17.min.js\n\n\nMIT License\n-----------\n\nhadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/angular-1.6.4.min.js\nhadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/angular-nvd3-1.0.9.min.js\nhadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/angular-route-1.6.4.min.js\nhadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.4.1\nhadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/dataTables.bootstrap.css\nhadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/dataTables.bootstrap.js\nhadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/dust-full-2.0.0.min.js\nhadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/dust-helpers-1.1.1.min.js\nhadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/jquery-3.6.0.min.js\nhadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/jquery.dataTables.min.js\nhadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/moment.min.js\nhadoop-tools/hadoop-sls/src/main/html/js/thirdparty/bootstrap.min.js\nhadoop-tools/hadoop-sls/src/main/html/js/thirdparty/jquery.js\nhadoop-tools/hadoop-sls/src/main/html/css/bootstrap.min.css\nhadoop-tools/hadoop-sls/src/main/html/css/bootstrap-responsive.min.css\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/webapps/static/dt-1.11.5/*\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/webapps/static/jquery\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/webapps/static/jt/jquery.jstree.js\nhadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/resources/TERMINAL\n\n=======\nFor hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/native/container-executor/impl/utils/cJSON.[ch]:\n\nCopyright (c) 2009-2017 Dave Gamble and cJSON contributors\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n"
        },
        {
          "name": "NOTICE-binary",
          "type": "blob",
          "size": 26.5283203125,
          "content": "Apache Hadoop\nCopyright 2006 and onwards The Apache Software Foundation.\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\nExport Control Notice\n---------------------\n\nThis distribution includes cryptographic software.  The country in\nwhich you currently reside may have restrictions on the import,\npossession, use, and/or re-export to another country, of\nencryption software.  BEFORE using any encryption software, please\ncheck your country's laws, regulations and policies concerning the\nimport, possession, or use, and re-export of encryption software, to\nsee if this is permitted.  See <http://www.wassenaar.org/> for more\ninformation.\n\nThe U.S. Government Department of Commerce, Bureau of Industry and\nSecurity (BIS), has classified this software as Export Commodity\nControl Number (ECCN) 5D002.C.1, which includes information security\nsoftware using or performing cryptographic functions with asymmetric\nalgorithms.  The form and manner of this Apache Software Foundation\ndistribution makes it eligible for export under the License Exception\nENC Technology Software Unrestricted (TSU) exception (see the BIS\nExport Administration Regulations, Section 740.13) for both object\ncode and source code.\n\nThe following provides more details on the included cryptographic software:\n\nThis software uses the SSL libraries from the Jetty project written\nby mortbay.org.\nHadoop Yarn Server Web Proxy uses the BouncyCastle Java\ncryptography APIs written by the Legion of the Bouncy Castle Inc.\n\n// ------------------------------------------------------------------\n// NOTICE file corresponding to the section 4d of The Apache License,\n// Version 2.0, in this case for\n// ------------------------------------------------------------------\n\n\nApache Yetus\nCopyright 2008-2017 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n---\nAdditional licenses for the Apache Yetus Source/Website:\n---\n\n\nSee LICENSE for terms.\n\n\n\nApache Avro\nCopyright 2010 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\nC JSON parsing provided by Jansson and\nwritten by Petri Lehtinen. The original software is\navailable from http://www.digip.org/jansson/.\n\n\nAWS SDK for Java\nCopyright 2010-2024 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n\nThis product includes software developed by\nAmazon Technologies, Inc (http://www.amazon.com/).\n\n**********************\nTHIRD PARTY COMPONENTS\n**********************\nThis software includes third party software subject to the following copyrights:\n- XML parsing and utility functions from JetS3t - Copyright 2006-2009 James Murty.\n- PKCS#1 PEM encoded private key parsing and utility functions from oauth.googlecode.com - Copyright 1998-2010 AOL Inc.\n\nThe licenses for these third party components are included in LICENSE.txt\n\n\nApache Commons BeanUtils\nCopyright 2000-2016 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n\nApache Commons CLI\nCopyright 2001-2009 The Apache Software Foundation\n\nThis product includes software developed by\nThe Apache Software Foundation (http://www.apache.org/).\n\n\nApache Commons Codec\nCopyright 2002-2017 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\nsrc/test/org/apache/commons/codec/language/DoubleMetaphoneTest.java\ncontains test data from http://aspell.net/test/orig/batch0.tab.\nCopyright (C) 2002 Kevin Atkinson (kevina@gnu.org)\n\n===============================================================================\n\nThe content of package org.apache.commons.codec.language.bm has been translated\nfrom the original php source code available at http://stevemorse.org/phoneticinfo.htm\nwith permission from the original authors.\nOriginal source copyright:\nCopyright (c) 2008 Alexander Beider & Stephen P. Morse.\n\n\nApache Commons Collections\nCopyright 2001-2018 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n\nApache Commons Compress\nCopyright 2002-2018 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (https://www.apache.org/).\n\nThe files in the package org.apache.commons.compress.archivers.sevenz\nwere derived from the LZMA SDK, version 9.20 (C/ and CPP/7zip/),\nwhich has been placed in the public domain:\n\n\"LZMA SDK is placed in the public domain.\" (http://www.7-zip.org/sdk.html)\n\n\nApache Commons Configuration\nCopyright 2001-2017 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n\nApache Commons CSV\nCopyright 2005-2014 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\nsrc/main/resources/contract.txt\nThis file was downloaded from http://www.ferc.gov/docs-filing/eqr/soft-tools/sample-csv/contract.txt and contains neither copyright notice nor license.\n\nsrc/main/resources/transaction.txt\nThis file was downloaded from http://www.ferc.gov/docs-filing/eqr/soft-tools/sample-csv/transaction.txt and contains neither copyright notice nor license.\n\nsrc/test/resources/CSVFileParser/bom.csv\nsrc/test/resources/CSVFileParser/test.csv\nsrc/test/resources/CSVFileParser/test_default.txt\nsrc/test/resources/CSVFileParser/test_default_comment.txt\nsrc/test/resources/CSVFileParser/test_rfc4180.txt\nsrc/test/resources/CSVFileParser/test_rfc4180_trim.txt\nsrc/test/resources/CSVFileParser/testCSV85.csv\nsrc/test/resources/CSVFileParser/testCSV85_default.txt\nsrc/test/resources/CSVFileParser/testCSV85_ignoreEmpty.txt\nThese files are used as test data and test result specifications.\n\n\nApache Commons Daemon\nCopyright 1999-2013 The Apache Software Foundation\n\nThis product includes software developed by\nThe Apache Software Foundation (http://www.apache.org/).\n\n\nApache Commons Digester\nCopyright 2001-2008 The Apache Software Foundation\n\nThis product includes software developed by\nThe Apache Software Foundation (http://www.apache.org/).\n\n\nApache Commons IO\nCopyright 2002-2016 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n\nApache Commons Lang\nCopyright 2001-2017 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\nThis product includes software from the Spring Framework,\nunder the Apache License 2.0 (see: StringUtils.containsWhitespace())\n\n\nApache Commons Logging\nCopyright 2003-2013 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n\nApache Commons Math\nCopyright 2001-2012 The Apache Software Foundation\n\nThis product includes software developed by\nThe Apache Software Foundation (http://www.apache.org/).\n\n===============================================================================\n\nThe BracketFinder (package org.apache.commons.math3.optimization.univariate)\nand PowellOptimizer (package org.apache.commons.math3.optimization.general)\nclasses are based on the Python code in module \"optimize.py\" (version 0.5)\ndeveloped by Travis E. Oliphant for the SciPy library (http://www.scipy.org/)\nCopyright © 2003-2009 SciPy Developers.\n===============================================================================\n\nThe LinearConstraint, LinearObjectiveFunction, LinearOptimizer,\nRelationShip, SimplexSolver and SimplexTableau classes in package\norg.apache.commons.math3.optimization.linear include software developed by\nBenjamin McCann (http://www.benmccann.com) and distributed with\nthe following copyright: Copyright 2009 Google Inc.\n===============================================================================\n\nThis product includes software developed by the\nUniversity of Chicago, as Operator of Argonne National\nLaboratory.\nThe LevenbergMarquardtOptimizer class in package\norg.apache.commons.math3.optimization.general includes software\ntranslated from the lmder, lmpar and qrsolv Fortran routines\nfrom the Minpack package\nMinpack Copyright Notice (1999) University of Chicago.  All rights reserved\n===============================================================================\n\nThe GraggBulirschStoerIntegrator class in package\norg.apache.commons.math3.ode.nonstiff includes software translated\nfrom the odex Fortran routine developed by E. Hairer and G. Wanner.\nOriginal source copyright:\nCopyright (c) 2004, Ernst Hairer\n===============================================================================\n\nThe EigenDecompositionImpl class in package\norg.apache.commons.math3.linear includes software translated\nfrom some LAPACK Fortran routines.  Original source copyright:\nCopyright (c) 1992-2008 The University of Tennessee.  All rights reserved.\n===============================================================================\n\nThe MersenneTwister class in package org.apache.commons.math3.random\nincludes software translated from the 2002-01-26 version of\nthe Mersenne-Twister generator written in C by Makoto Matsumoto and Takuji\nNishimura. Original source copyright:\nCopyright (C) 1997 - 2002, Makoto Matsumoto and Takuji Nishimura,\nAll rights reserved\n===============================================================================\n\nThe LocalizedFormatsTest class in the unit tests is an adapted version of\nthe OrekitMessagesTest class from the orekit library distributed under the\nterms of the Apache 2 licence. Original source copyright:\nCopyright 2010 CS Systèmes d'Information\n===============================================================================\n\nThe HermiteInterpolator class and its corresponding test have been imported from\nthe orekit library distributed under the terms of the Apache 2 licence. Original\nsource copyright:\nCopyright 2010-2012 CS Systèmes d'Information\n===============================================================================\n\nThe creation of the package \"o.a.c.m.analysis.integration.gauss\" was inspired\nby an original code donated by Sébastien Brisard.\n===============================================================================\n\n\nThe complete text of licenses and disclaimers associated with the the original\nsources enumerated above at the time of code translation are in the LICENSE.txt\nfile.\n\n\nApache Commons Net\nCopyright 2001-2017 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n\nApache Commons Text\nCopyright 2014-2018 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n\nApache Commons Validator\nCopyright 2001-2017 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n\nApache Curator\nCopyright 2013-2014 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n\nEhcache V3\nCopyright 2014-2016 Terracotta, Inc.\n\nThe product includes software from the Apache Commons Lang project,\nunder the Apache License 2.0 (see: org.ehcache.impl.internal.classes.commonslang)\n\n\nApache Geronimo\nCopyright 2003-2018 The Apache Software Foundation\n\nThis product includes software developed by\nThe Apache Software Foundation (http://www.apache.org/).\n\n\nCopyright 2014 The gRPC Authors\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\nThis product contains a modified portion of 'Netty', an open source\nnetworking library, which can be obtained at:\n\n  * LICENSE:\n    * netty/third_party/netty/LICENSE.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * https://netty.io\n  * LOCATION_IN_GRPC:\n    * netty/third_party/netty\n\n\nApache HBase\nCopyright 2007-2018 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n--\nThis product incorporates portions of the 'Hadoop' project\n\nCopyright 2007-2009 The Apache Software Foundation\n\nLicensed under the Apache License v2.0\n--\nOur Orca logo we got here: http://www.vectorfree.com/jumping-orca\nIt is licensed Creative Commons Attribution 3.0.\nSee https://creativecommons.org/licenses/by/3.0/us/\nWe changed the logo by stripping the colored background, inverting\nit and then rotating it some.\n\nLater we found that vectorfree.com image is not properly licensed.\nThe original is owned by vectorportal.com. The original was\nrelicensed so we could use it as Creative Commons Attribution 3.0.\nThe license is bundled with the download available here:\nhttp://www.vectorportal.com/subcategory/205/KILLER-WHALE-FREE-VECTOR.eps/ifile/9136/detailtest.asp\n--\nThis product includes portions of the Bootstrap project v3.0.0\n\nCopyright 2013 Twitter, Inc.\n\nLicensed under the Apache License v2.0\n\nThis product uses the Glyphicons Halflings icon set.\n\nhttp://glyphicons.com/\n\nCopyright Jan Kovařík\n\nLicensed under the Apache License v2.0 as a part of the Bootstrap project.\n\n--\nThis product includes portions of the Guava project v14 and v21, specifically\n'hbase-common/src/main/java/org/apache/hadoop/hbase/io/LimitInputStream.java'\n'hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java'\n\nCopyright (C) 2007 The Guava Authors\n\nLicensed under the Apache License, Version 2.0\n\n\nApache HTrace\nCopyright 2016 The Apache Software Foundation\n\nThis product includes software developed at The Apache Software\nFoundation (http://www.apache.org/).\n\nIn addition, this product includes software dependencies. See\nthe accompanying LICENSE.txt for a listing of dependencies\nthat are NOT Apache licensed (with pointers to their licensing)\n\nApache HTrace includes an Apache Thrift connector to Zipkin. Zipkin\nis a distributed tracing system that is Apache 2.0 Licensed.\nCopyright 2012 Twitter, Inc.\n\n\nApache HttpComponents Client\nCopyright 1999-2018 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n\nApache HttpComponents Core\nCopyright 2005-2018 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n\n==============================================================\n Jetty Web Container\n Copyright 1995-2017 Mort Bay Consulting Pty Ltd.\n==============================================================\n\nThe Jetty Web Container is Copyright Mort Bay Consulting Pty Ltd\nunless otherwise noted.\n\nJetty is dual licensed under both\n\n  * The Apache 2.0 License\n    http://www.apache.org/licenses/LICENSE-2.0.html\n\n      and\n\n  * The Eclipse Public 1.0 License\n    http://www.eclipse.org/legal/epl-v10.html\n\nJetty may be distributed under either license.\n\n------\nEclipse\n\nThe following artifacts are EPL.\n * org.eclipse.jetty.orbit:org.eclipse.jdt.core\n\nThe following artifacts are EPL and ASL2.\n * org.eclipse.jetty.orbit:javax.security.auth.message\n\n\nThe following artifacts are EPL and CDDL 1.0.\n * org.eclipse.jetty.orbit:javax.mail.glassfish\n\n\n------\nOracle\n\nThe following artifacts are CDDL + GPLv2 with classpath exception.\nhttps://glassfish.dev.java.net/nonav/public/CDDL+GPL.html\n\n * javax.servlet:javax.servlet-api\n * javax.annotation:javax.annotation-api\n * javax.transaction:javax.transaction-api\n * javax.websocket:javax.websocket-api\n\n------\nOracle OpenJDK\n\nIf ALPN is used to negotiate HTTP/2 connections, then the following\nartifacts may be included in the distribution or downloaded when ALPN\nmodule is selected.\n\n * java.sun.security.ssl\n\nThese artifacts replace/modify OpenJDK classes.  The modififications\nare hosted at github and both modified and original are under GPL v2 with\nclasspath exceptions.\nhttp://openjdk.java.net/legal/gplv2+ce.html\n\n\n------\nOW2\n\nThe following artifacts are licensed by the OW2 Foundation according to the\nterms of http://asm.ow2.org/license.html\n\norg.ow2.asm:asm-commons\norg.ow2.asm:asm\n\n\n------\nApache\n\nThe following artifacts are ASL2 licensed.\n\norg.apache.taglibs:taglibs-standard-spec\norg.apache.taglibs:taglibs-standard-impl\n\n\n------\nMortBay\n\nThe following artifacts are ASL2 licensed.  Based on selected classes from\nfollowing Apache Tomcat jars, all ASL2 licensed.\n\norg.mortbay.jasper:apache-jsp\n  org.apache.tomcat:tomcat-jasper\n  org.apache.tomcat:tomcat-juli\n  org.apache.tomcat:tomcat-jsp-api\n  org.apache.tomcat:tomcat-el-api\n  org.apache.tomcat:tomcat-jasper-el\n  org.apache.tomcat:tomcat-api\n  org.apache.tomcat:tomcat-util-scan\n  org.apache.tomcat:tomcat-util\n\norg.mortbay.jasper:apache-el\n  org.apache.tomcat:tomcat-jasper-el\n  org.apache.tomcat:tomcat-el-api\n\n\n------\nMortbay\n\nThe following artifacts are CDDL + GPLv2 with classpath exception.\n\nhttps://glassfish.dev.java.net/nonav/public/CDDL+GPL.html\n\norg.eclipse.jetty.toolchain:jetty-schemas\n\n------\nAssorted\n\nThe UnixCrypt.java code implements the one way cryptography used by\nUnix systems for simple password protection.  Copyright 1996 Aki Yoshida,\nmodified April 2001  by Iris Van den Broeke, Daniel Deville.\nPermission to use, copy, modify and distribute UnixCrypt\nfor non-commercial or commercial purposes and without fee is\ngranted provided that the copyright notice appears in all copies.\n\n\nApache Kafka\nCopyright 2012 The Apache Software Foundation.\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n\nApache Kerby\nCopyright 2015-2017 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n\nApache log4j\nCopyright 2010 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n\nMetrics\nCopyright 2010-2013 Coda Hale and Yammer, Inc.\n\nThis product includes software developed by Coda Hale and Yammer, Inc.\n\nThis product includes code derived from the JSR-166 project (ThreadLocalRandom, Striped64,\nLongAdder), which was released with the following comments:\n\n    Written by Doug Lea with assistance from members of JCP JSR-166\n    Expert Group and released to the public domain, as explained at\n    http://creativecommons.org/publicdomain/zero/1.0/\n\n\n\n                            The Netty Project\n                            =================\n\nPlease visit the Netty web site for more information:\n\n  * http://netty.io/\n\nCopyright 2014 The Netty Project\n\nThe Netty Project licenses this file to you under the Apache License,\nversion 2.0 (the \"License\"); you may not use this file except in compliance\nwith the License. You may obtain a copy of the License at:\n\n  http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\nWARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\nLicense for the specific language governing permissions and limitations\nunder the License.\n\nAlso, please refer to each LICENSE.<component>.txt file, which is located in\nthe 'license' directory of the distribution file, for the license terms of the\ncomponents that this product depends on.\n\n-------------------------------------------------------------------------------\nThis product contains the extensions to Java Collections Framework which has\nbeen derived from the works by JSR-166 EG, Doug Lea, and Jason T. Greene:\n\n  * LICENSE:\n    * license/LICENSE.jsr166y.txt (Public Domain)\n  * HOMEPAGE:\n    * http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/\n    * http://viewvc.jboss.org/cgi-bin/viewvc.cgi/jbosscache/experimental/jsr166/\n\nThis product contains a modified version of Robert Harder's Public Domain\nBase64 Encoder and Decoder, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.base64.txt (Public Domain)\n  * HOMEPAGE:\n    * http://iharder.sourceforge.net/current/java/base64/\n\nThis product contains a modified portion of 'Webbit', an event based\nWebSocket and HTTP server, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.webbit.txt (BSD License)\n  * HOMEPAGE:\n    * https://github.com/joewalnes/webbit\n\nThis product contains a modified portion of 'SLF4J', a simple logging\nfacade for Java, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.slf4j.txt (MIT License)\n  * HOMEPAGE:\n    * http://www.slf4j.org/\n\nThis product contains a modified portion of 'Apache Harmony', an open source\nJava SE, which can be obtained at:\n\n  * NOTICE:\n    * license/NOTICE.harmony.txt\n  * LICENSE:\n    * license/LICENSE.harmony.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * http://archive.apache.org/dist/harmony/\n\nThis product contains a modified portion of 'jbzip2', a Java bzip2 compression\nand decompression library written by Matthew J. Francis. It can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.jbzip2.txt (MIT License)\n  * HOMEPAGE:\n    * https://code.google.com/p/jbzip2/\n\nThis product contains a modified portion of 'libdivsufsort', a C API library to construct\nthe suffix array and the Burrows-Wheeler transformed string for any input string of\na constant-size alphabet written by Yuta Mori. It can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.libdivsufsort.txt (MIT License)\n  * HOMEPAGE:\n    * https://github.com/y-256/libdivsufsort\n\nThis product contains a modified portion of Nitsan Wakart's 'JCTools', Java Concurrency Tools for the JVM,\n which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.jctools.txt (ASL2 License)\n  * HOMEPAGE:\n    * https://github.com/JCTools/JCTools\n\nThis product optionally depends on 'JZlib', a re-implementation of zlib in\npure Java, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.jzlib.txt (BSD style License)\n  * HOMEPAGE:\n    * http://www.jcraft.com/jzlib/\n\nThis product optionally depends on 'Compress-LZF', a Java library for encoding and\ndecoding data in LZF format, written by Tatu Saloranta. It can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.compress-lzf.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * https://github.com/ning/compress\n\nThis product optionally depends on 'lz4', a LZ4 Java compression\nand decompression library written by Adrien Grand. It can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.lz4.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * https://github.com/jpountz/lz4-java\n\nThis product optionally depends on 'lzma-java', a LZMA Java compression\nand decompression library, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.lzma-java.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * https://github.com/jponge/lzma-java\n\nThis product contains a modified portion of 'jfastlz', a Java port of FastLZ compression\nand decompression library written by William Kinney. It can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.jfastlz.txt (MIT License)\n  * HOMEPAGE:\n    * https://code.google.com/p/jfastlz/\n\nThis product contains a modified portion of and optionally depends on 'Protocol Buffers', Google's data\ninterchange format, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.protobuf.txt (New BSD License)\n  * HOMEPAGE:\n    * https://github.com/google/protobuf\n\nThis product optionally depends on 'Bouncy Castle Crypto APIs' to generate\na temporary self-signed X.509 certificate when the JVM does not provide the\nequivalent functionality.  It can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.bouncycastle.txt (MIT License)\n  * HOMEPAGE:\n    * http://www.bouncycastle.org/\n\nThis product optionally depends on 'Snappy', a compression library produced\nby Google Inc, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.snappy.txt (New BSD License)\n  * HOMEPAGE:\n    * https://github.com/google/snappy\n\nThis product optionally depends on 'JBoss Marshalling', an alternative Java\nserialization API, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.jboss-marshalling.txt (GNU LGPL 2.1)\n  * HOMEPAGE:\n    * http://www.jboss.org/jbossmarshalling\n\nThis product optionally depends on 'Caliper', Google's micro-\nbenchmarking framework, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.caliper.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * https://github.com/google/caliper\n\nThis product optionally depends on 'Apache Commons Logging', a logging\nframework, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.commons-logging.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * http://commons.apache.org/logging/\n\nThis product optionally depends on 'Apache Log4J', a logging framework, which\ncan be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.log4j.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * http://logging.apache.org/log4j/\n\nThis product optionally depends on 'Aalto XML', an ultra-high performance\nnon-blocking XML processor, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.aalto-xml.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * http://wiki.fasterxml.com/AaltoHome\n\nThis product contains a modified version of 'HPACK', a Java implementation of\nthe HTTP/2 HPACK algorithm written by Twitter. It can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.hpack.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * https://github.com/twitter/hpack\n\nThis product contains a modified portion of 'Apache Commons Lang', a Java library\nprovides utilities for the java.lang API, which can be obtained at:\n\n  * LICENSE:\n    * license/LICENSE.commons-lang.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * https://commons.apache.org/proper/commons-lang/\n\n\nThis product contains the Maven wrapper scripts from 'Maven Wrapper', that provides an easy way to ensure a user has everything necessary to run the Maven build.\n\n  * LICENSE:\n    * license/LICENSE.mvn-wrapper.txt (Apache License 2.0)\n  * HOMEPAGE:\n    * https://github.com/takari/maven-wrapper\n\n\nThis product includes software developed by Google\n Snappy: http://code.google.com/p/snappy/ (New BSD License)\n\nThis product includes software developed by Apache\n PureJavaCrc32C from apache-hadoop-common http://hadoop.apache.org/\n (Apache 2.0 license)\n\nThis library containd statically linked libstdc++. This inclusion is allowed by\n\"GCC RUntime Library Exception\"\nhttp://gcc.gnu.org/onlinedocs/libstdc++/manual/license.html\n\n== Contributors ==\n  * Tatu Saloranta\n    * Providing benchmark suite\n  * Alec Wysoker\n    * Performance and memory usage improvement\n\n\nApache ZooKeeper\nCopyright 2009-2018 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n"
        },
        {
          "name": "NOTICE.txt",
          "type": "blob",
          "size": 1.5048828125,
          "content": "Apache Hadoop\nCopyright 2006 and onwards The Apache Software Foundation.\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\nExport Control Notice\n---------------------\n\nThis distribution includes cryptographic software.  The country in\nwhich you currently reside may have restrictions on the import,\npossession, use, and/or re-export to another country, of\nencryption software.  BEFORE using any encryption software, please\ncheck your country's laws, regulations and policies concerning the\nimport, possession, or use, and re-export of encryption software, to\nsee if this is permitted.  See <http://www.wassenaar.org/> for more\ninformation.\n\nThe U.S. Government Department of Commerce, Bureau of Industry and\nSecurity (BIS), has classified this software as Export Commodity\nControl Number (ECCN) 5D002.C.1, which includes information security\nsoftware using or performing cryptographic functions with asymmetric\nalgorithms.  The form and manner of this Apache Software Foundation\ndistribution makes it eligible for export under the License Exception\nENC Technology Software Unrestricted (TSU) exception (see the BIS\nExport Administration Regulations, Section 740.13) for both object\ncode and source code.\n\nThe following provides more details on the included cryptographic software:\n\nThis software uses the SSL libraries from the Jetty project written\nby mortbay.org.\nHadoop Yarn Server Web Proxy uses the BouncyCastle Java\ncryptography APIs written by the Legion of the Bouncy Castle Inc.\n"
        },
        {
          "name": "README.txt",
          "type": "blob",
          "size": 0.1708984375,
          "content": "For the latest information about Hadoop, please visit our website at:\n\n   http://hadoop.apache.org/\n\nand our wiki, at:\n\n   https://cwiki.apache.org/confluence/display/HADOOP/\n"
        },
        {
          "name": "dev-support",
          "type": "tree",
          "content": null
        },
        {
          "name": "hadoop-assemblies",
          "type": "tree",
          "content": null
        },
        {
          "name": "hadoop-build-tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "hadoop-client-modules",
          "type": "tree",
          "content": null
        },
        {
          "name": "hadoop-cloud-storage-project",
          "type": "tree",
          "content": null
        },
        {
          "name": "hadoop-common-project",
          "type": "tree",
          "content": null
        },
        {
          "name": "hadoop-dist",
          "type": "tree",
          "content": null
        },
        {
          "name": "hadoop-hdfs-project",
          "type": "tree",
          "content": null
        },
        {
          "name": "hadoop-mapreduce-project",
          "type": "tree",
          "content": null
        },
        {
          "name": "hadoop-maven-plugins",
          "type": "tree",
          "content": null
        },
        {
          "name": "hadoop-minicluster",
          "type": "tree",
          "content": null
        },
        {
          "name": "hadoop-project-dist",
          "type": "tree",
          "content": null
        },
        {
          "name": "hadoop-project",
          "type": "tree",
          "content": null
        },
        {
          "name": "hadoop-tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "hadoop-yarn-project",
          "type": "tree",
          "content": null
        },
        {
          "name": "licenses-binary",
          "type": "tree",
          "content": null
        },
        {
          "name": "licenses",
          "type": "tree",
          "content": null
        },
        {
          "name": "pom.xml",
          "type": "blob",
          "size": 36.9599609375,
          "content": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!--\n  Licensed under the Apache License, Version 2.0 (the \"License\");\n  you may not use this file except in compliance with the License.\n  You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\n  Unless required by applicable law or agreed to in writing, software\n  distributed under the License is distributed on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  See the License for the specific language governing permissions and\n  limitations under the License. See accompanying LICENSE file.\n-->\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\nxmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\nxsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\">\n  <modelVersion>4.0.0</modelVersion>\n  <groupId>org.apache.hadoop</groupId>\n  <artifactId>hadoop-main</artifactId>\n  <version>3.5.0-SNAPSHOT</version>\n  <description>Apache Hadoop Main</description>\n  <name>Apache Hadoop Main</name>\n  <packaging>pom</packaging>\n\n  <dependencyManagement>\n    <dependencies>\n      <dependency>\n        <groupId>com.cenqua.clover</groupId>\n        <artifactId>clover</artifactId>\n        <!-- Use the version needed by maven-clover-plugin -->\n        <version>3.0.2</version>\n      </dependency>\n    </dependencies>\n  </dependencyManagement>\n\n  <distributionManagement>\n    <repository>\n      <id>${distMgmtStagingId}</id>\n      <name>${distMgmtStagingName}</name>\n      <url>${distMgmtStagingUrl}</url>\n    </repository>\n    <snapshotRepository>\n      <id>${distMgmtSnapshotsId}</id>\n      <name>${distMgmtSnapshotsName}</name>\n      <url>${distMgmtSnapshotsUrl}</url>\n    </snapshotRepository>\n    <site>\n      <id>apache.website</id>\n      <url>scpexe://people.apache.org/www/hadoop.apache.org/docs/r${project.version}</url>\n    </site>\n  </distributionManagement>\n\n  <repositories>\n    <repository>\n      <id>${distMgmtSnapshotsId}</id>\n      <name>${distMgmtSnapshotsName}</name>\n      <url>${distMgmtSnapshotsUrl}</url>\n      <releases>\n        <enabled>false</enabled>\n      </releases>\n    </repository>\n    <repository>\n      <id>repository.jboss.org</id>\n      <url>https://repository.jboss.org/nexus/content/groups/public/</url>\n      <snapshots>\n        <enabled>false</enabled>\n      </snapshots>\n    </repository>\n  </repositories>\n\n  <licenses>\n    <license>\n      <name>Apache-2.0</name>\n      <url>https://www.apache.org/licenses/LICENSE-2.0.txt</url>\n    </license>\n  </licenses>\n\n  <organization>\n    <name>Apache Software Foundation</name>\n    <url>https://www.apache.org</url>\n  </organization>\n\n  <properties>\n    <!-- required as child projects with different version can't use ${project.version} -->\n    <hadoop.version>3.5.0-SNAPSHOT</hadoop.version>\n\n    <docker.image>apache/hadoop:${project.version}</docker.image>\n\n    <distMgmtSnapshotsId>apache.snapshots.https</distMgmtSnapshotsId>\n    <distMgmtSnapshotsName>Apache Development Snapshot Repository</distMgmtSnapshotsName>\n    <distMgmtSnapshotsUrl>https://repository.apache.org/content/repositories/snapshots</distMgmtSnapshotsUrl>\n    <distMgmtStagingId>apache.staging.https</distMgmtStagingId>\n    <distMgmtStagingName>Apache Release Distribution Repository</distMgmtStagingName>\n    <distMgmtStagingUrl>https://repository.apache.org/service/local/staging/deploy/maven2</distMgmtStagingUrl>\n\n    <!-- platform encoding override -->\n    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n    <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>\n\n    <!-- maven plugin versions -->\n    <maven-deploy-plugin.version>2.8.1</maven-deploy-plugin.version>\n    <maven-site-plugin.version>3.9.1</maven-site-plugin.version>\n    <maven-stylus-skin.version>1.5</maven-stylus-skin.version>\n    <maven-antrun-plugin.version>1.7</maven-antrun-plugin.version>\n    <maven-assembly-plugin.version>2.4</maven-assembly-plugin.version>\n    <maven-dependency-plugin.version>3.0.2</maven-dependency-plugin.version>\n    <maven-enforcer-plugin.version>3.5.0</maven-enforcer-plugin.version>\n    <restrict-imports.enforcer.version>2.0.0</restrict-imports.enforcer.version>\n    <maven-javadoc-plugin.version>3.0.1</maven-javadoc-plugin.version>\n    <maven-gpg-plugin.version>1.5</maven-gpg-plugin.version>\n    <maven-remote-resources-plugin.version>1.5</maven-remote-resources-plugin.version>\n    <maven-resources-plugin.version>3.0.1</maven-resources-plugin.version>\n    <apache-rat-plugin.version>0.12</apache-rat-plugin.version>\n    <wagon-ssh.version>2.4</wagon-ssh.version>\n    <clover-maven-plugin.version>4.4.1</clover-maven-plugin.version>\n    <maven-bundle-plugin.version>2.5.0</maven-bundle-plugin.version>\n    <lifecycle-mapping.version>1.0.0</lifecycle-mapping.version>\n    <maven-checkstyle-plugin.version>3.1.0</maven-checkstyle-plugin.version>\n    <checkstyle.version>8.29</checkstyle.version>\n    <dependency-check-maven.version>7.1.1</dependency-check-maven.version>\n    <spotbugs.version>4.2.2</spotbugs.version>\n    <spotbugs-maven-plugin.version>4.2.0</spotbugs-maven-plugin.version>\n    <jsonschema2pojo-maven-plugin.version>1.1.1</jsonschema2pojo-maven-plugin.version>\n    <maven-compiler-plugin.version>3.10.1</maven-compiler-plugin.version>\n    <cyclonedx.version>2.7.10</cyclonedx.version>\n    <docker-maven-plugin.version>0.29.0</docker-maven-plugin.version>\n\n    <shell-executable>bash</shell-executable>\n\n    <leveldbjni.group>org.fusesource.leveldbjni</leveldbjni.group>\n  </properties>\n\n  <modules>\n    <module>hadoop-project</module>\n    <module>hadoop-project-dist</module>\n    <module>hadoop-assemblies</module>\n    <module>hadoop-maven-plugins</module>\n    <module>hadoop-common-project</module>\n    <module>hadoop-hdfs-project</module>\n    <module>hadoop-yarn-project</module>\n    <module>hadoop-mapreduce-project</module>\n    <module>hadoop-tools</module>\n    <module>hadoop-dist</module>\n    <module>hadoop-minicluster</module>\n    <module>hadoop-client-modules</module>\n    <module>hadoop-build-tools</module>\n    <module>hadoop-cloud-storage-project</module>\n  </modules>\n\n  <build>\n    <pluginManagement>\n      <plugins>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-dependency-plugin</artifactId>\n          <version>${maven-dependency-plugin.version}</version>\n        </plugin>\n        <plugin>\n          <groupId>io.fabric8</groupId>\n          <artifactId>docker-maven-plugin</artifactId>\n          <version>${docker-maven-plugin.version}</version>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-enforcer-plugin</artifactId>\n          <version>${maven-enforcer-plugin.version}</version>\n          <configuration>\n            <rules>\n              <requireMavenVersion>\n                <version>[3.0.2,)</version>\n              </requireMavenVersion>\n              <requireJavaVersion>\n                <version>[1.8,)</version>\n              </requireJavaVersion>\n            </rules>\n          </configuration>\n          <dependencies>\n            <dependency>\n              <groupId>de.skuzzle.enforcer</groupId>\n              <artifactId>restrict-imports-enforcer-rule</artifactId>\n              <version>${restrict-imports.enforcer.version}</version>\n            </dependency>\n          </dependencies>\n          <executions>\n            <execution>\n              <id>banned-illegal-imports</id>\n              <phase>process-sources</phase>\n              <goals>\n                <goal>enforce</goal>\n              </goals>\n              <configuration>\n                <rules>\n                  <restrictImports>\n                    <includeTestCode>true</includeTestCode>\n                    <reason>Use hadoop-thirdparty shaded instead of curator shaded</reason>\n                    <bannedImports>\n                      <bannedImport>org.apache.curator.shaded.**</bannedImport>\n                    </bannedImports>\n                  </restrictImports>\n                  <restrictImports>\n                    <includeTestCode>true</includeTestCode>\n                    <reason>Use hadoop-common provided Sets rather than Guava provided Sets</reason>\n                    <bannedImports>\n                      <bannedImport>org.apache.hadoop.thirdparty.com.google.common.collect.Sets</bannedImport>\n                      <bannedImport>org.apache.hadoop.thirdparty.com.google.common.collect.Sets.**</bannedImport>\n                    </bannedImports>\n                  </restrictImports>\n                  <restrictImports>\n                    <includeTestCode>true</includeTestCode>\n                    <reason>Use hadoop-common provided Lists rather than Guava provided Lists</reason>\n                    <bannedImports>\n                      <bannedImport>org.apache.hadoop.thirdparty.com.google.common.collect.Lists</bannedImport>\n                      <bannedImport>org.apache.hadoop.thirdparty.com.google.common.collect.Lists.**</bannedImport>\n                    </bannedImports>\n                  </restrictImports>\n                  <restrictImports>\n                    <includeTestCode>true</includeTestCode>\n                    <reason>Use hadoop-annotation provided VisibleForTesting rather than the one provided by Guava</reason>\n                    <bannedImports>\n                      <bannedImport>org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting</bannedImport>\n                    </bannedImports>\n                  </restrictImports>\n                  <restrictImports>\n                    <includeTestCode>true</includeTestCode>\n                    <reason>Use alternatives to Guava common classes</reason>\n                    <bannedImports>\n                      <bannedImport>com.google.common.**</bannedImport>\n                    </bannedImports>\n                  </restrictImports>\n                  <restrictImports>\n                    <includeTestCode>true</includeTestCode>\n                    <reason>Use alternative to Guava provided BaseEncoding</reason>\n                    <bannedImports>\n                      <bannedImport>org.apache.hadoop.thirdparty.com.google.common.io.BaseEncoding</bannedImport>\n                      <bannedImport>org.apache.hadoop.thirdparty.com.google.common.io.BaseEncoding.**</bannedImport>\n                    </bannedImports>\n                  </restrictImports>\n                  <restrictImports>\n                    <includeTestCode>true</includeTestCode>\n                    <reason>Use java.nio.charset.StandardCharsets rather than Guava provided Charsets</reason>\n                    <bannedImports>\n                      <bannedImport>org.apache.hadoop.thirdparty.com.google.common.base.Charsets</bannedImport>\n                      <bannedImport>org.apache.hadoop.thirdparty.com.google.common.base.Charsets.**</bannedImport>\n                    </bannedImports>\n                  </restrictImports>\n                  <restrictImports>\n                    <includeTestCode>true</includeTestCode>\n                    <reason>Use alternative to Guava provided Optional</reason>\n                    <bannedImports>\n                      <bannedImport>org.apache.hadoop.thirdparty.com.google.common.base.Optional</bannedImport>\n                      <bannedImport>org.apache.hadoop.thirdparty.com.google.common.base.Optional.**</bannedImport>\n                    </bannedImports>\n                  </restrictImports>\n                  <restrictImports>\n                    <includeTestCode>true</includeTestCode>\n                    <reason>Use alternative to Guava provided Function</reason>\n                    <bannedImports>\n                      <bannedImport>org.apache.hadoop.thirdparty.com.google.common.base.Function</bannedImport>\n                      <bannedImport>org.apache.hadoop.thirdparty.com.google.common.base.Function.**</bannedImport>\n                    </bannedImports>\n                  </restrictImports>\n                  <restrictImports>\n                    <includeTestCode>true</includeTestCode>\n                    <reason>Use alternative to Guava provided Predicate</reason>\n                    <bannedImports>\n                      <bannedImport>org.apache.hadoop.thirdparty.com.google.common.base.Predicate</bannedImport>\n                      <bannedImport>org.apache.hadoop.thirdparty.com.google.common.base.Predicate.**</bannedImport>\n                    </bannedImports>\n                  </restrictImports>\n                  <restrictImports>\n                    <includeTestCode>true</includeTestCode>\n                    <reason>Use alternative to Guava provided Supplier</reason>\n                    <bannedImports>\n                      <bannedImport>org.apache.hadoop.thirdparty.com.google.common.base.Supplier</bannedImport>\n                      <bannedImport>org.apache.hadoop.thirdparty.com.google.common.base.Supplier.**</bannedImport>\n                    </bannedImports>\n                  </restrictImports>\n                  <restrictImports>\n                    <includeTestCode>true</includeTestCode>\n                    <reason>Use alternative to Guava provided ImmutableListMultimap</reason>\n                    <bannedImports>\n                      <bannedImport>org.apache.hadoop.thirdparty.com.google.common.collect.ImmutableListMultimap</bannedImport>\n                      <bannedImport>org.apache.hadoop.thirdparty.com.google.common.collect.ImmutableListMultimap.**</bannedImport>\n                    </bannedImports>\n                  </restrictImports>\n                  <restrictImports>\n                    <includeTestCode>true</includeTestCode>\n                    <reason>Use hadoop-common provided Preconditions rather than Guava provided</reason>\n                    <bannedImports>\n                      <bannedImport>org.apache.hadoop.thirdparty.com.google.common.base.Preconditions</bannedImport>\n                      <bannedImport>org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.**</bannedImport>\n                    </bannedImports>\n                  </restrictImports>\n                  <restrictImports>\n                    <includeTestCode>true</includeTestCode>\n                    <reason>Use Fasterxml Jackson 2 dependency in place of org.codehaus Jackson 1</reason>\n                    <bannedImports>\n                      <bannedImport>org.codehaus.jackson.**</bannedImport>\n                    </bannedImports>\n                  </restrictImports>\n                  <restrictImports>\n                    <includeTestCode>true</includeTestCode>\n                    <reason>Use HttpServlet APIs instead</reason>\n                    <bannedImports>\n                      <bannedImport>org.glassfish.grizzly</bannedImport>\n                      <bannedImport>org.glassfish.grizzly.**</bannedImport>\n                    </bannedImports>\n                  </restrictImports>\n                  <restrictImports>\n                    <includeTestCode>true</includeTestCode>\n                    <reason>Use slf4j based Logger</reason>\n                    <bannedImports>\n                      <bannedImport>org.apache.commons.logging.**</bannedImport>\n                    </bannedImports>\n                  </restrictImports>\n                </rules>\n              </configuration>\n            </execution>\n          </executions>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-assembly-plugin</artifactId>\n          <version>${maven-assembly-plugin.version}</version>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-deploy-plugin</artifactId>\n          <version>${maven-deploy-plugin.version}</version>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.rat</groupId>\n          <artifactId>apache-rat-plugin</artifactId>\n          <version>${apache-rat-plugin.version}</version>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-antrun-plugin</artifactId>\n          <version>${maven-antrun-plugin.version}</version>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-site-plugin</artifactId>\n          <version>${maven-site-plugin.version}</version>\n          <dependencies>\n            <dependency><!-- add support for ssh/scp -->\n              <groupId>org.apache.maven.wagon</groupId>\n              <artifactId>wagon-ssh</artifactId>\n              <version>${wagon-ssh.version}</version>\n            </dependency>\n          </dependencies>\n        </plugin>\n        <!--This plugin's configuration is used to store Eclipse m2e settings only.\n        It has no influence on the Maven build itself.-->\n        <plugin>\n          <groupId>org.eclipse.m2e</groupId>\n          <artifactId>lifecycle-mapping</artifactId>\n          <version>${lifecycle-mapping.version}</version>\n          <configuration>\n            <lifecycleMappingMetadata>\n              <pluginExecutions>\n                <pluginExecution>\n                  <pluginExecutionFilter>\n                    <groupId>org.apache.maven.plugins</groupId>\n                    <artifactId>maven-antrun-plugin</artifactId>\n                    <versionRange>[1.7,)</versionRange>\n                    <goals>\n                      <goal>run</goal>\n                    </goals>\n                  </pluginExecutionFilter>\n                  <action>\n                    <ignore></ignore>\n                  </action>\n                </pluginExecution>\n                <pluginExecution>\n                  <pluginExecutionFilter>\n                    <groupId>org.apache.maven.plugins</groupId>\n                    <artifactId>maven-resources-plugin</artifactId>\n                    <versionRange>[2.2,)</versionRange>\n                    <goals>\n                      <goal>testResources</goal>\n                      <goal>resources</goal>\n                    </goals>\n                  </pluginExecutionFilter>\n                  <action>\n                    <ignore></ignore>\n                  </action>\n                </pluginExecution>\n                <pluginExecution>\n                  <pluginExecutionFilter>\n                    <groupId>org.apache.avro</groupId>\n                    <artifactId>avro-maven-plugin</artifactId>\n                    <versionRange>[1.5.3,)</versionRange>\n                    <goals>\n                      <goal>schema</goal>\n                      <goal>protocol</goal>\n                    </goals>\n                  </pluginExecutionFilter>\n                  <action>\n                    <ignore></ignore>\n                  </action>\n                </pluginExecution>\n                <pluginExecution>\n                  <pluginExecutionFilter>\n                    <groupId>org.codehaus.mojo.jspc</groupId>\n                    <artifactId>jspc-maven-plugin</artifactId>\n                    <versionRange>[2.0-alpha-3,)</versionRange>\n                    <goals>\n                      <goal>compile</goal>\n                    </goals>\n                  </pluginExecutionFilter>\n                  <action>\n                    <ignore></ignore>\n                  </action>\n                </pluginExecution>\n                <pluginExecution>\n                  <pluginExecutionFilter>\n                    <groupId>org.apache.maven.plugins</groupId>\n                    <artifactId>maven-dependency-plugin</artifactId>\n                    <versionRange>[2.4,)</versionRange>\n                    <goals>\n                      <goal>copy-dependencies</goal>\n                      <goal>build-classpath</goal>\n                    </goals>\n                  </pluginExecutionFilter>\n                  <action>\n                    <ignore></ignore>\n                  </action>\n                </pluginExecution>\n                <pluginExecution>\n                  <pluginExecutionFilter>\n                    <groupId>org.codehaus.mojo</groupId>\n                    <artifactId>exec-maven-plugin</artifactId>\n                    <versionRange>[1.2,)</versionRange>\n                    <goals>\n                      <goal>exec</goal>\n                    </goals>\n                  </pluginExecutionFilter>\n                  <action>\n                    <ignore></ignore>\n                  </action>\n                </pluginExecution>\n                <pluginExecution>\n                  <pluginExecutionFilter>\n                    <groupId>org.apache.maven.plugins</groupId>\n                    <artifactId>maven-jar-plugin</artifactId>\n                    <versionRange>[2.3.1,)</versionRange>\n                    <goals>\n                      <goal>test-jar</goal>\n                    </goals>\n                  </pluginExecutionFilter>\n                  <action>\n                    <ignore></ignore>\n                  </action>\n                </pluginExecution>\n              </pluginExecutions>\n            </lifecycleMappingMetadata>\n          </configuration>\n        </plugin>\n        <plugin>\n          <groupId>org.openclover</groupId>\n          <artifactId>clover-maven-plugin</artifactId>\n          <version>${clover-maven-plugin.version}</version>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.felix</groupId>\n          <artifactId>maven-bundle-plugin</artifactId>\n          <version>${maven-bundle-plugin.version}</version>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-checkstyle-plugin</artifactId>\n          <version>${maven-checkstyle-plugin.version}</version>\n          <dependencies>\n            <dependency>\n              <groupId>org.apache.hadoop</groupId>\n              <artifactId>hadoop-build-tools</artifactId>\n              <version>${hadoop.version}</version>\n            </dependency>\n            <dependency>\n              <groupId>com.puppycrawl.tools</groupId>\n              <artifactId>checkstyle</artifactId>\n              <version>${checkstyle.version}</version>\n            </dependency>\n          </dependencies>\n          <configuration>\n            <configLocation>checkstyle/checkstyle.xml</configLocation>\n            <suppressionsLocation>checkstyle/suppressions.xml</suppressionsLocation>\n            <includeTestSourceDirectory>true</includeTestSourceDirectory>\n            <failOnViolation>false</failOnViolation>\n            <outputFile>${project.build.directory}/test/checkstyle-errors.xml</outputFile>\n          </configuration>\n        </plugin>\n        <plugin>\n          <groupId>org.owasp</groupId>\n          <artifactId>dependency-check-maven</artifactId>\n          <version>${dependency-check-maven.version}</version>\n        </plugin>\n        <plugin>\n          <groupId>com.github.spotbugs</groupId>\n          <artifactId>spotbugs-maven-plugin</artifactId>\n          <version>${spotbugs-maven-plugin.version}</version>\n          <dependencies>\n            <dependency>\n              <groupId>com.github.spotbugs</groupId>\n              <artifactId>spotbugs</artifactId>\n              <version>${spotbugs.version}</version>\n            </dependency>\n          </dependencies>\n        </plugin>\n        <plugin>\n          <groupId>org.jsonschema2pojo</groupId>\n          <artifactId>jsonschema2pojo-maven-plugin</artifactId>\n          <version>${jsonschema2pojo-maven-plugin.version}</version>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-compiler-plugin</artifactId>\n          <version>${maven-compiler-plugin.version}</version>\n        </plugin>\n      </plugins>\n    </pluginManagement>\n\n    <plugins>\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-enforcer-plugin</artifactId>\n        <inherited>false</inherited>\n        <executions>\n          <execution>\n            <id>clean</id>\n            <goals>\n              <goal>enforce</goal>\n            </goals>\n            <phase>pre-clean</phase>\n          </execution>\n          <execution>\n            <id>default</id>\n            <goals>\n              <goal>enforce</goal>\n            </goals>\n            <phase>validate</phase>\n          </execution>\n          <execution>\n            <id>site</id>\n            <goals>\n              <goal>enforce</goal>\n            </goals>\n            <phase>pre-site</phase>\n          </execution>\n          <execution>\n            <id>enforce-property</id>\n            <goals>\n              <goal>enforce</goal>\n            </goals>\n            <configuration>\n              <rules>\n                <requireProperty>\n                  <property>hadoop.version</property>\n                  <message>You must set a hadoop.version to be the same as ${project.version}</message>\n                  <regex>${project.version}</regex>\n                  <regexMessage>The hadoop.version property should be set and should be ${project.version}.</regexMessage>\n                </requireProperty>\n              </rules>\n              <fail>true</fail>\n              </configuration>\n          </execution>\n        </executions>\n      </plugin>\n      <plugin>\n        <groupId>org.apache.rat</groupId>\n        <artifactId>apache-rat-plugin</artifactId>\n       <configuration>\n          <excludes>\n            <exclude>.gitattributes</exclude>\n            <exclude>.gitignore</exclude>\n            <exclude>.git/**</exclude>\n            <exclude>.github/pull_request_template.md</exclude>\n            <exclude>.idea/**</exclude>\n            <exclude>**/build/**</exclude>\n            <exclude>**/patchprocess/**</exclude>\n            <exclude>**/*.js</exclude>\n            <exclude>licenses/**</exclude>\n            <exclude>licenses-binary/**</exclude>\n            <exclude>dev-support/docker/pkg-resolver/packages.json</exclude>\n            <exclude>dev-support/docker/pkg-resolver/platforms.json</exclude>\n            <exclude>**/target/**</exclude>\n         </excludes>\n       </configuration>\n      </plugin>\n      <plugin>\n        <artifactId>maven-site-plugin</artifactId>\n        <executions>\n          <execution>\n            <id>attach-descriptor</id>\n            <goals>\n              <goal>attach-descriptor</goal>\n            </goals>\n          </execution>\n        </executions>\n      </plugin>\n      <plugin>\n        <groupId>org.apache.felix</groupId>\n        <artifactId>maven-bundle-plugin</artifactId>\n        <inherited>true</inherited>\n        <extensions>true</extensions>\n      </plugin>\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-checkstyle-plugin</artifactId>\n        <version>${maven-checkstyle-plugin.version}</version>\n      </plugin>\n      <plugin>\n        <!-- OWASP's dependency-check plugin will scan the third party\n             dependencies of this project for known CVEs (security\n             vulnerabilities against them). It will produce a report\n             in target/dependency-check-report.html. To invoke, run\n             'mvn dependency-check:aggregate'. Note that this plugin\n             requires maven 3.1.1 or greater.\n        -->\n        <groupId>org.owasp</groupId>\n        <artifactId>dependency-check-maven</artifactId>\n        <version>${dependency-check-maven.version}</version>\n      </plugin>\n      <plugin>\n        <groupId>com.github.spotbugs</groupId>\n        <artifactId>spotbugs-maven-plugin</artifactId>\n      </plugin>\n      <plugin>\n        <groupId>org.cyclonedx</groupId>\n        <artifactId>cyclonedx-maven-plugin</artifactId>\n        <version>${cyclonedx.version}</version>\n      </plugin>\n    </plugins>\n  </build>\n\n  <reporting>\n    <excludeDefaults>true</excludeDefaults>\n    <plugins>\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-javadoc-plugin</artifactId>\n        <version>${maven-javadoc-plugin.version}</version>\n        <inherited>false</inherited>\n        <reportSets>\n          <reportSet>\n            <id>aggregate</id>\n            <configuration>\n              <maxmemory>1024m</maxmemory>\n              <quiet>true</quiet>\n              <verbose>false</verbose>\n              <source>${maven.compile.source}</source>\n              <charset>${maven.compile.encoding}</charset>\n              <reportOutputDirectory>${project.build.directory}/site</reportOutputDirectory>\n              <destDir>hadoop-project/api</destDir>\n              <!-- Non-public APIs -->\n              <excludePackageNames>org.apache.hadoop.authentication*,org.apache.hadoop.mapreduce.v2.proto,org.apache.hadoop.yarn.proto,org.apache.hadoop.yarn.server*,org.apache.hadoop.yarn.webapp*</excludePackageNames>\n              <groups>\n                <group>\n                  <title>Common</title>\n                  <packages>org.apache.hadoop*</packages>\n                </group>\n                <group>\n                  <title>HDFS</title>\n                  <packages>org.apache.hadoop.hdfs*</packages>\n                </group>\n                <group>\n                  <title>MapReduce</title>\n                  <packages>org.apache.hadoop.mapred*</packages>\n                </group>\n                <group>\n                  <title>YARN</title>\n                  <packages>org.apache.hadoop.yarn*</packages>\n                </group>\n              </groups>\n              <doclet>org.apache.hadoop.classification.tools.IncludePublicAnnotationsStandardDoclet</doclet>\n              <docletArtifacts>\n                <docletArtifact>\n                  <groupId>org.apache.hadoop</groupId>\n                  <artifactId>hadoop-annotations</artifactId>\n                  <version>${project.version}</version>\n                </docletArtifact>\n              </docletArtifacts>\n              <useStandardDocletOptions>true</useStandardDocletOptions>\n\n              <!-- switch on dependency-driven aggregation -->\n              <includeDependencySources>false</includeDependencySources>\n\n              <dependencySourceIncludes>\n                <!-- include ONLY dependencies I control -->\n                <dependencySourceInclude>org.apache.hadoop:hadoop-annotations</dependencySourceInclude>\n              </dependencySourceIncludes>\n\n            </configuration>\n            <reports>\n              <report>aggregate</report>\n            </reports>\n          </reportSet>\n        </reportSets>\n      </plugin>\n\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-dependency-plugin</artifactId>\n        <version>${maven-dependency-plugin.version}</version>\n        <reportSets>\n          <reportSet>\n            <reports>\n              <report>analyze-report</report>\n            </reports>\n          </reportSet>\n        </reportSets>\n      </plugin>\n    </plugins>\n  </reporting>\n\n  <profiles>\n    <profile>\n      <id>src</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <build>\n        <plugins>\n          <plugin>\n            <groupId>org.apache.maven.plugins</groupId>\n            <artifactId>maven-assembly-plugin</artifactId>\n            <inherited>false</inherited>\n            <executions>\n              <execution>\n                <id>src-dist</id>\n                <phase>package</phase>\n                <goals>\n                  <goal>single</goal>\n                </goals>\n                <configuration>\n                  <appendAssemblyId>false</appendAssemblyId>\n                  <attach>false</attach>\n                  <finalName>hadoop-${project.version}-src</finalName>\n                  <outputDirectory>hadoop-dist/target</outputDirectory>\n                  <!-- Not using descriptorRef and hadoop-assembly dependency -->\n                  <!-- to avoid making hadoop-main to depend on a module      -->\n                  <descriptors>\n                    <descriptor>hadoop-assemblies/src/main/resources/assemblies/hadoop-src.xml</descriptor>\n                  </descriptors>\n                </configuration>\n              </execution>\n            </executions>\n          </plugin>\n          <plugin>\n            <groupId>org.apache.maven.plugins</groupId>\n            <artifactId>maven-antrun-plugin</artifactId>\n            <inherited>false</inherited>\n            <executions>\n              <execution>\n                <id>src-dist-msg</id>\n                <phase>package</phase>\n                <goals>\n                  <goal>run</goal>\n                </goals>\n                <configuration>\n                  <target>\n                    <echo/>\n                    <echo>Hadoop source tar available at: ${basedir}/hadoop-dist/target/hadoop-${project.version}-src.tar.gz</echo>\n                    <echo/>\n                  </target>\n                </configuration>\n              </execution>\n            </executions>\n          </plugin>\n        </plugins>\n      </build>\n    </profile>\n\n    <profile>\n      <id>dist</id>\n      <build>\n        <plugins>\n          <plugin>\n            <groupId>org.cyclonedx</groupId>\n            <artifactId>cyclonedx-maven-plugin</artifactId>\n            <version>${cyclonedx.version}</version>\n            <executions>\n              <execution>\n                <phase>package</phase>\n                <goals>\n                  <goal>makeBom</goal>\n                </goals>\n              </execution>\n            </executions>\n            <configuration>\n              <outputFormat>xml</outputFormat>\n            </configuration>\n          </plugin>\n        </plugins>\n      </build>\n    </profile>\n\n    <profile>\n      <id>sign</id>\n      <build>\n        <plugins>\n          <plugin>\n            <groupId>org.apache.maven.plugins</groupId>\n            <artifactId>maven-gpg-plugin</artifactId>\n            <version>${maven-gpg-plugin.version}</version>\n            <executions>\n              <execution>\n                <id>sign-artifacts</id>\n                <phase>verify</phase>\n                <goals>\n                  <goal>sign</goal>\n                </goals>\n              </execution>\n            </executions>\n          </plugin>\n        </plugins>\n      </build>\n    </profile>\n    <profile>\n      <id>clover</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n        <property>\n          <name>clover</name>\n        </property>\n      </activation>\n      <properties>\n        <cloverDatabase>${project.build.directory}/clover/hadoop-coverage.db</cloverDatabase>\n        <!-- NB: This additional parametrization is made in order\n             to be able to re-define these properties with \"-Dk=v\" maven options.\n             By some reason the expressions declared in clover\n             docs like \"${maven.clover.generateHtml}\" do not work in that way.\n             However, the below properties are confirmed to work: e.g.\n             -DcloverGenHtml=false switches off the Html generation.\n             The default values provided here exactly correspond to Clover defaults, so\n             the behavior is 100% backwards compatible. -->\n        <cloverAlwaysReport>true</cloverAlwaysReport>\n        <cloverGenHtml>true</cloverGenHtml>\n        <cloverGenXml>true</cloverGenXml>\n        <cloverGenHistorical>false</cloverGenHistorical>\n      </properties>\n      <build>\n        <plugins>\n          <plugin>\n            <groupId>org.openclover</groupId>\n            <artifactId>clover-maven-plugin</artifactId>\n            <configuration>\n              <includesAllSourceRoots>false</includesAllSourceRoots>\n              <includesTestSourceRoots>true</includesTestSourceRoots>\n              <cloverDatabase>${cloverDatabase}</cloverDatabase>\n              <targetPercentage>50%</targetPercentage>\n              <outputDirectory>${project.build.directory}/clover</outputDirectory>\n              <alwaysReport>${cloverAlwaysReport}</alwaysReport>\n              <generateHtml>${cloverGenHtml}</generateHtml>\n              <generateXml>${cloverGenXml}</generateXml>\n              <generateHistorical>${cloverGenHistorical}</generateHistorical>\n              <excludes>\n                <exclude>**/examples/**/*.java</exclude>\n                <exclude>**/hamlet/*.java</exclude>\n                <exclude>**/ha/proto/*.java</exclude>\n                <exclude>**/protocol/proto/*.java</exclude>\n                <exclude>**/compiler/generated/*.java</exclude>\n                <exclude>**/protobuf/*.java</exclude>\n                <exclude>**/v2/proto/*.java</exclude>\n                <exclude>**/yarn/proto/*.java</exclude>\n                <exclude>**/security/proto/*.java</exclude>\n                <exclude>**/tools/proto/*.java</exclude>\n                <exclude>**/hs/proto/*.java</exclude>\n              </excludes>\n            </configuration>\n            <executions>\n              <execution>\n                <id>clover-setup</id>\n                <phase>process-sources</phase>\n                <goals>\n                  <goal>setup</goal>\n                </goals>\n              </execution>\n              <execution>\n                <id>clover</id>\n                <phase>test</phase>\n                <goals>\n                  <goal>clover</goal>\n                </goals>\n              </execution>\n            </executions>\n          </plugin>\n        </plugins>\n      </build>\n    </profile>\n    <profile>\n      <id>aarch64</id>\n      <properties>\n        <leveldbjni.group>org.openlabtesting.leveldbjni</leveldbjni.group>\n      </properties>\n      <activation>\n        <os>\n          <family>linux</family>\n          <arch>aarch64</arch>\n        </os>\n      </activation>\n    </profile>\n\n    <profile>\n      <id>docker-build</id>\n      <properties>\n        <docker.image>${user.name}/hadoop:${project.version}</docker.image>\n      </properties>\n    </profile>\n  </profiles>\n</project>\n"
        },
        {
          "name": "start-build-env.sh",
          "type": "blob",
          "size": 3.6328125,
          "content": "#!/usr/bin/env bash\n\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nset -e               # exit on error\n\ncd \"$(dirname \"$0\")\" # connect to root\n\nDOCKER_DIR=dev-support/docker\nDOCKER_FILE=\"${DOCKER_DIR}/Dockerfile\"\n\nCPU_ARCH=$(echo \"$MACHTYPE\" | cut -d- -f1)\nif [[ \"$CPU_ARCH\" == \"aarch64\" || \"$CPU_ARCH\" == \"arm64\" ]]; then\n  DOCKER_FILE=\"${DOCKER_DIR}/Dockerfile_aarch64\"\nfi\n\ndocker build -t hadoop-build -f $DOCKER_FILE $DOCKER_DIR\n\nUSER_NAME=${SUDO_USER:=$USER}\nUSER_ID=$(id -u \"${USER_NAME}\")\n\nif [ \"$(uname -s)\" = \"Darwin\" ]; then\n  GROUP_ID=100\nfi\n\nif [ \"$(uname -s)\" = \"Linux\" ]; then\n  GROUP_ID=$(id -g \"${USER_NAME}\")\n  # man docker-run\n  # When using SELinux, mounted directories may not be accessible\n  # to the container. To work around this, with Docker prior to 1.7\n  # one needs to run the \"chcon -Rt svirt_sandbox_file_t\" command on\n  # the directories. With Docker 1.7 and later the z mount option\n  # does this automatically.\n  if command -v selinuxenabled >/dev/null && selinuxenabled; then\n    DCKR_VER=$(docker -v|\n    awk '$1 == \"Docker\" && $2 == \"version\" {split($3,ver,\".\");print ver[1]\".\"ver[2]}')\n    DCKR_MAJ=${DCKR_VER%.*}\n    DCKR_MIN=${DCKR_VER#*.}\n    if [ \"${DCKR_MAJ}\" -eq 1 ] && [ \"${DCKR_MIN}\" -ge 7 ] ||\n        [ \"${DCKR_MAJ}\" -gt 1 ]; then\n      V_OPTS=:z\n    else\n      for d in \"${PWD}\" \"${HOME}/.m2\"; do\n        ctx=$(stat --printf='%C' \"$d\"|cut -d':' -f3)\n        if [ \"$ctx\" != svirt_sandbox_file_t ] && [ \"$ctx\" != container_file_t ]; then\n          printf 'INFO: SELinux is enabled.\\n'\n          printf '\\tMounted %s may not be accessible to the container.\\n' \"$d\"\n          printf 'INFO: If so, on the host, run the following command:\\n'\n          printf '\\t# chcon -Rt svirt_sandbox_file_t %s\\n' \"$d\"\n        fi\n      done\n    fi\n  fi\nfi\n\n# Set the home directory in the Docker container.\nDOCKER_HOME_DIR=${DOCKER_HOME_DIR:-/home/${USER_NAME}}\n\ndocker build -t \"hadoop-build-${USER_ID}\" - <<UserSpecificDocker\nFROM hadoop-build\nRUN rm -f /var/log/faillog /var/log/lastlog\nRUN groupadd --non-unique -g ${GROUP_ID} ${USER_NAME}\nRUN useradd -g ${GROUP_ID} -u ${USER_ID} -k /root -m ${USER_NAME} -d \"${DOCKER_HOME_DIR}\"\nRUN echo \"${USER_NAME} ALL=NOPASSWD: ALL\" > \"/etc/sudoers.d/hadoop-build-${USER_ID}\"\nENV HOME \"${DOCKER_HOME_DIR}\"\n\nUserSpecificDocker\n\n#If this env varible is empty, docker will be started\n# in non interactive mode\nDOCKER_INTERACTIVE_RUN=${DOCKER_INTERACTIVE_RUN-\"-i -t\"}\n\n# By mapping the .m2 directory you can do an mvn install from\n# within the container and use the result on your normal\n# system.  And this also is a significant speedup in subsequent\n# builds because the dependencies are downloaded only once.\ndocker run --rm=true $DOCKER_INTERACTIVE_RUN \\\n  -v \"${PWD}:${DOCKER_HOME_DIR}/hadoop${V_OPTS:-}\" \\\n  -w \"${DOCKER_HOME_DIR}/hadoop\" \\\n  -v \"${HOME}/.m2:${DOCKER_HOME_DIR}/.m2${V_OPTS:-}\" \\\n  -v \"${HOME}/.gnupg:${DOCKER_HOME_DIR}/.gnupg${V_OPTS:-}\" \\\n  -u \"${USER_ID}\" \\\n  \"hadoop-build-${USER_ID}\" \"$@\"\n"
        }
      ]
    }
  ]
}