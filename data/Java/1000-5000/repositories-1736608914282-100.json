{
  "metadata": {
    "timestamp": 1736608914282,
    "page": 100,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjEwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "yasserg/crawler4j",
      "stars": 4567,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 0.1083984375,
          "content": "# https://EditorConfig.org\n\n# top-most EditorConfig file\nroot = true\n\n[*]\nindent_style = space\nindent_size = 4\n"
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.1025390625,
          "content": ".DS_STORE\n.gradle\nbuild\n\n# IntelliJ IDEA\n**/*.iml\n\n# Eclipse\n.classpath\n.project\n.settings/\nbin/\ntarget/\n"
        },
        {
          "name": ".idea",
          "type": "tree",
          "content": null
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.173828125,
          "content": "sudo: required\n\nlanguage: java\n\njdk:\n    - openjdk8\n    - openjdk11\n\nservices:\n    - docker\n\nbranches:\n    only:\n        - master\n\nscript:\n    - ./gradlew testClasses checkstyle\n"
        },
        {
          "name": "CHANGES.txt",
          "type": "blob",
          "size": 5.78125,
          "content": "crawler4j Change Log\n\nVersion 4.1 (2015)\nEnhancements\n- Issue 281: Upgrade try-catch to java7 \"try with resources\"\n- Issue 214: Always log if exception happens + Some code refactoring\n- Issue 326: PageFetcher is unreadable\n- Issue 325: Remove Non official http status codes\n- Issue 238: fetchHeader Does a HTTP GET\n- Issue 149: Proper compression support in the PageFetcher\n- Issue 323: Upgrade CustomFetchStatus\n- Issue 322: WebCrawler should throw exceptions instead of returning at the middle of the method\n- Issue 321: Change logging from System.out.print to SLF4J\n- Issue 301: Upgrade the Pattern constant on the crawler examples\n\nBugFixes\n- Issue 329: Fixed relative path to the tld file (even when packed in the jar file)\n- Issue 324: NullPointerException when crawling links with no HREF\n- Issue 175: Missing IF-Statement causes crawler to throw a NullPointerException while syncing\n\n\nVersion 4.0 (December 2014)\nEnhancements\n- Issue 272: Parse Binary Content parsing, Now the crawler can really parse binary content. Based on Tero Jankilla's code\n- Issue 311: Add functionality to retrieve links from binary and text only files\n- Issue 88 & Issue 171:\tCrawling Password Protected Sites\n- Issue 213: Changed from log4j implementation to slf4j API - Removed any reference to log4j - Logging Implementations should be the user's choice and not the library choice. Instead I have inserted the slf4j API.\n- Issue 213: Upgrade all logging statements to use {} of slf4j - Slf4j optimizes string concatenation in logging statements by using {} placeholder. Upgrade all logging statements to use it.\n- Issue 312: Crawler should follow links in plain text files\n\n- Issue 278: Add hooks in the webcrawler for better error handling\n- Issue 239: Add an option to tweak the URL before processing the page Added hooks to several errors where by default we log the error but allow the user to override those methods in order to do anything they want with those URLs\n- Issue 276: Don't let a crawled URL to be dropped without proper logging. Each URL should be logged somehow so the user will know it was crawled. We shouldn't just drop URLs without logging them\n- Updated pom.xml project Dependencies were updated to their latest\n- Added log messages to PageFetcher These logs were taken from: ind9/crawler4j 153eb752bef5a57bd39016807423683ab22f3913\n- Issue 282: Add CHANGES.TXT with the changelog to the root\n- Issue 288: Upgrade Unit Tests to v4\n- Issue 289: Parsing a binary content shouldn't throw a general parsing error\n- Issue 236: Please default includeHttpsPages to true\n- Issue 273: Tabbing looks messed up in several places\n- Issue 290: We should support all redirect status codes\n- Issue 291: HtmlParseData should hold a unique list of URLs\n- Issue 133: Get the content type and prevent crawling for example feeds\n- Issue 160: Add more context in shouldVisit\n- Issue 205: Remove eclipse generated files from the repository\n- Issues 293 & 294: Grab the TLD list from the online URL Save the TLD list as a compressed file backup / fallback\n- Issue 295: Add meta tags into the parsed html object\n- Issue 297: Add tag name to WebUrl\n- Issue 225: Meta refresh does not work correctly ?\n- Issue 298: Fatal Transport Error when crawling robots.txt\n- Issue 303: Create a log configuration file default\n- Issue 174: crawler4j should support crawling all https page\n- Issue 302: Update deprecated methods/classes in PageFetcher\n- Issue 304: Crawl Site Maps\n- Issue 216: crawl JSON content instead of HTML\n\nBugFixes\n- Issue 284: Catching any exception and hiding the log. Upgraded logging in webcrawler Clarified a little statuscode 1005\n- Issue 251: Fix a typo, Fix a typo in line #92. 'cuncurrent' -> 'concurrent' \n- Issue 279: TikaException is thrown while crawling several PDFs in a row The problem was the wrong re-use of the metadata \n- Issue 139: A URL with a backslash was rejected \n- Issue 231: Memory leakage in crawler4j caused by database environment, Closing the environment solves the leak. \n- Issue 206: StringIndexOutOfBoundsException in WebURL \n- Issue 285: WebURL.java causes IndexOutOfBoundException \n- Issue 131: Internal error in WebURL\n- Issue 296: Threads not being killed in graceful shutdown\n- Issue 299: NullPointerException when trying to crawl different URLs\n\nVersion 3.5 (March 2013)\n- Fixed issues #184, #169, #136, #156, #191, #192, #127 \n- Fixed  issue #101  in normalizing Urls \n- Fixed  issue #143 : Anchor text is now provided correctly \n- Access to response headers is now provided as a field in Page object \n- Added support for handling content fetch and parsing issues. \n- Added meta refresh and location to outgoing links \n- Upgraded to Java 7 \n- Updated dependencies to their latest versions \n\nVersion 3.3\n- Updated URL canonicalizer based on RFC1808 and fixed bugs \n- Added Parent Url and Path to WebURL \n- Added support for domain and sub-domain detection. \n- Added support for handling http status codes for fetched pages \n\nVersion 3.1\n- Fixed thread-safety bug in page fetcher. \n- Improved URL canonicalizer. \n\nVersion 3.0\n- Major re-design of crawler4j to add many new features and make it extendable. \n- Multiple distinct crawlers can now run concurrently. \n- Maven support \n- Automatic detection of character encoding of pages to support crawling of non UTF-8 pages. \n- Implemented graceful shutdown of the crawlers. \n- Crawlers are now configurable through a config objects and the static crawler4j.properties file is removed. \n- Fixed several bugs in handling redirects, resuming crawling, ... \n\nVersion 2.6.1\n- Added Javadocs \n- Fixed bug in parsing robots.txt files \n\nVersion 2.6\n- Added support for robots.txt files \n- Added the feature to specify maximum number of pages to crawl \n\nVersion 2.5\n- Added support for specifying maximum crawl depth \n- Fixed bug in terminating all threads \n- Fixed bug in handling redirected pages \n- Fixed bug in handling pages with base url \n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0869140625,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2010-2018 Yasser Ganjisaffar\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 9.9609375,
          "content": "# crawler4j\n[![Build Status](https://travis-ci.org/yasserg/crawler4j.svg?branch=master)](https://travis-ci.org/yasserg/crawler4j)\n[![Maven Central](https://img.shields.io/maven-central/v/edu.uci.ics/crawler4j.svg?style=flat-square)](https://search.maven.org/search?q=g:edu.uci.ics%20a:crawler4j)\n[![Gitter Chat](http://img.shields.io/badge/chat-online-brightgreen.svg)](https://gitter.im/crawler4j/Lobby)\n\ncrawler4j is an open source web crawler for Java which provides a simple interface for\ncrawling the Web. Using it, you can setup a multi-threaded web crawler in few minutes.\n\n## Table of content\n\n- [Installation](#installation)\n- [Quickstart](#quickstart)   \n- [More Examples](#more-examples)\n- [Configuration Details](#configuration-details)\n- [License](#license)\n\n## Installation\n\n### Using Maven\n\nAdd the following dependency to your pom.xml:\n\n```xml\n    <dependency>\n        <groupId>edu.uci.ics</groupId>\n        <artifactId>crawler4j</artifactId>\n        <version>4.4.0</version>\n    </dependency>\n```\n\n### Using Gradle\n\nAdd the following dependency to your build.gradle file:\n\n    compile group: 'edu.uci.ics', name: 'crawler4j', version: '4.4.0'\n\n## Quickstart\nYou need to create a crawler class that extends WebCrawler. This class decides which URLs\nshould be crawled and handles the downloaded page. The following is a sample\nimplementation:\n```java\npublic class MyCrawler extends WebCrawler {\n\n    private final static Pattern FILTERS = Pattern.compile(\".*(\\\\.(css|js|gif|jpg\"\n                                                           + \"|png|mp3|mp4|zip|gz))$\");\n\n    /**\n     * This method receives two parameters. The first parameter is the page\n     * in which we have discovered this new url and the second parameter is\n     * the new url. You should implement this function to specify whether\n     * the given url should be crawled or not (based on your crawling logic).\n     * In this example, we are instructing the crawler to ignore urls that\n     * have css, js, git, ... extensions and to only accept urls that start\n     * with \"https://www.ics.uci.edu/\". In this case, we didn't need the\n     * referringPage parameter to make the decision.\n     */\n     @Override\n     public boolean shouldVisit(Page referringPage, WebURL url) {\n         String href = url.getURL().toLowerCase();\n         return !FILTERS.matcher(href).matches()\n                && href.startsWith(\"https://www.ics.uci.edu/\");\n     }\n\n     /**\n      * This function is called when a page is fetched and ready\n      * to be processed by your program.\n      */\n     @Override\n     public void visit(Page page) {\n         String url = page.getWebURL().getURL();\n         System.out.println(\"URL: \" + url);\n\n         if (page.getParseData() instanceof HtmlParseData) {\n             HtmlParseData htmlParseData = (HtmlParseData) page.getParseData();\n             String text = htmlParseData.getText();\n             String html = htmlParseData.getHtml();\n             Set<WebURL> links = htmlParseData.getOutgoingUrls();\n\n             System.out.println(\"Text length: \" + text.length());\n             System.out.println(\"Html length: \" + html.length());\n             System.out.println(\"Number of outgoing links: \" + links.size());\n         }\n    }\n}\n```\nAs can be seen in the above code, there are two main functions that should be overridden:\n\n- shouldVisit: This function decides whether the given URL should be crawled or not. In\nthe above example, this example is not allowing .css, .js and media files and only allows\n pages within 'www.ics.uci.edu' domain.\n- visit: This function is called after the content of a URL is downloaded successfully.\n You can easily get the url, text, links, html, and unique id of the downloaded page.\n\nYou should also implement a controller class which specifies the seeds of the crawl,\nthe folder in which intermediate crawl data should be stored and the number of concurrent\n threads:\n\n```java\npublic class Controller {\n    public static void main(String[] args) throws Exception {\n        String crawlStorageFolder = \"/data/crawl/root\";\n        int numberOfCrawlers = 7;\n\n        CrawlConfig config = new CrawlConfig();\n        config.setCrawlStorageFolder(crawlStorageFolder);\n\n        // Instantiate the controller for this crawl.\n        PageFetcher pageFetcher = new PageFetcher(config);\n        RobotstxtConfig robotstxtConfig = new RobotstxtConfig();\n        RobotstxtServer robotstxtServer = new RobotstxtServer(robotstxtConfig, pageFetcher);\n        CrawlController controller = new CrawlController(config, pageFetcher, robotstxtServer);\n\n        // For each crawl, you need to add some seed urls. These are the first\n        // URLs that are fetched and then the crawler starts following links\n        // which are found in these pages\n        controller.addSeed(\"https://www.ics.uci.edu/~lopes/\");\n        controller.addSeed(\"https://www.ics.uci.edu/~welling/\");\n    \tcontroller.addSeed(\"https://www.ics.uci.edu/\");\n    \t\n    \t// The factory which creates instances of crawlers.\n        CrawlController.WebCrawlerFactory<BasicCrawler> factory = MyCrawler::new;\n        \n        // Start the crawl. This is a blocking operation, meaning that your code\n        // will reach the line after this only when crawling is finished.\n        controller.start(factory, numberOfCrawlers);\n    }\n}\n```\n## More Examples\n- [Basic crawler](crawler4j-examples/crawler4j-examples-base/src/test/java/edu/uci/ics/crawler4j/examples/basic/): the full source code of the above example with more details.\n- [Image crawler](crawler4j-examples/crawler4j-examples-base/src/test/java/edu/uci/ics/crawler4j/examples/imagecrawler/): a simple image crawler that downloads image content from the crawling domain and stores them in a folder. This example demonstrates how binary content can be fetched using crawler4j.\n- [Collecting data from threads](crawler4j-examples/crawler4j-examples-base/src/test/java/edu/uci/ics/crawler4j/examples/localdata/): this example demonstrates how the controller can collect data/statistics from crawling threads.\n- [Multiple crawlers](crawler4j-examples/crawler4j-examples-base/src/test/java/edu/uci/ics/crawler4j/examples/multiple/): this is a sample that shows how two distinct crawlers can run concurrently. For example, you might want to split your crawling into different domains and then take different crawling policies for each group. Each crawling controller can have its own configurations.\n- [Shutdown crawling](crawler4j-examples/crawler4j-examples-base/src/test/java/edu/uci/ics/crawler4j/examples/shutdown/): this example shows how crawling can be terminated gracefully by sending the 'shutdown' command to the controller.\n- [Postgres/JDBC integration](crawler4j-examples/crawler4j-examples-postgres/): this shows how to save the crawled content into a Postgres database (or any other JDBC repository), thanks [rzo1](https://github.com/rzo1/).\n\n## Configuration Details\nThe controller class has a mandatory parameter of type [CrawlConfig](crawler4j/src/main/java/edu/uci/ics/crawler4j/crawler/CrawlConfig.java).\n Instances of this class can be used for configuring crawler4j. The following sections\ndescribe some details of configurations.\n\n### Crawl depth\nBy default there is no limit on the depth of crawling. But you can limit the depth of crawling. For example, assume that you have a seed page \"A\", which links to \"B\", which links to \"C\", which links to \"D\". So, we have the following link structure:\n\nA -> B -> C -> D\n\nSince, \"A\" is a seed page, it will have a depth of 0. \"B\" will have depth of 1 and so on. You can set a limit on the depth of pages that crawler4j crawls. For example, if you set this limit to 2, it won't crawl page \"D\". To set the maximum depth you can use:\n```java\ncrawlConfig.setMaxDepthOfCrawling(maxDepthOfCrawling);\n```\n### Enable SSL\nTo enable SSL simply:\n\n```java\nCrawlConfig config = new CrawlConfig();\n\nconfig.setIncludeHttpsPages(true);\n```\n\n### Maximum number of pages to crawl\nAlthough by default there is no limit on the number of pages to crawl, you can set a limit\non this:\n\n```java\ncrawlConfig.setMaxPagesToFetch(maxPagesToFetch);\n```\n\n### Enable Binary Content Crawling\nBy default crawling binary content (i.e. images, audio etc.) is turned off. To enable crawling these files:\n\n```java\ncrawlConfig.setIncludeBinaryContentInCrawling(true);\n```\n\nSee an example [here](crawler4j-examples/crawler4j-examples-base/src/test/java/edu/uci/ics/crawler4j/examples/imagecrawler/) for more details.\n\n### Politeness\ncrawler4j is designed very efficiently and has the ability to crawl domains very fast\n(e.g., it has been able to crawl 200 Wikipedia pages per second). However, since this\nis against crawling policies and puts huge load on servers (and they might block you!),\nsince version 1.3, by default crawler4j waits at least 200 milliseconds between requests.\nHowever, this parameter can be tuned:\n\n```java\ncrawlConfig.setPolitenessDelay(politenessDelay);\n```\n\n### Proxy\nShould your crawl run behind a proxy? If so, you can use:\n\n```java\ncrawlConfig.setProxyHost(\"proxyserver.example.com\");\ncrawlConfig.setProxyPort(8080);\n```\nIf your proxy also needs authentication:\n```java\ncrawlConfig.setProxyUsername(username);\ncrawlConfig.setProxyPassword(password);\n```\n\n### Resumable Crawling\nSometimes you need to run a crawler for a long time. It is possible that the crawler\nterminates unexpectedly. In such cases, it might be desirable to resume the crawling.\nYou would be able to resume a previously stopped/crashed crawl using the following\nsettings:\n```java\ncrawlConfig.setResumableCrawling(true);\n```\nHowever, you should note that it might make the crawling slightly slower.\n\n### User agent string\nUser-agent string is used for representing your crawler to web servers. See [here](http://en.wikipedia.org/wiki/User_agent)\nfor more details. By default crawler4j uses the following user agent string:\n\n```\n\"crawler4j (https://github.com/yasserg/crawler4j/)\"\n```\nHowever, you can overwrite it:\n```java\ncrawlConfig.setUserAgentString(userAgentString);\n```\n\n## License\n\nCopyright (c) 2010-2018 Yasser Ganjisaffar\n\nPublished under [Apache License 2.0](http://www.apache.org/licenses/LICENSE-2.0), see LICENSE\n"
        },
        {
          "name": "build.gradle",
          "type": "blob",
          "size": 1.9189453125,
          "content": "plugins {\n    id 'com.github.johnrengelman.shadow' version '4.0.4' apply false\n}\n\nwrapper {\n    gradleVersion = '5.2.1'\n    distributionType = Wrapper.DistributionType.ALL\n}\n\nallprojects {\n    apply plugin: 'idea'\n    apply plugin: 'eclipse'\n\n    group = 'edu.uci.ics'\n    version = '4.5.0-SNAPSHOT'\n}\n\nsubprojects {\n    apply plugin: 'java'\n    apply plugin: 'checkstyle'\n\n    repositories {\n        mavenCentral()\n    }\n\n    sourceCompatibility = 1.8\n    targetCompatibility = 1.8\n    tasks.withType(JavaCompile) {\n        options.encoding = 'UTF-8'\n        options.fork = true\n        options.incremental = true\n    }\n\n    tasks.withType(Javadoc) {\n        options.addStringOption('Xdoclint:none', '-quiet')\n    }\n\n    checkstyle {\n        toolVersion = '8.17'\n        configFile = new File(rootDir, 'config/checkstyle.xml')\n    }\n\n    tasks.withType(Checkstyle) {\n        reports {\n            xml.enabled false\n            html.enabled false\n        }\n    }\n\n    task checkstyle {\n        dependsOn checkstyleMain\n        dependsOn checkstyleTest\n    }\n\n    def projectName = it.name\n    tasks.withType(Test) {\n        testLogging {\n            exceptionFormat 'full'\n            testLogging { events 'skipped', 'failed', 'standardError' }\n            afterSuite { desc, result ->\n                if (!desc.parent) { // will match the outermost suite\n                    print \"Results: ${result.resultType} (${result.testCount} tests,\"\n                    print \" ${result.successfulTestCount} successes,\"\n                    print \" ${result.failedTestCount} failures,\"\n                    println \" ${result.skippedTestCount} skipped)\"\n                }\n            }\n        }\n\n        beforeTest { descriptor ->\n            logger.lifecycle(\"Starting Test: \" + descriptor)\n        }\n\n        reports {\n            junitXml.enabled = false\n            html.enabled = true\n        }\n\n        outputs.upToDateWhen { false }\n\n        jvmArgs '-Xmx2g'\n    }\n}\n"
        },
        {
          "name": "config",
          "type": "tree",
          "content": null
        },
        {
          "name": "crawler4j-examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "crawler4j",
          "type": "tree",
          "content": null
        },
        {
          "name": "gradle.properties",
          "type": "blob",
          "size": 0.146484375,
          "content": "org.gradle.caching=true\norg.gradle.parallel=true\n\n# Default values. Override these in ~/.gradle/gradle.properties\nsonatypeUsername=\nsonatypePassword=\n"
        },
        {
          "name": "gradle",
          "type": "tree",
          "content": null
        },
        {
          "name": "gradlew",
          "type": "blob",
          "size": 5.171875,
          "content": "#!/usr/bin/env sh\n\n##############################################################################\n##\n##  Gradle start up script for UN*X\n##\n##############################################################################\n\n# Attempt to set APP_HOME\n# Resolve links: $0 may be a link\nPRG=\"$0\"\n# Need this for relative symlinks.\nwhile [ -h \"$PRG\" ] ; do\n    ls=`ls -ld \"$PRG\"`\n    link=`expr \"$ls\" : '.*-> \\(.*\\)$'`\n    if expr \"$link\" : '/.*' > /dev/null; then\n        PRG=\"$link\"\n    else\n        PRG=`dirname \"$PRG\"`\"/$link\"\n    fi\ndone\nSAVED=\"`pwd`\"\ncd \"`dirname \\\"$PRG\\\"`/\" >/dev/null\nAPP_HOME=\"`pwd -P`\"\ncd \"$SAVED\" >/dev/null\n\nAPP_NAME=\"Gradle\"\nAPP_BASE_NAME=`basename \"$0\"`\n\n# Add default JVM options here. You can also use JAVA_OPTS and GRADLE_OPTS to pass JVM options to this script.\nDEFAULT_JVM_OPTS=\"\"\n\n# Use the maximum available, or set MAX_FD != -1 to use that value.\nMAX_FD=\"maximum\"\n\nwarn () {\n    echo \"$*\"\n}\n\ndie () {\n    echo\n    echo \"$*\"\n    echo\n    exit 1\n}\n\n# OS specific support (must be 'true' or 'false').\ncygwin=false\nmsys=false\ndarwin=false\nnonstop=false\ncase \"`uname`\" in\n  CYGWIN* )\n    cygwin=true\n    ;;\n  Darwin* )\n    darwin=true\n    ;;\n  MINGW* )\n    msys=true\n    ;;\n  NONSTOP* )\n    nonstop=true\n    ;;\nesac\n\nCLASSPATH=$APP_HOME/gradle/wrapper/gradle-wrapper.jar\n\n# Determine the Java command to use to start the JVM.\nif [ -n \"$JAVA_HOME\" ] ; then\n    if [ -x \"$JAVA_HOME/jre/sh/java\" ] ; then\n        # IBM's JDK on AIX uses strange locations for the executables\n        JAVACMD=\"$JAVA_HOME/jre/sh/java\"\n    else\n        JAVACMD=\"$JAVA_HOME/bin/java\"\n    fi\n    if [ ! -x \"$JAVACMD\" ] ; then\n        die \"ERROR: JAVA_HOME is set to an invalid directory: $JAVA_HOME\n\nPlease set the JAVA_HOME variable in your environment to match the\nlocation of your Java installation.\"\n    fi\nelse\n    JAVACMD=\"java\"\n    which java >/dev/null 2>&1 || die \"ERROR: JAVA_HOME is not set and no 'java' command could be found in your PATH.\n\nPlease set the JAVA_HOME variable in your environment to match the\nlocation of your Java installation.\"\nfi\n\n# Increase the maximum file descriptors if we can.\nif [ \"$cygwin\" = \"false\" -a \"$darwin\" = \"false\" -a \"$nonstop\" = \"false\" ] ; then\n    MAX_FD_LIMIT=`ulimit -H -n`\n    if [ $? -eq 0 ] ; then\n        if [ \"$MAX_FD\" = \"maximum\" -o \"$MAX_FD\" = \"max\" ] ; then\n            MAX_FD=\"$MAX_FD_LIMIT\"\n        fi\n        ulimit -n $MAX_FD\n        if [ $? -ne 0 ] ; then\n            warn \"Could not set maximum file descriptor limit: $MAX_FD\"\n        fi\n    else\n        warn \"Could not query maximum file descriptor limit: $MAX_FD_LIMIT\"\n    fi\nfi\n\n# For Darwin, add options to specify how the application appears in the dock\nif $darwin; then\n    GRADLE_OPTS=\"$GRADLE_OPTS \\\"-Xdock:name=$APP_NAME\\\" \\\"-Xdock:icon=$APP_HOME/media/gradle.icns\\\"\"\nfi\n\n# For Cygwin, switch paths to Windows format before running java\nif $cygwin ; then\n    APP_HOME=`cygpath --path --mixed \"$APP_HOME\"`\n    CLASSPATH=`cygpath --path --mixed \"$CLASSPATH\"`\n    JAVACMD=`cygpath --unix \"$JAVACMD\"`\n\n    # We build the pattern for arguments to be converted via cygpath\n    ROOTDIRSRAW=`find -L / -maxdepth 1 -mindepth 1 -type d 2>/dev/null`\n    SEP=\"\"\n    for dir in $ROOTDIRSRAW ; do\n        ROOTDIRS=\"$ROOTDIRS$SEP$dir\"\n        SEP=\"|\"\n    done\n    OURCYGPATTERN=\"(^($ROOTDIRS))\"\n    # Add a user-defined pattern to the cygpath arguments\n    if [ \"$GRADLE_CYGPATTERN\" != \"\" ] ; then\n        OURCYGPATTERN=\"$OURCYGPATTERN|($GRADLE_CYGPATTERN)\"\n    fi\n    # Now convert the arguments - kludge to limit ourselves to /bin/sh\n    i=0\n    for arg in \"$@\" ; do\n        CHECK=`echo \"$arg\"|egrep -c \"$OURCYGPATTERN\" -`\n        CHECK2=`echo \"$arg\"|egrep -c \"^-\"`                                 ### Determine if an option\n\n        if [ $CHECK -ne 0 ] && [ $CHECK2 -eq 0 ] ; then                    ### Added a condition\n            eval `echo args$i`=`cygpath --path --ignore --mixed \"$arg\"`\n        else\n            eval `echo args$i`=\"\\\"$arg\\\"\"\n        fi\n        i=$((i+1))\n    done\n    case $i in\n        (0) set -- ;;\n        (1) set -- \"$args0\" ;;\n        (2) set -- \"$args0\" \"$args1\" ;;\n        (3) set -- \"$args0\" \"$args1\" \"$args2\" ;;\n        (4) set -- \"$args0\" \"$args1\" \"$args2\" \"$args3\" ;;\n        (5) set -- \"$args0\" \"$args1\" \"$args2\" \"$args3\" \"$args4\" ;;\n        (6) set -- \"$args0\" \"$args1\" \"$args2\" \"$args3\" \"$args4\" \"$args5\" ;;\n        (7) set -- \"$args0\" \"$args1\" \"$args2\" \"$args3\" \"$args4\" \"$args5\" \"$args6\" ;;\n        (8) set -- \"$args0\" \"$args1\" \"$args2\" \"$args3\" \"$args4\" \"$args5\" \"$args6\" \"$args7\" ;;\n        (9) set -- \"$args0\" \"$args1\" \"$args2\" \"$args3\" \"$args4\" \"$args5\" \"$args6\" \"$args7\" \"$args8\" ;;\n    esac\nfi\n\n# Escape application args\nsave () {\n    for i do printf %s\\\\n \"$i\" | sed \"s/'/'\\\\\\\\''/g;1s/^/'/;\\$s/\\$/' \\\\\\\\/\" ; done\n    echo \" \"\n}\nAPP_ARGS=$(save \"$@\")\n\n# Collect all arguments for the java command, following the shell quoting and substitution rules\neval set -- $DEFAULT_JVM_OPTS $JAVA_OPTS $GRADLE_OPTS \"\\\"-Dorg.gradle.appname=$APP_BASE_NAME\\\"\" -classpath \"\\\"$CLASSPATH\\\"\" org.gradle.wrapper.GradleWrapperMain \"$APP_ARGS\"\n\n# by default we should be in the correct project dir, but when run from Finder on Mac, the cwd is wrong\nif [ \"$(uname)\" = \"Darwin\" ] && [ \"$HOME\" = \"$PWD\" ]; then\n  cd \"$(dirname \"$0\")\"\nfi\n\nexec \"$JAVACMD\" \"$@\"\n"
        },
        {
          "name": "gradlew.bat",
          "type": "blob",
          "size": 2.20703125,
          "content": "@if \"%DEBUG%\" == \"\" @echo off\r\n@rem ##########################################################################\r\n@rem\r\n@rem  Gradle startup script for Windows\r\n@rem\r\n@rem ##########################################################################\r\n\r\n@rem Set local scope for the variables with windows NT shell\r\nif \"%OS%\"==\"Windows_NT\" setlocal\r\n\r\nset DIRNAME=%~dp0\r\nif \"%DIRNAME%\" == \"\" set DIRNAME=.\r\nset APP_BASE_NAME=%~n0\r\nset APP_HOME=%DIRNAME%\r\n\r\n@rem Add default JVM options here. You can also use JAVA_OPTS and GRADLE_OPTS to pass JVM options to this script.\r\nset DEFAULT_JVM_OPTS=\r\n\r\n@rem Find java.exe\r\nif defined JAVA_HOME goto findJavaFromJavaHome\r\n\r\nset JAVA_EXE=java.exe\r\n%JAVA_EXE% -version >NUL 2>&1\r\nif \"%ERRORLEVEL%\" == \"0\" goto init\r\n\r\necho.\r\necho ERROR: JAVA_HOME is not set and no 'java' command could be found in your PATH.\r\necho.\r\necho Please set the JAVA_HOME variable in your environment to match the\r\necho location of your Java installation.\r\n\r\ngoto fail\r\n\r\n:findJavaFromJavaHome\r\nset JAVA_HOME=%JAVA_HOME:\"=%\r\nset JAVA_EXE=%JAVA_HOME%/bin/java.exe\r\n\r\nif exist \"%JAVA_EXE%\" goto init\r\n\r\necho.\r\necho ERROR: JAVA_HOME is set to an invalid directory: %JAVA_HOME%\r\necho.\r\necho Please set the JAVA_HOME variable in your environment to match the\r\necho location of your Java installation.\r\n\r\ngoto fail\r\n\r\n:init\r\n@rem Get command-line arguments, handling Windows variants\r\n\r\nif not \"%OS%\" == \"Windows_NT\" goto win9xME_args\r\n\r\n:win9xME_args\r\n@rem Slurp the command line arguments.\r\nset CMD_LINE_ARGS=\r\nset _SKIP=2\r\n\r\n:win9xME_args_slurp\r\nif \"x%~1\" == \"x\" goto execute\r\n\r\nset CMD_LINE_ARGS=%*\r\n\r\n:execute\r\n@rem Setup the command line\r\n\r\nset CLASSPATH=%APP_HOME%\\gradle\\wrapper\\gradle-wrapper.jar\r\n\r\n@rem Execute Gradle\r\n\"%JAVA_EXE%\" %DEFAULT_JVM_OPTS% %JAVA_OPTS% %GRADLE_OPTS% \"-Dorg.gradle.appname=%APP_BASE_NAME%\" -classpath \"%CLASSPATH%\" org.gradle.wrapper.GradleWrapperMain %CMD_LINE_ARGS%\r\n\r\n:end\r\n@rem End local scope for the variables with windows NT shell\r\nif \"%ERRORLEVEL%\"==\"0\" goto mainEnd\r\n\r\n:fail\r\nrem Set variable GRADLE_EXIT_CONSOLE if you need the _script_ return code instead of\r\nrem the _cmd.exe /c_ return code!\r\nif  not \"\" == \"%GRADLE_EXIT_CONSOLE%\" exit 1\r\nexit /b 1\r\n\r\n:mainEnd\r\nif \"%OS%\"==\"Windows_NT\" endlocal\r\n\r\n:omega\r\n"
        },
        {
          "name": "settings.gradle",
          "type": "blob",
          "size": 0.4189453125,
          "content": "rootProject.name = 'crawler4j-parent'\n\ninclude ':crawler4j'\ninclude ':crawler4j-examples-base'\ninclude ':crawler4j-examples-postgres'\n\nproject(':crawler4j').projectDir = \"$rootDir/crawler4j\" as File\nproject(':crawler4j-examples-base').projectDir = \"$rootDir/crawler4j-examples/crawler4j-examples-base\" as File\nproject(':crawler4j-examples-postgres').projectDir = \"$rootDir/crawler4j-examples/crawler4j-examples-postgres\" as File\n"
        }
      ]
    }
  ]
}