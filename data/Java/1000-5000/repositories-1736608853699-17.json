{
  "metadata": {
    "timestamp": 1736608853699,
    "page": 17,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjIw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "strimzi/strimzi-kafka-operator",
      "stars": 4942,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".azure",
          "type": "tree",
          "content": null
        },
        {
          "name": ".checkstyle",
          "type": "tree",
          "content": null
        },
        {
          "name": ".checksums",
          "type": "blob",
          "size": 1.3916015625,
          "content": "#!/usr/bin/env bash\n\n### IMPORTANT ###\n# if the below line has changed, this means the ./helm-charts directory has changed\n#   the checksum and ./helm-charts directory should only be modified on official releases as part of a release\n# if this checksum has changed as part of any non-release specific changes, please apply your changes to the\n#   development version of the helm charts in ./packaging/helm-charts\n### IMPORTANT ###\nHELM_CHART_CHECKSUM=\"136da6359a2b29c9aaf96fb3f0288aa379743e83  -\"\n\n### IMPORTANT ###\n# if the below line has changed, this means the ./install directory has changed\n#   the checksum and ./install directory should only be modified on official releases as part of a release\n# if this checksum has changed as part of any non-release specific changes, please apply your changes to the\n#   development version of the helm charts in ./packaging/install\n### IMPORTANT ###\nINSTALL_CHECKSUM=\"375c9b558fa0b01b0e7e77ebc49f975a83ec4526  -\"\n\n### IMPORTANT ###\n# if the below line has changed, this means the ./examples directory has changed\n#   the checksum and ./examples directory should only be modified on official releases as part of a release\n# if this checksum has changed as part of any non-release specific changes, please apply your changes to the\n#   development version of the helm charts in ./packaging/examples\n### IMPORTANT ###\nEXAMPLES_CHECKSUM=\"8b8d688379102e88c258a5f164ab7b878869982f  -\"\n"
        },
        {
          "name": ".fmf",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.357421875,
          "content": "# Set default behaviour, in case users don't have core.autocrlf set.\n* text=auto\n\n# Explicitly declare text files we want to always be normalized and converted \n# to native line endings on checkout.\n*.java text\n\n# Always lf ending\n*.sh text eol=lf\n*.bash text eol=lf\n*.properties text eol=lf\n*.json text eol=lf\n*.xml text eol=lf\n*.txt text eol=lf\n*.yaml text eol=lf\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.197265625,
          "content": "# Maven build targets\ntarget/\n\n# Maven release files\n*.releaseBackup\nrelease.properties\n\n# Eclipse specific\n.project\n.settings/\n.prefs\n.classpath\n.apt_generated/\n.apt_generated_tests/\n\n# IntelliJ IDEA specific\n.idea/\n*.iml\n\n# VS Code\n.factorypath\n.vscode\n\n# Velocity.log\nvelocity.log\n\n# Generated docs\ndocumentation/html/**\ndocumentation/pdf/**\ndocumentation/htmlnoheader/**\ndocumentation/**/build/**\nmaster.html\n\nhelm-charts/helm3/strimzi-kafka-operator-*.*.*.tgz\npackaging/helm-charts/helm3/strimzi-kafka-operator-*.*.*.tgz\n\ndocker-images/artifacts/binaries\ndocker-images/container-archives\ndocker-images/kafka-based/kafka/.*.tmp\ndocker-images/kafka-based/kafka/tmp/**\ndocker-images/operator/.*.tmp\ndocker-images/operator/tmp/**\n\n\n# Connect plugin (tests)\nsystemtest/*.tar.gz\nsystemtest/my-plugins/\nsystemtest/scripts/results.json\n\n# MacOS Desktop Services Store files\n**/.DS_Store\n\n# Hacking directory with different script utilities and more complex YAML examples used by developers for development and testing\n/hacking/\n\n# virtual machine crash logs, see http://www.java.com/en/download/help/error_hotspot.xml\nhs_err_pid*\n\n# Cluster operator config models\n**/cluster-operator/src/main/resources/kafka-*-config-model.json\n"
        },
        {
          "name": ".jenkins",
          "type": "tree",
          "content": null
        },
        {
          "name": ".packit.yaml",
          "type": "blob",
          "size": 8.0400390625,
          "content": "# Default packit instance is a prod and only this is used\n# stg instance is present for testing new packit features in forked repositories where stg is installed.\npackit_instances: [\"prod\", \"stg\"]\nupstream_project_url: https://github.com/strimzi/strimzi-kafka-operator\nissue_repository: https://github.com/strimzi/strimzi-kafka-operator\njobs:\n  - job: tests\n    trigger: pull_request\n    # Suffix for job name\n    identifier: \"automation-check\"\n    targets:\n      # This target is not used at all by our tests, but it has to be one of the available - https://packit.dev/docs/configuration/#aliases\n      - centos-stream-9-x86_64\n      - centos-stream-9-aarch64\n    # We don't need to build any packages for Fedora/RHEL/CentOS, it is not related to Strimzi tests\n    skip_build: true\n    manual_trigger: true\n    env: { IP_FAMILY: ipv4 }\n    labels:\n      - smoke\n      - automation-check\n    tf_extra_params:\n      test:\n        tmt:\n          name: smoke\n  ###############################################################################################\n\n  - job: tests\n    trigger: pull_request\n    identifier: \"upgrade\"\n    targets:\n      - centos-stream-9-x86_64\n      - centos-stream-9-aarch64\n    skip_build: true\n    manual_trigger: true\n    env: { IP_FAMILY: ipv4 }\n    labels:\n      - upgrade\n    tf_extra_params:\n      test:\n        tmt:\n          name: upgrade\n  ###############################################################################################\n\n  - job: tests\n    trigger: pull_request\n    identifier: \"regression-operators\"\n    targets:\n      - centos-stream-9-x86_64\n      - centos-stream-9-aarch64\n    skip_build: true\n    manual_trigger: true\n    env: { IP_FAMILY: ipv4 }\n    labels:\n      - regression\n      - operators\n      - regression-operators\n    tf_extra_params:\n      test:\n        tmt:\n          name: regression-operators\n  ###############################################################################################\n\n  - job: tests\n    trigger: pull_request\n    identifier: \"regression-brokers-and-security\"\n    targets:\n      - centos-stream-9-x86_64\n      - centos-stream-9-aarch64\n    skip_build: true\n    manual_trigger: true\n    env: { IP_FAMILY: ipv4 }\n    labels:\n      - regression\n      - brokers-and-security\n      - regression-brokers-and-security\n      - bas\n    tf_extra_params:\n      test:\n        tmt:\n          name: regression-brokers-and-security\n\n  - job: tests\n    trigger: pull_request\n    identifier: \"regression-operands\"\n    targets:\n      - centos-stream-9-x86_64\n      - centos-stream-9-aarch64\n    skip_build: true\n    manual_trigger: true\n    env: { IP_FAMILY: ipv4 }\n    labels:\n      - regression\n      - operands\n      - regression-operands\n    tf_extra_params:\n      test:\n        tmt:\n          name: regression-operands\n  ###############################################################################################\n\n  - job: tests\n    trigger: pull_request\n    identifier: \"acceptance\"\n    targets:\n      - centos-stream-9-x86_64\n      - centos-stream-9-aarch64\n    skip_build: true\n    manual_trigger: true\n    env: { IP_FAMILY: ipv4 }\n    labels:\n      - acceptance\n    tf_extra_params:\n      test:\n        tmt:\n          name: acceptance\n  ###############################################################################################\n\n  - job: tests\n    trigger: pull_request\n    identifier: \"sanity\"\n    targets:\n      - centos-stream-9-x86_64\n      - centos-stream-9-aarch64\n    skip_build: true\n    manual_trigger: true\n    env: { IP_FAMILY: ipv4 }\n    labels:\n      - sanity\n    tf_extra_params:\n      test:\n        tmt:\n          name: sanity\n\n  ###############################################################################################\n  ##################################    IPv6/dual jobs   ########################################\n  ###############################################################################################\n  - job: tests\n    trigger: pull_request\n    identifier: \"acceptance_ipv6\"\n    targets:\n      - centos-stream-9-x86_64\n      - centos-stream-9-aarch64\n    skip_build: true\n    manual_trigger: true\n    env: { IP_FAMILY: ipv6 }\n    labels:\n      - acceptance_ipv6\n      - ipv6\n    tf_extra_params:\n      test:\n        tmt:\n          name: acceptance\n  ###############################################################################################\n  - job: tests\n    trigger: pull_request\n    identifier: \"acceptance_dual\"\n    targets:\n      - centos-stream-9-x86_64\n      - centos-stream-9-aarch64\n    skip_build: true\n    manual_trigger: true\n    env: { IP_FAMILY: dual }\n    labels:\n      - acceptance_dual\n      - dual\n    tf_extra_params:\n      test:\n        tmt:\n          name: acceptance\n  ###############################################################################################\n  ####################################    Performance   #########################################\n  ###############################################################################################\n  - job: tests\n    trigger: pull_request\n    identifier: \"performance\"\n    targets:\n      - centos-stream-9-x86_64\n      - centos-stream-9-aarch64\n    skip_build: true\n    manual_trigger: true\n    env: { IP_FAMILY: ipv4 }\n    labels:\n      - performance\n      - performance-common\n    tf_extra_params:\n      settings:\n        pipeline:\n          timeout: 1440\n      test:\n        tmt:\n          name: performance\n  - job: tests\n    trigger: pull_request\n    identifier: \"capacity\"\n    targets:\n      - centos-stream-9-x86_64\n      - centos-stream-9-aarch64\n    skip_build: true\n    manual_trigger: true\n    env: { IP_FAMILY: ipv4 }\n    labels:\n      - capacity\n    tf_extra_params:\n      test:\n        tmt:\n          name: capacity\n\n  ##############################################################################################\n  ####################################     Releases    #########################################\n  ##############################################################################################\n  - job: tests\n    trigger: release\n    identifier: \"upgrade\"\n    targets:\n      - centos-stream-9-x86_64\n      - centos-stream-9-aarch64\n    skip_build: true\n    manual_trigger: false\n    env:\n      IP_FAMILY: ipv4\n      RELEASE: true\n    labels:\n      - upgrade\n    tf_extra_params:\n      test:\n        tmt:\n          name: upgrade\n  ###############################################################################################\n\n  - job: tests\n    trigger: release\n    identifier: \"regression-operators\"\n    targets:\n      - centos-stream-9-x86_64\n      - centos-stream-9-aarch64\n    skip_build: true\n    manual_trigger: false\n    env:\n      IP_FAMILY: ipv4\n      RELEASE: true\n    labels:\n      - regression\n      - operators\n      - regression-operators\n    tf_extra_params:\n      test:\n        tmt:\n          name: regression-operators\n  ###############################################################################################\n\n  - job: tests\n    trigger: release\n    identifier: \"regression-brokers-and-security\"\n    targets:\n      - centos-stream-9-x86_64\n      - centos-stream-9-aarch64\n    skip_build: true\n    manual_trigger: false\n    env:\n      IP_FAMILY: ipv4\n      RELEASE: true\n    labels:\n      - regression\n      - brokers-and-security\n      - regression-brokers-and-security\n      - bas\n    tf_extra_params:\n      test:\n        tmt:\n          name: regression-brokers-and-security\n\n  - job: tests\n    trigger: release\n    identifier: \"regression-operands\"\n    targets:\n      - centos-stream-9-x86_64\n      - centos-stream-9-aarch64\n    skip_build: true\n    manual_trigger: false\n    env:\n      IP_FAMILY: ipv4\n      RELEASE: true\n    labels:\n      - regression\n      - operands\n      - regression-operands\n    tf_extra_params:\n      test:\n        tmt:\n          name: regression-operands\n\n  - job: tests\n    trigger: release\n    identifier: \"performance\"\n    targets:\n      - centos-stream-9-x86_64\n      - centos-stream-9-aarch64\n    skip_build: true\n    manual_trigger: false\n    env:\n        IP_FAMILY: ipv4\n        RELEASE: true\n    labels:\n      - performance\n      - performance-common\n    tf_extra_params:\n      test:\n        tmt:\n          name: performance"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.3515625,
          "content": "# See https://pre-commit.com for more information\n# See https://pre-commit.com/hooks.html for more hooks\nrepos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v3.2.0\n    hooks:\n      - id: trailing-whitespace\n        files: '^packaging/examples/.*(yaml|yml)$'\n      - id: end-of-file-fixer\n        files: '^packaging/examples/.*(yaml|yml)$'\n"
        },
        {
          "name": ".spotbugs",
          "type": "tree",
          "content": null
        },
        {
          "name": "ADOPTERS.md",
          "type": "blob",
          "size": 1.8134765625,
          "content": "## Strimzi adopters\n\n* [Axual](https://axual.com/)\n    * [Optimizing Kafka Cluster Deployments in Kubernetes](https://itnext.io/optimizing-kafka-cluster-deployments-in-kubernetes-ceda3f95c157)\n* [Grupo MASMOVIL](https://www.grupomasmovil.com/)\n* [Helvetia](https://helvetia.com/)\n* [Baloise](https://baloise.ch/)\n* [IBM](https://www.ibm.com/cloud/event-streams)\n* [Lightbend](https://www.lightbend.com/)\n* [Marlow Navigation](https://marlow-navigation.com/)\n* [Red Hat](https://www.redhat.com/en/)\n    * [AMQ Streams](https://www.redhat.com/en/resources/amq-streams-datasheet)\n* [SBB CFF FFS](https://www.sbb.ch/en/home.html)\n* [Swisscom](https://www.swisscom.ch/)\n* [CN Group](https://www.cngroup.dk/)\n* [Atruvia](https://atruvia.de/)\n* [Procure Ai](https://www.procure.ai/)\n* [LittleHorse](https://littlehorse.dev/)\n* [Decathlon](https://digital.decathlon.net/)\n    * [Seamless data exchange with Kafka Connect and Strimzi on Kubernetes at Decathlon](https://medium.com/decathlondigital/seamless-data-exchange-with-kafka-connect-and-strimzi-on-kubernetes-at-decathlon-e6f81d034535)\n* [Skillsoft](https://www.skillsoft.com/)\n    * Utilizes Strimzi to deploy Kafka Connect on Kubernetes for Apache Kafka backup & disaster recovery.\n* [Hetzner](https://www.hetzner.com/)\n* [Ænix](https://aenix.io)\n    * Use Strimzi to provide Kafka as a Service in Open Source platform [Cozystack](https://cozystack.io)\n* [Reddit](https://www.reddit.com/r/RedditEng/)\n    * Use Strimzi to run their Kafka fleet of 500 brokers, data replication with Mirror Maker and CDC pipelines with Kafka Connect. \n* [Alauda](https://www.alauda.io/)\n    * Use Strimzi to provide Kafka as a Service on a cloud native platform\n\nAre you currently using Strimzi in production?\nPlease let us know by adding your company name and, if you want, a description of your use case to this document!\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 74.1943359375,
          "content": "# CHANGELOG\n\n## 0.46.0\n\n* Support for ZooKeeper-based Apache Kafka clusters and for KRaft migration has been removed\n* Support for MirrorMaker 1 has been removed\n* Added support to configure `dnsPolicy` and `dnsConfig` using the `template` sections.\n\n### Major changes, deprecations and removals\n\n* **Support for ZooKeeper-based clusters and for migration from ZooKeeper-based clusters to KRaft has been removed.**\n  **Please make sure all your clusters are using KRaft before upgrading to Strimzi 0.46.0 or newer!**\n* Support for MirrorMaker 1 has been removed.\n  Please make sure to migrate to MirrorMaker 2 before upgrading to Strimzi 0.46 or newer.\n* [Strimzi EnvVar Configuration Provider](https://github.com/strimzi/kafka-env-var-config-provider) (deprecated in Strimzi 0.38.0) and [Strimzi MirrorMaker 2 Extensions](https://github.com/strimzi/mirror-maker-2-extensions) (deprecated in Strimzi 0.28.0) plugins were removed from Strimzi container images.\n  Please use the Apache Kafka [EnvVarConfigProvider](https://github.com/strimzi/kafka-env-var-config-provider?tab=readme-ov-file#deprecation-notice) and [Identity Replication Policy](https://github.com/strimzi/mirror-maker-2-extensions?tab=readme-ov-file#identity-replication-policy) instead.\n* When using Kafka Connect or Kafka MirrorMaker 2 operands and upgrading from Strimzi 0.38 or older, make sure the `StableConnectIdentities` feature gate is enabled and `StrimziPodSets` are used before upgrading.\n* When using the Kafka operand and upgrading from Strimzi 0.34 or older, make sure the `UseStrimziPodSets` feature gate is enabled and `StrimziPodSet` resources are used before upgrading.\n\n## 0.45.0\n\n* Add support for Kafka 3.9.0 and 3.8.1. \n  Remove support for Kafka 3.7.0 and 3.7.1\n* Ability to move data between JBOD disks using Cruise Control.\n* Allow using custom certificates for communication with container registry in Kafka Connect Build with Kaniko \n* Only roll pods once for ClientsCa cert renewal.\n  This change also means the restart reason ClientCaCertKeyReplaced is removed and either CaCertRenewed or CaCertHasOldGeneration will be used.\n* Allow rolling update for new cluster CA trust (during Cluster CA key replacement) to continue where it left off before interruption without rolling all pods again.\n* Update HTTP bridge to 0.31.1\n* Add support for mounting CSI volumes using the `template` sections\n\n### Major changes, deprecations and removals\n\n* **Strimzi 0.45 is the last minor Strimzi version with support for ZooKeeper-based Apache Kafka clusters and MirrorMaker 1 deployments.**\n  **Please make sure to [migrate to KRaft](https://strimzi.io/docs/operators/latest/full/deploying.html#assembly-kraft-mode-str) and MirrorMaker 2 before upgrading to Strimzi 0.46 or newer.**\n* **Strimzi 0.45 is the last Strimzi version to include the [Strimzi EnvVar Configuration Provider](https://github.com/strimzi/kafka-env-var-config-provider) (deprecated in Strimzi 0.38.0) and [Strimzi MirrorMaker 2 Extensions](https://github.com/strimzi/mirror-maker-2-extensions) (deprecated in Strimzi 0.28.0).**\n  Please use the Apache Kafka [EnvVarConfigProvider](https://github.com/strimzi/kafka-env-var-config-provider?tab=readme-ov-file#deprecation-notice) and [Identity Replication Policy](https://github.com/strimzi/mirror-maker-2-extensions?tab=readme-ov-file#identity-replication-policy) instead. \n\n## 0.44.0\n\n* Add the \"Unmanaged\" KafkaTopic status update.\n* The `ContinueReconciliationOnManualRollingUpdateFailure` feature gate moves to beta stage and is enabled by default.\n  If needed, `ContinueReconciliationOnManualRollingUpdateFailure` can be disabled in the feature gates configuration in the Cluster Operator.\n* Add support for managing connector offsets via KafkaConnector and KafkaMirrorMaker2 custom resources.\n* Add support for templating `host` and `advertisedHost` fields in listener configuration.\n* Allow configuration of environment variables based on Config Map or Secret for every container in the container template sections.\n* Add support for disabling the generation of PodDisruptionBudget resources by the Cluster Operator.\n* Add support for running an automatic rebalancing, via Cruise Control, when the cluster is scaled down or up:\n  * after a scaling up, the operator triggers an auto-rebalancing for moving some of the existing partitions to the newly added brokers.\n  * before scaling down, and if the brokers to remove are hosting partitions, the operator triggers an auto-rebalancing to these partitions off the brokers to make them free to be removed.\n* Strimzi Access Operator 0.1.0 added to the installation files and examples\n\n### Changes, deprecations and removals\n\n* **From Strimzi 0.44.0 on, we support only Kubernetes 1.25 and newer.**\n  Kubernetes 1.23 and 1.24 are not supported anymore.\n* When finalizers are enabled (default), the Topic Operator will no longer restore finalizers on unmanaged `KafkaTopic` resources if they are removed, aligning the behavior with paused topics, where finalizers are also not restored.\n  This change matches user expectations.\n* The External Configuration (`.spec.externalConfiguration`) in `KafkaConnect` and `KafkaMirrorMaker2` resources is deprecated and will be removed in the future.\n  Please use the environment variables, additional volumes and volume mounts in Pod and container templates instead.\n* The Strimzi Canary installation files were removed based on the [_Strimzi proposal 086_](https://github.com/strimzi/proposals/blob/main/086-archive-canary.md) as the project was discontinued and archived.\n\n## 0.43.0\n\n* Add support for Apache Kafka 3.8.0.\n  Remove support for Apache Kafka 3.6.0, 3.6.1, and 3.6.2.\n* Added alerts for Connectors/Tasks in failed state.\n* Support for specifying additional volumes and volume mounts in Strimzi custom resources\n* Strimzi Drain Cleaner updated to 1.2.0 (included in the Strimzi installation files)\n* Additional OAuth configuration options have been added for 'oauth' authentication on the listener and the client. \n  On the listener `serverBearerTokenLocation` and `userNamePrefix` have been added. \n  On the client `accessTokenLocation`, `clientAssertion`, `clientAssertionLocation`, `clientAssertionType`, and `saslExtensions` have been added.\n* Add support for custom Cruise Control API users\n* Update HTTP bridge to latest 0.30.0 release\n* Unregistration of KRaft nodes after scale-down\n* Update Kafka Exporter to [1.8.0](https://github.com/danielqsj/kafka_exporter/releases/tag/v1.8.0) and update the Grafana dashboard to work with it\n\n### Changes, deprecations and removals\n\n* The storage overrides for configuring per-broker storage class are deprecated and will be removed in the future.\n  If you are using the storage overrides, you should migrate to KafkaNodePool resources and use multiple node pools with a different storage class each. \n* Strimzi 0.43.0 (and any of its patch releases) is the last Strimzi version with support for Kubernetes 1.23 and 1.24.\n  From Strimzi 0.44.0 on, we will support only Kubernetes 1.25 and newer.\n\n## 0.42.0\n\n* Add support for Kafka 3.7.1\n* The `UseKRaft` feature gate moves to GA stage and is permanently enabled without the possibility to disable it.\n  To use KRaft (ZooKeeper-less Apache Kafka), you still need to use the `strimzi.io/kraft: enabled` annotation on the `Kafka` custom resources or migrate from an existing ZooKeeper-based cluster.\n* Update the base image used by Strimzi containers from UBI8 to UBI9\n* Add support for filename patterns when configuring trusted certificates\n* Enhance `KafkaBridge` resource with consumer inactivity timeout and HTTP consumer/producer enablement.\n* Add support for feature gates to User and Topic Operators\n* Add support for setting `publishNotReadyAddresses` on services for listener types other than internal.\n* Update HTTP bridge to latest 0.29.0 release\n* Uncommented and enabled (by default) KRaft-related metrics in the `kafka-metrics.yaml` example file.\n* Added support for configuring the quotas plugin with type `strimzi` or `kafka` in the `Kafka` custom resource.\n  The Strimzi Quotas plugin version was updated to 0.3.1.\n\n### Changes, deprecations and removals\n\n* The `reconciliationIntervalSeconds` configuration for the Topic and User Operators is deprecated, and will be removed when upgrading schemas to v1.\n  Use `reconciliationIntervalMs` converting the value to milliseconds.\n* Usage of Strimzi Quotas plugin version 0.2.0 is not supported, the plugin was updated to 0.3.1 and changed significantly.\n  Additionally, from Strimzi 0.42.0 the plugin should be configured in `.spec.kafka.quotas` section - the configuration of the plugin inside `.spec.kafka.config` is ignored and should be removed.\n\n## 0.41.0\n\n* Add support for Apache Kafka 3.6.2\n* Provide metrics to monitor certificates expiration as well as modified `Strimzi Operators` dashboard to include certificate expiration per cluster.\n* Add support for JBOD storage in KRaft mode.\n  (Note: JBOD support in KRaft mode is considered early-access in Apache Kafka 3.7.x)\n* Added support for topic replication factor change to the Unidirectional Topic Operator when Cruise Control integration is enabled.\n* The `KafkaNodePools` feature gate moves to GA stage and is permanently enabled without the possibility to disable it.\n  To use the Kafka Node Pool resources, you still need to use the `strimzi.io/node-pools: enabled` annotation on the `Kafka` custom resources.\n* Added support for configuring the `externalIPs` field in node port type services.\n* The `UnidirectionalTopicOperator` feature gate moves to GA stage and is permanently enabled without the possibility to disable it.\n  If the topics whose names start with `strimzi-store-topic` and `strimzi-topic-operator` still exist, you can delete them.\n* Don't allow MirrorMaker2 mirrors with target set to something else than the connect cluster. \n* Added support for custom SASL config in standalone Topic Operator deployment to support alternate access controllers (i.e. `AWS_MSK_IAM`)\n* Remove Angular dependent plugins from Grafana example dashboard. This makes our dashboard compatible with Grafana 7.4.5 and higher.\n* Continue reconciliation after failed manual rolling update using the `strimzi.io/manual-rolling-update` annotation (when the `ContinueReconciliationOnManualRollingUpdateFailure` feature gate is enabled).\n\n### Changes, deprecations and removals\n\n* The `tlsSidecar` configuration for the Entity Operator is now deprecated and will be ignored.\n* The `zookeeperSessionTimeoutSeconds` and `topicMetadataMaxAttempts` configurations for the Entity Topic Operator have been removed and will be ignored.\n\n## 0.40.0\n\n* Add support for Apache Kafka 3.7.0.\n  Remove support for Apache Kafka 3.5.0, 3.5.1, and 3.5.2.\n* The `UseKRaft` feature gate moves to beta stage and is enabled by default.\n  If needed, `UseKRaft` can be disabled in the feature gates configuration in the Cluster Operator.\n* Add support for ZooKeeper to KRaft migration by enabling the users to move from using ZooKeeper to store metadata to use KRaft.\n* Add support for moving from dedicated controller-only KRaft nodes to mixed KRaft nodes\n* Fix NullPointerException from missing listenerConfig when using custom auth\n* Added support for Kafka Exporter `offset.show-all` parameter\n* Prevent removal of the `broker` process role from KRaft mixed-nodes that have assigned partition-replicas\n* Improve broker scale-down prevention to continue in reconciliation when scale-down cannot be executed\n* Added support for Tiered Storage by enabling the configuration of custom storage plugins through the Kafka custom resource.\n* Update HTTP bridge to latest 0.28.0 release\n\n### Changes, deprecations and removals\n\n* **From Strimzi 0.40.0 on, we support only Kubernetes 1.23 and newer.**\n  Kubernetes 1.21 and 1.22 are not supported anymore.\n* [#9508](https://github.com/strimzi/strimzi-kafka-operator/pull/9508) fixes the Strimzi CRDs and their definitions of labels and annotations.\n  This change brings our CRDs in-sync with the Kubernetes APIs.\n  After this fix, the label and annotation definitions in our CRDs (for example in the `template` sections) cannot contain integer values anymore and have to always use string values.\n  If your custom resources use an integer value, for example:\n  ```\n  template:\n    apiService:\n      metadata:\n        annotations:\n          discovery.myapigateway.io/port: 8080\n  ```\n  You might get an error similar to this when applying the resource:\n  ```\n  * spec.template.apiService.metadata.annotations.discovery.myapigateway.io/port: Invalid value: \"integer\": spec.template.apiService.metadata.annotations.discovery.myapigateway.io/port in body must be of type string: \"integer\"\n  ```\n  To fix the issue, just use a string value instead of an integer:\n  ```\n  template:\n    apiService:\n      metadata:\n        annotations:\n          discovery.myapigateway.io/port: \"8080\"\n  ```\n* Support for the JmxTrans component is now completely removed.\n  If you are upgrading from Strimzi 0.34 or earlier and have JmxTrans enabled in `.spec.jmxTrans` of the `Kafka` custom resource, you should disable it before the upgrade or delete it manually after the upgrade is complete.\n* The `api` module was refactored and classes were moved to new packages.\n* Strimzi Drain Cleaner 1.1.0 (included in the Strimzi 0.40.0 installation files) changes the way it handles Kubernetes eviction requests.\n  It denies them instead of allowing them.\n  This new behavior does not require the `PodDisruptionBudget` to be set to `maxUnavailable: 0`.\n  We expect this to improve the compatibility with various tools used for scaling Kubernetes clusters such as [Karpenter](https://karpenter.sh/).\n  If you observe any problems with your toolchain or just want to stick with the previous behavior, you can use the `STRIMZI_DENY_EVICTION` environment variable and set it to `false` to switch back to the old (legacy) mode.\n\n## 0.39.0\n\n* Add support for Apache Kafka 3.5.2 and 3.6.1\n* The `StableConnectIdentities` feature gate moves to GA stage and is now permanently enabled without the possibility to disable it.\n  All Connect and Mirror Maker 2 operands will now use StrimziPodSets.\n* The `KafkaNodePools` feature gate moves to beta stage and is enabled by default.\n  If needed, `KafkaNodePools` can be disabled in the feature gates configuration in the Cluster Operator.\n* The `UnidirectionalTopicOperator` feature gate moves to beta stage and is enabled by default.\n  If needed, `UnidirectionalTopicOperator` can be disabled in the feature gates configuration in the Cluster Operator.\n* Improved Kafka Connect metrics and dashboard example files\n* Allow specifying and managing KRaft metadata version\n* Add support for KRaft to KRaft upgrades (Apache Kafka upgrades for the KRaft based clusters)\n* Improved Kafka Mirror Maker 2 dashboard example file\n\n### Changes, deprecations and removals\n\n* The `StableConnectIdentities` feature gate moves to GA stage and cannot be disabled anymore.\n  When using Connect or Mirror Maker 2 operands, direct downgrade to Strimzi versions older than 0.34 is not supported anymore.\n  You have to first downgrade to Strimzi version between 0.34 to 0.38, disable the `StableConnectIdentities` feature gate, and only then downgrade to an older Strimzi version.\n* Strimzi 0.39.0 (and any of its patch releases) is the last Strimzi version with support for Kubernetes 1.21 and 1.22.\n  From Strimzi 0.40.0 on, we will support only Kubernetes 1.23 and newer.\n\n## 0.38.0\n\n* Add support for Apache Kafka 3.6.0 and drop support for 3.4.0 and 3.4.1\n* Sign containers using `cosign`\n* Generate and publish Software Bill of Materials (SBOMs) of Strimzi containers\n* Add support for stopping connectors according to [Strimzi Proposal #54](https://github.com/strimzi/proposals/blob/main/054-stopping-kafka-connect-connectors.md)\n* Allow manual rolling of Kafka Connect and Kafka Mirror Maker 2 pods using the `strimzi.io/manual-rolling-update` annotation (supported only when `StableConnectIdentities` feature gate is enabled) \n* Make sure brokers are empty before scaling them down\n* Update Cruise Control to 2.5.128\n* Add support for pausing reconciliations to the Unidirectional Topic Operator\n* Allow running ZooKeeper and KRaft based Apache Kafka clusters in parallel when the `+UseKRaft` feature gate is enabled\n* Add support for metrics to the Unidirectional Topic Operator\n* Added the `includeAcceptHeader` option to OAuth client and listener authentication configuration and to `keycloak` authorization. If set to `false` it turns off sending of `Accept` header when communicating with OAuth / OIDC authorization server. This feature is enabled by the updated Strimzi Kafka OAuth library (0.14.0).\n* Update HTTP bridge to latest 0.27.0 release\n\n### Changes, deprecations and removals\n\n* The `Kafka.KafkaStatus.ListenerStatus.type` property has been deprecated for a long time, and now we do not use it anymore.\n  The current plan is to completely remove this property in the next schema version.\n  If needed, you can use the `Kafka.KafkaStatus.ListenerStatus.name` property, which has the same value.\n* Added `strimzi.io/kraft` annotation to be applied on `Kafka` custom resource, together with the `+UseKRaft` feature gate enabled, to declare a ZooKeeper or KRaft based cluster.\n  * if `enabled` the `Kafka` resource defines a KRaft-based cluster.\n  * if `disabled`, missing or any other value, the operator handle the `Kafka` resource as a ZooKeeper-based cluster.\n* The `io.strimzi.kafka.EnvVarConfigProvider` configuration provider is now deprecated and will be removed in Strimzi 0.42. Users should migrate to Kafka's implementation, `org.apache.kafka.common.config.provider.EnvVarConfigProvider`, which is a drop-in replacement.\n  For example:\n  ```yaml\n  config:\n    # ...\n    config.providers: env\n    config.providers.env.class: io.strimzi.kafka.EnvVarConfigProvider\n    # ...\n  ```\n  becomes\n  ```yaml\n  config:\n    # ...\n    config.providers: env\n    config.providers.env.class: org.apache.kafka.common.config.provider.EnvVarConfigProvider\n    # ...\n  ```\n  \n## 0.37.0\n\n* The `StableConnectIdentites` feature gate moves to beta stage.\n  By default, StrimziPodSets are used for Kafka Connect and Kafka Mirror Maker 2.\n  If needed, `StableConnectIdentites` can be disabled in the feature gates configuration in the Cluster Operator.\n* Support for the `ppc64le` platform\n* Added version fields to the `Kafka` custom resource status to track install and upgrade state\n* Support for infinite auto-restarts of Kafka Connect and Kafka Mirror Maker 2 connectors\n\n### Changes, deprecations and removals\n\n* **Removed support for OpenTracing**:\n  * The `tracing.type: jaeger` configuration, in `KafkaConnect`, `KafkaMirrorMaker`, `KafkaMirrorMaker2` and `KafkaBridge` resources, is not supported anymore.\n  * The OpenTelemetry based tracing is the only available by using `tracing.type: opentelemetry`.\n* **The default behavior of the Kafka Connect connector auto-restart has changed.**\n  When the auto-restart feature is enabled in `KafkaConnector` or `KafkaMirrorMaker2` custom resources, it will now continue to restart the connectors indefinitely rather than stopping after 7 restarts, as previously.\n  If you want to use the original behaviour, use the `.spec.autoRestart.maxRestarts` option to configure the maximum number of restarts.\n  For example:\n  ```yaml\n  apiVersion: kafka.strimzi.io/v1beta2\n  kind: KafkaConnector\n  metadata:\n    labels:\n      strimzi.io/cluster: my-connect\n    name: echo-sink-connector\n  spec:\n    # ...\n    autoRestart:\n      enabled: true\n      maxRestarts: 7\n    # ...\n  ```\n* **The automatic configuration of Cruise Control CPU capacity has been changed in this release**:\n  * There are three ways to configure Cruise Control CPU capacity values:\n    * `.spec.cruiseControl.brokerCapacity` (for all brokers)\n    * `.spec.cruiseControl.brokerCapacity.overrides` (per broker)\n    * Kafka resource requests and limits (for all brokers).\n  * The precedence of which Cruise Control CPU capacity configuration is used has been changed.\n  * In previous Strimzi versions, the Kafka resource limit (if set) took precedence, regardless if any other CPU configurations were set.\n    * For example:\n      * (1) Kafka resource limits\n      * (2) `.spec.cruiseControl.brokerCapacity.overrides`\n      * (3) `.spec.cruiseControl.brokerCapacity`\n  * This previous behavior was identified as a bug and was fixed in this Strimzi release.\n  * Going forward, the brokerCapacity overrides per broker take top precedence, then general brokerCapacity configuration, and then the Kafka resource requests, then the Kafka resource limits.\n    * For example:\n      * (1) `.spec.cruiseControl.brokerCapacity.overrides`\n      * (2) `.spec.cruiseControl.brokerCapacity`\n      * (3) Kafka resource requests\n      * (4) Kafka resource limits\n    * When none of Cruise Control CPU capacity configurations mentioned above are configured, CPU capacity will be set to `1`.\n as any _override_ value configured in the `.spec.cruiseControl` section of the `Kafka` custom resource.\n\n## 0.36.1\n\n* Add support for Apache Kafka 3.5.1\n\n## 0.36.0\n\n* Add support for Apache Kafka 3.4.1 and 3.5.0, and remove support for 3.3.1 and 3.3.2\n* Enable SCRAM-SHA authentication in KRaft mode (supported in Apache Kafka 3.5.0 and newer)\n* Add support for insecure flag in Maven artifacts in Kafka Connect Build\n* Update Kafka Exporter to [1.7.0](https://github.com/danielqsj/kafka_exporter/releases/tag/v1.7.0)\n* Improve Kafka rolling update to avoid rolling broker in log recovery\n* Added support for Kafka Exporter topic exclude and consumer group exclude parameters\n* Update Kaniko container builder to 1.12.1\n* Add support for _Kafka node pools_ according to [Strimzi Proposal #50](https://github.com/strimzi/proposals/blob/main/050-Kafka-Node-Pools.md)\n* Add support for _Unidirectional Topic Operator_ according to [Strimzi Proposal #51](https://github.com/strimzi/proposals/blob/main/051-unidirectional-topic-operator.md)\n* Update OpenTelemetry 1.19.0\n* Fixed ordering of JVM performance options [#8579](https://github.com/strimzi/strimzi-kafka-operator/issues/8579)\n* Log a warning when a KafkaTopic has no spec [#8465](https://github.com/strimzi/strimzi-kafka-operator/issues/8465)\n* Updated Strimzi OAuth library to 0.13.0 with better support for KRaft\n\n### Changes, deprecations and removals\n\n* **From Strimzi 0.36.0 on, we support only Kubernetes 1.21 and newer.**\n  Kubernetes 1.19 and 1.20 are not supported anymore.\n* Enabling the `UseKRaft` feature gate is now possible only together with the `KafkaNodePools` feature gate.\n  To deploy a Kafka cluster in the KRaft mode, you have to use the `KafkaNodePool` resources.\n* The Helm Chart repository at `https://strimzi.io/charts/` is now deprecated.\n  Please use the Helm Chart OCI artifacts from our [Helm Chart OCI repository instead](https://quay.io/organization/strimzi-helm).\n* Option `customClaimCheck` of 'oauth' authentication which relies on JsonPath changed the handling of equal comparison against `null` as the behaviour was buggy and is now fixed in the updated version of JsonPath library [OAuth #196](https://github.com/strimzi/strimzi-kafka-oauth/pull/196)\n\n## 0.35.0\n\n* Redesigned the Cluster and User Operator configuration to make it more efficient and flexible\n* Allow multiple imagePullSecrets in the Strimzi Helm chart\n* Remove support for JMX Trans\n* Move feature gate `UseStrimziPodSets` to GA and remove support for StatefulSets\n* Add flag to load Grafana dashboards from Helm Chart\n\n### Changes, deprecations and removals\n\n* Strimzi 0.35.0 (and any possible patch releases) is the last Strimzi version with support for Kubernetes 1.19 and 1.20.\n  From Strimzi 0.36.0 on, we will support only Kubernetes 1.21 and newer.\n* Support for JMX Trans has been removed in Strimzi 0.35.0.\n  If you have JMX Trans enabled in your `Kafka` custom resource in the `.spec.jmxTrans` section, you should remove it.\n  If you upgrade to Strimzi 0.35.0 or newer with JMX Trans deployed / enabled in the `Kafka` custom resource, Strimzi will be automatically deleted after the upgrade.\n* The feature gate `UseStrimziPodSets` has graduated to GA and cannot be disabled anymore.\n  The StatefulSet template properties in the `Kafka` custom resource in `.spec.zookeeper.template.statefulSet` and `.spec.kafka.template.statefulSet` are deprecated and will be ignored.\n  You should remove them from your custom resources.\n\n## 0.34.0\n\n* Add support for Kafka 3.4.0 and remove support for Kafka 3.2.x\n* Stable Pod identities for Kafka Connect and MirrorMaker 2 (Feature Gate `StableConnectIdentities`)\n* Use JDK HTTP client in the Kubernetes client instead of the OkHttp client\n* Add truststore configuration for HTTPS connections to OPA server\n* Add image digest support in Helm chart\n* Added the `httpRetries` and `httpRetryPauseMs` options to OAuth authentication configuration. They are set to `0` by default - no retries, no backoff between retries. Also added analogous `httpRetries` option in the `keycloak` authorization configuration. These features are enabled by the updated Strimzi Kafka OAuth library (0.12.0).\n\n## 0.33.0\n\n* Add support for Kafka 3.3.2\n* Support loadBalancerClass attribute in service with type loadBalancer\n* Support for automatically restarting failed Connect or Mirror Maker 2 connectors\n* Redesign of Strimzi User Operator to improve its scalability\n* Use Java 17 as the runtime for all containers and language level for all modules except `api`, `crd-generator`, `crd-annotations`, and `test`\n* Improved FIPS (Federal Information Processing Standards) support\n* Upgrade Vert.x to 4.3.5\n* Moved from using the Jaeger exporter to OTLP exporter by default\n* Kafka Exporter support for `Recreate` deployment strategy\n* `ImageStream` validation for Kafka Connect builds on OpenShift\n* Support for configuring the metadata for the Role / RoleBinding of Entity Operator\n* Add liveness and readiness probes specifically for nodes running in KRaft combined mode\n* Upgrade HTTP bridge to latest 0.24.0 release\n\n### Known issues\n\n* The TLS passthrough feature of the Ingress-NGINX Controller for Kubernetes is not compatible with some new TLS features supported by Java 17 such as the _session tickets extension_.\n  If you use `type: ingress` listener with enabled mTLS authentication, we recommend you to test if your clients are affected or not.\n  If needed, you can also disable the _session ticket extension_ in the Kafka brokers in your `Kafka` custom resource by setting the `jdk.tls.server.enableSessionTicketExtension` Java system property to `false`:\n  ```yaml\n  apiVersion: kafka.strimzi.io/v1beta2\n  kind: Kafka\n  metadata:\n    # ...\n  spec:\n    # ...\n    kafka:\n      jvmOptions:\n        javaSystemProperties:\n          - name: jdk.tls.server.enableSessionTicketExtension\n            value: \"false\"\n    # ...\n  ```\n  For more details, see [kubernetes/ingress-nginx#9540](https://github.com/kubernetes/ingress-nginx/issues/9540).\n\n### Changes, deprecations and removals\n\n* The `UseStrimziPodSet` feature gate will move to GA in Strimzi 0.35.\n  Support for StatefulSets will be removed from Strimzi right after the 0.34 release.\n  Please use the Strimzi 0.33 release to test StrimziPodSets in your environment and report any major or blocking issues before the StatefulSet support is removed.\n* The default length of any new SCRAM-SHA-512 passwords will be 32 characters instead of 12 characters used in the previous Strimzi versions.\n  Existing passwords will not be affected by this change until they are regenerated (for example because the user secret is deleted).\n  If you want to keep using the original password length, you can set it using the `STRIMZI_SCRAM_SHA_PASSWORD_LENGTH` environment variable in `.spec.entityOperator.template.userOperatorContainer.env` in the `Kafka` custom resource or in the `Deployment` of the standalone User Operator.\n  ```yaml\n  userOperatorContainer:\n    env:\n      - name: STRIMZI_SCRAM_SHA_PASSWORD_LENGTH\n        value: \"12\"\n  ```\n* In previous versions, the `ssl.secure.random.implementation` option in Kafka brokers was always set to `SHA1PRNG`.\n  From Strimzi 0.33 on, it is using the default SecureRandom implementation from the Java Runtime.\n  If you want to keep using `SHA1PRNG` as your SecureRandom, you can configure it in `.spec.kafka.config` in your `Kafka` custom resource.\n* Support for JmxTrans in Strimzi is deprecated. \n  It is currently planned to be removed in Strimzi 0.35.0.\n* Support for `type: jaeger` tracing based on Jaeger clients and OpenTracing API was deprecated in the Strimzi 0.31 release.\n  As the Jaeger clients are retired and the OpenTracing project is archived, we cannot guarantee their support for future versions.\n  In Strimzi 0.32 and 0.33, we added support for OpenTelemetry tracing as a replacement.\n  If possible, we will maintain the support for `type: jaeger` tracing until June 2023 and remove it afterwards.\n  Please migrate to OpenTelemetry as soon as possible.\n* When OpenTelemetry is enabled for tracing, starting from this release, the operator configures the OTLP exporter instead of the Jaeger one by default.\n  The Jaeger exporter is even not included in the Kafka images anymore, so if you want to use it you have to add the binary by yourself.\n  The `OTEL_EXPORTER_OTLP_ENDPOINT` environment variable has to be used instead of the `OTEL_EXPORTER_JAEGER_ENDPOINT` in order to specify the OTLP endpoint to send traces to.\n  If you are using Jaeger as the backend system for tracing, you need to have 1.35 release at least which is the first one exposing an OTLP endpoint.\n\n## 0.32.0\n\n* Add support for Kafka 3.3.1 and remove support for Kafka 3.1.0, 3.1.1, and 3.1.2\n* Update Open Policy Agent (OPA) Authorizer to 1.5.0\n* Update KafkaConnector CR status so the 'NotReady' condition is added if the connector or any tasks are reporting a 'FAILED' state.\n* Add auto-approval mechanism on KafkaRebalance resource when an optimization proposal is ready\n* The `ControlPlaneListener` feature gate moves to GA\n* Add client rack-awareness support to Strimzi Bridge pods\n* Add support for OpenTelemetry for distributed tracing\n  * Kafka Connect, Mirror Maker, Mirror Maker 2 and Strimzi Bridge can be configured to use OpenTelemetry\n  * Using Jaeger exporter by default for backward compatibility\n* Updated JMX Exporter dependency to 0.17.2\n* ZookeeperRoller considers unready pods\n* Support multiple operations per ACLRule\n* Upgrade Vert.x to 4.3.4\n* Add `cluster-ip` listener. We can use it with a tcp port configuration in an ingress controller to expose kafka with an optional tls encryption and a single LoadBalancer.\n* Update Strimzi OAuth library to 0.11.0\n\n### Changes, deprecations and removals\n\n* **From 0.32.0 on, Strimzi supports only Kubernetes version 1.19 and newer.**\n* A connector or task failing triggers a 'NotReady' condition to be added to the KafkaConnector CR status. This is different from previous versions where the CR would report 'Ready' even if the connector or a task had failed.\n* The `ClusterRole` from file `020-ClusterRole-strimzi-cluster-operator-role.yaml` was split into two separate roles:\n  * The original `strimzi-cluster-operator-namespaced` `ClusterRole` in the file `020-ClusterRole-strimzi-cluster-operator-role.yaml` contains the rights related to the resources created based on some Strimzi custom resources.\n  * The new `strimzi-cluster-operator-watched` `ClusterRole` in the file `023-ClusterRole-strimzi-cluster-operator-role.yaml` contains the rights required to watch and manage the Strimzi custom resources.\n  \n  When deploying the Strimzi Cluster Operator as cluster-wide, the `strimzi-cluster-operator-watched` `ClusterRole` needs to be always granted at the cluster level.\n  But the `strimzi-cluster-operator-namespaced` `ClusterRole` might be granted only for the namespaces where any custom resources are created.\n* The `ControlPlaneListener` feature gate moves to GA. \n  Direct upgrade from Strimzi 0.22 or earlier is not possible anymore.\n  You have to upgrade first to one of the Strimzi versions between 0.22 and 0.32 before upgrading to Strimzi 0.32 or newer.\n  Please follow the docs for more details.  \n* The `spec.authorization.acls[*].operation` field in the `KafkaUser` resource has been deprecated in favour of the field\n  `spec.authorization.acls[*].operations` which allows to set multiple operations per ACLRule.\n\n## 0.31.1\n\n* Kafka 3.1.2 and 3.2.3 (fixes CVE-2022-34917)\n* Make `sasl.server.max.receive.size` broker option user configurable\n* Documentation improvements\n* Configuring number of operator replicas through the Strimzi Helm Chart\n* Update Strimzi Kafka Bridge to 0.22.1\n\n## 0.31.0\n\n* Add support for Kafka 3.2.1\n* Update Kaniko builder to 1.9.0 and Maven builder to 1.14\n* Update Kafka Exporter to 1.6.0 \n* Pluggable Pod Security Profiles with built-in support for _restricted_ Kubernetes Security Profile\n* Add support for leader election and running multiple operator replicas (1 active leader replicas and one or more stand-by replicas)\n* Update Strimzi Kafka Bridge to 0.22.0\n* Add support for IPv6 addresses being used in Strimzi issued certificates\n* Make it easier to wait for custom resource readiness when using the Strimzi api module\n* Add StrimziPodSet reconciliation metrics\n\n### Deprecations and removals\n\n* Strimzi 0.31.0 (and any possible patch releases) is the last Strimzi version with support for Kubernetes 1.16, 1.17 and 1.18.\n  From Strimzi 0.32.0 on, we will support only Kubernetes 1.19 and newer.\n  The supported Kubernetes versions will be re-evaluated again in Q1/2023.\n* The `type: jaeger` tracing support based on Jaeger clients and OpenTracing API is now deprecated.\n  Because the Jaeger clients are retired and the OpenTracing project is archived, we cannot guarantee their support for future Kafka versions.\n  In the future, we plan to replace it with a new tracing feature based on the OpenTelemetry project.\n\n## 0.30.0\n\n* Remove Kafka 3.0.0 and 3.0.1\n* Add support for `simple` authorization and for the User Operator to the experimental `UseKRaft` feature gate\n  _(Note: Due to [KAFKA-13909](https://issues.apache.org/jira/browse/KAFKA-13909), broker restarts currently don't work when authorization is enabled.)_\n* Add network capacity overrides for Cruise Control capacity config\n* The `ServiceAccountPatching` feature gate moves to GA.\n  It cannot be disabled anymore and will be permanently enabled.\n* The `UseStrimziPodSets` feature gate moves to beta stage.\n  By default, StrimziPodSets are used instead of StatefulSets.\n  If needed, `UseStrimziPodSets` can be disabled in the feature gates configuration in the Cluster Operator.\n* Use better encryption and digest algorithms when creating the PKCS12 stores.\n  For existing clusters, the certificates will not be updated during upgrade but only next time the PKCS12 store is created. \n* Add CPU capacity overrides for Cruise Control capacity config\n* Use CustomResource existing spec and status to fix Quarkus native build's serialization\n* Update JMX Exporter to version 0.17.0\n* Operator emits Kubernetes Events to explain why it restarted a Kafka broker\n* Better configurability of the Kafka Admin client in the User Operator\n* Update Strimzi Kafka Bridge to 0.21.6\n\n## 0.29.0\n\n* Add support for Apache Kafka 3.0.1, 3.1.1 and 3.2.0\n* Increase the size of the `/tmp` volumes to 5Mi to allow unpacking of compression libraries\n* Use `/healthz` endpoint for Kafka Exporter health checks\n* Renew user certificates in User Operator only during maintenance windows\n* Ensure Topic Operator using Kafka Streams state store can start up successfully \n* Update Cruise Control to 2.5.89\n* Remove TLS sidecar from Cruise Control pod. Cruise Control is now configured to not using ZooKeeper, so the TLS sidecar is not needed anymore.\n* Allow Cruise Control topic names to be configured\n* Add support for `spec.rack.topologyKey` property in Mirror Maker 2 to enable \"fetch from the closest replica\" feature.\n* Support for the s390x platform\n  _(The s390x support is currently considered as experimental. We are not aware of any issues, but the s390x build doesn't at this point undergo the same level of testing as the AMD64 container images.)_\n* Update Strimzi Kafka Bridge to 0.21.5\n* Added rebalancing modes on the `KafkaRebalance` custom resource\n  * `full`: this mode runs a full rebalance moving replicas across all the brokers in the cluster. This is the default one if not specified.\n  * `add-brokers`: after scaling up the cluster, this mode is used to move replicas to the newly added brokers specified in the custom resource.\n  * `remove-brokers`: this mode is used to move replicas off the brokers that are going to be removed, before scaling down the cluster.\n* **Experimental** KRaft mode (ZooKeeper-less Kafka) which can be enabled using the `UseKRaft` feature gate.\n  **Important: Use it for development and testing only!**\n\n### Changes, deprecations and removals\n\n* Since the Cruise Control TLS sidecar has been removed, the related configuration options `.spec.cruiseControl.tlsSidecar` and `.spec.cruiseControl.template.tlsSidecar` in the Kafka custom resource are now deprecated.\n\n## 0.28.0\n\n* Add support for Kafka 3.1.0; remove Kafka 2.8.0 and 2.8.1\n* Add support for `StrimziPodSet` resources (disabled by default through the `UseStrimziPodSets` feature gate)\n* Update Open Policy Agent authorizer to 1.4.0 and add support for enabling metrics\n* Support custom authentication mechanisms in Kafka listeners\n* Intra-broker disk balancing using Cruise Control\n* Add connector context to the default logging configuration in Kafka Connect and Kafka Mirror Maker 2\n* Added the option `createBootstrapService` in the Kafka Spec to disable the creation of the bootstrap service for the Load Balancer Type Listener. It will save the cost of one load balancer resource, specially in the public cloud.\n* Added the `connectTimeoutSeconds` and `readTimeoutSeconds` options to OAuth authentication configuration. The default connect and read timeouts are set to 60 seconds (previously there was no timeout). Also added `groupsClaim` and `groupsClaimDelimiter` options in the listener configuration of Kafka Spec to allow extracting group information from JWT token at authentication time, and making it available to the custom authorizer. These features are enabled by the updated Strimzi Kafka OAuth library (0.10.0).\n* Add support for disabling the FIPS mode in OpenJDK\n* Fix renewing your own CA certificates [#5466](https://github.com/strimzi/strimzi-kafka-operator/issues/5466)\n* Update Strimzi Kafka Bridge to 0.21.4\n* Update Cruise Control to 2.5.82\n\n### Changes, deprecations and removals\n\n* The Strimzi Identity Replication Policy (class `io.strimzi.kafka.connect.mirror.IdentityReplicationPolicy`) is now deprecated and will be removed in the future.\n  Please update to Kafka's own Identity Replication Policy (class `org.apache.kafka.connect.mirror.IdentityReplicationPolicy`).\n* The `type` field in `ListenerStatus` has been deprecated and will be removed in the future.\n* The `disk` and `cpuUtilization` fields in the `spec.cruiseControl.capacity` section of the Kafka resource have been deprecated, are ignored, and will be removed in the future.\n\n## 0.27.0\n\n* Multi-arch container images with support for x86_64 / AMD64 and AArch64 / ARM64 platforms\n  _(The support AArch64 is currently considered as experimental. We are not aware of any issues, but the AArch64 build doesn't at this point undergo the same level of testing as the AMD64 container images.)_\n* Added the option to configure the Cluster Operator's Zookeeper admin client session timeout via an new env var: `STRIMZI_ZOOKEEPER_ADMIN_SESSION_TIMEOUT_MS`\n* The `ControlPlaneListener` and `ServiceAccountPatching` feature gates are now in the _beta_ phase and are enabled by default.\n* Allow setting any extra environment variables for the Cluster Operator container through Helm using a new `extraEnvs` value.\n* Added SCRAM-SHA-256 authentication for Kafka clients\n* Update OPA Authorizer to 1.3.0\n* Update to Cruise Control version 2.5.79\n* Update Log4j2 to 2.17.0\n\n### Changes, deprecations and removals\n\n* The `ControlPlaneListener` feature gate is now enabled by default.\n  When upgrading from Strimzi 0.22 or earlier, you have to disable the `ControlPlaneListener` feature gate when upgrading the cluster operator to make sure the Kafka cluster stays available during the upgrade.\n  When downgrading to Strimzi 0.22 or earlier, you have to disable the `ControlPlaneListener` feature gate before downgrading the cluster operator to make sure the Kafka cluster stays available during the downgrade.\n\n## 0.26.0\n\n* Add support for Kafka 2.8.1 and 3.0.0; remove Kafka 2.7.0 and 2.7.1\n* Update the Open Policy Agent Authorizer to version [1.1.0](https://github.com/Bisnode/opa-kafka-plugin/releases/tag/v1.1.0)\n* Expose JMX port on Zookeeper nodes via a headless service.\n* Allow configuring labels and annotations for JMX authentication secrets\n* Enable Cruise Control anomaly.detection configurations\n* Add support for building connector images from the Maven coordinates\n* Allow Kafka Connect Build artifacts to be downloaded from insecure servers (#5542)\n* Add option to specify pull secret in Kafka Connect Build on OpenShift (#5631)\n* Configurable authentication, authorization, and SSL for Cruise Control API\n* Update to Cruise Control version 2.5.73\n* Allow to configure `/tmp` volume size via Pod template. By default `1Mi` is used.\n\n### Changes, deprecations and removals\n\n* imageRepositoryOverride,imageRegistryOverride and imageTagOverride are now removed from values.yaml. defaultImageRepository, defaultImageRegistry and defaultImageTag values are introduced in helm charts which sets the default registry, repository and tags for the images. Now the registry, repository and tag for a single image can be configured as per the requirement.\n* The OpenShift Templates were removed from the examples and are no longer supported (#5548)\n* Kafka MirrorMaker 1 has been deprecated in Apache Kafka 3.0.0 and will be removed in Apache Kafka 4.0.0.\n  As a result, the `KafkaMirrorMaker` custom resource which is used to deploy Kafka MirrorMaker 1 has been deprecated in Strimzi as well. (#5617)\n  The `KafkaMirrorMaker` resource will be removed from Strimzi when we adopt Apache Kafka 4.0.0.\n  As a replacement, use the `KafkaMirrorMaker2` custom resource with the [`IdentityReplicationPolicy`](https://strimzi.io/docs/operators/latest/using.html#unidirectional_replication_activepassive).\n\n## 0.25.0\n\n* Move from Scala 2.12 to Scala 2.13. (#5192)\n* Open Policy Agent authorizer updated to a new version supporting Scala 2.13. See the _Changes, deprecations and removals_ sections for more details. (#5192)\n* Allow a custom password to be set for SCRAM-SHA-512 users by referencing a secret in the `KafkaUser` resource\n* Add support for [EnvVar Configuration Provider for Apache Kafka](https://github.com/strimzi/kafka-env-var-config-provider)\n* Add support for `tls-external` authentication to User Operator to allow management of ACLs and Quotas for TLS users with user certificates generated externally (#5249) \n* Support for disabling the automatic generation of network policies by the Cluster Operator. Set the Cluster Operator's `STRIMZI_NETWORK_POLICY_GENERATION` environment variable to `false` to disable network policies. (#5258)\n* Update User Operator to use Admin API for managing SCRAM-SHA-512 users\n* Configure fixed size limit for `emptyDir` volumes used for temporary files (#5340)\n* Update Strimzi Kafka Bridge to 0.20.2\n\n### Changes, deprecations and removals\n\n* The `KafkaConnectS2I` resource has been removed and is no longer supported by the operator.\n  Please use the [migration guide](https://strimzi.io/docs/operators/0.24.0/full/using.html#proc-migrating-kafka-connect-s2i-str) to migrate your `KafkaConnectS2I` deployments to [`KafkaConnect` Build](https://strimzi.io/docs/operators/latest/full/deploying.html#creating-new-image-using-kafka-connect-build-str) instead.\n* The Open Policy Agent authorizer has been updated to a new version that supports Scala 2.13.\n  The new release introduces a new format of the input data sent to the Open Policy Agent server.\n  For more information about the new format and how to migrate from the old version, see the [OPA Kafka plugin v1.0.0 release notes](https://github.com/Bisnode/opa-kafka-plugin/releases/tag/v1.0.0).\n* User Operator now uses Kafka Admin API to manage SCRAM-SHA-512 credentials.\n  All operations done by the User Operator now use Kafka Admin API and connect directly to Kafka instead of ZooKeeper.\n  As a result, the environment variables `STRIMZI_ZOOKEEPER_CONNECT` and `STRIMZI_ZOOKEEPER_SESSION_TIMEOUT_MS` were removed from the User Operator configuration.\n* All `emptyDir` volumes used by Strimzi for temporary files have now configured a fixed size limit.\n* Annotate Cluster Operator resource metrics with a namespace label\n\n## 0.24.0\n\n* Add support for [Kubernetes Configuration Provider for Apache Kafka](https://github.com/strimzi/kafka-kubernetes-config-provider)\n* Use Red Hat UBI8 base image\n* Add support for Kafka 2.7.1 and remove support for 2.6.0, 2.6.1, and 2.6.2\n* Support for patching of service accounts and configuring their labels and annotations. The feature is disabled by default and enabled using the new `ServiceAccountPatching` feature gate.\n* Added support for configuring cluster-operator's worker thread pool size that is used for various sync and async tasks\n* Add Kafka Quotas plugin with produce, consume, and storage quotas\n* Support pausing reconciliation of KafkaTopic CR with annotation `strimzi.io/pause-reconciliation`\n* Update cruise control to 2.5.57\n* Update to Strimzi Kafka Bridge to 0.20.0\n* Support for broker load information added to the rebalance optimization proposal. Information on the load difference, before and after a rebalance is stored in a ConfigMap\n* Add support for selectively changing the verbosity of logging for individual CRs, using markers.\n* Added support for `controller_mutation_rate' quota. Creation/Deletion of topics and creation of partitions can be configured through this.\n* Use newer version of Kafka Exporter with different bugfixes \n\n### Changes, deprecations and removals\n\n* The deprecated `KafkaConnectS2I` custom resource will be removed after the 0.24.0 release. \n  Please use the [migration guide](https://strimzi.io/docs/operators/latest/full/using.html#proc-migrating-kafka-connect-s2i-str) to migrate your `KafkaConnectS2I` deployments to [`KafkaConnect` Build](https://strimzi.io/docs/operators/latest/full/deploying.html#creating-new-image-using-kafka-connect-build-str) instead.\n* The fields `topicsBlacklistPattern` and `groupsBlacklistPattern` in the `KafkaMirrorMaker2` resource are deprecated and will be removed in the future.\n  They are replaced by new fields `topicsExcludePattern` and `groupsExcludePattern`.\n* The field `whitelist` in the `KafkaMirrorMaker` resource is deprecated and will be removed in the future.\n  It is replaced with a new field `include`.\n* `bind-utils` removed from containers to improve security posture.\n* Kafka Connect Build now uses hashes to name downloaded artifact files. Previously, it was using the last segment of the download URL.\n  If your artifact requires a specific name, you can use the new `type: other` artifact and its `fileName` field.\n* The option `enableECDSA` of Kafka CR `authentication` of type `oauth` has been deprecated and is ignored. \n  ECDSA token signature support is now always enabled without the need for Strimzi Cluster Operator installing the BouncyCastle JCE crypto provider. \n  BouncyCastle library is no longer packaged with Strimzi Kafka images.\n\n## 0.23.0\n\n* Add support for Kafka 2.8.0 and 2.6.2, remove support for Kafka 2.5.x\n* Make it possible to configure maximum number of connections and maximum connection creation rate in listener configuration\n* Add support for configuring finalizers for `loadbalancer` type listeners\n* Use dedicated Service Account for Kafka Connect Build on Kubernetes \n* Remove direct ZooKeeper access for handling user quotas in the User Operator. Add usage of Admin Client API instead.\n* Migrate to CRD v1 (required by Kubernetes 1.22+)\n* Support for configuring custom Authorizer implementation \n* Changed Reconciliation interval for Topic Operator from 90 to 120 seconds (to keep it the same as for other operators)\n* Changed Zookeeper session timeout default value to 18 seconds for Topic and User Operators (for improved resiliency)\n* Removed requirement for replicas and partitions KafkaTopic spec making these parameters optional\n* Support to configure a custom filter for parent CR's labels propagation into subresources \n* Allow disabling service links (environment variables describing Kubernetes services) in Pod template\n* Update Kaniko executor to 1.6.0\n* Add support for separate control plane listener (disabled by default, available via the `ControlPlaneListener` feature gate)\n* Support for Dual Stack networking\n\n### Changes, deprecations and removals\n\n* Strimzi API versions `v1alpha1` and `v1beta1` were removed from all Strimzi custom resources apart from `KafkaTopic` and `KafkaUser` (use `v1beta2` versions instead)\n* The following annotations have been removed and cannot be used anymore:\n  * `cluster.operator.strimzi.io/delete-claim` (used internally only - replaced by `strimzi.io/delete-claim`)\n  * `operator.strimzi.io/generation` (used internally only - replaced by `strimzi.io/generation`)\n  * `operator.strimzi.io/delete-pod-and-pvc` (use `strimzi.io/delete-pod-and-pvc` instead)\n  * `operator.strimzi.io/manual-rolling-update` (use `strimzi.io/manual-rolling-update` instead)\n* When the `class` field is configured in the `configuration` section of an Ingress-type listener, Strimzi will not automatically set the deprecated `kubernetes.io/ingress.class` annotation anymore. In case you still need this annotation, you can set it manually in the listener configuration using the [`annotations` field](https://strimzi.io/docs/operators/latest/full/using.html#property-listener-config-annotations-reference) or in the [`.spec.kafka.template` section](https://strimzi.io/docs/operators/latest/full/using.html#type-KafkaClusterTemplate-reference).\n* The `.spec.kafkaExporter.template.service` section in the `Kafka` custom resource has been deprecated and will be removed in the next API version (the service itself was removed several releases ago).\n\n## 0.22.0\n\n* Add `v1beta2` version for all resources. `v1beta2` removes all deprecated fields.\n* Add annotations that enable the operator to restart Kafka Connect connectors or tasks. The annotations can be applied to the KafkaConnector and the KafkaMirrorMaker2 custom resources.\n* Add additional configuration options for the Kaniko executor used by the Kafka Connect Build on Kubernetes\n* Add support for JMX options configuration of all Kafka Connect (KC, KC2SI, MM2)\n* Update Strimzi Kafka OAuth to version 0.7 and add support for new features:\n  * OAuth authentication over SASL PLAIN mechanism\n  * Checking token audience\n  * Validating tokens using JSONPath filter queries to perform custom checks\n* Fix Cruise Control crash loop when updating container configurations\n* Configure external logging `ConfigMap` name and key.\n* Add support for configuring labels and annotations in ClusterRoleBindings created as part of Kafka and Kafka Connect clusters\n* Add support for Ingress v1 in Kubernetes 1.19 and newer\n* Add support for Kafka 2.6.1\n* List topics used by a Kafka Connect connector in the `.status` section of the `KafkaConnector` custom resource\n* Bump Cruise Control to v2.5.37 for Kafka 2.7 support. Note this new version of Cruise Control uses `Log4j 2` and is supported by dynamic logging configuration (where logging properties are defined in a ConfigMap). However, existing `Log4j` configurations must be updated to `Log4j 2` configurations.\n* Support pausing reconciliation of CR with annotation `strimzi.io/pause-reconciliation`\n\n### Changes, deprecations and removals\n\n* In the past, when no Ingress class was specified in the Ingress-type listener in the Kafka custom resource, the \n  `kubernetes.io/ingress.class` annotation was automatically set to `nginx`. Because of the support for the new \n  IngressClass resource and the new `ingressClassName` field in the Ingress resource, the default value will not be set \n  anymore. Please use the `class` field in `.spec.kafka.listeners[].configuration` to specify the class name.\n* The `KafkaConnectS2I` custom resource is deprecated and will be removed in the future. You can use the new [`KafkaConnect` build feature](https://strimzi.io/docs/operators/latest/full/deploying.html#creating-new-image-using-kafka-connect-build-str) instead.\n* Removed support for Helm2 charts as that version is now unsupported. There is no longer the need for separate `helm2` and `helm3` binaries, only `helm` (version 3) is required.\n* The following annotations are deprecated for a long time and will be removed in 0.23.0:\n  * `cluster.operator.strimzi.io/delete-claim` (used internally only - replaced by `strimzi.io/delete-claim`)\n  * `operator.strimzi.io/generation` (used internally only - replaced by `strimzi.io/generation`)\n  * `operator.strimzi.io/delete-pod-and-pvc` (use `strimzi.io/delete-pod-and-pvc` instead)\n  * `operator.strimzi.io/manual-rolling-update` (use `strimzi.io/manual-rolling-update` instead)\n* External logging configuration has changed. `spec.logging.name` is deprecated. Moved to `spec.logging.valueFrom.configMapKeyRef.name`. Key in the `ConfigMap` is configurable via `spec.logging.valueFrom.configMapKeyRef.key`.\n  * from\n  ```\n  logging:\n    type: external\n    name: my-config-map\n  ```\n  * to\n  ```\n  logging:\n    type: external\n    valueFrom:\n      configMapKeyRef:\n        name: my-config-map\n        key: my-key\n  ``` \n* Existing Cruise Control logging configurations must be updated from `Log4j` syntax to `Log4j 2` syntax.\n  * For existing inline configurations, replace the `cruisecontrol.root.logger` property with `rootLogger.level`.\n  * For existing external configurations, replace the existing configuration with a new configuration file named `log4j2.properties` using `log4j 2` syntax.\n\n## 0.21.0\n\n* Add support for declarative management of connector plugins in Kafka Connect CR \n* Add `inter.broker.protocol.version` to the default configuration in example YAMLs\n* Add support for `secretPrefix` property for User Operator to prefix all secret names created from KafkaUser resource.\n* Allow configuring labels and annotations for Cluster CA certificate secrets\n* Add the JAAS configuration string in the sasl.jaas.config property to the generated secrets for KafkaUser with SCRAM-SHA-512 authentication.\n* Strimzi `test-container` has been renamed to `strimzi-test-container` to make the name more clear\n* Updated the CPU usage metric in the Kafka, ZooKeeper and Cruise Control dashboards to include the CPU kernel time (other than the current user time)\n* Allow disabling ownerReference on CA secrets\n* Make it possible to run Strimzi operators and operands with read-only root filesystem\n* Move from Docker Hub to Quay.io as our container registry\n* Add possibility to configure DeploymentStrategy for Kafka Connect, Kafka Mirror Maker (1 and 2), and Kafka Bridge\n* Support passing metrics configuration as an external ConfigMap\n* Enable CORS configuration for Cruise Control\n* Add support for rolling individual Kafka or ZooKeeper pods through the Cluster Operator using an annotation\n* Add support for Topology Spread Constraints in Pod templates\n* Make Kafka `cluster-id` (KIP-78) available on Kafka CRD status\n* Add support for Kafka 2.7.0\n\n### Deprecations and removals\n* The `metrics` field in the Strimzi custom resources has been deprecated and will be removed in the future. For configuring metrics, use the new `metricsConfig` field and pass the configuration via ConfigMap.\n\n## 0.20.0\n\n**Note: This is the last version of Strimzi that will support Kubernetes 1.11 and higher. Future versions will drop support for Kubernetes 1.11-1.15 and support only Kubernetes 1.16 and higher.**\n\n* Add support for Kafka 2.5.1 and 2.6.0. Remove support for 2.4.0 and 2.4.1\n* Remove TLS sidecars from Kafka pods => Kafka now uses native TLS to connect to ZooKeeper\n* Updated to Cruise Control 2.5.11, which adds Kafka 2.6.0 support and fixes a previous issue with CPU utilization statistics for containers. As a result, the CpuCapacityGoal has now been enabled.\n* Cruise Control metrics integration:\n  * Enable metrics JMX exporter configuration in the `cruiseControl` property of the Kafka custom resource\n  * New Grafana dashboard for the Cruise Control metrics\n* Configure Cluster Operator logging using ConfigMap instead of environment variable and support dynamic changes  \n* Switch to use the `AclAuthorizer` class for the `simple` Kafka authorization type. `AclAuthorizer` contains new features such as the ability to control the amount of authorization logs in the broker logs.\n* Support dynamically changeable logging configuration of Kafka Connect and Kafka Connect S2I\n* Support dynamically changeable logging configuration of Kafka brokers\n* Support dynamically changeable logging configuration of Kafka MirrorMaker2\n* Add support for `client.rack` property for Kafka Connect to use `fetch from closest replica` feature. \n* Refactored operators Grafana dashboard\n  * Fixed bug on maximum reconcile time graph\n  * Removed the avarage reconcile time graph\n  * Rearranged graphs\n* Make `listeners` configurable as an array and add support for more different listeners in single cluster\n* Add support for configuring `hostAliases` in Pod templates\n* Add new resource state metric in the operators for reflecting the reconcile result on a specific resource\n* Add improvements for `oauth` authentication, and `keycloak` authorization:\n  * Support for re-authentication was added, which also enforces access token lifespan on the Kafka client session\n  * Permission changes through Keycloak Authorization Services are now detected by Kafka Brokers\n\n### Deprecations and removals\n\n#### Redesign of the `.spec.kafka.listeners` section\n\nThe `.spec.kafka.listeners` section of the Kafka CRD has been redesigned to allow configuring more different listeners.\nThe old `listeners` object which allowed only configuration of one`plain`, one `tls`, and one `external` listener is now deprecated and will be removed in the future.\nIt is replaced with an array allowing configuration of multiple different listeners:\n\n```yaml\nlisteners:\n  - name: local\n    port: 9092\n    type: internal\n    tls: true\n  - name: external1\n    port: 9093\n    type: loadbalancer\n    tls: true\n  - name: external2\n    port: 9094\n    type: nodeport\n    tls: true\n```\n\nThis change includes some other changes:\n* The `tls` field is now required.\n* The former `overrides` section is now merged with the `configuration` section.\n* The `dnsAnnotations` field has been renamed to `annotations` since we found out it has wider use.\n* Configuration of `loadBalancerSourceRanges` and `externalTrafficPolicy` has been moved into listener configuration. Its use in the `template` section is now deprecated.\n* For `type: internal` listeners, you can now use the flag `useServiceDnsDomain` to define whether they should use the fully qualified DNS names including the cluster service suffix (usually `.cluster.local`). This option defaults to false.\n* All listeners now support configuring the advertised hostname and port.\n* `preferredAddressType` has been removed to `preferredNodePortAddressType`.\n\nTo convert the old format into the new format with backwards compatibility, you should use following names and types:\n* For the old `plain` listener, use the name `plain`, port `9092` and type `internal`.\n* For the old `tls` listener, use the name `tls`, port `9093` and type `internal`.\n* For the old `external` listener, use the name `external`, port `9094`.\n\nFor example the following old configuration:\n\n```yaml\nlisteners:\n  plain:\n    # ...\n  tls: \n    # ...\n  external:\n    type: loadbalancer \n    # ...\n```\n\nWill look like this in the new format:\n\n```yaml\nlisteners:\n  - name: plain\n    port: 9092\n    type: internal\n    tls: false\n  - name: tls\n    port: 9093\n    type: internal\n    tls: true\n  - name: external\n    port: 9094\n    type: loadbalancer\n    tls: true\n```\n\n#### Removal of monitoring port on Kafka and ZooKeeper related services\n\nThe `PodMonitor` resource is now used instead of the `ServiceMonitor` for scraping metrics from Kafka, ZooKeeper, Kafka Connect and so on.\nFor this reason, we have removed the monitoring port `tcp-prometheus` (9404) on all the services where it is declared (Kafka bootstrap, ZooKeeper client and so on).\nIt was already deprecated in the previous 0.19.0 release.\nTogether with it we have also removed the Prometheus annotations from the services. If you want to add them, you can use the templates.\nSee here https://strimzi.io/docs/operators/master/using.html#assembly-customizing-kubernetes-resources-str for more details about templates usage.\nFinally, the Kafka Exporter service was has been removed because it was used just for the monitoring port.\n\n#### Deprecation of Kafka TLS sidecar configuration\n\nSince the Kafka TLS sidecar has been removed, the related configuration options in the Kafka custom resource are now deprecated:\n* `.spec.kafka.tlsSidecar`\n* `.spec.kafka.template.tlsSidecar`\n\n## 0.19.0\n\n* Add support for authorization using Open Policy Agent\n* Add support for scale subresource to make scaling of following resources easier:\n  * KafkaConnect\n  * KafkaConnectS2I\n  * KafkaBridge\n  * KafkaMirrorMaker\n  * KafkaMirrorMaker2\n  * KafkaConnector \n* Remove deprecated `Kafka.spec.topicOperator` classes and deployment logic\n* Use Java 11 as the Java runtime\n* Removed the need to manually create Cruise Control metrics topics if topic auto creation is disabled.\n* Migration to Helm 3\n* Refactored the format of the `KafkaRebalance` resource's status. The state of the rebalance is now displayed in the associated `Condition`'s `type` field rather than the `status` field. This was done so that the information would display correctly in various Kubernetes tools.\n* Added performance tuning options to the `KafkaRebalance` CR and the ability to define a regular expression that will exclude matching topics from a rebalance optimization proposal.\n* Use Strimzi Kafka Bridge 0.18.0\n* Make it possible to configure labels and annotations for secrets created by the User Operator\n* Strimzi Kafka Bridge metrics integration:\n  * enable/disable metrics in the KafkaBridge custom resource\n  * new Grafana dashboard for the bridge metrics\n* Support dynamically changeable logging in the Entity Operator and Kafka Bridge \n* Extended the Grafana example dashboard for Kafka Connect to provide more relevant information\n\n### Deprecations and removals\n\n#### Deprecation of Helm v2 chart\n\nThe Helm v2 support will end soon. \nBug fixing should stop on August 13th 2020 and security fixes on November 13th.\nSee https://helm.sh/blog/covid-19-extending-helm-v2-bug-fixes/ for more details.\n\nIn sync with that, the Helm v2 chart of Strimzi Cluster Operator is now deprecated and will be removed in the future as Helm v2 support ends.\nSince Strimzi 0.19.0, we have a new chart for Helm v3 which can be used instead.\n\n#### Removal of v1alpha1 versions of several custom resources\n\nIn Strimzi 0.12.0, the `v1alpha1` versions of the following resources have been deprecated and replaced by `v1beta1`:\n* `Kafka`\n* `KafkaConnect`\n* `KafkaConnectS2I`\n* `KafkaMirrorMaker`\n* `KafkaTopic`\n* `KafkaUser`\n\nIn the next release, the `v1alpha1` versions of these resources will be removed. \nPlease follow the guide for upgrading the resources: https://strimzi.io/docs/operators/latest/full/deploying.html#assembly-upgrade-resources-str.\n\n#### Removal deprecated cadvisor metric labels\n\nThe `pod_name` and `container_name` labels provided on the cadvisor metrics are now just `pod` and `container` starting from Kubernetes 1.16.\nWe removed the old ones from the Prometheus scraping configuration/alerts and on the Kafka and ZooKeeper dashboard as well.\nIt means that the charts related to memory and CPU usage are not going to work on Kuvbernetes version previous 1.14.\nFor more information on what is changed: https://github.com/strimzi/strimzi-kafka-operator/pull/3312\n\n#### Deprecation of monitoring port on Kafka and ZooKeeper related services\n\nThe `PodMonitor` resource is now used instead of the `ServiceMonitor` for scraping metrics from Kafka, ZooKeeper, Kafka Connect and so on.\nFor this reason, we are deprecating the monitoring port `tcp-prometheus` (9404) on all the services where it is declared (Kafka bootstrap, ZooKeeper client and so on).\nThis port will be removed in the next release.\nTogether with it we will also remove the Prometheus annotation from the service.\n\n#### Removal warning of Cluster Operator log level\n\nBecause of the new Cluster Operator dynamic logging configuration via [PR#3328](https://github.com/strimzi/strimzi-kafka-operator/pull/3328) we are going to remove the `STRIMZI_LOG_LEVEL` environment variable from the Cluster Operator deployment YAML file in the 0.20.0 release.\n\n## 0.18.0\n\n* Add possibility to set Java System Properties for User Operator and Topic Operator via `Kafka` CR.\n* Make it possible to configure PodManagementPolicy for StatefulSets\n* Update build system to use `yq` version 3 (https://github.com/mikefarah/yq)\n* Add more metrics to Cluster and User Operators\n* New Grafana dashboard for Operator monitoring \n* Allow `ssl.cipher.suites`, `ssl.protocol` and `ssl.enabled.protocols` to be configurable for Kafka and the different components supported by Strimzi\n* Add support for user configurable SecurityContext for each Strimzi container\n* Allow standalone User Operator to modify status on KafkaUser\n* Add support for Kafka 2.4.1\n* Add support for Kafka 2.5.0\n* Remove TLS sidecars from ZooKeeper pods, using native ZooKeeper TLS support instead\n* Add metrics for Topic Operator\n* Use Strimzi Kafka Bridge 0.16.0\n* Add support for CORS in the HTTP Kafka Bridge\n* Pass HTTP Proxy configuration from operator to operands\n* Add Cruise Control support, KafkaRebalance resource and rebalance operator\n\n## 0.17.0\n\n* Add possibility to set Java System Properties via CR yaml\n* Add support for Mirror Maker 2.0\n* Add Jmxtrans deployment\n* Add public keys of TLS listeners to the status section of the Kafka CR\n* Add support for using a Kafka authorizer backed by Keycloak Authorization Services\n\n## 0.16.0\n\n* Add support for Kafka 2.4.0 and upgrade from Zookeeper 3.4.x to 3.5.x\n* Drop support for Kafka 2.2.1 and 2.3.0\n* Add KafkaConnector resource and connector operator\n* Let user choose which node address will be used as advertised host (`ExternalDNS`, `ExternalIP`, `InternalDNS`, `InternalIP` or `Hostname`)\n* Add support for tini\n* When not explicitly configured by the user in `jvmOptions`, `-Xmx` option is calculated from memory requests rather than from memory limits\n* Expose JMX port on Kafka brokers via an internal service\n* Add support for `externalTrafficPolicy` and `loadBalancerSourceRanges` properties on loadbalancer and nodeport type services\n* Add support for user quotas\n* Add support for Istio protocol selection in service port names  \nNote: Strimzi is essentially adding a `tcp-` prefix to the port names in Kafka services and headless services.  \n(e.g clientstls -> tcp-clientstls)\n* Add service discovery labels and annotations\n* Add possibility to specify custom server certificates to TLS based listeners\n\n## 0.15.0\n\n* Drop support for Kafka 2.1.0, 2.1.1, and 2.2.0\n* Add support for Kafka 2.3.1\n* Improved Kafka rolling update\n* Improve Kafka Exporter Grafana dashboard\n* Add sizeLimit option to ephemeral storage (#1505)\n* Add `schedulerName` to `podTemplate` (#2114)\n* Allow overriding the auto-detected Kubernetes version\n* Garbage Collection (GC) logging disabled by default\n* Providing PKCS12 truststore and password in the cluster and clients CA certificates Secrets\n* Providing PKCS12 keystore and password in the TLS based KafkaUser related Secret\n\n## 0.14.0\n\n* Add support for configuring Ingress class (#1716)\n* Add support for setting custom environment variables in all containers\n* Add liveness and readiness checks to Mirror Maker\n* Allow configuring loadBalancerIP for LoadBalancer type services\n* Allow setting labels and annotations for Persistent Volume Claims\n* Add support for Jaeger tracing in Kafka Mirror Maker and Kafka Connect\n* Add support for deploying Kafka Exporter\n* Add initial support for OAuth authentication\n\n## 0.13.0\n\n* Allow users to manually configure ACL rules (for example, using `kafka-acls.sh`) for special Kafka users `*` and `ANONYMOUS` without them being deleted by the User Operator\n* Add support for configuring a Priority Class name for Pods deployed by Strimzi\n* Add support for Kafka 2.3.0\n* Add support for Kafka User resource status\n* Add support for Kafka Connect resource status\n* Add support for Kafka Connect S2I resource status\n* Add support for Kafka Bridge resource status\n* Add support for Kafka Mirror Maker resource status\n* Add support for DNS annotations to `nodeport` type external listeners\n\n## 0.12.0\n\n* **Drop support for Kubernetes 1.9 and 1.10 and OpenShift 3.9 and 3.10.**\n**Versions supported since Strimzi 0.12.0 are Kubernetes 1.11 and higher and OpenShift 3.11 and higher.** \n**This was required because the CRD versioning and CRD subresources support.** \n* Added support for Kafka 2.2.0 and 2.1.1, dropped support for Kafka 2.0.0 and 2.0.1\n* Persistent storage improvements\n  * Add resizing of persistent volumes\n  * Allow to specify different storage class for every broker\n  * Adding and removing volumes in Jbod Storage\n* Custom Resources improvements\n  * New CRD version `v1beta1`. See documentation for more information about upgrading from `v1alpha1` to `v1beta1`.\n  * Log at the warn level when a custom resource uses deprecated or unknown properties\n  * Add initial support for the `status` sub-resource in the `Kafka` custom resource \n* Add support for [Strimzi Kafka Bridge](https://github.com/strimzi/strimzi-kafka-bridge) for HTTP protocol\n* Reduce the number of container images needed to run Strimzi to just two: `kafka` and `operator`.\n* Add support for unprivileged users to install the operator with Helm\n* Support experimental off-cluster access using Kubernetes Nginx Ingress\n* Add ability to configure Image Pull Secrets for all pods in Cluster Operator\n* Support for SASL PLAIN mechanism in Kafka Connect and Mirror Maker (for use with non-Strimzi Kafka cluster)\n\n## 0.11.0\n\n* Add support for JBOD storage for Kafka brokers\n* Allow users to configure the default ImagePullPolicy\n* Add Prometheus alerting\n    * Resources for alert manager deployment and configuration\n    * Alerting rules with alert examples from Kafka and Zookeeper metrics\n* Enrich configuration options for off cluster access\n* Support for watching all namespaces\n* Operator Lifecycle Manager integration\n\n## 0.10.0\n\n* Support for Kafka 2.1.0\n* Support for Kafka upgrades\n* Add healthchecks to TLS sidecars\n* Add support for new fields in the Pod template: terminationGracePeriod, securityContext and imagePullSecrets\n* Rename annotations to use the `strimzi.io` domain consistently (The old annotations are deprecated, but still functional):\n    * `cluster.operator.strimzi.io/delete-claim` → `strimzi.io/delete-claim` \n    * `operator.strimzi.io/manual-rolling-update` → `strimzi.io/manual-rolling-update` \n    * `operator.strimzi.io/delete-pod-and-pvc` → `strimzi.io/delete-pod-and-pvc`\n    * `operator.strimzi.io/generation` → `strimzi.io/generation`\n* Add support for mounting Secrets and Config Maps into Kafka Connect and Kafka Connect S2I\n* Add support for NetworkPolicy peers in listener configurations\n* Make sure the TLS sidecar pods shutdown only after the main container\n* Add support for Pod Disruption Budgets\n\n## 0.9.0\n\n* Add possibility to label and annotate different resources (#1039)\n* Add support for TransactionalID in KafkaUser resource\n* Update to Kafka 2.0.1\n* Add maintenance time windows support for allowing CA certificates renewal rolling update started only in specific times (#1117)  \n* Add support for upgrading between Kafka versions (#1103). This removes support for `STRIMZI_DEFAULT_KAFKA_IMAGE` environment variable in the Cluster Operator, replacing it with `STRIMZI_KAFKA_IMAGES`.  \n\n\n## 0.8.2\n\n* Run images under group 0 to avoid storage issues\n\n## 0.8.1\n\n* Fix certificate renewal issues\n\n## 0.8.0\n\n* Support for unencrypted connections on LoadBalancers and NodePorts.\n* Better support for TLS hostname verification for external connections\n* Certificate renewal / expiration\n* Mirror Maker operator\n* Triggering rolling update / pod deletion manually\n\n## 0.7.0\n\n* Exposing Kafka to the outside using:\n  * OpenShift Routes\n  * LoadBalancers\n  * NodePorts\n* Use less wide RBAC permissions (`ClusterRoleBindings` where converted to `RoleBindings` where possible)\n* Support for SASL authentication using the SCRAM-SHA-512 mechanism added to Kafka Connect and Kafka Connect with S2I support \n* Network policies for managing access to Zookeeper ports and Kafka replication ports\n* Use OwnerReference and Kubernetes garbage collection feature to delete resources and to track the ownership\n\n## 0.6.0\n\n* Helm chart for Strimzi Cluster Operator\n* Topic Operator moving to Custom Resources instead of Config Maps\n* Make it possible to enabled and disable:\n  * Listeners\n  * Authorization\n  * Authentication\n* Configure Kafka _super users_ (`super.users` field in Kafka configuration)\n* User Operator\n  * Managing users and their ACL rights\n* Added new Entity Operator for deploying:\n  * User Operator\n  * Topic Operator\n* Deploying the Topic Operator outside of the new Entity Operator is now deprecated\n* Kafka 2.0.0\n* Kafka Connect:\n  * Added TLS support for connecting to the Kafka cluster\n  * Added TLS client authentication when connecting to the Kafka cluster \n\n## 0.5.0\n\n* The Cluster Operator now manages RBAC resource for managed resources:\n    * `ServiceAccount` and `ClusterRoleBindings` for Kafka pods\n    * `ServiceAccount` and `RoleBindings` for the Topic Operator pods\n* Renaming of Kubernetes services (Backwards incompatible!)\n  * Kubernetes services for Kafka, Kafka Connect and Zookeeper have been renamed to better correspond to their purpose\n  * `xxx-kafka` -> `xxx-kafka-bootstrap`\n  * `xxx-kafka-headless` -> `xxx-kafka-brokers`\n  * `xxx-zookeeper` -> `xxx-zookeeper-client`\n  * `xxx-zookeeper-headless` -> `xxx-zookeeper-nodes`\n  * `xxx-connect` -> `xxx-connect-api`\n* Cluster Operator moving to Custom Resources instead of Config Maps\n* TLS support has been added to Kafka, Zookeeper and Topic Operator. The following channels are now encrypted:\n    * Zookeeper cluster communication\n    * Kafka cluster commbunication\n    * Communication between Kafka and Zookeeper\n    * Communication between Topic Operator and Kafka / Zookeeper\n* Logging configuration for Kafka, Kafka Connect and Zookeeper\n* Add support for [Pod Affinity and Anti-Affinity](https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity)\n* Add support for [Tolerations](https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#toleration-v1-core)\n* Configuring different JVM options\n* Support for broker rack in Kafka\n\n## 0.4.0\n\n* Better configurability of Kafka, Kafka Connect, Zookeeper\n* Support for Kubernetes request and limits\n* Support for JVM memory configuration of all components\n* Controllers renamed to operators\n* Improved log verbosity of Cluster Operator\n* Update to Kafka 1.1.0\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 0.1767578125,
          "content": "# Strimzi Community Code of Conduct\n\nStrimzi Community Code of Conduct is defined in the [governance repository](https://github.com/strimzi/governance/blob/main/CODE_OF_CONDUCT.md)."
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 4.271484375,
          "content": "# Contributing\n\nYou can contribute by:\n\n* Raising any issues you find using Strimzi\n* Fixing issues by opening Pull Requests\n* Improving documentation\n* Talking about Strimzi\n\nAll bugs, tasks or enhancements are tracked as [GitHub issues][issues]. Issues which might be a good start for new contributors are marked with the [“good-start”][newbie-issues] label.\n\nThe [development guide][development-guide] describes how to quickly get setup to build Strimzi from source. It also goes into more detail of various ways you can build Strimzi and how to test your changes before submitting a patch or opening a pull request.\n\nThe [release checklist][release-list] describes the steps that need to be completed for a new version release.\n\nThe [documentation contributor guide][doc-contrib-guide] describes how to contribute to Strimzi documentation.\n\nIf you want to get in touch with us first before contributing, you can use:\n\n- [#strimzi channel on CNCF Slack](https://slack.cncf.io/)\n- [Strimzi Dev mailing list](https://lists.cncf.io/g/cncf-strimzi-dev/topics)\n\n## Developer Certificate Of Origin\n\nThe [Developer Certificate of Origin (DCO)][dco] is a lightweight way for contributors to certify that they wrote or otherwise have the right to submit the code they are contributing to the project.\n\nContributors to the Strimzi project sign-off that they adhere to these requirements by adding a Signed-off-by line to commit messages.\n\n```shell\nThis is my commit message\n\nSigned-off-by: John Doe <JohnDoe@somewhere.org>\n```\n\nGit even has a -s command line option to append this automatically to your commit message:\n\n```shell\ngit commit -s -m 'This is my commit message'\n```\n\nIf you have already made a commit and forgot to include the sign-off, you can amend your last commit to add the sign-off with the following command, which can then be force pushed.\n\n```shell\ngit commit --amend -s\n```\n\n[issues]: https://github.com/strimzi/strimzi-kafka-operator/issues\n[newbie-issues]: https://github.com/strimzi/strimzi-kafka-operator/labels/good-start\n[development-guide]: development-docs/DEV_GUIDE.md\n[release-list]: development-docs/RELEASE.md\n[doc-contrib-guide]: https://strimzi.io/contributing/guide/\n[dco]: https://developercertificate.org/\n\n# How to become a maintainer\n\nThe governance of the project is defined in the [GOVERNANCE.md](https://github.com/strimzi/strimzi-kafka-operator/blob/main/GOVERNANCE.md) file in the Strimzi Github repository, but in summary certain members of the community are the \"maintainers\" who decide the direction of the project. New maintainers can be elected by a ⅔ majority vote of the existing maintainers.\n\nSo as to be transparent and to ensure that all potential maintainers are judged fairly and consistently the following criteria should be taken into account in electing new maintainers:\n\n## Criteria\n\n* Sustained contributions over at least 3 months ideally including non-trivial PRs.\n* An area of developing expertise. This includes the HTTP Bridge and Oauth components. The candidate does not have to be the _go-to_ expert, but they should have a more than superficial understanding of at least one area. For example:\n    - A particular operator\n    - Some Kubernetes concern (CRDs, API, JSON Schema, and so on)\n    - Some associated bit of Kafka technology in which the project has a strategic interest (Cruise Control, for example)\n    - System tests\n    - Documentation\n* Reviewing other contributors' PRs (not just for trivial errors, such as typos, but also guiding contributors on \"big picture\" aspects such as the future direction of the project).\n* Contributing to different aspects of the project and community. For example it’s not enough to just implement features. We should also consider:\n    - Bug reporting, triage and fixing\n    - Addressing technical debt (in code, testing and documentation).\n    - Documentation (both content and structure).\n    - Helping users, for example on GitHub, the mailing list, Slack, Stack Overflow, and so on.   \n    - Promotion of Strimzi, for example by blogging, speaking at conferences, and so on.\n* An understanding of the overall architecture/structure of the codebase.\n* Knowing when to ask for help or seek consensus (being a maintainer is not a licence to merge \"at will\" whatever you chose).\n* An indication of being committed to the long term success of the project.\n\n"
        },
        {
          "name": "GOVERNANCE.md",
          "type": "blob",
          "size": 0.142578125,
          "content": "# Strimzi Governance\n\nStrimzi Governance is defined in the [governance repository](https://github.com/strimzi/governance/blob/main/GOVERNANCE.md)."
        },
        {
          "name": "KAFKA_VERSION_SUPPORT.md",
          "type": "blob",
          "size": 0.6171875,
          "content": "# Supported Apache Kafka versions\n\nIt is not feasible to maintain support for all available Apache Kafka versions.\nThe following rules describe our plans for Kafka versions supported in Strimzi:\n\n* Support at least the last two major/minor versions of Apache Kafka. _For example: Support for Kafka 2.2.x could be removed when support for 2.4.x is added._\n* Support at least one common Kafka release in two consecutive major/minor Strimzi releases to allow smooth upgrades between Strimzi and Kafka versions. _For example: when Strimzi 0.13.x supports Kafka 2.2.0 and 2.3.0, Strimzi 0.14.x has to provide support for 2.3.0 as well._\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"{}\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright {yyyy} {name of copyright owner}\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "MAINTAINERS",
          "type": "blob",
          "size": 0.15234375,
          "content": "# Strimzi Maintainers list\n\nStrimzi Maintainers list is defined in the [governance repository](https://github.com/strimzi/governance/blob/main/MAINTAINERS)."
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 13.373046875,
          "content": "TOPDIR=$(dir $(lastword $(MAKEFILE_LIST)))\n\ninclude ./Makefile.os\n\nSHELL = /usr/bin/env bash\nGITHUB_VERSION ?= main\nOAUTH_VERSION = $(shell source ./tools/strimzi-oauth-version.sh && get_strimzi_oauth_version)\nRELEASE_VERSION ?= latest\nCHART_SEMANTIC_RELEASE_VERSION ?= $(shell cat ./release.version | tr A-Z a-z)\nBRIDGE_VERSION ?= $(shell cat ./bridge.version | tr A-Z a-z)\nDOCKER_CMD ?= docker\n\nifneq ($(RELEASE_VERSION),latest)\n  GITHUB_VERSION = $(RELEASE_VERSION)\nendif\n\nSUBDIRS=kafka-agent tracing-agent crd-annotations test crd-generator api mockkube certificate-manager operator-common config-model config-model-generator cluster-operator topic-operator user-operator kafka-init systemtest docker-images/artifacts packaging/helm-charts/helm3 packaging/install packaging/examples\nDOCKERDIRS=docker-images/base docker-images/operator docker-images/kafka-based docker-images/maven-builder docker-images/kaniko-executor\nDOCKER_TARGETS=docker_build docker_push docker_tag docker_load docker_save docker_amend_manifest docker_push_manifest docker_sign_manifest docker_delete_manifest docker_delete_archive docker_sbom docker_push_sbom\nJAVA_TARGETS=java_build java_install java_clean\n\nall: prerequisites_check $(SUBDIRS) $(DOCKERDIRS) crd_install dashboard_install helm_install shellcheck docu_versions docu_check\nclean: prerequisites_check $(SUBDIRS) $(DOCKERDIRS) docu_clean\n$(DOCKER_TARGETS): prerequisites_check $(DOCKERDIRS)\n$(JAVA_TARGETS): prerequisites_check $(SUBDIRS)\nrelease: release_prepare release_version release_helm_version release_maven $(SUBDIRS) release_docu release_single_file release_pkg docu_clean\n\nnext_version:\n\techo $(shell echo $(NEXT_VERSION) | tr a-z A-Z) > release.version\n\tmvn versions:set -DnewVersion=$(shell echo $(NEXT_VERSION) | tr a-z A-Z)\n\tmvn versions:commit\n\nbridge_version:\n\t# Set Kafka Bridge version to its own version\n\t$(FIND) ./packaging/install -name '*.yaml' -type f -exec $(SED) -i '/value: \"\\?quay.io\\/strimzi\\/kafka-bridge:[a-zA-Z0-9_.-]\\+\"\\?/s/quay.io\\/strimzi\\/kafka-bridge:[a-zA-Z0-9_.-]\\+/quay.io\\/strimzi\\/kafka-bridge:$(BRIDGE_VERSION)/g' {} \\;\n\tCHART_PATH=./packaging/helm-charts/helm3/strimzi-kafka-operator; \\\n\t$(SED) -i '/name: kafka-bridge/{n;s/\\(tag: \\).*/\\1$(BRIDGE_VERSION)/g}' $$CHART_PATH/values.yaml; \\\n\t$(SED) -i 's/\\(kafkaBridge.image\\.tag[^\\n]*| \\)`.*`/\\1`$(BRIDGE_VERSION)`/g' $$CHART_PATH/README.md\n\nrelease_prepare:\n\techo $(shell echo $(RELEASE_VERSION) | tr a-z A-Z) > release.version\n\trm -rf ./strimzi-$(RELEASE_VERSION)\n\trm -f ./strimzi-$(RELEASE_VERSION).tar.gz\n\trm -f ./strimzi-$(RELEASE_VERSION).zip\n\trm -f ./strimzi-kafka-operator-helm-3-chart-$(RELEASE_VERSION).tgz\n\trm -f ./strimzi-topic-operator-$(RELEASE_VERSION).yaml\n\trm -f ./strimzi-cluster-operator-$(RELEASE_VERSION).yaml\n\trm -f ./strimzi-user-operator-$(RELEASE_VERSION).yaml\n\tmkdir ./strimzi-$(RELEASE_VERSION)\n\t$(CP) CHANGELOG.md ./strimzi-$(RELEASE_VERSION)\n\nrelease_version:\n\t# TODO: This would be replaced ideally once Helm Chart templating is used for cluster and topic operator examples\n\techo \"Changing Docker image tags in install to :$(RELEASE_VERSION)\"\n\t$(FIND) ./packaging/install -name '*.yaml' -type f -exec $(SED) -i '/image: \"\\?quay.io\\/strimzi\\/operator:[a-zA-Z0-9_.-]\\+\"\\?/s/:[a-zA-Z0-9_.-]\\+/:$(RELEASE_VERSION)/g' {} \\;\n\t$(FIND) ./packaging/install -name '*.yaml' -type f -exec $(SED) -i '/value: \"\\?quay.io\\/strimzi\\/operator:[a-zA-Z0-9_.-]\\+\"\\?/s/quay.io\\/strimzi\\/operator:[a-zA-Z0-9_.-]\\+/quay.io\\/strimzi\\/operator:$(RELEASE_VERSION)/g' {} \\;\n\t$(FIND) ./packaging/install -name '*.yaml' -type f -exec $(SED) -i '/value: \"\\?quay.io\\/strimzi\\/kafka-bridge:[a-zA-Z0-9_.-]\\+\"\\?/s/quay.io\\/strimzi\\/kafka-bridge:[a-zA-Z0-9_.-]\\+/quay.io\\/strimzi\\/kafka-bridge:$(BRIDGE_VERSION)/g' {} \\;\n\t$(FIND) ./packaging/install -name '*.yaml' -type f -exec $(SED) -i '/value: \"\\?quay.io\\/strimzi\\/kafka:[a-zA-Z0-9_.-]\\+\"\\?/s/quay.io\\/strimzi\\/kafka:[a-zA-Z0-9_.-]\\+-kafka-\\([0-9.]\\+\\)/quay.io\\/strimzi\\/kafka:$(RELEASE_VERSION)-kafka-\\1/g' {} \\;\n\t$(FIND) ./packaging/install -name '*.yaml' -type f -exec $(SED) -i '/[0-9.]\\+=quay.io\\/strimzi\\/kafka[a-zA-Z0-9_.-]\\?\\+:[a-zA-Z0-9_.-]\\+-kafka-[0-9.]\\+\"\\?/s/:[a-zA-Z0-9_.-]\\+-kafka-\\([0-9.]\\+\\)/:$(RELEASE_VERSION)-kafka-\\1/g' {} \\;\n\t$(FIND) ./packaging/install -name '*.yaml' -type f -exec $(SED) -i '/value: \"\\?quay.io\\/strimzi\\/kaniko-executor:[a-zA-Z0-9_.-]\\+\"\\?/s/quay.io\\/strimzi\\/kaniko-executor:[a-zA-Z0-9_.-]\\+/quay.io\\/strimzi\\/kaniko-executor:$(RELEASE_VERSION)/g' {} \\;\n\t$(FIND) ./packaging/install -name '*.yaml' -type f -exec $(SED) -i '/value: \"\\?quay.io\\/strimzi\\/maven-builder:[a-zA-Z0-9_.-]\\+\"\\?/s/quay.io\\/strimzi\\/maven-builder:[a-zA-Z0-9_.-]\\+/quay.io\\/strimzi\\/maven-builder:$(RELEASE_VERSION)/g' {} \\;\n\t# Set Kafka Bridge version to its own version\n\t$(FIND) ./packaging/install -name '*.yaml' -type f -exec $(SED) -i '/value: \"\\?quay.io\\/strimzi\\/kafka-bridge:[a-zA-Z0-9_.-]\\+\"\\?/s/quay.io\\/strimzi\\/kafka-bridge:[a-zA-Z0-9_.-]\\+/quay.io\\/strimzi\\/kafka-bridge:$(BRIDGE_VERSION)/g' {} \\;\n\nrelease_maven:\n\techo \"Update pom versions to $(RELEASE_VERSION)\"\n\tmvn versions:set -DnewVersion=$(shell echo $(RELEASE_VERSION) | tr a-z A-Z)\n\tmvn versions:commit\n\nrelease_pkg: helm_pkg\n\ttar -z -cf ./strimzi-$(RELEASE_VERSION).tar.gz strimzi-$(RELEASE_VERSION)/\n\tzip -r ./strimzi-$(RELEASE_VERSION).zip strimzi-$(RELEASE_VERSION)/\n\trm -rf ./strimzi-$(RELEASE_VERSION)\n\t$(FIND) ./examples/ -mindepth 1 -maxdepth 1 ! -name DO_NOT_EDIT.md -type f,d -exec rm -rvf {} +\n\t$(FIND) ./install/ -mindepth 1 -maxdepth 1 ! -name DO_NOT_EDIT.md -type f,d -exec rm -rvf {} +\n\trm -rfv ./helm-charts/helm3/strimzi-kafka-operator\n\t$(FIND) ./packaging/examples/ -mindepth 1 -maxdepth 1 ! -name Makefile -type f,d -exec $(CP) -rv {} ./examples/ \\;\n\t$(FIND) ./packaging/install/ -mindepth 1 -maxdepth 1 ! -name Makefile -type f,d -exec $(CP) -rv {} ./install/ \\;\n\t$(CP) -rv ./packaging/helm-charts/helm3/strimzi-kafka-operator ./helm-charts/helm3/strimzi-kafka-operator\n\nrelease_helm_version:\n\techo \"Updating default image tags in Helm Chart to $(RELEASE_VERSION)\"\n\tCHART_PATH=./packaging/helm-charts/helm3/strimzi-kafka-operator; \\\n\t$(SED) -i 's/\\(defaultImageTag: \\).*/\\1$(RELEASE_VERSION)/g' $$CHART_PATH/values.yaml; \\\n\t$(SED) -i 's/\\(defaultImageTag[^\\n]*| \\)`.*`/\\1`$(RELEASE_VERSION)`/g' $$CHART_PATH/README.md; \\\n\t$(SED) -i '/name: kafka-bridge/{n;s/\\(tag: \\).*/\\1$(BRIDGE_VERSION)/g}' $$CHART_PATH/values.yaml; \\\n\t$(SED) -i 's/\\(kafkaBridge.image\\.tag[^\\n]*| \\)`.*`/\\1`$(BRIDGE_VERSION)`/g' $$CHART_PATH/README.md\n\nrelease_single_file:\n\t$(FIND) ./strimzi-$(RELEASE_VERSION)/install/cluster-operator/ -type f -exec cat {} \\; -exec printf \"\\n---\\n\" \\; > strimzi-cluster-operator-$(RELEASE_VERSION).yaml\n\t$(FIND) ./strimzi-$(RELEASE_VERSION)/install/topic-operator/ -type f -exec cat {} \\; -exec printf \"\\n---\\n\" \\; > strimzi-topic-operator-$(RELEASE_VERSION).yaml\n\t$(FIND) ./strimzi-$(RELEASE_VERSION)/install/user-operator/ -type f -exec cat {} \\; -exec printf \"\\n---\\n\" \\; > strimzi-user-operator-$(RELEASE_VERSION).yaml\n\t$(FIND) ./strimzi-$(RELEASE_VERSION)/install/cluster-operator/*-Crd-*.yaml -type f -exec cat {} \\; -exec printf \"\\n---\\n\" \\; > strimzi-crds-$(RELEASE_VERSION).yaml\n\nhelm_pkg: dashboard_install\n\t# Copying unarchived Helm Chart to release directory\n\tmkdir -p strimzi-$(RELEASE_VERSION)/helm3-charts/\n\thelm package --version $(CHART_SEMANTIC_RELEASE_VERSION) --app-version $(CHART_SEMANTIC_RELEASE_VERSION) --destination ./ ./packaging/helm-charts/helm3/strimzi-kafka-operator/\n\t$(CP) strimzi-kafka-operator-$(CHART_SEMANTIC_RELEASE_VERSION).tgz strimzi-kafka-operator-helm-3-chart-$(CHART_SEMANTIC_RELEASE_VERSION).tgz\n\trm -rf strimzi-$(RELEASE_VERSION)/helm3-charts/\n\trm strimzi-kafka-operator-$(CHART_SEMANTIC_RELEASE_VERSION).tgz\n\ndocu_versions:\n\tdocumentation/version-dependent-attrs.sh > documentation/shared/version-dependent-attrs.adoc\n\tdocumentation/snip-images.sh > documentation/modules/snip-images.adoc\n\ndocu_html: docu_htmlclean docu_versions docu_check\n\tmkdir -p documentation/html\n\t$(CP) -vrL documentation/shared/images documentation/html/images\n\tasciidoctor -v --failure-level WARN -t -dbook -a ProductVersion=$(RELEASE_VERSION) -a BridgeVersion=$(BRIDGE_VERSION) -a GithubVersion=$(GITHUB_VERSION) -a OAuthVersion=$(OAUTH_VERSION) documentation/deploying/deploying.adoc -o documentation/html/deploying.html\n\tasciidoctor -v --failure-level WARN -t -dbook -a ProductVersion=$(RELEASE_VERSION) -a BridgeVersion=$(BRIDGE_VERSION) -a GithubVersion=$(GITHUB_VERSION) -a OAuthVersion=$(OAUTH_VERSION) documentation/configuring/configuring.adoc -o documentation/html/configuring.html\n\tasciidoctor -v --failure-level WARN -t -dbook -a ProductVersion=$(RELEASE_VERSION) -a BridgeVersion=$(BRIDGE_VERSION) -a GithubVersion=$(GITHUB_VERSION) -a OAuthVersion=$(OAUTH_VERSION) documentation/overview/overview.adoc -o documentation/html/overview.html\n\tasciidoctor -v --failure-level WARN -t -dbook -a ProductVersion=$(RELEASE_VERSION) -a BridgeVersion=$(BRIDGE_VERSION) -a GithubVersion=$(GITHUB_VERSION) -a OAuthVersion=$(OAUTH_VERSION) documentation/contributing/contributing.adoc -o documentation/html/contributing.html\n\ndocu_htmlnoheader: docu_htmlnoheaderclean docu_versions docu_check\n\tmkdir -p documentation/htmlnoheader\n\t$(CP) -vrL documentation/shared/images documentation/htmlnoheader/images\n\tasciidoctor -v --failure-level WARN -t -dbook -a ProductVersion=$(RELEASE_VERSION) -a BridgeVersion=$(BRIDGE_VERSION) -a GithubVersion=$(GITHUB_VERSION) -a OAuthVersion=$(OAUTH_VERSION) -s documentation/deploying/deploying.adoc -o documentation/htmlnoheader/deploying-book.html\n\tasciidoctor -v --failure-level WARN -t -dbook -a ProductVersion=$(RELEASE_VERSION) -a BridgeVersion=$(BRIDGE_VERSION) -a GithubVersion=$(GITHUB_VERSION) -a OAuthVersion=$(OAUTH_VERSION) -s documentation/configuring/configuring.adoc -o documentation/htmlnoheader/configuring-book.html\n\tasciidoctor -v --failure-level WARN -t -dbook -a ProductVersion=$(RELEASE_VERSION) -a BridgeVersion=$(BRIDGE_VERSION) -a GithubVersion=$(GITHUB_VERSION) -a OAuthVersion=$(OAUTH_VERSION) -s documentation/overview/overview.adoc -o documentation/htmlnoheader/overview-book.html\n\tasciidoctor -v --failure-level WARN -t -dbook -a ProductVersion=$(RELEASE_VERSION) -a BridgeVersion=$(BRIDGE_VERSION) -a GithubVersion=$(GITHUB_VERSION) -a OAuthVersion=$(OAUTH_VERSION) -s documentation/contributing/contributing.adoc -o documentation/htmlnoheader/contributing-book.html\n\ndocu_pdf: docu_pdfclean docu_versions docu_check\n\tmkdir -p documentation/pdf\n\tasciidoctor-pdf -v --failure-level WARN -t -dbook -a ProductVersion=$(RELEASE_VERSION) -a BridgeVersion=$(BRIDGE_VERSION) -a GithubVersion=$(GITHUB_VERSION) -a OAuthVersion=$(OAUTH_VERSION) documentation/deploying/deploying.adoc -o documentation/pdf/deploying.pdf\n\tasciidoctor-pdf -v --failure-level WARN -t -dbook -a ProductVersion=$(RELEASE_VERSION) -a BridgeVersion=$(BRIDGE_VERSION) -a GithubVersion=$(GITHUB_VERSION) -a OAuthVersion=$(OAUTH_VERSION) documentation/configuring/configuring.adoc -o documentation/pdf/configuring.pdf\n\tasciidoctor-pdf -v --failure-level WARN -t -dbook -a ProductVersion=$(RELEASE_VERSION) -a BridgeVersion=$(BRIDGE_VERSION) -a GithubVersion=$(GITHUB_VERSION) -a OAuthVersion=$(OAUTH_VERSION) documentation/overview/overview.adoc -o documentation/pdf/overview.pdf\n\tasciidoctor-pdf -v --failure-level WARN -t -dbook -a ProductVersion=$(RELEASE_VERSION) -a BridgeVersion=$(BRIDGE_VERSION) -a GithubVersion=$(GITHUB_VERSION) -a OAuthVersion=$(OAUTH_VERSION) documentation/contributing/contributing.adoc -o documentation/pdf/contributing.pdf\n\ndocu_check:\n\t./.azure/scripts/check_docs.sh\n\nshellcheck:\n\t./.azure/scripts/shellcheck.sh\n\nrelease_files_check:\n\t./.azure/scripts/release_files_check.sh\n\nspotbugs: $(SUBDIRS)\n\ndocu_pushtowebsite:\n\t./.azure/scripts/docu-push-to-website.sh\n\npushtonexus:\n\t./.azure/scripts/push-to-nexus.sh\n\nrelease_docu: docu_html docu_htmlnoheader docu_pdf\n\tmkdir -p strimzi-$(RELEASE_VERSION)/docs/html\n\tmkdir -p strimzi-$(RELEASE_VERSION)/docs/pdf\n\t$(CP) -rv documentation/pdf/overview.pdf strimzi-$(RELEASE_VERSION)/docs/pdf/\n\t$(CP) -rv documentation/pdf/deploying.pdf strimzi-$(RELEASE_VERSION)/docs/pdf/\n\t$(CP) -rv documentation/pdf/configuring.pdf strimzi-$(RELEASE_VERSION)/docs/pdf/\n\t$(CP) -rv documentation/html/overview.html strimzi-$(RELEASE_VERSION)/docs/html/\n\t$(CP) -rv documentation/html/deploying.html strimzi-$(RELEASE_VERSION)/docs/html/\n\t$(CP) -rv documentation/html/configuring.html strimzi-$(RELEASE_VERSION)/docs/html/\n\t$(CP) -rv documentation/html/images/ strimzi-$(RELEASE_VERSION)/docs/html/images/\n\ndocu_clean: docu_htmlclean docu_htmlnoheaderclean docu_pdfclean\n\ndocu_htmlclean:\n\trm -rf documentation/html\n\ndocu_htmlnoheaderclean:\n\trm -rf documentation/htmlnoheader\n\ndocu_pdfclean:\n\trm -rf documentation/pdf\n\nhelm_install:\n\t$(MAKE) -C packaging/helm-charts/helm3 helm_install\n\nhelm_unittest:\n\t$(MAKE) -C packaging/helm-charts/helm3 helm_unittest\n\ncrd_install:\n\t$(MAKE) -C packaging/install crd_install\n\ndashboard_install:\n\t$(MAKE) -C packaging/examples dashboard_install\n\n$(SUBDIRS):\n\t$(MAKE) -C $@ $(MAKECMDGOALS)\n\n$(DOCKERDIRS):\n\t$(MAKE) -C $@ $(MAKECMDGOALS)\n\nprerequisites_check:\n\tSED=$(SED) ./tools/prerequisites-check.sh\n\nchecksum_examples:\n\t@$(FIND) ./examples/ -type f -print0 | LC_ALL=C $(SORT) -z | $(XARGS) -0 $(SHA1SUM) | $(SHA1SUM)\n\nchecksum_install:\n\t@$(FIND) ./install/ -type f -print0 | LC_ALL=C $(SORT) -z | $(XARGS) -0 $(SHA1SUM) | $(SHA1SUM)\n\nchecksum_helm:\n\t@$(FIND) ./helm-charts/ -type f -print0 | LC_ALL=C $(SORT) -z | $(XARGS) -0 $(SHA1SUM) | $(SHA1SUM)\n\n.PHONY: all $(SUBDIRS) $(DOCKERDIRS) $(DOCKER_TARGETS) docu_versions spotbugs docu_check prerequisites_check\n"
        },
        {
          "name": "Makefile.docker",
          "type": "blob",
          "size": 7.1044921875,
          "content": "# Makefile.docker contains the shared tasks for building, tagging and pushing Docker images.\n# This file is included into the Makefile files which contain the Dockerfile files (E.g.\n# kafka-base, kafka etc.).\n#\n# The DOCKER_ORG (default is name of the current user) and DOCKER_TAG (based on Git Tag,\n# default latest) variables are used to name the Docker image. DOCKER_REGISTRY identifies\n# the registry where the image will be pushed (default is Docker Hub).\nTOPDIR=$(dir $(lastword $(MAKEFILE_LIST)))\nARCHIVE_DIR=$(TOPDIR)docker-images/container-archives\nSBOM_DIR=$(TOPDIR)sbom\n\nDOCKERFILE_DIR     ?= ./\nDOCKER_CMD         ?= docker\nDOCKER_REGISTRY    ?= docker.io\nDOCKER_ORG         ?= $(USER)\nDOCKER_TAG         ?= latest\nBUILD_TAG          ?= latest\nBUILD_ID           ?= n/a\nBUILD_COMMIT       ?= n/a\nRELEASE_VERSION    ?= $(shell cat $(TOPDIR)/release.version)\n\nifdef DOCKER_ARCHITECTURE\n  DOCKER_PLATFORM = --platform linux/$(DOCKER_ARCHITECTURE)\n  DOCKER_PLATFORM_TAG_SUFFIX = -$(DOCKER_ARCHITECTURE)\n  SBOM_DIR=$(TOPDIR)sbom/$(DOCKER_ARCHITECTURE)\nendif\n\nall: docker_build docker_push\n\ndocker_build_default:\n\t# Build Docker image ...\n\t$(DOCKER_CMD) $(DOCKER_BUILDX) build $(DOCKER_PLATFORM) $(DOCKER_BUILD_ARGS) --build-arg strimzi_version=$(RELEASE_VERSION) -t strimzi/$(PROJECT_NAME):latest $(DOCKERFILE_DIR)\n#   The Dockerfiles all use FROM ...:latest, so it is necessary to tag images with latest (-t above)\n#   But because we generate Kafka images for different versions we also need to tag with something\n#   including the kafka version number. This BUILD_TAG is used by the docker_tag target.\n\t# Also tag with $(BUILD_TAG)\n\t$(DOCKER_CMD) tag strimzi/$(PROJECT_NAME):latest strimzi/$(PROJECT_NAME):$(BUILD_TAG)$(DOCKER_PLATFORM_TAG_SUFFIX)\n\ndocker_tag_default:\n\t# Tag the $(BUILD_TAG) image we built with the given $(DOCKER_TAG) tag\n\t$(DOCKER_CMD) tag strimzi/$(PROJECT_NAME):$(BUILD_TAG)$(DOCKER_PLATFORM_TAG_SUFFIX) $(DOCKER_REGISTRY)/$(DOCKER_ORG)/$(PROJECT_NAME):$(DOCKER_TAG)$(DOCKER_PLATFORM_TAG_SUFFIX)\n\ndocker_push_default: docker_tag\n\t# Push the $(DOCKER_TAG)-tagged image to the registry\n\t$(DOCKER_CMD) push $(DOCKER_REGISTRY)/$(DOCKER_ORG)/$(PROJECT_NAME):$(DOCKER_TAG)$(DOCKER_PLATFORM_TAG_SUFFIX)\n\n.PHONY: docker_save_default\ndocker_save_default:\n\t# Saves the container as TGZ file\n\ttest -d $(ARCHIVE_DIR) || mkdir -p  $(ARCHIVE_DIR)\n\tdocker save strimzi/$(PROJECT_NAME):$(BUILD_TAG)$(DOCKER_PLATFORM_TAG_SUFFIX) | gzip > $(ARCHIVE_DIR)/$(PROJECT_NAME)-$(BUILD_TAG)$(DOCKER_PLATFORM_TAG_SUFFIX).tar.gz\n\n.PHONY: docker_load_default\ndocker_load_default:\n\t# Loads the container as TGZ file\n\tdocker load < $(ARCHIVE_DIR)/$(PROJECT_NAME)-$(BUILD_TAG)$(DOCKER_PLATFORM_TAG_SUFFIX).tar.gz\n\n.PHONY: docker_delete_archive_default\ndocker_delete_archive_default:\n\t# Deletes the archive\n\trm $(ARCHIVE_DIR)/$(PROJECT_NAME)-$(BUILD_TAG)$(DOCKER_PLATFORM_TAG_SUFFIX).tar.gz\n\n.PHONY: docker_amend_manifest_default\ndocker_amend_manifest_default:\n\t# Create / Amend the manifest\n\tdocker manifest create $(DOCKER_REGISTRY)/$(DOCKER_ORG)/$(PROJECT_NAME):$(DOCKER_TAG) --amend $(DOCKER_REGISTRY)/$(DOCKER_ORG)/$(PROJECT_NAME):$(DOCKER_TAG)$(DOCKER_PLATFORM_TAG_SUFFIX)\n\n.PHONY: docker_push_manifest_default\ndocker_push_manifest_default:\n\t# Push the manifest to the registry\n\tdocker manifest push $(DOCKER_REGISTRY)/$(DOCKER_ORG)/$(PROJECT_NAME):$(DOCKER_TAG)\n\n.PHONY: docker_sign_manifest_default\ndocker_sign_manifest_default:\n\t# Signs the manifest and its images\n\t@echo $$COSIGN_PRIVATE_KEY | base64 -d > cosign.key\n\tMANIFEST_DIGEST=$(shell docker buildx imagetools inspect $(DOCKER_REGISTRY)/$(DOCKER_ORG)/$(PROJECT_NAME):$(DOCKER_TAG) --format '{{ json . }}' | jq -r .manifest.digest); \\\n\tcosign sign --recursive --tlog-upload=false -a author=StrimziCI -a BuildID=$(BUILD_ID) -a Commit=$(BUILD_COMMIT) --key cosign.key $(DOCKER_REGISTRY)/$(DOCKER_ORG)/$(PROJECT_NAME)@$$MANIFEST_DIGEST\n\t@rm cosign.key\n\n.PHONY: docker_delete_manifest_default\ndocker_delete_manifest_default:\n\t# Delete the manifest to the registry, ignore the error if manifest doesn't exist\n\tdocker manifest rm $(DOCKER_REGISTRY)/$(DOCKER_ORG)/$(PROJECT_NAME):$(DOCKER_TAG) || true\n\n.PHONY: docker_sbom_default\ndocker_sbom_default:\n\t# Saves the SBOM of the image\n\ttest -d $(SBOM_DIR) || mkdir -p $(SBOM_DIR)\n\t# Generate the text format\n\tMANIFEST_DIGEST=$(shell docker buildx imagetools inspect $(DOCKER_REGISTRY)/$(DOCKER_ORG)/$(PROJECT_NAME):$(DOCKER_TAG)$(DOCKER_PLATFORM_TAG_SUFFIX) --format '{{ json . }}' | jq -r .manifest.digest); \\\n\tsyft packages $(DOCKER_REGISTRY)/$(DOCKER_ORG)/$(PROJECT_NAME)@$$MANIFEST_DIGEST --output syft-table --file $(SBOM_DIR)/$(DOCKER_REGISTRY)/$(DOCKER_ORG)/$(PROJECT_NAME)/$(DOCKER_TAG)/$$MANIFEST_DIGEST.txt\n\t# Generate the SPDX JSON format for machine processing\n\tMANIFEST_DIGEST=$(shell docker buildx imagetools inspect $(DOCKER_REGISTRY)/$(DOCKER_ORG)/$(PROJECT_NAME):$(DOCKER_TAG)$(DOCKER_PLATFORM_TAG_SUFFIX) --format '{{ json . }}' | jq -r .manifest.digest); \\\n\tsyft packages $(DOCKER_REGISTRY)/$(DOCKER_ORG)/$(PROJECT_NAME)@$$MANIFEST_DIGEST --output spdx-json --file $(SBOM_DIR)/$(DOCKER_REGISTRY)/$(DOCKER_ORG)/$(PROJECT_NAME)/$(DOCKER_TAG)/$$MANIFEST_DIGEST.json\n\t# Sign the TXT and SPDX-JSON SBOM\n\t@echo $$COSIGN_PRIVATE_KEY | base64 -d > cosign.key\n\tMANIFEST_DIGEST=$(shell docker buildx imagetools inspect $(DOCKER_REGISTRY)/$(DOCKER_ORG)/$(PROJECT_NAME):$(DOCKER_TAG)$(DOCKER_PLATFORM_TAG_SUFFIX) --format '{{ json . }}' | jq -r .manifest.digest); \\\n\tcosign sign-blob --tlog-upload=false --key cosign.key --bundle $(SBOM_DIR)/$(DOCKER_REGISTRY)/$(DOCKER_ORG)/$(PROJECT_NAME)/$(DOCKER_TAG)/$$MANIFEST_DIGEST.txt.bundle $(SBOM_DIR)/$(DOCKER_REGISTRY)/$(DOCKER_ORG)/$(PROJECT_NAME)/$(DOCKER_TAG)/$$MANIFEST_DIGEST.txt\n\tMANIFEST_DIGEST=$(shell docker buildx imagetools inspect $(DOCKER_REGISTRY)/$(DOCKER_ORG)/$(PROJECT_NAME):$(DOCKER_TAG)$(DOCKER_PLATFORM_TAG_SUFFIX) --format '{{ json . }}' | jq -r .manifest.digest); \\\n\tcosign sign-blob --tlog-upload=false --key cosign.key --bundle $(SBOM_DIR)/$(DOCKER_REGISTRY)/$(DOCKER_ORG)/$(PROJECT_NAME)/$(DOCKER_TAG)/$$MANIFEST_DIGEST.json.bundle $(SBOM_DIR)/$(DOCKER_REGISTRY)/$(DOCKER_ORG)/$(PROJECT_NAME)/$(DOCKER_TAG)/$$MANIFEST_DIGEST.json\n\t@rm cosign.key\n\n.PHONY: docker_push_sbom_default\ndocker_push_sbom_default:\n\t# Push the SBOMto the container registry and sign it\n\t@echo $$COSIGN_PRIVATE_KEY | base64 -d > cosign.key\n\tMANIFEST_DIGEST=$(shell docker buildx imagetools inspect $(DOCKER_REGISTRY)/$(DOCKER_ORG)/$(PROJECT_NAME):$(DOCKER_TAG)$(DOCKER_PLATFORM_TAG_SUFFIX) --format '{{ json . }}' | jq -r .manifest.digest); \\\n\tcosign attach sbom --sbom $(SBOM_DIR)/$(DOCKER_REGISTRY)/$(DOCKER_ORG)/$(PROJECT_NAME)/$(DOCKER_TAG)/$$MANIFEST_DIGEST.json $(DOCKER_REGISTRY)/$(DOCKER_ORG)/$(PROJECT_NAME):$(DOCKER_TAG)$(DOCKER_PLATFORM_TAG_SUFFIX)\n\tMANIFEST_DIGEST=$(shell docker buildx imagetools inspect $(DOCKER_REGISTRY)/$(DOCKER_ORG)/$(PROJECT_NAME):$(DOCKER_TAG)$(DOCKER_PLATFORM_TAG_SUFFIX) --format '{{ json . }}' | jq -r .manifest.digest); \\\n\tcosign sign --tlog-upload=false -a author=StrimziCI -a BuildID=$(BUILD_ID) -a Commit=$(BUILD_COMMIT) --key cosign.key --attachment sbom $(DOCKER_REGISTRY)/$(DOCKER_ORG)/$(PROJECT_NAME)@$$MANIFEST_DIGEST\n\t@rm cosign.key\n\ndocker_%: docker_%_default\n\t@  true"
        },
        {
          "name": "Makefile.maven",
          "type": "blob",
          "size": 0.5478515625,
          "content": "# Makefile.maven contains the shared tasks for building Java applications. This file is\n# included into the Makefile files which contain some Java sources which should be build\n# (E.g. cluster-operator etc.).\n\njava_build:\n\techo \"Building JAR file ...\"\n\tmvn $(MVN_ARGS) verify\n\njava_install_root:\n\techo \"Installing root pom ...\"\n\tmvn $(MVN_ARGS) install -f ../pom.xml -N\n\njava_install: java_install_root\n\techo \"Installing JAR files ...\"\n\tmvn $(MVN_ARGS) install\n\njava_clean:\n\techo \"Cleaning Maven build ...\"\n\tmvn clean\n\nspotbugs:\n\tmvn $(MVN_ARGS) spotbugs:check\n"
        },
        {
          "name": "Makefile.os",
          "type": "blob",
          "size": 0.265625,
          "content": "FIND = find\nSED = sed\nGREP = grep\nCP = cp\nUNIQ = uniq\nSORT = sort\nSHA1SUM = sha1sum\nXARGS = xargs\n\nUNAME_S := $(shell uname -s)\nifeq ($(UNAME_S),Darwin)\n\tFIND = gfind\n\tSED = gsed\n\tGREP = ggrep\n\tCP = gcp\n\tUNIQ = guniq\n\tSORT = gsort\n\tSHA1SUM = gsha1sum\n\tXARGS = gxargs\nendif"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 5.7158203125,
          "content": "[![Strimzi](./documentation/logo/strimzi.png)](https://strimzi.io/)\n\n# Run Apache Kafka on Kubernetes and OpenShift\n\n[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/strimzi/strimzi-kafka-operator/badge)](https://scorecard.dev/viewer/?uri=github.com/strimzi/strimzi-kafka-operator)\n[![Build Status](https://dev.azure.com/cncf/strimzi/_apis/build/status/build?branchName=main)](https://dev.azure.com/cncf/strimzi/_build/latest?definitionId=16&branchName=main)\n[![GitHub release](https://img.shields.io/github/release/strimzi/strimzi-kafka-operator.svg)](https://github.com/strimzi/strimzi-kafka-operator/releases/latest)\n[![License](https://img.shields.io/badge/license-Apache--2.0-blue.svg)](http://www.apache.org/licenses/LICENSE-2.0)\n[![Twitter Follow](https://img.shields.io/twitter/follow/strimziio?style=social)](https://twitter.com/strimziio)\n[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/strimzi-kafka-operator)](https://artifacthub.io/packages/search?repo=strimzi-kafka-operator)\n\nStrimzi provides a way to run an [Apache Kafka®][kafka] cluster on \n[Kubernetes][k8s] or [OpenShift][os] in various deployment configurations.\nSee our [website][strimzi] for more details about the project.\n\n## Quick Starts\n\nTo get up and running quickly, check our [Quick Start for Minikube, OKD (OpenShift Origin) and Kubernetes Kind](https://strimzi.io/quickstarts/). \n\n## Documentation\n\nDocumentation for the current _main_ branch as well as all releases can be found on our [website][strimzi].\n\n## Roadmap\n\nThe roadmap of the Strimzi Operator project is maintained as [GitHub Project](https://github.com/orgs/strimzi/projects/4).\n\n## Getting help\n\nIf you encounter any issues while using Strimzi, you can get help using:\n\n- [#strimzi channel on CNCF Slack](https://slack.cncf.io/)\n- [Strimzi Users mailing list](https://lists.cncf.io/g/cncf-strimzi-users/topics)\n- [GitHub Discussions](https://github.com/strimzi/strimzi-kafka-operator/discussions)\n\n## Strimzi Community Meetings\n\nYou can join our regular community meetings:\n* Thursday 8:00 AM UTC (every 4 weeks starting from 4th June 2020) - [convert to your timezone](https://www.thetimezoneconverter.com/?t=8%3A00&tz=UTC)\n* Thursday 4:00 PM UTC (every 4 weeks starting from 18th June 2020) - [convert to your timezone](https://www.thetimezoneconverter.com/?t=16%3A00&tz=UTC)\n\nResources:\n* [Meeting minutes, agenda and Zoom link](https://docs.google.com/document/d/1V1lMeMwn6d2x1LKxyydhjo2c_IFANveelLD880A6bYc/edit#heading=h.vgkvn1hr5uor)\n* [Recordings](https://youtube.com/playlist?list=PLpI4X8PMthYfONZopcRd4X_stq1C14Rtn)\n* [Calendar](https://calendar.google.com/calendar/embed?src=c_m9pusj5ce1b4hr8c92hsq50i00%40group.calendar.google.com) ([Subscribe to the calendar](https://calendar.google.com/calendar/u/0?cid=Y19tOXB1c2o1Y2UxYjRocjhjOTJoc3E1MGkwMEBncm91cC5jYWxlbmRhci5nb29nbGUuY29t))\n\n## Contributing\n\nYou can contribute by:\n- Raising any issues you find using Strimzi\n- Fixing issues by opening Pull Requests\n- Improving documentation\n- Talking about Strimzi\n\nAll bugs, tasks or enhancements are tracked as [GitHub issues](https://github.com/strimzi/strimzi-kafka-operator/issues). Issues which \nmight be a good start for new contributors are marked with [\"good-start\"](https://github.com/strimzi/strimzi-kafka-operator/labels/good-start)\nlabel.\n\nThe [Dev guide](https://github.com/strimzi/strimzi-kafka-operator/blob/main/development-docs/DEV_GUIDE.md) describes how to build Strimzi.\nBefore submitting a patch, please make sure to understand, how to test your changes before opening a PR [Test guide](https://github.com/strimzi/strimzi-kafka-operator/blob/main/development-docs/TESTING.md).\n\nThe [Documentation Contributor Guide](https://strimzi.io/contributing/guide/) describes how to contribute to Strimzi documentation.\n\nIf you want to get in touch with us first before contributing, you can use:\n\n- [#strimzi channel on CNCF Slack](https://slack.cncf.io/)\n- [Strimzi Dev mailing list](https://lists.cncf.io/g/cncf-strimzi-dev/topics)\n\n## License\nStrimzi is licensed under the [Apache License](./LICENSE), Version 2.0\n\n## Container signatures\n\nFrom the 0.38.0 release, Strimzi containers are signed using the [`cosign` tool](https://github.com/sigstore/cosign).\nStrimzi currently does not use the keyless signing and the transparency log.\nTo verify the container, you can copy the following public key into a file:\n\n```\n-----BEGIN PUBLIC KEY-----\nMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAET3OleLR7h0JqatY2KkECXhA9ZAkC\nTRnbE23Wb5AzJPnpevvQ1QUEQQ5h/I4GobB7/jkGfqYkt6Ct5WOU2cc6HQ==\n-----END PUBLIC KEY-----\n```\n\nAnd use it to verify the signature:\n\n```\ncosign verify --key strimzi.pub quay.io/strimzi/operator:latest --insecure-ignore-tlog=true\n```\n\n## Software Bill of Materials (SBOM)\n\nFrom the 0.38.0 release, Strimzi publishes the software bill of materials (SBOM) of our containers.\nThe SBOMs are published as an archive with `SPDX-JSON` and `Syft-Table` formats signed using cosign.\nFor releases, they are also pushed into the container registry.\nTo verify the SBOM signatures, please use the Strimzi public key:\n\n```\n-----BEGIN PUBLIC KEY-----\nMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAET3OleLR7h0JqatY2KkECXhA9ZAkC\nTRnbE23Wb5AzJPnpevvQ1QUEQQ5h/I4GobB7/jkGfqYkt6Ct5WOU2cc6HQ==\n-----END PUBLIC KEY-----\n```\n\nYou can use it to verify the signature of the SBOM files with the following command:\n\n```\ncosign verify-blob --key cosign.pub --bundle <SBOM-file>.bundle --insecure-ignore-tlog=true <SBOM-file>\n```\n\n---\n\nStrimzi is a <a href=\"http://cncf.io\">Cloud Native Computing Foundation</a> incubating project.\n\n![CNCF ><](./documentation/logo/cncf-color.png)\n\n[strimzi]: https://strimzi.io \"Strimzi\"\n[kafka]: https://kafka.apache.org \"Apache Kafka\"\n[k8s]: https://kubernetes.io/ \"Kubernetes\"\n[os]: https://www.openshift.com/ \"OpenShift\"\n"
        },
        {
          "name": "api",
          "type": "tree",
          "content": null
        },
        {
          "name": "bridge.version",
          "type": "blob",
          "size": 0.005859375,
          "content": "0.31.1"
        },
        {
          "name": "certificate-manager",
          "type": "tree",
          "content": null
        },
        {
          "name": "cluster-operator",
          "type": "tree",
          "content": null
        },
        {
          "name": "config-model-generator",
          "type": "tree",
          "content": null
        },
        {
          "name": "config-model",
          "type": "tree",
          "content": null
        },
        {
          "name": "crd-annotations",
          "type": "tree",
          "content": null
        },
        {
          "name": "crd-generator",
          "type": "tree",
          "content": null
        },
        {
          "name": "development-docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "dist.xml",
          "type": "blob",
          "size": 1.0234375,
          "content": "<assembly\n        xmlns=\"http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.2\"\n        xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n        xsi:schemaLocation=\"http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.2\n      http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.2\">\n    <id>dist</id>\n    <formats>\n        <format>zip</format>\n    </formats>\n    <includeBaseDirectory>false</includeBaseDirectory>\n    <fileSets>\n        <fileSet>\n            <filtered>true</filtered>\n            <outputDirectory>bin</outputDirectory>\n            <directory>scripts</directory>\n        </fileSet>\n    </fileSets>\n    <dependencySets>\n        <dependencySet>\n            <outputDirectory>lib</outputDirectory>\n            <unpack>false</unpack>\n            <scope>runtime</scope>\n            <outputFileNameMapping>${artifact.groupId}.${artifact.artifactId}-${artifact.version}${dashClassifier?}.${artifact.extension}</outputFileNameMapping>\n        </dependencySet>\n    </dependencySets>\n</assembly>"
        },
        {
          "name": "docker-images",
          "type": "tree",
          "content": null
        },
        {
          "name": "documentation",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "helm-charts",
          "type": "tree",
          "content": null
        },
        {
          "name": "install",
          "type": "tree",
          "content": null
        },
        {
          "name": "kafka-agent",
          "type": "tree",
          "content": null
        },
        {
          "name": "kafka-init",
          "type": "tree",
          "content": null
        },
        {
          "name": "kafka-versions.yaml",
          "type": "blob",
          "size": 13.5283203125,
          "content": "# This file is used to specify the versions of Kafka which will be built\n# and supported by the Cluster Operator. It affects both compile time and runtime:\n#   * The docker images built (see docker-images/build.sh)\n#   * The KAFKA_IMAGE_MAP configuring the CO in the helm-charts (see helm-charts/kafka-version-tpl.sh)\n#   * The io.strimzi.operator.cluster.model.KafkaVersion's loaded at runtime\n#   * Documentation snippets generated by `make docu_versions`\n# The idea is that this is the single place you need to update when changing the supported Kafka versions\n\n# Format of this file:\n#   <version> is the kafka version number\n#   <default> when `true` this is the version to be used by the CO by default when a `Kafka` resource lacks an explicit version. Only one Kafka version can be marked as default.\n#   <protocol> is the default `inter.broker.protocol.version` used by this Kafka version\n#   <format> is the default `log.message.format.version` used by this Kafka version\n#   <url> is the remote (using prefix 'http://' or 'https://') or local (using prefix 'file://') address of the Kafka binary tar archive for this version of Kafka. When using a local file path the absolute path to the binary archive should be used. It is assumed in both cases that the name of the file forms the last section of the path.\n#   <checksum> is the SHA512 checksum of the Kafka binary which is specified in the 'url' field.\n#   <zookeeper> is the version of zookeeper required by this version of Kafka.\n#   <third-party-libs> is the version string for the third party libraries\n#   <unsupported-features> is a list of Strimzi features that are not supported by this Kafka version\n#   <supported> when `true` this version is currently supported by the operator. Unsupported versions are kept for historical reasons.\n\n- version: 2.1.0\n  format: 2.1\n  protocol: 2.1\n  zookeeper: 3.4.13\n  supported: false\n  default: false\n- version: 2.1.1\n  format: 2.1\n  protocol: 2.1\n  zookeeper: 3.4.13\n  supported: false\n  default: false\n- version: 2.2.0\n  format: 2.2\n  protocol: 2.2\n  zookeeper: 3.4.13\n  supported: false\n  default: false\n- version: 2.2.1\n  format: 2.2\n  protocol: 2.2\n  zookeeper: 3.4.13\n  supported: false\n  default: false\n- version: 2.3.0\n  format: 2.3\n  protocol: 2.3\n  zookeeper: 3.4.14\n  supported: false\n  default: false\n- version: 2.3.1\n  format: 2.3\n  protocol: 2.3\n  zookeeper: 3.4.14\n  supported: false\n  default: false\n- version: 2.4.0\n  format: 2.4\n  protocol: 2.4\n  zookeeper: 3.5.6\n  supported: false\n  default: false\n- version: 2.4.1\n  format: 2.4\n  protocol: 2.4\n  zookeeper: 3.5.7\n  supported: false\n  default: false\n- version: 2.5.0\n  format: 2.5\n  protocol: 2.5\n  url: https://archive.apache.org/dist/kafka/2.5.0/kafka_2.12-2.5.0.tgz\n  checksum: 447A7057BCD9FACA98B6F4807BD6019EF73EEE90EFDC1E7B10005F669E2537A8A190CB8B9C9F4C20DB1D95B13D0F0487E9CC560D0759532058439CE7F722C7CD\n  zookeeper: 3.5.7\n  third-party-libs: 2.5.x\n  supported: false\n  default: false\n- version: 2.5.1\n  format: 2.5\n  protocol: 2.5\n  url: https://archive.apache.org/dist/kafka/2.5.1/kafka_2.12-2.5.1.tgz\n  checksum: 91F96F28C016BDAA3FE025F87ACE188417A1E594C8E32B7D23A104AA390BC25F5DB5897E23CCCF00EA7EDE3AC20B3028C10363EBE99DCBD7DB2CF6237EE7553A\n  zookeeper: 3.5.8\n  third-party-libs: 2.5.x\n  supported: false\n  default: false\n- version: 2.6.0\n  format: 2.6\n  protocol: 2.6\n  url: https://archive.apache.org/dist/kafka/2.6.0/kafka_2.12-2.6.0.tgz\n  checksum: 022AB51605DFFB8A0E4522DF297F02F4C5E488696520BB38DA8E8E70457C0B2696A47D7AD39A86389B747981215B385B2659AC25B3D43A6093AF13239723560D\n  zookeeper: 3.5.8\n  third-party-libs: 2.6.x\n  supported: false\n  default: false\n- version: 2.6.1\n  format: 2.6\n  protocol: 2.6\n  url: https://archive.apache.org/dist/kafka/2.6.1/kafka_2.12-2.6.1.tgz\n  checksum: 105BF29E4BED9F1B7A7A3CAADF016DF8AA774F6F509E3606529F8231EA4CAB89C38236C58BE9C2E9BD3C52C2917892EA5D3A5EC0BD94BD8A5F7257522A5AF4DB\n  zookeeper: 3.5.8\n  third-party-libs: 2.6.x\n  supported: false\n  default: false\n- version: 2.6.2\n  format: 2.6\n  protocol: 2.6\n  url: https://archive.apache.org/dist/kafka/2.6.2/kafka_2.12-2.6.2.tgz\n  checksum: 70F992DFAB02D1E727E352124D53F89B096868E738DFC50563890EA394ADFE056B132BDC8BAD70BDD6CE48B0C7561CDB33CC50D56586F09BAD96FF699A054F85\n  zookeeper: 3.5.9\n  third-party-libs: 2.6.x\n  supported: false\n  default: false\n- version: 2.7.0\n  format: 2.7\n  protocol: 2.7\n  url: https://archive.apache.org/dist/kafka/2.7.0/kafka_2.13-2.7.0.tgz\n  checksum: F3DD1FD88766D9150D3D395B285BFA75F5B89A835822381490C8428E6E568889054DDB5FADA1EB63613A6441989151BC7C7D6CDE16A871C6674B909C4EDD4E28\n  zookeeper: 3.5.8\n  third-party-libs: 2.7.x\n  supported: false\n  default: false\n- version: 2.7.1\n  format: 2.7\n  protocol: 2.7\n  url: https://archive.apache.org/dist/kafka/2.7.1/kafka_2.13-2.7.1.tgz\n  checksum: A1FC222284E3E1B538AB7FBC9205C735A2E8B31D84EE9F8D5CCC84F6FD48B885591899EEA538C909A26676C9C1F44520CC56E6748C4632E23B8A5AF0B788B48A\n  zookeeper: 3.5.9\n  third-party-libs: 2.7.x\n  supported: false\n  default: false\n- version: 2.8.0\n  format: 2.8\n  protocol: 2.8\n  url: https://archive.apache.org/dist/kafka/2.8.0/kafka_2.13-2.8.0.tgz\n  checksum: 3C49DCA1147A0A249DD88E089F40AF31A67B8207ED2D9E2294FA9A6D41F5ED0B006943CD60D8E30D7E69D760D398F299CAFCD68B6ED7BEDF9F93D1B7A9E8C487\n  zookeeper: 3.5.9\n  third-party-libs: 2.8.x\n  supported: false\n  default: false\n- version: 2.8.1\n  format: 2.8\n  protocol: 2.8\n  url: https://archive.apache.org/dist/kafka/2.8.1/kafka_2.13-2.8.1.tgz\n  checksum: 91FCD1061247AD0DDB63FA2B5C0251EE0E58E60CC9E1A3EBE2E84E9A31872448A36622DD15868DE2C6D3F7E26020A8C61477BC764E2FB6776A25E4344EB8892D\n  zookeeper: 3.5.9\n  third-party-libs: 2.8.x\n  supported: false\n  default: false\n- version: 3.0.0\n  format: 3.0\n  protocol: 3.0\n  url: https://archive.apache.org/dist/kafka/3.0.0/kafka_2.13-3.0.0.tgz\n  checksum: 86CDEB04AF123399858D03431E9777948C1C40EC0D843966CF9BD90B8235B47EBBB5CB96D1F0660710B9286DA86BBB5EE65E21E757606F5A1E67F970AE5CF57C\n  zookeeper: 3.6.3\n  third-party-libs: 3.0.x\n  supported: false\n  default: false\n- version: 3.0.1\n  format: 3.0\n  protocol: 3.0\n  url: https://archive.apache.org/dist/kafka/3.0.1/kafka_2.13-3.0.1.tgz\n  checksum: D949FA4BE7B601A9B482AE1C7861135A5DA007362C4C1C9C218BDCA94C45E918527E56738361AEDC6B6DFB7ABF02B1AA8110C7BC622CC2379B8A2EE557E5756F\n  zookeeper: 3.6.3\n  third-party-libs: 3.0.x\n  supported: false\n  default: false\n- version: 3.1.0\n  format: 3.1\n  protocol: 3.1\n  url: https://archive.apache.org/dist/kafka/3.1.0/kafka_2.13-3.1.0.tgz\n  checksum: 5954C1CF38187134A6E0A21520CBEF5CD5320A3E9290E630C3895990E892219917D911FABBC64DA5DB17BCAA940B8277C23344B50F2FF4256EACA78116E9FDC9\n  zookeeper: 3.6.3\n  third-party-libs: 3.1.x\n  supported: false\n  default: false\n- version: 3.1.1\n  format: 3.1\n  protocol: 3.1\n  url: https://archive.apache.org/dist/kafka/3.1.1/kafka_2.13-3.1.1.tgz\n  checksum: 5EC72EE76AD14997763F2654ECEF0390FD9628413C287619B734F44193252950D412DEBA684AAE5147AC844A88D9EF10EEFC0FFEB14435F2E00347EF946AA5D6\n  zookeeper: 3.6.3\n  third-party-libs: 3.1.x\n  supported: false\n  default: false\n- version: 3.1.2\n  format: 3.1\n  protocol: 3.1\n  url: https://archive.apache.org/dist/kafka/3.1.2/kafka_2.13-3.1.2.tgz\n  checksum: EC5955BD9BE0FFE15ADF84EF428F48D341B5393A1E4CBB9D7F80EC4062FF57A28A38D575E19BC0B40AF4143164BB5126721844F42DCE8E70516FC30348C57F95\n  zookeeper: 3.6.3\n  third-party-libs: 3.1.x\n  supported: false\n  default: false\n- version: 3.2.0\n  format: 3.2\n  protocol: 3.2\n  url: https://archive.apache.org/dist/kafka/3.2.0/kafka_2.13-3.2.0.tgz\n  checksum: 736A129823B058DC10788D0893BDE47B6F39B9E4972F9EAC2D5C9E85E51E477344C6F1E1EBD126CE34D5FD430EB07E55FDD60D60CB541F1D48655C0EBC0A4778\n  zookeeper: 3.6.3\n  third-party-libs: 3.2.x\n  supported: false\n  default: false\n- version: 3.2.1\n  format: 3.2\n  protocol: 3.2\n  url: https://archive.apache.org/dist/kafka/3.2.1/kafka_2.13-3.2.1.tgz\n  checksum: 9B7EE73C9C088E2B1D15685CD1330546054BCF1F025F4825FADCCD5076763230229480D87900CA4A8317CD01A36BEC1082FCADFAB7D220A415787E1BA2E3C9CF\n  zookeeper: 3.6.3\n  third-party-libs: 3.2.x\n  supported: false\n  default: false\n- version: 3.2.3\n  format: 3.2\n  protocol: 3.2\n  url: https://archive.apache.org/dist/kafka/3.2.3/kafka_2.13-3.2.3.tgz\n  checksum: 4A57D69F8D3B5158DDCA9C64AC366C2975CA55F4C2EF02CD3B122E127016AD1A5AA1DE92E7E2F392FDC3B57AABE75D4631373D77A3A5958C28D911F4034A136F\n  zookeeper: 3.6.3\n  third-party-libs: 3.2.3 # Kafka 3.2.3 uses a separate 3rd party libs directory because it uses Jackson 2.13 rather than 2.12 used by previous Kafka 3.2.x versions\n  supported: false\n  default: false\n- version: 3.3.1\n  format: 3.3\n  protocol: 3.3\n  url: https://archive.apache.org/dist/kafka/3.3.1/kafka_2.13-3.3.1.tgz\n  checksum: D14D9CC97D1702649B33378F38060C4A6220850A3D7182D1AF20E905CB98728E51F2AEEC63121F5773A389D6B66891B7508E5D23584DD1A4E424825E3D54E3E0\n  zookeeper: 3.6.3\n  third-party-libs: 3.3.x\n  supported: false\n  default: false\n- version: 3.3.2\n  format: 3.3\n  protocol: 3.3\n  url: https://archive.apache.org/dist/kafka/3.3.2/kafka_2.13-3.3.2.tgz\n  checksum: F56657105A67F6195C1D4795B5FB4A00FC5E2F5CCE061D7F7A504063778187B325C6FBE51D7C59F57CD7EF323A37D4C2C780C27A5609A2008852CBFA944287B3\n  zookeeper: 3.6.3\n  third-party-libs: 3.3.x\n  supported: false\n  default: false\n- version: 3.4.0\n  format: 3.4\n  protocol: 3.4\n  url: https://archive.apache.org/dist/kafka/3.4.0/kafka_2.13-3.4.0.tgz\n  checksum: 2C405149C065627CE2125088DFCCE0A4DC23AEBAA72C1157736D5829CB5CBEF273C0915EC55D2D8BA38E5E0524F0720F43E07D7D677439CD2AC7BEA618CAA65B\n  zookeeper: 3.6.3\n  third-party-libs: 3.4.x\n  supported: false\n  default: false\n- version: 3.4.1\n  format: 3.4\n  protocol: 3.4\n  url: https://archive.apache.org/dist/kafka/3.4.1/kafka_2.13-3.4.1.tgz\n  checksum: 875308E9B0A3597EA4A1088788F4040F257C3B825730572B038EDE0FEE3BC5336559F7EF0AB4D78B9512AC71385F84698180A2026CA81F1221EF65811BED6BCE\n  zookeeper: 3.6.4\n  third-party-libs: 3.4.x\n  supported: false\n  default: false\n- version: 3.5.0\n  format: 3.5\n  protocol: 3.5\n  metadata: 3.5\n  url: https://archive.apache.org/dist/kafka/3.5.0/kafka_2.13-3.5.0.tgz\n  checksum: 7B79BD0844DB683C06C3491955BB183D48A47FA4639D2E241B9F4FF4060C4B70814DAC7D96BEA87DFFCA0C8AE038278C4FABF68D4EA1194228D67D9C3B1D247C\n  zookeeper: 3.6.4\n  third-party-libs: 3.5.x\n  supported: false\n  default: false\n- version: 3.5.1\n  format: 3.5\n  protocol: 3.5\n  metadata: 3.5\n  url: https://archive.apache.org/dist/kafka/3.5.1/kafka_2.13-3.5.1.tgz\n  checksum: B6CEB010A5FE1791843CBC53D34D35993E97E03F9518344B4B5BDF7146D0A4E866CD2D4760CAB319D8B3323A5BF53037A78FED88C9384381AEA2CD0366877763\n  zookeeper: 3.6.4\n  third-party-libs: 3.5.x\n  supported: false\n  default: false\n- version: 3.5.2\n  format: 3.5\n  protocol: 3.5\n  metadata: 3.5\n  url: https://archive.apache.org/dist/kafka/3.5.2/kafka_2.13-3.5.2.tgz\n  checksum: 229CCC5E3E6B3B9845F59F6E829D70711C5A5A2293F32B6BCABC37350666F874BC7D8F08130F712A1B32915205C10F2847F04908C20D5F7FDB4B62D058C9DEFE\n  zookeeper: 3.6.4\n  third-party-libs: 3.5.x\n  supported: false\n  default: false\n- version: 3.6.0\n  format: 3.6\n  protocol: 3.6\n  metadata: 3.6\n  url: https://archive.apache.org/dist/kafka/3.6.0/kafka_2.13-3.6.0.tgz\n  checksum: 98D20F475BCCC11EB3CF05362112C788EEA7BFC88ABDDBA66CFCFB48880D3BB97918A90D44EB7C1720527BEBCA93DD231002B5159876F6EE8B7FCD91CC1B0644\n  zookeeper: 3.8.2\n  third-party-libs: 3.6.x\n  supported: false\n  default: false\n- version: 3.6.1\n  format: 3.6\n  protocol: 3.6\n  metadata: 3.6\n  url: https://archive.apache.org/dist/kafka/3.6.1/kafka_2.13-3.6.1.tgz\n  checksum: 1F063CD67463DD3BB5A5E06E7A1C2278DB84BFC836A634FAC7C9A005DE66A42AC00B32F5E9BBDD22086605F73659EFD4CE5BD1185196B02A743BE0898DAAC55D\n  zookeeper: 3.8.3\n  third-party-libs: 3.6.x\n  supported: false\n  default: false\n- version: 3.6.2\n  format: 3.6\n  protocol: 3.6\n  metadata: 3.6\n  url: https://archive.apache.org/dist/kafka/3.6.2/kafka_2.13-3.6.2.tgz\n  checksum: E5D5935DF6E687898E71E583E8EA376275C6FBAC2E7872E78F7C55AB2528485582362E3778678600C5368384437C1DA6B3D612A748917F4B294C06EA160173EE\n  zookeeper: 3.8.4\n  third-party-libs: 3.6.x\n  supported: false\n  default: false\n- version: 3.7.0\n  format: 3.7\n  protocol: 3.7\n  metadata: 3.7\n  url: https://archive.apache.org/dist/kafka/3.7.0/kafka_2.13-3.7.0.tgz\n  checksum: B8679283A2D8DAB86E7C636B2C688FE9D9E64AC437241F65EF7A1733F4D26A2BD415EEFA04F09F1911373BCD2A5DBC3838C76347F68656425C09202CD290CE91\n  zookeeper: 3.8.3\n  third-party-libs: 3.7.0\n  supported: false\n  default: false\n- version: 3.7.1\n  format: 3.7\n  protocol: 3.7\n  metadata: 3.7\n  url: https://archive.apache.org/dist/kafka/3.7.1/kafka_2.13-3.7.1.tgz\n  checksum: 78E985235D245BA9E2951A82E723A62B8ABA8B74A2C8376F7271906AF715A36DE9142C446096F13FD4BFF3A4C10F1D080EB924E91E2256EC2DB779906FD6737D\n  zookeeper: 3.8.4\n  third-party-libs: 3.7.1\n  supported: false\n  default: false\n- version: 3.8.0\n  format: 3.8\n  protocol: 3.8\n  metadata: 3.8\n  url: https://archive.apache.org/dist/kafka/3.8.0/kafka_2.13-3.8.0.tgz\n  checksum: 0A33B7BE7B6FA53249BA80F9D02CDA71ED81927C160AA6EE9BE1E3D3C1C4B50466FFC905293143FD88CEAC7F5E7D8F5BEC28EF972ADDD3C459CC8B1291E738AA\n  zookeeper: 3.8.4\n  third-party-libs: 3.8.x\n  supported: true\n  default: false\n- version: 3.8.1\n  format: 3.8\n  protocol: 3.8\n  metadata: 3.8\n  url: https://archive.apache.org/dist/kafka/3.8.1/kafka_2.13-3.8.1.tgz\n  checksum: B43FADA353B7DCA51C0F90ACF594EC1CE06B2344C046D4059D4DEAB0615E0E3E76E92ECCDBDFA1ADAD1FBDE76C5F25E71ACD0DB013FB4B1778827448B5285EDF\n  zookeeper: 3.8.4\n  third-party-libs: 3.8.x\n  supported: true\n  default: false\n- version: 3.9.0\n  format: 3.9\n  protocol: 3.9\n  metadata: 3.9\n  url: https://archive.apache.org/dist/kafka/3.9.0/kafka_2.13-3.9.0.tgz\n  checksum: 5324C1F44D4C84EA469712C2CC3D2D15545C3716EDBB5353722DF9C661FCC78B031FCF07D1C4F0309C5FDB32686665DFB0CFFE55210CD3A1FE2A370538CB4E6D\n  zookeeper: 3.8.4\n  third-party-libs: 3.9.x\n  supported: true\n  default: true"
        },
        {
          "name": "mockkube",
          "type": "tree",
          "content": null
        },
        {
          "name": "operator-common",
          "type": "tree",
          "content": null
        },
        {
          "name": "packaging",
          "type": "tree",
          "content": null
        },
        {
          "name": "pom.xml",
          "type": "blob",
          "size": 56.8115234375,
          "content": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\" xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">\n    <modelVersion>4.0.0</modelVersion>\n    <groupId>io.strimzi</groupId>\n    <artifactId>strimzi</artifactId>\n    <packaging>pom</packaging>\n    <version>0.46.0-SNAPSHOT</version>\n\n    <licenses>\n        <license>\n            <name>Apache License, Version 2.0</name>\n            <url>https://www.apache.org/licenses/LICENSE-2.0.txt</url>\n        </license>\n    </licenses>\n\n    <name>Strimzi - Apache Kafka on Kubernetes and OpenShift</name>\n    <description>Strimzi uses the Kubernetes operator pattern to provide a way to run an Apache Kafka cluster on\n        Kubernetes or OpenShift in various deployment configurations. </description>\n    <url>https://strimzi.io/</url>\n\n    <scm>\n        <connection>scm:git:git://github.com/strimzi/strimzi-kafka-operator.git</connection>\n        <developerConnection>scm:git:ssh://github.com:strimzi/strimzi-kafka-operator.git</developerConnection>\n        <url>https://github.com/strimzi/strimzi-kafka-operator</url>\n    </scm>\n\n    <issueManagement>\n        <system>GitHub</system>\n        <url>https://github.com/strimzi/strimzi-kafka-operator/issues</url>\n    </issueManagement>\n\n    <developers>\n        <developer>\n            <name>Tom Bentley</name>\n            <email>tbentley@redhat.com</email>\n            <organization>Red Hat</organization>\n            <organizationUrl>https://www.redhat.com</organizationUrl>\n        </developer>\n        <developer>\n            <name>Paolo Patierno</name>\n            <email>ppatierno@live.com</email>\n            <organization>Red Hat</organization>\n            <organizationUrl>https://www.redhat.com</organizationUrl>\n        </developer>\n        <developer>\n            <name>Jakub Scholz</name>\n            <email>github@scholzj.com</email>\n            <organization>Red Hat</organization>\n            <organizationUrl>https://www.redhat.com</organizationUrl>\n        </developer>\n        <developer>\n            <name>Sam Hawker</name>\n            <email>sam.b.hawker@gmail.com</email>\n            <organization>IBM</organization>\n            <organizationUrl>https://www.ibm.com</organizationUrl>\n        </developer>\n        <developer>\n            <name>Jakub Stejskal</name>\n            <email>xstejs24@gmail.com</email>\n            <organization>Red Hat</organization>\n            <organizationUrl>https://www.redhat.com</organizationUrl>\n        </developer>\n        <developer>\n            <name>Stanislav Knot</name>\n            <email>knot@cngroup.dk</email>\n            <organization>CN Group</organization>\n            <organizationUrl>https://www.cngroup.dk/</organizationUrl>\n        </developer>\n        <developer>\n            <name>Paul Mellor</name>\n            <email>pmellor@redhat.com</email>\n            <organization>Red Hat</organization>\n            <organizationUrl>https://www.redhat.com</organizationUrl>\n        </developer>\n        <developer>\n            <name>Lukáš Král</name>\n            <email>l.kral@outlook.com</email>\n            <organization>Red Hat</organization>\n            <organizationUrl>https://www.redhat.com</organizationUrl>\n        </developer>\n        <developer>\n            <name>Maroš Orsák</name>\n            <email>maros.orsak159@gmail.com</email>\n            <organization>Red Hat</organization>\n            <organizationUrl>https://www.redhat.com</organizationUrl>\n        </developer>\n        <developer>\n            <name>Kate Stanley</name>\n            <email>kstanley@redhat.com</email>\n            <organization>Red Hat</organization>\n            <organizationUrl>https://www.redhat.com</organizationUrl>\n        </developer>\n    </developers>\n\n    <properties>\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n        <maven.compiler.release>17</maven.compiler.release>\n\n        <!-- Points to the root directory of the Strimzi project directory and can be used for fixed location to configuration files -->\n        <strimziRootDirectory>${basedir}</strimziRootDirectory>\n\n        <!-- Maven plugin versions -->\n        <maven.compiler.version>3.10.1</maven.compiler.version>\n        <maven.surefire.version>3.1.2</maven.surefire.version>\n        <maven.failsafe.version>3.1.2</maven.failsafe.version>\n        <maven.assembly.version>3.4.2</maven.assembly.version>\n        <maven.shade.version>3.4.1</maven.shade.version>\n        <maven.javadoc.version>3.10.0</maven.javadoc.version>\n        <maven.source.version>3.0.1</maven.source.version>\n        <maven.dependency.version>3.3.0</maven.dependency.version>\n        <maven.gpg.version>1.6</maven.gpg.version>\n        <maven.checkstyle.version>3.5.0</maven.checkstyle.version>\n        <maven.enforcer.version>3.0.0-M2</maven.enforcer.version>\n        <maven.jar.version>3.1.0</maven.jar.version>\n        <sonatype.nexus.staging.version>1.7.0</sonatype.nexus.staging.version>\n        <maven.spotbugs.version>4.7.3.4</maven.spotbugs.version>\n        <maven.jacoco.version>0.8.12</maven.jacoco.version>\n        <maven.exec.version>3.1.0</maven.exec.version>\n        <maven.resources.version>3.1.0</maven.resources.version>\n\n        <!-- Build tools -->\n        <checkstyle.version>10.18.1</checkstyle.version>\n        <spotbugs.version>4.7.3</spotbugs.version>\n        <sundrio.version>0.200.0</sundrio.version>\n        <lombok.version>1.18.32</lombok.version>\n\n        <!-- Runtime dependencies -->\n        <fabric8.kubernetes-client.version>7.0.1</fabric8.kubernetes-client.version>\n        <fabric8.openshift-client.version>7.0.1</fabric8.openshift-client.version>\n        <fabric8.kubernetes-model.version>7.0.1</fabric8.kubernetes-model.version>\n        <fabric8.zjsonpatch.version>0.3.0</fabric8.zjsonpatch.version>\n        <fasterxml.jackson-core.version>2.16.2</fasterxml.jackson-core.version>\n        <fasterxml.jackson-databind.version>2.16.2</fasterxml.jackson-databind.version>\n        <fasterxml.jackson-dataformat.version>2.16.2</fasterxml.jackson-dataformat.version>\n        <fasterxml.jackson-annotations.version>2.16.2</fasterxml.jackson-annotations.version>\n        <fasterxml.jackson-datatype.version>2.16.2</fasterxml.jackson-datatype.version>\n        <fasterxml.jackson-jaxrs.version>2.16.2</fasterxml.jackson-jaxrs.version>\n        <vertx.version>4.5.11</vertx.version>\n        <vertx-junit5.version>4.5.11</vertx-junit5.version>\n        <kafka.version>3.9.0</kafka.version>\n        <yammer-metrics.version>2.2.0</yammer-metrics.version>\n        <snappy.version>1.1.10.5</snappy.version>\n        <slf4j.version>1.7.36</slf4j.version>\n        <log4j.version>2.17.2</log4j.version>\n        <quartz.version>2.3.2</quartz.version>\n        <opentelemetry.version>1.34.1</opentelemetry.version>\n        <opentelemetry-alpha.version>${opentelemetry.version}-alpha</opentelemetry-alpha.version>\n        <jetty.version>9.4.56.v20240826</jetty.version>\n        <javax-servlet.version>3.1.0</javax-servlet.version>\n        <strimzi-oauth.version>0.15.0</strimzi-oauth.version>\n        <netty.version>4.1.115.Final</netty.version>\n        <micrometer.version>1.12.3</micrometer.version>\n        <jayway-jsonpath.version>2.9.0</jayway-jsonpath.version>\n        <registry.version>1.3.2.Final</registry.version>\n        <commons-codec.version>1.13</commons-codec.version>\n\n        <!-- Test only dependencies -->\n        <hamcrest.version>2.2</hamcrest.version>\n        <mockito.version>4.11.0</mockito.version>\n        <junit.platform.version>1.8.2</junit.platform.version>\n        <junit-platform-surefire-provider.version>1.3.2</junit-platform-surefire-provider.version>\n        <opentest4j.version>1.2.0</opentest4j.version>\n        <jupiter.version>5.8.2</jupiter.version>\n        <strimzi-test-container.version>0.109.1</strimzi-test-container.version>\n        <mockserver.version>5.13.2</mockserver.version>\n        <mockwebserver.version>3.14.7</mockwebserver.version>\n        <valid4j.version>1.1</valid4j.version>\n        <javax.json.version>1.1.4</javax.json.version>\n        <bouncycastle.version>1.78.1</bouncycastle.version>\n        <kindcontainer.version>1.4.7</kindcontainer.version>\n        <junit4.version>4.13.2</junit4.version>\n        <skodjob.test-frame.version>0.8.0</skodjob.test-frame.version>\n        <skodjob-doc.version>0.3.0</skodjob-doc.version>\n\n        <!-- properties to skip surefire tests during failsafe execution -->\n        <skipTests>false</skipTests>\n        <skip.surefire.tests>${skipTests}</skip.surefire.tests>\n        <!-- failsafe fork-count configuration -->\n        <failsafe.forkCount>1</failsafe.forkCount>\n    </properties>\n\n    <distributionManagement>\n        <snapshotRepository>\n            <id>ossrh</id>\n            <url>https://oss.sonatype.org/content/repositories/snapshots</url>\n        </snapshotRepository>\n    </distributionManagement>\n\n    <modules>\n        <module>kafka-agent</module>\n        <module>tracing-agent</module>\n        <module>test</module>\n        <module>crd-annotations</module>\n        <module>crd-generator</module>\n        <module>api</module>\n        <module>mockkube</module>\n        <module>config-model</module>\n        <module>config-model-generator</module>\n        <module>operator-common</module>\n        <module>topic-operator</module>\n        <module>cluster-operator</module>\n        <module>user-operator</module>\n        <module>kafka-init</module>\n        <module>certificate-manager</module>\n        <module>systemtest</module>\n    </modules>\n\n    <dependencyManagement>\n        <dependencies>\n            <!-- Runtime and compile time dependencies-->\n            <dependency>\n                <groupId>io.strimzi</groupId>\n                <artifactId>crd-annotations</artifactId>\n                <version>${project.version}</version>\n                <scope>compile</scope>\n            </dependency>\n            <dependency>\n                <groupId>com.github.spotbugs</groupId>\n                <artifactId>spotbugs-annotations</artifactId>\n                <version>${spotbugs.version}</version>\n                <scope>provided</scope>\n            </dependency>\n            <dependency>\n                <groupId>io.sundr</groupId>\n                <artifactId>builder-annotations</artifactId>\n                <version>${sundrio.version}</version>\n                <exclusions>\n                    <exclusion>\n                        <groupId>com.sun</groupId>\n                        <artifactId>tools</artifactId>\n                    </exclusion>\n                </exclusions>\n            </dependency>\n            <dependency>\n                <groupId>org.projectlombok</groupId>\n                <artifactId>lombok</artifactId>\n                <version>${lombok.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.strimzi</groupId>\n                <artifactId>crd-generator</artifactId>\n                <version>${project.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.strimzi</groupId>\n                <artifactId>config-model</artifactId>\n                <version>${project.version}</version>\n                <scope>compile</scope>\n            </dependency>\n            <dependency>\n                <groupId>io.strimzi</groupId>\n                <artifactId>api</artifactId>\n                <version>${project.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.strimzi</groupId>\n                <artifactId>operator-common</artifactId>\n                <version>${project.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.strimzi</groupId>\n                <artifactId>certificate-manager</artifactId>\n                <version>${project.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.strimzi</groupId>\n                <artifactId>kafka-oauth-server</artifactId>\n                <version>${strimzi-oauth.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.strimzi</groupId>\n                <artifactId>kafka-oauth-server-plain</artifactId>\n                <version>${strimzi-oauth.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.strimzi</groupId>\n                <artifactId>kafka-oauth-client</artifactId>\n                <version>${strimzi-oauth.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.strimzi</groupId>\n                <artifactId>kafka-oauth-common</artifactId>\n                <version>${strimzi-oauth.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.strimzi</groupId>\n                <artifactId>kafka-oauth-keycloak-authorizer</artifactId>\n                <version>${strimzi-oauth.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.fabric8</groupId>\n                <artifactId>kubernetes-client</artifactId>\n                <version>${fabric8.kubernetes-client.version}</version>\n                <scope>runtime</scope>\n                <exclusions>\n                    <exclusion>\n                        <groupId>io.fabric8</groupId>\n                        <artifactId>kubernetes-httpclient-vertx</artifactId>\n                    </exclusion>\n                </exclusions>\n            </dependency>\n            <dependency>\n                <groupId>io.fabric8</groupId>\n                <artifactId>kubernetes-httpclient-jdk</artifactId>\n                <version>${fabric8.kubernetes-client.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.fabric8</groupId>\n                <artifactId>kubernetes-client-api</artifactId>\n                <version>${fabric8.kubernetes-client.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.fabric8</groupId>\n                <artifactId>kubernetes-model</artifactId>\n                <version>${fabric8.kubernetes-model.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.fabric8</groupId>\n                <artifactId>kubernetes-model-events</artifactId>\n                <version>${fabric8.kubernetes-model.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.fabric8</groupId>\n                <artifactId>kubernetes-model-extensions</artifactId>\n                <version>${fabric8.kubernetes-model.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.fabric8</groupId>\n                <artifactId>kubernetes-model-core</artifactId>\n                <version>${fabric8.kubernetes-model.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.fabric8</groupId>\n                <artifactId>kubernetes-model-common</artifactId>\n                <version>${fabric8.kubernetes-model.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.fabric8</groupId>\n                <artifactId>kubernetes-model-rbac</artifactId>\n                <version>${fabric8.kubernetes-model.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.fabric8</groupId>\n                <artifactId>kubernetes-model-apps</artifactId>\n                <version>${fabric8.kubernetes-model.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.fabric8</groupId>\n                <artifactId>kubernetes-model-apiextensions</artifactId>\n                <version>${fabric8.kubernetes-model.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.fabric8</groupId>\n                <artifactId>kubernetes-model-networking</artifactId>\n                <version>${fabric8.kubernetes-model.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.fabric8</groupId>\n                <artifactId>kubernetes-model-policy</artifactId>\n                <version>${fabric8.kubernetes-model.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.fabric8</groupId>\n                <artifactId>kubernetes-model-storageclass</artifactId>\n                <version>${fabric8.kubernetes-model.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.fabric8</groupId>\n                <artifactId>kubernetes-model-batch</artifactId>\n                <version>${fabric8.kubernetes-model.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.fabric8</groupId>\n                <artifactId>kubernetes-model-coordination</artifactId>\n                <version>${fabric8.kubernetes-model.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.fabric8</groupId>\n                <artifactId>openshift-model</artifactId>\n                <version>${fabric8.kubernetes-model.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.fabric8</groupId>\n                <artifactId>openshift-client</artifactId>\n                <version>${fabric8.openshift-client.version}</version>\n                <scope>runtime</scope>\n            </dependency>\n            <dependency>\n                <groupId>io.fabric8</groupId>\n                <artifactId>openshift-client-api</artifactId>\n                <version>${fabric8.kubernetes-client.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.fabric8</groupId>\n                <artifactId>zjsonpatch</artifactId>\n                <version>${fabric8.zjsonpatch.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.fabric8</groupId>\n                <artifactId>openshift-model-operatorhub</artifactId>\n                <version>${fabric8.openshift-client.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>org.apache.logging.log4j</groupId>\n                <artifactId>log4j-api</artifactId>\n                <version>${log4j.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>org.apache.logging.log4j</groupId>\n                <artifactId>log4j-core</artifactId>\n                <version>${log4j.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>org.apache.logging.log4j</groupId>\n                <artifactId>log4j-slf4j-impl</artifactId>\n                <version>${log4j.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>org.apache.kafka</groupId>\n                <artifactId>kafka-clients</artifactId>\n                <version>${kafka.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>org.apache.kafka</groupId>\n                <artifactId>kafka-tools</artifactId>\n                <version>${kafka.version}</version>\n                <scope>test</scope>\n            </dependency>\n            <dependency>\n                <groupId>org.apache.kafka</groupId>\n                <artifactId>kafka_2.13</artifactId>\n                <version>${kafka.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>org.apache.kafka</groupId>\n                <artifactId>kafka-server-common</artifactId>\n                <version>${kafka.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>org.apache.kafka</groupId>\n                <artifactId>connect-runtime</artifactId>\n                <version>${kafka.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>org.apache.kafka</groupId>\n                <artifactId>connect-json</artifactId>\n                <version>${kafka.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>org.apache.kafka</groupId>\n                <artifactId>connect-file</artifactId>\n                <version>${kafka.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>org.apache.kafka</groupId>\n                <artifactId>connect-api</artifactId>\n                <version>${kafka.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>org.apache.kafka</groupId>\n                <artifactId>kafka-streams</artifactId>\n                <version>${kafka.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>org.slf4j</groupId>\n                <artifactId>slf4j-api</artifactId>\n                <version>${slf4j.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>com.fasterxml.jackson.core</groupId>\n                <artifactId>jackson-core</artifactId>\n                <version>${fasterxml.jackson-core.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>com.fasterxml.jackson.core</groupId>\n                <artifactId>jackson-annotations</artifactId>\n                <version>${fasterxml.jackson-annotations.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>com.fasterxml.jackson.core</groupId>\n                <artifactId>jackson-databind</artifactId>\n                <version>${fasterxml.jackson-databind.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>com.fasterxml.jackson.dataformat</groupId>\n                <artifactId>jackson-dataformat-yaml</artifactId>\n                <version>${fasterxml.jackson-dataformat.version}</version>\n            </dependency>\n            <dependency>\n                <!-- transitive dep; override here to avoid buggy version -->\n                <groupId>com.fasterxml.jackson.dataformat</groupId>\n                <artifactId>jackson-dataformat-csv</artifactId>\n                <version>${fasterxml.jackson-dataformat.version}</version>\n            </dependency>\n            <dependency>\n                <!-- transitive dep; override here to avoid buggy version -->\n                <groupId>com.fasterxml.jackson.datatype</groupId>\n                <artifactId>jackson-datatype-jdk11</artifactId>\n                <version>${fasterxml.jackson-core.version}</version>\n            </dependency>\n            <dependency>\n                <!-- transitive dep; override here to avoid buggy version -->\n                <groupId>com.fasterxml.jackson.module</groupId>\n                <artifactId>jackson-module-jaxb-annotations</artifactId>\n                <version>${fasterxml.jackson-core.version}</version>\n            </dependency>\n            <dependency>\n                <!-- transitive dep; override here to avoid buggy version -->\n                <groupId>com.fasterxml.jackson.module</groupId>\n                <artifactId>jackson-module-paranamer</artifactId>\n                <version>${fasterxml.jackson-core.version}</version>\n            </dependency>\n            <dependency>\n                <!-- transitive dep; override here to avoid buggy version -->\n                <groupId>com.fasterxml.jackson.module</groupId>\n                <artifactId>jackson-module-scala_2.13</artifactId>\n                <version>${fasterxml.jackson-core.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>com.fasterxml.jackson.datatype</groupId>\n                <artifactId>jackson-datatype-jdk8</artifactId>\n                <version>${fasterxml.jackson-datatype.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>com.fasterxml.jackson.datatype</groupId>\n                <artifactId>jackson-datatype-jsr310</artifactId>\n                <version>${fasterxml.jackson-datatype.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>com.fasterxml.jackson.jaxrs</groupId>\n                <artifactId>jackson-jaxrs-base</artifactId>\n                <version>${fasterxml.jackson-jaxrs.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>com.fasterxml.jackson.jaxrs</groupId>\n                <artifactId>jackson-jaxrs-json-provider</artifactId>\n                <version>${fasterxml.jackson-jaxrs.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.vertx</groupId>\n                <artifactId>vertx-core</artifactId>\n                <version>${vertx.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.vertx</groupId>\n                <artifactId>vertx-micrometer-metrics</artifactId>\n                <version>${vertx.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.micrometer</groupId>\n                <artifactId>micrometer-core</artifactId>\n                <version>${micrometer.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.micrometer</groupId>\n                <artifactId>micrometer-registry-prometheus</artifactId>\n                <version>${micrometer.version}</version>\n            </dependency>\n            <dependency>\n                <!-- transitive dep; override here to avoid buggy version -->\n                <groupId>io.netty</groupId>\n                <artifactId>netty-common</artifactId>\n                <version>${netty.version}</version>\n            </dependency>\n            <dependency>\n                <!-- transitive dep; override here to avoid buggy version -->\n                <groupId>io.netty</groupId>\n                <artifactId>netty-buffer</artifactId>\n                <version>${netty.version}</version>\n            </dependency>\n            <dependency>\n                <!-- transitive dep; override here to avoid buggy version -->\n                <groupId>io.netty</groupId>\n                <artifactId>netty-transport</artifactId>\n                <version>${netty.version}</version>\n            </dependency>\n            <dependency>\n                <!-- transitive dep; override here to avoid buggy version -->\n                <groupId>io.netty</groupId>\n                <artifactId>netty-handler</artifactId>\n                <version>${netty.version}</version>\n            </dependency>\n            <dependency>\n                <!-- transitive dep; override here to avoid buggy version -->\n                <groupId>io.netty</groupId>\n                <artifactId>netty-codec</artifactId>\n                <version>${netty.version}</version>\n            </dependency>\n            <dependency>\n                <!-- transitive dep; override here to avoid buggy version -->\n                <groupId>io.netty</groupId>\n                <artifactId>netty-handler-proxy</artifactId>\n                <version>${netty.version}</version>\n            </dependency>\n            <dependency>\n                <!-- transitive dep; override here to avoid buggy version -->\n                <groupId>io.netty</groupId>\n                <artifactId>netty-codec-socks</artifactId>\n                <version>${netty.version}</version>\n            </dependency>\n            <dependency>\n                <!-- transitive dep; override here to avoid buggy version -->\n                <groupId>io.netty</groupId>\n                <artifactId>netty-codec-http</artifactId>\n                <version>${netty.version}</version>\n            </dependency>\n            <dependency>\n                <!-- transitive dep; override here to avoid buggy version -->\n                <groupId>io.netty</groupId>\n                <artifactId>netty-codec-http2</artifactId>\n                <version>${netty.version}</version>\n            </dependency>\n            <dependency>\n                <!-- transitive dep; override here to avoid buggy version -->\n                <groupId>io.netty</groupId>\n                <artifactId>netty-codec-dns</artifactId>\n                <version>${netty.version}</version>\n            </dependency>\n            <dependency>\n                <!-- transitive dep; override here to avoid buggy version -->\n                <groupId>io.netty</groupId>\n                <artifactId>netty-resolver</artifactId>\n                <version>${netty.version}</version>\n            </dependency>\n            <dependency>\n                <!-- transitive dep; override here to avoid buggy version -->\n                <groupId>io.netty</groupId>\n                <artifactId>netty-resolver-dns</artifactId>\n                <version>${netty.version}</version>\n            </dependency>\n            <dependency>\n                <!-- transitive dep; override here to avoid buggy version -->\n                <groupId>io.netty</groupId>\n                <artifactId>netty-transport-native-epoll</artifactId>\n                <version>${netty.version}</version>\n            </dependency>\n            <dependency>\n                <!-- transitive dep; override here to avoid buggy version -->\n                <groupId>io.netty</groupId>\n                <artifactId>netty-transport-native-unix-common</artifactId>\n                <version>${netty.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.netty</groupId>\n                <artifactId>netty-transport-native-epoll</artifactId>\n                <version>${netty.version}</version>\n                <classifier>linux-x86_64</classifier>\n            </dependency>\n            <dependency>\n                <groupId>io.netty</groupId>\n                <artifactId>netty-transport-native-epoll</artifactId>\n                <version>${netty.version}</version>\n                <classifier>linux-aarch_64</classifier>\n            </dependency>\n            <dependency>\n                <groupId>org.quartz-scheduler</groupId>\n                <artifactId>quartz</artifactId>\n                <version>${quartz.version}</version>\n            </dependency>\n            <dependency>\n                <!-- transitive dep; override here to avoid buggy version -->\n                <groupId>commons-codec</groupId>\n                <artifactId>commons-codec</artifactId>\n                <version>${commons-codec.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.apicurio</groupId>\n                <artifactId>apicurio-registry-utils-streams</artifactId>\n                <version>${registry.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.apicurio</groupId>\n                <artifactId>apicurio-registry-utils-kafka</artifactId>\n                <version>${registry.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.apicurio</groupId>\n                <artifactId>apicurio-registry-common</artifactId>\n                <version>${registry.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.opentelemetry</groupId>\n                <artifactId>opentelemetry-sdk-extension-autoconfigure</artifactId>\n                <version>${opentelemetry.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>com.jayway.jsonpath</groupId>\n                <artifactId>json-path</artifactId>\n                <version>${jayway-jsonpath.version}</version>\n            </dependency>\n            <!-- The skodjob dependency is required at compile time, not solely in the test scope, due to the creation of custom metrics components. -->\n            <dependency>\n                <groupId>io.skodjob</groupId>\n                <artifactId>test-frame-metrics-collector</artifactId>\n                <version>${skodjob.test-frame.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.skodjob</groupId>\n                <artifactId>test-frame-log-collector</artifactId>\n                <version>${skodjob.test-frame.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.skodjob</groupId>\n                <artifactId>test-frame-common</artifactId>\n                <version>${skodjob.test-frame.version}</version>\n            </dependency>\n            <!-- Test dependencies -->\n            <dependency>\n                <groupId>io.strimzi</groupId>\n                <artifactId>test</artifactId>\n                <version>${project.version}</version>\n                <scope>test</scope>\n            </dependency>\n            <dependency>\n                <groupId>io.strimzi</groupId>\n                <artifactId>mockkube</artifactId>\n                <version>${project.version}</version>\n                <scope>test</scope>\n            </dependency>\n            <dependency>\n                <groupId>io.strimzi</groupId>\n                <artifactId>api</artifactId>\n                <version>${project.version}</version>\n                <classifier>tests</classifier>\n                <type>test-jar</type>\n                <scope>test</scope>\n            </dependency>\n            <dependency>\n                <groupId>io.strimzi</groupId>\n                <artifactId>operator-common</artifactId>\n                <version>${project.version}</version>\n                <classifier>tests</classifier>\n                <type>test-jar</type>\n                <scope>test</scope>\n            </dependency>\n            <dependency>\n                <groupId>io.strimzi</groupId>\n                <artifactId>strimzi-test-container</artifactId>\n                <version>${strimzi-test-container.version}</version>\n                <scope>test</scope>\n            </dependency>\n            <dependency>\n                <groupId>org.mockito</groupId>\n                <artifactId>mockito-core</artifactId>\n                <version>${mockito.version}</version>\n                <scope>test</scope>\n            </dependency>\n            <dependency>\n                <groupId>org.mockito</groupId>\n                <artifactId>mockito-inline</artifactId>\n                <version>${mockito.version}</version>\n                <scope>test</scope>\n            </dependency>\n            <dependency>\n                <groupId>org.hamcrest</groupId>\n                <artifactId>hamcrest-core</artifactId>\n                <version>${hamcrest.version}</version>\n                <scope>test</scope>\n            </dependency>\n            <dependency>\n                <groupId>org.valid4j</groupId>\n                <artifactId>json-path-matchers</artifactId>\n                <version>${valid4j.version}</version>\n                <scope>test</scope>\n            </dependency>\n            <dependency>\n                <groupId>org.hamcrest</groupId>\n                <artifactId>hamcrest</artifactId>\n                <version>${hamcrest.version}</version>\n                <scope>test</scope>\n            </dependency>\n            <dependency>\n                <groupId>org.junit.jupiter</groupId>\n                <artifactId>junit-jupiter-api</artifactId>\n                <version>${jupiter.version}</version>\n                <scope>test</scope>\n            </dependency>\n            <dependency>\n                <groupId>org.junit.jupiter</groupId>\n                <artifactId>junit-jupiter-params</artifactId>\n                <version>${jupiter.version}</version>\n                <scope>test</scope>\n            </dependency>\n            <dependency>\n                <groupId>io.vertx</groupId>\n                <artifactId>vertx-junit5</artifactId>\n                <version>${vertx-junit5.version}</version>\n                <scope>test</scope>\n            </dependency>\n            <dependency>\n                <groupId>org.junit.platform</groupId>\n                <artifactId>junit-platform-commons</artifactId>\n                <version>${junit.platform.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>org.junit.platform</groupId>\n                <artifactId>junit-platform-launcher</artifactId>\n                <version>${junit.platform.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>org.junit.platform</groupId>\n                <artifactId>junit-platform-engine</artifactId>\n                <version>${junit.platform.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>org.eclipse.jetty</groupId>\n                <artifactId>jetty-server</artifactId>\n                <version>${jetty.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>org.eclipse.jetty</groupId>\n                <artifactId>jetty-util</artifactId>\n                <version>${jetty.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>javax.servlet</groupId>\n                <artifactId>javax.servlet-api</artifactId>\n                <version>${javax-servlet.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>com.dajudge.kindcontainer</groupId>\n                <artifactId>kindcontainer</artifactId>\n                <version>${kindcontainer.version}</version>\n            </dependency>\n            <!-- JUnit dependency is needed at compile time by MockKube because of how Test Containers are designed -->\n            <dependency>\n                <groupId>junit</groupId>\n                <artifactId>junit</artifactId>\n                <version>${junit4.version}</version>\n            </dependency>\n            <dependency>\n                <groupId>io.skodjob</groupId>\n                <artifactId>test-docs-generator-maven-plugin</artifactId>\n                <version>${skodjob-doc.version}</version>\n                <scope>test</scope>\n            </dependency>\n        </dependencies>\n    </dependencyManagement>\n\n    <build>\n        <pluginManagement>\n            <plugins>\n                <plugin>\n                    <groupId>org.apache.maven.plugins</groupId>\n                    <artifactId>maven-compiler-plugin</artifactId>\n                    <version>${maven.compiler.version}</version>\n                    <executions>\n                        <execution>\n                            <id>default-compile</id>\n                            <phase>compile</phase>\n                            <goals>\n                                <goal>compile</goal>\n                            </goals>\n                            <configuration>\n                                <compilerArgs>\n                                    <arg>-Xlint:unchecked,deprecation</arg>\n                                    <arg>-Werror</arg>\n                                </compilerArgs>\n                            </configuration>\n                        </execution>\n                    </executions>\n                </plugin>\n                <plugin>\n                    <groupId>org.apache.maven.plugins</groupId>\n                    <artifactId>maven-dependency-plugin</artifactId>\n                    <version>${maven.dependency.version}</version>\n                    <executions>\n                        <execution>\n                            <id>copy-dependencies</id>\n                            <phase>none</phase>\n                            <goals>\n                                <goal>copy-dependencies</goal>\n                            </goals>\n                            <configuration>\n                                <includeScope>runtime</includeScope>\n                                <outputDirectory>${project.build.directory}/lib</outputDirectory>\n                                <prependGroupId>true</prependGroupId>\n                                <overWriteReleases>false</overWriteReleases>\n                                <overWriteSnapshots>false</overWriteSnapshots>\n                                <overWriteIfNewer>true</overWriteIfNewer>\n                            </configuration>\n                        </execution>\n                        <execution>\n                            <id>set-classpath</id>\n                            <phase>none</phase>\n                            <goals>\n                                <goal>build-classpath</goal>\n                            </goals>\n                            <configuration>\n                                <includeScope>runtime</includeScope>\n                                <outputProperty>project.dist.classpath</outputProperty>\n                                <attach>false</attach>\n                                <prefix>lib</prefix>\n                                <prependGroupId>true</prependGroupId>\n                                <overWriteReleases>false</overWriteReleases>\n                                <overWriteSnapshots>false</overWriteSnapshots>\n                                <overWriteIfNewer>true</overWriteIfNewer>\n                            </configuration>\n                        </execution>\n                    </executions>\n                </plugin>\n                <plugin>\n                    <groupId>org.apache.maven.plugins</groupId>\n                    <artifactId>maven-assembly-plugin</artifactId>\n                    <version>${maven.assembly.version}</version>\n                    <executions>\n                        <execution>\n                            <id>make-dist-assembly</id>\n                            <phase>none</phase>\n                            <goals>\n                                <goal>single</goal>\n                            </goals>\n                            <configuration>\n                                <outputDirectory>../docker-images/artifacts/binaries</outputDirectory>\n                                <descriptors>\n                                    <descriptor>../dist.xml</descriptor>\n                                </descriptors>\n                                <delimiters>\n                                    <delimiter>@</delimiter>\n                                </delimiters>\n                            </configuration>\n                        </execution>\n                    </executions>\n                </plugin>\n            </plugins>\n        </pluginManagement>\n\n        <plugins>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-checkstyle-plugin</artifactId>\n                <version>${maven.checkstyle.version}</version>\n                <dependencies>\n                    <dependency>\n                        <groupId>com.puppycrawl.tools</groupId>\n                        <artifactId>checkstyle</artifactId>\n                        <version>${checkstyle.version}</version>\n                    </dependency>\n                </dependencies>\n                <executions>\n                    <execution>\n                        <id>validate</id>\n                        <phase>validate</phase>\n                        <configuration>\n                            <configLocation>.checkstyle/checkstyle.xml</configLocation>\n                            <suppressionsLocation>.checkstyle/suppressions.xml</suppressionsLocation>\n                            <includeTestSourceDirectory>true</includeTestSourceDirectory>\n                            <consoleOutput>true</consoleOutput>\n                            <failsOnError>true</failsOnError>\n                            <propertyExpansion>importControlFile=${strimziRootDirectory}/.checkstyle/import-control.xml</propertyExpansion>\n                        </configuration>\n                        <goals>\n                            <goal>check</goal>\n                        </goals>\n                    </execution>\n                </executions>\n            </plugin>\n            <plugin>\n                <groupId>org.jacoco</groupId>\n                <artifactId>jacoco-maven-plugin</artifactId>\n                <version>${maven.jacoco.version}</version>\n                <executions>\n                    <execution>\n                        <id>default-prepare-agent</id>\n                        <goals>\n                            <goal>prepare-agent</goal>\n                        </goals>\n                    </execution>\n                    <execution>\n                        <id>default-report</id>\n                        <goals>\n                            <goal>report</goal>\n                        </goals>\n                        <configuration>\n                            <excludes>\n                                <exclude>io/strimzi/api/**/*Fluent*.class</exclude>\n                                <exclude>io/strimzi/api/**/*Builder*.class</exclude>\n                            </excludes>\n                        </configuration>\n                    </execution>\n                </executions>\n            </plugin>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-surefire-plugin</artifactId>\n                <inherited>true</inherited>\n                <version>${maven.surefire.version}</version>\n                <configuration>\n                    <environmentVariables>\n                        <ENV_VAR_EXISTS>value</ENV_VAR_EXISTS>\n                        <ENV_VAR_EXISTS_BOOLEAN>true</ENV_VAR_EXISTS_BOOLEAN>\n                    </environmentVariables>\n                    <trimStackTrace>false</trimStackTrace>\n                    <forkCount>1</forkCount>\n                    <!-- This is workaround for https://issues.apache.org/jira/browse/SUREFIRE-1809 -->\n                    <useModulePath>false</useModulePath>\n                    <skipTests>${skip.surefire.tests}</skipTests>\n                </configuration>\n                <dependencies>\n                    <dependency>\n                        <groupId>org.junit.jupiter</groupId>\n                        <artifactId>junit-jupiter-engine</artifactId>\n                        <version>${jupiter.version}</version>\n                    </dependency>\n                    <dependency>\n                        <groupId>io.vertx</groupId>\n                        <artifactId>vertx-junit5</artifactId>\n                        <version>${vertx-junit5.version}</version>\n                    </dependency>\n                </dependencies>\n            </plugin>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-failsafe-plugin</artifactId>\n                <version>${maven.failsafe.version}</version>\n                <executions>\n                    <execution>\n                        <goals>\n                            <goal>integration-test</goal>\n                            <goal>verify</goal>\n                        </goals>\n                        <configuration>\n                            <includes>\n                                <include>**/IT*.java</include>\n                                <include>**/*IT.java</include>\n                                <include>**/ST*.java</include>\n                                <include>**/*ST.java</include>\n                            </includes>\n                            <trimStackTrace>false</trimStackTrace>\n                            <!--\n                              Fork count is configured through a system property:\n                                * ITs run with forked VM because of class path for Apache Kafka\n                                * STs run without forking the VM for better log output in CI pipelines\n                                -->\n                            <forkCount>${failsafe.forkCount}</forkCount>\n                            <!-- This is workaround for https://issues.apache.org/jira/browse/SUREFIRE-1809 -->\n                            <useModulePath>false</useModulePath>\n                            <statelessTestsetReporter implementation=\"org.apache.maven.plugin.surefire.extensions.junit5.JUnit5Xml30StatelessReporter\">\n                                <disable>false</disable>\n                                <version>3.0</version>\n                                <usePhrasedFileName>false</usePhrasedFileName>\n                                <usePhrasedTestSuiteClassName>true</usePhrasedTestSuiteClassName>\n                                <usePhrasedTestCaseClassName>true</usePhrasedTestCaseClassName>\n                                <usePhrasedTestCaseMethodName>true</usePhrasedTestCaseMethodName>\n                            </statelessTestsetReporter>\n                            <consoleOutputReporter implementation=\"org.apache.maven.plugin.surefire.extensions.junit5.JUnit5ConsoleOutputReporter\">\n                                <disable>false</disable>\n                                <encoding>UTF-8</encoding>\n                                <usePhrasedFileName>true</usePhrasedFileName>\n                            </consoleOutputReporter>\n                            <statelessTestsetInfoReporter implementation=\"org.apache.maven.plugin.surefire.extensions.junit5.JUnit5StatelessTestsetInfoReporter\">\n                                <disable>false</disable>\n                                <usePhrasedFileName>false</usePhrasedFileName>\n                                <usePhrasedClassNameInRunning>false</usePhrasedClassNameInRunning>\n                                <usePhrasedClassNameInTestCaseSummary>true</usePhrasedClassNameInTestCaseSummary>\n                            </statelessTestsetInfoReporter>\n                        </configuration>\n                    </execution>\n                </executions>\n            </plugin>\n            <plugin>\n                <groupId>com.github.spotbugs</groupId>\n                <artifactId>spotbugs-maven-plugin</artifactId>\n                <version>${maven.spotbugs.version}</version><dependencies>\n                <!-- overwrite dependency on spotbugs if you want to specify the version of˓→spotbugs -->\n                <dependency>\n                    <groupId>com.github.spotbugs</groupId>\n                    <artifactId>spotbugs</artifactId>\n                    <version>${spotbugs.version}</version>\n                </dependency></dependencies>\n                <configuration>\n                    <effort>Max</effort>\n                    <!-- Reports all bugs (other values are medium and max) -->\n                    <threshold>Low</threshold>\n                    <!-- Produces XML report -->\n                    <xmlOutput>true</xmlOutput>\n                    <!-- Configures the directory in which the XML report is created -->\n                    <spotbugsXmlOutputDirectory>${project.build.directory}/spotbugs</spotbugsXmlOutputDirectory>\n                    <!-- Configures the file for excluding warnings -->\n                    <excludeFilterFile>${project.basedir}/../.spotbugs/spotbugs-exclude.xml</excludeFilterFile>\n                </configuration>\n            </plugin>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-dependency-plugin</artifactId>\n                <version>${maven.dependency.version}</version>\n                <executions>\n                    <execution>\n                        <id>analyze</id>\n                        <goals>\n                            <goal>analyze-only</goal>\n                        </goals>\n                        <configuration>\n                            <failOnWarning>true</failOnWarning>\n                        </configuration>\n                    </execution>\n                </executions>\n            </plugin>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-source-plugin</artifactId>\n                <version>${maven.source.version}</version>\n                <executions>\n                    <execution>\n                        <id>attach-sources</id>\n                        <goals>\n                            <goal>jar</goal>\n                        </goals>\n                    </execution>\n                </executions>\n            </plugin>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-javadoc-plugin</artifactId>\n                <version>${maven.javadoc.version}</version>\n                <executions>\n                    <execution>\n                        <id>attach-javadocs</id>\n                        <goals>\n                            <goal>jar</goal>\n                        </goals>\n                        <configuration>\n                            <sourcepath>${project.build.sourceDirectory}:${project.build.directory}/generated-sources/annotations</sourcepath>\n                            <show>public</show>\n                            <failOnError>true</failOnError>\n                            <failOnWarnings>false</failOnWarnings>\n                        </configuration>\n                    </execution>\n                </executions>\n            </plugin>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-jar-plugin</artifactId>\n                <version>${maven.jar.version}</version>\n                <configuration>\n                    <archive>\n                        <manifest>\n                            <addDefaultImplementationEntries>true</addDefaultImplementationEntries>\n                            <addDefaultSpecificationEntries>true</addDefaultSpecificationEntries>\n                        </manifest>\n                    </archive>\n                </configuration>\n            </plugin>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-enforcer-plugin</artifactId>\n                <version>${maven.enforcer.version}</version>\n                <executions>\n                    <execution>\n                        <id>enforce-banned-dependencies</id>\n                        <goals>\n                            <goal>enforce</goal>\n                        </goals>\n                        <configuration>\n                            <rules>\n                                <bannedDependencies>\n                                    <excludes>\n                                        <!-- use org.apache.logging.log4j:log4j-slf4j-impl -->\n                                        <exclude>ch.qos.logback:*</exclude>\n                                        <!-- use org.apache.logging.log4j:log4j-1.2-api shim -->\n                                        <exclude>log4j:log4j:*:jar:compile</exclude>\n                                        <!-- use org.apache.logging.log4j:log4j-slf4j-impl -->\n                                        <exclude>org.slf4j:slf4j-log4j12:*:jar:compile</exclude>\n                                    </excludes>\n                                </bannedDependencies>\n                            </rules>\n                            <fail>true</fail>\n                        </configuration>\n                    </execution>\n                </executions>\n            </plugin>\n        </plugins>\n    </build>\n    <profiles>\n        <profile>\n            <id>coverage</id>\n            <build>\n                <plugins>\n                    <plugin>\n                        <groupId>org.apache.maven.plugins</groupId>\n                        <artifactId>maven-surefire-plugin</artifactId>\n                        <version>${maven.surefire.version}</version>\n                        <configuration>\n                            <!--suppress UnresolvedMavenProperty -->\n                            <argLine>${surefireArgLine}</argLine>\n                        </configuration>\n                    </plugin>\n                </plugins>\n            </build>\n        </profile>\n        <profile>\n            <id>ossrh</id>\n            <activation>\n                <activeByDefault>false</activeByDefault>\n            </activation>\n            <properties>\n                <!--suppress UnresolvedMavenProperty -->\n                <gpg.executable>${env.GPG_EXECUTABLE}</gpg.executable>\n                <!--suppress UnresolvedMavenProperty -->\n                <gpg.passphrase>${env.GPG_PASSPHRASE}</gpg.passphrase>\n            </properties>\n            <build>\n                <plugins>\n                    <plugin>\n                        <groupId>org.apache.maven.plugins</groupId>\n                        <artifactId>maven-gpg-plugin</artifactId>\n                        <version>${maven.gpg.version}</version>\n                        <executions>\n                            <execution>\n                                <id>sign-artifacts</id>\n                                <phase>verify</phase>\n                                <goals>\n                                    <goal>sign</goal>\n                                </goals>\n                                <configuration>\n                                    <gpgArguments>\n                                        <arg>--batch</arg>\n                                        <arg>--pinentry-mode</arg>\n                                        <arg>loopback</arg>\n                                    </gpgArguments>\n                                </configuration>\n                            </execution>\n                        </executions>\n                    </plugin>\n                    <plugin>\n                        <groupId>org.sonatype.plugins</groupId>\n                        <artifactId>nexus-staging-maven-plugin</artifactId>\n                        <version>${sonatype.nexus.staging.version}</version>\n                        <extensions>true</extensions>\n                        <configuration>\n                            <serverId>ossrh</serverId>\n                            <nexusUrl>https://oss.sonatype.org/</nexusUrl>\n                            <autoReleaseAfterClose>false</autoReleaseAfterClose>\n                        </configuration>\n                    </plugin>\n                </plugins>\n            </build>\n        </profile>\n    </profiles>\n</project>\n"
        },
        {
          "name": "release.version",
          "type": "blob",
          "size": 0.015625,
          "content": "0.46.0-SNAPSHOT\n"
        },
        {
          "name": "systemtest",
          "type": "tree",
          "content": null
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "topic-operator",
          "type": "tree",
          "content": null
        },
        {
          "name": "tracing-agent",
          "type": "tree",
          "content": null
        },
        {
          "name": "user-operator",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}