{
  "metadata": {
    "timestamp": 1736708178225,
    "page": 644,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjY1MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "lakesoul-io/LakeSoul",
      "stars": 2759,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.1083984375,
          "content": "# SPDX-FileCopyrightText: 2023 LakeSoul Contributors\n#\n# SPDX-License-Identifier: Apache-2.0\n\n/target/\n/.idea/\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.81640625,
          "content": "# SPDX-FileCopyrightText: 2023 LakeSoul Contributors\n#\n# SPDX-License-Identifier: Apache-2.0\n\n/target/\n/build/\n/.idea/\n/spark-warehouse/\n/derby.log\n/.metals/\n/.vscode/\n*.iml\n/native-io/lakesoul-io-java/target/\n/aws-test/target/\n/native-io/lakesoul-io-java/.idea/\ndependency-reduced-pom.xml\n/lakesoul-spark/spark-warehouse/\ndependency-reduced-pom.xml\n/lakesoul-spark/spark-warehouse/\n/script/benchmark/work-dir/*.jar\n*.DS_Store\n__pycache__/\n/cpp/build/\n/python/lakesoul/.libs/\n/python/lakesoul/arrow/_lakesoul_dataset.so\n/python/pyarrow\n/rust/lakesoul-io-c/lakesoul_c_bindings.h\n/rust/lakesoul-io-java/target/\n/rust/lakesoul-io-java/.idea/\n/python/lakesoul/metadata/generated/entity_pb2.py\n/python/lakesoul/metadata/generated/entity_pb2_grpc.py\n/python/build/\n/python/lakesoul.egg-info/\n*.whl\n/wheelhouse/\n/rust/.idea\n.flattened-pom.xml\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.083984375,
          "content": "<!--\nSPDX-FileCopyrightText: 2023 LakeSoul Contributors\n\nSPDX-License-Identifier: Apache-2.0\n-->\n\n# Code of Conduct\n\nAll members of this project agree to adhere to the following Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment include:\n\n* Using welcoming and inclusive language\n\n* Being respectful of differing viewpoints and experiences\n\n* Gracefully accepting constructive criticism\n\n* Focusing on what is best for the community\n\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or advances\n\n* Trolling, insulting/derogatory comments, and personal or political attacks\n\n* Public or private harassment\n\n* Publishing others’ private information, such as a physical or electronic address, without explicit permission\n\n* Other conduct which could reasonably be considered inappropriate in a professional setting\n\n## Our Responsibilities\n\nMaintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.\n\nMaintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting us at <lakesoul-tsc@lists.lfaidata.foundation>. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The Code of Conduct Committee is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.\n\n## Attribution\n\nThis Code of Conduct is adapted from the Contributor Covenant, version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 4.373046875,
          "content": "<!--\nSPDX-FileCopyrightText: 2023 LakeSoul Contributors\n\nSPDX-License-Identifier: Apache-2.0\n-->\n\n# Contributing to LakeSoul\n\nThis project welcomes contributors from any organization or background, provided they are\nwilling to follow the simple processes outlined below, as well as adhere to the \n[Code of Conduct](CODE_OF_CONDUCT.md).\n\n## Joining the community\n\nThe community collaborates primarily through  `GitHub` and the instance messaging tool, `Slack`.\nThere is also a mailing list.\nSee how to join [here](https://github.com/lakesoul-io/LakeSoul/blob/main/community-guideline.md)\n\n## Reporting an Issue\n\nPlease use the [issues][issues] section of the LakeSoul repository and search for a similar problem. If you don't find it, submit your bug, question, proposal or feature request.\n\nUse tags to indicate parts of the LakeSoul that your issue relates to.\nFor example, in the case of bugs, please provide steps to reproduce it and tag your issue with `bug` and integration that has that bug, for example `spark` or `flink`.\n\n\n## Contributing to the project\n\n### Creating Pull Requests\nBefore sending a Pull Request with significant changes, please use the [issue tracker][issues] to discuss the potential improvements you want to make.\n\nLakeSoul uses [GitHub's fork and pull model](https://help.github.com/articles/about-collaborative-development-models/)\nto create a contribution.\n\nTo ensure your pull request is accepted, follow these guidelines:\n\n* All changes should be accompanied by tests\n* Do your best to have a [well-formed commit message](https://tbaggery.com/2008/04/19/a-note-about-git-commit-messages.html) for your change\n* Do your best to have a [well-formed](https://frontside.com/blog/2020-7-reasons-for-good-pull-request-descriptions) pull request description for your change\n* [Keep diffs small](https://kurtisnusbaum.medium.com/stacked-diffs-keeping-phabricator-diffs-small-d9964f4dcfa6) and self-contained\n* If your change fixes a bug, please [link the issue](https://help.github.com/articles/closing-issues-using-keywords) in your pull request description\n* Your pull request title should be of the form `[component] name`, where `[component]` is the part of LakeSoul repo that your PR changes. For example: `[Flink] add table source implementation`\n* Use tags to indicate parts of the repository that your PR refers to\n\n### Branching\n\n* Use a _group_ at the beginning of your branch names:\n\n  ```\n  feature  Add or expand a feature\n  bug      Fix a bug\n  ```\n\n  _For example_:\n\n  ```\n  feature/my-cool-new-feature\n  bug/my-bug-fix\n  bug/my-other-bug-fix\n  ```\n\n* Choose _short_ and _descriptive_ branch names\n* Use dashes (`-`) to separate _words_ in branch names\n* Use _lowercase_ in branch names\n\n## Proposing changes\n\nCreate an issue and tag it as `proposal`.\n\nIn the description provide the following sections:\n - Purpose (Why?): What is the use case this is for. \n - Proposed implementation (How?): Quick description of how do you propose to implement it. Are you proposing a new facet?\n\nThis can be just a couple paragraphs to start with.\n\nIssue that could be splitted into several tasks should be tagged as `epic`.\n\n## First-Time Contributors\n\nIf this is your first contribution to open source, you can [follow this tutorial][contributiontutorial] or check out [this video series][contributionvideos] to learn about the contribution workflow with GitHub.\n\nLook for tickets labeled ['good first issue'][goodfirstissues] and ['help wanted'][helpwantedissues]. These are a great starting point if you want to contribute. Don't hesitate to ask questions about the issue if you are not sure about the strategy to follow.\n\n\n[issues]: https://github.com/metas-soul/LakeSoul/issues\n[contributiontutorial]: https://github.com/firstcontributions/first-contributions#first-contributions\n[contributionvideos]: https://egghead.io/courses/how-to-contribute-to-an-open-source-project-on-github\n[goodfirstissues]: https://github.com/lakesoul-io/LakeSoul/labels/good%20first%20issue\n[helpwantedissues]: https://github.com/lakesoul-io/LakeSoul/labels/help%20wanted\n\n## Triggering CI runs from forks (committers)\n\nCI runs on forks are disabled due to the possibility of access by external services via CI run. \nOnce a contributor decides a PR is ready to be checked, they can use [this script](https://github.com/jklukas/git-push-fork-to-upstream-branch)\nto trigger a CI run on a separate branch with the same commit ID. This will update the CI status of a PR.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.255859375,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [2023] [LakeSoul Contributors]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n   \nAdditional Remarks:\nSome work of this project originates from our previous project: https://github.com/engine-plus/starlake,\nwhich was also opensourced under APL V2.\n\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.1162109375,
          "content": "recursive-include python/lakesoul *.py\nrecursive-include python/lakesoul *.so*\nrecursive-exclude python/lakesoul *.cpp\n"
        },
        {
          "name": "README-CN.md",
          "type": "blob",
          "size": 5.07421875,
          "content": "<!--\nSPDX-FileCopyrightText: 2023 LakeSoul Contributors\n\nSPDX-License-Identifier: Apache-2.0\n-->\n\n<img src='https://github.com/lakesoul-io/artwork/blob/main/horizontal/color/LakeSoul_Horizontal_Color.svg' alt=\"LakeSoul\" height='200'>\n\n<img src='https://github.com/lfai/artwork/blob/main/lfaidata-assets/lfaidata-project-badge/sandbox/color/lfaidata-project-badge-sandbox-color.svg' alt=\"LF AI & Data Sandbox Project\" height='180'>\n\nLakeSoul 是一款开源云原生湖仓一体框架，具备高可扩展的元数据管理、ACID 事务、高效灵活的 upsert 操作、Schema 演进和批流一体化处理等特性。LakeSoul 支持多种计算引擎读写湖仓表数据，包括 Spark、Flink、Presto、PyTorch，支持批、流、MPP、AI 多种计算模式。LakeSoul 支持 HDFS、S3 等存储系统。\n![LakeSoul 架构](website/static/img/lakeSoulModel.png)\n\nLakeSoul 由数元灵科技研发并于 2023 年 5 月正式捐赠给 Linux Foundation AI & Data 基金会，成为基金会旗下 Sandbox 孵化项目。\n\nLakeSoul 专门为数据湖云存储之上的数据进行行、列级别增量更新、高并发入库、批量扫描读取做了大量优化。云原生计算存储分离的架构使得部署非常简单，同时可以以很低的成本支撑极大的数据量。\n\nLakeSoul 通过类似 LSM-Tree 的方式在哈希分区主键 upsert 场景支持了高性能的写吞吐能力。同时高度优化的 Merge on Read 实现也保证了读性能（参考 [性能对比](https://lakesoul-io.github.io/zh-Hans/blog/2023/04/21/lakesoul-2.2.0-release)）。LakeSoul 通过 PostgreSQL 来管理元数据，实现元数据的高可扩展性和高并发事物能力。\n\nLakeSoul 使用 Rust 实现了 native 的元数据层和 IO 层，并封装了 C/Java/Python 接口，从而能够支持大数据和 AI 等多种计算框架对接。\n\nLakeSoul 支持流、批并发读写，读写全面兼容 CDC 语义，通过自动 Schema 演进和严格一次语义等功能，能够轻松构建全链路流式数仓。\n\nLakeSoul 支持多工作空间和用户权限隔离。LakeSoul 使用 Postgres 的 RBAC 和行级别安全策略，实现了元数据的权限隔离。配合 Hadoop 用户和组，可以实现物理数据隔离。LakeSoul 的权限隔离对 SQL/Java/Python 的作业都是有效的。\n\nLakeSoul 支持自动分离式 Compaction 、自动表生命周期清理、自动冗余数据清理，降低维护成本，提升易用性。\n\n更多特性和其他产品对比请参考：[特性介绍](https://lakesoul-io.github.io/zh-Hans/docs/intro)\n\n# 使用教程\n* [湖仓对接 AI：使用 Python 进行数据预处理和模型训练](https://github.com/lakesoul-io/LakeSoul/tree/main/python/examples\u001b)：LakeSoul 将湖仓和 AI 无缝衔接，打造 Data+AI 的现代数据架构。\n* [CDC 整库入湖教程](https://lakesoul-io.github.io/zh-Hans/docs/Tutorials/flink-cdc-sink): LakeSoul 通过 Flink CDC 实现 MySQL 等多种数据库的整库同步，支持自动建表、自动 DDL 变更、严格一次（exactly once）保证。\n* [Flink SQL 教程](https://lakesoul-io.github.io/zh-Hans/docs/Usage%20Docs/flink-lakesoul-connector)：LakeSoul 支持 Flink 流、批读写。流式读写完整支持 Flink Changelog 语义，支持行级别流式增删改。\n* [多流合并构建宽表教程](https://lakesoul-io.github.io/zh-Hans/docs/Tutorials/mutil-stream-merge)：LakeSoul 原生支持多个具有相同主键的流（其余列可以不同）自动合并到同一张表，消除 Join.\n* [数据更新 (Upsert) 和 Merge UDF 使用教程](https://lakesoul-io.github.io/zh-Hans/docs/Tutorials/upsert-and-merge-udf)：LakeSoul 使用 Merge UDF 自定义 Merge 逻辑的用法示例。\n* [快照相关功能用法教程](https://lakesoul-io.github.io/zh-Hans/docs/Tutorials/snapshot-manage): LakeSoul 快照读、回滚、清理等功能用法。\n* [增量查询教程](https://lakesoul-io.github.io/zh-Hans/docs/Tutorials/incremental-query): Spark 中增量查询（支持流、批两种模式）用法。\n\n# 使用文档\n\n[快速开始](https://lakesoul-io.github.io/zh-Hans/docs/Getting%20Started/setup-local-env)\n\n[使用文档](https://lakesoul-io.github.io/zh-Hans/docs/Usage%20Docs/setup-meta-env)\n\n# 特性路线\n[Feature Roadmap](https://github.com/lakesoul-io/LakeSoul#feature-roadmap)\n\n# 社区准则\n[社区准则](community-guideline-cn.md)\n\n# 问题反馈\n\n欢迎提 issue、discussion 反馈问题。\n\n### 微信公众号\n欢迎关注 <u>**元灵数智**</u> 公众号，我们会定期推送关于 LakeSoul 的架构代码解读、端到端算法业务落地案例分享等干货文章：\n\n### LakeSoul 开发者社区微信群\n欢迎加入 LakeSoul 开发者社区微信群，随时交流 LakeSoul 开发相关的各类问题：请关注公众号后点击下方 \"了解我们-用户交流\" 获取最新微信群二维码。或扫描以下二维码添加小助手微信后加群：\n\n![微信交流群](website/static/img/wechat.png)\n\n# 联系我们\n发送邮件至 [lakesoul-technical-discuss@lists.lfaidata.foundation](mailto:lakesoul-technical-discuss@lists.lfaidata.foundation).\n\n# 开源协议\nLakeSoul 采用 Apache License v2.0 开源协议。"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 8.30859375,
          "content": "<!--\nSPDX-FileCopyrightText: 2023 LakeSoul Contributors\n\nSPDX-License-Identifier: Apache-2.0\n-->\n\n<img src='https://github.com/lakesoul-io/artwork/blob/main/horizontal/color/LakeSoul_Horizontal_Color.svg' alt=\"LakeSoul\" height='200'>\n\n<img src='https://github.com/lfai/artwork/blob/main/lfaidata-assets/lfaidata-project-badge/sandbox/color/lfaidata-project-badge-sandbox-color.svg' alt=\"LF AI & Data Sandbox Project\" height='180'>\n\n![OpenSSF Best Practices](https://bestpractices.coreinfrastructure.org/projects/7192/badge)\n\n![Maven Test](https://github.com/lakesoul-io/LakeSoul/actions/workflows/maven-test.yml/badge.svg)\n![Flink CDC Test](https://github.com/lakesoul-io/LakeSoul/actions/workflows/flink-cdc-test.yml/badge.svg)\n![Build](https://github.com/lakesoul-io/LakeSoul/actions/workflows/native-build.yml/badge.svg)\n\n[中文介绍](README-CN.md)\n\nLakeSoul is a cloud-native Lakehouse framework that supports scalable metadata management, ACID transactions, efficient and flexible upsert operation, schema evolution, and unified streaming & batch processing.\n\nLakeSoul supports multiple computing engines to read and write lake warehouse table data, including Spark, Flink, Presto, and PyTorch, and supports multiple computing modes such as batch, stream, MPP, and AI. LakeSoul supports storage systems such as HDFS and S3.\n\n![LakeSoul Arch](website/static/img/lakeSoulModel.png)\n\nLakeSoul was originally created by DMetaSoul company and was donated to Linux Foundation AI & Data as a sandbox project since May 2023.\n\nLakeSoul implements incremental upserts for both row and column and allows concurrent updates.\n\nLakeSoul uses LSM-Tree like structure to support updates on hash partitioning table with primary key, and achieves very high write throughput while providing optimized merge on read performance (refer to [Performance Benchmarks](https://lakesoul-io.github.io/blog/2023/04/21/lakesoul-2.2.0-release)). LakeSoul scales metadata management and achieves ACID control by using PostgreSQL.\n\nLakeSoul uses Rust to implement the native metadata layer and IO layer, and provides C/Java/Python interfaces to support the connecting of multiple computing frameworks such as big data and AI.\n\nLakeSoul supports concurrent batch or streaming read and write. Both read and write supports CDC semantics, and together with auto schema evolution and exacly-once guarantee, constructing realtime data warehouses is made easy.\n\nLakeSoul supports multi-workspace and RBAC. LakeSoul uses Postgres's RBAC and row-level security policies to implement permission isolation for metadata. Together with Hadoop users and groups, physical data isolation can be achieved. LakeSoul's permission isolation is effective for SQL/Java/Python jobs.\n\nLakeSoul supports automatic disaggregated compaction, automatic table life cycle maintenance, and automatic redundant data cleaning, reducing operation costs and improving usability.\n\nMore detailed features please refer to our doc page: [Documentations](https://lakesoul-io.github.io/docs/intro)\n\n# Quick Start\nFollow the [Quick Start](https://lakesoul-io.github.io/docs/Getting%20Started/setup-local-env) to quickly set up a test env.\n\n# Tutorials\nPlease find tutorials in doc site:\n\n* Checkout [Examples of Python Data Processing and AI Model Training on LakeSoul](https://github.com/lakesoul-io/LakeSoul/tree/main/python/examples) on how LakeSoul connecting AI to Lakehouse to build a unified and modern data infrastructure.\n* Checkout [LakeSoul Flink CDC Whole Database Synchronization Tutorial](https://lakesoul-io.github.io/docs/Tutorials/flink-cdc-sink) on how to sync an entire MySQL database into LakeSoul in realtime, with auto table creation, auto DDL sync and exactly once guarantee.\n* Checkout [Flink SQL Usage](https://lakesoul-io.github.io/docs/Usage%20Docs/flink-lakesoul-connector) on using Flink SQL to read or write LakeSoul in both batch and streaming mode, with the supports of Flink Changelog Stream semantics and row-level upsert and delete.\n* Checkout [Multi Stream Merge and Build Wide Table Tutorial](https://lakesoul-io.github.io/docs/Tutorials/mutil-stream-merge) on how to merge multiple stream with same primary key (and different other columns) concurrently without join.\n* Checkout [Upsert Data and Merge UDF Tutorial](https://lakesoul-io.github.io/docs/Tutorials/upsert-and-merge-udf) on how to upsert data and Merge UDF to customize merge logic.\n* Checkout [Snapshot API Usage](https://lakesoul-io.github.io/docs/Tutorials/snapshot-manage) on how to do snapshot read (time travel), snapshot rollback and cleanup.\n* Checkout [Incremental Query Tutorial](https://lakesoul-io.github.io/docs/Tutorials/incremental-query) on how to do incremental query in Spark in batch or stream mode.\n\n# Usage Documentations\nPlease find usage documentations in doc site:\n[Usage Doc](https://lakesoul-io.github.io/docs/Usage%20Docs/setup-meta-env)\n\n[快速开始](https://lakesoul-io.github.io/zh-Hans/docs/Getting%20Started/setup-local-env)\n\n[教程](https://lakesoul-io.github.io/zh-Hans/docs/Tutorials/flink-cdc-sink)\n\n[使用文档](https://lakesoul-io.github.io/zh-Hans/docs/Usage%20Docs/setup-meta-env)\n\n# Feature Roadmap\n* Data Science and AI\n  - [x] Native Python Reader (without PySpark)\n  - [x] PyTorch Dataset and distributed training\n* Meta Management ([#23](https://github.com/lakesoul-io/LakeSoul/issues/23))\n  - [x] Multiple Level Partitioning: Multiple range partition and at most one hash partition\n  - [x] Concurrent write with auto conflict resolution\n  - [x] MVCC with read isolation\n  - [x] Write transaction (two-stage commit) through Postgres Transaction\n  - [x] Schema Evolution: Column add/delete supported\n* Table operations \n  - [x] LSM-Tree style upsert for hash partitioned table\n  - [x] Merge on read for hash partition with upsert delta file\n  - [x] Copy on write update for non hash partitioned table\n  - [x] Automatic Disaggregated Compaction Service\n* Data Warehousing\n  - [x] CDC stream ingestion with auto ddl sync\n  - [x] Incremental and Snapshot Query\n    - [x] Snapshot Query ([#103](https://github.com/lakesoul-io/LakeSoul/issues/103))\n    - [x] Incremental Query ([#103](https://github.com/lakesoul-io/LakeSoul/issues/103))\n    - [x] Incremental Streaming Source ([#130](https://github.com/lakesoul-io/LakeSoul/issues/130))\n    - [x] Flink Stream/Batch Source\n  - [x] Multi Workspaces and RBAC\n* Spark Integration\n  - [x] Table/Dataframe API\n  - [x] SQL support with catalog except upsert\n  - [x] Query optimization\n    - [x] Shuffle/Join elimination for operations on primary key\n  - [x] Merge UDF (Merge operator)\n  - [ ] Merge Into SQL support\n    - [x] Merge Into SQL with match on Primary Key (Merge on read)\n    - [ ] Merge Into SQL with match on non-pk\n    - [ ] Merge Into SQL with match condition and complex expression (Merge on read when match on PK) (depends on [#66](https://github.com/lakesoul-io/LakeSoul/issues/66))\n* Flink Integration and CDC Ingestion ([#57](https://github.com/lakesoul-io/LakeSoul/issues/57))\n  - [x] Table API\n    - [x] Batch/Stream Sink\n    - [x] Batch/Stream source\n    - [x] Stream Source/Sink for ChangeLog Stream Semantics\n    - [x] Exactly Once Source and Sink\n  - [x] Flink CDC\n    - [x] Auto Schema Change (DDL) Sync\n    - [x] Auto Table Creation (depends on #78)\n    - [x] Support sink multiple source tables with different schemas ([#84](https://github.com/lakesoul-io/LakeSoul/issues/84))\n* Hive Integration\n  - [x] Export to Hive partition after compaction\n  - [x] Apache Kyuubi (Hive JDBC) Integration\n* Realtime Data Warehousing\n  - [x] CDC ingestion\n  - [x] Time Travel (Snapshot read)\n  - [x] Snapshot rollback\n  - [x] Automatic global compaction service\n  - [ ] MPP Engine Integration (depends on [#66](https://github.com/lakesoul-io/LakeSoul/issues/66))\n    - [x] Presto\n    - [ ] Trino\n* Cloud and Native IO ([#66](https://github.com/lakesoul-io/LakeSoul/issues/66))\n  - [x] Object storage IO optimization\n  - [x] Native merge on read\n  - [ ] Multi-layer storage classes support with data tiering\n\n# Community guidelines\n[Community guidelines](community-guideline.md)\n\n# Feedback and Contribution\nPlease feel free to open an issue or dicussion if you have any questions.\n\nJoin our [Discord](https://discord.gg/WJrHKq4BPf) server for discussions.\n\n# Contact Us\nEmail us at [lakesoul-technical-discuss@lists.lfaidata.foundation](mailto:lakesoul-technical-discuss@lists.lfaidata.foundation).\n\n# Opensource License\nLakeSoul is opensourced under Apache License v2.0.\n"
        },
        {
          "name": "community-guideline-cn.md",
          "type": "blob",
          "size": 2.3193359375,
          "content": "<!--\nSPDX-FileCopyrightText: 2023 LakeSoul Contributors\n\nSPDX-License-Identifier: Apache-2.0\n-->\n\n# 社区指引\n欢迎使用LakeSoul！在LakeSoul社区，您的任何发声都会被重视，我们希望您能够分享您使用LakeSoul产品的场景、在使用LakeSoul产品时遇到的问题，无论是功能上的需求，还是代码出现的bug都将有社区成员为您进行解决；我们也希望您能够积极地和其他成员进行交流，为社区提供源源不断地活力。欢迎每一位技术从业者参与到LakeSoul社区的治理当中（包括但不限于产品更新迭代、社区生态维护等）。为了使您更加了解、更好地参与到LakeSoul开源社区的治理中，请您阅读以下社区指引，了解LakeSoul社区的原则、使用规范以及社区组织架构，希望您能加入其中共同构建友好、包容、领先的开源社区。\n\n# 使用方式\n- 代码或教程：可以通过Code/Wiki获取\n- Bug或问题：可以通过Issues提出您遇到的任何问题\n- 反馈或建议：可以通过Discussion进行提交\n \n# 反馈/建议发布格式\n希望您能够按照以下格式进行内容发布：\n- 您所处的组织、公司或学校\n- 您所在的地区\n- 您的联系方式，包括但不限于邮箱、微信、社交网站账号等\n- 您使用/期待使用LakeSoul产品的场景\n- 您感兴趣/期待的功能点\n- 您的建议或反馈\n\n## 示例：\n    企业：你的公司名\n\n    地区：中国北京\n\n    联系方式：lakesoul-technical-discuss@lists.lfaidata.foundation\n\n    使用场景：使用LakeSoul构建实时机器学习样本库\n\n    感兴趣的功能点：Upsert；设置主键；实现历史数据大批量更新回溯\n\n    建议或反馈：完善更多功能，为用户提供更好的体验\n\n# 原则\nLakeSoul社区坚持以下原则：\n- 开放、透明：LakeSoul的产品是开源的，任何人都可以公开讨论各类技术问题。\n- 协作、包容：任何工作和问题都欢迎在LakeSoul社区进行讨论。\n- 友好、尊重：欢迎任何人使用LakeSoul的产品，尊重每一位的贡献。 \n- 行业领先：LakeSoul将提供最新的技术、让每一位技术从业者享受到数据智能的前沿红利\n点击社区角色了解更多社区组织相关信息。 \n\n点击[社区角色](community-roles-cn.md)了解更多社区组织相关信息。 \n"
        },
        {
          "name": "community-guideline.md",
          "type": "blob",
          "size": 3.1591796875,
          "content": "<!--\nSPDX-FileCopyrightText: 2023 LakeSoul Contributors\n\nSPDX-License-Identifier: Apache-2.0\n-->\n\n# Community guidelines\nWelcome to the community! In the community, any voice of users is valued. We hope you can share your scenarios of using products and the problems you encounter when using products. No matter the functional requirements, or the bugs in the code, community members will solve them for you. We hope you can actively communicate with other community members to provide a continuous energy flow. Welcome every technical practitioner to participate in the governance of the community (including but not limited to product updates and iteration and community ecological maintenance.). To better understand and participate in the management of the open source community, please read the following community guidelines to understand the principles, usage specifications, and community organization structure of the community. We hope you can join us in building a friendly, inclusive, and leading open source community.\n\n# Overview\nWe embrace open source to create a truly open ecosystem that provides a friendly atmosphere for developers. We focus on providing one-stop cloud-native data intelligent platform services for data scientists and AI practitioners, one-stop supporting services for the digital transformation and intelligent upgrading of governments and SMEs, accelerating the implementation and empowerment of AI technology to the actual business. \n\n# Usage\n- Code or tutorial: available via Code/Wiki \n- Bugs or Issues: Raise any problems you encounter via Issues \n- Feedback or Suggestions: Submit via Discussion, which is better in the format of \"Scenarios used, several feature points of most interest, and question feedback.\"\n\n# Feedback Format \nIt's better to publish your content **in the following format**: \n- Your organization, company, or school \n- Your area \n- Your contact information, including but not limited to email, wechat, social network account, etc \n- Scenarios in which you use/expect to use a telethon product \n- Feature points you are interested in/looking forward to \n- Your suggestions or feedback \n\n**Example**: \n\n    Enterprise: Your Company\n\n    Location: Beijing, China \n\n    Contact: lakesoul-technical-discuss@lists.lfaidata.foundation\n\n    Usage scenario: Use LakeSoul to build the real-time machine learning sample library \n    \n    Function points of interest: Upsert; Set primary key; Historical data batch update backtracking \n\n    Suggestions or feedback: improve more features to provide users with a better experience \n\n# Principles\nThe LakeSoul community adheres to the following principles:\n- **Open and transparent**: LakeSoul is open source, and anyone can openly discuss all kinds of technical issues. \n- **Collaboration, inclusion**: Any work or issue is welcome to be discussed in the community. \n- **Friendly and respectful**: anyone is welcome to use LakeSoul, and everyone's contribution is respected. \n- **Industry-leading**: LakeSoul will provide the latest technology so that every technical practitioner can enjoy the frontier dividend of data intelligence.\n\nClick on [Community Roles](./community-roles.md) to learn more about community organizations.\n \n"
        },
        {
          "name": "community-roles-cn.md",
          "type": "blob",
          "size": 4.376953125,
          "content": "<!--\nSPDX-FileCopyrightText: 2023 LakeSoul Contributors\n\nSPDX-License-Identifier: Apache-2.0\n-->\n\n# 社区角色\n## 使用者：\n使用者是仅使用LakeSoul但未进行贡献的技术者，但使用者仍可以在社区中发挥作用，包括但不限于：\n- 参与LakeSoul举办的活动\n- 对LakeSoul的产品进行推荐\n- 提出对产品的需求\n## 贡献者：\n贡献者是贡献代码或合并代码的技术人员。贡献者可以通过多种方式发挥作用，包括但不限于：\n- 创作或审查 PR，但无权合并\n- 提交或评论问题\n- 参与项目创新小组、社区治理委员会或社区讨论（例如技术交流群、会议、电子邮件等）\n- 内容创作者，推广LakeSoul社区\n## 技术经理：\n技术经理是有权合并代码的贡献者。技术经理负责审查贡献是否被接受，不仅要考虑代码质量，还要考虑贡献的整体影响，包括兼容性、性能和与其他领域的交互。技术经理必须是至少4个月的活跃贡献者，并且将由所有相关贡献者在项目创新小组、社区治理委员会内的投票过程中选出。第一批技术经理的任期为一年。第一年后，所有技术经理都需要通过公开选举获得资格。\n## 社区经理：\n社区经理是帮助管理LakeSoul日常治理操作的人。该角色由技术治理委员会任命，本身没有任何代码或投票相关特权。该角色没有任期限制，其持续时间仅取决于技术治理委员会批准的治理章程。\n## 合作伙伴：\n社区合作伙伴是通过以下一种或多种方式支持LakeSoul的组织（包括但不限于公司、大学、研究机构、行业协会、开源基金会/社区/项目等）：\n- 让员工或学生参与项目创新小组、社区治理委员会或技术治理委员会\n- 为LakeSoul举办研讨会或聚会\n- 为构建或托管LakeSoul资产提供资源\n-  进行媒体或公关活动以推广LakeSoul产品，\n- 支持LakeSoul的产品\n- 与LakeSoul合作进行开源开发\n# 组织架构\nLakeSoul社区的组织架构如下，所有治理、执行的计划和协调如下：\n- 技术治理委员会：由一定数量的人组成，主要任务是定义和迭代LakeSoul社区的愿景、目标、产品及治理过程。\n- 社区治理委员会：由一定数量的人组成，主要任务是维护LakeSoul社区的友好氛围、建设LakeSoul开源生态。\n- 项目创新小组：主要负责特定的项目。项目创新小组必须有公开透明的程序。欢迎任何人在遵守行为准则的前提下参与并做出贡献。项目创新小组的目的是制定一个要在一段时间内实现的目标，然后收集输入、推动共识和关闭、实施代码贡献和其他相关活动以实现目标。项目创新小组还负责对其区域内的代码进行持续维护。\n# 组织功能\n## 技术治理委员会\n- 技术治理委员会有一系列的权利和责任，包括:\n- 定义、发展和维护社区的愿景、价值观、使命和范围。\n- 定义、发展和维护行为准则，其中必须包括解决冲突的中立和公正的过程。\n- 定义和发展项目治理结构和策略，包括成员如何成为贡献者、技术经理、技术治理委员会主席等。\n- 为定义新的社区群体(特殊利益群体、工作组和任何未来可能定义的结构)制定并完善政策，并为这些群体建立透明度和问责制政策\n- 选举，决定谁是LakeSoul社区的成员以及需要什么特权\n- 决定哪些功能领域和范围是LakeSoul社区的一部分，包括项目创新小组的项目\n- 决定LakeSoul产品的官方发行方式和时间\n- 在满足质量/特性/其他需求时宣布发布\n- 定义任何认证过程。\n- 如果不能达成一致意见，则以多数票决定\n## 社区治理委员会\n- 创建粘合代码、规范、建议或实现以提交给相关项目创新小组以供批准和接受。\n- 管理LakeSoul品牌和任何对外营销 \n- 提出需要解决的确切问题及用户需求\n- 维护良好的社区生态\n## 项目创新小组\nLakeSoul社区的项目创新小组由来自多个公司和组织的个人组成，其共同目的是针对特定主题推进项目。我们的目标是实现分布式决策结构和代码所有权，并为完成工作、制定决策和加入新贡献者提供论坛。项目的每个可识别部分（例如，存储库、子目录、API、测试、问题、PR、IRC）都旨在由某个项目创新小组拥有。\n"
        },
        {
          "name": "community-roles.md",
          "type": "blob",
          "size": 5.5986328125,
          "content": "<!--\nSPDX-FileCopyrightText: 2023 LakeSoul Contributors\n\nSPDX-License-Identifier: Apache-2.0\n-->\n\n# Community Roles\n## Users: \nUsers are technology users who only use products but do not contribute, but users can still play a role in the community, including but not limited to: \n- Participates in an event hosted by LakeSoul\n- Recommend LakeSoul\n- Propose requirements for the product \n\n## Contributors: \nContributors are technical people who contribute code or combine code. Contributors can make a difference in several ways, including but not limited to: \n- Authoring or reviewing PRs, but do not have the right to merge\n- Filing or commenting on issues\n- Contributing to SIG, WG, or community discussions (e.g., IRC, meetings, email discussion forums, Stack Overflow.)\n- Content creator, promoting and advocating the community.\n\n## Technical Manager: \nThe technical manager is the contributor with authority to merge the code. The technical manager is responsible for reviewing the acceptance of contributions, not only for code quality but also for the overall impact of the contribution, including compatibility, performance, and interaction with other areas. The Technical Managers need to be active contributors for at least four months and be selected by all relevant contributors in a voting process within the Project Innovation Group and community Governance Committee. The first batch of technical managers will serve for one year. After the first year, all technical managers need to qualify through open elections. \n\n## Community Manager: \nThe community manager is the person who helps manage day-to-day governance operations. This role is appointed by the Technical Governance Board and does not have any code or voting privileges. This role has no term limit, and its duration is only subject to the governance charter approved by the Technical Governance Committee. \n\n## Partners: \nCommunity partners are organizations (including but not limited to companies, universities, research institutes, industry associations, open-source foundations/communities/projects.) that support LakeSoul in one or more of the following ways: \n- Involve staff or students in the project innovation team, community governance committee, or technology governance committee \n- Host a workshop or meetup for LakeSoul \n- Provide resources to build or host an asset\n- Promote the product by participating in the media or PR campaign\n- Lent support for products \n- Collaborate with for open source development\n\n## Organizational Structure\nThe organizational structure of the community is as follows, with all governance and execution planning and coordination as follows: \n\n- The Technical Governance Board is composed of several people whose primary task is to define and iterate on the vision, goals, products, and governance processes of the community. \n- Community Governance Committee is composed of a certain number of people whose main task is to maintain the friendly atmosphere of the community and build the open source ecology. \n- The project Innovation team is responsible for specific projects. The project innovation team must have an open and transparent process. Anyone is welcome to participate and contribute, subject to the code of conduct. The purpose of the project innovation team is to develop a goal to be achieved over some time, then collect input, drive consensus and closure, and implement code contributions and other related activities to achieve the goal. The project innovation team is also responsible for the ongoing maintenance of the code in its area. \n\n## Organization function \n### Technical Governance Committee \nA technology governance board participates in a series of rights and responsibilities, including: \n- Define, evolve, and defend the community's vision, values, mission, and scope.\n- Define, develop and uphold a code of conduct, including a neutral and impartial process for resolving conflict. \n- Define and develop the project governance structure and strategy, including how members become contributors, technical managers, chairs of a technical governance committee, and more. \n- Charter and refine policy for defining new community groups and promote transparency and accountability for those groups \n- Decide who is a member of the community and what privileges are required.\n- Decide which functional areas and areas are part of the community, including projects by the project innovation team.\n- Decide how and when product is officially released.\n- Declare releases when quality/feature/other requirements are met.\n- Static Defines any authentication process. \n- Make decisions by majority vote if consensus cannot be reached.\n\n### Community Governance Committee \nConsolidate code, specifications, recommendations, or implementations for submission to the relevant project innovation team for approval and acceptance. \nManage the brand and any external marketing \nIdentify specific problems to be solved and user needs \nMaintain good community ecology\n\n### Project Innovation Team\nThere are two project innovation groups, including LakeSoul and MetaSpore. \nThe community's project innovation team consists of individuals from multiple companies and organizations with the common purpose of advancing projects on specific topics. Our goal is to implement a distributed decision structure and code ownership and provide a forum for completing work, making decisions, and joining new contributors. Each identifiable part of the project (for example, repositories, subdirectories, APIs, tests, questions, PR, IRC) is intended to be owned by a project innovation team. \n\n## Criteria: \nAll code projects are under the Apache 2.0 license \nMust use creative Commons License Version 4.0 \n"
        },
        {
          "name": "cpp",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "javadoc",
          "type": "tree",
          "content": null
        },
        {
          "name": "lakesoul-common",
          "type": "tree",
          "content": null
        },
        {
          "name": "lakesoul-flink",
          "type": "tree",
          "content": null
        },
        {
          "name": "lakesoul-presto",
          "type": "tree",
          "content": null
        },
        {
          "name": "lakesoul-spark",
          "type": "tree",
          "content": null
        },
        {
          "name": "native-io",
          "type": "tree",
          "content": null
        },
        {
          "name": "pom.xml",
          "type": "blob",
          "size": 8.767578125,
          "content": "<!--\nSPDX-FileCopyrightText: 2023 LakeSoul Contributors\n\nSPDX-License-Identifier: Apache-2.0\n-->\n\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n    <groupId>com.dmetasoul</groupId>\n    <artifactId>lakesoul-parent</artifactId>\n    <version>${revision}</version>\n    <inceptionYear>2022</inceptionYear>\n    <modules>\n        <module>lakesoul-common</module>\n        <module>lakesoul-spark</module>\n        <module>lakesoul-flink</module>\n        <module>native-io/lakesoul-io-java</module>\n        <module>lakesoul-presto</module>\n    </modules>\n    <packaging>pom</packaging>\n    <name>LakeSoul</name>\n    <description>A Table Structure Storage to Unify Batch and Streaming Data Processing</description>\n    <url>https://github.com/lakesoul-io/LakeSoul</url>\n    <licenses>\n        <license>\n            <name>Apache 2.0 License</name>\n            <url>https://www.apache.org/licenses/LICENSE-2.0.html</url>\n            <distribution>repo</distribution>\n        </license>\n    </licenses>\n    <scm>\n        <connection>scm:git:git@github.com:lakesoul-io/LakeSoul.git</connection>\n        <url>scm:git:git@github.com:lakesoul-io/LakeSoul.git</url>\n        <tag>HEAD</tag>\n    </scm>\n    <organization>\n        <name>Linux Foundation AI &amp; Data</name>\n        <url>https://lfaidata.foundation/</url>\n    </organization>\n    <developers>\n        <developer>\n            <id>lakesoul-io</id>\n            <name>lakesoul-io</name>\n            <email>lakesoul-technical-discuss@lists.lfaidata.foundation</email>\n            <url>https://github.com/lakesoul-io</url>\n            <organization>LakeSoul, LF AI &amp; Data</organization>\n            <organizationUrl>https://github.com/lakesoul-io</organizationUrl>\n            <timezone>+8</timezone>\n        </developer>\n    </developers>\n\n    <properties>\n        <revision>2.6.0-SNAPSHOT</revision>\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n        <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>\n        <maven.compiler.encoding>UTF-8</maven.compiler.encoding>\n        <maven.compiler.source>8</maven.compiler.source>\n        <maven.compiler.target>8</maven.compiler.target>\n        <scala.binary.version>2.12</scala.binary.version>\n        <parquet.version>1.11.0</parquet.version>\n        <log4j.version>2.17.2</log4j.version>\n        <local.scope>provided</local.scope>\n        <spark.version>3.3.1</spark.version>\n        <scala.version>2.12.15</scala.version>\n        <java.version>1.8</java.version>\n    </properties>\n\n    <distributionManagement>\n        <snapshotRepository>\n            <id>ossrh</id>\n            <url>https://s01.oss.sonatype.org/content/repositories/snapshots</url>\n        </snapshotRepository>\n    </distributionManagement>\n\n    <dependencies>\n        <dependency>\n            <groupId>junit</groupId>\n            <artifactId>junit</artifactId>\n            <version>4.13.2</version>\n            <scope>test</scope>\n        </dependency>\n\n        <dependency>\n            <groupId>com.codahale.metrics</groupId>\n            <artifactId>metrics-core</artifactId>\n            <version>3.0.2</version>\n            <scope>test</scope>\n            <exclusions>\n                <exclusion>\n                    <groupId>org.slf4j</groupId>\n                    <artifactId>slf4j-api</artifactId>\n                </exclusion>\n            </exclusions>\n        </dependency>\n    </dependencies>\n\n    <profiles>\n        <profile>\n            <id>release-sign-artifacts</id>\n            <activation>\n                <property>\n                    <name>performRelease</name>\n                    <value>true</value>\n                </property>\n            </activation>\n            <build>\n                <plugins>\n                    <plugin>\n                        <groupId>org.apache.maven.plugins</groupId>\n                        <artifactId>maven-gpg-plugin</artifactId>\n                        <version>1.6</version>\n                        <executions>\n                            <execution>\n                                <id>sign-artifacts</id>\n                                <phase>verify</phase>\n                                <goals>\n                                    <goal>sign</goal>\n                                </goals>\n                                <configuration>\n                                    <gpgArguments>\n                                        <arg>--pinentry-mode</arg>\n                                        <arg>loopback</arg>\n                                    </gpgArguments>\n                                </configuration>\n                            </execution>\n                        </executions>\n                    </plugin>\n                </plugins>\n            </build>\n        </profile>\n    </profiles>\n\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-surefire-plugin</artifactId>\n                <version>3.1.0</version>\n            </plugin>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-compiler-plugin</artifactId>\n                <version>3.13.0</version>\n            </plugin>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-resources-plugin</artifactId>\n                <version>2.3</version>\n                <configuration>\n                    <encoding>UTF-8</encoding>\n                </configuration>\n            </plugin>\n            <plugin>\n                <groupId>org.sonatype.plugins</groupId>\n                <artifactId>nexus-staging-maven-plugin</artifactId>\n                <version>1.6.7</version>\n                <extensions>true</extensions>\n                <configuration>\n                    <serverId>ossrh</serverId>\n                    <nexusUrl>https://s01.oss.sonatype.org/</nexusUrl>\n                    <autoReleaseAfterClose>true</autoReleaseAfterClose>\n                    <stagingProgressTimeoutMinutes>15</stagingProgressTimeoutMinutes>\n                </configuration>\n            </plugin>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-source-plugin</artifactId>\n                <version>2.2.1</version>\n                <executions>\n                    <execution>\n                        <id>attach-sources</id>\n                        <goals>\n                            <goal>jar-no-fork</goal>\n                        </goals>\n                    </execution>\n                </executions>\n            </plugin>\n            <!-- We must generate a -javadoc JAR file to publish on Maven Central -->\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-jar-plugin</artifactId>\n                <version>3.3.0</version>\n                <executions>\n                    <execution>\n                        <id>empty-javadoc-jar</id>\n                        <phase>package</phase>\n                        <goals>\n                            <goal>jar</goal>\n                        </goals>\n                        <configuration>\n                            <classifier>javadoc</classifier>\n                            <classesDirectory>${basedir}/javadoc</classesDirectory>\n                        </configuration>\n                    </execution>\n                    <execution>\n                        <id>test-jar</id>\n                        <goals>\n                            <goal>test-jar</goal>\n                        </goals>\n                    </execution>\n                </executions>\n            </plugin>\n            <plugin>\n                <groupId>org.codehaus.mojo</groupId>\n                <artifactId>flatten-maven-plugin</artifactId>\n                <version>1.6.0</version>\n                <configuration>\n                    <flattenMode>ossrh</flattenMode>\n                </configuration>\n                <executions>\n                    <!-- enable flattening -->\n                    <execution>\n                        <id>flatten</id>\n                        <phase>process-resources</phase>\n                        <goals>\n                            <goal>flatten</goal>\n                        </goals>\n                    </execution>\n                    <!-- ensure proper cleanup -->\n                    <execution>\n                        <id>flatten.clean</id>\n                        <phase>clean</phase>\n                        <goals>\n                            <goal>clean</goal>\n                        </goals>\n                    </execution>\n                </executions>\n            </plugin>\n        </plugins>\n    </build>\n\n</project>\n"
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 2.095703125,
          "content": "# SPDX-FileCopyrightText: 2023 LakeSoul Contributors\n#\n# SPDX-License-Identifier: Apache-2.0\n\n[build-system]\nrequires = [\"setuptools >= 62.1.0\", \"wheel\", \"cython >= 0.29.31,<3\", \"grpcio[protobuf] ~= 1.57\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"lakesoul\"\nversion = \"1.0.0b2\"\nauthors = [\n  { name=\"LakeSoul Team\", email=\"lakesoul-technical-discuss@lists.lfaidata.foundation\" },\n]\ndescription = \"Python APIs for using LakeSoul\"\nreadme = \"README.md\"\nlicense = { text=\"Apache-2.0\" }\nrequires-python = \">=3.8\"\nkeywords = [\"lakesoul\", \"bigdata\", \"ai\"]\nclassifiers = [\n    \"Development Status :: 5 - Production/Stable\",\n    \"Intended Audience :: Developers\",\n    \"License :: OSI Approved :: Apache Software License\",\n    \"Operating System :: OS Independent\",\n    \"Topic :: Software Development :: Libraries :: Python Modules\",\n    \"Programming Language :: Python :: 3\",\n]\ndependencies = [\n    \"pyarrow==16.1.0\",\n    \"numpy<2.0\",\n    \"protobuf~=5.0\",\n]\n\n[project.urls]\n\"Homepage\" = \"https://github.com/lakesoul-io/LakeSoul\"\n\"Bug Tracker\" = \"https://github.com/lakesoul-io/LakeSoul/issues\"\n\n[tool.setuptools.packages.find]\nwhere = [\"python\"]\ninclude = [\"lakesoul*\"]\n\n[project.optional-dependencies]\ntorch = [\"torch>=1.11\"]\npandas = [\"pandas>=1.4\"]\ndatasets = [\"datasets>=2.14\", \"urllib3<2,>=1.21.1\"]\nray = [\"ray>=2.7\"]\nall = [\n    \"torch>=1.11\",\n    \"pandas>=1.4\",\n    \"datasets>=2.14\",\n    \"urllib3<2,>=1.21.1\",\n    \"ray>=2.7\",\n]\n\n[tool.cibuildwheel]\nmanylinux-x86_64-image = \"dmetasoul/lakesoul-python-wheel-build-env-manylinux_2_28:v1.0.0\"\nbuild = \"*-manylinux_x86_64\"\nskip = [\"cp36-*\", \"cp37-*\", \"cp311-*\", \"cp312-*\", \"pp*\"]\n\n[tool.cibuildwheel.linux]\nbefore-build = \"rm -rf {project}/cpp/build && {project}/cpp/compile.sh\"\nrepair-wheel-command = \"\"\"\\\n    auditwheel repair --plat manylinux_2_28_x86_64 \\\n                      --exclude libarrow_python.so \\\n                      --exclude libarrow_dataset.so.1601 \\\n                      --exclude libarrow_acero.so.1601 \\\n                      --exclude libparquet.so.1601 \\\n                      --exclude libarrow.so.1601 \\\n                      -w {dest_dir} {wheel}\\\n    \"\"\"\n"
        },
        {
          "name": "python",
          "type": "tree",
          "content": null
        },
        {
          "name": "rust",
          "type": "tree",
          "content": null
        },
        {
          "name": "script",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 3.8076171875,
          "content": "# SPDX-FileCopyrightText: 2023 LakeSoul Contributors\n#\n# SPDX-License-Identifier: Apache-2.0\n\nfrom setuptools import setup\nfrom setuptools import Extension\nfrom setuptools.command.build_ext import build_ext\n\nclass LakeSoulDatasetExtension(Extension):\n    def __init__(self, name):\n        super().__init__(name, sources=[])\n\nclass lakesoul_build_ext(build_ext):\n    def run(self):\n        for ext in self.extensions:\n            self._build_lakesoul(ext)\n\n    def _get_project_root_dir(self):\n        import os\n        dir_path = os.path.dirname(os.path.realpath(__file__))\n        return dir_path\n\n    def _get_lakesoul_dataset_so_path(self):\n        import os\n        key = '_LAKESOUL_DATASET_SO'\n        path = os.environ.get(key)\n        if path is not None and os.path.isfile(path):\n            return path\n        path = os.path.join(self._get_project_root_dir(), 'cpp/build/_lakesoul_dataset.so')\n        if os.path.isfile(path):\n            return path\n        message = \"'_lakesoul_dataset.so' is not specified via \"\n        message += \"environment variable %r \" % key\n        message += \"nor found at default location %r \" % path\n        raise RuntimeError(message)\n\n    def _get_lakesoul_metadata_so_path(self):\n        import os\n        key = '_LAKESOUL_METADATA_SO'\n        path = os.environ.get(key)\n        if path is not None and os.path.isfile(path):\n            return path\n        path = os.path.join(self._get_project_root_dir(), 'rust/target/release/liblakesoul_metadata_c.so')\n        if os.path.isfile(path):\n            return path\n        message = \"'liblakesoul_metadata_c.so' is not specified via \"\n        message += \"environment variable %r \" % key\n        message += \"nor found at default location %r \" % path\n        raise RuntimeError(message)\n\n    def _get_lakesoul_metadata_generated_path(self):\n        import os\n        key = '_LAKESOUL_METADATA_GENERATED'\n        path = os.environ.get(key)\n        if path is not None and os.path.isdir(path):\n            return path\n        path = os.path.join(self._get_project_root_dir(), 'cpp/build/python/lakesoul/metadata/generated')\n        if os.path.isdir(path):\n            return path\n        message = \"'generated' is not specified via \"\n        message += \"environment variable %r \" % key\n        message += \"nor found at default location %r \" % path\n        raise RuntimeError(message)\n\n    def _copy_lakesoul_metadata_files(self, metadata_dir_path):\n        import os\n        import glob\n        import shutil\n        lakesoul_metadata_so_path = self._get_lakesoul_metadata_so_path()\n        so_path = os.path.join(metadata_dir_path, 'lib', 'liblakesoul_metadata_c.so')\n        print(f'copy so cwd: {os.getcwd()} from {lakesoul_metadata_so_path} to {so_path}')\n        shutil.copy(lakesoul_metadata_so_path, so_path)\n        lakesoul_metadata_generated_path = self._get_lakesoul_metadata_generated_path()\n        glob_pattern = os.path.join(lakesoul_metadata_generated_path, '*.py')\n        for src_path in glob.glob(glob_pattern):\n            dst_path = os.path.join(metadata_dir_path, 'generated', os.path.basename(src_path))\n            print(f'copy py cwd: {os.getcwd()} from {src_path} to {dst_path}')\n            shutil.copy(src_path, dst_path)\n\n    def _build_lakesoul(self, ext):\n        import os\n        import shutil\n        lakesoul_dataset_so_path = self._get_lakesoul_dataset_so_path()\n        ext_so_path = self.get_ext_fullpath(ext.name)\n        print(f'ext copy so cwd: {os.getcwd()} from {lakesoul_dataset_so_path} to {ext_so_path}')\n        shutil.copy(lakesoul_dataset_so_path, ext_so_path)\n        metadata_dir_path = os.path.join(os.path.dirname(os.path.dirname(ext_so_path)), 'metadata')\n        self._copy_lakesoul_metadata_files(metadata_dir_path)\n\nsetup(\n    ext_modules=[LakeSoulDatasetExtension('lakesoul/arrow/_lakesoul_dataset')],\n    cmdclass={ 'build_ext': lakesoul_build_ext },\n)\n"
        },
        {
          "name": "website",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}