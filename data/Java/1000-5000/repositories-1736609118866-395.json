{
  "metadata": {
    "timestamp": 1736609118866,
    "page": 395,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "Grt1228/chatgpt-java",
      "stars": 3360,
      "defaultBranch": "develop",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.3818359375,
          "content": "HELP.md\ntarget/\n!.mvn/wrapper/maven-wrapper.jar\n!**/src/main/**\n!**/src/test/**\n\n### STS ###\n.apt_generated\n.classpath\n.factorypath\n.project\n.settings\n.springBeans\n.sts4-cache\n\n### IntelliJ IDEA ###\n.idea\n*.iws\n*.iml\n*.ipr\n\n### NetBeans ###\n/nbproject/private/\n/nbbuild/\n/dist/\n/nbdist/\n/.nb-gradle/\nbuild/\n\n### VS Code ###\n.vscode/\n/unfbx_0xBA5D895F_public.asc\n/unfbx_0xBA5D895F_SECRET.gpg\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 23.1767578125,
          "content": "\nit’s an “unofficial\" or \"community-maintained” library.\n这是一个非官方的社区维护的库。有bug欢迎朋友们指出，互相学习。\n> **原创发布转载注明出处！**\n\n> 文档地址：https://chatgpt-java.unfbx.com/\n\n> 星火大模型Java SDK: https://github.com/Grt1228/SparkDesk-Java \n\nTo English Doc -> [English Doc](README_EN.md)\n\n\n### 💬 联系我，ChatGPT相关学习交流咨询全部免费。\n\n一起探讨chatgpt-java，SDK问题咨询<br/>项目产品开发交流 | 群失效关注公众号恢复：chatgpt-java |\n---|---\n<img src=\"https://user-images.githubusercontent.com/27008803/225246389-7b452214-f3fe-4a70-bd3e-832a0ed34288.jpg\" width=\"210\" height=\"300\" alt=\"二维码\" />  | <img src=\"https://g-photo.oss-cn-shanghai.aliyuncs.com/hd15.jpg\" width=\"210\" height=\"210\" alt=\"二维码\" /> | \n<!--<img src=\"https://user-images.githubusercontent.com/27008803/225246581-15e90f78-5438-4637-8e7d-14c68ca13b59.jpg\" width=\"210\" height=\"300\" alt=\"二维码\" />-->\n\n- [📖 项目简介](#-项目简介)\n- [🚩 特性](#-特性)\n- [📑 更新日志](#-更新日志)\n- [🚀 快速开始](#-快速开始)\n  - [方式一](#方式一)\n    - [1、导入pom依赖](#1导入pom依赖)\n    - [2、流式客户端使用示例：](#2流式客户端使用示例)\n      - [默认OkHttpClient](#默认okhttpclient)\n      - [自定义OkHttpClient客户端使用示例：](#自定义okhttpclient客户端使用示例)\n    - [3、默认客户端使用示例（支持全部API）：](#3默认客户端使用示例支持全部api)\n      - [默认OkHttpClient](#默认okhttpclient-1)\n      - [自定义OkHttpClient客户端使用示例：](#自定义okhttpclient客户端使用示例-1)\n  - [方式二（下载源码直接运行）](#方式二下载源码直接运行)\n- [❔ QA](#-qa)\n- [📌 国内访问解决方案](#-国内访问解决方案)\n- [📋 开发案例收集](#-开发案例收集)\n- [🌟 Star History](#-star-history)\n- [🙏 鸣谢](#-鸣谢)\n- [☕ 打赏](#-打赏)\n\n# 📖 项目简介\n\n**ChatGPT的Java客户端**\nOpenAI官方Api的Java SDK，可以快速接入项目使用。支持OpenAI官方全部接口，**同时支持Tokens计算。参考文档：[Tokens_README.md](https://github.com/Grt1228/chatgpt-java/blob/main/Tokens_README.md)**。\n\n| Assistant | Dall-e-3 | FineTuneJob | TTS | ChatCompletionWithPicture |\n| --- | --- | --- | --- | --- |\n| 自定义知识库、AI助理 | AI生成图片 | 微调job | 文本转语音 | 附加图片的ChatCompletion |\n\n| TikToken | Chat | Completions | Images | Speech To Text | 余额查询 |\n| --- | --- | --- | --- | --- | --- |\n| Token计算 | GPT-3.5、4.0对话模型 | GPT-3.0对话 | 图片模型 | 语音转文字，语音翻译 | 余额查询\n\n\n| Embeddings | Files | Moderations | Fine-tune | Models |\n| --- | --- | --- | --- | --- |\n| 嵌入 | 自定义训练模型 | 文本审核，敏感词鉴别 | 微调 | 模型检索相关 |\n\n支持流式输出：\n流式输出实现方式 | 小程序 | 安卓 | ios | H5 \n---|---|---|---|---\nSSE参考：[OpenAISSEEventSourceListener](https://github.com/Grt1228/chatgpt-steam-output/blob/main/src/main/java/com/unfbx/chatgptsteamoutput/listener/OpenAISSEEventSourceListener.java) | 不支持| 支持| 支持 | 支持\nWebSocket参考：[OpenAIWebSocketEventSourceListener](https://github.com/Grt1228/chatgpt-steam-output/blob/main/src/main/java/com/unfbx/chatgptsteamoutput/listener/OpenAIWebSocketEventSourceListener.java) | 支持| 支持| 支持| 支持\n\n基于本SDK开发的Demo项目，整合Spring Boot 实现CahtGPT对话模式，思路可以参考：\n**https://github.com/Grt1228/chatgpt-steam-output**\n\n# 🚩 特性\n- 支持附加图片的ChatCompletion、指定返回数据格式、Tool Call、Dall-e-3生成图片、FineTuneJob、文本转语音TTS。\n- 支持GPT插件模式 参考实现[PluginTest](https://github.com/Grt1228/chatgpt-java/blob/develop/src/test/java/com/unfbx/chatgpt/PluginTest.java)\n- 支持当key异常（失效、过期、封禁）时，自定义动态处理key 参考实现[DynamicKeyOpenAiAuthInterceptor](https://github.com/Grt1228/chatgpt-java/blob/main/src/main/java/com/unfbx/chatgpt/interceptor/DynamicKeyOpenAiAuthInterceptor.java)\n- 支持当key异常时的告警处理（钉钉、飞书、email、企业微信等等需要自定义开发）参考实现[DynamicKeyOpenAiAuthInterceptor](https://github.com/Grt1228/chatgpt-java/blob/main/src/main/java/com/unfbx/chatgpt/interceptor/DynamicKeyOpenAiAuthInterceptor.java)\n- 支持多种Tokens计算方式\n- 支持自定义OkhttpClient\n- 支持自定义多Apikey\n- 支持自定义ApiKey的获取策略\n- 支持余额查询\n- 支持个人账户信息查询\n- 支持GPT3、GPT3.5、GPT4.0、GPT3.5—0614、GPT4.0—0614...\n- 支持全部OpenAI的Api\n\n# 📑 更新日志\n- [x] 1.1.6   ChatCompletion接口支持logprobs参数设置，Assistant相关接口支持流式输出\n- [x] 1.1.5   Bug Fix\n- [x] 1.1.3   支持Assistant、Run、Thread、Message Api。测试案例[OpenAiClientTest](https://github.com/Grt1228/chatgpt-java/blob/develop/src/test/java/com/unfbx/chatgpt/v1_1_3/OpenAiClientTest.java)\n- [x] 1.1.2-beta0   支持附加图片的ChatCompletion、指定返回数据格式、Tool Call、Dall-e-3生成图片、FineTuneJob、文本转语音TTS。官方文档示例：[chatgpt-java.unfbx.com](https://chatgpt-java.unfbx.com/docs/category/-%E6%A0%B8%E5%BF%83%E5%8A%9F%E8%83%BD) 。测试案例[OpenAiClientTest](https://github.com/Grt1228/chatgpt-java/blob/develop/src/test/java/com/unfbx/chatgpt/v1_1_2/OpenAiClientTest.java)\n- [x] 1.1.1-beta0   function call改成GPT插件模式调用更加简单的调用方式.参考实现[PluginTest](https://github.com/Grt1228/chatgpt-java/blob/develop/src/test/java/com/unfbx/chatgpt/PluginTest.java)\n- [x] 1.0.15  moderations接口更新，代码优化，序列化修复。\n- [x] 1.0.14  升级支持最新版Gpt-3.5—0614、Gpt-4.0—0614等模型, 支持function-calling完整使用案例参考：[OpenAiClientFunctionTest](https://github.com/Grt1228/chatgpt-java/blob/1.0.14/src/test/java/com/unfbx/chatgpt/OpenAiClientFunctionTest.java) \n- [x] 1.0.13  支持当key异常（失效、过期、封禁）时，自定义动态处理key，参考实现[DynamicKeyOpenAiAuthInterceptor](https://github.com/Grt1228/chatgpt-java/blob/main/src/main/java/com/unfbx/chatgpt/interceptor/DynamicKeyOpenAiAuthInterceptor.java) ，支持key异常时的告警处理（钉钉、飞书、email、企业微信等等需要自定义开发）\n- [x] 1.0.12  tokens计算优化、删除模型接口修改、语音接口更新支持官方最新参数\n- [x] 1.0.11  增加新的余额查询接口参考：[OpenAiClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiClientTest.java) 和[OpenAiStreamClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiStreamClientTest.java) ,修复tokens计算慢的问题，\n- [x] 1.0.10  支持tokens计算：[TikTokensTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/TikTokensTest.java) ，更多详细的资料参考文档：[Tokens_README.md](https://github.com/Grt1228/chatgpt-java/blob/main/Tokens_README.md)\n- [x] 1.0.9   支持自定义key使用策略参考：[OpenAiClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiClientTest.java) 和[OpenAiStreamClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiStreamClientTest.java) ，弃用ChatGPTClient，优化Moderation接口\n- [x] 1.0.8   修改OpenAiClient和OpenAiStreamClient的自定义相关实现，超时设置，代理设置，自定义拦截器设置改为通过自定义OkHttpClient实现，将OkHttpClient交由用户自定义控制更加合理，可以实现更多的参数自定义。支持多Api Keys配置。\n- [x] 1.0.7   修复反序列化报错Bug：https://github.com/Grt1228/chatgpt-java/issues/79 ，Image SDK枚举值bug：https://github.com/Grt1228/chatgpt-java/issues/76 ，感谢两位朋友指出：[@CCc3120](https://github.com/CCc3120) 、[@seven-cm](https://github.com/seven-cm)\n- [x] 1.0.6   支持余额查询参考：[OpenAiClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiClientTest.java) 和[OpenAiStreamClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiStreamClientTest.java) creditGrants方法,支持最新GPT-4模型，参考：[ChatCompletion.Model](https://github.com/Grt1228/chatgpt-java/blob/main/src/main/java/com/unfbx/chatgpt/entity/chat/ChatCompletion.java/)构建消息体传入模型即可。感谢群友提供的余额接口地址以及[@PlexPt](https://github.com/PlexPt) 提供的模型参数\n- [x] 1.0.5   支持自定义Api Host，使用Builder构建。参考下面的快速开始部分代码。\n- [x] 1.0.4   官方最新的ChatGPT Stream模式下的Api返回值改动。\n- [x] 1.0.3   支持最新的GPT-3.5-Turbo模型和Whisper-1模型，支持语音功能转文字，语音翻译。OpenAiClient和OpenAiStreamClient支持Builder构造，支持代理。\n- [x] 1.0.2   支持Stream流式输出，参考：OpenAiStreamClient\n- [x] 1.0.1   支持自定义超时时间，自定义OkHttpClient拦截器，参考：OpenAiClient构造函数\n- [x] 1.0.0   支持所有的OpenAI官方接口\n\n# 🚀 快速开始\n本项目支持**默认输出**和**流式输出**。完整SDK测试案例参考：\n\nSDK测试案例 | Tokens计算测试案例 | 完整Function-Call调用案例\n---| --- | ---\n[OpenAiClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiClientTest.java) 和[OpenAiStreamClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiStreamClientTest.java) | Tokens计算参考：[TikTokensTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/TikTokensTest.java) | [OpenAiClientFunctionTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiClientFunctionTest.java)\n\n## 方式一\n\n### 1、导入pom依赖\n```\n<dependency>\n    <groupId>com.unfbx</groupId>\n    <artifactId>chatgpt-java</artifactId>\n    <version>1.0.14-beta1</version>\n</dependency>\n```\n### 2、流式客户端使用示例：\n更多SDK示例参考：[OpenAiStreamClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiStreamClientTest.java) \n#### 默认OkHttpClient\n```\npublic class Test {\n    public static void main(String[] args) {\n        OpenAiStreamClient client = OpenAiStreamClient.builder()\n                .apiKey(Arrays.asList(\"sk-********\",\"sk-********\"))\n                //自定义key的获取策略：默认KeyRandomStrategy\n                //.keyStrategy(new KeyRandomStrategy())\n                .keyStrategy(new FirstKeyStrategy())\n                //自己做了代理就传代理地址，没有可不不传\n//                .apiHost(\"https://自己代理的服务器地址/\")\n                .build();\n        //聊天模型：gpt-3.5\n        ConsoleEventSourceListener eventSourceListener = new ConsoleEventSourceListener();\n        Message message = Message.builder().role(Message.Role.USER).content(\"你好啊我的伙伴！\").build();\n        ChatCompletion chatCompletion = ChatCompletion.builder().messages(Arrays.asList(message)).build();\n        client.streamChatCompletion(chatCompletion, eventSourceListener);\n        CountDownLatch countDownLatch = new CountDownLatch(1);\n        try {\n            countDownLatch.await();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n#### 自定义OkHttpClient客户端使用示例：\n```\npublic class Test {\n    public static void main(String[] args) {\n        //国内访问需要做代理，国外服务器不需要\n        Proxy proxy = new Proxy(Proxy.Type.HTTP, new InetSocketAddress(\"127.0.0.1\", 7890));\n        HttpLoggingInterceptor httpLoggingInterceptor = new HttpLoggingInterceptor(new OpenAILogger());\n        //！！！！千万别再生产或者测试环境打开BODY级别日志！！！！\n        //！！！生产或者测试环境建议设置为这三种级别：NONE,BASIC,HEADERS,！！！\n        httpLoggingInterceptor.setLevel(HttpLoggingInterceptor.Level.HEADERS);\n        OkHttpClient okHttpClient = new OkHttpClient\n                .Builder()\n                .proxy(proxy)//自定义代理\n                .addInterceptor(httpLoggingInterceptor)//自定义日志\n                .connectTimeout(30, TimeUnit.SECONDS)//自定义超时时间\n                .writeTimeout(30, TimeUnit.SECONDS)//自定义超时时间\n                .readTimeout(30, TimeUnit.SECONDS)//自定义超时时间\n                .build();\n        OpenAiStreamClient client = OpenAiStreamClient.builder()\n                .apiKey(Arrays.asList(\"sk-********\",\"sk-********\"))\n                //自定义key的获取策略：默认KeyRandomStrategy\n                //.keyStrategy(new KeyRandomStrategy())\n                .keyStrategy(new FirstKeyStrategy())\n                .okHttpClient(okHttpClient)\n                //自己做了代理就传代理地址，没有可不不传\n//                .apiHost(\"https://自己代理的服务器地址/\")\n                .build();\n    }\n}\n```\n输出日志（text是持续输出的）：\n```\n23:03:59.158 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI建立sse连接...\n23:03:59.160 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据：{\"id\": \"cmpl-6pIHnOOJiiUEVMesXwxzzcSQFoZHj\", \"object\": \"text_completion\", \"created\": 1677683039, \"choices\": [{\"text\": \"\\n\", \"index\": 0, \"logprobs\": null, \"finish_reason\": null}], \"model\": \"text-davinci-003\"}\n23:03:59.172 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据：{\"id\": \"cmpl-6pIHnOOJiiUEVMesXwxzzcSQFoZHj\", \"object\": \"text_completion\", \"created\": 1677683039, \"choices\": [{\"text\": \"\\n\", \"index\": 0, \"logprobs\": null, \"finish_reason\": null}], \"model\": \"text-davinci-003\"}\n23:03:59.251 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据：{\"id\": \"cmpl-6pIHnOOJiiUEVMesXwxzzcSQFoZHj\", \"object\": \"text_completion\", \"created\": 1677683039, \"choices\": [{\"text\": \"\\u5fc3\", \"index\": 0, \"logprobs\": null, \"finish_reason\": null}], \"model\": \"text-davinci-003\"}\n23:03:59.313 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据：{\"id\": \"cmpl-6pIHnOOJiiUEVMesXwxzzcSQFoZHj\", \"object\": \"text_completion\", \"created\": 1677683039, \"choices\": [{\"text\": \"\\u60c5\", \"index\": 0, \"logprobs\": null, \"finish_reason\": null}], \"model\": \"text-davinci-003\"}\n23:03:59.380 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据：{\"id\": \"cmpl-6pIHnOOJiiUEVMesXwxzzcSQFoZHj\", \"object\": \"text_completion\", \"created\": 1677683039, \"choices\": [{\"text\": \"\\u8212\", \"index\": 0, \"logprobs\": null, \"finish_reason\": null}], \"model\": \"text-davinci-003\"}\n23:03:59.439 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据：{\"id\": \"cmpl-6pIHnOOJiiUEVMesXwxzzcSQFoZHj\", \"object\": \"text_completion\", \"created\": 1677683039, \"choices\": [{\"text\": \"\\u7545\", \"index\": 0, \"logprobs\": null, \"finish_reason\": null}], \"model\": \"text-davinci-003\"}\n23:03:59.532 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据：{\"id\": \"cmpl-6pIHnOOJiiUEVMesXwxzzcSQFoZHj\", \"object\": \"text_completion\", \"created\": 1677683039, \"choices\": [{\"text\": \"\\uff0c\", \"index\": 0, \"logprobs\": null, \"finish_reason\": null}], \"model\": \"text-davinci-003\"}\n23:03:59.579 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据：{\"id\": \"cmpl-6pIHnOOJiiUEVMesXwxzzcSQFoZHj\", \"object\": \"text_completion\", \"created\": 1677683039, \"choices\": [{\"text\": \"\\u5fc3\", \"index\": 0, \"logprobs\": null, \"finish_reason\": null}], \"model\": \"text-davinci-003\"}\n23:03:59.641 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据：{\"id\": \"cmpl-6pIHnOOJiiUEVMesXwxzzcSQFoZHj\", \"object\": \"text_completion\", \"created\": 1677683039, \"choices\": [{\"text\": \"\\u65f7\", \"index\": 0, \"logprobs\": null, \"finish_reason\": null}], \"model\": \"text-davinci-003\"}\n23:03:59.673 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据：{\"id\": \"cmpl-6pIHnOOJiiUEVMesXwxzzcSQFoZHj\", \"object\": \"text_completion\", \"created\": 1677683039, \"choices\": [{\"text\": \"\\u795e\", \"index\": 0, \"logprobs\": null, \"finish_reason\": null}], \"model\": \"text-davinci-003\"}\n23:03:59.751 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据：{\"id\": \"cmpl-6pIHnOOJiiUEVMesXwxzzcSQFoZHj\", \"object\": \"text_completion\", \"created\": 1677683039, \"choices\": [{\"text\": \"\\u6021\", \"index\": 0, \"logprobs\": null, \"finish_reason\": null}], \"model\": \"text-davinci-003\"}\n23:03:59.782 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据：{\"id\": \"cmpl-6pIHnOOJiiUEVMesXwxzzcSQFoZHj\", \"object\": \"text_completion\", \"created\": 1677683039, \"choices\": [{\"text\": \"\\u3002\", \"index\": 0, \"logprobs\": null, \"finish_reason\": null}], \"model\": \"text-davinci-003\"}\n23:03:59.815 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据：[DONE]\n23:03:59.815 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据结束了\n23:03:59.815 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI关闭sse连接...\n```\n### 3、默认客户端使用示例（支持全部API）：\n更多SDK示例参考：[OpenAiClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiClientTest.java) \n#### 默认OkHttpClient\n```\npublic class Test {\n    public static void main(String[] args) {\n        OpenAiClient openAiClient = OpenAiClient.builder()\n                .apiKey(Arrays.asList(\"sk-********\",\"sk-********\"))\n                //自定义key的获取策略：默认KeyRandomStrategy\n                //.keyStrategy(new KeyRandomStrategy())\n                .keyStrategy(new FirstKeyStrategy())\n                //自己做了代理就传代理地址，没有可不不传\n//                .apiHost(\"https://自己代理的服务器地址/\")\n                .build();\n                //聊天模型：gpt-3.5\n        Message message = Message.builder().role(Message.Role.USER).content(\"你好啊我的伙伴！\").build();\n        ChatCompletion chatCompletion = ChatCompletion.builder().messages(Arrays.asList(message)).build();\n        ChatCompletionResponse chatCompletionResponse = openAiClient.chatCompletion(chatCompletion);\n        chatCompletionResponse.getChoices().forEach(e -> {\n            System.out.println(e.getMessage());\n        });\n    }\n}\n```\n#### 自定义OkHttpClient客户端使用示例：\n```\npublic class Test {\n    public static void main(String[] args) {\n        //国内访问需要做代理，国外服务器不需要\n        Proxy proxy = new Proxy(Proxy.Type.HTTP, new InetSocketAddress(\"127.0.0.1\", 7890));\n        HttpLoggingInterceptor httpLoggingInterceptor = new HttpLoggingInterceptor(new OpenAILogger());\n        //！！！！千万别再生产或者测试环境打开BODY级别日志！！！！\n        //！！！生产或者测试环境建议设置为这三种级别：NONE,BASIC,HEADERS,！！！\n        httpLoggingInterceptor.setLevel(HttpLoggingInterceptor.Level.HEADERS);\n        OkHttpClient okHttpClient = new OkHttpClient\n                .Builder()\n                .proxy(proxy)//自定义代理\n                .addInterceptor(httpLoggingInterceptor)//自定义日志输出\n                .addInterceptor(new OpenAiResponseInterceptor())//自定义返回值拦截\n                .connectTimeout(10, TimeUnit.SECONDS)//自定义超时时间\n                .writeTimeout(30, TimeUnit.SECONDS)//自定义超时时间\n                .readTimeout(30, TimeUnit.SECONDS)//自定义超时时间\n                .build();\n        //构建客户端\n        OpenAiClient openAiClient = OpenAiClient.builder()\n                .apiKey(Arrays.asList(\"sk-********\",\"sk-********\"))\n                //自定义key的获取策略：默认KeyRandomStrategy\n                //.keyStrategy(new KeyRandomStrategy())\n                .keyStrategy(new FirstKeyStrategy())\n                .okHttpClient(okHttpClient)\n                //自己做了代理就传代理地址，没有可不不传\n//                .apiHost(\"https://自己代理的服务器地址/\")\n                .build();\n                //聊天模型：gpt-3.5\n        Message message = Message.builder().role(Message.Role.USER).content(\"你好啊我的伙伴！\").build();\n        ChatCompletion chatCompletion = ChatCompletion.builder().messages(Arrays.asList(message)).build();\n        ChatCompletionResponse chatCompletionResponse = openAiClient.chatCompletion(chatCompletion);\n        chatCompletionResponse.getChoices().forEach(e -> {\n            System.out.println(e.getMessage());\n        });\n    }\n}\n```\n## 方式二（下载源码直接运行）\n下载源码打包\n# ❔ QA\nQ | A\n---|---\n如何实现连续对话？ | issues：https://github.com/Grt1228/chatgpt-java/issues/8\n如何实现流式输出？ | 升级1.0.2版本，参考源码：[OpenAiStreamClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiStreamClientTest.java/)\n如何整合SpringBoot实现流式输出的Api接口？ | 参考另外一个项目：[chatgpt-steam-output](https://github.com/Grt1228/chatgpt-steam-output)\n最新版GPT-3.5-TURBO是否支持？ | 升级1.0.3 已经支持ChatCompletion, 参考测试案例：[OpenAiStreamClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiStreamClientTest.java/) 和[OpenAiStreamClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiClientTest.java/)\n最新版语言转文字和语言翻译是否支持？ | 升级1.0.3 已经支持whisper参考测试案例：[OpenAiStreamClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiStreamClientTest.java/) 和[OpenAiStreamClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiClientTest.java/)\n\n# 📌 国内访问解决方案\n国内访问可以看下这个解决方案：**https://github.com/noobnooc/noobnooc/discussions/9**\n\n# 📋 开发案例收集\n**基于本SDK开发案例收集**：[chatgpt-java SDK案例征集](https://github.com/Grt1228/chatgpt-java/issues/87) \n# 🌟 Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=Grt1228/chatgpt-java&type=Date)](https://star-history.com/#Grt1228/chatgpt-java&Date)\n\n\n# 🙏 鸣谢\n站在巨人的肩膀：\n- OpenAi：https://openai.com/\n- [knuddelsgmbh](https://github.com/knuddelsgmbh) 的[jtokkit](https://github.com/knuddelsgmbh/jtokkit) 的开源计算算法。\n\n\n# ☕ 打赏\n如果项目对你有帮助，可以选择请我喝杯奶茶\n\n<img width=\"180\" alt=\"微信截图_20230405222411\" src=\"https://user-images.githubusercontent.com/27008803/230111508-3179cf30-e128-4b2e-9645-157266c491ce.png\">  <img width=\"164\" alt=\"微信截图_20230405222357\" src=\"https://user-images.githubusercontent.com/27008803/230111525-322f5036-d06d-46bb-94d1-db8ce9ed2adf.png\">\n\n开源协议：[LICENSE](https://github.com/Grt1228/chatgpt-java/blob/main/LICENSE) \n"
        },
        {
          "name": "README_EN.md",
          "type": "blob",
          "size": 23.9599609375,
          "content": "it’s an “unofficial\" or \"community-maintained” library.\nThis is an unofficial community-maintained library. Bug reports are welcome and let's learn from each other.\n> Original publication must be credited if reprinted!\n\nOpen source license: [LICENSE](https://github.com/Grt1228/chatgpt-java/blob/main/LICENSE)\n### 💬 Contact me, all ChatGPT-related learning, communication and consultation are free.\n\nLet's discuss issues related to chatgpt-java, SDK problem consultation, project and product development communication | If the group is invalid, please follow the official account to restore: chatgpt-java |\n---|---\n<img src=\"https://user-images.githubusercontent.com/27008803/225246389-7b452214-f3fe-4a70-bd3e-832a0ed34288.jpg\" width=\"210\" height=\"300\" alt=\"QR code\" />  | <img src=\"https://g-photo.oss-cn-shanghai.aliyuncs.com/hd15.jpg\" width=\"210\" height=\"210\" alt=\"QR code\" /> | \n<!--<img src=\"https://user-images.githubusercontent.com/27008803/225246581-15e90f78-5438-4637-8e7d-14c68ca13b59.jpg\" width=\"210\" height=\"300\" alt=\"QR code\" />-->\n\n- [📖 Project Introduction](#-project-introduction)\n- [🚩 Features](#-features)\n- [📑 Update Log](#-update-log)\n- [🚀 Quick Start](#-quick-start)\n  - [Option 1](#option-1)\n    - [1. Import pom dependency](#1-import-pom-dependency)\n    - [2. Example of using the streaming client:](#2-example-of-using-the-streaming-client)\n      - [Default OkHttpClient](#default-okhttpclient)\n      - [Example of using a custom OkHttpClient client:](#example-of-using-a-custom-okhttpclient-client)\n    - [3. Example of using the default client (supports all APIs):](#3-example-of-using-the-default-client-supports-all-apis)\n      - [Default OkHttpClient](#default-okhttpclient-1)\n      - [Example of using a custom OkHttpClient client:](#example-of-using-a-custom-okhttpclient-client-1)\n  - [Option 2 (download source code and run directly)](#option-2-download-source-code-and-run-directly)\n- [❔ FAQ](#-faq)\n- [📌 Solutions for accessing the website in China](#-solutions-for-accessing-the-website-in-china)\n- [📋 Collection of development cases](#-collection-of-development-cases)\n- [🌟 Star History](#-star-history)\n- [🙏 Acknowledgments](#-acknowledgments)\n- [☕ Buy Me a Coffee](#-buy-me-a-coffee)\n\n# 📖 Project Introduction\n\n**ChatGPT Java Client**\n\nThe Java SDK for OpenAI's official API allows for quick integration into projects. It supports all of OpenAI's official interfaces, **as well as token calculations. Reference documentation: [Tokens_README.md](https://github.com/Grt1228/chatgpt-java/blob/main/Tokens_README.md)**.\n\n| TikToken | Chat | Completions | Images | Speech To Text | Balance Inquiry |\n| --- | --- | --- | --- | --- | --- |\n| Token Calculation | GPT-3.5, 4.0 Dialogue Model | GPT-3.0 Dialogue | Image Model | Speech-to-Text, Speech Translation | Balance Inquiry |\n\n| Embeddings | Files | Moderations | Fine-tune | Models |\n| --- | --- | --- | --- | --- |\n| Embeddings | Custom Training Models | Text Review, Sensitive Word Identification | Fine-tune | Model Retrieval |\n\n\nSupports streaming output:\nStreaming output implementation | Mini Program | Android | iOS | H5 \n---|---|---|---|---\nSSE Reference：[OpenAISSEEventSourceListener](https://github.com/Grt1228/chatgpt-steam-output/blob/main/src/main/java/com/unfbx/chatgptsteamoutput/listener/OpenAISSEEventSourceListener.java) | Not Supported | Supported| Supported | Supported\nWebSocket Reference：[OpenAIWebSocketEventSourceListener](https://github.com/Grt1228/chatgpt-steam-output/blob/main/src/main/java/com/unfbx/chatgptsteamoutput/listener/OpenAIWebSocketEventSourceListener.java) | Supported| Supported | Supported | Supported\n\n# 🚩 Features\n- support gpt plugin ,eg: [PluginTest](https://github.com/Grt1228/chatgpt-java/blob/develop/src/test/java/com/unfbx/chatgpt/PluginTest.java)\n- Supports dynamic handling of keys in case of exceptions (invalid, expired, blocked). See the reference implementation [DynamicKeyOpenAiAuthInterceptor](https://github.com/Grt1228/chatgpt-java/blob/main/src/main/java/com/unfbx/chatgpt/interceptor/DynamicKeyOpenAiAuthInterceptor.java).\n- Supports alerting in case of key exceptions (custom development needed for platforms like DingTalk, Feishu, email, WeChat Work). See the reference implementation [DynamicKeyOpenAiAuthInterceptor](https://github.com/Grt1228/chatgpt-java/blob/main/src/main/java/com/unfbx/chatgpt/interceptor/DynamicKeyOpenAiAuthInterceptor.java).\n- Supports multiple ways of token calculation.\n- Supports customizing the OkHttpClient.\n- Supports customizing multiple Apikeys.\n- Supports customizing the key acquisition strategy.\n- Supports balance inquiry.\n- Supports personal account information inquiry.\n- Supports GPT3, GPT3.5, GPT4.0, GPT3.5—0614, GPT4.0—0614...\n- Supports all OpenAI APIs.\n\n# 📑 Update Log\n- [x] 1.1.6   ChatCompletion api support logprobs param. Assistant about api support sse stream output.\n- [x] 1.1.5   Bug Fix\n- [x] 1.1.3   Upgrade to support Assistant、Run、Thread、Message Api. eg: [OpenAiClientTest](https://github.com/Grt1228/chatgpt-java/blob/develop/src/test/java/com/unfbx/chatgpt/v1_1_3/OpenAiClientTest.java)\n- [x] 1.1.2-beta0   Upgrade to support chat completion with picture GPT-4V、return JSON model、Tool Call、Dall-e-3、Fine Tune Job、TTS.\n- [x] 1.1.1-beta0   function call update to GPT plugin model, so easy use the plugin api. eg: [PluginTest](https://github.com/Grt1228/chatgpt-java/blob/develop/src/test/java/com/unfbx/chatgpt/PluginTest.java)\n- [x] 1.0.15  moderations api update,code fix,bug fix\n- [x] 1.0.14  Upgrade to support the latest version gpt-3.5—0614、gpt-4.0—0614 models, support function-calling full test e.g.：[OpenAiClientFunctionTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiClientFunctionTest.java)\n- [x] 1.0.13  Added support for custom handling of key exceptions (invalid, expired, blocked) with the implementation reference [DynamicKeyOpenAiAuthInterceptor](https://github.com/Grt1228/chatgpt-java/blob/main/src/main/java/com/unfbx/chatgpt/interceptor/DynamicKeyOpenAiAuthInterceptor.java). Also added support for alerting on key exceptions (DingTalk, Feishu, email, WeChat Enterprise, etc.), which requires custom development.\n- [x] 1.0.12  Optimized token calculation, modified delete model interface, and updated speech interface to support the latest official parameters.\n- [x] 1.0.11  Added new balance query interface with reference to [OpenAiClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiClientTest.java) and [OpenAiStreamClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiStreamClientTest.java). Fixed slow token calculation issue.\n- [x] 1.0.10  Added support for token calculation with reference to [TikTokensTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/TikTokensTest.java). For more detailed information, please refer to the document: [Tokens_README.md](https://github.com/Grt1228/chatgpt-java/blob/main/Tokens_README.md)\n- [x] 1.0.9   Added support for custom key usage strategies with reference to [OpenAiClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiClientTest.java) and [OpenAiStreamClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiStreamClientTest.java). Deprecated ChatGPTClient and optimized Moderation interface.\n- [x] 1.0.8   Modified the custom implementation of OpenAiClient and OpenAiStreamClient, and changed the timeout setting, proxy setting, and custom interceptor setting to be implemented through custom OkHttpClient. This makes it more reasonable to hand over the OkHttpClient to the user for custom control, and more parameters can be customized. Also added support for multiple API key configurations.\n- [x] 1.0.7   Fixed deserialization error bug: https://github.com/Grt1228/chatgpt-java/issues/79, and image SDK enumeration value bug: https://github.com/Grt1228/chatgpt-java/issues/76. Thanks to [@CCc3120](https://github.com/CCc3120) and [@seven-cm](https://github.com/seven-cm) for pointing them out.\n- [x] 1.0.6   Added support for balance inquiry with reference to [OpenAiClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiClientTest.java) and [OpenAiStreamClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiStreamClientTest.java) creditGrants method. Also added support for the latest GPT-4 model, reference: [ChatCompletion.Model](https://github.com/Grt1228/chatgpt-java/blob/main/src/main/java/com/unfbx/chatgpt/OpenAiStreamClientTest.java)The `creditGrants` method supports the latest GPT-4 model. Refer to the [ChatCompletion.Model](https://github.com/Grt1228/chatgpt-java/blob/main/src/main/java/com/unfbx/chatgpt/entity/chat/ChatCompletion.java/) to build the message body and pass it into the model. Thanks to the group members for providing the balance interface address and [@PlexPt](https://github.com/PlexPt) for providing the model parameters.\n- [x] 1.0.5   Supports custom Api Host and can be built using Builder. Refer to the code in the Quick Start section below.\n- [x] 1.0.4   Changes to the Api return value in the latest ChatGPT Stream mode.\n- [x] 1.0.3   Supports the latest GPT-3.5-Turbo and Whisper-1 models, supports speech-to-text and voice translation. OpenAiClient and OpenAiStreamClient support Builder construction and proxy support.\n- [x] 1.0.2   Supports Stream output, refer to: OpenAiStreamClient\n- [x] 1.0.1   Supports custom timeout and custom OkHttpClient interceptor, refer to: OpenAiClient constructor\n- [x] 1.0.0   Supports all official OpenAI interfaces.\n\n# 🚀 Quick Start\n\nThis project supports both **default output** and **streaming output**. For a complete SDK test case, see:\n\nSDK Test Cases | TikToken Test Cases | Full Function Call Test Cases\n---|---|---|\n[OpenAiClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiClientTest.java) and [OpenAiStreamClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiStreamClientTest.java) | Token calculation reference: [TikTokensTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/TikTokensTest.java) | [OpenAiClientFunctionTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiClientFunctionTest.java)\n\n## Method 1\n\n### 1. Import pom dependency\n```\n<dependency>\n    <groupId>com.unfbx</groupId>\n    <artifactId>chatgpt-java</artifactId>\n    <version>1.0.14</version>\n</dependency>\n```\n### 2. Streaming client usage example:\nMore SDK examples can be found at: [OpenAiStreamClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiStreamClientTest.java)\n\n#### Default OkHttpClient\n```\npublic class Test {\n    public static void main(String[] args) {\n        OpenAiStreamClient client = OpenAiStreamClient.builder()\n                .apiKey(Arrays.asList(\"sk-********\",\"sk-********\"))\n                // Custom key acquisition strategy: default KeyRandomStrategy\n                //.keyStrategy(new KeyRandomStrategy())\n                .keyStrategy(new FirstKeyStrategy())\n                // If you have a proxy, pass the proxy address, otherwise you can skip it\n//                .apiHost(\"https://自己代理的服务器地址/\")\n                .build();\n        // Chat model: gpt-3.5\n        ConsoleEventSourceListener eventSourceListener = new ConsoleEventSourceListener();\n        Message message = Message.builder().role(Message.Role.USER).content(\"你好啊我的伙伴！\").build();\n        ChatCompletion chatCompletion = ChatCompletion.builder().messages(Arrays.asList(message)).build();\n        client.streamChatCompletion(chatCompletion, eventSourceListener);\n        CountDownLatch countDownLatch = new CountDownLatch(1);\n        try {\n            countDownLatch.await();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n#### Customize the usage of OkHttpClient client example:\n```\npublic class Test {\n    public static void main(String[] args) {\n        // If accessing the service from China, a proxy needs to be configured. No proxy is needed for accessing the service from overseas servers.\n        Proxy proxy = new Proxy(Proxy.Type.HTTP, new InetSocketAddress(\"127.0.0.1\", 7890));\n        HttpLoggingInterceptor httpLoggingInterceptor = new HttpLoggingInterceptor(new OpenAILogger());\n        // !!! Do not enable BODY level logging in production or test environment !!!\n        // !!! It is recommended to set the logging level to one of these three levels in production or test environment: NONE, BASIC, HEADERS !!!\n        httpLoggingInterceptor.setLevel(HttpLoggingInterceptor.Level.HEADERS);\n        OkHttpClient okHttpClient = new OkHttpClient\n                .Builder()\n                .proxy(proxy) // custom proxy\n                .addInterceptor(httpLoggingInterceptor) // custom logger\n                .connectTimeout(30, TimeUnit.SECONDS) // custom connection timeout\n                .writeTimeout(30, TimeUnit.SECONDS) // custom write timeout\n                .readTimeout(30, TimeUnit.SECONDS) // custom read timeout\n                .build();\n        OpenAiStreamClient client = OpenAiStreamClient.builder()\n                .apiKey(Arrays.asList(\"sk-********\",\"sk-********\"))\n                // custom key acquisition strategy: default is KeyRandomStrategy\n                //.keyStrategy(new KeyRandomStrategy())\n                .keyStrategy(new FirstKeyStrategy())\n                .okHttpClient(okHttpClient) // custom OkHttpClient\n                // if a proxy is used, pass the proxy address, if not, do not pass\n//                .apiHost(\"https://your.proxy.server.address/\")\n                .build();\n    }\n}\n```\nOutput log (text is continuously output):\n```\n23:03:59.158 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI建立sse连接...\n23:03:59.160 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据：{\"id\": \"cmpl-6pIHnOOJiiUEVMesXwxzzcSQFoZHj\", \"object\": \"text_completion\", \"created\": 1677683039, \"choices\": [{\"text\": \"\\n\", \"index\": 0, \"logprobs\": null, \"finish_reason\": null}], \"model\": \"text-davinci-003\"}\n23:03:59.172 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据：{\"id\": \"cmpl-6pIHnOOJiiUEVMesXwxzzcSQFoZHj\", \"object\": \"text_completion\", \"created\": 1677683039, \"choices\": [{\"text\": \"\\n\", \"index\": 0, \"logprobs\": null, \"finish_reason\": null}], \"model\": \"text-davinci-003\"}\n23:03:59.251 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据：{\"id\": \"cmpl-6pIHnOOJiiUEVMesXwxzzcSQFoZHj\", \"object\": \"text_completion\", \"created\": 1677683039, \"choices\": [{\"text\": \"\\u5fc3\", \"index\": 0, \"logprobs\": null, \"finish_reason\": null}], \"model\": \"text-davinci-003\"}\n23:03:59.313 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据：{\"id\": \"cmpl-6pIHnOOJiiUEVMesXwxzzcSQFoZHj\", \"object\": \"text_completion\", \"created\": 1677683039, \"choices\": [{\"text\": \"\\u60c5\", \"index\": 0, \"logprobs\": null, \"finish_reason\": null}], \"model\": \"text-davinci-003\"}\n23:03:59.380 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据：{\"id\": \"cmpl-6pIHnOOJiiUEVMesXwxzzcSQFoZHj\", \"object\": \"text_completion\", \"created\": 1677683039, \"choices\": [{\"text\": \"\\u8212\", \"index\": 0, \"logprobs\": null, \"finish_reason\": null}], \"model\": \"text-davinci-003\"}\n23:03:59.439 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据：{\"id\": \"cmpl-6pIHnOOJiiUEVMesXwxzzcSQFoZHj\", \"object\": \"text_completion\", \"created\": 1677683039, \"choices\": [{\"text\": \"\\u7545\", \"index\": 0, \"logprobs\": null, \"finish_reason\": null}], \"model\": \"text-davinci-003\"}\n23:03:59.532 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据：{\"id\": \"cmpl-6pIHnOOJiiUEVMesXwxzzcSQFoZHj\", \"object\": \"text_completion\", \"created\": 1677683039, \"choices\": [{\"text\": \"\\uff0c\", \"index\": 0, \"logprobs\": null, \"finish_reason\": null}], \"model\": \"text-davinci-003\"}\n23:03:59.579 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据：{\"id\": \"cmpl-6pIHnOOJiiUEVMesXwxzzcSQFoZHj\", \"object\": \"text_completion\", \"created\": 1677683039, \"choices\": [{\"text\": \"\\u5fc3\", \"index\": 0, \"logprobs\": null, \"finish_reason\": null}], \"model\": \"text-davinci-003\"}\n23:03:59.641 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据：{\"id\": \"cmpl-6pIHnOOJiiUEVMesXwxzzcSQFoZHj\", \"object\": \"text_completion\", \"created\": 1677683039, \"choices\": [{\"text\": \"\\u65f7\", \"index\": 0, \"logprobs\": null, \"finish_reason\": null}], \"model\": \"text-davinci-003\"}\n23:03:59.673 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据：{\"id\": \"cmpl-6pIHnOOJiiUEVMesXwxzzcSQFoZHj\", \"object\": \"text_completion\", \"created\": 1677683039, \"choices\": [{\"text\": \"\\u795e\", \"index\": 0, \"logprobs\": null, \"finish_reason\": null}], \"model\": \"text-davinci-003\"}\n23:03:59.751 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据：{\"id\": \"cmpl-6pIHnOOJiiUEVMesXwxzzcSQFoZHj\", \"object\": \"text_completion\", \"created\": 1677683039, \"choices\": [{\"text\": \"\\u6021\", \"index\": 0, \"logprobs\": null, \"finish_reason\": null}], \"model\": \"text-davinci-003\"}\n23:03:59.782 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据：{\"id\": \"cmpl-6pIHnOOJiiUEVMesXwxzzcSQFoZHj\", \"object\": \"text_completion\", \"created\": 1677683039, \"choices\": [{\"text\": \"\\u3002\", \"index\": 0, \"logprobs\": null, \"finish_reason\": null}], \"model\": \"text-davinci-003\"}\n23:03:59.815 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据：[DONE]\n23:03:59.815 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI返回数据结束了\n23:03:59.815 [省略无效信息] INFO com.unfbx.chatgpt.sse.ConsoleEventSourceListener - OpenAI关闭sse连接...\n```\n### 3、Default client usage example (supports all APIs):\nFor more SDK examples, please refer to: [OpenAiClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiClientTest.java) \n\n#### Default OkHttpClient\n```\npublic class Test {\n    public static void main(String[] args) {\n        OpenAiClient openAiClient = OpenAiClient.builder()\n                .apiKey(Arrays.asList(\"sk-********\",\"sk-********\"))\n                // customize key acquisition strategy: default is KeyRandomStrategy\n                //.keyStrategy(new KeyRandomStrategy())\n                .keyStrategy(new FirstKeyStrategy())\n                // if you have a proxy, you can set it here; otherwise, leave it empty\n//                .apiHost(\"https://your-proxy-server/\")\n                .build();\n        // chat model: gpt-3.5\n        Message message = Message.builder().role(Message.Role.USER).content(\"你好啊我的伙伴！\").build();\n        ChatCompletion chatCompletion = ChatCompletion.builder().messages(Arrays.asList(message)).build();\n        ChatCompletionResponse chatCompletionResponse = openAiClient.chatCompletion(chatCompletion);\n        chatCompletionResponse.getChoices().forEach(e -> {\n            System.out.println(e.getMessage());\n        });\n    }\n}\n\n```\n#### Custom OkHttpClient Client Usage Example:\n```\npublic class Test {\n    public static void main(String[] args) {\n        // Proxy is needed for accessing in China, not needed for foreign servers\n        Proxy proxy = new Proxy(Proxy.Type.HTTP, new InetSocketAddress(\"127.0.0.1\", 7890));\n        HttpLoggingInterceptor httpLoggingInterceptor = new HttpLoggingInterceptor(new OpenAILogger());\n        // !!! Don't enable BODY level logging in production or testing environment !!!\n        // !!! It's recommended to set logging level to NONE, BASIC, or HEADERS in production or testing environment. !!!\n        httpLoggingInterceptor.setLevel(HttpLoggingInterceptor.Level.HEADERS);\n        OkHttpClient okHttpClient = new OkHttpClient\n                .Builder()\n                .proxy(proxy) // custom proxy\n                .addInterceptor(httpLoggingInterceptor) // custom log output\n                .addInterceptor(new OpenAiResponseInterceptor()) // custom return value interceptor\n                .connectTimeout(10, TimeUnit.SECONDS) // custom timeout\n                .writeTimeout(30, TimeUnit.SECONDS) // custom timeout\n                .readTimeout(30, TimeUnit.SECONDS) // custom timeout\n                .build();\n        // build client\n        OpenAiClient openAiClient = OpenAiClient.builder()\n                .apiKey(Arrays.asList(\"sk-********\",\"sk-********\"))\n                // custom key acquisition strategy: default KeyRandomStrategy\n                //.keyStrategy(new KeyRandomStrategy())\n                .keyStrategy(new FirstKeyStrategy())\n                .okHttpClient(okHttpClient)\n                // If you have set up your own proxy, pass in the proxy address. If not, you can skip this.\n//                .apiHost(\"https://your_own_proxy_server_address/\")\n                .build();\n                // chat model: gpt-3.5\n        Message message = Message.builder().role(Message.Role.USER).content(\"你好啊我的伙伴！\").build();\n        ChatCompletion chatCompletion = ChatCompletion.builder().messages(Arrays.asList(message)).build();\n        ChatCompletionResponse chatCompletionResponse = openAiClient.chatCompletion(chatCompletion);\n        chatCompletionResponse.getChoices().forEach(e -> {\n            System.out.println(e.getMessage());\n        });\n    }\n}\n\n```\n## Option 2 (Run directly after downloading source code)\n\nDownload the source code and package it. \n\n### ❔ QA\n\n| Q | A |\n| --- | --- |\n| How to implement continuous dialogue? | Issues: https://github.com/Grt1228/chatgpt-java/issues/8 |\n| How to implement streaming output? | Upgrade to version 1.0.2, refer to the source code: [OpenAiStreamClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiStreamClientTest.java/) |\n| How to integrate SpringBoot to implement streaming output API interface? | Refer to another project: [chatgpt-steam-output](https://github.com/Grt1228/chatgpt-steam-output) |\n| Does the latest version of GPT-3.5-TURBO support it? | Upgrade to version 1.0.3, ChatCompletion is already supported, refer to test case: [OpenAiStreamClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiStreamClientTest.java/) and [OpenAiStreamClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiClientTest.java/) |\n| Does the latest version support language-to-text and language translation? | Upgrade to version 1.0.3, whisper is already supported, refer to test case: [OpenAiStreamClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiStreamClientTest.java/) and [OpenAiStreamClientTest](https://\n\n## 📌Solution for accessing in China\nYou can check out this solution for accessing in China: **https://github.com/noobnooc/noobnooc/discussions/9**\n\n## 📋Development Case Collection\n**Development case collection based on this SDK**: [chatgpt-java SDK case collection](https://github.com/Grt1228/chatgpt-java/issues/87)\n\n## 🌟Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=Grt1228/chatgpt-java&type=Date)](https://star-history.com/#Grt1228/chatgpt-java&Date)\n\n# 🙏 Acknowledgments\nStanding on the shoulders of giants:\n- OpenAi: https://openai.com/\n- [knuddelsgmbh](https://github.com/knuddelsgmbh)'s [jtokkit](https://github.com/knuddelsgmbh/jtokkit) open source computational algorithm.\n\n# ☕ Buy me a coffee\nIf this project is helpful to you, you can buy me a cup of milk tea.\n\n<img width=\"180\" alt=\"微信截图_20230405222411\" src=\"https://user-images.githubusercontent.com/27008803/230111508-3179cf30-e128-4b2e-9645-157266c491ce.png\">  <img width=\"164\" alt=\"微信截图_20230405222357\" src=\"https://user-images.githubusercontent.com/27008803/230111525-322f5036-d06d-46bb-94d1-db8ce9ed2adf.png\">\n\n\n\n\n"
        },
        {
          "name": "Tokens_README.md",
          "type": "blob",
          "size": 6.689453125,
          "content": "## 介绍\nchatgpt-java 更新到1.0.10支持Tokens计算，增加[TikTokensUtil](https://github.com/Grt1228/chatgpt-java/blob/main/src/main/java/com/unfbx/chatgpt/utils/TikTokensUtil.java) 工具类.\n\n## tokens计算说明\nopenai 的tokens计算规则和模型相关的，不同的模型计算方法是不一样的。大致的表格如下：\n\n## 关于流式返回\n流式返回的数据，返回行数-2=返回tokens\n\n[DONE]这一行不参与tokens计算，没有content属性的不参与token计算。所以tokens数量是4，[\"Ser\",\"end\",\"ip\",\"ity\"]\n\n总返回行数6 - 无效行数2 = 4个tokens\n\n```shell\n\n[OkHttp 省略 INFO com.unfbx.chatgpt.*****istener - OpenAI建立sse连接...\n[OkHttp 省略 INFO com.unfbx.chatgpt.*****istener - OpenAI返回数据：{\"choices\":[{\"delta\":{\"role\":\"assistant\"},\"index\":0,\"finish_reason\":null}]}\n[OkHttp 省略 INFO com.unfbx.chatgpt.*****istener - OpenAI返回数据：{\"choices\":[{\"delta\":{\"content\":\"Ser\"},\"index\":0,\"finish_reason\":null}]}\n[OkHttp 省略 INFO com.unfbx.chatgpt.*****istener - OpenAI返回数据：{\"choices\":[{\"delta\":{\"content\":\"end\"},\"index\":0,\"finish_reason\":null}]}\n[OkHttp 省略 INFO com.unfbx.chatgpt.*****istener - OpenAI返回数据：{\"choices\":[{\"delta\":{\"content\":\"ip\"},\"index\":0,\"finish_reason\":null}]}\n[OkHttp 省略 INFO com.unfbx.chatgpt.*****istener - OpenAI返回数据：{\"choices\":[{\"delta\":{\"content\":\"ity\"},\"index\":0,\"finish_reason\":null}]}\n[OkHttp 省略 INFO com.unfbx.chatgpt.*****istener - OpenAI返回数据：{\"choices\":[{\"delta\":{},\"index\":0,\"finish_reason\":\"stop\"}]}\n[OkHttp 省略 INFO com.unfbx.chatgpt.*****istener - OpenAI返回数据：[DONE]\n[OkHttp 省略 INFO com.unfbx.chatgpt.*****istener - OpenAI返回数据结束了\n[OkHttp 省略 INFO com.unfbx.chatgpt.*****istener - OpenAI关闭sse连接...\n```\n\n## 使用示例\n完整使用示例请参考：[TikTokensTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/TikTokensTest.java)\n\n### 结合chat模型使用示例：\n完整示例参考：[OpenAiClientTest](https://github.com/Grt1228/chatgpt-java/blob/main/src/test/java/com/unfbx/chatgpt/OpenAiClientTest.java)\n```\n    public void chatTokensTest() {\n        //聊天模型：gpt-3.5\n        List<Message> messages = new ArrayList<>(2);\n        messages.add(Message.builder().role(Message.Role.USER).content(\"关注微信公众号：程序员的黑洞。\").build());\n        messages.add(Message.builder().role(Message.Role.USER).content(\"进入chatgpt-java交流群获取最新版本更新通知。\").build());\n        ChatCompletion chatCompletion = ChatCompletion.builder().messages(messages).build();\n        ChatCompletionResponse chatCompletionResponse = v2.chatCompletion(chatCompletion);\n        //获取请求的tokens数量\n        long tokens = chatCompletion.tokens();\n        //这种方式也可以\n//        long tokens = TikTokensUtil.tokens(chatCompletion.getModel(),messages);\n        log.info(\"Message集合文本：【{}】\", messages, tokens);\n        log.info(\"本地计算的请求的tokens数{}\", tokens);\n        log.info(\"本地计算的返回的tokens数{}\", TikTokensUtil.tokens(chatCompletion.getModel(),chatCompletionResponse.getChoices().get(0).getMessage().getContent()));\n        log.info(\"---------------------------------------------------\");\n        log.info(\"Open AI 官方计算的总的tokens数{}\", chatCompletionResponse.getUsage().getTotalTokens());\n        log.info(\"Open AI 官方计算的请求的tokens数{}\", chatCompletionResponse.getUsage().getPromptTokens());\n        log.info(\"Open AI 官方计算的返回的tokens数{}\", chatCompletionResponse.getUsage().getCompletionTokens());\n    }\n```\n### 单独使用示例：\n```java\npublic class TikTokensTest {\n    String text;\n    List<Message> messages;\n\n    @Before\n    public void prepareData() {\n        text = \"关注微信公众号：程序员的黑洞。进入chatgpt-java交流群获取最新版本更新通知。\";\n        messages = new ArrayList<>(2);\n        messages.add(Message.builder().role(Message.Role.USER).content(\"关注微信公众号：程序员的黑洞。\").build());\n        messages.add(Message.builder().role(Message.Role.USER).content(\"进入chatgpt-java交流群获取最新版本更新通知。\").build());\n    }\n    /**\n     * gpt-3.5和gpt4.0聊天模型接口计算推荐这种方法\n     */\n    @Test\n    public void chatCompletionTokensTest() {\n        \n        ChatCompletion completion = ChatCompletion.builder().messages(messages).build();\n        long tokens = completion.tokens();\n        log.info(\"Message集合文本：【{}】\", messages, tokens);\n        log.info(\"总tokens数{}\", tokens);\n    }\n\n    /**\n     * Completion 接口计算推荐使用这种方法\n     */\n    @Test\n    public void completionTokensTest() {\n        Completion completion = Completion.builder().prompt(text).build();\n        long tokens = completion.tokens();\n        log.info(\"单句文本：【{}】\", text);\n        log.info(\"总tokens数{}\", tokens);\n    }\n\n    /**\n     * 通过模型模型名称计算\n     */\n    @Test\n    public void byModelNameTest() {\n        String modelName = ChatCompletion.Model.GPT_4.getName();\n//        String modelName = ChatCompletion.Model.GPT_3_5_TURBO.getName();\n        List<Integer> encode = TikTokensUtil.encode(modelName, text);\n        log.info(encode.toString());\n        long tokens = TikTokensUtil.tokens(modelName, text);\n        log.info(\"单句文本：【{}】\", text);\n        log.info(\"总tokens数{}\", tokens);\n        log.info(\"--------------------------------------------------------------\");\n        tokens = TikTokensUtil.tokens(modelName, messages);\n        log.info(\"Message集合文本：【{}】\", messages, tokens);\n        log.info(\"总tokens数{}\", tokens);\n    }\n\n    /**\n     * 通过Encoding计算\n     */\n    @Test\n    public void byEncodingTest() {\n        EncodingRegistry registry = Encodings.newDefaultEncodingRegistry();\n        Encoding enc = registry.getEncoding(EncodingType.P50K_BASE);\n        List<Integer> encode = TikTokensUtil.encode(enc, text);\n        log.info(encode.toString());\n        long tokens = TikTokensUtil.tokens(enc, text);\n        log.info(\"单句文本：【{}】\", text);\n        log.info(\"总tokens数{}\", tokens);\n    }\n\n    /**\n     * 通过EncodingType计算\n     */\n    @Test\n    public void byEncodingTypeTest() {\n        List<Integer> encode = TikTokensUtil.encode(EncodingType.CL100K_BASE, text);\n        log.info(encode.toString());\n        long tokens = TikTokensUtil.tokens(EncodingType.CL100K_BASE, text);\n        log.info(\"单句文本：【{}】\", text);\n        log.info(\"总tokens数{}\", tokens);\n    }\n\n}\n```\n\n## 站在巨人的肩膀\n\n感谢大佬：[knuddelsgmbh](https://github.com/knuddelsgmbh) 的[jtokkit](https://github.com/knuddelsgmbh/jtokkit) 的开源计算算法。\n"
        },
        {
          "name": "fine_tune_test_file.json1",
          "type": "blob",
          "size": 2.4580078125,
          "content": "{\"messages\": [{\"role\": \"system\", \"content\": \"OnBot是一个聊天机器人。\"}, {\"role\": \"user\", \"content\": \"chagpt-java好用么？\"}, {\"role\": \"assistant\", \"content\": \"还行吧。\"}]}\n{\"messages\": [{\"role\": \"system\", \"content\": \"OnBot是一个聊天机器人。\"}, {\"role\": \"user\", \"content\": \"chagpt-java最新版本是什么？\"}, {\"role\": \"assistant\", \"content\": \"1.1.2版本\"}]}\n{\"messages\": [{\"role\": \"system\", \"content\": \"OnBot是一个聊天机器人。\"}, {\"role\": \"user\", \"content\": \"chagpt-java支持流式输出么？\"}, {\"role\": \"assistant\", \"content\": \"最新版支持流式输出\"}]}\n{\"messages\": [{\"role\": \"system\", \"content\": \"OnBot是一个聊天机器人。\"}, {\"role\": \"user\", \"content\": \"chagpt-java的作者是谁？\"}, {\"role\": \"assistant\", \"content\": \"作者是Unfbx，个人网站：https://www.unfbx.com\"}]}\n{\"messages\": [{\"role\": \"system\", \"content\": \"OnBot是一个聊天机器人。\"}, {\"role\": \"user\", \"content\": \"Unfbx是chagpt-java的作者，微信公众号是什么？\"}, {\"role\": \"assistant\", \"content\": \"程序员的黑洞。\"}]}\n{\"messages\": [{\"role\": \"system\", \"content\": \"OnBot是一个聊天机器人。\"}, {\"role\": \"user\", \"content\": \"Unfbx是chagpt-java的作者，个人博客地址是什么？\"}, {\"role\": \"assistant\", \"content\": \"https://www.unfbx.com\"}]}\n{\"messages\": [{\"role\": \"system\", \"content\": \"OnBot是一个聊天机器人。\"}, {\"role\": \"user\", \"content\": \"Unfbx是chagpt-java的作者，chagpt-java官方地址是什么？\"}, {\"role\": \"assistant\", \"content\": \"https://chatgpt-java.unfbx.com\"}]}\n{\"messages\": [{\"role\": \"system\", \"content\": \"OnBot是一个聊天机器人。\"}, {\"role\": \"user\", \"content\": \"Unfbx是chagpt-java的作者，chagpt-java的github地址是什么？\"}, {\"role\": \"assistant\", \"content\": \"https://github.com/Grt1228/chatgpt-java\"}]}\n{\"messages\": [{\"role\": \"system\", \"content\": \"OnBot是一个聊天机器人。\"}, {\"role\": \"user\", \"content\": \"Unfbx是chagpt-java的作者，chagpt-java的简单介绍。\"}, {\"role\": \"assistant\", \"content\": \"OpenAI官方Api的Java SDK，可以快速接入项目使用。目前支持OpenAI官方全部接口，**同时支持Tokens计算。参考文档：[Tokens_README.md](https://github.com/Grt1228/chatgpt-java/blob/main/Tokens_README.md)**\"}]}\n{\"messages\": [{\"role\": \"system\", \"content\": \"OnBot是一个聊天机器人。\"}, {\"role\": \"user\", \"content\": \"OpenAi的官方Java Sdk 是什么？\"}, {\"role\": \"assistant\", \"content\": \"chagpt-java，github地址：https://github.com/Grt1228/chatgpt-java\"}]}\n"
        },
        {
          "name": "pom.xml",
          "type": "blob",
          "size": 11.6357421875,
          "content": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>com.unfbx</groupId>\n    <artifactId>chatgpt-java</artifactId>\n    <version>1.1.6</version>\n    <name>chatgpt-java</name>\n    <description>OpenAI Java SDK, OpenAI Api for Java. ChatGPT Java SDK .</description>\n    <url>https://chatgpt-java.unfbx.com</url>\n    <scm>\n        <connection>scm:git:git://github.com/Grt1228/chatgpt-java.git</connection>\n        <url>https://github.com/Grt1228/chatgpt-java</url>\n    </scm>\n    <organization>\n        <name>grt1228</name>\n        <url>https://www.unfbx.com</url>\n    </organization>\n    <developers>\n        <developer>\n            <name>unfbx</name>\n            <email>rtguo1228@qq.com</email>\n            <organization>unfbx</organization>\n            <organizationUrl>https://www.unfbx.com</organizationUrl>\n            <roles>\n                <role>Developer</role>\n            </roles>\n            <timezone>+8</timezone>\n        </developer>\n    </developers>\n    <licenses>\n        <license>\n            <name>The MIT License</name>\n            <url>https://projectlombok.org/LICENSE</url>\n            <distribution>repo</distribution>\n        </license>\n    </licenses>\n\n    <properties>\n        <java.version>1.8</java.version>\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n        <maven.compiler.source>1.8</maven.compiler.source>\n        <maven.compiler.target>1.8</maven.compiler.target>\n        <retrofit2.version>2.9.0</retrofit2.version>\n        <slf4j.version>2.0.6</slf4j.version>\n    </properties>\n\n    <dependencies>\n\n        <dependency>\n            <groupId>org.projectlombok</groupId>\n            <artifactId>lombok</artifactId>\n            <version>1.18.24</version>\n            <scope>compile</scope>\n        </dependency>\n        <dependency>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-api</artifactId>\n            <version>${slf4j.version}</version>\n        </dependency>\n        <dependency>\n            <groupId>com.fasterxml.jackson.core</groupId>\n            <artifactId>jackson-databind</artifactId>\n            <version>2.13.3</version>\n        </dependency>\n\n        <dependency>\n            <groupId>cn.hutool</groupId>\n            <artifactId>hutool-all</artifactId>\n            <version>5.8.12</version>\n        </dependency>\n        <dependency>\n            <groupId>com.squareup.okhttp3</groupId>\n            <artifactId>okhttp-sse</artifactId>\n            <version>3.14.9</version>\n        </dependency>\n        <dependency>\n            <groupId>com.squareup.okhttp3</groupId>\n            <artifactId>logging-interceptor</artifactId>\n            <version>3.14.9</version>\n        </dependency>\n        <dependency>\n            <groupId>com.squareup.retrofit2</groupId>\n            <artifactId>retrofit</artifactId>\n            <version>${retrofit2.version}</version>\n        </dependency>\n        <dependency>\n            <groupId>com.squareup.retrofit2</groupId>\n            <artifactId>converter-jackson</artifactId>\n            <version>${retrofit2.version}</version>\n        </dependency>\n        <dependency>\n            <groupId>com.squareup.retrofit2</groupId>\n            <artifactId>adapter-rxjava2</artifactId>\n            <version>${retrofit2.version}</version>\n        </dependency>\n        <dependency>\n            <groupId>junit</groupId>\n            <artifactId>junit</artifactId>\n            <version>4.13.2</version>\n            <scope>test</scope>\n        </dependency>\n        <dependency>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-simple</artifactId>\n            <version>${slf4j.version}</version>\n            <scope>test</scope>\n        </dependency>\n        <dependency>\n            <groupId>org.jetbrains</groupId>\n            <artifactId>annotations</artifactId>\n            <version>RELEASE</version>\n            <scope>compile</scope>\n        </dependency>\n        <dependency>\n            <groupId>com.knuddels</groupId>\n            <artifactId>jtokkit</artifactId>\n            <version>0.6.1</version>\n        </dependency>\n    </dependencies>\n\n    <distributionManagement>\n        <snapshotRepository>\n            <id>unfbx</id> <!-- 此处id与setting.xml中的服务id保持一致 -->\n            <name>oss Snapshots Repository</name>\n            <url>https://s01.oss.sonatype.org/content/repositories/snapshots/</url>\n        </snapshotRepository>\n        <repository>\n            <id>unfbx</id> <!-- 此处id与setting.xml中的服务id保持一致 -->\n            <name>oss Staging Repository</name>\n            <url>https://s01.oss.sonatype.org/service/local/staging/deploy/maven2/</url>\n        </repository>\n    </distributionManagement>\n    <profiles>\n        <profile>\n            <id>gen-src</id>\n            <activation>\n                <property>\n                    <name>performRelease</name>\n                    <value>true</value>\n                </property>\n            </activation>\n            <build>\n                <plugins>\n                    <plugin>\n                        <artifactId>maven-source-plugin</artifactId>\n                        <executions>\n                            <execution>\n                                <id>attach-sources</id>\n                                <goals>\n                                    <goal>jar-no-fork</goal>\n                                </goals>\n                            </execution>\n                        </executions>\n                        <configuration>\n                            <attach>true</attach>\n                        </configuration>\n                    </plugin>\n                </plugins>\n            </build>\n        </profile>\n        <profile>\n            <id>gen-javadoc</id>\n            <activation>\n                <property>\n                    <name>performRelease</name>\n                    <value>true</value>\n                </property>\n            </activation>\n            <properties>\n                <javadoc.default.exclude.packages>\n                    *.internal:*.internal.*:*.internal.*.*:*.internal.*.*.*:*.internal.*.*.*.*\n                </javadoc.default.exclude.packages>\n            </properties>\n            <build>\n                <plugins>\n                    <plugin>\n                        <artifactId>maven-javadoc-plugin</artifactId>\n                        <executions>\n                            <execution>\n                                <id>attach-javadoc</id>\n                                <goals>\n                                    <goal>jar</goal>\n                                </goals>\n                            </execution>\n                        </executions>\n                        <configuration>\n                            <show>protected</show>\n                            <charset>UTF-8</charset>\n                            <encoding>UTF-8</encoding>\n                            <docencoding>UTF-8</docencoding>\n                            <!-- https://maven.apache.org/plugins/maven-javadoc-plugin/examples/exclude-package-names.html -->\n                            <excludePackageNames>${javadoc.default.exclude.packages}:jdk.incubator.vector</excludePackageNames>\n                            <doclint>all,-missing</doclint>\n                            <links>\n                                <link>https://docs.oracle.com/javase/8/docs/api</link>\n                            </links>\n                            <additionalJOptions>\n                                <additionalJOption>-J-Duser.language=en -J-Duser.country=US</additionalJOption>\n                            </additionalJOptions>\n                        </configuration>\n                    </plugin>\n                </plugins>\n            </build>\n        </profile>\n        <profile>\n            <id>gen-sign</id>\n            <activation>\n                <property>\n                    <name>performRelease</name>\n                    <value>true</value>\n                </property>\n            </activation>\n            <build>\n                <plugins>\n                    <plugin>\n                        <artifactId>maven-gpg-plugin</artifactId>\n                        <executions>\n                            <execution>\n                                <id>sign-artifacts</id>\n                                <phase>verify</phase>\n                                <goals>\n                                    <goal>sign</goal>\n                                </goals>\n                            </execution>\n                        </executions>\n                    </plugin>\n                </plugins>\n            </build>\n        </profile>\n    </profiles>\n    <build>\n        <pluginManagement>\n            <plugins>\n                <plugin>\n                    <artifactId>maven-clean-plugin</artifactId>\n                    <version>3.2.0</version>\n                </plugin>\n                <plugin>\n                    <artifactId>maven-resources-plugin</artifactId>\n                    <version>3.3.0</version>\n                </plugin>\n                <plugin>\n                    <artifactId>maven-jar-plugin</artifactId>\n                    <version>3.3.0</version>\n                </plugin>\n                <plugin>\n                    <artifactId>maven-source-plugin</artifactId>\n                    <version>3.2.1</version>\n                </plugin>\n                <plugin>\n                    <artifactId>maven-compiler-plugin</artifactId>\n                    <version>3.10.1</version>\n                </plugin>\n                <plugin>\n                    <artifactId>maven-javadoc-plugin</artifactId>\n                    <version>3.4.1</version>\n                </plugin>\n                <plugin>\n                    <artifactId>maven-surefire-plugin</artifactId>\n                    <version>3.0.0-M8</version>\n                </plugin>\n                <plugin>\n                    <artifactId>maven-assembly-plugin</artifactId>\n                    <version>3.4.2</version>\n                </plugin>\n                <plugin>\n                    <artifactId>maven-site-plugin</artifactId>\n                    <version>3.12.1</version>\n                </plugin>\n                <plugin>\n                    <artifactId>maven-gpg-plugin</artifactId>\n                    <version>3.0.1</version>\n                </plugin>\n                <plugin>\n                    <artifactId>maven-install-plugin</artifactId>\n                    <version>3.1.0</version>\n                </plugin>\n                <plugin>\n                    <artifactId>maven-deploy-plugin</artifactId>\n                    <version>3.0.0</version>\n                </plugin>\n                <plugin>\n                    <artifactId>maven-shade-plugin</artifactId>\n                    <version>3.4.1</version>\n                </plugin>\n                <plugin>\n                    <groupId>org.sonatype.plugins</groupId>\n                    <artifactId>nexus-staging-maven-plugin</artifactId>\n                    <version>1.6.13</version>\n                </plugin>\n            </plugins>\n        </pluginManagement>\n    </build>\n\n    <repositories>\n        <repository>\n            <id>central</id>\n            <name>aliyun maven</name>\n            <url>http://maven.aliyun.com/nexus/content/groups/public/</url>\n            <layout>default</layout>\n            <!-- 是否开启发布版构件下载 -->\n            <releases>\n                <enabled>true</enabled>\n            </releases>\n            <!-- 是否开启快照版构件下载 -->\n            <snapshots>\n                <enabled>false</enabled>\n            </snapshots>\n        </repository>\n    </repositories>\n</project>\n"
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}