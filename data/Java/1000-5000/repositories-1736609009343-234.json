{
  "metadata": {
    "timestamp": 1736609009343,
    "page": 234,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "alibaba/jstorm",
      "stars": 3908,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.103515625,
          "content": "*.git\n*.project\n*.classpath\n*.prefs\n*.bat\ntarget\n/bin\n.idea\n*.iml\njstorm-local/\ndependency-reduced-pom.xml"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.119140625,
          "content": "[submodule \"jstorm-utility/rocket-mq\"]\n\tpath = jstorm-utility/rocket-mq\n\turl = https://github.com/rocketmq/rocketmq-storm\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.091796875,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 0.3984375,
          "content": "Alibaba Group has [donated JStorm project to the Apache Software Foundation](https://incubator.apache.org/ip-clearance/storm-jstorm.html) as a subproject of [Apache Storm](https://github.com/apache/storm). The improvements and features have been merged into Apache Storm. This is an archived and read-only repository which doesn't accept new issues. Please use Apache Storm instead and report issues there. \n"
        },
        {
          "name": "bin",
          "type": "tree",
          "content": null
        },
        {
          "name": "conf",
          "type": "tree",
          "content": null
        },
        {
          "name": "deploy",
          "type": "blob",
          "size": 0.6416015625,
          "content": "\r\n\r\nBuild\r\n\r\nmvn clean\r\nmvn package assembly:assembly\r\n\r\n\r\nthis will build one tar\r\n\r\n\r\n\r\n\r\nDeploy\r\n\r\n1. Deployment for nimbus or supervisor is same as storm. so please install jzmq and zmq.\r\n2. Deployment for client, \r\n2.1 please copy configuration to ~/.jstorm/storm.yaml \r\n2.2 touch $JSTORM_HOME/RELEASE\r\n3. Deployment for web ui.\r\n3.1 copy configuration to ~/.jstorm/storm.yaml\r\n3.2 downlaod tomcat 7.x\r\n3.3 Extrade tar of tomcat 7.x\r\n3.4 put jstorm-ui-0.9.1.war to Tomcat's webapps directory\r\n\r\nopen one webbrowser and go to $jstorm-ui-ip:8080/jstorm-ui-0.9.1 \r\n\r\n3.5 you also can change the default page as jstorm-ui, please google how to do it.\r\n\r\n\r\n"
        },
        {
          "name": "dev-tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "example",
          "type": "tree",
          "content": null
        },
        {
          "name": "history.md",
          "type": "blob",
          "size": 35.0068359375,
          "content": "[JStorm English introduction](http://42.121.19.155/jstorm/JStorm-introduce-en.pptx)\n[JStorm Chinese introduction](http://42.121.19.155/jstorm/JStorm-introduce.pptx)\n\n# Release 2.4.0\n## New features\n* Support exactly-once with async checkpoint via rocksdb and HDFS.\n* Introduce new window mechanism\n    1. supports tumbling window and sliding window.\n    1. supports count window, processing time window, event time window, session window.\n    2. doesn't hold all data before a window is triggered, computes on data arrival.\n* Support gray upgrade\n    1. supports per worker/component gray upgrade\n    2. supports upgrade rollback\n* Add memory/rocksdb-based KV store.\n* HBase metrics plugin is open source\n* Support multiple metrics uploaders.\n* Add api in MetricClient to register topology-level metrics\n* Support component stream metrics, i.e., stream metrics aggregated in components \n\n## Improvements\n* Support deserialize for no-arg class in kryo\n* Add getValue method in AsmMetric for quick assert so that unit tests/integration tests don't have to get metrics from \nnimbus\n\n## Bug Fix\n* Fix the bug of incorrect computation of unstopped tasks when assigning topology\n* Fix the bug that supervisor storm.yaml is always different from nimbus storm.yaml\n* Fix the bug that kryo doesn't accept conf value of literal string \"true\"/\"false\"\n* Thanks to @gohitbear @bryant1410 @oubenruing for doc fixes.\n* Thanks to @zeromem @elloray @yunfan123 @iBuddha @Glowdable @waooog for bug fixes. \n\n\n# Release 2.2.1\n\n## New features\n* Performance is improved by 200%~300%, compared to Release 2.1.1 and 0.9.8.1 in several testing scenarios, while \n120%~200% compared to Flink and 300%~400% compared to Storm.\n\t1. Restructure the batch solution\n\t2. Improve serialization and deserialization to reduce the cost of cpu and network\n\t3. Improve the cost of cpu on critical path and metrics\n\t4. Improve the strategy of netty client and netty server \n\t5. Support consume and publish of disruptor queue under batch mode\n* Introduce snapshot exactly once framework\n\t1. Compared to Trident solution, the performance of new framework is increased by several times. Besides it. \n\t2. The new framework also support \"at least once\" mode. Compared to the acker mechanism，it will reduce the cost \n\tof relative calculation in acker, and the cost of network, which will improve the performance singificantly.\n* Support JStorm on yarn。\n\t1. Currently, jstorm cluster is capable of fast deployments，and fast scale-in/scale-out. It will improve the utility of resource.\n* Re-design the solution of backpressure. Currently, the flow control is stage by stage。\n\t1. The solution is simple and effective now. The  response is much more faster when the exchange of switch on/off\n\t of backpressure. \n\t2. The performance and stability is improved significantly, compared to the original solution.\n* Introduce Window API\n\t1. Support tumbling window，sliding window\n\t2. window support two collection mode, count and duration. \n\t3. Support watermark mechanism\n* Introduce the support of Flux\n\t1. Flux is a programing framework or component which is aim to help create and deploy the topology of jstorm \n\tquickly.\n* Isolate the dependencies of jstorm and user topology by maven shade plugin to fix the conflict problem.\n* Improve Shuffle grouping solution\n\t1. Integrate shuffle， localOrShuffle and localFirst. The grouping solution will be auto adapted according to the assignment of topology.\n\t2. Introduce load aware in shuffle to ensure the load balance of downstreams.\n* Support to configure blacklist in Nimbus to exclude some problematic nodes\n* Support batch mode in trident\n* Support the push of configuration of cluster\n* Add buildTs to supervisor info and heartbeats\n* Add ext module for nimbus and supervisor to support external plugins\n* Add jstorm-elasticsearch support, thanks to @elloray for your contribution\n\n\n## Improvements\n* Restructure nimbus metrics implementation. Currently, the topology metrics runnable is event-drive.\n* Restructure topology master. Currently, the processor in TM is event-drive.\n* Add some examples to cover more scenarios\n* Disable stream metrics to reduce the cost of sending metrics to Nimbus\n* Support metrics in local mode\n* Improve the implementation of gauge by changing the instantaneous value of each minute，to the average value of some sample values in each minute.\n* Introduce an approximate histogram calculation to reduce memory usage of histogram metrics\n* Add Full GC and supervisor network related metrics \n\n\n## Bug Fix\n* Fix message disorder bug\n* Fix the bug that some connections to zookeeper are not closed by expected when encountering exception in supervisor.\n* The deactivate might be called by mistake when task init\n* The rootId might be duplicated occasionally. It will cause the unexpected message failure.\n* Fix the bug when local mode\n* Fix logwriter's bug\n* Some task metrics(RecvTps ProcessLatency) might not be aggregated correctly.\n* Fix the racing condition of AsmCounter during flushing\n\n\n# Release 2.1.1\n\n## New features\n1. 1.5~6X performance boost from worst to best scenarios compared to JStorm-2.1.0\n1. Add application-level auto-batch\n1. Add independent control channel to separate control msgs from biz msgs to guarantee high priority for control msgs\n1. Dramatic performance boost in metrics, see \"Improvements\" section\n1. Support jdk1.8\n1. Add Nimbus hook and topology hook\n1. Metrics system:\n    1. Support disable/enable metrics on the fly\n    1. Add jstorm metrics design docs, see JSTORM-METRICS.md\n1. JStorm web UI:\n    1. Add zookeeper viewer in web UI, thanks to @dingjun84\n    1. Add log search and deep log search, support both backward search and forward search\n    1. Support log file download\n1. Support changing log level on the fly\n1. Change error structure in zk, add errorLevel, errorCode and duration.\n1. Add supervisor health check\n1. Add -Dexclude.jars option to enable filtering jars manually\n\n## Improvements\n1. Metrics:\n    1. use JHistogram/JMeter instead of Histogram/Meter, change internal Clock.tick to System.currentTimeMillis to improve performance (50+% boost in Meter and 25%+ boost in Histogram)\n    1. add TupleLifeCycle metric\n    1. add supervisor metrics: total_cpu_usage, total_mem_usage, disk_usage\n    1. remove some unnecessary metrics like emitTime, etc.\n    1. Use HeapByteBuffer instead of List<Long> to transmit metric data points, reduce 60+% metrics memory usage \n    1. Change sample rate from 10% to 5% by default\n    1. Remove AsmTimer and related code\n1. Log related:\n    1. Use logback by default instead of log4j, exclude slf4j-log4j12 dependency\n    1. Use jstorm.log.dir property instead of ${jstorm.home}/logs, see jstorm.logback.xml \n    1. Change all log4j Logger's to slf4j Logger's\n    1. Set default log page size(log.page.size) in defaults.yaml to 128KB (web UI)\n    1. Change topology log structure, add ${topology.name} directory, see jstorm.logback.xml\n    1. Add timestamp in supervisor/nimbus gc log files; backup worker gc log before launching a new worker;\n    1. Set logback/log4j file encoding to UTF-8\n1. Refine backpressure stragety to avoid over-backpressure\n1. Change acker pending rotating map to single thread to improve performance\n1. Update RefreshConnections to avoid downloading assignments from zk frequently\n1. Change default memory of Supervisor to 1G (previous 512MB)\n1. Use ProcessLauncher to launch processes\n1. Add DefaultUncaughtExceptionHandler for supervisor and nimbus\n1. Change local ports to be different from 0.9.x versions (supervisor.slots.ports.base, nimbus.thrift.port, \n nimbus.deamon.logview.port, supervisor.deamon.logview.port)\n1. Change highcharts to echarts to avoid potential license violation\n1. Dependency upgrades:\n    1. Upgrade kryo to 2.23.0\n    1. Upgrade disruptor to 3.2.2\n\n## Bug fix\n1. Fix deadlock when starting workers\n1. Fix the bug that when localstate file is empty, supervisor can't start\n1. Fix kryo serialization for HeapByteBuffer in metrics\n1. Fix total memory usage calculation\n1. Fix the bug that empty worker is assigned when configured worker number is bigger than the actual number for user defined scheduler\n1. Fix UI log home directory \n1. Fix XSS security bug in web UI\n1. Don't start TopologyMetricsRunnable thread in local mode, thanks to @L-Donne\n1. Fix JSTORM-141, JSTORM-188 that TopologyMetricsRunnable consumes too much CPU\n1. Remove MaxTenuringThreshold JVM option support jdk1.8, thanks to @249550148\n1. Fix possible NPE in MkLocalShuffer\n\n## Deploy and scripts\n1. Add cleanup for core dumps\n1. Add supervisor health check in healthCheck.sh\n1. Change jstorm.py to terminate the original python process when starting nimbus/supervisor\n\n## Upgrade guide\n1. JStorm 2.1.1 is mostly compatible with 2.1.0, but it's better to restart your topologies to finish the upgrade.\n1. If you're using log4j, be cautious that we have switched default logging system to logback, if you still want to use log4j, please add \"user.defined.log4j.conf: jstorm.log4j.properties\" to your conf/storm.yaml.\n\n\n# Release 2.1.0\n\n## New features\n\n1. Totally redesign Web UI\n\t1.\tMake the UI more beautiful\n\t1.\tImprove Web UI speed much.\n\t1.\tAdd Cluster/Topology Level Summarized Metrics in recent 30 minutes.\n\t1.\tAdd DAG in the Web UI, support Uer Interaction to get key information such as emit, tuple lifecycle, tps\n1. Redesign Metrics/Monitor System\n\t1.\tNew metrics core, support sample with more metric, avoid noise, merge metrics automatically for user.\n\t1.\tNo metrics will be stored in ZK\n\t1.\tSupport metrics HA\n\t1.\tAdd more useful metrics, such as tuple lifecycle, netty metrics, disk space etc. accurately get worker memory\n\t1.\tSupport external storage plugin to store metrics.\n1. Implement Smart BackPressure \n\t1.\tSmart Backpressure, the dataflow will be more stable, avoid noise to trigger\n\t1.\tEasy to manual control Backpressure\n1. Implement TopologyMaster\n\t1.\tRedesign hearbeat mechanism, easily support 6000+ tasks\n\t1.\tCollect all task's metrics, do merge job, release Nimbus pressure.\n\t1.\tCentral Control Coordinator, issue control command\n1. Redesign ZK usage, one set of ZK support more 2000+ hardware nodes.\n\t1.\tNo dynamic data in ZK, such as heartbeat, metrics, monitor status.\n\t1.\tNimbus reduce visiting ZK frequence when serve thrift API.\n\t1.\tReduce visiting ZK frequence, merge some task level ZK node.\n\t1.\tReduce visiting ZK frequence, remove useless ZK node, such as empty taskerror node\n\t1.\tTuning ZK cache  \n\t1.  Optimize ZK reconnect mechanism\n1. Tuning Executor Batch performance\n\t1.\tAdd smart batch size setting\n\t1.\tRemove memory copy\n\t1.\tDirectly issue tuple without batch for internal channel\n\t1.\tSet the default Serialize/Deserialize method as Kryo\n1. Set the default Serialized/Deserialized method as Kryo  to improve performance.\n1. Support dynamic reload binary/configuration\n1. Tuning LocalShuffle performance, Set 3 level priority, local worker, local node, other node, add dynamic check queue status, connection status.\n1. Optimize Nimbus HA, only the highest priority nimbuses can be promoted as master \n\n## Improvement\n1. Supervisor automatically dump worker jstack/jmap, when worker's status is invalid.\n1. Supervisor can generate more ports according to memory.\n1. Supervisor can download binary more time.\n1. Support set logdir in configuration\n1. Add configuration \"nimbus.host.start.supervisor\"\n1. Add supervisor/nimbus/drpc gc log\n1. Adjust jvm parameter 1. set -Xmn 1/2 of heap memory 2. set PermSize to 1/32 and MaxPermSize 1/16 of heap memory; 3. set -Xms by \"worker.memory.min.size\"。\n1. Refine ZK error schema, when worker is dead, UI will report error\n1. Add function to zktool utility, support remove all topology znodes, support list \n1. Optimize netty client.\n1. Dynamic update connected task status by network connection, not by ZK znode.\n1. Add configuration \"topology.enable.metrics\".\n1. Classify all topology log into one directory by topologyName.\n\n## Bug fix\n1. Skip download same binary when assigment has been changed.\n1. Skip start worker when binary is invalid.\n1. Use correct configuration map in a lot of worker thread\n1. In the first step Nimbus will check topologyName or not when submit topology\n1. Support fieldGrouping for Object[]\n1. For drpc single instance under one configuration\n1. In the client topologyNameExists interface，directly use trhift api\n1. Fix failed to restart due to topology cleanup thread's competition\n1. Fix the bug that backpressure might be lost when trigger bolt was failed.\n1. Fixed the bug that DefaultMetricUploader doesn't delete metrics data in rocksdb, causing new metrics data cannot be appended.\n\n## Deploy and scripts\n1. Optimize cleandisk.sh, avoid delete useful worker log\n\n# Release 2.0.4-SNAPSHOT\n\n## New features\n1. Redesign Metric/Monitor system, new RollingWindow/Metrics/NettyMetrics, all data will send/recv through thrift\n2. Redesign Web-UI, the new Web-UI code is clear and clean\n3. Add NimbusCache Layer, using RocksDB and TimeCacheWindow\n4. Refactoring all ZK structure and ZK operation\n5. Refactoring all thrift structure\n6. Merge jstorm-client/jstorm-client-extension/jstorm-core 3 modules into jstorm－core\n7. Set the dependency version same as storm\n8. Sync apache-storm-0.10.0-beta1 all java code\n9. Switch log system to logback\n10. Upgrade thrift to apache thrift 0.9.2\n11. Performance tuning Huge topology more than 600 workers or 2000 tasks\n12. Require jdk7 or higher\n\n# Release 0.9.7.1\n\n## New Features\n1. Batch the tuples whose target task is same, before sending out（task.batch.tuple=true，task.msg.batch.size=4）.  \n2. LocalFirst grouping is updated. If all local tasks are busy, the tasks of outside nodes will be chosen as target task instead of waiting on the busy local task.\n3. Support user to reload the application config when topology is running.\n4. Support user to define the task heartbeat timeout and task cleanup timeout for topology.\n5. Update the wait strategy of disruptor queue to no-blocking mode \"TimeoutBlockingWaitStrategy\"\n6. Support user to define the timeout of discarding messages that are pending for a long time in netty buffer.  \n7. Update the message processing structure. The virtualPortDispatch and drainer thread are removed to reduce the unnecessary cost of cpu and the transmitting of tuples \n8. Add jstorm parameter \"--include-jars\" when submit topology, add these jar to classpath\n9. Nimbus or Supervisor suicide when the local ip is 127.0.0.0\n10. Add user-define-scheduler example\n11. Merge Supervisor's syncSupervisor and syncProcess\n\n## Bug Fix\n1. Improve the GC setting.\n2. Fix the bug that task heartbeat might not be updated timely in some scenarioes.  \n3. Fix the bug that the reconnection operation might be stick for a unexpected period when the connection to remote worker is shutdown and some messages are buffer in netty.   \n4. Reuse thrift client when submit topology\n5. Avoid repeatedly download binary when failed to start worker.\n\n## Changed setting\n1. Change task's heartbeat timeout to 4 minutes\n2. Set the netty client thread pool(clientScheduleService) size as 5 \n\n## Deploy and scripts\n1. Improve cleandisk.sh, avoid delete current directory and /tmp/hsperfdata_admin\n2. Add executable attribute for the script under example\n3. Add parameter to stat.sh, which can be used to start supervisor or not. This is useful under virtual \n\n# Release 0.9.7\n\n## New Features\n1. Support dynamic scale-out/scale-in of worker, spout, bolt or acker without stopping the service of topology.\n2. When enable cgroup, Support the upper limit control of cpu core usage. Default setting is 3 cpu cores.\n3. Update the mechanism of task heartbeats to make heartbeat to track the status of spout/bolt execute thread correctly.\n4. Support to add jstorm prefix info(clusterName, topologyName, ip:port, componentName, taskId, taskIndex) for worker/task log\n5. Check the heartbeat of supervisor when topology assignment to ensure no worker will be assigned into a dead supervisor\n6. Add api to query the task/worker's metric info, e.g. load status of task queue, worker cpu usage, worker mem usage...\n7. Try to re-download jars when staring worker fails several times to avoid potential corruption of jars \n8. Add Nimbus ZK cache, accelerate nimbus read zk\n9. Add thrift api getVersion, it will be used check between the client jstorm version and the server jstorm version.  \n10. Update the metrics' structure to Alimonitor\n11. Add exclude-jar parameter into jstorm.py, which avoid class conflict when submit topology\n\n## Bug Fix\n1. Fix the no response problem of supervisor process when subimtting big amout topologys in a short time\n2. When submitting two or more topologys at the same time, the later one might be failed.\n3. TickTuple does not need to be acked. Fix the incorrect count of failure message.\n4. Fix the potential incorrect assignment when use.old.assignment=true\n5. Fix failed to remove some zk nodes when kill topology \n6. Fix failed to restart topology, when nimbus do assignment job.\n7. Fix NPE when register metrics\n8. Fix failed to read ZK monitor znode through zktool\n9. Fix exception when enable classload and local mode\n10. Fix duplicate log when enable user-defined logback in local mode\n\n## Changed Setting\n1. Set Nimbus jvm memory size as 4G\n2. Set hearbeat from supervisor to nimbus timeout from 60s to 180s\n3. In order to avoid OOM, set storm.messaging.netty.max.pending as 4\n4. Set task queue size as 1024, worker's total send/receive queue size as 2048\n\n## Deploy and scripts\n1. Add rpm build spec\n2. Add deploy files of jstorm for rpm package building\n3. Enable the cleandisk cronjob every hour, reserve coredump for only one hour.\n\n# Release 0.9.6.3\n\n## New features\n1. Implement tick tuple\n2. Support logback\n3. Support to load the user defined configuration file of log4j\n4. Enable the display of user defined metrics in web UI\n5. Add \"topologyName\" parameter for \"jstorm list\" command\n6. Support the use of ip and hostname at the same for user defined schedule\n7. Support junit test for local mode\n8. Enable client command(e.g. jstorm jar) to load self-defined storm.yaml\n\n## Bug fix\n1. Add activate and deactivate api of spout, which are used in nextTuple prepare phase\n2. Update the support of multi language\n3. Check the worker's heartbeat asynchronously to speed up the lunch of worker\n4. Add the check of worker's pid to speed up the detect of dead worker\n5. Fix the high cpu load of disruptor producer when disruptor queue is full\n6. Remove the confused exception reported by disruptor queue when killing worker\n7. Fix the failure problem of \"jstorm restart\" client command\n8. Report error when user submits the jar built on a incompatible jstorm release\n9. Fix the problem that one log will printed twice when user define a configuration of log4j or logback on local mode\n10. Fix the potential exception when killing topology on local mode\n11. Forbid user to change the log level of jstorm log\n12. Add a configuration template of logback\n13. Fix the problem that process the upload of lib jar as application jar\n14. Makesure the clean of ZK node for a topology which is removed\n15. Add the information of topology name when java core dump\n16. Fix the incorrect value of -XX:MaxTenuringThreshold. Currently, the default value of jstorm is 20, but the max value in JDK8 is 15.\n17. Fix the potential reading failure of cpu core number, which may cause the supervisor slot to be set to 0\n18. Fix the \"Address family not supported by protocol family\" error on local mode\n19. Do not start logview http server on local mode\n20. Add the creation of log dir in supervisor alive checking scription\n21. Check the correctness of ip specified in configuration file before starting nimbus\n22. Check the correctness of env variable $JAVA_HOME/$JSTORM_HOME/$JSTORM_CONF_DIR before starting jstorm service\n23. Specify the log dir for rpm installation\n24. Add reading permission of /home/admin/jstorm and /home/admin/logs for all users after rpm installation\n25. Config local temporay ports when rpm installation\n26. Add noarch rpm package\n\n# Release 0.9.6.2\n1. Add option to switch between BlockingQueue and Disruptor\n2. Fix the bug which under sync netty mode, client failed to send message to server \n3. Fix the bug let web UI can dispaly 0.9.6.1 cluster\n4. Fix the bug topology can be submited without main jar but a lot of little jar\n5. Fix the bug restart command \n6. Fix the bug trident bug\n7. Add the validation of topology name, component name... Only A-Z, a-z, 0-9, '_', '-', '.' are valid now.\n8. Fix the bug close thrift client\n\n# Release 0.9.6.2-rc\n1. Improve user experience from Web UI\n1.1 Add jstack link\n1.2 Add worker log link in supervisor page\n1.3 Add Web UI log encode setting \"gbk\" or \"utf-8\"\n1.4 Show starting tasks in component page\n1.5 Show dead task's information in UI\n1.6 Fix the bug that error info can not be displayed in UI when task is restarting\n2. Add restart command, with this command, user can reload configuration, reset worker/task parallism\n3. Upgrade curator/disruptor/guava version\n4. Revert json lib to google-simple json, wrap all json operation into two utility method\n5. Add new storm submit api, supporting submit topology under java \n6. Enable launch process with backend method\n7. Set \"spout.pending.full.sleep\" default value as true\n8. Fix the bug user define sceduler not support a list of workers\n9. Add disruptor/JStormUtils junit test\n10. Enable user to configure the name of monitor name of alimonitor\n11. Add tcp option \"reuseAddress\" in netty framework\n12. Fix the bug: When spout does not implement the ICommitterTrident interface, MasterCoordinatorSpout will stick on commit phase.\n\n# Release 0.9.6.2-rc\n1. Improve user experience from Web UI\n1.1 Add jstack link\n1.2 Add worker log link in supervisor page\n1.3 Add Web UI log encode setting \"gbk\" or \"utf-8\"\n1.4 Show starting tasks in component page\n1.5 Show dead task's information in UI\n1.6 Fix the bug that error info can not be displayed in UI when task is restarting\n2. Add restart command, with this command, user can reload configuration, reset worker/task parallism\n3. Upgrade curator/disruptor/guava version\n4. Revert json lib to google-simple json, wrap all json operation into two utility method\n5. Add new storm submit api, supporting submit topology under java \n6. Enable launch process with backend method\n7. Set \"spout.pending.full.sleep\" default value as true\n8. Fix the bug user define sceduler not support a list of workers\n9. Add disruptor/JStormUtils junit test\n10. Enable user to configure the name of monitor name of alimonitor\n11. Add tcp option \"reuseAddress\" in netty framework\n12. Fix the bug: When spout does not implement the ICommitterTrident interface, MasterCoordinatorSpout will stick on commit phase.\n\n# Release 0.9.6.1\n1. Add management of multiclusters to Web UI. Added management tools for multiclusters in WebUI.\n2. Merged Trident API from storm-0.9.3\n3. Replaced gson with fastjson\n4. Refactored metric json generation code.\n5. Stored version info with $JSTORM_HOME/RELEASE.\n6. Replaced SingleThreadDisruptorQueue with MultiThreadDisruptorQueue in task deserialize thread.\n7. Fixed issues with worker count on Web UI.\n8. Fixed issues with accessing the task map with multi-threads.\n9. Fixed NullPointerException while killing worker and reading worker's hearbeat object.\n10. Netty client connect to server only in NettyClient module.\n11. Add break loop operation when netty client connection is closed\n12. Fix the bug that topology warning flag present in cluster page is not consistent with error information present in topology page\n13. Add recovery function when the data of task error information is corrupted\n14. Fix the bug that the metric data can not be uploaded onto Alimonitor when ugrading from pre-0.9.6 to 0.9.6 and executing pkill java without restart the topologying\n15. Fix the bug that zeroMq failed to receive data\n16. Add interface to easily setting worker's memory\n17. Set default value of topology.alimonitor.metrics.post to false\n18. Only start NETTY_SERVER_DECODE_TIME for netty server\n19. Keep compatible with Storm for local mode\n20. Print rootId when tuple failed\n21. In order to keep compatible with Storm, add submitTopologyWithProgressBar interface\n22. Upgrade netty version from 3.2.7 to 3.9.0\n23. Support assign topology to user-defined supervisors\n\n\n# Release 0.9.6\n1. Update UI \n  - Display the metrics information of task and worker\n  - Add warning flag when errors occur for a topology\n  - Add link from supervisor page to task page\n2. Send metrics data to Alimonitor\n3. Add metrics interface for user\n4. Add task.cleanup.timeout.sec setting to let task gently cleanup\n5. Set the worker's log name as topologyName-worker-port.log\n6. Add setting \"worker.redirect.output.file\", so worker can redirect System.out/System.err to one setting file\n7. Add storm list command\n8. Add closing channel check in netty client to avoid double close\n9. Add connecting check in netty client to avoid connecting one server twice at one time \n\n# Release 0.9.5.1\n1. Add netty sync mode\n2. Add block operation in netty async mode\n3. Replace exception with Throwable in executor layer\n4. Upgrade curator-framework version from 1.15 to 1.3.2\n5. Add more netty junit test\n6. Add log when queue is full\n\n# Release 0.9.5\n\n## Big feature:\n1. Redesign scheduler arithmetic, basing worker not task .\n\n## Bug fix\n1. Fix disruptor use too much cpu\n2. Add target NettyServer log when f1ail to send data by netty\n\n# Release 0.9.4.1\n\n## Bug fix:\n1. Improve speed between tasks who is running in one worker\n2. Fix wrong timeout seconds\n3. Add checking port when worker initialize and begin to kill old worker\n4. Move worker hearbeat thread before initializing tasks\n5. Move init netty-server before initializeing tasks \n6. Check whether tuple's rootId is duplicated\n7. Add default value into Utils.getInt\n8. Add result function in ReconnectRunnable\n9. Add operation to start Timetick\n10. Halt process when master nimbus lost ZK node\n11. Add exception catch when cgroups kill process\n12. Speed up  reconnect to netty-server\n13. Share one task hearbeat thread for all tasks\n14. Quickly haltprocess when initialization failed.\n15. Check web-ui logview page size \n\n\n\n# Release 0.9.4\n\n## Big features\n1. Add transaction programming mode\n2. Rewrite netty code, 1. use share boss/worker thread pool;2 async send batch tuples;3 single thread to do reconnect job;4 receive batch tuples\n3. Add metrics and statics\n4. Merge Alimama storm branch into this version, submit jar with -conf, -D, -lib\n\n\n## Enhancement\n1. add setting when supervisor has been shutdown, worker will shutdown automatically\n2. add LocalFristGrouping api\n3. enable cgroup for normal user\n\n\n\n## Bug fix:\n1. Setting buffer size  when upload jar\n2. Add lock between ZK watch and timer thread when refresh connection\n3. Enable nimbus monitor thread only when topology is running in cluster mode\n4. Fix exception when failed to read old assignment of ZK\n5. classloader fix when both parent and current classloader load the same class\n6. Fix log view null pointer exception\n\n# Release 0.9.3.1\n\n## Enhancement\n1. switch apache thrift7 to storm thrift7\n2. set defatult acker number is 1\n3. add \"spout.single.thread\" setting\n4. make nimbus logview port different from supervisor's\n5. web ui can list all files of log's subdir\n6. Set gc dump dir as log's dir\n\n\n# Release 0.9.3\n\n## New feature\n1. Support Aliyun Apsara/Hadoop Yarn\n\n## Enhancement\n1. Redesign Logview\n2. Kill old worker under the same port when worker is starting\n3. Add zk information/version information on UI\n4. Add nodeport information for dead task in nimbus\n5. Add interface to get values when spout doing ack\n6. Add timeout statics in bolt\n7. jstorm script return status\n8. Add logs when fail to deserialize tuple \n9. Skip sleep operation when max_pending is 1 and waiting ack\n10. Remove useless dependency\n11. Longer task timeout setting\n12. Add supervisor.use.ip setting\n13. Redirect supervisor out/err to /dev/null, redirect worker out/err to one file\n\n\n## Bug Fix\n1. Fix kryo fail to deserialize object when enable classloader\n2. Fix fail to reassign dead task when worker number is less than topology apply\n3. Set samller jvm heap memory for jstorm-client \n4. Fix fail to set topology status as active when  do rebalance operation twice at one time,\n5. Fix local mode bug under linux\n6. Fix average latency isn't accurate\n7. GC tuning.\n8. Add default kill function for AysncLoopRunnable\n \n\n\n# Release 0.9.2\n\n## New feature\n1. Support LocalCluster/LocalDrpc mode, support debugging topology under local mode\n2. Support CGroups, assigning CPU in hardware level.\n3. Support simple logview\n\n## Bug fix or enhancement\n1. Change SpoutExecutor's RotatingMap to TimeCacheMap, when putting too much timeout tuple is easy to cause deadlock in spout acker thread\n2. Tunning gc parameter, improve performance and avoid full GC\n3. Improve Topology's own gc priority, make it higher than JStorm system setting.\n4. Tuning Nimbus HA, switch nimbus faster, when occur nimbus failure.\n5. Fix bugs found by FindBugs tool.\n6. Revert Trident interface to 0.8.1, due to 0.8.1's trident interface's performance is better.\n7. Setting nimbus.task.timeout.secs as 60 to avoid nimbus doing assignment when task is under full gc.\n8. Setting default rpc framework as netty\n9. Tunning nimbus shutdown flow\n10. Tunning worker shutdown flow\n11. Add task heartbeat log\n12. Optimize Drpc/LocalDrpc source code.\n13. Move classloader to client jar.\n14  Fix classloader fail to load  anonymous class\n15. Web Ui display slave nimbus\n16. Add thrift max read buffer size\n17. Setting CPU slot base double\n18. Move Zk utility to jstorm-client-extension.jar\n19. Fix localOrShuffle null pointer\n20. Redirecting worker's System.out/System.err to file is configurable.\n21. Add new RPC frameworker JeroMq\n22. Fix Zk watcher miss problem\n23. Update sl4j 1.5.6 to 1.7.5\n24. Shutdown worker when occur exception in Smart thread\n25. Skip downloading useless topology in Supervisor\n26. Redownload the topology when failed to deserialize topology in Supervisor.\n27. Fix topology codeDir as resourceDir\n28. Catch error when normalize topology\n29. Add log when found one task is dead\n30. Add maven repository, JStorm is able to build outside of Alibaba\n31. Fix localOrShuffle null pointer exception\n32. Add statics counting for internal tuples in one worker\n33. Add thrift.close after download topology binary in Supervisor\n\n\n# Release 0.9.1\n\n## new features\n1. Application classloader. when Application jar is conflict with jstorm jar, \n   please enable application classloader.\n2. Group Quato, Different group with different resource quato.\n\n## Bug fix or enhancement\n1. Fix Rotation Map competition issue.\n2. Set default acker number as 0\n3. Set default spout/bolt number as 1\n4. Add log directory in log4j configuration file\n5. Add transaction example\n6. Fix UI showing wrong worker numbe in topology page\n7. Fix UI showing wrong latency in topology page\n8. Replace hardcode Integer convert with JStormUtils.parseInt\n9. Support string parse in Utils.getInt\n10. Remove useless dependency in pom.xml\n11. Support supervisor using IP or special hostname\n12. Add more details when no resource has been assigned to one new topology\n13. Replace normal thread with Smart thread\n14. Add gc details \n15. Code format\n16. Unify stormId and topologyId as topologyId\n17. Every nimbus will regist ip to ZK\n\n\n\n# Release 0.9.0\nIn this version, it will follow storm 0.9.0 interface, so the application running\non storm 0.9.0 can run in jstorm 0.9.0 without any change.\n\n## Stability\n1. provide nimbus HA. when the master nimbus shuts down, it will select another\n online nimbus to be the master. There is only one master nimbus online \n any time and the slave nimbuses just synchronouse the master's data.\n2. RPC through netty is stable, the sending speed is match with receiving speed. \n\n\n## Powerful scheduler\n1. Assigning resource on four dimensions:cpu, mem, disk, net\n2. Application can use old assignment.\n3. Application can use user-define resource.\n4. Task can apply extra cpu slot or memory slot.\n4. Application can force tasks run on different supervisor or the same supervisor\n\n\n# Release 0.7.1\nIn this version, it will follow storm 0.7.1 interface, so the topology running\nin storm 0.7.1 can run in jstorm without any change.\n\n## Stability\n* Assign workers in balance\n* add setting \"zmq.max.queue.msg\" for zeromq\n* communication between worker and tasks without zeromq\n* Add catch exception operation\n  * in supervisor SyncProcess/SyncSupervisor\n  * add catch exception and report_error in spout's open and bolt's prepare\n  * in all IO operation\n  * in all serialize/deserialize\n  * in all ZK operation\n  *  in topology upload/download function\n  *  during initialization zeromq\n* do assignmen/reassignment operation in one thread to avoid competition\n* redesign nimbus 's topology assign algorithm, make the logic simple much.\n* redesign supervisor's sync assignment algorithm, make the logic simple much\n* reduce zookeeper load\n  * redesign nimbus monitor logic, it will just scan tasks' hearbeat, frequency is 10s\n  * nimbus cancel watch on supervisor\n  * supervisor heartbeat frequence change to 10s\n  * supervisor syncSupervisor/syncProcess frequence change to 10s\n  * supervisor scan /$(ZKROOT)/assignment only once in one monitor loop\n  * task hearbeat change to 10s\n* create task pid file before connection zk, this is very import when zk is unstable.\n\n\n## Performance tuning\n* reduce once memory copy when deserialize tuple, improve performance huge.\n* split executor thread as two thread, one handing receive tuples, one sending tuples, improve performance much\n* redeisign sample code, it will sampling every 5 seconds, not every 20 tuple once, improve performance much\n* simplify the ack's logic, make acker more effeciency\n* Communication between worker and tasks won't use zeromq, just memory share in process\n* in worker's Drainer/virtualportdispatch thread, spout/bolt recv/send thread, \n   the thread will sleep 1 ms when there is not tuple in one loop\n* communication between worker and tasks without zeromq\n* sampling frequence change to 5s, not every 20 tuple once.\n\n## Enhancement:\n* add IFailValueSpout interface\n* Redesign sampling code, collection statics model become more common.\n  *  Add sending/recving tps statics, statics is more precise.\n* Atomatically do deactivate action when kill/rebalance topology, and the wait time is 2 * MSG_TIMEOUT\n* fix nongrouping bug, random.nextInt will generate value less than 0.\n* Sleep one setting time(default is 1 minute) after finish spout open, \n   which is used to wait other task finish initialization.\n* Add check component name when submit topology, forbidding the component \n   which name start with \"__\"\n* change the zk's node /$(ZKROOT)/storm to /$(ZKROOT)/topology\n* abstract topology check logic from generating real topology function\n* when supervisor is down and topology do rebalance, the alive task under down \n   supervisor is unavailable.\n* add close connection operation after finish download topology binary\n* automatically create all local dirtorie, such as \n   /$(LOCALDIR)/supervisor/localstate\n* when killing worker, add \"kill and sleep \" operation before \"kill -9\" operation\n* when generate real topology binary,\n  * configuration priority different.   \n      component configuration > topology configuration > system configuration\n  * skip the output stream which target component doesn't exist.\n  * skip the component whose parallism is 0.\n  * component's parallism is less than 0, throw exception.\n* skip ack/fail when inputstream setting is empty\n* add topology name to the log\n* fix ui select option error, default is 10 minutes\n* supervisor can display all worker's status"
        },
        {
          "name": "history_cn.md",
          "type": "blob",
          "size": 34.3896484375,
          "content": "[JStorm English introduction](http://42.121.19.155/jstorm/JStorm-introduce-en.pptx)\n[JStorm Chinese introduction](http://42.121.19.155/jstorm/JStorm-introduce.pptx)\n\n# Release 2.4.0\n\n## New features\n* exactly-once接口支持异步checkpoint(rocksdb+hdfs)\n* 引入重构的窗口机制\n    1. 支持滚动和滑动窗口\n    2. 支持常见窗口类型,包括:count window, processing time window, event time window, session window.\n    3. 不会在内存中憋数据,有数据到达即会触发计算\n* 支持灰度发布\n    1. 支持根据worker/component来进行灰度发布\n    2. 支持灰度发布的回滚\n* 支持基于内存/rocksdb的KV store\n* HBase metrics插件开源\n* 支持多个metrics uploader同时写异构存储\n* MetricClient支持注册汇总到topology级别的metrics\n* 支持component stream metrics, 即stream metrics在component级别的汇总 \n\n## Improvements\n* 支持kryo中没有无参构造函数类的序列化\n* 在AsmMetric中加入getValue方法,用于单测/集成测试中快速assert,而不必通过nimbus client从nimbus中获取数据\n\n## Bug Fix\n* 修复调度topology的时候unstopped task的计算错误\n* 修复supervisor中storm.yaml永远跟nimbus的storm.yaml不同,从而一直在同步的bug\n* 修复kryo配置中无法识别字符串\"true\"/\"false\"配置值的bug\n\n\n# Release 2.2.1\n\n## New features\n* 性能优化:对比2.1.1和去年的双十一版本0.9.8.1有200%~300%的提升。在高并发和低并发的多个测试场景(word count)中，是Flink性能的120%~200%，是Storm的300%~400%。\n\t1. 重构batch的实现方案\n\t2. 优化序列化和反序列过程，减少cpu和网络消耗\n\t3. 优化消息关键路径和metrics的cpu开销\n\t4. 优化网络接收和发送端的处理策略\n\t5. 增加disruptorQueue的异步batch操作\n* 加入新的snapshot exactly once(只处理一次)框架。\n\t1. 对比原有的Trident解决方案有着数倍的性能提升。同时可以减少用户在回滚的过程中的处理逻辑。\n\t2. 同时支持at least once(至少处理一次场景)。对比原有的acker机制，可以减少acker的消息处理开销，同时在高吞吐的场景中可以大量的减少acker消息占用的网络带宽。以提高任务性能。\n* 完成JStorm on yarn支持。\n\t1. 现在JStorm可以实现快速的集群部署，以及集群的扩容和缩容。有效的提高集群资源的弹性和利用率。\n* 重构backpressure设计，支持stage by stage的流控模式。\n\t1. 当前的设计更加轻量，让backpressure在流控开启和关闭时更加高效。\n\t2. 性能和稳定性对比原因的方案有着很大的提升。\n* 引入Window API。\n\t1. 支持tumbling window，sliding window\n\t2. 对应的window支持count和duration 模式\n\t3. 支持window的watermark机制\n* 引入对Flux的支持\n\t1. Flux是帮助创建和部署storm拓扑的编程框架及通用组件。帮助用户更方便创建及部署JStorm流式计算拓扑的编程框架\n* 通过maven shade的方式，对一些容易冲突的依赖包做shade。以解决jstorm依赖和用户依赖之前的冲突问题。\n* 优化Shuffle grouping方案\n\t1. 合并shuffle， localOrShuffle和localFirst。根据任务情况自动适配。\n\t2. shuffle时会根据下游节点的负载情况，做shuffle。以达到负载均衡。\n* 增加Nimbus的黑名单机制。\n* 增加Trident对消息batch模式的支持\n* 支持集群的全局配置推送\n* supervisor info和心跳中增加了buildTs，便于区分出集群中是否存在不同版本的supervisor\n* nimbus和supervisor通过ext模块来支持外部插件\n* 添加elastic search 5.11的支持, 感谢 @elloray 的PR\n\n## Improvements\n* 重构nimbus metrics 框架，将原TopologyMetricsRunnable打散成事件驱动\n* 重构Topology master的处理逻辑。改为事件驱动。提高Topology的处理性能。\n* 重构example 代码， 增加大量example和测试用例\n* 默认禁用stream metrics以及其他特定metrics，以减少发送的数据量\n* 本地模式下启用metrics\n* gauge的实现，由每分钟单值，改为每分钟采样多次计算平均值\n* 引入了一种近似计算的方式来计算histogram的值，以减少内存开销\n* 增加了Full GC以及supervisor中网络相关的metrics\n\n## Bug Fix\n* Fix 消息的乱序问题\n* Fix supervisor上有大量的zookeeper连接的问题\n* Fix task初始化时，deactivate的错误调用\n* Fix spout并发高时，少量消息rootid重复，导致消息失败的问题。\n* Fix 本地模式的一些bug\n* Fix logwriter的bug\n* 修复了task metrics中RecvTps, ProcessLatency没有合并到task的bug\n* 修复了AsmCounter在flush时的线程同步问题\n\n\n# Release 2.1.1\n\n## New features\n* 相比2.1.0有1.5～6倍的性能提升\n* 添加了应用层的自动batch\n* 增加了独立的控制消息通道，将控制消息与业务消息分开，保证控制消息有较高的优先级被处理\n* 支持jdk1.8\n* 添加了nimbus hook和topology hook\n* Metrics系统:\n    * 支持动态开关特定的metrics\n    * 添加了metrics的设计文档，见JSTORM-METRICS.md\n* JStorm web UI相关:\n    * 添加了zk节点的查看功能，感谢@dingjun84的PR\n    * 添加了普通日志搜索以及topology日志搜索功能，支持正向和反向搜索\n    * 支持日志的下载\n* 支持动态修改日志级别\n* 修改了zk中ErrorInfo的结构，增加了errorLevel, errorCode和duration\n* 增加了supervisor的健康检查\n* 增加了-Dexclude.jars选项以手动排除特定的jar包\n\n## Improvements\n* Metrics相关：\n    * 使用JHistogram/JMeter代替codahale的Histogram/Meter, 把内部的Clock.tick改为System.currentTimeMillis，Meter和Histogram分别有50%和25%+的性能提升\n    * 添加了TupleLifeCycle指标，用于统计消息从当前component发出来到下一个component被处理的总耗时\n    * 添加了supervisor的指标: total_cpu_usage, total_mem_usage, disk_usage\n    * 删除了一些不必要的指标，如emitTime等\n    * 使用HeapByteBuffer代替List<Long>来发送histogram中的点数据，节省60+%的metrics内存使用 \n    * 将metrics采样率从10%调为5%\n    * 删除AsmTimer及相关代码\n* 日志相关：\n    * 默认不再使用log4j，而是使用logback，除非slf4j-log4j12依赖\n    * 使用jstorm.log.dir配置取代原来的${jstorm.home}/logs, 详见jstorm.logback.xml \n    * 将logback/log4j中日志文件的默认编码改为UTF-8\n    * 修改日志目录结构，添加了${topology.name}目录, 详见jstorm.logback.xml\n    * 将代码中所有log4j的Logger改为slf4j的Logger\n    * 将defaults.yaml中默认的日志page size(log.page.size)由32K调整为128K\n    * 将supervisor/nimbus的gc日志文件加上时间戳，防止重启后被覆盖; 重启worker前备份worker之前的gc日志\n* 优化反压策略，防止过度反压\n* 将acker中的pending map改为单线程，以提高性能\n* 修改RefreshConnections逻辑，防止频繁地从zk中下载assignments\n* 将Supervisor的默认内存由512MB调到1GB\n* 统一使用ProcessLauncher来起进程\n* 为supervisor和nimbus添加DefaultUncaughtExceptionHandler\n* 与0.9.x系列错开端口配置，见supervisor.slots.ports.base, nimbus.thrift.port, nimbus.deamon.logview.port, supervisor.deamon.logview.port配置\n* 将web UI的前端库highcharts改为echarts，防止潜在的版权冲突\n* 依赖升级\n    * 升级kryo至2.23.0\n    * 升级disruptor至3.2.2\n\n## Bug fix\n* 修复了起worker时可能的死锁\n* 修复了当localstate文件为空时，supervisor无法启动的问题\n* 修复了开启kryo时metrics中HeapByteBuffer无法被注册的bug\n* 修复了内存使用率计算不准确的bug\n* 修复了当用户自定义调度中分配的worker大于真实worker数时会创建空worker的bug\n* 修复web UI的日志目录设置错误的问题 \n* 修复了web UI中的XSS bug\n* 在local mode的时候，TopologyMetricsRunnable线程不运行，感谢@L-Donne的PR\n* 修复JSTORM-141, JSTORM-188：TopologyMetricsRunnable消耗CPU过多的bug\n* 删除MaxTenuringThreshold JVM参数\n* 修复MkLocalShuffer中outTasks可能为null的bug\n\n## Deploy and scripts\n* 增加了对core dump文件的清理\n* 增加了supervisor的健康检测，见healthCheck.sh\n* 修改了jstorm.py，起进程后结束父python进程\n\n## 升级指南\n* JStorm2.1.1基本与JStorm2.1.0保持兼容，但是为了保险起见，建议重启topology\n* 如果你的topology原先使用log4j，请在你的conf或者storm.yaml中加入\"user.defined.log4j.conf: jstorm.log4j.properties\"配置，以保证JStorm框架使用log4j\n* 如果你使用slf4j-api + log4j，请在你的应用中添加slf4j-log4j12的依赖\n\n\n# Release 2.1.0\n\n## New features\n* 完全重构web ui\n\t*\t 大量美化界面\n\t*\t 大幅提高web ui展示速度\n\t*\t 增加topology和集群基本的最近30分钟的汇总信息\n\t*\t 增加拓扑图， 并增加一些交互功能来直观获取拓扑的一些关键信息(例如emit， tuple lifecycle time， tps)\n* 重构采样系统, 全新采样引擎和监控系统\n\t*\t 新采样不再存储数据到zk\n\t*\t 底层采样引擎更新， 支持抗噪处理, 合并计算更加方便\n\t*\t 支持metrics的高可用\n\t*\t 增加tuple生命周期, netty，disk空间 采样， worker内存采样更准确\n\t*\t 支持外接数据库插件存储监控数据\n* 实现智能反压(backpressure) 功能\n\t*\t 自动进行限流控制\n\t*\t 可以手动人工干预限流控制状态\n* 实现中央控制单元TopologyMaster\n\t*\t 重构心跳检查机制， 支持6000+ task\n\t*\t 收集所有metrics，并做合并计算\n\t*\t 中央控制流协调器\n\t*\t HA 状态存储\n* 重新定义zk 数据结构和使用方式， 使一套zookeeper可以支撑2000+物理机器\n\t*\t 不再存储任何动态数据\n\t*\t nimbus 获取topology／supervisor／cluster info时， 减少对zk访问次数\n\t*\t 合并大量task级别znode，降低对zk的访问\n\t*\t 优化task error节点，降低对zk的访问\n\t*\t 优化zk cache操作\n* 优化应用层batch功能， 提高性能\n\t*\t 增加自动调整batch size功能\n\t*\t 修复内存拷贝问题\n\t*\t 内部通道数据，无需batch\n\t*\t 默认kryo序列化\n* 增加动态binary更新功能和配置更新功能 \n* localShuffle 功能优化，提高性能，本worker，本节点，其他节点 3级shuffle，并动态探测队列负荷， 网络连接状态。\n* 默认打开kryo， 提高性能\n* 优化nimbus HA 机制， 优先级最高的nimbus 才能被promote成master，增加稳定性\n\n\n\n## 优化\n* supervisor自动dump worker jstack和jmap, 当worker处于invalid状态时.\n* supervisor可以对内存超卖设置\n* supervisor增加topology相关文件的下载重试机制。\n* 增加配置logdir设置\n* 增加配置，可使nimbus机器不自动启动supervisor\n* 增加supervisor/nimbus/drpc gc日志\n* 优化jvm参数  1. set -Xmn 1/2 of heap memory 2. set PermSize to 1/32 and MaxPermSize 1/16 of heap memory; 3. 增加最小内存设置-Xms \"worker.memory.min.size\"。\n* ZK error 重新定义， 并且当worker死去时会，会在web ui报错, \n* 更新zktool，支持清理不干净的topology，并支持list功能\n* 优化netty client和zk连接重试的时间间隔获取机制\n* 修改out task状态更新机制，从zk上读取心跳信息，改为根据网络连接状态。以减少zk的依赖\n* 增加配置参数 topology.enable.metrics: true/false, 用来启用或禁用metric\n* 日志归类，相同topologyName的日志归类到对应目录下\n\n\n## Bug fix\n* Fix supervisor在调度有变化时，重复的下载任务jar包\n* Fix supervisor下载失败，不会尝试用错误的jar去启动worker\n* 大量的线程使用了错误的conf， 应该使用worker的conf\n* 提交拓扑时，服务端会首先检测拓扑名字的合法性\n* Fix fieldGrouping方式之前对Object[]数据结构不支持\n* Fix 使drpc 单例模式\n* 客户端topologyNameExists改进，直接使用trhift api\n* Fix restart 过程中， 因定时清理线程清理导致的restart失败\n* Fix 当trigger bolt失败时,反压可能丢失\n* Fix DefaultMetricUploader没有删除rocksdb中的数据,导致新的metrics数据无法添加\n\n\n## 运维和脚本\n* 优化cleandisk.sh脚本, 防止误删worker日志\n\n# Release 2.0.4-SNAPSHOT\n\n## New features\n1. 完全重构采样系统， 使用全新的Rollingwindow和Metric计算方式，尤其是netty采样数据，另外metric 发送和接收将不通过zk\n2. 完全重构web-ui\n3. 引入rocketdb，增加nimbus cache layer\n4. 梳理所有的zk节点和zk操作， 去掉无用的zk 操作\n5. 梳理所有的thrift 数据结构和函数， 去掉无用的rpc函数\n6. 将jstorm-client/jstorm-client-extension/jstorm-core整合为jstorm－core\n7. 同步依赖和storm一样\n8. 同步apache-storm-0.10.0-beta1 java 代码\n9. 切换日志系统到logback\n10. 升级thrift 到apache thrift 0.9.2\n11. 针对超大型任务600个worker／2000个task以上任务进行优化\n12. 要求 jdk7 or higher\n\n# Release 0.9.7.1\n\n## New features\n1. 增加Tuple自动batch的支持，以提高TPS以及降低消息处理延迟（task.batch.tuple=true，task.msg.batch.size=4）\n2. localFirst在本地节点处理能力跟不上时，自动对外部节点进行扩容\n3. 任务运行时，支持对任务配置的动态更新\n4. 支持任务对task心跳和task cleanup超时时间的自定义设置\n5. 增加disruptor queue对非阻塞模式TimeoutBlockingWaitStrategy的支持\n6. 增加Netty层消息发送超时时间设置的支持，以及Netty Client配置的优化\n7. 更新Tuple消息处理架构。去除不必要的总接收和总发送队列，减少消息流动环节，提高性能以及降低jstorm自身的cpu消耗。\n8. 增加客户端\"--include-jars\"， 提交任务时，可以依赖额外的jar\n9. 启动nimbus/supervisor时， 如果取得的是127.0.0.0地址时， 拒绝启动\n10. 增加自定义样例\n11. 合并supervisor 的zk同步线程syncSupervisor和worker同步线程syncProcess\n\n## 配置变更\n1. 默认超时心跳时间设置为4分钟\n2. 修改netty 线程池clientScheduleService大小为5\n\n## Bug fix\n1. 优化gc参数，4g以下内存的worker默认4个gc线程，4g以上内存， 按内存大小/1g * 1.5原则设置gc线程数量\n2. Fix在bolt处理速度慢时，可能出现的task心跳更新不及时的bug\n3. Fix在一些情况下，netty连接重连时的异常等待bug\n4. 提交任务时， 避免重复创建thrift client\n5. Fix 启动worker失败时，重复下载binary问题\n\n## 运维和脚本\n1. 优化cleandisk.sh脚本， 防止把当前目录删除和/tmp/hsperfdata_admin/\n2. 增加example下脚本执行权限\n3. 添加参数supervisor.host.start: true/false，可以通过脚本start.sh批量控制启动supervisor或不启动supervisor，默认是启动supervisor\n\n# Release 0.9.7\n\n## New features\n1. 实现topology任务并发动态调整的功能。在任务不下线的情况下，可以动态的对worker，spout, bolt或者ack进行扩容或缩容。rebalance命令被扩展用于支持动态扩容/缩容功能。\n2. 当打开资源隔离时，增加worker对cpu核使用上限的控制\n3. 调整task心跳更新机制。保证能正确反映spout/bolt exectue主线程的状态。\n4. 对worker和task的日志，增加jstorm信息前缀(clusterName, topologyName, ip:port, componentName, taskId, taskIndex)的支持\n5. 对topology任务调度时，增加对supervisor心跳状态的检查，不往无响应的supervisor调度任务\n6. 增加metric查询API，如: task的队列负载情况，worker的cpu，memory使用情况\n7. 增加supervisor上对任务jar包下载的重试，让worker不会因为jar在下载过程中的损坏，而启动失败\n8. 增加ZK Cache功能, 加快zk 读取速度, 并对部分节点采取直读方式\n9. 增加thrift getVersion api， 当客户端和服务器端版本不一致是，报warning\n10. 增加supervisor 心跳检查， 会拒绝分配任务到supervisor心跳超时的supervisor\n11. 更新发送到Alimonitor的user defined metrics 数据结构\n12. 增加客户端exclude-jar 功能， 当客户端提交任务时，可以通过exclude-jar和classloader来解决jar冲突问题。\n\n## 配置变更\n1. 修改supervisor到nimbus的心跳 超时时间到180秒\n2. 为避免内存outofmemory， 设置storm.messaging.netty.max.pending默认值为4\n3. 设置Nimbus 内存至4G\n4. 调大队列大小 task 队列大小为1024， 总发送队列和总接收队列为2048\n\n## Bug fix\n1. 短时间能多次restart worker配置多的任务时，由于Nimbus thrift thread的OOM导致，Supervisor可能出现假死的情况\n2. 同时提交任务，后续的任务可能会失败\n3. tickTuple不需要ack，更正对于tickTuple不正确的failed消息统计\n4. 解决use.old.assignment=true时，默认调度可能出现错误 \n5. 解决删除topology zk 清理不干净问题\n6. 解决当做任务分配时， restart topology失败问题\n7. 解决同时提交多个topology 竞争问题\n8. 解决NPE 当注册metrics \n9. 解决 zkTool 读取 monitor的 znode 失败问题\n10.解决 本地模式和打开classloader模式下， 出现异常问题\n11.解决使用自定义日志logback时， 本地模式下，打印双份日志问题\n\n## 运维& 脚本\n1. Add rpm build spec\n2. Add deploy files of jstorm for rpm package building\n3. cronjob改成每小时运行一次， 并且coredump 改成保留1个小时\n\n# Release 0.9.6.3\n\n## New features\n1. 实现tick tuple\n2. 支持logbak\n3. 支持加载用户自定义Log4j 配置文件\n4. Web UI显示用户自定义metrics\n5. jstorm list 命令支持topologyName\n6. 所有底层使用ip，自定义调度的时候，支持自定义调度中ip和hostname混用\n7. 本地模式支持junit test\n8. 客户端命令（比如提交jar时）可以指定storm.yaml 配置文件\n\n## Bug fix\n1. 在spout 的prepare里面增加active动作\n2. 多语言支持\n3. 异步检查worker启动心跳，加快worker启动速度\n4. 进程pid检查，加快发现worker已经死去的速度\n5. 使用错误的disruptor 类， 当disruptor队列满时，producer狂占CPU\n6. kill worker时， disruptor 报错，引起误解\n7. restart 命令可能失败\n8. JStorm 升级后，客户端提交一不兼容版本的应用jar时， 需要正确报错\n9. 本地模式时， 如果用户配置了log4j或logback时， 会打印日志2次\n10. 本地模式时， 应用调用了killTopology时， 可能出现exception\n11. 避免应用hack logger, 需要额外设置jstorm 的log level为info\n12. 增加一个logback 配置文件模板\n13. 上传lib jar时， 会有可能把lib jar当作应用的jar来处理了\n14. 删除一个topology后， 发现zk还是有一些node没有清理干净\n15. java core dump时，必须带上topology的名字\n16. JDK8 里-XX:MaxTenuringThreshold 的最大值是15，默认配置里的是20\n17. 一些特殊情况下，无法获取cpu 核数，导致supervisor slot数为0\n18. Fix 本地模式时，zk 报\"Address family not supported by protocol family\"\n19. Fix 本地模式时，关闭logview http server\n20. 在检查supervisor是否存活脚本中，创建日志目录\n21. 启动脚本对nimbus ip 的完整word检查，避免误启动其他机器nimbus\n22. 启动脚本对环境变量$JAVA_HOME/$JSTORM_HOME/$JSTORM_CONF_DIR检查, 并自动加载bash配置文件\n23. rpm安装包中，修改日志目录为/home/admin/logs\n24. rpm安装后，需要让/home/admin/jstorm, /home/admin/logs 可以被任意用户读取\n25. rpm安装包中，设置本地临时端口区间\n26. 需要一个noarch的rpm包\n\n# Release 0.9.6.2\n1. Add option to switch between BlockingQueue and Disruptor\n2. Fix the bug which under sync netty mode, client failed to send message to server \n3. Fix the bug let web UI can dispaly 0.9.6.1 cluster\n4. Fix the bug topology can be submited without main jar but a lot of little jar\n5. Fix the bug restart command \n6. Fix the bug trident bug\n7. Add the validation of topology name, component name... Only A-Z, a-z, 0-9, '_', '-', '.' are valid now.\n8. Fix the bug close thrift client\n\n# Release 0.9.6.2-rc\n1. Improve user experience from Web UI\n1.1 Add jstack link\n1.2 Add worker log link in supervisor page\n1.3 Add Web UI log encode setting \"gbk\" or \"utf-8\"\n1.4 Show starting tasks in component page\n1.5 Show dead task's information in UI\n1.6 Fix the bug that error info can not be displayed in UI when task is restarting\n2. Add restart command, with this command, user can reload configuration, reset worker/task parallism\n3. Upgrade curator/disruptor/guava version\n4. Revert json lib to google-simple json, wrap all json operation into two utility method\n5. Add new storm submit api, supporting submit topology under java \n6. Enable launch process with backend method\n7. Set \"spout.pending.full.sleep\" default value as true\n8. Fix the bug user define sceduler not support a list of workers\n9. Add disruptor/JStormUtils junit test\n10. Enable user to configure the name of monitor name of alimonitor\n11. Add tcp option \"reuseAddress\" in netty framework\n12. Fix the bug: When spout does not implement the ICommitterTrident interface, MasterCoordinatorSpout will stick on commit phase.\n\n# Release 0.9.6.2-rc\n1. Improve user experience from Web UI\n1.1 Add jstack link\n1.2 Add worker log link in supervisor page\n1.3 Add Web UI log encode setting \"gbk\" or \"utf-8\"\n1.4 Show starting tasks in component page\n1.5 Show dead task's information in UI\n1.6 Fix the bug that error info can not be displayed in UI when task is restarting\n2. Add restart command, with this command, user can reload configuration, reset worker/task parallism\n3. Upgrade curator/disruptor/guava version\n4. Revert json lib to google-simple json, wrap all json operation into two utility method\n5. Add new storm submit api, supporting submit topology under java \n6. Enable launch process with backend method\n7. Set \"spout.pending.full.sleep\" default value as true\n8. Fix the bug user define sceduler not support a list of workers\n9. Add disruptor/JStormUtils junit test\n10. Enable user to configure the name of monitor name of alimonitor\n11. Add tcp option \"reuseAddress\" in netty framework\n12. Fix the bug: When spout does not implement the ICommitterTrident interface, MasterCoordinatorSpout will stick on commit phase.\n\n# Release 0.9.6.1\n1. Add management of multiclusters to Web UI. Added management tools for multiclusters in WebUI.\n2. Merged Trident API from storm-0.9.3\n3. Replaced gson with fastjson\n4. Refactored metric json generation code.\n5. Stored version info with $JSTORM_HOME/RELEASE.\n6. Replaced SingleThreadDisruptorQueue with MultiThreadDisruptorQueue in task deserialize thread.\n7. Fixed issues with worker count on Web UI.\n8. Fixed issues with accessing the task map with multi-threads.\n9. Fixed NullPointerException while killing worker and reading worker's hearbeat object.\n10. Netty client connect to server only in NettyClient module.\n11. Add break loop operation when netty client connection is closed\n12. Fix the bug that topology warning flag present in cluster page is not consistent with error information present in topology page\n13. Add recovery function when the data of task error information is corrupted\n14. Fix the bug that the metric data can not be uploaded onto Alimonitor when ugrading from pre-0.9.6 to 0.9.6 and executing pkill java without restart the topologying\n15. Fix the bug that zeroMq failed to receive data\n16. Add interface to easily setting worker's memory\n17. Set default value of topology.alimonitor.metrics.post to false\n18. Only start NETTY_SERVER_DECODE_TIME for netty server\n19. Keep compatible with Storm for local mode\n20. Print rootId when tuple failed\n21. In order to keep compatible with Storm, add submitTopologyWithProgressBar interface\n22. Upgrade netty version from 3.2.7 to 3.9.0\n23. Support assign topology to user-defined supervisors\n\n\n# Release 0.9.6\n1. Update UI \n  - Display the metrics information of task and worker\n  - Add warning flag when errors occur for a topology\n  - Add link from supervisor page to task page\n2. Send metrics data to Alimonitor\n3. Add metrics interface for user\n4. Add task.cleanup.timeout.sec setting to let task gently cleanup\n5. Set the worker's log name as topologyName-worker-port.log\n6. Add setting \"worker.redirect.output.file\", so worker can redirect System.out/System.err to one setting file\n7. Add storm list command\n8. Add closing channel check in netty client to avoid double close\n9. Add connecting check in netty client to avoid connecting one server twice at one time \n\n# Release 0.9.5.1\n1. Add netty sync mode\n2. Add block operation in netty async mode\n3. Replace exception with Throwable in executor layer\n4. Upgrade curator-framework version from 1.15 to 1.3.2\n5. Add more netty junit test\n6. Add log when queue is full\n\n# Release 0.9.5\n\n## Big feature:\n1. Redesign scheduler arithmetic, basing worker not task .\n\n## Bug fix\n1. Fix disruptor use too much cpu\n2. Add target NettyServer log when f1ail to send data by netty\n\n# Release 0.9.4.1\n\n## Bug fix:\n1. Improve speed between tasks who is running in one worker\n2. Fix wrong timeout seconds\n3. Add checking port when worker initialize and begin to kill old worker\n4. Move worker hearbeat thread before initializing tasks\n5. Move init netty-server before initializeing tasks \n6. Check whether tuple's rootId is duplicated\n7. Add default value into Utils.getInt\n8. Add result function in ReconnectRunnable\n9. Add operation to start Timetick\n10. Halt process when master nimbus lost ZK node\n11. Add exception catch when cgroups kill process\n12. Speed up  reconnect to netty-server\n13. Share one task hearbeat thread for all tasks\n14. Quickly haltprocess when initialization failed.\n15. Check web-ui logview page size \n\n\n\n# Release 0.9.4\n\n## Big features\n1. Add transaction programming mode\n2. Rewrite netty code, 1. use share boss/worker thread pool;2 async send batch tuples;3 single thread to do reconnect job;4 receive batch tuples\n3. Add metrics and statics\n4. Merge Alimama storm branch into this version, submit jar with -conf, -D, -lib\n\n\n## Enhancement\n1. add setting when supervisor has been shutdown, worker will shutdown automatically\n2. add LocalFristGrouping api\n3. enable cgroup for normal user\n\n\n\n## Bug fix:\n1. Setting buffer size  when upload jar\n2. Add lock between ZK watch and timer thread when refresh connection\n3. Enable nimbus monitor thread only when topology is running in cluster mode\n4. Fix exception when failed to read old assignment of ZK\n5. classloader fix when both parent and current classloader load the same class\n6. Fix log view null pointer exception\n\n# Release 0.9.3.1\n\n## Enhancement\n1. switch apache thrift7 to storm thrift7\n2. set defatult acker number is 1\n3. add \"spout.single.thread\" setting\n4. make nimbus logview port different from supervisor's\n5. web ui can list all files of log's subdir\n6. Set gc dump dir as log's dir\n\n\n# Release 0.9.3\n\n## New feature\n1. Support Aliyun Apsara/Hadoop Yarn\n\n## Enhancement\n1. Redesign Logview\n2. Kill old worker under the same port when worker is starting\n3. Add zk information/version information on UI\n4. Add nodeport information for dead task in nimbus\n5. Add interface to get values when spout doing ack\n6. Add timeout statics in bolt\n7. jstorm script return status\n8. Add logs when fail to deserialize tuple \n9. Skip sleep operation when max_pending is 1 and waiting ack\n10. Remove useless dependency\n11. Longer task timeout setting\n12. Add supervisor.use.ip setting\n13. Redirect supervisor out/err to /dev/null, redirect worker out/err to one file\n\n\n## Bug Fix\n1. Fix kryo fail to deserialize object when enable classloader\n2. Fix fail to reassign dead task when worker number is less than topology apply\n3. Set samller jvm heap memory for jstorm-client \n4. Fix fail to set topology status as active when  do rebalance operation twice at one time,\n5. Fix local mode bug under linux\n6. Fix average latency isn't accurate\n7. GC tuning.\n8. Add default kill function for AysncLoopRunnable\n \n\n\n# Release 0.9.2\n\n## New feature\n1. Support LocalCluster/LocalDrpc mode, support debugging topology under local mode\n2. Support CGroups, assigning CPU in hardware level.\n3. Support simple logview\n\n## Bug fix or enhancement\n1. Change SpoutExecutor's RotatingMap to TimeCacheMap, when putting too much timeout tuple is easy to cause deadlock in spout acker thread\n2. Tunning gc parameter, improve performance and avoid full GC\n3. Improve Topology's own gc priority, make it higher than JStorm system setting.\n4. Tuning Nimbus HA, switch nimbus faster, when occur nimbus failure.\n5. Fix bugs found by FindBugs tool.\n6. Revert Trident interface to 0.8.1, due to 0.8.1's trident interface's performance is better.\n7. Setting nimbus.task.timeout.secs as 60 to avoid nimbus doing assignment when task is under full gc.\n8. Setting default rpc framework as netty\n9. Tunning nimbus shutdown flow\n10. Tunning worker shutdown flow\n11. Add task heartbeat log\n12. Optimize Drpc/LocalDrpc source code.\n13. Move classloader to client jar.\n14  Fix classloader fail to load  anonymous class\n15. Web Ui display slave nimbus\n16. Add thrift max read buffer size\n17. Setting CPU slot base double\n18. Move Zk utility to jstorm-client-extension.jar\n19. Fix localOrShuffle null pointer\n20. Redirecting worker's System.out/System.err to file is configurable.\n21. Add new RPC frameworker JeroMq\n22. Fix Zk watcher miss problem\n23. Update sl4j 1.5.6 to 1.7.5\n24. Shutdown worker when occur exception in Smart thread\n25. Skip downloading useless topology in Supervisor\n26. Redownload the topology when failed to deserialize topology in Supervisor.\n27. Fix topology codeDir as resourceDir\n28. Catch error when normalize topology\n29. Add log when found one task is dead\n30. Add maven repository, JStorm is able to build outside of Alibaba\n31. Fix localOrShuffle null pointer exception\n32. Add statics counting for internal tuples in one worker\n33. Add thrift.close after download topology binary in Supervisor\n\n\n# Release 0.9.1\n\n## new features\n1. Application classloader. when Application jar is conflict with jstorm jar, \n   please enable application classloader.\n2. Group Quato, Different group with different resource quato.\n\n## Bug fix or enhancement\n1. Fix Rotation Map competition issue.\n2. Set default acker number as 0\n3. Set default spout/bolt number as 1\n4. Add log directory in log4j configuration file\n5. Add transaction example\n6. Fix UI showing wrong worker numbe in topology page\n7. Fix UI showing wrong latency in topology page\n8. Replace hardcode Integer convert with JStormUtils.parseInt\n9. Support string parse in Utils.getInt\n10. Remove useless dependency in pom.xml\n11. Support supervisor using IP or special hostname\n12. Add more details when no resource has been assigned to one new topology\n13. Replace normal thread with Smart thread\n14. Add gc details \n15. Code format\n16. Unify stormId and topologyId as topologyId\n17. Every nimbus will regist ip to ZK\n\n\n\n# Release 0.9.0\nIn this version, it will follow storm 0.9.0 interface, so the application running\non storm 0.9.0 can run in jstorm 0.9.0 without any change.\n\n## Stability\n1. provide nimbus HA. when the master nimbus shuts down, it will select another\n online nimbus to be the master. There is only one master nimbus online \n any time and the slave nimbuses just synchronouse the master's data.\n2. RPC through netty is stable, the sending speed is match with receiving speed. \n\n\n## Powerful scheduler\n1. Assigning resource on four dimensions:cpu, mem, disk, net\n2. Application can use old assignment.\n3. Application can use user-define resource.\n4. Task can apply extra cpu slot or memory slot.\n4. Application can force tasks run on different supervisor or the same supervisor\n\n\n\n\n\n\n\n\n# Release 0.7.1\nIn this version, it will follow storm 0.7.1 interface, so the topology running\nin storm 0.7.1 can run in jstorm without any change.\n\n## Stability\n* Assign workers in balance\n* add setting \"zmq.max.queue.msg\" for zeromq\n* communication between worker and tasks without zeromq\n* Add catch exception operation\n  * in supervisor SyncProcess/SyncSupervisor\n  * add catch exception and report_error in spout's open and bolt's prepare\n  * in all IO operation\n  * in all serialize/deserialize\n  * in all ZK operation\n  *  in topology upload/download function\n  *  during initialization zeromq\n* do assignmen/reassignment operation in one thread to avoid competition\n* redesign nimbus 's topology assign algorithm, make the logic simple much.\n* redesign supervisor's sync assignment algorithm, make the logic simple much\n* reduce zookeeper load\n  * redesign nimbus monitor logic, it will just scan tasks' hearbeat, frequency is 10s\n  * nimbus cancel watch on supervisor\n  * supervisor heartbeat frequence change to 10s\n  * supervisor syncSupervisor/syncProcess frequence change to 10s\n  * supervisor scan /$(ZKROOT)/assignment only once in one monitor loop\n  * task hearbeat change to 10s\n* create task pid file before connection zk, this is very import when zk is unstable.\n\n\n## Performance tuning\n* reduce once memory copy when deserialize tuple, improve performance huge.\n* split executor thread as two thread, one handing receive tuples, one sending tuples, improve performance much\n* redeisign sample code, it will sampling every 5 seconds, not every 20 tuple once, improve performance much\n* simplify the ack's logic, make acker more effeciency\n* Communication between worker and tasks won't use zeromq, just memory share in process\n* in worker's Drainer/virtualportdispatch thread, spout/bolt recv/send thread, \n   the thread will sleep 1 ms when there is not tuple in one loop\n* communication between worker and tasks without zeromq\n* sampling frequence change to 5s, not every 20 tuple once.\n\n## Enhancement:\n* add IFailValueSpout interface\n* Redesign sampling code, collection statics model become more common.\n  *  Add sending/recving tps statics, statics is more precise.\n* Atomatically do deactivate action when kill/rebalance topology, and the wait time is 2 * MSG_TIMEOUT\n* fix nongrouping bug, random.nextInt will generate value less than 0.\n* Sleep one setting time(default is 1 minute) after finish spout open, \n   which is used to wait other task finish initialization.\n* Add check component name when submit topology, forbidding the component \n   which name start with \"__\"\n* change the zk's node /$(ZKROOT)/storm to /$(ZKROOT)/topology\n* abstract topology check logic from generating real topology function\n* when supervisor is down and topology do rebalance, the alive task under down \n   supervisor is unavailable.\n* add close connection operation after finish download topology binary\n* automatically create all local dirtorie, such as \n   /$(LOCALDIR)/supervisor/localstate\n* when killing worker, add \"kill and sleep \" operation before \"kill -9\" operation\n* when generate real topology binary,\n  * configuration priority different.   \n      component configuration > topology configuration > system configuration\n  * skip the output stream which target component doesn't exist.\n  * skip the component whose parallism is 0.\n  * component's parallism is less than 0, throw exception.\n* skip ack/fail when inputstream setting is empty\n* add topology name to the log\n* fix ui select option error, default is 10 minutes\n* supervisor can display all worker's status"
        },
        {
          "name": "jstorm-core",
          "type": "tree",
          "content": null
        },
        {
          "name": "jstorm-hbase-metrics-plugin",
          "type": "tree",
          "content": null
        },
        {
          "name": "jstorm-hdfs",
          "type": "tree",
          "content": null
        },
        {
          "name": "jstorm-on-yarn",
          "type": "tree",
          "content": null
        },
        {
          "name": "jstorm-ui",
          "type": "tree",
          "content": null
        },
        {
          "name": "jstorm-utility",
          "type": "tree",
          "content": null
        },
        {
          "name": "other",
          "type": "tree",
          "content": null
        },
        {
          "name": "pom.xml",
          "type": "blob",
          "size": 14.2802734375,
          "content": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!--\n Licensed to the Apache Software Foundation (ASF) under one or more\n contributor license agreements.  See the NOTICE file distributed with\n this work for additional information regarding copyright ownership.\n The ASF licenses this file to You under the Apache License, Version 2.0\n (the \"License\"); you may not use this file except in compliance with\n the License.  You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n--><project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n<!--    \n    <parent>\n      <groupId>org.apache</groupId>\n      <artifactId>apache</artifactId>\n      <version>10</version>\n    </parent> \n    \n    // if release jstorm to maven center repository\n    // please set parent as oss-parent\n    <parent>\n      <groupId>org.sonatype.oss</groupId>\n      <artifactId>oss-parent</artifactId>\n      <version>7</version>\n    </parent>\n    \n    -->\n\n    \n  <groupId>com.alibaba.jstorm</groupId>\n  <artifactId>jstorm-all</artifactId>\n  <version>2.4.0</version>\n  <packaging>pom</packaging>\n  <name>jstorm-all</name>\n  <description>Distributed and fault-tolerant realtime computation</description>\n  <url>http://storm.taobao.org</url>\n  <licenses>\n    <license>\n      <name>The Apache Software License, Version 2.0</name>\n      <url>http://www.apache.org/licenses/LICENSE-2.0.txt</url>\n    </license>\n  </licenses>\n\n  <mailingLists>\n    <mailingList>\n      <!-- Due to JStorm has been merged into Storm, So directly use their email list -->\n      <name>Storm user mailing list</name>\n      <subscribe>user-subscribe@storm.apache.org</subscribe>\n      <unsubscribe>user-unsubscribe@storm.apache.org</unsubscribe>\n      <post>user@storm.apache.org</post>\n      <archive>http://mail-archives.apache.org/mod_mbox/storm-user/</archive>\n    </mailingList>\n    <mailingList>\n      <name>Storm developer mailing list</name>\n      <subscribe>dev-subscribe@storm.apache.org</subscribe>\n      <unsubscribe>dev-unsubscribe@storm.apache.org</unsubscribe>\n      <post>dev@storm.apache.org</post>\n      <archive>http://mail-archives.apache.org/mod_mbox/storm-dev/</archive>\n    </mailingList>\n  </mailingLists>\n\n  <developers>\n    <developer>\n      <id>longda</id>\n      <name>Longda Feng</name>\n      <email>zhongyan.feng@alibaba-inc.com</email>\n      <roles>\n        <role>Committer</role>\n      </roles>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>basti</id>\n      <name>Basti Liu</name>\n      <email>basti.liu@alibaba-inc.com</email>\n      <roles>\n        <role>Committer</role>\n      </roles>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>cody</id>\n      <name>Cody Innowhere</name>\n      <email>weiyue.wy@alibaba-inc.com</email>\n      <roles>\n        <role>Committer</role>\n      </roles>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>jian.wang</id>\n      <name>Jian Wang</name>\n      <email>Jian.Wang@alibaba-inc.com</email>\n      <roles>\n        <role>Committer</role>\n      </roles>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>john</id>\n      <name>John Fang</name>\n      <email>John.Fang@alibaba-inc.com</email>\n      <roles>\n        <role>Committer</role>\n      </roles>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>Jark</id>\n      <name>Jark Wu</name>\n      <email>Jark.Wu@alibaba-inc.com</email>\n      <roles>\n        <role>Committer</role>\n      </roles>\n      <timezone>+8</timezone>\n    </developer>\n  </developers>\n \n  <prerequisites>\n    <maven>3.0.0</maven>\n  </prerequisites>\n\n  <scm>\n    <connection>scm:git:https://github.com/alibaba/jstorm.git</connection>\n    <developerConnection>scm:git:https://github.com/alibaba/jstorm.git</developerConnection>\n    <tag>v0.10.0</tag>\n    <url>https://git-wip-us.apache.org/repos/asf/storm</url>\n  </scm>\n\n  <issueManagement>\n    <system>jira</system>\n    <url>https://issues.apache.org/jira/browse/STORM</url>\n  </issueManagement>\n\n  <properties>\n    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n    <test.extra.args>-Djava.net.preferIPv4Stack=true</test.extra.args>\n\n    <!-- dependency versions -->\n    <powermock.version>1.4.11</powermock.version>\n    <hadoop.version>2.6.2</hadoop.version>\n  </properties>\n  <modules>\n    <module>jstorm-core</module>\n    <module>example/sequence-split-merge</module>\n    <module>jstorm-ui</module>\n    <!--<module>jstorm-utility/jstorm-rocket-mq</module>-->\n    <module>jstorm-utility/jstorm-kafka</module>\n    <module>jstorm-utility/ons</module>\n    <module>jstorm-utility/jstorm-flux</module>\n    <module>jstorm-utility/jstorm-elasticsearch</module>\n    <module>jstorm-on-yarn</module>\n    <module>jstorm-hbase-metrics-plugin</module>\n    <module>jstorm-hdfs</module>\n  </modules>\n\n  <profiles>\n    <profile>\n      <id>sign</id>\n      <build>\n        <plugins>\n          <plugin>\n            <groupId>org.apache.maven.plugins</groupId>\n            <artifactId>maven-gpg-plugin</artifactId>\n            <executions>\n              <execution>\n                <id>sign-artifacts</id>\n                <phase>verify</phase>\n                <goals>\n                  <goal>sign</goal>\n                </goals>\n              </execution>\n            </executions>\n          </plugin>\n        </plugins>\n      </build>\n    </profile>\n      \n    <!-- \n    <profile>\n      <id>dist</id>\n      <modules>\n        <module>storm-dist/binary</module>\n        <module>storm-dist/source</module>\n      </modules>\n      <build>\n        <plugins>\n          <plugin>\n            <groupId>org.apache.maven.plugins</groupId>\n            <artifactId>maven-source-plugin</artifactId>\n            <executions>\n              <execution>\n                <id>attach-sources</id>\n                <goals>\n                  <goal>jar</goal>\n                </goals>\n              </execution>\n            </executions>\n          </plugin>\n          <plugin>\n            <groupId>org.apache.maven.plugins</groupId>\n            <artifactId>maven-javadoc-plugin</artifactId>\n            <configuration>\n              <outputDirectory>${project.build.directory}/javadoc</outputDirectory>\n              <reportOutputDirectory>./docs/javadoc</reportOutputDirectory>\n            </configuration>\n            <executions>\n              <execution>\n                <id>attach-javadocs</id>\n                <goals>\n                  <goal>jar</goal>\n                </goals>\n              </execution>\n              <execution>\n                <id>aggregate</id>\n                <goals>\n                  <goal>aggregate</goal>\n                </goals>\n                <phase>site</phase>\n              </execution>\n            </executions>\n          </plugin>\n          <plugin>\n            <groupId>org.apache.maven.plugins</groupId>\n            <artifactId>maven-jar-plugin</artifactId>\n            <configuration>\n              <archive>\n                <manifest>\n                  <addDefaultImplementationEntries>true</addDefaultImplementationEntries>\n                  <addDefaultSpecificationEntries>true</addDefaultSpecificationEntries>\n                </manifest>\n              </archive>\n            </configuration>\n          </plugin>\n      </plugins>\n    </build>\n  </profile>\n  -->\n  </profiles>\n\n<!--\n  <distributionManagement>\n    <repository>\n      <id>releases</id>\n      <name>releases</name>\n      <url>http://mvnrepo.alibaba-inc.com/nexus/content/repositories/releases/</url>\n    </repository>\n    <snapshotRepository>\n      <id>snapshots</id>\n      <name>snapshots</name>\n      <url>http://mvnrepo.alibaba-inc.com/nexus/content/repositories/snapshots/</url>\n    </snapshotRepository>\n    <snapshotRepository>\n      <id>ossrh</id>\n      <url>https://oss.sonatype.org/content/repositories/snapshots</url>\n    </snapshotRepository>\n    <repository>\n      <id>ossrh</id>\n      <url>https://oss.sonatype.org/service/local/staging/deploy/maven2/</url>\n    </repository>\n  </distributionManagement>\n-->\n\n  <repositories>\n    <repository>\n      <id>nexus</id>\n      <name>local private nexus</name>\n      <url>http://maven.oschina.net/content/groups/public/</url>\n      <releases>\n        <enabled>true</enabled>\n      </releases>\n      <snapshots>\n        <enabled>false</enabled>\n      </snapshots>\n    </repository>\n    <repository>\n      <id>taobao</id>\n      <url>http://mvnrepo.code.taobao.org/nexus/content/repositories/releases/</url>\n    </repository>\n    <repository>\n      <id>twitter4j</id>\n      <url>http://twitter4j.org/maven2</url>\n    </repository>\n    <repository>\n      <id>central</id>\n      <url>http://repo1.maven.org/maven2</url>\n    </repository>\n    <repository>\n      <id>clojars</id>\n      <url>http://clojars.org/repo/</url>\n    </repository>\n    <repository>\n      <id>C</id>\n      <url>http://repository.sonatype.org/content/groups/public/</url>\n    </repository>\n  </repositories>\n\n  <build>\n    <pluginManagement>\n      <plugins>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-surefire-plugin</artifactId>\n          <version>2.18.1</version>\n          <configuration>\n            <redirectTestOutputToFile>true</redirectTestOutputToFile>\n          </configuration>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-assembly-plugin</artifactId>\n          <version>2.4</version>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-dependency-plugin</artifactId>\n          <version>2.10</version>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-install-plugin</artifactId>\n          <version>2.4</version>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-compiler-plugin</artifactId>\n          <version>3.1</version>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-source-plugin</artifactId>\n          <version>2.2.1</version>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-javadoc-plugin</artifactId>\n          <version>2.10.1</version>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-jar-plugin</artifactId>\n          <version>2.4</version>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-release-plugin</artifactId>\n          <version>2.5</version>\n        </plugin>\n        <plugin>\n          <groupId>com.theoryinpractise</groupId>\n          <artifactId>clojure-maven-plugin</artifactId>\n          <version>1.7.1</version>\n          <extensions>true</extensions>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-surefire-report-plugin</artifactId>\n          <version>2.16</version>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-gpg-plugin</artifactId>\n          <version>1.6</version>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-shade-plugin</artifactId>\n          <version>2.4.1</version>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-project-info-reports-plugin</artifactId>\n          <version>2.7</version>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-site-plugin</artifactId>\n          <version>3.3</version>\n        </plugin>\n      </plugins>\n    </pluginManagement>\n    <plugins>\n      <plugin>\n        <artifactId>maven-compiler-plugin</artifactId>\n        <configuration>\n          <source>1.7</source>\n          <target>1.7</target>\n        </configuration>\n      </plugin>\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-source-plugin</artifactId>\n        <executions>\n          <execution>\n            <id>attach-sources</id>\n            <goals>\n              <goal>jar-no-fork</goal>\n            </goals>\n          </execution>\n        </executions>\n      </plugin>\n      \n      <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-javadoc-plugin</artifactId>\n          <configuration>\n              <additionalparam>-Xdoclint:none</additionalparam>\n              <outputDirectory>${project.build.directory}/javadoc</outputDirectory>\n              <reportOutputDirectory>./docs/javadoc</reportOutputDirectory>\n          </configuration>\n          <executions>\n              <execution>\n                  <id>attach-javadocs</id>\n                  <goals>\n                      <goal>jar</goal>\n                  </goals>\n              </execution>\n              <execution>\n                  <id>aggregate</id>\n                  <goals>\n                      <goal>aggregate</goal>\n                  </goals>\n                  <phase>site</phase>\n              </execution>\n          </executions>\n      </plugin>\n\n      <!--\n      // if release jstorm to maven center repository\n      // please set parent as oss-parent\n          <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-gpg-plugin</artifactId>\n        <executions>\n          <execution>\n            <id>sign-artifacts</id>\n            <phase>verify</phase>\n            <goals>\n              <goal>sign</goal>\n            </goals>\n          </execution>\n        </executions>\n      </plugin>\n       -->\n       \n      <plugin>\n        <artifactId>maven-assembly-plugin</artifactId>\n        <configuration>\n          <finalName>aloha</finalName>\n          <descriptors>\n            <descriptor>release.xml</descriptor>\n          </descriptors>\n        </configuration>\n      </plugin>\n        </plugins>\n    </build>\n</project>\n"
        },
        {
          "name": "release.xml",
          "type": "blob",
          "size": 7.0693359375,
          "content": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<assembly>\n    <id>tgz</id>\n    <baseDirectory>jstorm-${project.version}</baseDirectory>\n    <formats>\n        <format>dir</format>\n        <format>zip</format>\n    </formats>\n    <files>\n        <file>\n            <source>bin/jstorm.py</source>\n            <outputDirectory>/bin</outputDirectory>\n            <fileMode>0755</fileMode>\n            <destName>jstorm</destName>\n        </file>\n        <file>\n            <source>bin/start.sh</source>\n            <outputDirectory>/bin</outputDirectory>\n            <fileMode>0755</fileMode>\n            <destName>start.sh</destName>\n        </file>\n        <file>\n            <source>bin/stop.sh</source>\n            <outputDirectory>/bin</outputDirectory>\n            <fileMode>0755</fileMode>\n            <destName>stop.sh</destName>\n        </file>\n        <file>\n            <source>./jstorm-core/src/main/resources/version</source>\n            <outputDirectory>./</outputDirectory>\n            <destName>RELEASE</destName>\n        </file>\n        <file>\n            <source>./history.md</source>\n            <outputDirectory>./</outputDirectory>\n            <destName>history.md</destName>\n        </file>\n        <file>\n            <source>./history_cn.md</source>\n            <outputDirectory>./</outputDirectory>\n            <destName>history_cn.md</destName>\n        </file>\n        <file>\n            <source>./LICENSE</source>\n            <outputDirectory>./</outputDirectory>\n            <destName>LICENSE</destName>\n        </file>\n        <file>\n            <source>./README.md</source>\n            <outputDirectory>./</outputDirectory>\n            <destName>README.md</destName>\n        </file>\n\n        <file>\n            <source>jstorm-ui/target/jstorm-ui-${project.version}.war</source>\n            <outputDirectory>./</outputDirectory>\n            <fileMode>0755</fileMode>\n            <destName>jstorm-ui-${project.version}.war</destName>\n        </file>\n        <file>\n            <source>example/sequence-split-merge/target/sequence-split-merge-${project.version}.jar</source>\n            <outputDirectory>./example/sequence_test</outputDirectory>\n            <fileMode>0755</fileMode>\n            <destName>sequence-split-merge.jar</destName>\n        </file>\n\n    </files>\n    <fileSets>\n        <fileSet>\n            <directory>./conf</directory>\n            <outputDirectory>/conf</outputDirectory>\n            <includes>\n                <include>**/*</include>\n            </includes>\n        </fileSet>\n        <fileSet>\n            <directory>./conf</directory>\n            <outputDirectory>/logs</outputDirectory>\n            <directoryMode>0755</directoryMode>\n            <excludes>\n                <exclude>*</exclude>\n            </excludes>\n        </fileSet>\n        <fileSet>\n            <directory>./conf</directory>\n            <outputDirectory>/data</outputDirectory>\n            <directoryMode>0755</directoryMode>\n            <excludes>\n                <exclude>*</exclude>\n            </excludes>\n        </fileSet>\n        <fileSet>\n            <directory>./example/sequence-split-merge/conf</directory>\n            <outputDirectory>/example/sequence_test</outputDirectory>\n            <directoryMode>0755</directoryMode>\n            <fileMode>0644</fileMode>\n            <includes>\n                <include>**/*</include>\n            </includes>\n        </fileSet>\n        <fileSet>\n            <directory>./example/sequence-split-merge/deploy</directory>\n            <outputDirectory>/example/sequence_test</outputDirectory>\n            <directoryMode>0755</directoryMode>\n            <fileMode>0755</fileMode>\n            <includes>\n                <include>**/*</include>\n            </includes>\n        </fileSet>\n        <fileSet>\n            <directory>jstorm-hbase-metrics-plugin/target/</directory>\n            <outputDirectory>lib/ext/hbase</outputDirectory>\n            <includes>\n                <include>jstorm-hbase-metrics-plugin-${project.version}.jar</include>\n            </includes>\n        </fileSet>\n        <fileSet>\n            <directory>jstorm-hbase-metrics-plugin/target/lib</directory>\n            <outputDirectory>lib/ext/hbase</outputDirectory>\n            <includes>\n                <include>**/*</include>\n            </includes>\n        </fileSet>\n        <fileSet>\n            <directory>jstorm-hdfs/target/</directory>\n            <outputDirectory>lib/ext/hdfs</outputDirectory>\n            <includes>\n                <include>jstorm-hdfs-${project.version}.jar</include>\n            </includes>\n        </fileSet>\n        <fileSet>\n            <directory>jstorm-hdfs/target/lib</directory>\n            <outputDirectory>lib/ext/hdfs</outputDirectory>\n            <includes>\n                <include>**/*</include>\n            </includes>\n        </fileSet>\n    </fileSets>\n    <moduleSets>\n        <moduleSet>\n            <includes>\n                <include>com.alibaba.jstorm:jstorm-core</include>\n            </includes>\n            <binaries>\n                <outputDirectory>./</outputDirectory>\n                <unpack>false</unpack>\n                <dependencySets>\n                    <dependencySet>\n                        <excludes>\n                            <exclude>com.alibaba.jstorm:jstorm-core</exclude>\n                            <!-- don't need these jars, these jars have already been relocate by maven-shade-plugin in jstorm-client -->\n                            <exclude>com.esotericsoftware:*</exclude>\n                            <exclude>org.apache.thrift:*</exclude>\n                            <exclude>org.apache.httpcomponents:http*</exclude>\n                            <exclude>org.apache.zookeeper:zookeeper</exclude>\n                            <exclude>org.apache.curator:*</exclude>\n                            <exclude>com.google.guava:guava</exclude>\n                            <exclude>org.objenesis:objenesis</exclude>\n                            <exclude>org.ow2.asm:asm</exclude>\n                            <exclude>org.yaml:snakeyaml</exclude>\n                            <exclude>com.google.code.gson:gson</exclude>\n                            <exclude>io.dropwizard.metrics:*</exclude>\n                            <exclude>org.apache.commons:commons-exec</exclude>\n                            <exclude>org.apache.commons:commons-compress</exclude>\n                            <exclude>commons-cli:commons-cli</exclude>\n                            <exclude>commons-io:commons-io</exclude>\n                            <exclude>commons-codec:commons-codec</exclude>\n                            <exclude>commons-lang:commons-lang</exclude>\n                            <exclude>org.jgrapht:jgrapht-core</exclude>\n                            <exclude>jline:jline</exclude>\n                            <exclude>org.tukaani:xz</exclude>\n                            <exclude>com.googlecode.json-simple:json-simple</exclude>\n                            <exclude>com.lmax:disruptor</exclude>\n                        </excludes>\n                        <outputDirectory>lib</outputDirectory>\n                    </dependencySet>\n                </dependencySets>\n            </binaries>\n        </moduleSet>\n    </moduleSets>\n\n</assembly>\n"
        },
        {
          "name": "version",
          "type": "blob",
          "size": 0.005859375,
          "content": "2.4.0\n"
        }
      ]
    }
  ]
}