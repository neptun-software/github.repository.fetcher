{
  "metadata": {
    "timestamp": 1736708170663,
    "page": 628,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjY0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "linkedin/cruise-control",
      "stars": 2779,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".circleci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.3662109375,
          "content": ".project\n.settings\n.classpath\n.gradle\n.idea\n*.iml\n*.ipr\n*.iws\n/build\n*/build\nout/\n*/bin/\n.reviewboardrc\nlogs\n*~\ntarget/\naccess.log\n*.egg\n/bin/\n.vertx\n**openapi.json\nfileStore/failedBrokers.txt\ncruise-control/src/main/resources/webroot/.openapi-generator-ignore\ncruise-control/src/main/resources/webroot/.openapi-generator/\ncruise-control/src/main/resources/webroot/README.md\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 1.7890625,
          "content": "Contribution Agreement\n======================\n\nAs a contributor, you represent that the code you submit is your\noriginal work or that of your employer (in which case you represent you\nhave the right to bind your employer). By submitting code, you (and, if\napplicable, your employer) are licensing the submitted code to LinkedIn\nand the open source community subject to the BSD 2-Clause license. \n\nResponsible Disclosure of Security Vulnerabilities\n==================================================\n\nPlease do not file reports on Github for security issues.\nPlease review the guidelines on at \nhttps://www.linkedin.com/help/linkedin/answer/62924/security-vulnerabilities?lang=en\n\nTips for Getting Your Pull Request (PR) Accepted\n===========================================\n\n1. Make sure all new features are tested and the tests pass -- i.e. a submitted PR should have already been tested for \nexisting and new unit tests.\n2. Bug fixes must include a test case demonstrating the error that it fixes.\n3. Open an issue first and seek advice for your change before submitting a PR. Large features which have never been \ndiscussed are unlikely to be accepted.\n4. New contributors should create an account in CircleCI first before raising the PR. \n5. Do not create a PR with \"work-in-progress\" (WIP) changes.\n6. Use clear and concise titles for submitted PRs and issues.\n7. Each PR should be linked to an existing issue corresponding to the PR \n(see [PR template](./docs/pull_request_template.md)).\n8. If there are no existing issues about a PR, create one before submitting the PR.\n9. We strongly encourage the use of recommended code-style for the project \n(see [code-style.xml](./docs/code-style.xml)).\n10. A pre-commit CheckStyle hook can be run by adding `./checkstyle/checkstyle-pre-commit` to your `.git/hooks/pre-commit` script.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.32421875,
          "content": "BSD 2-CLAUSE LICENSE\n\nCopyright 2017, 2018, 2019, 2020, 2021, 2022 LinkedIn Corporation.\nAll Rights Reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "NOTICE",
          "type": "blob",
          "size": 0.296875,
          "content": "Copyright 2017 LinkedIn Corporation\nAll Rights Reserved.\n\nLicensed under the BSD 2-Clause License (the \"License\").\nSee LICENSE in the project root for license information.\n\nThis product includes Apache Kafka (http://kafka.apache.org)\nCopyright (c) 2017 The Apache Software Foundation\nLicense: Apache 2.0\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 15.23828125,
          "content": "Cruise Control for Apache Kafka\n===================\n\n[![CI](https://github.com/linkedin/cruise-control/actions/workflows/ci.yaml/badge.svg)](https://github.com/linkedin/cruise-control/actions/workflows/ci.yaml)\n[![CircleCI](https://circleci.com/gh/linkedin/cruise-control.svg?style=svg)](https://circleci.com/gh/linkedin/cruise-control)\n\n\n### Introduction ###\n  Cruise Control is a product that helps run Apache Kafka clusters at large scale. Due to the popularity of \n  Apache Kafka, many companies have increasingly large Kafka clusters with hundreds of brokers. At LinkedIn, we have 10K+ Kafka brokers, \n  which means broker deaths are an almost daily occurrence and balancing the workload of Kafka also becomes a big overhead. \n  \n  Kafka Cruise Control is designed to address this operational scalability issue.\n  \n### Features ###\n  Kafka Cruise Control provides the following features out of the box:\n  \n  * Resource utilization tracking for brokers, topics, and partitions.\n  \n  * Query the current Kafka cluster state to see the online and offline partitions, in-sync and out-of-sync replicas,\n  replicas under `min.insync.replicas`, online and offline logDirs, and distribution of replicas in the cluster.\n  \n  * Multi-goal rebalance proposal generation for:\n    * Rack-awareness\n    * Resource capacity violation checks (CPU, DISK, Network I/O)\n    * Per-broker replica count violation check\n    * Resource utilization balance (CPU, DISK, Network I/O)\n    * Leader traffic distribution\n    * Replica distribution for topics\n    * Global replica distribution\n    * Global leader replica distribution\n    * Custom goals that you wrote and plugged in\n  \n  * Anomaly detection, alerting, and self-healing for the Kafka cluster, including:\n    * Goal violation\n    * Broker failure detection\n    * Metric anomaly detection\n    * Disk failure detection (not available in `kafka_0_11_and_1_0` branch)\n    * Slow broker detection (not available in `kafka_0_11_and_1_0` branch)\n  \n  * Admin operations, including:\n    * Add brokers\n    * Remove brokers\n    * Demote brokers\n    * Rebalance the cluster\n    * Fix offline replicas (not available in `kafka_0_11_and_1_0` branch)\n    * Perform preferred leader election (PLE)\n    * Fix offline replicas\n    * Adjust replication factor\n\n### Environment Requirements ###\n* The `main` (previously `migrate_to_kafka_2_5`) branch of Cruise Control is compatible with Apache Kafka `2.5+` (i.e. [Releases](https://github.com/linkedin/cruise-control/releases) with `2.5.*`),\n  `2.6` (i.e. [Releases](https://github.com/linkedin/cruise-control/releases) with `2.5.11+`), `2.7` (i.e. [Releases](https://github.com/linkedin/cruise-control/releases) with `2.5.36+`),\n  `2.8` (i.e. [Releases](https://github.com/linkedin/cruise-control/releases) with `2.5.66+`), `3.0` (i.e. [Releases](https://github.com/linkedin/cruise-control/releases) with `2.5.85+`),\n  and `3.1` (i.e. [Releases](https://github.com/linkedin/cruise-control/releases) with `2.5.85+`).\n* The `migrate_to_kafka_2_4` branch of Cruise Control is compatible with Apache Kafka `2.4` (i.e. [Releases](https://github.com/linkedin/cruise-control/releases) with `2.4.*`).\n* The `kafka_2_0_to_2_3` branch (deprecated) of Cruise Control is compatible with Apache Kafka `2.0`, `2.1`, `2.2`, and `2.3` (i.e. [Releases](https://github.com/linkedin/cruise-control/releases) with `2.0.*`).\n* The `kafka_0_11_and_1_0` branch (deprecated) of Cruise Control is compatible with Apache Kafka `0.11.0.0`, `1.0`, and `1.1` (i.e. [Releases](https://github.com/linkedin/cruise-control/releases) with `0.1.*`).\n* `message.format.version` `0.10.0` and above is needed.\n* The `kafka_2_0_to_2_3` and `kafka_0_11_and_1_0` branches compile with `Scala 2.11`.\n* The branch `migrate_to_kafka_2_4` compiles with `Scala 2.12`.\n* The branch `migrate_to_kafka_2_5` compile with `Scala 2.13`.\n* This project requires Java 11.\n\n#### Known Compatibility Issues ####\n* Support for Apache Kafka `2.0`, `2.1`, `2.2`, and `2.3` requires [KAFKA-8875](https://issues.apache.org/jira/browse/KAFKA-8875) hotfix.\n\n### Quick Start ###\n0. Get Cruise Control\n    1. (Option-1): via `git clone`\n        * `git clone https://github.com/linkedin/cruise-control.git && cd cruise-control/`\n    2. (Option-2): via browsing the available releases:\n        * Browse `https://github.com/linkedin/cruise-control/releases` to pick a release -- e.g. `0.1.10`\n        * Get and extract the release: `wget https://github.com/linkedin/cruise-control/archive/0.1.10.tar.gz \n        && tar zxvf 0.1.10.tar.gz && cd cruise-control-0.1.10/`\n        * Initialize the local repo: `git init && git add . && git commit -m \"Init local repo.\"\n        && git tag -a 0.1.10 -m \"Init local version.\"`\n1. This step is required if `CruiseControlMetricsReporter` is used for metrics collection (i.e. the default for Cruise\nControl). The metrics reporter periodically samples the Kafka raw metrics on the broker and sends them to a Kafka topic.\n    * `./gradlew jar` (Note: This project requires Java 11)\n    * Copy `./cruise-control-metrics-reporter/build/libs/cruise-control-metrics-reporter-A.B.C.jar` (Where `A.B.C` is\n    the version of the Cruise Control) to your Kafka server dependency jar folder. For Apache Kafka, the folder would\n    be `core/build/dependant-libs-SCALA_VERSION/` (for a Kafka source checkout) or `libs/` (for a Kafka release download).\n    * Modify Kafka server configuration to set `metric.reporters` to\n    `com.linkedin.kafka.cruisecontrol.metricsreporter.CruiseControlMetricsReporter`. For Apache Kafka, server \n    properties are located at `./config/server.properties`.\n    * If `SSL` is enabled, ensure that the relevant client configurations are properly set for all brokers in \n    `./config/server.properties`. Note that `CruiseControlMetricsReporter` takes all configurations for vanilla \n    `KafkaProducer` with a prefix of `cruise.control.metrics.reporter.` -- e.g. \n    `cruise.control.metrics.reporter.ssl.truststore.password`.    \n    * If the default broker cleanup policy is `compact`, make sure that the topic to which Cruise Control metrics\n    reporter should send messages is created with the `delete` cleanup policy -- the default metrics reporter topic\n    is `__CruiseControlMetrics`.\n2. Start ZooKeeper and Kafka server ([See tutorial](https://kafka.apache.org/quickstart)).\n3. Modify `config/cruisecontrol.properties` of Cruise Control:\n    * (Required) fill in `bootstrap.servers` and `zookeeper.connect` to the Kafka cluster to be monitored.\n    * (Required) update `capacity.config.file` to the path of your capacity file.  \n      * Capacity file is a JSON file that provides the capacity of the brokers\n      * You can start Cruise Control server with the default file (`config/capacityJBOD.json`), but it may not reflect the actual capacity of the brokers \n      * See [BrokerCapacityConfigurationFileResolver configurations](https://github.com/linkedin/cruise-control/wiki/Configurations#brokercapacityconfigurationfileresolver-configurations) for more information and examples\n    * (Optional) set `metric.sampler.class` to your implementation (the default sampler class is `CruiseControlMetricsReporterSampler`) \n    * (Optional) set `sample.store.class` to your implementation if you have one (the default `SampleStore` is `KafkaSampleStore`)\n4. Run the following command \n    ```\n    ./gradlew jar copyDependantLibs\n    ./kafka-cruise-control-start.sh [-jars PATH_TO_YOUR_JAR_1,PATH_TO_YOUR_JAR_2] config/cruisecontrol.properties [port]\n    ```\n    JAR files correspond to your applications and `port` enables customizing the Cruise Control port number (default: `9090`).\n    * (Note) To emit Cruise Control JMX metrics on a particular port (e.g. `56666`), `export JMX_PORT=56666` before\n    running `kafka-cruise-control-start.sh`\n5. (Verify your setup) Visit `http://localhost:9090/kafkacruisecontrol/state` (or \n`http://localhost:\\[port\\]/kafkacruisecontrol/state` if you specified the port when starting Cruise Control).\n\n**Note**: \n* Cruise Control will need some time to read the raw Kafka metrics from the cluster.\n* The metrics of a newly up broker may take a few minutes to get stable. Cruise Control will drop the inconsistent \nmetrics (e.g when topic bytes-in is higher than broker bytes-in), so first few windows may not have enough valid partitions.\n\n### REST API ###\nCruise Control provides a [REST API](https://github.com/linkedin/cruise-control/wiki/REST-APIs) for users \nto interact with. See the wiki page for more details.\n\n### How Does It Work ###\nCruise Control relies on the recent load information of replicas to optimize the cluster.\n\nCruise Control periodically collects resource utilization samples at both broker- and partition-level to \ninfer the traffic pattern of each partition. Based on the traffic characteristics and distribution of all the partitions, \nit derives the load impact of each partition over the brokers. Cruise Control then builds a workload\nmodel to simulate the workload of the Kafka cluster. The goal optimizer explores different ways to generate \ncluster workload optimization proposals based on the user-specified list of goals.\n\nCruise Control also monitors the liveness of all the brokers in the cluster.\nTo avoid the loss of redundancy, Cruise Control automatically moves replicas from failed brokers to alive ones.\n\nFor more details about how Cruise Control achieves that, see \n[these slides](https://www.slideshare.net/JiangjieQin/introduction-to-kafka-cruise-control-68180931).\n\n### Configurations for Cruise Control ###\nTo read more about the configurations. Check the \n[configurations wiki page](https://github.com/linkedin/cruise-control/wiki/Configurations).\n\n### Artifactory ###\nPublished at [Jfrog Artifactory](https://linkedin.jfrog.io/linkedin/webapp/#/artifacts/browse/tree/General/cruise-control). See [available releases](https://github.com/linkedin/cruise-control/releases). \n\n### Pluggable Components ###\nMore about pluggable components can be found in the \n[pluggable components wiki page](https://github.com/linkedin/cruise-control/wiki/Pluggable-Components).\n\n#### Metric Sampler #### \nThe metric sampler enables users to deploy Cruise Control to various environments and work with the existing metric systems.\n\nCruise Control provides a metrics reporter that can be configured in your Apache Kafka server. Metrics reporter generates\nperformance metrics to a Kafka metrics topic that can be consumed by Cruise Control.\n\n#### Sample Store ####\nThe Sample Store enables storage of collected metric samples and training samples in an external storage. \n\nMetric sampling uses derived data from the raw metrics, and the accuracy of the derived data depends on the metadata of the cluster at that point.\nHence, when we look at the old metrics, if we do not know the metadata at the point the metric was collected, the derived data would not be accurate.\nSample Store helps solving this problem by storing the derived data directly to an external storage for later loading.\n\nThe default Sample Store implementation produces metric samples back to Kafka.\n\n#### Goals ####\nThe goals in Cruise Control are pluggable with different priorities. The default goals in order of decreasing priority are:\n * **RackAwareGoal** - Ensures that all replicas of each partition are assigned in a rack aware manner -- i.e. no more than one replica of \n each partition resides in the same rack.\n * **RackAwareDistributionGoal** - A relaxed version of `RackAwareGoal`. Contrary to `RackAwareGoal`, as long as replicas of each partition\n can achieve a perfectly even distribution across the racks, this goal lets placement of multiple replicas of a partition into a single rack.\n * **MinTopicLeadersPerBrokerGoal** - Ensures that each alive broker has at least a certain number of leader replica of each topic in a configured set of topics\n * **ReplicaCapacityGoal** - Ensures that the maximum number of replicas per broker is under the specified maximum limit.\n * **DiskCapacityGoal** - Ensures that Disk space usage of each broker is below a given threshold.\n * **NetworkInboundCapacityGoal** - Ensures that inbound network utilization of each broker is below a given threshold.\n * **NetworkOutboundCapacityGoal** - Ensures that outbound network utilization of each broker is below a given threshold.\n * **CpuCapacityGoal** - Ensures that CPU utilization of each broker is below a given threshold.\n * **ReplicaDistributionGoal** - Attempts to make all the brokers in a cluster have a similar number of replicas.\n * **PotentialNwOutGoal** - Ensures that the potential network output (when all the replicas in the broker become leaders) on each of the broker do \n not exceed the broker’s network outbound bandwidth capacity.\n * **DiskUsageDistributionGoal** - Attempts to keep the Disk space usage variance among brokers within a certain range relative to the average Disk utilization.\n * **NetworkInboundUsageDistributionGoal** - Attempts to keep the inbound network utilization variance among brokers within a certain range relative to the average inbound network utilization.\n * **NetworkOutboundUsageDistributionGoal** - Attempts to keep the outbound network utilization variance among brokers within a certain range relative to the average outbound network utilization.\n * **CpuUsageDistributionGoal** - Attempts to keep the CPU usage variance among brokers within a certain range relative to the average CPU utilization.\n * **LeaderReplicaDistributionGoal** - Attempts to make all the brokers in a cluster have a similar number of leader replicas.\n * **LeaderBytesInDistributionGoal** - Attempts to equalize the leader bytes in rate on each host.\n * **TopicReplicaDistributionGoal** - Attempts to maintain an even distribution of any topic's partitions across the entire cluster.\n * **PreferredLeaderElectionGoal** - Simply move the leaders to the first replica of each partition.\n * **KafkaAssignerDiskUsageDistributionGoal** - (Kafka-assigner mode) Attempts to distribute disk usage evenly among brokers based on swap.\n * **IntraBrokerDiskCapacityGoal** - (Rebalance-disk mode, not available in `kafka_0_11_and_1_0` branch) Ensures that Disk space usage of each disk is below a given threshold.\n * **IntraBrokerDiskUsageDistributionGoal** - (Rebalance-disk mode, not available in `kafka_0_11_and_1_0` branch) Attempts to keep the Disk space usage variance among disks within a certain range relative to the average broker Disk utilization.\n\n#### Anomaly Notifier ####\nThe anomaly notifier allows users to be notified when an anomaly is detected. Anomalies include:\n * Broker failure\n * Goal violation\n * Metric anomaly\n * Disk failure (not available in `kafka_0_11_and_1_0` branch)\n * Slow brokers (not available in `kafka_0_11_and_1_0` branch)\n * Topic replication factor anomaly (not available in `kafka_0_11_and_1_0` branch)\n * Topic partition size anomaly (not available in `kafka_0_11_and_1_0` branch)\n * Maintenance Events (not available in `kafka_0_11_and_1_0` branch)\n \nIn addition to anomaly notifications, users can enable actions to be taken in response to an anomaly by turning self-healing\non for the relevant anomaly detectors. Multiple anomaly detectors work in harmony using distinct mitigation mechanisms.\nTheir actions broadly fall into the following categories:\n * **fix** - fix the problem right away (e.g. start a rebalance, fix offline replicas)\n * **check** - check the situation again after a configurable delay (e.g. adopt a grace period before fixing broker failures)\n * **ignore** - ignore the anomaly (e.g. self-healing is disabled)\n"
        },
        {
          "name": "build.gradle",
          "type": "blob",
          "size": 15.2021484375,
          "content": "/*\n * Copyright 2017 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n */\nimport com.linkedin.gradle.build.DistributeTask\n\nplugins {\n  id \"com.jfrog.artifactory\"\n  id \"idea\"\n  id \"jacoco\" // Java Code Coverage plugin\n  id \"com.github.ben-manes.versions\" version \"0.42.0\"\n  id \"com.github.spotbugs\" version \"6.0.6\" apply false\n  id \"checkstyle\"\n  id \"org.openapi.generator\" version \"5.3.0\"\n}\n\ngroup = 'com.linkedin.cruisecontrol'\n\nproject.ext {\n  pomConfig = {\n    url \"https://github.com/linkedin/cruise-control\"\n    licenses {\n      license {\n        name \"BSD 2-CLAUSE LICENSE\"\n        url \"https://opensource.org/licenses/BSD-2-Clause\"\n      }\n    }\n    developers {\n      developer {\n        name \"Adem Efe Gencer\"\n        email \"efegencer@gmail.com\"\n      }\n      developer {\n        name \"Jiangjie (Becket) Qin\"\n        email \"becket.qin@gmail.com\"\n      }\n      developer {\n        name \"Sir Joel Koshy\"\n        email \"jjkoshy@yahoo.com\"\n      }\n    }\n    scm {\n      url \"https://github.com/linkedin/cruise-control\"\n    }\n  }\n  buildVersionFileName = \"cruise-control-version.properties\"\n  commitId = project.hasProperty('commitId') ? commitId : null\n  scalaBinaryVersion = getScalaBinaryVersion(scalaVersion)\n}\n\nallprojects {\n\n  repositories {\n    mavenCentral()\n  }\n\n  apply plugin: 'com.github.ben-manes.versions'\n\n  dependencyUpdates {\n    revision=\"release\"\n    resolutionStrategy {\n      componentSelection { rules ->\n        rules.all { ComponentSelection selection ->\n          boolean rejected = ['snap', 'alpha', 'beta', 'rc', 'cr', 'm'].any { qualifier ->\n            selection.candidate.version ==~ /(?i).*[.-]${qualifier}[.\\d-]*/\n          }\n          if (rejected) {\n            selection.reject('Release candidate')\n          }\n        }\n      }\n    }\n  }\n}\n\nsubprojects {\n  group = rootProject.group\n  version = rootProject.version\n\n  apply plugin: 'java'\n  apply plugin: 'java-library'\n  apply plugin: 'checkstyle'\n  apply plugin: 'maven-publish'\n  apply plugin: \"com.github.spotbugs\"\n  apply plugin: 'jacoco'\n\n  // This project requires Java 11\n  sourceCompatibility = JavaVersion.VERSION_11\n\n  task sourcesJar(type: Jar, dependsOn: classes) {\n    archiveClassifier.set(\"sources\")\n    from sourceSets.main.allSource\n  }\n\n  task javadocJar(type: Jar, dependsOn: javadoc) {\n    archiveClassifier.set(\"javadoc\")\n    from javadoc.destinationDir\n  }\n\n  //code quality and inspections\n  checkstyle {\n    toolVersion = '10.0'\n    ignoreFailures = false\n    configDirectory = file(\"$rootDir/checkstyle\")\n  }\n\n  spotbugs {\n    toolVersion = '4.7.1'\n    excludeFilter = file(\"$rootDir/gradle/findbugs-exclude.xml\")\n    ignoreFailures = false\n    jvmArgs = [ '-Xms512m' ]\n    maxHeapSize = '768m'\n    showProgress = true\n  }\n  spotbugsMain {\n    reports {\n      xml.enabled = (project.hasProperty('xmlFindBugsReport'))\n      html.enabled = (!project.hasProperty('xmlFindBugsReport'))\n    }\n  }\n  spotbugsTest {\n    reports {\n      xml.enabled = (project.hasProperty('xmlFindBugsReport'))\n      html.enabled = (!project.hasProperty('xmlFindBugsReport'))\n    }\n  }\n  // aggregated task for checkstyle and spotbugs static analyzers\n  task('analyze') {\n    dependsOn('checkstyleMain', 'checkstyleTest', 'spotbugsMain', 'spotbugsTest')\n    doLast {}\n  }\n\n  test.dependsOn('checkstyleMain', 'checkstyleTest', 'spotbugsMain', 'spotbugsTest')\n\n  jar {\n    from \"$rootDir/LICENSE\"\n    from \"$rootDir/NOTICE\"\n  }\n\n  test {\n    useJUnit {}\n    testLogging {\n      events \"passed\", \"failed\", \"skipped\"\n      exceptionFormat = 'full'\n    }\n    if (!project.hasProperty(\"maxParallelForks\")) {\n      maxParallelForks = Runtime.runtime.availableProcessors()\n    }\n    finalizedBy jacocoTestReport\n  }\n\n  jacocoTestReport {\n    reports {\n      xml.required = false\n      csv.required = false\n      html.outputLocation = layout.buildDirectory.dir('jacocoHtml')\n    }\n  }\n}\n\nproject(':cruise-control-core') {\n  apply plugin: 'maven-publish'\n  apply plugin: 'com.jfrog.artifactory'\n\n  configurations {\n    testOutput\n  }\n\n  dependencies {\n    configurations.all {\n      exclude group: 'org.slf4j', module: 'slf4j-log4j12'\n      exclude group: 'log4j', module: 'log4j'\n      exclude group: 'ch.qos.logback'\n    }\n    implementation \"org.slf4j:slf4j-api:1.7.36\"\n    implementation \"org.apache.logging.log4j:log4j-slf4j-impl:2.17.2\"\n    implementation 'org.apache.commons:commons-math3:3.6.1'\n    api \"org.eclipse.jetty:jetty-servlet:${jettyVersion}\"\n    implementation 'com.google.code.findbugs:jsr305:3.0.2'\n\n    api \"io.vertx:vertx-core:${vertxVersion}\"\n    api \"io.vertx:vertx-web:${vertxVersion}\"\n\n    testImplementation 'junit:junit:4.13.2'\n\n    testOutput sourceSets.test.output\n  }\n\n  publishing {\n    publications {\n      java(MavenPublication) {\n        from components.java\n        artifact sourcesJar\n        artifact javadocJar\n        pom.withXml {\n          def root = asNode()\n          root.appendNode('name', 'cruise-control-core')\n          root.appendNode('description', 'cruise control core related')\n          root.children().last() + rootProject.ext.pomConfig\n        }\n      }\n    }\n  }\n\n  artifactoryPublish.dependsOn assemble\n  artifactoryPublish.dependsOn publishToMavenLocal\n\n  sourceSets {\n    main {\n      java {\n        srcDirs = ['src/main/java']\n      }\n    }\n    test {\n      java {\n        srcDirs = ['src/test/java']\n      }\n    }\n\n  }\n\n}\n\nproject(':cruise-control') {\n  apply plugin: 'scala'\n  apply plugin: 'maven-publish'\n  apply plugin: 'com.jfrog.artifactory'\n\n  //needed because our java classes depend on scala classes, so must be compiled by scala\n  sourceSets {\n    main {\n      java {\n        srcDirs = []\n      }\n\n      scala {\n        srcDirs = ['src/main/java', 'src/main/scala']\n      }\n    }\n\n    test {\n      java {\n        srcDirs = []\n      }\n      scala {\n        srcDirs = ['src/test/java', 'src/test/scala']\n      }\n    }\n\n    integrationTest {\n      java {\n        srcDirs = [\"src/integrationTest/java\"]\n      }\n      resources {\n        srcDirs = ['src/integrationTest/resources']\n      }\n      compileClasspath += main.output + test.output\n      runtimeClasspath += main.output + test.output\n    }\n\n  }\n\n  configurations {\n    integrationTestImplementation.extendsFrom testImplementation\n    integrationTestRuntime.extendsFrom testRuntime\n   }\n\n  dependencies {\n    configurations.all {\n      exclude group: 'org.slf4j', module: 'slf4j-log4j12'\n      exclude group: 'log4j', module: 'log4j'\n      exclude group: 'ch.qos.logback'\n    }\n\n    api project(':cruise-control-metrics-reporter')\n    api project(':cruise-control-core')\n    implementation \"org.slf4j:slf4j-api:1.7.36\"\n    implementation \"org.apache.logging.log4j:log4j-slf4j-impl:2.17.2\"\n    implementation \"org.apache.zookeeper:zookeeper:${zookeeperVersion}\"\n    implementation \"io.netty:netty-handler:${nettyVersion}\"\n    implementation \"io.netty:netty-transport-native-epoll:${nettyVersion}\"\n    api \"org.apache.kafka:kafka_$scalaBinaryVersion:$kafkaVersion\"\n    api \"org.apache.kafka:kafka-clients:$kafkaVersion\"\n    // Add following dependency when upgrading to Kafka 3.5\n    api \"org.apache.kafka:kafka-storage:$kafkaVersion\"\n    implementation \"org.scala-lang:scala-library:$scalaVersion\"\n    implementation 'org.apache.commons:commons-math3:3.6.1'\n    implementation 'org.apache.httpcomponents:httpclient:4.5.13'\n    implementation 'commons-codec:commons-codec:1.15'\n    implementation 'com.google.code.gson:gson:2.9.0'\n    implementation \"org.eclipse.jetty:jetty-server:${jettyVersion}\"\n    implementation 'io.dropwizard.metrics:metrics-jmx:4.2.9'\n    implementation 'com.nimbusds:nimbus-jose-jwt:9.45'\n    implementation 'io.swagger.parser.v3:swagger-parser-v3:2.1.16'\n    implementation 'io.github.classgraph:classgraph:4.8.141'\n    implementation 'com.google.code.findbugs:jsr305:3.0.2'\n    // Temporary pin for vulnerability\n    implementation 'com.fasterxml.jackson.core:jackson-databind:2.15.2'\n    api \"io.vertx:vertx-web-openapi:${vertxVersion}\"\n    api \"io.vertx:vertx-core:${vertxVersion}\"\n    api \"io.vertx:vertx-web:${vertxVersion}\"\n    api \"io.vertx:vertx-junit5:${vertxVersion}\"\n    api 'io.swagger.core.v3:swagger-annotations:2.0.2'\n    api 'io.swagger.core.v3:swagger-core:2.0.2'\n    api 'com.google.guava:guava:32.1.3-jre'\n    api 'org.json:json:20231013'\n    api 'org.xerial.snappy:snappy-java:1.1.10.5'\n\n    testImplementation project(path: ':cruise-control-metrics-reporter', configuration: 'testOutput')\n    testImplementation project(path: ':cruise-control-core', configuration: 'testOutput')\n    testImplementation \"org.scala-lang:scala-library:$scalaVersion\"\n    testImplementation 'junit:junit:4.13.2'\n    testImplementation 'org.easymock:easymock:4.3'\n    testImplementation \"org.apache.kafka:kafka_$scalaBinaryVersion:$kafkaVersion:test\"\n    testImplementation \"org.apache.kafka:kafka-clients:$kafkaVersion:test\"\n    testImplementation 'commons-io:commons-io:2.11.0'\n    testImplementation 'org.apache.httpcomponents:httpclient:4.5.13:tests'\n    testImplementation 'org.bouncycastle:bcpkix-jdk15on:1.70'\n    testImplementation 'org.apache.kerby:kerb-simplekdc:2.1.0'\n    testImplementation 'com.jayway.jsonpath:json-path:2.7.0'\n    testImplementation 'org.powermock:powermock-module-junit4:2.0.9'\n    testImplementation 'org.powermock:powermock-api-easymock:2.0.9'\n  }\n\n  publishing {\n    publications {\n      java(MavenPublication) {\n        from components.java\n        artifact sourcesJar\n        artifact javadocJar\n        pom.withXml {\n          def root = asNode()\n          root.appendNode('name', 'cruise-control')\n          root.appendNode('description', 'cruise control related')\n          root.children().last() + rootProject.ext.pomConfig\n        }\n      }\n    }\n  }\n\n  artifactoryPublish.dependsOn assemble\n  artifactoryPublish.dependsOn publishToMavenLocal\n\n  tasks.create(name: \"copyDependantLibs\", type: Copy) {\n    from (configurations.testRuntimeClasspath) {\n      include('log4j-slf4j-impl*')\n    }\n    from (configurations.runtimeClasspath) {\n\n    }\n    into \"$buildDir/dependant-libs\"\n    duplicatesStrategy 'exclude'\n  }\n\n  tasks.create(name: \"buildFatJar\", type: Jar, dependsOn: [\"createVersionFile\", \":cruise-control-metrics-reporter:jar\", \":cruise-control-core:jar\"]) {\n    archiveBaseName = project.name + '-all'\n    duplicatesStrategy = DuplicatesStrategy.INCLUDE\n    from { configurations.runtimeClasspath.collect { it.isDirectory() ? it : zipTree(it) } }\n    manifest {\n      attributes(\"Multi-Release\": true)\n    }\n    with jar\n  }\n\n  compileScala.finalizedBy(tasks.copyDependantLibs)\n\n  task determineCommitId {\n    def takeFromHash = 40\n    if (commitId) {\n      commitId = commitId.take(takeFromHash)\n    } else if (file(\"$rootDir/.git/HEAD\").exists()) {\n      def headRef = file(\"$rootDir/.git/HEAD\").text\n      if (headRef.contains('ref: ')) {\n        headRef = headRef.replaceAll('ref: ', '').trim()\n        if (file(\"$rootDir/.git/$headRef\").exists()) {\n          commitId = file(\"$rootDir/.git/$headRef\").text.trim().take(takeFromHash)\n        }\n      } else {\n        commitId = headRef.trim().take(takeFromHash)\n      }\n    } else {\n      commitId = \"unknown\"\n    }\n  }\n\n  // Referenced similar method for getting software version in Kafka code.\n  task createVersionFile(dependsOn: determineCommitId) {\n    ext.receiptFile = file(\"$buildDir/cruise-control/$buildVersionFileName\")\n    outputs.file receiptFile\n    outputs.upToDateWhen { false }\n    doLast {\n      def data = [\n          commitId: commitId,\n          version: version,\n      ]\n\n      receiptFile.parentFile.mkdirs()\n      def content = data.entrySet().collect { \"$it.key=$it.value\" }.sort().join(\"\\n\")\n      receiptFile.setText(content, \"ISO-8859-1\")\n    }\n  }\n\n  task integrationTest(type: Test) {\n    testClassesDirs = sourceSets.integrationTest.output.classesDirs\n    classpath = sourceSets.integrationTest.runtimeClasspath\n    testLogging {\n      events \"passed\", \"failed\", \"skipped\"\n      exceptionFormat = 'full'\n    }\n  }\n\n  compileIntegrationTestJava.dependsOn copyDependantLibs\n\n  jar {\n    dependsOn createVersionFile\n    from(\"$buildDir\") {\n      include \"cruise-control/$buildVersionFileName\"\n    }\n  }\n\n  task generateOpenApiJson(type: org.openapitools.generator.gradle.plugin.tasks.GenerateTask) {\n    inputSpec = \"$rootDir/cruise-control/src/main/resources/yaml/base.yaml\"\n    generatorName = \"openapi\"\n    outputDir = \"$rootDir/cruise-control/src/main/resources/webroot\"\n  }\n\n  processResources.dependsOn generateOpenApiJson\n  compileJava.dependsOn generateOpenApiJson\n}\n\nproject(':cruise-control-metrics-reporter') {\n  apply plugin: 'maven-publish'\n  apply plugin: 'com.jfrog.artifactory'\n\n  configurations {\n    testOutput\n  }\n\n  dependencies {\n    configurations.all {\n      exclude group: 'org.slf4j', module: 'slf4j-log4j12'\n      exclude group: 'log4j', module: 'log4j'\n      exclude group: 'ch.qos.logback'\n    }\n\n    implementation \"org.slf4j:slf4j-api:1.7.36\"\n    implementation \"com.yammer.metrics:metrics-core:2.2.0\"\n    implementation \"org.apache.logging.log4j:log4j-slf4j-impl:2.17.2\"\n    implementation \"org.apache.kafka:kafka_$scalaBinaryVersion:$kafkaVersion\"\n    implementation \"org.apache.kafka:kafka-clients:$kafkaVersion\"\n    implementation 'com.google.code.findbugs:jsr305:3.0.2'\n    // Temporary pin for vulnerability\n    implementation 'com.fasterxml.jackson.core:jackson-databind:2.15.2'\n\n    testImplementation 'junit:junit:4.13.2'\n    testImplementation 'org.bouncycastle:bcpkix-jdk15on:1.70'\n    testImplementation 'org.powermock:powermock-module-junit4:2.0.9'\n    testImplementation 'org.powermock:powermock-api-easymock:2.0.9'\n    testImplementation \"org.apache.kafka:kafka-clients:$kafkaVersion:test\"\n    testImplementation \"org.apache.kafka:kafka-clients:$kafkaVersion\"\n    testImplementation 'commons-io:commons-io:2.11.0'\n    testImplementation \"org.apache.zookeeper:zookeeper:${zookeeperVersion}\"\n    testOutput sourceSets.test.output\n  }\n\n  publishing {\n    publications {\n      java(MavenPublication) {\n        from components.java\n        artifact sourcesJar\n        artifact javadocJar\n        pom.withXml {\n          def root = asNode()\n          root.appendNode('name', 'cruise-control-metrics-reporter')\n          root.appendNode('description', 'cruise control metrics reporter related')\n          root.children().last() + rootProject.ext.pomConfig\n        }\n      }\n    }\n  }\n\n  artifactoryPublish.dependsOn assemble\n  artifactoryPublish.dependsOn publishToMavenLocal\n\n}\n\nartifactoryPublish.skip = true\nartifactory {\n  contextUrl = 'https://linkedin.jfrog.io/linkedin'\n  publish {\n    repoKey = 'cruise-control'\n    username = System.getenv('ARTIFACTORY_USER')\n    password = System.getenv('ARTIFACTORY_KEY')\n\n    defaults {\n      publications ('java')\n      publishBuildInfo = true\n      publishArtifacts = true\n      publishPom = true\n      publishIvy = true\n    }\n  }\n  clientConfig.setIncludeEnvVars(false)\n}\n\ntask distributeBuild(type: DistributeTask) {\n  dependsOn ':artifactoryPublish', ':cruise-control:artifactoryPublish', ':cruise-control-core:artifactoryPublish', ':cruise-control-metrics-reporter:artifactoryPublish'\n}\n\ntask buildApiWiki(type: Exec) {\n  workingDir '.'\n  commandLine './build_api_wiki.sh'\n}\n\nstatic def getScalaBinaryVersion(versionStr) {\n  String[] versionList = versionStr.split(\"\\\\.\")\n  return versionList[0] + \".\" + versionList[1]\n}\n\n//wrapper generation task\nwrapper {\n  gradleVersion = '8.5'\n  distributionType = Wrapper.DistributionType.ALL\n}\n"
        },
        {
          "name": "buildSrc",
          "type": "tree",
          "content": null
        },
        {
          "name": "build_api_wiki.sh",
          "type": "blob",
          "size": 0.2939453125,
          "content": "#!/bin/bash\n\nset -e\n\nBASE_DIR=$(pwd)\nSCHEMA_WORKDIR=\"$BASE_DIR/cruise-control/src/main/resources/yaml\"\nWIKI_TARGET=\"$BASE_DIR/target/api_wiki\"\n\nrm -rf \"$WIKI_TARGET\"\nmkdir -p \"$WIKI_TARGET\"\n\ncd \"$SCHEMA_WORKDIR\"; npx redoc-cli bundle base.yaml\nmv -v \"$SCHEMA_WORKDIR\"/redoc-static.html \"$WIKI_TARGET\"\n"
        },
        {
          "name": "checkstyle",
          "type": "tree",
          "content": null
        },
        {
          "name": "config",
          "type": "tree",
          "content": null
        },
        {
          "name": "cruise-control-client",
          "type": "tree",
          "content": null
        },
        {
          "name": "cruise-control-core",
          "type": "tree",
          "content": null
        },
        {
          "name": "cruise-control-metrics-reporter",
          "type": "tree",
          "content": null
        },
        {
          "name": "cruise-control",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "fileStore",
          "type": "tree",
          "content": null
        },
        {
          "name": "gradle.properties",
          "type": "blob",
          "size": 0.220703125,
          "content": "org.gradle.daemon=false\norg.gradle.parallel=false\norg.gradle.jvmargs=-Xms512m -Xmx512m\nscalaVersion=2.13.13\nkafkaVersion=3.5.1\nzookeeperVersion=3.9.3\nnettyVersion=4.1.114.Final\njettyVersion=9.4.56.v20240826\nvertxVersion=4.5.8\n"
        },
        {
          "name": "gradle",
          "type": "tree",
          "content": null
        },
        {
          "name": "gradlew",
          "type": "blob",
          "size": 8.4873046875,
          "content": "#!/bin/sh\n\n#\n# Copyright © 2015-2021 the original authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n##############################################################################\n#\n#   Gradle start up script for POSIX generated by Gradle.\n#\n#   Important for running:\n#\n#   (1) You need a POSIX-compliant shell to run this script. If your /bin/sh is\n#       noncompliant, but you have some other compliant shell such as ksh or\n#       bash, then to run this script, type that shell name before the whole\n#       command line, like:\n#\n#           ksh Gradle\n#\n#       Busybox and similar reduced shells will NOT work, because this script\n#       requires all of these POSIX shell features:\n#         * functions;\n#         * expansions «$var», «${var}», «${var:-default}», «${var+SET}»,\n#           «${var#prefix}», «${var%suffix}», and «$( cmd )»;\n#         * compound commands having a testable exit status, especially «case»;\n#         * various built-in commands including «command», «set», and «ulimit».\n#\n#   Important for patching:\n#\n#   (2) This script targets any POSIX shell, so it avoids extensions provided\n#       by Bash, Ksh, etc; in particular arrays are avoided.\n#\n#       The \"traditional\" practice of packing multiple parameters into a\n#       space-separated string is a well documented source of bugs and security\n#       problems, so this is (mostly) avoided, by progressively accumulating\n#       options in \"$@\", and eventually passing that to Java.\n#\n#       Where the inherited environment variables (DEFAULT_JVM_OPTS, JAVA_OPTS,\n#       and GRADLE_OPTS) rely on word-splitting, this is performed explicitly;\n#       see the in-line comments for details.\n#\n#       There are tweaks for specific operating systems such as AIX, CygWin,\n#       Darwin, MinGW, and NonStop.\n#\n#   (3) This script is generated from the Groovy template\n#       https://github.com/gradle/gradle/blob/HEAD/subprojects/plugins/src/main/resources/org/gradle/api/internal/plugins/unixStartScript.txt\n#       within the Gradle project.\n#\n#       You can find Gradle at https://github.com/gradle/gradle/.\n#\n##############################################################################\n\n# Attempt to set APP_HOME\n\n# Resolve links: $0 may be a link\napp_path=$0\n\n# Need this for daisy-chained symlinks.\nwhile\n    APP_HOME=${app_path%\"${app_path##*/}\"}  # leaves a trailing /; empty if no leading path\n    [ -h \"$app_path\" ]\ndo\n    ls=$( ls -ld \"$app_path\" )\n    link=${ls#*' -> '}\n    case $link in             #(\n      /*)   app_path=$link ;; #(\n      *)    app_path=$APP_HOME$link ;;\n    esac\ndone\n\n# This is normally unused\n# shellcheck disable=SC2034\nAPP_BASE_NAME=${0##*/}\n# Discard cd standard output in case $CDPATH is set (https://github.com/gradle/gradle/issues/25036)\nAPP_HOME=$( cd \"${APP_HOME:-./}\" > /dev/null && pwd -P ) || exit\n\n# Use the maximum available, or set MAX_FD != -1 to use that value.\nMAX_FD=maximum\n\nwarn () {\n    echo \"$*\"\n} >&2\n\ndie () {\n    echo\n    echo \"$*\"\n    echo\n    exit 1\n} >&2\n\n# OS specific support (must be 'true' or 'false').\ncygwin=false\nmsys=false\ndarwin=false\nnonstop=false\ncase \"$( uname )\" in                #(\n  CYGWIN* )         cygwin=true  ;; #(\n  Darwin* )         darwin=true  ;; #(\n  MSYS* | MINGW* )  msys=true    ;; #(\n  NONSTOP* )        nonstop=true ;;\nesac\n\nCLASSPATH=$APP_HOME/gradle/wrapper/gradle-wrapper.jar\n\n\n# Determine the Java command to use to start the JVM.\nif [ -n \"$JAVA_HOME\" ] ; then\n    if [ -x \"$JAVA_HOME/jre/sh/java\" ] ; then\n        # IBM's JDK on AIX uses strange locations for the executables\n        JAVACMD=$JAVA_HOME/jre/sh/java\n    else\n        JAVACMD=$JAVA_HOME/bin/java\n    fi\n    if [ ! -x \"$JAVACMD\" ] ; then\n        die \"ERROR: JAVA_HOME is set to an invalid directory: $JAVA_HOME\n\nPlease set the JAVA_HOME variable in your environment to match the\nlocation of your Java installation.\"\n    fi\nelse\n    JAVACMD=java\n    if ! command -v java >/dev/null 2>&1\n    then\n        die \"ERROR: JAVA_HOME is not set and no 'java' command could be found in your PATH.\n\nPlease set the JAVA_HOME variable in your environment to match the\nlocation of your Java installation.\"\n    fi\nfi\n\n# Increase the maximum file descriptors if we can.\nif ! \"$cygwin\" && ! \"$darwin\" && ! \"$nonstop\" ; then\n    case $MAX_FD in #(\n      max*)\n        # In POSIX sh, ulimit -H is undefined. That's why the result is checked to see if it worked.\n        # shellcheck disable=SC2039,SC3045\n        MAX_FD=$( ulimit -H -n ) ||\n            warn \"Could not query maximum file descriptor limit\"\n    esac\n    case $MAX_FD in  #(\n      '' | soft) :;; #(\n      *)\n        # In POSIX sh, ulimit -n is undefined. That's why the result is checked to see if it worked.\n        # shellcheck disable=SC2039,SC3045\n        ulimit -n \"$MAX_FD\" ||\n            warn \"Could not set maximum file descriptor limit to $MAX_FD\"\n    esac\nfi\n\n# Collect all arguments for the java command, stacking in reverse order:\n#   * args from the command line\n#   * the main class name\n#   * -classpath\n#   * -D...appname settings\n#   * --module-path (only if needed)\n#   * DEFAULT_JVM_OPTS, JAVA_OPTS, and GRADLE_OPTS environment variables.\n\n# For Cygwin or MSYS, switch paths to Windows format before running java\nif \"$cygwin\" || \"$msys\" ; then\n    APP_HOME=$( cygpath --path --mixed \"$APP_HOME\" )\n    CLASSPATH=$( cygpath --path --mixed \"$CLASSPATH\" )\n\n    JAVACMD=$( cygpath --unix \"$JAVACMD\" )\n\n    # Now convert the arguments - kludge to limit ourselves to /bin/sh\n    for arg do\n        if\n            case $arg in                                #(\n              -*)   false ;;                            # don't mess with options #(\n              /?*)  t=${arg#/} t=/${t%%/*}              # looks like a POSIX filepath\n                    [ -e \"$t\" ] ;;                      #(\n              *)    false ;;\n            esac\n        then\n            arg=$( cygpath --path --ignore --mixed \"$arg\" )\n        fi\n        # Roll the args list around exactly as many times as the number of\n        # args, so each arg winds up back in the position where it started, but\n        # possibly modified.\n        #\n        # NB: a `for` loop captures its iteration list before it begins, so\n        # changing the positional parameters here affects neither the number of\n        # iterations, nor the values presented in `arg`.\n        shift                   # remove old arg\n        set -- \"$@\" \"$arg\"      # push replacement arg\n    done\nfi\n\n\n# Add default JVM options here. You can also use JAVA_OPTS and GRADLE_OPTS to pass JVM options to this script.\nDEFAULT_JVM_OPTS='\"-Xmx64m\" \"-Xms64m\"'\n\n# Collect all arguments for the java command:\n#   * DEFAULT_JVM_OPTS, JAVA_OPTS, JAVA_OPTS, and optsEnvironmentVar are not allowed to contain shell fragments,\n#     and any embedded shellness will be escaped.\n#   * For example: A user cannot expect ${Hostname} to be expanded, as it is an environment variable and will be\n#     treated as '${Hostname}' itself on the command line.\n\nset -- \\\n        \"-Dorg.gradle.appname=$APP_BASE_NAME\" \\\n        -classpath \"$CLASSPATH\" \\\n        org.gradle.wrapper.GradleWrapperMain \\\n        \"$@\"\n\n# Stop when \"xargs\" is not available.\nif ! command -v xargs >/dev/null 2>&1\nthen\n    die \"xargs is not available\"\nfi\n\n# Use \"xargs\" to parse quoted args.\n#\n# With -n1 it outputs one arg per line, with the quotes and backslashes removed.\n#\n# In Bash we could simply go:\n#\n#   readarray ARGS < <( xargs -n1 <<<\"$var\" ) &&\n#   set -- \"${ARGS[@]}\" \"$@\"\n#\n# but POSIX shell has neither arrays nor command substitution, so instead we\n# post-process each arg (as a line of input to sed) to backslash-escape any\n# character that might be a shell metacharacter, then use eval to reverse\n# that process (while maintaining the separation between arguments), and wrap\n# the whole thing up as a single \"set\" statement.\n#\n# This will of course break if any of these variables contains a newline or\n# an unmatched quote.\n#\n\neval \"set -- $(\n        printf '%s\\n' \"$DEFAULT_JVM_OPTS $JAVA_OPTS $GRADLE_OPTS\" |\n        xargs -n1 |\n        sed ' s~[^-[:alnum:]+,./:=@_]~\\\\&~g; ' |\n        tr '\\n' ' '\n    )\" '\"$@\"'\n\nexec \"$JAVACMD\" \"$@\""
        },
        {
          "name": "gradlew.bat",
          "type": "blob",
          "size": 2.6982421875,
          "content": "@rem\r\n@rem Copyright 2015 the original author or authors.\r\n@rem\r\n@rem Licensed under the Apache License, Version 2.0 (the \"License\");\r\n@rem you may not use this file except in compliance with the License.\r\n@rem You may obtain a copy of the License at\r\n@rem\r\n@rem      https://www.apache.org/licenses/LICENSE-2.0\r\n@rem\r\n@rem Unless required by applicable law or agreed to in writing, software\r\n@rem distributed under the License is distributed on an \"AS IS\" BASIS,\r\n@rem WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n@rem See the License for the specific language governing permissions and\r\n@rem limitations under the License.\r\n@rem\r\n\r\n@if \"%DEBUG%\" == \"\" @echo off\r\n@rem ##########################################################################\r\n@rem\r\n@rem  Gradle startup script for Windows\r\n@rem\r\n@rem ##########################################################################\r\n\r\n@rem Set local scope for the variables with windows NT shell\r\nif \"%OS%\"==\"Windows_NT\" setlocal\r\n\r\nset DIRNAME=%~dp0\r\nif \"%DIRNAME%\" == \"\" set DIRNAME=.\r\nset APP_BASE_NAME=%~n0\r\nset APP_HOME=%DIRNAME%\r\n\r\n@rem Resolve any \".\" and \"..\" in APP_HOME to make it shorter.\r\nfor %%i in (\"%APP_HOME%\") do set APP_HOME=%%~fi\r\n\r\n@rem Add default JVM options here. You can also use JAVA_OPTS and GRADLE_OPTS to pass JVM options to this script.\r\nset DEFAULT_JVM_OPTS=\"-Xmx64m\" \"-Xms64m\"\r\n\r\n@rem Find java.exe\r\nif defined JAVA_HOME goto findJavaFromJavaHome\r\n\r\nset JAVA_EXE=java.exe\r\n%JAVA_EXE% -version >NUL 2>&1\r\nif \"%ERRORLEVEL%\" == \"0\" goto execute\r\n\r\necho.\r\necho ERROR: JAVA_HOME is not set and no 'java' command could be found in your PATH.\r\necho.\r\necho Please set the JAVA_HOME variable in your environment to match the\r\necho location of your Java installation.\r\n\r\ngoto fail\r\n\r\n:findJavaFromJavaHome\r\nset JAVA_HOME=%JAVA_HOME:\"=%\r\nset JAVA_EXE=%JAVA_HOME%/bin/java.exe\r\n\r\nif exist \"%JAVA_EXE%\" goto execute\r\n\r\necho.\r\necho ERROR: JAVA_HOME is set to an invalid directory: %JAVA_HOME%\r\necho.\r\necho Please set the JAVA_HOME variable in your environment to match the\r\necho location of your Java installation.\r\n\r\ngoto fail\r\n\r\n:execute\r\n@rem Setup the command line\r\n\r\nset CLASSPATH=%APP_HOME%\\gradle\\wrapper\\gradle-wrapper.jar\r\n\r\n\r\n@rem Execute Gradle\r\n\"%JAVA_EXE%\" %DEFAULT_JVM_OPTS% %JAVA_OPTS% %GRADLE_OPTS% \"-Dorg.gradle.appname=%APP_BASE_NAME%\" -classpath \"%CLASSPATH%\" org.gradle.wrapper.GradleWrapperMain %*\r\n\r\n:end\r\n@rem End local scope for the variables with windows NT shell\r\nif \"%ERRORLEVEL%\"==\"0\" goto mainEnd\r\n\r\n:fail\r\nrem Set variable GRADLE_EXIT_CONSOLE if you need the _script_ return code instead of\r\nrem the _cmd.exe /c_ return code!\r\nif  not \"\" == \"%GRADLE_EXIT_CONSOLE%\" exit 1\r\nexit /b 1\r\n\r\n:mainEnd\r\nif \"%OS%\"==\"Windows_NT\" endlocal\r\n\r\n:omega\r\n"
        },
        {
          "name": "kafka-cruise-control-start.sh",
          "type": "blob",
          "size": 5.2109375,
          "content": "#!/bin/bash\n# Copyright 2017 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\").\n# See License in the project root for license information.\n\nif [ $# -lt 1 ];\nthen\n  echo \"USAGE: $0 [-daemon] [-name servicename] [-loggc] [-jars jar_path] config_path [port]\"\n  exit 1\nfi\n\n# CYGINW == 1 if Cygwin is detected, else 0.\nif [[ $(uname -a) =~ \"CYGWIN\" ]]; then\n  CYGWIN=1\nelse\n  CYGWIN=0\nfi\n\ncopyJars() {\n  if [ -z $1 ]; then\n    return 0\n  fi\n  files=$1\n  jars=(${files//,/ })\n  for usrJar in ${jars[@]};\n  do\n    cp $usrJar \"$base_dir\"/cruise-control/build/dependant-libs/\n  done\n}\n\nbase_dir=$(dirname $0)\n\nif [ -z \"$SCALA_VERSION\" ]; then\n  SCALA_VERSION=2.13.6\nfi\n\nif [ -z \"$SCALA_BINARY_VERSION\" ]; then\n  SCALA_BINARY_VERSION=$(echo $SCALA_VERSION | cut -f 1-2 -d '.')\nfi\n\n# run ./gradlew copyDependantLibs to get all dependant jars in a local dir\nshopt -s nullglob\nfor dir in \"$base_dir\"/cruise-control/build/dependant-libs;\ndo\n  if [ -z \"$CLASSPATH\" ] ; then\n    CLASSPATH=\"$dir/*\"\n  else\n    CLASSPATH=\"$CLASSPATH:$dir/*\"\n  fi\ndone\n\nif [ -z \"$CLASSPATH\" ]; then\n  CLASSPATH=\"$base_dir/cruise-control/build/libs/*\"\nelse\n  CLASSPATH=\"$CLASSPATH:$base_dir/cruise-control/build/libs/*\"\nfi\n\nif [ -z \"$CLASSPATH\" ]; then\n  CLASSPATH=\"$base_dir/cruise-control-metrics-reporter/build/libs/*\"\nelse\n  CLASSPATH=\"$CLASSPATH:$base_dir/cruise-control-metrics-reporter/build/libs/*\"\nfi\nshopt -u nullglob\n\n# JMX settings\nif [ -z \"$KAFKA_JMX_OPTS\" ]; then\n  KAFKA_JMX_OPTS=\"-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false  -Dcom.sun.management.jmxremote.ssl=false \"\nfi\n\n# JMX port to use\nif [  $JMX_PORT ]; then\n  KAFKA_JMX_OPTS=\"$KAFKA_JMX_OPTS -Dcom.sun.management.jmxremote.port=$JMX_PORT \"\nfi\n\n# Log directory to use\nif [ \"x$LOG_DIR\" = \"x\" ]; then\n  LOG_DIR=\"$base_dir/logs\"\nfi\n\n# Log4j settings\nif [ -z \"$KAFKA_LOG4J_OPTS\" ]; then\n  # Log to console. This is a tool.\n  LOG4J_DIR=\"$base_dir/config/log4j.properties\"\n  # If Cygwin is detected, LOG4J_DIR is converted to Windows format.\n  (( CYGWIN )) && LOG4J_DIR=$(cygpath --path --mixed \"${LOG4J_DIR}\")\n  KAFKA_LOG4J_OPTS=\"-Dlog4j.configurationFile=file:${LOG4J_DIR}\"\nelse\n  # create logs directory\n  if [ ! -d \"$LOG_DIR\" ]; then\n    mkdir -p \"$LOG_DIR\"\n  fi\nfi\n\n# If Cygwin is detected, LOG_DIR is converted to Windows format.\n(( CYGWIN )) && LOG_DIR=$(cygpath --path --mixed \"${LOG_DIR}\")\nKAFKA_LOG4J_OPTS=\"-Dkafka.logs.dir=$LOG_DIR $KAFKA_LOG4J_OPTS\"\n\n# Generic jvm settings you want to add\nif [ -z \"$KAFKA_OPTS\" ]; then\n  KAFKA_OPTS=\"\"\nfi\n\n# Set Debug options if enabled\nif [ \"x$KAFKA_DEBUG\" != \"x\" ]; then\n\n    # Use default ports\n    DEFAULT_JAVA_DEBUG_PORT=\"5005\"\n\n    if [ -z \"$JAVA_DEBUG_PORT\" ]; then\n        JAVA_DEBUG_PORT=\"$DEFAULT_JAVA_DEBUG_PORT\"\n    fi\n\n    # Use the defaults if JAVA_DEBUG_OPTS was not set\n    DEFAULT_JAVA_DEBUG_OPTS=\"-agentlib:jdwp=transport=dt_socket,server=y,suspend=${DEBUG_SUSPEND_FLAG:-n},address=$JAVA_DEBUG_PORT\"\n    if [ -z \"$JAVA_DEBUG_OPTS\" ]; then\n        JAVA_DEBUG_OPTS=\"$DEFAULT_JAVA_DEBUG_OPTS\"\n    fi\n\n    echo \"Enabling Java debug options: $JAVA_DEBUG_OPTS\"\n    KAFKA_OPTS=\"$JAVA_DEBUG_OPTS $KAFKA_OPTS\"\nfi\n\n# Which java to use\nif [ -z \"$JAVA_HOME\" ]; then\n  JAVA=\"java\"\nelse\n  JAVA=\"$JAVA_HOME/bin/java\"\nfi\n\n# Memory options\nif [ -z \"$KAFKA_HEAP_OPTS\" ]; then\n  KAFKA_HEAP_OPTS=\"-Xmx1G\"\nfi\n\n# JVM performance options\nif [ -z \"$KAFKA_JVM_PERFORMANCE_OPTS\" ]; then\n  KAFKA_JVM_PERFORMANCE_OPTS=\"-server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+DisableExplicitGC -Djava.awt.headless=true\"\nfi\n\n#Add jaas file to KAFKA_OPTS if present\nif [ -f $base_dir/config/cruise_control_jaas.conf ]\nthen\n  KAFKA_OPTS=\"-Djava.security.auth.login.config=$base_dir/config/cruise_control_jaas.conf $KAFKA_OPTS\"\nfi\n\nDAEMON_NAME=\"kafka-cruise-control\"\nCONSOLE_OUTPUT_FILE=\"${LOG_DIR}\"/\"${DAEMON_NAME}\".out\nwhile [ $# -gt 0 ]; do\n  COMMAND=$1\n  case $COMMAND in\n    -name)\n      DAEMON_NAME=$2\n      CONSOLE_OUTPUT_FILE=\"${LOG_DIR}\"/\"${DAEMON_NAME}\".out\n      shift 2\n      ;;\n    -loggc)\n      if [ -z \"$KAFKA_GC_LOG_OPTS\" ]; then\n        GC_LOG_ENABLED=\"true\"\n      fi\n      shift\n      ;;\n    -daemon)\n      DAEMON_MODE=\"true\"\n      shift\n      ;;\n    -jars)\n      JAR_PATHS=$2\n      copyJars \"$JAR_PATHS\"\n      shift 2\n      ;;\n    *)\n      break\n      ;;\n  esac\ndone\n\n# GC options\nGC_FILE_SUFFIX='-gc.log'\nGC_LOG_FILE_NAME=''\nif [ \"x$GC_LOG_ENABLED\" = \"xtrue\" ]; then\n  GC_LOG_FILE_NAME=$DAEMON_NAME$GC_FILE_SUFFIX\n  KAFKA_GC_LOG_OPTS=\"-Xloggc:$LOG_DIR/$GC_LOG_FILE_NAME -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100M\"\nfi\n\n# If Cygwin is detected, classpath is converted to Windows format.\n(( CYGWIN )) && CLASSPATH=$(cygpath --path --mixed \"${CLASSPATH}\")\n\n# Launch mode\nif [ \"x$DAEMON_MODE\" = \"xtrue\" ]; then\n  nohup $JAVA $KAFKA_HEAP_OPTS $KAFKA_JVM_PERFORMANCE_OPTS $KAFKA_GC_LOG_OPTS $KAFKA_JMX_OPTS $KAFKA_LOG4J_OPTS -cp $CLASSPATH $KAFKA_OPTS com.linkedin.kafka.cruisecontrol.KafkaCruiseControlMain \"$@\" > \"$CONSOLE_OUTPUT_FILE\" 2>&1 < /dev/null &\nelse\n  exec $JAVA $KAFKA_HEAP_OPTS $KAFKA_JVM_PERFORMANCE_OPTS $KAFKA_GC_LOG_OPTS $KAFKA_JMX_OPTS $KAFKA_LOG4J_OPTS -cp $CLASSPATH $KAFKA_OPTS com.linkedin.kafka.cruisecontrol.KafkaCruiseControlMain \"$@\"\nfi\n"
        },
        {
          "name": "kafka-cruise-control-stop.sh",
          "type": "blob",
          "size": 0.3623046875,
          "content": "#!/bin/bash\n# Copyright 2019 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\").\n# See License in the project root for license information.\n\nSIGNAL=${SIGNAL:-TERM}\nPIDS=$(ps ax | grep 'java.*KafkaCruiseControlMain' | grep -v grep | awk '{print $1}')\n\nif [ -z \"$PIDS\" ]; then\n  echo \"No cruise-control to stop\"\n  exit 1\nelse\n  kill -s $SIGNAL $PIDS\nfi\n"
        },
        {
          "name": "semantic-build-versioning.gradle",
          "type": "blob",
          "size": 0.1494140625,
          "content": "\npreRelease {\n  startingVersion = 'RC.0'\n  // The bumping scheme is RC.0 -> RC.1 -> ... -> RC.n\n  bump = {\n    \"RC.${((it - ~/^RC\\./) as int) + 1}\"\n  }\n}"
        },
        {
          "name": "settings.gradle",
          "type": "blob",
          "size": 1.2001953125,
          "content": "/*\n * Copyright 2017 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n */\nimport org.gradle.util.GradleVersion\n\nbuildscript {\n  repositories {\n    maven {\n      url 'https://plugins.gradle.org/m2/'\n    }\n  }\n  dependencies {\n    // Needed to override an old version of Apache HttpClient that was being included by the\n    // net.vivin.gradle-semantic-build-versioning plugin.\n    // See https://www.jfrog.com/jira/browse/GAP-317 for more info.\n    classpath 'org.apache.httpcomponents:httpclient:4.5.13'\n    classpath 'gradle.plugin.net.vivin:gradle-semantic-build-versioning:4.0.0'\n  }\n}\n\napply plugin: 'net.vivin.gradle-semantic-build-versioning'\n\n//otherwise it defaults to the folder name\nrootProject.name = 'cruise-control'\n\ninclude 'cruise-control', 'cruise-control-metrics-reporter', 'cruise-control-core'\n\ndef gradleVer = GradleVersion.current()\ndef minimumVersion = GradleVersion.version(\"7.2\")\nif (gradleVer < minimumVersion) {\n  throw new GradleScriptException(\"this build cannot be run with gradle < \" + minimumVersion + \". current detection version is \" +\n      gradleVer + \". use newer gradle or (better yet) use the wrapper\", null)\n}\n"
        }
      ]
    }
  ]
}