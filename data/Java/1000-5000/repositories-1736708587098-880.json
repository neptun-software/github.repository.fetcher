{
  "metadata": {
    "timestamp": 1736708587098,
    "page": 880,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjkwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "in28minutes/devops-master-class",
      "stars": 2387,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.884765625,
          "content": "# See http://help.github.com/ignore-files/ for more about ignoring files.\n\n# compiled output\n/dist\n/tmp\n/out-tsc\n\n# dependencies\nnode_modules\n\n# terraform excludes\n*.tfstate\n*.tfstate.backup\n.terraform\n*.terraform.lock.hcl\n\n# IDEs and editors\n/.idea\n.project\n.classpath\n.c9/\n*.launch\n.settings/\n*.sublime-workspace\n\n# IDE - VSCode\n.vscode/*\n!.vscode/settings.json\n!.vscode/tasks.json\n!.vscode/launch.json\n!.vscode/extensions.json\n\n# misc\n/.sass-cache\n/connect.lock\n/coverage\n/libpeerconnection.log\nnpm-debug.log\nyarn-error.log\ntestem.log\n/typings\n\n# System Files\n.DS_Store\nThumbs.db\n\n# Compiled class file\n*.class\n\n# Log file\n*.log\n\n# BlueJ files\n*.ctxt\n\n# Mobile Tools for Java (J2ME)\n.mtj.tmp/\n\n# Package Files #\n*.ear\n*.tar.gz\n*.rar\n*.cmd\n*.classpath\n*.settings\n*.project\n*.mvn\nmvnw\ntarget\n*.DS_Store\n\n# virtual machine crash logs, see http://www.java.com/en/download/help/error_hotspot.xml\nhs_err_pid*\n"
        },
        {
          "name": "2.12",
          "type": "blob",
          "size": 0.0888671875,
          "content": "[master 52590a2] version                = ~\n 1 file changed, 1 insertion(+), 1 deletion(-)\n"
        },
        {
          "name": "ansible",
          "type": "tree",
          "content": null
        },
        {
          "name": "azure-devops",
          "type": "tree",
          "content": null
        },
        {
          "name": "build-images.md",
          "type": "blob",
          "size": 0.7724609375,
          "content": "## Use Images supporting multiple architectures - linux/amd64,linux/arm64\n\n```\nFROM maven:3.8.2-jdk-8-slim AS build\n```\n\n## Execute buildx to create multi platform builds\n\n```\ndocker buildx build \\\n--platform linux/amd64,linux/arm64 \\\n-t in28min/hello-world-python:0.0.1.RELEASE \\\n--push \\\n.\n\ndocker buildx build \\\n--platform linux/amd64,linux/arm64 \\\n-t in28min/hello-world-nodejs:0.0.1.RELEASE \\\n--push \\\n.\n\ndocker buildx build \\\n--platform linux/amd64,linux/arm64 \\\n-t in28min/hello-world-java:0.0.1.RELEASE \\\n--push \\\n.\n\n# NOT EXECUTED\ndocker buildx build \\\n--platform linux/amd64,linux/arm64 \\\n-t in28min/currency-exchange:0.0.1-RELEASE \\\n--push \\\n.\n\n# NOT EXECUTED\ndocker buildx build \\\n--platform linux/amd64,linux/arm64 \\\n-t in28min/currency-conversion:0.0.1-RELEASE \\\n--push \\\n.\n```"
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "jenkins",
          "type": "tree",
          "content": null
        },
        {
          "name": "kubernetes",
          "type": "tree",
          "content": null
        },
        {
          "name": "presentation.pdf",
          "type": "blob",
          "size": 4576.3466796875,
          "content": null
        },
        {
          "name": "projects",
          "type": "tree",
          "content": null
        },
        {
          "name": "readme.md",
          "type": "blob",
          "size": 24.5859375,
          "content": "# DevOps for Beginners - Docker, Kubernetes, Terraform and Azure Devops\n\n[![Image](https://www.springboottutorial.com/images/Course-DevOps.png \"DevOps Course\")](https://links.in28minutes.com/DevOps-SBT)\n\n\n## Learn Devops with Docker, Kubernetes, Terraform, Ansible, Jenkins and Azure Devops\n\n## Pipeline Project Github Repositories\n- Azure Devops - https://github.com/in28minutes/azure-devops-kubernetes-terraform-pipeline\n- Jenkins - https://github.com/in28minutes/jenkin-devops-microservice\n\n## Course Introduction\n\n200+ Videos. 20+ Hours. 6 DevOps Tools - Docker, Kubernetes, Azure Devops, Jenkins, Terraform, and Ansible. 3 Different Clouds - AWS, Azure and Google Cloud. \n\nDo you need more reasons for enrolling for this amazing course on DevOps?\n\nDo you have ZERO experience with DevOps with Docker, Kubernetes, Azure Devops, Jenkins, Terraform, Ansible, AWS, Azure and Google Cloud? No Problem.\n\nDo you have ZERO experience with DevOps Containers and Container Orchestration with Docker and Kubernetes? No Problem.\n\nDo you have ZERO experience with Continuous Integration or Continuous Delivery in DevOps with Azure Devops and Jenkins? No Problem.\n\nDo you have ZERO experience with the Cloud? No Problem.\n\nAre you ready to learn DevOps with Docker, Kubernetes, Terraform, Ansible, Jenkins and Azure Devops in multiple clouds - AWS, Azure and Google Cloud?\n\nDo you want to join 300,000+ learners having Amazing Learning Experiences with in28Minutes?\n\nBuckle up and Get ready for this wonderful ride on DevOps, Microservices and the Cloud.\n\nLook No Further!\n\n## Course Overview\n\nDevOps is all about People, Process and Tools. In this course, you will understand the basics of DevOps and learn to do DevOps with Docker, Kubernetes, Ansible, Terraform, Azure DevOps and Jenkins. You will learn to implement DevOps with Continuous Integration, Continuous Delivery and Infrastructure as Code. You will play with 3 different clouds - AWS, Azure and Google Cloud.\n\nYou will do DevOps with Docker to create and run Docker images for:\n- Hello World Applications - Python, JavaScript and Java\n- Microservices - Currency Exchange and Currency Conversion\n\nYou will learn the basics of Kubernetes on the Google Kubernetes Engine implementing Service Discovery, Centralized Configuration and Load Balancing for Microservices. You will do DevOps with Kubernetes using Terraform (Infrastructure as Code) and Azure DevOps (Continuous Delivery) on multiple cloud platforms (AWS and Azure)\n\nYou will learn the basics of Continuous Integration and Continuous Delivery and implement them using Jenkins and Azure DevOps. You will learn to Create Kubernetes Clusters and Deploy Microservices to Kubernetes using Azure DevOps Pipelines on the Cloud with AWS EKS and Azure AKS.\n\nYou will learn the basics of Terraform and Ansible and implement Infrastructure as Code. You will provision a number of AWS Resources - EC2 Instances and Load Balancers - using Terraform and configure them with Ansible. You will learn to provision Kubernetes Clusters in AWS and Azure using Terraform. You would learn to run Terraform Configuration in Azure DevOps Pipelines.\n\nThis course would be a perfect first step as an introduction to DevOps.\n\n\n## What you'll learn\n- You will learn DevOps with Docker, Kubernetes and Azure DevOps from ZERO, no previous experience required\n- You will learn the fundamentals of 6 Most Popular DevOps Tools - Docker, Kubernetes, Azure Devops, Jenkins, Terraform, and Ansible\n- You will learn the building blocks of DevOps - Continuous Integration, Continuous Delivery and Infrastructure as Code\n- You will learn to implement Azure Devops Pipelines integrating Docker, Kubernetes and  Terraform on AWS EKS and Azure AKS\n- You will learn DevOps with Continuous Integration & Continuous Delivery on Azure DevOps and Jenkins\n- You will do containerization and container orchestration for microservices with Docker and Kubernetes\n- You will play with Docker, Docker Compose and Kubernetes\n- You will implement Service Discovery, Centralized Configuration and Load Balancing for Docker Microservices deployed in Kubernetes\n- You will Join 300,000 Learners having AMAZING LEARNING Experiences with in28Minutes\n\n## Requirements\n- You have an attitude to learn while having fun :)\n- You have some programming experience with either Java, Python or JavaScript\n- You DO NOT need to have any experience with DevOps, Kubernetes, Docker or Azure DevOps\n- We will help you install the tools and create your cloud accounts\n\n## Who is this course for\n- You are a programmer wanting to explore DevOps with Docker, Kubernetes and Azure DevOps\n- You want to automate deployment of your microservices to the cloud using DevOps with Docker, Kubernetes and Azure DevOps\n\n## Step By Step Details\n\n### Promo\n- 00 - Step 00 - Master Devops - Docker, Kubernetes, Terraform and Azure Devops - Promo\n\n### Quick Overview of DevOps\n- Step 01 - Master Devops - Docker, Kubernetes, Terraform and Azure Devops - 01 - Intro\n- Step 02 - DevOps and Evolution of Software Development \n- Step 03 - Evolution to Agile\n- Step 04 - DevOps - An Overview\n\n### Start DevOps with Docker\n- Step 00 00 - DevOps and Containerization\n- Step 01 - Docker and DevOps - Installation and Introduction\n- Step 02 - Your First Docker Usecase\n- Step 03 - Important Docker Concepts - Registry, Repository, Tag, Image and Container\n- Step 04 - Playing with Docker Images - Java, JavaScript and Python\n- Step 05 - Playing with Docker - Detached Mode and Logs\n- Step 06 - Playing with Docker Images and Containers\n- Step 07 - Understanding Docker Architecture - Docker Client, Docker Engine\n- Step 08 - Understanding Docker Popularity - My 3 Top Reasons\n- Step 09 - Learning Docker Images - Commands\n- Step 10 - Learning Docker Containers - Commands\n- Step 11 - Learning Docker Commands - system and stats\n- Step 12 - 01 - Import Docker Projects into Visual Studio Code\n- Step 12 - 02 - Building Docker Images for Python Application\n- Step 13 - Understanding creation of Docker Images in Depth\n- Step 14 - Pushing Python App Docker Image to Docker Hub\n- Step 15 - Building and Pushing Docker Image for Node JavaScript App\n- Step 16 - Building and Pushing Docker Image for Java Application\n- Step 17 - Building Efficient Docker Images - Improving Layer Caching\n- Step 18 - Understanding ENTRYPOINT vs CMD\n- Step 19 - Docker and Microservices - Quick Start\n- Step 20 - Introduction to Microservices - CE and CC\n- Step 21 - Running Microservices as Docker Containers\n- Step 22 - Using Docker Link to Connect Microservices\n- Step 23 - Using Custom Networking to Connect Microservices\n- Step 24 - Using Docker Compose to Simplify Microservices Launch\n- Step 25 - Understanding Docker Compose further\n\n### DevOps with Kubernetes on Google Kubernetes Engine\n- Step 01 - Getting Started with Docker, Kubernetes and Google Kubernetes Engine\n- Step 02 - Creating Google Cloud Account\n- Step 03 - Creating Kubernetes Cluster with Google Kubernete Engine (GKE)\n- Step 04 - Review Kubernetes Cluster and Learn Few Fun Facts about Kubernetes\n- Step 05 - Deploy Your First Spring Boot Application to Kubernetes Cluster\n- Step 06 - Quick Look at Kubernetes Concepts - Pods, Replica Sets and Deployment\n- Step 07 - Understanding Pods in Kubernetes\n- Step 08 - Understanding ReplicaSets in Kubernetes\n- Step 09 - Understanding Deployment in Kubernetes\n- Step 10 - Quick Review of Kubernetes Concepts - Pods, Replica Sets and Deployment\n- Step 11 - Understanding Services in Kubernetes\n- Step 12 - Quick Review of GKE on Google Cloud Console \n- Step 13 - Understanding Kubernetes Architecture - Master Node and Nodes\n- Step 14 - Understand Google Cloud Regions and Zones\n- Step 15 - Installing GCloud\n- Step 16 - Installing Kubectl\n- Step 17 - Understand Kubernetes Rollouts\n- Step 18 - Generate Kubernetes YAML Configuration for Deployment and Service\n- Step 19 - Understand and Improve Kubernetes YAML Configuration\n- Step 20 - Using Kubernetes YAML Configuration to Create Resources\n- Step 21 - Understanding Kubernetes YAML Configuration - Labels and Selectors\n- Step 22 - Quick Fix to reduce release downtime with minReadySeconds\n- Step 23 - Understanding Replica Sets in Depth - Using Kubernetes YAML Config\n- Step 24 - Configure Multiple Kubernetes Deployments with One Service\n- Step 25 - Playing with Kubernetes Commands - Top Node and Pod\n- Step 26 - Delete Hello World Deployments\n- Step 27 - Quick Introduction to Microservices - CE and CC\n- Step 28 - Deploy Microservices to Kubernetes\n- Step 29 - Understand Environment Variables created by Kubernetes for Services\n- Step 30 - Microservices and Kubernetes Service Discovery - Part 1\n- Step 31 - Microservices and Kubernetes Service Discovery - Part 2 DNS\n- Step 32 - Microservices Centralized Configuration with Kubernetes ConfigMaps\n- Step 33 - Simplify Microservices with Kubernetes Ingress - Part 1\n- Step 34 - Simplify Microservices with Kubernetes Ingress - Part 2\n- Step 35 - Delete Kubernetes Clusters\n\n### Getting Started with Terraform\n- Step 00 00 - Getting Started with Infrastructure as Code\n- Step 00 01 - Getting Started with Terraform\n- Step 01 - Creating and Initializing First Terraform Project\n- Step 02 - Create AWS IAM User Access Key and Secret\n- Step 03 - Configure Terraform Environment Variables for AWS Access Keys\n- Step 04 - Creating AWS S3 Buckets with Terraform\n- Step 05 - Playing with Terraform State - Desired, Known and Actual\n- Step 06 - Playing with Terraform Console\n- Step 07 - Creating AWS IAM User with Terraform\n- Step 08 - Updating AWS IAM User Name with Terraform\n- Step 09 - Understanding Terraform tfstate files in depth\n- Step 10 - gitignore Terraform tfstate files\n- Step 11 - Refactoring Terraform files - Variables, Main and Outputs\n- Step 12 - Creating Terraform Project for Multiple IAM Users\n- Step 13 - Playing with Terraform Commands - fmt, show and console\n- Step 14 - Recovering from Errors with Terraform\n- Step 15 - Understanding Variables in Terraform\n- Step 16 - Creating Terraform Project for Understanding List and Map\n- Step 17 - Adding Elements - Problem with Terraform Lists\n- Step 18 - Creating Terraform Project for Learning Terraform Maps\n- Step 19 - Quick Review of Terraform FAQ\n- Step 20 - Understanding Creation of EC2 Instances in AWS Console\n- Step 21 - Creating New Terraform Project for AWS EC2 Instances\n- Step 22 - Creating New EC2 Key Pair and Setting Up\n- Step 23 - Adding AWS EC2 Configuration to Terraform Configuration\n- Step 24 - Installing Http Server on EC2 with Terraform - Part 1\n- Step 25 - 01 - Installing Http Server on EC2 with Terraform - Part 2\n- Step 25 - 02 - Immutable Servers with Infrastructure as Code\n- Step 26 - Remove hardcoding of Default VPC with AWS Default VPC\n- Step 27 - Remove hardcoding of subnets with Data Providers\n- Step 28 - Remove hardcoding of AMI with Data Providers\n- Step 29 - Playing with Terraform Graph and Destroy EC2 Instances\n- Step 30 - Creating New Terraform Project for AWS EC2 with Load Balancers\n- Step 31 - Create Security Group and Classic Load Balancer in Terraform\n- Step 32 - Review and Destroy AWS EC2 with Load Balancers\n- Step 33 - Creating Terraform Project for Storing Remote State in S3\n- Step 34 - Create Remote Backend Project for Creating S3 Buckets\n- Step 35 - Update User Project to use AWS S3 Remote Backend\n- Step 36 - Creating multiple environments using Terraform Workspaces\n- Step 37 - Creating multiple environments using Terraform Modules\n\n### Learn Azure DevOps - Continuous Integration, Deployment and Delivery\n- Step 00 00 - Getting Started with Continuous Integration, Deployment and Delivery\n- Step 00 01 - Getting Started with Azure DevOps\n- Step 01 - Getting Started with Azure DevOps - First Project\n- Step 02 - Setting up Git Repo for Azure DevOps Pipeline\n- Step 03 - Creating your first Azure DevOps Pipeline\n- Step 04 - Getting Started with Azure DevOps - Agents and Jobs - 1\n- Step 05 - Getting Started with Azure DevOps - Agents and Jobs - 2\n- Step 06 - Using dependsOn with Jobs\n- Step 07 - Creating Azure DevOps Pipeline for Playing with Stages\n- Step 08 - Playing with Variables and dependsOn for Stages\n- Step 09 - Understanding Azure DevOps Pipeline Variables\n- Step 10 - Creating Azure DevOps Tasks for Copy Files and Publish Artifacts\n- Step 11 - Running Azure DevOps Jobs on Multiple Agents\n- Step 12 - Understanding Azure DevOps Deployment Jobs - Environments and Approvals\n- Step 13 - Build and Push Docker Image in Azure DevOps - Part 1\n- Step 14 - Build and Push Docker Image in Azure DevOps - Part 2\n- Step 15 - Playing with Azure DevOps Releases\n\n### CI, CD and IAAC on Azure AKS Kubernetes Clusters with Docker, Azure DevOps and Terraform\n- Step 00 - Getting Started with IAAC for Azure AKS with Azure DevOps, Terraform and Kubernetes\n- Step 01 - Review Terraform Configuration for Azure Kubernetes Cluster Creation\n- Step 02 - Setting up Client ID, Secret and Public Key for Azure Kubernetes Cluster Creation\n- Step 03 - Creating Azure DevOps Pipeline for Azure Kubernetes Cluster IAAC\n- Step 04 - Performing Terraform apply to create Azure Kubernetes Cluster in Azure DevOps\n- Step 05 - 01 - Installing Azure CLI\n- Step 05 - 02 - Connecting to Azure Kubernetes Cluster using Azure CLI\n- Step 06 - 01 - Creating Azure DevOps Pipeline for Deploying Microservice to Azure Kubernetes\n- Step 06 - 02 - Managing Pipelines and Github Repositories for Kubernetes and Microservices\n- Step 07 - Creating V2 and Enable Build and Push of Docker Image - Part 1\n- Step 08 - Creating V2 and Enable Build and Push of Docker Image - Part 2\n- Step 09 - Performing Terraform destroy to delete Azure Kubernetes Cluster in Azure DevOps\n- Step 10 - Quick Review of Terraform destroy\n\n### CI, CD and IAAC on AWS EKS Kubernetes Clusters with Docker, Azure DevOps and Terraform\n- Step 00 - Geting Started with IAAC for AWS EKS with Azure DevOps, Terraform and Kubernetes\n- Step 01 - Review Terraform Configuration for AWS EKS Cluster Creation\n- Step 02 - Setup AWS S3 Buckets and Subnet Configuration\n- Step 03 - Enable AWS Tools in Azure DevOps and Create Azure DevOps Pipeline\n- Step 04 - Performing Terraform apply to create AWS EKS Cluster in Azure DevOps\n- Step 05 - Retry Terraform apply for Creating Cluster Binding\n- Step 06 - 01 - Installing AWS CLI\n- Step 06 - 02 - Configure AWS CLI and Setup Kubernetes Connection using Service Account\n- Step 07 - Creating Azure DevOps Pipeline for Deploying Microservice to AWS EKS\n- Step 08 - Creating V3 and Enable Build and Push of Docker Image - Part 1\n- Step 09 - Creating V3 and Enable Build and Push of Docker Image - Part 2\n- Step 10 - Performing Terraform destroy to delete AWS EKS Cluster in Azure DevOps - 1\n- Step 11 - Performing Terraform destroy to delete AWS EKS Cluster in Azure DevOps - 2\n\n### Learn Azure DevOps with Boards and Backlogs\n- Step 01 - Getting Started with Azure DevOps with Demo Generator\n- Step 02 - Overview of Azure DevOps - Boards, Wiki, Repos and Pipelines\n- Step 03 - Exploring Azure DevOps Boards - Epics, Features and User Stories\n- Step 04 - Azure DevOps - Boards View vs Backlogs View\n- Step 05 - Understanding Sprints in Azure DevOps\n- Step 06 - Creating Azure DevOps Queries\n- Step 07 - Playing with Azure DevOps Repos\n- Step 08 - Quick Review of Azure DevOps Pipelines\n- Step 09 - Quick Review of Azure DevOps\n\n### Learn Continuous Integration with Jenkins\n- Step 00 01 - Getting Started with Jenkins\n- Step 01 - Introduction and Launching Jenkins as Docker Container\n- Step 02 - Initializing Jenkins Plugins and Creating Github Repo\n- Step 03 - Setting up Docker and Maven in Jenkins and First Pipeline Run\n- Step 04 - Understanding Scripted Pipelines in Jenkins\n- Step 05 - Understanding Declarative Pipelines in Jenkins - Stages\n- Step 06 - Using Docker Images as Jenkins Pipeline Agents\n- Step 07 - Review Pipeline Syntax and Understanding Variables\n- Step 08 - Configuring Jenkins Pipeline Path with Docker and Maven Tools\n- Step 09 - Running Unit Tests and Integration Tests in Jenkins Pipelines - 1\n- Step 10 - Running Unit Tests and Integration Tests in Jenkins Pipelines - 2\n- Step 11 - Build and Push Docker Image in Jenkins Pipelines - 1\n- Step 12 - Build and Push Docker Image in Jenkins Pipelines - 2\n\n### Getting Started with Ansible\n- Step 00 01 - Getting Started with Ansible\n- Step 01 - Creating EC2 Instances for Ansible - Manually and with Terraform\n- Step 02 - Setting Ansible Project with cfg and ansible hosts\n- Step 03 - Playing with Ansible Commands\n- Step 04 - Playing with Ansible Host File and Custom Groups\n- Step 05 - Creating an Ansible Playbook for Ping\n- Step 06 - Understanding Ansible Terminology - Control Node, Managed Nodes, Inventory\n- Step 07 - Creating New Ansible Playbook for Executing Shell Commands\n- Step 08 - Playing with Ansible Variables\n- Step 09 - Creating New Ansible Playbook for Understanding Ansible Facts\n- Step 10 - Creating New Ansible Playbook for Installing Apache and Serving HTML\n- Step 11 - Reuse and Executing Multiple Ansible Playbooks\n- Step 12 - Understanding Conditionals and Loops with Ansible\n- Step 13 - 01 - Getting Ready for EC2 Dynamic Inventory with Ansible\n- Step 13 - 02 - Configuring EC2 Dynamic Inventory with Ansible\n- Step 14 - Creating AWS EC2 Instances with Ansible\n- Step 15 - Providing Declarative Configuration with Ansible\n- Step 16 - Deleting all AWS EC2 Instances\n\n### Appendix - Installing Visual Studio Code \n- Step 01 - Installing VS Code\n- Step 02 - Download and Setup Projects in Visual Studio Code\n\n### Appendix - Introduction to Microservices\n- Step 01 - Introduction to Microservices\n- Step 02 - Advantages of Microservices\n\n### Appendix - Exploring Microservice Projects\n- Step 01 - Code Review - Microservices\n\n### Appendix - Getting Started with AWS\n- Step 01 - Creating an AWS Root Account\n- Step 02 - Creating an IAM User for your AWS Account\n- Step 03 - Its Your Responsibility to Monitor Billing on the Cloud - 5 Recommendations\n- Step 04 - Monitor AWS Billing - Setting Billing Alerts\n\n### Appendix - Getting Started with Azure\n- Step 01 - Creating an Azure Account\n- Step 02 - Exploring Cloud Best Practices - Minimize Costs\n\n### Appendix - DevOps Best Practices and Perspectives\n- Step 01 - DevOps - Break down the wall\n- Step 02 - DevOps Perspectives - CAMS\n- Step 03 - DevOps Best Practices\n- Step 04 - DevOps Perspectives - Continuous DevOps\n- Step 05 - DevOps Maturity Assessment - Questions to ask\n\n#### Required Tools\n- Visual Studio Code\n- Docker\n- Docker Compose\n- AWS Account\n- AWS CLI\n- Azure Account\n- Azure CLI\n- Google Cloud Account\n- Terraform \n- Ansible\n\n## Next Steps\n\n## Diagrams\n\n```\n\ngraph architecture {\n\nnode[style=filled,color=\"#59C8DE\"]\n//node [style=filled,color=\"#D14D28\", fontcolor=white];\nrankdir = LR\nnode[shape=record, width=1.6]\n\n\nParentNode1 -- ChildNode1\nChildNode1 -- ChildNode2\nChildNode1 -- ChildNode3\nChildNode1 -- ChildNode4\n\nParentNode1[label=<Configuration <BR/>and Scripts>]\nChildNode1[label=<Ansible>];\nChildNode2[label=<Server 1>];\nChildNode3[label=<Server 2>];\nChildNode4[label=<Server 3>];\n\n}\n\ngraph architecture {\nlayout=\"circo\";\nnode[style=filled,  fillcolor=\"#D14D28\", fontcolor=white]\n//node [style=filled,color=\"#D14D28\", fontcolor=white];\nrankdir = LR\nnode[shape = circle,  width=1]\nedge [dir=forward]\n\nNode1 -- Node2\nNode2 -- Node3\nNode3 -- Node4\nNode4 -- Node1\n//Node4 -- Node5\n//Node5 -- Node6\n\nNode1[label=<DEV>]\nNode2[label=<QA>]\nNode3[label=<STAGE>]\nNode4[label=<PROD>]\n//Node5[label=<5>]\n//Node6[label=<6>]\n\n}\n\n\ngraph architecture {\nrankdir = LR\nnode[shape = circle,  width=1, style=filled,fillcolor=\"#59C8DE\"]\n//shape = record\nedge [dir=forward]\n\nNode1 -- Node2\nNode2 -- Node3\nNode3 -- Node4\n//Node4 -- Node1\n//Node4 -- Node5\n//Node5 -- Node6\n\nNode1[label=<DEV>]\nNode2[label=<QA>]\nNode3[label=<STAGE>]\nNode4[label=<PROD>]\n//Node5[label=<5>]\n//Node6[label=<6>]\n\n}\n\ngraph architecture {\nrankdir = LR\nnode[shape = circle,  width=1, style=filled,fillcolor=\"#59C8DE\"]\n//shape = record\nedge [dir=forward]\n\nNode3 -- Node4\nNode4 -- Node5\nNode5 -- Node6\nNode6 -- Node7\nNode7 -- Node1\nNode1 -- Node2\nNode2 -- Node3\n\nNode1[label=<Code>]\nNode2[label=<Build>]\nNode3[label=<Test>]\nNode4[label=<Release>]\nNode5[label=<Deploy>]\nNode6[label=<Review>]\nNode7[label=<Plan>]\n\n}\n\ngraph architecture {\nrankdir = LR\nnode[shape = circle,  width=1.3, style=filled,color=\"#59C8DE\", fontcolor=black]\n//shape = record\n//fillcolor=\"#59C8DE\"\n//edge [dir=forward]\nedge [width=0]\n#D14D28\n\nNode3 -- Node4[style=invis]\nNode4 -- Node5[style=invis]\nNode1 -- Node2[style=invis]\nNode2 -- Node3[style=invis]\n\nNode1[label=<Business>]\nNode2[label=<Architecture>]\nNode3[label=<Development>]\nNode4[label=<Testing>]\nNode5[label=<Operations>]\n\n}\n\ngraph architecture {\nrankdir = LR\nnode[shape = circle,  width=1, style=filled,color=\"#D14D28\", fontcolor=white]\n//shape = record\n//fillcolor=\"#59C8DE\"\nedge [dir=forward]\n\nNode3 -- Node4\nNode4 -- Node5\nNode5 -- Node6\nNode1 -- Node2\nNode2 -- Node3\n\nNode1[label=<Vision>]\nNode2[label=<Iteration 1>]\nNode3[label=<Iteration 2>]\nNode4[label=<...>]\nNode5[label=<Iteration n>]\nNode6[label=<Product>]\n\n}\n\ngraph architecture {\nrankdir = LR\nnode[shape = circle,  width=1, style=filled,fillcolor=\"#59C8DE\"]\n//shape = record\nedge [dir=forward]\n\nNode3 -- Node4\nNode4 -- Node5\nNode5 -- Node6\nNode6 -- Node7\nNode7 -- Node8\nNode8 -- Node1\nNode1 -- Node2\nNode2 -- Node3\n\nNode1[label=<Code>]\nNode2[label=<Build>]\nNode3[label=<Test>]\nNode4[label=<Release>]\nNode5[label=<Deploy>]\nNode6[label=<Operate>]\nNode7[label=<Monitor>]\nNode8[label=<Plan>, fillcolor=white]\n\n}\n\ngraph architecture {\nrankdir = LR\nnode[shape = circle,  width=2, style=filled,fillcolor=\"#D14D28\", fontcolor=white]\n//shape = record\n//edge [dir=forward]\n\nNode3 -- Node4\nNode4 -- Node5\nNode5 -- Node6\nNode6 -- Node7\nNode7 -- Node8\nNode8 -- Node1\nNode1 -- Node2\nNode2 -- Node3\n\nNode1[label=<<FONT POINT-SIZE=\"20\">Continuous<br/>Planning</FONT>>]\nNode2[label=<<FONT POINT-SIZE=\"20\">Continuous<br/>Development</FONT>>]\nNode3[label=<<FONT POINT-SIZE=\"20\">Continuous<br/>Integration</FONT>>]\nNode4[label=<<FONT POINT-SIZE=\"20\">Continuous<br/>Deployment</FONT>>]\nNode5[label=<<FONT POINT-SIZE=\"20\">Continuous<br/>Testing</FONT>>]\nNode6[label=<<FONT POINT-SIZE=\"20\">Continuous<br/>Delivery</FONT>>]\nNode7[label=<<FONT POINT-SIZE=\"20\">Continuous<br/>Monitoring</FONT>>]\nNode8[label=<<FONT POINT-SIZE=\"20\">Continuous<br/>Feedback</FONT>>]\n\n}\n\ngraph architecture {\nrankdir = LR\nnode[shape = circle,  width=1.6, style=filled,fillcolor=\"#D14D28\", fontcolor=white]\n//shape = record\nedge [dir=forward]\n{ rank=same Node1 Node2 Node3 }\n{ rank=same Node7 Node8 Node9 }\n\nNode3 -- Node4\nNode4 -- Node5\nNode5 -- Node6\nNode6 -- Node7\nNode7 -- Node8\nNode8 -- Node9\nNode1 -- Node2\nNode2 -- Node3\n\nNode1[label=<<FONT POINT-SIZE=\"20\">Code<br/>Commit</FONT>>]\nNode2[label=<<FONT POINT-SIZE=\"20\">Unit<br/>Tests</FONT>>]\nNode3[label=<<FONT POINT-SIZE=\"20\">Integration<br/>Tests</FONT>>]\nNode4[label=<<FONT POINT-SIZE=\"20\">Package<br/></FONT>>]\nNode5[label=<<FONT POINT-SIZE=\"20\">Deploy</FONT>>]\nNode6[label=<<FONT POINT-SIZE=\"20\">Automated<br/> Tests</FONT>>]\nNode7[label=<<FONT POINT-SIZE=\"20\">Testing<br/>Approval</FONT>>, fillcolor=white, fontcolor=black]\nNode8[label=<<FONT POINT-SIZE=\"20\">Deploy<br/>NEXT</FONT>>]\nNode9[label=<<FONT POINT-SIZE=\"20\">..</FONT>>]\n\n}\n\ngraph architecture {\nrankdir = LR\nnode[shape = circle,  width=1.6, style=filled,fillcolor=\"#D14D28\", fontcolor=white]\n//shape = record\nedge [dir=forward]\n\nNode3 -- Node4\nNode4 -- Node5\nNode1 -- Node2\nNode2 -- Node3\n\nNode1[label=<<FONT POINT-SIZE=\"20\">Provision<br/>Server</FONT>>]\nNode2[label=<<FONT POINT-SIZE=\"20\">Install<br/>Java</FONT>>]\nNode3[label=<<FONT POINT-SIZE=\"20\">Install<br/>Tomcat</FONT>>]\nNode4[label=<<FONT POINT-SIZE=\"20\">Configure<br/>Tomcat</FONT>>]\nNode5[label=<<FONT POINT-SIZE=\"20\">Deploy<br/>Application</FONT>>]\n\n}\n\ngraph architecture {\nrankdir = LR\nnode[shape = circle,  width=1.6, style=filled,fillcolor=\"#D14D28\", fontcolor=white]\n//shape = record\nedge [dir=forward]\n\nNode3 -- Node4\nNode4 -- Node5\nNode1 -- Node2\nNode2 -- Node3\n\nNode1[label=<<FONT POINT-SIZE=\"20\">Create<br/>Template</FONT>>]\nNode2[label=<<FONT POINT-SIZE=\"20\">Provision<br/>Server</FONT>>]\nNode3[label=<<FONT POINT-SIZE=\"20\">Install<br/>Software</FONT>>]\nNode4[label=<<FONT POINT-SIZE=\"20\">Configure<br/>Software</FONT>>]\nNode5[label=<<FONT POINT-SIZE=\"20\">Deploy<br/>App</FONT>>]\n\n}\n\ngraph architecture {\nrankdir = LR\nnode[shape = circle,  width=1.6, style=filled,fillcolor=\"#D14D28\", fontcolor=white]\n//shape = record\nedge [dir=forward]\n\nNode3 -- Node4\nNode1 -- Node2\nNode2 -- Node3\n\nNode1[label=<<FONT POINT-SIZE=\"20\">Provision<br/>Server v1</FONT>>]\nNode2[label=<<FONT POINT-SIZE=\"20\">Provision<br/>Server v2</FONT>>]\nNode3[label=<<FONT POINT-SIZE=\"20\">Remove<br/>Server v1</FONT>>]\nNode4[label=<<FONT POINT-SIZE=\"20\">..<br/></FONT>>]\n\n}\n```\n\n## Todo\n- Course Promotion\n  - 2 Emails on Udemy\n  - 2 Emails to Email List\n  - Create YouTube Course Preview Video\n    - Add YouTube Course Preview Video as End Video for all videos\n    - Make it the YouTube Default Video\n  - Release atleast 20 small videos - one a day on Youtube\n  - Do atleast 3 Youtube live sessions\n  - After a Month\n    - UFB\n"
        },
        {
          "name": "terraform",
          "type": "tree",
          "content": null
        },
        {
          "name": "zz-notes.md",
          "type": "blob",
          "size": 26.9921875,
          "content": "DevOps is all about People, Process and Tools. In this course, you will learn to do DevOps using Docker, Kubernetes, Ansible, Terraform, Azure DevOps and Jenkins. You will play with 3 different clouds - AWS, Azure and Google Cloud.\n\nAgile\n- Individuals and interactions over processes and tools,  Working software over comprehensive documentation, Customer collaboration over contract negotiation,  Responding to change over following a plan\n- Faster Feedback\n\t- Short Iterations (Vision -> Iteration 1 -> Iteration 2 -> .. -> Iteration n -> Product)\n\t- Code, Build, Test, Release, Deploy, Plan\n\t- more frequent deployments, higher-quality products and happier customers\n- More Automation\n\t- CI, UT, AT, TDD, Visualization\n- Enhanced Communication \n\t- Business, Architecture, Development (Cross Functional), Testing\n\t- No need to wait for 6 months how something looks\n\nArchitectures Moved towards Microservices which increased deployments exponentially. Operations became the bottleneck.\n\nDevOps\n- Natural Evolution of Software Development. \n- DevOps is NOT JUST a tool, framework or just automation. It is a combination. Its more of a culture and a mindset. (Faster Feedback (TTM), High Quality Software. )\n- People (Culture), Process, Products (Tools) - Culture is very important\n- Business, Architecture, Development, Testing, Operations (Security)\n- More Automation - Continuous Deployment, Continuous Delivery, IAAC, Monitoring\n- Borrows from Agile and Lean\n- Code, Build, Test, Release, Deploy, Operate, Monitor, Plan\n- Values or Principles\n- Practices\n- Tools\n\n7C's \n- Continuous Planning, Development, Integration, Deployment, Testing (Shift Left in Testing), Delivery, Monitoring, Feedback - Do Often\n\nBreakdown the wall\n- Working towards a common goal\n- Bringing Ops and Dev Together - Automated Platforms and Services - (DH Chapter 8)\n- Dev Shares OPs Responsiblities\n- Dev maintains releases for first week\n- Self Provisioning\n- Integrate OPS Engineers into Scrum Teams\n- OPS Liason for Every Scrum Team\n- Involve Ops in Standups and Retros\n- Make Ops work visible\n\nAttitude\n- DevOps is still evolving\n- Do you know the complexity in aiming for something big like DevOps in multiple clouds (AWS, Azure and GCP) with multiple tools (Docker, K8S, Terraform, Ansible)? You will get confused. So, don't worry if you get confused by the terminology. You can re-watch this course 1000 times if you would want. \n- Tools are not important. Concepts and your thought process is important. Tomorrow, Docker might not be around. But if you understand the problem Docker solved, you can use another tool to solve the problem.\n- Is there a perfect tool set or a perfect approach for DevOps? Is there an Utopian World for DevOps? Unfortunately, the answer is no! With evolution of Cloud and Microservices, DevOps Toolset is also evolving everyday. \n\nPipelines, CI, Continuous Deployment, Continuous Delivery\nCommit -> Unit Tests >  Run Integration Tests > Package > Deploy App > Manual Testing > Approval > Next Environment\n\nIAAC\n- Done Manually - Provision Server, Install Java, Install Tomcat, Deploy Application\n\t- Everytime you create a server, this needs to be done manually. What if Java version needs to be updated? A security patch needs to be applied?\n\t- \n- Code Your Infra - Treat Infrastructure the same way as application code\n\t- Infra team focuses on value added work (instead of routine work)\n\t- Less Errors and Quick Recovery from Failures\n\t- Servers are Consistent (Avoids Configuration Drift)\n- Best Practices\n\t- Self Provisioning\n\t- Treat Servers as Disposable\n\t- Do not do anything manually\n\t- Version Your Infra\n\t- Incremental Changes\n\t- Zero Downtime Deployments\n- Create Template, Provision Servers(Enabled by Cloud), Install Software, Configure Software, Deploy Application\n- Provisioning Tools - Get new server ready with networking capabilities - CloudFormation and Terraform - Designed to provision the servers themselves (as well as the rest of your infrastructure, like load balancers, databases, networking configuration, etc). You can use precreated images created using Packer and AMI (Amazon Machine Image).\n- Configuration management tools - Chef, Puppet, Ansible, and SaltStack - Designed to install and manage software on existing servers.\n- Build - Building a deployable version of application. Tools - Maven, Gradle, Docker, WASM, What is used for Python?, Anything else for JavaScript?\n- Deployment - Putting new applications or new versions of application live. Tools - CI/CD Tools. Application Deployable - ear, war, container image\n\nDevOps Transformation\n- Journey to adopt the right tools, maturing the teams, maturing the managers, etc etc\n- Challenges in implementing devops - the real challenge in implementing devops is not about tools\n- Organizational challenges in implementing DevOps\n- How low and medium maturity organizations do this complete cycle..(develop, test, deploy and monitor)\n\nDevOps Metrics\n- Improve deployment frequency\n- Achieve faster time to market\n- Lower failure rate of new releases\n- Shorten lead time between fixes\n- Improve mean time to recovery\n\nBest Practices\n- Standardization - Get all teams aligned - Tools/Processes - Containers\n- Limit Work In Progress, Limit Batch Size, Constraints - Manual Env Setup > Manual Deployment > Manual Testing \n\t- Reduce Lead Time and Process Time - Business Idea, Work Started, Work Complete\n- Version Control Everything - App Code, DB Schemas, Infrastructure\n- Self Provisioning - On demand creation of Dev, Test and Prod Environments\n- Enable Quick Feedback - Shift Left - Keep Pushing Quality Close To Source and Fast Feedback - Drive towards TDD and Pair Programming!\n- Have the right mix of I Shaped, T Shaped and E Shaped Teams Scott Prugh\n- Automate As Much As Possible\n  - NFR Tests - Performance and Load Tests\n- Immutable Infra\n- Enable Low Risk Releases\n- Culture\n\nCulture\n- What would you do if something is very difficult? DO IT OFTEN?\n- Culture of Learning and Calculated Risk Taking\n- Continuous Improvements\n- Local Discoveries > Global Improvements\n- A/B Testing\n\nEnable Low Risk Releases\n- Small\n- Canaries\n- Feature Toggles\n- A/B Testing\n- Dev Prod Parity\n- Automated Testing\n- IAAC\n\t- Dev Prod Parity - Options > Copy from Machine Image, Create from Bare Metal EAch time, IAAC, Containerization, Using Cloud \n\nImmutability\n- Server Template, Provision Server, Tweak1 (Script 0), Tweak2(Script 1), Tweak3(Script 2), Current State. Tweaks - Security Patch, Version Upgrade\n- How do we replicate?\n- You want to create a new server. Will you have the confidence to execute scripts in order?\n\nITS NEVER DONE DONE!!! STORY OF DEVOPS\n\n### Story\n\nHere's an amazing story:\n\nYou are the star developer in a team and you would need to make a quick fix. You go to a github repository! \n\nYou quickly checkout the project. \n\nYou quickly create your local environment. \n\nYou make a change. You test it. You update the unit and automation tests.\n\nYou commit it.\n\nYou get an email saying it is deployed to QA. \n\nA few integration tests are automatically run.\n\nYour QA team gets an email asking for approval. They do a manual test and approve.\n\nYour code is live in production in a few minutes.\n\nYou might think this is an ideal scenario. But, do you know that this is what is happening in innovative enterprises like Netflix, Amazon and Google day in and day out!\n\nThis is the story of DevOps. \n\nIn this course, you will learn to make this possible for complex microservices architectures in multiple clouds using some amazing tools - Docker, Kubernetes, Azure DevOps, Jenkins, Terraform and Ansible.\n\nAre you ready to get start with this amazing course?\n\n### What is DevOps\n\nShow a variety of definitions!\n\nAs you can see it is not easy to get people to agree on a definition of devops. \n\nHowever there are a few things that every body agrees on!\n\nBreak down the wall between Dev and Ops! \n\nAgile helped in bridging the gap between the business and development teams. Development Teams understood the priorities of the business and worked with the business to deliver the stories providing most value first. However, the Dev and Ops teams were not aligned.\n\nThey had different goals.\n\nThe goal of Dev team is to take as many new features to production as possible.\n\nThe goal of Ops team was to keep the production environment as stable as possible.\n\nAs you can see, if taking things to production is difficult, dev and ops are unaligned.\n\nDevOps aims to align the Dev and Ops teams with shared goals. \n\nDev team works with the Ops team to understand and solve operational challenges. Ops team is part of the scrum team and understands the features under development.\n\nHow can we make this possible?\n\nDevops Values CAMS\n- There are four core values in the DevOps movement: Culture, Automation, Measurement, and Sharing (sometimes abbreviated as the acronym CAMS). The goal is to automate as much of the software delivery process as possible.\n\n\nHow about learning DevOps and the 6 Most Popular DevOps Tools (Docker, Kubernetes, Azure Devops, Jenkins, Terraform and Ansible) on three cloud platforms (AWS, Azure and Google Cloud)?\n\nSounds like a dream?\n\nin28minutes makes it a reality with this amazing course containing 200+ step by step lectures and 21 hours of video.\n\nThis course expects ZERO experience with Cloud or DevOps or any of the DevOps tools. \n\n\nThere are a number of use cases we would work on during the course. Here are a couple of examples.\nUSE CASE 1 : You want to be able to provision and make changes to kubernetes clusters in the cloud automatically. All that you want to do is to commit configuration changes to a git repository.\nUSE CASE 2 : You want to automatically deploy new versions of microservices to the kubernetes cluster. You commit your changes to git repository and the new version of microservices will be automatically deployed.\n\nHere is how these use cases would work. Let's start with use case 1.\n- You \n- \n-\n\nIn this course, you will be working on several such use cases to learn\n- 6 Most Popular DevOps Tools (Docker, Kubernetes, Azure Devops, Jenkins, Terraform and Ansible)\n- Three cloud platforms (AWS, Azure and Google Cloud) \n- Implement Continuous Integration, Continuous Deployment, Infrastructure as Code, Service Discovery, Load Balancing and Centralized Configuration for Microservices on Kubernetes in the Cloud\n\nYou will create and run Docker Images for simple Java, Python and JavaScript Applications and a few microservices. You will run the microservices with amazing features on Kubernetes. You will create 8 terraform projects to provision virtual servers, storage buckets, load balancers and kubernetes clusters. You will create 8 azure devops pipelines and learn to use azure devops to manage your agile sprints. You will learn to implement continuous integration with Jenkins. You will install and manage software on multiple cloud servers using Ansible.\n\nFor course video : In the next 10 minutes, we will get a quick introduction to how software development evolved from water fall to agile to devops. Once you get the overview, we will start getting our hands dirty with containers and Docker.\n\nI will see you in the next step with a little bit of history. See you there.\n\n\nI'm Ranga Karanam. I'm the founder of in28Minutes and creator of some of the world's most popular courses on Full Stack, Microservices and the Cloud. I've helped more than 300,000 learners around the world acquire new technology skills. We have almost 30,000 5-Star reviews on our courses. So, rest assured you are in good hands.\n\nSo, are your ready to join me and take this amazing journey into the world of DevOps with 6 tools and 3 clouds?\n\nAre you ready to learn DevOps with Docker, Kubernetes, Terraform, Ansible, Jenkins and Azure DevOps in multiple clouds - AWS, Azure and Google Cloud?\n\nStart learning DevOps and join me on this exciting journey now.\n\nI'll see you in the course.\n\nhttps://www.udemy.com/course/devops-with-docker-kubernetes-and-azure-devops/?couponCode=NEW-COURSE\n\nhttps://links.in28minutes.com/DevOps-LinkedIn\nhttps://links.in28minutes.com/DevOps-YouTube\nhttps://links.in28minutes.com/DevOps-SBT\nhttps://links.in28minutes.com/DevOps-Teachable\n\n\nAre you excited to learn about DevOps? Let's get started.\n\nWhat is DevOps? How do you define it?\n\nAs with most buzzwords around software development, there is no accepted definition for DevOps.\n\nDefinitions vary from simple ones, like these two, to complex definitions that last 3 slides.. \n\nInstead of trying define DevOps, let's understand how Software Development evolved to DevOps.\n\nFirst few decades of software development was centered around the water fall model. Waterfall model approached software development the same way that you would approach building a real estate project - for example, building an amazing bridge. You will build software in multiple phases that can go on for a period any where between a few weeks to a few months  - Requirements, ..... In most waterfall projects, it would be months before the business sees a working version of an application. \n\nWhile working in the waterfall model for a few decades, we understood a few key elements around developing great software:\n- Software Development is a multi disciplinary effort involving a variety of skills. Communication between people is essential for the success of a software project. In the waterfall model, we tried to enhance communication by trying to prepare 1000 page documents on Requirements, Design, Architecture and Deployment. But, over a period of time, we understood that the best way to enhance communication within the team, is to get the team together. Get a variety of skills in the same team. We understood that cross functional teams - with wide range of skills - work great.\n- Getting Feedback Quickly is important. Building great software is all about getting quick feedback? Are we building an application which meets the business expections? You cannot wait for months to get feedback. You would want to know quickly. Will your application have problems if it is deployed to production? You don't want to know it after a few months. You want to find it out as early as possible.\nThe earlier we find a problem, the easier it is to fix it.\nWe found that the best software teams are structured to enable quick feedback. Anything I'm working on, I would like to know if I'm doing the right thing as early as possible . \n- Automation is critical. Software Development involves a wide range of activities. Doing things manually is slow and error prone. We understood that it's essential to always look for opportunities to introduce Automation.\n\nSo, having understood the key elements to develop great software, in the next steps, lets look at how we evolved to Agile and DevOps.\n\nIn the next step, let's look at the evolution towards Agile.\n\nWelcome Back.  Agile was the first step in evolution towards implementing our learnings with enhanced communication between teams, getting feedback and bringing in automation.\n\nAgile brought the business and development teams together into one team which works to build great software in small iterations called sprints. Instead of spending weeks or months on each phase of development, agile focuses on taking small requirements called user stories through the development cycle within a few days, sometimes within the same day.\n\nHow did Agile enhance communication between teams? \n\nAgile brought the business and development teams together. Business is responsible for defining what to build? What are the requirements? Development is responsible for building a product that meets the requirements. When I say Development, I include everybody that works on Design, Coding, Testing and Packaging your software. \n\nIn Agile, a representative from Business, called a Product Owner, is always present with the team, the team understands the business objectives clearly. When the development team does not understand the requirements well and is going in a wrong path, Product Owner helps them do course correction and stay on the correct path. Result : The final product the team builds is something that the business wants.\n\nAnother important factor is that Agile Teams have cross functional skills - coding skills - front end, api and databases, testing skills and business skills. This enhances communication between people that have to work together to build great software.\n\nWhat are the Automation areas where Agile Teams focused on? Software Products can have a variety of defects. Functional Defects mean the product does not work as expected. Technical Defects make the maintainence of the software difficult. For example, code quality problems. In general, agile teams were focused on using automation to find technical and functional defects as early as possible.\n\nAgile teams focused on automation tests. Writing great unit tests to test your methods and classes. Writing great integration tests to test your modules and applications. Agile teams also focused extensively on code quality. Tools like SONAR were used to assess the code quality of applications. \n\nIs it sufficient if you have great automation tests and great code quality checks? You would want to run them as often as possible. Agile Teams focused on Continuous Integration. You make a commit to version control. Your Unit Tests, Automation Tests and Code Quality Checks were automatically executed in a Continuous Integration Pipeline. Most popular CI/CD tool during the early agile time period was Jenkins.\n\nHow did Agile promote immediate feedback? \n\nMost important factor is that Business does not need to wait for months to see the final product.  At the end of every sprint, the product is demoed to all stakeholders including Architecture and Business Teams. All feedback is taken in while prioritizing user stories for the next sprint. Result : The final product the team builds is something that the business wants. \n\nAnother important factor that enables immediate feedback is continuous integration. Let's say I commit some code into version control. Within 30 minutes, I get feedback if my code causes a unit test failure or a integration test failure. I will get feedback if my code does not meet code quality standards or does not have enough code coverage in the unit tests.\n\nWas agile successful? Yes. For sure. By focusing on improving the communication between business and development teams, and focusing on finding a variety of defects early, Agile took software development to the next level. \n\nI, personally, had a wonderful experience working with some amazing teams in the Agile model. Software Engineering, which for me represents all the efforts in building software from requirements to taking applications live, for the first time, was as enjoyable as programming.\n\nBut, does evolution stop? Nope.\n\nNew challenges emerged. We started moving towards a microservices architecture and we started building a number of small api's instead of building large monolith applications. What was the new challenge? Operations becomes more important. Instead of doing 1 monolith release a month, you are doing hundreds of small microservice releases every week. Debugging problems across microservices and getting visibility into what's happening with the microservices became important. \n\nIt was time for a new buzzword in software development. DevOps.\n\nLet's discuss DevOps in the next step.\n\nWelcome Back. What was the focus of DevOps? Focus of DevOps was on enhancing the communication between the Development and the Operations Team. How do we make deployments easier? How do we make the work operations team does more visible to the development team?\n\nHow did DevOps enhance communication between teams? DevOps brought Operations Teams closer to the Development Teams. In more mature enterprises, Development and Operations Teams worked as one Team. They started sharing common goals and both teams started to understand the challenges the other team faces. In enterprises in the early stages of devops evolution, a representative from the operations team can be involved in the sprints - standups and retrospectives.\n\nWhat are the Automation areas where DevOps Teams focused on? In addition to the focus areas of agile - Continuous Integration and Test Automation, the DevOps teams were focused on helping automate several of the Operation Teams Activities - Provisioning Servers, Configuring Software on Servers, Deploying Applications and Monitoring Production Environments. A few key terminology are Continuous Deployment, Continuous Delivery and Infrastructure as Code. \n\nContinuous Deployment is all about continuously deploying new version of software on Test Environments. In even more mature organizations like Google, Facebook, Continuous Delivery helps in continuously deploying software to production - maybe hundreds of production deployments per day. Infrastructure as Code is all about treating your Infrastructure like you treat your application code. You create your infrastructure - servers, load balancers and database - in an automated way using configuration. You would version control your infrastructure - so that you can track your infrastructure changes over a period of time. We would discuss Continuous Deployment, Continuous Delivery and Infrastructure as Code in depth in the next steps. \n\nHow did DevOps promote immediate feedback? \n\nDevOps brings Operations and Development Teams Together. Because Operations and Development are part of the same team, the entire team understands the challenges associated with Operations and Development. Any operational problems get quick attention of the developers. Any challenges in taking software live get early attention of operations team.\n\nDevOps encouraged Continuous Integration, Continuous Delivery and Infrastructure as Code.\n\nBecause of Continous Delivery, If I make a code change or a configuration change that might break a test or a staging environment, I would know it within a few hours.\n\nBecause of Infrastructure As Code, Developers can self provision environments, deploy code and find problems on their own, without any help from operations team. \n\nWhile we talk as if agile and devops are two different things to make things simple, in reality, there is no accepted definition for what devops means. \n\nI see agile and devops as two phases that helped us improve how build great software. They don't compete against each other but together they help us build amazing software products.\n\nAs far as iam concerned the objective of Agile and DevOps together is to do things that \n- Promote Communication and Feedback between Business, Development and Operations Teams\n- Ease the painpoints with Automation. We will discuss about Unit Tests, Integration Tests, Code Quality Checks, Continuous Integration, Continuous Delivery, Infrastructure as Code and Standardization through Containerization during this amazing journey in this course.\n\nIn the next steps, let's focus on some of the most important aspects of DevOps - Enhancing communication between Dev and Ops, Enhancing quick feedback through Continuous Delivery and Automating Infrastructure using IAAC.\n\nBring Down the Wall\n\nAs we discussed in the previous steps, DevOps is a Natural Evolution of Software Development. DevOps is NOT JUST a tool, a framework or just automation. It is a combination of all these. \n\nDevOps focuses on People, Process and Products. People aspects of DevOps are all about Culture and Create a Great Mindset. A culture which promotes open communication and values quick feedback. A culture that value high quality software. \n\nAgile helped in bridging the gap between the business and development teams. Development Teams understood the priorities of the business and worked with the business to deliver the stories providing most value first. However, the Dev and Ops teams were not aligned.\n\nThey had different goals.\n\nThe goal of Dev team is to take as many new features to production as possible.\n\nThe goal of Ops team was to keep the production environment as stable as possible.\n\nAs you can see, if taking things to production is difficult, dev and ops are unaligned.\n\nDevOps aims to align the Dev and Ops teams with shared goals. \n\nDev team works with the Ops team to understand and solve operational challenges. Ops team is part of the scrum team and understands the features under development.\n\nHow can we make this possible?\n\nBreak down the wall between Dev and Ops! \n\nIn matured Dev Ops enterprises, Dev and Ops work as part of the same scrum team and share each other responsibilities. However, if you are in the early stages of devops evolution, how can you get Dev and Ops have common objectives and work together?\n\nHere are some of the things you can do:\n\nOne of the things you can start with is to have the development team share some of the responsibilities of the operation team. For example, the dev team can take the responsibility of new release for the first week after production deployment. This helps the development team understand the challenges faced by operations in taking new releases live and help them come together and find better solutions.\n\nOther thing you can do is to involve a representative of the operations team in the Scrum activities. Involve them in Standups and Retrospectives of the team.\n\nThe next thing you can do is to make the challenges faced by Operations team more visible to the Development team. When you face any challenges in operations, make development teams part of the teams working on solutions.\n\nWhich way you take, find ways of breaking the wall and get the Development and Operations team together.\n\nAnother interesting option emerges because of automation. By using Infrastructure as Code and enabling Self Provisioning for Developers, You can create common language that operations and development teams understand - code. More about this in the next couple of steps.\n\nPipelines, Continuous Integration, Continuous Deployment, Continuous Delivery\n- Commit -> Unit Tests >  Code Quality Checks > Integration Tests > Package > Deploy App > Manual Testing > Approval > Next Environment\n- Tools - Azure DevOps and Jenkins\n- Build - Building a deployable version of application. Tools - Maven, Gradle, Docker, WASM, What is used for Python?, Anything else for JavaScript?\n- Deployment - Putting new applications or new versions of application live. Tools - CI/CD Tools. Application Deployable - ear, war, container image\n\n\nIAAC\n- Done Manually - Provision Server, Install Java, Install Tomcat, Deploy Application\n\t- Everytime you create a server, this needs to be done manually. What if Java version needs to be updated? A security patch needs to be applied?\n\t- \n- Code Your Infra - Treat Infrastructure the same way as application code\n\t- Infra team focuses on value added work (instead of routine work)\n\t- Less Errors and Quick Recovery from Failures\n\t- Servers are Consistent (Avoids Configuration Drift)\n- Tools - Ansible and Terraform\n- Create Template, Provision Servers(Enabled by Cloud), Install Software, Configure Software, Deploy Application\n- Provisioning Tools - Get new server ready with networking capabilities - CloudFormation and Terraform - Designed to provision the servers themselves (as well as the rest of your infrastructure, like load balancers, databases, networking configuration, etc). You can use precreated images created using Packer and AMI (Amazon Machine Image).\n- Configuration management tools - Chef, Puppet, Ansible, and SaltStack - Designed to install and manage software on existing servers.\n\n\nStandardization\n"
        }
      ]
    }
  ]
}