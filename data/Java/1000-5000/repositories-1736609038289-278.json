{
  "metadata": {
    "timestamp": 1736609038289,
    "page": 278,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI4MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "kermitt2/grobid",
      "stars": 3701,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 1.3779296875,
          "content": "/.git\n/bin\n/build\n\n**/build\n!**/pdf.js/build\n**/target\n\ntarget\ngrobid-home/tmp\n.DS_Store\nThumbs.db\n.project\n.settings\n.classpath\n.idea\n#.gradle\n#gradle\n*/out/\n*.iml\n*.log\n*.log.*\n*.old\ntei-alt\nraw-alt\n/log\n/logs\n\ndependency-reduced-pom.xml\n\ngrobid-core/dependency-reduced-pom.xml\n\ngrobid-core/src/test/resources/org/grobid/core/annotations/resTeiStAXParser/out.tei.xml\n\ngrobid-home/models/affiliation-address/model.crf.old\n\ngrobid-home/models/name/header/model.crf.old\n\nbuild.xml\n\n*/maven-build.properties\n*/maven-build.xml\nmaven-build.xml\nrelease.properties\n\ngrobid-quantities\ngrobid-dictionaries\ngrobid-ner\ngrobid-bio\ngrobid-istex\ngrobid-astro\ngrobid-chem\ngrobid-books\ngrobid-smecta\ngrobid-example\ngrobid-test-ant\ngrobid-software\ngrobid-books\ngrobid-smecta\ngrobid-keyterm\ngrobid-home/models/quantities\ngrobid-home/models/dictionaries-lexical-entries\ngrobid-home/models/units\ngrobid-home/models/bio\ngrobid-home/models/ner\ngrobid-home/models/nerfr\ngrobid-home/models/nersense\ngrobid-home/models/astro\ngrobid-home/models/lexical-entry/*\ngrobid-home/models/*lexical-entry*\ngrobid-home/models/lexical-entry/model.wapiti\ngrobid-home/models/dictionary*\ngrobid-home/models/dictionaries*\n\ngrobid-home/models/software*\ngrobid-home/models/superconductors*\ngrobid-home/models/values\ngrobid-home/models/dataseer\ngrobid-home/models/dataset\ngrobid-home/models/*bert/\ngrobid-home/models/*BERT*/\ngrobid-home/models/*scibert*/\n"
        },
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 0.4296875,
          "content": "[*]\ncharset=utf-8\nend_of_line=lf\ninsert_final_newline=false\nindent_style=space\nindent_size=4\n\n[{.babelrc,.stylelintrc,.eslintrc,jest.config,*.bowerrc,*.jsb3,*.jsb2,*.avsc,*.json}]\nindent_style=space\nindent_size=2\n\n[{*.ddl,*.sql}]\nindent_style=space\nindent_size=2\n\n[*.less]\nindent_style=space\nindent_size=2\n\n[*.md]\ninsert_final_newline=true\n\n[{*.yml,*.yaml}]\nindent_style=space\nindent_size=2\n\n[GrobidRestProcessString.java]\nindent_style=tab\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.03125,
          "content": "* text=auto\n*.wapiti text eol=lf"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.560546875,
          "content": ".java-version\ntarget\nbin\ngrobid-home/tmp\n.DS_Store\nThumbs.db\n.project\n.settings\n.classpath\n.idea\n.vscode\n.gradle\n**/build\n*/out/\n*.iml\n*.log\n*.log.*\n*.old\n*.back\ntei-alt\nraw-alt\ntei-new\nraw-new\n/log\n/logs\n\ndependency-reduced-pom.xml\n\ngrobid-core/dependency-reduced-pom.xml\n\ngrobid-core/src/test/resources/org/grobid/core/annotations/resTeiStAXParser/out.tei.xml\n\ngrobid-home/models/affiliation-address/model.crf.old\n\ngrobid-home/models/name/header/model.crf.old\n\nbuild.xml\n\n*/maven-build.properties\n*/maven-build.xml\nmaven-build.xml\nrelease.properties\n\ngrobid-quantities\ngrobid-superconductors\ngrobid-dictionaries\ngrobid-ner\ngrobid-bio\ngrobid-istex\ngrobid-astro\ngrobid-chem\ngrobid-books\ngrobid-smecta\ngrobid-example\ngrobid-software\nsoftware-mentions\ngrobid-keyterm\ndataseer-ml\ndatastet\ngrobid-test-ant\ngrobid-home/models/quantities*\ngrobid-home/models/dictionaries-lexical-entries\ngrobid-home/models/units*\ngrobid-home/models/values*\ngrobid-home/models/bio\ngrobid-home/models/ner\ngrobid-home/models/nerfr\ngrobid-home/models/nersense\ngrobid-home/models/astro\ngrobid-home/models/datasets\n\ngrobid-home/models/lexical-entry/*\ngrobid-home/models/*lexical-entry*\ngrobid-home/models/lexical-entry/model.wapiti\ngrobid-home/models/dictionary*\ngrobid-home/models/dictionaries*\n\ngrobid-home/models/software*\ngrobid-home/models/superconductors*\ngrobid-home/models/values\ngrobid-home/models/dataseer*\ngrobid-home/models/datasets*\ngrobid-home/models/*-bert*/\ngrobid-home/models/*_bert*/\ngrobid-home/models/*scibert*/\ngrobid-home/models/context_*\n\nDockerfile.dataseer\nDockerfile.software\nDockerfile.datastet\n.run\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 19.5810546875,
          "content": "# Changelog\n\nAll notable changes to this project will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/).\n\n## [0.8.2] - TBD\n\n### Added\n- New model specialisation/variants (flavors) mechanism #1151\n- Specialisation/variant process for a lightweight processing that covers other type of scientific articles that are not following the general segmentation schema (e.g. corrections, editorial letters, etc.) #1202\n- Additional training data covering edge cases where the Data Availability statements are over multiple pages #1200\n- Added a flag that allow output the raw copyright information in TEI #1181\n\n### Changed\n\n### Fixed\n- Fix URL identification for certain edge cases #1190, #1191, #1185\n- Fix fulltext model training data #1107 \n- Fix header model training data #1128\n- Updated the docker image's packages to reduce the vulnerabilities #1173\n- Fixed a bug in the handling of badly formatted figures/tables #1207\n- Fixed various security vulnerabilities #1125 #1123 #1205\n- Correct replacement in the filenames of the fulltext generated files #1204\n- Fixed fulltext block start #1203\n\n\n## [0.8.1] - 2024-09-14\n\n### Added\n - Identified URLs are now added in the TEI output #1099\n - Added DL models for patent processing #1082\n - Copyrights owner and licenses identification models #1078 \n - Add research infrastructure recognition for funding processing #1085\n - Add paragraphs coordinates in the TEI output #1068\n - Specify configuration file with DL models enabled for the full docker image #1117\n - Support for biblio-glutton 0.3 #1086\n\n### Changed\n - Update affiliation process #1069\n - Improved the recognition of URLs using (when available) PDF annotations, such as clickable links\n - Updated TEI schema #1084\n - Review patent process #1082\n - Add Kotlin language to support development and testing #1096\n\n### Fixed\n - Avoid splitting URLs between sentences #1097\n - Add missing sentence segmentation in funding and acknowledgement #1106\n - Docker image was optimized to reduce the needed space #1088\n - Fixed OOBE when processing large quantities of notes #1075\n - Corrected `<title>` coordinate attribute name #1070\n - Fix missing coordinates in paragraph continuation #1076\n - Fixed JSON log output\n - Fixed notes identification #1124\n - Fixed extraneous semicolon in the training data #1133\n - Reduced security vulnerabilities in the dependencies #1136 #1137\n\n## New Contributors\n* @tanaynayak made their first contribution in https://github.com/kermitt2/grobid/pull/1133\n* @vipulg13 made their first contribution in https://github.com/kermitt2/grobid/pull/1137\n\n## [0.8.0] - 2023-11-19\n\n### Added\n\n+ Extraction of funder and funding information with a specific new model, see https://github.com/kermitt2/grobid/pull/1046 for details\n+ Optional consolidation of funder with CrossRef Funder Registry\n+ Identification of acknowledged entities in the acknowledgement section\n+ Optional coordinates in title elements\n\n### Changed\n\n+ Dropwizard upgrade to 4.0\n+ Minimum JDK/JVM requirement for building/running the project is now 1.11\n+ Logging now with Logback, removal of Log4j2, optional logs in json format\n+ General review of logs\n+ Enable Github actions / Disable circleci\n\n### Fixed\n\n+ Set dynamic memory limit in pdfalto_server #1038 \n+ Logging in files when training models work now as expected\n+ Various dependency upgrades\n+ Fix #1051 with possible problematic PDF\n+ Fix #1036 for pdfalto memory limit \n+ fix readthedocs build #1040 \n+ fix for null equation #1030\n+ Other minor fixes\n\n## [0.7.3] – 2023-05-13\n\n### Added\n\n+ Support for JDK beyond 1.11, tested up to Java 17, thanks to removal of dynamic native library loading after the start of the JVM\n+ Incremental training (all models and ML engines), add this option in training command line and training web service (#971)\n+ Systematic benchmarking on two new sets: PLOS (1000 artilces) and eLife (984 articles)\n+ All end-to-end evaluation datasets are now available from the same place: https://zenodo.org/record/7708580\n+ Option to output coordinates in notes and figure/table captions\n+ Support for Mac ARM architecture (#975)\n+ Play With Docker documentation (#962)\n\n### Changed\n\n+ Update to DeLFT version 0.3.3\n+ Demo now hosted as HuggingFace space\n+ Additional training data, in particular for citation, reference-segmenter, segmentation, header, etc. \n+ Update Deep Learning models (and some of the CRF)\n+ The standard analyzer for sub-lexical tokenization is available in grobid-core, and used for the citation model (in particular for improving CJK references) (#990)\n+ Update evaluations\n\n### Fixed\n\n+ Correct wrong content type in doc for processCitation web service\n+ Sentence segmentation applied to notes (#995)\n+ Other minor fixes\n\n## [0.7.2] – 2022-10-29\n\n### Added\n\n+ Explicit identification of data/code availability statements (#951) and funding statements (#959), including when they are located in the header\n+ Link footnote and their \"callout\" marker in full text (#944)\n+ Option to consolidate header only with DOI if a DOI is extracted (#742)\n+ \"Window\" application of RNN model for reference-segmenter to cover long bibliographical sections\n+ Add dynamic timeout on pdfalto_server (#926) \n+ A modest Python script to help to find \"interesting\" error cases in a repo of JATS/PDF pairs, grobid-home/scripts/select_error_cases.py\n\n### Changed\n\n+ Update to DeLFT version 0.3.2\n+ Some more training data (authors in reference, segmentation, citation, reference-segmenter) (including #961, #864)\n+ Update of some models, RNN with feature channels and CRF (segmentation, header, reference-segmenter, citation)\n+ Review guidelines for segmentation model\n+ Better URL matching, using in particular PDF URL annotation in account\n\n### Fixed\n\n+ Fix unexpected figure and table labeling in short texts\n+ When matching an ORCID to an author, prioritize Crossref info over extracted ORCID from the PDF (#838)\n+ Annotation errors for acknowledgement and other minor stuff\n+ Fix for Python library loading for Mac\n+ Update docker file to support new CUDA key\n+ Do not dehyphenize text in superscript or subscript\n+ Allow absolute temporary paths\n+ Fix redirected stderr from pdfalto not \"gobbled\" by the java ProcessBuilder call (#923)\n+ Other minor fixes\n\n## [0.7.1] – 2022-04-16\n\n### Added\n\n+ Web services for training models (#778)\n+ Some additional training data for bibliographical references from arXiv\n+ Add a web service to process a list of reference strings, see https://grobid.readthedocs.io/en/processcitationlist/Grobid-service/#apiprocesscitationlist\n+ Extended processHeaderDocument to get result in bibTeX\n\n### Changed\n\n+ Update to DeLFT version to 0.3.1 and TensorFlow 2.7, with many improvements, see https://github.com/kermitt2/delft/releases/tag/v0.3.0\n+ Update of Deep Learning models\n+ Update of JEP and add install script\n+ Update to new biblio-glutton version 0.2, for improved and faster bibliographical reference matching\n+ circleci to replace Travis\n+ Update of processFulltextAssetDocument service to use the same parameters as processFulltextDocument\n+ Pre-compile regex if not already done\n+ Review features for header model\n\n### Fixed\n\n+ Improved date normalization (#760)\n+ Fix possible issue with coordinates related to reference markers (#908) and sentence (#811)\n+ Fix path to bitmap/vector graphics (#836)\n+ Fix possible catastrophic regex backtracking (#867)\n+ Other minor fixes\n\n## [0.7.0] – 2021-07-17\n\n### Added\n\n+ New YAML configuration: all the settings are in one single yaml file, each model can be fully configured independently\n+ Improvement of the segmentation and header models (for header, +1 F1-score for PMC evaluation, +4 F1-score for bioRxiv), improvements for body and citations \n+ Add figure and table pop-up visualization on PDF in the console demo\n+ Add PDF MD5 digest in the TEI results (service only)\n+ Language support packages and xpdfrc file for pdfalto (support of CJK and exotic fonts)\n+ Prometheus metrics \n+ BidLSTM-CRF-FEATURES implementation available for more models\n+ Addition of a \"How GROBID works\" page in the documentation\n\n### Changed\n\n+ JitPack release (RIP jcenter)\n+ Improved DOI cleaning \n+ Speed improvement (around +10%), by factorizing some layout token manipulation\n+ Update CrossRef requests implementation to align to the current usage of CrossRef's `X-Rate-Limit-Limit` response parameter\n\n### Fixed\n\n+ Fix base url in demo console\n+ Add missing pdfalto Graphics information when `-noImage` is used, fix graphics data path in TEI\n+ Fix the tendency to merge tables when they are in close proximity\n\n## [0.6.2] – 2021-03-20\n\n### Added\n\n+ Docker image covering both Deep Learning and CRF models, with GPU detection and preloading of embeddings\n+ For Deep Learning models, labeling is now done by batch: application of the citation DL model is 4 times faster for BidLSTM-CRF (with or without features) and 6 times faster for SciBERT\n+ More tests for sentence segmentation\n+ Add orcid of persons when available from the PDF or via consolidation (i.e. if in CrossRef metadata) \n+ Add BidLSTM-CRF-FEATURES header model (with feature channel)\n+ Add bioRxiv end-to-end evaluation\n+ Bounding boxes for optional section titles coordinates\n\n### Changed\n\n+ Reduce the size of docker images \n+ Improve end-to-end evaluation: multithreaded processing of PDF, progress bar, output the evaluation report in markdown format\n+ Update of several models covering CRF, BidLSTM-CRF and BidLSTM-CRF-FEATURES, mainly improving citation and author recognitions\n+ OpenNLP is the default optional sentence segmenter (similar result as Pragmatic Segmenter for scholar documents after benchmarking, but 30 times faster)\n+ Refine sentence segmentation to exploit layout information and predicted reference callouts\n+ Update jep version to 3.9.1\n\n### Fixed\n\n+ Ignore invalid utf-8 sequences\n+ Update CrossRef multithreaded calls to avoid using the unreliable time interval returned by the CrossRef REST API service, update usage of `Crossref-Plus-API-Token` and update the deprecated crossref field `query.title`\n+ Missing last table or figure when generating training data for the fulltext model\n+ Fix an error related to the feature value for the reference callout for the fulltext model\n+ Review/correct DeLFT configuration documentation, with a step-by-step configuration documentation\n+ Other minor fixes\n\n## [0.6.1] – 2020-08-12\n\n### Added\n\n+ Support of line number (typically in preprints)\n+ End-to-end evaluation and benchmark for preprints using the bioRxiv 10k dataset \n+ Check whether PDF annotation is orcid and add orcid to author in the TEI result\n+ Configuration for making sequence labeling engine (CRF Wapiti or Deep Learning) specific to models\n+ Add a developers guide and a FAQ section in the documentation\n+ Visualization of formulas on PDF layout in the demo console\n+ Feature for subscript/superscript style in fulltext model\n\n### Changed\n\n+ New significantly improved header model: with new features, new training data (600 new annotated examples, old training data is entirely removed), new labels and updated data structures in line with the other models\n+ Update of the segmentation models with more training data\n+ Removal of heuristics related to the header\n+ Update to gradle 6.5.1 to support JDK 13 and 14\n+ TEI schemas \n+ Windows is not supported in this release\n\n### Fixed\n\n+ Preserve affiliations after consolidation of the authors \n+ Environment variable config override for all properties \n+ Unfrequent duplication of the abstract in the TEI result\n+ Incorrect merging of affiliations\n+ Noisy parentheses in the bibliographical reference markers\n+ In the console demo, fix the output filename wrongly taken from the input form when the text form is used\n+ Synchronisation of the language detection singleton initialisation in case of multithread environment\n+ Other minor fixes\n\n## [0.6.0] – 2020-04-24\n\n### Added\n\n+ Table content structuring (thanks to @Vitaliy-1), see [PR #546](https://github.com/kermitt2/grobid/pull/546)\n+ Support for `application/x-bibtex` at `/api/processReferences` and `/api/processCitation` (thanks to @koppor)\n+ Optionally include raw affiliation string in the TEI result\n+ Add dummy model for facilitating test in Grobid modules\n+ Allow environment variables for config properties values to ease Docker config \n+ ChangeLog\n\n### Changed\n\n+ Improve CORS configuration #527 (thank you @lfoppiano)\n+ Documentation improvements\n+ Update of segmentation and fulltext model and training data\n+ Better handling of affiliation block fragments\n+ Improved DOI string recognition\n+ More robust n-fold cross validation (case of shared grobid-home)\n\n### Fixed\n\n+ Fixed flags of pdf2xml in `Dockerfile`\n+ Some fixes for better TEI result format conformance \n+ Other minor fixes\n\n## [0.5.6] – 2019-10-16\n\n### Added\n\n+ n-fold cross evaluation and better evaluation report (thanks to @lfoppiano)\n\n### Changed\n\n+ Better abstract structuring (with citation contexts)\n+ Improved PMC ID and PMID recognition\n+ Improved subscript/superscript and font style recognition (via [pdfalto](https://github.com/kermitt2/pdfalto))\n+ Improved JEP integration (support of python virtual environment for using DeLFT Deep Learning library, thanks @de-code and @lfoppiano)\n+ Improved dehyphenization (thanks to @lfoppiano)\n\n### Fixed\n\n+ Several bug fixes (thanks @de-code, @bnewbold, @Vitaliy-1 and @lfoppiano)\n\n## [0.5.5] – 2019-05-29\n\n### Changed\n\n+ Using [pdfalto](https://github.com/kermitt2/pdfalto) instead of pdf2xml for the first PDF parsing stage, with many improvements in robustness, ICU support, unknown glyph/font normalization (thanks in particular to @aazhar)\n+ Improvement and full review of the integration of consolidation services, supporting [biblio-glutton](https://github.com/kermitt2/biblio-glutton) (additional identifiers and Open Access links) and [Crossref REST API](https://github.com/CrossRef/rest-api-doc) (add specific user agent, email and token for Crossref Metadata Plus)\n+ Updated lexicon #396\n\n### Fixed\n\n+ Fix bounding box issues for some PDF #330\n\n## [0.5.4] – 2019-02-12\n\n### Added\n\n+ Transparent usage of [DeLFT](https://github.com/kermitt2/delft) deep learning models (BidLSTM-CRF/ELMo) instead of Wapiti CRF models, native integration via [JEP](https://github.com/ninia/jep)\n+ Support of [biblio-glutton](https://github.com/kermitt2/biblio-glutton) as DOI/metadata matching service, alternative to crossref REST API\n\n### Changed\n\n+ Improvement of citation context identification and matching (+9% recall with similar precision, for PMC sample 1943 articles, from 43.35 correct citation contexts per article to 49.98 correct citation contexts per article)\n+ Citation callout now in abstract, figure and table captions\n+ Structured abstract (including update of TEI schema)\n\n### Fixed\n\n+ Bug fixes and some more parameters: by default using all available threads when training (thanks [@de-code](https://github.com/de-code)) and possibility to load models at the start of the service\n\n## [0.5.3] – 2018-11-25\n\n### Added\n\n+ Support of proxy for calling crossref with Apache HttpClient\n\n### Changed\n\n+ Improvement of consolidation options and processing (better handling of CrossRef API, but the best is coming soon ;)\n+ Better recall for figure and table identification (thanks to @detonator413)\n\n### Fixed\n\n+ Minor bug fixing\n\n## [0.5.2] – 2018-10-17\n\n### Added\n\n+ Added [Grobid clients](https://grobid.readthedocs.io/en/latest/Grobid-service/#clients-for-grobid-web-services) for Java, Python and NodeJS\n+ Added metrics in the REST entrypoint (accessible via <http://localhost:8071>)\n+ Added counters for consolidation tasks and consolidation results\n+ Added case sensitiveness option in lexicon/FastMatcher\n\n### Changed\n\n+ Updated documentation\n\n### Fixed\n\n+ Corrected back status codes from the REST API when no available engine (503 is back again to inform the client to wait, it was removed by error in version 0.5.0 and 0.5.1 for PDF processing services only, see documentation of the REST API)\n+ Bugfixing #339, #322, #300, and others\n\n## [0.5.1] – 2018-01-29\n\n### Fixed\n\n+ Various bug fixes\n\n## [0.5.0] – 2017-11-09\n\n### Changed\n\n+ Migrate from maven to gradle for faster, more flexible and more stable build, release, etc.\n+ Usage of Dropwizard for web services\n+ Move the Grobid service manual to [readthedocs](http://grobid.readthedocs.io/en/latest/Grobid-service/)\n+ (thanks to @detonator413 and @lfoppiano for this release! future work in versions 0.5.* will focus again on improving PDF parsing and structuring accuracy)\n\n## [0.4.4] – 2017-10-13\n\n### Fixed\n\n+ Fixed issue that was making the release build not working\n\n## [0.4.3] – 2017-10-07\n\n### Added\n\n+ New training data and features for bibliographical references, in particular for covering HEP domain (INSPIRE), arXiv identifier, DOI and url (thanks @iorala and @michamos !)\n+ Support for CrossRef REST API (instead of the slow OpenURL-style API which requires a CrossRef account), in particular for multithreading usage (thanks @Vi-dot)\n+ Unicode normalisation and more robust body extraction (thanks @aoboturov)\n\n### Changed\n\n+ Updated models: f-score improvement on the PubMed Central sample, bibliographical references +2.5%, header +7%  \n+ Improve training data generation and documentation (thanks @jfix)\n+ Update of the pdf2xml fork for Windows (thanks @lfoppiano)\n\n### Fixed\n\n+ fixes, tests, documentation\n\n## [0.4.2] – 2017-08-05\n\n### Added\n\n+ Identification of equations (with PDF coordinates)\n+ End-to-end evaluation with Pub2TEI conversions\n\n### Changed\n\n+ f-score improvement for the PubMed Central sample: fulltext +10-14%, header +0.5%, citations +0.5%\n+ More robust PDF parsing\n\n### Fixed\n\n+ many fixes and refactoring\n\n## [0.4.1] – 2016-10-02\n\n### Added\n\n+ Support for Windows thanks to the contributions of Christopher Boumenot!\n+ Support for Docker\n+ New web services for PDF annotation and updated web console application\n\n### Changed\n\n+ Some improvements on figure/table extraction - but still experimental at this stage (work in progress, as the whole full text model)\n\n### Fixed\n\n+ Fixes and refactoring.\n\n## [0.4.0] – 2016-10-02\n\n### Changed\n\n+ Improvement of the recognition of citations thanks to refinements of CRF features - +4% in f-score for the PubMed Central sample.\n+ Improvement of the full text model, with new features and the introduction of two additional models for figures and tables.\n+ More robust synchronization of CRF sequence with PDF areas, resulting in improved bounding box calculations for locating annotations in the PDF documents.\n+ Improved general robustness thanks to better token alignments.\n\n[Unreleased]: https://github.com/kermitt2/grobid/compare/0.7.0...HEAD\n[0.7.0]: https://github.com/kermitt2/grobid/compare/0.6.2...0.7.0\n[0.6.2]: https://github.com/kermitt2/grobid/compare/0.6.1...0.6.2\n[0.6.1]: https://github.com/kermitt2/grobid/compare/0.6.0...0.6.1\n[0.6.0]: https://github.com/kermitt2/grobid/compare/0.5.6...0.6.0\n[0.5.6]: https://github.com/kermitt2/grobid/compare/0.5.5...0.5.6\n[0.5.5]: https://github.com/kermitt2/grobid/compare/0.5.4...0.5.5\n[0.5.4]: https://github.com/kermitt2/grobid/compare/0.5.3...0.5.4\n[0.5.3]: https://github.com/kermitt2/grobid/compare/0.5.2...0.5.3\n[0.5.2]: https://github.com/kermitt2/grobid/compare/0.5.1...0.5.2\n[0.5.1]: https://github.com/kermitt2/grobid/compare/0.5.0...0.5.1\n[0.5.0]: https://github.com/kermitt2/grobid/compare/grobid-parent-0.4.4...0.5.0\n[0.4.4]: https://github.com/kermitt2/grobid/compare/grobid-parent-0.4.3...grobid-parent-0.4.4\n[0.4.3]: https://github.com/kermitt2/grobid/compare/grobid-parent-0.4.2...grobid-parent-0.4.3\n[0.4.2]: https://github.com/kermitt2/grobid/compare/grobid-parent-0.4.1...grobid-parent-0.4.2\n[0.4.1]: https://github.com/kermitt2/grobid/compare/grobid-parent-0.4.0...grobid-parent-0.4.1\n[0.4.0]: https://github.com/kermitt2/grobid/compare/grobid-parent-0.3.9...grobid-parent-0.4.0\n\n<!-- markdownlint-disable-file MD024 MD033 -->\n"
        },
        {
          "name": "Dockerfile.crf",
          "type": "blob",
          "size": 2.798828125,
          "content": "## Docker GROBID image\n\n## Docker GROBID image using CRF models only - NOTE: you SHOULD use preferably the Deep Learning image\n\n## See https://grobid.readthedocs.io/en/latest/Grobid-docker/\n\n## docker build -t grobid/grobid:GROBID_VERSION --build-arg GROBID_VERSION=GROBID_VERSION .\n## docker run -t --rm -p 8080:8070 -p 8081:8071 {image_name}\n\n# To connect to the container with a bash shell\n# > docker exec -i -t {container_name} /bin/bash\n\n# -------------------\n# build builder image\n# -------------------\nFROM openjdk:17-jdk-slim as builder\n\nUSER root\n\nRUN apt-get update && \\\n    apt-get -y upgrade && \\\n    apt-get -y --no-install-recommends install unzip\n\nWORKDIR /opt/grobid-source\n\n# gradle\nCOPY gradle/ ./gradle/\nCOPY gradlew ./\nCOPY gradle.properties ./\nCOPY build.gradle ./\nCOPY settings.gradle ./\n\n# source\nCOPY grobid-home/ ./grobid-home/\nCOPY grobid-core/ ./grobid-core/\nCOPY grobid-service/ ./grobid-service/\nCOPY grobid-trainer/ ./grobid-trainer/\n\n# cleaning unused native libraries before packaging\nRUN rm -rf grobid-home/pdf2xml\nRUN rm -rf grobid-home/pdfalto/lin-32\nRUN rm -rf grobid-home/pdfalto/mac-64\nRUN rm -rf grobid-home/pdfalto/mac_arm-64\nRUN rm -rf grobid-home/pdfalto/win-*\nRUN rm -rf grobid-home/lib/lin-32\nRUN rm -rf grobid-home/lib/win-*\nRUN rm -rf grobid-home/lib/mac-64\n\n# cleaning Delft models\nRUN rm -rf grobid-home/models/*-BidLSTM_CRF*\n\nENV GROBID_SERVICE_OPTS \"-Djava.library.path=grobid-home/lib/lin-64:grobid-home/lib/lin-64/jep\"\n\nRUN ./gradlew clean assemble --no-daemon  --info --stacktrace\n\nWORKDIR /opt/grobid\nRUN unzip -o /opt/grobid-source/grobid-service/build/distributions/grobid-service-*.zip && \\\n    mv grobid-service* grobid-service\nRUN unzip -o /opt/grobid-source/grobid-home/build/distributions/grobid-home-*.zip && \\\n    chmod -R 755 /opt/grobid/grobid-home/pdfalto\nRUN rm -rf grobid-source\n\n# -------------------\n# build runtime image\n# -------------------\nFROM openjdk:17-slim\n\nRUN apt-get update && \\\n    apt-get -y upgrade && \\\n    apt-get -y --no-install-recommends install libxml2 libfontconfig && \\\n    rm -rf /var/lib/apt/lists/*\n\n# Add Tini\nENV TINI_VERSION v0.19.0\nADD https://github.com/krallin/tini/releases/download/${TINI_VERSION}/tini /tini\nRUN chmod +x /tini\nENTRYPOINT [\"/tini\", \"-s\", \"--\"]\n\nWORKDIR /opt/grobid\n\nCOPY --from=builder /opt/grobid .\n\nENV GROBID_SERVICE_OPTS \"-Djava.library.path=grobid-home/lib/lin-64:grobid-home/lib/lin-64/jep --add-opens java.base/java.lang=ALL-UNNAMED --add-opens java.base/sun.nio.ch=ALL-UNNAMED --add-opens java.base/java.io=ALL-UNNAMED\"\n\nCMD [\"./grobid-service/bin/grobid-service\"]\n\nARG GROBID_VERSION\n\nLABEL \\\n    authors=\"The contributors\" \\\n    org.label-schema.name=\"GROBID\" \\\n    org.label-schema.description=\"Image with GROBID service\" \\\n    org.label-schema.url=\"https://github.com/kermitt2/grobid\" \\\n    org.label-schema.version=${GROBID_VERSION}\n"
        },
        {
          "name": "Dockerfile.delft",
          "type": "blob",
          "size": 5.6181640625,
          "content": "## Docker GROBID image using deep learning models and/or CRF models\n\n## See https://grobid.readthedocs.io/en/latest/Grobid-docker/\n\n## usage example with version 0.8.0:\n## docker build -t grobid/grobid:0.8.0 --build-arg GROBID_VERSION=0.8.0 --file Dockerfile.delft .\n\n## no GPU:\n## docker run -t --rm --init -p 8070:8070 -p 8071:8071 -v /home/lopez/grobid/grobid-home/config/grobid.properties:/opt/grobid/grobid-home/config/grobid.properties:ro  grobid/grobid:0.8.0\n\n## allocate all available GPUs (only Linux with proper nvidia driver installed on host machine):\n## docker run --rm --gpus all --init -p 8070:8070 -p 8071:8071 -v /home/lopez/grobid/grobid-home/config/grobid.properties:/opt/grobid/grobid-home/config/grobid.properties:ro  grobid/grobid:0.8.0\n\n# -------------------\n# build builder image\n# -------------------\n\nFROM openjdk:17-jdk-slim as builder\n\nUSER root\n\nRUN apt-get update && \\\n    apt-get -y upgrade && \\\n    apt-get -y --no-install-recommends install unzip\n\nWORKDIR /opt/grobid-source\n\n# gradle\nCOPY gradle/ ./gradle/\nCOPY gradlew ./\nCOPY gradle.properties ./\nCOPY build.gradle ./\nCOPY settings.gradle ./\n\n# source\nCOPY grobid-home/ ./grobid-home/\nCOPY grobid-core/ ./grobid-core/\nCOPY grobid-service/ ./grobid-service/\nCOPY grobid-trainer/ ./grobid-trainer/\n\n# cleaning unused native libraries before packaging\nRUN rm -rf grobid-home/pdf2xml\nRUN rm -rf grobid-home/pdfalto/lin-32\nRUN rm -rf grobid-home/pdfalto/mac-64\nRUN rm -rf grobid-home/pdfalto/mac_arm-64\nRUN rm -rf grobid-home/pdfalto/win-*\nRUN rm -rf grobid-home/lib/lin-32\nRUN rm -rf grobid-home/lib/win-*\nRUN rm -rf grobid-home/lib/mac-64\n\n# Setting DL-powered configuration\nRUN rm grobid-home/config/grobid.yaml && \\\n    mv grobid-home/config/grobid-full.yaml grobid-home/config/grobid.yaml\n\nRUN ./gradlew clean assemble --no-daemon  --info --stacktrace\n\nWORKDIR /opt/grobid\nRUN unzip -o /opt/grobid-source/grobid-service/build/distributions/grobid-service-*.zip && \\\n    mv grobid-service* grobid-service\nRUN unzip -o /opt/grobid-source/grobid-home/build/distributions/grobid-home-*.zip && \\\n    chmod -R 755 /opt/grobid/grobid-home/pdfalto\nRUN rm -rf grobid-source\n\n# -------------------\n# build runtime image\n# -------------------\n\n# use NVIDIA Container Toolkit to automatically recognize possible GPU drivers on the host machine\nFROM tensorflow/tensorflow:2.7.0-gpu\n\n# setting locale is likely useless but to be sure\nENV LANG C.UTF-8\n\n# update NVIDIA Cuda key (following a key rotation in April 2022)\nRUN apt-get install -y wget && \\\n    apt-key del 7fa2af80 && \\\n    rm /etc/apt/sources.list.d/cuda.list && \\\n    rm /etc/apt/sources.list.d/nvidia-ml.list && \\\n    wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.0-1_all.deb && \\\n    dpkg -i cuda-keyring_1.0-1_all.deb\n\n# Add Tini\nENV TINI_VERSION v0.19.0\nADD https://github.com/krallin/tini/releases/download/${TINI_VERSION}/tini /tini\nRUN chmod +x /tini\nENTRYPOINT [\"/tini\", \"-s\", \"--\"]\n\n# install JRE, python and other dependencies\nRUN apt-get update && \\\n    apt-mark hold libcudnn8 && \\\n    apt-get -y upgrade && \\\n    apt-get -y --no-install-recommends install apt-utils build-essential gcc libxml2 libfontconfig unzip curl \\\n    openjdk-17-jre-headless ca-certificates-java \\\n    musl gfortran \\\n    python3 python3-pip python3-setuptools python3-dev \\\n    && apt-get clean \\\n    && rm -rf /var/lib/apt/lists/*\n\nWORKDIR /opt/grobid\n\nCOPY --from=builder /opt/grobid .\n\nRUN python3 -m pip install pip --upgrade\n\n# install DeLFT via pypi\nRUN pip3 install requests delft==0.3.3\n# link the data directory to /data\n# the current working directory will most likely be /opt/grobid\nRUN mkdir -p /data \\\n    && ln -s /data /opt/grobid/data \\\n    && ln -s /data ./data\n\n# disable python warnings (and fix logging)\nENV PYTHONWARNINGS=\"ignore\"\n\nWORKDIR /opt/grobid\n\nENV JAVA_OPTS=-Xmx4g\n\n# install jep (and temporarily the matching JDK)\nENV JDK_URL=https://download.java.net/java/GA/jdk17.0.2/dfd4a8d0985749f896bed50d7138ee7f/8/GPL/openjdk-17.0.2_linux-x64_bin.tar.gz\nRUN curl --fail --show-error --location -q ${JDK_URL} -o /tmp/openjdk.tar.gz &&  \\\n    mkdir /tmp/jdk-17 &&  \\\n    tar xvfz /tmp/openjdk.tar.gz --directory /tmp/jdk-17 --strip-components 1 --no-same-owner && \\\n    /tmp/jdk-17/bin/javac -version && \\\n    JAVA_HOME=/tmp/jdk-17 pip3 install jep==4.0.2 &&  \\\n    rm -f /tmp/openjdk.tar.gz && \\\n    rm -rf /tmp/jdk-17\n\nENV LD_LIBRARY_PATH=/usr/local/lib/python3.8/dist-packages/jep:grobid-home/lib/lin-64:grobid-home/lib/lin-64/jep:${LD_LIBRARY_PATH}\n# remove libjep.so because we are providing our own version in the virtual env above\nRUN rm /opt/grobid/grobid-home/lib/lin-64/jep/libjep.so\n\n# preload embeddings, for GROBID all the RNN models use glove-840B (default for the script), ELMo is currently not loaded \n# to be done: mechanism to download GROBID fine-tuned models based on SciBERT if selected (but not good enough for the moment)\n\nCOPY --from=builder /opt/grobid-source/grobid-home/scripts/preload_embeddings.py .\nCOPY --from=builder /opt/grobid-source/grobid-home/config/resources-registry.json .\nRUN python3 preload_embeddings.py --registry ./resources-registry.json &&  \\\n    ln -s /opt/grobid /opt/delft\n\nRUN mkdir delft && \\\n    cp ./resources-registry.json delft/\n\nENV GROBID_SERVICE_OPTS \"--add-opens java.base/java.lang=ALL-UNNAMED --add-opens java.base/sun.nio.ch=ALL-UNNAMED --add-opens java.base/java.io=ALL-UNNAMED\"\n\nCMD [\"./grobid-service/bin/grobid-service\"]\n\nARG GROBID_VERSION\n\nLABEL \\\n    authors=\"The contributors\" \\\n    org.label-schema.name=\"GROBID\" \\\n    org.label-schema.description=\"Image with GROBID service\" \\\n    org.label-schema.url=\"https://github.com/kermitt2/grobid\" \\\n    org.label-schema.version=${GROBID_VERSION}\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 10.9267578125,
          "content": "\n                                Apache License\n                          Version 2.0, January 2004\n                       http://www.apache.org/licenses/\n\n  TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n  1. Definitions.\n\n     \"License\" shall mean the terms and conditions for use, reproduction,\n     and distribution as defined by Sections 1 through 9 of this document.\n\n     \"Licensor\" shall mean the copyright owner or entity authorized by\n     the copyright owner that is granting the License.\n\n     \"Legal Entity\" shall mean the union of the acting entity and all\n     other entities that control, are controlled by, or are under common\n     control with that entity. For the purposes of this definition,\n     \"control\" means (i) the power, direct or indirect, to cause the\n     direction or management of such entity, whether by contract or\n     otherwise, or (ii) ownership of fifty percent (50%) or more of the\n     outstanding shares, or (iii) beneficial ownership of such entity.\n\n     \"You\" (or \"Your\") shall mean an individual or Legal Entity\n     exercising permissions granted by this License.\n\n     \"Source\" form shall mean the preferred form for making modifications,\n     including but not limited to software source code, documentation\n     source, and configuration files.\n\n     \"Object\" form shall mean any form resulting from mechanical\n     transformation or translation of a Source form, including but\n     not limited to compiled object code, generated documentation,\n     and conversions to other media types.\n\n     \"Work\" shall mean the work of authorship, whether in Source or\n     Object form, made available under the License, as indicated by a\n     copyright notice that is included in or attached to the work\n     (an example is provided in the Appendix below).\n\n     \"Derivative Works\" shall mean any work, whether in Source or Object\n     form, that is based on (or derived from) the Work and for which the\n     editorial revisions, annotations, elaborations, or other modifications\n     represent, as a whole, an original work of authorship. For the purposes\n     of this License, Derivative Works shall not include works that remain\n     separable from, or merely link (or bind by name) to the interfaces of,\n     the Work and Derivative Works thereof.\n\n     \"Contribution\" shall mean any work of authorship, including\n     the original version of the Work and any modifications or additions\n     to that Work or Derivative Works thereof, that is intentionally\n     submitted to Licensor for inclusion in the Work by the copyright owner\n     or by an individual or Legal Entity authorized to submit on behalf of\n     the copyright owner. For the purposes of this definition, \"submitted\"\n     means any form of electronic, verbal, or written communication sent\n     to the Licensor or its representatives, including but not limited to\n     communication on electronic mailing lists, source code control systems,\n     and issue tracking systems that are managed by, or on behalf of, the\n     Licensor for the purpose of discussing and improving the Work, but\n     excluding communication that is conspicuously marked or otherwise\n     designated in writing by the copyright owner as \"Not a Contribution.\"\n\n     \"Contributor\" shall mean Licensor and any individual or Legal Entity\n     on behalf of whom a Contribution has been received by Licensor and\n     subsequently incorporated within the Work.\n\n  2. Grant of Copyright License. Subject to the terms and conditions of\n     this License, each Contributor hereby grants to You a perpetual,\n     worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n     copyright license to reproduce, prepare Derivative Works of,\n     publicly display, publicly perform, sublicense, and distribute the\n     Work and such Derivative Works in Source or Object form.\n\n  3. Grant of Patent License. Subject to the terms and conditions of\n     this License, each Contributor hereby grants to You a perpetual,\n     worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n     (except as stated in this section) patent license to make, have made,\n     use, offer to sell, sell, import, and otherwise transfer the Work,\n     where such license applies only to those patent claims licensable\n     by such Contributor that are necessarily infringed by their\n     Contribution(s) alone or by combination of their Contribution(s)\n     with the Work to which such Contribution(s) was submitted. If You\n     institute patent litigation against any entity (including a\n     cross-claim or counterclaim in a lawsuit) alleging that the Work\n     or a Contribution incorporated within the Work constitutes direct\n     or contributory patent infringement, then any patent licenses\n     granted to You under this License for that Work shall terminate\n     as of the date such litigation is filed.\n\n  4. Redistribution. You may reproduce and distribute copies of the\n     Work or Derivative Works thereof in any medium, with or without\n     modifications, and in Source or Object form, provided that You\n     meet the following conditions:\n\n     (a) You must give any other recipients of the Work or\n         Derivative Works a copy of this License; and\n\n     (b) You must cause any modified files to carry prominent notices\n         stating that You changed the files; and\n\n     (c) You must retain, in the Source form of any Derivative Works\n         that You distribute, all copyright, patent, trademark, and\n         attribution notices from the Source form of the Work,\n         excluding those notices that do not pertain to any part of\n         the Derivative Works; and\n\n     (d) If the Work includes a \"NOTICE\" text file as part of its\n         distribution, then any Derivative Works that You distribute must\n         include a readable copy of the attribution notices contained\n         within such NOTICE file, excluding those notices that do not\n         pertain to any part of the Derivative Works, in at least one\n         of the following places: within a NOTICE text file distributed\n         as part of the Derivative Works; within the Source form or\n         documentation, if provided along with the Derivative Works; or,\n         within a display generated by the Derivative Works, if and\n         wherever such third-party notices normally appear. The contents\n         of the NOTICE file are for informational purposes only and\n         do not modify the License. You may add Your own attribution\n         notices within Derivative Works that You distribute, alongside\n         or as an addendum to the NOTICE text from the Work, provided\n         that such additional attribution notices cannot be construed\n         as modifying the License.\n\n     You may add Your own copyright statement to Your modifications and\n     may provide additional or different license terms and conditions\n     for use, reproduction, or distribution of Your modifications, or\n     for any such Derivative Works as a whole, provided Your use,\n     reproduction, and distribution of the Work otherwise complies with\n     the conditions stated in this License.\n\n  5. Submission of Contributions. Unless You explicitly state otherwise,\n     any Contribution intentionally submitted for inclusion in the Work\n     by You to the Licensor shall be under the terms and conditions of\n     this License, without any additional terms or conditions.\n     Notwithstanding the above, nothing herein shall supersede or modify\n     the terms of any separate license agreement you may have executed\n     with Licensor regarding such Contributions.\n\n  6. Trademarks. This License does not grant permission to use the trade\n     names, trademarks, service marks, or product names of the Licensor,\n     except as required for reasonable and customary use in describing the\n     origin of the Work and reproducing the content of the NOTICE file.\n\n  7. Disclaimer of Warranty. Unless required by applicable law or\n     agreed to in writing, Licensor provides the Work (and each\n     Contributor provides its Contributions) on an \"AS IS\" BASIS,\n     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n     implied, including, without limitation, any warranties or conditions\n     of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n     PARTICULAR PURPOSE. You are solely responsible for determining the\n     appropriateness of using or redistributing the Work and assume any\n     risks associated with Your exercise of permissions under this License.\n\n  8. Limitation of Liability. In no event and under no legal theory,\n     whether in tort (including negligence), contract, or otherwise,\n     unless required by applicable law (such as deliberate and grossly\n     negligent acts) or agreed to in writing, shall any Contributor be\n     liable to You for damages, including any direct, indirect, special,\n     incidental, or consequential damages of any character arising as a\n     result of this License or out of the use or inability to use the\n     Work (including but not limited to damages for loss of goodwill,\n     work stoppage, computer failure or malfunction, or any and all\n     other commercial damages or losses), even if such Contributor\n     has been advised of the possibility of such damages.\n\n  9. Accepting Warranty or Additional Liability. While redistributing\n     the Work or Derivative Works thereof, You may choose to offer,\n     and charge a fee for, acceptance of support, warranty, indemnity,\n     or other liability obligations and/or rights consistent with this\n     License. However, in accepting such obligations, You may act only\n     on Your own behalf and on Your sole responsibility, not on behalf\n     of any other Contributor, and only if You agree to indemnify,\n     defend, and hold each Contributor harmless for any liability\n     incurred by, or claims asserted against, such Contributor by reason\n     of your accepting any such warranty or additional liability.\n\n  END OF TERMS AND CONDITIONS\n\n  APPENDIX: How to apply the Apache License to your work.\n\n     To apply the Apache License to your work, attach the following\n     boilerplate notice, with the fields enclosed by brackets \"[]\"\n     replaced with your own identifying information. (Don't include\n     the brackets!)  The text should be enclosed in the appropriate\n     comment syntax for the file format. We also recommend that a\n     file or class name and description of purpose be included on the\n     same \"printed page\" as the copyright notice for easier\n     identification within third-party archives.\n\n  Copyright 2008-2023 GROBID's contributors\n\n  Licensed under the Apache License, Version 2.0 (the \"License\");\n  you may not use this file except in compliance with the License.\n  You may obtain a copy of the License at\n\n      http://www.apache.org/licenses/LICENSE-2.0\n\n  Unless required by applicable law or agreed to in writing, software\n  distributed under the License is distributed on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  See the License for the specific language governing permissions and\n  limitations under the License.\n\n"
        },
        {
          "name": "Readme.md",
          "type": "blob",
          "size": 15.326171875,
          "content": "# GROBID\n\n[![License](http://img.shields.io/:license-apache-blue.svg)](http://www.apache.org/licenses/LICENSE-2.0.html)\n[![Coverage Status](https://coveralls.io/repos/kermitt2/grobid/badge.svg)](https://coveralls.io/r/kermitt2/grobid)\n[![Documentation Status](https://readthedocs.org/projects/grobid/badge/?version=latest)](https://readthedocs.org/projects/grobid/?badge=latest)\n[![GitHub release](https://img.shields.io/github/release/kermitt2/grobid.svg)](https://github.com/kermitt2/grobid/releases/)\n[![Demo grobid.science-miner.com](https://img.shields.io/website-up-down-green-red/https/grobid.science-miner.com.svg)](https://grobid.science-miner.com)\n[![Docker Hub](https://img.shields.io/docker/pulls/grobid/grobid.svg)](https://hub.docker.com/r/grobid/grobid/ \"Docker Pulls\")\n[![Docker Hub](https://img.shields.io/docker/pulls/lfoppiano/grobid.svg)](https://hub.docker.com/r/lfoppiano/grobid/ \"Docker Pulls\")\n[![SWH](https://archive.softwareheritage.org/badge/origin/https://github.com/kermitt2/grobid/)](https://archive.softwareheritage.org/browse/origin/?origin_url=https://github.com/kermitt2/grobid)\n\n## GROBID documentation\n\nVisit the [GROBID documentation](https://grobid.readthedocs.io) for more detailed information.\n\n## Summary\n\nGROBID (or Grobid, but not GroBid nor GroBiD) means **G**ene**R**ation **O**f **BI**bliographic **D**ata.\n\nGROBID is a machine learning library for extracting, parsing and re-structuring raw documents such as PDF into structured XML/TEI encoded documents with a particular focus on technical and scientific publications. First developments started in 2008 as a hobby, following a suggestion by Laurent Romary (Inria, France). In 2011, the tool has been made available in open source. Work on GROBID has been steady as a side project since the beginning and is expected to continue as such, facilitated in particular to the continuous support of Inria.\n\nThe following functionalities are available:\n\n- __Header extraction and parsing__ from article in PDF format. The extraction here covers the usual bibliographical information (e.g. title, abstract, authors, affiliations, keywords, etc.).\n- __References extraction and parsing__ from articles in PDF format, around .87 F1-score against on an independent PubMed Central set of 1943 PDF containing 90,125 references, and around .90 on a similar bioRxiv set of 2000 PDF (using the Deep Learning citation model). All the usual publication metadata are covered (including DOI, PMID, etc.).\n- __Citation contexts recognition and resolution__ of the full bibliographical references of the article. The accuracy of citation contexts resolution is between .76 and .91 F1-score depending on the evaluation collection (this corresponds to both the correct identification of the citation callout and its correct association with a full bibliographical reference).\n- __Full text extraction and structuring__ from PDF articles, including a model for the overall document segmentation and models for the structuring of the text body (paragraph, section titles, reference and footnote callouts, figures, tables, data availability statements, etc.). \n- __PDF coordinates__ for extracted information, allowing to create \"augmented\" interactive PDF based on bounding boxes of the identified structures.\n- Parsing of __references in isolation__ (above .90 F1-score at instance-level, .95 F1-score at field level, using the Deep Learning model).\n- __Parsing of names__ (e.g. person title, forenames, middle name, etc.), in particular author names in header, and author names in references (two distinct models).\n- __Parsing of affiliation and address__ blocks.\n- __Parsing of dates__, ISO normalized day, month, year.\n- __Consolidation/resolution of the extracted bibliographical references__ using the [biblio-glutton](https://github.com/kermitt2/biblio-glutton) service or the [CrossRef REST API](https://github.com/CrossRef/rest-api-doc). In both cases, DOI/PMID resolution performance is higher than 0.95 F1-score from PDF extraction.\n- __Extraction and parsing of patent and non-patent references in patent__ publications.\n- __Extraction of Funders and funding information__ with optional matching of extracted funders with the CrossRef Funder Registry.\n- __Identification of copyrights' owner and license associated to the document__, e.g. publisher or authors copyrights, CC-BY/CC-BY-NC/etc. license.\n\nIn a complete PDF processing, GROBID manages 68 final labels used to build relatively fine-grained structures, from traditional publication metadata (title, author first/last/middle names, affiliation types, detailed address, journal, volume, issue, pages, DOI, PMID, etc.) to full text structures (section title, paragraph, reference markers, head/foot notes, figure captions, etc.).\n\nGROBID includes a comprehensive [web service API](https://grobid.readthedocs.io/en/latest/Grobid-service/), [Docker images](https://grobid.readthedocs.io/en/latest/Grobid-docker/), [batch processing](https://grobid.readthedocs.io/en/latest/Grobid-batch/), a JAVA API, a generic [training and evaluation framework](https://grobid.readthedocs.io/en/latest/Training-the-models-of-Grobid/) (precision, recall, etc., n-fold cross-evaluation), systematic [end-to-end benchmarking](https://grobid.readthedocs.io/en/latest/Benchmarking/) on thousand documents and the semi-automatic generation of training data.\n\nGROBID can be considered as production ready. Deployments in production includes ResearchGate, Semantic Scholar, HAL Research Archive, scite.ai, Academia.edu, Internet Archive Scholar, INIST-CNRS, CERN (Invenio), and many more. The tool is designed for speed and high scalability in order to address the full scientific literature corpus.\n\nGROBID should run properly \"out of the box\" on Linux (64 bits) and macOS (Intel and ARM). We cannot ensure currently support for Windows as we did before (help welcome!).\n\nGROBID uses Deep Learning models relying on the [DeLFT](https://github.com/kermitt2/delft) library, a task-agnostic Deep Learning framework for sequence labelling and text classification, via [JEP](https://github.com/ninia/jep). GROBID can run Deep Learning architectures (RNN or transformers with or without layout feature channels) or with feature engineered CRF (default), or any mixtures of CRF and DL to balance scalability and accuracy. These models use joint text and visual/layout information provided by [pdfalto](https://github.com/kermitt2/pdfalto). \n\nNote that by default the Deep Learning models are not used, only CRF are selected in the default configuration to accommodate \"out of the box\" hardware. For improved accuracy, you need to [select the Deep Learning models](https://grobid.readthedocs.io/en/latest/Deep-Learning-models/#recommended-deep-learning-models) to be used in the GROBID configuration file, according to your need and hardware capacities (in particular GPU availability and runtime requirements). **Some GROBID Deep Learning models perform significantly better than default CRF**, in particular for bibliographical reference parsing, so it is recommended to consider selecting them to use this tool appropriately. \n\n## Demo\n\n### Demo server\n\nFor testing purposes, two public GROBID demo servers are available thanks to HuggingFace, hosted as [spaces](https://huggingface.co/kermitt2).\n\nA GROBID demo server with a combination of Deep Learning models and CRF models is available at the following address: [https://kermitt2-grobid.hf.space/](https://kermitt2-grobid.hf.space/) or at [https://huggingface.co/spaces/kermitt2/grobid](https://huggingface.co/spaces/kermitt2/grobid). This demo runs however on CPU only. If you have GPU for your own server deployment, it will be significantly faster. \n\nA faster demo with CRF only is available at [https://kermitt2-grobid-crf.hf.space/](https://kermitt2-grobid-crf.hf.space/) or [https://huggingface.co/spaces/kermitt2/grobid-crf](https://huggingface.co/spaces/kermitt2/grobid-crf). However, accuracy is lower.\n\nThe Web services are documented [here](https://grobid.readthedocs.io/en/latest/Grobid-service/).\n\n_Warning_: Some quota and query limitation apply to the demo server! Please be courteous and do not overload the demo server. \nFor any serious works, you will need to deploy and use your own Grobid server, see the [GROBID and Docker containers documentation](https://grobid.readthedocs.io/en/latest/Grobid-docker/) for doing that easily and activate some Deep Learning models. \n\n### Try in Play With Docker\n\n<a href=\"https://labs.play-with-docker.com/?stack=https://raw.githubusercontent.com/kermitt2/grobid/master/compose.yml\">\n  <img src=\"https://raw.githubusercontent.com/play-with-docker/stacks/master/assets/images/button.png\" alt=\"Try in PWD\"/>\n</a>\n\nWait for 30 seconds for Grobid container to be created before opening a browser tab on port 8080. This demo container runs only with CRF models. Note that there is an additional 60s needed when processing a PDF for the first time for the loading of the models on the \"cold\" container. Then this Grobid container is available just for you during 4 hours. \n\n## Clients\n\nFor facilitating the usage GROBID service at scale, we provide clients written in Python, Java, node.js using the [web services](https://grobid.readthedocs.io/en/latest/Grobid-service/) for parallel batch processing:\n\n- <a href=\"https://github.com/kermitt2/grobid-client-python\" target=\"_blank\">Python GROBID client</a> (the most complete one in term of supported services and options)\n- <a href=\"https://github.com/kermitt2/grobid-client-java\" target=\"_blank\">Java GROBID client</a>\n- <a href=\"https://github.com/kermitt2/grobid-client-node\" target=\"_blank\">Node.js GROBID client</a>\n\nA third party client for Go is available offering functionality similar to the Python client:\n\n- <a href=\"https://github.com/miku/grobidclient\" target=\"_blank\">Go GROBID client</a>\n\nAll these clients will take advantage of the multi-threading for scaling large set of PDF processing. As a consequence, they will be much more efficient than the [batch command lines](https://grobid.readthedocs.io/en/latest/Grobid-batch/) (which use only one thread) and should be preferred.\n\nFor example, we have been able to run the complete full-text processing at around 10.6 PDF per second (around 915,000 PDF per day, around 20M pages per day) with the node.js client listed above during one week on one 16 CPU machine (16 threads, 32GB RAM, no SDD, articles from mainstream publishers), see [here](https://github.com/kermitt2/grobid/issues/443#issuecomment-505208132) (11.3M PDF were processed in 6 days by 2 servers without interruption).\n\nIn addition, a Java example project is available to illustrate how to use GROBID as a Java library: [https://github.com/kermitt2/grobid-example](https://github.com/kermitt2/grobid-example). The example project is using GROBID Java API for extracting header metadata and citations from a PDF and output the results in BibTeX format.  \n\nFinally, the following python utilities can be used to create structured full text corpora of scientific articles. The tool simply takes a list of strong identifiers like DOI or PMID, performing the identification of online Open Access PDF, full text harvesting, metadata aggregation and Grobid processing in one workflow at scale: [article-dataset-builder](https://github.com/kermitt2/article-dataset-builder)\n\n## How GROBID works \n\nVisit the [documentation page describing the system](https://grobid.readthedocs.io/en/latest/Principles/). To summarize, the key design principles of GROBID are:\n\n- GROBID uses a [cascade of sequence labeling models](https://grobid.readthedocs.io/en/latest/Principles/#document-parsing-as-a-cascade-of-sequence-labeling-models) to parse a document. \n\n- The different models [do not work on text, but on **Layout Tokens**](https://grobid.readthedocs.io/en/latest/Principles/#layout-tokens-not-text) to exploit various visual/layout information available for every tokens.\n\n- GROBID does not use training data derived from existing publisher XML documents, but [small, high quality sets](https://grobid.readthedocs.io/en/latest/Principles/#training-data-qualitat-statt-quantitat) of manually labeled training data. \n\n- Technical choices and [default settings](https://grobid.readthedocs.io/en/latest/Principles/#balancing-accuracy-and-scalability) are driven by the ability to process PDF quickly, with commodity hardware and with good parallelization and scalability capacities.\n\nDetailed end-to-end [benchmarking](https://grobid.readthedocs.io/en/latest/Benchmarking/) are available [GROBID documentation](https://grobid.readthedocs.org) and continuously updated.\n\n## GROBID Modules\n\nA series of additional modules have been developed for performing __structure aware__ text mining directly on scholar PDF, reusing GROBID's PDF processing and sequence labelling weaponry:\n\n- [software-mention](https://github.com/ourresearch/software-mentions): recognition of software mentions and associated attributes in scientific literature\n- [datastet](https://github.com/kermitt2/datastet): identification of sections and sentences introducing datasets in a scientific article, identification of dataset names and attributes (implict and named datasets) and classification of the type of datasets\n- [grobid-quantities](https://github.com/kermitt2/grobid-quantities): recognition and normalization of physical quantities/measurements\n- [grobid-superconductors](https://github.com/lfoppiano/grobid-superconductors): recognition of superconductor material and properties in scientific literature\n- [entity-fishing](https://github.com/kermitt2/entity-fishing), a tool for extracting Wikidata entities from text and document, which can also use Grobid to pre-process scientific articles in PDF, leading to more precise and relevant entity extraction and the capacity to annotate the PDF with interactive layout\n- [grobid-ner](https://github.com/kermitt2/grobid-ner): named entity recognition\n- [grobid-astro](https://github.com/kermitt2/grobid-astro): recognition of astronomical entities in scientific papers\n- [grobid-bio](https://github.com/kermitt2/grobid-bio): a toy bio-entity tagger using BioNLP/NLPBA 2004 dataset\n- [grobid-dictionaries](https://github.com/MedKhem/grobid-dictionaries): structuring dictionaries in raw PDF format\n\n## Release and changes\n\nSee the [Changelog](CHANGELOG.md).\n\n## License\n\nGROBID is distributed under [Apache 2.0 license](http://www.apache.org/licenses/LICENSE-2.0). \n\nThe documentation is distributed under [CC-0](https://creativecommons.org/publicdomain/zero/1.0/) license and the annotated data under [CC-BY](https://creativecommons.org/licenses/by/4.0/) license.\n\nIf you contribute to GROBID, you agree to share your contribution following these licenses. \n\nMain author and contact: Patrice Lopez (<patrice.lopez@science-miner.com>)\n\n## Sponsors\n\nej-technologies provided us a free open-source license for its Java Profiler. Click the JProfiler logo below to learn more.\n\n[![JProfiler](doc/img/jprofiler_medium.png)](http://www.ej-technologies.com/products/jprofiler/overview.html)\n\n## How to cite\n\nIf you want to cite this work, please refer to the present GitHub project, together with the [Software Heritage](https://www.softwareheritage.org/) project-level permanent identifier. For example, with BibTeX:\n\n```bibtex\n@misc{GROBID,\n    title = {GROBID},\n    howpublished = {\\url{https://github.com/kermitt2/grobid}},\n    publisher = {GitHub},\n    year = {2008--2024},\n    archivePrefix = {swh},\n    eprint = {1:dir:dab86b296e3c3216e2241968f0d63b68e8209d3c}\n}\n```\n\nSee the [GROBID documentation](https://grobid.readthedocs.org/en/latest/References) for more related resources. \n"
        },
        {
          "name": "build.gradle",
          "type": "blob",
          "size": 24.828125,
          "content": "buildscript {\n    repositories {\n        mavenLocal()\n        mavenCentral()\n        maven {\n            url 'https://plugins.gradle.org/m2/'\n        }\n    }\n    dependencies {\n        classpath 'gradle.plugin.org.kt3k.gradle.plugin:coveralls-gradle-plugin:2.12.0'\n        classpath \"gradle.plugin.com.github.jengelman.gradle.plugins:shadow:7.0.0\"\n        classpath 'com.adarshr:gradle-test-logger-plugin:2.0.0'\n        classpath \"org.jetbrains.kotlin:kotlin-gradle-plugin:1.8.21\"\n        classpath group: 'net.researchgate', name: 'gradle-release', version: '3.0.2'\n    }\n}\n\nrepositories {\n    mavenLocal()\n    mavenCentral()\n    maven {\n        url = uri(\"https://plugins.gradle.org/m2/\")\n    }\n}\n\napply plugin: 'jacoco'\n\njacoco {\n    toolVersion = '0.8.8'\n}\n\nallprojects {\n    apply plugin: 'java-library'\n    apply plugin: 'base'\n    apply plugin: 'com.github.kt3k.coveralls'\n    apply plugin: 'com.adarshr.test-logger'\n    apply plugin: 'org.jetbrains.kotlin.jvm'\n    apply plugin: 'net.researchgate.release'\n\n    group = \"org.grobid\"\n\n    tasks.withType(JavaCompile) {\n        options.encoding = 'UTF-8'\n        // note: the following is not working\n        options.compilerArgs << '-parameters'\n    }\n}\n\nsubprojects {\n    apply plugin: 'java'\n    apply plugin: 'maven-publish'\n\n    publishing {\n        publications {\n            mavenJava(MavenPublication) {\n                from components.java\n                //artifact jar \n            }\n        }\n        repositories {\n            mavenLocal()\n        }\n    }\n\n    sourceCompatibility = 1.11\n    targetCompatibility = 1.11\n\n    tasks.withType(KotlinCompile).configureEach {\n        sourceCompatibility = JavaVersion.VERSION_11\n        targetCompatibility = JavaVersion.VERSION_11\n        kotlinOptions {\n            jvmTarget = JavaVersion.VERSION_11\n        }\n    }\n\n//    kotlin {\n//        jvmToolchain(11)\n//    }\n\n//    java {\n//        toolchain {\n//            languageVersion.set(JavaLanguageVersion.of(11))\n//            vendor.set(JvmVendorSpec.ADOPTIUM)\n//\n//        }\n//    }\n\n    repositories {\n        mavenCentral()\n        maven {\n            url new File(rootProject.rootDir, \"grobid-core/localLibs\")\n        }\n        maven { url \"https://jitpack.io\" }\n    }\n\n    configurations {\n        all*.exclude group: 'org.slf4j', module: \"slf4j-log4j12\"\n        all*.exclude group: 'log4j', module: \"log4j\"\n        implementation.setCanBeResolved(true)\n    }\n\n    ext {\n        // treating them separately, these jars will be flattened into grobid-core.jar on installing,\n        // to avoid missing dependencies from the projects that include grobid-core (see 'jar' task in grobid-core)\n        localLibs = ['crfpp-1.0.2.jar',\n                     'langdetect-1.1-20120112.jar',\n                     'wipo-analysers-0.0.2.jar',\n                     'imageio-pnm-1.0.jar',\n                     'wapiti-1.5.0.jar']\n    }\n\n    dependencies {\n        // packaging local libs inside grobid-core.jar\n        implementation fileTree(dir: new File(rootProject.rootDir, 'grobid-core/localLibs'), include: localLibs)\n\n        testRuntimeOnly \"org.junit.jupiter:junit-jupiter-engine\"\n        testRuntimeOnly \"org.junit.vintage:junit-vintage-engine\"\n        testImplementation(platform('org.junit:junit-bom:5.10.2'))\n        testRuntimeOnly(\"org.junit.platform:junit-platform-launcher\") {\n            because(\"Only needed to run tests in a version of IntelliJ IDEA that bundles older versions\")\n        }\n        testImplementation('org.junit.jupiter:junit-jupiter')\n        testImplementation 'org.easymock:easymock:5.1.0'\n        testImplementation \"org.powermock:powermock-api-easymock:2.0.7\"\n        testImplementation \"org.powermock:powermock-module-junit4:2.0.7\"\n        testImplementation \"org.xmlunit:xmlunit-matchers:2.10.0\"\n        testImplementation \"org.xmlunit:xmlunit-legacy:2.10.0\"\n        testImplementation \"org.hamcrest:hamcrest-all:1.3\"\n        testImplementation 'org.jetbrains.kotlin:kotlin-test'\n        testImplementation \"io.mockk:mockk:1.13.9\"\n\n        implementation \"com.cybozu.labs:langdetect:1.1-20120112\"\n        implementation \"com.rockymadden.stringmetric:stringmetric-core_2.11:0.27.4\"\n        implementation \"commons-pool:commons-pool:1.6\"\n        implementation \"commons-io:commons-io:2.5\"\n        implementation \"org.apache.commons:commons-lang3:3.6\"\n        implementation \"org.apache.commons:commons-collections4:4.1\"\n        implementation 'org.apache.commons:commons-text:1.11.0'\n        implementation \"commons-dbutils:commons-dbutils:1.7\"\n        implementation \"com.google.guava:guava:31.0.1-jre\"\n        implementation \"org.apache.httpcomponents:httpclient:4.5.3\"\n        implementation \"black.ninia:jep:4.0.2\"\n\n        implementation \"com.fasterxml.jackson.core:jackson-core:2.14.3\"\n        implementation \"com.fasterxml.jackson.core:jackson-databind:2.14.3\"\n        implementation \"com.fasterxml.jackson.module:jackson-module-afterburner:2.14.3\"\n        implementation \"com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:2.14.3\"\n    }\n\n    task sourceJar(type: Jar) {\n        description = 'A jar that contains source code'\n        archiveClassifier = 'sources'\n        from project.sourceSets.main.java\n    }\n\n    artifacts {\n        archives sourceJar\n        archives jar\n    }\n\n    //compileJava.dependsOn(changeVersionIfNeeded)\n\n//    uploadArchives {\n//        // if you want to enable uploading to some maven repo, add those properties to ~/.gradle/gradle.properties, e.g.:\n//        /*\n//            mavenRepoUserName=maven_username\n//            mavenRepoPassword=super_secret\n//            mavenRepoReleasesUrl=https://nexus3.example.org/repository/maven-releases/\n//            mavenRepoSnapshotsUrl=https://nexus3.example.org/repository/maven-snapshots/\n//        */\n//        def user = project.hasProperty('mavenRepoUserName') ? project.findProperty('mavenRepoUserName') : ''\n//        def password = project.hasProperty('mavenRepoPassword') ? project.findProperty('mavenRepoPassword') : ''\n//        def rurl = project.hasProperty('mavenRepoReleasesUrl') ? project.findProperty('mavenRepoReleasesUrl') : ''\n//        def surl = project.hasProperty('mavenRepoSnapshotsUrl') ? project.findProperty('mavenRepoSnapshotsUrl') : ''\n//\n//        repositories.mavenDeployer {\n//            repository(url: rurl) {\n//                authentication(userName: user, password: password)\n//            }\n//            snapshotRepository(url: surl) {\n//                authentication(userName: user, password: password)\n//            }\n//\n//        }\n//    }\n\n    test {\n        useJUnitPlatform()\n\n        testLogging.showStandardStreams = true\n        // enable for having separate test executor for different tests\n        forkEvery = 1\n        maxHeapSize = \"1024m\"\n\n        def libraries = \"\"\n        if (Os.isFamily(Os.FAMILY_MAC)) {\n            if (Os.OS_ARCH.equals(\"aarch64\")) {\n                libraries = \"${file(\"./grobid-home/lib/mac_arm-64\").absolutePath}\"\n            } else {\n                libraries = \"${file(\"./grobid-home/lib/mac-64\").absolutePath}\"\n            }\n        } else if (Os.isFamily(Os.FAMILY_UNIX)) {\n            def jepDir = rootProject.rootDir.getAbsolutePath() + \"/grobid-home/lib/lin-64/jep\"\n            libraries = jepDir\n            jepDir = rootProject.rootDir.getAbsolutePath() + \"/grobid-home/lib/lin-64\"\n            libraries += \":\"+jepDir\n        } else {\n            throw new RuntimeException(\"Unsupported platform!\")\n        }\n\n        if (JavaVersion.current().compareTo(JavaVersion.VERSION_1_8) > 0) {\n            jvmArgs \"--add-opens\", \"java.base/java.util.stream=ALL-UNNAMED\",\n            \"--add-opens\", \"java.base/java.io=ALL-UNNAMED\", \"--add-opens\", \"java.xml/jdk.xml.internal=ALL-UNNAMED\"\n        }\n        systemProperty \"java.library.path\",\"${System.getProperty('java.library.path')}:\" + libraries\n    }\n}\n\n/** SUBPROJECTS **/\n\nproject(\"grobid-core\") {\n    apply plugin: 'com.github.johnrengelman.shadow'\n    apply plugin: 'jacoco'\n\n    configurations {\n        shadedLib\n    }\n\n    dependencies {\n        implementation(group: 'xml-apis', name: 'xml-apis') {\n            // otherwise xml-apis 2.0.1 will come from XOM and will result in\n            // java.lang.ClassNotFoundException: org.w3c.dom.ElementTraversal\n            //TODO: sort out this problem better\n            version {\n                strictly '1.4.01'\n            }\n        }\n\n        // Logs\n        implementation 'org.slf4j:slf4j-api:1.7.30'\n        implementation 'ch.qos.logback:logback-classic:1.2.3'\n\n        implementation \"org.apache.pdfbox:pdfbox:2.0.18\"\n\n        api \"xerces:xercesImpl:2.12.0\"\n        api \"net.arnx:jsonic:1.3.10\"\n        api \"net.sf.saxon:Saxon-HE:9.6.0-9\"\n        api \"xom:xom:1.3.2\"\n        api 'javax.xml.bind:jaxb-api:2.3.0'\n\n        implementation \"joda-time:joda-time:2.9.9\"\n        implementation \"org.apache.lucene:lucene-analyzers-common:4.5.1\"\n        implementation 'black.ninia:jep:4.0.2'\n        implementation 'org.apache.opennlp:opennlp-tools:1.9.1'\n        implementation group: 'org.jruby', name: 'jruby-complete', version: '9.2.13.0'\n\n        shadedLib \"org.apache.lucene:lucene-analyzers-common:4.5.1\"\n    }\n\n    jar {\n        from {\n            project.configurations.runtimeClasspath.collect {\n                it.isDirectory() ? [] : localLibs.contains(it.getName()) ? zipTree(it) : []\n            }\n        }\n        exclude(\"logback.xml\")\n        duplicatesStrategy = DuplicatesStrategy.EXCLUDE\n    }\n\n    shadowJar {\n        archiveClassifier = 'onejar'\n        mergeServiceFiles()\n        zip64 true\n        manifest {\n            attributes 'Main-Class': 'org.grobid.core.main.batch.GrobidMain'\n        }\n        from sourceSets.main.output\n\n        from {\n            project.configurations.runtimeClasspath.collect {\n                it.isDirectory() ? [] : localLibs.contains(it.getName()) ? zipTree(it) : []\n            }\n        }\n\n        configurations = [project.configurations.shadedLib, project.configurations.runtimeClasspath]\n        relocate 'org.apache.lucene', 'org.grobid.shaded.org.apache.lucene'\n    }\n\n    artifacts {\n        archives jar\n        archives shadowJar\n    }\n\n    processResources {\n        filesMatching('grobid-version.txt') {\n            filter {\n                it.replace('project.version', project.property('version'))\n            }\n        }\n    }\n\n    task install {\n        dependsOn publishToMavenLocal\n        dependsOn 'shadowJar'\n    }\n}\n\nproject(\"grobid-home\") {\n    task packageGrobidHome(type: Zip) {\n        zip64 true\n        from('.') {\n            include(\"config/*\")\n            include(\"language-detection/**\")\n            include(\"sentence-segmentation/**\")\n            include(\"lib/**\")\n            include(\"pdfalto/**\")\n            include(\"models/**\")\n            include(\"lexicon/**\")\n            include(\"schemas/**\")\n            include(\"scripts/**\")\n            exclude(\"models/**/*.old\")\n        }\n        into(\"grobid-home\")\n    }\n    artifacts {\n        archives packageGrobidHome\n    }\n}\n\nimport org.apache.tools.ant.taskdefs.condition.Os\nimport org.jetbrains.kotlin.gradle.tasks.KotlinCompile\n\nproject(\":grobid-service\") {\n    apply plugin: 'application'\n    apply plugin: 'jacoco'\n    apply plugin: 'com.github.johnrengelman.shadow'\n\n    mainClassName = 'org.grobid.service.main.GrobidServiceApplication'\n\n    tasks.run {\n        def libraries = \"\"\n        if (Os.isFamily(Os.FAMILY_MAC)) {\n            if (Os.OS_ARCH.equals(\"aarch64\")) {\n                libraries = \"${file(\"../grobid-home/lib/mac_arm-64\").absolutePath}\"\n            } else {\n                libraries = \"${file(\"../grobid-home/lib/mac-64\").absolutePath}\"\n            }\n        } else if (Os.isFamily(Os.FAMILY_UNIX)) {\n            libraries = \"${file(\"../grobid-home/lib/lin-64/jep\").absolutePath}:\" +\n                \"${file(\"../grobid-home/lib/lin-64\").absolutePath}:\"\n        } else  {\n            throw new RuntimeException(\"Unsupported platform!\")\n        }\n\n        if (JavaVersion.current().compareTo(JavaVersion.VERSION_1_8) > 0) {\n            jvmArgs \"--add-opens\", \"java.base/java.lang=ALL-UNNAMED\"\n        }\n        workingDir = rootProject.rootDir\n        def javaLibraryPath = \"${System.getProperty('java.library.path')}:\" + libraries\n//        if (System.env.CONDA_PREFIX) {\n//            def condaEnv = \"${System.env.CONDA_PREFIX}/lib\"\n//            def pythonDirectory = file(condaEnv).listFiles({ it.toString().contains(\"/lib/python\") } as FileFilter)?.first()\n//            def pythonVersion = (pythonDirectory =~ /python([0-9]\\.[0-9]+)/)[0][1]\n//\n//            javaLibraryPath = \"${System.getProperty('java.library.path')}:\" +\n//                libraries + \":\" +\n//                \"${System.env.CONDA_PREFIX}/lib:\" +\n//                \"${System.env.CONDA_PREFIX}/lib/python${pythonVersion}/site-packages/jep\"\n//        }\n        systemProperty \"java.library.path\", javaLibraryPath\n    }\n\n    tasks.distZip.enabled = true\n    tasks.distTar.enabled = false\n    //tasks.distZip.zip64 = true\n    tasks.shadowDistZip.enabled = false\n    tasks.shadowDistTar.enabled = false\n\n    distZip { duplicatesStrategy = DuplicatesStrategy.EXCLUDE }\n    distTar { duplicatesStrategy = DuplicatesStrategy.EXCLUDE }\n\n    dependencies {\n        implementation project(':grobid-core')\n        implementation project(':grobid-trainer')\n\n        //Dropwizard\n        implementation 'ru.vyarus:dropwizard-guicey:7.0.0'\n\n        implementation 'io.dropwizard:dropwizard-bom:4.0.0'\n        implementation 'io.dropwizard:dropwizard-core:4.0.0'\n        implementation 'io.dropwizard:dropwizard-assets:4.0.0'\n        implementation 'io.dropwizard:dropwizard-testing:4.0.0'\n        implementation 'io.dropwizard.modules:dropwizard-testing-junit4:4.0.0'\n        implementation 'io.dropwizard:dropwizard-forms:4.0.0'\n        implementation 'io.dropwizard:dropwizard-client:4.0.0'\n        implementation 'io.dropwizard:dropwizard-auth:4.0.0'\n        implementation 'io.dropwizard.metrics:metrics-core:4.2.22'\n        implementation 'io.dropwizard.metrics:metrics-servlets:4.2.22'\n        implementation 'io.dropwizard:dropwizard-json-logging:4.0.0'\n\n        implementation \"org.apache.pdfbox:pdfbox:2.0.3\"\n        implementation \"javax.activation:activation:1.1.1\"\n        implementation \"io.prometheus:simpleclient_dropwizard:0.16.0\"\n        implementation \"io.prometheus:simpleclient_servlet:0.16.0\"\n    }\n\n    shadowJar {\n        archiveClassifier = 'onejar'\n        mergeServiceFiles()\n        zip64 true\n        manifest {\n            attributes 'Main-Class': 'org.grobid.core.main.batch.GrobidMain'\n        }\n\n        exclude(\"logback.xml\")\n\n        duplicatesStrategy = DuplicatesStrategy.EXCLUDE\n    }\n\n    artifacts {\n        archives shadowJar\n    }\n\n    distributions {\n        main {\n            contents {\n                //from(new File(rootProject.rootDir, \"grobid-service/README.md\")) {\n                //    into \"doc\"\n                //}\n                from(new File(rootProject.rootDir, \"../grobid-home/config/grobid.yaml\")) {\n                    into \"config\"\n                }\n                from(new File(rootProject.rootDir, \"grobid-service/build/scripts/*\")) {\n                    into \"bin\"\n                }\n            }\n        }\n    }\n}\n\nproject(\":grobid-trainer\") {\n    apply plugin: 'com.github.johnrengelman.shadow'\n    apply plugin: 'jacoco'\n\n    dependencies {\n        implementation(group: 'xml-apis', name: 'xml-apis') {\n            // otherwise xml-apis 2.0.1 will come from XOM and will result in\n            // java.lang.ClassNotFoundException: org.w3c.dom.ElementTraversal\n            //TODO: sort out this problem better\n            version {\n                strictly '1.4.01'\n            }\n        }\n        implementation project(':grobid-core')\n        implementation \"com.rockymadden.stringmetric:stringmetric-core_2.10:0.27.3\"\n        implementation \"me.tongfei:progressbar:0.9.0\"\n\n        // logs\n        implementation 'org.slf4j:slf4j-api:1.7.30'\n        implementation 'ch.qos.logback:logback-classic:1.2.3'\n    }\n\n    configurations {\n    }\n\n    jar {\n        from {\n            project.configurations.runtimeClasspath.collect {\n                it.isDirectory() ? [] : localLibs.contains(it.getName()) ? zipTree(it) : []\n            }\n        }\n        exclude(\"logback.xml\")\n\n        duplicatesStrategy = DuplicatesStrategy.EXCLUDE\n    }\n\n    shadowJar {\n        archiveClassifier = 'onejar'\n        mergeServiceFiles()\n        zip64 true\n        manifest {\n            attributes 'Main-Class': 'org.grobid.trainer.TrainerRunner'\n        }\n\n        from('src/main/resources') {\n            include '*.xml'\n        }\n\n        duplicatesStrategy = DuplicatesStrategy.EXCLUDE\n    }\n\n    artifacts {\n        archives shadowJar\n        archives jar\n    }\n\n    task install {\n        dependsOn publishToMavenLocal\n        dependsOn 'shadowJar'\n    }\n\n    def trainerTasks = [\n        \"train_name_header\"             : \"org.grobid.trainer.NameHeaderTrainer\",\n        \"train_name_citation\"           : \"org.grobid.trainer.NameCitationTrainer\",\n        \"train_affiliation_address\"     : \"org.grobid.trainer.AffiliationAddressTrainer\",\n        \"train_shorttext\"               : \"org.grobid.trainer.ShorttextTrainer\",\n        \"train_figure\"                  : \"org.grobid.trainer.FigureTrainer\",\n        \"train_table\"                   : \"org.grobid.trainer.TableTrainer\",\n        \"train_citation\"                : \"org.grobid.trainer.CitationTrainer\",\n        \"train_date\"                    : \"org.grobid.trainer.DateTrainer\",\n        \"train_reference_segmentation\"  : \"org.grobid.trainer.ReferenceSegmenterTrainer\",\n        \"train_ebook_model\"             : \"org.grobid.trainer.EbookTrainer\",\n        \"train_patent_citation\"         : \"org.grobid.trainer.PatentParserTrainer\",\n        \"train_funding_acknowledgement\" : \"org.grobid.trainer.FundingAcknowledgementTrainer\"\n    ]\n\n    def complexTrainerTasks = [\n        \"train_header\"                          : [\"org.grobid.trainer.HeaderTrainer\", \"\"],\n        \"train_header_article_light\"            : [\"org.grobid.trainer.HeaderTrainer\", \"article/light\"],\n        \"train_header_article_light_ref\"        : [\"org.grobid.trainer.HeaderTrainer\", \"article/light-ref\"],\n        \"train_header_ietf\"                     : [\"org.grobid.trainer.HeaderTrainer\", \"sdo/ietf\"],\n        \"train_segmentation\"                    : [\"org.grobid.trainer.SegmentationTrainer\", \"\"],\n        \"train_segmentation_article_light\"      : [\"org.grobid.trainer.SegmentationTrainer\", \"article/light\"],\n        \"train_segmentation_article_light_ref\"  : [\"org.grobid.trainer.SegmentationTrainer\", \"article/light-ref\"],\n        \"train_segmentation_ietf\"               : [\"org.grobid.trainer.SegmentationTrainer\", \"sdo/ietf\"],\n        \"train_fulltext\"                        : [\"org.grobid.trainer.FulltextTrainer\", \"\"],\n        \"train_fulltext_article_light\"          : [\"org.grobid.trainer.FulltextTrainer\", \"article/light\"],\n        \"train_fulltext_article_light_ref\"      : [\"org.grobid.trainer.FulltextTrainer\", \"article/light-ref\"],\n    ]\n\n    def libraries = \"\"\n    if (Os.isFamily(Os.FAMILY_MAC)) {\n        if (Os.OS_ARCH.equals(\"aarch64\")) {\n            libraries = \"${file(\"../grobid-home/lib/mac_arm-64\").absolutePath}\"\n        } else {\n            libraries = \"${file(\"../grobid-home/lib/mac-64\").absolutePath}\"\n        }\n    } else if (Os.isFamily(Os.FAMILY_UNIX)) {\n        libraries = \"${file(\"../grobid-home/lib/lin-64/jep\").absolutePath}:\" +\n            \"${file(\"../grobid-home/lib/lin-64\").absolutePath}:\"\n    } else  {\n        throw new RuntimeException(\"Unsupported platform!\")\n    }\n\n    trainerTasks.each { taskName, mainClassName ->\n        tasks.create(name: taskName, type: JavaExec, group: 'modeltraining') {\n            main = mainClassName\n            classpath = sourceSets.main.runtimeClasspath\n            if (JavaVersion.current().compareTo(JavaVersion.VERSION_1_8) > 0) {\n                jvmArgs '-Xmx3072m', \"--add-opens\", \"java.base/java.lang=ALL-UNNAMED\"\n            } else {\n                jvmArgs '-Xmx3072m'\n            }\n            systemProperty \"java.library.path\",\"${System.getProperty('java.library.path')}:\" + libraries\n        }\n    }\n\n    complexTrainerTasks.each { taskName, mainClassNameAndArgs ->\n        tasks.create(name: taskName, type: JavaExec, group: 'modeltraining') {\n            main = mainClassNameAndArgs[0]\n            classpath = sourceSets.main.runtimeClasspath\n            if (JavaVersion.current().compareTo(JavaVersion.VERSION_1_8) > 0) {\n                jvmArgs '-Xmx3072m', \"--add-opens\", \"java.base/java.lang=ALL-UNNAMED\"\n            } else {\n                jvmArgs '-Xmx3072m'\n            }\n            args mainClassNameAndArgs[1]\n        }\n    }\n\n    // evaluation tasks\n    ext.getArg = { propName, defaultVal ->\n        return project.hasProperty(propName) ? project.getProperty(propName) : defaultVal;\n    }\n\n    // run like this:\n    // ./gradlew jatsEval -Pp2t=/path/to/goldenSet\n    // ./gradlew jatsEval -Pp2t=/path/to/goldenSet -Prun=1 -PfileRatio=0.1\n    // ./gradlew teiEval -Pp2t=/path/to/goldenSet\n    // ./gradlew PrepareDOIMatching -Pp2t=ABS_PATH_TO_PMC/PMC_sample_1943 \n    // ./gradlew EvaluateDOIMatching -Pp2t=ABS_PATH_TO_PMC/PMC_sample_1943 \n    task(jatsEval, dependsOn: 'classes', type: JavaExec, group: 'modelevaluation') {\n        main = 'org.grobid.trainer.evaluation.EndToEndEvaluation'\n        classpath = sourceSets.main.runtimeClasspath\n        args 'nlm', getArg('p2t', '.'), getArg('run', '0'), getArg('fileRatio', '1.0'), getArg('flavor', '')\n        if (JavaVersion.current().compareTo(JavaVersion.VERSION_1_8) > 0) {\n            jvmArgs '-Xmx3072m', \"--add-opens\", \"java.base/java.lang=ALL-UNNAMED\"\n        } else {\n            jvmArgs '-Xmx3072m'\n        }\n        systemProperty \"java.library.path\",\"${System.getProperty('java.library.path')}:\" + libraries\n    }\n\n    task(teiEval, dependsOn: 'classes', type: JavaExec, group: 'modelevaluation') {\n        main = 'org.grobid.trainer.evaluation.EndToEndEvaluation'\n        classpath = sourceSets.main.runtimeClasspath\n        args 'tei', getArg('p2t', '.'), getArg('run', '0'), getArg('fileRatio', '1.0'), getArg('flavor', '')\n        if(JavaVersion.current().compareTo(JavaVersion.VERSION_1_8) > 0) {\n            jvmArgs '-Xmx3072m', \"--add-opens\", \"java.base/java.lang=ALL-UNNAMED\"\n        } else {\n            jvmArgs '-Xmx3072m'\n        }\n        systemProperty \"java.library.path\",\"${System.getProperty('java.library.path')}:\" + libraries\n    }\n\n    task(PrepareDOIMatching, dependsOn: 'classes', type: JavaExec, group: 'modelevaluation') {\n        main = 'org.grobid.trainer.evaluation.EvaluationDOIMatching'\n        classpath = sourceSets.main.runtimeClasspath\n        args 'data', getArg('p2t', '.')\n        if(JavaVersion.current().compareTo(JavaVersion.VERSION_1_8) > 0) {\n            jvmArgs '-Xmx3072m', \"--add-opens\", \"java.base/java.lang=ALL-UNNAMED\"\n        } else {\n            jvmArgs '-Xmx3072m'\n        }\n        systemProperty \"java.library.path\",\"${System.getProperty('java.library.path')}:\" + libraries\n    }\n\n    task(EvaluateDOIMatching, dependsOn: 'classes', type: JavaExec, group: 'modelevaluation') {\n        main = 'org.grobid.trainer.evaluation.EvaluationDOIMatching'\n        classpath = sourceSets.main.runtimeClasspath\n        args 'eval', getArg('p2t', '.')\n        if(JavaVersion.current().compareTo(JavaVersion.VERSION_1_8) > 0) {\n            jvmArgs '-Xmx3072m', \"--add-opens\", \"java.base/java.lang=ALL-UNNAMED\"\n        } else {\n            jvmArgs '-Xmx3072m'\n        }\n        systemProperty \"java.library.path\",\"${System.getProperty('java.library.path')}:\" + libraries\n    }\n}\n\n/** JACOCO **/\n\ntasks.register(\"codeCoverageReport\", JacocoReport) {\n    // If a subproject applies the 'jacoco' plugin, add the result it to the report\n    subprojects { subproject ->\n        subproject.plugins.withType(JacocoPlugin).configureEach {\n            subproject.tasks.matching({ t -> t.extensions.findByType(JacocoTaskExtension) }).configureEach { testTask ->\n                sourceSets subproject.sourceSets.main\n                executionData(testTask)\n            }\n\n            // To automatically run `test` every time `./gradlew codeCoverageReport` is called,\n            // you may want to set up a task dependency between them as shown below.\n            // Note that this requires the `test` tasks to be resolved eagerly (see `forEach`) which\n            // may have a negative effect on the configuration time of your build.\n            subproject.tasks.matching({ t -> t.extensions.findByType(JacocoTaskExtension) }).forEach {\n                rootProject.tasks.codeCoverageReport.dependsOn(it)\n            }\n        }\n    }\n\n    // XML -> coveralls,\n    // HTML -> for manual check\n    reports {\n        xml.enabled true\n        html.enabled true\n        csv.enabled true\n    }\n\n}\n\n/** COVERALLS **/\ncoveralls {\n    sourceDirs = files(subprojects.sourceSets.main.allSource.srcDirs).files.absolutePath\n}\n\ntasks.coveralls {\n    dependsOn codeCoverageReport\n}\n\nwrapper {\n    gradleVersion \"7.2\"\n}\n\nbuild.dependsOn project.getSubprojects().collect({ it.getTasks().getByName(\"build\") })\n\nrelease {\n    failOnUnversionedFiles = false\n    failOnCommitNeeded = false\n    tagTemplate = '${version}'\n    git {\n        requireBranch.set('master')\n    }\n}"
        },
        {
          "name": "doc",
          "type": "tree",
          "content": null
        },
        {
          "name": "gradle.properties",
          "type": "blob",
          "size": 0.4697265625,
          "content": "version=0.8.2-SNAPSHOT\n# Set workers to 1 that even for parallel builds it works. (I guess the shadow plugin makes some trouble)\norg.gradle.workers.max=1\norg.gradle.caching = true\norg.gradle.parallel = true\norg.gradle.vfs.watch = true\n# from Java 9+\n#org.gradle.jvmargs=--add-modules=java.xml.bind,java.activation\n#systemProp.https.proxyHost=\n#systemProp.https.proxyPort=\n#systemProp.https.proxyHost=\n#systemProp.https.proxyPort=\n\norg.gradle.java.installations.auto-download=false\n"
        },
        {
          "name": "gradle",
          "type": "tree",
          "content": null
        },
        {
          "name": "gradlew",
          "type": "blob",
          "size": 7.880859375,
          "content": "#!/bin/sh\n\n#\n# Copyright © 2015-2021 the original authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n##############################################################################\n#\n#   Gradle start up script for POSIX generated by Gradle.\n#\n#   Important for running:\n#\n#   (1) You need a POSIX-compliant shell to run this script. If your /bin/sh is\n#       noncompliant, but you have some other compliant shell such as ksh or\n#       bash, then to run this script, type that shell name before the whole\n#       command line, like:\n#\n#           ksh Gradle\n#\n#       Busybox and similar reduced shells will NOT work, because this script\n#       requires all of these POSIX shell features:\n#         * functions;\n#         * expansions «$var», «${var}», «${var:-default}», «${var+SET}»,\n#           «${var#prefix}», «${var%suffix}», and «$( cmd )»;\n#         * compound commands having a testable exit status, especially «case»;\n#         * various built-in commands including «command», «set», and «ulimit».\n#\n#   Important for patching:\n#\n#   (2) This script targets any POSIX shell, so it avoids extensions provided\n#       by Bash, Ksh, etc; in particular arrays are avoided.\n#\n#       The \"traditional\" practice of packing multiple parameters into a\n#       space-separated string is a well documented source of bugs and security\n#       problems, so this is (mostly) avoided, by progressively accumulating\n#       options in \"$@\", and eventually passing that to Java.\n#\n#       Where the inherited environment variables (DEFAULT_JVM_OPTS, JAVA_OPTS,\n#       and GRADLE_OPTS) rely on word-splitting, this is performed explicitly;\n#       see the in-line comments for details.\n#\n#       There are tweaks for specific operating systems such as AIX, CygWin,\n#       Darwin, MinGW, and NonStop.\n#\n#   (3) This script is generated from the Groovy template\n#       https://github.com/gradle/gradle/blob/master/subprojects/plugins/src/main/resources/org/gradle/api/internal/plugins/unixStartScript.txt\n#       within the Gradle project.\n#\n#       You can find Gradle at https://github.com/gradle/gradle/.\n#\n##############################################################################\n\n# Attempt to set APP_HOME\n\n# Resolve links: $0 may be a link\napp_path=$0\n\n# Need this for daisy-chained symlinks.\nwhile\n    APP_HOME=${app_path%\"${app_path##*/}\"}  # leaves a trailing /; empty if no leading path\n    [ -h \"$app_path\" ]\ndo\n    ls=$( ls -ld \"$app_path\" )\n    link=${ls#*' -> '}\n    case $link in             #(\n      /*)   app_path=$link ;; #(\n      *)    app_path=$APP_HOME$link ;;\n    esac\ndone\n\nAPP_HOME=$( cd \"${APP_HOME:-./}\" && pwd -P ) || exit\n\nAPP_NAME=\"Gradle\"\nAPP_BASE_NAME=${0##*/}\n\n# Add default JVM options here. You can also use JAVA_OPTS and GRADLE_OPTS to pass JVM options to this script.\nDEFAULT_JVM_OPTS='\"-Xmx64m\" \"-Xms64m\"'\n\n# Use the maximum available, or set MAX_FD != -1 to use that value.\nMAX_FD=maximum\n\nwarn () {\n    echo \"$*\"\n} >&2\n\ndie () {\n    echo\n    echo \"$*\"\n    echo\n    exit 1\n} >&2\n\n# OS specific support (must be 'true' or 'false').\ncygwin=false\nmsys=false\ndarwin=false\nnonstop=false\ncase \"$( uname )\" in                #(\n  CYGWIN* )         cygwin=true  ;; #(\n  Darwin* )         darwin=true  ;; #(\n  MSYS* | MINGW* )  msys=true    ;; #(\n  NONSTOP* )        nonstop=true ;;\nesac\n\nCLASSPATH=$APP_HOME/gradle/wrapper/gradle-wrapper.jar\n\n\n# Determine the Java command to use to start the JVM.\nif [ -n \"$JAVA_HOME\" ] ; then\n    if [ -x \"$JAVA_HOME/jre/sh/java\" ] ; then\n        # IBM's JDK on AIX uses strange locations for the executables\n        JAVACMD=$JAVA_HOME/jre/sh/java\n    else\n        JAVACMD=$JAVA_HOME/bin/java\n    fi\n    if [ ! -x \"$JAVACMD\" ] ; then\n        die \"ERROR: JAVA_HOME is set to an invalid directory: $JAVA_HOME\n\nPlease set the JAVA_HOME variable in your environment to match the\nlocation of your Java installation.\"\n    fi\nelse\n    JAVACMD=java\n    which java >/dev/null 2>&1 || die \"ERROR: JAVA_HOME is not set and no 'java' command could be found in your PATH.\n\nPlease set the JAVA_HOME variable in your environment to match the\nlocation of your Java installation.\"\nfi\n\n# Increase the maximum file descriptors if we can.\nif ! \"$cygwin\" && ! \"$darwin\" && ! \"$nonstop\" ; then\n    case $MAX_FD in #(\n      max*)\n        MAX_FD=$( ulimit -H -n ) ||\n            warn \"Could not query maximum file descriptor limit\"\n    esac\n    case $MAX_FD in  #(\n      '' | soft) :;; #(\n      *)\n        ulimit -n \"$MAX_FD\" ||\n            warn \"Could not set maximum file descriptor limit to $MAX_FD\"\n    esac\nfi\n\n# Collect all arguments for the java command, stacking in reverse order:\n#   * args from the command line\n#   * the main class name\n#   * -classpath\n#   * -D...appname settings\n#   * --module-path (only if needed)\n#   * DEFAULT_JVM_OPTS, JAVA_OPTS, and GRADLE_OPTS environment variables.\n\n# For Cygwin or MSYS, switch paths to Windows format before running java\nif \"$cygwin\" || \"$msys\" ; then\n    APP_HOME=$( cygpath --path --mixed \"$APP_HOME\" )\n    CLASSPATH=$( cygpath --path --mixed \"$CLASSPATH\" )\n\n    JAVACMD=$( cygpath --unix \"$JAVACMD\" )\n\n    # Now convert the arguments - kludge to limit ourselves to /bin/sh\n    for arg do\n        if\n            case $arg in                                #(\n              -*)   false ;;                            # don't mess with options #(\n              /?*)  t=${arg#/} t=/${t%%/*}              # looks like a POSIX filepath\n                    [ -e \"$t\" ] ;;                      #(\n              *)    false ;;\n            esac\n        then\n            arg=$( cygpath --path --ignore --mixed \"$arg\" )\n        fi\n        # Roll the args list around exactly as many times as the number of\n        # args, so each arg winds up back in the position where it started, but\n        # possibly modified.\n        #\n        # NB: a `for` loop captures its iteration list before it begins, so\n        # changing the positional parameters here affects neither the number of\n        # iterations, nor the values presented in `arg`.\n        shift                   # remove old arg\n        set -- \"$@\" \"$arg\"      # push replacement arg\n    done\nfi\n\n# Collect all arguments for the java command;\n#   * $DEFAULT_JVM_OPTS, $JAVA_OPTS, and $GRADLE_OPTS can contain fragments of\n#     shell script including quotes and variable substitutions, so put them in\n#     double quotes to make sure that they get re-expanded; and\n#   * put everything else in single quotes, so that it's not re-expanded.\n\nset -- \\\n        \"-Dorg.gradle.appname=$APP_BASE_NAME\" \\\n        -classpath \"$CLASSPATH\" \\\n        org.gradle.wrapper.GradleWrapperMain \\\n        \"$@\"\n\n# Use \"xargs\" to parse quoted args.\n#\n# With -n1 it outputs one arg per line, with the quotes and backslashes removed.\n#\n# In Bash we could simply go:\n#\n#   readarray ARGS < <( xargs -n1 <<<\"$var\" ) &&\n#   set -- \"${ARGS[@]}\" \"$@\"\n#\n# but POSIX shell has neither arrays nor command substitution, so instead we\n# post-process each arg (as a line of input to sed) to backslash-escape any\n# character that might be a shell metacharacter, then use eval to reverse\n# that process (while maintaining the separation between arguments), and wrap\n# the whole thing up as a single \"set\" statement.\n#\n# This will of course break if any of these variables contains a newline or\n# an unmatched quote.\n#\n\neval \"set -- $(\n        printf '%s\\n' \"$DEFAULT_JVM_OPTS $JAVA_OPTS $GRADLE_OPTS\" |\n        xargs -n1 |\n        sed ' s~[^-[:alnum:]+,./:=@_]~\\\\&~g; ' |\n        tr '\\n' ' '\n    )\" '\"$@\"'\n\nexec \"$JAVACMD\" \"$@\"\n"
        },
        {
          "name": "gradlew.bat",
          "type": "blob",
          "size": 2.611328125,
          "content": "@rem\n@rem Copyright 2015 the original author or authors.\n@rem\n@rem Licensed under the Apache License, Version 2.0 (the \"License\");\n@rem you may not use this file except in compliance with the License.\n@rem You may obtain a copy of the License at\n@rem\n@rem      https://www.apache.org/licenses/LICENSE-2.0\n@rem\n@rem Unless required by applicable law or agreed to in writing, software\n@rem distributed under the License is distributed on an \"AS IS\" BASIS,\n@rem WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n@rem See the License for the specific language governing permissions and\n@rem limitations under the License.\n@rem\n\n@if \"%DEBUG%\" == \"\" @echo off\n@rem ##########################################################################\n@rem\n@rem  Gradle startup script for Windows\n@rem\n@rem ##########################################################################\n\n@rem Set local scope for the variables with windows NT shell\nif \"%OS%\"==\"Windows_NT\" setlocal\n\nset DIRNAME=%~dp0\nif \"%DIRNAME%\" == \"\" set DIRNAME=.\nset APP_BASE_NAME=%~n0\nset APP_HOME=%DIRNAME%\n\n@rem Resolve any \".\" and \"..\" in APP_HOME to make it shorter.\nfor %%i in (\"%APP_HOME%\") do set APP_HOME=%%~fi\n\n@rem Add default JVM options here. You can also use JAVA_OPTS and GRADLE_OPTS to pass JVM options to this script.\nset DEFAULT_JVM_OPTS=\"-Xmx64m\" \"-Xms64m\"\n\n@rem Find java.exe\nif defined JAVA_HOME goto findJavaFromJavaHome\n\nset JAVA_EXE=java.exe\n%JAVA_EXE% -version >NUL 2>&1\nif \"%ERRORLEVEL%\" == \"0\" goto execute\n\necho.\necho ERROR: JAVA_HOME is not set and no 'java' command could be found in your PATH.\necho.\necho Please set the JAVA_HOME variable in your environment to match the\necho location of your Java installation.\n\ngoto fail\n\n:findJavaFromJavaHome\nset JAVA_HOME=%JAVA_HOME:\"=%\nset JAVA_EXE=%JAVA_HOME%/bin/java.exe\n\nif exist \"%JAVA_EXE%\" goto execute\n\necho.\necho ERROR: JAVA_HOME is set to an invalid directory: %JAVA_HOME%\necho.\necho Please set the JAVA_HOME variable in your environment to match the\necho location of your Java installation.\n\ngoto fail\n\n:execute\n@rem Setup the command line\n\nset CLASSPATH=%APP_HOME%\\gradle\\wrapper\\gradle-wrapper.jar\n\n\n@rem Execute Gradle\n\"%JAVA_EXE%\" %DEFAULT_JVM_OPTS% %JAVA_OPTS% %GRADLE_OPTS% \"-Dorg.gradle.appname=%APP_BASE_NAME%\" -classpath \"%CLASSPATH%\" org.gradle.wrapper.GradleWrapperMain %*\n\n:end\n@rem End local scope for the variables with windows NT shell\nif \"%ERRORLEVEL%\"==\"0\" goto mainEnd\n\n:fail\nrem Set variable GRADLE_EXIT_CONSOLE if you need the _script_ return code instead of\nrem the _cmd.exe /c_ return code!\nif  not \"\" == \"%GRADLE_EXIT_CONSOLE%\" exit 1\nexit /b 1\n\n:mainEnd\nif \"%OS%\"==\"Windows_NT\" endlocal\n\n:omega\n"
        },
        {
          "name": "grobid-core",
          "type": "tree",
          "content": null
        },
        {
          "name": "grobid-home",
          "type": "tree",
          "content": null
        },
        {
          "name": "grobid-service",
          "type": "tree",
          "content": null
        },
        {
          "name": "grobid-trainer",
          "type": "tree",
          "content": null
        },
        {
          "name": "mkdocs.yml",
          "type": "blob",
          "size": 2.09375,
          "content": "site_name: GROBID Documentation\nrepo_url: https://github.com/kermitt2/grobid/\nrepo_name: GitHub\ntheme: readthedocs\nsite_description: Documentation for GROBID\ndocs_dir: doc\nextra_css:\n  - css/custom.css\nplugins:\n    - search\nnav:\n  - Home: 'index.md'\n  - About:\n    - 'Introduction': 'Introduction.md'\n    - 'How GROBID works': 'Principles.md'\n    - 'References': 'References.md'\n    - 'Licence': 'License.md'\n  - User manual:\n    - 'Run GROBID': 'Run-Grobid.md'\n    - 'GROBID service': 'Grobid-service.md'\n    - 'Build GROBID from source': 'Install-Grobid.md'\n    - 'GROBID with containers': 'Grobid-docker.md'\n    - 'GROBID batch mode': 'Grobid-batch.md'\n    - 'GROBID configuration': 'Configuration.md'\n    - 'GROBID specialized processes': 'Grobid-specialized-processes.md'\n    - 'Troubleshooting and known issues': 'Troubleshooting.md'\n    - 'Java library': 'Grobid-java-library.md'\n    - 'TEI encoding of results': 'TEI-encoding-of-results.md'\n    - 'Coordinates of structures in the PDF': 'Coordinates-in-PDF.md'\n    - 'Adding a consolidation service': 'Consolidation.md'\n    - 'Training the GROBID models': 'Training-the-models-of-Grobid.md'\n    - 'End-to-end evaluation': 'End-to-end-evaluation.md'\n    - 'Frequently asked Questions': 'Frequently-asked-questions.md'\n  - Benchmarking:\n    - 'Description': 'Benchmarking.md'\n    - 'PubMed Central': 'Benchmarking-pmc.md'\n    - 'bioRxiv': 'Benchmarking-biorxiv.md'\n    - 'PLOS': 'Benchmarking-plos.md'\n    - 'eLife': 'Benchmarking-elife.md'\n  - Annotation guidelines:\n    - 'General principles': 'training/General-principles.md'\n    - 'Segmentation model': 'training/segmentation.md'\n    - 'Fulltext model': 'training/fulltext.md'\n    - 'Header model': 'training/header.md'\n    - 'Bibliographical references': 'training/Bibliographical-references.md'\n    - 'Affiliation-address model': 'training/affiliation-address.md'\n    - 'Date model': 'training/date.md'\n  - Developer notes:\n    - 'Notes for the Grobid Developers': 'Notes-grobid-developers.md'\n    - 'Deep Learning models': 'Deep-Learning-models.md'\n    - 'Recompiling CRF libraries': 'Recompiling-and-integrating-CRF-libraries.md'\n"
        },
        {
          "name": "readthedocs.yml",
          "type": "blob",
          "size": 0.3818359375,
          "content": "# .readthedocs.yaml\n# Read the Docs configuration file\n# See https://docs.readthedocs.io/en/stable/config-file/v2.html for details\n\n# Required\nversion: 2\n\n# Set the version of Python and other tools you might need\nbuild:\n  os: ubuntu-22.04\n  tools:\n    python: \"3.11\"\n\npython:\n  install:\n    - requirements: doc/requirements.txt\n\nmkdocs:\n  configuration: mkdocs.yml\n  fail_on_warning: false\n"
        },
        {
          "name": "settings.gradle",
          "type": "blob",
          "size": 0.1201171875,
          "content": "rootProject.name = \"grobid\"\ninclude 'grobid-core'\ninclude 'grobid-service'\ninclude 'grobid-home'\ninclude 'grobid-trainer'\n\n"
        }
      ]
    }
  ]
}