{
  "metadata": {
    "timestamp": 1736708536812,
    "page": 770,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjc5MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "apache/logging-flume",
      "stars": 2545,
      "defaultBranch": "trunk",
      "files": [
        {
          "name": ".asf.yaml",
          "type": "blob",
          "size": 1.5986328125,
          "content": "# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# `.asf.yaml` is a branch-specific YAML configuration file for Git repositories to control features such as notifications, GitHub settings, etc.\n# See its documentation for details: https://cwiki.apache.org/confluence/display/INFRA/Git+-+.asf.yaml+features\n\nnotifications:\n  # GitHub already provides notifications for PRs and issues.\n  # Please don't duplicate that noise here!\n  commits: commits@logging.apache.org\n  jira_options: link label\ngithub:\n  description: \"Apache Flume is a distributed, reliable, and available service for efficiently collecting, aggregating, and moving large amounts of log-like data\"\n  homepage: https://flume.apache.org/\n  features:\n    issues: true\n  del_branch_on_merge: true\n  autolink_jira:\n    - FLUME\n  labels:\n    - apache\n    - api\n    - java\n    - jvm\n    - library\n    - flume\n  protected_branches:\n    main: {}\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.9931640625,
          "content": "# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# All text files with LF line endings\n* text=auto eol=lf\n# PS1 files are Windows specific\n*.ps1 eol=crlf\n# Maven Wrapper cmd script\n/mvnw.cmd eol=crlf\n# Maven Wrapper need LF line endings\n/.mvn/wrapper/maven-wrapper.properties eol=lf\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.28125,
          "content": "# Lines that start with '#' are comments.\n*~\n*.diff\n*#\n.classpath\n.project\n.settings\nbin/flume-env.sh\nconf/flume-site.xml\nbin/.settings\n.eclipse\npmd_report.html\n*/bin\ntarget\npatchprocess\nderby.log\n.idea\n*.iml\nnb-configuration.xml\n.DS_Store\n/.mvn/wrapper/maven-wrapper.jar\n**/metastore_db\n"
        },
        {
          "name": ".mvn",
          "type": "tree",
          "content": null
        },
        {
          "name": ".travis.yml.sav",
          "type": "blob",
          "size": 1.4765625,
          "content": "# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\nlanguage: generic\n\nenv:\n  global:\n\njobs:\n  include:\n    - name: \"Linux amd64\"\n      arch: amd64\n      dist: bionic\n    - name: \"Linux aarch64\"\n      arch: arm64-graviton2\n      dist: focal\n      virt: lxd\n      group: edge\n\ncache:\n  directories:\n    - $HOME/.m2\n\nbefore_install:\n  - export MAVEN_SKIP_RC=\"true\" # Travis has settings in /etc/mavenrc. We want to override them. See https://github.com/travis-ci/travis-ci/issues/4613\n  - sudo apt update\n  - sudo apt install -y openjdk-8-jdk\n  - export JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-${TRAVIS_CPU_ARCH}/\"\n  - export PATH=\"$JAVA_HOME/bin:$PATH\"\n\ninstall: true\n\nscript:\n  - MAVEN_OPTS=\"-Xms1024m -Xmx1024m\" travis_wait 50 ./mvnw test --fail-fast -DredirectTestOutput=false\n"
        },
        {
          "name": "CHANGELOG",
          "type": "blob",
          "size": 87.05859375,
          "content": "Release Notes - Flume - Version 1.12.0\n\n** Improvement\n    * [FLUME-3453 - Move flume-spring-boot to its own repo.\n\nRelease Notes - Flume - Version 1.11.0\n\n** Bug\n    * [FLUME-3315] - [KafkaSink][KafkaSource] Impossible to disable hostname verification with SSL enryption\n    * [FLUME-3437] - Validate providerUrl\n\n** New Feature\n    * [FLUME-3440] - Add support for Spring Boot\n\n** Improvement\n    * [FLUME-3435] - Allow KafkaSink to include timestamp and KafkaHeaders\n\n** Dependency upgrade\n    * [FLUME-3441] - Dependency Upgrades for Flume 1.11.0\n        * Update Maven Jar Plugin to 3.2.2\n        * Update Scala library to 2.13.9\n        * Update Gson to 2.9.1\n\nRelease Notes - Flume - Version 1.10.1\n\n** Bug\n    * [FLUME-3428] - Need better parameter validation\n    * [FLUME-3434] - TwitterSource exceptions on serialization\n\n** Improvement\n    * [FLUME-3427] - Add support for JPMS\n    * [FLUME-3433] - Limit the default Lookups to a specific few.\n\nRelease Notes - Flume - Version 1.10.0\n\n** Bug\n    * [FLUME-3151] - Upgrade Hadoop to 2.10.1\n    * [FLUME-3311] - Update Wrong Use In HDFS Sink\n    * [FLUME-3316] - Syslog Rfc3164Date test fails when the test date falls on a leap day\n    * [FLUME-3328] - Fix Deprecated Properties table of HDFS Sink\n    * [FLUME-3356] - Probable security issue in Flume\n    * [FLUME-3360] - Maven assemble failed on macOS\n    * [FLUME-3395] - Fix for CVE-2021-44228\n    * [FLUME-3407] - workaround for jackson-mapper-asl-1.9.13.jar  @ flume-ng\n    * [FLUME-3409] - upgrade httpclient due to cve\n    * [FLUME-3416] - Improve input validation\n    * [FLUME-3421] - Default log4j settings do not log to console after FLUME-2050\n    * [FLUME-3426] - Unresolved Security Issues\n\n** New Feature\n    * [FLUME-3412] - Add LoadBalancingChannelSelector\n\n** Improvement\n    * [FLUME-199] - Unit tests should hunt for available ports if defaults are in use\n    * [FLUME-2050] - Upgrade to log4j2 (when GA)\n    * [FLUME-3045] - Document GitHub Pull Requests in How to Contribute Guide\n    * [FLUME-3335] - Support configuration and reconfiguration via HTTP(S)\n    * [FLUME-3338] - Doc Flume Recoverability with Kafka\n    * [FLUME-3363] - CVE-2019-20445\n    * [FLUME-3368] - Update Jackson to 2.9.10\n    * [FLUME-3389] - Build and test Apache Flume on ARM64 CPU architecture\n    * [FLUME-3397] - Upgrade Log4 to 2.17.1 and SLF4J to 1.7.32\n    * [FLUME-3398] - Upgrade Kafka to a supported version.\n    * [FLUME-3399] - Update Jackson to 2.13.1\n    * [FLUME-3403] - The parquet-avro version used by flume is 1.4.1, which is vulnerabel.\n    * [FLUME-3405] - Reopened - The parquet-avro version used by flume is 1.4.1, which is vulnerabel.\n    * [FLUME-3413] - Add \"initialization\" phase to components.\n\n** Wish\n    * [FLUME-3400] - Upgrade commons-io to 2.11.0\n\n** Task\n    * [FLUME-3401] - Remove Kite Dataset Sink\n    * [FLUME-3402] - remove org.codehaus.jackson dependencies\n    * [FLUME-3404] - Update Commons CLI to 1.5.0, Commons Codec to 1.15, Commons Compress to 1.21 and Commons Lang to 2.6\n    * [FLUME-3410] - upgrade hbase version\n    * [FLUME-3411] - upgrade hive sink to 1.2.2\n    * [FLUME-3417] - Remove Elasticsearch sink that requires Elasticsearch 0.90.1\n    * [FLUME-3419] - Review project LICENSE and NOTICE\n    * [FLUME-3424] - Upgrade Twitter4j to version 4.0.7+\n\n** Dependency upgrade\n    * [FLUME-3339] - Remove Xerces and Xalan dependencies\n    * [FLUME-3385] - flume-ng-sdk uses Avro-IPC version with vulnerable version of Jetty\n    * [FLUME-3386] - flume-ng-sdk uses vulnerable version of netty\n\nRelease Notes - Flume - Version 1.9.0\n\n** New Feature\n    * [FLUME-2071] - Flume Context doesn't support float or double configuration values.\n    * [FLUME-2442] - Need an alternative to providing clear text passwords in flume config\n    * [FLUME-3142] - Adding HBase2 sink\n\n** Improvement\n    * [FLUME-2653] - Allow inUseSuffix to be null/empty\n    * [FLUME-2854] - Parameterize jetty version in pom\n    * [FLUME-2977] - Upgrade RAT to 0.12\n    * [FLUME-3050] - add counters for error conditions and expose to monitor URL\n    * [FLUME-3182] - Please add support for SSL/TLS for syslog (tcp) & multi_port syslog (tcp) sources\n    * [FLUME-3186] - Make asyncHbaseClient configuration parameters available from flume config\n    * [FLUME-3223] - Flume HDFS Sink should retry close prior to performing a recoverLease\n    * [FLUME-3227] - Add Rate Limiter to StressSource\n    * [FLUME-3239] - Do not rename files in SpoolDirectorySource\n    * [FLUME-3246] - Validate flume configuration to prevent larger source batch size than the channel transaction capacity\n    * [FLUME-3269] - Support JSSE keystore/trustore -D system properties\n    * [FLUME-3275] - Components supporting SSL/TLS should be able to specify protocol list\n    * [FLUME-3276] - Components supporting SSL/TLS should be able to specify cipher suite list\n    * [FLUME-3280] - Improve maven build to help code reviews by adding static code analyzer to it\n    * [FLUME-3281] - Update to Kafka 2.0 client\n    * [FLUME-3282] - Use slf4j in every component\n\n** Bug\n    * [FLUME-1282] - Flume 1.x build fails on Maven 2\n    * [FLUME-2232] - Add findbugs to Flume build\n    * [FLUME-2436] - Make hadoop-2 the default build profile\n    * [FLUME-2464] - Remove hadoop-2 profile\n    * [FLUME-2786] -  It will enter a deadlock state when modify the conf file before I stop flume-ng\n    * [FLUME-2894] - Flume components should stop in the correct order (graceful shutdown)\n    * [FLUME-2973] - Deadlock in hdfs sink\n    * [FLUME-2976] - Exception when JMS source tries to connect to a Weblogic server without authentication\n    * [FLUME-2988] - Kafka Sink metrics missing eventDrainAttemptCount\n    * [FLUME-2989] - Kafka Channel metrics missing eventTakeAttemptCount and eventPutAttemptCount\n    * [FLUME-3056] - TestApplication hangs indefinitely\n    * [FLUME-3101] - taildir source may endless loop when tail a file\n    * [FLUME-3106] - When batchSize of sink greater than transactionCapacity of Memory Channel, Flume can produce endless data\n    * [FLUME-3107] - When batchSize of sink greater than transactionCapacity of File Channel, Flume can produce endless data\n    * [FLUME-3114] - Upgrade commons-httpclient library dependency\n    * [FLUME-3117] - Application  can be dead loop when call System.exit()  in methodconfigure\n    * [FLUME-3133] - Add a ipHeader config in Syslog Sources\n    * [FLUME-3201] - Fix SyslogUtil to handle RFC3164 format in december correctly\n    * [FLUME-3218] - Fix external process config filter test\n    * [FLUME-3222] - java.nio.file.NoSuchFileException thrown when files are being deleted from the TAILDIR source\n    * [FLUME-3237] - Handling RuntimeExceptions coming from the JMS provider in JMSSource\n    * [FLUME-3253] - JP Morgan Chase scan shows vulnerabilities for Splunk App using Apache Flume 1.8\n    * [FLUME-3265] - Cannot set batch-size for LoadBalancingRpcClient\n    * [FLUME-3270] - Close JMS resources in JMSMessageConsumer constructor in case of failure\n    * [FLUME-3278] - Handling -D keystore parameters in Kafka components\n    * [FLUME-3294] - Fix polling logic in TaildirSource\n    * [FLUME-3298] - Make hadoop-common optional in flume-ng-hadoop-credential-store-config-filter\n    * [FLUME-3299] - Fix log4j scopes in pom files\n\n** Sub-task\n    * [FLUME-3158] - Upgrade surefire version and config\n    * [FLUME-3243] - Increase the default of hdfs.callTimeout and document it's deprecation\n\n** Test\n    * [FLUME-3195] - Split up the TestKafkaChannel class\n\n** Wish\n    * [FLUME-3087] - Change log level from WARN to INFO when using default \"maxIOWorkers\" value.\n\n** Task\n    * [FLUME-3183] - Maven: generate SHA-512 checksum during deploy\n\n** Dependency upgrade\n    * [FLUME-2698] - Upgrade Jetty Version\n    * [FLUME-3115] - Upgrade netty library dependency\n    * [FLUME-3194] - upgrade derby to the latest (1.14.1.0) version\n\n\nRelease Notes - Flume - Version v1.8.0\n\n** New Feature\n    * [FLUME-2171] - Add Interceptor to remove headers from event\n    * [FLUME-2917] - Provide netcat UDP source as alternative to TCP\n    * [FLUME-2993] - Support environment variables in configuration files\n\n** Improvement\n    * [FLUME-1520] - Timestamp interceptor should support custom headers\n    * [FLUME-2945] - Bump java target version to 1.8\n    * [FLUME-3020] - Improve HDFSEventSink Escape Ingestion by more then 10x by not getting InetAddress on every record\n    * [FLUME-3025] - Expose FileChannel.open on JMX\n    * [FLUME-3072] - Add IP address to headers in flume log4j appender\n    * [FLUME-3092] - Extend the FileChannel's monitoring metrics\n    * [FLUME-3100] - Support arbitrary header substitution for topic of Kafka\n    * [FLUME-3144] - Improve Log4jAppender's performance by allowing logging collection of messages\n\n** Bug\n    * [FLUME-2620] - File channel throws NullPointerException if a header value is null\n    * [FLUME-2752] - Flume AvroSource will leak the memory and the OOM will be happened.\n    * [FLUME-2812] - Exception in thread \"SinkRunner-PollingRunner-DefaultSinkProcessor\" java.lang.Error: Maximum permit count exceeded\n    * [FLUME-2857] - Kafka Source/Channel/Sink does not restore default values when live update config\n    * [FLUME-2905] - NetcatSource - Socket not closed when an exception is encountered during start() leading to file descriptor leaks\n    * [FLUME-2991] - ExecSource command execution starts before starting the sourceCounter\n    * [FLUME-3027] - Kafka Channel should clear offsets map after commit\n    * [FLUME-3031] - sequence source should reset its counter for event body on channel exception\n    * [FLUME-3043] - KafkaSink SinkCallback throws NullPointerException when Log4J level is debug\n    * [FLUME-3046] - Kafka Sink and Source Configuration Improvements\n    * [FLUME-3049] - Wrapping the exception into SecurityException in UGIExecutor.execute hides the original one\n    * [FLUME-3057] - Build fails due to unsupported snappy-java version on ppc64le\n    * [FLUME-3080] - Close failure in HDFS Sink might cause data loss\n    * [FLUME-3083] - Taildir source can miss events if file updated in same second as file close\n    * [FLUME-3085] - HDFS Sink can skip flushing some BucketWriters, might lead to data loss\n    * [FLUME-3112] - Upgrade jackson-core library dependency\n    * [FLUME-3127] - Upgrade libfb303 library dependency\n    * [FLUME-3131] - Upgrade spring framework library dependencies\n    * [FLUME-3132] - Upgrade tomcat jasper library dependencies\n    * [FLUME-3135] - property logger in org.apache.flume.interceptor.RegexFilteringInterceptor confused\n    * [FLUME-3141] - Small typo found in RegexHbaseEventSerializer.java\n    * [FLUME-3152] - Add Flume Metric for Backup Checkpoint Errors\n    * [FLUME-3155] - Use batch mode in mvn to fix Travis CI error\n    * [FLUME-3157] - Refactor TestHDFSEventSinkOnMiniCluster to not use LeaseManager private API\n    * [FLUME-3173] - Upgrade joda-time\n    * [FLUME-3174] - HdfsSink AWS S3A authentication does not work on JDK 8\n    * [FLUME-3175] - Javadoc generation fails due to Java8's strict doclint\n\n** Documentation\n    * [FLUME-2175] - Update Developer Guide with notes on how to upgrade Protocol Buffer version\n    * [FLUME-2817] - Sink for multi-agent flow example in user guide is set up incorrectly\n\n** Wish\n    * [FLUME-2579] - JMS source support durable subscriptions and message listening\n\n** Question\n    * [FLUME-2427] - java.lang.NoSuchMethodException and warning on HDFS (S3) sink \n\n** Task\n    * [FLUME-3093] - Groundwork for version changes in root pom\n    * [FLUME-3154] - Add HBase client version check to AsyncHBaseSink and HBaseSink\n\n** Test\n    * [FLUME-2997] - Fix flaky junit test in SpillableMemoryChannel\n    * [FLUME-3002] - Some tests in TestBucketWriter are flaky\n\n\nRelease Notes - Flume - Version v1.7.0\n\n** New Feature\n    * [FLUME-2498] - Implement Taildir Source\n\n** Improvement\n    * [FLUME-1899] - Make SpoolDir work with Sub-Directories\n    * [FLUME-2526] - Build flume by jdk 7 in default\n    * [FLUME-2628] - Add an optional parameter to specify the expected input text encoding for the netcat sourcef the netcat source\n    * [FLUME-2704] - Configurable poll delay for spooling directory source\n    * [FLUME-2718] - HTTP Source to support generic Stream Handler\n    * [FLUME-2729] - Allow pollableSource backoff times to be configurable\n    * [FLUME-2755] - Kafka Source reading multiple topics\n    * [FLUME-2781] - A Kafka Channel defined as parseAsFlumeEvent=false cannot be correctly used by a Flume source\n    * [FLUME-2799] - Kafka Source - Message Offset and Partition add to headers\n    * [FLUME-2801] - Performance improvement on TailDir source\n    * [FLUME-2810] - Add static Schema URL to AvroEventSerializer configuration\n    * [FLUME-2820] - Support New Kafka APIs\n    * [FLUME-2852] - Kafka Source/Sink should optionally read/write Flume records\n    * [FLUME-2868] - Kafka Channel partition topic by key\n    * [FLUME-2872] - Kafka Sink should be able to select which header as the key\n    * [FLUME-2875] - Allow RollingFileSink to specify a file prefix and a file extension.\n    * [FLUME-2909] - Bump Rat version\n    * [FLUME-2910] - AsyncHBaseSink - Failure callbacks should log the exception that caused them\n    * [FLUME-2911] - Add includePattern option in SpoolDirectorySource configuration\n    * [FLUME-2918] - TaildirSource is underperforming with huge parent directories\n    * [FLUME-2937] - Integrate checkstyle for non-test classes\n    * [FLUME-2941] - Integrate checkstyle for test classes\n    * [FLUME-2954] - make raw data appearing in log messages explicit\n    * [FLUME-2955] - Add file path to the header in TaildirSource\n    * [FLUME-2959] - Fix issues with flume-checkstyle module\n    * [FLUME-2982] - Add localhost escape sequence to HDFS sink\n    * [FLUME-2999] - Kafka channel and sink should enable statically assigned partition per event via header\n    * [FLUME-2821] - Flume-Kafka Source with new Consumer\n    * [FLUME-2822] - Flume-Kafka-Sink with new Producer\n    * [FLUME-2823] - Flume-Kafka-Channel with new APIs\n\n** Bug\n    * [FLUME-1668] - Hdfs Sink File Rollover\n    * [FLUME-2132] - Exception while syncing from Flume to HDFS\n    * [FLUME-2143] - Flume build occasionally fails with OutOfMemoryError on Windows.\n    * [FLUME-2215] - ResettableFileInputStream can't support  ucs-4 character\n    * [FLUME-2318] - SpoolingDirectory is unable to handle empty files\n    * [FLUME-2448] - Building flume from trunk failing with dependency error\n    * [FLUME-2484] - NullPointerException in Kafka Sink test\n    * [FLUME-2485] - Thrift Source tests fail on Oracle JDK 8\n    * [FLUME-2514] - Some TestFileChannelRestart tests are extremely slow\n    * [FLUME-2567] - Remove unneeded repository declarations in pom.xml\n    * [FLUME-2573] - flume-ng --conf parameter is not used when starting a flume agent\n    * [FLUME-2593] - ResettableFileInputStream returns negate values from read() method\n    * [FLUME-2619] - Spooldir source does not log channel exceptions\n    * [FLUME-2632] - High CPU on KafkaSink\n    * [FLUME-2652] - Documented transaction handling semantics incorrect\n    * [FLUME-2660] - Add documentation for EventValidator\n    * [FLUME-2672] - NPE in KafkaSourceCounter\n    * [FLUME-2712] - Optional channel errors slows down the Source to Main channel event rate\n    * [FLUME-2725] - HDFS Sink does not use configured timezone for rounding\n    * [FLUME-2732] - Make maximum tolerated failures before shutting down and recreating client in AsyncHbaseSink configurable\n    * [FLUME-2734] - Kafka Channel timeout property is overridden by default value\n    * [FLUME-2738] - Async HBase sink FD leak on client shutdown\n    * [FLUME-2746] - How to include this Flume Patch in Flume 1.5.2 ?\n    * [FLUME-2749] - Kerberos configuration error when using short names in multiple HDFS Sinks\n    * [FLUME-2751] - Upgrade Derby version to 10.11.1.1\n    * [FLUME-2753] - Error when specifying empty replace string in Search and Replace Interceptor\n    * [FLUME-2754] - Hive Sink skipping first transaction in each Batch of Hive Transactions\n    * [FLUME-2761] - Move Hive sink out of preview mode\n    * [FLUME-2763] - flume_env script should handle jvm parameters like -javaagent -agentpath -agentlib\n    * [FLUME-2773] - TailDirSource throws FileNotFound Exception if ~/.flume directory is not created already\n    * [FLUME-2797] - SyslogTcpSource uses Deprecated Class + Deprecate SyslogTcpSource\n    * [FLUME-2798] - Malformed Syslog messages can lead to OutOfMemoryException\n    * [FLUME-2804] - Hive sink - abort remaining transactions on shutdown\n    * [FLUME-2806] - flume-ng.ps1 Error running script to start an agent on Windows\n    * [FLUME-2835] -  Hive Sink tests need to create table with transactional property set\n    * [FLUME-2841] - Upgrade commons-collections to 3.2.2\n    * [FLUME-2844] - ChannelCounter of SpillableMemoryChannel doesn't register actually.\n    * [FLUME-2881] - Windows Launch Script fails in plugins dir code\n    * [FLUME-2886] - Optional Channels can cause OOMs\n    * [FLUME-2889] - Fixes to  DateTime computations\n    * [FLUME-2891] - Revert FLUME-2712 and FLUME-2886\n    * [FLUME-2897] - AsyncHBase sink NPE when Channel.getTransaction() fails\n    * [FLUME-2901] - Document Kerberos setup for Kafka channel\n    * [FLUME-2908] - NetcatSource - SocketChannel not closed when session is broken\n    * [FLUME-2913] - Flume classpath too long\n    * [FLUME-2915] - The kafka channel using new APIs will be stuck when the sink is avro sink\n    * [FLUME-2920] - Kafka Channel Should Not Commit Offsets When Stopping\n    * [FLUME-2922] - HDFSSequenceFile Should Sync Writer\n    * [FLUME-2923] - Bump AsyncHBase version\n    * [FLUME-2936] - KafkaSource tests arbitrarily fail\n    * [FLUME-2939] - Upgrade recursive SpoolDir to use Java7 features\n    * [FLUME-2948] - Docs: Fixed parameters on Replicating Channel Selector documentation example\n    * [FLUME-2949] - Flume fails to build on Windows\n    * [FLUME-2950] - ReliableSpoolingFileEventReader.rollCurrentFile is broken\n    * [FLUME-2952] - SyslogAgent possible NPE on stop()\n    * [FLUME-2972] - Handle offset migration in the new Kafka Channel\n    * [FLUME-2974] - Some tests are broken in TestReliableSpoolingFileEventReader and TestSpoolingFileLineReader\n    * [FLUME-2983] - Handle offset migration in the new Kafka Source\n\n** Documentation\n    * [FLUME-2575] - FLUME-2548 brings SSLv2Hello back for Avro Sink, but UG says it is one of the protocols to exclude\n    * [FLUME-2713] - Document Fault Tolerant Config parameters in FlumeUserGuide\n    * [FLUME-2737] - Documentation for Pollable Source config parameters introduced in FLUME-2729\n    * [FLUME-2783] - Update Website Team page with new Committer's\n    * [FLUME-2890] - Typo in Twitter source warning\n    * [FLUME-2934] - Document new cachePatternMatching option for TaildirSource\n    * [FLUME-2963] - FlumeUserGuide - error in Kafka Source properties table\n    * [FLUME-2971] - Document secure Kafka Sink/Source/Channel setup\n    * [FLUME-2975] - Minor mistake in NetCat Source example in documentation\n    * [FLUME-2998] - Add missing configuration parameter to SequenceSource docs\n\n** Task\n    * [FLUME-2935] - Bump java target version to 1.7\n\n** Test\n    * [FLUME-3003] - testSourceCounter in TestSyslogUdpSource is flaky\n\n\nRelease Notes - Flume - Version v1.6.0\n\n** Sub-task\n    * [FLUME-2250] - Add support for Kafka Source\n    * [FLUME-2251] - Add support for Kafka Sink\n    * [FLUME-2677] - Update versions in 1.6.0 branch\n    * [FLUME-2686] - Update KEYS file for 1.6 release\n\n** Bug\n    * [FLUME-1793] - Unit test TestElasticSearchLogStashEventSerializer fails with IBM JDK\n    * [FLUME-1934] - Spoolingdir source exception when reading multiple   zero size files\n    * [FLUME-2024] - Add ExecSource flush timeout to Flume User Guide\n    * [FLUME-2126] - Problem in elasticsearch sink when the event body is a complex field\n    * [FLUME-2148] - Windows : Add  flume-env.ps1\n    * [FLUME-2214] - FileChannelIntegrityTool needs documentation in user guide\n    * [FLUME-2245] - HDFS files with errors unable to close\n    * [FLUME-2337] - export JAVA_HOME in flume-env.sh.template and increase heap size\n    * [FLUME-2346] - idLogFileMap in Log can lose track of file ids\n    * [FLUME-2404] - Default maxReadBufferBytes might cause OOM and cause scribe source exit\n    * [FLUME-2408] - Remove FLUME-1899 from Flume 1.5.0 change log.\n    * [FLUME-2416] - Use CodecPool in compressed stream to prevent leak of direct buffers\n    * [FLUME-2420] - HDFSEventSink#stop might throw ConcurrentModificationException\n    * [FLUME-2425] - FileChannel should trim data and checkpoint directories\n    * [FLUME-2432] - Update Kite dependency to 0.15.0\n    * [FLUME-2438] - Make Syslog source message body configurable\n    * [FLUME-2450] - Improve replay index insertion speed.\n    * [FLUME-2466] - Embedded agent name cannot contain spaces\n    * [FLUME-2470] - Kafka Sink and Source must use camel case for all configs.\n    * [FLUME-2472] - SyslogUtils fails when system locale is not English\n    * [FLUME-2475] - toLowerCase/toUpperCase used without Locale parameter to manipulate Enum\n    * [FLUME-2479] - Kafka property auto.commit.enable is incorrect for KafkaSource\n    * [FLUME-2480] - Typo in file channel exception: \"Usable space exhaused\"\n    * [FLUME-2481] - TestFileChannelEncryption fails with System locale other than en_US\n    * [FLUME-2482] - Race condition in File Channels' Log.removeOldLogs\n    * [FLUME-2486] - TestExecSource fails on some environments\n    * [FLUME-2487] - SyslogParser has rounding errors in timestamp parsing\n    * [FLUME-2488] - TestElasticSearchRestClient fails on Oracle JDK 8\n    * [FLUME-2489] - Upgrade Apache Curator to 2.6.0\n    * [FLUME-2492] - Flume's Kafka Source doesn't account time correctly\n    * [FLUME-2495] - Kafka Source may miss events when channel is not available\n    * [FLUME-2497] - TCP and UDP syslog sources parsing the timestamp incorrectly\n    * [FLUME-2500] - Add a channel that uses Kafka\n    * [FLUME-2505] - Test added in FLUME-2502 is flaky\n    * [FLUME-2517] - Performance issue: SimpleDateFormat constructor takes 30% of HDFSEventSink.process()\n    * [FLUME-2525] - flume should handle a zero byte .flumespool-main.meta file for the spooldir source\n    * [FLUME-2538] - TestResettableFileInputStream fails on JDK 8\n    * [FLUME-2556] - TestBucketPath.testDateFormatHours fails intermittently\n    * [FLUME-2557] - DatasetSink doesn't work with Kerberos\n    * [FLUME-2560] - Kafka channel entries missing for output jar generation\n    * [FLUME-2568] - Additional fix for TestReliableSpoolingFileEventReader\n    * [FLUME-2578] - Kafka source throws NPE if Kafka record has null key\n    * [FLUME-2586] - HDFS Sink should have an option to try rename even if close fails\n    * [FLUME-2592] - Specify main manifest attribute in flume tools jar\n    * [FLUME-2594] - Close Async HBase Client if there are large number of consecutive timeouts\n    * [FLUME-2595] - Add option to checkpoint on file channel shutdown\n    * [FLUME-2624] - Improve Hive Sink performance\n    * [FLUME-2626] - Remove trustmanager-type from Thrift RPC client\n    * [FLUME-2633] - Update Kite dependency to 1.0.0\n    * [FLUME-2639] - SecureThriftRpcClient client privileged calls throw IllegalAccessError\n    * [FLUME-2645] - ipFilter.rules property name is wrong\n    * [FLUME-2654] - Memory channel error message related to byteCapacity needs refining\n    * [FLUME-2657] - Upgrade to Hive 1.0\n    * [FLUME-2658] - Upgrade to Hbase 1.0\n    * [FLUME-2664] - Site profile fails due to dependency issues\n    * [FLUME-2665] - Update documentation for hdfs.closeTries based on FLUME-2586\n    * [FLUME-2670] - Modify dependencies to not pull hadoop/hive related jars\n    * [FLUME-2673] - Remove unused import in TestLog\n    * [FLUME-2678] - Upgrade xalan to 2.7.2 to take care of CVE-2014-0107 vulnerability\n    * [FLUME-2679] - Make hbase-1 the default profile\n\n** Dependency upgrade\n    * [FLUME-2443] - org.apache.hadoop.fs.FSDataOutputStream.sync() is deprecated in hadoop 2.4\n\n** Documentation\n    * [FLUME-1594] - Document JMX options\n    * [FLUME-2509] - Add description for properties in Failover Sink Processor\n    * [FLUME-2630] - Update documentation for Thrift Src/Sink SSL support and Kerberos support\n    * [FLUME-2635] - Documentation for zookeeper dynamic configuration in flume\n    * [FLUME-2668] - Document SecureThriftRpcClient/SecureRpcClientFactory in Flume Developer Guide\n\n** Improvement\n    * [FLUME-1334] - Write an startscript for flume agents on Windows\n    * [FLUME-1491] - Dynamic configuration from Zookeeper watcher\n    * [FLUME-1521] - Document the StressSource\n    * [FLUME-1710] - JSONEvent.getBody should not return null\n    * [FLUME-1920] - Test case TestFileChannel fails when flume is built from paths containing the string \"hadoop\"\n    * [FLUME-2237] - Example config in User Guide to use same notation for Agent name\n    * [FLUME-2246] - event body data size can make it configurable for logger sinker\n    * [FLUME-2273] - ElasticSearchSink: Add handling for header substitution in indexName\n    * [FLUME-2373] - Enable configuration to switch thrift source serialization protocol\n    * [FLUME-2385] - Flume spans log file with \"Spooling Directory Source runner has shutdown\" messages at INFO level\n    * [FLUME-2401] - Optionally Compress Backup Checkpoint\n    * [FLUME-2439] - Update DatasetSink for Kite 0.15.0\n    * [FLUME-2462] - Remove use of deprecated methods in DatasetSink\n    * [FLUME-2463] - Add support for Hive and HBase datasets to DatasetSink\n    * [FLUME-2469] - DatasetSink should load dataset when needed, not at startup\n    * [FLUME-2499] - Include Kafka Message Key in Event Header, Updated Comments\n    * [FLUME-2502] - Spool source's directory listing is inefficient\n    * [FLUME-2558] - Update javadoc for StressSource\n    * [FLUME-2562] - Metrics for Flafka components\n    * [FLUME-2591] - Kite DatasetSink 2.0\n    * [FLUME-2613] - Tool/script for deleting individual message from queue\n    * [FLUME-2642] - Limit kerberos relogin attempt\n\n** New Feature\n    * [FLUME-1734] - Create a Hive Sink based on the new Hive Streaming support\n    * [FLUME-2242] - Flume Sink and Source for Apache Kafka\n    * [FLUME-2426] - Support interceptors in the Embedded Agent\n    * [FLUME-2431] - Add simple regex search-and-replace interceptor\n    * [FLUME-2570] - Add option to not pad date fields\n    * [FLUME-2574] - SSL Support for Thrift Rpc\n    * [FLUME-2631] - End to End authentication in Flume\n\n** Task\n    * [FLUME-2365] - Please create a DOAP file for your TLP\n    * [FLUME-2454] - Support batchSize to allow multiple events per transaction to the Kafka Sink\n    * [FLUME-2455] - Documentation update for Kafka Sink\n    * [FLUME-2523] - Document Kafka channel\n    * [FLUME-2612] - Update kite to 0.17.1\n\n** Test\n    * [FLUME-1501] - Flume Scribe Source needs unit tests.\n\nRelease Notes - Flume - Version v1.5.2\n\n** Bug\n    * [FLUME-2547] - Removing SSLv2Hello causes Java 6 clients to break\n\n** Sub-task\n    * [FLUME-2548] - Enable SSLv2Hello for Avro Source and NettyAvroRpcClient\n    * [FLUME-2549] - Enable SSLv2Hello for HttpSource\n\n** Improvement\n    * [FLUME-2551] - Add dev-support to src tarball\n\nRelease Notes - Flume - Version v1.5.1\n\n** Bug\n    * [FLUME-2441] - Unit test TestHTTPSource.java failed with IBM JDK 1.7\n    * [FLUME-2520] - HTTP Source should be able to block a prefixed set of protocols.\n    * [FLUME-2533] - HTTPS tests fail on Java 6\n\n** Improvement\n    * [FLUME-2511] - Allow configuration of enabled protocols in Avro source and Rpc client\n\nRelease Notes - Flume - Version v1.5.0.1\n\n** Bug\n    * [FLUME-2389] - Spillable Memory Channel Example is incorrect\n    * [FLUME-2397] - HBase-98 compatibility\n    * [FLUME-2400] - Dataset Sink is not built in hbase-98 profile\n\nRelease Notes - Flume - Version v1.5.0\n\n** New Feature\n    * [FLUME-1227] - Introduce some sort of SpillableChannel\n    * [FLUME-2056] - Allow SpoolDir to pass just the filename that is the source of an event\n    * [FLUME-2071] - Flume Context doesn't support float or double configuration values.\n    * [FLUME-2185] - Upgrade morphlines to 0.7.0\n    * [FLUME-2188] - flume-ng-log4jappender Support user supplied headers\n    * [FLUME-2225] - Elasticsearch Sink for ES HTTP API\n    * [FLUME-2294] - Add a sink for Kite Datasets\n    * [FLUME-2309] - Spooling directory should not always consume the oldest file first.\n\n** Improvement\n    * [FLUME-1542] - Flume User Guide sample configurations need fixing\n    * [FLUME-2052] - Spooling directory source should be able to replace or ignore malformed characters\n    * [FLUME-2130] - Handle larger payloads via SyslogUDPSource\n    * [FLUME-2139] - upgrade morphline library dependency to a 0.5.0 release\n    * [FLUME-2154] - Reducing duplicate events caused by reset-connection-interval\n    * [FLUME-2155] - Improve replay time\n    * [FLUME-2181] - Optionally disable File Channel fsyncs\n    * [FLUME-2202] - AsyncHBaseSink should coalesce increments to reduce RPC roundtrips\n    * [FLUME-2206] - ElasticSearchSink ttl field modification to mimic Elasticsearch way of specifying TTL\n    * [FLUME-2207] - HDFS file suffix style index suffix in ElasticSearchSink\n    * [FLUME-2212] - upgrade to Morphlines-0.8.0\n    * [FLUME-2213] - MorphlineInterceptor should share metric registry across threads for better (aggregate) reporting\n    * [FLUME-2217] - Preserve priority, timestamp and hostname fields in MultiportSyslogTcp and Udp sources\n    * [FLUME-2231] - Add details in Flume Ganglia config in User Guide\n    * [FLUME-2243] - AvroSource to use TransceiverThreadFactory for Thread naming while initializing NioServerSocketChannelFactory\n    * [FLUME-2267] - Increase default transactionCapacity for FileChannel to 10000 from 1000\n    * [FLUME-2275] - Improve scalability of MorphlineInterceptor under contention\n    * [FLUME-2292] - Upgrade mapdb to 0.9.8\n    * [FLUME-2316] - Upgrade MorphlineSolrSink to kite-0.12.0\n    * [FLUME-2340] - Refactor to make room for Morphlines Elasticsearch Sink\n    * [FLUME-2343] - Add user impersonation to DatasetSink\n    * [FLUME-2351] - Ability to override any parameter from the configuration file\n    * [FLUME-2352] - HDFSCompressedDataStream should support appendBatch\n\n** Bug\n    * [FLUME-1666] - Syslog source strips timestamp and hostname from log message body\n    * [FLUME-1679] - Add dependency on Guava to flume-ng-elasticsearch-sink POM\n    * [FLUME-1892] - IRC Sink NPE\n    * [FLUME-1951] - Remove unused future from FlumeEventQueue\n    * [FLUME-2007] - HDFS Sink should check if file is closed and retry if it is not.\n    * [FLUME-2088] - Minor typo in Flume User Guide JSON Reporting section\n    * [FLUME-2109] - HTTPS support in HTTP Source\n    * [FLUME-2110] - Scribe Source must check if category is null before inserting the headers\n    * [FLUME-2119] - duplicate files cause flume to enter irrecoverable state\n    * [FLUME-2121] - Upgrade Flume to log4j 1.2.17 to be in sync with HDFS/HBase\n    * [FLUME-2122] - Minor cleanups of User guide\n    * [FLUME-2123] - Morphline Solr sink missing short type name\n    * [FLUME-2124] - Upgrade Morphline Solr Sink to CDK 0.4.1\n    * [FLUME-2127] - JMX shutdown command for Flume\n    * [FLUME-2134] - AsyncHbase Sink bugfix plus tests errors on Windows\n    * [FLUME-2135] - Add zip to the build distribution for Windows support\n    * [FLUME-2136] - Windows - Fix intermitent test failure in TestMonitoredCounterGroup.java\n    * [FLUME-2137] - Fix StagedInstall.java to invoke the correct startup script on Windows\n    * [FLUME-2142] - HTTPS tests for http source\n    * [FLUME-2145] - TestCheckpointRebuilder.testFastReplay  fails on Windows due to checkpoint file being memory mapped\n    * [FLUME-2151] - Windows:  Update TestExecSource to use native commands on Windows\n    * [FLUME-2152] - Flume user guide says \"Ganglia support\" where it should say \"JSON support\"\n    * [FLUME-2156] - Unregister then re-register MonitoredCounterGroup JMX MBeans on reconfigure\n    * [FLUME-2157] - Spool directory source does not shut down correctly when Flume is reconfigured\n    * [FLUME-2159] - Sporadic failures in  TestNettyAvroRpcClient.spinThreadsCrazily()\n    * [FLUME-2161] - Flume does not support spaces in -X java-opt command line args\n    * [FLUME-2172] - Update protocol buffer from 2.4.1 to 2.5.0\n    * [FLUME-2176] - SpoolDir Source, get 'File has changed' exception but actually there is no change on the file\n    * [FLUME-2182] - Spooling Directory Source will not ingest data completely when a wide character appears at the edge of a buffer\n    * [FLUME-2184] - flume-ng-morphline-solr-sink Build failing due to incorrect hadoop-common dependency declaration\n    * [FLUME-2191] - HDFS Minicluster tests failing after protobuf upgrade.\n    * [FLUME-2192] - AbstractSinkProcessor stop incorrectly calls start\n    * [FLUME-2198] - Avro Source should disable itself if ipFilterRules contains invalid rules\n    * [FLUME-2199] - Flume builds with new version require mvn install before site can be generated\n    * [FLUME-2200] - HTTP Source should be able to use \"port\" parameter if SSL is enabled\n    * [FLUME-2208] - Jetty's default SocketSelector leaks File descriptors\n    * [FLUME-2209] - AsyncHBaseSink will never recover if the column family does not exists for the first start\n    * [FLUME-2210] - UnresolvedAddressException when using multiple hostNames in Elasticsearch sink configuration\n    * [FLUME-2220] - ElasticSearch sink - duplicate fields in indexed document\n    * [FLUME-2229] - Backoff period gets reset too often in OrderSelector\n    * [FLUME-2233] - MemoryChannel lock contention on every put due to bytesRemaining Semaphore\n    * [FLUME-2235] - idleFuture should be cancelled at the start of append\n    * [FLUME-2238] - Provide option to configure worker threads in NettyAvroRpcClient\n    * [FLUME-2239] - Clarify File Channel's  dataDirs setting in User Guide\n    * [FLUME-2252] - Add null check before closing table in HbaseSink\n    * [FLUME-2253] - Please delete old releases from mirroring system\n    * [FLUME-2255] - Spooling Directory Source cannot handle channel exceptions\n    * [FLUME-2259] - transaction  closure not happening for all the scenario in hbasesink\n    * [FLUME-2262] - Log4j Appender should use timeStamp field not getTimestamp\n    * [FLUME-2263] - Bump Hadoop 2 version to 2.3.0\n    * [FLUME-2264] - Log4j Appender + Avro Reflection on string results in an invalid avro schema\n    * [FLUME-2265] - Closed bucket writers should be removed from sfwriters map\n    * [FLUME-2266] - Update Morphline Sink to kite-0.10.0\n    * [FLUME-2270] - Twitter Source Documentation Does not load properly\n    * [FLUME-2272] - Getting start page returning 503 error\n    * [FLUME-2283] - Spool Dir source must check interrupt flag before writing to channel\n    * [FLUME-2289] - Disable maxUnderReplication test which is extremely flakey\n    * [FLUME-2301] - Update HBaseSink tests to reflect sink returning backoff only on empty batches\n    * [FLUME-2302] - TestHDFS Sink fails with Can't get Kerberos realm\n    * [FLUME-2303] - HBaseSink tests can fail based on order of execution\n    * [FLUME-2304] - DatasetSink test fails unexpectedly\n    * [FLUME-2305] - BucketWriter#close must cancel idleFuture\n    * [FLUME-2307] - Remove Log writetimeout\n    * [FLUME-2311] - Use standard way of finding queue/topic\n    * [FLUME-2312] - Add utility for adorning HTTP contexts in Jetty\n    * [FLUME-2314] - Upgrade to Mapdb 0.9.9\n    * [FLUME-2320] - Deadlock in DatasetSink\n    * [FLUME-2323] - Morphline sink must increment eventDrainAttemptCount when it takes event from channel\n    * [FLUME-2324] - Support writing to multiple HBase clusters using HBaseSink\n    * [FLUME-2325] - BucketWriter might throw BucketClosedException incorrectly\n    * [FLUME-2328] - FileChannel Dual Checkpoint Backup Thread not released on Application stop\n    * [FLUME-2329] - Add an alias for the Morphline Solr Sink\n    * [FLUME-2330] - Remove the MorphlineHandlerImpl configuration option from MorphlineSink\n    * [FLUME-2334] - Upgrade Asynchbase to 1.5.0 as this include hbase 0.96.x support\n    * [FLUME-2335] - TestHBaseSink#testWithoutConfigurationObject() must delete the table at the end of the test\n    * [FLUME-2336] - HBase tests that pass in ZK configs must use a new context object\n    * [FLUME-2338] - Support coalescing increments in HBaseSink\n    * [FLUME-2345] - Update to Kite 0.12.0 dependency\n    * [FLUME-2347] - Add FLUME_JAVA_OPTS which allows users to inject java properties from cmd line\n    * [FLUME-2350] - Consume Order tests need to space out file creation\n    * [FLUME-2357] - HDFS sink should retry closing files that previously had close errors\n    * [FLUME-2381] - Upgrade Hadoop version in Hadoop 2 profile to 2.4.0\n    * [FLUME-2379] - Flume's pom files are invalid and not parseable by non-maven build tools\n\n** Documentation\n    * [FLUME-1223] - Userguide improvement rolling file sink\n    * [FLUME-1678] - Incorrect documentation for HBase sink\n    * [FLUME-1851] - User Guide grammar mistake\n    * [FLUME-2064] - Typo/Grammar in flume main user doc under Scribe\n    * [FLUME-2065] - Regex Extractor Interceptor config agent name inconsistent with rest of docs\n    * [FLUME-2183] - Add \"Other Resources\" page to wiki\n    * [FLUME-2278] - Incorrect documentation for write-timeout of File Channel\n    * [FLUME-2319] - Incorrect property name of Ganglia Reporting documentation\n\n\nRelease Notes - Flume - Version v1.4.0\n\n** New Feature\n    * [FLUME-924] - Implement a JMS source for Flume NG\n    * [FLUME-997] - Support secure transport mechanism\n    * [FLUME-1170] - Create a framework for transaction listeners\n    * [FLUME-1502] - Support for running simple configurations embedded in host process\n    * [FLUME-1516] - FileChannel Write Dual Checkpoints to avoid replays\n    * [FLUME-1632] - Persist progress on each file in file spooling client/source\n    * [FLUME-1735] - Add support for a plugins.d directory\n    * [FLUME-1894] - Implement Thrift RPC\n    * [FLUME-1917] - FileChannel group commit (coalesce fsync)\n    * [FLUME-2004] - Need to capture metrics on the Flume exec source such as events received, rejected, etc.\n    * [FLUME-2010] - Support Avro records in Log4jAppender and the HDFS Sink\n    * [FLUME-2048] - Avro container file deserializer\n    * [FLUME-2070] - Add a Flume Morphline Solr Sink\n\n** Improvement\n    * [FLUME-1076] - Sink batch sizes vary wildy\n    * [FLUME-1100] - HDFSWriterFactory and HDFSFormatterFactory should allow extension\n    * [FLUME-1571] - Channels should check for positive capacity and transaction capacity values\n    * [FLUME-1586] - File Channel should support verifying integrity of individual events.\n    * [FLUME-1652] - Logutils.getLogs could NPE\n    * [FLUME-1661] - ExecSource cannot execute complex *nix commands\n    * [FLUME-1677] - Add File-channel dependency to flume-ng-node's pom.xml\n    * [FLUME-1699] - Make the rename of the meta file platform neutral\n    * [FLUME-1702] - HDFSEventSink should write to a hidden file as opposed to a .tmp file\n    * [FLUME-1740] - Remove contrib/ directory from Flume NG\n    * [FLUME-1745] - FlumeConfiguration Eats Exceptions\n    * [FLUME-1756] - Avro client should be able to use load balancing RPC\n    * [FLUME-1757] - Improve configuration of hbase serializers\n    * [FLUME-1762] - File Channel should recover automatically if the checkpoint is incomplete or bad by deleting the contents of the checkpoint directory\n    * [FLUME-1768] - Multiplexing channel selector should allow optional-only channels\n    * [FLUME-1769] - Replicating channel selector should support optional channels\n    * [FLUME-1770] - Flume should have serializer which supports serializer the headers to a simple string\n    * [FLUME-1777] - AbstractSource does not provide enough implementation for sub-classes\n    * [FLUME-1790] - Commands in EncryptionTestUtils comments require high encryption pack to be installed\n    * [FLUME-1794] - FileChannel check for full disks in the background\n    * [FLUME-1800] - Docs for spooling source durability changes\n    * [FLUME-1808] - ElasticSearchSink is missing log4.properties\n    * [FLUME-1821] - Support configuration of hbase instances to be used in AsyncHBaseSink from flume config\n    * [FLUME-1847] - NPE in SourceConfiguration\n    * [FLUME-1848] - HDFSDataStream logger is actually for a sequence file\n    * [FLUME-1855] - Sequence gen source should be able to stop after a fixed number of events\n    * [FLUME-1864] - Allow hdfs idle callback to clean up closed bucket writers\n    * [FLUME-1874] - Ship with log4j.properties file that has a reliable time based rolling policy\n    * [FLUME-1876] - Document hadoop dependency of FileChannel when used with EmbeddedAgent\n    * [FLUME-1878] - FileChannel replay should print status every 10000 events\n    * [FLUME-1886] - Add a JMS enum type to SourceType so that users don't need to enter FQCN for JMSSource\n    * [FLUME-1889] - Add HBASE and ASYNC_HBASE enum types to SinkType so that users don't need to enter FQCNs\n    * [FLUME-1906] - Ability to disable WAL for put operation in HBaseSink\n    * [FLUME-1915] - Enhance NettyAvroRpcClient and the use of NettyServer to optionally use compression\n    * [FLUME-1926] - Optionally timeout Avro Sink Rpc Clients to avoid stickiness\n    * [FLUME-1940] - Log a snapshot of Flume metrics on shutdown\n    * [FLUME-1945] - HBase Serializer allow key from regular expression group\n    * [FLUME-1976] - JMS Source document should provide instruction on JMS implementation jars\n    * [FLUME-1977] - JMS Source connectionFactory property is not documented\n    * [FLUME-1992] - ElasticSearch dependency is marked optional\n    * [FLUME-1994] - Add ELASTICSEARCH enum type to SinkType to eliminate need for FQCN in agent configuration files\n    * [FLUME-2005] - Minor improvements to Flume assembly config\n    * [FLUME-2008] - it would be very convenient to have a fat jar of flume-ng-log4jappender\n    * [FLUME-2009] - Flume project throws error when imported into Eclipse IDE (Juno)\n    * [FLUME-2013] - Parametrize java source and target version in the main pom file\n    * [FLUME-2015] - ElasticSearchSink: need access to IndexRequestBuilder instance during flume event processing\n    * [FLUME-2046] - Typo in HBaseSink java doc\n    * [FLUME-2049] - Compile ElasticSearchSink with elasticsearch 0.90\n    * [FLUME-2062] - make it possible for HBase sink to deposit event headers into corresponding column qualifiers\n    * [FLUME-2063] - Add Configurable charset to RegexHbaseEventSerializer\n    * [FLUME-2076] - JMX metrics support for HTTP Source\n    * [FLUME-2093] - binary tarball that is created by flume's assembly shouldn't contain sources\n    * [FLUME-2100] - Increase default batchSize of Morphline Solr Sink\n    * [FLUME-2105] - Add docs for MorphlineSolrSink\n\n** Bug\n    * [FLUME-1110] - HDFS Sink throws IllegalStateException when flume-daemon shuts down\n    * [FLUME-1153] - flume-ng script is missing some agent options in help output\n    * [FLUME-1175] - RollingFileSink complains of Bad File Descriptor upon a reconfig event\n    * [FLUME-1262] - Move doc generation to a different profile\n    * [FLUME-1285] - FileChannel has a dependency on Hadoop IO classes\n    * [FLUME-1296] - Lifecycle supervisor should check if the monitor service is still running before supervising\n    * [FLUME-1511] - Scribe-source doesn't handle zero message request correctly.\n    * [FLUME-1676] - ExecSource should provide a configurable charset\n    * [FLUME-1688] - Bump AsyncHBase version to 1.4.1\n    * [FLUME-1709] - HDFS CompressedDataStream doesn't support serializer parameter\n    * [FLUME-1720] - LICENSE file contain entry for protobuf-<version>.jar, however proper artifact name is protobuf-java-<version>.jar\n    * [FLUME-1731] - SpoolableDirectorySource should have configurable support for deleting files it has already completed instead of renaming\n    * [FLUME-1741] - ElasticSearch tests leave directory data/elasticsearch/nodes/ lying around\n    * [FLUME-1748] - HDFS Sink should check if the thread is interrupted before performing any HDFS operations\n    * [FLUME-1755] - Load balancing RPC client has issues with downed hosts\n    * [FLUME-1766] - AvroSource throws confusing exception when configured without a port\n    * [FLUME-1772] - AbstractConfigurationProvider should remove component which throws exception from configure method.\n    * [FLUME-1773] - File Channel worker thread should not be daemon\n    * [FLUME-1774] - EventBackingStoreFactory error message asks user to delete checkpoint which is now done automatically\n    * [FLUME-1775] - FileChannel Log Background worker should catch Throwable\n    * [FLUME-1776] - Several modules require commons-lang but do not declare this in the pom\n    * [FLUME-1778] - Upgrade Flume to use Avro 1.7.3\n    * [FLUME-1784] - JMSource fix minor documentation problem and parameter name\n    * [FLUME-1788] - Flume Thrift source can fail intermittently because of a race condition in Thrift server implementation on some Linux systems\n    * [FLUME-1789] - Unit tests TestJCEFileKeyProvider and TestFileChannelEncryption fail with IBM JDK and flume-1.3.0\n    * [FLUME-1795] - Flume thrift legacy source does not have proper logging configured\n    * [FLUME-1797] - TestFlumeConfiguration is in com.apache.flume.conf namespace.\n    * [FLUME-1799] - Generated source tarball is missing flume-ng-embedded-agent\n    * [FLUME-1802] - Missing parameter --conf in example of the Flume User Guide\n    * [FLUME-1803] - Generated dist tarball is missing flume-ng-embedded-agent\n    * [FLUME-1804] - JMS source not included in binary dist\n    * [FLUME-1805] - Embedded agent deps should be specified in dependencyManagement section of pom\n    * [FLUME-1818] - Support various layouts in log4jappender\n    * [FLUME-1819] - ExecSource don't flush the cache if there is no input entries\n    * [FLUME-1820] - Should not be possible for RPC client to block indefinitely on close()\n    * [FLUME-1822] - Update javadoc for FlumeConfiguration\n    * [FLUME-1823] - LoadBalancingRpcClient method must throw exception if it is called after close is called.\n    * [FLUME-1824] - Inflights can complete successfully even if checkpoint fails\n    * [FLUME-1828] - ResettableInputStream should support seek()\n    * [FLUME-1834] - Userguide on trunk is missing some memory channel props\n    * [FLUME-1835] - Flume User Guide has wrong prop in Load Balancing Sink Selector\n    * [FLUME-1844] - HDFSEventSink should have option to use RawLocalFileSystem\n    * [FLUME-1845] - Document plugin.d directory structure\n    * [FLUME-1849] - Embedded Agent doesn't shutdown supervisor\n    * [FLUME-1852] - Issues with EmbeddedAgentConfiguration\n    * [FLUME-1854] - Application class can deadlock if stopped immediately after start\n    * [FLUME-1863] - EmbeddedAgent pom must pull in file channel\n    * [FLUME-1865] - Rename the Sequence File formatters to Serializer to be consistent with the rest of Flume\n    * [FLUME-1866] - ChannelProcessor is not logging ChannelExceptions.\n    * [FLUME-1867] - There's no option to set hostname for HTTPSource\n    * [FLUME-1868] - FlumeUserGuide mentions wrong FQCN for JSONHandler\n    * [FLUME-1869] - Request to add \"HTTP\" source type to SourceType.java\n    * [FLUME-1870] - Flume sends non-numeric values with type as float to Ganglia causing ganglia to crash\n    * [FLUME-1872] - SpoolingDirectorySource doesn't delete tracker file when deletePolicy is \"immediate\"\n    * [FLUME-1879] - Secure HBase documentation\n    * [FLUME-1880] - Double-logging of created HDFS files\n    * [FLUME-1882] - Allow case-insensitive deserializer value for SpoolDirectorySource\n    * [FLUME-1890] - Flume should set the hbase keytab and principal in HBase conf object.\n    * [FLUME-1891] - Fast replay runs even when checkpoint exists.\n    * [FLUME-1893] - File Channel could miss possible checkpoint corruption\n    * [FLUME-1911] - Add deprecation back to the legacy thrift code\n    * [FLUME-1916] - HDFS sink should poll for # of active replicas. If less than required, roll the file.\n    * [FLUME-1918] - File Channel cannot handle capacity of more than 500 Million events\n    * [FLUME-1922] - HDFS Sink should optionally insert the timestamp at the sink\n    * [FLUME-1924] - Bug in serializer context parsing in RollingFileSink\n    * [FLUME-1925] - HDFS timeouts should not starve other threads\n    * [FLUME-1929] - CheckpointRebuilder main method does not work\n    * [FLUME-1930] - Inflights should clean up executors on close.\n    * [FLUME-1931] - HDFS Sink has a commons-lang dependency which is missing in pom\n    * [FLUME-1932] - no-reload-conf command line param does not work\n    * [FLUME-1937] - Issue with maxUnderReplication in HDFS sink\n    * [FLUME-1939] - FlumeEventQueue must check if file is open before setting the length of the file\n    * [FLUME-1943] - ExecSource tests failing on Jenkins\n    * [FLUME-1948] - plugins.d directory(ies) should be separately overridable, independent of FLUME_HOME\n    * [FLUME-1949] - Documentation for sink processor lists incorrect default\n    * [FLUME-1955] - fileSuffix does not work with compressed streams\n    * [FLUME-1958] - Remove attlasian-ide-plugin.xml from the repo\n    * [FLUME-1964] - hdfs sink depends on commons-io but does not specify it in the pom\n    * [FLUME-1965] - Thrift sink alias doesn't exist\n    * [FLUME-1969] - Update user Guide to explain the purpose of minimumRequiredSpace setting for FileChannel\n    * [FLUME-1974] - Thrift compatibility issue with hbase-0.92\n    * [FLUME-1975] - Use TThreadedSelectServer in ThriftSource if it is available\n    * [FLUME-1980] - Log4jAppender should optionally drop events if append fails\n    * [FLUME-1981] - Rpc client expiration can be done in a more thread-safe way\n    * [FLUME-1986] - doTestInflightCorrupts should not commit transactions\n    * [FLUME-1993] - On Windows, when using the spooling directory source, there is a file sharing violation when trying to delete tracker file\n    * [FLUME-2002] - Flume RPC Client creates 2 threads per each log attempt if the remote flume agent goes down\n    * [FLUME-2011] - \"mvn test\" fails\n    * [FLUME-2012] - Two tests fail on Mac OS (saying they fail to load native library) with Java 7\n    * [FLUME-2014] - Race condition when using local timestamp with BucketPath\n    * [FLUME-2023] - Flume must login to secure HBase before creating the HTable instance\n    * [FLUME-2025] - ThriftSource throws NPE in stop() if start() failed because socket open failed or if thrift server instance creation threw.\n    * [FLUME-2026] - TestHTTPSource should use any available port rather than a hardcoded port number\n    * [FLUME-2027] - Check for default replication fails on federated cluster in hdfs sink\n    * [FLUME-2032] - HDFSEventSink doesn't work in Windows\n    * [FLUME-2036] - Make hostname optional for HTTPSource\n    * [FLUME-2042] - log4jappender timeout should be configurable\n    * [FLUME-2043] - JMS Source removed on failure to create configuration\n    * [FLUME-2044] - HDFS Sink impersonation fails after the first file\n    * [FLUME-2051] - Surefire 2.12 cannot run a single test on Windows. Upgrade to 2.12.3\n    * [FLUME-2054] - Support Version Info  on Windows  and fix failure of TestVersionInfo\n    * [FLUME-2057] - Failures in  FileChannel's TestEventQueueBackingStoreFactory  on Windows\n    * [FLUME-2060] - Failure in TestLog.testReplaySucceedsWithUnusedEmptyLogMetaDataFastReplay test on Windows\n    * [FLUME-2072] - JMX metrics support for HBase Sink\n    * [FLUME-2081] - JMX metrics support for SpoolDir\n    * [FLUME-2082] - JMX support for Seq Generator Source\n    * [FLUME-2083] - Avro Source should not start if SSL is enabled and keystore cannot be opened\n    * [FLUME-2098] - Make Solr sink depend on the CDK version of morphlines\n\n** Documentation\n    * [FLUME-1621] - Document new MemoryChannel parameters in Flume User Guide\n    * [FLUME-1910] - Add thrift RPC documentation\n    * [FLUME-1953] - Fix dev guide error that says sink can read from multiple channels\n    * [FLUME-1962] - Document proper specification of lzo codec as lzop in Flume User Guide\n    * [FLUME-1979] - Wrong propname for connection reset interval in avro sink\n    * [FLUME-2030] - Documentation of Configuration Changes JMSSource, HBaseSink, AsyncHBaseSink and ElasticSearchSink\n\n** Task\n    * [FLUME-1686] - Exclude target directories & Eclipse files from rat checks\n    * [FLUME-2094] - Remove the deprecated - Recoverable Memory Channel\n\n** Sub-task\n    * [FLUME-1626] - Support Hbase security in Hbase sink\n    * [FLUME-1630] - Flume configuration code could be improved\n    * [FLUME-1674] - Documentation / Wiki\n    * [FLUME-1896] - Implement Thrift RpcClient\n    * [FLUME-1897] - Implement Thrift Sink\n    * [FLUME-1898] - Implement Thrift Source\n    * [FLUME-2102] - Update LICENSE file for Flume 1.4.0\n\n----\n\nRelease Notes - Flume - Version v1.3.0\n\n** New Feature\n    * [FLUME-1199] - Add HTTP Post Source\n    * [FLUME-1371] - ElasticSearch Sink\n    * [FLUME-1382] - Flume adopt message from existing local Scribe\n    * [FLUME-1385] - Add a multiport syslog source\n    * [FLUME-1424] - File Channel should support encryption\n    * [FLUME-1425] - Create a SpoolDirectory Source and Client\n    * [FLUME-1488] - Load Balancing RPC client should support exponential backoff of failed nodes\n    * [FLUME-1537] - Dump RollingFileSink's counter status when agent stops\n    * [FLUME-1657] - Regex Extractor Interceptor\n\n** Improvement\n    * [FLUME-946] - Allow multiplexing channel selector to specify optional channels.\n    * [FLUME-1337] - Add IDEA files to .gitignore\n    * [FLUME-1358] - Add a regex-based filtering interceptor\n    * [FLUME-1383] - Improve various log messages in FileChannel and HDFSSink\n    * [FLUME-1408] - ScheduledExecutorService does not log uncaught Throwables, we should log them\n    * [FLUME-1418] - Improvement for Log4j configuration\n    * [FLUME-1419] - Using system time if 'timestamp' property is absent in event header\n    * [FLUME-1434] - Distinguish background worker with channel name\n    * [FLUME-1480] - Replace object descriptor with detailed component type plus name\n    * [FLUME-1487] - FileChannel format needs to be extensible\n    * [FLUME-1490] - Option to limit number of events sent in Stress source\n    * [FLUME-1496] - TestFileChannel is bloated\n    * [FLUME-1507] - Have \"Topology Design Considerations\" in User Guide\n    * [FLUME-1509] - Flume HDFS sink should allow for the use of different timezones when resolving sink paths\n    * [FLUME-1519] - LifecycleController prints tons of DEBUG messages\n    * [FLUME-1523] - Allow -X java opts to be passed to the agent on the command line\n    * [FLUME-1526] - LogFile log message is scary when no harm has been done\n    * [FLUME-1531] - Flume User Guide should provide more details on configuring the timestamp interceptor\n    * [FLUME-1535] - Ability to specify the capacity of MemoryChannel in bytes\n    * [FLUME-1536] - Support for batch size in StressSource\n    * [FLUME-1538] - Channels should expose channel fill ratio through JMX\n    * [FLUME-1543] - TestFileChannel should be factored into many tests\n    * [FLUME-1546] - File channel encryption: trim() passwords and warn user if he doesn't have JCE policy file\n    * [FLUME-1548] - Build dies due to older protocol buffers compiler\n    * [FLUME-1550] - Use maven-antrun-plugin to save version\n    * [FLUME-1554] - FileChannel fails to build on machines with old protocol buffer compiler\n    * [FLUME-1556] - It would be nice if NullSink logged the number of event processed every 10K or so\n    * [FLUME-1560] - TestFileChannel* tests which fill up the channel should use larger batch size than 1\n    * [FLUME-1563] - FileChannel Encryption KeyProvider configuration properties should be more consistent\n    * [FLUME-1564] - FileChannel log file creation could be clarified and tested\n    * [FLUME-1569] - MemoryChannel uses an Integer as a lock\n    * [FLUME-1575] - FIleChannel Encryption should disallow a null key\n    * [FLUME-1603] - FileChannel capacity reached message is unclear\n    * [FLUME-1607] - FileChannel We should use a regex as opposed to simple filename filter when finding logs\n    * [FLUME-1609] - FileChannel detecting when the underlying file systems are full could provide cleaner error recovery\n    * [FLUME-1631] - Retire hdfs.txnEventMax in HDFS sink\n    * [FLUME-1645] - add hdfs.fileSuffix property to HDFSEventSink\n    * [FLUME-1660] - Close \"idle\" hdfs handles\n    * [FLUME-1675] - Ignore netbeans config files in rat & git\n    * [FLUME-1681] - Disable empty-file unit test for Spooling File Reader\n    * [FLUME-1684] - Re-enable empty file unit test\n    * [FLUME-1689] - BodyTextSerializer should allow an option not to add a newline to each serialized event\n    * [FLUME-1692] - MultiportSyslogTCPSource user documentation and nickname\n    * [FLUME-1707] - Update FlumeDevGuide\n    * [FLUME-1706] - Website for 1.3 fails to build\n    * [FLUME-1698] - Update RELEASE-NOTES\n    * [FLUME-1711] - Update Flume User Guide\n    * [FLUME-1713] - Netcat source should allow for *not* returning \"OK\" upon receipt of each message.\n    * [FLUME-1740] - Remove contrib/ directory from Flume NG\n    * [FLUME-1750] - File spooling client uses -D as command line option\n    * [FLUME-1751] - User Guide Examples for File Channel encryption are broken in 1.3 rc5\n    * [FLUME-1749] - .gitignore and elipse related files should not be included in source tarball\n    * [FLUME-1752] - Update CHANGELOG for flume 1.3.0 rc6 to include latest changes\n\n\n** Bug\n    * [FLUME-1208] - Hbase sink should be built only in Hadoop-1.0  profile\n    * [FLUME-1256] - OutofMemory erros in Flume build\n    * [FLUME-1259] - Flume throws OutOfMemory error when sending data from netcat to avro source (negative test case)\n    * [FLUME-1276] - Create a static header interceptor\n    * [FLUME-1277] - Error parsing Syslog rfc 3164 messages with null values\n    * [FLUME-1310] - Make Asynch hbase sink test work with other versions of Hbase\n    * [FLUME-1354] - Update docs to show that recoverable memory channel is deprecated\n    * [FLUME-1362] - Port retrying in TestThriftLegacySource not working\n    * [FLUME-1363] - flume-ng-node - TestNetcatSource doesn't try multiple ports\n    * [FLUME-1364] - Document the necessity of the timestamp header when using time-related escapes for hdfs sink paths\n    * [FLUME-1373] - Remove hardcoded file separator in HDFSEventSink\n    * [FLUME-1374] - Support ganglia reporting\n    * [FLUME-1376] - StaticInterceptor doc update\n    * [FLUME-1377] - ChannelProcessor clobbers exception with NPE if Channel.getTransaction() throws\n    * [FLUME-1389] - Flume gives opaque error if interceptor type not specified\n    * [FLUME-1391] - Use sync() instead of syncFs() in HDFS Sink to be compatible with hadoop 0.20.2\n    * [FLUME-1392] - Inactive channels get added to source channels list causing NPE\n    * [FLUME-1398] - Improve concurrency for async hbase sink\n    * [FLUME-1412] - Commons collections is used in file channel - even though it is not in pom.xml\n    * [FLUME-1414] - VersionInfo should not create a log instance\n    * [FLUME-1416] - Version Info should have hardcoded git repo address\n    * [FLUME-1417] - File Channel checkpoint can be bad leading to the channel being unable to start.\n    * [FLUME-1420] - Exception should be thrown if we cannot instaniate an EventSerializer\n    * [FLUME-1421] - PollableSourceRunner does not name it's thread\n    * [FLUME-1422] - Fix \"BarSource\" Class Signature in Flume Developer Guide\n    * [FLUME-1426] - FileChannel Replay could be faster\n    * [FLUME-1428] - File Channel should not consider a file as inactive until all takes are committed.\n    * [FLUME-1432] - FileChannel should replay logs in the order they were written\n    * [FLUME-1437] - Checkpoint can miss pending takes.\n    * [FLUME-1470] - Syslog source does not parse facility correctly\n    * [FLUME-1479] - Multiple Sinks can connect to single Channel\n    * [FLUME-1482] - Flume should support exposing metrics via HTTP in JSON/some other web service format.\n    * [FLUME-1498] - File channel - Log updates and queue updates should be atomic\n    * [FLUME-1500] - Upgrade flume to use latest version of Avro - v1.7\n    * [FLUME-1504] - Test file channel times out randomly\n    * [FLUME-1506] - Child poms pull in specific versions of packages not in top level pom\n    * [FLUME-1512] - File Channel should not stop during a checkpoint.\n    * [FLUME-1513] - File Channel log close() method should not be synchronized\n    * [FLUME-1514] - Log4jAppender should also have flume-ng-configuration in the pom\n    * [FLUME-1515] - Fix flume-1.3.0 branch test failures on ASF Jenkins.\n    * [FLUME-1524] - TestMonitoredCounterGroup is flaky\n    * [FLUME-1525] - On some (slow) machines TestFileChannel can fail\n    * [FLUME-1534] - CheckpointRebuilder$ComparableFlumeEventPointer#equals does not work correctly.\n    * [FLUME-1540] - CheckpointBuilder needs to open logfiles in inactive mode\n    * [FLUME-1541] - Implement a SinkSelector for LoadBalancingSinkProcessor that includes failover mechanics\n    * [FLUME-1544] - Update dev guide to reflect the protoc requirement\n    * [FLUME-1545] - File channel missing implicit dependency on commons-lang\n    * [FLUME-1552] - TestFileChannelEncryption fails without a high encryption policy file\n    * [FLUME-1553] - TestFileChannelEncryption should be refactored to use TestFileChannelBase\n    * [FLUME-1555] - StressSource outputs bad log messages that reference (Sequence generator)\n    * [FLUME-1557] - It would be nice if SequenceGeneratorSource could do batching\n    * [FLUME-1562] - TestLoadBalancingSinkProcessor.testRoundRobinBackoffFailureRecovery is flaky, fails every once in a while...\n    * [FLUME-1565] - FileChannel Decryption in RandomReader is not thread safe\n    * [FLUME-1567] - Avro source should expose the number of active connections through JMX\n    * [FLUME-1570] - StressSource batching does not work unless maxTotalEvents is specified\n    * [FLUME-1572] - Add batching to FILE_ROLL sink\n    * [FLUME-1576] - CHECKPOINT_INCOMPLETE should be synced to disk before starting the checkpoint.\n    * [FLUME-1577] - CHECKPOINT_INCOMPLETE should be synced to disk before starting the checkpoint.\n    * [FLUME-1578] - Proposal to modify file channel encryption config\n    * [FLUME-1582] - flume-ng script should set LD_LIBRARY_PATH\n    * [FLUME-1583] - FileChannel fast full replay will always be used if enabled\n    * [FLUME-1595] - HDFS SequenceFile implementation is not durable due to not using syncFs()\n    * [FLUME-1606] - Rollbacks of Put transactions does not clear the transaction from inflight puts.\n    * [FLUME-1610] - HDFSEventSink and bucket writer have a race condition\n    * [FLUME-1611] - LogUtils regex can be precompiled\n    * [FLUME-1613] - All of the sink examples in the user guide are broken\n    * [FLUME-1616] - FileChannel will lose data in when rollback fails with IOException\n    * [FLUME-1620] - Update flume user guide for LoadBalancingSinkProcessor with the backoff changes.\n    * [FLUME-1622] - MemoryChannel throws NPE if the event has no body\n    * [FLUME-1638] - LoadBalancingRpcClient depends on com.google.common.collect.Maps\n    * [FLUME-1639] - Client SDK should not have dependency on Guava\n    * [FLUME-1650] - Fix flume-ng-hbase-sink compilation against Hadoop 2.X\n    * [FLUME-1651] - in the hadoop-0.23 profile HBase version needs to be at least 0.94.2\n    * [FLUME-1653] - Update Hadoop-23 profile to point to hadoop-2 alpha artifacts\n    * [FLUME-1655] - Doc update needed for Regex Filtering Interceptor\n    * [FLUME-1656] - flume-ng script disregards stderr  from hadoop command when finding hadoop jars\n    * [FLUME-1659] - JSON Handler should return simple events, not JSONEvents.\n    * [FLUME-1662] - Convert null body in events into zero length arrays.\n    * [FLUME-1664] - Logutils.getLogs remove unneeded directory check\n    * [FLUME-1671] - Add support for custom components to MonitoredCounterGroup\n    * [FLUME-1673] - MonitoredCounterGroup publishes this reference to platform MBean server in constructor\n    * [FLUME-1683] - Fix Time Granularity Bug in SpoolingFileLineReader\n    * [FLUME-1690] - Elastic Search Sink doesn't run it's unit tests\n    * [FLUME-1712] - Regex Extractor Interceptor tests have timezone issues\n    * [FLUME-1705] - SpoolDirectory short name points at the wrong class\n    * [FLUME-1719] - Example export command in README do not properly close the string\n    * [FLUME-1723] - AsyncHBase and Avro bring in different versions of Netty\n    * [FLUME-1726] - SpoolingFileLineReader must close the reader before renaming\n    * [FLUME-1743] - Multiport syslog tcp source does not load (v1.3 rc5)\n\n\n** Test\n    * [FLUME-1492] - Create integration test for file channel\n\n** Task\n    * [FLUME-1359] - Update main pom.xml file with regards to Flume TLP promotion\n\n** Sub-task\n    * [FLUME-897] - Implement write ahead log library\n    * [FLUME-1629] - Add Audience/Stability annotations\n    * [FLUME-1694] - Fix LICENSE file for binary artifacts\n    * [FLUME-1695] - Fix tarball names and directories\n    * [FLUME-1696] - Update build instructions as Flume build requires more memory\n    * [FLUME-1697] - Update CHANGELOG after 1.3.0 RC0\n    * [FLUME-1727] - Update CHANGELOG for rc4\n\n----\n\nRelease Notes - Flume - Version v1.2.0\n\n** New Feature\n    * [FLUME-896] - Implement a Durable Memory Channel\n    * [FLUME-971] - Create developer guide for Flume NG\n    * [FLUME-988] - Client SDK\n    * [FLUME-1085] - Implement a durable FileChannel\n    * [FLUME-1157] - Implement Interceptors (previously known as Decorators) for Flume 1.x\n    * [FLUME-1183] - Implement an HBase Sink which supports table level access\n    * [FLUME-1215] - Implement Timestamp Interceptor\n    * [FLUME-1252] - Asynchronous HBase Sink\n\n** Improvement\n    * [FLUME-828] - LoggerSink representation of the event's body isn't too useful\n    * [FLUME-881] - Would be nice if HDFS Sink would automatically choose best writableFormat based on fileType\n    * [FLUME-979] - ExecSource should optionally restart the command when it exits\n    * [FLUME-985] - All HDFS Operations in HDFSEventSink should have a timeout\n    * [FLUME-1001] - Support custom processors\n    * [FLUME-1011] - AvroSource should have a configurable max thread count\n    * [FLUME-1020] - Implement Kerberos security for HDFS Sink\n    * [FLUME-1030] - Retry logic for failover sink processor to handle downstream exceptions in a predictable manner.\n    * [FLUME-1032] - Fix / clean up Flume NG build\n    * [FLUME-1043] - SDK should mark slf4j deps as optional\n    * [FLUME-1048] - speed up mvn package: stop building .zip packages\n    * [FLUME-1049] - Use hadoop-1.0.0 as basis for default Flume build instead of 0.20.205\n    * [FLUME-1078] - flume-ng script has no way to add, not replace, classpath\n    * [FLUME-1090] - JDBC Channel: Minimize logging under nominal conditions\n    * [FLUME-1117] - Support output to files in Avro container format\n    * [FLUME-1122] - Flume documentation layout should be refactored\n    * [FLUME-1126] - Support RFC 3164 and 5424 syslog format timestamp parsing\n    * [FLUME-1127] - Add configuration support to AbstractAvroEventSerializer for Avro sync interval and compression support\n    * [FLUME-1132] - HDFSEventSink has spurious and verbose log message\n    * [FLUME-1140] - Adding Xms value in flume-env.sh\n    * [FLUME-1160] - ComponentConfigurationFactory catches NullPointerException\n    * [FLUME-1196] - Allow different HDFS Sinks within the same agent to write to HDFS as different users\n    * [FLUME-1198] - Implement a load-balancing sink processor\n    * [FLUME-1212] - Flume should pick HBase jars from HBASE_HOME\n    * [FLUME-1238] - Support active rolling of files created by HDFS Event Sink\n    * [FLUME-1242] - Make flume user & dev guides easily editable\n    * [FLUME-1275] - Add Regex Serializer for HBaseSink\n    * [FLUME-1287] - Add Standalone Example to Docs\n    * [FLUME-1330] - Avro Source should not use Fixed thread pool for boss threads when pool size is specified\n    * [FLUME-1338] - Produce helpful error message in case that timestamp header is missing when time based bucketing is in use\n    * [FLUME-1343] - Improve user guide\n    * [FLUME-1345] - Use apache-flume for the artifact instead of flume-ng-dist\n    * [FLUME-1351] - Add release version to Flume documentation\n\n** Bug\n    * [FLUME-862] - AvroSource breaks when config properties changes different service\n    * [FLUME-1002] - FailoverSinkProcessor replaces sinks with same priority\n    * [FLUME-1017] - syslog classes missing\n    * [FLUME-1026] - Document Thread Safety Guarantees\n    * [FLUME-1027] - Missing log4j library in Flume distribution\n    * [FLUME-1031] - Deprecate code generated by Thrift and Avro OG sources that is under com.cloudera package\n    * [FLUME-1035] - slf4j error in flume sdk unit tests\n    * [FLUME-1036] - Reconfiguration of AVRO or NETCAT source causes port bind exception\n    * [FLUME-1037] - NETCAT handler theads terminate under stress test\n    * [FLUME-1040] - Release-Notes says Apache Ivy instead of Apache Flume\n    * [FLUME-1041] - maven warns of duplicate dependencies\n    * [FLUME-1046] - invoking flume-ng script from bin directory fails\n    * [FLUME-1047] - Client SDK has dependency on apache commons\n    * [FLUME-1070] - Fix javadoc for configuring hdfsSink\n    * [FLUME-1074] - AvroSink if any non-caught exception is thrown, an exception is thrown in finally clause\n    * [FLUME-1075] - HDFSEventSink begin is called when transaction opened due to other error\n    * [FLUME-1079] - Flume agent reconfiguration enters permanent bad state\n    * [FLUME-1080] - Issue with HDFSEventSink for append support\n    * [FLUME-1083] - Why does flume binary archive produces the following empty directories: bin/{ia64,amd64} ?\n    * [FLUME-1087] - Restore Client API compat with v1.1.0\n    * [FLUME-1088] - TestWAL.testThreadedAppend fails on jenkins build server\n    * [FLUME-1094] - hadoop.profile=23 build is broken by slf4j-jcl dependencies\n    * [FLUME-1096] - Add support to pass headers through AvroCLIClient\n    * [FLUME-1098] - Hadoop jars from compilation step included in assembly build\n    * [FLUME-1099] - copy-paste issue with RecoverableMemoryChannel\n    * [FLUME-1102] - HDFSEventSink rollInterval is broken\n    * [FLUME-1104] - HDFS rolls the first file incorrectly\n    * [FLUME-1108] - FILE_ROLL sink doesn't accept value 0 for unlimited wait time before rolling file\n    * [FLUME-1109] - Syslog sources need to be refactored\n    * [FLUME-1112] - HDFSCompressedDataStream append does not work\n    * [FLUME-1114] - Syslog Sources does not implement maxsize\n    * [FLUME-1116] - Extra event created for max payload size of 2500 bytes in Flume syslogtcp source\n    * [FLUME-1119] - Remove default ports for syslog sources\n    * [FLUME-1121] - Recoverable Memory Channel cannot recover data\n    * [FLUME-1124] - Lifecycle supervisor can cause thread contention, sometimes causing components to not startup.\n    * [FLUME-1125] - flume-ng script allows flume-env.sh to clobber some command-line arguments\n    * [FLUME-1128] - Conf poller should use schedule with fixed delay\n    * [FLUME-1129] - change foo to agent in sample config\n    * [FLUME-1130] - flume-ng script bad ordering on FLUME_HOME var\n    * [FLUME-1135] - flume-docs exclude is not sufficient for rat\n    * [FLUME-1136] - Remove from executor service does not always remove the runnables from the queue\n    * [FLUME-1142] - Seq source fails with multiplexing channel selector\n    * [FLUME-1148] - Refactor logging\n    * [FLUME-1149] - All sources get same channel list even if configuration is different.\n    * [FLUME-1154] - flume-ng script should first try finding java from PATH and then try using bigtop, instead of vice-versa\n    * [FLUME-1156] - If config file has empty sources, then throws NPE\n    * [FLUME-1163] - HDFSEventSink leaves .tmp files in place when Flume is stopped\n    * [FLUME-1164] - Configure should be called after stopping all events.\n    * [FLUME-1177] - Maven deps on flume-ng-configuration module are brought in transitively instead of directly\n    * [FLUME-1180] - ChannelSelectorFactory creates incorrect selector for multiplexing selector type\n    * [FLUME-1181] - Context must enforce dot-separated prefix for sub-properties.\n    * [FLUME-1182] - Syslog source cannot read format correctly from configuration\n    * [FLUME-1184] - TestFileChannel.testThreaded fails sometimes\n    * [FLUME-1188] - TestRecoverableMemoryChannel.testThreaded can fail sometimes\n    * [FLUME-1190] - DurableFileChannel requires FILE enum definition in ChannelConfigurationType\n    * [FLUME-1194] - RecoverableMemoryChannel prop misspelled -- \"rentention\" should be \"retention\"\n    * [FLUME-1200] - HDFSEventSink causes *.snappy file to be created in HDFS even when snappy isn't used (due to missing lib)\n    * [FLUME-1202] - Too many approved licenses\n    * [FLUME-1204] - Add more unit tests for hbase sink\n    * [FLUME-1205] - NPE related to checkpointing when using FileChannel\n    * [FLUME-1213] - HDFS sink should allow bucketpath rounding down.\n    * [FLUME-1216] - Need useful error message when keytab does not exist\n    * [FLUME-1217] - HDFS Event Sink generates warnings due to recent change\n    * [FLUME-1219] - Race conditions in BucketWriter / HDFSEventSink\n    * [FLUME-1220] - Load balancing channel selector needs to be in the configuration type\n    * [FLUME-1221] - ThriftLegacySource doesn't handle fields -> headers conversions for bytebuffers\n    * [FLUME-1226] - FailoverRpcClient should check for NULL batch-size property\n    * [FLUME-1229] - System.nanoTime incorrectly used in filename for HDFS file rolling\n    * [FLUME-1230] - Sink gets initialized even when not active\n    * [FLUME-1231] - Deadlock between BucketWriter and LeaseChecker on shutdown\n    * [FLUME-1232] - Cannot start agent a 3rd time when using FileChannel\n    * [FLUME-1234] - Can't use %P escape sequence for bucket path of HDFS sink\n    * [FLUME-1236] - File channel has a race condition between start and create transaction method\n    * [FLUME-1240] - Add version info to Flume NG\n    * [FLUME-1241] - Flume dist should include the flume-ng-doc directory\n    * [FLUME-1244] - Implement a load-balancing RpcClient with round/robin and random distribution capabilties.\n    * [FLUME-1245] - HDFSCompressedDataStream calls finish() on sync instead of flush()\n    * [FLUME-1246] - FileChannel hangs silently when Hadoop libs not found\n    * [FLUME-1248] - flume-ng script gets broken when it tried to load hbase classpath\n    * [FLUME-1253] - Support for running integration tests\n    * [FLUME-1254] - RpcClient can hang when communication is broken with the source.\n    * [FLUME-1270] - Incorrect default hdfs.callTimeout and hdfs.fileType of  HDFSEventSink in FlumeUserGuide.rst\n    * [FLUME-1271] - Incorrect configuration causes NPE\n    * [FLUME-1280] - Make all config properties of Hbase sinks public constants\n    * [FLUME-1284] - Need host interceptor for hdfs bucket path escape sequence\n    * [FLUME-1288] - Async hbase sink should throw exception when hbase reports failure and check hbase table correctness\n    * [FLUME-1290] - HDFS Sink should accept fileType parameters of arbitrary case\n    * [FLUME-1297] - Flume tests should wait for a few seconds for agent to start.\n    * [FLUME-1301] - HDFSCompressedDataStream can lose data\n    * [FLUME-1303] - java.library.path value is being truncated at first 'n' char\n    * [FLUME-1304] - Allow for faster allocation of checkpoint file.\n    * [FLUME-1306] - LoadBalancingRpcClient should catch exception for invalid RpcClient and failover to valid one\n    * [FLUME-1309] - Integration tests not included in assembly build artifacts\n    * [FLUME-1312] - Host interceptor should support custom headers\n    * [FLUME-1314] - File channel log file can grow beyond max size which causes startup failure\n    * [FLUME-1315] - Null sink should support batching\n    * [FLUME-1316] - AvroSink should be configurable for connect-timeout and request-timeout\n    * [FLUME-1317] - Assembly build pulls in target folder from flume-ng-tests\n    * [FLUME-1319] - File Channel optimize replay of logs when a checkpoint is present\n    * [FLUME-1320] - Add safeguard for checkpoint corruption detection\n    * [FLUME-1322] - ChannelProcessor should catch Throwable to work around close() clobbering uncaught Exceptions\n    * [FLUME-1323] - Remove shutdown hook from FileChannel\n    * [FLUME-1324] - File Channel Log can contain unassigned blocks\n    * [FLUME-1325] - Components should be stopped in the reverse order that they were started\n    * [FLUME-1327] - File Channel can deadlock in when checkpoint happens in between a put/take/commit\n    * [FLUME-1329] - AvroSink can hang during Avro RPC handshake\n    * [FLUME-1331] - Start method of components throwing NoClassDefFoundError are not caught\n    * [FLUME-1333] - Disable running of saveVersion.sh on Windows\n    * [FLUME-1341] - Build fails on jenkins because a file exists in the environment\n    * [FLUME-1344] - AvroSink JMX does not report connection created count accurately\n    * [FLUME-1346] - Build warning from missing maven-sphinx version in reporting section\n    * [FLUME-1347] - Deprecate RecoverableMemoryChannel\n    * [FLUME-1348] - Update the documentation, correcting links and removing incubation.\n    * [FLUME-1349] - Document Hbase sinks.\n    * [FLUME-1352] - Add documentation for HDFS path rounddown.\n    * [FLUME-1355] - Improve user guide section about sink processors\n    * [FLUME-1356] - Document interceptors\n\n** Task\n    * [FLUME-840] - Update project committers in pom file\n    * [FLUME-991] - Make flume configuration validation component specific at time rather than at runtime\n    * [FLUME-1028] - Fix jenkins build after addition of submodule\n    * [FLUME-1050] - Update version of surefire plugin\n    * [FLUME-1073] - Default Log4j configuration file should have a rolling policy\n    * [FLUME-1082] - Add User and dev guide to Flume site\n    * [FLUME-1151] - Exclude docs directory from rat\n    * [FLUME-1189] - Test ReoverableMemoryChannel throughput versus FileChannel\n    * [FLUME-1300] - Update user guide for File Channel\n    * [FLUME-1353] - Ensure license headers are consistent\n\n** Sub-task\n    * [FLUME-748] - Create metric collection infrastructure\n    * [FLUME-962] - Failover capability for Client SDK\n    * [FLUME-992] - Create configuration stubs for sources, channels, sinks etc\n    * [FLUME-999] - Updating init scripts and variables to fit the term agent\n    * [FLUME-1052] - Core configuration component\n    * [FLUME-1053] - Basic SourceConfiguration\n    * [FLUME-1054] - Basic ChannelConfiguration\n    * [FLUME-1055] - Basic SinkConfiguration\n    * [FLUME-1105] - Allow the optional disabling of foreign keys\n    * [FLUME-1107] - Configuration keys for JDBC channel contain redundant prefix.\n    * [FLUME-1113] - JDBC Channel invokes size query on every put\n\n----\n\nRelease Notes - Flume - Version v1.1.0\n\n** Sub-task\n    * [FLUME-989] - Factor Flume Avro RPC interfaces out into separate Client SDK\n\n** Bug\n    * [FLUME-11] - Tests are setting logger level and should not be.\n    * [FLUME-889] - All events in memory channel are lost on reconfiguration\n    * [FLUME-920] - flume-ng script does not work on Ubuntu Maverick\n    * [FLUME-933] - Default[Source|Sink|Channel]Factory implementation should do reference counting for create/unregistering instances.\n    * [FLUME-936] - MemoryChannel is not thread safe\n    * [FLUME-955] - Rat failure: Legacy Avro Source missing Apache license header\n    * [FLUME-957] - Remove unused flume json config file\n    * [FLUME-960] - TestAvroSink.testFailedConnect is racy and fails often\n    * [FLUME-963] - Add additional tests to TestHDFSEventSink and demystify existing tests\n    * [FLUME-972] - Missing dep when attempting to prepare flume dir for import into Eclipse\n    * [FLUME-987] - LoggerSink prints garbage for body\n    * [FLUME-1003] - The memory channel does not seem to respect the capacity\n    * [FLUME-1005] - Several issues with flume-ng script\n    * [FLUME-1009] - HDFSEventSink should return BACKOFF when the channel returns null\n    * [FLUME-1018] - Context can cause NullPointerException\n\n** Improvement\n    * [FLUME-886] - Create Log4j Appender\n    * [FLUME-919] - flume-ng script should use exec when spawning the java process\n    * [FLUME-922] - Straighten up branches for development\n    * [FLUME-925] - Update build infrastructure to follow Apache Maven guidelines\n    * [FLUME-931] - Flume NG TailSource\n    * [FLUME-932] - Making flume-ng components pluggage and name aware\n    * [FLUME-935] - Create abstract implementations of basic channel/transaction semantics\n    * [FLUME-939] - Load flume-env.sh from flume_conf_dir environment variable / system property as opposed to bin directory\n    * [FLUME-945] - Add the ability to specify a default channel for multiplexing channel selector.\n    * [FLUME-956] - Configuration File Template\n    * [FLUME-958] - Miscellaneous build improvements\n    * [FLUME-964] - Remove compiler warnings where possible\n    * [FLUME-978] - Context interface is too basic requiring boilerplate user code\n    * [FLUME-984] - SinkRunner should catch unhanded exceptions and log them like PollingSourceRunner\n    * [FLUME-990] - Hive sink\n    * [FLUME-1019] - Document Sink and related interfaces, defining expected behaviors\n    * [FLUME-1021] - Document API contracts and expected behavior in additional interfaces, including Source\n\n** New Feature\n    * [FLUME-865] - Implement failover sink\n    * [FLUME-892] - Support for SysLog as source\n    * [FLUME-914] - Port the IRC sink to flume ng\n    * [FLUME-930] - Support for multiplexing into different channels from single source.\n    * [FLUME-942] - Support event compatibility with Flume 0.9x\n    * [FLUME-970] - Create user guide for Flume NG\n    * [FLUME-1015] - S3 sink on flumeNG\n\n** Task\n    * [FLUME-940] - Remove unused code from Flume\n    * [FLUME-949] - Collapse PollableSink into Sink interface.\n    * [FLUME-977] - Migrate trunk to 0.9.5 branch and move branch flume-728 over to trunk\n\n----\n\nRelease Notes - Flume - Version v1.0.0 - 20111230\n\n** Bug\n    * [FLUME-830] - flume uber jar is missing files from flume-file-channel project\n    * [FLUME-831] - flume-jdbc-channel project has unnecessary direct dependency on log4j API\n    * [FLUME-833] - Audit Direct Library Deps for Flume NG\n    * [FLUME-835] - Issues during clean build of Flume NG\n    * [FLUME-850] - Upgrade the version of Hadoop we use for HDFS sink\n    * [FLUME-858] - HDFSWriterFactory is using operation == for string comparison\n    * [FLUME-863] - Use of unknown sink type leads to NullPointerException\n    * [FLUME-868] - RAT checks fail on builds.apache.org due to local maven repo\n    * [FLUME-869] - JDBC channel tests leave derby.log in module directory\n    * [FLUME-870] - LoggerSink contains two calls to Transaction#commit()\n    * [FLUME-880] - HDFSFormatterFactory is using == operator for String objects\n    * [FLUME-887] - Add maven assembly to build a source only artifact\n    * [FLUME-891] - flume-ng script doesn't build the classpath properly\n    * [FLUME-894] - Add log4j as part of the build\n    * [FLUME-898] - Create DISCLAIMER file for Flume project\n    * [FLUME-900] - RELEASENOTES file needs to be ignored by RAT\n    * [FLUME-902] - Remove thrift references in NG build\n    * [FLUME-903] - Update project metadata in main pom\n    * [FLUME-904] - Update plugin and dependency repos referenced in the main pom\n    * [FLUME-905] - ExecSource silently fails after first transaction with channel\n    * [FLUME-906] - Maven Avro plugin missing an entry in plugin dep management\n    * [FLUME-907] - Maven assembly missing CHANGELOG and other misc files\n    * [FLUME-908] - Clean out old bin and conf contents\n    * [FLUME-909] -  org.apache.flume.node.TestAbstractLogicalNodeManager is failing on some machines\n    * [FLUME-910] - Typo in maven avro plugin groupId in plugin dep management\n    * [FLUME-911] - README should reference Apache Flume rather than just Flume\n    * [FLUME-912] - DEVNOTES contains outdated info\n    * [FLUME-913] - slf4j-log4j binding is excluded from the dist assembly due to test scope\n    * [FLUME-915] - Incorrect license information in various files\n    * [FLUME-916] - DISCLAIMER file has an incorrect URL\n\n** Improvement\n    * [FLUME-846] - Bump Avro version to 1.6.x\n    * [FLUME-867] - Pollable source and sink runners should reduce poll interval after several BACKOFFs\n    * [FLUME-871] - HDFS sink needs to handle blocked/hung append operation\n\n** Question\n    * [FLUME-856] - Move data across hosts\n\n** Task\n    * [FLUME-876] - Update README, NOTICE, LICENSE, and DEVNOTES files\n    * [FLUME-878] - Write release-ready Maven assembly descriptor\n    * [FLUME-879] - Document Flume's ASF release process\n    * [FLUME-885] - Set version number of project to 1.0.0-SNAPSHOT for NG branch\n    * [FLUME-899] - Add Release notes\n    * [FLUME-901] - Make Flume NG build and pass tests against Hadoop 0.23 branch\n\nRelease Notes - Flume - Version NG alpha 2 - 20111107\n\n** Bug\n    * [FLUME-773] - ExecSource doesn't rollback transactions on errors\n    * [FLUME-805] - HDFS sink should mangle the names of incomplete files till they are closed\n    * [FLUME-815] - Test json config file has missing bind property\n    * [FLUME-816] - TestJdbcChannelProvider throws OOME based on RNG values\n    * [FLUME-817] - JdbcChannel can not be created by DefaultChannelFactory\n    * [FLUME-818] - PropertiesFileConfigurationProvider doesn't properly log exceptions\n    * [FLUME-822] - JDBC channel lock acquisition failure during take()\n    * [FLUME-823] - The properties configuration provider should fail if the configuration file is not found\n    * [FLUME-825] - Need to remove dependency on hadoop core from flume-ng-core project\n    * [FLUME-827] - Avro client conn failure results in 60-second wait before terminating\n    * [FLUME-848] - Typo is TestHDFSEventSink path\n    * [FLUME-861] - AvroSource is failing on ClosedChannelException\n\n** Improvement\n    * [FLUME-819] - JDBC channel plugin is not registered with Flume node\n    * [FLUME-820] - JDBC channel should support capacity specification.\n    * [FLUME-821] - Derby schema handler should create the necessary indexes for fast lookups.\n    * [FLUME-826] - Update libs\n\n** New Feature\n    * [FLUME-775] - Support text output\n    * [FLUME-814] - Add support for multiple channels to sources\n\n** Task\n    * [FLUME-812] - Enable Apache RAT checks during Maven build\n    * [FLUME-866] - Remove old plugins and log4j appender\n\nRelease Notes - Flume - Version NG alpha 1 - 20111021\n\n** Sub-task\n    * [FLUME-737] - Port Flume OG sources and sinks to NG interfaces\n    * [FLUME-739] - Create NG node configuration components\n    * [FLUME-747] - Create NG command line launchers and daemon infrastructure\n    * [FLUME-760] - Implement JDBC based channel implementation\n    * [FLUME-761] - Implement HDFS Flume NG sink\n    * [FLUME-777] - Support text output for HDFS sink\n    * [FLUME-795] - Replace the non-transactional memory channel with new transactional memory channel\n\n** Bug\n    * [FLUME-769] - FLUME-728 - TestJsonFileConfigurationProvider fails due to timing issue\n    * [FLUME-784] - MemoryChannel should poll with timeout on take() rather than block indefinitely\n    * [FLUME-788] - Add more test cases to Flume-NG HDFS test\n    * [FLUME-803] - support re-entrant transaction for memory channel\n    * [FLUME-806] - Fix cast exception in MemoryChannel due to config type changes\n    * [FLUME-807] - Fix tests broken by FLUME-802 changes\n    * [FLUME-809] - Fix channel syntax javadoc bug in PropertiesFileConfigurationProvider\n    * [FLUME-811] - Remove logging of avro client that causes errors with proxy object methods\n\n** Epic\n    * [FLUME-728] - Flume NG refactoring\n\n** Improvement\n    * [FLUME-772] - MemoryChannel should push events back into channel on rollback\n    * [FLUME-774] - Move HDFS sink into a separate module\n    * [FLUME-781] - Add error checking to AvroCLICilent\n    * [FLUME-782] - Instrument AvroSource with counters\n    * [FLUME-783] - Add a batch event RPC call to AvroSource\n    * [FLUME-804] - Support help and node name arguments from the command line\n    * [FLUME-810] - Add help command line options to AvroCLIClient\n\n** New Feature\n    * [FLUME-771] - Implement NG Avro source\n    * [FLUME-778] - Implement NG Avro sink\n    * [FLUME-779] - Create an Avro CLI for sending data to the Avro source\n\n** Task\n    * [FLUME-780] - Reduce default log levels for chatty libraries\n    * [FLUME-785] - Write javadoc for builtin channels\n    * [FLUME-786] - Write javadoc for builtin sources\n    * [FLUME-787] - Write javadoc for builtin sinks\n    * [FLUME-801] - Write NG getting started guide\n    * [FLUME-802] - Complete PropertyFileConfigurationProvider implementation\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 14.763671875,
          "content": "<!---\nLicensed to the Apache Software Foundation (ASF) under one\nor more contributor license agreements.  See the NOTICE file\ndistributed with this work for additional information\nregarding copyright ownership.  The ASF licenses this file\nto you under the Apache License, Version 2.0 (the\n\"License\"); you may not use this file except in compliance\nwith the License.  You may obtain a copy of the License at\n http://www.apache.org/licenses/LICENSE-2.0\nUnless required by applicable law or agreed to in writing,\nsoftware distributed under the License is distributed on an\n\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\nKIND, either express or implied.  See the License for the\nspecific language governing permissions and limitations\nunder the License.\n-->\nApache Flume: How to Contribute\n===============================\n\nWelcome contributors! We strive to include everyone's contributions.\nThis page provides necessary guidelines on how to contribute effectively\ntowards furthering the development and evolution of Flume. You should\nalso read the guide on setting up Development Environment where you will find\ndetails on how to checkout, build and test Flume.\n\n**Note**: This guide applies to general contributors. If you are a\ncommitter, please read the How to Commit guide as well.\n\n\nWhat can be contributed?\n------------------------\n\nThere are many ways you can contribute towards the project. A few of\nthese are:\n\n**Jump in on discussions**: It is possible that someone initiates a\nthread on the mailing list describing a problem that you have dealt with\nin the past. You can help the project by chiming in on that thread and\nguiding that user to overcome or workaround that problem or limitation.\n\n**File Bugs**: If you notice a problem and are sure it is a bug, then go\nahead and [file a JIRA](https://issues.apache.org/jira/browse/Flume). If\nhowever, you are not very sure that it is a bug, you should first\nconfirm it by discussing it on the [Mailing\nLists](https://cwiki.apache.org/confluence/display/FLUME/Mailing+Lists).\n\n**Review Code**: If you see that a JIRA ticket has a \"Patch Available\"\nstatus, go ahead and review it. It cannot be stressed enough that **you\nmust be kind in your review** and explain the rationale for your\nfeedback and suggestions. Also note that not all review feedback is\naccepted - often times it is a compromise between the contributor and\nreviewer. If you are happy with the change and do not spot any major\nissues, then `+1` it. More information on this is available in the\nfollowing sections.\n\n**Provide Patches**: We encourage you to assign the relevant JIRA issue\nto yourself and supply a patch for it. The patch you provide can be\n**code**, **documentation**, **build changes**, or any combination of\nthese. More information on this is available in the following sections.\n\nProviding Patches\n-----------------\n\nIn order to provide patches, follow these guidelines:\n\n-   **Make sure there is a JIRA**:\n    1.  If you are working on fixing a problem that already has an\n        associated JIRA, then go ahead and assign it to yourself.\n    2.  If it is already assigned to someone else, check with the\n        current assignee before moving it over to your queue.\n    3.  If the current assignee has already worked out some part of the\n        fix, suggest that you can take that change over from them and\n        complete the remaining parts.\n\n\n\n-   **Attach the patches as you go through development**:\n    -   While small fixes are easily done in a single patch, it is\n        preferable that you attach patches to the JIRA as you go along.\n        This serves as an early feedback mechanism where interested\n        folks can look it over and suggest changes where necessary. It\n        also ensures that if for some reason you are not able to find\n        the time to complete the change, someone else can take up your\n        initial patches and drive them to completion.\n\n-   **Before you submit your patch**:\n    1.  Your change should be well-formatted and readable. Please use\n        two spaces for indentation (no tabs).\n    2.  Carefully consider whether you have handled all boundary\n        conditions and have provided sufficiently defensive code\n        where necessary.\n    3.  Add one or more unit tests, if your change is not covered by\n        existing automated tests.\n    4.  Insert javadocs and code comments where appropriate.\n    5.  Update the [Flume User\n        Guide](http://flume.apache.org/FlumeUserGuide.html)\n        ([source](https://git-wip-us.apache.org/repos/asf?p=flume.git;a=blob;f=flume-ng-doc/sphinx/FlumeUserGuide.rst;hb=trunk))\n        if your change affects the Flume config file or any\n        user interface. Include those changes in your patch.\n    6.  Make sure you update the relevant developer documentation, wiki\n        pages, etc. if your change affects the development\n        environment.\n\n-   **Test your changes before submitting a review**:\n    -   Before you make the JIRA status as \"Patch Available\", please\n        test your changes thoroughly. Try any new feature or fix out for\n        yourself, and make sure that it works.\n    -   Make sure that all unit/integration tests are passing, and that\n        the functionality you have worked on is tested through existing\n        or new tests.\n    -   You can run all the tests by going to the root level of the\n        source tree and typing `mvn clean install`.\n\n-   **How to create a patch file**:\n    -   The preferred naming convention for Flume patches is\n        `FLUME-12345.patch`, or `FLUME-12345-0.patch` where `12345` is\n        the JIRA number. You might want to name successive versions of\n        the patch something like `FLUME-12345-1.patch`,\n        `FLUME-12345-2.patch`, etc. as you iterate on your changes based\n        on review feedback and re-submit them.\n    -   The command to generate the patch is \"git diff\". Example:\n\n        ```\n        $ git diff > /path/to/FLUME-1234-0.patch\n        ```\n\n\n-   **How to apply someone else's patch file**:\n    -   You can apply someone else's patch with the GNU `patch` tool.\n        Example:\n\n        ```\n        $ cd ~/src/flume # or wherever you keep the root of your Flume source tree\n        $ patch -p1 < FLUME-1234.patch\n        ```\n\n    -   Contributors may variously submit patches in a couple of\n        different formats. If you get some dialog from the `patch` tool\n        asking which file you want to patch, try variously the \"-p1\" or\n        \"-p0\" flags to `patch`. Without any additional arguments,\n        `git diff` generates patches that are applied using `patch -p1`.\n        If you use `git diff --no-prefix` to generate your patch, you\n        have to apply it using `patch -p0`. The ReviewBoard tool\n        understands both formats and is able to apply both\n        types automatically.\n\n\n-   **Submitting your patch for review:**\n    1.  To submit a patch, attach the patch file to the JIRA and change\n        the status of the JIRA to \"Patch Available\".\n    2.  If the change is non-trivial, please also post it for review on\n        the [Review\n        Board](https://reviews.apache.org/groups/Flume/).\n        Use the Repository \"flume-git\" on Review Board.\n    3.  Link the JIRA to the Review Board review. JIRA has a feature you\n        can use for this by going to More Actions &gt; Link &gt; Web\n        Link when logged into JIRA.\n\n\n\n-   **Identify a reviewer:**\n    1.  When posting on [review\n        board](https://reviews.apache.org/groups/Flume/)\n        (repository: \"flume-git\"), always add the Group \"Flume\" to the\n        list of reviewers.\n    2.  Optionally, you may also add a specific reviewer to the review.\n        You can pick any of the project committers for review. Note that\n        identifying a reviewer does not stop others from reviewing\n        your change. Be prepared for having your change reviewed by\n        others at any time.\n    3.  If you have posted your change for review and no one has had a\n        chance to review it yet, you can gently remind everyone by\n        dropping a note on the developer mailing list with a link to\n        the review.\n\n\n\n-   **Work with reviewers to get your change fleshed out**:\n    1.  When your change is reviewed, please engage with the reviewer\n        via JIRA or review board to get necessary clarifications and\n        work out other details.\n    2.  The goal is to ensure that the final state of your change is\n        acceptable to the reviewer so that they can +1 it.\n\nReviewing Code\n--------------\n\nFlume uses the [Apache Review\nBoard](https://reviews.apache.org/groups/Flume) for\ndoing code reviews. In order for a change to be reviewed, it should be\neither posted on the review board or attached to the JIRA. If the change\nis a minor change affecting only few lines and does not seem to impact\nmain logic of the affected sources, it need not be posted on the review\nboard. However, if the code change is large or otherwise impacting the\ncore logic of the affected sources, it should be posted on the review\nboard. Feel free to comment on the JIRA requesting the assignee to post\nthe patch for review on review board.\n\n**Note**: Not all patches attached to a JIRA are ready for review.\nSometimes the patches are attached just to solicit early feedback\nregarding the implementation direction. Feel free to look it over and\ngive your feedback in the JIRA as necessary. Patches are considered\nready for review either when the patch has been posted on review board,\nor the JIRA status has been changed to 'Patch Available'. Find here a\n[list of Flume JIRAs marked Patch\nAvailable](https://issues.apache.org/jira/issues/?jql=project%20%3D%20flume%20AND%20status%20%3D%20%22Patch%20Available%22).\n\n### Goals for Code Reviews\n\nThe net outcome from the review should be the same - which is to ensure\nthe following:\n\n-   Bugs/Omissions/Regressions are caught before the change is committed\n    to the source control.\n-   The change is subjected to keeping the quality of code high so as to\n    make the overall system sustainable. The implementation of the\n    change should be easily readable, documented where necessary, and\n    must favor simplicity of implementation.\n-   Changes are evaluated from the perspective of a consumer\n    (the reviewer) as opposed to the developer, which often brings out\n    subtleties in the implementation that otherwise go unnoticed.\n-   The change should be backward compatible and not require extensive\n    work on existing installations in order for it to be consumed. There\n    are exceptions to this in some cases like when work is done on a\n    major release, but otherwise backward compatibility should be upheld\n    at all times. If you are not clear, raise it is as a concern to be\n    clarified during the review.\n\n### Code review guidelines\n\nFollowing are some guidelines on how to do a code review. You may use\nany other approach instead as long as the above stated goals are met.\nThat said, here is an approach that works fine generally:\n\n-   **Understand the problem being solved**: This often requires going\n    through the JIRA comments and/or mailing list threads where the\n    discussion around the problem has happened in the past. Look for key\n    aspects of the problem such as how it has impacted the users and\n    what, if any, is the suggested way to solve it. You may not find\n    enough information regarding the problem in some cases, in which\n    case - feel free to ask for clarification from the developer\n    contributing the change.\n\n\n\n-   **Think about how you would solve the problem**: There are many ways\n    to solve any code problem, with different ways having\n    different merits. Before proceeding to review the change, think\n    through how you would solve the problem if you were the one\n    implementing the solution. Note the various aspects of the problem\n    that your solution might have. Some such aspects to think about\n    are - impact on backward compatibility, overall usability of the\n    system, any impact on performance etc.\n\n\n\n-   **Evaluate the proposed change in contrast to your solution**:\n    Unless the change is obvious, it is likely that the implementation\n    of the change you are reviewing is very different from the solution\n    you would go for. Evaluate this change on the various aspects that\n    you evaluated your solution on in the previous step. See how it\n    measures up and give feedback where you think it could be improved.\n\n\n\n-   **Look for typical pitfalls**: Read through the implementation to\n    see if: it needs to be documented at places where the intention is\n    not clear; if all the boundary conditions are being addressed; if\n    the code is defensive enough; if any bad idioms have leaked in such\n    as double check locking etc. In short, check for things that a\n    developer is likely to miss in their own code which are otherwise\n    obvious to someone trying to read and understand the code.\n\n\n\n-   **See if the change is complete**: Check if the change is such that\n    it affects the user interface. If it does, then the documentation\n    should likely be updated. What about testing - does it have enough\n    test coverage or not? What about other aspects like license headers,\n    copyright statements etc. How about checkstyle and findbugs - did\n    they generate new warnings? How about compiler warnings?\n\n\n\n-   **Test the change**: It is very easy to test the change if you have\n    the development environment setup. Run as many tests as\n    you want with the patch. Manually test the change for functionality\n    that you think is not fully covered via the associated tests. If you\n    find a problem, report it.\n\n### How to give feedback\n\nOnce you have collected your comments/concerns/feedback you need to send\nit to back to the contributor. In doing so, please be as courteous as\npossible and ensure the following:\n\n-   Your feedback should be clear and actionable. Giving\n    subjective/vague feedback does not add any value or facilitate a\n    constructive dialog.\n-   Where possible, suggest how your concern can be addressed. For\n    example if your testing revealed that a certain use-case is not\n    satisfied, it is acceptable to state that as is, but it would be\n    even better if you could suggest how the developer can address it.\n    Present your suggestion as a possible solution rather than\n    *the* solution.\n-   If you do not understand part of the change, or for some reason were\n    not able to review part of the change, state it explicitly so as to\n    encourage other reviewers to jump in and help.\n\nOnce you have provided your feedback, wait for the developer to respond.\nIt is possible that the developer may need further clarification on your\nfeedback, in which case you should promptly provide it where necessary.\nIn general, the dialog between the reviewer and developer should lead to\nfinding a reasonable middle ground where key concerns are satisfied and\nthe goals of the review have been met.\n\nIf a change has met all your criteria for review, please `+1` the change\nto indicate that you are happy with it.\n"
        },
        {
          "name": "DEVNOTES",
          "type": "blob",
          "size": 5.5478515625,
          "content": "Flume Developer Notes\n=====================\n\n// This is in asciidoc markup\n\n== Introduction\n\nThis is meant to be a a guide for issues that occur when building,\ndebugging and setting up Flume as developer.\n\n== High level directory and file structure.\n\nFlume uses the Maven build system and has a Maven project object model\n(pom) that has many components broken down into Maven modules.  Below\nwe describe the contents of different directories.\n\n----\n./bin/                  Flume startup scripts\n./conf/                 Flume configuration file samples\n./flume-ng-core         Flume core module\n./flume-ng-dist         Flume distribution package module\n./flume-ng-channels     Flume channels modules (memory, JDBC and File)\n./flume-ng-node         Flume node module\n./flume-ng-sinks        Flume sink modules (HDFS)\n----\n\nThe files exclusions in `.gitignore` are either autogenerated by Maven or Eclipse.\n\n== Building and Testing Flume\n\n\n=== Prerequisites\n\nYou need to have Apache Maven 3.x installed.\n\n=== Using Maven\n\nWe are using Maven v3.x.  The Maven build system steps through several phases\nto create build artefacts.  At the highest level, the phases that are relevent\nto most devs are \"compile\" -> \"test\" -> \"package\" -> \"install\".\n\nSet MAVEN_OPTS to give the Flume build enough RAM to build.\n\n  export MAVEN_OPTS=\"-Xms512m -Xmx1024m\"\n\nBuilds\n------\n\nA development build that runs unit tests and installs to local Maven repo.\nThis builds and tests all plugins.\n\n----\nmvn install\n----\n\nA development build that skips the execution of unit tests.\n\n----\nmvn install -DskipTests\n----\n\nA development build that runs unit tests. (no package generation)\n\n----\nmvn test\n----\n\nA development build that runs unit tests including only specific tests\n(where <TestFile> is a regex of a class name without .java or .class\nor path).\n\n----\nmvn test -Dtest=<ClassRegex>\n----\n\n==== Including or excluding specific sets of tests.\n\nWe've added hooks to the maven build that will enable you to exclude\nor include specific tests on a test run.  This is useful for excluding\nflakey tests or making a build that focuses solely upon flakey tests.\n\nTo do this we created two variables:\n\n# test.include.pattern\n# test.exclude.pattern\n\nThese variables take regular expression patterns of the files to be\nincluded or excluded.\n\nFor the next set of examples, let's say you have flakey test called\nTestFlaky1 and TestFlaky2.\n\nYou can execute tests that skip TestFlaky1 and TestFlaky2 by using the\nfollowing command line:\n\n----\nmvn test -Dtest.exclude.pattern=**/TestFlaky*.java\n----\n\nAlternately, you could be more explicit\n\n----\nmvn test -Dtest.exclude.pattern=**/TestFlaky1.java,**/TestFlaky2.java\n----\n\nConversely, you could execute only the flaky tests by using:\n\n----\nmvn test -Dtest.include.pattern=**/TestFlaky*.java\n----\n\nYou can also have a combination of imports and exports.  This runs\nTestFlaky* but skips over TestFlaky2:\n\n----\nmvn test -Dtest.include.pattern=**/TestFlaky*.java -Dtest.exclude.pattern=**/TestFlaky2.java\n----\n\nNOTE: Both test.exclude.pattern and test.include.pattern get\noverridden if the test parameter is used.  Consider:\n\n----\nmvn test -Dtest.exclude.pattern=**/TestFlaky*.java -Dtest=TestFlaky1\n---\n\nIn this case, TestFlaky1 will be run despite being in the\ntest.exclude.pattern.\n\n=== Running the most recent build\n\nTo run the most recent build of Flume, first build the distribuion\npackages.\n\n----\nmvn install -DskipTests\n----\n\n== Integrated Development Environments for Flume\n\nCurrently most Flume developers use the Eclipse IDE. We have included\nsome instructions for getting started with Eclipse.\n\n=== Setting up a Flume Eclipse projects from the Maven POMs.\n\nIf you use Eclipse we suggest you use the m2eclipse plugin available\nhere to properly create an environment for dev and testing in Eclipse.\n\nhttp://m2eclipse.sonatype.org/\n\nAfter installing it in Eclipse you will want to \"Import\" the Flume\npom.xml project.\n\nThis can be done by going to the Eclipse applications menu, navigating\nto File > Import... > Existing Maven Projects.  From there, browse to\nand select the directory that contains the root of the Flume project.\n\n== Rules of the Repository\n\nWe have a few basic rules for code in the repository.\n\nThe master/trunk pointer:\n\n* MUST always build.\n* SHOULD always pass all unit tests\n\nWhen commitng code we tag pushes with JIRA numbers, and their short descriptions.\nGenerally these are in the following format:\n\n----\nFLUME-42: Description from the jira\n----\n\nAll source files must include the following header (or a variant\ndepending on comment characters):\n\n----\n/**\n *      Licensed to the Apache Software Foundation (ASF) under one\n *      or more contributor license agreements.  See the NOTICE file\n *      distributed with this work for additional information\n *      regarding copyright ownership.  The ASF licenses this file\n *      to you under the Apache License, Version 2.0 (the\n *      \"License\"); you may not use this file except in compliance\n *      with the License.  You may obtain a copy of the License at\n *\n *        http://www.apache.org/licenses/LICENSE-2.0\n *\n *      Unless required by applicable law or agreed to in writing,\n *      software distributed under the License is distributed on an\n *      \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n *      KIND, either express or implied.  See the License for the\n *      specific language governing permissions and limitations\n *      under the License.\n */\n----\n\nNo build generated files should be checked in.  Here are some examples\nof generate files that should not be checked:\n\n* html documentation\n* avro-generated source\n* auto-generated versioning annotations\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 14.146484375,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n====\n\nThe following files are included under the 2-Clause BSD License\n\nflume-ng-sinks/flume-ng-morphline-solr-sink/src/test/resources/solr/collection1/conf/lang/stopwords_ar.txt\nflume-ng-sinks/flume-ng-morphline-solr-sink/src/test/resources/solr/collection1/conf/lang/stopwords_bg.txt\nflume-ng-sinks/flume-ng-morphline-solr-sink/src/test/resources/solr/collection1/conf/lang/stopwords_da.txt\nflume-ng-sinks/flume-ng-morphline-solr-sink/src/test/resources/solr/collection1/conf/lang/stopwords_de.txt\nflume-ng-sinks/flume-ng-morphline-solr-sink/src/test/resources/solr/collection1/conf/lang/stopwords_es.txt\nflume-ng-sinks/flume-ng-morphline-solr-sink/src/test/resources/solr/collection1/conf/lang/stopwords_fa.txt\nflume-ng-sinks/flume-ng-morphline-solr-sink/src/test/resources/solr/collection1/conf/lang/stopwords_fi.txt\nflume-ng-sinks/flume-ng-morphline-solr-sink/src/test/resources/solr/collection1/conf/lang/stopwords_fr.txt\nflume-ng-sinks/flume-ng-morphline-solr-sink/src/test/resources/solr/collection1/conf/lang/stopwords_hi.txt\nflume-ng-sinks/flume-ng-morphline-solr-sink/src/test/resources/solr/collection1/conf/lang/stopwords_hu.txt\nflume-ng-sinks/flume-ng-morphline-solr-sink/src/test/resources/solr/collection1/conf/lang/stopwords_it.txt\nflume-ng-sinks/flume-ng-morphline-solr-sink/src/test/resources/solr/collection1/conf/lang/stopwords_nl.txt\nflume-ng-sinks/flume-ng-morphline-solr-sink/src/test/resources/solr/collection1/conf/lang/stopwords_no.txt\nflume-ng-sinks/flume-ng-morphline-solr-sink/src/test/resources/solr/collection1/conf/lang/stopwords_pt.txt\nflume-ng-sinks/flume-ng-morphline-solr-sink/src/test/resources/solr/collection1/conf/lang/stopwords_ro.txt\nflume-ng-sinks/flume-ng-morphline-solr-sink/src/test/resources/solr/collection1/conf/lang/stopwords_ru.txt\nflume-ng-sinks/flume-ng-morphline-solr-sink/src/test/resources/solr/collection1/conf/lang/stopwords_sv.txt\n\nRedistribution and use in source and binary forms, with or without modification,\nare permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\nlist of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\nthis list of conditions and the following disclaimer in the documentation and/or\nother materials provided with the distribution.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR\nANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\nANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "NOTICE",
          "type": "blob",
          "size": 0.2685546875,
          "content": "Apache Flume\nCopyright 2011-2022 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\nPortions of this software were developed at\nCloudera, Inc. (http://www.cloudera.com/), copyright 2009-2011.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 2.7841796875,
          "content": "<!--\nLicensed to the Apache Software Foundation (ASF) under one\nor more contributor license agreements.  See the NOTICE file\ndistributed with this work for additional information\nregarding copyright ownership.  The ASF licenses this file\nto you under the Apache License, Version 2.0 (the\n\"License\"); you may not use this file except in compliance\nwith the License.  You may obtain a copy of the License at\n\n  http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing,\nsoftware distributed under the License is distributed on an\n\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\nKIND, either express or implied.  See the License for the\nspecific language governing permissions and limitations\nunder the License.\n-->\n\n# Project status\n\n> [!WARNING]\n> **This project is not maintained anymore!**\n> [It has been marked as dormant by Apache Logging Services consensus on 2024-10-10.](https://lists.apache.org/thread/dg9wro6dp7w95o1x911lbyqxzl808b3l)\n> Users are advised to migrate to alternatives.\n> For other inquiries, see [the support policy](https://logging.apache.org/support.html).\n\n# Welcome to Apache Flume!\n\nApache Flume is a distributed, reliable, and available service for efficiently\ncollecting, aggregating, and moving large amounts of log data. It has a simple\nand flexible architecture based on streaming data flows. It is robust and fault\ntolerant with tunable reliability mechanisms and many failover and recovery\nmechanisms. The system is centrally managed and allows for intelligent dynamic\nmanagement. It uses a simple extensible data model that allows for online\nanalytic application.\n\nThe Apache Flume 1.x (NG) code line is a refactoring of the first generation\nFlume to solve certain known issues and limitations of the original design.\n\nApache Flume is open-sourced under the Apache Software Foundation License v2.0.\n\n## Documentation\n\nDocumentation is included in the binary distribution under the docs directory.\nIn source form, it can be found in the flume-ng-doc directory.\n\nThe Flume 1.x guide and FAQ are available here:\n\n* https://cwiki.apache.org/FLUME\n* https://cwiki.apache.org/confluence/display/FLUME/Getting+Started\n\n## Contact us!\n\n* Mailing lists: https://cwiki.apache.org/confluence/display/FLUME/Mailing+Lists\n* IRC channel #flume on irc.freenode.net\n\nBug and Issue tracker.\n\n* https://issues.apache.org/jira/browse/FLUME\n\n## Compiling Flume\n\nCompiling Flume requires the following tools:\n\n* Oracle Java JDK 1.8\n* Apache Maven 3.x\n\nNote: The Apache Flume build requires more memory than the default configuration.\nWe recommend you set the following Maven options:\n\n`export MAVEN_OPTS=\"-Xms512m -Xmx1024m\"`\n\nTo compile Flume and build a distribution tarball, run `mvn install` from the\ntop level directory. The artifacts will be placed under `flume-ng-dist/target/`.\n"
        },
        {
          "name": "RELEASE-NOTES",
          "type": "blob",
          "size": 1.552734375,
          "content": "Apache Flume 1.11.0\n\nCONTENTS\n1. What is Apache Flume\n2. Status of this release\n3. Major changes in this Release\n4. How to Get Involved\n5. How to Report Issues\n\n1. What is Apache Flume\nFlume is a distributed, reliable, and available service for\nefficiently collecting, aggregating, and moving large amounts of event\ndata. It has a simple and flexible architecture based on streaming\ndata flows. It is robust and fault tolerant with tunable reliability\nmechanisms and many failover and recovery mechanisms. Flume uses a\nsimple, extensible data model that allows for online analytic\napplication.\n\n2. Status of this release\nApache Flume 1.11.0 is the next GA release of Flume as an Apache top-level\nproject (TLP). Apache Flume 1.11.0 is production-ready software.\n\n3. Major changes in this Release\nFor a detailed list of changes, please see the CHANGELOG file included\nin this distribution.\n\nApache Flume versions 1.0.0 and greater represent a major refactoring of the\nFlume codebase and are not backwards compatible with the 0.9.x series of Flume\nreleases. However, the developers of Flume strive to maintain backwards\ncompatibility within the 1.x codeline.\n\n4. How to Get Involved\nThe Apache Flume project really needs and appreciates any contributions,\nincluding documentation help, source code and feedback. If you are interested\nin contributing, please visit:\nhttps://cwiki.apache.org/confluence/display/FLUME/How+to+Contribute\n\n5. How to Report Issues\nThe Apache Flume project uses JIRA for issue tracking. Please report any issues\nyou find at http://issues.apache.org/jira/browse/FLUME\n"
        },
        {
          "name": "bin",
          "type": "tree",
          "content": null
        },
        {
          "name": "build-support",
          "type": "tree",
          "content": null
        },
        {
          "name": "conf",
          "type": "tree",
          "content": null
        },
        {
          "name": "dev-docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "dev-support",
          "type": "tree",
          "content": null
        },
        {
          "name": "doap_Flume.rdf",
          "type": "blob",
          "size": 2.8095703125,
          "content": "<?xml version=\"1.0\"?>\n<?xml-stylesheet type=\"text/xsl\"?>\n<rdf:RDF xml:lang=\"en\"\n         xmlns=\"http://usefulinc.com/ns/doap#\" \n         xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" \n         xmlns:asfext=\"http://projects.apache.org/ns/asfext#\"\n         xmlns:foaf=\"http://xmlns.com/foaf/0.1/\">\n<!--\n    Licensed to the Apache Software Foundation (ASF) under one or more\n    contributor license agreements.  See the NOTICE file distributed with\n    this work for additional information regarding copyright ownership.\n    The ASF licenses this file to You under the Apache License, Version 2.0\n    (the \"License\"); you may not use this file except in compliance with\n    the License.  You may obtain a copy of the License at\n   \n         http://www.apache.org/licenses/LICENSE-2.0\n   \n    Unless required by applicable law or agreed to in writing, software\n    distributed under the License is distributed on an \"AS IS\" BASIS,\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.\n-->\n  <Project rdf:about=\"http://flume.apache.org\">\n    <created>2014-06-13</created>\n    <license rdf:resource=\"http://spdx.org/licenses/Apache-2.0\" />\n    <name>Apache Flume</name>\n    <homepage rdf:resource=\"http://flume.apache.org\" />\n    <asfext:pmc rdf:resource=\"http://logging.apache.org\" />\n    <shortdesc>Apache Flume is a distributed, reliable, and available system for efficiently collecting, aggregating and moving large amounts of log data from many different sources to a centralized data store.</shortdesc>\n    <description>Apache Flume is a distributed, reliable, and available system for efficiently collecting, aggregating and moving large amounts of log data from many different sources to a centralized data store</description>\n    <bug-database rdf:resource=\"https://issues.apache.org/jira/browse/FLUME\" />\n    <mailing-list rdf:resource=\"http://flume.apache.org/mailinglists.html\" />\n    <download-page rdf:resource=\"http://flume.apache.org/download.html\" />\n    <programming-language>Java</programming-language>\n    <category rdf:resource=\"http://projects.apache.org/category/big-data\" />\n    <release>\n      <Version>\n        <name>Apache Flume</name>\n        <created>2014-05-20</created>\n        <revision>1.5.0</revision>\n      </Version>\n    </release>\n    <repository>\n      <SVNRepository>\n        <location rdf:resource=\"https://git-wip-us.apache.org/repos/asf?p=flume.git\"/>\n        <browse rdf:resource=\"https://git-wip-us.apache.org/repos/asf?p=flume.git\"/>\n      </SVNRepository>\n    </repository>\n    <maintainer>\n      <foaf:Person>\n        <foaf:name>Apache Logging Services</foaf:name>\n          <foaf:mbox rdf:resource=\"mailto:dev@logging.apache.org\"/>\n      </foaf:Person>\n    </maintainer>\n  </Project>\n</rdf:RDF>\n"
        },
        {
          "name": "flume-bom",
          "type": "tree",
          "content": null
        },
        {
          "name": "flume-ng-auth",
          "type": "tree",
          "content": null
        },
        {
          "name": "flume-ng-channels",
          "type": "tree",
          "content": null
        },
        {
          "name": "flume-ng-clients",
          "type": "tree",
          "content": null
        },
        {
          "name": "flume-ng-configfilters",
          "type": "tree",
          "content": null
        },
        {
          "name": "flume-ng-configuration",
          "type": "tree",
          "content": null
        },
        {
          "name": "flume-ng-core",
          "type": "tree",
          "content": null
        },
        {
          "name": "flume-ng-dist",
          "type": "tree",
          "content": null
        },
        {
          "name": "flume-ng-embedded-agent",
          "type": "tree",
          "content": null
        },
        {
          "name": "flume-ng-node",
          "type": "tree",
          "content": null
        },
        {
          "name": "flume-ng-sdk",
          "type": "tree",
          "content": null
        },
        {
          "name": "flume-ng-sinks",
          "type": "tree",
          "content": null
        },
        {
          "name": "flume-ng-sources",
          "type": "tree",
          "content": null
        },
        {
          "name": "flume-ng-tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "flume-parent",
          "type": "tree",
          "content": null
        },
        {
          "name": "flume-tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "mvnw",
          "type": "blob",
          "size": 11.0244140625,
          "content": "#!/bin/sh\n# ----------------------------------------------------------------------------\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n# ----------------------------------------------------------------------------\n\n# ----------------------------------------------------------------------------\n# Apache Maven Wrapper startup batch script, version 3.2.0\n#\n# Required ENV vars:\n# ------------------\n#   JAVA_HOME - location of a JDK home dir\n#\n# Optional ENV vars\n# -----------------\n#   MAVEN_OPTS - parameters passed to the Java VM when running Maven\n#     e.g. to debug Maven itself, use\n#       set MAVEN_OPTS=-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=8000\n#   MAVEN_SKIP_RC - flag to disable loading of mavenrc files\n# ----------------------------------------------------------------------------\n\nif [ -z \"$MAVEN_SKIP_RC\" ] ; then\n\n  if [ -f /usr/local/etc/mavenrc ] ; then\n    . /usr/local/etc/mavenrc\n  fi\n\n  if [ -f /etc/mavenrc ] ; then\n    . /etc/mavenrc\n  fi\n\n  if [ -f \"$HOME/.mavenrc\" ] ; then\n    . \"$HOME/.mavenrc\"\n  fi\n\nfi\n\n# OS specific support.  $var _must_ be set to either true or false.\ncygwin=false;\ndarwin=false;\nmingw=false\ncase \"$(uname)\" in\n  CYGWIN*) cygwin=true ;;\n  MINGW*) mingw=true;;\n  Darwin*) darwin=true\n    # Use /usr/libexec/java_home if available, otherwise fall back to /Library/Java/Home\n    # See https://developer.apple.com/library/mac/qa/qa1170/_index.html\n    if [ -z \"$JAVA_HOME\" ]; then\n      if [ -x \"/usr/libexec/java_home\" ]; then\n        JAVA_HOME=\"$(/usr/libexec/java_home)\"; export JAVA_HOME\n      else\n        JAVA_HOME=\"/Library/Java/Home\"; export JAVA_HOME\n      fi\n    fi\n    ;;\nesac\n\nif [ -z \"$JAVA_HOME\" ] ; then\n  if [ -r /etc/gentoo-release ] ; then\n    JAVA_HOME=$(java-config --jre-home)\n  fi\nfi\n\n# For Cygwin, ensure paths are in UNIX format before anything is touched\nif $cygwin ; then\n  [ -n \"$JAVA_HOME\" ] &&\n    JAVA_HOME=$(cygpath --unix \"$JAVA_HOME\")\n  [ -n \"$CLASSPATH\" ] &&\n    CLASSPATH=$(cygpath --path --unix \"$CLASSPATH\")\nfi\n\n# For Mingw, ensure paths are in UNIX format before anything is touched\nif $mingw ; then\n  [ -n \"$JAVA_HOME\" ] && [ -d \"$JAVA_HOME\" ] &&\n    JAVA_HOME=\"$(cd \"$JAVA_HOME\" || (echo \"cannot cd into $JAVA_HOME.\"; exit 1); pwd)\"\nfi\n\nif [ -z \"$JAVA_HOME\" ]; then\n  javaExecutable=\"$(which javac)\"\n  if [ -n \"$javaExecutable\" ] && ! [ \"$(expr \"\\\"$javaExecutable\\\"\" : '\\([^ ]*\\)')\" = \"no\" ]; then\n    # readlink(1) is not available as standard on Solaris 10.\n    readLink=$(which readlink)\n    if [ ! \"$(expr \"$readLink\" : '\\([^ ]*\\)')\" = \"no\" ]; then\n      if $darwin ; then\n        javaHome=\"$(dirname \"\\\"$javaExecutable\\\"\")\"\n        javaExecutable=\"$(cd \"\\\"$javaHome\\\"\" && pwd -P)/javac\"\n      else\n        javaExecutable=\"$(readlink -f \"\\\"$javaExecutable\\\"\")\"\n      fi\n      javaHome=\"$(dirname \"\\\"$javaExecutable\\\"\")\"\n      javaHome=$(expr \"$javaHome\" : '\\(.*\\)/bin')\n      JAVA_HOME=\"$javaHome\"\n      export JAVA_HOME\n    fi\n  fi\nfi\n\nif [ -z \"$JAVACMD\" ] ; then\n  if [ -n \"$JAVA_HOME\"  ] ; then\n    if [ -x \"$JAVA_HOME/jre/sh/java\" ] ; then\n      # IBM's JDK on AIX uses strange locations for the executables\n      JAVACMD=\"$JAVA_HOME/jre/sh/java\"\n    else\n      JAVACMD=\"$JAVA_HOME/bin/java\"\n    fi\n  else\n    JAVACMD=\"$(\\unset -f command 2>/dev/null; \\command -v java)\"\n  fi\nfi\n\nif [ ! -x \"$JAVACMD\" ] ; then\n  echo \"Error: JAVA_HOME is not defined correctly.\" >&2\n  echo \"  We cannot execute $JAVACMD\" >&2\n  exit 1\nfi\n\nif [ -z \"$JAVA_HOME\" ] ; then\n  echo \"Warning: JAVA_HOME environment variable is not set.\"\nfi\n\n# traverses directory structure from process work directory to filesystem root\n# first directory with .mvn subdirectory is considered project base directory\nfind_maven_basedir() {\n  if [ -z \"$1\" ]\n  then\n    echo \"Path not specified to find_maven_basedir\"\n    return 1\n  fi\n\n  basedir=\"$1\"\n  wdir=\"$1\"\n  while [ \"$wdir\" != '/' ] ; do\n    if [ -d \"$wdir\"/.mvn ] ; then\n      basedir=$wdir\n      break\n    fi\n    # workaround for JBEAP-8937 (on Solaris 10/Sparc)\n    if [ -d \"${wdir}\" ]; then\n      wdir=$(cd \"$wdir/..\" || exit 1; pwd)\n    fi\n    # end of workaround\n  done\n  printf '%s' \"$(cd \"$basedir\" || exit 1; pwd)\"\n}\n\n# concatenates all lines of a file\nconcat_lines() {\n  if [ -f \"$1\" ]; then\n    # Remove \\r in case we run on Windows within Git Bash\n    # and check out the repository with auto CRLF management\n    # enabled. Otherwise, we may read lines that are delimited with\n    # \\r\\n and produce $'-Xarg\\r' rather than -Xarg due to word\n    # splitting rules.\n    tr -s '\\r\\n' ' ' < \"$1\"\n  fi\n}\n\nlog() {\n  if [ \"$MVNW_VERBOSE\" = true ]; then\n    printf '%s\\n' \"$1\"\n  fi\n}\n\nBASE_DIR=$(find_maven_basedir \"$(dirname \"$0\")\")\nif [ -z \"$BASE_DIR\" ]; then\n  exit 1;\nfi\n\nMAVEN_PROJECTBASEDIR=${MAVEN_BASEDIR:-\"$BASE_DIR\"}; export MAVEN_PROJECTBASEDIR\nlog \"$MAVEN_PROJECTBASEDIR\"\n\n##########################################################################################\n# Extension to allow automatically downloading the maven-wrapper.jar from Maven-central\n# This allows using the maven wrapper in projects that prohibit checking in binary data.\n##########################################################################################\nwrapperJarPath=\"$MAVEN_PROJECTBASEDIR/.mvn/wrapper/maven-wrapper.jar\"\nif [ -r \"$wrapperJarPath\" ]; then\n    log \"Found $wrapperJarPath\"\nelse\n    log \"Couldn't find $wrapperJarPath, downloading it ...\"\n\n    if [ -n \"$MVNW_REPOURL\" ]; then\n      wrapperUrl=\"$MVNW_REPOURL/org/apache/maven/wrapper/maven-wrapper/3.2.0/maven-wrapper-3.2.0.jar\"\n    else\n      wrapperUrl=\"https://repo.maven.apache.org/maven2/org/apache/maven/wrapper/maven-wrapper/3.2.0/maven-wrapper-3.2.0.jar\"\n    fi\n    while IFS=\"=\" read -r key value; do\n      # Remove '\\r' from value to allow usage on windows as IFS does not consider '\\r' as a separator ( considers space, tab, new line ('\\n'), and custom '=' )\n      safeValue=$(echo \"$value\" | tr -d '\\r')\n      case \"$key\" in (wrapperUrl) wrapperUrl=\"$safeValue\"; break ;;\n      esac\n    done < \"$MAVEN_PROJECTBASEDIR/.mvn/wrapper/maven-wrapper.properties\"\n    log \"Downloading from: $wrapperUrl\"\n\n    if $cygwin; then\n      wrapperJarPath=$(cygpath --path --windows \"$wrapperJarPath\")\n    fi\n\n    if command -v wget > /dev/null; then\n        log \"Found wget ... using wget\"\n        [ \"$MVNW_VERBOSE\" = true ] && QUIET=\"\" || QUIET=\"--quiet\"\n        if [ -z \"$MVNW_USERNAME\" ] || [ -z \"$MVNW_PASSWORD\" ]; then\n            wget $QUIET \"$wrapperUrl\" -O \"$wrapperJarPath\" || rm -f \"$wrapperJarPath\"\n        else\n            wget $QUIET --http-user=\"$MVNW_USERNAME\" --http-password=\"$MVNW_PASSWORD\" \"$wrapperUrl\" -O \"$wrapperJarPath\" || rm -f \"$wrapperJarPath\"\n        fi\n    elif command -v curl > /dev/null; then\n        log \"Found curl ... using curl\"\n        [ \"$MVNW_VERBOSE\" = true ] && QUIET=\"\" || QUIET=\"--silent\"\n        if [ -z \"$MVNW_USERNAME\" ] || [ -z \"$MVNW_PASSWORD\" ]; then\n            curl $QUIET -o \"$wrapperJarPath\" \"$wrapperUrl\" -f -L || rm -f \"$wrapperJarPath\"\n        else\n            curl $QUIET --user \"$MVNW_USERNAME:$MVNW_PASSWORD\" -o \"$wrapperJarPath\" \"$wrapperUrl\" -f -L || rm -f \"$wrapperJarPath\"\n        fi\n    else\n        log \"Falling back to using Java to download\"\n        javaSource=\"$MAVEN_PROJECTBASEDIR/.mvn/wrapper/MavenWrapperDownloader.java\"\n        javaClass=\"$MAVEN_PROJECTBASEDIR/.mvn/wrapper/MavenWrapperDownloader.class\"\n        # For Cygwin, switch paths to Windows format before running javac\n        if $cygwin; then\n          javaSource=$(cygpath --path --windows \"$javaSource\")\n          javaClass=$(cygpath --path --windows \"$javaClass\")\n        fi\n        if [ -e \"$javaSource\" ]; then\n            if [ ! -e \"$javaClass\" ]; then\n                log \" - Compiling MavenWrapperDownloader.java ...\"\n                (\"$JAVA_HOME/bin/javac\" \"$javaSource\")\n            fi\n            if [ -e \"$javaClass\" ]; then\n                log \" - Running MavenWrapperDownloader.java ...\"\n                (\"$JAVA_HOME/bin/java\" -cp .mvn/wrapper MavenWrapperDownloader \"$wrapperUrl\" \"$wrapperJarPath\") || rm -f \"$wrapperJarPath\"\n            fi\n        fi\n    fi\nfi\n##########################################################################################\n# End of extension\n##########################################################################################\n\n# If specified, validate the SHA-256 sum of the Maven wrapper jar file\nwrapperSha256Sum=\"\"\nwhile IFS=\"=\" read -r key value; do\n  case \"$key\" in (wrapperSha256Sum) wrapperSha256Sum=$value; break ;;\n  esac\ndone < \"$MAVEN_PROJECTBASEDIR/.mvn/wrapper/maven-wrapper.properties\"\nif [ -n \"$wrapperSha256Sum\" ]; then\n  wrapperSha256Result=false\n  if command -v sha256sum > /dev/null; then\n    if echo \"$wrapperSha256Sum  $wrapperJarPath\" | sha256sum -c > /dev/null 2>&1; then\n      wrapperSha256Result=true\n    fi\n  elif command -v shasum > /dev/null; then\n    if echo \"$wrapperSha256Sum  $wrapperJarPath\" | shasum -a 256 -c > /dev/null 2>&1; then\n      wrapperSha256Result=true\n    fi\n  else\n    echo \"Checksum validation was requested but neither 'sha256sum' or 'shasum' are available.\"\n    echo \"Please install either command, or disable validation by removing 'wrapperSha256Sum' from your maven-wrapper.properties.\"\n    exit 1\n  fi\n  if [ $wrapperSha256Result = false ]; then\n    echo \"Error: Failed to validate Maven wrapper SHA-256, your Maven wrapper might be compromised.\" >&2\n    echo \"Investigate or delete $wrapperJarPath to attempt a clean download.\" >&2\n    echo \"If you updated your Maven version, you need to update the specified wrapperSha256Sum property.\" >&2\n    exit 1\n  fi\nfi\n\nMAVEN_OPTS=\"$(concat_lines \"$MAVEN_PROJECTBASEDIR/.mvn/jvm.config\") $MAVEN_OPTS\"\n\n# For Cygwin, switch paths to Windows format before running java\nif $cygwin; then\n  [ -n \"$JAVA_HOME\" ] &&\n    JAVA_HOME=$(cygpath --path --windows \"$JAVA_HOME\")\n  [ -n \"$CLASSPATH\" ] &&\n    CLASSPATH=$(cygpath --path --windows \"$CLASSPATH\")\n  [ -n \"$MAVEN_PROJECTBASEDIR\" ] &&\n    MAVEN_PROJECTBASEDIR=$(cygpath --path --windows \"$MAVEN_PROJECTBASEDIR\")\nfi\n\n# Provide a \"standardized\" way to retrieve the CLI args that will\n# work with both Windows and non-Windows executions.\nMAVEN_CMD_LINE_ARGS=\"$MAVEN_CONFIG $*\"\nexport MAVEN_CMD_LINE_ARGS\n\nWRAPPER_LAUNCHER=org.apache.maven.wrapper.MavenWrapperMain\n\n# shellcheck disable=SC2086 # safe args\nexec \"$JAVACMD\" \\\n  $MAVEN_OPTS \\\n  $MAVEN_DEBUG_OPTS \\\n  -classpath \"$MAVEN_PROJECTBASEDIR/.mvn/wrapper/maven-wrapper.jar\" \\\n  \"-Dmaven.multiModuleProjectDirectory=${MAVEN_PROJECTBASEDIR}\" \\\n  ${WRAPPER_LAUNCHER} $MAVEN_CONFIG \"$@\"\n"
        },
        {
          "name": "mvnw.cmd",
          "type": "blob",
          "size": 7.61328125,
          "content": "@REM ----------------------------------------------------------------------------\r\n@REM Licensed to the Apache Software Foundation (ASF) under one\r\n@REM or more contributor license agreements.  See the NOTICE file\r\n@REM distributed with this work for additional information\r\n@REM regarding copyright ownership.  The ASF licenses this file\r\n@REM to you under the Apache License, Version 2.0 (the\r\n@REM \"License\"); you may not use this file except in compliance\r\n@REM with the License.  You may obtain a copy of the License at\r\n@REM\r\n@REM    http://www.apache.org/licenses/LICENSE-2.0\r\n@REM\r\n@REM Unless required by applicable law or agreed to in writing,\r\n@REM software distributed under the License is distributed on an\r\n@REM \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\r\n@REM KIND, either express or implied.  See the License for the\r\n@REM specific language governing permissions and limitations\r\n@REM under the License.\r\n@REM ----------------------------------------------------------------------------\r\n\r\n@REM ----------------------------------------------------------------------------\r\n@REM Apache Maven Wrapper startup batch script, version 3.2.0\r\n@REM\r\n@REM Required ENV vars:\r\n@REM JAVA_HOME - location of a JDK home dir\r\n@REM\r\n@REM Optional ENV vars\r\n@REM MAVEN_BATCH_ECHO - set to 'on' to enable the echoing of the batch commands\r\n@REM MAVEN_BATCH_PAUSE - set to 'on' to wait for a keystroke before ending\r\n@REM MAVEN_OPTS - parameters passed to the Java VM when running Maven\r\n@REM     e.g. to debug Maven itself, use\r\n@REM set MAVEN_OPTS=-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=8000\r\n@REM MAVEN_SKIP_RC - flag to disable loading of mavenrc files\r\n@REM ----------------------------------------------------------------------------\r\n\r\n@REM Begin all REM lines with '@' in case MAVEN_BATCH_ECHO is 'on'\r\n@echo off\r\n@REM set title of command window\r\ntitle %0\r\n@REM enable echoing by setting MAVEN_BATCH_ECHO to 'on'\r\n@if \"%MAVEN_BATCH_ECHO%\" == \"on\"  echo %MAVEN_BATCH_ECHO%\r\n\r\n@REM set %HOME% to equivalent of $HOME\r\nif \"%HOME%\" == \"\" (set \"HOME=%HOMEDRIVE%%HOMEPATH%\")\r\n\r\n@REM Execute a user defined script before this one\r\nif not \"%MAVEN_SKIP_RC%\" == \"\" goto skipRcPre\r\n@REM check for pre script, once with legacy .bat ending and once with .cmd ending\r\nif exist \"%USERPROFILE%\\mavenrc_pre.bat\" call \"%USERPROFILE%\\mavenrc_pre.bat\" %*\r\nif exist \"%USERPROFILE%\\mavenrc_pre.cmd\" call \"%USERPROFILE%\\mavenrc_pre.cmd\" %*\r\n:skipRcPre\r\n\r\n@setlocal\r\n\r\nset ERROR_CODE=0\r\n\r\n@REM To isolate internal variables from possible post scripts, we use another setlocal\r\n@setlocal\r\n\r\n@REM ==== START VALIDATION ====\r\nif not \"%JAVA_HOME%\" == \"\" goto OkJHome\r\n\r\necho.\r\necho Error: JAVA_HOME not found in your environment. >&2\r\necho Please set the JAVA_HOME variable in your environment to match the >&2\r\necho location of your Java installation. >&2\r\necho.\r\ngoto error\r\n\r\n:OkJHome\r\nif exist \"%JAVA_HOME%\\bin\\java.exe\" goto init\r\n\r\necho.\r\necho Error: JAVA_HOME is set to an invalid directory. >&2\r\necho JAVA_HOME = \"%JAVA_HOME%\" >&2\r\necho Please set the JAVA_HOME variable in your environment to match the >&2\r\necho location of your Java installation. >&2\r\necho.\r\ngoto error\r\n\r\n@REM ==== END VALIDATION ====\r\n\r\n:init\r\n\r\n@REM Find the project base dir, i.e. the directory that contains the folder \".mvn\".\r\n@REM Fallback to current working directory if not found.\r\n\r\nset MAVEN_PROJECTBASEDIR=%MAVEN_BASEDIR%\r\nIF NOT \"%MAVEN_PROJECTBASEDIR%\"==\"\" goto endDetectBaseDir\r\n\r\nset EXEC_DIR=%CD%\r\nset WDIR=%EXEC_DIR%\r\n:findBaseDir\r\nIF EXIST \"%WDIR%\"\\.mvn goto baseDirFound\r\ncd ..\r\nIF \"%WDIR%\"==\"%CD%\" goto baseDirNotFound\r\nset WDIR=%CD%\r\ngoto findBaseDir\r\n\r\n:baseDirFound\r\nset MAVEN_PROJECTBASEDIR=%WDIR%\r\ncd \"%EXEC_DIR%\"\r\ngoto endDetectBaseDir\r\n\r\n:baseDirNotFound\r\nset MAVEN_PROJECTBASEDIR=%EXEC_DIR%\r\ncd \"%EXEC_DIR%\"\r\n\r\n:endDetectBaseDir\r\n\r\nIF NOT EXIST \"%MAVEN_PROJECTBASEDIR%\\.mvn\\jvm.config\" goto endReadAdditionalConfig\r\n\r\n@setlocal EnableExtensions EnableDelayedExpansion\r\nfor /F \"usebackq delims=\" %%a in (\"%MAVEN_PROJECTBASEDIR%\\.mvn\\jvm.config\") do set JVM_CONFIG_MAVEN_PROPS=!JVM_CONFIG_MAVEN_PROPS! %%a\r\n@endlocal & set JVM_CONFIG_MAVEN_PROPS=%JVM_CONFIG_MAVEN_PROPS%\r\n\r\n:endReadAdditionalConfig\r\n\r\nSET MAVEN_JAVA_EXE=\"%JAVA_HOME%\\bin\\java.exe\"\r\nset WRAPPER_JAR=\"%MAVEN_PROJECTBASEDIR%\\.mvn\\wrapper\\maven-wrapper.jar\"\r\nset WRAPPER_LAUNCHER=org.apache.maven.wrapper.MavenWrapperMain\r\n\r\nset WRAPPER_URL=\"https://repo.maven.apache.org/maven2/org/apache/maven/wrapper/maven-wrapper/3.2.0/maven-wrapper-3.2.0.jar\"\r\n\r\nFOR /F \"usebackq tokens=1,2 delims==\" %%A IN (\"%MAVEN_PROJECTBASEDIR%\\.mvn\\wrapper\\maven-wrapper.properties\") DO (\r\n    IF \"%%A\"==\"wrapperUrl\" SET WRAPPER_URL=%%B\r\n)\r\n\r\n@REM Extension to allow automatically downloading the maven-wrapper.jar from Maven-central\r\n@REM This allows using the maven wrapper in projects that prohibit checking in binary data.\r\nif exist %WRAPPER_JAR% (\r\n    if \"%MVNW_VERBOSE%\" == \"true\" (\r\n        echo Found %WRAPPER_JAR%\r\n    )\r\n) else (\r\n    if not \"%MVNW_REPOURL%\" == \"\" (\r\n        SET WRAPPER_URL=\"%MVNW_REPOURL%/org/apache/maven/wrapper/maven-wrapper/3.2.0/maven-wrapper-3.2.0.jar\"\r\n    )\r\n    if \"%MVNW_VERBOSE%\" == \"true\" (\r\n        echo Couldn't find %WRAPPER_JAR%, downloading it ...\r\n        echo Downloading from: %WRAPPER_URL%\r\n    )\r\n\r\n    powershell -Command \"&{\"^\r\n\t\t\"$webclient = new-object System.Net.WebClient;\"^\r\n\t\t\"if (-not ([string]::IsNullOrEmpty('%MVNW_USERNAME%') -and [string]::IsNullOrEmpty('%MVNW_PASSWORD%'))) {\"^\r\n\t\t\"$webclient.Credentials = new-object System.Net.NetworkCredential('%MVNW_USERNAME%', '%MVNW_PASSWORD%');\"^\r\n\t\t\"}\"^\r\n\t\t\"[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12; $webclient.DownloadFile('%WRAPPER_URL%', '%WRAPPER_JAR%')\"^\r\n\t\t\"}\"\r\n    if \"%MVNW_VERBOSE%\" == \"true\" (\r\n        echo Finished downloading %WRAPPER_JAR%\r\n    )\r\n)\r\n@REM End of extension\r\n\r\n@REM If specified, validate the SHA-256 sum of the Maven wrapper jar file\r\nSET WRAPPER_SHA_256_SUM=\"\"\r\nFOR /F \"usebackq tokens=1,2 delims==\" %%A IN (\"%MAVEN_PROJECTBASEDIR%\\.mvn\\wrapper\\maven-wrapper.properties\") DO (\r\n    IF \"%%A\"==\"wrapperSha256Sum\" SET WRAPPER_SHA_256_SUM=%%B\r\n)\r\nIF NOT %WRAPPER_SHA_256_SUM%==\"\" (\r\n    powershell -Command \"&{\"^\r\n       \"$hash = (Get-FileHash \\\"%WRAPPER_JAR%\\\" -Algorithm SHA256).Hash.ToLower();\"^\r\n       \"If('%WRAPPER_SHA_256_SUM%' -ne $hash){\"^\r\n       \"  Write-Output 'Error: Failed to validate Maven wrapper SHA-256, your Maven wrapper might be compromised.';\"^\r\n       \"  Write-Output 'Investigate or delete %WRAPPER_JAR% to attempt a clean download.';\"^\r\n       \"  Write-Output 'If you updated your Maven version, you need to update the specified wrapperSha256Sum property.';\"^\r\n       \"  exit 1;\"^\r\n       \"}\"^\r\n       \"}\"\r\n    if ERRORLEVEL 1 goto error\r\n)\r\n\r\n@REM Provide a \"standardized\" way to retrieve the CLI args that will\r\n@REM work with both Windows and non-Windows executions.\r\nset MAVEN_CMD_LINE_ARGS=%*\r\n\r\n%MAVEN_JAVA_EXE% ^\r\n  %JVM_CONFIG_MAVEN_PROPS% ^\r\n  %MAVEN_OPTS% ^\r\n  %MAVEN_DEBUG_OPTS% ^\r\n  -classpath %WRAPPER_JAR% ^\r\n  \"-Dmaven.multiModuleProjectDirectory=%MAVEN_PROJECTBASEDIR%\" ^\r\n  %WRAPPER_LAUNCHER% %MAVEN_CONFIG% %*\r\nif ERRORLEVEL 1 goto error\r\ngoto end\r\n\r\n:error\r\nset ERROR_CODE=1\r\n\r\n:end\r\n@endlocal & set ERROR_CODE=%ERROR_CODE%\r\n\r\nif not \"%MAVEN_SKIP_RC%\"==\"\" goto skipRcPost\r\n@REM check for post script, once with legacy .bat ending and once with .cmd ending\r\nif exist \"%USERPROFILE%\\mavenrc_post.bat\" call \"%USERPROFILE%\\mavenrc_post.bat\"\r\nif exist \"%USERPROFILE%\\mavenrc_post.cmd\" call \"%USERPROFILE%\\mavenrc_post.cmd\"\r\n:skipRcPost\r\n\r\n@REM pause the script if MAVEN_BATCH_PAUSE is set to 'on'\r\nif \"%MAVEN_BATCH_PAUSE%\"==\"on\" pause\r\n\r\nif \"%MAVEN_TERMINATE_CMD%\"==\"on\" exit %ERROR_CODE%\r\n\r\ncmd /C exit /B %ERROR_CODE%\r\n"
        },
        {
          "name": "pom.xml",
          "type": "blob",
          "size": 1.96875,
          "content": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!--\nLicensed to the Apache Software Foundation (ASF) under one or more\ncontributor license agreements.  See the NOTICE file distributed with\nthis work for additional information regarding copyright ownership.\nThe ASF licenses this file to You under the Apache License, Version 2.0\n(the \"License\"); you may not use this file except in compliance with\nthe License.  You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n-->\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n\n  <parent>\n    <groupId>org.apache</groupId>\n    <artifactId>apache</artifactId>\n    <version>23</version>\n  </parent>\n\n  <modelVersion>4.0.0</modelVersion>\n  <groupId>org.apache.flume</groupId>\n  <artifactId>flume-project</artifactId>\n  <version>1.11.1-SNAPSHOT</version>\n  <packaging>pom</packaging>\n\n  <name>Apache Flume Project</name>\n\n  <modules>\n    <module>flume-bom</module>\n    <module>flume-parent</module>\n    <module>flume-ng-core</module>\n    <module>flume-ng-configuration</module>\n    <module>flume-ng-embedded-agent</module>\n    <module>flume-ng-sinks</module>\n    <module>flume-ng-sources</module>\n    <module>flume-ng-node</module>\n    <module>flume-ng-dist</module>\n    <module>flume-ng-channels</module>\n    <module>flume-ng-clients</module>\n    <module>flume-ng-sdk</module>\n    <module>flume-ng-tests</module>\n    <module>flume-tools</module>\n    <module>flume-ng-auth</module>\n    <module>flume-ng-configfilters</module>\n    <module>build-support</module>\n  </modules>\n\n</project>\n"
        }
      ]
    }
  ]
}