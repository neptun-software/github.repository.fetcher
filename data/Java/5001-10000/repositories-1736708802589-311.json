{
  "metadata": {
    "timestamp": 1736708802589,
    "page": 311,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjMyMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "apache/hbase",
      "stars": 5264,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".asf.yaml",
          "type": "blob",
          "size": 1.54296875,
          "content": "# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# This file controls the integration of HBase project with ASF infrastructure. Refer to\n# https://cwiki.apache.org/confluence/display/INFRA/.asf.yaml+features+for+git+repositories for\n# details. Be careful when changing the contents of this file since it may affect many developers\n# of the project and make sure to discuss the changes with dev@ before committing.\n\ngithub:\n  description: \"Apache HBase\"\n  homepage: https://hbase.apache.org/\n  labels:\n    - database\n    - java\n    - hbase\n  features:\n    wiki: false\n    issues: false\n    projects: false\n  enabled_merge_buttons:\n    squash:  true\n    merge:   false\n    rebase:  true\nnotifications:\n  commits:      commits@hbase.apache.org\n  issues:       issues@hbase.apache.org\n  pullrequests: issues@hbase.apache.org\n  jira_options: link label\n"
        },
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 32.2470703125,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n[*]\ncharset = utf-8\nend_of_line = lf\nindent_size = 2\nindent_style = space\ninsert_final_newline = true\nmax_line_length = 100\ntab_width = 2\nij_continuation_indent_size = 2\nij_formatter_off_tag = @formatter:off\nij_formatter_on_tag = @formatter:on\nij_formatter_tags_enabled = false\nij_smart_tabs = false\nij_wrap_on_typing = false\n\n[*.css]\nij_css_align_closing_brace_with_properties = false\nij_css_blank_lines_around_nested_selector = 1\nij_css_blank_lines_between_blocks = 1\nij_css_brace_placement = 0\nij_css_hex_color_long_format = false\nij_css_hex_color_lower_case = false\nij_css_hex_color_short_format = false\nij_css_hex_color_upper_case = false\nij_css_keep_blank_lines_in_code = 2\nij_css_keep_indents_on_empty_lines = false\nij_css_keep_single_line_blocks = false\nij_css_properties_order = font,font-family,font-size,font-weight,font-style,font-variant,font-size-adjust,font-stretch,line-height,position,z-index,top,right,bottom,left,display,visibility,float,clear,overflow,overflow-x,overflow-y,clip,zoom,align-content,align-items,align-self,flex,flex-flow,flex-basis,flex-direction,flex-grow,flex-shrink,flex-wrap,justify-content,order,box-sizing,width,min-width,max-width,height,min-height,max-height,margin,margin-top,margin-right,margin-bottom,margin-left,padding,padding-top,padding-right,padding-bottom,padding-left,table-layout,empty-cells,caption-side,border-spacing,border-collapse,list-style,list-style-position,list-style-type,list-style-image,content,quotes,counter-reset,counter-increment,resize,cursor,user-select,nav-index,nav-up,nav-right,nav-down,nav-left,transition,transition-delay,transition-timing-function,transition-duration,transition-property,transform,transform-origin,animation,animation-name,animation-duration,animation-play-state,animation-timing-function,animation-delay,animation-iteration-count,animation-direction,text-align,text-align-last,vertical-align,white-space,text-decoration,text-emphasis,text-emphasis-color,text-emphasis-style,text-emphasis-position,text-indent,text-justify,letter-spacing,word-spacing,text-outline,text-transform,text-wrap,text-overflow,text-overflow-ellipsis,text-overflow-mode,word-wrap,word-break,tab-size,hyphens,pointer-events,opacity,color,border,border-width,border-style,border-color,border-top,border-top-width,border-top-style,border-top-color,border-right,border-right-width,border-right-style,border-right-color,border-bottom,border-bottom-width,border-bottom-style,border-bottom-color,border-left,border-left-width,border-left-style,border-left-color,border-radius,border-top-left-radius,border-top-right-radius,border-bottom-right-radius,border-bottom-left-radius,border-image,border-image-source,border-image-slice,border-image-width,border-image-outset,border-image-repeat,outline,outline-width,outline-style,outline-color,outline-offset,background,background-color,background-image,background-repeat,background-attachment,background-position,background-position-x,background-position-y,background-clip,background-origin,background-size,box-decoration-break,box-shadow,text-shadow\nij_css_space_after_colon = true\nij_css_space_before_opening_brace = true\nij_css_value_alignment = 0\n\n[*.java]\nij_java_align_consecutive_assignments = false\nij_java_align_consecutive_variable_declarations = false\nij_java_align_group_field_declarations = false\nij_java_align_multiline_annotation_parameters = false\nij_java_align_multiline_array_initializer_expression = false\nij_java_align_multiline_assignment = false\nij_java_align_multiline_binary_operation = false\nij_java_align_multiline_chained_methods = false\nij_java_align_multiline_extends_list = false\nij_java_align_multiline_for = true\nij_java_align_multiline_method_parentheses = false\nij_java_align_multiline_parameters = false\nij_java_align_multiline_parameters_in_calls = false\nij_java_align_multiline_parenthesized_expression = false\nij_java_align_multiline_resources = false\nij_java_align_multiline_ternary_operation = false\nij_java_align_multiline_throws_list = false\nij_java_align_subsequent_simple_methods = false\nij_java_align_throws_keyword = false\nij_java_annotation_parameter_wrap = off\nij_java_array_initializer_new_line_after_left_brace = false\nij_java_array_initializer_right_brace_on_new_line = false\nij_java_array_initializer_wrap = normal\nij_java_assert_statement_colon_on_next_line = false\nij_java_assert_statement_wrap = off\nij_java_assignment_wrap = normal\nij_java_binary_operation_sign_on_next_line = true\nij_java_binary_operation_wrap = normal\nij_java_blank_lines_after_anonymous_class_header = 0\nij_java_blank_lines_after_class_header = 0\nij_java_blank_lines_after_imports = 1\nij_java_blank_lines_after_package = 1\nij_java_blank_lines_around_class = 1\nij_java_blank_lines_around_field = 0\nij_java_blank_lines_around_field_in_interface = 0\nij_java_blank_lines_around_initializer = 1\nij_java_blank_lines_around_method = 1\nij_java_blank_lines_around_method_in_interface = 1\nij_java_blank_lines_before_class_end = 0\nij_java_blank_lines_before_imports = 1\nij_java_blank_lines_before_method_body = 0\nij_java_blank_lines_before_package = 0\nij_java_block_brace_style = end_of_line\nij_java_block_comment_at_first_column = true\nij_java_call_parameters_new_line_after_left_paren = false\nij_java_call_parameters_right_paren_on_new_line = false\nij_java_call_parameters_wrap = normal\nij_java_case_statement_on_separate_line = true\nij_java_catch_on_new_line = false\nij_java_class_annotation_wrap = normal\nij_java_class_brace_style = end_of_line\nij_java_class_count_to_use_import_on_demand = 999\nij_java_class_names_in_javadoc = 1\nij_java_do_not_indent_top_level_class_members = false\nij_java_do_not_wrap_after_single_annotation = false\nij_java_do_while_brace_force = always\nij_java_doc_add_blank_line_after_description = true\nij_java_doc_add_blank_line_after_param_comments = false\nij_java_doc_add_blank_line_after_return = false\nij_java_doc_add_p_tag_on_empty_lines = true\nij_java_doc_align_exception_comments = true\nij_java_doc_align_param_comments = true\nij_java_doc_do_not_wrap_if_one_line = false\nij_java_doc_enable_formatting = true\nij_java_doc_enable_leading_asterisks = true\nij_java_doc_indent_on_continuation = false\nij_java_doc_keep_empty_lines = false\nij_java_doc_keep_empty_parameter_tag = true\nij_java_doc_keep_empty_return_tag = true\nij_java_doc_keep_empty_throws_tag = true\nij_java_doc_keep_invalid_tags = true\nij_java_doc_param_description_on_new_line = false\nij_java_doc_preserve_line_breaks = false\nij_java_doc_use_throws_not_exception_tag = true\nij_java_else_on_new_line = false\nij_java_entity_dd_suffix = EJB\nij_java_entity_eb_suffix = Bean\nij_java_entity_hi_suffix = Home\nij_java_entity_lhi_prefix = Local\nij_java_entity_lhi_suffix = Home\nij_java_entity_li_prefix = Local\nij_java_entity_pk_class = java.lang.String\nij_java_entity_vo_suffix = VO\nij_java_enum_constants_wrap = off\nij_java_extends_keyword_wrap = normal\nij_java_extends_list_wrap = normal\nij_java_field_annotation_wrap = normal\nij_java_finally_on_new_line = false\nij_java_for_brace_force = always\nij_java_for_statement_new_line_after_left_paren = false\nij_java_for_statement_right_paren_on_new_line = false\nij_java_for_statement_wrap = off\nij_java_generate_final_locals = false\nij_java_generate_final_parameters = false\nij_java_if_brace_force = always\nij_java_imports_layout = $*,*,org.apache.hbase.thirdparty.**,org.apache.hadoop.hbase.shaded.**\nij_java_indent_case_from_switch = true\nij_java_insert_inner_class_imports = false\nij_java_insert_override_annotation = true\nij_java_keep_blank_lines_before_right_brace = 1\nij_java_keep_blank_lines_between_package_declaration_and_header = 2\nij_java_keep_blank_lines_in_code = 1\nij_java_keep_blank_lines_in_declarations = 1\nij_java_keep_control_statement_in_one_line = true\nij_java_keep_first_column_comment = false\nij_java_keep_indents_on_empty_lines = false\nij_java_keep_line_breaks = false\nij_java_keep_multiple_expressions_in_one_line = false\nij_java_keep_simple_blocks_in_one_line = false\nij_java_keep_simple_classes_in_one_line = false\nij_java_keep_simple_lambdas_in_one_line = false\nij_java_keep_simple_methods_in_one_line = false\nij_java_lambda_brace_style = end_of_line\nij_java_layout_static_imports_separately = true\nij_java_line_comment_add_space = false\nij_java_line_comment_at_first_column = true\nij_java_message_dd_suffix = EJB\nij_java_message_eb_suffix = Bean\nij_java_method_annotation_wrap = normal\nij_java_method_brace_style = end_of_line\nij_java_method_call_chain_wrap = normal\nij_java_method_parameters_new_line_after_left_paren = false\nij_java_method_parameters_right_paren_on_new_line = false\nij_java_method_parameters_wrap = normal\nij_java_modifier_list_wrap = false\nij_java_names_count_to_use_import_on_demand = 999\nij_java_parameter_annotation_wrap = normal\nij_java_parentheses_expression_new_line_after_left_paren = false\nij_java_parentheses_expression_right_paren_on_new_line = false\nij_java_place_assignment_sign_on_next_line = false\nij_java_prefer_longer_names = true\nij_java_prefer_parameters_wrap = false\nij_java_repeat_synchronized = true\nij_java_replace_instanceof_and_cast = false\nij_java_replace_null_check = true\nij_java_replace_sum_lambda_with_method_ref = true\nij_java_resource_list_new_line_after_left_paren = false\nij_java_resource_list_right_paren_on_new_line = false\nij_java_resource_list_wrap = on_every_item\nij_java_session_dd_suffix = EJB\nij_java_session_eb_suffix = Bean\nij_java_session_hi_suffix = Home\nij_java_session_lhi_prefix = Local\nij_java_session_lhi_suffix = Home\nij_java_session_li_prefix = Local\nij_java_session_si_suffix = Service\nij_java_space_after_closing_angle_bracket_in_type_argument = false\nij_java_space_after_colon = true\nij_java_space_after_comma = true\nij_java_space_after_comma_in_type_arguments = true\nij_java_space_after_for_semicolon = true\nij_java_space_after_quest = true\nij_java_space_after_type_cast = true\nij_java_space_before_annotation_array_initializer_left_brace = false\nij_java_space_before_annotation_parameter_list = false\nij_java_space_before_array_initializer_left_brace = true\nij_java_space_before_catch_keyword = true\nij_java_space_before_catch_left_brace = true\nij_java_space_before_catch_parentheses = true\nij_java_space_before_class_left_brace = true\nij_java_space_before_colon = true\nij_java_space_before_colon_in_foreach = true\nij_java_space_before_comma = false\nij_java_space_before_do_left_brace = true\nij_java_space_before_else_keyword = true\nij_java_space_before_else_left_brace = true\nij_java_space_before_finally_keyword = true\nij_java_space_before_finally_left_brace = true\nij_java_space_before_for_left_brace = true\nij_java_space_before_for_parentheses = true\nij_java_space_before_for_semicolon = false\nij_java_space_before_if_left_brace = true\nij_java_space_before_if_parentheses = true\nij_java_space_before_method_call_parentheses = false\nij_java_space_before_method_left_brace = true\nij_java_space_before_method_parentheses = false\nij_java_space_before_opening_angle_bracket_in_type_parameter = false\nij_java_space_before_quest = true\nij_java_space_before_switch_left_brace = true\nij_java_space_before_switch_parentheses = true\nij_java_space_before_synchronized_left_brace = true\nij_java_space_before_synchronized_parentheses = true\nij_java_space_before_try_left_brace = true\nij_java_space_before_try_parentheses = true\nij_java_space_before_type_parameter_list = false\nij_java_space_before_while_keyword = true\nij_java_space_before_while_left_brace = true\nij_java_space_before_while_parentheses = true\nij_java_space_inside_one_line_enum_braces = false\nij_java_space_within_empty_array_initializer_braces = false\nij_java_space_within_empty_method_call_parentheses = false\nij_java_space_within_empty_method_parentheses = false\nij_java_spaces_around_additive_operators = true\nij_java_spaces_around_assignment_operators = true\nij_java_spaces_around_bitwise_operators = true\nij_java_spaces_around_equality_operators = true\nij_java_spaces_around_lambda_arrow = true\nij_java_spaces_around_logical_operators = true\nij_java_spaces_around_method_ref_dbl_colon = false\nij_java_spaces_around_multiplicative_operators = true\nij_java_spaces_around_relational_operators = true\nij_java_spaces_around_shift_operators = true\nij_java_spaces_around_type_bounds_in_type_parameters = true\nij_java_spaces_around_unary_operator = false\nij_java_spaces_within_angle_brackets = false\nij_java_spaces_within_annotation_parentheses = false\nij_java_spaces_within_array_initializer_braces = true\nij_java_spaces_within_braces = false\nij_java_spaces_within_brackets = false\nij_java_spaces_within_cast_parentheses = false\nij_java_spaces_within_catch_parentheses = false\nij_java_spaces_within_for_parentheses = false\nij_java_spaces_within_if_parentheses = false\nij_java_spaces_within_method_call_parentheses = false\nij_java_spaces_within_method_parentheses = false\nij_java_spaces_within_parentheses = false\nij_java_spaces_within_switch_parentheses = false\nij_java_spaces_within_synchronized_parentheses = false\nij_java_spaces_within_try_parentheses = false\nij_java_spaces_within_while_parentheses = false\nij_java_special_else_if_treatment = true\nij_java_subclass_name_suffix = Impl\nij_java_ternary_operation_signs_on_next_line = false\nij_java_ternary_operation_wrap = on_every_item\nij_java_test_name_suffix = Test\nij_java_throws_keyword_wrap = normal\nij_java_throws_list_wrap = normal\nij_java_use_external_annotations = false\nij_java_use_fq_class_names = false\nij_java_use_single_class_imports = true\nij_java_variable_annotation_wrap = normal\nij_java_visibility = public\nij_java_while_brace_force = always\nij_java_while_on_new_line = false\nij_java_wrap_comments = false\nij_java_wrap_first_method_in_call_chain = false\nij_java_wrap_long_lines = false\n\n[*.proto]\nij_proto_keep_indents_on_empty_lines = false\n\n[.editorconfig]\nij_editorconfig_align_group_field_declarations = false\nij_editorconfig_space_after_colon = false\nij_editorconfig_space_after_comma = true\nij_editorconfig_space_before_colon = false\nij_editorconfig_space_before_comma = false\nij_editorconfig_spaces_around_assignment_operators = true\n\n[{*.cjs,*.js}]\nij_javascript_align_imports = false\nij_javascript_align_multiline_array_initializer_expression = false\nij_javascript_align_multiline_binary_operation = false\nij_javascript_align_multiline_chained_methods = false\nij_javascript_align_multiline_extends_list = false\nij_javascript_align_multiline_for = true\nij_javascript_align_multiline_parameters = true\nij_javascript_align_multiline_parameters_in_calls = false\nij_javascript_align_multiline_ternary_operation = false\nij_javascript_align_object_properties = 0\nij_javascript_align_union_types = false\nij_javascript_align_var_statements = 0\nij_javascript_array_initializer_new_line_after_left_brace = false\nij_javascript_array_initializer_right_brace_on_new_line = false\nij_javascript_array_initializer_wrap = off\nij_javascript_assignment_wrap = off\nij_javascript_binary_operation_sign_on_next_line = false\nij_javascript_binary_operation_wrap = off\nij_javascript_blacklist_imports = rxjs/Rx,node_modules/**/*,@angular/material,@angular/material/typings/**\nij_javascript_blank_lines_after_imports = 1\nij_javascript_blank_lines_around_class = 1\nij_javascript_blank_lines_around_field = 0\nij_javascript_blank_lines_around_function = 1\nij_javascript_blank_lines_around_method = 1\nij_javascript_block_brace_style = end_of_line\nij_javascript_call_parameters_new_line_after_left_paren = false\nij_javascript_call_parameters_right_paren_on_new_line = false\nij_javascript_call_parameters_wrap = off\nij_javascript_catch_on_new_line = false\nij_javascript_chained_call_dot_on_new_line = true\nij_javascript_class_brace_style = end_of_line\nij_javascript_comma_on_new_line = false\nij_javascript_do_while_brace_force = never\nij_javascript_else_on_new_line = false\nij_javascript_enforce_trailing_comma = keep\nij_javascript_extends_keyword_wrap = off\nij_javascript_extends_list_wrap = off\nij_javascript_field_prefix = _\nij_javascript_file_name_style = relaxed\nij_javascript_finally_on_new_line = false\nij_javascript_for_brace_force = never\nij_javascript_for_statement_new_line_after_left_paren = false\nij_javascript_for_statement_right_paren_on_new_line = false\nij_javascript_for_statement_wrap = off\nij_javascript_force_quote_style = false\nij_javascript_force_semicolon_style = false\nij_javascript_function_expression_brace_style = end_of_line\nij_javascript_if_brace_force = never\nij_javascript_import_merge_members = global\nij_javascript_import_prefer_absolute_path = global\nij_javascript_import_sort_members = true\nij_javascript_import_sort_module_name = false\nij_javascript_import_use_node_resolution = true\nij_javascript_imports_wrap = on_every_item\nij_javascript_indent_case_from_switch = true\nij_javascript_indent_chained_calls = true\nij_javascript_indent_package_children = 0\nij_javascript_jsx_attribute_value = braces\nij_javascript_keep_blank_lines_in_code = 2\nij_javascript_keep_first_column_comment = true\nij_javascript_keep_indents_on_empty_lines = false\nij_javascript_keep_line_breaks = true\nij_javascript_keep_simple_blocks_in_one_line = false\nij_javascript_keep_simple_methods_in_one_line = false\nij_javascript_line_comment_add_space = true\nij_javascript_line_comment_at_first_column = false\nij_javascript_method_brace_style = end_of_line\nij_javascript_method_call_chain_wrap = off\nij_javascript_method_parameters_new_line_after_left_paren = false\nij_javascript_method_parameters_right_paren_on_new_line = false\nij_javascript_method_parameters_wrap = off\nij_javascript_object_literal_wrap = on_every_item\nij_javascript_parentheses_expression_new_line_after_left_paren = false\nij_javascript_parentheses_expression_right_paren_on_new_line = false\nij_javascript_place_assignment_sign_on_next_line = false\nij_javascript_prefer_as_type_cast = false\nij_javascript_prefer_parameters_wrap = false\nij_javascript_reformat_c_style_comments = false\nij_javascript_space_after_colon = true\nij_javascript_space_after_comma = true\nij_javascript_space_after_dots_in_rest_parameter = false\nij_javascript_space_after_generator_mult = true\nij_javascript_space_after_property_colon = true\nij_javascript_space_after_quest = true\nij_javascript_space_after_type_colon = true\nij_javascript_space_after_unary_not = false\nij_javascript_space_before_async_arrow_lparen = true\nij_javascript_space_before_catch_keyword = true\nij_javascript_space_before_catch_left_brace = true\nij_javascript_space_before_catch_parentheses = true\nij_javascript_space_before_class_lbrace = true\nij_javascript_space_before_class_left_brace = true\nij_javascript_space_before_colon = true\nij_javascript_space_before_comma = false\nij_javascript_space_before_do_left_brace = true\nij_javascript_space_before_else_keyword = true\nij_javascript_space_before_else_left_brace = true\nij_javascript_space_before_finally_keyword = true\nij_javascript_space_before_finally_left_brace = true\nij_javascript_space_before_for_left_brace = true\nij_javascript_space_before_for_parentheses = true\nij_javascript_space_before_for_semicolon = false\nij_javascript_space_before_function_left_parenth = true\nij_javascript_space_before_generator_mult = false\nij_javascript_space_before_if_left_brace = true\nij_javascript_space_before_if_parentheses = true\nij_javascript_space_before_method_call_parentheses = false\nij_javascript_space_before_method_left_brace = true\nij_javascript_space_before_method_parentheses = false\nij_javascript_space_before_property_colon = false\nij_javascript_space_before_quest = true\nij_javascript_space_before_switch_left_brace = true\nij_javascript_space_before_switch_parentheses = true\nij_javascript_space_before_try_left_brace = true\nij_javascript_space_before_type_colon = false\nij_javascript_space_before_unary_not = false\nij_javascript_space_before_while_keyword = true\nij_javascript_space_before_while_left_brace = true\nij_javascript_space_before_while_parentheses = true\nij_javascript_spaces_around_additive_operators = true\nij_javascript_spaces_around_arrow_function_operator = true\nij_javascript_spaces_around_assignment_operators = true\nij_javascript_spaces_around_bitwise_operators = true\nij_javascript_spaces_around_equality_operators = true\nij_javascript_spaces_around_logical_operators = true\nij_javascript_spaces_around_multiplicative_operators = true\nij_javascript_spaces_around_relational_operators = true\nij_javascript_spaces_around_shift_operators = true\nij_javascript_spaces_around_unary_operator = false\nij_javascript_spaces_within_array_initializer_brackets = false\nij_javascript_spaces_within_brackets = false\nij_javascript_spaces_within_catch_parentheses = false\nij_javascript_spaces_within_for_parentheses = false\nij_javascript_spaces_within_if_parentheses = false\nij_javascript_spaces_within_imports = false\nij_javascript_spaces_within_interpolation_expressions = false\nij_javascript_spaces_within_method_call_parentheses = false\nij_javascript_spaces_within_method_parentheses = false\nij_javascript_spaces_within_object_literal_braces = false\nij_javascript_spaces_within_object_type_braces = true\nij_javascript_spaces_within_parentheses = false\nij_javascript_spaces_within_switch_parentheses = false\nij_javascript_spaces_within_type_assertion = false\nij_javascript_spaces_within_union_types = true\nij_javascript_spaces_within_while_parentheses = false\nij_javascript_special_else_if_treatment = true\nij_javascript_ternary_operation_signs_on_next_line = false\nij_javascript_ternary_operation_wrap = off\nij_javascript_union_types_wrap = on_every_item\nij_javascript_use_chained_calls_group_indents = false\nij_javascript_use_double_quotes = true\nij_javascript_use_explicit_js_extension = global\nij_javascript_use_path_mapping = always\nij_javascript_use_public_modifier = false\nij_javascript_use_semicolon_after_statement = true\nij_javascript_var_declaration_wrap = normal\nij_javascript_while_brace_force = never\nij_javascript_while_on_new_line = false\nij_javascript_wrap_comments = false\n\n[{*.gradle,*.groovy,*.gant,*.gdsl,*.gy,*.gson,Jenkinsfile*}]\nindent_size = 4\nij_groovy_align_group_field_declarations = false\nij_groovy_align_multiline_array_initializer_expression = false\nij_groovy_align_multiline_assignment = false\nij_groovy_align_multiline_binary_operation = false\nij_groovy_align_multiline_chained_methods = false\nij_groovy_align_multiline_extends_list = false\nij_groovy_align_multiline_for = true\nij_groovy_align_multiline_method_parentheses = false\nij_groovy_align_multiline_parameters = true\nij_groovy_align_multiline_parameters_in_calls = false\nij_groovy_align_multiline_resources = true\nij_groovy_align_multiline_ternary_operation = false\nij_groovy_align_multiline_throws_list = false\nij_groovy_align_throws_keyword = false\nij_groovy_array_initializer_new_line_after_left_brace = false\nij_groovy_array_initializer_right_brace_on_new_line = false\nij_groovy_array_initializer_wrap = off\nij_groovy_assert_statement_wrap = off\nij_groovy_assignment_wrap = off\nij_groovy_binary_operation_wrap = off\nij_groovy_blank_lines_after_class_header = 0\nij_groovy_blank_lines_after_imports = 1\nij_groovy_blank_lines_after_package = 1\nij_groovy_blank_lines_around_class = 1\nij_groovy_blank_lines_around_field = 0\nij_groovy_blank_lines_around_field_in_interface = 0\nij_groovy_blank_lines_around_method = 1\nij_groovy_blank_lines_around_method_in_interface = 1\nij_groovy_blank_lines_before_imports = 1\nij_groovy_blank_lines_before_method_body = 0\nij_groovy_blank_lines_before_package = 0\nij_groovy_block_brace_style = end_of_line\nij_groovy_block_comment_at_first_column = true\nij_groovy_call_parameters_new_line_after_left_paren = false\nij_groovy_call_parameters_right_paren_on_new_line = false\nij_groovy_call_parameters_wrap = off\nij_groovy_catch_on_new_line = false\nij_groovy_class_annotation_wrap = split_into_lines\nij_groovy_class_brace_style = end_of_line\nij_groovy_do_while_brace_force = never\nij_groovy_else_on_new_line = false\nij_groovy_enum_constants_wrap = off\nij_groovy_extends_keyword_wrap = off\nij_groovy_extends_list_wrap = off\nij_groovy_field_annotation_wrap = split_into_lines\nij_groovy_finally_on_new_line = false\nij_groovy_for_brace_force = never\nij_groovy_for_statement_new_line_after_left_paren = false\nij_groovy_for_statement_right_paren_on_new_line = false\nij_groovy_for_statement_wrap = off\nij_groovy_if_brace_force = never\nij_groovy_indent_case_from_switch = true\nij_groovy_keep_blank_lines_before_right_brace = 2\nij_groovy_keep_blank_lines_in_code = 2\nij_groovy_keep_blank_lines_in_declarations = 2\nij_groovy_keep_control_statement_in_one_line = true\nij_groovy_keep_first_column_comment = true\nij_groovy_keep_indents_on_empty_lines = false\nij_groovy_keep_line_breaks = true\nij_groovy_keep_multiple_expressions_in_one_line = false\nij_groovy_keep_simple_blocks_in_one_line = false\nij_groovy_keep_simple_classes_in_one_line = true\nij_groovy_keep_simple_lambdas_in_one_line = true\nij_groovy_keep_simple_methods_in_one_line = true\nij_groovy_lambda_brace_style = end_of_line\nij_groovy_line_comment_add_space = false\nij_groovy_line_comment_at_first_column = true\nij_groovy_method_annotation_wrap = split_into_lines\nij_groovy_method_brace_style = end_of_line\nij_groovy_method_call_chain_wrap = off\nij_groovy_method_parameters_new_line_after_left_paren = false\nij_groovy_method_parameters_right_paren_on_new_line = false\nij_groovy_method_parameters_wrap = off\nij_groovy_modifier_list_wrap = false\nij_groovy_parameter_annotation_wrap = off\nij_groovy_parentheses_expression_new_line_after_left_paren = false\nij_groovy_parentheses_expression_right_paren_on_new_line = false\nij_groovy_prefer_parameters_wrap = false\nij_groovy_resource_list_new_line_after_left_paren = false\nij_groovy_resource_list_right_paren_on_new_line = false\nij_groovy_resource_list_wrap = off\nij_groovy_space_after_colon = true\nij_groovy_space_after_comma = true\nij_groovy_space_after_comma_in_type_arguments = true\nij_groovy_space_after_for_semicolon = true\nij_groovy_space_after_quest = true\nij_groovy_space_after_type_cast = true\nij_groovy_space_before_annotation_parameter_list = false\nij_groovy_space_before_array_initializer_left_brace = false\nij_groovy_space_before_catch_keyword = true\nij_groovy_space_before_catch_left_brace = true\nij_groovy_space_before_catch_parentheses = true\nij_groovy_space_before_class_left_brace = true\nij_groovy_space_before_colon = true\nij_groovy_space_before_comma = false\nij_groovy_space_before_do_left_brace = true\nij_groovy_space_before_else_keyword = true\nij_groovy_space_before_else_left_brace = true\nij_groovy_space_before_finally_keyword = true\nij_groovy_space_before_finally_left_brace = true\nij_groovy_space_before_for_left_brace = true\nij_groovy_space_before_for_parentheses = true\nij_groovy_space_before_for_semicolon = false\nij_groovy_space_before_if_left_brace = true\nij_groovy_space_before_if_parentheses = true\nij_groovy_space_before_method_call_parentheses = false\nij_groovy_space_before_method_left_brace = true\nij_groovy_space_before_method_parentheses = false\nij_groovy_space_before_quest = true\nij_groovy_space_before_switch_left_brace = true\nij_groovy_space_before_switch_parentheses = true\nij_groovy_space_before_synchronized_left_brace = true\nij_groovy_space_before_synchronized_parentheses = true\nij_groovy_space_before_try_left_brace = true\nij_groovy_space_before_try_parentheses = true\nij_groovy_space_before_while_keyword = true\nij_groovy_space_before_while_left_brace = true\nij_groovy_space_before_while_parentheses = true\nij_groovy_space_within_empty_array_initializer_braces = false\nij_groovy_space_within_empty_method_call_parentheses = false\nij_groovy_spaces_around_additive_operators = true\nij_groovy_spaces_around_assignment_operators = true\nij_groovy_spaces_around_bitwise_operators = true\nij_groovy_spaces_around_equality_operators = true\nij_groovy_spaces_around_lambda_arrow = true\nij_groovy_spaces_around_logical_operators = true\nij_groovy_spaces_around_multiplicative_operators = true\nij_groovy_spaces_around_relational_operators = true\nij_groovy_spaces_around_shift_operators = true\nij_groovy_spaces_within_annotation_parentheses = false\nij_groovy_spaces_within_array_initializer_braces = false\nij_groovy_spaces_within_braces = true\nij_groovy_spaces_within_brackets = false\nij_groovy_spaces_within_cast_parentheses = false\nij_groovy_spaces_within_catch_parentheses = false\nij_groovy_spaces_within_for_parentheses = false\nij_groovy_spaces_within_if_parentheses = false\nij_groovy_spaces_within_method_call_parentheses = false\nij_groovy_spaces_within_method_parentheses = false\nij_groovy_spaces_within_parentheses = false\nij_groovy_spaces_within_switch_parentheses = false\nij_groovy_spaces_within_synchronized_parentheses = false\nij_groovy_spaces_within_try_parentheses = false\nij_groovy_spaces_within_while_parentheses = false\nij_groovy_special_else_if_treatment = true\nij_groovy_ternary_operation_wrap = off\nij_groovy_throws_keyword_wrap = off\nij_groovy_throws_list_wrap = off\nij_groovy_variable_annotation_wrap = off\nij_groovy_while_brace_force = never\nij_groovy_while_on_new_line = false\nij_groovy_wrap_long_lines = false\n\n[{*.html,*.sht,*.shtm,*.shtml,*.ng,*.htm}]\nij_html_add_new_line_before_tags = body,div,p,form,h1,h2,h3\nij_html_align_attributes = true\nij_html_align_text = false\nij_html_attribute_wrap = normal\nij_html_block_comment_at_first_column = true\nij_html_do_not_align_children_of_min_lines = 0\nij_html_do_not_break_if_inline_tags = title,h1,h2,h3,h4,h5,h6,p\nij_html_do_not_indent_children_of_tags = html,body,thead,tbody,tfoot\nij_html_enforce_quotes = false\nij_html_inline_tags = a,abbr,acronym,b,basefont,bdo,big,br,cite,cite,code,dfn,em,font,i,img,input,kbd,label,q,s,samp,select,small,span,strike,strong,sub,sup,textarea,tt,u,var\nij_html_keep_blank_lines = 2\nij_html_keep_indents_on_empty_lines = false\nij_html_keep_line_breaks = true\nij_html_keep_line_breaks_in_text = true\nij_html_keep_whitespaces = false\nij_html_keep_whitespaces_inside = span,pre,textarea\nij_html_line_comment_at_first_column = true\nij_html_new_line_after_last_attribute = never\nij_html_new_line_before_first_attribute = never\nij_html_quote_style = double\nij_html_remove_new_line_before_tags = br\nij_html_space_after_tag_name = false\nij_html_space_around_equality_in_attribute = false\nij_html_space_inside_empty_tag = false\nij_html_text_wrap = normal\n\n[{*.jhm,*.xjb,*.rng,*.wsdd,*.wsdl,*.fxml,*.plan,*.bpmn,*.pom,*.xslt,*.jrxml,*.ant,*.xul,*.xsl,*.xsd,*.tld,*.jnlp,*.wadl,*.xml}]\nij_xml_block_comment_at_first_column = true\nij_xml_keep_indents_on_empty_lines = false\nij_xml_line_comment_at_first_column = true\n\n[{*.vsl,*.vm,*.ft}]\nij_vtl_keep_indents_on_empty_lines = false\n\n[{*.xjsp,*.tagf,*.tag,*.jsf,*.jsp,*.jspf}]\nij_jsp_jsp_prefer_comma_separated_import_list = false\nij_jsp_keep_indents_on_empty_lines = false\n\n[{*.yml,*.yaml}]\nij_yaml_keep_indents_on_empty_lines = false\nij_yaml_keep_line_breaks = true\n\n[{*.zsh,*.bash,*.sh}]\nij_shell_binary_ops_start_line = false\nij_shell_keep_column_alignment_padding = false\nij_shell_minify_program = false\nij_shell_redirect_followed_by_space = false\nij_shell_switch_cases_indented = false\n\n[{.asciidoctorconfig,*.ad,*.adoc,*.asciidoc}]\nij_asciidoc_formatting_enabled = true\nij_asciidoc_one_sentence_per_line = true\n\n[{messages.*,spring.schemas,messages,spring.handlers,*.properties}]\nij_properties_align_group_field_declarations = false\n\n[{rcov,rake,cucumber,rails,spec,spork,capfile,gemfile,rakefile,guardfile,isolate,vagrantfile,Puppetfile,*.thor,*.gemspec,*.rb,*.rake,*.rbw,*.ru,*.jbuilder}]\nij_continuation_indent_size = 4\nij_ruby_align_group_field_declarations = false\nij_ruby_align_multiline_parameters = true\nij_ruby_blank_lines_around_method = 1\nij_ruby_convert_brace_block_by_enter = true\nij_ruby_force_newlines_around_visibility_mods = true\nij_ruby_indent_private_methods = false\nij_ruby_indent_protected_methods = false\nij_ruby_indent_public_methods = false\nij_ruby_indent_when_cases = false\nij_ruby_keep_blank_lines_in_declarations = 2\nij_ruby_keep_indents_on_empty_lines = false\nij_ruby_keep_line_breaks = true\nij_ruby_parentheses_around_method_arguments = true\nij_ruby_spaces_around_hashrocket = true\nij_ruby_spaces_around_other_operators = true\nij_ruby_spaces_around_range_operators = false\nij_ruby_spaces_around_relational_operators = true\nij_ruby_spaces_within_array_initializer_braces = true\nij_ruby_spaces_within_braces = false\n\n[*.py]\nindent_size = 4\ntab_width = 4\n"
        },
        {
          "name": ".git-blame-ignore-revs",
          "type": "blob",
          "size": 0.080078125,
          "content": "9c8c9e7fbf8005ea89fa9b13d6d063b9f0240443\nacf144717bd85d2486cc33fbb0e3622b06c66717\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.9912109375,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Set default behaviour, in case users don't have core.autocrlf set.\n* text=auto\n\n# Declare files that will always have LF\n*.sh text eol=lf\n\n# Declare files that will always have CRLF line endings on checkout.\n*.sln text eol=crlf\n\n"
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.2900390625,
          "content": "/.externalToolBuilders\n.project\n*.settings/\n.DS_Store\n.classpath\n/build\n/.idea/\n/logs\n*target/\n*.orig\n*~\nhbase-*/test\n*.iws\n*.iml\n*.ipr\npatchprocess/\ndependency-reduced-pom.xml\nlink_report/\nlinklint-*.zip\nlinklint/\n.checkstyle\n**/.checkstyle\n.java-version\n*.log\n**/*.log\ntmp\n**/.flattened-pom.xml\n"
        },
        {
          "name": ".pylintrc",
          "type": "blob",
          "size": 9.4169921875,
          "content": "[MASTER]\n\n# Specify a configuration file.\n#rcfile=\n\n# Python code to execute, usually for sys.path manipulation such as\n# pygtk.require().\n#init-hook=\n\n# Profiled execution.\n#profile=no\n\n# Add files or directories to the blacklist. They should be base names, not\n# paths.\nignore=CVS\n\n# Pickle collected data for later comparisons.\npersistent=yes\n\n# List of plugins (as comma separated values of python modules names) to load,\n# usually to register additional checkers.\nload-plugins=\n\n\n[MESSAGES CONTROL]\n\n# Enable the message, report, category or checker with the given id(s). You can\n# either give multiple identifier separated by comma (,) or put this option\n# multiple time.\n#enable=\n\n# Disable the message, report, category or checker with the given id(s). You\n# can either give multiple identifier separated by comma (,) or put this option\n# multiple time (only on the command line, not in the configuration file where\n# it should appear only once).\n# CHANGED:\n# C0103: Invalid name \"\"\n# C0111: Missing docstring\n# C0302: Too many lines in module (N)\n# I0010: Unable to consider inline option ''\n# I0011: Locally disabling WNNNN\n#\n# R0801: Similar lines in N files\n# R0901: Too many ancestors (8/7)\n# R0902: Too many instance attributes (N/7)\n# R0903: Too few public methods (N/2)\n# R0904: Too many public methods (N/20)\n# R0911: Too many return statements (N/6)\n# R0912: Too many branches (N/12)\n# R0913: Too many arguments (N/5)\n# R0914: Too many local variables (N/15)\n# R0915: Too many statements (N/50)\n# R0921: Abstract class not referenced\n# R0922: Abstract class is only referenced 1 times\n# W0122: Use of the exec statement\n# W0141: Used builtin function ''\n# W0142: Used * or ** magic\n# W0402: Uses of a deprecated module 'string'\n# W0404: 41: Reimport 'XX' (imported line NN)\n# W0511: TODO\n# W0603: Using the global statement\n# W0703: Catch \"Exception\"\n# W1201: Specify string format arguments as logging function parameters\n#\n# These should get enabled, but the codebase has too many violations currently.\n# bad-continuation\n# anomalous-backslash-in-string\n# bad-context-manager\n# bad-indentation\n# bad-str-strip-call\n# bad-whitespace\n# cell-var-from-loop\n# deprecated-lambda\n# eval-used\n# function-redefined\n# import-error\n# locally-enabled\n# missing-final-newline\n# no-init\n# no-name-in-module\n# no-self-use\n# not-callable\n# old-style-class\n# protected-access\n# superfluous-parens\n# super-on-old-class\n# too-many-function-args\n# trailing-whitespace\n# unnecessary-semicolon\n# unpacking-non-sequence\n# unused-import\n# useless-else-on-loop\ndisable=C0103,C0111,C0302,I0010,I0011,R0801,R0901,R0902,R0903,R0904,R0911,R0912,R0913,R0914,R0915,R0921,R0922,W0122,W0141,W0142,W0402,W0404,W0511,W0603,W0703,W1201,bad-continuation,anomalous-backslash-in-string,bad-context-manager,bad-indentation,bad-str-strip-call,bad-whitespace,cell-var-from-loop,deprecated-lambda,eval-used,function-redefined,import-error,locally-enabled,missing-final-newline,no-init,no-name-in-module,no-self-use,not-callable,old-style-class,protected-access,superfluous-parens,super-on-old-class,too-many-function-args,trailing-whitespace,unnecessary-semicolon,unpacking-non-sequence,unused-import,useless-else-on-loop\n\n\n[REPORTS]\n\n# Set the output format. Available formats are text, parseable, colorized, msvs\n# (visual studio) and html\noutput-format=text\n\n# Put messages in a separate file for each module / package specified on the\n# command line instead of printing them on stdout. Reports (if any) will be\n# written in a file name \"pylint_global.[txt|html]\".\nfiles-output=no\n\n# Tells whether to display a full report or only the messages\n# CHANGED:\nreports=no\n\n# Python expression which should return a note less than 10 (10 is the highest\n# note). You have access to the variables errors warning, statement which\n# respectively contain the number of errors / warnings messages and the total\n# number of statements analyzed. This is used by the global evaluation report\n# (RP0004).\nevaluation=10.0 - ((float(5 * error + warning + refactor + convention) / statement) * 10)\n\n# Add a comment according to your evaluation note. This is used by the global\n# evaluation report (RP0004).\n#comment=no\n\n\n[VARIABLES]\n\n# Tells whether we should check for unused import in __init__ files.\ninit-import=no\n\n# A regular expression matching the beginning of the name of dummy variables\n# (i.e. not used).\ndummy-variables-rgx=_|dummy\n\n# List of additional names supposed to be defined in builtins. Remember that\n# you should avoid to define new builtins when possible.\nadditional-builtins=\n\n# List of modules that can redefine builtins. (For python 2/3 compatibility)\nredefining-builtins-modules=builtins\n\n\n[TYPECHECK]\n\n# Tells whether missing members accessed in mixin class should be ignored. A\n# mixin class is detected if its name ends with \"mixin\" (case insensitive).\nignore-mixin-members=yes\n\n# List of classes names for which member attributes should not be checked\n# (useful for classes with attributes dynamically set).\nignored-classes=SQLObject,twisted.internet.reactor,hashlib,google.appengine.api.memcache\n\n# When zope mode is activated, add a predefined set of Zope acquired attributes\n# to generated-members.\n#zope=no\n\n# List of members which are set dynamically and missed by pylint inference\n# system, and so shouldn't trigger E0201 when accessed. Python regular\n# expressions are accepted.\ngenerated-members=REQUEST,acl_users,aq_parent,multiprocessing.managers.SyncManager\n\n\n[MISCELLANEOUS]\n\n# List of note tags to take in consideration, separated by a comma.\nnotes=FIXME,XXX,TODO\n\n\n[SIMILARITIES]\n\n# Minimum lines number of a similarity.\nmin-similarity-lines=4\n\n# Ignore comments when computing similarities.\nignore-comments=yes\n\n# Ignore docstrings when computing similarities.\nignore-docstrings=yes\n\n\n[FORMAT]\n\n# Maximum number of characters on a single line.\nmax-line-length=100\n\n# Maximum number of lines in a module\nmax-module-lines=1000\n\n# String used as indentation unit\nindent-string='    '\n\n\n[BASIC]\n\n# Required attributes for module, separated by a comma\n#required-attributes=\n\n# List of builtins function names that should not be used, separated by a comma\nbad-functions=map,filter,apply,input\n\n# Regular expression which should only match correct module names\nmodule-rgx=(([a-z_][a-z0-9_]*)|([A-Z][a-zA-Z0-9]+))$\n\n# Regular expression which should only match correct module level names\nconst-rgx=(([A-Z_][A-Z0-9_]*)|(__.*__))$\n\n# Regular expression which should only match correct class names\nclass-rgx=[A-Z_][a-zA-Z0-9]+$\n\n# Regular expression which should only match correct function names\nfunction-rgx=[a-z_][a-z0-9_]{2,30}$\n\n# Regular expression which should only match correct method names\nmethod-rgx=[a-z_][a-z0-9_]{2,30}$\n\n# Regular expression which should only match correct instance attribute names\nattr-rgx=[a-z_][a-z0-9_]{2,30}$\n\n# Regular expression which should only match correct argument names\nargument-rgx=[a-z_][a-z0-9_]{2,30}$\n\n# Regular expression which should only match correct variable names\nvariable-rgx=[a-z_][a-z0-9_]{2,30}$\n\n# Regular expression which should only match correct list comprehension /\n# generator expression variable names\ninlinevar-rgx=[A-Za-z_][A-Za-z0-9_]*$\n\n# Good variable names which should always be accepted, separated by a comma\ngood-names=i,j,k,ex,Run,_\n\n# Bad variable names which should always be refused, separated by a comma\nbad-names=foo,bar,baz,toto,tutu,tata\n\n# Regular expression which should only match functions or classes name which do\n# not require a docstring\nno-docstring-rgx=__.*__\n\n\n[DESIGN]\n\n# Maximum number of arguments for function / method\nmax-args=5\n\n# Argument names that match this expression will be ignored. Default to name\n# with leading underscore\nignored-argument-names=_.*\n\n# Maximum number of locals for function / method body\nmax-locals=15\n\n# Maximum number of return / yield for function / method body\nmax-returns=6\n\n# Maximum number of branch for function / method body\nmax-branchs=12\n\n# Maximum number of statements in function / method body\nmax-statements=50\n\n# Maximum number of parents for a class (see R0901).\nmax-parents=7\n\n# Maximum number of attributes for a class (see R0902).\nmax-attributes=7\n\n# Minimum number of public methods for a class (see R0903).\nmin-public-methods=2\n\n# Maximum number of public methods for a class (see R0904).\nmax-public-methods=20\n\n\n[CLASSES]\n\n# List of interface methods to ignore, separated by a comma. This is used for\n# instance to not check methods defines in Zope's Interface base class.\n#ignore-iface-methods=isImplementedBy,deferred,extends,names,namesAndDescriptions,queryDescriptionFor,getBases,getDescriptionFor,getDoc,getName,getTaggedValue,getTaggedValueTags,isEqualOrExtendedBy,setTaggedValue,isImplementedByInstancesOf,adaptWith,is_implemented_by\n\n# List of method names used to declare (i.e. assign) instance attributes.\ndefining-attr-methods=__init__,__new__,setUp\n\n# List of valid names for the first argument in a class method.\nvalid-classmethod-first-arg=cls\n\n\n[IMPORTS]\n\n# Deprecated modules which should not be used, separated by a comma\ndeprecated-modules=regsub,string,TERMIOS,Bastion,rexec\n\n# Create a graph of every (i.e. internal and external) dependencies in the\n# given file (report RP0402 must not be disabled)\nimport-graph=\n\n# Create a graph of external dependencies in the given file (report RP0402 must\n# not be disabled)\next-import-graph=\n\n# Create a graph of internal dependencies in the given file (report RP0402 must\n# not be disabled)\nint-import-graph=\n\n\n[EXCEPTIONS]\n\n# Exceptions that will emit a warning when being caught. Defaults to\n# \"Exception\"\novergeneral-exceptions=Exception\n"
        },
        {
          "name": ".rubocop.yml",
          "type": "blob",
          "size": 0.1533203125,
          "content": "Naming/HeredocDelimiterNaming:\n  Enabled: false\n\nLayout/HeredocIndentation:\n  Enabled: false\n\nLayout/LineLength:\n  Max: 100\n\nMetrics/MethodLength:\n  Max: 75\n"
        },
        {
          "name": "CHANGES.txt",
          "type": "blob",
          "size": 255.0048828125,
          "content": "HBase Change Log\nRelease 0.93.0 - Unreleased\n  *DO NOT ADD ISSUES HERE ON COMMIT ANY MORE.  WE'LL GENERATE THE LIST\n  FROM JIRA INSTEAD WHEN WE MAKE A RELEASE*\n\nRelease 0.92.1 - Unreleased\n  BUG FIXES\n   HBASE-5176  AssignmentManager#getRegion: logging nit  adds a redundant '+' (Karthik K)\n   HBASE-5237  Addendum for HBASE-5160 and HBASE-4397 (Ram)\n   HBASE-5235  HLogSplitter writer thread's streams not getting closed when any\n               of the writer threads has exceptions. (Ram)\n   HBASE-5243  LogSyncerThread not getting shutdown waiting for the interrupted flag (Ram)\n   HBASE-5255  Use singletons for OperationStatus to save memory (Benoit)\n   HBASE-5345  CheckAndPut doesn't work when value is empty byte[] (Evert Arckens)\n   HBASE-5466  Opening a table also opens the metatable and never closes it\n               (Ashley Taylor)\n\n  TESTS\n   HBASE-5223  TestMetaReaderEditor is missing call to CatalogTracker.stop()\n\nRelease 0.92.0 - 01/23/2012\n  INCOMPATIBLE CHANGES\n   HBASE-2002  Coprocessors: Client side support; Support RPC interface\n               changes at runtime (Gary Helmling via Andrew Purtell)\n   HBASE-3677  Generate a globally unique cluster ID (changed\n               ClusterStatus serialization)\n   HBASE-3762  HTableFactory.releaseHTableInterface() should throw IOException\n               instead of wrapping in RuntimeException (Ted Yu via garyh)\n   HBASE-3629  Update our thrift to 0.6 (Moaz Reyad)\n   HBASE-1502  Remove need for heartbeats in HBase\n   HBASE-451   Remove HTableDescriptor from HRegionInfo (Subbu M Iyer)\n   HBASE-451   Remove HTableDescriptor from HRegionInfo\n               addendum that fixes TestTableMapReduce\n   HBASE-3534  Action should not store or serialize regionName (Ted Yu)\n   HBASE-4197  RegionServer expects all scanner to be subclasses of\n               HRegion.RegionScanner (Lars Hofhansl)\n   HBASE-4233  Update protobuf dependency to 2.4.0a (todd)\n   HBASE-4299  Update to Avro 1.5.3 and use Avro Maven plugin to generate\n               Avro classes. (Alejandro Abdelnur)\n   HBASE-4369  Deprecate HConnection#getZookeeperWatcher in prep for HBASE-1762\n   HBASE-4247  Add isAborted method to the Abortable interface\n               (Akash Ashok)\n   HBASE-4503  Purge deprecated HBaseClusterTestCase\n   HBASE-4374  Up default regions size from 256M to 1G\n   HBASE-4648  Bytes.toBigDecimal() doesn't use offset (Bryan Keller via Lars H)\n   HBASE-4715  Remove stale broke .rb scripts from bin dir\n   HBASE-3433  Remove the KV copy of every KV in Scan; introduced by HBASE-3232 (Lars H)\n   HBASE-5017  Bump the default hfile.block.cache.size because of HFileV2\n\n  BUG FIXES\n   HBASE-3280  YouAreDeadException being swallowed in HRS getMaster\n   HBASE-3282  Need to retain DeadServers to ensure we don't allow\n               previously expired RS instances to rejoin cluster\n   HBASE-3283  NPE in AssignmentManager if processing shutdown of RS who\n               doesn't have any regions assigned to it\n   HBASE-3173  HBase 2984 breaks ability to specify BLOOMFILTER &\n               COMPRESSION via shell\n   HBASE-3310  Failing creating/altering table with compression agrument from\n               the HBase shell (Igor Ranitovic via Stack)\n   HBASE-3317  Javadoc and Throws Declaration for Bytes.incrementBytes() is\n               Wrong (Ed Kohlwey via Stack)\n   HBASE-1888  KeyValue methods throw NullPointerException instead of\n               IllegalArgumentException during parameter sanity check\n   HBASE-3337  Restore HBCK fix of unassignment and dupe assignment for new\n               master\n   HBASE-3332  Regions stuck in transition after RS failure\n   HBASE-3418  Increment operations can break when qualifiers are split\n               between memstore/snapshot and storefiles\n   HBASE-3403  Region orphaned after failure during split\n   HBASE-3492  NPE while splitting table with empty column family store\n   HBASE-3400  Coprocessor Support for Generic Interfaces\n               (Ed Kohlwey via Gary Helmling)\n   HBASE-3552  Coprocessors are unable to load if RegionServer is launched\n               using a different classloader than system default\n   HBASE-3578  TableInputFormat does not setup the configuration for HBase\n               mapreduce jobs correctly (Dan Harvey via Stack)\n   HBASE-3601  TestMasterFailover broken in TRUNK\n   HBASE-3605  Fix balancer log message\n   HBASE-3538  Column families allow to have slashes in name (Ian Knome via Stack)\n   HBASE-3313  Table name isn't checked in isTableEnabled/isTableDisabled\n               (Ted Yu via Stack)\n   HBASE-3514  Speedup HFile.Writer append (Matteo Bertozzi via Ryan)\n   HBASE-3665  tighten assertions for testBloomFilterSize\n   HBASE-3662  REST server does not respect client supplied max versions when\n               creating scanner\n   HBASE-3641  LruBlockCache.CacheStats.getHitCount() is not using the\n               correct variable\n   HBASE-3532  HRegion#equals is broken (Ted Yu via Stack)\n   HBASE-3697  Admin actions that use MetaReader to iterate regions need to\n               skip offline ones\n   HBASE-3583  Coprocessors: scannerNext and scannerClose hooks are called\n               when HRegionInterface#get is invoked (Mingjie Lai via\n               Andrew Purtell)\n   HBASE-3688  Setters of class HTableDescriptor do not work properly\n   HBASE-3702  Fix NPE in Exec method parameter serialization\n   HBASE-3709  HFile compression not sharing configuration\n   HBASE-3711  importtsv fails if rowkey length exceeds MAX_ROW_LENGTH\n               (Kazuki Ohta via todd)\n   HBASE-3716  Intermittent TestRegionRebalancing failure\n               (Ted Yu via Stack)\n   HBASE-3712  HTable.close() doesn't shutdown thread pool\n               (Ted Yu via Stack)\n   HBASE-3238  HBase needs to have the CREATE permission on the parent of its\n               ZooKeeper parent znode (Alex Newman via Stack)\n   HBASE-3728  NPE in HTablePool.closeTablePool (Ted Yu via Stack)\n   HBASE-3733  MemStoreFlusher.flushOneForGlobalPressure() shouldn't\n               be using TreeSet for HRegion (Ted Yu via J-D)\n   HBASE-3739  HMaster.getProtocolVersion() should distinguish\n               HMasterInterface and HMasterRegionInterface versions\n   HBASE-3723  Major compact should be done when there is only one storefile\n               and some keyvalue is outdated (Zhou Shuaifeng via Stack)\n   HBASE-3624  Only one coprocessor of each priority can be loaded for a table\n   HBASE-3598  Broken formatting in LRU stats output (Erik Onnen)\n   HBASE-3758  Delete triggers pre/postScannerOpen upcalls of RegionObserver\n               (Mingjie Lai via garyh)\n   HBASE-3790  Fix NPE in ExecResult.write() with null return value\n   HBASE-3781  hbase shell cannot start \"NoMethodError: undefined method\n               `close' for nil:NilClass\" (Mikael Sitruk)\n   HBASE-3802  Redundant list creation in HRegion\n   HBASE-3788  Two error handlings in AssignmentManager.setOfflineInZooKeeper()\n               (Ted Yu)\n   HBASE-3800  HMaster is not able to start due to AlreadyCreatedException\n   HBASE-3806  distributed log splitting double escapes task names\n               (Prakash Khemani)\n   HBASE-3819  TestSplitLogWorker has too many SLWs running -- makes for\n               contention and occasional failures\n   HBASE-3210  HBASE-1921 for the new master\n   HBASE-3827  hbase-1502, removing heartbeats, broke master joining a running\n               cluster and was returning master hostname for rs to use\n   HBASE-3829  TestMasterFailover failures in jenkins\n   HBASE-3843  splitLogWorker starts too early (Prakash Khemani)\n   HBASE-3838  RegionCoprocesorHost.preWALRestore throws npe in case there is\n               no RegionObserver registered (Himanshu Vashishtha)\n   HBASE-3847  Turn off DEBUG logging of RPCs in WriteableRPCEngine on TRUNK\n   HBASE-3777  Redefine Identity Of HBase Configuration (Karthick Sankarachary)\n   HBASE-3849  Fix master ui; hbase-1502 broke requests/second\n   HBASE-3853  Fix TestInfoServers to pass after HBASE-3835 (todd)\n   HBASE-3862  Race conditions in aggregate calculation (John Heitmann)\n   HBASE-3865  Failing TestWALReplay\n   HBASE-3864  Rename of hfile.min.blocksize.size in HBASE-2899 reverted in\n               HBASE-1861 (Aaron T. Myers)\n   HBASE-3876  TestCoprocessorInterface.testCoprocessorInterface broke on\n               jenkins and local\n   HBASE-3897  Docs (notsoquick guide) suggest invalid XML (Philip Zeyliger)\n   HBASE-3898  TestSplitTransactionOnCluster broke in TRUNK\n   HBASE-3826  Minor compaction needs to check if still over\n               compactionThreshold after compacting (Nicolas Spiegelberg)\n   HBASE-3912  [Stargate] Columns not handle by Scan\n   HBASE-3903  A successful write to client write-buffer may be lost or not\n               visible (Doug Meil)\n   HBASE-3894  Thread contention over row locks set monitor (Dave Latham)\n   HBASE-3959  hadoop-snappy version in the pom.xml is incorrect\n               (Alejandro Abdelnur)\n   HBASE-3971  Compression.java uses ClassLoader.getSystemClassLoader()\n               to load codec (Alejandro Abdelnur)\n   HBASE-3979  Trivial fixes in code, document (Ming Ma)\n   HBASE-3794  Ability to Discard Bad HTable Puts\n   HBASE-3923  HBASE-1502 Broke Shell's status 'simple' and 'detailed'\n   HBASE-3978  Rowlock lease renew doesn't work when custom coprocessor\n               indicates to bypass default action (Ming Ma)\n   HBASE-3963  Schedule all log-spliiting at startup all at once (mingjian)\n   HBASE-3983  list command in shell seems broken\n   HBASE-3793  HBASE-3468 Broke checkAndPut with null value (Ming Ma)\n   HBASE-3889  NPE in Distributed Log Splitting (Anirudh Todi)\n   HBASE-4000  You can't specify split points when you create a table in\n               the shell (Joey Echeverria)\n   HBASE-4029  Inappropriate checking of Logging Mode in HRegionServer\n               (Akash Ashok via Ted Yu)\n   HBASE-4037  Add timeout annotations to preempt surefire killing\n               all tests\n   HBASE-4024  Major compaction may not be triggered, even though region\n               server log says it is triggered (Ted Yu)\n   HBASE-4016  HRegion.incrementColumnValue() doesn't have a consistent\n               behavior when the field that we are incrementing is less\n               than 8 bytes long (Li Pi)\n   HBASE-4012  Further optimize byte comparison methods (Ted Yu)\n   HBASE-4037  Add timeout annotations to preempt surefire killing\n               all tests - TestFullLogReconstruction\n   HBASE-4051  [Coprocessors] Table coprocessor loaded twice when region is\n               initialized\n   HBASE-4059  If a region is split during RS shutdown process, the daughter\n               regions are NOT made online by master\n   HBASE-3904  HBA.createTable(final HTableDescriptor desc, byte [][] splitKeys)\n               should be synchronous\n   HBASE-4053  Most of the regions were added into AssignmentManager#servers twice\n   HBASE-4061  getTableDirs is missing directories to skip\n   HBASE-3867  when cluster is stopped and server which hosted meta region is\n               removed from cluster, master breaks down after restarting cluster.\n   HBASE-4074  When a RS has hostname with uppercase letter, there are two\n               RS entries in master (Weihua via Ted Yu)\n   HBASE-4077  Deadlock if WrongRegionException is thrown from getLock in\n               HRegion.delete (Adam Warrington via Ted Yu)\n   HBASE-3893  HRegion.internalObtainRowLock shouldn't wait forever\n   HBASE-4075  A bug in TestZKBasedOpenCloseRegion (Jieshan Bean via Ted Yu)\n   HBASE-4087  HBaseAdmin should perform validation of connection it holds\n   HBASE-4052  Enabling a table after master switch does not allow table scan,\n               throwing NotServingRegionException (ramkrishna via Ted Yu)\n   HBASE-4112  Creating table may throw NullPointerException (Jinchao via Ted Yu)\n   HBASE-4093  When verifyAndAssignRoot throws exception, the deadServers state\n               cannot be changed (fulin wang via Ted Yu)\n   HBASE-4118  method regionserver.MemStore#updateColumnValue: the check for\n               qualifier and family is missing (N Keywal via Ted Yu)\n   HBASE-4127  Don't modify table's name away in HBaseAdmin\n   HBASE-4105  Stargate does not support Content-Type: application/json and\n               Content-Encoding: gzip in parallel\n   HBASE-4116  [stargate] StringIndexOutOfBoundsException in row spec parse\n               (Allan Yan)\n   HBASE-3845  data loss because lastSeqWritten can miss memstore edits\n               (Prakash Khemani and ramkrishna.s.vasudevan)\n   HBASE-4083  If Enable table is not completed and is partial, then scanning of\n               the table is not working (ramkrishna.s.vasudevan)\n   HBASE-4138  If zookeeper.znode.parent is not specifed explicitly in Client\n               code then HTable object loops continuously waiting for the root region\n               by using /hbase as the base node.(ramkrishna.s.vasudevan)\n   HBASE-4032  HBASE-451 improperly breaks public API HRegionInfo#getTableDesc\n   HBASE-4003  Cleanup Calls Conservatively On Timeout (Karthick)\n   HBASE-3857  Fix TestHFileBlock.testBlockHeapSize test failure (Mikhail)\n   HBASE-4150  Don't enforce pool size limit with ThreadLocalPool\n               (Karthick Sankarachary via garyh)\n   HBASE-4171  HBase shell broken in trunk (Lars Hofhansl)\n   HBASE-4162  Fix TestHRegionInfo.testGetSetOfHTD: delete /tmp/hbase-<username>\n               if it already exists (Mikhail Bautin)\n   HBASE-4179  Failed to run RowCounter on top of Hadoop branch-0.22\n               (Michael Weng)\n   HBASE-4181  HConnectionManager can't find cached HRegionInterface and makes clients\n               work very slow (Jia Liu)\n   HBASE-4156  ZKConfig defaults clientPort improperly (Michajlo Matijkiw)\n   HBASE-4184  CatalogJanitor doesn't work properly when \"fs.default.name\" isn't\n               set in config file (Ming Ma)\n   HBASE-4186  No region is added to regionsInTransitionInRS\n   HBASE-4194  RegionSplitter: Split on under-loaded region servers first\n   HBASE-2399  Forced splits only act on the first family in a table (Ming Ma)\n   HBASE-4211  Do init-sizing of the StringBuilder making a ServerName\n               (Benot Sigoure)\n   HBASE-4175  Fix FSUtils.createTableDescriptor() (Ramkrishna)\n   HBASE-4008  Problem while stopping HBase (Akash Ashok)\n   HBASE-4065  TableOutputFormat ignores failure to create table instance\n               (Brock Noland)\n   HBASE-4167  Potential leak of HTable instances when using HTablePool with\n               PoolType.ThreadLocal (Karthick Sankarachary)\n   HBASE-4239  HBASE-4012 introduced duplicate variable Bytes.LONG_BYTES\n   HBASE-4225  NoSuchColumnFamilyException in multi doesn't say which family\n               is bad (Ramkrishna Vasudevan)\n   HBASE-4220  Lots of DNS queries from client\n   HBASE-4253  Intermittent test failure because of missing config parameter in new\n               HTable(tablename) (Ramkrishna)\n   HBASE-4217  HRS.closeRegion should be able to close regions with only\n               the encoded name (ramkrishna.s.vasudevan)\n   HBASE-3229  HBASE-3229 Table creation, though using \"async\" call to master,\n               can actually run for a while and cause RPC timeout (Ming Ma)\n   HBASE-4252  TestLogRolling's low-probability failure (Jieshan Bean)\n   HBASE-4278  Race condition in Slab.java that occurs due to spinlock unlocking\n               early (Li Pi)\n   HBASE-4269  Add tests and restore semantics to TableInputFormat/TableRecordReader\n               (Jonathan Hsieh)\n   HBASE-4290  HLogSplitter doesn't mark its MonitoredTask as complete in\n               non-distributed case (todd)\n   HBASE-4303  HRegionInfo.toString has bad quoting (todd)\n   HBASE-4307  race condition in CacheTestUtils (Li Pi)\n   HBASE-4310  SlabCache metrics bugfix (Li Pi)\n   HBASE-4283  HBaseAdmin never recovers from restarted cluster (Lars Hofhansl)\n   HBASE-4315  RPC logging too verbose (todd)\n   HBASE-4273  java.lang.NullPointerException when a table is being disabled and\n               HMaster restarts (Ming Ma)\n   HBASE-4027  Off Heap Cache never creates Slabs (Li Pi)\n   HBASE-4265  zookeeper.KeeperException$NodeExistsException if HMaster restarts\n               while table is being disabled (Ming Ma)\n   HBASE-4338  Package build for rpm and deb are broken (Eric Yang)\n   HBASE-4309  slow query log metrics spewing warnings (Riley Patterson)\n   HBASE-4302  Only run Snappy compression tests if Snappy is available\n               (Alejandro Abdelnur via todd)\n   HBASE-4271  Clean up coprocessor handling of table operations\n               (Ming Ma via garyh)\n   HBASE-4341  HRS#closeAllRegions should take care of HRS#onlineRegions's\n               weak consistency (Jieshan Bean)\n   HBASE-4297  TableMapReduceUtil overwrites user supplied options\n               (Jan Lukavsky)\n   HBASE-4015  Refactor the TimeoutMonitor to make it less racy\n               (ramkrishna.s.vasudevan)\n   HBASE-4350  Fix a Bloom filter bug introduced by HFile v2 and\n               TestMultiColumnScanner that caught it (Mikhail Bautin)\n   HBASE-4007  distributed log splitting can get indefinitely stuck\n               (Prakash Khemani)\n   HBASE-4301  META migration from 0.90 to trunk fails (Subbu Iyer)\n   HBASE-4331  Bypassing default actions in prePut fails sometimes with\n               HTable client (Lars Hofhansl via garyh)\n   HBASE-4340  Hbase can't balance if ServerShutdownHandler encountered\n               exception (Jinchao Gao)\n   HBASE-4394  Add support for seeking hints to FilterList\n   HBASE-4406  TestOpenRegionHandler failing after HBASE-4287 (todd)\n   HBASE-4330  Fix races in slab cache (Li Pi & Todd)\n   HBASE-4383  SlabCache reports negative heap sizes (Li Pi)\n   HBASE-4351  If from Admin we try to unassign a region forcefully,\n               though a valid region name is given the master is not able\n               to identify the region to unassign (Ramkrishna)\n   HBASE-4363  [replication] ReplicationSource won't close if failing\n               to contact the sink (JD and Lars Hofhansl)\n   HBASE-4390  [replication] ReplicationSource's UncaughtExceptionHandler\n               shouldn't join\n   HBASE-4395  EnableTableHandler races with itself\n   HBASE-4414  Region splits by size not being triggered\n   HBASE-4322  HBASE-4322 [hbck] Update checkIntegrity/checkRegionChain\n               to present more accurate region split problem\n               (Jon Hseih)\n   HBASE-4417  HBaseAdmin.checkHBaseAvailable() doesn't close ZooKeeper connections\n               (Stefan Seelmann)\n   HBASE-4195  Possible inconsistency in a memstore read after a reseek,\n               possible performance improvement (nkeywal)\n   HBASE-4420  MasterObserver preMove() and postMove() should throw\n               IOException instead of UnknownRegionException\n   HBASE-4419  Resolve build warning messages (Praveen Patibandia)\n   HBASE-4428  Two methods in CacheTestUtils don't call setDaemon() on the threads\n   HBASE-4400  .META. getting stuck if RS hosting it is dead and znode state is in\n               RS_ZK_REGION_OPENED (Ramkrishna)\n   HBASE-3421  Very wide rows -- 30M plus -- cause us OOME (Nate Putnam)\n   HBASE-4153  Handle RegionAlreadyInTransitionException in AssignmentManager\n               (Ramkrishna)\n   HBASE-4452  Possibility of RS opening a region though tickleOpening fails due to\n               znode version mismatch (Ramkrishna)\n   HBASE-4446  Rolling restart RSs scenario, regions could stay in OPENING state\n               (Ming Ma)\n   HBASE-4468  Wrong resource name in an error massage: webapps instead of\n               hbase-webapps (nkeywal)\n   HBASE-4472  MiniHBaseCluster.shutdown() doesn't work if no active master\n   HBASE-4455  Rolling restart RSs scenario, -ROOT-, .META. regions are lost in\n               AssignmentManager (Ming Ma)\n   HBASE-4513  NOTICES.txt refers to Facebook for Thrift\n   HBASE-3130  [replication] ReplicationSource can't recover from session\n               expired on remote clusters (Chris Trezzo via JD)\n   HBASE-4212  TestMasterFailover fails occasionally (Gao Jinchao)\n   HBASE-4412  No need to retry scan operation on the same server in case of\n               RegionServerStoppedException (Ming Ma)\n   HBASE-4476  Compactions must fail if column tracker gets columns out of order\n               (Mikhail Bautin)\n   HBASE-4209  The HBase hbase-daemon.sh SIGKILLs master when stopping it\n               (Roman Shaposhnik)\n   HBASE-4496  HFile V2 does not honor setCacheBlocks when scanning (Lars and Mikhail)\n   HBASE-4531  hbase-4454 failsafe broke mvn site; back it out or fix\n               (Akash Ashok)\n   HBASE-4334  HRegion.get never validates row (Lars Hofhansl)\n   HBASE-4494  AvroServer:: get fails with NPE on a non-existent row\n               (Kay Kay)\n   HBASE-4481  TestMergeTool failed in 0.92 build 20\n   HBASE-4386  Fix a potential NPE in TaskMonitor (todd)\n   HBASE-4402  Retaining locality after restart broken\n   HBASE-4482  Race Condition Concerning Eviction in SlabCache (Li Pi)\n   HBASE-4547  TestAdmin failing in 0.92 because .tableinfo not found\n   HBASE-4540  OpenedRegionHandler is not enforcing atomicity of the operation\n               it is performing(Ram)\n   HBASE-4335  Splits can create temporary holes in .META. that confuse clients\n               and regionservers (Lars H)\n   HBASE-4555  TestShell seems passed, but actually errors seen in test output\n               file (Mingjie Lai)\n   HBASE-4582  Store.java cleanup (failing TestHeapSize and has warnings)\n   HBASE-4556  Fix all incorrect uses of InternalScanner.next(...) (Lars H)\n   HBASE-4078  Validate store files after flush/compaction\n   HBASE-3417  CacheOnWrite is using the temporary output path for block\n               names, need to use a more consistent block naming scheme (jgray)\n   HBASE-4551  Fix pom and some test cases to compile and run against\n               Hadoop 0.23 (todd)\n   HBASE-3446  ProcessServerShutdown fails if META moves, orphaning lots of\n               regions\n   HBASE-4589  CacheOnWrite broken in some cases because it can conflict\n               with evictOnClose (jgray)\n   HBASE-4579  CST.requestCompaction semantics changed, logs are now\n               spammed when too many store files\n   HBASE-4620  I broke the build when I submitted HBASE-3581 (Send length\n               of the rpc response)\n   HBASE-4621  TestAvroServer fails quite often intermittently (Akash Ashok)\n   HBASE-4378  [hbck] Does not complain about regions with startkey==endkey.\n               (Jonathan Hsieh)\n   HBASE-4459  HbaseObjectWritable code is a byte, we will eventually run out of codes\n   HBASE-4430  Disable TestSlabCache and TestSingleSizedCache temporarily to\n               see if these are cause of build box failure though all tests\n               pass (Li Pi)\n   HBASE-4510  Check and workaround usage of internal HDFS APIs in HBase\n               (Harsh)\n   HBASE-4595  HFilePrettyPrinter Scanned kv count always 0 (Matteo Bertozzi)\n   HBASE-4580  Some invalid zk nodes were created when a clean cluster restarts\n               (Gaojinchao)\n   HBASE-4588  The floating point arithmetic to validate memory allocation\n               configurations need to be done as integers (dhruba)\n   HBASE-4647  RAT finds about 40 files missing licenses\n   HBASE-4642  Add Apache License Header\n   HBASE-4591  TTL for old HLogs should be calculated from last modification time.\n   HBASE-4578  NPE when altering a table that has moving regions (gaojinchao)\n   HBASE-4070  Improve region server metrics to report loaded coprocessors to\n               master (Eugene Koontz via apurtell)\n   HBASE-3512  Shell support for listing currently loaded coprocessors (Eugene\n               Koontz via apurtell)\n   HBASE-4670  Fix javadoc warnings\n   HBASE-4367  Deadlock in MemStore flusher due to JDK internally synchronizing\n               on current thread\n   HBASE-4645  Edits Log recovery losing data across column families\n   HBASE-4634  \"test.build.data\" property overused leading to write data at the\n               wrong place (nkeywal)\n   HBASE-4388  Second start after migration from 90 to trunk crashes\n   HBASE-4685  TestDistributedLogSplitting.testOrphanLogCreation failing because\n               of ArithmeticException: / by zero.\n   HBASE-4300  Start of new-version master fails if old master's znode is\n               hanging around\n   HBASE-4679  Thrift null mutation error\n   HBASE-4304  requestsPerSecond counter stuck at 0 (Li Pi)\n   HBASE-4692  HBASE-4300 broke the build\n   HBASE-4641  Block cache can be mistakenly instantiated on Master (jgray)\n   HBASE-4687  regionserver may miss zk-heartbeats to master when replaying\n               edits at region open (prakash via jgray)\n   HBASE-4701  TestMasterObserver fails up on jenkins\n   HBASE-4700  TestSplitTransactionOnCluster fails on occasion when it tries\n               to move a region\n   HBASE-4613  hbase.util.Threads#threadDumpingIsAlive sleeps 1 second,\n               slowing down the shutdown by 0.5s\n   HBASE-4552  multi-CF bulk load is not atomic across column families (Jonathan Hsieh)\n   HBASE-4710  UnknownProtocolException should abort client retries\n   HBASE-4695  WAL logs get deleted before region server can fully flush\n               (gaojinchao)\n   HBASE-4708  Revert safemode related pieces of hbase-4510 (Harsh J)\n   HBASE-3515  [replication] ReplicationSource can miss a log after RS comes out of GC\n   HBASE-4713  Raise debug level to warn on ExecutionException in\n               HConnectionManager$HConnectionImplementation (Lucian George Iordache)\n   HBASE-4716  Improve locking for single column family bulk load\n   HBASE-4609  ThriftServer.getRegionInfo() is expecting old ServerName format, need to\n               use new Addressing class instead (Jonathan Gray)\n   HBASE-4719  HBase script assumes pre-Hadoop 0.21 layout of jar files\n               (Roman Shposhnik)\n   HBASE-4553  The update of .tableinfo is not atomic; we remove then rename\n   HBASE-4725  NPE in AM#updateTimers\n   HBASE-4745  LRU statistics thread should be a daemon\n   HBASE-4749  TestMasterFailover#testMasterFailoverWithMockedRITOnDeadRS\n               occasionally fails\n   HBASE-4753  org.apache.hadoop.hbase.regionserver.TestHRegionInfo#testGetSetOfHTD\n               throws NPE on trunk (nkeywal)\n   HBASE-4754  FSTableDescriptors.getTableInfoPath() should handle FileNotFoundException\n   HBASE-4740  [bulk load] the HBASE-4552 API can't tell if errors on region server are recoverable\n               (Jonathan Hsieh)\n   HBASE-4741  Online schema change doesn't return errors\n   HBASE-4734  [bulk load] Warn if bulk load directory contained no files\n   HBASE-4723  Loads of NotAllMetaRegionsOnlineException traces when starting\n               the master\n   HBASE-4511  There is data loss when master failovers\n   HBASE-4577  Region server reports storefileSizeMB bigger than\n               storefileUncompressedSizeMB (gaojinchao)\n   HBASE-4478  Improve AssignmentManager.handleRegion so that it can process certain ZK state\n               in the case of RS offline\n   HBASE-4777  Write back to client 'incompatible' if we show up with wrong version\n   HBASE-4775  Remove -ea from all but tests; enable it if you need it testing\n   HBASE-4784  Void return types not handled correctly for CoprocessorProtocol\n               methods\n   HBASE-4792  SplitRegionHandler doesn't care if it deletes the znode or not,\n               leaves the parent region stuck offline\n   HBASE-4793  HBase shell still using deprecated methods removed in HBASE-4436\n   HBASE-4801  alter_status shell prints sensible message at completion\n   HBASE-4796  Race between SplitRegionHandlers for the same region kills the master\n   HBASE-4816  Regionserver wouldn't go down because split happened exactly at same\n               time we issued bulk user region close call on our way out\n   HBASE-4815  Disable online altering by default, create a config for it\n   HBASE-4623  Remove @deprecated Scan methods in 0.90 from TRUNK and 0.92\n   HBASE-4842  [hbck] Fix intermittent failures on TestHBaseFsck.testHBaseFsck\n               (Jon Hsieh)\n   HBASE-4308  Race between RegionOpenedHandler and AssignmentManager (Ram)\n   HBASE-4857  Recursive loop on KeeperException in\n               AuthenticationTokenSecretManager/ZKLeaderManager\n   HBASE-4739  Master dying while going to close a region can leave it in transition\n               forever (Gao Jinchao)\n   HBASE-4855  SplitLogManager hangs on cluster restart due to batch.installed doubly counted\n   HBASE-4877  TestHCM failing sporadically on jenkins and always for me on an\n               ubuntu machine\n   HBASE-4878  Master crash when splitting hlog may cause data loss (Chunhui Shen)\n   HBASE-4945  NPE in HRegion.bulkLoadHFiles (Andrew P and Lars H)\n   HBASE-4942  HMaster is unable to start of HFile V1 is used (Honghua Zhu)\n   HBASE-4610  Port HBASE-3380 (Master failover can split logs of live servers) to 92/trunk\n   HBASE-4946  HTable.coprocessorExec (and possibly coprocessorProxy) does not work with\n               dynamically loaded coprocessors (Andrei Dragomir)\n   HBASE-5026  Add coprocessor hook to HRegionServer.ScannerListener.leaseExpired()\n   HBASE-4935  hbase 0.92.0 doesn't work going against 0.20.205.0, its packaged hadoop\n   HBASE-5078  DistributedLogSplitter failing to split file because it has edits for\n               lots of regions\n   HBASE-5077  SplitLogWorker fails to let go of a task, kills the RS\n   HBASE-5096  Replication does not handle deletes correctly. (Lars H)\n   HBASE-5103  Fix improper master znode deserialization (Jonathan Hsieh)\n   HBASE-5099  ZK event thread waiting for root region assignment may block server\n               shutdown handler for the region sever the root region was on (Jimmy)\n   HBASE-5100  Rollback of split could cause closed region to be opened again (Chunhui)\n   HBASE-4397  -ROOT-, .META. tables stay offline for too long in recovery phase after all RSs\n               are shutdown at the same time (Ming Ma)\n   HBASE-5094  The META can hold an entry for a region with a different server name from the one\n               actually in the AssignmentManager thus making the region inaccessible. (Ram)\n   HBASE-5081  Distributed log splitting deleteNode races against splitLog retry (Prakash)\n   HBASE-4357  Region stayed in transition - in closing state (Ming Ma)\n   HBASE-5088  A concurrency issue on SoftValueSortedMap (Jieshan Bean and Lars H)\n   HBASE-5152  Region is on service before completing initialization when doing rollback of split,\n               it will affect read correctness (Chunhui)\n   HBASE-5137  MasterFileSystem.splitLog() should abort even if waitOnSafeMode() throws IOException(Ted)\n   HBASE-5121  MajorCompaction may affect scan's correctness (chunhui shen and Lars H)\n   HBASE-5143  Fix config typo in pluggable load balancer factory (Harsh J)\n   HBASE-5196  Failure in region split after PONR could cause region hole (Jimmy Xiang)\n\n  TESTS\n   HBASE-4450  test for number of blocks read: to serve as baseline for expected\n               blocks read and for catching regressions (Kannan)\n   HBASE-4492  TestRollingRestart fails intermittently (Ted Yu and Ram)\n   HBASE-4512  JVMClusterUtil throwing wrong exception when master thread cannot be created (Ram)\n   HBASE-4479  TestMasterFailover failure in Hbase-0.92#17(Ram)\n   HBASE-4651  ConcurrentModificationException might be thrown in\n               TestHCM.testConnectionUniqueness (Jinchao)\n   HBASE-4518  TestServerCustomProtocol fails intermittently\n   HBASE-4790  Occasional TestDistributedLogSplitting failure (Jinchao)\n   HBASE-4864  TestMasterObserver#testRegionTransitionOperations occasionally\n               fails (Gao Jinchao)\n   HBASE-4868  TestOfflineMetaRebuildBase#testMetaRebuild occasionally fails\n               (Gao Jinchao)\n   HBASE-4874  Run tests with non-secure random, some tests hang otherwise (Lars H)\n   HBASE-5112  TestReplication#queueFailover flaky due to potentially\n               uninitialized Scan (Jimmy Xiang)\n   HBASE-5113  TestDrainingServer expects round robin region assignment but misses a\n               config parameter\n   HBASE-5105  TestImportTsv failed with hadoop 0.22 (Ming Ma)\n\n  IMPROVEMENTS\n   HBASE-3290  Max Compaction Size (Nicolas Spiegelberg via Stack)\n   HBASE-3292  Expose block cache hit/miss/evict counts into region server\n               metrics\n   HBASE-2936  Differentiate between daemon & restart sleep periods\n   HBASE-3316  Add support for Java Serialization to HbaseObjectWritable\n               (Ed Kohlwey via Stack)\n   HBASE-1861  Multi-Family support for bulk upload tools\n   HBASE-3308  SplitTransaction.splitStoreFiles slows splits a lot\n   HBASE-3328  Added Admin API to specify explicit split points\n   HBASE-3377  Upgrade Jetty to 6.1.26\n   HBASE-3393  Update Avro gateway to use Avro 1.4.1 and the new\n               server.join() method (Jeff Hammerbacher via Stack)\n   HBASE-3433  KeyValue API to explicitly distinguish between deep & shallow\n               copies\n   HBASE-3522  Unbundle our RPC versioning; rather than a global for all 4\n               Interfaces -- region, master, region to master, and\n               coprocesssors -- instead version each individually\n   HBASE-3520  Update our bundled hadoop from branch-0.20-append to latest\n               (rpc version 43)\n   HBASE-3563  [site] Add one-page-only version of hbase doc\n   HBASE-3564  DemoClient.pl - a demo client in Perl\n   HBASE-3560  the hbase-default entry of \"hbase.defaults.for.version\"\n               causes tests not to run via not-maven\n   HBASE-3513  upgrade thrift to 0.5.0 and use mvn version\n   HBASE-3533  Allow HBASE_LIBRARY_PATH env var to specify extra locations\n               of native lib\n   HBASE-3631  CLONE - HBase 2984 breaks ability to specify BLOOMFILTER &\n               COMPRESSION via shell\n   HBASE-3630  DemoClient.Java is outdated (Moaz Reyed via Stack)\n   HBASE-3618  Add to HBase book, 'schema' chapter - pre-creating regions and\n               key types (Doug Meil via Stack)\n   HBASE-2495  Allow record filtering with selected row key values in HBase\n               Export (Subbu M Iyer via Stack)\n   HBASE-3440  Clean out load_table.rb and make sure all roads lead to\n               completebulkload tool (Vidhyashankar Venkataraman via Stack)\n   HBASE-3653  Parallelize Server Requests on HBase Client\n   HBASE-3657  reduce copying of HRegionInfo's (Ted Yu via Stack)\n   HBASE-3422  Balancer will try to rebalance thousands of regions in one go;\n               needs an upper bound added (Ted Yu via Stack)\n   HBASE-3676  Update region server load for AssignmentManager through\n               regionServerReport() (Ted Yu via Stack)\n   HBASE-3468  Enhance checkAndPut and checkAndDelete with comparators\n   HBASE-3683  NMapInputFormat should use a different config param for\n               number of maps\n   HBASE-3673  Reduce HTable Pool Contention Using Concurrent Collections\n               (Karthick Sankarachary via Stack)\n   HBASE-3474  HFileOutputFormat to use column family's compression algorithm\n   HBASE-3541  REST Multi Gets (Elliott Clark via Stack)\n   HBASE-3052  Add ability to have multiple ZK servers in a quorum in\n               MiniZooKeeperCluster for test writing (Liyin Tang via Stack)\n   HBASE-3693  isMajorCompaction() check triggers lots of listStatus DFS RPC\n               calls from HBase (Liyin Tang via Stack)\n   HBASE-3717  deprecate HTable isTableEnabled() methods in favor of\n               HBaseAdmin methods (David Butler via Stack)\n   HBASE-3720  Book.xml - porting conceptual-view / physical-view sections of\n               HBaseArchitecture wiki (Doug Meil via Stack)\n   HBASE-3705  Allow passing timestamp into importtsv (Andy Sautins via Stack)\n   HBASE-3715  Book.xml - adding architecture section on client, adding section\n               on spec-ex under mapreduce (Doug Meil via Stack)\n   HBASE-3684  Support column range filter (Jerry Chen via Stack)\n   HBASE-3647  Distinguish read and write request count in region\n               (Ted Yu via Stack)\n   HBASE-3704  Show per region request count in table.jsp\n               (Ted Yu via Stack)\n   HBASE-3694  high multiput latency due to checking global mem store size\n               in a synchronized function (Liyin Tang via Stack)\n   HBASE-3710  Book.xml - fill out descriptions of metrics\n               (Doug Meil via Stack)\n   HBASE-3738  Book.xml - expanding Architecture Client section\n               (Doug Meil via Stack)\n   HBASE-3587  Eliminate use of read-write lock to guard loaded\n               coprocessor collection\n   HBASE-3729  Get cells via shell with a time range predicate\n               (Ted Yu via Stack)\n   HBASE-3764  Book.xml - adding 2 FAQs (SQL and arch question)\n   HBASE-3770  Make FilterList accept var arg Filters in its constructor\n               as a convenience (Erik Onnen via Stack)\n   HBASE-3769  TableMapReduceUtil is inconsistent with other table-related\n               classes that accept byte[] as a table name (Erik Onnen via Stack)\n   HBASE-3768  Add best practice to book for loading row key only\n               (Erik Onnen via Stack)\n   HBASE-3765  metrics.xml - small format change and adding nav to hbase\n               book metrics section (Doug Meil)\n   HBASE-3759  Eliminate use of ThreadLocals for CoprocessorEnvironment\n               bypass() and complete()\n   HBASE-3701  revisit ArrayList creation (Ted Yu via Stack)\n   HBASE-3753  Book.xml - architecture, adding more Store info (Doug Meil)\n   HBASE-3784  book.xml - adding small subsection in architecture/client on\n               filters (Doug Meil)\n   HBASE-3785  book.xml - moving WAL into architecture section, plus adding\n               more description on what it does (Doug Meil)\n   HBASE-3699  Make RegionServerServices and MasterServices extend Server\n               (Erik Onnen)\n   HBASE-3757  Upgrade to ZK 3.3.3\n   HBASE-3609  Improve the selection of regions to balance; part 2 (Ted Yu)\n   HBASE-2939  Allow Client-Side Connection Pooling (Karthik Sankarachary)\n   HBASE-3798  [REST] Allow representation to elide row key and column key\n   HBASE-3812  Tidy up naming consistency and documentation in coprocessor\n               framework (Mingjie Lai)\n   HBASE-1512  Support aggregate functions (Himanshu Vashishtha)\n   HBASE-3796  Per-Store Enties in Compaction Queue\n   HBASE-3670  Fix error handling in get(List<Get> gets)\n               (Harsh J Chouraria)\n   HBASE-3835  Switch master and region server pages to Jamon-based templates\n   HBASE-3721  Speedup LoadIncrementalHFiles (Ted Yu)\n   HBASE-3855  Performance degradation of memstore because reseek is linear\n               (dhruba borthakur)\n   HBASE-3797  StoreFile Level Compaction Locking\n   HBASE-1476  Multithreaded Compactions\n   HBASE-3877  Determine Proper Defaults for Compaction ThreadPools\n   HBASE-3880  Make mapper function in ImportTSV plug-able (Bill Graham)\n   HBASE-2938  HBASE-2938 Add Thread-Local Behavior To HTable Pool\n               (Karthick Sankarachary)\n   HBASE-3811  Allow adding attributes to Scan (Alex Baranau)\n   HBASE-3841  HTable and HTableInterface docs are inconsistent with\n               one another (Harsh J Chouraria)\n   HBASE-2937  Facilitate Timeouts In HBase Client (Karthick Sankarachary)\n   HBASE-3921  Allow adding arbitrary blobs to Put (dhruba borthakur)\n   HBASE-3931  Allow adding attributes to Get\n   HBASE-3942  The thrift scannerOpen functions should support row caching\n               (Adam Worthington)\n   HBASE-2556  Add convenience method to HBaseAdmin to get a collection of\n               HRegionInfo objects for each table (Ming Ma)\n   HBASE-3952  Guava snuck back in as a dependency via hbase-3777\n   HBASE-3808  Implement Executor.toString for master handlers at least\n               (Brock Noland)\n   HBASE-3873  Mavenize Hadoop Snappy JAR/SOs project dependencies\n               (Alejandro Abdelnur)\n   HBASE-3941  \"hbase version\" command line should print version info\n               (Jolly Chen)\n   HBASE-3961  Add Delete.setWriteToWAL functionality (Bruno Dumon)\n   HBASE-3928  Some potential performance improvements to Bytes/KeyValue\n   HBASE-3982  Improvements to TestHFileSeek\n   HBASE-3940  HBase daemons should log version info at startup and possibly\n               periodically (Li Pi)\n   HBASE-3789  Cleanup the locking contention in the master\n   HBASE-3927  Display total uncompressed byte size of a region in web UI\n   HBASE-4011  New MasterObserver hook: post startup of active master\n   HBASE-3994  SplitTransaction has a window where clients can\n               get RegionOfflineException\n   HBASE-4010  HMaster.createTable could be heavily optimized\n   HBASE-3506  Ability to disable, drop and enable tables using regex expression\n               (Joey Echeverria via Ted Yu)\n   HBASE-3516  Coprocessors: add test cases for loading coprocessor jars\n               (Mingjie Lai via garyh)\n   HBASE-4036  Implementing a MultipleColumnPrefixFilter (Anirudh Todi)\n   HBASE-4048  [Coprocessors] Support configuration of coprocessor at load time\n   HBASE-3240  Improve documentation of importtsv and bulk loads.\n               (Aaron T. Myers via todd)\n   HBASE-4054  Usability improvement to HTablePool (Daniel Iancu)\n   HBASE-4079  HTableUtil - helper class for loading data (Doug Meil via Ted Yu)\n   HBASE-3871  Speedup LoadIncrementalHFiles by parallelizing HFile splitting\n   HBASE-4081  Issues with HRegion.compactStores methods (Ming Ma)\n   HBASE-3465  Hbase should use a HADOOP_HOME environment variable if available\n               (Alejandro Abdelnur)\n   HBASE-3899  enhance HBase RPC to support free-ing up server handler threads\n               even if response is not ready (Vlad Dogaru)\n   HBASE-4142  Advise against large batches in javadoc for HTable#put(List<Put>)\n   HBASE-4139  [stargate] Update ScannerModel with support for filter package\n               additions\n   HBASE-1938  Make in-memory table scanning faster (nkeywal)\n   HBASE-4143  HTable.doPut(List) should check the writebuffer length every so often\n               (Doug Meil via Ted Yu)\n   HBASE-3065  Retry all 'retryable' zk operations; e.g. connection loss (Liyin Tang)\n   HBASE-3810  Registering a coprocessor in HTableDescriptor should be easier\n               (Mingjie Lai via garyh)\n   HBASE-4158  Upgrade pom.xml to surefire 2.9 (Aaron Kushner & Mikhail)\n   HBASE-3899  Add ability for delayed RPC calls to set return value\n               immediately at call return. (Vlad Dogaru via todd)\n   HBASE-4169  FSUtils LeaseRecovery for non HDFS FileSystems (Lohit Vijayarenu)\n   HBASE-3807  Fix units in RS UI metrics (subramanian raghunathan)\n   HBASE-4193  Enhance RPC debug logging to provide more details on\n               call contents\n   HBASE-4190  Coprocessors: pull up some cp constants from cp package to\n               o.a.h.h.HConstants (Mingjie Lai)\n   HBASE-4227  Modify the webUI so that default values of column families are\n               not shown (Nileema Shingte)\n   HBASE-4229  Replace Jettison JSON encoding with Jackson in HLogPrettyPrinter\n               (Riley Patterson)\n   HBASE-4230  Compaction threads need names\n   HBASE-4236  Don't lock the stream while serializing the response (Benoit Sigoure)\n   HBASE-4237  Directly remove the call being handled from the map of outstanding RPCs\n               (Benoit Sigoure)\n   HBASE-4199  blockCache summary - backend (Doug Meil)\n   HBASE-4240  Allow Loadbalancer to be pluggable\n   HBASE-4244  Refactor bin/hbase help\n   HBASE-4241  Optimize flushing of the Memstore (Lars Hofhansl)\n   HBASE-4248  Enhancements for Filter Language exposing HBase filters through\n               the Thrift API (Anirudh Todi)\n   HBASE-3900  Expose progress of a major compaction in UI and/or in shell\n               (Brad Anderson)\n   HBASE-4291  Improve display of regions in transition in UI to be more\n               readable (todd)\n   HBASE-4281  Add facility to dump current state of all executors (todd)\n   HBASE-4275  RS should communicate fatal \"aborts\" back to the master (todd)\n   HBASE-4263  New config property for user-table only RegionObservers\n               (Lars Hofhansl)\n   HBASE-4257  Limit the number of regions in transitions displayed on\n               master webpage. (todd)\n   HBASE-1730  Online Schema Changes\n   HBASE-4206  jenkins hash implementation uses longs unnecessarily\n               (Ron Yang)\n   HBASE-3842  Refactor Coprocessor Compaction API\n   HBASE-4312  Deploy new hbase logo\n   HBASE-4327  Compile HBase against hadoop 0.22 (Joep Rottinghuis)\n   HBASE-4339  Improve eclipse documentation and project file generation\n               (Eric Charles)\n   HBASE-4342  Update Thrift to 0.7.0 (Moaz Reyad)\n   HBASE-4260  Expose a command to manually trigger an HLog roll\n               (ramkrishna.s.vasudevan)\n   HBASE-4347  Remove duplicated code from Put, Delete, Get, Scan, MultiPut\n               (Lars Hofhansl)\n   HBASE-4359  Show dead RegionServer names in the HMaster info page\n               (Harsh J)\n   HBASE-4287  If region opening fails, change region in transition into\n               a FAILED_OPEN state so that it can be retried quickly. (todd)\n   HBASE-4381  Refactor split decisions into a split policy class. (todd)\n   HBASE-4373  HBaseAdmin.assign() does not use force flag (Ramkrishna)\n   HBASE-4425  Provide access to RpcServer instance from RegionServerServices\n   HBASE-4411  When copying tables/CFs, allow CF names to be changed\n               (David Revell)\n   HBASE-4424  Provide coprocessors access to createTable() via\n               MasterServices\n   HBASE-4432  Enable/Disable off heap cache with config (Li Pi)\n   HBASE-4434  seek optimization: don't do eager HFile Scanner\n               next() unless the next KV is needed\n               (Kannan Muthukkaruppan)\n   HBASE-4280  [replication] ReplicationSink can deadlock itself via handlers\n   HBASE-4014  Coprocessors: Flag the presence of coprocessors in logged\n               exceptions (Eugene Koontz)\n   HBASE-4449  LoadIncrementalHFiles should be able to handle CFs with blooms\n               (David Revell)\n   HBASE-4454  Add failsafe plugin to build and rename integration tests\n               (Jesse Yates)\n   HBASE-4499  [replication] Source shouldn't update ZK if it didn't progress\n               (Chris Trezzo via JD)\n   HBASE-2794  Utilize ROWCOL bloom filter if multiple columns within same family\n               are requested in a Get (Mikhail Bautin)\n   HBASE-4487  The increment operation can release the rowlock before sync-ing\n               the Hlog (dhruba borthakur)\n   HBASE-4526  special case for stopping master in hbase-daemon.sh is no longer\n               required (Roman Shaposhnik)\n   HBASE-4520  Better handling of Bloom filter type discrepancy between HFile\n               and CF config (Mikhail Bautin)\n   HBASE-4558  Refactor TestOpenedRegionHandler and TestOpenRegionHandler.(Ram)\n   HBASE-4558  Addendum for TestMasterFailover (Ram) - Breaks the build\n   HBASE-4568  Make zk dump jsp response faster\n   HBASE-4606  Remove spam in HCM and fix a list.size == 0\n   HBASE-3581  hbase rpc should send size of response\n   HBASE-4585  Avoid seek operation when current kv is deleted(Liyin Tang)\n   HBASE-4486  Improve Javadoc for HTableDescriptor (Akash Ashok)\n   HBASE-4604  hbase.client.TestHTablePool could start a single\n               cluster instead of one per method (nkeywal)\n   HBASE-3929  Add option to HFile tool to produce basic stats (Matteo\n               Bertozzi and todd via todd)\n   HBASE-4694  Some cleanup of log messages in RS and M\n   HBASE-4603  Uneeded sleep time for tests in\n               hbase.master.ServerManager#waitForRegionServers (nkeywal)\n   HBASE-4703  Improvements in tests (nkeywal)\n   HBASE-4611  Add support for Phabricator/Differential as an alternative code review tool\n   HBASE-3939  Some crossports of Hadoop IPC fixes\n   HBASE-4756  Enable tab-completion in HBase shell (Ryan Thiessen)\n   HBASE-4759  Migrate from JUnit 4.8.2 to JUnit 4.10 (nkeywal)\n   HBASE-4554  Allow set/unset coprocessor table attributes from shell\n               (Mingjie Lai)\n   HBASE-4779  TestHTablePool, TestScanWithBloomError, TestRegionSplitCalculator are\n               not tagged and TestPoolMap should not use TestSuite (N Keywal)\n   HBASE-4805  Allow better control of resource consumption in HTable (Lars H)\n   HBASE-4903  Return a result from RegionObserver.preIncrement\n               (Daniel Gmez Ferro via Lars H)\n   HBASE-4683  Always cache index and bloom blocks\n\n  TASKS\n   HBASE-3559  Move report of split to master OFF the heartbeat channel\n   HBASE-3573  Move shutdown messaging OFF hearbeat; prereq for fix of\n               hbase-1502\n   HBASE-3071  Graceful decommissioning of a regionserver\n   HBASE-3970  Address HMaster crash/failure half way through meta migration\n               (Subbu M Iyer)\n   HBASE-4013  Make ZooKeeperListener Abstract (Akash Ashok via Ted Yu)\n   HBASE-4025  Server startup fails during startup due to failure in loading\n               all table descriptors. (Subbu Iyer via Ted Yu)\n   HBASE-4017  BlockCache interface should be truly modular (Li Pi)\n   HBASE-4152  Rename o.a.h.h.regionserver.wal.WALObserver to\n               o.a.h.h.regionserver.wal.WALActionsListener\n   HBASE-4039  Users should be able to choose custom TableInputFormats without\n               modifying TableMapReduceUtil.initTableMapperJob() (Brock Noland)\n   HBASE-4185  Add doc for new hfilev2 format\n   HBASE-4315  RS requestsPerSecond counter seems to be off (subramanian raghunathan)\n   HBASE-4289  Move spinlock to SingleSizeCache rather than the slab allocator\n               (Li Pi)\n   HBASE-4296  Deprecate HTable[Interface].getRowOrBefore(...) (Lars Hofhansl)\n   HBASE-2195  Support cyclic replication (Lars Hofhansl)\n   HBASE-2196  Support more than one slave cluster (Lars Hofhansl)\n   HBASE-4429  Provide synchronous balanceSwitch()\n   HBASE-4437  Update hadoop in 0.92 (0.20.205?)\n   HBASE-4656  Note how dfs.support.append has to be enabled in 0.20.205.0\n               clusters\n   HBASE-4699  Cleanup the UIs\n   HBASE-4552  Remove trivial 0.90 deprecated code from 0.92 and trunk.\n               (Jonathan Hsieh)\n   HBASE-4714  Don't ship w/ icms enabled by default\n   HBASE-4747  Upgrade maven surefire plugin to 2.10\n   HBASE-4288  \"Server not running\" exception during meta verification causes RS abort\n   HBASE-4856  Upgrade zookeeper to 3.4.0 release\n   HBASE-5111  Upgrade zookeeper to 3.4.2 release\n   HBASE-5125  Upgrade hadoop to 1.0.0\n\n  NEW FEATURES\n   HBASE-2001  Coprocessors: Colocate user code with regions (Mingjie Lai via\n               Andrew Purtell)\n   HBASE-3287  Add option to cache blocks on hfile write and evict blocks on\n               hfile close\n   HBASE-3335  Add BitComparator for filtering (Nathaniel Cook via Stack)\n   HBASE-3260  Coprocessors: Add explicit lifecycle management\n   HBASE-3256  Coprocessors: Coprocessor host and observer for HMaster\n   HBASE-3345  Coprocessors: Allow observers to completely override base\n               function\n   HBASE-2824  A filter that randomly includes rows based on a configured\n               chance (Ferdy via Andrew Purtell)\n   HBASE-3455  Add memstore-local allocation buffers to combat heap\n               fragmentation in the region server. Enabled by default as of\n               0.91\n   HBASE-3257  Coprocessors: Extend server side API to include HLog operations\n               (Mingjie Lai via Andrew Purtell)\n   HBASE-3606  Create an package integration project (Eric Yang via Ryan)\n   HBASE-3488  Add CellCounter to count multiple versions of rows\n               (Subbu M. Iyer via Stack)\n   HBASE-1364  [performance] Distributed splitting of regionserver commit logs\n               (Prakash Khemani)\n   HBASE-3836  Add facility to track currently progressing actions and\n               workflows. (todd)\n   HBASE-3837  Show regions in transition on the master web page (todd)\n   HBASE-3839  Add monitoring of currently running tasks to the master and\n               RS web UIs\n   HBASE-3691  Add compressor support for 'snappy', google's compressor\n               (Nichole Treadway and Nicholas Telford)\n   HBASE-2233  Support both Hadoop 0.20 and 0.22\n   HBASE-3857  Change the HFile Format (Mikhail & Liyin)\n   HBASE-4114  Metrics for HFile HDFS block locality (Ming Ma)\n   HBASE-4176  Exposing HBase Filters to the Thrift API (Anirudh Todi)\n   HBASE-4221  Changes necessary to build and run against Hadoop 0.23\n               (todd)\n   HBASE-4071  Data GC: Remove all versions > TTL EXCEPT the last\n               written version (Lars Hofhansl)\n   HBASE-4242  Add documentation for HBASE-4071 (Lars Hofhansl)\n   HBASE-4027  Enable direct byte buffers LruBlockCache (Li Pi)\n   HBASE-4117  Slow Query Log and Client Operation Fingerprints\n               (Riley Patterson)\n   HBASE-4292  Add a debugging dump servlet to the master and regionserver\n               (todd)\n   HBASE-4057  Implement HBase version of \"show processlist\" (Riley Patterson)\n   HBASE-4219  Per Column Family Metrics\n   HBASE-4219  Addendum for failure of TestHFileBlock\n   HBASE-4377  [hbck] Offline rebuild .META. from fs data only\n               (Jonathan Hsieh)\n   HBASE-4298  Support to drain RS nodes through ZK (Aravind Gottipati)\n   HBASE-2742  Provide strong authentication with a secure RPC engine\n   HBASE-3025  Coprocessor based access control\n\nRelease 0.90.7 - Unreleased\n\n  BUG FIXES\n   HBASE-5271  Result.getValue and Result.getColumnLatest return the wrong column (Ghais Issa)\n\nRelease 0.90.6 - Unreleased\n\n  BUG FIXES\n   HBASE-4970  Add a parameter so that keepAliveTime of Htable thread pool can be changed (gaojinchao)\n   HBASE-5060  HBase client is blocked forever (Jinchao)\n   HBASE-5009  Failure of creating split dir if it already exists prevents splits from happening further\n   HBASE-5041  Major compaction on non existing table does not throw error (Shrijeet)\n   HBASE-5327  Print a message when an invalid hbase.rootdir is passed (Jimmy Xiang)\n\nRelease 0.90.5 - Released\n\n  BUG FIXES\n   HBASE-4160  HBase shell move and online may be unusable if region name\n               or server includes binary-encoded data (Jonathan Hsieh)\n   HBASE-4168  A client continues to try and connect to a powered down\n               regionserver (Anirudh Todi)\n   HBASE-4196  TableRecordReader may skip first row of region (Ming Ma)\n   HBASE-4170  createTable java doc needs to be improved (Mubarak Seyed)\n   HBASE-4144  RS does not abort if the initialization of RS fails\n               (ramkrishna.s.vasudevan)\n   HBASE-4148  HFileOutputFormat doesn't fill in TIMERANGE_KEY metadata\n               (Jonathan Hsieh)\n   HBASE-4159  HBaseServer - IPC Reader threads are not daemons (Douglas\n               Campbell)\n   HBASE-4095  Hlog may not be rolled in a long time if checkLowReplication's\n               request of LogRoll is blocked (Jieshan Bean)\n   HBASE-4253  TestScannerTimeOut.test3686a and TestHTablePool.\n               testReturnDifferentTable() failure because of using new\n               HTable(tablename) (ramkrishna.s.vasudevan)\n   HBASE-4124  ZK restarted while a region is being assigned, new active HM\n               re-assigns it but the RS warns 'already online on this server'\n               (Gaojinchao)\n   HBASE-4294  HLogSplitter sleeps with 1-second granularity (todd)\n   HBASE-4270  IOE ignored during flush-on-close causes dataloss\n   HBASE-4180  HBase should check the isSecurityEnabled flag before login\n   HBASE-4325  Improve error message when using STARTROW for meta scans\n               (Jonathan Hsieh)\n   HBASE-4238  CatalogJanitor can clear a daughter that split before\n               processing its parent\n   HBASE-4445  Not passing --config when checking if distributed mode or not\n   HBASE-4453  TestReplication failing up on builds.a.o because already\n               running zk with new format root servername\n   HBASE-4387  Error while syncing: DFSOutputStream is closed\n               (Lars Hofhansl)\n   HBASE-4295  rowcounter does not return the correct number of rows in\n               certain circumstances (David Revell)\n   HBASE-4515  User.getCurrent() can fail to initialize the current user\n   HBASE-4473  NPE when executors are down but events are still coming in\n   HBASE-4537  TestUser imports breaking build against secure Hadoop\n   HBASE-4501  [replication] Shutting down a stream leaves recovered\n               sources running\n   HBASE-4563  When error occurs in this.parent.close(false) of split,\n               the split region cannot write or read (bluedavy via Lars H)\n   HBASE-4570. Fix a race condition that could cause inconsistent results\n               from scans during concurrent writes. (todd and Jonathan Jsieh\n               via todd)\n   HBASE-4562  When split doing offlineParentInMeta encounters error, it'll\n               cause data loss (bluedavy via Lars H)\n   HBASE-4800  Result.compareResults is incorrect (James Taylor and Lars H)\n   HBASE-4848  TestScanner failing because hostname can't be null\n   HBASE-4862  Splitting hlog and opening region concurrently may cause data loss\n               (Chunhui Shen)\n   HBASE-4773  HBaseAdmin may leak ZooKeeper connections (Xufeng)\n\n  IMPROVEMENT\n   HBASE-4205  Enhance HTable javadoc (Eric Charles)\n   HBASE-4222  Make HLog more resilient to write pipeline failures\n   HBASE-4293  More verbose logging in ServerShutdownHandler for meta/root\n               cases (todd)\n   HBASE-4276  AssignmentManager debug logs should be at INFO level for\n               META/ROOT regions (todd)\n   HBASE-4323  Add debug logging when AssignmentManager can't make a plan\n               for a region (todd)\n   HBASE-4313  Refactor TestHBaseFsck to make adding individual hbck tests\n               easier (Jonathan Hsieh)\n   HBASE-4272. Add -metaonly flag to hbck feature to only inspect and try\n               to repair META and ROOT. (todd)\n   HBASE-4321. Add a more comprehensive region split calculator for future use\n               in hbck. (Jonathan Hsieh)\n   HBASE-4384  Hard to tell what causes failure in CloseRegionHandler#getCurrentVersion\n               (Harsh J)\n   HBASE-4375  [hbck] Add region coverage visualization to hbck\n               (Jonathan Hsieh)\n   HBASE-4506  [hbck] Allow HBaseFsck to be instantiated without connecting\n               (Jonathan Hsieh)\n   HBASE-4509  [hbck] Improve region map output\n               (Jonathan Hsieh)\n   HBASE-4806  Fix logging message in HbaseObjectWritable\n               (Jonathan Hsieh via todd)\n\nRelease 0.90.4 - August 10, 2011\n\n  BUG FIXES\n   HBASE-3878  Hbase client throws NoSuchElementException (Ted Yu)\n   HBASE-3881  Add disable balancer in graceful_stop.sh script\n   HBASE-3895  Fix order of parameters after HBASE-1511\n   HBASE-3874  ServerShutdownHandler fails on NPE if a plan has a random\n               region assignment\n   HBASE-3902  Add Bytes.toBigDecimal and Bytes.toBytes(BigDecimal)\n               (Vaibhav Puranik)\n   HBASE-3820  Splitlog() executed while the namenode was in safemode may\n               cause data-loss (Jieshan Bean)\n   HBASE-3905  HBaseAdmin.createTableAsync() should check for invalid split\n               keys (Ted Yu)\n   HBASE-3908  TableSplit not implementing \"hashCode\" problem (Daniel Iancu)\n   HBASE-3915  Binary row keys in hbck and other miscellaneous binary key\n               display issues\n   HBASE-3914  ROOT region appeared in two regionserver's onlineRegions at\n               the same time (Jieshan Bean)\n   HBASE-3934  MemStoreFlusher.getMemStoreLimit() doesn't honor defaultLimit\n               (Ted Yu)\n   HBASE-3946  The splitted region can be online again while the standby\n               hmaster becomes the active one (Jieshan Bean)\n   HBASE-3916  Fix the default bind address of ThriftServer to be wildcard\n               instead of localhost. (Li Pi)\n   HBASE-3985  Same Region could be picked out twice in LoadBalance\n               (Jieshan Bean)\n   HBASE-3987  Fix a NullPointerException on a failure to load Bloom filter data\n               (Mikhail Bautin)\n   HBASE-3948  Improve split/compact result page for RegionServer status page\n               (Li Pi)\n   HBASE-3988  Infinite loop for secondary master (Liyin Tang)\n   HBASE-3995  HBASE-3946 broke TestMasterFailover\n   HBASE-2077  NullPointerException with an open scanner that expired causing\n               an immediate region server shutdown -- part 2.\n   HBASE-4005  close_region bugs\n   HBASE-4028  Hmaster crashes caused by splitting log.\n               (gaojinchao via Ted Yu)\n   HBASE-4035  Fix local-master-backup.sh - parameter order wrong\n               (Lars George via Ted Yu)\n   HBASE-4020  \"testWritesWhileGetting\" unit test needs to be fixed.\n               (Vandana Ayyalasomayajula via Ted Yu)\n   HBASE-3984  CT.verifyRegionLocation isn't doing a very good check,\n               can delay cluster recovery\n   HBASE-4045  [replication] NPE in ReplicationSource when ZK is gone\n   HBASE-4034  HRegionServer should be stopped even if no META regions\n               are hosted by the HRegionServer (Akash Ashok)\n   HBASE-4033  The shutdown RegionServer could be added to\n               AssignmentManager.servers again (Jieshan Bean)\n   HBASE-4088  npes in server shutdown\n   HBASE-3872  Hole in split transaction rollback; edits to .META. need\n               to be rolled back even if it seems like they didn't make it\n   HBASE-4101  Regionserver Deadlock (ramkrishna.s.vasudevan)\n   HBASE-4115  HBase shell assign and unassign unusable if region name\n               includes binary-encoded data (Ryan Brush)\n   HBASE-4126  Make timeoutmonitor timeout after 30 minutes instead of 3\n   HBASE-4129  HBASE-3872 added a warn message 'CatalogJanitor: Daughter regiondir\n               does not exist' that is triggered though its often legit that daughter\n               is not present\n\n  IMPROVEMENT\n   HBASE-3882  hbase-config.sh needs to be updated so it can auto-detects the\n               sun jre provided by RHEL6 (Roman Shaposhnik)\n   HBASE-3920  HLog hbase.regionserver.flushlogentries no longer supported\n               (Dave Latham)\n   HBASE-3919  More places output binary data to text (Dave Latham)\n   HBASE-3873  HBase IRB shell: Don't pretty-print the output when stdout\n               isn't a TTY (Benot Sigoure)\n   HBASE-3969  Outdated data can not be cleaned in time (Zhou Shuaifeng)\n   HBASE-3968  HLog Pretty Printer (Riley Patterson)\n\nRelease 0.90.3 - May 19th, 2011\n\n  BUG FIXES\n   HBASE-3746  Clean up CompressionTest to not directly reference\n               DistributedFileSystem (todd)\n   HBASE-3734  HBaseAdmin creates new configurations in getCatalogTracker\n   HBASE-3756  Can't move META or ROOT from shell\n   HBASE-3740  hbck doesn't reset the number of errors when retrying\n   HBASE-3744  createTable blocks until all regions are out of transition\n               (Ted Yu via Stack)\n   HBASE-3750  HTablePool.putTable() should call releaseHTableInterface()\n               for discarded tables (Ted Yu via garyh)\n   HBASE-3755  Catch zk's ConnectionLossException and augment error\n               message with more help\n   HBASE-3722  A lot of data is lost when name node crashed (gaojinchao)\n   HBASE-3771  All jsp pages don't clean their HBA\n   HBASE-3685  when multiple columns are combined with TimestampFilter, only\n               one column is returned (Jerry Chen)\n   HBASE-3708  createAndFailSilent is not so silent; leaves lots of logging\n               in ensemble logs (Dmitriy Ryaboy)\n   HBASE-3783  hbase-0.90.2.jar exists in hbase root and in 'lib/'\n   HBASE-3539  Improve shell help to reflect all possible options\n               (Harsh J Chouraria)\n   HBASE-3817  HBase Shell has an issue accepting FILTER for the 'scan' command.\n               (Harsh J Chouraria)\n   HBASE-3634  Fix JavaDoc for put(List<Put> puts) in HTableInterface\n               (Harsh J Chouraria)\n   HBASE-3749  Master can't exit when open port failed (gaojinchao)\n   HBASE-3794  TestRpcMetrics fails on machine where region server is running\n               (Alex Newman)\n   HBASE-3741  Make HRegionServer aware of the regions it's opening/closing\n   HBASE-3597  ageOfLastAppliedOp should update after cluster replication\n               failures\n   HBASE-3821  \"NOT flushing memstore for region\" keep on printing for half\n               an hour (zhoushuaifeng)\n\n  IMPROVEMENTS\n   HBASE-3747  ReplicationSource should differanciate remote and local exceptions\n   HBASE-3652  Speed up tests by lowering some sleeps\n   HBASE-3767  Improve how HTable handles threads used for multi actions\n   HBASE-3795  Remove the \"Cache hit for row\" message\n   HBASE-3580  Remove RS from DeadServer when new instance checks in\n   HBASE-2470  Add Scan.setTimeRange() support in Shell (Harsh J Chouraria)\n   HBASE-3805  Log RegionState that are processed too late in the master\n   HBASE-3695  Some improvements to Hbck to test the entire region chain in\n                Meta and provide better error reporting (Marc Limotte)\n   HBASE-3813  Change RPC callQueue size from 'handlerCount *\n               MAX_QUEUE_SIZE_PER_HANDLER;'\n   HBASE-3860  HLog shouldn't create a new HBC when rolling\n\n  TASKS\n   HBASE-3748  Add rolling of thrift/rest daemons to graceful_stop.sh script\n   HBASE-3846  Set RIT timeout higher\n\nRelease 0.90.2 - 20110408\n\n  BUG FIXES\n   HBASE-3545  Possible liveness issue with MasterServerAddress in\n               HRegionServer getMaster (Greg Bowyer via Stack)\n   HBASE-3548  Fix type in documentation of pseudo distributed mode\n   HBASE-3553  HTable ThreadPoolExecutor does not properly initialize\n               for hbase.htable.threads.max threads\n               (Himanshu Vashishtha via garyh)\n   HBASE-3566  writeToWAL is not serialized for increment operation\n   HBASE-3576  MasterAddressTracker is registered to ZooKeeperWatcher twice\n   HBASE-3561  OPTS arguments are duplicated\n   HBASE-3572  memstore lab can leave half inited data structs (bad!)\n   HBASE-3589  test jar should not include mapred-queues.xml and\n               log4j.properties\n   HBASE-3593  DemoClient.cpp is outdated\n   HBASE-3591  completebulkload doesn't honor generic -D options\n   HBASE-3594  Rest server fails because of missing asm jar\n   HBASE-3582  Allow HMaster and HRegionServer to login from keytab\n               when on secure Hadoop\n   HBASE-3608  MemstoreFlusher error message doesnt include exception!\n   HBASE-1960  Master should wait for DFS to come up when creating\n               hbase.version; use alternate strategy for waiting for DNs\n   HBASE-3612  HBaseAdmin::isTableAvailable returns true when the table does\n               not exit\n   HBASE-3626  Update instructions in thrift demo files (Moaz Reyad via Stack)\n   HBASE-3633  ZKUtil::createSetData should only create a node when it\n               nonexists (Guanpeng Xu via Stack)\n   HBASE-3636  a bug about deciding whether this key is a new key for the ROWCOL\n               bloomfilter (Liyin Tang via Stack)\n   HBASE-3639  FSUtils.getRootDir should qualify path\n   HBASE-3648  [replication] failover is sloppy with znodes\n   HBASE-3613  NPE in MemStoreFlusher\n   HBASE-3650  HBA.delete can return too fast\n   HBASE-3659  Fix TestHLog to pass on newer versions of Hadoop\n   HBASE-3595  get_counter broken in shell\n   HBASE-3664  [replication] Adding a slave when there's none may kill the cluster\n   HBASE-3671  Split report before we finish parent region open; workaround\n               till 0.92; Race between split and OPENED processing\n   HBASE-3674  Treat ChecksumException as we would a ParseException splitting\n               logs; else we replay split on every restart\n   HBASE-3621  The timeout handler in AssignmentManager does an RPC while\n               holding lock on RIT; a big no-no (Ted Yu via Stack)\n   HBASE-3575  Update rename table script\n   HBASE-3687  Bulk assign on startup should handle a ServerNotRunningException\n   HBASE-3617  NoRouteToHostException during balancing will cause Master abort\n               (Ted Yu via Stack)\n   HBASE-3668  CatalogTracker.waitForMeta can wait forever and totally stall a RS\n   HBASE-3627  NPE in EventHandler when region already reassigned\n   HBASE-3660  HMaster will exit when starting with stale data in cached locations\n               such as -ROOT- or .META.\n   HBASE-3654  Weird blocking between getOnlineRegion and createRegionLoad\n               (Subbu M Iyer via Stack)\n   HBASE-3666  TestScannerTimeout fails occasionally\n   HBASE-3497  TableMapReduceUtil.initTableReducerJob broken due to setConf\n               method in TableOutputFormat\n   HBASE-3686  ClientScanner skips too many rows on recovery if using scanner\n               caching (Sean Sechrist via Stack)\n\n  IMPROVEMENTS\n   HBASE-3542  MultiGet methods in Thrift\n   HBASE-3586  Improve the selection of regions to balance (Ted Yu via Andrew\n               Purtell)\n   HBASE-3603  Remove -XX:+HeapDumpOnOutOfMemoryError autodump of heap option\n               on OOME\n   HBASE-3285  Hlog recovery takes too much time\n   HBASE-3623  Allow non-XML representable separator characters in the ImportTSV tool\n               (Harsh J Chouraria via Stack)\n   HBASE-3620  Make HBCK utility faster\n   HBASE-3625  improve/fix support excluding Tests via Maven -D property\n               (Alejandro Abdelnur via todd)\n   HBASE-3437  Support Explict Split Points from the Shell\n   HBASE-3448  RegionSplitter, utility class to manually split tables\n   HBASE-3610  Improve RegionSplitter performance\n   HBASE-3496  HFile CLI Improvements\n   HBASE-3596  [replication] Wait a few seconds before transferring queues\n   HBASE-3600  Update our jruby to 1.6.0\n   HBASE-3640  [replication] Transferring queues shouldn't be done inline with RS startup\n   HBASE-3658  Alert when heap is over committed (Subbu M Iyer via Stack)\n   HBASE-3681  Check the sloppiness of the region load before balancing (Ted Yu via JD)\n   HBASE-3703  hbase-config.sh needs to be updated so it can auto-detect\n               the sun jdk provided by RHEL6 (Bruno Mahe via todd)\n\nRelease 0.90.1 - February 9th, 2011\n\n  NEW FEATURES\n   HBASE-3455  Add memstore-local allocation buffers to combat heap\n               fragmentation in the region server. Experimental / disabled\n               by default in 0.90.1\n\n  BUG FIXES\n   HBASE-3445  Master crashes on data that was moved from different host\n   HBASE-3449  Server shutdown handlers deadlocked waiting for META\n   HBASE-3456  Fix hardcoding of 20 second socket timeout down in HBaseClient\n   HBASE-3476  HFile -m option need not scan key values\n               (Prakash Khemani via Lars George)\n   HBASE-3481  max seq id in flushed file can be larger than its correct value\n               causing data loss during recovery\n   HBASE-3493  HMaster sometimes hangs during initialization due to missing\n               notify call (Bruno Dumon via Stack)\n   HBASE-3483  Memstore lower limit should trigger asynchronous flushes\n   HBASE-3494  checkAndPut implementation doesnt verify row param and writable\n               row are the same\n   HBASE-3416  For intra-row scanning, the update readers notification resets\n               the query matcher and can lead to incorrect behavior\n   HBASE-3495  Shell is failing on subsequent split calls\n   HBASE-3502  Can't open region because can't open .regioninfo because\n               AlreadyBeingCreatedException\n   HBASE-3501  Remove the deletion limit in LogCleaner\n   HBASE-3500  Documentation update for replicatio\n   HBASE-3419  If re-transition to OPENING during log replay fails, server\n               aborts. Instead, should just cancel region open.\n   HBASE-3524  NPE from CompactionChecker\n   HBASE-3531  When under global memstore pressure, dont try to flush\n               unflushable regions.\n   HBASE-3550  FilterList reports false positives (Bill Graham via Andrew\n               Purtell)\n\n  IMPROVEMENTS\n   HBASE-3305  Allow round-robin distribution for table created with\n               multiple regions (ted yu via jgray)\n   HBASE-3508  LruBlockCache statistics thread should have a name\n   HBASE-3511  Allow rolling restart to apply to only RS or only masters\n   HBASE-3510  Add thread name for IPC reader threads\n   HBASE-3509  Add metric for flush queue length\n   HBASE-3517  Store build version in hbase-default.xml and verify at runtime\n\nRelease 0.90.0 - January 19th, 2011\n  INCOMPATIBLE CHANGES\n   HBASE-1822  Remove the deprecated APIs\n   HBASE-1848  Fixup shell for HBASE-1822\n   HBASE-1854  Remove the Region Historian\n   HBASE-1930  Put.setTimeStamp misleading (doesn't change timestamp on\n               existing KeyValues, not copied in copy constructor)\n               (Dave Latham via Stack)\n   HBASE-1360  move up to Thrift 0.2.0 (Kay Kay and Lars Francke via Stack)\n   HBASE-2212  Refactor out lucene dependencies from HBase\n               (Kay Kay via Stack)\n   HBASE-2219  stop using code mapping for method names in the RPC\n   HBASE-1728  Column family scoping and cluster identification\n   HBASE-2099  Move build to Maven (Paul Smith via Stack)\n   HBASE-2260  Remove all traces of Ant and Ivy (Lars Francke via Stack)\n   HBASE-2255  take trunk back to hadoop 0.20\n   HBASE-2378  Bulk insert with multiple reducers broken due to improper\n               ImmutableBytesWritable comparator (Todd Lipcon via Stack)\n   HBASE-2392  Upgrade to ZooKeeper 3.3.0\n   HBASE-2294  Enumerate ACID properties of HBase in a well defined spec\n               (Todd Lipcon via Stack)\n   HBASE-2541  Remove transactional contrib (Clint Morgan via Stack)\n   HBASE-2542  Fold stargate contrib into core\n   HBASE-2565  Remove contrib module from hbase\n   HBASE-2397  Bytes.toStringBinary escapes printable chars\n   HBASE-2771  Update our hadoop jar to be latest from 0.20-append branch\n   HBASE-2803  Remove remaining Get code from Store.java,etc\n   HBASE-2553  Revisit IncrementColumnValue implementation in 0.22\n   HBASE-2692  Master rewrite and cleanup for 0.90\n               (Karthik Ranganathan, Jon Gray & Stack)\n   HBASE-2961  Close zookeeper when done with it (HCM, Master, and RS)\n   HBASE-2641  HBASE-2641 Refactor HLog splitLog, hbase-2437 continued;\n               break out split code as new classes\n               (James Kennedy via Stack)\n\n  BUG FIXES\n   HBASE-1791  Timeout in IndexRecordWriter (Bradford Stephens via Andrew\n               Purtell)\n   HBASE-1737  Regions unbalanced when adding new node (recommit)\n   HBASE-1792  [Regression] Cannot save timestamp in the future\n   HBASE-1793  [Regression] HTable.get/getRow with a ts is broken\n   HBASE-1698  Review documentation for o.a.h.h.mapreduce\n   HBASE-1798  [Regression] Unable to delete a row in the future\n   HBASE-1790  filters are not working correctly (HBASE-1710 HBASE-1807 too)\n   HBASE-1779  ThriftServer logged error if getVer() result is empty\n   HBASE-1778  Improve PerformanceEvaluation (Schubert Zhang via Stack)\n   HBASE-1751  Fix KeyValue javadoc on getValue for client-side\n   HBASE-1795  log recovery doesnt reset the max sequence id, new logfiles can\n               get tossed as 'duplicates'\n   HBASE-1794  recovered log files are not inserted into the storefile map\n   HBASE-1824  [stargate] default timestamp should be LATEST_TIMESTAMP\n   HBASE-1740  ICV has a subtle race condition only visible under high load\n   HBASE-1808  [stargate] fix how columns are specified for scanners\n   HBASE-1828  CompareFilters are broken from client-side\n   HBASE-1836  test of indexed hbase broken\n   HBASE-1838  [javadoc] Add javadoc to Delete explaining behavior when no\n               timestamp provided\n   HBASE-1821  Filtering by SingleColumnValueFilter bug\n   HBASE-1840  RowLock fails when used with IndexTable\n               (Keith Thomas via Stack)\n   HBASE-818   HFile code review and refinement (Schubert Zhang via Stack)\n   HBASE-1830  HbaseObjectWritable methods should allow null HBCs\n               for when Writable is not Configurable (Stack via jgray)\n   HBASE-1847  Delete latest of a null qualifier when non-null qualifiers\n               exist throws a RuntimeException\n   HBASE-1850  src/examples/mapred do not compile after HBASE-1822\n   HBASE-1853  Each time around the regionserver core loop, we clear the\n               messages to pass master, even if we failed to deliver them\n   HBASE-1815  HBaseClient can get stuck in an infinite loop while attempting\n               to contact a failed regionserver\n   HBASE-1856  HBASE-1765 broke MapReduce when using Result.list()\n               (Lars George via Stack)\n   HBASE-1857  WrongRegionException when setting region online after .META.\n               split (Cosmin Lehane via Stack)\n   HBASE-1809  NPE thrown in BoundedRangeFileInputStream\n   HBASE-1859  Misc shell fixes patch (Kyle Oba via Stack)\n   HBASE-1865  0.20.0 TableInputFormatBase NPE\n   HBASE-1866  Scan(Scan) copy constructor does not copy value of\n               cacheBlocks\n   HBASE-1869  IndexedTable delete fails when used in conjunction with\n               RowLock (Keith Thomas via Stack)\n   HBASE-1858  Master can't split logs created by THBase (Clint Morgan via\n               Andrew Purtell)\n   HBASE-1871  Wrong type used in TableMapReduceUtil.initTableReduceJob()\n               (Lars George via Stack)\n   HBASE-1883  HRegion passes the wrong minSequenceNumber to\n               doReconstructionLog (Clint Morgan via Stack)\n   HBASE-1878  BaseScanner results can't be trusted at all (Related to\n               hbase-1784)\n   HBASE-1831  Scanning API must be reworked to allow for fully functional\n               Filters client-side\n   HBASE-1890  hbase-1506 where assignment is done at regionserver doesn't\n               work\n   HBASE-1889  ClassNotFoundException on trunk for REST\n   HBASE-1905  Remove unused config. hbase.hstore.blockCache.blockSize\n   HBASE-1906  FilterList of prefix and columnvalue not working properly with\n               deletes and multiple values\n   HBASE-1896  WhileMatchFilter.reset should call encapsulated filter reset\n   HBASE-1912  When adding a secondary index to an existing table, it will\n               cause NPE during re-indexing (Mingjui Ray Liao via Andrew\n               Purtell)\n   HBASE-1916  FindBugs and javac warnings cleanup\n   HBASE-1908  ROOT not reassigned if only one regionserver left\n   HBASE-1915  HLog.sync is called way too often, needs to be only called one\n               time per RPC\n   HBASE-1777  column length is not checked before saved to memstore\n   HBASE-1925  IllegalAccessError: Has not been initialized (getMaxSequenceId)\n   HBASE-1929  If hbase-default.xml is not in CP, zk session timeout is 10\n               seconds!\n   HBASE-1927  Scanners not closed properly in certain circumstances\n   HBASE-1934  NullPointerException in ClientScanner (Andrew Purtell via Stack)\n   HBASE-1946  Unhandled exception at regionserver (Dmitriy Lyfar via Stack)\n   HBASE-1682  IndexedRegion does not properly handle deletes\n               (Andrew McCall via Clint Morgan and Stack)\n   HBASE-1953  Overhaul of overview.html (html fixes, typos, consistency) -\n               no content changes (Lars Francke via Stack)\n   HBASE-1954  Transactional scans do not see newest put (Clint Morgan via\n               Stack)\n   HBASE-1919  code: HRS.delete seems to ignore exceptions it shouldnt\n   HBASE-1951  Stack overflow when calling HTable.checkAndPut()\n               when deleting a lot of values\n   HBASE-1781  Weird behavior of WildcardColumnTracker.checkColumn(),\n               looks like recursive loop\n   HBASE-1949  KeyValue expiration by Time-to-Live during major compaction is\n               broken (Gary Helmling via Stack)\n   HBASE-1957  Get-s can't set a Filter\n   HBASE-1928  ROOT and META tables stay in transition state (making the system\n               not usable) if the designated regionServer dies before the\n               assignment is complete (Yannis Pavlidis via Stack)\n   HBASE-1962  Bulk loading script makes regions incorrectly (loadtable.rb)\n   HBASE-1966  Apply the fix from site/ to remove the forrest dependency on\n               Java 5\n   HBASE-1967  [Transactional] client.TestTransactions.testPutPutScan fails\n               sometimes -- Temporary fix\n   HBASE-1841  If multiple of same key in an hfile and they span blocks, may\n               miss the earlier keys on a lookup\n               (Schubert Zhang via Stack)\n   HBASE-1977  Add ts and allow setting VERSIONS when scanning in shell\n   HBASE-1979  MurmurHash does not yield the same results as the reference C++\n               implementation when size % 4 >= 2 (Olivier Gillet via Andrew\n               Purtell)\n   HBASE-1999  When HTable goes away, close zk session in shutdown hook or\n               something...\n   HBASE-1997  zk tick time bounds maximum zk session time\n   HBASE-2003  [shell] deleteall ignores column if specified\n   HBASE-2018  Updates to .META. blocked under high MemStore load\n   HBASE-1994  Master will lose hlog entries while splitting if region has\n               empty oldlogfile.log (Lars George via Stack)\n   HBASE-2022  NPE in housekeeping kills RS\n   HBASE-2034  [Bulk load tools] loadtable.rb calls an undefined method\n               'descendingIterator' (Ching-Shen Chen via Stack)\n   HBASE-2033  Shell scan 'limit' is off by one\n   HBASE-2040  Fixes to group commit\n   HBASE-2047  Example command in the \"Getting Started\"\n               documentation doesn't work (Benoit Sigoure via JD)\n   HBASE-2048  Small inconsistency in the \"Example API Usage\"\n               (Benoit Sigoure via JD)\n   HBASE-2044  HBASE-1822 removed not-deprecated APIs\n   HBASE-1960  Master should wait for DFS to come up when creating\n               hbase.version\n   HBASE-2054  memstore size 0 is >= than blocking -2.0g size\n   HBASE-2064  Cannot disable a table if at the same the Master is moving\n               its regions around\n   HBASE-2065  Cannot disable a table if any of its region is opening\n               at the same time\n   HBASE-2026  NPE in StoreScanner on compaction\n   HBASE-2072  fs.automatic.close isn't passed to FileSystem\n   HBASE-2075  Master requires HDFS superuser privileges due to waitOnSafeMode\n   HBASE-2077  NullPointerException with an open scanner that expired causing\n               an immediate region server shutdown (Sam Pullara via JD)\n   HBASE-2078  Add JMX settings as commented out lines to hbase-env.sh\n               (Lars George via JD)\n   HBASE-2082  TableInputFormat is ignoring input scan's stop row setting\n               (Scott Wang via Andrew Purtell)\n   HBASE-2068  MetricsRate is missing \"registry\" parameter\n               (Lars George and Gary Helmling via Stack)\n   HBASE-2093  [stargate] RowSpec parse bug\n   HBASE-2114  Can't start HBase in trunk (JD and Kay Kay via JD)\n   HBASE-2115  ./hbase shell would not launch due to missing jruby dependency\n               (Kay Kay via JD)\n   HBASE-2101  KeyValueSortReducer collapses all values to last passed\n   HBASE-2119  Fix top-level NOTICES.txt file. Its stale.\n   HBASE-2120  [stargate] Unable to delete column families (Greg Lu via Andrew\n               Purtell)\n   HBASE-2123  Remove 'master' command-line option from PE\n   HBASE-2024  [stargate] Deletes not working as expected (Greg Lu via Andrew\n               Purtell)\n   HBASE-2122  [stargate] Initializing scanner column families doesn't work\n               (Greg Lu via Andrew Purtell)\n   HBASE-2124  Useless exception in HMaster on startup\n   HBASE-2127  randomWrite mode of PerformanceEvaluation benchmark program\n               writes only to a small range of keys (Kannan Muthukkaruppan\n               via Stack)\n   HBASE-2126  Fix build break - ec2 (Kay Kay via JD)\n   HBASE-2134  Ivy nit regarding checking with latest snapshots (Kay Kay via\n               Andrew Purtell)\n   HBASE-2138  unknown metrics type (Stack via JD)\n   HBASE-2137  javadoc warnings from 'javadoc' target (Kay Kay via Stack)\n   HBASE-2135  ant javadoc complains about missing classe (Kay Kay via Stack)\n   HBASE-2130  bin/* scripts - not to include lib/test/**/*.jar\n               (Kay Kay via Stack)\n   HBASE-2140  findbugs issues - 2 performance warnings as suggested by\n               findbugs (Kay Kay via Stack)\n   HBASE-2139  findbugs task in build.xml (Kay Kay via Stack)\n   HBASE-2147  run zookeeper in the same jvm as master during non-distributed\n               mode\n   HBASE-65    Thrift Server should have an option to bind to ip address\n               (Lars Francke via Stack)\n   HBASE-2146  RPC related metrics are missing in 0.20.3 since recent changes\n               (Gary Helmling via Lars George)\n   HBASE-2150  Deprecated HBC(Configuration) constructor doesn't call this()\n   HBASE-2154  Fix Client#next(int) javadoc\n   HBASE-2152  Add default jmxremote.{access|password} files into conf\n               (Lars George and Gary Helmling via Stack)\n   HBASE-2156  HBASE-2037 broke Scan - only a test for trunk\n   HBASE-2057  Cluster won't stop (Gary Helmling and JD via JD)\n   HBASE-2160  Can't put with ts in shell\n   HBASE-2144  Now does \\x20 for spaces\n   HBASE-2163  ZK dependencies - explicitly add them until ZK artifacts are\n               published to mvn repository (Kay Kay via Stack)\n   HBASE-2164  Ivy nit - clean up configs (Kay Kay via Stack)\n   HBASE-2184  Calling HTable.getTableDescriptor().* on a full cluster takes\n               a long time (Cristian Ivascu via Stack)\n   HBASE-2193  Better readability of - hbase.regionserver.lease.period\n               (Kay Kay via Stack)\n   HBASE-2199  hbase.client.tableindexed.IndexSpecification, lines 72-73\n               should be reversed (Adrian Popescu via Stack)\n   HBASE-2224  Broken build: TestGetRowVersions.testGetRowMultipleVersions\n   HBASE-2129  ant tar build broken since switch to Ivy (Kay Kay via Stack)\n   HBASE-2226  HQuorumPeerTest doesnt run because it doesnt start with the\n               word Test\n   HBASE-2230  SingleColumnValueFilter has an ungaurded debug log message\n   HBASE-2258  The WhileMatchFilter doesn't delegate the call to filterRow()\n   HBASE-2259  StackOverflow in ExplicitColumnTracker when row has many columns\n   HBASE-2268  [stargate] Failed tests and DEBUG output is dumped to console\n               since move to Mavenized build\n   HBASE-2276  Hbase Shell hcd() method is broken by the replication scope\n               parameter (Alexey Kovyrin via Lars George)\n   HBASE-2244  META gets inconsistent in a number of crash scenarios\n   HBASE-2284  fsWriteLatency metric may be incorrectly reported\n               (Kannan Muthukkaruppan via Stack)\n   HBASE-2063  For hfileoutputformat, on timeout/failure/kill clean up\n               half-written hfile (Ruslan Salyakhov via Stack)\n   HBASE-2281  Hbase shell does not work when started from the build dir\n               (Alexey Kovyrin via Stack)\n   HBASE-2293  CME in RegionManager#isMetaServer\n   HBASE-2261  The javadoc in WhileMatchFilter and it's tests in TestFilter\n               are not accurate/wrong\n   HBASE-2299  [EC2] mapreduce fixups for PE\n   HBASE-2295  Row locks may deadlock with themselves\n               (dhruba borthakur via Stack)\n   HBASE-2308  Fix the bin/rename_table.rb script, make it work again\n   HBASE-2307  hbase-2295 changed hregion size, testheapsize broke... fix it\n   HBASE-2269  PerformanceEvaluation \"--nomapred\" may assign duplicate random\n               seed over multiple testing threads (Tatsuya Kawano via Stack)\n   HBASE-2287  TypeError in shell (Alexey Kovyrin via Stack)\n   HBASE-2023  Client sync block can cause 1 thread of a multi-threaded client\n               to block all others (Karthik Ranganathan via Stack)\n   HBASE-2305  Client port for ZK has no default (Suraj Varma via Stack)\n   HBASE-2323  filter.RegexStringComparator does not work with certain bytes\n               (Benoit Sigoure via Stack)\n   HBASE-2313  Nit-pick about hbase-2279 shell fixup, if you do get with\n               non-existant column family, throws lots of exceptions\n               (Alexey Kovyrin via Stack)\n   HBASE-2334  Slimming of Maven dependency tree - improves assembly build\n               speed (Paul Smith via Stack)\n   HBASE-2336  Fix build broken with HBASE-2334 (Lars Francke via Lars George)\n   HBASE-2283  row level atomicity (Kannan Muthukkaruppan via Stack)\n   HBASE-2355  Unsynchronized logWriters map is mutated from several threads in\n               HLog splitting (Todd Lipcon via Andrew Purtell)\n   HBASE-2358  Store doReconstructionLog will fail if oldlogfile.log is empty\n               and won't load region (Cosmin Lehene via Stack)\n   HBASE-2370  saveVersion.sh doesnt properly grab the git revision\n   HBASE-2373  Remove confusing log message of how \"BaseScanner GET got\n               different address/startcode than SCAN\"\n   HBASE-2361  WALEdit broke replication scope\n   HBASE-2365  Double-assignment around split\n   HBASE-2398  NPE in HLog.append when calling writer.getLength\n               (Kannan Muthukkaruppan via Stack)\n   HBASE-2410  spurious warnings from util.Sleeper\n   HBASE-2335  mapred package docs don't say zookeeper jar is a dependent\n   HBASE-2417  HCM.locateRootRegion fails hard on \"Connection refused\"\n   HBASE-2346  Usage of FilterList slows down scans\n   HBASE-2341  ZK settings for initLimit/syncLimit should not have been removed\n               from hbase-default.xml\n   HBASE-2439  HBase can get stuck if updates to META are blocked\n               (Kannan Muthukkaruppan via Stack)\n   HBASE-2451  .META. by-passes cache; BLOCKCACHE=>'false'\n   HBASE-2453  Revisit compaction policies after HBASE-2248 commit\n               (Jonathan Gray via Stack)\n   HBASE-2458  Client stuck in TreeMap,remove (Todd Lipcon via Stack)\n   HBASE-2460  add_table.rb deletes any tables for which the target table name\n               is a prefix (Todd Lipcon via Stack)\n   HBASE-2463  Various Bytes.* functions silently ignore invalid arguments\n               (Benoit Sigoure via Stack)\n   HBASE-2443  IPC client can throw NPE if socket creation fails\n               (Todd Lipcon via Stack)\n   HBASE-2447  LogSyncer.addToSyncQueue doesn't check if syncer is still\n               running before waiting (Todd Lipcon via Stack)\n   HBASE-2494  Does not apply new.name parameter to CopyTable\n               (Yoonsik Oh via Stack)\n   HBASE-2481  Client is not getting UnknownScannerExceptions; they are\n               being eaten (Jean-Daniel Cryans via Stack)\n   HBASE-2448  Scanner threads are interrupted without acquiring lock properly\n               (Todd Lipcon via Stack)\n   HBASE-2491  master.jsp uses absolute links to table.jsp. This broke when\n               master.jsp moved under webapps/master(Cristian Ivascu via Stack)\n   HBASE-2487  Uncaught exceptions in receiving IPC responses orphan clients\n               (Todd Lipcon via Stack)\n   HBASE-2497  ProcessServerShutdown throws NullPointerException for offline\n               regiond (Miklos Kurucz via Stack)\n   HBASE-2499  Race condition when disabling a table leaves regions in transition\n   HBASE-2489  Make the \"Filesystem needs to be upgraded\" error message more\n               useful (Benoit Sigoure via Stack)\n   HBASE-2482  regions in transition do not get reassigned by master when RS\n               crashes (Todd Lipcon via Stack)\n   HBASE-2513  hbase-2414 added bug where we'd tight-loop if no root available\n   HBASE-2503  PriorityQueue isn't thread safe, KeyValueHeap uses it that way\n   HBASE-2431  Master does not respect generation stamps, may result in meta\n               getting permanently offlined\n   HBASE-2515  ChangeTableState considers split&&offline regions as being served\n   HBASE-2544  Forward port branch 0.20 WAL to TRUNK\n   HBASE-2546  Specify default filesystem in both the new and old way (needed\n               if we are to run on 0.20 and 0.21 hadoop)\n   HBASE-1895  HConstants.MAX_ROW_LENGTH is incorrectly 64k, should be 32k\n   HBASE-1968  Give clients access to the write buffer\n   HBASE-2028  Add HTable.incrementColumnValue support to shell\n               (Lars George via Andrew Purtell)\n   HBASE-2138  unknown metrics type\n   HBASE-2551  Forward port fixes that are in branch but not in trunk (part of\n               the merge of old 0.20 into TRUNK task) -- part 1.\n   HBASE-2474  Bug in HBASE-2248 - mixed version reads (not allowed by spec)\n   HBASE-2509  NPEs in various places, HRegion.get, HRS.close\n   HBASE-2344  InfoServer and hence HBase Master doesn't fully start if you\n               have HADOOP-6151 patch (Kannan Muthukkaruppan via Stack)\n   HBASE-2382  Don't rely on fs.getDefaultReplication() to roll HLogs\n               (Nicolas Spiegelberg via Stack)\n   HBASE-2415  Disable META splitting in 0.20 (Todd Lipcon via Stack)\n   HBASE-2421  Put hangs for 10 retries on failed region servers\n   HBASE-2442  Log lease recovery catches IOException too widely\n               (Todd Lipcon via Stack)\n   HBASE-2457  RS gets stuck compacting region ad infinitum\n   HBASE-2562  bin/hbase doesn't work in-situ in maven\n               (Todd Lipcon via Stack)\n   HBASE-2449  Local HBase does not stop properly\n   HBASE-2539  Cannot start ZK before the rest in tests anymore\n   HBASE-2561  Scanning .META. while split in progress yields\n               IllegalArgumentException (Todd Lipcon via Stack)\n   HBASE-2572  hbase/bin/set_meta_block_caching.rb:72: can't convert\n               Java::JavaLang::String into String (TypeError) - little\n               issue with script\n   HBASE-2483  Some tests do not use ephemeral ports\n   HBASE-2573  client.HConnectionManager$TableServers logs non-printable\n               binary bytes (Benot Sigoure via Stack)\n   HBASE-2576  TestHRegion.testDelete_mixed() failing on hudson\n   HBASE-2581  Bloom commit broke some tests... fix\n   HBASE-2582  TestTableSchemaModel not passing after commit of blooms\n   HBASE-2583  Make webapps work in distributed mode again and make webapps\n               deploy at / instead of at /webapps/master/master.jsp\n   HBASE-2590  Failed parse of branch element in saveVersion.sh\n   HBASE-2591  HBASE-2587 hardcoded the port that dfscluster runs on\n   HBASE-2519  StoreFileScanner.seek swallows IOEs (Todd Lipcon via Stack)\n   HBASE-2516  Ugly IOE when region is being closed; rather, should NSRE\n               (Daniel Ploeg via Stack)\n   HBASE-2589  TestHRegion.testWritesWhileScanning flaky on trunk\n               (Todd Lipcon via Stack)\n   HBASE-2590  Failed parse of branch element in saveVersion.sh\n               (Benot Sigoure via Stack)\n   HBASE-2586  Move hbase webapps to a hbase-webapps dir (Todd Lipcon via\n               Andrew Purtell)\n   HBASE-2610  ValueFilter copy pasted javadoc from QualifierFilter\n   HBASE-2619  HBase shell 'alter' command cannot set table properties to False\n               (Christo Wilson via Stack)\n   HBASE-2621  Fix bad link to HFile documentation in javadoc\n               (Jeff Hammerbacher via Todd Lipcon)\n   HBASE-2371  Fix 'list' command in shell (Alexey Kovyrin via Todd Lipcon)\n   HBASE-2620  REST tests don't use ephemeral ports\n   HBASE-2635  ImmutableBytesWritable ignores offset in several cases\n   HBASE-2654  Add additional maven repository temporarily to fetch Guava\n   HBASE-2560  Fix IllegalArgumentException when manually splitting table\n               from web UI\n   HBASE-2657  TestTableResource is broken in trunk\n   HBASE-2662  TestScannerResource.testScannerResource broke in trunk\n   HBASE-2667  TestHLog.testSplit failing in trunk (Cosmin and Stack)\n   HBASE-2614  killing server in TestMasterTransitions causes NPEs and test deadlock\n   HBASE-2615  M/R on bulk imported tables\n   HBASE-2676  TestInfoServers should use ephemeral ports\n   HBASE-2616  TestHRegion.testWritesWhileGetting flaky on trunk\n   HBASE-2684  TestMasterWrongRS flaky in trunk\n   HBASE-2691  LeaseStillHeldException totally ignored by RS, wrongly named\n   HBASE-2703  ui not working in distributed context\n   HBASE-2710  Shell should use default terminal width when autodetection fails\n               (Kannan Muthukkaruppan via Todd Lipcon)\n   HBASE-2712  Cached region location that went stale won't recover if\n               asking for first row\n   HBASE-2732  TestZooKeeper was broken, HBASE-2691 showed it\n   HBASE-2670  Provide atomicity for readers even when new insert has\n               same timestamp as current row.\n   HBASE-2733  Replacement of LATEST_TIMESTAMP with real timestamp was broken\n               by HBASE-2353.\n   HBASE-2734  TestFSErrors should catch all types of exceptions, not just RTE\n   HBASE-2738  TestTimeRangeMapRed updated now that we keep multiple cells with\n               same timestamp in MemStore\n   HBASE-2725  Shutdown hook management is gone in trunk; restore\n   HBASE-2740  NPE in ReadWriteConsistencyControl\n   HBASE-2752  Don't retry forever when waiting on too many store files\n   HBASE-2737  CME in ZKW introduced in HBASE-2694 (Karthik Ranganathan via JD)\n   HBASE-2756  MetaScanner.metaScan doesn't take configurations\n   HBASE-2656  HMaster.getRegionTableClosest should not return null for closed\n               regions\n   HBASE-2760  Fix MetaScanner TableNotFoundException when scanning starting at\n               the first row in a table.\n   HBASE-1025  Reconstruction log playback has no bounds on memory used\n   HBASE-2757  Fix flaky TestFromClientSide test by forcing region assignment\n   HBASE-2741  HBaseExecutorService needs to be multi-cluster friendly\n               (Karthik Ranganathan via JD)\n   HBASE-2769  Fix typo in warning message for HBaseConfiguration\n   HBASE-2768  Fix teardown order in TestFilter\n   HBASE-2763  Cross-port HADOOP-6833 IPC parameter leak bug\n   HBASE-2758  META region stuck in RS2ZK_REGION_OPENED state\n               (Karthik Ranganathan via jgray)\n   HBASE-2767  Fix reflection in tests that was made incompatible by HDFS-1209\n   HBASE-2617  Load balancer falls into pathological state if one server under\n               average - slop; endless churn\n   HBASE-2729  Interrupted or failed memstore flushes should not corrupt the\n               region\n   HBASE-2772  Scan doesn't recover from region server failure\n   HBASE-2775  Update of hadoop jar in HBASE-2771 broke TestMultiClusters\n   HBASE-2774  Spin in ReadWriteConsistencyControl eating CPU (load > 40) and\n               no progress running YCSB on clean cluster startup\n   HBASE-2785  TestScannerTimeout.test2772 is flaky\n   HBASE-2787  PE is confused about flushCommits\n   HBASE-2707  Can't recover from a dead ROOT server if any exceptions happens\n               during log splitting\n   HBASE-2501  Refactor StoreFile Code\n   HBASE-2806  DNS hiccups cause uncaught NPE in HServerAddress#getBindAddress\n               (Benoit Sigoure via Stack)\n   HBASE-2806  (small compile fix via jgray)\n   HBASE-2797  Another NPE in ReadWriteConsistencyControl\n   HBASE-2831  Fix '$bin' path duplication in setup scripts\n               (Nicolas Spiegelberg via Stack)\n   HBASE-2781  ZKW.createUnassignedRegion doesn't make sure existing znode is\n               in the right state (Karthik Ranganathan via JD)\n   HBASE-2727  Splits writing one file only is untenable; need dir of recovered\n               edits ordered by sequenceid\n   HBASE-2843  Readd bloomfilter test over zealously removed by HBASE-2625\n   HBASE-2846  Make rest server be same as thrift and avro servers\n   HBASE-1511  Pseudo distributed mode in LocalHBaseCluster\n               (Nicolas Spiegelberg via Stack)\n   HBASE-2851  Remove testDynamicBloom() unit test\n               (Nicolas Spiegelberg via Stack)\n   HBASE-2853  TestLoadIncrementalHFiles fails on TRUNK\n   HBASE-2854  broken tests on trunk\n   HBASE-2859  Cleanup deprecated stuff in TestHLog (Alex Newman via Stack)\n   HBASE-2858  TestReplication.queueFailover fails half the time\n   HBASE-2863  HBASE-2553 removed an important edge case\n   HBASE-2866  Region permanently offlined\n   HBASE-2849  HBase clients cannot recover when their ZooKeeper session\n               becomes invalid (Benit Sigoure via Stack)\n   HBASE-2876  HBase hbck: false positive error reported for parent regions\n               that are in offline state in meta after a split\n   HBASE-2815  not able to run the test suite in background because TestShell\n               gets suspended on tty output (Alexey Kovyrin via Stack)\n   HBASE-2852  Bloom filter NPE (pranav via jgray)\n   HBASE-2820  hbck throws an error if HBase root dir isn't on the default FS\n   HBASE-2884  TestHFileOutputFormat flaky when map tasks generate identical\n               data\n   HBASE-2890  Initialize RPC JMX metrics on startup (Gary Helmling via Stack)\n   HBASE-2755  Duplicate assignment of a region after region server recovery\n               (Kannan Muthukkaruppan via Stack)\n   HBASE-2892  Replication metrics aren't updated\n   HBASE-2461  Split doesn't handle IOExceptions when creating new region\n               reference files\n   HBASE-2871  Make \"start|stop\" commands symmetric for Master & Cluster\n               (Nicolas Spiegelberg via Stack)\n   HBASE-2901  HBASE-2461 broke build\n   HBASE-2823  Entire Row Deletes not stored in Row+Col Bloom\n               (Alexander Georgiev via Stack)\n   HBASE-2897  RowResultGenerator should handle NoSuchColumnFamilyException\n   HBASE-2905  NPE when inserting mass data via REST interface (Sandy Yin via\n               Andrew Purtell)\n   HBASE-2908  Wrong order of null-check [in TIF] (Libor Dener via Stack)\n   HBASE-2909  SoftValueSortedMap is broken, can generate NPEs\n   HBASE-2919  initTableReducerJob: Unused method parameter\n               (Libor Dener via Stack)\n   HBASE-2923  Deadlock between HRegion.internalFlushCache and close\n   HBASE-2927  BaseScanner gets stale HRegionInfo in some race cases\n   HBASE-2928  Fault in logic in BinaryPrefixComparator leads to\n               ArrayIndexOutOfBoundsException (pranav via jgray)\n   HBASE-2924  TestLogRolling doesn't use the right HLog half the time\n   HBASE-2931  Do not throw RuntimeExceptions in RPC/HbaseObjectWritable\n               code, ensure we log and rethrow as IOE\n               (Karthik Ranganathan via Stack)\n   HBASE-2915  Deadlock between HRegion.ICV and HRegion.close\n   HBASE-2920  HTable.checkAndPut/Delete doesn't handle null values\n   HBASE-2944  cannot alter bloomfilter setting for a column family from\n               hbase shell (Kannan via jgray)\n   HBASE-2948  bin/hbase shell broken (after hbase-2692)\n               (Sebastian Bauer via Stack)\n   HBASE-2954  Fix broken build caused by hbase-2692 commit\n   HBASE-2918  SequenceFileLogWriter doesnt make it clear if there is no\n               append by config or by missing lib/feature\n   HBASE-2799  \"Append not enabled\" warning should not show if hbase\n               root dir isn't on DFS\n   HBASE-2943  major_compact (and other admin commands) broken for .META.\n   HBASE-2643  Figure how to deal with eof splitting logs\n               (Nicolas Spiegelberg via Stack)\n   HBASE-2925  LRU of HConnectionManager.HBASE_INSTANCES breaks if\n               HBaseConfiguration is changed\n               (Robert Mahfoud via Stack)\n   HBASE-2964  Deadlock when RS tries to RPC to itself inside SplitTransaction\n   HBASE-1485  Wrong or indeterminate behavior when there are duplicate\n               versions of a column (pranav via jgray)\n   HBASE-2967  Failed split: IOE 'File is Corrupt!' -- sync length not being\n               written out to SequenceFile\n   HBASE-2969  missing sync in HTablePool.getTable()\n               (Guilherme Mauro Germoglio Barbosa via Stack)\n   HBASE-2973  NPE in LogCleaner\n   HBASE-2974  LoadBalancer ArithmeticException: / by zero\n   HBASE-2975  DFSClient names in master and RS should be unique\n   HBASE-2978  LoadBalancer IndexOutOfBoundsException\n   HBASE-2983  TestHLog unit test is mis-comparing an assertion\n               (Alex Newman via Todd Lipcon)\n   HBASE-2986  multi writable can npe causing client hang\n   HBASE-2979  Fix failing TestMultParrallel in hudson build\n   HBASE-2899  hfile.min.blocksize.size ignored/documentation wrong\n   HBASE-3006  Reading compressed HFile blocks causes way too many DFS RPC\n               calls severly impacting performance\n               (Kannan Muthukkaruppan via Stack)\n   HBASE-3010  Can't start/stop/start... cluster using new master\n   HBASE-3015  recovered.edits files not deleted if it only contain edits that\n               have already been flushed; hurts perf for all future opens of\n               the region\n   HBASE-3018  Bulk assignment on startup runs serially through the cluster\n               servers assigning in bulk to one at a time\n   HBASE-3023  NPE processing server crash in MetaReader. getServerUserRegions\n   HBASE-3024  NPE processing server crash in MetaEditor.addDaughter\n   HBASE-3026  Fixup of \"missing\" daughters on split is too aggressive\n   HBASE-3003  ClassSize constants dont use 'final'\n   HBASE-3002  Fix zookeepers.sh to work properly with strange JVM options\n   HBASE-3028  No basescanner means no GC'ing of split, offlined parent regions\n   HBASE-2989  [replication] RSM won't cleanup after locking if 0 peers\n   HBASE-2992  [replication] MalformedObjectNameException in ReplicationMetrics\n   HBASE-3037  When new master joins running cluster does \"Received report from\n               unknown server -- telling it to STOP_REGIONSERVER.\n   HBASE-3039  Stuck in regionsInTransition because rebalance came in at same\n               time as a split\n   HBASE-3042  Use LO4J in SequenceFileLogReader\n               (Nicolas Spiegelberg via Stack)\n   HBASE-2995  Incorrect dependency on Log class from Jetty\n   HBASE-3038  WALReaderFSDataInputStream.getPos() fails if Filesize > MAX_INT\n               (Nicolas Spiegelberg via Stack)\n   HBASE-3047  If new master crashes, restart is messy\n   HBASE-3054  Remore TestEmptyMetaInfo; it doesn't make sense any more.\n   HBASE-3056  Fix ordering in ZKWatcher constructor to prevent weird race\n               condition\n   HBASE-3057  Race condition when closing regions that causes flakiness in\n               TestRestartCluster\n   HBASE-3058  Fix REST tests on trunk\n   HBASE-3068  IllegalStateException when new server comes online, is given\n               200 regions to open and 200th region gets timed out of regions\n               in transition\n   HBASE-3064  Long sleeping in HConnectionManager after thread is interrupted\n               (Bruno Dumon via Stack)\n   HBASE-2753  Remove sorted() methods from Result now that Gets are Scans\n   HBASE-3059  TestReadWriteConsistencyControl occasionally hangs (Hairong\n               via Ryan)\n   HBASE-2906  [rest/stargate] URI decoding in RowResource\n   HBASE-3008  Memstore.updateColumnValue passes wrong flag to heapSizeChange\n               (Causes memstore size to go negative)\n   HBASE-3089  REST tests are broken locally and up in hudson\n   HBASE-3062  ZooKeeper KeeperException$ConnectionLossException is a\n               \"recoverable\" exception; we should retry a while on server\n               startup at least.\n   HBASE-3074  Zookeeper test failing on hudson\n   HBASE-3089  REST tests are broken locally and up in hudson\n   HBASE-3085  TestSchemaResource broken on TRUNK up on HUDSON\n   HBASE-3080  TestAdmin hanging on hudson\n   HBASE-3063  TestThriftServer failing in TRUNK\n   HBASE-3094  Fixes for miscellaneous broken tests\n   HBASE-3060  [replication] Reenable replication on trunk with unit tests\n   HBASE-3041  [replication] ReplicationSink shouldn't kill the whole RS when\n               it fails to replicate\n   HBASE-3044  [replication] ReplicationSource won't cleanup logs if there's\n               nothing to replicate\n   HBASE-3113  Don't reassign regions if cluster is being shutdown\n   HBASE-2933  Skip EOF Errors during Log Recovery\n               (Nicolas Spiegelberg via Stack)\n   HBASE-3081  Log Splitting & Replay: Distinguish between Network IOE and\n               Parsing IOE (Nicolas Spiegelberg via Stack)\n   HBASE-3098  TestMetaReaderEditor is broken in TRUNK; hangs\n   HBASE-3110  TestReplicationSink failing in TRUNK up on Hudson\n   HBASE-3101  bin assembly doesn't include -tests or -source jars\n   HBASE-3121  [rest] Do not perform cache control when returning results\n   HBASE-2669  HCM.shutdownHook causes data loss with\n               hbase.client.write.buffer != 0\n   HBASE-2985  HRegionServer.multi() no longer calls HRegion.put(List) when\n               possible\n   HBASE-3031  CopyTable MR job named \"Copy Table\" in Driver\n   HBASE-2658  REST (stargate) TableRegionModel Regions need to be updated to\n               work w/ new region naming convention from HBASE-2531\n   HBASE-3140  Rest schema modification throw null pointer exception\n               (David Worms via Stack)\n   HBASE-2998  rolling-restart.sh shouldn't rely on zoo.cfg\n   HBASE-3145  importtsv fails when the line contains no data\n               (Kazuki Ohta via Todd Lipcon)\n   HBASE-2984  [shell] Altering a family shouldn't reset to default unchanged\n               attributes\n   HBASE-3143  Adding the tests' hbase-site.xml to the jar breaks some clients\n   HBASE-3139  Server shutdown processor stuck because meta not online\n   HBASE-3136  Stale reads from ZK can break the atomic CAS operations we\n               have in ZKAssign\n   HBASE-2753  Remove sorted() methods from Result now that Gets are Scans\n   HBASE-3147  Regions stuck in transition after rolling restart, perpetual\n               timeout handling but nothing happens\n   HBASE-3158  Bloom File Writes Broken if keySize is large\n               (Nicolas Spiegelberg via Stack)\n   HBASE-3155  HFile.appendMetaBlock() uses wrong comparator\n               (Nicolas Spiegelberg via Stack)\n   HBASE-3012  TOF doesn't take zk client port for remote clusters\n   HBASE-3159  Double play of OpenedRegionHandler for a single region\n               and assorted fixes around this + TestRollingRestart added\n   HBASE-3160  Use more intelligent priorities for PriorityCompactionQueue\n               (Nicolas Spiegelberg via Stack)\n   HBASE-3172  Reverse order of AssignmentManager and MetaNodeTracker in\n               ZooKeeperWatcher\n   HBASE-2406  Define semantics of cell timestamps/versions\n   HBASE-3175  Commit of HBASE-3160 broke TestPriorityCompactionQueue up on\n               hudson (nicolas via jgray)\n   HBASE-3163  If we timeout PENDING_CLOSE and send another closeRegion RPC,\n               need to handle NSRE from RS (comes as a RemoteException)\n   HBASE-3164  Handle case where we open META, ROOT has been closed but\n               znode location not deleted yet, and try to update META\n               location in ROOT\n   HBASE-2006  Documentation of hbase-site.xml parameters\n   HBASE-2672  README.txt should contain basic information like how to run\n               or build HBase\n   HBASE-3179  Enable ReplicationLogsCleaner only if replication is,\n               and fix its test\n   HBASE-3185  User-triggered compactions are triggering splits!\n   HBASE-1932  Encourage use of 'lzo' compression... add the wiki page to\n               getting started\n   HBASE-3151  NPE when trying to read regioninfo from .META.\n   HBASE-3191  FilterList with MUST_PASS_ONE and SCVF isn't working\n               (Stefan Seelmann via Stack)\n   HBASE-2471  Splitting logs, we'll make an output file though the\n               region no longer exists\n   HBASE-3095  Client needs to reconnect if it expires its zk session\n   HBASE-2935  Refactor \"Corrupt Data\" Tests in TestHLogSplit\n               (Alex Newman via Stack)\n   HBASE-3202  Closing a region, if we get a ConnectException, handle\n               it rather than abort\n   HBASE-3198  Log rolling archives files prematurely\n   HBASE-3203  We can get an order to open a region while shutting down\n               and it'll hold up regionserver shutdown\n   HBASE-3204  Reenable deferred log flush\n   HBASE-3195  [rest] Fix TestTransform breakage on Hudson\n   HBASE-3205  TableRecordReaderImpl.restart NPEs when first next is restarted\n   HBASE-3208  HLog.findMemstoresWithEditsOlderThan needs to look for edits\n               that are equal to too\n   HBASE-3141  Master RPC server needs to be started before an RS can check in\n   HBASE-3112  Enable and disable of table needs a bit of loving in new master\n   HBASE-3207  If we get IOException when closing a region, we should still\n               remove it from online regions and complete the close in ZK\n   HBASE-3199  large response handling: some fixups and cleanups\n   HBASE-3212  More testing of enable/disable uncovered base condition not in\n               place; i.e. that only one enable/disable runs at a time\n   HBASE-2898  MultiPut makes proper error handling impossible and leads to\n   \t       corrupted data\n   HBASE-3213  If do abort of backup master will get NPE instead of graceful\n               abort\n   HBASE-3214  TestMasterFailover.testMasterFailoverWithMockedRITOnDeadRS is\n               failing (Gary via jgray)\n   HBASE-3216  Move HBaseFsck from client to util\n   HBASE-3219  Split parents are reassigned on restart and on disable/enable\n   HBASE-3222  Regionserver region listing in UI is no longer ordered\n   HBASE-3221  Race between splitting and disabling\n   HBASE-3224  NPE in KeyValue$KVComparator.compare when compacting\n   HBASE-3233  Fix Long Running Stats\n   HBASE-3232  Fix KeyOnlyFilter + Add Value Length (Nicolas via Ryan)\n   HBASE-3235  Intermittent incrementColumnValue failure in TestHRegion\n   \t       (Gary via Ryan)\n   HBASE-3241  check to see if we exceeded hbase.regionserver.maxlogs limit is\n               incorrect (Kannan Muthukkaruppan via JD)\n   HBASE-3239  Handle null regions to flush in HLog.cleanOldLogs (Kannan\n               Muthukkaruppan via JD)\n   HBASE-3237  Split request accepted -- BUT CURRENTLY A NOOP\n   HBASE-3252  TestZooKeeperNodeTracker sometimes fails due to a race condition\n               in test notification (Gary Helmling via Andrew Purtell)\n   HBASE-3253  Thrift's missing from all the repositories in pom.xml\n   HBASE-3258  EOF when version file is empty\n   HBASE-3259  Can't kill the region servers when they wait on the master or\n               the cluster state znode\n   HBASE-3249  Typing 'help shutdown' in the shell shouldn't shutdown the cluster\n   HBASE-3262  TestHMasterRPCException uses non-ephemeral port for master\n   HBASE-3272  Remove no longer used options\n   HBASE-3269  HBase table truncate semantics seems broken as \"disable\" table\n               is now async by default\n   HBASE-3275  [rest] No gzip/deflate content encoding support\n   HBASE-3261  NPE out of HRS.run at startup when clock is out of sync\n   HBASE-3277  HBase Shell zk_dump command broken\n   HBASE-3267  close_region shell command breaks region\n   HBASE-3265  Regionservers waiting for ROOT while Master waiting for RegionServers\n   HBASE-3263  Stack overflow in AssignmentManager\n   HBASE-3234  hdfs-724 \"breaks\" TestHBaseTestingUtility multiClusters\n   HBASE-3286  Master passes IP and not hostname back to region server\n   HBASE-3297  If rows in .META. with no HRegionInfo cell, then hbck fails read\n               of .META.\n   HBASE-3294  WARN org.apache.hadoop.hbase.regionserver.Store: Not in set\n               (double-remove?) org.apache.hadoop.hbase.regionserver.StoreScanner@76607d3d\n   HBASE-3299  If failed open, we don't output the IOE\n   HBASE-3291  If split happens while regionserver is going down, we can stick open.\n   HBASE-3295  Dropping a 1k+ regions table likely ends in a client socket timeout\n               and it's very confusing\n   HBASE-3301  Treat java.net.SocketTimeoutException same as ConnectException\n               assigning/unassigning regions\n   HBASE-3296  Newly created table ends up disabled instead of assigned\n   HBASE-3304  Get spurious master fails during bootup\n   HBASE-3298  Regionserver can close during a split causing double assignment\n   HBASE-3309  \" Not running balancer because dead regionserver processing\" is a lie\n   HBASE-3314  [shell] 'move' is broken\n   HBASE-3315  Add debug output for when balancer makes bad balance\n   HBASE-3278  AssertionError in LoadBalancer\n   HBASE-3318  Split rollback leaves parent with writesEnabled=false\n   HBASE-3334  Refresh our hadoop jar because of HDFS-1520\n   HBASE-3347  Can't truncate/disable table that has rows in .META. that have empty\n               info:regioninfo column\n   HBASE-3321  Replication.join shouldn't clear the logs znode\n   HBASE-3352  enabling a non-existent table from shell prints no error\n   HBASE-3353  table.jsp doesn't handle entries in META without server info\n   HBASE-3351  ReplicationZookeeper goes to ZK every time a znode is modified\n   HBASE-3326  Replication state's znode should be created else it\n               defaults to false\n   HBASE-3355  Stopping a stopped cluster leaks an HMaster\n   HBASE-3356  Add more checks in replication if RS is stopped\n   HBASE-3358  Recovered replication queue wait on themselves when terminating\n   HBASE-3359  LogRoller not added as a WAL listener when replication is enabled\n   HBASE-3360  ReplicationLogCleaner is enabled by default in 0.90 -- causes NPE\n   HBASE-3363  ReplicationSink should batch delete\n   HBASE-3365  EOFE contacting crashed RS causes Master abort\n   HBASE-3362  If .META. offline between OPENING and OPENED, then wrong server\n               location in .META. is possible\n   HBASE-3368  Split message can come in before region opened message; results\n               in 'Region has been PENDING_CLOSE for too long' cycle\n   HBASE-3366  WALObservers should be notified before the lock\n   HBASE-3367  Failed log split not retried\n   HBASE-3370  ReplicationSource.openReader fails to locate HLogs when they\n               aren't split yet\n   HBASE-3371  Race in TestReplication can make it fail\n   HBASE-3323  OOME in master splitting logs\n   HBASE-3374  Our jruby jar has *GPL jars in it; fix\n   HBASE-3343  Server not shutting down after losing log lease\n   HBASE-3381  Interrupt of a region open comes across as a successful open\n   HBASE-3386  NPE in TableRecordReaderImpl.restart\n   HBASE-3388  NPE processRegionInTransition(AssignmentManager.java:264)\n               doing rolling-restart.sh\n   HBASE-3383  [0.90RC1] bin/hbase script displays \"no such file\" warning on\n               target/cached_classpath.txt\n   HBASE-3344  Master aborts after RPC to server that was shutting down\n   HBASE-3408  AssignmentManager NullPointerException\n   HBASE-3402  Web UI shows two META regions\n   HBASE-3409  Failed server shutdown processing when retrying hlog split\n   HBASE-3412  HLogSplitter should handle missing HLogs\n   HBASE-3420  Handling a big rebalance, we can queue multiple instances of\n               a Close event; messes up state\n   HBASE-3423  hbase-env.sh over-rides HBASE_OPTS incorrectly (Ted Dunning via\n               Andrew Purtell)\n   HBASE-3407  hbck should pause between fixing and re-checking state\n   HBASE-3401  Region IPC operations should be high priority\n   HBASE-3430  hbase-daemon.sh should clean up PID files on process stop\n\n\n  IMPROVEMENTS\n   HBASE-1760  Cleanup TODOs in HTable\n   HBASE-1759  Ability to specify scanner caching on a per-scan basis\n               (Ken Weiner via jgray)\n   HBASE-1763  Put writeToWAL methods do not have proper getter/setter names\n               (second commit to fix compile error in hregion)\n   HBASE-1770  HTable.setWriteBufferSize does not flush the writeBuffer when\n               its size is set to a value lower than its current size.\n               (Mathias via jgray)\n   HBASE-1771  PE sequentialWrite is 7x slower because of\n               MemStoreFlusher#checkStoreFileCount\n   HBASE-1758  Extract interface out of HTable (Vaibhav Puranik via Andrew\n               Purtell)\n   HBASE-1776  Make rowcounter enum public\n   HBASE-1276  [testing] Upgrade to JUnit 4.x and use @BeforeClass\n               annotations to optimize tests\n   HBASE-1800  Too many ZK connections\n   HBASE-1819  Update to 0.20.1 hadoop and zk 3.2.1\n   HBASE-1820  Update jruby from 1.2 to 1.3.1\n   HBASE-1687  bin/hbase script doesn't allow for different memory settings\n               for each daemon type\n   HBASE-1823  Ability for Scanners to bypass the block cache\n   HBASE-1827  Add disabling block cache scanner flag to the shell\n   HBASE-1835  Add more delete tests\n   HBASE-1574  Client and server APIs to do batch deletes\n   HBASE-1833  hfile.main fixes\n   HBASE-1684  Backup (Export/Import) contrib tool for 0.20\n   HBASE-1860  Change HTablePool#createHTable from private to protected\n   HBASE-48    Bulk load tools\n   HBASE-1855  HMaster web application doesn't show the region end key in the\n               table detail page (Andrei Dragomir via Stack)\n   HBASE-1870  Bytes.toFloat(byte[], int) is marked private\n   HBASE-1874  Client Scanner mechanism that is used for HbaseAdmin methods\n               (listTables, tableExists), is very slow if the client is far\n               away from the HBase cluster (Andrei Dragomir via Stack)\n   HBASE-1879  ReadOnly transactions generate WAL activity (Clint Morgan via\n               Stack)\n   HBASE-1875  Compression test utility\n   HBASE-1832  Faster enable/disable/delete\n   HBASE-1481  Add fast row key only scanning\n   HBASE-1506  [performance] Make splits faster\n   HBASE-1722  Add support for exporting HBase metrics via JMX\n               (Gary Helming via Stack)\n   HBASE-1899  Use scanner caching in shell count\n   HBASE-1887  Update hbase trunk to latests on hadoop 0.21 branch so we can\n               all test sync/append\n   HBASE-1902  Let PerformanceEvaluation support setting tableName and compress\n               algorithm (Schubert Zhang via Stack)\n   HBASE-1885  Simplify use of IndexedTable outside Java API\n               (Kevin Patterson via Stack)\n   HBASE-1903  Enable DEBUG by default\n   HBASE-1907  Version all client writables\n   HBASE-1914  hlog should be able to set replication level for the log\n               indendently from any other files\n   HBASE-1537  Intra-row scanning\n   HBASE-1918  Don't do DNS resolving in .META. scanner for each row\n   HBASE-1756  Refactor HLog (changing package first)\n   HBASE-1926  Remove unused xmlenc jar from trunk\n   HBASE-1936  HLog group commit\n   HBASE-1921  When the Master's session times out and there's only one,\n               cluster is wedged\n   HBASE-1942  Update hadoop jars in trunk; update to r831142\n   HBASE-1943  Remove AgileJSON; unused\n   HBASE-1944  Add a \"deferred log flush\" attribute to HTD\n   HBASE-1945  Remove META and ROOT memcache size bandaid\n   HBASE-1947  If HBase starts/stops often in less than 24 hours,\n               you end up with lots of store files\n   HBASE-1829  Make use of start/stop row in TableInputFormat\n               (Lars George via Stack)\n   HBASE-1867  Tool to regenerate an hbase table from the data files\n   HBASE-1904  Add tutorial for installing HBase on Windows using Cygwin as\n               a test and development environment (Wim Van Leuven via Stack)\n   HBASE-1963  Output to multiple tables from Hadoop MR without use of HTable\n               (Kevin Peterson via Andrew Purtell)\n   HBASE-1975  SingleColumnValueFilter: Add ability to match the value of\n               previous versions of the specified column\n               (Jeremiah Jacquet via Stack)\n   HBASE-1971  Unit test the full WAL replay cycle\n   HBASE-1970  Export does one version only; make it configurable how many\n               it does\n   HBASE-1987  The Put object has no simple read methods for checking what\n               has already been added (Ryan Smith via Stack)\n   HBASE-1985  change HTable.delete(ArrayList) to HTable.delete(List)\n   HBASE-1958  Remove \"# TODO: PUT BACK !!! \"${HADOOP_HOME}\"/bin/hadoop\n               dfsadmin -safemode wait\"\n   HBASE-2011  Add zktop like output to HBase's master UI (Lars George via\n               Andrew Purtell)\n   HBASE-1995  Add configurable max value size check (Lars George via Andrew\n               Purtell)\n   HBASE-2017  Set configurable max value size check to 10MB\n   HBASE-2029  Reduce shell exception dump on console\n               (Lars George and J-D via Stack)\n   HBASE-2027  HConnectionManager.HBASE_INSTANCES leaks TableServers\n               (Dave Latham via Stack)\n   HBASE-2013  Add useful helpers to HBaseTestingUtility.java (Lars George\n               via J-D)\n   HBASE-2031  When starting HQuorumPeer, try to match on more than 1 address\n   HBASE-2043  Shell's scan broken\n   HBASE-2044  HBASE-1822 removed not-deprecated APIs\n   HBASE-2049  Cleanup HLog binary log output (Dave Latham via Stack)\n   HBASE-2052  Make hbase more 'live' when comes to noticing table creation,\n               splits, etc., for 0.20.3\n   HBASE-2059  Break out WAL reader and writer impl from HLog\n   HBASE-2060  Missing closing tag in mapreduce package info (Lars George via\n               Andrew Purtell)\n   HBASE-2028  Add HTable.incrementColumnValue support to shell (Lars George\n               via Andrew Purtell)\n   HBASE-2062  Metrics documentation outdated (Lars George via JD)\n   HBASE-2045  Update trunk and branch zk to just-release 3.2.2.\n   HBASE-2074  Improvements to the hadoop-config script (Bassam Tabbara via\n               Stack)\n   HBASE-2076  Many javadoc warnings\n   HBASE-2068  MetricsRate is missing \"registry\" parameter (Lars George via JD)\n   HBASE-2025  0.20.2 accessed from older client throws\n               UndeclaredThrowableException; frustrates rolling upgrade\n   HBASE-2081  Set the retries higher in shell since client pause is lower\n   HBASE-1956  Export HDFS read and write latency as a metric\n   HBASE-2036  Use Configuration instead of HBaseConfiguration (Enis Soztutar\n               via Stack)\n   HBASE-2085  StringBuffer -> StringBuilder - conversion of references as\n               necessary (Kay Kay via Stack)\n   HBASE-2052  Upper bound of outstanding WALs can be overrun\n   HBASE-2086  Job(configuration,String) deprecated (Kay Kay via Stack)\n   HBASE-1996  Configure scanner buffer in bytes instead of number of rows\n               (Erik Rozendaal and Dave Latham via Stack)\n   HBASE-2090  findbugs issues (Kay Kay via Stack)\n   HBASE-2089  HBaseConfiguration() ctor. deprecated (Kay Kay via Stack)\n   HBASE-2035  Binary values are formatted wrong in shell\n   HBASE-2095  TIF shuold support more confs for the scanner (Bassam Tabbara\n               via Andrew Purtell)\n   HBASE-2107  Upgrading Lucene 2.2 to Lucene 3.0.0 (Kay Kay via Stack)\n   HBASE-2111  Move to ivy broke our being able to run in-place; i.e.\n               ./bin/start-hbase.sh in a checkout\n   HBASE-2136  Forward-port the old mapred package\n   HBASE-2133  Increase default number of client handlers\n   HBASE-2109  status 'simple' should show total requests per second, also\n   \t       the requests/sec is wrong as is\n   HBASE-2151  Remove onelab and include generated thrift classes in javadoc\n               (Lars Francke via Stack)\n   HBASE-2149  hbase.regionserver.global.memstore.lowerLimit is too low\n   HBASE-2157  LATEST_TIMESTAMP not replaced by current timestamp in KeyValue\n               (bulk loading)\n   HBASE-2153  Publish generated HTML documentation for Thrift on the website\n               (Lars Francke via Stack)\n   HBASE-1373  Update Thrift to use compact/framed protocol (Lars Francke via\n               Stack)\n   HBASE-2172  Add constructor to Put for row key and timestamp\n               (Lars Francke via Stack)\n   HBASE-2178  Hooks for replication\n   HBASE-2180  Bad random read performance from synchronizing\n               hfile.fddatainputstream\n   HBASE-2194  HTable - put(Put) , put(List<Put) code duplication (Kay Kay via\n               Stack)\n   HBASE-2185  Add html version of default hbase-site.xml (Kay Kay via Stack)\n   HBASE-2198  SingleColumnValueFilter should be able to find the column value\n               even when it's not specifically added as input on the sc\n               (Ferdy via Stack)\n   HBASE-2189  HCM trashes meta cache even when not needed\n   HBASE-2190  HRS should report to master when HMsg are available\n   HBASE-2209  Support of List [ ] in HBaseOutputWritable for serialization\n               (Kay Kay via Stack)\n   HBASE-2177  Add timestamping to gc logging option\n   HBASE-2066  Perf: parallelize puts\n   HBASE-2222  Improve log \"Trying to contact region server Some server for\n               region, row 'ip_info_100,,1263329969690', but failed after\n               11 attempts\".\n   HBASE-2220  Add a binary comparator that only compares up to the length\n               of the supplied byte array (Bruno Dumon via Stack)\n   HBASE-2211  Add a new Filter that checks a single column value but does not\n               emit it. (Ferdy via Stack)\n   HBASE-2241  Change balancer sloppyness from 0.1 to 0.3\n   HBASE-2250  typo in the maven pom\n   HBASE-2254  Improvements to the Maven POMs (Lars Francke via Stack)\n   HBASE-2262  ZKW.ensureExists should check for existence\n   HBASE-2264  Adjust the contrib apps to the Maven project layout\n               (Lars Francke via Lars George)\n   HBASE-2245  Unnecessary call to syncWal(region); in HRegionServer\n               (Benoit Sigoure via JD)\n   HBASE-2246  Add a getConfiguration method to HTableInterface\n               (Benoit Sigoure via JD)\n   HBASE-2282  More directories should be ignored when using git for\n               development (Alexey Kovyrin via Stack)\n   HBASE-2267  More improvements to the Maven build (Lars Francke via Stack)\n   HBASE-2174  Stop from resolving HRegionServer addresses to names using DNS\n               on every heartbeat (Karthik Ranganathan via Stack)\n   HBASE-2302  Optimize M-R by bulk excluding regions - less InputSplit-s to\n               avoid traffic on region servers when performing M-R on a subset\n               of the table (Kay Kay via Stack)\n   HBASE-2309  Add apache releases to pom (list of ) repositories\n               (Kay Kay via Stack)\n   HBASE-2279  Hbase Shell does not have any tests (Alexey Kovyrin via Stack)\n   HBASE-2314  [shell] Support for getting counters (Alexey Kovyrin via Stack)\n   HBASE-2324  Refactoring of TableRecordReader (mapred / mapreduce) for reuse\n               outside the scope of InputSplit / RecordReader (Kay Kay via\n               Stack)\n   HBASE-2313  Nit-pick about hbase-2279 shell fixup, if you do get with\n               non-existant column family, throws lots of exceptions\n               (Alexey Kovyrin via Stack)\n   HBASE-2331  [shell] count command needs a way to specify scan caching\n               (Alexey Kovyrin via Stack)\n   HBASE-2364  Ignore Deprecations during build (Paul Smith via Stack)\n   HBASE-2338  log recovery: deleted items may be resurrected\n               (Aravind Menon via Stack)\n   HBASE-2359  WALEdit doesn't implement HeapSize\n               (Kannan Muthukkaruppan via Stack)\n   HBASE-2348  [stargate] Stargate needs both JAR and WAR artifacts (Paul Smith\n               via Andrew Purtell)\n   HBASE-2389  HTable - delete / put unnecessary sync (Kay Kay via Stack)\n   HBASE-2385  Debug Message \"Received report from unknown server\" should be\n               INFO or WARN\n   HBASE-2374  TableInputFormat - Configurable parameter to add column families\n               (Kay Kay via Stack)\n   HBASE-2388  Give a very explicit message when we figure a big GC pause\n   HBASE-2270  Improve how we handle recursive calls in ExplicitColumnTracker\n               and WildcardColumnTracker\n   HBASE-2402  [stargate] set maxVersions on gets\n   HBASE-2087  The wait on compaction because \"Too many store files\"\n               holds up all flushing\n   HBASE-2252  Mapping a very big table kills region servers\n   HBASE-2412  [stargate] PerformanceEvaluation\n   HBASE-2419  Remove from RS logs the fat NotServingRegionException stack\n   HBASE-2286  [Transactional Contrib] Correctly handle or avoid cases where\n               writes occur in same millisecond (Clint Morgan via J-D)\n   HBASE-2360  Make sure we have all the hadoop fixes in our our copy of its rpc\n               (Todd Lipcon via Stack)\n   HBASE-2423  Update 'Getting Started' for 0.20.4 including making\n               \"important configurations more visiable\"\n   HBASE-2435  HTablePool - method to release resources after use\n               (Kay Kay via Stack)\n   HBASE-1933  Upload Hbase jars to a public maven repository\n               (Kay Kay via Stack)\n   HBASE-2440  Master UI should check against known bad JDK versions and\n               warn the user (Todd Lipcon via Stack)\n   HBASE-2430  Disable frag display in trunk, let HBASE-2165 replace it\n   HBASE-1892  [performance] make hbase splits run faster\n   HBASE-2456  deleteChangedReaderObserver spitting warnings after HBASE-2248\n   HBASE-2452  Fix our Maven dependencies (Lars Francke via Stack)\n   HBASE-2490  Improve the javadoc of the client API for HTable\n               (Benoit Sigoure via Stack)\n   HBASE-2488  Master should warn more loudly about unexpected events\n               (Todd Lipcon via Stack)\n   HBASE-2393  ThriftServer instantiates a new HTable per request\n               (Bogdan DRAGU via Stack)\n   HBASE-2496  Less ArrayList churn on the scan path\n   HBASE-2414  Enhance test suite to be able to specify distributed scenarios\n   HBASE-2518  Kill all the trailing whitespaces in the code base\n               (Benoit Sigoure via Stack)\n   HBASE-2528  ServerManager.ServerMonitor isn't daemonized\n   HBASE-2537  Change ordering of maven repos listed in pom.xml to have\n               ibiblio first\n   HBASE-2540  Make QueryMatcher.MatchCode public (Clint Morgan via Stack)\n   HBASE-2524  Unresponsive region server, potential deadlock\n               (Todd Lipcon via Stack)\n   HBASE-2547  [mvn] assembly:assembly does not include hbase-X.X.X-test.jar\n               (Paul Smith via Stack)\n   HBASE-2037  The core elements of HBASE-2037: refactoring flushing, and adding\n   \t           configurability in which HRegion subclass is instantiated\n   HBASE-2248  Provide new non-copy mechanism to assure atomic reads in get and scan\n   HBASE-2523  Add check for licenses before rolling an RC, add to\n               how-to-release doc. and check for inlining a tool that does\n               this for us\n   HBASE-2234  HBASE-2234  Roll Hlog if any datanode in the write pipeline dies\n               (Nicolas Spiegelberg via Stack)\n   HBASE-2340  Add end-to-end test of sync/flush (Forward-port from branch)\n   HBASE-2555  Get rid of HColumnDescriptor.MAPFILE_INDEX_INTERVAL\n   HBASE-2520  Cleanup arrays vs Lists of scanners (Todd Lipcon via Stack)\n   HBASE-2551  Forward port fixes that are in branch but not in trunk (part\n               of the merge of old 0.20 into TRUNK task)\n   HBASE-2466  Improving filter API to allow for modification of keyvalue list\n   \t           by filter (Juhani Connolly via Ryan)\n   HBASE-2566  Remove 'lib' dir; it only has libthrift and that is being\n               pulled from http://people.apache.org/~rawson/repo/....\n   HBASE-2534  Recursive deletes and misc improvements to ZKW\n   HBASE-2577  Remove 'core' maven module; move core up a level\n   HBASE-2587  Coral where tests write data when running and make sure clean\n               target removes all written\n   HBASE-2580  Make the hlog file names unique\n   HBASE-2594  Narrow pattern used finding unit tests to run -- make it same\n               was we had in 0.20\n   HBASE-2538  Work on repository order in pom (adding fbmirror to top,\n               ibiblio on bottom)\n   HBASE-2613  Remove the code around MSG_CALL_SERVER_STARTUP\n   HBASE-2599  BaseScanner says \"Current assignment of X is not valid\" over\n               and over for same region\n   HBASE-2630  HFile should use toStringBinary in various places\n   HBASE-2632  Shell should autodetect terminal width\n   HBASE-2636  Upgrade Jetty to 6.1.24\n   HBASE-2437  Refactor HLog splitLog (Cosmin Lehene via Stack)\n   HBASE-2638  Speed up REST tests\n   HBASE-2653  Remove unused DynamicBloomFilter (especially as its tests are\n               failing hudson on occasion)\n   HBASE-2651  Allow alternate column separators to be specified for ImportTsv\n   HBASE-2661  Add test case for row atomicity guarantee\n   HBASE-2578  Add ability for tests to override server-side timestamp\n   \t           setting (currentTimeMillis) (Daniel Ploeg via Ryan Rawson)\n   HBASE-2558  Our javadoc overview -- \"Getting Started\", requirements, etc. --\n               is not carried across by mvn javadoc:javadoc target\n   HBASE-2618  Don't inherit from HConstants (Benoit Sigoure via Stack)\n   HBASE-2208  TableServers # processBatchOfRows - converts from List to [ ]\n               - Expensive copy\n   HBASE-2694  Move RS to Master region open/close messaging into ZooKeeper\n   HBASE-2716  Make HBase's maven artifacts configurable with -D\n               (Alex Newman via Stack)\n   HBASE-2718  Update .gitignore for trunk after removal of contribs\n               (Lars Francke via Stack)\n   HBASE-2468  Improvements to prewarm META cache on clients\n               (Mingjie Lai via Stack)\n   HBASE-2353  Batch puts should sync HLog as few times as possible\n   HBASE-2726  Region Server should never abort without an informative log\n               message\n   HBASE-2724  Update to new release of Guava library\n   HBASE-2735  Make HBASE-2694 replication-friendly\n   HBASE-2683  Make it obvious in the documentation that ZooKeeper needs\n               permanent storage\n   HBASE-2764  Force all Chore tasks to have a thread name\n   HBASE-2762  Add warning to master if running without append enabled\n   HBASE-2779  Build a -src tgz to sit beside our -bin tgz when you call\n               maven assembly:assembly\n   HBASE-2783  Quick edit of 'Getting Started' for development release 0.89.x\n   HBASE-2345  Add Test in 0.20 to Check for proper HDFS-200 append/sync support\n               (Nicolas Spiegelberg via JD)\n   HBASE-2786  TestHLog.testSplit hangs (Nicolas Spiegelberg via JD)\n   HBASE-2790  Purge apache-forrest from TRUNK\n   HBASE-2793  Add ability to extract a specified list of versions of a column\n               in a single roundtrip (Kannan via Ryan)\n   HBASE-2828  HTable unnecessarily coupled with HMaster\n               (Nicolas Spiegelberg via Stack)\n   HBASE-2265  HFile and Memstore should maintain minimum and maximum timestamps\n               (Pranav via Ryan)\n   HBASE-2836  Speed mvn site building by removing generation of useless reports\n   HBASE-2808  Document the implementation of replication\n   HBASE-2517  During reads when passed the specified time range, seek to\n               next column (Pranav via jgray)\n   HBASE-2835  Update hadoop jar to head of branch-0.20-append to catch three\n               added patches\n   HBASE-2840  Remove the final remnants of the old Get code - the query matchers\n               and other helper classes\n   HBASE-2845  Small edit of shell main help page cutting down some on white\n               space and text\n   HBASE-2850  slf4j version needs to be reconciled in pom: thrift wants 1.5.x\n               and hadoop/avro 1.4.x\n   HBASE-2865  Cleanup of LRU logging; its hard to read, uses custom MB'maker,\n               repeats info, too many numbers after the point, etc.\n   HBASE-2869  Regularize how we log sequenceids -- sometimes its myseqid,\n               other times its sequence id, etc.\n   HBASE-2873  Minor clean up in basescanner; fix a log and make deletes of\n               region processing run in order\n   HBASE-2830  NotServingRegionException shouldn't log a stack trace\n   HBASE-2874  Unnecessary double-synchronization in ZooKeeperWrapper\n               (Benot Sigoure via Stack)\n   HBASE-2879  Offer ZK CLI outside of HBase Shell\n               (Nicolas Spiegelberg via Stack)\n   HBASE-2886  Add search box to site (Alex Baranau via Stack)\n   HBASE-2792  Create a better way to chain log cleaners\n               (Chongxin Li via Stack)\n   HBASE-2844  Capping the number of regions (Pranav Khaitan via Stack)\n   HBASE-2870  Add Backup CLI Option to HMaster (Nicolas Spiegelberg via Stack)\n   HBASE-2868  Do some small cleanups in org.apache.hadoop.hbase.regionserver.wal\n               (Alex Newman via Stack)\n   HBASE-1660  HBASE-1660 script to handle rolling restarts\n               (Nicolas Spiegelberg via Stack)\n   HBASE-1517  Implement inexpensive seek operations in HFile (Pranav via Ryan)\n   HBASE-2903  ColumnPrefix filtering (Pranav via Ryan)\n   HBASE-2904  Smart seeking using filters (Pranav via Ryan)\n   HBASE-2922  HLog preparation and cleanup are done under the updateLock,\n               major slowdown\n   HBASE-1845  MultiGet, MultiDelete, and MultiPut - batched to the\n               appropriate region servers (Marc Limotte via Ryan)\n   HBASE-2867  Have master show its address using hostname rather than IP\n   HBASE-2696  ZooKeeper cleanup and refactor\n   HBASE-2695  HMaster cleanup and refactor\n   HBASE-2692  Open daughters immediately on parent's regionserver\n   HBASE-2405  Close, split, open of regions in RegionServer are run by a single\n               thread only.\n   HBASE-1676  load balancing on a large cluster doesn't work very well\n   HBASE-2953  Edit of hbase-default.xml removing stale configs.\n   HBASE-2857  HBaseAdmin.tableExists() should not require a full meta scan\n   HBASE-2962  Add missing methods to HTableInterface (and HTable)\n               (Lars Francke via Stack)\n   HBASE-2942  Custom filters should not require registration in\n               HBaseObjectWritable (Gary Helmling via Andrew Purtell)\n   HBASE-2976  Running HFile tool passing fully-qualified filename I get\n               'IllegalArgumentException: Wrong FS'\n   HBASE-2977  Refactor master command line to a new class\n   HBASE-2980  Refactor region server command line to a new class\n   HBASE-2988  Support alternate compression for major compactions\n   HBASE-2941  port HADOOP-6713 - threading scalability for RPC reads - to HBase\n   HBASE-2782  QOS for META table access\n   HBASE-3017  More log pruning\n   HBASE-3022  Change format of enum messages in o.a.h.h.executor package\n   HBASE-3001  Ship dependency jars to the cluster for all jobs\n   HBASE-3033  [replication] ReplicationSink.replicateEntries improvements\n   HBASE-3040  BlockIndex readIndex too slowly in heavy write scenario\n               (Andy Chen via Stack)\n   HBASE-3030  The return code of many filesystem operations are not checked\n               (dhruba borthakur via Stack)\n   HBASE-2646  Compaction requests should be prioritized to prevent blocking\n               (Jeff Whiting via Stack)\n   HBASE-3019  Make bulk assignment on cluster startup run faster\n   HBASE-3066  We don't put the port for hregionserver up into znode since\n               new master\n   HBASE-2825  Scans respect row locks\n   HBASE-3070  Add to hbaseadmin means of shutting down a regionserver\n   HBASE-2996  Fix and clean up Maven (Lars Francke via Stack)\n   HBASE-2917  Reseek directly to next row (Pranav Khaitan)\n   HBASE-2907  [rest/stargate] Improve error response when trying to create a\n               scanner on a nonexistant table\n   HBASE-3092  Replace deprecated \"new HBaseConfiguration(...)\" calls\n               (Lars Francke)\n   HBASE-2968  No standard family filter provided (Andrey Stepachev)\n   HBASE-3088  TestAvroServer and TestThriftServer broken because use same\n               table in all tests and tests enable/disable/delete\n   HBASE-3097  Merge in hbase-1200 doc on bloomfilters into hbase book\n   HBASE-2700  Test of: Handle master failover for regions in transition\n   HBASE-3115  HBaseClient wastes 1 TCP packet per RPC\n   HBASE-3076  Allow to disable automatic shipping of dependency jars\n               for mapreduce jobs (Bruno Dumon)\n   HBASE-3128  On assign, if ConnectException, reassign another server\n   HBASE-3133  Only log compaction requests when a request is actually added\n               to the queue\n   HBASE-3132  Print TimestampRange and BloomFilters in HFile pretty print\n   HBASE-2514  RegionServer should refuse to be assigned a region that use\n   \t       LZO when LZO isn't available\n   HBASE-3082  For ICV gets, first look in MemStore before reading StoreFiles\n               (prakash via jgray)\n   HBASE-3167  HBase Export: Add ability to export specific Column Family;\n               Turn Block Cache off during export; improve usage doc\n               (Kannan Muthukkaruppan via Stack)\n   HBASE-3102  Enhance HBase rMetrics for Long-running Stats\n               (Nicolas Spiegelberg via Stack)\n   HBASE-3169  NPE when master joins running cluster if a RIT references\n               a RS no longer present\n   HBASE-3174  Add ability for Get operations to enable/disable use of block\n               caching\n   HBASE-3162  Add TimeRange support into Increment to optimize for counters\n               that are partitioned on time\n   HBASE-2253  Show Block cache hit ratio for requests where\n               cacheBlocks=true\n   HBASE-3126  Force use of 'mv -f' when moving aside hbase logfiles\n   HBASE-3176  Remove compile warnings in HRegionServer\n   HBASE-3154  HBase RPC should support timeout (Hairong via jgray)\n   HBASE-3184  Xmx setting in pom to use for tests/surefire does not appear\n               to work\n   HBASE-3120  [rest] Content transcoding\n   HBASE-3181  Review, document, and fix up Regions-in-Transition timeout\n               logic\n   HBASE-3180  Review periodic master logging, especially ServerManager once\n               a minute\n   HBASE-3189  Stagger Major Compactions (Nicolas Spiegelberg via Stack)\n   HBASE-2564  [rest] Tests use deprecated foundation\n   HBASE-2819  hbck should have the ability to repair basic problems\n   HBASE-3200  Make is so can disable DEBUG logging on HConnectionImplemenation\n               without losing important messages\n   HBASE-3201  Add accounting of empty regioninfo_qualifier rows in meta to\n               hbasefsck.\n   HBASE-3048  unify code for major/minor compactions (Amit via jgray)\n   HBASE-3083  Major compaction check should use new timestamp meta\n               information in HFiles (rather than dfs timestamp) along with\n               TTL to allow major even if single file\n   HBASE-3194  HBase should run on both secure and vanilla versions of Hadoop 0.20\n               (Gary Helmling via Stack)\n   HBASE-3209  HBASE-3209 : New Compaction Algorithm\n               (Nicolas Spiegelberg via Stack)\n   HBASE-3168  Sanity date and time check when a region server joins the\n               cluster (Jeff Whiting and jgray)\n   HBASE-3090  Don't include hbase-default in conf/ assembly\n   HBASE-3161  Provide option for Stargate to only serve GET requests\n               (Bennett Neale via Stack)\n   HBASE-3218  Shell help cleanup/cosmetics/edit\n   HBASE-3079  Shell displaying uninformative exceptions\n   HBASE-3227  Edit of log messages before branching.\n   HBASE-3230  Refresh our hadoop jar and update zookeeper to\n               just-released 3.3.2\n   HBASE-3231  Update to zookeeper 3.3.2.\n   HBASE-3273  Set the ZK default timeout to 3 minutes\n   HBASE-3279  [rest] Filter for gzip content encoding that wraps both input\n               and output side.\n   HBASE-3223  Get VersionInfo for Running HBase Process\n               (Nicolas Spiegelberg via Stack)\n   HBASE-3303  Lower hbase.regionserver.handler.count from 25 back to 10\n   HBASE-2467  Concurrent flushers in HLog sync using HDFS-895\n   HBASE-3349  Pass HBase configuration to HttpServer\n   HBASE-3372  HRS shouldn't print a full stack for ServerNotRunningException\n   HBASE-3392  Update backport of InputSampler to reflect MAPREDUCE-1820\n   HBASE-3405  Allow HBaseRpcMetrics to register custom interface methods\n\n\n  NEW FEATURES\n   HBASE-1961  HBase EC2 scripts\n   HBASE-1982  [EC2] Handle potentially large and uneven instance startup times\n   HBASE-2009  [EC2] Support mapreduce\n   HBASE-2012  [EC2] LZO support\n   HBASE-2019  [EC2] remember credentials if not configured\n   HBASE-2080  [EC2] Support multivolume local instance storage\n   HBASE-2083  [EC2] HDFS DataNode no longer required on master\n   HBASE-2084  [EC2] JAVA_HOME handling broken\n   HBASE-2100  [EC2] Adjust fs.file-max\n   HBASE-2103  [EC2] pull version from build\n   HBASE-2131  [EC2] Mount data volumes as xfs, noatime\n   HBASE-1901  \"General\" partitioner for \"hbase-48\" bulk (behind the api, write\n               hfiles direct) uploader\n   HBASE-1433  Update hbase build to match core, use ivy, publish jars to maven\n               repo, etc. (Kay Kay via Stack)\n   HBASE-2129  Simple Master/Slave replication\n   HBASE-2070  Collect HLogs and delete them after a period of time\n   HBASE-2221  MR to copy a table\n   HBASE-2257  [stargate] multiuser mode\n   HBASE-2263  [stargate] multiuser mode: authenticator for zookeeper\n   HBASE-2273  [stargate] export metrics via Hadoop metrics, JMX, and zookeeper\n   HBASE-2274  [stargate] filter support: JSON descriptors\n   HBASE-2316  Need an ability to run shell tests w/o invoking junit\n               (Alexey Kovyrin via Stack)\n   HBASE-2327  [EC2] Allocate elastic IP addresses for ZK and master nodes\n   HBASE-2319  [stargate] multiuser mode: request shaping\n   HBASE-2403  [stargate] client HTable interface to REST connector\n   HBASE-2438  Addition of a Column Pagination Filter (Paul Kist via Stack)\n   HBASE-2473  Add to admin create table start and end key params and\n               desired number of regions\n   HBASE-2529  Make OldLogsCleaner easier to extend\n   HBASE-2527  Add the ability to easily extend some HLog actions\n   HBASE-2559  Set hbase.hregion.majorcompaction to 0 to disable\n   HBASE-1200  Add bloomfilters (Nicolas Spiegelberg via Stack)\n   HBASE-2588  Add easier way to ship HBase dependencies to MR cluster within Job\n   HBASE-1923  Bulk incremental load into an existing table\n   HBASE-2579  Add atomic checkAndDelete support (Michael Dalton via Stack)\n   HBASE-2400  new connector for Avro RPC access to HBase cluster\n               (Jeff Hammerbacher via Ryan Rawson)\n   HBASE-7     Provide a HBase checker and repair tool similar to fsck\n               (dhruba borthakur via Stack)\n   HBASE-2223  Handle 10min+ network partitions between clusters\n   HBASE-2862  Name DFSClient for Improved Debugging\n               (Nicolas Spiegelberg via Stack)\n   HBASE-2838  Replication metrics\n   HBASE-3000  Add \"hbase classpath\" command to dump classpath\n   HBASE-3043  'hbase-daemon.sh stop regionserver' should kill compactions\n               that are in progress\n               (Nicolas Spiegelberg via Stack)\n   HBASE-3073  New APIs for Result, faster implementation for some calls\n   HBASE-3053  Add ability to have multiple Masters LocalHBaseCluster for\n               test writing\n   HBASE-2201  JRuby shell for replication\n   HBASE-2946  Increment multiple columns in a row at once\n   HBASE-3013  Tool to verify data in two clusters\n   HBASE-2896  Retain assignment information between cluster\n               shutdown/startup\n   HBASE-3211  Key (Index) Only Fetches\n\n\n  OPTIMIZATIONS\n   HBASE-410   [testing] Speed up the test suite\n   HBASE-2041  Change WAL default configuration values\n   HBASE-2997  Performance fixes - profiler driven\n   HBASE-2450  For single row reads of specific columns, seek to the\n   \t       first column in HFiles rather than start of row\n\t       (Pranav via Ryan, some Ryan)\n\n\nRelease 0.20.0 - Tue Sep  8 12:53:05 PDT 2009\n  INCOMPATIBLE CHANGES\n   HBASE-1147  Modify the scripts to use Zookeeper\n   HBASE-1144  Store the ROOT region location in Zookeeper\n               (Nitay Joffe via Stack)\n   HBASE-1146  Replace the HRS leases with Zookeeper\n   HBASE-61    Create an HBase-specific MapFile implementation\n               (Ryan Rawson via Stack)\n   HBASE-1145  Ensure that there is only 1 Master with Zookeeper (Removes\n               hbase.master) (Nitay Joffe via Stack)\n   HBASE-1289  Remove \"hbase.fully.distributed\" option and update docs\n               (Nitay Joffe via Stack)\n   HBASE-1234  Change HBase StoreKey format\n   HBASE-1348  Move 0.20.0 targeted TRUNK to 0.20.0 hadoop\n               (Ryan Rawson and Stack)\n   HBASE-1342  Add to filesystem info needed to rebuild .META.\n   HBASE-1361  Disable bloom filters\n   HBASE-1367  Get rid of Thrift exception 'NotFound'\n   HBASE-1381  Remove onelab and bloom filters files from hbase\n   HBASE-1411  Remove HLogEdit.\n   HBASE-1357  If one sets the hbase.master to 0.0.0.0 non local regionservers\n               can't find the master\n   HBASE-1304  New client server implementation of how gets and puts are\n               handled (holstad, jgray, rawson, stack)\n   HBASE-1582  Translate ColumnValueFilter and RowFilterSet to the new\n               Filter interface (Clint Morgan and Stack)\n   HBASE-1599  Fix TestFilterSet, broken up on hudson (Jon Gray via Stack)\n   HBASE-1799  deprecate o.a.h.h.rest in favor of stargate\n\n  BUG FIXES\n   HBASE-1140  \"ant clean test\" fails (Nitay Joffe via Stack)\n   HBASE-1129  Master won't go down; stuck joined on rootScanner\n   HBASE-1136  HashFunction inadvertently destroys some randomness\n               (Jonathan Ellis via Stack)\n   HBASE-1138  Test that readers opened after a sync can see all data up to the\n               sync (temporary until HADOOP-4379 is resolved)\n   HBASE-1121  Cluster confused about where -ROOT- is\n   HBASE-1148  Always flush HLog on root or meta region updates\n   HBASE-1181  src/saveVersion.sh bails on non-standard Bourne shells\n               (e.g. dash) (K M via Jean-Daniel Cryans)\n   HBASE-1175  HBA administrative tools do not work when specifying region\n               name (Jonathan Gray via Andrew Purtell)\n   HBASE-1190  TableInputFormatBase with row filters scan too far (Dave\n               Latham via Andrew Purtell)\n   HBASE-1198  OOME in IPC server does not trigger abort behavior\n   HBASE-1209  Make port displayed the same as is used in URL for RegionServer\n               table in UI (Lars George via Stack)\n   HBASE-1217  add new compression and hfile blocksize to HColumnDescriptor\n   HBASE-859   HStoreKey needs a reworking\n   HBASE-1211  NPE in retries exhausted exception\n   HBASE-1233  Transactional fixes: Overly conservative scan read-set,\n               potential CME (Clint Morgan via Stack)\n   HBASE-1239  in the REST interface does not correctly clear the character\n               buffer each iteration-1185  wrong request/sec in the gui\n               reporting wrong (Brian Beggs via Stack)\n   HBASE-1245  hfile meta block handling bugs (Ryan Rawson via Stack)\n   HBASE-1238  Under upload, region servers are unable\n               to compact when loaded with hundreds of regions\n   HBASE-1247  checkAndSave doesn't Write Ahead Log\n   HBASE-1243  oldlogfile.dat is screwed, so is it's region\n   HBASE-1169  When a shutdown is requested, stop scanning META regions\n               immediately\n   HBASE-1251  HConnectionManager.getConnection(HBaseConfiguration) returns\n               same HConnection for different HBaseConfigurations\n   HBASE-1157, HBASE-1156 If we do not take start code as a part of region\n               server recovery, we could inadvertantly try to reassign regions\n               assigned to a restarted server with a different start code;\n               Improve lease handling\n   HBASE-1267  binary keys broken in trunk (again) -- part 2 and 3\n               (Ryan Rawson via Stack)\n   HBASE-1268  ZooKeeper config parsing can break HBase startup\n               (Nitay Joffe via Stack)\n   HBASE-1270  Fix TestInfoServers (Nitay Joffe via Stack)\n   HBASE-1277  HStoreKey: Wrong comparator logic (Evgeny Ryabitskiy)\n   HBASE-1275  TestTable.testCreateTable broken (Ryan Rawson via Stack)\n   HBASE-1274  TestMergeTable is broken in Hudson (Nitay Joffe via Stack)\n   HBASE-1283  thrift's package descrpition needs to update for start/stop\n               procedure (Rong-en Fan via Stack)\n   HBASE-1284  drop table drops all disabled tables\n   HBASE-1290  table.jsp either 500s out or doesnt list the regions (Ryan\n               Rawson via Andrew Purtell)\n   HBASE-1293  hfile doesn't recycle decompressors (Ryan Rawson via Andrew\n               Purtell)\n   HBASE-1150  HMsg carries safemode flag; remove (Nitay Joffe via Stack)\n   HBASE-1232  zookeeper client wont reconnect if there is a problem (Nitay\n               Joffe via Andrew Purtell)\n   HBASE-1303  Secondary index configuration prevents HBase from starting\n               (Ken Weiner via Stack)\n   HBASE-1298  master.jsp & table.jsp do not URI Encode table or region\n               names in links (Lars George via Stack)\n   HBASE-1310  Off by one error in Bytes.vintToBytes\n   HBASE-1202  getRow does not always work when specifying number of versions\n   HBASE-1324  hbase-1234 broke testget2 unit test (and broke the build)\n   HBASE-1321  hbase-1234 broke TestCompaction; fix and reenable\n   HBASE-1330  binary keys broken on trunk (Ryan Rawson via Stack)\n   HBASE-1332  regionserver carrying .META. starts sucking all cpu, drives load\n               up - infinite loop? (Ryan Rawson via Stack)\n   HBASE-1334  .META. region running into hfile errors (Ryan Rawson via Stack)\n   HBASE-1338  lost use of compaction.dir; we were compacting into live store\n               subdirectory\n   HBASE-1058  Prevent runaway compactions\n   HBASE-1292  php thrift's getRow() would throw an exception if the row does\n               not exist (Rong-en Fan via Stack)\n   HBASE-1340  Fix new javadoc warnings (Evgeny Ryabitskiy via Stack)\n   HBASE-1287  Partitioner class not used in TableMapReduceUtil\n               .initTableReduceJob() (Lars George and Billy Pearson via Stack)\n   HBASE-1320  hbase-1234 broke filter tests\n   HBASE-1355  [performance] Cache family maxversions; we were calculating on\n               each access\n   HBASE-1358  Bug in reading from Memcache method (read only from snapshot)\n               (Evgeny Ryabitskiy via Stack)\n   HBASE-1322  hbase-1234 broke TestAtomicIncrement; fix and reenable\n               (Evgeny Ryabitskiy and Ryan Rawson via Stack)\n   HBASE-1347  HTable.incrementColumnValue does not take negative 'amount'\n               (Evgeny Ryabitskiy via Stack)\n   HBASE-1365  Typo in TableInputFormatBase.setInputColums (Jon Gray via Stack)\n   HBASE-1279  Fix the way hostnames and IPs are handled\n   HBASE-1368  HBASE-1279 broke the build\n   HBASE-1264  Wrong return values of comparators for ColumnValueFilter\n               (Thomas Schneider via Andrew Purtell)\n   HBASE-1374  NPE out of ZooKeeperWrapper.loadZooKeeperConfig\n   HBASE-1336  Splitting up the compare of family+column into 2 different\n               compare\n   HBASE-1377  RS address is null in master web UI\n   HBASE-1344  WARN IllegalStateException: Cannot set a region as open if it\n               has not been pending\n   HBASE-1386  NPE in housekeeping\n   HBASE-1396  Remove unused sequencefile and mapfile config. from\n               hbase-default.xml\n   HBASE-1398  TableOperation doesnt format keys for meta scan properly\n               (Ryan Rawson via Stack)\n   HBASE-1399  Can't drop tables since HBASE-1398 (Ryan Rawson via Andrew\n               Purtell)\n   HBASE-1311  ZooKeeperWrapper: Failed to set watcher on ZNode /hbase/master\n               (Nitay Joffe via Stack)\n   HBASE-1391  NPE in TableInputFormatBase$TableRecordReader.restart if zoo.cfg\n               is wrong or missing on task trackers\n   HBASE-1323  hbase-1234 broke TestThriftServer; fix and reenable\n   HBASE-1425  ColumnValueFilter and WhileMatchFilter fixes on trunk\n               (Clint Morgan via Stack)\n   HBASE-1431  NPE in HTable.checkAndSave when row doesn't exist (Guilherme\n               Mauro Germoglio Barbosa via Andrew Purtell)\n   HBASE-1421  Processing a regionserver message -- OPEN, CLOSE, SPLIT, etc. --\n               and if we're carrying more than one message in payload, if\n               exception, all messages that follow are dropped on floor\n   HBASE-1434  Duplicate property in hbase-default.xml (Lars George via Andrew\n               Purtell)\n   HBASE-1435  HRegionServer is using wrong info bind address from\n               hbase-site.xml (Lars George via Stack)\n   HBASE-1438  HBASE-1421 broke the build (#602 up on hudson)\n   HBASE-1440  master won't go down because joined on a rootscanner that is\n               waiting for ever\n   HBASE-1441  NPE in ProcessRegionStatusChange#getMetaRegion\n   HBASE-1162  CME in Master in RegionManager.applyActions\n   HBASE-1010  IOE on regionserver shutdown because hadn't opened an HLog\n   HBASE-1415  Stuck on memcache flush\n   HBASE-1257  base64 encoded values are not contained in quotes during the\n               HBase REST JSON serialization (Brian Beggs via Stack)\n   HBASE-1436  Killing regionserver can make corrupted hfile\n   HBASE-1272  Unreadable log messages -- \"... to the only server\n               localhost_1237525439599_56094\" <- You'd have to be perverse\n               to recognize that as a hostname, startcode, and port\n   HBASE-1395  InfoServers no longer put up a UI\n   HBASE-1302  When a new master comes up, regionservers should continue with\n               their region assignments from the last master\n   HBASE-1457  Taking down ROOT/META regionserver can result in cluster\n               becoming in-operational (Ryan Rawson via Stack)\n   HBASE-1471  During cluster shutdown, deleting zookeeper regionserver nodes\n               causes exceptions\n   HBASE-1483  HLog split loses track of edits (Clint Morgan via Stack)\n   HBASE-1484  commit log split writes files with newest edits first\n               (since hbase-1430); should be other way round\n   HBASE-1493  New TableMapReduceUtil methods should be static (Billy Pearson\n               via Andrew Purtell)\n   HBASE-1486  BLOCKCACHE always on even when disabled (Lars George via Stack)\n   HBASE-1491  ZooKeeper errors: \"Client has seen zxid 0xe our last zxid\n               is 0xd\"\n   HBASE-1499  Fix javadoc warnings after HBASE-1304 commit (Lars George via\n               Stack)\n   HBASE-1504  Remove left-over debug from 1304 commit\n   HBASE-1518  Delete Trackers using compareRow, should just use raw\n               binary comparator (Jon Gray via Stack)\n   HBASE-1500  KeyValue$KeyComparator array overrun\n   HBASE-1513  Compactions too slow\n   HBASE-1516  Investigate if StoreScanner will not return the next row if\n               earlied-out of previous row (Jon Gray)\n   HBASE-1520  StoreFileScanner catches and ignore IOExceptions from HFile\n   HBASE-1522  We delete splits before their time occasionally\n   HBASE-1523  NPE in BaseScanner\n   HBASE-1525  HTable.incrementColumnValue hangs()\n   HBASE-1526  mapreduce fixup\n   HBASE-1503  hbase-1304 dropped updating list of store files on flush\n               (jgray via stack)\n   HBASE-1480  compaction file not cleaned up after a crash/OOME server\n               (Evgeny Ryabitskiy via Stack)\n   HBASE-1529  familyMap not invalidated when a Result is (re)read as a\n               Writable\n   HBASE-1528  Ensure scanners work across memcache snapshot\n   HBASE-1447  Take last version of the hbase-1249 design doc. and make\n               documentation out of it\n   HBASE-1206  Scanner spins when there are concurrent inserts to column family\n   HBASE-1536  Controlled crash of regionserver not hosting meta/root leaves\n               master in spinning state, regions not reassigned\n   HBASE-1543  Unnecessary toString during scanning costs us some CPU\n   HBASE-1544  Cleanup HTable (Jonathan Gray via Stack)\n   HBASE-1488  After 1304 goes in, fix and reenable test of thrift, mr indexer,\n               and merge tool\n   HBASE-1531  Change new Get to use new filter API\n   HBASE-1549  in zookeeper.sh, use localhost instead of 127.0.0.1\n   HBASE-1534  Got ZooKeeper event, state: Disconnected on HRS and then NPE on\n               reinit\n   HBASE-1387  Before release verify all object sizes using Ryans' instrumented\n               JVM trick (Erik Holstad via Stack)\n   HBASE-1545  atomicIncrements creating new values with Long.MAX_VALUE\n   HBASE-1547  atomicIncrement doesnt increase hregion.memcacheSize\n   HBASE-1553  ClassSize missing in trunk\n   HBASE-1561  HTable Mismatch between javadoc and what it actually does\n   HBASE-1558  deletes use 'HConstants.LATEST_TIMESTAMP' but no one translates\n               that into 'now'\n   HBASE-1508  Shell \"close_region\" reveals a Master<>HRS problem, regions are\n               not reassigned\n   HBASE-1568  Client doesnt consult old row filter interface in\n               filterSaysStop() - could result in NPE or excessive scanning\n   HBASE-1564  in UI make host addresses all look the same -- not IP sometimes\n               and host at others\n   HBASE-1567  cant serialize new filters\n   HBASE-1585  More binary key/value log output cleanup\n               (Lars George via Stack)\n   HBASE-1563  incrementColumnValue does not write to WAL (Jon Gray via Stack)\n   HBASE-1569  rare race condition can take down a regionserver\n   HBASE-1450  Scripts passed to hbase shell do not have shell context set up\n               for them\n   HBASE-1566  using Scan(startRow,stopRow) will cause you to iterate the\n               entire table\n   HBASE-1560  TIF can't seem to find one region\n   HBASE-1580  Store scanner does not consult filter.filterRow at end of scan\n               (Clint Morgan via Stack)\n   HBASE-1437  broken links in hbase.org\n   HBASE-1582  Translate ColumnValueFilter and RowFilterSet to the new Filter\n               interface\n   HBASE-1594  Fix scan addcolumns after hbase-1385 commit (broke hudson build)\n   HBASE-1595  hadoop-default.xml and zoo.cfg in hbase jar\n   HBASE-1602  HRegionServer won't go down since we added in new LruBlockCache\n   HBASE-1608  TestCachedBlockQueue failing on some jvms (Jon Gray via Stack)\n   HBASE-1615  HBASE-1597 introduced a bug when compacting after a split\n               (Jon Gray via Stack)\n   HBASE-1616  Unit test of compacting referenced StoreFiles (Jon Gray via\n               Stack)\n   HBASE-1618  Investigate further into the MemStoreFlusher StoreFile limit\n               (Jon Gray via Stack)\n   HBASE-1625  Adding check to Put.add(KeyValue), to see that it has the same\n               row as when instantiated (Erik Holstad via Stack)\n   HBASE-1629  HRS unable to contact master\n   HBASE-1633  Can't delete in TRUNK shell; makes it hard doing admin repairs\n   HBASE-1641  Stargate build.xml causes error in Eclipse\n   HBASE-1627  TableInputFormatBase#nextKeyValue catches the wrong exception\n               (Doacan Gney via Stack)\n   HBASE-1644  Result.row is cached in getRow; this breaks MapReduce\n               (Doacan Gney via Stack)\n   HBASE-1639  clean checkout with empty hbase-site.xml, zk won't start\n   HBASE-1646  Scan-s can't set a Filter (Doacan Gney via Stack)\n   HBASE-1649  ValueFilter may not reset its internal state\n               (Doacan Gney via Stack)\n   HBASE-1651  client is broken, it requests ROOT region location from ZK too\n               much\n   HBASE-1650  HBASE-1551 broke the ability to manage non-regionserver\n               start-up/shut down. ie: you cant start/stop thrift on a cluster\n               anymore\n   HBASE-1658  Remove UI refresh -- its annoying\n   HBASE-1659  merge tool doesnt take binary regions with \\x escape format\n   HBASE-1663  Request compaction only once instead of every time 500ms each\n               time we cycle the hstore.getStorefilesCount() >\n               this.blockingStoreFilesNumber loop\n   HBASE-1058  Disable 1058 on catalog tables\n   HBASE-1583  Start/Stop of large cluster untenable\n   HBASE-1668  hbase-1609 broke TestHRegion.testScanSplitOnRegion unit test\n   HBASE-1669  need dynamic extensibility of HBaseRPC code maps and interface\n               lists (Clint Morgan via Stack)\n   HBASE-1359  After a large truncating table HBase becomes unresponsive\n   HBASE-1215  0.19.0 -> 0.20.0 migration (hfile, HCD changes, HSK changes)\n   HBASE-1689  Fix javadoc warnings and add overview on client classes to\n               client package\n   HBASE-1680  FilterList writable only works for HBaseObjectWritable\n               defined types (Clint Morgan via Stack and Jon Gray)\n   HBASE-1607  transactions / indexing fixes: trx deletes not handeled, index\n               scan can't specify stopRow (Clint Morgan via Stack)\n   HBASE-1693  NPE close_region \".META.\" in shell\n   HBASE-1706  META row with missing HRI breaks UI\n   HBASE-1709  Thrift getRowWithColumns doesn't accept column-family only\n               (Mathias Lehmann via Stack)\n   HBASE-1692  Web UI is extremely slow / freezes up if you have many tables\n   HBASE-1686  major compaction can create empty store files, causing AIOOB\n               when trying to read\n   HBASE-1705  Thrift server: deletes in mutateRow/s don't delete\n               (Tim Sell and Ryan Rawson via Stack)\n   HBASE-1703  ICVs across /during a flush can cause multiple keys with the\n               same TS (bad)\n   HBASE-1671  HBASE-1609 broke scanners riding across splits\n   HBASE-1717  Put on client-side uses passed-in byte[]s rather than always\n               using copies\n   HBASE-1647  Filter#filterRow is called too often, filters rows it shouldn't\n               have (Doacan Gney via Ryan Rawson and Stack)\n   HBASE-1718  Reuse of KeyValue during log replay could cause the wrong\n               data to be used\n   HBASE-1573  Holes in master state change; updated startcode and server\n               go into .META. but catalog scanner just got old values (redux)\n   HBASE-1534  Got ZooKeeper event, state: Disconnected on HRS and then NPE\n               on reinit\n   HBASE-1725  Old TableMap interface's definitions are not generic enough\n               (Doacan Gney via Stack)\n   HBASE-1732  Flag to disable regionserver restart\n   HBASE-1727  HTD and HCD versions need update\n   HBASE-1604  HBaseClient.getConnection() may return a broken connection\n               without throwing an exception (Eugene Kirpichov via Stack)\n   HBASE-1737  Regions unbalanced when adding new node\n   HBASE-1739  hbase-1683 broke splitting; only split three logs no matter\n               what N was\n   HBASE-1745  [tools] Tool to kick region out of inTransistion\n   HBASE-1757  REST server runs out of fds\n   HBASE-1768  REST server has upper limit of 5k PUT\n   HBASE-1766  Add advanced features to HFile.main() to be able to analyze\n               storefile problems\n   HBASE-1761  getclosest doesn't understand delete family; manifests as\n               \"HRegionInfo was null or empty in .META\" A.K.A the BS problem\n   HBASE-1738  Scanner doesnt reset when a snapshot is created, could miss\n               new updates into the 'kvset' (active part)\n   HBASE-1767  test zookeeper broken in trunk and 0.20 branch; broken on\n               hudson too\n   HBASE-1780  HTable.flushCommits clears write buffer in finally clause\n   HBASE-1784  Missing rows after medium intensity insert\n   HBASE-1809  NPE thrown in BoundedRangeFileInputStream\n   HBASE-1810  ConcurrentModificationException in region assignment\n               (Mathias Herberts via Stack)\n   HBASE-1804  Puts are permitted (and stored) when including an appended colon\n   HBASE-1715  Compaction failure in ScanWildcardColumnTracker.checkColumn\n   HBASE-2352  Small values for hbase.client.retries.number and\n               ipc.client.connect.max.retries breaks long ops in hbase shell\n               (Alexey Kovyrin via Stack)\n   HBASE-2531  32-bit encoding of regionnames waaaaaaayyyyy too susceptible to\n               hash clashes (Kannan Muthukkaruppan via Stack)\n\n  IMPROVEMENTS\n   HBASE-1089  Add count of regions on filesystem to master UI; add percentage\n               online as difference between whats open and whats on filesystem\n               (Samuel Guo via Stack)\n   HBASE-1130  PrefixRowFilter (Michael Gottesman via Stack)\n   HBASE-1139  Update Clover in build.xml\n   HBASE-876   There are a large number of Java warnings in HBase; part 1,\n               part 2, part 3, part 4, part 5, part 6, part 7 and part 8\n               (Evgeny Ryabitskiy via Stack)\n   HBASE-896   Update jruby from 1.1.2 to 1.1.6\n   HBASE-1031  Add the Zookeeper jar\n   HBASE-1142  Cleanup thrift server; remove Text and profuse DEBUG messaging\n               (Tim Sell via Stack)\n   HBASE-1064  HBase REST xml/json improvements (Brian Beggs working of\n               initial Michael Gottesman work via Stack)\n   HBASE-5121  Fix shell usage for format.width\n   HBASE-845   HCM.isTableEnabled doesn't really tell if it is, or not\n   HBASE-903   [shell] Can't set table descriptor attributes when I alter a\n               table\n   HBASE-1166  saveVersion.sh doesn't work with git (Nitay Joffe via Stack)\n   HBASE-1167  JSP doesn't work in a git checkout (Nitay Joffe via Andrew\n               Purtell)\n   HBASE-1178  Add shutdown command to shell\n   HBASE-1184  HColumnDescriptor is too restrictive with family names\n               (Toby White via Andrew Purtell)\n   HBASE-1180  Add missing import statements to SampleUploader and remove\n               unnecessary @Overrides (Ryan Smith via Andrew Purtell)\n   HBASE-1191  ZooKeeper ensureParentExists calls fail\n               on absolute path (Nitay Joffe via Jean-Daniel Cryans)\n   HBASE-1187  After disabling/enabling a table, the regions seems to\n               be assigned to only 1-2 region servers\n   HBASE-1210  Allow truncation of output for scan and get commands in shell\n               (Lars George via Stack)\n   HBASE-1221  When using ant -projecthelp to build HBase not all the important\n               options show up (Erik Holstad via Stack)\n   HBASE-1189  Changing the map type used internally for HbaseMapWritable\n               (Erik Holstad via Stack)\n   HBASE-1188  Memory size of Java Objects - Make cacheable objects implement\n               HeapSize (Erik Holstad via Stack)\n   HBASE-1230  Document installation of HBase on Windows\n   HBASE-1241  HBase additions to ZooKeeper part 1 (Nitay Joffe via JD)\n   HBASE-1231  Today, going from a RowResult to a BatchUpdate reqiures some\n               data processing even though they are pretty much the same thing\n               (Erik Holstad via Stack)\n   HBASE-1240  Would be nice if RowResult could be comparable\n               (Erik Holstad via Stack)\n   HBASE-803   Atomic increment operations (Ryan Rawson and Jon Gray via Stack)\n               Part 1 and part 2 -- fix for a crash.\n   HBASE-1252  Make atomic increment perform a binary increment\n               (Jonathan Gray via Stack)\n   HBASE-1258,1259 ganglia metrics for 'requests' is confusing\n               (Ryan Rawson via Stack)\n   HBASE-1265  HLogEdit static constants should be final (Nitay Joffe via\n               Stack)\n   HBASE-1244  ZooKeeperWrapper constants cleanup (Nitay Joffe via Stack)\n   HBASE-1262  Eclipse warnings, including performance related things like\n               synthetic accessors (Nitay Joffe via Stack)\n   HBASE-1273  ZooKeeper WARN spits out lots of useless messages\n               (Nitay Joffe via Stack)\n   HBASE-1285  Forcing compactions should be available via thrift\n               (Tim Sell via Stack)\n   HBASE-1186  Memory-aware Maps with LRU eviction for cell cache\n               (Jonathan Gray via Andrew Purtell)\n   HBASE-1205  RegionServers should find new master when a new master comes up\n               (Nitay Joffe via Andrew Purtell)\n   HBASE-1309  HFile rejects key in Memcache with empty value\n   HBASE-1331  Lower the default scanner caching value\n   HBASE-1235  Add table enabled status to shell and UI\n               (Lars George via Stack)\n   HBASE-1333  RowCounter updates\n   HBASE-1195  If HBase directory exists but version file is inexistent, still\n               proceed with bootstrapping (Evgeny Ryabitskiy via Stack)\n   HBASE-1301  HTable.getRow() returns null if the row does no exist\n               (Rong-en Fan via Stack)\n   HBASE-1176  Javadocs in HBA should be clear about which functions are\n               asynchronous and which are synchronous\n               (Evgeny Ryabitskiy via Stack)\n   HBASE-1260  Bytes utility class changes: remove usage of ByteBuffer and\n               provide additional ByteBuffer primitives (Jon Gray via Stack)\n   HBASE-1183  New MR splitting algorithm and other new features need a way to\n               split a key range in N chunks (Jon Gray via Stack)\n   HBASE-1350  New method in HTable.java to return start and end keys for\n               regions in a table (Vimal Mathew via Stack)\n   HBASE-1271  Allow multiple tests to run on one machine\n               (Evgeny Ryabitskiy via Stack)\n   HBASE-1112  we will lose data if the table name happens to be the logs' dir\n               name (Samuel Guo via Stack)\n   HBASE-889   The current Thrift API does not allow a new scanner to be\n               created without supplying a column list unlike the other APIs.\n               (Tim Sell via Stack)\n   HBASE-1341  HTable pooler\n   HBASE-1379  re-enable LZO using hadoop-gpl-compression library\n               (Ryan Rawson via Stack)\n   HBASE-1383  hbase shell needs to warn on deleting multi-region table\n   HBASE-1286  Thrift should support next(nbRow) like functionality\n               (Alex Newman via Stack)\n   HBASE-1392  change how we build/configure lzocodec (Ryan Rawson via Stack)\n   HBASE-1397  Better distribution in the PerformanceEvaluation MapReduce\n               when rows run to the Billions\n   HBASE-1393  Narrow synchronization in HLog\n   HBASE-1404  minor edit of regionserver logging messages\n   HBASE-1405  Threads.shutdown has unnecessary branch\n   HBASE-1407  Changing internal structure of ImmutableBytesWritable\n               contructor (Erik Holstad via Stack)\n   HBASE-1345  Remove distributed mode from MiniZooKeeper (Nitay Joffe via\n               Stack)\n   HBASE-1414  Add server status logging chore to ServerManager\n   HBASE-1379  Make KeyValue implement Writable\n               (Erik Holstad and Jon Gray via Stack)\n   HBASE-1380  Make KeyValue implement HeapSize\n               (Erik Holstad and Jon Gray via Stack)\n   HBASE-1413  Fall back to filesystem block size default if HLog blocksize is\n               not specified\n   HBASE-1417  Cleanup disorientating RPC message\n   HBASE-1424  have shell print regioninfo and location on first load if\n               DEBUG enabled\n   HBASE-1008  [performance] The replay of logs on server crash takes way too\n               long\n   HBASE-1394  Uploads sometimes fall to 0 requests/second (Binding up on\n               HLog#append?)\n   HBASE-1429  Allow passing of a configuration object to HTablePool\n   HBASE-1432  LuceneDocumentWrapper is not public\n   HBASE-1401  close HLog (and open new one) if there hasnt been edits in N\n               minutes/hours\n   HBASE-1420  add abliity to add and remove (table) indexes on existing\n               tables (Clint Morgan via Stack)\n   HBASE-1430  Read the logs in batches during log splitting to avoid OOME\n   HBASE-1017  Region balancing does not bring newly added node within\n               acceptable range (Evgeny Ryabitskiy via Stack)\n   HBASE-1454  HBaseAdmin.getClusterStatus\n   HBASE-1236  Improve readability of table descriptions in the UI\n               (Lars George and Alex Newman via Stack)\n   HBASE-1455  Update DemoClient.py for thrift 1.0 (Tim Sell via Stack)\n   HBASE-1464  Add hbase.regionserver.logroll.period to hbase-default\n   HBASE-1192  LRU-style map for the block cache (Jon Gray and Ryan Rawson\n               via Stack)\n   HBASE-1466  Binary keys are not first class citizens\n               (Ryan Rawson via Stack)\n   HBASE-1445  Add the ability to start a master from any machine\n   HBASE-1474  Add zk attributes to list of attributes\n               in master and regionserver UIs\n   HBASE-1448  Add a node in ZK to tell all masters to shutdown\n   HBASE-1478  Remove hbase master options from shell (Nitay Joffe via Stack)\n   HBASE-1462  hclient still seems to depend on master\n   HBASE-1143  region count erratic in master UI\n   HBASE-1490  Update ZooKeeper library\n   HBASE-1489  Basic git ignores for people who use git and eclipse\n   HBASE-1453  Add HADOOP-4681 to our bundled hadoop, add to 'gettting started'\n               recommendation that hbase users backport\n   HBASE-1507  iCMS as default JVM\n   HBASE-1509  Add explanation to shell \"help\" command on how to use binarykeys\n               (Lars George via Stack)\n   HBASE-1514  hfile inspection tool\n   HBASE-1329  Visibility into ZooKeeper\n   HBASE-867   If millions of columns in a column family, hbase scanner won't\n               come up (Jonathan Gray via Stack)\n   HBASE-1538  Up zookeeper timeout from 10 seconds to 30 seconds to cut down\n               on hbase-user traffic\n   HBASE-1539  prevent aborts due to missing zoo.cfg\n   HBASE-1488  Fix TestThriftServer and re-enable it\n   HBASE-1541  Scanning multiple column families in the presence of deleted\n               families results in bad scans\n   HBASE-1540  Client delete unit test, define behavior\n               (Jonathan Gray via Stack)\n   HBASE-1552  provide version running on cluster via getClusterStatus\n   HBASE-1550  hbase-daemon.sh stop should provide more information when stop\n               command fails\n   HBASE-1515  Address part of config option hbase.regionserver unnecessary\n   HBASE-1532  UI Visibility into ZooKeeper\n   HBASE-1572  Zookeeper log4j property set to ERROR on default, same output\n               when cluster working and not working (Jon Gray via Stack)\n   HBASE-1576  TIF needs to be able to set scanner caching size for smaller\n               row tables & performance\n   HBASE-1577  Move memcache to ConcurrentSkipListMap from\n               ConcurrentSkipListSet\n   HBASE-1578  Change the name of the in-memory updates from 'memcache' to\n               'memtable' or....\n   HBASE-1562  How to handle the setting of 32 bit versus 64 bit machines\n               (Erik Holstad via Stack)\n   HBASE-1584  Put add methods should return this for ease of use (Be\n               consistant with Get) (Clint Morgan via Stack)\n   HBASE-1581  Run major compaction on .META. when table is dropped or\n               truncated\n   HBASE-1587  Update ganglia config and doc to account for ganglia 3.1 and\n               hadoop-4675\n   HBASE-1589  Up zk maxClientCnxns from default of 10 to 20 or 30 or so\n   HBASE-1385  Revamp TableInputFormat, needs updating to match hadoop 0.20.x\n               AND remove bit where we can make < maps than regions\n               (Lars George via Stack)\n   HBASE-1596  Remove WatcherWrapper and have all users of Zookeeper provide a\n               Watcher\n   HBASE-1597  Prevent unnecessary caching of blocks during compactions\n               (Jon Gray via Stack)\n   HBASE-1607  Redo MemStore heap sizing to be accurate, testable, and more\n               like new LruBlockCache (Jon Gray via Stack)\n   HBASE-1218  Implement in-memory column (Jon Gray via Stack)\n   HBASE-1606  Remove zoo.cfg, put config options into hbase-site.xml\n   HBASE-1575  HMaster does not handle ZK session expiration\n   HBASE-1620  Need to use special StoreScanner constructor for major\n               compactions (passed sf, no caching, etc) (Jon Gray via Stack)\n   HBASE-1624  Don't sort Puts if only one in list in HCM#processBatchOfRows\n   HBASE-1626  Allow emitting Deletes out of new TableReducer\n               (Lars George via Stack)\n   HBASE-1551  HBase should manage multiple node ZooKeeper quorum\n   HBASE-1637  Delete client class methods should return itself like Put, Get,\n               Scan (Jon Gray via Nitay)\n   HBASE-1640  Allow passing arguments to jruby script run when run by hbase\n               shell\n   HBASE-698   HLog recovery is not performed after master failure\n   HBASE-1643  ScanDeleteTracker takes comparator but it unused\n   HBASE-1603  MR failed \"RetriesExhaustedException: Trying to contact region\n               server Some server for region TestTable...\" -- deubugging\n   HBASE-1470  hbase and HADOOP-4379, dhruba's flush/sync\n   HBASE-1632  Write documentation for configuring/managing ZooKeeper\n   HBASE-1662  Tool to run major compaction on catalog regions when hbase is\n               shutdown\n   HBASE-1665  expose more load information to the client side\n   HBASE-1609  We wait on leases to expire before regionserver goes down.\n               Rather, just let client fail\n   HBASE-1655  Usability improvements to HTablePool (Ken Weiner via jgray)\n   HBASE-1688  Improve javadocs in Result and KeyValue\n   HBASE-1694  Add TOC to 'Getting Started', add references to THBase and\n               ITHBase\n   HBASE-1699  Remove hbrep example as it's too out of date\n               (Tim Sell via Stack)\n   HBASE-1683  OOME on master splitting logs; stuck, won't go down\n   HBASE-1704  Better zk error when failed connect\n   HBASE-1714  Thrift server: prefix scan API\n   HBASE-1719  hold a reference to the region in stores instead of only the\n               region info\n   HBASE-1743  [debug tool] Add regionsInTransition list to ClusterStatus\n               detailed output\n   HBASE-1772  Up the default ZK session timeout from 30seconds to 60seconds\n   HBASE-2625  Make testDynamicBloom()'s \"randomness\" deterministic\n               (Nicolas Spiegelberg via Stack)\n\n  OPTIMIZATIONS\n   HBASE-1412  Change values for delete column and column family in KeyValue\n   HBASE-1535  Add client ability to perform mutations without the WAL\n               (Jon Gray via Stack)\n   HBASE-1460  Concurrent LRU Block Cache (Jon Gray via Stack)\n   HBASE-1635  PerformanceEvaluation should use scanner prefetching\n\nRelease 0.19.0 - 01/21/2009\n  INCOMPATIBLE CHANGES\n   HBASE-885   TableMap and TableReduce should be interfaces\n               (Doacan Gney via Stack)\n   HBASE-905   Remove V5 migration classes from 0.19.0 (Jean-Daniel Cryans via\n               Jim Kellerman)\n   HBASE-852   Cannot scan all families in a row with a LIMIT, STARTROW, etc.\n               (Izaak Rubin via Stack)\n   HBASE-953   Enable BLOCKCACHE by default [WAS -> Reevaluate HBASE-288 block\n               caching work....?] -- Update your hbase-default.xml file!\n   HBASE-636   java6 as a requirement\n   HBASE-994   IPC interfaces with different versions can cause problems\n   HBASE-1028  If key does not exist, return null in getRow rather than an\n               empty RowResult\n   HBASE-1134  OOME in HMaster when HBaseRPC is older than 0.19\n\n  BUG FIXES\n   HBASE-891   HRS.validateValuesLength throws IOE, gets caught in the retries\n   HBASE-892   Cell iteration is broken (Doacan Gney via Jim Kellerman)\n   HBASE-898   RowResult.containsKey(String) doesn't work\n               (Doacan Gney via Jim Kellerman)\n   HBASE-906   [shell] Truncates output\n   HBASE-912   PE is broken when other tables exist\n   HBASE-853   [shell] Cannot describe meta tables (Izaak Rubin via Stack)\n   HBASE-844   Can't pass script to hbase shell\n   HBASE-837   Add unit tests for ThriftServer.HBaseHandler (Izaak Rubin via\n               Stack)\n   HBASE-913   Classes using log4j directly\n   HBASE-914   MSG_REPORT_CLOSE has a byte array for a message\n   HBASE-918   Region balancing during startup makes cluster unstable\n   HBASE-921   region close and open processed out of order; makes for\n               disagreement between master and regionserver on region state\n   HBASE-925   HRS NPE on way out if no master to connect to\n   HBASE-928   NPE throwing RetriesExhaustedException\n   HBASE-924   Update hadoop in lib on 0.18 hbase branch to 0.18.1\n   HBASE-929   Clarify that ttl in HColumnDescriptor is seconds\n   HBASE-930   RegionServer stuck: HLog: Could not append. Requesting close of\n               log java.io.IOException: Could not get block locations\n   HBASE-926   If no master, regionservers should hang out rather than fail on\n               connection and shut themselves down\n   HBASE-919   Master and Region Server need to provide root region location if\n               they are using HTable\n               With J-D's one line patch, test cases now appear to work and\n               PerformanceEvaluation works as before.\n   HBASE-939   NPE in HStoreKey\n   HBASE-945   Be consistent in use of qualified/unqualified mapfile paths\n   HBASE-946   Row with 55k deletes timesout scanner lease\n   HBASE-950   HTable.commit no longer works with existing RowLocks though it's\n               still in API\n   HBASE-952   Deadlock in HRegion.batchUpdate\n   HBASE-954   Don't reassign root region until ProcessServerShutdown has split\n               the former region server's log\n   HBASE-957   PerformanceEvaluation tests if table exists by comparing\n               descriptors\n   HBASE-728,  HBASE-956, HBASE-955 Address thread naming, which threads are\n               Chores, vs Threads, make HLog manager the write ahead log and\n               not extend it to provided optional HLog sync operations.\n   HBASE-970   Update the copy/rename scripts to go against change API\n   HBASE-966   HBASE-748 misses some writes\n   HBASE-971   Fix the failing tests on Hudson\n   HBASE-973   [doc] In getting started, make it clear that hbase needs to\n               create its directory in hdfs\n   HBASE-963   Fix the retries in HTable.flushCommit\n   HBASE-969   Won't when storefile > 2G.\n   HBASE-976   HADOOP 0.19.0 RC0 is broke; replace with HEAD of branch-0.19\n   HBASE-977   Arcane HStoreKey comparator bug\n   HBASE-979   REST web app is not started automatically\n   HBASE-980   Undo core of HBASE-975, caching of start and end row\n   HBASE-982   Deleting a column in MapReduce fails (Doacan Gney via\n               Stack)\n   HBASE-984   Fix javadoc warnings\n   HBASE-985   Fix javadoc warnings\n   HBASE-951   Either shut down master or let it finish cleanup\n   HBASE-964   Startup stuck \"waiting for root region\"\n   HBASE-964, HBASE-678 provide for safe-mode without locking up HBase \"waiting\n               for root region\"\n   HBASE-990   NoSuchElementException in flushSomeRegions; took two attempts.\n   HBASE-602   HBase Crash when network card has a IPv6 address\n   HBASE-996   Migration script to up the versions in catalog tables\n   HBASE-991   Update the mapred package document examples so they work with\n               TRUNK/0.19.0.\n   HBASE-1003  If cell exceeds TTL but not VERSIONs, will not be removed during\n               major compaction\n   HBASE-1005  Regex and string comparison operators for ColumnValueFilter\n   HBASE-910   Scanner misses columns / rows when the scanner is obtained\n               during a memcache flush\n   HBASE-1009  Master stuck in loop wanting to assign but regions are closing\n   HBASE-1016  Fix example in javadoc overvie\n   HBASE-1021  hbase metrics FileContext not working\n   HBASE-1023  Check global flusher\n   HBASE-1036  HBASE-1028 broke Thrift\n   HBASE-1037  Some test cases failing on Windows/Cygwin but not UNIX/Linux\n   HBASE-1041  Migration throwing NPE\n   HBASE-1042  OOME but we don't abort; two part commit.\n   HBASE-927   We don't recover if HRS hosting -ROOT-/.META. goes down\n   HBASE-1029  REST wiki documentation incorrect\n               (Sishen Freecity via Stack)\n   HBASE-1043  Removing @Override attributes where they are no longer needed.\n               (Ryan Smith via Jim Kellerman)\n   HBASE-927   We don't recover if HRS hosting -ROOT-/.META. goes down -\n               (fix bug in createTable which caused tests to fail)\n   HBASE-1039  Compaction fails if bloomfilters are enabled\n   HBASE-1027  Make global flusher check work with percentages rather than\n               hard code memory sizes\n   HBASE-1000  Sleeper.sleep does not go back to sleep when interrupted\n               and no stop flag given.\n   HBASE-900   Regionserver memory leak causing OOME during relatively\n               modest bulk importing; part 1 and part 2\n   HBASE-1054  Index NPE on scanning (Clint Morgan via Andrew Purtell)\n   HBASE-1052  Stopping a HRegionServer with unflushed cache causes data loss\n               from org.apache.hadoop.hbase.DroppedSnapshotException\n   HBASE-1059  ConcurrentModificationException in notifyChangedReadersObservers\n   HBASE-1063  \"File separator problem on Windows\" (Max Lehn via Stack)\n   HBASE-1068  TestCompaction broken on hudson\n   HBASE-1067  TestRegionRebalancing broken by running of hdfs shutdown thread\n   HBASE-1070  Up default index interval in TRUNK and branch\n   HBASE-1045  Hangup by regionserver causes write to fail\n   HBASE-1079  Dumb NPE in ServerCallable hides the RetriesExhausted exception\n   HBASE-782   The DELETE key in the hbase shell deletes the wrong character\n               (Tim Sell via Stack)\n   HBASE-543,  HBASE-1046, HBase-1051 A region's state is kept in several places\n               in the master opening the possibility for race conditions\n   HBASE-1087  DFS failures did not shutdown regionserver\n   HBASE-1072  Change Thread.join on exit to a timed Thread.join\n   HBASE-1098  IllegalStateException: Cannot set a region to be closed it it\n               was not already marked as closing\n   HBASE-1100  HBASE-1062 broke TestForceSplit\n   HBASE-1191  shell tools -> close_region does not work for regions that did\n               not deploy properly on startup\n   HBASE-1093  NPE in HStore#compact\n   HBASE-1097  SequenceFile.Reader keeps around buffer whose size is that of\n               largest item read -> results in lots of dead heap\n   HBASE-1107  NPE in HStoreScanner.updateReaders\n   HBASE-1083  Will keep scheduling major compactions if last time one ran, we\n               didn't.\n   HBASE-1101  NPE in HConnectionManager$TableServers.processBatchOfRows\n   HBASE-1099  Regions assigned while master is splitting logs of recently\n               crashed server; regionserver tries to execute incomplete log\n   HBASE-1104, HBASE-1098, HBASE-1096: Doubly-assigned regions redux,\n               IllegalStateException: Cannot set a region to be closed it it was\n               not already marked as closing, Does not recover if HRS carrying\n               -ROOT- goes down\n   HBASE-1114  Weird NPEs compacting\n   HBASE-1116  generated web.xml and svn don't play nice together\n   HBASE-1119  ArrayOutOfBoundsException in HStore.compact\n   HBASE-1121  Cluster confused about where -ROOT- is\n   HBASE-1125  IllegalStateException: Cannot set a region to be closed if it was\n               not already marked as pending close\n   HBASE-1124  Balancer kicks in way too early\n   HBASE-1127  OOME running randomRead PE\n   HBASE-1132  Can't append to HLog, can't roll log, infinite cycle (another\n               spin on HBASE-930)\n\n  IMPROVEMENTS\n   HBASE-901   Add a limit to key length, check key and value length on client side\n   HBASE-890   Alter table operation and also related changes in REST interface\n               (Sishen Freecity via Stack)\n   HBASE-894   [shell] Should be able to copy-paste table description to create\n               new table (Sishen Freecity via Stack)\n   HBASE-886, HBASE-895 Sort the tables in the web UI, [shell] 'list' command\n               should emit a sorted list of tables (Krzysztof Szlapinski via Stack)\n   HBASE-884   Double and float converters for Bytes class\n               (Doacan Gney via Stack)\n   HBASE-908   Add approximate counting to CountingBloomFilter\n               (Andrzej Bialecki via Stack)\n   HBASE-920   Make region balancing sloppier\n   HBASE-902   Add force compaction and force split operations to UI and Admin\n   HBASE-942   Add convenience methods to RowFilterSet\n               (Clint Morgan via Stack)\n   HBASE-943   to ColumnValueFilter: add filterIfColumnMissing property, add\n               SubString operator (Clint Morgan via Stack)\n   HBASE-937   Thrift getRow does not support specifying columns\n               (Doacan Gney via Stack)\n   HBASE-959   Be able to get multiple RowResult at one time from client side\n               (Sishen Freecity via Stack)\n   HBASE-936   REST Interface: enable get number of rows from scanner interface\n               (Sishen Freecity via Stack)\n   HBASE-960   REST interface: more generic column family configure and also\n               get Rows using offset and limit (Sishen Freecity via Stack)\n   HBASE-817   Hbase/Shell Truncate\n   HBASE-949   Add an HBase Manual\n   HBASE-839   Update hadoop libs in hbase; move hbase TRUNK on to an hadoop\n               0.19.0 RC\n   HBASE-785   Remove InfoServer, use HADOOP-3824 StatusHttpServer\n               instead (requires hadoop 0.19)\n   HBASE-81    When a scanner lease times out, throw a more \"user friendly\" exception\n   HBASE-978   Remove BloomFilterDescriptor. It is no longer used.\n   HBASE-975   Improve MapFile performance for start and end key\n   HBASE-961   Delete multiple columns by regular expression\n               (Samuel Guo via Stack)\n   HBASE-722   Shutdown and Compactions\n   HBASE-983   Declare Perl namespace in Hbase.thrift\n   HBASE-987   We need a Hbase Partitioner for TableMapReduceUtil.initTableReduceJob\n               MR Jobs (Billy Pearson via Stack)\n   HBASE-993   Turn off logging of every catalog table row entry on every scan\n   HBASE-992   Up the versions kept by catalog tables; currently 1. Make it 10?\n   HBASE-998   Narrow getClosestRowBefore by passing column family\n   HBASE-999   Up versions on historian and keep history of deleted regions for a\n               while rather than delete immediately\n   HBASE-938   Major compaction period is not checked periodically\n   HBASE-947   [Optimization] Major compaction should remove deletes as well as\n               the deleted cell\n   HBASE-675   Report correct server hosting a table split for assignment to\n               for MR Jobs\n   HBASE-927   We don't recover if HRS hosting -ROOT-/.META. goes down\n   HBASE-1013  Add debugging around commit log cleanup\n   HBASE-972   Update hbase trunk to use released hadoop 0.19.0\n   HBASE-1022  Add storefile index size to hbase metrics\n   HBASE-1026  Tests in mapred are failing\n   HBASE-1020  Regionserver OOME handler should dump vital stats\n   HBASE-1018  Regionservers should report detailed health to master\n   HBASE-1034  Remove useless TestToString unit test\n   HBASE-1030  Bit of polish on HBASE-1018\n   HBASE-847   new API: HTable.getRow with numVersion specified\n               (Doacan Gney via Stack)\n   HBASE-1048  HLog: Found 0 logs to remove out of total 1450; oldest\n               outstanding seqnum is 162297053 fr om region -ROOT-,,0\n   HBASE-1055  Better vm stats on startup\n   HBASE-1065  Minor logging improvements in the master\n   HBASE-1053  bring recent rpc changes down from hadoop\n   HBASE-1056  [migration] enable blockcaching on .META. table\n   HBASE-1069  Show whether HRegion major compacts or not in INFO level\n   HBASE-1066  Master should support close/open/reassignment/enable/disable\n               operations on individual regions\n   HBASE-1062  Compactions at (re)start on a large table can overwhelm DFS\n   HBASE-1102  boolean HTable.exists()\n   HBASE-1105  Remove duplicated code in HCM, add javadoc to RegionState, etc.\n   HBASE-1106  Expose getClosestRowBefore in HTable\n               (Michael Gottesman via Stack)\n   HBASE-1082  Administrative functions for table/region maintenance\n   HBASE-1090  Atomic Check And Save in HTable (Michael Gottesman via Stack)\n   HBASE-1137  Add not on xceivers count to overview documentation\n\n  NEW FEATURES\n   HBASE-875   Use MurmurHash instead of JenkinsHash [in bloomfilters]\n               (Andrzej Bialecki via Stack)\n   HBASE-625   Metrics support for cluster load history: emissions and graphs\n   HBASE-883   Secondary indexes (Clint Morgan via Andrew Purtell)\n   HBASE-728   Support for HLog appends\n\n  OPTIMIZATIONS\n   HBASE-748   Add an efficient way to batch update many rows\n   HBASE-887   Fix a hotspot in scanners\n   HBASE-967   [Optimization] Cache cell maximum length (HCD.getMaxValueLength);\n               its used checking batch size\n   HBASE-940   Make the TableOutputFormat batching-aware\n   HBASE-576   Investigate IPC performance\n\nRelease 0.18.0 - September 21st, 2008\n\n  INCOMPATIBLE CHANGES\n   HBASE-697   Thrift idl needs update/edit to match new 0.2 API (and to fix bugs)\n               (Tim Sell via Stack)\n   HBASE-822   Update thrift README and HBase.thrift to use thrift 20080411\n               Updated all other languages examples (only python went in)\n\n  BUG FIXES\n   HBASE-881   Fixed bug when Master tries to reassign split or offline regions\n               from a dead server\n   HBASE-860   Fixed Bug in IndexTableReduce where it concerns writing lucene\n               index fields.\n   HBASE-805   Remove unnecessary getRow overloads in HRS (Jonathan Gray via\n               Jim Kellerman) (Fix whitespace diffs in HRegionServer)\n   HBASE-811   HTD is not fully copyable (Andrew Purtell via Jim Kellerman)\n   HBASE-729   Client region/metadata cache should have a public method for\n               invalidating entries (Andrew Purtell via Stack)\n   HBASE-819   Remove DOS-style ^M carriage returns from all code where found\n               (Jonathan Gray via Jim Kellerman)\n   HBASE-818   Deadlock running 'flushSomeRegions' (Andrew Purtell via Stack)\n   HBASE-820   Need mainline to flush when 'Blocking updates' goes up.\n               (Jean-Daniel Cryans via Stack)\n   HBASE-821   UnknownScanner happens too often (Jean-Daniel Cryans via Stack)\n   HBASE-813   Add a row counter in the new shell (Jean-Daniel Cryans via Stack)\n   HBASE-824   Bug in Hlog we print array of byes for region name\n               (Billy Pearson via Stack)\n   HBASE-825   Master logs showing byte [] in place of string in logging\n               (Billy Pearson via Stack)\n   HBASE-808,809 MAX_VERSIONS not respected, and Deletall doesn't and inserts\n               after delete don't work as expected\n               (Jean-Daniel Cryans via Stack)\n   HBASE-831   committing BatchUpdate with no row should complain\n               (Andrew Purtell via Jim Kellerman)\n   HBASE-833   Doing an insert with an unknown family throws a NPE in HRS\n   HBASE-810   Prevent temporary deadlocks when, during a scan with write\n               operations, the region splits (Jean-Daniel Cryans via Jim\n               Kellerman)\n   HBASE-843   Deleting and recreating a table in a single process does not work\n               (Jonathan Gray via Jim Kellerman)\n   HBASE-849   Speed improvement in JenkinsHash (Andrzej Bialecki via Stack)\n   HBASE-552   Bloom filter bugs (Andrzej Bialecki via Jim Kellerman)\n   HBASE-762   deleteFamily takes timestamp, should only take row and family.\n               Javadoc describes both cases but only implements the timestamp\n               case. (Jean-Daniel Cryans via Jim Kellerman)\n   HBASE-768   This message 'java.io.IOException: Install 0.1.x of hbase and run\n               its migration first' is useless (Jean-Daniel Cryans via Jim\n               Kellerman)\n   HBASE-826   Delete table followed by recreation results in honked table\n   HBASE-834   'Major' compactions and upper bound on files we compact at any\n               one time (Billy Pearson via Stack)\n   HBASE-836   Update thrift examples to work with changed IDL (HBASE-697)\n               (Toby White via Stack)\n   HBASE-854   hbase-841 broke build on hudson? - makes sure that proxies are\n               closed. (Andrew Purtell via Jim Kellerman)\n   HBASE-855   compaction can return less versions then we should in some cases\n               (Billy Pearson via Stack)\n   HBASE-832   Problem with row keys beginnig with characters < than ',' and\n               the region location cache\n   HBASE-864   Deadlock in regionserver\n   HBASE-865   Fix javadoc warnings (Rong-En Fan via Jim Kellerman)\n   HBASE-872   Getting exceptions in shell when creating/disabling tables\n   HBASE-868   Incrementing binary rows cause strange behavior once table\n               splits (Jonathan Gray via Stack)\n   HBASE-877   HCM is unable to find table with multiple regions which contains\n               binary (Jonathan Gray via Stack)\n\n  IMPROVEMENTS\n   HBASE-801  When a table haven't disable, shell could response in a \"user\n              friendly\" way.\n   HBASE-816  TableMap should survive USE (Andrew Purtell via Stack)\n   HBASE-812  Compaction needs little better skip algo (Daniel Leffel via Stack)\n   HBASE-806  Change HbaseMapWritable and RowResult to implement SortedMap\n              instead of Map (Jonathan Gray via Stack)\n   HBASE-795  More Table operation in TableHandler for REST interface: part 1\n              (Sishen Freecity via Stack)\n   HBASE-795  More Table operation in TableHandler for REST interface: part 2\n              (Sishen Freecity via Stack)\n   HBASE-830  Debugging HCM.locateRegionInMeta is painful\n   HBASE-784  Base hbase-0.3.0 on hadoop-0.18\n   HBASE-841  Consolidate multiple overloaded methods in HRegionInterface,\n              HRegionServer (Jean-Daniel Cryans via Jim Kellerman)\n   HBASE-840  More options on the row query in REST interface\n              (Sishen Freecity via Stack)\n   HBASE-874  deleting a table kills client rpc; no subsequent communication if\n              shell or thrift server, etc. (Jonathan Gray via Jim Kellerman)\n   HBASE-871  Major compaction periodicity should be specifyable at the column\n              family level, not cluster wide (Jonathan Gray via Stack)\n   HBASE-465  Fix javadoc for all public declarations\n   HBASE-882  The BatchUpdate class provides, put(col, cell) and delete(col)\n              but no get() (Ryan Smith via Stack and Jim Kellerman)\n\n  NEW FEATURES\n   HBASE-787  Postgresql to HBase table replication example (Tim Sell via Stack)\n   HBASE-798  Provide Client API to explicitly lock and unlock rows (Jonathan\n              Gray via Jim Kellerman)\n   HBASE-798  Add missing classes: UnknownRowLockException and RowLock which\n              were present in previous versions of the patches for this issue,\n              but not in the version that was committed. Also fix a number of\n              compilation problems that were introduced by patch.\n   HBASE-669  MultiRegion transactions with Optimistic Concurrency Control\n              (Clint Morgan via Stack)\n   HBASE-842  Remove methods that have Text as a parameter and were deprecated\n              in 0.2.1 (Jean-Daniel Cryans via Jim Kellerman)\n\n  OPTIMIZATIONS\n\nRelease 0.2.0 - August 8, 2008.\n\n  INCOMPATIBLE CHANGES\n   HBASE-584   Names in the filter interface are confusing (Clint Morgan via\n               Jim Kellerman) (API change for filters)\n   HBASE-601   Just remove deprecated methods in HTable; 0.2 is not backward\n               compatible anyways\n   HBASE-82    Row keys should be array of bytes\n   HBASE-76    Purge servers of Text (Done as part of HBASE-82 commit).\n   HBASE-487   Replace hql w/ a hbase-friendly jirb or jython shell\n               Part 1: purge of hql and added raw jirb in its place.\n   HBASE-521   Improve client scanner interface\n   HBASE-288   Add in-memory caching of data. Required update of hadoop to\n               0.17.0-dev.2008-02-07_12-01-58. (Tom White via Stack)\n   HBASE-696   Make bloomfilter true/false and self-sizing\n   HBASE-720   clean up inconsistencies around deletes (Izaak Rubin via Stack)\n   HBASE-796   Deprecates Text methods from HTable\n               (Michael Gottesman via Stack)\n\n  BUG FIXES\n   HBASE-574   HBase does not load hadoop native libs (Rong-En Fan via Stack)\n   HBASE-598   Loggging, no .log file; all goes into .out\n   HBASE-622   Remove StaticTestEnvironment and put a log4j.properties in src/test\n   HBASE-624   Master will shut down if number of active region servers is zero\n               even if shutdown was not requested\n   HBASE-629   Split reports incorrect elapsed time\n   HBASE-623   Migration script for hbase-82\n   HBASE-630   Default hbase.rootdir is garbage\n   HBASE-589   Remove references to deprecated methods in Hadoop once\n               hadoop-0.17.0 is released\n   HBASE-638   Purge \\r from src\n   HBASE-644   DroppedSnapshotException but RegionServer doesn't restart\n   HBASE-641   Improve master split logging\n   HBASE-642   Splitting log in a hostile environment -- bad hdfs -- we drop\n               write-ahead-log edits\n   HBASE-646   EOFException opening HStoreFile info file (spin on HBASE-645and 550)\n   HBASE-648   If mapfile index is empty, run repair\n   HBASE-640   TestMigrate failing on hudson\n   HBASE-651   Table.commit should throw NoSuchColumnFamilyException if column\n               family doesn't exist\n   HBASE-649   API polluted with default and protected access data members and methods\n   HBASE-650   Add String versions of get, scanner, put in HTable\n   HBASE-656   Do not retry exceptions such as unknown scanner or illegal argument\n   HBASE-659   HLog#cacheFlushLock not cleared; hangs a region\n   HBASE-663   Incorrect sequence number for cache flush\n   HBASE-655   Need programmatic way to add column family: need programmatic way\n               to enable/disable table\n   HBASE-654   API HTable.getMetadata().addFamily shouldn't be exposed to user\n   HBASE-666   UnmodifyableHRegionInfo gives the wrong encoded name\n   HBASE-668   HBASE-533 broke build\n   HBASE-670   Historian deadlocks if regionserver is at global memory boundary\n               and is hosting .META.\n   HBASE-665   Server side scanner doesn't honor stop row\n   HBASE-662   UI in table.jsp gives META locations, not the table's regions\n               location (Jean-Daniel Cryans via Stack)\n   HBASE-676   Bytes.getInt returns a long (Clint Morgan via Stack)\n   HBASE-680   Config parameter hbase.io.index.interval  should be\n               hbase.index.interval, according to HBaseMapFile.HbaseWriter\n               (LN via Stack)\n   HBASE-682   Unnecessary iteration in HMemcache.internalGet? got much better\n               reading performance after break it (LN via Stack)\n   HBASE-686   MemcacheScanner didn't return the first row(if it exists),\n               because HScannerInterface's output incorrect (LN via Jim Kellerman)\n   HBASE-691   get* and getScanner are different in how they treat column parameter\n   HBASE-694   HStore.rowAtOrBeforeFromMapFile() fails to locate the row if # of mapfiles >= 2\n               (Rong-En Fan via Bryan)\n   HBASE-652   dropping table fails silently if table isn't disabled\n   HBASE-683   can not get svn revision # at build time if locale is not english\n               (Rong-En Fan via Stack)\n   HBASE-699   Fix TestMigrate up on Hudson\n   HBASE-615   Region balancer oscillates during cluster startup\n   HBASE-613   Timestamp-anchored scanning fails to find all records\n   HBASE-681   NPE in Memcache\n   HBASE-701   Showing bytes in log when should be String\n   HBASE-702   deleteall doesn't\n   HBASE-704   update new shell docs and commands on help menu\n   HBASE-709   Deadlock while rolling WAL-log while finishing flush\n   HBASE-710   If clocks are way off, then we can have daughter split come\n               before rather than after its parent in .META.\n   HBASE-714   Showing bytes in log when should be string (2)\n   HBASE-627   Disable table doesn't work reliably\n   HBASE-716   TestGet2.testGetClosestBefore fails with hadoop-0.17.1\n   HBASE-715   Base HBase 0.2 on Hadoop 0.17.1\n   HBASE-718   hbase shell help info\n   HBASE-717   alter table broke with new shell returns InvalidColumnNameException\n   HBASE-573   HBase does not read hadoop-*.xml for dfs configuration after\n               moving out hadoop/contrib\n   HBASE-11    Unexpected exits corrupt DFS\n   HBASE-12    When hbase regionserver restarts, it says \"impossible state for\n               createLease()\"\n   HBASE-575   master dies with stack overflow error if rootdir isn't qualified\n   HBASE-582   HBase 554 forgot to clear results on each iteration caused by a filter\n               (Clint Morgan via Stack)\n   HBASE-532   Odd interaction between HRegion.get, HRegion.deleteAll and compactions\n   HBASE-10    HRegionServer hangs upon exit due to DFSClient Exception\n   HBASE-595   RowFilterInterface.rowProcessed() is called *before* fhe final\n               filtering decision is made (Clint Morgan via Stack)\n   HBASE-586   HRegion runs HStore memcache snapshotting -- fix it so only HStore\n               knows about workings of memcache\n   HBASE-588   Still a 'hole' in scanners, even after HBASE-532\n   HBASE-604   Don't allow CLASSPATH from environment pollute the hbase CLASSPATH\n   HBASE-608   HRegionServer::getThisIP() checks hadoop config var for dns interface name\n               (Jim R. Wilson via Stack)\n   HBASE-609   Master doesn't see regionserver edits because of clock skew\n   HBASE-607   MultiRegionTable.makeMultiRegionTable is not deterministic enough\n               for regression tests\n   HBASE-405   TIF and TOF use log4j directly rather than apache commons-logging\n   HBASE-618   We always compact if 2 files, regardless of the compaction threshold setting\n   HBASE-619   Fix 'logs' link in UI\n   HBASE-478   offlining of table does not run reliably\n   HBASE-453   undeclared throwable exception from HTable.get\n   HBASE-620   testmergetool failing in branch and trunk since hbase-618 went in\n   HBASE-550   EOF trying to read reconstruction log stops region deployment\n   HBASE-551   Master stuck splitting server logs in shutdown loop; on each\n               iteration, edits are aggregated up into the millions\n   HBASE-505   Region assignments should never time out so long as the region\n               server reports that it is processing the open request\n   HBASE-561   HBase package does not include LICENSE.txt nor build.xml\n   HBASE-563   TestRowFilterAfterWrite erroneously sets master address to\n               0.0.0.0:60100 rather than relying on conf\n   HBASE-507   Use Callable pattern to sleep between retries\n   HBASE-564   Don't do a cache flush if there are zero entries in the cache.\n   HBASE-554   filters generate StackOverflowException\n   HBASE-567   Reused BatchUpdate instances accumulate BatchOperations\n   HBASE-577   NPE getting scanner\n   HBASE-19    CountingBloomFilter can overflow its storage\n               (Stu Hood and Bryan Duxbury via Stack)\n   HBASE-28    thrift put/mutateRow methods need to throw IllegalArgument\n               exceptions (Dave Simpson via Bryan Duxbury via Stack)\n   HBASE-2     hlog numbers should wrap around when they reach 999\n               (Bryan Duxbury via Stack)\n   HBASE-421   TestRegionServerExit broken\n   HBASE-426   hbase can't find remote filesystem\n   HBASE-437   Clear Command should use system.out (Edward Yoon via Stack)\n   HBASE-434, HBASE-435 TestTableIndex and TestTableMapReduce failed in Hudson builds\n   HBASE-446   Fully qualified hbase.rootdir doesn't work\n   HBASE-438   XMLOutputter state should be initialized. (Edward Yoon via Stack)\n   HBASE-8     Delete table does not remove the table directory in the FS\n   HBASE-428   Under continuous upload of rows, WrongRegionExceptions are thrown\n               that reach the client even after retries\n   HBASE-460   TestMigrate broken when HBase moved to subproject\n   HBASE-462   Update migration tool\n   HBASE-473   When a table is deleted, master sends multiple close messages to\n               the region server\n   HBASE-490   Doubly-assigned .META.; master uses one and clients another\n   HBASE-492   hbase TRUNK does not build against hadoop TRUNK\n   HBASE-496   impossible state for createLease writes 400k lines in about 15mins\n   HBASE-472   Passing on edits, we dump all to log\n   HBASE-495   No server address listed in .META.\n   HBASE-433 HBASE-251 Region server should delete restore log after successful\n               restore, Stuck replaying the edits of crashed machine.\n   HBASE-27    hregioninfo cell empty in meta table\n   HBASE-501   Empty region server address in info:server entry and a\n               startcode of -1 in .META.\n   HBASE-516   HStoreFile.finalKey does not update the final key if it is not\n               the top region of a split region\n   HBASE-525   HTable.getRow(Text) does not work (Clint Morgan via Bryan Duxbury)\n   HBASE-524   Problems with getFull\n   HBASE-528   table 'does not exist' when it does\n   HBASE-531   Merge tool won't merge two overlapping regions (port HBASE-483 to\n               trunk)\n   HBASE-537   Wait for hdfs to exit safe mode\n   HBASE-476   RegexpRowFilter behaves incorectly when there are multiple store\n               files (Clint Morgan via Jim Kellerman)\n   HBASE-527   RegexpRowFilter does not work when there are columns from\n               multiple families (Clint Morgan via Jim Kellerman)\n   HBASE-534   Double-assignment at SPLIT-time\n   HBASE-712   midKey found compacting is the first, not necessarily the optimal\n   HBASE-719   Find out why users have network problems in HBase and not in Hadoop\n               and HConnectionManager (Jean-Daniel Cryans via Stack)\n   HBASE-703   Invalid regions listed by regionserver.jsp (Izaak Rubin via Stack)\n   HBASE-674   Memcache size unreliable\n   HBASE-726   Unit tests won't run because of a typo (Sebastien Rainville via Stack)\n   HBASE-727   Client caught in an infinite loop when trying to connect to cached\n               server locations (Izaak Rubin via Stack)\n   HBASE-732   shell formatting error with the describe command\n               (Izaak Rubin via Stack)\n   HBASE-731   delete, deletefc in HBase shell do not work correctly\n               (Izaak Rubin via Stack)\n   HBASE-734   scan '.META.', {LIMIT => 10} crashes (Izaak Rubin via Stack)\n   HBASE-736   Should have HTable.deleteAll(String row) and HTable.deleteAll(Text row)\n               (Jean-Daniel Cryans via Stack)\n   HBASE-740   ThriftServer getting table names incorrectly (Tim Sell via Stack)\n   HBASE-742   Rename getMetainfo in HTable as getTableDescriptor\n   HBASE-739   HBaseAdmin.createTable() using old HTableDescription doesn't work\n               (Izaak Rubin via Stack)\n   HBASE-744   BloomFilter serialization/deserialization broken\n   HBASE-742   Column length limit is not enforced (Jean-Daniel Cryans via Stack)\n   HBASE-737   Scanner: every cell in a row has the same timestamp\n   HBASE-700   hbase.io.index.interval need be configuratable in column family\n               (Andrew Purtell via Stack)\n   HBASE-62    Allow user add arbitrary key/value pairs to table and column\n               descriptors (Andrew Purtell via Stack)\n   HBASE-34    Set memcache flush size per column (Andrew Purtell via Stack)\n   HBASE-42    Set region split size on table creation (Andrew Purtell via Stack)\n   HBASE-43    Add a read-only attribute to columns (Andrew Purtell via Stack)\n   HBASE-424   Should be able to enable/disable .META. table\n   HBASE-679   Regionserver addresses are still not right in the new tables page\n   HBASE-758   Throwing IOE read-only when should be throwing NSRE\n   HBASE-743   bin/hbase migrate upgrade fails when redo logs exists\n   HBASE-754   The JRuby shell documentation is wrong in \"get\" and \"put\"\n               (Jean-Daniel Cryans via Stack)\n   HBASE-756   In HBase shell, the put command doesn't process the timestamp\n               (Jean-Daniel Cryans via Stack)\n   HBASE-757   REST mangles table names (Sishen via Stack)\n   HBASE-706   On OOME, regionserver sticks around and doesn't go down with cluster\n               (Jean-Daniel Cryans via Stack)\n   HBASE-759   TestMetaUtils failing on hudson\n   HBASE-761   IOE: Stream closed exception all over logs\n   HBASE-763   ClassCastException from RowResult.get(String)\n               (Andrew Purtell via Stack)\n   HBASE-764   The name of column request has padding zero using REST interface\n               (Sishen Freecity via Stack)\n   HBASE-750   NPE caused by StoreFileScanner.updateReaders\n   HBASE-769   TestMasterAdmin fails throwing RegionOfflineException when we're\n               expecting IllegalStateException\n   HBASE-766   FileNotFoundException trying to load HStoreFile 'data'\n   HBASE-770   Update HBaseRPC to match hadoop 0.17 RPC\n   HBASE-780   Can't scan '.META.' from new shell\n   HBASE-424   Should be able to enable/disable .META. table\n   HBASE-771   Names legal in 0.1 are not in 0.2; breaks migration\n   HBASE-788   Div by zero in Master.jsp (Clint Morgan via Jim Kellerman)\n   HBASE-791   RowCount doesn't work (Jean-Daniel Cryans via Stack)\n   HBASE-751   dfs exception and regionserver stuck during heavy write load\n   HBASE-793   HTable.getStartKeys() ignores table names when matching columns\n               (Andrew Purtell and Dru Jensen via Stack)\n   HBASE-790   During import, single region blocks requests for >10 minutes,\n               thread dumps, throws out pending requests, and continues\n               (Jonathan Gray via Stack)\n\n  IMPROVEMENTS\n   HBASE-559   MR example job to count table rows\n   HBASE-596   DemoClient.py (Ivan Begtin via Stack)\n   HBASE-581   Allow adding filters to TableInputFormat (At same time, ensure TIF\n               is subclassable) (David Alves via Stack)\n   HBASE-603   When an exception bubbles out of getRegionServerWithRetries, wrap\n               the exception with a RetriesExhaustedException\n   HBASE-600   Filters have excessive DEBUG logging\n   HBASE-611   regionserver should do basic health check before reporting\n               alls-well to the master\n   HBASE-614   Retiring regions is not used; exploit or remove\n   HBASE-538   Improve exceptions that come out on client-side\n   HBASE-569   DemoClient.php (Jim R. Wilson via Stack)\n   HBASE-522   Where new Text(string) might be used in client side method calls,\n               add an overload that takes String (Done as part of HBASE-82)\n   HBASE-570   Remove HQL unit test (Done as part of HBASE-82 commit).\n   HBASE-626   Use Visitor pattern in MetaRegion to reduce code clones in HTable\n               and HConnectionManager (Jean-Daniel Cryans via Stack)\n   HBASE-621   Make MAX_VERSIONS work like TTL: In scans and gets, check\n               MAX_VERSIONs setting and return that many only rather than wait on\n               compaction (Jean-Daniel Cryans via Stack)\n   HBASE-504   Allow HMsg's carry a payload: e.g. exception that happened over\n               on the remote side.\n   HBASE-583   RangeRowFilter/ColumnValueFilter to allow choice of rows based on\n               a (lexicographic) comparison to column's values\n               (Clint Morgan via Stack)\n   HBASE-579   Add hadoop 0.17.x\n   HBASE-660   [Migration] addColumn/deleteColumn functionality in MetaUtils\n   HBASE-632   HTable.getMetadata is very inefficient\n   HBASE-671   New UI page displaying all regions in a table should be sorted\n   HBASE-672   Sort regions in the regionserver UI\n   HBASE-677   Make HTable, HRegion, HRegionServer, HStore, and HColumnDescriptor\n               subclassable (Clint Morgan via Stack)\n   HBASE-682   Regularize toString\n   HBASE-672   Sort regions in the regionserver UI\n   HBASE-469   Streamline HStore startup and compactions\n   HBASE-544   Purge startUpdate from internal code and test cases\n   HBASE-557   HTable.getRow() should receive RowResult objects\n   HBASE-452   \"region offline\" should throw IOException, not IllegalStateException\n   HBASE-541   Update hadoop jars.\n   HBASE-523   package-level javadoc should have example client\n   HBASE-415   Rewrite leases to use DelayedBlockingQueue instead of polling\n   HBASE-35    Make BatchUpdate public in the API\n   HBASE-409   Add build path to svn:ignore list (Edward Yoon via Stack)\n   HBASE-408   Add .classpath and .project to svn:ignore list\n               (Edward Yoon via Stack)\n   HBASE-410   Speed up the test suite (make test timeout 5 instead of 15 mins).\n   HBASE-281   Shell should allow deletions in .META. and -ROOT- tables\n               (Edward Yoon & Bryan Duxbury via Stack)\n   HBASE-56    Unnecessary HQLClient Object creation in a shell loop\n               (Edward Yoon via Stack)\n   HBASE-3     rest server: configure number of threads for jetty\n               (Bryan Duxbury via Stack)\n   HBASE-416   Add apache-style logging to REST server and add setting log\n               level, etc.\n   HBASE-406   Remove HTable and HConnection close methods\n               (Bryan Duxbury via Stack)\n   HBASE-418   Move HMaster and related classes into master package\n               (Bryan Duxbury via Stack)\n   HBASE-410   Speed up the test suite - Apparently test timeout was too\n               aggressive for Hudson. TestLogRolling timed out even though it\n               was operating properly. Change test timeout to 10 minutes.\n   HBASE-436   website: http://hadoop.apache.org/hbase\n   HBASE-417   Factor TableOperation and subclasses into separate files from\n               HMaster (Bryan Duxbury via Stack)\n   HBASE-440   Add optional log roll interval so that log files are garbage\n               collected\n   HBASE-407   Keep HRegionLocation information in LRU structure\n   HBASE-444   hbase is very slow at determining table is not present\n   HBASE-438   XMLOutputter state should be initialized.\n   HBASE-414   Move client classes into client package\n   HBASE-79    When HBase needs to be migrated, it should display a message on\n               stdout, not just in the logs\n   HBASE-461   Simplify leases.\n   HBASE-419   Move RegionServer and related classes into regionserver package\n   HBASE-457   Factor Master into Master, RegionManager, and ServerManager\n   HBASE-464   HBASE-419 introduced javadoc errors\n   HBASE-468   Move HStoreKey back to o.a.h.h\n   HBASE-442   Move internal classes out of HRegionServer\n   HBASE-466   Move HMasterInterface, HRegionInterface, and\n               HMasterRegionInterface into o.a.h.h.ipc\n   HBASE-479   Speed up TestLogRolling\n   HBASE-480   Tool to manually merge two regions\n   HBASE-477   Add support for an HBASE_CLASSPATH\n   HBASE-443   Move internal classes out of HStore\n   HBASE-515   At least double default timeouts between regionserver and master\n   HBASE-529   RegionServer needs to recover if datanode goes down\n   HBASE-456   Clearly state which ports need to be opened in order to run HBase\n   HBASE-536   Remove MiniDFS startup from MiniHBaseCluster\n   HBASE-521   Improve client scanner interface\n   HBASE-562   Move Exceptions to subpackages (Jean-Daniel Cryans via Stack)\n   HBASE-631   HTable.getRow() for only a column family\n               (Jean-Daniel Cryans via Stack)\n   HBASE-731   Add a meta refresh tag to the Web ui for master and region server\n               (Jean-Daniel Cryans via Stack)\n   HBASE-735   hbase shell doesn't trap CTRL-C signal (Jean-Daniel Cryans via Stack)\n   HBASE-730   On startup, rinse STARTCODE and SERVER from .META.\n               (Jean-Daniel Cryans via Stack)\n   HBASE-738   overview.html in need of updating (Izaak Rubin via Stack)\n   HBASE-745   scaling of one regionserver, improving memory and cpu usage (partial)\n               (LN via Stack)\n   HBASE-746   Batching row mutations via thrift (Tim Sell via Stack)\n   HBASE-772   Up default lease period from 60 to 120 seconds\n   HBASE-779   Test changing hbase.hregion.memcache.block.multiplier to 2\n   HBASE-783   For single row, single family retrieval, getRow() works half\n               as fast as getScanner().next() (Jean-Daniel Cryans via Stack)\n   HBASE-789   add clover coverage report targets (Rong-en Fan via Stack)\n\n  NEW FEATURES\n   HBASE-47    Option to set TTL for columns in hbase\n               (Andrew Purtell via Bryan Duxbury and Stack)\n   HBASE-23    UI listing regions should be sorted by address and show additional\n               region state (Jean-Daniel Cryans via Stack)\n   HBASE-639   Add HBaseAdmin.getTableDescriptor function\n   HBASE-533   Region Historian\n   HBASE-487   Replace hql w/ a hbase-friendly jirb or jython shell\n   HBASE-548   Tool to online single region\n   HBASE-71    Master should rebalance region assignments periodically\n   HBASE-512   Add configuration for global aggregate memcache size\n   HBASE-40    Add a method of getting multiple (but not all) cells for a row\n               at once\n   HBASE-506   When an exception has to escape ServerCallable due to exhausted\n               retries, show all the exceptions that lead to this situation\n   HBASE-747   Add a simple way to do batch updates of many rows (Jean-Daniel\n               Cryans via JimK)\n   HBASE-733   Enhance Cell so that it can contain multiple values at multiple\n               timestamps\n   HBASE-511   Do exponential backoff in clients on NSRE, WRE, ISE, etc.\n               (Andrew Purtell via Jim Kellerman)\n\n  OPTIMIZATIONS\n   HBASE-430   Performance: Scanners and getRow return maps with duplicate data\n\nRelease 0.1.3 - 07/25/2008\n\n  BUG FIXES\n   HBASE-644   DroppedSnapshotException but RegionServer doesn't restart\n   HBASE-645   EOFException opening region (HBASE-550 redux)\n   HBASE-641   Improve master split logging\n   HBASE-642   Splitting log in a hostile environment -- bad hdfs -- we drop\n               write-ahead-log edits\n   HBASE-646   EOFException opening HStoreFile info file (spin on HBASE-645 and 550)\n   HBASE-648   If mapfile index is empty, run repair\n   HBASE-659   HLog#cacheFlushLock not cleared; hangs a region\n   HBASE-663   Incorrect sequence number for cache flush\n   HBASE-652   Dropping table fails silently if table isn't disabled\n   HBASE-674   Memcache size unreliable\n   HBASE-665   server side scanner doesn't honor stop row\n   HBASE-681   NPE in Memcache (Clint Morgan via Jim Kellerman)\n   HBASE-680   config parameter hbase.io.index.interval should be\n               hbase.index.interval, accroding to HBaseMapFile.HbaseWriter\n               (LN via Stack)\n   HBASE-684   unnecessary iteration in HMemcache.internalGet? got much better\n               reading performance after break it (LN via Stack)\n   HBASE-686   MemcacheScanner didn't return the first row(if it exists),\n               because HScannerInterface's output incorrect (LN via Jim Kellerman)\n   HBASE-613   Timestamp-anchored scanning fails to find all records\n   HBASE-709   Deadlock while rolling WAL-log while finishing flush\n   HBASE-707   High-load import of data into single table/family never triggers split\n   HBASE-710   If clocks are way off, then we can have daughter split come\n               before rather than after its parent in .META.\n\nRelease 0.1.2 - 05/13/2008\n\n  BUG FIXES\n   HBASE-577   NPE getting scanner\n   HBASE-574   HBase does not load hadoop native libs (Rong-En Fan via Stack).\n   HBASE-11    Unexpected exits corrupt DFS - best we can do until we have at\n               least a subset of HADOOP-1700\n   HBASE-573   HBase does not read hadoop-*.xml for dfs configuration after\n               moving out hadoop/contrib\n   HBASE-12    when hbase regionserver restarts, it says \"impossible state for\n               createLease()\"\n   HBASE-575   master dies with stack overflow error if rootdir isn't qualified\n   HBASE-500   Regionserver stuck on exit\n   HBASE-582   HBase 554 forgot to clear results on each iteration caused by a filter\n               (Clint Morgan via Stack)\n   HBASE-532   Odd interaction between HRegion.get, HRegion.deleteAll and compactions\n   HBASE-590   HBase migration tool does not get correct FileSystem or root\n               directory if configuration is not correct\n   HBASE-595   RowFilterInterface.rowProcessed() is called *before* fhe final\n               filtering decision is made (Clint Morgan via Stack)\n   HBASE-586   HRegion runs HStore memcache snapshotting -- fix it so only HStore\n               knows about workings of memcache\n   HBASE-572   Backport HBASE-512 to 0.1 branch\n   HBASE-588   Still a 'hole' in scanners, even after HBASE-532\n   HBASE-604   Don't allow CLASSPATH from environment pollute the hbase CLASSPATH\n   HBASE-608   HRegionServer::getThisIP() checks hadoop config var for dns interface name\n               (Jim R. Wilson via Stack)\n   HBASE-609   Master doesn't see regionserver edits because of clock skew\n   HBASE-607   MultiRegionTable.makeMultiRegionTable is not deterministic enough\n               for regression tests\n   HBASE-478   offlining of table does not run reliably\n   HBASE-618   We always compact if 2 files, regardless of the compaction threshold setting\n   HBASE-619   Fix 'logs' link in UI\n   HBASE-620   testmergetool failing in branch and trunk since hbase-618 went in\n\n  IMPROVEMENTS\n   HBASE-559   MR example job to count table rows\n   HBASE-578   Upgrade branch to 0.16.3 hadoop.\n   HBASE-596   DemoClient.py (Ivan Begtin via Stack)\n\n\nRelease 0.1.1 - 04/11/2008\n\n  BUG FIXES\n   HBASE-550   EOF trying to read reconstruction log stops region deployment\n   HBASE-551   Master stuck splitting server logs in shutdown loop; on each\n               iteration, edits are aggregated up into the millions\n   HBASE-505   Region assignments should never time out so long as the region\n               server reports that it is processing the open request\n   HBASE-552   Fix bloom filter bugs (Andrzej Bialecki via Jim Kellerman)\n   HBASE-507   Add sleep between retries\n   HBASE-555   Only one Worker in HRS; on startup, if assigned tens of regions,\n               havoc of reassignments because open processing is done in series\n   HBASE-547   UI shows hadoop version, not hbase version\n   HBASE-561   HBase package does not include LICENSE.txt nor build.xml\n   HBASE-556   Add 0.16.2 to hbase branch -- if it works\n   HBASE-563   TestRowFilterAfterWrite erroneously sets master address to\n               0.0.0.0:60100 rather than relying on conf\n   HBASE-554   filters generate StackOverflowException (Clint Morgan via\n               Jim Kellerman)\n   HBASE-567   Reused BatchUpdate instances accumulate BatchOperations\n\n  NEW FEATURES\n   HBASE-548   Tool to online single region\n\nRelease 0.1.0\n\n  INCOMPATIBLE CHANGES\n   HADOOP-2750 Deprecated methods startBatchUpdate, commitBatch, abortBatch,\n               and renewLease have been removed from HTable (Bryan Duxbury via\n               Jim Kellerman)\n   HADOOP-2786 Move hbase out of hadoop core\n   HBASE-403   Fix build after move of hbase in svn\n   HBASE-494   Up IPC version on 0.1 branch so we cannot mistakenly connect\n               with a hbase from 0.16.0\n\n  NEW FEATURES\n   HBASE-506   When an exception has to escape ServerCallable due to exhausted retries,\n               show all the exceptions that lead to this situation\n\n  OPTIMIZATIONS\n\n  BUG FIXES\n   HADOOP-2731 Under load, regions become extremely large and eventually cause\n               region servers to become unresponsive\n   HADOOP-2693 NPE in getClosestRowBefore (Bryan Duxbury & Stack)\n   HADOOP-2599 Some minor improvements to changes in HADOOP-2443\n               (Bryan Duxbury & Stack)\n   HADOOP-2773 Master marks region offline when it is recovering from a region\n               server death\n   HBASE-425   Fix doc. so it accomodates new hbase untethered context\n   HBase-421   TestRegionServerExit broken\n   HBASE-426   hbase can't find remote filesystem\n   HBASE-446   Fully qualified hbase.rootdir doesn't work\n   HBASE-428   Under continuous upload of rows, WrongRegionExceptions are\n               thrown that reach the client even after retries\n   HBASE-490   Doubly-assigned .META.; master uses one and clients another\n   HBASE-496   impossible state for createLease writes 400k lines in about 15mins\n   HBASE-472   Passing on edits, we dump all to log\n   HBASE-79    When HBase needs to be migrated, it should display a message on\n               stdout, not just in the logs\n   HBASE-495   No server address listed in .META.\n   HBASE-433 HBASE-251 Region server should delete restore log after successful\n               restore, Stuck replaying the edits of crashed machine.\n   HBASE-27    hregioninfo cell empty in meta table\n   HBASE-501   Empty region server address in info:server entry and a\n               startcode of -1 in .META.\n   HBASE-516   HStoreFile.finalKey does not update the final key if it is not\n               the top region of a split region\n   HBASE-524   Problems with getFull\n   HBASE-514   table 'does not exist' when it does\n   HBASE-537   Wait for hdfs to exit safe mode\n   HBASE-534   Double-assignment at SPLIT-time\n\n  IMPROVEMENTS\n   HADOOP-2555 Refactor the HTable#get and HTable#getRow methods to avoid\n               repetition of retry-on-failure logic (thanks to Peter Dolan and\n               Bryan Duxbury)\n   HBASE-281   Shell should allow deletions in .META. and -ROOT- tables\n   HBASE-480   Tool to manually merge two regions\n   HBASE-477   Add support for an HBASE_CLASSPATH\n   HBASE-515   At least double default timeouts between regionserver and master\n   HBASE-482   package-level javadoc should have example client or at least\n               point at the FAQ\n   HBASE-497   RegionServer needs to recover if datanode goes down\n   HBASE-456   Clearly state which ports need to be opened in order to run HBase\n   HBASE-483   Merge tool won't merge two overlapping regions\n   HBASE-476   RegexpRowFilter behaves incorectly when there are multiple store\n               files (Clint Morgan via Jim Kellerman)\n   HBASE-527   RegexpRowFilter does not work when there are columns from\n               multiple families (Clint Morgan via Jim Kellerman)\n\nRelease 0.16.0\n\n  2008/02/04   HBase is now a subproject of Hadoop. The first HBase release as\n               a subproject will be release 0.1.0 which will be equivalent to\n               the version of HBase included in Hadoop 0.16.0. In order to\n               accomplish this, the HBase portion of HBASE-288 (formerly\n               HADOOP-1398) has been backed out. Once 0.1.0 is frozen (depending\n               mostly on changes to infrastructure due to becoming a sub project\n               instead of a contrib project), this patch will re-appear on HBase\n               trunk.\n\n  INCOMPATIBLE CHANGES\n   HADOOP-2056 A table with row keys containing colon fails to split regions\n   HADOOP-2079 Fix generated HLog, HRegion names\n   HADOOP-2495 Minor performance improvements: Slim-down BatchOperation, etc.\n   HADOOP-2506 Remove the algebra package\n   HADOOP-2519 Performance improvements: Customized RPC serialization\n   HADOOP-2478 Restructure how HBase lays out files in the file system (phase 1)\n               (test input data)\n   HADOOP-2478 Restructure how HBase lays out files in the file system (phase 2)\n               Includes migration tool org.apache.hadoop.hbase.util.Migrate\n   HADOOP-2558 org.onelab.filter.BloomFilter class uses 8X the memory it should\n               be using\n\n  NEW FEATURES\n    HADOOP-2061 Add new Base64 dialects\n    HADOOP-2084 Add a LocalHBaseCluster\n    HADOOP-2068 RESTful interface (Bryan Duxbury via Stack)\n    HADOOP-2316 Run REST servlet outside of master\n                (Bryan Duxbury & Stack)\n    HADOOP-1550 No means of deleting a'row' (Bryan Duxbuery via Stack)\n    HADOOP-2384 Delete all members of a column family on a specific row\n                (Bryan Duxbury via Stack)\n    HADOOP-2395 Implement \"ALTER TABLE ... CHANGE column\" operation\n                (Bryan Duxbury via Stack)\n    HADOOP-2240 Truncate for hbase (Edward Yoon via Stack)\n    HADOOP-2389 Provide multiple language bindings for HBase (Thrift)\n                (David Simpson via Stack)\n\n  OPTIMIZATIONS\n   HADOOP-2479 Save on number of Text object creations\n   HADOOP-2485 Make mapfile index interval configurable (Set default to 32\n               instead of 128)\n   HADOOP-2553 Don't make Long objects calculating hbase type hash codes\n   HADOOP-2377 Holding open MapFile.Readers is expensive, so use less of them\n   HADOOP-2407 Keeping MapFile.Reader open is expensive: Part 2\n   HADOOP-2533 Performance: Scanning, just creating MapWritable in next\n               consumes >20% CPU\n   HADOOP-2443 Keep lazy cache of regions in client rather than an\n               'authoritative' list (Bryan Duxbury via Stack)\n   HADOOP-2600 Performance: HStore.getRowKeyAtOrBefore should use\n               MapFile.Reader#getClosest (before)\n               (Bryan Duxbury via Stack)\n\n  BUG FIXES\n   HADOOP-2059 In tests, exceptions in min dfs shutdown should not fail test\n               (e.g. nightly #272)\n   HADOOP-2064 TestSplit assertion and NPE failures (Patch build #952 and #953)\n   HADOOP-2124 Use of `hostname` does not work on Cygwin in some cases\n   HADOOP-2083 TestTableIndex failed in #970 and #956\n   HADOOP-2109 Fixed race condition in processing server lease timeout.\n   HADOOP-2137 hql.jsp : The character 0x19 is not valid\n   HADOOP-2109 Fix another race condition in processing dead servers,\n               Fix error online meta regions: was using region name and not\n               startKey as key for map.put. Change TestRegionServerExit to\n               always kill the region server for the META region. This makes\n               the test more deterministic and getting META reassigned was\n               problematic.\n   HADOOP-2155 Method expecting HBaseConfiguration throws NPE when given Configuration\n   HADOOP-2156 BufferUnderflowException for un-named HTableDescriptors\n   HADOOP-2161 getRow() is orders of magnitudes slower than get(), even on rows\n               with one column (Clint Morgan and Stack)\n   HADOOP-2040 Hudson hangs AFTER test has finished\n   HADOOP-2274 Excess synchronization introduced by HADOOP-2139 negatively\n               impacts performance\n   HADOOP-2196 Fix how hbase sits in hadoop 'package' product\n   HADOOP-2276 Address regression caused by HADOOP-2274, fix HADOOP-2173 (When\n               the master times out a region servers lease, the region server\n               may not restart)\n   HADOOP-2253 getRow can return HBASE::DELETEVAL cells\n               (Bryan Duxbury via Stack)\n   HADOOP-2295 Fix assigning a region to multiple servers\n   HADOOP-2234 TableInputFormat erroneously aggregates map values\n   HADOOP-2308 null regioninfo breaks meta scanner\n   HADOOP-2304 Abbreviated symbol parsing error of dir path in jar command\n               (Edward Yoon via Stack)\n   HADOOP-2320 Committed TestGet2 is managled (breaks build).\n   HADOOP-2322 getRow(row, TS) client interface not properly connected\n   HADOOP-2309 ConcurrentModificationException doing get of all region start keys\n   HADOOP-2321 TestScanner2 does not release resources which sometimes cause the\n               test to time out\n   HADOOP-2315 REST servlet doesn't treat / characters in row key correctly\n               (Bryan Duxbury via Stack)\n   HADOOP-2332 Meta table data selection in Hbase Shell\n               (Edward Yoon via Stack)\n   HADOOP-2347 REST servlet not thread safe but run in a threaded manner\n               (Bryan Duxbury via Stack)\n   HADOOP-2365 Result of HashFunction.hash() contains all identical values\n   HADOOP-2362 Leaking hdfs file handle on region split\n   HADOOP-2338 Fix NullPointerException in master server.\n   HADOOP-2380 REST servlet throws NPE when any value node has an empty string\n               (Bryan Duxbury via Stack)\n   HADOOP-2350 Scanner api returns null row names, or skips row names if\n               different column families do not have entries for some rows\n   HADOOP-2283 AlreadyBeingCreatedException (Was: Stuck replay of failed\n               regionserver edits)\n   HADOOP-2392 TestRegionServerExit has new failure mode since HADOOP-2338\n   HADOOP-2324 Fix assertion failures in TestTableMapReduce\n   HADOOP-2396 NPE in HMaster.cancelLease\n   HADOOP-2397 The only time that a meta scanner should try to recover a log is\n               when the master is starting\n   HADOOP-2417 Fix critical shutdown problem introduced by HADOOP-2338\n   HADOOP-2418 Fix assertion failures in TestTableMapReduce, TestTableIndex,\n               and TestTableJoinMapReduce\n   HADOOP-2414 Fix ArrayIndexOutOfBoundsException in bloom filters.\n   HADOOP-2430 Master will not shut down if there are no active region servers\n   HADOOP-2199 Add tools for going from hregion filename to region name in logs\n   HADOOP-2441 Fix build failures in TestHBaseCluster\n   HADOOP-2451 End key is incorrectly assigned in many region splits\n   HADOOP-2455 Error in Help-string of CREATE command (Edward Yoon via Stack)\n   HADOOP-2465 When split parent regions are cleaned up, not all the columns are\n               deleted\n   HADOOP-2468 TestRegionServerExit failed in Hadoop-Nightly #338\n   HADOOP-2467 scanner truncates resultset when > 1 column families\n   HADOOP-2503 REST Insert / Select encoding issue (Bryan Duxbury via Stack)\n   HADOOP-2505 formatter classes missing apache license\n   HADOOP-2504 REST servlet method for deleting a scanner was not properly\n               mapped (Bryan Duxbury via Stack)\n   HADOOP-2507 REST servlet does not properly base64 row keys and column names\n               (Bryan Duxbury via Stack)\n   HADOOP-2530 Missing type in new hbase custom RPC serializer\n   HADOOP-2490 Failure in nightly #346 (Added debugging of hudson failures).\n   HADOOP-2558 fixes for build up on hudson (part 1, part 2, part 3, part 4)\n   HADOOP-2500 Unreadable region kills region servers\n   HADOOP-2579 Initializing a new HTable object against a nonexistent table\n               throws a NoServerForRegionException instead of a\n               TableNotFoundException when a different table has been created\n               previously (Bryan Duxbury via Stack)\n   HADOOP-2587 Splits blocked by compactions cause region to be offline for\n               duration of compaction.\n   HADOOP-2592 Scanning, a region can let out a row that its not supposed\n               to have\n   HADOOP-2493 hbase will split on row when the start and end row is the\n               same cause data loss (Bryan Duxbury via Stack)\n   HADOOP-2629 Shell digests garbage without complaint\n   HADOOP-2619 Compaction errors after a region splits\n   HADOOP-2621 Memcache flush flushing every 60 secs with out considering\n               the max memcache size\n   HADOOP-2584 Web UI displays an IOException instead of the Tables\n   HADOOP-2650 Remove Writables.clone and use WritableUtils.clone from\n               hadoop instead\n   HADOOP-2668 Documentation and improved logging so fact that hbase now\n               requires migration comes as less of a surprise\n   HADOOP-2686 Removed tables stick around in .META.\n   HADOOP-2688 IllegalArgumentException processing a shutdown stops\n               server going down and results in millions of lines of output\n   HADOOP-2706 HBase Shell crash\n   HADOOP-2712 under load, regions won't split\n   HADOOP-2675 Options not passed to rest/thrift\n   HADOOP-2722 Prevent unintentional thread exit in region server and master\n   HADOOP-2718 Copy Constructor HBaseConfiguration(Configuration) will override\n               hbase configurations if argumant is not an instance of\n               HBaseConfiguration.\n   HADOOP-2753 Back out 2718; programmatic config works but hbase*xml conf\n               is overridden\n   HADOOP-2718 Copy Constructor HBaseConfiguration(Configuration) will override\n               hbase configurations if argumant is not an instance of\n               HBaseConfiguration (Put it back again).\n   HADOOP-2631 2443 breaks HTable.getStartKeys when there is more than one\n               table or table you are enumerating isn't the first table\n   Delete empty file: src/contrib/hbase/src/java/org/apache/hadoop/hbase/mapred/\n               TableOutputCollector.java per Nigel Daley\n\n  IMPROVEMENTS\n   HADOOP-2401 Add convenience put method that takes writable\n               (Johan Oskarsson via Stack)\n   HADOOP-2074 Simple switch to enable DEBUG level-logging in hbase\n   HADOOP-2088 Make hbase runnable in $HADOOP_HOME/build(/contrib/hbase)\n   HADOOP-2126 Use Bob Jenkins' hash for bloom filters\n   HADOOP-2157 Make Scanners implement Iterable\n   HADOOP-2176 Htable.deleteAll documentation is ambiguous\n   HADOOP-2139 (phase 1) Increase parallelism in region servers.\n   HADOOP-2267 [Hbase Shell] Change the prompt's title from 'hbase' to 'hql'.\n               (Edward Yoon via Stack)\n   HADOOP-2139 (phase 2) Make region server more event driven\n   HADOOP-2289 Useless efforts of looking for the non-existant table in select\n               command.\n               (Edward Yoon via Stack)\n   HADOOP-2257 Show a total of all requests and regions on the web ui\n               (Paul Saab via Stack)\n   HADOOP-2261 HTable.abort no longer throws exception if there is no active update.\n   HADOOP-2287 Make hbase unit tests take less time to complete.\n   HADOOP-2262 Retry n times instead of n**2 times.\n   HADOOP-1608 Relational Algrebra Operators\n               (Edward Yoon via Stack)\n   HADOOP-2198 HTable should have method to return table metadata\n   HADOOP-2296 hbase shell: phantom columns show up from select command\n   HADOOP-2297 System.exit() Handling in hbase shell jar command\n               (Edward Yoon via Stack)\n   HADOOP-2224 Add HTable.getRow(ROW, ts)\n               (Bryan Duxbury via Stack)\n   HADOOP-2339 Delete command with no WHERE clause\n               (Edward Yoon via Stack)\n   HADOOP-2299 Support inclusive scans (Bryan Duxbury via Stack)\n   HADOOP-2333 Client side retries happen at the wrong level\n   HADOOP-2357 Compaction cleanup; less deleting + prevent possible file leaks\n   HADOOP-2392 TestRegionServerExit has new failure mode since HADOOP-2338\n   HADOOP-2370 Allow column families with an unlimited number of versions\n               (Edward Yoon via Stack)\n   HADOOP-2047 Add an '--master=X' and '--html' command-line parameters to shell\n               (Edward Yoon via Stack)\n   HADOOP-2351 If select command returns no result, it doesn't need to show the\n               header information (Edward Yoon via Stack)\n   HADOOP-2285 Add being able to shutdown regionservers (Dennis Kubes via Stack)\n   HADOOP-2458 HStoreFile.writeSplitInfo should just call\n               HStoreFile.Reference.write\n   HADOOP-2471 Add reading/writing MapFile to PerformanceEvaluation suite\n   HADOOP-2522 Separate MapFile benchmark from PerformanceEvaluation\n               (Tom White via Stack)\n   HADOOP-2502 Insert/Select timestamp, Timestamp data type in HQL\n               (Edward Yoon via Stack)\n   HADOOP-2450 Show version (and svn revision) in hbase web ui\n   HADOOP-2472 Range selection using filter (Edward Yoon via Stack)\n   HADOOP-2548 Make TableMap and TableReduce generic\n               (Frederik Hedberg via Stack)\n   HADOOP-2557 Shell count function (Edward Yoon via Stack)\n   HADOOP-2589 Change an classes/package name from Shell to hql\n               (Edward Yoon via Stack)\n   HADOOP-2545 hbase rest server should be started with hbase-daemon.sh\n   HADOOP-2525 Same 2 lines repeated 11 million times in HMaster log upon\n               HMaster shutdown\n   HADOOP-2616 hbase not spliting when the total size of region reaches max\n               region size * 1.5\n   HADOOP-2643 Make migration tool smarter.\n\nRelease 0.15.1\nBranch 0.15\n\n  INCOMPATIBLE CHANGES\n    HADOOP-1931 Hbase scripts take --ARG=ARG_VALUE when should be like hadoop\n                and do ---ARG ARG_VALUE\n\n  NEW FEATURES\n    HADOOP-1768 FS command using Hadoop FsShell operations\n                (Edward Yoon via Stack)\n    HADOOP-1784 Delete: Fix scanners and gets so they work properly in presence\n                of deletes. Added a deleteAll to remove all cells equal to or\n                older than passed timestamp.  Fixed compaction so deleted cells\n                do not make it out into compacted output.  Ensure also that\n                versions > column max are dropped compacting.\n    HADOOP-1720 Addition of HQL (Hbase Query Language) support in Hbase Shell.\n                The old shell syntax has been replaced by HQL, a small SQL-like\n                set of operators, for creating, altering, dropping, inserting,\n                deleting, and selecting, etc., data in hbase.\n                (Inchul Song and Edward Yoon via Stack)\n    HADOOP-1913 Build a Lucene index on an HBase table\n                (Ning Li via Stack)\n    HADOOP-1957 Web UI with report on cluster state and basic browsing of tables\n\n  OPTIMIZATIONS\n\n  BUG FIXES\n    HADOOP-1527 Region server won't start because logdir exists\n    HADOOP-1723 If master asks region server to shut down, by-pass return of\n                shutdown message\n    HADOOP-1729 Recent renaming or META tables breaks hbase shell\n    HADOOP-1730 unexpected null value causes META scanner to exit (silently)\n    HADOOP-1747 On a cluster, on restart, regions multiply assigned\n    HADOOP-1776 Fix for sporadic compaction failures closing and moving\n                compaction result\n    HADOOP-1780 Regions are still being doubly assigned\n    HADOOP-1797 Fix NPEs in MetaScanner constructor\n    HADOOP-1799 Incorrect classpath in binary version of Hadoop\n    HADOOP-1805 Region server hang on exit\n    HADOOP-1785 TableInputFormat.TableRecordReader.next has a bug\n                (Ning Li via Stack)\n    HADOOP-1800 output should default utf8 encoding\n    HADOOP-1801 When hdfs is yanked out from under hbase, hbase should go down gracefully\n    HADOOP-1813 OOME makes zombie of region server\n    HADOOP-1814\tTestCleanRegionServerExit fails too often on Hudson\n    HADOOP-1820 Regionserver creates hlogs without bound\n                (reverted 2007/09/25) (Fixed 2007/09/30)\n    HADOOP-1821 Replace all String.getBytes() with String.getBytes(\"UTF-8\")\n    HADOOP-1832 listTables() returns duplicate tables\n    HADOOP-1834 Scanners ignore timestamp passed on creation\n    HADOOP-1847 Many HBase tests do not fail well.\n    HADOOP-1847 Many HBase tests do not fail well. (phase 2)\n    HADOOP-1870 Once file system failure has been detected, don't check it again\n                and get on with shutting down the hbase cluster.\n    HADOOP-1888 NullPointerException in HMemcacheScanner (reprise)\n    HADOOP-1903 Possible data loss if Exception happens between snapshot and\n                flush to disk.\n    HADOOP-1920 Wrapper scripts broken when hadoop in one location and hbase in\n                another\n    HADOOP-1923, HADOOP-1924 a) tests fail sporadically because set up and tear\n                 down is inconsistent b) TestDFSAbort failed in nightly #242\n    HADOOP-1929 Add hbase-default.xml to hbase jar\n    HADOOP-1941 StopRowFilter throws NPE when passed null row\n    HADOOP-1966 Make HBase unit tests more reliable in the Hudson environment.\n    HADOOP-1975 HBase tests failing with java.lang.NumberFormatException\n    HADOOP-1990 Regression test instability affects nightly and patch builds\n    HADOOP-1996 TestHStoreFile fails on windows if run multiple times\n    HADOOP-1937 When the master times out a region server's lease, it is too\n                aggressive in reclaiming the server's log.\n    HADOOP-2004 webapp hql formatting bugs\n    HADOOP_2011 Make hbase daemon scripts take args in same order as hadoop\n                daemon scripts\n    HADOOP-2017 TestRegionServerAbort failure in patch build #903 and\n                nightly #266\n    HADOOP-2029 TestLogRolling fails too often in patch and nightlies\n    HADOOP-2038 TestCleanRegionExit failed in patch build #927\n\n  IMPROVEMENTS\n    HADOOP-1737 Make HColumnDescriptor data publically members settable\n    HADOOP-1746 Clean up findbugs warnings\n    HADOOP-1757 Bloomfilters: single argument constructor, use enum for bloom\n                filter types\n    HADOOP-1760 Use new MapWritable and SortedMapWritable classes from\n                org.apache.hadoop.io\n    HADOOP-1793 (Phase 1) Remove TestHClient (Phase2) remove HClient.\n    HADOOP-1794 Remove deprecated APIs\n    HADOOP-1802 Startup scripts should wait until hdfs as cleared 'safe mode'\n    HADOOP-1833 bin/stop_hbase.sh returns before it completes\n                (Izaak Rubin via Stack)\n    HADOOP-1835 Updated Documentation for HBase setup/installation\n                (Izaak Rubin via Stack)\n    HADOOP-1868 Make default configuration more responsive\n    HADOOP-1884 Remove useless debugging log messages from hbase.mapred\n    HADOOP-1856 Add Jar command to hbase shell using Hadoop RunJar util\n                (Edward Yoon via Stack)\n    HADOOP-1928 Have master pass the regionserver the filesystem to use\n    HADOOP-1789 Output formatting\n    HADOOP-1960 If a region server cannot talk to the master before its lease\n                times out, it should shut itself down\n    HADOOP-2035 Add logo to webapps\n\n\nBelow are the list of changes before 2007-08-18\n\n  1. HADOOP-1384. HBase omnibus patch. (jimk, Vuk Ercegovac, and Michael Stack)\n  2. HADOOP-1402. Fix javadoc warnings in hbase contrib. (Michael Stack)\n  3. HADOOP-1404. HBase command-line shutdown failing (Michael Stack)\n  4. HADOOP-1397. Replace custom hbase locking with\n     java.util.concurrent.locks.ReentrantLock (Michael Stack)\n  5. HADOOP-1403. HBase reliability - make master and region server more fault\n     tolerant.\n  6. HADOOP-1418. HBase miscellaneous: unit test for HClient, client to do\n     'Performance Evaluation', etc.\n  7. HADOOP-1420, HADOOP-1423. Findbugs changes, remove reference to removed\n     class HLocking.\n  8. HADOOP-1424. TestHBaseCluster fails with IllegalMonitorStateException. Fix\n     regression introduced by HADOOP-1397.\n  9. HADOOP-1426. Make hbase scripts executable + add test classes to CLASSPATH.\n 10. HADOOP-1430. HBase shutdown leaves regionservers up.\n 11. HADOOP-1392. Part1: includes create/delete table; enable/disable table;\n     add/remove column.\n 12. HADOOP-1392. Part2: includes table compaction by merging adjacent regions\n     that have shrunk in size.\n 13. HADOOP-1445 Support updates across region splits and compactions\n 14. HADOOP-1460 On shutdown IOException with complaint 'Cannot cancel lease\n     that is not held'\n 15. HADOOP-1421 Failover detection, split log files.\n     For the files modified, also clean up javadoc, class, field and method\n     visibility (HADOOP-1466)\n 16. HADOOP-1479 Fix NPE in HStore#get if store file only has keys < passed key.\n 17. HADOOP-1476 Distributed version of 'Performance Evaluation' script\n 18. HADOOP-1469 Asychronous table creation\n 19. HADOOP-1415 Integrate BSD licensed bloom filter implementation.\n 20. HADOOP-1465 Add cluster stop/start scripts for hbase\n 21. HADOOP-1415 Provide configurable per-column bloom filters - part 2.\n 22. HADOOP-1498. Replace boxed types with primitives in many places.\n 23. HADOOP-1509.  Made methods/inner classes in HRegionServer and HClient protected\n     instead of private for easier extension. Also made HRegion and HRegionInfo public too.\n     Added an hbase-default.xml property for specifying what HRegionInterface extension to use\n     for proxy server connection. (James Kennedy via Jim Kellerman)\n 24. HADOOP-1534. [hbase] Memcache scanner fails if start key not present\n 25. HADOOP-1537. Catch exceptions in testCleanRegionServerExit so we can see\n     what is failing.\n 26. HADOOP-1543 [hbase] Add HClient.tableExists\n 27. HADOOP-1519 [hbase] map/reduce interface for HBase.  (Vuk Ercegovac and\n     Jim Kellerman)\n 28. HADOOP-1523 Hung region server waiting on write locks\n 29. HADOOP-1560 NPE in MiniHBaseCluster on Windows\n 30. HADOOP-1531 Add RowFilter to HRegion.HScanner\n     Adds a row filtering interface and two implemenentations: A page scanner,\n     and a regex row/column-data matcher. (James Kennedy via Stack)\n 31. HADOOP-1566 Key-making utility\n 32. HADOOP-1415 Provide configurable per-column bloom filters.\n     HADOOP-1466 Clean up visibility and javadoc issues in HBase.\n 33. HADOOP-1538 Provide capability for client specified time stamps in HBase\n     HADOOP-1466 Clean up visibility and javadoc issues in HBase.\n 34. HADOOP-1589 Exception handling in HBase is broken over client server connections\n 35. HADOOP-1375 a simple parser for hbase (Edward Yoon via Stack)\n 36. HADOOP-1600 Update license in HBase code\n 37. HADOOP-1589 Exception handling in HBase is broken over client server\n 38. HADOOP-1574 Concurrent creates of a table named 'X' all succeed\n 39. HADOOP-1581 Un-openable tablename bug\n 40. HADOOP-1607 [shell] Clear screen command (Edward Yoon via Stack)\n 41. HADOOP-1614 [hbase] HClient does not protect itself from simultaneous updates\n 42. HADOOP-1468 Add HBase batch update to reduce RPC overhead\n 43. HADOOP-1616 Sporadic TestTable failures\n 44. HADOOP-1615 Replacing thread notification-based queue with\n     java.util.concurrent.BlockingQueue in HMaster, HRegionServer\n 45. HADOOP-1606 Updated implementation of RowFilterSet, RowFilterInterface\n     (Izaak Rubin via Stack)\n 46. HADOOP-1579 Add new WhileMatchRowFilter and StopRowFilter filters\n    (Izaak Rubin via Stack)\n 47. HADOOP-1637 Fix to HScanner to Support Filters, Add Filter Tests to\n     TestScanner2 (Izaak Rubin via Stack)\n 48. HADOOP-1516 HClient fails to readjust when ROOT or META redeployed on new\n     region server\n 49. HADOOP-1646 RegionServer OOME's under sustained, substantial loading by\n     10 concurrent clients\n 50. HADOOP-1468 Add HBase batch update to reduce RPC overhead (restrict batches\n     to a single row at a time)\n 51. HADOOP-1528 HClient for multiple tables (phase 1) (James Kennedy & JimK)\n 52. HADOOP-1528 HClient for multiple tables (phase 2) all HBase client side code\n     (except TestHClient and HBaseShell) have been converted to use the new client\n     side objects (HTable/HBaseAdmin/HConnection) instead of HClient.\n 53. HADOOP-1528 HClient for multiple tables - expose close table function\n 54. HADOOP-1466 Clean up warnings, visibility and javadoc issues in HBase.\n 55. HADOOP-1662 Make region splits faster\n 56. HADOOP-1678 On region split, master should designate which host should\n     serve daughter splits. Phase 1: Master balances load for new regions and\n     when a region server fails.\n 57. HADOOP-1678 On region split, master should designate which host should\n     serve daughter splits. Phase 2: Master assigns children of split region\n     instead of HRegionServer serving both children.\n 58. HADOOP-1710 All updates should be batch updates\n 59. HADOOP-1711 HTable API should use interfaces instead of concrete classes as\n     method parameters and return values\n 60. HADOOP-1644 Compactions should not block updates\n 60. HADOOP-1672 HBase Shell should use new client classes\n     (Edward Yoon via Stack).\n 61. HADOOP-1709 Make HRegionInterface more like that of HTable\n     HADOOP-1725 Client find of table regions should not include offlined, split parents\n=\n"
        },
        {
          "name": "LICENSE.txt",
          "type": "blob",
          "size": 38.92578125,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n----\nThis project bundles portions of the 'JQuery' project under the terms of the MIT license.\n\n    Copyright 2012 jQuery Foundation and other contributors\n    http://jquery.com/\n\n    Permission is hereby granted, free of charge, to any person obtaining\n    a copy of this software and associated documentation files (the\n    \"Software\"), to deal in the Software without restriction, including\n    without limitation the rights to use, copy, modify, merge, publish,\n    distribute, sublicense, and/or sell copies of the Software, and to\n    permit persons to whom the Software is furnished to do so, subject to\n    the following conditions:\n\n    The above copyright notice and this permission notice shall be\n    included in all copies or substantial portions of the Software.\n\n    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n    EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n    MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n    LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n    OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n    WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n----\nThis project bundles a derivative of portions of the 'Asciidoctor' project\nunder the terms of the MIT license.\n\n    The MIT License\n    Copyright (C) 2012-2015 Dan Allen, Ryan Waldron and the Asciidoctor Project\n\n    Permission is hereby granted, free of charge, to any person obtaining a copy\n    of this software and associated documentation files (the \"Software\"), to deal\n    in the Software without restriction, including without limitation the rights\n    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n    copies of the Software, and to permit persons to whom the Software is\n    furnished to do so, subject to the following conditions:\n\n    The above copyright notice and this permission notice shall be included in\n    all copies or substantial portions of the Software.\n\n    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n    THE SOFTWARE.\n\n----\nThis project incorporates portions of the 'Protocol Buffers' project available\nunder a '3-clause BSD' license.\n\n  Copyright 2008, Google Inc.\n  All rights reserved.\n\n  Redistribution and use in source and binary forms, with or without\n  modification, are permitted provided that the following conditions are\n  met:\n\n      * Redistributions of source code must retain the above copyright\n  notice, this list of conditions and the following disclaimer.\n      * Redistributions in binary form must reproduce the above\n  copyright notice, this list of conditions and the following disclaimer\n  in the documentation and/or other materials provided with the\n  distribution.\n      * Neither the name of Google Inc. nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\n  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n  \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n  Code generated by the Protocol Buffer compiler is owned by the owner\n  of the input file used when generating it.  This code is not\n  standalone and requires a support library to be linked with it.  This\n  support library is itself covered by the above license.\n\n----\nThis project bundles a derivative image for our Orca Logo. This image is\navailable under the Creative Commons By Attribution 3.0 License.\n\n    Creative Commons Legal Code\n\n    Attribution 3.0 Unported\n\n        CREATIVE COMMONS CORPORATION IS NOT A LAW FIRM AND DOES NOT PROVIDE\n        LEGAL SERVICES. DISTRIBUTION OF THIS LICENSE DOES NOT CREATE AN\n        ATTORNEY-CLIENT RELATIONSHIP. CREATIVE COMMONS PROVIDES THIS\n        INFORMATION ON AN \"AS-IS\" BASIS. CREATIVE COMMONS MAKES NO WARRANTIES\n        REGARDING THE INFORMATION PROVIDED, AND DISCLAIMS LIABILITY FOR\n        DAMAGES RESULTING FROM ITS USE.\n\n    License\n\n    THE WORK (AS DEFINED BELOW) IS PROVIDED UNDER THE TERMS OF THIS CREATIVE\n    COMMONS PUBLIC LICENSE (\"CCPL\" OR \"LICENSE\"). THE WORK IS PROTECTED BY\n    COPYRIGHT AND/OR OTHER APPLICABLE LAW. ANY USE OF THE WORK OTHER THAN AS\n    AUTHORIZED UNDER THIS LICENSE OR COPYRIGHT LAW IS PROHIBITED.\n\n    BY EXERCISING ANY RIGHTS TO THE WORK PROVIDED HERE, YOU ACCEPT AND AGREE\n    TO BE BOUND BY THE TERMS OF THIS LICENSE. TO THE EXTENT THIS LICENSE MAY\n    BE CONSIDERED TO BE A CONTRACT, THE LICENSOR GRANTS YOU THE RIGHTS\n    CONTAINED HERE IN CONSIDERATION OF YOUR ACCEPTANCE OF SUCH TERMS AND\n    CONDITIONS.\n\n    1. Definitions\n\n     a. \"Adaptation\" means a work based upon the Work, or upon the Work and\n        other pre-existing works, such as a translation, adaptation,\n        derivative work, arrangement of music or other alterations of a\n        literary or artistic work, or phonogram or performance and includes\n        cinematographic adaptations or any other form in which the Work may be\n        recast, transformed, or adapted including in any form recognizably\n        derived from the original, except that a work that constitutes a\n        Collection will not be considered an Adaptation for the purpose of\n        this License. For the avoidance of doubt, where the Work is a musical\n        work, performance or phonogram, the synchronization of the Work in\n        timed-relation with a moving image (\"synching\") will be considered an\n        Adaptation for the purpose of this License.\n     b. \"Collection\" means a collection of literary or artistic works, such as\n        encyclopedias and anthologies, or performances, phonograms or\n        broadcasts, or other works or subject matter other than works listed\n        in Section 1(f) below, which, by reason of the selection and\n        arrangement of their contents, constitute intellectual creations, in\n        which the Work is included in its entirety in unmodified form along\n        with one or more other contributions, each constituting separate and\n        independent works in themselves, which together are assembled into a\n        collective whole. A work that constitutes a Collection will not be\n        considered an Adaptation (as defined above) for the purposes of this\n        License.\n     c. \"Distribute\" means to make available to the public the original and\n        copies of the Work or Adaptation, as appropriate, through sale or\n        other transfer of ownership.\n     d. \"Licensor\" means the individual, individuals, entity or entities that\n        offer(s) the Work under the terms of this License.\n     e. \"Original Author\" means, in the case of a literary or artistic work,\n        the individual, individuals, entity or entities who created the Work\n        or if no individual or entity can be identified, the publisher; and in\n        addition (i) in the case of a performance the actors, singers,\n        musicians, dancers, and other persons who act, sing, deliver, declaim,\n        play in, interpret or otherwise perform literary or artistic works or\n        expressions of folklore; (ii) in the case of a phonogram the producer\n        being the person or legal entity who first fixes the sounds of a\n        performance or other sounds; and, (iii) in the case of broadcasts, the\n        organization that transmits the broadcast.\n     f. \"Work\" means the literary and/or artistic work offered under the terms\n        of this License including without limitation any production in the\n        literary, scientific and artistic domain, whatever may be the mode or\n        form of its expression including digital form, such as a book,\n        pamphlet and other writing; a lecture, address, sermon or other work\n        of the same nature; a dramatic or dramatico-musical work; a\n        choreographic work or entertainment in dumb show; a musical\n        composition with or without words; a cinematographic work to which are\n        assimilated works expressed by a process analogous to cinematography;\n        a work of drawing, painting, architecture, sculpture, engraving or\n        lithography; a photographic work to which are assimilated works\n        expressed by a process analogous to photography; a work of applied\n        art; an illustration, map, plan, sketch or three-dimensional work\n        relative to geography, topography, architecture or science; a\n        performance; a broadcast; a phonogram; a compilation of data to the\n        extent it is protected as a copyrightable work; or a work performed by\n        a variety or circus performer to the extent it is not otherwise\n        considered a literary or artistic work.\n     g. \"You\" means an individual or entity exercising rights under this\n        License who has not previously violated the terms of this License with\n        respect to the Work, or who has received express permission from the\n        Licensor to exercise rights under this License despite a previous\n        violation.\n     h. \"Publicly Perform\" means to perform public recitations of the Work and\n        to communicate to the public those public recitations, by any means or\n        process, including by wire or wireless means or public digital\n        performances; to make available to the public Works in such a way that\n        members of the public may access these Works from a place and at a\n        place individually chosen by them; to perform the Work to the public\n        by any means or process and the communication to the public of the\n        performances of the Work, including by public digital performance; to\n        broadcast and rebroadcast the Work by any means including signs,\n        sounds or images.\n     i. \"Reproduce\" means to make copies of the Work by any means including\n        without limitation by sound or visual recordings and the right of\n        fixation and reproducing fixations of the Work, including storage of a\n        protected performance or phonogram in digital form or other electronic\n        medium.\n\n    2. Fair Dealing Rights. Nothing in this License is intended to reduce,\n    limit, or restrict any uses free from copyright or rights arising from\n    limitations or exceptions that are provided for in connection with the\n    copyright protection under copyright law or other applicable laws.\n\n    3. License Grant. Subject to the terms and conditions of this License,\n    Licensor hereby grants You a worldwide, royalty-free, non-exclusive,\n    perpetual (for the duration of the applicable copyright) license to\n    exercise the rights in the Work as stated below:\n\n     a. to Reproduce the Work, to incorporate the Work into one or more\n        Collections, and to Reproduce the Work as incorporated in the\n        Collections;\n     b. to create and Reproduce Adaptations provided that any such Adaptation,\n        including any translation in any medium, takes reasonable steps to\n        clearly label, demarcate or otherwise identify that changes were made\n        to the original Work. For example, a translation could be marked \"The\n        original work was translated from English to Spanish,\" or a\n        modification could indicate \"The original work has been modified.\";\n     c. to Distribute and Publicly Perform the Work including as incorporated\n        in Collections; and,\n     d. to Distribute and Publicly Perform Adaptations.\n     e. For the avoidance of doubt:\n\n         i. Non-waivable Compulsory License Schemes. In those jurisdictions in\n            which the right to collect royalties through any statutory or\n            compulsory licensing scheme cannot be waived, the Licensor\n            reserves the exclusive right to collect such royalties for any\n            exercise by You of the rights granted under this License;\n        ii. Waivable Compulsory License Schemes. In those jurisdictions in\n            which the right to collect royalties through any statutory or\n            compulsory licensing scheme can be waived, the Licensor waives the\n            exclusive right to collect such royalties for any exercise by You\n            of the rights granted under this License; and,\n       iii. Voluntary License Schemes. The Licensor waives the right to\n            collect royalties, whether individually or, in the event that the\n            Licensor is a member of a collecting society that administers\n            voluntary licensing schemes, via that society, from any exercise\n            by You of the rights granted under this License.\n\n    The above rights may be exercised in all media and formats whether now\n    known or hereafter devised. The above rights include the right to make\n    such modifications as are technically necessary to exercise the rights in\n    other media and formats. Subject to Section 8(f), all rights not expressly\n    granted by Licensor are hereby reserved.\n\n    4. Restrictions. The license granted in Section 3 above is expressly made\n    subject to and limited by the following restrictions:\n\n     a. You may Distribute or Publicly Perform the Work only under the terms\n        of this License. You must include a copy of, or the Uniform Resource\n        Identifier (URI) for, this License with every copy of the Work You\n        Distribute or Publicly Perform. You may not offer or impose any terms\n        on the Work that restrict the terms of this License or the ability of\n        the recipient of the Work to exercise the rights granted to that\n        recipient under the terms of the License. You may not sublicense the\n        Work. You must keep intact all notices that refer to this License and\n        to the disclaimer of warranties with every copy of the Work You\n        Distribute or Publicly Perform. When You Distribute or Publicly\n        Perform the Work, You may not impose any effective technological\n        measures on the Work that restrict the ability of a recipient of the\n        Work from You to exercise the rights granted to that recipient under\n        the terms of the License. This Section 4(a) applies to the Work as\n        incorporated in a Collection, but this does not require the Collection\n        apart from the Work itself to be made subject to the terms of this\n        License. If You create a Collection, upon notice from any Licensor You\n        must, to the extent practicable, remove from the Collection any credit\n        as required by Section 4(b), as requested. If You create an\n        Adaptation, upon notice from any Licensor You must, to the extent\n        practicable, remove from the Adaptation any credit as required by\n        Section 4(b), as requested.\n     b. If You Distribute, or Publicly Perform the Work or any Adaptations or\n        Collections, You must, unless a request has been made pursuant to\n        Section 4(a), keep intact all copyright notices for the Work and\n        provide, reasonable to the medium or means You are utilizing: (i) the\n        name of the Original Author (or pseudonym, if applicable) if supplied,\n        and/or if the Original Author and/or Licensor designate another party\n        or parties (e.g., a sponsor institute, publishing entity, journal) for\n        attribution (\"Attribution Parties\") in Licensor's copyright notice,\n        terms of service or by other reasonable means, the name of such party\n        or parties; (ii) the title of the Work if supplied; (iii) to the\n        extent reasonably practicable, the URI, if any, that Licensor\n        specifies to be associated with the Work, unless such URI does not\n        refer to the copyright notice or licensing information for the Work;\n        and (iv) , consistent with Section 3(b), in the case of an Adaptation,\n        a credit identifying the use of the Work in the Adaptation (e.g.,\n        \"French translation of the Work by Original Author,\" or \"Screenplay\n        based on original Work by Original Author\"). The credit required by\n        this Section 4 (b) may be implemented in any reasonable manner;\n        provided, however, that in the case of a Adaptation or Collection, at\n        a minimum such credit will appear, if a credit for all contributing\n        authors of the Adaptation or Collection appears, then as part of these\n        credits and in a manner at least as prominent as the credits for the\n        other contributing authors. For the avoidance of doubt, You may only\n        use the credit required by this Section for the purpose of attribution\n        in the manner set out above and, by exercising Your rights under this\n        License, You may not implicitly or explicitly assert or imply any\n        connection with, sponsorship or endorsement by the Original Author,\n        Licensor and/or Attribution Parties, as appropriate, of You or Your\n        use of the Work, without the separate, express prior written\n        permission of the Original Author, Licensor and/or Attribution\n        Parties.\n     c. Except as otherwise agreed in writing by the Licensor or as may be\n        otherwise permitted by applicable law, if You Reproduce, Distribute or\n        Publicly Perform the Work either by itself or as part of any\n        Adaptations or Collections, You must not distort, mutilate, modify or\n        take other derogatory action in relation to the Work which would be\n        prejudicial to the Original Author's honor or reputation. Licensor\n        agrees that in those jurisdictions (e.g. Japan), in which any exercise\n        of the right granted in Section 3(b) of this License (the right to\n        make Adaptations) would be deemed to be a distortion, mutilation,\n        modification or other derogatory action prejudicial to the Original\n        Author's honor and reputation, the Licensor will waive or not assert,\n        as appropriate, this Section, to the fullest extent permitted by the\n        applicable national law, to enable You to reasonably exercise Your\n        right under Section 3(b) of this License (right to make Adaptations)\n        but not otherwise.\n\n    5. Representations, Warranties and Disclaimer\n\n    UNLESS OTHERWISE MUTUALLY AGREED TO BY THE PARTIES IN WRITING, LICENSOR\n    OFFERS THE WORK AS-IS AND MAKES NO REPRESENTATIONS OR WARRANTIES OF ANY\n    KIND CONCERNING THE WORK, EXPRESS, IMPLIED, STATUTORY OR OTHERWISE,\n    INCLUDING, WITHOUT LIMITATION, WARRANTIES OF TITLE, MERCHANTIBILITY,\n    FITNESS FOR A PARTICULAR PURPOSE, NONINFRINGEMENT, OR THE ABSENCE OF\n    LATENT OR OTHER DEFECTS, ACCURACY, OR THE PRESENCE OF ABSENCE OF ERRORS,\n    WHETHER OR NOT DISCOVERABLE. SOME JURISDICTIONS DO NOT ALLOW THE EXCLUSION\n    OF IMPLIED WARRANTIES, SO SUCH EXCLUSION MAY NOT APPLY TO YOU.\n\n    6. Limitation on Liability. EXCEPT TO THE EXTENT REQUIRED BY APPLICABLE\n    LAW, IN NO EVENT WILL LICENSOR BE LIABLE TO YOU ON ANY LEGAL THEORY FOR\n    ANY SPECIAL, INCIDENTAL, CONSEQUENTIAL, PUNITIVE OR EXEMPLARY DAMAGES\n    ARISING OUT OF THIS LICENSE OR THE USE OF THE WORK, EVEN IF LICENSOR HAS\n    BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\n\n    7. Termination\n\n     a. This License and the rights granted hereunder will terminate\n        automatically upon any breach by You of the terms of this License.\n        Individuals or entities who have received Adaptations or Collections\n        from You under this License, however, will not have their licenses\n        terminated provided such individuals or entities remain in full\n        compliance with those licenses. Sections 1, 2, 5, 6, 7, and 8 will\n        survive any termination of this License.\n     b. Subject to the above terms and conditions, the license granted here is\n        perpetual (for the duration of the applicable copyright in the Work).\n        Notwithstanding the above, Licensor reserves the right to release the\n        Work under different license terms or to stop distributing the Work at\n        any time; provided, however that any such election will not serve to\n        withdraw this License (or any other license that has been, or is\n        required to be, granted under the terms of this License), and this\n        License will continue in full force and effect unless terminated as\n        stated above.\n\n    8. Miscellaneous\n\n     a. Each time You Distribute or Publicly Perform the Work or a Collection,\n        the Licensor offers to the recipient a license to the Work on the same\n        terms and conditions as the license granted to You under this License.\n     b. Each time You Distribute or Publicly Perform an Adaptation, Licensor\n        offers to the recipient a license to the original Work on the same\n        terms and conditions as the license granted to You under this License.\n     c. If any provision of this License is invalid or unenforceable under\n        applicable law, it shall not affect the validity or enforceability of\n        the remainder of the terms of this License, and without further action\n        by the parties to this agreement, such provision shall be reformed to\n        the minimum extent necessary to make such provision valid and\n        enforceable.\n     d. No term or provision of this License shall be deemed waived and no\n        breach consented to unless such waiver or consent shall be in writing\n        and signed by the party to be charged with such waiver or consent.\n     e. This License constitutes the entire agreement between the parties with\n        respect to the Work licensed here. There are no understandings,\n        agreements or representations with respect to the Work not specified\n        here. Licensor shall not be bound by any additional provisions that\n        may appear in any communication from You. This License may not be\n        modified without the mutual written agreement of the Licensor and You.\n     f. The rights granted under, and the subject matter referenced, in this\n        License were drafted utilizing the terminology of the Berne Convention\n        for the Protection of Literary and Artistic Works (as amended on\n        September 28, 1979), the Rome Convention of 1961, the WIPO Copyright\n        Treaty of 1996, the WIPO Performances and Phonograms Treaty of 1996\n        and the Universal Copyright Convention (as revised on July 24, 1971).\n        These rights and subject matter take effect in the relevant\n        jurisdiction in which the License terms are sought to be enforced\n        according to the corresponding provisions of the implementation of\n        those treaty provisions in the applicable national law. If the\n        standard suite of rights granted under applicable copyright law\n        includes additional rights not granted under this License, such\n        additional rights are deemed to be included in the License; this\n        License is not intended to restrict the license of any rights under\n        applicable law.\n\n\n    Creative Commons Notice\n\n        Creative Commons is not a party to this License, and makes no warranty\n        whatsoever in connection with the Work. Creative Commons will not be\n        liable to You or any party on any legal theory for any damages\n        whatsoever, including without limitation any general, special,\n        incidental or consequential damages arising in connection to this\n        license. Notwithstanding the foregoing two (2) sentences, if Creative\n        Commons has expressly identified itself as the Licensor hereunder, it\n        shall have all rights and obligations of Licensor.\n\n        Except for the limited purpose of indicating to the public that the\n        Work is licensed under the CCPL, Creative Commons does not authorize\n        the use by either party of the trademark \"Creative Commons\" or any\n        related trademark or logo of Creative Commons without the prior\n        written consent of Creative Commons. Any permitted use will be in\n        compliance with Creative Commons' then-current trademark usage\n        guidelines, as may be published on its website or otherwise made\n        available upon request from time to time. For the avoidance of doubt,\n        this trademark restriction does not form part of this License.\n\n        Creative Commons may be contacted at https://creativecommons.org/.\n\n----\nThis project incorporates portions of the 'Ruby' project available\nunder a '2-clause BSD' license.\n\n  Copyright (C) 1993-2013 Yukihiro Matsumoto. All rights reserved.\n\n  Redistribution and use in source and binary forms, with or without\n  modification, are permitted provided that the following conditions\n  are met:\n  1. Redistributions of source code must retain the above copyright\n  notice, this list of conditions and the following disclaimer.\n  2. Redistributions in binary form must reproduce the above copyright\n  notice, this list of conditions and the following disclaimer in the\n  documentation and/or other materials provided with the distribution.\n\n  THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND\n  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n  ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE\n  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS\n  OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n  HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n  LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n  OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n  SUCH DAMAGE.\n\n----\nThis project bundles a copy of the Vega minified javascript library version\n5.24.0, the Vega-Lite minified javascript library version 5.6.1, and the\nVega-Embed minified javascript library version 6.21.3. All three are\navailable under the following '3-clause BSD' license.\n\nCopyright (c) 2015-2023, University of Washington Interactive Data Lab\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its contributors\n  may be used to endorse or promote products derived from this software\n  without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "NOTICE.txt",
          "type": "blob",
          "size": 1.5517578125,
          "content": "Apache HBase\nCopyright 2007-2022 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n--\nThis product incorporates portions of the 'Hadoop' project\n\nCopyright 2007-2009 The Apache Software Foundation\n\nLicensed under the Apache License v2.0\n--\nOur Orca logo we got here: http://www.vectorfree.com/jumping-orca\nIt is licensed Creative Commons Attribution 3.0.\nSee https://creativecommons.org/licenses/by/3.0/us/\nWe changed the logo by stripping the colored background, inverting\nit and then rotating it some.\n\nLater we found that vectorfree.com image is not properly licensed.\nThe original is owned by vectorportal.com. The original was\nrelicensed so we could use it as Creative Commons Attribution 3.0.\nThe license is bundled with the download available here:\nhttp://www.vectorportal.com/subcategory/205/KILLER-WHALE-FREE-VECTOR.eps/ifile/9136/detailtest.asp\n--\nThis product includes portions of the Bootstrap project v5.3.3\n\nCopyright 2011-2024 The Bootstrap Authors\n\nLicensed under the MIT license\n\n--\nThis product includes portions of the Guava project v14 and v21, specifically\n'hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java'\n'hbase-common/src/main/java/org/apache/hadoop/hbase/util/ByteBufferUtils.java'\n\nCopyright (C) 2007 The Guava Authors\n\nLicensed under the Apache License, Version 2.0\n--\nThis product includes portions of Jetty project, specially\n'hbase-shaded-hbase-shaded-testing-util/src/main/resources/org/apache/hadoop/hbase/shaded/org/mortbay/jetty/webapp/webdefault.xml'\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 3.078125,
          "content": "<!--\nLicensed to the Apache Software Foundation (ASF) under one\nor more contributor license agreements.  See the NOTICE file\ndistributed with this work for additional information\nregarding copyright ownership.  The ASF licenses this file\nto you under the Apache License, Version 2.0 (the\n\"License\"); you may not use this file except in compliance\nwith the License.  You may obtain a copy of the License at\n\n  http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing,\nsoftware distributed under the License is distributed on an\n\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\nKIND, either express or implied.  See the License for the\nspecific language governing permissions and limitations\nunder the License.\n-->\n\n![hbase-logo](https://raw.githubusercontent.com/apache/hbase/master/src/site/resources/images/hbase_logo_with_orca_large.png)\n\n[Apache HBase](https://hbase.apache.org) is an open-source, distributed, versioned, column-oriented store modeled after Google' [Bigtable](https://research.google.com/archive/bigtable.html): A Distributed Storage System for Structured Data by Chang et al. Just as Bigtable leverages the distributed data storage provided by the Google File System, HBase provides Bigtable-like capabilities on top of [Apache Hadoop](https://hadoop.apache.org/).\n\n# Getting Start\nTo get started using HBase, the full documentation for this release can be found under the doc/ directory that accompanies this README. Using a browser, open the docs/index.html to view the project home page (or browse https://hbase.apache.org). The hbase '[book](https://hbase.apache.org/book.html)' has a 'quick start' section and is where you should being your exploration of the hbase project.\n\nThe latest HBase can be downloaded from the [download page](https://hbase.apache.org/downloads.html).\n\nWe use mailing lists to send notice and discuss. The mailing lists and archives are listed [here](http://hbase.apache.org/mail-lists.html)\n\nWe use the #hbase channel on the official [ASF Slack Workspace](https://the-asf.slack.com/) for real time questions and discussions. Please mail dev@hbase.apache.org to request an invite.\n\n# How to Contribute\nThe source code can be found at https://hbase.apache.org/source-repository.html\n\nThe HBase issue tracker is at https://hbase.apache.org/issue-tracking.html\n\nNotice that, the public registration for https://issues.apache.org/ has been disabled due to spam. If you want to contribute to HBase, please visit the [Request a jira account](https://selfserve.apache.org/jira-account.html) page to submit your request. Please make sure to select **hbase** as the '_ASF project you want to file a ticket_' so we can receive your request and process it.\n\n> **_NOTE:_** we need to process the requests manually so it may take sometime, for example, up to a week, for us to respond to your request.\n\n# About\nApache HBase is made available under the [Apache License, version 2.0](https://hbase.apache.org/license.html)\n\nThe HBase distribution includes cryptographic software. See the export control notice [here](https://hbase.apache.org/export_control.html).\n"
        },
        {
          "name": "bin",
          "type": "tree",
          "content": null
        },
        {
          "name": "conf",
          "type": "tree",
          "content": null
        },
        {
          "name": "dev-support",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-annotations",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-archetypes",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-assembly",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-asyncfs",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-backup",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-balancer",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-build-configuration",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-checkstyle",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-client",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-common",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-compression",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-dev-generate-classpath",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-diagnostics",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-endpoint",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-extensions",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-external-blockcache",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-hadoop-compat",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-hbtop",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-http",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-it",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-logging",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-mapreduce",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-metrics-api",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-metrics",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-procedure",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-protocol-shaded",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-replication",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-resource-bundle",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-rest",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-server",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-shaded",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-shell",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-testing-util",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-thrift",
          "type": "tree",
          "content": null
        },
        {
          "name": "hbase-zookeeper",
          "type": "tree",
          "content": null
        },
        {
          "name": "pom.xml",
          "type": "blob",
          "size": 185.2763671875,
          "content": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n  <!--\n/**\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n\n  ON MVN COMPILE NOT WORKING\n\n  If you wondering why 'mvn compile' does not work building HBase\n  (in particular, if you are doing it for the first time), instead do\n  'mvn package'.  If you are interested in the full story, see\n  https://issues.apache.org/jira/browse/HBASE-6795.\n\n-->\n  <modelVersion>4.0.0</modelVersion>\n  <parent>\n    <groupId>org.apache</groupId>\n    <artifactId>apache</artifactId>\n    <version>23</version>\n    <relativePath/>\n    <!-- no parent resolution -->\n  </parent>\n  <groupId>org.apache.hbase</groupId>\n  <artifactId>hbase</artifactId>\n  <version>${revision}</version>\n  <packaging>pom</packaging>\n  <name>Apache HBase</name>\n  <description>Apache HBase is the Hadoop database. Use it when you need\n    random, realtime read/write access to your Big Data.\n    This project's goal is the hosting of very large tables -- billions of rows X millions of columns -- atop clusters\n    of commodity hardware.</description>\n  <url>https://hbase.apache.org</url>\n  <inceptionYear>2007</inceptionYear>\n  <!-- Set here so we can consistently use the correct name, even on branches with\n       an ASF parent pom older than v15. Also uses the url from v18.\n    -->\n  <licenses>\n    <license>\n      <name>Apache License, Version 2.0</name>\n      <url>https://www.apache.org/licenses/LICENSE-2.0.txt</url>\n      <distribution>repo</distribution>\n    </license>\n  </licenses>\n  <developers>\n    <developer>\n      <id>achouhan</id>\n      <name>Abhishek Singh Chouhan</name>\n      <email>achouhan@apache.org</email>\n      <timezone>+5</timezone>\n    </developer>\n    <developer>\n      <id>acube123</id>\n      <name>Amitanand S. Aiyer</name>\n      <email>acube123@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>allan163</id>\n      <name>Allan Yang</name>\n      <email>allan163@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>andor</id>\n      <name>Andor Molnar</name>\n      <email>andor@apache.org</email>\n      <timezone>-5</timezone>\n    </developer>\n    <developer>\n      <id>appy</id>\n      <name>Apekshit Sharma</name>\n      <email>appy@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>anastasia</id>\n      <name>Anastasia Braginsky</name>\n      <email>anastasia@apache.org</email>\n      <timezone>+2</timezone>\n    </developer>\n    <developer>\n      <id>apurtell</id>\n      <name>Andrew Purtell</name>\n      <email>apurtell@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>anoopsamjohn</id>\n      <name>Anoop Sam John</name>\n      <email>anoopsamjohn@apache.org</email>\n      <timezone>+5</timezone>\n    </developer>\n    <developer>\n      <id>antonov</id>\n      <name>Mikhail Antonov</name>\n      <email>antonov@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>ashishsinghi</id>\n      <name>Ashish Singhi</name>\n      <email>ashishsinghi@apache.org</email>\n      <timezone>+5</timezone>\n    </developer>\n    <developer>\n      <id>ashu</id>\n      <name>Ashu Pachauri</name>\n      <email>ashu@apache.org</email>\n      <timezone>+5</timezone>\n    </developer>\n    <developer>\n      <id>bharathv</id>\n      <name>Bharath Vissapragada</name>\n      <email>bharathv@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>binlijin</id>\n      <name>Lijin Bin</name>\n      <email>binlijin@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>brfrn169</id>\n      <name>Toshihiro Suzuki</name>\n      <email>brfrn169@apache.org</email>\n      <timezone>+9</timezone>\n    </developer>\n    <developer>\n      <id>busbey</id>\n      <name>Sean Busbey</name>\n      <email>busbey@apache.org</email>\n      <timezone>-6</timezone>\n    </developer>\n    <developer>\n      <id>chenglei</id>\n      <name>Cheng Lei</name>\n      <email>chenglei@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>chenheng</id>\n      <name>Heng Chen</name>\n      <email>chenheng@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>chia7712</id>\n      <name>Chia-Ping Tsai</name>\n      <email>chia7712@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>ddas</id>\n      <name>Devaraj Das</name>\n      <email>ddas@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>dimaspivak</id>\n      <name>Dima Spivak</name>\n      <email>dimaspivak@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>dmeil</id>\n      <name>Doug Meil</name>\n      <email>dmeil@apache.org</email>\n      <timezone>-5</timezone>\n    </developer>\n    <developer>\n      <id>eclark</id>\n      <name>Elliott Clark</name>\n      <email>eclark@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>elserj</id>\n      <name>Josh Elser</name>\n      <email>elserj@apache.org</email>\n      <timezone>-5</timezone>\n    </developer>\n    <developer>\n      <id>enis</id>\n      <name>Enis Soztutar</name>\n      <email>enis@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>eshcar</id>\n      <name>Eshcar Hillel</name>\n      <email>eshcar@apache.org</email>\n      <timezone>+2</timezone>\n    </developer>\n    <developer>\n      <id>fenghh</id>\n      <name>Honghua Feng</name>\n      <email>fenghh@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>garyh</id>\n      <name>Gary Helmling</name>\n      <email>garyh@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>gchanan</id>\n      <name>Gregory Chanan</name>\n      <email>gchanan@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>gjacoby</id>\n      <name>Geoffrey Jacoby</name>\n      <email>gjacoby@apache.org</email>\n      <timezone>-5</timezone>\n    </developer>\n    <developer>\n      <id>gxcheng</id>\n      <name>Guangxu Cheng</name>\n      <email>gxcheng@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>haxiaolin</id>\n      <name>Xiaolin Ha</name>\n      <email>haxiaolin@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>huaxiangsun</id>\n      <name>Huaxiang Sun</name>\n      <email>huaxiangsun@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>huiruan</id>\n      <name>Hui Ruan</name>\n      <email>huiruan@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>jdcryans</id>\n      <name>Jean-Daniel Cryans</name>\n      <email>jdcryans@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>jeffreyz</id>\n      <name>Jeffrey Zhong</name>\n      <email>jeffreyz@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>jerryjch</id>\n      <name>Jing Chen (Jerry) He</name>\n      <email>jerryjch@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>jyates</id>\n      <name>Jesse Yates</name>\n      <email>jyates@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>jgray</id>\n      <name>Jonathan Gray</name>\n      <email>jgray@fb.com</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>jingchengdu</id>\n      <name>Jingcheng Du</name>\n      <email>jingchengdu@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>esteban</id>\n      <name>Esteban Gutierrez</name>\n      <email>esteban@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>janh</id>\n      <name>Jan Hentschel</name>\n      <email>janh@apache.org</email>\n      <timezone>+1</timezone>\n    </developer>\n    <developer>\n      <id>jmhsieh</id>\n      <name>Jonathan Hsieh</name>\n      <email>jmhsieh@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>jxiang</id>\n      <name>Jimmy Xiang</name>\n      <email>jxiang@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>kannan</id>\n      <name>Kannan Muthukkaruppan</name>\n      <email>kannan@fb.com</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>karthik</id>\n      <name>Karthik Ranganathan</name>\n      <email>kranganathan@fb.com</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>larsfrancke</id>\n      <name>Lars Francke</name>\n      <email>larsfrancke@apache.org</email>\n      <timezone>Europe/Berlin</timezone>\n    </developer>\n    <developer>\n      <id>larsgeorge</id>\n      <name>Lars George</name>\n      <email>larsgeorge@apache.org</email>\n      <timezone>+1</timezone>\n    </developer>\n    <developer>\n      <id>larsh</id>\n      <name>Lars Hofhansl</name>\n      <email>larsh@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>liangxie</id>\n      <name>Liang Xie</name>\n      <email>liangxie@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>liushaohui</id>\n      <name>Shaohui Liu</name>\n      <email>liushaohui@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>liyin</id>\n      <name>Liyin Tang</name>\n      <email>liyin.tang@fb.com</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>liyu</id>\n      <name>Yu Li</name>\n      <email>liyu@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>mbautin</id>\n      <name>Mikhail Bautin</name>\n      <email>mbautin@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>mbertozzi</id>\n      <name>Matteo Bertozzi</name>\n      <email>mbertozzi@apache.org</email>\n      <timezone>0</timezone>\n    </developer>\n    <developer>\n      <id>mdrob</id>\n      <name>Mike Drob</name>\n      <email>mdrob@apache.org</email>\n      <timezone>-5</timezone>\n    </developer>\n    <developer>\n      <id>meszibalu</id>\n      <name>Balazs Meszaros</name>\n      <email>meszibalu@apache.org</email>\n      <timezone>+1</timezone>\n    </developer>\n    <developer>\n      <id>misty</id>\n      <name>Misty Stanley-Jones</name>\n      <email>misty@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>ndimiduk</id>\n      <name>Nick Dimiduk</name>\n      <email>ndimiduk@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>nihaljain</id>\n      <name>Nihal Jain</name>\n      <email>nihaljain@apache.org</email>\n      <timezone>+5</timezone>\n    </developer>\n    <developer>\n      <id>niuyulin</id>\n      <name>Yulin Niu</name>\n      <email>niuyulin@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>nkeywal</id>\n      <name>Nicolas Liochon</name>\n      <email>nkeywal@apache.org</email>\n      <timezone>+1</timezone>\n    </developer>\n    <developer>\n      <id>nspiegelberg</id>\n      <name>Nicolas Spiegelberg</name>\n      <email>nspiegelberg@fb.com</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>octo47</id>\n      <name>Andrey Stepachev</name>\n      <email>octo47@gmail.com</email>\n      <timezone>0</timezone>\n    </developer>\n    <developer>\n      <id>openinx</id>\n      <name>Zheng Hu</name>\n      <email>openinx@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>pankajkumar</id>\n      <name>Pankaj Kumar</name>\n      <email>pankajkumar@apache.org</email>\n      <timezone>+5</timezone>\n    </developer>\n    <developer>\n      <id>psomogyi</id>\n      <name>Peter Somogyi</name>\n      <email>psomogyi@apache.org</email>\n      <timezone>+1</timezone>\n    </developer>\n    <developer>\n      <id>rajeshbabu</id>\n      <name>Rajeshbabu Chintaguntla</name>\n      <email>rajeshbabu@apache.org</email>\n      <timezone>+5</timezone>\n    </developer>\n    <developer>\n      <id>ramkrishna</id>\n      <name>Ramkrishna S Vasudevan</name>\n      <email>ramkrishna@apache.org</email>\n      <timezone>+5</timezone>\n    </developer>\n    <developer>\n      <id>rawson</id>\n      <name>Ryan Rawson</name>\n      <email>rawson@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>reidchan</id>\n      <name>Reid Chan</name>\n      <email>reidchan@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>shahrs87</id>\n      <name>Rushabh Shah</name>\n      <email>shahrs87@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>sakthi</id>\n      <name>Sakthi Vel</name>\n      <email>sakthi@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>rmattingly</id>\n      <name>Ray Mattingly</name>\n      <email>rmattingly@apache.org</email>\n      <timezone>-5</timezone>\n    </developer>\n    <developer>\n      <id>sershe</id>\n      <name>Sergey Shelukhin</name>\n      <email>sershe@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>ssrungarapu</id>\n      <name>Srikanth Srungarapu</name>\n      <email>ssrungarapu@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>stack</id>\n      <name>Michael Stack</name>\n      <email>stack@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>stoty</id>\n      <name>Istvan Toth</name>\n      <email>stoty@apache.org</email>\n      <timezone>+1</timezone>\n    </developer>\n    <developer>\n      <id>syuanjiang</id>\n      <name>Stephen Yuan Jiang</name>\n      <email>syuanjiang@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>taklwu</id>\n      <name>Tak-Lon (Stephen) Wu</name>\n      <email>taklwu@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>tedyu</id>\n      <name>Ted Yu</name>\n      <email>yuzhihong@gmail.com</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>tianhang</id>\n      <name>Tianhang Tang</name>\n      <email>tianhang@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>tianjy</id>\n      <email>tianjy@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>todd</id>\n      <name>Todd Lipcon</name>\n      <email>todd@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>toffer</id>\n      <name>Francis Liu</name>\n      <email>toffer@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>vikasv</id>\n      <name>Vikas Vishwakarma</name>\n      <email>vikasv@apache.org</email>\n      <timezone>+5</timezone>\n    </developer>\n    <developer>\n      <id>virag</id>\n      <name>Virag Kothari</name>\n      <email>virag@yahoo-inc.com</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>vjasani</id>\n      <name>Viraj Jasani</name>\n      <email>vjasani@apache.org</email>\n      <timezone>+5</timezone>\n    </developer>\n    <developer>\n      <id>water</id>\n      <name>Xiang Li</name>\n      <email>xiangli@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>wchevreuil</id>\n      <name>Wellington Chevreuil</name>\n      <email>wchevreuil@apache.org</email>\n      <timezone>0</timezone>\n    </developer>\n    <developer>\n      <id>weichiu</id>\n      <name>Wei-Chiu Chuang</name>\n      <email>weichiu@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>xucang</id>\n      <name>Xu Cang</name>\n      <email>xucang@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>yangzhe1991</id>\n      <name>Phil Yang</name>\n      <email>yangzhe1991@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>zghao</id>\n      <name>Guanghao Zhang</name>\n      <email>zghao@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>zhangduo</id>\n      <name>Duo Zhang</name>\n      <email>zhangduo@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>zhaobaiqiang</id>\n      <name>Baiqiang Zhao</name>\n      <email>zhaobaiqiang@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>zjushch</id>\n      <name>Chunhui Shen</name>\n      <email>zjushch@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>churro</id>\n      <name>Rahul Gidwani</name>\n      <email>churro@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>yiliang</id>\n      <name>Yi Liang</name>\n      <email>yiliang@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>zyork</id>\n      <name>Zach York</name>\n      <email>zyork@apache.org</email>\n      <timezone>-8</timezone>\n    </developer>\n    <developer>\n      <id>meiyi</id>\n      <name>Yi Mei</name>\n      <email>meiyi@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>wangzheng</id>\n      <name>Zheng (bsglz) Wang</name>\n      <email>wangzheng@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>sunxin</id>\n      <name>Xin Sun</name>\n      <email>sunxin@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>huangzhuoyue</id>\n      <name>Zhuoyue Huang</name>\n      <email>huangzhuoyue@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>xiaoyt</id>\n      <name>Yutong Xiao</name>\n      <email>xiaoyt@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n    <developer>\n      <id>bbeaudreault</id>\n      <name>Bryan Beaudreault</name>\n      <email>bbeaudreault@apache.org</email>\n      <timezone>-5</timezone>\n    </developer>\n    <developer>\n      <id>heliangjun</id>\n      <name>Liangjun He</name>\n      <email>heliangjun@apache.org</email>\n      <timezone>+8</timezone>\n    </developer>\n  </developers>\n  <mailingLists>\n    <mailingList>\n      <name>User List</name>\n      <subscribe>user-subscribe@hbase.apache.org</subscribe>\n      <unsubscribe>user-unsubscribe@hbase.apache.org</unsubscribe>\n      <post>user@hbase.apache.org</post>\n      <archive>https://lists.apache.org/list.html?user@hbase.apache.org</archive>\n      <otherArchives>\n        <otherArchive>https://dir.gmane.org/gmane.comp.java.hadoop.hbase.user</otherArchive>\n      </otherArchives>\n    </mailingList>\n    <mailingList>\n      <name>Developer List</name>\n      <subscribe>dev-subscribe@hbase.apache.org</subscribe>\n      <unsubscribe>dev-unsubscribe@hbase.apache.org</unsubscribe>\n      <post>dev@hbase.apache.org</post>\n      <archive>https://lists.apache.org/list.html?dev@hbase.apache.org</archive>\n      <otherArchives>\n        <otherArchive>https://dir.gmane.org/gmane.comp.java.hadoop.hbase.devel</otherArchive>\n      </otherArchives>\n    </mailingList>\n    <mailingList>\n      <name>Commits List</name>\n      <subscribe>commits-subscribe@hbase.apache.org</subscribe>\n      <unsubscribe>commits-unsubscribe@hbase.apache.org</unsubscribe>\n      <archive>https://lists.apache.org/list.html?commits@hbase.apache.org</archive>\n    </mailingList>\n    <mailingList>\n      <name>Issues List</name>\n      <subscribe>issues-subscribe@hbase.apache.org</subscribe>\n      <unsubscribe>issues-unsubscribe@hbase.apache.org</unsubscribe>\n      <archive>https://lists.apache.org/list.html?issues@hbase.apache.org</archive>\n    </mailingList>\n    <mailingList>\n      <name>Builds List</name>\n      <subscribe>builds-subscribe@hbase.apache.org</subscribe>\n      <unsubscribe>builds-unsubscribe@hbase.apache.org</unsubscribe>\n      <archive>https://lists.apache.org/list.html?builds@hbase.apache.org</archive>\n    </mailingList>\n    <mailingList>\n      <name>User (ZH) List</name>\n      <subscribe>user-zh-subscribe@hbase.apache.org</subscribe>\n      <unsubscribe>user-zh-unsubscribe@hbase.apache.org</unsubscribe>\n      <post>user-zh@hbase.apache.org</post>\n      <archive>https://lists.apache.org/list.html?user-zh@hbase.apache.org</archive>\n    </mailingList>\n  </mailingLists>\n\n  <modules>\n    <module>hbase-build-configuration</module>\n    <module>hbase-replication</module>\n    <module>hbase-balancer</module>\n    <module>hbase-mapreduce</module>\n    <module>hbase-diagnostics</module>\n    <module>hbase-resource-bundle</module>\n    <module>hbase-http</module>\n    <module>hbase-server</module>\n    <module>hbase-thrift</module>\n    <module>hbase-shell</module>\n    <module>hbase-protocol-shaded</module>\n    <module>hbase-client</module>\n    <module>hbase-hadoop-compat</module>\n    <module>hbase-common</module>\n    <module>hbase-procedure</module>\n    <module>hbase-endpoint</module>\n    <module>hbase-it</module>\n    <module>hbase-examples</module>\n    <module>hbase-assembly</module>\n    <module>hbase-testing-util</module>\n    <module>hbase-annotations</module>\n    <module>hbase-rest</module>\n    <module>hbase-checkstyle</module>\n    <module>hbase-external-blockcache</module>\n    <module>hbase-shaded</module>\n    <module>hbase-archetypes</module>\n    <module>hbase-metrics-api</module>\n    <module>hbase-metrics</module>\n    <module>hbase-backup</module>\n    <module>hbase-zookeeper</module>\n    <module>hbase-hbtop</module>\n    <module>hbase-asyncfs</module>\n    <module>hbase-logging</module>\n    <module>hbase-compression</module>\n    <module>hbase-extensions</module>\n    <module>hbase-dev-generate-classpath</module>\n  </modules>\n  <scm>\n    <connection>scm:git:git://gitbox.apache.org/repos/asf/hbase.git</connection>\n    <developerConnection>scm:git:https://gitbox.apache.org/repos/asf/hbase.git</developerConnection>\n    <url>https://gitbox.apache.org/repos/asf?p=hbase.git</url>\n  </scm>\n  <issueManagement>\n    <system>JIRA</system>\n    <url>https://issues.apache.org/jira/browse/HBASE</url>\n  </issueManagement>\n  <distributionManagement>\n    <site>\n      <id>hbase.apache.org</id>\n      <name>HBase Website at hbase.apache.org</name>\n      <!-- On why this is the tmp dir and not hbase.apache.org, see\n        https://issues.apache.org/jira/browse/HBASE-7593?focusedCommentId=13555866&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13555866\n       -->\n      <url>file:///tmp</url>\n    </site>\n  </distributionManagement>\n  <properties>\n    <revision>4.0.0-alpha-1-SNAPSHOT</revision>\n    <!-- override on command line to have generated LICENSE files include\n         diagnostic info for verifying notice requirements -->\n    <license.debug.print.included>false</license.debug.print.included>\n    <!-- When a particular module bundles its depenendencies, should be true -->\n    <license.bundles.dependencies>false</license.bundles.dependencies>\n    <!-- modules that include a the logo in their source tree should set true -->\n    <license.bundles.logo>false</license.bundles.logo>\n    <!-- modules that include bootstrap in their source tree should set true -->\n    <license.bundles.bootstrap>false</license.bundles.bootstrap>\n    <!-- modules that include jquery in their source tree should set true -->\n    <license.bundles.jquery>false</license.bundles.jquery>\n    <!-- modules that include vega in their source tree should set true -->\n    <license.bundles.vega>false</license.bundles.vega>\n    <tar.name>${project.build.finalName}.tar.gz</tar.name>\n    <maven.build.timestamp.format>yyyy-MM-dd'T'HH:mm</maven.build.timestamp.format>\n    <buildDate>${maven.build.timestamp}</buildDate>\n    <compileSource>17</compileSource>\n    <releaseTarget>17</releaseTarget>\n    <!-- Build dependencies -->\n    <!-- The $revision feature is introduced in 3.5.0 -->\n    <maven.min.version>3.5.0</maven.min.version>\n    <java.min.version>${compileSource}</java.min.version>\n    <!-- Dependencies -->\n    <hadoop-three.version>3.4.1</hadoop-three.version>\n    <!-- These must be defined here for downstream build tools that don't look at profiles.\n    -->\n    <hadoop.version>${hadoop-three.version}</hadoop.version>\n    <assembly.file>src/main/assembly/hadoop-three-compat.xml</assembly.file>\n    <!--\n      These property is for transitive netty dependencies from thirdparty dependencies, like\n      hadoop and zookeeper. HBase netty comes in via hbase-thirdparty hbase-shaded-netty\n      In the old time, netty-all includes all the classes but maven does not know it so it is\n      possible that we have netty-all and netty-handler both on the classpath but they have\n      different version and cause conflicts. Newer version of netty-all solved the this problem\n      by depending all other netty modules, but we'd better still specify the version by our own\n      in the dependencyManagement section as it could still lead to different versions of netty\n      modules and cause trouble if we only rely on transitive dependencies.\n    -->\n    <netty4.version>4.1.112.Final</netty4.version>\n    <!-- end HBASE-15925 default hadoop compatibility values -->\n    <audience-annotations.version>0.15.0</audience-annotations.version>\n    <javadoc.audience-annotations.version>0.15.0</javadoc.audience-annotations.version>\n    <avro.version>1.11.4</avro.version>\n    <caffeine.version>2.8.1</caffeine.version>\n    <commons-codec.version>1.15</commons-codec.version>\n    <commons-validator.version>1.7</commons-validator.version>\n    <commons-io.version>2.14.0</commons-io.version>\n    <commons-lang3.version>3.9</commons-lang3.version>\n    <commons-math.version>3.6.1</commons-math.version>\n    <commons-cli.version>1.5.0</commons-cli.version>\n    <disruptor.version>3.4.4</disruptor.version>\n    <httpclient.version>4.5.13</httpclient.version>\n    <httpcore.version>4.4.13</httpcore.version>\n    <metrics-core.version>3.2.6</metrics-core.version>\n    <!--\n      Note that the version of jackson-[annotations,core,databind] must be kept in sync with the\n      version of jackson-jaxrs-json-provider shipped in hbase-thirdparty.\n    -->\n    <jackson.version>2.17.2</jackson.version>\n    <jackson.databind.version>2.17.2</jackson.databind.version>\n    <jaxb-api.version>2.3.1</jaxb-api.version>\n    <servlet.api.version>3.1.0</servlet.api.version>\n    <wx.rs.api.version>2.1.1</wx.rs.api.version>\n    <tomcat.jasper.version>9.0.93</tomcat.jasper.version>\n    <jruby.version>9.4.9.0</jruby.version>\n    <junit.version>4.13.2</junit.version>\n    <hamcrest.version>1.3</hamcrest.version>\n    <opentelemetry.version>1.15.0</opentelemetry.version>\n    <opentelemetry-javaagent.version>1.15.0</opentelemetry-javaagent.version>\n    <log4j2.version>2.17.2</log4j2.version>\n    <mockito.version>4.11.0</mockito.version>\n    <!--\n      Version of protobuf that hbase uses internally (we shade our pb) Must match what is out\n      in hbase-thirdparty include.\n    -->\n    <internal.protobuf.version>4.28.2</internal.protobuf.version>\n    <protobuf.plugin.version>0.6.1</protobuf.plugin.version>\n    <thrift.path>thrift</thrift.path>\n    <thrift.version>0.14.1</thrift.version>\n    <zookeeper.version>3.8.4</zookeeper.version>\n    <jline.version>2.11</jline.version>\n    <slf4j.version>1.7.30</slf4j.version>\n    <clover.version>4.0.3</clover.version>\n    <jamon-runtime.version>2.4.1</jamon-runtime.version>\n    <jettison.version>1.5.4</jettison.version>\n    <!--Make sure these joni/jcodings are compatible with the versions used by jruby-->\n    <joni.version>2.2.1</joni.version>\n    <jcodings.version>1.0.58</jcodings.version>\n    <spy.version>2.12.3</spy.version>\n    <bouncycastle.version>1.78</bouncycastle.version>\n    <skyscreamer.version>1.5.1</skyscreamer.version>\n    <kerby.version>1.0.1</kerby.version>\n    <commons-crypto.version>1.1.0</commons-crypto.version>\n    <curator.version>4.2.0</curator.version>\n    <!-- Plugin Dependencies -->\n    <asciidoctor.plugin.version>2.2.2</asciidoctor.plugin.version>\n    <asciidoctorj.pdf.version>2.0.6</asciidoctorj.pdf.version>\n    <build.helper.maven.version>3.0.0</build.helper.maven.version>\n    <buildnumber.maven.version>1.4</buildnumber.maven.version>\n    <!--\n      When updating checkstyle.version, please make the same change in `.idea/checkstyle-idea.xml`\n    -->\n    <checkstyle.version>8.29</checkstyle.version>\n    <exec.maven.version>3.1.0</exec.maven.version>\n    <error-prone.version>2.28.0</error-prone.version>\n    <jamon.plugin.version>2.4.2</jamon.plugin.version>\n    <lifecycle.mapping.version>1.0.0</lifecycle.mapping.version>\n    <maven.antrun.version>1.8</maven.antrun.version>\n    <maven.bundle.version>3.3.0</maven.bundle.version>\n    <maven.checkstyle.version>3.1.0</maven.checkstyle.version>\n    <maven.eclipse.version>2.10</maven.eclipse.version>\n    <maven.gpg.version>3.0.1</maven.gpg.version>\n    <maven.javadoc.version>3.4.0</maven.javadoc.version>\n    <maven.warbucks.version>1.1.0</maven.warbucks.version>\n    <maven.project.info.report.version>3.1.2</maven.project.info.report.version>\n    <os.maven.version>1.5.0.Final</os.maven.version>\n    <findbugs-annotations.version>1.3.9-1</findbugs-annotations.version>\n    <spotbugs.version>4.7.3</spotbugs.version>\n    <spotbugs.maven.version>4.7.2.1</spotbugs.maven.version>\n    <surefire.version>3.1.0</surefire.version>\n    <wagon.ssh.version>2.12</wagon.ssh.version>\n    <xml.maven.version>1.0.1</xml.maven.version>\n    <spotless.version>2.27.2</spotless.version>\n    <maven-site.version>3.12.0</maven-site.version>\n    <!-- compression -->\n    <aircompressor.version>0.27</aircompressor.version>\n    <brotli4j.version>1.11.0</brotli4j.version>\n    <lz4.version>1.8.0</lz4.version>\n    <snappy.version>1.1.10.4</snappy.version>\n    <zstd-jni.version>1.5.5-2</zstd-jni.version>\n    <!--\n        Note that the version of protobuf shipped in hbase-thirdparty must match the version used\n        in hbase-protocol-shaded and hbase-examples. The version of jackson-[annotations,core,\n        databind] must be kept in sync with the version of jackson-jaxrs-json-provider shipped in\n        hbase-thirdparty.\n    -->\n    <hbase-thirdparty.version>4.1.9</hbase-thirdparty.version>\n    <!-- for.exclusion version are NOT for direct dependencies. To use the provided\n    scope to transitively exclude some transitive dependencies, we need to specify\n    some existing version to for maven. -->\n    <tomcat.version.for.exclusion>9.0.93</tomcat.version.for.exclusion>\n    <!-- Coverage properties -->\n    <jacoco.version>0.8.8</jacoco.version>\n    <jacocoArgLine/>\n    <sonar-maven-plugin.version>3.9.1.2184</sonar-maven-plugin.version>\n    <shell-executable>bash</shell-executable>\n    <surefire.provider>surefire-junit47</surefire.provider>\n    <!-- default: run small & medium, medium with 2 threads -->\n    <surefire.skipFirstPart>false</surefire.skipFirstPart>\n    <surefire.skipSecondPart>false</surefire.skipSecondPart>\n    <!-- Fork count varies w/ CPU count. Setting is conservative mostly determined\n        by what apache jenkins nightly builds will tolerate (See HBASE-24072). Up this\n      value is you want to burn through tests faster (could make for more failures\n      if more contention around resources). There is a matching MAVEN_ARG\n      in our yetus personality where we set the maven -T command to 0.25C too.\n      For example, to run at a rate that is more furious than our 0.25C, do\n      something like this:\n         f=\"0.5C\" ;  mvn -T$f -Dsurefire.firstPartForkCount=$f -Dsurefire.secondPartForkCount=$f test -PrunAllTests\n    -->\n    <surefire.firstPartForkCount>0.25C</surefire.firstPartForkCount>\n    <surefire.secondPartForkCount>0.25C</surefire.secondPartForkCount>\n    <surefire.firstPartGroups>org.apache.hadoop.hbase.testclassification.SmallTests</surefire.firstPartGroups>\n    <surefire.secondPartGroups>org.apache.hadoop.hbase.testclassification.MediumTests</surefire.secondPartGroups>\n    <surefire.testFailureIgnore>false</surefire.testFailureIgnore>\n    <test.output.tofile>true</test.output.tofile>\n    <surefire.timeout>900</surefire.timeout>\n    <test.exclude.pattern/>\n    <!--\n      Use -Dsurefire.Xmx=xxg to run tests with different JVM Xmx value.\n      This value is managed separately for jdk11. See below.\n    -->\n    <surefire.Xmx>2200m</surefire.Xmx>\n    <surefire.Xms>1000m</surefire.Xms>\n\n    <surefire.cygwinXmx>2200m</surefire.cygwinXmx>\n    <surefire.cygwinXms>1000m</surefire.cygwinXms>\n    <!--Mark our test runs with '-Dhbase.build.id' so we can identify a surefire test as ours in a process listing\n\n      And for netty eventloops that have no explicit configuration, netty sets\n      nioeventloopgroup thread count to CPU count * 2. Thats too much for mini\n      clusters/tests.\n     -->\n    <hbase-surefire.argLine>-enableassertions -Dhbase.build.id=${build.id} -Xmx${surefire.Xmx}\n      -Xms${surefire.Xms} -Djava.security.egd=file:/dev/./urandom -Djava.net.preferIPv4Stack=true\n      -Djava.awt.headless=true -Djdk.net.URLClassPath.disableClassPathURLCheck=true\n      -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.level=advanced\n      -Dio.netty.eventLoopThreads=3 -Dio.opentelemetry.context.enableStrictContext=true</hbase-surefire.argLine>\n    <hbase-surefire.cygwin-argLine>-enableassertions -Xmx${surefire.cygwinXmx}\n      -Xms${surefire.cygwinXms} -Djava.security.egd=file:/dev/./urandom -Djava.net.preferIPv4Stack=true\n      \"-Djava.library.path=${hadoop.library.path};${java.library.path}\"\n      -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.level=advanced\n      -Dio.opentelemetry.context.enableStrictContext=true</hbase-surefire.cygwin-argLine>\n    <!--\n      Keep these options in sync with add_jdk17_jvm_flags() in bin/hbase, except the below ones\n      which are only used in test code\n      'java.base/jdk.internal.util.random' is required by the test code\n      'java.base/sun.security.x509' and 'java.base/sun.security.util' are required by\n      TestLdapHttpServer, see HBASE-28341\n      'java.base/java.net' is required by TestSecureIPC, see HBASE-28723\n    -->\n    <hbase-surefire.jdk17.flags>-Dorg.apache.hbase.thirdparty.io.netty.tryReflectionSetAccessible=true\n      --add-modules jdk.unsupported\n      --add-opens java.base/java.io=ALL-UNNAMED\n      --add-opens java.base/java.nio=ALL-UNNAMED\n      --add-opens java.base/sun.nio.ch=ALL-UNNAMED\n      --add-opens java.base/java.lang=ALL-UNNAMED\n      --add-opens java.base/jdk.internal.ref=ALL-UNNAMED\n      --add-opens java.base/java.lang.reflect=ALL-UNNAMED\n      --add-opens java.base/java.util=ALL-UNNAMED\n      --add-opens java.base/java.util.concurrent=ALL-UNNAMED\n      --add-exports java.base/jdk.internal.misc=ALL-UNNAMED\n      --add-exports java.security.jgss/sun.security.krb5=ALL-UNNAMED\n      --add-exports java.base/sun.net.dns=ALL-UNNAMED\n      --add-exports java.base/sun.net.util=ALL-UNNAMED\n      --add-opens java.base/jdk.internal.util.random=ALL-UNNAMED\n      --add-opens java.base/sun.security.x509=ALL-UNNAMED\n      --add-opens java.base/sun.security.util=ALL-UNNAMED\n      --add-opens java.base/java.net=ALL-UNNAMED</hbase-surefire.jdk17.flags>\n    <!-- Surefire argLine defaults to Linux, cygwin argLine is used in the os.windows profile -->\n    <argLine>${hbase-surefire.argLine} @{jacocoArgLine}</argLine>\n    <extra.enforcer.version>1.5.1</extra.enforcer.version>\n    <enforcer.version>3.0.0</enforcer.version>\n    <restrict-imports.enforcer.version>0.14.0</restrict-imports.enforcer.version>\n    <!-- Location of test resources -->\n    <test.build.classes>${project.build.directory}/test-classes</test.build.classes>\n    <test.tmp.dir>${project.build.directory}</test.tmp.dir>\n    <maven.build.timestamp.format>yyyy-MM-dd'T'HH:mm:ss'Z'</maven.build.timestamp.format>\n    <!--This build.id we'll add as flag so can identify which forked processes belong to our build.\n        Default is the build start timestamp. Up on jenkins pass in the jenkins build id by setting\n        this parameter by invoking mvn with -Dbuild.id=$BUILD_ID-->\n    <build.id>${maven.build.timestamp}</build.id>\n    <shell-executable>bash</shell-executable>\n    <!-- Still need this to ignore some errors when building javadoc-->\n    <doclint>none</doclint>\n    <!-- Required for testing LDAP integration -->\n    <apacheds.version>2.0.0.AM26</apacheds.version>\n    <ldap-api.version>2.0.0</ldap-api.version>\n  </properties>\n  <!-- Sorted by groups of dependencies then groupId and artifactId -->\n  <dependencyManagement>\n    <dependencies>\n      <!--\n      Note: There are a few exclusions to prevent duplicate code in different jars to be included:\n          org.mortbay.jetty:servlet-api, javax.servlet:servlet-api: These are excluded because they are\n          the same implementations. I chose org.mortbay.jetty:servlet-api-2.5 instead, which is a third\n          implementation of the same, because Hadoop also uses this version\n          javax.servlet:jsp-api in favour of javax.servlet.jsp:javax.servlet.jsp-api:2.3.1 since it\n          is what glassfish's jspC jar uses and that's where we get our own need for a jsp-api.\n        -->\n      <!-- Intra-module dependencies -->\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-annotations</artifactId>\n        <version>${project.version}</version>\n        <type>test-jar</type>\n        <!--Was test scope only but if we want to run hbase-it tests, need the annotations test jar-->\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-backup</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-common</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-common</artifactId>\n        <version>${project.version}</version>\n        <type>test-jar</type>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-logging</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-logging</artifactId>\n        <version>${project.version}</version>\n        <type>test-jar</type>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-protocol-shaded</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-procedure</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-procedure</artifactId>\n        <version>${project.version}</version>\n        <type>test-jar</type>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-hadoop-compat</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-hadoop-compat</artifactId>\n        <version>${project.version}</version>\n        <type>test-jar</type>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-replication</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-replication</artifactId>\n        <version>${project.version}</version>\n        <type>test-jar</type>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-balancer</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-balancer</artifactId>\n        <version>${project.version}</version>\n        <type>test-jar</type>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-http</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-http</artifactId>\n        <version>${project.version}</version>\n        <type>test-jar</type>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-server</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-server</artifactId>\n        <version>${project.version}</version>\n        <type>test-jar</type>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-mapreduce</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-mapreduce</artifactId>\n        <version>${project.version}</version>\n        <type>test-jar</type>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-diagnostics</artifactId>\n        <version>${project.version}</version>\n        <type>test-jar</type>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-endpoint</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-shell</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-shell</artifactId>\n        <version>${project.version}</version>\n        <type>test-jar</type>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-thrift</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-thrift</artifactId>\n        <version>${project.version}</version>\n        <type>test-jar</type>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-testing-util</artifactId>\n        <version>${project.version}</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-examples</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-external-blockcache</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-it</artifactId>\n        <version>${project.version}</version>\n        <type>test-jar</type>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-client</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-client</artifactId>\n        <version>${project.version}</version>\n        <type>test-jar</type>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-metrics-api</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-metrics-api</artifactId>\n        <version>${project.version}</version>\n        <type>test-jar</type>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-metrics</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-metrics</artifactId>\n        <version>${project.version}</version>\n        <type>test-jar</type>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-rest</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-resource-bundle</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-zookeeper</artifactId>\n        <version>${project.version}</version>\n        <exclusions>\n          <exclusion>\n            <groupId>com.google.code.findbugs</groupId>\n            <artifactId>jsr305</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>com.github.spotbugs</groupId>\n            <artifactId>spotbugs-annotations</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-zookeeper</artifactId>\n        <version>${project.version}</version>\n        <type>test-jar</type>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-hbtop</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-shaded-client</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-shaded-client-byo-hadoop</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-shaded-mapreduce</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-shaded-testing-util</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-asyncfs</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-asyncfs</artifactId>\n        <version>${project.version}</version>\n        <type>test-jar</type>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-compression-aircompressor</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-compression-brotli</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-compression-lz4</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-compression-snappy</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-compression-zstd</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-openssl</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-diagnostics</artifactId>\n        <version>${project.version}</version>\n      </dependency>\n      <!-- General dependencies -->\n      <dependency>\n        <groupId>com.github.stephenc.findbugs</groupId>\n        <artifactId>findbugs-annotations</artifactId>\n        <version>${findbugs-annotations.version}</version>\n      </dependency>\n      <!--\n        Logging dependencies. In general, we use slf4j as the log facade in HBase, so all sub\n        modules should depend on slf4j-api at compile scope, and then depend on log4j-slf4j-impl\n        and log4j2 at test scope(and in hbase-assembly when shipping the binary) to redirect the\n        log message to log4j. Do not introduce logging dependencies other than slf4j-api at compile\n        scope as it will mess up the logging framework for downstream users.\n        Here we also depend on jcl-over-slf4j and jul-to-slf4j, as some of the libraries we depend\n        on use these logging framework so we need to redirect their log message to slf4j, and then\n        redirect the log message to our log4j framework.\n      -->\n      <dependency>\n        <groupId>org.codehaus.jettison</groupId>\n        <artifactId>jettison</artifactId>\n        <version>${jettison.version}</version>\n      </dependency>\n      <!-- Logging -->\n      <dependency>\n        <groupId>org.slf4j</groupId>\n        <artifactId>slf4j-api</artifactId>\n        <version>${slf4j.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.slf4j</groupId>\n        <artifactId>jcl-over-slf4j</artifactId>\n        <version>${slf4j.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.slf4j</groupId>\n        <artifactId>jul-to-slf4j</artifactId>\n        <version>${slf4j.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.logging.log4j</groupId>\n        <artifactId>log4j-api</artifactId>\n        <version>${log4j2.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.logging.log4j</groupId>\n        <artifactId>log4j-core</artifactId>\n        <version>${log4j2.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.logging.log4j</groupId>\n        <artifactId>log4j-slf4j-impl</artifactId>\n        <version>${log4j2.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.logging.log4j</groupId>\n        <artifactId>log4j-1.2-api</artifactId>\n        <version>${log4j2.version}</version>\n      </dependency>\n      <!-- Avro dependencies we mostly get transitively, manual version coallescing -->\n      <dependency>\n        <groupId>org.apache.avro</groupId>\n        <artifactId>avro</artifactId>\n        <version>${avro.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>com.github.ben-manes.caffeine</groupId>\n        <artifactId>caffeine</artifactId>\n        <version>${caffeine.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>io.dropwizard.metrics</groupId>\n        <artifactId>metrics-core</artifactId>\n        <version>${metrics-core.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.httpcomponents</groupId>\n        <artifactId>httpclient</artifactId>\n        <version>${httpclient.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.httpcomponents</groupId>\n        <artifactId>httpcore</artifactId>\n        <version>${httpcore.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>commons-codec</groupId>\n        <artifactId>commons-codec</artifactId>\n        <version>${commons-codec.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>commons-validator</groupId>\n        <artifactId>commons-validator</artifactId>\n        <version>${commons-validator.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>commons-io</groupId>\n        <artifactId>commons-io</artifactId>\n        <version>${commons-io.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.commons</groupId>\n        <artifactId>commons-lang3</artifactId>\n        <version>${commons-lang3.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.commons</groupId>\n        <artifactId>commons-math3</artifactId>\n        <version>${commons-math.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>commons-cli</groupId>\n        <artifactId>commons-cli</artifactId>\n        <version>${commons-cli.version}</version>\n      </dependency>\n      <dependency>\n        <!-- commons-logging is only used by hbase-http's HttpRequestLog and hbase-server's\n             HBaseTestingUtil.\n          -->\n        <groupId>commons-logging</groupId>\n        <artifactId>commons-logging</artifactId>\n        <version>1.2</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.zookeeper</groupId>\n        <artifactId>zookeeper</artifactId>\n        <version>${zookeeper.version}</version>\n        <exclusions>\n          <exclusion>\n            <groupId>ch.qos.logback</groupId>\n            <artifactId>logback-core</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>ch.qos.logback</groupId>\n            <artifactId>logback-classic</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>jline</groupId>\n        <artifactId>jline</artifactId>\n        <version>${jline.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.thrift</groupId>\n        <artifactId>libthrift</artifactId>\n        <version>${thrift.version}</version>\n        <exclusions>\n          <exclusion>\n            <groupId>org.apache.tomcat.embed</groupId>\n            <artifactId>tomcat-embed-core</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>org.jruby</groupId>\n        <artifactId>jruby-complete</artifactId>\n        <version>${jruby.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.jruby.jcodings</groupId>\n        <artifactId>jcodings</artifactId>\n        <version>${jcodings.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.jruby.joni</groupId>\n        <artifactId>joni</artifactId>\n        <version>${joni.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>com.fasterxml.jackson.core</groupId>\n        <artifactId>jackson-annotations</artifactId>\n        <version>${jackson.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>com.fasterxml.jackson.core</groupId>\n        <artifactId>jackson-core</artifactId>\n        <version>${jackson.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>com.fasterxml.jackson.core</groupId>\n        <artifactId>jackson-databind</artifactId>\n        <version>${jackson.databind.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.jamon</groupId>\n        <artifactId>jamon-runtime</artifactId>\n        <version>${jamon-runtime.version}</version>\n      </dependency>\n      <!-- REST dependencies -->\n      <dependency>\n        <groupId>javax.servlet</groupId>\n        <artifactId>javax.servlet-api</artifactId>\n        <version>${servlet.api.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>javax.ws.rs</groupId>\n        <artifactId>javax.ws.rs-api</artifactId>\n        <version>${wx.rs.api.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>com.sun.activation</groupId>\n        <artifactId>javax.activation</artifactId>\n        <version>1.2.0</version>\n      </dependency>\n      <dependency>\n        <groupId>javax.annotation</groupId>\n        <artifactId>javax.annotation-api</artifactId>\n        <version>1.2</version>\n      </dependency>\n      <dependency>\n        <!--This lib has JspC in it. Needed precompiling jsps in hbase-rest, etc.-->\n        <groupId>org.apache.tomcat</groupId>\n        <artifactId>tomcat-jasper</artifactId>\n        <version>${tomcat.jasper.version}</version>\n        <exclusions>\n          <exclusion>\n            <groupId>org.eclipse.jdt</groupId>\n            <artifactId>ecj</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.tomcat</groupId>\n            <artifactId>tomcat-servlet-api</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.tomcat</groupId>\n            <artifactId>tomcat-jsp-api</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <!-- this lib is used by the compiled Jsp from the above JspC -->\n        <groupId>javax.servlet.jsp</groupId>\n        <artifactId>javax.servlet.jsp-api</artifactId>\n        <version>2.3.1</version>\n      </dependency>\n      <dependency>\n        <groupId>javax.xml.bind</groupId>\n        <artifactId>jaxb-api</artifactId>\n        <version>${jaxb-api.version}</version>\n        <exclusions>\n          <exclusion>\n            <groupId>javax.xml.stream</groupId>\n            <artifactId>stax-api</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>junit</groupId>\n        <artifactId>junit</artifactId>\n        <version>${junit.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.hamcrest</groupId>\n        <artifactId>hamcrest-core</artifactId>\n        <version>${hamcrest.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.hamcrest</groupId>\n        <artifactId>hamcrest-library</artifactId>\n        <version>${hamcrest.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.mockito</groupId>\n        <artifactId>mockito-bom</artifactId>\n        <version>${mockito.version}</version>\n        <type>pom</type>\n        <scope>import</scope>\n      </dependency>\n      <dependency>\n        <groupId>io.opentelemetry</groupId>\n        <artifactId>opentelemetry-bom</artifactId>\n        <version>${opentelemetry.version}</version>\n        <type>pom</type>\n        <scope>import</scope>\n      </dependency>\n      <dependency>\n        <groupId>io.opentelemetry</groupId>\n        <artifactId>opentelemetry-semconv</artifactId>\n        <version>${opentelemetry.version}-alpha</version>\n      </dependency>\n      <dependency>\n        <groupId>io.opentelemetry.javaagent</groupId>\n        <artifactId>opentelemetry-javaagent</artifactId>\n        <version>${opentelemetry-javaagent.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>com.lmax</groupId>\n        <artifactId>disruptor</artifactId>\n        <version>${disruptor.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>net.spy</groupId>\n        <artifactId>spymemcached</artifactId>\n        <version>${spy.version}</version>\n        <optional>true</optional>\n      </dependency>\n      <dependency>\n        <groupId>org.bouncycastle</groupId>\n        <artifactId>bcprov-jdk18on</artifactId>\n        <version>${bouncycastle.version}</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.skyscreamer</groupId>\n        <artifactId>jsonassert</artifactId>\n        <version>${skyscreamer.version}</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.bouncycastle</groupId>\n        <artifactId>bcpkix-jdk18on</artifactId>\n        <version>${bouncycastle.version}</version>\n        <scope>test</scope>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.kerby</groupId>\n        <artifactId>kerb-core</artifactId>\n        <version>${kerby.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.kerby</groupId>\n        <artifactId>kerb-client</artifactId>\n        <version>${kerby.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.kerby</groupId>\n        <artifactId>kerb-simplekdc</artifactId>\n        <version>${kerby.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.commons</groupId>\n        <artifactId>commons-crypto</artifactId>\n        <version>${commons-crypto.version}</version>\n        <exclusions>\n          <exclusion>\n            <groupId>net.java.dev.jna</groupId>\n            <artifactId>jna</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.curator</groupId>\n        <artifactId>curator-framework</artifactId>\n        <version>${curator.version}</version>\n        <exclusions>\n          <exclusion>\n            <groupId>org.apache.zookeeper</groupId>\n            <artifactId>zookeeper</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.curator</groupId>\n        <artifactId>curator-client</artifactId>\n        <version>${curator.version}</version>\n        <exclusions>\n          <exclusion>\n            <groupId>com.google.guava</groupId>\n            <artifactId>guava</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.zookeeper</groupId>\n            <artifactId>zookeeper</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.curator</groupId>\n        <artifactId>curator-recipes</artifactId>\n        <version>${curator.version}</version>\n        <exclusions>\n          <exclusion>\n            <groupId>com.google.guava</groupId>\n            <artifactId>guava</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>org.apache.zookeeper</groupId>\n            <artifactId>zookeeper</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.yetus</groupId>\n        <artifactId>audience-annotations</artifactId>\n        <version>${audience-annotations.version}</version>\n      </dependency>\n      <!-- compression -->\n      <dependency>\n        <groupId>io.airlift</groupId>\n        <artifactId>aircompressor</artifactId>\n        <version>${aircompressor.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.lz4</groupId>\n        <artifactId>lz4-java</artifactId>\n        <version>${lz4.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.xerial.snappy</groupId>\n        <artifactId>snappy-java</artifactId>\n        <version>${snappy.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>com.github.luben</groupId>\n        <artifactId>zstd-jni</artifactId>\n        <version>${zstd-jni.version}</version>\n      </dependency>\n      <!-- shaded thirdparty -->\n      <dependency>\n        <groupId>org.apache.hbase.thirdparty</groupId>\n        <artifactId>hbase-shaded-gson</artifactId>\n        <version>${hbase-thirdparty.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase.thirdparty</groupId>\n        <artifactId>hbase-shaded-miscellaneous</artifactId>\n        <version>${hbase-thirdparty.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase.thirdparty</groupId>\n        <artifactId>hbase-shaded-netty</artifactId>\n        <version>${hbase-thirdparty.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase.thirdparty</groupId>\n        <artifactId>hbase-shaded-netty-tcnative</artifactId>\n        <version>${hbase-thirdparty.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase.thirdparty</groupId>\n        <artifactId>hbase-shaded-protobuf</artifactId>\n        <version>${hbase-thirdparty.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase.thirdparty</groupId>\n        <artifactId>hbase-shaded-jetty</artifactId>\n        <version>${hbase-thirdparty.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase.thirdparty</groupId>\n        <artifactId>hbase-shaded-jersey</artifactId>\n        <version>${hbase-thirdparty.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase.thirdparty</groupId>\n        <artifactId>hbase-shaded-jackson-jaxrs-json-provider</artifactId>\n        <version>${hbase-thirdparty.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>org.apache.hbase.thirdparty</groupId>\n        <artifactId>hbase-unsafe</artifactId>\n        <version>${hbase-thirdparty.version}</version>\n      </dependency>\n      <dependency>\n        <groupId>com.sun.xml.ws</groupId>\n        <artifactId>jaxws-rt</artifactId>\n        <version>2.3.7</version>\n        <exclusions>\n          <exclusion>\n            <groupId>javax.activation</groupId>\n            <artifactId>javax.activation-api</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>com.sun.xml.ws</groupId>\n            <artifactId>release-documentation</artifactId>\n          </exclusion>\n          <exclusion>\n            <groupId>com.sun.xml.ws</groupId>\n            <artifactId>samples</artifactId>\n          </exclusion>\n        </exclusions>\n      </dependency>\n      <dependency>\n        <groupId>io.netty</groupId>\n        <artifactId>netty-bom</artifactId>\n        <version>${netty4.version}</version>\n        <type>pom</type>\n        <scope>import</scope>\n      </dependency>\n    </dependencies>\n  </dependencyManagement>\n  <dependencies>\n    <!--REMOVE THIS. HERE TEMPORARILY.\n         Implication is that every module needs junit which is not so.\n         Cannot undo though because build runs test on each module and\n         it fails if no junit. TODO. -->\n    <dependency>\n      <groupId>junit</groupId>\n      <artifactId>junit</artifactId>\n      <scope>test</scope>\n    </dependency>\n  </dependencies>\n  <build>\n    <!-- Plugin versions are inherited from ASF parent pom: https://maven.apache.org/pom/asf/\n         For specific version use a property and define it in the parent pom.\n     -->\n    <pluginManagement>\n      <plugins>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-remote-resources-plugin</artifactId>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-release-plugin</artifactId>\n          <configuration>\n            <!--You need this profile. It'll sign your artifacts.\n                I'm not sure if this config. actually works though.\n                I've been specifying -Papache-release on the command-line\n             -->\n            <releaseProfiles>apache-release</releaseProfiles>\n            <!--This stops our running tests for each stage of maven release.\n                But it builds the test jar.  From SUREFIRE-172.\n              -->\n            <arguments>-Dmaven.test.skip.exec ${arguments}</arguments>\n            <goals>${goals}</goals>\n            <pomFileName>pom.xml</pomFileName>\n          </configuration>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-compiler-plugin</artifactId>\n          <configuration>\n            <showWarnings>true</showWarnings>\n            <showDeprecation>false</showDeprecation>\n            <useIncrementalCompilation>false</useIncrementalCompilation>\n            <compilerArgument>-Xlint:-options</compilerArgument>\n          </configuration>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-javadoc-plugin</artifactId>\n          <version>${maven.javadoc.version}</version>\n          <configuration>\n            <source>${compileSource}</source>\n          </configuration>\n        </plugin>\n        <!-- Test oriented plugins -->\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-surefire-plugin</artifactId>\n          <version>${surefire.version}</version>\n          <!-- Generic testing configuration for all packages -->\n          <configuration>\n            <groups>${surefire.firstPartGroups}</groups>\n            <failIfNoTests>false</failIfNoTests>\n            <failIfNoSpecifiedTests>false</failIfNoSpecifiedTests>\n            <trimStackTrace>false</trimStackTrace>\n            <skip>${surefire.skipFirstPart}</skip>\n            <forkCount>${surefire.firstPartForkCount}</forkCount>\n            <forkNode implementation=\"org.apache.maven.plugin.surefire.extensions.SurefireForkNodeFactory\"/>\n            <!--\n              The counter in HBaseTestAppender will be broken if we set reuseForks to true, be\n              careful when you want to change this value. See HBASE-26947 for more details.\n            -->\n            <reuseForks>false</reuseForks>\n            <reportsDirectory>${surefire.reportsDirectory}</reportsDirectory>\n            <tempDir>${surefire.tempDir}</tempDir>\n            <testFailureIgnore>${surefire.testFailureIgnore}</testFailureIgnore>\n            <forkedProcessTimeoutInSeconds>${surefire.timeout}</forkedProcessTimeoutInSeconds>\n            <redirectTestOutputToFile>${test.output.tofile}</redirectTestOutputToFile>\n            <systemPropertyVariables>\n              <test.build.classes>${test.build.classes}</test.build.classes>\n              <java.io.tmpdir>${test.tmp.dir}</java.io.tmpdir>\n              <java.util.logging.config.class>org.apache.hadoop.hbase.logging.JulToSlf4jInitializer</java.util.logging.config.class>\n            </systemPropertyVariables>\n            <excludes>\n              <!-- users can add -D option to skip particular test classes\n             ex: mvn test -Dtest.exclude.pattern=**/TestFoo.java,**/TestBar.java\n              -->\n              <exclude>${test.exclude.pattern}</exclude>\n            </excludes>\n            <properties>\n              <property>\n                <name>listener</name>\n                <value>org.apache.hadoop.hbase.TimedOutTestsListener,org.apache.hadoop.hbase.HBaseClassTestRuleChecker,org.apache.hadoop.hbase.ResourceCheckerJUnitListener</value>\n              </property>\n            </properties>\n          </configuration>\n          <dependencies>\n            <!-- by default surefire selects dynamically the connector to the unit tests\n              tool. We want to use always the same as the different connectors can have different\n              bugs and behaviour. -->\n            <dependency>\n              <groupId>org.apache.maven.surefire</groupId>\n              <artifactId>${surefire.provider}</artifactId>\n              <version>${surefire.version}</version>\n            </dependency>\n          </dependencies>\n          <executions>\n            <execution>\n              <id>secondPartTestsExecution</id>\n              <goals>\n                <goal>test</goal>\n              </goals>\n              <phase>test</phase>\n              <configuration>\n                <skip>${surefire.skipSecondPart}</skip>\n                <testFailureIgnore>${surefire.testFailureIgnore}</testFailureIgnore>\n                <!--\n                  The counter in HBaseTestAppender will be broken if we set reuseForks to true, be\n                  careful when you want to change this value. See HBASE-26947 for more details.\n                -->\n                <reuseForks>false</reuseForks>\n                <forkCount>${surefire.secondPartForkCount}</forkCount>\n                <forkNode implementation=\"org.apache.maven.plugin.surefire.extensions.SurefireForkNodeFactory\"/>\n                <groups>${surefire.secondPartGroups}</groups>\n                <forkedProcessTimeoutInSeconds>${surefire.timeout}</forkedProcessTimeoutInSeconds>\n              </configuration>\n            </execution>\n          </executions>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-surefire-report-plugin</artifactId>\n          <version>${surefire.version}</version>\n        </plugin>\n        <plugin>\n          <groupId>org.codehaus.mojo</groupId>\n          <artifactId>buildnumber-maven-plugin</artifactId>\n          <version>${buildnumber.maven.version}</version>\n        </plugin>\n        <plugin>\n          <groupId>com.github.spotbugs</groupId>\n          <artifactId>spotbugs-maven-plugin</artifactId>\n          <version>${spotbugs.maven.version}</version>\n          <configuration>\n            <excludeFilterFile>${project.basedir}/../dev-support/spotbugs-exclude.xml</excludeFilterFile>\n            <spotbugsXmlOutput>true</spotbugsXmlOutput>\n            <xmlOutput>true</xmlOutput>\n            <effort>Max</effort>\n          </configuration>\n          <dependencies>\n            <!-- overwrite dependency on spotbugs if you want to specify the version of spotbugs -->\n            <dependency>\n              <groupId>com.github.spotbugs</groupId>\n              <artifactId>spotbugs</artifactId>\n              <version>${spotbugs.version}</version>\n            </dependency>\n          </dependencies>\n        </plugin>\n        <plugin>\n          <groupId>org.codehaus.mojo</groupId>\n          <artifactId>build-helper-maven-plugin</artifactId>\n          <version>${build.helper.maven.version}</version>\n        </plugin>\n        <plugin>\n          <artifactId>maven-antrun-plugin</artifactId>\n          <version>${maven.antrun.version}</version>\n        </plugin>\n        <plugin>\n          <groupId>org.jamon</groupId>\n          <artifactId>jamon-maven-plugin</artifactId>\n          <version>${jamon.plugin.version}</version>\n        </plugin>\n        <!-- Make a jar and put the sources in the jar.\n        In the parent pom, so submodules will do the right thing. -->\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-source-plugin</artifactId>\n          <executions>\n            <execution>\n              <id>attach-sources</id>\n              <goals>\n                <goal>jar-no-fork</goal>\n                <goal>test-jar-no-fork</goal>\n              </goals>\n              <phase>prepare-package</phase>\n              <configuration>\n                <excludes>\n                  <exclude>log4j2.xml</exclude>\n                </excludes>\n              </configuration>\n            </execution>\n          </executions>\n        </plugin>\n        <!-- General configuration for submodules who want to build a test jar -->\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-jar-plugin</artifactId>\n          <configuration>\n            <skipIfEmpty>true</skipIfEmpty>\n            <excludes>\n              <exclude>hbase-site.xml</exclude>\n              <exclude>hdfs-site.xml</exclude>\n              <exclude>mapred-queues.xml</exclude>\n              <exclude>mapred-site.xml</exclude>\n            </excludes>\n          </configuration>\n          <executions>\n            <execution>\n              <goals>\n                <!--This goal will install a -test.jar when we do install\n                      See https://maven.apache.org/guides/mini/guide-attached-tests.html\n                   -->\n                <goal>test-jar</goal>\n              </goals>\n              <phase>prepare-package</phase>\n            </execution>\n          </executions>\n        </plugin>\n        <plugin>\n          <!-- excludes are inherited -->\n          <groupId>org.apache.rat</groupId>\n          <artifactId>apache-rat-plugin</artifactId>\n          <configuration>\n            <excludes>\n              <exclude>**/*.versionsBackup</exclude>\n              <exclude>**/*.log</exclude>\n              <exclude>**/.*</exclude>\n              <exclude>**/*.tgz</exclude>\n              <exclude>**/*.orig</exclude>\n              <exclude>**/0000000000000016310</exclude>\n              <exclude>**/a6a6562b777440fd9c34885428f5cb61.21e75333ada3d5bafb34bb918f29576c</exclude>\n              <exclude>**/8e8ab58dcf39412da19833fcd8f687ac</exclude>\n              <exclude>**/.idea/**</exclude>\n              <exclude>**/*.iml</exclude>\n              <exclude>**/CHANGES.txt</exclude>\n              <exclude>**/generated/**</exclude>\n              <exclude>**/gen-*/**</exclude>\n              <!-- No material contents -->\n              <exclude>conf/regionservers</exclude>\n              <exclude>**/*.avpr</exclude>\n              <exclude>**/*.svg</exclude>\n              <!-- non-standard notice file from jruby included by reference -->\n              <exclude>**/src/main/resources/META-INF/LEGAL</exclude>\n              <!-- MIT: https://github.com/asciidoctor/asciidoctor/blob/master/LICENSE.adoc -->\n              <exclude>**/src/main/asciidoc/hbase.css</exclude>\n              <!-- MIT https://jquery.org/license -->\n              <exclude>**/jquery.min.js</exclude>\n              <exclude>**/jquery.tablesorter.min.js</exclude>\n              <exclude>**/parser-date-iso8601.min.js</exclude>\n              <!-- MIT: bootstrap -->\n              <exclude>**/src/main/resources/hbase-webapps/static/*/bootstrap*</exclude>\n              <!-- BSD 3-clause: Vega, Vega-Lite, Vega-Embed -->\n              <exclude>**/hbase-webapps/static/js/vega*.min.js</exclude>\n              <!-- vector graphics -->\n              <exclude>**/*.vm</exclude>\n              <!-- apache doxia generated -->\n              <exclude>**/control</exclude>\n              <exclude>**/conffile</exclude>\n              <!-- auto-gen docs -->\n              <exclude>docs/*</exclude>\n              <exclude>logs/*</exclude>\n              <!--  exclude source control files -->\n              <exclude>.git/**</exclude>\n              <exclude>.svn/**</exclude>\n              <exclude>**/.settings/**</exclude>\n              <exclude>**/patchprocess/**</exclude>\n              <exclude>src/site/resources/repo/**</exclude>\n              <exclude>**/dependency-reduced-pom.xml</exclude>\n              <exclude>**/rat.txt</exclude>\n              <!-- exclude the shaded protobuf files -->\n              <exclude>**/shaded/com/google/protobuf/**</exclude>\n              <exclude>**/src/main/patches/**</exclude>\n              <exclude>**/vote.tmpl</exclude>\n              <!-- gzipped list of S3N URIs for hbase-it -->\n              <exclude>**/CC-MAIN-2021-10-warc.paths.gz</exclude>\n            </excludes>\n          </configuration>\n        </plugin>\n        <plugin>\n          <artifactId>maven-assembly-plugin</artifactId>\n          <configuration>\n            <!--Defer to the hbase-assembly sub-module.  It\n             does all assembly-->\n            <skipAssembly>true</skipAssembly>\n          </configuration>\n        </plugin>\n        <plugin>\n          <groupId>org.xolstice.maven.plugins</groupId>\n          <artifactId>protobuf-maven-plugin</artifactId>\n          <version>${protobuf.plugin.version}</version>\n          <configuration>\n            <protoSourceRoot>${basedir}/src/main/protobuf/</protoSourceRoot>\n            <clearOutputDirectory>false</clearOutputDirectory>\n            <checkStaleness>true</checkStaleness>\n          </configuration>\n        </plugin>\n        <plugin>\n          <!-- Approach followed here is roughly the same as mentioned here:\n          https://maven.apache.org/plugins/maven-checkstyle-plugin/examples/multi-module-config.html\n          -->\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-checkstyle-plugin</artifactId>\n          <version>${maven.checkstyle.version}</version>\n          <configuration>\n            <configLocation>hbase/checkstyle.xml</configLocation>\n            <suppressionsLocation>hbase/checkstyle-suppressions.xml</suppressionsLocation>\n            <includeTestSourceDirectory>true</includeTestSourceDirectory>\n          </configuration>\n          <dependencies>\n            <dependency>\n              <groupId>org.apache.hbase</groupId>\n              <artifactId>hbase-checkstyle</artifactId>\n              <version>${project.version}</version>\n            </dependency>\n            <dependency>\n              <groupId>com.puppycrawl.tools</groupId>\n              <artifactId>checkstyle</artifactId>\n              <version>${checkstyle.version}</version>\n            </dependency>\n          </dependencies>\n        </plugin>\n        <!--Need this old plugin to replace in generated files instances\n           of com.google.protobuf so instead its o.a.h.h.com.google.protobuf.\n           Plugin is old and in google code archive. Here is usage done by\n           anohther: https://github.com/beiliubei/maven-replacer-plugin/wiki/Usage-Guide\n           The mess with the regex in the below is to prevent replacement every time\n           we run mvn install. There is probably a better way of avoiding the\n           double interpolation but this is it for now.\n        -->\n        <plugin>\n          <groupId>com.google.code.maven-replacer-plugin</groupId>\n          <artifactId>replacer</artifactId>\n          <version>1.5.3</version>\n          <configuration>\n            <basedir>${basedir}/target/generated-sources/</basedir>\n            <includes>\n              <include>**/*.java</include>\n            </includes>\n            <!-- Ignore errors when missing files, because it means this build\n                   was run with -Dprotoc.skip and there is no -Dreplacer.skip -->\n            <ignoreErrors>true</ignoreErrors>\n            <replacements>\n              <replacement>\n                <token>([^\\.])com.google.protobuf</token>\n                <value>$1org.apache.hbase.thirdparty.com.google.protobuf</value>\n              </replacement>\n              <replacement>\n                <token>(public)(\\W+static)?(\\W+final)?(\\W+class)</token>\n                <value>@javax.annotation.Generated(\"proto\") $1$2$3$4</value>\n              </replacement>\n              <!-- replacer doesn't support anchoring or negative lookbehind -->\n              <replacement>\n                <token>(@javax.annotation.Generated\\(\"proto\"\\) ){2}</token>\n                <value>$1</value>\n              </replacement>\n            </replacements>\n          </configuration>\n          <executions>\n            <execution>\n              <goals>\n                <goal>replace</goal>\n              </goals>\n              <phase>process-sources</phase>\n            </execution>\n          </executions>\n        </plugin>\n        <plugin>\n          <groupId>net.revelc.code</groupId>\n          <artifactId>warbucks-maven-plugin</artifactId>\n          <version>${maven.warbucks.version}</version>\n          <configuration>\n            <ignoreRuleFailures>false</ignoreRuleFailures>\n            <rules>\n              <rule>\n                <!-- exclude the generated java files -->\n                <classPattern>(?!.*(.generated.|.tmpl.|\\$)).*</classPattern>\n                <includeTestClasses>false</includeTestClasses>\n                <includePublicClasses>true</includePublicClasses>\n                <includePackagePrivateClasses>false</includePackagePrivateClasses>\n                <includeProtectedClasses>false</includeProtectedClasses>\n                <includePrivateClasses>false</includePrivateClasses>\n                <classAnnotationPattern>org[.]apache[.]yetus[.]audience[.]InterfaceAudience.*</classAnnotationPattern>\n              </rule>\n            </rules>\n          </configuration>\n          <executions>\n            <execution>\n              <id>run-warbucks</id>\n              <goals>\n                <goal>check</goal>\n                <!-- runs at process-test-classes phase -->\n              </goals>\n            </execution>\n          </executions>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-enforcer-plugin</artifactId>\n          <version>${enforcer.version}</version>\n          <dependencies>\n            <dependency>\n              <groupId>org.codehaus.mojo</groupId>\n              <artifactId>extra-enforcer-rules</artifactId>\n              <version>${extra.enforcer.version}</version>\n            </dependency>\n            <dependency>\n              <groupId>de.skuzzle.enforcer</groupId>\n              <artifactId>restrict-imports-enforcer-rule</artifactId>\n              <version>${restrict-imports.enforcer.version}</version>\n            </dependency>\n          </dependencies>\n        </plugin>\n        <plugin>\n          <groupId>org.apache.maven.plugins</groupId>\n          <artifactId>maven-gpg-plugin</artifactId>\n          <version>${maven.gpg.version}</version>\n        </plugin>\n      </plugins>\n    </pluginManagement>\n    <plugins>\n      <plugin>\n        <groupId>org.codehaus.mojo</groupId>\n        <artifactId>flatten-maven-plugin</artifactId>\n        <version>1.3.0</version>\n        <configuration>\n          <embedBuildProfileDependencies>true</embedBuildProfileDependencies>\n          <updatePomFile>true</updatePomFile>\n          <flattenMode>oss</flattenMode>\n        </configuration>\n        <executions>\n          <!-- enable flattening -->\n          <execution>\n            <id>flatten</id>\n            <goals>\n              <goal>flatten</goal>\n            </goals>\n            <phase>process-resources</phase>\n          </execution>\n          <!-- ensure proper cleanup -->\n          <execution>\n            <id>flatten.clean</id>\n            <goals>\n              <goal>clean</goal>\n            </goals>\n            <phase>clean</phase>\n          </execution>\n        </executions>\n      </plugin>\n      <plugin>\n        <groupId>org.codehaus.mojo</groupId>\n        <artifactId>build-helper-maven-plugin</artifactId>\n        <executions>\n          <execution>\n            <id>negate-license-bundles-property</id>\n            <goals>\n              <goal>bsh-property</goal>\n            </goals>\n            <configuration>\n              <source>skip.license.check = !${license.bundles.dependencies};</source>\n              <properties>\n                <property>skip.license.check</property>\n              </properties>\n            </configuration>\n          </execution>\n          <!-- sets where to find the generated LICENSE files -->\n          <execution>\n            <id>create-license-file-path-property</id>\n            <goals>\n              <goal>regex-property</goal>\n            </goals>\n            <configuration>\n              <name>license.aggregate.path</name>\n              <value>${project.build.directory}/maven-shared-archive-resources/META-INF/LICENSE</value>\n              <regex>\\\\</regex>\n              <replacement>/</replacement>\n              <failIfNoMatch>false</failIfNoMatch>\n            </configuration>\n          </execution>\n          <execution>\n            <id>set-current-year</id>\n            <goals>\n              <goal>timestamp-property</goal>\n            </goals>\n            <phase>pre-site</phase>\n            <configuration>\n              <name>current.year</name>\n              <pattern>yyyy</pattern>\n              <unit>year</unit>\n            </configuration>\n          </execution>\n          <execution>\n            <id>set-current-date</id>\n            <goals>\n              <goal>timestamp-property</goal>\n            </goals>\n            <phase>pre-site</phase>\n            <configuration>\n              <name>current.date</name>\n              <pattern>yyyy-MM-dd</pattern>\n              <unit>day</unit>\n            </configuration>\n          </execution>\n        </executions>\n      </plugin>\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-enforcer-plugin</artifactId>\n        <executions>\n          <execution>\n            <id>display-info</id>\n            <goals>\n              <goal>display-info</goal>\n            </goals>\n            <phase>initialize</phase>\n            <inherited>false</inherited>\n          </execution>\n          <execution>\n            <id>hadoop-profile-min-maven-min-java-banned-xerces</id>\n            <goals>\n              <goal>enforce</goal>\n            </goals>\n            <configuration>\n              <rules>\n                <!-- Help people activate profiles correctly -->\n                <evaluateBeanshell>\n                  <condition>System.getProperty(\"hadoop-profile\", \"\").isEmpty()</condition>\n                  <message>The hadoop-profile property is unused, did you mean to set hadoop.profile instead?</message>\n                </evaluateBeanshell>\n                <!-- The earliest maven version we verify builds for via ASF Jenkins -->\n                <requireMavenVersion>\n                  <version>[${maven.min.version},)</version>\n                  <message>Maven is out of date.\n  HBase requires at least version ${maven.min.version} of Maven to properly build from source.\n  You appear to be using an older version. You can use either \"mvn -version\" or\n  \"mvn enforcer:display-info\" to verify what version is active.\n  See the reference guide on building for more information: https://hbase.apache.org/book.html#build</message>\n                </requireMavenVersion>\n                <!-- The earliest JVM version we verify builds for via ASF Jenkins -->\n                <requireJavaVersion>\n                  <version>[${java.min.version},)</version>\n                  <message>Java is out of date.\n  HBase requires at least version ${java.min.version} of the JDK to properly build from source.\n  You appear to be using an older version. You can use either \"mvn -version\" or\n  \"mvn enforcer:display-info\" to verify what version is active.\n  See the reference guide on building for more information: https://hbase.apache.org/book.html#build</message>\n                </requireJavaVersion>\n                <bannedDependencies>\n                  <excludes>\n                    <exclude>xerces:xercesImpl</exclude>\n                  </excludes>\n                  <message>We avoid adding our own Xerces jars to the classpath, see HBASE-16340.</message>\n                </bannedDependencies>\n              </rules>\n            </configuration>\n          </execution>\n          <execution>\n            <id>banned-jsr305</id>\n            <goals>\n              <goal>enforce</goal>\n            </goals>\n            <configuration>\n              <rules>\n                <bannedDependencies>\n                  <excludes>\n                    <exclude>com.google.code.findbugs:jsr305</exclude>\n                  </excludes>\n                  <message>We don't allow the JSR305 jar from the Findbugs project, see HBASE-16321.</message>\n                </bannedDependencies>\n              </rules>\n            </configuration>\n          </execution>\n          <execution>\n            <id>banned-scala</id>\n            <goals>\n              <goal>enforce</goal>\n            </goals>\n            <configuration>\n              <rules>\n                <bannedDependencies>\n                  <excludes>\n                    <exclude>org.scala-lang:scala-library</exclude>\n                  </excludes>\n                  <message>We don't allow Scala, see HBASE-13992.</message>\n                </bannedDependencies>\n              </rules>\n            </configuration>\n          </execution>\n          <execution>\n            <id>banned-commons-logging</id>\n            <goals>\n              <goal>enforce</goal>\n            </goals>\n            <configuration>\n              <rules>\n                <bannedDependencies>\n                  <excludes>\n                    <exclude>commons-logging:commons-logging</exclude>\n                  </excludes>\n                  <message>We don't use commons-logging any more, so do not depend on it directly.</message>\n                  <searchTransitive>false</searchTransitive>\n                </bannedDependencies>\n              </rules>\n            </configuration>\n          </execution>\n          <execution>\n            <id>banned-other-logging-framework</id>\n            <goals>\n              <goal>enforce</goal>\n            </goals>\n            <configuration>\n              <rules>\n                <bannedDependencies>\n                  <excludes>\n                    <exclude>log4j:*</exclude>\n                    <exclude>org.slf4j:slf4j-log4j12</exclude>\n                    <exclude>ch.qos.reload4j:*</exclude>\n                    <exclude>org.slf4j:slf4j-reload4j</exclude>\n                    <exclude>ch.qos.logback:*</exclude>\n                  </excludes>\n                  <message>We do not allow other logging frameworks as now we use log4j2</message>\n                </bannedDependencies>\n              </rules>\n            </configuration>\n          </execution>\n          <execution>\n            <id>banned-jetty</id>\n            <goals>\n              <goal>enforce</goal>\n            </goals>\n            <configuration>\n              <rules>\n                <bannedDependencies>\n                  <excludes>\n                    <exclude>org.eclipse.jetty:**</exclude>\n                  </excludes>\n                  <message>Use shaded jetty instead</message>\n                  <searchTransitive>false</searchTransitive>\n                </bannedDependencies>\n              </rules>\n            </configuration>\n          </execution>\n          <execution>\n            <id>banned-jersey</id>\n            <goals>\n              <goal>enforce</goal>\n            </goals>\n            <configuration>\n              <rules>\n                <bannedDependencies>\n                  <excludes>\n                    <exclude>org.glassfish.jersey.containers:**</exclude>\n                    <exclude>org.glassfish.jersey.core:**</exclude>\n                  </excludes>\n                  <message>Use shaded jersey instead</message>\n                  <searchTransitive>false</searchTransitive>\n                </bannedDependencies>\n              </rules>\n            </configuration>\n          </execution>\n          <execution>\n            <id>banned-htrace</id>\n            <goals>\n              <goal>enforce</goal>\n            </goals>\n            <configuration>\n              <rules>\n                <bannedDependencies>\n                  <excludes>\n                    <exclude>org.apache.htrace:**</exclude>\n                  </excludes>\n                  <message>Use OpenTelemetry instead</message>\n                  <searchTransitive>false</searchTransitive>\n                </bannedDependencies>\n              </rules>\n            </configuration>\n          </execution>\n          <execution>\n            <id>banned-bouncycastle-jdk15on</id>\n            <goals>\n              <goal>enforce</goal>\n            </goals>\n            <configuration>\n              <rules>\n                <bannedDependencies>\n                  <excludes>\n                    <exclude>org.bouncycastle:*-jdk15on</exclude>\n                  </excludes>\n                  <message>Use org.bouncycastle:*-jdk18on instead</message>\n                  <searchTransitive>true</searchTransitive>\n                </bannedDependencies>\n              </rules>\n            </configuration>\n          </execution>\n          <execution>\n            <id>check-aggregate-license</id>\n            <goals>\n              <goal>enforce</goal>\n            </goals>\n            <!-- must check after LICENSE is built at 'generate-resources' -->\n            <phase>process-resources</phase>\n            <configuration>\n              <rules>\n                <evaluateBeanshell>\n                  <condition>File license = new File(\"${license.aggregate.path}\");\n\n                    // Beanshell does not support try-with-resources,\n                    // so we must close this scanner manually\n                    Scanner scanner = new Scanner(license);\n\n                    while (scanner.hasNextLine()) {\n                      if (scanner.nextLine().startsWith(\"ERROR:\")) {\n                        scanner.close();\n                        return false;\n                      }\n                    }\n                    scanner.close();\n                    return true;</condition>\n                  <message>License errors detected, for more detail find ERROR in\n                    ${license.aggregate.path}</message>\n                </evaluateBeanshell>\n              </rules>\n              <skip>${skip.license.check}</skip>\n            </configuration>\n          </execution>\n          <execution>\n            <id>banned-illegal-imports</id>\n            <goals>\n              <goal>enforce</goal>\n            </goals>\n            <phase>process-sources</phase>\n            <configuration>\n              <rules>\n                <restrictImports implementation=\"de.skuzzle.enforcer.restrictimports.rule.RestrictImports\">\n                  <includeTestCode>true</includeTestCode>\n                  <commentLineBufferSize>512</commentLineBufferSize>\n                  <reason>Use SLF4j for logging</reason>\n                  <bannedImports>\n                    <bannedImport>org.apache.commons.logging.**</bannedImport>\n                    <bannedImport>org.apache.log4j.**</bannedImport>\n                    <bannedImport>org.apache.logging.log4j.**</bannedImport>\n                  </bannedImports>\n                  <exclusions>\n                    <!-- Exclude this one as it is a log4j2 appender implementation -->\n                    <exclusion>org.apache.hadoop.hbase.logging.HBaseTestAppender</exclusion>\n                  </exclusions>\n                </restrictImports>\n                <restrictImports implementation=\"de.skuzzle.enforcer.restrictimports.rule.RestrictImports\">\n                  <includeTestCode>false</includeTestCode>\n                  <commentLineBufferSize>512</commentLineBufferSize>\n                  <reason>Do not use log4j2 directly in code, see Log4jUtils in hbase-logging for more details.</reason>\n                  <bannedImports>\n                    <bannedImport>org.apache.logging.log4j.**</bannedImport>\n                  </bannedImports>\n                </restrictImports>\n                <restrictImports implementation=\"de.skuzzle.enforcer.restrictimports.rule.RestrictImports\">\n                  <includeTestCode>true</includeTestCode>\n                  <commentLineBufferSize>512</commentLineBufferSize>\n                  <reason>Use shaded version in hbase-thirdparty</reason>\n                  <bannedImports>\n                    <bannedImport>com.google.common.**</bannedImport>\n                    <bannedImport>io.netty.**</bannedImport>\n                    <bannedImport>org.apache.commons.cli.**</bannedImport>\n                    <bannedImport>org.apache.commons.collections.**</bannedImport>\n                    <bannedImport>org.apache.commons.collections4.**</bannedImport>\n                    <bannedImport>org.apache.hadoop.thirdparty.**</bannedImport>\n                  </bannedImports>\n                </restrictImports>\n                <restrictImports implementation=\"de.skuzzle.enforcer.restrictimports.rule.RestrictImports\">\n                  <includeTestCode>true</includeTestCode>\n                  <commentLineBufferSize>512</commentLineBufferSize>\n                  <reason>Do not use shaded classes from other dependencies</reason>\n                  <bannedImports>\n                    <bannedImport>org.apache.curator.shaded.**</bannedImport>\n                    <bannedImport>org.apache.htrace.shaded.**</bannedImport>\n                  </bannedImports>\n                </restrictImports>\n                <restrictImports implementation=\"de.skuzzle.enforcer.restrictimports.rule.RestrictImports\">\n                  <includeTestCode>true</includeTestCode>\n                  <commentLineBufferSize>512</commentLineBufferSize>\n                  <reason>Use shaded gson in hbase-thirdparty</reason>\n                  <bannedImports>\n                    <bannedImport>org.codehaus.jackson.**</bannedImport>\n                  </bannedImports>\n                </restrictImports>\n                <restrictImports implementation=\"de.skuzzle.enforcer.restrictimports.rule.RestrictImports\">\n                  <includeTestCode>true</includeTestCode>\n                  <commentLineBufferSize>512</commentLineBufferSize>\n                  <reason>Use commons lang 3</reason>\n                  <bannedImports>\n                    <bannedImport>org.apache.commons.lang.**</bannedImport>\n                  </bannedImports>\n                </restrictImports>\n                <restrictImports implementation=\"de.skuzzle.enforcer.restrictimports.rule.RestrictImports\">\n                  <includeTestCode>true</includeTestCode>\n                  <commentLineBufferSize>512</commentLineBufferSize>\n                  <reason>Use yetus IA and IS annotations</reason>\n                  <bannedImports>\n                    <bannedImport>org.apache.hadoop.classificatio.**</bannedImport>\n                  </bannedImports>\n                </restrictImports>\n                <restrictImports implementation=\"de.skuzzle.enforcer.restrictimports.rule.RestrictImports\">\n                  <includeTestCode>true</includeTestCode>\n                  <commentLineBufferSize>512</commentLineBufferSize>\n                  <reason>Do not use htrace</reason>\n                  <bannedImports>\n                    <bannedImport>org.htrace.**</bannedImport>\n                    <bannedImport>org.apache.htrace.**</bannedImport>\n                  </bannedImports>\n                </restrictImports>\n                <restrictImports implementation=\"de.skuzzle.enforcer.restrictimports.rule.RestrictImports\">\n                  <includeTestCode>true</includeTestCode>\n                  <commentLineBufferSize>512</commentLineBufferSize>\n                  <reason>Use shaded jetty in hbase-thirdparty</reason>\n                  <bannedImports>\n                    <bannedImport>org.eclipse.jetty.**</bannedImport>\n                  </bannedImports>\n                </restrictImports>\n                <restrictImports implementation=\"de.skuzzle.enforcer.restrictimports.rule.RestrictImports\">\n                  <includeTestCode>true</includeTestCode>\n                  <commentLineBufferSize>512</commentLineBufferSize>\n                  <reason>Use shaded jersey in hbase-thirdparty</reason>\n                  <bannedImports>\n                    <bannedImport>org.glassfish.jersey.**</bannedImport>\n                  </bannedImports>\n                </restrictImports>\n                <restrictImports implementation=\"de.skuzzle.enforcer.restrictimports.rule.RestrictImports\">\n                  <includeTestCode>true</includeTestCode>\n                  <commentLineBufferSize>512</commentLineBufferSize>\n                  <reason>You should never use this style of annotations(i.e, 'this is for test only')\n                    in IA.Public or IA.LimitedPrivate classes. Use IA.Private to tell users this is\n                    not for public use.\n                    For IA.Private classes, use RestrictedApi annotation in error prone instead.</reason>\n                  <bannedImports>\n                    <bannedImport>org.apache.hbase.thirdparty.com.google.common.annotations.VisibleForTesting</bannedImport>\n                  </bannedImports>\n                </restrictImports>\n                <restrictImports implementation=\"de.skuzzle.enforcer.restrictimports.rule.RestrictImports\">\n                  <includeTestCode>true</includeTestCode>\n                  <commentLineBufferSize>512</commentLineBufferSize>\n                  <reason>Use shaded javax.ws.rs in hbase-thirdparty</reason>\n                  <bannedImports>\n                    <bannedImport>javax.ws.rs.**</bannedImport>\n                  </bannedImports>\n                </restrictImports>\n                <restrictImports implementation=\"de.skuzzle.enforcer.restrictimports.rule.RestrictImports\">\n                  <includeTestCode>true</includeTestCode>\n                  <commentLineBufferSize>512</commentLineBufferSize>\n                  <reason>Use shaded jackson-jaxrs-json-provider in hbase-thirdparty</reason>\n                  <bannedImports>\n                    <bannedImport>com.fasterxml.jackson.jaxrs.**</bannedImport>\n                  </bannedImports>\n                </restrictImports>\n                <restrictImports implementation=\"de.skuzzle.enforcer.restrictimports.rule.RestrictImports\">\n                  <includeTestCode>true</includeTestCode>\n                  <commentLineBufferSize>512</commentLineBufferSize>\n                  <reason>Use junit4 instead</reason>\n                  <bannedImports>\n                    <bannedImport>junit.framework.**</bannedImport>\n                  </bannedImports>\n                </restrictImports>\n              </rules>\n            </configuration>\n          </execution>\n        </executions>\n      </plugin>\n      <!-- Make a jar and put the sources in the jar -->\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-source-plugin</artifactId>\n      </plugin>\n      <!-- parent-module only plugins -->\n      <plugin>\n        <groupId>org.codehaus.mojo</groupId>\n        <artifactId>xml-maven-plugin</artifactId>\n        <version>${xml.maven.version}</version>\n        <inherited>false</inherited>\n        <configuration>\n          <transformationSets>\n            <!-- For asciidoc -->\n            <transformationSet>\n              <!--Reaching up and over into common sub-module for hbase-default.xml-->\n              <dir>${basedir}/hbase-common/src/main/resources/</dir>\n              <includes>\n                <include>hbase-default.xml</include>\n              </includes>\n              <stylesheet>${basedir}/src/main/xslt/configuration_to_asciidoc_chapter.xsl</stylesheet>\n              <fileMappers>\n                <fileMapper implementation=\"org.codehaus.plexus.components.io.filemappers.RegExpFileMapper\">\n                  <pattern>^(.*)\\.xml$</pattern>\n                  <replacement>$1.adoc</replacement>\n                </fileMapper>\n              </fileMappers>\n              <outputDir>${basedir}/target/asciidoc</outputDir>\n            </transformationSet>\n          </transformationSets>\n        </configuration>\n        <executions>\n          <execution>\n            <!-- Run the hbase-default.xml through a stylesheet so can show it in doc-->\n            <goals>\n              <goal>transform</goal>\n            </goals>\n            <phase>site</phase>\n          </execution>\n        </executions>\n      </plugin>\n      <!-- Special configuration for spotbugs just in the parent so\n      the filter file location can be more general (see definition in pluginManagement) -->\n      <plugin>\n        <groupId>com.github.spotbugs</groupId>\n        <artifactId>spotbugs-maven-plugin</artifactId>\n        <executions>\n          <execution>\n            <goals>\n              <goal>spotbugs</goal>\n            </goals>\n            <inherited>false</inherited>\n            <configuration>\n              <excludeFilterFile>${basedir}/dev-support/spotbugs-exclude.xml</excludeFilterFile>\n            </configuration>\n          </execution>\n        </executions>\n      </plugin>\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-checkstyle-plugin</artifactId>\n      </plugin>\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-site-plugin</artifactId>\n        <version>${maven-site.version}</version>\n        <configuration>\n          <siteDirectory>${basedir}/src/site</siteDirectory>\n          <customBundle>${basedir}/src/site/custom/project-info-report.properties</customBundle>\n          <inputEncoding>UTF-8</inputEncoding>\n          <outputEncoding>UTF-8</outputEncoding>\n        </configuration>\n        <dependencies>\n          <dependency>\n            <!-- add support for ssh/scp -->\n            <groupId>org.apache.maven.wagon</groupId>\n            <artifactId>wagon-ssh</artifactId>\n            <version>${wagon.ssh.version}</version>\n          </dependency>\n        </dependencies>\n      </plugin>\n      <!-- For AsciiDoc docs building -->\n      <plugin>\n        <groupId>org.asciidoctor</groupId>\n        <artifactId>asciidoctor-maven-plugin</artifactId>\n        <version>${asciidoctor.plugin.version}</version>\n        <inherited>false</inherited>\n        <configuration>\n          <outputDirectory>${project.reporting.outputDirectory}/</outputDirectory>\n          <doctype>book</doctype>\n          <attributes>\n            <docVersion>${project.version}</docVersion>\n            <imagesdir>images</imagesdir>\n            <source-highlighter>coderay</source-highlighter>\n          </attributes>\n        </configuration>\n        <dependencies>\n          <dependency>\n            <groupId>org.asciidoctor</groupId>\n            <artifactId>asciidoctorj-pdf</artifactId>\n            <version>${asciidoctorj.pdf.version}</version>\n          </dependency>\n        </dependencies>\n        <executions>\n          <execution>\n            <id>output-html</id>\n            <goals>\n              <goal>process-asciidoc</goal>\n            </goals>\n            <phase>site</phase>\n            <configuration>\n              <attributes>\n                <stylesheet>hbase.css</stylesheet>\n              </attributes>\n              <backend>html5</backend>\n            </configuration>\n          </execution>\n          <execution>\n            <id>output-pdf</id>\n            <goals>\n              <goal>process-asciidoc</goal>\n            </goals>\n            <phase>site</phase>\n            <configuration>\n              <backend>pdf</backend>\n              <attributes>\n                <pagenums/>\n                <toc/>\n                <idprefix/>\n                <idseparator>-</idseparator>\n              </attributes>\n            </configuration>\n          </execution>\n        </executions>\n      </plugin>\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-resources-plugin</artifactId>\n        <!--$NO-MVN-MAN-VER$ -->\n        <inherited>false</inherited>\n        <configuration>\n          <escapeString>\\</escapeString>\n        </configuration>\n        <executions>\n          <execution>\n            <id>copy-htaccess</id>\n            <goals>\n              <goal>copy-resources</goal>\n            </goals>\n            <phase>site</phase>\n            <configuration>\n              <outputDirectory>${project.reporting.outputDirectory}/</outputDirectory>\n              <resources>\n                <resource>\n                  <directory>${basedir}/src/site/resources/</directory>\n                  <includes>\n                    <include>.htaccess</include>\n                  </includes>\n                </resource>\n              </resources>\n            </configuration>\n          </execution>\n          <!-- needed to make the redirect above work -->\n          <execution>\n            <id>copy-empty-book-dir</id>\n            <goals>\n              <goal>copy-resources</goal>\n            </goals>\n            <phase>site</phase>\n            <configuration>\n              <outputDirectory>${project.reporting.outputDirectory}/</outputDirectory>\n              <resources>\n                <resource>\n                  <directory>${basedir}/src/site/resources/</directory>\n                  <includes>\n                    <include>book/**</include>\n                  </includes>\n                </resource>\n              </resources>\n            </configuration>\n          </execution>\n        </executions>\n      </plugin>\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-antrun-plugin</artifactId>\n        <version>${maven.antrun.version}</version>\n        <inherited>false</inherited>\n        <!-- Rename the book.pdf generated by asciidoctor -->\n        <executions>\n          <execution>\n            <id>rename-pdf</id>\n            <goals>\n              <goal>run</goal>\n            </goals>\n            <phase>site</phase>\n            <configuration>\n              <target name=\"rename file\">\n                <move file=\"${project.reporting.outputDirectory}/book.pdf\" tofile=\"${project.reporting.outputDirectory}/apache_hbase_reference_guide.pdf\"/>\n              </target>\n            </configuration>\n          </execution>\n        </executions>\n      </plugin>\n      <plugin>\n        <groupId>org.codehaus.mojo</groupId>\n        <artifactId>buildnumber-maven-plugin</artifactId>\n        <configuration>\n          <timestampFormat>yyyy</timestampFormat>\n          <timestampPropertyName>build.year</timestampPropertyName>\n        </configuration>\n        <executions>\n          <execution>\n            <goals>\n              <goal>create-timestamp</goal>\n            </goals>\n            <phase>validate</phase>\n          </execution>\n        </executions>\n      </plugin>\n      <plugin>\n        <groupId>org.apache.felix</groupId>\n        <artifactId>maven-bundle-plugin</artifactId>\n        <version>${maven.bundle.version}</version>\n        <extensions>true</extensions>\n        <inherited>true</inherited>\n      </plugin>\n      <plugin>\n        <groupId>com.diffplug.spotless</groupId>\n        <artifactId>spotless-maven-plugin</artifactId>\n        <version>${spotless.version}</version>\n        <configuration>\n          <!-- define a language-specific format -->\n          <java>\n            <excludes>\n              <exclude>**/generated/*</exclude>\n              <exclude>**/package-info.java</exclude>\n              <exclude>**/.idea/**</exclude>\n            </excludes>\n            <!--\n              e.g., remove the following lines:\n              \"* @param paramName\"\n              \"* @throws ExceptionType\"\n              \"* @return returnType\"'\n              Multiline to allow anchors on newlines\n              See https://errorprone.info/bugpattern/EmptyBlockTag\n            -->\n            <replaceRegex>\n              <name>Remove unhelpful javadoc stubs</name>\n              <searchRegex>(?m)^ *\\* *@(?:param|throws|return) *\\w* *\\n</searchRegex>\n              <replacement/>\n            </replaceRegex>\n            <!--\n              e.g., rewrite\n              /** @return blabla */\n              or\n              /**\n               * @return blabla\n               */\n              to\n              /** Returns blabla */\n              See https://errorprone.info/bugpattern/MissingSummary\n              https://google.github.io/styleguide/javaguide.html#s7.2-summary-fragment\n            -->\n            <replaceRegex>\n              <name>Purge single returns tag multi line</name>\n              <searchRegex>(?m)^ */\\*\\*\\n *\\* *@return *(.*) *\\n *\\*/$</searchRegex>\n              <replacement>/** Returns $1 */</replacement>\n            </replaceRegex>\n            <replaceRegex>\n              <name>Purge single returns tag single line</name>\n              <searchRegex>^ */\\*\\* *@return *(.*) *\\*/$</searchRegex>\n              <replacement>/** Returns $1 */</replacement>\n            </replaceRegex>\n            <!-- apply a specific flavor -->\n            <eclipse>\n              <file>${session.executionRootDirectory}/dev-support/hbase_eclipse_formatter.xml</file>\n            </eclipse>\n            <importOrder>\n              <file>${session.executionRootDirectory}/dev-support/eclipse.importorder</file>\n            </importOrder>\n            <trimTrailingWhitespace/>\n            <endWithNewline/>\n            <removeUnusedImports/>\n          </java>\n          <pom>\n            <sortPom>\n              <expandEmptyElements>false</expandEmptyElements>\n            </sortPom>\n          </pom>\n          <formats>\n            <!-- you can define as many formats as you want, each is independent -->\n            <format>\n              <!-- define the files to apply to -->\n              <includes>\n                <include>**/*.xml</include>\n                <include>**/*.sh</include>\n                <include>**/*.py</include>\n                <include>**/Jenkinsfile*</include>\n                <include>**/*.md</include>\n                <include>*.md</include>\n                <include>**/*.txt</include>\n                <include>*.txt</include>\n              </includes>\n              <excludes>\n                <exclude>**/target/**</exclude>\n                <exclude>**/dependency-reduced-pom.xml</exclude>\n                <exclude>**/.idea/**</exclude>\n              </excludes>\n              <!-- define the steps to apply to those files -->\n              <trimTrailingWhitespace/>\n              <endWithNewline/>\n            </format>\n            <format>\n              <!--\n                We have some files which have special license header which must be kept, so\n                here we add a special format section to apply license header, and leave the\n                java section above only used for formatting code style\n              -->\n              <includes>\n                <include>src/main/java/**/*.java</include>\n                <include>src/test/java/**/*.java</include>\n              </includes>\n              <excludes>\n                <exclude>**/generated/*</exclude>\n                <exclude>**/package-info.java</exclude>\n                <!-- ByteRange, from Google protobuf -->\n                <exclude>src/main/java/org/apache/hadoop/hbase/util/AbstractByteRange.java</exclude>\n                <exclude>src/main/java/org/apache/hadoop/hbase/util/SimpleMutableByteRange.java</exclude>\n                <exclude>src/main/java/org/apache/hadoop/hbase/util/SimplePositionedMutableByteRange.java</exclude>\n                <!-- Metrics, from Josh Elser -->\n                <exclude>src/main/java/org/apache/hadoop/hbase/metrics/impl/HBaseMetrics2HadoopMetricsAdapter.java</exclude>\n                <!-- https://github.com/ept/warc-hadoop, from Martin Kleppmann -->\n                <exclude>src/test/java/org/apache/hadoop/hbase/test/util/warc/WARCFileReader.java</exclude>\n                <exclude>src/test/java/org/apache/hadoop/hbase/test/util/warc/WARCFileWriter.java</exclude>\n                <exclude>src/test/java/org/apache/hadoop/hbase/test/util/warc/WARCInputFormat.java</exclude>\n                <exclude>src/test/java/org/apache/hadoop/hbase/test/util/warc/WARCOutputFormat.java</exclude>\n                <exclude>src/test/java/org/apache/hadoop/hbase/test/util/warc/WARCRecord.java</exclude>\n                <exclude>src/test/java/org/apache/hadoop/hbase/test/util/warc/WARCWritable.java</exclude>\n              </excludes>\n              <licenseHeader>\n                <file>${session.executionRootDirectory}/dev-support/license-header</file>\n                <delimiter>package</delimiter>\n              </licenseHeader>\n            </format>\n          </formats>\n        </configuration>\n      </plugin>\n    </plugins>\n    <extensions>\n      <extension>\n        <groupId>kr.motd.maven</groupId>\n        <artifactId>os-maven-plugin</artifactId>\n        <version>${os.maven.version}</version>\n      </extension>\n    </extensions>\n  </build>\n  <!-- See https://jira.codehaus.org/browse/MSITE-443 why the settings need to be here and not in pluginManagement. -->\n  <reporting>\n    <plugins>\n      <plugin>\n        <artifactId>maven-project-info-reports-plugin</artifactId>\n        <version>${maven.project.info.report.version}</version>\n        <!-- see src/site/site.xml for selected reports -->\n        <configuration>\n          <dependencyLocationsEnabled>false</dependencyLocationsEnabled>\n        </configuration>\n        <reportSets>\n          <reportSet>\n            <reports>\n              <report>dependencies</report>\n              <report>dependency-convergence</report>\n              <report>dependency-info</report>\n              <report>dependency-management</report>\n              <report>index</report>\n              <report>issue-management</report>\n              <report>licenses</report>\n              <report>mailing-lists</report>\n              <report>plugin-management</report>\n              <report>plugins</report>\n              <report>team</report>\n              <report>scm</report>\n              <report>summary</report>\n            </reports>\n          </reportSet>\n        </reportSets>\n      </plugin>\n\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-javadoc-plugin</artifactId>\n        <configuration>\n          <tags>\n            <tag>\n              <name>apiNote</name>\n              <placement>a</placement>\n              <head>API Note:</head>\n            </tag>\n          </tags>\n        </configuration>\n        <reportSets>\n          <!-- Dev API -->\n          <reportSet>\n            <id>devapi</id>\n            <reports>\n              <report>aggregate-no-fork</report>\n            </reports>\n            <configuration>\n              <destDir>devapidocs</destDir>\n              <name>Developer API</name>\n              <description>The full HBase API, including private and unstable APIs</description>\n              <doctitle>Apache HBase ${project.version} API</doctitle>\n              <sourceFileExcludes>\n                <exclude>**/generated/*</exclude>\n                <exclude>**/protobuf/*</exclude>\n              </sourceFileExcludes>\n              <excludePackageNames>org.apache.hadoop.hbase.tmpl.common:com.google.protobuf:org.apache.hadoop.hbase.generated*</excludePackageNames>\n              <show>private</show>\n              <!-- (shows all classes and members) -->\n              <quiet>true</quiet>\n              <linksource>true</linksource>\n              <sourcetab>2</sourcetab>\n              <validateLinks>true</validateLinks>\n              <fixClassComment>true</fixClassComment>\n              <fixFieldComment>true</fixFieldComment>\n              <fixMethodComment>true</fixMethodComment>\n              <fixTags>all</fixTags>\n              <notimestamp>true</notimestamp>\n              <locale>en_US</locale>\n              <!-- Pass some options straight to the javadoc executable since it is easier -->\n              <additionalJOption>-J-Xmx2G</additionalJOption>\n              <!-- JDK8 javadoc requires test scope transitive dependencies due to our custom doclet -->\n              <additionalDependencies>\n                <additionalDependency>\n                  <groupId>org.mockito</groupId>\n                  <artifactId>mockito-core</artifactId>\n                  <version>${mockito.version}</version>\n                </additionalDependency>\n                <additionalDependency>\n                  <groupId>org.hamcrest</groupId>\n                  <artifactId>hamcrest-core</artifactId>\n                  <version>${hamcrest.version}</version>\n                </additionalDependency>\n                <!-- javadoc tooling requires jsr305 due to references to it from things we rely on -->\n                <additionalDependency>\n                  <groupId>com.google.code.findbugs</groupId>\n                  <artifactId>jsr305</artifactId>\n                  <version>3.0.2</version>\n                </additionalDependency>\n              </additionalDependencies>\n              <inherited>false</inherited>\n            </configuration>\n          </reportSet>\n          <reportSet>\n            <id>testdevapi</id>\n            <reports>\n              <report>test-aggregate-no-fork</report>\n            </reports>\n            <configuration>\n              <destDir>testdevapidocs</destDir>\n              <name>Test Developer API</name>\n              <description>The full HBase API test code, including private and unstable APIs</description>\n              <testDoctitle>Apache HBase ${project.version} Test API</testDoctitle>\n              <sourceFileExcludes>\n                <exclude>**/generated/*</exclude>\n                <exclude>**/protobuf/*</exclude>\n              </sourceFileExcludes>\n              <excludePackageNames>org.apache.hadoop.hbase.tmpl.common:com.google.protobuf:org.apache.hadoop.hbase.generated*</excludePackageNames>\n              <show>private</show>\n              <!-- (shows all classes and members) -->\n              <quiet>true</quiet>\n              <linksource>true</linksource>\n              <sourcetab>2</sourcetab>\n              <validateLinks>true</validateLinks>\n              <fixClassComment>true</fixClassComment>\n              <fixFieldComment>true</fixFieldComment>\n              <fixMethodComment>true</fixMethodComment>\n              <fixTags>all</fixTags>\n              <notimestamp>true</notimestamp>\n              <locale>en_US</locale>\n              <!-- Pass some options straight to the javadoc executable since it is easier -->\n              <additionalJOption>-J-Xmx2G</additionalJOption>\n              <!-- JDK8 javadoc requires test scope transitive dependencies due to our custom doclet -->\n              <additionalDependencies>\n                <additionalDependency>\n                  <groupId>org.mockito</groupId>\n                  <artifactId>mockito-core</artifactId>\n                  <version>${mockito.version}</version>\n                </additionalDependency>\n                <additionalDependency>\n                  <groupId>org.hamcrest</groupId>\n                  <artifactId>hamcrest-core</artifactId>\n                  <version>${hamcrest.version}</version>\n                </additionalDependency>\n                <!-- javadoc tooling requires jsr305 due to references to it from things we rely on -->\n                <additionalDependency>\n                  <groupId>com.google.code.findbugs</groupId>\n                  <artifactId>jsr305</artifactId>\n                  <version>3.0.2</version>\n                </additionalDependency>\n              </additionalDependencies>\n              <inherited>false</inherited>\n            </configuration>\n          </reportSet>\n\n          <!-- User API -->\n          <reportSet>\n            <id>userapi</id>\n            <reports>\n              <report>aggregate-no-fork</report>\n            </reports>\n            <configuration>\n              <doclet>org.apache.yetus.audience.tools.IncludePublicAnnotationsStandardDoclet</doclet>\n              <docletArtifact>\n                <groupId>org.apache.yetus</groupId>\n                <artifactId>audience-annotations</artifactId>\n                <version>${javadoc.audience-annotations.version}</version>\n              </docletArtifact>\n              <useStandardDocletOptions>true</useStandardDocletOptions>\n              <destDir>apidocs</destDir>\n              <name>User API</name>\n              <description>The HBase Application Programmer's API</description>\n              <doctitle>Apache HBase ${project.version} API</doctitle>\n              <excludePackageNames>org.apache.hadoop.hbase.backup*:org.apache.hadoop.hbase.catalog:org.apache.hadoop.hbase.client.coprocessor:org.apache.hadoop.hbase.client.metrics:org.apache.hadoop.hbase.codec*:org.apache.hadoop.hbase.constraint:org.apache.hadoop.hbase.coprocessor.*:org.apache.hadoop.hbase.executor:org.apache.hadoop.hbase.fs:*.generated.*:org.apache.hadoop.hbase.io.hfile.*:org.apache.hadoop.hbase.mapreduce.hadoopbackport:org.apache.hadoop.hbase.mapreduce.replication:org.apache.hadoop.hbase.master.*:org.apache.hadoop.hbase.metrics*:org.apache.hadoop.hbase.migration:org.apache.hadoop.hbase.monitoring:org.apache.hadoop.hbase.p*:org.apache.hadoop.hbase.regionserver.compactions:org.apache.hadoop.hbase.regionserver.handler:org.apache.hadoop.hbase.regionserver.snapshot:org.apache.hadoop.hbase.replication.*:org.apache.hadoop.hbase.rest.filter:org.apache.hadoop.hbase.rest.model:org.apache.hadoop.hbase.rest.p*:org.apache.hadoop.hbase.security.*:org.apache.hadoop.hbase.thrift*:org.apache.hadoop.hbase.tmpl.*:org.apache.hadoop.hbase.tool:org.apache.hadoop.hbase.trace:org.apache.hadoop.hbase.util.byterange*:org.apache.hadoop.hbase.util.test:org.apache.hadoop.hbase.util.vint:org.apache.hadoop.metrics2*:org.apache.hadoop.hbase.io.compress*</excludePackageNames>\n              <!-- switch on dependency-driven aggregation -->\n              <includeDependencySources>false</includeDependencySources>\n              <sourceFilesExclude>**/generated/*</sourceFilesExclude>\n              <show>protected</show>\n              <!-- (shows only public and protected classes and members) -->\n              <quiet>true</quiet>\n              <linksource>true</linksource>\n              <sourcetab>2</sourcetab>\n              <validateLinks>true</validateLinks>\n              <fixClassComment>true</fixClassComment>\n              <fixFieldComment>true</fixFieldComment>\n              <fixMethodComment>true</fixMethodComment>\n              <fixTags>all</fixTags>\n              <notimestamp>true</notimestamp>\n              <locale>en_US</locale>\n              <!-- Pass some options straight to the javadoc executable since it is easier -->\n              <additionalJOption>-J-Xmx2G</additionalJOption>\n              <!-- JDK8 javadoc requires test scope transitive dependencies due to our custom doclet -->\n              <additionalDependencies>\n                <additionalDependency>\n                  <groupId>org.mockito</groupId>\n                  <artifactId>mockito-core</artifactId>\n                  <version>${mockito.version}</version>\n                </additionalDependency>\n                <additionalDependency>\n                  <groupId>org.hamcrest</groupId>\n                  <artifactId>hamcrest-core</artifactId>\n                  <version>${hamcrest.version}</version>\n                </additionalDependency>\n                <!-- javadoc tooling requires jsr305 due to references to it from things we rely on -->\n                <additionalDependency>\n                  <groupId>com.google.code.findbugs</groupId>\n                  <artifactId>jsr305</artifactId>\n                  <version>3.0.2</version>\n                </additionalDependency>\n              </additionalDependencies>\n              <inherited>false</inherited>\n            </configuration>\n          </reportSet>\n          <!-- User Test API -->\n          <reportSet>\n            <id>testuserapi</id>\n            <reports>\n              <report>test-aggregate-no-fork</report>\n            </reports>\n            <configuration>\n              <doclet>org.apache.yetus.audience.tools.IncludePublicAnnotationsStandardDoclet</doclet>\n              <docletArtifact>\n                <groupId>org.apache.yetus</groupId>\n                <artifactId>audience-annotations</artifactId>\n                <version>${javadoc.audience-annotations.version}</version>\n              </docletArtifact>\n              <useStandardDocletOptions>true</useStandardDocletOptions>\n              <destDir>testapidocs</destDir>\n              <name>Test User API</name>\n              <description>The HBase Application Programmer's API test code</description>\n              <testDoctitle>Apache HBase ${project.version} Test API</testDoctitle>\n              <excludePackageNames>org.apache.hadoop.hbase.backup*:org.apache.hadoop.hbase.catalog:org.apache.hadoop.hbase.client.coprocessor:org.apache.hadoop.hbase.client.metrics:org.apache.hadoop.hbase.codec*:org.apache.hadoop.hbase.constraint:org.apache.hadoop.hbase.coprocessor.*:org.apache.hadoop.hbase.executor:org.apache.hadoop.hbase.fs:*.generated.*:org.apache.hadoop.hbase.io.hfile.*:org.apache.hadoop.hbase.mapreduce.hadoopbackport:org.apache.hadoop.hbase.mapreduce.replication:org.apache.hadoop.hbase.master.*:org.apache.hadoop.hbase.metrics*:org.apache.hadoop.hbase.migration:org.apache.hadoop.hbase.monitoring:org.apache.hadoop.hbase.p*:org.apache.hadoop.hbase.regionserver.compactions:org.apache.hadoop.hbase.regionserver.handler:org.apache.hadoop.hbase.regionserver.snapshot:org.apache.hadoop.hbase.replication.*:org.apache.hadoop.hbase.rest.filter:org.apache.hadoop.hbase.rest.model:org.apache.hadoop.hbase.rest.p*:org.apache.hadoop.hbase.security.*:org.apache.hadoop.hbase.thrift*:org.apache.hadoop.hbase.tmpl.*:org.apache.hadoop.hbase.tool:org.apache.hadoop.hbase.trace:org.apache.hadoop.hbase.util.byterange*:org.apache.hadoop.hbase.util.test:org.apache.hadoop.hbase.util.vint:org.apache.hadoop.metrics2*:org.apache.hadoop.hbase.io.compress*</excludePackageNames>\n              <!-- switch on dependency-driven aggregation -->\n              <includeDependencySources>false</includeDependencySources>\n              <sourceFilesExclude>**/generated/*</sourceFilesExclude>\n              <show>protected</show>\n              <!-- (shows only public and protected classes and members) -->\n              <quiet>true</quiet>\n              <linksource>true</linksource>\n              <sourcetab>2</sourcetab>\n              <validateLinks>true</validateLinks>\n              <fixClassComment>true</fixClassComment>\n              <fixFieldComment>true</fixFieldComment>\n              <fixMethodComment>true</fixMethodComment>\n              <fixTags>all</fixTags>\n              <notimestamp>true</notimestamp>\n              <locale>en_US</locale>\n              <!-- Pass some options straight to the javadoc executable since it is easier -->\n              <additionalJOption>-J-Xmx2G</additionalJOption>\n              <!-- JDK8 javadoc requires test scope transitive dependencies due to our custom doclet -->\n              <additionalDependencies>\n                <additionalDependency>\n                  <groupId>org.mockito</groupId>\n                  <artifactId>mockito-core</artifactId>\n                  <version>${mockito.version}</version>\n                </additionalDependency>\n                <additionalDependency>\n                  <groupId>org.hamcrest</groupId>\n                  <artifactId>hamcrest-core</artifactId>\n                  <version>${hamcrest.version}</version>\n                </additionalDependency>\n                <!-- javadoc tooling requires jsr305 due to references to it from things we rely on -->\n                <additionalDependency>\n                  <groupId>com.google.code.findbugs</groupId>\n                  <artifactId>jsr305</artifactId>\n                  <version>3.0.2</version>\n                </additionalDependency>\n              </additionalDependencies>\n              <inherited>false</inherited>\n            </configuration>\n          </reportSet>\n        </reportSets>\n      </plugin>\n\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-checkstyle-plugin</artifactId>\n        <version>${maven.checkstyle.version}</version>\n        <configuration>\n          <excludes>target/**</excludes>\n        </configuration>\n      </plugin>\n\n    </plugins>\n  </reporting>\n\n  <!--\n  To publish, use the following settings.xml file ( placed in ~/.m2/settings.xml )\n\n <settings>\n  <servers>\n    <server>\n      <id>apache.releases.https</id>\n      <username>hbase_committer</username>\n      <password>********</password>\n    </server>\n\n    <server>\n      <id>apache.snapshots.https</id>\n      <username>hbase_committer</username>\n      <password>********</password>\n    </server>\n\n  </servers>\n </settings>\n\n  $ mvn deploy\n(or)\n  $ mvn -s /my/path/settings.xml deploy\n\n  -->\n  <profiles>\n    <profile>\n      <id>build-with-jdk17</id>\n      <activation>\n        <jdk>[17,)</jdk>\n      </activation>\n      <properties>\n        <maven.compiler.release>${releaseTarget}</maven.compiler.release>\n        <argLine>${hbase-surefire.jdk17.flags}\n          ${hbase-surefire.argLine}\n          @{jacocoArgLine}</argLine>\n        <!--\n          Value to use for surefire when running jdk11.\n          TODO: replicate logic for windows\n        -->\n        <surefire.Xmx>2200m</surefire.Xmx>\n      </properties>\n      <build>\n        <pluginManagement>\n          <plugins>\n            <plugin>\n              <groupId>org.apache.maven.plugins</groupId>\n              <artifactId>maven-javadoc-plugin</artifactId>\n              <version>${maven.javadoc.version}</version>\n              <configuration>\n                <source>${compileSource}</source>\n                <!--\n                  Need to add this option to ignore the source errors, epsecially that we reference\n                  test code in hbase-testing-util's main code.\n                -->\n                <additionalOptions>--ignore-source-errors</additionalOptions>\n                <additionalJOptions>\n                  <additionalJOption>-J-Xmx2G</additionalJOption>\n                  <additionalJOption>-J--add-exports</additionalJOption>\n                  <additionalJOption>-Jjdk.javadoc/jdk.javadoc.internal.tool=ALL-UNNAMED</additionalJOption>\n                </additionalJOptions>\n              </configuration>\n            </plugin>\n          </plugins>\n        </pluginManagement>\n      </build>\n    </profile>\n    <!-- profile activated by the Jenkins patch testing job -->\n    <profile>\n      <id>jenkins.patch</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n        <property>\n          <name>HBasePatchProcess</name>\n        </property>\n      </activation>\n      <properties>\n        <surefire.rerunFailingTestsCount>2</surefire.rerunFailingTestsCount>\n      </properties>\n      <build>\n        <plugins>\n          <plugin>\n            <groupId>org.apache.maven.plugins</groupId>\n            <artifactId>maven-antrun-plugin</artifactId>\n            <inherited>false</inherited>\n            <executions>\n              <execution>\n                <goals>\n                  <goal>run</goal>\n                </goals>\n                <phase>validate</phase>\n                <configuration>\n                  <tasks>\n                    <echo>Maven Execution Environment</echo>\n                    <echo>MAVEN_OPTS=\"${env.MAVEN_OPTS}\"</echo>\n                  </tasks>\n                </configuration>\n              </execution>\n            </executions>\n          </plugin>\n        </plugins>\n      </build>\n    </profile>\n    <profile>\n      <id>jacoco</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <properties>\n        <sonar.exclusions>**/generated/**/*</sonar.exclusions>\n        <sonar.coverage.exclusions>**/generated/**/*,hbase-it/**,**/hbase-logging/**/*,**/hbase-testing-util/**/*,\n          **/hbase-protocol-shaded/**/*,**/hbase-external-blockcache/**/*,**/hbase-examples/**/*,\n          **/hbase-archetypes/**/*</sonar.coverage.exclusions>\n      </properties>\n      <build>\n        <plugins>\n          <plugin>\n            <groupId>org.jacoco</groupId>\n            <artifactId>jacoco-maven-plugin</artifactId>\n            <version>${jacoco.version}</version>\n            <configuration>\n              <excludes>\n                <exclude>**/generated/**/*</exclude>\n              </excludes>\n            </configuration>\n            <executions>\n              <execution>\n                <id>prepare-agent</id>\n                <goals>\n                  <goal>prepare-agent</goal>\n                </goals>\n                <phase>initialize</phase>\n                <configuration>\n                  <propertyName>jacocoArgLine</propertyName>\n                  <append>true</append>\n                </configuration>\n              </execution>\n              <execution>\n                <id>report</id>\n                <goals>\n                  <goal>report</goal>\n                </goals>\n                <phase>prepare-package</phase>\n              </execution>\n            </executions>\n          </plugin>\n          <plugin>\n            <groupId>org.sonarsource.scanner.maven</groupId>\n            <artifactId>sonar-maven-plugin</artifactId>\n            <version>${sonar-maven-plugin.version}</version>\n          </plugin>\n        </plugins>\n      </build>\n    </profile>\n    <profile>\n      <id>os.linux</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n        <os>\n          <family>Linux</family>\n        </os>\n      </activation>\n      <properties>\n        <build.platform>${os.name}-${os.arch}-${sun.arch.data.model}</build.platform>\n      </properties>\n    </profile>\n    <profile>\n      <id>os.mac</id>\n      <activation>\n        <os>\n          <family>Mac</family>\n        </os>\n      </activation>\n      <properties>\n        <build.platform>Mac_OS_X-${sun.arch.data.model}</build.platform>\n      </properties>\n    </profile>\n    <profile>\n      <id>os.windows</id>\n      <activation>\n        <os>\n          <family>Windows</family>\n        </os>\n      </activation>\n      <properties>\n        <build.platform>cygwin</build.platform>\n        <argLine>${hbase-surefire.cygwin-argLine} @{jacocoArgLine}</argLine>\n      </properties>\n    </profile>\n    <!-- this profile should match the name of the release profile in the root asf pom -->\n    <profile>\n      <id>apache-release</id>\n      <build>\n        <plugins>\n          <!-- This should insert itself in place of the normal deploy plugin and then\n               handle either closing or dropping the staging repository for us depending\n               on if the build succeeds.\n            -->\n          <plugin>\n            <groupId>org.sonatype.plugins</groupId>\n            <artifactId>nexus-staging-maven-plugin</artifactId>\n            <version>1.6.8</version>\n            <extensions>true</extensions>\n            <configuration>\n              <nexusUrl>https://repository.apache.org/</nexusUrl>\n              <serverId>apache.releases.https</serverId>\n            </configuration>\n          </plugin>\n        </plugins>\n      </build>\n    </profile>\n    <!-- this profile should be activated for release builds -->\n    <profile>\n      <id>release</id>\n      <build>\n        <plugins>\n          <plugin>\n            <groupId>org.apache.rat</groupId>\n            <artifactId>apache-rat-plugin</artifactId>\n            <executions>\n              <execution>\n                <goals>\n                  <goal>check</goal>\n                </goals>\n                <phase>package</phase>\n              </execution>\n            </executions>\n          </plugin>\n          <plugin>\n            <groupId>org.apache.maven.plugins</groupId>\n            <artifactId>maven-enforcer-plugin</artifactId>\n            <version>${enforcer.version}</version>\n            <configuration>\n              <rules>\n                <enforceBytecodeVersion>\n                  <maxJdkVersion>${compileSource}</maxJdkVersion>\n                  <message>HBase has unsupported dependencies.\n  HBase requires that all dependencies be compiled with version ${compileSource} or earlier\n  of the JDK to properly build from source.  You appear to be using a newer dependency. You can use\n  either \"mvn -version\" or \"mvn enforcer:display-info\" to verify what version is active.\n  Non-release builds can temporarily build with a newer JDK version by setting the\n  'compileSource' property (eg. mvn -DcompileSource=1.8 clean package).</message>\n                  <ignoreClasses>\n                    <ignoreClass>module-info</ignoreClass>\n                  </ignoreClasses>\n                </enforceBytecodeVersion>\n              </rules>\n            </configuration>\n            <dependencies>\n              <dependency>\n                <groupId>org.codehaus.mojo</groupId>\n                <artifactId>extra-enforcer-rules</artifactId>\n                <version>${extra.enforcer.version}</version>\n              </dependency>\n            </dependencies>\n          </plugin>\n          <plugin>\n            <groupId>org.cyclonedx</groupId>\n            <artifactId>cyclonedx-maven-plugin</artifactId>\n            <version>2.7.10</version>\n            <executions>\n              <execution>\n                <goals>\n                  <goal>makeBom</goal>\n                </goals>\n                <phase>package</phase>\n              </execution>\n            </executions>\n          </plugin>\n        </plugins>\n      </build>\n    </profile>\n    <!-- Dependency management profiles for submodules when building against specific hadoop branches.-->\n    <!-- Submodules that need hadoop dependencies should declare\n         profiles with activation properties matching the profile here.\n         Generally, it should be sufficient to copy the first\n         few lines of the profile you want to match. -->\n    <!-- Profile for building against Hadoop 3.0.0. Activate by default -->\n    <profile>\n      <id>hadoop-3.0</id>\n      <activation>\n        <property>\n          <name>!hadoop.profile</name>\n        </property>\n      </activation>\n      <properties>\n        <hadoop.version>${hadoop-three.version}</hadoop.version>\n        <assembly.file>src/main/assembly/hadoop-three-compat.xml</assembly.file>\n      </properties>\n      <dependencyManagement>\n        <dependencies>\n          <dependency>\n            <groupId>org.apache.hadoop</groupId>\n            <artifactId>hadoop-mapreduce-client-core</artifactId>\n            <version>${hadoop-three.version}</version>\n            <exclusions>\n              <exclusion>\n                <groupId>com.google.guava</groupId>\n                <artifactId>guava</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>com.sun.jersey</groupId>\n                <artifactId>jersey-core</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>javax.xml.bind</groupId>\n                <artifactId>jaxb-api</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>javax.ws.rs</groupId>\n                <artifactId>jsr311-api</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.codehaus.jackson</groupId>\n                <artifactId>*</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>javax.servlet</groupId>\n                <artifactId>servlet-api</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>javax.inject</groupId>\n                <artifactId>javax.inject</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>com.google.guava</groupId>\n                <artifactId>guava</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.slf4j</groupId>\n                <artifactId>slf4j-log4j12</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>log4j</groupId>\n                <artifactId>log4j</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>ch.qos.reload4j</groupId>\n                <artifactId>reload4j</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.slf4j</groupId>\n                <artifactId>slf4j-reload4j</artifactId>\n              </exclusion>\n            </exclusions>\n          </dependency>\n          <dependency>\n            <groupId>org.apache.hadoop</groupId>\n            <artifactId>hadoop-mapreduce-client-app</artifactId>\n            <version>${hadoop-three.version}</version>\n            <type>test-jar</type>\n            <exclusions>\n              <exclusion>\n                <groupId>org.codehaus.jackson</groupId>\n                <artifactId>jackson-mapper-asl</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.codehaus.jackson</groupId>\n                <artifactId>jackson-core-asl</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>javax.xml.bind</groupId>\n                <artifactId>jaxb-api</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>javax.ws.rs</groupId>\n                <artifactId>jsr311-api</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.codehaus.jackson</groupId>\n                <artifactId>*</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>javax.xml.bind</groupId>\n                <artifactId>jaxb-api</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>javax.ws.rs</groupId>\n                <artifactId>jsr311-api</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.slf4j</groupId>\n                <artifactId>slf4j-log4j12</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>log4j</groupId>\n                <artifactId>log4j</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>ch.qos.reload4j</groupId>\n                <artifactId>reload4j</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.slf4j</groupId>\n                <artifactId>slf4j-reload4j</artifactId>\n              </exclusion>\n            </exclusions>\n          </dependency>\n          <dependency>\n            <groupId>org.apache.hadoop</groupId>\n            <artifactId>hadoop-mapreduce-client-jobclient</artifactId>\n            <version>${hadoop-three.version}</version>\n            <exclusions>\n              <exclusion>\n                <groupId>com.sun.jersey</groupId>\n                <artifactId>jersey-core</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>javax.servlet</groupId>\n                <artifactId>servlet-api</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.slf4j</groupId>\n                <artifactId>slf4j-log4j12</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>ch.qos.reload4j</groupId>\n                <artifactId>reload4j</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.slf4j</groupId>\n                <artifactId>slf4j-reload4j</artifactId>\n              </exclusion>\n            </exclusions>\n          </dependency>\n          <dependency>\n            <groupId>org.apache.hadoop</groupId>\n            <artifactId>hadoop-mapreduce-client-jobclient</artifactId>\n            <version>${hadoop-three.version}</version>\n            <type>test-jar</type>\n            <scope>test</scope>\n            <exclusions>\n              <exclusion>\n                <groupId>com.sun.jersey</groupId>\n                <artifactId>jersey-core</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>javax.servlet</groupId>\n                <artifactId>servlet-api</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.slf4j</groupId>\n                <artifactId>slf4j-log4j12</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>ch.qos.reload4j</groupId>\n                <artifactId>reload4j</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.slf4j</groupId>\n                <artifactId>slf4j-reload4j</artifactId>\n              </exclusion>\n            </exclusions>\n          </dependency>\n          <dependency>\n            <groupId>org.apache.hadoop</groupId>\n            <artifactId>hadoop-hdfs</artifactId>\n            <version>${hadoop-three.version}</version>\n            <exclusions>\n              <exclusion>\n                <groupId>com.sun.jersey</groupId>\n                <artifactId>jersey-core</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>com.sun.jersey</groupId>\n                <artifactId>jersey-server</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>javax.servlet.jsp</groupId>\n                <artifactId>jsp-api</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>javax.servlet</groupId>\n                <artifactId>servlet-api</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>stax</groupId>\n                <artifactId>stax-api</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>xerces</groupId>\n                <artifactId>xercesImpl</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.codehaus.jackson</groupId>\n                <artifactId>*</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>com.google.guava</groupId>\n                <artifactId>guava</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.slf4j</groupId>\n                <artifactId>slf4j-log4j12</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>log4j</groupId>\n                <artifactId>log4j</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>ch.qos.reload4j</groupId>\n                <artifactId>reload4j</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.slf4j</groupId>\n                <artifactId>slf4j-reload4j</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.fusesource.leveldbjni</groupId>\n                <artifactId>leveldbjni-all</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.openlabtesting.leveldbjni</groupId>\n                <artifactId>leveldbjni-all</artifactId>\n              </exclusion>\n            </exclusions>\n          </dependency>\n          <dependency>\n            <groupId>org.apache.hadoop</groupId>\n            <artifactId>hadoop-hdfs</artifactId>\n            <version>${hadoop-three.version}</version>\n            <type>test-jar</type>\n            <scope>test</scope>\n            <exclusions>\n              <exclusion>\n                <groupId>javax.servlet.jsp</groupId>\n                <artifactId>jsp-api</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>javax.servlet</groupId>\n                <artifactId>servlet-api</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>stax</groupId>\n                <artifactId>stax-api</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>xerces</groupId>\n                <artifactId>xercesImpl</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.codehaus.jackson</groupId>\n                <artifactId>*</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>com.google.guava</groupId>\n                <artifactId>guava</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>com.sun.jersey</groupId>\n                <artifactId>jersey-core</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.slf4j</groupId>\n                <artifactId>slf4j-log4j12</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>log4j</groupId>\n                <artifactId>log4j</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>ch.qos.reload4j</groupId>\n                <artifactId>reload4j</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.slf4j</groupId>\n                <artifactId>slf4j-reload4j</artifactId>\n              </exclusion>\n            </exclusions>\n          </dependency>\n          <dependency>\n            <groupId>org.apache.hadoop</groupId>\n            <artifactId>hadoop-auth</artifactId>\n            <version>${hadoop-three.version}</version>\n            <exclusions>\n              <exclusion>\n                <groupId>com.google.guava</groupId>\n                <artifactId>guava</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>net.minidev</groupId>\n                <artifactId>json-smart</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.slf4j</groupId>\n                <artifactId>slf4j-log4j12</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>log4j</groupId>\n                <artifactId>log4j</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>ch.qos.reload4j</groupId>\n                <artifactId>reload4j</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.slf4j</groupId>\n                <artifactId>slf4j-reload4j</artifactId>\n              </exclusion>\n            </exclusions>\n          </dependency>\n          <dependency>\n            <groupId>org.apache.hadoop</groupId>\n            <artifactId>hadoop-common</artifactId>\n            <version>${hadoop-three.version}</version>\n            <exclusions>\n              <exclusion>\n                <groupId>com.sun.jersey</groupId>\n                <artifactId>jersey-core</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>com.sun.jersey</groupId>\n                <artifactId>jersey-json</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>com.sun.jersey</groupId>\n                <artifactId>jersey-servlet</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>com.sun.jersey</groupId>\n                <artifactId>jersey-server</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>javax.servlet.jsp</groupId>\n                <artifactId>jsp-api</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>javax.servlet</groupId>\n                <artifactId>javax.servlet-api</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>stax</groupId>\n                <artifactId>stax-api</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>com.google.code.findbugs</groupId>\n                <artifactId>jsr305</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>junit</groupId>\n                <artifactId>junit</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.codehaus.jackson</groupId>\n                <artifactId>*</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.slf4j</groupId>\n                <artifactId>slf4j-log4j12</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>log4j</groupId>\n                <artifactId>log4j</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>ch.qos.reload4j</groupId>\n                <artifactId>reload4j</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.slf4j</groupId>\n                <artifactId>slf4j-reload4j</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.bouncycastle</groupId>\n                <artifactId>bcprov-jdk15on</artifactId>\n              </exclusion>\n            </exclusions>\n          </dependency>\n          <dependency>\n            <!--\n             a missing transitive dependency on JDK9+ (obsoleted by Hadoop-3.3.0+, HADOOP-15775)\n           -->\n            <groupId>javax.activation</groupId>\n            <artifactId>javax.activation-api</artifactId>\n            <version>1.2.0</version>\n            <scope>test</scope>\n          </dependency>\n          <dependency>\n            <groupId>org.apache.hadoop</groupId>\n            <artifactId>hadoop-common</artifactId>\n            <version>${hadoop-three.version}</version>\n            <type>test-jar</type>\n            <exclusions>\n              <exclusion>\n                <groupId>com.sun.jersey</groupId>\n                <artifactId>jersey-core</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>com.google.code.findbugs</groupId>\n                <artifactId>jsr305</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.slf4j</groupId>\n                <artifactId>slf4j-log4j12</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>log4j</groupId>\n                <artifactId>log4j</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>ch.qos.reload4j</groupId>\n                <artifactId>reload4j</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.slf4j</groupId>\n                <artifactId>slf4j-reload4j</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.codehaus.jackson</groupId>\n                <artifactId>*</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>javax.servlet.jsp</groupId>\n                <artifactId>jsp-api</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>javax.xml.bind</groupId>\n                <artifactId>jaxb-api</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>javax.ws.rs</groupId>\n                <artifactId>jsr311-api</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.bouncycastle</groupId>\n                <artifactId>bcprov-jdk15on</artifactId>\n              </exclusion>\n            </exclusions>\n          </dependency>\n          <dependency>\n            <!-- Is this needed? Seems a duplicate of the above dependency but for the\n            classifier-->\n            <groupId>org.apache.hadoop</groupId>\n            <artifactId>hadoop-client</artifactId>\n            <version>${hadoop-three.version}</version>\n          </dependency>\n          <dependency>\n            <groupId>org.apache.hadoop</groupId>\n            <artifactId>hadoop-annotations</artifactId>\n            <version>${hadoop-three.version}</version>\n          </dependency>\n          <!-- This was marked as test dep in earlier pom, but was scoped compile.\n           Where do we actually need it? -->\n          <dependency>\n            <groupId>org.apache.hadoop</groupId>\n            <artifactId>hadoop-minicluster</artifactId>\n            <version>${hadoop-three.version}</version>\n            <exclusions>\n              <!--If we comment this in, a few tests in hbase-mapreduce\n                   fail. They depend on jersey-core somehow. But excluding\n                   jersey-core here messes up hbase-it because jersey-core\n                   implements a 1.x jaxrs Response Interface when we depend\n                   on the 2.x Interface... . Letting this jar come in\n                   transitively here but will exclude it down in hbase-it.\n                   See HBASE-22029.\n             <exclusion>\n               <groupId>com.sun.jersey</groupId>\n               <artifactId>jersey-core</artifactId>\n             </exclusion>\n             -->\n              <exclusion>\n                <groupId>commons-httpclient</groupId>\n                <artifactId>commons-httpclient</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>javax.servlet.jsp</groupId>\n                <artifactId>jsp-api</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>javax.servlet</groupId>\n                <artifactId>servlet-api</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>stax</groupId>\n                <artifactId>stax-api</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>com.google.code.findbugs</groupId>\n                <artifactId>jsr305</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.slf4j</groupId>\n                <artifactId>slf4j-log4j12</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>log4j</groupId>\n                <artifactId>log4j</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>ch.qos.reload4j</groupId>\n                <artifactId>reload4j</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.slf4j</groupId>\n                <artifactId>slf4j-reload4j</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.bouncycastle</groupId>\n                <artifactId>bcprov-jdk15on</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.bouncycastle</groupId>\n                <artifactId>bcpkix-jdk15on</artifactId>\n              </exclusion>\n            </exclusions>\n          </dependency>\n          <dependency>\n            <groupId>org.apache.hadoop</groupId>\n            <artifactId>hadoop-minikdc</artifactId>\n            <version>${hadoop-three.version}</version>\n            <scope>test</scope>\n            <exclusions>\n              <exclusion>\n                <groupId>org.slf4j</groupId>\n                <artifactId>slf4j-log4j12</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>ch.qos.reload4j</groupId>\n                <artifactId>reload4j</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>org.slf4j</groupId>\n                <artifactId>slf4j-reload4j</artifactId>\n              </exclusion>\n              <exclusion>\n                <groupId>bouncycastle</groupId>\n                <artifactId>bcprov-jdk15</artifactId>\n              </exclusion>\n            </exclusions>\n          </dependency>\n          <dependency>\n            <groupId>org.apache.hadoop</groupId>\n            <artifactId>hadoop-distcp</artifactId>\n            <version>${hadoop-three.version}</version>\n          </dependency>\n\n          <dependency>\n            <groupId>org.apache.hadoop</groupId>\n            <artifactId>hadoop-hdfs-client</artifactId>\n            <version>${hadoop-three.version}</version>\n          </dependency>\n        </dependencies>\n      </dependencyManagement>\n\n    </profile>\n    <!-- profiles for the tests\n         See as well the properties of the project for the values\n         when no profile is active.     -->\n    <profile>\n      <!-- Use it to launch all tests in the same JVM  -->\n      <id>singleJVMTests</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <properties>\n        <surefire.firstPartForkCount>1</surefire.firstPartForkCount>\n        <surefire.skipFirstPart>false</surefire.skipFirstPart>\n        <surefire.skipSecondPart>true</surefire.skipSecondPart>\n        <surefire.firstPartGroups/>\n      </properties>\n    </profile>\n    <profile>\n      <!-- Use it to launch small tests only -->\n      <id>runSmallTests</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <properties>\n        <surefire.skipFirstPart>false</surefire.skipFirstPart>\n        <surefire.skipSecondPart>true</surefire.skipSecondPart>\n        <surefire.firstPartGroups>org.apache.hadoop.hbase.testclassification.SmallTests</surefire.firstPartGroups>\n        <surefire.secondPartGroups/>\n      </properties>\n    </profile>\n    <profile>\n      <!-- Use it to launch medium tests only -->\n      <id>runMediumTests</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <properties>\n        <surefire.skipFirstPart>false</surefire.skipFirstPart>\n        <surefire.skipSecondPart>true</surefire.skipSecondPart>\n        <surefire.firstPartGroups>org.apache.hadoop.hbase.testclassification.MediumTests</surefire.firstPartGroups>\n        <surefire.secondPartGroups/>\n      </properties>\n    </profile>\n    <profile>\n      <!-- Use it to launch large tests only -->\n      <id>runLargeTests</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <properties>\n        <surefire.skipFirstPart>false</surefire.skipFirstPart>\n        <surefire.skipSecondPart>true</surefire.skipSecondPart>\n        <surefire.firstPartGroups>org.apache.hadoop.hbase.testclassification.LargeTests</surefire.firstPartGroups>\n        <surefire.secondPartGroups/>\n      </properties>\n    </profile>\n    <profile>\n      <!-- Use it to launch small & medium tests -->\n      <id>runDevTests</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <properties>\n        <surefire.firstPartForkCount>1</surefire.firstPartForkCount>\n        <surefire.skipFirstPart>false</surefire.skipFirstPart>\n        <surefire.skipSecondPart>false</surefire.skipSecondPart>\n        <surefire.firstPartGroups>org.apache.hadoop.hbase.testclassification.SmallTests</surefire.firstPartGroups>\n        <surefire.secondPartGroups>org.apache.hadoop.hbase.testclassification.MediumTests</surefire.secondPartGroups>\n      </properties>\n    </profile>\n    <profile>\n      <!-- Use it to launch all tests -->\n      <id>runAllTests</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <properties>\n        <surefire.skipFirstPart>false</surefire.skipFirstPart>\n        <surefire.skipSecondPart>false</surefire.skipSecondPart>\n        <surefire.firstPartGroups>org.apache.hadoop.hbase.testclassification.SmallTests</surefire.firstPartGroups>\n        <surefire.secondPartGroups>org.apache.hadoop.hbase.testclassification.MediumTests,org.apache.hadoop.hbase.testclassification.LargeTests</surefire.secondPartGroups>\n      </properties>\n    </profile>\n    <profile>\n      <id>runMiscTests</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <properties>\n        <surefire.skipFirstPart>false</surefire.skipFirstPart>\n        <surefire.skipSecondPart>true</surefire.skipSecondPart>\n        <surefire.firstPartGroups>org.apache.hadoop.hbase.testclassification.MiscTests</surefire.firstPartGroups>\n        <surefire.secondPartGroups/>\n      </properties>\n    </profile>\n    <profile>\n      <id>runCoprocessorTests</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <properties>\n        <surefire.firstPartForkCount>1</surefire.firstPartForkCount>\n        <surefire.secondPartForkCount>1</surefire.secondPartForkCount>\n        <surefire.skipFirstPart>false</surefire.skipFirstPart>\n        <surefire.skipSecondPart>true</surefire.skipSecondPart>\n        <surefire.firstPartGroups>org.apache.hadoop.hbase.testclassification.CoprocessorTests</surefire.firstPartGroups>\n        <surefire.secondPartGroups/>\n      </properties>\n    </profile>\n    <profile>\n      <id>runClientTests</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <properties>\n        <surefire.firstPartForkCount>1</surefire.firstPartForkCount>\n        <surefire.secondPartForkCount>1</surefire.secondPartForkCount>\n        <surefire.skipFirstPart>false</surefire.skipFirstPart>\n        <surefire.skipSecondPart>true</surefire.skipSecondPart>\n        <surefire.firstPartGroups>org.apache.hadoop.hbase.testclassification.ClientTests</surefire.firstPartGroups>\n        <surefire.secondPartGroups/>\n      </properties>\n    </profile>\n    <profile>\n      <id>runMasterTests</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <properties>\n        <surefire.firstPartForkCount>1</surefire.firstPartForkCount>\n        <surefire.secondPartForkCount>1</surefire.secondPartForkCount>\n        <surefire.skipFirstPart>false</surefire.skipFirstPart>\n        <surefire.skipSecondPart>true</surefire.skipSecondPart>\n        <surefire.firstPartGroups>org.apache.hadoop.hbase.testclassification.MasterTests</surefire.firstPartGroups>\n        <surefire.secondPartGroups/>\n      </properties>\n    </profile>\n    <profile>\n      <id>runMapredTests</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <properties>\n        <surefire.firstPartForkCount>1</surefire.firstPartForkCount>\n        <surefire.secondPartForkCount>1</surefire.secondPartForkCount>\n        <surefire.skipFirstPart>false</surefire.skipFirstPart>\n        <surefire.skipSecondPart>true</surefire.skipSecondPart>\n        <surefire.firstPartGroups>org.apache.hadoop.hbase.testclassification.MapredTests</surefire.firstPartGroups>\n        <surefire.secondPartGroups/>\n      </properties>\n    </profile>\n    <profile>\n      <id>runMapreduceTests</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <properties>\n        <surefire.firstPartForkCount>1</surefire.firstPartForkCount>\n        <surefire.secondPartForkCount>1</surefire.secondPartForkCount>\n        <surefire.skipFirstPart>false</surefire.skipFirstPart>\n        <surefire.skipSecondPart>true</surefire.skipSecondPart>\n        <surefire.firstPartGroups>org.apache.hadoop.hbase.testclassification.MapReduceTests</surefire.firstPartGroups>\n        <surefire.secondPartGroups/>\n      </properties>\n    </profile>\n    <profile>\n      <id>runRegionServerTests</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <properties>\n        <surefire.firstPartForkCount>1</surefire.firstPartForkCount>\n        <surefire.secondPartForkCount>1</surefire.secondPartForkCount>\n        <surefire.skipFirstPart>false</surefire.skipFirstPart>\n        <surefire.skipSecondPart>true</surefire.skipSecondPart>\n        <surefire.firstPartGroups>org.apache.hadoop.hbase.testclassification.RegionServerTests</surefire.firstPartGroups>\n        <surefire.secondPartGroups/>\n      </properties>\n    </profile>\n    <profile>\n      <id>runVerySlowMapReduceTests</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <properties>\n        <surefire.firstPartForkCount>2</surefire.firstPartForkCount>\n        <surefire.secondPartForkCount>1</surefire.secondPartForkCount>\n        <surefire.skipFirstPart>false</surefire.skipFirstPart>\n        <surefire.skipSecondPart>true</surefire.skipSecondPart>\n        <surefire.firstPartGroups>org.apache.hadoop.hbase.testclassification.VerySlowMapReduceTests</surefire.firstPartGroups>\n        <surefire.secondPartGroups/>\n      </properties>\n    </profile>\n\n    <profile>\n      <id>runVerySlowRegionServerTests</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <properties>\n        <surefire.firstPartForkCount>2</surefire.firstPartForkCount>\n        <surefire.secondPartForkCount>1</surefire.secondPartForkCount>\n        <surefire.skipFirstPart>false</surefire.skipFirstPart>\n        <surefire.skipSecondPart>true</surefire.skipSecondPart>\n        <surefire.firstPartGroups>org.apache.hadoop.hbase.testclassification.VerySlowRegionServerTests</surefire.firstPartGroups>\n        <surefire.secondPartGroups/>\n      </properties>\n    </profile>\n\n    <profile>\n      <id>runFilterTests</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <properties>\n        <surefire.firstPartForkCount>1</surefire.firstPartForkCount>\n        <surefire.secondPartForkCount>1</surefire.secondPartForkCount>\n        <surefire.skipFirstPart>false</surefire.skipFirstPart>\n        <surefire.skipSecondPart>true</surefire.skipSecondPart>\n        <surefire.firstPartGroups>org.apache.hadoop.hbase.testclassification.FilterTests</surefire.firstPartGroups>\n        <surefire.secondPartGroups/>\n      </properties>\n    </profile>\n    <profile>\n      <id>runIOTests</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <properties>\n        <surefire.firstPartForkCount>1</surefire.firstPartForkCount>\n        <surefire.secondPartForkCount>1</surefire.secondPartForkCount>\n        <surefire.skipFirstPart>false</surefire.skipFirstPart>\n        <surefire.skipSecondPart>true</surefire.skipSecondPart>\n        <surefire.firstPartGroups>org.apache.hadoop.hbase.testclassification.IOTests</surefire.firstPartGroups>\n        <surefire.secondPartGroups/>\n      </properties>\n    </profile>\n    <profile>\n      <id>runRestTests</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <properties>\n        <surefire.firstPartForkCount>1</surefire.firstPartForkCount>\n        <surefire.secondPartForkCount>1</surefire.secondPartForkCount>\n        <surefire.skipFirstPart>false</surefire.skipFirstPart>\n        <surefire.skipSecondPart>true</surefire.skipSecondPart>\n        <surefire.firstPartGroups>org.apache.hadoop.hbase.testclassification.RestTests</surefire.firstPartGroups>\n        <surefire.secondPartGroups/>\n      </properties>\n    </profile>\n    <profile>\n      <id>runRPCTests</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <properties>\n        <surefire.firstPartForkCount>1</surefire.firstPartForkCount>\n        <surefire.secondPartForkCount>1</surefire.secondPartForkCount>\n        <surefire.skipFirstPart>false</surefire.skipFirstPart>\n        <surefire.skipSecondPart>true</surefire.skipSecondPart>\n        <surefire.firstPartGroups>org.apache.hadoop.hbase.testclassification.RPCTests</surefire.firstPartGroups>\n        <surefire.secondPartGroups/>\n      </properties>\n    </profile>\n    <profile>\n      <id>runReplicationTests</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <properties>\n        <surefire.firstPartForkCount>1</surefire.firstPartForkCount>\n        <surefire.secondPartForkCount>1</surefire.secondPartForkCount>\n        <surefire.skipFirstPart>false</surefire.skipFirstPart>\n        <surefire.skipSecondPart>true</surefire.skipSecondPart>\n        <surefire.firstPartGroups>org.apache.hadoop.hbase.testclassification.ReplicationTests</surefire.firstPartGroups>\n        <surefire.secondPartGroups/>\n      </properties>\n    </profile>\n    <profile>\n      <id>runSecurityTests</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <properties>\n        <surefire.firstPartForkCount>1</surefire.firstPartForkCount>\n        <surefire.secondPartForkCount>1</surefire.secondPartForkCount>\n        <surefire.skipFirstPart>false</surefire.skipFirstPart>\n        <surefire.skipSecondPart>true</surefire.skipSecondPart>\n        <surefire.firstPartGroups>org.apache.hadoop.hbase.testclassification.SecurityTests</surefire.firstPartGroups>\n        <surefire.secondPartGroups/>\n      </properties>\n    </profile>\n    <profile>\n      <id>runFlakeyTests</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <properties>\n        <surefire.firstPartForkCount>1</surefire.firstPartForkCount>\n        <surefire.secondPartForkCount>1</surefire.secondPartForkCount>\n        <surefire.skipFirstPart>false</surefire.skipFirstPart>\n        <surefire.skipSecondPart>true</surefire.skipSecondPart>\n        <surefire.firstPartGroups>org.apache.hadoop.hbase.testclassification.FlakeyTests</surefire.firstPartGroups>\n        <surefire.secondPartGroups/>\n      </properties>\n    </profile>\n    <profile>\n      <id>runZKTests</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <properties>\n        <surefire.firstPartForkCount>1</surefire.firstPartForkCount>\n        <surefire.secondPartForkCount>1</surefire.secondPartForkCount>\n        <surefire.skipFirstPart>false</surefire.skipFirstPart>\n        <surefire.skipSecondPart>true</surefire.skipSecondPart>\n        <surefire.firstPartGroups>org.apache.hadoop.hbase.testclassification.ZKTests</surefire.firstPartGroups>\n        <surefire.secondPartGroups/>\n      </properties>\n    </profile>\n    <profile>\n      <id>runRSGroupTests</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n      </activation>\n      <properties>\n        <surefire.firstPartForkCount>1</surefire.firstPartForkCount>\n        <surefire.secondPartForkCount>1</surefire.secondPartForkCount>\n        <surefire.skipFirstPart>false</surefire.skipFirstPart>\n        <surefire.skipSecondPart>true</surefire.skipSecondPart>\n        <surefire.firstPartGroups>org.apache.hadoop.hbase.testclassification.RSGroupTests</surefire.firstPartGroups>\n        <surefire.secondPartGroups/>\n      </properties>\n    </profile>\n\n    <profile>\n      <!-- Use it to launch tests locally-->\n      <id>localTests</id>\n      <activation>\n        <property>\n          <name>test</name>\n        </property>\n      </activation>\n      <properties>\n        <surefire.provider>surefire-junit4</surefire.provider>\n        <surefire.skipFirstPart>false</surefire.skipFirstPart>\n        <surefire.skipSecondPart>true</surefire.skipSecondPart>\n        <surefire.firstPartGroups/>\n      </properties>\n    </profile>\n    <!-- Profile for running clover. You need to have a clover license under ~/.clover.license for ${clover.version}\n         or you can provide the license with -Dmaven.clover.licenseLocation=/path/to/license. Committers can find\n         the license under https://svn.apache.org/repos/private/committers/donated-licenses/clover/\n         The report will be generated under target/site/clover/index.html when you run\n         MAVEN_OPTS=\"-Xmx2048m\" mvn clean package -Pclover site -->\n    <profile>\n      <id>clover</id>\n      <activation>\n        <activeByDefault>false</activeByDefault>\n        <property>\n          <name>clover</name>\n        </property>\n      </activation>\n      <properties>\n        <maven.clover.licenseLocation>${user.home}/.clover.license</maven.clover.licenseLocation>\n      </properties>\n      <build>\n        <plugins>\n          <!-- When Clover is active, we need to add it as a dependency for the javadoc plugin, or\n             our instrumented classes for the doclet will fail\n          -->\n          <plugin>\n            <groupId>org.apache.maven.plugins</groupId>\n            <artifactId>maven-javadoc-plugin</artifactId>\n            <dependencies>\n              <dependency>\n                <groupId>com.atlassian.maven.plugins</groupId>\n                <artifactId>maven-clover2-plugin</artifactId>\n                <version>${clover.version}</version>\n              </dependency>\n            </dependencies>\n          </plugin>\n          <plugin>\n            <groupId>com.atlassian.maven.plugins</groupId>\n            <artifactId>maven-clover2-plugin</artifactId>\n            <version>${clover.version}</version>\n            <configuration>\n              <includesAllSourceRoots>true</includesAllSourceRoots>\n              <includesTestSourceRoots>true</includesTestSourceRoots>\n              <targetPercentage>50%</targetPercentage>\n              <generateHtml>true</generateHtml>\n              <generateXml>true</generateXml>\n              <excludes>\n                <exclude>**/generated/**</exclude>\n              </excludes>\n            </configuration>\n            <executions>\n              <execution>\n                <id>clover-setup</id>\n                <goals>\n                  <goal>setup</goal>\n                </goals>\n                <phase>process-sources</phase>\n              </execution>\n              <execution>\n                <id>clover</id>\n                <goals>\n                  <goal>clover</goal>\n                </goals>\n                <phase>site</phase>\n              </execution>\n            </executions>\n          </plugin>\n        </plugins>\n      </build>\n    </profile>\n    <profile>\n      <!-- Used by the website generation script on jenkins to\n           do a local install of the jars we need to run a normal\n           site build w/o forking.\n        -->\n      <id>site-install-step</id>\n      <properties>\n        <skipTests>true</skipTests>\n        <maven.javadoc.skip>true</maven.javadoc.skip>\n        <enforcer.skip>true</enforcer.skip>\n        <checkstyle.skip>true</checkstyle.skip>\n        <spotbugs.skip>true</spotbugs.skip>\n        <warbucks.skip>true</warbucks.skip>\n      </properties>\n    </profile>\n    <profile>\n      <!-- Used by the website generation script on jenkins to\n           mitigate the impact of unneeded build forks while building\n           our javadocs.\n        -->\n      <id>site-build-step</id>\n      <properties>\n        <skipTests>true</skipTests>\n        <enforcer.skip>true</enforcer.skip>\n        <maven.main.skip>true</maven.main.skip>\n        <maven.test.skip>true</maven.test.skip>\n        <warbucks.skip>true</warbucks.skip>\n        <protoc.skip>true</protoc.skip>\n        <remoteresources.skip>true</remoteresources.skip>\n      </properties>\n    </profile>\n    <profile>\n      <id>eclipse-specific</id>\n      <activation>\n        <property>\n          <name>m2e.version</name>\n        </property>\n      </activation>\n      <build>\n        <pluginManagement>\n          <plugins>\n            <!-- General config for eclipse classpath/settings -->\n            <plugin>\n              <groupId>org.apache.maven.plugins</groupId>\n              <artifactId>maven-eclipse-plugin</artifactId>\n              <version>${maven.eclipse.version}</version>\n            </plugin>\n            <!--This plugin's configuration is used to store Eclipse m2e settings\n                only. It has no influence on the Maven build itself. m2e does not\n                provide any safeguards against rogue maven plugins that leak\n                classloaders, modify random files inside workspace or throw nasty\n                exceptions to fail the build.\n                Top level doesn't do any specific configuration currently - left\n                to modules to decide what they want to bind, sans those plugins\n                defined in this pom. -->\n            <plugin>\n              <groupId>org.eclipse.m2e</groupId>\n              <artifactId>lifecycle-mapping</artifactId>\n              <version>${lifecycle.mapping.version}</version>\n              <configuration>\n                <lifecycleMappingMetadata>\n                  <pluginExecutions>\n                    <pluginExecution>\n                      <pluginExecutionFilter>\n                        <groupId>org.jacoco</groupId>\n                        <artifactId>jacoco-maven-plugin</artifactId>\n                        <versionRange>[0.6.2.201302030002,)</versionRange>\n                        <goals>\n                          <goal>prepare-agent</goal>\n                        </goals>\n                      </pluginExecutionFilter>\n                      <action>\n                        <ignore/>\n                      </action>\n                    </pluginExecution>\n                    <pluginExecution>\n                      <pluginExecutionFilter>\n                        <groupId>org.apache.maven.plugins</groupId>\n                        <artifactId>maven-enforcer-plugin</artifactId>\n                        <versionRange>${enforcer.version}</versionRange>\n                        <goals>\n                          <goal>enforce</goal>\n                        </goals>\n                      </pluginExecutionFilter>\n                      <action>\n                        <ignore/>\n                      </action>\n                    </pluginExecution>\n                    <pluginExecution>\n                      <pluginExecutionFilter>\n                        <groupId>org.apache.maven.plugins</groupId>\n                        <artifactId>maven-remote-resources-plugin</artifactId>\n                        <versionRange>[1.5,)</versionRange>\n                        <goals>\n                          <goal>process</goal>\n                          <goal>bundle</goal>\n                        </goals>\n                      </pluginExecutionFilter>\n                      <action>\n                        <ignore/>\n                      </action>\n                    </pluginExecution>\n                    <pluginExecution>\n                      <pluginExecutionFilter>\n                        <groupId>org.codehaus.mojo</groupId>\n                        <artifactId>buildnumber-maven-plugin</artifactId>\n                        <versionRange>[1.3,)</versionRange>\n                        <goals>\n                          <goal>create-timestamp</goal>\n                        </goals>\n                      </pluginExecutionFilter>\n                      <action>\n                        <execute>\n                          <runOnConfiguration>true</runOnConfiguration>\n                          <runOnIncremental>true</runOnIncremental>\n                        </execute>\n                      </action>\n                    </pluginExecution>\n                  </pluginExecutions>\n                </lifecycleMappingMetadata>\n              </configuration>\n            </plugin>\n          </plugins>\n        </pluginManagement>\n      </build>\n    </profile>\n  </profiles>\n</project>\n"
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}