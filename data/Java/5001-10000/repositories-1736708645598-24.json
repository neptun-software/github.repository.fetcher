{
  "metadata": {
    "timestamp": 1736708645598,
    "page": 24,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjMw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "StarRocks/starrocks",
      "stars": 9539,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 0.8984375,
          "content": "---\nLanguage: Cpp\nBasedOnStyle: Google\nAccessModifierOffset: -4\nAllowShortFunctionsOnASingleLine: Inline\nColumnLimit: 120\nConstructorInitializerIndentWidth: 8 # double of IndentWidth\nContinuationIndentWidth: 8 # double of IndentWidth\nDerivePointerAlignment: false # always use PointerAlignment\nIndentCaseLabels: false\nIndentWidth: 4\nPointerAlignment: Left\nReflowComments: false\nSortUsingDeclarations: false\nSpacesBeforeTrailingComments: 1\n---\nLanguage: Java\nBasedOnStyle: Google\nAccessModifierOffset: -4\nAllowShortFunctionsOnASingleLine: Inline\nColumnLimit: 120\nConstructorInitializerIndentWidth: 8 # double of IndentWidth\nContinuationIndentWidth: 8 # double of IndentWidth\nDerivePointerAlignment: false # always use PointerAlignment\nIndentCaseLabels: false\nIndentWidth: 4\nPointerAlignment: Left\nReflowComments: false\nSortUsingDeclarations: false\nSpacesBeforeTrailingComments: 1\n---\nLanguage: Proto\nBasedOnStyle: Google\n"
        },
        {
          "name": ".clang-tidy",
          "type": "blob",
          "size": 1.328125,
          "content": "---\nChecks: >\n    -*,\n    cppcoreguidelines-virtual-class-destructor,\n    modernize-concat-nested-namespaces,\n    modernize-deprecated-headers,\n    modernize-deprecated-ios-base-aliases,\n    modernize-make-shared,\n    modernize-make-unique,\n    modernize-pass-by-value,\n    modernize-raw-string-literal,\n    modernize-redundant-void-arg,\n    modernize-replace-auto-ptr,\n    modernize-replace-disallow-copy-and-assign-macro,\n    modernize-replace-random-shuffle,\n    -modernize-return-braced-init-list,\n    modernize-shrink-to-fit,\n    modernize-unary-static-assert,\n    modernize-use-bool-literals,\n    modernize-use-default-member-init,\n    modernize-use-emplace,\n    modernize-use-equals-default,\n    modernize-use-equals-delete,\n    modernize-use-nullptr,\n    modernize-use-override,\n    modernize-use-uncaught-exceptions,\n    performance-faster-string-find,\n    performance-for-range-copy,\n    performance-implicit-conversion-in-loop,\n    performance-inefficient-algorithm,\n    performance-inefficient-vector-operation\n    performance-move-const-arg,\n    performance-no-automatic-move,\n    performance-no-int-to-ptr,\n    performance-noexcept-move-constructor,\n    performance-trivially-destructible,\n    performance-type-promotion-in-math-fn,\n    performance-unnecessary-copy-initialization,\n    performance-unnecessary-value-param,\n\nWarningsAsErrors: '*'\n"
        },
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.509765625,
          "content": "#Ignore any files or directories at any level, including the context root, named thirdparty\n**/cmake-build*\n**/ut_build_*\n**/be/output\nbe/build_\nthirdparty/installed\nthirdparty/src\n**/target\n**/log\n**/.github\n**/.idea\n**/*.o\n**/output\n# negate the output as it might be used for packing container from locally build artifact\n!output\noutput/fe/meta\noutput/fe/log\noutput/be/storage\noutput/be/log\n# allow build fs_broker into allin1 docker image\n!fs_brokers/apache_hdfs_broker/output\nfs_brokers/apache_hdfs_broker/output/log\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.5908203125,
          "content": "*.swp\n*.pyc\nbe/output\nbe/build\nbe/build_Release\nbe/ut_build\noutput\ndocs/contents\ndocs/.temp\ndocs/.vuepress/dist\ndocs/node_modules\ndocs/build\ndocs/contents\ngensrc/build\nfe/fe-core/target\nthirdparty/src\nthirdparty/installed\n*.so.tmp\n.DS_Store\n*.iml\ncore.*\nextension/spark-doris-connector/.classpath\nextension/spark-doris-connector/target\ncontrib/trino-connector/target/\nfe/log\n**/ut_ports\nvenv/\ncustom_env.sh\nut_dir\nlog/\nfe_plugins/*/target\nfe_plugins/output\nfe/mocked\nfe/ut_ports\nfe/*/target\nfe/fe-core/gen\nfe/fe-common/.classpath\nfe/fe-core/src/main/java/com/starrocks/sql/parser/gen\nfe/fe-core/src/main/java/com/starrocks/builtins\nfe/fe-core/src/main/java/com/starrocks/common/Version.java\nfe/fe-core/src/main/java/com/starrocks/proto\nfe/fe-core/src/main/java/com/starrocks/thrift\nfs_brokers/apache_hdfs_broker/src/main/resources/\nfs_brokers/apache_hdfs_broker/src/main/thrift/\nfs_brokers/apache_hdfs_broker/jindosdk-4.6.2\ndependency-reduced-pom.xml\ntest/conf/\ntest/conf/sr.conf\ntest/nosetests.xml\ntest/common/data\ntags\n.tags\n.cache\n*.vim\n*.swo\ncompile_commands.json\n.factorypath\n.classpath\n.vimspector.json\n.gdb_history\n\n# ignore generated files\nStarRocksLex.tokens\n\n\n#ignore eclipse project file & idea project file\n.cproject\n.project\n.settings/\n.idea/\n.gradle/\n/Default/\nbe/cmake-build*\nbe/.vscode\nbe/src/gen_cpp/cmake-build*\nbe/src/gen_cpp/*.cc\nbe/src/gen_cpp/*.cpp\n!be/src/gen_cpp/thrift_types_customize_impl.cpp\nbe/src/gen_cpp/*.h\nbe/src/gen_cpp/opcode\nbe/src/thirdparty/starcache/\nbe/ut_build_ASAN/\nbe/tags\n\n#ignore vscode project file\n.vscode\n!.gitignore\n!.clang-format\n!.github\nbuild/\ncmake-build-debug/\nCMakeLists.txt\n"
        },
        {
          "name": ".mergify.yml",
          "type": "blob",
          "size": 0.603515625,
          "content": "commands_restrictions:\n  backport:\n    conditions:\n      - or:\n        - sender-permission>=read\n        - sender=github-actions[bot]\n\n  rebase:\n    conditions:\n      - or:\n        - sender-permission>=read\n        - sender=github-actions[bot]\n\npull_request_rules:\n  - name: assign PRs with the pr author\n    conditions:\n      - -merged\n    actions:\n      assign:\n        add_users: \n          - \"{{author}}\"\n\n  - name: close pr when conflict\n    conditions:\n      - label=conflicts\n    actions:\n      close:\n        message:\n          \"@{{author}}: Backport conflict, please reslove the conflict and resubmit the pr\"\n"
        },
        {
          "name": ".trivyignore",
          "type": "blob",
          "size": 0.3125,
          "content": "# ignore protobuf cve temporary\nCVE-2024-7254\n# ignore commons-io-2.11.0.jar introduced by odps-reader\nCVE-2024-47554\n# ignore avro-1.11.3.jar introduced by iceberg-core-1.6.0\nCVE-2024-47561\n# ingore nimbus-jose-jwt-9.31.jar\nCVE-2023-52428\n# ingore io.netty:netty-common (netty-common-4.1.100.Final.jar) \nCVE-2024-47535\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.185546875,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to make participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity, and expression, level of experience, education, socioeconomic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment include:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies within all project spaces, and it also applies when an individual is representing the project or its community in public spaces. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at opensource@starrocks.com. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality about the reporter of an incident. Further details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant](https://www.contributor-covenant.org/), version 1.4.\n\nFor answers to common questions about this code of conduct, see [FAQ](https://www.contributor-covenant.org/faq).\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 6.587890625,
          "content": "# Contributing to StarRocks\n\nStarRocks is built by an open and friendly community. We are dedicated to building a collaborative, inspiring, and exuberant open-source community for our members. Everyone is more than welcome to join our community to get help and to contribute to StarRocks.\n\n## Table of contents\n\n- [How to contribute](#How-to-contribute)\n- [Contributing guideline](#Contributing-guideline)\n  - [Report a bug](#Report-a-bug)\n  - [Contributing code](#Contributing-code)\n    - [General workflow](#General-workflow)\n    - [StarRocks code structure](#StarRocks-code-structure)\n    - [Important directories](#Important-directories)\n    - [Set your development environment](#Set-your-development-environment)\n    - [Coding style](#Coding-style)\n    - [Unit test](#Unit-test)\n    - [Commit message](#Commit-message)\n    - [PR body](#PR-body)\n    - [Contributor License Agreement](#Contributor-License-Agreement)\n    - [Best practices](#Best-practices)\n    - [Important contacts](#Important-contacts)\n  - [Contributing test case](#Contributing-test-case)\n  - [Reviewing code](#Reviewing-code)\n  - [Contributing documentation](#Contributing-documentation)\n  - [Help community members](#Help-community-members)\n  - [Spread our idea](#Spread-our-idea)\n- [Code of conduct](#Code-of-conduct)\n\n## How to contribute\n\nContributions to StarRocks are cordially welcome from everyone. Contributing to StarRocks is not limited to contributing codes. Below, we list different approaches to contributing to our community.\n\n|Contribution|Details|\n|------------|-------|\n|Report a bug|You can [file an issue](https://github.com/StarRocks/starrocks/issues/new/choose) To report a bug with StarRock.|\n|Contribute code|You can contribute your code by fixing a bug or implementing a feature.|\n|Contribute test case|You can contribute your test cases.|\n|Help review code|If you are an active contributor or committer of StarRocks, you can help us review the pull requests (PRs).|\n|Contribute documentation|StarRocks community maintains a tremendous amount of documentation both in Chinese and English. You can contribute documentation changes by fixing a documentation bug or proposing a new piece of content.|\n|Help StarRocks users|You can help newcomers who meet difficulties in our community.|\n|Spread the word about StarRocks|You can author an article or give a talk about us to help us spread our technology to the world.|\n\n## Contributing guideline\n\nThis guide describes how to make various types of contribution to StarRocks community.\n\n### Report a bug\n\nTo report a bug with StarRocks, you should [file an issue](https://github.com/StarRocks/starrocks/issues/new/choose) in StarRocks repository, and provide necessary information and, if possible, steps to reproduce the bug in the issue body.\n\n### Contributing code\n\nYou can contribute your code by fixing a bug you identified or in an [existing issue](https://github.com/StarRocks/starrocks/issues). If you are new to this project, you may find the issues labelled good-first-issue suitable for your first contribution. Usually, such issues provide a detailed description of the procedure to solve the problem in its issue body.\n\nIf you are confident with your programming proficiency, you can also contribute your code by helping develop a feature for StarRocks.\n\n#### General workflow\n\nBefore getting your hands on codes, you should comment and mention the repository maintainer in the issue body, and inform him/her to assign to you the issue that you wish to solve. It is recommended to share your plan on how to solve this problem in the issue body as well.\n\nIn StarRocks community, we follow the fork-and-merge GitHub workflow when contributing code.\n\n1. Create a fork of StarRocks in your GitHub account.\n2. Clone this forked repository to your local device.\n3. Check out a new branch based on the branch you expect to contribute.\n4. Commit your code changes on the new branch.\n5. Push the branch with code changes to GitHub.\n6. Create a PR to submit your code changes.\n\nThe repository maintainers will review your code changes as soon as possible. Your commits will be merged once approved.\n\nFor detailed instruction on GitHub workflow, see [StarRocks GitHub Workflow](https://github.com/StarRocks/community/blob/main/Contributors/guide/workflow.md).\n\n#### StarRocks code structure\n\nTBC\n\n#### Important directories\n\nTBC\n\n#### Set your development environment\n\n1. For FE development environment, see [The development configuration setup for StarRocks on IDEA](https://github.com/StarRocks/community/blob/main/Contributors/guide/IDEA.md).\n2. For BE development environment, see [The development configuration setup for StarRocks on Clion](https://github.com/StarRocks/community/blob/main/Contributors/guide/Clion.md).\n3. To compile StarRocks with Docker, see [Compile StarRocks with Docker](https://docs.starrocks.io/docs/developers/build-starrocks/Build_in_docker/).\n4. To deploy StarRocks manually, see [Deploy StarRocks manually](https://docs.starrocks.io/docs/deployment/deploy_manually/).\n\n#### Coding style\n\nTBC\n\n#### Unit test\n\nTBC\n\n#### Commit message\n\n- Write your commit message in English.\n- Start your commit message with a verb clause initiated with an upper case letter.\n- Use concise, explicit language.\n\n#### PR body\n\n- You should relate the issue you worked on in the PR body.\n- It is recommended to submit ONE commit in ONE PR.\nSee [PR template](https://github.com/StarRocks/starrocks/blob/main/.github/PULL_REQUEST_TEMPLATE.md) for more inforamtion.\n\n#### Contributor License Agreement\n\nTo get your PR merged, you must [submit your Contributor License Agreement (CLA)](https://cla-assistant.io/StarRocks/starrocks) first. You only need to submit it ONCE.\n\n#### Best practices\n\nTBC\n\n#### Important contacts\n\nWhenever you have difficulties in development, you can reach out to the following members for help. You can mention them in your issue or PR.\n\n- TBC\n\n### Contributing test case\n\nTBC\n\n### Reviewing code\n\nTBC\n\n### Contributing documentation\n\nTo contribute to StarRocks documentation, please refer to [Document Contribution Guideline](https://github.com/StarRocks/starrocks/blob/main/docs/README.md).\n\n### Help community members\n\nIf you are a proficient StarRocks user, you can contribute to our community by helping new members solve the problems when they use StarRocks.\n\n### Spread our idea\n\nYou are welcome to author a blog article about StarRocks in the media, or host a live broadcast to spread StarRocks to the world. Please contact opensource@starrocks.com for more information and instructions.\n\n## Code of conduct\n\nAll members in the community are instructed to follow our [Code of Conduct](https://github.com/StarRocks/starrocks/blob/main/CODE_OF_CONDUCT.md).\n"
        },
        {
          "name": "LICENSE.txt",
          "type": "blob",
          "size": 9.994140625,
          "content": "Copyright 2021-present StarRocks, Inc. All rights reserved.\n\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n"
        },
        {
          "name": "NOTICE.txt",
          "type": "blob",
          "size": 1.75390625,
          "content": "StarRocks\n\nCopyright 2021-present, StarRocks Inc.\n\n---------------------------\napache-doris-incubating NOTICE\n---------------------------\nApache Doris (incubating)\nCopyright 2018-2021 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\nBased on source code originally developed by\nBaidu (http://www.baidu.com/).\n\n\n---------------------------\napache-impala NOTICE\n---------------------------\nApache Impala\nCopyright 2019 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\nPortions of this software were developed at\nCloudera, Inc (http://www.cloudera.com/).\n\nThis product includes software developed by the OpenSSL\nProject for use in the OpenSSL Toolkit (http://www.openssl.org/)\n\nThis product includes cryptographic software written by Eric Young\n(eay@cryptsoft.com).  This product includes software written by Tim\nHudson (tjh@cryptsoft.com).\n\nThis product includes software developed by the University of Chicago,\nas Operator of Argonne National Laboratory.\nCopyright (C) 1999 University of Chicago. All rights reserved.\n\n---------------------------\napache-kudu NOTICE\n---------------------------\nApache Kudu\nCopyright 2016 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\nPortions of this software were developed at\nCloudera, Inc (http://www.cloudera.com/).\n\nThis product includes software developed by the OpenSSL\nProject for use in the OpenSSL Toolkit (http://www.openssl.org/)\n\nThis product includes cryptographic software written by Eric Young\n(eay@cryptsoft.com).  This product includes software written by Tim\nHudson (tjh@cryptsoft.com).\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 7.83984375,
          "content": "\n <img referrerpolicy=\"no-referrer-when-downgrade\" src=\"https://static.scarf.sh/a.png?x-pxid=e8355b6b-a9fc-4d4e-8ed8-b3157aa1827d\" />\n <p align=\"center\">\n <a href=\"https://starrocks.io/index\">\n    <img  width=\"900\" src=\"https://cdn.starrocks.io/static/github/starrocks.png?t=12234\">\n   </a>\n</p>\n<p align=\"center\">\n  <a href=\"https://starrocks.io/download/community\">Download</a> | <a href=\"https://docs.starrocks.io/\">Docs</a> | <a href=\"https://starrocks.io/blog/benchmark-test\">Benchmarks</a> | <a href=\"https://github.com/StarRocks/demo\">Demo</a>\n</p>\n<p align=\"center\">\n\n <img src=\"https://img.shields.io/badge/Made%20with-JAVA%20%26%20C%2B%2B-red\" alt=\"JAVA&C++\">\n    </a>\n    <img src=\"https://img.shields.io/github/commit-activity/m/StarRocks/starrocks\" alt=\"Commit Activities\">\n    </a>\n   <a href=\"https://github.com/StarRocks/starrocks/issues\">\n    <img src=\"https://img.shields.io/github/issues-raw/StarRocks/starrocks\" alt=\"Open Issues\">\n  </a>\n  </a>\n   <a href=\"https://starrocks.io/index\">\n    <img src=\"https://img.shields.io/badge/Visit%20StarRocks-Website-green\" alt=\"Website\">\n  </a>\n  </a>\n   <a href=\"https://try.starrocks.com/join-starrocks-on-slack\">\n    <img src=\"https://img.shields.io/badge/Join-Slack-ff69b4\" alt=\"Slack\">\n  </a>\n  </a>\n   <a href=\"https://twitter.com/StarRocksLabs\">\n    <img src=\"https://img.shields.io/twitter/follow/StarRocksLabs?style=social\" alt=\"Twitter\">\n  </a>\n  <a href=\"https://gurubase.io/g/starrocks\">\n    <img src=\"https://img.shields.io/badge/Gurubase-Ask%20StarRocks%20Guru-006BFF\" alt=\"Gurubase\">\n  </a>\n </p>\n\n<div align=\"center\"> \n\n</div>\nStarRocks is the world's fastest open query engine for sub-second, ad-hoc analytics both on and off the data lakehouse. With average query performance 3x faster than other popular alternatives, StarRocks is a query engine that eliminates the need for denormalization and adapts to your use cases, without having to move your data or rewrite SQL. A Linux Foundation project. <br></br>\n\nLearn more üëâüèª [What Is StarRocks: Features and Use Cases](https://www.youtube.com/watch?v=RfXO5GOnbW4&ab_channel=CelerData)\n\n<br>\n <p align=\"center\">\n    <img src=\"https://cdn.starrocks.io/static/github/community.gif\">\n   </a>\n</p>\n</br>\n\n## Features\n\n* **üöÄ Native vectorized SQL engine:** StarRocks adopts vectorization technology to make full use of the parallel computing power of CPU, achieving sub-second query returns in multi-dimensional analyses, which is 5 to 10 times faster than previous systems.\n* **üìä Standard SQL:** StarRocks supports ANSI SQL syntax (fully supported TPC-H and TPC-DS). It is also compatible with the MySQL protocol. Various clients and BI software can be used to access StarRocks.\n* **üí° Smart query optimization:** StarRocks can optimize complex queries through CBO (Cost Based Optimizer). With a better execution plan, the data analysis efficiency will be greatly improved.\n* **‚ö° Real-time update:** The updated model of StarRocks can perform upsert/delete operations according to the primary key, and achieve efficient query while concurrent updates.\n* **ü™ü Intelligent materialized view:** The materialized view of StarRocks can be automatically updated during the data import and automatically selected when the query is executed.\n* **‚ú® Querying data in data lakes directly**: StarRocks allows direct access to data from Apache Hive‚Ñ¢, Apache Iceberg‚Ñ¢, Delta Lake‚Ñ¢ and Apache Hudi‚Ñ¢ without importing.\n* **üéõÔ∏è Resource management**: This feature allows StarRocks to limit resource consumption for queries and implement isolation and efficient use of resources among tenants in the same cluster.\n* **üí† Easy to maintain**: Simple architecture makes StarRocks easy to deploy, maintain and scale out. StarRocks tunes its query plan agilely, balances the resources when the cluster is scaled in or out, and recovers the data replica under node failure automatically.\n\n\n\n<br>\n  \n## Architecture Overview\n\n <p align=\"center\">\n    <img src=\"images/arch.png\">\n   </a>\n</p>\n\n\nStarRocks‚Äôs streamlined architecture is mainly composed of two modules: Frontend (FE) and Backend (BE).  The entire system eliminates single points of failure through seamless and horizontal scaling of FE and BE, as well as replication of metadata and data.\n\nStarting from version 3.0, StarRocks supports a new shared-data architecture, which can provide better scalability and lower costs.\n\n <p align=\"center\">\n    <img src=\"docs/en/_assets/shared-data.png\" width=\"55%\" height=\"55%\">\n   </a>\n</p>\n\n\n<br>\n\n## Resources\n\n### üìö Read the docs\n\n| Section | Description |\n|-|-|\n| [Quick Starts](https://docs.starrocks.io/docs/quick_start/)| How-tos and Tutorials. |\n| [Deploy](https://docs.starrocks.io/docs/deployment/deployment_overview/) | Learn how to run and configure StarRocks.|\n| [Docs](https://docs.starrocks.io/)| Full documentation. |\n| [Blogs](https://www.starrocks.io/blog) | StarRocks deep dive and user stories.  |\n\n### ‚ùì Get support  \n[<img align=\"right\" width=\"150\" src=\"https://firstcontributions.github.io/assets/Readme/join-slack-team.png\">](https://try.starrocks.com/join-starrocks-on-slack)\n-  [Slack community: ](https://try.starrocks.com/join-starrocks-on-slack) join technical discussions, ask questions, and meet other users!\n-  [YouTube channel:](https://www.youtube.com/channel/UC38wR-ogamk4naaWNQ45y7Q/featured) subscribe to the latest video tutorials and webcasts.\n-  [GitHub issues:](https://github.com/StarRocks/starrocks/issues) report an issue with StarRocks.\n\n\n<br>  \n  \n## Contributing to StarRocks\n\nWe welcome all kinds of contributions from the community, individuals and partners. We owe our success to your active involvement.\n\n1. See [Contributing.md](https://github.com/StarRocks/starrocks/blob/main/CONTRIBUTING.md) to get started.\n2. Set up StarRocks development environment:\n* [IDE Setup](https://docs.starrocks.io/docs/developers/development-environment/ide-setup/) \n* [Compile StarRocks with Docker](https://docs.starrocks.io/docs/developers/build-starrocks/Build_in_docker/) \n* [Deploy StarRocks manually](https://docs.starrocks.io/docs/deployment/deploy_manually/) \n3. Understand our [GitHub workflow](https://github.com/StarRocks/community/blob/main/Contributors/guide/workflow.md) for opening a pull request; use this [PR Template](https://github.com/StarRocks/starrocks/blob/main/.github/PULL_REQUEST_TEMPLATE.md) when submitting a pull request.\n4. Pick a [good first issue](https://github.com/StarRocks/starrocks/labels/good%20first%20issue) and start contributing. \n\n**üìù License:** StarRocks is licensed under [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0).\n\n**üë• Community Membership:** Learn more about different [contributor roles](community/membership.md) in StarRocks community.\n\n**üí¨ Developer GroupÔºö** Please join our [Google Groups](https://groups.google.com/g/starrocks-dev) to discuss StarRocks features, project directions, issues, pull requests, or share suggestions.\n  \n<br>\n  \n## Used By\n\nThis project is used by the following companies. Learn more about their use cases:\n\n- [Airbnb](https://www.youtube.com/watch?v=AzDxEZuMBwM&ab_channel=StarRocks_labs)\n- [Pinterest](https://medium.com/pinterest-engineering/delivering-faster-analytics-at-pinterest-a639cdfad374)\n- [Coinbase](https://www.youtube.com/watch?v=3Z9jSCaHnYg&list=PL0eWwaesODdhBhKSnvpfIEAB9sgk8rKmy)\n- [Tencent(Games)](https://www.starrocks.io/blog/tencent-unifies-their-gaming-analytics-with-starrocks)\n- [Tencent(LLM)](https://www.youtube.com/watch?v=WVHXFks9EQk)\n- [Demandbase](https://starrocks.medium.com/demandbase-ditches-denormalization-by-switching-off-clickhouse-44195d795a83)\n- [Shopee](https://celerdata.com/blog/how-shopee-3xed-their-query-performance-with-starrocks)\n- [Trip.com](https://starrocks.medium.com/trip-com-starrocks-efficiently-supports-high-concurrent-queries-dramatically-reduces-labor-and-1e1921dd6bf8) \n- [Didi](https://www.starrocks.io/blog/reduced-80-cost-didis-journey-from-multiple-olap-engines-to-starrocks) \n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.1845703125,
          "content": "# Security Policy\n\n## Reporting a Vulnerability\n\nTo report a potential vulnerability in StarRocks please send the details about it to [support@starrocks.com](mailto:support@starrocks.com).\n"
        },
        {
          "name": "be",
          "type": "tree",
          "content": null
        },
        {
          "name": "bin",
          "type": "tree",
          "content": null
        },
        {
          "name": "build-support",
          "type": "tree",
          "content": null
        },
        {
          "name": "build.sh",
          "type": "blob",
          "size": 26.908203125,
          "content": "#!/usr/bin/env bash\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n##############################################################\n# This script is used to compile StarRocks\n# Usage: \n#    sh build.sh --help\n# Eg:\n#    sh build.sh                                      build all\n#    sh build.sh  --be                                build Backend without clean\n#    sh build.sh  --fe --clean                        clean and build Frontend and Spark Dpp application\n#    sh build.sh  --fe --be --clean                   clean and build Frontend, Spark Dpp application and Backend\n#    sh build.sh  --spark-dpp                         build Spark DPP application alone\n#    sh build.sh  --hive-udf                          build Hive UDF alone\n#    BUILD_TYPE=build_type ./build.sh --be            build Backend is different mode (build_type could be Release, Debug, or Asan. Default value is Release. To build Backend in Debug mode, you can execute: BUILD_TYPE=Debug ./build.sh --be)\n#\n# You need to make sure all thirdparty libraries have been\n# compiled and installed correctly.\n##############################################################\nstartTime=$(date +%s)\nROOT=`dirname \"$0\"`\nROOT=`cd \"$ROOT\"; pwd`\nMACHINE_TYPE=$(uname -m)\n\nexport STARROCKS_HOME=${ROOT}\n\nif [ -z $BUILD_TYPE ]; then\n    export BUILD_TYPE=Release\nfi\n\ncd $STARROCKS_HOME\nif [ -z $STARROCKS_VERSION ]; then\n    tag_name=$(git describe --tags --exact-match 2>/dev/null)\n    branch_name=$(git symbolic-ref -q --short HEAD)\n    if [ ! -z $tag_name ]; then\n        export STARROCKS_VERSION=$tag_name\n    elif [ ! -z $branch_name ]; then\n        export STARROCKS_VERSION=$branch_name\n    else\n        export STARROCKS_VERSION=$(git rev-parse --short=7 HEAD)\n    fi\nfi\n\nif [ -z $STARROCKS_COMMIT_HASH ] ; then\n    export STARROCKS_COMMIT_HASH=$(git rev-parse --short=7 HEAD)\nfi\n\nset -eo pipefail\n. ${STARROCKS_HOME}/env.sh\n\nif [[ $OSTYPE == darwin* ]] ; then\n    PARALLEL=$(sysctl -n hw.ncpu)\n    # We know for sure that build-thirdparty.sh will fail on darwin platform, so just skip the step.\nelse\n    if [[ ! -f ${STARROCKS_THIRDPARTY}/installed/llvm/lib/libLLVMInstCombine.a ]]; then\n        echo \"Thirdparty libraries need to be build ...\"\n        ${STARROCKS_THIRDPARTY}/build-thirdparty.sh\n    fi\n    PARALLEL=$[$(nproc)/4+1]\nfi\n\n# Check args\nusage() {\n  echo \"\nUsage: $0 <options>\n  Optional options:\n     --be               build Backend\n     --format-lib       build StarRocks format library, only with shared-data mode cluster\n     --fe               build Frontend and Spark Dpp application\n     --spark-dpp        build Spark DPP application\n     --hive-udf         build Hive UDF\n     --clean            clean and build target\n     --enable-shared-data\n                        build Backend with shared-data feature support\n     --use-staros       DEPRECATED, an alias of --enable-shared-data option\n     --with-gcov        build Backend with gcov, has an impact on performance\n     --without-gcov     build Backend without gcov(default)\n     --with-bench       build Backend with bench(default without bench)\n     --with-clang-tidy  build Backend with clang-tidy(default without clang-tidy)\n     --without-java-ext build Backend without java-extensions(default with java-extensions)\n     --without-starcache\n                        build Backend without starcache library\n     -j                 build Backend parallel\n     --output-compile-time \n                        save a list of the compile time for every C++ file in ${ROOT}/compile_times.txt.\n                        Turning this option on automatically disables ccache.\n     --without-tenann\n                        build without vector index tenann library\n     --with-compress-debug-symbol {ON|OFF}\n                        build with compressing debug symbol. (default: $WITH_COMPRESS)\n     --with-source-file-relative-path {ON|OFF}\n                        build source file with relative path. (default: $WITH_RELATIVE_SRC_PATH)\n     --without-avx2     build Backend without avx2(instruction)    \n     -h,--help          Show this help message\n  Eg.\n    $0                                           build all\n    $0 --be                                      build Backend without clean\n    $0 --format-lib                              build StarRocks format library without clean\n    $0 --fe --clean                              clean and build Frontend and Spark Dpp application\n    $0 --fe --be --clean                         clean and build Frontend, Spark Dpp application and Backend\n    $0 --spark-dpp                               build Spark DPP application alone\n    $0 --hive-udf                                build Hive UDF\n    BUILD_TYPE=build_type ./build.sh --be        build Backend is different mode (build_type could be Release, Debug, or Asan. Default value is Release. To build Backend in Debug mode, you can execute: BUILD_TYPE=Debug ./build.sh --be)\n  \"\n  exit 1\n}\n\nOPTS=$(getopt \\\n  -n $0 \\\n  -o 'hj:' \\\n  -l 'be' \\\n  -l 'format-lib' \\\n  -l 'fe' \\\n  -l 'spark-dpp' \\\n  -l 'hive-udf' \\\n  -l 'clean' \\\n  -l 'with-gcov' \\\n  -l 'with-bench' \\\n  -l 'with-clang-tidy' \\\n  -l 'without-gcov' \\\n  -l 'without-java-ext' \\\n  -l 'without-starcache' \\\n  -l 'with-brpc-keepalive' \\\n  -l 'use-staros' \\\n  -l 'enable-shared-data' \\\n  -l 'output-compile-time' \\\n  -l 'without-tenann' \\\n  -l 'with-compress-debug-symbol:' \\\n  -l 'with-source-file-relative-path:' \\\n  -l 'without-avx2' \\\n  -l 'help' \\\n  -- \"$@\")\n\nif [ $? != 0 ] ; then\n    usage\nfi\n\neval set -- \"$OPTS\"\n\nBUILD_BE=\nBUILD_FORMAT_LIB=\nBUILD_FE=\nBUILD_SPARK_DPP=\nBUILD_HIVE_UDF=\nCLEAN=\nRUN_UT=\nWITH_GCOV=OFF\nWITH_BENCH=OFF\nWITH_CLANG_TIDY=OFF\nWITH_COMPRESS=ON\nWITH_STARCACHE=ON\nUSE_STAROS=OFF\nBUILD_JAVA_EXT=ON\nOUTPUT_COMPILE_TIME=OFF\nWITH_TENANN=ON\nWITH_RELATIVE_SRC_PATH=ON\nMSG=\"\"\nMSG_FE=\"Frontend\"\nMSG_DPP=\"Spark Dpp application\"\nMSG_BE=\"Backend\"\nMSG_FORMAT_LIB=\"Format Lib\"\nif [[ -z ${USE_AVX2} ]]; then\n    USE_AVX2=ON\nfi\nif [[ -z ${USE_AVX512} ]]; then\n    ## Disable it by default\n    USE_AVX512=OFF\nfi\nif [[ -z ${USE_SSE4_2} ]]; then\n    USE_SSE4_2=ON\nfi\nif [[ -z ${USE_BMI_2} ]]; then\n    USE_BMI_2=ON\nfi\nif [[ -z ${JEMALLOC_DEBUG} ]]; then\n    JEMALLOC_DEBUG=OFF\nfi\nif [[ -z ${ENABLE_JIT} ]]; then\n    ENABLE_JIT=ON\nfi\n\nif [[ -z ${CCACHE} ]] && [[ -x \"$(command -v ccache)\" ]]; then\n    CCACHE=ccache\nfi\n\nif [ -e /proc/cpuinfo ] ; then\n    # detect cpuinfo\n    if [[ -z $(grep -o 'avx[^ ]\\+' /proc/cpuinfo) ]]; then\n        USE_AVX2=OFF\n    fi\n    if [[ -z $(grep -o 'avx512' /proc/cpuinfo) ]]; then\n        USE_AVX512=OFF\n    fi\n    if [[ -z $(grep -o 'sse4[^ ]*' /proc/cpuinfo) ]]; then\n        USE_SSE4_2=OFF\n    fi\n    if [[ -z $(grep -o 'bmi2' /proc/cpuinfo) ]]; then\n        USE_BMI_2=OFF\n    fi\nfi\n\nif [[ -z ${ENABLE_QUERY_DEBUG_TRACE} ]]; then\n\tENABLE_QUERY_DEBUG_TRACE=OFF\nfi\n\nif [[ -z ${ENABLE_FAULT_INJECTION} ]]; then\n    ENABLE_FAULT_INJECTION=OFF\nfi\n\nHELP=0\nif [ $# == 1 ] ; then\n    # default. `sh build.sh``\n    BUILD_BE=1\n    BUILD_FE=1\n    BUILD_SPARK_DPP=1\n    BUILD_HIVE_UDF=1\n    BUILD_FORMAT_LIB=0\n    CLEAN=0\n    RUN_UT=0\nelif [[ $OPTS =~ \"-j \" ]] && [ $# == 3 ]; then\n    # default. `sh build.sh -j 32`\n    BUILD_BE=1\n    BUILD_FE=1\n    BUILD_SPARK_DPP=1\n    BUILD_HIVE_UDF=1\n    BUILD_FORMAT_LIB=0\n    CLEAN=0\n    RUN_UT=0\n    PARALLEL=$2\nelse\n    BUILD_BE=0\n    BUILD_FORMAT_LIB=0\n    BUILD_FE=0\n    BUILD_SPARK_DPP=0\n    BUILD_HIVE_UDF=0\n    CLEAN=0\n    RUN_UT=0\n    while true; do\n        case \"$1\" in\n            --be) BUILD_BE=1 ; shift ;;\n            --format-lib) BUILD_FORMAT_LIB=1 ; shift ;;\n            --fe) BUILD_FE=1 ; shift ;;\n            --spark-dpp) BUILD_SPARK_DPP=1 ; shift ;;\n            --hive-udf) BUILD_HIVE_UDF=1 ; shift ;;\n            --clean) CLEAN=1 ; shift ;;\n            --ut) RUN_UT=1   ; shift ;;\n            --with-gcov) WITH_GCOV=ON; shift ;;\n            --without-gcov) WITH_GCOV=OFF; shift ;;\n            --enable-shared-data|--use-staros) USE_STAROS=ON; shift ;;\n            --with-bench) WITH_BENCH=ON; shift ;;\n            --with-clang-tidy) WITH_CLANG_TIDY=ON; shift ;;\n            --without-java-ext) BUILD_JAVA_EXT=OFF; shift ;;\n            --without-starcache) WITH_STARCACHE=OFF; shift ;;\n            --output-compile-time) OUTPUT_COMPILE_TIME=ON; shift ;;\n            --without-tenann) WITH_TENANN=OFF; shift ;;\n            --without-avx2) USE_AVX2=OFF; shift ;;\n            --with-compress-debug-symbol) WITH_COMPRESS=$2 ; shift 2 ;;\n            --with-source-file-relative-path) WITH_RELATIVE_SRC_PATH=$2 ; shift 2 ;;\n            -h) HELP=1; shift ;;\n            --help) HELP=1; shift ;;\n            -j) PARALLEL=$2; shift 2 ;;\n            --) shift ;  break ;;\n            *) echo \"Internal error\" ; exit 1 ;;\n        esac\n    done\nfi\n\nif [[ ${HELP} -eq 1 ]]; then\n    usage\n    exit\nfi\n\nif [ ${CLEAN} -eq 1 ] && [ ${BUILD_BE} -eq 0 ] && [ ${BUILD_FORMAT_LIB} -eq 0 ] && [ ${BUILD_FE} -eq 0 ] && [ ${BUILD_SPARK_DPP} -eq 0 ] && [ ${BUILD_HIVE_UDF} -eq 0 ]; then\n    echo \"--clean can not be specified without --fe or --be or --format-lib or --spark-dpp or --hive-udf\"\n    exit 1\nfi\nif [ ${BUILD_BE} -eq 1 ] && [ ${BUILD_FORMAT_LIB} -eq 1 ]; then\n    echo \"--format-lib can not be specified with --be\"\n    exit 1\nfi\nif [ ${BUILD_FORMAT_LIB} -eq 1 ]; then\n    echo \"do not build java extensions when build format-lib.\"\n    BUILD_JAVA_EXT=OFF\nfi\n\necho \"Get params:\n    BUILD_BE                    -- $BUILD_BE\n    BUILD_FORMAT_LIB            -- $BUILD_FORMAT_LIB\n    BE_CMAKE_TYPE               -- $BUILD_TYPE\n    BUILD_FE                    -- $BUILD_FE\n    BUILD_SPARK_DPP             -- $BUILD_SPARK_DPP\n    BUILD_HIVE_UDF              -- $BUILD_HIVE_UDF\n    CCACHE                      -- ${CCACHE}\n    CLEAN                       -- $CLEAN\n    RUN_UT                      -- $RUN_UT\n    WITH_GCOV                   -- $WITH_GCOV\n    WITH_BENCH                  -- $WITH_BENCH\n    WITH_CLANG_TIDY             -- $WITH_CLANG_TIDY\n    WITH_COMPRESS_DEBUG_SYMBOL  -- $WITH_COMPRESS\n    WITH_STARCACHE              -- $WITH_STARCACHE\n    ENABLE_SHARED_DATA          -- $USE_STAROS\n    USE_AVX2                    -- $USE_AVX2\n    USE_AVX512                  -- $USE_AVX512\n    USE_SSE4_2                  -- $USE_SSE4_2\n    USE_BMI_2                   -- $USE_BMI_2\n    JEMALLOC_DEBUG              -- $JEMALLOC_DEBUG\n    PARALLEL                    -- $PARALLEL\n    ENABLE_QUERY_DEBUG_TRACE    -- $ENABLE_QUERY_DEBUG_TRACE\n    ENABLE_FAULT_INJECTION      -- $ENABLE_FAULT_INJECTION\n    BUILD_JAVA_EXT              -- $BUILD_JAVA_EXT\n    OUTPUT_COMPILE_TIME         -- $OUTPUT_COMPILE_TIME\n    WITH_TENANN                 -- $WITH_TENANN\n    WITH_RELATIVE_SRC_PATH      -- $WITH_RELATIVE_SRC_PATH\n\"\n\ncheck_tool()\n{\n    local toolname=$1\n    if [ -e $STARROCKS_THIRDPARTY/installed/bin/$toolname ] ; then\n        return 0\n    fi\n    if which $toolname &>/dev/null ; then\n        return 0\n    fi\n    return 1\n}\n\n# check protoc and thrift\nfor tool in protoc thrift\ndo\n    if ! check_tool $tool ; then\n        echo \"Can't find command tool '$tool'!\"\n        exit 1\n    fi\ndone\n\n# Clean and build generated code\necho \"Build generated code\"\ncd ${STARROCKS_HOME}/gensrc\nif [ ${CLEAN} -eq 1 ]; then\n   make clean\n   rm -rf ${STARROCKS_HOME}/fe/fe-core/target\nfi\n# DO NOT using parallel make(-j) for gensrc\nmake\ncd ${STARROCKS_HOME}\n\nif [[ \"${MACHINE_TYPE}\" == \"aarch64\" ]]; then\n    export LIBRARY_PATH=${JAVA_HOME}/jre/lib/aarch64/server/\n    WITH_TENANN=OFF\nelse\n    export LIBRARY_PATH=${JAVA_HOME}/jre/lib/amd64/server/\nfi\n\n# Clean and build Backend\nif [ ${BUILD_BE} -eq 1 ] || [ ${BUILD_FORMAT_LIB} -eq 1 ] ; then\n    if ! ${CMAKE_CMD} --version; then\n        echo \"Error: cmake is not found\"\n        exit 1\n    fi\n\n    # When build starrocks format lib, USE_STAROS must be ON\n    if [ ${BUILD_FORMAT_LIB} -eq 1 ] ; then\n        USE_STAROS=ON\n        WITH_TENANN=OFF\n    fi\n\n    CMAKE_BUILD_TYPE=$BUILD_TYPE\n    echo \"Build Backend: ${CMAKE_BUILD_TYPE}\"\n    CMAKE_BUILD_DIR=${STARROCKS_HOME}/be/build_${CMAKE_BUILD_TYPE}\n    if [ \"${WITH_GCOV}\" = \"ON\" ]; then\n        CMAKE_BUILD_DIR=${STARROCKS_HOME}/be/build_${CMAKE_BUILD_TYPE}_gcov\n    fi\n    if [ ${BUILD_FORMAT_LIB} -eq 1 ] ; then\n        CMAKE_BUILD_DIR=${STARROCKS_HOME}/be/build_${CMAKE_BUILD_TYPE}_format-lib\n    fi\n\n    if [ ${CLEAN} -eq 1 ]; then\n        rm -rf $CMAKE_BUILD_DIR\n        rm -rf ${STARROCKS_HOME}/be/output/\n    fi\n    mkdir -p ${CMAKE_BUILD_DIR}\n\n    source ${STARROCKS_HOME}/bin/common.sh\n\n    cd ${CMAKE_BUILD_DIR}\n    if [ \"${USE_STAROS}\" == \"ON\"  ]; then\n      if [ -z \"$STARLET_INSTALL_DIR\" ] ; then\n        # assume starlet_thirdparty is installed to ${STARROCKS_THIRDPARTY}/installed/starlet/\n        STARLET_INSTALL_DIR=${STARROCKS_THIRDPARTY}/installed/starlet\n      fi\n      export STARLET_INSTALL_DIR\n    fi\n    \n    if [ \"${OUTPUT_COMPILE_TIME}\" == \"ON\" ]; then\n        rm -f ${ROOT}/compile_times.txt\n        CXX_COMPILER_LAUNCHER=${ROOT}/build-support/compile_time.sh\n    else\n        CXX_COMPILER_LAUNCHER=${CCACHE}\n    fi\n    if [ \"${WITH_CLANG_TIDY}\" == \"ON\" ];then\n        # this option cannot work with clang-14\n        WITH_COMPRESS=OFF\n    fi\n\n\n    ${CMAKE_CMD} -G \"${CMAKE_GENERATOR}\"                                \\\n                  -DSTARROCKS_THIRDPARTY=${STARROCKS_THIRDPARTY}        \\\n                  -DSTARROCKS_HOME=${STARROCKS_HOME}                    \\\n                  -DSTARLET_INSTALL_DIR=${STARLET_INSTALL_DIR}          \\\n                  -DCMAKE_CXX_COMPILER_LAUNCHER=${CXX_COMPILER_LAUNCHER} \\\n                  -DCMAKE_BUILD_TYPE=${CMAKE_BUILD_TYPE}                \\\n                  -DMAKE_TEST=OFF -DWITH_GCOV=${WITH_GCOV}              \\\n                  -DUSE_AVX2=$USE_AVX2 -DUSE_AVX512=$USE_AVX512         \\\n                  -DUSE_SSE4_2=$USE_SSE4_2 -DUSE_BMI_2=$USE_BMI_2       \\\n                  -DJEMALLOC_DEBUG=$JEMALLOC_DEBUG                      \\\n                  -DENABLE_QUERY_DEBUG_TRACE=$ENABLE_QUERY_DEBUG_TRACE  \\\n                  -DWITH_BENCH=${WITH_BENCH}                            \\\n                  -DWITH_CLANG_TIDY=${WITH_CLANG_TIDY}                  \\\n                  -DWITH_COMPRESS=${WITH_COMPRESS}                      \\\n                  -DWITH_STARCACHE=${WITH_STARCACHE}                    \\\n                  -DUSE_STAROS=${USE_STAROS}                            \\\n                  -DENABLE_FAULT_INJECTION=${ENABLE_FAULT_INJECTION}    \\\n                  -DBUILD_BE=${BUILD_BE}                                \\\n                  -DWITH_TENANN=${WITH_TENANN}                          \\\n                  -DSTARROCKS_JIT_ENABLE=${ENABLE_JIT}                  \\\n                  -DCMAKE_EXPORT_COMPILE_COMMANDS=ON                    \\\n                  -DBUILD_FORMAT_LIB=${BUILD_FORMAT_LIB}                \\\n                  -DWITH_RELATIVE_SRC_PATH=${WITH_RELATIVE_SRC_PATH}    \\\n                  ..\n\n    time ${BUILD_SYSTEM} -j${PARALLEL}\n    if [ \"${WITH_CLANG_TIDY}\" == \"ON\" ];then\n        exit 0\n    fi\n\n    ${BUILD_SYSTEM} install\n\n    # Build Java Extensions\n    if [ ${BUILD_JAVA_EXT} = \"ON\" ]; then\n        echo \"Build Java Extensions\"\n        cd ${STARROCKS_HOME}/java-extensions\n        if [ ${CLEAN} -eq 1 ]; then\n            ${MVN_CMD} clean\n        fi\n        ${MVN_CMD} package -DskipTests\n        cd ${STARROCKS_HOME}\n    else\n        echo \"Skip Building Java Extensions\"\n    fi\nfi\n\ncd ${STARROCKS_HOME}\n\n# Assesmble FE modules\nFE_MODULES=\nif [ ${BUILD_FE} -eq 1 ] || [ ${BUILD_SPARK_DPP} -eq 1 ] || [ ${BUILD_HIVE_UDF} -eq 1 ]; then\n    if [ ${BUILD_SPARK_DPP} -eq 1 ]; then\n        FE_MODULES=\"fe-common,spark-dpp\"\n    fi\n    if [ ${BUILD_HIVE_UDF} -eq 1 ]; then\n        FE_MODULES=\"fe-common,hive-udf\"\n    fi\n    if [ ${BUILD_FE} -eq 1 ]; then\n        FE_MODULES=\"hive-udf,fe-common,spark-dpp,fe-core\"\n    fi\nfi\n\n# Clean and build Frontend\nif [ ${FE_MODULES}x != \"\"x ]; then\n    echo \"Build Frontend Modules: $FE_MODULES\"\n    cd ${STARROCKS_HOME}/fe\n    if [ ${CLEAN} -eq 1 ]; then\n        ${MVN_CMD} clean\n    fi\n    ${MVN_CMD} package -am -pl ${FE_MODULES} -DskipTests\n    cd ${STARROCKS_HOME}/java-extensions\n    ${MVN_CMD} package -am -pl hadoop-ext -DskipTests\n    cd ${STARROCKS_HOME}\nfi\n\n\n# Clean and prepare output dir\nSTARROCKS_OUTPUT=${STARROCKS_HOME}/output/\nmkdir -p ${STARROCKS_OUTPUT}\n\n# Copy Frontend and Backend\nif [ ${BUILD_FE} -eq 1 -o ${BUILD_SPARK_DPP} -eq 1 ]; then\n    if [ ${BUILD_FE} -eq 1 ]; then\n        install -d ${STARROCKS_OUTPUT}/fe/bin ${STARROCKS_OUTPUT}/fe/conf/ \\\n                   ${STARROCKS_OUTPUT}/fe/webroot/ ${STARROCKS_OUTPUT}/fe/lib/ \\\n                   ${STARROCKS_OUTPUT}/fe/spark-dpp/ ${STARROCKS_OUTPUT}/fe/hive-udf\n\n        cp -r -p ${STARROCKS_HOME}/bin/*_fe.sh ${STARROCKS_OUTPUT}/fe/bin/\n        cp -r -p ${STARROCKS_HOME}/bin/show_fe_version.sh ${STARROCKS_OUTPUT}/fe/bin/\n        cp -r -p ${STARROCKS_HOME}/bin/common.sh ${STARROCKS_OUTPUT}/fe/bin/\n        cp -r -p ${STARROCKS_HOME}/conf/fe.conf ${STARROCKS_OUTPUT}/fe/conf/\n        cp -r -p ${STARROCKS_HOME}/conf/udf_security.policy ${STARROCKS_OUTPUT}/fe/conf/\n        cp -r -p ${STARROCKS_HOME}/conf/hadoop_env.sh ${STARROCKS_OUTPUT}/fe/conf/\n        cp -r -p ${STARROCKS_HOME}/conf/core-site.xml ${STARROCKS_OUTPUT}/fe/conf/\n        cp -r -p ${STARROCKS_HOME}/conf/cluster_snapshot.yaml ${STARROCKS_OUTPUT}/fe/conf/\n\n        rm -rf ${STARROCKS_OUTPUT}/fe/lib/*\n        cp -r -p ${STARROCKS_HOME}/fe/fe-core/target/lib/* ${STARROCKS_OUTPUT}/fe/lib/\n        cp -r -p ${STARROCKS_HOME}/fe/fe-core/target/starrocks-fe.jar ${STARROCKS_OUTPUT}/fe/lib/\n        cp -r -p ${STARROCKS_HOME}/java-extensions/hadoop-ext/target/starrocks-hadoop-ext.jar ${STARROCKS_OUTPUT}/fe/lib/\n        cp -r -p ${STARROCKS_HOME}/webroot/* ${STARROCKS_OUTPUT}/fe/webroot/\n        cp -r -p ${STARROCKS_HOME}/fe/spark-dpp/target/spark-dpp-*-jar-with-dependencies.jar ${STARROCKS_OUTPUT}/fe/spark-dpp/\n        cp -r -p ${STARROCKS_HOME}/fe/hive-udf/target/hive-udf-1.0.0.jar ${STARROCKS_OUTPUT}/fe/hive-udf/\n        cp -r -p ${STARROCKS_THIRDPARTY}/installed/async-profiler ${STARROCKS_OUTPUT}/fe/bin/\n        MSG=\"${MSG} ‚àö ${MSG_FE}\"\n    elif [ ${BUILD_SPARK_DPP} -eq 1 ]; then\n        install -d ${STARROCKS_OUTPUT}/fe/spark-dpp/\n        rm -rf ${STARROCKS_OUTPUT}/fe/spark-dpp/*\n        cp -r -p ${STARROCKS_HOME}/fe/spark-dpp/target/spark-dpp-*-jar-with-dependencies.jar ${STARROCKS_OUTPUT}/fe/spark-dpp/\n        cp -r -p ${STARROCKS_HOME}/fe/hive-udf/target/hive-udf-1.0.0.jar ${STARROCKS_HOME}/fe/hive-udf/\n        MSG=\"${MSG} ‚àö ${MSG_DPP}\"\n    fi\nfi\n\nif [ ${BUILD_FORMAT_LIB} -eq 1 ]; then\n    rm -rf ${STARROCKS_OUTPUT}/format-lib/*\n    mkdir -p ${STARROCKS_OUTPUT}/format-lib\n    cp -r ${STARROCKS_HOME}/be/output/format-lib/* ${STARROCKS_OUTPUT}/format-lib/\n    # format $BUILD_TYPE to lower case\n    ibuildtype=`echo ${BUILD_TYPE} | tr 'A-Z' 'a-z'`\n    if [ \"${ibuildtype}\" == \"release\" ] ; then\n        pushd ${STARROCKS_OUTPUT}/format-lib/ &>/dev/null\n        FORMAT_LIB=libstarrocks_format.so\n        FORMAT_LIB_DEBUGINFO=libstarrocks_format.debuginfo\n        echo \"Split $FORMAT_LIB debug symbol to $FORMAT_LIB_DEBUGINFO ...\"\n        # strip be binary\n        # if eu-strip is available, can replace following three lines into `eu-strip -g -f starrocks_be.debuginfo starrocks_be`\n        objcopy --only-keep-debug $FORMAT_LIB $FORMAT_LIB_DEBUGINFO\n        strip --strip-debug $FORMAT_LIB\n        objcopy --add-gnu-debuglink=$FORMAT_LIB_DEBUGINFO $FORMAT_LIB\n        popd &>/dev/null\n    fi\n    MSG=\"${MSG} ‚àö ${MSG_FORMAT_LIB}\"\nfi\n\nif [ ${BUILD_BE} -eq 1 ]; then\n    rm -rf ${STARROCKS_OUTPUT}/be/lib/*\n    mkdir -p ${STARROCKS_OUTPUT}/be/lib/jni-packages\n    mkdir -p ${STARROCKS_OUTPUT}/be/lib/py-packages\n\n    install -d ${STARROCKS_OUTPUT}/be/bin  \\\n               ${STARROCKS_OUTPUT}/be/conf \\\n               ${STARROCKS_OUTPUT}/be/lib/hadoop \\\n               ${STARROCKS_OUTPUT}/be/www  \\\n\n    cp -r -p ${STARROCKS_HOME}/be/output/bin/* ${STARROCKS_OUTPUT}/be/bin/\n    cp -r -p ${STARROCKS_HOME}/be/output/conf/be.conf ${STARROCKS_OUTPUT}/be/conf/\n    cp -r -p ${STARROCKS_HOME}/be/output/conf/udf_security.policy ${STARROCKS_OUTPUT}/be/conf/\n    cp -r -p ${STARROCKS_HOME}/be/output/conf/be_test.conf ${STARROCKS_OUTPUT}/be/conf/\n    cp -r -p ${STARROCKS_HOME}/be/output/conf/cn.conf ${STARROCKS_OUTPUT}/be/conf/\n    cp -r -p ${STARROCKS_HOME}/be/output/conf/hadoop_env.sh ${STARROCKS_OUTPUT}/be/conf/\n    cp -r -p ${STARROCKS_HOME}/be/output/conf/log4j2.properties ${STARROCKS_OUTPUT}/be/conf/\n    cp -r -p ${STARROCKS_HOME}/be/output/conf/core-site.xml ${STARROCKS_OUTPUT}/be/conf/\n\n    if [ \"${BUILD_TYPE}\" == \"ASAN\" ]; then\n        cp -r -p ${STARROCKS_HOME}/be/output/conf/asan_suppressions.conf ${STARROCKS_OUTPUT}/be/conf/\n    fi\n    cp -r -p ${STARROCKS_HOME}/be/output/lib/starrocks_be ${STARROCKS_OUTPUT}/be/lib/\n    cp -r -p ${STARROCKS_HOME}/be/output/lib/libmockjvm.so ${STARROCKS_OUTPUT}/be/lib/libjvm.so\n    cp -r -p ${STARROCKS_THIRDPARTY}/installed/jemalloc/bin/jeprof ${STARROCKS_OUTPUT}/be/bin\n    # format $BUILD_TYPE to lower case\n    ibuildtype=`echo ${BUILD_TYPE} | tr 'A-Z' 'a-z'`\n    if [ \"${ibuildtype}\" == \"release\" ] ; then\n        pushd ${STARROCKS_OUTPUT}/be/lib/ &>/dev/null\n        BE_BIN=starrocks_be\n        BE_BIN_DEBUGINFO=starrocks_be.debuginfo\n        echo \"Split $BE_BIN debug symbol to $BE_BIN_DEBUGINFO ...\"\n        # strip be binary\n        # if eu-strip is available, can replace following three lines into `eu-strip -g -f starrocks_be.debuginfo starrocks_be`\n        objcopy --only-keep-debug $BE_BIN $BE_BIN_DEBUGINFO\n        strip --strip-debug $BE_BIN\n        objcopy --add-gnu-debuglink=$BE_BIN_DEBUGINFO $BE_BIN\n        popd &>/dev/null\n    fi\n    cp -r -p ${STARROCKS_HOME}/be/output/www/* ${STARROCKS_OUTPUT}/be/www/\n\n    if [ \"${BUILD_JAVA_EXT}\" == \"ON\" ]; then\n        cp -r -p ${STARROCKS_HOME}/java-extensions/jdbc-bridge/target/starrocks-jdbc-bridge-jar-with-dependencies.jar ${STARROCKS_OUTPUT}/be/lib/jni-packages\n        cp -r -p ${STARROCKS_HOME}/java-extensions/udf-extensions/target/udf-extensions-jar-with-dependencies.jar ${STARROCKS_OUTPUT}/be/lib/jni-packages\n        cp -r -p ${STARROCKS_HOME}/java-extensions/java-utils/target/starrocks-java-utils.jar ${STARROCKS_OUTPUT}/be/lib/jni-packages\n        cp -r -p ${STARROCKS_HOME}/java-extensions/jni-connector/target/starrocks-jni-connector.jar ${STARROCKS_OUTPUT}/be/lib/jni-packages\n        cp -r -p ${STARROCKS_HOME}/java-extensions/hudi-reader/target/hudi-reader-lib ${STARROCKS_OUTPUT}/be/lib/\n        cp -r -p ${STARROCKS_HOME}/java-extensions/hudi-reader/target/starrocks-hudi-reader.jar ${STARROCKS_OUTPUT}/be/lib/jni-packages\n        cp -r -p ${STARROCKS_HOME}/java-extensions/hudi-reader/target/starrocks-hudi-reader.jar ${STARROCKS_OUTPUT}/be/lib/hudi-reader-lib\n        cp -r -p ${STARROCKS_HOME}/java-extensions/odps-reader/target/odps-reader-lib ${STARROCKS_OUTPUT}/be/lib/\n        cp -r -p ${STARROCKS_HOME}/java-extensions/odps-reader/target/starrocks-odps-reader.jar ${STARROCKS_OUTPUT}/be/lib/jni-packages\n        cp -r -p ${STARROCKS_HOME}/java-extensions/odps-reader/target/starrocks-odps-reader.jar ${STARROCKS_OUTPUT}/be/lib/odps-reader-lib\n        cp -r -p ${STARROCKS_HOME}/java-extensions/iceberg-metadata-reader/target/iceberg-reader-lib ${STARROCKS_OUTPUT}/be/lib/\n        cp -r -p ${STARROCKS_HOME}/java-extensions/iceberg-metadata-reader/target/starrocks-iceberg-metadata-reader.jar ${STARROCKS_OUTPUT}/be/lib/jni-packages\n        cp -r -p ${STARROCKS_HOME}/java-extensions/iceberg-metadata-reader/target/starrocks-iceberg-metadata-reader.jar ${STARROCKS_OUTPUT}/be/lib/iceberg-reader-lib\n        cp -r -p ${STARROCKS_HOME}/java-extensions/common-runtime/target/common-runtime-lib ${STARROCKS_OUTPUT}/be/lib/\n        cp -r -p ${STARROCKS_HOME}/java-extensions/paimon-reader/target/paimon-reader-lib ${STARROCKS_OUTPUT}/be/lib/\n        cp -r -p ${STARROCKS_HOME}/java-extensions/paimon-reader/target/starrocks-paimon-reader.jar ${STARROCKS_OUTPUT}/be/lib/jni-packages\n        cp -r -p ${STARROCKS_HOME}/java-extensions/paimon-reader/target/starrocks-paimon-reader.jar ${STARROCKS_OUTPUT}/be/lib/paimon-reader-lib\n        cp -r -p ${STARROCKS_HOME}/java-extensions/kudu-reader/target/kudu-reader-lib ${STARROCKS_OUTPUT}/be/lib/\n        cp -r -p ${STARROCKS_HOME}/java-extensions/kudu-reader/target/starrocks-kudu-reader.jar ${STARROCKS_OUTPUT}/be/lib/jni-packages\n        cp -r -p ${STARROCKS_HOME}/java-extensions/kudu-reader/target/starrocks-kudu-reader.jar ${STARROCKS_OUTPUT}/be/lib/kudu-reader-lib\n        cp -r -p ${STARROCKS_HOME}/java-extensions/hadoop-ext/target/starrocks-hadoop-ext.jar ${STARROCKS_OUTPUT}/be/lib/jni-packages\n        cp -r -p ${STARROCKS_HOME}/java-extensions/hive-reader/target/hive-reader-lib ${STARROCKS_OUTPUT}/be/lib/\n        cp -r -p ${STARROCKS_HOME}/java-extensions/hive-reader/target/starrocks-hive-reader.jar ${STARROCKS_OUTPUT}/be/lib/jni-packages\n        cp -r -p ${STARROCKS_HOME}/java-extensions/hive-reader/target/starrocks-hive-reader.jar ${STARROCKS_OUTPUT}/be/lib/hive-reader-lib\n    fi\n\n    cp -r -p ${STARROCKS_THIRDPARTY}/installed/hadoop/share/hadoop/common ${STARROCKS_OUTPUT}/be/lib/hadoop/\n    cp -r -p ${STARROCKS_THIRDPARTY}/installed/hadoop/share/hadoop/hdfs ${STARROCKS_OUTPUT}/be/lib/hadoop/\n    cp -p ${STARROCKS_THIRDPARTY}/installed/hadoop/share/hadoop/tools/lib/hadoop-azure-* ${STARROCKS_OUTPUT}/be/lib/hadoop/hdfs\n    cp -p ${STARROCKS_THIRDPARTY}/installed/hadoop/share/hadoop/tools/lib/azure-* ${STARROCKS_OUTPUT}/be/lib/hadoop/hdfs\n    cp -p ${STARROCKS_THIRDPARTY}/installed/gcs_connector/*.jar ${STARROCKS_OUTPUT}/be/lib/hadoop/hdfs\n    cp -r -p ${STARROCKS_THIRDPARTY}/installed/hadoop/lib/native ${STARROCKS_OUTPUT}/be/lib/hadoop/\n\n    # remove zookeeper\n    rm -f ${STARROCKS_OUTPUT}/be/lib/hadoop/common/lib/zookeeper-3.8.3.jar\n    rm -f ${STARROCKS_OUTPUT}/be/lib/hadoop/hdfs/lib/zookeeper-3.8.3.jar\n    rm -f ${STARROCKS_OUTPUT}/be/lib/hadoop/common/lib/avro-1.9.2.jar\n    rm -f ${STARROCKS_OUTPUT}/be/lib/hadoop/hdfs/lib/avro-1.9.2.jar\n\n    cp -r -p ${STARROCKS_HOME}/be/extension/python-udf/src/flight_server.py ${STARROCKS_OUTPUT}/be/lib/py-packages\n\n    MSG=\"${MSG} ‚àö ${MSG_BE}\"\nfi\n\n\n\ncp -r -p \"${STARROCKS_HOME}/LICENSE.txt\" \"${STARROCKS_OUTPUT}/LICENSE.txt\"\nbuild-support/gen_notice.py \"${STARROCKS_HOME}/licenses,${STARROCKS_HOME}/licenses-binary\" \"${STARROCKS_OUTPUT}/NOTICE.txt\" all\n\nendTime=$(date +%s)\ntotalTime=$((endTime - startTime))\n\necho \"***************************************\"\necho \"Successfully build StarRocks ${MSG} ; StartTime:$(date -d @$startTime '+%Y-%m-%d %H:%M:%S'), EndTime:$(date -d @$endTime '+%Y-%m-%d %H:%M:%S'), TotalTime:${totalTime}s\"\necho \"***************************************\"\n\nif [[ ! -z ${STARROCKS_POST_BUILD_HOOK} ]]; then\n    eval ${STARROCKS_POST_BUILD_HOOK}\nfi\n\nexit 0\n"
        },
        {
          "name": "codecov.yml",
          "type": "blob",
          "size": 0.4853515625,
          "content": "comment: false\ncodecov:\n  allow_coverage_offsets: true\n  max_report_age: off\ngithub_checks:\n  annotations: false\ncoverage:\n  status:\n    project:\n      default: off\n      fe-total:\n        target: 60%\n        threshold: 5%\n        only_pulls: true\n        flags:\n          - fe-total\n      be-total:\n        target: 60%\n        threshold: 5%\n        only_pulls: true\n        flags:\n          - be-total\n    patch: false\nflags:\n  fe-total:\n    paths:\n      - fe/\n  be-total:\n    paths:\n      - be/\n"
        },
        {
          "name": "community",
          "type": "tree",
          "content": null
        },
        {
          "name": "conf",
          "type": "tree",
          "content": null
        },
        {
          "name": "contrib",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "env.sh",
          "type": "blob",
          "size": 3.30078125,
          "content": "# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n# check STARROCKS_HOME\nif [[ -z ${STARROCKS_HOME} ]]; then\n    echo \"Error: STARROCKS_HOME is not set\"\n    exit 1\nfi\n\n# include custom environment variables\nif [[ -f ${STARROCKS_HOME}/custom_env.sh ]]; then\n    . ${STARROCKS_HOME}/custom_env.sh\nfi\n\n# set STARROCKS_THIRDPARTY\nif [[ -z ${STARROCKS_THIRDPARTY} ]]; then\n    export STARROCKS_THIRDPARTY=${STARROCKS_HOME}/thirdparty\nfi\n\n# check python\nif [[ -z ${PYTHON} ]]; then\n    export PYTHON=python3\nfi\n\nif ${PYTHON} --version | grep -q '^Python 3\\.'; then\n    echo \"Found python3, version: `\\${PYTHON} --version`\"\nelse\n    echo \"Error: python3 is needed\"\n    exit 1\nfi\n\n\n# set GCC HOME\nif [[ -z ${STARROCKS_GCC_HOME} ]]; then\n    export STARROCKS_GCC_HOME=$(dirname `which gcc`)/..\nfi\n\ngcc_ver=`${STARROCKS_GCC_HOME}/bin/gcc -dumpfullversion -dumpversion`\nrequired_ver=\"5.3.1\"\nif [[ ! \"$(printf '%s\\n' \"$required_ver\" \"$gcc_ver\" | sort -V | head -n1)\" = \"$required_ver\" ]]; then\n    echo \"Error: GCC version (${gcc_ver}) must be greater than or equal to ${required_ver}\"\n    exit 1\nfi\n\n# export CLANG COMPATIBLE FLAGS\nexport CLANG_COMPATIBLE_FLAGS=`echo | ${STARROCKS_GCC_HOME}/bin/gcc -Wp,-v -xc++ - -fsyntax-only 2>&1 \\\n                | grep -E '^\\s+/' | awk '{print \"-I\" $1}' | tr '\\n' ' '`\n\nif [[ -z ${JAVA_HOME} ]]; then\n    export JAVA_HOME=\"$(dirname $(dirname $(readlink -f $(which javac))))\"\n    echo \"Infered JAVA_HOME=$JAVA_HOME\"\nfi\n\nif [[ -z ${JAVA_HOME} ]]; then\n    echo \"Error: JAVA_HOME is not set\"\n    exit 1\nfi\n\nif ! command -v $JAVA_HOME/bin/java &> /dev/null; then\n    echo \"Error: JAVA not found, JAVA_HOME may be set wrong\"\n    exit 1\nfi\n\n# check java version\nexport JAVA=${JAVA_HOME}/bin/java\n# Some examples of different variant of jdk output for `java -version`\n# - Oracle JDK: java version \"1.8.0_202\"\n# - OpenJDK: openjdk version \"1.8.0_362\"\n# - OpenJDK: openjdk version \"11.0.20.1\" 2023-08-24\nJAVA_VER=$(${JAVA} -version 2>&1 | awk -F'\"' '{print $2}' | awk -F. '{if ($1 == 1) {print $2;} else {print $1;}}')\nif [[ $JAVA_VER -lt 11 ]]; then\n    echo \"Error: require JAVA with JDK version at least 11, but got $JAVA_VER\"\n    exit 1\nfi\n\n# check maven\nMVN_CMD=mvn\nif [[ ! -z ${CUSTOM_MVN} ]]; then\n    MVN_CMD=${CUSTOM_MVN}\nfi\nif ! ${MVN_CMD} --version; then\n    echo \"Error: mvn is not found\"\n    exit 1\nfi\nexport MVN_CMD\n\nCMAKE_CMD=cmake\nif [[ ! -z ${CUSTOM_CMAKE} ]]; then\n    CMAKE_CMD=${CUSTOM_CMAKE}\nfi\nexport CMAKE_CMD\n\nCMAKE_GENERATOR=\"Unix Makefiles\"\nBUILD_SYSTEM=\"make\"\nif ninja --version 2>/dev/null; then\n    BUILD_SYSTEM=\"ninja\"\n    CMAKE_GENERATOR=\"Ninja\"\nfi\nexport CMAKE_GENERATOR\nexport BUILD_SYSTEM\n"
        },
        {
          "name": "extra",
          "type": "tree",
          "content": null
        },
        {
          "name": "fe",
          "type": "tree",
          "content": null
        },
        {
          "name": "format-sdk",
          "type": "tree",
          "content": null
        },
        {
          "name": "fs_brokers",
          "type": "tree",
          "content": null
        },
        {
          "name": "gensrc",
          "type": "tree",
          "content": null
        },
        {
          "name": "images",
          "type": "tree",
          "content": null
        },
        {
          "name": "java-extensions",
          "type": "tree",
          "content": null
        },
        {
          "name": "licenses-binary",
          "type": "tree",
          "content": null
        },
        {
          "name": "licenses",
          "type": "tree",
          "content": null
        },
        {
          "name": "run-be-ut.sh",
          "type": "blob",
          "size": 11.3310546875,
          "content": "#!/usr/bin/env bash\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\nset -eo pipefail\n\nROOT=`dirname \"$0\"`\nROOT=`cd \"$ROOT\"; pwd`\n\nexport STARROCKS_HOME=${ROOT}\n\n. ${STARROCKS_HOME}/env.sh\n\nPARALLEL=$[$(nproc)/4+1]\n\n# Check args\nusage() {\n  echo \"\nUsage: $0 <options>\n  Optional options:\n     --test TEST_NAME               run specific test\n     --gtest_filter GTEST_FILTER    run test cases with gtest filters\n     --dry-run                      dry-run unit tests\n     --clean                        clean old unit tests before run\n     --with-gcov                    enable to build with gcov\n     --with-aws                     enable to test aws\n     --with-bench                   enable to build with benchmark\n     --excluding-test-suit          don't run cases of specific suit\n     --module                       module to run uts\n     --enable-shared-data           enable to build with shared-data feature support\n     --without-starcache            build without starcache library\n     --use-staros                   DEPRECATED. an alias of --enable-shared-data option\n     --without-debug-symbol-split   split debug symbol out of the test binary to accelerate the speed\n                                    of loading binary into memory and start execution.\n     -j                             build parallel\n\n  Eg.\n    $0                              run all unit tests\n    $0 --test CompactionUtilsTest   run compaction test\n    $0 --dry-run                    dry-run unit tests\n    $0 --clean                      clean old unit tests before run\n    $0 --help                       display usage\n    $0 --gtest_filter CompactionUtilsTest*:TabletUpdatesTest*   run the two test suites: CompactionUtilsTest and TabletUpdatesTest\n  \"\n  exit 1\n}\n\n# Append negative cases to existing $TEST_NAME\n# refer to https://github.com/google/googletest/blob/main/docs/advanced.md#running-a-subset-of-the-tests\n# for detailed explaination of `--gtest_filter`\nappend_negative_case() {\n    local exclude_case=$1\n    case $TEST_NAME in\n      *-*)\n        # already has negative cases, just append the cases to the end\n        TEST_NAME=${TEST_NAME}:$exclude_case\n        ;;\n      *)\n        # doesn't have negative cases, start the negative session\n        TEST_NAME=${TEST_NAME}-$exclude_case\n        ;;\n    esac\n}\n\n# -l run and -l gtest_filter only used for compatibility\nOPTS=$(getopt \\\n  -n $0 \\\n  -o '' \\\n  -l 'test:' \\\n  -l 'dry-run' \\\n  -l 'clean' \\\n  -l 'with-gcov' \\\n  -l 'module:' \\\n  -l 'with-aws' \\\n  -l 'with-bench' \\\n  -l 'excluding-test-suit:' \\\n  -l 'use-staros' \\\n  -l 'enable-shared-data' \\\n  -l 'without-starcache' \\\n  -l 'with-brpc-keepalive' \\\n  -l 'without-debug-symbol-split' \\\n  -o 'j:' \\\n  -l 'help' \\\n  -l 'run' \\\n  -l 'gtest_filter:' \\\n  -- \"$@\")\n\nif [ $? != 0 ] ; then\n    usage\nfi\n\neval set -- \"$OPTS\"\n\nCLEAN=0\nDRY_RUN=0\nTEST_NAME=*\nTEST_MODULE=\".*\"\nEXCLUDING_TEST_SUIT=\nHELP=0\nWITH_AWS=OFF\nUSE_STAROS=OFF\nWITH_GCOV=OFF\nWITH_STARCACHE=ON\nWITH_BRPC_KEEPALIVE=OFF\nWITH_DEBUG_SYMBOL_SPLIT=ON\nwhile true; do\n    case \"$1\" in\n        --clean) CLEAN=1 ; shift ;;\n        --dry-run) DRY_RUN=1 ; shift ;;\n        --run) shift ;; # Option only for compatibility\n        --test) TEST_NAME=${2}* ; shift 2;;\n        --gtest_filter) TEST_NAME=$2 ; shift 2;;\n        --module) TEST_MODULE=$2; shift 2;;\n        --help) HELP=1 ; shift ;;\n        --with-aws) WITH_AWS=ON; shift ;;\n        --with-gcov) WITH_GCOV=ON; shift ;;\n        --without-starcache) WITH_STARCACHE=OFF; shift ;;\n        --with-brpc-keepalive) WITH_BRPC_KEEPALIVE=ON; shift ;;\n        --excluding-test-suit) EXCLUDING_TEST_SUIT=$2; shift 2;;\n        --enable-shared-data|--use-staros) USE_STAROS=ON; shift ;;\n        --without-debug-symbol-split) WITH_DEBUG_SYMBOL_SPLIT=OFF; shift ;;\n        -j) PARALLEL=$2; shift 2 ;;\n        --) shift ;  break ;;\n        *) echo \"Internal error\" ; exit 1 ;;\n    esac\ndone\n\nif [ ${HELP} -eq 1 ]; then\n    usage\n    exit 0\nfi\n\nCMAKE_BUILD_TYPE=${BUILD_TYPE:-ASAN}\nCMAKE_BUILD_TYPE=\"${CMAKE_BUILD_TYPE}\"\nif [[ -z ${USE_SSE4_2} ]]; then\n    USE_SSE4_2=ON\nfi\nif [[ -z ${USE_BMI_2} ]]; then\n    USE_BMI_2=ON\nfi\nif [[ -z ${USE_AVX2} ]]; then\n    USE_AVX2=ON\nfi\nif [[ -z ${USE_AVX512} ]]; then\n    # Disable it by default\n    USE_AVX512=OFF\nfi\necho \"Build Backend UT\"\n\nCMAKE_BUILD_DIR=${STARROCKS_HOME}/be/ut_build_${CMAKE_BUILD_TYPE}\nif [ ${CLEAN} -eq 1 ]; then\n    rm ${CMAKE_BUILD_DIR} -rf\n    rm ${STARROCKS_HOME}/be/output/ -rf\nfi\n\nif [ ! -d ${CMAKE_BUILD_DIR} ]; then\n    mkdir -p ${CMAKE_BUILD_DIR}\nfi\n\nsource ${STARROCKS_HOME}/bin/common.sh\n\ncd ${CMAKE_BUILD_DIR}\nif [ \"${USE_STAROS}\" == \"ON\"  ]; then\n  if [ -z \"$STARLET_INSTALL_DIR\" ] ; then\n    # assume starlet_thirdparty is installed to ${STARROCKS_THIRDPARTY}/installed/starlet/\n    STARLET_INSTALL_DIR=${STARROCKS_THIRDPARTY}/installed/starlet\n  fi\n  export STARLET_INSTALL_DIR\nfi\n\n${CMAKE_CMD}  -G \"${CMAKE_GENERATOR}\" \\\n            -DSTARROCKS_THIRDPARTY=${STARROCKS_THIRDPARTY}\\\n            -DSTARROCKS_HOME=${STARROCKS_HOME} \\\n            -DCMAKE_CXX_COMPILER_LAUNCHER=ccache \\\n            -DMAKE_TEST=ON -DCMAKE_BUILD_TYPE=${CMAKE_BUILD_TYPE} \\\n            -DUSE_AVX2=$USE_AVX2 -DUSE_AVX512=$USE_AVX512 -DUSE_SSE4_2=$USE_SSE4_2 -DUSE_BMI_2=$USE_BMI_2\\\n            -DUSE_STAROS=${USE_STAROS} \\\n            -DSTARLET_INSTALL_DIR=${STARLET_INSTALL_DIR}          \\\n            -DWITH_GCOV=${WITH_GCOV} \\\n            -DWITH_STARCACHE=${WITH_STARCACHE} \\\n            -DWITH_BRPC_KEEPALIVE=${WITH_BRPC_KEEPALIVE} \\\n            -DSTARROCKS_JIT_ENABLE=ON \\\n            -DWITH_RELATIVE_SRC_PATH=OFF \\\n            -DCMAKE_EXPORT_COMPILE_COMMANDS=ON ../\n\n${BUILD_SYSTEM} -j${PARALLEL}\n\ncd ${STARROCKS_HOME}\nexport STARROCKS_TEST_BINARY_DIR=${CMAKE_BUILD_DIR}/test\nTEST_BIN=starrocks_test\nif [ \"x$WITH_DEBUG_SYMBOL_SPLIT\" = \"xON\" ] && test -f ${STARROCKS_TEST_BINARY_DIR}/$TEST_BIN ; then\n    pushd ${STARROCKS_TEST_BINARY_DIR} >/dev/null 2>&1\n    TEST_BIN_SYMBOL=starrocks_test.debuginfo\n    echo -n \"[INFO] Split $TEST_BIN debug symbol to $TEST_BIN_SYMBOL ...\"\n    objcopy --only-keep-debug $TEST_BIN $TEST_BIN_SYMBOL\n    strip --strip-debug $TEST_BIN\n    objcopy --add-gnu-debuglink=$TEST_BIN_SYMBOL $TEST_BIN\n    # continue the echo output from the previous `echo -n`\n    echo \" split done.\"\n    popd >/dev/null 2>&1\nfi\n\necho \"*********************************\"\necho \"  Starting to Run BE Unit Tests  \"\necho \"*********************************\"\n\nexport TERM=xterm\nexport UDF_RUNTIME_DIR=${STARROCKS_HOME}/lib/udf-runtime\nexport LOG_DIR=${STARROCKS_HOME}/log\nexport LSAN_OPTIONS=suppressions=${STARROCKS_HOME}/conf/asan_suppressions.conf\nfor i in `sed 's/ //g' $STARROCKS_HOME/conf/be_test.conf | egrep \"^[[:upper:]]([[:upper:]]|_|[[:digit:]])*=\"`; do\n    eval \"export $i\";\ndone\n\nmkdir -p $LOG_DIR\nmkdir -p ${UDF_RUNTIME_DIR}\nrm -f ${UDF_RUNTIME_DIR}/*\n\n# ====================== configure JAVA/JVM ====================\n# NOTE: JAVA_HOME must be configed if using hdfs scan, like hive external table\n# this is only for starting be\njvm_arch=\"amd64\"\nif [[ \"${MACHINE_TYPE}\" == \"aarch64\" ]]; then\n    jvm_arch=\"aarch64\"\nfi\n\nif [ \"$JAVA_HOME\" = \"\" ]; then\n    export LD_LIBRARY_PATH=$STARROCKS_HOME/lib/jvm/$jvm_arch/server:$STARROCKS_HOME/lib/jvm/$jvm_arch:$LD_LIBRARY_PATH\nelse\n    java_version=$(jdk_version)\n    if [[ $java_version -gt 8 ]]; then\n        export LD_LIBRARY_PATH=$JAVA_HOME/lib/server:$JAVA_HOME/lib:$LD_LIBRARY_PATH\n    # JAVA_HOME is jdk\n    elif [[ -d \"$JAVA_HOME/jre\"  ]]; then\n        export LD_LIBRARY_PATH=$JAVA_HOME/jre/lib/$jvm_arch/server:$JAVA_HOME/jre/lib/$jvm_arch:$LD_LIBRARY_PATH\n    # JAVA_HOME is jre\n    else\n        export LD_LIBRARY_PATH=$JAVA_HOME/lib/$jvm_arch/server:$JAVA_HOME/lib/$jvm_arch:$LD_LIBRARY_PATH\n    fi\nfi\n\nexport LD_LIBRARY_PATH=$STARROCKS_HOME/lib/hadoop/native:$LD_LIBRARY_PATH\nif [[ -n \"$STARROCKS_GCC_HOME\" ]] ; then\n    # add gcc lib64 into LD_LIBRARY_PATH because of dynamic link libstdc++ and libgcc\n    export LD_LIBRARY_PATH=$STARROCKS_GCC_HOME/lib64:$LD_LIBRARY_PATH\nfi\n\nTHIRDPARTY_HADOOP_HOME=${STARROCKS_THIRDPARTY}/installed/hadoop/share/hadoop\nif [[ -d ${THIRDPARTY_HADOOP_HOME} ]] ; then\n    export HADOOP_CLASSPATH=${THIRDPARTY_HADOOP_HOME}/common/*:${THIRDPARTY_HADOOP_HOME}/common/lib/*:${THIRDPARTY_HADOOP_HOME}/hdfs/*:${THIRDPARTY_HADOOP_HOME}/hdfs/lib/*\n    # get rid of StackOverflowError on the process reaper thread, which has a small stack size.\n    # https://bugs.openjdk.org/browse/JDK-8153057\n    export LIBHDFS_OPTS=\"$LIBHDFS_OPTS -Djdk.lang.processReaperUseDefaultStackSize=true\"\nelse\n    # exclude HdfsFileSystemTest related test case if no hadoop env found\n    echo \"[INFO] Can't find available HADOOP common lib, disable HdfsFileSystemTest related test!\"\n    append_negative_case \"HdfsFileSystemTest*\"\nfi\n# HADOOP_CLASSPATH defined in $STARROCKS_HOME/conf/hadoop_env.sh\n# put $STARROCKS_HOME/conf ahead of $HADOOP_CLASSPATH so that custom config can replace the config in $HADOOP_CLASSPATH\nexport CLASSPATH=$STARROCKS_HOME/conf:$HADOOP_CLASSPATH:$CLASSPATH\n\n# ===========================================================\n\nexport ASAN_OPTIONS=\"abort_on_error=1:disable_coredump=0:unmap_shadow_on_exit=1:detect_stack_use_after_return=1\"\n\nif [ $WITH_AWS = \"OFF\" ]; then\n    append_negative_case \"*S3*\"\nfi\n\nif [ -n \"$EXCLUDING_TEST_SUIT\" ]; then\n    excluding_test_suit=$EXCLUDING_TEST_SUIT\n    excluding_test_suit_array=(\"${excluding_test_suit//|/ }\")\n    for element in ${excluding_test_suit_array[*]}; do\n        append_negative_case \"*.${element}_*\"\n    done\nfi\n\n# prepare util test_data\nif [ -d ${STARROCKS_TEST_BINARY_DIR}/util/test_data ]; then\n    rm -rf ${STARROCKS_TEST_BINARY_DIR}/util/test_data\nfi\ncp -r ${STARROCKS_HOME}/be/test/util/test_data ${STARROCKS_TEST_BINARY_DIR}/util/\n\ntest_files=`find ${STARROCKS_TEST_BINARY_DIR} -type f -perm -111 -name \"*test\" \\\n    | grep -v starrocks_test \\\n    | grep -v bench_test \\\n    | grep -e \"$TEST_MODULE\" `\n\necho \"[INFO] gtest_filter: $TEST_NAME\"\n# run cases in starrocks_test in parallel if has gtest-parallel script.\n# reference: https://github.com/google/gtest-parallel\nif [[ $TEST_MODULE == '.*'  || $TEST_MODULE == 'starrocks_test' ]]; then\n  echo \"Run test: ${STARROCKS_TEST_BINARY_DIR}/starrocks_test\"\n  if [ ${DRY_RUN} -eq 0 ]; then\n    if [ -x \"${GTEST_PARALLEL}\" ]; then\n        ${GTEST_PARALLEL} ${STARROCKS_TEST_BINARY_DIR}/starrocks_test \\\n            --gtest_filter=${TEST_NAME} \\\n            --serialize_test_cases ${GTEST_PARALLEL_OPTIONS}\n    else\n        ${STARROCKS_TEST_BINARY_DIR}/starrocks_test $GTEST_OPTIONS --gtest_filter=${TEST_NAME}\n    fi\n  fi\nfi\n\nfor test_bin in $test_files\ndo\n    echo \"Run test: $test_bin\"\n    if [ ${DRY_RUN} -eq 0 ]; then\n        file_name=${test_bin##*/}\n        if [ -z $RUN_FILE ] || [ $file_name == $RUN_FILE ]; then\n            $test_bin $GTEST_OPTIONS --gtest_filter=${TEST_NAME}\n        fi\n    fi\ndone\n"
        },
        {
          "name": "run-fe-ut.sh",
          "type": "blob",
          "size": 4.0859375,
          "content": "#!/usr/bin/env bash\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\nset -eo pipefail\n\nROOT=`dirname \"$0\"`\nROOT=`cd \"$ROOT\"; pwd`\n\nexport STARROCKS_HOME=${ROOT}\n\n. ${STARROCKS_HOME}/env.sh\n\n# Check args\nusage() {\n  echo \"\nUsage: $0 <options>\n  Optional options:\n     --test [TEST_NAME]         run specific test\n     --filter [TEST_NAME]       skip run specific test,\n                                multiple tests separated by commas and enclosed in quotation marks\n     --dry-run                  dry-run unit tests\n     --coverage                 run coverage statistic tasks\n     --dumpcase [PATH]          run dump case and save to path\n\n  Eg.\n    $0                                            run all unit tests\n    $0 --test com.starrocks.utframe.Demo          run demo test\n    $0 --filter com.starrocks.utframe.Demo#Test0  skip run demo test0\n    $0 --dry-run                                  dry-run unit tests\n    $0 --coverage                                 run coverage statistic tasks\n    $0 --dumpcase /home/disk1/                    run dump case and save to path\n  \"\n  exit 1\n}\n\n# -l run only used for compatibility\nOPTS=$(getopt \\\n  -n $0 \\\n  -o '' \\\n  -l 'test:' \\\n  -l 'filter:' \\\n  -l 'dry-run' \\\n  -l 'coverage' \\\n  -l 'dumpcase' \\\n  -l 'help' \\\n  -l 'run' \\\n  -- \"$@\")\n\nif [ $? != 0 ] ; then\n    usage\nfi\n\neval set -- \"$OPTS\"\n\nHELP=0\nDRY_RUN=0\nRUN_SPECIFIED_TEST=0\nTEST_NAME=*\nFILTER_TEST=\"\"\nCOVERAGE=0\nDUMPCASE=0\nwhile true; do\n    case \"$1\" in\n        --coverage) COVERAGE=1 ; shift ;;\n        --test) RUN_SPECIFIED_TEST=1; TEST_NAME=$2; shift 2;;\n        --filter) FILTER_TEST=$2; shift 2;;\n        --run) shift ;; # only used for compatibility\n        --dumpcase) DUMPCASE=1; shift ;;\n        --dry-run) DRY_RUN=1 ; shift ;;\n        --help) HELP=1 ; shift ;;\n        --) shift ;  break ;;\n        *) echo \"Internal error\" ; exit 1 ;;\n    esac\ndone\n\nif [ ${HELP} -eq 1 ]; then\n    usage\n    exit 0\nfi\n\necho \"*********************************\"\necho \"  Starting to Run FE Unit Tests  \"\necho \"*********************************\"\n\ncd ${STARROCKS_HOME}/fe/\nmkdir -p build/compile\n\nif [ -z \"${FE_UT_PARALLEL}\" ]; then\n    # the default fe unit test parallel is 1\n    export FE_UT_PARALLEL=4\nfi\necho \"Unit test parallel is: $FE_UT_PARALLEL\"\n\nif [ -d \"./mocked\" ]; then\n    rm -r ./mocked\nfi\n\nif [ -d \"./ut_ports\" ]; then\n    rm -r ./ut_ports\nfi\n\nmkdir ut_ports\n\nif [[ ${DUMPCASE} -ne 1 ]]; then\n    DUMP_FILTER_TEST=\"com.starrocks.sql.dump.QueryDumpRegressionTest,com.starrocks.sql.dump.QueryDumpCaseRewriter\"\n\n    if [[ $FILTER_TEST != \"\" ]];then\n        FILTER_TEST=\"${FILTER_TEST},${DUMP_FILTER_TEST}\"\n    else\n        FILTER_TEST=\"${DUMP_FILTER_TEST}\"\n    fi\n\n    FILTER_TEST=`echo $FILTER_TEST | sed -E 's/([^,]+)/!\\1/g'`\n    TEST_NAME=\"$TEST_NAME,$FILTER_TEST\"\nfi\n\nif [ ${COVERAGE} -eq 1 ]; then\n    echo \"Run coverage statistic tasks\"\n    ant cover-test\nelif [ ${DUMPCASE} -eq 1 ]; then\n    ${MVN_CMD} test -DfailIfNoTests=false -DtrimStackTrace=false -D test=com.starrocks.sql.dump.QueryDumpRegressionTest -D dumpJsonConfig=$1\nelse\n    if [ $DRY_RUN -eq 0 ]; then\n        if [ ${RUN_SPECIFIED_TEST} -eq 1 ]; then\n            echo \"Run test: $TEST_NAME\"\n        else\n            echo \"Run All Frontend Unittests\"\n        fi\n\n        # set trimStackTrace to false to show full stack when debugging specified class or case\n        ${MVN_CMD} test -DfailIfNoTests=false -DtrimStackTrace=false -D test=\"$TEST_NAME\"\n    fi\nfi\n"
        },
        {
          "name": "run-java-exts-ut.sh",
          "type": "blob",
          "size": 1.1162109375,
          "content": "#!/usr/bin/env bash\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\nset -eo pipefail\n\nROOT=`dirname \"$0\"`\nROOT=`cd \"$ROOT\"; pwd`\n\nexport STARROCKS_HOME=${ROOT}\n\n. ${STARROCKS_HOME}/env.sh\n\necho \"*********************************************\"\necho \"  Starting to Run java-extensions Unit Tests  \"\necho \"*********************************************\"\n\ncd ${STARROCKS_HOME}/java-extensions/\n\n${MVN_CMD} test\n"
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "thirdparty",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "trivy.yaml",
          "type": "blob",
          "size": 0.71875,
          "content": "severity:\n  - HIGH\n  - CRITICAL\nscan:\n  skip-dirs:\n    # ignore broker's cve\n    - apache_hdfs_broker/\n  skip-files:\n    # hudi required\n    - \"**/htrace-core4-4.2.0-incubating.jar\"\n    - \"**/hbase-protocol-shaded-2.4.13.jar\"\n    - \"**/hbase-shaded-netty-4.1.1.jar\"\n    # kudu required, already latest\n    - \"**/kudu-client-1.17.0.jar\"\n    # hadoop-common 3.4.0 introduced, already latest\n    - \"**/dnsjava-3.4.0.jar\"\n    - \"**/hadoop-client-runtime-3.4.0.jar\"\n    - \"**/commons-compress-1.24.0.jar\"\n    - \"**/netty-common-4.1.100.Final.jar\"\n    # paimon required, already latest\n    - \"**/paimon-bundle-0.8.2.jar\"\n    # apache ranger required\n    - \"**/jackson-mapper-asl-1.9.13.jar\"\n    # aws sdk bundle\n    - \"**/bundle-2.23.19.jar\"\n"
        },
        {
          "name": "webroot",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}