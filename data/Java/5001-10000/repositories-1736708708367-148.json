{
  "metadata": {
    "timestamp": 1736708708367,
    "page": 148,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE1MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "apache/iceberg",
      "stars": 6750,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".asf.yaml",
          "type": "blob",
          "size": 1.8369140625,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n#\n\n# The format of this file is documented at\n# https://cwiki.apache.org/confluence/display/INFRA/Git+-+.asf.yaml+features\n\ngithub:\n  description: \"Apache Iceberg\"\n  homepage: https://iceberg.apache.org/\n  labels:\n    - iceberg\n    - apache\n    - hacktoberfest\n  \n  enabled_merge_buttons:\n    merge: false\n    squash: true\n    rebase: true\n\n  protected_branches:\n    main:\n      required_pull_request_reviews:\n        required_approving_review_count: 1\n\n      required_linear_history: true\n\n  del_branch_on_merge: true\n  \n  features:\n    wiki: true\n    issues: true\n    projects: true\n  collaborators:  # Note: the number of collaborators is limited to 10\n    - chenjunjiedada\n    - jun-he\n    - marton-bod\n    - samarthjain\n    - SreeramGarlapati\n    - gaborkaszab\n    - bitsondatadev\n    - ajantha-bhat\n    - jbonofre\n    - manuzhang\n  ghp_branch: gh-pages\n  ghp_path: /\n\nnotifications:\n    commits:      commits@iceberg.apache.org\n    issues:       issues@iceberg.apache.org\n    pullrequests: issues@iceberg.apache.org\n    jira_options: link label link label\n\npublish:\n    whoami:  asf-site\n"
        },
        {
          "name": ".baseline",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 1.32421875,
          "content": "#\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n# \n#   http://www.apache.org/licenses/LICENSE-2.0\n# \n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n#\n\n# Files marked as export-ignore will be ignored from the release's\n# built via `git archive`. This simplifies the release script and \n# uses an industry standard as opposed to possibly hard to read\n# shell scripts with many flags. Unfortunately, directories themselves\n# won't recursively ignore, so we need the top level directories\n# as well as their files.\n/build         export-ignore\n/build/**      export-ignore\n/examples      export-ignore\n/examples/**   export-ignore\njitpack.yml    export-ignore\n/docs          export-ignore\n/docs/**       export-ignore\n\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.8603515625,
          "content": "*.swp\n.DS_Store\n.cache\ntmp/\n\n# intellij files\n.idea\n.idea_modules/\n*.ipr\n*.iws\n*.iml\nout\n\n# gradle build\n.gradle\n.out/\nbuild\ndependencies.lock\n**/dependencies.lock\ngradle/\ngradle/wrapper/gradle-wrapper.jar\n\n# rat library install location\nlib/\n\n# web site build\ndocs/site/\nsite/site/\nsite/docs/docs/\nsite/docs/.asf.yaml\nsite/docs/javadoc/\n\n# benchmark output\nspark/v3.3/spark/benchmark/*\nspark/v3.3/spark-extensions/benchmark/*\nspark/v3.4/spark/benchmark/*\nspark/v3.4/spark-extensions/benchmark/*\nspark/v3.5/spark/benchmark/*\nspark/v3.5/spark-extensions/benchmark/*\n*/benchmark/*\n\n__pycache__/\n*.py[cod]\n.eggs/\n.tox/\nenv/\nvenv/\n*.egg-info/\ntest-reports\nbuild/\ndist/\nsdist/\n.coverage\ncoverage.xml\n.pytest_cache/\n\n# vscode/eclipse files\n.classpath\n.project\n.settings\nbin/\n\n# Hive/metastore files\nmetastore_db/\n\n# Spark/metastore files\nspark-warehouse/\nderby.log\n\n# jenv\n.java-version\n"
        },
        {
          "name": ".palantir",
          "type": "tree",
          "content": null
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 0.955078125,
          "content": "<!--\n  - Licensed to the Apache Software Foundation (ASF) under one\n  - or more contributor license agreements.  See the NOTICE file\n  - distributed with this work for additional information\n  - regarding copyright ownership.  The ASF licenses this file\n  - to you under the Apache License, Version 2.0 (the\n  - \"License\"); you may not use this file except in compliance\n  - with the License.  You may obtain a copy of the License at\n  -\n  -   http://www.apache.org/licenses/LICENSE-2.0\n  -\n  - Unless required by applicable law or agreed to in writing,\n  - software distributed under the License is distributed on an\n  - \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n  - KIND, either express or implied.  See the License for the\n  - specific language governing permissions and limitations\n  - under the License.\n  -->\n\n# Contributing\n\nPlease refer to the [contributing](https://iceberg.apache.org/contribute/) section for instructions\non how to contribute to Iceberg.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 15.60546875,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n--------------------------------------------------------------------------------\n\nThis product includes a gradle wrapper.\n\n* gradlew and gradle/wrapper/gradle-wrapper.properties\n\nCopyright: 2010-2019 Gradle Authors.\nHome page: https://github.com/gradle/gradle\nLicense: https://www.apache.org/licenses/LICENSE-2.0\n\n--------------------------------------------------------------------------------\n\nThis product includes code from Apache Avro.\n\n* Conversion in DecimalWriter is based on Avro's Conversions.DecimalConversion.\n\nCopyright: 2014-2017 The Apache Software Foundation.\nHome page: https://avro.apache.org/\nLicense: https://www.apache.org/licenses/LICENSE-2.0\n\n--------------------------------------------------------------------------------\n\nThis product includes code from Apache Parquet.\n\n* DynMethods.java\n* DynConstructors.java\n* IOUtil.java readFully and tests\n* ByteBufferInputStream implementations and tests\n\nCopyright: 2014-2017 The Apache Software Foundation.\nHome page: https://parquet.apache.org/\nLicense: https://www.apache.org/licenses/LICENSE-2.0\n\n--------------------------------------------------------------------------------\n\nThis product includes code from Cloudera Kite.\n\n* SchemaVisitor and visit methods\n\nCopyright: 2013-2017 Cloudera Inc.\nHome page: https://kitesdk.org/\nLicense: https://www.apache.org/licenses/LICENSE-2.0\n\n--------------------------------------------------------------------------------\n\nThis product includes code from Presto.\n\n* Retry wait and jitter logic in Tasks.java\n* S3FileIO logic derived from PrestoS3FileSystem.java in S3InputStream.java\n  and S3OutputStream.java\n* SQL grammar rules for parsing CALL statements in IcebergSqlExtensions.g4\n* some aspects of handling stored procedures\n\nCopyright: 2016 Facebook and contributors\nHome page: https://prestodb.io/\nLicense: https://www.apache.org/licenses/LICENSE-2.0\n\n--------------------------------------------------------------------------------\n\nThis product includes code from Apache iBATIS.\n\n* Hive ScriptRunner.java\n\nCopyright: 2004 Clinton Begin\nHome page: https://ibatis.apache.org/\nLicense: https://www.apache.org/licenses/LICENSE-2.0\n\n--------------------------------------------------------------------------------\n\nThis product includes code from Apache Hive.\n\n* Hive metastore derby schema in hive-schema-3.1.0.derby.sql\n\nCopyright: 2011-2018 The Apache Software Foundation\nHome page: https://hive.apache.org/\nLicense: https://www.apache.org/licenses/LICENSE-2.0\n\n--------------------------------------------------------------------------------\n\nThis product includes code from Apache Spark.\n\n* dev/check-license script\n* vectorized reading of definition levels in BaseVectorizedParquetValuesReader.java\n* portions of the extensions parser\n* casting logic in AssignmentAlignmentSupport\n* implementation of SetAccumulator.\n* Connector expressions.\n\nCopyright: 2011-2018 The Apache Software Foundation\nHome page: https://spark.apache.org/\nLicense: https://www.apache.org/licenses/LICENSE-2.0\n\n--------------------------------------------------------------------------------\n\nThis product includes code from Delta Lake.\n\n* AssignmentAlignmentSupport is an independent development but UpdateExpressionsSupport in Delta was used as a reference.\n* RoaringPositionBitmap is a Java implementation of RoaringBitmapArray in Delta.\n\nCopyright: 2020 The Delta Lake Project Authors.\nHome page: https://delta.io/\nLicense: https://www.apache.org/licenses/LICENSE-2.0\n\n--------------------------------------------------------------------------------\n\nThis product includes code from Apache Commons.\n\n* Core ArrayUtil.\n\nCopyright: 2020 The Apache Software Foundation\nHome page: https://commons.apache.org/\nLicense: https://www.apache.org/licenses/LICENSE-2.0\n\n--------------------------------------------------------------------------------\n\nThis product includes code from Apache HttpComponents Client.\n\n* retry and error handling logic in ExponentialHttpRequestRetryStrategy.java\n\nCopyright: 1999-2022 The Apache Software Foundation.\nHome page: https://hc.apache.org/\nLicense: https://www.apache.org/licenses/LICENSE-2.0\n\n--------------------------------------------------------------------------------\n\nThis product includes code from Apache Flink.\n\n* Parameterized test at class level logic in ParameterizedTestExtension.java\n* Parameter provider annotation for parameterized tests in Parameters.java\n* Parameter field annotation for parameterized tests in Parameter.java\n\nCopyright: 1999-2022 The Apache Software Foundation.\nHome page: https://flink.apache.org/\nLicense: https://www.apache.org/licenses/LICENSE-2.0"
        },
        {
          "name": "NOTICE",
          "type": "blob",
          "size": 0.91015625,
          "content": "\nApache Iceberg\nCopyright 2017-2024 The Apache Software Foundation\n\nThis product includes software developed at\nThe Apache Software Foundation (http://www.apache.org/).\n\n--------------------------------------------------------------------------------\n\nThis project includes code from Kite, developed at Cloudera, Inc. with\nthe following copyright notice:\n\n| Copyright 2013 Cloudera Inc.\n|\n| Licensed under the Apache License, Version 2.0 (the \"License\");\n| you may not use this file except in compliance with the License.\n| You may obtain a copy of the License at\n|\n|   http://www.apache.org/licenses/LICENSE-2.0\n|\n| Unless required by applicable law or agreed to in writing, software\n| distributed under the License is distributed on an \"AS IS\" BASIS,\n| WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n| See the License for the specific language governing permissions and\n| limitations under the License.\n\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 4.65625,
          "content": "<!--\n  - Licensed to the Apache Software Foundation (ASF) under one\n  - or more contributor license agreements.  See the NOTICE file\n  - distributed with this work for additional information\n  - regarding copyright ownership.  The ASF licenses this file\n  - to you under the Apache License, Version 2.0 (the\n  - \"License\"); you may not use this file except in compliance\n  - with the License.  You may obtain a copy of the License at\n  -\n  -   http://www.apache.org/licenses/LICENSE-2.0\n  -\n  - Unless required by applicable law or agreed to in writing,\n  - software distributed under the License is distributed on an\n  - \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n  - KIND, either express or implied.  See the License for the\n  - specific language governing permissions and limitations\n  - under the License.\n  -->\n\n![Iceberg](https://iceberg.apache.org/assets/images/Iceberg-logo.svg)\n\n[![](https://github.com/apache/iceberg/actions/workflows/java-ci.yml/badge.svg)](https://github.com/apache/iceberg/actions/workflows/java-ci.yml)\n[![Slack](https://img.shields.io/badge/chat-on%20Slack-brightgreen.svg)](https://apache-iceberg.slack.com/)\n\nIceberg is a high-performance format for huge analytic tables. Iceberg brings the reliability and simplicity of SQL tables to big data, while making it possible for engines like Spark, Trino, Flink, Presto, Hive and Impala to safely work with the same tables, at the same time.\n\nBackground and documentation is available at <https://iceberg.apache.org>\n\n\n## Status\n\nIceberg is under active development at the Apache Software Foundation.\n\nThe [Iceberg format specification][iceberg-spec] is stable and new features are added with each version.\n\nThe core Java library is located in this repository and is the reference implementation for other libraries.\n\n[Documentation][iceberg-docs] is available for all libraries and integrations.\n\n[iceberg-docs]: https://iceberg.apache.org/docs/latest/\n[iceberg-spec]: https://iceberg.apache.org/spec/\n\n## Collaboration\n\nIceberg tracks issues in GitHub and prefers to receive contributions as pull requests.\n\nCommunity discussions happen primarily on the [dev mailing list][dev-list] or on specific issues.\n\n[dev-list]: mailto:dev@iceberg.apache.org\n\n\n### Building\n\nIceberg is built using Gradle with Java 11, 17, or 21.\n\n* To invoke a build and run tests: `./gradlew build`\n* To skip tests: `./gradlew build -x test -x integrationTest`\n* To fix code style for default versions: `./gradlew spotlessApply`\n* To fix code style for all versions of Spark/Hive/Flink:`./gradlew spotlessApply -DallModules`\n\nIceberg table support is organized in library modules:\n\n* `iceberg-common` contains utility classes used in other modules\n* `iceberg-api` contains the public Iceberg API\n* `iceberg-core` contains implementations of the Iceberg API and support for Avro data files, **this is what processing engines should depend on**\n* `iceberg-parquet` is an optional module for working with tables backed by Parquet files\n* `iceberg-arrow` is an optional module for reading Parquet into Arrow memory\n* `iceberg-orc` is an optional module for working with tables backed by ORC files\n* `iceberg-hive-metastore` is an implementation of Iceberg tables backed by the Hive metastore Thrift client\n* `iceberg-data` is an optional module for working with tables directly from JVM applications\n\nIceberg also has modules for adding Iceberg support to processing engines:\n\n* `iceberg-spark` is an implementation of Spark's Datasource V2 API for Iceberg with submodules for each spark versions (use runtime jars for a shaded version)\n* `iceberg-flink` contains classes for integrating with Apache Flink (use iceberg-flink-runtime for a shaded version)\n* `iceberg-mr` contains an InputFormat and other classes for integrating with Apache Hive\n\n---\n**NOTE**\n\nThe tests require Docker to execute. On MacOS (with Docker Desktop), you might need to create a symbolic name to the docker socket in order to be detected by the tests:\n\n```\nsudo ln -s $HOME/.docker/run/docker.sock /var/run/docker.sock\n```\n---\n\n### Engine Compatibility\n\nSee the [Multi-Engine Support](https://iceberg.apache.org/multi-engine-support/) page to know about Iceberg compatibility with different Spark, Flink and Hive versions.\nFor other engines such as Presto or Trino, please visit their websites for Iceberg integration details.\n\n### Implementations\n\nThis repository contains the Java implementation of Iceberg. Other implementations can be found at:\n\n* **Go**: [iceberg-go](https://github.com/apache/iceberg-go)\n* **PyIceberg** (Python): [iceberg-python](https://github.com/apache/iceberg-python)\n* **Rust**: [iceberg-rust](https://github.com/apache/iceberg-rust)\n* **C++**: [iceberg-cpp](https://github.com/apache/iceberg-cpp)\n"
        },
        {
          "name": "aliyun",
          "type": "tree",
          "content": null
        },
        {
          "name": "api",
          "type": "tree",
          "content": null
        },
        {
          "name": "arrow",
          "type": "tree",
          "content": null
        },
        {
          "name": "aws-bundle",
          "type": "tree",
          "content": null
        },
        {
          "name": "aws",
          "type": "tree",
          "content": null
        },
        {
          "name": "azure-bundle",
          "type": "tree",
          "content": null
        },
        {
          "name": "azure",
          "type": "tree",
          "content": null
        },
        {
          "name": "baseline.gradle",
          "type": "blob",
          "size": 7.279296875,
          "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\napply plugin: 'com.palantir.baseline-config'\n\nallprojects {\n  apply plugin: 'com.palantir.baseline-idea'\n}\n\nsubprojects {\n  if (it.name == 'iceberg-bom') {\n    // the BOM does not build anything, the below plugins are not necessary (and can fail)\n    return\n  }\n\n  // Currently, if any subproject applies the blanket Baseline plugin, it forces the Baseline plugin\n  // to be applied to ALL projects. And we are not prepared to address all of the build errors that\n  // occur as a result at this time. Furthermore, baseline-format will not work out of the box for\n  // us - see below.\n\n  // Thus we concede to applying all of the Baseline plugins individually on all the projects we are\n  // ready to enforce linting on.\n  apply plugin: 'org.inferred.processors'\n  if (!project.hasProperty('quick')) {\n    apply plugin: 'com.palantir.baseline-checkstyle'\n    apply plugin: 'com.palantir.baseline-error-prone'\n  }\n  apply plugin: 'com.palantir.baseline-class-uniqueness'\n  // What 'com.palantir.baseline-reproducibility' used to do, except the check for the\n  // `sourceCompatibility` Java compile option, which conflicts with the `release` compile option.\n  tasks.withType(AbstractArchiveTask.class).configureEach(t -> {\n    t.setPreserveFileTimestamps(false);\n    t.setReproducibleFileOrder(true);\n    t.setDuplicatesStrategy(DuplicatesStrategy.WARN);\n  });\n  apply plugin: 'com.palantir.baseline-exact-dependencies'\n  apply plugin: 'com.diffplug.spotless'\n\n  pluginManager.withPlugin('com.palantir.baseline-checkstyle') {\n    checkstyle {\n      // com.palantir.baseline:gradle-baseline-java:4.42.0 (the last version supporting Java 8) pulls\n      // in an old version of the checkstyle(9.1), which has this OutOfMemory bug https://github.com/checkstyle/checkstyle/issues/10934.\n      // So, override its checkstyle version using CheckstyleExtension to 9.3 (the latest java 8 supported version) which contains a fix.\n      toolVersion '9.3'\n    }\n  }\n\n  pluginManager.withPlugin('com.diffplug.spotless') {\n    spotless {\n      java {\n        target 'src/main/java/**/*.java', 'src/test/java/**/*.java', 'src/testFixtures/java/**/*.java', 'src/jmh/java/**/*.java', 'src/integration/java/**/*.java'\n        // 1.23.0 has an issue in formatting comments https://github.com/google/google-java-format/issues/1155\n        // so we stick to 1.22.0 to produce consistent result for JDK 11/17/21\n        googleJavaFormat(\"1.22.0\")\n        removeUnusedImports()\n        licenseHeaderFile \"$rootDir/.baseline/copyright/copyright-header-java.txt\"\n      }\n    }\n  }\n\n  pluginManager.withPlugin('com.palantir.baseline-error-prone') {\n    tasks.withType(JavaCompile).configureEach {\n      options.errorprone.errorproneArgs.addAll (\n          // error-prone is slow, don't run on tests/generated-src/generated\n          '-XepExcludedPaths:.*/(test|generated-src|generated)/.*',\n          '-Xep:AnnotateFormatMethod:ERROR',\n          '-Xep:BadComparable:ERROR',\n          '-Xep:BadInstanceof:ERROR',\n          '-Xep:CatchFail:ERROR',\n          '-Xep:ClassCanBeStatic:ERROR',\n          '-Xep:ClassNewInstance:ERROR',\n          '-Xep:CollectionUndefinedEquality:ERROR',\n          // specific to Palantir - Uses name `log` but we use name `LOG`\n          '-Xep:ConsistentLoggerName:OFF',\n          '-Xep:DangerousJavaDeserialization:ERROR',\n          '-Xep:DangerousThreadPoolExecutorUsage:OFF',\n          '-Xep:DefaultCharset:ERROR',\n          '-Xep:DefaultLocale:ERROR',\n          // subclasses are not equal\n          '-Xep:EqualsGetClass:OFF',\n          '-Xep:EqualsUnsafeCast:ERROR',\n          '-Xep:EqualsUsingHashCode:ERROR',\n          '-Xep:ExtendsObject:ERROR',\n          '-Xep:FallThrough:ERROR',\n          // specific to Palantir\n          '-Xep:FinalClass:OFF',\n          '-Xep:Finalize:ERROR',\n          '-Xep:FormatStringAnnotation:ERROR',\n          '-Xep:GetClassOnEnum:ERROR',\n          '-Xep:HidingField:ERROR',\n          '-Xep:ImmutableSetForContains:ERROR',\n          '-Xep:ImmutablesReferenceEquality:ERROR',\n          '-Xep:InconsistentCapitalization:ERROR',\n          '-Xep:InconsistentHashCode:ERROR',\n          '-Xep:IntLongMath:ERROR',\n          '-Xep:JdkObsolete:ERROR',\n          // prefer method references over lambdas\n          '-Xep:LambdaMethodReference:ERROR',\n          // enforce logging conventions\n          '-Xep:LoggerEnclosingClass:ERROR',\n          // patterns that are allowed\n          '-Xep:MissingCasesInEnumSwitch:OFF',\n          // Enforce missing override\n          '-Xep:MissingOverride:ERROR',\n          '-Xep:MissingSummary:ERROR',\n          '-Xep:ModifiedButNotUsed:ERROR',\n          '-Xep:MutablePublicArray:ERROR',\n          '-Xep:NarrowCalculation:ERROR',\n          '-Xep:NarrowingCompoundAssignment:ERROR',\n          '-Xep:NullOptional:ERROR',\n          '-Xep:NullableOptional:ERROR',\n          '-Xep:NullablePrimitive:ERROR',\n          '-Xep:ObjectEqualsForPrimitives:ERROR',\n          // Enforce hashCode over hash\n          '-Xep:ObjectsHashCodeUnnecessaryVarargs:ERROR',\n          '-Xep:OrphanedFormatString:ERROR',\n          '-Xep:Overrides:ERROR',\n          // Triggers false-positives whenever relocated @VisibleForTesting is used\n          '-Xep:PreferCommonAnnotations:OFF',\n          // specific to Palantir\n          '-Xep:PreferSafeLoggableExceptions:OFF',\n          '-Xep:PreferSafeLogger:OFF',\n          // specific to Palantir\n          '-Xep:PreferSafeLoggingPreconditions:OFF',\n          '-Xep:PreferStaticLoggers:ERROR',\n          // specific to Palantir\n          '-Xep:RawTypes:OFF',\n          // specific to Palantir\n          '-Xep:Slf4jLogsafeArgs:OFF',\n          '-Xep:Slf4jThrowable:ERROR',\n          // Added because it errors out compile, but we need to figure out if we want it\n          '-Xep:StrictUnusedVariable:OFF',\n          // Enforce safe string splitting\n          '-Xep:StringSplitter:ERROR',\n          '-Xep:TypeParameterShadowing:OFF',\n          '-Xep:TypeParameterUnusedInFormals:OFF',\n          '-Xep:UnicodeEscape:ERROR',\n          // Palantir's UnnecessarilyQualified may throw during analysis\n          '-Xep:UnnecessarilyQualified:OFF',\n          '-Xep:UnnecessaryLongToIntConversion:ERROR',\n          '-Xep:UnnecessaryMethodReference:ERROR',\n          '-Xep:UnusedMethod:ERROR',\n          '-Xep:UnusedVariable:ERROR',\n          '-Xep:UseEnumSwitch:ERROR',\n      )\n    }\n  }\n\n  pluginManager.withPlugin('com.github.alisiikh.scalastyle') {\n    scalastyle {\n      config = file(\"${rootDir}/project/scalastyle_config.xml\")\n      inputEncoding = 'UTF-8'\n      outputEncoding = 'UTF-8'\n      failOnWarning = false\n      verbose = false\n      quiet = false\n    }\n  }\n}\n"
        },
        {
          "name": "build.gradle",
          "type": "blob",
          "size": 39.580078125,
          "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\nimport groovy.transform.Memoized\nimport java.util.regex.Matcher\nimport java.util.regex.Pattern\n\nbuildscript {\n  repositories {\n    gradlePluginPortal()\n  }\n  dependencies {\n    classpath 'com.gradleup.shadow:shadow-gradle-plugin:8.3.5'\n    classpath 'com.palantir.baseline:gradle-baseline-java:5.72.0'\n    classpath 'com.diffplug.spotless:spotless-plugin-gradle:6.25.0'\n    classpath 'gradle.plugin.org.inferred:gradle-processors:3.7.0'\n    classpath 'me.champeau.jmh:jmh-gradle-plugin:0.7.2'\n    classpath 'gradle.plugin.io.morethan.jmhreport:gradle-jmh-report:0.9.6'\n    classpath \"com.github.alisiikh:gradle-scalastyle-plugin:3.5.0\"\n    classpath 'org.revapi:gradle-revapi:1.8.0'\n    classpath 'com.gorylenko.gradle-git-properties:gradle-git-properties:2.4.2'\n    classpath 'com.palantir.gradle.gitversion:gradle-git-version:3.1.0'\n    classpath 'org.openapitools:openapi-generator-gradle-plugin:6.6.0'\n  }\n}\n\nString scalaVersion = System.getProperty(\"scalaVersion\") != null ? System.getProperty(\"scalaVersion\") : System.getProperty(\"defaultScalaVersion\")\nString sparkVersionsString = System.getProperty(\"sparkVersions\") != null ? System.getProperty(\"sparkVersions\") : System.getProperty(\"defaultSparkVersions\")\nList<String> sparkVersions = sparkVersionsString != null && !sparkVersionsString.isEmpty() ? sparkVersionsString.split(\",\") : []\n\ntry {\n  // apply these plugins in a try-catch block so that we can handle cases without .git directory\n  apply plugin: 'com.palantir.git-version'\n} catch (Exception e) {\n  project.logger.error(e.getMessage())\n}\n\nif (JavaVersion.current() == JavaVersion.VERSION_11) {\n  project.ext.jdkVersion = '11'\n  project.ext.extraJvmArgs = []\n} else if (JavaVersion.current() == JavaVersion.VERSION_17 || JavaVersion.current() == JavaVersion.VERSION_21) {\n  project.ext.jdkVersion = JavaVersion.current().getMajorVersion().toString()\n  project.ext.extraJvmArgs = [\"--add-opens\", \"java.base/java.io=ALL-UNNAMED\",\n                              \"--add-opens\", \"java.base/java.lang.invoke=ALL-UNNAMED\",\n                              \"--add-opens\", \"java.base/java.lang.reflect=ALL-UNNAMED\",\n                              \"--add-opens\", \"java.base/java.lang=ALL-UNNAMED\",\n                              \"--add-opens\", \"java.base/java.math=ALL-UNNAMED\",\n                              \"--add-opens\", \"java.base/java.net=ALL-UNNAMED\",\n                              \"--add-opens\", \"java.base/java.nio=ALL-UNNAMED\",\n                              \"--add-opens\", \"java.base/java.text=ALL-UNNAMED\",\n                              \"--add-opens\", \"java.base/java.time=ALL-UNNAMED\",\n                              \"--add-opens\", \"java.base/java.util.concurrent.atomic=ALL-UNNAMED\",\n                              \"--add-opens\", \"java.base/java.util.concurrent=ALL-UNNAMED\",\n                              \"--add-opens\", \"java.base/java.util.regex=ALL-UNNAMED\",\n                              \"--add-opens\", \"java.base/java.util=ALL-UNNAMED\",\n                              \"--add-opens\", \"java.base/jdk.internal.ref=ALL-UNNAMED\",\n                              \"--add-opens\", \"java.base/jdk.internal.reflect=ALL-UNNAMED\",\n                              \"--add-opens\", \"java.sql/java.sql=ALL-UNNAMED\",\n                              \"--add-opens\", \"java.base/sun.util.calendar=ALL-UNNAMED\",\n                              \"--add-opens\", \"java.base/sun.nio.ch=ALL-UNNAMED\",\n                              \"--add-opens\", \"java.base/sun.nio.cs=ALL-UNNAMED\",\n                              \"--add-opens\", \"java.base/sun.security.action=ALL-UNNAMED\",\n                              \"--add-opens\", \"java.base/sun.util.calendar=ALL-UNNAMED\"]\n} else {\n  throw new GradleException(\"This build must be run with JDK 11 or 17 or 21 but was executed with JDK \" + JavaVersion.current())\n}\n\ntasks.withType(AbstractArchiveTask).configureEach {\n  preserveFileTimestamps = false\n  reproducibleFileOrder = true\n}\n\napply plugin: 'com.gorylenko.gradle-git-properties'\n// git properties file for the root project for adding to the source tarball\ngitProperties {\n  gitPropertiesName = 'iceberg-build.properties'\n  gitPropertiesResourceDir = file(\"${rootDir}/build\")\n  extProperty = 'gitProps'\n  failOnNoGitDirectory = true\n  keys = ['git.branch', 'git.build.version', 'git.closest.tag.name','git.commit.id.abbrev', 'git.commit.id',\n          'git.commit.message.short', 'git.commit.time', 'git.tags']\n}\ngenerateGitProperties.outputs.upToDateWhen { false }\n\nif (file(\"${rootDir}/iceberg-build.properties\").exists()) {\n  tasks.register('buildInfo', Exec) {\n    project.logger.info('Using build info from iceberg-build.properties')\n    commandLine 'cp', \"${rootDir}/iceberg-build.properties\", 'build/iceberg-build.properties'\n  }\n} else {\n  tasks.register('buildInfo') {\n    project.logger.info('Generating iceberg-build.properties from git')\n    dependsOn generateGitProperties\n  }\n}\n\ndef projectVersion = getProjectVersion()\nfinal REVAPI_PROJECTS = [\"iceberg-api\", \"iceberg-core\", \"iceberg-parquet\", \"iceberg-orc\", \"iceberg-common\", \"iceberg-data\"]\n\nallprojects {\n  group = \"org.apache.iceberg\"\n  version = projectVersion\n  repositories {\n    mavenCentral()\n    mavenLocal()\n  }\n}\n\nsubprojects {\n  if (it.name == 'iceberg-bom') {\n    // the BOM does not build anything, the code below expects \"source code\"\n    return\n  }\n\n  apply plugin: 'java-library'\n\n  if (project.name in REVAPI_PROJECTS) {\n    apply plugin: 'org.revapi.revapi-gradle-plugin'\n    revapi {\n      oldGroup = project.group\n      oldName = project.name\n      oldVersion = \"1.7.0\"\n    }\n\n    tasks.register('showDeprecationRulesOnRevApiFailure') {\n      doLast {\n        throw new RuntimeException(\"==================================================================================\" +\n                \"\\nAPI/ABI breaks detected.\\n\" +\n                \"Adding RevAPI breaks should only be done after going through a deprecation cycle.\" +\n                \"\\nPlease make sure to follow the deprecation rules defined in\\n\" +\n                \"https://github.com/apache/iceberg/blob/main/CONTRIBUTING.md#semantic-versioning.\\n\" +\n                \"==================================================================================\")\n      }\n      onlyIf {\n        tasks.revapi.state.failure != null\n      }\n    }\n\n    tasks.configureEach { rootTask ->\n      if (rootTask.name == 'revapi') {\n        rootTask.finalizedBy showDeprecationRulesOnRevApiFailure\n      }\n    }\n    \n    tasks.named(\"revapiAnalyze\").configure {\n      dependsOn(\":iceberg-common:jar\")\n    }\n  }\n\n  configurations {\n    testImplementation.extendsFrom compileOnly\n\n    compileClasspath {\n      // do not exclude Guava so the bundle project can reference classes.\n      if (project.name != 'iceberg-bundled-guava') {\n        exclude group: 'com.google.guava', module: 'guava'\n      }\n      // contains a copy of Guava\n      exclude group: 'org.apache.spark', module: 'spark-network-common_2.12'\n    }\n\n    all {\n      exclude group: 'org.slf4j', module: 'slf4j-log4j12'\n      exclude group: 'org.mortbay.jetty'\n      exclude group: 'com.sun.jersey'\n      exclude group: 'com.sun.jersey.contribs'\n      exclude group: 'org.pentaho', module: 'pentaho-aggdesigner-algorithm'\n    }\n\n    testArtifacts\n  }\n\n  tasks.withType(JavaCompile.class).configureEach {\n    options.encoding = \"UTF-8\"\n    options.release = 11\n  }\n\n  javadoc {\n    options.encoding = 'UTF-8'\n  }\n\n  dependencies {\n    implementation libs.slf4j.api\n\n    testImplementation libs.junit.jupiter\n    testImplementation libs.junit.jupiter.engine\n    testImplementation libs.slf4j.simple\n    testImplementation libs.mockito.core\n    testImplementation libs.mockito.inline\n    testImplementation libs.assertj.core\n  }\n\n  test {\n    def logDir = \"${rootDir}/build/testlogs\"\n    def logFile = \"${logDir}/${project.name}.log\"\n    mkdir(\"${logDir}\")\n    delete(\"${logFile}\")\n    def buildLog = new File(logFile)\n    addTestOutputListener(new TestOutputListener() {\n      def lastDescriptor\n      @Override\n      void onOutput(TestDescriptor testDescriptor, TestOutputEvent testOutputEvent) {\n        if (lastDescriptor != testDescriptor) {\n          buildLog << \"--------\\n- Test log for: \"<< testDescriptor << \"\\n--------\\n\"\n          lastDescriptor = testDescriptor\n        }\n        buildLog << testOutputEvent.destination << \" \" << testOutputEvent.message\n      }\n    })\n\n    maxHeapSize = \"1500m\"\n\n    jvmArgs += project.property('extraJvmArgs')\n\n    testLogging {\n      events \"failed\"\n      exceptionFormat \"full\"\n    }\n  }\n\n  plugins.withType(ScalaPlugin.class) {\n    tasks.withType(ScalaCompile.class) {\n      scalaCompileOptions.keepAliveMode.set(KeepAliveMode.DAEMON)\n      // `options.release` doesn't seem to work for ScalaCompile :(\n      sourceCompatibility = \"11\"\n      targetCompatibility = \"11\"\n      scalaCompileOptions.additionalParameters.add(\"-release:11\")\n    }\n  }\n}\n\nproject(':iceberg-bundled-guava') {\n  apply plugin: 'com.gradleup.shadow'\n\n  tasks.jar.dependsOn tasks.shadowJar\n\n  dependencies {\n    compileOnly(libs.guava.guava) {\n      exclude group: 'com.google.code.findbugs'\n      // may be LGPL - use ALv2 findbugs-annotations instead\n      exclude group: 'com.google.errorprone'\n      exclude group: 'com.google.j2objc'\n    }\n  }\n\n  shadowJar {\n    archiveClassifier.set(null)\n    configurations = [project.configurations.compileClasspath]\n    zip64 true\n\n    // include the LICENSE and NOTICE files for the shaded Jar\n    from(projectDir) {\n      include 'LICENSE'\n      include 'NOTICE'\n    }\n\n    dependencies {\n      exclude(dependency('org.slf4j:slf4j-api'))\n      exclude(dependency('org.checkerframework:checker-qual'))\n    }\n\n    relocate 'com.google.common', 'org.apache.iceberg.relocated.com.google.common'\n\n    minimize()\n  }\n\n  jar {\n    archiveClassifier.set('empty')\n  }\n}\n\nproject(':iceberg-api') {\n  test {\n    useJUnitPlatform()\n  }\n\n  dependencies {\n    implementation project(path: ':iceberg-bundled-guava', configuration: 'shadow')\n    compileOnly libs.errorprone.annotations\n    compileOnly libs.findbugs.jsr305\n    testImplementation libs.avro.avro\n    testImplementation libs.esotericsoftware.kryo\n    testImplementation libs.awaitility\n  }\n\n  tasks.processTestResources.dependsOn rootProject.tasks.buildInfo\n\n  // Workaround to prevent:\n  // Task ':iceberg-api:processTestResources' uses this output of task\n  // ':spotlessInternalRegisterDependencies' without declaring an explicit or implicit dependency.\n  // This can lead to incorrect results being produced, depending on what order the tasks are executed.\n  rootProject.tasks.configureEach { rootTask ->\n    if (rootTask.name == 'spotlessInternalRegisterDependencies') {\n      tasks.processTestResources.dependsOn rootTask\n    }\n  }\n\n  sourceSets {\n    test {\n      resources {\n        srcDir \"${rootDir}/build\"\n      }\n    }\n  }\n}\n\nproject(':iceberg-common') {\n  dependencies {\n    implementation project(path: ':iceberg-bundled-guava', configuration: 'shadow')\n  }\n}\n\nproject(':iceberg-core') {\n  test {\n    useJUnitPlatform()\n  }\n  dependencies {\n    api project(':iceberg-api')\n    implementation project(':iceberg-common')\n    implementation project(path: ':iceberg-bundled-guava', configuration: 'shadow')\n    annotationProcessor libs.immutables.value\n    compileOnly libs.immutables.value\n\n    api(libs.avro.avro) {\n      exclude group: 'org.tukaani' // xz compression is not supported\n    }\n\n    implementation libs.aircompressor\n    implementation libs.httpcomponents.httpclient5\n    implementation platform(libs.jackson.bom)\n    implementation libs.jackson.core\n    implementation libs.jackson.databind\n    implementation libs.caffeine\n    implementation libs.roaringbitmap\n    compileOnly(libs.hadoop2.client) {\n      exclude group: 'org.apache.avro', module: 'avro'\n      exclude group: 'org.slf4j', module: 'slf4j-log4j12'\n    }\n\n    testImplementation libs.jetty.servlet\n    testImplementation libs.jakarta.servlet\n    testImplementation libs.jetty.server\n    testImplementation libs.mockserver.netty\n    testImplementation libs.mockserver.client.java\n    testImplementation libs.sqlite.jdbc\n    testImplementation project(path: ':iceberg-api', configuration: 'testArtifacts')\n    testImplementation libs.esotericsoftware.kryo\n    testImplementation libs.guava.testlib\n    testImplementation libs.awaitility\n  }\n}\n\nproject(':iceberg-data') {\n  dependencies {\n    implementation project(path: ':iceberg-bundled-guava', configuration: 'shadow')\n    api project(':iceberg-api')\n    implementation project(':iceberg-core')\n    compileOnly project(':iceberg-parquet')\n    compileOnly project(':iceberg-orc')\n    compileOnly(libs.hadoop2.common) {\n      exclude group: 'commons-beanutils'\n      exclude group: 'org.apache.avro', module: 'avro'\n      exclude group: 'org.slf4j', module: 'slf4j-log4j12'\n    }\n\n    implementation(\"${libs.orc.core.get().module}:${libs.versions.orc.get()}:nohive\") {\n      exclude group: 'org.apache.hadoop'\n      exclude group: 'commons-lang'\n      // These artifacts are shaded and included in the orc-core fat jar\n      exclude group: 'com.google.protobuf', module: 'protobuf-java'\n      exclude group: 'org.apache.hive', module: 'hive-storage-api'\n    }\n\n    implementation(libs.parquet.avro) {\n      exclude group: 'org.apache.avro', module: 'avro'\n      // already shaded by Parquet\n      exclude group: 'it.unimi.dsi'\n      exclude group: 'org.codehaus.jackson'\n    }\n\n    compileOnly libs.avro.avro\n\n    testImplementation(libs.hadoop2.client) {\n      exclude group: 'org.apache.avro', module: 'avro'\n      exclude group: 'org.slf4j', module: 'slf4j-log4j12'\n    }\n\n    testImplementation project(path: ':iceberg-api', configuration: 'testArtifacts')\n    testImplementation project(path: ':iceberg-core', configuration: 'testArtifacts')\n    testImplementation libs.junit.vintage.engine\n  }\n\n  test {\n    useJUnitPlatform()\n    // Only for TestSplitScan as of Gradle 5.0+\n    maxHeapSize '1500m'\n  }\n}\n\nproject(':iceberg-aliyun') {\n  test {\n    useJUnitPlatform()\n  }\n  dependencies {\n    implementation project(path: ':iceberg-bundled-guava', configuration: 'shadow')\n    api project(':iceberg-api')\n    implementation project(':iceberg-core')\n    implementation project(':iceberg-common')\n\n    compileOnly libs.aliyun.sdk.oss\n    compileOnly libs.jaxb.api\n    compileOnly libs.activation\n    compileOnly libs.jaxb.runtime\n    compileOnly(libs.hadoop2.common) {\n      exclude group: 'org.apache.avro', module: 'avro'\n      exclude group: 'org.slf4j', module: 'slf4j-log4j12'\n      exclude group: 'javax.servlet', module: 'servlet-api'\n      exclude group: 'com.google.code.gson', module: 'gson'\n    }\n\n    testImplementation platform(libs.jackson.bom)\n    testImplementation \"com.fasterxml.jackson.dataformat:jackson-dataformat-xml\"\n    testImplementation project(path: ':iceberg-api', configuration: 'testArtifacts')\n  }\n}\n\nproject(':iceberg-aws') {\n  test {\n    useJUnitPlatform()\n  }\n  dependencies {\n    implementation project(path: ':iceberg-bundled-guava', configuration: 'shadow')\n    api project(':iceberg-api')\n    implementation project(':iceberg-common')\n    implementation project(':iceberg-core')\n    annotationProcessor libs.immutables.value\n    compileOnly libs.immutables.value\n    implementation libs.caffeine\n    implementation libs.failsafe\n    implementation platform(libs.jackson.bom)\n    implementation libs.jackson.core\n    implementation libs.jackson.databind\n\n    compileOnly(platform(libs.awssdk.bom))\n    compileOnly(libs.awssdk.s3accessgrants)\n    compileOnly(\"software.amazon.awssdk:url-connection-client\")\n    compileOnly(\"software.amazon.awssdk:apache-client\")\n    compileOnly(\"software.amazon.awssdk:auth\")\n    compileOnly(\"software.amazon.awssdk:http-auth-aws-crt\")\n    compileOnly(\"software.amazon.awssdk:s3\")\n    compileOnly(\"software.amazon.awssdk:kms\")\n    compileOnly(\"software.amazon.awssdk:glue\")\n    compileOnly(\"software.amazon.awssdk:sts\")\n    compileOnly(\"software.amazon.awssdk:dynamodb\")\n    compileOnly(\"software.amazon.awssdk:lakeformation\")\n\n    compileOnly(libs.hadoop2.common) {\n      exclude group: 'org.apache.avro', module: 'avro'\n      exclude group: 'org.slf4j', module: 'slf4j-log4j12'\n      exclude group: 'javax.servlet', module: 'servlet-api'\n      exclude group: 'com.google.code.gson', module: 'gson'\n    }\n\n    compileOnly libs.httpcomponents.httpclient5\n\n    testImplementation(platform(libs.awssdk.bom))\n    testImplementation(\"software.amazon.awssdk:iam\")\n    testImplementation(\"software.amazon.awssdk:s3control\")\n    testImplementation(\"software.amazon.s3.accessgrants:aws-s3-accessgrants-java-plugin\")\n    testImplementation project(path: ':iceberg-api', configuration: 'testArtifacts')\n    testImplementation libs.esotericsoftware.kryo\n    testImplementation libs.sqlite.jdbc\n    testImplementation libs.testcontainers\n    testImplementation libs.testcontainers.junit.jupiter\n    testImplementation libs.testcontainers.minio\n    testImplementation libs.httpcomponents.httpclient5\n    testImplementation libs.mockserver.netty\n    testImplementation libs.mockserver.client.java\n    testImplementation libs.jaxb.api\n    testImplementation project(path: ':iceberg-core', configuration: 'testArtifacts')\n    testImplementation libs.awaitility\n    testImplementation libs.jetty.servlet\n  }\n\n  sourceSets {\n    integration {\n      java.srcDir \"$projectDir/src/integration/java\"\n      resources.srcDir \"$projectDir/src/integration/resources\"\n      compileClasspath += main.output + test.output\n      runtimeClasspath += main.output + test.output\n    }\n  }\n\n  configurations {\n    integrationImplementation.extendsFrom testImplementation\n    integrationRuntime.extendsFrom testRuntimeOnly\n  }\n\n  task integrationTest(type: Test) {\n    useJUnitPlatform()\n    testClassesDirs = sourceSets.integration.output.classesDirs\n    classpath = sourceSets.integration.runtimeClasspath\n    jvmArgs += project.property('extraJvmArgs')\n  }\n\n  def s3SignerSpec = \"$projectDir/src/main/resources/s3-signer-open-api.yaml\"\n  tasks.register('validateS3SignerSpec', org.openapitools.generator.gradle.plugin.tasks.ValidateTask) {\n    inputSpec.set(s3SignerSpec)\n    recommend.set(true)\n  }\n  check.dependsOn('validateS3SignerSpec')\n}\n\nproject(':iceberg-azure') {\n  test {\n    useJUnitPlatform()\n  }\n\n  dependencies {\n    implementation project(path: ':iceberg-bundled-guava', configuration: 'shadow')\n    api project(':iceberg-api')\n    implementation project(':iceberg-common')\n    implementation project(':iceberg-core')\n\n    compileOnly platform(libs.azuresdk.bom)\n    compileOnly \"com.azure:azure-storage-file-datalake\"\n    compileOnly \"com.azure:azure-identity\"\n\n    testImplementation project(path: ':iceberg-api', configuration: 'testArtifacts')\n    testImplementation libs.esotericsoftware.kryo\n    testImplementation libs.testcontainers\n  }\n}\n\nproject(':iceberg-delta-lake') {\n  // use integration test since we can take advantages of spark 3.3 to read datafiles of delta lake table\n  // and create some tests involving sql query.\n  test {\n    useJUnitPlatform()\n  }\n  configurations {\n    integrationImplementation.extendsFrom testImplementation\n    integrationRuntime.extendsFrom testRuntimeOnly\n  }\n\n  dependencies {\n    implementation project(path: ':iceberg-bundled-guava', configuration: 'shadow')\n    api project(':iceberg-api')\n    implementation project(':iceberg-common')\n    implementation project(':iceberg-core')\n    implementation project(':iceberg-parquet')\n    implementation platform(libs.jackson.bom)\n    implementation libs.jackson.databind\n    annotationProcessor libs.immutables.value\n    compileOnly libs.immutables.value\n\n    compileOnly \"io.delta:delta-standalone_${scalaVersion}:${libs.versions.delta.standalone.get()}\"\n\n    compileOnly(libs.hadoop2.common) {\n      exclude group: 'org.apache.avro', module: 'avro'\n      exclude group: 'org.slf4j', module: 'slf4j-log4j12'\n      exclude group: 'javax.servlet', module: 'servlet-api'\n      exclude group: 'com.google.code.gson', module: 'gson'\n    }\n\n    // The newest version of delta-core uses Spark 3.5.*. Since its only for test, we do\n    // not need to include older version of delta-core\n    if (sparkVersions.contains(\"3.5\")) {\n      integrationImplementation \"io.delta:delta-spark_${scalaVersion}:${libs.versions.delta.spark.get()}\"\n      integrationImplementation project(path: \":iceberg-spark:iceberg-spark-3.5_${scalaVersion}\")\n      integrationImplementation(libs.hadoop2.minicluster) {\n        exclude group: 'org.apache.avro', module: 'avro'\n        // to make sure netty libs only come from project(':iceberg-arrow')\n        exclude group: 'io.netty', module: 'netty-buffer'\n        exclude group: 'io.netty', module: 'netty-common'\n      }\n      integrationImplementation project(path: ':iceberg-hive-metastore')\n      integrationImplementation project(path: ':iceberg-hive-metastore', configuration: 'testArtifacts')\n      integrationImplementation(\"org.apache.spark:spark-hive_${scalaVersion}:${libs.versions.spark.hive35.get()}\") {\n        exclude group: 'org.apache.avro', module: 'avro'\n        exclude group: 'org.apache.arrow'\n        exclude group: 'org.apache.parquet'\n        // to make sure netty libs only come from project(':iceberg-arrow')\n        exclude group: 'io.netty', module: 'netty-buffer'\n        exclude group: 'io.netty', module: 'netty-common'\n        exclude group: 'org.roaringbitmap'\n      }\n    }\n  }\n\n  // The newest version of delta-core uses Spark 3.5.*. The integration test should only be built\n  // if iceberg-spark-3.5 is available\n  if (sparkVersions.contains(\"3.5\")) {\n    sourceSets {\n      integration {\n        java.srcDir \"$projectDir/src/integration/java\"\n        resources.srcDir \"$projectDir/src/integration/resources\"\n        compileClasspath += main.output + test.output\n        runtimeClasspath += main.output + test.output\n      }\n    }\n\n    task integrationTest(type: Test) {\n      useJUnitPlatform()\n      testClassesDirs = sourceSets.integration.output.classesDirs\n      classpath = sourceSets.integration.runtimeClasspath\n      jvmArgs += project.property('extraJvmArgs')\n    }\n    check.dependsOn integrationTest\n  }\n}\n\nproject(':iceberg-gcp') {\n  test {\n    useJUnitPlatform()\n  }\n\n  dependencies {\n    implementation project(path: ':iceberg-bundled-guava', configuration: 'shadow')\n    api project(':iceberg-api')\n    implementation project(':iceberg-common')\n    implementation project(':iceberg-core')\n\n    compileOnly platform(libs.google.libraries.bom)\n    compileOnly \"com.google.cloud:google-cloud-storage\"\n\n    testImplementation \"com.google.cloud:google-cloud-nio\"\n\n    testImplementation project(path: ':iceberg-api', configuration: 'testArtifacts')\n    testImplementation project(path: ':iceberg-core', configuration: 'testArtifacts')\n\n    testImplementation(libs.hadoop2.common) {\n      exclude group: 'org.apache.avro', module: 'avro'\n      exclude group: 'org.slf4j', module: 'slf4j-log4j12'\n      exclude group: 'javax.servlet', module: 'servlet-api'\n      exclude group: 'com.google.code.gson', module: 'gson'\n    }\n    testImplementation libs.esotericsoftware.kryo\n    testImplementation libs.mockserver.netty\n    testImplementation libs.mockserver.client.java\n  }\n}\n\nproject(':iceberg-hive-metastore') {\n  test {\n    useJUnitPlatform()\n  }\n\n  dependencies {\n    implementation project(path: ':iceberg-bundled-guava', configuration: 'shadow')\n    implementation project(':iceberg-core')\n    api project(':iceberg-api')\n    implementation project(':iceberg-common')\n    annotationProcessor libs.immutables.value\n    compileOnly libs.immutables.value\n\n    implementation libs.caffeine\n\n    compileOnly libs.avro.avro\n\n    compileOnly(libs.hive2.metastore) {\n      exclude group: 'org.apache.avro', module: 'avro'\n      exclude group: 'org.slf4j', module: 'slf4j-log4j12'\n      exclude group: 'org.pentaho' // missing dependency\n      exclude group: 'org.apache.hbase'\n      exclude group: 'org.apache.logging.log4j'\n      exclude group: 'co.cask.tephra'\n      exclude group: 'com.google.code.findbugs', module: 'jsr305'\n      exclude group: 'org.eclipse.jetty.aggregate', module: 'jetty-all'\n      exclude group: 'org.eclipse.jetty.orbit', module: 'javax.servlet'\n      exclude group: 'org.apache.parquet', module: 'parquet-hadoop-bundle'\n      exclude group: 'com.tdunning', module: 'json'\n      exclude group: 'javax.transaction', module: 'transaction-api'\n      exclude group: 'com.zaxxer', module: 'HikariCP'\n    }\n\n    // By default, hive-exec is a fat/uber jar and it exports a guava library\n    // that's really old. We use the core classifier to be able to override our guava\n    // version. Luckily, hive-exec seems to work okay so far with this version of guava\n    // See: https://github.com/apache/hive/blob/master/ql/pom.xml#L911 for more context.\n    testImplementation(\"${libs.hive2.exec.get().module}:${libs.hive2.exec.get().getVersion()}:core\") {\n      exclude group: 'org.apache.avro', module: 'avro'\n      exclude group: 'org.slf4j', module: 'slf4j-log4j12'\n      exclude group: 'org.pentaho' // missing dependency\n      exclude group: 'org.apache.hive', module: 'hive-llap-tez'\n      exclude group: 'org.apache.logging.log4j'\n      exclude group: 'com.google.protobuf', module: 'protobuf-java'\n      exclude group: 'org.apache.calcite'\n      exclude group: 'org.apache.calcite.avatica'\n      exclude group: 'com.google.code.findbugs', module: 'jsr305'\n    }\n\n    testImplementation(libs.hive2.metastore) {\n      exclude group: 'org.apache.avro', module: 'avro'\n      exclude group: 'org.slf4j', module: 'slf4j-log4j12'\n      exclude group: 'org.pentaho' // missing dependency\n      exclude group: 'org.apache.hbase'\n      exclude group: 'org.apache.logging.log4j'\n      exclude group: 'co.cask.tephra'\n      exclude group: 'com.google.code.findbugs', module: 'jsr305'\n      exclude group: 'org.eclipse.jetty.aggregate', module: 'jetty-all'\n      exclude group: 'org.eclipse.jetty.orbit', module: 'javax.servlet'\n      exclude group: 'org.apache.parquet', module: 'parquet-hadoop-bundle'\n      exclude group: 'com.tdunning', module: 'json'\n      exclude group: 'javax.transaction', module: 'transaction-api'\n      exclude group: 'com.zaxxer', module: 'HikariCP'\n    }\n\n    compileOnly(libs.hadoop2.client) {\n      exclude group: 'org.apache.avro', module: 'avro'\n      exclude group: 'org.slf4j', module: 'slf4j-log4j12'\n    }\n\n    testImplementation project(path: ':iceberg-api', configuration: 'testArtifacts')\n    testImplementation project(path: ':iceberg-core', configuration: 'testArtifacts')\n    testImplementation libs.awaitility\n  }\n}\n\nproject(':iceberg-orc') {\n  test {\n    useJUnitPlatform()\n  }\n  dependencies {\n    implementation project(path: ':iceberg-bundled-guava', configuration: 'shadow')\n    api project(':iceberg-api')\n    implementation project(':iceberg-common')\n    implementation project(':iceberg-core')\n    implementation(libs.avro.avro) {\n      exclude group: 'org.tukaani' // xz compression is not supported\n    }\n\n    implementation(\"${libs.orc.core.get().module}:${libs.versions.orc.get()}:nohive\") {\n      exclude group: 'org.apache.hadoop'\n      exclude group: 'commons-lang'\n      // These artifacts are shaded and included in the orc-core fat jar\n      exclude group: 'com.google.protobuf', module: 'protobuf-java'\n      exclude group: 'org.apache.hive', module: 'hive-storage-api'\n    }\n\n    compileOnly(libs.hadoop2.common) {\n      exclude group: 'commons-beanutils'\n      exclude group: 'org.apache.avro', module: 'avro'\n      exclude group: 'org.slf4j', module: 'slf4j-log4j12'\n    }\n    compileOnly(libs.hadoop2.client) {\n      exclude group: 'org.apache.avro', module: 'avro'\n    }\n\n    testImplementation project(path: ':iceberg-api', configuration: 'testArtifacts')\n    testImplementation project(path: ':iceberg-core', configuration: 'testArtifacts')\n    testImplementation project(':iceberg-common')\n    testImplementation libs.orc.tools\n  }\n}\n\nproject(':iceberg-parquet') {\n  test {\n    useJUnitPlatform()\n  }\n  dependencies {\n    implementation project(path: ':iceberg-bundled-guava', configuration: 'shadow')\n    api project(':iceberg-api')\n    implementation project(':iceberg-core')\n    implementation project(':iceberg-common')\n\n    implementation(libs.parquet.avro) {\n      exclude group: 'org.apache.avro', module: 'avro'\n      // already shaded by Parquet\n      exclude group: 'it.unimi.dsi'\n      exclude group: 'org.codehaus.jackson'\n    }\n\n    compileOnly libs.avro.avro\n    compileOnly(libs.hadoop2.client) {\n      exclude group: 'org.apache.avro', module: 'avro'\n    }\n\n    testImplementation project(path: ':iceberg-api', configuration: 'testArtifacts')\n    testImplementation project(path: ':iceberg-core', configuration: 'testArtifacts')\n  }\n}\n\nproject(':iceberg-arrow') {\n  test {\n    useJUnitPlatform()\n  }\n  dependencies {\n    implementation project(path: ':iceberg-bundled-guava', configuration: 'shadow')\n    api project(':iceberg-api')\n    implementation project(':iceberg-core')\n    implementation project(':iceberg-parquet')\n\n    implementation(libs.arrow.vector) {\n      exclude group: 'io.netty', module: 'netty-buffer'\n      exclude group: 'io.netty', module: 'netty-common'\n      exclude group: 'com.google.code.findbugs', module: 'jsr305'\n    }\n    implementation(libs.arrow.memory.netty) {\n      exclude group: 'com.google.code.findbugs', module: 'jsr305'\n      exclude group: 'io.netty', module: 'netty-common'\n      exclude group: 'io.netty', module: 'netty-buffer'\n    }\n\n    runtimeOnly libs.netty.buffer\n\n    implementation(libs.parquet.avro) {\n      exclude group: 'org.apache.avro', module: 'avro'\n      // already shaded by Parquet\n      exclude group: 'it.unimi.dsi'\n      exclude group: 'org.codehaus.jackson'\n    }\n\n    testImplementation project(path: ':iceberg-core', configuration: 'testArtifacts')\n    // To run ArrowReaderTest test cases, :netty-common is needed.\n    // We import :netty-common through :arrow-memory-netty\n    // so that the same version as used by the :arrow-memory-netty module is picked.\n    testImplementation libs.arrow.memory.netty\n    testImplementation libs.hadoop2.common\n    testImplementation libs.hadoop2.mapreduce.client.core\n  }\n}\n\nproject(':iceberg-nessie') {\n  test {\n    useJUnitPlatform()\n  }\n\n  dependencies {\n    api project(':iceberg-api')\n    implementation project(':iceberg-common')\n    implementation project(':iceberg-core')\n    implementation project(path: ':iceberg-bundled-guava', configuration: 'shadow')\n    implementation(libs.nessie.client) {\n      exclude group: 'com.fasterxml.jackson'\n    }\n    implementation platform(libs.jackson.bom)\n    implementation libs.jackson.core\n    implementation libs.jackson.databind\n\n    compileOnly libs.hadoop2.common\n    // Only there to prevent \"warning: unknown enum constant SchemaType.OBJECT\" compile messages\n    compileOnly libs.microprofile.openapi.api\n\n    testImplementation libs.nessie.jaxrs.testextension\n    testImplementation libs.nessie.versioned.storage.inmemory.tests\n    testImplementation libs.nessie.versioned.storage.testextension\n    // Need to \"pull in\" el-api explicitly :(\n    testImplementation libs.jakarta.el.api\n\n    testImplementation libs.avro.avro\n\n    testImplementation project(path: ':iceberg-api', configuration: 'testArtifacts')\n    testImplementation project(path: ':iceberg-core', configuration: 'testArtifacts')\n\n    // Only there to prevent \"warning: unknown enum constant SchemaType.OBJECT\" compile messages\n    testCompileOnly libs.microprofile.openapi.api\n  }\n}\n\nproject(':iceberg-dell') {\n  test {\n    useJUnitPlatform()\n  }\n  dependencies {\n    implementation project(':iceberg-core')\n    implementation project(':iceberg-common')\n    implementation project(path: ':iceberg-bundled-guava', configuration: 'shadow')\n    compileOnly libs.object.client.bundle\n\n    testImplementation project(path: ':iceberg-api', configuration: 'testArtifacts')\n    testImplementation libs.jaxb.api\n    testImplementation libs.activation\n    testImplementation libs.jaxb.runtime\n  }\n}\n\nproject(':iceberg-snowflake') {\n  test {\n    useJUnitPlatform()\n  }\n\n  dependencies {\n    implementation project(':iceberg-core')\n    implementation project(':iceberg-common')\n    implementation project(path: ':iceberg-bundled-guava', configuration: 'shadow')\n    implementation platform(libs.jackson.bom)\n    implementation libs.jackson.core\n    implementation libs.jackson.databind\n\n    runtimeOnly libs.snowflake.jdbc\n\n    testImplementation libs.mockito.junit.jupiter\n    testImplementation project(path: ':iceberg-core', configuration: 'testArtifacts')\n  }\n}\n\nproject(':iceberg-open-api') {\n  apply plugin: 'java-test-fixtures'\n  apply plugin: 'com.gradleup.shadow'\n\n  build.dependsOn shadowJar\n\n  dependencies {\n    testImplementation project(':iceberg-api')\n    testImplementation project(':iceberg-core')\n    testImplementation project(':iceberg-core').sourceSets.test.runtimeClasspath\n    testImplementation(testFixtures(project(':iceberg-open-api')))\n\n    testImplementation libs.junit.jupiter\n    testImplementation libs.junit.suite.api\n    testImplementation libs.junit.suite.engine\n    testImplementation libs.assertj.core\n\n    testImplementation project(':iceberg-aws-bundle')\n    testImplementation project(':iceberg-gcp-bundle')\n    testImplementation project(':iceberg-azure-bundle')\n\n    testFixturesImplementation project(':iceberg-api')\n    testFixturesImplementation project(':iceberg-core')\n    testFixturesImplementation project(path: ':iceberg-core', configuration: 'testArtifacts')\n    testFixturesImplementation project(':iceberg-aws')\n    testFixturesImplementation project(':iceberg-gcp')\n    testFixturesImplementation project(':iceberg-azure')\n    testFixturesImplementation(libs.hadoop3.common) {\n      exclude group: 'org.slf4j'\n      exclude group: 'ch.qos.reload4j'\n      exclude group: 'org.apache.avro', module: 'avro'\n      exclude group: 'com.google.guava'\n      exclude group: 'com.google.protobuf'\n      exclude group: 'org.apache.curator'\n      exclude group: 'org.apache.zookeeper'\n      exclude group: 'org.apache.kerby'\n      exclude group: 'org.apache.hadoop.thirdparty', module: 'hadoop-shaded-protobuf_3_7'\n      exclude group: 'org.eclipse.jetty'\n      exclude group: 'com.google.re2j', module: 're2j'\n      exclude group: 'com.google.code.gson', module: 'gson'\n      exclude group: 'com.jcraft', module: 'jsch'\n      exclude group: 'com.google.code.findbugs', module: 'jsr305'\n      exclude group: 'io.dropwizard.metrics', module: 'metrics-core'\n      exclude group: 'dnsjava', module: 'dnsjava'\n      exclude group: 'org.xerial.snappy', module: 'snappy-java'\n      exclude group: 'commons-cli', module: 'commons-cli'\n      exclude group: 'com.github.pjfanning', module: 'jersey-json'\n    }\n    testFixturesImplementation project(path: ':iceberg-bundled-guava', configuration: 'shadow')\n    testFixturesImplementation libs.junit.jupiter\n\n    testFixturesImplementation libs.slf4j.api\n    testFixturesImplementation libs.slf4j.simple\n\n    testFixturesImplementation libs.jetty.servlet\n    testFixturesImplementation libs.jetty.server\n    testFixturesImplementation libs.sqlite.jdbc\n\n    testFixturesCompileOnly libs.apiguardian\n\n    testFixturesRuntimeOnly project(':iceberg-aws-bundle')\n    testFixturesRuntimeOnly project(':iceberg-azure-bundle')\n    testFixturesRuntimeOnly project(':iceberg-gcp-bundle')\n  }\n\n  test {\n    useJUnitPlatform()\n\n    // Always rerun the compatibility tests\n    outputs.upToDateWhen {false}\n    maxParallelForks = 1\n\n    // Pass through any system properties that start with \"rck\" (REST Compatibility Kit)\n    // Note: only pass through specific properties so they do not affect other build/test\n    //       configurations\n    systemProperties System.properties\n            .findAll { k, v -> k.startsWith(\"rck\") }\n            .collectEntries { k, v -> { [(k):v, (k.replaceFirst(\"rck.\", \"\")):v] }} // strip prefix\n  }\n\n  def restCatalogSpec = \"$projectDir/rest-catalog-open-api.yaml\"\n  tasks.register('validateRESTCatalogSpec', org.openapitools.generator.gradle.plugin.tasks.ValidateTask) {\n    inputSpec.set(restCatalogSpec)\n    recommend.set(true)\n  }\n  check.dependsOn('validateRESTCatalogSpec')\n\n  shadowJar {\n    archiveBaseName.set(\"iceberg-open-api-test-fixtures-runtime\")\n    archiveClassifier.set(null)\n    configurations = [project.configurations.testFixturesRuntimeClasspath]\n    from sourceSets.testFixtures.output\n    zip64 true\n\n    // include the LICENSE and NOTICE files for the runtime Jar\n    from(projectDir) {\n      include 'LICENSE'\n      include 'NOTICE'\n    }\n\n    manifest {\n      attributes 'Main-Class': 'org.apache.iceberg.rest.RESTCatalogServer'\n    }\n  }\n\n  jar {\n    enabled = false\n  }\n}\n\n@Memoized\nboolean versionFileExists() {\n  return file('version.txt').exists()\n}\n\n@Memoized\nString getVersionFromFile() {\n  return file('version.txt').text.trim()\n}\n\nString getProjectVersion() {\n  if (versionFileExists()) {\n    return getVersionFromFile()\n  }\n\n  try {\n    // we're fetching the version from the latest tag (prefixed with 'apache-iceberg-'),\n    // which can look like this: '0.13.0-2-g805400f0.dirty' but we're only interested in the MAJOR.MINOR.PATCH part\n    String version = gitVersion(prefix: 'apache-iceberg-')\n    Pattern pattern = Pattern.compile(\"^([0-9]+)\\\\.([0-9]+)\\\\.([0-9]+)(.*)?\\$\")\n    Matcher matcher = pattern.matcher(version)\n    if (matcher.matches()) {\n      // bump the MINOR version and always set the PATCH version to 0\n      return matcher.group(1) + \".\" + (Integer.valueOf(matcher.group(2)) + 1) + \".0-SNAPSHOT\"\n    }\n    return version\n  } catch (Exception e) {\n    throw new Exception(\"Neither version.txt nor git version exists: \" + e.getMessage(), e)\n  }\n}\n\nString getJavadocVersion() {\n  if (versionFileExists()) {\n    return getVersionFromFile()\n  }\n\n  try {\n    // use the branch name in place of version in Javadoc\n    return versionDetails().branchName\n  } catch (NullPointerException e) {\n    throw new Exception(\"Neither version.txt nor git version exists\")\n  }\n}\n\napply from: 'jmh.gradle'\napply from: 'baseline.gradle'\napply from: 'deploy.gradle'\napply from: 'tasks.gradle'\n\nproject(':iceberg-bom') {\n  apply plugin: 'java-platform'\n\n  dependencies {\n    constraints {\n      // The Iceberg-Build builds for only one Scala version at a time, so the BOM would also\n      // only contain artifacts for that single Scala version. The following code ensures that\n      // the BOM references the artifacts for all Scala versions.\n      def sparkScalaPattern = ~\"(.*)-([0-9][.][0-9]+)_([0-9][.][0-9]+)\"\n      def sparkScalaVersions = [\n        \"3.3\": [\"2.12\", \"2.13\"],\n        \"3.4\": [\"2.12\", \"2.13\"],\n        \"3.5\": [\"2.12\", \"2.13\"],\n      ]\n      rootProject.allprojects.forEach {\n        // Do not include ':iceberg-spark', the bom itself and the root project.\n        if (it.name != 'iceberg-bom' && it != rootProject && it.childProjects.isEmpty()) {\n          if (it.name.startsWith(\"iceberg-spark-\")) {\n            def sparkScalaMatcher = sparkScalaPattern.matcher(it.name)\n            if (!sparkScalaMatcher.find()) {\n              throw new GradleException(\"Expected a Spark/Scala version combination in Gradle project name ${it.name}\")\n            }\n            def prjName = sparkScalaMatcher.group(1)\n            def sparkVer = sparkScalaMatcher.group(2)\n            for (def scalaVer in sparkScalaVersions[sparkVer]) {\n              add(\"api\", \"${it.group}:$prjName-${sparkVer}_$scalaVer:${it.version}\")\n            }\n          } else {\n            add(\"api\", project(it.path))\n          }\n        }\n      }\n    }\n  }\n\n  // Needed to get the \"faked\" Scala artifacts into the bom\n  javaPlatform { allowDependencies() }\n}\n"
        },
        {
          "name": "bundled-guava",
          "type": "tree",
          "content": null
        },
        {
          "name": "common",
          "type": "tree",
          "content": null
        },
        {
          "name": "core",
          "type": "tree",
          "content": null
        },
        {
          "name": "data",
          "type": "tree",
          "content": null
        },
        {
          "name": "dell",
          "type": "tree",
          "content": null
        },
        {
          "name": "delta-lake",
          "type": "tree",
          "content": null
        },
        {
          "name": "deploy.gradle",
          "type": "blob",
          "size": 4.583984375,
          "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\nif (project.hasProperty('release') && jdkVersion != '11') {\n  throw new GradleException(\"Releases must be built with Java 11\")\n}\n\nsubprojects {\n  def isBom = it.name == 'iceberg-bom'\n  def isOpenApi = it.name == 'iceberg-open-api'\n\n  apply plugin: 'maven-publish'\n  apply plugin: 'signing'\n  afterEvaluate {\n\n    if (!isBom) {\n      task sourceJar(type: Jar, dependsOn: classes) {\n        archiveClassifier.set('sources')\n        from sourceSets.main.allSource\n        group 'build'\n      }\n\n      task javadocJar(type: Jar, dependsOn: javadoc) {\n        archiveClassifier.set('javadoc')\n        from javadoc.destinationDir\n        group 'build'\n      }\n\n      task testJar(type: Jar) {\n        archiveClassifier.set('tests')\n        from sourceSets.test.output\n      }\n\n      artifacts {\n        archives sourceJar\n        archives javadocJar\n        archives testJar\n        testArtifacts testJar\n      }\n\n      // add LICENSE and NOTICE\n      [jar, sourceJar, javadocJar, testJar].each { task ->\n        task.dependsOn rootProject.tasks.buildInfo\n        task.from(\"${rootDir}/build\") {\n          include 'iceberg-build.properties'\n        }\n        task.from(rootDir) {\n          include 'LICENSE'\n          include 'NOTICE'\n        }\n      }\n    }\n\n    publishing {\n      publications {\n        apache(MavenPublication) {\n          if (isBom) {\n            from components.javaPlatform\n          } else if (isOpenApi) {\n            artifact testJar\n            artifact testFixturesJar\n            artifact shadowJar\n          } else {\n            if (tasks.matching({task -> task.name == 'shadowJar'}).isEmpty()) {\n              from components.java\n            } else {\n              project.shadow.component(it)\n            }\n\n            artifact sourceJar\n            artifact javadocJar\n            artifact testJar\n\n            versionMapping {\n              allVariants {\n                fromResolutionResult()\n              }\n            }\n          }\n\n          groupId = 'org.apache.iceberg'\n          pom {\n            name = 'Apache Iceberg'\n            description = 'A table format for huge analytic datasets'\n            url = 'https://iceberg.apache.org'\n            licenses {\n              license {\n                name = 'The Apache Software License, Version 2.0'\n                url = 'http://www.apache.org/licenses/LICENSE-2.0.txt'\n              }\n            }\n            mailingLists {\n              mailingList {\n                name = 'Dev Mailing List'\n                post = 'dev@iceberg.apache.org'\n                subscribe = 'dev-subscribe@iceberg.apache.org'\n                unsubscribe = 'dev-unsubscribe@iceberg.apache.org'\n              }\n            }\n            issueManagement {\n              system = 'GitHub'\n              url = 'https://github.com/apache/iceberg/issues'\n            }\n          }\n        }\n      }\n\n      repositories {\n        maven {\n          credentials {\n            username project.hasProperty('mavenUser') ? \"$mavenUser\" : \"\"\n            password project.hasProperty('mavenPassword') ? \"$mavenPassword\" : \"\"\n          }\n          // upload to the releases repository using ./gradlew -Prelease publish\n          def apacheSnapshotsRepoUrl = 'https://repository.apache.org/content/repositories/snapshots'\n          def apacheReleasesRepoUrl = 'https://repository.apache.org/service/local/staging/deploy/maven2'\n          def snapshotsRepoUrl = project.hasProperty('mavenSnapshotsRepo') ? \"$mavenSnapshotsRepo\" : \"$apacheSnapshotsRepoUrl\"\n          def releasesRepoUrl = project.hasProperty('mavenReleasesRepo') ? \"$mavenReleasesRepo\" : \"$apacheReleasesRepoUrl\"\n          url = project.hasProperty('release') ? releasesRepoUrl : snapshotsRepoUrl\n        }\n      }\n    }\n\n    if (project.hasProperty('release')) {\n      signing {\n        useGpgCmd()\n        sign publishing.publications.apache\n      }\n    }\n  }\n}\n"
        },
        {
          "name": "dev",
          "type": "tree",
          "content": null
        },
        {
          "name": "doap.rdf",
          "type": "blob",
          "size": 2.837890625,
          "content": "<?xml version=\"1.0\"?>\n<?xml-stylesheet type=\"text/xsl\"?>\n<rdf:RDF xml:lang=\"en\"\n         xmlns=\"http://usefulinc.com/ns/doap#\" \n         xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" \n         xmlns:asfext=\"http://projects.apache.org/ns/asfext#\"\n         xmlns:foaf=\"http://xmlns.com/foaf/0.1/\">\n<!--\n    Licensed to the Apache Software Foundation (ASF) under one or more\n    contributor license agreements.  See the NOTICE file distributed with\n    this work for additional information regarding copyright ownership.\n    The ASF licenses this file to You under the Apache License, Version 2.0\n    (the \"License\"); you may not use this file except in compliance with\n    the License.  You may obtain a copy of the License at\n   \n         https://www.apache.org/licenses/LICENSE-2.0\n   \n    Unless required by applicable law or agreed to in writing, software\n    distributed under the License is distributed on an \"AS IS\" BASIS,\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.\n-->\n  <Project rdf:about=\"https://iceberg.apache.org\">\n    <created>2023-09-14</created>\n    <license rdf:resource=\"https://spdx.org/licenses/Apache-2.0\" />\n    <name>Apache Iceberg</name>\n    <homepage rdf:resource=\"https://iceberg.apache.org\" />\n    <asfext:pmc rdf:resource=\"https://iceberg.apache.org\" />\n    <shortdesc>Iceberg is a high-performance format for huge analytic tables.</shortdesc>\n    <description>Iceberg brings the reliability and simplicity of SQL tables to big data, while making it possible for engines like Spark, Trino, Flink, Presto, Hive and Impala to safely work with the same tables, at the same time.</description>\n    <bug-database rdf:resource=\"https://github.com/apache/iceberg/issues\" />\n    <mailing-list rdf:resource=\"https://iceberg.apache.org/community/\" />\n    <download-page rdf:resource=\"https://iceberg.apache.org/releases/\" />\n    <programming-language>Java</programming-language>\n    <programming-language>Python</programming-language>\n    <programming-language>Go</programming-language>\n    <programming-language>Rust</programming-language>\n    <programming-language>C++</programming-language>\n    <category rdf:resource=\"https://projects.apache.org/category/big-data\" />\n    <category rdf:resource=\"https://projects.apache.org/category/database\" />\n    <category rdf:resource=\"https://projects.apache.org/category/data-engineering\" />\n    <release>\n      <Version>\n        <name>1.7.1</name>\n        <created>2024-12-06</created>\n        <revision>1.7.1</revision>\n      </Version>\n    </release>\n    <repository>\n      <GitRepository>\n        <location rdf:resource=\"https://github.com/apache/iceberg\"/>\n        <browse rdf:resource=\"https://github.com/apache/iceberg\"/>\n      </GitRepository>\n    </repository>\n  </Project>\n</rdf:RDF>\n\n"
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "flink",
          "type": "tree",
          "content": null
        },
        {
          "name": "format",
          "type": "tree",
          "content": null
        },
        {
          "name": "gcp-bundle",
          "type": "tree",
          "content": null
        },
        {
          "name": "gcp",
          "type": "tree",
          "content": null
        },
        {
          "name": "gradle.properties",
          "type": "blob",
          "size": 1.5546875,
          "content": "# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\njmhOutputPath=build/reports/jmh/human-readable-output.txt\njmhJsonOutputPath=build/reports/jmh/results.json\njmhIncludeRegex=.*\nsystemProp.defaultFlinkVersions=1.20\nsystemProp.knownFlinkVersions=1.18,1.19,1.20\nsystemProp.defaultHiveVersions=2\nsystemProp.knownHiveVersions=2,3\nsystemProp.defaultSparkVersions=3.5\nsystemProp.knownSparkVersions=3.3,3.4,3.5\nsystemProp.defaultKafkaVersions=3\nsystemProp.knownKafkaVersions=3\nsystemProp.defaultScalaVersion=2.12\nsystemProp.knownScalaVersions=2.12,2.13\n# enable the Gradle build cache - speeds up builds!\norg.gradle.caching=true\n# enable Gradle parallel builds\norg.gradle.parallel=true\n# configure only necessary Gradle tasks\norg.gradle.configureondemand=true\n# explicitly disable the configuration cache\norg.gradle.configuration-cache=false\norg.gradle.jvmargs=-Xmx1024m\n"
        },
        {
          "name": "gradle",
          "type": "tree",
          "content": null
        },
        {
          "name": "gradlew",
          "type": "blob",
          "size": 8.71484375,
          "content": "#!/bin/sh\n\n#\n# Copyright  2015-2021 the original authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n\n##############################################################################\n#\n#   Gradle start up script for POSIX generated by Gradle.\n#\n#   Important for running:\n#\n#   (1) You need a POSIX-compliant shell to run this script. If your /bin/sh is\n#       noncompliant, but you have some other compliant shell such as ksh or\n#       bash, then to run this script, type that shell name before the whole\n#       command line, like:\n#\n#           ksh Gradle\n#\n#       Busybox and similar reduced shells will NOT work, because this script\n#       requires all of these POSIX shell features:\n#         * functions;\n#         * expansions $var, ${var}, ${var:-default}, ${var+SET},\n#           ${var#prefix}, ${var%suffix}, and $( cmd );\n#         * compound commands having a testable exit status, especially case;\n#         * various built-in commands including command, set, and ulimit.\n#\n#   Important for patching:\n#\n#   (2) This script targets any POSIX shell, so it avoids extensions provided\n#       by Bash, Ksh, etc; in particular arrays are avoided.\n#\n#       The \"traditional\" practice of packing multiple parameters into a\n#       space-separated string is a well documented source of bugs and security\n#       problems, so this is (mostly) avoided, by progressively accumulating\n#       options in \"$@\", and eventually passing that to Java.\n#\n#       Where the inherited environment variables (DEFAULT_JVM_OPTS, JAVA_OPTS,\n#       and GRADLE_OPTS) rely on word-splitting, this is performed explicitly;\n#       see the in-line comments for details.\n#\n#       There are tweaks for specific operating systems such as AIX, CygWin,\n#       Darwin, MinGW, and NonStop.\n#\n#   (3) This script is generated from the Groovy template\n#       https://github.com/gradle/gradle/blob/HEAD/platforms/jvm/plugins-application/src/main/resources/org/gradle/api/internal/plugins/unixStartScript.txt\n#       within the Gradle project.\n#\n#       You can find Gradle at https://github.com/gradle/gradle/.\n#\n##############################################################################\n\n# Attempt to set APP_HOME\n\n# Resolve links: $0 may be a link\napp_path=$0\n\n# Need this for daisy-chained symlinks.\nwhile\n    APP_HOME=${app_path%\"${app_path##*/}\"}  # leaves a trailing /; empty if no leading path\n    [ -h \"$app_path\" ]\ndo\n    ls=$( ls -ld \"$app_path\" )\n    link=${ls#*' -> '}\n    case $link in             #(\n      /*)   app_path=$link ;; #(\n      *)    app_path=$APP_HOME$link ;;\n    esac\ndone\n\n# This is normally unused\n# shellcheck disable=SC2034\nAPP_BASE_NAME=${0##*/}\n# Discard cd standard output in case $CDPATH is set (https://github.com/gradle/gradle/issues/25036)\nAPP_HOME=$( cd -P \"${APP_HOME:-./}\" > /dev/null && printf '%s\\n' \"$PWD\" ) || exit\n\nif [ ! -e $APP_HOME/gradle/wrapper/gradle-wrapper.jar ]; then\n    curl -o $APP_HOME/gradle/wrapper/gradle-wrapper.jar https://raw.githubusercontent.com/gradle/gradle/v8.12.0/gradle/wrapper/gradle-wrapper.jar\nfi\n\n# Use the maximum available, or set MAX_FD != -1 to use that value.\nMAX_FD=maximum\n\nwarn () {\n    echo \"$*\"\n} >&2\n\ndie () {\n    echo\n    echo \"$*\"\n    echo\n    exit 1\n} >&2\n\n# OS specific support (must be 'true' or 'false').\ncygwin=false\nmsys=false\ndarwin=false\nnonstop=false\ncase \"$( uname )\" in                #(\n  CYGWIN* )         cygwin=true  ;; #(\n  Darwin* )         darwin=true  ;; #(\n  MSYS* | MINGW* )  msys=true    ;; #(\n  NONSTOP* )        nonstop=true ;;\nesac\n\nCLASSPATH=$APP_HOME/gradle/wrapper/gradle-wrapper.jar\n\n\n# Determine the Java command to use to start the JVM.\nif [ -n \"$JAVA_HOME\" ] ; then\n    if [ -x \"$JAVA_HOME/jre/sh/java\" ] ; then\n        # IBM's JDK on AIX uses strange locations for the executables\n        JAVACMD=$JAVA_HOME/jre/sh/java\n    else\n        JAVACMD=$JAVA_HOME/bin/java\n    fi\n    if [ ! -x \"$JAVACMD\" ] ; then\n        die \"ERROR: JAVA_HOME is set to an invalid directory: $JAVA_HOME\n\nPlease set the JAVA_HOME variable in your environment to match the\nlocation of your Java installation.\"\n    fi\nelse\n    JAVACMD=java\n    if ! command -v java >/dev/null 2>&1\n    then\n        die \"ERROR: JAVA_HOME is not set and no 'java' command could be found in your PATH.\n\nPlease set the JAVA_HOME variable in your environment to match the\nlocation of your Java installation.\"\n    fi\nfi\n\n# Increase the maximum file descriptors if we can.\nif ! \"$cygwin\" && ! \"$darwin\" && ! \"$nonstop\" ; then\n    case $MAX_FD in #(\n      max*)\n        # In POSIX sh, ulimit -H is undefined. That's why the result is checked to see if it worked.\n        # shellcheck disable=SC2039,SC3045\n        MAX_FD=$( ulimit -H -n ) ||\n            warn \"Could not query maximum file descriptor limit\"\n    esac\n    case $MAX_FD in  #(\n      '' | soft) :;; #(\n      *)\n        # In POSIX sh, ulimit -n is undefined. That's why the result is checked to see if it worked.\n        # shellcheck disable=SC2039,SC3045\n        ulimit -n \"$MAX_FD\" ||\n            warn \"Could not set maximum file descriptor limit to $MAX_FD\"\n    esac\nfi\n\n# Collect all arguments for the java command, stacking in reverse order:\n#   * args from the command line\n#   * the main class name\n#   * -classpath\n#   * -D...appname settings\n#   * --module-path (only if needed)\n#   * DEFAULT_JVM_OPTS, JAVA_OPTS, and GRADLE_OPTS environment variables.\n\n# For Cygwin or MSYS, switch paths to Windows format before running java\nif \"$cygwin\" || \"$msys\" ; then\n    APP_HOME=$( cygpath --path --mixed \"$APP_HOME\" )\n    CLASSPATH=$( cygpath --path --mixed \"$CLASSPATH\" )\n\n    JAVACMD=$( cygpath --unix \"$JAVACMD\" )\n\n    # Now convert the arguments - kludge to limit ourselves to /bin/sh\n    for arg do\n        if\n            case $arg in                                #(\n              -*)   false ;;                            # don't mess with options #(\n              /?*)  t=${arg#/} t=/${t%%/*}              # looks like a POSIX filepath\n                    [ -e \"$t\" ] ;;                      #(\n              *)    false ;;\n            esac\n        then\n            arg=$( cygpath --path --ignore --mixed \"$arg\" )\n        fi\n        # Roll the args list around exactly as many times as the number of\n        # args, so each arg winds up back in the position where it started, but\n        # possibly modified.\n        #\n        # NB: a `for` loop captures its iteration list before it begins, so\n        # changing the positional parameters here affects neither the number of\n        # iterations, nor the values presented in `arg`.\n        shift                   # remove old arg\n        set -- \"$@\" \"$arg\"      # push replacement arg\n    done\nfi\n\n\n# Add default JVM options here. You can also use JAVA_OPTS and GRADLE_OPTS to pass JVM options to this script.\nDEFAULT_JVM_OPTS='\"-Xmx64m\" \"-Xms64m\"'\n\n# Collect all arguments for the java command:\n#   * DEFAULT_JVM_OPTS, JAVA_OPTS, and optsEnvironmentVar are not allowed to contain shell fragments,\n#     and any embedded shellness will be escaped.\n#   * For example: A user cannot expect ${Hostname} to be expanded, as it is an environment variable and will be\n#     treated as '${Hostname}' itself on the command line.\n\nset -- \\\n        \"-Dorg.gradle.appname=$APP_BASE_NAME\" \\\n        -classpath \"$CLASSPATH\" \\\n        org.gradle.wrapper.GradleWrapperMain \\\n        \"$@\"\n\n# Stop when \"xargs\" is not available.\nif ! command -v xargs >/dev/null 2>&1\nthen\n    die \"xargs is not available\"\nfi\n\n# Use \"xargs\" to parse quoted args.\n#\n# With -n1 it outputs one arg per line, with the quotes and backslashes removed.\n#\n# In Bash we could simply go:\n#\n#   readarray ARGS < <( xargs -n1 <<<\"$var\" ) &&\n#   set -- \"${ARGS[@]}\" \"$@\"\n#\n# but POSIX shell has neither arrays nor command substitution, so instead we\n# post-process each arg (as a line of input to sed) to backslash-escape any\n# character that might be a shell metacharacter, then use eval to reverse\n# that process (while maintaining the separation between arguments), and wrap\n# the whole thing up as a single \"set\" statement.\n#\n# This will of course break if any of these variables contains a newline or\n# an unmatched quote.\n#\n\neval \"set -- $(\n        printf '%s\\n' \"$DEFAULT_JVM_OPTS $JAVA_OPTS $GRADLE_OPTS\" |\n        xargs -n1 |\n        sed ' s~[^-[:alnum:]+,./:=@_]~\\\\&~g; ' |\n        tr '\\n' ' '\n    )\" '\"$@\"'\n\nexec \"$JAVACMD\" \"$@\"\n"
        },
        {
          "name": "hive-metastore",
          "type": "tree",
          "content": null
        },
        {
          "name": "hive-runtime",
          "type": "tree",
          "content": null
        },
        {
          "name": "hive3-orc-bundle",
          "type": "tree",
          "content": null
        },
        {
          "name": "hive3",
          "type": "tree",
          "content": null
        },
        {
          "name": "jitpack.yml",
          "type": "blob",
          "size": 0.8037109375,
          "content": "# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\ninstall:\n  - ./gradlew publishToMavenLocal\n"
        },
        {
          "name": "jmh.gradle",
          "type": "blob",
          "size": 3.1572265625,
          "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\nif (jdkVersion != '11' && jdkVersion != '17' && jdkVersion != '21') {\n  throw new GradleException(\"The JMH benchmarks must be run with JDK 11 or JDK 17 or JDK 21\")\n}\n\ndef flinkVersions = (System.getProperty(\"flinkVersions\") != null ? System.getProperty(\"flinkVersions\") : System.getProperty(\"defaultFlinkVersions\")).split(\",\")\ndef sparkVersions = (System.getProperty(\"sparkVersions\") != null ? System.getProperty(\"sparkVersions\") : System.getProperty(\"defaultSparkVersions\")).split(\",\")\ndef scalaVersion = System.getProperty(\"scalaVersion\") != null ? System.getProperty(\"scalaVersion\") : System.getProperty(\"defaultScalaVersion\")\ndef jmhProjects = [project(\":iceberg-core\"), project(\":iceberg-data\")]\n\nif (flinkVersions.contains(\"1.18\")) {\n  jmhProjects.add(project(\":iceberg-flink:iceberg-flink-1.18\"))\n}\n\nif (flinkVersions.contains(\"1.19\")) {\n  jmhProjects.add(project(\":iceberg-flink:iceberg-flink-1.19\"))\n}\n\nif (flinkVersions.contains(\"1.20\")) {\n  jmhProjects.add(project(\":iceberg-flink:iceberg-flink-1.20\"))\n}\n\nif (sparkVersions.contains(\"3.3\")) {\n  jmhProjects.add(project(\":iceberg-spark:iceberg-spark-3.3_${scalaVersion}\"))\n  jmhProjects.add(project(\":iceberg-spark:iceberg-spark-extensions-3.3_${scalaVersion}\"))\n}\n\nif (sparkVersions.contains(\"3.4\")) {\n  jmhProjects.add(project(\":iceberg-spark:iceberg-spark-3.4_${scalaVersion}\"))\n  jmhProjects.add(project(\":iceberg-spark:iceberg-spark-extensions-3.4_${scalaVersion}\"))\n}\n\nif (sparkVersions.contains(\"3.5\")) {\n  jmhProjects.add(project(\":iceberg-spark:iceberg-spark-3.5_${scalaVersion}\"))\n  jmhProjects.add(project(\":iceberg-spark:iceberg-spark-extensions-3.5_${scalaVersion}\"))\n}\n\nconfigure(jmhProjects) {\n  apply plugin: 'me.champeau.jmh'\n  apply plugin: 'io.morethan.jmhreport'\n\n  def jmhReportDir = project.property(\"jmhJsonOutputPath\").toString().replace(\".json\", \"\")\n  mkdir(file(jmhReportDir))\n\n  jmh {\n    jmhVersion = '1.37'\n    failOnError = true\n    forceGC = true\n    includeTests = true\n    humanOutputFile = file(jmhOutputPath)\n    resultsFile = file(jmhJsonOutputPath)\n    resultFormat = 'JSON'\n    includes = [jmhIncludeRegex]\n    zip64 = true\n  }\n\n  jmhReport {\n    jmhResultPath = file(jmhJsonOutputPath)\n    jmhReportOutput = file(jmhReportDir)\n  }\n\n  jmhCompileGeneratedClasses {\n    pluginManager.withPlugin('com.palantir.baseline-error-prone') {\n      options.errorprone.enabled = false\n    }\n  }\n\n  tasks.jmh.finalizedBy tasks.jmhReport\n}\n"
        },
        {
          "name": "kafka-connect",
          "type": "tree",
          "content": null
        },
        {
          "name": "mr",
          "type": "tree",
          "content": null
        },
        {
          "name": "nessie",
          "type": "tree",
          "content": null
        },
        {
          "name": "open-api",
          "type": "tree",
          "content": null
        },
        {
          "name": "orc",
          "type": "tree",
          "content": null
        },
        {
          "name": "parquet",
          "type": "tree",
          "content": null
        },
        {
          "name": "project",
          "type": "tree",
          "content": null
        },
        {
          "name": "settings.gradle",
          "type": "blob",
          "size": 10.24609375,
          "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\nrootProject.name = 'iceberg'\ninclude 'bom'\ninclude 'api'\ninclude 'common'\ninclude 'core'\ninclude 'data'\ninclude 'aliyun'\ninclude 'aws'\ninclude 'aws-bundle'\ninclude 'azure'\ninclude 'azure-bundle'\ninclude 'orc'\ninclude 'arrow'\ninclude 'parquet'\ninclude 'bundled-guava'\ninclude 'spark'\ninclude 'hive-metastore'\ninclude 'nessie'\ninclude 'gcp'\ninclude 'gcp-bundle'\ninclude 'dell'\ninclude 'snowflake'\ninclude 'delta-lake'\ninclude 'open-api'\n\nproject(':bom').name = 'iceberg-bom'\nproject(':api').name = 'iceberg-api'\nproject(':common').name = 'iceberg-common'\nproject(':core').name = 'iceberg-core'\nproject(':data').name = 'iceberg-data'\nproject(':aliyun').name = 'iceberg-aliyun'\nproject(':aws').name = 'iceberg-aws'\nproject(':aws-bundle').name = 'iceberg-aws-bundle'\nproject(':azure').name = 'iceberg-azure'\nproject(':azure-bundle').name = 'iceberg-azure-bundle'\nproject(':orc').name = 'iceberg-orc'\nproject(':arrow').name = 'iceberg-arrow'\nproject(':parquet').name = 'iceberg-parquet'\nproject(':bundled-guava').name = 'iceberg-bundled-guava'\nproject(':spark').name = 'iceberg-spark'\nproject(':hive-metastore').name = 'iceberg-hive-metastore'\nproject(':nessie').name = 'iceberg-nessie'\nproject(':gcp').name = 'iceberg-gcp'\nproject(':gcp-bundle').name = 'iceberg-gcp-bundle'\nproject(':dell').name = 'iceberg-dell'\nproject(':snowflake').name = 'iceberg-snowflake'\nproject(':delta-lake').name = 'iceberg-delta-lake'\nproject(':open-api').name = 'iceberg-open-api'\n\nif (null != System.getProperty(\"allModules\")) {\n  System.setProperty(\"flinkVersions\", System.getProperty(\"knownFlinkVersions\"))\n  System.setProperty(\"sparkVersions\", System.getProperty(\"knownSparkVersions\"))\n  System.setProperty(\"hiveVersions\", System.getProperty(\"knownHiveVersions\"))\n  System.setProperty(\"kafkaVersions\", System.getProperty(\"knownKafkaVersions\"))\n}\n\nList<String> knownFlinkVersions = System.getProperty(\"knownFlinkVersions\").split(\",\")\nString flinkVersionsString = System.getProperty(\"flinkVersions\") != null ? System.getProperty(\"flinkVersions\") : System.getProperty(\"defaultFlinkVersions\")\nList<String> flinkVersions = flinkVersionsString != null && !flinkVersionsString.isEmpty() ? flinkVersionsString.split(\",\") : []\n\nif (!knownFlinkVersions.containsAll(flinkVersions)) {\n  throw new GradleException(\"Found unsupported Flink versions: \" + (flinkVersions - knownFlinkVersions))\n}\n\nList<String> knownHiveVersions = System.getProperty(\"knownHiveVersions\").split(\",\")\nString hiveVersionsString = System.getProperty(\"hiveVersions\") != null ? System.getProperty(\"hiveVersions\") : System.getProperty(\"defaultHiveVersions\")\nList<String> hiveVersions = hiveVersionsString != null && !hiveVersionsString.isEmpty() ? hiveVersionsString.split(\",\") : []\n\nif (!knownHiveVersions.containsAll(hiveVersions)) {\n  throw new GradleException(\"Found unsupported Hive versions: \" + (hiveVersions - knownHiveVersions))\n}\n\nList<String> knownSparkVersions = System.getProperty(\"knownSparkVersions\").split(\",\")\nString sparkVersionsString = System.getProperty(\"sparkVersions\") != null ? System.getProperty(\"sparkVersions\") : System.getProperty(\"defaultSparkVersions\")\nList<String> sparkVersions = sparkVersionsString != null && !sparkVersionsString.isEmpty() ? sparkVersionsString.split(\",\") : []\n\nif (!knownSparkVersions.containsAll(sparkVersions)) {\n  throw new GradleException(\"Found unsupported Spark versions: \" + (sparkVersions - knownSparkVersions))\n}\n\nList<String> knownKafkaVersions = System.getProperty(\"knownKafkaVersions\").split(\",\")\nString kafkaVersionsString = System.getProperty(\"kafkaVersions\") != null ? System.getProperty(\"kafkaVersions\") : System.getProperty(\"defaultKafkaVersions\")\nList<String> kafkaVersions = kafkaVersionsString != null && !kafkaVersionsString.isEmpty() ? kafkaVersionsString.split(\",\") : []\n\nif (!knownKafkaVersions.containsAll(kafkaVersions)) {\n  throw new GradleException(\"Found unsupported Kafka versions: \" + (kafkaVersions - knownKafkaVersions))\n}\n\nList<String> knownScalaVersions = System.getProperty(\"knownScalaVersions\").split(\",\")\nString scalaVersion = System.getProperty(\"scalaVersion\") != null ? System.getProperty(\"scalaVersion\") : System.getProperty(\"defaultScalaVersion\")\n\nif (!knownScalaVersions.contains(scalaVersion)) {\n  throw new GradleException(\"Found unsupported Scala version: \" + scalaVersion)\n}\n\nif (!flinkVersions.isEmpty()) {\n  include 'flink'\n  project(':flink').name = 'iceberg-flink'\n}\n\nif (flinkVersions.contains(\"1.18\")) {\n  include \":iceberg-flink:flink-1.18\"\n  include \":iceberg-flink:flink-runtime-1.18\"\n  project(\":iceberg-flink:flink-1.18\").projectDir = file('flink/v1.18/flink')\n  project(\":iceberg-flink:flink-1.18\").name = \"iceberg-flink-1.18\"\n  project(\":iceberg-flink:flink-runtime-1.18\").projectDir = file('flink/v1.18/flink-runtime')\n  project(\":iceberg-flink:flink-runtime-1.18\").name = \"iceberg-flink-runtime-1.18\"\n}\n\nif (flinkVersions.contains(\"1.19\")) {\n  include \":iceberg-flink:flink-1.19\"\n  include \":iceberg-flink:flink-runtime-1.19\"\n  project(\":iceberg-flink:flink-1.19\").projectDir = file('flink/v1.19/flink')\n  project(\":iceberg-flink:flink-1.19\").name = \"iceberg-flink-1.19\"\n  project(\":iceberg-flink:flink-runtime-1.19\").projectDir = file('flink/v1.19/flink-runtime')\n  project(\":iceberg-flink:flink-runtime-1.19\").name = \"iceberg-flink-runtime-1.19\"\n}\n\nif (flinkVersions.contains(\"1.20\")) {\n  include \":iceberg-flink:flink-1.20\"\n  include \":iceberg-flink:flink-runtime-1.20\"\n  project(\":iceberg-flink:flink-1.20\").projectDir = file('flink/v1.20/flink')\n  project(\":iceberg-flink:flink-1.20\").name = \"iceberg-flink-1.20\"\n  project(\":iceberg-flink:flink-runtime-1.20\").projectDir = file('flink/v1.20/flink-runtime')\n  project(\":iceberg-flink:flink-runtime-1.20\").name = \"iceberg-flink-runtime-1.20\"\n}\n\nif (sparkVersions.contains(\"3.3\")) {\n  include \":iceberg-spark:spark-3.3_${scalaVersion}\"\n  include \":iceberg-spark:spark-extensions-3.3_${scalaVersion}\"\n  include \":iceberg-spark:spark-runtime-3.3_${scalaVersion}\"\n  project(\":iceberg-spark:spark-3.3_${scalaVersion}\").projectDir = file('spark/v3.3/spark')\n  project(\":iceberg-spark:spark-3.3_${scalaVersion}\").name = \"iceberg-spark-3.3_${scalaVersion}\"\n  project(\":iceberg-spark:spark-extensions-3.3_${scalaVersion}\").projectDir = file('spark/v3.3/spark-extensions')\n  project(\":iceberg-spark:spark-extensions-3.3_${scalaVersion}\").name = \"iceberg-spark-extensions-3.3_${scalaVersion}\"\n  project(\":iceberg-spark:spark-runtime-3.3_${scalaVersion}\").projectDir = file('spark/v3.3/spark-runtime')\n  project(\":iceberg-spark:spark-runtime-3.3_${scalaVersion}\").name = \"iceberg-spark-runtime-3.3_${scalaVersion}\"\n}\n\nif (sparkVersions.contains(\"3.4\")) {\n  include \":iceberg-spark:spark-3.4_${scalaVersion}\"\n  include \":iceberg-spark:spark-extensions-3.4_${scalaVersion}\"\n  include \":iceberg-spark:spark-runtime-3.4_${scalaVersion}\"\n  project(\":iceberg-spark:spark-3.4_${scalaVersion}\").projectDir = file('spark/v3.4/spark')\n  project(\":iceberg-spark:spark-3.4_${scalaVersion}\").name = \"iceberg-spark-3.4_${scalaVersion}\"\n  project(\":iceberg-spark:spark-extensions-3.4_${scalaVersion}\").projectDir = file('spark/v3.4/spark-extensions')\n  project(\":iceberg-spark:spark-extensions-3.4_${scalaVersion}\").name = \"iceberg-spark-extensions-3.4_${scalaVersion}\"\n  project(\":iceberg-spark:spark-runtime-3.4_${scalaVersion}\").projectDir = file('spark/v3.4/spark-runtime')\n  project(\":iceberg-spark:spark-runtime-3.4_${scalaVersion}\").name = \"iceberg-spark-runtime-3.4_${scalaVersion}\"\n}\n\nif (sparkVersions.contains(\"3.5\")) {\n  include \":iceberg-spark:spark-3.5_${scalaVersion}\"\n  include \":iceberg-spark:spark-extensions-3.5_${scalaVersion}\"\n  include \":iceberg-spark:spark-runtime-3.5_${scalaVersion}\"\n  project(\":iceberg-spark:spark-3.5_${scalaVersion}\").projectDir = file('spark/v3.5/spark')\n  project(\":iceberg-spark:spark-3.5_${scalaVersion}\").name = \"iceberg-spark-3.5_${scalaVersion}\"\n  project(\":iceberg-spark:spark-extensions-3.5_${scalaVersion}\").projectDir = file('spark/v3.5/spark-extensions')\n  project(\":iceberg-spark:spark-extensions-3.5_${scalaVersion}\").name = \"iceberg-spark-extensions-3.5_${scalaVersion}\"\n  project(\":iceberg-spark:spark-runtime-3.5_${scalaVersion}\").projectDir = file('spark/v3.5/spark-runtime')\n  project(\":iceberg-spark:spark-runtime-3.5_${scalaVersion}\").name = \"iceberg-spark-runtime-3.5_${scalaVersion}\"\n}\n\n// hive 3 depends on hive 2, so always add hive 2 if hive3 is enabled\nif (hiveVersions.contains(\"2\") || hiveVersions.contains(\"3\")) {\n  include 'mr'\n  include 'hive-runtime'\n\n  project(':mr').name = 'iceberg-mr'\n  project(':hive-runtime').name = 'iceberg-hive-runtime'\n}\n\nif (hiveVersions.contains(\"3\")) {\n  include 'hive3'\n  include 'hive3-orc-bundle'\n  project(':hive3').name = 'iceberg-hive3'\n  project(':hive3-orc-bundle').name = 'iceberg-hive3-orc-bundle'\n}\n\nif (kafkaVersions.contains(\"3\")) {\n  include 'kafka-connect'\n  project(':kafka-connect').name = 'iceberg-kafka-connect'\n\n  include \":iceberg-kafka-connect:kafka-connect-events\"\n  project(\":iceberg-kafka-connect:kafka-connect-events\").projectDir = file('kafka-connect/kafka-connect-events')\n  project(\":iceberg-kafka-connect:kafka-connect-events\").name = \"iceberg-kafka-connect-events\"\n\n  include \":iceberg-kafka-connect:kafka-connect\"\n  project(\":iceberg-kafka-connect:kafka-connect\").projectDir = file('kafka-connect/kafka-connect')\n  project(\":iceberg-kafka-connect:kafka-connect\").name = \"iceberg-kafka-connect\"\n\n  include \":iceberg-kafka-connect:kafka-connect-runtime\"\n  project(\":iceberg-kafka-connect:kafka-connect-runtime\").projectDir = file('kafka-connect/kafka-connect-runtime')\n  project(\":iceberg-kafka-connect:kafka-connect-runtime\").name = \"iceberg-kafka-connect-runtime\"\n}\n"
        },
        {
          "name": "site",
          "type": "tree",
          "content": null
        },
        {
          "name": "snowflake",
          "type": "tree",
          "content": null
        },
        {
          "name": "spark",
          "type": "tree",
          "content": null
        },
        {
          "name": "tasks.gradle",
          "type": "blob",
          "size": 1.76171875,
          "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\n\ntask aggregateJavadoc(type: Javadoc) {\n  def javadocTasks = subprojects.findAll { it.name != 'iceberg-bom' }.javadoc\n  dependsOn javadocTasks\n  source javadocTasks.source\n  destinationDir project.rootProject.file(\"site/docs/javadoc/${getJavadocVersion()}\")\n  classpath = project.rootProject.files(javadocTasks.classpath)\n\n  final JAVADOC_FIX_SEARCH_STR = '\\n\\n' +\n          'getURLPrefix = function(ui) {\\n' +\n          '    return \\'\\';\\n' +\n          '};\\n'\n\n  doLast {\n    // Fix bug with search\n    // Append the fix to the file\n    def searchScript = new File(\"site/docs/javadoc/${getJavadocVersion()}\" + '/search.js')\n    searchScript.append JAVADOC_FIX_SEARCH_STR\n  }\n}\n\ntask removeJavadoc(type: Exec) {\n  commandLine 'rm', '-rf', \"site/docs/javadoc/${getJavadocVersion()}\"\n}\n\ntask refreshJavadoc() {\n  dependsOn aggregateJavadoc\n  dependsOn removeJavadoc\n  aggregateJavadoc.mustRunAfter removeJavadoc\n}\n\ntask deploySite(type: Exec) {\n  workingDir 'site'\n  commandLine('./deploy.sh')\n}\n\n"
        }
      ]
    }
  ]
}