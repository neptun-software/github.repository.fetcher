{
  "metadata": {
    "timestamp": 1736709377432,
    "page": 87,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjkw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "postgresml/postgresml",
      "stars": 6101,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 0.2216796875,
          "content": "root = true\n\n[*]\nend_of_line = lf\ninsert_final_newline = true\ncharset = utf-8\n\n[*.py, *.rs]\nindent_style = space\nindent_size = 4\n\n[*.js]\nindent_style = space\nindent_size = 2\n\n[*.{html,css}]\nindent_style = space\nindent_size = 2\n"
        },
        {
          "name": ".git-blame-ignore-revs",
          "type": "blob",
          "size": 0.09375,
          "content": "# .git-blame-ignore-revs\n# Fixed Windows line endings.\n5d91e570a567c4b9059e66b36421b007d00f889f\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.125,
          "content": "# Set the default behavior, in case people don't have core.autocrlf set.\n* text=auto\n\n*.sh     text eol=lf\n*.docker text eol=lf\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 3.0576171875,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n.DS_Store\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\n/lib\nlib64/\nparts/\nsdist/\n/var\nwheels/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\ncover/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\n.pybuilder/\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n#   For a library or package, you might want to ignore these files since the code is\n#   intended to run in multiple environments; otherwise, check them in:\n# .python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# poetry\n#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.\n#   This is especially recommended for binary packages to ensure reproducibility, and is more\n#   commonly ignored for libraries.\n#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control\n#poetry.lock\n\n# pdm\n#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.\n#pdm.lock\n#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it\n#   in version control.\n#   https://pdm.fming.dev/#use-with-ide\n.pdm.toml\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# pytype static type analyzer\n.pytype/\n\n# Cython debug symbols\ncython_debug/\n\n# PyCharm\n#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can\n#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore\n#  and can be added to the global gitignore or merged into this file.  For a more nuclear\n#  option (not recommended) you can uncomment the following to ignore the entire idea folder.\n.idea/\n\n# local scratch pad\nscratch.sql\nscratch.py\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.1142578125,
          "content": "[submodule \"pgml-extension/deps/linfa\"]\n\tpath = pgml-extension/deps/linfa\n\turl = https://github.com/postgresml/linfa\n"
        },
        {
          "name": "MIT-LICENSE.txt",
          "type": "blob",
          "size": 1.0341796875,
          "content": "Copyright (c) 2022 PostgresML Team\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 9.8408203125,
          "content": "<div align=\"center\">\n   <picture>\n     <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/user-attachments/assets/5d5510da-6014-4cf3-849f-566050e053da\">\n     <source media=\"(prefers-color-scheme: light)\" srcset=\"https://github.com/user-attachments/assets/aea1c38a-15bf-4270-8365-3d5e6311f5fc\">\n     <img alt=\"Logo\" src=\"\" width=\"520\">\n   </picture>\n</div>\n\n<p align=\"center\">\n   <p align=\"center\"><b>Postgres + GPUs for ML/AI applications.</b></p>\n</p>\n\n<p align=\"center\">\n| <a href=\"https://postgresml.org/docs/\"><b>Documentation</b></a> | <a href=\"https://postgresml.org/blog\"><b>Blog</b></a> | <a href=\"https://discord.gg/DmyJP3qJ7U\"><b>Discord</b></a> |\n</p>\n\n---\nWhy do ML/AI in Postgres?\n\nData for ML & AI systems is inherently larger and more dynamic than the models. It's more efficient, manageable and reliable to move models to the database, rather than constantly moving data to the models.</b></p>\n</p>\n\n- [Getting started](#getting-started)\n    - [PostgresML Cloud](#postgresml-cloud)\n    - [Self-hosted](#self-hosted)\n    - [Ecosystem](#ecosystem)\n- [Large Language Models](#large-language-models)\n    - [Hugging Face](#hugging-face)\n    - [OpenAI and Other Providers](#openai)\n- [RAG](#rag)\n    - [Chunk](#chunk)\n    - [Embed](#embed)\n    - [Rank](#rank)\n    - [Transform](#transform)\n- [Machine Learning](#machine-learning)\n\n## Architecture\n\n<div align=\"center\">\n   <picture>\n     <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/user-attachments/assets/e27f8bda-1fe6-49f8-b9d8-ef563e0150e5\">\n     <source media=\"(prefers-color-scheme: light)\" srcset=\"https://github.com/user-attachments/assets/09bbed94-b73f-447b-95d9-2d4a7727c3aa\">\n     <img alt=\"Logo\" src=\"\" width=\"784\">\n   </picture>\n</div>\n\n<div align=\"center\">\n<b>PostgresML is a powerful Postgres extension that seamlessly combines data storage and machine learning inference within your database</b>. By integrating these functionalities, PostgresML eliminates the need for separate systems and data transfers, enabling you to perform ML operations directly on your data where it resides.\n</div>\n\n## Features at a glance\n\n- **In-Database ML/AI**: Run machine learning and AI operations directly within PostgreSQL\n- **GPU Acceleration**: Leverage GPU power for faster computations and model inference\n- **Large Language Models**: Integrate and use state-of-the-art LLMs from Hugging Face\n- **RAG Pipeline**: Built-in functions for chunking, embedding, ranking, and transforming text\n- **Vector Search**: Efficient similarity search using pgvector integration\n- **Diverse ML Algorithms**: 47+ classification and regression algorithms available\n- **High Performance**: 8-40X faster inference compared to HTTP-based model serving\n- **Scalability**: Support for millions of transactions per second and horizontal scaling\n- **NLP Tasks**: Wide range of natural language processing capabilities\n- **Security**: Enhanced data privacy by keeping models and data together\n- **Seamless Integration**: Works with existing PostgreSQL tools and client libraries\n\n# Getting started\n\nThe only prerequisites for using PostgresML is a Postgres database with our open-source `pgml` extension installed.\n\n## PostgresML Cloud\n\nOur serverless cloud is the easiest and recommend way to get started.\n\n[Sign up for a free PostgresML account](https://postgresml.org/signup). You'll get a free database in seconds, with access to GPUs and state of the art LLMs.\n\n## Self-hosted\n\nIf you don't want to use our cloud you can self host it.\n\n```\ndocker run \\\n    -it \\\n    -v postgresml_data:/var/lib/postgresql \\\n    -p 5433:5432 \\\n    -p 8000:8000 \\\n    ghcr.io/postgresml/postgresml:2.7.12 \\\n    sudo -u postgresml psql -d postgresml\n```\n\nFor more details, take a look at our [Quick Start with Docker](https://postgresml.org/docs/open-source/pgml/developers/quick-start-with-docker) documentation.\n\n## Ecosystem\n\nWe have a number of other tools and libraries that are specifically designed to work with PostgreML. Remeber PostgresML is a postgres extension running inside of Postgres so you can connect with `psql` and use any of your favorite tooling and client libraries like [psycopg](https://www.psycopg.org/psycopg3/) to connect and run queries.\n\n<b>PostgresML Specific Client Libraries:</b>\n- [Korvus](https://github.com/postgresml/korvus) - Korvus is a Python, JavaScript, Rust and C search SDK that unifies the entire RAG pipeline in a single database query.\n- [postgresml-django](https://github.com/postgresml/postgresml-django) - postgresml-django is a Python module that integrates PostgresML with Django ORM.\n\n<b>Recommended Postgres Poolers:</b>\n- [pgcat](https://github.com/postgresml/pgcat) - pgcat is a PostgreSQL pooler with sharding, load balancing and failover support.\n\n# Large language models\n\nPostgresML brings models directly to your data, eliminating the need for costly and time-consuming data transfers. This approach significantly enhances performance, security, and scalability for AI-driven applications.\n\nBy running models within the database, PostgresML enables:\n\n- Reduced latency and improved query performance\n- Enhanced data privacy and security\n- Simplified infrastructure management\n- Seamless integration with existing database operations\n\n## Hugging Face\n\nPostgresML supports a wide range of state-of-the-art deep learning architectures available on the Hugging Face [model hub](https://huggingface.co/models). This integration allows you to:\n\n- Access thousands of pre-trained models\n- Utilize cutting-edge NLP, computer vision, and other AI models\n- Easily experiment with different architectures\n\n## OpenAI and other providers\n\nWhile cloud-based LLM providers offer powerful capabilities, making API calls from within the database can introduce latency, security risks, and potential compliance issues. Currently, PostgresML does not directly support integration with remote LLM providers like OpenAI.\n\n# RAG\n\nPostgresML transforms your PostgreSQL database into a powerful vector database for Retrieval-Augmented Generation (RAG) applications. It leverages pgvector for efficient storage and retrieval of embeddings.\n\nOur RAG implementation is built on four key SQL functions:\n\n1. [Chunk](#chunk): Splits text into manageable segments\n2. [Embed](#embed): Generates vector embeddings from text using pre-trained models\n3. [Rank](#rank): Performs similarity search on embeddings\n4. [Transform](#transform): Applies language models for text generation or transformation\n\nFor more information on using RAG with PostgresML see our guide on [Unified RAG](https://postgresml.org/docs/open-source/pgml/guides/unified-rag).\n\n## Chunk\n\nThe `pgml.chunk` function chunks documents using the specified splitter. This is typically done before embedding.\n\n```postgresql\npgml.chunk(\n    splitter TEXT,    -- splitter name\n    text TEXT,        -- text to embed\n    kwargs JSON       -- optional arguments (see below)\n)\n```\n\nSee [pgml.chunk docs](https://postgresml.org/docs/open-source/pgml/api/pgml.chunk) for more information.\n\n## Embed\n\nThe `pgml.embed` function generates embeddings from text using in-database models.\n\n```postgresql\npgml.embed(\n    transformer TEXT,\n    \"text\" TEXT,\n    kwargs JSONB\n)\n```\nSee [pgml.embed docs](https://postgresml.org/docs/open-source/pgml/api/pgml.embed) for more information.\n\n## Rank\n\nThe `pgml.rank` function uses [Cross-Encoders](https://www.sbert.net/examples/applications/cross-encoder/README.html) to score sentence pairs.\n\nThis is typically used as a re-ranking step when performing search.\n\n```postgresl\npgml.rank(\n    transformer TEXT,\n    query TEXT,\n    documents TEXT[],\n    kwargs JSONB\n)\n```\n\nDocs coming soon.\n\n## Transform\n\nThe `pgml.transform` function can be used to generate text.\n\n```postgresql\nSELECT pgml.transform(\n    task   => TEXT OR JSONB,     -- Pipeline initializer arguments\n    inputs => TEXT[] OR BYTEA[], -- inputs for inference\n    args   => JSONB              -- (optional) arguments to the pipeline.\n)\n```\n\nSee [pgml.transform docs](https://postgresml.org/docs/open-source/pgml/api/pgml.transform) for more information.\n\nSee our [Text Generation guide](https://postgresml.org/docs/open-source/pgml/guides/llms/text-generation) for a guide on generating text.\n\n# Machine learning\n\n<b>Some highlights:</b>\n- [47+ classification and regression algorithms](https://postgresml.org/docs/open-source/pgml/api/pgml.train)\n- [8 - 40X faster inference than HTTP based model serving](https://postgresml.org/blog/postgresml-is-8x-faster-than-python-http-microservices)\n- [Millions of transactions per second](https://postgresml.org/blog/scaling-postgresml-to-one-million-requests-per-second)\n- [Horizontal scalability](https://postgresml.org/docs/open-source/pgcat/)\n\n**Training a classification model**\n\n*Training*\n```postgresql\nSELECT * FROM pgml.train(\n    'Handwritten Digit Image Classifier',\n    algorithm => 'xgboost',\n    'classification',\n    'pgml.digits',\n    'target'\n);\n```\n\n*Inference*\n```postgresql\nSELECT pgml.predict(\n    'My Classification Project',\n    ARRAY[0.1, 2.0, 5.0]\n) AS prediction;\n```\n\n## NLP\n\nThe `pgml.transform` function exposes a number of available NLP tasks.\n\nAvailable tasks are:\n- [Text Classification](https://postgresml.org/docs/open-source/pgml/guides/llms/text-classification)\n- [Zero-Shot Classification](https://postgresml.org/docs/open-source/pgml/guides/llms/zero-shot-classification)\n- [Token Classification](https://postgresml.org/docs/open-source/pgml/guides/llms/token-classification)\n- [Translation](https://postgresml.org/docs/open-source/pgml/guides/llms/translation)\n- [Summarization](https://postgresml.org/docs/open-source/pgml/guides/llms/summarization)\n- [Question Answering](https://postgresml.org/docs/open-source/pgml/guides/llms/question-answering)\n- [Text Generation](https://postgresml.org/docs/open-source/pgml/guides/llms/text-generation)\n- [Text-to-Text Generation](https://postgresml.org/docs/open-source/pgml/guides/llms/text-to-text-generation)\n- [Fill-Mask](https://postgresml.org/docs/open-source/pgml/guides/llms/fill-mask)\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.3935546875,
          "content": "# Security Policy\n\n## Supported Versions\n\n| Version | Supported          |\n| ------- | ------------------ |\n| 1.x     | :white_check_mark: |\n| 2.x     | :white_check_mark: |\n\n## Reporting a Vulnerability\n\nPlease report security vulnerabilities you discover to security at postgresml.org.\nAll reports will be acknowledged within 24 hours. You'll receive daily updates\nuntil the vulnerability is patched.\n"
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "packages",
          "type": "tree",
          "content": null
        },
        {
          "name": "pgml-apps",
          "type": "tree",
          "content": null
        },
        {
          "name": "pgml-cms",
          "type": "tree",
          "content": null
        },
        {
          "name": "pgml-dashboard",
          "type": "tree",
          "content": null
        },
        {
          "name": "pgml-extension",
          "type": "tree",
          "content": null
        },
        {
          "name": "pgml-sdks",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}