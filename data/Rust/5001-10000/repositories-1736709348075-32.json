{
  "metadata": {
    "timestamp": 1736709348075,
    "page": 32,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "spacejam/sled",
      "stars": 8260,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.205078125,
          "content": "default.sled\ncrash_*\n*db\n*conf\n*snap.*\n*grind.out*\nvgcore*\n*.bk\n*orig\ntags\nperf*\n*folded\n*out\n*perf\n*svg\n*txt\nexperiments\ntarget\nCargo.lock\n*swp\n*swo\n*.proptest-regressions\ncorpus\nartifacts\n.idea\ncargo-timing*\n"
        },
        {
          "name": ".rustfmt.toml",
          "type": "blob",
          "size": 0.1513671875,
          "content": "version = \"Two\"\nuse_small_heuristics = \"Max\"\nreorder_imports = true\nmax_width = 80\nwrap_comments = true\ncombine_control_expr = true\nreport_todo = \"Always\"\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 12.51953125,
          "content": "# Unreleased\n\n## New Features\n\n* #1178 batches and transactions are now unified for subscribers.\n* #1231 `Tree::get_zero_copy` allows for reading a value directly\n  in-place without making an `IVec` first.\n* #1250 the global `print_profile` function has been added\n  which is enabled when compiling with the `metrics` feature.\n* #1254 `IVec` data will now always have an alignment of 8,\n  which may enable interesting architecture-specific use cases.\n* #1307 & #1315 `Db::contains_tree` can be used to see if a\n  `Tree` with a given name already exists.\n\n## Improvements\n\n* #1214 a new slab-style storage engine has been added which\n  replaces the previous file-per-blob technique for storing\n  large pages.\n* #1231 tree nodes now get merged into a single-allocation\n  representation that is able to dynamically avoid various\n  overheads, resulting in significant efficiency improvements.\n\n## Breaking Changes\n\n* #1400 Bump MSRV to 1.57.\n* #1399 Thread support is now required on all platforms.\n* #1135 The \"no_metrics\" anti-feature has been replaced with\n  the \"metrics\" positive feature.\n* #1178 the `Event` enum has become a unified struct that allows\n  subscribers to iterate over each (Tree, key, optional value)\n  involved in single key operations, batches, or transactions in\n  a unified way.\n* #1178 the `Event::key` method has been removed in favor of the\n  new more comprehensive `iter` method.\n* #1214 The deprecated `Config::build` method has been removed.\n* #1248 The deprecated `Tree::set` method has been removed.\n* #1248 The deprecated `Tree::del` method has been removed.\n* #1250 The `Config::print_profile_on_drop` method has been\n  removed in favor of the global `print_profile` function.\n* #1252 The deprecated `Db::open` method has been removed.\n* #1252 The deprecated `Config::segment_cleanup_skew` method\n  has been removed.\n* #1252 The deprecated `Config::segment_cleanup_threshold`\n  method has been removed.\n* #1252 The deprecated `Config::snapshot_path` method has\n  been removed.\n* #1253 The `IVec::subslice` method has been removed.\n* #1275 Keys and values are now limited to 128gb on 64-bit\n  platforms and 512mb on 32-bit platforms.\n* #1281 `Config`'s `cache_capacity` is now a usize, as u64\n  doesn't make sense for things that must fit in memory anyway.\n* #1314 `Subscriber::next_timeout` now requires a mutable self\n  reference.\n* #1349 The \"measure_allocs\" feature has been removed.\n* #1354 `Error` has been modified to be Copy, removing all\n  heap-allocated variants.\n\n## Bug Fixes\n\n* #1202 Fix a space leak where blobs were not\n  removed when replaced by another blob.\n* #1229 the powerful ALICE crash consistency tool has been\n  used to discover several crash vulnerabilities, now fixed.\n\n# 0.34.7\n\n## Bug Fixes\n\n* #1314 Fix a bug in Subscriber's Future impl.\n\n# 0.34.6\n\n## Improvements\n\n* documentation improved\n\n# 0.34.5\n\n## Improvements\n\n* #1164 widen some trait bounds on trees and batches\n\n# 0.34.4\n\n## New Features\n\n* #1151 `Send` is implemented for `Iter`\n* #1167 added `Tree::first` and `Tree::last` functions\n  to retrieve the first or last items in a `Tree`, unless\n  the `Tree` is empty.\n\n## Bug Fixes\n\n* #1159 dropping a `Db` instance will no-longer\n  prematurely shut-down the background flusher\n  thread.\n* #1168 fixed an issue that was causing panics during\n  recovery in 32-bit code.\n* #1170 when encountering corrupted storage data,\n  the recovery process will panic less often.\n\n# 0.34.3\n\n## New Features\n\n* #1146 added `TransactionalTree::generate_id`\n\n# 0.34.2\n\n## Improvements\n\n* #1133 transactions and writebatch performance has been\n  significantly improved by removing a bottleneck in\n  the atomic batch stability tracking code.\n\n# 0.34.1\n\n## New Features\n\n* #1136 Added the `TransactionalTree::flush` method to\n  flush the underlying database after the transaction\n  commits and before the transaction returns.\n\n# 0.34\n\n## Improvements\n\n* #1132 implemented From<sled::Error> for io::Error to\n  reduce friction in some situations.\n\n## Breaking Changes\n\n* #1131 transactions performed on `Tree`s from different\n  `Db`s will now safely fail.\n* #1131 transactions may now only be performed on tuples\n  of up to 14 elements. For higher numbers, please use\n  slices.\n\n# 0.33\n\n## Breaking Changes\n\n* #1125 the backtrace crate has been made optional, which\n  cuts several seconds off compilation time, but may cause\n  breakage if you interacted with the backtrace field\n  of corruption-related errors.\n\n## Bug Fixes\n\n* #1128 `Tree::pop_min` and `Tree::pop_max` had a bug where\n  they were not atomic.\n\n# 0.32.1\n\n## New Features\n\n* #1116 `IVec::subslice` has been added to facilitate\n  creating zero-copy subsliced `IVec`s that are backed\n  by the same data.\n\n## Bug Fixes\n\n* #1120 Fixed a use-after-free caused by missing `ref` keyword\n  on a `Copy` type in a pattern match in `IVec::as_mut`.\n* #1108 conversions from `Box<[u8]>` to `IVec` are fixed.\n\n# 0.32\n\n## New Features\n\n* #1079 `Transactional` is now implemented for\n  `[&Tree]` and `[Tree]` so you can avoid the\n  previous friction of using tuples, as was\n  necessary previously.\n* #1058 The minimum supported Rust version (MSRV)\n  is now 1.39.0.\n* #1037 `Subscriber` now implements `Future` (non-fused)\n  so prefix watching may now be iterated over via\n  `while let Some(event) = (&mut subscriber).await {}`\n\n## Improvements\n\n* #965 concurrency control is now dynamically enabled\n  for atomic point operations, so that it may be\n  avoided unless transactional functionality is\n  being used in the system. This significantly\n  increases performance for workloads that do not\n  use transactions.\n* A number of memory optimizations have been implemented.\n* Disk usage has been significantly reduced for many\n  workloads.\n* #1016 On 64-bit systems, we can now store 1-2 trillion items.\n* #993 Added DerefMut and AsMut<[u8]> for `IVec` where it\n  works similarly to a `Cow`, making a private copy\n  if the backing `Arc`'s strong count is not 1.\n* #1020 The sled wiki has been moved into the documentation\n  itself, and is accessible through the `doc` module\n  exported in lib.\n\n## Breaking Changes\n\n* #975 Changed the default `segment_size` from 8m to 512k.\n  This will result in far smaller database files due\n  to better file garbage collection granularity.\n* #975 deprecated several `Config` options that will be\n  removed over time.\n* #1000 rearranged some transaction-related imports, and\n  moved them to the `transaction` module away from\n  the library root to keep the top level docs clean.\n* #1015 `TransactionalTree::apply_batch` now accepts\n  its argument by reference instead of by value.\n* `Event` has been changed to make the inner fields\n  named instead of anonymous.\n* #1057 read-only mode has been removed due to not having\n  the resources to properly keep it tested while\n  making progress on high priority issues. This may\n  be correctly implemented in the future if resources\n  permit.\n* The conversion between `Box<[u8]>` and `IVec` has\n  been temporarily removed. This is re-added in 0.32.1.\n\n# 0.31\n\n## Improvements\n\n* #947 dramatic read and recovery optimizations\n* #921 reduced the reliance on locks while\n  performing multithreaded IO on windows.\n* #928 use `sync_file_range` on linux instead\n  of a full fsync for most writes.\n* #946 io_uring support changed to the `rio` crate\n* #939 reduced memory consumption during\n  zstd decompression\n\n## Breaking Changes\n\n* #927 use SQLite-style varints for serializing\n  `u64`. This dramatically reduces the written\n  bytes for databases that store small keys and\n  values.\n* #943 use varints for most of the fields in\n  message headers, causing an additional large\n  space reduction. combined with #927, these\n  changes reduce bytes written by 68% for workloads\n  writing small items.\n\n# 0.30.3\n\n* Documentation-only release\n\n# 0.30.2\n\n## New Features\n\n* Added the `open` function for quickly\n  opening a database at a path with default\n  configuration.\n\n# 0.30.1\n\n## Bugfixes\n\n* Fixed an issue where an idle threadpool worker\n  would spin in a hot loop until work arrived\n\n# 0.30\n\n## Breaking Changes\n\n* Migrated to a new storage format\n\n## Bugfixes\n\n* Fixed a bug where cache was not being evicted.\n* Fixed a bug with using transactions with\n  compression.\n\n# 0.29.2\n\n## New Features\n\n* The `create_new` option has been added\n  to `Config`, allowing the user to specify\n  that a database should only be freshly\n  created, rather than re-opened.\n\n# 0.29.1\n\n## Bugfixes\n\n* Fixed a bug where prefix encoding could be\n  incorrectly handled when merging nodes together.\n\n# 0.29\n\n## New Features\n\n* The `Config::open` method has been added to give\n  `Config` a similar feel to std's `fs::OpenOptions`.\n  The `Config::build` and `Db::start` methods are\n  now deprecated in favor of calling `Config::open`\n  directly.\n* A `checksum` method has been added to Tree and Db\n  for use in verifying backups and migrations.\n* Transactions may now involve up to 69 different\n  tables. Nice.\n* The `TransactionError::Abort` variant has had\n  a generic member added that can be returned\n  as a way to return information from a\n  manually-aborted transaction. An `abort` helper\n  function has been added to reduce the boiler-\n  plate required to return aborted results.\n\n## Breaking Changes\n\n* The `ConfigBuilder` structure has been removed\n  in favor of a simplified `Config` structure\n  with the same functionality.\n* The way that sled versions are detected at\n  initialization time is now independent of serde.\n* The `cas` method is deprecated in favor of the new\n  `compare_and_swap` method which now returns the\n  proposed value that failed to be applied.\n* Tree nodes now have constant prefix encoding\n  lengths.\n* The `io_buf_size` configurable renamed to\n  `segment_size`.\n* The `io_buf_size` configurable method has been\n  removed from ConfigBuilder. This can be manually\n  set by setting the attribute directly on the\n  ConfigBuilder, but this is discouraged.\n  Additionally, this must now be a power of 2.\n* The `page_consolidation_threshold` method has been\n  removed from ConfigBuilder, and this is now\n  a constant of 10.\n\n# 0.28\n\n## Breaking Changes\n\n* `Iter` no longer has a lifetime parameter.\n* `Db::open_tree` now returns a `Tree` instead of\n  an `Arc<Tree>`. `Tree` now has an inner type that\n  uses an `Arc`, so you don't need to think about it.\n\n## Bug Fixes\n\n* A bug with prefix encoding has been fixed that\n  led to nodes with keys longer than 256 bytes\n  being stored incorrectly, which led to them\n  being inaccessible and also leading to infinite\n  loops during iteration.\n* Several cases of incorrect unsafe code were removed\n  from the sled crate. No bugs are known to have been\n  encountered, but they may have resulted in\n  incorrect optimizations in future refactors.\n\n# 0.27\n\n## Breaking Changes\n\n* `Event::Set` has been renamed to `Event::Insert` and\n  `Event::Del` has been renamed to `Event::Remove`. These\n  names better align with the methods of BTreeMap from\n  the standard library.\n\n## Bug Fixes\n\n* A deadlock was possible in very high write volume\n  situations when the segment accountant lock was\n  taken by all IO threads while a task was blocked\n  trying to submit a file truncation request to the\n  threadpool while holding the segment accountant lock.\n\n## New Features\n\n* `flush_async` has been added to perform time-intensive\n  flushing in an asynchronous manner, returning a Future.\n\n# 0.26.1\n\n## Improvements\n\n* std::thread is no longer used on platforms other than\n  linux, macos, and windows, which increases portability.\n\n# 0.26\n\n## New Features\n\n* Transactions! You may now call `Tree::transaction` and\n  perform reads, writes, and deletes within a provided\n  closure with a `TransactionalTree` argument. This\n  closure may be called multiple times if the transaction\n  encounters a concurrent update in the process of its\n  execution. Transactions may also be used on tuples of\n  `Tree` objects, where the closure will then be\n  parameterized on `TransactionalTree` instances providing\n  access to each of the provided `Tree` instances. This\n  allows you to atomically read and modify multiple\n  `Tree` instances in a single atomic operation.\n  These transactions are serializable, fully ACID,\n  and optimistic.\n* `Tree::apply_batch` allows you to apply a `Batch`\n* `TransactionalTree::apply_batch` allow you to\n  apply a `Batch` from within a transaction.\n\n## Breaking Changes\n\n* `Tree::batch` has been removed. Now you can directly\n  create a `Batch` with `Batch::default()` and then apply\n  it to a `Tree` with `Tree::apply_batch` or during a\n  transaction using `TransactionalTree::apply_batch`.\n  This facilitates multi-`Tree` batches via transactions.\n* `Event::Merge` has been removed, and `Tree::merge` will\n  now send a complete `Event::Set` item to be distributed\n  to all listening subscribers.\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 2.232421875,
          "content": "# Welcome to the Project :)\n\n* Don't be a jerk - here's our [code of conduct](./code-of-conduct.md).\n  We have a track record of defending our community from harm.\n\nThere are at least three great ways to contribute to sled:\n\n* [financial contribution](https://github.com/sponsors/spacejam)\n* coding\n* conversation\n\n#### Coding Considerations:\n\nPlease don't waste your time or ours by implementing things that\nwe do not want to introduce and maintain. Please discuss in an\nissue or on chat before submitting a PR with:\n\n* public API changes\n* new functionality of any sort\n* additional unsafe code\n* significant refactoring\n\nThe above changes are unlikely to be merged or receive\ntimely attention without prior discussion.\n\nPRs that generally require less coordination beforehand:\n\n* Anything addressing a correctness issue.\n* Better docs: whatever you find confusing!\n* Small code changes with big performance implications, substantiated with [responsibly-gathered metrics](https://sled.rs/perf#experiment-checklist).\n* FFI submodule changes: these are generally less well maintained than the Rust core, and benefit more from public assistance.\n* Generally any new kind of test that avoids biases inherent in the others.\n\n#### All PRs block on failing tests!\n\nsled has intense testing, including crash tests, multi-threaded tests with\ndelay injection, a variety of mechanically-generated tests that combine fault\ninjection with concurrency in interesting ways, cross-compilation and minimum\nsupported Rust version checks, LLVM sanitizers, and more. It can sometimes be\nchallenging to understand why something is failing these intense tests.\n\nFor better understanding test failures, please:\n\n1. read the failing test name and output log for clues\n1. try to reproduce the failed test locally by running its associated command from the [test script](https://github.com/spacejam/sled/blob/main/.github/workflows/test.yml)\n1. If it is not clear why your test is failing, feel free to request help with understanding it either on discord or requesting help on the PR, and we will do our best to help.\n\nWant to help sled but don't have time for individual contributions? Contribute via [GitHub Sponsors](https://github.com/sponsors/spacejam) to support the people pushing the project forward!\n"
        },
        {
          "name": "Cargo.toml",
          "type": "blob",
          "size": 1.783203125,
          "content": "[package]\nname = \"sled\"\nversion = \"0.34.7\"\nauthors = [\"Tyler Neely <t@jujit.su>\"]\ndescription = \"Lightweight high-performance pure-rust transactional embedded database.\"\nlicense = \"MIT OR Apache-2.0\"\nhomepage = \"https://github.com/spacejam/sled\"\nrepository = \"https://github.com/spacejam/sled\"\nkeywords = [\"redis\", \"mongo\", \"sqlite\", \"lmdb\", \"rocksdb\"]\ncategories = [\"database-implementations\", \"concurrency\", \"data-structures\", \"algorithms\", \"caching\"]\ndocumentation = \"https://docs.rs/sled/\"\nreadme = \"README.md\"\nedition = \"2018\"\nexclude = [\"benchmarks\", \"examples\", \"bindings\", \"scripts\", \"experiments\"]\n\n[package.metadata.docs.rs]\nfeatures = [\"docs\", \"metrics\"]\n\n[badges]\nmaintenance = { status = \"actively-developed\" }\n\n[profile.release]\ndebug = true\nopt-level = 3\noverflow-checks = true\n\n[features]\ndefault = []\nfor-internal-testing-only = [\"event_log\", \"lock_free_delays\", \"light_testing\"]\nlight_testing = [\"failpoints\", \"backtrace\", \"memshred\"]\nlock_free_delays = []\nfailpoints = []\nevent_log = []\nmetrics = [\"num-format\"]\nno_logs = [\"log/max_level_off\"]\nno_inline = []\npretty_backtrace = [\"color-backtrace\"]\ndocs = []\nno_zstd = []\nmiri_optimizations = []\nmutex = []\nmemshred = []\n\n[dependencies]\nlibc = \"0.2.96\"\ncrc32fast = \"1.2.1\"\nlog = \"0.4.14\"\nparking_lot = \"0.12.1\"\ncolor-backtrace = { version = \"0.5.1\", optional = true }\nnum-format = { version = \"0.4.0\", optional = true }\nbacktrace = { version = \"0.3.60\", optional = true }\nim = \"15.1.0\"\n\n[target.'cfg(any(target_os = \"linux\", target_os = \"macos\", target_os=\"windows\"))'.dependencies]\nfs2 = \"0.4.3\"\n\n[dev-dependencies]\nrand = \"0.7\"\nrand_chacha = \"0.3.1\"\nrand_distr = \"0.3\"\nquickcheck = \"0.9\"\nlog = \"0.4.14\"\nenv_logger = \"0.9.0\"\nzerocopy = \"0.6.0\"\nbyteorder = \"1.4.3\"\n\n[[test]]\nname = \"test_crash_recovery\"\npath = \"tests/test_crash_recovery.rs\"\nharness = false\n"
        },
        {
          "name": "LICENSE-APACHE",
          "type": "blob",
          "size": 11.2802734375,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"{}\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2015 Tyler Neely\n   Copyright 2016 Tyler Neely\n   Copyright 2017 Tyler Neely\n   Copyright 2018 Tyler Neely\n   Copyright 2019 Tyler Neely\n   Copyright 2020 Tyler Neely\n   Copyright 2021 Tyler Neely\n   Copyright 2022 Tyler Neely\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "LICENSE-MIT",
          "type": "blob",
          "size": 1.1513671875,
          "content": "Copyright (c) 2018 Tyler Neely\nCopyright (c) 2019 Tyler Neely\nCopyright (c) 2020 Tyler Neely\nCopyright (c) 2021 Tyler Neely\nCopyright (c) 2022 Tyler Neely\n\nPermission is hereby granted, free of charge, to any\nperson obtaining a copy of this software and associated\ndocumentation files (the \"Software\"), to deal in the\nSoftware without restriction, including without\nlimitation the rights to use, copy, modify, merge,\npublish, distribute, sublicense, and/or sell copies of\nthe Software, and to permit persons to whom the Software\nis furnished to do so, subject to the following\nconditions:\n\nThe above copyright notice and this permission notice\nshall be included in all copies or substantial portions\nof the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\nANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\nTO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\nPARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT\nSHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\nCLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR\nIN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\nDEALINGS IN THE SOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 9.5,
          "content": "\n<table style=\"width:100%\">\n<tr>\n  <td>\n    <table style=\"width:100%\">\n      <tr>\n        <td> key </td>\n        <td> value </td>\n      </tr>\n      <tr>\n        <td><a href=\"https://github.com/sponsors/spacejam\">buy a coffee for us to convert into databases</a></td>\n        <td><a href=\"https://github.com/sponsors/spacejam\"><img src=\"https://img.shields.io/github/sponsors/spacejam\"></a></td>\n      </tr>\n      <tr>\n        <td><a href=\"https://docs.rs/sled\">documentation</a></td>\n        <td><a href=\"https://docs.rs/sled\"><img src=\"https://docs.rs/sled/badge.svg\"></a></td>\n      </tr>\n      <tr>\n        <td><a href=\"https://discord.gg/Z6VsXds\">chat about databases with us</a></td>\n        <td><a href=\"https://discord.gg/Z6VsXds\"><img src=\"https://img.shields.io/discord/509773073294295082.svg?logo=discord\"></a></td>\n      </tr>\n     </table>\n  </td>\n  <td>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/spacejam/sled/main/art/tree_face_anti-transphobia.png\" width=\"40%\" height=\"auto\" />\n  </p>\n  </td>\n </tr>\n</table>\n\n\n# sled - ~~it's all downhill from here!!!~~\n\nAn embedded database.\n\n```rust\nlet tree = sled::open(\"/tmp/welcome-to-sled\")?;\n\n// insert and get, similar to std's BTreeMap\nlet old_value = tree.insert(\"key\", \"value\")?;\n\nassert_eq!(\n  tree.get(&\"key\")?,\n  Some(sled::IVec::from(\"value\")),\n);\n\n// range queries\nfor kv_result in tree.range(\"key_1\"..\"key_9\") {}\n\n// deletion\nlet old_value = tree.remove(&\"key\")?;\n\n// atomic compare and swap\ntree.compare_and_swap(\n  \"key\",\n  Some(\"current_value\"),\n  Some(\"new_value\"),\n)?;\n\n// block until all operations are stable on disk\n// (flush_async also available to get a Future)\ntree.flush()?;\n```\n\nIf you would like to work with structured data without paying expensive deserialization costs, check out the [structured](examples/structured.rs) example!\n\n# features\n\n* [API](https://docs.rs/sled) similar to a threadsafe `BTreeMap<[u8], [u8]>`\n* serializable (ACID) [transactions](https://docs.rs/sled/latest/sled/struct.Tree.html#method.transaction)\n  for atomically reading and writing to multiple keys in multiple keyspaces.\n* fully atomic single-key operations, including [compare and swap](https://docs.rs/sled/latest/sled/struct.Tree.html#method.compare_and_swap)\n* zero-copy reads\n* [write batches](https://docs.rs/sled/latest/sled/struct.Tree.html#method.apply_batch)\n* [subscribe to changes on key\n  prefixes](https://docs.rs/sled/latest/sled/struct.Tree.html#method.watch_prefix)\n* [multiple keyspaces](https://docs.rs/sled/latest/sled/struct.Db.html#method.open_tree)\n* [merge operators](https://docs.rs/sled/latest/sled/doc/merge_operators/index.html)\n* forward and reverse iterators over ranges of items\n* a crash-safe monotonic [ID generator](https://docs.rs/sled/latest/sled/struct.Db.html#method.generate_id)\n  capable of generating 75-125 million unique ID's per second\n* [zstd](https://github.com/facebook/zstd) compression (use the\n  `compression` build feature, disabled by default)\n* cpu-scalable lock-free implementation\n* flash-optimized log-structured storage\n* uses modern b-tree techniques such as prefix encoding and suffix\n  truncation for reducing the storage costs of long keys with shared\n  prefixes. If keys are the same length and sequential then the\n  system can avoid storing 99%+ of the key data in most cases,\n  essentially acting like a learned index\n\n# expectations, gotchas, advice\n\n* Maybe one of the first things that seems weird is the `IVec` type.\n  This is an inlinable `Arc`ed slice that makes some things more efficient.\n* Durability: **sled automatically fsyncs every 500ms by default**,\n  which can be configured with the `flush_every_ms` configurable, or you may\n  call `flush` / `flush_async` manually after operations.\n* **Transactions are optimistic** - do not interact with external state\n  or perform IO from within a transaction closure unless it is\n  [idempotent](https://en.wikipedia.org/wiki/Idempotent).\n* Internal tree node optimizations: sled performs prefix encoding\n  on long keys with similar prefixes that are grouped together in a range,\n  as well as suffix truncation to further reduce the indexing costs of\n  long keys. Nodes will skip potentially expensive length and offset pointers\n  if keys or values are all the same length (tracked separately, don't worry\n  about making keys the same length as values), so it may improve space usage\n  slightly if you use fixed-length keys or values. This also makes it easier\n  to use [structured access](examples/structured.rs) as well.\n* sled does not support multiple open instances for the time being. Please\n  keep sled open for the duration of your process's lifespan. It's totally\n  safe and often quite convenient to use a global lazy_static sled instance,\n  modulo the normal global variable trade-offs. Every operation is threadsafe,\n  and most are implemented under the hood with lock-free algorithms that avoid\n  blocking in hot paths.\n\n# performance\n\n* [LSM tree](https://en.wikipedia.org/wiki/Log-structured_merge-tree)-like write performance\n  with [traditional B+ tree](https://en.wikipedia.org/wiki/B%2B_tree)-like read performance\n* over a billion operations in under a minute at 95% read 5% writes on 16 cores on a small dataset\n* measure your own workloads rather than relying on some marketing for contrived workloads\n\n# a note on lexicographic ordering and endianness\n\nIf you want to store numerical keys in a way that will play nicely with sled's iterators and ordered operations, please remember to store your numerical items in big-endian form. Little endian (the default of many things) will often appear to be doing the right thing until you start working with more than 256 items (more than 1 byte), causing lexicographic ordering of the serialized bytes to diverge from the lexicographic ordering of their deserialized numerical form.\n\n* Rust integral types have built-in `to_be_bytes` and `from_be_bytes` [methods](https://doc.rust-lang.org/std/primitive.u64.html#method.from_be_bytes).\n* bincode [can be configured](https://docs.rs/bincode/1.2.0/bincode/struct.Config.html#method.big_endian) to store integral types in big-endian form.\n\n# interaction with async\n\nIf your dataset resides entirely in cache (achievable at startup by setting the cache\nto a large enough value and performing a full iteration) then all reads and writes are\nnon-blocking and async-friendly, without needing to use Futures or an async runtime.\n\nTo asynchronously suspend your async task on the durability of writes, we support the\n[`flush_async` method](https://docs.rs/sled/latest/sled/struct.Tree.html#method.flush_async),\nwhich returns a Future that your async tasks can await the completion of if they require\nhigh durability guarantees and you are willing to pay the latency costs of fsync.\nNote that sled automatically tries to sync all data to disk several times per second\nin the background without blocking user threads.\n\nWe support async subscription to events that happen on key prefixes, because the\n`Subscriber` struct implements `Future<Output=Option<Event>>`:\n\n```rust\nlet sled = sled::open(\"my_db\").unwrap();\n\nlet mut sub = sled.watch_prefix(\"\");\n\nsled.insert(b\"a\", b\"a\").unwrap();\n\nextreme::run(async move {\n    while let Some(event) = (&mut sub).await {\n        println!(\"got event {:?}\", event);\n    }\n});\n```\n\n# minimum supported Rust version (MSRV)\n\nWe support Rust 1.62 and up.\n\n# architecture\n\nlock-free tree on a lock-free pagecache on a lock-free log. the pagecache scatters\npartial page fragments across the log, rather than rewriting entire pages at a time\nas B+ trees for spinning disks historically have. on page reads, we concurrently\nscatter-gather reads across the log to materialize the page from its fragments.\ncheck out the [architectural outlook](https://github.com/spacejam/sled/wiki/sled-architectural-outlook)\nfor a more detailed overview of where we're at and where we see things going!\n\n# philosophy\n\n1. don't make the user think. the interface should be obvious.\n1. don't surprise users with performance traps.\n1. don't wake up operators. bring reliability techniques from academia into real-world practice.\n1. don't use so much electricity. our data structures should play to modern hardware's strengths.\n\n# known issues, warnings\n\n* if reliability is your primary constraint, use SQLite. sled is beta.\n* if storage price performance is your primary constraint, use RocksDB. sled uses too much space sometimes.\n* if you have a multi-process workload that rarely writes, use LMDB. sled is architected for use with long-running, highly-concurrent workloads such as stateful services or higher-level databases.\n* quite young, should be considered unstable for the time being.\n* the on-disk format is going to change in ways that require [manual migrations](https://docs.rs/sled/latest/sled/struct.Db.html#method.export) before the `1.0.0` release!\n\n# priorities\n\n1. A full rewrite of sled's storage subsystem is happening on a modular basis as part of the [komora project](https://github.com/komora-io), in particular the marble storage engine. This will dramatically lower both the disk space usage (space amplification) and garbage collection overhead (write amplification) of sled.\n2. The memory layout of tree nodes is being completely rewritten to reduce fragmentation and eliminate serialization costs.\n3. The merge operator feature will change into a trigger feature that resembles traditional database triggers, allowing state to be modified as part of the same atomic writebatch that triggered it for retaining serializability with reactive semantics.\n\n# fund feature development\n\nLike what we're doing? Help us out via [GitHub Sponsors](https://github.com/sponsors/spacejam)!\n"
        },
        {
          "name": "RELEASE_CHECKLIST.md",
          "type": "blob",
          "size": 1.318359375,
          "content": "# Release Checklist\n\nThis checklist must be completed before publishing a release of any kind.\n\nOver time, anything in this list that can be turned into an automated test should be, but\nthere are still some big blind spots.\n\n## API stability\n\n- [ ] rust-flavored semver respected\n\n## Performance\n\n- [ ] micro-benchmark regressions should not happen unless newly discovered correctness criteria demands them\n- [ ] mixed point operation latency distribution should narrow over time\n- [ ] sequential operation average throughput should increase over time\n- [ ] workloads should pass TSAN and ASAN on macOS. Linux should additionally pass LSAN & MSAN.\n- [ ] workload write and space amplification thresholds should see no regressions\n\n## Concurrency Audit\n\n- [ ] any new `Guard` objects are dropped inside the rayon threadpool\n- [ ] no new EBR `Collector`s, as they destroy causality. These will be optimized in-bulk in the future.\n- [ ] no code assumes a recently read page pointer will remain unchanged (transactions may change this if reads are inline)\n- [ ] no calls to `rand::thread_rng` from a droppable function (anything in the SegmentAccountant)\n\n## Burn-In\n\n- [ ] fuzz tests should run at least 24 hours each with zero crashes\n- [ ] sequential and point workloads run at least 24 hours in constrained docker container without OOM / out of disk\n"
        },
        {
          "name": "SAFETY.md",
          "type": "blob",
          "size": 2.9912109375,
          "content": "# sled safety model\n\nThis document applies\n[STPA](http://psas.scripts.mit.edu/home/get_file.php?name=STPA_handbook.pdf)-style\nhazard analysis to the sled embedded database for the purpose of guiding\ndesign and testing efforts to prevent unacceptable losses.\n\nOutline\n\n* [purpose of analysis](#purpose-of-analysis)\n  * [losses](#losses)\n  * [system boundary](#system-boundary)\n  * [hazards](#hazards)\n  * [leading indicators](#leading-indicators)\n  * [constraints](#constraints)\n* [model of control structure](#model-of-control-structure)\n* [identify unsafe control actions](#identify-unsafe-control-actions)\n* [identify loss scenarios][#identify-loss-scenarios)\n* [resources for learning more about STAMP, STPA, and CAST](#resources)\n\n# Purpose of Analysis\n\n## Losses\n\nWe wish to prevent the following undesirable situations:\n\n* data loss\n* inconsistent (non-linearizable) data access\n* process crash\n* resource exhaustion\n\n## System Boundary\n\nWe draw the line between system and environment where we can reasonably\ninvest our efforts to prevent losses.\n\nInside the boundary:\n\n* codebase\n  * put safe control actions into place that prevent losses\n* documentation\n  * show users how to use sled safely\n  * recommend hardware, kernels, user code\n\nOutside the boundary:\n\n* Direct changes to hardware, kernels, user code\n\n## Hazards\n\nThese hazards can result in the above losses:\n\n* data may be lost if\n  * bugs in the logging system\n    * `Db::flush` fails to make previous writes durable\n  * bugs in the GC system\n    * the old location is overwritten before the defragmented location becomes durable\n  * bugs in the recovery system\n  * hardware failures\n* consistency violations may be caused by\n  * transaction concurrency control failure to enforce linearizability (strict serializability)\n  * non-linearizable lock-free single-key operations\n* panic\n  * of user threads\n  * IO threads\n  * flusher & GC thread\n  * indexing\n  * unwraps/expects\n  * failed TryInto/TryFrom + unwrap\n* persistent storage exceeding (2 + N concurrent writers) * logical data size\n* in-memory cache exceeding the configured cache size\n  * caused by incorrect calculation of cache\n* use-after-free\n* data race\n* memory leak\n* integer overflow\n* buffer overrun\n* uninitialized memory access\n\n## Constraints\n\n# Models of Control Structures\n\nfor each control action we have, consider:\n\n1. what hazards happen when we fail to apply it / it does not exist?\n2. what hazards happen when we do apply it\n3. what hazards happen when we apply it too early or too late?\n4. what hazards happen if we apply it for too long or not long enough?\n\ndurability model\n\n  * recovery\n    * LogIter::max_lsn\n      * return None if last_lsn_in_batch >= self.max_lsn\n    * batch requirement set to last reservation base + inline len - 1\n      * reserve bumps\n        * bump_atomic_lsn(&self.iobufs.max_reserved_lsn, reservation_lsn + inline_buf_len as Lsn - 1);\n\nlock-free linearizability model\n\ntransactional linearizability (strict serializability) model\n\npanic model\n\nmemory usage model\n\nstorage usage model\n\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.7939453125,
          "content": "# Security Policy\n\n## Reporting a Vulnerability\n\nsled uses some unsafe functionality in the core lock-free algorithms, and in a few places to more efficiently copy data.\n\nPlease contact [Tyler Neely](mailto:tylerneely@gmail.com?subject=sled%20security%20issue) immediately if you find any vulnerability, and I will work with you to fix the issue rapidly and coordinate public disclosure with an expedited release including the fix.\n\nIf you are a bug hunter or a person with a security interest, here is my mental model of memory corruption risk in the sled codebase:\n\n1. memory issues relating to the lock-free data structures in their colder failure paths. these have been tested a bit by injecting delays into random places, but this is still an area with elevated risk\n1. anywhere the `unsafe` keyword is used\n"
        },
        {
          "name": "art",
          "type": "tree",
          "content": null
        },
        {
          "name": "benchmarks",
          "type": "tree",
          "content": null
        },
        {
          "name": "bindings",
          "type": "tree",
          "content": null
        },
        {
          "name": "code-of-conduct.md",
          "type": "blob",
          "size": 3.173828125,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to making participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, sex characteristics, gender identity and expression,\nlevel of experience, education, socio-economic status, nationality, personal\nappearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\n  advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\n  address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies both within project spaces and in public spaces\nwhen an individual is representing the project or its community. Examples of\nrepresenting a project or community include using an official project e-mail\naddress, posting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event. Representation of a project may be\nfurther defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the project team at tylerneely@gmail.com. All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\n[homepage]: https://www.contributor-covenant.org\n\n"
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "experiments",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "tsan_suppressions.txt",
          "type": "blob",
          "size": 0.8349609375,
          "content": "# This suppressions file should really only be used for things\n# that TSAN can not correctly reason about, like raw memory\n# fences or implicit equivalents created by performing atomic\n# operations on variables.\n\n# Read more about how to use this file at:\n# https://github.com/google/sanitizers/wiki/ThreadSanitizerSuppressions\n\n# We ignore this because collect() calls functionality that relies\n# on atomic::fence for correctness, which doesn't get picked up by TSAN\n# as of Feb 1 2018 / rust 1.23.\nrace:sled::ebr::internal::Global::collect\n\n# Arc::drop is not properly detected by TSAN due to the use\n# of a raw atomic Acquire fence after the strong-count\n# atomic subtraction with a Release fence in the Drop impl.\nrace:Arc*drop\n\n# lazy_static and thread_local rely on implicit barriers not\n# picked-up by TSAN\nrace:lazy_static\nrace:std::thread::local\n"
        }
      ]
    }
  ]
}