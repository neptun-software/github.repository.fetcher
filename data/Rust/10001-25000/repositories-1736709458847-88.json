{
  "metadata": {
    "timestamp": 1736709458847,
    "page": 88,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjkw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "rayon-rs/rayon",
      "stars": 11320,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.03515625,
          "content": "Cargo.lock\ntarget\n*~\nTAGS\n*.bk\n.idea"
        },
        {
          "name": "Cargo.toml",
          "type": "blob",
          "size": 1.0947265625,
          "content": "[package]\nname = \"rayon\"\nversion = \"1.10.0\"\nauthors = [\"Niko Matsakis <niko@alum.mit.edu>\",\n           \"Josh Stone <cuviper@gmail.com>\"]\ndescription = \"Simple work-stealing parallelism for Rust\"\nrust-version = \"1.63\"\nedition = \"2021\"\nlicense = \"MIT OR Apache-2.0\"\nrepository = \"https://github.com/rayon-rs/rayon\"\ndocumentation = \"https://docs.rs/rayon/\"\nreadme = \"README.md\"\nkeywords = [\"parallel\", \"thread\", \"concurrency\", \"join\", \"performance\"]\ncategories = [\"concurrency\"]\nexclude = [\"/ci/*\", \"/scripts/*\", \"/.github/*\"]\n\n[workspace]\nmembers = [\"rayon-demo\", \"rayon-core\"]\nexclude = [\"ci\"]\n\n[dependencies]\nrayon-core = { version = \"1.12.1\", path = \"rayon-core\" }\nwasm_sync = { version = \"0.1.0\", optional = true }\n\n# This is a public dependency!\n[dependencies.either]\nversion = \"1.0\"\ndefault-features = false\n\n[features]\n# This feature switches to a spin-lock implementation on the browser's\n# main thread to avoid the forbidden `atomics.wait`.\n#\n# Only useful on the `wasm32-unknown-unknown` target.\nweb_spin_lock = [\"dep:wasm_sync\", \"rayon-core/web_spin_lock\"]\n\n[dev-dependencies]\nrand = \"0.8\"\nrand_xorshift = \"0.3\"\n"
        },
        {
          "name": "FAQ.md",
          "type": "blob",
          "size": 9.0302734375,
          "content": "# Rayon FAQ\n\nThis file is for general questions that don't fit into the README or crate docs.\n\n## How many threads will Rayon spawn?\n\nBy default, Rayon uses the same number of threads as the number of CPUs\navailable. Note that on systems with hyperthreading enabled this equals the\nnumber of logical cores and not the physical ones.\n\nIf you want to alter the number of threads spawned, you can set the\nenvironmental variable `RAYON_NUM_THREADS` to the desired number of threads or\nuse the\n[`ThreadPoolBuilder::build_global` function](https://docs.rs/rayon/*/rayon/struct.ThreadPoolBuilder.html#method.build_global)\nmethod.\n\n## How does Rayon balance work between threads?\n\nBehind the scenes, Rayon uses a technique called **work stealing** to try and\ndynamically ascertain how much parallelism is available and exploit it. The idea\nis very simple: we always have a pool of worker threads available, waiting for\nsome work to do. When you call `join` the first time, we shift over into that\npool of threads. But if you call `join(a, b)` from a worker thread W, then W\nwill place `b` into its work queue, advertising that this is work that other\nworker threads might help out with. W will then start executing `a`.\n\nWhile W is busy with `a`, other threads might come along and take `b` from its\nqueue. That is called *stealing* `b`. Once `a` is done, W checks whether `b` was\nstolen by another thread and, if not, executes `b` itself. If W runs out of jobs\nin its own queue, it will look through the other threads' queues and try to\nsteal work from them.\n\nThis technique is not new. It was first introduced by the [Cilk project][cilk],\ndone at MIT in the late nineties. The name Rayon is an homage to that work.\n\n[cilk]: http://supertech.csail.mit.edu/cilk/\n\n## What should I do if I use `Rc`, `Cell`, `RefCell` or other non-Send-and-Sync types?\n\nThere are a number of non-threadsafe types in the Rust standard library, and if\nyour code is using them, you will not be able to combine it with Rayon.\nSimilarly, even if you don't have such types, but you try to have multiple\nclosures mutating the same state, you will get compilation errors; for example,\nthis function won't work, because both closures access `slice`:\n\n```rust\n/// Increment all values in slice.\nfn increment_all(slice: &mut [i32]) {\n    rayon::join(|| process(slice), || process(slice));\n}\n```\n\nThe correct way to resolve such errors will depend on the case. Some cases are\neasy: for example, uses of [`Rc`] can typically be replaced with [`Arc`], which\nis basically equivalent, but thread-safe.\n\nCode that uses `Cell` or `RefCell`, however, can be somewhat more complicated.\nIf you can refactor your code to avoid those types, that is often the best way\nforward, but otherwise, you can try to replace those types with their threadsafe\nequivalents:\n\n- `Cell` -- replacement: `AtomicUsize`, `AtomicBool`, etc\n- `RefCell` -- replacement: `RwLock`, or perhaps `Mutex`\n\nHowever, you have to be wary! The parallel versions of these types have\ndifferent atomicity guarantees. For example, with a `Cell`, you can increment a\ncounter like so:\n\n```rust\nlet value = counter.get();\ncounter.set(value + 1);\n```\n\nBut when you use the equivalent `AtomicUsize` methods, you are actually\nintroducing a potential race condition (not a data race, technically, but it can\nbe an awfully fine distinction):\n\n```rust\nlet value = tscounter.load(Ordering::SeqCst);\ntscounter.store(value + 1, Ordering::SeqCst);\n```\n\nYou can already see that the `AtomicUsize` API is a bit more complex, as it\nrequires you to specify an\n[ordering](https://doc.rust-lang.org/std/sync/atomic/enum.Ordering.html). (I\nwon't go into the details on ordering here, but suffice to say that if you don't\nknow what an ordering is, and probably even if you do, you should use\n`Ordering::SeqCst`.) The danger in this parallel version of the counter is that\nother threads might be running at the same time and they could cause our counter\nto get out of sync. For example, if we have two threads, then they might both\nexecute the \"load\" before either has a chance to execute the \"store\":\n\n```\nThread 1                                          Thread 2\nlet value = tscounter.load(Ordering::SeqCst);\n// value = X                                      let value = tscounter.load(Ordering::SeqCst);\n                                                  // value = X\ntscounter.store(value+1);                         tscounter.store(value+1);\n// tscounter = X+1                                // tscounter = X+1\n```\n\nNow even though we've had two increments, we'll only increase the counter by\none! Even though we've got no data race, this is still probably not the result\nwe wanted. The problem here is that the `Cell` API doesn't make clear the scope\nof a \"transaction\" -- that is, the set of reads/writes that should occur\natomically. In this case, we probably wanted the get/set to occur together.\n\nIn fact, when using the `Atomic` types, you very rarely want a plain `load` or\nplain `store`. You probably want the more complex operations. A counter, for\nexample, would use `fetch_add` to atomically load and increment the value in one\nstep. Compare-and-swap is another popular building block.\n\nA similar problem can arise when converting `RefCell` to `RwLock`, but it is\nsomewhat less likely, because the `RefCell` API does in fact have a notion of a\ntransaction: the scope of the handle returned by `borrow` or `borrow_mut`. So if\nyou convert each call to `borrow` to `read` (and `borrow_mut` to `write`),\nthings will mostly work fine in a parallel setting, but there can still be\nchanges in behavior. Consider using a `handle: RefCell<Vec<i32>>` like:\n\n```rust\nlet len = handle.borrow().len();\nfor i in 0 .. len {\n    let data = handle.borrow()[i];\n    println!(\"{}\", data);\n}\n```\n\nIn sequential code, we know that this loop is safe. But if we convert this to\nparallel code with an `RwLock`, we do not: this is because another thread could\ncome along and do `handle.write().unwrap().pop()`, and thus change the length of\nthe vector. In fact, even in *sequential* code, using very small borrow sections\nlike this is an anti-pattern: you ought to be enclosing the entire transaction\ntogether, like so:\n\n```rust\nlet vec = handle.borrow();\nlet len = vec.len();\nfor i in 0 .. len {\n    let data = vec[i];\n    println!(\"{}\", data);\n}\n```\n\nOr, even better, using an iterator instead of indexing:\n\n```rust\nlet vec = handle.borrow();\nfor data in vec {\n    println!(\"{}\", data);\n}\n```\n\nThere are several reasons to prefer one borrow over many. The most obvious is\nthat it is more efficient, since each borrow has to perform some safety checks.\nBut it's also more reliable: suppose we modified the loop above to not just\nprint things out, but also call into a helper function:\n\n```rust\nlet vec = handle.borrow();\nfor data in vec {\n    helper(...);\n}\n```\n\nAnd now suppose, independently, this helper fn evolved and had to pop something\noff of the vector:\n\n```rust\nfn helper(...) {\n    handle.borrow_mut().pop();\n}\n```\n\nUnder the old model, where we did lots of small borrows, this would yield\nprecisely the same error that we saw in parallel land using an `RwLock`: the\nlength would be out of sync and our indexing would fail (note that in neither\ncase would there be an actual *data race* and hence there would never be\nundefined behavior). But now that we use a single borrow, we'll see a borrow\nerror instead, which is much easier to diagnose, since it occurs at the point of\nthe `borrow_mut`, rather than downstream. Similarly, if we move to an `RwLock`,\nwe'll find that the code either deadlocks (if the write is on the same thread as\nthe read) or, if the write is on another thread, works just fine. Both of these\nare preferable to random failures in my experience.\n\n## But wait, isn't Rust supposed to free me from this kind of thinking?\n\nYou might think that Rust is supposed to mean that you don't have to think about\natomicity at all. In fact, if you avoid interior mutability (`Cell` and\n`RefCell` in a sequential setting, or `AtomicUsize`, `RwLock`, `Mutex`, et al.\nin parallel code), then this is true: the type system will basically guarantee\nthat you don't have to think about atomicity at all. But often there are times\nwhen you WANT threads to interleave in the ways I showed above.\n\nConsider for example when you are conducting a search in parallel, say to find\nthe shortest route. To avoid fruitless search, you might want to keep a cell\nwith the shortest route you've found thus far. This way, when you are searching\ndown some path that's already longer than this shortest route, you can just stop\nand avoid wasted effort. In sequential land, you might model this \"best result\"\nas a shared value like `Rc<Cell<usize>>` (here the `usize` represents the length\nof best path found so far); in parallel land, you'd use a `Arc<AtomicUsize>`.\n\n```rust\nfn search(path: &Path, cost_so_far: usize, best_cost: &AtomicUsize) {\n    if cost_so_far >= best_cost.load(Ordering::SeqCst) {\n        return;\n    }\n    // Using `fetch_min` to avoid a race condition, in case it changed since `load`.\n    best_cost.fetch_min(..., Ordering::SeqCst);\n}\n```\n\nNow in this case, we really WANT to see results from other threads interjected\ninto our execution!\n"
        },
        {
          "name": "LICENSE-APACHE",
          "type": "blob",
          "size": 10.5927734375,
          "content": "                              Apache License\n                        Version 2.0, January 2004\n                     http://www.apache.org/licenses/\n\nTERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n1. Definitions.\n\n   \"License\" shall mean the terms and conditions for use, reproduction,\n   and distribution as defined by Sections 1 through 9 of this document.\n\n   \"Licensor\" shall mean the copyright owner or entity authorized by\n   the copyright owner that is granting the License.\n\n   \"Legal Entity\" shall mean the union of the acting entity and all\n   other entities that control, are controlled by, or are under common\n   control with that entity. For the purposes of this definition,\n   \"control\" means (i) the power, direct or indirect, to cause the\n   direction or management of such entity, whether by contract or\n   otherwise, or (ii) ownership of fifty percent (50%) or more of the\n   outstanding shares, or (iii) beneficial ownership of such entity.\n\n   \"You\" (or \"Your\") shall mean an individual or Legal Entity\n   exercising permissions granted by this License.\n\n   \"Source\" form shall mean the preferred form for making modifications,\n   including but not limited to software source code, documentation\n   source, and configuration files.\n\n   \"Object\" form shall mean any form resulting from mechanical\n   transformation or translation of a Source form, including but\n   not limited to compiled object code, generated documentation,\n   and conversions to other media types.\n\n   \"Work\" shall mean the work of authorship, whether in Source or\n   Object form, made available under the License, as indicated by a\n   copyright notice that is included in or attached to the work\n   (an example is provided in the Appendix below).\n\n   \"Derivative Works\" shall mean any work, whether in Source or Object\n   form, that is based on (or derived from) the Work and for which the\n   editorial revisions, annotations, elaborations, or other modifications\n   represent, as a whole, an original work of authorship. For the purposes\n   of this License, Derivative Works shall not include works that remain\n   separable from, or merely link (or bind by name) to the interfaces of,\n   the Work and Derivative Works thereof.\n\n   \"Contribution\" shall mean any work of authorship, including\n   the original version of the Work and any modifications or additions\n   to that Work or Derivative Works thereof, that is intentionally\n   submitted to Licensor for inclusion in the Work by the copyright owner\n   or by an individual or Legal Entity authorized to submit on behalf of\n   the copyright owner. For the purposes of this definition, \"submitted\"\n   means any form of electronic, verbal, or written communication sent\n   to the Licensor or its representatives, including but not limited to\n   communication on electronic mailing lists, source code control systems,\n   and issue tracking systems that are managed by, or on behalf of, the\n   Licensor for the purpose of discussing and improving the Work, but\n   excluding communication that is conspicuously marked or otherwise\n   designated in writing by the copyright owner as \"Not a Contribution.\"\n\n   \"Contributor\" shall mean Licensor and any individual or Legal Entity\n   on behalf of whom a Contribution has been received by Licensor and\n   subsequently incorporated within the Work.\n\n2. Grant of Copyright License. Subject to the terms and conditions of\n   this License, each Contributor hereby grants to You a perpetual,\n   worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n   copyright license to reproduce, prepare Derivative Works of,\n   publicly display, publicly perform, sublicense, and distribute the\n   Work and such Derivative Works in Source or Object form.\n\n3. Grant of Patent License. Subject to the terms and conditions of\n   this License, each Contributor hereby grants to You a perpetual,\n   worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n   (except as stated in this section) patent license to make, have made,\n   use, offer to sell, sell, import, and otherwise transfer the Work,\n   where such license applies only to those patent claims licensable\n   by such Contributor that are necessarily infringed by their\n   Contribution(s) alone or by combination of their Contribution(s)\n   with the Work to which such Contribution(s) was submitted. If You\n   institute patent litigation against any entity (including a\n   cross-claim or counterclaim in a lawsuit) alleging that the Work\n   or a Contribution incorporated within the Work constitutes direct\n   or contributory patent infringement, then any patent licenses\n   granted to You under this License for that Work shall terminate\n   as of the date such litigation is filed.\n\n4. Redistribution. You may reproduce and distribute copies of the\n   Work or Derivative Works thereof in any medium, with or without\n   modifications, and in Source or Object form, provided that You\n   meet the following conditions:\n\n   (a) You must give any other recipients of the Work or\n       Derivative Works a copy of this License; and\n\n   (b) You must cause any modified files to carry prominent notices\n       stating that You changed the files; and\n\n   (c) You must retain, in the Source form of any Derivative Works\n       that You distribute, all copyright, patent, trademark, and\n       attribution notices from the Source form of the Work,\n       excluding those notices that do not pertain to any part of\n       the Derivative Works; and\n\n   (d) If the Work includes a \"NOTICE\" text file as part of its\n       distribution, then any Derivative Works that You distribute must\n       include a readable copy of the attribution notices contained\n       within such NOTICE file, excluding those notices that do not\n       pertain to any part of the Derivative Works, in at least one\n       of the following places: within a NOTICE text file distributed\n       as part of the Derivative Works; within the Source form or\n       documentation, if provided along with the Derivative Works; or,\n       within a display generated by the Derivative Works, if and\n       wherever such third-party notices normally appear. The contents\n       of the NOTICE file are for informational purposes only and\n       do not modify the License. You may add Your own attribution\n       notices within Derivative Works that You distribute, alongside\n       or as an addendum to the NOTICE text from the Work, provided\n       that such additional attribution notices cannot be construed\n       as modifying the License.\n\n   You may add Your own copyright statement to Your modifications and\n   may provide additional or different license terms and conditions\n   for use, reproduction, or distribution of Your modifications, or\n   for any such Derivative Works as a whole, provided Your use,\n   reproduction, and distribution of the Work otherwise complies with\n   the conditions stated in this License.\n\n5. Submission of Contributions. Unless You explicitly state otherwise,\n   any Contribution intentionally submitted for inclusion in the Work\n   by You to the Licensor shall be under the terms and conditions of\n   this License, without any additional terms or conditions.\n   Notwithstanding the above, nothing herein shall supersede or modify\n   the terms of any separate license agreement you may have executed\n   with Licensor regarding such Contributions.\n\n6. Trademarks. This License does not grant permission to use the trade\n   names, trademarks, service marks, or product names of the Licensor,\n   except as required for reasonable and customary use in describing the\n   origin of the Work and reproducing the content of the NOTICE file.\n\n7. Disclaimer of Warranty. Unless required by applicable law or\n   agreed to in writing, Licensor provides the Work (and each\n   Contributor provides its Contributions) on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n   implied, including, without limitation, any warranties or conditions\n   of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n   PARTICULAR PURPOSE. You are solely responsible for determining the\n   appropriateness of using or redistributing the Work and assume any\n   risks associated with Your exercise of permissions under this License.\n\n8. Limitation of Liability. In no event and under no legal theory,\n   whether in tort (including negligence), contract, or otherwise,\n   unless required by applicable law (such as deliberate and grossly\n   negligent acts) or agreed to in writing, shall any Contributor be\n   liable to You for damages, including any direct, indirect, special,\n   incidental, or consequential damages of any character arising as a\n   result of this License or out of the use or inability to use the\n   Work (including but not limited to damages for loss of goodwill,\n   work stoppage, computer failure or malfunction, or any and all\n   other commercial damages or losses), even if such Contributor\n   has been advised of the possibility of such damages.\n\n9. Accepting Warranty or Additional Liability. While redistributing\n   the Work or Derivative Works thereof, You may choose to offer,\n   and charge a fee for, acceptance of support, warranty, indemnity,\n   or other liability obligations and/or rights consistent with this\n   License. However, in accepting such obligations, You may act only\n   on Your own behalf and on Your sole responsibility, not on behalf\n   of any other Contributor, and only if You agree to indemnify,\n   defend, and hold each Contributor harmless for any liability\n   incurred by, or claims asserted against, such Contributor by reason\n   of your accepting any such warranty or additional liability.\n\nEND OF TERMS AND CONDITIONS\n\nAPPENDIX: How to apply the Apache License to your work.\n\n   To apply the Apache License to your work, attach the following\n   boilerplate notice, with the fields enclosed by brackets \"[]\"\n   replaced with your own identifying information. (Don't include\n   the brackets!)  The text should be enclosed in the appropriate\n   comment syntax for the file format. We also recommend that a\n   file or class name and description of purpose be included on the\n   same \"printed page\" as the copyright notice for easier\n   identification within third-party archives.\n\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n"
        },
        {
          "name": "LICENSE-MIT",
          "type": "blob",
          "size": 1.0458984375,
          "content": "Copyright (c) 2010 The Rust Project Developers\n\nPermission is hereby granted, free of charge, to any\nperson obtaining a copy of this software and associated\ndocumentation files (the \"Software\"), to deal in the\nSoftware without restriction, including without\nlimitation the rights to use, copy, modify, merge,\npublish, distribute, sublicense, and/or sell copies of\nthe Software, and to permit persons to whom the Software\nis furnished to do so, subject to the following\nconditions:\n\nThe above copyright notice and this permission notice\nshall be included in all copies or substantial portions\nof the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\nANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\nTO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\nPARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT\nSHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\nCLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR\nIN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\nDEALINGS IN THE SOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 5.7978515625,
          "content": "# Rayon\n\n[![Rayon crate](https://img.shields.io/crates/v/rayon.svg)](https://crates.io/crates/rayon)\n[![Rayon documentation](https://docs.rs/rayon/badge.svg)](https://docs.rs/rayon)\n![minimum rustc 1.63](https://img.shields.io/badge/rustc-1.63+-red.svg)\n[![build status](https://github.com/rayon-rs/rayon/workflows/main/badge.svg)](https://github.com/rayon-rs/rayon/actions)\n[![Join the chat at https://gitter.im/rayon-rs/Lobby](https://badges.gitter.im/rayon-rs/Lobby.svg)](https://gitter.im/rayon-rs/Lobby?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\nRayon is a data-parallelism library for Rust. It is extremely\nlightweight and makes it easy to convert a sequential computation into\na parallel one. It also guarantees data-race freedom. (You may also\nenjoy [this blog post][blog] about Rayon, which gives more background\nand details about how it works, or [this video][video], from the Rust\nBelt Rust conference.) Rayon is\n[available on crates.io](https://crates.io/crates/rayon), and\n[API documentation is available on docs.rs](https://docs.rs/rayon).\n\n[blog]: https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/\n[video]: https://www.youtube.com/watch?v=gof_OEv71Aw\n\n## Parallel iterators and more\n\nRayon makes it drop-dead simple to convert sequential iterators into\nparallel ones: usually, you just change your `foo.iter()` call into\n`foo.par_iter()`, and Rayon does the rest:\n\n```rust\nuse rayon::prelude::*;\nfn sum_of_squares(input: &[i32]) -> i32 {\n    input.par_iter() // <-- just change that!\n         .map(|&i| i * i)\n         .sum()\n}\n```\n\n[Parallel iterators] take care of deciding how to divide your data\ninto tasks; it will dynamically adapt for maximum performance. If you\nneed more flexibility than that, Rayon also offers the [join] and\n[scope] functions, which let you create parallel tasks on your own.\nFor even more control, you can create [custom threadpools] rather than\nusing Rayon's default, global threadpool.\n\n[Parallel iterators]: https://docs.rs/rayon/*/rayon/iter/index.html\n[join]: https://docs.rs/rayon/*/rayon/fn.join.html\n[scope]: https://docs.rs/rayon/*/rayon/fn.scope.html\n[custom threadpools]: https://docs.rs/rayon/*/rayon/struct.ThreadPool.html\n\n## No data races\n\nYou may have heard that parallel execution can produce all kinds of\ncrazy bugs. Well, rest easy. Rayon's APIs all guarantee **data-race\nfreedom**, which generally rules out most parallel bugs (though not\nall). In other words, **if your code compiles**, it typically does the\nsame thing it did before.\n\nFor the most, parallel iterators in particular are guaranteed to\nproduce the same results as their sequential counterparts. One caveat:\nIf your iterator has side effects (for example, sending methods to\nother threads through a [Rust channel] or writing to disk), those side\neffects may occur in a different order. Note also that, in some cases,\nparallel iterators offer alternative versions of the sequential\niterator methods that can have higher performance.\n\n[Rust channel]: https://doc.rust-lang.org/std/sync/mpsc/fn.channel.html\n\n## Using Rayon\n\n[Rayon is available on crates.io](https://crates.io/crates/rayon). The\nrecommended way to use it is to add a line into your Cargo.toml such\nas:\n\n```toml\n[dependencies]\nrayon = \"1.10\"\n```\n\nTo use the parallel iterator APIs, a number of traits have to be in\nscope. The easiest way to bring those things into scope is to use the\n[Rayon prelude](https://docs.rs/rayon/*/rayon/prelude/index.html). In\neach module where you would like to use the parallel iterator APIs,\njust add:\n\n```rust\nuse rayon::prelude::*;\n```\n\nRayon currently requires `rustc 1.63.0` or greater.\n\n### Usage with WebAssembly\n\nBy default, when building to WebAssembly, Rayon will treat it as any\nother platform without multithreading support and will fall back to\nsequential iteration. This allows existing code to compile and run\nsuccessfully with no changes necessary, but it will run slower as it\nwill only use a single CPU core.\n\nYou can build Rayon-based projects with proper multithreading support\nfor the Web, but you'll need an adapter and some project configuration\nto account for differences between WebAssembly threads and threads on\nthe other platforms.\n\nCheck out the\n[wasm-bindgen-rayon](https://github.com/RReverser/wasm-bindgen-rayon)\ndocs for more details.\n\n## Contribution\n\nRayon is an open source project! If you'd like to contribute to Rayon,\ncheck out\n[the list of \"help wanted\" issues](https://github.com/rayon-rs/rayon/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22).\nThese are all (or should be) issues that are suitable for getting\nstarted, and they generally include a detailed set of instructions for\nwhat to do. Please ask questions if anything is unclear! Also, check\nout the\n[Guide to Development](https://github.com/rayon-rs/rayon/wiki/Guide-to-Development)\npage on the wiki. Note that all code submitted in PRs to Rayon is\nassumed to\n[be licensed under Rayon's dual MIT/Apache 2.0 licensing](https://github.com/rayon-rs/rayon/blob/main/README.md#license).\n\n## Quick demo\n\nTo see Rayon in action, check out the `rayon-demo` directory, which\nincludes a number of demos of code using Rayon. For example, run this\ncommand to get a visualization of an N-body simulation. To see the\neffect of using Rayon, press `s` to run sequentially and `p` to run in\nparallel.\n\n```text\n> cd rayon-demo\n> cargo run --release -- nbody visualize\n```\n\nFor more information on demos, try:\n\n```text\n> cd rayon-demo\n> cargo run --release -- --help\n```\n\n## Other questions?\n\nSee [the Rayon FAQ][faq].\n\n[faq]: https://github.com/rayon-rs/rayon/blob/main/FAQ.md\n\n## License\n\nRayon is distributed under the terms of both the MIT license and the\nApache License (Version 2.0). See [LICENSE-APACHE](LICENSE-APACHE) and\n[LICENSE-MIT](LICENSE-MIT) for details. Opening a pull request is\nassumed to signal agreement with these licensing terms.\n"
        },
        {
          "name": "RELEASES.md",
          "type": "blob",
          "size": 35.3583984375,
          "content": "# Release rayon 1.10.0 (2024-03-23)\n\n- The new methods `ParallelSlice::par_chunk_by` and\n  `ParallelSliceMut::par_chunk_by_mut` work like the slice methods `chunk_by`\n  and `chunk_by_mut` added in Rust 1.77.\n\n# Release rayon 1.9.0 (2024-02-27)\n\n- The new methods `IndexedParallelIterator::by_exponential_blocks` and\n  `by_uniform_blocks` allow processing items in smaller groups at a time.\n- The new `iter::walk_tree`, `walk_tree_prefix`, and `walk_tree_postfix`\n  functions enable custom parallel iteration over tree-like structures.\n- The new method `ParallelIterator::collect_vec_list` returns items as a linked\n  list of vectors, which is an efficient mode of parallel collection used by\n  many of the internal implementations of `collect`.\n- The new methods `ParallelSliceMut::par_split_inclusive_mut`,\n  `ParallelSlice::par_split_inclusive`, and\n  `ParallelString::par_split_inclusive` all work like a normal split but\n  keeping the separator as part of the left slice.\n- The new `ParallelString::par_split_ascii_whitespace` splits only on ASCII\n  whitespace, which is faster than including Unicode multi-byte whitespace.\n- `OsString` now implements `FromParallelIterator<_>` and `ParallelExtend<_>`\n  for a few item types similar to the standard `FromIterator` and `Extend`.\n- The internal `Pattern` trait for string methods is now implemented for\n  `[char; N]` and `&[char; N]`, matching any of the given characters.\n\n# Release rayon 1.8.1 / rayon-core 1.12.1 (2024-01-17)\n\n- The new `\"web_spin_lock\"` crate feature makes mutexes spin on the main\n  browser thread in WebAssembly, rather than suffer an error about forbidden\n  `atomics.wait` if they were to block in that context. Thanks @RReverser!\n\n# Release rayon 1.8.0 / rayon-core 1.12.0 (2023-09-20)\n\n- The minimum supported `rustc` is now 1.63.\n- Added `ThreadPoolBuilder::use_current_thread` to use the builder thread as\n  part of the new thread pool. That thread does not run the pool's main loop,\n  but it may participate in work-stealing if it yields to rayon in some way.\n- Implemented `FromParallelIterator<T>` for `Box<[T]>`, `Rc<[T]>`, and\n  `Arc<[T]>`, as well as `FromParallelIterator<Box<str>>` and\n  `ParallelExtend<Box<str>>` for `String`.\n- `ThreadPoolBuilder::build_scoped` now uses `std::thread::scope`.\n- The default number of threads is now determined using\n  `std::thread::available_parallelism` instead of the `num_cpus` crate.\n- The internal logging facility has been removed, reducing bloat for all users.\n- Many smaller performance tweaks and documentation updates.\n\n# Release rayon 1.7.0 / rayon-core 1.11.0 (2023-03-03)\n\n- The minimum supported `rustc` is now 1.59.\n- Added a fallback when threading is unsupported.\n- The new `ParallelIterator::take_any` and `skip_any` methods work like\n  unordered `IndexedParallelIterator::take` and `skip`, counting items in\n  whatever order they are visited in parallel.\n- The new `ParallelIterator::take_any_while` and `skip_any_while` methods work\n  like unordered `Iterator::take_while` and `skip_while`, which previously had\n  no parallel equivalent. The \"while\" condition may be satisfied from anywhere\n  in the parallel iterator, affecting all future items regardless of position.\n- The new `yield_now` and `yield_local` functions will cooperatively yield\n  execution to Rayon, either trying to execute pending work from the entire\n  pool or from just the local deques of the current thread, respectively.\n\n# Release rayon-core 1.10.2 (2023-01-22)\n\n- Fixed miri-reported UB for SharedReadOnly tags protected by a call.\n\n# Release rayon 1.6.1 (2022-12-09)\n\n- Simplified `par_bridge` to only pull one item at a time from the iterator,\n  without batching. Threads that are waiting for iterator items will now block\n  appropriately rather than spinning CPU. (Thanks @njaard!)\n- Added protection against recursion in `par_bridge`, so iterators that also\n  invoke rayon will not cause mutex recursion deadlocks.\n\n# Release rayon-core 1.10.1 (2022-11-18)\n\n- Fixed a race condition with threads going to sleep while a broadcast starts.\n\n# Release rayon 1.6.0 / rayon-core 1.10.0 (2022-11-18)\n\n- The minimum supported `rustc` is now 1.56.\n- The new `IndexedParallelIterator::fold_chunks` and `fold_chunks_with` methods\n  work like `ParallelIterator::fold` and `fold_with` with fixed-size chunks of\n  items. This may be useful for predictable batching performance, without the\n  allocation overhead of `IndexedParallelIterator::chunks`.\n- New \"broadcast\" methods run a given function on all threads in the pool.\n  These run at a sort of reduced priority after each thread has exhausted their\n  local work queue, but before they attempt work-stealing from other threads.\n  - The global `broadcast` function and `ThreadPool::broadcast` method will\n    block until completion, returning a `Vec` of all return values.\n  - The global `spawn_broadcast` function and methods on `ThreadPool`, `Scope`,\n    and `ScopeFifo` will run detached, without blocking the current thread.\n- Panicking methods now use `#[track_caller]` to report the caller's location.\n- Fixed a truncated length in `vec::Drain` when given an empty range.\n\n## Contributors\n\nThanks to all of the contributors for this release!\n\n- @cuviper\n- @idanmuze\n- @JoeyBF\n- @JustForFun88\n- @kianmeng\n- @kornelski\n- @ritchie46\n- @ryanrussell\n- @steffahn\n- @TheIronBorn\n- @willcrozi\n\n# Release rayon 1.5.3 (2022-05-13)\n\n- The new `ParallelSliceMut::par_sort_by_cached_key` is a stable sort that caches\n  the keys for each item -- a parallel version of `slice::sort_by_cached_key`.\n\n# Release rayon-core 1.9.3 (2022-05-13)\n\n- Fixed a use-after-free race in job notification.\n\n# Release rayon 1.5.2 / rayon-core 1.9.2 (2022-04-13)\n\n- The new `ParallelSlice::par_rchunks()` and `par_rchunks_exact()` iterate\n  slice chunks in reverse, aligned the against the end of the slice if the\n  length is not a perfect multiple of the chunk size. The new\n  `ParallelSliceMut::par_rchunks_mut()` and `par_rchunks_exact_mut()` are the\n  same for mutable slices.\n- The `ParallelIterator::try_*` methods now support `std::ops::ControlFlow` and\n  `std::task::Poll` items, mirroring the unstable `Try` implementations in the\n  standard library.\n- The `ParallelString` pattern-based methods now support `&[char]` patterns,\n  which match when any character in that slice is found in the string.\n- A soft limit is now enforced on the number of threads allowed in a single\n  thread pool, respecting internal bit limits that already existed. The current\n  maximum is publicly available from the new function `max_num_threads()`.\n- Fixed several Stacked Borrow and provenance issues found by `cargo miri`.\n\n## Contributors\n\nThanks to all of the contributors for this release!\n\n- @atouchet\n- @bluss\n- @cuviper\n- @fzyzcjy\n- @nyanzebra\n- @paolobarbolini\n- @RReverser\n- @saethlin\n\n# Release rayon 1.5.1 / rayon-core 1.9.1 (2021-05-18)\n\n- The new `in_place_scope` and `in_place_scope_fifo` are variations of `scope`\n  and `scope_fifo`, running the initial non-`Send` callback directly on the\n  current thread, rather than moving execution to the thread pool.\n- With Rust 1.51 or later, arrays now implement `IntoParallelIterator`.\n- New implementations of `FromParallelIterator` make it possible to `collect`\n  complicated nestings of items.\n  - `FromParallelIterator<(A, B)> for (FromA, FromB)` works like `unzip`.\n  - `FromParallelIterator<Either<L, R>> for (A, B)` works like `partition_map`.\n- Type inference now works better with parallel `Range` and `RangeInclusive`.\n- The implementation of `FromParallelIterator` and `ParallelExtend` for\n  `Vec<T>` now uses `MaybeUninit<T>` internally to avoid creating any\n  references to uninitialized data.\n- `ParallelBridge` fixed a bug with threads missing available work.\n\n## Contributors\n\nThanks to all of the contributors for this release!\n\n- @atouchet\n- @cuviper\n- @Hywan\n- @iRaiko\n- @Qwaz\n- @rocallahan\n\n# Release rayon 1.5.0 / rayon-core 1.9.0 (2020-10-21)\n\n- Update crossbeam dependencies.\n- The minimum supported `rustc` is now 1.36.\n\n## Contributors\n\nThanks to all of the contributors for this release!\n\n- @cuviper\n- @mbrubeck\n- @mrksu\n\n# Release rayon 1.4.1 (2020-09-29)\n\n- The new `flat_map_iter` and `flatten_iter` methods can be used to flatten\n  sequential iterators, which may perform better in cases that don't need the\n  nested parallelism of `flat_map` and `flatten`.\n- The new `par_drain` method is a parallel version of the standard `drain` for\n  collections, removing items while keeping the original capacity. Collections\n  that implement this through `ParallelDrainRange` support draining items from\n  arbitrary index ranges, while `ParallelDrainFull` always drains everything.\n- The new `positions` method finds all items that match the given predicate and\n  returns their indices in a new iterator.\n\n# Release rayon-core 1.8.1 (2020-09-17)\n\n- Fixed an overflow panic on high-contention workloads, for a counter that was\n  meant to simply wrap. This panic only occurred with debug assertions enabled,\n  and was much more likely on 32-bit targets.\n\n# Release rayon 1.4.0 / rayon-core 1.8.0 (2020-08-24)\n\n- Implemented a new thread scheduler, [RFC 5], which uses targeted wakeups for\n  new work and for notifications of completed stolen work, reducing wasteful\n  CPU usage in idle threads.\n- Implemented `IntoParallelIterator for Range<char>` and `RangeInclusive<char>`\n  with the same iteration semantics as Rust 1.45.\n- Relaxed the lifetime requirements of the initial `scope` closure.\n\n[RFC 5]: https://github.com/rayon-rs/rfcs/pull/5\n\n## Contributors\n\nThanks to all of the contributors for this release!\n\n- @CAD97\n- @cuviper\n- @kmaork\n- @nikomatsakis\n- @SuperFluffy\n\n\n# Release rayon 1.3.1 / rayon-core 1.7.1 (2020-06-15)\n\n- Fixed a use-after-free race in calls blocked between two rayon thread pools.\n- Collecting to an indexed `Vec` now drops any partial writes while unwinding,\n  rather than just leaking them. If dropping also panics, Rust will abort.\n  - Note: the old leaking behavior is considered _safe_, just not ideal.\n- The new `IndexedParallelIterator::step_by()` adapts an iterator to step\n  through items by the given count, like `Iterator::step_by()`.\n- The new `ParallelSlice::par_chunks_exact()` and mutable equivalent\n  `ParallelSliceMut::par_chunks_exact_mut()` ensure that the chunks always have\n  the exact length requested, leaving any remainder separate, like the slice\n  methods `chunks_exact()` and `chunks_exact_mut()`.\n\n## Contributors\n\nThanks to all of the contributors for this release!\n\n- @adrian5\n- @bluss\n- @cuviper\n- @FlyingCanoe\n- @GuillaumeGomez\n- @matthiasbeyer\n- @picoHz\n- @zesterer\n\n\n# Release rayon 1.3.0 / rayon-core 1.7.0 (2019-12-21)\n\n- Tuples up to length 12 now implement `IntoParallelIterator`, creating a\n  `MultiZip` iterator that produces items as similarly-shaped tuples.\n- The `--cfg=rayon_unstable` supporting code for `rayon-futures` is removed.\n- The minimum supported `rustc` is now 1.31.\n\n## Contributors\n\nThanks to all of the contributors for this release!\n\n- @cuviper\n- @c410-f3r\n- @silwol\n\n\n# Release rayon-futures 0.1.1 (2019-12-21)\n\n- `Send` bounds have been added for the `Item` and `Error` associated types on\n  all generic `F: Future` interfaces. While technically a breaking change, this\n  is a soundness fix, so we are not increasing the semantic version for this.\n- This crate is now deprecated, and the `--cfg=rayon_unstable` supporting code\n  will be removed in `rayon-core 1.7.0`. This only supported the now-obsolete\n  `Future` from `futures 0.1`, while support for `std::future::Future` is\n  expected to come directly in `rayon-core` -- although that is not ready yet.\n\n## Contributors\n\nThanks to all of the contributors for this release!\n\n- @cuviper\n- @kornelski\n- @jClaireCodesStuff\n- @jwass\n- @seanchen1991\n\n\n# Release rayon 1.2.1 / rayon-core 1.6.1 (2019-11-20)\n\n- Update crossbeam dependencies.\n- Add top-level doc links for the iterator traits.\n- Document that the iterator traits are not object safe.\n\n## Contributors\n\nThanks to all of the contributors for this release!\n\n- @cuviper\n- @dnaka91\n- @matklad\n- @nikomatsakis\n- @Qqwy\n- @vorner\n\n\n# Release rayon 1.2.0 / rayon-core 1.6.0 (2019-08-30)\n\n- The new `ParallelIterator::copied()` converts an iterator of references into\n  copied values, like `Iterator::copied()`.\n- `ParallelExtend` is now implemented for the unit `()`.\n- Internal updates were made to improve test determinism, reduce closure type\n  sizes, reduce task allocations, and update dependencies.\n- The minimum supported `rustc` is now 1.28.\n\n## Contributors\n\nThanks to all of the contributors for this release!\n\n- @Aaron1011\n- @cuviper\n- @ralfbiedert\n\n\n# Release rayon 1.1.0 / rayon-core 1.5.0 (2019-06-12)\n\n- FIFO spawns are now supported using the new `spawn_fifo()` and `scope_fifo()`\n  global functions, and their corresponding `ThreadPool` methods.\n  - Normally when tasks are queued on a thread, the most recent is processed\n    first (LIFO) while other threads will steal the oldest (FIFO). With FIFO\n    spawns, those tasks are processed locally in FIFO order too.\n  - Regular spawns and other tasks like `join` are not affected.\n  - The `breadth_first` configuration flag, which globally approximated this\n    effect, is now deprecated.\n  - For more design details, please see [RFC 1].\n- `ThreadPoolBuilder` can now take a custom `spawn_handler` to control how\n  threads will be created in the pool.\n  - `ThreadPoolBuilder::build_scoped()` uses this to create a scoped thread\n    pool, where the threads are able to use non-static data.\n  - This may also be used to support threading in exotic environments, like\n    WebAssembly, which don't support the normal `std::thread`.\n- `ParallelIterator` has 3 new methods: `find_map_any()`, `find_map_first()`,\n  and `find_map_last()`, like `Iterator::find_map()` with ordering constraints.\n- The new `ParallelIterator::panic_fuse()` makes a parallel iterator halt as soon\n  as possible if any of its threads panic. Otherwise, the panic state is not\n  usually noticed until the iterator joins its parallel tasks back together.\n- `IntoParallelIterator` is now implemented for integral `RangeInclusive`.\n- Several internal `Folder`s now have optimized `consume_iter` implementations.\n- `rayon_core::current_thread_index()` is now re-exported in `rayon`.\n- The minimum `rustc` is now 1.26, following the update policy defined in [RFC 3].\n\n## Contributors\n\nThanks to all of the contributors for this release!\n\n- @cuviper\n- @didroe\n- @GuillaumeGomez\n- @huonw\n- @janriemer\n- @kornelski\n- @nikomatsakis\n- @seanchen1991\n- @yegeun542\n\n[RFC 1]: https://github.com/rayon-rs/rfcs/blob/main/accepted/rfc0001-scope-scheduling.md\n[RFC 3]: https://github.com/rayon-rs/rfcs/blob/main/accepted/rfc0003-minimum-rustc.md\n\n\n# Release rayon 1.0.3 (2018-11-02)\n\n- `ParallelExtend` is now implemented for tuple pairs, enabling nested\n  `unzip()` and `partition_map()` operations.  For instance, `(A, (B, C))`\n  items can be unzipped into `(Vec<A>, (Vec<B>, Vec<C>))`.\n  - `ParallelExtend<(A, B)>` works like `unzip()`.\n  - `ParallelExtend<Either<A, B>>` works like `partition_map()`.\n- `ParallelIterator` now has a method `map_init()` which calls an `init`\n  function for a value to pair with items, like `map_with()` but dynamically\n  constructed.  That value type has no constraints, not even `Send` or `Sync`.\n  - The new `for_each_init()` is a variant of this for simple iteration.\n  - The new `try_for_each_init()` is a variant for fallible iteration.\n\n## Contributors\n\nThanks to all of the contributors for this release!\n\n- @cuviper\n- @dan-zheng\n- @dholbert\n- @ignatenkobrain\n- @mdonoughe\n\n\n# Release rayon 1.0.2 / rayon-core 1.4.1 (2018-07-17)\n\n- The `ParallelBridge` trait with method `par_bridge()` makes it possible to\n  use any `Send`able `Iterator` in parallel!\n  - This trait has been added to `rayon::prelude`.\n  - It automatically implements internal synchronization and queueing to\n    spread the `Item`s across the thread pool.  Iteration order is not\n    preserved by this adaptor.\n  - \"Native\" Rayon iterators like `par_iter()` should still be preferred when\n    possible for better efficiency.\n- `ParallelString` now has additional methods for parity with `std` string\n  iterators: `par_char_indices()`, `par_bytes()`, `par_encode_utf16()`,\n  `par_matches()`, and `par_match_indices()`.\n- `ParallelIterator` now has fallible methods `try_fold()`, `try_reduce()`,\n  and `try_for_each`, plus `*_with()` variants of each, for automatically\n  short-circuiting iterators on `None` or `Err` values.  These are inspired by\n  `Iterator::try_fold()` and `try_for_each()` that were stabilized in Rust 1.27.\n- `Range<i128>` and `Range<u128>` are now supported with Rust 1.26 and later.\n- Small improvements have been made to the documentation.\n- `rayon-core` now only depends on `rand` for testing.\n- Rayon tests now work on stable Rust.\n\n## Contributors\n\nThanks to all of the contributors for this release!\n\n- @AndyGauge\n- @cuviper\n- @ignatenkobrain\n- @LukasKalbertodt\n- @MajorBreakfast\n- @nikomatsakis\n- @paulkernfeld\n- @QuietMisdreavus\n\n\n# Release rayon 1.0.1 (2018-03-16)\n\n- Added more documentation for `rayon::iter::split()`.\n- Corrected links and typos in documentation.\n\n## Contributors\n\nThanks to all of the contributors for this release!\n\n- @cuviper\n- @HadrienG2\n- @matthiasbeyer\n- @nikomatsakis\n\n\n# Release rayon 1.0.0 / rayon-core 1.4.0 (2018-02-15)\n\n- `ParallelIterator` added the `update` method which applies a function to\n  mutable references, inspired by `itertools`.\n- `IndexedParallelIterator` added the `chunks` method which yields vectors of\n  consecutive items from the base iterator, inspired by `itertools`.\n- `String` now implements `FromParallelIterator<Cow<str>>` and\n  `ParallelExtend<Cow<str>>`, inspired by `std`.\n- `()` now implements `FromParallelIterator<()>`, inspired by `std`.\n- The new `ThreadPoolBuilder` replaces and deprecates `Configuration`.\n  - Errors from initialization now have the concrete `ThreadPoolBuildError`\n    type, rather than `Box<Error>`, and this type implements `Send` and `Sync`.\n  - `ThreadPool::new` is deprecated in favor of `ThreadPoolBuilder::build`.\n  - `initialize` is deprecated in favor of `ThreadPoolBuilder::build_global`.\n- Examples have been added to most of the parallel iterator methods.\n- A lot of the documentation has been reorganized and extended.\n\n## Breaking changes\n\n- Rayon now requires rustc 1.13 or greater.\n- `IndexedParallelIterator::len` and `ParallelIterator::opt_len` now operate on\n  `&self` instead of `&mut self`.\n- `IndexedParallelIterator::collect_into` is now `collect_into_vec`.\n- `IndexedParallelIterator::unzip_into` is now `unzip_into_vecs`.\n- Rayon no longer exports the deprecated `Configuration` and `initialize` from\n  rayon-core.\n\n## Contributors\n\nThanks to all of the contributors for this release!\n\n- @Bilkow\n- @cuviper\n- @Enet4\n- @ignatenkobrain\n- @iwillspeak\n- @jeehoonkang\n- @jwass\n- @Kerollmops\n- @KodrAus\n- @kornelski\n- @MaloJaffre\n- @nikomatsakis\n- @obv-mikhail\n- @oddg\n- @phimuemue\n- @stjepang\n- @tmccombs\n- bors[bot]\n\n\n# Release rayon 0.9.0 / rayon-core 1.3.0 / rayon-futures 0.1.0 (2017-11-09)\n\n- `Configuration` now has a `build` method.\n- `ParallelIterator` added `flatten` and `intersperse`, both inspired by\n  itertools.\n- `IndexedParallelIterator` added `interleave`, `interleave_shortest`, and\n  `zip_eq`, all inspired by itertools.\n- The new functions `iter::empty` and `once` create parallel iterators of\n  exactly zero or one item, like their `std` counterparts.\n- The new functions `iter::repeat` and `repeatn` create parallel iterators\n  repeating an item indefinitely or `n` times, respectively.\n- The new function `join_context` works like `join`, with an added `FnContext`\n  parameter that indicates whether the job was stolen.\n- `Either` (used by `ParallelIterator::partition_map`) is now re-exported from\n  the `either` crate, instead of defining our own type.\n  - `Either` also now implements `ParallelIterator`, `IndexedParallelIterator`,\n    and `ParallelExtend` when both of its `Left` and `Right` types do.\n- All public types now implement `Debug`.\n- Many of the parallel iterators now implement `Clone` where possible.\n- Much of the documentation has been extended. (but still could use more help!)\n- All rayon crates have improved metadata.\n- Rayon was evaluated in the Libz Blitz, leading to many of these improvements.\n- Rayon pull requests are now guarded by bors-ng.\n\n## Futures\n\nThe `spawn_future()` method has been refactored into its own `rayon-futures`\ncrate, now through a `ScopeFutureExt` trait for `ThreadPool` and `Scope`.  The\nsupporting `rayon-core` APIs are still gated by `--cfg rayon_unstable`.\n\n## Breaking changes\n\n- Two breaking changes have been made to `rayon-core`, but since they're fixing\n  soundness bugs, we are considering these _minor_ changes for semver.\n  - `Scope::spawn` now requires `Send` for the closure.\n  - `ThreadPool::install` now requires `Send` for the return value.\n- The `iter::internal` module has been renamed to `iter::plumbing`, to hopefully\n  indicate that while these are low-level details, they're not really internal\n  or private to rayon.  The contents of that module are needed for third-parties\n  to implement new parallel iterators, and we'll treat them with normal semver\n  stability guarantees.\n- The function `rayon::iter::split` is no longer re-exported as `rayon::split`.\n\n## Contributors\n\nThanks to all of the contributors for this release!\n\n- @AndyGauge\n- @ChristopherDavenport\n- @chrisvittal\n- @cuviper\n- @dns2utf8\n- @dtolnay\n- @frewsxcv\n- @gsquire\n- @Hittherhod\n- @jdr023\n- @laumann\n- @leodasvacas\n- @lvillani\n- @MajorBreakfast\n- @mamuleanu\n- @marmistrz\n- @mbrubeck\n- @mgattozzi\n- @nikomatsakis\n- @smt923\n- @stjepang\n- @tmccombs\n- @vishalsodani\n- bors[bot]\n\n\n# Release rayon 0.8.2 (2017-06-28)\n\n- `ParallelSliceMut` now has six parallel sorting methods with the same\n  variations as the standard library.\n  - `par_sort`, `par_sort_by`, and `par_sort_by_key` perform stable sorts in\n    parallel, using the default order, a custom comparator, or a key extraction\n    function, respectively.\n  - `par_sort_unstable`, `par_sort_unstable_by`, and `par_sort_unstable_by_key`\n    perform unstable sorts with the same comparison options.\n  - Thanks to @stjepang!\n\n\n# Release rayon 0.8.1 / rayon-core 1.2.0 (2017-06-14)\n\n- The following core APIs are being stabilized:\n  - `rayon::spawn()` -- spawns a task into the Rayon threadpool; as it\n    is contained in the global scope (rather than a user-created\n    scope), the task cannot capture anything from the current stack\n    frame.\n  - `ThreadPool::join()`, `ThreadPool::spawn()`, `ThreadPool::scope()`\n    -- convenience APIs for launching new work within a thread-pool.\n- The various iterator adapters are now tagged with `#[must_use]`\n- Parallel iterators now offer a `for_each_with` adapter, similar to\n  `map_with`.\n- We are adopting a new approach to handling the remaining unstable\n  APIs (which primarily pertain to futures integration). As awlays,\n  unstable APIs are intended for experimentation, but do not come with\n  any promise of compatibility (in other words, we might change them\n  in arbitrary ways in any release). Previously, we designated such\n  APIs using a Cargo feature \"unstable\". Now, we are using a regular\n  `#[cfg]` flag. This means that to see the unstable APIs, you must do\n  `RUSTFLAGS='--cfg rayon_unstable' cargo build`. This is\n  intentionally inconvenient; in particular, if you are a library,\n  then your clients must also modify their environment, signaling\n  their agreement to instability.\n\n\n# Release rayon 0.8.0 / rayon-core 1.1.0 (2017-06-13)\n\n## Rayon 0.8.0\n\n- Added the `map_with` and `fold_with` combinators, which help for\n  passing along state (like channels) that cannot be shared between\n  threads but which can be cloned on each thread split.\n- Added the `while_some` combinator, which helps for writing short-circuiting iterators.\n- Added support for \"short-circuiting\" collection: e.g., collecting\n  from an iterator producing `Option<T>` or `Result<T, E>` into a\n  `Option<Collection<T>>` or `Result<Collection<T>, E>`.\n- Support `FromParallelIterator` for `Cow`.\n- Removed the deprecated weight APIs.\n- Simplified the parallel iterator trait hierarchy by removing the\n  `BoundedParallelIterator` and `ExactParallelIterator` traits,\n  which were not serving much purpose.\n- Improved documentation.\n- Added some missing `Send` impls.\n- Fixed some small bugs.\n\n## Rayon-core 1.1.0\n\n- We now have more documentation.\n- Renamed the (unstable) methods `spawn_async` and\n  `spawn_future_async` -- which spawn tasks that cannot hold\n  references -- to simply `spawn` and `spawn_future`, respectively.\n- We are now using the coco library for our deque.\n- Individual threadpools can now be configured in \"breadth-first\"\n  mode, which causes them to execute spawned tasks in the reverse\n  order that they used to.  In some specific scenarios, this can be a\n  win (though it is not generally the right choice).\n- Added top-level functions:\n  - `current_thread_index`, for querying the index of the current worker thread within\n    its thread-pool (previously available as `thread_pool.current_thread_index()`);\n  - `current_thread_has_pending_tasks`, for querying whether the\n    current worker that has an empty task deque or not. This can be\n    useful when deciding whether to spawn a task.\n- The environment variables for controlling Rayon are now\n  `RAYON_NUM_THREADS` and `RAYON_LOG`. The older variables (e.g.,\n  `RAYON_RS_NUM_CPUS` are still supported but deprecated).\n\n## Rayon-demo\n\n- Added a new game-of-life benchmark.\n\n## Contributors\n\nThanks to the following contributors:\n\n- @ChristopherDavenport\n- @SuperFluffy\n- @antoinewdg\n- @crazymykl\n- @cuviper\n- @glandium\n- @julian-seward1\n- @leodasvacas\n- @leshow\n- @lilianmoraru\n- @mschmo\n- @nikomatsakis\n- @stjepang\n\n\n# Release rayon 0.7.1 / rayon-core 1.0.2 (2017-05-30)\n\nThis release is a targeted performance fix for #343, an issue where\nrayon threads could sometimes enter into a spin loop where they would\nbe unable to make progress until they are pre-empted.\n\n\n# Release rayon 0.7 / rayon-core 1.0 (2017-04-06)\n\nThis release marks the first step towards Rayon 1.0. **For best\nperformance, it is important that all Rayon users update to at least\nRayon 0.7.** This is because, as of Rayon 0.7, we have taken steps to\nensure that, no matter how many versions of rayon are actively in use,\nthere will only be a single global scheduler. This is achieved via the\n`rayon-core` crate, which is being released at version 1.0, and which\nencapsulates the core schedule APIs like `join()`. (Note: the\n`rayon-core` crate is, to some degree, an implementation detail, and\nnot intended to be imported directly; it's entire API surface is\nmirrored through the rayon crate.)\n\nWe have also done a lot of work reorganizing the API for Rayon 0.7 in\npreparation for 1.0. The names of iterator types have been changed and\nreorganized (but few users are expected to be naming those types\nexplicitly anyhow). In addition, a number of parallel iterator methods\nhave been adjusted to match those in the standard iterator traits more\nclosely. See the \"Breaking Changes\" section below for\ndetails.\n\nFinally, Rayon 0.7 includes a number of new features and new parallel\niterator methods. **As of this release, Rayon's parallel iterators\nhave officially reached parity with sequential iterators** -- that is,\nevery sequential iterator method that makes any sense in parallel is\nsupported in some capacity.\n\n### New features and methods\n\n- The internal `Producer` trait now features `fold_with`, which enables\n  better performance for some parallel iterators.\n- Strings now support `par_split()` and `par_split_whitespace()`.\n- The `Configuration` API is expanded and simplified:\n    - `num_threads(0)` no longer triggers an error\n    - you can now supply a closure to name the Rayon threads that get created\n      by using `Configuration::thread_name`.\n    - you can now inject code when Rayon threads start up and finish\n    - you can now set a custom panic handler to handle panics in various odd situations\n- Threadpools are now able to more gracefully put threads to sleep when not needed.\n- Parallel iterators now support `find_first()`, `find_last()`, `position_first()`,\n  and `position_last()`.\n- Parallel iterators now support `rev()`, which primarily affects subsequent calls\n  to `enumerate()`.\n- The `scope()` API is now considered stable (and part of `rayon-core`).\n- There is now a useful `rayon::split` function for creating custom\n  Rayon parallel iterators.\n- Parallel iterators now allow you to customize the min/max number of\n  items to be processed in a given thread. This mechanism replaces the\n  older `weight` mechanism, which is deprecated.\n- `sum()` and friends now use the standard `Sum` traits\n\n### Breaking changes\n\nIn the move towards 1.0, there have been a number of minor breaking changes:\n\n- Configuration setters like `Configuration::set_num_threads()` lost the `set_` prefix,\n  and hence become something like `Configuration::num_threads()`.\n- `Configuration` getters are removed\n- Iterator types have been shuffled around and exposed more consistently:\n    - combinator types live in `rayon::iter`, e.g. `rayon::iter::Filter`\n    - iterators over various types live in a module named after their type,\n      e.g. `rayon::slice::Windows`\n- When doing a `sum()` or `product()`, type annotations are needed for the result\n  since it is now possible to have the resulting sum be of a type other than the value\n  you are iterating over (this mirrors sequential iterators).\n\n### Experimental features\n\nExperimental features require the use of the `unstable` feature. Their\nAPIs may change or disappear entirely in future releases (even minor\nreleases) and hence they should be avoided for production code.\n\n- We now have (unstable) support for futures integration. You can use\n  `Scope::spawn_future` or `rayon::spawn_future_async()`.\n- There is now a `rayon::spawn_async()` function for using the Rayon\n  threadpool to run tasks that do not have references to the stack.\n\n### Contributors\n\nThanks to the following people for their contributions to this release:\n\n- @Aaronepower\n- @ChristopherDavenport\n- @bluss\n- @cuviper\n- @froydnj\n- @gaurikholkar\n- @hniksic\n- @leodasvacas\n- @leshow\n- @martinhath\n- @mbrubeck\n- @nikomatsakis\n- @pegomes\n- @schuster\n- @torkleyy\n\n\n# Release 0.6 (2016-12-21)\n\nThis release includes a lot of progress towards the goal of parity\nwith the sequential iterator API, though there are still a few methods\nthat are not yet complete. If you'd like to help with that effort,\n[check out the milestone](https://github.com/rayon-rs/rayon/issues?q=is%3Aopen+is%3Aissue+milestone%3A%22Parity+with+the+%60Iterator%60+trait%22)\nto see the remaining issues.\n\n**Announcement:** @cuviper has been added as a collaborator to the\nRayon repository for all of his outstanding work on Rayon, which\nincludes both internal refactoring and helping to shape the public\nAPI. Thanks @cuviper! Keep it up.\n\n- We now support `collect()` and not just `collect_with()`.\n  You can use `collect()` to build a number of collections,\n  including vectors, maps, and sets. Moreover, when building a vector\n  with `collect()`, you are no longer limited to exact parallel iterators.\n  Thanks @nikomatsakis, @cuviper!\n- We now support `skip()` and `take()` on parallel iterators.\n  Thanks @martinhath!\n- **Breaking change:** We now match the sequential APIs for `min()` and `max()`.\n  We also support `min_by_key()` and `max_by_key()`. Thanks @tapeinosyne!\n- **Breaking change:** The `mul()` method is now renamed to `product()`,\n  to match sequential iterators. Thanks @jonathandturner!\n- We now support parallel iterator over ranges on `u64` values. Thanks @cuviper!\n- We now offer a `par_chars()` method on strings for iterating over characters\n  in parallel. Thanks @cuviper!\n- We now have new demos: a traveling salesman problem solver as well as matrix\n  multiplication. Thanks @nikomatsakis, @edre!\n- We are now documenting our minimum rustc requirement (currently\n  v1.12.0).  We will attempt to maintain compatibility with rustc\n  stable v1.12.0 as long as it remains convenient, but if new features\n  are stabilized or added that would be helpful to Rayon, or there are\n  bug fixes that we need, we will bump to the most recent rustc. Thanks @cuviper!\n- The `reduce()` functionality now has better inlining.\n  Thanks @bluss!\n- The `join()` function now has some documentation. Thanks @gsquire!\n- The project source has now been fully run through rustfmt.\n  Thanks @ChristopherDavenport!\n- Exposed helper methods for accessing the current thread index.\n  Thanks @bholley!\n\n\n# Release 0.5 (2016-11-04)\n\n- **Breaking change:** The `reduce` method has been vastly\n  simplified, and `reduce_with_identity` has been deprecated.\n- **Breaking change:** The `fold` method has been changed. It used to\n  always reduce the values, but now instead it is a combinator that\n  returns a parallel iterator which can itself be reduced. See the\n  docs for more information.\n- The following parallel iterator combinators are now available (thanks @cuviper!):\n  - `find_any()`: similar to `find` on a sequential iterator,\n    but doesn't necessarily return the *first* matching item\n  - `position_any()`: similar to `position` on a sequential iterator,\n    but doesn't necessarily return the index of *first* matching item\n  - `any()`, `all()`: just like their sequential counterparts\n- The `count()` combinator is now available for parallel iterators.\n- We now build with older versions of rustc again (thanks @durango!),\n  as we removed a stray semicolon from `thread_local!`.\n- Various improvements to the (unstable) `scope()` API implementation.\n\n\n# Release 0.4.3 (2016-10-25)\n\n- Parallel iterators now offer an adaptive weight scheme,\n  which means that explicit weights should no longer\n  be necessary in most cases! Thanks @cuviper!\n  - We are considering removing weights or changing the weight mechanism\n    before 1.0. Examples of scenarios where you still need weights even\n    with this adaptive mechanism would be great. Join the discussion\n    at <https://github.com/rayon-rs/rayon/issues/111>.\n- New (unstable) scoped threads API, see `rayon::scope` for details.\n  - You will need to supply the [cargo feature] `unstable`.\n- The various demos and benchmarks have been consolidated into one\n  program, `rayon-demo`.\n- Optimizations in Rayon's inner workings. Thanks @emilio!\n- Update `num_cpus` to 1.0. Thanks @jamwt!\n- Various internal cleanup in the implementation and typo fixes.\n  Thanks @cuviper, @Eh2406, and @spacejam!\n\n[cargo feature]: https://doc.rust-lang.org/cargo/reference/features.html#the-features-section\n\n\n# Release 0.4.2 (2016-09-15)\n\n- Updated crates.io metadata.\n\n\n# Release 0.4.1 (2016-09-14)\n\n- New `chain` combinator for parallel iterators.\n- `Option`, `Result`, as well as many more collection types now have\n  parallel iterators.\n- New mergesort demo.\n- Misc fixes.\n\nThanks to @cuviper, @edre, @jdanford, @frewsxcv for their contributions!\n\n\n# Release 0.4 (2016-05-16)\n\n- Make use of latest versions of catch-panic and various fixes to panic propagation.\n- Add new prime sieve demo.\n- Add `cloned()` and `inspect()` combinators.\n- Misc fixes for Rust RFC 1214.\n\nThanks to @areilb1, @Amanieu, @SharplEr, and @cuviper for their contributions!\n\n\n# Release 0.3 (2016-02-23)\n\n- Expanded `par_iter` APIs now available:\n  - `into_par_iter` is now supported on vectors (taking ownership of the elements)\n- Panic handling is much improved:\n  - if you use the Nightly feature, experimental panic recovery is available\n  - otherwise, panics propagate out and poision the workpool\n- New `Configuration` object to control number of threads and other details\n- New demos and benchmarks\n  - try `cargo run --release -- visualize` in `demo/nbody` :)\n    - Note: a nightly compiler is required for this demo due to the\n      use of the `+=` syntax\n\nThanks to @bjz, @cuviper, @Amanieu, and @willi-kappler for their contributions!\n\n\n# Release 0.2 and earlier\n\nNo release notes were being kept at this time.\n"
        },
        {
          "name": "ci",
          "type": "tree",
          "content": null
        },
        {
          "name": "rayon-core",
          "type": "tree",
          "content": null
        },
        {
          "name": "rayon-demo",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}