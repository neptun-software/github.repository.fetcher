{
  "metadata": {
    "timestamp": 1736709316972,
    "page": 710,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjcxMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "timescale/pgvectorscale",
      "stars": 1547,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".cargo",
          "type": "tree",
          "content": null
        },
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.0205078125,
          "content": "pgvectorscale/target\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.4111328125,
          "content": "# Generated by Cargo\n# will have compiled files and executables\ndebug/\ntarget/\n\n# Remove Cargo.lock from gitignore if creating an executable, leave it for libraries\n# More information here https://doc.rust-lang.org/cargo/guide/cargo-toml-vs-cargo-lock.html\nCargo.lock\n\n# These are backup files generated by rustfmt\n**/*.rs.bk\n\n# MSVC Windows builds of rustc generate these, which store debugging information\n*.pdb\n\n.idea\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.24609375,
          "content": "repos:\n  - repo: https://github.com/doublify/pre-commit-rust\n    rev: v1.0\n    hooks:\n      - id: fmt\n        args: [\"--all\", \"--\"]\n      - id: cargo-check\n        args: [\"--\"]\n      - id: clippy\n        args: [\"--all-targets\", \"--\", \"-D\", \"warnings\"]\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 5.2177734375,
          "content": "# Contributing to pgvectorscale\n\nWe appreciate any help the community can provide to make pgvectorscale better!\n\nYou can help in different ways:\n\n* Open an [issue](https://github.com/timescale/pgvectorscale/issues) with a\n  bug report, build issue, feature request, suggestion, etc.\n\n* Fork this repository and submit a pull request\n\nFor any particular improvement you want to make, it can be beneficial to\nbegin discussion on the GitHub issues page. This is the best place to\ndiscuss your proposed improvement (and its implementation) with the core\ndevelopment team.\n\nBefore we accept any code contributions, pgvectorscale contributors need to\nsign the [Contributor License Agreement](https://cla-assistant.io/timescale/pgvectorscale) (CLA). By signing a CLA, we can\nensure that the community is free and confident in its ability to use your\ncontributions.\n\n## Development\n\nPlease follow our DEVELOPMENT doc for [instructions how to develop and test](https://github.com/timescale/pgvectorscale/blob/main/DEVELOPMENT.md).\n\n## Code review workflow\n\n* Sign the [Contributor License Agreement](https://cla-assistant.io/timescale/pgvectorscale) (CLA) if you're a new contributor.\n\n* Develop on your local branch:\n\n    * Fork the repository and create a local feature branch to do work on,\n      ideally on one thing at a time.  Don't mix bug fixes with unrelated\n      feature enhancements or stylistical changes.\n\n    * Hack away. Add tests for non-trivial changes.\n\n    * Run the [test suite](#testing) and make sure everything passes.\n\n    * When committing, be sure to write good commit messages according to [these\n      seven rules](https://chris.beams.io/posts/git-commit/#seven-rules). Doing \n      `git commit` prints a message if any of the rules is violated. \n      Stylistically,\n      we use commit message titles in the imperative tense, e.g., `Add\n      merge-append query optimization for time aggregate`.  In the case of\n      non-trivial changes, include a longer description in the commit message\n      body explaining and detailing the changes.  That is, a commit message\n      should have a short title, followed by a empty line, and then\n      followed by the longer description.\n\n    * When committing, link which GitHub issue of [this \n      repository](https://github.com/timescale/pgvectorscale/issues) is fixed or \n      closed by the commit with a [linking keyword recognised by \n      GitHub](https://docs.github.com/en/github/managing-your-work-on-github/linking-a-pull-request-to-an-issue#linking-a-pull-request-to-an-issue-using-a-keyword). \n      For example, if the commit fixes bug 123, add a line at the end of the \n      commit message with  `Fixes #123`, if the commit implements feature \n      request 321, add a line at the end of the commit message `Closes #321`.\n      This will be recognized by GitHub. It will close the corresponding issue \n      and place a hyperlink under the number.\n\n* Push your changes to an upstream branch:\n\n    * Make sure that each commit in the pull request will represent a\n      logical change to the code, will compile, and will pass tests.\n\n    * Make sure that the pull request message contains all important \n      information from the commit messages including which issues are\n      fixed and closed. If a pull request contains one commit only, then\n      repeating the commit message is preferred, which is done automatically\n      by GitHub when it creates the pull request.\n\n    * Rebase your local feature branch against main (`git fetch origin`,\n      then `git rebase origin/main`) to make sure you're\n      submitting your changes on top of the newest version of our code.\n\n    * When finalizing your PR (i.e., it has been approved for merging),\n      aim for the fewest number of commits that\n      make sense. That is, squash any \"fix up\" commits into the commit they\n      fix rather than keep them separate. Each commit should represent a\n      clean, logical change and include a descriptive commit message.\n\n    * Push your commit to your upstream feature branch: `git push -u <yourfork> my-feature-branch`\n\n* Create and manage pull request:\n\n    * [Create a pull request using GitHub](https://help.github.com/articles/creating-a-pull-request).\n      If you know a core developer well suited to reviewing your pull\n      request, either mention them (preferably by GitHub name) in the PR's\n      body or [assign them as a reviewer](https://help.github.com/articles/assigning-issues-and-pull-requests-to-other-github-users/).\n\n    * Address feedback by amending your commit(s). If your change contains\n      multiple commits, address each piece of feedback by amending that\n      commit to which the particular feedback is aimed.\n\n    * The PR is marked as accepted when the reviewer thinks it's ready to be\n      merged.  Most new contributors aren't allowed to merge themselves; in\n      that case, we'll do it for you.\n\n## Testing\n\nEvery non-trivial change to the code base should be accompanied by a\nrelevant addition to or modification of the test suite.\n\nPlease check that the full test suite (including your test additions\nor changes) passes successfully on your local machine **before you\nopen a pull request**.\n\nSee our [testing](https://github.com/timescale/pgvectorscale/blob/main/DEVELOPMENT.md#testing)\ninstructions for help with how to test.\n"
        },
        {
          "name": "Cargo.toml",
          "type": "blob",
          "size": 0.1767578125,
          "content": "[workspace]\nmembers = [\"pgvectorscale\"]\nresolver = \"2\"\n\n[profile.dev]\npanic = \"unwind\"\n\n[profile.release]\npanic = \"unwind\"\nopt-level = 3\nlto = \"fat\"\ncodegen-units = 1\n#debug = true\n"
        },
        {
          "name": "DEVELOPMENT.md",
          "type": "blob",
          "size": 1.865234375,
          "content": "# Setup your pgvectorscale developer environment\n\nYou build pgvectorscale from source, then integrate the extension into each database in your PostgreSQL environment. \n\n## pgvectorscale prerequisites\n\nTo create a pgvectorscale developer environment, you need the following on your local machine:\n\n* [PostgreSQL v16](https://docs.timescale.com/self-hosted/latest/install/installation-linux/#install-and-configure-timescaledb-on-postgresql)\n* [pgvector](https://github.com/pgvector/pgvector/blob/master/README.md)\n* Development packages:\n    ```\n    sudo apt-get install make gcc pkg-config clang postgresql-server-dev-16 libssl-dev\n    ```\n  \n* [Rust][rust-language]:\n    ```shell\n    curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n    ```\n  \n* [Cargo-pgrx][cargo-pgrx]:\n    ```shell\n    cargo install --locked cargo-pgrx --version $(cargo metadata --format-version 1 | jq -r '.packages[] | select(.name == \"pgrx\") | .version')\n    ```\n  You must reinstall cargo-pgrx whenever you update Rust, cargo-pgrx must \n  be built with the same compiler as pgvectorscale.\n\n * The pgrx development environment:\n    ```shell\n    cargo pgrx init --pg16 pg_config\n    ```\n\n## Build and install pgvectorscale on your database\n\n1. In Terminal, clone this repository and switch to the extension subdirectory:\n\n    ```shell\n    git clone https://github.com/timescale/pgvectorscale && \\\n    cd pgvectorscale/pgvectorscale\n    ```\n\n1. Build pgvectorscale:\n\n    ```shell\n    cargo pgrx install --release\n    ```\n\n1. Connect to the database:\n\n   ```bash\n   psql -d \"postgres://<username>@<password>:<port>/<database-name>\"\n   ```\n\n1. Add pgvectorscale to your database:\n\n    ```postgresql\n    CREATE EXTENSION IF NOT EXISTS vectorscale CASCADE;\n    ```\n\n\n[pgvector]: https://github.com/pgvector/pgvector/blob/master/README.md\n[rust-language]: https://www.rust-lang.org/\n[cargo-pgrx]: https://lib.rs/crates/cargo-pgrx"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 0.8837890625,
          "content": "The PostgreSQL License\n\nPermission to use, copy, modify, and distribute this software and its\ndocumentation for any purpose, without fee, and without a written agreement\nis hereby granted, provided that the above copyright notice and this paragraph\nand the following two paragraphs appear in all copies.\n\nIN NO EVENT SHALL TIMESCALE BE LIABLE TO ANY PARTY FOR DIRECT, INDIRECT,\nSPECIAL, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, INCLUDING LOST PROFITS, ARISING\nOUT OF THE USE OF THIS SOFTWARE AND ITS DOCUMENTATION, EVEN IF Timescale HAS\nBEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nTIMESCALE SPECIFICALLY DISCLAIMS ANY WARRANTIES, INCLUDING, BUT NOT LIMITED TO,\nTHE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.\nTHE SOFTWARE PROVIDED HEREUNDER IS ON AN \"AS IS\" BASIS, AND TIMESCALE HAS NO\nOBLIGATIONS TO PROVIDE MAINTENANCE, SUPPORT, UPDATES, ENHANCEMENTS, OR\nMODIFICATIONS."
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 2.484375,
          "content": "SHELL:=/bin/bash\nROOTDIR = $(realpath .)\nRUST_SRCDIR =$(ROOTDIR)/pgvectorscale\n\nPG_CONFIG = $(shell which pg_config)\nEXTENSION=vectorscale\n\nPG_VERSION = $(shell ${PG_CONFIG} --version | awk -F'[ \\.]' '{print $$2}')\n##TODO error out if this is not PG14???\nPGRX_HOME?= ${HOME}/.pgrx\nPGRX_VERSION=0.9.8\nVECTOR_VERSION?=$(shell sed -n 's/^[[:space:]]*version[[:space:]]*=[[:space:]]*\"\\(.*\\)\"/\\1/p' pgvectorscale/Cargo.toml)\nPG_DATA=${PGRX_HOME}/data-${PG_VERSION}\n\nPG_PKGLIBDIR=$(shell ${PG_CONFIG} --pkglibdir)\nPG_SHARELIBDIR=$(shell ${PG_CONFIG} --sharedir)\n$(info pg_pkglib = $(PG_PKGLIBDIR) and pg_sharelib = $(PG_SHARELIBDIR) )\n\nMODULE_big = $(EXTENSION)\nPGXS := $(shell $(PG_CONFIG) --pgxs)\n\ninclude $(PGXS)\nPG_REGRESS='$(top_builddir)/src/test/regress/pg_regress'\nPG_REGRESS_OPTS_EXTRA=--create-role=superuser,tsdbadmin,test_role_1  --launcher=./test/runner.sh\nexport TEST_OUTPUT_DIR:=$(ROOTDIR)/test_output\nexport PG_ABS_SRCDIR:=$(ROOTDIR)/test\nexport TEST_DBNAME:=regression\n\n### default collation settings on Cloud is C.UTF-8\nPG_DEFAULT_REGRESS_LOCALE=$(shell uname | grep -q 'Darwin' && echo 'en_US.UTF-8'  || echo 'C.UTF-8')\nPG_REGRESS_LOCALE?=$(PG_DEFAULT_REGRESS_LOCALE)\nPG_REGRESS_ENV=CONFDIR='$(CURDIR)/test' TESTDIR='$(CURDIR)' LC_COLLATE=$(PG_REGRESS_LOCALE) LC_CTYPE=$(PG_REGRESS_LOCALE)\n\n#ifdef PGHOST\n#USE_EXISTING_INSTANCE=0\n#endif\n\nifdef USE_EXISTING_INSTANCE\n$(info Use existing instance)\nINSTANCE_OPTS=\nelse\n$(info Use temp instance)\nINSTANCE_OPTS=--temp-instance=$(ROOTDIR)/test_instance --temp-config=$(ROOTDIR)/test/postgres.conf\nendif\n\n.PHONY: format\nformat:\n\tcd $(RUST_SRCDIR)/src && rustfmt --edition 2021 *.rs\n\n.PHONY: build\nbuild:\n\tcd $(RUST_SRCDIR) && cargo build --features pg${PG_VERSION} $(EXTRA_RUST_ARGS)\n\n.PHONY: install-pgrx\ninstall-pgrx:\n\tcargo install cargo-pgrx --version ${PGRX_VERSION}\n\n.PHONY: init-pgrx\ninit-pgrx: $(PG_DATA)\n\n$(PG_DATA):\n\tcd $(RUST_SRCDIR) && cargo pgrx init --pg${PG_VERSION}=${PG_CONFIG}\n\n.PHONY: install-debug\n###pgxs.mk has a rule for install.So we need a different rule name\ninstall-debug: init-pgrx\n\tcd $(RUST_SRCDIR) && cargo pgrx install --features pg${PG_VERSION}\n\n.PHONY: install-release\ninstall-release: init-pgrx\n\tcd $(RUST_SRCDIR) && cargo pgrx install --release --features pg${PG_VERSION}\n\n\n.PHONY: package\npackage: init-pgrx\n\tcd $(RUST_SRCDIR) && cargo pgrx package --features pg${PG_VERSION}\n\n.PHONY: shellcheck\nshellcheck:\n\tfind . -name '*.sh' -exec shellcheck '{}' +\n\n.PHONY: shfmt\nshfmt:\n\tshfmt -w -i 4 test scripts\n\n\n.PHONY: release rust test prove install clean\n"
        },
        {
          "name": "NOTICE",
          "type": "blob",
          "size": 0.61328125,
          "content": "pgvectorscale by Timescale (TM)\n\nCopyright (c) 2023-2024  Timescale, Inc. All Rights Reserved.\n\nLicensed under the PostgreSQL License (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n   https://github.com/timescale/pgvectorscale/blob/main/LICENSE\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 11.5615234375,
          "content": "\n<p></p>\n<div align=center>\n\n# pgvectorscale\n\n<h3>pgvectorscale builds on pgvector with higher performance embedding search and cost-efficient storage for AI applications. </h3>\n\n[![Discord](https://img.shields.io/badge/Join_us_on_Discord-black?style=for-the-badge&logo=discord&logoColor=white)](https://discord.gg/KRdHVXAmkp)\n[![Try Timescale for free](https://img.shields.io/badge/Try_Timescale_for_free-black?style=for-the-badge&logo=timescale&logoColor=white)](https://tsdb.co/gh-pgvector-signup)\n</div>\n\npgvectorscale complements [pgvector][pgvector], the open-source vector data extension for PostgreSQL, and introduces the following key innovations for pgvector data:\n- A new index type called StreamingDiskANN, inspired by the [DiskANN](https://github.com/microsoft/DiskANN) algorithm, based on research from Microsoft.\n- Statistical Binary Quantization: developed by Timescale researchers, This compression method improves on standard Binary Quantization.\n\nOn a benchmark dataset of 50 million Cohere embeddings with 768 dimensions\neach, PostgreSQL with `pgvector` and `pgvectorscale` achieves **28x lower p95\nlatency** and **16x higher query throughput** compared to Pinecone's storage\noptimized (s1) index for approximate nearest neighbor queries at 99% recall,\nall at 75% less cost when self-hosted on AWS EC2.\n\n<div align=center>\n\n![Benchmarks](https://assets.timescale.com/docs/images/benchmark-comparison-pgvectorscale-pinecone.png)\n\n</div>\n\nTo learn more about the performance impact of pgvectorscale, and details about benchmark methodology and results, see the [pgvector vs Pinecone comparison blog post](http://www.timescale.com/blog/pgvector-vs-pinecone).\n\nIn contrast to pgvector, which is written in C, pgvectorscale is developed in [Rust][rust-language] using the [PGRX framework](https://github.com/pgcentralfoundation/pgrx),\noffering the PostgreSQL community a new avenue for contributing to vector support.\n\n**Application developers or DBAs** can use pgvectorscale with their PostgreSQL databases.\n   * [Install pgvectorscale](#installation)\n   * [Get started using pgvectorscale](#get-started-with-pgvectorscale)\n\nIf you **want to contribute** to this extension, see how to [build pgvectorscale from source in a developer environment](./DEVELOPMENT.md).\n\nFor production vector workloads, get **private beta access to vector-optimized databases** with pgvector and pgvectorscale on Timescale. [Sign up here for priority access](https://timescale.typeform.com/to/H7lQ10eQ).\n\n## Installation\n\nThe fastest ways to run PostgreSQL with pgvectorscale are:\n\n* [Using a pre-built Docker container](#using-a-pre-built-docker-container)\n* [Installing from source](#installing-from-source)\n* [Enable pgvectorscale in a Timescale Cloud service](#enable-pgai-in-a-timescale-cloud-service)\n\n### Using a pre-built Docker container\n\n1.  [Run the TimescaleDB Docker image](https://docs.timescale.com/self-hosted/latest/install/installation-docker/).\n\n1. Connect to your database:\n   ```bash\n   psql -d \"postgres://<username>:<password>@<host>:<port>/<database-name>\"\n   ```\n\n1. Create the pgvectorscale extension:\n\n    ```sql\n    CREATE EXTENSION IF NOT EXISTS vectorscale CASCADE;\n    ```\n\n   The `CASCADE` automatically installs `pgvector`.\n\n### Installing from source\n\nYou can install pgvectorscale from source and install it in an existing PostgreSQL server\n\n1. Compile and install the extension\n\n    ```bash\n    # install prerequisites\n    ## rust\n    curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n    ## cargo-pgrx with the same version as pgrx\n    cargo install --locked cargo-pgrx --version $(cargo metadata --format-version 1 | jq -r '.packages[] | select(.name == \"pgrx\") | .version')\n    cargo pgrx init --pg17 pg_config\n\n    #download, build and install pgvectorscale\n    cd /tmp\n    git clone --branch <version> https://github.com/timescale/pgvectorscale\n    cd pgvectorscale/pgvectorscale\n    cargo pgrx install --release\n    ```\n\n    You can also take a look at our [documentation for extension developers](./DEVELOPMENT.md) for more complete instructions.\n\n1. Connect to your database:\n   ```bash\n   psql -d \"postgres://<username>:<password>@<host>:<port>/<database-name>\"\n   ```\n\n1. Ensure the pgvector extension is available:\n\n   ```sql\n   SELECT * FROM pg_available_extensions WHERE name = 'vector';\n   ```\n\n   If pgvector is not available, install it using the [pgvector installation\n   instructions][pgvector-install].\n\n\n1. Create the pgvectorscale extension:\n\n    ```sql\n    CREATE EXTENSION IF NOT EXISTS vectorscale CASCADE;\n    ```\n\n   The `CASCADE` automatically installs `pgvector`.\n\n### Enable pgvectorscale in a Timescale Cloud service\n\nNote: the instructions below are for Timescale's standard compute instance. For production vector workloads, we’re offering **private beta access to vector-optimized databases** with pgvector and pgvectorscale on Timescale. [Sign up here for priority access](https://timescale.typeform.com/to/H7lQ10eQ).\n\nTo enable pgvectorscale:\n\n1. Create a new [Timescale Service](https://console.cloud.timescale.com/signup?utm_campaign=vectorlaunch).\n\n   If you want to use an existing service, pgvectorscale is added as an available extension on the first maintenance window\n   after the pgvectorscale release date.\n\n1. Connect to your Timescale service:\n   ```bash\n   psql -d \"postgres://<username>:<password>@<host>:<port>/<database-name>\"\n   ```\n\n1. Create the pgvectorscale extension:\n\n    ```postgresql\n    CREATE EXTENSION IF NOT EXISTS vectorscale CASCADE;\n    ```\n\n   The `CASCADE` automatically installs `pgvector`.\n\n\n## Get started with pgvectorscale\n\n\n1. Create a table with an embedding column. For example:\n\n    ```postgresql\n    CREATE TABLE IF NOT EXISTS document_embedding  (\n        id BIGINT PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY,\n        metadata JSONB,\n        contents TEXT,\n        embedding VECTOR(1536)\n    )\n    ```\n\n1. Populate the table.\n\n   For more information, see the [pgvector instructions](https://github.com/pgvector/pgvector/blob/master/README.md#storing) and [list of clients](https://github.com/pgvector/pgvector/blob/master/README.md#languages).\n1. Create a StreamingDiskANN index on the embedding column:\n    ```postgresql\n    CREATE INDEX document_embedding_idx ON document_embedding\n    USING diskann (embedding vector_cosine_ops);\n    ```\n1. Find the 10 closest embeddings using the index.\n\n    ```postgresql\n    SELECT *\n    FROM document_embedding\n    ORDER BY embedding <=> $1\n    LIMIT 10\n    ```\n\n    Note: pgvectorscale currently supports: cosine distance (`<=>`) queries, for indices created with `vector_cosine_ops`; L2 distance (`<->`) queries, for indices created with `vector_l2_ops`; and inner product (`<#>`) queries, for indices created with `vector_ip_ops`.  This is the same syntax used by `pgvector`.  If you would like additional distance types,\n    [create an issue](https://github.com/timescale/pgvectorscale/issues).  (Note: inner product indices are not compatible with plain storage.)\n\n## Tuning\n\nThe StreamingDiskANN index comes with **smart defaults** but also the ability to customize its behavior. There are two types of parameters: index build-time parameters that are specified when an index is created and query-time parameters that can be tuned when querying an index.\n\nWe suggest setting the index build-time paramers for major changes to index operations while query-time parameters can be used to tune the accuracy/performance tradeoff for individual queries.\n\n We expect most people to tune the query-time parameters (if any) and leave the index build time parameters set to default.\n\n### StreamingDiskANN index build-time parameters\n\nThese parameters can be set when an index is created.\n\n| Parameter name   | Description                                                                                                                                                    | Default value |\n|------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------|\n| `storage_layout` | `memory_optimized` which uses SBQ to compress vector data or `plain` which stores data uncompressed | memory_optimized\n| `num_neighbors`    | Sets the maximum number of neighbors per node. Higher values increase accuracy but make the graph traversal slower.                                           | 50            |\n| `search_list_size` | This is the S parameter used in the greedy search algorithm used during construction. Higher values improve graph quality at the cost of slower index builds. | 100           |\n| `max_alpha`        | Is the alpha parameter in the algorithm. Higher values improve graph quality at the cost of slower index builds.                                              | 1.2           |\n| `num_dimensions` | The number of dimensions to index. By default, all dimensions are indexed. But you can also index less dimensions to make use of [Matryoshka embeddings](https://huggingface.co/blog/matryoshka) | 0 (all dimensions)\n| `num_bits_per_dimension` | Number of bits used to encode each dimension when using SBQ | 2 for less than 900 dimensions, 1 otherwise\n\nAn example of how to set the `num_neighbors` parameter is:\n\n```sql\nCREATE INDEX document_embedding_idx ON document_embedding\nUSING diskann (embedding) WITH(num_neighbors=50);\n```\n\n#### StreamingDiskANN query-time parameters\n\nYou can also set two parameters to control the accuracy vs. query speed trade-off at query time. We suggest adjusting `diskann.query_rescore` to fine-tune accuracy.\n\n| Parameter name   | Description                                                                                                                                                    | Default value |\n|------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------|\n| `diskann.query_search_list_size` | The number of additional candidates considered during the graph search. | 100\n| `diskann.query_rescore` | The number of elements rescored (0 to disable rescoring) | 50\n\n\nYou can set the value by using `SET` before executing a query. For example:\n\n```sql\nSET diskann.query_rescore = 400;\n```\n\nNote the [SET command](https://www.postgresql.org/docs/current/sql-set.html) applies to the entire session (database connection) from the point of execution. You can use a transaction-local variant using `LOCAL` which will\nbe reset after the end of the transaction:\n\n```sql\nBEGIN;\nSET LOCAL diskann.query_search_list_size= 10;\nSELECT * FROM document_embedding ORDER BY embedding <=> $1 LIMIT 10\nCOMMIT;\n```\n\n## Get involved\n\npgvectorscale is still at an early stage. Now is a great time to help shape the\ndirection of this project; we are currently deciding priorities. Have a look at the\nlist of features we're thinking of working on. Feel free to comment, expand\nthe list, or hop on the Discussions forum.\n\n## About Timescale\n\nTimescale is a PostgreSQL cloud company. To learn more visit the [timescale.com](https://www.timescale.com).\n\n[Timescale Cloud](https://console.cloud.timescale.com/signup?utm_campaign=vectorlaunch) is a high-performance, developer focused, cloud platform that provides PostgreSQL services for the most demanding AI, time-series, analytics, and event workloads. Timescale Cloud is ideal for production applications and provides high availability, streaming backups, upgrades over time, roles and permissions, and great security.\n\n\n[pgvector]: https://github.com/pgvector/pgvector/blob/master/README.md\n[rust-language]: https://www.rust-lang.org/\n[pgvector-install]: https://github.com/pgvector/pgvector?tab=readme-ov-file#installation\n"
        },
        {
          "name": "pgvectorscale",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}