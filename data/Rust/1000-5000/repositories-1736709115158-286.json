{
  "metadata": {
    "timestamp": 1736709115158,
    "page": 286,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI5MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "headwaymaps/headway",
      "stars": 2663,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".arg",
          "type": "blob",
          "size": 0,
          "content": ""
        },
        {
          "name": ".earthlyignore",
          "type": "blob",
          "size": 0.01171875,
          "content": "*/*/target/\n"
        },
        {
          "name": ".env-example",
          "type": "blob",
          "size": 1.7626953125,
          "content": "# The named area to download if using a prebuilt extract (e.g. Amsterdam) or\n# the filename (without extension) of a local extract (e.g. planet-v1.19).\n# NOTE: This is case sensitive.\nHEADWAY_AREA=Amsterdam\n\n# A space-delimited list of lng/lat pairs describing the bounding box of your\n# OSM extract.\n#\n# The format is `west_lng south_lat east_lng north_lat`.\n#\n# The easiest way to get these pairs is probably to go on google maps and\n# estimate the locations for the southwest and northeast points of your\n# extract. You can long-click on a point on the map and it'll show you\n# coordinates. If you generated your OSM extract yourself using Osmium you can\n# just copy the bounding box from the command you used to create it.\nHEADWAY_BBOX=\"4.535 52.205 5.211 52.525\"\n\n# If you've prepared the transit feeds and passed them into the build process,\n# you can enable transit routing, otherwise leave this disabled.\nHEADWAY_ENABLE_TRANSIT_ROUTING=0\n\n# A base URL for the domain you wish to serve on, paying attention to scheme\n# (http vs https), domain, and port (if not default).\n# e.g. \"https://example.com\", \"http://maps.my.cool.intranet\" or \"https://maps.example.com:8080\".\n# NOTE: Please omit the trailing slash.\nHEADWAY_PUBLIC_URL=http://127.0.0.1:8080\n\nHEADWAY_HTTP_PORT=8080\n\nHEADWAY_ABOUT_URL=\"https://about.maps.earth\"\nHEADWAY_ABOUT_LINK_TEXT=\"About maps.earth\"\nHEADWAY_CONTACT_URL=\"mailto:info@maps.earth?subject=Hello,%20Earth\"\nHEADWAY_CONTACT_LINK_TEXT=\"Contact Us\"\n\n##\n# The following are only needed for the scripts in bin/*\n# If you're not using them, we can leave these blank.\n##\n\n# The bucket to upload your map data to\nexport HEADWAY_S3_BUCKET=\"\"\n\n# Where artifacts are downloaded from by k8s init-containers\nexport HEADWAY_K8S_ARTIFACT_ROOT=\"https://data.example.com${HEADWAY_S3_BUCKET}\"\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.056640625,
          "content": ".tmp_*\n*.swp\n*.osm.pbf\n*.mbtiles\n**/.DS_Store\ndata/*\n.env\n"
        },
        {
          "name": "ARCHITECTURE.md",
          "type": "blob",
          "size": 0.71484375,
          "content": "# Headway is:\n\n1. a bunch of other projects stitched together\n2. a consolidated build system for those projects\n3. a web frontend\n\n## Components\n\n- web frontend\n  - custom quasar/vue.js app in [services/frontend](https://github.com/headwaymaps/headway/tree/main/services/frontend)\n- build system\n  -  Earthly [read more](https://github.com/headwaymaps/headway/blob/main/BUILD.md)\n- map tiles\n  - tile building: [planetiler](https://github.com/onthegomap/planetiler)\n  - tile server: https://www.npmjs.com/package/tileserver-gl-light\n- geocoding: \n  - [pelias](https://pelias.io/)\n- routing\n  - bike, pedestrian, cars: [valhalla](https://github.com/valhalla/valhalla)\n  - transit: [OpenTripPlanner](http://www.opentripplanner.org/)\n\n"
        },
        {
          "name": "BUILD.md",
          "type": "blob",
          "size": 7.01171875,
          "content": "# Building Headway\n\nSetting up your own Headway instance should be fairly straightforward if you follow these docs. Feel free to open bugs if things go wrong, or PRs to improve the project though!\n\nThere is a script contributed by Santiago Crespo that will automatically deploy Headway as a systemd service on Debian, but it has not been widely tested yet. See [contrib/DEBIAN_BUILD.md](./contrib/DEBIAN_BUILD.md) for details.\n\nPrerequisites: [Install earthly.](#install-earthly)\n\n[Option 1: Building from a pre-configured city](#building-headway-from-a-supported-bbbike-extract)\n\n[Option 2: Building from your own OSM extract](#building-headway-from-your-own-osm-extract)\n\n[Option 3: Building Headway for the whole planet](#full-planet-considerations)\n\n## Install Earthly\n\nHeadway processes data and builds its containers for hosting using Earthly. Earthly is a build system (like a Makefile) for orchestrating a bunch of depdendent docker containers. \n\nInstructions for installing the cloud-free version of earthly can be found here: https://earthly.dev/get-earthly\n\n⚠️ The earthly company has a cloud product that they will try to upsell you, but **you do not need to create an account** or use their cloud product to build Headway. I only ever use their account-free local client and recommend you start there as well.\n\n## Supported Build Methods\n\nHeadway can be built using a BBBike extract if one exists for a metro area you're interested in, or you can supply your own `.osm.pbf` file to cover areas that BBBike doesn't cover, or larger areas like US states or European countries.\n\n### Building Headway from a supported BBBike extract\n\nThis section pertains to builds from BBBike extracts. Skip this if you know you need to bring your own OpenStreetMap extract.\n\n#### Currently supported cities\n\nHeadway currently supports fully automatic builds for the following cities:\n\n<details>\n  <summary>Supported cities</summary>\n   Aachen, Aarhus, Adelaide, Albuquerque, Alexandria, Amsterdam, Antwerpen, Arnhem, Auckland, Augsburg, Austin, Baghdad, Baku, Balaton, Bamberg, Bangkok, Barcelona, Basel, Beijing, Beirut, Berkeley, Berlin, Bern, Bielefeld, Birmingham, Bochum, Bogota, Bombay, Bonn, Bordeaux, Boulder, BrandenburgHavel, Braunschweig, Bremen, Bremerhaven, Brisbane, Bristol, Brno, Bruegge, Bruessel, Budapest, BuenosAires, Cairo, Calgary, Cambridge, CambridgeMa, Canberra, CapeTown, Chemnitz, Chicago, ClermontFerrand, Colmar, Copenhagen, Cork, Corsica, Corvallis, Cottbus, Cracow, CraterLake, Curitiba, Cusco, Dallas, Darmstadt, Davis, DenHaag, Denver, Dessau, Dortmund, Dresden, Dublin, Duesseldorf, Duisburg, Edinburgh, Eindhoven, Emden, Erfurt, Erlangen, Eugene, Flensburg, FortCollins, Frankfurt, FrankfurtOder, Freiburg, Gdansk, Genf, Gent, Gera, Glasgow, Gliwice, Goerlitz, Goeteborg, Goettingen, Graz, Groningen, Halifax, Halle, Hamburg, Hamm, Hannover, Heilbronn, Helsinki, Hertogenbosch, Huntsville, Innsbruck, Istanbul, Jena, Jerusalem, Johannesburg, Kaiserslautern, Karlsruhe, Kassel, Katowice, Kaunas, Kiel, Kiew, Koblenz, Koeln, Konstanz, LakeGarda, LaPaz, LaPlata, Lausanne, Leeds, Leipzig, Lima, Linz, Lisbon, Liverpool, Ljubljana, Lodz, London, Luebeck, Luxemburg, Lyon, Maastricht, Madison, Madrid, Magdeburg, Mainz, Malmoe, Manchester, Mannheim, Marseille, Melbourne, Memphis, MexicoCity, Miami, Minsk, Moenchengladbach, Montevideo, Montpellier, Montreal, Moscow, Muenchen, Muenster, NewDelhi, NewOrleans, NewYork, Nuernberg, Oldenburg, Oranienburg, Orlando, Oslo, Osnabrueck, Ostrava, Ottawa, Paderborn, Palma, PaloAlto, Paris, Perth, Philadelphia, PhnomPenh, Portland, PortlandME, Porto, PortoAlegre, Potsdam, Poznan, Prag, Providence, Regensburg, Riga, RiodeJaneiro, Rostock, Rotterdam, Ruegen, Saarbruecken, Sacramento, Saigon, Salzburg, SanFrancisco, SanJose, SanktPetersburg, SantaBarbara, SantaCruz, Santiago, Sarajewo, Schwerin, Seattle, Seoul, Sheffield, Singapore, Sofia, Stockholm, Stockton, Strassburg, Stuttgart, Sucre, Sydney, Szczecin, Tallinn, Tehran, Tilburg, Tokyo, Toronto, Toulouse, Trondheim, Tucson, Turin, UlanBator, Ulm, Usedom, Utrecht, Vancouver, Victoria, WarenMueritz, Warsaw, WashingtonDC, Waterloo, Wien, Wroclaw, Wuerzburg, Wuppertal, Zagreb, Zuerich\n</details>\n\n#### Build procedure.\n\n1. Pick a metro area from the list above, like \"Amsterdam\" or \"Denver\". These values are case-sensitive.\n2. (Optional) Set up GTFS feeds for public transit routing. This dramatically increases hardware requirements for large metro areas.\n   1. Run `earthly -P +gtfs-enumerate --area=\"Amsterdam\"`, replacing \"Amsterdam\" with your metro area of choice.\n   2. Examine `data/Amsterdam.gtfs_feeds.csv` and manually edit it if necessary to curate GTFS feeds. Some may have errors, and many may be useless for your purposes.\n3. Execute `earthly -P +build --area=\"Amsterdam\"` using your chosen metro area, or if you want public transit routing, run `earthly -P +build --area=\"Amsterdam\" --transit_feeds=\"data/Amsterdam.gts_feeds.csv` using your chosen metro area.\n4. Make a `.env` file with your configuration. See `.env.example` for documentation and defaults.\n5. Execute `docker-compose up -d` to bring up a headway server on port 8080.\n6. (For https and non-default port use only) reverse-proxy traffic to port 8080.\n\nThat's it! In the future I'd like to have a kubernetes config to further productionize this project.\n\n### Building Headway from your own OSM extract\n\nUsing a custom OSM extract is a bit more complicated, and less regularly tested. Please report issues if you have any. Transit trip planning isn't currently supported for arbitrary OSM extracts, contributions are welcome though!\n\n1. Copy your OSM extract into Headway's top-level directory (same directory as this file), as e.g. `./california.osm.pbf`. It is important to name it something different than the cities listed above. For example, if I was building a custom extract of Amsterdam to avoid conflicts I would name it `AmsterdamCustom`.\n2. Execute `earthly -P +build --area=\"california\" --countries=\"US\"` replacing `california` with the name (no extension) of your OSM extract, and `US` with a comma-separated list of the countries that the extract covers.\nCountries should be provided as two-character [ISO-3166-1 codes](https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2)\nThis specifies which data to download from Who's On First. Accidentally including a country won't harm anything but it will cause needless downloads. You may wish to simply put `ALL` which will download data for the whole planet (potentially tens of gigabytes).\n3. Make a `.env` file with configuration. See/copy `.env.example` for defaults. In particular:\n\n## Docker-compose restarts\n\nBecause Headway's docker-compose configuration uses init containers to populate a docker volume containing internal data, rebuilding the data for a metro area won't update existing containers. It's necessary to run `docker-compose down --volumes` to re-initialize the data in the init containers.\n\nThis is necessary whenever you rebuild the data for a metro area, or change which area you're serving data for in the `.env` file.\n\n## Full-planet considerations\n\nSee [FULL_PLANET.md](./FULL_PLANET.md).\n"
        },
        {
          "name": "Earthfile",
          "type": "blob",
          "size": 28.748046875,
          "content": "VERSION 0.8\n\n##############################\n# OSM extract\n##############################\nARG --global is_planet_build = false\n\nbuild:\n    # The name of <area>.osm.pbf if you've downloaded a custom extract, or the\n    # name of one of the pre-configured downloadable extracts available from\n    # bbike.org\n    ARG --required area\n\n    # `countries` is used by whosonfirst dataset.\n    # If left blank we try to guess the country based on the area argument.\n    # Use the special value `ALL` when doing a planet build.\n    ARG countries\n\n    # tag for created docker containers\n    ARG tags=\"dev\"\n\n    # Run +gtfs-enumerate to build an appropriate input for transit_feeds.\n    # If omitted, you cannot enable transit routing.\n    ARG transit_feeds\n\n    BUILD +save --area=${area} --countries=${countries} --transit_feeds=${transit_feeds}\n    BUILD +images --tags=${tags}\n\nsave:\n    FROM +save-base\n    ARG --required area\n    ARG countries\n    ARG transit_feeds\n    BUILD +save-extract --area=${area}\n    BUILD +save-mbtiles --area=${area}\n    IF [ ! -z \"${transit_feeds}\" ]\n        BUILD +save-gtfs --area=${area} --transit_feeds=${transit_feeds}\n        BUILD +save-otp-graph --area=${area} --transit_feeds=${transit_feeds} --clip_to_gtfs=0\n    END\n    BUILD +save-valhalla --area=${area}\n    BUILD +save-pelias --area=${area} --countries=${countries}\n    BUILD +save-tileserver-terrain\n\nsave-pelias:\n    FROM +save-base\n    ARG --required area\n    ARG countries\n    BUILD +save-elasticsearch --area=${area} --countries=${countries}\n    BUILD +save-placeholder --area=${area} --countries=${countries}\n    BUILD +save-pelias-config --area=${area} --countries=${countries}\n\nsave-polylines:\n    FROM +save-base\n    ARG --required area\n    RUN mkdir -p /data\n    COPY (+valhalla-build-polylines/polylines.0sv --area=${area}) /data/polylines.0sv\n    # This isn't used at runtime, but it can be useful when doing a\n    # planet-scale import of pelias outside of earthly.\n    SAVE ARTIFACT /data/polylines.0sv AS LOCAL ./data/${area}-polylines.0sv\n\nsave-extract:\n    FROM +save-base\n    ARG --required area\n    COPY (+extract/data.osm.pbf --area=${area}) /data.osm.pbf\n    # This isn't used at runtime, but it might be useful to archive the input\n    SAVE ARTIFACT /data.osm.pbf AS LOCAL ./data/${area}.osm.pbf\n\nsave-transit-zones:\n    ARG --required area\n    ARG --required transit_zones\n    ARG otp_build_config\n    BUILD +save-gtfs-zones --area=${area} --transit_zones=${transit_zones}\n    BUILD +save-otp-zones --area=${area} --transit_zones=${transit_zones} --otp_build_config=${otp_build_config}\n\nsave-gtfs-zones:\n    FROM +save-base\n    ARG --required area\n    ARG --required transit_zones\n    FOR transit_feeds IN $transit_zones\n        BUILD +save-gtfs --area=${area} --transit_feeds=${transit_feeds}\n    END\n\nsave-gtfs:\n    FROM +save-base\n    ARG --required area\n    ARG --required transit_feeds\n\n    COPY +cache-buster/todays_date .\n    ARG cache_key=$(cat todays_date)\n\n    ARG output_prefix=$(basename $transit_feeds .gtfs_feeds.csv)\n\n    COPY (+gtfs-build/gtfs --transit_feeds=${transit_feeds} --cache_key=${cache_key}) /gtfs\n    RUN tar --use-compress-program=\"zstd -T0\" -cf /gtfs.tar.zst -C /gtfs .\n    # This isn't used at runtime, but it might be useful to archive the input\n    SAVE ARTIFACT /gtfs.tar.zst AS LOCAL ./data/${area}-${output_prefix}-${cache_key}.gtfs.tar.zst\n\nsave-otp-zones:\n    FROM +save-base\n    ARG --required area\n    # List of filenames. Each file corresponds to an OTP graph to output. Each row in each file references a GTFS feeds input to that OTP graph.\n    ARG --required transit_zones\n    ARG otp_build_config\n    FOR transit_feeds IN $transit_zones\n        BUILD +save-otp-graph --area=${area} --transit_feeds=${transit_feeds} --clip_to_gtfs=1 --otp_build_config=${otp_build_config}\n        BUILD +save-otp-router-config --transit_feeds=${transit_feeds}\n    END\n\nsave-otp-graph:\n    FROM +save-base\n    ARG --required area\n    ARG --required transit_feeds\n    ARG --required clip_to_gtfs\n    ARG otp_build_config\n\n    # When working with a very large (e.g. planet sized) osm.pbf, we can't support\n    # transit for the entire thing, but we can support smaller transit zones within the\n    # planet.\n    # We extract a bbox'd area of the input osm.pbf around the actual transit\n    # zone for OTP to have any chance of fitting into memory.\n    ARG transit_zone=$(basename $transit_feeds .gtfs_feeds.csv)\n    IF [ -n \"$clip_to_gtfs\" ]\n        ARG output_name=\"${area}-${transit_zone}\"\n    ELSE\n        ARG clip_to_gtfs=0\n        ARG output_name=\"${transit_zone}\"\n    END\n\n    COPY +cache-buster/todays_date .\n    ARG cache_key=$(cat todays_date)\n\n    COPY (+otp-build-graph/graph.obj --area=${area} \\\n                               --clip_to_gtfs=${clip_to_gtfs} \\\n                               --transit_feeds=${transit_feeds} \\\n                               --cache_key=${cache_key} \\\n                               --otp_build_config=${otp_build_config} \\\n    ) /graph.obj\n\n    RUN zstd -T0 /graph.obj\n    SAVE ARTIFACT /graph.obj.zst AS LOCAL ./data/${output_name}-${cache_key}.graph.obj.zst\n\nsave-mbtiles:\n    FROM +save-base\n    ARG --required area\n    COPY (+planetiler-build-mbtiles/output.mbtiles --area=${area}) /output.mbtiles\n    SAVE ARTIFACT /output.mbtiles AS LOCAL ./data/${area}.mbtiles\n\nsave-valhalla:\n    FROM +save-base\n    ARG --required area\n    COPY (+valhalla-build/tiles --area=${area}) /valhalla\n    RUN tar --use-compress-program=\"zstd -T0\" -cf /valhalla.tar.zst -C /valhalla .\n    SAVE ARTIFACT /valhalla.tar.zst AS LOCAL ./data/${area}.valhalla.tar.zst\n\nsave-elasticsearch:\n    FROM +save-base\n    ARG --required area\n    ARG countries\n    COPY (+pelias-import/elasticsearch --area=${area} --countries=${countries}) /elasticsearch\n    RUN tar --use-compress-program=\"zstd -T0\" -cf /elasticsearch.tar.zst -C /elasticsearch .\n    SAVE ARTIFACT /elasticsearch.tar.zst AS LOCAL ./data/${area}.elasticsearch.tar.zst\n\nsave-placeholder:\n    FROM +save-base\n    ARG --required area\n    ARG countries\n    COPY (+pelias-prepare-placeholder/placeholder --countries=${countries}) /placeholder\n    RUN tar --use-compress-program=\"zstd -T0\" -cf /placeholder.tar.zst -C /placeholder .\n    SAVE ARTIFACT /placeholder.tar.zst AS LOCAL ./data/${area}.placeholder.tar.zst\n\nsave-pelias-config:\n    FROM +save-base\n    ARG --required area\n    ARG countries\n    COPY (+pelias-config/pelias.json --area=${area} --countries=${countries}) /pelias.json\n    SAVE ARTIFACT /pelias.json AS LOCAL ./data/${area}.pelias.json\n\nsave-tileserver-terrain:\n    FROM +downloader-base\n    ARG asset_root=https://github.com/headwaymaps/headway-data/raw/main/tiles/\n    RUN wget -nv ${asset_root}/terrain.mbtiles\n    SAVE ARTIFACT terrain.mbtiles AS LOCAL ./data/terrain.mbtiles\n    RUN wget -nv ${asset_root}/landcover.mbtiles\n    SAVE ARTIFACT landcover.mbtiles AS LOCAL ./data/landcover.mbtiles\n\nimages:\n    FROM debian:bookworm-slim\n    ARG tags=\"dev\"\n    ARG branding\n    BUILD +travelmux-serve-image --tags=${tags}\n    BUILD +otp-serve-image --tags=${tags}\n    BUILD +valhalla-serve-image --tags=${tags}\n    BUILD +web-serve-image --tags=${tags} --branding=${branding}\n    BUILD +tileserver-serve-image --tags=${tags}\n    BUILD +otp-init-image --tags=${tags}\n    BUILD +valhalla-init-image --tags=${tags}\n    BUILD +web-init-image --tags=${tags}\n    BUILD +tileserver-init-image --tags=${tags}\n    BUILD +pelias-init-image --tags=${tags}\n\nextract:\n    FROM +downloader-base\n    ARG --required area\n    ARG clip_bbox\n\n    RUN apt-get update \\\n        && apt-get install -y --no-install-recommends osmium-tool \\\n        && rm -rf /var/lib/apt/lists/*\n\n    WORKDIR /data\n\n    COPY --if-exists ${area}.osm.pbf data.osm.pbf\n    IF [ ! -f data.osm.pbf ]\n        RUN wget -nv -U headway/1.0 -O data.osm.pbf \"https://download.bbbike.org/osm/bbbike/${area}/${area}.osm.pbf\"\n    END\n\n    IF [ ! -f data.osm.pbf ]\n        RUN echo \"osm file not found\"\n        RUN exit 1\n    END\n\n    IF [ -n \"${clip_bbox}\" ]\n        # I don't understand why the following line doesn't work:\n        #    ARG comma_separated_bbox=$(echo ${clip_bbox} | sed 's/ /,/g')\n        # ... but anway, here's a 2-line work around:\n        RUN echo ${clip_bbox} | sed 's/ /,/g' > comma_separated_bbox.txt\n        ARG comma_separated_bbox=$(cat comma_separated_bbox.txt)\n\n        # It'd be nice to mv rather than cp, but I get this weird error:\n        # >    mv: cannot move 'data.osm.pbf' to a subdirectory of itself, 'unclipped.osm.pbf'\n        # I'm not sure if this is a bug with large files+docker+zfs or what.\n        # RUN mv data.osm.pbf unclipped.osm.pbf && \\\n        RUN cp data.osm.pbf unclipped.osm.pbf && rm data.osm.pbf && \\\n            osmium extract --bbox=\"$comma_separated_bbox\" unclipped.osm.pbf --output=data.osm.pbf && \\\n            rm unclipped.osm.pbf\n    END\n\n    SAVE ARTIFACT /data/data.osm.pbf /data.osm.pbf\n\n##############################\n# Pelias\n##############################\n\npelias-init-image:\n    FROM +downloader-base\n    RUN mkdir -p /app\n    COPY ./services/pelias/init* /app/\n    CMD [\"echo\", \"run a specific command\"]\n    ARG --required tags\n    FOR tag IN ${tags}\n        SAVE IMAGE --push ghcr.io/headwaymaps/pelias-init:${tag}\n    END\n\n# We use this both for import and for production pelias instances.\n# But we might want to try a longer timeout for the import process?\npelias-config:\n    FROM node:20-slim\n\n    ARG --required area\n    ARG countries\n\n    COPY services/pelias/generate_config ./generate_config\n    WORKDIR ./generate_config\n\n    RUN yarn install && yarn build\n    RUN bin/generate-pelias-config areas.csv \"${area}\" \"${countries}\" > pelias.json\n    SAVE ARTIFACT pelias.json /pelias.json\n\npelias-import-base:\n    FROM earthly/dind:alpine\n    ARG --required area\n    ARG countries\n\n    WORKDIR /pelias-import\n\n    RUN mkdir /data && chmod -R uga=rwX /data\n    ENV DATA_DIR=/data\n\n    COPY (+pelias-config/pelias.json --area=${area} --countries=${countries}) pelias.json\n    COPY services/pelias/docker-compose-import.yaml compose.yaml\n    COPY services/pelias/wait.sh ./tools/wait.sh\n    COPY services/pelias/do-if-openaddresses-supported ./\n\n    # Cache needed data in the base image so that multiple subsequent images don't need to\n    # copy them individually.\n    COPY (+extract/data.osm.pbf --area=${area}) /data/openstreetmap/data.osm.pbf\n    WITH DOCKER --compose compose.yaml --service pelias_whosonfirst \\\n                                       --service pelias_openaddresses\n        RUN docker-compose run -T 'pelias_whosonfirst' ./bin/download && \\\n            ./do-if-openaddresses-supported docker-compose run -T 'pelias_openaddresses' ./bin/download\n    END\n\npelias-prepare-placeholder:\n    ARG --required area\n    ARG countries\n    FROM +pelias-import-base --area=${area} --countries=${countries}\n\n    WITH DOCKER --compose compose.yaml --service pelias_placeholder\n        RUN docker-compose run -T 'pelias_placeholder' bash -c \"./cmd/extract.sh && ./cmd/build.sh\"\n    END\n    SAVE ARTIFACT /data/placeholder /placeholder\n\npelias-import:\n    ARG --required area\n    ARG countries\n    FROM +pelias-import-base --area=${area} --countries=${countries}\n\n    COPY (+valhalla-build-polylines/polylines.0sv --area=${area}) /data/polylines/extract.0sv\n\n    RUN mkdir -p /data/elasticsearch && chmod 777 /data/elasticsearch\n\n    WITH DOCKER --compose compose.yaml --service pelias_schema \\\n                                       --service pelias_openstreetmap \\\n                                       --service pelias_openaddresses \\\n                                       --service pelias_whosonfirst \\\n                                       --service pelias_polylines_import\n\n        RUN docker-compose run -T 'pelias_schema' /tools/wait.sh && \\\n            docker-compose run -T 'pelias_schema' ./bin/create_index && \\\n            docker-compose run -T 'pelias_whosonfirst' ./bin/start && \\\n            ./do-if-openaddresses-supported docker-compose run -T 'pelias_openaddresses' ./bin/start && \\\n            docker-compose run -T 'pelias_openstreetmap' ./bin/start && \\\n            docker-compose run -T 'pelias_polylines_import' ./bin/start\n    END\n\n    SAVE ARTIFACT /data/elasticsearch /elasticsearch\n\n##############################\n# Planetiler\n##############################\n\nplanetiler-build-mbtiles:\n    FROM ghcr.io/onthegomap/planetiler:0.7.0\n\n    RUN mkdir -p /data/sources\n    RUN curl --no-progress-meter https://f000.backblazeb2.com/file/headway/sources.tar | tar -x --directory /data/sources\n\n    ARG --required area\n    COPY (+extract/data.osm.pbf --area=${area}) /data/\n\n    # Instead of a docker-in-docker thing here, we could extend from the planetiler base image,\n    # but the Entrypoint feels a little strange to hardcode since it's not a typical binary.\n    # Presumably this is some automated java+docker build thing.\n    # \"Entrypoint\": [\n    #     \"java\",\n    #     \"-cp\",\n    #     \"@/app/jib-classpath-file\",\n    #     \"com.onthegomap.planetiler.Main\"\n    # ],\n\n    COPY ./services/tilebuilder/percent-of-available-memory .\n\n    IF [ \"$is_planet_build\" = \"false\" ]\n      RUN --entrypoint -- \\\n          --osm_path=/data/data.osm.pbf \\\n          --force\n    ELSE\n      RUN --entrypoint -- \\\n          -Xmx$(./percent-of-available-memory 75) \\\n          `# return unused heap memory to the OS` \\\n          -XX:MaxHeapFreeRatio=40 \\\n          --osm_path=/data/data.osm.pbf \\\n\n          --bounds=planet \\\n          `# Store temporary node locations at fixed positions in a memory-mapped file` \\\n          --nodemap-type=array \\\n          --storage=mmap \\\n          --force\n    END\n\n\n    SAVE ARTIFACT /data/output.mbtiles /output.mbtiles\n\n##############################\n# GTFS\n##############################\n\ngtfs-base:\n    FROM python:3\n    RUN pip install requests\n    WORKDIR /gtfs\n    RUN mkdir /gtfs_feeds\n\ncache-buster:\n    FROM debian:bookworm-slim\n    RUN --no-cache echo $(date +%Y-%m-%d) > todays_date\n    SAVE ARTIFACT todays_date\n\n# Get a list of all gtfs feeds that intersect with the given area\n# Feeds are sourced from The Mobility Database Catalogs\n# https://github.com/MobilityData/mobility-database-catalogs\ngtfs-enumerate:\n    FROM +gtfs-base\n\n    COPY ./services/gtfs/filter_feeds.py /gtfs/\n\n    # Earthly caches computed ARGs - subsequent runs will use the cache_key\n    # that was computed last time, unless something else has busted the cache.\n    #\n    # Reported: https://github.com/earthly/earthly/issues/2523\n    #\n    # This is \"expected behavior\", but earthly might one day offer a better\n    # solution such as `ARG --no-cache`. In the meanwhile we have this\n    # cache-buster work around\n    COPY +cache-buster/todays_date .\n    ARG cache_key=$(cat todays_date)\n    # If Earthly does one day implement `ARG --no-cache`, we can replace the\n    # two lines above with the following:\n    #    ARG --no-cache cache_key=$(date +%Y-%m-%d)\n\n    COPY (+gtfs-get-mobilitydb/mobilitydb.csv --cache_key=${cache_key}) mobilitydb.csv\n\n    ARG --required area\n    COPY (+bbox/bbox.txt --area=${area}) bbox.txt\n    ARG bbox=$(cat bbox.txt)\n    RUN python /gtfs/filter_feeds.py --bbox=\"${bbox}\" --gtfs-rt-service-alerts < mobilitydb.csv > gtfs_feeds.csv\n\n    SAVE ARTIFACT gtfs_feeds.csv /gtfs_feeds.csv AS LOCAL ./data/${area}-${cache_key}.gtfs_feeds.csv\n\ngtfout:\n    FROM rust:bookworm\n\n    COPY ./services/gtfs/gtfout /gtfout\n    WORKDIR /gtfout\n    RUN cargo build --release\n\n    SAVE ARTIFACT target/release/gtfs-bbox gtfs-bbox\n    SAVE ARTIFACT target/release/assume-bikes-allowed assume-bikes-allowed\n\ngtfs-compute-bbox:\n    FROM debian:bookworm-slim\n\n    ARG --required transit_feeds\n    ARG --required cache_key\n\n    COPY +gtfout/gtfs-bbox .\n\n    RUN apt-get update \\\n        && apt-get install -y --no-install-recommends unzip \\\n        && rm -rf /var/lib/apt/lists/*\n\n    COPY (+gtfs-build/gtfs --transit_feeds=${transit_feeds} --cache_key=${cache_key}) /gtfs_zips\n\n    RUN mkdir gtfs && \\\n        (cd gtfs_zips && \\\n            ls *.zip | while read zip_file; do unzip -d ../gtfs/$(basename $zip_file .zip) $zip_file; done)\n\n    RUN ./gtfs-bbox gtfs/* > bbox.txt\n\n    SAVE ARTIFACT bbox.txt /bbox.txt\n\nbbox:\n    FROM debian:bookworm-slim\n    ARG --required area\n    COPY services/gtfs/bboxes.csv /gtfs/bboxes.csv\n    # ensure `area` has an entry in bboxes.csv, otherwise you'll need to add one\n    RUN test $(grep \"${area}:\" /gtfs/bboxes.csv | wc -l) -eq 1\n    RUN grep \"${area}:\" /gtfs/bboxes.csv | cut -d':' -f2 | tee bbox.txt\n    SAVE ARTIFACT bbox.txt /bbox.txt\n\ngtfs-get-mobilitydb:\n    FROM +downloader-base\n    ARG --required cache_key\n    RUN wget 'https://storage.googleapis.com/storage/v1/b/mdb-csv/o/sources.csv?alt=media' -O mobilitydb.csv\n    SAVE ARTIFACT mobilitydb.csv mobilitydb.csv AS LOCAL \"./data/mobilitydb-${cache_key}.csv\"\n\nsave-otp-router-config:\n    FROM +gtfs-base\n    ARG --required transit_feeds\n    ARG transit_zone=$(basename $transit_feeds | sed 's/.gtfs_feeds.csv//')\n\n    COPY \"${transit_feeds}\" gtfs_feeds.csv\n    COPY ./services/gtfs/filter_feeds.py /gtfs\n    COPY ./services/gtfs/otp_router_config.py /gtfs\n    WORKDIR /gtfs\n\n    RUN ./otp_router_config.py < gtfs_feeds.csv > router-config.json\n\n    SAVE ARTIFACT router-config.json /router-config.json AS LOCAL \"./data/otp/${transit_zone}-router-config.json\"\n\ngtfs-build:\n    FROM +gtfs-base\n    ARG --required transit_feeds\n    ARG --required cache_key\n\n    RUN apt-get update \\\n        && apt-get install -y --no-install-recommends zip \\\n        && rm -rf /var/lib/apt/lists/*\n\n    COPY +gtfout/assume-bikes-allowed .\n\n    COPY \"${transit_feeds}\" gtfs_feeds.csv\n    COPY ./services/gtfs/download_gtfs_feeds.py ./\n\n    # re-run when cache_key changes\n    RUN touch \"cache-buster-${cache_key}\"\n\n    RUN ./download_gtfs_feeds.py --output=downloads < gtfs_feeds.csv\n\n    RUN mkdir unzipped && \\\n        (cd downloads && \\\n            ls *.zip | while read zip_file; do unzip -d ../unzipped/$(basename $zip_file .zip) $zip_file; done)\n\n    RUN mkdir -p /output/gtfs && for gtfs in unzipped/*; do \\\n            ./assume-bikes-allowed  \\\n                < \"${gtfs}/routes.txt\" \\\n                > tmp-routes.txt \\\n            && mv tmp-routes.txt \"${gtfs}/routes.txt\" \\\n            && (cd \"$gtfs\" && zip -r \"/output/gtfs/$(basename ${gtfs}).zip\" .); \\\n        done\n\n    SAVE ARTIFACT /output/gtfs /gtfs\n\n\n##############################\n# OpenTripPlanner\n##############################\n\notp-base:\n    FROM opentripplanner/opentripplanner:2.5.0\n\n    RUN mkdir /var/opentripplanner\n\notp-build-graph:\n    FROM +otp-base\n\n    ARG --required area\n\n    # Clip the mapping data area to the transit_feeds's bbox to save memory.\n    #\n    # This option is only relevant if you are configuring small transit\n    # zones within an otherwise huge map. OTP reads all the map data into\n    # memory, which can be very large.\n    ARG clip_to_gtfs\n\n    ARG --required transit_feeds\n    ARG --required cache_key\n\n    # Optional path to configuration that specifies non-default build options\n    # See https://docs.opentripplanner.org/en/v2.2.0/BuildConfiguration\n    ARG otp_build_config\n\n    WORKDIR /var/opentripplanner\n\n    IF [ -n \"$otp_build_config\" ]\n        COPY \"${otp_build_config}\" /var/opentripplanner/build-config.json\n    END\n\n    # Note: This bounds all directions to the extent of the transit feeds, so e.g. you can't get OTP\n    # bike routing anywhere outside the bounds of the transit feeds. This should usually be fine, but it'd\n    # be nice to handle the case where someone wants biking outside of their transit graph bbox.\n    COPY (+gtfs-compute-bbox/bbox.txt --transit_feeds=${transit_feeds} --cache_key=${cache_key}) bbox.txt\n    ARG gtfs_bbox=$(cat bbox.txt)\n\n    IF [ -n \"$clip_to_gtfs\" ]\n        COPY (+extract/data.osm.pbf --area=${area} --clip_bbox=${gtfs_bbox}) /var/opentripplanner\n    ELSE\n        COPY (+extract/data.osm.pbf --area=${area}) /var/opentripplanner\n    END\n\n    COPY (+elevation/elevation-tifs --bbox=${gtfs_bbox}) /var/opentripplanner\n\n    COPY (+gtfs-build/gtfs --transit_feeds=${transit_feeds} --cache_key=${cache_key}) /var/opentripplanner\n\n    RUN --entrypoint -- --build --save\n\n    SAVE ARTIFACT /var/opentripplanner/graph.obj /graph.obj\n\ndownload-elevation:\n    FROM +valhalla-base-image\n\n    # e.g. '-122.462 47.394 -122.005 47.831'\n    # Note: this is the bbox format we use everywhere, but we need to convert it to the comma separated one that valhalla uses\n    ARG --required bbox\n\n    ARG valhalla_bbox=$(echo ${bbox} | sed 's/ /,/g')\n    RUN valhalla_build_elevation --outdir elevation-hgts --from-bbox=${valhalla_bbox}\n\n    SAVE ARTIFACT elevation-hgts\n\nelevation:\n    FROM debian:bookworm-slim\n    ARG --required bbox\n\n    RUN apt-get update \\\n        && apt-get install -y --no-install-recommends gdal-bin \\\n        && rm -rf /var/lib/apt/lists/*\n\n    COPY services/otp/dem-hgt-to-tif .\n\n    COPY (+download-elevation/elevation-hgts --bbox=${bbox}) elevation-hgts/\n\n    RUN ./dem-hgt-to-tif elevation-hgts elevation-tifs\n\n    SAVE ARTIFACT elevation-tifs\n\notp-init-image:\n    FROM +downloader-base\n    COPY ./services/otp/init.sh /app/init.sh\n    CMD [\"/app/init.sh\"]\n    ARG --required tags\n    FOR tag IN ${tags}\n        SAVE IMAGE --push ghcr.io/headwaymaps/opentripplanner-init:${tag}\n    END\n\notp-serve-image:\n    FROM +otp-base\n\n    EXPOSE 8000\n    ENV PORT 8000\n\n    # We add a layer of `sh -c` indirection in order to substitute in the PORT\n    # env variable at runtime\n    ENTRYPOINT [\"sh\", \"-c\"]\n    CMD [\"/docker-entrypoint.sh --load --port ${PORT}\"]\n\n    # used for healthcheck\n    RUN apt-get update \\\n        && apt-get install -y --no-install-recommends netcat \\\n        && rm -rf /var/lib/apt/lists/*\n\n    HEALTHCHECK --interval=5s --start-period=120s \\\n        CMD nc -z localhost ${PORT}\n\n    ARG --required tags\n    FOR tag IN ${tags}\n        SAVE IMAGE --push ghcr.io/headwaymaps/opentripplanner:${tag}\n    END\n\nbuild-travelmux:\n    FROM rust:bookworm\n\n    WORKDIR travelmux\n\n    # This speeds up rebuilds of rust projectst by caching the prebuilt\n    # dependencies in a separate docker layer. Without this, every change to\n    # the source requires re-downloading and re-building all the project deps,\n    # which takes a while.\n    COPY ./services/travelmux/Cargo.toml .\n    COPY ./services/travelmux/Cargo.lock .\n    RUN mkdir src\n    RUN echo 'fn main() { /* dummy main to get cargo to build deps */ }' > src/main.rs\n    RUN cargo build --release\n    RUN rm src/main.rs\n\n    COPY ./services/travelmux .\n    RUN cargo build --release\n    SAVE ARTIFACT target/release/travelmux-server /travelmux-server\n\ntravelmux-serve-image:\n    FROM debian:bookworm-slim\n\n    RUN apt-get update \\\n        && apt-get install -y --no-install-recommends libssl3 \\\n        && rm -rf /var/lib/apt/lists/*\n\n    RUN adduser --disabled-login travelmux --gecos \"\"\n    USER travelmux\n\n    WORKDIR /home/travelmux\n    COPY +build-travelmux/travelmux-server travelmux-server\n\n    EXPOSE 8000\n    ENV RUST_LOG=info\n    ENTRYPOINT [\"/home/travelmux/travelmux-server\"]\n    CMD [\"http://valhalla:8002\", \"http://opentripplanner:8000/otp/routers\"]\n\n    ARG --required tags\n    FOR tag IN ${tags}\n        SAVE IMAGE --push ghcr.io/headwaymaps/travelmux:${tag}\n    END\n\n##############################\n# Valhalla\n##############################\n\nvalhalla-base-image:\n    # Valhalla hasn't tagged a new version in over a year, so we track `latest`.\n    FROM ghcr.io/gis-ops/docker-valhalla/valhalla\n\n    USER root\n    WORKDIR /tiles\n    RUN chown valhalla /tiles\n    USER valhalla\n\nvalhalla-build:\n    FROM +valhalla-base-image\n\n    RUN valhalla_build_config --mjolnir-tile-dir /tiles --mjolnir-timezone /tiles/timezones.sqlite --mjolnir-admin /tiles/admins.sqlite > valhalla.json\n    RUN valhalla_build_timezones > /tiles/timezones.sqlite\n\n    ARG --required area\n\n    USER root\n    RUN mkdir -p /data/osm\n    COPY (+extract/data.osm.pbf --area=${area}) /data/osm/data.osm.pbf\n\n    USER valhalla\n    RUN valhalla_build_tiles -c valhalla.json /data/osm/data.osm.pbf\n\n    SAVE ARTIFACT /tiles /tiles\n\nvalhalla-build-polylines:\n    ARG --required area\n    FROM +valhalla-build --area=${area}\n\n    RUN valhalla_export_edges -c valhalla.json > /tiles/polylines.0sv\n\n    SAVE ARTIFACT /tiles/polylines.0sv\n\nvalhalla-init-image:\n    FROM +valhalla-base-image\n    USER root\n\n    RUN apt-get update \\\n        && apt-get install -y --no-install-recommends wget zstd \\\n        && rm -rf /var/lib/apt/lists/*\n\n    USER valhalla\n    COPY ./services/valhalla/init.sh /app/init.sh\n    ENTRYPOINT [\"/bin/bash\"]\n    USER root\n    CMD [\"/app/init.sh\"]\n    ARG --required tags\n    FOR tag IN ${tags}\n        SAVE IMAGE --push ghcr.io/headwaymaps/valhalla-init:${tag}\n    END\n\nvalhalla-serve-image:\n    FROM +valhalla-base-image\n    ENTRYPOINT [\"valhalla_service\"]\n    USER valhalla\n    CMD [\"/data/valhalla.json\"]\n    ARG --required tags\n    FOR tag IN ${tags}\n        SAVE IMAGE --push ghcr.io/headwaymaps/valhalla:${tag}\n    END\n\n##############################\n# tileserver-gl-light\n##############################\n\ntileserver-build:\n    FROM node:20-slim\n\n    COPY ./services/tileserver/assets/build_glyphs.js \\\n        ./services/tileserver/assets/build_sprites.js \\\n        ./services/tileserver/assets/package.json \\\n        ./services/tileserver/assets/package-lock.json \\\n        ./services/tileserver/assets/*.ttf \\\n        /app/\n\n    WORKDIR /app\n    RUN npm install\n    RUN mkdir -p /app/sprites/\n    COPY ./services/tileserver/assets/sprites/*.svg /app/sprites/\n\n    RUN mkdir /output\n    RUN useradd -s /bin/bash fontnik\n    RUN chown fontnik /output\n\n    USER fontnik\n\n    # Output fonts\n    ENV FONTS_DIR=/output/fonts\n    RUN mkdir \"$FONTS_DIR\"\n\n    RUN mkdir \"${FONTS_DIR}/Roboto Regular\"\n    RUN node build_glyphs Roboto-Regular.ttf \"${FONTS_DIR}/Roboto Regular\"\n\n    RUN mkdir \"${FONTS_DIR}/Roboto Medium\"\n    RUN node build_glyphs Roboto-Medium.ttf \"${FONTS_DIR}/Roboto Medium\"\n\n    RUN mkdir \"${FONTS_DIR}/Roboto Condensed Italic\"\n    RUN node build_glyphs Roboto-Condensed-Italic.ttf \"${FONTS_DIR}/Roboto Condensed Italic\"\n\n    SAVE ARTIFACT \"$FONTS_DIR\" /fonts\n\n    # Output sprite\n    ENV SPRITE_DIR=/output/sprites\n    RUN mkdir \"$SPRITE_DIR\"\n\n    RUN node build_sprites \"${SPRITE_DIR}/sprite\" /app/sprites\n    RUN node build_sprites --retina \"${SPRITE_DIR}/sprite@2x\" /app/sprites\n\n    SAVE ARTIFACT \"$SPRITE_DIR\"  /sprites\n\ntileserver-init-image:\n    FROM +downloader-base\n\n    COPY ./services/tileserver/init.sh /app/init.sh\n    CMD [\"/app/init.sh\"]\n\n    ARG --required tags\n    FOR tag IN ${tags}\n        SAVE IMAGE --push ghcr.io/headwaymaps/tileserver-init:${tag}\n    END\n\ntileserver-serve-image:\n    FROM node:20-slim\n\n    RUN npm install -g tileserver-gl-light\n\n    USER root\n\n    RUN apt-get update \\\n        && apt-get install -y gettext-base \\\n        && rm -rf /var/lib/apt/lists/*\n\n    RUN mkdir -p /app/styles\n    RUN chown -R node /app\n\n    USER node\n\n    COPY ./services/tileserver/styles/basic /app/styles/basic\n    COPY (+tileserver-build/sprites) /app/sprites\n    COPY (+tileserver-build/fonts) /app/fonts\n\n    COPY ./services/tileserver/templates /templates/\n    COPY ./services/tileserver/configure_run.sh /app/\n\n    ENV HEADWAY_PUBLIC_URL=http://127.0.0.1:8080\n    CMD [\"/app/configure_run.sh\"]\n    ARG --required tags\n    FOR tag IN ${tags}\n        SAVE IMAGE --push ghcr.io/headwaymaps/tileserver:${tag}\n    END\n\n##############################\n# Web\n##############################\n\nweb-build:\n    FROM node:20-slim\n    RUN yarn global add @quasar/cli\n    COPY ./services/frontend/www-app /www-app\n    WORKDIR /www-app\n    ARG branding\n    IF [ ! -z ${branding} ]\n        RUN sed -i \"s/.*productName.*/  \\\"productName\\\": \\\"${branding}\\\",/\" package.json\n    END\n    RUN yarn install && quasar build\n    SAVE ARTIFACT /www-app/dist/spa /spa\n\nweb-init-image:\n    FROM +downloader-base\n\n    COPY ./services/frontend/init.sh ./services/frontend/generate_config.sh /app/\n    ENV HEADWAY_SHARED_VOL=/data\n    CMD [\"/app/init.sh\"]\n\n    ARG --required tags\n    FOR tag IN ${tags}\n        SAVE IMAGE --push ghcr.io/headwaymaps/headway-init:${tag}\n    END\n\nweb-serve-image:\n    FROM nginx\n\n    ARG branding\n    COPY (+web-build/spa --branding=${branding}) /usr/share/nginx/html/\n\n    COPY services/frontend/nginx.conf.template /etc/nginx/templates/nginx.conf.template\n\n    ENV HEADWAY_PUBLIC_URL=http://127.0.0.1:8080\n    ENV HEADWAY_SHARED_VOL=/data\n    ENV HEADWAY_HTTP_PORT=8080\n    ENV HEADWAY_RESOLVER=127.0.0.11\n    ENV HEADWAY_TRAVELMUX_URL=http://travelmux:8000\n    ENV HEADWAY_TILESERVER_URL=http://tileserver:8000\n    ENV HEADWAY_PELIAS_URL=http://pelias-api:8080\n    # for escaping $ in nginx template\n    ENV ESC=$\n    ENV NGINX_ENVSUBST_OUTPUT_DIR=/etc/nginx\n\n    ARG --required tags\n    FOR tag IN ${tags}\n        SAVE IMAGE --push ghcr.io/headwaymaps/headway:${tag}\n    END\n\n##############################\n# Generic base images\n##############################\n\ndownloader-base:\n    FROM debian:bookworm-slim\n    ENV TZ=\"America/New_York\"\n    RUN apt-get update \\\n        && apt-get install -y --no-install-recommends wget ca-certificates zstd \\\n        && rm -rf /var/lib/apt/lists/*\n    RUN mkdir /data\n\nsave-base:\n    FROM debian:bookworm-slim\n    RUN apt-get update \\\n        && apt-get install -y --no-install-recommends zip zstd \\\n        && rm -rf /var/lib/apt/lists/*\n"
        },
        {
          "name": "FULL_PLANET.md",
          "type": "blob",
          "size": 1.1650390625,
          "content": "# Full-planet considerations\n\n## Build requirements\n\nEarthly makes many needless copies of data in its cache, so unless you have truly excessive amounts of storage you will need to perform planet builds on a system with deduplication. There are two main options for that that I'm aware of: LVM VDO and ZFS. I've only attempted to use ZFS for this purpose.\n\nWith deduplication enabled the disk space requirement for a full-planet build is fairly low, expect to need around 1TB of fast storage. You'll also need to disable BuildKit parallelism in earthly and set `cache_size_mb` to 10000000 to trick it into using more disk space than you technically have available. I've observed deduplication ratios as high as 15x, with an average of 8-10x for full-planet work.\n\n### Earthly\n\nEarthly added a timeout to buildkit (default 24h). Planet builds may take multiple days, depending on your hardware.\nYou'll want to increase it, or you can disable it altogether in your `~/.earthly/config.yml`\n\n```\nglobal:\n    buildkit_additional_args: ['-e', 'BUILDKIT_SESSION_TIMEOUT=0']\n```\n\n## Runtime requirements\n\nExpect to need 64GB of RAM and fast disk for elasticsearch in particular.\n\n### Kubernetes\n\nTODO\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.091796875,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 2.0224609375,
          "content": "# <p align=center>Headway</p>\n\n<p align=center>\n<img alt=\"GitHub Actions status badge\" src=\"https://github.com/headwaymaps/headway/actions/workflows/checks.yml/badge.svg?branch=main\"/>\n<img alt=\"License badge\" src=\"https://img.shields.io/github/license/headwaymaps/headway\"/>\n<img alt=\"GitHub last commit badge\" src=\"https://img.shields.io/github/last-commit/headwaymaps/headway\"/>\n<img alt=\"GitHub commit activity badge\" src=\"https://img.shields.io/github/commit-activity/m/headwaymaps/headway\"/>\n</p>\n\n<p align=center>\n<picture>\n<source media=\"(prefers-color-scheme: dark)\" srcset=\"assets/world_dark.svg?raw=true\">\n<img alt=\"World map image\" src=\"assets/world_light.svg?raw=true\">\n</picture>\n</p>\n\nHeadway is a maps stack in a box that makes it easy to take your location data into your own hands. With just a few commands you can bring up your own fully functional maps server. This includes a frontend, basemap, geocoder and routing engine. Choose one of the 200+ predefined cities or provide your own OpenStreetMap extract covering any area: from a neighborhood to the whole planet.\n\nSee [BUILD.md](./BUILD.md) for more information about the build process.\n\n### Status\n\nHeadway is currently capable of showing a map, searching for points of interest and addresses within an OpenStreetMap extract and providing directions between any two places within that extract. Supported modes include driving, cycling and walking. Transit directions are a work-in-progress.\n\n### System Requirements\n\nHeadway has been confirmed working on amd64 machines running Linux and macOS. The machine used for generation of the data files needs to have at least 8GB of memory, potentially more for larger areas. The requirements for running an instance of the stack are lower though. Expect to need around 4GB for a medium sized metro area. Additionally, you should expect to need 50GB-100GB of disk space during the build process.\n\n### License\n\nHeadway is available freely under the terms of the Apache License, version 2.0. Please consider opening a PR for any enhancements or bugfixes!\n"
        },
        {
          "name": "VALUES.md",
          "type": "blob",
          "size": 0.7626953125,
          "content": "# Headway Values\n\n## Simplicity\n\nHeadway should be easy to use. This should inform all decisions made for the project. Headway should be simple to use for end users, simple to set up for system administrators and simple to extend and modify by developers.\n\n## Privacy\n\nHeadway should not persist data about its users on the backend under any circumstances. A user's recourse for deciding that they don't trust [maps.earth](https://maps.earth/) should always be available, celebrated and encouraged: hosting their own instance.\n\n## Responsibility\n\nHeadway should not under any circumstances endanger people, animals or the planet. Nothing should be added that could encourage or enable distracted driving, and people should be able to get transportation options other than driving.\n"
        },
        {
          "name": "assets",
          "type": "tree",
          "content": null
        },
        {
          "name": "bin",
          "type": "tree",
          "content": null
        },
        {
          "name": "builds",
          "type": "tree",
          "content": null
        },
        {
          "name": "contrib",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker-compose-with-transit.yaml",
          "type": "blob",
          "size": 6.095703125,
          "content": "version: \"3\"\nservices:\n  tileserver-init:\n    image: ghcr.io/headwaymaps/tileserver-init:latest\n    env_file: .env\n    environment:\n      AREAMAP_ARTIFACT_DEST: /data/${HEADWAY_AREA}.mbtiles\n      AREAMAP_ARTIFACT_SOURCE: /bootstrap/${HEADWAY_AREA}.mbtiles\n      TERRAIN_ARTIFACT_DEST: /data/terrain.mbtiles\n      TERRAIN_ARTIFACT_SOURCE: /bootstrap/terrain.mbtiles\n      LANDCOVER_ARTIFACT_DEST: /data/landcover.mbtiles\n      LANDCOVER_ARTIFACT_SOURCE: /bootstrap/landcover.mbtiles\n    volumes:\n      - \"./data/:/bootstrap/:ro\"\n      - \"tileserver_data:/data/:rw\"\n  tileserver:\n    image: ghcr.io/headwaymaps/tileserver:latest\n    restart: always\n    env_file: .env\n    environment:\n      PORT: 8000\n    volumes:\n      - \"tileserver_data:/data/:ro\"\n    depends_on:\n      tileserver-init:\n        condition: service_completed_successfully\n    expose:\n      - \"8000\"\n    networks:\n      - tileserver_frontend\n  opentripplanner-init:\n    image: ghcr.io/headwaymaps/opentripplanner-init:latest\n    env_file: .env\n    environment:\n      OTP_ARTIFACT_SOURCE_PATH: /bootstrap/${HEADWAY_AREA}.graph.obj.zst\n    volumes:\n      - \"./data/:/bootstrap/:ro\"\n      - \"opentripplanner_data:/data/:rw\"\n  opentripplanner:\n    image: ghcr.io/headwaymaps/opentripplanner:latest\n    restart: always\n    env_file: .env\n    volumes:\n      - \"opentripplanner_data:/var/opentripplanner/:ro\"\n    depends_on:\n      opentripplanner-init:\n        condition: service_completed_successfully\n    networks:\n      - otp_backend\n    # ports:\n    #   - \"9002:8000\"\n  travelmux:\n    image: ghcr.io/headwaymaps/travelmux:latest\n    restart: always\n    env_file: .env\n    depends_on:\n      opentripplanner:\n        condition: service_healthy\n    networks:\n      - travel_frontend\n      - otp_backend\n      - valhalla_backend\n    command: [\"http://valhalla:8002\", \"http://opentripplanner:8000/otp/routers\"]\n  valhalla-init:\n    image: ghcr.io/headwaymaps/valhalla-init:latest\n    env_file: .env\n    volumes:\n      - \"valhalla_data:/data/:rw\"\n      - \"./data/:/bootstrap/:ro\"\n    environment:\n      VALHALLA_ARTIFACT_SOURCE_PATH: /bootstrap/${HEADWAY_AREA}.valhalla.tar.zst\n    ulimits:\n      nofile:\n        soft: 8192\n        hard: 8192\n  valhalla:\n    image: ghcr.io/headwaymaps/valhalla:latest\n    restart: always\n    env_file: .env\n    networks:\n      - valhalla_backend\n    volumes:\n      - \"valhalla_data:/data/:ro\"\n    ulimits:\n      nofile:\n        soft: 8192\n        hard: 8192\n    depends_on:\n      valhalla-init:\n        condition: service_completed_successfully\n    # ports:\n    #   - \"9001:8002\"\n  frontend-init:\n    image: ghcr.io/headwaymaps/headway-init:latest\n    env_file: .env\n    volumes:\n      - \"./data/:/bootstrap/:ro\"\n      - \"frontend_data:/data/:rw\"\n  frontend:\n    image: ghcr.io/headwaymaps/headway:latest\n    restart: always\n    env_file: .env\n    environment:\n      HEADWAY_RESOLVER: 127.0.0.11\n      HEADWAY_PELIAS_URL: http://pelias-api:4000\n      HEADWAY_TILESERVER_URL: http://tileserver:8000\n      HEADWAY_TRAVELMUX_URL: http://travelmux:8000\n    ports:\n      - \"8080:8080\"\n    networks:\n      - pelias_frontend\n      - tileserver_frontend\n      - travel_frontend\n    volumes:\n      - \"frontend_data:/data/:ro\"\n    depends_on:\n      - \"pelias-api\"\n      - \"tileserver\"\n      - \"travelmux\"\n      - \"valhalla\"\n  pelias-config-init:\n    image: ghcr.io/headwaymaps/pelias-init:latest\n    env_file: .env\n    environment:\n      PELIAS_CONFIG_ARTIFACT_SOURCE_PATH: /bootstrap/${HEADWAY_AREA}.pelias.json\n    command: [ \"/bin/bash\", \"/app/init_config.sh\" ]\n    volumes:\n      - \"./data/:/bootstrap/:ro\"\n      - \"pelias_config_data:/config\"\n  pelias-elasticsearch-init:\n    image: ghcr.io/headwaymaps/pelias-init:latest\n    env_file: .env\n    environment:\n      ELASTICSEARCH_ARTIFACT_SOURCE_PATH: /bootstrap/${HEADWAY_AREA}.elasticsearch.tar.zst\n    command: [ \"/bin/bash\", \"/app/init_elastic.sh\" ]\n    volumes:\n      - \"./data/:/bootstrap/:ro\"\n      - \"pelias_elasticsearch_data:/usr/share/elasticsearch/data\"\n  pelias-placeholder-init:\n    image: ghcr.io/headwaymaps/pelias-init:latest\n    env_file: .env\n    environment:\n      PLACEHOLDER_ARTIFACT_SOURCE_PATH: /bootstrap/${HEADWAY_AREA}.placeholder.tar.zst\n    command: [ \"/bin/bash\", \"/app/init_placeholder.sh\" ]\n    volumes:\n      - \"./data/:/bootstrap/:ro\"\n      - \"pelias_placeholder_data:/data/placeholder\"\n  pelias-libpostal:\n    image: pelias/libpostal-service\n    restart: always\n    networks:\n      - pelias_backend\n  pelias-api:\n    image: pelias/api:master\n    restart: always\n    environment:\n      PORT: 4000\n      PELIAS_CONFIG: /config/pelias.json\n    networks:\n      - pelias_backend\n      - pelias_frontend\n    volumes:\n      - \"pelias_config_data:/config:ro\"\n    depends_on:\n      pelias-elasticsearch:\n        condition: service_healthy\n      pelias-config-init:\n        condition: service_completed_successfully\n    # ports:\n    #   - \"4000:4000\"\n  pelias-placeholder:\n    image: pelias/placeholder:master\n    restart: always\n    environment:\n      PORT: 4100\n    networks:\n      - pelias_backend\n    volumes:\n      - \"pelias_config_data:/config:ro\"\n      - \"pelias_placeholder_data:/data/placeholder\"\n    depends_on:\n      pelias-config-init:\n        condition: service_completed_successfully\n      pelias-placeholder-init:\n        condition: service_completed_successfully\n  pelias-elasticsearch:\n    image: pelias/elasticsearch:8.12.2-beta\n    restart: always\n    networks:\n      - pelias_backend\n    volumes:\n      - \"pelias_elasticsearch_data:/usr/share/elasticsearch/data\"\n    ulimits:\n      memlock:\n        soft: -1\n        hard: -1\n      nofile:\n        soft: 65536\n        hard: 65536\n    cap_add: [ \"IPC_LOCK\" ]\n    depends_on:\n      pelias-elasticsearch-init:\n        condition: service_completed_successfully\n      pelias-config-init:\n        condition: service_completed_successfully\n    healthcheck:\n      test: nc -z localhost 9200\n      interval: 5s\n      start_period: 60s\nnetworks:\n  tileserver_frontend:\n  pelias_frontend:\n  pelias_backend:\n  travel_frontend:\n  valhalla_backend:\n  otp_backend:\nvolumes:\n  pelias_config_data:\n  pelias_placeholder_data:\n  pelias_elasticsearch_data:\n  tileserver_data:\n  opentripplanner_data:\n  valhalla_data:\n  frontend_data:\n"
        },
        {
          "name": "docker-compose.yaml",
          "type": "blob",
          "size": 5.28125,
          "content": "version: \"3\"\nservices:\n  tileserver-init:\n    image: ghcr.io/headwaymaps/tileserver-init:latest\n    env_file: .env\n    environment:\n      AREAMAP_ARTIFACT_DEST: /data/${HEADWAY_AREA}.mbtiles\n      AREAMAP_ARTIFACT_SOURCE: /bootstrap/${HEADWAY_AREA}.mbtiles\n      TERRAIN_ARTIFACT_DEST: /data/terrain.mbtiles\n      TERRAIN_ARTIFACT_SOURCE: /bootstrap/terrain.mbtiles\n      LANDCOVER_ARTIFACT_DEST: /data/landcover.mbtiles\n      LANDCOVER_ARTIFACT_SOURCE: /bootstrap/landcover.mbtiles\n    volumes:\n      - \"./data/:/bootstrap/:ro\"\n      - \"tileserver_data:/data/:rw\"\n  tileserver:\n    image: ghcr.io/headwaymaps/tileserver:latest\n    restart: always\n    env_file: .env\n    environment:\n      PORT: 8000\n    volumes:\n      - \"tileserver_data:/data/:ro\"\n    depends_on:\n      tileserver-init:\n        condition: service_completed_successfully\n    expose:\n      - \"8000\"\n    networks:\n      - tileserver_frontend\n  travelmux:\n    image: ghcr.io/headwaymaps/travelmux:latest\n    restart: always\n    env_file: .env\n    networks:\n      - travel_frontend\n      - valhalla_backend\n    command: [\"http://valhalla:8002\"]\n  valhalla-init:\n    image: ghcr.io/headwaymaps/valhalla-init:latest\n    env_file: .env\n    volumes:\n      - \"valhalla_data:/data/:rw\"\n      - \"./data/:/bootstrap/:ro\"\n    environment:\n      VALHALLA_ARTIFACT_SOURCE_PATH: /bootstrap/${HEADWAY_AREA}.valhalla.tar.zst\n    ulimits:\n      nofile:\n        soft: 8192\n        hard: 8192\n  valhalla:\n    image: ghcr.io/headwaymaps/valhalla:latest\n    restart: always\n    env_file: .env\n    networks:\n      - valhalla_backend\n    volumes:\n      - \"valhalla_data:/data/:ro\"\n    ulimits:\n      nofile:\n        soft: 8192\n        hard: 8192\n    depends_on:\n      valhalla-init:\n        condition: service_completed_successfully\n    # ports:\n    #   - \"9002:8002\"\n  frontend-init:\n    image: ghcr.io/headwaymaps/headway-init:latest\n    env_file: .env\n    volumes:\n      - \"./data/:/bootstrap/:ro\"\n      - \"frontend_data:/data/:rw\"\n  frontend:\n    image: ghcr.io/headwaymaps/headway:latest\n    restart: always\n    env_file: .env\n    environment:\n      HEADWAY_RESOLVER: 127.0.0.11\n      HEADWAY_PELIAS_URL: http://pelias-api:4000\n      HEADWAY_TILESERVER_URL: http://tileserver:8000\n      HEADWAY_TRAVELMUX_URL: http://travelmux:8000\n    ports:\n      - \"8080:8080\"\n    networks:\n      - pelias_frontend\n      - tileserver_frontend\n      - travel_frontend\n    volumes:\n      - \"frontend_data:/data/:ro\"\n    depends_on:\n      - \"pelias-api\"\n      - \"tileserver\"\n      - \"travelmux\"\n      - \"valhalla\"\n  pelias-config-init:\n    image: ghcr.io/headwaymaps/pelias-init:latest\n    env_file: .env\n    environment:\n      PELIAS_CONFIG_ARTIFACT_SOURCE_PATH: /bootstrap/${HEADWAY_AREA}.pelias.json\n    command: [ \"/bin/bash\", \"/app/init_config.sh\" ]\n    volumes:\n      - \"./data/:/bootstrap/:ro\"\n      - \"pelias_config_data:/config\"\n  pelias-elasticsearch-init:\n    image: ghcr.io/headwaymaps/pelias-init:latest\n    env_file: .env\n    environment:\n      ELASTICSEARCH_ARTIFACT_SOURCE_PATH: /bootstrap/${HEADWAY_AREA}.elasticsearch.tar.zst\n    command: [ \"/bin/bash\", \"/app/init_elastic.sh\" ]\n    volumes:\n      - \"./data/:/bootstrap/:ro\"\n      - \"pelias_elasticsearch_data:/usr/share/elasticsearch/data\"\n  pelias-placeholder-init:\n    image: ghcr.io/headwaymaps/pelias-init:latest\n    env_file: .env\n    environment:\n      PLACEHOLDER_ARTIFACT_SOURCE_PATH: /bootstrap/${HEADWAY_AREA}.placeholder.tar.zst\n    command: [ \"/bin/bash\", \"/app/init_placeholder.sh\" ]\n    volumes:\n      - \"./data/:/bootstrap/:ro\"\n      - \"pelias_placeholder_data:/data/placeholder\"\n  pelias-libpostal:\n    image: pelias/libpostal-service\n    restart: always\n    networks:\n      - pelias_backend\n  pelias-api:\n    image: pelias/api:master\n    restart: always\n    environment:\n      PORT: 4000\n      PELIAS_CONFIG: /config/pelias.json\n    networks:\n      - pelias_backend\n      - pelias_frontend\n    volumes:\n      - \"pelias_config_data:/config:ro\"\n    depends_on:\n      pelias-elasticsearch:\n        condition: service_healthy\n      pelias-config-init:\n        condition: service_completed_successfully\n  pelias-placeholder:\n    image: pelias/placeholder:master\n    restart: always\n    environment:\n      PORT: 4100\n    networks:\n      - pelias_backend\n    volumes:\n      - \"pelias_config_data:/config:ro\"\n      - \"pelias_placeholder_data:/data/placeholder\"\n    depends_on:\n      pelias-config-init:\n        condition: service_completed_successfully\n      pelias-placeholder-init:\n        condition: service_completed_successfully\n  pelias-elasticsearch:\n    image: pelias/elasticsearch:8.12.2-beta\n    restart: always\n    networks:\n      - pelias_backend\n    volumes:\n      - \"pelias_elasticsearch_data:/usr/share/elasticsearch/data\"\n    ulimits:\n      memlock:\n        soft: -1\n        hard: -1\n      nofile:\n        soft: 65536\n        hard: 65536\n    cap_add: [ \"IPC_LOCK\" ]\n    depends_on:\n      pelias-elasticsearch-init:\n        condition: service_completed_successfully\n      pelias-config-init:\n        condition: service_completed_successfully\n    healthcheck:\n      test: nc -z localhost 9200\n      interval: 5s\n      start_period: 60s\nnetworks:\n  tileserver_frontend:\n  pelias_frontend:\n  pelias_backend:\n  travel_frontend:\n  valhalla_backend:\nvolumes:\n  pelias_config_data:\n  pelias_placeholder_data:\n  pelias_elasticsearch_data:\n  tileserver_data:\n  valhalla_data:\n  frontend_data:\n"
        },
        {
          "name": "git-hooks",
          "type": "tree",
          "content": null
        },
        {
          "name": "k8s",
          "type": "tree",
          "content": null
        },
        {
          "name": "services",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}