{
  "metadata": {
    "timestamp": 1736709214309,
    "page": 496,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjUwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "sarah-quinones/faer-rs",
      "stars": 1909,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.1416015625,
          "content": "target\nCargo.lock\n*.out\nf32.txt\nf64.txt\nf128.txt\nc32.txt\nc64.txt\nc128.txt\n*.pdf\ncompile_commands.json\n.cache\ndiol*.json\nmkl_bench\nopenblas_bench\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 7.9912109375,
          "content": "# 0.19\n- Support matrix-scalar multiplication/division without the `Scale` wrapper for `f32`/`f64`.\n- Implemented conjugate gradient, BiCGSTAB, and LSMR iterative solvers (currently gated by the `unstable` feature).\n- Implemented Hermitian matrix pseudoinverse implementation. Thanks @lishen_ for the contribution.\n- Implemented column and row mean and variance in `faer::stats`.\n- Added more iterator and parallel iterator functions (`MatRef::[col|row]_partition`, `MatRef::par_[col|row]_partition`, etc.).\n- Added `full` and `zeros` constructors to owned Col, Row, and Matrix ([issue-125](https://github.com/sarah-ek/faer-rs/issues/125)).\n- Added `shape` function to return both the row and the column count of a matrix.\n- Added several missing associated functions from the mut and owning variants of matrices.\n- Implemented `core::iter::{Sum, Product}` for `c32` and `c64`.\n- Sparse Cholesky can now be used with user-provided permutations.\n- Simplified matrix constructors, adding a variant with a `_generic` prefix for the old behavior.\n- LDLT and Bunch-Kaufman decompositions now stores the diagonal blocks instead of their inverses. This helps avoid infinities and NaNs when dealing with singular matrices.\n- Integrated `nano-gemm` as a backend for small matrix multiplication.\n- Significant performance improvements for small LLT and LDLT decompositions.\n\n# 0.18\n- Refactored the project so that `faer` contains all the core and decomposition implementations. `faer-{core,cholesky,lu,qr,svd,evd,sparse}` are now deprecated and will no longer be updated.\n- Improved the multithreaded performance of the Eigenvalue decomposition for large matrices.\n- Decomposition solve functions now accept column vectors as well as matrices.\n- Implemented the L1 norm, and the squared L2 norm.\n- Implemented conversions from sparse to dense matrices, by calling `mat.to_dense()`.\n- Sparse matrices now support duplicated entries. Note that `faer` will not add duplicated entries to a matrix unless the opposite is explicitly mentioned in the function documentation. `faer` also will deduplicate entries when created with `Sparse{Col,Row}Mat::try_new_from_indices` and other similar functions.\n- Implemented conversions from unsorted to sorted sparse matrices by calling `mat.to_sorted()` (or `mat.sort_indices()` for owned matrices).\n- Implemented `{Col,Row}::try_as_slice[_mut]` functions that return data as a slice if it is contiguous.\n- Implemented `.for_each_with_index` and `.map_with_index` for the matrix zipping API, which passes the matrix row and column indices as well as the values.\n- Added `rand` support for randomly generating matrices in the `faer::stats` module, as well as for `faer::complex_native::{c32,c64}`.\n- Implemented a pseudoinverse helper for the high level SVD and thin SVD decompositions.\n\n# 0.17\n- Implemented sparse matrix arithmetic operators (other than sparse-sparse matrix multiplication), and added mutable sparse views as well as owning sparse matrix containers.\n- Implemented `try_from_triplets` for sparse matrices.\n- Re-exported subcrates in `faer::modules`.\n- Improved performance of the SVD decomposition for small matrices.\n- Implemented `col!`, `row!` and `concat!` macros. Thanks @DeliciousHair for the contribution.\n- Implemented more `c32/c64` operations. Thanks @edyounis for the contribution.\n- Implemented the Kronecker product in `faer_core`. Thanks @edyounis for the contribution.\n- Implemented (de)serialization of `Mat`. Thanks @cramt for the contribution.\n\n# 0.16\n- Implemented the index operator for row and column structures. Thanks @DeliciousHair for the contribution.\n- Exposed a few sparse matrix operations in the high level API.\n- Implemented sparse LU and QR, and exposed sparse decompositions in the high level API.\n- Better assertion error messages in no_std mode.\n\n# 0.15\n- Implemented initial API of `Row`/`RowRef`/`RowMut` and `Col`/`ColRef`/`ColMut` structs for handling matrices with a single row or column.\n- Implemented `[Mat|Col|Row]::norm_l2` and `[Mat|Col|Row]::norm_max` for computing the L2 norm of a matrix or its maximum absolute value.\n- Fixed several bugs in the eigenvalue decompositions. Special thanks to @AlexMath for tracking down the errors.\n- Updated `zipped!` macro API, which now requires a matching `unzipped!` for matching the closure arguments.\n- Removed the limitation on the number of matrices that can be passed to `zipped!`.\n- Added a `zipped!(...).map(|unzipped!(...)| { ... })` API to allow mapping a zipped pack of matrices and returns the result as a matrix.\n- Updated `polars` dependency to 0.34.\n- Speed improvements for complex matrix multiplication on AMD cpus.\n- New SIMD functions in the Entity trait for aligned loads and stores.\n- Renamed multiple methods such as `MatMut::transpose` to `MatMut::transpose_mut`.\n\n# 0.14\n- Implemented sparse data structures in `faer_core::sparse`.\n- Implemented sparse Cholesky decompositions, simplicial and supernodal. Only the low level API is currently exposed in `faer-sparse`.\n- Implemented dynamic regularization for the Bunch-Kaufman Cholesky decomposition.\n- Implemented diagonal wrappers that can be used to interpret a matrix as a diagonal matrix, using `{MatRef,MatMut}::diagonal` and `{MatRef,MatMut}::column_vector_as_diagonal`.\n- Implemented matrix multiplication syntax sugar for diagonal wrappers, and permutation matrices.\n- Implemented `compute_thin_r` and `compute_thin_q` in `faer::solvers::{Qr,ColPivQr}`.\n- Implemented initial SIMD support for aarch64.\n\n# 0.13\n- Implemented the Bunch-Kaufman Cholesky decomposition for hermitian indefinite matrices.\n- Implemented dynamic regularization for the diagonal LDLT.\n- Support conversions involving complex values using `IntoFaerComplex`, `IntoNalgebraComplex` and `IntoNdarrayComplex`.\n- Refactored the Entity trait for better ergonomics.\n- `faer` scalar traits are now prefixed with `faer_` to avoid conflicts with standard library and popular library traits.\n- `no_std` and `no_rayon` are now supported, with the optional features `std` and `rayon` (enabled by default).\n- Performance improvements in the eigenvalue decomposition and thin matrix multiplication.\n\n# 0.12\n- Implemented matrix chunked iterators and parallel chunked iterators.\n- Renamed `{Mat,MatMut}::fill_with_zero` to `fill_zeros`\n- Renamed `{Mat,MatMut}::fill_with_constant` to `fill`\n- More ergonomic `polars` api.\n- Refactored Entity and ComplexField SIMD api.\n- Switched from DynStack/GlobalMemBuffer to PodStack/GlobalPodBuffer.\n- Fixed usize overflow bug in eigenvalue decomposition.\n\n# 0.11\n- High level api implemented in `faer`.\n- Renamed `Mat::with_dims` to `Mat::from_fn`.\n- Renamed `{Mat,MatMut}::set_zeros` to `fill_with_zero`.\n- Renamed `{Mat,MatMut}::set_constant` to `fill_with_constant`.\n\n# 0.10\n- Performance improvements for small matrices.\n- Simpler SVD/EVD API for fixed precision floating point types.\n- Simpler math operators (+, -, *). Thanks @geo-ant and @DJDuque.\n- More robust pivoted decompositions for rank deficient matrices.\n- Better overflow/underflow handling in matrix decompositions, as well as non finite inputs.\n- Provide control over global parallelism settings in `faer-core`.\n- Various bug fixes for complex number handling.\n\n# 0.9\n- Implement the non Hermitian eigenvalue decomposition.\n- Improve performance of matrix multiplication.\n- Improve performance of LU decomposition with partial pivoting.\n\n# 0.8\n- Refactor the core traits for better SIMD support for non native types, using a structure-of-arrays layout.\n- Implement the Hermitian eigenvalue decomposition.\n\n# 0.7\n- Add `to_owned` function for converting a `MatRef/MatMut` to a `Mat`. Thanks @Tastaturtaste\n- Allow comparison of conjugated matrices\n- Performance improvements for `f32`, `c32`, and `c64`\n- Performance improvements for small/medium matrix decompositions\n- Refactor the `ComplexField` trait to allow for non `Copy` types. Note that types other than `f32`, `f64`, `c32`, `c64` are not yet supported.\n\n# 0.6\n- Start keeping track of changes.\n- Complex SVD support.\n- Improve performance for thin SVD.\n- Fixed an edge case in complex Householder computation where the input vector is all zeros.\n"
        },
        {
          "name": "CITATION.cff",
          "type": "blob",
          "size": 0.5869140625,
          "content": "# This CITATION.cff file was generated with cffinit.\n# Visit https://bit.ly/cffinit to generate yours today!\n\ncff-version: 1.2.0\ntitle: faer-rs\nmessage: >-\n  If you use this software, please cite it using the\n  metadata from this file.\ntype: software\nauthors:\n  - given-names: Sarah\n    family-names: El Kazdadi\n    email: sarah.elkazdadi@gmail.com\n    orcid: 'https://orcid.org/0000-0002-5657-0710'\nrepository-code: 'https://github.com/sarah-ek/faer-rs'\nurl: 'https://faer-rs.github.io/'\nabstract: A high performance linear algebra library for Rust\nkeywords:\n  - math\n  - linear algebra\nlicense: MIT\n"
        },
        {
          "name": "Cargo.toml",
          "type": "blob",
          "size": 2.6259765625,
          "content": "[package]\nname = \"faer\"\nversion = \"0.20.2\"\nedition = \"2021\"\nauthors = [\"sarah <>\"]\ndescription = \"Linear algebra routines\"\nreadme = \"README.md\"\nrepository = \"https://github.com/sarah-ek/faer-rs/\"\nlicense = \"MIT\"\nkeywords = [\"math\", \"matrix\", \"linear-algebra\"]\nrust-version = \"1.81.0\"\n\n[dependencies]\nbytemuck = \"1.14.3\"\ncoe-rs = \"0.1.2\"\ndbgf = \"0.1.2\"\npaste = \"1.0.14\"\nreborrow = \"0.5.5\"\n\ndyn-stack = { version = \"0.11.0\", default-features = false }\nequator = \"0.4.1\"\nfaer-entity = { version =\"0.20.1\", default-features = false, path = \"./faer-entity\" }\n\ngemm = { version = \"0.18.1\", default-features = false }\nnano-gemm = { version = \"0.1.2\", default-features = false }\nnum-complex = { version = \"0.4.5\", default-features = false }\nnum-traits = { version = \"0.2.18\", default-features = false }\n\nmatrixcompare-core = { version = \"0.1.0\", optional = true }\nmatrixcompare = { version = \"0.3\", optional = true }\n\nrayon = { version = \"1.8.1\", optional = true }\nserde = { version = \"1\", optional = true,  features = [\"derive\"] }\nlog = { version = \"0.4\", optional = true, default-features = false }\nnpyz = { version = \"0.8\", optional = true }\nrand = { version = \"0.8.5\", default-features = false, optional = true }\nrand_distr = { version = \"0.4.3\", default-features = false, optional = true }\nlibm = \"0.2.8\"\ngenerativity = \"1.1.0\"\n\n[features]\ndefault = [\n  \"std\",\n  \"rayon\",\n  \"serde\",\n  \"rand\",\n  \"npy\",\n  \"linalg\",\n]\nunstable = []\nstd = [\n  \"faer-entity/std\",\n  \"gemm/std\",\n  \"nano-gemm/std\",\n  \"matrixcompare-core\",\n  \"matrixcompare\",\n  \"num-traits/std\",\n  \"num-complex/std\",\n]\nrand = [\"dep:rand\", \"rand_distr\", \"num-complex/rand\"]\nrayon = [\"std\", \"gemm/rayon\", \"dep:rayon\"]\nnightly = [\n  \"faer-entity/nightly\",\n  \"gemm/nightly\",\n  \"nano-gemm/nightly\",\n]\nperf-warn = [\"log\"]\nserde = [\"dep:serde\"]\nnpy = [\"std\", \"dep:npyz\"]\n\nlinalg = [\n  \"cholesky\",\n  \"qr\",\n  \"lu\",\n  \"svd\",\n  \"evd\",\n  \"sparse\",\n]\ncholesky = []\nqr = []\nlu = []\nevd = [\"qr\"]\nsvd = [\"qr\"]\nsparse = []\n\n[dev-dependencies]\naligned-vec = \"0.6.0\"\namd = \"0.2.2\"\nassert_approx_eq = \"1.1.0\"\ncore_affinity = \"0.8.1\"\ncsv = \"1.3.0\"\ndiol = { version = \"0.8.3\", default-features = false }\nmatrix-market-rs = \"0.1.3\"\nmatrixcompare = \"0.3.0\"\nnalgebra = \"0.32.5\"\nnum_cpus = \"1.16.0\"\nrand = \"0.8.5\"\nrand_distr = \"0.4.3\"\nserde_json = \"1.0.116\"\nserde_test = \"1.0.176\"\n\n[profile.dev]\nopt-level = 3\n\n[package.metadata.docs.rs]\nfeatures = [\"default\"]\nrustdoc-args = [\"--cfg\", \"docsrs\", \"--html-in-header\", \"katex-header.html\"]\n\n[[bench]]\nname = \"cholesky\"\nharness = false\n\n[[bench]]\nname = \"qr\"\nharness = false\n\n[[bench]]\nname = \"meanvar\"\nharness = false\n\n[[bench]]\nname = \"bench\"\nharness = false\n\n[[bench]]\nname = \"bench_aggregate\"\nharness = false\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.037109375,
          "content": "MIT License\n\nCopyright (c) 2022 sarah\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 1.2080078125,
          "content": "# faer\n\n[![Documentation](https://docs.rs/faer/badge.svg)](https://docs.rs/faer)\n[![Crate](https://img.shields.io/crates/v/faer.svg)](https://crates.io/crates/faer)\n\n`faer` is a Rust crate that implements low level linear algebra routines and a high level wrapper for ease of use, in pure Rust.\nThe aim is to provide a fully featured library for linear algebra with focus on portability, correctness, and performance.\n\nSee the [official website](https://faer-rs.github.io) and the [docs.rs](https://docs.rs/faer/latest/faer) documentation for code examples and usage instructions.\n\nQuestions about using the library, contributing, and future directions can be discussed in the [Discord server](https://discord.gg/Ak5jDsAFVZ).\n\n# Contributing\n\nIf you'd like to contribute to `faer`, check out the list of \"good first issue\"\nissues. These are all (or should be) issues that are suitable for getting\nstarted, and they generally include a detailed set of instructions for what to\ndo. Please ask questions on the Discord server or the issue itself if anything\nis unclear!\n\n# Minimum supported Rust version\n\nThe current MSRV is Rust 1.81.0.\n\n# Benchmarks\n\nSee [the benchmark page](https://faer-rs.github.io/bench-st.html) on the main website.\n"
        },
        {
          "name": "benches",
          "type": "tree",
          "content": null
        },
        {
          "name": "book",
          "type": "tree",
          "content": null
        },
        {
          "name": "compile_benches.sh",
          "type": "blob",
          "size": 0.2353515625,
          "content": "g++ -DBENCH_MKL -fopenmp -std=c++20 -O3 lapack.cpp -ldiol -lmkl_rt -o ./target/mkl_bench\ng++ -fopenmp -std=c++20 -O3 lapack.cpp \"/usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.a\" -ldiol -lopenblas -lgfortran -o ./target/openblas_bench\n"
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "faer-entity",
          "type": "tree",
          "content": null
        },
        {
          "name": "faer-no-std-test",
          "type": "tree",
          "content": null
        },
        {
          "name": "justfile",
          "type": "blob",
          "size": 0.51953125,
          "content": "publish-entity:\n    cd faer-entity && cargo publish --package faer-entity\n\npublish-libs:\n    cd faer-libs   && cargo publish --package faer-core\n    cd faer-libs   && cargo publish --package faer-lu\n    cd faer-libs   && cargo publish --package faer-qr\n    cd faer-libs   && cargo publish --package faer-cholesky\n    cd faer-libs   && cargo publish --package faer-svd\n    cd faer-libs   && cargo publish --package faer-evd\n    cd faer-libs   && cargo publish --package faer-sparse\n    cd faer-libs   && cargo publish --package faer\n"
        },
        {
          "name": "katex-header.html",
          "type": "blob",
          "size": 1.015625,
          "content": "<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css\" integrity=\"sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y\" crossorigin=\"anonymous\">\n<script src=\"https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.js\"                  integrity=\"sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/contrib/auto-render.min.js\"    integrity=\"sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe\" crossorigin=\"anonymous\"></script>\n<script>\n    document.addEventListener(\"DOMContentLoaded\", function() {\n        renderMathInElement(document.body, {\n            delimiters: [\n                {left: \"$$\", right: \"$$\", display: true},\n                {left: \"\\\\(\", right: \"\\\\)\", display: false},\n                {left: \"$\", right: \"$\", display: false},\n                {left: \"\\\\[\", right: \"\\\\]\", display: true}\n            ]\n        });\n    });\n</script>\n"
        },
        {
          "name": "lapack.cpp",
          "type": "blob",
          "size": 12.8681640625,
          "content": "#include <diol.hpp>\n#include <eigen3/Eigen/Core>\n\n#include <mkl/mkl_lapack.h>\n\n#define CAT_(A, B) A##B\n#define CAT(A, B) CAT_(A, B)\n#define MAKE_LAPACK(prefix, func)                                              \\\n  inline static constexpr auto func = CAT(CAT(prefix, func), _);\n\nusing namespace diol;\ntemplate <typename T> T const *addr(T const &ptr) { return &ptr; }\ntemplate <typename T> T *addr(T &&ptr) { return &ptr; }\nMKL_INT max(MKL_INT a, MKL_INT b) { return a > b ? a : b; }\n\nusing f32 = float;\nusing f64 = double;\nusing c32 = std::complex<f32>;\nusing c64 = std::complex<f64>;\n\ntemplate <typename T> using Mat = Eigen::Matrix<T, -1, -1>;\n\n#define MAKE_MKL(ty, mkl_ty, prefix, sym)                                      \\\n  template <> struct Mkl<ty> {                                                 \\\n    using T = mkl_ty;                                                          \\\n    MAKE_LAPACK(prefix, potrf);                                                \\\n    MAKE_LAPACK(prefix, geqrf);                                                \\\n    MAKE_LAPACK(prefix, geqp3);                                                \\\n    MAKE_LAPACK(prefix, getrf);                                                \\\n    MAKE_LAPACK(prefix, getc2);                                                \\\n    MAKE_LAPACK(prefix, gesdd);                                                \\\n    MAKE_LAPACK(CAT(prefix, sym), evd);                                        \\\n    MAKE_LAPACK(prefix, geev);                                                 \\\n  };\n\ntemplate <typename E> struct Mkl;\n\nMAKE_MKL(f32, f32, s, sy);\nMAKE_MKL(f64, f64, d, sy);\nMAKE_MKL(c32, MKL_Complex8, c, he);\nMAKE_MKL(c64, MKL_Complex16, z, he);\n\ntemplate <typename T> using Data = typename Mkl<T>::T *;\n\ntemplate <typename T> MKL_INT stride(Mat<T> const &mat) {\n  return mat.outerStride();\n}\ntemplate <typename T> auto data(Mat<T> &mat) { return Data<T>(mat.data()); }\n\ntemplate <typename T> Mat<T> rand(MKL_INT m, MKL_INT n) {\n  Mat<T> A(m, n);\n  A.setRandom();\n  return A;\n}\n\ntemplate <typename T> Mat<T> rand_pos_def(MKL_INT n) {\n  Mat<T> A(n, n);\n  A.setRandom();\n  Mat<T> H = T(0.5) * (A + A.adjoint());\n  H += T(n) * Mat<T>::Identity(n, n);\n  return H;\n}\n\ntemplate <typename T> Mat<T> randh(MKL_INT n) {\n  Mat<T> A(n, n);\n  A.setRandom();\n  Mat<T> H = T(0.5) * (A + A.adjoint());\n  return H;\n}\n\ntemplate <typename T> void cholesky(Bencher bencher, PlotArg arg) {\n  MKL_INT n = arg.n;\n  std::srand(0);\n  Mat<T> H_orig = rand_pos_def<T>(n);\n  Mat<T> H = H_orig;\n\n  std::move(bencher).bench([&] {\n    H = H_orig;\n\n    Mkl<T>::potrf(\"L\", addr(n), data(H), addr(stride(H)), addr((MKL_INT)0));\n  });\n}\n\ntemplate <typename T> void qr(Bencher bencher, PlotArg arg) {\n  MKL_INT n = arg.n;\n  std::srand(0);\n  Mat<T> H_orig = rand<T>(n, n);\n  Mat<T> H = H_orig;\n  Mat<T> tau(n, 1);\n\n  T lwork_;\n  Mkl<T>::geqrf(addr(n), addr(n), data(H), addr(stride(H)), data(tau),\n                Data<T>(&lwork_), addr((MKL_INT)-1), addr((MKL_INT)0));\n  MKL_INT lwork = 2 * (MKL_INT)std::real(lwork_);\n  Mat<T> work(lwork, 1);\n\n  std::move(bencher).bench([&] {\n    H = H_orig;\n\n    Mkl<T>::geqrf(addr(n), addr(n), data(H), addr(stride(H)), data(tau),\n                  data(work), addr(lwork), addr((MKL_INT)0));\n  });\n}\n\ntemplate <typename T> void piv_qr(Bencher bencher, PlotArg arg) {\n  MKL_INT n = arg.n;\n  std::srand(0);\n  Mat<T> H_orig = rand<T>(n, n);\n  Mat<T> H = H_orig;\n  Mat<T> tau(n, 1);\n  Mat<MKL_INT> p(n, 1);\n  Mat<typename Mat<T>::RealScalar> rwork(2 * n, 1);\n\n  T lwork_;\n  if constexpr (std::same_as<T, typename Mkl<T>::T>) {\n    Mkl<T>::geqp3(addr(n), addr(n), data(H), addr(stride(H)), p.data(),\n                  data(tau), Data<T>(&lwork_), addr((MKL_INT)-1),\n                  addr((MKL_INT)0));\n  } else {\n    Mkl<T>::geqp3(addr(n), addr(n), data(H), addr(stride(H)), p.data(),\n                  data(tau), Data<T>(&lwork_), addr((MKL_INT)-1), data(rwork),\n                  addr((MKL_INT)0));\n  }\n  auto lwork = 2 * (MKL_INT)std::real(lwork_);\n  Mat<T> work(lwork, 1);\n\n  std::move(bencher).bench([&] {\n    H = H_orig;\n\n    if constexpr (std::same_as<T, typename Mkl<T>::T>) {\n      Mkl<T>::geqp3(addr(n), addr(n), data(H), addr(stride(H)), p.data(),\n                    data(tau), data(work), addr(lwork), addr((MKL_INT)0));\n    } else {\n      Mkl<T>::geqp3(addr(n), addr(n), data(H), addr(stride(H)), p.data(),\n                    data(tau), data(work), addr(lwork), data(rwork),\n                    addr((MKL_INT)0));\n    }\n  });\n}\n\ntemplate <typename T> void lu(Bencher bencher, PlotArg arg) {\n  MKL_INT n = arg.n;\n  std::srand(0);\n  Mat<T> H_orig = rand<T>(n, n);\n  Mat<T> H = H_orig;\n  Mat<MKL_INT> p(n, 1);\n  Mat<T> work(n, max(n, 16));\n\n  std::move(bencher).bench([&] {\n    H = H_orig;\n\n    Mkl<T>::getrf(addr(n), addr(n), data(H), addr(stride(H)), p.data(),\n                  addr((MKL_INT)0));\n  });\n}\n\ntemplate <typename T> void piv_lu(Bencher bencher, PlotArg arg) {\n  MKL_INT n = arg.n;\n  std::srand(0);\n  Mat<T> H_orig = rand<T>(n, n);\n  Mat<T> H = H_orig;\n  Mat<MKL_INT> p(n, 1);\n  Mat<MKL_INT> q(n, 1);\n  Mat<T> work(n, max(n, 16));\n\n  std::move(bencher).bench([&] {\n    H = H_orig;\n\n    Mkl<T>::getc2(addr(n), data(H), addr(stride(H)), p.data(), q.data(),\n                  addr((MKL_INT)0));\n  });\n}\ntemplate <typename T> void svd(Bencher bencher, PlotArg arg) {\n  MKL_INT m = arg.n;\n  MKL_INT n = arg.n;\n  MKL_INT mn = m * n;\n  MKL_INT mx = max(m, n);\n\n  std::srand(0);\n  Mat<T> H_orig = rand<T>(m, n);\n  Mat<T> H = H_orig;\n  Mat<T> U(m, m);\n  Mat<T> V(n, n);\n  Mat<typename Mat<T>::RealScalar> S(m, 1);\n\n  Mat<typename Mat<T>::RealScalar> rwork(\n      max(5 * mn * mn + 5 * mn, 2 * mx * mn + 2 * mn * mn + mn), 1);\n  Mat<MKL_INT> iwork(8 * max(m, n), 1);\n\n  T lwork_;\n  if constexpr (std::same_as<T, typename Mkl<T>::T>) {\n    Mkl<T>::gesdd(\"A\", addr(m), addr(n), data(H), addr(stride(H)), data(S),\n                  data(U), addr(stride(U)), data(V), addr(stride(V)),\n                  Data<T>(&lwork_), addr((MKL_INT)-1), iwork.data(),\n                  addr((MKL_INT)0));\n  } else {\n    Mkl<T>::gesdd(\"A\", addr(m), addr(n), data(H), addr(stride(H)), data(S),\n                  data(U), addr(stride(U)), data(V), addr(stride(V)),\n                  Data<T>(&lwork_), addr((MKL_INT)-1), data(rwork),\n                  iwork.data(), addr((MKL_INT)0));\n  }\n\n  auto lwork = 2 * (MKL_INT)std::real(lwork_);\n  Mat<T> work(lwork, 1);\n\n  std::move(bencher).bench([&] {\n    H = H_orig;\n\n    if constexpr (std::same_as<T, typename Mkl<T>::T>) {\n      Mkl<T>::gesdd(\"A\", addr(m), addr(n), data(H), addr(stride(H)), data(S),\n                    data(U), addr(stride(U)), data(V), addr(stride(V)),\n                    data(work), addr(lwork), iwork.data(), addr((MKL_INT)0));\n    } else {\n      Mkl<T>::gesdd(\"A\", addr(m), addr(n), data(H), addr(stride(H)), data(S),\n                    data(U), addr(stride(U)), data(V), addr(stride(V)),\n                    data(work), addr(lwork), data(rwork), iwork.data(),\n                    addr((MKL_INT)0));\n    }\n  });\n}\ntemplate <typename T> void thin_svd(Bencher bencher, PlotArg arg) {\n  MKL_INT m = 4096;\n  MKL_INT n = arg.n;\n  MKL_INT mn = m * n;\n  MKL_INT mx = max(m, n);\n\n  std::srand(0);\n  Mat<T> H_orig = rand<T>(m, n);\n  Mat<T> H = H_orig;\n  Mat<T> U(m, m);\n  Mat<T> V(n, n);\n  Mat<typename Mat<T>::RealScalar> S(m, 1);\n\n  Mat<typename Mat<T>::RealScalar> rwork(\n      max(5 * mn * mn + 5 * mn, 2 * mx * mn + 2 * mn * mn + mn), 1);\n  Mat<MKL_INT> iwork(8 * max(m, n), 1);\n\n  T lwork_;\n  if constexpr (std::same_as<T, typename Mkl<T>::T>) {\n    Mkl<T>::gesdd(\"S\", addr(m), addr(n), data(H), addr(stride(H)), data(S),\n                  data(U), addr(stride(U)), data(V), addr(stride(V)),\n                  Data<T>(&lwork_), addr((MKL_INT)-1), iwork.data(),\n                  addr((MKL_INT)0));\n  } else {\n    Mkl<T>::gesdd(\"S\", addr(m), addr(n), data(H), addr(stride(H)), data(S),\n                  data(U), addr(stride(U)), data(V), addr(stride(V)),\n                  Data<T>(&lwork_), addr((MKL_INT)-1), data(rwork),\n                  iwork.data(), addr((MKL_INT)0));\n  }\n\n  auto lwork = 2 * (MKL_INT)std::real(lwork_);\n  Mat<T> work(lwork, 1);\n\n  std::move(bencher).bench([&] {\n    H = H_orig;\n\n    if constexpr (std::same_as<T, typename Mkl<T>::T>) {\n      Mkl<T>::gesdd(\"S\", addr(m), addr(n), data(H), addr(stride(H)), data(S),\n                    data(U), addr(stride(U)), data(V), addr(stride(V)),\n                    data(work), addr(lwork), iwork.data(), addr((MKL_INT)0));\n    } else {\n      Mkl<T>::gesdd(\"S\", addr(m), addr(n), data(H), addr(stride(H)), data(S),\n                    data(U), addr(stride(U)), data(V), addr(stride(V)),\n                    data(work), addr(lwork), data(rwork), iwork.data(),\n                    addr((MKL_INT)0));\n    }\n  });\n}\ntemplate <typename T> void eigh(Bencher bencher, PlotArg arg) {\n  MKL_INT n = arg.n;\n\n  std::srand(0);\n  Mat<T> H_orig = randh<T>(n);\n  Mat<T> H = H_orig;\n  Mat<T> U(n, n);\n  Mat<typename Mat<T>::RealScalar> W(n, 1);\n\n  T lwork_ = 0;\n  typename Mat<T>::RealScalar lrwork_ = 0;\n  MKL_INT liwork_ = 0;\n\n  if constexpr (std::same_as<T, typename Mkl<T>::T>) {\n    Mkl<T>::evd(\"V\", \"L\", addr(n), data(H), addr(stride(H)), data(W),\n                Data<T>(&lwork_), addr((MKL_INT)-1), &liwork_,\n                addr((MKL_INT)-1), addr((MKL_INT)0));\n  } else {\n    Mkl<T>::evd(\"V\", \"L\", addr(n), data(H), addr(stride(H)), data(W),\n                Data<T>(&lwork_), addr((MKL_INT)-1), &lrwork_,\n                addr((MKL_INT)-1), &liwork_, addr((MKL_INT)-1),\n                addr((MKL_INT)0));\n  }\n\n  MKL_INT lwork = 2 * (MKL_INT)(std::real(lwork_));\n  MKL_INT lrwork = 2 * (MKL_INT)(lrwork_);\n  MKL_INT liwork = 2 * (MKL_INT)(liwork_);\n\n  Mat<T> work(lwork, 1);\n  Mat<typename Mat<T>::RealScalar> rwork(lrwork, 1);\n  Mat<MKL_INT> iwork(liwork, 1);\n\n  std::move(bencher).bench([&] {\n    H = H_orig;\n\n    if constexpr (std::same_as<T, typename Mkl<T>::T>) {\n      Mkl<T>::evd(\"V\", \"L\", addr(n), data(H), addr(stride(H)), data(W),\n                  data(work), addr(lwork), iwork.data(), addr(liwork),\n                  addr((MKL_INT)0));\n    } else {\n      Mkl<T>::evd(\"V\", \"L\", addr(n), data(H), addr(stride(H)), data(W),\n                  data(work), addr(lwork), data(rwork), addr(lrwork),\n                  iwork.data(), addr(liwork), addr((MKL_INT)0));\n    }\n  });\n}\ntemplate <typename T> void eig(Bencher bencher, PlotArg arg) {\n  MKL_INT n = arg.n;\n\n  std::srand(0);\n  Mat<T> H_orig = rand<T>(n, n);\n  Mat<T> H = H_orig;\n  Mat<T> U(n, n);\n  Mat<T> V(n, n);\n  Mat<T> W(n, 1);\n  Mat<typename Mat<T>::RealScalar> W_im(n, 1);\n  Mat<typename Mat<T>::RealScalar> rwork(2 * n, 1);\n\n  T lwork_;\n\n  if constexpr (std::same_as<T, typename Mkl<T>::T>) {\n    Mkl<T>::geev(\"V\", \"N\", addr(n), data(H), addr(stride(H)), data(W),\n                 data(W_im), data(U), addr(stride(U)), data(V), addr(stride(V)),\n                 Data<T>(&lwork_), addr((MKL_INT)-1), addr((MKL_INT)0));\n  } else {\n    Mkl<T>::geev(\"V\", \"N\", addr(n), data(H), addr(stride(H)), data(W), data(U),\n                 addr(stride(U)), data(V), addr(stride(V)), Data<T>(&lwork_),\n                 addr((MKL_INT)-1), data(rwork), addr((MKL_INT)0));\n  }\n\n  MKL_INT lwork = 2 * (MKL_INT)std::real(lwork_);\n\n  Mat<T> work(lwork, 1);\n\n  std::move(bencher).bench([&] {\n    H = H_orig;\n\n    if constexpr (std::same_as<T, typename Mkl<T>::T>) {\n      Mkl<T>::geev(\"V\", \"N\", addr(n), data(H), addr(stride(H)), data(W),\n                   data(W_im), data(U), addr(stride(U)), data(V),\n                   addr(stride(V)), data(work), addr(lwork), addr((MKL_INT)0));\n    } else {\n      Mkl<T>::geev(\"V\", \"N\", addr(n), data(H), addr(stride(H)), data(W),\n                   data(U), addr(stride(U)), data(V), addr(stride(V)),\n                   data(work), addr(lwork), data(rwork), addr((MKL_INT)0));\n    }\n  });\n}\n\nstd::string glue_name(std::string prefix, std::string name, std::string type) {\n  return prefix + \"_\" + name + \"<\" + type + \">\";\n}\ntemplate <typename T>\nvoid register_funcs(std::string prefix, std::string ty, Bench &bench) {\n  PlotArg args[] = {\n      4,   8,   12,   16,   24,   32,   48,   64,   128,\n      256, 512, 1024, 1536, 2048, 2560, 3072, 3584, 4096,\n  };\n\n  auto do_it = [&](std::string name, FnPtr<Bencher, PlotArg> fn) {\n    bench.register_funcs<PlotArg>({{{glue_name(prefix, name, ty), fn}}}, args);\n  };\n\n  do_it(\"cholesky\", cholesky<T>);\n  do_it(\"qr\", qr<T>);\n  do_it(\"piv_qr\", piv_qr<T>);\n  do_it(\"lu\", lu<T>);\n  do_it(\"piv_lu\", piv_lu<T>);\n  do_it(\"svd\", svd<T>);\n  do_it(\"thin_svd\", thin_svd<T>);\n  do_it(\"eigh\", eigh<T>);\n  do_it(\"eig\", eig<T>);\n}\n\nf64 flops_per_sec(size_t n, f64 time) {\n  return f64(n) * f64(n) * f64(n) / time;\n}\n\nint main() {\n  auto config = BenchConfig::from_args();\n  config.set_metric(\"n³/s\", Monotonicity::HigherIsBetter, flops_per_sec);\n  auto bench = Bench::from_config(config);\n#ifdef BENCH_MKL\n  std::string prefix = \"mkl\";\n#else\n  std::string prefix = \"openblas\";\n#endif\n\n  register_funcs<f32>(prefix, \"f32\", bench);\n  register_funcs<f64>(prefix, \"f64\", bench);\n  register_funcs<c32>(prefix, \"c32\", bench);\n  register_funcs<c64>(prefix, \"c64\", bench);\n  bench.run();\n}\n"
        },
        {
          "name": "launch_benches.sh",
          "type": "blob",
          "size": 1.0361328125,
          "content": "OMP_NUM_THREADS=12 ./target/mkl_bench --output=\"./target/diol_mkl_mt.json\" --func-filter=\"$FUNC_FILTER\" --arg-filter=\"$ARG_FILTER\"\nOMP_NUM_THREADS=12 ./target/openblas_bench --output=\"./target/diol_openblas_mt.json\" --func-filter=\"$FUNC_FILTER\" --arg-filter=\"$ARG_FILTER\"\nOMP_NUM_THREADS=1 ./target/mkl_bench --output=\"./target/diol_mkl_st.json\" --func-filter=\"$FUNC_FILTER\" --arg-filter=\"$ARG_FILTER\"\nOMP_NUM_THREADS=1 ./target/openblas_bench --output=\"./target/diol_openblas_st.json\" --func-filter=\"$FUNC_FILTER\" --arg-filter=\"$ARG_FILTER\"\ncargo bench --bench bench --features=nightly -- --output=\"./target/diol_faer_mt.json\" --func-filter=\"faer_par_\"\"$FUNC_FILTER\" --arg-filter=\"$ARG_FILTER\"\ncargo bench --bench bench --features=nightly -- --output=\"./target/diol_faer_st.json\" --func-filter=\"faer_seq_\"\"$FUNC_FILTER\" --arg-filter=\"$ARG_FILTER\"\ncargo bench --bench bench --features=nightly -- --output=\"./target/diol_nalgebra_st.json\" --func-filter=\"nalgebra_\"\"$FUNC_FILTER\" --arg-filter=\"$ARG_FILTER\"\n\ncargo bench --bench bench_aggregate --features=nightly\n"
        },
        {
          "name": "paper.bib",
          "type": "blob",
          "size": 7.37109375,
          "content": "@article{BLIS1,\n  author      = {Field G. {Van~Zee} and Robert A. {van~de~Geijn}},\n  title       = {{BLIS}: A Framework for Rapidly Instantiating {BLAS} Functionality},\n  journal     = {ACM Transactions on Mathematical Software},\n  volume      = {41},\n  number      = {3},\n  pages       = {14:1--14:33},\n  month       = {June},\n  year        = {2015},\n  issue_date  = {June 2015},\n  url         = {https://doi.acm.org/10.1145/2764454},\n}\n@inproceedings{10.1145/2503210.2503219,\n  author = {Wang, Qian and Zhang, Xianyi and Zhang, Yunquan and Yi, Qing},\n  title = {AUGEM: Automatically Generate High Performance Dense Linear Algebra Kernels on X86 CPUs},\n  year = {2013},\n  isbn = {9781450323789},\n  publisher = {Association for Computing Machinery},\n  address = {New York, NY, USA},\n  url = {https://doi.org/10.1145/2503210.2503219},\n  doi = {10.1145/2503210.2503219},\n  abstract = {Basic Liner algebra subprograms (BLAS) is a fundamental library in scientific computing. In this paper, we present a template-based optimization framework, AUGEM, which can automatically generate fully optimized assembly code for several dense linear algebra (DLA) kernels, such as GEMM, GEMV, AXPY and DOT, on varying multi-core CPUs without requiring any manual interference from developers. In particular, based on domain-specific knowledge about algorithms of the DLA kernels, we use a collection of parameterized code templates to formulate a number of commonly occurring instruction sequences within the optimized low-level C code of these DLA kernels. Then, our framework uses a specialized low-level C optimizer to identify instruction sequences that match the pre-defined code templates and thereby translates them into extremely efficient SSE/AVX instructions. The DLA kernels generated by our template-based approach surpass the implementations of Intel MKL and AMD ACML BLAS libraries, on both Intel Sandy Bridge and AMD Piledriver processors.},\n  booktitle = {Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis},\n  articleno = {25},\n  numpages = {12},\n  keywords = {DLA code optimization, auto-tuning, code generation},\n  location = {Denver, Colorado},\n  series = {SC '13}\n}\n@BOOK{lapack99,\n  AUTHOR = {Anderson, E. and Bai, Z. and Bischof, C. and\n  Blackford, S. and Demmel, J. and Dongarra, J. and\n  Du Croz, J. and Greenbaum, A. and Hammarling, S. and\n  McKenney, A. and Sorensen, D.},\n  TITLE = {{LAPACK} Users' Guide},\n  EDITION = {Third},\n  PUBLISHER = {Society for Industrial and Applied Mathematics},\n  YEAR = {1999},\n  ADDRESS = {Philadelphia, PA},\n  ISBN = {0-89871-447-8 (paperback)} \n} \n@MISC{eigenweb,\n  author = {Ga\\\"{e}l Guennebaud and Beno\\^{i}t Jacob and others},\n  title = {Eigen v3},\n  howpublished = {http://eigen.tuxfamily.org},\n  year = {2010}\n}\n@MISC{rayon,\n  author = {{Rayon developers}},\n  title = {Rayon},\n  howpublished = {https://github.com/rayon-rs/rayon},\n  year = {2015}\n}\n@article{10.1145/2382585.2382587,\n  author = {{Van~Zee}, Field G. and {van~de~Geijn}, Robert A. and Quintana-Ort\\'{\\i}, Gregorio and Elizondo, G. Joseph},\n  title = {Families of Algorithms for Reducing a Matrix to Condensed Form},\n  year = {2012},\n  issue_date = {November 2012},\n  publisher = {Association for Computing Machinery},\n  address = {New York, NY, USA},\n  volume = {39},\n  number = {1},\n  issn = {0098-3500},\n  url = {https://doi.org/10.1145/2382585.2382587},\n  doi = {10.1145/2382585.2382587},\n  abstract = {In a recent paper it was shown how memory traffic can be diminished by reformulating the classic algorithm for reducing a matrix to bidiagonal form, a preprocess when computing the singular values of a dense matrix. The key is a reordering of the computation so that the most memory-intensive operations can be “fused.” In this article, we show that other operations that reduce matrices to condensed form (reduction to upper Hessenberg form and reduction to tridiagonal form) can be similarly reorganized, yielding different sets of operations that can be fused. By developing the algorithms with a common framework and notation, we facilitate the comparing and contrasting of the different algorithms and opportunities for optimization on sequential architectures. We discuss the algorithms, develop a simple model to estimate the speedup potential from fusing, and showcase performance improvements consistent with the what the model predicts.},\n  journal = {ACM Trans. Math. Softw.},\n  month = {nov},\n  articleno = {2},\n  numpages = {32},\n  keywords = {libraries, Hessenberg, tridiagonal, bidiagonal, high performance, reduction, Linear algebra}\n}\n@article{cholmod,\n  author = {Chen, Yanqing and Davis, Timothy A. and Hager, William W. and Rajamanickam, Sivasankaran},\n  title = {Algorithm 887: CHOLMOD, Supernodal Sparse Cholesky Factorization and Update/Downdate},\n  year = {2008},\n  issue_date = {October 2008},\n  publisher = {Association for Computing Machinery},\n  address = {New York, NY, USA},\n  volume = {35},\n  number = {3},\n  issn = {0098-3500},\n  url = {https://doi.org/10.1145/1391989.1391995},\n  doi = {10.1145/1391989.1391995},\n  abstract = {CHOLMOD is a set of routines for factorizing sparse symmetric positive definite matrices of the form A or AAT, updating/downdating a sparse Cholesky factorization, solving linear systems, updating/downdating the solution to the triangular system Lx = b, and many other sparse matrix functions for both symmetric and unsymmetric matrices. Its supernodal Cholesky factorization relies on LAPACK and the Level-3 BLAS, and obtains a substantial fraction of the peak performance of the BLAS. Both real and complex matrices are supported. CHOLMOD is written in ANSI/ISO C, with both C and MATLABTM interfaces. It appears in MATLAB 7.2 as x = Ab when A is sparse symmetric positive definite, as well as in several other sparse matrix functions.},\n  journal = {ACM Trans. Math. Softw.},\n  month = {oct},\n  articleno = {22},\n  numpages = {14},\n  keywords = {sparse matrices, linear equations, Cholesky factorization}\n}\n@book{chandra2001parallel,\n  title={Parallel programming in OpenMP},\n  author={Chandra, Rohit and Dagum, Leo and Kohr, David and Menon, Ramesh and Maydan, Dror and McDonald, Jeff},\n  year={2001},\n  publisher={Morgan kaufmann}\n}\n@article{tbb,\n  author = {Pheatt, Chuck},\n  title = {Intel® Threading Building Blocks},\n  year = {2008},\n  issue_date = {April 2008},\n  publisher = {Consortium for Computing Sciences in Colleges},\n  address = {Evansville, IN, USA},\n  volume = {23},\n  number = {4},\n  issn = {1937-4771},\n  doi = {10.1016/b978-0-12-803761-4.00011-3},\n  abstract = {Intel® Threading Building Blocks [1] is a C++ runtime library that abstracts the low-level threading details necessary for effectively utilizing multi-core processors. It uses C++ templates to eliminate the need to create and manage threads. Applications tend to be more portable since parallelism is achieved through library calls and utilization of a task manager for scheduling. The task manager analyzes the system the software is running on, chooses the optimal number of threads, and performs load balancing that spreads out the work evenly across all processor cores. The library consists of data structures and algorithms that simplify parallel programming in C++ by avoiding requiring a programmer to use native threading packages such as POSIX threads or Windows threads, or even the portable Boost Threads.},\n  journal = {J. Comput. Sci. Coll.},\n  month = {apr},\n  pages = {298},\n  numpages = {1}\n}\n"
        },
        {
          "name": "paper.md",
          "type": "blob",
          "size": 7.3603515625,
          "content": "---\ntitle: 'faer: A linear algebra library for the Rust programming language'\ntags:\n  - Rust\n  - linear algebra\n  - math\nauthors:\n  - name: Sarah El Kazdadi\n    orcid: 0000-0002-5657-0710\n    affiliation: 1\naffiliations:\n - name: Independent Researcher, France\n   index: 1\ndate: 5 October 2023\nbibliography: paper.bib\n---\n\n# Summary\n\n`faer` is a portable high performance dense linear algebra library written in Rust.\nThe library offers a convenient high level API for performing matrix\ndecompositions and solving linear systems. This API is built on top of\na lower level API that gives the user more control over the memory allocation\nand multithreading settings.\n\nSupported platforms include the ones supported by Rust.\nExplicit SIMD instructions are currently used for x86-64 and Aarch64 (NEON),\nwith plans for SVE/SME and RVV optimizations once intrinsics for those are stabilized in Rust,\npossibly earlier than that if we allow usage of a JIT backend[^1].\n\nThe library provides a `Mat` type, allowing for quick and simple construction\nand manipulation of matrices, as well as lightweight view types `MatRef` and\n`MatMut` for building memory views over existing data.\n\nThese views are currently used to represent different kinds of matrices,\nsuch as generic rectangular matrices, symmetric/Hermitian/triangular \n(where only half of the matrix is stored) square matrices.\nIn the future, we plan to make use of the robust Rust type-system to better\nexpress the properties of those matrices, and prevent accidental misuse of the library's API. \n\nMultiple scalar types are supported, and the library code is generic over the\ndata type. Native floating point types `f32`, `f64`[^2], `c32`, and `c64` are\nsupported out of the box, as well as any user-defined types that satisfy the\nrequested interface, such as extended precision real numbers (double-double or multi-precision floats),\ncomplex numbers using the aforementioned types as the base element, dual/hyper-dual numbers[^3]\n\n\n[^1]: Inline assembly is not entirely appropriate for our use case since it's hard to make it generic enough for all the operations and types that we wish to support.\n[^2]: IEEE 754-2008, with no implicit `fusedMultiplyAdd` contractions and with slight differences around NaN handling. See the [float semantics](https://github.com/rust-lang/rfcs/pull/3514) RFC for more information.\n[^3]: These support at least for the simpler matrix decompositions (Cholesky, LU, QR). It's not clear yet how to handle iterative algorithms like the SVD and Eigendecomposition.\n\n# Statement of need\n\nRust was chosen as a language for the library since it allows full control\nover the memory layout of data and exposes low level CPU intrinsics for\nSIMD[^4] computations. Additionally, its memory safety features make it a\nperfect candidate for writing efficient and parallel code, since the compiler\nstatically checks for errors that are common in other low level languages,\nsuch as data races and fatal use-after-free errors.\n\nRust also allows compatibility with the C ABI, allowing for simple interoperability\nwith C, and most other languages by extension. Once a design has been properly fleshed out,\nwe plan to expose a C API, along with bindings to other languages (Currently planned are C, C++, Python and Julia bindings).\n\nAside from `faer`, the Rust ecosystem lacks high performance matrix factorization\nlibraries that aren't C library wrappers, which presents a distribution\nchallenge and can impede generic programming.\n\n[^4]: Single instruction, multiple data operations that CPUs can use to parallelize data processing at the instruction level.\n\n# Features\n\n`faer` exposes a central `Entity` trait that allows users to describe how their\ndata should be laid out in memory. For example, native floating point types are\nlaid out contiguously in memory to make use of SIMD instructions that prefer this layout,\nwhile complex types have the option of either being laid out contiguously or in a split format.\nThe latter is also called a zomplex data type in CHOLMOD (@cholmod).\nAn example of a type that benefits immensely from this is the double-double type, which is\ncomposed of two `f64` components, stored in separate containers. This separate\nstorage scheme allows us to load each chunk individually to a SIMD register,\nopening new avenues for generic vectorization.\n\nThe library generically implements algorithms for matrix multiplication, based\non the approach of @BLIS1. For native types, `faer` uses explicit SIMD\ndepending on the detected CPU features, that dispatch to several precompiled\nvariants for operations that can make use of these features.\nAn interesting alternative would be to compile the code Just-in-Time, which could improve compilation times and reduce binary size.\nBut there are also possible downsides that have to be weighed against these advantages,\nsuch as increasing the startup time to optimize and assemble the code,\nas well as the gap in maturity between ahead-of-time compilation (currently backed by LLVM),\nand just-in-time compilation, for which the Rust ecosystem is still developing.\nThe library then uses matrix multiplication as a building block to implement commonly used matrix\ndecompositions, based on state of the art algorithms in order to guarantee\nnumerical robustness:  \n- Cholesky (LLT, LDLT and Bunch-Kaufman LDLT),  \n- QR (with and without column pivoting),  \n- LU (with partial and full pivoting),  \n- SVD (with or without singular vectors, thin or full),  \n- eigenvalue decomposition (with or without eigenvectors).\n\nFor algorithms that are memory-bound and don't make much use of matrix multiplication,\n`faer` uses optimized fused kernels[^5]. This can immensely improve the performance of the\nQR decomposition with column pivoting, the LU decomposition with full pivoting,\nas well as the reduction to condensed form to prepare matrices for the SVD or\neigenvalue decomposition, as described by @10.1145/2382585.2382587.\n\nState of the art algorithms are used for each decomposition, allowing performance\nthat matches or even surpasses other low level libraries such as OpenBLAS\n(@10.1145/2503210.2503219), LAPACK (@lapack99), and Eigen (@eigenweb).\n\nTo achieve high performance parallelism, `faer` uses the Rayon library (@rayon) as a\nbackend, and has shown to be competitive with other frameworks such as OpenMP (@chandra2001parallel)\nand Intel Thread Building Blocks (@tbb).\n\n[^5]: For example, computing $A x$ and $A.T y$ with a single pass over $A$, rather than two.\n\n# Performance\n\nHere we present the benchmarks for a representative subset of operations that\nshowcase our improvements over the current state of the art.\n\nThe benchmarks were run on an 11th Gen Intel(R) Core(TM) i5-11400 @ 2.60GHz with 12 threads.\nEigen is compiled with the `-fopenmp` flag to enable parallelism.\n\n![$n^3$ over run time of matrix multiplication. Higher is better](https://github.com/sarah-ek/faer-rs/files/13344473/matmul.pdf){#matmul_perf width=\"100%\"}\n\n![$n^3$ over run time of QR decomposition. Higher is better](https://github.com/sarah-ek/faer-rs/files/13344474/qr.pdf){#qr_perf width=\"100%\"}\n\n![$n^3$ over run time of eigenvalue decomposition. Higher is better](https://github.com/sarah-ek/faer-rs/files/13344472/evd.pdf){#evd_perf width=\"100%\"}\n\n# Future work\nWe have so far focused mainly on dense matrix algorithms, which will eventually form\nthe foundation of supernodal sparse decompositions.\nSparse algorithm implementations are still a work in progress and will be\nshowcased in a future paper.\n\n# References\n"
        },
        {
          "name": "plot_script.jl",
          "type": "blob",
          "size": 2.599609375,
          "content": "using Plots\nusing CSV\n\nENV[\"GKSwstype\"]=\"nul\"\n\nSIZE = (640, 400)\n\nfor ty in [\"f32\", \"f64\", \"c32\", \"c64\"]\n    for (algo, name) in [\n        (\"cholesky\", \"Cholesky\"),\n        (\"qr\", \"QR\"),\n        (\"piv_qr\", \"QR with column pivoting\"),\n        (\"lu\", \"LU with partial pivoting\"),\n        (\"piv_lu\", \"LU with full pivoting\"),\n        (\"svd\", \"Singular value decomposition\"),\n        (\"thin_svd\", \"Thin singular value decomposition\"),\n        (\"eigh\", \"Self adjoint eigenvalue decomposition\"),\n        (\"eig\", \"General eigenvalue decomposition\"),\n    ]\n        data = CSV.File(\"./target/mt_$(algo)_$(ty).csv\", types=Float64)\n        norm = data[\"faer\"]\n        p = plot(\n            data[\"n\"],\n            [data[\"faer\"]./norm data[\"mkl\"]./norm data[\"openblas\"]./norm],\n            size=SIZE,\n            xaxis=:log,\n            yaxis=:log,\n            title=\"$(name) ($(ty))\",\n            label=[\"faer\" \"mkl\" \"openblas\"],\n            xlabel=\"Matrix dimension (n)\",\n            ylabel=\"1/time (normalized)\",\n            ylims=(0.1, 10.0),\n            yticks=([0.1, 0.2, 0.5, 1.0, 2.0, 5.0, 10.0], [\"0.1\", \"0.2\", \"0.5\", \"1.0\", \"2.0\", \"5.0\", \"10.0\"])\n        )\n        savefig(p, \"./target/mt_$(algo)_$(ty)_plot.png\")\n    end\nend\n\nfor ty in [\"f32\", \"f64\", \"c32\", \"c64\"]\n    for (algo, name) in [\n        (\"cholesky\", \"Cholesky\"),\n        (\"qr\", \"QR\"),\n        (\"piv_qr\", \"QR with column pivoting\"),\n        (\"lu\", \"LU with partial pivoting\"),\n        (\"piv_lu\", \"LU with full pivoting\"),\n        (\"svd\", \"Singular value decomposition\"),\n        (\"thin_svd\", \"Thin singular value decomposition\"),\n        (\"eigh\", \"Self adjoint eigenvalue decomposition\"),\n        (\"eig\", \"General eigenvalue decomposition\"),\n    ]\n        data = CSV.File(\"./target/st_$(algo)_$(ty).csv\", types=Float64)\n        norm = data[\"faer\"]\n        if all(isnan.(data[\"nalgebra\"]))\n            funcs = [data[\"faer\"]./norm data[\"mkl\"]./norm data[\"openblas\"]./norm]\n            label = [\"faer\" \"mkl\" \"openblas\"]\n        else\n            funcs = [data[\"faer\"]./norm data[\"mkl\"]./norm data[\"openblas\"]./norm data[\"nalgebra\"]./norm]\n            label = [\"faer\" \"mkl\" \"openblas\" \"nalgebra\"]\n        end\n        p = plot(\n            data[\"n\"],\n            funcs,\n            size=SIZE,\n            xaxis=:log,\n            yaxis=:log,\n            title=\"$(name) ($(ty))\",\n            label=label,\n            xlabel=\"Matrix dimension (n)\",\n            ylabel=\"1/time (normalized)\",\n            ylims=(0.1, 10.0),\n            yticks=([0.1, 0.2, 0.5, 1.0, 2.0, 5.0, 10.0], [\"0.1\", \"0.2\", \"0.5\", \"1.0\", \"2.0\", \"5.0\", \"10.0\"])\n        )\n        savefig(p, \"./target/st_$(algo)_$(ty)_plot.png\")\n    end\nend\n\n"
        },
        {
          "name": "rustfmt.toml",
          "type": "blob",
          "size": 0.1259765625,
          "content": "unstable_features = true\nimports_granularity=\"crate\"\nformat_code_in_doc_comments = true\nwrap_comments = true\ncomment_width = 100\n"
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "test_data",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}