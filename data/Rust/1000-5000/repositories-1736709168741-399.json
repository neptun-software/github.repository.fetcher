{
  "metadata": {
    "timestamp": 1736709168741,
    "page": 399,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "rustcc/writing-an-os-in-rust",
      "stars": 2190,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0107421875,
          "content": ".DS_Store\n\n"
        },
        {
          "name": "01-freestanding-rust-binary.md",
          "type": "blob",
          "size": 18.1689453125,
          "content": "> 原文：https://os.phil-opp.com/freestanding-rust-binary/\r\n>\r\n> 原作者：@phil-opp\r\n>\r\n> 译者：洛佳  华中科技大学\r\n\r\n# 使用Rust编写操作系统（一）：独立式可执行程序\r\n\r\n我们的第一步，是在不连接标准库的前提下，创建独立的Rust可执行文件。无需底层操作系统的支撑，这将能让在**裸机**（[bare metal](https://en.wikipedia.org/wiki/Bare_machine)）上运行Rust代码成为现实。\r\n\r\n## 简介\r\n\r\n要编写一个操作系统内核，我们的代码应当不基于任何的操作系统特性。这意味着我们不能使用线程、文件、堆内存、网络、随机数、标准输出，或其它任何需要特定硬件和操作系统抽象的特性；这其实讲得通，因为我们正在编写自己的硬件驱动和操作系统。\r\n\r\n实现这一点，意味着我们不能使用[Rust标准库](https://doc.rust-lang.org/std/)的大部分；但还有很多Rust特性是我们依然可以使用的。比如说，我们可以使用[迭代器](https://doc.rust-lang.org/book/ch13-02-iterators.html)、[闭包](https://doc.rust-lang.org/book/ch13-01-closures.html)、[模式匹配](https://doc.rust-lang.org/book/ch06-00-enums.html)、[Option](https://doc.rust-lang.org/core/option/)、[Result](https://doc.rust-lang.org/core/result/index.html)、[字符串格式化](https://doc.rust-lang.org/core/macro.write.html)，当然还有[所有权系统](https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html)。这些功能让我们能够编写表达性强、高层抽象的操作系统，而无需操心[未定义行为](https://www.nayuki.io/page/undefined-behavior-in-c-and-cplusplus-programs)和[内存安全](https://tonyarcieri.com/it-s-time-for-a-memory-safety-intervention)。\r\n\r\n为了用Rust编写一个操作系统内核，我们需要独立于操作系统，创建一个可执行程序。这样的可执行程序常被称作**独立式可执行程序**（freestanding executable）或**裸机程序**(bare-metal executable)。\r\n\r\n在这篇文章里，我们将逐步地创建一个独立式可执行程序，并且详细解释为什么每个步骤都是必须的。如果读者只对最终的代码感兴趣，可以跳转到本篇文章的小结部分。\r\n\r\n## 禁用标准库\r\n\r\n在默认情况下，所有的Rust**包**（crate）都会链接**标准库**（[standard library](https://doc.rust-lang.org/std/)），而标准库依赖于操作系统功能，如线程、文件系统、网络。标准库还与**Rust的C语言标准库实现库**（libc）相关联，它也是和操作系统紧密交互的。既然我们的计划是编写自己的操作系统，我们就可以不使用任何与操作系统相关的库——因此我们必须禁用**标准库自动引用**（automatic inclusion）。使用[no_std属性](https://doc.rust-lang.org/book/first-edition/using-rust-without-the-standard-library.html)可以实现这一点。\r\n\r\n我们可以从创建一个新的cargo项目开始。最简单的办法是使用下面的命令：\r\n\r\n```bash\r\n> cargo new blog_os\r\n```\r\n\r\n这里，我把项目命名为`blog_os`，当然读者也可以选择自己的项目名称。这里，cargo默认为我们添加了`--bin`选项，说明我们将要创建一个可执行文件（而不是一个库）；cargo还为我们添加了`--edition 2018`标签，指明项目的包要使用Rust的**2018版次**（[2018 edition](https://rust-lang-nursery.github.io/edition-guide/rust-2018/index.html)）。当我们执行这行指令的时候，cargo为我们创建的目录结构如下：\r\n\r\n```text\r\nblog_os\r\n├── Cargo.toml\r\n└── src\r\n    └── main.rs\r\n```\r\n\r\n在这里，`Cargo.toml`文件包含了包的**配置**（configuration），比如包的名称、作者、[semver版本](http://semver.org/)和项目依赖项；`src/main.rs`文件包含包的**根模块**（root module）和main函数。我们可以使用`cargo build`来编译这个包，然后在`target/debug`文件夹内找到编译好的`blog_os`二进制文件。\r\n\r\n### no_std属性\r\n\r\n现在我们的包依然隐式地与标准库链接。为了禁用这种链接，我们可以尝试添加[no_std属性](https://doc.rust-lang.org/book/first-edition/using-rust-without-the-standard-library.html)：\r\n\r\n```rust\r\n// main.rs\r\n\r\n#![no_std]\r\n\r\nfn main() {\r\n    println!(\"Hello, world!\");\r\n}\r\n```\r\n\r\n看起来非常顺利。但我们使用`cargo build`来编译时，却出现了下面的错误：\r\n\r\n```rust\r\nerror: cannot find macro `println!` in this scope\r\n --> src\\main.rs:4:5\r\n  |\r\n4 |     println!(\"Hello, world!\");\r\n  |     ^^^^^^^\r\n```\r\n\r\n出现这个错误的原因是，[println!宏](https://doc.rust-lang.org/std/macro.println.html)是标准库的一部分，而我们的项目不再依赖标准库。我们选择不再打印字符串。这也能解释得通，因为`println!`将会向**标准输出**（[standard output](https://en.wikipedia.org/wiki/Standard_streams#Standard_output_.28stdout.29)）打印字符，它依赖于特殊的文件描述符；这个特性是由操作系统提供的。\r\n\r\n所以我们可以移除这行代码，这样main函数就是空的了。再次编译：\r\n\r\n```rust\r\n// main.rs\r\n\r\n#![no_std]\r\n\r\nfn main() {}\r\n```\r\n\r\n```\r\n> cargo build\r\nerror: `#[panic_handler]` function required, but not found\r\nerror: language item required, but not found: `eh_personality`\r\n```\r\n\r\n现在我们发现，代码缺少一个`#[panic_handler]`函数和一个**语言项**（language item）。\r\n\r\n## 实现panic处理函数\r\n\r\n`panic_handler`属性被用于定义一个函数；在程序panic时，这个函数将会被调用。标准库中提供了自己的panic处理函数，但在`no_std`环境中，我们需要定义自己的panic处理函数：\r\n\r\n```rust\r\n// in main.rs\r\n\r\nuse core::panic::PanicInfo;\r\n\r\n/// 这个函数将在panic时被调用\r\n#[panic_handler]\r\nfn panic(_info: &PanicInfo) -> ! {\r\n    loop {}\r\n}\r\n```\r\n\r\n类型为[PanicInfo](https://doc.rust-lang.org/nightly/core/panic/struct.PanicInfo.html)的参数包含了panic发生的文件名、代码行数和可选的错误信息。这个函数从不返回，所以他被标记为**发散函数**（[diverging function](https://doc.rust-lang.org/book/first-edition/functions.html#diverging-functions)）。发散函数的返回类型称作**Never类型**（[\"never\" type](https://doc.rust-lang.org/nightly/std/primitive.never.html)），记为`!`。对这个函数，我们目前能做的事情很少，所以我们只需编写一个无限循环`loop {}`。\r\n\r\n## eh_personality语言项\r\n\r\n语言项是一些编译器需求的特殊函数或类型。举例来说，Rust的[Copy](https://doc.rust-lang.org/nightly/core/marker/trait.Copy.html) trait是一个这样的语言项，告诉编译器哪些类型需要遵循**复制语义**（[copy semantics](https://doc.rust-lang.org/nightly/core/marker/trait.Copy.html)）——当我们查找`Copy` trait的[实现](https://github.com/rust-lang/rust/blob/485397e49a02a3b7ff77c17e4a3f16c653925cb3/src/libcore/marker.rs#L296-L299)时，我们会发现，一个特殊的`#[lang = \"copy\"]`属性将它定义为了一个语言项，达到与编译器联系的目的。\r\n\r\n我们可以自己实现语言项，但这只应该是最后的手段：目前来看，语言项是高度不稳定的语言细节实现，它们不会经过编译期类型检查（所以编译器甚至不确保它们的参数类型是否正确）。幸运的是，我们有更稳定的方式，来修复上面的语言项错误。\r\n\r\n`eh_personality`语言项标记的函数，将被用于实现**栈展开**（[stack unwinding](http://www.bogotobogo.com/cplusplus/stackunwinding.php)）。在使用标准库的情况下，当panic发生时，Rust将使用栈展开，来运行在栈上活跃的所有变量的**析构函数**（destructor）——这确保了所有使用的内存都被释放，允许调用程序的**父进程**（parent thread）捕获panic，处理并继续运行。但是，栈展开是一个复杂的过程，如Linux的[libunwind](http://www.nongnu.org/libunwind/)或Windows的**结构化异常处理**（[structured exception handling, SEH](https://msdn.microsoft.com/en-us/library/windows/desktop/ms680657(v=vs.85).aspx)），通常需要依赖于操作系统的库；所以我们不在自己编写的操作系统中使用它。\r\n\r\n### 禁用栈展开\r\n\r\n在其它一些情况下，栈展开不是迫切需求的功能；因此，Rust提供了**panic时中止**（[abort on panic](https://github.com/rust-lang/rust/pull/32900)）的选项。这个选项能禁用栈展开相关的标志信息生成，也因此能缩小生成的二进制程序的长度。有许多方式能打开这个选项，最简单的方式是把下面的几行设置代码加入我们的`Cargo.toml`：\r\n\r\n```toml\r\n[profile.dev]\r\npanic = \"abort\"\r\n\r\n[profile.release]\r\npanic = \"abort\"\r\n```\r\n\r\n这些选项能将**dev配置**（dev profile）和**release配置**（release profile）的panic策略设为`abort`。`dev`配置适用于`cargo build`，而`release`配置适用于`cargo build --release`。现在编译器应该不再要求我们提供`eh_personality`语言项实现。\r\n\r\n现在我们已经修复了出现的两个错误，可以信心满满地开始编译了。然而，尝试编译运行后，一个新的错误出现了：\r\n\r\n```bash\r\n> cargo build\r\nerror: requires `start` lang_item\r\n```\r\n\r\n## start语言项\r\n\r\n这里，我们的程序遗失了`start`语言项，它将定义一个程序的**入口点**（entry point）。\r\n\r\n我们通常会认为，当运行一个程序时，首先被调用的是`main`函数。但是，大多数语言都拥有一个**运行时系统**（[runtime system](https://en.wikipedia.org/wiki/Runtime_system)），它通常为**垃圾回收**（garbage collection）或**绿色线程**（software threads，或green threads）服务，如Java的GC或Go语言的协程（goroutine）；这个运行时系统需要在main函数前启动，因为它需要让程序初始化。\r\n\r\n一个典型的使用标准库的Rust程序，它的运行将从名为`crt0`的运行时库开始。`crt0`意为C runtime zero，它能建立一个适合运行C语言程序的环境，这包含了栈的创建和可执行程序参数的传入。这之后，这个运行时库会调用[Rust的运行时入口点](https://github.com/rust-lang/rust/blob/bb4d1491466d8239a7a5fd68bd605e3276e97afb/src/libstd/rt.rs#L32-L73)，这个入口点被称作**start语言项**（\"start\" language item）。Rust只拥有一个极小的运行时，它只拥有较少的功能，如爆栈检测和打印**堆栈轨迹**（stack trace）。这之后，运行时将会调用main函数。\r\n\r\n我们的独立式可执行程序并不能访问Rust运行时或`crt0`库，所以我们需要定义自己的入口点。实现一个`start`语言项并不能解决问题，因为这之后程序依然要求`crt0`库。所以，我们要做的是，直接重写整个`crt0`库和它定义的入口点。\r\n\r\n### 重写入口点\r\n\r\n要告诉Rust编译器我们不使用预定义的入口点，我们可以添加`#![no_main]`属性。\r\n\r\n```rust\r\n#![no_std]\r\n#![no_main]\r\n\r\nuse core::panic::PanicInfo;\r\n\r\n/// 这个函数将在panic时被调用\r\n#[panic_handler]\r\nfn panic(_info: &PanicInfo) -> ! {\r\n    loop {}\r\n}\r\n```\r\n\r\n读者也许会注意到，我们移除了`main`函数。很显然，既然没有底层已有的运行时调用它，`main`函数将不会被运行。为了重写操作系统的入口点，我们转而编写一个`_start`函数：\r\n\r\n```rust\r\n#[no_mangle]\r\npub extern \"C\" fn _start() -> ! {\r\n    loop {}\r\n}\r\n```\r\n\r\n我们使用`no_mangle`标记这个函数，来对它禁用**名称重整**（[name mangling](https://en.wikipedia.org/wiki/Name_mangling)）——这确保Rust编译器输出一个名为`_start`的函数；否则，编译器可能最终生成名为`_ZN3blog_os4_start7hb173fedf945531caE`的函数，无法让链接器正确辨别。\r\n\r\n我们还将函数标记为`extern \"C\"`，告诉编译器这个函数应当使用[C语言的调用约定](https://en.wikipedia.org/wiki/Calling_convention)，而不是Rust语言的调用约定。函数名为`_start`，是因为大多数系统默认使用这个名字作为入口点名称。\r\n\r\n与前文的`panic`函数类似，这个函数的返回值类型为`!`——它定义了一个发散函数，或者说一个不允许返回的函数。这一点是必要的，因为这个入口点不将被任何函数调用，但将直接被操作系统或**引导程序**（bootloader）调用。所以作为函数返回的替换，这个入口点应该调用，比如操作系统提供的**exit系统调用**（[\"exit\" system call](https://en.wikipedia.org/wiki/Exit_(system_call))）函数。在我们编写操作系统的情况下，关机应该是一个合适的选择，因为**当一个独立式可执行程序返回时，不会留下任何需要做的事情**（there is nothing to do if a freestanding binary returns）。暂时来看，我们可以添加一个无限循环，这样可以符合返回值的类型。\r\n\r\n如果我们现在编译这段程序，会出来一大段不太好看的**链接器错误**（linker error）。\r\n\r\n## 链接器错误\r\n\r\n**链接器**（linker）是一个程序，它将生成的目标文件组合为一个可执行文件。不同的操作系统如Windows、macOS、Linux，规定了不同的可执行文件格式，因此也各有自己的链接器，抛出不同的错误；但这些错误的根本原因还是相同的：链接器的默认配置假定程序依赖于C语言的运行时环境，但我们的程序并不依赖于它。\r\n\r\n为了解决这个错误，我们需要告诉链接器，它不应该包含（include）C语言运行环境。我们可以选择提供特定的**链接器参数**（linker argument），也可以选择编译为**裸机目标**（bare metal target）。\r\n\r\n### 编译为裸机目标\r\n\r\n在默认情况下，Rust尝试适配当前的系统环境，编译可执行程序。举个栗子，如果你使用`x86_64`平台的Windows系统，Rust将尝试编译一个扩展名为`.exe`的Windows可执行程序，并使用`x86_64`指令集。这个环境又被称作你的**宿主系统**（\"host\" system）。\r\n\r\n为了描述不同的环境，Rust使用一个称为**目标三元组**（target triple）的字符串。要查看当前系统的目标三元组，我们可以运行`rustc --version --verbose`：\r\n\r\n```\r\nrustc 1.35.0-nightly (474e7a648 2019-04-07)\r\nbinary: rustc\r\ncommit-hash: 474e7a6486758ea6fc761893b1a49cd9076fb0ab\r\ncommit-date: 2019-04-07\r\nhost: x86_64-unknown-linux-gnu\r\nrelease: 1.35.0-nightly\r\nLLVM version: 8.0\r\n```\r\n\r\n上面这段输出来自于`x86_64`平台下的Linux系统。我们能看到，`host`字段的值为三元组`x86_64-unknown-linux-gnu`，它分为以下几个部分：CPU架构`x86_64`；供应商`unknown`；操作系统`linux`和[二进制接口](https://en.wikipedia.org/wiki/Application_binary_interface)`gnu`。\r\n\r\nRust编译器尝试为当前系统的三元组编译，并假定底层有一个类似于Windows或Linux的操作系统提供C语言运行环境——这将导致链接器错误。所以，为了避免这个错误，我们可以另选一个底层没有操作系统的运行环境。\r\n\r\n这样的运行环境被称作裸机环境，例如目标三元组`thumbv7em-none-eabihf`描述了一个ARM**嵌入式系统**（[embedded system](https://en.wikipedia.org/wiki/Embedded_system)）。我们暂时不需要了解它的细节，只需要知道这个环境底层没有操作系统——这是由三元组中的`none`描述的。我们需要用rustup安装这个目标：\r\n\r\n```\r\nrustup target add thumbv7em-none-eabihf\r\n```\r\n\r\n这行命令将为目标下载一个标准库和core库。这之后，我们就能为这个目标构建独立式可执行程序了：\r\n\r\n```\r\ncargo build --target thumbv7em-none-eabihf\r\n```\r\n\r\n我们传递了`--target`参数，来为裸机目标系统**交叉编译**（[cross compile](https://en.wikipedia.org/wiki/Cross_compiler)）我们的程序。我们的目标并不包括操作系统，所以链接器不会试着链接C语言运行环境，因此构建过程成功完成，不会产生链接器错误。\r\n\r\n我们将使用这个方法编写自己的操作系统内核。我们不将编译到`thumbv7em-none-eabihf`，而是使用描述`x86_64`环境的**自定义目标**（[custom target](https://doc.rust-lang.org/rustc/targets/custom.html)）。在下篇文章中，我们将详细描述一些相关的细节。\r\n\r\n### 链接器参数\r\n\r\n我们也可以选择不编译到裸机系统，因为传递特定的参数也能解决链接器错误问题。虽然我们不将在后文中使用这个方法，为了教程的完整性，我们也撰写了专门的短文，来提供这个途径的解决方案。\r\n\r\n[链接器参数](./appendix-a-linker-arguments.md)\r\n\r\n## 小结\r\n\r\n一个用Rust编写的最小化的独立式可执行程序应该长这样：\r\n\r\n`src/main.rs`：\r\n\r\n```rust\r\n#![no_std] // 不链接Rust标准库\r\n#![no_main] // 禁用所有Rust层级的入口点\r\n\r\nuse core::panic::PanicInfo;\r\n\r\n#[no_mangle] // 不重整函数名\r\npub extern \"C\" fn _start() -> ! {\r\n    // 因为编译器会寻找一个名为`_start`的函数，所以这个函数就是入口点\r\n    // 默认命名为`_start`\r\n    loop {}\r\n}\r\n\r\n/// 这个函数将在panic时被调用\r\n#[panic_handler]\r\nfn panic(_info: &PanicInfo) -> ! {\r\n    loop {}\r\n}\r\n```\r\n\r\n`Cargo.toml`：\r\n\r\n```toml\r\n[package]\r\nname = \"crate_name\"\r\nversion = \"0.1.0\"\r\nauthors = [\"Author Name <author@example.com>\"]\r\n\r\n# 使用`cargo build`编译时需要的配置\r\n[profile.dev]\r\npanic = \"abort\" # 禁用panic时栈展开\r\n\r\n# 使用`cargo build --release`编译时需要的配置\r\n[profile.release]\r\npanic = \"abort\" # 禁用panic时栈展开\r\n```\r\n\r\n选用任意一个裸机目标来编译。比如对`thumbv7em-none-eabihf`，我们使用以下命令：\r\n\r\n```bash\r\ncargo build --target thumbv7em-none-eabihf\r\n```\r\n\r\n要注意的是，现在我们的代码只是一个Rust编写的独立式可执行程序的一个例子。运行这个二进制程序还需要很多准备，比如在`_start`函数之前需要一个已经预加载完毕的栈。所以为了真正运行这样的程序，我们还有很多事情需要做。\r\n\r\n## 下篇预告\r\n\r\n基于这篇文章的成果，下一篇文章要做的更深。我们将详细讲述编写一个最小的操作系统内核需要的步骤：如何配置特定的编译目标，如何将可执行程序与引导程序拼接，以及如何把一些特定的字符串打印到屏幕上。\r\n"
        },
        {
          "name": "02-minimal-rust-kernel.md",
          "type": "blob",
          "size": 29.2197265625,
          "content": ">原文：https://os.phil-opp.com/minimal-rust-kernel/\r\n>\r\n>原作者：@phil-opp\r\n>\r\n>译者：洛佳  华中科技大学\r\n\r\n# 使用Rust编写操作系统（二）：最小化内核\r\n\r\n这篇文章将基于**x86架构**（the x86 architecture）；我们是试着使用Rust语言，编写一个最小化内核。我们将从独立式可执行程序开始，构建自己的内核。我们将向显示器打印字符串，最终打包内核为能引导启动的**磁盘映像**（disk image）。\r\n\r\n## 引导启动\r\n\r\n当我们启动电脑时，主板[ROM](https://en.wikipedia.org/wiki/Read-only_memory)内存储的**固件**（firmware）将会运行：它将负责电脑的**上电自检**（[power-on self test](https://en.wikipedia.org/wiki/Power-on_self-test)），**可用内存**（available RAM）的检测，以及CPU和其它硬件的预加载。这之后，它将寻找一个**可引导的存储介质**（bootable disk），并开始引导启动其中的**内核**（kernel）。\r\n\r\nx86架构支持两种固件标准：**BIOS**（[Basic Input/Output System](https://en.wikipedia.org/wiki/BIOS)）和**UEFI**（[Unified Extensible Firmware Interface](https://en.wikipedia.org/wiki/Unified_Extensible_Firmware_Interface)）。其中，BIOS标准显得陈旧而过时，但实现简单，并为1980年代后的所有x86设备所支持；相反地，UEFI更现代化，功能也更全面，但开发和构建更复杂（至少从我的角度看是如此）。\r\n\r\n在这篇文章中，我们暂时只提供BIOS固件的引导启动方式。\r\n\r\n### BIOS启动\r\n\r\n几乎所有的x86硬件系统都支持BIOS启动，这也包含新式的、基于UEFI、用**模拟BIOS**（emulated BIOS）的方式向后兼容的硬件系统。这可以说是一件好事情，因为无论是上世纪还是现在的硬件系统，你都只需编写同样的引导启动逻辑；但这种兼容性有时也是BIOS引导启动最大的缺点，因为这意味着在系统启动前，你的CPU必须先进入一个16位系统兼容的**实模式**（[real mode](https://en.wikipedia.org/wiki/Real_mode)），这样1980年代古老的引导固件才能够继续使用。\r\n\r\n让我们从头开始，理解一遍BIOS启动的过程。\r\n\r\n当电脑启动时，主板上特殊的闪存中存储的BIOS固件将被加载。BIOS固件将会上电自检、初始化硬件，然后它将寻找一个可引导的存储介质。如果找到了，那电脑的控制权将被转交给**引导程序**（bootloader）：一段存储在存储介质的开头的、512字节长度的程序片段。大多数的引导程序长度都大于512字节——所以通常情况下，引导程序都被切分为一段优先启动、长度不超过512字节、存储在介质开头的**第一阶段引导程序**（first stage bootloader），和一段随后由其加载的、长度可能较长、存储在其它位置的**第二阶段引导程序**（second stage bootloader）。\r\n\r\n引导程序必须决定内核的位置，并将内核加载到内存。引导程序还需要将CPU从16位的实模式，先切换到32位的**保护模式**（[protected mode](https://en.wikipedia.org/wiki/Protected_mode)），最终切换到64位的**长模式**（[long mode](https://en.wikipedia.org/wiki/Long_mode)）：此时，所有的64位寄存器和整个**主内存**（main memory）才能被访问。引导程序的第三个作用，是从BIOS查询特定的信息，并将其传递到内核；如查询和传递**内存映射表**（memory map）。\r\n\r\n编写一个引导程序并不是一个简单的任务，因为这需要使用汇编语言，而且必须经过许多意图并不明显的步骤——比如，把一些**魔术数字**（magic number）写入某个寄存器。因此，我们不会讲解如何编写自己的引导程序，而是推荐[bootimage工具](https://github.com/rust-osdev/bootimage)——它能够自动而方便地为你的内核准备一个引导程序。\r\n\r\n### Multiboot标准\r\n\r\n每个操作系统都实现自己的引导程序，而这只对单个操作系统有效。为了避免这样的僵局，1995年，**自由软件基金会**（[Free Software Foundation](https://en.wikipedia.org/wiki/Free_Software_Foundation)）颁布了一个开源的引导程序标准——[Multiboot](https://wiki.osdev.org/Multiboot)。这个标准定义了引导程序和操作系统间的统一接口，所以任何适配Multiboot的引导程序，都能用来加载任何同样适配了Multiboot的操作系统。[GNU GRUB](https://en.wikipedia.org/wiki/GNU_GRUB)是一个可供参考的Multiboot实现，它也是最热门的Linux系统引导程序之一。\r\n\r\n要编写一款适配Multiboot的内核，我们只需要在内核文件开头，插入被称作**Multiboot头**（[Multiboot header](https://www.gnu.org/software/grub/manual/multiboot/multiboot.html#OS-image-format)）的数据片段。这让GRUB很容易引导任何操作系统，但是，GRUB和Multiboot标准也有一些可预知的问题：\r\n\r\n1. 它们只支持32位的保护模式。这意味着，在引导之后，你依然需要配置你的CPU，让它切换到64位的长模式；\r\n2. 它们被设计为精简引导程序，而不是精简内核。举个栗子，内核需要以调整过的**默认页长度**（[default page size](https://wiki.osdev.org/Multiboot#Multiboot_2)）被链接，否则GRUB将无法找到内核的Multiboot头。另一个例子是**引导信息**（[boot information](https://www.gnu.org/software/grub/manual/multiboot/multiboot.html#Boot-information-format)），这个包含着大量与架构有关的数据，会在引导启动时，被直接传到操作系统，而不会经过一层清晰的抽象；\r\n3. GRUB和Multiboot标准并没有被详细地注释，阅读相关文档需要一定经验；\r\n4. 为了创建一个能够被引导的磁盘映像，我们在开发时必须安装GRUB：这加大了基于Windows或macOS开发内核的难度。\r\n\r\n出于这些考虑，我们决定不使用GRUB或者Multiboot标准。然而，Multiboot支持功能也在bootimage工具的开发计划之中，所以从原理上讲，如果选用bootimage工具，在未来使用GRUB引导你的系统内核是可能的。\r\n\r\n## 最小化内核\r\n\r\n现在我们已经明白电脑是如何启动的，那也是时候编写我们自己的内核了。我们的小目标是，创建一个内核的磁盘映像，它能够在启动时，向屏幕输出一行“Hello World!”；我们的工作将基于上一章构建的独立式可执行程序。\r\n\r\n如果读者还有印象的话，在上一章，我们使用`cargo`构建了一个独立的二进制程序；但这个程序依然基于特定的操作系统平台：因平台而异，我们需要定义不同名称的函数，且使用不同的编译指令。这是因为在默认情况下，`cargo`会为特定的**宿主系统**（host system）构建源码，比如为你正在运行的系统构建源码。这并不是我们想要的，因为我们的内核不应该基于另一个操作系统——我们想要编写的，就是这个操作系统。确切地说，我们想要的是，编译为一个特定的**目标系统**（target system）。\r\n\r\n## 安装 Nightly Rust\r\n\r\nRust语言有三个**发行频道**（release channel），分别是stable、beta和nightly。《Rust程序设计语言》中对这三个频道的区别解释得很详细，可以前往[这里](https://doc.rust-lang.org/book/appendix-07-nightly-rust.html)看一看。为了搭建一个操作系统，我们需要一些只有nightly会提供的实验性功能，所以我们需要安装一个nightly版本的Rust。\r\n\r\n要管理安装好的Rust，我强烈建议使用[rustup](https://www.rustup.rs/)：它允许你同时安装nightly、beta和stable版本的编译器，而且让更新Rust变得容易。你可以输入`rustup override add nightly`来选择在当前目录使用nightly版本的Rust。或者，你也可以在项目根目录添加一个名称为`rust-toolchain`、内容为`nightly`的文件。要检查你是否已经安装了一个nightly，你可以运行`rustc --version`：返回的版本号末尾应该包含`-nightly`。\r\n\r\nNightly版本的编译器允许我们在源码的开头插入**特性标签**（feature flag），来自由选择并使用大量实验性的功能。举个栗子，要使用实验性的[内联汇编（asm!宏）](https://doc.rust-lang.org/nightly/unstable-book/language-features/asm.html)，我们可以在`main.rs`的顶部添加`#![feature(asm)]`。要注意的是，这样的实验性功能**不稳定**（unstable），意味着未来的Rust版本可能会修改或移除这些功能，而不会有预先的警告过渡。因此我们只有在绝对必要的时候，才应该使用这些特性。\r\n\r\n### 目标配置清单\r\n\r\n通过`--target`参数，`cargo`支持不同的目标系统。这个目标系统可以使用一个**目标三元组**（[target triple](https://clang.llvm.org/docs/CrossCompilation.html#target-triple)）来描述，它描述了CPU架构、平台供应者、操作系统和**应用程序二进制接口**（[Application Binary Interface, ABI](https://stackoverflow.com/a/2456882)）。比方说，目标三元组`x86_64-unknown-linux-gnu`描述一个基于`x86_64`架构CPU的、没有明确的平台供应者的linux系统，它遵循GNU风格的ABI。Rust支持[许多不同的目标三元组](https://forge.rust-lang.org/platform-support.html)，包括安卓系统对应的`arm-linux-androideabi`和[WebAssembly使用的wasm32-unknown-unknown](https://www.hellorust.com/setup/wasm-target/)。\r\n\r\n为了编写我们的目标系统，鉴于我们需要做一些特殊的配置（比如没有依赖的底层操作系统），[已经支持的目标三元组](https://forge.rust-lang.org/platform-support.html)都不能满足我们的要求。幸运的是，只需使用一个JSON文件，Rust便允许我们定义自己的目标系统；这个文件常被称作**目标配置清单**（target specification）。比如，一个描述`x86_64-unknown-linux-gnu`目标系统的配置清单大概长这样：\r\n\r\n```json\r\n{\r\n    \"llvm-target\": \"x86_64-unknown-linux-gnu\",\r\n    \"data-layout\": \"e-m:e-i64:64-f80:128-n8:16:32:64-S128\",\r\n    \"arch\": \"x86_64\",\r\n    \"target-endian\": \"little\",\r\n    \"target-pointer-width\": \"64\",\r\n    \"target-c-int-width\": \"32\",\r\n    \"os\": \"linux\",\r\n    \"executables\": true,\r\n    \"linker-flavor\": \"gcc\",\r\n    \"pre-link-args\": [\"-m64\"],\r\n    \"morestack\": false\r\n}\r\n```\r\n\r\n一个配置清单中包含多个**配置项**（field）。大多数的配置项都是LLVM需求的，它们将配置为特定平台生成的代码。打个比方，`data-layout`配置项定义了不同的整数、浮点数、指针类型的长度；另外，还有一些Rust是用作条件变编译的配置项，如`target-pointer-width`。还有一些类型的配置项，定义了这个包该如何被编译，例如，`pre-link-args`配置项指定了该向**链接器**（[linker](https://en.wikipedia.org/wiki/Linker_(computing))）传入的参数。\r\n\r\n我们将把我们的内核编译到`x86_64`架构，所以我们的配置清单将和上面的例子相似。现在，我们来创建一个名为`x86_64-blog_os.json`的文件——当然也可以选用自己喜欢的文件名——里面包含这样的内容：\r\n\r\n```json\r\n{\r\n    \"llvm-target\": \"x86_64-unknown-none\",\r\n    \"data-layout\": \"e-m:e-i64:64-f80:128-n8:16:32:64-S128\",\r\n    \"arch\": \"x86_64\",\r\n    \"target-endian\": \"little\",\r\n    \"target-pointer-width\": \"64\",\r\n    \"target-c-int-width\": \"32\",\r\n    \"os\": \"none\",\r\n    \"executables\": true,\r\n}\r\n```\r\n\r\n需要注意的是，因为我们要在**裸机**（bare metal）上运行内核，我们已经修改了`llvm-target`的内容，并将`os`配置项的值改为`none`。\r\n\r\n我们还需要添加下面与编译相关的配置项：\r\n\r\n```json\r\n\"linker-flavor\": \"ld.lld\",\r\n\"linker\": \"rust-lld\",\r\n```\r\n\r\n在这里，我们不使用平台默认提供的链接器，因为它可能不支持Linux目标系统。为了链接我们的内核，我们使用跨平台的**LLD链接器**（[LLD linker](https://lld.llvm.org/)），它是和Rust打包发布的。\r\n\r\n```json\r\n\"panic-strategy\": \"abort\",\r\n```\r\n\r\n这个配置项的意思是，我们的编译目标不支持panic时的**栈展开**（[stack unwinding](http://www.bogotobogo.com/cplusplus/stackunwinding.php)），所以我们选择直接**在panic时中止**（abort on panic）。这和在`Cargo.toml`文件中添加`panic = \"abort\"`选项的作用是相同的，所以我们可以不在这里的配置清单中填写这一项。\r\n\r\n```json\r\n\"disable-redzone\": true,\r\n```\r\n\r\n我们正在编写一个内核，所以我们应该同时处理中断。要安全地实现这一点，我们必须禁用一个与**红区**（redzone）有关的栈指针优化：因为此时，这个优化可能会导致栈被破坏。我们撰写了一篇专门的短文，来更详细地解释红区及与其相关的优化。\r\n\r\n```json\r\n\"features\": \"-mmx,-sse,+soft-float\",\r\n```\r\n\r\n`features`配置项被用来启用或禁用某个目标**CPU特征**（CPU feature）。通过在它们前面添加`-`号，我们将`mmx`和`sse`特征禁用；添加前缀`+`号，我们启用了`soft-float`特征。\r\n\r\n`mmx`和`sse`特征决定了是否支持**单指令多数据流**（[Single Instruction Multiple Data，SIMD](https://en.wikipedia.org/wiki/SIMD)）相关指令，这些指令常常能显著地提高程序层面的性能。然而，在内核中使用庞大的SIMD寄存器，可能会造成较大的性能影响：因为每次程序中断时，内核不得不储存整个庞大的SIMD寄存器以备恢复——这意味着，对每个硬件中断或系统调用，完整的SIMD状态必须存到主存中。由于SIMD状态可能相当大（512~1600个字节），而中断可能时常发生，这些额外的存储与恢复操作可能显著地影响效率。为解决这个问题，我们对内核禁用SIMD（但这不意味着禁用内核之上的应用程序的SIMD支持）。\r\n\r\n禁用SIMD产生的一个问题是，`x86_64`架构的浮点数指针运算默认依赖于SIMD寄存器。我们的解决方法是，启用`soft-float`特征，它将使用基于整数的软件功能，模拟浮点数指针运算。\r\n\r\n为了让读者的印象更清晰，我们撰写了一篇关于禁用SIMD的短文。\r\n\r\n现在，我们将各个配置项整合在一起。我们的目标配置清单应该长这样：\r\n\r\n```json\r\n{\r\n  \"llvm-target\": \"x86_64-unknown-none\",\r\n  \"data-layout\": \"e-m:e-i64:64-f80:128-n8:16:32:64-S128\",\r\n  \"arch\": \"x86_64\",\r\n  \"target-endian\": \"little\",\r\n  \"target-pointer-width\": \"64\",\r\n  \"target-c-int-width\": \"32\",\r\n  \"os\": \"none\",\r\n  \"executables\": true,\r\n  \"linker-flavor\": \"ld.lld\",\r\n  \"linker\": \"rust-lld\",\r\n  \"panic-strategy\": \"abort\",\r\n  \"disable-redzone\": true,\r\n  \"features\": \"-mmx,-sse,+soft-float\"\r\n}\r\n```\r\n\r\n### 编译内核\r\n\r\n要编译我们的内核，我们将使用Linux系统的编写风格（这可能是LLVM的默认风格）。这意味着，我们需要把前一篇文章中编写的入口点重命名为`_start`：\r\n\r\n```rust\r\n// src/main.rs\r\n\r\n#![no_std] // 不链接Rust标准库\r\n#![no_main] // 禁用所有Rust层级的入口点\r\n\r\nuse core::panic::PanicInfo;\r\n\r\n/// 这个函数将在panic时被调用\r\n#[panic_handler]\r\nfn panic(_info: &PanicInfo) -> ! {\r\n    loop {}\r\n}\r\n\r\n#[no_mangle] // 不重整函数名\r\npub extern \"C\" fn _start() -> ! {\r\n    // 因为编译器会寻找一个名为`_start`的函数，所以这个函数就是入口点\r\n    // 默认命名为`_start`\r\n    loop {}\r\n}\r\n```\r\n\r\n注意的是，无论你开发使用的是哪类操作系统，你都需要将入口点命名为`_start`。前一篇文章中编写的Windows系统和macOS对应的入口点不应该被保留。\r\n\r\n通过把JSON文件名传入`--target`选项，我们现在可以开始编译我们的内核。让我们试试看：\r\n\r\n```text\r\n> cargo build --target x86_64-blog_os.json\r\n\r\nerror[E0463]: can't find crate for `core`\r\n（或者是下面的错误）\r\nerror[E0463]: can't find crate for `compiler_builtins`\r\n```\r\n\r\n哇哦，编译失败了！输出的错误告诉我们，Rust编译器找不到`core`或者`compiler_builtins`包；而所有`no_std`上下文都隐式地链接到这两个包。[`core`包](https://doc.rust-lang.org/nightly/core/index.html)包含基础的Rust类型，如`Result`、`Option`和迭代器等；[`compiler_builtins`包](https://github.com/rust-lang-nursery/compiler-builtins)提供LLVM需要的许多底层操作，比如`memcpy`。\r\n\r\n通常状况下，`core`库以**预编译库**（precompiled library）的形式与Rust编译器一同发布——这时，`core`库只对支持的宿主系统有效，而我们自定义的目标系统无效。如果我们想为其它系统编译代码，我们需要为这些系统重新编译整个`core`库。\r\n\r\n### Cargo xbuild\r\n\r\n这就是为什么我们需要[cargo xbuild工具](https://github.com/rust-osdev/cargo-xbuild)。这个工具封装了`cargo build`；但不同的是，它将自动交叉编译`core`库和一些**编译器内建库**（compiler built-in libraries）。我们可以用下面的命令安装它：\r\n\r\n```bash\r\ncargo install cargo-xbuild\r\n```\r\n\r\n这个工具依赖于Rust的源代码；我们可以使用`rustup component add rust-src`来安装源代码。\r\n\r\n现在我们可以使用`xbuild`代替`build`重新编译：\r\n\r\n```bash\r\n> cargo xbuild --target x86_64-blog_os.json\r\n   Compiling core v0.0.0 (/…/rust/src/libcore)\r\n   Compiling compiler_builtins v0.1.5\r\n   Compiling rustc-std-workspace-core v1.0.0 (/…/rust/src/tools/rustc-std-workspace-core)\r\n   Compiling alloc v0.0.0 (/tmp/xargo.PB7fj9KZJhAI)\r\n    Finished release [optimized + debuginfo] target(s) in 45.18s\r\n   Compiling blog_os v0.1.0 (file:///…/blog_os)\r\n    Finished dev [unoptimized + debuginfo] target(s) in 0.29 secs\r\n```\r\n\r\n我们能看到，`cargo xbuild`为我们自定义的目标交叉编译了`core`、`compiler_builtin`和`alloc`三个部件。这些部件使用了大量的**不稳定特性**（unstable features），所以只能在[nightly版本的Rust编译器](https://os.phil-opp.com/freestanding-rust-binary/#installing-rust-nightly)中工作。这之后，`cargo xbuild`成功地编译了我们的`blog_os`包。\r\n\r\n现在我们可以为裸机编译内核了；但是，我们提供给引导程序的入口点`_start`函数还是空的。我们可以添加一些东西进去，不过我们可以先做一些优化工作。\r\n\r\n### 设置默认目标\r\n\r\n为了避免每次使用`cargo xbuild`时传递`--target`参数，我们可以覆写默认的编译目标。我们创建一个名为`.cargo/config`的[cargo配置文件](https://doc.rust-lang.org/cargo/reference/config.html)，添加下面的内容：\r\n\r\n```toml\r\n# in .cargo/config\r\n\r\n[build]\r\ntarget = \"x86_64-blog_os.json\"\r\n```\r\n\r\n这里的配置告诉`cargo`在没有显式声明目标的情况下，使用我们提供的`x86_64-blog_os.json`作为目标配置。这意味着保存后，我们可以直接使用：\r\n\r\n```text\r\ncargo xbuild\r\n```\r\n\r\n来编译我们的内核。[官方提供的一份文档](https://doc.rust-lang.org/cargo/reference/config.html)中有对cargo配置文件更详细的说明。\r\n\r\n### 向屏幕打印字符\r\n\r\n要做到这一步，最简单的方式是写入**VGA字符缓冲区**（[VGA text buffer](https://en.wikipedia.org/wiki/VGA-compatible_text_mode)）：这是一段映射到VGA硬件的特殊内存片段，包含着显示在屏幕上的内容。通常情况下，它能够存储25行、80列共2000个**字符单元**（character cell）；每个字符单元能够显示一个ASCII字符，也能设置这个字符的**前景色**（foreground color）和**背景色**（background color）。输出到屏幕的字符大概长这样：\r\n\r\n![字符](https://upload.wikimedia.org/wikipedia/commons/6/6d/Codepage-737.png)\r\n\r\n我们将在下篇文章中详细讨论VGA字符缓冲区的内存布局；目前我们只需要知道，这段缓冲区的地址是`0xb8000`，且每个字符单元包含一个ASCII码字节和一个颜色字节。\r\n\r\n我们的实现就像这样：\r\n\r\n```rust\r\nstatic HELLO: &[u8] = b\"Hello World!\";\r\n\r\n#[no_mangle]\r\npub extern \"C\" fn _start() -> ! {\r\n    let vga_buffer = 0xb8000 as *mut u8;\r\n\r\n    for (i, &byte) in HELLO.iter().enumerate() {\r\n        unsafe {\r\n            *vga_buffer.offset(i as isize * 2) = byte;\r\n            *vga_buffer.offset(i as isize * 2 + 1) = 0xb;\r\n        }\r\n    }\r\n\r\n    loop {}\r\n}\r\n```\r\n\r\n在这段代码中，我们预先定义了一个**字节串**（byte string）类型的**静态变量**（static variable），名为`HELLO`。我们首先将整数`0xb8000`**转换**（cast）为一个**裸指针**（[raw pointer](https://doc.rust-lang.org/stable/book/second-edition/ch19-01-unsafe-rust.html#dereferencing-a-raw-pointer)）。这之后，我们迭代`HELLO`的每个字节，使用[enumerate](https://doc.rust-lang.org/core/iter/trait.Iterator.html#method.enumerate)获得一个额外的序号变量`i`。在`for`语句的循环体中，我们使用[offset](https://doc.rust-lang.org/std/primitive.pointer.html#method.offset)偏移裸指针，解引用它，来将字符串的每个字节和对应的颜色字节——`0xb`代表淡青色——写入内存位置。\r\n\r\n要注意的是，所有的裸指针内存操作都被一个**unsafe语句块**（[unsafe block](https://doc.rust-lang.org/stable/book/second-edition/ch19-01-unsafe-rust.html)）包围。这是因为，此时编译器不能确保我们创建的裸指针是有效的；一个裸指针可能指向任何一个你内存位置；直接解引用并写入它，也许会损坏正常的数据。使用`unsafe`语句块时，程序员其实在告诉编译器，自己保证语句块内的操作是有效的。事实上，`unsafe`语句块并不会关闭Rust的安全检查机制；它允许你多做的事情[只有四件](https://doc.rust-lang.org/stable/book/second-edition/ch19-01-unsafe-rust.html#unsafe-superpowers)。\r\n\r\n使用`unsafe`语句块要求程序员有足够的自信，所以必须强调的一点是，**肆意使用unsafe语句块并不是Rust编程的一贯方式**。在缺乏足够经验的前提下，直接在`unsafe`语句块内操作裸指针，非常容易把事情弄得很糟糕；比如，在不注意的情况下，我们很可能会意外地操作缓冲区以外的内存。\r\n\r\n在这样的前提下，我们希望最小化`unsafe`语句块的使用。使用Rust语言，我们能够将不安全操作将包装为一个安全的抽象模块。举个栗子，我们可以创建一个VGA缓冲区类型，把所有的不安全语句封装起来，来确保从类型外部操作时，无法写出不安全的代码：通过这种方式，我们只需要最少的`unsafe`语句块来确保我们不破坏**内存安全**（[memory safety](https://en.wikipedia.org/wiki/Memory_safety)）。在下一篇文章中，我们将会创建这样的VGA缓冲区封装。\r\n\r\n## 启动内核\r\n\r\n既然我们已经有了一个能够打印字符的可执行程序，是时候把它运行起来试试看了。首先，我们将编译完毕的内核与引导程序链接，来创建一个引导映像；这之后，我们可以在QEMU虚拟机中运行它，或者通过U盘在真机上运行。\r\n\r\n### 创建引导映像\r\n\r\n要将可执行程序转换为**可引导的映像**（bootable disk image），我们需要把它和引导程序链接。这里，引导程序将负责初始化CPU并加载我们的内核。\r\n\r\n编写引导程序并不容易，所以我们不编写自己的引导程序，而是使用已有的[bootloader](https://crates.io/crates/bootloader)包；无需依赖于C语言，这个包基于Rust代码和内联汇编，实现了一个五脏俱全的BIOS引导程序。为了用它启动我们的内核，我们需要将它添加为一个依赖项，在`Cargo.toml`中添加下面的代码：\r\n\r\n```toml\r\n# in Cargo.toml\r\n\r\n[dependencies]\r\nbootloader = \"0.6.0\"\r\n```\r\n\r\n只添加引导程序为依赖项，并不足以创建一个可引导的磁盘映像；我们还需要内核编译完成之后，将内核和引导程序组合在一起。然而，截至目前，原生的cargo并不支持在编译完成后添加其它步骤（详见[这个issue](https://github.com/rust-lang/cargo/issues/545)）。\r\n\r\n为了解决这个问题，我们建议使用`bootimage`工具——它将会在内核编译完毕后，将它和引导程序组合在一起，最终创建一个能够引导的磁盘映像。我们可以使用下面的命令来安装这款工具：\r\n\r\n```bash\r\ncargo install bootimage --version \"^0.7.3\"\r\n```\r\n\r\n参数`^0.7.3`是一个**脱字号条件**（[caret requirement](https://doc.rust-lang.org/cargo/reference/specifying-dependencies.html#caret-requirements)），它的意义是“0.7.3版本或一个兼容0.7.3的新版本”。这意味着，如果这款工具发布了修复bug的版本`0.7.4`或`0.7.5`，cargo将会自动选择最新的版本，因为它依然兼容`0.7.x`；但cargo不会选择`0.8.0`，因为这个版本被认为并不和`0.7.x`系列版本兼容。需要注意的是，`Cargo.toml`中定义的依赖包版本都默认是脱字号条件：刚才我们指定`bootloader`包的版本时，遵循的就是这个原则。\r\n\r\n为了运行`bootimage`以及编译引导程序，我们需要安装rustup模块`llvm-tools-preview`——我们可以使用`rustup component add llvm-tools-preview`来安装这个工具。\r\n\r\n成功安装`bootimage`后，创建一个可引导的磁盘映像就变得相当容易。我们来输入下面的命令：\r\n\r\n```bash\r\n> cargo bootimage\r\n```\r\n\r\n可以看到的是，`bootimage`工具开始使用`cargo xbuild`编译你的内核，所以它将增量编译我们修改后的源码。在这之后，它会编译内核的引导程序，这可能将花费一定的时间；但和所有其它依赖包相似的是，在首次编译后，产生的二进制文件将被缓存下来——这将显著地加速后续的编译过程。最终，`bootimage`将把内核和引导程序组合为一个可引导的磁盘映像。\r\n\r\n运行这行命令之后，我们应该能在`target/x86_64-blog_os/debug`目录内找到我们的映像文件`bootimage-blog_os.bin`。我们可以在虚拟机内启动它，也可以刻录到U盘上以便在真机上启动。（需要注意的是，因为文件格式不同，这里的bin文件并不是一个光驱映像，所以将它刻录到光盘不会起作用。）\r\n\r\n事实上，在这行命令背后，`bootimage`工具执行了三个步骤：\r\n\r\n1. 编译我们的内核为一个**ELF**（[Executable and Linkable Format](https://en.wikipedia.org/wiki/Executable_and_Linkable_Format)）文件；\r\n2. 编译引导程序为独立的可执行文件；\r\n3. 将内核ELF文件**按字节拼接**（append by bytes）到引导程序的末端。\r\n\r\n当机器启动时，引导程序将会读取并解析拼接在其后的ELF文件。这之后，它将把程序片段映射到**分页表**（page table）中的**虚拟地址**（virtual address），清零**BSS段**（BSS segment），还将创建一个栈。最终它将读取**入口点地址**（entry point address）——我们程序中`_start`函数的位置——并跳转到这个位置。\r\n\r\n### 在QEMU中启动内核\r\n\r\n现在我们可以在虚拟机中启动内核了。为了在[QEMU](https://www.qemu.org/)中启动内核，我们使用下面的命令：\r\n\r\n```bash\r\n> qemu-system-x86_64 -drive format=raw,file=bootimage-blog_os.bin\r\n```\r\n\r\n![qemu的显示内容](https://os.phil-opp.com/minimal-rust-kernel/qemu.png)\r\n\r\n我们可以看到，屏幕窗口已经显示出“Hello World!”字符串。祝贺你！\r\n\r\n### 在真机上运行内核\r\n\r\n我们也可以使用dd工具把内核写入U盘，以便在真机上启动。可以输入下面的命令：\r\n\r\n```bash\r\n> dd if=target/x86_64-blog_os/debug/bootimage-blog_os.bin of=/dev/sdX && sync\r\n```\r\n\r\n在这里，`sdX`是U盘的**设备名**（[device name](https://en.wikipedia.org/wiki/Device_file)）。请注意，**在选择设备名的时候一定要极其小心，因为目标设备上已有的数据将全部被擦除**。\r\n\r\n写入到U盘之后，你可以在真机上通过引导启动你的系统。视情况而定，你可能需要在BIOS中打开特殊的启动菜单，或者调整启动顺序。需要注意的是，`bootloader`包暂时不支持UEFI，所以我们并不能在UEFI机器上启动。\r\n\r\n### 使用`cargo run`\r\n\r\n要让在QEMU中运行内核更轻松，我们可以设置在cargo配置文件中设置`runner`配置项：\r\n\r\n```toml\r\n# in .cargo/config\r\n\r\n[target.'cfg(target_os = \"none\")']\r\nrunner = \"bootimage runner\"\r\n```\r\n\r\n在这里，`target.'cfg(target_os = \"none\")'`筛选了三元组中宿主系统设置为`\"none\"`的所有编译目标——这将包含我们的`x86_64-blog_os.json`目标。另外，`runner`的值规定了运行`cargo run`使用的命令；这个命令将在成功编译后执行，而且会传递可执行文件的路径为第一个参数。[官方提供的cargo文档](https://doc.rust-lang.org/cargo/reference/config.html)讲述了更多的细节。\r\n\r\n命令`bootimage runner`由`bootimage`包提供，参数格式经过特殊设计，可以用于`runner`命令。它将给定的可执行文件与项目的引导程序依赖项链接，然后在QEMU中启动它。`bootimage`包的[README文档](https://github.com/rust-osdev/bootimage)提供了更多细节和可以传入的配置参数。\r\n\r\n现在我们可以使用`cargo xrun`来编译内核并在QEMU中启动了。和`xbuild`类似，`xrun`子命令将在调用cargo命令前编译内核所需的包。这个子命令也由`cargo-xbuild`工具提供，所以你不需要安装额外的工具。\r\n\r\n## 下篇预告\r\n\r\n在下篇文章中，我们将细致地探索VGA字符缓冲区，并包装它为一个安全的接口。我们还将基于它实现`println!`宏。\r\n"
        },
        {
          "name": "03-vga-text-mode.md",
          "type": "blob",
          "size": 31.52734375,
          "content": "> 原文：https://os.phil-opp.com/vga-text-mode/\n>\n> 原作者：@phil-opp\n>\n> 译者：洛佳  华中科技大学\n\n# 使用Rust编写操作系统（三）：VGA字符模式\n\n**VGA字符模式**（[VGA text mode](https://en.wikipedia.org/wiki/VGA-compatible_text_mode)）是打印字符到屏幕的一种简单方式。在这篇文章中，为了包装这个模式为一个安全而简单的接口，我们包装unsafe代码到独立的模块。我们还将实现对Rust语言**格式化宏**（[formatting macros](https://doc.rust-lang.org/std/fmt/#related-macros)）的支持。\n\n## VGA字符缓冲区\n\n为了在VGA字符模式向屏幕打印字符，我们必须将它写入硬件提供的**VGA字符缓冲区**（VGA text buffer）。通常状况下，VGA字符缓冲区是一个25行、80列的二维数组，它的内容将被实时渲染到屏幕。这个数组的元素被称作**字符单元**（character cell），它使用下面的格式描述一个屏幕上的字符：\n\n| Bit(s)    | Value |\n|-----|----------------|\n| 0-7   | ASCII code point |\n| 8-11  | Foreground color |\n| 12-14 | Background color |\n| 15    | Blink |\n\n其中，**前景色**（foreground color）和**背景色**（background color）取值范围如下：\n\n| Number  | Color  | Number + Bright Bit  | Bright Color |\n|-----|----------|------|--------|\n| 0x0  | Black  | 0x8  | Dark Gray |\n| 0x1  | Blue  | 0x9  | Light Blue |\n| 0x2  | Green  | 0xa  | Light Green |\n| 0x3  | Cyan  | 0xb  | Light Cyan |\n| 0x4  | Red  | 0xc  | Light Red |\n| 0x5  | Magenta  | 0xd  | Pink |\n| 0x6  | Brown  | 0xe  | Yellow |\n| 0x7  | Light Gray  | 0xf  | White |\n\n每个颜色的第四位称为**加亮位**（bright bit）。\n\n要修改VGA字符缓冲区，我们可以通过**存储器映射输入输出**（[memory-mapped I/O](https://en.wikipedia.org/wiki/Memory-mapped_I/O)）的方式，读取或写入地址`0xb8000`；这意味着，我们可以像操作普通的内存区域一样操作这个地址。\n\n需要注意的是，一些硬件虽然映射到存储器，却可能不会完全支持所有的内存操作：可能会有一些设备支持按`u8`字节读取，却在读取`u64`时返回无效的数据。幸运的是，字符缓冲区都[支持标准的读写操作](https://web.stanford.edu/class/cs140/projects/pintos/specs/freevga/vga/vgamem.htm#manip)，所以我们不需要用特殊的标准对待它。\n\n## 包装到Rust模块\n\n既然我们已经知道VGA文字缓冲区如何工作，也是时候创建一个Rust模块来处理文字打印了。我们输入这样的代码：\n\n```rust\n// in src/main.rs\nmod vga_buffer;\n```\n\n这行代码定义了一个Rust模块，它的内容应当保存在`src/vga_buffer.rs`文件中。使用**2018版次**（2018 edition）的Rust时，我们可以把模块的**子模块**（submodule）文件直接保存到`src/vga_buffer/`文件夹下，与`vga_buffer.rs`文件共存，而无需创建一个`mod.rs`文件。\n\n我们的模块暂时不需要添加子模块，所以我们将它创建为`src/vga_buffer.rs`文件。除非另有说明，本文中的代码都保存到这个文件中。\n\n### 颜色\n\n首先，我们使用Rust的**枚举**（enum）表示一种颜色：\n\n```rust\n// in src/vga_buffer.rs\n\n#[allow(dead_code)]\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\n#[repr(u8)]\npub enum Color {\n    Black = 0,\n    Blue = 1,\n    Green = 2,\n    Cyan = 3,\n    Red = 4,\n    Magenta = 5,\n    Brown = 6,\n    LightGray = 7,\n    DarkGray = 8,\n    LightBlue = 9,\n    LightGreen = 10,\n    LightCyan = 11,\n    LightRed = 12,\n    Pink = 13,\n    Yellow = 14,\n    White = 15,\n}\n```\n\n我们使用**类似于C语言的枚举**（C-like enum），为每个颜色明确指定一个数字。在这里，每个用`repr(u8)`注记标注的枚举类型，都会以一个`u8`的形式存储——事实上4个二进制位就足够了，但Rust语言并不提供`u4`类型。\n\n通常来说，编译器会对每个未使用的变量发出**警告**（warning）；使用`#[allow(dead_code)]`，我们可以对`Color`枚举类型禁用这个警告。\n\n我们还**生成**（[derive](http://rustbyexample.com/trait/derive.html)）了 [`Copy`](https://doc.rust-lang.org/nightly/core/marker/trait.Copy.html)、[`Clone`](https://doc.rust-lang.org/nightly/core/clone/trait.Clone.html)、[`Debug`](https://doc.rust-lang.org/nightly/core/fmt/trait.Debug.html)、[`PartialEq`](https://doc.rust-lang.org/nightly/core/cmp/trait.PartialEq.html)和[`Eq`](https://doc.rust-lang.org/nightly/core/cmp/trait.Eq.html) 这几个trait：这让我们的类型遵循**复制语义**（[copy semantics](https://doc.rust-lang.org/book/first-edition/ownership.html#copy-types)），也让它可以被比较、被调试打印。\n\n为了描述包含前景色和背景色的、完整的**颜色代码**（color code），我们基于`u8`创建一个新类型：\n\n```rust\n// in src/vga_buffer.rs\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\n#[repr(transparent)]\nstruct ColorCode(u8);\n\nimpl ColorCode {\n    fn new(foreground: Color, background: Color) -> ColorCode {\n        ColorCode((background as u8) << 4 | (foreground as u8))\n    }\n}\n```\n\n这里，`ColorCode`类型包装了一个完整的颜色代码字节，它包含前景色和背景色信息。和`Color`类型类似，我们为它生成`Copy`和`Debug`等一系列trait。为了确保`ColorCode`和`u8`有完全相同的内存布局，我们添加[repr(transparent)标记](https://doc.rust-lang.org/nomicon/other-reprs.html#reprtransparent)。\n\n### 字符缓冲区\n\n现在，我们可以添加更多的结构体，来描述屏幕上的字符和整个字符缓冲区：\n\n```rust\n// in src/vga_buffer.rs\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\n#[repr(C)]\nstruct ScreenChar {\n    ascii_character: u8,\n    color_code: ColorCode,\n}\n\nconst BUFFER_HEIGHT: usize = 25;\nconst BUFFER_WIDTH: usize = 80;\n\n#[repr(transparent)]\nstruct Buffer {\n    chars: [[ScreenChar; BUFFER_WIDTH]; BUFFER_HEIGHT],\n}\n```\n\n在内存布局层面，Rust并不保证按顺序布局成员变量。因此，我们需要使用`#[repr(C)]`标记结构体；这将按C语言约定的顺序布局它的成员变量，让我们能正确地映射内存片段。对`Buffer`类型，我们再次使用`repr(transparent)`，来确保类型和它的单个成员有相同的内存布局。\n\n为了输出字符到屏幕，我们来创建一个`Writer`类型：\n\n```rust\n// in src/vga_buffer.rs\n\npub struct Writer {\n    column_position: usize,\n    color_code: ColorCode,\n    buffer: &'static mut Buffer,\n}\n```\n\n我们将让这个`Writer`类型将字符写入屏幕的最后一行，并在一行写满或收到换行符`\\n`的时候，将所有的字符向上位移一行。`column_position`变量将跟踪光标在最后一行的位置。当前字符的前景和背景色将由`color_code`变量指定；另外，我们存入一个VGA字符缓冲区的可变借用到`buffer`变量中。需要注意的是，这里我们对借用使用**显式生命周期**（[explicit lifetime](https://doc.rust-lang.org/book/ch10-03-lifetime-syntax.html#lifetime-annotation-syntax)），告诉编译器这个借用在何时有效：我们使用**`'static`生命周期**（['static lifetime](https://doc.rust-lang.org/book/ch10-03-lifetime-syntax.html#the-static-lifetime)），意味着这个借用应该在整个程序的运行期间有效；这对一个全局有效的VGA字符缓冲区来说，是非常合理的。\n\n### 打印字符\n\n现在我们可以使用`Writer`类型来更改缓冲区内的字符了。首先，为了写入一个ASCII码字节，我们创建这样的函数：\n\n```rust\n// in src/vga_buffer.rs\n\nimpl Writer {\n    pub fn write_byte(&mut self, byte: u8) {\n        match byte {\n            b'\\n' => self.new_line(),\n            byte => {\n                if self.column_position >= BUFFER_WIDTH {\n                    self.new_line();\n                }\n\n                let row = BUFFER_HEIGHT - 1;\n                let col = self.column_position;\n\n                let color_code = self.color_code;\n                self.buffer.chars[row][col] = ScreenChar {\n                    ascii_character: byte,\n                    color_code,\n                };\n                self.column_position += 1;\n            }\n        }\n    }\n\n    fn new_line(&mut self) {/* TODO */}\n}\n```\n\n如果这个字节是一个**换行符**（[line feed](https://en.wikipedia.org/wiki/Newline)）字节`\\n`，我们的`Writer`不应该打印新字符，相反，它将调用我们稍后会实现的`new_line`方法；其它的字节应该将在`match`语句的第二个分支中被打印到屏幕上。\n\n当打印字节时，`Writer`将检查当前行是否已满。如果已满，它将首先调用`new_line`方法来将这一行字向上提升，再将一个新的`ScreenChar`写入到缓冲区，最终将当前的光标位置前进一位。\n\n要打印整个字符串，我们把它转换为字节并依次输出：\n\n```rust\n// in src/vga_buffer.rs\n\nimpl Writer {\n    pub fn write_string(&mut self, s: &str) {\n        for byte in s.bytes() {\n            match byte {\n                // 可以是能打印的ASCII码字节，也可以是换行符\n                0x20...0x7e | b'\\n' => self.write_byte(byte),\n                // 不包含在上述范围之内的字节\n                _ => self.write_byte(0xfe),\n            }\n\n        }\n    }\n}\n```\n\nVGA字符缓冲区只支持ASCII码字节和**代码页437**（[Code page 437](https://en.wikipedia.org/wiki/Code_page_437)）定义的字节。Rust语言的字符串默认编码为[UTF-8](http://www.fileformat.info/info/unicode/utf8.htm)，也因此可能包含一些VGA字符缓冲区不支持的字节：我们使用`match`语句，来区别可打印的ASCII码或换行字节，和其它不可打印的字节。对每个不可打印的字节，我们打印一个`■`符号；这个符号在VGA硬件中被编码为十六进制的`0xfe`。\n\n我们可以亲自试一试已经编写的代码。为了这样做，我们可以临时编写一个函数：\n\n```rust\n// in src/vga_buffer.rs\n\npub fn print_something() {\n    let mut writer = Writer {\n        column_position: 0,\n        color_code: ColorCode::new(Color::Yellow, Color::Black),\n        buffer: unsafe { &mut *(0xb8000 as *mut Buffer) },\n    };\n\n    writer.write_byte(b'H');\n    writer.write_string(\"ello \");\n    writer.write_string(\"Wörld!\");\n}\n```\n\n这个函数首先创建一个指向`0xb8000`地址VGA缓冲区的`Writer`。实现这一点，我们需要编写的代码可能看起来有点奇怪：首先，我们把整数`0xb8000`强制转换为一个可变的**裸指针**（[raw pointer](https://doc.rust-lang.org/book/ch19-01-unsafe-rust.html#dereferencing-a-raw-pointer)）；之后，通过运算符`*`，我们将这个裸指针解引用；最后，我们再通过`&mut`，再次获得它的可变借用。这些转换需要**`unsafe`语句块**（[unsafe block](https://doc.rust-lang.org/book/ch19-01-unsafe-rust.html)），因为编译器并不能保证这个裸指针是有效的。\n\n然后它将字节 `b'H'` 写入缓冲区内. 前缀 `b`创建了一个字节字面量（[byte literal](https://doc.rust-lang.org/reference/tokens.html#byte-literals)），表示单个ASCII码字符；通过尝试写入 `\"ello \"` 和 `\"Wörld!\"`，我们可以测试 `write_string` 方法和其后对无法打印字符的处理逻辑。为了观察输出，我们需要在`_start`函数中调用`print_something`方法：\n\n```rust\n// in src/main.rs\n#[no_mangle]\npub extern \"C\" fn _start() -> ! {\n    vga_buffer::print_something();\n    loop {}\n}\n```\n\n编译运行后，黄色的`Hello W■■rld!`字符串将会被打印在屏幕的左下角：\n\n![QEMU output with a yellow Hello W■■rld! in the lower left corner](https://os.phil-opp.com/vga-text-mode/vga-hello.png)\n\n需要注意的是，`ö`字符被打印为两个`■`字符。这是因为在[UTF-8](http://www.fileformat.info/info/unicode/utf8.htm)编码下，字符`ö`是由两个字节表述的——而这两个字节并不处在可打印的ASCII码字节范围之内。事实上，这是UTF-8编码的基本特点之一：**如果一个字符占用多个字节，那么每个组成它的独立字节都不是有效的ASCII码字节**（the individual bytes of multi-byte values are never valid ASCII）。\n\n### 易失操作\n\n我们刚才看到，自己想要输出的信息被正确地打印到屏幕上。然而，未来Rust编译器更暴力的优化可能让这段代码不按预期工作。\n\n产生问题的原因在于，我们只向`Buffer`写入，却不再从它读出数据。此时，编译器不知道我们事实上已经在操作VGA缓冲区内存，而不是在操作普通的RAM——因此也不知道产生的副作用，即会有几个字符显示在屏幕上。这时，编译器也许会认为这些写入操作都没有必要，甚至会选择忽略这些操作！所以，为了避免这些并不正确的优化，这些写入操作应当被指定为[易失操作](https://en.wikipedia.org/wiki/Volatile_(computer_programming))。这将告诉编译器，这些写入可能会产生副效应，不应该被优化掉。\n\n为了在我们的VGA缓冲区中使用易失的写入操作，我们使用[volatile](https://docs.rs/volatile)库。这个**包**（crate）提供一个名为`Volatile`的**包装类型**（wrapping type），它的`read`、`write`方法；这些方法包装了`core::ptr`内的[read_volatile](https://doc.rust-lang.org/nightly/core/ptr/fn.read_volatile.html)和[write_volatile](https://doc.rust-lang.org/nightly/core/ptr/fn.write_volatile.html) 函数，从而保证读操作或写操作不会被编译器优化。\n\n要添加`volatile`包为项目的**依赖项**（dependency），我们可以在`Cargo.toml`文件的`dependencies`中添加下面的代码：\n\n```toml\n# in Cargo.toml\n\n[dependencies]\nvolatile = \"0.2.3\"\n```\n\n`0.2.3`表示一个**语义版本号**（[semantic version number](http://semver.org/)），在cargo文档的[《指定依赖项》章节](https://doc.rust-lang.org/cargo/reference/specifying-dependencies.html)可以找到与它相关的使用指南。\n\n现在，我们使用它来完成VGA缓冲区的volatile写入操作。我们将`Buffer`类型的定义修改为下列代码：\n\n```rust\n// in src/vga_buffer.rs\n\nuse volatile::Volatile;\n\nstruct Buffer {\n    chars: [[Volatile<ScreenChar>; BUFFER_WIDTH]; BUFFER_HEIGHT],\n}\n```\n\n在这里，我们不使用`ScreenChar`，而选择使用`Volatile<ScreenChar>`——在这里，`Volatile`类型是一个**泛型**（[generic](https://doc.rust-lang.org/book/ch10-01-syntax.html)），可以包装几乎所有的类型——这确保了我们不会通过普通的写入操作，意外地向它写入数据；我们转而使用提供的`write`方法。\n\n这意味着，我们必须要修改我们的`Writer::write_byte`方法：\n\n```rust\n// in src/vga_buffer.rs\n\nimpl Writer {\n    pub fn write_byte(&mut self, byte: u8) {\n        match byte {\n            b'\\n' => self.new_line(),\n            byte => {\n                ...\n\n                self.buffer.chars[row][col].write(ScreenChar {\n                    ascii_character: byte,\n                    color_code: color_code,\n                });\n                ...\n            }\n        }\n    }\n    ...\n}\n```\n\n正如代码所示，我们不再使用普通的`=`赋值，而使用了`write`方法：这能确保编译器不再优化这个写入操作。\n\n### 格式化宏\n\n支持Rust提供的**格式化宏**（formatting macros）也是一个相当棒的主意。通过这种途径，我们可以轻松地打印不同类型的变量，如整数或浮点数。为了支持它们，我们需要实现[`core::fmt::Write`](https://doc.rust-lang.org/nightly/core/fmt/trait.Write.html) trait；要实现它，唯一需要提供的方法是`write_str`，它和我们先前编写的`write_string`方法差别不大，只是返回值类型变成了`fmt::Result`：\n\n```rust\n// in src/vga_buffer.rs\n\nuse core::fmt::Write;\n\nimpl fmt::Write for Writer {\n    fn write_str(&mut self, s: &str) -> fmt::Result {\n        self.write_string(s);\n        Ok(())\n    }\n}\n```\n\n这里，`Ok(())`属于`Result`枚举类型中的`Ok`，包含一个值为`()`的变量。\n\n现在我们就可以使用Rust内置的格式化宏`write!`和`writeln!`了：\n\n```rust\n// in src/vga_buffer.rs\n\npub fn print_something() {\n    use core::fmt::Write;\n    let mut writer = Writer {\n        column_position: 0,\n        color_code: ColorCode::new(Color::Yellow, Color::Black),\n        buffer: unsafe { &mut *(0xb8000 as *mut Buffer) },\n    };\n\n    writer.write_byte(b'H');\n    writer.write_string(\"ello! \");\n    write!(writer, \"The numbers are {} and {}\", 42, 1.0/3.0).unwrap();\n}\n```\n\n现在，你应该在屏幕下端看到一串`Hello! The numbers are 42 and 0.3333333333333333`。`write!`宏返回的`Result`类型必须被使用，所以我们调用它的[`unwrap`](https://doc.rust-lang.org/core/result/enum.Result.html#method.unwrap)方法，它将在错误发生时panic。这里的情况下应该不会发生这样的问题，因为写入VGA字符缓冲区并没有可能失败。\n\n### 换行\n\n在之前的代码中，我们忽略了换行符，因此没有处理超出一行字符的情况。当换行时，我们想要把每个字符向上移动一行——此时最顶上的一行将被删除——然后在最后一行的起始位置继续打印。要做到这一点，我们要为`Writer`实现一个新的`new_line`方法：\n\n```rust\n// in src/vga_buffer.rs\n\nimpl Writer {\n    fn new_line(&mut self) {\n        for row in 1..BUFFER_HEIGHT {\n            for col in 0..BUFFER_WIDTH {\n                let character = self.buffer.chars[row][col].read();\n                self.buffer.chars[row - 1][col].write(character);\n            }\n        }\n        self.clear_row(BUFFER_HEIGHT - 1);\n        self.column_position = 0;\n    }\n\n    fn clear_row(&mut self, row: usize) {/* TODO */}\n}\n```\n\n我们遍历每个屏幕上的字符，把每个字符移动到它上方一行的相应位置。这里，`..`符号是**区间标号**（range notation）的一种；它表示左闭右开的区间，因此不包含它的上界。在外层的枚举中，我们从第1行开始，省略了对第0行的枚举过程——因为这一行应该被移出屏幕，即它将被下一行的字符覆写。\n\n所以我们实现的`clear_row`方法代码如下：\n\n```rust\n// in src/vga_buffer.rs\n\nimpl Writer {\n    fn clear_row(&mut self, row: usize) {\n        let blank = ScreenChar {\n            ascii_character: b' ',\n            color_code: self.color_code,\n        };\n        for col in 0..BUFFER_WIDTH {\n            self.buffer.chars[row][col].write(blank);\n        }\n    }\n}\n```\n\n通过向对应的缓冲区写入空格字符，这个方法能清空一整行的字符位置。\n\n## 全局接口\n\n编写其它模块时，我们希望无需随身携带`Writer`实例，便能使用它的方法。我们尝试创建一个静态的`WRITER`变量：\n\n```rust\n// in src/vga_buffer.rs\n\npub static WRITER: Writer = Writer {\n    column_position: 0,\n    color_code: ColorCode::new(Color::Yellow, Color::Black),\n    buffer: unsafe { &mut *(0xb8000 as *mut Buffer) },\n};\n```\n\n我们尝试编译这些代码，却发生了下面的编译错误：\n\n```\nerror[E0015]: calls in statics are limited to constant functions, tuple structs and tuple variants\n --> src/vga_buffer.rs:7:17\n  |\n7 |     color_code: ColorCode::new(Color::Yellow, Color::Black),\n  |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nerror[E0396]: raw pointers cannot be dereferenced in statics\n --> src/vga_buffer.rs:8:22\n  |\n8 |     buffer: unsafe { &mut *(0xb8000 as *mut Buffer) },\n  |                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ dereference of raw pointer in constant\n\nerror[E0017]: references in statics may only refer to immutable values\n --> src/vga_buffer.rs:8:22\n  |\n8 |     buffer: unsafe { &mut *(0xb8000 as *mut Buffer) },\n  |                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ statics require immutable values\n\nerror[E0017]: references in statics may only refer to immutable values\n --> src/vga_buffer.rs:8:13\n  |\n8 |     buffer: unsafe { &mut *(0xb8000 as *mut Buffer) },\n  |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ statics require immutable values\n```\n\n为了明白现在发生了什么，我们需要知道一点：一般的变量在运行时初始化，而静态变量在编译时初始化。Rust编译器规定了一个称为**常量求值器**（[const evaluator](https://rust-lang.github.io/rustc-guide/const-eval.html)）的组件，它应该在编译时处理这样的初始化工作。虽然它目前的功能较为有限，但对它的扩展工作进展活跃，比如允许在常量中panic的[一篇RFC文档](https://github.com/rust-lang/rfcs/pull/2345)。\n\n关于`ColorCode::new`的问题应该能使用**常函数**（[`const` functions](https://doc.rust-lang.org/unstable-book/language-features/const-fn.html)）解决，但常量求值器还存在不完善之处，它还不能在编译时直接转换裸指针到变量的引用——也许未来这段代码能够工作，但在那之前，我们需要寻找另外的解决方案。\n\n### 延迟初始化\n\n使用非常函数初始化静态变量是Rust程序员普遍遇到的问题。幸运的是，有一个叫做[lazy_static](https://docs.rs/lazy_static/1.0.1/lazy_static/)的包提供了一个很棒的解决方案：它提供了名为`lazy_static!`的宏，定义了一个**延迟初始化**（lazily initialized）的静态变量；这个变量的值将在第一次使用时计算，而非在编译时计算。这时，变量的初始化过程将在运行时执行，任意的初始化代码——无论简单或复杂——都是能够使用的。\n\n现在，我们将`lazy_static`包导入到我们的项目：\n\n```toml\n# in Cargo.toml\n\n[dependencies.lazy_static]\nversion = \"1.0\"\nfeatures = [\"spin_no_std\"]\n```\n\n在这里，由于程序不连接标准库，我们需要启用`spin_no_std`特性。\n\n使用`lazy_static`我们就可以定义一个不出问题的`WRITER`变量：\n\n```rust\n// in src/vga_buffer.rs\n\nuse lazy_static::lazy_static;\n\nlazy_static! {\n    pub static ref WRITER: Writer = Writer {\n        column_position: 0,\n        color_code: ColorCode::new(Color::Yellow, Color::Black),\n        buffer: unsafe { &mut *(0xb8000 as *mut Buffer) },\n    };\n}\n```\n\n然而，这个`WRITER`可能没有什么用途，因为它目前还是**不可变变量**（immutable variable）：这意味着我们无法向它写入数据，因为所有与写入数据相关的方法都需要实例的可变引用`&mut self`。一种解决方案是使用**可变静态**（[mutable static](https://doc.rust-lang.org/book/ch19-01-unsafe-rust.html#accessing-or-modifying-a-mutable-static-variable)）的变量，但所有对它的读写操作都被规定为不安全的（unsafe）操作，因为这很容易导致数据竞争或发生其它不好的事情——使用`static mut`极其不被赞成，甚至有一些提案认为[应该将它删除](https://internals.rust-lang.org/t/pre-rfc-remove-static-mut/1437)。也有其它的替代方案，比如可以尝试使用比如[RefCell](https://doc.rust-lang.org/book/ch15-05-interior-mutability.html#keeping-track-of-borrows-at-runtime-with-refcellt)或甚至[UnsafeCell](https://doc.rust-lang.org/nightly/core/cell/struct.UnsafeCell.html)等类型提供的**内部可变性**（[interior mutability](https://doc.rust-lang.org/book/ch15-05-interior-mutability.html)）；但这些类型都被设计为非同步类型，即不满足[Sync](https://doc.rust-lang.org/nightly/core/marker/trait.Sync.html)约束，所以我们不能在静态变量中使用它们。\n\n### 自旋锁\n\n要定义同步的内部可变性，我们往往使用标准库提供的互斥锁类[Mutex](https://doc.rust-lang.org/nightly/std/sync/struct.Mutex.html)，它通过提供当资源被占用时将线程**阻塞**（block）的**互斥条件**（mutual exclusion）实现这一点；但我们初步的内核代码还没有线程和阻塞的概念，我们将不能使用这个类。不过，我们还有一种较为基础的互斥锁实现方式——**自旋锁**（[spinlock](https://en.wikipedia.org/wiki/Spinlock)）。自旋锁并不会调用阻塞逻辑，而是在一个小的无限循环中反复尝试获得这个锁，也因此会一直占用CPU时间，直到互斥锁被它的占用者释放。\n\n为了使用自旋的互斥锁，我们添加[spin包](https://crates.io/crates/spin)到项目的依赖项列表：\n\n```toml\n# in Cargo.toml\n[dependencies]\nspin = \"0.4.9\"\n```\n\n现在，我们能够使用自旋的互斥锁，为我们的`WRITER`类实现安全的[内部可变性](https://doc.rust-lang.org/book/ch15-05-interior-mutability.html)：\n\n```rust\n// in src/vga_buffer.rs\n\nuse spin::Mutex;\n...\nlazy_static! {\n    pub static ref WRITER: Mutex<Writer> = Mutex::new(Writer {\n        column_position: 0,\n        color_code: ColorCode::new(Color::Yellow, Color::Black),\n        buffer: unsafe { &mut *(0xb8000 as *mut Buffer) },\n    });\n}\n```\n\n现在我们可以删除`print_something`函数，尝试直接在`_start`函数中打印字符：\n\n```rust\n// in src/main.rs\n#[no_mangle]\npub extern \"C\" fn _start() -> ! {\n    use core::fmt::Write;\n    vga_buffer::WRITER.lock().write_str(\"Hello again\").unwrap();\n    write!(vga_buffer::WRITER.lock(), \", some numbers: {} {}\", 42, 1.337).unwrap();\n\n    loop {}\n}\n```\n\n在这里，我们需要导入名为`fmt::Write`的trait，来使用实现它的类的相应方法。\n\n### 安全性\n\n经过上文的努力后，我们现在的代码只剩一个unsafe语句块，它用于创建一个指向`0xb8000`地址的`Buffer`类型引用；在这步之后，所有的操作都是安全的。Rust将为每个数组访问检查边界，所以我们不会在不经意间越界到缓冲区之外。因此，我们把需要的条件编码到Rust的类型系统，这之后，我们为外界提供的接口就符合内存安全原则了。\n\n### `println!`宏\n\n现在我们有了一个全局的`Writer`实例，我们就可以基于它实现`println!`宏，这样它就能被任意地方的代码使用了。Rust提供的[宏定义语法](https://doc.rust-lang.org/nightly/book/ch19-06-macros.html#declarative-macros-with-macro_rules-for-general-metaprogramming)需要时间理解，所以我们将不从零开始编写这个宏。我们先看看标准库中[`println!`宏的实现源码](https://doc.rust-lang.org/nightly/std/macro.println!.html)：\n\n```rust\n#[macro_export]\nmacro_rules! println {\n    () => (print!(\"\\n\"));\n    ($($arg:tt)*) => (print!(\"{}\\n\", format_args!($($arg)*)));\n}\n```\n\n宏是通过一个或多个**规则**（rule）定义的，这就像`match`语句的多个分支。`println!`宏有两个规则：第一个规则不要求传入参数——就比如`println!()`——它将被扩展为`print!(\"\\n\")`，因此只会打印一个新行；第二个要求传入参数——好比`println!(\"Rust能够编写操作系统\")`或`println!(\"我学习Rust已经{}年了\", 3)`——它将使用`print!`宏扩展，传入它需求的所有参数，并在输出的字符串最后加入一个换行符`\\n`。\n\n这里，`#[macro_export]`属性让整个包（crate）和基于它的包都能访问这个宏，而不仅限于定义它的模块（module）。它还将把宏置于包的根模块（crate root）下，这意味着比如我们需要通过`use std::println`来导入这个宏，而不是通过`std::macros::println`。\n\n[`print!`宏](https://doc.rust-lang.org/nightly/std/macro.print!.html)是这样定义的：\n\n```\n#[macro_export]\nmacro_rules! print {\n    ($($arg:tt)*) => ($crate::io::_print(format_args!($($arg)*)));\n}\n```\n\n这个宏将扩展为一个对`io`模块中[`_print`函数](https://github.com/rust-lang/rust/blob/29f5c699b11a6a148f097f82eaa05202f8799bbc/src/libstd/io/stdio.rs#L698)的调用。[`$crate`变量](https://doc.rust-lang.org/1.30.0/book/first-edition/macros.html#the-variable-crate)将在`std`包之外被解析为`std`包，保证整个宏在`std`包之外也可以使用。\n\n[`format_args!`宏](https://doc.rust-lang.org/nightly/std/macro.format_args.html)将传入的参数搭建为一个[fmt::Arguments](https://doc.rust-lang.org/nightly/core/fmt/struct.Arguments.html)类型，这个类型将被传入`_print`函数。`std`包中的[`_print` 函数](https://github.com/rust-lang/rust/blob/29f5c699b11a6a148f097f82eaa05202f8799bbc/src/libstd/io/stdio.rs#L698)将调用复杂的私有函数`print_to`，来处理对不同`Stdout`设备的支持。我们不需要编写这样的复杂函数，因为我们只需要打印到VGA字符缓冲区。\n\n要打印到字符缓冲区，我们把`println!`和`print!`两个宏复制过来，但修改部分代码，让这些宏使用我们定义的`_print`函数：\n\n```rust\n// in src/vga_buffer.rs\n\n#[macro_export]\nmacro_rules! print {\n    ($($arg:tt)*) => ($crate::vga_buffer::_print(format_args!($($arg)*)));\n}\n\n#[macro_export]\nmacro_rules! println {\n    () => ($crate::print!(\"\\n\"));\n    ($($arg:tt)*) => ($crate::print!(\"{}\\n\", format_args!($($arg)*)));\n}\n\n#[doc(hidden)]\npub fn _print(args: fmt::Arguments) {\n    use core::fmt::Write;\n    WRITER.lock().write_fmt(args).unwrap();\n}\n```\n\n我们首先修改了`println!`宏，在每个使用的`print!`宏前面添加了`$crate`变量。这样我们在只需要使用`println!`时，不必也编写代码导入`print!`宏。\n\n就像标准库做的那样，我们为两个宏都添加了`#[macro_export]`属性，这样在包的其它地方也可以使用它们。需要注意的是，这将占用包的**根命名空间**（root namespace），所以我们不能通过`use crate::vga_buffer::println`来导入它们；我们应该使用`use crate::println`。\n\n另外，`_print`函数将占有静态变量`WRITER`的锁，并调用它的`write_fmt`方法。这个方法是从名为`Write`的trait中获得的，所以我们需要导入这个trait。额外的`unwrap()`函数将在打印不成功的时候panic；但既然我们的`write_str`总是返回`Ok`，这种情况不应该发生。\n\n如果这个宏将能在模块外访问，它们也应当能访问`_print`函数，因此这个函数必须是公有的（public）。然而，考虑到这是一个私有的实现细节，我们添加一个[`doc(hidden)`属性](https://doc.rust-lang.org/nightly/rustdoc/the-doc-attribute.html#dochidden)，防止它在生成的文档中出现。\n\n### 使用`println!`的Hello World\n\n现在，我们可以在`_start`里使用`println!`了：\n\n```rust\n// in src/main.rs\n\n#[no_mangle]\npub extern \"C\" fn _start() {\n    println!(\"Hello World{}\", \"!\");\n\n    loop {}\n}\n```\n\n要注意的是，我们在入口函数中不需要导入这个宏——因为它已经被置于包的根命名空间了。\n\n运行这段代码，和我们预料的一样，一个 *“Hello World!”* 字符串被打印到了屏幕上：\n\n![QEMU printing “Hello World!”](https://os.phil-opp.com/vga-text-mode/vga-hello-world.png)\n\n### 打印panic信息\n\n既然我们已经有了`println!`宏，我们可以在panic处理函数中，使用它打印panic信息和panic产生的位置：\n\n```rust\n// in main.rs\n\n/// 这个函数将在panic发生时被调用\n#[panic_handler]\nfn panic(info: &PanicInfo) -> ! {\n    println!(\"{}\", info);\n    loop {}\n}\n```\n\n当我们在`_start`函数中插入一行`panic!(\"Some panic message\");`后，我们得到了这样的输出：\n\n![QEMU printing “panicked at 'Some panic message', src/main.rs:28:5](https://os.phil-opp.com/vga-text-mode/vga-panic.png)\n\n所以，现在我们不仅能知道panic已经发生，还能够知道panic信息和产生panic的代码。\n\n## 小结\n\n这篇文章中，我们学习了VGA字符缓冲区的结构，以及如何在`0xb8000`的内存映射地址访问它。我们将所有的不安全操作包装为一个Rust模块，以便在外界安全地访问它。\n\n我们也发现了——感谢便于使用的cargo——在Rust中使用第三方提供的包是及其容易的。我们添加的两个依赖项，`lazy_static`和`spin`，都在操作系统开发中及其有用；我们将在未来的文章中多次使用它们。\n\n## 下篇预告\n\n下一篇文章中，我们将会讲述如何配置Rust内置的单元测试框架。我们还将为本文编写的VGA缓冲区模块添加基础的单元测试项目。\n"
        },
        {
          "name": "04-testing.md",
          "type": "blob",
          "size": 44.2431640625,
          "content": "> 原文：https://os.phil-opp.com/testing/\n>\n> 原作者：@phil-opp\n>\n> 译者：readlnh\n\n# 使用Rust编写操作系统（四）：内核测试\n\n本文主要讲述了在`no_std`环境下进行单元测试和集成测试的方法。我们将通过Rust的自定义测试框架来在我们的内核中执行一些测试函数。为了将结果反馈到QEMU上，我们需要使用QEMU的一些其他的功能以及`bootimage`工具。\n\n<!-- more -->\n\n这个系列的blog在[GitHub]上开放开发，如果你有任何问题，请在这里开一个issue来讨论。当然你也可以在[底部]留言。你可以在[这里][post branch]找到这篇文章的完整源码。\n\n[GitHub]: https://github.com/phil-opp/blog_os\n[at the bottom]: #comments\n[post branch]: https://github.com/phil-opp/blog_os/tree/post-04\n\n<!-- toc -->\n\n## 阅读要求\n\n这篇文章替换了此前的(现在已经过时了) [_单元测试(Unit Testing)_] 和 [_集成测试(Integration Tests)_] 两篇文章。这里我将假定你是在2019-04-27日后阅读的[_最小Rust内核_]一文。总而言之，本文要求你已经有一个[设置默认目标]的 `.cargo/config` 文件且[定义了一个runner可执行文件]。\n\n[_单元测试(Unit Testing)_]: ./second-edition/posts/deprecated/04-unit-testing/index.md\n[_集成测试(Integration Tests)_]: ./second-edition/posts/deprecated/05-integration-tests/index.md\n[_最小Rust内核_]: ./second-edition/posts/02-minimal-rust-kernel/index.md\n[设置默认目标]: ./second-edition/posts/02-minimal-rust-kernel/index.md#set-a-default-target\n[定义了一个runner可执行文件]: ./second-edition/posts/02-minimal-rust-kernel/index.md#using-cargo-run\n\n## Rust中的测试\n\nRust有一个**内置的测试框架**（[built-in test framework]）：无需任何设置就可以进行单元测试，只需要创建一个通过assert来检查结果的函数并在函数的头部加上`#[test]`属性即可。然后`cargo test`会自动找到并执行你的crate中的所有测试函数。\n\n[built-in test framework]: https://doc.rust-lang.org/book/second-edition/ch11-00-testing.html\n\n不幸的是，对于一个`no_std`的应用，比如我们的内核，这有点点复杂。现在的问题是，Rust的测试框架会隐式的调用内置的[`test`]库，但是这个库依赖于标准库。这也就是说我们的 `#[no_std]`内核无法使用默认的测试框架。\n\n[`test`]: https://doc.rust-lang.org/test/index.html\n\n当我们试图在我们的项目中执行`cargo xtest`时，我们可以看到如下信息:\n\n```text\n> cargo xtest\n   Compiling blog_os v0.1.0 (/…/blog_os)\nerror[E0463]: can't find crate for `test`\n```\n\n由于`test`crate依赖于标准库，所以它在我们的裸机目标上并不可用。虽然将`test`crate移植到一个 `#[no_std]` 上下文环境中是[可能的][utest]，但是这样做是高度不稳定的并且还会需要一些特殊的hacks，例如重定义 `panic` 宏。\n\n[utest]: https://github.com/japaric/utest\n\n### 自定义测试框架\n\n幸运的是，Rust支持通过使用不稳定的**自定义测试框架**（[`custom_test_frameworks`]） 功能来替换默认的测试框架。该功能不需要额外的库，因此在 `#[no_std]`环境中它也可以工作。它的工作原理是收集所有标注了 `#[test_case]`属性的函数，然后将这个测试函数的列表作为参数传递给用户指定的runner函数。因此，它实现了对测试过程的最大控制。\n\n[`custom_test_frameworks`]: https://doc.rust-lang.org/unstable-book/language-features/custom-test-frameworks.html\n\n与默认的测试框架相比，它的缺点是有一些高级功能诸如 [`should_panic` tests]都不可用了。相对的，如果需要这些功能，我们需要自己来实现。当然，这点对我们来说是好事，因为我们的环境非常特殊，在这个环境里，这些高级功能的默认实现无论如何都是无法工作的，举个例子， `#[should_panic]`属性依赖于堆栈展开来捕获内核panic，而我的内核早已将其禁用了。\n\n[`should_panic` tests]: https://doc.rust-lang.org/book/ch11-01-writing-tests.html#checking-for-panics-with-should_panic\n\n要为我们的内核实现自定义测试框架，我们需要将如下代码添加到我们的`main.rs`中去:\n\n```rust\n// in src/main.rs\n\n#![feature(custom_test_frameworks)]\n#![test_runner(crate::test_runner)]\n\n#[cfg(test)]\nfn test_runner(tests: &[&dyn Fn()]) {\n    println!(\"Running {} tests\", tests.len());\n    for test in tests {\n        test();\n    }\n}\n```\n\n我们的runner会打印一个简短的debug信息然后调用列表中的每个测试函数。参数类型 `&[&dyn Fn()]` 是[_Fn()_] trait的 [_trait object_] 引用的一个 [_slice_]。它基本上可以被看做一个可以像函数一样被调用的类型的引用列表。由于这个函数在不进行测试的时候没有什么用，这里我们使用 `#[cfg(test)]`属性保证它只会出现在测试中。\n\n[_slice_]: https://doc.rust-lang.org/std/primitive.slice.html\n[_trait object_]: https://doc.rust-lang.org/1.30.0/book/first-edition/trait-objects.html\n[_Fn()_]: https://doc.rust-lang.org/std/ops/trait.Fn.html\n\n现在当我们运行 `cargo xtest` ，我们可以发现运行成功了。然而，我们看到的仍然是\"Hello World\"而不是我们的 `test_runner`传递来的信息。这是由于我们的入口点仍然是 `_start` 函数——自定义测试框架会生成一个`main`函数来调用`test_runner`，但是由于我们使用了 `#[no_main]`并提供了我们自己的入口点，所以这个`main`函数就被忽略了。\n\n为了修复这个问题，我们需要通过 `reexport_test_harness_main`属性来将生成的函数的名称更改为与`main`不同的名称。然后我们可以在我们的`_start`函数里调用这个重命名的函数:\n\n```rust\n// in src/main.rs\n\n#![reexport_test_harness_main = \"test_main\"]\n\n#[no_mangle]\npub extern \"C\" fn _start() -> ! {\n    println!(\"Hello World{}\", \"!\");\n\n    #[cfg(test)]\n    test_main();\n\n    loop {}\n}\n```\n\n我们将测试框架的入口函数的名字设置为`test_main`，并在我们的 `_start`入口点里调用它。通过使用**条件编译**（[conditional compilation]），我们能够只在上下文环境为测试（test）时调用`test_main`，因为该函数将不在非测试上下文中生成。\n\n[ conditional compilation ]: https://doc.rust-lang.org/1.30.0/book/first-edition/conditional-compilation.html\n\n现在当我们执行 `cargo xtest`时，我们可以看到我们的`test_runner`将\"Running 0 tests\"信息显示在屏幕上了。我们可以创建第一个测试函数了:\n\n```rust\n// in src/main.rs\n\n#[test_case]\nfn trivial_assertion() {\n    print!(\"trivial assertion... \");\n    assert_eq!(1, 1);\n    println!(\"[ok]\");\n}\n```\n\n现在，当我们运行 `cargo xtest`时，我们可以看到如下输出:\n\n![QEMU printing \"Hello World!\", \"Running 1 tests\", and \"trivial assertion... [ok]\"](https://os.phil-opp.com/testing/qemu-test-runner-output.png)\n\n传递给 `test_runner`函数的`tests`切片里包含了一个 `trivial_assertion` 函数的引用，从屏幕上输出的 `trivial assertion... [ok]`信息可见，我们的测试已被调用并且顺利通过。\n\n在执行完tests后， `test_runner`会将结果返回给 `test_main`函数，而这个函数又返回到 `_start`入口点函数——这样我们就进入了一个死循环，因为入口点函数是不允许返回的。这将导致一个问题：我们希望`cargo xtest`在所有的测试运行完毕后，才返回并退出。\n\n## 退出QEMU\n\n现在我们在`_start`函数结束后进入了一个死循环，所以每次执行完`cargo xtest`后我们都需要手动去关闭QEMU；但是我们还想在没有用户交互的脚本环境下执行 `cargo xtest`。解决这个问题的最佳方式，是实现一个合适的方法来关闭我们的操作系统——不幸的是，这个方式实现起来相对有些复杂，因为这要求我们实现对[APM]或[ACPI]电源管理标准的支持。\n\n[APM]: https://wiki.osdev.org/APM\n[ACPI]: https://wiki.osdev.org/ACPI\n\n幸运的是，还有一个绕开这些问题的办法：QEMU支持一种名为 `isa-debug-exit`的特殊设备，它提供了一种从客户系统（guest system）里退出QEMU的简单方式。为了使用这个设备，我们需要向QEMU传递一个`-device`参数。当然，我们也可以通过将 `package.metadata.bootimage.test-args` 配置关键字添加到我们的`Cargo.toml`来达到目的：\n\n```toml\n# in Cargo.toml\n\n[package.metadata.bootimage]\ntest-args = [\"-device\", \"isa-debug-exit,iobase=0xf4,iosize=0x04\"]\n```\n\n `bootimage runner` 会在QEMU的默认测试命令后添加`test-args` 参数。（对于`cargo xrun`命令，这个参数会被忽略。）\n\n在传递设备名 (`isa-debug-exit`)的同时，我们还传递了两个参数，`iobase` 和 `iosize` 。这两个参数指定了一个_I/O 端口_，我们的内核将通过它来访问设备。\n\n### I/O 端口\n\n在x86平台上，CPU和外围硬件通信通常有两种方式，**内存映射I/O**和**端口映射I/O**。之前，我们已经使用内存映射的方式，通过内存地址`0xb8000`访问了[VGA文本缓冲区]。该地址并没有映射到RAM，而是映射到了VGA设备的一部分内存上。\n\n[VGA text buffer]: ./second-edition/posts/03-vga-text-buffer/index.md\n\n与内存映射不同，端口映射I/O使用独立的I/O总线来进行通信。每个外围设备都有一个或数个端口号。CPU采用了特殊的`in`和`out`指令来和端口通信，这些指令要求一个端口号和一个字节的数据作为参数（有些这种指令的变体也允许发送`u16`或是`u32`长度的数据）。\n\n`isa-debug-exit`设备使用的就是端口映射I/O。其中， `iobase` 参数指定了设备对应的端口地址（在x86中，`0xf4`是一个[通常未被使用的端口][list of x86 I/O ports]），而`iosize`则指定了端口的大小（`0x04`代表4字节）。\n\n[list of x86 I/O ports]: https://wiki.osdev.org/I/O_Ports#The_list\n\n### 使用退出(Exit)设备\n\n `isa-debug-exit`设备的功能非常简单。当一个 `value`写入`iobase`指定的端口时，它会导致QEMU以**退出状态**（[exit status]）`(value << 1) | 1`退出。也就是说，当我们向端口写入`0`时，QEMU将以退出状态`(0 << 1) | 1 = 1`退出，而当我们向端口写入`1`时，它将以退出状态`(1 << 1) | 1 = 3`退出。\n\n[exit status]: https://en.wikipedia.org/wiki/Exit_status\n\n这里我们使用 [`x86_64`] crate提供的抽象，而不是手动调用`in`或`out`指令。为了添加对该crate的依赖，我们可以将其添加到我们的 `Cargo.toml`中的 `dependencies` 小节中去:\n\n[`x86_64`]: https://docs.rs/x86_64/0.7.5/x86_64/\n\n```toml\n# in Cargo.toml\n\n[dependencies]\nx86_64 = \"0.7.5\"\n```\n\n现在我们可以使用crate中提供的[`Port`] 类型来创建一个`exit_qemu` 函数了:\n\n[`Port`]: https://docs.rs/x86_64/0.7.0/x86_64/instructions/port/struct.Port.html\n\n```rust\n// in src/main.rs\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\n#[repr(u32)]\npub enum QemuExitCode {\n    Success = 0x10,\n    Failed = 0x11,\n}\n\npub fn exit_qemu(exit_code: QemuExitCode) {\n    use x86_64::instructions::port::Port;\n\n    unsafe {\n        let mut port = Port::new(0xf4);\n        port.write(exit_code as u32);\n    }\n}\n```\n\n该函数在`0xf4`处创建了一个新的端口，该端口同时也是 `isa-debug-exit` 设备的 `iobase` 。然后它会向端口写入传递的退出代码。这里我们使用`u32`来传递数据，因为我们之前已经将 `isa-debug-exit`设备的 `iosize` 指定为4字节了。上述两个操作都是`unsafe`的，因为I/O端口的写入操作通常会导致一些不可预知的行为。\n\n为了指定退出状态，我们创建了一个 `QemuExitCode`枚举。思路大体上是，如果所有的测试均成功，就以成功退出码退出；否则就以失败退出码退出。这个枚举类型被标记为 `#[repr(u32)]`，代表每个变量都是一个`u32`的整数类型。我们使用退出代码`0x10`代表成功，`0x11`代表失败。 实际的退出代码并不重要，只要它们不与QEMU的默认退出代码冲突即可。 例如，使用退出代码0表示成功可能并不是一个好主意，因为它在转换后就变成了`(0 << 1) | 1 = 1` ，而`1`是QEMU运行失败时的默认退出代码。 这样，我们就无法将QEMU错误与成功的测试运行区分开来了。\n\n现在我们来更新`test_runner`的代码，让程序在运行所有测试完毕后退出QEMU：\n\n```rust\nfn test_runner(tests: &[&dyn Fn()]) {\n    println!(\"Running {} tests\", tests.len());\n    for test in tests {\n        test();\n    }\n    /// new\n    exit_qemu(QemuExitCode::Success);\n}\n```\n\n当我们现在运行`cargo xtest`时，QEMU会在测试运行后立刻退出。现在的问题是，即使我们传递了表示成功（`Success`）的退出代码， `cargo test`依然会将所有的测试都视为失败：\n\n```text\n> cargo xtest\n    Finished dev [unoptimized + debuginfo] target(s) in 0.03s\n     Running target/x86_64-blog_os/debug/deps/blog_os-5804fc7d2dd4c9be\nBuilding bootloader\n   Compiling bootloader v0.5.3 (/home/philipp/Documents/bootloader)\n    Finished release [optimized + debuginfo] target(s) in 1.07s\nRunning: `qemu-system-x86_64 -drive format=raw,file=/…/target/x86_64-blog_os/debug/\n    deps/bootimage-blog_os-5804fc7d2dd4c9be.bin -device isa-debug-exit,iobase=0xf4,\n    iosize=0x04`\nerror: test failed, to rerun pass '--bin blog_os'\n```\n\n这里的问题在于，`cargo test`会将所有非`0`的错误码都视为测试失败。\n\n### 代表成功的退出代码\n\n为了解决这个问题， `bootimage`提供了一个 `test-success-exit-code`配置项，可以将指定的退出代码映射到退出代码`0`:\n\n```toml\n[package.metadata.bootimage]\ntest-args = […]\ntest-success-exit-code = 33         # (0x10 << 1) | 1\n```\n\n有了这个配置，`bootimage`就会将我们的成功退出码映射到退出码0；这样一来， `cargo xtest`就能正确的识别出测试成功的情况，而不会将其视为测试失败。\n\n我们的测试runner现在会在正确报告测试结果后自动关闭QEMU。我们可以看到QEMU的窗口只会显示很短的时间——我们不容易看清测试的结果。如果测试结果会打印在控制台上而不是QEMU里，让我们能在QEMU退出后仍然能看到测试结果就好了。\n\n## 打印到控制台\n\n要在控制台上查看测试输出，我们需要以某种方式将数据从内核发送到宿主系统。 有多种方法可以实现这一点，例如通过TCP网络接口来发送数据。但是，设置网络堆栈是一项很复杂的任务——这里我们选择更简单的解决方案。\n\n### 串口\n\n发送数据的一个简单的方式是通过[串行端口]，这是一个现代电脑中已经不存在的旧标准接口（译者注：玩过单片机的同学应该知道，其实译者上大学的时候有些同学的笔记本电脑还有串口的，没有串口的同学在烧录单片机程序的时候也都会需要usb转串口线，一般是51，像stm32有st-link，这个另说，不过其实也可以用串口来下载）。串口非常易于编程，QEMU可以将通过串口发送的数据重定向到宿主机的标准输出或是文件中。\n\n[串行端口]: https://en.wikipedia.org/wiki/Serial_port\n\n用来实现串行接口的芯片被称为 [UARTs]。在x86上，有[很多UART模型]，但是幸运的是，它们之间仅有的那些不同之处都是我们用不到的高级功能。目前通用的UARTs都会兼容[16550 UART]，所以我们在我们测试框架里采用该模型。\n\n[UARTs]: https://en.wikipedia.org/wiki/Universal_asynchronous_receiver-transmitter\n[很多UART模型]: https://en.wikipedia.org/wiki/Universal_asynchronous_receiver-transmitter#UART_models\n[16550 UART]: https://en.wikipedia.org/wiki/16550_UART\n\n我们使用[`uart_16550`] crate来初始化UART，并通过串口来发送数据。为了将该crate添加为依赖，我们将我们的`Cargo.toml`和`main.rs`修改为如下:\n\n[`uart_16550`]: https://docs.rs/uart_16550\n\n```toml\n# in Cargo.toml\n\n[dependencies]\nuart_16550 = \"0.2.0\"\n```\n\n `uart_16550` crate包含了一个代表UART寄存器的`SerialPort`结构体，但是我们仍然需要自己来创建一个相应的实例。我们使用以下内容来创建一个新的串口模块`serial`:\n\n```rust\n// in src/main.rs\n\nmod serial;\n```\n\n```rust\n// in src/serial.rs\n\nuse uart_16550::SerialPort;\nuse spin::Mutex;\nuse lazy_static::lazy_static;\n\nlazy_static! {\n    pub static ref SERIAL1: Mutex<SerialPort> = {\n        let mut serial_port = unsafe { SerialPort::new(0x3F8) };\n        serial_port.init();\n        Mutex::new(serial_port)\n    };\n}\n```\n\n就像[VGA文本缓冲区][vga lazy-static]一样，我们使用 `lazy_static` 和一个自旋锁来创建一个 `static` writer实例。通过使用 `lazy_static` ，我们可以保证`init`方法只会在该示例第一次被使用使被调用。\n\n和 `isa-debug-exit`设备一样，UART也是用过I/O端口进行编程的。由于UART相对来讲更加复杂，它使用多个I/O端口来对不同的设备寄存器进行编程。不安全的`SerialPort::new`函数需要UART的第一个I/O端口的地址作为参数，从该地址中可以计算出所有所需端口的地址。我们传递的端口地址为`0x3F8` ，该地址是第一个串行接口的标准端口号。\n\n[vga lazy-static]: ./second-edition/posts/03-vga-text-buffer/index.md#lazy-statics\n\n为了使串口更加易用，我们添加了 `serial_print!` 和 `serial_println!`宏:\n\n```rust\n#[doc(hidden)]\npub fn _print(args: ::core::fmt::Arguments) {\n    use core::fmt::Write;\n    SERIAL1.lock().write_fmt(args).expect(\"Printing to serial failed\");\n}\n\n/// Prints to the host through the serial interface.\n#[macro_export]\nmacro_rules! serial_print {\n    ($($arg:tt)*) => {\n        $crate::serial::_print(format_args!($($arg)*));\n    };\n}\n\n/// Prints to the host through the serial interface, appending a newline.\n#[macro_export]\nmacro_rules! serial_println {\n    () => ($crate::serial_print!(\"\\n\"));\n    ($fmt:expr) => ($crate::serial_print!(concat!($fmt, \"\\n\")));\n    ($fmt:expr, $($arg:tt)*) => ($crate::serial_print!(\n        concat!($fmt, \"\\n\"), $($arg)*));\n}\n```\n\n该实现和我们此前的`print`和`println`宏的实现非常类似。 由于`SerialPort`类型已经实现了`fmt::Write` trait，所以我们不需要提供我们自己的实现了。\n\n[`fmt::Write`]: https://doc.rust-lang.org/nightly/core/fmt/trait.Write.html\n\n现在我们可以从测试代码里向串行接口打印而不是向VGA文本缓冲区打印了:\n\n```rust\n// in src/main.rs\n\n#[cfg(test)]\nfn test_runner(tests: &[&dyn Fn()]) {\n    serial_println!(\"Running {} tests\", tests.len());\n    […]\n}\n\n#[test_case]\nfn trivial_assertion() {\n    serial_print!(\"trivial assertion... \");\n    assert_eq!(1, 1);\n    serial_println!(\"[ok]\");\n}\n```\n\n注意，由于我们使用了 `#[macro_export]` 属性， `serial_println`宏直接位于根命名空间下——所以通过`use crate::serial::serial_println` 来导入该宏是不起作用的。\n\n### QEMU参数\n\n为了查看QEMU的串行输出，我们需要使用`-serial`参数将输出重定向到stdout：\n\n```toml\n# in Cargo.toml\n\n[package.metadata.bootimage]\ntest-args = [\n    \"-device\", \"isa-debug-exit,iobase=0xf4,iosize=0x04\", \"-serial\", \"stdio\"\n]\n```\n\n现在，当我们运行 `cargo xtest`时，我们可以直接在控制台里看到测试输出了:\n\n```text\n> cargo xtest\n    Finished dev [unoptimized + debuginfo] target(s) in 0.02s\n     Running target/x86_64-blog_os/debug/deps/blog_os-7b7c37b4ad62551a\nBuilding bootloader\n    Finished release [optimized + debuginfo] target(s) in 0.02s\nRunning: `qemu-system-x86_64 -drive format=raw,file=/…/target/x86_64-blog_os/debug/\n    deps/bootimage-blog_os-7b7c37b4ad62551a.bin -device\n    isa-debug-exit,iobase=0xf4,iosize=0x04 -serial stdio`\nRunning 1 tests\ntrivial assertion... [ok]\n```\n\n然而，当测试失败时，我们仍然会在QEMU内看到输出结果，因为我们的panic handler还是用了`println`。为了模拟这个过程，我们将我们的 `trivial_assertion` test中的断言(assertion)修改为 `assert_eq!(0, 1)`:\n\n![QEMU printing \"Hello World!\" and \"panicked at 'assertion failed: `(left == right)`\n    left: `0`, right: `1`', src/main.rs:55:5](https://os.phil-opp.com/testing/qemu-failed-test.png)\n\n可以看到，panic信息被打印到了VGA缓冲区里，而测试输出则被打印到串口上了。panic信息非常有用，所以我们希望能够在控制台中来查看它。\n\n### 在panic时打印一个错误信息\n\n为了在panic时使用错误信息来退出QEMU，我们可以使用**条件编译**（[conditional compilation]）在测试模式下使用（与非测试模式下）不同的panic处理方式:\n\n[conditional compilation]: https://doc.rust-lang.org/1.30.0/book/first-edition/conditional-compilation.html\n\n```rust\n// our existing panic handler\n#[cfg(not(test))] // new attribute\n#[panic_handler]\nfn panic(info: &PanicInfo) -> ! {\n    println!(\"{}\", info);\n    loop {}\n}\n\n// our panic handler in test mode\n#[cfg(test)]\n#[panic_handler]\nfn panic(info: &PanicInfo) -> ! {\n    serial_println!(\"[failed]\\n\");\n    serial_println!(\"Error: {}\\n\", info);\n    exit_qemu(QemuExitCode::Failed);\n    loop {}\n}\n```\n\n在我们的测试panic处理中，我们用 `serial_println`来代替`println` 并使用失败代码来退出QEMU。注意，在`exit_qemu`调用后，我们仍然需要一个无限循环的`loop`因为编译器并不知道 `isa-debug-exit`设备会导致程序退出。\n\n现在，即使在测试失败的情况下QEMU仍然会存在，并会将一些有用的错误信息打印到控制台：\n\n```text\n> cargo xtest\n    Finished dev [unoptimized + debuginfo] target(s) in 0.02s\n     Running target/x86_64-blog_os/debug/deps/blog_os-7b7c37b4ad62551a\nBuilding bootloader\n    Finished release [optimized + debuginfo] target(s) in 0.02s\nRunning: `qemu-system-x86_64 -drive format=raw,file=/…/target/x86_64-blog_os/debug/\n    deps/bootimage-blog_os-7b7c37b4ad62551a.bin -device\n    isa-debug-exit,iobase=0xf4,iosize=0x04 -serial stdio`\nRunning 1 tests\ntrivial assertion... [failed]\n\nError: panicked at 'assertion failed: `(left == right)`\n  left: `0`,\n right: `1`', src/main.rs:65:5\n```\n\n由于现在所有的测试都将输出到控制台上，我们不再需要让QEMU窗口弹出一小会儿了——我们完全可以把窗口藏起来。\n\n### 隐藏 QEMU\n\n由于我们使用`isa-debug-exit`设备和串行端口来报告完整的测试结果，所以我们不再需要QMEU的窗口了。我们可以通过向QEMU传递 `-display none`参数来将其隐藏:\n\n```toml\n# in Cargo.toml\n\n[package.metadata.bootimage]\ntest-args = [\n    \"-device\", \"isa-debug-exit,iobase=0xf4,iosize=0x04\", \"-serial\", \"stdio\",\n    \"-display\", \"none\"\n]\n```\n\n现在QEMU完全在后台运行且没有任何窗口会被打开。这不仅不那么烦人，还允许我们的测试框架在没有图形界面的环境里，诸如CI服务器或是[SSH]连接里运行。\n\n[SSH]: https://en.wikipedia.org/wiki/Secure_Shell\n\n### 超时\n\n由于 `cargo xtest` 会等待测试运行器退出，如果一个测试永远不返回那么它就会一直阻塞测试运行器。幸运的是，在实际应用中这并不是一个大问题，因为无限循环通常是很容易避免的。在我们的这个例子里，无限循环会发生在以下几种不同的情况中：\n\n- bootloader加载内核失败，导致系统不停重启；\n- BIOS/UEFI固件加载bootloader失败，同样会导致无限重启；\n- CPU在某些函数结束时进入一个`loop {}`语句，例如因为QEMU的exit设备无法正常工作而导致死循环；\n- 硬件触发了系统重置，例如未捕获CPU异常时（后续的文章将会详细解释）。\n\n由于无限循环可能会在各种情况中发生，因此， `bootimage` 工具默认为每个可执行测试设置了一个长度为5分钟的超时时间。如果测试未在此时间内完成，则将其标记为失败，并向控制台输出\"Timed Out（超时）\"错误。这个功能确保了那些卡在无限循环里的测试不会一直阻塞`cargo xtest`。\n\n你可以将`loop {}`语句添加到 `trivial_assertion`测试中来进行尝试。当你运行 `cargo xtest`时，你可以发现该测试会在五分钟后被标记为超时。超时持续的时间可以通过Cargo.toml中的`test-timeout`来进行[配置][bootimage config]：\n\n[bootimage config]: https://github.com/rust-osdev/bootimage#configuration\n\n```toml\n# in Cargo.toml\n\n[package.metadata.bootimage]\ntest-timeout = 300          # (in seconds)\n```\n\n如果你不想为了观察`trivial_assertion` 测试超时等待5分钟之久，你可以暂时降低将上述值。\n\n此后，我们不再需要 `trivial_assertion` 测试，所以我们可以将其删除。\n\n## 测试VGA缓冲区\n\n现在我们已经有了一个可以工作的测试框架了，我们可以为我们的VGA缓冲区实现创建一些测试。首先，我们创建了一个非常简单的测试来验证 `println`是否正常运行而不会panic：\n\n```rust\n// in src/vga_buffer.rs\n\n#[cfg(test)]\nuse crate::{serial_print, serial_println};\n\n#[test_case]\nfn test_println_simple() {\n    serial_print!(\"test_println... \");\n    println!(\"test_println_simple output\");\n    serial_println!(\"[ok]\");\n}\n```\n\n这个测试所做的仅仅是将一些内容打印到VGA缓冲区。如果它正常结束并且没有panic，也就意味着`println`调用也没有panic。由于我们只需要将 `serial_println` 导入到测试模式里，所以我们添加了 `cfg(test)` 属性（attribute）来避免正常模式下 `cargo xbuild`会出现的未使用导入警告（unused import warning）。\n\n为了确保即使打印很多行且有些行超出屏幕的情况下也没有panic发生，我们可以创建另一个测试：\n\n```rust\n// in src/vga_buffer.rs\n\n#[test_case]\nfn test_println_many() {\n    serial_print!(\"test_println_many... \");\n    for _ in 0..200 {\n        println!(\"test_println_many output\");\n    }\n    serial_println!(\"[ok]\");\n}\n```\n\n我们还可以创建另一个测试函数，来验证打印的几行字符是否真的出现在了屏幕上:\n\n```rust\n// in src/vga_buffer.rs\n\n#[test_case]\nfn test_println_output() {\n    serial_print!(\"test_println_output... \");\n\n    let s = \"Some test string that fits on a single line\";\n    println!(\"{}\", s);\n    for (i, c) in s.chars().enumerate() {\n        let screen_char = WRITER.lock().buffer.chars[BUFFER_HEIGHT - 2][i].read();\n        assert_eq!(char::from(screen_char.ascii_character), c);\n    }\n\n    serial_println!(\"[ok]\");\n}\n```\n\n该函数定义了一个测试字符串，并通过 `println`将其输出，然后遍历静态 `WRITER`也就是vga字符缓冲区的屏幕字符。由于`println`在将字符串打印到屏幕上最后一行后会立刻附加一个新行(即输出完后有一个换行符)，所以这个字符串应该会出现在第 `BUFFER_HEIGHT - 2`行。\n\n通过使用[`enumerate`] ，我们统计了变量`i`的迭代次数，然后用它来加载对应于`c`的屏幕字符。 通过比较屏幕字符的`ascii_character`和`c` ，我们可以确保字符串的每个字符确实出现在vga文本缓冲区中。\n\n[`enumerate`]: https://doc.rust-lang.org/core/iter/trait.Iterator.html#method.enumerate\n\n如你所想，我们可以创建更多的测试函数：例如一个用来测试当打印一个很长的且包装正确的行时是否会发生panic的函数，或是一个用于测试换行符、不可打印字符、非unicode字符是否能被正确处理的函数。\n\n在这篇文章的剩余部分，我们还会解释如何创建一个_集成测试_以测试不同组建之间的交互。 \n\n\n## 集成测试\n\n在Rust中，**集成测试**（[integration tests]）的约定是将其放到项目根目录中的`tests`目录下(即`src`的同级目录)。无论是默认测试框架还是自定义测试框架都将自动获取并执行该目录下所有的测试。\n\n[integration tests]: https://doc.rust-lang.org/book/ch11-03-test-organization.html#integration-tests\n\n所有的集成测试都是它们自己的可执行文件，并且与我们的`main.rs`完全独立。这也就意味着每个测试都需要定义它们自己的函数入口点。让我们创建一个名为`basic_boot`的例子来看看集成测试的工作细节吧:\n\n```rust\n// in tests/basic_boot.rs\n\n#![no_std]\n#![no_main]\n#![feature(custom_test_frameworks)]\n#![test_runner(crate::test_runner)]\n#![reexport_test_harness_main = \"test_main\"]\n\nuse core::panic::PanicInfo;\n\n#[no_mangle] // don't mangle the name of this function\npub extern \"C\" fn _start() -> ! {\n    test_main();\n\n    loop {}\n}\n\nfn test_runner(tests: &[&dyn Fn()]) {\n    unimplemented!();\n}\n\n#[panic_handler]\nfn panic(info: &PanicInfo) -> ! {\n    loop {}\n}\n```\n\n由于集成测试都是单独的可执行文件，所以我们需要再次提供所有的crate属性(`no_std`, `no_main`, `test_runner`, 等等)。我们还需要创建一个新的入口点函数`_start`，用于调用测试入口函数`test_main`。我们不需要任何的`cfg(test)` attributes(属性)，因为集成测试的二进制文件在非测试模式下根本不会被编译构建。\n\n这里我们采用[`unimplemented`]宏，充当`test_runner`暂未实现的占位符；添加简单的`loop {}`循环，作为`panic`处理器的内容。理想情况下，我们希望能向我们在`main.rs`里所做的一样使用`serial_println`宏和`exit_qemu`函数来实现这个函数。但问题是，由于这些测试的构建和我们的`main.rs`的可执行文件是完全独立的，我们没有办法使用这些函数。\n\n[`unimplemented`]: https://doc.rust-lang.org/core/macro.unimplemented.html\n\n如果现阶段你运行`cargo xtest`，你将进入一个无限循环，因为目前panic的处理就是进入无限循环。你需要使用快捷键`Ctrl+c`，才可以退出QEMU。\n\n### 创建一个库\n\n为了让这些函数能在我们的集成测试中使用，我们需要从我们的`main.rs`中分割出一个库，这个库应当可以被其他的crate和集成测试可执行文件使用。为了达成这个目的，我们创建了一个新文件，`src/lib.rs`:\n\n```rust\n// src/lib.rs\n\n#![no_std]\n```\n\n和`main.rs`一样，`lib.rs`也是一个可以被cargo自动识别的特殊文件。该库是一个独立的编译单元，所以我们需要再次指定`#![no_std]` 属性。\n\n为了让我们的库可以和`cargo xtest`一起协同工作，我们还需要添加以下测试函数和属性:\n\n```rust\n// in src/lib.rs\n\n#![cfg_attr(test, no_main)]\n#![feature(custom_test_frameworks)]\n#![test_runner(crate::test_runner)]\n#![reexport_test_harness_main = \"test_main\"]\n\nuse core::panic::PanicInfo;\n\npub fn test_runner(tests: &[&dyn Fn()]) {\n    serial_println!(\"Running {} tests\", tests.len());\n    for test in tests {\n        test();\n    }\n    exit_qemu(QemuExitCode::Success);\n}\n\npub fn test_panic_handler(info: &PanicInfo) -> ! {\n    serial_println!(\"[failed]\\n\");\n    serial_println!(\"Error: {}\\n\", info);\n    exit_qemu(QemuExitCode::Failed);\n    loop {}\n}\n\n/// Entry point for `cargo xtest`\n#[cfg(test)]\n#[no_mangle]\npub extern \"C\" fn _start() -> ! {\n    test_main();\n    loop {}\n}\n\n#[cfg(test)]\n#[panic_handler]\nfn panic(info: &PanicInfo) -> ! {\n    test_panic_handler(info)\n}\n```\n\n为了能在可执行文件和集成测试中使用`test_runner`，我们不对其应用`cfg(test)` 属性，并将其设置为public。同时，我们还将panic的处理程序分解为public函数`test_panic_handler`，这样一来它也可以用于可执行文件了。\n\n由于我们的`lib.rs`是独立于`main.rs`进行测试的，因此当该库实在测试模式下编译时我们需要添加一个`_start`入口点和一个panic处理程序。通过使用[`cfg_attr`] ，我们可以在这种情况下有条件地启用`no_main` 属性。\n\n[`cfg_attr`]: https://doc.rust-lang.org/reference/conditional-compilation.html#the-cfg_attr-attribute\n\n我们还将`QemuExitCode`枚举和`exit_qemu`函数从main.rs移动过来，并将其设置为公有函数：\n\n```rust\n// in src/lib.rs\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\n#[repr(u32)]\npub enum QemuExitCode {\n    Success = 0x10,\n    Failed = 0x11,\n}\n\npub fn exit_qemu(exit_code: QemuExitCode) {\n    use x86_64::instructions::port::Port;\n\n    unsafe {\n        let mut port = Port::new(0xf4);\n        port.write(exit_code as u32);\n    }\n}\n```\n\n现在，可执行文件和集成测试都可以从库中导入这些函数，而不需要实现自己的定义。为了使`println` 和 `serial_println`可用，我们将以下的模块声明代码也移动到`lib.rs`中：\n\n```rust\n// in src/lib.rs\n\npub mod serial;\npub mod vga_buffer;\n```\n\n我们将这些模块设置为public(公有)，这样一来我们在库的外部也一样能使用它们了。由于这两者都用了该模块内的`_print`函数，所以这也是让`println` 和 `serial_println`宏可用的必要条件。\n\n现在我们修改我们的`main.rs`代码来使用该库:\n\n```rust\n// src/main.rs\n\n#![no_std]\n#![no_main]\n#![feature(custom_test_frameworks)]\n#![test_runner(blog_os::test_runner)]\n#![reexport_test_harness_main = \"test_main\"]\n\nuse core::panic::PanicInfo;\nuse blog_os::println;\n\n#[no_mangle]\npub extern \"C\" fn _start() -> ! {\n    println!(\"Hello World{}\", \"!\");\n\n    #[cfg(test)]\n    test_main();\n\n    loop {}\n}\n\n/// This function is called on panic.\n#[cfg(not(test))]\n#[panic_handler]\nfn panic(info: &PanicInfo) -> ! {\n    println!(\"{}\", info);\n    loop {}\n}\n\n#[cfg(test)]\n#[panic_handler]\nfn panic(info: &PanicInfo) -> ! {\n    blog_os::test_panic_handler(info)\n}\n```\n\n可以看到，这个库用起来就像一个普通的外部crate。它的调用方法与其它crate无异；在我们的这个例子中，位置可能为`blog_os`。上述代码使用了`test_runner`属性中的`blog_os::test_runner`函数，`cfg(test)`的panic处理中的`blog_os::test_panic_handler`函数。它还导入了`println`宏，这样一来，我们可以在我们的`_start`和`panic`中使用它了。\n\n与此同时，`cargo xrun`和`cargo xtest`可以再次正常工作了。当然了，`cargo xtest`仍然会进入无限循环（你可以通过`ctrl+c`来退出）。接下来让我们在我们的集成测试中通过所需要的库函数来修复这个问题吧。\n\n### 完成集成测试\n\n就像我们的`src/main.rs`，我们的`tests/basic_boot.rs`可执行文件同样可以从我们的新库中导入类型。这也就意味着我们可以导入缺失的组件来完成我们的测试。\n\n```rust\n// in tests/basic_boot.rs\n\n#![test_runner(blog_os::test_runner)]\n\n#[panic_handler]\nfn panic(info: &PanicInfo) -> ! {\n    blog_os::test_panic_handler(info)\n}\n```\n\n这里我们使用我们的库中的`test_runner`函数，而不是重新实现一个测试运行器。至于panic处理，调用`blog_os::test_panic_handler`函数即可，就像我们之前在我们的`main.rs`里面做的一样。\n\n现在，`cargo xtest`又可以正常退出了。当你运行该命令时，你会发现它为我们的`lib.rs`, `main.rs`, 和 `basic_boot.rs`分别构建并运行了测试。其中，对于 `main.rs` 和 `basic_boot`的集成测试，它会报告\"Running 0 tests\"（正在执行0个测试），因为这些文件里面没有任何用 `#[test_case]`标注的函数。\n\n现在我们可以在`basic_boot.rs`中添加测试了。举个例子，我们可以测试`println`是否能够正常工作而不panic，就像我们之前在vga缓冲区测试中做的那样:\n\n```rust\n// in tests/basic_boot.rs\n\nuse blog_os::{println, serial_print, serial_println};\n\n#[test_case]\nfn test_println() {\n    serial_print!(\"test_println... \");\n    println!(\"test_println output\");\n    serial_println!(\"[ok]\");\n}\n```\n\n现在当我们运行`cargo xtest`时，我们可以看到它会寻找并执行这些测试函数。\n\n由于该测试和vga缓冲区测试中的一个几乎完全相同，所以目前它看起来似乎没什么用。然而，在将来，我们的`main.rs`和`lib.rs`中的`_start`函数的内容会不断增长，并且在运行`test_main`之前需要调用一系列的初始化进程，所以这两个测试将会运行在完全不同的环境中(译者注:也就是说虽然现在看起来差不多，但是在将来该测试和vga buffer中的测试会很不一样，有必要单独拿出来，这两者并没有重复)。\n\n通过在`basic_boot`环境里不掉用任何初始化例程的`_start`中测试`println`函数，我们可以确保`println`在启动（boot）后可以正常工作。这一点非常重要，因为我们有很多部分依赖于`println`，例如打印panic信息。\n\n### 未来的测试\n\n集成测试的强大之处在于，它们可以被看成是完全独立的可执行文件；这也给了它们完全控制环境的能力，使得他们能够测试代码和CPU或是其他硬件的交互是否正确。\n\n我们的`basic_boot`测试正是集成测试的一个非常简单的例子。在将来，我们的内核的功能会变得更多，和硬件交互的方式也会变得多种多样。通过添加集成测试，我们可以保证这些交互按预期工作（并一直保持工作）。下面是一些对于未来的测试的设想:\n\n- **CPU异常**：当代码执行无效操作（例如除以零）时，CPU就会抛出异常。内核会为这些异常注册处理函数。集成测试可以验证在CPU异常时是否调用了正确的异常处理程序，或者在可解析的异常之后程序是否能正确执行；\n- **页表**：页表定义了哪些内存区域是有效且可访问的。通过修改页表，可以重新分配新的内存区域，例如，当你启动一个软件的时候。我们可以在集成测试中调整`_start`函数中的一些页表项，并确认这些改动是否会对`#[test_case]`的函数产生影响；\n- **用户空间程序**：用户空间程序是只能访问有限的系统资源的程序。例如，他们无法访问内核数据结构或是其他应用程序的内存。集成测试可以启动执行禁止操作的用户空间程序验证认内核是否会将这些操作全都阻止。\n\n可以想象，还有更多的测试可以进行。通过添加各种各样的测试，我们确保在为我们的内核添加新功能或是重构代码时，不会意外地破坏他们。这一点在我们的内核变得更大和更复杂的时候显得尤为重要。\n\n### 那些应该Panic的测试\n\n标准库的测试框架支持允许构造失败测试的[`#[should_panic]` attribute][should_panic]。这个功能对于验证传递无效参数时函数是否会失败非常有用。不幸的是，这个属性需要标准库的支持，因此，在`#[no_std]`环境下无法使用。\n\n[should_panic]: https://doc.rust-lang.org/rust-by-example/testing/unit_testing.html#testing-panics\n\n尽管我们不能在我们的内核中使用`#[should_panic]` 属性，但是通过创建一个集成测试我们可以达到类似的效果——该集成测试可以从panic处理程序中返回一个成功错误代码。接下来让我一起来创建一个如上所述名为`should_panic`的测试吧：\n\n```rust\n// in tests/should_panic.rs\n\n#![no_std]\n#![no_main]\n\nuse core::panic::PanicInfo;\nuse blog_os::{QemuExitCode, exit_qemu, serial_println};\n\n#[panic_handler]\nfn panic(_info: &PanicInfo) -> ! {\n    serial_println!(\"[ok]\");\n    exit_qemu(QemuExitCode::Success);\n    loop {}\n}\n```\n\n这个测试还没有完成，因为它尚未定义`_start`函数或是其他自定义的测试运行器属性。让我们来补充缺少的内容吧：\n\n\n```rust\n// in tests/should_panic.rs\n\n#![feature(custom_test_frameworks)]\n#![test_runner(test_runner)]\n#![reexport_test_harness_main = \"test_main\"]\n\n#[no_mangle]\npub extern \"C\" fn _start() -> ! {\n    test_main();\n\n    loop {}\n}\n\npub fn test_runner(tests: &[&dyn Fn()]) {\n    serial_println!(\"Running {} tests\", tests.len());\n    for test in tests {\n        test();\n        serial_println!(\"[test did not panic]\");\n        exit_qemu(QemuExitCode::Failed);\n    }\n    exit_qemu(QemuExitCode::Success);\n}\n```\n\n这个测试定义了自己的`test_runner`函数，而不是复用`lib.rs`中的`test_runner`，该函数会在测试没有panic而是正常退出时返回一个错误退出代码(因为这里我们希望测试会panic)。如果没有定义测试函数，运行器就会以一个成功错误代码退出。由于这个运行器总是在执行完单个的测试后就退出，因此定义超过一个`#[test_case]`的函数都是没有意义的。\n\n现在我们来创建一个应该失败的测试:\n\n```rust\n// in tests/should_panic.rs\n\nuse blog_os::serial_print;\n\n#[test_case]\nfn should_fail() {\n    serial_print!(\"should_fail... \");\n    assert_eq!(0, 1);\n}\n```\n\n该测试用 `assert_eq`来断言（assert）`0`和`1`是否相等。毫无疑问，这当然会失败(`0`当然不等于`1`)，所以我们的测试就会像我们想要的那样panic。\n\n当我们通过`cargo xtest --test should_panic`运行该测试时，我们会发现成功了因为该测试如我们预期的那样panic了。当我们将断言部分（即`assert_eq!(0, 1);`）注释掉后，我们就会发现测试失败并返回了_\"test did not panic\"_的信息。\n\n这种方法的缺点是它只使用于单个的测试函数。对于多个`#[test_case]`函数，它只会执行第一个函数因为程序无法在panic处理被调用后继续执行。我目前没有想到解决这个问题的方法，如果你有任何想法，请务必告诉我！\n\n### 无约束测试\n\n对于那些只有单个测试函数的集成测试而言(例如我们的`should_panic`测试)，其实并不需要测试运行器。对于这种情况，我们可以完全禁用测试运行器，直接在`_start`函数中直接运行我们的测试。\n\n这里的关键就是在`Cargo.toml`中为测试禁用 `harness` flag，这个标志（flag）定义了是否将测试运行器用于集成测试中。如果该标志位被设置为`false`，那么默认的测试运行器和自定义的测试运行器功能都将被禁用，这样一来该测试就可以像一个普通的可执行程序一样运行了。\n\n现在让我们为我们的`should_panic`测试禁用`harness` flag吧：\n\n```toml\n# in Cargo.toml\n\n[[test]]\nname = \"should_panic\"\nharness = false\n```\n\n现在我们通过移除测试运行器相关的代码，大大简化了我们的`should_panic`测试。结果看起来如下：\n\n```rust\n// in tests/should_panic.rs\n\n#![no_std]\n#![no_main]\n\nuse core::panic::PanicInfo;\nuse blog_os::{QemuExitCode, exit_qemu, serial_println};\n\n#[no_mangle]\npub extern \"C\" fn _start() -> ! {\n    should_fail();\n    serial_println!(\"[test did not panic]\");\n    exit_qemu(QemuExitCode::Failed);\n    loop{}\n}\n\nfn should_fail() {\n    serial_print!(\"should_fail... \");\n    assert_eq!(0, 1);\n}\n\n#[panic_handler]\nfn panic(_info: &PanicInfo) -> ! {\n    serial_println!(\"[ok]\");\n    exit_qemu(QemuExitCode::Success);\n    loop {}\n}\n```\n\n现在我们可以通过我们的`_start`函数来直接调用`should_fail`函数了，如果返回则返回一个失败退出代码并退出。现在当我们执行`cargo xtest --test should_panic`时，我们可以发现测试的行为和之前完全一样。\n\n除了创建`should_panic`测试，禁用`harness` attribute对复杂集成测试也很有用，例如，当单个测试函数会产生一些边际效应需要通过特定的顺序执行时。\n\n## 总结\n\n测试是一种非常有用的技术，它能确保特定的部件拥有我们期望的行为。即使它们不能显示是否有bug，它们仍然是用来寻找bug的利器，尤其是用来避免回归。\n\n本文讲述了如何为我们的Rust kernel创建一个测试框架。我们使用Rust的自定义框架功能为我们的裸机环境实现了一个简单的`#[test_case]` attribute支持。通过使用QEMU的`isa-debug-exit`设备，我们的测试运行器可以在运行测试后退出QEMU并报告测试状态。我们还为串行端口实现了一个简单的驱动，使得错误信息可以被打印到控制台而不是VGA buffer中。\n\n在为我们的`println`宏创建了一些测试后，我们在本文的后半部分还探索了集成测试。我们了解到它们位于`tests`目录中，并被视为完全独立的可执行文件。为了使他们能够使用`exit_qemu` 函数和 `serial_println` 宏，我们将大部分代码移动到一个库里，使其能够被导入到所有可执行文件和集成测试中。由于集成测试在各自独立的环境中运行，所以能够测试与硬件的交互或是创建应该panic的测试。\n\n我们现在有了一个在QEMU内部真是环境中运行的测试框架。在未来的文章里，我们会创建更多的测试，从而让我们的内核在变得更复杂的同时保持可维护性。\n\n## 下期预告\n\n在下一篇文章中，我们将会探索 _CPU异常_ 。这些异常将在一些非法事件发生时由CPU抛出，例如抛出除以零或是访问没有映射的内存页（通常也被称为`page fault`即缺页异常）。能够捕获和检查这些异常，对将来的调试来说是非常重要的。异常处理与键盘支持所需的硬件中断处理十分相似。\n"
        },
        {
          "name": "05-cpu-exceptions.md",
          "type": "blob",
          "size": 26.59765625,
          "content": "# CPU异常\n\n> 原文：[https://os.phil-opp.com/cpu-exceptions/](https://os.phil-opp.com/cpu-exceptions/)\n>\n> 原作者：@phil-opp\n>\n> 译者：[倪广野](https://github.com/niguangye)\n\n触发CPU异常的情况多种多样，例如：访问非法内存地址或执行非法指令（除以零）等。为了应对CPU异常，我们需要建立中断描述符表（interrupt descriptor table)，它列举了不同异常所对应的处理函数(handler functions)。在博文的最后，我们的内核（kernel)可以捕获断点异常（[breakpoint exceptions](https://wiki.osdev.org/Exceptions#Breakpoint)）并且恢复CPU的正常运行。\n\n[TOC]\n\n## 概述\n\n异常的发生标志着当前正在执行的指令出现了问题。例如：指令试图除以0的时候，CPU会抛出一个异常。当异常发生，CPU会中断（interrupt）它当前的流程，并立即调用该类型异常对应的处理函数。\n\n在x86体系结构中，有大约20种不同的CPU 异常类型。常见的如下：\n\n- **缺页错误（Page Fault）**：缺页错误发生在非法的内存访问操作中。例如：当前指令试图访问没有映射的内存页或试图写入只读的内存页。\n\n- **非法操作码（Invalid Opcode）**：非法操作码发生在当前指令不正确的情况下。例如：试图在不支持 [SSE 指令集](https://en.wikipedia.org/wiki/Streaming_SIMD_Extensions) 的老旧CPU上使用该指令集。\n- **通用保护错误（General Protection Fault）**：这是一个触发原因相对宽泛的异常。试图在用户态程序中执行特权指令或试图写入配置寄存器的保留位等非法访问操作均会触发该异常。\n- **双重异常（Double Fault）**：异常发生后，CPU会调用对应的异常处理函数。在调用过程中如果发生另一个异常，CPU会触发双重异常。双重异常也会在找不到对应的异常处理函数的情况下发生。\n- **三重异常（Triple Fault）**：如果异常发生在CPU调用双重异常处理函数的过程中，这会导致严重的三重异常。我们不能捕获或者处理三重异常。大多数处理器会选择复位并重启操作系统。\n\n你可以在[这里](https://wiki.osdev.org/Exceptions)找到所有的CPU异常列表。\n\n### 中断描述符表（interrupt descriptor table)\n\n为了捕获并处理CPU异常，我们需要建立所谓的中断描述符表（interrupt descriptor table，IDT)。在IDT中，我们可以为每种异常指定一个处理函数。硬件会直接使用这张表，所以我们需要遵循提前约定好的格式。IDT的每一项（entry）必须是16字节的结构：\n\n| Type | Name             | Description                                                  |\n| ---- | ---------------- | ------------------------------------------------------------ |\n| u16  | 函数指针 [0:15]  | 处理函数（handler function)指针的低16位                      |\n| u16  | GDT 选择子       | [global descriptor table](https://en.wikipedia.org/wiki/Global_Descriptor_Table) 代码段的选择子 |\n| u16  | 选项参数         | 参见下文                                                     |\n| u16  | 函数指针 [16:31] | 处理函数（handler function)指针的中间16位                    |\n| u32  | 函数指针 [32:63] | 处理函数（handler function)指针剩下的32位                    |\n| u32  | 保留位           |                                                              |\n\n选项参数必须是下面的结构：\n\n| Bits  | Name                 | Description                                                  |\n| ----- | -------------------- | ------------------------------------------------------------ |\n| 0-2   | 中断栈表索引         | 0: 不切换栈, 1-7:当处理函数被调用时，切换到中断栈表（Interrupt Stack Table）的第n个栈 |\n| 3-7   | 保留位               |                                                              |\n| 8     | 0: 中断门, 1: 陷阱门 | 如果这个bit被设置为0，处理函数被调用的时候，中断会被禁用。   |\n| 9-11  | 必须为1              |                                                              |\n| 12    | 必须为0              |                                                              |\n| 13‑14 | 特权等级描述符 (DPL) | 允许调用该处理函数的最小特权等级。                           |\n| 15    | Present              |                                                              |\n\n每个异常都拥有提前约定好的IDT索引。例如：非法操作码的表索引是6，而缺页错误的的表索引是14。因此，硬件可以找到每种异常对应的中断描述符表的条目（interrupt descriptor table entry, IDT entry)。[OSDev wiki](https://wiki.osdev.org/Exceptions)页面的Exception Table的“Vector nr.”列展示了所有异常的IDT索引。\n\n当异常发生时，CPU大致遵循下面的流程：\n\n1. 将一些寄存器的内容压入栈中，包括当前指令的指针和[RFLAGS](http://en.wikipedia.org/wiki/FLAGS_register)寄存器的内容（我们会在文章的后续部分用到这些值）。\n\n2. 读取中断描述符表（IDT）中对应的条目。例如：缺页错误发生时，CPU会读取IDT的第十四个条目。\n3. 检查这个条目是否存在，如果没有则升级为双重错误（double fault)。\n4. 如果条目是一个中断门（第40个bit没有被设置为1），则禁用硬件中断。\n5. 装载指定的GDT 选择子到CS段。\n6. 跳转到指定的处理函数。\n\n现在不要担心第四、五步，我们会在未来的文章中研究GDT和硬件中断。\n\n## 一个IDT类型（An IDT Type)\n\n我们选择使用`x86_64` crate中的 `InterruptDescriptorTable` 结构体，而不是创建自己的 IDT 类型：\n\n```rust\n#[repr(C)]\npub struct InterruptDescriptorTable {\n    pub divide_by_zero: Entry<HandlerFunc>,\n    pub debug: Entry<HandlerFunc>,\n    pub non_maskable_interrupt: Entry<HandlerFunc>,\n    pub breakpoint: Entry<HandlerFunc>,\n    pub overflow: Entry<HandlerFunc>,\n    pub bound_range_exceeded: Entry<HandlerFunc>,\n    pub invalid_opcode: Entry<HandlerFunc>,\n    pub device_not_available: Entry<HandlerFunc>,\n    pub double_fault: Entry<HandlerFuncWithErrCode>,\n    pub invalid_tss: Entry<HandlerFuncWithErrCode>,\n    pub segment_not_present: Entry<HandlerFuncWithErrCode>,\n    pub stack_segment_fault: Entry<HandlerFuncWithErrCode>,\n    pub general_protection_fault: Entry<HandlerFuncWithErrCode>,\n    pub page_fault: Entry<PageFaultHandlerFunc>,\n    pub x87_floating_point: Entry<HandlerFunc>,\n    pub alignment_check: Entry<HandlerFuncWithErrCode>,\n    pub machine_check: Entry<HandlerFunc>,\n    pub simd_floating_point: Entry<HandlerFunc>,\n    pub virtualization: Entry<HandlerFunc>,\n    pub security_exception: Entry<HandlerFuncWithErrCode>,\n    // some fields omitted\n}\n```\n\n`InterruptDescriptorTable`结构体的字段都是[`idt::Entry`](https://docs.rs/x86_64/0.12.1/x86_64/structures/idt/struct.Entry.html)类型，这种类型是一种代表`IDT`条目字段的结构体（见上面的示例）。类型参数`F`定义了预期的处理函数类型。我们可以发现上面的条目字段需要 [`HandlerFunc `](https://docs.rs/x86_64/0.12.1/x86_64/structures/idt/type.HandlerFunc.html) 或 [`HandlerFuncWithErrCode `](https://docs.rs/x86_64/0.12.1/x86_64/structures/idt/type.HandlerFuncWithErrCode.html) 参数。缺页错误甚至拥有它独有的处理函数类型：[`PageFaultHandlerFunc `](https://docs.rs/x86_64/0.12.1/x86_64/structures/idt/type.PageFaultHandlerFunc.html) 。\n\n首先，我们探讨一下 `HandlerFunc` 类型：\n\n```rust\ntype HandlerFunc = extern \"x86-interrupt\" fn(_: &mut InterruptStackFrame);\n```\n\n`HandlerFunc ` 是 `extern \"x86-interrupt\" fn` 的类型别名。`extern` 关键字定义了一个外部调用约定（ [foreign calling convention](https://doc.rust-lang.org/nomicon/ffi.html#foreign-calling-conventions) ），它经常被用于链接C语言代码（`extern \"C\" fn`）。那么，`x86-interrupt`调用约定是什么呢?\n\n## 中断调用约定（ The Interrupt Calling Convention）\n\nCPU异常与函数调用非常相似：CPU跳转到调用函数的第一条指令并执行它。然后，CPU跳转到返回地址并继续执行函数的调用者函数（`parent function`)。\n\n然而，异常和函数调用有一个重要的区别：函数调用是被编译器生成的 `call` 指令主动发起，而\n\n异常可以发生在所有指令的执行过程中。为了理解这个区别的重要性，我们需要更进一步地研究函数调用。\n\n[调用约定 Calling conventions](https://en.wikipedia.org/wiki/Calling_convention) 明确规定了函数调用的细节。例如，它规定了函数参数的位置（ 寄存器还是函数栈）和结果的返回方式。在x86_64 Linux体系中，C语言函数调用适用下面的规则（在[System V ABI](https://refspecs.linuxbase.org/elf/x86_64-abi-0.99.pdf)中规定）：\n\n- 前六个整数参数会被放在寄存器中传递：`rdi`, `rsi`, `rdx`, `rcx`, `r8`, `r9`\n- 剩下的参数被放在栈中传递\n- 结果被放在 `rax` 和 `rdx` 中返回\n\nRust 没有遵顼C ABI （事实上，Rust甚至没有规定的ABI），所以这些规则仅仅适用于声明了 `extern \"C\" fn` 的函数。\n\n###  Preserved and Scratch 寄存器\n\n调用约定（ `calling convention`）将寄存器分为两个部分： *preserved* 和 *scratch* 寄存器。\n\n 在函数调用的过程中，*preserved*寄存器的值必须保持不变。所以，被调用的函数（`callee`）必须保证会在返回以前会主动复原这些寄存器的原始值，才可以修改这些寄存器的值。因此，这些寄存器被称为被**调用者保存寄存器**（*callee-saved*，译者注：也就是AKA非易失性寄存器）。通行的模式是在函数的开始保存这些寄存器的值到函数栈中，并在函数马上返回的时候复原他们。\n\n相比之下，被调用的函数（`callee`）可以无约束地修改 *scratch*寄存器。如果调用者函数希望在函数调用的过程中保留 *scratch*寄存器的值，它需要在调用函数之前备份和复原 *scratch*寄存器的值（例如将这些值压入栈中）。所以，这些寄存器被称为**调用者寄存器**（*caller-saved*，译者注：也就是AKA易失性寄存器）。\n\n 在x86_64架构中，C语言调用约定明确规定了下面的 preserved and scratch 寄存器：\n\n| preserved 寄存器                                | scratch 寄存器                                              |\n| ----------------------------------------------- | ----------------------------------------------------------- |\n| `rbp`, `rbx`, `rsp`, `r12`, `r13`, `r14`, `r15` | `rax`, `rcx`, `rdx`, `rsi`, `rdi`, `r8`, `r9`, `r10`, `r11` |\n| *callee-saved*                                  | *caller-saved*                                              |\n\n编译器遵顼这些规定生成二进制字节码。例如：绝大多数函数地字节码开始于`push rbp`指令，这个指令会备份`rbp`寄存器地值到函数栈中（因为这是一个`callee-saved`寄存器）。\n\n### 保存所有寄存器\n\n与函数调用形成鲜明对比的是，异常可以发生在所有指令的执行过程中。大多数情况下，我们甚至不能识别出编译器生成的代码是否会引起异常。例如，编译器不能预见到一个指令是否会引起栈溢出或缺页错误。\n\n既然不能预见到异常的发生时机，我们自然也无法做到提前备份任何寄存器的值。这意味着我们不能使用依赖于 `caller-saved` 寄存器的调用约定去处理异常。然而，我们需要一个会保存所有寄存器值的调用约定。`x86-interrupt`调用约定恰恰能够保证所有寄存器会在函数调用结束以前复原到原始值。\n\n这并不意味着所有寄存器的值会在函数开始时被保存到函数栈中。相反，编译器（生成的代码）只会备份被函数覆盖的寄存器的值。在这种方式下，较短的函数编译生成的二进制字节码会非常高效，也就是只使用尽可能少的寄存器。\n\n### 中断栈帧（ The Interrupt Stack Frame）\n\n在寻常的函数调用（`call`指令执行）中，CPU跳转到相应的函数之前会将返回地址压入到函数栈中。在函数返回（`ret`指令执行）的时候，CPU会弹出并跳转到这个返回地址。所以，寻常的函数调用栈帧会如下图所示：\n\n![function-stack-frame](https://markdown-ngy.oss-cn-beijing.aliyuncs.com/function-stack-frame.svg)\n\n然而，异常和中断处理函数并不能将返回地址压入到函数栈中，因为中断处理函数往往运行在不同的上下文（栈指针，CPU flags等）中。相反，在异常发生的时候，CPU会执行以下步骤：\n\n1. **对齐栈指针**：中断可以发生在任何指令的执行过程中，栈指针自然也可能是任何值。然而，一些CPU指令集（e.g. 一些 SSE指令集）需要栈指针在16字节边界上对齐，因此CPU会在中断之后靠右对齐栈指针。\n2. **切换栈（在某种情况下）**：CPU特权等级发生改变的时候，栈会被切换，例如CPU 异常发生在用户态程序的时候。用所谓的中断栈表（ *Interrupt Stack Table* , 下篇文章解释 ）配置特定中断的栈切换也是可行的。\n3. **压入原来的栈指针**：在中断发生的时候（对齐栈指针发生之前），CPU将栈指针（`rsp`）和栈段（`ss`)寄存器压入栈中。如此一来，中断处理函数返回时就可以复原栈指针的原始值。\n4. **压入并更新`RFLAGS`寄存器**：[`RFLAGS`](https://en.wikipedia.org/wiki/FLAGS_register)寄存器保存了多种控制和状态位。进入中断函数时，CPU修改一些位并压入旧的值。\n5. **压入指令指针**：跳转到中断处理函数之前，CPU压入指令指针（`rip`）和代码段（`cs`)。这类似于寻常的函数调用压入返回地址的过程。\n6. **压入错误码（对于部分异常）**：对于缺页错误等特定的异常，CPU会压入解释异常原因的错误码。\n7. **调用中断处理函数**：CPU从IDT对应的字段中读取中断处理函数的地址和段描述符。然后通过加载这些值到`rip`和`cs`寄存器中，调用中断处理函数。\n\n所以，中断调用栈帧会如下图所示：\n\n![exception-stack-frame](https://markdown-ngy.oss-cn-beijing.aliyuncs.com/exception-stack-frame.svg)\n\n在Rust的`x86_64`库中，中断调用栈帧被抽象为[`InterruptStackFrame`](https://docs.rs/x86_64/0.12.1/x86_64/structures/idt/struct.InterruptStackFrame.html)结构体。它会被作为`&mut`传递给中断处理函数，并被用来获取更多的关于异常原因的信息。由于只有小部分异常会压入错误码，所以[`InterruptStackFrame`](https://docs.rs/x86_64/0.12.1/x86_64/structures/idt/struct.InterruptStackFrame.html)并没有设置`error_code`字段。这些异常会另外使用[`HandlerFuncWithErrCode`](https://docs.rs/x86_64/0.12.1/x86_64/structures/idt/type.HandlerFuncWithErrCode.html)函数来处理，这个函数有一个`error_code`参数用来保存错误码。\n\n### 幕后工作\n\n`x86-interrupt`调用约定作为一个优秀的抽象，它几乎隐藏了异常处理过程中所有繁杂的细节。然而，理解幕布后的工作在某些时候是有益的。下面简要概述了`x86-interrupt`调用约定所处理的事情：\n\n- **抽取参数**：大多数调用约定希望参数被放在寄存器中传递。这对于异常处理函数是不可能的，因为我们不能在保存寄存器的值之前覆盖这些寄存器。然而，`x86-interrupt`调用约定明白这些参数早就被放在栈的某个位置上了。\n- **使用`iretq`返回**：既然中断栈帧和寻常函数调用的栈帧是不同的，我们不能使用`ret`指令从中断处理函数中返回。但是可以使用`iretq`指令。\n- **处理错误码**：部分特定异常压入的错误码是事情变得更加复杂。它改变了栈对齐（见对齐栈部分）并且需要在返回之前从栈中弹出。`x86-interrupt`调用约定处理了所有难题。但是，它无法获得每种异常对应的处理函数，所以，它需要从函数的参数中推断这些信息。这意味着，程序员有责任使用正确的函数类型处理每种异常。幸运的是，`x86_64`库的`InterruptDescriptorTable`可以确保这一过程不会出错。\n- **对齐栈**：一些指令集（尤其是SSE指令集）使用16字节的栈对齐。在异常发生的时候，CPU会确保栈对齐。但是在压入错误码后，栈对齐会再次被破坏。`x86-interrupt`调用约定会通过再次对齐栈解决这个问题。\n\n如果你对更多的细节感兴趣：我们也有一系列文章解释了如何使用 [naked functions](https://github.com/rust-lang/rfcs/blob/master/text/1201-naked-fns.md)处理异常。\n\n ## 实现\n\n现在我们理解了这些理论，是时候在我们的内核中实现CPU异常处理了。我们首先在`src/interrupts.rs`中创建一个新的interrupts 模块，其中`init_idt`函数创建了一个新的`InterruptDescriptorTable`：\n\n```rust\n// in src/lib.rs\n\npub mod interrupts;\n\n// in src/interrupts.rs\n\nuse x86_64::structures::idt::InterruptDescriptorTable;\n\npub fn init_idt() {\n    let mut idt = InterruptDescriptorTable::new();\n}\n```\n\n现在我们可以增加更多的处理函数。我们首先创建断点异常（[breakpoint exception](https://wiki.osdev.org/Exceptions#Breakpoint)）的处理函数。断点异常是一个绝佳的测试处理异常过程的示例。它唯一的用途是在断点指令`int3`执行的时候暂停整个程序。\n\n断点异常通常被用于调试程序（debugger）：当用户设置了断点，调试程序会使用`int3`指令覆盖对应位置的指令，当CPU执行到这一位置的时候会抛出断点异常。当用户希望继续执行程序时，调试程序将`int3`指令替换回原来的指令并继续执行。可以从 [\"*How debuggers work*\"](https://eli.thegreenplace.net/2011/01/27/how-debuggers-work-part-2-breakpoints) 系列获取更多的细节。\n\n我们无需覆盖任何指令。因为我们只希望程序在异常指令执行的时候打印一条消息，然后继续执行。让我们创建一个简单的断点异常处理函数（breakpoint_handler）并添加到IDT：\n\n```rust\n// in src/interrupts.rs\n\nuse x86_64::structures::idt::{InterruptDescriptorTable, InterruptStackFrame};\nuse crate::println;\n\npub fn init_idt() {\n    let mut idt = InterruptDescriptorTable::new();\n    idt.breakpoint.set_handler_fn(breakpoint_handler);\n}\n\nextern \"x86-interrupt\" fn breakpoint_handler(\n    stack_frame: &mut InterruptStackFrame)\n{\n    println!(\"EXCEPTION: BREAKPOINT\\n{:#?}\", stack_frame);\n}\n```\n\n处理函数只输出了一条消息并美观的打印了中断栈帧。\n\n当我们试图编译程序的时候，错误出现了：\n\n```rust\nerror[E0658]: x86-interrupt ABI is experimental and subject to change (see issue #40180)\n  --> src/main.rs:53:1\n   |\n53 | / extern \"x86-interrupt\" fn breakpoint_handler(stack_frame: &mut InterruptStackFrame) {\n54 | |     println!(\"EXCEPTION: BREAKPOINT\\n{:#?}\", stack_frame);\n55 | | }\n   | |_^\n   |\n   = help: add #![feature(abi_x86_interrupt)] to the crate attributes to enable\n```\n\n这个错误是因为 `x86-interrupt` 中断调用约定仍然不稳定。我们需要明确地在`lib.rs`顶部增加`#![feature(abi_x86_interrupt)]`去激活它。\n\n### 加载IDT\n\n为了让CPU使用我们新的中断描述符表，我们需要使用 [`lidt`](https://www.felixcloutier.com/x86/lgdt:lidt) 指令去加载它。`x86_64` 库的`InterruptDescriptorTable` 结构体提供了一个 `load` 方法去实现这个操作：\n\n```rust\n// in src/interrupts.rs\n\npub fn init_idt() {\n    let mut idt = InterruptDescriptorTable::new();\n    idt.breakpoint.set_handler_fn(breakpoint_handler);\n    idt.load();\n}\n```\n\n当我们试图编译程序的时候，下面的错误出现了：\n\n```rust\nerror: `idt` does not live long enough\n  --> src/interrupts/mod.rs:43:5\n   |\n43 |     idt.load();\n   |     ^^^ does not live long enough\n44 | }\n   | - borrowed value only lives until here\n   |\n   = note: borrowed value must be valid for the static lifetime...\n```\n\n `load` 方法期望一个 `&'static self`，以确保 `idt` 引用在整个程序生命周期中可用。因为CPU会在每个异常发生的时候访问这张表，直到我们加载了其它的`InterruptDescriptorTable`对象。所以，使用比 `'static` 短的生命周期会导致 use-after-free bug。\n\n事实上，情况很明白。我们的 `idt`  在栈上创建，所以它只在 `init` 函数的生命周期中有效。一旦这个栈内存被其它函数重用，CPU会把随机的栈内存当作IDT。幸运的是， `InterruptDescriptorTable::load` 在函数定义中明确要求了必要的生命周期条件（译者注：也就是必须使用 `'static` 生命周期）。所以，Rust 编译器可以在编译期就阻止这个潜在的 bug 。\n\n为了解决这个问题，我们需要保存我们的 `idt` 对象到拥有 `'static` 生命周期的地方。我们可以使用 `Box` 把 IDT 分配到堆上，并转换为 `'static` 引用，但是我们是在开发操作系统内核，所以并不会有堆这个概念。\n\n作为代替，我们可以把 IDT 保存为 常量（`static`）：\n\n```\nstatic IDT: InterruptDescriptorTable = InterruptDescriptorTable::new();\n\npub fn init_idt() {\n    IDT.breakpoint.set_handler_fn(breakpoint_handler);\n    IDT.load();\n}\n```\n\n但是，这有一个问题：常量是不可变的，所以我们不能修改来自 `init` 函数的IDT中的断点条目。我们可以使用 [`static mut`](https://doc.rust-lang.org/1.30.0/book/second-edition/ch19-01-unsafe-rust.html#accessing-or-modifying-a-mutable-static-variable) 解决这个问题：\n\n```rust\nstatic mut IDT: InterruptDescriptorTable = InterruptDescriptorTable::new();\n\npub fn init_idt() {\n    unsafe {\n        IDT.breakpoint.set_handler_fn(breakpoint_handler);\n        IDT.load();\n    }\n}\n```\n\n这种变体不会出现编译错误，但是并不符合优雅的编程风格。 `static mut` 非常容易造成数据竞争，所以在每一次访问中都需要使用 [`unsafe`](https://doc.rust-lang.org/1.30.0/book/second-edition/ch19-01-unsafe-rust.html#unsafe-superpowers) 代码块。\n\n#### 懒加载常量\n\n `lazy_static` 宏的存在令人庆幸。它可以让常量在被第一次使用的时候被初始化，而不是在编译期。因此，我们可以在初始化代码块中做几乎所有的事情，甚至读取常量在运行时的值。\n\n我们已经在 [created an abstraction for the VGA text buffer](https://os.phil-opp.com/vga-text-mode/#lazy-statics) 引用了 `lazy_static` 库。所以我们可以直接使用 `lazy_static!` 宏去创建静态的IDT：\n\n```\n// in src/interrupts.rs\n\nuse lazy_static::lazy_static;\n\nlazy_static! {\n    static ref IDT: InterruptDescriptorTable = {\n        let mut idt = InterruptDescriptorTable::new();\n        idt.breakpoint.set_handler_fn(breakpoint_handler);\n        idt\n    };\n}\n\npub fn init_idt() {\n    IDT.load();\n}\n```\n\n这种方法不需要 [`unsafe`](https://doc.rust-lang.org/1.30.0/book/second-edition/ch19-01-unsafe-rust.html#unsafe-superpowers) 代码块，因为 `lazy_static!` 宏在底层使用了 [`unsafe`](https://doc.rust-lang.org/1.30.0/book/second-edition/ch19-01-unsafe-rust.html#unsafe-superpowers) 代码块，但是抽象出了一个安全接口。\n\n### 运行\n\n让内核种的异常处理工作的最后一步是在 `main.rs` 中调用 `init_idt` 函数。在 `lib.rs` 中抽象一个总体的 `init` 函数而不是直接调用:\n\n```\n// in src/lib.rs\n\npub fn init() {\n    interrupts::init_idt();\n}\n```\n\n这个函数用来放置可以被 `main.rs` , `lib.rs`中的 `_start` 函数和集成测试所共享的初始化代码。\n\n在 `main.rs` 中的 `_start` 函数中调用 `init` 函数，并触发一个断点异常。\n\n```\n// in src/main.rs\n\n#[no_mangle]\npub extern \"C\" fn _start() -> ! {\n    println!(\"Hello World{}\", \"!\");\n\n    blog_os::init(); // new\n\n    // invoke a breakpoint exception\n    x86_64::instructions::interrupts::int3(); // new\n\n    // as before\n    #[cfg(test)]\n    test_main();\n\n    println!(\"It did not crash!\");\n    loop {}\n}\n```\n\n使用 `cargo run` 命令在QEMU中运行程序：\n\n![qemu-breakpoint-exception](https://markdown-ngy.oss-cn-beijing.aliyuncs.com/qemu-breakpoint-exception.png)\n\nCPU成功调用了断点异常处理函数，并打印了一些消息，然后返回 `_start` 函数继续打印了 `It did not crash!` 消息。\n\n可以发现，中断栈帧显示了中断发生时的指令和栈指针地址。这有助于调试不该发生的异常。\n\n### 增加Test\n\n增加一个确认上文中CPU继续工作的测试。首先，让 `lib.rs` 的  `_start` 函数同样调用 `init` 函数：\n\n```\n// in src/lib.rs\n\n/// Entry point for `cargo test`\n#[cfg(test)]\n#[no_mangle]\npub extern \"C\" fn _start() -> ! {\n    init();      // new\n    test_main();\n    loop {}\n}\n```\n\n既然 `lib.rs` 中的测试完全独立于 `main.rs` ，必须使用命令  `cargo test --lib` 来指定运行 `lib.rs` 中的 `_start` 函数。在`lib.rs` 中的测试运行以前，我们需要调用 `init` 函数去建立IDT。\n\n现在，创建一个 `test_breakpoint_exception` 测试：\n\n```\n// in src/interrupts.rs\n\n#[test_case]\nfn test_breakpoint_exception() {\n    // invoke a breakpoint exception\n    x86_64::instructions::interrupts::int3();\n}\n```\n\n这个测试调用了 `x86_64` 库的 `int3` 函数去触发断点异常。通过检查异常处理后程序继续执行，可以验证断点异常处理函数正常工作。\n\n使用 `cargo test` （所有测试）或 `cargo test --lib`（只限于 `lib.rs` 和它的子模块中的测试）命令运行新的测试，应当可以看见：\n\n```\nblog_os::interrupts::test_breakpoint_exception...\t[ok]\n```\n\n## 过于抽象?（ Too much Magic?）\n\n `x86-interrupt` 调用约定和 [`InterruptDescriptorTable`](https://docs.rs/x86_64/0.12.1/x86_64/structures/idt/struct.InterruptDescriptorTable.html) 让异常处理流程变得相当简单愉快。如果你觉得太过抽象或有兴趣学习异常处理更硬核的细节，[“Handling Exceptions with Naked Functions”](https://os.phil-opp.com/first-edition/extra/naked-exceptions/)  系列会告诉你如何在不使用 `x86-interrupt` 调用约定的情况下处理异常并建立自己的IDT类型。在 `x86-interrupt` 调用约定和 `x86_64` 库问世以前，这个系列可以说是最主流的异常处理主体相关的博客。不得不提的是，这些文章基于第一版本的 [Writing an OS in Rust ](https://os.phil-opp.com/first-edition/)，所以可能会有些过时。\n\n## 接下来?\n\n我们成功地触发了第一个异常并从中返回！下一步是确保可以捕获所有异常，因为未被捕获地异常会引发严重的 [triple fault](https://wiki.osdev.org/Triple_Fault) ，继而导致系统复位。下一篇文章解释了如何通过捕获 [双重异常 double faults](https://wiki.osdev.org/Double_Fault#Double_Fault) 来避免这些问题。\n\n"
        },
        {
          "name": "06-double-fault-exceptions.md",
          "type": "blob",
          "size": 28.9453125,
          "content": "# 双重异常\n\n> 原文：[https://os.phil-opp.com/double-fault-exceptions/](https://os.phil-opp.com/double-fault-exceptions/)\n>\n> 原作者：@phil-opp\n>\n> 译者：[倪广野](https://github.com/niguangye)\n\n这篇文章将深入探究双重异常（*double fault*），这是一个在CPU调用异常处理函数失败的时候触发的异常。通过处理双重异常，可以避免会引起系统复位的三重异常。为了彻底防止各种情况下的三重异常，需要建立中断栈表（ *Interrupt Stack Table* ）去捕获所有不同内核栈的双重异常。\n\n这个博客在 [GitHub](https://github.com/phil-opp/blog_os) 上开源。如果你遇到问题或困难，请到那里提 issue 。或者你也可以在博客的最下方留言。你可以在 [`post-06`](https://github.com/phil-opp/blog_os/tree/post-06) 分支找到这篇文章的完整源码。\n\n> 译注：中文版请移步[《编写 Rust 语言的操作系统》](https://github.com/rustcc/writing-an-os-in-rust)\n\n## 双重异常的定义\n\n简单点说，双重异常就是一个在CPU调用异常处理函数失败的时候触发的特定异常。例如，CPU触发缺页异常（*page fault*），但是中断描述符表（ *[Interrupt Descriptor Table](https://os.phil-opp.com/cpu-exceptions/#the-interrupt-descriptor-table)* ，*IDT*）中却没有对应处理函数的情况。所以，这和编程语言中捕获所有异常的代码块（*catch-all blocks*）有些相似，例如 C++ 中的 `catch(...)` 或 Java和 C# 中的 `catch(Exception e)` 。\n\n双重异常的表现和普通异常区别不大。它拥有一个特定的向量号（*Interrupt Vector Number*） `8` ，我们可以在 *IDT* 中定义一个对应的处理函数。定义双重异常的处理函数十分重要，因为双重异常在不被处理的情况下会引发致命的三重异常。三重异常不能被捕获，而且会引起大多数硬件的系统复位。\n\n### 触发一个双重异常\n\n让我们通过触发一个没有处理函数的普通异常来引发双重异常：\n\n```rust\n// in src/main.rs\n\n#[no_mangle]\npub extern \"C\" fn _start() -> ! {\n    println!(\"Hello World{}\", \"!\");\n\n    blog_os::init();\n\n    // trigger a page fault\n    unsafe {\n        *(0xdeadbeef as *mut u64) = 42;\n    };\n\n    // as before\n    #[cfg(test)]\n    test_main();\n\n    println!(\"It did not crash!\");\n    loop {}\n}\n```\n\n我们使用 `unsafe`  去写入非法的内存地址 `0xdeadbeef` 。这个虚拟地址没有在页表中被映射到物理地址，这会触发一个缺页异常。而缺页异常的处理函数还没有被定义到 [IDT](https://os.phil-opp.com/cpu-exceptions/#the-interrupt-descriptor-table) ，因此双重异常被触发了。\n\n现在启动内核，它会进入到无穷尽的启动循环。原因如下：\n\n1. *CPU* 试图写入非法的内存地址 `0xdeadbeef` ，这会触发缺页异常。\n2. *CPU* 查找到 *IDT* 中缺页异常对应的条目，并且没有发现对应的处理函数。因为它不能正常调用缺页异常的处理函数，所以触发了双重异常。\n3. *CPU* 查找到 *IDT* 中双重异常对应的条目，并且也没有发现对应的处理函数。因此，三重异常被触发。\n4. 三重异常是致命的。*QEMU* 像大多数的硬件一样选择系统复位。\n\n所以为了阻止三重异常，我们需要提供缺页异常或双重异常的处理函数。我们希望阻止所有情况下的三重异常，因此我们选择建立所有异常未被处理时都会调用的双重异常处理函数。\n\n## 双重异常处理函数\n\n双重异常由普通异常和错误码组成，所以我们可以像断点异常处理函数那样定义一个双重异常处理函数。\n\n```rust\n// in src/interrupts.rs\n\nlazy_static! {\n    static ref IDT: InterruptDescriptorTable = {\n        let mut idt = InterruptDescriptorTable::new();\n        idt.breakpoint.set_handler_fn(breakpoint_handler);\n        idt.double_fault.set_handler_fn(double_fault_handler); // new\n        idt\n    };\n}\n\n// new\nextern \"x86-interrupt\" fn double_fault_handler(\n    stack_frame: &mut InterruptStackFrame, _error_code: u64) -> !\n{\n    panic!(\"EXCEPTION: DOUBLE FAULT\\n{:#?}\", stack_frame);\n}\n```\n\n双重异常处理函数打印了一个简短的错误消息和异常栈帧信息。双重异常的错误码通常会是0，所以没有必要打印出来。双重异常处理函数和断点异常处理函数的区别在于，它是一个发散函数（ [*diverging*](https://doc.rust-lang.org/stable/rust-by-example/fn/diverging.html)）。因为 `x86_64` 体系架构不允许从双重异常中返回。\n\n现在启动内核，我们可以看见双重异常处理函数被调用了：\n\n![qemu-catch-double-fault](https://markdown-ngy.oss-cn-beijing.aliyuncs.com/qemu-catch-double-fault.png)\n\n工作正常！这次发生了什么：\n\n1. *CPU* 试图写入非法的内存地址 `0xdeadbeef` ，这会触发缺页异常。\n2. 像上次一样，*CPU* 查找到 *IDT* 中缺页异常对应的条目，并且没有发现对应的处理函数。因为它不能正常调用缺页异常的处理函数，所以触发了双重异常。\n3. *CPU* 跳转到双重异常处理函数——它现在是就绪的了。\n\n因为 *CPU* 现在可以正常调用双重异常处理函数，所以三重异常（和启动循环）不会再次出现。\n\n这非常容易理解！那么我们为什么需要用整篇文章讨论这个话题? 我们现在可以捕获大多数双重异常，但是在某些情况下，现在的方式并不足够有效。\n\n\n\n## 双重异常的触发原因\n\n在探究某个特定的原因之前，我们需要理解双重异常的确切定义。上文中，我们给出了相当粗略的定义：\n\n> 双重异常就是一个在CPU调用异常处理函数失败的时候触发的特定异常。\n\n“调用异常处理函数失败”的准确含义是什么? 处理函数不可用? 处理函数被换出（ [swapped out](http://pages.cs.wisc.edu/~remzi/OSTEP/vm-beyondphys.pdf)）? 并且如果处理函数自身触发了异常会发生什么?\n\n例如，下列情况会发生什么：\n\n1. 断点异常触发，但是对应的处理函数被换出?\n2. 缺页异常触发，但是缺页异常处理函数被换出?\n3. 除0异常引发了断点异常，但是断点异常处理函数被换出?\n4. 内核栈溢出，同时保护页（ *guard page*）被命中（*hit*）? \n\n幸运的是，AMD64手册（([PDF](https://www.amd.com/system/files/TechDocs/24593.pdf)）给出了明确定义（8.2.9章节）。根据手册的定义，“当第二个异常出现在先前的（第一个）异常处理函数执行期间，双重异常**可能**会被触发”。“**可能**”二字说明：只有特定的异常组合才会导致双重异常。这些组合是：\n\n| 第一个异常                                                   | 第二个异常                                                   |\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\n| [Divide-by-zero，除0](https://wiki.osdev.org/Exceptions#Divide-by-zero_Error),<br> [Invalid TSS，非法任务状态段](https://wiki.osdev.org/Exceptions#Invalid_TSS), <br/>[Segment Not Present，段不存在](https://wiki.osdev.org/Exceptions#Segment_Not_Present),<br/> [Stack-Segment Fault，栈段错误](https://wiki.osdev.org/Exceptions#Stack-Segment_Fault), <br/>[General Protection Fault，一般保护错误](https://wiki.osdev.org/Exceptions#General_Protection_Fault) | [Invalid TSS，非法任务状态段](https://wiki.osdev.org/Exceptions#Invalid_TSS), <br/>[Segment Not Present，段不存在](https://wiki.osdev.org/Exceptions#Segment_Not_Present), <br/>[Stack-Segment Fault，栈段错误](https://wiki.osdev.org/Exceptions#Stack-Segment_Fault), <br/>[General Protection Fault，一般保护错误](https://wiki.osdev.org/Exceptions#General_Protection_Fault) |\n| [Page Fault，缺页异常](https://wiki.osdev.org/Exceptions#Page_Fault) | [Page Fault，缺页异常](https://wiki.osdev.org/Exceptions#Page_Fault),<br/> [Invalid TSS，非法任务状态段](https://wiki.osdev.org/Exceptions#Invalid_TSS), <br/>[Segment Not Present，段不存在](https://wiki.osdev.org/Exceptions#Segment_Not_Present),<br/> [Stack-Segment Fault，栈段错误](https://wiki.osdev.org/Exceptions#Stack-Segment_Fault),<br/> [General Protection Fault，一般保护错误](https://wiki.osdev.org/Exceptions#General_Protection_Fault) |\n\n所以缺页异常紧跟除0异常不会触发双重异常（缺页异常处理函数被调用），但是一般保护错误紧跟除0异常一定会触发双重异常。\n\n参考这张表格，可以得到上述前三个问题的答案：\n\n1. 断点异常触发，但是对应的处理函数被换出，缺页异常会被触发，然后调用缺页异常处理函数。\n2. 缺页异常触发，但是缺页异常处理函数被换出，双重异常会被触发，然后调用双重异常处理函数。\n3. 除0异常引发了断点异常，CPU试图调用断点异常处理函数。如果断点异常处理函数被换出，缺页异常会被触发，然后调用缺页异常处理函数。\n\n实际上，异常在 *IDT* 中没有对应的处理函数时会遵顼以下方案：\n\n当异常发生时，*CPU* 试图读取对应的 *IDT* 条目。如果条目是0，说明这不是一个合法的 *IDT* 条目，一般保护错误会被触发。我们没有定义一般保护错误的处理函数，所以另一个一般保护错误被触发。根据上表，这会导致双重异常。\n\n### 内核栈溢出\n\n让我们开始探究第四个问题：\n\n> 内核栈溢出，同时保护页（ *guard page*）被命中（*hit*）? \n\n保护页是存在栈底的特定内存页，它被用来发现栈溢出。保护页没有映射到任何物理内存页，所以访问它会导致缺页异常而不是无声无息地损坏其它内存。引导程序（*bootloader*）为内核栈建立了保护页，所以内核栈溢出会触发缺页异常。\n\n当缺页异常发生，CPU 查找 IDT 中地缺页异常处理函数并将中断栈帧（ [interrupt stack frame](https://os.phil-opp.com/cpu-exceptions/#the-interrupt-stack-frame)）压入内核栈。然而，当前栈指针依然指向不可用地保护页。因此，第二个缺页异常被触发了，这会引发双重异常（根据上表）。\n\nCPU 试图调用双重异常处理函数，它当然会试图压入异常栈帧。此时栈指针依然会指向保护页（因为栈溢出了），所以第三个缺页异常被触发了，紧接着三重异常和系统复位也发生了。当前的双重异常处理函数无法阻止这种情形下的三重异常。\n\n让我们复现这个情形吧！通过调用无穷的递归函数可以轻易引发内核栈溢出：\n\n```rust\n// in src/main.rs\n\n#[no_mangle] // don't mangle the name of this function\npub extern \"C\" fn _start() -> ! {\n    println!(\"Hello World{}\", \"!\");\n\n    blog_os::init();\n\n    fn stack_overflow() {\n        stack_overflow(); // for each recursion, the return address is pushed\n    }\n\n    // trigger a stack overflow\n    stack_overflow();\n\n    […] // test_main(), println(…), and loop {}\n}\n```\n\n在QEMU中执行程序的时候，操作系统再次进入无限重启的情况：\n\n如何阻止这个问题? 由于压入异常栈帧是CPU硬件的操作，所以我们不能干扰这一步。我们只能以某种方式让内核栈在双重异常触发的时候保持可用（不会溢出）。幸运的是，`x86_64` 架构提供了这个问题的解决方式。\n\n## 切换栈\n\n`x86_64` 架构可以在异常发生时切换到预定义且已知良好的栈中。这个切换发生在硬件级别，所以它可以在*CPU*压入异常栈帧之前完成。\n\n切换机制基于中断栈表（ *Interrupt Stack Table* ，*IST*）。*IST*由7个指向已知良好的栈的指针组成。Rust风格的伪代码：\n\n```rust\nstruct InterruptStackTable {\n    stack_pointers: [Option<StackPointer>; 7],\n}\n```\n\n对于每一个异常处理器，我们可以通过对应 [IDT entry](https://os.phil-opp.com/cpu-exceptions/#the-interrupt-descriptor-table) 中的 `stack_pointers`字段在 *IST* 中找到一个栈。例如，双重异常处理器可以使用 *IST* 中的第一个栈。此后，CPU会主动在双重异常发生时切换到这个栈。切换之前不会由任何东西被压入栈中，所以它可以阻止三重异常的发生。\n\n### 中断栈表和任务状态段（ The IST and TSS）\n\n中断栈表是早期遗留下来的结构体——任务状态段（ *[Task State Segment](https://en.wikipedia.org/wiki/Task_state_segment)，TSS*）的一部分。在32位模式下，*TSS* 被用来保存任务（*task*）相关的各种信息（例如寄存器的状态），包括硬件上下文切换（[hardware context switching](https://wiki.osdev.org/Context_Switching#Hardware_Context_Switching)）等。然而，在64位模式下，硬件上下文切换不再被支持，同时 *TSS* 的格式也已经面目全非。\n\n在 `x86_64` 架构下，*TSS* 不再保存任何关于任务（*task*）的信息。取而代之的是两个栈表（ *IST* 是其中之一）。*TSS* 在32位和64位模式下唯一相同的字段是指向 [I/O port permissions bitmap](https://en.wikipedia.org/wiki/Task_state_segment#I.2FO_port_permissions) 的指针。\n\n在64位模式下， *TSS* 的格式如下：\n\n| Field                             | Type       |\n| --------------------------------- | ---------- |\n| (保留位)                          | `u32`      |\n| 特权栈表（Privilege Stack Table） | `[u64; 3]` |\n| (保留位)                          | `u64`      |\n| 中断栈表（Interrupt Stack Table） | `[u64; 7]` |\n| (保留位)                          | `u64`      |\n| (保留位)                          | `u16`      |\n| I/O Map Base Address              | `u16`      |\n\n特权栈表会在 *CPU* 改变特权级别的时候被使用。例如，*CPU* 处在用户模式（*user mode*，特权级别 3 ）时触发了异常，它通常会在调用异常处理函数之前切换到内核模式（*kernel mode*，特权级别 0 ）。在这种情况下，*CPU* 会切换到特权栈表的第0个栈中（因为目标特权级别是0）。我们当前的内核没有运行在用户模式下的程序，所以可以暂时忽略特权栈表。\n\n### 创建任务状态段\n\n为了创建一个在自身的中断栈表中包含不同双重异常栈的 *TSS* ，我们需要一个 *TSS* 结构体。幸运的是， `x86_64` 模块已经提供了 [`TaskStateSegment` 结构体](https://docs.rs/x86_64/0.12.1/x86_64/structures/tss/struct.TaskStateSegment.html) 供我们使用。\n\n我们在新的 `gdt` 模块（下文中解释）中创建 *TSS* 。\n\n```rust\n// in src/lib.rs\n\npub mod gdt;\n\n// in src/gdt.rs\n\nuse x86_64::VirtAddr;\nuse x86_64::structures::tss::TaskStateSegment;\nuse lazy_static::lazy_static;\n\npub const DOUBLE_FAULT_IST_INDEX: u16 = 0;\n\nlazy_static! {\n    static ref TSS: TaskStateSegment = {\n        let mut tss = TaskStateSegment::new();\n        tss.interrupt_stack_table[DOUBLE_FAULT_IST_INDEX as usize] = {\n            const STACK_SIZE: usize = 4096 * 5;\n            static mut STACK: [u8; STACK_SIZE] = [0; STACK_SIZE];\n\n            let stack_start = VirtAddr::from_ptr(unsafe { &STACK });\n            let stack_end = stack_start + STACK_SIZE;\n            stack_end\n        };\n        tss\n    };\n}\n```\n\n由于Rust的常量求值器（ Rust's const evaluator ）并不支持在编译期内完成初始化，所以我们使用了 `lazy_static` 。我们定义了 *IST* 的第0个条目指向双重异常栈（ *IST* 的其它条目也可以正常运行），然后向第0个条目写入了双重异常栈的顶部地址（因为 `x86` 机器的栈地址向下扩展，也就是从高地址到低地址）。\n\n因为我们的内核还没有实现内存管理机制，所以我们还没有一个像样的方式去分配新的栈。作为替代，我们当前使用 `static mut` 数组作为栈的存储。 `unsafe` 是必要的，因为编译器不能确保可变静态变量被访问时的竞争自由。使用 `static mut` 而不是 `static` 是因为 *bootloader* 会把它映射到只读内存页上。下篇文章中，我们会使用一个像样的栈内存分配方式去取代这个方式，那时就不再需要 `unsafe` 了。\n\n不得不提的是，这个双重异常栈没有保护页去避免栈溢出。这意味着我们不能在双重异常处理函数中做任何过度使用函数栈的的事情，以避免栈溢出破坏栈地址以下的内存。\n\n#### 加载 *TSS*\n\n我们需要一种方式让 *CPU* 明白新的 *TSS* 已经可用了。不幸的是，这个过程很复杂，因为 *TSS* 使用了分段系统（历史遗留问题）。既然不能直接加载 *TSS* ，我们需要在全局描述符表（ *[Global Descriptor Table](https://web.archive.org/web/20190217233448/https://www.flingos.co.uk/docs/reference/Global-Descriptor-Table/) ，GDT*）中增加一个段描述符。然后就可以通过各自的 *GDT* 指针调用 [`ltr` 指令](https://www.felixcloutier.com/x86/ltr) 去加载 *TSS* 。\n\n### 全局描述符表（ The Global Descriptor Table，GDT）\n\n全局描述符表是分页机制成为事实上的标准之前的一个古老概念，它被用于内存分段（ [memory segmentation](https://en.wikipedia.org/wiki/X86_memory_segmentation) ）。全局描述符表在64位模式下依然发挥着作用，例如内核/用户模式的配置和 *TSS* 的加载。*GDT* 包含了一个程序的所有分段。在分页机制还没有成为标准的古老体系架构中，*GDT* 被用来隔离所有的程序。你可以检阅开源手册 [“Three Easy Pieces” ](http://pages.cs.wisc.edu/~remzi/OSTEP/) 的同名章节获取更多关于分段机制的信息。虽然64位模式下不再支持分段机制，但是*GDT* 仍然保留了下来。它被用于两件事情：在内核空间和用户空间之间切换，加载 *TSS* 结构体。\n\n#### 创建GDT\n\n创建一个包含用于 `TSS` 静态变量的段的 *GDT* ：\n\n```rust\n// in src/gdt.rs\n\nuse x86_64::structures::gdt::{GlobalDescriptorTable, Descriptor};\n\nlazy_static! {\n    static ref GDT: GlobalDescriptorTable = {\n        let mut gdt = GlobalDescriptorTable::new();\n        gdt.add_entry(Descriptor::kernel_code_segment());\n        gdt.add_entry(Descriptor::tss_segment(&TSS));\n        gdt\n    };\n}\n```\n\n由于Rust的常量求值器（ Rust's const evaluator ）并不支持在编译期内完成初始化，所以我们再次使用了 `lazy_static` 。我们创建了一个包含代码段（code segment）和 *TSS* 段（ *TSS* segment）的 *GDT* 。\n\n#### 加载GDT\n\n通过在 `init` 函数调用新建立的 `gdt::init` 函数加载 *GDT* ：\n\n```rust\n// in src/gdt.rs\n\npub fn init() {\n    GDT.load();\n}\n\n// in src/lib.rs\n\npub fn init() {\n    gdt::init();\n    interrupts::init_idt();\n}\n```\n\n现在 *GDT* 已经加载完毕（因为 `_start` 函数调用了 `init` 函数），但是仍然出现了栈溢出引发的启动循环。\n\n### 最后的步骤\n\n由于段寄存器和 *TSS* 寄存器仍然保存着来自于旧的 *GDT* 的内容，我们新 *GDT* 的分段并没有起作用。所以我们还需要修改双重异常对应的 *IDT* 条目去让它使用新的栈。\n\n总的来说，我们需要完成以下步骤：\n\n1. **重新装载代码段寄存器**：我们修改了 *GDT* ，所以应当重新装载代码段寄存器—— `cs` 。这是必要的，既然现在旧的段选择子可以指向不同的 *GDT* 描述符（例如 *TSS* 描述符）。\n2. **加载 *TSS*** ：我们已经加载了包含 *TSS* 段选择子的 *GDT* ，但是仍然需要告知 *CPU* 使用新的 *TSS* 。\n3. **更新 IDT 条目**：一旦 *TSS* 加载完毕，CPU便访问到了合法的中断栈表（ *IST* ）。然后通过更新双重异常条目告知 *CPU* 使用新的双重异常栈。\n\n第一、二步需要我们在 `gdt::init` 函数中访问 `code_selector` 和 `tss_selector` 变量。为了实现这个操作，我们可以通过一个新的 `Selectors` 结构体将它们包含在 *static* 块中。\n\n```rust\n// in src/gdt.rs\n\nuse x86_64::structures::gdt::SegmentSelector;\n\nlazy_static! {\n    static ref GDT: (GlobalDescriptorTable, Selectors) = {\n        let mut gdt = GlobalDescriptorTable::new();\n        let code_selector = gdt.add_entry(Descriptor::kernel_code_segment());\n        let tss_selector = gdt.add_entry(Descriptor::tss_segment(&TSS));\n        (gdt, Selectors { code_selector, tss_selector })\n    };\n}\n\nstruct Selectors {\n    code_selector: SegmentSelector,\n    tss_selector: SegmentSelector,\n}\n```\n\n现在可以使用选择子（*selectors*）重新加载 `cs` 段寄存器并加载新的 `TSS` ：\n\n```rust\n// in src/gdt.rs\n\npub fn init() {\n    use x86_64::instructions::segmentation::set_cs;\n    use x86_64::instructions::tables::load_tss;\n\n    GDT.0.load();\n    unsafe {\n        set_cs(GDT.1.code_selector);\n        load_tss(GDT.1.tss_selector);\n    }\n}\n```\n\n我们使用 [`set_cs`](https://docs.rs/x86_64/0.12.1/x86_64/instructions/segmentation/fn.set_cs.html) 和 [`load_tss`](https://docs.rs/x86_64/0.12.1/x86_64/instructions/tables/fn.load_tss.html) 函数分别重新加载代码段寄存器和 `TSS` 。我们需要在 `unsafe` 代码块中调用这两个函数，因为它们均被声明为 `unsafe` —— 它们可能由于加载了非法的选择子而破坏内存安全。\n\n现在，合法的 *TSS* 和 中断栈表已经加载完毕，我们可以在 *IDT* 中设置用于双重异常的栈指针：\n\n```rust\n// in src/interrupts.rs\n\nuse crate::gdt;\n\nlazy_static! {\n    static ref IDT: InterruptDescriptorTable = {\n        let mut idt = InterruptDescriptorTable::new();\n        idt.breakpoint.set_handler_fn(breakpoint_handler);\n        unsafe {\n            idt.double_fault.set_handler_fn(double_fault_handler)\n                .set_stack_index(gdt::DOUBLE_FAULT_IST_INDEX); // new\n        }\n\n        idt\n    };\n}\n```\n\n `set_stack_index` 方法是不安全的，因为调用者必须保证使用的指针是合法的并且没有被用于其它异常。\n\nThat's it!  *CPU* 会在所有双重异常发生的时候切换到双重异常栈。因此，我们可以捕获所有双重异常——包括在内核栈溢出的情况中。\n\n![qemu-double-fault-on-stack-overflow](https://markdown-ngy.oss-cn-beijing.aliyuncs.com/qemu-double-fault-on-stack-overflow.png)\n\n从现在起，三重异常永远不会再次出现了！为了确保不会意外地弄坏上面的程序，我们应该加上测试。\n\n## 栈溢出测试\n\n为了测试新的 `gdt` 模块并且确保在栈溢出的情况下，双重异常处理函数被正确的调用，我们可以增加一个集成测试。思路是在测试函数中触发一个双重异常并验证双重异常处理函数被调用。\n\n从最小可用版本开始：\n\n```rust\n// in tests/stack_overflow.rs\n\n#![no_std]\n#![no_main]\n\nuse core::panic::PanicInfo;\n\n#[no_mangle]\npub extern \"C\" fn _start() -> ! {\n    unimplemented!();\n}\n\n#[panic_handler]\nfn panic(info: &PanicInfo) -> ! {\n    blog_os::test_panic_handler(info)\n}\n```\n\n类似于 `panic_handler` 测试，新的测试不会运行在测试环境下（ [without a test harness](https://os.phil-opp.com/testing/#no-harness-tests)）。原因在于我们不能在双重异常之后继续执行，所以连续进行多个测试是行不通的。为了禁用测试环境，需要在 `Cargo.toml` 中增加以下配置：\n\n```rust\n# in Cargo.toml\n\n[[test]]\nname = \"stack_overflow\"\nharness = false\n```\n\n现在，执行 `cargo test --test stack_overflow` 会编译成功。测试当然会由于 `unimplemented` 宏的崩溃（panics）而失败。\n\n### 实现 `_start`\n\n `_start` 函数的实现如下所示：\n\n```rust\n// in tests/stack_overflow.rs\n\nuse blog_os::serial_print;\n\n#[no_mangle]\npub extern \"C\" fn _start() -> ! {\n    serial_print!(\"stack_overflow::stack_overflow...\\t\");\n\n    blog_os::gdt::init();\n    init_test_idt();\n\n    // trigger a stack overflow\n    stack_overflow();\n\n    panic!(\"Execution continued after stack overflow\");\n}\n\n#[allow(unconditional_recursion)]\nfn stack_overflow() {\n    stack_overflow(); // for each recursion, the return address is pushed\n    volatile::Volatile::new(0).read(); // prevent tail recursion optimizations\n}\n```\n\n调用 `gdt::init` 函数初始化新的 *GDT* 。我们调用了 `init_test_idt` 函数（稍后会解释它）而不是 `interrupts::init_idt` 函数。原因在于我们希望注册一个自定义的双重异常处理函数执行`exit_qemu(QemuExitCode::Success) ` 而不是直接崩溃（ *panicking*）。\n\n `stack_overflow` 函数和 `main.rs` 中的函数几乎一致。唯一的不同是我们在函数末尾增加了额外的 [volatile](https://en.wikipedia.org/wiki/Volatile_(computer_programming)) 读，这是使用 [`Volatile`](https://docs.rs/volatile/0.2.6/volatile/struct.Volatile.html) 类型阻止编译器的尾调用优化（ [*tail call elimination*](https://en.wikipedia.org/wiki/Tail_call)）。此外，这个优化允许编译器将递归函数转化为循环。因此，函数调用的时候不会有额外的栈帧产生，栈的使用是固定不变的（*译注：上文中提到这个双重异常栈没有保护页去避免栈溢出。如果在双重异常处理函数中做任何过度使用函数栈的的事情，会导致栈溢出破坏栈地址以下的内存*）。\n\n在测试场景中，我们希望栈溢出的发生，所以在函数的末尾增加了一个模拟的 *volatile* 读语句，这个语句不会被编译器优化掉。因此，这个函数不再是尾递归，也不会被转化为循环。我们同时使用 `allow(unconditional_recursion)` 属性禁止了编译器的警告——这个函数会无休止地重复。\n\n### 测试用IDT\n\n如上所述，这个测试需要独立持有双重异常处理函数的 *IDT* 。实现如下：\n\n```rust\n// in tests/stack_overflow.rs\n\nuse lazy_static::lazy_static;\nuse x86_64::structures::idt::InterruptDescriptorTable;\n\nlazy_static! {\n    static ref TEST_IDT: InterruptDescriptorTable = {\n        let mut idt = InterruptDescriptorTable::new();\n        unsafe {\n            idt.double_fault\n                .set_handler_fn(test_double_fault_handler)\n                .set_stack_index(blog_os::gdt::DOUBLE_FAULT_IST_INDEX);\n        }\n\n        idt\n    };\n}\n\npub fn init_test_idt() {\n    TEST_IDT.load();\n}\n```\n\n这个实现和 `interrupts.rs` 中普通的 *IDT* 非常相似。和在普通的 *IDT* 中一样，我们在 *IST* 中将双重异常处理函数设置为独立的栈。 `init_test_idt` 函数通过 `load` 方法加载 *IDT* 到CPU中。\n\n### 双重异常处理函数\n\n现在唯一缺少的便是双重异常处理函数了。实现如下：\n\n```rust\n// in tests/stack_overflow.rs\n\nuse blog_os::{exit_qemu, QemuExitCode, serial_println};\nuse x86_64::structures::idt::InterruptStackFrame;\n\nextern \"x86-interrupt\" fn test_double_fault_handler(\n    _stack_frame: &mut InterruptStackFrame,\n    _error_code: u64,\n) -> ! {\n    serial_println!(\"[ok]\");\n    exit_qemu(QemuExitCode::Success);\n    loop {}\n}\n```\n\n当双重异常处理函数被调用，我们退出*QEMU*，并且退出码是代表着测试通过的成功退出码。随着集成测试各自独立地执行完毕，我们需要在测试文件的顶部再次设置 `#![feature(abi_x86_interrupt)]` 属性。\n\n现在可以使用 `cargo test --test stack_overflow`命令运行双重异常测试了（或者使用 `cargo test` 直接运行所有测试）。不出所料，控制台输出了 `stack_overflow... [ok]` 消息。如果注释掉 `set_stack_index` 行：测试应当失败。\n\n## 总结\n\n在这篇文章中，我们学到了双重异常及其触发条件，添加了基本的双重异常处理函数打印错误消息，同时补充了相应的集成测试。\n\n我们也让硬件支持了双重异常发生时的栈切换，这让它可以在栈溢出的情况下正常工作。在实现的同时，我们学到了任务状态段（*TSS*），包含其中的中断栈表（*IST*），以及旧体系架构中用于分段机制的全局描述符（*GDT*）。\n\n## 接下来?\n\n下一篇文章，我们将阐明如何处理来自外部设备的中断，例如时钟、键盘或网卡等。这些硬件中断和异常十分相似，它们也会通过 *IDT* 分发到相应的处理函数。然而与异常不同的是，它们并不直接由 *CPU* 内部产生。中断控制器（*interrupt controller*）会汇总这些中断，然后根据它们的优先级高低发送到 *CPU* 。在下篇文章中，我们会介绍 [Intel 8259](https://en.wikipedia.org/wiki/Intel_8259) (“PIC”) 中断控制器，并学习如何实现键盘支持（*keyboard support*）。\n\n## 支持我\n\n创建并维护这个[博客](https://os.phil-opp.com/status-update/) 和相关的库是一个繁重的工作，但是我非常喜欢这个它。你的支持可以鼓励我投入更多的时间在新的内容，新的功能以及持续维护工作上。\n\n支持我的最好方式是 [*sponsor me on GitHub*](https://github.com/sponsors/phil-opp) 。GitHub 会匹配赞助（*译注：见[GitHub Sponsors Matching Fund](https://docs.github.com/en/free-pro-team@latest/github/supporting-the-open-source-community-with-github-sponsors/about-github-sponsors)*）直到2020年10月！我同时拥有 [*Patreon*](https://www.patreon.com/phil_opp) 和 [*Donorbox*](https://donorbox.org/phil-opp) 账户。最后一种是最灵活的，它支持多国货币和一次性捐赠。\n\n谢谢！\n\n> 译注：《支持我》章节中的“我”均指原作者 [@Philipp Oppermann](https://github.com/phil-opp) 。\n\n"
        },
        {
          "name": "07-hardware-interrupts.md",
          "type": "blob",
          "size": 33.9482421875,
          "content": "> 原文：https://os.phil-opp.com/hardware-interrupts/\n>\n> 原作者：@phil-opp\n>\n> 译者：尚卓燃（@psiace） 华中农业大学\n\n# 使用Rust编写操作系统（七）：硬件中断\n\n在这一章中，我们将会学习如何设置可编程中断控制器（Programmable Interrupt Controller，PIC），以将硬件中断正确转发到 CPU 。为了处理这些中断，需要向中断描述符表（Interrupt Descriptor Table，IDT）中添加新的表项，就像我们实现异常处理程序那样。通过对这一章的学习，你会了解到如何获取周期性定时器中断以及键盘输入。\n\n## 简介\n\n中断为外部硬件设备提供了向 CPU 发送通知的方法。这样一来，内核就不必定期检查键盘上是否有新字符产生（这一过程称作「[轮询]」），而是由键盘在出现按键事件时通知内核。采用这种方法有两个好处：一是中断处理更高效，因为内核只需要在硬件触发中断后进行响应；二是响应时间更短，因为内核可以即时作出响应，而不是在下一次轮询中进行处理。\n\n[轮询]: https://en.wikipedia.org/wiki/Polling_(computer_science)\n\n要将所有硬件设备都与 CPU 直接连接是不现实的。替代办法是使用一个单独的「中断控制器」（Interrupt Controller）来聚合所有中断，然后再通知 CPU ：\n\n```text\n                                     ____________             _____\n               定时器 ------------> |            |           |     |\n               键盘 --------------> | 中断控制器 |---------> | CPU |\n               其他硬件 ----------> |            |           |_____|\n               更多... -----------> |____________|\n\n```\n\n大多数中断控制器都是可编程的，这意味着它们支持为中断分配不同的优先级。举个例子：如果需要保证计时准确，我们可以为定时器中断设置比键盘中断更高的优先级。\n\n与异常不同的是，硬件中断是异步（Asynchronously）发生的。这意味着它们完全独立于执行的代码，并且可能在任何时候发生。因此，内核中就突然出现了一种并发形式，而且我们也不得不面对所有与并发相关的潜在错误。Rust 严格的所有权模型会为我们提供一定帮助，因为它禁止使用可变的全局状态。然而，死锁仍然可能发生，我们在后面也会遇到这种情况。\n\n## 8259 可编程中断控制器\n\n[Intel 8259] 是一款在 1976 年推出的可编程中断控制器（PIC）。早已被新的「[高级可编程中断控制器（APIC）]」所取代，但由于 APIC 保持了较好的向后兼容，所以它的接口仍然在当前系统上得到较好的支持。8259 PIC 比 APIC 更容易设置，所以在我们切换到 APIC 之前，将先使用它来介绍中断。\n\n[高级可编程中断控制器（APIC）]: https://en.wikipedia.org/wiki/Intel_APIC_Architecture\n\n8259 有 8 条中断控制线和几条与 CPU 通信的线。当时的典型系统配备了一主一从两个 8259 PIC 实例，其中从控制器连接到主控制器的一条中断控制线上。\n\n[intel 8259]: https://en.wikipedia.org/wiki/Intel_8259\n\n```text\n                     ____________                          ____________\n实时时钟 ---------> |            |   定时器 ------------> |            |\nACPI -------------> |            |   键盘 --------------> |            |      _____\n可用 -------------> |            |----------------------> |            |     |     |\n可用 -------------> | 从中断     |   串行端口 2 --------> | 主中断     |---> | CPU |\n鼠标 -------------> |     控制器 |   串行端口 1 --------> |     控制器 |     |_____|\n协处理器 ---------> |            |   并行端口 2/3 ------> |            |\n主 ATA -----------> |            |   软盘 --------------> |            |\n次 ATA -----------> |____________|   并行端口 1 --------> |____________|\n\n```\n\n上图显示了中断控制线的经典分配方案。我们看到剩下 15 条线中的大多数都对应有一个固定的映射，例如从中断控制器的第 4 条中断控制线被分配给了鼠标。\n\n每个控制器可以通过两个 [I/O 端口] 进行配置，其中一个是「命令」端口，另一个是「数据」端口。 在主控制器中，这两个端口分别位于 0x20（命令）和 0x21（数据）。 而在从控制器中，分别是 0xa0（命令）和 0xa1（数据）。 如果你想要了解关于「如何配置可编程中断控制器」的更多信息，可以参考 [osdev.org 上的文章]。\n\n[I/O 端口]: ./04-testing.md#IO-端口\n[osdev.org 上的文章]: https://wiki.osdev.org/8259_PIC\n\n### 实现\n\n不能使用默认的 PIC 配置，因为它将会向 CPU 发送 0-15 范围内的中断类型码。而这些数字已经被 CPU 异常占用了，例如数字 8 对应二重错误。为了解决此重叠问题，我们需要将中断重新映射到不同的中断类型码。实际范围并不重要，只要不与异常重叠就可以，但通常会选择范围 32-47 的数字，因为这是 32 个异常槽之后的第一组空闲数字。\n\n配置是通过向 PIC 的命令和数据端口写入特殊值来完成的。幸运的是，已经有一个名为 [`pic8259_simple`] 的包，所以我们不需要自己编写初始化序列。如果您对它的工作原理感兴趣，请查看 [它的源代码][pic crate source] ，它相当小并且有齐全的文档说明。\n\n[pic crate source]: https://docs.rs/crate/pic8259_simple/0.1.1/source/src/lib.rs\n\n要将包添加为依赖项，我们需要将以下内容添加到项目中:\n\n[`pic8259_simple`]: https://docs.rs/pic8259_simple/0.1.1/pic8259_simple/\n\n```toml\n# in Cargo.toml\n\n[dependencies]\npic8259 = \"0.10.0\"\n```\n\n这个包提供的主要抽象是 [`ChainedPics`] 结构，它表示我们上面看到的「主/从二级可编程中断控制器」布局。基于它的设计，我们可以按以下方式来使用它：\n\n[`ChainedPics`]: https://docs.rs/pic8259_simple/0.1.1/pic8259_simple/struct.ChainedPics.html\n\n```rust\n// in src/interrupts.rs\n\nuse pic8259::ChainedPics;\nuse spin;\n\npub const PIC_1_OFFSET: u8 = 32;\npub const PIC_2_OFFSET: u8 = PIC_1_OFFSET + 8;\n\npub static PICS: spin::Mutex<ChainedPics> =\n    spin::Mutex::new(unsafe { ChainedPics::new(PIC_1_OFFSET, PIC_2_OFFSET) });\n```\n\n就像在前面提过的那样，我们将会为 PIC 设置偏移量，使得中断类型码范围为 32-47 。 通过用 `Mutex` 包装 `ChainedPics` 结构，能够获得安全的可变访问（通过 [`lock` 方法][spin mutex lock]），这是下一步所需要的。`ChainedPics::new` 函数不安全，因为错误的偏移量可能会导致未定义行为。\n\n[spin mutex lock]: https://docs.rs/spin/0.5.2/spin/struct.Mutex.html#method.lock\n\n现在我们可以在 `init` 函数中初始化 8259 PIC：\n\n```rust\n// in src/lib.rs\n\npub fn init() {\n    gdt::init();\n    interrupts::init_idt();\n    unsafe { interrupts::PICS.lock().initialize() }; // new\n}\n```\n\n我们使用 [`initialize`] 函数来执行 PIC 的初始化。 像 `ChainedPics::new` 函数一样，这个函数也不安全，因为如果 PIC 配置错误，它可能导致未定义行为。\n\n[`initialize`]: https://docs.rs/pic8259_simple/0.1.1/pic8259_simple/struct.ChainedPics.html#method.initialize\n\n如果一切顺利，我们应该在执行 `cargo xrun` 时继续看到「It did not crash」这条消息。\n\n## 启用中断\n\n到目前为止，什么都没有发生，因为 CPU 配置中仍然禁用了中断。 这意味着 CPU 根本没有侦听中断控制器，因此没有中断可以到达 CPU。让我们试着改变这一点:\n\n```rust\n// in src/lib.rs\n\npub fn init() {\n    gdt::init();\n    interrupts::init_idt();\n    unsafe { interrupts::PICS.lock().initialize() };\n    x86_64::instructions::interrupts::enable();     // new\n}\n```\n\n`x86_64` 包的 `interrupts::enable` 函数执行特殊的 `sti` 指令（设置中断「set interrupts」）以启用外部中断。现在尝试运行 `cargo xrun` 命令，我们会看到发生双重错误：\n\n![QEMU printing `EXCEPTION: DOUBLE FAULT` because of hardware timer](https://os.phil-opp.com/hardware-interrupts/qemu-hardware-timer-double-fault.png)\n\n出现这种双重错误的原因是硬件定时器（确切地说是 [Intel 8253]）被设置为默认启用，一旦启用中断，我们就会开始接收定时器中断。 由于我们还没有为它定义中断处理程序，因此就会调用双重错误处理程序。\n\n[intel 8253]: https://en.wikipedia.org/wiki/Intel_8253\n\n## 处理定时器中断\n\n如 [上文](#8259-可编程中断控制器) 中的图例所示，定时器使用了主 PIC 的第 0 条中断控制线。 这意味着中断会以中断类型码 32（ 0 + 偏移量 32 ）的形式到达 CPU。 我们不会对索引 32 进行硬编码，而是将它存储在枚举结构（enum） `InterruptIndex` 中：\n\n```rust\n// in src/interrupts.rs\n\n#[derive(Debug, Clone, Copy)]\n#[repr(u8)]\npub enum InterruptIndex {\n    Timer = PIC_1_OFFSET,\n}\n\nimpl InterruptIndex {\n    fn as_u8(self) -> u8 {\n        self as u8\n    }\n\n    fn as_usize(self) -> usize {\n        usize::from(self.as_u8())\n    }\n}\n```\n\nRust 中的枚举是 [c-like 风格的枚举]，因此我们可以直接为其内的每个变体指定索引。 `repr(u8)` 属性指定每个变体都以 `u8` 类型表示。 接下来，我们将会为其他中断添加更多的变体。\n\n[c-like 风格的枚举]: https://doc.rust-lang.org/reference/items/enumerations.html#custom-discriminant-values-for-field-less-enumerations\n\n现在我们可以为定时器中断添加一个处理函数：\n\n```rust\n// in src/interrupts.rs\n\nuse crate::print;\n\nlazy_static! {\n    static ref IDT: InterruptDescriptorTable = {\n        let mut idt = InterruptDescriptorTable::new();\n        idt.breakpoint.set_handler_fn(breakpoint_handler);\n        […]\n        idt[InterruptIndex::Timer.as_usize()]\n            .set_handler_fn(timer_interrupt_handler); // new\n\n        idt\n    };\n}\n\nextern \"x86-interrupt\" fn timer_interrupt_handler(\n    _stack_frame: &mut InterruptStackFrame)\n{\n    print!(\".\");\n}\n```\n\n定时器中断处理程序 `timer_interrupt_handler` 具有与异常处理程序相同的函数签名，因为 CPU 对异常和外部中断的反应是相同的（唯一的区别是有些异常会返回错误代码）。 [`InterruptDescriptorTable`] 结构实现了 [`IndexMut`] 特质（trait），因此我们可以通过数组索引语法访问单个表项。\n\n[`interruptdescriptortable`]: https://docs.rs/x86_64/0.8.1/x86_64/structures/idt/struct.InterruptDescriptorTable.html\n[`indexmut`]: https://doc.rust-lang.org/core/ops/trait.IndexMut.html\n\n定时器定时器中断处理程序将会在屏幕上输出一个点 `'.'`。由于定时器中断周期性地发生，我们期望看到每当定时器「滴答」一下就输出一个点。但是，当我们运行程序时，屏幕上只输出了一个点:\n\n![QEMU printing only a single dot for hardware timer](https://os.phil-opp.com/hardware-interrupts/qemu-single-dot-printed.png)\n\n### 中断结束\n\n之所以出现上面的故障，是因为 PIC 期望从错误处理程序得到一个明确的「中断结束」（End of Interrupt，EOI）信号。 这个信号告诉控制器：中断已经被处理，并且系统已经准备好接收下一个中断。 所以 PIC 认为系统仍然忙于处理第一个定时器中断，并在发送下一个中断之前耐心地等待 EOI 信号。\n\n为了发送 EOI ，我们再次使用静态结构 `PICS` ：\n\n```rust\n// in src/interrupts.rs\n\nextern \"x86-interrupt\" fn timer_interrupt_handler(\n    _stack_frame: &mut InterruptStackFrame)\n{\n    print!(\".\");\n\n    unsafe {\n        PICS.lock()\n            .notify_end_of_interrupt(InterruptIndex::Timer.as_u8());\n    }\n}\n```\n\n通知中断结束函数 `notify_end_of_interrupt` 将会指出主控制器或从控制器是否发送中断，然后使用 `命令` 和 `数据` 端口向各控制器发送相应的 EOI 信号。 如果从 PIC 发送了中断，那么需要通知两个 PIC ，因为从 PIC 与主 PIC 的一条输入线相连。\n\n我们需要谨慎地使用正确的中断类型码，否则可能会意外地删除重要的未发送中断或导致我们的系统挂起。这也是该函数不安全的原因。\n\n现在执行 `cargo xrun` ，我们会看到一些点周期性地出现在屏幕上:\n\n![QEMU printing consecutive dots showing the hardware timer](https://os.phil-opp.com/hardware-interrupts/qemu-hardware-timer-dots.gif)\n\n### 配置定时器\n\n我们使用的硬件定时器是可编程间隔定时器（Progammable Interval Timer, PIT）。 顾名思义，可以配置两个中断之间的间隔。我们不会详细介绍这些，因为我们很快就会切换到 [APIC 定时器]，但是 OSDev wiki 上有一篇详细的关于「[如何配置 PIT ]」的文章。\n\n[APIC 定时器]: https://wiki.osdev.org/APIC_timer\n[如何配置 PIT ]: https://wiki.osdev.org/Programmable_Interval_Timer\n\n## 死锁\n\n现在内核中存在一种并发的情形：定时器中断是异步发生的，因此它们可以随时中断我们的 `_start` 函数。 幸运的是，Rust 的所有权系统可以在编译时防止许多种类型的与并发相关的错误。 但死锁是一个值得注意的例外。 如果一个线程试图获取一个永远不会释放的锁，就会发生死锁。 这样，线程将会无限期地处于挂起状态。\n\n当前我们的内核中已经可以引发死锁。请注意，我们的 `println` 宏调用 `vga_buffer::_print` 函数，它使用自旋锁来[锁定一个全局的 WRITER 类][vga spinlock]：\n\n[vga spinlock]: ./03-vga-text-mode.md#自旋锁\n\n```rust\n// in src/vga_buffer.rs\n\n[…]\n\n#[doc(hidden)]\npub fn _print(args: fmt::Arguments) {\n    use core::fmt::Write;\n    WRITER.lock().write_fmt(args).unwrap();\n}\n```\n\n它锁定 `WRITER`，调用 `write_fmt`，并在函数的末尾隐式地解锁。现在，我们设想一下，如果在 `WRITER` 被锁定时触发一个中断，同时相应的中断处理程序也试图打印一些东西：\n\n| 时间       | \\_start               | interrupt_handler                       |\n| ---------- | --------------------- | --------------------------------------- |\n| 0          | 调用 `println!`       | &nbsp;                                  |\n| 1          | `print` 锁定 `WRITER` | &nbsp;                                  |\n| 2          |                       | **中断发生**，处理程序开始运行          |\n| 3          |                       | 调用 `println!`                         |\n| 4          |                       | `print` 尝试锁定 `WRITER`（已经被锁定） |\n| 5          |                       | `print` 尝试锁定 `WRITER`（已经被锁定） |\n| …          |                       | …                                       |\n| _无法发生_ | _解锁 `WRITER`_       |                                         |\n\n由于 `WRITER` 已经被锁定，所以中断处理程序将会一直等待，直到它被释放。但这种情况永远不会发生，因为 `_start` 函数只有在中断处理程序返回后才继续运行。因此，整个系统就会挂起。\n\n### 引发死锁\n\n通过在 `_start` 函数末尾的循环中打印一些内容，我们很容易在内核中引发这样的死锁:\n\n```rust\n// in src/main.rs\n\n#[no_mangle]\npub extern \"C\" fn _start() -> ! {\n    […]\n    loop {\n        use blog_os::print;\n        print!(\"-\");        // new\n    }\n}\n```\n\n当我们在 QEMU 中运行它时，得到的输出如下:\n\n![QEMU output with many rows of hyphens and no dots](https://os.phil-opp.com/hardware-interrupts/qemu-deadlock.png)\n\n只有有限数量的连字符 `'-'` 被打印，直到第一次定时器中断发生。接着系统挂起，因为定时器中断处理程序试图打印点时引发了死锁。这就是为什么我们在上面的输出中看不到任何点的原因。\n\n由于定时器中断是异步发生的，因此连字符的实际数量在两次运行之间会有所不同。这种不确定性使得与并发相关的错误很难调试。\n\n### 修复死锁\n\n为了避免这种死锁，我们可以采取这样的方案：只要互斥锁 `Mutex` 是锁定的，就可以禁用中断。\n\n```rust\n// in src/vga_buffer.rs\n\n/// Prints the given formatted string to the VGA text buffer\n/// through the global `WRITER` instance.\n#[doc(hidden)]\npub fn _print(args: fmt::Arguments) {\n    use core::fmt::Write;\n    use x86_64::instructions::interrupts;   // new\n\n    interrupts::without_interrupts(|| {     // new\n        WRITER.lock().write_fmt(args).unwrap();\n    });\n}\n```\n\n[`without_interrupts`] 函数接受一个 [闭包（closure）]，并在无中断的环境中执行。我们使用它来确保只要 `Mutex` 处于锁定状态，就不会发生中断。现在运行内核，就可以看到它一直运行而不会挂起。（我们仍然无法看到任何点，但这是因为他们滚动过快。尝试减慢打印速度，例如在循环中加上 `for _ in 0..10000 {}`）。\n\n[`without_interrupts`]: https://docs.rs/x86_64/0.8.1/x86_64/instructions/interrupts/fn.without_interrupts.html\n[闭包（closure）]: https://doc.rust-lang.org/book/second-edition/ch13-01-closures.html\n\n我们可以对串行打印函数进行相同的更改，以确保它不会发生死锁：\n\n```rust\n// in src/serial.rs\n\n#[doc(hidden)]\npub fn _print(args: ::core::fmt::Arguments) {\n    use core::fmt::Write;\n    use x86_64::instructions::interrupts;       // new\n\n    interrupts::without_interrupts(|| {         // new\n        SERIAL1\n            .lock()\n            .write_fmt(args)\n            .expect(\"Printing to serial failed\");\n    });\n}\n```\n\n值得注意的是，禁用中断不应该成为一种通用的解决方案。这一方案的弊端是，它会延长最坏情况下的中断等待时间，也就是系统对中断做出反应之前的时间。 因此，应该只在非常短的时间内禁用中断。\n\n## 修复竞争条件\n\n如果你运行 `cargo xtest`，可能会看到 `test_println_output` 测试失败:\n\n```shell\n> cargo xtest --lib\n[…]\nRunning 4 tests\ntest_breakpoint_exception...[ok]\ntest_println... [ok]\ntest_println_many... [ok]\ntest_println_output... [failed]\n\nError: panicked at 'assertion failed: `(left == right)`\n  left: `'.'`,\n right: `'S'`', src/vga_buffer.rs:205:9\n```\n\n这是由测试和定时器处理程序之间的竞争条件导致的。测试程序是这样的：\n\n```rust\n// in src/vga_buffer.rs\n\n#[test_case]\nfn test_println_output() {\n    serial_print!(\"test_println_output... \");\n\n    let s = \"Some test string that fits on a single line\";\n    println!(\"{}\", s);\n    for (i, c) in s.chars().enumerate() {\n        let screen_char = WRITER.lock().buffer.chars[BUFFER_HEIGHT - 2][i].read();\n        assert_eq!(char::from(screen_char.ascii_character), c);\n    }\n\n    serial_println!(\"[ok]\");\n}\n```\n\n测试将一个字符串打印到 VGA 缓冲区，然后通过在缓冲区字符数组 `buffer_chars` 上手动迭代来检查输出。 出现竞争条件是因为定时器中断处理程序可能在 `println` 和读取屏幕字符之间运行。注意，这不是危险的 **数据竞争**，Rust 在编译时完全避免了这种竞争。 更多详细信息，可以参考 [_Rustonomicon_][nomicon-races] 。\n\n[nomicon-races]: https://doc.rust-lang.org/nomicon/races.html\n\n要解决这个问题，我们需要在测试的整个持续时间内保持对 `WRITER` 的锁定状态，这样定时器处理程序就不能在操作之间将 `.` 写入屏幕。修复后的测试看起来像这样：\n\n```rust\n// in src/vga_buffer.rs\n\n#[test_case]\nfn test_println_output() {\n    use core::fmt::Write;\n    use x86_64::instructions::interrupts;\n\n    serial_print!(\"test_println_output... \");\n\n    let s = \"Some test string that fits on a single line\";\n    interrupts::without_interrupts(|| {\n        let mut writer = WRITER.lock();\n        writeln!(writer, \"\\n{}\", s).expect(\"writeln failed\");\n        for (i, c) in s.chars().enumerate() {\n            let screen_char = writer.buffer.chars[BUFFER_HEIGHT - 2][i].read();\n            assert_eq!(char::from(screen_char.ascii_character), c);\n        }\n    });\n\n    serial_println!(\"[ok]\");\n}\n```\n\n我们做了下述改动：\n\n- 显式地使用 `lock()` 方法来保证 `writer` 在整个测试期间都处于锁定状态。使用 [`writeln`] 宏替代 `println` ，这将会允许打印字符到已锁定的 `writer` 中。\n- 为避免再次出现死锁，我们在测试期间禁用中断。 否则，在 `writer` 仍然处于锁定状态时，测试可能会中断。\n- 由于计时器中断处理程序仍然可以在测试之前运行，因此我们在打印字符串 `s` 之前再打印一个换行符 `'\\n'` 。这样可以避免因计时器处理程序已经将一些 `'.'` 字符打印到当前行而引起的测试失败。\n\n[`writeln`]: https://doc.rust-lang.org/core/macro.writeln.html\n\n经过修改后，`cargo xtest` 现在确实又成功了。\n\n这是一个相对无害的竞争条件，它只会导致测试失败。可以想象，由于其他竞争条件的不确定性，它们的调试可能更加困难。幸运的是，Rust 防止了数据竞争的出现，这是最严重的竞争条件，因为它们可以导致各种各样的未定义行为，包括系统崩溃和静默内存损坏。\n\n## `hlt` 指令\n\n到目前为止，我们在 `_start` 和 `panic` 函数的末尾使用了一个简单的空循环语句。这将导致 CPU 无休止地自旋，从而按预期工作。但是这种方法也是非常低效的，因为即使在没有任何工作要做的情况下，CPU 仍然会继续全速运行。在运行内核时，您可以在任务管理器中看到这个问题: QEMU 进程在整个过程中都需要接近 100% 的 CPU。\n\n我们真正想做的是让 CPU 停下来，直到下一个中断到达。这允许 CPU 进入休眠状态，在这种状态下它消耗的能量要少得多。[`hlt` 指令] 正是为此而生。让我们使用它来创建一个节能的无限循环：\n\n[`hlt` 指令]: https://en.wikipedia.org/wiki/HLT_(x86_instruction)\n\n```rust\n// in src/lib.rs\n\npub fn hlt_loop() -> ! {\n    loop {\n        x86_64::instructions::hlt();\n    }\n}\n```\n\n`instructions::hlt` 函数只是汇编指令的 [瘦包装]。这是安全的，因为它不可能危及内存安全。\n\n[瘦包装]: https://github.com/rust-osdev/x86_64/blob/5e8e218381c5205f5777cb50da3ecac5d7e3b1ab/src/instructions/mod.rs#L16-L22\n\n现在，我们可以使用 `hlt_loop` 循环来代替 `_start` 和 `panic` 函数中的无限循环：\n\n```rust\n// in src/main.rs\n\n#[no_mangle]\npub extern \"C\" fn _start() -> ! {\n    […]\n\n    println!(\"It did not crash!\");\n    blog_os::hlt_loop();            // new\n}\n\n\n#[cfg(not(test))]\n#[panic_handler]\nfn panic(info: &PanicInfo) -> ! {\n    println!(\"{}\", info);\n    blog_os::hlt_loop();            // new\n}\n\n```\n\n让我们也更新一下 `lib.rs`：\n\n```rust\n// in src/lib.rs\n\n/// Entry point for `cargo xtest`\n#[cfg(test)]\n#[no_mangle]\npub extern \"C\" fn _start() -> ! {\n    init();\n    test_main();\n    hlt_loop();         // new\n}\n\npub fn test_panic_handler(info: &PanicInfo) -> ! {\n    serial_println!(\"[failed]\\n\");\n    serial_println!(\"Error: {}\\n\", info);\n    exit_qemu(QemuExitCode::Failed);\n    hlt_loop();         // new\n}\n```\n\n现在，用 QEMU 运行内核，我们会发现 CPU 使用率大大降低。\n\n## 键盘输入\n\n现在已经能够处理来自外部设备的中断，我们终于可以添加对键盘输入的支持。 这将是我们与内核进行的第一次交互。\n\n> 注意，这里只描述如何处理 [PS/2] 键盘，而不包括 USB 键盘。然而，主板会将 USB 键盘模拟为 PS/2 设备，以支持旧的软件，所以可以放心地忽略 USB 键盘，直到内核中有 USB 支持为止。\n\n[PS/2]: https://en.wikipedia.org/wiki/PS/2_port\n\n与硬件定时器一样，键盘控制器也被设置为默认启用。因此，当你按下一个键时，键盘控制器会向 PIC 发送一个中断，然后由 PIC 将中断转发给 CPU 。CPU 在 IDT 中查找处理程序函数，但是相应的表项是空的。所以会引发双重错误。\n\n那么，让我们为键盘中断添加一个处理程序函数。它和我们定义的定时器中断处理程序非常相似，只是使用了一个不同的中断类型码：\n\n```rust\n// in src/interrupts.rs\n\n#[derive(Debug, Clone, Copy)]\n#[repr(u8)]\npub enum InterruptIndex {\n    Timer = PIC_1_OFFSET,\n    Keyboard, // new\n}\n\nlazy_static! {\n    static ref IDT: InterruptDescriptorTable = {\n        let mut idt = InterruptDescriptorTable::new();\n        idt.breakpoint.set_handler_fn(breakpoint_handler);\n        […]\n        // new\n        idt[InterruptIndex::Keyboard.as_usize()]\n            .set_handler_fn(keyboard_interrupt_handler);\n\n        idt\n    };\n}\n\nextern \"x86-interrupt\" fn keyboard_interrupt_handler(\n    _stack_frame: &mut InterruptStackFrame)\n{\n    print!(\"k\");\n\n    unsafe {\n        PICS.lock()\n            .notify_end_of_interrupt(InterruptIndex::Keyboard.as_u8());\n    }\n}\n```\n\n如 [上文](#8259-可编程中断控制器) 中的图例所示，键盘使用了主 PIC 的第 1 条中断控制线。这意味着中断会以中断类型码 33（ 1 + 偏移量 32 ）的形式到达 CPU 。我们将这个索引作为新的 `Keyboard` 变体添加到 `InterruptIndex` 枚举中。 我们不需要显式指定这个值，因为它默认为前一个值加 1 ，也就是 33 。 在中断处理程序中，我们输出一个 `k` 并将中断结束信号发送给中断控制器。\n\n现在看到，当我们按下一个键时，屏幕上会出现一个 `k` 。 然而，这只适用于按下的第一个键，即使我们继续按键，也不会有更多的 `k` 出现在屏幕上。 这是因为键盘控制器在我们读取所谓的「键盘扫描码（scancode）」之前不会发送另一个中断。\n\n### 读取键盘扫描码\n\n要找出按了 _哪个_ 键，需要查询键盘控制器。我们可以通过读取 PS/2 控制器的数据端口来实现这一点，该端口属于 [I/O 端口] ，编号为 `0x60` ：\n\n[I/O 端口]: @/second-edition/posts/04-testing/index.md#i-o-ports\n\n```rust\n// in src/interrupts.rs\n\nextern \"x86-interrupt\" fn keyboard_interrupt_handler(\n    _stack_frame: &mut InterruptStackFrame)\n{\n    use x86_64::instructions::port::Port;\n\n    let mut port = Port::new(0x60);\n    let scancode: u8 = unsafe { port.read() };\n    print!(\"{}\", scancode);\n\n    unsafe {\n        PICS.lock()\n            .notify_end_of_interrupt(InterruptIndex::Keyboard.as_u8());\n    }\n}\n```\n\n我们使用 `x86_64` 包提供的端口类型 [`Port`] 从键盘的数据端口读取一个字节。这个字节就是「[**键盘扫描码**]」，一个表示物理键 按下/松开 的数字。 目前，我们还没有对键盘扫描码进行处理，只是把它打印到屏幕上：\n\n[`Port`]: https://docs.rs/x86_64/0.8.1/x86_64/instructions/port/struct.Port.html\n[**键盘扫描码**]: https://en.wikipedia.org/wiki/Scancode\n\n![QEMU printing scancodes to the screen when keys are pressed](https://os.phil-opp.com/hardware-interrupts/qemu-printing-scancodes.gif)\n\n上图显示了我正在慢慢地键入字符串 `\"123\"` 。可以看到，相邻物理键的键盘扫描码也相邻，而 按下/松开 物理键触发的键盘扫描码是不同的。但是我们如何将键盘扫描码转换为实际的按键操作呢？\n\n### 解释键盘扫描码\n\n键盘扫描码和物理键之间的映射有三种不同的标准，即所谓的「键盘扫描码集」。这三者都可以追溯到早期 IBM 计算机的键盘：[IBM XT]、 [IBM 3270 PC] 和 [IBM AT] 。幸运地是，后来的计算机没有继续定义新的键盘扫描码集的趋势，而是对现有的集合进行模拟和扩展。时至今日，大多数键盘都可以配置为模拟这三种标准中的任何一组。\n\n[IBM XT]: https://en.wikipedia.org/wiki/IBM_Personal_Computer_XT\n[IBM 3270 PC]: https://en.wikipedia.org/wiki/IBM_3270_PC\n[IBM AT]: https://en.wikipedia.org/wiki/IBM_Personal_Computer/AT\n\n默认情况下，PS/2 键盘模拟键盘扫描码集 1（「XT」）。在这个码集中，每个键盘扫描码的低 7 位字节定义了物理键信息，而最高有效位则定义了物理键状态是按下（「0」）还是释放（「1」）。原始的「IBM XT」键盘上没有的键，如键盘上的 `enter` 键，会连续生成两个键盘扫描码: `0xe0` 转义字节和一个表示物理键的字节。有关键盘扫描码集 1 中的所有键盘扫描码及其对应物理键的列表，请访问 [OSDev Wiki][scancode set 1] 。\n\n[scancode set 1]: https://wiki.osdev.org/Keyboard#Scan_Code_Set_1\n\n要将键盘扫描码转换为按键操作，可以使用 `match` 语句：\n\n```rust\n// in src/interrupts.rs\n\nextern \"x86-interrupt\" fn keyboard_interrupt_handler(\n    _stack_frame: &mut InterruptStackFrame)\n{\n    use x86_64::instructions::port::Port;\n\n    let mut port = Port::new(0x60);\n    let scancode: u8 = unsafe { port.read() };\n\n    // new\n    let key = match scancode {\n        0x02 => Some('1'),\n        0x03 => Some('2'),\n        0x04 => Some('3'),\n        0x05 => Some('4'),\n        0x06 => Some('5'),\n        0x07 => Some('6'),\n        0x08 => Some('7'),\n        0x09 => Some('8'),\n        0x0a => Some('9'),\n        0x0b => Some('0'),\n        _ => None,\n    };\n    if let Some(key) = key {\n        print!(\"{}\", key);\n    }\n\n    unsafe {\n        PICS.lock()\n            .notify_end_of_interrupt(InterruptIndex::Keyboard.as_u8());\n    }\n}\n```\n\n上面的代码转换数字键 0-9 的按键操作，并忽略所有其他键。 它使用 [match] 语句为每个键盘扫描码分配相应的字符或 `None`。 然后它使用 [`if let`] 来解构可选的 `key` 。 通过在模式中使用相同的变量名 `key` ，我们可以 [隐藏] 前面的声明，这是 Rust 中解构 `Option` 类型的常见模式。\n\n[match]: https://doc.rust-lang.org/book/ch06-02-match.html\n[`if let`]: https://doc.rust-lang.org/book/ch18-01-all-the-places-for-patterns.html#conditional-if-let-expressions\n[隐藏]: https://doc.rust-lang.org/book/ch03-01-variables-and-mutability.html#shadowing\n\n现在我们可以往屏幕上写数字了:\n\n![QEMU printing numbers to the screen](https://os.phil-opp.com/hardware-interrupts/qemu-printing-numbers.gif)\n\n我们也可以用同样的方式转换其他按键操作。幸运的是，有一个名为 [`pc-keyboard`] 的包，专门用于翻译键盘扫描码集 1 和 2 中的键盘扫描码，因此我们无须自己实现。要使用这个包，需要将它添加到 `Cargo.toml` 内，并导入到 `lib.rs` 中：\n\n[`pc-keyboard`]: https://docs.rs/pc-keyboard/0.5.0/pc_keyboard/\n\n```toml\n# in Cargo.toml\n\n[dependencies]\npc-keyboard = \"0.5.0\"\n```\n\n现在我们可以使用这个包来重写键盘中断处理程序 `keyboard_interrupt_handler`：\n\n```rust\n// in/src/interrupts.rs\n\nextern \"x86-interrupt\" fn keyboard_interrupt_handler(\n    _stack_frame: &mut InterruptStackFrame)\n{\n    use pc_keyboard::{layouts, DecodedKey, HandleControl, Keyboard, ScancodeSet1};\n    use spin::Mutex;\n    use x86_64::instructions::port::Port;\n\n    lazy_static! {\n        static ref KEYBOARD: Mutex<Keyboard<layouts::Us104Key, ScancodeSet1>> =\n            Mutex::new(Keyboard::new(layouts::Us104Key, ScancodeSet1,\n                HandleControl::Ignore)\n            );\n    }\n\n    let mut keyboard = KEYBOARD.lock();\n    let mut port = Port::new(0x60);\n\n    let scancode: u8 = unsafe { port.read() };\n    if let Ok(Some(key_event)) = keyboard.add_byte(scancode) {\n        if let Some(key) = keyboard.process_keyevent(key_event) {\n            match key {\n                DecodedKey::Unicode(character) => print!(\"{}\", character),\n                DecodedKey::RawKey(key) => print!(\"{:?}\", key),\n            }\n        }\n    }\n\n    unsafe {\n        PICS.lock()\n            .notify_end_of_interrupt(InterruptIndex::Keyboard.as_u8());\n    }\n}\n```\n\n我们使用 `lazy_static` 宏来创建一个由互斥锁保护的静态对象 [`Keyboard`]。 我们使用美国键盘布局初始化键盘，并采用键盘扫描码集 1 。 [`HandleControl`] 参数允许将 `ctrl+[a-z]` 映射到 Unicode 字符 `U+0001` - `U+001A` 。 我们不想这样做，所以使用 `Ignore` 选项来像处理普通键一样处理 `ctrl` 键。\n\n[`Handlecontrol`]: https://docs.rs/pc-keyboard/0.5.0/pc_keyboard/enum.HandleControl.html\n\n每当中断发生，我们锁定互斥对象，从键盘控制器读取键盘扫描码并将其传递给 [`add_byte`] 方法，后者将键盘扫描码转换为 `Option<KeyEvent>` 。 [`KeyEvent`] 包含引发事件的物理键以及它的事件类型——按下或是松开。\n\n[`Keyboard`]: https://docs.rs/pc-keyboard/0.5.0/pc_keyboard/struct.Keyboard.html\n[`add_byte`]: https://docs.rs/pc-keyboard/0.5.0/pc_keyboard/struct.Keyboard.html#method.add_byte\n[`keyEvent`]: https://docs.rs/pc-keyboard/0.5.0/pc_keyboard/struct.KeyEvent.html\n\n为了解释按键事件，我们将其传递给 [`process_keyevent`] ，该方法将按键事件转换为字符。例如，根据是否按下 `shift` 键，将物理键 `a` 的按下事件转换为对应的小写字符或大写字符。\n\n[`process_keyevent`]: https://docs.rs/pc-keyboard/0.5.0/pc_keyboard/struct.Keyboard.html#method.process_keyevent\n\n有了这个修改过的中断处理程序，我们就可以写一些文本内容：\n\n![Typing \"Hello World\" in QEMU](https://os.phil-opp.com/hardware-interrupts/qemu-typing.gif)\n\n### 配置键盘\n\n我们也可以对 PS/2 键盘的某些方面进行配置，例如应该使用哪个键盘扫描码集。我们不会在这里讨论它，因为这篇文章已经足够长了，但是 OSDev Wiki 上有一篇关于可能的 [配置命令] 的概述。\n\n[配置命令]: https://wiki.osdev.org/PS/2_Keyboard#Commands\n\n## 小结\n\n这篇文章解释了如何启用和处理外部中断。 我们学习了 8259 PIC 和经典的主/从二级布局，中断类型码的重映射，以及「中断结束」信号。 我们实现了硬件定时器和键盘的中断处理程序，并且学习了 `hlt` 指令，它会暂停 CPU 直到触发下一个中断。\n\n现在我们可以与内核进行交互，并且有一些基本的构建块，可以用来创建一个小 shell 或简单的游戏。\n\n## 下篇预告\n\n定时器中断对于操作系统来说是必不可少的，因为它们提供了一种周期性地中断运行进程并使内核重新获得控制权的方法。这样一来，内核就可以切换到不同的进程，并营造出一种多个进程并行运行的错觉。\n\n但是在创建进程或线程之前，我们需要一种为它们分配内存的方法。下一篇文章将探讨内存管理，以提供这一基本构建块。\n"
        },
        {
          "name": "08-introduction-to-paging.md",
          "type": "blob",
          "size": 31.5693359375,
          "content": "---\ntitle: 介绍分页\ndate: 2019-01-31 18:20:38\ntags: [Memory Management]\nsummary: 这篇文章介绍了分页，这是一种非常常见的内存管理方案，我们也将将其用于我们的操作系统。 它解释了为什么需要内存隔离，分段如何工作，虚拟内存是什么，以及分页如何解决内存碎片问题。 它还探讨了x86_64架构上多级页表的布局。\n---\n\n## 内存保护\n\n操作系统的一个主要任务是将程序彼此隔离。例如，您的Web浏览器不应该干扰您的文本编辑器。为实现此目标，操作系统利用硬件功能来确保一个进程的内存区域不能被其他进程访问。根据硬件和操作系统的实现，有不同的方法来做到这一点。\n\n例如，某些ARM Cortex-M处理器（通常用于嵌入式系统）具有内存保护单元（MPU），它允许您定义少量（例如8个）内存区域具有的不同访问权限（例如，无访问权限，只读，读写）。在每次内存访问时，MPU确保该地址位于具有正确访问权限的区域中，否则会抛出一个异常。通过在每次切换进程的时候同时也切换内存区域和访问权限，操作系统可以确保每个进程只访问自己的内存，从而将进程彼此隔离。\n\n在x86上，硬件支持两种不同的内存保护方法：分段和分页。\n\n## 分段\n\n分段在1978年就已经引入了，最初是为了增加可寻址内存的数量。当时的情况是CPU只有16位地址线，这将可寻址内存量限制为64KiB。为了访问这64KiB之外的内存，引入了额外的段寄存器，每个寄存器包含一个偏移地址。 CPU会在每次内存访问时自动添加此偏移量，以便访问高达1MiB的内存。\n\n段寄存器由CPU自动选择，具体取决于存储器访问的类型：对于获取指令，使用代码段CS，对于堆栈操作（push/pop），使用堆栈段SS。其他指令使用数据段DS或额外段ES。后来增加了两个额外的段寄存器FS和GS，可以自由使用。\n\n在最初的分段机制设计中，段寄存器直接存储偏移量，并且没有访问控制。后来随着保护模式的引入，这一点改变了。当CPU以此模式运行时，段描述符包含本地或全局描述符表的索引，该表除了包含偏移地址外，还包含段大小和访问权限。通过为每个进程加载单独的全局/本地描述符表来限制对进程自身内存区域的内存访问，操作系统可以将进程彼此隔离。\n\n通过在实际访问之前修改存储器地址，分段机制已经采用了现在几乎在任何地方使用的技术：虚拟内存。\n\n## 虚拟内存\n\n虚拟内存背后的想法是从底层物理存储设备中抽象出内存地址。不是直接访问存储设备，而是首先执行转换步骤。对于分段，转换步骤是添加活动段的偏移地址。想象一个程序访问偏移量为`0x1111000`的段中的内存地址`0x1234000`：真正访问的地址是`0x2345000`。\n\n为了区分这两种地址类型，转换前的地址称为虚拟地址，转换后的地址称为物理地址。这两种地址之间的一个重要区别是物理地址是独一无二的的，并且始终指向相同的，唯一的存储位置。另一方面，虚拟地址取决于翻译功能。两个不同的虚拟地址完全可能指的是相同的物理地址。此外，相同的虚拟地址在使用不同的转换功能时可以指向不同的物理地址。\n\n证明此属性有用的一个例子是并行运行相同的程序两次：\n\n![Two virtual address spaces with address 0–150, one translated to 100–250, the other to 300–450](https://os.phil-opp.com/paging-introduction/segmentation-same-program-twice.svg)\n\n这里相同的程序被运行了两次，但具有不同的地址映射。 第一个实例的段偏移量为100，因此其虚拟地址0-150被转换为物理地址100-250。 第二个实例具有偏移300，其将其虚拟地址0-150转换为物理地址300-450。 这允许两个程序运行相同的代码并使用相同的虚拟地址而不会相互干扰。\n\n另一个优点是，程序现在可以被放置在任意物理内存位置，即使它们使用完全不同的虚拟地址。 因此，OS可以利用全部可用内存而无需重新编译程序。\n\n## 碎片\n\n虚拟地址和物理地址之间的区别使得分段功能非常强大。 但是，它存在碎片问题。 举个例子，假设我们要运行上面看到的程序的第三个副本：\n\n![Three virtual address spaces, but there is not enough continuous space for the third](https://os.phil-opp.com/paging-introduction/segmentation-fragmentation.svg)\n\n即使有足够的可用内存，也无法将程序的第三个实例映射到虚拟内存而不会重叠。 问题是我们需要连续的内存，不能使用小的空闲块。\n\n解决掉这种碎片的一种方法是暂停执行，将存储器的已使用部分移近一些，更新地址映射，然后恢复执行：\n\n\n\n![Three virtual address spaces after defragmentation](https://os.phil-opp.com/paging-introduction/segmentation-fragmentation-compacted.svg)\n\n现在有足够的连续空间来启动我们程序的第三个实例了。\n\n这种碎片整理过程的缺点是需要复制大量内存，这会降低系统性能。 在内存变得过于分散之前，还需要定期进行。 这使得系统的行为变得不可预测，因为程序可能在任何时间暂停并且可能无响应[^1]。\n\n碎片问题是大多数操作系统不再使用分段的原因之一。 实际上，x86的64位模式甚至不再支持分段。 而是使用分页，这完全避免了碎片问题。\n\n## 分页\n\n我们的想法是将虚拟和物理内存空间分成小的固定大小的块。 虚拟存储器空间的块称为页面，物理地址空间的块称为帧。 每个页面可以单独映射到一个帧，这样就可以跨越非连续的物理帧分割更大的内存区域。\n\n如果我们回顾碎片化内存空间的示例，但是这次使用分页而不是分段，这一点的优势变得明显：\n\n![With paging the third program instance can be split across many smaller physical areas](https://os.phil-opp.com/paging-introduction/paging-fragmentation.svg)\n\n在这个例子中，我们的页面大小为50字节，这意味着我们的每个内存区域分为三页。 每个页面都单独映射到一个帧，因此连续的虚拟内存区域可以映射到非连续的物理帧。 这允许我们在不执行任何碎片整理的情况下启动程序的第三个实例。\n\n## 隐藏的碎片\n\n与分段相比，分页使用许多小的固定大小的存储区域而不是几个大的可变大小的区域。由于每个帧具有相同的大小，因此没有太小的帧不能使用，因此不会发生碎片。\n\n似乎没有碎片会出现。但是事实上仍然会存在一些隐藏的碎片，即所谓的内部碎片。发生内部碎片是因为并非每个内存区域都是页面大小的精确倍数。想象一下上面例子中一个大小为101的程序：它仍然需要三个大小为50的页面，因此它将比所需的多占用49个字节。为了区分这两种类型的碎片，使用分段时发生的碎片类型称为外部碎片。\n\n出现内部碎片是很不幸的，但通常比使用分段时出现的外部碎片更好。它仍然浪费内存，但不需要进行碎片整理，并且可以预测碎片量（平均每个内存区域半页）。 \n\n## 页表\n\n我们看到可能有数百万个页面被映射到单独的一个帧。 此映射信息需要存储在某处。 分段对每个活动的内存区域使用单独的段选择器寄存器，这对于分页是不可能的，因为页面的数量远多于寄存器。 相反，分页使用称为页表的表结构来存储映射信息。\n\n对于上面的示例，页表将如下所示：\n\n![Three page tables, one for each program instance. For instance 1 the mapping is 0->100, 50->150, 100->200. For instance 2 it is 0->300, 50->350, 100->400. For instance 3 it is 0->250, 50->450, 100->500.](https://os.phil-opp.com/paging-introduction/paging-page-tables.svg)\n\n我们看到每个程序实例都有自己的页表。 指向当前活跃的页表的指针存储在特殊CPU寄存器中。 在x86上，该寄存器称为CR3。 在运行每个程序实例之前，操作系统要将指向正确页表的指针加载到该寄存器。\n\n在每次访问内存时，CPU从寄存器中读取页表指针，并在表中查找要访问页面的映射到的帧。 这完全由硬件完成，对运行的程序完全透明。 为了加快转换过程，许多CPU架构都有一个特殊的缓存，可以记住上次翻译的结果。\n\n在一些体系结构上，页表条目还可以在标志字段中存储诸如访问权限之类的属性。 在上面的例子中，“r/w”标志表示页面既可读又可写。\n\n## 多级页表\n\n我们刚刚看到的简单页表在较大的地址空间中存在问题：它们本身要占用很多内存。 例如，假设一个程序使用四个虚拟页面0,1_000_000,1_000_050和1_000_100（我们使用_作为千位分隔符）：\n\n![Page 0 mapped to frame 0 and pages 1_000_000–1_000_150 mapped to frames 100–250](https://os.phil-opp.com/paging-introduction/single-level-page-table.svg)\n\n这个程序运行只需要4个物理帧，但页表中有超过一百万个条目。 我们不能省略空条目，因为那样的话CPU在翻译过程中不再能直接跳转到表中的正确条目（例如，不再保证第四页的数据在第四个条目）[^2]。\n\n为了减少浪费的内存，我们可以使用**两级页表**。 我们的想法是我们为不同的地址区域使用不同的页表。 另一个称为2级页表的表包含虚拟地址区域和1级页表之间的映射。\n\n最好用一个例子来解释。 让我们定义每个1级页面表负责一个大小为10_000的区域。 然后，上面的示例映射将存在以下表：\n\n![Page 0 points to entry 0 of the level 2 page table, which points to the level 1 page table T1. The first entry of T1 points to frame 0, the other entries are empty. Pages 1_000_000–1_000_150 point to the 100th entry of the level 2 page table, which points to a different level 1 page table T2. The first three entries of T2 point to frames 100–250, the other entries are empty.](https://os.phil-opp.com/paging-introduction/multilevel-page-table.svg)\n\n第0页在第一个10_000字节区域中，因此它使用2级页表的第一个条目。此条目指向1级页表T1，它指出页0指向的是第0帧。\n\n页面1_000_000,1_000_050和1_000_100都属于第100个10_000字节区域，因此它们使用2级页面表的第100个条目。该条目指向另一个的1级页表T2，其将三个页面映射到帧100,150和200。注意，1级页表中的页面地址不包括区域偏移，因此例如，一级页表中第1_000_050页的条目就只是50（而非1_000_050）。\n\n我们在2级页表中仍然有100个空条目，但比之前的百万个空条目少得多。这种节省的原因是我们不需要为10_000和1_000_000之间的未映射内存区域创建1级页面表。\n\n两级页表的原理可以扩展到三级，四级或更多级。然后页表寄存器指向最高级别表，该表指向下一个较低级别的表，再指向下一个较低级别的表，依此类推。然后，1级页面表指向映射的帧。这整个原理被称为多级或分层页表。\n\n现在我们知道分页和多级页表如何工作，我们可以看一下如何在x86_64架构中实现分页（我们假设CPU在64位模式下运行）。\n\n## x86_64下的分页\n\nx86_64体系结构使用4级页表，页面大小为4KiB。 每个页表，无论是哪级页表，具有固定大小512个条目。 每个条目的大小为8个字节，因此每个页表大小都为512 * 8B = 4KiB大，恰好能装入一个页面。\n\n每个级别的页表索引可以直接从虚拟地址中读出：\n\n![Bits 0–12 are the page offset, bits 12–21 the level 1 index, bits 21–30 the level 2 index, bits 30–39 the level 3 index, and bits 39–48 the level 4 index](https://os.phil-opp.com/paging-introduction/x86_64-table-indices-from-address.svg)\n\n我们看到每个表索引由9位组成，这是因为每个表有2^9 = 512个条目。 最低的12位是4KiB页面中的偏移（2^12字节= 4KiB）。48到64位没用，这意味着x86_64实际上不是64位，因为它只支持48位地址。 有计划通过5级页表将地址大小扩展到57位，但是还没有支持此功能的处理器。\n\n即使48到64位不被使用，也不能将它们设置为任意值。 相反，此范围内的所有位必须是第47位的副本，以保持地址的唯一性，并允许未来的扩展，如5级页表。 这称为符号扩展，因为它与二进制补码中的符号扩展非常相似。 如果地址未正确进行符号扩展，则CPU会抛出异常。\n\n## 地址翻译的示例\n\n让我们通过一个例子来了解地址翻译过程的详细工作原理：\n\n![An example 4-level page hierarchy with each page table shown in physical memory](https://os.phil-opp.com/paging-introduction/x86_64-page-table-translation.svg)\n\n当前活跃的的4级页表的物理地址（这个4级页表的基地址）存储在CR3寄存器中。 然后，每个页表条目指向下一级表的物理帧。 然后，1级页表的条目指向映射到的帧。 请注意，页表中的所有地址都是物理的而不是虚拟的，否则CPU也需要转换这些地址，导致永无止境的递归。\n\n上面的页表层次结构映射了两个页面（用蓝色表示）。 从页表索引我们可以推断出这两个页面的虚拟地址是`0x803FE7F000`和`0x803FE00000`。 让我们看看当程序试图从地址`0x803FE7F5CE`读取时会发生什么。 首先，我们将地址转换为二进制，并确定页表索引和地址的页面偏移量：\n\n![The sign extension bits are all 0, the level 4 index is 1, the level 3 index is 0, the level 2 index is 511, the level 1 index is 127, and the page offset is 0x5ce](https://os.phil-opp.com/paging-introduction/x86_64-page-table-translation-addresses.png)\n\n使用这些页表索引，我们现在可以遍历页表层次结构以确定地址的映射帧：\n\n- 我们首先从CR3寄存器中读取4级页表的地址。\n- 4级索引是1，所以我们查看该表的索引1的条目，它告诉我们3级页表存储在物理地址16KiB处。\n- 我们从该地址加载3级表，并查看索引为0的条目，它将我们指向物理地址24KiB处的2级页表。\n- 2级索引是511，因此我们查看该页面的最后一个条目以找出1级页表的地址。\n- 通过级别1表的索引127的条目，我们最终发现页面映射到物理地址为12KiB（或十六进制的0xc000）的帧。\n- 最后一步是将页面偏移量加到获得的帧的基地址中，以获得最终的物理地址0xc000 + 0x5ce = 0xc5ce。\n\n![The same example 4-level page hierarchy with 5 additional arrows: \"Step 0\" from the CR3 register to the level 4 table, \"Step 1\" from the level 4 entry to the level 3 table, \"Step 2\" from the level 3 entry to the level 2 table, \"Step 3\" from the level 2 entry to the level 1 table, and \"Step 4\" from the level 1 table to the mapped frames.](https://os.phil-opp.com/paging-introduction/x86_64-page-table-translation-steps.svg)\n\n1级页表中页面的权限是`r`，表示只读。 硬件会强制保证这些权限，如果我们尝试写入该页面，则会抛出异常。 更高级别页面中的权限限制了较低级别的权限，因此如果我们将3级页表中的条目设置为只读，则使用此条目的页面都不可写，即使较低级别指定读/写权限也是如此。\n\n重要的是要注意，尽管此示例仅使用每个表的单个实例，但每个地址空间中通常存在多个每个级别页表的实例。 最多，有：\n\n- 一个4级页表\n- 512个3级页表（因为4级页表有512个条目）\n- 512*512个2级页表（因为512个3级页表中的每一个都有512个条目）\n- 512 * 512 * 512个1级页表（每个2级页表512个条目）\n\n## 页表格式\n\nx86_64体系结构上的页表基本上是512个条目的数组。 在Rust语法中：\n\n```rust\n#[repr(align(4096))]\npub struct PageTable {\n    entries: [PageTableEntry; 512],\n}\n```\n\n如repr属性所示，页表需要页面对齐，即在4KiB边界上进行内存对齐。 此要求可确保页表始终填充整个页面，并允许进行优化，使条目非常紧凑。\n\n每个条目都是8字节（64位）大，具有以下格式：\n\n| Bit(s) | Name                  | Meaning                                                      |\n| ------ | --------------------- | ------------------------------------------------------------ |\n| 0      | present               | 这个页面是否正在内存中                                       |\n| 1      | writable              | 这个页面是否可写                                             |\n| 2      | user accessible       | 这个页面是否可以被用户态访问                                 |\n| 3      | write through caching | 对这个页面的写入是否直接进入内存（不经过cache）              |\n| 4      | disable cache         | 是否完全禁止使用cache                                        |\n| 5      | accessed              | 当这个页面正在被使用时，这个位会被CPU自动设置                |\n| 6      | dirty                 | 当这个页面有被写入时，CPU会自动被CPU设置                     |\n| 7      | huge page/null        | 在 1级和4级页表中必须为0，在3级页表中会创建1GiB的内存页，在2级页表中会创建2MiB的内存页 |\n| 8      | global                | 地址空间切换时，页面不会被换出cache ( CR4 中的PGE 位必须被设置) |\n| 9-11   | available             | OS可以随意使用                                               |\n| 12-51  | physical address      | 物理帧地址或下一个页表的地址                                 |\n| 52-62  | available             | OS可以随意使用                                               |\n| 63     | no execute            | 禁止将这个页面上的数据当作代码执行 (EFER寄存器中的NXE位必须被设置) |\n\n我们看到只有12-51位用于存储物理帧地址，其余位用作标志或可由操作系统自由使用。 这是因为我们总是指向一个4096字节的对齐地址，可以是页面对齐的页表，也可以是映射到的帧的开头。 这意味着0-11位始终为零，因此没有理由存储这些位，因为硬件可以在使用地址之前将它们设置为零。 对于位52-63也是如此，因为x86_64架构仅支持52位物理地址（类似于它仅支持48位虚拟地址）。\n\n让我们仔细看看可用的标志位：\n\n- `present`标志将映射过的页面与未映射页面区分开来。当主内存已满时，它可用于临时将页面换出到磁盘。随后访问页面时，会发生一个称为缺页异常的特殊异常，操作系统可以从磁盘重新加载缺少的页面然后继续执行该程序。\n- `writable`和`no execute`标志分别控制页面内容是否可写和是否包含可执行指令。\n- 当对页面进行读取或写入时，CPU会自动设置`accessed`和`dirty`标志。该信息可以被操作系统所利用，例如确定自上次保存到磁盘后要换出的页面或页面内容是否被修改。\n- 通过`write through caching`和 `disable cache` 标志的写入允许单独控制每个页面的缓存。\n-  `user accessible` 标志使页面可用于用户态的代码，否则只有在CPU处于内核态时才可访问该页面。通过在用户空间程序运行时保持内核映射，此功能可用于更快地进行系统调用。但是，Spectre漏洞可以允许用户空间程序读取这些页面。\n- `global`标志告诉硬件这个页在所有地址空间中都可用，因此不需要从地址空间切换的高速缓存中删除（请参阅下面有关TLB的部分）。该标志通常与用户可访问标志（设置为0）一起使用，以将内核代码映射到所有地址空间。\n-  `huge page` 标志允许通过让级别2或级别3页表的条目直接指向映射的帧来创建更大尺寸的页面。设置此位后，对于2级条目，页面大小增加512倍至2MiB = 512 * 4KiB，对于3级条目，页面大小甚至增加到了1GiB = 512 * 2MiB。使用较大页面的优点是需要更少的地址切换缓存行和更少的页表。\n\n`x86_64` crate为页表及其条目提供了类型，因此我们不需要自己创建这些结构。\n\n## 转译后备缓冲器[^3]\n\n4级页表使得虚拟地址的转换变得昂贵，因为每次地址翻译需要4次内存访问。为了提高性能，x86_64架构将最后几个转换缓存在所谓的转译后备缓冲器（TLB）中。这允许在仍然某个地址翻译仍然在缓存中时跳过翻译。\n\n与其他CPU缓存不同，TLB不是完全透明的，并且在页表的内容发生更改时不会更新或删除缓存的转换规则。这意味着内核必须在修改页表时手动更新TLB。为此，有一个名为`invlpg`的特殊CPU指令（“invalidate page”），用于从TLB中删除指定页面的转换规则，下次访问时这个转换规则将从页表中从新加载。通过重新设置CR3寄存器，假装进行一次地址空间转换，也可以完全刷新TLB。 `x86_64` crate在tlb模块中提供了实现这两个功能的Rust函数。\n\n重要的是要记住在每个页表修改时也要同时刷新TLB，否则CPU可能会继续使用旧的转换规则，这可能导致不确定的错误，这些错误很难调试。\n\n## 实现\n\n我们还没有提到的一件事：**我们的内核已经有分页机制了**。 我们在“A minimal Rust Kernel”那一篇文章中添加的引导加载程序已经设置了一个4级分页层次结构，它将我们内核的每个页面映射到一个物理帧。 bootloader程序执行此操作是因为在x86_64上的64位模式下必须进行分页。\n\n这意味着我们在内核中使用的每个内存地址都是一个虚拟地址。 访问地址为0xb8000的VGA缓冲区能用，这是因为bootloader程序已经将该内存页映射到本身了，这意味着它将虚拟页0xb8000映射到物理帧0xb8000。\n\n分页使我们的内核已经相对安全，因为每个超出范围的内存访问都会导致页面错误异常，而不是写入随机的物理内存。 引导加载程序甚至为每个页面设置了正确的访问权限，这意味着只有包含代码的页面是可执行的，只有数据页面是可写的。\n\n## 页面错误\n\n让我们尝试通过访问内核之外的一些内存来导致页面错误。 首先，我们创建一个页面错误处理程序并在我们的IDT中注册它，以便我们看到page fault exception而不是通用的double fault：\n\n```rust\n// in src/interrupts.rs\n\nlazy_static! {\n    static ref IDT: InterruptDescriptorTable = {\n        let mut idt = InterruptDescriptorTable::new();\n\n        […]\n\n        idt.page_fault.set_handler_fn(page_fault_handler); // new\n\n        idt\n    };\n}\n\nuse x86_64::structures::idt::PageFaultErrorCode;\n\nextern \"x86-interrupt\" fn page_fault_handler(\n    stack_frame: &mut ExceptionStackFrame,\n    _error_code: PageFaultErrorCode,\n) {\n    use crate::hlt_loop;\n    use x86_64::registers::control::Cr2;\n\n    println!(\"EXCEPTION: PAGE FAULT\");\n    println!(\"Accessed Address: {:?}\", Cr2::read());\n    println!(\"{:#?}\", stack_frame);\n    hlt_loop();\n}\n```\n\n`CR2`寄存器由CPU在页面错误时自动设置，并包含导致页面错误的虚拟地址。 我们使用`x86_64` crate 的`Cr2 :: read`函数来读取和打印它。 通常，`PageFaultErrorCode`类型将提供有关导致页面错误的内存访问类型的更多信息，但目前有一个传递无效错误代码的LLVM bug[^4]，因此我们暂时忽略它。 我们无法在不解决页面错误的情况下继续执行程序，因此我们最后会进入一个`hlt_loop`。\n\n现在我们可以尝试访问内核之外的一些内存：\n\n```rust\n// in src/main.rs\n\n#[cfg(not(test))]\n#[no_mangle]\npub extern \"C\" fn _start() -> ! {\n    use blog_os::interrupts::PICS;\n\n    println!(\"Hello World{}\", \"!\");\n\n    // set up the IDT first, otherwise we would enter a boot loop instead of\n    // invoking our page fault handler\n    blog_os::gdt::init();\n    blog_os::interrupts::init_idt();\n    unsafe { PICS.lock().initialize() };\n    x86_64::instructions::interrupts::enable();\n\n    // new\n    let ptr = 0xdeadbeaf as *mut u32;\n    unsafe { *ptr = 42; }\n\n    println!(\"It did not crash!\");\n    blog_os::hlt_loop();\n}\n```\n\n当我们运行这个程序，我们可以看到页面错误异常的回调函数被调用了：\n\n![EXCEPTION: Page Fault, Accessed Address: VirtAddr(0xdeadbeaf), ExceptionStackFrame: {…}](https://os.phil-opp.com/paging-introduction/qemu-page-fault.png)\n\n`CR2`寄存器确实包含`0xdeadbeaf`，我们试图访问的地址。\n\n我们看到当前指令指针是`0x20430a`，所以我们可以知道这个地址指向一个代码页。 代码页由引导加载程序以只读方式映射，因此从该地址读取有效但写入会导致页面错误。 您可以通过将`0xdeadbeaf`指针更改为`0x20430a`来尝试此操作：\n\n```rust\n// Note: The actual address might be different for you. Use the address that\n// your page fault handler reports.\nlet ptr = 0x20430a as *mut u32;\n// read from a code page -> works\nunsafe { let x = *ptr; }\n// write to a code page -> page fault\nunsafe { *ptr = 42; }\n```\n\n注释掉最后一行，我们可以看出读操作成功了，但写操作会导致一个页面异常。\n\n## 读取页表\n\n让我们试着看看我们的内核运行时用的页面表：\n\n```rust\n// in src/main.rs\n\n#[cfg(not(test))]\n#[no_mangle]\npub extern \"C\" fn _start() -> ! {\n    […] // initialize GDT, IDT, PICS\n\n    use x86_64::registers::control::Cr3;\n\n    let (level_4_page_table, _) = Cr3::read();\n    println!(\"Level 4 page table at: {:?}\", level_4_page_table.start_address());\n\n    println!(\"It did not crash!\");\n    blog_os::hlt_loop();\n}\n```\n\n`x86_64`的`Cr3::read`函数从`CR3`寄存器返回当前活动的4级页表。 它返回`PhysFrame`和`Cr3Flags`类型的元组。 我们只对`PhysFrame`感兴趣，所以我们忽略了元组的第二个元素。\n\n当我们运行它时，我们看到以下输出：\n\n```shell\nLevel 4 page table at: PhysAddr(0x1000)\n```\n\n因此，当前活动的4级页表存储在物理内存中的地址0x1000处，如`PhysAddr`包装器类型所示。现在的问题是：我们如何从内核访问该表？\n\n当分页处于活动状态时，无法直接访问物理内存，因为程序可以轻松地绕过内存保护并访问其他程序的内存。因此，访问该表的唯一方法是通过一些映射到地址`0x1000`处的物理帧的虚拟页面。为页表帧创建映射的这个问题是一个普遍问题，因为内核需要定期访问页表，例如在为新线程分配堆栈时。\n\n下一篇文章将详细解释此问题的解决方案。现在，只需要知道引导加载程序使用称为递归页表的技术将虚拟地址空间的最后一页映射到4级页表的物理帧就足够了。虚拟地址空间的最后一页是`0xffff_ffff_ffff_f000`，所以让我们用它来读取该表的一些条目：\n\n```rust\n// in src/main.rs\n\n#[cfg(not(test))]\n#[no_mangle]\npub extern \"C\" fn _start() -> ! {\n    […] // initialize GDT, IDT, PICS\n\n    let level_4_table_pointer = 0xffff_ffff_ffff_f000 as *const u64;\n    for i in 0..10 {\n        let entry = unsafe { *level_4_table_pointer.offset(i) };\n        println!(\"Entry {}: {:#x}\", i, entry);\n    }\n\n    println!(\"It did not crash!\");\n    blog_os::hlt_loop();\n}\n```\n\n我们将最后一个虚拟页面的地址转换为指向`u64`类型的指针。 正如我们在上一节中看到的，每个页表项都是8个字节（64位），因此一个`u64`只代表一个条目。 我们使用`for`循环打印表的前10个条目。 在循环内部，我们使用`unsafe`块来读取原始指针和`offset\t`方法来执行指针运算。\n\n当我们运行它时，我们看到以下输出：\n\n![Entry 0: 0x2023, Entry 1: 0x6e2063, Entry 2-9: 0x0](https://os.phil-opp.com/paging-introduction/qemu-print-p4-entries.png)\n\n当我们查看页表条目的格式时，我们看到条目0的值`0x2023`意味着该条目`present`，`writable`，由CPU `accessed`，并映射到帧`0x2000`。 条目1映射到帧`0x6e2000`并且具有与条目0相同的标志，并添加了表示页面已写入的`dirty`标志。 条目2-9不`present`，因此这些虚拟地址范围不会映射到任何物理地址。\n\n我们可以使用`x86_64`crate 的`PageTable`类型，而不是使用不安全的原始指针：\n\n```rust\n// in src/main.rs\n\n#[cfg(not(test))]\n#[no_mangle]\npub extern \"C\" fn _start() -> ! {\n    […] // initialize GDT, IDT, PICS\n\n    use x86_64::structures::paging::PageTable;\n\n    let level_4_table_ptr = 0xffff_ffff_ffff_f000 as *const PageTable;\n    let level_4_table = unsafe {&*level_4_table_ptr};\n    for i in 0..10 {\n        println!(\"Entry {}: {:?}\", i, level_4_table[i]);\n    }\n\n    println!(\"It did not crash!\");\n    blog_os::hlt_loop();\n}\n```\n\n这里我们首先将`0xffff_ffff_ffff_f000`指针转换为原始指针，然后将其转换为Rust引用。 此操作仍然需要`unsafe`，因为编译器无法知道访问此地址的有效性。 但是在转换之后，我们有一个安全的`PageTable`类型，它允许我们通过安全的，有边界检查的索引操作来访问各个条目。\n\ncrate还为各个条目提供了一些抽象，以便我们在打印它们时直接看到设置了哪些标志：\n\n![ Entry 0: PageTableEntry { addr: PhysAddr(0x2000), flags: PRESENT | WRITABLE | ACCCESSED } Entry 1: PageTableEntry { addr: PhysAddr(0x6e5000), flags: PRESENT | WRITABLE | ACCESSED | DIRTY } Entry 2: PageTableEntry { addr: PhysAddr(0x0), flags: (empty)} Entry 3: PageTableEntry { addr: PhysAddr(0x0), flags: (empty)} Entry 4: PageTableEntry { addr: PhysAddr(0x0), flags: (empty)} Entry 5: PageTableEntry { addr: PhysAddr(0x0), flags: (empty)} Entry 6: PageTableEntry { addr: PhysAddr(0x0), flags: (empty)} Entry 7: PageTableEntry { addr: PhysAddr(0x0), flags: (empty)} Entry 8: PageTableEntry { addr: PhysAddr(0x0), flags: (empty)} Entry 9: PageTableEntry { addr: PhysAddr(0x0), flags: (empty)}](https://os.phil-opp.com/paging-introduction/qemu-print-p4-entries-abstraction.png)\n\n下一步是遵循条目0或条目1中的指针到3级页表。 但我们现在将再次遇到`0x2000`和`0x6e5000`是物理地址的问题，因此我们无法直接访问它们。 这个问题将在下一篇文章中解决。\n\n## 总结\n\n这个帖子介绍了两种内存保护技术：分段和分页。 前者使用可变大小的内存区域并且受到外部碎片的影响，后者使用固定大小的页面，并允许对访问权限进行更细粒度的控制。\n\n分页存储具有一个或多个级别的页表中的页面的映射信息。 x86_64体系结构使用4级页表，页面大小为4KiB。 硬件自动遍历页表并在转译后备缓冲区（TLB）中缓存生成的转译规则。 此缓冲区不是透明的，需要在页表更改时手动刷新。\n\n我们了解到我们的内核已经在分页之上运行，并且非法内存访问会导致页面错误异常。 我们尝试访问当前活动的页表，但我们只能访问4级表，因为页表存储了我们无法直接从内核访问的物理地址。\n\n## 接下来是什么？\n\n下一篇文章建立在我们在这篇文章中学到的基础知识的基础上。 它引入了一种称为递归页表的高级技术，以解决从我们的内核访问页表的问题。 这允许我们遍历页表层次结构并实现基于软件的翻译功能。 该帖子还解释了如何在页表中创建新映射。\n\n[^1]: @各大GC，尤其是某个会Stop the world 的GC\n[^2]: 即地址翻译的过程不再是O(1)，对于一个每条指令的运行都要进行（甚至进行多次）的工作来说，O(1)真的很重要！\n[^3]: 这是维基百科上的译名（还是想吐槽：这什么鬼……），常见的译名是“页表缓存”\n[^4]: 我想这就是为啥作者拖更了那么多时间"
        },
        {
          "name": "09-paging-implementation.md",
          "type": "blob",
          "size": 57.685546875,
          "content": "---\ntitle: 实现分页\ndate: 2019-09-25 07:43:38\ntags: [Memory Management]\nsummary: 这篇文章展示了如何在我们的内核中实现分页支持。 首先探讨了使内核可以访问物理页表帧的各种技术，并讨论了它们各自的优缺点。 然后，它实现了地址转换功能和创建新地址映射的功能。\n---\n\n## 简介\n\n上一篇文章介绍了分页的概念。通过与分段进行比较，它介绍了分页，解释了分页和页表的工作原理，然后介绍了 `x86_64` 的4级页表设计。我们发现引导加载程序已经为内核建立了页表层次结构，这意味着我们的内核已经在虚拟地址上运行。非法内存访问会导致页面错误异常，而不是修改任意物理内存，因此可以提高安全性。\n\n帖子的结尾是我们无法从内核访问页表的问题，因为它们存储在物理内存中，并且内核已经在虚拟地址上运行。这篇文章在这一点上继续，并探讨使我们的内核可访问页表帧的不同方法。我们将讨论每种方法的优缺点，然后为我们的内核决定一种方法。\n\n要实现此方法，我们将需要引导加载程序的支持，因此我们将首先对其进行配置。之后，我们将实现遍历页表层次结构的功能，以将虚拟地址转换为物理地址。最后，我们学习如何在页表中创建新的映射以及如何找到未使用的内存帧来创建新的页表。\n\n\n## 访问页表\n\n从我们的内核访问页表并不像看起来那样容易。 为了理解这个问题，让我们再次看一下前一篇文章的示例4级页面表层次结构：\n\n![An example 4-level page hierarchy with each page table shown in physical memory](https://os.phil-opp.com/paging-introduction/x86_64-page-table-translation.svg)\n\n这里重要的是每个页面条目都存储下一张表的 *物理地址*。 这避免了再次为这些地址运行地址转换，否则将对性能造成不利影响，并很容易导致无限的转换循环。\n\n对我们来说，问题在于我们无法直接从内核访问物理地址，因为我们的内核也运行在虚拟地址之上。例如，当我们访问地址 `4 KiB` 时，我们访问的是 *虚拟* 地址 `4 KiB`，而不是存储第4级页表的 *物理* 地址 `4 KiB`。 当我们想访问 *物理* 地址 `4 KiB` 时，我们只能通过一些映射到它的虚拟地址来进行访问。\n\n因此，为了访问页表帧，我们需要将一些虚拟页映射到它们。 创建这些映射的方法有很多，所有这些方法都允许我们访问任意页表帧。\n\n### 恒等映射\n\n一个简单的解决方案是**对所有页表进行恒等映射**：\n\n![A virtual and a physical address space with various virtual pages mapped to the physical frame with the same address](https://os.phil-opp.com/paging-implementation/identity-mapped-page-tables.svg)\n\n在此示例中，我们看到了很多被恒等映射的页表帧。这样一来，页表的物理地址也是有效的虚拟地址，因此我们可以轻松地从CR3寄存器访问所有级别的页表。\n\n但是，它会使虚拟地址空间变得混乱，并使得找到大尺寸的连续内存区域变得更加困难。例如，假设我们要在上面的图形中创建一个大小为 1000 KiB 的虚拟内存区域，例如用于[内存映射文件](https://zh.wikipedia.org/wiki/内存映射文件)。我们无法在 `28 KiB` 处开始该区域，因为它会与 `1004KiB` 处已映射的页碰撞。因此，我们必须继续寻找，直到找到足够大的未映射区域，例如 `1008 KiB` 。这是与分段类似的碎片问题。\n\n同样，这使创建新的页表变得更加困难，因为我们需要找到其对应的页尚未使用的物理帧。例如，假设我们为内存映射文件保留了从`1008 KiB` 开始的虚拟 1000 KiB 内存区域。现在我们不能再使用物理地址在`1000 KiB`和`2008 KiB`之间的任何帧，因为我们无法对其进行恒等映射。\n\n### 以固定偏移量映射\n为了避免弄乱虚拟地址空间，我们可以 **为页表映射使用单独的内存区域**。我们不再对页表帧进行恒等映射，而是将其从一个有固定偏移量的虚拟地址空间开始映射。例如，偏移量可以是 10 TiB：\n\n![The same figure as for the identity mapping, but each mapped virtual page is offset by 10 TiB.](https://os.phil-opp.com/paging-implementation/page-tables-mapped-at-offset.svg)\n\n通过将 `10TiB..(10TiB + 物理内存大小)` 范围内的虚拟地址专门用于页表映射，我们避免了恒等映射的冲突问题。但要保留虚拟地址空间中这么大的一块区域，只能在虚拟地址空间远大于物理内存大小时才可行。这在x86_64上不是问题，因为其 48 位地址空间大小为 256 TiB。\n\n这种方法仍然有一个缺点，那就是每当我们创建一个新的页表时我们都需要创建一个新的映射。 另外，它不允许访问其他地址空间的页表，这在创建新进程时很有用。\n\n### 映射整个物理内存\n\n我们可以通过映射完整的物理内存——而不是仅映射页表帧——来解决这些问题：\n\n![The same figure as for the offset mapping, but every physical frame has a mapping (at 10TiB + X) instead of only page table frames.](https://os.phil-opp.com/paging-implementation/map-complete-physical-memory.svg)\n\n此方法允许我们的内核访问任意物理内存，包括其他地址空间的页表帧。 保留的虚拟内存范围具有与以前相同的大小，不同之处在于它不再包含未映射的页面。\n\n这种方法的缺点是需要额外的页表来存储物理内存的映射。 这些页表需要存储在某个地方，因此它们会占用一部分物理内存，这在内存量较小的设备上可能会成为问题。\n\n但是在 x86_64 上，我们可以使用大小为 2MiB 的 huge 页 ([huge pages](https://en.wikipedia.org/wiki/Page_%28computer_memory%29#Multiple_page_sizes)) 来进行映射，而不是使用默认的 4KiB 页。 这样一来，由于只需要一个 3 级表和 32 个 2 级表，映射 32 GiB 物理内存仅需要 132 KiB 大小的页表。  huge 页还可以提高缓存效率，因为它们在转译后备缓冲器（TLB）中使用的条目更少。\n\n### 临时映射\n\n对于物理内存量很小的设备，我们只能在需要访问它们时才 **临时映射页表帧** 。 为了能够创建临时映射，我们只需要一个恒等映射的 1 级页表：\n\n![A virtual and a physical address space with an identity mapped level 1 table, which maps its 0th entry to the level 2 table frame, thereby mapping that frame to page with address 0](https://os.phil-opp.com/paging-implementation/temporarily-mapped-page-tables.svg)\n\n此图中的 1 级表控制虚拟地址空间的前2MiB。这是因为它可以通过从CR3寄存器开始，沿着4级，3级和2级页表中的第0个条目来最终访问到。索引为 8 的条目将地址 `32 KiB` 的虚拟页映射到地址`32 KiB`的物理帧，从而恒等映射了 1 级页表自身。该图通过 32 KiB 处的水平箭头显示了此恒等映射。\n\n通过写这个恒等映射的 1 级页表，内核最多可以创建511个临时映射（512减去映射自身所需的条目）。在上面的示例中，内核创建了两个临时映射：\n\n- 通过将 1 级表的第 0 个条目映射到地址为 `24 KiB` 的帧，它创建了一个临时映射，将 `0 KiB` 处的虚拟页映射到第 2 级页表的物理帧，如虚线箭头所示。\n- 通过将 1 级表的第 9 个条目映射到地址为 `4 KiB` 的帧，它创建了一个虚拟映射，将 `36 KiB` 处的虚拟页映射到 4 级页表的物理帧，如虚线箭头所示。\n\n现在内核可以通过写入 `0 KiB` 处的页面来访问2级页面表，并通过写入 `36 KiB` 处的页面来访问 4 级页面表。\n\n使用临时映射访问任意页表帧的过程将是：\n\n- 在恒等映射的第 1 级页表中搜索空闲条目。\n- 将该条目映射到我们要访问的页表的物理帧。\n- 通过映射到条目的虚拟页面访问目标帧。\n- 将条目设置回未使用状态，从而删除临时映射。\n\n这种方法重复使用相同的512个虚拟页来创建映射，因此仅需要4KiB的物理内存。缺点是它有点麻烦，特别是因为新映射可能需要修改多个表级别，这意味着我们将需要重复上述过程多次。\n\n### 递归页表\n\n另一个有趣的方法——根本不需要额外页表——是递归地映射页表。 这种方法的思想是将 4 级页面表的某些条目映射到 4 级表本身。 通过这样做，我们有效地保留了虚拟地址空间的一部分，并将所有当前和将来的页表帧映射到该空间。\n\n让我们通过一个例子来理解这一切是如何工作的：\n\n![An example 4-level page hierarchy with each page table shown in physical memory. Entry 511 of the level 4 page is mapped to frame 4KiB, the frame of the level 4 table itself.](https://os.phil-opp.com/paging-implementation/recursive-page-table.png)\n\n与本文开头示例的唯一区别是，第 4 级表中索引为 `511` 的条目被映射到了物理帧`4 KiB`，也就是这个 4 级表它本身。\n\n当 CPU 在翻译地址的过程中跟随这个条目，它不会到达一个 3 级表，而是又到达同一个 4 级表。这类似于一个调用自身的递归函数，因此这个表被称为 *递归页表* 。需要注意的是，CPU 假定 4 级表中的每个条目都指向一个 3 级表，因此现在 CPU 将这个 4 级表视为一个 3 级表。这是可行的，因为在x86_64上，所有级别的页表的布局都完全相同。\n\n通过在开始实际转换之前进行一次或多次递归，我们可以有效地缩短CPU遍历的级别数。例如，如果我们只跟踪一次递归条目，然后进入 3 级表，则CPU认为 3 级表是 2 级表。更进一步，它将 2 级表视为 1 级表，1 级表视为映射的帧。这意味着我们现在可以读写1级页表，因为CPU认为它是映射的帧。下图说明了5个翻译步骤：\n\n![The above example 4-level page hierarchy with 5 arrows: \"Step 0\" from CR4 to level 4 table, \"Step 1\" from level 4 table to level 4 table, \"Step 2\" from level 4 table to level 3 table, \"Step 3\" from level 3 table to level 2 table, and \"Step 4\" from level 2 table to level 1 table.](https://os.phil-opp.com/paging-implementation/recursive-page-table-access-level-1.png)\n\n同样，在开始翻译之前，我们可以两次跟踪递归项，以将遍历级别的数量减少到两个：\n\n![The same 4-level page hierarchy with the following 4 arrows: \"Step 0\" from CR4 to level 4 table, \"Steps 1&2\" from level 4 table to level 4 table, \"Step 3\" from level 4 table to level 3 table, and \"Step 4\" from level 3 table to level 2 table.](https://os.phil-opp.com/paging-implementation/recursive-page-table-access-level-2.png)\n\n让我们一步步看：首先，CPU 根据 4 级表上的递归条目进行跳转，并认为它到达了一个 3 级表。然后，它再次进行递归，并认为它到达了一个 2 级表。但实际上，它仍然位于此 4 级表中。现在，CPU跟着另一个不同的条目跳转时，它将实际到达一个 3 级表，但 CPU 认为它已经到了一个 1 级表上。因此，当下一个条目指向2级表时，CPU 认为它指向一个被映射的帧。这使我们可以读写2级表。\n\n访问3级和4级表的工作方式相同。为了访问3级表，我们跟随递归条目进行了 3 次跳转，使CPU认为它已经在1级表中。然后，我们跟随另一个条目并到达第 3 级表，CPU将其视为映射帧。要访问4级表本身，我们只需遵循递归项四次，直到CPU将4级表本身视为映射帧（下图中的蓝色）。\n\n![The same 4-level page hierarchy with the following 3 arrows: \"Step 0\" from CR4 to level 4 table, \"Steps 1,2,3\" from level 4 table to level 4 table, and \"Step 4\" from level 4 table to level 3 table. In blue the alternative \"Steps 1,2,3,4\" arrow from level 4 table to level 4 table.](https://os.phil-opp.com/paging-implementation/recursive-page-table-access-level-3.png)\n\n你可能需要一点时间理清楚这些概念，但是它在实际中很有用。\n\n在下面的部分，我们将解释如何构建虚拟地址以方便进行一次或多次的递归。在我们实际的内核实现中我们不会使用递归页表，所以你可以不继续读下面这部分了。但如果你觉得有兴趣，可以点击“地址计算”以展开。\n\n<details>\n<summary> 地址计算 </summary>\n\n我们看到我们可以通过在实际翻译之前递归一次或多次来访问所有级别的表。 由于四个级别的表中的索引直接来自虚拟地址，因此我们需要为此技术构建特殊的虚拟地址。 请记住，页表索引是通过以下方式从地址中得到的：\n\n![Bits 0–12 are the page offset, bits 12–21 the level 1 index, bits 21–30 the level 2 index, bits 30–39 the level 3 index, and bits 39–48 the level 4 index](https://d33wubrfki0l68.cloudfront.net/55d00a7a89ddaf126f40bb1414de0d78fcde09e4/478a7/paging-introduction/x86_64-table-indices-from-address.svg)\n\n假设我们想要访问映射特定页面的1级页表。 如上所述，这意味着在继续使用4级，3级和2级索引之前，我们必须递归一次。 为此，我们将地址的每个块向右移动一个块，并将原始的4级索引设置为递归条目的索引：\n\n![Bits 0–12 are the offset into the level 1 table frame, bits 12–21 the level 2 index, bits 21–30 the level 3 index, bits 30–39 the level 4 index, and bits 39–48 the index of the recursive entry](https://os.phil-opp.com/advanced-paging/table-indices-from-address-recursive-level-1.svg)\n\n为了访问该页面的2级页表，我们将每个索引块向右移动两个块，并将原来的4级索引和原来的3级索引的块都设置为递归条目的索引：\n\n![Bits 0–12 are the offset into the level 2 table frame, bits 12–21 the level 3 index, bits 21–30 the level 4 index, and bits 30–39 and bits 39–48 are the index of the recursive entry](https://os.phil-opp.com/advanced-paging/table-indices-from-address-recursive-level-2.svg)\n\n访问3级表的方法是将每个块向右移动三个块，并使用原来的4级，3级和2级地址块的递归索引：\n\n![Bits 0–12 are the offset into the level 3 table frame, bits 12–21 the level 4 index, and bits 21–30, bits 30–39 and bits 39–48 are the index of the recursive entry](https://os.phil-opp.com/advanced-paging/table-indices-from-address-recursive-level-3.svg)\n\n最后，我们可以通过向右移动每个块四个块并使用除偏移之外的所有地址块的递归索引来访问4级表：\n\n![Bits 0–12 are the offset into the level l table frame and bits 12–21, bits 21–30, bits 30–39 and bits 39–48 are the index of the recursive entry](https://os.phil-opp.com/advanced-paging/table-indices-from-address-recursive-level-4.svg)\n\n我们现在可以计算所有四个级别的页表的虚拟地址。 我们甚至可以通过将其索引乘以8（页表条目的大小）来计算精确指向特定页表条目的地址。\n\n下表总结了访问不同类型帧的地址结构：\n\n|           | 虚拟地址的结构(八进制)           |\n| --------- | -------------------------------- |\n| 页        | `0o_SSSSSS_AAA_BBB_CCC_DDD_EEEE` |\n| 1级页表项 | `0o_SSSSSS_RRR_AAA_BBB_CCC_DDDD` |\n| 2级页表项 | `0o_SSSSSS_RRR_RRR_AAA_BBB_CCCC` |\n| 3级页表项 | `0o_SSSSSS_RRR_RRR_RRR_AAA_BBBB` |\n| 4级页表项 | `0o_SSSSSS_RRR_RRR_RRR_RRR_AAAA` |\n\n`AAA`是4级索引，`BBB`是3级索引，`CCC`是2级索引，`DDD`是映射帧的1级索引，而`EEEE`是偏移量。 `RRR`是递归条目的索引。 当索引（三位数）转换为偏移量（四位数）时，通过将其乘以8（页面表条目的大小）来完成。使用此偏移量，结果地址直接指向相应的页表条目。\n\n`SSSSSS`是符号扩展位，这意味着它们都是第47位的副本。这是x86_64体系结构上对有效地址的特殊要求。 我们在上一篇文章中解释过它。\n\n我们使用八进制数来表示地址，因为每个八进制字符代表三位，这使我们能够清楚地分离不同页表级别的9位索引。 对于每个字符代表四位的十六进制系统，这是不可能的。\n\n#### Rust代码\n\n要在Rust代码中构造这样的地址，可以使用按位操作：\n\n```rust\n// the virtual address whose corresponding page tables you want to access\nlet addr: usize = […];\n\nlet r = 0o777; // recursive index\nlet sign = 0o177777 << 48; // sign extension\n\n// retrieve the page table indices of the address that we want to translate\nlet l4_idx = (addr >> 39) & 0o777; // level 4 index\nlet l3_idx = (addr >> 30) & 0o777; // level 3 index\nlet l2_idx = (addr >> 21) & 0o777; // level 2 index\nlet l1_idx = (addr >> 12) & 0o777; // level 1 index\nlet page_offset = addr & 0o7777;\n\n// calculate the table addresses\nlet level_4_table_addr =\n    sign | (r << 39) | (r << 30) | (r << 21) | (r << 12);\nlet level_3_table_addr =\n    sign | (r << 39) | (r << 30) | (r << 21) | (l4_idx << 12);\nlet level_2_table_addr =\n    sign | (r << 39) | (r << 30) | (l4_idx << 21) | (l3_idx << 12);\nlet level_1_table_addr =\n    sign | (r << 39) | (l4_idx << 30) | (l3_idx << 21) | (l2_idx << 12);\n```\n\n上面的代码假定索引为`0o777`（511）的最后一个4级条目被递归映射。 目前情况并非如此，因此代码尚无法使用。 请参阅下文，了解如何告诉引导加载程序设置递归映射。\n\n除了手动执行按位运算，还可以使用`x86_64` crate的[`RecursivePageTable`](https://docs.rs/x86_64/0.7.5/x86_64/structures/paging/mapper/struct.RecursivePageTable.html)类型，该类型为各种页表操作提供安全的抽象。 例如，以下代码显示了如何将虚拟地址转换为其映射的物理地址：\n\n```rust\n// in src/memory.rs\n\nuse x86_64::structures::paging::{Mapper, Page, PageTable, RecursivePageTable};\nuse x86_64::{VirtAddr, PhysAddr};\n\n/// Creates a RecursivePageTable instance from the level 4 address.\nlet level_4_table_addr = […];\nlet level_4_table_ptr = level_4_table_addr as *mut PageTable;\nlet recursive_page_table = unsafe {\n    let level_4_table = &mut *level_4_table_ptr;\n    RecursivePageTable::new(level_4_table).unwrap();\n}\n\n\n/// Retrieve the physical address for the given virtual address\nlet addr: u64 = […]\nlet addr = VirtAddr::new(addr);\nlet page: Page = Page::containing_address(addr);\n\n// perform the translation\nlet frame = recursive_page_table.translate_page(page);\nframe.map(|frame| frame.start_address() + u64::from(addr.page_offset()))\n```\n\n同样，此代码需要有效的递归映射。 使用这种映射，可以像第一个代码示例中那样计算`level_4_table_addr`。\n\n</details>\n\n递归分页是一种有趣的技术，它向我们展示了一个页表中的映射可以非常有用。 它相对容易实现，只需要很少的设置（只需一个递归项），因此它是第一个分页实验的不错选择。\n\n但是，它也有一些缺点：\n\n- 它占用大量虚拟内存（512GiB）。 在较大的 48 位地址空间中，这不是一个大问题，但它可能导致非最优的缓存行为。\n- 它仅允许轻松访问当前活动的地址空间。 通过更改递归项仍然可以访问其他地址空间，但是需要临时映射才能切换回去。 我们在（过时的）“[重新映射内核](https://os.phil-opp.com/remap-the-kernel/#overview)”一文中描述了如何执行此操作。\n- 它在很大程度上依赖于 x86 的页表格式，可能无法在其他体系结构上使用。\n\n## Bootloader 支持\n\n所有这些方法都需要在初始化时对页表进行修改。 例如，需要创建物理内存的映射，或者需要递归映射一个 4 级表的条目。问题在于，如果没有现有的访问页表的方法，我们将无法创建这些必需的映射。\n\n这意味着我们需要引导加载程序的帮助——它创建内核运行的页表。引导加载程序有权访问页表，因此它可以创建我们需要的任何映射。在当前的实现中，`bootloader` crate支持上述两种方法，并通过 cargo fratures 进行控制：\n\n- `map_physical_memory` 功能将整个物理内存映射到虚拟地址空间中的某个位置。因此，内核可以访问所有物理内存，并且可以遵循 “映射完整物理内存” 方法。\n- 借助 `recursive_page_table` 功能，引导加载程序将递归映射一个 4 级页面表的条目。这允许内核按照“递归页面表”部分中的描述访问页面表。\n\n我们为内核选择第一种方法，因为它简单，平台无关且功能更强大（它还允许访问 *非页表帧*）。为了启用所需的引导程序支持，我们将`map_physical_memory`功能添加到了引导程序依赖项中：\n\n```toml\n[dependencies]\nbootloader = { version = \"0.8.0\", features = [\"map_physical_memory\"]}\n```\n\n启用此功能后，引导加载程序会将完整的物理内存映射到一些未使用的虚拟地址范围。 为了将虚拟地址范围传达给我们的内核，引导加载程序会传递一个 *引导信息* 结构。\n\n### 引导信息\n\n`bootloader` crate定义了一个[`BootInfo`](https://docs.rs/bootloader/0.3.11/bootloader/bootinfo/struct.BootInfo.html) 结构体，该结构包含传递给我们内核的所有信息。\n这个结构体仍处于早期阶段，因此如果日后升级为 [语义版本号不兼容](https://doc.rust-lang.org/stable/cargo/reference/specifying-dependencies.html#caret-requirements) 的版本时，可能会出现不向后兼容的情况。\n当启用 `map_physical_memory` 功能后，当前它具有两个字段 `memory_map` 和 `physical_memory_offset`：\n\n- `memory_map` 字段包含可用物理内存的概述。这告诉我们内核系统中有多少可用物理内存，以及哪些内存区域为 VGA 硬件等设备保留。内存映射可以从 BIOS 或 UEFI 固件中查询，但是只能在启动过程中的早期进行查询。出于这个原因，它必须由引导加载程序提供，因为内核无法在之后获取它。在本文的后面，我们将需要内存映射。\n- `physical_memory_offset` 告诉我们物理内存映射的虚拟起始地址。通过将此偏移量添加到物理地址，我们可以获得相应的虚拟地址。这使我们可以从内核访问任意物理内存。\n\n引导加载程序以 `_start` 函数的 `&'static BootInfo` 参数的形式将 `BootInfo` 结构体传递给我们的内核。我们尚未在函数中声明此参数，因此让我们添加一下：\n\n```rust\n// in src/main.rs\n\nuse bootloader::BootInfo;\n\n#[no_mangle]\npub extern \"C\" fn _start(boot_info: &'static BootInfo) -> ! { // new argument\n    […]\n}\n```\n\n在此之前我们不此参数不是问题，因为 x86_64 调用约定在 CPU 寄存器中传递第一个参数。 因此，如果不声明参数，这个参数会被忽略。 但是，如果我们不小心使用了错误的参数类型，那就有问题了，因为编译器不知道我们入口点函数的正确类型签名。\n\n### `entry_point`宏\n由于`_start`函数是从引导加载程序外部调用的，因此不会检查函数签名。 这意味着我们可以让它接受任意参数而没有任何编译错误，但是它将失败或在运行时导致未定义的行为。\n\n为了确保入口点函数始终具有引导程序期望的正确签名，`bootloader` crate提供了`entry_point`宏，该宏提供了类型检查的方式来将Rust函数定义为入口点。 让我们重写我们的入口点函数以使用此宏：\n\n```rust\n// in src/main.rs\n\nuse bootloader::{BootInfo, entry_point};\n\nentry_point!(kernel_main);\n\nfn kernel_main(boot_info: &'static BootInfo) -> ! {\n    […]\n}\n```\n\n我们不再需要在我们的入口点上使用`extern \"C\"`或`no_mangle`，因为该宏为我们定义了真正的下层`_start`入口点。 现在，`kernel_main`函数是一个完全正常的Rust函数，因此我们可以为其选择任意名称。 重要的是对它进行类型检查，以便在我们使用错误的函数签名时（例如通过添加参数或更改参数类型）发生编译错误。\n\n让我们在`lib.rs`中执行相同的更改：\n\n```rust\n// in src/lib.rs\n\n#[cfg(test)]\nuse bootloader::{entry_point, BootInfo};\n\n#[cfg(test)]\nentry_point!(test_kernel_main);\n\n/// Entry point for `cargo xtest`\n#[cfg(test)]\nfn test_kernel_main(_boot_info: &'static BootInfo) -> ! {\n    // like before\n    init();\n    test_main();\n    hlt_loop();\n}\n```\n\n由于入口点仅在测试模式下使用，因此我们将`＃[cfg(test)]`属性添加到所有项。 我们为测试入口点指定不同的名称`test_kernel_main`，以避免与main.rs的`kernel_main`混淆。 我们暂时不使用`BootInfo`参数，因此我们在参数名称前添加`_`以禁用\"未使用的变量\"警告。\n\n## 实现\n\n现在，我们可以访问物理内存了，我们终于可以开始实现页表代码了。 首先，我们来看看运行内核的当前活动页表。 在第二步中，我们将创建一个转换函数，该函数返回给定虚拟地址映射到的物理地址。 作为最后一步，我们将尝试修改页表以创建新的映射。\n\n在开始之前，我们为代码创建一个新的内存模块：\n\n```rust\n// in src/lib.rs\n\npub mod memory;\n```\n\n### 访问页表\n在上一篇文章的末尾，我们试图查看内核运行的页表，但是由于无法访问CR3寄存器指向的物理帧而失败。 现在，我们可以通过创建一个 `active_level_4_table` 函数来返回对活动4级页面表的引用，从而继续：\n\n```rust\n// in src/memory.rs\n\nuse x86_64::{\n    structures::paging::PageTable,\n    VirtAddr,\n};\n\n/// Returns a mutable reference to the active level 4 table.\n///\n/// This function is unsafe because the caller must guarantee that the\n/// complete physical memory is mapped to virtual memory at the passed\n/// `physical_memory_offset`. Also, this function must be only called once\n/// to avoid aliasing `&mut` references (which is undefined behavior).\npub unsafe fn active_level_4_table(physical_memory_offset: VirtAddr)\n    -> &'static mut PageTable\n{\n    use x86_64::registers::control::Cr3;\n\n    let (level_4_table_frame, _) = Cr3::read();\n\n    let phys = level_4_table_frame.start_address();\n    let virt = physical_memory_offset + phys.as_u64();\n    let page_table_ptr: *mut PageTable = virt.as_mut_ptr();\n\n    &mut *page_table_ptr // unsafe\n}\n```\n\n首先，我们从CR3寄存器中读取活动的4级表的物理帧。 然后，我们获取其物理起始地址，将其转换为u64，并将其与 `physical_memory_offset` 相加，以获取页表帧所映射的虚拟地址。 最后，我们通过 `as_mut_ptr` 方法将虚拟地址转换为`*mut PageTable` 原始指针，然后从中安全地创建 `&mut PageTable` 引用。 我们创建一个 `&mut` 引用而不是 `&` 引用，因为我们将在本文后面中对此页表进行可变操作。\n\n我们在这里不需要使用 unsafe 块，因为 Rust 将 `unsafe fn` 整个函数体都视作一个大的 `unsafe` 块。 这使我们的代码更加危险，因为我们可能在不注意的情况下意外引入了不安全的操作。 这也使发现不安全操作变得更加困难。 有一个 [RFC提案](https://github.com/rust-lang/rfcs/pull/2585) 希望可以更改此行为。\n\n现在，我们可以使用此函数来打印 4 级页表的条目：\n\n```rust\n// in src/main.rs\n\nfn kernel_main(boot_info: &'static BootInfo) -> ! {\n    use blog_os::memory::active_level_4_table;\n    use x86_64::VirtAddr;\n\n    println!(\"Hello World{}\", \"!\");\n    blog_os::init();\n\n    let phys_mem_offset = VirtAddr::new(boot_info.physical_memory_offset);\n    let l4_table = unsafe { active_level_4_table(phys_mem_offset) };\n\n    for (i, entry) in l4_table.iter().enumerate() {\n        if !entry.is_unused() {\n            println!(\"L4 Entry {}: {:?}\", i, entry);\n        }\n    }\n\n    // as before\n    #[cfg(test)]\n    test_main();\n\n    println!(\"It did not crash!\");\n    blog_os::hlt_loop();\n}\n```\n\n首先，我们 将`BootInfo` 结构的`physical_memory_offset` 转换为 `VirtAddr`，并将其传递给`active_level_4_table` 函数。 然后，我们使用 `iter` 函数对页表条目进行迭代，并使用 `enumerate` 组合子为每个元素添加索引 `i`。 我们仅打印非空条目，因为所有512个条目均无法显示在屏幕上。\n\n运行它时，我们看到以下输出：\n\n![QEMU printing entry 0 (0x2000, PRESENT, WRITABLE, ACCESSED), entry 1 (0x894000, PRESENT, WRITABLE, ACCESSED, DIRTY), entry 31 (0x88e000, PRESENT, WRITABLE, ACCESSED, DIRTY), entry 175 (0x891000, PRESENT, WRITABLE, ACCESSED, DIRTY), and entry 504 (0x897000, PRESENT, WRITABLE, ACCESSED, DIRTY)](https://os.phil-opp.com/paging-implementation/qemu-print-level-4-table.png)\n\n\n我们看到有各种非空条目，它们都映射到不同的3级表。 有这么多区域是因为内核代码，内核堆栈，物理内存映射和引导信息都使用隔开的内存区域。\n\n为了进一步遍历页表并查看 3 级表，我们可以将一个条目的映射到的帧再次转换为虚拟地址：\n\n```rust\n// in the `for` loop in src/main.rs\n\nuse x86_64::structures::paging::PageTable;\n\nif !entry.is_unused() {\n    println!(\"L4 Entry {}: {:?}\", i, entry);\n\n    // get the physical address from the entry and convert it\n    let phys = entry.frame().unwrap().start_address();\n    let virt = phys.as_u64() + boot_info.physical_memory_offset;\n    let ptr = VirtAddr::new(virt).as_mut_ptr();\n    let l3_table: &PageTable = unsafe { &*ptr };\n\n    // print non-empty entries of the level 3 table\n    for (i, entry) in l3_table.iter().enumerate() {\n        if !entry.is_unused() {\n            println!(\"  L3 Entry {}: {:?}\", i, entry);\n        }\n    }\n}\n```\n\n为了查看2级和1级表，我们对 3 级和 2 级条目重复该过程。 您可以想象，这很快就会变得非常冗长，因此我们在这里不显示完整的代码。\n\n手动遍历页表很有趣，因为它有助于了解CPU如何执行转换。 但是，大多数时候我们只对给定虚拟地址的映射物理地址感兴趣，因此让我们为其创建一个函数。\n\n### 地址转换\n为了将虚拟地址转换为物理地址，我们必须遍历四级页表，直到到达映射的帧。 让我们创建一个执行此转换的函数：\n\n```rust\n// in src/memory.rs\n\nuse x86_64::PhysAddr;\n\n/// Translates the given virtual address to the mapped physical address, or\n/// `None` if the address is not mapped.\n///\n/// This function is unsafe because the caller must guarantee that the\n/// complete physical memory is mapped to virtual memory at the passed\n/// `physical_memory_offset`.\npub unsafe fn translate_addr(addr: VirtAddr, physical_memory_offset: VirtAddr)\n    -> Option<PhysAddr>\n{\n    translate_addr_inner(addr, physical_memory_offset)\n}\n```\n\n我们将该函数转发给安全的`translate_addr_inner`函数，以限制 `unsafe` 的范围。 如上所述，Rust 将 `unsafe fn` 的整个函数体视为一个大的 `unsafe` 块。 通过调用私有safe函数，我们使每个 `unsafe` 操作是显式的。\n\n内部私有函数包含实际的实现：\n\n```rust\n// in src/memory.rs\n\n/// Private function that is called by `translate_addr`.\n///\n/// This function is safe to limit the scope of `unsafe` because Rust treats\n/// the whole body of unsafe functions as an unsafe block. This function must\n/// only be reachable through `unsafe fn` from outside of this module.\nfn translate_addr_inner(addr: VirtAddr, physical_memory_offset: VirtAddr)\n    -> Option<PhysAddr>\n{\n    use x86_64::structures::paging::page_table::FrameError;\n    use x86_64::registers::control::Cr3;\n\n    // read the active level 4 frame from the CR3 register\n    let (level_4_table_frame, _) = Cr3::read();\n\n    let table_indexes = [\n        addr.p4_index(), addr.p3_index(), addr.p2_index(), addr.p1_index()\n    ];\n    let mut frame = level_4_table_frame;\n\n    // traverse the multi-level page table\n    for &index in &table_indexes {\n        // convert the frame into a page table reference\n        let virt = physical_memory_offset + frame.start_address().as_u64();\n        let table_ptr: *const PageTable = virt.as_ptr();\n        let table = unsafe {&*table_ptr};\n\n        // read the page table entry and update `frame`\n        let entry = &table[index];\n        frame = match entry.frame() {\n            Ok(frame) => frame,\n            Err(FrameError::FrameNotPresent) => return None,\n            Err(FrameError::HugeFrame) => panic!(\"huge pages not supported\"),\n        };\n    }\n\n    // calculate the physical address by adding the page offset\n    Some(frame.start_address() + u64::from(addr.page_offset()))\n}\n```\n\n我们不再重用我们的 `active_level_4_table` 函数，而是再次从`CR3`寄存器读取4级帧。我们这样做是因为它简化了此原型的实现。不用担心，我们稍后会创建一个更好的解决方案。\n\n`VirtAddr` 结构已经提供了将索引计算到四个级别的页表中的方法。我们将这些索引存储在一个小的数组中，因为它允许我们使用 `for` 循环遍历页表。在循环之外，我们记住最后访问的帧，以便稍后计算物理地址。 `frame` 变量在迭代时指向页表帧，并在最后一次迭代后（即在跟随1级条目之后）指向映射的帧。\n\n在循环内部，我们再次使用 `physical_memory_offset` 将帧转换为页表引用。 然后，我们读取当前页表的条目，并使用 `PageTableEntry::frame` 函数检索映射的帧。 如果条目未映射到帧，则返回 `None`。 如果条目映射了一个 `2MiB` 或`1GiB` 的huge页面，我们现在会 panic。\n\n让我们通过翻译一些地址来测试我们的翻译功能：\n\n```rust\n// in src/main.rs\n\nfn kernel_main(boot_info: &'static BootInfo) -> ! {\n    // new imports\n    use blog_os::memory::translate_addr;\n    use x86_64::VirtAddr;\n\n    […] // hello world and blog_os::init\n\n    let phys_mem_offset = VirtAddr::new(boot_info.physical_memory_offset);\n\n    let addresses = [\n        // the identity-mapped vga buffer page\n        0xb8000,\n        // some code page\n        0x201008,\n        // some stack page\n        0x0100_0020_1a10,\n        // virtual address mapped to physical address 0\n        boot_info.physical_memory_offset,\n    ];\n\n    for &address in &addresses {\n        let virt = VirtAddr::new(address);\n        let phys = unsafe { translate_addr(virt, phys_mem_offset) };\n        println!(\"{:?} -> {:?}\", virt, phys);\n    }\n\n    […] // test_main(), \"it did not crash\" printing, and hlt_loop()\n}\n```\n\n跑一下看看，我们可以看到如下输出：\n\n![0xb8000 -> 0xb8000, 0x201008 -> 0x401008, 0x10000201a10 -> 0x279a10, \"panicked at 'huge pages not supported'](https://os.phil-opp.com/paging-implementation/qemu-translate-addr.png)\n\n如预期的那样，恒等映射的地址 `0xb8000` 转换为相同的物理地址。代码页和堆栈页转换为不定的物理地址，这取决于引导加载程序如何为内核创建初始映射。值得注意的是，转换后的最后12位始终保持不变，这也应该是这样的，因为这些位是页面偏移量，不是转换的一部分。\n\n由于可以通过添加 `physical_memory_offset` 来访问每个物理地址，因此 `physical_memory_offset` 地址本身的转换应指向物理地址0。但是，转换失败了，因为该映射使用 huge页 来提高效率，这在我们的实现中尚不支持。\n\n### 使用 `OffsetPageTable`\n将虚拟地址转换为物理地址是OS内核中的常见任务，因此`x86_64` crate 为其提供了抽象。该实现已经支持 huge 页和其他几个页面表功能（除了 `translate_addr`），因此我们将在下面使用它，而不是向我们自己的实现添加 huge 页支持。\n\n此抽象的基础是定义各种页表映射功能的两个 trait：\n\n- `Mapper` trait 在页面大小上是通用的，并提供可在页面上操作的函数。例如：`translate_page` （将给定页转换为相同大小的帧）和 `map_to`（在页面表中创建新的映射）。\n- `MapperAllSizes` trait 意味着其实现者也同时为所有的页大小都实现 `Mapper`。此外，它提供了适用于多种页面大小的函数，例如 `translate_addr` 或常规的 `translate`。\n\ntrait 仅定义接口，它们不提供任何实现。当前，`x86_64` crate 提供了三种类型，根据不同的要求实现了这些 trait。\n`OffsetPageTable` 类型假定完整的物理内存以某个偏移量映射到虚拟地址空间。\n`MappedPageTable` 稍微灵活一些：它只需要将每个页表帧映射到可计算地址处的虚拟地址空间即可。\n最后，可以使用 `RecursivePageTable` 类型来通过递归页表访问页表帧。\n\n在我们的例子中，引导加载程序将完整的物理内存映射到由 `physical_memory_offset` 变量指定的虚拟地址，因此我们可以使用 `OffsetPageTable` 类型。要初始化它，我们在 `memory` 模块中创建一个新的 `init` 函数：\n\n```rust\nuse x86_64::structures::paging::OffsetPageTable;\n\n/// Initialize a new OffsetPageTable.\n///\n/// This function is unsafe because the caller must guarantee that the\n/// complete physical memory is mapped to virtual memory at the passed\n/// `physical_memory_offset`. Also, this function must be only called once\n/// to avoid aliasing `&mut` references (which is undefined behavior).\npub unsafe fn init(physical_memory_offset: VirtAddr) -> OffsetPageTable<'static> {\n    let level_4_table = active_level_4_table(physical_memory_offset);\n    OffsetPageTable::new(level_4_table, physical_memory_offset)\n}\n\n// make private\nunsafe fn active_level_4_table(physical_memory_offset: VirtAddr)\n    -> &'static mut PageTable\n{…}\n```\n\n该函数接受 `physical_memory_offset` 作为参数，并返回一个具有 `'static` 生命周期的新 `OffsetPageTable` 实例。这意味着这个实例在内核整个的运行时都有效。\n在函数主体中，我们首先调用 `active_level_4_table` 函数以获取一个对第 4 级页表的可变引用。接着，我们使用这个引用来调用 `OffsetPageTable::new` 函数。\n`new` 函数的第二个参数需要一个虚拟地址，使得虚拟地址空间从此处开始映射物理地址空间，也就是 `physical_memory_offset` 变量。\n\n从现在开始，仅应从 `init` 函数调用 `active_level_4_table` 函数。\n因为如果多次调用它，很容易导致同名可变引用，从而导致未定义行为（UB）。因此，我们通过删除 `pub` 说明符来使函数私有。\n\n现在，我们可以使用 `MapperAllSizes::translate_addr` 方法来代替我们自己的 `memory::translate_addr` 函数。我们只需要在 `kernel_main` 中更改几行：\n\n```rust\n// in src/main.rs\n\nfn kernel_main(boot_info: &'static BootInfo) -> ! {\n    // new: different imports\n    use blog_os::memory;\n    use x86_64::{structures::paging::MapperAllSizes, VirtAddr};\n\n    […] // hello world and blog_os::init\n\n    let phys_mem_offset = VirtAddr::new(boot_info.physical_memory_offset);\n    // new: initialize a mapper\n    let mapper = unsafe { memory::init(phys_mem_offset) };\n\n    let addresses = […]; // same as before\n\n    for &address in &addresses {\n        let virt = VirtAddr::new(address);\n        // new: use the `mapper.translate_addr` method\n        let phys = mapper.translate_addr(virt);\n        println!(\"{:?} -> {:?}\", virt, phys);\n    }\n\n    […] // test_main(), \"it did not crash\" printing, and hlt_loop()\n}\n```\n\n我们需要导入 `MapperAllSizes` trait 以使用它提供的 `translate_addr` 方法。\n\n现在运行它时，我们会看到与以前相同的翻译结果，不同之处在于 huge页翻译现在也可以工作：\n\n![0xb8000 -> 0xb8000, 0x201008 -> 0x401008, 0x10000201a10 -> 0x279a10, 0x18000000000 -> 0x0](https://os.phil-opp.com/paging-implementation/qemu-mapper-translate-addr.png)\n\n不出所料，`0xb8000` 的转换以及代码和堆栈地址与我们自己的转换功能相同。 此外，我们现在看到虚拟地址`physical_memory_offset` 映射到物理地址 `0x0`。\n\n通过使用 `MappedPageTable` 类型的转换函数，我们可以节省掉实现 huge 页的工作量。 我们现在还可以调用其他页函数了，例如 `map_to`，我们将在下一部分中使用。\n\n此时，我们不再需要 `memory::translate_addr` 函数，因此可以将其删除。\n\n### 创建一个新映射\n\n到目前为止，我们仅查看页面表，而没有进行任何修改。让我们通过为以前未映射的页面创建一个新的映射来更改它。\n\n我们将使用 `Mapper` trait 的 `map_to` 函数进行实现，因此让我们首先看一下该函数。 文档告诉我们，它接受四个参数：我们要映射的页面，该页面应映射到的帧，页表项的一组标记（flags）以及一个 `frame_allocator`（帧分配器）。我们需要一个帧分配器，因为映射给定页面可能需要创建其他页表，这些页表需要未使用的帧作为后备存储。\n\n#### `create_example_mapping` 函数\n\n我们实现的第一步是创建一个新的 `create_example_mapping` 函数，该函数将给定的虚拟页面映射到 `0xb8000`（VGA文本缓冲区的物理帧）。我们选择该帧是因为它使我们能够轻松测试映射是否正确创建：我们只需要向新映射的页面写入，然后查看是否看到写入内容出现在屏幕上。\n\n`create_example_mapping`函数如下所示：\n\n```rust\n// in src/memory.rs\n\nuse x86_64::{\n    PhysAddr,\n    structures::paging::{Page, PhysFrame, Mapper, Size4KiB, FrameAllocator}\n};\n\n/// Creates an example mapping for the given page to frame `0xb8000`.\npub fn create_example_mapping(\n    page: Page,\n    mapper: &mut OffsetPageTable,\n    frame_allocator: &mut impl FrameAllocator<Size4KiB>,\n) {\n    use x86_64::structures::paging::PageTableFlags as Flags;\n\n    let frame = PhysFrame::containing_address(PhysAddr::new(0xb8000));\n    let flags = Flags::PRESENT | Flags::WRITABLE;\n\n    let map_to_result = unsafe {\n        mapper.map_to(page, frame, flags, frame_allocator)\n    };\n    map_to_result.expect(\"map_to failed\").flush();\n}\n```\n\n除了应该映射到的 `page` 之外，该函数还需要一个对 `OffsetPageTable` 实例的可变引用，和一个 `frame_allocator`。\n`frame_allocator` 参数使用 `impl Trait` 语法以定义一个泛型函数来支持所有实现了 `FrameAllocator` 的参数类型。\n`FrameAllocator` trait 也是一个泛型，接受实现了 `PageSize` trait 的类型，以同时支持 4KiB 大小的页和 2MiB/1GiB 的页。\n这里我们只想创建 4KiB 大小的映射，因此我们设置泛型的参数为 `Size4KiB`。\n\n`map_to` 方法被标记为 unsafe 的，因此调用者必须确保帧现在没有被使用。其原因是如果映射了同一个帧两次会导致未定义行为，例如两个不同的 `&mut` 引用指向了同一个物理地址。在我们这个例子中，我们重新使用 VGA 文字缓冲区帧，它已经被映射过了，我们破坏了调用条件。但是，`create_example_mapping` 函数只是一个我们用来临时测试的函数，我们马上将会删除它。为了提醒我们这个不安全因素，我们加上一句 `FIXME` 注释。\n\n除了 `page` 和 `unused_frame` 参数，`map_to` 方法还接受一组 flags 和一个 `frame_allcator` 的引用，我们马上就会解释。对于这组 flags，我们设置 `PRESENT`，因为对于所有有效的条目它都是需要的；设置 `WRITABLE` 以使得被映射的页可写。查看所有可能的 flags，查看上一篇文章的“页面表格式”部分。\n\n`map_to`函数可能会失败，因此它将返回`Result`。由于这只是一些示例代码，不需要鲁棒性，因此我们直接在发生错误时使用`expect` 来引发一个panic。成功后，该函数将返回 `MapperFlush` 类型，该类型提供了一种使用其 `flush` 方法从转换后备缓冲区（TLB）中刷新新映射页面的简便方法。像 `Result` 一样，当我们意外忘记使用它时，由于使用了`#[must_use]`属性，会发出一个警告。\n\n#### 一个虚拟的 FrameAllocator\n\n为了能够调用`create_example_mapping`，我们需要创建一个首先实现`FrameAllocator` Trait的类型。如上所述，如果`map_to`需要帧，则Trait负责为新页表分配帧。\n\n让我们从简单的案例开始，并假设我们不需要创建新的页表。对于这种情况，始终返回`None`的帧分配器就足够了。我们创建了一个`EmptyFrameAllocator`来测试我们的映射功能：\n\n```rust\n// in src/memory.rs\n\n/// A FrameAllocator that always returns `None`.\npub struct EmptyFrameAllocator;\n\nunsafe impl FrameAllocator<Size4KiB> for EmptyFrameAllocator {\n    fn allocate_frame(&mut self) -> Option<PhysFrame> {\n        None\n    }\n}\n```\n\n实现 `FrameAllocator` 是 unsafe 的，因为实现者必须保证分配器仅返回未使用的帧。 否则可能会发生不确定的行为，例如，当两个虚拟页面映射到同一物帧时。 我们的 `EmptyFrameAllocator` 只返回 `None`，因此在这种情况下这不是问题。\n\n#### 选择虚拟页面\n\n现在，我们有了一个简单的帧分配器，可以将其传递给 `create_example_mapping` 函数。 但是，分配器始终返回`None`，因此只有在不需要其他页表帧来创建映射时，此分配器才起作用。 要了解何时需要其他页表帧以及何时不需要，我们考虑一个示例：\n\n![A virtual and a physical address space with a single mapped page and the page tables of all four levels](https://os.phil-opp.com/paging-implementation/required-page-frames-example.svg)\n\n该图在左侧显示虚拟地址空间，在右侧显示物理地址空间，在中间显示页表。页表存储在物理内存帧中，由虚线表示。虚拟地址空间在地址 `0x803fe00000` 包含一个被映射的页，以蓝色标记。为了将此页转换为其对应的帧，CPU遍历4级页表，直到到达地址36 KiB 的帧。\n\n此外，该图以红色显示VGA文本缓冲区的物理帧。我们的目标是使用我们的 `create_example_mapping` 函数将一个先前未映射的虚拟页映射到此帧。由于 `EmptyFrameAllocator` 始终返回 `None`，因此我们要创建一个不需要分配器中的其他帧的映射。这取决于我们为映射选择的虚拟页。\n\n该图显示了虚拟地址空间中的两个候选页面，均以黄色标记。一页位于地址 `0x803fdfd000`，即映射页之前的3页（蓝色）。尽管第4级和第3级页表索引与蓝页相同，但第2级和第1级索引却不同（请参阅上一篇文章）。级别2表中的索引不同，意味着此页面使用了不同的级别1表。由于此1级表尚不存在，因此如果我们为示例映射选择该页面，则需要创建该表，这将需要一个额外的未使用的物理帧。相反，位于地址 `0x803fe02000` 的第二个候选页面不存在此问题，因为它使用与蓝色页面相同的1级页面表。因此，所有必需的页表已经存在。\n\n总而言之，创建新映射的难度取决于我们要映射的虚拟页面。在最简单的情况下，该页面的1级页面表已经存在，我们只需要编写一个条目即可。在最困难的情况下，该页面位于尚不存在第3级的内存区域中，因此我们需要首先创建新的第3级，第2级和第1级页表。\n\n为了使用 `EmptyFrameAllocator` 调用 `create_example_mapping` 函数，我们需要选择一个页面，其所有页表均已存在。要找到这样的页面，我们可以利用引导加载程序将自身加载到虚拟地址空间的第一个兆字节中这一事实。这意味着该区域的所有页面都存在一个有效的1级表。因此，我们可以为示例映射选择该存储区域中任何未使用的页面，例如地址 `0` 的页。\n通常，该页面应保持未使用状态，以确保取消引用空指针会引发一个 页错误（page fault）。因此我们知道引导加载程序保留了该页未映射。\n\n#### 创建映射\n\n现在，我们有了用于调用 `create_example_mapping` 函数的所有必需参数，因此让我们修改 `kernel_main` 函数，以将页面映射到虚拟地址 0。由于我们将页面映射到VGA文本缓冲区的帧，因此我们应该能够向屏幕写入。实现看起来像这样：\n\n```rust\n// in src/main.rs\n\nfn kernel_main(boot_info: &'static BootInfo) -> ! {\n    use blog_os::memory;\n    use x86_64::{structures::paging::Page, VirtAddr}; // new import\n\n    […] // hello world and blog_os::init\n\n    let phys_mem_offset = VirtAddr::new(boot_info.physical_memory_offset);\n    let mut mapper = unsafe { memory::init(phys_mem_offset) };\n    let mut frame_allocator = memory::EmptyFrameAllocator;\n\n    // map an unused page\n    let page = Page::containing_address(VirtAddr::new(0));\n    memory::create_example_mapping(page, &mut mapper, &mut frame_allocator);\n\n    // write the string `New!` to the screen through the new mapping\n    let page_ptr: *mut u64 = page.start_address().as_mut_ptr();\n    unsafe { page_ptr.offset(400).write_volatile(0x_f021_f077_f065_f04e)};\n\n    […] // test_main(), \"it did not crash\" printing, and hlt_loop()\n}\n```\n\n我们首先通过调用 `create_example_mapping` 函数来调用地址 `0` 处的页面的映射。 这会将页面映射到 VGA 文本缓冲区帧，因此我们应该在屏幕上看到对其进行的写入。\n\n然后，我们将页面转换为原始指针，并向偏移量 `400` 写入一个值。我们不写入页面的开头，因为VGA缓冲区的第一行直接由下一个 `println` 移出屏幕。 我们写入值`0x_f021_f077_f065_f04e`，它表示字符串“ New！”。 在白色背景上。 正如我们在“ VGA Text Mode”（VGA文本模式）文章中所了解的那样，对VGA缓冲区的写入应该是易失的，因此我们使用`write_volatile` 方法。\n\n在 QEMU 中运行它时，将看到以下输出：\n\n![QEMU printing \"It did not crash!\" with four completely white cells in the middle of the screen](https://os.phil-opp.com/paging-implementation/qemu-new-mapping.png)\n\n屏幕上的 \"New!\" 是通过写入第 `0` 页来显示的，这意味着我们已在页表中成功创建了新映射。\n\n仅因为负责地址0的页面的1级表已经存在，所以创建该映射才起作用。 当我们尝试为尚不存在1级表的页面进行映射时，`map_to`函数将失败，因为它试图从 `EmptyFrameAllocator` 分配帧以创建新的页表。 当我们尝试映射页面 `0xdeadbeaf000` 而不是 `0` 时，我们可以看到这种情况：\n\n```rust\n// in src/main.rs\n\nfn kernel_main(boot_info: &'static BootInfo) -> ! {\n    […]\n    let page = Page::containing_address(VirtAddr::new(0xdeadbeaf000));\n    […]\n}\n```\n\n当我们运行它时，会出现以下错误消息：\n\n```rust\npanicked at 'map_to failed: FrameAllocationFailed', /…/result.rs:999:5\n```\n\n要映射没有 1 级页面表的页面，我们需要创建一个适当的`FrameAllocator`。 但是我们如何知道哪些帧未使用以及有多少物理内存可用？\n\n#### 分配帧\n为了创建新的页表，我们需要创建一个适当帧分配器。 为此，我们使用 `memory_map`，它由引导程序作为 `BootInfo` 结构的一部分传递：\n\n```rust\n// in src/memory.rs\n\nuse bootloader::bootinfo::MemoryMap;\n\n/// A FrameAllocator that returns usable frames from the bootloader's memory map.\npub struct BootInfoFrameAllocator {\n    memory_map: &'static MemoryMap,\n    next: usize,\n}\n\nimpl BootInfoFrameAllocator {\n    /// Create a FrameAllocator from the passed memory map.\n    ///\n    /// This function is unsafe because the caller must guarantee that the passed\n    /// memory map is valid. The main requirement is that all frames that are marked\n    /// as `USABLE` in it are really unused.\n    pub unsafe fn init(memory_map: &'static MemoryMap) -> Self {\n        BootInfoFrameAllocator {\n            memory_map,\n            next: 0,\n        }\n    }\n}\n```\n\n该结构有两个字段：对引导加载程序传递的内存映射的 `'static` 引用，以及一个跟踪分配器应返回的下一帧的编号的`next`字段。\n\n如我们在“引导信息”部分所述，内存映射由BIOS / UEFI固件提供。它只能在引导过程的早期被查询，因此引导加载程序已经为我们调用了相应的函数。内存映射由 `MemoryRegion` 结构的列表组成，这些结构包含每个存储器区域的起始地址，长度和类型（例如未使用，保留等）。\n\n`init` 函数使用给定的内存映射初始化一个 `BootInfoFrameAllocator`。`next` 字段用 `0` 初始化，并且将在每次帧分配时递增，以避免两次返回同一帧。由于我们不知道内存映射的可用帧是否已在其他地方使用，因此我们的 `init` 函数必须为 `unsafe` 才能要求调用者提供额外的保证。\n\n#### `usable_frames`方法\n\n在实现`FrameAllocator`特性之前，我们添加了一个辅助方法，该方法将内存映射转换为可用帧的迭代器：\n\n```rust\n// in src/memory.rs\n\nuse bootloader::bootinfo::MemoryRegionType;\n\nimpl BootInfoFrameAllocator {\n    /// Returns an iterator over the usable frames specified in the memory map.\n    fn usable_frames(&self) -> impl Iterator<Item = PhysFrame> {\n        // get usable regions from memory map\n        let regions = self.memory_map.iter();\n        let usable_regions = regions\n            .filter(|r| r.region_type == MemoryRegionType::Usable);\n        // map each region to its address range\n        let addr_ranges = usable_regions\n            .map(|r| r.range.start_addr()..r.range.end_addr());\n        // transform to an iterator of frame start addresses\n        let frame_addresses = addr_ranges.flat_map(|r| r.step_by(4096));\n        // create `PhysFrame` types from the start addresses\n        frame_addresses\n            .map(|addr|PhysFrame::containing_address(PhysAddr::new(addr)))\n    }\n}\n\n```\n\n此函数使用迭代器组合子方法将初始 `MemoryMap` 转换为可用物理帧的迭代器：\n\n- 首先，我们调用 `iter` 方法将内存映射转换为 `MemoryRegions` 的迭代器。\n- 然后，我们使用 `filter` 方法跳过任何保留的区域或其他不可用的区域。引导加载程序会为其创建的所有映射更新内存映射，因此内核使用的帧（代码，数据或堆栈）或用于存储引导信息的帧已被标记为 `InUse` 或类似的。因此，我们可以确定 `Usable` 帧没有在其他地方使用。\n- 之后，我们使用 `map` 组合子和Rust的range语法将内存区域的迭代器转换为地址范围的迭代器。\n- 下一步是最复杂的：我们通过 `into_iter` 方法将每个范围转换为一个迭代器，然后使用 `step_by` 隔 4096 选择范围内的每个地址。由于页面大小为4096字节（= 4 KiB），因此我们获得了每个帧的起始地址。 Bootloader 页面会对齐所有可用的内存区域，因此我们在此处不需要任何对齐或舍入代码。通过使用 `flat_map` 而不是 `map`，我们得到了 `Iterator <Item = u64>` 而不是 `Iterator <Item = Iterator <Item = u64 >>`。\n- 最后，我们将起始地址转换为 `PhysFrame` 类型，以构造所需的 `Iterator <Item = PhysFrame>`。然后，我们使用此迭代器创建并返回一个新的 `BootInfoFrameAllocator`。\n  \n该函数的返回类型使用 `impl Trait` 功能。\n这样一来，我们可以指出我们返回了一种类型，其实现了 `Iterator` trait，item 类型为 `PhysFram`，而不需要命名具体的返回类型。这一点很重要，因为我们无法命名具体类型，因为它取决于不可命名的闭包类型。\n\n#### 实现 `FrameAllocator` Trait\n\n现在我们可以实现`FrameAllocator` trait：\n\n```rust\n// in src/memory.rs\n\nunsafe impl FrameAllocator<Size4KiB> for BootInfoFrameAllocator {\n    fn allocate_frame(&mut self) -> Option<PhysFrame> {\n        let frame = self.usable_frames().nth(self.next);\n        self.next += 1;\n        frame\n    }\n}\n```\n\n我们首先使用 `usable_frames` 方法从内存映射中获取可用帧的迭代器。 然后，我们使用 `Iterator::nth` 函数获取索引为 `self.next` 的帧（从而跳过 `(self.next-1)` 帧）。 在返回该帧之前，我们将`self.next`增加一，以便在下一次调用时返回下一个帧。\n\n这种实现方式并不是十分理想，因为它会在每次分配时都重新创建 `usable_frame` 分配器。 最好直接将迭代器存储为`struct` 字段。 然后，我们将不需要 `nth` 方法，而只需对每个分配调用 `next`。 这种方法的问题在于，当前无法在`struct` 字段中存储 `impl Trait` 类型。等将来完全实现了 [具名存在性类型](https://github.com/rust-lang/rfcs/pull/2071) ，这个方法可能可以使用。\n\n#### 使用`BootInfoFrameAllocator`\n\n现在，我们可以修改 `kernel_main` 函数，以传递 `BootInfoFrameAllocator` 实例而不是 `EmptyFrameAllocator`：\n\n```rust\n// in src/main.rs\n\nfn kernel_main(boot_info: &'static BootInfo) -> ! {\n    use blog_os::memory::BootInfoFrameAllocator;\n    […]\n    let mut frame_allocator = unsafe {\n        BootInfoFrameAllocator::init(&boot_info.memory_map)\n    };\n    […]\n}\n```\n\n使用引导信息帧分配器，映射成功了，并且我们看到了黑白“ New！” 再次出现在屏幕上。 在后台，`map_to` 方法通过以下方式创建缺少的页表：\n\n- 从传递的 `frame_allocator` 中分配未使用的帧。\n- 将帧内容全部设置为 `0` 以创建一个新的空页表。\n- 将更高级别的表的条目映射到该帧。\n- 继续下一个表格级别。\n\n尽管我们的 `create_example_mapping` 函数只是一些示例代码，但我们现在能够为任意页面创建新的映射。 这对于在以后的帖子中分配内存或实现多线程至关重要。\n\n## 总结\n\n在这篇文章中，我们了解了访问页表物理帧的各种技术，包括恒等映射，完整物理内存的映射，临时映射和递归页表。 我们选择映射完整的物理内存，因为它简单，可移植且功能强大。\n\n没有页表访问权限，我们无法映射内核中的物理内存，因此我们需要引导加载程序的支持。 `bootloader` crate 支持通过可选的 cargo features 创建所需的映射。 它将所需信息以 `&BootInfo` 参数的形式传递给我们的内核入口函数。\n\n对于我们的实现，我们首先手动遍历页表以实现地址翻译功能，然后使用 `x86_64` crate 的 `MappedPageTable` 类型。 我们还学习了如何在页表中创建新的映射，以及如何在引导加载程序传递的内存映射之上创建必要的 `FrameAllocator`。\n\n## 接下来？\n\n下一篇文章将为我们的内核创建一个堆内存区域，这将使我们能够分配内存并使用各种集合类型。\n"
        },
        {
          "name": "10-heap-allocation.md",
          "type": "blob",
          "size": 65.392578125,
          "content": "---\ntitle: 分配堆内存\ndate: 2019-09-29 09:45:40\ntags: [Memory Management]\nsummary: 这篇文章为我们的内核增加了对堆分配的支持。 首先，它介绍了动态内存，并展示了借用检查器如何防止常见的分配错误。 然后，它实现Rust的基本分配接口，创建一个堆内存区域，并设置一个分配器crate。 在这篇文章的结尾，内置分配crate的所有分配和收集类型将对我们的内核可用。\n---\n\n这篇文章为我们的内核增加了对堆分配的支持。 首先，它介绍了动态内存，并展示了借用检查器如何防止常见的分配错误。 然后，它实现Rust的基本分配接口，创建一个堆内存区域，并设置一个分配器crate。 在这篇文章的结尾，内置分配crate的所有分配和收集类型将对我们的内核可用。\n\n该博客在[GitHub上](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://github.com/phil-opp/blog_os&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhh6KGm1hLx2QlIFubK_gEmxif3aHg)公开开发。 此文章的完整源代码可以在[`post-10`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://github.com/phil-opp/blog_os/tree/post-10&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhijyi0qw7SN36BGwlhAbAJ_nMofiA)分支中找到。\n\n## 局部和静态变量\n\n当前，我们在内核中使用两种类型的变量：局部变量和`static`变量。 局部变量存储在[调用堆栈](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://en.wikipedia.org/wiki/Call_stack&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhiDjrmAp1RMPlkX43yI6cMjfgQlEg)中，并且仅在所在的函数返回之前才有效。 静态变量存储在固定的内存位置，并且在程序的整个生命周期中始终有效。\n\n### 局部变量\n\n局部变量存储在[调用堆栈中](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://en.wikipedia.org/wiki/Call_stack&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhiDjrmAp1RMPlkX43yI6cMjfgQlEg) ， [调用堆栈](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://en.wikipedia.org/wiki/Call_stack&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhiDjrmAp1RMPlkX43yI6cMjfgQlEg)是支持`push`和`pop`操作的[堆栈数据结构](https://en.wikipedia.org/wiki/Stack_(abstract_data_type)) 。 在每个函数里，编译器会将被调用函数的参数，返回地址和局部变量压入栈中：\n\n![An outer() and an inner(i: usize) function. Both have some local variables. Outer calls inner(1). The call stack contains the following slots: the local variables of outer, then the argument i = 1, then the return address, then the local variables of inner.](https://os.phil-opp.com/heap-allocation/call-stack.svg)\n\n上面的示例显示了`inner`函数被`outer`函数调用之后的调用堆栈。 我们看到调用堆栈首先包含了`outer`的局部变量。 在`inner`调用中，参数`1`和函数的返回地址被压入栈中。 然后将控制权转移到`inner` ，从而开始压入其局部变量。\n\n`inner`函数返回后，将弹出其调用堆栈的一部分，仅保留`outer`函数的局部变量：\n\n我们看到`inner`的局部变量仅在函数返回之前有效。 当我们使用某个值太久时，例如当我们尝试返回对局部变量的引用时，Rust编译器会强制检查这些生命周期并引发错误：\n\n```rust\nfn inner(i: usize) -> &'static u32 {\n    let z = [1, 2, 3];\n    &z[i]\n}\n```\n\n（[在Playground中运行示例](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://play.rust-lang.org/%3Fversion%3Dstable%26mode%3Ddebug%26edition%3D2018%26gist%3D6186a0f3a54f468e1de8894996d12819&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhhcWnAktOoWRK84k152ti4sf_VPhQ)）\n\n虽然在此示例中返回引用毫无意义，但在某些情况下，我们希望变量的寿命比函数更长。 当我们尝试[加载中断描述符表](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://os.phil-opp.com/cpu-exceptions/&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhgwRvWr9gSPjeJgzsv7l7wShMNucg#loading-the-idt)并不得不使用`static`变量来延长生存期时，我们已经在内核中看到了这种情况。\n\n### 静态变量\n\n静态变量存储在与堆栈分开的固定内存位置。 链接器在编译时分配了此存储位置，并编码在了可执行文件中。 静态变量在程序的完整运行时中都有效，因此它们具有`'static`生命周期，并且始终可以从局部变量中进行引用：\n\n\n\n![The same outer/inner example with the difference that inner has a static Z: [u32; 3] = [1,2,3]; and returns a &Z[i] reference](https://os.phil-opp.com/heap-allocation/call-stack-static.svg)\n\n在上面的示例中，当`inner`函数返回时，它的部分调用堆栈被销毁。静态变量位于一个不会被销毁的单独的内存范围内，因此`&Z[1]`引用在返回后仍然有效。\n\n除了`'static`生命周期之外，静态变量还具有有用的属性：它们的位置在编译时确定，因此不需要引用即可访问它。 我们为`println`宏利用了该属性：通过在内部使用[静态`Writer`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://os.phil-opp.com/vga-text-mode/&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhjKVQ-rVdxu77flCvGVy5Fx-CA02w#a-global-interface) ，不需要`&mut Writer`引用即可调用该宏，这在我们无法访问任何其他变量的[异常处理程序](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://os.phil-opp.com/cpu-exceptions/&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhgwRvWr9gSPjeJgzsv7l7wShMNucg#implementation)中非常有用。\n\n但是，静态变量的此属性带来一个关键的缺点：默认情况下，它们是只读的。 Rust之所以要这样做是因为，例如，如果两个线程同时修改一个静态变量，则会发生[数据争用](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/nomicon/races.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhjYe_MLT6P-PIV2jWQnPjP6WbgrPQ) 。 修改静态变量的唯一方法是将其封装为[`Mutex`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/spin/0.5.2/spin/struct.Mutex.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhiPigEeaETYxRVwZpm59ZJfQBqK7w)类型，以确保在任何时间点仅存在一个`&mut`引用。 我们已经为[静态VGA缓冲区`Writer`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://os.phil-opp.com/vga-text-mode/&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhjKVQ-rVdxu77flCvGVy5Fx-CA02w#spinlocks)使用了`Mutex` 。\n\n## 动态内存\n\n局部变量和静态变量已经非常强大，可以满足大部分场合的要求。 但是，我们看到它们都有局限性：\n\n- 局部变量仅在所在函数或块结束之前有效。 这是因为它们存在于调用堆栈中，并在所在的函数返回后销毁。\n- 静态变量在程序运行时始终有效，因此无法在不再需要时回收和重用其内存。 而且，它们的所有权语义不明确，并且可以从所有函数中访问，因此，当我们要修改它们时，需要使用[`Mutex`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/spin/0.5.2/spin/struct.Mutex.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhiPigEeaETYxRVwZpm59ZJfQBqK7w)进行保护。\n\n局部和静态变量的另一个限制是它们具有固定的大小。 因此，当添加更多元素时，它们将无法存储动态增长的集合。 （Rust中有一些关于建议使用[未确定](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://github.com/rust-lang/rust/issues/48055&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhhs9Pf2O2O5WPZ-Xvlj1DibDpm-Rg)大小的[右值](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://github.com/rust-lang/rust/issues/48055&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhhs9Pf2O2O5WPZ-Xvlj1DibDpm-Rg)的建议，该值允许动态大小的局部变量，但它们仅在某些特定情况下有效。）\n\n为了避免这些缺点，编程语言通常支持第三个内存区域：**堆 **来存储变量。 堆通过两个称为`allocate`和`deallocate`函数在运行时支持*动态内存分配* 。 它以以下方式工作： `allocate`函数返回指定大小的可用内存块，可用于存储变量。 然后，该变量将一直存在，直到通过调用对该变量的引用的`deallocate`函数将其`deallocate`为止。\n\n让我们来看一个例子：\n\n![The inner function calls allocate(size_of([u32; 3])), writes z.write([1,2,3]);, and returns (z as *mut u32).offset(i). The outer function does deallocate(y, size_of(u32)) on the returned value y.](https://os.phil-opp.com/heap-allocation/call-stack-heap.svg)\n\n在这里， `inner`函数使用堆内存而不是静态变量来存储`z` 。 它首先分配所需大小的内存块，然后返回`*mut u8` [原始指针](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/book/ch19-01-unsafe-rust.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhgxBivPXeHGd4Lv7ZRfhxcOwPp25w#dereferencing-a-raw-pointer) 。 然后，它使用[`ptr::write`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/core/ptr/fn.write.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhhGBOZaaa9afSHJ_T9_KNkhBtR70w)方法将数组`[1,2,3]`写入其中。 在最后一步中，它使用[`offset`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/std/primitive.pointer.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhjoDpBUUAFPMkakB2aev8GBAmlz1A#method.offset)函数计算指向第`i`个元素的指针，然后将其返回。 （请注意，为简洁起见，我们在此示例函数中省略了一些必需的强制转换和unsafe块。）\n\n分配的内存将一直存在，直到通过调用`deallocate`显式释放它为止。 因此，即使在`inner`返回并且调用栈的一部分被销毁之后，返回的指针仍然有效。 与静态内存相比，使用堆内存的优势在于，可以在释放内存后重用内存，这是通过`deallocate`中的`deallocate`调用实现的。 调用之后，情况如下：\n\n![The call stack contains the local variables of outer, the heap contains z[0] and z[2], but no longer z[1].](https://os.phil-opp.com/heap-allocation/call-stack-heap-freed.svg)\n\n我们看到`z[1]`的位置上又是空闲的了，可以重新用于下一个`allocate`调用。 但是，我们也看到`z[0]`和`z[2]`没有被释放，因为我们从未释放过它们。 这种错误称为*内存泄漏* ，通常是导致程序过度消耗内存的原因（试想一下，当我们在循环中重复调用`inner`时会发生什么）。 这看起来很糟糕，但是动态分配还可能会发生更多危险的错误类型。\n\n### 常见错误\n\n除了不幸的但不会使程序容易受到攻击的内存泄漏外，还有两种常见的错误类型，其后果更为严重：\n\n- 当我们在调用`deallocate`后意外地继续使用变量时，我们有一个所谓的**use-after-free**漏洞。这样的错误会导致未定义的行为，并且攻击者经常会利用它执行任意代码。\n- 当我们不小心两次释放变量时，我们就有一个**double-free**漏洞。它可能在第一次`deallocate`调用之后释放在同一位置分配的另一个变量。 因此，它可能导致use-after-free漏洞。\n\n这些类型的漏洞是众所周知的，因此人们可能会期望大家现在已经学会了如何避免它们。 但是，他们并没有，仍然经常发现此类漏洞，例如Linux中最近发现的[use-after-free漏洞](https://securityboulevard.com/2019/02/linux-use-after-free-vulnerability-found-in-linux-2-6-through-4-20-11/)允许任意代码执行。 这表明即使是最好的程序员也不一定总是能够正确处理复杂项目中的动态内存。\n\n为了避免这些问题，许多语言（例如Java或Python）都使用称为[*垃圾回收*](https://en.wikipedia.org/wiki/Garbage_collection_(computer_science))的技术自动管理动态内存。 这种方法让程序员永远不要手动调用`deallocate` 。 而是定期暂停程序并扫描未使用的堆变量，然后将它们自动释放。 因此，上述漏洞永远不会发生。 缺点是常规扫描的性能开销以及可能较长的暂停时间。\n\nRust针对此问题采用了不同的方法：它使用一种称为[*所有权*](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/book/ch04-01-what-is-ownership.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhiXg-xhyAHe5PuaeLsNN8Nsck3u9g)的概念，该概念能够在编译时检查动态内存操作的正确性。 因此，不需要垃圾收集来避免提到的漏洞，这意味着没有性能开销。 这种方法的另一个优点是，程序员仍然可以像使用C或C ++一样对动态内存的使用进行细粒度的控制。\n\n### Rust中的动态内存分配\n\nRust标准库提供了抽象类型来隐式调用这些函数，而不是让程序员手动调用`allocate`和`deallocate` 。 最重要的类型是[**Box**](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/std/boxed/index.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhgydQDRRu9l94xRKsKXfpC58IaGQQ) ，它是堆分配值的抽象。 它提供了一个[`Box::new`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/boxed/struct.Box.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhiALFCmMq4SQmt-_lR3sbOud4Zh8g#method.new)构造函数，该函数接受一个值，使用该值的大小调用`allocate` ，然后将该值移动到堆上新分配的插槽中。 为了再次释放堆内存， `Box`类型实现了[`Drop`特性](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/book/ch15-03-drop.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhiheLdRjZNyOmgfBOzki5tmpGGmEA)以在超出范围时调用`deallocate` ：\n\n```rust\n{\n    let z = Box::new([1,2,3]);\n    […]\n} // z goes out of scope and `deallocate` is called\n```\n\n此模式有一个奇怪的名称， [*资源获得即初始化*](https://en.wikipedia.org/wiki/Resource_acquisition_is_initialization) （或简称*RAII* ）。 它起源于C++，用于实现类似的抽象类型[`std::unique_ptr`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://en.cppreference.com/w/cpp/memory/unique_ptr&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhiqCXA9Qx4dEIWJLDL41o5wPIwCJg) 。\n\n单靠这种类型不足以防止所有的use-after-free漏洞，因为在`Box`超出范围并释放相应的堆内存空间之后，程序员仍然可以保留对内容的引用：\n\n```rust\nlet x = {\n    let z = Box::new([1,2,3]);\n    &z[1]\n}; // z goes out of scope and `deallocate` is called\nprintln!(\"{}\", x);\n```\n\n这就是Rust所有权机制起作用的地方。它为每个引用分配了抽象[生命周期](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/book/ch10-03-lifetime-syntax.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhheK8nR0_Zz4xow84YA4SkVmwPdbg) ，这是该引用有效的范围。 在上面的示例中， `x`引用是从`z`数组中获取的，因此在`z`超出范围后，它将变为无效。 在[Playgroud中运行上述示例时](https://play.rust-lang.org/?version=stable&mode=debug&edition=2018&gist=28180d8de7b62c6b4a681a7b1f745a48)，您会看到Rust编译器确实报告了错误：\n\n```shell\nerror[E0597]: `z[_]` does not live long enough\n --> src/main.rs:4:9\n  |\n2 |     let x = {\n  |         - borrow later stored here\n3 |         let z = Box::new([1,2,3]);\n4 |         &z[1]\n  |         ^^^^^ borrowed value does not live long enough\n5 |     }; // z goes out of scope and `deallocate` is called\n  |     - `z[_]` dropped here while still borrowed\n```\n\n一开始，这个错误提示可能会有些混乱。 创建一个值的引用被称为*借用*，因为它类似于现实生活中的借用：您可以临时访问某个对象，但需要在某个时候将其返回，并且不得销毁它。 通过检查所有借用在对象被销毁之前是否已结束，Rust编译器可以保证不会发生use-after-free。\n\nRust的所有权系统更进了一步，它不仅可以防止使用后使用的错误，而且可以像Java或Python这样的垃圾收集语言提供完全的[*内存安全性*](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://en.wikipedia.org/wiki/Memory_safety&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhiUSIOCdxW0QA2oZubgSMT-wZKM7Q) 。 另外，它保证[*线程安全*](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://en.wikipedia.org/wiki/Thread_safety&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhgl5oGZfFqc51TdoKgVrffZcKjSfg) ，Rust代码在多线程环境下比那些语言更安全。 最重要的是，所有这些检查都在编译时进行，因此与C中的手动内存管理相似，它没有运行时开销。\n\n### 用例\n\n现在我们知道Rust中动态内存分配的基础知识，但是什么时候应该使用它呢？ 没有动态内存分配的内核已经走得很远了，那么为什么现在需要它呢？\n\n首先，动态内存分配总是会带来一些性能开销，因为我们需要为每个分配在堆上找到一个空闲空间。 因此，通常最好使用局部变量，尤其是在性能敏感的内核代码中。 但是，在某些情况下，动态内存分配是最佳选择。\n\n基本规则是，具有动态生存期或可变大小的变量需要动态内存。 动态生存期最重要的类型是[**Rc**](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/rc/index.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhhOvikyjnB-QTtPny0gSuSLpF9Tkw) ，它对其包装值的引用进行计数，并在所有引用离开作用域后将其释放。另外一些具有可变大小的类型的示例包括[**Vec**](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/vec/index.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhhHCKQLyRM5nVe02J_5GfW_hJSj_g) ， [**String**](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/string/index.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhhxFOZSUCPDiU1gZFAW_5Q5bksW7A)等[集合类型](https://doc.rust-lang.org/alloc/collections/index.html) ，这些[类型](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/collections/index.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhihRW6JMQDicWS77B_50faSnHwSug)会在添加更多元素时动态增长。 这些类型的工作方式是在它们装满时重新分配一块更大的内存，将所有元素复制过来，然后取消掉旧的分配。\n\n对于我们的内核，我们最需要的是集合类型，例如，在以后的帖子中实现多任务处理时用于存储活动任务的列表。\n\n## 分配器接口\n\n实现堆分配器的第一步是添加对内置`alloc`crate的依赖。 与[`core`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/core/&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhiAG6dIvJgsOsusTaEqJeByp29mQA)crate一样，它是标准库的子集，另外还包含分配和集合类型。 为了添加对`alloc`的依赖，我们将以下内容添加到我们的`lib.rs`：\n\n```rust\n// in src/lib.rs\n\nextern crate alloc;\n```\n\n与其他依赖不同，我们不需要修改`Cargo.toml` 。 原因是`alloc`crate与Rust编译器一起作为标准库的一部分提供，因此我们只需要启用它即可。 这就是这个`extern crate`语句的作用。（历史上，所有依赖项都需要一个`extern crate`语句，该语句现在是可选的）。\n\n`#[no_std]`默认禁用了`alloc`crate，其原因是它还有其他要求。 现在尝试编译项目时，我们可以从错误中提示看到这些要求：\n\n```shell\nerror: no global memory allocator found but one is required; link to std or add\n       #[global_allocator] to a static item that implements the GlobalAlloc trait.\n\nerror: `#[alloc_error_handler]` function required, but not found\n```\n\n发生第一个错误是因为分配箱需要堆分配器，该堆分配器是提供`allocate`和`deallocate`功能的对象。 在Rust中，堆分配器由[`GlobalAlloc`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/alloc/trait.GlobalAlloc.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhja9Cla59NwkTNZAMz6PcSj4jN6wg)特性描述，该特性在错误消息中提到。 要为crate设置堆分配器，必须将`#[global_allocator]`属性应用于实现`GlobalAlloc` trait的`static`变量。\n\n发生第二个错误是因为`allocate`调用可能失败，通常是在没有更多可用内存时失败。 我们的程序必须能够对这种情况做出反应，这就是`#[alloc_error_handler]`函数的作用。\n\n在以下各节中，我们将详细描述这些特征和属性。\n\n### `GlobalAlloc`Trait\n\n[`GlobalAlloc`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/alloc/trait.GlobalAlloc.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhja9Cla59NwkTNZAMz6PcSj4jN6wg) Trait 定义了堆分配器必须提供的功能。 该Trait很特殊，因为程序员几乎从不直接使用它。 相反，当使用`alloc`分配内存和使用集合类型时，编译器将自动向trait中的方法插入适当的调用。\n\n由于我们将需要为我们的分配器类型实现trait，因此有必要仔细研究其声明：\n\n```rust\npub unsafe trait GlobalAlloc {\n    unsafe fn alloc(&self, layout: Layout) -> *mut u8;\n    unsafe fn dealloc(&self, ptr: *mut u8, layout: Layout);\n\n    unsafe fn alloc_zeroed(&self, layout: Layout) -> *mut u8 { ... }\n    unsafe fn realloc(\n        &self,\n        ptr: *mut u8,\n        layout: Layout,\n        new_size: usize\n    ) -> *mut u8 { ... }\n}\n```\n\n它定义了两个必需的方法[`alloc`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhixPH85ItX6ssyPAbPLnxIX8ZIpXA)和[`dealloc`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/alloc/trait.GlobalAlloc.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhja9Cla59NwkTNZAMz6PcSj4jN6wg#tymethod.dealloc) ，它们与我们在示例中使用的`allocate`和`deallocate`函数相对应：\n\n- [`alloc`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhixPH85ItX6ssyPAbPLnxIX8ZIpXA)方法将[`Layout`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/alloc/struct.Layout.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhgfbVGb4vhKLhix2Ocb5VA9y29OfA)实例作为参数，该实例描述分配的内存应具有的所需大小和对齐方式。 它返回[原始指针](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/book/ch19-01-unsafe-rust.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhgxBivPXeHGd4Lv7ZRfhxcOwPp25w#dereferencing-a-raw-pointer) ， [指向](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/book/ch19-01-unsafe-rust.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhgxBivPXeHGd4Lv7ZRfhxcOwPp25w#dereferencing-a-raw-pointer)分配的内存块的第一个字节。 `alloc`方法返回空指针而非显式的错误值以指示分配错误。 这有点令人不习惯，但是它的优点是包装现有的系统分配器很容易，因为它们使用相同的调用约定。\n- 对应的有[`dealloc`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/alloc/trait.GlobalAlloc.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhja9Cla59NwkTNZAMz6PcSj4jN6wg#tymethod.dealloc)方法，负责释放内存块。 它接收两个参数，一个是`alloc`返回的指针， `alloc`是用于分配的`Layout` 。\n\n该特征还使用默认实现定义了两个方法[`alloc_zeroed`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/alloc/trait.GlobalAlloc.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhja9Cla59NwkTNZAMz6PcSj4jN6wg#method.alloc_zeroed)和[`realloc`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/alloc/trait.GlobalAlloc.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhja9Cla59NwkTNZAMz6PcSj4jN6wg#method.realloc) ：\n\n- [`alloc_zeroed`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/alloc/trait.GlobalAlloc.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhja9Cla59NwkTNZAMz6PcSj4jN6wg#method.alloc_zeroed)方法等效于调用`alloc` ，然后将分配的内存块设置为零，这正是提供的默认实现所执行的。 如果可能的话，分配器实现可以使用更有效的自定义实现来覆盖默认实现。\n- [`realloc`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/alloc/trait.GlobalAlloc.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhja9Cla59NwkTNZAMz6PcSj4jN6wg#method.realloc)方法允许增加或减少分配。 默认实现分配一个具有所需大小的新内存块，并复制先前分配的所有内容。 同样，分配器实现可能可以提供此方法的更有效实现，例如，如果可能的话，通过就地扩展/缩小分配。\n\n#### Unsafe\n\n要注意的一件事是trait本身和所有trait方法都被声明为`unsafe` ：\n\n- 将该特征声明为`unsafe`的原因是，程序员必须保证分配器类型的特征实现是正确的。 例如， `alloc`方法绝不能返回已在其他地方使用的内存块，因为这将导致未定义的行为。\n- 同样，方法`unsafe`的原因是，调用方在调用方法时必须确保各种不变性，例如，传递给`alloc`的`Layout`指定一个非零大小。 在实践中，这实际上并不重要，因为方法通常是由编译器直接调用的，这可以确保满足要求。\n\n### `DummyAllocator`\n\n既然我们知道应该提供什么分配器类型，我们就可以创建一个简单的虚拟分配器。 为此，我们创建一个新的`allocator`模块：\n\n```rust\n// in src/lib.rs\n\npub mod allocator;\n```\n\n我们的DummyAllocator会尽最大的努力来实现Trait，并在调用`alloc`时始终返回错误。 看起来像这样：\n\n```rust\n// in src/allocator.rs\n\nuse alloc::alloc::{GlobalAlloc, Layout};\nuse core::ptr::null_mut;\n\npub struct Dummy;\n\nunsafe impl GlobalAlloc for Dummy {\n    unsafe fn alloc(&self, _layout: Layout) -> *mut u8 {\n        null_mut()\n    }\n\n    unsafe fn dealloc(&self, _ptr: *mut u8, _layout: Layout) {\n        panic!(\"dealloc should be never called\")\n    }\n}\n```\n\n该结构不需要任何字段，因此我们将其创建[为零大小类型](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/nomicon/exotic-sizes.html&xid=25657,15700023,15700186,15700190,15700256,15700259,15700262,15700265,15700271&usg=ALkJrhhjDn4Dp1jvubRT6ctCKEw2rj_gYA#zero-sized-types-zsts) 。 如上所述，我们总是从`alloc`返回空指针，它对应于分配错误。 由于分配器从不返回任何内存，因此永远不会发生对`dealloc`的调用。 因此，我们在`dealloc`方法被调用时panic。 `alloc_zeroed`和`realloc`方法具有默认实现，因此我们无需为其提供实现。\n\n现在我们有了一个简单的分配器，但是我们仍然必须告诉Rust编译器它应该使用这个分配器。这时`#[global_allocator]`就有用了。\n\n### #`[global_allocator]`属性\n\n`#[global_allocator]`属性告诉Rust编译器应该使用哪个分配器实例作为全局堆分配器。 该属性仅适用于实现`GlobalAlloc`特性的`static` 。 让我们将`Dummy`分配器的一个实例注册为全局分配器：\n\n```rust\n// in src/lib.rs\n\n#[global_allocator]\nstatic ALLOCATOR: allocator::Dummy = allocator::Dummy;\n```\n\n由于`Dummy`分配器是[零大小的类型](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/nomicon/exotic-sizes.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhgeU-TEc9SDEbOIraxGeQ8xYg4r3A#zero-sized-types-zsts) ，因此我们不需要在初始化表达式中指定任何字段。 请注意， `#[global_allocator]`模块[不能在子模块中使用](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://github.com/rust-lang/rust/pull/51335&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhiRtm-6gsZO_3uOw-LJ9wMyI-a1kA) ，因此我们需要将其放入`lib.rs` 。\n\n现在，当我们尝试编译它时，第一个错误应该消失了。 让我们修复剩余的第二个错误：\n\n```rust\nerror: `#[alloc_error_handler]` function required, but not found\n```\n\n### `#[alloc_error_handler]`属性\n\n正如我们在讨论`GlobalAlloc`特性时所了解的那样， `alloc`函数可以通过返回空指针来指示分配错误。 问题是：Rust运行时应如何应对这种分配失败？ 这是`#[alloc_error_handler]`属性的来源。它指定发生分配错误时调用的函数，类似于在发生panic时调用panic处理程序的方式。\n\n让我们添加这样的函数来修复编译错误：\n\n```rust\n// in src/lib.rs\n\n#![feature(alloc_error_handler)] // at the top of the file\n\n#[alloc_error_handler]\nfn alloc_error_handler(layout: alloc::alloc::Layout) -> ! {\n    panic!(\"allocation error: {:?}\", layout)\n}\n```\n\n`alloc_error_handler`函数仍然不稳定，因此我们需要一个特性设置来启用它。 该函数接收一个参数：发生分配失败时传递给`alloc`的`Layout`实例。 我们对解决该错误无能为力，因此我们只是发送包含`Layout`实例的panic消息。\n\n加上这个函数之后，编译错误应该已经被修复了。 现在我们可以使用`alloc`的分配和收集类型，例如，我们可以使用[`Box`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/boxed/struct.Box.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhiosxpeNyAEHn8OqRYErq2bnWWKRw)在堆上分配一个值：\n\n```rust\n// in src/main.rs\n\nextern crate alloc;\n\nuse alloc::boxed::Box;\n\nfn kernel_main(boot_info: &'static BootInfo) -> ! {\n    // […] print \"Hello World!\", call `init`, create `mapper` and `frame_allocator`\n\n    let x = Box::new(41);\n\n    // […] call `test_main` in test mode\n\n    println!(\"It did not crash!\");\n    blog_os::hlt_loop();\n}\n```\n\n请注意，我们也需要在`main.rs`指定`extern crate alloc`语句。 这是必需的，因为`main.rs`和`main.rs`部分被视为单独的crate。 但是，我们不需要创建另一个静态`#[global_allocator]`，因为全局分配器适用于项目中的所有crate。 实际上，在另一个crate中指定其他分配器将是错误的。\n\n运行上面的代码时，我们看到我们的`alloc_error_handler`函数被调用：![QEMU printing \"panicked at `allocation error: Layout { size_: 4, align_: 4 }, src/lib.rs:89:5\"](https://os.phil-opp.com/heap-allocation/qemu-dummy-output.png)\n\n调用错误处理程序是因为`Box::new`函数隐式调用了全局分配器的`alloc`函数。 我们的虚拟分配器始终返回空指针，因此每次分配都会失败。 为了解决这个问题，我们需要创建一个实际上返回可用内存的分配器。\n\n## 创建内核堆\n\n在创建合适的分配器之前，我们首先需要创建一个堆内存区域，分配器可以从中分配内存。 为此，我们需要为堆区域定义一个虚拟内存范围，然后将该区域映射到物理帧。 有关虚拟内存和页表的概述，请参见[*“分页简介”*](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://os.phil-opp.com/paging-introduction/&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhhkanSS8TkxwpQrLCkMYDffTLWobg) 。\n\n第一步是为堆定义虚拟内存区域。 我们可以选择所需的任何虚拟地址范围，只要它尚未用于其他内存区域即可。 让我们将其定义为从地址`0x_4444_4444_0000`开始的内存，以便稍后可以轻松识别堆指针：\n\n```rust\n// in src/allocator.rs\n\npub const HEAP_START: usize = 0x_4444_4444_0000;\npub const HEAP_SIZE: usize = 100 * 1024; // 100 KiB\n```\n\n我们现在将堆大小设置为100 KiB。 如果将来需要更多空间，我们可以简单地增加它。\n\n如果我们现在尝试使用此堆区域，则会发生页面错误，因为虚拟内存区域尚未映射到物理内存。为了解决这个问题，我们创建了一个`init_heap`函数，该函数使用我们在[*“分页实现”一文中*](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://os.phil-opp.com/paging-implementation/&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhj_xC5St0tlJnPmBv9hvbAEPd6W5A)介绍的[`Mapper` API](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://os.phil-opp.com/paging-implementation/&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhj_xC5St0tlJnPmBv9hvbAEPd6W5A#using-mappedpagetable)映射堆页面：\n\n```rust\n// in src/allocator.rs\n\nuse x86_64::{\n    structures::paging::{\n        mapper::MapToError, FrameAllocator, Mapper, Page, PageTableFlags, Size4KiB,\n    },\n    VirtAddr,\n};\n\npub fn init_heap(\n    mapper: &mut impl Mapper<Size4KiB>,\n    frame_allocator: &mut impl FrameAllocator<Size4KiB>,\n) -> Result<(), MapToError> {\n    let page_range = {\n        let heap_start = VirtAddr::new(HEAP_START as u64);\n        let heap_end = heap_start + HEAP_SIZE - 1u64;\n        let heap_start_page = Page::containing_address(heap_start);\n        let heap_end_page = Page::containing_address(heap_end);\n        Page::range_inclusive(heap_start_page, heap_end_page)\n    };\n\n    for page in page_range {\n        let frame = frame_allocator\n            .allocate_frame()\n            .ok_or(MapToError::FrameAllocationFailed)?;\n        let flags = PageTableFlags::PRESENT | PageTableFlags::WRITABLE;\n        unsafe { mapper.map_to(page, frame, flags, frame_allocator)?.flush() };\n    }\n\n    Ok(())\n}\n```\n\n该函数通过使用[`Size4KiB`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/x86_64/0.7.5/x86_64/structures/paging/page/enum.Size4KiB.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhg2M_G0Ol9na-mTvgYz9wcyhGSTxg)作为模版参数来获取对[`Mapper`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/x86_64/0.7.5/x86_64/structures/paging/mapper/trait.Mapper.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhgVFv5BTMRwDVcKqwVIbnPTvsmTPg)和[`FrameAllocator`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/x86_64/0.7.5/x86_64/structures/paging/trait.FrameAllocator.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhjggS52v2i2ScjsxhDb74n9oOyHIA)实例的可变引用，它们均限于4KiB页。 该函数的返回值是一个[`Result`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/core/result/enum.Result.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhhce2hBUz9y9tfOupW--gctQJa0tQ) ，其[`Result`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/core/result/enum.Result.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhhce2hBUz9y9tfOupW--gctQJa0tQ)成功时为单位类型`()`，而出错时为[`MapToError`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/x86_64/0.7.5/x86_64/structures/paging/mapper/enum.MapToError.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhicxFwlIHtXfyNzcvL79bpGKF_HjA)，这是[`Mapper::map_to`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/x86_64/0.7.5/x86_64/structures/paging/mapper/trait.Mapper.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhgVFv5BTMRwDVcKqwVIbnPTvsmTPg#tymethod.map_to)方法返回的错误类型。 在这里重用错误类型是有意义的，因为`map_to`方法是此函数中错误的主要来源。\n\n实现可以分为两部分：\n\n- **创建页面范围：：**要创建我们要映射的页面范围，我们将`HEAP_START`指针转换为[`VirtAddr`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/x86_64/0.7.5/x86_64/struct.VirtAddr.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhhNOHf3zU7AgNVZhjYJkAVQ39Xufw)类型。 然后，我们通过添加`HEAP_SIZE`从中计算出堆结束地址。 我们需要一个包含性的边界（堆最后一个字节的地址），因此我们减去1。接下来，我们使用[`containing_address`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/x86_64/0.7.5/x86_64/structures/paging/page/struct.Page.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhjSe7J0VwXNgWPo3i7TiwHf8vSwFw#method.containing_address)函数将地址转换为[`Page`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/x86_64/0.7.5/x86_64/structures/paging/page/struct.Page.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhjSe7J0VwXNgWPo3i7TiwHf8vSwFw)类型。 最后，我们使用[`Page::range_inclusive`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/x86_64/0.7.5/x86_64/structures/paging/page/struct.Page.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhjSe7J0VwXNgWPo3i7TiwHf8vSwFw#method.range_inclusive)函数从起始页面和结束页面创建页面范围。\n- **映射页面：**第二步是映射我们刚刚创建的页面范围的所有页面。 为此，我们使用`for`循环遍历该范围内的页面。 对于每个页面，我们执行以下操作：\n  - 我们使用[`FrameAllocator::allocate_frame`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/x86_64/0.7.5/x86_64/structures/paging/trait.FrameAllocator.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhjggS52v2i2ScjsxhDb74n9oOyHIA#tymethod.allocate_frame)方法[`FrameAllocator::allocate_frame`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/x86_64/0.7.5/x86_64/structures/paging/trait.FrameAllocator.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhjggS52v2i2ScjsxhDb74n9oOyHIA#tymethod.allocate_frame)页面应映射到的物理帧。 当没有剩余的帧时，此方法将返回[`None`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/core/option/enum.Option.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhhaJ_Il3_-qAEhTV0CU_eroK_zIqA#variant.None) 。 我们通过使用[`Option::ok_or`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/core/option/enum.Option.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhhaJ_Il3_-qAEhTV0CU_eroK_zIqA#method.ok_or)方法将其映射到[`MapToError::FrameAllocationFailed`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/x86_64/0.7.5/x86_64/structures/paging/mapper/enum.MapToError.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhicxFwlIHtXfyNzcvL79bpGKF_HjA#variant.FrameAllocationFailed)错误来处理这种情况，然后应用[问号运算符](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/edition-guide/rust-2018/error-handling-and-panics/the-question-mark-operator-for-easier-error-handling.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhg1cg548fqAFT-Y_9h9-bsEfN4Qpw)以在出现错误的情况下尽早返回。\n  - 我们为页面设置了必需的`PRESENT`标志和`WRITABLE`标志。 使用这些标志，允许读取和写入访问，这对于堆内存是有意义的。\n  - 我们使用不安全的[`Mapper::map_to`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/x86_64/0.7.5/x86_64/structures/paging/mapper/trait.Mapper.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhgVFv5BTMRwDVcKqwVIbnPTvsmTPg#tymethod.map_to)方法在活动页面表中创建映射。 该方法可能会失败，因此我们再次使用[问号运算符](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/edition-guide/rust-2018/error-handling-and-panics/the-question-mark-operator-for-easier-error-handling.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhg1cg548fqAFT-Y_9h9-bsEfN4Qpw)将错误转发给调用方。 成功后，该方法将返回一个[`MapperFlush`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/x86_64/0.7.5/x86_64/structures/paging/mapper/struct.MapperFlush.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhhu0tpL-XJy7I4bFlQNnOuMtOYO7g)实例，我们可以使用该实例使用[`flush`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/x86_64/0.7.5/x86_64/structures/paging/mapper/struct.MapperFlush.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhhu0tpL-XJy7I4bFlQNnOuMtOYO7g#method.flush)方法来更新[*转换后备缓冲区*](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://os.phil-opp.com/paging-introduction/&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhhkanSS8TkxwpQrLCkMYDffTLWobg#the-translation-lookaside-buffer)。\n\n最后一步是从我们的`kernel_main`调用此函数：\n\n```rust\n// in src/main.rs\n\nfn kernel_main(boot_info: &'static BootInfo) -> ! {\n    use blog_os::allocator; // new import\n    use blog_os::memory::{self, BootInfoFrameAllocator};\n\n    println!(\"Hello World{}\", \"!\");\n    blog_os::init();\n\n    let mut mapper = unsafe { memory::init(boot_info.physical_memory_offset) };\n    let mut frame_allocator = unsafe {\n        BootInfoFrameAllocator::init(&boot_info.memory_map)\n    };\n\n    // new\n    allocator::init_heap(&mut mapper, &mut frame_allocator)\n        .expect(\"heap initialization failed\");\n\n    let x = Box::new(41);\n\n    // […] call `test_main` in test mode\n\n    println!(\"It did not crash!\");\n    blog_os::hlt_loop();\n}\n```\n\n我们在这里出示了完整的代码，为了便于参考上下文。 仅有的新行是`blog_os::allocator`导入和对`allocator::init_heap`函数的调用。 万一`init_heap`函数返回错误，我们会使用[`Result::expect`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/core/result/enum.Result.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhhce2hBUz9y9tfOupW--gctQJa0tQ#method.expect)方法来引发panic，因为当前没有明智的方法来处理此错误。\n\n现在，我们有一个准备使用的映射堆内存区域。 `Box::new`调用仍然使用我们旧的`Dummy`分配器，因此运行它时，您仍然会看到“内存不足”错误。 让我们通过使用适当的分配器来解决此问题。\n\n## 使用分配器 crate\n\n由于实现分配器有些复杂，因此我们首先使用外部分配器crate。 在下一篇文章中，我们将学习如何实现自己的分配器。\n\n`no_std`应用程序的一个简单分配器箱是[`linked_list_allocator`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://github.com/phil-opp/linked-list-allocator/&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhjRQdwoIoMwukn1dxQxvPbEk9FaCw)箱子。 它起这个名称是因为：它使用链接列表数据结构来跟踪释放的内存区域。 有关此方法的详细说明，请参见下一篇文章。\n\n要使用板条箱，我们首先需要在`Cargo.toml`添加对它的依赖：\n\n```rust\n# in Cargo.toml\n\n[dependencies]\nlinked_list_allocator = \"0.6.4\"\n```\n\n然后，我们可以用crate提供的分配器替换我们的dummy分配器：\n\n```rust\n// in src/lib.rs\n\nuse linked_list_allocator::LockedHeap;\n\n#[global_allocator]\nstatic ALLOCATOR: LockedHeap = LockedHeap::empty();\n```\n\n该结构被命名为`LockedHeap`因为，它使用[`spin::Mutex`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/spin/0.5.2/spin/struct.Mutex.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhiB-xAcS86h4-YyKqhs0T_npkoGBQ)进行同步。 这是必需的，因为多个线程可以同时访问`ALLOCATOR`静态对象。 一如往常，在使用`Mutex`时 ，我们需要注意不要意外导致死锁。 这意味着我们不应该在中断处理程序中执行任何分配，因为它们可以在任意时间运行，并且可能会中断正在进行的分配。\n\n仅将`LockedHeap`设置为全局分配器是不够的。 原因是我们使用了[`empty`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/linked_list_allocator/0.6.4/linked_list_allocator/struct.LockedHeap.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhjSImcHYQIFUsXh6pW843hrmoYKmQ#method.empty)构造函数，该函数创建了一个没有任何后备内存的分配器。 就像我们的虚拟分配器一样，它总是在`alloc`上返回错误。为了解决这个问题，我们需要在创建堆之后初始化分配器：\n\n```rust\n// in src/allocator.rs\n\npub fn init_heap(\n    mapper: &mut impl Mapper<Size4KiB>,\n    frame_allocator: &mut impl FrameAllocator<Size4KiB>,\n) -> Result<(), MapToError> {\n    // […] map all heap pages to physical frames\n\n    // new\n    unsafe {\n        super::ALLOCATOR.lock().init(HEAP_START, HEAP_SIZE);\n    }\n\n    Ok(())\n}\n```\n\n我们使用[`LockedHeap::lock`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/linked_list_allocator/0.6.4/linked_list_allocator/struct.LockedHeap.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhjSImcHYQIFUsXh6pW843hrmoYKmQ#method.lock)方法获取对包装后的[`Heap`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/linked_list_allocator/0.6.4/linked_list_allocator/struct.Heap.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhgOQD-NmzuyehtvmIr_FZz2Unvq2A)实例的排他性引用，然后在该实例上以堆边界作为参数调用[`init`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/linked_list_allocator/0.6.4/linked_list_allocator/struct.Heap.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhgOQD-NmzuyehtvmIr_FZz2Unvq2A#method.init)方法。 重要的是在映射堆页面*之后*初始化堆，因为[`init`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/linked_list_allocator/0.6.4/linked_list_allocator/struct.Heap.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhgOQD-NmzuyehtvmIr_FZz2Unvq2A#method.init)函数会尝试写入堆内存。\n\n初始化堆之后，我们现在可以使用内置alloc crate中的的所有分配和集合类型，而不会出现错误：\n\n```rust\n// in src/main.rs\n\nuse alloc::{boxed::Box, vec, vec::Vec, rc::Rc};\n\nfn kernel_main(boot_info: &'static BootInfo) -> ! {\n    // […] initialize interrupts, mapper, frame_allocator, heap\n\n    // allocate a number on the heap\n    let heap_value = Box::new(41);\n    println!(\"heap_value at {:p}\", heap_value);\n\n    // create a dynamically sized vector\n    let mut vec = Vec::new();\n    for i in 0..500 {\n        vec.push(i);\n    }\n    println!(\"vec at {:p}\", vec.as_slice());\n\n    // create a reference counted vector -> will be freed when count reaches 0\n    let reference_counted = Rc::new(vec![1, 2, 3]);\n    let cloned_reference = reference_counted.clone();\n    println!(\"current reference count is {}\", Rc::strong_count(&cloned_reference));\n    core::mem::drop(reference_counted);\n    println!(\"reference count is {} now\", Rc::strong_count(&cloned_reference));\n\n    // […] call `test_main` in test context\n    println!(\"It did not crash!\");\n    blog_os::hlt_loop();\n}\n```\n\n此代码示例演示[`Box`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/boxed/struct.Box.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhiosxpeNyAEHn8OqRYErq2bnWWKRw) ， [`Vec`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/vec/&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhieY-F6KPuz5zi1aQC51lYwWTpocQ)和[`Rc`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/rc/&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhhRszVAQpT964_IqTwW-N23ixY3Og)类型的某些用法。对于`Box`和`Vec`类型，我们使用[`{:p}`格式说明符](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/core/fmt/trait.Pointer.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhi8JAgOHJJ7R4OMg1lddXKPPImIfg)打印基础堆指针。为了进行展示`Rc`，我们创建了一个引用计数的堆值，并使用该[`Rc::strong_count`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/rc/struct.Rc.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhgdb8ySpOxHWtrwxFWLY2BRF6R_0Q#method.strong_count)函数在删除实例之前和之后（使用[`core::mem::drop`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/core/mem/fn.drop.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhj1lgzbQAChTDPbzBUXrB1rjwXYkQ)）打印当前引用计数。\n\n运行它时，我们看到以下内容：\n\n![QEMU在0x444444440000打印vec在0x4444444408000处的heap_value当前引用计数为2引用计数现在为1](https://os.phil-opp.com/heap-allocation/qemu-alloc-showcase.png)\n\n如预期的那样，我们看到`Box` 和 `Vec`值存在于堆中，如以开头的指针所指示`0x_4444_4444`。引用计数值也表现出预期的效果，在`clone`调用之后，引用计数为2，在删除一个实例之后，引用计数再次为1。\n\n向量从`0x800`开始的原因不是装箱的值是`0x800`字节大的，而是向量需要增加其容量时发生的[重新分配](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/vec/struct.Vec.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhggQTZld9-J9QlCghMnx6mS6Iv6Yw#capacity-and-reallocation)。例如，当向量的容量为32且我们尝试添加下一个元素时，向量将在幕后分配容量为64的新后备数组，并将所有元素复制到其后。然后释放旧分配。\n\n当然`alloc`，我们现在可以在内核中使用所有更多的分配和收集类型，包括：\n\n- 线程安全引用计数的指针 [`Arc`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/sync/struct.Arc.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhj0W9GHTbExBe7ogcC-At7IwnbvzA)\n- 有所有权的字符串类型[`String`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/string/struct.String.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhjCj3aWKrmBGjI8tSiHyAR6AM07kw)和[`format!`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/macro.format.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhgROMRJHZB_3JXG5v6BfGOFfyxgeQ)宏\n- [`LinkedList`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/collections/linked_list/struct.LinkedList.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhgxe05cnRkWpSbYK8E95OQ9Dr16uQ)\n- 可成长的环形缓冲区 [`VecDeque`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/collections/vec_deque/struct.VecDeque.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhjMDKrGsPBTUoy8J-dzcNlJ9_icLA)\n- [`BinaryHeap`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/collections/binary_heap/struct.BinaryHeap.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhiLc9dwZt2-i1zsmCUyeP0MaFeI3Q)优先队列\n- [`BTreeMap`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/collections/btree_map/struct.BTreeMap.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhg_SwcL9IDCpGKpEg1N6gV9Voruxw) 和 [`BTreeSet`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/collections/btree_set/struct.BTreeSet.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhix7vWfraqRdLrcIm8JC7VWF8p5ZA)\n\n当我们要实现线程列表，调度队列或支持async/await时，这些类型将变得非常有用。 \n\n## 添加测试\n\n为了确保我们不会意外破坏新的分配代码，我们应该为其添加集成测试。我们首先创建一个`tests/heap_allocation.rs`具有以下内容的新文件：\n\n```rust\n// in tests/heap_allocation.rs\n\n#![no_std]\n#![no_main]\n#![feature(custom_test_frameworks)]\n#![test_runner(blog_os::test_runner)]\n#![reexport_test_harness_main = \"test_main\"]\n\nextern crate alloc;\n\nuse bootloader::{entry_point, BootInfo};\nuse core::panic::PanicInfo;\n\nentry_point!(main);\n\nfn main(boot_info: &'static BootInfo) -> ! {\n    unimplemented!();\n}\n\n#[panic_handler]\nfn panic(info: &PanicInfo) -> ! {\n    blog_os::test_panic_handler(info)\n}\n```\n\n我们重用了`lib.rs`中的`test_runner`和`test_panic_handler`。由于我们要测试内存分配，因此通过`extern crate alloc`语句启用了这个crate。有关测试样板的更多信息，请查看“ [*测试”*](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://os.phil-opp.com/testing/&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhie76olh4ei1lGqtBZIyplpwxv8qg)文章。\n\n该`main`函数的实现如下所示：\n\n```rust\n// in tests/heap_allocation.rs\n\nfn main(boot_info: &'static BootInfo) -> ! {\n    use blog_os::allocator;\n    use blog_os::memory::{self, BootInfoFrameAllocator};\n    use x86_64::VirtAddr;\n\n    blog_os::init();\n    let phys_mem_offset = VirtAddr::new(boot_info.physical_memory_offset);\n    let mut mapper = unsafe { memory::init(phys_mem_offset) };\n    let mut frame_allocator = unsafe {\n        BootInfoFrameAllocator::init(&boot_info.memory_map)\n    };\n    allocator::init_heap(&mut mapper, &mut frame_allocator)\n        .expect(\"heap initialization failed\");\n\n    test_main();\n    loop {}\n}\n```\n\n它与我们`main.rs`中的`kernel_main`函数非常相似，不同之处在于我们不调用`println`，不包含任何示例分配以及无条件地调用`test_main`。\n\n现在我们准备添加一些测试用例。首先，我们添加一个测试，该测试使用进行简单分配[`Box`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/boxed/struct.Box.html&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhiosxpeNyAEHn8OqRYErq2bnWWKRw)并检查分配的值，以确保基本分配有效：\n\n```rust\n// in tests/heap_allocation.rs\n\nuse blog_os::{serial_print, serial_println};\nuse alloc::boxed::Box;\n\n#[test_case]\nfn simple_allocation() {\n    serial_print!(\"simple_allocation... \");\n    let heap_value = Box::new(41);\n    assert_eq!(*heap_value, 41);\n    serial_println!(\"[ok]\");\n}\n```\n\n最重要的是，此测试可验证没有发生分配错误。 \n\n接下来，我们迭代构建一个大向量，以测试大量分配和多次分配（由于重新分配）：\n\n```rust\n// in tests/heap_allocation.rs\n\nuse alloc::vec::Vec;\n\n#[test_case]\nfn large_vec() {\n    serial_print!(\"large_vec... \");\n    let n = 1000;\n    let mut vec = Vec::new();\n    for i in 0..n {\n        vec.push(i);\n    }\n    assert_eq!(vec.iter().sum::<u64>(), (n - 1) * n / 2);\n    serial_println!(\"[ok]\");\n}\n```\n\n我们通过与[第n部分和](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://en.wikipedia.org/wiki/1_%2B_2_%2B_3_%2B_4_%2B_%E2%8B%AF&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhgV_rmHr53cE-UooOstgDtXajdMwA#Partial_sums)的公式进行比较来验证[和](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://en.wikipedia.org/wiki/1_%2B_2_%2B_3_%2B_4_%2B_%E2%8B%AF&xid=17259,15700022,15700186,15700191,15700256,15700259,15700262,15700265&usg=ALkJrhgV_rmHr53cE-UooOstgDtXajdMwA#Partial_sums)。这使我们确信分配的值都是正确的。\n\n作为第三项测试，我们依次创建一万个分配：\n\n```rust\n// in tests/heap_allocation.rs\n\n#[test_case]\nfn many_boxes() {\n    serial_print!(\"many_boxes... \");\n    for i in 0..10_000 {\n        let x = Box::new(i);\n        assert_eq!(*x, i);\n    }\n    serial_println!(\"[ok]\");\n}\n```\n\n此测试可确保分配器将释放的内存重新用于后续分配，因为否则分配器将耗尽内存。这似乎是对分配器的明显要求，但是有些分配器设计没有这样做。下一篇文章中将展示一个做不到这一点的不好的分配器设计。\n\n让我们运行新的集成测试：\n\n```rust\n> cargo xtest --test heap_allocation\n[…]\nRunning 3 tests\nsimple_allocation... [ok]\nlarge_vec... [ok]\nmany_boxes... [ok]\n```\n\n## 总结\n\n这篇文章介绍了动态内存，并解释了为什么以及在什么地方需要它。我们了解了Rust的借用检查器如何防止常见漏洞，并了解了Rust的内存分配API的工作方式。\n\n在使用虚拟分配器创建了Rust分配器接口的最小实现之后，我们为内核创建了一个适当的堆内存区域。为此，我们定义的堆的虚拟地址范围，然后使用该映射范围内的物理帧的所有页面`Mapper`，并`FrameAllocator`从以前的帖子。\n\n最后，我们添加了对`linked_list_allocator`板条箱的依赖，以向内核添加适当的分配器。有了这个分配器，我们能够使用`Box`，`Vec`并从其他分配和集合类型`alloc` crate。\n\n## 接下来？\n\n尽管我们已经在本文中添加了堆分配支持，但我们将大部分工作交给了`linked_list_allocator` crate。下一篇文章将详细显示如何从头开始实现分配器。它将介绍多种可能的分配器设计，展示如何实现它们的简单版本，并说明其优缺点。"
        },
        {
          "name": "11-allocator-designs.md",
          "type": "blob",
          "size": 65.701171875,
          "content": "---\ntitle: 内存分配器设计\ndate: 2020-01-22 18:31:30\ntags: [Memory Management]\nsummary: 这篇文章介绍了如何从头开始实现堆分配器。它提出并讨论了不同的分配器设计，包括Bump分配，基于链表的分配和固定大小的块分配。 对于这三种设计中的每一种，我们将创建一个可用于我们的内核的基本实现。\n---\n\n## 介绍\n\n在[上一篇文章](https://os.phil-opp.com/heap-allocation)中我们向内核添加了对堆内存分配的基本支持。 为此，我们在页表中[创建了一个新的内存区域](https://os.phil-opp.com/heap-allocation#creating-a-kernel-heap) ，并[使用`linked_list_allocator` crate](https://os.phil-opp.com/heap-allocation#using-an-allocator-crate)管理该部分内存。 现在我们有了一个可以工作的堆，但大部分工作都是这个crate做的，而我们没有了解它是如何工作的。\n\n在本文中，我们将展示如何从头开始创建自己的堆分配器，而不是依赖现有的分配器crate。 我们将讨论不同的分配器设计，包括简单的*Bump分配器*和基本的*固定大小的块分配器* ，并使用此过程中得到的知识来实现（相比`linked_list_allocator` crate）性能更好的分配器。\n\n### 设计目标\n\n分配器的职责是管理可用的堆内存。 它需要在`alloc`调用中返回未使用的内存，并跟踪由`dealloc`释放的内存，以便可以再次重用它。 最重要的是，它绝不能重复分配已经在其他地方使用的内存，因为这会导致不确定的行为。\n\n除了正确性之外，还有许多次要设计目标。 例如，分配器应有效地利用可用内存并使[*碎片*](https://en.wikipedia.org/wiki/Fragmentation_(computing))减少。此外，它对于并发应用程序应能很好地工作，并可扩展到任意数量的处理器。 为了获得最佳性能，它甚至可以针对CPU缓存优化内存布局，以提高[缓存亲和性](http://docs.cray.com/books/S-2315-50/html-S-2315-50/qmeblljm.html)并避免[False Sharing](http://mechanical-sympathy.blogspot.de/2011/07/false-sharing.html) 。\n\n这些要求会使好的分配器非常复杂。 例如， [jemalloc](http://jemalloc.net/)具有超过30,000行代码。 通常我们不希望内核代码中的分配器如此复杂，因为其中的单个错误会就会导致严重的安全漏洞。 幸运的是，与用户空间代码相比，内核代码的分配模式通常要简单得多，因此相对简单的分配器设计通常就足够了。\n\n在下文中，我们介绍了三种可能的内核分配器设计，并说明了它们的优缺点。\n\n## Bump分配器\n\n最简单的分配器设计是*Bump分配器* 。 它线性分配内存，并且仅记录分配的字节数和分配次数。 它仅在非常特定的用例中有用，因为它有一个严格的限制：它只能一次释放所有内存。\n\n### 基本想法\n\nBump分配器背后的思想是通过增加（ *“Bump”* ） `next`变量来线性分配内存，该变量指向未使用的内存的开头。 一开始， `next`等于堆的起始地址。 每次分配时， `next`都会增加，因此它始终指向已用和未用内存之间的边界：\n\n![在三个时间点的堆内存区域：1：在堆的开始处存在一个分配；下一个指针指向其结尾 2：在第一个分配之后立即添加了第二个分配；下一个指针指向第二个分配的末尾3：在第二个分配之后立即添加了第三个分配；`下一个指针指向第三分配的末尾](https://os.phil-opp.com/allocator-designs/bump-allocation.svg)\n\n`next`指针单向移动，因此永远不会两次分配相同的存储区域。 当`next`到达堆末尾时，无法再分配更多的内存，从而导致下一次分配出现内存不足错误。\n\nBump分配器通常带有一个分配计数器，分配计数器在每个`alloc`调用中增加1，在每个`dealloc`调用中减少1。 当分配计数器达到零时，表示堆上分配的所有内存都已释放。 在这种情况下，可以将`next`指针重置为堆的起始地址，以便完整的堆内存可再次用于分配。\n\n### 实现\n\n我们通过声明一个新的`allocator::bump`子模块开始我们的实现：\n\n```rust\n// in src/allocator.rs\n\npub mod bump;\n```\n\n子模块的内容位于新的`src/allocator/bump.rs`文件中，如下：\n\n```rust\n// in src/allocator/bump.rs\n\npub struct BumpAllocator {\n    heap_start: usize,\n    heap_end: usize,\n    next: usize,\n    allocations: usize,\n}\n\nimpl BumpAllocator {\n    /// Creates a new empty bump allocator.\n    pub const fn new() -> Self {\n        BumpAllocator {\n            heap_start: 0,\n            heap_end: 0,\n            next: 0,\n            allocations: 0,\n        }\n    }\n\n    /// Initializes the bump allocator with the given heap bounds.\n    ///\n    /// This method is unsafe because the caller must ensure that the given\n    /// memory range is unused. Also, this method must be called only once.\n    pub unsafe fn init(&mut self, heap_start: usize, heap_size: usize) {\n        self.heap_start = heap_start;\n        self.heap_end = heap_start + heap_size;\n        self.next = heap_start;\n    }\n}\n```\n\n`heap_start`和`heap_end`字段跟踪堆内存区域的下限和上限。 调用者需要确保这些地址有效，否则分配器将返回无效的内存。 因此， `init`函数是`unsafe`的。\n\n`next`字段的目的是始终指向堆的第一个未使用字节，即下一个分配的起始地址。 在`init`函数中将其设置为`heap_start` ，因为在开始时没有使用任何堆内存。 在每次分配时，此字段都会增加分配大小（ *“ bumped”* ），以确保我们不会两次返回相同的内存区域。\n\n`allocations`字段是记录分配数的简单计数器，目的是在释放最后一个分配后重置分配器。 初始化为0。\n\n我们选择创建一个单独的`init`函数，而不是直接在`new`中直接执行初始化，以使接口与`linked_list_allocator` crate提供的分配器相同。 这样，无需更改其他代码即可切换分配器。\n\n### 实现`GlobalAlloc`\n\n如[前](https://os.phil-opp.com/heap-allocation#the-allocator-interface)一篇[文章所述](https://os.phil-opp.com/heap-allocation#the-allocator-interface) ，所有堆分配器都需要实现[`GlobalAlloc trait`](https://doc.rust-lang.org/alloc/alloc/trait.GlobalAlloc.html)，其定义如下：\n\n```rust\npub unsafe trait GlobalAlloc {\n    unsafe fn alloc(&self, layout: Layout) -> *mut u8;\n    unsafe fn dealloc(&self, ptr: *mut u8, layout: Layout);\n\n    unsafe fn alloc_zeroed(&self, layout: Layout) -> *mut u8 { ... }\n    unsafe fn realloc(\n        &self,\n        ptr: *mut u8,\n        layout: Layout,\n        new_size: usize\n    ) -> *mut u8 { ... }\n}\n```\n\n仅需要`alloc`和`dealloc`方法，其他两个方法具有默认实现，可以省略。\n\n#### 首次尝试实现\n\n让我们尝试为`BumpAllocator`实现`alloc`方法：\n\n```rust\n// in src/allocator/bump.rs\n\nuse alloc::alloc::{GlobalAlloc, Layout};\n\nunsafe impl GlobalAlloc for BumpAllocator {\n    unsafe fn alloc(&self, layout: Layout) -> *mut u8 {\n        // TODO alignment and bounds check\n        let alloc_start = self.next;\n        self.next = alloc_start + layout.size();\n        self.allocations += 1;\n        alloc_start as *mut u8\n    }\n\n    unsafe fn dealloc(&self, _ptr: *mut u8, _layout: Layout) {\n        todo!();\n    }\n}\n```\n\n首先，我们使用`next`字段作为分配的起始地址。 然后，我们更新`next`字段以指向分配的结束地址，这是堆上的下一个未使用的地址。 在以`*mut u8`指针返回分配的开始地址之前，我们将`allocations`计数器增加1。\n\n请注意，我们不执行任何边界检查或对齐调整，因此此实现尚不安全。 这并不要紧，因为无论如何它都无法编译并出现以下错误：\n\n```\nerror[E0594]: cannot assign to `self.next` which is behind a `&` reference\n  --> src/allocator/bump.rs:29:9\n   |\n26 |     unsafe fn alloc(&self, layout: Layout) -> *mut u8 {\n   |                     ----- help: consider changing this to be a mutable reference: `&mut self`\n...\n29 |         self.next = alloc_start + layout.size();\n   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ `self` is a `&` reference, so the data it refers to cannot be written\n```\n\n（ `self.allocations += 1`行也发生相同的错误。为简洁起见，在此省略。）\n\n发生该错误是因为`GlobalAlloc` trait的[`alloc`](https://doc.rust-lang.org/alloc/alloc/trait.GlobalAlloc.html#tymethod.alloc)和[`dealloc`](https://doc.rust-lang.org/alloc/alloc/trait.GlobalAlloc.html#tymethod.dealloc)方法仅在不可变的`&self`引用上运行，因此无法更新`next`和`allocations`字段。 这是有问题的，因为在每个分配上`next`进行更新是Bump分配器的基本原理。\n\n注意，在方法声明中将`&self`更改为`&mut self`的编译器建议在这里不起作用。 原因是方法签名是由`GlobalAlloc` trait定义的，不能在实现端进行更改。 （我在Rust 的repo开了一个关于此类不合法的编译期建议的[issue](https://github.com/rust-lang/rust/issues/68049)。）\n\n#### `GlobalAlloc`和可变性\n\n在我们研究此可变性问题的可能解决方案之前，让我们尝试理解为什么使用`&self`参数定义`GlobalAlloc` trait方法的：正如我们在上一篇文章中看到[的那样](https://os.phil-opp.com/heap-allocation#the-global-allocator-attribute) ，全局堆分配器是通过将`#[global_allocator]`属性添加到实现`GlobalAlloc`特性的`static` 。静态变量在Rust中是不可变的，因此无法调用在静态分配器上采用`&mut self`的方法。 因此， `GlobalAlloc`所有方法仅采用不可变的`&self`引用。\n\n幸运的是，有一种方法可以从`&self`引用中获取`&mut self`引用：通过将分配器包装在[`spin::Mutex`](https://docs.rs/spin/0.5.0/spin/struct.Mutex.html)自旋锁中，我们可以使用同步[内部可变性](https://doc.rust-lang.org/book/ch15-05-interior-mutability.html) 。 这种类型提供了执行[互斥](https://en.wikipedia.org/wiki/Mutual_exclusion)的`lock`方法，因此可以安全地将`&self`引用转换为`&mut self`引用。 我们已经在内核中多次使用了包装器类型，例如[VGA文本缓冲区](https://os.phil-opp.com/vga-text-mode#spinlocks) 。\n\n#### `Locked`包装类型\n\n借助`spin::Mutex`包装器类型，我们可以为Bump分配器实现`GlobalAlloc`特性。 诀窍是不是直接为`BumpAllocator`实现特征，而是为包装的`spin::Mutex`类型实现特征：\n\n```rust\nunsafe impl GlobalAlloc for spin::Mutex<BumpAllocator> {…}\n```\n\n不幸的是，这仍然不起作用，因为Rust编译器不允许实现其他crate中定义trait：\n\n```\nerror[E0117]: only traits defined in the current crate can be implemented for arbitrary types\n  --> src/allocator/bump.rs:28:1\n   |\n28 | unsafe impl GlobalAlloc for spin::Mutex<BumpAllocator> {\n   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^--------------------------\n   | |                           |\n   | |                           `spin::mutex::Mutex` is not defined in the current crate\n   | impl doesn't use only types from inside the current crate\n   |\n   = note: define and implement a trait or new type instead\n```\n\n为了解决这个问题，我们需要围绕`spin::Mutex`创建我们自己的包装器类型：\n\n```rust\n// in src/allocator.rs\n\n/// A wrapper around spin::Mutex to permit trait implementations.\npub struct Locked<A> {\n    inner: spin::Mutex<A>,\n}\n\nimpl<A> Locked<A> {\n    pub const fn new(inner: A) -> Self {\n        Locked {\n            inner: spin::Mutex::new(inner),\n        }\n    }\n\n    pub fn lock(&self) -> spin::MutexGuard<A> {\n        self.inner.lock()\n    }\n}\n```\n\n该类型是围绕`spin::Mutex<A>`的通用包装。 它对包装的类型`A`没有任何限制，因此可以用于包装所有类型，而不仅仅是分配器。 它提供了一个简单的`new`构造函数，该函数将给定值包装了起来。 为了方便起见，它还提供了一个`lock` 函数，该函数调用被包装的`Mutex`上的`lock` 。 由于`Locked`类型足够通用，因此也可用于其他分配器实现，因此我们将其放在父`allocator`模块中。\n\n####  `Locked<BumpAllocator>`\n\n`Locked`类型是在我们自己的crate中定义的（与`spin::Mutex`相反），因此我们可以使用它为我们的Bump分配器实现`GlobalAlloc` 。 完整的实现如下所示：\n\n```rust\n// in src/allocator/bump.rs\n\nuse super::{align_up, Locked};\nuse alloc::alloc::{GlobalAlloc, Layout};\nuse core::ptr;\n\nunsafe impl GlobalAlloc for Locked<BumpAllocator> {\n    unsafe fn alloc(&self, layout: Layout) -> *mut u8 {\n        let mut bump = self.lock(); // get a mutable reference\n\n        let alloc_start = align_up(bump.next, layout.align());\n        let alloc_end = alloc_start + layout.size();\n\n        if alloc_end > bump.heap_end {\n            ptr::null_mut() // out of memory\n        } else {\n            bump.next = alloc_end;\n            bump.allocations += 1;\n            alloc_start as *mut u8\n        }\n    }\n\n    unsafe fn dealloc(&self, _ptr: *mut u8, _layout: Layout) {\n        let mut bump = self.lock(); // get a mutable reference\n\n        bump.allocations -= 1;\n        if bump.allocations == 0 {\n            bump.next = bump.heap_start;\n        }\n    }\n}\n```\n\n`alloc`和`dealloc`第一步都是通过`inner`字段调用[`Mutex::lock`](https://docs.rs/spin/0.5.0/spin/struct.Mutex.html#method.lock)方法，以获取对包装后的分配器类型的可变引用。 该实例将保持锁定状态，直到方法结束，以便在多线程上下文中不会发生数据竞争（我们将很快添加线程支持）。\n\n与以前的原型相比， `alloc`实现现在遵守对齐要求并执行边界检查以确保分配保留在堆内存区域内。 第一步是将`next`地址四舍五入为`Layout`参数指定的对齐方式。 `align_up`显示`align_up`函数的代码。 像以前一样，我们然后将请求的分配大小添加到`alloc_start`以获得分配的结束地址。 如果它大于堆的结束地址，我们将返回一个空指针，以指示内存不足的情况。否则，我们将更新`next`地址，并像以前一样将`allocations`计数器增加1。 最后，我们返回转换为`*mut u8`指针的`alloc_start`地址。\n\n`dealloc`函数将忽略给定的指针和`Layout`参数。 相反，它只是减少了`allocations`计数器。如果计数器再次达到`0` ，则意味着所有分配都被再次释放。 在这种情况下，它将`next`地址重置为`heap_start`地址，以使完整的堆内存再次可用。\n\n`align_up`函数足够通用，可以将其放入父`allocator`模块中。 看起来像这样：\n\n```rust\n// in src/allocator.rs\n\nfn align_up(addr: usize, align: usize) -> usize {\n    let remainder = addr % align;\n    if remainder == 0 {\n        addr // addr already aligned\n    } else {\n        addr - remainder + align\n    }\n}\n```\n\n该函数首先计算`align`除`addr`除法的[余数](https://en.wikipedia.org/wiki/Euclidean_division) 。 如果余数为`0` ，则地址已与给定的对齐方式对齐。 否则，我们通过减去余数（这样新的余数为0）然后加上`align`（以便地址不会变得小于原始地址）来对齐地址。\n\n### 使用\n\n要使用Bump分配器而不是`linked_list_allocator` crate，我们需要更新`allocator.rs`的`ALLOCATOR`静态值：\n\n```rust\n// in src/allocator.rs\n\nuse bump::BumpAllocator;\n\n#[global_allocator]\nstatic ALLOCATOR: Locked<BumpAllocator> = Locked::new(BumpAllocator::new());\n```\n\n在这里，重要的是，我们将`BumpAllocator::new`和`Locked::new` 定义为[`const`函数](https://doc.rust-lang.org/reference/items/functions.html#const-functions) 。 如果它们是普通函数，则将发生编译错误，因为`static`的初始化表达式必须在编译时求值。\n\n我们不需要在`init_heap`函数中更改`ALLOCATOR.lock().init(HEAP_START, HEAP_SIZE)`调用，因为凹凸分配器提供的接口与`linked_list_allocator`提供的分配器相同。\n\n现在我们的内核使用我们的凹凸分配器！ 一切都应该仍然有效，包括我们在上[`heap_allocation`](https://os.phil-opp.com/heap-allocation#adding-a-test)文章中创建的[`heap_allocation`测试](https://os.phil-opp.com/heap-allocation#adding-a-test) ：\n\n```\n> cargo xtest --test heap_allocation\n[…]\nRunning 3 tests\nsimple_allocation... [ok]\nlarge_vec... [ok]\nmany_boxes... [ok]\n```\n\n### 讨论\n\nBump分配的最大优点是它非常快。 与需要主动寻找合适的内存块并在`alloc`和`dealloc`时执行各种记录任务的其他分配器设计（请参见下文）相比， 可以将Bump分配器优化为仅使用数条汇编指令。 这使得凹凸分配器对于优化分配性能很有用，例如在创建[虚拟DOM库时](https://hacks.mozilla.org/2019/03/fast-bump-allocated-virtual-doms-with-rust-and-wasm) 。\n\n虽然很少使用Bump分配器作为全局分配器，但是凹凸分配的原理通常以竞技场分配的形式应用，[竞技场分配](https://mgravell.github.io/Pipelines.Sockets.Unofficial/docs/arenas.html)基本上是将多次分配集中在一起以提高性能。 Rust的竞技场分配器的一个示例是[`toolshed`](https://docs.rs/toolshed/0.8.1/toolshed/index.html) 。\n\n#### Bump分配器的缺点\n\nBump分配器的主要局限性在于，只有释放所有分配后，它才能重新使用释放的内存。 这意味着单个长期分配足以防止内存重用。 当我们添加`many_boxes`测试的变体时，我们可以看到这一点：\n\n```rust\n// in tests/heap_allocation.rs\n\n#[test_case]\nfn many_boxes_long_lived() {\n    serial_print!(\"many_boxes_long_lived... \");\n    let long_lived = Box::new(1); // new\n    for i in 0..HEAP_SIZE {\n        let x = Box::new(i);\n        assert_eq!(*x, i);\n    }\n    assert_eq!(*long_lived, 1); // new\n    serial_println!(\"[ok]\");\n}\n```\n\n像`many_boxes`测试一样，如果分配器不重新使用释放的内存，此测试会创建大量分配以引发内存不足故障。 此外，测试会创建一个`long_lived`分配，该分配对于整个循环执行有效。\n\n当我们尝试运行新测试时，我们发现它确实失败了：\n\n```\n> cargo xtest --test heap_allocation\nRunning 4 tests\nsimple_allocation... [ok]\nlarge_vec... [ok]\nmany_boxes... [ok]\nmany_boxes_long_lived... [failed]\n\nError: panicked at 'allocation error: Layout { size_: 8, align_: 8 }', src/lib.rs:86:5\n```\n\n让我们尝试详细了解为什么会发生此故障：首先，在堆的开头分配了`long_lived`，从而将`allocations`计数器增加1。对于循环的每次迭代，都会临时分配一次内存并在下一次迭代开始之前释放它。 这意味着`allocations`计数器在迭代开始时临时增加到2，在迭代结束时减少到1。 现在的问题是，凹凸分配器仅在释放*所有*分配后才可以重用内存，即`allocations`计数器降为0。由于在循环结束之前不会发生这种情况，因此每次循环迭代都会分配一个新的内存区域，多次迭代后导致了内存不足错误。\n\n#### 重用释放的内存？\n\n问题是：我们可以通过某种方式扩展凹凸分配器以消除此限制吗？\n\n正如我们在上一篇文章中了解到的那样，分配可以生存任意长的时间，并且可以按任意顺序释放。 这意味着我们需要跟踪数量可能无限的非连续未使用内存区域，如以下示例所示：\n\n![img](https://os.phil-opp.com/allocator-designs/allocation-fragmentation.svg)\n\n该图显示了一段时间内的堆。 一开始，整个堆还没有被使用， `next`地址等于`heap_start` （第1行）。 然后发生第一个分配（第2行）。 在第3行中，分配了第二个存储块，并释放了第一次分配的内润。 在第4行中进行了更多分配。其中一半寿命很短，在第5行中已被释放，在该行中还进行了另一次新分配。\n\n第5行显示了一个基本问题：我们共有五个未使用的内存区域，它们的大小各不相同，但是`next`指针只能指向最后一个区域的开始。 尽管对于本示例，我们可以将其他未使用的存储区域的起始地址和大小存储在大小为4的数组中，但这并不是一般的解决方案，因为我们可以轻松地创建一个包含8、16或1000个未使用的存储区域的示例。\n\n通常，当我们有数量不定的项目时，我们可以使用在堆上分配的集合类型。 但此时这是不可能的，因为堆分配器不能依赖于自身（这将导致无限递归或死锁）。 因此，我们需要找到其他解决方案。\n\n## 链表分配器\n\n在实现分配器时，跟踪任意数量的空闲内存区域的常见技巧是将这些区域本身用作后备存储。 这利用了以下事实：区域仍被映射到虚拟地址并由物理帧支持，但是不再需要存储信息。 通过在已被释放的区域中存储有关的信息，我们可以跟踪无限制数量的已被释放的区域，而无需额外的内存。\n\n最常见的实现方法是在释放的内存中构造一个链表，每个节点都是一个释放的内存区域：\n\n![img](https://os.phil-opp.com/allocator-designs/linked-list-allocation.svg)\n\n每个列表节点包含两个字段：内存区域的大小和指向下一个未使用的内存区域的指针。 使用这种方法，我们只需要一个指向第一个未使用区域（称为`head` ）的指针即可跟踪所有未使用区域，而与它们的数量无关。 产生的数据结构通常称为[*空闲列表*](https://en.wikipedia.org/wiki/Free_list) 。\n\n正如您可能从名称中猜到的那样，这是`linked_list_allocator` crate使用的技术。\n\n### 实现\n\n在下面，我们将创建自己的简单`LinkedListAllocator`类型，该类型使用上述方法来跟踪已被释放的内存区域。 文章的其他部分不需要这一部分知识，因此您可以根据需要跳过这部分实现细节。\n\n#### 分配器类型\n\n我们首先在一个新的`allocator::linked_list`子模块中创建一个私有`ListNode`结构：\n\n```rust\n// in src/allocator.rs\n\npub mod linked_list;\n```\n\n```rust\n// in src/allocator/linked_list.rs\n\nstruct ListNode {\n    size: usize,\n    next: Option<&'static mut ListNode>,\n}\n```\n\n就像图中一样，列表节点具有`size`字段和指向下一个节点的可选指针，由`Option<&'static mut ListNode>`类型表示。 `&'static mut`类型在语义上描述了一个有所有权的，在指针后面的对象。 基本上，这是一个没有析构函数的[`Box`](https://doc.rust-lang.org/alloc/boxed/index.html) ，它在所在作用域的末尾释放对象。\n\n我们为`ListNode`实现以下方法：\n\n```rust\n// in src/allocator/linked_list.rs\n\nimpl ListNode {\n    const fn new(size: usize) -> Self {\n        ListNode { size, next: None }\n    }\n\n    fn start_addr(&self) -> usize {\n        self as *const Self as usize\n    }\n\n    fn end_addr(&self) -> usize {\n        self.start_addr() + self.size\n    }\n}\n```\n\n该类型具有一个名为`new`的简单构造函数，以及用于计算所表示区域的开始和结束地址的方法。我们将`new`函数设为[const函数](https://doc.rust-lang.org/reference/items/functions.html#const-functions) ，稍后在构造静态链表分配器时将需要使用该函数。 请注意，在const函数中使用可变引用（包括将`next`字段设置为`None` ）仍然不稳定。 为了使其能够编译，我们需要在`lib.rs`的开头添加 **`#![feature(const_mut_refs)]`** 。\n\n使用`ListNode`结构作为构建块，我们现在可以创建`LinkedListAllocator`结构：\n\n```rust\n// in src/allocator/linked_list.rs\n\npub struct LinkedListAllocator {\n    head: ListNode,\n}\n\nimpl LinkedListAllocator {\n    /// Creates an empty LinkedListAllocator.\n    pub const fn new() -> Self {\n        Self {\n            head: ListNode::new(0),\n        }\n    }\n\n    /// Initialize the allocator with the given heap bounds.\n    ///\n    /// This function is unsafe because the caller must guarantee that the given\n    /// heap bounds are valid and that the heap is unused. This method must be\n    /// called only once.\n    pub unsafe fn init(&mut self, heap_start: usize, heap_size: usize) {\n        self.add_free_region(heap_start, heap_size);\n    }\n\n    /// Adds the given memory region to the front of the list.\n    unsafe fn add_free_region(&mut self, addr: usize, size: usize) {\n        todo!();\n    }\n}\n```\n\n该结构包含一个指向第一个堆区域的`head`节点。 我们只对`next`指针的值感兴趣，因此我们在`ListNone::new`函数中将`size`设置为0。 我们让`head`为`ListNode`类型而非`&'static mut ListNode`类型，这样做的优点是， `alloc`方法的实现将更加简单。\n\n像Bump分配器一样， `new`函数不会使用堆边界来初始化分配器。 除了保持API兼容性之外，原因还在于初始化函数需要将节点写入堆内存，这只能在运行时发生。 但是， `new`函数必须是可以在编译时求值的[`const`函数](https://doc.rust-lang.org/reference/items/functions.html#const-functions) ，因为它将用于初始化`ALLOCATOR`静态函数。 出于这个原因，我们再次单独提供了一个非const的`init`方法。\n\n`init`方法使用`add_free_region`方法，稍后将显示其实现。 现在，我们使用[`todo!`](https://doc.rust-lang.org/core/macro.todo.html) 宏，以提供一个总是panic的占位符实现。\n\n#### `add_free_region`方法\n\n`add_free_region`方法提供对链表的基本*push*操作。 当前，我们仅从`init`调用此方法，但它也将成为我们`dealloc`实现中的中心方法。 请记住，当再次释放分配的内存区域时，将调用`dealloc`方法。 为了跟踪此释放的内存区域，我们希望将其push到链表。\n\n`add_free_region`方法的实现如下所示：\n\n```rust\n// in src/allocator/linked_list.rs\n\nuse super::align_up;\nuse core::mem;\n\nimpl LinkedListAllocator {\n    /// Adds the given memory region to the front of the list.\n    unsafe fn add_free_region(&mut self, addr: usize, size: usize) {\n        // ensure that the freed region is capable of holding ListNode\n        assert!(align_up(addr, mem::align_of::<ListNode>()) == addr);\n        assert!(size >= mem::size_of::<ListNode>());\n\n        // create a new list node and append it at the start of the list\n        let mut node = ListNode::new(size);\n        node.next = self.head.next.take();\n        let node_ptr = addr as *mut ListNode;\n        node_ptr.write(node);\n        self.head.next = Some(&mut *node_ptr)\n    }\n}\n```\n\n该方法以地址和大小表示的内存区域作为参数，并将其添加到列表的前面。 首先，它确保给定区域具有存储`ListNode`所需的大小和对齐方式。 然后，它通过以下步骤创建节点并将其插入到列表中：\n\n![img](https://os.phil-opp.com/allocator-designs/linked-list-allocator-push.svg)\n\n步骤0显示了在`add_free_region`之前堆的状态。 在步骤1中，使用图中标记为已`freed`的内存区域调用该方法。 初步检查后，该方法在其堆栈上创建一个具有被释放区域大小的新`node` 。 然后，它使用[`Option::take`](https://doc.rust-lang.org/core/option/enum.Option.html#method.take)方法将节点的`next`指针设置为当前的`head`指针，从而将`head`指针重置为`None` 。\n\n在步骤2中，该方法通过[`write`](https://doc.rust-lang.org/std/primitive.pointer.html#method.write)方法将新创建的`node`写入到被释放的内存区域的开头。 然后将`head`指针指向新节点。 最终的指针结构看起来有些混乱，因为被释放区域总是插入在列表的开头，但是如果我们跟随指针，我们会看到每个空闲区域仍然可以从`head`指针到达。\n\n#### `find_region`方法\n\n对链表的第二项基本操作是查找条目并将其从列表中删除。 这是实现`alloc`方法所需的中心操作。 我们通过以下方式将操作实现为`find_region`方法：\n\n```rust\n// in src/allocator/linked_list.rs\n\nimpl LinkedListAllocator {\n    /// Looks for a free region with the given size and alignment and removes\n    /// it from the list.\n    ///\n    /// Returns a tuple of the list node and the start address of the allocation.\n    fn find_region(&mut self, size: usize, align: usize)\n        -> Option<(&'static mut ListNode, usize)>\n    {\n        // reference to current list node, updated for each iteration\n        let mut current = &mut self.head;\n        // look for a large enough memory region in linked list\n        while let Some(ref mut region) = current.next {\n            if let Ok(alloc_start) = Self::alloc_from_region(&region, size, align) {\n                // region suitable for allocation -> remove node from list\n                let next = region.next.take();\n                let ret = Some((current.next.take().unwrap(), alloc_start));\n                current.next = next;\n                return ret;\n            } else {\n                // region not suitable -> continue with next region\n                current = current.next.as_mut().unwrap();\n            }\n        }\n\n        // no suitable region found\n        None\n    }\n}\n```\n\n该方法使用一个`current`变量和一个[`while let`循环](https://doc.rust-lang.org/reference/expressions/loop-expr.html#predicate-pattern-loops)来遍历列表元素。 首先，将`current`设置到（虚拟） `head`节点。 然后在每次迭代中，将其更新到当前节点的`next`字段（在`else`块中）。 如果该区域适合于具有给定大小和对齐方式的分配，则将该区域从列表中删除，并与`alloc_start`地址一起返回。\n\n当`current.next`指针变为`None` ，循环退出。 这意味着我们遍历了整个列表，但是没有找到适合分配的区域。 在这种情况下，我们返回`None` 。 检查区域是否合适是通过`alloc_from_region`函数来进行的，稍后将展示其实现。\n\n让我们更详细地研究如何从列表中删除合适的区域：\n\n![img](https://os.phil-opp.com/allocator-designs/linked-list-allocator-remove-region.svg)\n\n步骤0显示了任何指针调整之前的情况。 图中标记出了`region`和`current`区域以及`region.next`和`current.next`指针。 在步骤1中，可以使用[`Option::take`](https://doc.rust-lang.org/core/option/enum.Option.html#method.take)方法将`region.next`和`current.next`指针都重置为`None` 。 原始指针存储在名为`next`和`ret`局部变量中。\n\n在步骤2中，将`current.next`指针设置为本地的`next`指针，它是原来的`region.next`指针。结果是`current`直接指向region之后的`region` ，因此`region`不再是链表的元素。 然后，该函数将指针返回到存储在本地`ret`变量中的区域。\n\n##### `alloc_from_region`函数\n\n`alloc_from_region`函数返回区域是否适合于具有给定大小和对齐方式的分配。 定义如下：\n\n```rust\n// in src/allocator/linked_list.rs\n\nimpl LinkedListAllocator {\n    /// Try to use the given region for an allocation with given size and\n    /// alignment.\n    ///\n    /// Returns the allocation start address on success.\n    fn alloc_from_region(region: &ListNode, size: usize, align: usize)\n        -> Result<usize, ()>\n    {\n        let alloc_start = align_up(region.start_addr(), align);\n        let alloc_end = alloc_start + size;\n\n        if alloc_end > region.end_addr() {\n            // region too small\n            return Err(());\n        }\n\n        let excess_size = region.end_addr() - alloc_end;\n        if excess_size > 0 && excess_size < mem::size_of::<ListNode>() {\n            // rest of region too small to hold a ListNode (required because the\n            // allocation splits the region in a used and a free part)\n            return Err(());\n        }\n\n        // region suitable for allocation\n        Ok(alloc_start)\n    }\n}\n```\n\n首先，该函数使用我们之前定义的`align_up`函数来计算潜在分配的开始和结束地址。 如果要求的结束地址在该区域的结束地址之后，则该分配不适合该区域，并且我们返回错误。\n\n此后，该函数执行了一个作用不太显然的检查。 进行此检查是必要的，因为在大多数情况下，分配并不能完全适合某个合适的区域，因此分配后，该区域的一部分仍然可用。 该区域的这一部分必须在分配后存储自己的`ListNode` ，因此它必须足够大才能存储。该检查准确地验证了这一点：分配是否完全适合（`excess_size == 0`）或多余的大小足以存储a `ListNode`。\n\n#### 实现`GlobalAlloc`\n\n通过`add_free_region`和`find_region`方法提供的基本操作，我们现在可以最终实现`GlobalAlloc` trait。与Bump分配器一样，我们不直接针对`LinkedListAllocator`，而是仅针对包装过的`Locked<LinkedListAllocator>`来实现trait。该[`Locked`包装](https://os.phil-opp.com/allocator-designs#a-locked-wrapper-type)通过自旋锁向分配器实例添加了内部可变性，这使得我们可以修改它，即使`alloc`和`dealloc`方法的参数是不可变的`&self`引用。\n\n实现看起来像这样：\n\n```rust\n// in src/allocator/linked_list.rs\n\nuse super::Locked;\nuse alloc::alloc::{GlobalAlloc, Layout};\nuse core::ptr;\n\nunsafe impl GlobalAlloc for Locked<LinkedListAllocator> {\n    unsafe fn alloc(&self, layout: Layout) -> *mut u8 {\n        // perform layout adjustments\n        let (size, align) = LinkedListAllocator::size_align(layout);\n        let mut allocator = self.inner.lock();\n\n        if let Some((region, alloc_start)) = allocator.find_region(size, align) {\n            let alloc_end = alloc_start + size;\n            let excess_size = region.end_addr() - alloc_end;\n            if excess_size > 0 {\n                allocator.add_free_region(alloc_end, excess_size);\n            }\n            alloc_start as *mut u8\n        } else {\n            ptr::null_mut()\n        }\n    }\n\n    unsafe fn dealloc(&self, ptr: *mut u8, layout: Layout) {\n        // perform layout adjustments\n        let (size, _) = LinkedListAllocator::size_align(layout);\n\n        self.inner.lock().add_free_region(ptr as usize, size)\n    }\n}\n```\n\n让我们从该`dealloc`方法开始，因为它更简单：首先，它执行一些布局调整，我们将在稍后进行解释，并通过调用[Locked wrapper](https://os.phil-opp.com/allocator-designs#a-locked-wrapper-type)的[`Mutex::lock`](https://docs.rs/spin/0.5.0/spin/struct.Mutex.html#method.lock)函数来获取`&mut LinkedListAllocator`。然后，它调用`add_free_region`函数以将释放区域添加到空闲列表中。\n\n该`alloc`方法有点复杂。它以相同的布局调整开始，并且还调用该[`Mutex::lock`](https://docs.rs/spin/0.5.0/spin/struct.Mutex.html#method.lock)函数以接收可变的分配器引用。然后，它使用`find_region`方法找到适合分配的存储区域，并将其从列表中删除。如果此操作失败并返回`None`，则返回`null_mut`，告知用户没有合适的存储区域。\n\n在成功的情况下，该`find_region`方法返回合适区域（不再在列表中）的元组和分配的起始地址。使用`alloc_start`、分配大小和区域的结束地址，它再次计算分配的结束地址和多余的大小。如果多余的大小不为null，则调用`add_free_region`将内存区域的多余的大小添加回空闲列表。最后，它返回转换为`*mut u8`指针的`alloc_start`。\n\n#### 布局调整\n\n那么我们在`alloc`和`dealloc`的一开始做的这些布局的调整，都是什么？它们确保每个分配的块都能够存储一个`ListNode`。这一点很重要，因为在某个时候我们要释放这一块内存并向其中写一个`ListNode`。如果块小于一个`ListNode`的大小或没有正确的对齐方式，则会发生未定义的行为。\n\n布局调整由一个`size_align`函数执行，该函数定义如下：\n\n```rust\n// in src/allocator/linked_list.rs\n\nimpl LinkedListAllocator {\n    /// Adjust the given layout so that the resulting allocated memory\n    /// region is also capable of storing a `ListNode`.\n    ///\n    /// Returns the adjusted size and alignment as a (size, align) tuple.\n    fn size_align(layout: Layout) -> (usize, usize) {\n        let layout = layout\n            .align_to(mem::align_of::<ListNode>())\n            .expect(\"adjusting alignment failed\")\n            .pad_to_align();\n        let size = layout.size().max(mem::size_of::<ListNode>());\n        (size, layout.align())\n    }\n}\n```\n\n首先，如果需要，函数对[`Layout`](https://doc.rust-lang.org/alloc/alloc/struct.Layout.html)参数应用`align_to`方法来将内存对齐到能够容纳一个 `ListNode` 。然后，它使用该[`pad_to_align`](https://doc.rust-lang.org/core/alloc/struct.Layout.html#method.pad_to_align)方法将大小四舍五入为对齐方式的倍数，以确保下一个存储块的起始地址也将具有正确的对齐方式以存储`ListNode`。在第二步中，它使用[`max`](https://doc.rust-lang.org/std/cmp/trait.Ord.html#method.max)方法来强制最小分配大小为`mem::size_of::<ListNode>`。这样，`dealloc`函数可以安全地将`ListNode`写入已释放的内存块。\n\n无论是`align_to`和`pad_to_align`方法都使用了不稳定的特性。要启用该功能，我们需要将添加**`#![feature(alloc_layout_extra)]`**到`lib.rs`的开头。\n\n### 使用\n\n现在，我们可以更新 `allocator`模块中的`ALLOCATOR`静态变量以使用我们的新`LinkedListAllocator`：\n\n```rust\n// in src/allocator.rs\n\nuse linked_list::LinkedListAllocator;\n\n#[global_allocator]\nstatic ALLOCATOR: Locked<LinkedListAllocator> =\n    Locked::new(LinkedListAllocator::new());\n```\n\n由于`init`函数对于Bump和链表分配器的行为相同，因此我们不需要修改`init_heap`中的`init`调用。\n\n现在，当我们再次运行`heap_allocation`测试时，我们看到所有测试现在都通过了，包括Bump分配器没有通过的`many_boxes_long_lived`：\n\n```\n> cargo xtest --test heap_allocation\nsimple_allocation... [ok]\nlarge_vec... [ok]\nmany_boxes... [ok]\nmany_boxes_long_lived... [ok]\n```\n\n这表明我们的链表分配器能够将释放的内存重新用于后续分配。 \n\n### 讨论\n\n与Bump分配器相比，链表分配器更适合用作通用分配器，主要是因为它能够直接重用释放的内存。但是，它也有一些缺点。其中一些是由我们的实现引起的，但是链表分配器这种设计本身也存在一些缺点。\n\n#### 合并释放的块\n\n我们实现的主要问题是，它只会将堆拆分为较小的块，而不会将它们重新合并在一起。考虑以下示例：\n\n![img](https://os.phil-opp.com/allocator-designs/linked-list-allocator-fragmentation-on-dealloc.svg)\n\n在第一行中，在堆上进行了三次分配。它们中的两个在第2行中再次被释放，而第三个在第3行中被释放。现在整个堆都不再被使用，但仍被分成四个单独的块。此时，可能无法再进行大分配，因为四个块都不足够大。随着时间的流逝，该过程将继续进行，并将堆分成越来越小的块。这样下去总有一天，堆中会充满此类碎片，以至于正常大小的分配都将失败。\n\n要解决此问题，我们需要将相邻的释放块重新合并在一起。对于上面的示例，这意味着：\n\n![img](https://os.phil-opp.com/allocator-designs/linked-list-allocator-merge-on-dealloc.svg)\n\n像以前一样，三个分配中的两个在第`2`行中被释放。现在，我们不执行保留碎片的堆的操作，而是直接执行另外一个步骤，`2a`行将两个最右边的块合并在一起。在`3`第3 行中，释放了第三个分配（如之前一样），从而导致完全未使用的堆由三个不同的块组成。然后，在附加的合并步骤中（`3a`行）我们将三个相邻的块合并在一起。\n\n`linked_list_allocator` crate以下列方式这一合并策略：它始终保持列表按照起始地址排序，而不是直接在链表的开头插入被`deallocate`释放的内存块。这样，`deallocate`调用时可以通过检查列表中两个相邻块的地址和大小来进行合并。当然，这种方式的释放操作比较慢，但是可以防止我们在上面看到的堆碎片。\n\n#### 性能\n\n正如我们在上面学到的，Bump分配器非常快，可以优化为仅需几个汇编指令操作。链表分配器的性能要差得多。其问题是分配请求可能需要遍历完整的链表，直到找到合适的块为止。\n\n由于列表长度取决于未使用的存储块的数量，因此对于不同的程序，其性能可能会发生极大的变化。仅创建几个分配的程序将有相对较快的分配性能。但是，对于一个会进行很多次分配，导致堆变得碎片化的程序，分配性能将非常糟糕，因为链表将非常长，并且其中大多数包含的块都非常小。\n\n值得注意的是，这类性能问题不是由我们的实现引起的问题，而是链表方法的根本问题。由于分配性能对于内核级代码非常重要，因此我们在下面探讨了第三种分配器设计，该设计以降低内存利用率代价来提高性能。\n\n## 固定大小的块分配器\n\n下面，我们介绍一种分配器设计，该设计使用固定大小的内存块来满足分配请求。这样，分配器通常返回的块大于分配所需的块，这会由于[内部碎片](https://en.wikipedia.org/wiki/Fragmentation_(computing)#Internal_fragmentation)而导致内存浪费。另一方面，它大大减少了找到合适块所需的时间（与链表分配器相比），从而有更好的分配性能。\n\n### 介绍\n\n*固定大小的块分配器*背后的思想是：并不恰好分配大小等于所需的内存，而是固定一些块大小并将每个分配舍入到能装下它的最小块大小。例如，对于16、64和512字节的块大小，分配4个字节将返回一个16字节的块，分配一个48字节将返回一个64字节的块，而分配128个字节将返回一个512字节的块。 。\n\n像链表分配器一样，我们通过在未使用的内存中创建链表来跟踪未使用的内存。但是，我们不使用具有不同块大小的单个列表，而是为每个大小类创建一个单独的列表。然后，每个链表仅存储单个大小的块。例如，对于块大小为16、64和512的内存，将有三个单独的链表：\n\n![img](https://os.phil-opp.com/allocator-designs/fixed-size-block-example.svg)\n\n我们有三个头指针`head_16`，`head_64`以及`head_512`而不是一个单一的`head`指针，每个都指到到对应的大小的第一个未使用块。单个列表中的所有节点都具有相同的大小。例如，由`head_16`指针开始的列表仅包含16字节的块。这意味着我们不再需要在每个列表节点中存储大小，因为它已经由头指针的名称指定了。\n\n由于列表中的每个元素都具有相同的大小，因此每个列表元素都同样适用于分配请求。这意味着我们可以使用以下步骤非常有效地执行分配：\n\n- 将请求的分配大小四舍五入到下一个块大小。例如，当请求分配12个字节时，在上面的示例中，我们将选择16的块大小。\n- 检索列表的头部指针，例如从一个头指针数组中检索。对于块大小16，我们需要使用`head_16`。\n- 从列表中删除第一个块并返回它。 \n\n最值得注意的是，我们总是可以返回链表的第一个元素，而不再需要遍历整个链表。因此，分配比使用链表分配器快得多。\n\n#### 块大小和浪费的内存\n\n根据块大小，我们通过舍入会损失很多内存。例如，当返回一个512字节的块以进行128字节的分配时，分配的内存中有四分之三未被使用。通过定义合理的块大小，可以在某种程度上限制浪费的内存量。例如，当使用2的幂（4、8、16、32、64、128、…）作为块大小时，在最坏的情况下，我们可以将内存浪费限制为分配大小的一半，平均情况下为分配的四分之一。\n\n通常也会基于程序中的常用的分配大小来优化块大小。例如，我们可以额外增加块大小24，以提高经常执行24字节分配的程序的内存使用率。这样，通常可以减少浪费的内存量，而不会损失性能优势。\n\n#### 释放\n\n像分配一样，释放也非常高效。它涉及以下步骤：\n\n- 将释放的内存大小四舍五入到下一个块大小。这是必需的，因为编译器仅将请求的分配大小传递给`dealloc`，而不传递`alloc`所返回的块的大小。通过在`alloc`和`dealloc`中使用相同的大小调整函数我们可以确保始终释放正确的内存量。\n- 检索列表的头部指针，例如从一个头指针数组中检索。 \n- 通过更新头指针，将释放的块添加到列表的开头。 \n\n最值得注意的是，也无需遍历列表即可进行释放。这意味着`dealloc`无论列表长度如何，所需的时间都保持不变。\n\n#### 后备分配器\n\n鉴于大容量分配（> 2KB）通常是很少见的，尤其是在操作系统内核中，因此有可能需要退回到其他分配器进行这些分配。例如，为了减少内存浪费，我们可以退回到链表分配器中进行大于2048字节的分配。由于预期该大小的分配非常少，因此这个链表将保持较小状态，因此分配和释放仍会相当快。\n\n#### 创建新块\n\n上面，我们始终假定列表中始终有足够的特定大小的块来满足所有分配请求。但是，在某个时候，块大小的链接列表将为空。此时，有两种方法可以创建特定大小的未使用的新块来满足分配请求：\n\n- 从后备分配器分配一个新块（如果有）。 \n- 从其他列表中拆分较大的块。如果块大小为2的幂，则此方法最有效。例如，一个32字节的块可以分为两个16字节的块。\n\n对于我们的实现，为了简单考虑，因此我们将从后备分配器分配新块。 \n\n### 实现\n\n现在我们知道了固定大小的块分配器是如何工作的，我们可以开始实现它了。我们将不依赖于上一节中创建的链表分配器的实现，因此即使您跳过了链表分配器的实现，也可以看这一部分。\n\n#### 列表节点\n\n我们通过在新`allocator::fixed_size_block`模块中创建`ListNode`类型来开始实现：\n\n```rust\n// in src/allocator.rs\n\npub mod fixed_size_block;\n```\n\n```rust\n// in src/allocator/fixed_size_block.rs\n\nstruct ListNode {\n    next: Option<&'static mut ListNode>,\n}\n```\n\n这种类型类似于我们的[链表分配器](https://os.phil-opp.com/allocator-designs#the-allocator-type)中的`ListNode`类型，不同之处在于我们没有第二个`size`字段。不需要该字段是因为每个列表中的每个块都具有相同的大小。\n\n#### 块大小\n\n接下来，我们定义一个常量`BLOCK_SIZES`切片，并使用用于实现的块大小：\n\n```rust\n// in src/allocator/fixed_size_block.rs\n\n/// The block sizes to use.\n///\n/// The sizes must each be power of 2 because they are also used as\n/// the block alignment (alignments must be always powers of 2).\nconst BLOCK_SIZES: &[usize] = &[8, 16, 32, 64, 128, 256, 512, 1024, 2048];\n```\n\n我们使用从8到2048的2的幂作为块大小。我们不定义任何小于8的块大小，因为每个块在释放时必须能够存储指向下一个块的64位指针。对于大于2048字节的分配，我们将退回到链表分配器。\n\n为了简化实现，我们定义块的大小也是其在内存中所需的对齐方式。因此，一个16字节的块始终在16字节的边界上对齐，而512字节的块始终在512字节的边界上对齐。由于对齐始终需要为2的幂，因此排除了任何其他块大小。如果将来需要的块大小不是2的幂，我们仍然可以为此调整实现（例如，通过定义第二个`BLOCK_ALIGNMENTS`数组）。\n\n#### 分配器类型\n\n使用`ListNode`类型和`BLOCK_SIZES`切片，我们现在可以定义分配器类型：\n\n```rust\n// in src/allocator/fixed_size_block.rs\n\npub struct FixedSizeBlockAllocator {\n    list_heads: [Option<&'static mut ListNode>; BLOCK_SIZES.len()],\n    fallback_allocator: linked_list_allocator::Heap,\n}\n```\n\n该`list_heads`字段是一个`head`指针数组，每个块大小一个。这是通过`len()`将`BLOCK_SIZES`slice的用作数组长度来实现的。作为大于最大块大小的分配的后备分配器，我们使用由`linked_list_allocator`提供的分配器。我们也可以使用我们自己实现的`LinkedListAllocator`，但是它的缺点是它不[合并被释放的块](https://os.phil-opp.com/allocator-designs#merging-freed-blocks)。\n\n对于`FixedSizeBlockAllocator`，我们提供了与其他分配器类型相同的`new`和`init`函数：\n\n```rust\n// in src/allocator/fixed_size_block.rs\n\nimpl FixedSizeBlockAllocator {\n    /// Creates an empty FixedSizeBlockAllocator.\n    pub const fn new() -> Self {\n        FixedSizeBlockAllocator {\n            list_heads: [None; BLOCK_SIZES.len()],\n            fallback_allocator: linked_list_allocator::Heap::empty(),\n        }\n    }\n\n    /// Initialize the allocator with the given heap bounds.\n    ///\n    /// This function is unsafe because the caller must guarantee that the given\n    /// heap bounds are valid and that the heap is unused. This method must be\n    /// called only once.\n    pub unsafe fn init(&mut self, heap_start: usize, heap_size: usize) {\n        self.fallback_allocator.init(heap_start, heap_size);\n    }\n}\n```\n\n`new`函数只是使用空节点初始化`list_heads`数组，并创建一个空链表分配器作为`fallback_allocator`。 由于初始化非`Copy`类型的数组仍然是不稳定特性，因此我们需要在lib.rs的开头添加`#![feature(const_in_array_repeat_expressions)]`。 在这种情况下，`None`不是`Copy`的原因是`ListNode`没有实现`Copy`。 因此，`Option`包装及其`None`变体也不是`Copy`。\n\n不安全的init函数仅调用`fallback_allocator`的init函数，而无需对`list_heads`数组进行任何其他初始化。 相反，我们将在`alloc`和`dealloc`调用时lazy地初始化列表。\n\n为了方便起见，我们还创建了一个私有`fallback_alloc`方法，该方法使用`fallback_allocator`分配空间：\n\n```rust\n// in src/allocator/fixed_size_block.rs\n\nuse alloc::alloc::Layout;\nuse core::ptr;\n\nimpl FixedSizeBlockAllocator {\n    /// Allocates using the fallback allocator.\n    fn fallback_alloc(&mut self, layout: Layout) -> *mut u8 {\n        match self.fallback_allocator.allocate_first_fit(layout) {\n            Ok(ptr) => ptr.as_ptr(),\n            Err(_) => ptr::null_mut(),\n        }\n    }\n}\n```\n\n由于`linked_list_allocator`crate的[`Heap`](https://docs.rs/linked_list_allocator/0.6.4/linked_list_allocator/struct.Heap.html)类型无法实现[`GlobalAlloc`](https://doc.rust-lang.org/alloc/alloc/trait.GlobalAlloc.html)（因为如果没有锁，这是不可能的）。而是提供了[`allocate_first_fit`](https://docs.rs/linked_list_allocator/0.6.4/linked_list_allocator/struct.Heap.html#method.allocate_first_fit)这样一个接口稍有不同的方法。它返回`Result<NonNull<u8>, AllocErr>`，而不是返回 `*mut u8`并使用空指针来表示错误。该[`NonNull`](https://doc.rust-lang.org/nightly/core/ptr/struct.NonNull.html)类型是保证非空的原始指针的抽象。[`AllocErr`](https://doc.rust-lang.org/nightly/core/alloc/struct.AllocErr.html)是用于标记分配错误的类型。通过将`Ok`case 映射到[`NonNull::as_ptr`](https://doc.rust-lang.org/nightly/core/ptr/struct.NonNull.html#method.as_ptr)方法并将`Err`case 映射到空指针，我们可以轻松地将其转换回`*mut u8`类型。\n\n#### 计算链表索引\n\n在实现`GlobalAlloc`特征之前，我们定义一个`list_index`辅助函数，该函数对一个[`Layout`](https://doc.rust-lang.org/alloc/alloc/struct.Layout.html)返回给定的最小可能块大小：\n\n```rust\n// in src/allocator/fixed_size_block.rs\n\n/// Choose an appropriate block size for the given layout.\n///\n/// Returns an index into the `BLOCK_SIZES` array.\nfn list_index(layout: &Layout) -> Option<usize> {\n    let required_block_size = layout.size().max(layout.align());\n    BLOCK_SIZES.iter().position(|&s| s >= required_block_size)\n}\n```\n\n被分配的块必须至少具有给定`Layout`所需的大小和对齐方式。由于我们让块的大小等于其对齐到的大小，因此这意味着`required_block_size`是`size()`和`align()`属性的[最大值](https://doc.rust-lang.org/core/cmp/trait.Ord.html#method.max)。要查找`BLOCK_SIZES`切片中首个比所要求的更大的块，我们首先使用`iter()`方法来获得迭代器，然后使用`position`方法来找到第一个大小大于等于要求的块的索引。\n\n请注意，我们不返回块大小本身，而是返回`BLOCK_SIZES`切片的索引。原因是我们要使用返回的索引作为`list_heads`数组的索引。\n\n#### 实现`GlobalAlloc`\n\n最后一步是实现`GlobalAlloc` trait：\n\n```rust\n// in src/allocator/fixed_size_block.rs\n\nuse super::Locked;\nuse alloc::alloc::GlobalAlloc;\n\nunsafe impl GlobalAlloc for Locked<FixedSizeBlockAllocator> {\n    unsafe fn alloc(&self, layout: Layout) -> *mut u8 {\n        todo!();\n    }\n\n    unsafe fn dealloc(&self, ptr: *mut u8, layout: Layout) {\n        todo!();\n    }\n}\n```\n\n像其他分配器一样，我们不直接为`GlobalAlloc`分配器类型实现trait，而是使用[`Locked`包装器](https://os.phil-opp.com/allocator-designs#a-locked-wrapper-type)添加同步的内部可变性。由于`alloc`和的`dealloc`的实现相对较大，因此我们在下面逐一介绍它们。\n\n##### `alloc`\n\n该`alloc`方法的实现如下所示：\n\n```rust\n// in `impl` block in src/allocator/fixed_size_block.rs\n\nunsafe fn alloc(&self, layout: Layout) -> *mut u8 {\n    let mut allocator = self.lock();\n    match list_index(&layout) {\n        Some(index) => {\n            match allocator.list_heads[index].take() {\n                Some(node) => {\n                    allocator.list_heads[index] = node.next.take();\n                    node as *mut ListNode as *mut u8\n                }\n                None => {\n                    // no block exists in list => allocate new block\n                    let block_size = BLOCK_SIZES[index];\n                    // only works if all block sizes are a power of 2\n                    let block_align = block_size;\n                    let layout = Layout::from_size_align(block_size, block_align)\n                        .unwrap();\n                    allocator.fallback_alloc(layout)\n                }\n            }\n        }\n        None => allocator.fallback_alloc(layout),\n    }\n}\n```\n\n让我们一步步看： \n\n首先，我们使用该`Locked::lock`方法来获取对包装后的分配器实例的可变引用。接下来，我们调用`list_index`刚刚定义的函数，以计算给定布局的适当块大小，并将相应的索引获取到`list_heads`数组中。如果此索引为`None`，则不适合该分配的块大小，因此我们使用`fallback_allocator`using `fallback_alloc`函数。\n\n如果列表索引为`Some`，则尝试`list_heads[index]`使用该[`Option::take`](https://doc.rust-lang.org/core/option/enum.Option.html#method.take)方法删除相应列表中的第一个节点。如果列表不为空，则进入语句的`Some(node)`分支，在`match`该处将列表的顶部指针指向弹出的后继对象`node`（[`take`](https://doc.rust-lang.org/core/option/enum.Option.html#method.take)再次使用）。最后，我们将弹出的`node`指针作为返回`*mut u8`。\n\n如果列表头为`None`，则表示块列表为空。这意味着我们需要[如上所述](https://os.phil-opp.com/allocator-designs#creating-new-blocks)构建一个新块。为此，我们首先从`BLOCK_SIZES`切片中获取当前块的大小，并将其用作新块的大小和对齐方式。然后，我们`Layout`从中创建一个新对象，并调用该`fallback_alloc`方法来执行分配。调整布局和对齐方式的原因是，该块将在取消分配时添加到块列表中。\n\n#### `dealloc`\n\n`dealloc`方法的实现如下所示：\n\n```rust\n// in src/allocator/fixed_size_block.rs\n\nuse core::{mem, ptr::NonNull};\n\n// inside the `unsafe impl GlobalAlloc` block\n\nunsafe fn dealloc(&self, ptr: *mut u8, layout: Layout) {\n    let mut allocator = self.lock();\n    match list_index(&layout) {\n        Some(index) => {\n            let new_node = ListNode {\n                next: allocator.list_heads[index].take(),\n            };\n            // verify that block has size and alignment required for storing node\n            assert!(mem::size_of::<ListNode>() <= BLOCK_SIZES[index]);\n            assert!(mem::align_of::<ListNode>() <= BLOCK_SIZES[index]);\n            let new_node_ptr = ptr as *mut ListNode;\n            new_node_ptr.write(new_node);\n            allocator.list_heads[index] = Some(&mut *new_node_ptr);\n        }\n        None => {\n            let ptr = NonNull::new(ptr).unwrap();\n            allocator.fallback_allocator.deallocate(ptr, layout);\n        }\n    }\n}\n```\n\n像`alloc`中一样，我们首先使用`lock`方法获取可变的分配器引用，然后使用`list_index`函数获取与给定`Layout`对应的块列表。如果index为`None`，则不存在合适的块大小`BLOCK_SIZES`，这表明该分配是由后备分配器创建的。因此，我们使用后备分配器的[`deallocate`](https://docs.rs/linked_list_allocator/0.6.4/linked_list_allocator/struct.Heap.html#method.deallocate)释放内存。该方法期望使用 [`NonNull`](https://doc.rust-lang.org/nightly/core/ptr/struct.NonNull.html)而不是 `*mut u8`，因此我们需要先转换指针。 （`unwrap`仅在指针为null时调用失败，这在编译器调用`dealloc`时永远不会发生。）\n\n如果`list_index`返回了块索引，则需要将释放的内存块添加到列表中。为此，我们首先创建一个`ListNode`指向当前列表头的新内容（通过再次使用[`Option::take`](https://doc.rust-lang.org/core/option/enum.Option.html#method.take)）。在将新节点写入释放的内存块之前，我们首先要断言由指定的当前块大小`index`具有存储`ListNode`大小和对齐方式所需的空间。然后，我们通过将给定的`*mut u8`指针转换为`*mut ListNode`指针，然后[`write`](https://doc.rust-lang.org/std/primitive.pointer.html#method.write)在其上调用unsafe 方法来执行写操作。最后一步是将列表的起始指针设置为新创建的结点。为此，我们将原始指针`new_node_ptr`转换为可变引用。\n\n有几件事值得注意： \n\n- 我们不区分从块列表分配的块和从后备分配器分配的块。这意味着在`alloc`中创建的新块将添加到上的块列表中`dealloc`，从而增加了该大小的块数。\n- 该`alloc`方法是在我们的实现中唯一创建新块的地方。这意味着我们最初从空块列表开始，仅在执行针对该块大小的分配时才懒惰地填充列表。\n- 即使我们执行了某些`unsafe`操作，也不需要在`alloc`和`dealloc`中添加`unsafe`块。原因是Rust目前将`unsafe`函数的全部视为一个大`unsafe`块。由于使用显式块具有明显的优点，即哪些操作不安全，哪些操作不安全，因此[有一个RFC](https://github.com/rust-lang/rfcs/pull/2585)建议更改此行为。\n\n### 使用\n\n要使用新的 `FixedSizeBlockAllocator`，我们需要更新`allocator`模块中的`ALLOCATOR`静态变量：\n\n```rust\n// in src/allocator.rs\n\nuse fixed_size_block::FixedSizeBlockAllocator;\n\n#[global_allocator]\nstatic ALLOCATOR: Locked<FixedSizeBlockAllocator> = Locked::new(\n    FixedSizeBlockAllocator::new());\n```\n\n由于`init`函数对于我们实现的所有分配器的行为均相同，因此无需修改`init_heap`中的`init`调用。\n\n现在，当我们再次运行`heap_allocation`测试时，所有测试仍应通过：\n\n```\n> cargo xtest --test heap_allocation\nsimple_allocation... [ok]\nlarge_vec... [ok]\nmany_boxes... [ok]\nmany_boxes_long_lived... [ok]\n```\n\n我们的新分配器似乎可以正常工作！ \n\n### 讨论\n\n尽管固定大小的块方法比链表方法具有更好的性能，但是当使用2的幂作为块大小时，它最差情况下会浪费多达一半的内存。这种权衡是否值得，在很大程度上取决于应用程序类型。对于性能至关重要的操作系统内核，固定大小块方法似乎是更好的选择。\n\n在实现方面，我们可以在当前的实现中进行很多改进： \n\n- 与其仅使用后备分配器Lazy地分配块，还不如预先填充列表以提高初始分配的性能。 \n- 为了简化实现，我们只允许块大小为2的幂，以便我们也可以将它们用作块对齐。通过以不同的方式存储（或计算）对齐方式，我们还可以允许任意其他块大小。这样，我们可以增加更多的块大小，例如常见的分配大小，以最大程度地减少浪费的内存。\n- 目前，我们仅创建新的块，但不再释放它们。这会导致碎片，最终可能导致大块内存的分配请求失败。为每种块大小列表强制设置最大长度可能是一个好的选择。当达到最大长度时，后续的释放使用后备分配器进行，而不是将其添加到列表中。\n- 我们可以使用一个特殊的分配器来分配大于4KiB的内存，而不是使用链表分配器。这个想法利用了在4KiB页面上运行的[分页](https://os.phil-opp.com/paging-introduction)可以将连续的虚拟内存块映射到非连续的物理帧。这样，未分配内存的碎片对于大分配而言不再是问题。\n- 使用这样的页面分配器，可能有必要添加最大4KiB的块大小并完全删除链表分配器。这样做的主要优点是减少了碎片并提高了性能可预测性，即更好的最坏情况性能。\n\n请务必注意，上面概述的实现上的改进仅是建议。操作系统内核中使用的分配器通常会针对内核的特定工作负载进行高度优化，这只有通过广泛的性能分析才能实现。\n\n### 变化\n\n固定大小的块分配器设计也有很多变体。*slab分配器*和*伙伴分配器*是两个流行的示例，它们也用在诸如Linux之类的流行内核中。下面，我们对这两种设计进行简短介绍。\n\n#### slab分配器\n\n[*slab*分配器](https://en.wikipedia.org/wiki/Slab_allocation)的思想是使用与内核中选定类型直接对应的块大小。这样，那些类型的分配恰好适合块大小，并且不会浪费内存。有时，甚至有可能在未使用的块中预先初始化好类型实例，以进一步提高性能。\n\nslab分配通常与其他分配器结合使用。例如，它可以与固定大小的块分配器一起使用，以进一步拆分分配的块，以减少内存浪费。它还经常用于在一次分配大块内存，然后在这块内存上实现[对象池模式](https://en.wikipedia.org/wiki/Object_pool_pattern)。\n\n#### 伙伴分配器\n\n[伙伴分配器](https://en.wikipedia.org/wiki/Buddy_memory_allocation)设计不是使用链表来管理释放的块，而是使用[二叉树](https://en.wikipedia.org/wiki/Binary_tree)数据结构以及2的幂次方块大小。当需要一定大小的新块时，它将一个较大的块分成两半，从而在树中创建两个子节点。每当再次释放一个块时，就会分析树中的相邻块。如果邻居也是空的，则将两个块重新连接在一起，成为一个大小两倍的块。\n\n此合并过程的优点是减少了[外部碎片](https://en.wikipedia.org/wiki/Fragmentation_(computing)#External_fragmentation)，因此可以将较小的释放块重新用于较大的分配。它还不使用后备分配器，因此性能更可预测。最大的缺点是只能使用2的幂次的块大小，这可能会由于[内部碎片](https://en.wikipedia.org/wiki/Fragmentation_(computing)#Internal_fragmentation)而导致大量的内存浪费。因此，伙伴分配器通常与slab分配器结合使用，以将分配的块进一步拆分为多个较小的块。\n\n## 总结\n\n这篇文章概述了不同的分配器设计。我们学习了如何实现基本的[Bump分配器](https://os.phil-opp.com/allocator-designs#bump-allocator)，该[分配器](https://os.phil-opp.com/allocator-designs#bump-allocator)通过增加单个`next`指针来线性[分配](https://os.phil-opp.com/allocator-designs#bump-allocator)内存。虽然Bump分配非常快，但是只有释放所有分配后，它才能重新使用内存。因此，它很少用作全局分配器。\n\n接下来，我们创建了一个[链表分配器](https://os.phil-opp.com/allocator-designs#linked-list-allocator)，该[分配器](https://os.phil-opp.com/allocator-designs#linked-list-allocator)使用空闲的内存块本身来创建链表，即所谓的[链表](https://en.wikipedia.org/wiki/Free_list)。该列表可以存储任意数量的大小不同的已释放块。尽管不会发生内存浪费，但是由于分配请求可能需要完整遍历列表，因此该方法的性能很差。我们的实现还遭受[外部碎片](https://en.wikipedia.org/wiki/Fragmentation_(computing)#External_fragmentation)的困扰，因为它不会将相邻的释放块重新合并在一起。\n\n为了解决链表方法的性能问题，我们创建了一个[固定大小块分配器](https://os.phil-opp.com/allocator-designs#fixed-size-block-allocator)，该[分配器](https://os.phil-opp.com/allocator-designs#fixed-size-block-allocator)预定义了一组固定的块大小。对于每个块大小，都存在一个单独的[空闲列表](https://en.wikipedia.org/wiki/Free_list)，因此分配和取消分配只需要在[列表的](https://en.wikipedia.org/wiki/Free_list)开头插入/弹出，因此非常快。由于每个分配都向上舍入到下一个更大的块大小，因此由于[内部碎片](https://en.wikipedia.org/wiki/Fragmentation_(computing)#Internal_fragmentation)而浪费了一些内存。\n\n还有更多具有不同权衡取舍的分配器设计。[slab分配](https://os.phil-opp.com/allocator-designs#slab-allocator)可以很好地优化常见固定大小结构的分配，但并非在所有情况下都适用。[伙伴分配](https://os.phil-opp.com/allocator-designs#buddy-allocator)使用二叉树将释放的块合并回去，但浪费了大量内存，因为它仅支持2次幂的块大小。同样重要的是要记住，每个内核实现都有独特的工作负载，因此没有适合所有情况的“最佳”分配器设计。\n\n## 接下来是什么？\n\n通过这篇文章，我们现在就结束了我们的内存管理部分。接下来，我们将开始探索[*多任务处理*](https://en.wikipedia.org/wiki/Computer_multitasking&)，从[*线程*](https://en.wikipedia.org/wiki/Thread_(computing))开始。在随后的文章中，我们将探索多处理器、进程以及基于async/await的协作式多任务处理。\n"
        },
        {
          "name": "12-async-await.md",
          "type": "blob",
          "size": 113.412109375,
          "content": "---\ntitle: Async/Await\ndate: 2019-09-29 09:45:40\ntags: [Multitasking]\nsummary: 在本文中，我们将探讨协作式多任务处理以及Rust的async/await功能。我们详细研究了Rust中async/await的工作方式，包括Future trait的设计，状态机转换和pinning。然后，我们将会通过创建异步键盘任务和基本executor，将对async/await的基本支持添加到内核中。\n---\n\n该博客在[GitHub上](https://github.com/phil-opp/blog_os)公开开发。如果您有任何问题或疑问，请在此处打开一个issue。您也可以在底部留下评论。这篇文章的完整源代码可以在[post-12](https://github.com/phil-opp/blog_os/tree/post-12)分支中找到。\n\n## 多任务\n\n多数操作系统的基本特征之一是[*多任务处理*](https://en.wikipedia.org/wiki/Computer_multitasking) ，即能够同时执行多个任务的功能。 例如，您可能在看这篇文章时打开了其他程序，例如文本编辑器或终端窗口。 即使只打开一个浏览器窗口，也可能会有各种后台任务来管理桌面窗口，检查更新或为文件建立索引。\n\n尽管看起来所有任务都是并行运行的，但实际上一个CPU核心一次只能执行一个任务。 为了产生任务并行运行的错觉，操作系统会在活动任务之间快速切换，以便每个任务都可以向前推进。 由于计算机速度很快，因此我们大多数时候不会注意到这些切换。\n\n单核CPU一次只能执行一个任务，而多核CPU可以真正并行地运行多个任务。 例如，具有8个内核的CPU可以同时运行8个任务。 我们将在以后的文章中解释如何设置多核CPU。 在本文中，为简单起见，我们将重点介绍单核CPU。 （值得注意的是，所有多核CPU一开始都是以单核启动，因此我们现在可以将它们视为单核CPU。）\n\n多任务处理有两种形式： *协作*多任务处理要求任务定期放弃对CPU的控制，以便其他任务可以取得进展。 *抢占式*多任务使用操作系统功能通过在任意时间点强行暂停线程切换线程。 在下文中，我们将更详细地探讨多任务的两种形式，并讨论它们各自的优点和缺点。\n\n### 抢占式多任务\n\n抢占式多任务处理的思想是操作系统控制何时切换任务。 为此，它利用了它在每个中断上重新获得对CPU的控制这一事实。 这样，只要系统有新输入可用，就可以切换任务。 例如，当移动鼠标或到达网络数据包时，可以切换任务。 操作系统还可以通过配置硬件计时器在该时间之后发送中断来确定允许任务运行的确切时间。\n\n下图说明了硬件中断时的任务切换过程：\n\n![img](https://os.phil-opp.com/async-await/regain-control-on-interrupt.svg)\n\n在第一行中，CPU正在执行程序`A`任务`A1` 。 所有其他任务都已暂停。 在第二行中，硬件中断到达CPU。 如[*硬件中断*](https://os.phil-opp.com/hardware-interrupts)中所述，CPU立即停止执行任务`A1`并跳转到中断描述符表（IDT）中定义的中断处理程序。 通过此中断处理程序，操作系统现在再次具有对CPU的控制权，从而允许它切换到任务`B1`而不是继续执行任务`A1` 。\n\n#### 保存状态\n\n任务在任意时间点都可能被中断，此时它们可能正在进行某些计算。 为了能够在以后继续进行运算，操作系统必须备份任务的整个状态，包括其[调用堆栈](https://en.wikipedia.org/wiki/Call_stack)和所有CPU寄存器的值。 此过程称为[*上下文切换*](https://en.wikipedia.org/wiki/Context_switch) 。\n\n由于调用堆栈可能非常大，因此操作系统通常为每个任务设置单独的调用堆栈，而不是在每每次切换任务时备份整个调用堆栈的内容。 具有单独堆栈的此类任务称为*线程* 。 通过为每个任务使用单独的堆栈，在上下文切换时仅需要保存寄存器内容（包括程序计数器和堆栈指针）。 这种方法可以最大程度地减少上下文切换的性能开销，这非常重要，因为上下文切换通常每秒发生100次。\n\n#### 讨论\n\n抢占式多任务处理的主要优点是操作系统可以完全控制任务的允许执行时间。 这样，它可以确保每个任务都能公平分配CPU时间，而无需信任任务之间的协作。 当运行第三方任务或多个用户共享系统时，这一点尤其重要。\n\n抢占式任务调度的缺点是每个任务都需要自己的堆栈。 与共享堆栈相比，这将导致每个任务的内存使用量更高，并且通常会限制系统中的任务数量。 另一个缺点是，即使任务仅使用了寄存器中的一小部分，操作系统仍必须在每次任务切换时保存完整的CPU寄存器状态。\n\n抢占式多任务处理和线程是操作系统的基本组件，因为它们使运行不受信任的用户空间程序成为可能。 我们将在以后的文章中详细讨论这些概念。 但是，在这篇文章中，我们将专注于协作式多任务处理，这也为我们的内核提供了有用的功能。\n\n### 协作式多任务\n\n协作式多任务处理可以使每个任务运行直到自愿放弃对CPU的控制，而不是在任意时间点强行暂停正在运行的任务。 这使任务可以在方便的时间点（例如，无论如何需要等待I/O操作时）暂停自己的运行。\n\n协作式多任务通常在语言级别使用，例如以[协程](https://en.wikipedia.org/wiki/Coroutine)或[async/await的形式](https://rust-lang.github.io/async-book/01_getting_started/04_async_await_primer.html)。 主要想法是由程序员或编译器将[*yield*](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://en.wikipedia.org/wiki/Yield_(multithreading)&usg=ALkJrhhQcxajutZrtjPo80ap592S0-q1Xw)操作插入到程序中，从而放弃对CPU的控制并允许其他任务运行。 例如，可以在复杂循环的每次迭代之后插入一个yield。\n\n通常都是将协作式多任务与[异步操作](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://en.wikipedia.org/wiki/Asynchronous_I/O&usg=ALkJrhhFH_sPNGha3oLOtqlv77-mFYnO2Q)结合在一起。 如果操作尚未完成，则异步操作将返回“未就绪”状态，而不是等到操作完成并阻止此时再次执行其他任务。 在这种情况下，等待的任务可以执行yield操作以让其他任务运行。\n\n#### 保存状态\n\n由于任务自己定义了暂停点，因此它们不需要操作系统来保存其状态。 相反，他们可以在暂停之前准确保存需要继续的状态，这通常可以提高性能。 例如，刚完成复杂计算的任务可能只需要备份计算的最终结果，因为它不再需要中间结果。\n\n语言支持的协作任务实现通常甚至可以在暂停之前备份调用堆栈的所需部分。 例如，Rust的async/await实现将所有仍需要的局部变量存储在自动生成的结构中（见下文）。 通过在暂停之前备份调用堆栈的相关部分，所有任务可以共享一个调用堆栈，从而使每个任务的内存消耗大大减少。这样就可以创建几乎任意数量的协作任务，而不会耗尽内存。\n\n#### 讨论\n\n协作式多任务处理的缺点是，不让出执行机会的CPU的协作任务可能会无限期地运行。 因此，恶意或有Bug的任务可能会阻止其他任务运行并减慢甚至使整个系统停止运行。 因此，仅当已知所有任务都会让出执行机会时才应使用协作式多任务处理。 作为反例，操作系统对用户级程序使用协作式多任务调度就不是一个好主意。\n\n但是，协作多任务的强大性能和内存优势使其成为程序*内*使用的好方法，尤其是与异步操作结合使用时。 由于操作系统内核是与异步硬件进行交互的，性能至关重要的程序，因此协作多任务似乎是实现并发的好方法。\n\n## Rust Rust中的Async /Await\n\nRust语言以async/await的形式为协作式多任务提供了支持。 在探讨什么是async/await及其如何工作之前，我们需要了解*futures*和异步编程如何在Rust中工作。\n\n### Futures\n\n*Future*代表一个可能尚不可用值。 例如，这可能是由另一个任务计算的整数，也可以是从网络下载的文件。 Future无需等到该值可用时，就可以继续执行，直到需要该值为止。\n\n#### 例子\n\n最好用一个小例子来说明Futures的概念：\n\n![Sequence diagram: main calls read_file and is blocked until it returns; then it calls foo() and is also blocked until it returns. The same process is repeated, but this time async_read_file is called, which directly returns a future; then foo() is called again, which now runs concurrently to the file load. The file is available before foo() returns.](https://os.phil-opp.com/async-await/async-example.svg)\n\n\n\n此序列图显示了一个`main`函数，该函数从文件系统读取文件，然后调用函数`foo` 。 此过程重复两次：一次通过同步`read_file`调用，一次通过异步`async_read_file`调用。\n\n通过同步调用访问文件时， `main`函数需要等待文件系统加载完文件。 只有这样，它才能调用`foo`函数，这要求它再次等待结果。\n\n通过异步`async_read_file`调用，文件系统直接返回一个`future`并在后台异步加载文件。 这允许`main`函数更早地调用`foo` ，然后`foo`与文件加载并行运行。 在此示例中，文件加载甚至能在`foo`返回之前完成，因此`main`可以直接处理文件，而无需在`foo`返回之后再等待。\n\n#### Rust的Future\n\n在Rust中，Future由[`Future`](https://doc.rust-lang.org/nightly/core/future/trait.Future.html) trait表示，如下所示：\n\n```Rust\npub trait Future {\n    type Output;\n    fn poll(self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output>;\n}\n```\n\n[关联类型](https://doc.rust-lang.org/book/ch19-03-advanced-traits.html#specifying-placeholder-types-in-trait-definitions-with-associated-types) `Output`指定异步值的类型。 例如， `async_read_file`函数将返回`Future`实例，并且`Output`设置为`File` 。\n\n[`poll`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/nightly/core/future/trait.Future.html&usg=ALkJrhjkxk--77ETh7OgMyt44sTRaCqxaA#tymethod.poll)方法允许检查该值是否已可用。 它返回一个[`Poll`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/nightly/core/future/trait.Future.html&usg=ALkJrhjkxk--77ETh7OgMyt44sTRaCqxaA#tymethod.poll)枚举，如下所示：\n\n```Rust\npub enum Poll<T> {\n    Ready(T),\n    Pending,\n}\n```\n\n当该值已经可用时（例如，已从磁盘完全读取文件），将其包装在`Ready`中返回。 否则，将返回`Pending`，它告知调用方该值尚不可用。\n\n`poll`方法采用两个参数： `self: Pin<&mut Self>`和`cx: &mut Context` 。 前者的行为类似于普通的`&mut self`引用，不同之处在于`self`值 [*固定*](https://doc.rust-lang.org/nightly/core/pin/index.html)在其内存位置 如果不先了解异步/等待的工作原理，就很难了解`Pin`以及为什么需要它。 因此，我们将在本文后面解释。\n\n`cx: &mut Context`参数的目的是将[`Waker`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/nightly/core/task/struct.Waker.html&usg=ALkJrhh1VExi94vM8AqKJrzNZJgsyP4dPw)实例传递给异步任务，例如文件系统负载。 该`Waker`允许异步任务发信号通知它（或其一部分）已完成，例如，文件是从磁盘加载的。 由于主任务知道在`Future`准备就绪时会收到通知，因此它不需要一遍又一遍地调用`poll` 。 当我们实现自己的waker类型时，我们将在本文后面的部分中更详细地说明此过程。\n\n### 使用futures\n\n现在，我们知道了如何定义future并了解`poll`方法背后的基本思想。 但是，我们仍然不知道如何有效地使用futures。 问题在于，future代表了异步任务的结果，这可能尚不可用。 但是，实际上，我们经常直接需要这些值以进行进一步的计算。 所以问题是：我们如何在需要时有效地获取future的值？\n\n#### 等待future\n\n一种可能的方法是等到future准备就绪。 可能看起来像这样：\n\n```Rust\nlet future = async_read_file(\"foo.txt\");\nlet file_content = loop {\n    match future.poll(…) {\n        Poll::Ready(value) => break value,\n        Poll::Pending => {}, // do nothing\n    }\n}\n```\n\n在这里，我们在一个循环中调用`poll`来*积极地*等待future。 `poll`的参数在这里无关紧要，因此我们省略了它们。 尽管这个解决方案能用，但效率很低，因为我们一直使CPU忙碌，直到该值可用为止。\n\n一种更有效的方法可能是*阻塞*当前线程，直到将来数据可用。 当然，这只有在有线程的情况下才有可能，因此该解决方案不适用于我们的内核，至少目前还不能。 即使在支持阻塞的系统上，也常常不希望这样做，因为它将再次将异步任务转换为同步任务，从而抑制了并行任务的潜在性能优势。\n\n#### Future组合子\n\n等待的替代方法是使用Future的组合子。 Future组合子是类似于`map`方法，它允许将Future链接和组合在一起，类似于[`Iterator`](https://doc.rust-lang.org/stable/core/iter/trait.Iterator.html)上的方法。 这些组合器不等待Future，而是自己返回一个Future，这将对`poll`应用映射操作。\n\n例如，用于将`Future<Output=String>`转换为`Future<Output=usize>`的简单`string_len`组合器可能如下所示：\n\n```Rust\nstruct StringLen<F> {\n    inner_future: F,\n}\n\nimpl<F> Future for StringLen<F> where F: Future<Output = String> {\n    type Output = usize;\n\n    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<T> {\n        match self.inner_future.poll(cx) {\n            Poll::Ready(s) => Poll::Ready(s.len()),\n            Poll::Pending => Poll::Pending,\n        }\n    }\n}\n\nfn string_len(string: impl Future<Output = String>)\n    -> impl Future<Output = usize>\n{\n    StringLen {\n        inner_future: string,\n    }\n}\n\n// Usage\nfn file_len() -> impl Future<Output = usize> {\n    let file_content_future = async_read_file(\"foo.txt\");\n    string_len(file_content_future)\n}\n```\n\n该代码无法正常工作，因为它不处理[*固定*](https://doc.rust-lang.org/stable/core/pin/index.html)问题，但是作为示例就足够了。 基本思想是`string_len`函数将给定的`Future`实例包装到新的`StringLen`结构中，该结构还实现了`Future` 。 当对打包的future进行轮询时，它将轮询内部的未来。 如果该值尚未准备好，则包装的future也返回`Poll::Pending` 。 如果准备好该值，则从`Poll::Ready`变量中提取字符串，并计算其长度。然后，将其包装在`Poll::Ready`并返回。\n\n使用这个`string_len`函数，我们可以计算异步字符串的长度，而无需等待它。 由于该函数再次返回`Future` ，因此调用者无法直接对返回的值进行操作，而需要再次使用组合器函数。 这样，整个调用图就变得异步了，我们可以高效地在某个时候一次等待多个future，例如在main函数中。\n\n手动编写组合器函数很困难，因此它们通常由库提供。 尽管Rust标准库本身还没有提供组合器方法，但半官方（和`no_std`兼容）的[`futures`](https://docs.rs/futures/0.3.4/futures) crate却提供了。 它的[`FutureExt`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/futures/0.3.4/futures/future/trait.FutureExt.html&usg=ALkJrhip68n2ChVnp4OvzFIkddAvkNxzeA)特性提供了高级组合器方法，例如[`map`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/futures/0.3.4/futures/future/trait.FutureExt.html&usg=ALkJrhip68n2ChVnp4OvzFIkddAvkNxzeA#method.map)或[`then`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/futures/0.3.4/futures/future/trait.FutureExt.html&usg=ALkJrhip68n2ChVnp4OvzFIkddAvkNxzeA#method.then) ，可用于对future结果的操作。\n\n##### 优势\n\nFuture组合子的最大优点是它们使操作保持异步。与异步I/O接口结合使用，这种方法可以带来非常高的性能。 Future组合子是通过常规的使用struct和trait实现的，这使得编译器可以对其进行优化。 有关更多详细信息，请参阅《[Rust中的零开销Future](https://aturon.github.io/blog/2016/08/11/futures/)》一文，该文章宣布将Future添加到Rust生态系统中。\n\n##### 缺点\n\n尽管Future组合子可以编写非常有效的代码，但是由于类型系统和基于闭包的接口，在某些情况下它们可能很难使用。 例如，考虑如下代码：\n\n```Rust\nfn example(min_len: usize) -> impl Future<Output = String> {\n    async_read_file(\"foo.txt\").then(move |content| {\n        if content.len() < min_len {\n            Either::Left(async_read_file(\"bar.txt\").map(|s| content + &s))\n        } else {\n            Either::Right(future::ready(content))\n        }\n    })\n}\n```\n\n在这里，我们读取文件`foo.txt` ，然后使用[`then`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/futures/0.3.4/futures/future/trait.FutureExt.html&usg=ALkJrhip68n2ChVnp4OvzFIkddAvkNxzeA#method.then)组合器根据文件内容链接第二个future。如果内容长度小于给定的`min_len` ，我们将读取另一个`bar.txt`文件，然后使用[`map`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/futures/0.3.4/futures/future/trait.FutureExt.html&usg=ALkJrhip68n2ChVnp4OvzFIkddAvkNxzeA#method.map)组合器将其附加到`content` 。 否则，我们仅返回`foo.txt`的内容。\n\n我们需要对传递给`then`的闭包使用[`move`关键字](https://doc.rust-lang.org/std/keyword.move.html) ，因为否则将会对`min_len`造成生命周期错误。 使用[`Either`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/futures/0.3.4/futures/future/enum.Either.html&usg=ALkJrhhYdLDwZBgIEwMjk4f7ORxn8GK85Q)包装器的原因是if和else块必须始终具有相同的类型。 由于我们在块中返回了不同类型的Future，因此必须使用包装器类型将它们统一为一个类型。 [`ready`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/futures/0.3.4/futures/future/fn.ready.html&usg=ALkJrhjGlCdXHWuPkApugnx6SwnEFKiQSg)函数将值包装到将来立即准备好的future中。 这里需要该函数，因为`Either`包装器希望包装的值实现`Future` 。\n\n可以想象，这会很快导致大型项目的代码非常复杂。 如果涉及借贷和不同的生存期，则变得特别复杂。 由于这个原因，为了使异步代码从根本上更易于编写，我们投入了大量工作来为Rust添加对异步/等待的支持。\n\n### Async/Await模式\n\nasync/await背后的想法是让程序员编写*看起来*像普通同步代码的代码，但被编译器转换为异步代码。 它基于两个关键字`async`和`await`起作用。 可以在函数签名中使用`async`关键字，以将同步函数转换为返回Future的异步函数：\n\n```RustRu s\nasync fn foo() -> u32 {\n    0\n}\n\n// the above is roughly translated by the compiler to:\nfn foo() -> impl Future<Output = u32> {\n    future::ready(0)\n}\n```\n\n仅此关键字不会有用。 但是在`async`函数内部，可以使用`await`关键字来检索future的异步值：\n\n```Rust\nasync fn example(min_len: usize) -> String {\n    let content = async_read_file(\"foo.txt\").await;\n    if content.len() < min_len {\n        content + &async_read_file(\"bar.txt\").await\n    } else {\n        content\n    }\n}\n```\n\n此函数是从[上面](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://os.phil-opp.com/async-await/&usg=ALkJrhjPwHsjeYsVEhyo_3NTm2YfROaXvQ#drawbacks)使用组合子的`example`函数的直接翻译。 使用`.await`运算符，我们可以检索future的值，而无需任何闭包或`Either`类型。 结果，我们可以像编写普通的同步代码一样编写代码，区别在于*这仍然是异步代码* 。\n\n#### 状态机转换\n\n编译器在此幕后所做的就是将`async`函数的主体转换为[*状态机*](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://en.wikipedia.org/wiki/Finite-state_machine&usg=ALkJrhiQPX47iIIfJQrZOT0XJkKeYLjsdw) ，每个`.await`调用代表一个不同的状态。 对于上面的`example`函数，编译器创建具有以下四个状态的状态机：\n\n![特定状态：开始，等待foo.txt，等待bar.txt，结束](https://os.phil-opp.com/async-await/async-state-machine-states.svg)\n\n\n\n每个状态代表该函数的不同暂停点。 *“Start”*和*“End”*状态代表函数在其执行的开始和结束时的状态。 *“Waiting on foo.txt”*状态表示该函数当前正在等待第一个`async_read_file`结果。 同样， *“Waiting on bar.txt”*状态表示功能在第二个`async_read_file`结果上等待的暂停点。\n\n状态机通过使每个`poll`调用可能的状态转换来实现`Future`特性：\n\n![Four states: start, waiting on foo.txt, waiting on bar.txt, end](https://os.phil-opp.com/async-await/async-state-machine-basic.svg)\n\n该图使用箭头表示状态切换，并使用菱形表示选择执行。 例如，如果`foo.txt`文件尚未准备好，则采用标记为*“ no”*的路径，并达到*“ Waiting on foo.txt”*状态。 否则，采用*“yes”*路径。 没有标题的红色小菱形代表`example`函数的`if content.len() < 100`分支。\n\n我们看到，第一个`poll`调用启动了该函数并使它运行，直到到达尚未准备好的Future为止。 如果路径上的所有Future都准备就绪，则该函数可以运行到*“ End”*状态，并返回包装在`Poll::Ready`中的结果 。否则，状态机进入等待状态并返回`Poll::Pending` 。 在下一个`poll`呼叫中，状态机从上一个等待状态开始，然后重试上一个操作。\n\n#### 保存状态\n\n为了能够从上一个等待状态继续，状态机必须在内部跟踪当前状态。 此外，它必须保存在下一个`poll`调用中继续执行所需的所有变量。 这是编译器真正发挥作用的地方：由于它知道何时使用哪些变量，因此它可以自动生成具有所需变量的结构。\n\n作为示例，编译器为上述`example`函数生成类似于以下的结构：\n\n```Rust\n// The `example` function again so that you don't have to scroll up\nasync fn example(min_len: usize) -> String {\n    let content = async_read_file(\"foo.txt\").await;\n    if content.len() < min_len {\n        content + &async_read_file(\"bar.txt\").await\n    } else {\n        content\n    }\n}\n\n// The compiler-generated state structs:\n\nstruct StartState {\n    min_len: usize,\n}\n\nstruct WaitingOnFooTxtState {\n    min_len: usize,\n    foo_txt_future: impl Future<Output = String>,\n}\n\nstruct WaitingOnBarTxtState {\n    content: String,\n    bar_txt_future: impl Future<Output = String>,\n}\n\nstruct EndState {}\n```\n\n在“start”和*“waiting on foo.txt”*状态下，需要存储`min_len`参数，因为稍后与`content.len()`比较时需要使用该参数。 *“waiting on foo.txt”*状态还存储了一个`foo_txt_future` ，它表示`async_read_file`调用返回的future。 状态机继续运行时，需要再次轮询此future，因此需要保存它。\n\n*“waiting on bar.txt”*状态包含`content`变量，因为在`bar.txt`准备就绪后，字符串拼接需要使用该变量。 它还存储了一个`bar_txt_future` ，它表示`bar_txt_future`的正在进行中的负载。该结构不包含`min_len`变量，因为在`content.len()`比较之后不再需要它。 在*“End”*状态下，没有存储任何变量，因为该函数已经运行完毕。\n\n请记住，这只是编译器可能生成的代码的示例。 结构名称和字段布局是实现细节，可能有所不同。\n\n#### 整个状态机的类型\n\n尽管确切的编译器生成的代码是实现细节，但有助于理解想象生成的状态机如何查找`example`函数。 我们已经定义了代表不同状态并包含所需变量的结构。 为了在它们之上创建一个状态机，我们可以将它们组合成一个[`enum`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/book/ch06-01-defining-an-enum.html&usg=ALkJrhhSZuP8PCSTV4Cs7ml_J59xpRHsWQ) ：\n\n```Rust\nenum ExampleStateMachine {\n    Start(StartState),\n    WaitingOnFooTxt(WaitingOnFooTxtState),\n    WaitingOnBarTxt(WaitingOnBarTxtState),\n    End(EndState),\n}\n```\n\n我们为每个状态定义一个单独的枚举变量，并将对应的状态结构作为字段添加到每个变量。 为了实现状态转换，编译器根据`example`函数生成`Future` trait的实现：\n\n```Rust\nimpl Future for ExampleStateMachine {\n    type Output = String; // return type of `example`\n\n    fn poll(self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n        loop {\n            match self { // TODO: handle pinning\n                ExampleStateMachine::Start(state) => {…}\n                ExampleStateMachine::WaitingOnFooTxt(state) => {…}\n                ExampleStateMachine::WaitingOnBarTxt(state) => {…}\n                ExampleStateMachine::End(state) => {…}\n            }\n        }\n    }\n}\n```\n\n`Output`类型为`String`因为它是`example`函数的返回类型。 为了实现`poll`函数，我们在`loop`内的当前状态上使用match语句。 这个想法是我们尽可能长时间地切换到下一个状态，并在无法继续时使用显式`return Poll::Pending` 。\n\n为简单起见，我们仅显示简化的代码，不处理[固定](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/stable/core/pin/index.html&usg=ALkJrhgBb6s7BfzBtFOTJvpa-SiXi4xloQ) ，所有权，生命周期等。因此，此代码和以下代码应视为伪代码，不能直接使用。 当然，真正的编译器生成的代码可以正确处理所有内容，尽管可能以不同的方式进行。\n\n为了使代码片段较小，我们将分别显示每个match分支的代码。 让我们从`Start`状态开始：\n\n```Rust\nExampleStateMachine::Start(state) => {\n    // from body of `example`\n    let foo_txt_future = async_read_file(\"foo.txt\");\n    // `.await` operation\n    let state = WaitingOnFooTxtState {\n        min_len: state.min_len,\n        foo_txt_future,\n    };\n    *self = ExampleStateMachine::WaitingOnFooTxt(state);\n}\n```\n\n在函数一开始调用时，状态机就处于`Start`状态。 在这种情况下，我们将执行`example`函数主体中的所有代码，直到第一个`.await` 。 为了处理`.await`操作，我们将`self`状态机的状态更改为`WaitingOnFooTxt` ，其中包括`WaitingOnFooTxtState`结构的构造。\n\n由于`match self {…}`语句是在循环中执行的，因此该执行将跳转到下一个`WaitingOnFooTxt`：\n\n```Rust\nExampleStateMachine::WaitingOnFooTxt(state) => {\n    match state.foo_txt_future.poll(cx) {\n        Poll::Pending => return Poll::Pending,\n        Poll::Ready(content) => {\n            // from body of `example`\n            if content.len() < state.min_len {\n                let bar_txt_future = async_read_file(\"bar.txt\");\n                // `.await` operation\n                let state = WaitingOnBarTxtState {\n                    content,\n                    bar_txt_future,\n                };\n                *self = ExampleStateMachine::WaitingOnBarTxt(state);\n            } else {\n                *self = ExampleStateMachine::End(EndState));\n                return Poll::Ready(content);\n            }\n        }\n    }\n}\n```\n\n在此匹配分支中，我们首先调用`foo_txt_future`的`poll`函数。 如果其尚未准备好，则退出循环并返回`Poll::Pending` 。 由于在这种情况下`self`保持在`WaitingOnFooTxt`状态，因此状态机上的下一个`poll`调用将进入相同的匹配并再试一次。\n\n当`foo_txt_future`准备就绪时，我们将结果分配给`content`变量，然后继续执行`example`函数的代码：如果`content.len()`小于状态struct中保存的`min_len`则异步读取`bar.txt`文件。   我们再次将`.await`操作转换为状态更改，这次转换为`WaitingOnBarTxt`状态。 由于我们是在循环内执行`match` ，因此执行会直接跳到新状态的匹配分支，然后轮询`bar_txt_future` 。\n\n如果我们进入`else`分支，则不会进行进一步的`.await`操作。 我们到达函数的结尾，并返回包装在`Poll::Ready` 。 我们还将当前状态更改为`End`状态。\n\n`WaitingOnBarTxt`状态的代码如下所示：\n\n```Rust\nExampleStateMachine::WaitingOnBarTxt(state) => {\n    match state.bar_txt_future.poll(cx) {\n        Poll::Pending => return Poll::Pending,\n        Poll::Ready(bar_txt) => {\n            *self = ExampleStateMachine::End(EndState));\n            // from body of `example`\n            return Poll::Ready(state.content + &bar_txt);\n        }\n    }\n}\n```\n\n与`WaitingOnFooTxt`状态类似，我们从轮询`bar_txt_future`开始。 如果仍在等待处理，则退出循环并返回`Poll::Pending` 。 否则，我们可以执行`example`函数的最后一个操作：将`content`变量与将来的结果连接起来。 我们将状态机更新为`End`状态，然后返回包装在`Poll::Ready`的结果。\n\n最后， `End`状态的代码如下所示：\n\n```Rust\nExampleStateMachine::End(_) => {\n    panic!(\"poll called after Poll::Ready was returned\");\n}\n```\n\nFuture返回`Poll::Ready`之后，不应再次对其进行轮询，因此，如果在已经处于`End`状态的情况下调用`poll` ，我们将panic。\n\n现在我们知道了编译器生成的状态机及其对`Future` trait的实现。 实际上，编译器以不同的方式生成代码。 （如果您有兴趣，当前的实现是基于[*generator*](https://doc.rust-lang.org/nightly/unstable-book/language-features/generators.html)的 ，但这只是实现的细节。）\n\n难题的最后一部分是为`example`函数本身生成代码。 记住，函数头是这样定义的：\n\n```Rust\nasync fn example(min_len: usize) -> String\n```\n\n由于现在完整的功能主体是由状态机实现的，因此该功能唯一需要做的就是初始化状态机并将其返回。 为此生成的代码如下所示：\n\n```Rust\nfn example(min_len: usize) -> ExampleStateMachine {\n    ExampleStateMachine::Start(StartState {\n        min_len,\n    })\n}\n```\n\n该函数不再具有`async`修饰符，因为它现在显式返回`ExampleStateMachine`类型，该类型实现了`Future`特性。 如预期的那样，状态机被构造为“`Start`”状态，并且使用`min_len`参数初始化了相应的状态结构。\n\n请注意，此功能不会启动状态机的执行。 这是Rust future的一个基本设计决策：在第一次poll之前，它们什么都不做。\n\n### 固定\n\n我们已经在这篇文章中偶然发现了多次*固定* 。 现在终于可以探索固定是什么以及为什么需要固定了。\n\n#### 自引用结构\n\n如上所述，状态机转换将每个暂停点的局部变量存储在结构中。 对于像我们的`example`函数这样的小例子，这很简单，并且不会导致任何问题。 但是，当变量互相引用时，事情变得更加困难。例如，考虑以下函数：\n\n```Rust\nasync fn pin_example() -> i32 {\n    let array = [1, 2, 3];\n    let element = &array[2];\n    async_write_file(\"foo.txt\", element.to_string()).await;\n    *element\n}\n```\n\n此函数创建一个包含内容`1`，`2`和`3`的小`array` 。 然后，它创建对最后一个数组元素的引用，并将其存储在`element`变量中。 接下来，它将异步将转换为字符串的数字写入`foo.txt`文件。 最后，它返回由`element`引用的数字。\n\n由于该函数使用单个`await`操作，因此结果状态机具有三种状态：开始，结束和“等待写入”。 该函数不带参数，因此开始状态的结构为空。 像以前一样，结束状态的结构也是空的，因为该功能已在此时完成。 “等待写入”状态的结构更有趣：\n\n```Rust\nstruct WaitingOnWriteState {\n    array: [1, 2, 3],\n    element: 0x1001a, // address of the last array element\n}\n```\n\n我们需要存储`array`和`element`变量，因为返回值需要`element` ，而`array`是由`element`引用的。 由于`element`是引用，因此它存储*指向*所引用元素的*指针* （即内存地址）。我们`0x1001a`在这里以内存地址为例。实际上，它必须是`array`字段的最后一个元素的地址，因此它的值取决于该结构在内存中的位置。具有此类内部指针的结构被称为*自引用*结构，因为它们对其字段之一进行引用。\n\n#### 自我指涉的Structs存在的问题\n\n我们的自引用结构的内部指针会导致一个基本的问题，当我们查看其内存布局时，该问题变得显而易见：\n\n![array at 0x10014 with fields 1, 2, and 3; element at address 0x10020, pointing to the last array element at 0x1001a](https://os.phil-opp.com/async-await/self-referential-struct.svg)\n\n这里的`array`字段从地址0x10014开始，`element`字段从地址0x10020开始。它指向地址0x1001a，因为最后一个数组元素位于该地址。到现在为止还看不出什么问题。但是，当我们将此结构移到其他内存地址时，会发生问题：\n\n![在0x10024处具有字段1、2和3的数组； 即使最后一个数组元素现在位于0x1002a，地址0x10030处的元素仍指向0x1001a](https://os.phil-opp.com/async-await/self-referential-struct-moved.svg)\n\n我们稍微移动了结构，使其现在从`0x10024`的地址开始。例如，当我们将struct作为函数参数传递或将其赋值给其他堆栈中的变量时，可能会发生这种情况。问题在于，即使最后一个元素现在位于`0x1002a` ，该`element`字段仍然指向`0x1001a` 。因此，指针现在处于悬垂状态，结果就是在下一次调用时发生未定义的行为。\n\n#### 可能的解决方案\n\n有三种基本方法可以解决悬垂指针问题： \n\n- **在移动时更新指针：**想法是每当结构在内存中移动时都更新内部指针，以使其在移动后仍然有效。不幸的是，这种方法将需要对Rust进行大量更改，从而可能导致巨大的性能损失。原因是某种运行时需要跟踪所有结构字段的类型，并检查每个移动操作是否需要更新指针。\n\n- **存储偏移量而不是自引用：**为了避免更新指针的要求，编译器可以尝试将自引用存储为结构体开始处的偏移量。例如，`element`上面`WaitingOnWriteState`结构的`element_offset`字段可以以值8的形式存储，因为引用指向的数组元素在结构开始后的8个字节处开始。由于在移动结构时偏移量保持不变，因此不需要字段更新。\n\n  这种方法的问题在于，它要求编译器检测所有自引用。这在编译时是不可能的，因为引用的值可能取决于用户输入，因此我们将再次需要运行时来分析引用并正确创建状态结构。这不仅会导致运行时成本增加，而且还会阻止某些编译器优化，从而会再次导致较大的性能损失。\n\n- **禁止移动该结构：**如上所示，仅当我们在内存中移动该结构时，才会出现悬垂指针。通过完全禁止对自引用结构的移动操作，也可以避免该问题。这种方法的最大优点是，可以在类型系统级别上实现它，而不会增加运行时成本。缺点是它将处理移动操作的负担放在程序员的可能自引用的结构上。\n\n由于其原则是提供*零成本抽象*，这意味着抽象不应施加额外的运行时成本，因此Rust选择了第三个解决方案。为此，在[RFC 2349](https://github.com/rust-lang/rfcs/blob/master/text/2349-pin.md)中提出了[*固定*](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/stable/core/pin/index.html&usg=ALkJrhgBb6s7BfzBtFOTJvpa-SiXi4xloQ) API 。在下文中，我们将简要概述此API，并说明其如何与async / await和futures一起使用。\n\n#### 堆上的值\n\n第一个观察结果是，[堆分配的](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://os.phil-opp.com/heap-allocation/&usg=ALkJrhgeACYVwoeyL3uU2Y6L8zDc9_N_aA)值大多数时候已经具有固定的内存地址。它们是调用`allocate`创建的，然后由指针类型（如`Box`）引用。虽然可以移动指针类型，但指针指向的堆值将保持在相同的内存地址，直到`deallocate`再次通过调用将其释放为止。\n\n使用堆分配，我们可以尝试创建一个自引用结构：\n\n```Rust\nfn main() {\n    let mut heap_value = Box::new(SelfReferential {\n        self_ptr: 0 as *const _,\n    });\n    let ptr = &*heap_value as *const SelfReferential;\n    heap_value.self_ptr = ptr;\n    println!(\"heap value at: {:p}\", heap_value);\n    println!(\"internal reference: {:p}\", heap_value.self_ptr);\n}\n\nstruct SelfReferential {\n    self_ptr: *const Self,\n}\n```\n\n我们创建一个名为`SelfReferential`的简单结构，其中包含单个指针字段。首先，我们使用空指针初始化此结构，然后使用将其分配到堆上`Box::new`。然后，我们确定堆分配的结构的内存地址，并将其存储在`ptr`变量中。最后，通过将`ptr`变量分配给`self_ptr`字段，使结构自引用。\n\n在[playground中](https://play.rust-lang.org/%3Fversion%3Dstable%26mode%3Ddebug%26edition%3D2018%26gist%3Dce1aff3a37fcc1c8188eeaf0f39c97e8)执行此代码时，我们看到堆值的地址及其内部指针相等，这意味着该`self_ptr`字段是有效的自引用。由于`heap_value`变量只是指针，因此移动变量（例如，通过将其传递给函数）不会更改结构本身的地址，因此`self_ptr`即使指针被移动，其保持有效。\n\n但是，仍然有一种方法可以破坏此示例：我们可以移出`Box`或替换其内容：\n\n```Rust\nlet stack_value = mem::replace(&mut *heap_value, SelfReferential {\n    self_ptr: 0 as *const _,\n});\nprintln!(\"value at: {:p}\", &stack_value);\nprintln!(\"internal reference: {:p}\", stack_value.self_ptr);\n```\n\n在这里，我们使用该[`mem::replace`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/nightly/core/mem/fn.replace.html&usg=ALkJrhjw0xphkuD3qZU5jcZ2f63TCSH6vg)函数用新的struct实例替换堆分配的值。这使我们可以将原始对象`heap_value`移到堆栈中，而`self_ptr `struct 的字段现在是一个悬垂指针，该指针仍然指向旧的堆地址。当您尝试在playground中运行示例时，您会看到打印的*“ value at：”*和*“ internal reference：”*行确实显示了不同的指针。因此，堆分配值不足以使自引用安全。\n\n导致上述破坏的根本问题是`Box`允许我们获得`&mut T`，即对堆分配值的可变引用。该`&mut`引用使使用[`mem::replace`](https://doc.rust-lang.org/nightly/core/mem/fn.replace.html)或[`mem::swap`](https://doc.rust-lang.org/nightly/core/mem/fn.swap.html)来使得堆分配的值无效成为可能。若要解决此问题，我们必须防止`&mut`创建对自引用结构的引用。\n\n#### `Pin<Box<T>>` 和 `Unpin`\n\n固定API以`Pin`包装器类型和`Unpin`标记trait的形式提供了对`&mut T`问题的解决方案。 这些类型背后的思想是对Pin的所有能获取包装中值的的`&mut`的方法，都将其转发给`Unpin` trait。 Unpin trait是一个自动trait，对于除明确选择不实现的类型之外，所有类型均自动实现了`Unpin`。 只要自引用结构明确选择不实现Unpin，就没有（safe的）方法可以从`Pin<Box<T>>`类型获取`&mut T`。 这样做的结果就是保证了它们的内部自引用保持有效。\n\n例如，让我们更新上面的`SelfReferential`类型以选择取消固定：\n\n```Rust\nuse core::marker::PhantomPinned;\n\nstruct SelfReferential {\n    self_ptr: *const Self,\n    _pin: PhantomPinned,\n}\n```\n\n我们选择强制不实现`Unping`，方法是添加类型为[`PhantomPinned`](https://doc.rust-lang.org/nightly/core/marker/struct.PhantomPinned.html)的一个字段。此类型是大小为零的标记类型，其唯一目的是*不*实现`Unpin`特征。由于[auto trait](https://doc.rust-lang.org/reference/special-types-and-traits.html#auto-traits)的工作方式，单个不`Unpin`的字段也会使得整个struct `Unpin`。\n\n第二步是将例子中的`Box<SelfReferential>`类型更改为`Pin<Box<SelfReferential>>`类型。最简单的方法是使用[`Box::pin`](https://doc.rust-lang.org/nightly/alloc/boxed/struct.Box.html#method.pin)函数而不是[`Box::new`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/nightly/alloc/boxed/struct.Box.html&usg=ALkJrhgm5P3u85GIcQAK0vWvRdhU5G9TsA#method.new)创建堆分配的值：\n\n```Rust\nlet mut heap_value = Box::pin(SelfReferential {\n    self_ptr: 0 as *const _,\n    _pin: PhantomPinned,\n});\n```\n\n除了更改`Box::new`为`Box::pin`，我们还需要在struct初始化中添加新字段`_pin`。由于`PhantomPinned`是零大小的类型，因此我们只需要使用其类型名称即可对其进行初始化。\n\n现在，当我们[尝试运行调整后的示例时](https://play.rust-lang.org/%3Fversion%3Dstable%26mode%3Ddebug%26edition%3D2018%26gist%3D961b0db194bbe851ff4d0ed08d3bd98a)，我们发现它不能编译了：\n\n```shell\nerror[E0594]: cannot assign to data in a dereference of `std::pin::Pin<std::boxed::Box<SelfReferential>>`\n  --> src/main.rs:10:5\n   |\n10 |     heap_value.self_ptr = ptr;\n   |     ^^^^^^^^^^^^^^^^^^^^^^^^^ cannot assign\n   |\n   = help: trait `DerefMut` is required to modify through a dereference, but it is not implemented for `std::pin::Pin<std::boxed::Box<SelfReferential>>`\n\nerror[E0596]: cannot borrow data in a dereference of `std::pin::Pin<std::boxed::Box<SelfReferential>>` as mutable\n  --> src/main.rs:16:36\n   |\n16 |     let stack_value = mem::replace(&mut *heap_value, SelfReferential {\n   |                                    ^^^^^^^^^^^^^^^^ cannot borrow as mutable\n   |\n   = help: trait `DerefMut` is required to modify through a dereference, but it is not implemented for `std::pin::Pin<std::boxed::Box<SelfReferential>>`\n```\n\n发生这两个错误是因为`Pin<Box<SelfReferential>>`类型不再实现`DerefMut` trait。这正是我们想要的，因为`DerefMut` trait将返回一个`&mut`引用，我们希望避免这样做。这正是因为我们选择了不自动实现`Unpin`并更改`Box::new`为`Box::pin`。\n\n现在的问题是，编译器不仅禁止了在第16行中移动这个类型的变量，而且还禁止了在第10行中初始化`self_ptr`字段。这是因为编译器无法区分`&mut`引用的有效使用和无效使用。为了正确初始化这个结构体，我们必须使用unsafe的 [`get_unchecked_mut`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/nightly/core/pin/struct.Pin.html&usg=ALkJrhidyLKfTsLxgp8abZumPURfnAi4GQ#method.get_unchecked_mut)方法：\n\n```rust\n// safe because modifying a field doesn't move the whole struct\nunsafe {\n    let mut_ref = Pin::as_mut(&mut heap_value);\n    Pin::get_unchecked_mut(mut_ref).self_ptr = ptr;\n}\n```\n\n该[`get_unchecked_mut`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/nightly/core/pin/struct.Pin.html&usg=ALkJrhidyLKfTsLxgp8abZumPURfnAi4GQ#method.get_unchecked_mut)函数在 `Pin<&mut T>`工作，而不是在`Pin<Box<T>>`上，因此我们必须先使用[`Pin::as_mut`](https://doc.rust-lang.org/nightly/core/pin/struct.Pin.html#method.as_mut)转换值。然后，我们可以使用`get_unchecked_mut`返回的可变引用来设置字段`self_ptr`。\n\n现在剩下的唯一错误来源于`mem::replace`。此操作尝试将堆上分配的值移动到栈上，这会破坏存储在`self_ptr`字段中的自引用。通过选择不自动实现`Unpin`并使用`Pin<Box<T>>`，我们可以防止在编译时执行此操作，从而可以安全地使用自引用结构。如我们所见，编译器（暂时）无法证明自引用的创建是安全的，因此我们需要使用unsafe块并自己验证其正确性。\n\n#### 栈上的固定和`Pin<&mut T>`\n\n在上一节中，我们学习了如何用`Pin<Box<T>>`安全地创建分配了堆的自引用值。尽管这种方法可以很好地工作并且相对safe（除了unsafe的构造），但是所需的堆分配会带来性能成本。由于Rust一直希望尽可能提供*零成本的抽象*，因此固定API还允许创建`Pin<&mut T>`指向栈上分配的值的实例。\n\n与*拥有*包装值*所有权*的`Pin<Box<T>>`实例不同， `Pin<&mut T>`实例仅临时借用包装值。这使事情变得更加复杂，因为它要求程序员自己提供一些额外的保证。最重要的是，一个`Pin<&mut T>`实例必须在被引用的整个生命周期中保持固定状态，这对于基于堆栈的变量来说很难验证。为了解决这个问题，有类似[`pin-utils`](https://docs.rs/pin-utils/0.1.0-alpha.4/pin_utils/)这样的crate的存在，但除非您真的知道自己在做什么，否则我仍然不建议固定在堆栈上的变量。\n\n要进一步阅读，请查阅[`pin`模块](https://doc.rust-lang.org/nightly/core/pin/index.html)和[`Pin::new_unchecked`](https://doc.rust-lang.org/nightly/core/pin/struct.Pin.html#method.new_unchecked)方法的文档。\n\n#### 固定与Future\n\n正如我们在本文中已经看到的那样，[`Future::poll`](https://doc.rust-lang.org/nightly/core/future/trait.Future.html#tymethod.poll)方法以`Pin<&mut Self>`参数形式使用固定：\n\n```Rust\nfn poll(self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output>\n```\n\n[如上所示](https://os.phil-opp.com/async-await#self-referential-structs)，此方法采用非常规的`self: Pin<&mut Self>`而非一般的`&mut self`作为参数，从async/await创建的Future实例通常是自引用的。通过将`Self`包装入`Pin`并让编译器让async/await创建的含有自我指涉的Future不自动实现Unpin，它保证了Future在多次调用之间未在内存之间移动。这样可以确保所有内部引用仍然有效。\n\n值得注意的是，在第一个`poll`调用之前移动Future是可以的。这是由于Future是懒惰的，在第一次被poll之前什么都不做。因此生成的状态机的`start`状态，只包含了函数的参数，而不会有内部引用。为了调用`poll`，调用者必须先将future包装到`Pin`，以确保future无法再在内存中移动。由于栈上的固定很难正确完成，因此我建议为此始终使用结合[`Box::pin`](https://doc.rust-lang.org/nightly/alloc/boxed/struct.Box.html#method.pin)和[`Pin::as_mut`](https://doc.rust-lang.org/nightly/core/pin/struct.Pin.html#method.as_mut)的方式。\n\n如果你有兴趣了解如何使用栈上固定安全地实现Future的组合子函数，可以看看`futures`crate中相对较短的[`map`组合子方法](https://docs.rs/futures-util/0.3.4/src/futures_util/future/future/map.rs.html)的源码，以及有关[投影和结构的固定](https://doc.rust-lang.org/stable/std/pin/index.html#projections-and-structural-pinning)的文档。\n\n### Executors 和 Wakers\n\n使用async/await，可以以符合人的习惯却完全异步的方式处理Future。但是，正如我们从上面了解到的那样，在poll之前，Future什么都不做。这意味着我们必须在某个时候`poll`它们，否则异步代码将永远不会执行。\n\n对于单一的Future，我们总是可以使用[如上所述](https://os.phil-opp.com/async-await#waiting-on-futures)的循环手动等待每个Future。但是，这种方法效率很低，并且对于创建大量Future的程序不实用。解决此问题的最常见方法是定义一个全局*Executor*，该*Executor*负责轮询系统中的所有Future，直到完成为止。\n\n#### Executor\n\n*Executor*的目的是允许将Future作为独立的任务生成，通常通过某种`spawn`方法。然后，Executor负责轮询所有Future，直到完成为止。中心化管理所有Future的最大优势在于，每当Future返回`Poll::Pending`时，Executor就可以切换到另一个Future。因此，异步操作可以并行运行，并且CPU保持繁忙。\n\n许多*Executor*的实现也可以利用具有多个CPU内核的系统。他们创建了一个[线程池](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://en.wikipedia.org/wiki/Thread_pool&usg=ALkJrhgkcQe0TaMFtM2LMSjMFyuetBdU6w)，如果有足够的可用工作，该[线程池](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://en.wikipedia.org/wiki/Thread_pool&usg=ALkJrhgkcQe0TaMFtM2LMSjMFyuetBdU6w)就可以利用所有内核，并使用诸如[工作窃取](https://en.wikipedia.org/wiki/Work_stealing)之类的技术来平衡内核之间的负载。嵌入式系统还有一些特殊的执行器实现，它们可以优化以降低延迟和内存开销。\n\n为了避免一遍又一遍地查询Future的开销，Executor通常还利用Rust Future支持的*唤醒* API。\n\n#### Wakers\n\nWaker API背后的想法是，将特殊的[`Waker`](https://doc.rust-lang.org/nightly/core/task/struct.Waker.html)类型变量传递给包装在该[`Context`](https://doc.rust-lang.org/nightly/core/task/struct.Context.html)类型中的每次`poll`调用。此`Waker`类型变量由Executor创建，并且异步任务可以用它来表示其（部分）完成。这样Executor在相应的Waker通知它之前，就不再需要不断在先前返回了`Poll::Pending`的future上调用`poll`了。\n\n最好通过一个小例子来说明：\n\n```rust\nasync fn write_file() {\n    async_write_file(\"foo.txt\", \"Hello\").await;\n}\n```\n\n此函数将字符串“Hello”异步写入`foo.txt`文件。由于硬盘写入需要一些时间，因此`poll`此将来的首次调用很可能会返回`Poll::Pending`。但是，硬盘驱动器将在内部存储`poll`调用中的`Waker`，并在文件写入磁盘时使用它来通知执行程序。这样，执行程序`poll`在接收唤醒通知之前，不需要浪费任何时间再次poll这个future。\n\n在本文的实现部分中，当我们创建具有唤醒器支持的执行程序时，我们将详细了解`Waker`类型如何工作。\n\n### 合作式多任务？\n\n在本文的开头，我们讨论了抢先式和协作式多任务。抢占式多任务处理依靠操作系统在正在运行的任务之间进行强制切换，而协作式多任务处理则要求任务通过定期的*yield*操作自愿放弃对CPU的控制。协作方法的最大优点是任务可以自己保存状态，从而可以更有效地进行上下文切换，并可以在任务之间共享相同的调用堆栈。\n\n这可能并不明显，但是future和async/await是协作式多任务处理模式的实现： \n\n- 添加到执行器中的每个Future基本上都是一项合作任务。 \n\n- Future不使用显式的yield操作，而是通过返回\n\n  `Poll::Pending`（或最后的`Poll::Ready`）来放弃对CPU内核的控制。\n\n  - 没有什么可以强迫future放弃CPU。如果他们愿意，他们将永远无法从`poll`中返回，例如通过死循环。\n  - 由于每个future都可以阻止Executor中其他future的执行，因此我们需要相信它们不是恶意的。 \n\n- Future在内部存储了在下一次poll被调用时继续执行所需的所有状态。使用async/await，编译器会自动检测所需的所有变量，并将其存储在生成的状态机中。\n\n  - 仅保存继续所需的最小状态。 \n  - 由于`poll`方法在返回时会放弃调用堆栈，因此该堆栈可用于轮询其他future。\n\n我们看到Future和async/await非常适合协作多任务处理模式，它们只是使用一些不同的术语。因此，在下文中，我们将互换使用术语“任务”和“future”。\n\n## 实现\n\n现在，我们了解了基于Future和异步/等待的协作式多任务在Rust中的工作原理，是时候向我们的内核添加对它的支持了。由于[`Future`](https://doc.rust-lang.org/nightly/core/future/trait.Future.html) trait是`core`库的一部分，而async/await是语言本身的功能，因此我们无需做任何特殊操作即可在`#![no_std]`内核中使用它。唯一的要求是我们至少使用nightly `2020-03-25` 之后的Rust，因为在此之前async/await 不兼容`no_std`。（那以后的nightly rust版本还没有rustfmt和clippy组件，因此您可能必须将`--force`标志传递给`rustup update`，即使会删除了一些已安装的组件，使用该标志后也会执行更新。）\n\n在使用了一个足够新的nightly Rust 版本后，我们可以开始在我们`main.rs`中使用async/await：\n\n```rust\n// in src/main.rs\n\nasync fn async_number() -> u32 {\n    42\n}\n\nasync fn example_task() {\n    let number = async_number().await;\n    println!(\"async number: {}\", number);\n}\n```\n\n`async_number`函数是一个 `async fn`，因此编译器将其转换为实现了`Future`的状态机。由于该函数仅返回`42`，因此生成的future将在第一次`poll`调用时直接返回`Poll::Ready(42)`。就像`async_number`那样，`example_task`函数也是`async fn`。它等待返回的数字`async_number`，然后使用`println`宏将其打印出来。\n\n要运行`example_task`返回的future，我们需要对其进行调用`poll`，直到它通过返回来表示已完成`Poll::Ready`。为此，我们需要创建一个简单的executor类型。\n\n### 任务\n\n在开始执行执行程序之前，我们创建一个`task`模块，其具有以下`Task`类型：\n\n```rust\n// in src/lib.rs\n\npub mod task;\n```\n\n```rust\n// in src/task/mod.rs\n\nuse core::{future::Future, pin::Pin};\nuse alloc::boxed::Box;\n\npub struct Task {\n    future: Pin<Box<dyn Future<Output = ()>>>,\n}\n```\n\n该`Task`结构是一个包裹了一个堆上的，固定的，且动态派发的输出为空类型`()`的future输出。让我们详细研究一下：\n\n- 我们要求与任务相关的future返回`()`。这意味着任务不会返回任何结果，它们只是为了副作用而执行。例如，上面定义的`example_task`函数没有返回值，但是它会在屏幕上显示一些副作用。\n- `dyn`关键字表明我们存储在`Box`中的是一个[*trait对象*](https://doc.rust-lang.org/book/ch17-02-trait-objects.html)中。这意味着Future上的方法是[*动态派发*](https://doc.rust-lang.org/book/ch17-02-trait-objects.html#trait-objects-perform-dynamic-dispatch)的，从而可以在该`Task`类型中存储不同类型的Future 。这很重要，因为每个`async fn`都有自己的类型，我们希望能够创建多个不同的任务。\n- 正如我们在[固定](https://os.phil-opp.com/async-await#pinning)一节中所了解的那样，`Pin`类型可以通过将值放在堆上并防止创建对它的`&mut`引用来确保它不能在内存中移动。这很重要，因为async/await生成的future可能是自我指涉的，即包含指向自身的指针，这些指针在移动future时将失效。\n\n为了允许用future创建新`Task`，我们创建一个`new`函数：\n\n```rust\n// in src/task/mod.rs\n\nimpl Task {\n    pub fn new(future: impl Future<Output = ()> + 'static) -> Task {\n        Task {\n            future: Box::pin(future),\n        }\n    }\n}\n```\n\n该函数接受一个输出值为`()`类型的future并通过[`Box::pin`](https://doc.rust-lang.org/nightly/alloc/boxed/struct.Box.html#method.pin)函数将其固定在内存中。然后，将装入Box的future包装在`Task`结构中并返回。`'static`生命周期在此处是必须的，因为返回的`Task`可能存活任意长的时间，因此那个future也需要在那段时间内一直有效。\n\n我们还添加了一个`poll`方法，使executor可以轮询存储的future：\n\n```rust\n// in src/task/mod.rs\n\nuse core::task::{Context, Poll};\n\nimpl Task {\n    fn poll(&mut self, context: &mut Context) -> Poll<()> {\n        self.future.as_mut().poll(context)\n    }\n}\n```\n\n由于`Future`trait的[`poll`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/nightly/core/future/trait.Future.html&usg=ALkJrhjkxk--77ETh7OgMyt44sTRaCqxaA#tymethod.poll)方法希望在`Pin<&mut T>`类型上调用，因此我们使用[`Pin::as_mut`](https://doc.rust-lang.org/nightly/core/pin/struct.Pin.html#method.as_mut)方法首先转换字段`self.future`的类型。然后，我们在转换后的`self.future`字段上调用`poll`并返回结果。由于该`Task::poll`方法仅应由我们稍后创建的executor调用，因此我们将函数保留为`task`模块私有。\n\n### 简单执行器\n\n由于Executor可能非常复杂，因此，我们刻意从创建一个非常基本的执行程序开始，之后再实现功能更强大的Executor。为此，我们首先创建一个新的`task::simple_executor`子模块：\n\n```rust\n// in src/task/mod.rs\n\npub mod simple_executor;\n```\n\n```rust\n// in src/task/simple_executor.rs\n\nuse super::Task;\nuse alloc::collections::VecDeque;\n\npub struct SimpleExecutor {\n    task_queue: VecDeque<Task>,\n}\n\nimpl SimpleExecutor {\n    pub fn new() -> SimpleExecutor {\n        SimpleExecutor {\n            task_queue: VecDeque::new(),\n        }\n    }\n\n    pub fn spawn(&mut self, task: Task) {\n        self.task_queue.push_back(task)\n    }\n}\n```\n\n该结构包含一个[`VecDeque`](https://doc.rust-lang.org/stable/alloc/collections/vec_deque/struct.VecDeque.html)类型的字段`task_queue`。[`VecDeque`](https://doc.rust-lang.org/stable/alloc/collections/vec_deque/struct.VecDeque.html)类型基本上是一个允许在两端进行推入和弹出操作的向量。使用这种类型背后的想法是，我们在`spawn`方法的最后插入新任务，并从前面弹出要执行的下一个任务。这样，我们得到一简单的[FIFO队列](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)&usg=ALkJrhhRCKxAHewelZq3weF-AvTwGuZ7hQ)（*“* [先进先出](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)&usg=ALkJrhhRCKxAHewelZq3weF-AvTwGuZ7hQ)*”*）。\n\n#### Dummy Waker\n\n为了调用该`poll`方法，我们需要创建一个[`Context`](https://doc.rust-lang.org/nightly/core/task/struct.Context.html)，作为[`Waker`](https://doc.rust-lang.org/nightly/core/task/struct.Waker.html)类型的包装类型。首先，我们将创建一个不执行任何操作的Dummy唤醒器。为此，我们创建一个[`RawWaker`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/stable/core/task/struct.RawWaker.html&usg=ALkJrhjOuwz5oSe58stzvVL7q0DlBpW03w)实例，该实例定义了不同`Waker`方法的实现，然后使用[`Waker::from_raw`](https://doc.rust-lang.org/stable/core/task/struct.Waker.html#method.from_raw)函数将其转换为`Waker`：\n\n```rust\n// in src/task/simple_executor.rs\n\nuse core::task::{Waker, RawWaker};\n\nfn dummy_raw_waker() -> RawWaker {\n    todo!();\n}\n\nfn dummy_waker() -> Waker {\n    unsafe { Waker::from_raw(dummy_raw_waker()) }\n}\n```\n\n该`from_raw`函数是unsafe的，因为如果程序员不遵守文档中对`RawWaker`的要求，则会发生未定义的行为。在研究`dummy_raw_waker`函数的实现之前，我们首先尝试了解`RawWaker`类型的工作方式。\n\n##### `RawWaker`\n\n该[`RawWaker`](https://doc.rust-lang.org/stable/core/task/struct.RawWaker.html)类型要求程序员明确定义一个[*虚函数表*](https://en.wikipedia.org/wiki/Virtual_method_table)（*vtable*），该*表*指定了在`RawWaker`克隆，唤醒或删除它们时应调用的函数。此vtable的布局由[`RawWakerVTable`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/stable/core/task/struct.RawWakerVTable.html&usg=ALkJrhhw23YeIwD9TejZL0gPQapSx4FlKw)类型定义。每个函数接收一个`*const ()`参数，该参数基本上是指向某个结构的*类型被擦除掉的* `&self`指针，例如，堆上的内存分配。使用`*const ()`指针而不是适当的引用的原因是该`RawWaker`类型应该是非泛型的，但仍支持任意类型。传递给函数的指针值是[`RawWaker::new`](https://doc.rust-lang.org/stable/core/task/struct.RawWaker.html#method.new)中传入的`data`指针值。\n\n通常，`RawWaker`为包裹在[`Box`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/stable/alloc/boxed/struct.Box.html&usg=ALkJrhh5TXJ5H6x82XpGXpGzQuQC88TCeg)或[`Arc`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/stable/alloc/sync/struct.Arc.html&usg=ALkJrhhytzcnWX7C38Bdbd_rI5EPjRlGig)类型中的一些堆分配的结构创建。对于此类类型，可以使用诸如[`Box::into_raw`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/stable/alloc/boxed/struct.Box.html&usg=ALkJrhh5TXJ5H6x82XpGXpGzQuQC88TCeg#method.into_raw)之类的方法将`Box<T>`转换为`*const T`指针。然后，可以将该指针转换为匿名`*const ()`指针并传递给`RawWaker::new`。由于每个vtable函数接收同样的的`*const ()`参数，因此这些函数可以安全地将指针强制转换回`Box<T>`或 `&T`进行操作。可以想象，此过程非常危险，很容易导致错误的不确定行为。因此，除非必要，否则不建议手动创建`RawWaker`。\n\n##### Dummy`RawWaker`\n\n虽然不建议手动创建`RawWaker` ，但是目前没有其他方法可以创建一个不执行任何操作的dummy `Waker`。幸运的是，我们实际上什么也不做的事实使得实现`dummy_raw_waker`函数相对安全：\n\n```rust\n// in src/task/simple_executor.rs\n\nuse core::task::RawWakerVTable;\n\nfn dummy_raw_waker() -> RawWaker {\n    fn no_op(_: *const ()) {}\n    fn clone(_: *const ()) -> RawWaker {\n        dummy_raw_waker()\n    }\n\n    let vtable = &RawWakerVTable::new(clone, no_op, no_op, no_op);\n    RawWaker::new(0 as *const (), vtable)\n}\n```\n\n首先，我们定义两个名为`no_op`和`clone`的内部函数。`no_op`函数需要一个`*const ()`指针，但不执行任何操作。`clone`函数获取一个`*const ()`指针，并通过`dummy_raw_waker`返回一个新的`RawWaker`。我们使用这两个函数来创建一个最小的`RawWakerVTable`：`clone`函数用于克隆操作，`no_op`函数用于所有其他操作。既然`RawWaker`什么都不做，那么在克隆它时直接返回一个新`RawWaker`而不是真的克隆它也没有关系。\n\n创建`vtable`之后，我们使用[`RawWaker::new`](https://doc.rust-lang.org/stable/core/task/struct.RawWaker.html#method.new)函数创建`RawWaker`。传入的`*const ()`无关紧要，因为vtable函数均未使用它。因此，我们只传递一个空指针。\n\n#### `run`方法\n\n现在我们有了创建`Waker`实例的方法，可以使用它在executor上实现一个`run`方法。最简单的`run`方法是在循环中重复轮询所有排队的任务，直到完成所有任务。这不是很高效，因为它没有利用`Waker`类型的通知，但是它是让一切运行起来的简单方法：\n\n```rust\n// in src/task/simple_executor.rs\n\nuse core::task::{Context, Poll};\n\nimpl SimpleExecutor {\n    pub fn run(&mut self) {\n        while let Some(mut task) = self.task_queue.pop_front() {\n            let waker = dummy_waker();\n            let mut context = Context::from_waker(&waker);\n            match task.poll(&mut context) {\n                Poll::Ready(()) => {} // task done\n                Poll::Pending => self.task_queue.push_back(task),\n            }\n        }\n    }\n}\n```\n\n该函数使用`while let`循环来处理`task_queue`中的所有任务。对于每个任务，它首先通过包装由我们的`dummy_waker`函数返回的`Waker`实例来创建一个`Context`类型。然后，它使用这个`context`调用方法`Task::poll`。如果`poll`方法返回`Poll::Ready`，则任务完成，我们可以继续下一个任务。如果任务仍然存在`Poll::Pending`，我们将其再次添加到队列的后面，以便在后续循环迭代中再次对其进行轮询。\n\n#### 试一试\n\n使用我们的`SimpleExecutor`类型，我们现在可以尝试运行`main.rs`中`example_task`函数返回的任务：\n\n```rust\n// in src/main.rs\n\nuse blog_os::task::{Task, simple_executor::SimpleExecutor};\n\nfn kernel_main(boot_info: &'static BootInfo) -> ! {\n    // […] initialization routines, including `init_heap`\n\n    let mut executor = SimpleExecutor::new();\n    executor.spawn(Task::new(example_task()));\n    executor.run();\n\n    // […] test_main, \"it did not crash\" message, hlt_loop\n}\n\n\n// Below is the example_task function again so that you don't have to scroll up\n\nasync fn async_number() -> u32 {\n    42\n}\n\nasync fn example_task() {\n    let number = async_number().await;\n    println!(\"async number: {}\", number);\n}\n```\n\n当我们运行它时，我们可以看到预期的*“async number: 42”*消息打印到屏幕上：\n\n![QEMU printing \"Hello World\", \"async number: 42\", and \"It did not crash!\"](https://os.phil-opp.com/async-await/qemu-simple-executor.png)\n\n让我们总结一下此示例发生的各个步骤： \n\n- 首先，使用一个空的`task_queue`创建一个我们`SimpleExecutor`类型的新实例。\n\n- 接下来，我们调用异步`example_task`函数，该函数返回一个future。我们将这个future包装在`Task`类型中，将其移动到堆中并固定，然后通过`spawn`方法将任务添加到`Executor`的`task_queue`。\n\n- 然后，我们调用该`run`方法以开始执行队列中的单个任务。\n\n  这涉及：\n\n  - 从`task_queue`头部弹出任务。\n  - 为任务创建一个`RawWaker`，将其转换为[`Waker`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/nightly/core/task/struct.Waker.html&usg=ALkJrhh1VExi94vM8AqKJrzNZJgsyP4dPw)实例，然后从中创建一个[`Context`](https://doc.rust-lang.org/nightly/core/task/struct.Context.html)实例。\n  - 使用我们刚创建的`Context`实例在任务的future上调用[`poll`](https://doc.rust-lang.org/nightly/core/future/trait.Future.html#tymethod.poll)方法。\n  - 由于`example_task`无需等待，因此可以直接在第一次`poll`调用就运行到底。也就会打印出*“async number:42”*。\n  - 由于`example_task`直接返回`Poll::Ready`，因此不会将其添加回任务队列。\n\n- `task_queue`变为空后，`run`方法返回。我们的`kernel_main`功能继续执行，并且打印\"*It did not crash!*\"信息。\n\n### 异步键盘输入\n\n我们简单的executor不使用`Waker`通知，而是循环遍历所有任务，直到完成为止。对于我们的例子来说，这不是问题，因为我们`example_task`可以直接在第一次`poll`调用时就运行完。要观察适当`Waker`实现的性能优势，我们首先需要创建一个真正异步的任务，即在第一次`poll`调用时可能返回`Poll::Pending`的任务。\n\n我们的系统中已经存在某种异步性：硬件中断。正如我们在[*硬件中断一文中*](https://os.phil-opp.com/hardware-interrupts)了解到的那样，硬件中断可以在取决于某些外部设备的任意时间发生。例如，在经过一段预定义的时间后，硬件计时器将中断发送到CPU。当CPU接收到中断时，它将立即将控制权转移到在中断描述符表（IDT）中定义的相应处理程序。\n\n下面，我们将基于键盘中断创建一个异步任务。键盘中断是一个很好的选择，因为它既不确定又对延迟至关重要。非确定性意味着无法预测下一次按键的发生时间，因为它完全取决于用户。延迟关键性意味着我们要及时处理键盘输入，否则用户会感到系统卡顿。为了以有效的方式支持此类任务，executor必须具有适当的`Waker`通知支持，这一点至关重要。\n\n#### 扫描码队列\n\n当前，我们直接在中断处理程序中处理键盘输入。从长远来看，这不是一个好主意，因为中断处理程序应尽可能短，因为它们可能会中断重要的工作。更好的方案是，中断处理程序仅执行必要的最少工作量（例如，读取键盘扫描码），而将其余工作（例如，解释扫描码）留给后台任务。\n\n将工作委派给后台任务的常见模式是创建某种队列。中断处理程序将工作单元推送到队列，而后台任务处理队列中的工作。应用于我们的键盘中断，这意味着中断处理程序仅从键盘读取扫描代码，然后将其推送到队列，然后返回。键盘任务位于队列的另一端，并解释和处理推入队列的每个扫描代码：\n\n\n\n![Scancode queue with 8 slots on the top. Keyboard interrupt handler on the bottom left with a \"push scancode\" arrow to the left of the queue. Keyboard task on the bottom right with a \"pop scancode\" queue coming from the right side of the queue.](https://os.phil-opp.com/async-await/scancode-queue.svg)\n\n\n\n该队列的一个简单实现可以是用互斥锁保护的[`VecDeque`](https://doc.rust-lang.org/stable/alloc/collections/vec_deque/struct.VecDeque.html)。但是，在中断处理程序中使用互斥锁不是一个好主意，因为它很容易导致死锁。例如，当用户在键盘任务锁定队列时按下某个键时，中断处理程序将尝试再次获取该锁定并无限期挂起。这种方法的另一个问题是，`VecDeque`满时，会进行新的堆分配来自动增加其容量。这可能再次导致死锁，因为我们的分配器还在内部使用了互斥锁。更进一步的问题是，当堆碎片化时，堆分配可能会失败或花费大量时间。\n\n为避免这些问题，我们需要更好的一个队列实现，该队列实现不需要互斥量或在`push`操作时分配内存。可以通过使用无锁[原子操作](https://doc.rust-lang.org/core/sync/atomic/index.html)来推送和弹出元素来实现此类队列。这样，`push`和`pop`操作仅需要`&self`引用，因此无需互斥即可使用。为了避免在`push`时分配内存，可以使用预先分配的固定大小的缓冲区来支持队列。虽然这使队列*有界*（即具有一个固定的最大长度），但实际上通常可以为队列长度定义合理的上限，因此这样做问题不大。\n\n##### `crossbeam` Crate\n\n以正确有效的方式实现这样的队列非常困难，因此我建议坚持使用经过良好测试的现有实现。有一个流行的Rust项目[`crossbeam`](https://github.com/crossbeam-rs/crossbeam)实现了并发编程的各种无锁类型。它提供了一个名为[`ArrayQueue`](https://docs.rs/crossbeam/0.7.3/crossbeam/queue/struct.ArrayQueue.html)的类型，正是这种情况下我们需要的类型。而且我们很幸运：该类型与具有内存分配支持的`no_std` crate完全兼容。\n\n要使用该类型，我们需要添加一个依赖项`crossbeam-queue` crate：\n\n```toml\n# in Cargo.toml\n\n[dependencies.crossbeam-queue]\nversion = \"0.2.1\"\ndefault-features = false\nfeatures = [\"alloc\"]\n```\n\n默认情况下，crate使用了标准库。为了使其与`no_std`兼容，我们需要禁用其默认功能，同时启用该`alloc`功能。（请注意，`crossbeam` crate在这里不能用，因为它在`no_std`下没有导出 `queue`模块。我提出了[拉取请求](u=https://github.com/crossbeam-rs/crossbeam/pull/480)以解决此问题，但这个版本尚未在crates.io上发布。）\n\n##### 队列的实现\n\n使用该`ArrayQueue`类型，我们现在可以在新`task::keyboard`模块中创建全局扫描代码队列：\n\n```rust\n// in src/task/mod.rs\n\npub mod keyboard;\n```\n\n```rust\n// in src/task/keyboard.rs\n\nuse conquer_once::spin::OnceCell;\nuse crossbeam_queue::ArrayQueue;\n\nstatic SCANCODE_QUEUE: OnceCell<ArrayQueue<u8>> = OnceCell::uninit();\n```\n\n由于[`ArrayQueue::new`](https://docs.rs/crossbeam/0.7.3/crossbeam/queue/struct.ArrayQueue.htm#method.new)执行堆分配，而这（[暂时](https://github.com/rust-lang/const-eval/issues/20)）是在编译时不能进行的，因此我们无法直接初始化静态变量。相反，我们使用[`conquer_once`](https://docs.rs/conquer-once/0.2.0/conquer_once/index.html) crate 的[`OnceCell`](https://docs.rs/conquer-once/0.2.0/conquer_once/raw/struct.OnceCell.html)类型，这使得执行安全的静态值一次性初始化成为可能。要使用这个crate，我们需要将其作为依赖项添加到我们的`Cargo.toml`：\n\n```toml\n# in Cargo.toml\n\n[dependencies.conquer-once]\nversion = \"0.2.0\"\ndefault-features = false\n```\n\n除了[`OnceCell`](https://docs.rs/conquer-once/0.2.0/conquer_once/raw/struct.OnceCell.html)，我们还可以在此处使用[`lazy_static`](https://docs.rs/lazy_static/1.4.0/lazy_static/index.html)宏。但是，`OnceCell`类型的优点是我们可以确保初始化不会在中断处理程序中发生，从而防止了在中断处理程序中执行堆分配。\n\n#### 填充队列\n\n为了填充扫描代码队列，我们创建了一个新`add_scancode`函数，我们将会从中断处理程序中调用它：\n\n```rust\n// in src/task/keyboard.rs\n\nuse crate::println;\n\n/// Called by the keyboard interrupt handler\n///\n/// Must not block or allocate.\npub(crate) fn add_scancode(scancode: u8) {\n    if let Ok(queue) = SCANCODE_QUEUE.try_get() {\n        if let Err(_) = queue.push(scancode) {\n            println!(\"WARNING: scancode queue full; dropping keyboard input\");\n        }\n    } else {\n        println!(\"WARNING: scancode queue uninitialized\");\n    }\n}\n```\n\n我们使用[`OnceCell::try_get`](https://docs.rs/conquer-once/0.2.0/conquer_once/raw/struct.OnceCell.html#method.try_get)来获取对初始化过的队列的引用。如果队列尚未初始化，我们将忽略键盘扫描码并打印警告。重要的是我们不会尝试在此函数中初始化队列，因为它将由中断处理程序调用，该中断处理程序不应执行堆分配。由于不应从`main.rs`调用此函数，我们使用`pub(crate)`可见性使得其仅在`lib.rs`中可用。\n\n[`ArrayQueue::push`](https://docs.rs/crossbeam/0.7.3/crossbeam/queue/struct.ArrayQueue.html#method.push)方法仅需要`&self`引用，这使得在静态队列上调用该方法非常简单。`ArrayQueue`类型本身会执行所有必要的同步，因此这里不需要互斥包装。如果队列已满，我们也会打印警告。\n\n为了在键盘中断时调用`add_scancode`函数，我们要更新在`interrupts`模块中的`keyboard_interrupt_handler`函数：\n\n```rust\n// in src/interrupts.rs\n\nextern \"x86-interrupt\" fn keyboard_interrupt_handler(\n    _stack_frame: &mut InterruptStackFrame\n) {\n    use x86_64::instructions::port::Port;\n\n    let mut port = Port::new(0x60);\n    let scancode: u8 = unsafe { port.read() };\n    crate::task::keyboard::add_scancode(scancode); // new\n\n    unsafe {\n        PICS.lock()\n            .notify_end_of_interrupt(InterruptIndex::Keyboard.as_u8());\n    }\n}\n```\n\n我们从该函数中删除了所有键盘处理代码，而是添加了对`add_scancode`函数的调用。其余功能与以前相同。\n\n不出所料，当我们`cargo xrun`现在使用项目运行项目时，按键不再显示在屏幕上。取而代之的是，每次击键时我们都会看到未初始化scancode队列的警告。\n\n#### 键盘扫描码Stream\n\n要`SCANCODE_QUEUE`以异步方式初始化并从队列中读取扫描代码，我们需要创建一个新`ScancodeStream`类型：\n\n```rust\n// in src/task/keyboard.rs\n\npub struct ScancodeStream {\n    _private: (),\n}\n\nimpl ScancodeStream {\n    pub fn new() -> Self {\n        SCANCODE_QUEUE.try_init_once(|| ArrayQueue::new(100))\n            .expect(\"ScancodeStream::new should only be called once\");\n        ScancodeStream { _private: () }\n    }\n}\n```\n\n`_private`域的目的是防止从模块外部构造结构。这使`new`函数成为构造该类型的唯一方法。在函数中，我们首先尝试初始化`SCANCODE_QUEUE`静态变量。如果它已经初始化，则panic，以确保只能为`ScancodeStream`创建一个实例。\n\n为了使扫描代码可用于异步任务，下一步是实现与`poll`类似的方法，该方法尝试将下一个扫描代码弹出队列。虽然这听起来像我们应该为我们的类型实现[`Future`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/nightly/core/future/trait.Future.html&usg=ALkJrhjkxk--77ETh7OgMyt44sTRaCqxaA) trait，但这在这里并不完全合适。问题在于，`Future`特征仅抽象出一个异步值，并且期望该`poll`方法返回`Poll::Ready`后不再被调用。但是，我们的扫描代码队列包含多个异步值，因此可以继续对其进行polling。\n\n##### `Stream` Trait\n\n由于产生多个异步值的类型很常见，所以[`futures`](https://docs.rs/futures/0.3.4/futures) crate为此类类型提供了有用的抽象：[`Stream`](https://rust-lang.github.io/async-book/05_streams/01_chapter.html) trait。Trait定义如下：\n\n```rust\npub trait Stream {\n    type Item;\n\n    fn poll_next(self: Pin<&mut Self>, cx: &mut Context)\n        -> Poll<Option<Self::Item>>;\n}\n```\n\n此定义与[`Future`](https://doc.rust-lang.org/nightly/core/future/trait.Future.html) trait非常相似，但有以下区别：\n\n- 关联的类型名为`Item`而不是`Output`。\n- 代替返回`Poll<Self::Item>`的`poll`方法，`Stream` trait定义了`poll_next`方法，该方法返回一个`Poll<Option<Self::Item>>`（注意多出来的`Option`）。\n\n还有一个语义上的区别：`poll_next`可以重复调用，直到返回`Poll::Ready(None)`以表明流已完成。在这方面，该方法类似于在最后一个值之后[`Iterator::next`](https://doc.rust-lang.org/stable/core/iter/trait.Iterator.html#tymethod.next)方法返回`None`。\n\n##### 实现`Stream`\n\n让我们为`ScancodeStream`实现`Stream` trait来以异步方式提供`SCANCODE_QUEUE`的值。为此，我们首先需要添加对`futures-util` crate的依赖关系，其中包含`Stream`类型：\n\n```toml\n# in Cargo.toml\n\n[dependencies.futures-util]\nversion = \"0.3.4\"\ndefault-features = false\nfeatures = [\"alloc\"]\n```\n\n我们禁用默认feature以使crate 与 `no_std`兼容，同时也要启用`alloc ` feature以使其基于分配的类型可用（稍后我们将需要它）。（请注意，我们还可以在主`futures`包装箱上添加一个依赖项，从而重新导出该`futures-util`包装箱，但这将导致更多的依赖项和更长的编译时间。）\n\n现在我们可以导入并实现`Stream`特征：\n\n```rust\n// in src/task/keyboard.rs\n\nuse core::{pin::Pin, task::{Poll, Context}};\nuse futures_util::stream::Stream;\n\nimpl Stream for ScancodeStream {\n    type Item = u8;\n\n    fn poll_next(self: Pin<&mut Self>, cx: &mut Context) -> Poll<Option<u8>> {\n        let queue = SCANCODE_QUEUE.try_get().expect(\"not initialized\");\n        match queue.pop() {\n            Ok(scancode) => Poll::Ready(Some(scancode)),\n            Err(crossbeam_queue::PopError) => Poll::Pending,\n        }\n    }\n}\n```\n\n我们首先使用该[`OnceCell::try_get`](https://docs.rs/conquer-once/0.2.0/conquer_once/raw/struct.OnceCell.html#method.try_get)方法来获取对初始化的扫描代码队列的引用。这应该永远不会失败，因为我们在`new`函数中初始化了队列，我们可以安全地使用`expect`方法在未初始化队列时panic。接下来，我们使用[`ArrayQueue::pop`](https://docs.rs/crossbeam/0.7.3/crossbeam/queue/struct.ArrayQueue.html#method.pop)方法尝试从队列中获取下一个元素。如果成功，我们返回包裹在`Poll::Ready(Some(…))`中的键盘扫描代码。如果失败，则表示队列为空。在这种情况下，我们返回`Poll::Pending`。\n\n#### Waker支持\n\n与该`Futures::poll`方法类似，`Stream::poll_next`方法要求异步任务在`Poll::Pending`返回后准备就绪时通知执行程序。这样，执行程序无需再次poll相同的任务，直到waker通知它为止，这大大降低了等待任务的性能开销。\n\n要发送此通知，任务应从传入的[`Context`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/nightly/core/task/struct.Context.html&usg=ALkJrhienQeYRRGlCkB2M_ymB7qxtTE8Gg)引用中提取[`Waker`](https://doc.rust-lang.org/nightly/core/task/struct.Waker.html)并将其存储在某处。当任务准备就绪时，它应该调用`Waker`存储的[`wake`](https://doc.rust-lang.org/stable/core/task/struct.Waker.html#method.wake)方法以通知executor应该再次轮询任务。\n\n##### AtomicWaker\n\n要为`ScancodeStream`实现`Waker`通知，我们需要一个可以在两次轮询调用之间存储`Waker`的位置。我们不能将其存储为`ScancodeStream`本身的字段，因为需要从`add_scancode`函数中对其进行访问。解决方案是使用crate `futures-util`提供的 [`AtomicWaker`](https://docs.rs/futures-util/0.3.4/futures_util/task/struct.AtomicWaker.html)类型的静态变量。与`ArrayQueue`类型一样，此类型也基于原子指令，可以安全地存储在static变量中并可以并发安全地进行修改。\n\n让我们使用[`AtomicWaker`](https://docs.rs/futures-util/0.3.4/futures_util/task/struct.AtomicWaker.htmlA)类型来定义一个静态变量 `WAKER`：\n\n```rust\n// in src/task/keyboard.rs\n\nuse futures_util::task::AtomicWaker;\n\nstatic WAKER: AtomicWaker = AtomicWaker::new();\n```\n\n`poll_next`的实现会将waker放在这个static里，并且当`add_scancode`将新的扫描代码添加到队列时会调用这个`wake`函数。\n\n##### 存放Waker\n\n`poll`/`poll_next` 要求任务在返回 `Poll::Pending` 时为传入的Waker注册一个唤醒函数。让我们修改`poll_next`实现以满足这些要求：\n\n```rust\n// in src/task/keyboard.rs\n\nimpl Stream for ScancodeStream {\n    type Item = u8;\n\n    fn poll_next(self: Pin<&mut Self>, cx: &mut Context) -> Poll<Option<u8>> {\n        let queue = SCANCODE_QUEUE\n            .try_get()\n            .expect(\"scancode queue not initialized\");\n\n        // fast path\n        if let Ok(scancode) = queue.pop() {\n            return Poll::Ready(Some(scancode));\n        }\n\n        WAKER.register(&cx.waker());\n        match queue.pop() {\n            Ok(scancode) => {\n                WAKER.take();\n                Poll::Ready(Some(scancode))\n            }\n            Err(crossbeam_queue::PopError) => Poll::Pending,\n        }\n    }\n}\n```\n\n像之前一样，我们首先使用[`OnceCell::try_get`](https://docs.rs/conquer-once/0.2.0/conquer_once/raw/struct.OnceCell.html#method.try_get)函数来获取对初始化的scancode队列的引用。然后，我们乐观地尝试`pop`从队列中返回并`Poll::Ready`在成功时返回。这样，我们可以避免在队列不为空时注册唤醒程序的性能开销。\n\n如果第一次调用`queue.pop()`失败，则队列可能为空。这里用“可能”是因为中断处理程序可能在检查后立即异步填充了队列。由于此竞态条件可能在下一次检查时再次出现，因此我们需要在第二次检查之前在`WAKER`静态变量中注册`Waker`。这样，在我们返回`Poll::Pending`之前可能会发生唤醒，但是这可以确保在检查后推送的所有扫描代码都能够触发唤醒。\n\n在通过函数[`AtomicWaker::register`](https://docs.rs/futures-util/0.3.4/futures_util/task/struct.AtomicWaker.html#method.register)注册了传入的[`Context`](https://doc.rust-lang.org/nightly/core/task/struct.Context.html)中的`Waker`后，我们尝试再次从队列中弹出。如果现在成功了，我们将返回`Poll::Ready`。我们还使用[`AtomicWaker::take`](https://docs.rs/futures/0.3.4/futures/task/struct.AtomicWaker.html#method.take)再次删除了已注册的唤醒器，因为不再需要唤醒器通知。万一`queue.pop()`第二次失败，我们会像以前一样返回`Poll::Pending`，但是这次注册过了唤醒。\n\n请注意，对于不返回`Poll::Pending`的任务，也在两种情况下可能会被唤醒。一种方法是在返回`Poll::Pending`之前立即发生唤醒时提到的竞态条件。另一种方法是在注册唤醒程序后队列不再为空时`Poll::Ready`返回。由于这些伪造的唤醒是无法避免的，因此执行者需要能够正确处理它们。\n\n##### 唤醒存储的Waker\n\n要唤醒存储的`Waker`，我们在`add_scancode`函数中添加了对`WAKER.wake()`的调用：\n\n```rust\n// in src/task/keyboard.rs\n\npub(crate) add_scancode(scancode: u8) {\n    if let Ok(queue) = SCANCODE_QUEUE.try_get() {\n        if let Err(_) = scancode_queue.push(scancode) {\n            println!(\"WARNING: scancode queue full; dropping keyboard input\");\n        } else {\n            WAKER.wake(); // new\n        }\n    } else {\n        println!(\"WARNING: scancode queue uninitialized\");\n    }\n}\n```\n\n我们做的唯一更改是，如果成功推送到scancode队列，则添加一个对`WAKER.wake()`的调用。如果唤醒程序在`WAKER`静态变量中注册过，则此方法将在其上调用同名方法[`wake`](https://doc.rust-lang.org/stable/core/task/struct.Waker.html#method.wake)，该方法将会通知executor。否则，该操作为空操作，即什么都不会发生。\n\n重要的是，我们仅在推送到队列后才调用`wake`，因为否则当队列仍然为空时，可能会太早唤醒任务。例如，当使用多线程执行程序在另一个CPU内核上同时启动唤醒的任务时，可能会发生这种情况。虽然我们还没有支持线程，但我们会尽快添加它，并且我们不希望那时出现问题。\n\n#### 键盘任务\n\n现在，我们已经为`ScancodeStream`实现了`Stream  `trait，我们可以使用它来创建异步键盘任务：\n\n```rust\n// in src/task/keyboard.rs\n\nuse futures_util::stream::StreamExt;\nuse pc_keyboard::{layouts, DecodedKey, HandleControl, Keyboard, ScancodeSet1};\nuse crate::print;\n\npub async fn print_keypresses() {\n    let mut scancodes = ScancodeStream::new();\n    let mut keyboard = Keyboard::new(layouts::Us104Key, ScancodeSet1,\n        HandleControl::Ignore);\n\n    while let Some(scancode) = scancodes.next().await {\n        if let Ok(Some(key_event)) = keyboard.add_byte(scancode) {\n            if let Some(key) = keyboard.process_keyevent(key_event) {\n                match key {\n                    DecodedKey::Unicode(character) => print!(\"{}\", character),\n                    DecodedKey::RawKey(key) => print!(\"{:?}\", key),\n                }\n            }\n        }\n    }\n}\n```\n\n该代码与我们在本文中对其进行修改之前的[键盘中断处理程序中](https://os.phil-opp.com/hardware-interrupts#interpreting-the-scancodes)使用的代码非常相似。唯一的区别是，我们不是从I/O端口读取扫描代码，而是从`ScancodeStream`那里获取它。为此，我们首先创建一个新`Scancode`流，然后重复使用[`StreamExt`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/futures-util/0.3.4/futures_util/stream/trait.StreamExt.html&usg=ALkJrhi9qF4h34_mgzwOmdMkkTUAoNktzg) trait提供的[`next`](https://docs.rs/futures-util/0.3.4/futures_util/stream/trait.StreamExt.html#method.next)方法来获取包裹了流中下一个元素的`Future`。通过在其上使用`await`，我们异步等待将来的结果。\n\n我们使用`while let`循环，直到流返回`None`以表示其结束。由于我们的`poll_next`方法从不返回`None`，因此实际上这是一个无休止的循环，因此`print_keypresses`任务永远不会完成。\n\n让我们将`print_keypresses`任务添加到`main.rs`的执行器中，以便再次获得有效的键盘输入：\n\n```rust\n// in src/main.rs\n\nuse blog_os::task::keyboard; // new\n\nfn kernel_main(boot_info: &'static BootInfo) -> ! {\n\n    // […] initialization routines, including init_heap, test_main\n\n    let mut executor = SimpleExecutor::new();\n    executor.spawn(Task::new(example_task()));\n    executor.spawn(Task::new(keyboard::print_keypresses())); // new\n    executor.run();\n\n    // […] \"it did not crash\" message, hlt_loop\n}\n```\n\n现在执行时`cargo xrun`，我们看到键盘输入再次能用了：\n\n![QEMU printing \".....H...e...l...l..o..... ...W..o..r....l...d...!\"](https://os.phil-opp.com/async-await/qemu-keyboard-output.gif)\n\n如果您关注计算机的CPU利用率，您会发现该`QEMU`进程现在持续使CPU处于繁忙状态。发生这种情况是因为我们的`SimpleExecutor`poll任务反复循环进行。因此，即使我们没有按键盘上的任何键，执行器也会重复调用`poll`我们的`print_keypresses`任务，即使该任务无法取得任何进展并且`Poll::Pending`每次都会返回。\n\n### Waker支持下的Executor\n\n为了解决性能问题，我们需要创建一个可以正确利用`Waker`通知的执行程序。这样，当下一个键盘中断发生时，将通知执行程序，因此它不需要一遍又一遍地poll`print_keypresses`任务。\n\n#### 任务编号\n\n创建支持waker通知的执行程序的第一步是为每个任务赋予唯一的ID。这是必需的，因为我们需要一种方法来指定应唤醒的任务。我们首先创建一个新的`TaskId`包装器类型：\n\n```rust\n// in src/task/mod.rs\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]\nstruct TaskId(usize);\n```\n\n`TaskId`结构是对`usize`的简单包装。我们为它derive了许多trait，使其可打印，可复制，可比较和可排序。后者很重要，因为我们想马上将其`TaskId`用作[`BTreeMap`](https://doc.rust-lang.org/alloc/collections/btree_map/struct.BTreeMap.html)的键类型。\n\n为了为每个任务分配唯一的ID，我们利用了每个任务都存储固定的，由堆分配的Future这一特点：\n\n```rust\npub struct Task {\n    future: Pin<Box<dyn Future<Output = ()>>>,\n}\n```\n\n主要想法是使用此future的内存地址作为ID。该地址是唯一的，因为没有两个future存储在同一地址。`Pin`类型确保他们不能在内存中移动，所以我们也知道地址保持不变，只要任务存在。这些属性使地址成为ID的良好候选者。\n\n实现看起来像这样：\n\n```rust\n// in src/task/mod.rs\n\nimpl Task {\n    fn id(&self) -> TaskId {\n        use core::ops::Deref;\n\n        let addr = Pin::deref(&self.future) as *const _ as *const () as usize;\n        TaskId(addr)\n    }\n}\n```\n\n我们使用[`Deref`](https://doc.rust-lang.org/core/ops/trait.Deref.html) trait的`deref`方法来获取对将来分配的堆的引用。为了获得相应的内存地址，我们将此引用转换为原始指针，然后转换为`usize`。最后，我们返回包装在`TaskId`结构中的地址。\n\n#### `Executor`类型\n\n我们在`task::executor`模块中创建新`Executor`：\n\n```rust\n// in src/task/mod.rs\n\npub mod executor;\n```\n\n```rust\n// in src/task/executor.rs\n\nuse super::{Task, TaskId};\nuse alloc::{collections::{BTreeMap, VecDeque}, sync::Arc};\nuse core::task::Waker;\nuse crossbeam_queue::ArrayQueue;\n\npub struct Executor {\n    task_queue: VecDeque<Task>,\n    waiting_tasks: BTreeMap<TaskId, Task>,\n    wake_queue: Arc<ArrayQueue<TaskId>>,\n    waker_cache: BTreeMap<TaskId, Waker>,\n}\n\nimpl Executor {\n    pub fn new() -> Self {\n        Executor {\n            task_queue: VecDeque::new(),\n            waiting_tasks: BTreeMap::new(),\n            wake_queue: Arc::new(ArrayQueue::new(100)),\n            waker_cache: BTreeMap::new(),\n        }\n    }\n}\n```\n\n除了存储准备执行的任务的`task_queue`之外，该类型还具有个`waiting_tasks` map，一个 `wake_queue`和一个 `waker_cache`。这些字段具有以下目的：\n\n- `waiting_tasks `map存储了返回`Poll::Pending`的任务。map由`TaskId`索引，以允许有效地继续执行特定任务。\n\n- `wake_queue` 是一个task ID的 [`ArrayQueue`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/crossbeam/0.7.3/crossbeam/queue/struct.ArrayQueue.html&usg=ALkJrhgYss2zDLVUgDk7pgbZR6MKjexiCw)，被包装入[`Arc`](https://doc.rust-lang.org/stable/alloc/sync/struct.Arc.html)，一个实现*引用计数*的类型。通过引用计数，可以在多个所有者之间共享所有权。它的工作原理是在堆上分配值并计算对其的引用数。当引用的数量达到零时，说明不再需要该值，可以将其释放。\n\n  我们将`Arc`包装器用于`wake_queue`因为它将在执行者和唤醒者之间共享。这个想法是唤醒者将已唤醒任务的ID推入队列。执行程序位于队列的接收端，并将所有唤醒的任务从`waiting_tasks`映射移回到`task_queue`。使用固定大小队列而不是无限制队列，如[`SegQueue`](https://docs.rs/crossbeam-queue/0.2.1/crossbeam_queue/struct.SegQueue.html)的原因是，不能在其中进行动态内存分配的的中断处理程序将推送到此队列。\n\n- 任务创建后，`waker_cache` map会对[`Waker`](https://doc.rust-lang.org/nightly/core/task/struct.Waker.html)进行缓存。这有两个原因：首先，它通过将同一唤醒程序重复用于同一任务的多次唤醒来提高性能，而不是每次都创建一个新的唤醒程序。其次，它确保不会在中断处理程序中释放`Arc`中的唤醒程序，因为这可能会导致死锁（下面有更多详细信息）。\n\n要创建一个`Executor`，我们提供了一个简单的`new`功能。我们选择的容量为100 `wake_queue`，这在可预见的将来应该足够了。如果我们的系统在某个时候将有100个以上的并发任务，我们可以轻松地增加这个大小。\n\n#### Spawn任务\n\n至于`SimpleExecutor`，我们在`Executor`类型上提供了一个`spawn`方法，可将给定的任务添加到`task_queue`：\n\n```rust\n// in src/task/executor.rs\n\nimpl Executor {\n    pub fn spawn(&mut self, task: Task) {\n        self.task_queue.push_back(task)\n    }\n}\n```\n\n由于此方法需要对executor的`&mut`引用，此方法executor启动后不可调用。如果要让任务本身在某个时候产生其他任务，我们可以将任务队列的类型更改为并发队列，例如[`SegQueue`](https://docs.rs/crossbeam-queue/0.2.1/crossbeam_queue/struct.SegQueue.html)并与任务共享对此队列的引用。\n\n#### 运行任务\n\n要执行`task_queue`中的所有任务，我们创建一个私有`run_ready_tasks`方法：\n\n```rust\n// in src/task/executor.rs\n\nuse core::task::{Context, Poll};\n\nimpl Executor {\n    fn run_ready_tasks(&mut self) {\n        while let Some(mut task) = self.task_queue.pop_front() {\n            let task_id = task.id();\n            if !self.waker_cache.contains_key(&task_id) {\n                self.waker_cache.insert(task_id, self.create_waker(task_id));\n            }\n            let waker = self.waker_cache.get(&task_id).expect(\"should exist\");\n            let mut context = Context::from_waker(waker);\n            match task.poll(&mut context) {\n                Poll::Ready(()) => {\n                    // task done -> remove cached waker\n                    self.waker_cache.remove(&task_id);\n                }\n                Poll::Pending => {\n                    if self.waiting_tasks.insert(task_id, task).is_some() {\n                        panic!(\"task with same ID already in waiting_tasks\");\n                    }\n                },\n            }\n        }\n    }\n}\n```\n\n此函数的基本思想类似于我们的`SimpleExecutor`：遍历`task_queue`中的所有任务，为每个任务创建一个唤醒器，然后对其进行poll。但是，我们没有将待处理的任务添加回`task_queue`的末尾，而是将它们存储在`waiting_tasks` map中，直到再次唤醒它们为止。唤醒器的创建是通过`create_waker`方法完成的，稍后将展示其实现。\n\n为了避免每次poll时都创建唤醒程序的性能开销，我们使用`waker_cache` map在创建每个任务后为每个任务存储唤醒程序。为此，我们首先使用[`BTreeMap::contains_key`](https://doc.rust-lang.org/alloc/collections/btree_map/struct.BTreeMap.html#method.contains_key)方法检查任务是否存在缓存的唤醒器。如果没有，我们使用[`BTreeMap::insert`](https://doc.rust-lang.org/alloc/collections/btree_map/struct.BTreeMap.html#method.insert)方法创建它。此后，我们可以确定唤醒器存在，因此我们将该[`BTreeMap::get`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/alloc/collections/btree_map/struct.BTreeMap.html&usg=ALkJrhjSeGuQgzKpGI3zFBfr7v7KHf7Zjg#method.get)方法与[`expect`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/core/option/enum.Option.html&usg=ALkJrhhrcr3tliazH2802ZCiz5sbhEl84A#method.expect)调用结合使用以获取对其的引用。\n\n请注意，并非所有唤醒器实现都可以像这样重用唤醒器，但是我们的实现允许这样做。当任务完成时为了清理`waker_cache`，我们使用[`BTreeMap::remove`](https://doc.rust-lang.org/alloc/collections/btree_map/struct.BTreeMap.html#method.remove)方法从map中删除该任务的所有缓存的唤醒器。\n\n#### Waker设计\n\n唤醒程序的工作是将已唤醒任务的ID推送到`wake_queue`。我们通过创建一个新`TaskWaker`结构来实现此目的，该结构存储任务ID和对`wake_queue`的引用：\n\n```rust\n// in src/task/executor.rs\n\nstruct TaskWaker {\n    task_id: TaskId,\n    wake_queue: Arc<ArrayQueue<TaskId>>,\n}\n```\n\n由于`wake_queue`的所有权是在executor和waker之间共享的，因此我们使用[`Arc`](https://doc.rust-lang.org/stable/alloc/sync/struct.Arc.html)包装器类型来实现共享的所有权引用计数。\n\n唤醒操作的实现非常简单：\n\n```rust\n// in src/task/executor.rs\n\nimpl TaskWaker {\n    fn wake_task(&self) {\n        self.wake_queue.push(self.task_id).expect(\"wake_queue full\");\n    }\n}\n```\n\n我们将`task_id`到压入引用的`wake_queue`。由于修改[`ArrayQueue`](https://docs.rs/crossbeam/0.7.3/crossbeam/queue/struct.ArrayQueue.html)类型仅需要一个共享引用，我们可以用`&self`而非`&mut self`来实现此方法。\n\n##### `Wake` Trait\n\n为了使用我们的`TaskWaker`类型来poll future，我们需要先将其转换为[`Waker`](https://doc.rust-lang.org/nightly/core/task/struct.Waker.html)实例。这是必需的，因为[`Future::poll`](https://doc.rust-lang.org/nightly/core/future/trait.Future.html#tymethod.poll)方法以[`Context`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/nightly/core/task/struct.Context.html&usg=ALkJrhienQeYRRGlCkB2M_ymB7qxtTE8Gg)实例作为参数，该实例只能从`Waker`类型构造。尽管我们可以通过提供[`RawWaker`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/stable/core/task/struct.RawWaker.html&usg=ALkJrhjOuwz5oSe58stzvVL7q0DlBpW03w)类型的实现来做到这一点，但实现基于`Arc` 的`Waker` trait，然后使用标准库提供的[`From`](https://doc.rust-lang.org/nightly/core/convert/trait.From.html)实现来构造`Waker`，既简单又安全。\n\ntrait实现如下所示：\n\n```rust\n// in src/task/simple_executor.rs\n\nuse alloc::task::Wake;\n\nimpl Wake for TaskWaker {\n    fn wake(self: Arc<Self>) {\n        self.wake_task();\n    }\n\n    fn wake_by_ref(self: &Arc<Self>) {\n        self.wake_task();\n    }\n}\n```\n\n该trait仍然不稳定，因此我们必须添加`#![feature(wake_trait)]`到`lib.rs`顶部才能使用它。由于唤醒程序通常在executor 和异步任务之间共享，因此trait方法要求`Self`实例被包装在[`Arc`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/stable/alloc/sync/struct.Arc.html&usg=ALkJrhhytzcnWX7C38Bdbd_rI5EPjRlGig)类型中，该类型实现引用计数所有权。这意味着，我们对我们移动`TaskWaker`到一个`Arc`以调用他们。\n\n`wake`和`wake_by_ref`方法之间的区别在于，后者仅需要引用`Arc`，而前者则拥有`Arc`的所有权，`Arc`因此通常需要增加引用计数。并非所有类型都支持按引用唤醒，因此实现该`wake_by_ref`方法是可选的，但是由于可以避免不必要的引用计数修改，因此可以提高性能。在我们的例子中，我们可以简单地将这两个特征方法都转发到我们的`wake_task`函数中，该函数仅需要一个共享的`&self`引用。\n\n##### 创建Waker\n\n由于`Waker`类型支持从所有所有包装在`Arc`内实现了`Wake` trait的值的[`From`](https://doc.rust-lang.org/nightly/core/convert/trait.From.html)转换，因此我们现在可以使用`TaskWaker`来实现`Executor::create_waker`方法：\n\n```rust\n// in src/task/executor.rs\n\nimpl Executor {\n    fn create_waker(&self, task_id: TaskId) -> Waker {\n        Waker::from(Arc::new(TaskWaker {\n            task_id,\n            wake_queue: self.wake_queue.clone(),\n        }))\n    }\n}\n```\n\n我们使用传递的`task_id`和`wake_queue`的副本创建`TaskWaker`。由于`wake_queue`封装为`Arc`，因此`clone`只会增加值的引用计数，但仍指向相同的堆上的队列。我们也将`TaskWaker`储存在`Arc`中，因为`Waker::from`的实现需要它。然后，此函数负责为我们的`TaskWaker`类型构造[`RawWakerVTable`](https://doc.rust-lang.org/stable/core/task/struct.RawWakerVTable.html)和[`RawWaker`](https://doc.rust-lang.org/stable/core/task/struct.RawWaker.html)实例。如果您对它的详细工作方式感兴趣，请[在`alloc`crate中检查其实现](https://github.com/rust-lang/rust/blob/cdb50c6f2507319f29104a25765bfb79ad53395c/src/liballoc/task.rs#L58-L87)。\n\n##### 处理唤醒\n\n为了处理executor中的唤醒，我们添加了一个`wake_tasks`方法：\n\n```rust\n// in src/task/executor.rs\n\nimpl Executor {\n    fn wake_tasks(&mut self) {\n        while let Ok(task_id) = self.wake_queue.pop() {\n            if let Some(task) = self.waiting_tasks.remove(&task_id) {\n                self.task_queue.push_back(task);\n            }\n        }\n    }\n}\n```\n\n我们使用`while let`循环从`wake_queue`中弹出所有项目。对于每个弹出的任务ID，我们从`waiting_tasks`map中删除相应的任务，并将其添加到`task_queue`的后面。由于我们在检查是否需要使任务进入睡眠状态之前注册了唤醒器，因此即使任务不在`waiting_tasks`map中，也可能会发生任务唤醒。在这种情况下，我们只是忽略唤醒。\n\n#### `run`方法\n\n通过我们的唤醒器实现，我们最终可以为executor构造一个`run`方法：\n\n```rust\n// in src/task/executor.rs\n\nimpl Executor {\n    pub fn run(&mut self) -> ! {\n        loop {\n            self.wake_tasks();\n            self.run_ready_tasks();\n        }\n    }\n}\n```\n\n此方法仅在循环中调用`wake_tasks`和`run_ready_tasks`函数。从理论上讲，当`task_queue`和都`waiting_tasks`变为空时我们可以从函数返回，但这永远不会发生，因为我们`keyboard_task`永远都不会结束，因此简单地`loop`就足够了。由于函数永远不会返回，我们使用的`!`返回类型来告知编译器函数是[发散](https://doc.rust-lang.org/stable/rust-by-example/fn/diverging.html)的。\n\n现在，我们可以更改`kernel_main`，使其使用新的`Executor`而不是`SimpleExecutor`：\n\n```rust\n// in src/main.rs\n\nuse blog_os::task::executor::Executor; // new\n\nfn kernel_main(boot_info: &'static BootInfo) -> ! {\n    // […] initialization routines, including init_heap, test_main\n\n    let mut executor = Executor::new(); // new\n    executor.spawn(Task::new(example_task()));\n    executor.spawn(Task::new(keyboard::print_keypresses()));\n    executor.run();\n}\n```\n\n我们只需要更改导入和类型名称。由于我们的`run`函数被标记为发散，编译器知道它永远不会返回，因此我们不再需要在`kernel_main`函数末尾调用`hlt_loop`。\n\n现在当我们使用`cargo xrun`运行内核时，我们看到键盘输入仍然有效：\n\n![QEMU printing \".....H...e...l...l..o..... ...a..g..a....i...n...!\"](https://os.phil-opp.com/async-await/qemu-keyboard-output-again.gif)\n\n但是，QEMU的CPU使用率没有任何改善。原因是我们仍然使CPU始终保持忙碌状态。在任务被唤醒之前，我们不再轮询任务，但仍需要在忙循环中检查`wake_queue`和`task_queue`。要解决此问题，我们需要在没有其他工作要做时使CPU进入睡眠状态。\n\n#### 空闲时睡眠\n\n基本思想是在`task_queue`和`wake_queue`都为空时执行[`hlt`指令](https://en.wikipedia.org/wiki/HLT_(x86_instruction))。该指令使CPU进入睡眠状态，直到下一个中断到来。CPU立即在中断后再次变为活动状态，这确保了当中断处理程序向`wake_queue`推送时，我们仍然可以直接做出反应。\n\n为了实现这一点，我们为executor创建了一个新`sleep_if_idle`方法，并从我们的`run`方法中调用它：\n\n```rust\n// in src/task/executor.rs\n\nimpl Executor {\n    pub fn run(&mut self) -> ! {\n        loop {\n            self.wake_tasks();\n            self.run_ready_tasks();\n            self.sleep_if_idle();   // new\n        }\n    }\n\n    fn sleep_if_idle(&self) {\n        if self.wake_queue.is_empty() {\n            x86_64::instructions::hlt();\n        }\n    }\n}\n```\n\n由于我们在`run_ready_tasks`之后直接调用`sleep_if_idle`，它会一直循环直到`task_queue`变为空，因此我们只需要检查即可`wake_queue`。如果它也为空，则没有准备运行的任务，此时我们将通过[`x86_64`](https://docs.rs/x86_64/0.9.6/x86_64/index.html) crate 提供的[`instructions::hlt`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://docs.rs/x86_64/0.9.6/x86_64/instructions/fn.hlt.html&usg=ALkJrhjR_AOULnJlUUNudJ2x7x3rHcxz6Q)包装器函数执行`hlt`指令。\n\n不幸的是，此实现中存在一个微妙的竞态条件。由于中断是异步的，并且可以随时发生，因此有可能在`is_empty`检查和`hlt`调用之间发生中断：\n\n```rust\nif self.wake_queue.is_empty() {\n    /// <--- interrupt can happen here\n    x86_64::instructions::hlt();\n}\n```\n\n如果中断向`wake_queue`推送，即使现在有一个准备好的任务，我们也会使CPU进入睡眠状态。在最坏的情况下，这可能会延迟键盘中断的处理，直到下一次按键或下一个定时器中断为止。那么我们如何预防呢？\n\n答案是在检查之前禁用CPU上的中断，并与`hlt`指令一起自动启用它们。这样，两个指令之间的所有中断都会被延迟到指令之后，从而不会丢失任何唤醒。要实现此方法，我们可以使用[`x86_64`](https://docs.rs/x86_64/0.9.6/x86_64/index.html) crate提供的函数[`enable_interrupts_and_hlt`](https://docs.rs/x86_64/0.9.6/x86_64/instructions/interrupts/fn.enable_interrupts_and_hlt.html)。此函数仅在0.9.6版以后可用，因此您可能需要更新`x86_64`依赖项才能使用它。\n\n我们`sleep_if_idle`函数的更新实现如下所示：\n\n```rust\n// in src/task/executor.rs\n\nimpl Executor {\n    fn sleep_if_idle(&self) {\n        use x86_64::instructions::interrupts::{self, enable_interrupts_and_hlt};\n\n        // fast path\n        if !self.wake_queue.is_empty() {\n            return;\n        }\n\n        interrupts::disable();\n        if self.wake_queue.is_empty() {\n            enable_interrupts_and_hlt();\n        } else {\n            interrupts::enable();\n        }\n    }\n}\n```\n\n为了避免不必要地禁用中断，如果`wake_queue`不为空，我们会尽早返回。否则，我们禁用中断并再次检查`wake_queue`。如果它仍然为空，则使用[`enable_interrupts_and_hlt`](https://docs.rs/x86_64/0.9.6/x86_64/instructions/interrupts/fn.enable_interrupts_and_hlt.html)函数启用中断，并使CPU以单个原子操作的方式进入睡眠状态。如果队列不再为空，则意味着中断在第一次和第二检查之间唤醒了一个任务。在这种情况下，我们将再次启用中断并直接继续执行而不执行`hlt`。\n\n现在，我们的执行器可以在无事可做的情况下正确地使CPU进入睡眠状态。我们可以看到，`cargo xrun`再次运行内核时，QEMU进程的CPU使用率要低得多。\n\n#### 可能的扩展\n\n我们的executor现在可以高效地运行任务。它利用唤醒程序来避免不断poll等待中的任务，并在当前无工作要做时使CPU进入睡眠状态。但是，我们的executor仍然是非常基础的，并且有许多可能的方式来扩展其功能：\n\n- **调度：**我们目前使用的[`VecDeque`](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://doc.rust-lang.org/stable/alloc/collections/vec_deque/struct.VecDeque.html&usg=ALkJrhiXuJElXDamcn6zQ9-511Hx54ABqw)类型来为我们的`task_queue`实现一个*先进先出*（FIFO）的策略，这也经常被称为*轮转*调度。此策略可能并不对所有类型的工作负载来说都是最有效的。例如，优先考虑对延迟至关重要的任务或执行大量I / O的任务可能会更好。可以阅读 [*Operating Systems: Three Easy Pieces*](http://pages.cs.wisc.edu/~remzi/OSTEP/) 中的 [scheduling 一章](http://pages.cs.wisc.edu/~remzi/OSTEP/cpu-sched.pdf)或者Wikipedia上的[调度页面]([Wikipedia article on scheduling](https://en.wikipedia.org/wiki/Scheduling_(computing))来获取更多信息。\n- **任务Spawning**：我们的`Executor::spawn`方法当前需要`&mut self`，因此启动`run`方法后其不再可用。为了解决这个问题，我们可以另外创建一个`Spawner`类型，该类型与执行程序共享某种队列，并允许从任务内部创建新的任务。这个队列可以是`task_queue` 或是另一个executor在其运行的循环中不断检查的单独的队列。\n- **使用线程**：我们尚不支持线程，但我们将在下一篇文章中添加它。这将使得可以在不同的线程中启动执行程序的多个实例。这种方法的优点是可以减少长时间运行的任务带来的延迟，因为其他任务可以同时运行。这种方法还允许它利用多个CPU内核。\n- **负载均衡**：添加线程支持时，如何在执行程序之间分配任务以确保利用所有CPU内核变得很重要。一种常见的技术是[*工作窃取*](https://translate.googleusercontent.com/translate_c?depth=1&rurl=translate.google.com.hk&sl=en&sp=nmt4&tl=zh-CN&u=https://en.wikipedia.org/wiki/Work_stealing&usg=ALkJrhhJLg327BIIM2T-3Np3Rid7wrnD5Q)。\n\n## 总结\n\n我们通过介绍**多任务**和区分*抢占式*多任务（强制性地定期中断正在运行的任务）和*协作*式多任务（使任务一直运行到自愿放弃对CPU的控制）之间的区别来开始本文。\n\n然后，我们探讨了Rust对**async/await**的支持如何提供协作式多任务处理的语言级实现。Rust使用了基于polling的`Future` trait，其为抽象了的异步任务。使用async/await，可以像编写普通同步代码一样使用Future。不同之处在于异步函数还是会返回`Future` ，需要在某个时候将其添加到执行程序才能运行它。\n\n在后台，编译器将异步/等待代码转换为*状态机*，每个`.await`操作对应一个可能的暂停点。通过利用其对程序的了解，编译器每个暂停点只会保存最小状态，从而使每个任务的内存消耗非常小。一个挑战是生成的状态机可能包含*自引用*结构，例如，当异步函数的局部变量相互引用时。为了防止指针失效，Rust使用该`Pin`类型来确保在第一次对其进行poll之后，就不能再将其在内存中移动。\n\n对于我们的**实现**，我们首先创建了一个非常基本的执行程序，该执行程序不断使用循环poll所有产生的任务，而`Waker`根本什么都不做。然后，我们通过实现异步键盘任务来展示唤醒通知的优势。该任务使用`crossbeam` crate中`ArrayQueue`提供的无锁类型定义静态变量`SCANCODE_QUEUE`。现在，键盘中断处理程序不再直接处理按键，而是将所有接收到的扫描代码放入队列中，然后唤醒已注册的`Waker`以发出新输入可用的信号。在接收端，我们创建了一个`ScancodeStream`类型以提供`Future`对队列中下一个扫描代码的解析。这使得使用async/await的解释和打印队列中扫描代码的异步`print_keypresses`成为可能。 \n\n为了利用键盘任务的唤醒通知，我们创建了一种新`Executor`类型，可以区分准备好了的任务和等待任务。使用`Arc`内的的`wake_queue`，我们实现了一种`TaskWaker`类型，该类型将唤醒通知直接发送到执行程序，然后执行程序可以将相应的任务再次标记为就绪。为了在无任务可运行时节省电量，我们增加了使用`hlt`指令使CPU进入睡眠状态的支持。最后，我们讨论了executor的一些潜在扩展，例如，用于提供多核支持。\n\n## 下一步是什么？\n\n使用async/await，我们现在对内核中的协作多任务有了基本的支持。尽管协作式多任务处理非常有效，但是当单个任务保持运行太长时间从而导致其他任务无法运行时，则会导致延迟问题。因此，在我们的内核中添加对抢占式多任务的支持也是有意义的。\n\n在下一篇文章中，我们将介绍*线程*作为抢占式多任务处理的最常见形式。除了解决任务长期运行的问题之外，线程还将为让我们可以准备好利用多个CPU核心并在将来运行不受信任的用户程序。\n\n\n\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 18.888671875,
          "content": "Attribution-NonCommercial 4.0 International\n\n=======================================================================\n\nCreative Commons Corporation (\"Creative Commons\") is not a law firm and\ndoes not provide legal services or legal advice. Distribution of\nCreative Commons public licenses does not create a lawyer-client or\nother relationship. Creative Commons makes its licenses and related\ninformation available on an \"as-is\" basis. Creative Commons gives no\nwarranties regarding its licenses, any material licensed under their\nterms and conditions, or any related information. Creative Commons\ndisclaims all liability for damages resulting from their use to the\nfullest extent possible.\n\nUsing Creative Commons Public Licenses\n\nCreative Commons public licenses provide a standard set of terms and\nconditions that creators and other rights holders may use to share\noriginal works of authorship and other material subject to copyright\nand certain other rights specified in the public license below. The\nfollowing considerations are for informational purposes only, are not\nexhaustive, and do not form part of our licenses.\n\n     Considerations for licensors: Our public licenses are\n     intended for use by those authorized to give the public\n     permission to use material in ways otherwise restricted by\n     copyright and certain other rights. Our licenses are\n     irrevocable. Licensors should read and understand the terms\n     and conditions of the license they choose before applying it.\n     Licensors should also secure all rights necessary before\n     applying our licenses so that the public can reuse the\n     material as expected. Licensors should clearly mark any\n     material not subject to the license. This includes other CC-\n     licensed material, or material used under an exception or\n     limitation to copyright. More considerations for licensors:\n\twiki.creativecommons.org/Considerations_for_licensors\n\n     Considerations for the public: By using one of our public\n     licenses, a licensor grants the public permission to use the\n     licensed material under specified terms and conditions. If\n     the licensor's permission is not necessary for any reason--for\n     example, because of any applicable exception or limitation to\n     copyright--then that use is not regulated by the license. Our\n     licenses grant only permissions under copyright and certain\n     other rights that a licensor has authority to grant. Use of\n     the licensed material may still be restricted for other\n     reasons, including because others have copyright or other\n     rights in the material. A licensor may make special requests,\n     such as asking that all changes be marked or described.\n     Although not required by our licenses, you are encouraged to\n     respect those requests where reasonable. More_considerations\n     for the public: \n\twiki.creativecommons.org/Considerations_for_licensees\n\n=======================================================================\n\nCreative Commons Attribution-NonCommercial 4.0 International Public\nLicense\n\nBy exercising the Licensed Rights (defined below), You accept and agree\nto be bound by the terms and conditions of this Creative Commons\nAttribution-NonCommercial 4.0 International Public License (\"Public\nLicense\"). To the extent this Public License may be interpreted as a\ncontract, You are granted the Licensed Rights in consideration of Your\nacceptance of these terms and conditions, and the Licensor grants You\nsuch rights in consideration of benefits the Licensor receives from\nmaking the Licensed Material available under these terms and\nconditions.\n\n\nSection 1 -- Definitions.\n\n  a. Adapted Material means material subject to Copyright and Similar\n     Rights that is derived from or based upon the Licensed Material\n     and in which the Licensed Material is translated, altered,\n     arranged, transformed, or otherwise modified in a manner requiring\n     permission under the Copyright and Similar Rights held by the\n     Licensor. For purposes of this Public License, where the Licensed\n     Material is a musical work, performance, or sound recording,\n     Adapted Material is always produced where the Licensed Material is\n     synched in timed relation with a moving image.\n\n  b. Adapter's License means the license You apply to Your Copyright\n     and Similar Rights in Your contributions to Adapted Material in\n     accordance with the terms and conditions of this Public License.\n\n  c. Copyright and Similar Rights means copyright and/or similar rights\n     closely related to copyright including, without limitation,\n     performance, broadcast, sound recording, and Sui Generis Database\n     Rights, without regard to how the rights are labeled or\n     categorized. For purposes of this Public License, the rights\n     specified in Section 2(b)(1)-(2) are not Copyright and Similar\n     Rights.\n  d. Effective Technological Measures means those measures that, in the\n     absence of proper authority, may not be circumvented under laws\n     fulfilling obligations under Article 11 of the WIPO Copyright\n     Treaty adopted on December 20, 1996, and/or similar international\n     agreements.\n\n  e. Exceptions and Limitations means fair use, fair dealing, and/or\n     any other exception or limitation to Copyright and Similar Rights\n     that applies to Your use of the Licensed Material.\n\n  f. Licensed Material means the artistic or literary work, database,\n     or other material to which the Licensor applied this Public\n     License.\n\n  g. Licensed Rights means the rights granted to You subject to the\n     terms and conditions of this Public License, which are limited to\n     all Copyright and Similar Rights that apply to Your use of the\n     Licensed Material and that the Licensor has authority to license.\n\n  h. Licensor means the individual(s) or entity(ies) granting rights\n     under this Public License.\n\n  i. NonCommercial means not primarily intended for or directed towards\n     commercial advantage or monetary compensation. For purposes of\n     this Public License, the exchange of the Licensed Material for\n     other material subject to Copyright and Similar Rights by digital\n     file-sharing or similar means is NonCommercial provided there is\n     no payment of monetary compensation in connection with the\n     exchange.\n\n  j. Share means to provide material to the public by any means or\n     process that requires permission under the Licensed Rights, such\n     as reproduction, public display, public performance, distribution,\n     dissemination, communication, or importation, and to make material\n     available to the public including in ways that members of the\n     public may access the material from a place and at a time\n     individually chosen by them.\n\n  k. Sui Generis Database Rights means rights other than copyright\n     resulting from Directive 96/9/EC of the European Parliament and of\n     the Council of 11 March 1996 on the legal protection of databases,\n     as amended and/or succeeded, as well as other essentially\n     equivalent rights anywhere in the world.\n\n  l. You means the individual or entity exercising the Licensed Rights\n     under this Public License. Your has a corresponding meaning.\n\n\nSection 2 -- Scope.\n\n  a. License grant.\n\n       1. Subject to the terms and conditions of this Public License,\n          the Licensor hereby grants You a worldwide, royalty-free,\n          non-sublicensable, non-exclusive, irrevocable license to\n          exercise the Licensed Rights in the Licensed Material to:\n\n            a. reproduce and Share the Licensed Material, in whole or\n               in part, for NonCommercial purposes only; and\n\n            b. produce, reproduce, and Share Adapted Material for\n               NonCommercial purposes only.\n\n       2. Exceptions and Limitations. For the avoidance of doubt, where\n          Exceptions and Limitations apply to Your use, this Public\n          License does not apply, and You do not need to comply with\n          its terms and conditions.\n\n       3. Term. The term of this Public License is specified in Section\n          6(a).\n\n       4. Media and formats; technical modifications allowed. The\n          Licensor authorizes You to exercise the Licensed Rights in\n          all media and formats whether now known or hereafter created,\n          and to make technical modifications necessary to do so. The\n          Licensor waives and/or agrees not to assert any right or\n          authority to forbid You from making technical modifications\n          necessary to exercise the Licensed Rights, including\n          technical modifications necessary to circumvent Effective\n          Technological Measures. For purposes of this Public License,\n          simply making modifications authorized by this Section 2(a)\n          (4) never produces Adapted Material.\n\n       5. Downstream recipients.\n\n            a. Offer from the Licensor -- Licensed Material. Every\n               recipient of the Licensed Material automatically\n               receives an offer from the Licensor to exercise the\n               Licensed Rights under the terms and conditions of this\n               Public License.\n\n            b. No downstream restrictions. You may not offer or impose\n               any additional or different terms or conditions on, or\n               apply any Effective Technological Measures to, the\n               Licensed Material if doing so restricts exercise of the\n               Licensed Rights by any recipient of the Licensed\n               Material.\n\n       6. No endorsement. Nothing in this Public License constitutes or\n          may be construed as permission to assert or imply that You\n          are, or that Your use of the Licensed Material is, connected\n          with, or sponsored, endorsed, or granted official status by,\n          the Licensor or others designated to receive attribution as\n          provided in Section 3(a)(1)(A)(i).\n\n  b. Other rights.\n\n       1. Moral rights, such as the right of integrity, are not\n          licensed under this Public License, nor are publicity,\n          privacy, and/or other similar personality rights; however, to\n          the extent possible, the Licensor waives and/or agrees not to\n          assert any such rights held by the Licensor to the limited\n          extent necessary to allow You to exercise the Licensed\n          Rights, but not otherwise.\n\n       2. Patent and trademark rights are not licensed under this\n          Public License.\n\n       3. To the extent possible, the Licensor waives any right to\n          collect royalties from You for the exercise of the Licensed\n          Rights, whether directly or through a collecting society\n          under any voluntary or waivable statutory or compulsory\n          licensing scheme. In all other cases the Licensor expressly\n          reserves any right to collect such royalties, including when\n          the Licensed Material is used other than for NonCommercial\n          purposes.\n\n\nSection 3 -- License Conditions.\n\nYour exercise of the Licensed Rights is expressly made subject to the\nfollowing conditions.\n\n  a. Attribution.\n\n       1. If You Share the Licensed Material (including in modified\n          form), You must:\n\n            a. retain the following if it is supplied by the Licensor\n               with the Licensed Material:\n\n                 i. identification of the creator(s) of the Licensed\n                    Material and any others designated to receive\n                    attribution, in any reasonable manner requested by\n                    the Licensor (including by pseudonym if\n                    designated);\n\n                ii. a copyright notice;\n\n               iii. a notice that refers to this Public License;\n\n                iv. a notice that refers to the disclaimer of\n                    warranties;\n\n                 v. a URI or hyperlink to the Licensed Material to the\n                    extent reasonably practicable;\n\n            b. indicate if You modified the Licensed Material and\n               retain an indication of any previous modifications; and\n\n            c. indicate the Licensed Material is licensed under this\n               Public License, and include the text of, or the URI or\n               hyperlink to, this Public License.\n\n       2. You may satisfy the conditions in Section 3(a)(1) in any\n          reasonable manner based on the medium, means, and context in\n          which You Share the Licensed Material. For example, it may be\n          reasonable to satisfy the conditions by providing a URI or\n          hyperlink to a resource that includes the required\n          information.\n\n       3. If requested by the Licensor, You must remove any of the\n          information required by Section 3(a)(1)(A) to the extent\n          reasonably practicable.\n\n       4. If You Share Adapted Material You produce, the Adapter's\n          License You apply must not prevent recipients of the Adapted\n          Material from complying with this Public License.\n\n\nSection 4 -- Sui Generis Database Rights.\n\nWhere the Licensed Rights include Sui Generis Database Rights that\napply to Your use of the Licensed Material:\n\n  a. for the avoidance of doubt, Section 2(a)(1) grants You the right\n     to extract, reuse, reproduce, and Share all or a substantial\n     portion of the contents of the database for NonCommercial purposes\n     only;\n\n  b. if You include all or a substantial portion of the database\n     contents in a database in which You have Sui Generis Database\n     Rights, then the database in which You have Sui Generis Database\n     Rights (but not its individual contents) is Adapted Material; and\n\n  c. You must comply with the conditions in Section 3(a) if You Share\n     all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not\nreplace Your obligations under this Public License where the Licensed\nRights include other Copyright and Similar Rights.\n\n\nSection 5 -- Disclaimer of Warranties and Limitation of Liability.\n\n  a. UNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE\n     EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS\n     AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF\n     ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS,\n     IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION,\n     WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR\n     PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS,\n     ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT\n     KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT\n     ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU.\n\n  b. TO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE\n     TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION,\n     NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT,\n     INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES,\n     COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR\n     USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN\n     ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR\n     DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR\n     IN PART, THIS LIMITATION MAY NOT APPLY TO YOU.\n\n  c. The disclaimer of warranties and limitation of liability provided\n     above shall be interpreted in a manner that, to the extent\n     possible, most closely approximates an absolute disclaimer and\n     waiver of all liability.\n\n\nSection 6 -- Term and Termination.\n\n  a. This Public License applies for the term of the Copyright and\n     Similar Rights licensed here. However, if You fail to comply with\n     this Public License, then Your rights under this Public License\n     terminate automatically.\n\n  b. Where Your right to use the Licensed Material has terminated under\n     Section 6(a), it reinstates:\n\n       1. automatically as of the date the violation is cured, provided\n          it is cured within 30 days of Your discovery of the\n          violation; or\n\n       2. upon express reinstatement by the Licensor.\n\n     For the avoidance of doubt, this Section 6(b) does not affect any\n     right the Licensor may have to seek remedies for Your violations\n     of this Public License.\n\n  c. For the avoidance of doubt, the Licensor may also offer the\n     Licensed Material under separate terms or conditions or stop\n     distributing the Licensed Material at any time; however, doing so\n     will not terminate this Public License.\n\n  d. Sections 1, 5, 6, 7, and 8 survive termination of this Public\n     License.\n\n\nSection 7 -- Other Terms and Conditions.\n\n  a. The Licensor shall not be bound by any additional or different\n     terms or conditions communicated by You unless expressly agreed.\n\n  b. Any arrangements, understandings, or agreements regarding the\n     Licensed Material not stated herein are separate from and\n     independent of the terms and conditions of this Public License.\n\n\nSection 8 -- Interpretation.\n\n  a. For the avoidance of doubt, this Public License does not, and\n     shall not be interpreted to, reduce, limit, restrict, or impose\n     conditions on any use of the Licensed Material that could lawfully\n     be made without permission under this Public License.\n\n  b. To the extent possible, if any provision of this Public License is\n     deemed unenforceable, it shall be automatically reformed to the\n     minimum extent necessary to make it enforceable. If the provision\n     cannot be reformed, it shall be severed from this Public License\n     without affecting the enforceability of the remaining terms and\n     conditions.\n\n  c. No term or condition of this Public License will be waived and no\n     failure to comply consented to unless expressly agreed to by the\n     Licensor.\n\n  d. Nothing in this Public License constitutes or may be interpreted\n     as a limitation upon, or waiver of, any privileges and immunities\n     that apply to the Licensor or You, including from the legal\n     processes of any jurisdiction or authority.\n\n=======================================================================\n\nCreative Commons is not a party to its public\nlicenses. Notwithstanding, Creative Commons may elect to apply one of\nits public licenses to material it publishes and in those instances\nwill be considered the “Licensor.” The text of the Creative Commons\npublic licenses is dedicated to the public domain under the CC0 Public\nDomain Dedication. Except for the limited purpose of indicating that\nmaterial is shared under a Creative Commons public license or as\notherwise permitted by the Creative Commons policies published at\ncreativecommons.org/policies, Creative Commons does not authorize the\nuse of the trademark \"Creative Commons\" or any other trademark or logo\nof Creative Commons without its prior written consent including,\nwithout limitation, in connection with any unauthorized modifications\nto any of its public licenses or any other arrangements,\nunderstandings, or agreements concerning use of licensed material. For\nthe avoidance of doubt, this paragraph does not form part of the\npublic licenses.\n\nCreative Commons may be contacted at creativecommons.org.\n\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 3.33984375,
          "content": "# writing-an-os-in-rust\n\n《编写 Rust 语言的操作系统》简体中文翻译\n\n## 目录\n\n### 正文\n\n| 序号 | 标题             | 链接                                              | 源文件                                   | 状态    | 长度    |\n| ---- | ---------------- | ------------------------------------------------- | ---------------------------------------- | ------- | ------- |\n| 一   | 独立式可执行程序 | [知乎专栏](https://zhuanlan.zhihu.com/p/53064186) | [点我](./01-freestanding-rust-binary.md) | Done    | 11 千字 |\n| 二   | 最小化内核       | [知乎专栏](https://zhuanlan.zhihu.com/p/56433770) | [点我](./02-minimal-rust-kernel.md)      | Done    | 19 千字 |\n| 三   | VGA 字符模式     | [知乎专栏](https://zhuanlan.zhihu.com/p/53745617) | [点我](./03-vga-text-mode.md)            | Done    | 21 千字 |\n| 四   | 内核测试         | [知乎专栏](https://zhuanlan.zhihu.com/p/90758552) | [点我](./04-testing.md)                  | Done    | 27 千字 |\n| 五   | CPU 异常         | 待添加                                            | [点我](./05-cpu-exceptions.md)           | Pending | -       |\n| 六   | 双重异常         | 待添加                                            | [点我](./06-double-fault-exceptions.md)  | Pending | -       |\n| 七   | 硬件中断         | 待添加                                            | [点我](./07-hardware-interrupts.md)      | Done | 21 千字 |\n| 八   | 内存分页简介     | 待添加                                            | [点我](./08-introduction-to-paging.md)   | Done | 16 千字 |\n| 九   | 内存分页实现     | 待添加                                            | [点我](./09-paging-implementation.md)     | Done | 28 千字 |\n| 十   | 堆分配           | 待添加                                            | [点我](./10-heap-allocation.md)          | Done | 20 千字 |\n| 十一 | 内存分配器设计   | 待添加                                            | [点我](./11-allocator-designs.md)        | Done | 35 千字 |\n| 十二 | Async/Await   | 待添加                                            | [点我](./12-async-await.md)        | Done | 51 千字 |\n\n### 附录\n\n| 序号   | 标题             | 链接                                              | 源文件                                   | 状态    | 长度   |\n| ------ | ---------------- | ------------------------------------------------- | ---------------------------------------- | ------- | ------ |\n| 附录一 | 链接器参数       | [知乎专栏](https://zhuanlan.zhihu.com/p/69393545) | [点我](./appendix-a-linker-arguments.md) | Done    | 6 千字 |\n| 附录二 | 禁用红区         | [知乎专栏](https://zhuanlan.zhihu.com/p/53240133) | [点我](./appendix-b-red-zone.md)         | Done    | 2 千字 |\n| 附录三 | 禁用 SIMD        | [知乎专栏](https://zhuanlan.zhihu.com/p/53350970) | [点我](./appendix-c-disable-simd.md)     | Done    | 2 千字 |\n| 附录四 | 在安卓系统上构建 | 待添加                                            | 待添加                                   | Pending | -      |\n\n### 译名表\n\n[点我](./translation-table.md)\n\n## 译者\n\n- 洛佳 (@luojia65)，华中科技大学\n- 龙方淞 (@longfangsong)，上海大学开源社区\n- readlnh (@readlnh)\n- 尚卓燃 (@psiace)，华中农业大学\n"
        },
        {
          "name": "appendix-a-linker-arguments.md",
          "type": "blob",
          "size": 8.06640625,
          "content": ">原文：https://os.phil-opp.com/freestanding-rust-binary/#linker-arguments\n>\n>原作者：@phil-opp\n>\n>译者：洛佳  华中科技大学\n\n# 使用Rust编写操作系统（附录一）：链接器参数\n\n用Rust编写操作系统时，我们可能遇到一些链接器错误。这篇文章中，我们不将更换编译目标，而传送特定的链接器参数，尝试修复错误。我们将在常用系统Linux、Windows和macOS下，举例编写裸机应用时，可能出现的一些链接器错误；我们将逐个处理它们，还将讨论这种方式开发的必要性。\n\n要注意的是，可执行程序在不同操作系统下格式各异；所以在不同平台下，参数和错误信息可能略有不同。\n\n## Linux\n\n我们在Linux下尝试编写裸机程序，可能出现这样的链接器错误：\n\n```\nerror: linking with `cc` failed: exit code: 1\n  |\n  = note: \"cc\" […]\n  = note: /usr/lib/gcc/../x86_64-linux-gnu/Scrt1.o: In function `_start':\n          (.text+0x12): undefined reference to `__libc_csu_fini'\n          /usr/lib/gcc/../x86_64-linux-gnu/Scrt1.o: In function `_start':\n          (.text+0x19): undefined reference to `__libc_csu_init'\n          /usr/lib/gcc/../x86_64-linux-gnu/Scrt1.o: In function `_start':\n          (.text+0x25): undefined reference to `__libc_start_main'\n          collect2: error: ld returned 1 exit status\n```\n\n这里遇到的问题是，链接器将默认引用C语言运行时的启动流程，或者也被描述为`_start`函数。它将使用我们在`no_std`下被排除的C语言标准库实现库`libc`，因此链接器不能解析相关的引用，得到“undefined reference”问题。为解决这个问题，我们需要告诉链接器，它不应该引用C语言使用的启动流程——我们可以添加`-nostartfiles`标签来做到这一点。\n\n要通过cargo添加参数到链接器，我们使用`cargo rustc`命令。这个命令的作用和`cargo build`相同，但允许开发者向下层的Rust编译器`rustc`传递参数。另外，`rustc`提供一个`-C link-arg`标签，它能够传递所需的参数到链接器。综上所述，我们可以编写下面的命令：\n\n```\ncargo rustc -- -C link-arg=-nostartfiles\n```\n\n这样之后，我们的包应该能成功编译，作为Linux系统下的独立式可执行程序了。这里我们没有显式指定入口点函数的名称，因为链接器将默认使用函数名`_start`。\n\n## Windows\n\n在Windows系统下，可能有不一样的链接器错误：\n\n```\nerror: linking with `link.exe` failed: exit code: 1561\n  |\n  = note: \"C:\\\\Program Files (x86)\\\\…\\\\link.exe\" […]\n  = note: LINK : fatal error LNK1561: entry point must be defined\n```\n\n链接器错误提示“必须定义入口点”，意味着它没有找到入口点。在Windows系统下，默认的入口点函数名[由使用的子系统决定](https://docs.microsoft.com/en-us/cpp/build/reference/entry-entry-point-symbol)。对`CONSOLE`子系统，链接器将寻找名为`mainCRTStartup`的函数；而对`WINDOWS`子系统，它将寻找`WinMainCRTStartup`。我们的`_start`函数并非这两个名称：为了使用它，我们可以向链接器传递`/ENTRY`参数：\n\n```\ncargo rustc -- -C link-arg=/ENTRY:_start\n```\n\n我们也能从这里的参数的格式中看到，Windows系统下的链接器在使用方法上，与Linux下的有较大不同。\n\n运行命令，我们得到了另一个链接器错误：\n\n```\nerror: linking with `link.exe` failed: exit code: 1221\n  |\n  = note: \"C:\\\\Program Files (x86)\\\\…\\\\link.exe\" […]\n  = note: LINK : fatal error LNK1221: a subsystem can't be inferred and must be\n          defined\n```\n\n产生这个错误，是由于Windows可执行程序可以使用不同的**子系统**（[subsystem](https://docs.microsoft.com/en-us/cpp/build/reference/entry-entry-point-symbol)）。对一般的Windows程序，使用的子系统将由入口点的函数名推断而来：如果入口点是`main`函数，将使用`CONSOLE`子系统；如果是`WinMain`函数，则使用`WINDOWS`子系统。由于我们的`_start`函数名称与上两者不同，我们需要显式指定使用的子系统：\n\n```\ncargo rustc -- -C link-args=\"/ENTRY:_start /SUBSYSTEM:console\"\n```\n\n这里我们使用`CONSOLE`子系统，但`WINDOWS`子系统也是可行的。这里，我们使用复数参数`link-args`代替多个`-C link-arg`，因为后者要求把所有参数依次列出，比较占用空间。\n\n使用这行命令后，我们的可执行程序应该能在Windows下运行了。\n\n## macOS\n\n如果使用macOS系统开发，我们可能遇到这样的链接器错误：\n\n```\nerror: linking with `cc` failed: exit code: 1\n  |\n  = note: \"cc\" […]\n  = note: ld: entry point (_main) undefined. for architecture x86_64\n          clang: error: linker command failed with exit code 1 […]\n```\n\n这个错误消息告诉我们，链接器不能找到默认的入口点函数，它被命名为`main`——出于一些原因，macOS的所有函数名都被加以下划线`_`前缀。要设置入口点函数到`_start`，我们传送链接器参数`-e`：\n\n```\ncargo rustc -- -C link-args=\"-e __start\"\n```\n\n`-e`参数指定了入口点的名称。由于每个macOS下的函数都有下划线`_`前缀，我们应该命名入口点函数为`__start`，而不是`_start`。\n\n运行这行命令，现在出现了这样的链接器错误：\n\n```\nerror: linking with `cc` failed: exit code: 1\n  |\n  = note: \"cc\" […]\n  = note: ld: dynamic main executables must link with libSystem.dylib\n          for architecture x86_64\n          clang: error: linker command failed with exit code 1 […]\n```\n\n这个错误的原因是，macOS[并不官方支持静态链接的二进制库](https://developer.apple.com/library/content/qa/qa1118/_index.html)，而要求程序默认链接到`libSystem`库。要链接到静态二进制库，我们把`-static`标签传送到链接器：\n\n```\ncargo rustc -- -C link-args=\"-e __start -static\"\n```\n\n运行修改后的命令。链接器似乎并不满意，又给我们抛出新的错误：\n\n```\nerror: linking with `cc` failed: exit code: 1\n  |\n  = note: \"cc\" […]\n  = note: ld: library not found for -lcrt0.o\n          clang: error: linker command failed with exit code 1 […]\n```\n\n出现这个错误的原因是，macOS上的程序默认链接到`crt0`（C runtime zero）库。这和Linux系统上遇到的问题相似，我们可以添加一个`-nostartfiles`链接器参数：\n\n```\ncargo rustc -- -C link-args=\"-e __start -static -nostartfiles\"\n```\n\n现在，我们的程序应该能够在macOS上成功编译了。\n\n## 统一所有的编译命令\n\n我们的裸机程序已经可以在多个平台上编译，但对每个平台，我们不得不记忆和使用不同的编译命令。为了避免这么做，我们创建`.cargo/config`文件，为每个平台填写对应的命令：\n\n```toml\n# in .cargo/config\n\n[target.'cfg(target_os = \"linux\")']\nrustflags = [\"-C\", \"link-arg=-nostartfiles\"]\n\n[target.'cfg(target_os = \"windows\")']\nrustflags = [\"-C\", \"link-args=/ENTRY:_start /SUBSYSTEM:console\"]\n\n[target.'cfg(target_os = \"macos\")']\nrustflags = [\"-C\", \"link-args=-e __start -static -nostartfiles\"]\n```\n\n这里，`rustflags`参数包含的内容，将被自动添加到每次`rustc`调用中。我们可以在[官方文档](https://doc.rust-lang.org/cargo/reference/config.html)中找到更多关于`.cargo/config`文件的说明。\n\n做完这一步后，我们使用简单的一行指令——\n\n```\ncargo build\n```\n\n——就能在三个不同的平台上编译裸机程序了。\n\n## 我们应该这么做吗？\n\n虽然通过上文的方式，的确可以面向多个系统编译独立式可执行程序，但这可能不是一个好的途径。这么描述的原因是，我们的可执行程序仍然需要其它准备，比如在`_start`函数调用前一个加载完毕的栈。不使用C语言运行环境的前提下，这些准备可能并没有全部完成——这可能导致程序运行失败，比如说会抛出臭名昭著的段错误。\n\n如果我们要为给定的操作系统创建最小的二进制程序，可以试着使用`libc`库并设定`#[start]`标记。[有一篇官方文档](https://doc.rust-lang.org/1.16.0/book/no-stdlib.html)给出了较好的建议。\n"
        },
        {
          "name": "appendix-b-red-zone.md",
          "type": "blob",
          "size": 2.3583984375,
          "content": ">原文：https://os.phil-opp.com/red-zone/\n>\n>原作者：@phil-opp\n>\n>译者：洛佳  华中科技大学\n\n# 使用Rust编写操作系统（附录二）：禁用红区\n\n**红区**（redzone）是System V ABI提供的一种优化的产物，它允许函数无需调整**栈指针**（stack pointer），便能临时使用其**栈帧**（stack frame）下方的128个字节：\n\n![](https://os.phil-opp.com/red-zone/red-zone.svg)\n\n这张图片展示了一个有`n`个**局部变量**（local variable）的函数的栈帧。在进入函数时，栈指针将被调节到合适的位置，以便为**返回地址**（return address）和局部变量提供内存空间。\n\n红区被定义为调整过的栈指针下方128个字节的区域——函数将会使用这个区域，来存放一些无需跨越函数调用的临时数据。因此，在一些情况下，比如在小的**叶函数**（leaf function）[1]中，我们可以优化掉调整栈指针所需的两条指令。\n\n然而，当**异常**（exception）或**硬件中断**（hardware interrupt）发生时，这种优化却可能产生严重的问题。为了理解这一点，我们假设，当某个函数正在使用红区时，发生了一个异常：\n\n![](https://os.phil-opp.com/red-zone/red-zone-overwrite.svg)\n\n当异常发生时，CPU和**异常处理器**（exception handler）会向下**覆写**（overwrite）红区内的数据；这些曾经存在但被覆写的红区数据，却可能仍然将被被中断的函数使用。这之后，当我们从异常处理器中返回时，这个函数不再像它的定义一样正常工作。这个特性可能会产生许多奇怪而隐蔽的bug，甚至需要几周时间才能找到它的成因。\n\n为了避免这样的bug发生，我们编写异常处理器时，常常从一开始便禁用红区。因此，要实现这一点，我们可以在编译目标的**配置文件**（configuration file）中，添加一行`\"disable-redzone\": true`。\n\n_译者注：红区的产生可能有一定的历史缘由，调整或禁用它的作用还有待发掘，文章如有不当或疏漏敬请谅解，建议阅读维基百科和其它资料上对红区的解释_\n\n---\n\n[1] **叶函数**（leaf function）指的是不调用其它函数的函数；可以理解为，是函数调用图的叶子节点。特别地，**尾递归函数**（tail recursive function）的尾部可以看作是叶函数。\n"
        },
        {
          "name": "appendix-c-disable-simd.md",
          "type": "blob",
          "size": 3.423828125,
          "content": ">原文：https://os.phil-opp.com/disable-simd/\n>\n>原作者：@phil-opp\n>\n>译者：洛佳  华中科技大学\n\n# 使用Rust编写操作系统（附录三）：禁用SIMD\n\n**单指令多数据流**（[Single Instruction Multiple Data，SIMD](https://en.wikipedia.org/wiki/SIMD)）指令能够同时对多个**数据字**（data word）执行同一个操作，这能显著地加快程序运行的速度。`x86_64`架构支持下面的SIMD标准：\n\n1. **MMX**（[Multi Media Extension](https://en.wikipedia.org/wiki/MMX_(instruction_set))）。MMX指令集发布于1997年，它定义了8个64位的寄存器，从`mm0`到`mm7`。这些寄存器只是**x87浮点数单元**（[x87 floating point unit](https://en.wikipedia.org/wiki/X87)）所用寄存器的别称；\n2. **SSE**（[Streaming SIMD Extensions](https://en.wikipedia.org/wiki/Streaming_SIMD_Extensions)）。SSE指令集于1999年发布。它定义了一些全新的寄存器集合，而不是重复使用已有的浮点数单元寄存器。从`xmm0`到`xmm15`，SSE定义了16个全新的寄存器，每个寄存器有128位长；\n3. **AVX**（[Advanced Vector Extensions](https://en.wikipedia.org/wiki/Advanced_Vector_Extensions)）。2008年发布的AVX又一次扩展了多媒体相关的寄存器，新的寄存器被称作`ymm0`到`ymm15`，长度均为256位。这些寄存器只是`xmm`寄存器的拓展，所以例如`xmm0`只是`ymm0`的低128位。\n\n通过使用这些SIMD标准，程序通常能极大地提升速度。一些优秀的编译器拥有**自动矢量化编译技术**（[auto-vectorization](https://en.wikipedia.org/wiki/Automatic_vectorization)），能够自动将普通的循环代码转变为使用SIMD指令集的二进制码。\n\n然而，庞大的SIMD寄存器可能在操作系统内核层面造成问题。当硬件中断发生时，我们的内核不得不备份所有它使用的寄存器：因为在程序继续时，内核依然需要它原来的寄存器数据。所以如果内核使用了SIMD寄存器，它就不得不额外备份大量的SIMD寄存器数据（可能多达512~1600个字节），这将很显著地降低效率。为了避免效率损失，我们在开发内核时，常常禁用`sse`和`mmx`这两个**CPU特征**（CPU feature）。（`avx`特征是默认被禁用的。）\n\n要禁用这两个特征，我们可以修改**目标配置清单**（target specification）的`features`配置项。使用`-`号，我们可以禁用`sse`和`mmx`两个CPU特征：\n\n```json\n\"features\": \"-mmx,-sse\"\n```\n\n## 浮点数\n\n关于浮点数，我们有一个好消息和一个坏消息。坏消息是，`x86_64`架构也使用SSE寄存器做一些浮点数运算。因此，禁用SSE环境下的浮点数运算，都将导致LLVM发生错误。Rust的core库基于浮点数运算实现——比如它实现了f32和f64类型——这样的特点，让我们无法通过避免使用浮点数而绕开这个错误。而好消息是，LLVM支持一个称作`soft-float`的特征，它能够基于普通的整数运算软件模拟浮点运算；无需使用SSE寄存器，这让我们在内核中使用浮点数变为可能——只是性能上会慢一点点。\n\n为了启用这个特征，我们把`+`号开头的特征名称加入配置项：\n\n```json\n\"features\": \"-mmx,-sse,+soft-float\"\n```\n\n\n\n> *原文链接：*<https://os.phil-opp.com/red-zone/>  *原作者：@phil-opp*  \n>\n> 译文链接：--\n>\n> 译者：洛佳  华中科技大学* \n>\n> 转载请注明出处，商业转载请联系原作者*"
        },
        {
          "name": "dummy.rs",
          "type": "blob",
          "size": 0.0595703125,
          "content": "fn main() {\n    println!(\"Hint that this is a Rust repo!\")\n}\n"
        },
        {
          "name": "translation-table.md",
          "type": "blob",
          "size": 5.3779296875,
          "content": "# 译名表\n\n收录书中涉及专有名词的英文单词、短语，给出本书的中文译名。\n\n采纳惯用译名为主。没有合适译名的，尽量做到信、达、雅的前提下，给出新翻译。\n\n英文部分书名、人名请使用斜体；保留原有的大小写。请按英文字母顺序排序。\n\n涉及特定语言、软件和架构等的概念，标注(Rust)(x86)(QEMU)等，以便和其它语言、技术的概念相区分。\n\n| 英文 | 出现章节 | 中文翻译 |\n|:----|:--------|:------|\n| append by bytes | 二 | 按字符拼接 |\n| Application Binary Interface, ABI | 二 | 应用程序二进制接口 |\n| assert | 四 | 断言 |\n| attribute (Rust) | 四 | 属性 |\n| background color | 二，三 | 背景色 |\n| bare metal | 一，二 | 裸机 |\n| bare-metal executable | 一 | 裸机程序 |\n| block (in contexts) | 三 | 阻塞 |\n| bootable disk image | 二 | 可引导的映像 |\n| bootloader | 二 | 引导程序 |\n| bright bit | 三 | 加亮位 |\n| BSS segment | 二 | BSS段 |\n| byte literal | 三 | 字节字面量 |\n| byte string | 二 | 字节串 |\n| caret requirement (Rust) | 二 | 脱字号条件 |\n| character cell | 二，三 | 字符单元 |\n| C-like enum (Rust) | 三 | 类似于C语言的枚举 |\n| Code page 437 | 三 | 代码页437 |\n| color code | 三 | 颜色代码 |\n| Combinators | 十二 | 组合子 |\n| compiler built-in libraries | 二 | 编译器内建库 |\n| conditional compilation | 四 | 条件编译 |\n| const evaluator | 三 | 常量求值器 |\n| const functions (Rust) | 三 | 常函数 |\n| Cooperative Multitasking | 十二 | 协作式多任务 |\n| copy semantics | 一，三 | 复制语义 |\n| CPU exception (x86) | 四 | CPU异常 |\n| CPU feature | 二 | CPU特征 |\n| crate (Rust) | 三 | 包 |\n| crate root (Rust) | 三 | 根模块 |\n| cross compile | 一 | 交叉编译 |\n| custom target | 一 | 自定义目标 |\n| dependency (Rust) | 三 | 依赖项 |\n| derive (Rust) | 三 | 生成 |\n| destructor | 一 | 析构函数 |\n| \"dev\" profile (Rust) | 一 | dev配置 |\n| device name | 二 | 设备名 |\n| diverging | 十二 | 发散 |\n| diverging function (Rust) | 一 | 发散函数 |\n| dynamically dispatch | 十二 | 动态派发 |\n| edition (Rust) | 一 | 版次 |\n| enum (Rust) | 三 | 枚举 |\n| Executable and Linkable Format, ELF | 二 | ELF格式 |\n| exit status (QEMU) | 四 | 退出状态 |\n| explicit lifetime (Rust) | 三 | 显式生命周期 |\n| embedded system | 一 | 嵌入式系统 |\n| entry point | 一 | 入口点 |\n| entry point address | 二 | 入口点地址 |\n| feature flag | 二 | 特性标签 |\n| foreground color | 二，三 | 前景色 |\n| formatting macros (Rust) | 三 | 格式化宏 |\n| freestanding executable | 一 | 独立式可执行程序 |\n| garbage collection | 一 | 垃圾回收 |\n| generic | 三 | 泛型 |\n| green threads | 一 | 绿色线程，软件线程 |\n| guest system | 四 | 客户系统 |\n| host system | 一，二 | 宿主系统 |\n| immutable variable (Rust) | 三 | 不可变变量 |\n| integration test | 四 | 集成测试 |\n| interior mutability (Rust) | 三 | 内部可变性 |\n| I/O port (x86) | 四 | IO端口 |\n| kernel | 二 | 内核 |\n| language item (Rust) | 一 | 语言项 |\n| line feed | 三 | 换行符 |\n| linker | 一，二 | 链接器 |\n| linker argument | 一 | 链接器参数 |\n| lazy initialization | 三 | 延迟初始化 |\n| magic number | 二 | 魔术数字 |\n| memory-mapped I/O | 三 | 存储器映射输入输出 |\n| memory safety | 二 | 内存安全 |\n| module (Rust) | 三 | 模块 |\n| mutable static variable (Rust) | 三 | 可变静态变量 |\n| mutual exclusion | 三 | 互斥条件 |\n| name mangling | 一 | 名称重整 |\n| \"never\" type (Rust) | 一 | Never类型 |\n| page table | 二 | 分页表 |\n| page fault| 四 | 缺页异常 |\n| Pin | 十二 | 固定 |\n| precompiled library | 二 | 预编译库 |\n| Preemptive Multitasking | 十二 | 抢占式多任务 |\n| range notation (Rust) | 三 | 区间标号 |\n| raw pointer | 二，三 | 裸指针 |\n| redzone | 二 | 红区 |\n| release channel (Rust) | 二 | 发行频道 |\n| \"release\" profile | 一 | release配置 |\n| root module | 一 | 根模块 |\n| root namespace | 三 | 根命名空间 |\n| rule (in macros, Rust) | 三 | （宏的）规则 |\n| runtime system | 一 | 运行时系统 |\n| semantic version number, semver | 三 | 语义版本号 |\n| serial port | 四 | 串行端口 |\n| Single Instruction Multiple Data, SIMD | 二 | 单指令多数据流 |\n| spinlock | 三 | 自旋锁 |\n| stack trace | 一 | 堆栈轨迹 |\n| stack unwinding | 一，二 | 栈展开 |\n| standard output | 一 | 标准输出 |\n| 'static lifetime (Rust) | 三 | 'static生命周期 |\n| static variable | 二 | 静态变量 |\n| structured exception handling, SEH | 一 | 结构化异常处理 |\n| software threads | 一 | 软件线程，绿色线程 |\n| submodule (Rust) | 三 | 子模块 |\n| system call | 一 | 系统调用 |\n| target triple (Rust) | 一，二 | 目标三元组 |\n| target specification | 二 | 目标配置清单 |\n| target system | 二 | 目标系统 |\n| test runner | 四 | 测试运行器 |\n| trait object (Rust) | 四 | trait对象 |\n| unsafe block | 二，三 | unsafe语句块 |\n| unstable feature | 二 | 不稳定特性 |\n| VGA text buffer (x86) | 二，三 | VGA字符缓冲区 |\n| VGA text mode (x86) | 三 | VGA字符模式 |\n| virtual address | 二 | 虚拟地址 |\n| volatile operation | 三 | 易失操作 |\n| warning | 三 | 警告 |\n| wrapping type | 三 | 包装类型 |\n"
        }
      ]
    }
  ]
}