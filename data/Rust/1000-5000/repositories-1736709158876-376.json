{
  "metadata": {
    "timestamp": 1736709158876,
    "page": 376,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjM4MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "sonos/tract",
      "stars": 2284,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".all_crates.sh",
          "type": "blob",
          "size": 0.1748046875,
          "content": "\nALL_CRATES_PATH=\"data linalg core nnef nnef/nnef-resources pulse-opl pulse extra hir tflite tensorflow onnx-opl onnx metal libcli api api/rs api/ffi api/proxy/sys api/proxy cli\"\n"
        },
        {
          "name": ".change_crate_dep.sh",
          "type": "blob",
          "size": 0.185546875,
          "content": "#!/bin/bash\n\ncrate=$1\nversion=$2\n\nperl -pi -e \"s/^($crate = {.*version *= *)\\\"([^\\\"]*)\\\"(.*)$/\\$1\\\"=$version\\\"\\$3/\" \\\n    `find . -name Cargo.toml \\! -path \"./target/*\" \\! -path \"./issue*\"`\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.2236328125,
          "content": "target\n**/*.rs.bk\n*.rustfmt\n*.back\nCargo.lock\nexamples/data\n.idea\n.cached/**\nflamegraph.svg\nperf.data*\nreadings.*\nmetrics\ntract.out\n.gdb_history\n/issue-*\n/.dinghy.toml\n.cargo\nproptest-regressions\n/tmp\nwheelhouse\ntarget-bisector*\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 4.123046875,
          "content": "language: rust\ndist: trusty\ncache:\n  # - cargo\n  #- directories:\n  #- $HOME/cached\naddons:\n  apt:\n    packages:\n    - awscli\n    - jshon\n    - moreutils\nenv:\n  global:\n  - RUST_BACKTRACE=1\n  - AWS_DEFAULT_REGION=us-east-1\n    #  - CACHEDIR=$HOME/cached\n  - secure: DdQqS4fFDevY/JknS0M6CwW+ooj6ZhKmBk4lFliG3WQgjYietbPMCkiHPEC8Df8U07l54+8G4j+sZJJ4VYQY8WQcuKGWt9/ALjoYHYZ1Dlw0KW0rRJ1BZWLUh8MwpJ5pxHSWfl1a8QqTy/0mI3eJ8iVIDxiZR6b1fGwPYDkNXyqnfOvz31X1aMyoGslNkP7LitObCdBJyzobPlvWafGCQLf7oLbK4a5Ysyc9T607n1B0okco3Te2ztahEOwNoxmHlEFRojM6ZmAmo8LzwkCdFQNjHw+mQ3vScC8gpngi61G9U35luAfweMt30m1UmecVGADeEmwSnJLeAHo5HYKT5n6Q1begxlMGMxezinstTHUX6G8EhEumO/ii3PAscFJ6C+VfciGA7JDS2ICghygKSIqQvVeugNR0glW97lhszLnoXCNY45siknAZVTVqwhgn1ctTQiPWqGVuQp+m9NYIoQAYUpOFNo1mEtEjurHOk96Q0XjRJMfUSLOB5KfPakk/ghEY1ZYDDB9wi134f3Z5hLw1FGj/Uiw9LcnEIcORV2o8fbFrb2IgGsKQbRtdPEJ92q5bdeA00TbSrzoDDRFGbwBg+8ibFMF8O2J3Q54sUu6LmkP7qjtMIT2vB09M7LWQYtW3Vd6ovHwI6v+tNJK2D4cJA0KOSwzpOgIBhEubrZI=\n  - secure: su5wLbN7lr59HSKGM8M9pW9VSFMtdTBbQ1oBZFTvw+RNoNew3BBMh8XymbjEv6R+yyGmDAa8Dw6E7HPiBtI5O4q89rHxl7MO5keZINjpXDzTydZ5MQ2juZPIRQpLfpl6AN1meG8I3SoOrTMDgGqfPh2rqEjIS6cBZbo8Re/0KSBuJB781qdT6x80Qfpy87sDu9GTRM8ueXsV+jRw0Yek709m29MSB8pkFAP9OitKHxzF5OFnxVPV2becj53racOe7q9ZE5QWmWnzPZUxflVyrtzDsN0J/C4g0SoEbxLFg1OLbffO1GVJ/Iv6ZeaggzYRvCYwSSANyfqorqSUDT5NPwQlUXjgBPHlOXbCfY2s5hFzQQ3z4R86fyzfdfBQ56uXTXkB4CWpn/JieUoviuDO0/YNaI0KU6hOrOn68BZrBSqwHcxwhtcP3cw/EXfR1aiok7OoDPAWnR4f3Lu/+fmkW+VUEg5Ufh/GgjZt7XwsNBfo+pmvO3mO/5okxa2/HbOwcoTpELAzPMKyh1xn5gjrk5bWcZofeGtFMoXN4+G8+1qlQ/sLp3144QHyRf00n4qlhA6xZwplpBWN12haXyKRx67lPTzE5QuT1BRoyCdRvbjQiOdo61xGvoOK9J8PL9C06xtnKQ+6iDnjFaWielASoENvcNL+DCKqiecpUb5hoR4=\n  - secure: HZHubUhHLYh+v5yuyMy5TmfleHqAdcmVZd6hZf7c2sXQLsrcjoLGPxu4jzS9OJt27Sfp6xXVFeeA7SFDMobxe8AFm3+SRCbzvT6mu8/LlsuTsQO3jYQtt8j5OIhtLQ7yfDyOscXwy2I3SgluhVQ0HCIi6ShQ8YRD1vE119Qku2x/sWlKcZQckcl5T/yyig08sXfOM+IfFQPIW1gvMWM3dv6RigiCiy4qjfeQy8v8xbvbRayXeT4Vpfv9CqN79kAQ03r7MSmBBn6i88mGoQEzVDMEZPZq8rMNqn8qyIn8LxjXaCpUz0fTCYJrHSmzKyCE7+k7IEidlkyT6hJpvpXCfNYBSk2fB7SDxlm98ELVgqPBq6vjYoPaqsqs7Cz+pTTQYOCnCKvRDYhccqhAsgjNVKDRIJc0H7cT5sv4TuJxsMp/vYVh7RxoFem2r37ns4pu8XPP9RVsmoAVYzlHu8Fnd8TWY30MXACf3t43ceaPfor0IARrZcjQR1lt7eMJGQDkduJRxzq0cBB1djP8HfZGab/I0cVFEXGeJWDQfaHZ8Pq/M3+bBPLD9XLqKmpoNbW+gqQQl49/w01/EJrp9QhK/Og6ujfkeA1OCziPCUDLAHYvmwaYZYzV9z5VSPfUYwiiJzva92/ywWfhCmz3SpXPbq8cTPoDWzeBUeqcw8iIWVU=\n  - secure: vH8bS7RVgaHLGZUeqtViCQYDJfhubMiCMETLPD959pv9sODmSfjOhYtFgZtbn0wZ2fhCQFgKhYKUJdti5Vo9OUlyBiUsfLPilAAaeZu0Y2SQIKpbuNU9kJibuzyj6KZoRhjvsifhO5/mB03W7CpzjSGvJntK62BM0b6CrDtUlHlOgjwd3U1c5brZS9VWfnkh8pohgneB/XYtefTJXHuGjJgf75uw2TO/ZKQmmaKJWPoMVN76cgarRmXS/SoGMLr0+7ArnvIMNW9QRMABrSzUgP0RBvNfndwjiIQDZpIefIz/UVTa5e/pS79CLoQKM9FSWZANf3ZJgz0SzYgMprSe9f3RZGu5i0BLQA0SzdxCjCra5/3/pz+p86/iWGHnBfV6pvH9c2W1OUCCTiohNk7bgUfXxVrxk2RHxhc375MFiCxu6KtPRW8kJoRTSZP+k2itaBPUSevV0cdWrVlRjnTwoCskxMIFQH+vStxQjUXV0/g9SZzwdIR/j1aKIjb6VdQS2WOh0+BKgHy0jy2w4GJHtuObIg0aTcQAtt44aK0T/VeHJ0f1FxfjzPxrcqcgSxvi2E4HgedSCvtOHPWs5YYYGt76yH0G5ZOMOF8xP2CRStlcNB0TtLdpcUvQT2ejK7t4sCOj8Kz81s2cbLCZnJdkFaaBsffV7JtbjexXRwohGxI=\n\nmatrix:\n  include:\n    - rust: stable\n    - rust: stable\n      env: PLATFORM=raspbian\n    - rust: 1.35.0\n    - rust: stable\n      script: .travis/tf.sh\n    - rust: stable\n      script: .travis/debug-tests.sh\n    - rust: stable\n      os: osx\n      osx_image: xcode9.3\n      env: PARTIAL_CI=true\n    - rust: stable\n      env: PLATFORM=aarch64-unknown-linux-gnu\n    - rust: stable\n      env:\n        - PLATFORM=armv6vfp-unknown-linux-gnueabihf\n        - TRACT_CPU_EXPECT_ARM32_NEON=false\n    - rust: stable\n      env:\n        - PLATFORM=armv7-unknown-linux-gnueabihf\n        - TRACT_CPU_ARM32_NEON=true\n        - TRACT_CPU_EXPECT_ARM32_NEON=true\n    - rust: stable\n      env: PLATFORM=aarch64-linux-android\n    - rust: stable\n      env: PLATFORM=armv7-linux-androideabi\n    - rust: stable\n      env: PLATFORM=i686-linux-android\n    - rust: stable\n      env: PLATFORM=x86_64-linux-android\n    - rust: stable\n      os: osx\n      osx_image: xcode9.3\n      env: PLATFORM=aarch64-apple-ios\n    - rust: beta\n    - rust: nightly\n    - rust: stable\n      os: windows\n      script: cargo test -p tract-linalg\n  allow_failures:\n   - rust: nightly\n   - os: windows\n\nscript: \".travis/travis.sh\"\n"
        },
        {
          "name": ".travis",
          "type": "tree",
          "content": null
        },
        {
          "name": ".vim",
          "type": "tree",
          "content": null
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 19.1181640625,
          "content": "# Unreleased\n\n# 0.21.8 - 2024-12-05\n* [linalg, compression] introduce mmm kits\n* [linalg] (wip) rework f16 on non-f16 machines\n* [linalg] element-wise binary operators optimisation\n* [core, compression] gather with compressed weights\n* [metal] new kernels\n* [metal] new memory management\n* [nnef] opt-in deterministic tar encoding\n\n# 0.21.7 - 2024-09-23\n* [metal] (experimental) introduce partial support for Apple Metal\n* [core] Potential internal API breaking changes (operator names, comparison ops refactored)\n* [data] (experimental) Smarter TDim simplification, handling of Min and Max. TDim assertions for simplifications.\n* [data] (experimental) WIP around multiple scenarios (modes) for LLM inference\n* Extra examples\n* [linalg] (experimental) kernels targetting LLM block-quantized tasks (inc. intel 32x1 q40f32)\n\n# 0.21.6 - 2024-07-24\n* [data] Rework tdim and symbols, introduce inequalities assertions, min and max operators\n* [data] Generalize Blob usage in Tensor\n* [linalg] Rework reduce implementation, introduce more generic binary ops support (wip)\n* [linalg] Introduce multithreaded matrix multiplication runner\n* [linalg] Introduce Q4_0 block quantization for weights (wip)\n* [linalg] Introduce AMX f16 kernels, Neon Q40F16 kernel (experimental)\n* [linalg] wasm f32 4x4 kernel \n* [core] Introduce Opaque and OpaqueFact to escape Tensor and TValue formalism\n* [core] generalize/improve float precision translator, with translation filter\n* [core] Introduce garbage collecting in patch application, new compact algo, and rework constant propagation to spare memory\n* [core] Rework packed format and packing metadata\n* [linalg/core] Introduce multiple packing format for matmul kernels\n* [core] Work In Progress refactoring binary, towards more optimized execution strategies\n* [nnef] inequalities assertions extension, q4_0 extension\n* [tflite] plug in tanh and sigmoid\n\n# 0.21.5 - 2024-05-11\n* [TFLite] fixes for fully connected and max pool layers\n* Allow opting out of new memory friendly execution order optimisation\n\n# 0.21.4 - 2024-04-23\n* More memory/cache friendly execution order\n* Several fixes around symbolic dimensions computation (some should help with attention models)\n\n# 0.21.3 - 2024-04-03\n* [AMX] Put AMX for iOS behind a feature gate (\"tract-linalg/apple-amx-ios\").\n\n# 0.21.2 - 2024-03-29 (yanked)\n* [ONNX] Support for external storage of tensors with offset and length\n* [ONNX] Lots of fixes around binary quantized operators (add, mul, etc)\n* [PY] Fix python source distribution\n* [AMX] Activate AMX on iOS\n* [API] Introduce transforms in external api\n* [BLAS] Introduce a simple BLAS transform for Matrix multiplication\n* [F16] Introduce a Reduce<MeanOfSquares> that solves many L2 normalization errors in f16\n\nThis version has been yanked to revert systematic activation of AMX on iOS. AMX is a private API and Apple may reject an App that performs AMX instructions.\n\n# 0.21.1 - 2024-02-08\n* [ONNX] Support for external storage of tensors with offset and length\n\n# 0.21.0 - 2024-01-16\n* MSRV is now 1.75.0\n* [internal] ConvUnary and MatmulUnary are replaced by binary, potentially dynamic equivalent\n\n# 0.20.22 - 2023-11-28\n* [ONNX] LayerNormalization support\n\n# 0.20.21 - 2023-10-31\n* [ONNX] ignoring output shapes is now the default\n* \n\n# 0.20.18 - 2023-08-30\n* [intel] fix in AVX512F matrix vector product\n* [tflite] alpha, embryonic support. some convolutional models working.\n* [kaldi] remove abandonned kaldi experimental support\n* [refactoring] Runtime abstraction and runtime-targetting tests\n* [refactoring] Refactoring Python and C API around a possible tract-api. Introducing dylib support.\n* [pytorch compat] fixes around node names starting by / (bug triggered by recent pytorch versions)\n\n0.20.7 to 0.20.17 are misfires\n\n# 0.20.6 - 2023-06-09\n* Bug fixes, fix display of If operator\n\n# 0.20.5 - 2023-05-26\n* Various bugfix around Einsum\n* Einsum now has functions to translate to MatMul and other axes manipulations\n\n# 0.20.0, 0.20.1, 0,20.2, 0.20.3 - 2023-04-25\n* [optim] 32x32 f32 AMX kernel (for Apple Silicon M family)\n* [optim] bunch of AMX512F kernels (square, skinny, vector)\n* [ONNX] introduce Trilu, TopK\n* [NNEF/OPL] submodel loader\n* [ONNX] support alternative layout for LSTM (layout=1, batch becomes first axis)\n* [ONNX] If operators with dynamic condition (very basic optimisations, no nnef support yet).\n\n# 0.19.9 & 0.19.10 - 2023-04-17\n* HardSwiwh ONNX, tract_core_hard_swish in NNEF/OPL\n* introducing tract_core_submodel in NNEF/OPL\n* JSON resource loader in NNEF/OPL\n* Profiling API tweaks\n* `--folded` view for model command line dump (hide Scan loops)\n\n# 0.19.8 - 2023-03-27\n* Various bug fixes\n\n# 0.19.7 & 0.19.6 - 2023-02-24\n* more bug fixes\n* wip on python doc auto-deploy\n\n# 0.19.5 - 2023-02-22\n* 0.19.3 and 0.19.4 are release misfires\n* lots of bugfixes following 0.19 big changes\n* introducing the JSON NNEF resource\n\n# 0.19.2 - 2023-01-30\n* [NNEF/OPL] introduce json resource loader\n* extend Complex number support (under a feature flag)\n\n# 0.19.1 - 2023-01-23\n* [nnef] new identifier syntax is now opt-in for serialization (both accepted at loading)\n* alpha-level C interface. how and how to deploy it (where to put the .h, whether or not to build and ship dylibs)\n* alpha-level python interface. deployed on pypi as \"tract\". At this stage, API is undocumented and may still change significantly.\n\n# 0.19.0 - 2023-01-11\n* [BREAKING] TValue are now used in run() instead of the previous mix of Tensor and Arc<Tensor>\n* internal API breaking changes: no more op_families, libcli split away. State is no longer Send (but can be \"frozen\" to a Send counterpart).\n* Symbols can now be String instead of char. They are not shared globally anymore, but scoped in the Model instead.\n* [pulse] S symbol is no longer magic. The time dimension symbol must be provided at pulsification time.\n* [pulse] In most cases, we can now pulsify without an explicit pulse len (pulse len can be expression).\n* [cli] deprecated \"x\" syntax for shape is removed\n* [nnef/opl] new i\"...\" syntax for escaping identifiers: i\"some arbitrary string\". Allow serialization of any ONNX model with any kind of string as node names.\n* [ONNX] Signal processing operators (DTF, STFT, MelWeightMatrix, BlackmanWindow, HammingWindow, HannWindow)\n* [ONNX] bitwise operations\n* [ONNX] Compatibility target raised to operator set 18\n\n# 0.18.3 - 2022-10-27\n* [NNEF] Introduce a \"resource\" extension for loading values from a separate source (as a config file)\n* Workaround for cpu detection failure on FreeBSD / arm64\n* Various bug fixes\n\n# 0.18.2 - 2022-10-18\n* [pulse] improve convolution (and others) pulsification to avoid some unecessary buffering delay\n* [cli] support multiple streaming inputs and outputs\n* [ONNX] more relaxed Clip operator rules\n\n# 0.18.1 - 2022-10-06\n* prepare NNEF for further tract-opl extension (resource support)\n* more generic matmul\n* optimise some EinSum cases as matmul\n\n# 0.18.0 - 2022-09-21\n* [ONNX Breaking] Several changes to move towards supporting ONNX symbolic dimensions (actual fixes, but they may break stuff that was working more or less by accident). It may be required to erase output shapes explicitely when input shape is overriden on models that were working before.\n* [CLI breaking] ONXN symbolic dimensions has some impact here too. --input-bundle is deprecated, is was overriden and ambiguous. Instead, there is a  --input-facts-from-bundle global option, and a --input-from-bundle option in the subcommands run, profile, dump. --allow-random-input is also moved to subcommands. We think all previously supported behaviours are still there. Please open issues if not.\n\n# 0.17.7 - 2022-09-05\n* clippy up all tract code\n* various fixes\n* 0.17.5 and 0.17.6 are misfired\n\n# 0.17.4 - 2022-08-11\n* [cli] global --set (as a somehat cleaner --concretize successor) allow to set a symbol value after decluttering\n* [cli] run --save-outputs output.npz to save execution outputs\n* dozens of fixs and code cleanup (clippy-fication in progress)\n\n# 0.17.3 - 2022-07-25\n* [License] Allowing https://spdx.org/licenses/Unicode-DFS-2016.html (no tldr yet, but pretty similar to BSD-2)\n* [Breaking] CLI --json option reports costs as strings instead of numbers (in order to allow symbolic values).\n* Sigmoid/Tanh f32 reimpl, plus new f16 impl.\n\n# 0.17.1 - 2022-07-11\n* Sanitiser=address in the CI. Fixed a couple of overflow/memleaks. (Nothing looked too awful.)\n* ONNX NonMaxSuppression\n\n# 0.17.0 - 2022-06-13\n* [Breaking] [ONNX-ML] TreeEnsembleClassifier with binary output (single class) now mimicks scikit-learn output layout.\n\n# 0.16.9 - 2022-06-10\n* bump ONNX protobuf file and support external tensors format\n* new \"skinny\" kernels for avx2/fma f32 multiplication (positive impact on low, non 1 batch size for DNN-heavy loads)\n\n# 0.16.7 - 2022-05-16\n* Softmax is now an operator in core, coming with a direct quantized implementation\n* new TypedFact constructor API ( f32::fact(&[1, 4, 12]), f32::fact(shape!(Symbol::from('N'), 12)))\n* fixes and optimisation of re-quantization pipeline\n* fixes around symbols in NNEF/OPL\n\n# 0.16.6 - 2022-05-03\n* Various changes around quantization support (qi32 appearance)\n\n# 0.16.5 - 2022-04-27\n* Intel optimisation are back\n* Range is now more flexible, should unlock some BERT models with symbolic dimensions.\n\n# 0.16.4 - 2022-04-14\n* some optimisations in depthwise convolutions\n* various bugfixes\n* [Breaking] Fixed nnef \"tile\" operator definition (\"repeats\" is plural). As a consequence models using \"tile\" serialized with tract with prior versions can not be loaded anymore (and vice-versa).\n\n# 0.16.3 - 2022-03-30\n* [Breaking] tract-opl models Scan syntax changed a bit. Models exported by <0.16.2 are loadable in >=0.16.2, but not the other way around.\n* Optimisation in deconv\n\n# 0.16.1 - 2022-03-02\n* [Breaking] Minimum Rust Supported Version is now 1.59.0\n* [Breaking] Small API changes in model api: .compact(), .optimize(), .declutter() now take &mut self and work in place.\n* [LICENSE] Only the licensing for dependencies of the top-level library crates (tensorflow, onnx, kaldi, pulse) will now be monitored. The command line tool (tract crate in cli folder) is for developpers (tract developpers or tract integrators), is not meant to be shipped to end-user, and it concentrates most of the license and dependency complexity.\n* [LICENSE] BSD-3-Clause is now accepted in tract.\n* Optimisations around convolutions and deconvolution\n* Optimisation on Cortex-A53, first round of Cortex-A55 optimisation too.\n\n# 0.15.8 - 2021-11-18\n* Fix brand new ArrayFeatureExtractor inference\n\n# 0.15.7 - 2021-11-16\n* ONNX ArrayFeatureExtractor\n* ConvTranspose/deconv optimisation\n\n# 0.15.6 - yanked \n* just a release script failure\n\n# 0.15.5 - 2021-10-26\n* hold half at 1.7.x for compat with rust 1.50\n\n# 0.15.4 - 2021-10-21\n* ConvTranspose/deconv pulse support\n* ONNX SpaceToDepth/DepthToSpace\n\n# 0.15.3 - 2021-07-29\n* optimise i8*u8, u8*i8 and u8*u8 matrix products (and convo)\n\n# 0.15.2 - 2021-07-09\n* bump prost dep\n\n# 0.15.1 - 2021-07-08\n* some optimisations for arm32 (cortex-a7 and a9)\n\n# 0.15.0 - 2021-06-24\n\n* Switched the order of item_type and item_type_vendor in the NNEF tendor format to be consistent with NNEF-tools, and changed the item_type of integers due to an error in the specification. Breaking for tensor files containing integers or strings.\n* Scan output batching optimisation\n* Concat pulsification over a secondary axis\n* new aarch64 16x4 f32 kernel\n\n## 0.14.2 - 2021-05-27\n\n* better handling of errors in ONNX parser\n* fix/workaround some performance regressions bubling from recent ndarray changes\n\n## 0.14.1 - 2021-05-18\n\n* ONNX ConvTranspose, Gather, GatherND, GatherElements, Scatter, ScatterND, ScatterElements support (and NNEF deconv)\n* Fixes around integer serialisation in NNEF\n* workaround subtle breaking changes in ndarray (between 0.15.1 and 0.15.2)\n\n## 0.14.0 - 2021-04-19\n\n* low-level functions in linalg are now version tagged: two versions of tract can now co-exist in the same binary\n* rustc minimal version is now 1.50\n* dependencies version bumps (ndarray, itertools, and others)\n\n## 0.13.2\n\n* fix sigmoid and tanh variability on intel\n\n## 0.13.1\n\n* temporary disable binary unicast add fusing (too many bugs)\n\n## 0.13.0\n\n* Release are now \"in sync\": all tract crate versions on a build *must* be aligned\n* optimisations, with a focus on aarch64\n\n## 0.12.5 - 2021-01-12\n\n* Dependency bumps\n\n## 0.12.4 - 2021-01-06\n\n* 0.12.3 is a misfire\n* hotfixes on 0.12.2 new tree classifier\n* fix X compilation from macos/aarch64 to macos/intel\n\n## 0.12.2 - 2021-01-05\n\n* ONNX-ML: CategoryMapper and TreeEnsembleClassifier (partial, SoftmaxZero and Probits are missing). With NNEF support.\n* cargo-deny enforces licences choices\n\n## 0.12.1 - 2020-12-11\n\n* 0.12.0 is a misfire.\n\n* API BREAKING: TypedFact::dt_shape & friends can not fail anymore, no longer return a result (remove `?`)\n* Breaking: Rust minimal version bumped to 1.42\n\n* Early, basic, correct but slow support for i8 by u8 matrix mult.\n* Support for Apple Silicon, aka M1, aka aarch64 darwin (but not in CI yet)\n* dynamic quantization convolution support\n* release now ships cli musl builds for linux\n* optimizations targetting small Cortex-A (like 7, 8, and 9)\n* command line dump --profile --cost now computes flops\n* ONNX: OneHot op support\n\n## 0.11.2 - 2020-10-26\n\n* ONNX: new op: DynamicQuantizeLinear\n* tract-data crate split from core, containing tensor, dim, and datum types.\n\n## 0.11.1 - 2020-10-20\n\n* switch from error_chain to anyhow\n* simplify trivial gathers to a slice\n* generalize symbolic dimension a bit: support \"2S\" and the like\n* deprecate \"x\" syntax in CLI, please use `,`  instead\n\n## 0.11.0\n\n### Breaking \n\n* NNEF: tract-nnef no longer performs gunziping, but expect an uncompressed tar\n    stream. We found out is it counter-productive (weights matrices are more or\n    less random, they do not compress easily, and decompression is expensive).\n    NNEF networks in the wild are .tgz file. Using flate2, decompression is a\n    one-liner, but it must be done by the client code now.\n* bumped extended nnef compat version (unchecked at this stage) to \"alpha1\"\n* move pulse operators and translation to their own crate and nnef registry\n* generalize TDim to support an arbitrary number of symbols\n* concretize_stream_dim is superseded by concrentize_dims\n\n### Notable\n\n* new crates, building on tract-opl introduction:\n    * *tract-pulse-opl*: pulse runtime (handful of ops, including Delay) is now separated from core\n    * *tract-onnx-opl*: onnx runtime (4 ops not belonging in core)\n    * *tract-pulse*: pulsification of models (model-translation time)\n    * tract-onnx is now limited to onnx model loading and conversion\n\n## 0.10.10 - 2020-08-30\n\n* load a NNEF as a TypedModel using tract_nnef, and from the CLI\n* dump a tract TypedModel to NNEF (with extensions for op not nnef compatbile)\n* not a full coverage of nnef, but enough for most CNN (image categorizers zoo working)\n* 80% of onnx tests are surviving a NNEF dump and reload at this stage\n\n## 0.10.0 - 2020-07-28\n\n### ONNX\n\n* covered operators compatible with Operator Sets 9, 10, 11 (new) and 12 (new)\n\n### API Breaking\n\n* Tensor::l1 method is gone\n\n### Windows\n\n* Support for -gnu targets (non-mvsc).\n\n### Notable\n\n* --cost now gives the number of parameters in the model\n* SimpleState is clonable again (actually useful !)\n\n## 0.9.2 - 2020-06-16\n\n* introduce `TypedModel::method.concretize_stream_dim`\n* various pulsification bugfixes\n\n## 0.9.1 - 2020-06-16\n\n* fix Reshape with TDim\n\n## 0.9.0 - 2020-06-15\n\nStill no shortage of version numbers...\n\n### API Breakage\n\n* NormalizedModel (and friends) are gone. They were only useful as a pre-pulse transformation pre-requisite that the current TypedModel (& co) meets.\n* TypedModel::into_optimized() is gone. InferenceModel::into_optimized() stays as an end-to-end shortcut for simple cases. It does .into_typed()?.declutter()?.optimize()).\n* TypedModel::codegen() is now ::optimize()\n\n## 0.8.0 - 2020-06-13\n\nI wish I had seen these issues yesterday. Anyway, version numbers are cheap.\n\n* Bumping minimum rust to 1.41\n\n## 0.7.0 - 2020-06-12\n\n* CLI refactoring (hopefully stabilizing a bit?)\n    * `profile --bench` is now bench\n    * profile is now `dump --profile`\n    * cost is now `dump --cost`\n    * profiling is now done during a full net instead of per op\n    * new \"compact\" graph dumper, profile visual hints\n    * `dump --cost --profile --json` output profiling and cost information\n    * show logical names for ops instead of the Op struct names (not 100% sure it's right)\n    * criterion integration\n* WASM support for tract-onnx and tract-tensorflow targets (CI)\n* Convenience methods added to Models to allow model building in fluent style, up to Plan instantiation (SimplePlan now nicknamed RunnableModel). Non breaking.\n* Support for ONNX bidi LSTM (CI), GRU and RNN (untested, consider alpha)\n* Fixes around nets with a non trivial batch size (axis simplification code, matmul op fusion)\n\n## 0.6.3 - 2020-04-25\n\n* Lock ndarray version to dodge rustc/llvm issue (https://github.com/rust-lang/rust/issues/71506)\n\n## 0.6.2 - 2020-04-15\n\n* Use http://gihub.com/kali/readings for instrumentation.\n\n## 0.6.0 - 2020-02-19\n\n### Notable\n\n* New jupyter/keras/tf example\n* ARMv8 tanh / sigmoid optimisation\n\n### API Breaking\n\n* refactor exports and dependencies\n    * preferred way to use tract is now to `use tract_tensorflow::prelude::*;`\n    * singleton framework is built by `let tensorflow = tensorflow()`. The Framework trait is in the prelude too.\n    * the prelude contains a reexport of `tract_core`, and of ndarray as `tract_ndarray`\n    * no more need to declare dependency on `tract-core` and/or `tract-linalg` in Cargo.toml\n    * same goes for `tract_onnx`\n\n## 0.5.9 - 2020-02-07\n\n### Breaking\n\n* Rustc minimum version is now 1.39\n\n### Onnx\n\n* Support for MatMulInteger, ConvInteger\n* Support for QuantizeLinear DequantizeLinear\n* Basic support for QLinearMatMul, QLinearConv\n\n## 0.5.6 - 2019-10-30\n\n### Tensorflow\n\n* Initial support for GatherV2\n\n### Onnx\n\n* Fix PReLu normalization\n\n## 0.5.5 - 2019-10-25\n\n### Tensorflow\n\n* Initial support for AddV2, Mean, Min, Prod, Sum\n\n## 0.5.4 - 2019-09-30\n\n### Notable\n\n* Make Onnx loader operator set aware, and Slice-10 support.\n* Cost now reports Delay ops buffer size\n* Bump dependencies (protobuf) and fix codegen\n* Windows CI now performs a top-level \"cargo check\"\n\n## 0.5.1 - 2019-09-24\n\n### Bugfix\n\n* remove the no_panic checks, as too fragile (breaking non-lto builds)\n\n## 0.5.0 - 2019-09-20\n\n### Breaking\n\n* Change tensor facts names for consistency: TensorFact is now InferenceFact.\n\n### Notable\n\n* Introduce Windows support, including CI coverage for linalg\n* Switch from Travis to GitHub Actions\n* Internal refactoring around tract-core canonic opset\n* Tract CLI can now compute a FLOP number for networks (\"cost\" subcommand). \n    Furthermore the CI asserts its value for a few networks to prevent optimisation regressions.\n* Fix: handling of -1 in ONNX Reshape op\n\n## 0.4.2 - 2019-09-10\n\n* Fix release script after 0.4.1 release disaster.\n\n## 0.4.1 - 2019-09-09 [YANKED]\n\n* Fix for OS where CARGO_CFG_TARGET_FAMILY is undefined\n* Linear Algebra package refactor\n* tract-core canonic operator set introduction\n* significant performance boost (up to 20% on some real-life networks)\n\n## 0.4.0 - 2019-07-30\n\n* Start Kaldi networks support (LSTM, Renorm, Affine, downsample)\n\n## Before...\n\nThis Changelog started way too late. But better late than never.\n\n"
        },
        {
          "name": "Cargo.toml",
          "type": "blob",
          "size": 6.07421875,
          "content": "[workspace]\nresolver = \"2\"\nmembers = [\n    \"data\",\n    \"linalg\",\n    \"core\",\n    \"pulse\",\n    \"pulse-opl\",\n    \"hir\",\n    \"nnef\",\n    \"nnef/cli\",\n    \"nnef/nnef-resources\",\n    \"tensorflow\",\n    \"tflite\",\n    \"onnx-opl\",\n    \"onnx\",\n    \"libcli\",\n    \"cli\",\n    \"metal\",\n    \"extra\",\n\n    \"metal\",\n\n    \"api\",\n    \"api/rs\",\n    \"api/ffi\",\n    \"api/proxy\",\n    \"api/proxy/sys\",\n\n    \"examples/face_detection_yolov8onnx_example\",\n    \"examples/face_similarity_arcface_onnx\",\n    \"examples/tensorflow-mobilenet-v2\",\n    \"examples/tflite-mobilenet-v3\",\n    \"examples/keras-tract-tf2\",\n    \"examples/nnef-dump-mobilenet-v2\",\n    \"examples/nnef-mobilenet-v2\",\n    \"examples/onnx-mobilenet-v2\",\n    \"examples/pytorch-albert-v2\",\n    \"examples/pytorch-resnet\",\n\n    \"harness/core-proptest-pulse\",\n    \"harness/lstm-proptest-onnx-vs-tf\",\n    \"harness/nnef-inceptionv3\",\n    \"harness/tf-inceptionv3\",\n    \"harness/tf-mobilenet-v2\",\n    \"harness/tf-moz-deepspeech\",\n    \"harness/tfl-mobilenet-v2-q\",\n\n    \"test-rt/infra\",\n    \"test-rt/suite-unit\",\n    \"test-rt/suite-onnx\",\n    \"test-rt/test-f16\",\n    \"test-rt/test-blas\",\n    \"test-rt/test-metal\",\n    \"test-rt/test-unit-core\",\n    \"test-rt/test-onnx-core\",\n    \"test-rt/test-nnef-cycle\",\n    \"test-rt/test-tflite\"\n]\n\n# same, without metal, test-metal and test-tflite which are probelematic on specific targets\ndefault-members = [\n    \"data\",\n    \"linalg\",\n    \"core\",\n    \"pulse\",\n    \"pulse-opl\",\n    \"hir\",\n    \"nnef\",\n    \"nnef/cli\",\n    \"nnef/nnef-resources\",\n    \"tensorflow\",\n    \"tflite\",\n    \"onnx-opl\",\n    \"onnx\",\n    \"libcli\",\n    \"cli\",\n    \"extra\",\n\n    \"api\",\n    \"api/rs\",\n    \"api/ffi\",\n\n    \"examples/face_detection_yolov8onnx_example\",\n    \"examples/face_similarity_arcface_onnx\",\n    \"examples/tensorflow-mobilenet-v2\",\n    \"examples/tflite-mobilenet-v3\",\n    \"examples/keras-tract-tf2\",\n    \"examples/nnef-dump-mobilenet-v2\",\n    \"examples/nnef-mobilenet-v2\",\n    \"examples/onnx-mobilenet-v2\",\n    \"examples/pytorch-albert-v2\",\n    \"examples/pytorch-resnet\",\n\n    \"harness/core-proptest-pulse\",\n    \"harness/lstm-proptest-onnx-vs-tf\",\n    \"harness/nnef-inceptionv3\",\n    \"harness/tf-inceptionv3\",\n    \"harness/tf-mobilenet-v2\",\n    \"harness/tf-moz-deepspeech\",\n    \"harness/tfl-mobilenet-v2-q\",\n\n    \"test-rt/infra\",\n    \"test-rt/suite-unit\",\n    \"test-rt/suite-onnx\",\n    \"test-rt/test-f16\",\n    \"test-rt/test-blas\",\n    \"test-rt/test-unit-core\",\n    \"test-rt/test-onnx-core\",\n    \"test-rt/test-nnef-cycle\",\n]\n\n[workspace.dependencies]\naccelerate-src = \"0.3\"\nansi_term = \"0.12.1\"\nanstyle = \"1.0.2\"\nanstyle-parse = \"0.2.1\"\nanstyle-query = \"1.0.0\"\nanyhow = \"1.0.43\"\nanymap = \"0.12.1\"\napprox = \"0.5\"\nbit-set= \"0.5.2\"\nblis-src = { version = \"0.2\", features = [\"static\", \"pthreads\"] }\nblock = \"0.1.6\"\nboow = \"0.1.3\"\nbox_drawing = \"0.1.2\"\nbyteorder = \"1.4.3\"\nbytes = \"1.0.1\"\ncblas = \"0.4\"\ncc = \"1.0.69\"\nclap = { version = \"~3.1\", features = [ \"cargo\" ] }\ncolorous = \"1.0.5\"\ncore_affinity = \"0.8.0\"\ncriterion = \"0.5.1\"\nderive-new = \"0.5.9\"\ndinghy-test = \"0.6\"\ndowncast-rs = \"1.2.0\"\ndyn-clone = \"1.0.4\"\ndyn-hash = \"0.2\"\nenv_logger = \"0.10\"\nflatbuffers = \"23.1.21\"\nflate2 = \"1.0.20\"\nforeign-types = \"0.5\"\nfs-err = \"2\"\nfs2 = \"0.4.3\"\ngetrandom = \"0.2\"\nhalf = { version=\"2.4\", features = [ \"std\", \"num-traits\" ] }\nhome = \"=0.5.9\"\nimage = \"0.24.1\"\nitertools = \"0.12.1\"\nlazy_static = \"1.5.0\"\nlibc = \"=0.2.164\"\nliquid = \"0.26\"\nliquid-core = \"0.26\"\nlog = \"0.4.14\"\nmaplit = \"1.0.2\"\nmemmap2 = \"0.9\"\nmetal = { version = \"0.30.0\", features = [\"mps\"] }\nndarray = \"0.16\"\nndarray-npy = { version = \"0.9.1\", features = [ \"compressed_npz\" ] }\nnom = \"7.0.0\"\nnu-ansi-term = \"0.46\"\nnum-complex = \"0.4.0\"\nnum-integer = \"0.1.44\"\nnum-traits = \"0.2.14\"\nnum_cpus = \"1\"\nopenblas-src = { version = \"0.10\", features = [\"static\"] }\npaste = \"1.0.5\"\nproptest = \"1.0.0\"\nprost = \"0.11.0\"\nprost-types = \"0.11.0\"\npy_literal = \"0.4.0\"\nrand = { version = \"0.8.4\", features = [\"small_rng\"] }\nrand_distr = \"0.4\"\nrayon = \"1.10\"\nreadings-probe = \"0.1.3\"\nregex = \"1.5.4\"\nreqwest = { version = \"0.11.4\", features = [ \"blocking\", \"rustls-tls\" ], default-features = false }\nrustfft = { version = \"6.1\", features = [ \"neon\" ] }\nrustix = \"0.38.4\"\nrustls = \"0.20.4\"\nscan_fmt = \"0.2.6\"\nserde = { version = \"1.0.127\", features = [ \"derive\" ] }\nserde_json = \"1.0\"\nsmallvec = \"1.6.1\"\nstring-interner = \"0.15\"\nstructopt = { version = \"0.3\", default-features = false }\ntar = \"0.4.37\"\ntempfile = \"3.8\"\ntensorflow = \"0.17.0\"\ntflitec = { git = \"https://github.com/kali/tflitec-rs.git\", rev=\"b37d65a\" }\ntime = \"0.3.23\"\ntime-macros = \"0.2.10\"\ntokenizers = \"0.19\"\nunicode-normalization = \"0.1.19\"\nwalkdir = \"2.3.2\"\ntract-api = { version = \"0.21.10-pre\", path = 'api' }\ntract-core = { version = \"0.21.10-pre\", path = 'core' }\ntract-data = { version = \"0.21.10-pre\", path = 'data' }\ntract-extra = { version = \"0.21.10-pre\", path = 'extra' }\ntract-hir = { version = \"0.21.10-pre\", path = 'hir' }\ntract-libcli = { version = \"0.21.10-pre\", path = 'libcli' }\ntract-linalg = { version = \"0.21.10-pre\", path = 'linalg' }\ntract-metal = { version = \"0.21.10-pre\", path = 'metal' }\ntract-nnef-resources = { version = \"0.21.10-pre\", path = 'nnef/nnef-resources' }\ntract-nnef = { version = \"0.21.10-pre\", path = 'nnef' }\ntract-onnx-opl = { version = \"0.21.10-pre\", path = 'onnx-opl' }\ntract-onnx = { version = \"0.21.10-pre\", path = 'onnx' }\ntract-pulse-opl = { version = \"0.21.10-pre\", path = 'pulse-opl' }\ntract-pulse = { version = \"0.21.10-pre\", path = 'pulse' }\ntract-tensorflow = { version = \"0.21.10-pre\", path = 'tensorflow' }\ntract-tflite = { version = \"0.21.10-pre\", path = 'tflite' }\ntract-rs = { version = \"0.21.10-pre\", path = 'api/rs' }\ntract-proxy = { version = \"0.21.10-pre\", path = 'api/proxy' }\ntract-proxy-sys = { version = \"0.21.10-pre\", path = 'api/proxy/sys' }\ntract-ffi = { version = \"0.21.10-pre\" }\ntract = { version = \"0.21.10-pre\" }\n\n\n[profile.opt-no-lto]\ninherits=\"release\"\nlto=false\n\n[profile.release]\n# debug = true\nlto = true\n\n[profile.bench]\ndebug = true\n\n[profile.dev.package.\"*\"]\nopt-level = 2\n\n[profile.dev.package.darling_macro]\nopt-level = 0 # work around never ending build on wondows\n\n[profile.dev.build-override]\ndebug = false\n# strip = \"debuginfo\" does not work on android and ios\nincremental = false\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 0.4833984375,
          "content": "## License\n\nLicensed under either of\n * Apache License, Version 2.0 ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n * MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\nat your option.\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in the work by you, as defined in the Apache-2.0 license, shall\nbe dual licensed as above, without any additional terms or conditions.\n"
        },
        {
          "name": "LICENSE-APACHE",
          "type": "blob",
          "size": 10.5927734375,
          "content": "                              Apache License\n                        Version 2.0, January 2004\n                     http://www.apache.org/licenses/\n\nTERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n1. Definitions.\n\n   \"License\" shall mean the terms and conditions for use, reproduction,\n   and distribution as defined by Sections 1 through 9 of this document.\n\n   \"Licensor\" shall mean the copyright owner or entity authorized by\n   the copyright owner that is granting the License.\n\n   \"Legal Entity\" shall mean the union of the acting entity and all\n   other entities that control, are controlled by, or are under common\n   control with that entity. For the purposes of this definition,\n   \"control\" means (i) the power, direct or indirect, to cause the\n   direction or management of such entity, whether by contract or\n   otherwise, or (ii) ownership of fifty percent (50%) or more of the\n   outstanding shares, or (iii) beneficial ownership of such entity.\n\n   \"You\" (or \"Your\") shall mean an individual or Legal Entity\n   exercising permissions granted by this License.\n\n   \"Source\" form shall mean the preferred form for making modifications,\n   including but not limited to software source code, documentation\n   source, and configuration files.\n\n   \"Object\" form shall mean any form resulting from mechanical\n   transformation or translation of a Source form, including but\n   not limited to compiled object code, generated documentation,\n   and conversions to other media types.\n\n   \"Work\" shall mean the work of authorship, whether in Source or\n   Object form, made available under the License, as indicated by a\n   copyright notice that is included in or attached to the work\n   (an example is provided in the Appendix below).\n\n   \"Derivative Works\" shall mean any work, whether in Source or Object\n   form, that is based on (or derived from) the Work and for which the\n   editorial revisions, annotations, elaborations, or other modifications\n   represent, as a whole, an original work of authorship. For the purposes\n   of this License, Derivative Works shall not include works that remain\n   separable from, or merely link (or bind by name) to the interfaces of,\n   the Work and Derivative Works thereof.\n\n   \"Contribution\" shall mean any work of authorship, including\n   the original version of the Work and any modifications or additions\n   to that Work or Derivative Works thereof, that is intentionally\n   submitted to Licensor for inclusion in the Work by the copyright owner\n   or by an individual or Legal Entity authorized to submit on behalf of\n   the copyright owner. For the purposes of this definition, \"submitted\"\n   means any form of electronic, verbal, or written communication sent\n   to the Licensor or its representatives, including but not limited to\n   communication on electronic mailing lists, source code control systems,\n   and issue tracking systems that are managed by, or on behalf of, the\n   Licensor for the purpose of discussing and improving the Work, but\n   excluding communication that is conspicuously marked or otherwise\n   designated in writing by the copyright owner as \"Not a Contribution.\"\n\n   \"Contributor\" shall mean Licensor and any individual or Legal Entity\n   on behalf of whom a Contribution has been received by Licensor and\n   subsequently incorporated within the Work.\n\n2. Grant of Copyright License. Subject to the terms and conditions of\n   this License, each Contributor hereby grants to You a perpetual,\n   worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n   copyright license to reproduce, prepare Derivative Works of,\n   publicly display, publicly perform, sublicense, and distribute the\n   Work and such Derivative Works in Source or Object form.\n\n3. Grant of Patent License. Subject to the terms and conditions of\n   this License, each Contributor hereby grants to You a perpetual,\n   worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n   (except as stated in this section) patent license to make, have made,\n   use, offer to sell, sell, import, and otherwise transfer the Work,\n   where such license applies only to those patent claims licensable\n   by such Contributor that are necessarily infringed by their\n   Contribution(s) alone or by combination of their Contribution(s)\n   with the Work to which such Contribution(s) was submitted. If You\n   institute patent litigation against any entity (including a\n   cross-claim or counterclaim in a lawsuit) alleging that the Work\n   or a Contribution incorporated within the Work constitutes direct\n   or contributory patent infringement, then any patent licenses\n   granted to You under this License for that Work shall terminate\n   as of the date such litigation is filed.\n\n4. Redistribution. You may reproduce and distribute copies of the\n   Work or Derivative Works thereof in any medium, with or without\n   modifications, and in Source or Object form, provided that You\n   meet the following conditions:\n\n   (a) You must give any other recipients of the Work or\n       Derivative Works a copy of this License; and\n\n   (b) You must cause any modified files to carry prominent notices\n       stating that You changed the files; and\n\n   (c) You must retain, in the Source form of any Derivative Works\n       that You distribute, all copyright, patent, trademark, and\n       attribution notices from the Source form of the Work,\n       excluding those notices that do not pertain to any part of\n       the Derivative Works; and\n\n   (d) If the Work includes a \"NOTICE\" text file as part of its\n       distribution, then any Derivative Works that You distribute must\n       include a readable copy of the attribution notices contained\n       within such NOTICE file, excluding those notices that do not\n       pertain to any part of the Derivative Works, in at least one\n       of the following places: within a NOTICE text file distributed\n       as part of the Derivative Works; within the Source form or\n       documentation, if provided along with the Derivative Works; or,\n       within a display generated by the Derivative Works, if and\n       wherever such third-party notices normally appear. The contents\n       of the NOTICE file are for informational purposes only and\n       do not modify the License. You may add Your own attribution\n       notices within Derivative Works that You distribute, alongside\n       or as an addendum to the NOTICE text from the Work, provided\n       that such additional attribution notices cannot be construed\n       as modifying the License.\n\n   You may add Your own copyright statement to Your modifications and\n   may provide additional or different license terms and conditions\n   for use, reproduction, or distribution of Your modifications, or\n   for any such Derivative Works as a whole, provided Your use,\n   reproduction, and distribution of the Work otherwise complies with\n   the conditions stated in this License.\n\n5. Submission of Contributions. Unless You explicitly state otherwise,\n   any Contribution intentionally submitted for inclusion in the Work\n   by You to the Licensor shall be under the terms and conditions of\n   this License, without any additional terms or conditions.\n   Notwithstanding the above, nothing herein shall supersede or modify\n   the terms of any separate license agreement you may have executed\n   with Licensor regarding such Contributions.\n\n6. Trademarks. This License does not grant permission to use the trade\n   names, trademarks, service marks, or product names of the Licensor,\n   except as required for reasonable and customary use in describing the\n   origin of the Work and reproducing the content of the NOTICE file.\n\n7. Disclaimer of Warranty. Unless required by applicable law or\n   agreed to in writing, Licensor provides the Work (and each\n   Contributor provides its Contributions) on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n   implied, including, without limitation, any warranties or conditions\n   of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n   PARTICULAR PURPOSE. You are solely responsible for determining the\n   appropriateness of using or redistributing the Work and assume any\n   risks associated with Your exercise of permissions under this License.\n\n8. Limitation of Liability. In no event and under no legal theory,\n   whether in tort (including negligence), contract, or otherwise,\n   unless required by applicable law (such as deliberate and grossly\n   negligent acts) or agreed to in writing, shall any Contributor be\n   liable to You for damages, including any direct, indirect, special,\n   incidental, or consequential damages of any character arising as a\n   result of this License or out of the use or inability to use the\n   Work (including but not limited to damages for loss of goodwill,\n   work stoppage, computer failure or malfunction, or any and all\n   other commercial damages or losses), even if such Contributor\n   has been advised of the possibility of such damages.\n\n9. Accepting Warranty or Additional Liability. While redistributing\n   the Work or Derivative Works thereof, You may choose to offer,\n   and charge a fee for, acceptance of support, warranty, indemnity,\n   or other liability obligations and/or rights consistent with this\n   License. However, in accepting such obligations, You may act only\n   on Your own behalf and on Your sole responsibility, not on behalf\n   of any other Contributor, and only if You agree to indemnify,\n   defend, and hold each Contributor harmless for any liability\n   incurred by, or claims asserted against, such Contributor by reason\n   of your accepting any such warranty or additional liability.\n\nEND OF TERMS AND CONDITIONS\n\nAPPENDIX: How to apply the Apache License to your work.\n\n   To apply the Apache License to your work, attach the following\n   boilerplate notice, with the fields enclosed by brackets \"[]\"\n   replaced with your own identifying information. (Don't include\n   the brackets!)  The text should be enclosed in the appropriate\n   comment syntax for the file format. We also recommend that a\n   file or class name and description of purpose be included on the\n   same \"printed page\" as the copyright notice for easier\n   identification within third-party archives.\n\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n\thttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n"
        },
        {
          "name": "LICENSE-MIT",
          "type": "blob",
          "size": 0.9990234375,
          "content": "Permission is hereby granted, free of charge, to any\nperson obtaining a copy of this software and associated\ndocumentation files (the \"Software\"), to deal in the\nSoftware without restriction, including without\nlimitation the rights to use, copy, modify, merge,\npublish, distribute, sublicense, and/or sell copies of\nthe Software, and to permit persons to whom the Software\nis furnished to do so, subject to the following\nconditions:\n\nThe above copyright notice and this permission notice\nshall be included in all copies or substantial portions\nof the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\nANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\nTO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\nPARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT\nSHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\nCLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR\nIN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\nDEALINGS IN THE SOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 10.90625,
          "content": "![tract-logo](assets/tract-logo/PNG/tract-horizontal-blue.png)\n\n![Rust](https://img.shields.io/badge/rust-%23000000.svg?style=for-the-badge&logo=rust&logoColor=white)\n![rustc >= 1.75.0](https://img.shields.io/badge/rustc-%3E%3D1.75.0-brightgreen)\n![MIT/Apache 2](https://img.shields.io/crates/l/tract)\n[![Native Linux test status](https://github.com/snipsco/tract/workflows/Native%20Linux/badge.svg)](https://github.com/snipsco/tract/actions)\n[![Embedded targets status](https://github.com/snipsco/tract/workflows/Embedded%20targets/badge.svg)](https://github.com/snipsco/tract/actions)\n[![Doc](https://docs.rs/tract-core/badge.svg)](https://docs.rs/tract-core)\n\n[![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)](https://pypi.org/project/tract/)\n\n\nSonos' Neural Network inference engine.\n\n_This project used to be called tfdeploy, or Tensorflow-deploy-rust._\n\n## What ?\n\n`tract` is a Neural Network inference toolkit. It can read ONNX or NNEF, optimize them and run them.\n\n## Quick start, examples\n\n* [MobileNet v2 with ONNX](examples/onnx-mobilenet-v2)\n* [BERT example with ONNX](examples/pytorch-albert-v2)\n* [MobileNet v2 with TensorFlow](examples/tensorflow-mobilenet-v2)\n* [From Keras and TensorFlow 2 to tract](examples/keras-tract-tf2)\n* [ResNet with PyTorch](examples/pytorch-resnet)\n\nThere is also [some technical documentation](doc/) and [blog](https://tech-blog.sonos.com/posts/optimising-a-neural-network-for-inference/) posts.\n\n## Tract in the landscape\n\n### ONNX\n\nAs of today, `tract` passes successfully about 85% of ONNX backends\ntests. All \"real life\" integration tests in ONNX test suite are passing: \nbvlc_alexnet, densenet121, inception_v1, inception_v2, resnet50, shufflenet,\nsqueezenet, vgg19, zfnet512.\n\nNotable missing parts are operators dealing with Tensor Sequences and Optional Tensors : tract /really/ wants to flow Tensors and nothing else.\nThis is structural. Changing it would be pretty difficult, and it's unclear whether it can be done without impairing performance or maintainability.\nWe are not convinced these features have shown their interest in the wild yet, so we prefer to leave them aside.\n\nOther dark corners are specific operators like \"Resize\" which fit perfectly in the framework but need a complex internal logic that is far\nfrom our core business. In these cases, we are happy to accept contributions and to help. \n\nThe following operators are implemented and tested.\n\nAbs, Acos, Acosh, Add, And, ArgMax, ArgMin, ArrayFeatureExtractor, Asin, Asinh, Atan, Atanh, AveragePool, BatchNormalization, BitShift, BitwiseAnd, BitwiseNot, BitwiseOr, BitwiseXor, BlackmanWindow, Cast, CastLike, CategoryMapper, Ceil, Clip, Compress, Concat, Constant, ConstantLike, ConstantOfShape, Conv, ConvInteger, ConvTranspose, Cos, Cosh, CumSum, DFT, DepthToSpace, DequantizeLinear, Div, Dropout, DynamicQuantizeLinear, Einsum, Elu, Equal, Erf, Exp, Expand, EyeLike, Flatten, Floor, GRU, Gather, GatherElements, GatherND, Gemm, GlobalAveragePool, GlobalLpPool, GlobalMaxPool, Greater, GreaterOrEqual, HammingWindow, HannWindow, HardSigmoid, Hardmax, Identity, If, InstanceNormalization, IsInf, IsNaN, LRN, LSTM, LeakyRelu, Less, LessOrEqual, Log, LogSoftmax, MatMul, MatMulInteger, Max, MaxPool, Mean, MelWeightMatrix, Min, Mod, Mul, Multinomial, Neg, NonMaxSuppression, NonZero, Not, OneHot, Or, PRelu, Pad, ParametricSoftplus, Pow, QLinearConv, QLinearMatMul, QuantizeLinear, RNN, RandomNormal, RandomNormalLike, RandomUniform, RandomUniformLike, Range, Reciprocal, ReduceL1, ReduceL2, ReduceLogSum, ReduceLogSumExp, ReduceMax, ReduceMean, ReduceMin, ReduceProd, ReduceSum, ReduceSumSquare, Relu, Reshape, Resize, Round, Rsqrt, STFT, ScaledTanh, Scan, Scatter, ScatterElements, ScatterND, Selu, Shape, Shrink, Sigmoid, Sign, Sin, Sinh, Size, Slice, Softmax, Softplus, Softsign, SpaceToDepth, Split, Sqrt, Squeeze, Sub, Sum, Tan, Tanh, ThresholdedRelu, Tile, Transpose, TreeEnsembleClassifier, Unsqueeze, Where, Xor\n\nWe test these operators against from ONNX 1.4.1 (operator set 9), up to ONNX 1.13.0 (operator set 18).\n\nWe are using ONNX test suite, but it does not cover everything.\nWe also deliberately ignore some tests, or restricting their scope depending on what we feel is realistic.\nSometimes these decisions are just wrong, and sometimes they become wrong as time goes by and the fields moves in unexpected directions.\nSo if you are puzzled by an ONNX model that does not work in tract, we are happy to take a look.\n\n### NNEF\n\nLong story short, TensorFlow and ONNX formats are good for designing and\ntraining networks. They need to move fast to follow the research field, tend to\nintegrate new features and operators greedily. They also exhibit a high level\nof expressivity to facilitate network design.\n\nOn the other hand, only a subset of operators and network features actually\nreach production, so systems running production network do not have to deal\nwith so many operators. Furthermore, some information required for training can\nbe stripped from the network before going to production for prediction.\n\nNNEF tries to bridge the gap between training frameworks and inference by\nproposing a format dedicated to production and prediction.\n\nTract supports NNEF:\n\n* tract_nnef can load and execute NNEF networks\n* tract supports most of the NNEF specification, the most notable exception\n    being the ROI operators\n* tract introduces tract-OPL, a series of NNEF extensions to support other\n    operators (or extend some operators semantics) in order to represent the\n    full range of tract-core neural network support: any network understood by\n    tract should be serializable to tract-OPL. This is a work in progress.\n* tract command line can translate networks from TensorFlow or ONNX to NNEF/OPL.\n\n### tract-opl version compatibility\n\nA remainder: NNEF is not expressive enough to represent all ONNX. tract-OPL extends\nNNEF using proprietary to support what is missing. Notable extensions are pulse\noperators, recurring operators (as Scan) and symbolic extensions.\n\nThere is no strict check in place here, so... implementation is not bullet proof.\n* NNEF part aims at being very stable. It is strongly constrained with compatibility\nwith NNEF specification.\n* tract-opl is a bit more in flux. Nevertheless we try to maintain the following\ngolden rule:\n\n     `models serialized with tract 0.x.y should work with tract 0.x.z where z >= y`\n\n* in practice, breaking changes have been relatively rare so far. Most models are\nforward and retro compatible from when tract has acquired NNEF support.\n\nNotable breakage occurred:\n* 0.16.3 (forward compatible) on Scan operator\n* 0.17.0 for binary decision tree classifier\n\nStarting with `0.17.0`, a model property is injected in tract-opl files (`tract_nnef_ser_version`)\nto tag which version of tract generated the file. As most models will remain compatible,\ntract will not do any version check. It is up to the application developer to do so.\n\nA softer version tag exists as `tract_nnef_format_version`. pre-0.17.0 version set it to\n`alpha1`, post-0.17.0 set it `beta1`. Don't put too much emphasis into the \"alpha-ness\" naming \nof versions here.\n\n### Note: support for TensorFlow 1.x\n\nEven if `tract` is very far from supporting any arbitrary model, it can run\nGoogle Inception v3 and Snips wake word models. Missing operators are relatively \neasy to add. The lack of easy to reuse test suite, and the wide diversity of \noperators in Tensorflow make it difficult to target a full support.\n\nThe following operators are implemented and tested:\n\nAbs, Add, AddN, AddV2, Assign, AvgPool, BatchToSpaceND, BiasAdd, BlockLSTM, Cast, Ceil, ConcatV2, Const, Conv2D, DepthwiseConv2dNative, Div, Enter, Equal, Exit, ExpandDims, FakeQuantWithMinMaxVars, Fill, FloorMod, FusedBatchNorm, GatherNd, GatherV2, Greater, GreaterEqual, Identity, Less, LessEqual, Log, LogicalAnd, LogicalOr, LoopCond, MatMul, Max, MaxPool, Maximum, Mean, Merge, Min, Minimum, Mul, Neg, NoOp, Pack, Pad, Placeholder, Pow, Prod, RandomUniform, RandomUniformInt, Range, RealDiv, Relu, Relu6, Reshape, Rsqrt, Shape, Sigmoid, Slice, Softmax, SpaceToBatchND, Squeeze, StridedSlice, Sub, Sum, Switch, Tanh, Tile, Transpose, VariableV2\n\nAdditionally, the complexity of TensorFlow 2 make it very unlikely that a direct\nsupport will ever exist in tract. But many TensorFlow 2 models can be\nconverted to ONNX and then loaded in tract.\n\n## Example of supported networks\n\nThese models among others, are used to track tract performance evolution as\npart of the Continuous Integration jobs. See [.travis/README.md](readme) and \n[.travis/bundle-entrypoint.sh](.travis/bundle-entrypoint.sh) for more\ninformation.\n\n### Keyword spotting on Arm Cortex-M Microcontrollers\n\nhttps://github.com/ARM-software/ML-KWS-for-MCU\n\nARM demonstrated the capabilities of the Cortex-M family by providing\ntutorials and pre-trained models for keyword spotting. While the exercise\nis ultimately meant for micro-controllers, `tract` can run the intermediate\nTensorFlow models.\n\nFor instance, on a Raspberry Pi Zero, the \"CNN M\" model runs in about 70\nmicro-seconds, and 11 micro-seconds on a Raspberry Pi 3.\n\n### Snips wake word models\n\nhttps://arxiv.org/abs/1811.07684\n\nSnips uses `tract` to run the wake word detectors. While earlier models were\nclass-based and did not require any special treatment, `tract` pulsing\ncapabilities made it possible to run WaveNet models efficiently enough for a\nRaspberry Pi Zero.\n\n### Inception v3\n\n|      Device         |      Family    |  TensorFlow-lite  |  tract  |\n|---------------------|----------------|-------------------|---------|\n|  Raspberry Pi Zero  |    Armv6 VFP   |        113s       |   39s   |\n|  Raspberry Pi 2     |    Armv7 NEON  |         25s       |    7s   |\n|  Raspberry Pi 3     |  aarch32 NEON  |          5s       |    5s   |\n\nNotes:\n\n * while the Raspberry Pi 3 is an Armv8 device, this bench is running\n     on Raspbian, an armv6 operating system, crippling the performance\n     of both benches\n * there exists other benches on the internet that show better\n     performance results for TensorFlow (not -Lite) on the Pi 3.\n     They use all four cores of the device. Both TensorFlow-Lite and tract\n     here have been made to run on a single-core.\n\n# License\n\nNote: files in the `tensorflow/protos` directory are copied from the\n[TensorFlow](https://github.com/tensorflow/tensorflow) project and are not\ncovered by the following licence statement.\n\nNote: files in the `onnx/protos` directory are copied from the\n[ONNX](https://github.com/onnx/onnx) project and are not\ncovered by the following license statement.\n\n## Apache 2.0/MIT\n\nAll original work licensed under either of\n * Apache License, Version 2.0 ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)\n * MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\nat your option.\n\n## Contribution\n\nUnless you explicitly state otherwise, any Contribution intentionally submitted\nfor inclusion in the work by you, as defined in the Apache-2.0 license, shall\nbe dual licensed as above, without any additional terms or conditions.\n"
        },
        {
          "name": "api",
          "type": "tree",
          "content": null
        },
        {
          "name": "assets",
          "type": "tree",
          "content": null
        },
        {
          "name": "ci",
          "type": "tree",
          "content": null
        },
        {
          "name": "cli",
          "type": "tree",
          "content": null
        },
        {
          "name": "core",
          "type": "tree",
          "content": null
        },
        {
          "name": "data",
          "type": "tree",
          "content": null
        },
        {
          "name": "deny.toml",
          "type": "blob",
          "size": 1.40234375,
          "content": "\n# add whatever else we support.\n[graph]\ntargets = [\n    { triple = \"x86_64-unknown-linux-gnu\" },\n    { triple = \"x86_64-unknown-linux-musl\" },\n    { triple = \"x86_64-apple-darwin\" },\n    { triple = \"x86_64-pc-windows-msvc\" },\n    { triple = \"aarch64-linux-android\" },\n    { triple = \"aarch64-unknown-linux-gnu\" },\n    { triple = \"aarch64-unknown-linux-musl\" },\n    { triple = \"aarch64-apple-ios\" },\n    { triple = \"aarch64-apple-darwin\" },\n    { triple = \"armv7-unknown-linux-gnueabihf\" },\n    { triple = \"armv7-unknown-linux-musleabi\" },\n    { triple = \"arm-unknown-linux-gnueabihf\" },\n    { triple = \"wasm32-unknown-unknown\" },\n]\n\n[advisories]\ngit-fetch-with-cli = true\nyanked = \"deny\"\nignore = [\n]\n\n[bans]\nmultiple-versions = \"deny\"\nwildcards = \"allow\"\ndeny = [\n    # List crates we don't want in our dependency tree here.\n]\n\n# Skip some multiple-versions checks, until they can be fixed.\nskip = [\n    { name = \"itertools\", version=\"<=0.12.1\" },\n    { name = \"regex-syntax\", version=\"<8\" },\n    { name = \"syn\", version=\"<2\" },\n    { name = \"windows-sys\", version=\"<0.59\" },\n]\n\n[sources]\n# trusted git sources.\nallow-git = [\n]\n\n[licenses]\nallow = [\n    \"Apache-2.0\",                     # https://tldrlegal.com/license/apache-license-2.0-(apache-2.0)\n    \"MIT\",                            # https://tldrlegal.com/license/mit-license\n    \"Unicode-3.0\"                     # https://spdx.org/licenses/Unicode-3.0.html\n]\n\nclarify = [\n]\n"
        },
        {
          "name": "doc",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "extra",
          "type": "tree",
          "content": null
        },
        {
          "name": "harness",
          "type": "tree",
          "content": null
        },
        {
          "name": "hir",
          "type": "tree",
          "content": null
        },
        {
          "name": "libcli",
          "type": "tree",
          "content": null
        },
        {
          "name": "linalg",
          "type": "tree",
          "content": null
        },
        {
          "name": "metal",
          "type": "tree",
          "content": null
        },
        {
          "name": "nnef",
          "type": "tree",
          "content": null
        },
        {
          "name": "onnx-opl",
          "type": "tree",
          "content": null
        },
        {
          "name": "onnx",
          "type": "tree",
          "content": null
        },
        {
          "name": "post-release.sh",
          "type": "blob",
          "size": 0.4677734375,
          "content": "#!/bin/sh\n\nVERSION=$1\n. ./.all_crates.sh\n\nif [ `uname` = \"Darwin\" ]\nthen\n    SED=gsed\nelse\n    SED=sed\nfi\n\nif [ -z \"$VERSION\" ]\nthen\n    echo \"Usage: $0 <version>\" \n    exit 1\nfi\n\nfor path in $ALL_CRATES_PATH\ndo\n    crate=$(tomato get package.name $path/Cargo.toml)\n    echo $crate\n    tomato set package.version $VERSION $path/Cargo.toml > /dev/null\n    tomato set workspace.dependencies.$crate.version $VERSION Cargo.toml\ndone\n\ngit commit . -m \"post-release $VERSION\"\ngit push\n"
        },
        {
          "name": "pulse-opl",
          "type": "tree",
          "content": null
        },
        {
          "name": "pulse",
          "type": "tree",
          "content": null
        },
        {
          "name": "release.sh",
          "type": "blob",
          "size": 0.8330078125,
          "content": "#!/bin/bash\n\nset -e\n\ngit pull # make sure we are in sync\ngit push\n\nwhich tomato || cargo install tomato-toml\n\nCRATE_PATH=$1\nVERSION=$2\n. ./.all_crates.sh\n\nif [ -z \"$VERSION\" ]\nthen\n    echo \"Usage: $0 <crate> <version>\" \n    echo crates order is: $ALL_CRATES_PATH\n    exit 1\nfi\n\nset -ex\n\nif [ \"$CRATE_PATH\" = \"all\" ]\nthen\n    for c in $ALL_CRATES_PATH\n    do\n        $0 $c $VERSION\n    done\n    exit 0\nfi\n\ncrate=$(tomato get package.name $CRATE_PATH/Cargo.toml)\ntomato set package.version $VERSION $CRATE_PATH/Cargo.toml\nif [ \"$crate\" = \"tract-metal\" ]\nthen\n    cargo publish -q --allow-dirty --no-verify -p $crate \nelse\n    cargo publish -q --allow-dirty -p $crate\nfi\n\n#./.change_crate_dep.sh $crate $VERSION\n#\n#cargo update\n\nif [ \"$CRATE_PATH\" = \"cli\" ]\nthen\n    git commit -m \"release $VERSION\" .\n    git tag -f v\"$VERSION\"\n    git push -f --tags\nfi\n"
        },
        {
          "name": "rustfmt.toml",
          "type": "blob",
          "size": 0.1005859375,
          "content": "use_small_heuristics = \"Max\"\nuse_field_init_shorthand = true\nuse_try_shorthand = true\nedition = \"2018\"\n"
        },
        {
          "name": "tensorflow",
          "type": "tree",
          "content": null
        },
        {
          "name": "test-rt",
          "type": "tree",
          "content": null
        },
        {
          "name": "tflite",
          "type": "tree",
          "content": null
        },
        {
          "name": "yank.sh",
          "type": "blob",
          "size": 0.3046875,
          "content": "#!/bin/sh\n\nVERSION=$1\n. ./.all_crates.sh\n\nif [ `uname` = \"Darwin\" ]\nthen\n    SED=gsed\nelse\n    SED=sed\nfi\n\nif [ -z \"$VERSION\" ]\nthen\n    echo \"Usage: $0 <version>\" \n    exit 1\nfi\n\nfor path in $ALL_CRATES_PATH\ndo\n    crate=$(tomato get package.name $path/Cargo.toml)\n    cargo yank --version $VERSION $crate\ndone\n"
        }
      ]
    }
  ]
}