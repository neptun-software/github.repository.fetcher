{
  "metadata": {
    "timestamp": 1736709155155,
    "page": 370,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjM3MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "uber/piranha",
      "stars": 2305,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.576171875,
          "content": "java/.gradle\njava/build/\njava/*/build/\n.idea\n.DS_STORE\npiranha.iml\nobjc/process\nobjc/piranha-objc\nswift/artifact\nswift/Piranha.xcodeproj\nswift/Package.resolved\n**/*.iml\npolyglot/piranha/target\npolyglot/piranha/Cargo.lock\npolyglot/piranha/.idea\n.history\n.vscode\n**/*.log\npolyglot/piranha/demo/piranha\n**/.env/**\n**.pyc\ntarget\nCargo.lock\ntmp_test*\nenv/\n\n\n# Dependencies\n**/node_modules\n\n# Production\n**/build\n\n# Generated files\n.docusaurus\n.cache-loader\n\n# Misc\n.DS_Store\n.env.local\n.env.development.local\n.env.test.local\n.env.production.local\n\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 1.7490234375,
          "content": "repos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.4.0\n    hooks:\n      - id: check-byte-order-marker\n      - id: check-case-conflict\n      - id: check-merge-conflict\n      - id: check-yaml\n        # excluding as inline json fails check-yaml\n        exclude: ^.github/workflows/polyglot_release.yml$\n      - id: check-toml\n        files: src/|test-resources/|demo/\n      - id: end-of-file-fixer\n        files: src/|test-resources/|demo/\n      - id: mixed-line-ending\n        files: src/|test-resources/|demo/\n  - repo: local\n    hooks:\n      - id: toml-fmt\n        name: toml-fmt\n        language: system\n        entry: taplo fmt\n      - id: cargo-fmt\n        name: cargo fmt\n        language: system\n        entry: bash -c 'cargo fmt'\n        types: [rust]\n      - id: cargo-clippy\n        name: cargo clippy\n        language: system\n        entry: bash -c 'cargo clippy --fix --allow-staged'\n        types: [rust]\n\n  - repo: https://github.com/Lucas-C/pre-commit-hooks\n    rev: v1.3.1\n    hooks:\n      - id: forbid-tabs\n        files: src/\n      - id: remove-tabs\n        files: src/\n      - id: insert-license\n        files: \\.rs$\n        args:\n          - --license-filepath\n          - license_header.txt\n          - --comment-style\n          - /*| | */\n      - id: insert-license\n        files: '^piranha_playground/.*\\.py$'\n        args:\n          - --license-filepath\n          - license_header.txt\n          - --comment-style\n          - \"#\"\n  - repo: https://github.com/pre-commit/mirrors-autopep8\n    rev: \"v2.0.2\"\n    hooks:\n      - id: autopep8\n        files: demo/\n        exclude: only_lists.py\n  - repo: https://github.com/pre-commit/mirrors-prettier\n    rev: \"v3.0.2\"\n    hooks:\n      - id: prettier\n        files: ^experimental/piranha_playground/\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 4.5419921875,
          "content": "Version 0.3.27\n-------------\n\n* Improve whitespace handling\n* Support ctrl+c\n* Improve logging\n* Change language names\n\nVersion 0.3.26\n-------------\n\n* Support for YAML structural find/replace\n\nVersion 0.3.25\n-------------\n\n* Better concrete syntax semantics (https://github.com/uber/piranha/pull/671)\n* More Python types in _polyglot_piranha.pyi_ (https://github.com/uber/piranha/pull/675 ; https://github.com/uber/piranha/pull/674)\n* Fixing bug with `.kt` extension (https://github.com/uber/piranha/pull/676)\n* Improvements and fixes to Spark migration rules (https://github.com/uber/piranha/pull/658)\n* Ruby support (https://github.com/uber/piranha/pull/649 ; https://github.com/uber/piranha/pull/670)\n* Disabled graph validation by default (https://github.com/uber/piranha/pull/672)\n\nVersion 0.3.24\n-------------\n\n* Maturin: 1.4.0 <= version < 2.0\n* Fix python wheel not working on specific Linux versions.\n\nVersion 0.3.23\n-------------\nThis version may fail to `pip install polyglot-piranha` in some Linux versions.\n\n* Python wheel with no duplicate entries in generated METADATA\n* RELEASING.md: updated instructions\n* Starter kit for Zap Transformation plugin\n\nVersion 0.3.22\n-------------\n* Improved rule syntax. Now :[x] pattern is supported for references too.\n\nVersion 0.3.21\n-------------\n* Improved Swift cleanup\n\nVersion 0.3.20\n-------------\n* Bug fix: concrete syntax matching- Handle trailing commas and comments\n* Feature: Support for `ParentIterative` edge\n\nVersion 0.3.19\n-------------\n* Fix swift cleanup of statements after return\n\nVersion 0.3.18\n-------------\n* Improve go feature flag cleanup\n* Fix bug related to leading/trailing comma\n* Breaking change: the Piranha argument api now accepts a list of paths to source code (paths_to_codebase), as opposed to accepting just `path_to_codebase`\n\nVersion 0.3.17\n-------------\n* Add support for scala\n\nVersion 0.3.16\n-------------\n* Added concrete syntax as matching language\n\nVersion 0.3.15\n-------------\n* Bug-fix in query validation\n\nVersion 0.3.14\n-------------\n* Bug-fix in graph validation\n\nVersion 0.3.13\n-------------\n* Introduce graph validation\n* Improved swift syntax support\n\nVersion 0.3.12\n-------------\n* Capture interface as \"Class\" scope in Java\n\nVersion 0.3.11\n-------------\n* Refactor to support other matching languages\n* Introduce regex syntax for rules\n\nVersion 0.3.10\n-------------\n* Add support for replace node index\n* Bug fix for iOS cleanup\n\nVersion 0.3.9\n-------------\n* Rule graph validation #493\n* Bug fix #497 #499\n* Kotlin dependency update\n\nVersion 0.3.8\n-------------\n* Bug Fix related to code snippet mode #489\n* Added support for iOS string resource file format #490\n\nVersion 0.3.7\n-------------\n* Support `enabled, err := foobar(), nil` scenario\n\nVersion 0.3.6\n-------------\n* Support richer constraints with `not_enclosing_node`\n* Added checks to make sure filter arguments are consistent\n\nVersion 0.3.5\n-------------\n* Support filters without `enclosing_node` (#482)\n\nVersion 0.3.4\n-------------\n* Support richer constraints\n* ability to `include` or `exclude` particular paths\n* Support variable / field inlining in Swift\n* More optimized if-statement cleanups\n* Swift cleanup bug fixes\n\nVersion 0.3.3\n-------------\n* Added equality simplification for Java\n* Add support for thrift\n* Ternary operator simplification for Swift\n\nVersion 0.3.2\n-------------\n* Improved the Python interface for constructing PiranhaArguments\n\nVersion 0.3.1\n-------------\n* Improve handling of leading (and trailing) commas and comments\n* Fix boolean simplification rules\n* Add Enum scope for Java\n* Add option to transform/analyze partially parsable code (`--alow-dirty-tree`)\n* Bug fixes\n\nVersion 0.3.0\n-------------\n* Introduce Feature flag cleanup for Go and Swift\n* Introduce a Python / Rust API for defining rules, edges and the arguments\n* Introduce code snippet mode\n* Improvements for the command line interface\n* Bug fixes\n\nVersion 0.2.0\n-------------\n* Fixed bug related to __build-in cleanup rules__ not being packaged [#247]\n* Improve demos and documentation [#242] [#243]\n* Add Python Structural/Replace support [#248]\n* Improve logging and expose logs via pyo3 [#246]\n* Fix *delete trailing comma* bug [#251]\n* Add `File` Scope for Kotlin [#249]\n* Added GitHub workflow to make release\n\nVersion 0.2.1\n-------------\n* Fix disjunction rule [#269]\n* Handle cleanups for feature flags within constructors [#268]\n* Add `dry_run` as a command line argument [#263]\n* Support for structural match/replace (with chaining) for Go [#256]\n* Support for structural match/replace (with chaining) for TS / TSX [#260]\n* Improve documentation [#261, #259, #258, #257]\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.1494140625,
          "content": "\n# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment include:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at mobile-open-source@uber.com. The project team will review and investigate all complaints, and will respond in a way that it deems appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4, available at [http://contributor-covenant.org/version/1/4][version]\n\n[homepage]: http://contributor-covenant.org\n[version]: http://contributor-covenant.org/version/1/4/\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 1.625,
          "content": "\nContributing to Piranha\n=======================\n\nUber welcomes contributions of all kinds and sizes. This includes everything from from simple bug reports to large features.\n\nWorkflow\n--------\n\nWe love GitHub issues!\n\nFor small feature requests, an issue first proposing it for discussion or demo implementation in a PR suffice.\n\nFor big features, please open an issue so that we can agree on the direction, and hopefully avoid investing a lot of time on a feature that might need reworking.\n\nSmall pull requests for things like typos, bug fixes, etc are always welcome.\n\nDOs and DON'Ts\n--------------\n\n* DO format your code using rustftmt (or just make sure to install the pre-commit hook). \n* DO include tests when adding new features. When fixing bugs, start with adding a test that highlights how the current behavior is broken.\n* DO keep the discussions focused. When a new or related topic comes up it's often better to create new issue than to side track the discussion.\n\n* DON'T submit PRs that alter licensing related files or headers. If you believe there's a problem with them, file an issue and we'll be happy to discuss it.\n\nGuiding Principles\n------------------\n\n* We allow anyone to participate in our projects. Tasks can be carried out by anyone that demonstrates the capability to complete them\n* Always be respectful of one another. Assume the best in others and act with empathy at all times\n* Collaborate closely with individuals maintaining the project or experienced users. Getting ideas out in the open and seeing a proposal before it's a pull request helps reduce redundancy and ensures we're all connected to the decision making process\n\n"
        },
        {
          "name": "Cargo.toml",
          "type": "blob",
          "size": 2.1044921875,
          "content": "[package]\nauthors = [\"Uber Technologies Inc.\"]\nname = \"piranha\"\ndescription = \"Polyglot Piranha is a library for performing structural find and replace with deep cleanup.\"\nversion = \"0.3.27\"\nedition = \"2021\"\ninclude = [\"pyproject.toml\", \"src/\"]\nexclude = [\"legacy\"]\nlicense-file = \"LICENSE\"\ncategories = [\n  \"structural find-replace\",\n  \"find-replace\",\n  \"structural seearch\",\n  \"structural search and replace\",\n  \"tree-sitter\",\n]\n\n[[bin]]\nname = \"polyglot_piranha\"\npath = \"src/main.rs\"\n\n[lib]\nname = \"polyglot_piranha\"\npath = \"src/lib.rs\"\ncrate-type = [\"cdylib\", \"rlib\"]\ndoctest = false\n\n[build-dependencies]\ncc = \"1.0.73\"\n\n[dependencies]\ntree-sitter = \"0.20.6\"\ntree-sitter-traversal = \"0.1.2\"\njson = \"0.12.4\"\ntoml = \"0.8.8\"\nserde = \"1.0.136\"\nserde_derive = \"1.0.136\"\ncolored = \"2.0.0\"\nitertools = \"0.12.0\"\nregex = \"1.5.5\"\njwalk = \"0.8.1\"\nclap = { version = \"4.0.3\", features = [\"derive\"] }\nlog = \"0.4.16\"\nenv_logger = \"0.10.0\"\ntempdir = \"0.3\"\nserde_json = \"1.0.82\"\nctrlc = \"3.4\"\n\n# TODO: Update if we upgrade tree-sitter to >=0.21\ntree-sitter-kotlin = \"=0.3.5\"\ntree-sitter-java = \"0.20.2\"\n# TODO: Update after: https://github.com/alex-pinkus/tree-sitter-swift/issues/278 resolves\ntree-sitter-swift = { git = \"https://github.com/satyam1749/tree-sitter-swift.git\", rev = \"08a28993599f1968bc81631a89690503e1db7704\" }\ntree-sitter-python = \"0.20.2\"\ntree-sitter-ruby = \"0.20.1\"\ntree-sitter-typescript = \"0.20.1\"\n# TODO: Update after https://github.com/tree-sitter/tree-sitter-go/pull/103 lands\ntree-sitter-go = { git = \"https://github.com/uber/tree-sitter-go.git\", rev = \"f8cffd0af7baaf7bf6062e403efe7c0d06319c41\" }\ntree-sitter-thrift = \"0.5.0\"\ntree-sitter-strings = { git = \"https://github.com/uber/tree-sitter-strings.git\" }\ntree-sitter-query = \"0.1.0\"\ntree-sitter-scala = \"0.20.1\"\n# newer versions of \"tree-sitter-yaml\" require that we bump \"tree-sitter\" version\ntree-sitter-yaml = \"0.0.1\"\nderive_builder = \"0.12.0\"\ngetset = \"0.1.2\"\npyo3 = \"0.20.0\"\npyo3-log = \"0.9.0\"\nglob = \"0.3.1\"\nlazy_static = \"1.4.0\"\n\n[features]\nextension-module = [\"pyo3/extension-module\"]\ndefault = [\"extension-module\"]\n\n\n[dev-dependencies]\nassert_cmd = \"2.0.7\"\npredicates = \"3.0.2\"\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0927734375,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner].\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "NOTICE",
          "type": "blob",
          "size": 0.1435546875,
          "content": "[Piranha]\nCopyright (c) 2018 Uber Technologies, Inc.\n\nThis product includes software developed at \nUber Technologies, Inc. (http://www.uber.com/).\n"
        },
        {
          "name": "POLYGLOT_README.md",
          "type": "blob",
          "size": 30.4853515625,
          "content": "# Polyglot Piranha\n\nPolyglot Piranha is a flexible multilingual structural search/replace engine that allows users to apply chains of interdependent structural search/replace rules for deeper cleanups. Polyglot Piranha builds upon tree-sitter queries for expressing the structural search/replace rules.\n\n__This repository contains the Polyglot Piranha framework and pre-built cleanup rules that can be leveraged for deleting code related to stale feature flags__.\n\n## Table of Contents\n- [Polyglot Piranha](#polyglot-piranha)\n  - [Table of Contents](#table-of-contents)\n  - [Overview](#overview)\n  - [When is Polyglot Piranha useful?](#when-is-polyglot-piranha-useful)\n  - [Using Polyglot Piranha](#using-polyglot-piranha)\n    - [:snake: Python API](#snake-python-api)\n    - [:computer: Command-line Interface](#computer-command-line-interface)\n    - [Languages supported](#languages-supported)\n  - [Piranha's DSL](#piranha-dsl)\n  - [Getting Started with demos](#getting-started-with-demos)\n  - [*Stale Feature Flag Cleanup* in depth](#stale-feature-flag-cleanup-in-depth)\n  - [Visualizing Graphs for Rules and Groups](#visualizing-graphs-for-rules-and-groups)\n  - [Piranha Arguments](#piranha-arguments)\n  - [Contributing](#contributing)\n\n\n\n## Overview\n<p style=\"text-align:center;\">\n<img src=\"images/piranha_architecture.svg\" width=\"800\" height=\"500\" alt=\"Polyglot Piranha Architecture\"/>\n</p>\n\nThis is the higher level architecture of Polyglot Piranha.\nAt its heart, Polyglot Piranha is a structural find/replacement (rewrite) engine and pre-build language specific cleanup rules like - like simplifying boolean expressions, simplifying `if-else` statements, deleting empty class, deleting files with no type declarations, inline local variables, and many more.\nA user provides :\n- A set (or, a graph) of structural find/replace rules\n- Path to the code base\n- [Arguments](#piranha-arguments) to modify Piranha's behavior (like deleting associated comments).\n\nWhen Piranha applies the set (or graph) of user defined rules, it triggers the __pre-built__ language specific cleanup rules to do a deep cleanup.\nBelow we can see an [automatically generated graph](#visualizing-graphs-for-rules-and-groups) for the Java pre-built cleanup rules.\n\n<p style=\"text-align:center;\">\n    <img src=\"images/java_prebuilt_rules.svg\" width=\"800\" height=\"500\" alt=\"Java pre-built cleanup rules\"/>\n</p>\n\n## When is Polyglot Piranha useful?\n\n<h5> Example 1 (Stale Feature Flag Cleanup) </h5>\n\nLet's take an example, where we know for a fact that the expression `exp.isTreated(\"SHOW_MENU\")` always returns `true` (i.e. the feature *Show Menu* is treated)\n```java\npublic String fooBar(boolean x) {\n    if(exp.isTreated(\"SHOW_MENU\")|| x){\n        String menu = getMenu();\n        return menu;\n    }\n    return \"\";\n}\n```\nTo cleanup this code with Piranha, a user would have to write *one* rule to update the expressions like `exp.isTreated(\"SHOW_MENU\")` to `true` and hook it to the pre-built boolean simplification rules. It would result in :\n```java\npublic String fooBar(boolean x) {\n    String menu = getMenu();\n    return menu;\n}\n```\nNote how, user only specified the seed rule to update the expression to true, and Piranha simplified the disjunction (`exp.isTreated(\"SHOW_MENU\")|| x` => `true`), then removed the stale if condition and finally deleted the unreachable return statement (`return \"\";`).\n\n<h5> Example 2 (Structural Find/Replace with built-in cleanup) </h5>\n\nLet's say a user writes a piranha rule to delete an unused enum case (let's say `LOW`). However, this enum case \"co-incidentally\" is the only enum case in this enum declaration.\n```java\nenum Level {\n  LOW,\n}\n```\nIf the user hooks up this *enum case deletion* rule to the pre-built rules, it would not only delete the enum case (`LOW`), but also the consequent empty enum declaration and also optionally delete the consequently empty compilation unit.\n\n\n<h5> Example 3 (Structural Find/Replace with custom cleanup) </h5>\n\nLet's take a canonical example of replacing `Arrays.asList` with `Collections.singletonList`, when possible.\nThis task involves two steps (i) Replacing the expression (ii) Adding the import statement for `Collections` if absent (Assuming *google java format* takes care of the unused imports :smile:).\nHowever, Piranha does not contain pre-built rules to add such a custom import statements.\n```java\nimport java.util.ArrayList;\nimport java.util.Arrays;\n+ import java.util.Collections;\nclass Character{\n    String name;\n    List<String> friends;\n    List<String> enemies;\n\n    Character(String name) {\n        this.name = name;\n        this.friends = new ArrayList<>();\n -         this.enemies = Arrays.asList(this.name);\n +         this.enemies = Collections.singletonList(this.name);\n    }\n}\n```\nFor such a scenario a developer could first write a seed rule for replacing the expression and then craft a custom \"cleanup\" rule (that would be triggered by the seed rule) to add the import statement if absent within the same file.\n\n*Note a user can also craft a set of rules that trigger no other rule, i.e. use piranha as a simple structural find/replace tool*\n\n*If you end up implementing a cleanup rule that could be useful for the community, feel free to make a PR to add it into the pre-built language specific rules*\n\n## Using Polyglot Piranha\n\nPolyglot Piranha can be used as a python library or as a command line tool.\n\n### :snake: Python API\n\n<h3> Installing the Python API </h3>\n\n`pip install polyglot-piranha`\n\nCurrently, we support one simple API (`execute_piranha`), a simple python wrapper around Polyglot Piranha's CLI. \nWe believe this makes it easy to incorporate Piranha in *\"pipelining\"*.\n\n<h4> <code>execute_piranha</code></h4>\n\n```python\nfrom polyglot_piranha import execute_piranha, PiranhaArguments\n\npiranha_arguments = PiranhaArguments(\n    path_to_codebase = \"...\",\n    path_to_configurations = \"...\",\n    language= \"java\",\n    substitutions = {},\n    dry_run = False, \n    cleanup_comments = True\n)\npiranha_summary = execute_piranha(piranha_arguments)\n```\nThe API `execute_piranha` accepts a `PiranhaArguments`\nAn object of PiranhaArguments can be instantiated with the following arguments:\n\n- (*required*) `path_to_codebase` (`str`): Path to source code folder\n- (*required*) `path_to_configuration` (`str`) : A directory containing files named `rules.toml` and `edges.toml`\n  * `rules.toml`: *piranha rules* expresses the specific AST patterns to match and __replacement patterns__ for these matches (in-place). These rules can also specify the pre-built language specific cleanups to trigger.\n  * `edges.toml` : expresses the flow between the rules\n- (*required*) `language` (`str`) : Target language (`java`, `py`, `kt`, `swift`, `py`, `ts` and `tsx`)\n- (*required*) `substitutions` (`dict`): Substitutions to instantiate the initial set of feature flag rules\n- (*optional*) `dry_run` (`bool`) : Disables in-place rewriting of code\n- (*optional*) `cleanup_comments` (`bool`) : Enables deletion of associated comments\n- (*optional*) `cleanup_comments_buffer` (`usize`): The number of lines to consider for cleaning up the comments\n- (*optional*) `number_of_ancestors_in_parent_scope` (`usize`): The number of ancestors considered when `PARENT` rules\n- (*optional*) `delete_file_if_empty` (`bool`): User option that determines whether an empty file will be deleted\n- (*optional*) `delete_consecutive_new_lines` (`bool`) : Replaces consecutive `\\n`s  with a single `\\n`\n\n<h5> Returns </h5>\n\n`[Piranha_Output]` : a [`PiranhaOutputSummary`](/src/models/piranha_output.rs) for each file touched or analyzed by Piranha. It contains useful information like, matches found (for *match-only* rules), rewrites performed, and content of the file after the rewrite. The content is particularly useful when `dry_run` is passed as `true`.\n\n### :computer: Command-line Interface\n\n\nGet platform-specific binary from [releases](https://github.com/uber/piranha/releases) or build it from source following the below steps:\n\n* Install [Rust](https://www.rust-lang.org/tools/install)\n* `git clone https://github.com/uber/piranha.git`\n* `cd piranha`\n* `cargo build --release` (`cargo build --release --no-default-features` for macOS)\n* Binary will be generated under `target/release`\n\n\n```bash\nPolyglot Piranha\nA refactoring tool that eliminates dead code related to stale feature flags\n\nUsage: polyglot_piranha [OPTIONS] --path-to-codebase <PATH_TO_CODEBASE> --path-to-configurations <PATH_TO_CONFIGURATIONS> -l <LANGUAGE>\n\nOptions:\n  -c, --path-to-codebase <PATH_TO_CODEBASE>\n          Path to source code folder or file\n      --include [<INCLUDE>...]\n          Paths to include (as glob patterns)\n      --exclude [<EXCLUDE>...]\n          Paths to exclude (as glob patterns)\n          \n  -t, --code-snippet <CODE_SNIPPET>\n          Code snippet to transform [default: ]\n  -s <SUBSTITUTIONS>\n          These substitutions instantiate the initial set of rules. Usage : -s stale_flag_name=SOME_FLAG -s namespace=SOME_NS1\n  -f, --path-to-configurations <PATH_TO_CONFIGURATIONS>\n          Directory containing the configuration files -  `rules.toml` and  `edges.toml` (optional)\n  -j, --path-to-output-summary <PATH_TO_OUTPUT_SUMMARY>\n          Path to output summary json file\n  -l <LANGUAGE>\n          The target language [possible values: java, swift, py, kt, go, tsx, ts]\n      --delete-file-if-empty\n          User option that determines whether an empty file will be deleted\n      --delete-consecutive-new-lines\n          Replaces consecutive `\\n`s  with a `\\n`\n      --global-tag-prefix <GLOBAL_TAG_PREFIX>\n          the prefix used for global tag names [default: GLOBAL_TAG.]\n      --number-of-ancestors-in-parent-scope <NUMBER_OF_ANCESTORS_IN_PARENT_SCOPE>\n          The number of ancestors considered when `PARENT` rules [default: 4]\n      --cleanup-comments-buffer <CLEANUP_COMMENTS_BUFFER>\n          The number of lines to consider for cleaning up the comments [default: 2]\n      --cleanup-comments\n          Enables deletion of associated comments\n      --dry-run\n          Disables in-place rewriting of code\n      --allow-dirty-ast\n          Allows syntax errors in the input source code\n  -h, --help\n          Print help\n```\n\nThe output JSON is the serialization of- [`PiranhaOutputSummary`](/src/models/piranha_output.rs) produced for each file touched or analyzed by Piranha.\n\n*It can be seen that the Python API is basically a wrapper around this command line interface.*\n\n\n## Piranha DSL\n\nIn PolyglotPiranha, programs are graphs of match-replace rules that can be composed and chained.\n\n### Rules\n\nIndividual edits are represented as rules in Polyglot Piranha, where each rule matches and replaces a specific code snippet.\nA program in PolyglotPiranha should contain at least one rule with the following properties:\n- `query`: A query to find the code pattern to refactor \n- `replace_node`: The captured node in the query that will be replaced.\n- `replace_string`: Replacement string or pattern for the refactored code.\n- `holes`: Placeholders in your queries that will be instantiated at runtime.\n- `is_seed_rule`: Specifies whether this rule is an entry point for the rule graph.\n\nOptionally, a rule can have filters. Piranha supports two kinds of filters:\n- `enclosing_node`: A pattern that specifies the enclosing node of the rule.\n- `not_enclosing_node`: A pattern that should not match any parent of the main match.\n\nThe `enclosing_node` and `not_enclosing_node` filters can be refined using contains with specified `[at_least, at_most]` bounds, as well as `not_contains`.\n\n\nThe rule queries, and filters can be written in the following languages:\n\n<h4> Tree-sitter Queries </h4>\n\nFor a detailed understanding of the syntax, refer to the [Tree-sitter Syntax Reference](https://tree-sitter.github.io/tree-sitter/syntax-highlighting#queries).\n\n<h4> Regular Expressions (Regex) </h4>\n\nTo create a rule in regex, prepend your query with `rgx `.\nFor instance: `rgx <your regex query>`. Piranha supports the regex syntax derived from the [regex](https://docs.rs/regex/) crate.\n\n<h4> Concrete Syntax </h4>\n\nPiranha's Concrete Syntax is a custom rule language designed for matching and replacing code. \nConcrete Syntax operates at the parse tree level, similar to [comby](https://comby.dev/).\nThe key difference is that it matches a parse tree node only if the entire parse tree can be traversed using the concrete syntax template.\n\nTo use concrete syntax, prepend the query with `cs <your_query>`. \nFor example, to match the code snippet `exp.isTreated(\"SHOW_MENU\")`, you can use the following query `cs :[object].isTreated(:[string])`\n\n\n<h4> Example of a rule in TOML </h4>\n\n```toml\n[[rules]]\nname = \"your_rule_name\"\nquery = \"\"\"(\n    (method_invocation name: (_) @name\n                       arguments: (argument_list) @args) @invk\n    (#eq? @name @method_name))\n\"\"\"\nreplace_node = \"invk\"\nreplace = \"foo @args\"\nholes = [\"method_name\"]\nis_seed_rule = true\n\n[[rules.filters]]\nenclosing_node = \"cs class MyClass { :[body] }\"\n```\n\n### Edges\n\nEdges in Polyglot Piranha allow rules to depend on each other, establishing a hierarchy or sequence of application among rules. \nAn edge essentially describes the direction of dependency between two or more rules.\nEdges are also represented in the TOML format.\n\nExample edges in TOML:\n```toml\n[[edges]]\nscope = \"Method\"\nfrom = \"your_rule_name\"\nto = [\"other_rule_name\", \"another_rule_name\"]\n\n[[edges]]\nscope = \"Method\"\nfrom = \"other_rule_name\"\nto = [\"your_rule_name\"]\n```\n\n\n## Getting Started with demos\n\n<h3> Running the Demos </h3>\n\nWe believe, the easiest way to get started with Piranha is to build upon the demos.\n\nTo setup the demo please follow the below steps:\n* `git clone https://github.com/uber/piranha.git`\n* `cd piranha`\n* Create a virtual environment:\n  - `python3 -m venv .env`\n  - `source .env/bin/activate`\n* Install Polyglot Piranha\n  - `pip install --upgrade pip`\n  - `pip install .` to run demo against current source code (please install [Rust](https://www.rust-lang.org/tools/install), it takes less than a minute)\n  - Or, `pip install polyglot-piranha` to run demos against the latest release.\n\n\nCurrently, we have demos for the following :\n\n<h4>Stale Feature Flag Cleanup:</h4>\n\n  * run `python3 demo/stale_feature_flag_cleanup_demos.py`. It will execute the scenarios listed under [demo/feature_flag_cleanup/java](demo/feature_flag_cleanup/java/configurations/rules.toml) and [demo/feature_flag_cleanup/kt](demo/feature_flag_cleanup/kt/configurations/rules.toml). These scenarios use simple feature flag API.\n  * In these demos the `configurations` contain :\n    * `rules.toml` : expresses how to capture different feature flag APIs (`isTreated`, `enum constant`)\n    * `piranha_arguments.toml` : expresses the flag behavior, i.e. the flag name and whether it is treated or not. Basically the `substitutions` provided in the `piranha_arguments.toml` can be used to instantiate the rules [reference](#piranha-arguments).\n\n<h4>  Match-only rules: </h4>\n\n  * run `python3 demo/match_only_demos.py`\n  * This demo also shows how the piranha summary output can be used.\n    * `rules.toml` : express how to capture two patterns - (i) invocation of the method `fooBar(\"...\")`  and invocation of the method `barFoo(\"...\")` (but only in non-static methods)\n\n<h4>  Structural Find/Replace </h4>\n\n  * run `python3 demo/find_replace_demos.py`\n  * This demo shows how to use Piranha as a simple structural find/replace tool (that optionally hooks up to built-in cleanup rules)\n\n<h4>  Structural Find/Replace with Custom Cleanup </h4>\n\n   * run `python3 demo/find_replace_custom_cleanup_demos.py`\n   * This demo shows how to replace `new ArrayList<>()` with `Collections.emptyList()`. Note it also adds the required import statement.\n\n\n*Please refer to our test cases at [`/test-resources/<language>/`](/test-resources/) as a reference for handling complicated scenarios*\n\n\n<h3>Building upon the stale feature flag cleanup demo </h3>\n\nFirst, check if Polyglot Piranha supports *Stale feature flag cleanup* for the required language.\n\nThen see if your API usage is similar to the ones shown in the demo ([java-demo](/demo/java/configurations/rules.toml)) or in the test resources ([java-ff_system1](/test-resources/java/feature_flag_system_1/control/configurations/rules.toml), [java-ff_system2](/test-resources/java/feature_flag_system_2/control/configurations/rules.toml), [kt-ff_system1](/test-resources/kotlin/feature_flag_system_1/control/configurations/rules.toml), [kt-ff_system2](/test-resources/kotlin/feature_flag_system_2/control/configurations/rules.toml)).\n\nIf not :|, try to adapt these examples to your requirements. Further, you can study the [tree-sitter query documentation](https://tree-sitter.github.io/tree-sitter/using-parsers#pattern-matching-with-queries) to understand how tree-sitter queries work. It is recommended to read the section- [Adding support for a new feature flag system](#adding-support-for-a-new-feature-flag-system)\n\nThen adapt the [argument file](/demo/java/configurations/piranha_arguments.toml) as per your requirements. For instance, you may want to update the value corresponding to the `@stale_flag_name` and `@treated`. If your rules do not contain require other tags feel free to remove them from your arguments file. In most cases [edges file](/src/cleanup_rules/java/edges.toml) is not required, unless your feature flag system API rules are inter-dependent.\n\n\nMore details for configuring Piranha - [Adding support for a new feature flag system](#adding-support-for-a-new-feature-flag-system)\nand [Adding Cleanup Rules](#adding-cleanup-rules).\n\n\n*One can similarly build upon the other demos too.*\n\n## *Stale Feature Flag Cleanup* in depth\n\n<h3> Adding support for a new feature flag system </h3>\n\nTo onboard a new feature flag system users will have to specify the `<path-to-configurations>/rules.toml` and `<path-to-configurations>/edges.toml` files (look [here](/src/cleanup_rules/java)). The `rules.toml` will contain rules that identify the usage of a feature flag system API. Defining `edges.toml` is required if your feature flag system API rules are inter-dependent.\nFor instance, you want to delete a method declaration with specific annotations and then update its usages with some boolean value.\nPlease refer to the `test-resources/java` for detailed examples.\n\n\n<h3> Adding a new API usage </h3>\n\nThe example below shows a usage of a feature flag API (`experiment.isTreated(STALE_FLAG)`), in a `if_statement`.\n```java\nclass PiranhaDemo {\n\n    void demoMethod(ExperimentAPI experiment){\n        // Some code\n        if (experiment.isTreated(STALE_FLAG)) {\n            // Do something\n        } else {\n            // Do something else\n        }\n        // Do other things\n    }\n}\n```\nIn the case when STALE_FLAG is treated, we would expect Piranha to refactor the code as shown below (assuming that `STALE_FLAG` is treated) :\n```java\nclass PiranhaDemo {\n\n    void demoMethod(ExperimentAPI experiment){\n        // Some code\n        // Do something\n        // Do other things\n    }\n}\n```\nThis can be achieved by adding a rule in the `input_rules.toml` file (as shown below) :\n```toml\n[[rules]]\nname = \"Enum Based, toggle enabled\"\nquery = \"\"\"((\n    (method_invocation\n        name : (_) @n1\n        arguments: ((argument_list\n                        ([\n                          (field_access field: (_)@f)\n                          (_) @f\n                         ])) )\n\n    ) @mi\n)\n(#eq? @n1 \"isTreated\")\n(#eq? @f \"@stale_flag_name\")\n)\"\"\"\nreplace_node = \"mi\"\nreplace = \"@treated\"\ngroups = [ \"replace_expression_with_boolean_literal\"]\nholes = [\"treated\", \"stale_flag_name\"]\n```\nThis specifies a rule that matches against expressions like `exp.isTreated(SOME_FLAG_NAME)` and replaces it with `true` or `false`.\nThe `query` property of the rule contains a [tree-sitter query](https://tree-sitter.github.io/tree-sitter/using-parsers#pattern-matching-with-queries) that is matched against the source code.\nThe node captured by the tag-name specified in the `replace_node` property is replaced with the pattern specified in the `replace` property.\nThe `replace` pattern can use the tags from the `query` to construct a replacement based on the match (like [regex-replace](https://docs.microsoft.com/en-us/visualstudio/ide/using-regular-expressions-in-visual-studio?view=vs-2022)).\n\nEach rule also contains the `groups` property, that specifies the kind of change performed by this rule. Based on this group, appropriate\ncleanup will be performed by Piranha. For instance, `replace_expression_with_boolean_literal` will trigger deep cleanups to eliminate dead code (like eliminating `consequent` of a `if statement`) caused by replacing an expression with a boolean literal.\nCurrently, Piranha provides deep clean-ups for edits that belong the groups - `replace_expression_with_boolean_literal`, `delete_statement`, and `delete_method`. Basically, by adding an appropriate entry to the groups, a user can hook up their rules to the pre-built cleanup rules.\n\nSetting the `is_seed_rule=False` ensures that the user defined rule is treated as a cleanup rule not as a seed rule (For more details refer to `demo/find_replace_custom_cleanup`).\n\nA user can also define exclusion filters for a rule (`rules.filters`). These filters allow matching against the context of the primary match. For instance, we can write a rule that matches the expression `new ArrayList<>()` and exclude all instances that occur inside static methods (For more details, refer to the `demo/match_only`).\n\nAt a higher level, we can say that - Piranha first selects AST nodes matching `rules.query`, excluding those that match **any of** the `rules.filters.not_contains` (within `rules.filters.enclosing_node`). It then replaces the node identified as `rules.replace_node` with the formatted (using matched tags) content of `rules.replace`.\n\n<h3> Parameterizing the behavior of the feature flag API </h3>\n\nThe `rule` contains `holes` or template variables that need to be instantiated.\nFor instance, in the above rule `@treated` and `@stale_flag_name` need to be replaced with some concrete value so that the rule matches only the feature flag API usages corresponding to a specific flag, and replace it specifically with `true` or `false`.  To specify such a behavior,\nuser should create a `piranha_arguments.toml` file as shown below (assuming that the behavior of STALE_FLAG is **treated**):\n```toml\nlanguage = [\"java\"]\nsubstitutions = [\n    [\"stale_flag_name\", \"STALE_FLAG\"],\n    [\"treated\", \"true\"]\n]\n```\nThis file specifies that, the user wants to perform this refactoring for `java` files.\nThe `substitutions` field captures mapping between the tags and their corresponding concrete values. In this example, we specify that the tag named `stale_flag_name` should be replaced with `STALE_FLAG` and `treated` with `true`.\n\n\n<h3> Adding Cleanup Rules </h3>\n\nThis section describes how to configure Piranha to support a new language. Users who do not intend to onboard a new language can skip this section.\nThis section will describe how to encode cleanup rules that are triggered based on the update applied to the flag API usages.\nThese rules should perform cleanups like simplifying boolean expressions, or if statements when the condition is constant, or deleting empty interfaces, or in-lining variables.\nFor instance, the below example shows a rule that simplifies a `or` operation where its `RHS` is true.\n```toml\n[[rules]]\nname = \"Or - right operand is True\"\nquery = \"\"\"(\n(binary_expression\n    left : (_)*\n    operator:\"||\"\n    right: (true)\n) @binary_expression)\"\"\"\nreplace_node = \"binary_expression\"\nreplace = \"true\"\n```\n\nCurrently, Piranha picks up the language specific configurations from `src/cleanup_rule/<language>`.\n\n\n<h5> Example </h5>\n\nLet's consider an example where we want to define a cleanup for the scenario where\n<table>\n<tr>\n<td> Before </td> <td> After </td>\n</tr>\n<tr>\n<td>\n\n```java\nint foobar(){\n    boolean x = exp.isTreated(SOME_STALE_FLAG);\n    if (x || someCondition()) {\n        return 100;\n    }\n    return 0;\n}\n```\n\n</td>\n\n<td>\n\n```java\nint foobar(){\n    return 100;\n}\n```\n\n</td>\n</table>\n\nWe would first define flag API rules as discussed in the section [Adding Support for a new language](#adding-support-for-a-new-language). Assuming this rule replaces the occurrence of the flag API corresponding to `SOME_STALE_FLAG` with `true`; we would have to define more cleanup rules as follows:\n\n* `R0`: Deletes the enclosing variable declaration (i.e. `x`) (E.g. [java-rules](/src/cleanup_rules/java/rules.toml):`delete_variable_declarations`)\n* `R1`: replace the identifier with the RHS of the deleted variable declaration, within the body of the enclosing method where `R0` was applied i.e. replace `x` with `true` within the method body of `foobar`. (E.g. [java-rules](/src/cleanup_rules/java/rules.toml):`replace_expression_with_boolean_literal`)\n* `R2`: simplify the boolean expressions, for example replace `true || someCondition()` with `true`, that encloses the node where `R1` was applied. (E.g. [java-rules](/src/cleanup_rules/java/rules.toml): `true_or_something`)\n* `R3`: eliminate the enclosing if statement with a constant condition where `R2` was applied (`if (true) { return 100;}` → `return 100;`). E.g. [java-rules](/src/cleanup_rules/java/rules.toml): `simplify_if_statement_true, remove_unnecessary_nested_block`\n* `R4`: eliminate unreachable code (`return 0;` in `return 100; return 0;`) in the enclosing block where `R3` was applied. (E.g. [java-rules](/src/cleanup_rules/java/rules.toml): `delete_all_statements_after_return`)\n\nThe fact that `R2` has to be applied to the enclosing node where `R1` was applied, is expressed by specifying the `edges.toml` file.\n\nTo define how these cleanup rules should be chained, one needs to specify edges (e.g. the [java-edges](/src/cleanup_rules/java/edges.toml) file) between the groups and (or) individual rules.\nThe edges can be labelled as `Parent`, `Global` or even much finer scopes like `Method` or `Class` (or let's say `functions` in `go-lang`).\n* A `Parent` edge implies that after Piranha applies the `\"from\"` rule to update the node `n1` in the AST to node `n2`, Piranha tries to apply `\"to\"` rules on any ancestor of `\"n2\"` (e.g. `R1` → `R2`, `R2` → `R3`, `R3` → `R4`)\n* A `Method` edge implies that after Piranha applies the `\"from\"` rule to update the node `n1` in the AST to node `n2`, Piranha tries to apply `\"to\"` rules within the enclosing method's body. (e.g. `R0` → `R1`)\n* A `Class` edge implies that after Piranha applies the `\"from\"` rule to update the node `n1` in the AST to node `n2`, Piranha tries to apply `\"to\"` rules within the enclosing class body. (e.g. in-lining a private field)\n* A `Global` edge implies that after Piranha applies the `\"from\"` rule to update the node `n1` in the AST to node `n2`, Piranha tries to apply `\"to\"` rules in the entire code base. (e.g. in-lining a public field).\n\n`scope_config.toml` file specifies how to capture these fine-grained scopes like `method`, `function`, `lambda`, `class`.\nFirst decide, what scopes you need to capture, for instance, in Java we capture \"Method\" and \"Class\" scopes. Once, you decide the scopes construct scope query generators similar to [java-scope_config](/src/cleanup_rules/java/scope_config.toml). Each scope query generator has two parts - (i) `matcher` is a tree-sitter query that matches the AST for the scope, and (ii) `generator` is a tree-sitter query with holes that is instantiated with the code snippets corresponding to tags when `matcher` is matched.\n\n\n## Visualizing Graphs for Rules and Groups\n\nVisualizing rules, groups and their edges through a graph is a great way to understand how Piranha Polyglot works.\n\nWe use [Graphviz](https://graphviz.org/) to generate a .dot file and a .svg image generated by `visualize_rules_graph.py`.\nPlease follow the instructions to install Graphviz at <https://graphviz.org/download/>.\nMoreover, the script also needs the `toml` and `graphviz` python packages.\n\nThe script takes as first argument a path for the generated .dot file.\nThe following arguments are paths for directories containing `rules.toml` and `edges.toml` files.\nOptionally, you can provide a `--title` argument to give a title to the generated graph.\nTo generate the .dot file and the .svg image used in this README (assuming a Python venv and a valid Graphviz installation):\n\n```bash\npip install toml\npip install graphviz\npython visualize_rules_graph.py ./java_prebuilt_rules.dot src/cleanup_rules/java --title \"Java pre-built cleanup rules\"\n```\n\nTo generate an image for [java-ff_system1](test-resources/java/feature_flag_system_1/control/configurations/) in our tests:\n\n```bash\npython visualize_rules_graph.py ./java-ff_system1.dot src/cleanup_rules/java test-resources/java/feature_flag_system_1/control/configurations --title \"Java Test Feature Flag Cleanup System 1\"\n```\n\n\n## Piranha Arguments\n\nThe purpose of Piranha Arguments is determining the behavior of Piranha.\n- `language` : The programming language used by the source code\n- `substitutions` : Seed substitutions for the rules (if any). In case of stale feature flag cleanup, we pass the stale feature flag name and whether it is treated or not.\n- `delete_file_if_empty` : enables delete file if it consequently becomes empty\n-  `delete_consecutive_new_lines` : enables deleting consecutive empty new line\n-  `cleanup_comments` : enables cleaning up the comments associated to the deleted code elements like fields, methods or classes\n-  `cleanup_comments_buffer` : determines how many lines above to look up for a comment.\n\n\n\n\n## Development\n\nPrerequisites: \n* Install [pre-commit](https://pre-commit.com/)\n* Install [taplo](https://taplo.tamasfe.dev/cli/introduction.html)\n\n<h4> Naming conventions for the rules </h4>\n\n* We name the rules in the format - <verb>_<ast_kind>. E.g., `delete_method_declaration` or `replace_expression with_boolean_literal`\n* We name the dummy rules in the format - `<ast_kind>_cleanup` E.g. `statement_cleanup` or `boolean_literal_cleanup`. Using dummy rules (E.g. [java-rules](/src/cleanup_rules/java/rules.toml): `boolean_literal_cleanup`) makes it easier and cleaner when specifying the flow between rules.\n\n<h4> Writing tests </h4>\n\nCurrently we maintain\n* Unit tests for the internal functionality can be found under `<models|utilities>/unit_test`.\n* End-to-end tests for the configurations execute  Piranha on the test scenarios in `test-resources/<language>/input` and check if the output is as expected (`test-resources/<language>/expected_treated` and `test-resources/<language>/expected_control`).\n\nTo add new scenarios to the existing tests for a given language, you can add them to new file in the `input` directory and then create similarly named files with the expected output in `expected_treated` and `expected_control` directory.\nUpdate the `piranha_arguments_treated.toml` and `piranha_arguments_control.toml` files too.\n\nTo add tests for a new language, please add a new `<language>` folder inside `test-resources/` and populate the `input`, `expected_treated` and `expected_control` directories appropriately.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 4.1904296875,
          "content": "# PolyglotPiranha\n\nPolyglotPiranha is a lightweight code transformation toolset for automating large scale changes. At Uber, it is mostly used to clean up stale feature flags.\n\nWe only support languages that are used at Uber. We likely won't be able to add new languages in this repo. There are a number of forks (see https://github.com/uber/piranha/forks for a full list) that may provide additional features.\n\n\n## Installation\n\nTo install Polyglot Piranha, you can use it as a Python library or as a command-line tool.\n\n### Python API\n\nTo install the Python API, run the following command:\n\n```bash\npip install polyglot-piranha\n```\n\n### Command-line Interface\n\nTo install the command-line interface, follow these steps:\n\n1. Install [Rust](https://www.rust-lang.org/tools/install)\n2. Clone the repository: `git clone https://github.com/uber/piranha.git`\n3. Navigate to the cloned directory: `cd piranha`\n4. Build the project: `cargo build --release` (or `cargo build --release --no-default-features` for macOS)\n5. The binary will be generated under `target/release`\n\n## Example Usage\n\n```python\nfrom polyglot_piranha import execute_piranha, PiranhaArguments, Rule, RuleGraph, OutgoingEdges\n\n# Original code snippet\ncode = \"\"\"\nif (obj.isLocEnabled() || x > 0) {\n    // do something\n} else {\n    // do something else!\n}\n\"\"\"\n\n# Define the rule to replace the method call\nr1 = Rule(\n    name=\"replace_method\",\n    query=\"cs :[x].isLocEnabled()\", # cs indicates we are using concrete syntax\n    replace_node=\"*\",\n    replace=\"true\",\n    is_seed_rule=True\n)\n\n# Define the edges for the rule graph. \n# In this case, boolean_literal_cleanup is already defined for java [see src/cleanup_rules]\nedge = OutgoingEdges(\"replace_method\", to=[\"boolean_literal_cleanup\"], scope=\"parent\")\n\n# Create Piranha arguments\npiranha_arguments = PiranhaArguments(\n    code_snippet=code,\n    language=\"java\",\n    rule_graph=RuleGraph(rules=[r1], edges=[edge])\n)\n\n# Execute Piranha and print the transformed code\npiranha_summary = execute_piranha(piranha_arguments)\nprint(piranha_summary[0].content)\n```\n\n\n## Documentation\n\nFor more examples and explanations of the toolset, please check our demos and extended [POLYGLOT_README.md](POLYGLOT_README.md) file.\n\n\n## Feature Flags\n\n\nFeature flags are commonly used to enable gradual rollout or experiment with new features. In a few cases, even after the purpose of the flag is accomplished, the code pertaining to the feature flag is not removed. We refer to such flags as stale flags. The presence of code pertaining to stale flags can have the following drawbacks: \n- Unnecessary code clutter increases the overall complexity w.r.t maintenance resulting in reduced developer productivity \n- The flags can interfere with other experimental flags (e.g., due to nesting under a flag that is always false)\n- Presence of unused code in the source as well as the binary \n- Stale flags can also cause bugs \n\nPolyglotPiranha is a tool that can automatically refactor code related to stale flags. At a higher level, the input to the tool is the name of the flag and the expected behavior, after specifying a list of APIs related to flags in a properties file. Piranha will use these inputs to automatically refactor the code according to the expected behavior.\n\nPolyglotPiranha (as of May 2022) is a common refactoring tool to support multiple languages and feature flag APIs.\nFor legacy language-specific implementations please check following [tag](https://github.com/uber/piranha/releases/tag/last-version-having-legacy-piranha).\n\n\n\nA few additional links on Piranha: \n\n- Research paper published at [PLDI 2024](https://dl.acm.org/doi/10.1145/3656429) on PolyglotPiranha.\n- A technical [report](report.pdf) detailing our experiences with using Piranha at Uber.\n- A [blogpost](https://eng.uber.com/piranha/) presenting more information on Piranha. \n- 6 minute [video](https://www.youtube.com/watch?v=V5XirDs6LX8&feature=emb_logo) overview of Piranha.\n\n## Support\n\nIf you have any questions on how to use Piranha or find any bugs, please [open a GitHub issue](https://github.com/uber/piranha/issues).\n\n## License\nPiranha is licensed under the Apache 2.0 license.  See the LICENSE file for more information.\n\n## Note\n\nThis is not an official Uber product, and provided as is.\n\n\n"
        },
        {
          "name": "RELEASING.md",
          "type": "blob",
          "size": 1.130859375,
          "content": "Releasing\n=========\n\n 1. Create a new branch - `git checkout -b \"release-X.Y.Z\"` (where X.Y.Z is the new version)\n 2. Change the version in `Cargo.toml` to the next version.\n 3. Update the `CHANGELOG.md` for the impending release.\n 4. Update the `README.md` with the new version.\n 5. `git commit -am \"[PolyglotPiranha] Prepare for release X.Y.Z.\"` (where X.Y.Z is the new version)\n 6. `git tag -a vX.Y.Z-polyglot -m \"PolyglotPiranha Version X.Y.Z\"` (where X.Y.Z is the new version)\n 7. `git push --set-upstream origin release-X.Y.Z && git push --tags`\n 8. Create a PR, request for review and merge it into `master` after it is approved.\n 9. From your terminal run : `gh workflow run \"Release Polyglot Piranha\" --ref master` or do this from the Github UI\n 10. Wait till this action is completed.\n 11. Manually release MacOS M1 wheel (Currently GitHub Actions do not provide M1 VM)\n      1. Clone the piranha repo and pull the latest `master` branch\n      2. `cargo build --no-default-features`\n      3. `maturin build --release`\n      4. `twine upload --skip-existing target/wheels/*`\n 13. Visit [polyglot-piranha](https://pypi.org/project/polyglot-piranha/)\n"
        },
        {
          "name": "build.rs",
          "type": "blob",
          "size": 1.3671875,
          "content": "/*\n Copyright (c) 2023 Uber Technologies, Inc.\n\n <p>Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file\n except in compliance with the License. You may obtain a copy of the License at\n <p>http://www.apache.org/licenses/LICENSE-2.0\n\n <p>Unless required by applicable law or agreed to in writing, software distributed under the\n License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n express or implied. See the License for the specific language governing permissions and\n limitations under the License.\n*/\n\nuse std::process::Command;\n\n/// Set up the development environment\n/// Creates a `venv` with pre-commit / maturin\nfn main() {\n  // Create python virtual environment\n  _ = Command::new(\"python3\")\n    .arg(\"-m\")\n    .args([\"venv\", \".env\"])\n    .spawn()\n    .expect(\"Could not create virtual environment\");\n\n  // Install pre-commit and maturin\n  _ = Command::new(\"pip3\")\n    .args([\"install\", \"pre-commit\", \"maturin\"])\n    .spawn()\n    .expect(\"Could not install pre-commit (pip dependency)\");\n\n  // Add pre-commit hook\n  _ = Command::new(\"sh\")\n    .arg(\"-c\")\n    .arg(\"pre-commit install\")\n    .spawn()\n    .expect(\"Install pre-commit hook\");\n\n  // Install taplo-cli\n  _ = Command::new(\"cargo\")\n    .args([\"install\", \"taplo-cli\", \"--locked\"])\n    .spawn()\n    .expect(\"Could not install taplo (toml formatter)\");\n}\n"
        },
        {
          "name": "demo",
          "type": "tree",
          "content": null
        },
        {
          "name": "experimental",
          "type": "tree",
          "content": null
        },
        {
          "name": "images",
          "type": "tree",
          "content": null
        },
        {
          "name": "license_header.txt",
          "type": "blob",
          "size": 0.55859375,
          "content": "Copyright (c) 2023 Uber Technologies, Inc.\n\n<p>Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file\nexcept in compliance with the License. You may obtain a copy of the License at\n<p>http://www.apache.org/licenses/LICENSE-2.0\n\n<p>Unless required by applicable law or agreed to in writing, software distributed under the\nLicense is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\nexpress or implied. See the License for the specific language governing permissions and\nlimitations under the License.\n"
        },
        {
          "name": "plugins",
          "type": "tree",
          "content": null
        },
        {
          "name": "polyglot_piranha.pyi",
          "type": "blob",
          "size": 10.2578125,
          "content": "# Copyright (c) 2023 Uber Technologies, Inc.\n#\n# <p>Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file\n# except in compliance with the License. You may obtain a copy of the License at\n# <p>http://www.apache.org/licenses/LICENSE-2.0\n#\n# <p>Unless required by applicable law or agreed to in writing, software distributed under the\n# License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n# express or implied. See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\nfrom typing import List, Optional, Literal\n\n# Languages that Piranha supports (see ./src/models/language.rs)\nPiranhaLanguage = Literal[\"java\", \"kt\", \"kotlin\", \"go\", \"python\", \"swift\", \"typescript\", \"tsx\", \"thrift\", \"strings\", \"scm\", \"scala\", \"ruby\", \"yaml\", \"yml\"]\n\n\ndef execute_piranha(piranha_argument: PiranhaArguments) -> list[PiranhaOutputSummary]:\n    \"\"\"\n    Executes piranha for the given `piranha_arguments` and returns `PiranhaOutputSummary` for each file analyzed by Piranha\n    Parameters\n    ------------\n        piranha_arguments: Piranha Arguments\n            Configurations for piranha\n    Returns\n    ------------\n    List of `PiranhaOutPutSummary`\n    \"\"\"\n    ...\n\nclass PiranhaArguments:\n    \"\"\"\n    A class to capture Piranha's configurations\n    \"\"\"\n\n    def __init__(\n        self,\n        language: PiranhaLanguage,\n        paths_to_codebase: Optional[List[str]] = None,\n        include: Optional[List[str]] = None,\n        exclude: Optional[List[str]] = None,\n        substitutions: Optional[dict[str, str]] = None,\n        path_to_configurations: Optional[str] = None,\n        rule_graph: Optional[RuleGraph] = None,\n        code_snippet: Optional[str] = None,\n        dry_run: Optional[bool] = None,\n        cleanup_comments: Optional[bool] = None,\n        cleanup_comments_buffer: Optional[int] = None,\n        number_of_ancestors_in_parent_scope: Optional[int] = None,\n        delete_consecutive_new_lines: Optional[bool] = None,\n        global_tag_prefix: Optional[str] = \"GLOBAL_TAG\",\n        delete_file_if_empty: Optional[bool] = None,\n        path_to_output: Optional[str] = None,\n        allow_dirty_ast: Optional[bool] = None,\n        should_validate: Optional[bool] = None,\n        experiment_dyn: Optional[bool] = None,\n    ):\n        \"\"\"\n        Constructs `PiranhaArguments`\n\n        Parameters\n        ------------\n            language: PiranhaLanguage\n                the target language\n            paths_to_codebase: List[str]\n                Paths to source code folder or file\n            keyword arguments: _\n                 substitutions (dict): Substitutions to instantiate the initial set of rules\n                 path_to_configurations (str): Directory containing the configuration files - `piranha_arguments.toml`, `rules.toml`, and  `edges.toml`\n                 rule_graph (RuleGraph): The rule graph constructed via RuleGraph DSL\n                 code_snippet (str): The input code snippet to transform\n                 dry_run (bool): Disables in-place rewriting of code\n                 cleanup_comments (bool): Enables deletion of associated comments\n                 cleanup_comments_buffer (int): The number of lines to consider for cleaning up the comments\n                 number_of_ancestors_in_parent_scope (int): The number of ancestors considered when PARENT rules\n                 delete_consecutive_new_lines (bool): Replaces consecutive \\ns  with a \\n\n                 global_tag_prefix (str): the prefix for global tags\n                 delete_file_if_empty (bool): User option that determines whether an empty file will be deleted\n                 path_to_output (str): Path to the output json file\n                 allow_dirty_ast (bool): Allows syntax errors in the input source code\n        \"\"\"\n        ...\n\nclass PiranhaOutputSummary:\n    \"\"\"\n    A class to represent Piranha's output\n\n    Attributes\n    ----------\n    path: path to the file\n    content: content of the file after all the rewrites\n    matches: All the occurrences of \"match-only\" rules\n    rewrites: All the applied edits\n    \"\"\"\n\n    path: str\n    \"path to the file\"\n\n    original_content: str\n    \"Original content of the file before any rewrites\"\n\n    content: str\n    \"Final content of the file after all the rewrites\"\n\n    matches: list[tuple[str, Match]]\n    'All the occurrences of \"match-only\" rules'\n\n    rewrites: list[Edit]\n    \"All the applied edits\"\n\nclass Edit:\n    \"\"\"\n     A class to represent an edit performed by Piranha\n\n    Attributes\n    ----------\n    p_match: The match representing the target site of the edit\n    replacement_string: The string to replace the substring encompassed by the match\n    matched_rule: The rule used for creating this match-replace\n    \"\"\"\n\n    p_match: Match\n    \"The match representing the target site of the edit\"\n\n    matched_rule: str\n    \"The rule used for creating this match-replace\"\n\n    replacement_string: str\n    \"The string to replace the substring encompassed by the match\"\n\nclass Match:\n    \"\"\"\n     A class to represent a match\n\n    Attributes\n    ----------\n    matched_sting: Code snippet that matched\n    range: Range of the entire AST node captured by the match\n    matches: The mapping between tags and string representation of the AST captured\n    \"\"\"\n\n    matched_string: str\n    \"Code snippet that matched\"\n\n    range: Range\n    \"Range of the entire AST node captured by the match\"\n\n    matches: dict[str, str]\n    \"The mapping between tags and string representation of the AST captured\"\n    \"\"\n\nclass Range:\n    \"\"\"A range of positions in a multi-line text document,\n    both in terms of bytes and of rows and columns.\n    \"\"\"\n\n    start_byte: int\n    end_byte: int\n    start_point: Point\n    end_point: Point\n\nclass Point:\n    row: int\n    column: int\n\nclass Filter:\n    \"\"\"A class to capture filters of a Piranha Rule\"\"\"\n\n    enclosing_node: TSQuery\n    \"AST patterns that some ancestor node of the primary match should comply\"\n    not_contains: list[TSQuery]\n    \"AST patterns that SHOULD NOT match any subtree of node matching `enclosing_node` pattern\"\n    contains: TSQuery\n    \"AST pattern that SHOULD match subtrees of `enclosing_node`. \" \"Number of matches should be within the range of `at_least` and `at_most`.\"\n    at_least: int\n    \"The minimum number of times the contains query should match in the enclosing node\"\n    at_most: int\n    \"The maximum number of times the contains query should match in the enclosing node\"\n    child_count: int\n    \"Number of named children under the primary matched node\"\n    sibling_count: int\n    \"Number of named siblings of the primary matched node\"\n    def __init__(\n        self,\n        enclosing_node: Optional[str] = None,\n        not_enclosing_node: Optional[str] = None,\n        not_contains: list[str] = [],\n        contains: Optional[str] = None,\n        at_least: int = 1,\n        at_most: int = 4294967295,  # u32::MAX\n        child_count: int = 4294967295,  # u32::MAX\n        sibling_count: int = 4294967295,  # u32::MAX\n    ):\n        \"\"\"\n        Constructs `Filter`\n\n        Parameters\n        ------------\n            enclosing_node: str\n                AST patterns that some ancestor node of the primary match should comply\n            not_contains: list[str]\n                 AST patterns that should not match any subtree of node matching `enclosing_node` pattern\n        \"\"\"\n        ...\n\nclass Rule:\n    \"\"\"A class to capture Piranha Rule\"\"\"\n\n    name: str\n    \"Name of the rule\"\n    query: TSQuery\n    \"Tree-sitter query as string\"\n    replace_node: str\n    \"The tag corresponding to the node to be replaced\"\n    replace_node_idx: str\n    \"The i'th child of node corresponding to the replace_node tag will be replaced\"\n    replace: str\n    \"Replacement pattern\"\n    groups: set[str]\n    \"Group(s) to which the rule belongs\"\n    holes: set[str]\n    \"Holes that need to be filled, in order to instantiate a rule\"\n    filters: set[Filter]\n    \"Filters to test before applying a rule\"\n    is_seed_rule: bool\n    \"Marks a rule as a seed rule\"\n\n    def __init__(\n        self,\n        name: str,\n        query: Optional[str] = None,\n        replace_node: Optional[str] = None,\n        replace: Optional[str] = None,\n        groups: set[str] = set(),\n        holes: set[str] = set(),\n        filters: set[Filter] = set(),\n        is_seed_rule: bool = True,\n    ):\n        \"\"\"\n        Constructs `Rule`\n\n        Parameters\n        ------------\n            name: str\n                Name of the rule\n            query: str\n                Tree-sitter query as string\n            replace_node: str\n                The tag corresponding to the node to be replaced\n            replace: str\n                Replacement pattern\n            groups: set[str]\n                Group(s) to which the rule belongs\n            holes: set[str]\n                Holes that need to be filled, in order to instantiate a rule\n            filters: set[Filter]\n                Filters to test before applying a rule\n            is_seed_rule: bool\n                Marks a rule as a seed rule\n        \"\"\"\n        ...\n\nclass OutgoingEdges:\n    frm: str\n    \"The source rule or group of rules\"\n    to: list[str]\n    \"The target edges or groups of edges\"\n    scope: str\n    \"The scope label for the edge\"\n\n    def __init__(\n        self,\n        frm: str,\n        to: list[str],\n        scope: str,\n    ):\n        \"\"\"\n        Constructs `OutgoingEdge`\n\n        Parameters\n        ------------\n            frm: str\n                The source rule or group of rules\n            to: list[str]\n                The target edges or groups of edges\n            scope: str\n                The scope label for the edge\n        \"\"\"\n        ...\n\nclass RuleGraph:\n    rules: list[Rule]\n    \"The rules in the graph\"\n    edges: list[OutgoingEdges]\n    \"The edges in the graph\"\n    graph: dict[str, list[tuple[str, str]]]\n    \"The graph itself (as an adjacency list)\"\n\n    def __init__(\n        self,\n        rules: list[Rule],\n        edges: list[OutgoingEdges],\n    ):\n        \"\"\"\n        Constructs `OutgoingEdge`\n\n        Parameters\n        ------------\n            rules: list[Rule]\n                The rules in the graph\n            edges: list[OutgoingEdges]\n                The edges in the graph\n        \"\"\"\n        ...\n\nclass TSQuery:\n    \"Captures a Tree sitter query\"\n    def query(self):\n        \"\"\"The query\"\"\"\n        ...\n"
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.6513671875,
          "content": "[project]\nname = \"polyglot_piranha\"\nrequires-python = \">=3.8\"\ndescription = \"Polyglot Piranha is a library for performing structural find and replace with deep cleanup.\"\nauthors = [{ name = \"Uber Technologies Inc.\" }]\nlicense = \"Apache-2.0\"\nreadme = \"README.md\"\nkeywords = [\n  \"refactoring\",\n  \"code update\",\n  \"structural find-replace\",\n  \"structural search and replace\",\n  \"structural search\",\n]\n\n[project.urls]\nhomepage = \"https://github.com/uber/piranha\"\ndocumentation = \"https://github.com/uber/piranha\"\nrepository = \"https://github.com/uber/piranha\"\n\n[build-system]\nrequires = [\"maturin>=1.4.0,<2.0\"]\nbuild-backend = \"maturin\"\n\n[tool.maturin]\nbindings = \"pyo3\"\n"
        },
        {
          "name": "report.pdf",
          "type": "blob",
          "size": 644.6005859375,
          "content": null
        },
        {
          "name": "rustfmt.toml",
          "type": "blob",
          "size": 0.6982421875,
          "content": "# /*\n# Copyright (c) 2023 Uber Technologies, Inc.\n\n#  <p>Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file\n#  except in compliance with the License. You may obtain a copy of the License at\n#  <p>http://www.apache.org/licenses/LICENSE-2.0\n\n#  <p>Unless required by applicable law or agreed to in writing, software distributed under the\n#  License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n#  express or implied. See the License for the specific language governing permissions and\n#  limitations under the License.\n# */\nmax_width = 100\ntab_spaces = 2\nedition = \"2021\"\nfn_args_layout = \"Compressed\"\nuse_field_init_shorthand = true\n"
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "test-resources",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "visualize_rules_graph.py",
          "type": "blob",
          "size": 9.458984375,
          "content": "import argparse\nimport os\nimport re\nimport toml\nimport graphviz\nfrom dataclasses import dataclass\n\n# REQUIRED: pip install toml\n# REQUIRED: pip install graphviz\n\n\n@dataclass(frozen=True, eq=True)\nclass Edge:\n    to: str\n    scope: str\n\n\ndef collect_rules_groups_edges():\n    for config_path in args.configurations_path:\n        config_path = os.path.abspath(config_path) + os.path.sep\n        rules_file = config_path + 'rules.toml'\n\n        # rules.toml should exist, deliberately fail otherwise\n        rules_toml_dict = toml.load(rules_file)\n        collect_rules_and_groups(rules_toml_dict)\n\n        # edges are optional for input rules (i.e., non built-in)\n        edges_file = config_path + 'edges.toml'\n        if os.path.exists(edges_file):\n            edges_toml_dict = toml.load(edges_file)\n            collect_edges(edges_toml_dict)\n\n\ndef collect_rules_and_groups(rules_toml_dict):\n    \"\"\"\n    Collects rules and groups to further build graph nodes.\n\n    Rules belonging to a group different than `Cleanup Rule` are displayed below the group name.\n\n    Cleanup Rule's are added to a set as they are displayed differently.\n        They get an additional label `(Cleanup_Rule)`.\n\n    Nodes without a group are added to a different set.\n    \"\"\"\n    for rule_toml in rules_toml_dict['rules']:\n        rule_name: str = sanitize_name(rule_toml['name'])\n        if 'query' not in rule_toml:\n            dummy_nodes.add(rule_name)\n\n        if 'groups' in rule_toml:\n            rule_groups = rule_toml['groups']\n            collect_node_for_rule_with_group(rule_name, rule_groups)\n        else:\n            nodes_without_groups.add(rule_name)\n\n\ndef collect_node_for_rule_with_group(rule_name: str, rule_groups: 'list[str]'):\n    for group_name in rule_groups:\n        group_name = sanitize_name(group_name)\n        if group_name != 'Cleanup_Rule':\n            if group_name in rules_by_group_dict:\n                rules_by_group_dict[group_name].append(rule_name)\n            else:\n                rules_by_group_dict[group_name] = [rule_name]\n        else:  # we don't want to group `Cleanup Rule`s under the same graphviz shape\n            cleanup_rules.add(rule_name)\n\n\ndef sanitize_name(s: str) -> str:\n    \"\"\"Graphviz does not like names with spaces. Converts spaces to '_'.\"\"\"\n    s = re.sub(r\"\\s+\", '_', s)\n    return s\n\n\ndef collect_edges(edges_toml_dict):\n    \"\"\"\n    Groups outgoing edges by rule/group.\n\n    All names are sanitized to replace empty spaces by `_`.\n    \"\"\"\n    for edge_toml in edges_toml_dict['edges']:\n        from_node = sanitize_name(edge_toml['from'])\n        to_nodes: 'list[str]' = edge_toml['to']\n        scope = sanitize_name(edge_toml['scope'])\n        for to_node in to_nodes:\n            to_node = sanitize_name(to_node)\n            edge = Edge(to=to_node, scope=scope)\n            if from_node in outgoing_edges_by_node:\n                outgoing_edges_by_node[from_node].append(edge)\n            else:\n                outgoing_edges_by_node[from_node] = [edge]\n\n\ndef initialize_graph() -> graphviz.Digraph:\n    graph_attr = {\n        'label': str(args.title),\n        'labelloc': 't',\n        'fontsize': '30'\n    }\n    graph = graphviz.Digraph(filename=output_file_path, graph_attr=graph_attr)\n    graph.format = 'svg'\n    return graph\n\n\ndef generate_graph_nodes():\n    generate_nodes_with_groups_and_outgoing_edges()\n    # rules *without* outgoing edges and no groups have not been added yet\n    # this is because we focus on outgoing edges when traversing `edges.toml`\n    generate_nodes_without_groups_and_no_outgoing_edges()\n\n\ndef generate_nodes_with_groups_and_outgoing_edges():\n    for rule_name in all_rule_names_with_groups_and_outgoing_edges():\n        if rule_name in rules_by_group_dict:\n            # several (n >= 1) rules under the same graphviz `record` shape.\n            generate_node_for_group(rule_name)\n        else:\n            # not a graphviz `record` node. single rule in the shape.\n            generate_node_for_rule_not_under_a_group(rule_name)\n\n        added_nodes.add(rule_name)\n\n\ndef all_rule_names_with_groups_and_outgoing_edges() -> 'list[str]':\n    # set difference\n    # map.keys() is a set view, it doesn't have set's methods but supports operators\n    node_names_with_only_outgoing_edges = rules_by_group_dict.keys() - \\\n        outgoing_edges_by_node.keys()\n\n    rule_names_with_groups = list(outgoing_edges_by_node.keys())\n    rule_names_with_groups.extend(node_names_with_only_outgoing_edges)\n    rule_names_with_groups.extend(cleanup_rules)\n    return rule_names_with_groups\n\n\ndef generate_node_for_group(rule_name: str):\n    rule_names_in_group = rules_by_group_dict[rule_name]\n    for group_rule_name in rule_names_in_group:\n        added_nodes.add(group_rule_name)\n\n    rule_names_label: 'list[str]' = [\n        append_cleanup_rule_if_needed(rule_name) for rule_name in rule_names_in_group\n    ]\n\n    #############################\n    # boolean_expression_simplify\n    #\n    # simplify_not_false\n    # simplify_not_true\n    # ...\n    #############################\n    node_label = rule_name + '\\\\n\\\\n' + '\\\\n'.join(rule_names_label)\n\n    graph.node(rule_name, node_label, shape='record')\n\n\ndef append_cleanup_rule_if_needed(rule_name: str) -> str:\n    \"\"\"\n    Should be called for rules under a group.\n\n    If a rule is a cleanup rule, we append the label to the node's name *on the same line*.\n    Cleanup Rules are treated differently because:\n      1) Currently, there are no edges to `Cleanup Rule` (as opposed to other groups)\n      2) nodes may have another group with incoming/outgoing edges.\n\n    We want to display rules under a group which indicates flow (i.e., has edges).\n    At the same time, we still want to indicate in the graph that a rule is a cleanup rule.\n    \"\"\"\n    if rule_name in cleanup_rules:\n        return f'{rule_name} (Cleanup Rule)'\n    else:\n        return rule_name\n\n\ndef generate_node_for_rule_not_under_a_group(rule_name: str):\n    \"\"\"The rule will be a standalone node; we can add (Cleanup Rule) *on a new line* if needed.\"\"\"\n    if rule_name not in added_nodes:\n        if rule_name in dummy_nodes:\n            graph.node(rule_name, shape='doubleoctagon')\n        elif rule_name in cleanup_rules:\n            node_label = f'{rule_name}\\\\n(Cleanup Rule)'\n            graph.node(rule_name, node_label)\n        else:\n            graph.node(rule_name)\n\n\ndef generate_nodes_without_groups_and_no_outgoing_edges():\n    # nodes that don't have any group, not even 'Cleanup_Rule'\n    # and also no outgoing edge\n    # i.e., leaf nodes with no groups -> standalone shape\n    for node in nodes_without_groups:\n        # avoid adding a node already added through an edge\n        if node not in added_nodes:\n            added_nodes.add(node)\n            graph.node(node)\n\n\ndef generate_graph_edges():\n    for node, edges in outgoing_edges_by_node.items():\n        for edge in edges:\n            graph.edge(node, edge.to, edge.scope)\n\n\n###########\n# Arguments\nexample_text = '''For a complete output, the script needs the directory with the built-in rules for a given language. Example:\n\n        python visualize_rules_graph.py ./ff_cleanup.dot src/cleanup_rules/java demo/feature_flag_cleanup/java/configurations --title \"Feature Flag Cleanup\"\n\n    Experimental:\n        The generated graph may end very wide if you have several rules with no outgoing edges.\n        You can experiment passing the `--unflatten` option and changing the values of `--stagger` (https://graphviz.readthedocs.io/en/stable/manual.html#unflatten).\n        Another option is to manually edit the generated .dot file to include invisible edges (https://stackoverflow.com/a/11136488/1008952).\n    '''\n\ndescription_text = '''Script to output a .dot graph and svg image for visualizing how rules/groups are connected.\nPlease install the `toml` PyPi package: `python install toml`.\nPlease install the `graphviz` PyPi package: `python install graphviz`.\n\nThe script assumes that rules will have at most [0,2] groups. If a rule has two groups, one will be `Cleanup Rule`. The visualization will likely break if any rule has > 2 groups.'''\n\narg_parser = argparse.ArgumentParser(\n    description=description_text, epilog=example_text, formatter_class=argparse.RawDescriptionHelpFormatter)\narg_parser.add_argument('output_file_path', type=str,\n                        help=\"Path and file name/extension for the output file.\")\narg_parser.add_argument('configurations_path', type=str, nargs='+',\n                        help=\"One or more root directory that contains 'rules.toml' and 'edges.toml'\")\narg_parser.add_argument('--title', nargs='?', default='',\n                        help='Optional title for the graph')\narg_parser.add_argument('--unflatten', action='store_true', default=False)\narg_parser.add_argument('--stagger', nargs='?', default=2, const=2, type=int)\nargs = arg_parser.parse_args()\n\n###########\n# Execution\nrules_by_group_dict: 'dict[str, list[str]]' = {}\noutgoing_edges_by_node: 'dict[str, list[Edge]]' = {}\n\ncleanup_rules: 'set[str]' = set()\nnodes_without_groups: 'set[str]' = set()\n# nodes without `query`\ndummy_nodes: 'set[str]' = set()\n\noutput_file_path = os.path.abspath(args.output_file_path)\n\nif os.path.isdir(output_file_path):\n    raise ValueError(\n        'output_file_path (first arg) should be a file, not a directory')\n\noutput_dir_path = os.path.dirname(output_file_path)\nif not os.path.exists(output_dir_path):\n    os.makedirs(output_dir_path)\n\ncollect_rules_groups_edges()\n\ngraph = initialize_graph()\nadded_nodes: 'set[str]' = set()\ngenerate_graph_nodes()\ngenerate_graph_edges()\n\nif args.unflatten:\n    graph.unflatten(stagger=args.stagger).render()\nelse:\n    graph.render()\n\n"
        }
      ]
    }
  ]
}