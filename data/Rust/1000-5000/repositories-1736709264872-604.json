{
  "metadata": {
    "timestamp": 1736709264872,
    "page": 604,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjYxMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "J-F-Liu/lopdf",
      "stars": 1709,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".chglog",
          "type": "tree",
          "content": null
        },
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 0.189453125,
          "content": "root = true\n\n[*]\nend_of_line = lf\ncharset = utf-8\ntrim_trailing_whitespace = true\ninsert_final_newline = true\nindent_style = space\nindent_size = 4\n\n[*.{md,pdf}]\ntrim_trailing_whitespace = false\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.146484375,
          "content": "*          text eol=lf\n\n*.rs       text diff=rust\n*.toml     text diff=toml\n*.pdf      binary\nCargo.lock text\n*.jpg binary\n*.jpeg binary\n*.png binary\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0380859375,
          "content": "target\nCargo.lock\ntest*.pdf\n.idea\n*.pdf"
        },
        {
          "name": ".vscode",
          "type": "tree",
          "content": null
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 24.71875,
          "content": "\n<a name=\"v0.34.0\"></a>\n## [v0.34.0](https://github.com/J-F-Liu/lopdf/compare/v0.33.0...v0.34.0) (2024-08-31)\n\n### Add\n\n* Add ASCII85 decoding ([#317](https://github.com/J-F-Liu/lopdf/issues/317))\n* Add text extraction based on ToUnicode cmap  ([#314](https://github.com/J-F-Liu/lopdf/issues/314))\n* Add error handling to object stream ([#299](https://github.com/J-F-Liu/lopdf/issues/299))\n* Add PDFDocEncoding ([#296](https://github.com/J-F-Liu/lopdf/issues/296))\n\n### Cleanup\n\n* Cleanup comments and cargo fmt ([#290](https://github.com/J-F-Liu/lopdf/issues/290))\n\n### Detect\n\n* Detect reference cycles when going through trailers ([#308](https://github.com/J-F-Liu/lopdf/issues/308))\n* Detect reference cycles when parsing streams (with nom_parser) ([#300](https://github.com/J-F-Liu/lopdf/issues/300))\n* Detect reference cycles when collecting page resources ([#298](https://github.com/J-F-Liu/lopdf/issues/298))\n\n### Fix\n\n* Fix unicode fonts extraction in extract text example. ([#315](https://github.com/J-F-Liu/lopdf/issues/315))\n* Fix clippy warings\n\n### Implement\n\n* Implement encoding and decoding of text strings (PDF1.7 section 7.9.2.2) ([#297](https://github.com/J-F-Liu/lopdf/issues/297))\n\n### Improve\n\n* Improve error handling ([#307](https://github.com/J-F-Liu/lopdf/issues/307))\n\n### Refactor\n\n* Refactor get_or_create_resources() ([#291](https://github.com/J-F-Liu/lopdf/issues/291))\n\n### Release\n\n* Release 0.34\n\n### Replace\n\n* Replace unwrap with returning error ([#310](https://github.com/J-F-Liu/lopdf/issues/310))\n* Replace LinkedHashMap with IndexMap ([#293](https://github.com/J-F-Liu/lopdf/issues/293))\n\n### Update\n\n* Update dependencies ([#309](https://github.com/J-F-Liu/lopdf/issues/309))\n* Update readme of pdfutil ([#295](https://github.com/J-F-Liu/lopdf/issues/295))\n\n\n<a name=\"v0.33.0\"></a>\n## [v0.33.0](https://github.com/J-F-Liu/lopdf/compare/v0.32.0...v0.33.0) (2024-08-31)\n\n### Accept\n\n* Accept comments in content parsing ([#261](https://github.com/J-F-Liu/lopdf/issues/261))\n\n### Added\n\n* Added a new feature to get images info from the pdf page. ([#275](https://github.com/J-F-Liu/lopdf/issues/275))\n\n### Async\n\n* Async Examples ([#266](https://github.com/J-F-Liu/lopdf/issues/266))\n\n### AsyncReader\n\n* AsyncReader ([#265](https://github.com/J-F-Liu/lopdf/issues/265))\n\n### Fix\n\n* Fix parse outline failed, the key ’D‘ might be an object id ([#274](https://github.com/J-F-Liu/lopdf/issues/274))\n* Fix parse outline failed([#270](https://github.com/J-F-Liu/lopdf/issues/270)) ([#271](https://github.com/J-F-Liu/lopdf/issues/271))\n\n### Indexmap\n\n* indexmap use in TOC for sorted TOC ([#267](https://github.com/J-F-Liu/lopdf/issues/267))\n\n### Release\n\n* Release 0.33\n\n### Replace\n\n* Replace md5 with md-5 ([#272](https://github.com/J-F-Liu/lopdf/issues/272))\n\n\n<a name=\"v0.32.0\"></a>\n## [v0.32.0](https://github.com/J-F-Liu/lopdf/compare/v0.31.0...v0.32.0) (2024-08-31)\n\n### Add\n\n* Add debug format for hexadecimal ([#240](https://github.com/J-F-Liu/lopdf/issues/240))\n\n### Added\n\n* Added big generation value parsing ([#257](https://github.com/J-F-Liu/lopdf/issues/257))\n\n### Added\n\n* added object parse to get_page_fonts ([#249](https://github.com/J-F-Liu/lopdf/issues/249))\n* added meta info decryption ([#237](https://github.com/J-F-Liu/lopdf/issues/237))\n\n### Fix\n\n* Fix clippy warning and format code\n* Fix clippy warnings\n* Fix typo in README.md ([#251](https://github.com/J-F-Liu/lopdf/issues/251))\n\n### Fixed\n\n* Fixed parsing of the PDFs with incorrect xrefs to indirect objects ([#254](https://github.com/J-F-Liu/lopdf/issues/254))\n\n### Fixed\n\n* fixed clippy issues ([#238](https://github.com/J-F-Liu/lopdf/issues/238))\n\n### Handle\n\n* Handle references to arrays in get_page_contents() ([#245](https://github.com/J-F-Liu/lopdf/issues/245))\n\n### Object\n\n* Object and related types implement PartialEq ([#236](https://github.com/J-F-Liu/lopdf/issues/236))\n\n### Release\n\n* Release 0.32\n\n\n<a name=\"v0.31.0\"></a>\n## [v0.31.0](https://github.com/J-F-Liu/lopdf/compare/v0.30.0...v0.31.0) (2023-05-10)\n\n### Add\n\n* Add example of page rotation ([#230](https://github.com/J-F-Liu/lopdf/issues/230))\n* Add decryption of documents using RC4 encryption. ([#228](https://github.com/J-F-Liu/lopdf/issues/228))\n\n### Annotate\n\n* Annotate feature usage ([#229](https://github.com/J-F-Liu/lopdf/issues/229))\n\n### Fix\n\n* Fix typo in README.md ([#233](https://github.com/J-F-Liu/lopdf/issues/233))\n\n### PDF\n\n* PDF 2.0 is now a free specification\n\n### Release\n\n* Release 0.31\n\n### Remove\n\n* Remove extraneous `Q` operation from insert_image ([#227](https://github.com/J-F-Liu/lopdf/issues/227))\n\n\n<a name=\"v0.30.0\"></a>\n## [v0.30.0](https://github.com/J-F-Liu/lopdf/compare/v0.29.0...v0.30.0) (2023-04-09)\n\n### Add\n\n* Add support for extracting TOC, Outlines and NamedDestinations ([#211](https://github.com/J-F-Liu/lopdf/issues/211))\n* Add example extract_text ([#212](https://github.com/J-F-Liu/lopdf/issues/212))\n* Add get_encrypted and is_encrypted ([#210](https://github.com/J-F-Liu/lopdf/issues/210))\n* Add load_filtered method ([#198](https://github.com/J-F-Liu/lopdf/issues/198))\n* Add as_string method to Object ([#196](https://github.com/J-F-Liu/lopdf/issues/196))\n\n### Adding\n\n* Adding Comments to examples ([#220](https://github.com/J-F-Liu/lopdf/issues/220))\n\n### Fix\n\n* Fix clippy warning\n* Fix cliippy warnings\n* Fix datetime using time crate\n* Fix Cargo.toml ([#213](https://github.com/J-F-Liu/lopdf/issues/213))\n* Fix ci build issue ([#209](https://github.com/J-F-Liu/lopdf/issues/209))\n* Fix extract_text to split text at word boundaries.\n* Fix embed_image feature\n\n### Make\n\n* Make some more objects public. ([#199](https://github.com/J-F-Liu/lopdf/issues/199))\n\n### Readd\n\n* Readd accidently deleted pdf files in assets ([#204](https://github.com/J-F-Liu/lopdf/issues/204))\n\n### Release\n\n* Release 0.30\n\n### Remove\n\n* Remove obsolete lifetime\n\n### Replace\n\n* Replace unmaitained encoding crate with encoding_rs ([#222](https://github.com/J-F-Liu/lopdf/issues/222))\n\n### Set\n\n* Set default to nom_parser and rayon ([#208](https://github.com/J-F-Liu/lopdf/issues/208))\n\n### Update\n\n* Update time dependency ([#206](https://github.com/J-F-Liu/lopdf/issues/206))\n* Update nom dependency\n* Update time dependency\n* Update edition and some dependencies.\n\n\n<a name=\"v0.29.0\"></a>\n## [v0.29.0](https://github.com/J-F-Liu/lopdf/compare/v0.27.0...v0.29.0) (2023-04-09)\n\n### Add\n\n* Add function get_page_annotations and include an example ([#184](https://github.com/J-F-Liu/lopdf/issues/184))\n\n### Added\n\n* Added documentation and improved tests ([#178](https://github.com/J-F-Liu/lopdf/issues/178))\n\n### Allow\n\n* Allow mutable access to the document catalog ([#189](https://github.com/J-F-Liu/lopdf/issues/189))\n\n### Extend\n\n* Extend match layout change and Full bookmark example in merge. ([#179](https://github.com/J-F-Liu/lopdf/issues/179))\n\n### Fix\n\n* Fix nom parser\n* Fix clippy warnings\n* Fix add_barcode example\n* Fix Incremental.pdf\n* Fix documentation issues and make README testable ([#171](https://github.com/J-F-Liu/lopdf/issues/171))\n* Fix pdfutil build error\n* Fix `extend` definition confusion bug ([#161](https://github.com/J-F-Liu/lopdf/issues/161))\n\n### Fixed\n\n* Fixed [#175](https://github.com/J-F-Liu/lopdf/issues/175) and some clippy issues.  ([#182](https://github.com/J-F-Liu/lopdf/issues/182))\n\n### Guard\n\n* Guard example based on if the \"parser\" feature is enabled ([#173](https://github.com/J-F-Liu/lopdf/issues/173))\n\n### Made\n\n* made XREF parser accept an optional space character after 'xref' ([#167](https://github.com/J-F-Liu/lopdf/issues/167))\n\n### Make\n\n* Make add_xobject follow references ([#187](https://github.com/J-F-Liu/lopdf/issues/187))\n* Make xref public ,fix line endings and Fix Xref output so Adobe will open them again. ([#181](https://github.com/J-F-Liu/lopdf/issues/181))\n\n### Merge\n\n* Merge branch 'master' of https://github.com/J-F-Liu/lopdf\n\n### Release\n\n* Release 0.29\n* Release 0.28\n\n### Remove\n\n* Remove --no-default-features test\n\n### Remove\n\n* remove unneccessary time 0.1 dependency ([#163](https://github.com/J-F-Liu/lopdf/issues/163))\n\n### Reorder\n\n* Reorder Pages before Renumbering Objects. ([#193](https://github.com/J-F-Liu/lopdf/issues/193))\n\n### Support\n\n* Support Incremental Updates ([#176](https://github.com/J-F-Liu/lopdf/issues/176))\n\n### Switch\n\n* switch to single-precision floating point ([#190](https://github.com/J-F-Liu/lopdf/issues/190))\n\n### Update\n\n* Update itoa dependency to 1.0 ([#162](https://github.com/J-F-Liu/lopdf/issues/162))\n\n\n<a name=\"v0.27.0\"></a>\n## [v0.27.0](https://github.com/J-F-Liu/lopdf/compare/v0.26.0...v0.27.0) (2021-12-16)\n\n### Add\n\n* Add GitHub Actions build matrix ([#127](https://github.com/J-F-Liu/lopdf/issues/127))\n* Add Change Log\n\n### Added\n\n* Added Object::as_float() to convert numerical values to float. ([#124](https://github.com/J-F-Liu/lopdf/issues/124))\n* Added Object::as_bool ([#123](https://github.com/J-F-Liu/lopdf/issues/123))\n\n### Avoid\n\n* Avoid panic when encounters negative stream length\n\n### Bookmarks\n\n* Bookmarks ([#135](https://github.com/J-F-Liu/lopdf/issues/135))\n\n### Change\n\n* Change indent_style to space\n\n### Check\n\n* Check stream length\n\n### Do\n\n* Do not limit Real precision to two digits ([#155](https://github.com/J-F-Liu/lopdf/issues/155))\n\n### Fix\n\n* Fix document save race in parser_aux::load_and_save and creator::create_document ([#151](https://github.com/J-F-Liu/lopdf/issues/151))\n* Fix clippy warnings & add clippy build job ([#128](https://github.com/J-F-Liu/lopdf/issues/128))\n\n### Preserve\n\n* Preserve the eol characters in literal strings ([#131](https://github.com/J-F-Liu/lopdf/issues/131))\n\n### Reduce\n\n* Reduce allocation by reusing the iterator ([#129](https://github.com/J-F-Liu/lopdf/issues/129))\n\n### Release\n\n* Release 0.27\n* Release pdfutil 0.4\n\n### Replace\n\n* Replace lzw with weezl ([#140](https://github.com/J-F-Liu/lopdf/issues/140))\n\n### Return\n\n* Return early on error in `Stream::filters` ([#130](https://github.com/J-F-Liu/lopdf/issues/130))\n\n### Unwrap\n\n* Unwrap the text ([#119](https://github.com/J-F-Liu/lopdf/issues/119))\n\n### Update\n\n* Update nom to 6.0 ([#126](https://github.com/J-F-Liu/lopdf/issues/126))\n\n\n<a name=\"v0.26.0\"></a>\n## [v0.26.0](https://github.com/J-F-Liu/lopdf/compare/v0.25.0...v0.26.0) (2020-09-29)\n\n### Add\n\n* Add as_str, as_str_mut methods to Object ([#107](https://github.com/J-F-Liu/lopdf/issues/107))\n\n### Dtoa\n\n* dtoa may write real number in exponential format which is not allowed in PDF\n\n### Genericize\n\n* Genericize Content to allow AsRef<[Operation]> ([#111](https://github.com/J-F-Liu/lopdf/issues/111))\n\n### Make\n\n* Make pom dependency optional (but default) ([#112](https://github.com/J-F-Liu/lopdf/issues/112))\n* Make rayon dependency optional ([#108](https://github.com/J-F-Liu/lopdf/issues/108))\n\n### Merge\n\n* Merge document PDF logic with some fixes ([#117](https://github.com/J-F-Liu/lopdf/issues/117))\n\n### Various\n\n* Various improvements, updated libraries and image features ([#118](https://github.com/J-F-Liu/lopdf/issues/118))\n\n\n<a name=\"v0.25.0\"></a>\n## [v0.25.0](https://github.com/J-F-Liu/lopdf/compare/v0.24.0...v0.25.0) (2020-06-25)\n\n### Add\n\n* add indexing checks ([#98](https://github.com/J-F-Liu/lopdf/issues/98))\n\n### Add\n\n* Add a test for [#93](https://github.com/J-F-Liu/lopdf/issues/93) ([#95](https://github.com/J-F-Liu/lopdf/issues/95))\n\n### Bugfix\n\n* Bugfix for xref_start. ([#105](https://github.com/J-F-Liu/lopdf/issues/105))\n\n### Check\n\n* check  that the buffer is big enough for startxref ([#93](https://github.com/J-F-Liu/lopdf/issues/93))\n\n### Create\n\n* Create rust.yml ([#104](https://github.com/J-F-Liu/lopdf/issues/104))\n\n### Extend\n\n* extend recursion limit to non-local references ([#100](https://github.com/J-F-Liu/lopdf/issues/100))\n\n### Fix\n\n* Fix compilation error&test error ([#102](https://github.com/J-F-Liu/lopdf/issues/102))\n\n### Keep\n\n* keep looking for the last pattern ([#94](https://github.com/J-F-Liu/lopdf/issues/94))\n\n### Limit\n\n* Limit allowed bracket depth. ([#97](https://github.com/J-F-Liu/lopdf/issues/97))\n\n### Limit\n\n* limit recursion to the number of objects ([#92](https://github.com/J-F-Liu/lopdf/issues/92))\n\n### Move\n\n* Move bracket depth checking into parsers. ([#101](https://github.com/J-F-Liu/lopdf/issues/101))\n\n### Release\n\n* Release 0.25\n\n### Return\n\n* Return Result from as_array_mut() ([#106](https://github.com/J-F-Liu/lopdf/issues/106))\n\n### Update\n\n* Update itoa and linked-hash-map ([#91](https://github.com/J-F-Liu/lopdf/issues/91))\n\n\n<a name=\"v0.24.0\"></a>\n## [v0.24.0](https://github.com/J-F-Liu/lopdf/compare/v0.23.0...v0.24.0) (2020-02-17)\n\n### Compute\n\n* Compute an accurate iterator size when the page tree is sane.\n\n### Fix\n\n* Fix datetime parser ([#89](https://github.com/J-F-Liu/lopdf/issues/89))\n\n### More\n\n* More permissive datetime parsing ([#90](https://github.com/J-F-Liu/lopdf/issues/90))\n\n### Release\n\n* Release 0.24\n\n### Validate\n\n* Validate expected id in pom parser.\n* Validate the expected id when reading indirect objects.\n\n\n<a name=\"v0.23.0\"></a>\n## [v0.23.0](https://github.com/J-F-Liu/lopdf/compare/v0.22.0...v0.23.0) (2019-07-14)\n\n### Adapt\n\n* Adapt pom parser.\n\n### Add\n\n* Add error descriptions.\n* Add a proper error type and remove some more panics.\n\n### Allow\n\n* Allow loading a document from a memory slice.\n\n### Avoid\n\n* Avoid allocating an intermediate collection for iteration.\n* Avoid unwraps when already returning an Option for failure.\n\n### Error\n\n* Error signaling around compression and image handling.\n\n### Escape\n\n* Escape fix ([#68](https://github.com/J-F-Liu/lopdf/issues/68))\n\n### Export\n\n* Export dereference function as it is useful for PDF consumers.\n* Export filters module.\n\n### Get_font_encoding\n\n* get_font_encoding seems more at home with Dictionary.\n\n### Handle\n\n* Handle stream filter chains ([#66](https://github.com/J-F-Liu/lopdf/issues/66))\n\n### Hex\n\n* Hex fix ([#67](https://github.com/J-F-Liu/lopdf/issues/67))\n\n### Implement\n\n* Implement LZW decompression.\n\n### Improve\n\n* Improve hex parsing performance.\n\n### Make\n\n* Make a page iterator.\n* Make Reader::read consume the Reader.\n* Make content operations faillible.\n\n### Protect\n\n* Protect against reference loops.\n* Protect against a corrupted page tree.\n\n### Refactor\n\n* Refactor a bit to allow a utility function.\n\n### Release\n\n* Release 0.23.0\n\n### Remove\n\n* Remove intermediate assignation.\n* Remove unsafe code around FilterType.\n* Remove unsafe code on get_object_mut.\n* Remove some 'if let' for readability.\n* Remove more panic paths in xref parsing.\n\n### Replace\n\n* Replace unwraps in processor.rs.\n\n### Return\n\n* Return results when appropriate.\n\n### Separate\n\n* Separate decompression into two functions.\n\n### Take\n\n* Take care of panic that I actually hit on the pom side.\n* Take care of creator.rs.\n\n### Unify\n\n* Unify buffer creation.\n\n### Use\n\n* Use lifetime ellision.\n* Use TryInto.\n* Use writeln where appropriate.\n* Use error enum in reader.\n* Use stable cloned.\n\n\n<a name=\"v0.22.0\"></a>\n## [v0.22.0](https://github.com/J-F-Liu/lopdf/compare/v0.21.0...v0.22.0) (2019-05-13)\n\n### Add\n\n* Add parsing benchmark.\n* Add nom dependency.\n\n### Also\n\n* Also test with nom parsing feature enabled.\n\n### Array\n\n* Array and dictionary parsing.\n\n### Avoid\n\n* Avoid using format! when writing.\n\n### Be\n\n* Be explicit about trait objects.\n\n### Boolean\n\n* Boolean and null parsing.\n\n### Content\n\n* Content parsing.\n\n### Duplicate\n\n* Duplicate pom parser for incremental replacement with nom 5.\n\n### Ease\n\n* Ease off on rayon a bit.\n\n### Escape\n\n* Escape sequence parsing.\n\n### Extern\n\n* extern crate is not required anymore with 2018 edition.\n\n### Fix\n\n* Fix last ugly parser.\n* Fix octal parser.\n* Fix pdfutil build\n\n### Float\n\n* Float parsing.\n\n### Header\n\n* Header parsing.\n\n### Hex\n\n* Hex string parsing.\n\n### Indirect\n\n* Indirect object and stream parsing.\n\n### Literal\n\n* Literal string syntax.\n\n### Make\n\n* Make sure Stream.start_position is relative to the whole file.\n\n### Merge\n\n* Merge remote-tracking branch 'upstream/master' into nom5\n* Merge remote-tracking branch 'upstream/master' into nom5\n\n### More\n\n* More 2018 edition lints.\n* More cleanup.\n* More cleanup.\n* More simplifications.\n\n### Object\n\n* Object id and reference parsing.\n\n### Octal\n\n* Octal and hexadecimal parsing.\n\n### Parallel\n\n* Parallel object stream parsing.\n\n### Rayon\n\n* Rayon usage proof of concept.\n\n### Release\n\n* Release 0.22.0\n\n### Remove\n\n* Remove pom dependency in tests.\n\n### Replace\n\n* Replace name parser.\n\n### Resolve\n\n* Resolve name collisions.\n\n### Simplify\n\n* Simplify lifetime annotations.\n\n### Slowly\n\n* Slowly replace the cute pom parser with nom.\n\n### Trailer\n\n* Trailer and xref start.\n\n### Turns\n\n* Turns out \"contained\" already exists in nom.\n\n### Unify\n\n* Unify both variants of the parsing functions.\n\n### Use\n\n* Use a BufWriter when saving to path.\n* Use parse_at(&self.buffer, offset) to read indirect_object\n* Use nom digit testing functions.\n* Use lifetime ellision.\n* Use nom sequence operators.\n\n### Useless\n\n* Useless move.\n\n### Xref\n\n* Xref stream and trailer parsing.\n* Xref parsing.\n\n\n<a name=\"v0.21.0\"></a>\n## [v0.21.0](https://github.com/J-F-Liu/lopdf/compare/v0.20.0...v0.21.0) (2019-04-26)\n\n### Avoid\n\n* Avoid allocating a String.\n\n### Check\n\n* Check offsets read from file to avoid panics\n* Check and correct Size entry of trailer dictionary\n\n### Clean\n\n* Clean up bytes_to_string, string_to_bytes iterators\n\n### Fix\n\n* Fix clippy warnings\n* Fix .editorconfig\n\n### Fixed\n\n* fixed finally\n\n### Redundant\n\n* Redundant imports with 2018 edition.\n\n### Release\n\n* Release 0.21.0\n\n### Update\n\n* Update example\n* Update Cargo.toml\n\n### Use\n\n* Use env_logger in pdfutil\n\n\n<a name=\"v0.20.0\"></a>\n## [v0.20.0](https://github.com/J-F-Liu/lopdf/compare/v0.19.0...v0.20.0) (2019-03-07)\n\n### Release\n\n* Release 0.20.0\n\n### Replace\n\n* Replace println with log macros\n\n### Use\n\n* Use Rust 2018\n* Use pom 3.0\n\n\n<a name=\"v0.19.0\"></a>\n## [v0.19.0](https://github.com/J-F-Liu/lopdf/compare/v0.18.0...v0.19.0) (2018-10-24)\n\n### Allow\n\n* Allow xref section has zero entries\n\n### Dictionary\n\n* Dictionary key type changed to Vec<u8>\n\n### Format\n\n* Format code with rustfmt\n\n### Improve\n\n* Improve codestyle (simplify loops, remove closures, use is_empty() etc.)\n\n### Move\n\n* Move image dependency to embed_image feature\n\n### Release\n\n* Release 0.19.0\n\n### Skip\n\n* Skip corrupt deflate stream\n\n\n<a name=\"v0.18.0\"></a>\n## [v0.18.0](https://github.com/J-F-Liu/lopdf/compare/v0.17.0...v0.18.0) (2018-10-05)\n\n### Able\n\n* Able to read stream when it's length is in object stream\n\n### Adress\n\n* Adress timezone formatting problem from [#34](https://github.com/J-F-Liu/lopdf/issues/34)\n\n### Insert\n\n* insert image on page\n\n\n<a name=\"v0.17.0\"></a>\n## [v0.17.0](https://github.com/J-F-Liu/lopdf/compare/v0.16.0...v0.17.0) (2018-09-19)\n\n### Make\n\n* Make chrono crate optional\n\n### Release\n\n* Release 0.17.0\n\n### Update\n\n* Update add_barcode example\n\n\n<a name=\"v0.16.0\"></a>\n## [v0.16.0](https://github.com/J-F-Liu/lopdf/compare/v0.15.3...v0.16.0) (2018-09-18)\n\n### Add\n\n* Add form xobject to page\n* Add extract_stream subcommand\n\n### Compress\n\n* Compress created Form xobject\n\n### Compress\n\n* compress page content after change\n\n### Fix\n\n* Fix collect_fonts_from_resources for referenced resources\n* Fix add xobject to page resources as direct object\n\n\n<a name=\"v0.15.3\"></a>\n## [v0.15.3](https://github.com/J-F-Liu/lopdf/compare/v0.15.0...v0.15.3) (2018-09-14)\n\n### Decompress\n\n* Decompress Form XObject\n\n### Disable\n\n* Disable auto format markdown\n\n### Fix\n\n* Fix bug in reading incremental updated document\n* Fix build warning\n* Fix string_to_bytes method\n\n### Hexadecimal\n\n* Hexadecimal strings can contain white space.\n\n### Remove\n\n* Remove println in extract_text\n\n### Update\n\n* Update example code\n* Update example\n\n\n<a name=\"v0.15.0\"></a>\n## [v0.15.0](https://github.com/J-F-Liu/lopdf/compare/v0.14.1...v0.15.0) (2018-02-04)\n\n### Add\n\n* add `get_object_mut`\n* add method as_array_mut\n\n### Extract\n\n* Extract text from specified pages\n\n### Replace\n\n* Replace text of specified page\n\n\n<a name=\"v0.14.1\"></a>\n## [v0.14.1](https://github.com/J-F-Liu/lopdf/compare/v0.13.0...v0.14.1) (2017-11-03)\n\n### Add\n\n* Add `impl From<_> for Object` for more numeric types\n* Add an Object::string_literal constructor\n* Add a `dictionary!` macro that creates a Dictionary\n* Add `impl From<ObjectId> for Object` creating Object::Reference\n\n### Derive\n\n* Derive Clone for lopdf::Document\n\n### Release\n\n* Release 0.14.0\n\n### Remove\n\n* Remove the Seek bound on Document::save_to\n\n\n<a name=\"v0.13.0\"></a>\n## [v0.13.0](https://github.com/J-F-Liu/lopdf/compare/v0.11.0...v0.13.0) (2017-10-02)\n\n### Avoid\n\n* Avoid decompress flate stream which has Subtype\n\n### Debug\n\n* Debug with lldb\n\n### Fix\n\n* Fix get_object for created document\n\n### Ignore\n\n* Ignore invalid objects when reading all object in xref table\n\n### Impl\n\n* impl fmt::Debug for Object\n\n### Pdfutil\n\n* pdfutil add extract_pages command\n\n### Read\n\n* Read optional space at the end of xref subsection header line\n\n### Release\n\n* Release 0.13.0\n* Release 0.12.0\n\n### Store\n\n* Store compressed stream objects and normal objects together\n\n\n<a name=\"v0.11.0\"></a>\n## [v0.11.0](https://github.com/J-F-Liu/lopdf/compare/v0.10.0...v0.11.0) (2017-08-21)\n\n### Release\n\n* Release 0.11.0\n\n### Use\n\n* Use itoa and dtoa to improve writing performance\n\n\n<a name=\"v0.10.0\"></a>\n## [v0.10.0](https://github.com/J-F-Liu/lopdf/compare/v0.9.0...v0.10.0) (2017-07-20)\n\n### Added\n\n* Added optional allows_compression for Stream object\n\n### Release\n\n* Release 0.10.0\n\n\n<a name=\"v0.9.0\"></a>\n## [v0.9.0](https://github.com/J-F-Liu/lopdf/compare/v0.8.0...v0.9.0) (2017-05-24)\n\n### Add\n\n* Add pdfutil readme\n\n### Added\n\n* Added unit test for load_from() and save_to()\n* Added Document::with_version + refactored save() and load()\n* Added Debug trait for lopdf::Document\n\n### Apply\n\n* Apply multiple operations in one command\n\n### Build\n\n* Build with Rust stable\n* Build with Rust beta\n\n### Fix\n\n* Fix delete_zero_length_streams\n\n### Fixed\n\n* Fixed unit tests\n* Fixed breaking API changes\n\n### Release\n\n* Release 0.9.0\n\n\n<a name=\"v0.8.0\"></a>\n## [v0.8.0](https://github.com/J-F-Liu/lopdf/compare/v0.7.0...v0.8.0) (2017-03-16)\n\n### Change\n\n* Change Name(String) to Name(Vec<u8>)\n\n### Delete_object\n\n* delete_object and delete_unused_objects\n\n### Get_pages\n\n* get_pages and delete_pages\n\n### Handle\n\n* Handle zero length stream\n\n### Release\n\n* Release 0.8.0\n\n### Traverse\n\n* Traverse objects from trailer recursively\n\n\n<a name=\"v0.7.0\"></a>\n## [v0.7.0](https://github.com/J-F-Liu/lopdf/compare/v0.6.0...v0.7.0) (2017-03-07)\n\n### Add\n\n* Add Content::decode() function\n\n### Build\n\n* Build on Rust 1.17\n\n### Create\n\n* Create String object for DateTime\n\n### Parse\n\n* Parse PDF datetime value\n\n### Read\n\n* Read xref stream in hybrid-reference file\n\n### Update\n\n* Update create_document example\n* Update README\n\n\n<a name=\"v0.6.0\"></a>\n## [v0.6.0](https://github.com/J-F-Liu/lopdf/compare/v0.5.0...v0.6.0) (2017-02-16)\n\n### Add\n\n* Add Stream::decompressed_content() method\n\n### Read\n\n* Read previous Xrefs of linearized or incremental updated document\n\n\n<a name=\"v0.5.0\"></a>\n## [v0.5.0](https://github.com/J-F-Liu/lopdf/compare/v0.4.0...v0.5.0) (2017-02-10)\n\n### Add\n\n* Add size field to Xref\n* Add Xref struct\n\n### Decode\n\n* Decode PNG frame after FlateDecode\n\n### Read\n\n* Read compressed objects from object stream\n* Read xref stream\n\n### Update\n\n* Update README\n\n### Use\n\n* Use pom 0.9.0\n\n### XrefEntry\n\n* XrefEntry as enum type\n\n\n<a name=\"v0.4.0\"></a>\n## [v0.4.0](https://github.com/J-F-Liu/lopdf/compare/v0.3.0...v0.4.0) (2017-01-29)\n\n### Add\n\n* Add Operation constructor\n* Add modify_text test\n* Add travis-ci build status\n* Add FAQ in Readme\n* Add print_xref_size() for debuging\n\n### Decode\n\n* Decode content stream\n\n### Encode\n\n* Encode content operations\n\n### Fix\n\n* Fix load_document test\n* Fix https://github.com/rust-lang/rust/issues/39177\n\n### Optimize\n\n* Optimize parser code\n\n### Solve\n\n* Solve mutual reference problem between Pages and Page objects\n\n### Trigger\n\n* Trigger new release to pass build on docs.rs\n\n### Update\n\n* Update create PDF example\n\n\n<a name=\"v0.3.0\"></a>\n## [v0.3.0](https://github.com/J-F-Liu/lopdf/compare/v0.2.0...v0.3.0) (2017-01-18)\n\n### Add\n\n* Add compress/decompress subcommands to pdfutil\n\n### Create\n\n* create PDF parser using pom instead of nom\n\n### Dictionary\n\n* Dictionary preserve key insert order\n\n### Update\n\n* Update README\n* Update parser to use pom 0.6.0\n\n### Use\n\n* Use reader to get stream length if it is a reference object\n\n\n<a name=\"v0.2.0\"></a>\n## [v0.2.0](https://github.com/J-F-Liu/lopdf/compare/v0.1.0...v0.2.0) (2017-01-05)\n\n### Add\n\n* Add pdfutil program\n\n### Fix\n\n* Fix parsing PDF array error\n\n### Improve\n\n* Improve documentation\n\n\n<a name=\"v0.1.0\"></a>\n## v0.1.0 (2016-12-23)\n\n### Editor\n\n* Editor config\n\n### Impl\n\n* impl Document add_object method\n\n### Improve\n\n* Improve Document::save functional type\n\n### Initial\n\n* Initial commit\n\n### PDF\n\n* PDF objects and document definition\n\n### Parse\n\n* Parse and load PDF document\n\n### Read\n\n* Read objects from xref table instead of sequentially from file stream\n\n### Save\n\n* Save PDF document to file\n\n### Store\n\n* Store max_id as a field of document\n\n"
        },
        {
          "name": "Cargo.toml",
          "type": "blob",
          "size": 1.8486328125,
          "content": "[package]\nauthors = [\n    \"Junfeng Liu <china.liujunfeng@gmail.com>\",\n    \"Emulator <emulator@hotmail.it>\",\n]\ncategories = [\"text-processing\"]\ndescription = \"A Rust library for PDF document manipulation.\"\ndocumentation = \"https://docs.rs/crate/lopdf/\"\nedition = \"2021\"\nhomepage = \"https://github.com/J-F-Liu/lopdf\"\nkeywords = [\"pdf\", \"editing\", \"manipulation\", \"merge\"]\nlicense = \"MIT\"\nname = \"lopdf\"\nreadme = \"README.md\"\nrepository = \"https://github.com/J-F-Liu/lopdf.git\"\nversion = \"0.34.0\"\nrust-version = \"1.74\"\n\n[dependencies]\naes = \"0.8.4\"\ncbc = \"0.1.2\"\nchrono = { version = \"0.4\", optional = true, default-features = false, features = [\n    \"std\",\n    \"clock\",\n] }\nencoding_rs = \"0.8.32\"\nflate2 = \"1.0\"\nimage = { version = \"0.25\", optional = true }\nindexmap = \"2.2.3\"\nitoa = \"1.0\"\nlog = \"0.4\"\nmd-5 = \"0.10\"\nnom = { version = \"7.1\", optional = true }\nnom_locate = { version = \"4.2.0\", optional = true }\nrangemap = \"1.5\"\nrayon = { version = \"1.6\", optional = true }\nserde = { version = \"1.0\", features = [\"derive\"], optional = true }\nthiserror = \"2.0.3\"\ntime = { version = \"0.3\", features = [\"formatting\", \"parsing\"] }\ntokio = { version = \"1\", features = [\"fs\", \"io-util\"], optional = true }\nweezl = \"0.1\"\n\n[dev-dependencies]\nclap = { version = \"4.0\", features = [\"derive\"] }\nenv_logger = \"0.11\"\nserde_json = \"1.0\"\nshellexpand = \"3.0\"\ntempfile = \"3.3\"\n\n[features]\nasync = [\"tokio/rt-multi-thread\", \"tokio/macros\"]\nchrono_time = [\"chrono\"]\ndefault = [\"chrono_time\", \"nom_parser\", \"rayon\"]\nembed_image = [\"image\"]\nnom_parser = [\"nom\", \"nom_locate\"]\nserde = [\"dep:serde\"]\n\n[[example]]\nname = \"extract_toc\"\nrequired-features = [\"serde\"]\n\n[[example]]\nname = \"extract_text\"\nrequired-features = [\"serde\"]\n\n[[example]]\nname = \"print_annotations\"\nrequired-features = [\"default\"]\n\n[[example]]\nname = \"rotate\"\nrequired-features = [\"nom_parser\"]\n\n[badges]\ntravis-ci = { repository = \"J-F-Liu/lopdf\" }\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.04296875,
          "content": "MIT License\n\nCopyright (c) 2016 Junfeng Liu\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 15.9228515625,
          "content": "# lopdf\n\n[![Crates.io](https://img.shields.io/crates/v/lopdf.svg)](https://crates.io/crates/lopdf)\n[![CI](https://github.com/J-F-Liu/lopdf/actions/workflows/ci.yml/badge.svg)](https://github.com/J-F-Liu/lopdf/actions/workflows/ci.yml)\n[![Docs]( https://docs.rs/lopdf/badge.svg)](https://docs.rs/lopdf)\n\nA Rust library for PDF document manipulation.\n\nA useful reference for understanding the PDF file format and the\neventual usage of this library is the\n[PDF 1.7 Reference Document](https://opensource.adobe.com/dc-acrobat-sdk-docs/pdfstandards/PDF32000_2008.pdf).\nThe PDF 2.0 specification is available [here](https://www.pdfa.org/announcing-no-cost-access-to-iso-32000-2-pdf-2-0/).\n\n## Example Code\n\n* Create PDF document\n\n```rust\nuse lopdf::dictionary;\nuse lopdf::{Document, Object, Stream};\nuse lopdf::content::{Content, Operation};\n\n// `with_version` specifes the PDF version this document complies with.\nlet mut doc = Document::with_version(\"1.5\");\n// Object IDs are used for cross referencing in PDF documents.\n// `lopdf` helps keep track of them for us. They are simple integers.\n// Calls to `doc.new_object_id` and `doc.add_object` return an object ID.\n\n// \"Pages\" is the root node of the page tree.\nlet pages_id = doc.new_object_id();\n\n// Fonts are dictionaries. The \"Type\", \"Subtype\" and \"BaseFont\" tags\n// are straight out of the PDF spec.\n//\n// The dictionary macro is a helper that allows complex\n// key-value relationships to be represented in a simpler\n// visual manner, similar to a match statement.\n// A dictionary is implemented as an IndexMap of Vec<u8>, and Object\nlet font_id = doc.add_object(dictionary! {\n    // type of dictionary\n    \"Type\" => \"Font\",\n    // type of font, type1 is simple postscript font\n    \"Subtype\" => \"Type1\",\n    // basefont is postscript name of font for type1 font.\n    // See PDF reference document for more details\n    \"BaseFont\" => \"Courier\",\n});\n\n// Font dictionaries need to be added into resource\n// dictionaries in order to be used.\n// Resource dictionaries can contain more than just fonts,\n// but normally just contains fonts.\n// Only one resource dictionary is allowed per page tree root.\nlet resources_id = doc.add_object(dictionary! {\n    // Fonts are actually triplely nested dictionaries. Fun!\n    \"Font\" => dictionary! {\n        // F1 is the font name used when writing text.\n        // It must be unique in the document. It does not\n        // have to be F1\n        \"F1\" => font_id,\n    },\n});\n\n// `Content` is a wrapper struct around an operations struct that contains\n// a vector of operations. The operations struct contains a vector of\n// that match up with a particular PDF operator and operands.\n// Refer to the PDF spec for more details on the operators and operands\n// Note, the operators and operands are specified in a reverse order\n// from how they actually appear in the PDF file itself.\nlet content = Content {\n    operations: vec![\n        // BT begins a text element. It takes no operands.\n        Operation::new(\"BT\", vec![]),\n        // Tf specifies the font and font size.\n        // Font scaling is complicated in PDFs.\n        // Refer to the spec for more info.\n        // The `into()` methods convert the types into\n        // an enum that represents the basic object types in PDF documents.\n        Operation::new(\"Tf\", vec![\"F1\".into(), 48.into()]),\n        // Td adjusts the translation components of the text matrix.\n        // When used for the first time after BT, it sets the initial\n        // text position on the page.\n        // Note: PDF documents have Y=0 at the bottom. Thus 600 to print text near the top.\n        Operation::new(\"Td\", vec![100.into(), 600.into()]),\n        // Tj prints a string literal to the page. By default, this is black text that is\n        // filled in. There are other operators that can produce various textual effects and\n        // colors\n        Operation::new(\"Tj\", vec![Object::string_literal(\"Hello World!\")]),\n        // ET ends the text element.\n        Operation::new(\"ET\", vec![]),\n    ],\n};\n\n// Streams are a dictionary followed by a (possibly encoded) sequence of bytes.\n// What that sequence of bytes represents, depends on the context.\n// The stream dictionary is set internally by lopdf and normally doesn't\n// need to be manually manipulated. It contains keys such as\n// Length, Filter, DecodeParams, etc.\nlet content_id = doc.add_object(Stream::new(dictionary! {}, content.encode().unwrap()));\n\n// Page is a dictionary that represents one page of a PDF file.\n// Its required fields are \"Type\", \"Parent\" and \"Contents\".\nlet page_id = doc.add_object(dictionary! {\n    \"Type\" => \"Page\",\n    \"Parent\" => pages_id,\n    \"Contents\" => content_id,\n});\n\n// Again, \"Pages\" is the root of the page tree. The ID was already created\n// at the top of the page, since we needed it to assign to the parent element\n// of the page dictionary.\n//\n// These are just the basic requirements for a page tree root object.\n// There are also many additional entries that can be added to the dictionary,\n// if needed. Some of these can also be defined on the page dictionary itself,\n// and not inherited from the page tree root.\nlet pages = dictionary! {\n    // Type of dictionary\n    \"Type\" => \"Pages\",\n    // Vector of page IDs in document. Normally would contain more than one ID\n    // and be produced using a loop of some kind.\n    \"Kids\" => vec![page_id.into()],\n    // Page count\n    \"Count\" => 1,\n    // ID of resources dictionary, defined earlier\n    \"Resources\" => resources_id,\n    // A rectangle that defines the boundaries of the physical or digital media.\n    // This is the \"page size\".\n    \"MediaBox\" => vec![0.into(), 0.into(), 595.into(), 842.into()],\n};\n\n// Using `insert()` here, instead of `add_object()` since the ID is already known.\ndoc.objects.insert(pages_id, Object::Dictionary(pages));\n\n// Creating document catalog.\n// There are many more entries allowed in the catalog dictionary.\nlet catalog_id = doc.add_object(dictionary! {\n    \"Type\" => \"Catalog\",\n    \"Pages\" => pages_id,\n});\n\n// The \"Root\" key in trailer is set to the ID of the document catalog,\n// the remainder of the trailer is set during `doc.save()`.\ndoc.trailer.set(\"Root\", catalog_id);\ndoc.compress();\n\n// Store file in current working directory.\n// Note: Line is excluded when running tests\nif false {\n    doc.save(\"example.pdf\").unwrap();\n}\n```\n\n* Merge PDF documents\n\n```rust\nuse lopdf::dictionary;\n\nuse std::collections::BTreeMap;\n\nuse lopdf::content::{Content, Operation};\nuse lopdf::{Document, Object, ObjectId, Stream, Bookmark};\n\npub fn generate_fake_document() -> Document {\n    let mut doc = Document::with_version(\"1.5\");\n    let pages_id = doc.new_object_id();\n    let font_id = doc.add_object(dictionary! {\n        \"Type\" => \"Font\",\n        \"Subtype\" => \"Type1\",\n        \"BaseFont\" => \"Courier\",\n    });\n    let resources_id = doc.add_object(dictionary! {\n        \"Font\" => dictionary! {\n            \"F1\" => font_id,\n        },\n    });\n    let content = Content {\n        operations: vec![\n            Operation::new(\"BT\", vec![]),\n            Operation::new(\"Tf\", vec![\"F1\".into(), 48.into()]),\n            Operation::new(\"Td\", vec![100.into(), 600.into()]),\n            Operation::new(\"Tj\", vec![Object::string_literal(\"Hello World!\")]),\n            Operation::new(\"ET\", vec![]),\n        ],\n    };\n    let content_id = doc.add_object(Stream::new(dictionary! {}, content.encode().unwrap()));\n    let page_id = doc.add_object(dictionary! {\n        \"Type\" => \"Page\",\n        \"Parent\" => pages_id,\n        \"Contents\" => content_id,\n        \"Resources\" => resources_id,\n        \"MediaBox\" => vec![0.into(), 0.into(), 595.into(), 842.into()],\n    });\n    let pages = dictionary! {\n        \"Type\" => \"Pages\",\n        \"Kids\" => vec![page_id.into()],\n        \"Count\" => 1,\n    };\n    doc.objects.insert(pages_id, Object::Dictionary(pages));\n    let catalog_id = doc.add_object(dictionary! {\n        \"Type\" => \"Catalog\",\n        \"Pages\" => pages_id,\n    });\n    doc.trailer.set(\"Root\", catalog_id);\n\n    doc\n}\n\nfn main() -> std::io::Result<()> {\n    // Generate a stack of Documents to merge.\n    let documents = vec![\n        generate_fake_document(),\n        generate_fake_document(),\n        generate_fake_document(),\n        generate_fake_document(),\n    ];\n\n    // Define a starting `max_id` (will be used as start index for object_ids).\n    let mut max_id = 1;\n    let mut pagenum = 1;\n    // Collect all Documents Objects grouped by a map\n    let mut documents_pages = BTreeMap::new();\n    let mut documents_objects = BTreeMap::new();\n    let mut document = Document::with_version(\"1.5\");\n\n    for mut doc in documents {\n        let mut first = false;\n        doc.renumber_objects_with(max_id);\n\n        max_id = doc.max_id + 1;\n\n        documents_pages.extend(\n            doc\n                    .get_pages()\n                    .into_iter()\n                    .map(|(_, object_id)| {\n                        if !first {\n                            let bookmark = Bookmark::new(String::from(format!(\"Page_{}\", pagenum)), [0.0, 0.0, 1.0], 0, object_id);\n                            document.add_bookmark(bookmark, None);\n                            first = true;\n                            pagenum += 1;\n                        }\n\n                        (\n                            object_id,\n                            doc.get_object(object_id).unwrap().to_owned(),\n                        )\n                    })\n                    .collect::<BTreeMap<ObjectId, Object>>(),\n        );\n        documents_objects.extend(doc.objects);\n    }\n\n    // \"Catalog\" and \"Pages\" are mandatory.\n    let mut catalog_object: Option<(ObjectId, Object)> = None;\n    let mut pages_object: Option<(ObjectId, Object)> = None;\n\n    // Process all objects except \"Page\" type\n    for (object_id, object) in documents_objects.iter() {\n        // We have to ignore \"Page\" (as are processed later), \"Outlines\" and \"Outline\" objects.\n        // All other objects should be collected and inserted into the main Document.\n        match object.type_name().unwrap_or(b\"\") {\n            b\"Catalog\" => {\n                // Collect a first \"Catalog\" object and use it for the future \"Pages\".\n                catalog_object = Some((\n                    if let Some((id, _)) = catalog_object {\n                        id\n                    } else {\n                        *object_id\n                    },\n                    object.clone(),\n                ));\n            }\n            b\"Pages\" => {\n                // Collect and update a first \"Pages\" object and use it for the future \"Catalog\"\n                // We have also to merge all dictionaries of the old and the new \"Pages\" object\n                if let Ok(dictionary) = object.as_dict() {\n                    let mut dictionary = dictionary.clone();\n                    if let Some((_, ref object)) = pages_object {\n                        if let Ok(old_dictionary) = object.as_dict() {\n                            dictionary.extend(old_dictionary);\n                        }\n                    }\n\n                    pages_object = Some((\n                        if let Some((id, _)) = pages_object {\n                            id\n                        } else {\n                            *object_id\n                        },\n                        Object::Dictionary(dictionary),\n                    ));\n                }\n            }\n            b\"Page\" => {}     // Ignored, processed later and separately\n            b\"Outlines\" => {} // Ignored, not supported yet\n            b\"Outline\" => {}  // Ignored, not supported yet\n            _ => {\n                document.objects.insert(*object_id, object.clone());\n            }\n        }\n    }\n\n    // If no \"Pages\" object found, abort.\n    if pages_object.is_none() {\n        println!(\"Pages root not found.\");\n\n        return Ok(());\n    }\n\n    // Iterate over all \"Page\" objects and collect into the parent \"Pages\" created before\n    for (object_id, object) in documents_pages.iter() {\n        if let Ok(dictionary) = object.as_dict() {\n            let mut dictionary = dictionary.clone();\n            dictionary.set(\"Parent\", pages_object.as_ref().unwrap().0);\n\n            document\n                    .objects\n                    .insert(*object_id, Object::Dictionary(dictionary));\n        }\n    }\n\n    // If no \"Catalog\" found, abort.\n    if catalog_object.is_none() {\n        println!(\"Catalog root not found.\");\n\n        return Ok(());\n    }\n\n    let catalog_object = catalog_object.unwrap();\n    let pages_object = pages_object.unwrap();\n\n    // Build a new \"Pages\" with updated fields\n    if let Ok(dictionary) = pages_object.1.as_dict() {\n        let mut dictionary = dictionary.clone();\n\n        // Set new pages count\n        dictionary.set(\"Count\", documents_pages.len() as u32);\n\n        // Set new \"Kids\" list (collected from documents pages) for \"Pages\"\n        dictionary.set(\n            \"Kids\",\n            documents_pages\n                    .into_iter()\n                    .map(|(object_id, _)| Object::Reference(object_id))\n                    .collect::<Vec<_>>(),\n        );\n\n        document\n                .objects\n                .insert(pages_object.0, Object::Dictionary(dictionary));\n    }\n\n    // Build a new \"Catalog\" with updated fields\n    if let Ok(dictionary) = catalog_object.1.as_dict() {\n        let mut dictionary = dictionary.clone();\n        dictionary.set(\"Pages\", pages_object.0);\n        dictionary.remove(b\"Outlines\"); // Outlines not supported in merged PDFs\n\n        document\n                .objects\n                .insert(catalog_object.0, Object::Dictionary(dictionary));\n    }\n\n    document.trailer.set(\"Root\", catalog_object.0);\n\n    // Update the max internal ID as wasn't updated before due to direct objects insertion\n    document.max_id = document.objects.len() as u32;\n\n    // Reorder all new Document objects\n    document.renumber_objects();\n\n    // Set any Bookmarks to the First child if they are not set to a page\n    document.adjust_zero_pages();\n\n    // Set all bookmarks to the PDF Object tree then set the Outlines to the Bookmark content map.\n    if let Some(n) = document.build_outline() {\n        if let Ok(Object::Dictionary(dict)) = document.get_object_mut(catalog_object.0) {\n            dict.set(\"Outlines\", Object::Reference(n));\n        }\n    }\n\n    document.compress();\n\n    // Save the merged PDF.\n    // Store file in current working directory.\n    // Note: Line is excluded when running doc tests\n    if false {\n        document.save(\"merged.pdf\").unwrap();\n    }\n\n    Ok(())\n}\n```\n\n* Modify PDF document\n\n```rust\nuse lopdf::Document;\n\n// For this example to work a parser feature needs to be enabled\n#[cfg(not(feature = \"async\"))]\n#[cfg(feature = \"nom_parser\")]\n{\n    let mut doc = Document::load(\"assets/example.pdf\").unwrap();\n\n    doc.version = \"1.4\".to_string();\n    doc.replace_text(1, \"Hello World!\", \"Modified text!\");\n    // Store file in current working directory.\n    // Note: Line is excluded when running tests\n    if false {\n        doc.save(\"modified.pdf\").unwrap();\n    }\n}\n\n#[cfg(feature = \"async\")]\n#[cfg(feature = \"nom_parser\")]\n{\n    tokio::runtime::Builder::new_current_thread()\n        .build()\n        .expect(\"Failed to create runtime\")\n        .block_on(async move {\n            let mut doc = Document::load(\"assets/example.pdf\").await.unwrap();\n            \n            doc.version = \"1.4\".to_string();\n            doc.replace_text(1, \"Hello World!\", \"Modified text!\");\n            // Store file in current working directory.\n            // Note: Line is excluded when running tests\n            if false {\n                doc.save(\"modified.pdf\").unwrap();\n            }\n    });\n}\n```\n\n## FAQ\n\n* Why does the library keep everything in memory as high-level objects until finally serializing the entire document?\n\n    Normally, a PDF document won't be very large, ranging from tens of KB to hundreds of MB. Memory size is not a bottle neck for today's computer.\n    By keeping the whole document in memory, the stream length can be pre-calculated, no need to use a reference object for the Length entry.\n    The resulting PDF file is smaller for distribution and faster for PDF consumers to process.\n\n    Producing is a one-time effort, while consuming is many more.\n"
        },
        {
          "name": "assets",
          "type": "tree",
          "content": null
        },
        {
          "name": "benches",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "pdfutil",
          "type": "tree",
          "content": null
        },
        {
          "name": "rustfmt.toml",
          "type": "blob",
          "size": 0.1318359375,
          "content": "format_strings = false\nreorder_imports = true\nfn_params_layout = \"Compressed\"\nmax_width = 120\ncomment_width = 120\nwrap_comments = true\n"
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}