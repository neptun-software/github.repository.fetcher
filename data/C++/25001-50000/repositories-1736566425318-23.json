{
  "metadata": {
    "timestamp": 1736566425318,
    "page": 23,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjMw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "facebook/rocksdb",
      "stars": 28948,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 0.134765625,
          "content": "# Complete list of style options can be found at: \n# http://clang.llvm.org/docs/ClangFormatStyleOptions.html\n---\nBasedOnStyle: Google\n...\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.048828125,
          "content": "make_config.mk\nrocksdb.pc\n\n*.a\n*.arc\n*.d\n*.dylib*\n*.gcda\n*.gcno\n*.o\n*.o.tmp\n*.so\n*.so.*\n*_test\n*_bench\n*_stress\n*.out\n*.class\n*.jar\n*.*jnilib*\n*.d-e\n*.o-*\n*.swp\n*~\n*.vcxproj\n*.vcxproj.filters\n*.sln\n*.cmake\n.watchmanconfig\nCMakeCache.txt\nCMakeFiles/\nbuild/\n\nldb\nmanifest_dump\nsst_dump\nblob_dump\nblock_cache_trace_analyzer\ntools/block_cache_analyzer/*.pyc\ncolumn_aware_encoding_exp\nutil/build_version.cc\nbuild_tools/VALGRIND_LOGS/\ncoverage/COVERAGE_REPORT\n.gdbhistory\n.gdb_history\npackage/\nunity.a\ntags\netags\nGPATH\nGRTAGS\nGTAGS\nrocksdb_dump\nrocksdb_undump\ndb_test2\ntrace_analyzer\nblock_cache_trace_analyzer\nio_tracer_parser\n.DS_Store\n.vs\n.vscode\n.clangd\n\njava/out\njava/target\njava/test-libs\njava/*.log\njava/include/org_rocksdb_*.h\n\n.idea/\n*.iml\n\nrocksdb.cc\nrocksdb.h\nunity.cc\njava/crossbuild/.vagrant\n.vagrant/\njava/**/*.asc\njava/javadoc\n\nscan_build_report/\nt\nLOG\n\ndb_logs/\ntp2/\nfbcode/\nfbcode\nbuckifier/*.pyc\nbuckifier/__pycache__\n.arcconfig\n\ncompile_commands.json\nclang-format-diff.py\n.py3/\n\nfuzz/proto/gen/\nfuzz/crash-*\n\ncmake-build-*\nthird-party/folly/\n.cache\n*.sublime-*\n"
        },
        {
          "name": ".lgtm.yml",
          "type": "blob",
          "size": 0.0654296875,
          "content": "extraction:\n  cpp:\n    index:\n      build_command: make static_lib\n"
        },
        {
          "name": ".watchmanconfig",
          "type": "blob",
          "size": 0.126953125,
          "content": "{\n  \"content_hash_warming\": true,\n  \"content_hash_max_items\": 333333,\n  \"hint_num_files_per_dir\": 8,\n  \"fsevents_latency\": 0.05\n}\n"
        },
        {
          "name": "AUTHORS",
          "type": "blob",
          "size": 0.314453125,
          "content": "Facebook Inc.\nFacebook Engineering Team\n\nGoogle Inc.\n# Initial version authors:\nJeffrey Dean <jeff@google.com>\nSanjay Ghemawat <sanjay@google.com>\n\n# Partial list of contributors:\nKevin Regan <kevin.d.regan@gmail.com>\nJohan Bilien <jobi@litl.com>\nMatthew Von-Maszewski <https://github.com/matthewvon> (Basho Technologies)\n"
        },
        {
          "name": "BUCK",
          "type": "blob",
          "size": 647.8515625,
          "content": "# This file @generated by:\n#$ python3 buckifier/buckify_rocksdb.py\n# --> DO NOT EDIT MANUALLY <--\n# This file is a Facebook-specific integration for buck builds, so can\n# only be validated by Facebook employees.\nload(\"//rocks/buckifier:defs.bzl\", \"cpp_library_wrapper\",\"rocks_cpp_library_wrapper\",\"cpp_binary_wrapper\",\"cpp_unittest_wrapper\",\"fancy_bench_wrapper\",\"add_c_test_wrapper\")\nload(\"@fbcode_macros//build_defs:export_files.bzl\", \"export_file\")\n\n\ncpp_library_wrapper(name=\"rocksdb_lib\", srcs=[\n        \"cache/cache.cc\",\n        \"cache/cache_entry_roles.cc\",\n        \"cache/cache_helpers.cc\",\n        \"cache/cache_key.cc\",\n        \"cache/cache_reservation_manager.cc\",\n        \"cache/charged_cache.cc\",\n        \"cache/clock_cache.cc\",\n        \"cache/compressed_secondary_cache.cc\",\n        \"cache/lru_cache.cc\",\n        \"cache/secondary_cache.cc\",\n        \"cache/secondary_cache_adapter.cc\",\n        \"cache/sharded_cache.cc\",\n        \"cache/tiered_secondary_cache.cc\",\n        \"db/arena_wrapped_db_iter.cc\",\n        \"db/attribute_group_iterator_impl.cc\",\n        \"db/blob/blob_contents.cc\",\n        \"db/blob/blob_fetcher.cc\",\n        \"db/blob/blob_file_addition.cc\",\n        \"db/blob/blob_file_builder.cc\",\n        \"db/blob/blob_file_cache.cc\",\n        \"db/blob/blob_file_garbage.cc\",\n        \"db/blob/blob_file_meta.cc\",\n        \"db/blob/blob_file_reader.cc\",\n        \"db/blob/blob_garbage_meter.cc\",\n        \"db/blob/blob_log_format.cc\",\n        \"db/blob/blob_log_sequential_reader.cc\",\n        \"db/blob/blob_log_writer.cc\",\n        \"db/blob/blob_source.cc\",\n        \"db/blob/prefetch_buffer_collection.cc\",\n        \"db/builder.cc\",\n        \"db/c.cc\",\n        \"db/coalescing_iterator.cc\",\n        \"db/column_family.cc\",\n        \"db/compaction/compaction.cc\",\n        \"db/compaction/compaction_iterator.cc\",\n        \"db/compaction/compaction_job.cc\",\n        \"db/compaction/compaction_outputs.cc\",\n        \"db/compaction/compaction_picker.cc\",\n        \"db/compaction/compaction_picker_fifo.cc\",\n        \"db/compaction/compaction_picker_level.cc\",\n        \"db/compaction/compaction_picker_universal.cc\",\n        \"db/compaction/compaction_service_job.cc\",\n        \"db/compaction/compaction_state.cc\",\n        \"db/compaction/sst_partitioner.cc\",\n        \"db/compaction/subcompaction_state.cc\",\n        \"db/convenience.cc\",\n        \"db/db_filesnapshot.cc\",\n        \"db/db_impl/compacted_db_impl.cc\",\n        \"db/db_impl/db_impl.cc\",\n        \"db/db_impl/db_impl_compaction_flush.cc\",\n        \"db/db_impl/db_impl_debug.cc\",\n        \"db/db_impl/db_impl_experimental.cc\",\n        \"db/db_impl/db_impl_files.cc\",\n        \"db/db_impl/db_impl_follower.cc\",\n        \"db/db_impl/db_impl_open.cc\",\n        \"db/db_impl/db_impl_readonly.cc\",\n        \"db/db_impl/db_impl_secondary.cc\",\n        \"db/db_impl/db_impl_write.cc\",\n        \"db/db_info_dumper.cc\",\n        \"db/db_iter.cc\",\n        \"db/dbformat.cc\",\n        \"db/error_handler.cc\",\n        \"db/event_helpers.cc\",\n        \"db/experimental.cc\",\n        \"db/external_sst_file_ingestion_job.cc\",\n        \"db/file_indexer.cc\",\n        \"db/flush_job.cc\",\n        \"db/flush_scheduler.cc\",\n        \"db/forward_iterator.cc\",\n        \"db/import_column_family_job.cc\",\n        \"db/internal_stats.cc\",\n        \"db/log_reader.cc\",\n        \"db/log_writer.cc\",\n        \"db/logs_with_prep_tracker.cc\",\n        \"db/malloc_stats.cc\",\n        \"db/manifest_ops.cc\",\n        \"db/memtable.cc\",\n        \"db/memtable_list.cc\",\n        \"db/merge_helper.cc\",\n        \"db/merge_operator.cc\",\n        \"db/output_validator.cc\",\n        \"db/periodic_task_scheduler.cc\",\n        \"db/range_del_aggregator.cc\",\n        \"db/range_tombstone_fragmenter.cc\",\n        \"db/repair.cc\",\n        \"db/seqno_to_time_mapping.cc\",\n        \"db/snapshot_impl.cc\",\n        \"db/table_cache.cc\",\n        \"db/table_properties_collector.cc\",\n        \"db/transaction_log_impl.cc\",\n        \"db/trim_history_scheduler.cc\",\n        \"db/version_builder.cc\",\n        \"db/version_edit.cc\",\n        \"db/version_edit_handler.cc\",\n        \"db/version_set.cc\",\n        \"db/wal_edit.cc\",\n        \"db/wal_manager.cc\",\n        \"db/wide/wide_column_serialization.cc\",\n        \"db/wide/wide_columns.cc\",\n        \"db/wide/wide_columns_helper.cc\",\n        \"db/write_batch.cc\",\n        \"db/write_batch_base.cc\",\n        \"db/write_controller.cc\",\n        \"db/write_stall_stats.cc\",\n        \"db/write_thread.cc\",\n        \"env/composite_env.cc\",\n        \"env/env.cc\",\n        \"env/env_chroot.cc\",\n        \"env/env_encryption.cc\",\n        \"env/env_posix.cc\",\n        \"env/file_system.cc\",\n        \"env/file_system_tracer.cc\",\n        \"env/fs_on_demand.cc\",\n        \"env/fs_posix.cc\",\n        \"env/fs_remap.cc\",\n        \"env/io_posix.cc\",\n        \"env/mock_env.cc\",\n        \"env/unique_id_gen.cc\",\n        \"file/delete_scheduler.cc\",\n        \"file/file_prefetch_buffer.cc\",\n        \"file/file_util.cc\",\n        \"file/filename.cc\",\n        \"file/line_file_reader.cc\",\n        \"file/random_access_file_reader.cc\",\n        \"file/read_write_util.cc\",\n        \"file/readahead_raf.cc\",\n        \"file/sequence_file_reader.cc\",\n        \"file/sst_file_manager_impl.cc\",\n        \"file/writable_file_writer.cc\",\n        \"logging/auto_roll_logger.cc\",\n        \"logging/event_logger.cc\",\n        \"logging/log_buffer.cc\",\n        \"memory/arena.cc\",\n        \"memory/concurrent_arena.cc\",\n        \"memory/jemalloc_nodump_allocator.cc\",\n        \"memory/memkind_kmem_allocator.cc\",\n        \"memory/memory_allocator.cc\",\n        \"memtable/alloc_tracker.cc\",\n        \"memtable/hash_linklist_rep.cc\",\n        \"memtable/hash_skiplist_rep.cc\",\n        \"memtable/skiplistrep.cc\",\n        \"memtable/vectorrep.cc\",\n        \"memtable/wbwi_memtable.cc\",\n        \"memtable/write_buffer_manager.cc\",\n        \"monitoring/histogram.cc\",\n        \"monitoring/histogram_windowing.cc\",\n        \"monitoring/in_memory_stats_history.cc\",\n        \"monitoring/instrumented_mutex.cc\",\n        \"monitoring/iostats_context.cc\",\n        \"monitoring/perf_context.cc\",\n        \"monitoring/perf_level.cc\",\n        \"monitoring/persistent_stats_history.cc\",\n        \"monitoring/statistics.cc\",\n        \"monitoring/thread_status_impl.cc\",\n        \"monitoring/thread_status_updater.cc\",\n        \"monitoring/thread_status_updater_debug.cc\",\n        \"monitoring/thread_status_util.cc\",\n        \"monitoring/thread_status_util_debug.cc\",\n        \"options/cf_options.cc\",\n        \"options/configurable.cc\",\n        \"options/customizable.cc\",\n        \"options/db_options.cc\",\n        \"options/offpeak_time_info.cc\",\n        \"options/options.cc\",\n        \"options/options_helper.cc\",\n        \"options/options_parser.cc\",\n        \"port/mmap.cc\",\n        \"port/port_posix.cc\",\n        \"port/stack_trace.cc\",\n        \"port/win/env_default.cc\",\n        \"port/win/env_win.cc\",\n        \"port/win/io_win.cc\",\n        \"port/win/port_win.cc\",\n        \"port/win/win_logger.cc\",\n        \"port/win/win_thread.cc\",\n        \"table/adaptive/adaptive_table_factory.cc\",\n        \"table/block_based/binary_search_index_reader.cc\",\n        \"table/block_based/block.cc\",\n        \"table/block_based/block_based_table_builder.cc\",\n        \"table/block_based/block_based_table_factory.cc\",\n        \"table/block_based/block_based_table_iterator.cc\",\n        \"table/block_based/block_based_table_reader.cc\",\n        \"table/block_based/block_builder.cc\",\n        \"table/block_based/block_cache.cc\",\n        \"table/block_based/block_prefetcher.cc\",\n        \"table/block_based/block_prefix_index.cc\",\n        \"table/block_based/data_block_footer.cc\",\n        \"table/block_based/data_block_hash_index.cc\",\n        \"table/block_based/filter_block_reader_common.cc\",\n        \"table/block_based/filter_policy.cc\",\n        \"table/block_based/flush_block_policy.cc\",\n        \"table/block_based/full_filter_block.cc\",\n        \"table/block_based/hash_index_reader.cc\",\n        \"table/block_based/index_builder.cc\",\n        \"table/block_based/index_reader_common.cc\",\n        \"table/block_based/parsed_full_filter_block.cc\",\n        \"table/block_based/partitioned_filter_block.cc\",\n        \"table/block_based/partitioned_index_iterator.cc\",\n        \"table/block_based/partitioned_index_reader.cc\",\n        \"table/block_based/reader_common.cc\",\n        \"table/block_based/uncompression_dict_reader.cc\",\n        \"table/block_fetcher.cc\",\n        \"table/compaction_merging_iterator.cc\",\n        \"table/cuckoo/cuckoo_table_builder.cc\",\n        \"table/cuckoo/cuckoo_table_factory.cc\",\n        \"table/cuckoo/cuckoo_table_reader.cc\",\n        \"table/format.cc\",\n        \"table/get_context.cc\",\n        \"table/iterator.cc\",\n        \"table/merging_iterator.cc\",\n        \"table/meta_blocks.cc\",\n        \"table/persistent_cache_helper.cc\",\n        \"table/plain/plain_table_bloom.cc\",\n        \"table/plain/plain_table_builder.cc\",\n        \"table/plain/plain_table_factory.cc\",\n        \"table/plain/plain_table_index.cc\",\n        \"table/plain/plain_table_key_coding.cc\",\n        \"table/plain/plain_table_reader.cc\",\n        \"table/sst_file_dumper.cc\",\n        \"table/sst_file_reader.cc\",\n        \"table/sst_file_writer.cc\",\n        \"table/table_factory.cc\",\n        \"table/table_properties.cc\",\n        \"table/two_level_iterator.cc\",\n        \"table/unique_id.cc\",\n        \"test_util/sync_point.cc\",\n        \"test_util/sync_point_impl.cc\",\n        \"test_util/transaction_test_util.cc\",\n        \"tools/dump/db_dump_tool.cc\",\n        \"tools/io_tracer_parser_tool.cc\",\n        \"tools/ldb_cmd.cc\",\n        \"tools/ldb_tool.cc\",\n        \"tools/sst_dump_tool.cc\",\n        \"trace_replay/block_cache_tracer.cc\",\n        \"trace_replay/io_tracer.cc\",\n        \"trace_replay/trace_record.cc\",\n        \"trace_replay/trace_record_handler.cc\",\n        \"trace_replay/trace_record_result.cc\",\n        \"trace_replay/trace_replay.cc\",\n        \"util/async_file_reader.cc\",\n        \"util/build_version.cc\",\n        \"util/cleanable.cc\",\n        \"util/coding.cc\",\n        \"util/compaction_job_stats_impl.cc\",\n        \"util/comparator.cc\",\n        \"util/compression.cc\",\n        \"util/compression_context_cache.cc\",\n        \"util/concurrent_task_limiter_impl.cc\",\n        \"util/crc32c.cc\",\n        \"util/crc32c_arm64.cc\",\n        \"util/data_structure.cc\",\n        \"util/dynamic_bloom.cc\",\n        \"util/file_checksum_helper.cc\",\n        \"util/hash.cc\",\n        \"util/murmurhash.cc\",\n        \"util/random.cc\",\n        \"util/rate_limiter.cc\",\n        \"util/ribbon_config.cc\",\n        \"util/slice.cc\",\n        \"util/status.cc\",\n        \"util/stderr_logger.cc\",\n        \"util/string_util.cc\",\n        \"util/thread_local.cc\",\n        \"util/threadpool_imp.cc\",\n        \"util/udt_util.cc\",\n        \"util/write_batch_util.cc\",\n        \"util/xxhash.cc\",\n        \"utilities/agg_merge/agg_merge.cc\",\n        \"utilities/backup/backup_engine.cc\",\n        \"utilities/blob_db/blob_compaction_filter.cc\",\n        \"utilities/blob_db/blob_db.cc\",\n        \"utilities/blob_db/blob_db_impl.cc\",\n        \"utilities/blob_db/blob_db_impl_filesnapshot.cc\",\n        \"utilities/blob_db/blob_dump_tool.cc\",\n        \"utilities/blob_db/blob_file.cc\",\n        \"utilities/cache_dump_load.cc\",\n        \"utilities/cache_dump_load_impl.cc\",\n        \"utilities/cassandra/cassandra_compaction_filter.cc\",\n        \"utilities/cassandra/format.cc\",\n        \"utilities/cassandra/merge_operator.cc\",\n        \"utilities/checkpoint/checkpoint_impl.cc\",\n        \"utilities/compaction_filters.cc\",\n        \"utilities/compaction_filters/remove_emptyvalue_compactionfilter.cc\",\n        \"utilities/convenience/info_log_finder.cc\",\n        \"utilities/counted_fs.cc\",\n        \"utilities/debug.cc\",\n        \"utilities/env_mirror.cc\",\n        \"utilities/env_timed.cc\",\n        \"utilities/fault_injection_env.cc\",\n        \"utilities/fault_injection_fs.cc\",\n        \"utilities/fault_injection_secondary_cache.cc\",\n        \"utilities/leveldb_options/leveldb_options.cc\",\n        \"utilities/memory/memory_util.cc\",\n        \"utilities/merge_operators.cc\",\n        \"utilities/merge_operators/bytesxor.cc\",\n        \"utilities/merge_operators/max.cc\",\n        \"utilities/merge_operators/put.cc\",\n        \"utilities/merge_operators/sortlist.cc\",\n        \"utilities/merge_operators/string_append/stringappend.cc\",\n        \"utilities/merge_operators/string_append/stringappend2.cc\",\n        \"utilities/merge_operators/uint64add.cc\",\n        \"utilities/object_registry.cc\",\n        \"utilities/option_change_migration/option_change_migration.cc\",\n        \"utilities/options/options_util.cc\",\n        \"utilities/persistent_cache/block_cache_tier.cc\",\n        \"utilities/persistent_cache/block_cache_tier_file.cc\",\n        \"utilities/persistent_cache/block_cache_tier_metadata.cc\",\n        \"utilities/persistent_cache/persistent_cache_tier.cc\",\n        \"utilities/persistent_cache/volatile_tier_impl.cc\",\n        \"utilities/simulator_cache/cache_simulator.cc\",\n        \"utilities/simulator_cache/sim_cache.cc\",\n        \"utilities/table_properties_collectors/compact_for_tiering_collector.cc\",\n        \"utilities/table_properties_collectors/compact_on_deletion_collector.cc\",\n        \"utilities/trace/file_trace_reader_writer.cc\",\n        \"utilities/trace/replayer_impl.cc\",\n        \"utilities/transactions/lock/lock_manager.cc\",\n        \"utilities/transactions/lock/point/point_lock_manager.cc\",\n        \"utilities/transactions/lock/point/point_lock_tracker.cc\",\n        \"utilities/transactions/lock/range/range_tree/lib/locktree/concurrent_tree.cc\",\n        \"utilities/transactions/lock/range/range_tree/lib/locktree/keyrange.cc\",\n        \"utilities/transactions/lock/range/range_tree/lib/locktree/lock_request.cc\",\n        \"utilities/transactions/lock/range/range_tree/lib/locktree/locktree.cc\",\n        \"utilities/transactions/lock/range/range_tree/lib/locktree/manager.cc\",\n        \"utilities/transactions/lock/range/range_tree/lib/locktree/range_buffer.cc\",\n        \"utilities/transactions/lock/range/range_tree/lib/locktree/treenode.cc\",\n        \"utilities/transactions/lock/range/range_tree/lib/locktree/txnid_set.cc\",\n        \"utilities/transactions/lock/range/range_tree/lib/locktree/wfg.cc\",\n        \"utilities/transactions/lock/range/range_tree/lib/standalone_port.cc\",\n        \"utilities/transactions/lock/range/range_tree/lib/util/dbt.cc\",\n        \"utilities/transactions/lock/range/range_tree/lib/util/memarena.cc\",\n        \"utilities/transactions/lock/range/range_tree/range_tree_lock_manager.cc\",\n        \"utilities/transactions/lock/range/range_tree/range_tree_lock_tracker.cc\",\n        \"utilities/transactions/optimistic_transaction.cc\",\n        \"utilities/transactions/optimistic_transaction_db_impl.cc\",\n        \"utilities/transactions/pessimistic_transaction.cc\",\n        \"utilities/transactions/pessimistic_transaction_db.cc\",\n        \"utilities/transactions/snapshot_checker.cc\",\n        \"utilities/transactions/transaction_base.cc\",\n        \"utilities/transactions/transaction_db_mutex_impl.cc\",\n        \"utilities/transactions/transaction_util.cc\",\n        \"utilities/transactions/write_prepared_txn.cc\",\n        \"utilities/transactions/write_prepared_txn_db.cc\",\n        \"utilities/transactions/write_unprepared_txn.cc\",\n        \"utilities/transactions/write_unprepared_txn_db.cc\",\n        \"utilities/ttl/db_ttl_impl.cc\",\n        \"utilities/types_util.cc\",\n        \"utilities/wal_filter.cc\",\n        \"utilities/write_batch_with_index/write_batch_with_index.cc\",\n        \"utilities/write_batch_with_index/write_batch_with_index_internal.cc\",\n    ], deps=[\n        \"//folly/container:f14_hash\",\n        \"//folly/experimental/coro:blocking_wait\",\n        \"//folly/experimental/coro:collect\",\n        \"//folly/experimental/coro:coroutine\",\n        \"//folly/experimental/coro:task\",\n        \"//folly/synchronization:distributed_mutex\",\n    ], headers=glob([\"**/*.h\"]), link_whole=False, extra_test_libs=False)\n\ncpp_library_wrapper(name=\"rocksdb_whole_archive_lib\", srcs=[], deps=[\":rocksdb_lib\"], headers=[], link_whole=True, extra_test_libs=False)\n\ncpp_library_wrapper(name=\"rocksdb_with_faiss_lib\", srcs=[\"utilities/secondary_index/faiss_ivf_index.cc\"], deps=[\n        \"//faiss:faiss\",\n        \":rocksdb_lib\",\n    ], headers=[], link_whole=False, extra_test_libs=False)\n\ncpp_library_wrapper(name=\"rocksdb_test_lib\", srcs=[\n        \"db/db_test_util.cc\",\n        \"db/db_with_timestamp_test_util.cc\",\n        \"table/mock_table.cc\",\n        \"test_util/mock_time_env.cc\",\n        \"test_util/secondary_cache_test_util.cc\",\n        \"test_util/testharness.cc\",\n        \"test_util/testutil.cc\",\n        \"tools/block_cache_analyzer/block_cache_trace_analyzer.cc\",\n        \"tools/trace_analyzer_tool.cc\",\n        \"utilities/agg_merge/test_agg_merge.cc\",\n        \"utilities/cassandra/test_utils.cc\",\n    ], deps=[\":rocksdb_lib\"], headers=[], link_whole=False, extra_test_libs=True)\n\ncpp_library_wrapper(name=\"rocksdb_with_faiss_test_lib\", srcs=[\n        \"db/db_test_util.cc\",\n        \"db/db_with_timestamp_test_util.cc\",\n        \"table/mock_table.cc\",\n        \"test_util/mock_time_env.cc\",\n        \"test_util/secondary_cache_test_util.cc\",\n        \"test_util/testharness.cc\",\n        \"test_util/testutil.cc\",\n        \"tools/block_cache_analyzer/block_cache_trace_analyzer.cc\",\n        \"tools/trace_analyzer_tool.cc\",\n        \"utilities/agg_merge/test_agg_merge.cc\",\n        \"utilities/cassandra/test_utils.cc\",\n    ], deps=[\":rocksdb_with_faiss_lib\"], headers=[], link_whole=False, extra_test_libs=True)\n\ncpp_library_wrapper(name=\"rocksdb_tools_lib\", srcs=[\n        \"test_util/testutil.cc\",\n        \"tools/block_cache_analyzer/block_cache_trace_analyzer.cc\",\n        \"tools/db_bench_tool.cc\",\n        \"tools/simulated_hybrid_file_system.cc\",\n        \"tools/trace_analyzer_tool.cc\",\n    ], deps=[\":rocksdb_lib\"], headers=[], link_whole=False, extra_test_libs=False)\n\ncpp_library_wrapper(name=\"rocksdb_cache_bench_tools_lib\", srcs=[\"cache/cache_bench_tool.cc\"], deps=[\":rocksdb_lib\"], headers=[], link_whole=False, extra_test_libs=False)\n\nrocks_cpp_library_wrapper(name=\"rocksdb_stress_lib\", srcs=[\n        \"db_stress_tool/batched_ops_stress.cc\",\n        \"db_stress_tool/cf_consistency_stress.cc\",\n        \"db_stress_tool/db_stress_common.cc\",\n        \"db_stress_tool/db_stress_driver.cc\",\n        \"db_stress_tool/db_stress_filters.cc\",\n        \"db_stress_tool/db_stress_gflags.cc\",\n        \"db_stress_tool/db_stress_listener.cc\",\n        \"db_stress_tool/db_stress_shared_state.cc\",\n        \"db_stress_tool/db_stress_stat.cc\",\n        \"db_stress_tool/db_stress_test_base.cc\",\n        \"db_stress_tool/db_stress_tool.cc\",\n        \"db_stress_tool/db_stress_wide_merge_operator.cc\",\n        \"db_stress_tool/expected_state.cc\",\n        \"db_stress_tool/expected_value.cc\",\n        \"db_stress_tool/multi_ops_txns_stress.cc\",\n        \"db_stress_tool/no_batched_ops_stress.cc\",\n        \"test_util/testutil.cc\",\n        \"tools/block_cache_analyzer/block_cache_trace_analyzer.cc\",\n        \"tools/trace_analyzer_tool.cc\",\n    ], headers=[])\n\n\ncpp_binary_wrapper(name=\"ldb\", srcs=[\"tools/ldb.cc\"], deps=[\":rocksdb_tools_lib\"], extra_preprocessor_flags=[], extra_bench_libs=False)\n\ncpp_binary_wrapper(name=\"db_stress\", srcs=[\"db_stress_tool/db_stress.cc\"], deps=[\":rocksdb_stress_lib\"], extra_preprocessor_flags=[], extra_bench_libs=False)\n\ncpp_binary_wrapper(name=\"db_bench\", srcs=[\"tools/db_bench.cc\"], deps=[\":rocksdb_tools_lib\"], extra_preprocessor_flags=[], extra_bench_libs=False)\n\ncpp_binary_wrapper(name=\"cache_bench\", srcs=[\"cache/cache_bench.cc\"], deps=[\":rocksdb_cache_bench_tools_lib\"], extra_preprocessor_flags=[], extra_bench_libs=False)\n\ncpp_binary_wrapper(name=\"ribbon_bench\", srcs=[\"microbench/ribbon_bench.cc\"], deps=[], extra_preprocessor_flags=[], extra_bench_libs=True)\n\ncpp_binary_wrapper(name=\"db_basic_bench\", srcs=[\"microbench/db_basic_bench.cc\"], deps=[], extra_preprocessor_flags=[], extra_bench_libs=True)\n\nadd_c_test_wrapper()\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_0\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:1/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                                'get_mean',\n                                                                                                                                                                'threads',\n                                                                                                                                                                'real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBPut/comp_style:1/max_data:107374182400/per_key_size:256/enable_statistics:1/wal:1/iterations:51200/threads:8': ['real_time',\n                                                                                                                                       'put_mean',\n                                                                                                                                       'cpu_time',\n                                                                                                                                       'db_size',\n                                                                                                                                       'threads'],\n                    'DBPut/comp_style:2/max_data:107374182400/per_key_size:256/enable_statistics:0/wal:0/iterations:51200/threads:8': ['real_time',\n                                                                                                                                       'cpu_time',\n                                                                                                                                       'db_size',\n                                                                                                                                       'threads']},\n 'ribbon_bench': {'FilterBuild/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                              'cpu_time',\n                                                                                              'threads',\n                                                                                              'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:20/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                  'cpu_time',\n                                                                                                  'threads',\n                                                                                                  'size'],\n                  'FilterQueryNegative/filter_impl:3/bits_per_key:10/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryPositive/filter_impl:2/bits_per_key:10/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads'],\n                  'FilterQueryPositive/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads'],\n                  'FilterQueryPositive/filter_impl:3/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads'],\n                  'FilterQueryPositive/filter_impl:3/bits_per_key:20/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads']}}, slow=False, expected_runtime=2438, sl_iterations=3, regression_threshold=10)\n\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_1\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:1/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                                'get_mean',\n                                                                                                                                                                'threads',\n                                                                                                                                                                'real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                                'get_mean',\n                                                                                                                                                                'threads',\n                                                                                                                                                                'real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBPut/comp_style:2/max_data:107374182400/per_key_size:256/enable_statistics:1/wal:0/iterations:409600/threads:1': ['real_time',\n                                                                                                                                        'put_mean',\n                                                                                                                                        'cpu_time',\n                                                                                                                                        'db_size',\n                                                                                                                                        'threads'],\n                    'DBPut/comp_style:2/max_data:107374182400/per_key_size:256/enable_statistics:1/wal:1/iterations:51200/threads:8': ['real_time',\n                                                                                                                                       'put_mean',\n                                                                                                                                       'cpu_time',\n                                                                                                                                       'db_size',\n                                                                                                                                       'threads']},\n 'ribbon_bench': {'FilterBuild/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                               'cpu_time',\n                                                                                               'threads',\n                                                                                               'size'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads',\n                                                                                                         'fp_pct'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:20/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:20/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads'],\n                  'FilterQueryPositive/filter_impl:2/bits_per_key:20/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads'],\n                  'FilterQueryPositive/filter_impl:3/bits_per_key:20/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads']}}, slow=False, expected_runtime=2437, sl_iterations=3, regression_threshold=10)\n\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_2\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                                'get_mean',\n                                                                                                                                                                'threads',\n                                                                                                                                                                'real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'neg_qu_pct'],\n                    'DBGet/comp_style:1/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBPut/comp_style:1/max_data:107374182400/per_key_size:256/enable_statistics:0/wal:0/iterations:409600/threads:1': ['real_time',\n                                                                                                                                        'cpu_time',\n                                                                                                                                        'db_size',\n                                                                                                                                        'threads'],\n                    'DBPut/comp_style:2/max_data:107374182400/per_key_size:256/enable_statistics:0/wal:0/iterations:409600/threads:1': ['real_time',\n                                                                                                                                        'cpu_time',\n                                                                                                                                        'db_size',\n                                                                                                                                        'threads']}}, slow=False, expected_runtime=2446, sl_iterations=3, regression_threshold=10)\n\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_3\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'db_size',\n                                                                                                                                                              'neg_qu_pct',\n                                                                                                                                                              'threads'],\n                    'DBGet/comp_style:1/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                                'get_mean',\n                                                                                                                                                                'threads',\n                                                                                                                                                                'real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'neg_qu_pct'],\n                    'DBGet/comp_style:1/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBPut/comp_style:0/max_data:107374182400/per_key_size:256/enable_statistics:0/wal:1/iterations:51200/threads:8': ['real_time',\n                                                                                                                                       'cpu_time',\n                                                                                                                                       'db_size',\n                                                                                                                                       'threads'],\n                    'DataBlockSeek/iterations:1000000': ['real_time',\n                                                         'cpu_time',\n                                                         'seek_ns',\n                                                         'threads']},\n 'ribbon_bench': {'FilterBuild/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                               'cpu_time',\n                                                                                               'threads',\n                                                                                               'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                  'cpu_time',\n                                                                                                  'threads',\n                                                                                                  'size'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads',\n                                                                                                         'fp_pct'],\n                  'FilterQueryNegative/filter_impl:3/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryPositive/filter_impl:2/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads']}}, slow=False, expected_runtime=2437, sl_iterations=3, regression_threshold=10)\n\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_4\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:1/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:1/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBPut/comp_style:1/max_data:107374182400/per_key_size:256/enable_statistics:0/wal:1/iterations:51200/threads:8': ['real_time',\n                                                                                                                                       'cpu_time',\n                                                                                                                                       'db_size',\n                                                                                                                                       'threads'],\n                    'RandomAccessFileReaderRead/enable_statistics:1/iterations:1000000': ['real_time',\n                                                                                          'cpu_time',\n                                                                                          'threads']},\n 'ribbon_bench': {'FilterBuild/filter_impl:0/bits_per_key:20/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                              'cpu_time',\n                                                                                              'threads',\n                                                                                              'size'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads',\n                                                                                                          'fp_pct'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:20/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads',\n                                                                                                         'fp_pct'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads',\n                                                                                                          'fp_pct'],\n                  'FilterQueryPositive/filter_impl:2/bits_per_key:20/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads']}}, slow=False, expected_runtime=2437, sl_iterations=3, regression_threshold=10)\n\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_5\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:1/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'db_size',\n                                                                                                                                                              'neg_qu_pct',\n                                                                                                                                                              'threads'],\n                    'DBGet/comp_style:1/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBPut/comp_style:2/max_data:107374182400/per_key_size:256/enable_statistics:0/wal:1/iterations:51200/threads:8': ['real_time',\n                                                                                                                                       'cpu_time',\n                                                                                                                                       'db_size',\n                                                                                                                                       'threads']},\n 'ribbon_bench': {'FilterBuild/filter_impl:2/bits_per_key:20/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                              'cpu_time',\n                                                                                              'threads',\n                                                                                              'size'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:20/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:20/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads',\n                                                                                                          'fp_pct'],\n                  'FilterQueryNegative/filter_impl:3/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads'],\n                  'FilterQueryPositive/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads'],\n                  'FilterQueryPositive/filter_impl:3/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads'],\n                  'FilterQueryPositive/filter_impl:3/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads']}}, slow=False, expected_runtime=2437, sl_iterations=3, regression_threshold=10)\n\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_6\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:1/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBPut/comp_style:2/max_data:107374182400/per_key_size:256/enable_statistics:0/wal:1/iterations:409600/threads:1': ['real_time',\n                                                                                                                                        'cpu_time',\n                                                                                                                                        'db_size',\n                                                                                                                                        'threads'],\n                    'DBPut/comp_style:2/max_data:107374182400/per_key_size:256/enable_statistics:1/wal:0/iterations:51200/threads:8': ['real_time',\n                                                                                                                                       'put_mean',\n                                                                                                                                       'cpu_time',\n                                                                                                                                       'db_size',\n                                                                                                                                       'threads']},\n 'ribbon_bench': {'FilterBuild/filter_impl:2/bits_per_key:10/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                               'cpu_time',\n                                                                                               'threads',\n                                                                                               'size'],\n                  'FilterBuild/filter_impl:2/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                  'cpu_time',\n                                                                                                  'threads',\n                                                                                                  'size'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryPositive/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads']}}, slow=False, expected_runtime=2437, sl_iterations=3, regression_threshold=10)\n\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_7\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBPut/comp_style:0/max_data:107374182400/per_key_size:256/enable_statistics:1/wal:0/iterations:51200/threads:8': ['real_time',\n                                                                                                                                       'put_mean',\n                                                                                                                                       'cpu_time',\n                                                                                                                                       'db_size',\n                                                                                                                                       'threads'],\n                    'DBPut/comp_style:1/max_data:107374182400/per_key_size:256/enable_statistics:1/wal:1/iterations:409600/threads:1': ['real_time',\n                                                                                                                                        'put_mean',\n                                                                                                                                        'cpu_time',\n                                                                                                                                        'db_size',\n                                                                                                                                        'threads'],\n                    'RandomAccessFileReaderRead/enable_statistics:0/iterations:1000000': ['real_time',\n                                                                                          'cpu_time',\n                                                                                          'threads']},\n 'ribbon_bench': {'FilterBuild/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:20/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                              'cpu_time',\n                                                                                              'threads',\n                                                                                              'size'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:10/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct']}}, slow=False, expected_runtime=2438, sl_iterations=3, regression_threshold=10)\n\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_8\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:1/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBPut/comp_style:0/max_data:107374182400/per_key_size:256/enable_statistics:0/wal:0/iterations:409600/threads:1': ['real_time',\n                                                                                                                                        'cpu_time',\n                                                                                                                                        'db_size',\n                                                                                                                                        'threads'],\n                    'DBPut/comp_style:2/max_data:107374182400/per_key_size:256/enable_statistics:1/wal:1/iterations:409600/threads:1': ['real_time',\n                                                                                                                                        'put_mean',\n                                                                                                                                        'cpu_time',\n                                                                                                                                        'db_size',\n                                                                                                                                        'threads']},\n 'ribbon_bench': {'FilterBuild/filter_impl:0/bits_per_key:20/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:2/bits_per_key:20/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:20/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:20/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryNegative/filter_impl:3/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads',\n                                                                                                         'fp_pct'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:20/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads']}}, slow=False, expected_runtime=2437, sl_iterations=3, regression_threshold=10)\n\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_9\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                                'get_mean',\n                                                                                                                                                                'threads',\n                                                                                                                                                                'real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'neg_qu_pct'],\n                    'DBPut/comp_style:1/max_data:107374182400/per_key_size:256/enable_statistics:0/wal:0/iterations:51200/threads:8': ['real_time',\n                                                                                                                                       'cpu_time',\n                                                                                                                                       'db_size',\n                                                                                                                                       'threads'],\n                    'DBPut/comp_style:1/max_data:107374182400/per_key_size:256/enable_statistics:0/wal:1/iterations:409600/threads:1': ['real_time',\n                                                                                                                                        'cpu_time',\n                                                                                                                                        'db_size',\n                                                                                                                                        'threads']},\n 'ribbon_bench': {'FilterBuild/filter_impl:3/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                               'cpu_time',\n                                                                                               'threads',\n                                                                                               'size'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryNegative/filter_impl:3/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads',\n                                                                                                          'fp_pct'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads']}}, slow=False, expected_runtime=2437, sl_iterations=3, regression_threshold=10)\n\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_10\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                                'get_mean',\n                                                                                                                                                                'threads',\n                                                                                                                                                                'real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:1/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:1/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBPut/comp_style:0/max_data:107374182400/per_key_size:256/enable_statistics:1/wal:1/iterations:409600/threads:1': ['real_time',\n                                                                                                                                        'put_mean',\n                                                                                                                                        'cpu_time',\n                                                                                                                                        'db_size',\n                                                                                                                                        'threads']},\n 'ribbon_bench': {'FilterBuild/filter_impl:3/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                              'cpu_time',\n                                                                                              'threads',\n                                                                                              'size'],\n                  'FilterQueryPositive/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads']}}, slow=False, expected_runtime=2437, sl_iterations=3, regression_threshold=10)\n\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_11\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                                'get_mean',\n                                                                                                                                                                'threads',\n                                                                                                                                                                'real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'neg_qu_pct'],\n                    'DBGet/comp_style:1/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                                'get_mean',\n                                                                                                                                                                'threads',\n                                                                                                                                                                'real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'neg_qu_pct'],\n                    'DBGet/comp_style:1/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                                'get_mean',\n                                                                                                                                                                'threads',\n                                                                                                                                                                'real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'neg_qu_pct'],\n                    'DBPut/comp_style:1/max_data:107374182400/per_key_size:256/enable_statistics:1/wal:0/iterations:409600/threads:1': ['real_time',\n                                                                                                                                        'put_mean',\n                                                                                                                                        'cpu_time',\n                                                                                                                                        'db_size',\n                                                                                                                                        'threads'],\n                    'DBPut/comp_style:1/max_data:107374182400/per_key_size:256/enable_statistics:1/wal:0/iterations:51200/threads:8': ['real_time',\n                                                                                                                                       'put_mean',\n                                                                                                                                       'cpu_time',\n                                                                                                                                       'db_size',\n                                                                                                                                       'threads']}}, slow=False, expected_runtime=2446, sl_iterations=3, regression_threshold=10)\n\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_12\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                                'get_mean',\n                                                                                                                                                                'threads',\n                                                                                                                                                                'real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'neg_qu_pct'],\n                    'DBGet/comp_style:1/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct']},\n 'ribbon_bench': {'FilterBuild/filter_impl:0/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                               'cpu_time',\n                                                                                               'threads',\n                                                                                               'size'],\n                  'FilterBuild/filter_impl:0/bits_per_key:20/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                  'cpu_time',\n                                                                                                  'threads',\n                                                                                                  'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:10/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                               'cpu_time',\n                                                                                               'threads',\n                                                                                               'size'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads',\n                                                                                                          'fp_pct'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:20/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads',\n                                                                                                         'fp_pct'],\n                  'FilterQueryNegative/filter_impl:3/bits_per_key:20/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads',\n                                                                                                         'fp_pct'],\n                  'FilterQueryNegative/filter_impl:3/bits_per_key:20/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads',\n                                                                                                          'fp_pct'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads'],\n                  'FilterQueryPositive/filter_impl:3/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads']}}, slow=False, expected_runtime=2437, sl_iterations=3, regression_threshold=10)\n\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_13\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBPut/comp_style:0/max_data:107374182400/per_key_size:256/enable_statistics:0/wal:1/iterations:409600/threads:1': ['real_time',\n                                                                                                                                        'cpu_time',\n                                                                                                                                        'db_size',\n                                                                                                                                        'threads'],\n                    'DBPut/comp_style:0/max_data:107374182400/per_key_size:256/enable_statistics:1/wal:0/iterations:409600/threads:1': ['real_time',\n                                                                                                                                        'put_mean',\n                                                                                                                                        'cpu_time',\n                                                                                                                                        'db_size',\n                                                                                                                                        'threads']},\n 'ribbon_bench': {'FilterBuild/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                  'cpu_time',\n                                                                                                  'threads',\n                                                                                                  'size'],\n                  'FilterQueryNegative/filter_impl:3/bits_per_key:20/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryPositive/filter_impl:3/bits_per_key:10/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads'],\n                  'FilterQueryPositive/filter_impl:3/bits_per_key:20/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads']}}, slow=False, expected_runtime=2437, sl_iterations=3, regression_threshold=10)\n\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_14\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                                'get_mean',\n                                                                                                                                                                'threads',\n                                                                                                                                                                'real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'neg_qu_pct'],\n                    'DBPut/comp_style:0/max_data:107374182400/per_key_size:256/enable_statistics:0/wal:0/iterations:51200/threads:8': ['real_time',\n                                                                                                                                       'cpu_time',\n                                                                                                                                       'db_size',\n                                                                                                                                       'threads'],\n                    'DBPut/comp_style:0/max_data:107374182400/per_key_size:256/enable_statistics:1/wal:1/iterations:51200/threads:8': ['real_time',\n                                                                                                                                       'put_mean',\n                                                                                                                                       'cpu_time',\n                                                                                                                                       'db_size',\n                                                                                                                                       'threads']},\n 'ribbon_bench': {'FilterBuild/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                              'cpu_time',\n                                                                                              'threads',\n                                                                                              'size'],\n                  'FilterBuild/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                  'cpu_time',\n                                                                                                  'threads',\n                                                                                                  'size'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads']}}, slow=False, expected_runtime=2437, sl_iterations=3, regression_threshold=10)\n\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_0_slow\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'db_size',\n                                                                                                                                                              'neg_qu_pct',\n                                                                                                                                                              'threads'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:1/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                                'get_mean',\n                                                                                                                                                                'threads',\n                                                                                                                                                                'real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'neg_qu_pct'],\n                    'DBPut/comp_style:1/max_data:107374182400/per_key_size:256/enable_statistics:1/wal:0/iterations:409600/threads:1': ['real_time',\n                                                                                                                                        'put_mean',\n                                                                                                                                        'cpu_time',\n                                                                                                                                        'db_size',\n                                                                                                                                        'threads'],\n                    'IteratorPrev/comp_style:1/max_data:536870912/per_key_size:256/iterations:10240': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'db_size',\n                                                                                                       'threads'],\n                    'IteratorPrev/comp_style:2/max_data:536870912/per_key_size:256/iterations:10240': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'db_size',\n                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'PrefixSeek/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:0/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:0/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                  'cpu_time',\n                                                                                                                                                  'db_size',\n                                                                                                                                                  'threads'],\n                    'PrefixSeek/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                  'cpu_time',\n                                                                                                                                                  'db_size',\n                                                                                                                                                  'threads'],\n                    'PrefixSeek/comp_style:1/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:1/enable_filter:0/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:1/max_data:536870912/per_key_size:256/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                         'cpu_time',\n                                                                                                                                         'db_size',\n                                                                                                                                         'threads'],\n                    'PrefixSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                   'cpu_time',\n                                                                                                                                                   'db_size',\n                                                                                                                                                   'threads'],\n                    'PrefixSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads']},\n 'ribbon_bench': {'FilterBuild/filter_impl:0/bits_per_key:20/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                              'cpu_time',\n                                                                                              'threads',\n                                                                                              'size'],\n                  'FilterBuild/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                  'cpu_time',\n                                                                                                  'threads',\n                                                                                                  'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:20/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                               'cpu_time',\n                                                                                               'threads',\n                                                                                               'size'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryNegative/filter_impl:3/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads',\n                                                                                                         'fp_pct'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads'],\n                  'FilterQueryPositive/filter_impl:3/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads']}}, slow=True, expected_runtime=88891, sl_iterations=3, regression_threshold=10)\n\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_1_slow\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'db_size',\n                                                                                                                                                              'neg_qu_pct',\n                                                                                                                                                              'threads'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:1/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                                'get_mean',\n                                                                                                                                                                'threads',\n                                                                                                                                                                'real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'neg_qu_pct'],\n                    'DBPut/comp_style:1/max_data:107374182400/per_key_size:256/enable_statistics:1/wal:0/iterations:409600/threads:1': ['real_time',\n                                                                                                                                        'put_mean',\n                                                                                                                                        'cpu_time',\n                                                                                                                                        'db_size',\n                                                                                                                                        'threads'],\n                    'IteratorPrev/comp_style:1/max_data:536870912/per_key_size:256/iterations:10240': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'db_size',\n                                                                                                       'threads'],\n                    'IteratorPrev/comp_style:2/max_data:536870912/per_key_size:256/iterations:10240': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'db_size',\n                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'PrefixSeek/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:0/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:0/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                  'cpu_time',\n                                                                                                                                                  'db_size',\n                                                                                                                                                  'threads'],\n                    'PrefixSeek/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                  'cpu_time',\n                                                                                                                                                  'db_size',\n                                                                                                                                                  'threads'],\n                    'PrefixSeek/comp_style:1/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:1/enable_filter:0/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:1/max_data:536870912/per_key_size:256/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                         'cpu_time',\n                                                                                                                                         'db_size',\n                                                                                                                                         'threads'],\n                    'PrefixSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                   'cpu_time',\n                                                                                                                                                   'db_size',\n                                                                                                                                                   'threads'],\n                    'PrefixSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads']},\n 'ribbon_bench': {'FilterBuild/filter_impl:0/bits_per_key:20/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                              'cpu_time',\n                                                                                              'threads',\n                                                                                              'size'],\n                  'FilterBuild/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                  'cpu_time',\n                                                                                                  'threads',\n                                                                                                  'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:20/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                               'cpu_time',\n                                                                                               'threads',\n                                                                                               'size'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryNegative/filter_impl:3/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads',\n                                                                                                         'fp_pct'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads'],\n                  'FilterQueryPositive/filter_impl:3/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads']}}, slow=True, expected_runtime=88804, sl_iterations=3, regression_threshold=10)\n\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_2_slow\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'db_size',\n                                                                                                                                                              'neg_qu_pct',\n                                                                                                                                                              'threads'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:1/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                                'get_mean',\n                                                                                                                                                                'threads',\n                                                                                                                                                                'real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'neg_qu_pct'],\n                    'DBPut/comp_style:1/max_data:107374182400/per_key_size:256/enable_statistics:1/wal:0/iterations:409600/threads:1': ['real_time',\n                                                                                                                                        'put_mean',\n                                                                                                                                        'cpu_time',\n                                                                                                                                        'db_size',\n                                                                                                                                        'threads'],\n                    'IteratorPrev/comp_style:1/max_data:536870912/per_key_size:256/iterations:10240': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'db_size',\n                                                                                                       'threads'],\n                    'IteratorPrev/comp_style:2/max_data:536870912/per_key_size:256/iterations:10240': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'db_size',\n                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'PrefixSeek/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:0/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:0/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                  'cpu_time',\n                                                                                                                                                  'db_size',\n                                                                                                                                                  'threads'],\n                    'PrefixSeek/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                  'cpu_time',\n                                                                                                                                                  'db_size',\n                                                                                                                                                  'threads'],\n                    'PrefixSeek/comp_style:1/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:1/enable_filter:0/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:1/max_data:536870912/per_key_size:256/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                         'cpu_time',\n                                                                                                                                         'db_size',\n                                                                                                                                         'threads'],\n                    'PrefixSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                   'cpu_time',\n                                                                                                                                                   'db_size',\n                                                                                                                                                   'threads'],\n                    'PrefixSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads']},\n 'ribbon_bench': {'FilterBuild/filter_impl:0/bits_per_key:20/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                              'cpu_time',\n                                                                                              'threads',\n                                                                                              'size'],\n                  'FilterBuild/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                  'cpu_time',\n                                                                                                  'threads',\n                                                                                                  'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:20/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                               'cpu_time',\n                                                                                               'threads',\n                                                                                               'size'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryNegative/filter_impl:3/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads',\n                                                                                                         'fp_pct'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads'],\n                  'FilterQueryPositive/filter_impl:3/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads']}}, slow=True, expected_runtime=88803, sl_iterations=3, regression_threshold=10)\n\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_3_slow\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'db_size',\n                                                                                                                                                              'neg_qu_pct',\n                                                                                                                                                              'threads'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:1/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                                'get_mean',\n                                                                                                                                                                'threads',\n                                                                                                                                                                'real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'neg_qu_pct'],\n                    'DBPut/comp_style:1/max_data:107374182400/per_key_size:256/enable_statistics:1/wal:0/iterations:409600/threads:1': ['real_time',\n                                                                                                                                        'put_mean',\n                                                                                                                                        'cpu_time',\n                                                                                                                                        'db_size',\n                                                                                                                                        'threads'],\n                    'IteratorPrev/comp_style:1/max_data:536870912/per_key_size:256/iterations:10240': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'db_size',\n                                                                                                       'threads'],\n                    'IteratorPrev/comp_style:2/max_data:536870912/per_key_size:256/iterations:10240': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'db_size',\n                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'PrefixSeek/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:0/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:0/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                  'cpu_time',\n                                                                                                                                                  'db_size',\n                                                                                                                                                  'threads'],\n                    'PrefixSeek/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                  'cpu_time',\n                                                                                                                                                  'db_size',\n                                                                                                                                                  'threads'],\n                    'PrefixSeek/comp_style:1/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:1/enable_filter:0/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:1/max_data:536870912/per_key_size:256/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                         'cpu_time',\n                                                                                                                                         'db_size',\n                                                                                                                                         'threads'],\n                    'PrefixSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                   'cpu_time',\n                                                                                                                                                   'db_size',\n                                                                                                                                                   'threads'],\n                    'PrefixSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads']},\n 'ribbon_bench': {'FilterBuild/filter_impl:0/bits_per_key:20/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                              'cpu_time',\n                                                                                              'threads',\n                                                                                              'size'],\n                  'FilterBuild/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                  'cpu_time',\n                                                                                                  'threads',\n                                                                                                  'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:20/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                               'cpu_time',\n                                                                                               'threads',\n                                                                                               'size'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryNegative/filter_impl:3/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads',\n                                                                                                         'fp_pct'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads'],\n                  'FilterQueryPositive/filter_impl:3/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads']}}, slow=True, expected_runtime=88891, sl_iterations=3, regression_threshold=10)\n\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_4_slow\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'db_size',\n                                                                                                                                                              'neg_qu_pct',\n                                                                                                                                                              'threads'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:1/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                                'get_mean',\n                                                                                                                                                                'threads',\n                                                                                                                                                                'real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'neg_qu_pct'],\n                    'DBPut/comp_style:1/max_data:107374182400/per_key_size:256/enable_statistics:1/wal:0/iterations:409600/threads:1': ['real_time',\n                                                                                                                                        'put_mean',\n                                                                                                                                        'cpu_time',\n                                                                                                                                        'db_size',\n                                                                                                                                        'threads'],\n                    'IteratorPrev/comp_style:1/max_data:536870912/per_key_size:256/iterations:10240': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'db_size',\n                                                                                                       'threads'],\n                    'IteratorPrev/comp_style:2/max_data:536870912/per_key_size:256/iterations:10240': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'db_size',\n                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'PrefixSeek/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:0/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:0/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                  'cpu_time',\n                                                                                                                                                  'db_size',\n                                                                                                                                                  'threads'],\n                    'PrefixSeek/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                  'cpu_time',\n                                                                                                                                                  'db_size',\n                                                                                                                                                  'threads'],\n                    'PrefixSeek/comp_style:1/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:1/enable_filter:0/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:1/max_data:536870912/per_key_size:256/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                         'cpu_time',\n                                                                                                                                         'db_size',\n                                                                                                                                         'threads'],\n                    'PrefixSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                   'cpu_time',\n                                                                                                                                                   'db_size',\n                                                                                                                                                   'threads'],\n                    'PrefixSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads']},\n 'ribbon_bench': {'FilterBuild/filter_impl:0/bits_per_key:20/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                              'cpu_time',\n                                                                                              'threads',\n                                                                                              'size'],\n                  'FilterBuild/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                  'cpu_time',\n                                                                                                  'threads',\n                                                                                                  'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:20/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                               'cpu_time',\n                                                                                               'threads',\n                                                                                               'size'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryNegative/filter_impl:3/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads',\n                                                                                                         'fp_pct'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads'],\n                  'FilterQueryPositive/filter_impl:3/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads']}}, slow=True, expected_runtime=88809, sl_iterations=3, regression_threshold=10)\n\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_5_slow\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'db_size',\n                                                                                                                                                              'neg_qu_pct',\n                                                                                                                                                              'threads'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:1/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                                'get_mean',\n                                                                                                                                                                'threads',\n                                                                                                                                                                'real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'neg_qu_pct'],\n                    'DBPut/comp_style:1/max_data:107374182400/per_key_size:256/enable_statistics:1/wal:0/iterations:409600/threads:1': ['real_time',\n                                                                                                                                        'put_mean',\n                                                                                                                                        'cpu_time',\n                                                                                                                                        'db_size',\n                                                                                                                                        'threads'],\n                    'IteratorPrev/comp_style:1/max_data:536870912/per_key_size:256/iterations:10240': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'db_size',\n                                                                                                       'threads'],\n                    'IteratorPrev/comp_style:2/max_data:536870912/per_key_size:256/iterations:10240': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'db_size',\n                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'PrefixSeek/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:0/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:0/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                  'cpu_time',\n                                                                                                                                                  'db_size',\n                                                                                                                                                  'threads'],\n                    'PrefixSeek/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                  'cpu_time',\n                                                                                                                                                  'db_size',\n                                                                                                                                                  'threads'],\n                    'PrefixSeek/comp_style:1/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:1/enable_filter:0/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:1/max_data:536870912/per_key_size:256/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                         'cpu_time',\n                                                                                                                                         'db_size',\n                                                                                                                                         'threads'],\n                    'PrefixSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                   'cpu_time',\n                                                                                                                                                   'db_size',\n                                                                                                                                                   'threads'],\n                    'PrefixSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads']},\n 'ribbon_bench': {'FilterBuild/filter_impl:0/bits_per_key:20/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                              'cpu_time',\n                                                                                              'threads',\n                                                                                              'size'],\n                  'FilterBuild/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                  'cpu_time',\n                                                                                                  'threads',\n                                                                                                  'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:20/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                               'cpu_time',\n                                                                                               'threads',\n                                                                                               'size'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryNegative/filter_impl:3/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads',\n                                                                                                         'fp_pct'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads'],\n                  'FilterQueryPositive/filter_impl:3/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads']}}, slow=True, expected_runtime=88803, sl_iterations=3, regression_threshold=10)\n\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_6_slow\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'db_size',\n                                                                                                                                                              'neg_qu_pct',\n                                                                                                                                                              'threads'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:1/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                                'get_mean',\n                                                                                                                                                                'threads',\n                                                                                                                                                                'real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'neg_qu_pct'],\n                    'DBPut/comp_style:1/max_data:107374182400/per_key_size:256/enable_statistics:1/wal:0/iterations:409600/threads:1': ['real_time',\n                                                                                                                                        'put_mean',\n                                                                                                                                        'cpu_time',\n                                                                                                                                        'db_size',\n                                                                                                                                        'threads'],\n                    'IteratorPrev/comp_style:1/max_data:536870912/per_key_size:256/iterations:10240': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'db_size',\n                                                                                                       'threads'],\n                    'IteratorPrev/comp_style:2/max_data:536870912/per_key_size:256/iterations:10240': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'db_size',\n                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'PrefixSeek/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:0/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:0/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                  'cpu_time',\n                                                                                                                                                  'db_size',\n                                                                                                                                                  'threads'],\n                    'PrefixSeek/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                  'cpu_time',\n                                                                                                                                                  'db_size',\n                                                                                                                                                  'threads'],\n                    'PrefixSeek/comp_style:1/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:1/enable_filter:0/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:1/max_data:536870912/per_key_size:256/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                         'cpu_time',\n                                                                                                                                         'db_size',\n                                                                                                                                         'threads'],\n                    'PrefixSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                   'cpu_time',\n                                                                                                                                                   'db_size',\n                                                                                                                                                   'threads'],\n                    'PrefixSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads']},\n 'ribbon_bench': {'FilterBuild/filter_impl:0/bits_per_key:20/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                              'cpu_time',\n                                                                                              'threads',\n                                                                                              'size'],\n                  'FilterBuild/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                  'cpu_time',\n                                                                                                  'threads',\n                                                                                                  'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:20/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                               'cpu_time',\n                                                                                               'threads',\n                                                                                               'size'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryNegative/filter_impl:3/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads',\n                                                                                                         'fp_pct'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads'],\n                  'FilterQueryPositive/filter_impl:3/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads']}}, slow=True, expected_runtime=88813, sl_iterations=3, regression_threshold=10)\n\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_7_slow\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'db_size',\n                                                                                                                                                              'neg_qu_pct',\n                                                                                                                                                              'threads'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:1/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                                'get_mean',\n                                                                                                                                                                'threads',\n                                                                                                                                                                'real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'neg_qu_pct'],\n                    'DBPut/comp_style:1/max_data:107374182400/per_key_size:256/enable_statistics:1/wal:0/iterations:409600/threads:1': ['real_time',\n                                                                                                                                        'put_mean',\n                                                                                                                                        'cpu_time',\n                                                                                                                                        'db_size',\n                                                                                                                                        'threads'],\n                    'IteratorPrev/comp_style:1/max_data:536870912/per_key_size:256/iterations:10240': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'db_size',\n                                                                                                       'threads'],\n                    'IteratorPrev/comp_style:2/max_data:536870912/per_key_size:256/iterations:10240': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'db_size',\n                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'PrefixSeek/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:0/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:0/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                  'cpu_time',\n                                                                                                                                                  'db_size',\n                                                                                                                                                  'threads'],\n                    'PrefixSeek/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                  'cpu_time',\n                                                                                                                                                  'db_size',\n                                                                                                                                                  'threads'],\n                    'PrefixSeek/comp_style:1/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:1/enable_filter:0/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:1/max_data:536870912/per_key_size:256/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                         'cpu_time',\n                                                                                                                                         'db_size',\n                                                                                                                                         'threads'],\n                    'PrefixSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                   'cpu_time',\n                                                                                                                                                   'db_size',\n                                                                                                                                                   'threads'],\n                    'PrefixSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads']},\n 'ribbon_bench': {'FilterBuild/filter_impl:0/bits_per_key:20/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                              'cpu_time',\n                                                                                              'threads',\n                                                                                              'size'],\n                  'FilterBuild/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                  'cpu_time',\n                                                                                                  'threads',\n                                                                                                  'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:20/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                               'cpu_time',\n                                                                                               'threads',\n                                                                                               'size'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryNegative/filter_impl:3/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads',\n                                                                                                         'fp_pct'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads'],\n                  'FilterQueryPositive/filter_impl:3/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads']}}, slow=True, expected_runtime=88813, sl_iterations=3, regression_threshold=10)\n\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_8_slow\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'db_size',\n                                                                                                                                                              'neg_qu_pct',\n                                                                                                                                                              'threads'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:1/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                                'get_mean',\n                                                                                                                                                                'threads',\n                                                                                                                                                                'real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'neg_qu_pct'],\n                    'DBPut/comp_style:1/max_data:107374182400/per_key_size:256/enable_statistics:1/wal:0/iterations:409600/threads:1': ['real_time',\n                                                                                                                                        'put_mean',\n                                                                                                                                        'cpu_time',\n                                                                                                                                        'db_size',\n                                                                                                                                        'threads'],\n                    'IteratorPrev/comp_style:1/max_data:536870912/per_key_size:256/iterations:10240': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'db_size',\n                                                                                                       'threads'],\n                    'IteratorPrev/comp_style:2/max_data:536870912/per_key_size:256/iterations:10240': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'db_size',\n                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'PrefixSeek/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:0/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:0/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                  'cpu_time',\n                                                                                                                                                  'db_size',\n                                                                                                                                                  'threads'],\n                    'PrefixSeek/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                  'cpu_time',\n                                                                                                                                                  'db_size',\n                                                                                                                                                  'threads'],\n                    'PrefixSeek/comp_style:1/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:1/enable_filter:0/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:1/max_data:536870912/per_key_size:256/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                         'cpu_time',\n                                                                                                                                         'db_size',\n                                                                                                                                         'threads'],\n                    'PrefixSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                   'cpu_time',\n                                                                                                                                                   'db_size',\n                                                                                                                                                   'threads'],\n                    'PrefixSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads']},\n 'ribbon_bench': {'FilterBuild/filter_impl:0/bits_per_key:20/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                              'cpu_time',\n                                                                                              'threads',\n                                                                                              'size'],\n                  'FilterBuild/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                  'cpu_time',\n                                                                                                  'threads',\n                                                                                                  'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:20/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                               'cpu_time',\n                                                                                               'threads',\n                                                                                               'size'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryNegative/filter_impl:3/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads',\n                                                                                                         'fp_pct'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads'],\n                  'FilterQueryPositive/filter_impl:3/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads']}}, slow=True, expected_runtime=88709, sl_iterations=3, regression_threshold=10)\n\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_9_slow\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'db_size',\n                                                                                                                                                              'neg_qu_pct',\n                                                                                                                                                              'threads'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:1/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                                'get_mean',\n                                                                                                                                                                'threads',\n                                                                                                                                                                'real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'neg_qu_pct'],\n                    'DBPut/comp_style:1/max_data:107374182400/per_key_size:256/enable_statistics:1/wal:0/iterations:409600/threads:1': ['real_time',\n                                                                                                                                        'put_mean',\n                                                                                                                                        'cpu_time',\n                                                                                                                                        'db_size',\n                                                                                                                                        'threads'],\n                    'IteratorPrev/comp_style:1/max_data:536870912/per_key_size:256/iterations:10240': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'db_size',\n                                                                                                       'threads'],\n                    'IteratorPrev/comp_style:2/max_data:536870912/per_key_size:256/iterations:10240': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'db_size',\n                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'PrefixSeek/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:0/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:0/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                  'cpu_time',\n                                                                                                                                                  'db_size',\n                                                                                                                                                  'threads'],\n                    'PrefixSeek/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                  'cpu_time',\n                                                                                                                                                  'db_size',\n                                                                                                                                                  'threads'],\n                    'PrefixSeek/comp_style:1/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:1/enable_filter:0/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:1/max_data:536870912/per_key_size:256/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                         'cpu_time',\n                                                                                                                                         'db_size',\n                                                                                                                                         'threads'],\n                    'PrefixSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                   'cpu_time',\n                                                                                                                                                   'db_size',\n                                                                                                                                                   'threads'],\n                    'PrefixSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads']},\n 'ribbon_bench': {'FilterBuild/filter_impl:0/bits_per_key:20/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                              'cpu_time',\n                                                                                              'threads',\n                                                                                              'size'],\n                  'FilterBuild/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                  'cpu_time',\n                                                                                                  'threads',\n                                                                                                  'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:20/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                               'cpu_time',\n                                                                                               'threads',\n                                                                                               'size'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryNegative/filter_impl:3/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads',\n                                                                                                         'fp_pct'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads'],\n                  'FilterQueryPositive/filter_impl:3/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads']}}, slow=True, expected_runtime=88711, sl_iterations=3, regression_threshold=10)\n\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_10_slow\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'db_size',\n                                                                                                                                                              'neg_qu_pct',\n                                                                                                                                                              'threads'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:1/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                                'get_mean',\n                                                                                                                                                                'threads',\n                                                                                                                                                                'real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'neg_qu_pct'],\n                    'DBPut/comp_style:1/max_data:107374182400/per_key_size:256/enable_statistics:1/wal:0/iterations:409600/threads:1': ['real_time',\n                                                                                                                                        'put_mean',\n                                                                                                                                        'cpu_time',\n                                                                                                                                        'db_size',\n                                                                                                                                        'threads'],\n                    'IteratorPrev/comp_style:1/max_data:536870912/per_key_size:256/iterations:10240': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'db_size',\n                                                                                                       'threads'],\n                    'IteratorPrev/comp_style:2/max_data:536870912/per_key_size:256/iterations:10240': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'db_size',\n                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'PrefixSeek/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:0/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:0/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                  'cpu_time',\n                                                                                                                                                  'db_size',\n                                                                                                                                                  'threads'],\n                    'PrefixSeek/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                  'cpu_time',\n                                                                                                                                                  'db_size',\n                                                                                                                                                  'threads'],\n                    'PrefixSeek/comp_style:1/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:1/enable_filter:0/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads'],\n                    'PrefixSeek/comp_style:1/max_data:536870912/per_key_size:256/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                         'cpu_time',\n                                                                                                                                         'db_size',\n                                                                                                                                         'threads'],\n                    'PrefixSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                   'cpu_time',\n                                                                                                                                                   'db_size',\n                                                                                                                                                   'threads'],\n                    'PrefixSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:0/enable_filter:1/iterations:10240': ['real_time',\n                                                                                                                                          'cpu_time',\n                                                                                                                                          'db_size',\n                                                                                                                                          'threads']},\n 'ribbon_bench': {'FilterBuild/filter_impl:0/bits_per_key:20/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                              'cpu_time',\n                                                                                              'threads',\n                                                                                              'size'],\n                  'FilterBuild/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                  'cpu_time',\n                                                                                                  'threads',\n                                                                                                  'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:20/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                 'cpu_time',\n                                                                                                 'threads',\n                                                                                                 'size'],\n                  'FilterBuild/filter_impl:3/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                               'cpu_time',\n                                                                                               'threads',\n                                                                                               'size'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryNegative/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:10/key_len_avg:10/entry_num:1024': ['real_time',\n                                                                                                      'cpu_time',\n                                                                                                      'threads',\n                                                                                                      'fp_pct'],\n                  'FilterQueryNegative/filter_impl:2/bits_per_key:20/key_len_avg:100/entry_num:1024': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'threads',\n                                                                                                       'fp_pct'],\n                  'FilterQueryNegative/filter_impl:3/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads',\n                                                                                                         'fp_pct'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:10/key_len_avg:10/entry_num:1048576': ['real_time',\n                                                                                                         'cpu_time',\n                                                                                                         'threads'],\n                  'FilterQueryPositive/filter_impl:0/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads'],\n                  'FilterQueryPositive/filter_impl:3/bits_per_key:10/key_len_avg:100/entry_num:1048576': ['real_time',\n                                                                                                          'cpu_time',\n                                                                                                          'threads']}}, slow=True, expected_runtime=88819, sl_iterations=3, regression_threshold=10)\n\n\nfancy_bench_wrapper(suite_name=\"rocksdb_microbench_suite_11_slow\", binary_to_bench_to_metric_list_map={'db_basic_bench': {'DBGet/comp_style:0/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'db_size',\n                                                                                                                                                                'neg_qu_pct',\n                                                                                                                                                                'threads'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'db_size',\n                                                                                                                                                              'neg_qu_pct',\n                                                                                                                                                              'threads'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                               'get_mean',\n                                                                                                                                                               'threads',\n                                                                                                                                                               'real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'neg_qu_pct'],\n                    'DBGet/comp_style:0/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:1/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:1/max_data:536870912/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:1/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                               'cpu_time',\n                                                                                                                                                               'db_size',\n                                                                                                                                                               'neg_qu_pct',\n                                                                                                                                                               'threads'],\n                    'DBGet/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['db_size',\n                                                                                                                                                              'get_mean',\n                                                                                                                                                              'threads',\n                                                                                                                                                              'real_time',\n                                                                                                                                                              'cpu_time',\n                                                                                                                                                              'neg_qu_pct'],\n                    'DBGet/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['db_size',\n                                                                                                                                                                'get_mean',\n                                                                                                                                                                'threads',\n                                                                                                                                                                'real_time',\n                                                                                                                                                                'cpu_time',\n                                                                                                                                                                'neg_qu_pct'],\n                    'DBPut/comp_style:1/max_data:107374182400/per_key_size:256/enable_statistics:1/wal:0/iterations:409600/threads:1': ['real_time',\n                                                                                                                                        'put_mean',\n                                                                                                                                        'cpu_time',\n                                                                                                                                        'db_size',\n                                                                                                                                        'threads'],\n                    'IteratorPrev/comp_style:1/max_data:536870912/per_key_size:256/iterations:10240': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'db_size',\n                                                                                                       'threads'],\n                    'IteratorPrev/comp_style:2/max_data:536870912/per_key_size:256/iterations:10240': ['real_time',\n                                                                                                       'cpu_time',\n                                                                                                       'db_size',\n                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:0/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:0/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:1/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:1/max_data:536870912/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:1024/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                      'cpu_time',\n                                                                                                                                                                      'db_size',\n                                                                                                                                                                      'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:0/negative_query:0/enable_filter:1/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:2/max_data:134217728/per_key_size:256/enable_statistics:1/negative_query:1/enable_filter:0/iterations:1280/threads:8': ['real_time',\n                                                                                                                                                                     'cpu_time',\n                                                                                                                                                                     'db_size',\n                                                                                                                                                                     'threads'],\n                    'IteratorSeek/comp_style:2/max_data:536870912/per_key_size:1024/enable_statistics:0/negative_query:0/enable_filter:0/iterations:10240/threads:1': ['real_time',\n                                                                                                                                                                       'cpu_time',\n                                                                                                                                                                       'db_size',\n                                                                                                                                                                       'threads'],\n            "
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 58.6220703125,
          "content": "# Prerequisites for Windows:\n#     This cmake build is for Windows 64-bit only.\n#\n# Prerequisites:\n#     You must have at least Visual Studio 2019. Start the Developer Command Prompt window that is a part of Visual Studio installation.\n#     Run the build commands from within the Developer Command Prompt window to have paths to the compiler and runtime libraries set.\n#     You must have git.exe in your %PATH% environment variable.\n#\n# To build Rocksdb for Windows is as easy as 1-2-3-4-5:\n#\n# 1. Update paths to third-party libraries in thirdparty.inc file\n# 2. Create a new directory for build artifacts\n#        mkdir build\n#        cd build\n# 3. Run cmake to generate project files for Windows, add more options to enable required third-party libraries.\n#    See thirdparty.inc for more information.\n#        sample command: cmake -G \"Visual Studio 16 2019\" -DCMAKE_BUILD_TYPE=Release -DWITH_GFLAGS=1 -DWITH_SNAPPY=1 -DWITH_JEMALLOC=1 -DWITH_JNI=1 ..\n# 4. Then build the project in debug mode (you may want to add /m[:<N>] flag to run msbuild in <N> parallel threads\n#                                          or simply /m to use all avail cores)\n#        msbuild rocksdb.sln\n#\n#        rocksdb.sln build features exclusions of test only code in Release. If you build ALL_BUILD then everything\n#        will be attempted but test only code does not build in Release mode.\n#\n# 5. And release mode (/m[:<N>] is also supported)\n#        msbuild rocksdb.sln /p:Configuration=Release\n#\n# Linux:\n#\n# 1. Install a recent toolchain if you're on a older distro. C++17 required (GCC >= 7, Clang >= 5)\n# 2. mkdir build; cd build\n# 3. cmake ..\n# 4. make -j\n\ncmake_minimum_required(VERSION 3.12)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_LIST_DIR}/cmake/modules/\")\ninclude(ReadVersion)\ninclude(GoogleTest)\nget_rocksdb_version(rocksdb_VERSION)\nproject(rocksdb\n  VERSION ${rocksdb_VERSION}\n  DESCRIPTION \"An embeddable persistent key-value store for fast storage\"\n  HOMEPAGE_URL https://rocksdb.org/\n  LANGUAGES CXX C ASM)\n\nif(APPLE)\n  # On macOS Cmake, when cross-compiling, sometimes CMAKE_SYSTEM_PROCESSOR wrongfully stays\n  # the same as CMAKE_HOST_SYSTEM_PROCESSOR regardless the target CPU.\n  # The manual call to  set(CMAKE_SYSTEM_PROCESSOR) has to be set after the project() call.\n  # because project() might reset CMAKE_SYSTEM_PROCESSOR back to the value of CMAKE_HOST_SYSTEM_PROCESSOR.\n  # Check if CMAKE_SYSTEM_PROCESSOR is not equal to CMAKE_OSX_ARCHITECTURES\n  if(NOT CMAKE_OSX_ARCHITECTURES STREQUAL \"\")\n    if(NOT CMAKE_SYSTEM_PROCESSOR STREQUAL CMAKE_OSX_ARCHITECTURES)\n      # Split CMAKE_OSX_ARCHITECTURES into a list\n      string(REPLACE \";\" \" \" ARCH_LIST ${CMAKE_OSX_ARCHITECTURES})\n      separate_arguments(ARCH_LIST UNIX_COMMAND ${ARCH_LIST})\n      # Count the number of architectures\n      list(LENGTH ARCH_LIST ARCH_COUNT)\n      # Ensure that exactly one architecture is specified\n      if(NOT ARCH_COUNT EQUAL 1)\n          message(FATAL_ERROR \"CMAKE_OSX_ARCHITECTURES must have exactly one value. Current value: ${CMAKE_OSX_ARCHITECTURES}\")\n      endif()\n      set(CMAKE_SYSTEM_PROCESSOR ${CMAKE_OSX_ARCHITECTURES})\n      message(STATUS \"CMAKE_SYSTEM_PROCESSOR is manually set to ${CMAKE_SYSTEM_PROCESSOR}\")\n    endif()\n  endif()\nendif()\n\nif(POLICY CMP0042)\n  cmake_policy(SET CMP0042 NEW)\nendif()\n\nif(NOT CMAKE_BUILD_TYPE)\n  if(EXISTS \"${CMAKE_SOURCE_DIR}/.git\")\n    set(default_build_type \"Debug\")\n  else()\n    set(default_build_type \"RelWithDebInfo\")\n  endif()\n  set(CMAKE_BUILD_TYPE \"${default_build_type}\" CACHE STRING\n    \"Default BUILD_TYPE is ${default_build_type}\" FORCE)\nendif()\n\nfind_program(CCACHE_FOUND ccache)\nif(CCACHE_FOUND)\n  set_property(GLOBAL PROPERTY RULE_LAUNCH_COMPILE ccache)\n  set_property(GLOBAL PROPERTY RULE_LAUNCH_LINK ccache)\nendif(CCACHE_FOUND)\n\noption(WITH_JEMALLOC \"build with JeMalloc\" OFF)\noption(WITH_LIBURING \"build with liburing\" ON)\noption(WITH_SNAPPY \"build with SNAPPY\" OFF)\noption(WITH_LZ4 \"build with lz4\" OFF)\noption(WITH_ZLIB \"build with zlib\" OFF)\noption(WITH_ZSTD \"build with zstd\" OFF)\noption(WITH_WINDOWS_UTF8_FILENAMES \"use UTF8 as characterset for opening files, regardles of the system code page\" OFF)\nif (WITH_WINDOWS_UTF8_FILENAMES)\n  add_definitions(-DROCKSDB_WINDOWS_UTF8_FILENAMES)\nendif()\noption(ROCKSDB_BUILD_SHARED \"Build shared versions of the RocksDB libraries\" ON)\n\nif( NOT DEFINED CMAKE_CXX_STANDARD )\n  set(CMAKE_CXX_STANDARD 17)\nendif()\n\ninclude(CMakeDependentOption)\n\nif(MSVC)\n  option(WITH_GFLAGS \"build with GFlags\" OFF)\n  option(WITH_XPRESS \"build with windows built in compression\" OFF)\n  option(ROCKSDB_SKIP_THIRDPARTY \"skip thirdparty.inc\" OFF)\n\n  if(NOT ROCKSDB_SKIP_THIRDPARTY)\n    include(${CMAKE_CURRENT_SOURCE_DIR}/thirdparty.inc)\n  endif()\nelse()\n  if(CMAKE_SYSTEM_NAME MATCHES \"FreeBSD\" AND NOT CMAKE_SYSTEM_NAME MATCHES \"kFreeBSD\")\n    # FreeBSD has jemalloc as default malloc\n    # but it does not have all the jemalloc files in include/...\n    set(WITH_JEMALLOC ON)\n  else()\n    if(WITH_JEMALLOC)\n      find_package(JeMalloc REQUIRED)\n      add_definitions(-DROCKSDB_JEMALLOC -DJEMALLOC_NO_DEMANGLE)\n      list(APPEND THIRDPARTY_LIBS JeMalloc::JeMalloc)\n    endif()\n  endif()\n\n  if(MINGW)\n    option(WITH_GFLAGS \"build with GFlags\" OFF)\n  else()\n    option(WITH_GFLAGS \"build with GFlags\" ON)\n  endif()\n  set(GFLAGS_LIB)\n  if(WITH_GFLAGS)\n    # Config with namespace available since gflags 2.2.2\n    option(GFLAGS_USE_TARGET_NAMESPACE \"Use gflags import target with namespace.\" ON)\n    find_package(gflags CONFIG)\n    if(gflags_FOUND)\n      if(TARGET ${GFLAGS_TARGET})\n        # Config with GFLAGS_TARGET available since gflags 2.2.0\n        set(GFLAGS_LIB ${GFLAGS_TARGET})\n      else()\n        # Config with GFLAGS_LIBRARIES available since gflags 2.1.0\n        set(GFLAGS_LIB ${gflags_LIBRARIES})\n      endif()\n    else()\n      find_package(gflags REQUIRED)\n      set(GFLAGS_LIB gflags::gflags)\n    endif()\n    include_directories(${GFLAGS_INCLUDE_DIR})\n    list(APPEND THIRDPARTY_LIBS ${GFLAGS_LIB})\n    add_definitions(-DGFLAGS=1)\n  endif()\n\n  if(WITH_SNAPPY)\n    find_package(Snappy CONFIG)\n    if(NOT Snappy_FOUND)\n      find_package(Snappy REQUIRED)\n    endif()\n    add_definitions(-DSNAPPY)\n    list(APPEND THIRDPARTY_LIBS Snappy::snappy)\n  endif()\n\n  if(WITH_ZLIB)\n    find_package(ZLIB REQUIRED)\n    add_definitions(-DZLIB)\n    list(APPEND THIRDPARTY_LIBS ZLIB::ZLIB)\n  endif()\n\n  option(WITH_BZ2 \"build with bzip2\" OFF)\n  if(WITH_BZ2)\n    find_package(BZip2 REQUIRED)\n    add_definitions(-DBZIP2)\n    if(BZIP2_INCLUDE_DIRS)\n      include_directories(${BZIP2_INCLUDE_DIRS})\n    else()\n      include_directories(${BZIP2_INCLUDE_DIR})\n    endif()\n    list(APPEND THIRDPARTY_LIBS ${BZIP2_LIBRARIES})\n  endif()\n\n  if(WITH_LZ4)\n    find_package(lz4 REQUIRED)\n    add_definitions(-DLZ4)\n    list(APPEND THIRDPARTY_LIBS lz4::lz4)\n  endif()\n\n  if(WITH_ZSTD)\n    find_package(zstd REQUIRED)\n    add_definitions(-DZSTD)\n    include_directories(${ZSTD_INCLUDE_DIRS})\n    list(APPEND THIRDPARTY_LIBS zstd::zstd)\n  endif()\nendif()\n\noption(WITH_MD_LIBRARY \"build with MD\" ON)\nif(WIN32 AND MSVC)\n  if(WITH_MD_LIBRARY)\n    set(RUNTIME_LIBRARY \"MD\")\n  else()\n    set(RUNTIME_LIBRARY \"MT\")\n  endif()\nendif()\n\nif(MSVC)\n  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /Zi /nologo /EHsc /GS /Gd /GR /GF /fp:precise /Zc:wchar_t /Zc:forScope /errorReport:queue\")\n  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /FC /d2Zi+ /W4 /wd4127 /wd4996 /wd4100 /wd4324\")\nelse()\n  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -W -Wextra -Wall -pthread\")\n  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -Wsign-compare -Wshadow -Wno-unused-parameter -Wno-unused-variable -Woverloaded-virtual -Wnon-virtual-dtor -Wno-missing-field-initializers -Wno-strict-aliasing -Wno-invalid-offsetof\")\n  if(CMAKE_SYSTEM_PROCESSOR MATCHES \"x86_64\")\n    set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -Wstrict-prototypes\")\n  endif()\n  if(MINGW)\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -Wno-format\")\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -Wa,-mbig-obj\")\n    add_definitions(-D_POSIX_C_SOURCE=1)\n  endif()\n  if(NOT CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fno-omit-frame-pointer\")\n    include(CheckCXXCompilerFlag)\n    CHECK_CXX_COMPILER_FLAG(\"-momit-leaf-frame-pointer\" HAVE_OMIT_LEAF_FRAME_POINTER)\n    if(HAVE_OMIT_LEAF_FRAME_POINTER)\n      set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -momit-leaf-frame-pointer\")\n    endif()\n  endif()\nendif()\n\ninclude(CheckCCompilerFlag)\nif(CMAKE_SYSTEM_PROCESSOR MATCHES \"^(powerpc|ppc)64\")\n  CHECK_C_COMPILER_FLAG(\"-mcpu=power9\" HAS_POWER9)\n  if(HAS_POWER9)\n    set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -mcpu=power9 -mtune=power9\")\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -mcpu=power9 -mtune=power9\")\n  else()\n    CHECK_C_COMPILER_FLAG(\"-mcpu=power8\" HAS_POWER8)\n    if(HAS_POWER8)\n      set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -mcpu=power8 -mtune=power8\")\n      set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -mcpu=power8 -mtune=power8\")\n    endif(HAS_POWER8)\n  endif(HAS_POWER9)\n  CHECK_C_COMPILER_FLAG(\"-maltivec\" HAS_ALTIVEC)\n  if(HAS_ALTIVEC)\n    message(STATUS \" HAS_ALTIVEC yes\")\n    set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -maltivec\")\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -maltivec\")\n  endif(HAS_ALTIVEC)\nendif(CMAKE_SYSTEM_PROCESSOR MATCHES \"^(powerpc|ppc)64\")\n\nif(CMAKE_SYSTEM_PROCESSOR MATCHES \"arm64|aarch64|AARCH64\")\n        CHECK_C_COMPILER_FLAG(\"-march=armv8-a+crc+crypto\" HAS_ARMV8_CRC)\n  if(HAS_ARMV8_CRC)\n    message(STATUS \" HAS_ARMV8_CRC yes\")\n    set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -march=armv8-a+crc+crypto -Wno-unused-function\")\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -march=armv8-a+crc+crypto -Wno-unused-function\")\n  endif(HAS_ARMV8_CRC)\nendif(CMAKE_SYSTEM_PROCESSOR MATCHES \"arm64|aarch64|AARCH64\")\n\nif(CMAKE_SYSTEM_PROCESSOR MATCHES \"s390x\")\n  CHECK_C_COMPILER_FLAG(\"-march=native\" HAS_S390X_MARCH_NATIVE)\n  if(HAS_S390X_MARCH_NATIVE)\n    message(STATUS \" HAS_S390X_MARCH_NATIVE yes\")\n  endif(HAS_S390X_MARCH_NATIVE)\nendif(CMAKE_SYSTEM_PROCESSOR MATCHES \"s390x\")\n\nif(CMAKE_SYSTEM_PROCESSOR MATCHES \"loongarch64\")\n  CHECK_C_COMPILER_FLAG(\"-march=loongarch64\" HAS_LOONGARCH64)\n  if(HAS_LOONGARCH64)\n    set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -march=loongarch64 -mtune=loongarch64\")\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -march=loongarch64 -mtune=loongarch64\")\n  endif(HAS_LOONGARCH64)\nendif(CMAKE_SYSTEM_PROCESSOR MATCHES \"loongarch64\")\n\nset(PORTABLE 0 CACHE STRING \"Minimum CPU arch to support, or 0 = current CPU, 1 = baseline CPU\")\nif(PORTABLE MATCHES \"1|ON|YES|TRUE|Y\")\n  # Usually nothing to do; compiler default is typically the most general\n  if(NOT MSVC)\n    if(CMAKE_SYSTEM_PROCESSOR MATCHES \"^s390x\")\n      set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -march=z196\")\n    endif()\n    if(CMAKE_SYSTEM_PROCESSOR MATCHES \"^loongarch64\")\n      set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -march=loongarch64\")\n    endif()\n  endif()\nelseif(PORTABLE MATCHES \"0|OFF|NO|FALSE|N\")\n  if(MSVC)\n    # NOTE: No auto-detection of current CPU, but instead assume some useful\n    # level of optimization is supported\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /arch:AVX2\")\n  else()\n    # Require instruction set from current CPU (with some legacy or opt-out\n    # exceptions)\n    if(CMAKE_SYSTEM_PROCESSOR MATCHES \"^s390x\" AND NOT HAS_S390X_MARCH_NATIVE)\n      set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -march=z196\")\n    elseif(NOT CMAKE_SYSTEM_PROCESSOR MATCHES \"^(powerpc|ppc)64\" AND NOT HAS_ARMV8_CRC)\n      set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -march=native\")\n    endif()\n  endif()\nelse()\n  # Name of a CPU arch spec or feature set to require\n  if(MSVC)\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /arch:${PORTABLE}\")\n  else()\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -march=${PORTABLE}\")\n  endif()\nendif()\n\ninclude(CheckCXXSourceCompiles)\nset(OLD_CMAKE_REQUIRED_FLAGS ${CMAKE_REQUIRED_FLAGS})\nif(NOT MSVC)\n  set(CMAKE_REQUIRED_FLAGS \"-msse4.2 -mpclmul\")\nendif()\n\n# Check if -latomic is required or not\nif (NOT MSVC)\n  set(CMAKE_REQUIRED_FLAGS \"--std=c++17\")\n  CHECK_CXX_SOURCE_COMPILES(\"\n#include <atomic>\nstd::atomic<uint64_t> x(0);\nint main() {\n  uint64_t i = x.load(std::memory_order_relaxed);\n  bool b = x.is_lock_free();\n  return 0;\n}\n\" BUILTIN_ATOMIC)\n  if (NOT BUILTIN_ATOMIC)\n    #TODO: Check if -latomic exists\n    list(APPEND THIRDPARTY_LIBS atomic)\n  endif()\nendif()\n\nif (WITH_LIBURING)\n  find_package(uring)\n  if (uring_FOUND)\n    add_definitions(-DROCKSDB_IOURING_PRESENT)\n    list(APPEND THIRDPARTY_LIBS uring::uring)\n  endif()\nendif()\n\n# Reset the required flags\nset(CMAKE_REQUIRED_FLAGS ${OLD_CMAKE_REQUIRED_FLAGS})\n\noption(WITH_IOSTATS_CONTEXT \"Enable IO stats context\" ON)\nif (NOT WITH_IOSTATS_CONTEXT)\n  add_definitions(-DNIOSTATS_CONTEXT)\nendif()\n\noption(WITH_PERF_CONTEXT \"Enable perf context\" ON)\nif (NOT WITH_PERF_CONTEXT)\n  add_definitions(-DNPERF_CONTEXT)\nendif()\n\noption(FAIL_ON_WARNINGS \"Treat compile warnings as errors\" ON)\nif(FAIL_ON_WARNINGS)\n  if(MSVC)\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /WX\")\n  else() # assume GCC\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -Werror\")\n  endif()\nendif()\n\noption(WITH_ASAN \"build with ASAN\" OFF)\nif(WITH_ASAN)\n  set(CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS} -fsanitize=address\")\n  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fsanitize=address\")\n  set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -fsanitize=address\")\n  if(WITH_JEMALLOC)\n    message(FATAL \"ASAN does not work well with JeMalloc\")\n  endif()\nendif()\n\noption(WITH_TSAN \"build with TSAN\" OFF)\nif(WITH_TSAN)\n  set(CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS} -fsanitize=thread -Wl,-pie\")\n  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fsanitize=thread -fPIC\")\n  set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -fsanitize=thread -fPIC\")\n  if(WITH_JEMALLOC)\n    message(FATAL \"TSAN does not work well with JeMalloc\")\n  endif()\nendif()\n\noption(WITH_UBSAN \"build with UBSAN\" OFF)\nif(WITH_UBSAN)\n  add_definitions(-DROCKSDB_UBSAN_RUN)\n  set(CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS} -fsanitize=undefined\")\n  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fsanitize=undefined\")\n  set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -fsanitize=undefined\")\n  if(WITH_JEMALLOC)\n    message(FATAL \"UBSAN does not work well with JeMalloc\")\n  endif()\nendif()\n\noption(WITH_NUMA \"build with NUMA policy support\" OFF)\nif(WITH_NUMA)\n  find_package(NUMA REQUIRED)\n  add_definitions(-DNUMA)\n  include_directories(${NUMA_INCLUDE_DIRS})\n  list(APPEND THIRDPARTY_LIBS NUMA::NUMA)\nendif()\n\noption(WITH_TBB \"build with Threading Building Blocks (TBB)\" OFF)\nif(WITH_TBB)\n  find_package(TBB REQUIRED)\n  add_definitions(-DTBB)\n  list(APPEND THIRDPARTY_LIBS TBB::TBB)\nendif()\n\n# Stall notifications eat some performance from inserts\noption(DISABLE_STALL_NOTIF \"Build with stall notifications\" OFF)\nif(DISABLE_STALL_NOTIF)\n  add_definitions(-DROCKSDB_DISABLE_STALL_NOTIFICATION)\nendif()\n\noption(WITH_DYNAMIC_EXTENSION \"build with dynamic extension support\" OFF)\nif(NOT WITH_DYNAMIC_EXTENSION)\n  add_definitions(-DROCKSDB_NO_DYNAMIC_EXTENSION)\nendif()\n\noption(ASSERT_STATUS_CHECKED \"build with assert status checked\" OFF)\nif (ASSERT_STATUS_CHECKED)\n  message(STATUS \"Build with assert status checked\")\n  add_definitions(-DROCKSDB_ASSERT_STATUS_CHECKED)\nendif()\n\n\n# RTTI is by default AUTO which enables it in debug and disables it in release.\nset(USE_RTTI AUTO CACHE STRING \"Enable RTTI in builds\")\nset_property(CACHE USE_RTTI PROPERTY STRINGS AUTO ON OFF)\nif(USE_RTTI STREQUAL \"AUTO\")\n  message(STATUS \"Enabling RTTI in Debug builds only (default)\")\n  set(CMAKE_CXX_FLAGS_DEBUG \"${CMAKE_CXX_FLAGS_DEBUG} -DROCKSDB_USE_RTTI\")\n  if(MSVC)\n    set(CMAKE_CXX_FLAGS_RELEASE \"${CMAKE_CXX_FLAGS_RELEASE} /GR-\")\n  else()\n    set(CMAKE_CXX_FLAGS_RELEASE \"${CMAKE_CXX_FLAGS_RELEASE} -fno-rtti\")\n  endif()\nelseif(USE_RTTI)\n  message(STATUS \"Enabling RTTI in all builds\")\n  set(CMAKE_CXX_FLAGS_DEBUG \"${CMAKE_CXX_FLAGS_DEBUG} -DROCKSDB_USE_RTTI\")\n  set(CMAKE_CXX_FLAGS_RELEASE \"${CMAKE_CXX_FLAGS_RELEASE} -DROCKSDB_USE_RTTI\")\nelse()\n  if(MSVC)\n    message(STATUS \"Disabling RTTI in Release builds. Always on in Debug.\")\n    set(CMAKE_CXX_FLAGS_DEBUG \"${CMAKE_CXX_FLAGS_DEBUG} -DROCKSDB_USE_RTTI\")\n    set(CMAKE_CXX_FLAGS_RELEASE \"${CMAKE_CXX_FLAGS_RELEASE} /GR-\")\n  else()\n    message(STATUS \"Disabling RTTI in all builds\")\n    set(CMAKE_CXX_FLAGS_DEBUG \"${CMAKE_CXX_FLAGS_DEBUG} -fno-rtti\")\n    set(CMAKE_CXX_FLAGS_RELEASE \"${CMAKE_CXX_FLAGS_RELEASE} -fno-rtti\")\n  endif()\nendif()\n\n# Used to run CI build and tests so we can run faster\noption(OPTDBG \"Build optimized debug build with MSVC\" OFF)\noption(WITH_RUNTIME_DEBUG \"build with debug version of runtime library\" ON)\nif(MSVC)\n  if(OPTDBG)\n    message(STATUS \"Debug optimization is enabled\")\n    set(CMAKE_CXX_FLAGS_DEBUG \"/Oxt\")\n  else()\n    set(CMAKE_CXX_FLAGS_DEBUG \"${CMAKE_CXX_FLAGS_DEBUG} /Od /RTC1\")\n\n    # Minimal Build is deprecated after MSVC 2015\n    if( MSVC_VERSION GREATER 1900 )\n      set(CMAKE_CXX_FLAGS_DEBUG \"${CMAKE_CXX_FLAGS_DEBUG} /Gm-\")\n    else()\n      set(CMAKE_CXX_FLAGS_DEBUG \"${CMAKE_CXX_FLAGS_DEBUG} /Gm\")\n    endif()\n\n  endif()\n  if(WITH_RUNTIME_DEBUG)\n    set(CMAKE_CXX_FLAGS_DEBUG \"${CMAKE_CXX_FLAGS_DEBUG} /${RUNTIME_LIBRARY}d\")\n  else()\n    set(CMAKE_CXX_FLAGS_DEBUG \"${CMAKE_CXX_FLAGS_DEBUG} /${RUNTIME_LIBRARY}\")\n  endif()\n  set(CMAKE_CXX_FLAGS_RELEASE \"${CMAKE_CXX_FLAGS_RELEASE} /Oxt /Zp8 /Gm- /Gy /${RUNTIME_LIBRARY}\")\n\n  set(CMAKE_SHARED_LINKER_FLAGS \"${CMAKE_SHARED_LINKER_FLAGS} /DEBUG\")\n  set(CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS} /DEBUG\")\nendif()\n\nif(CMAKE_COMPILER_IS_GNUCXX)\n  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fno-builtin-memcmp\")\nendif()\n\nif(CMAKE_SYSTEM_NAME MATCHES \"Cygwin\")\n  add_definitions(-fno-builtin-memcmp -DCYGWIN)\nelseif(CMAKE_SYSTEM_NAME MATCHES \"Darwin\")\n  add_definitions(-DOS_MACOSX)\nelseif(CMAKE_SYSTEM_NAME MATCHES \"iOS\")\n  add_definitions(-DOS_MACOSX -DIOS_CROSS_COMPILE)\nelseif(CMAKE_SYSTEM_NAME MATCHES \"Linux\")\n  add_definitions(-DOS_LINUX)\nelseif(CMAKE_SYSTEM_NAME MATCHES \"SunOS\")\n  add_definitions(-DOS_SOLARIS)\nelseif(CMAKE_SYSTEM_NAME MATCHES \"kFreeBSD\")\n  add_definitions(-DOS_GNU_KFREEBSD)\nelseif(CMAKE_SYSTEM_NAME MATCHES \"FreeBSD\")\n  add_definitions(-DOS_FREEBSD)\nelseif(CMAKE_SYSTEM_NAME MATCHES \"NetBSD\")\n  add_definitions(-DOS_NETBSD)\nelseif(CMAKE_SYSTEM_NAME MATCHES \"OpenBSD\")\n  add_definitions(-DOS_OPENBSD)\nelseif(CMAKE_SYSTEM_NAME MATCHES \"DragonFly\")\n  add_definitions(-DOS_DRAGONFLYBSD)\nelseif(CMAKE_SYSTEM_NAME MATCHES \"Android\")\n  add_definitions(-DOS_ANDROID)\nelseif(CMAKE_SYSTEM_NAME MATCHES \"Windows\")\n  add_definitions(-DWIN32 -DOS_WIN -D_MBCS -DWIN64 -DNOMINMAX)\n  if(MINGW)\n    add_definitions(-D_WIN32_WINNT=_WIN32_WINNT_VISTA)\n  endif()\nendif()\n\nif(NOT WIN32)\n  add_definitions(-DROCKSDB_PLATFORM_POSIX -DROCKSDB_LIB_IO_POSIX)\nendif()\n\noption(WITH_FALLOCATE \"build with fallocate\" ON)\nif(WITH_FALLOCATE)\n  CHECK_CXX_SOURCE_COMPILES(\"\n#include <fcntl.h>\n#include <linux/falloc.h>\nint main() {\n int fd = open(\\\"/dev/null\\\", 0);\n fallocate(fd, FALLOC_FL_KEEP_SIZE, 0, 1024);\n}\n\" HAVE_FALLOCATE)\n  if(HAVE_FALLOCATE)\n    add_definitions(-DROCKSDB_FALLOCATE_PRESENT)\n  endif()\nendif()\n\nCHECK_CXX_SOURCE_COMPILES(\"\n#include <fcntl.h>\nint main() {\n  int fd = open(\\\"/dev/null\\\", 0);\n  sync_file_range(fd, 0, 1024, SYNC_FILE_RANGE_WRITE);\n}\n\" HAVE_SYNC_FILE_RANGE_WRITE)\nif(HAVE_SYNC_FILE_RANGE_WRITE)\n  add_definitions(-DROCKSDB_RANGESYNC_PRESENT)\nendif()\n\nCHECK_CXX_SOURCE_COMPILES(\"\n#include <pthread.h>\nint main() {\n  (void) PTHREAD_MUTEX_ADAPTIVE_NP;\n}\n\" HAVE_PTHREAD_MUTEX_ADAPTIVE_NP)\nif(HAVE_PTHREAD_MUTEX_ADAPTIVE_NP)\n  add_definitions(-DROCKSDB_PTHREAD_ADAPTIVE_MUTEX)\nendif()\n\ninclude(CheckCXXSymbolExists)\nif(CMAKE_SYSTEM_NAME MATCHES \"^FreeBSD\")\n  check_cxx_symbol_exists(malloc_usable_size malloc_np.h HAVE_MALLOC_USABLE_SIZE)\nelse()\n  check_cxx_symbol_exists(malloc_usable_size malloc.h HAVE_MALLOC_USABLE_SIZE)\nendif()\nif(HAVE_MALLOC_USABLE_SIZE)\n  add_definitions(-DROCKSDB_MALLOC_USABLE_SIZE)\nendif()\n\ncheck_cxx_symbol_exists(sched_getcpu sched.h HAVE_SCHED_GETCPU)\nif(HAVE_SCHED_GETCPU)\n  add_definitions(-DROCKSDB_SCHED_GETCPU_PRESENT)\nendif()\n\ncheck_cxx_symbol_exists(getauxval \"sys/auxv.h\" HAVE_AUXV_GETAUXVAL)\nif(HAVE_AUXV_GETAUXVAL)\n  add_definitions(-DROCKSDB_AUXV_GETAUXVAL_PRESENT)\nendif()\n\ncheck_cxx_symbol_exists(F_FULLFSYNC \"fcntl.h\" HAVE_FULLFSYNC)\nif(HAVE_FULLFSYNC)\n  add_definitions(-DHAVE_FULLFSYNC)\nendif()\n\ninclude_directories(${PROJECT_SOURCE_DIR})\ninclude_directories(${PROJECT_SOURCE_DIR}/include)\n\nif(USE_COROUTINES)\n  if(USE_FOLLY OR USE_FOLLY_LITE)\n    message(FATAL_ERROR \"Please specify exactly one of USE_COROUTINES,\"\n    \" USE_FOLLY, and USE_FOLLY_LITE\")\n  endif()\n  set(CMAKE_CXX_STANDARD 20)\n  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fcoroutines -Wno-maybe-uninitialized\")\n  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -Wno-deprecated\")\n  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -Wno-redundant-move\")\n  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -Wno-invalid-memory-model\")\n  add_compile_definitions(USE_COROUTINES)\n  set(USE_FOLLY 1)\nendif()\n\nif(USE_FOLLY)\n  if(USE_FOLLY_LITE)\n    message(FATAL_ERROR \"Please specify one of USE_FOLLY or USE_FOLLY_LITE\")\n  endif()\n  if(ROCKSDB_BUILD_SHARED)\n    message(FATAL_ERROR \"Cannot build RocksDB shared library with folly\")\n  endif()\n  set(ROCKSDB_BUILD_SHARED OFF)\n  set(GFLAGS_SHARED FALSE)\n  find_package(folly)\n  # If cmake could not find the folly-config.cmake file, fall back\n  # to looking in third-party/folly for folly and its dependencies\n  if(NOT FOLLY_LIBRARIES)\n    exec_program(python3 ${PROJECT_SOURCE_DIR}/third-party/folly ARGS\n    build/fbcode_builder/getdeps.py show-inst-dir OUTPUT_VARIABLE\n    FOLLY_INST_PATH)\n    exec_program(ls ARGS -d ${FOLLY_INST_PATH}/../boost* OUTPUT_VARIABLE\n    BOOST_INST_PATH)\n    exec_program(ls ARGS -d ${FOLLY_INST_PATH}/../fmt* OUTPUT_VARIABLE\n    FMT_INST_PATH)\n    exec_program(ls ARGS -d ${FOLLY_INST_PATH}/../gflags* OUTPUT_VARIABLE\n    GFLAGS_INST_PATH)\n    set(Boost_DIR ${BOOST_INST_PATH}/lib/cmake/Boost-1.83.0)\n    if(EXISTS ${FMT_INST_PATH}/lib64)\n      set(fmt_DIR ${FMT_INST_PATH}/lib64/cmake/fmt)\n    else()\n      set(fmt_DIR ${FMT_INST_PATH}/lib/cmake/fmt)\n    endif()\n    set(gflags_DIR ${GFLAGS_INST_PATH}/lib/cmake/gflags)\n\n    exec_program(sed ARGS -i 's/gflags_shared//g'\n    ${FOLLY_INST_PATH}/lib/cmake/folly/folly-targets.cmake)\n\n    include(${FOLLY_INST_PATH}/lib/cmake/folly/folly-config.cmake)\n  endif()\n\n  add_compile_definitions(USE_FOLLY FOLLY_NO_CONFIG HAVE_CXX11_ATOMIC)\n  list(APPEND THIRDPARTY_LIBS Folly::folly)\n  set(FOLLY_LIBS Folly::folly)\n  set(CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS} -Wl,--copy-dt-needed-entries\")\nendif()\nfind_package(Threads REQUIRED)\n\n# Main library source code\n\nset(SOURCES\n        cache/cache.cc\n        cache/cache_entry_roles.cc\n        cache/cache_key.cc\n        cache/cache_helpers.cc\n        cache/cache_reservation_manager.cc\n        cache/charged_cache.cc\n        cache/clock_cache.cc\n        cache/compressed_secondary_cache.cc\n        cache/lru_cache.cc\n        cache/secondary_cache.cc\n        cache/secondary_cache_adapter.cc\n        cache/sharded_cache.cc\n        cache/tiered_secondary_cache.cc\n        db/arena_wrapped_db_iter.cc\n        db/attribute_group_iterator_impl.cc\n        db/blob/blob_contents.cc\n        db/blob/blob_fetcher.cc\n        db/blob/blob_file_addition.cc\n        db/blob/blob_file_builder.cc\n        db/blob/blob_file_cache.cc\n        db/blob/blob_file_garbage.cc\n        db/blob/blob_file_meta.cc\n        db/blob/blob_file_reader.cc\n        db/blob/blob_garbage_meter.cc\n        db/blob/blob_log_format.cc\n        db/blob/blob_log_sequential_reader.cc\n        db/blob/blob_log_writer.cc\n        db/blob/blob_source.cc\n        db/blob/prefetch_buffer_collection.cc\n        db/builder.cc\n        db/c.cc\n        db/coalescing_iterator.cc\n        db/column_family.cc\n        db/compaction/compaction.cc\n        db/compaction/compaction_iterator.cc\n        db/compaction/compaction_picker.cc\n        db/compaction/compaction_job.cc\n        db/compaction/compaction_picker_fifo.cc\n        db/compaction/compaction_picker_level.cc\n        db/compaction/compaction_picker_universal.cc\n        db/compaction/compaction_service_job.cc\n        db/compaction/compaction_state.cc\n        db/compaction/compaction_outputs.cc\n        db/compaction/sst_partitioner.cc\n        db/compaction/subcompaction_state.cc\n        db/convenience.cc\n        db/db_filesnapshot.cc\n        db/db_impl/compacted_db_impl.cc\n        db/db_impl/db_impl.cc\n        db/db_impl/db_impl_write.cc\n        db/db_impl/db_impl_compaction_flush.cc\n        db/db_impl/db_impl_files.cc\n        db/db_impl/db_impl_follower.cc\n        db/db_impl/db_impl_open.cc\n        db/db_impl/db_impl_debug.cc\n        db/db_impl/db_impl_experimental.cc\n        db/db_impl/db_impl_readonly.cc\n        db/db_impl/db_impl_secondary.cc\n        db/db_info_dumper.cc\n        db/db_iter.cc\n        db/dbformat.cc\n        db/error_handler.cc\n        db/event_helpers.cc\n        db/experimental.cc\n        db/external_sst_file_ingestion_job.cc\n        db/file_indexer.cc\n        db/flush_job.cc\n        db/flush_scheduler.cc\n        db/forward_iterator.cc\n        db/import_column_family_job.cc\n        db/internal_stats.cc\n        db/logs_with_prep_tracker.cc\n        db/log_reader.cc\n        db/log_writer.cc\n        db/malloc_stats.cc\n        db/manifest_ops.cc\n        db/memtable.cc\n        db/memtable_list.cc\n        db/merge_helper.cc\n        db/merge_operator.cc\n        db/output_validator.cc\n        db/periodic_task_scheduler.cc\n        db/range_del_aggregator.cc\n        db/range_tombstone_fragmenter.cc\n        db/repair.cc\n        db/seqno_to_time_mapping.cc\n        db/snapshot_impl.cc\n        db/table_cache.cc\n        db/table_properties_collector.cc\n        db/transaction_log_impl.cc\n        db/trim_history_scheduler.cc\n        db/version_builder.cc\n        db/version_edit.cc\n        db/version_edit_handler.cc\n        db/version_set.cc\n        db/wal_edit.cc\n        db/wal_manager.cc\n        db/wide/wide_column_serialization.cc\n        db/wide/wide_columns.cc\n        db/wide/wide_columns_helper.cc\n        db/write_batch.cc\n        db/write_batch_base.cc\n        db/write_controller.cc\n        db/write_stall_stats.cc\n        db/write_thread.cc\n        env/composite_env.cc\n        env/env.cc\n        env/env_chroot.cc\n        env/env_encryption.cc\n        env/file_system.cc\n        env/file_system_tracer.cc\n        env/fs_on_demand.cc\n        env/fs_remap.cc\n        env/mock_env.cc\n        env/unique_id_gen.cc\n        file/delete_scheduler.cc\n        file/file_prefetch_buffer.cc\n        file/file_util.cc\n        file/filename.cc\n        file/line_file_reader.cc\n        file/random_access_file_reader.cc\n        file/read_write_util.cc\n        file/readahead_raf.cc\n        file/sequence_file_reader.cc\n        file/sst_file_manager_impl.cc\n        file/writable_file_writer.cc\n        logging/auto_roll_logger.cc\n        logging/event_logger.cc\n        logging/log_buffer.cc\n        memory/arena.cc\n        memory/concurrent_arena.cc\n        memory/jemalloc_nodump_allocator.cc\n        memory/memkind_kmem_allocator.cc\n        memory/memory_allocator.cc\n        memtable/alloc_tracker.cc\n        memtable/hash_linklist_rep.cc\n        memtable/hash_skiplist_rep.cc\n        memtable/skiplistrep.cc\n        memtable/vectorrep.cc\n        memtable/wbwi_memtable.cc\n        memtable/write_buffer_manager.cc\n        monitoring/histogram.cc\n        monitoring/histogram_windowing.cc\n        monitoring/in_memory_stats_history.cc\n        monitoring/instrumented_mutex.cc\n        monitoring/iostats_context.cc\n        monitoring/perf_context.cc\n        monitoring/perf_level.cc\n        monitoring/persistent_stats_history.cc\n        monitoring/statistics.cc\n        monitoring/thread_status_impl.cc\n        monitoring/thread_status_updater.cc\n        monitoring/thread_status_util.cc\n        monitoring/thread_status_util_debug.cc\n        options/cf_options.cc\n        options/configurable.cc\n        options/customizable.cc\n        options/db_options.cc\n        options/offpeak_time_info.cc\n        options/options.cc\n        options/options_helper.cc\n        options/options_parser.cc\n        port/mmap.cc\n        port/stack_trace.cc\n        table/adaptive/adaptive_table_factory.cc\n        table/block_based/binary_search_index_reader.cc\n        table/block_based/block.cc\n        table/block_based/block_based_table_builder.cc\n        table/block_based/block_based_table_factory.cc\n        table/block_based/block_based_table_iterator.cc\n        table/block_based/block_based_table_reader.cc\n        table/block_based/block_builder.cc\n        table/block_based/block_cache.cc\n        table/block_based/block_prefetcher.cc\n        table/block_based/block_prefix_index.cc\n        table/block_based/data_block_hash_index.cc\n        table/block_based/data_block_footer.cc\n        table/block_based/filter_block_reader_common.cc\n        table/block_based/filter_policy.cc\n        table/block_based/flush_block_policy.cc\n        table/block_based/full_filter_block.cc\n        table/block_based/hash_index_reader.cc\n        table/block_based/index_builder.cc\n        table/block_based/index_reader_common.cc\n        table/block_based/parsed_full_filter_block.cc\n        table/block_based/partitioned_filter_block.cc\n        table/block_based/partitioned_index_iterator.cc\n        table/block_based/partitioned_index_reader.cc\n        table/block_based/reader_common.cc\n        table/block_based/uncompression_dict_reader.cc\n        table/block_fetcher.cc\n        table/cuckoo/cuckoo_table_builder.cc\n        table/cuckoo/cuckoo_table_factory.cc\n        table/cuckoo/cuckoo_table_reader.cc\n        table/format.cc\n        table/get_context.cc\n        table/iterator.cc\n        table/merging_iterator.cc\n        table/compaction_merging_iterator.cc\n        table/meta_blocks.cc\n        table/persistent_cache_helper.cc\n        table/plain/plain_table_bloom.cc\n        table/plain/plain_table_builder.cc\n        table/plain/plain_table_factory.cc\n        table/plain/plain_table_index.cc\n        table/plain/plain_table_key_coding.cc\n        table/plain/plain_table_reader.cc\n        table/sst_file_dumper.cc\n        table/sst_file_reader.cc\n        table/sst_file_writer.cc\n        table/table_factory.cc\n        table/table_properties.cc\n        table/two_level_iterator.cc\n        table/unique_id.cc\n        test_util/sync_point.cc\n        test_util/sync_point_impl.cc\n        test_util/testutil.cc\n        test_util/transaction_test_util.cc\n        tools/block_cache_analyzer/block_cache_trace_analyzer.cc\n        tools/dump/db_dump_tool.cc\n        tools/io_tracer_parser_tool.cc\n        tools/ldb_cmd.cc\n        tools/ldb_tool.cc\n        tools/sst_dump_tool.cc\n        tools/trace_analyzer_tool.cc\n        trace_replay/block_cache_tracer.cc\n        trace_replay/io_tracer.cc\n        trace_replay/trace_record_handler.cc\n        trace_replay/trace_record_result.cc\n        trace_replay/trace_record.cc\n        trace_replay/trace_replay.cc\n        util/async_file_reader.cc\n        util/cleanable.cc\n        util/coding.cc\n        util/compaction_job_stats_impl.cc\n        util/comparator.cc\n        util/compression.cc\n        util/compression_context_cache.cc\n        util/concurrent_task_limiter_impl.cc\n        util/crc32c.cc\n        util/data_structure.cc\n        util/dynamic_bloom.cc\n        util/hash.cc\n        util/murmurhash.cc\n        util/random.cc\n        util/rate_limiter.cc\n        util/ribbon_config.cc\n        util/slice.cc\n        util/file_checksum_helper.cc\n        util/status.cc\n        util/stderr_logger.cc\n        util/string_util.cc\n        util/thread_local.cc\n        util/threadpool_imp.cc\n        util/udt_util.cc\n        util/write_batch_util.cc\n        util/xxhash.cc\n        utilities/agg_merge/agg_merge.cc\n        utilities/backup/backup_engine.cc\n        utilities/blob_db/blob_compaction_filter.cc\n        utilities/blob_db/blob_db.cc\n        utilities/blob_db/blob_db_impl.cc\n        utilities/blob_db/blob_db_impl_filesnapshot.cc\n        utilities/blob_db/blob_dump_tool.cc\n        utilities/blob_db/blob_file.cc\n        utilities/cache_dump_load.cc\n        utilities/cache_dump_load_impl.cc\n        utilities/cassandra/cassandra_compaction_filter.cc\n        utilities/cassandra/format.cc\n        utilities/cassandra/merge_operator.cc\n        utilities/checkpoint/checkpoint_impl.cc\n        utilities/compaction_filters.cc\n        utilities/compaction_filters/remove_emptyvalue_compactionfilter.cc\n        utilities/counted_fs.cc\n        utilities/debug.cc\n        utilities/env_mirror.cc\n        utilities/env_timed.cc\n        utilities/fault_injection_env.cc\n        utilities/fault_injection_fs.cc\n        utilities/fault_injection_secondary_cache.cc\n        utilities/leveldb_options/leveldb_options.cc\n        utilities/memory/memory_util.cc\n        utilities/merge_operators.cc\n        utilities/merge_operators/bytesxor.cc\n        utilities/merge_operators/max.cc\n        utilities/merge_operators/put.cc\n        utilities/merge_operators/sortlist.cc\n        utilities/merge_operators/string_append/stringappend.cc\n        utilities/merge_operators/string_append/stringappend2.cc\n        utilities/merge_operators/uint64add.cc\n        utilities/object_registry.cc\n        utilities/option_change_migration/option_change_migration.cc\n        utilities/options/options_util.cc\n        utilities/persistent_cache/block_cache_tier.cc\n        utilities/persistent_cache/block_cache_tier_file.cc\n        utilities/persistent_cache/block_cache_tier_metadata.cc\n        utilities/persistent_cache/persistent_cache_tier.cc\n        utilities/persistent_cache/volatile_tier_impl.cc\n        utilities/simulator_cache/cache_simulator.cc\n        utilities/simulator_cache/sim_cache.cc\n        utilities/table_properties_collectors/compact_for_tiering_collector.cc\n        utilities/table_properties_collectors/compact_on_deletion_collector.cc\n        utilities/trace/file_trace_reader_writer.cc\n        utilities/trace/replayer_impl.cc\n        utilities/transactions/lock/lock_manager.cc\n        utilities/transactions/lock/point/point_lock_tracker.cc\n        utilities/transactions/lock/point/point_lock_manager.cc\n        utilities/transactions/lock/range/range_tree/range_tree_lock_manager.cc\n        utilities/transactions/lock/range/range_tree/range_tree_lock_tracker.cc\n        utilities/transactions/optimistic_transaction_db_impl.cc\n        utilities/transactions/optimistic_transaction.cc\n        utilities/transactions/pessimistic_transaction.cc\n        utilities/transactions/pessimistic_transaction_db.cc\n        utilities/transactions/snapshot_checker.cc\n        utilities/transactions/transaction_base.cc\n        utilities/transactions/transaction_db_mutex_impl.cc\n        utilities/transactions/transaction_util.cc\n        utilities/transactions/write_prepared_txn.cc\n        utilities/transactions/write_prepared_txn_db.cc\n        utilities/transactions/write_unprepared_txn.cc\n        utilities/transactions/write_unprepared_txn_db.cc\n        utilities/types_util.cc\n        utilities/ttl/db_ttl_impl.cc\n        utilities/wal_filter.cc\n        utilities/write_batch_with_index/write_batch_with_index.cc\n        utilities/write_batch_with_index/write_batch_with_index_internal.cc)\n\nlist(APPEND SOURCES\n  utilities/transactions/lock/range/range_tree/lib/locktree/concurrent_tree.cc\n  utilities/transactions/lock/range/range_tree/lib/locktree/keyrange.cc\n  utilities/transactions/lock/range/range_tree/lib/locktree/lock_request.cc\n  utilities/transactions/lock/range/range_tree/lib/locktree/locktree.cc\n  utilities/transactions/lock/range/range_tree/lib/locktree/manager.cc\n  utilities/transactions/lock/range/range_tree/lib/locktree/range_buffer.cc\n  utilities/transactions/lock/range/range_tree/lib/locktree/treenode.cc\n  utilities/transactions/lock/range/range_tree/lib/locktree/txnid_set.cc\n  utilities/transactions/lock/range/range_tree/lib/locktree/wfg.cc\n  utilities/transactions/lock/range/range_tree/lib/standalone_port.cc\n  utilities/transactions/lock/range/range_tree/lib/util/dbt.cc\n  utilities/transactions/lock/range/range_tree/lib/util/memarena.cc)\n\nmessage(STATUS \"ROCKSDB_PLUGINS: ${ROCKSDB_PLUGINS}\")\nif ( ROCKSDB_PLUGINS )\n  string(REPLACE \" \" \";\" PLUGINS ${ROCKSDB_PLUGINS})\n  foreach (plugin ${PLUGINS})\n    add_subdirectory(\"plugin/${plugin}\")\n    foreach (src ${${plugin}_SOURCES})\n      list(APPEND SOURCES plugin/${plugin}/${src})\n      set_source_files_properties(\n        plugin/${plugin}/${src}\n        PROPERTIES COMPILE_FLAGS \"${${plugin}_COMPILE_FLAGS}\")\n    endforeach()\n    foreach (test ${${plugin}_TESTS})\n      list(APPEND PLUGIN_TESTS plugin/${plugin}/${test})\n      set_source_files_properties(\n        plugin/${plugin}/${test}\n        PROPERTIES COMPILE_FLAGS \"${${plugin}_COMPILE_FLAGS}\")\n    endforeach()\n    foreach (path ${${plugin}_INCLUDE_PATHS})\n      include_directories(${path})\n    endforeach()\n    foreach (lib ${${plugin}_LIBS})\n      list(APPEND THIRDPARTY_LIBS ${lib})\n    endforeach()\n    foreach (link_path ${${plugin}_LINK_PATHS})\n      link_directories(AFTER ${link_path})\n    endforeach()\n    set(CMAKE_SHARED_LINKER_FLAGS \"${CMAKE_SHARED_LINKER_FLAGS} ${${plugin}_CMAKE_SHARED_LINKER_FLAGS}\")\n    set(CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS} ${${plugin}_CMAKE_EXE_LINKER_FLAGS}\")\n  endforeach()\nendif()\n\nif(CMAKE_SYSTEM_PROCESSOR MATCHES \"^(powerpc|ppc)64\")\n  list(APPEND SOURCES\n    util/crc32c_ppc.c\n    util/crc32c_ppc_asm.S)\nendif(CMAKE_SYSTEM_PROCESSOR MATCHES \"^(powerpc|ppc)64\")\n\nif(HAS_ARMV8_CRC)\n  list(APPEND SOURCES\n    util/crc32c_arm64.cc)\nendif(HAS_ARMV8_CRC)\n\nif(WIN32)\n  list(APPEND SOURCES\n    port/win/io_win.cc\n    port/win/env_win.cc\n    port/win/env_default.cc\n    port/win/port_win.cc\n    port/win/win_logger.cc\n    port/win/win_thread.cc)\nif(WITH_XPRESS)\n  list(APPEND SOURCES\n    port/win/xpress_win.cc)\nendif()\n\nif(WITH_JEMALLOC)\n  list(APPEND SOURCES\n    port/win/win_jemalloc.cc)\nendif()\n\nelse()\n  list(APPEND SOURCES\n    port/port_posix.cc\n    env/env_posix.cc\n    env/fs_posix.cc\n    env/io_posix.cc)\nendif()\n\nif(USE_FOLLY_LITE)\n  list(APPEND SOURCES\n    third-party/folly/folly/container/detail/F14Table.cpp\n    third-party/folly/folly/detail/Futex.cpp\n    third-party/folly/folly/lang/Exception.cpp\n    third-party/folly/folly/lang/SafeAssert.cpp\n    third-party/folly/folly/lang/ToAscii.cpp\n    third-party/folly/folly/ScopeGuard.cpp\n    third-party/folly/folly/synchronization/AtomicNotification.cpp\n    third-party/folly/folly/synchronization/DistributedMutex.cpp\n    third-party/folly/folly/synchronization/ParkingLot.cpp)\n  include_directories(${PROJECT_SOURCE_DIR}/third-party/folly)\n  exec_program(python3 ${PROJECT_SOURCE_DIR}/third-party/folly ARGS\n  build/fbcode_builder/getdeps.py show-source-dir boost OUTPUT_VARIABLE\n  BOOST_SOURCE_PATH)\n  exec_program(ls ARGS -d ${BOOST_SOURCE_PATH}/boost* OUTPUT_VARIABLE\n  BOOST_INCLUDE_DIR)\n  include_directories(${BOOST_INCLUDE_DIR})\n  add_definitions(-DUSE_FOLLY -DFOLLY_NO_CONFIG)\n  list(APPEND THIRDPARTY_LIBS glog)\nendif()\n\nset(ROCKSDB_STATIC_LIB rocksdb${ARTIFACT_SUFFIX})\nset(ROCKSDB_SHARED_LIB rocksdb-shared${ARTIFACT_SUFFIX})\n\n\nif(WIN32)\n  set(SYSTEM_LIBS ${SYSTEM_LIBS} shlwapi.lib rpcrt4.lib)\nelse()\n  set(SYSTEM_LIBS ${CMAKE_THREAD_LIBS_INIT})\nendif()\n\nset(ROCKSDB_PLUGIN_EXTERNS \"\")\nset(ROCKSDB_PLUGIN_BUILTINS \"\")\nmessage(STATUS \"ROCKSDB PLUGINS TO BUILD ${ROCKSDB_PLUGINS}\")\nforeach(PLUGIN IN LISTS PLUGINS)\n  set(PLUGIN_ROOT \"${CMAKE_CURRENT_SOURCE_DIR}/plugin/${PLUGIN}/\")\n  message(STATUS \"PLUGIN ${PLUGIN} including rocksb plugin ${PLUGIN_ROOT}\")\n  set(PLUGINMKFILE \"${PLUGIN_ROOT}${PLUGIN}.mk\")\n  if (NOT EXISTS ${PLUGINMKFILE})\n    message(FATAL_ERROR \"PLUGIN ${PLUGIN} Missing plugin makefile: ${PLUGINMKFILE}\")\n  endif()\n  file(READ ${PLUGINMKFILE} PLUGINMK)\n\n  string(REGEX MATCH \"SOURCES = ([^\\n]*)\" FOO ${PLUGINMK})\n  set(MK_SOURCES ${CMAKE_MATCH_1})\n  separate_arguments(MK_SOURCES)\n  foreach(MK_FILE IN LISTS MK_SOURCES)\n    list(APPEND SOURCES \"${PLUGIN_ROOT}${MK_FILE}\")\n    message(STATUS \"PLUGIN ${PLUGIN} Appending ${PLUGIN_ROOT}${MK_FILE} to SOURCES\")\n  endforeach()\n\n  string(REGEX MATCH \"_FUNC = ([^\\n]*)\" FOO ${PLUGINMK})\n  if (NOT ${CMAKE_MATCH_1} STREQUAL \"\")\n    string(APPEND ROCKSDB_PLUGIN_BUILTINS \"{\\\"${PLUGIN}\\\", \" ${CMAKE_MATCH_1} \"},\")\n    string(APPEND ROCKSDB_PLUGIN_EXTERNS \"int \" ${CMAKE_MATCH_1} \"(ROCKSDB_NAMESPACE::ObjectLibrary&, const std::string&); \")\n  endif()\n\n  string(REGEX MATCH \"_LIBS = ([^\\n]*)\" FOO ${PLUGINMK})\n  separate_arguments(CMAKE_MATCH_1)\n  foreach(MK_LIB IN LISTS CMAKE_MATCH_1)\n    list(APPEND THIRDPARTY_LIBS \"${MK_LIB}\")\n  endforeach()\n  message(STATUS \"PLUGIN ${PLUGIN} THIRDPARTY_LIBS=${THIRDPARTY_LIBS}\")\n\n  #TODO: We need to set any compile/link-time flags and add any link libraries\nendforeach()\n\nstring(TIMESTAMP TS \"%Y-%m-%d %H:%M:%S\" UTC)\nset(BUILD_DATE \"${TS}\" CACHE STRING \"the time we first built rocksdb\")\n\nfind_package(Git)\n\nif(GIT_FOUND AND EXISTS \"${CMAKE_CURRENT_SOURCE_DIR}/.git\")\n  execute_process(WORKING_DIRECTORY \"${CMAKE_CURRENT_SOURCE_DIR}\" OUTPUT_VARIABLE GIT_SHA COMMAND \"${GIT_EXECUTABLE}\" rev-parse HEAD )\n  execute_process(WORKING_DIRECTORY \"${CMAKE_CURRENT_SOURCE_DIR}\" RESULT_VARIABLE GIT_MOD COMMAND \"${GIT_EXECUTABLE}\" diff-index HEAD --quiet)\n  execute_process(WORKING_DIRECTORY \"${CMAKE_CURRENT_SOURCE_DIR}\" OUTPUT_VARIABLE GIT_DATE COMMAND \"${GIT_EXECUTABLE}\" log -1 --date=format:\"%Y-%m-%d %T\" --format=\"%ad\")\n  execute_process(WORKING_DIRECTORY \"${CMAKE_CURRENT_SOURCE_DIR}\" OUTPUT_VARIABLE GIT_TAG RESULT_VARIABLE rv COMMAND \"${GIT_EXECUTABLE}\" symbolic-ref -q --short HEAD OUTPUT_STRIP_TRAILING_WHITESPACE)\n  if (rv AND NOT rv EQUAL 0)\n    execute_process(WORKING_DIRECTORY \"${CMAKE_CURRENT_SOURCE_DIR}\" OUTPUT_VARIABLE GIT_TAG COMMAND \"${GIT_EXECUTABLE}\" describe --tags --exact-match OUTPUT_STRIP_TRAILING_WHITESPACE)\n  endif()\nelse()\n  set(GIT_SHA 0)\n  set(GIT_MOD 1)\nendif()\nstring(REGEX REPLACE \"[^0-9a-fA-F]+\" \"\" GIT_SHA \"${GIT_SHA}\")\nstring(REGEX REPLACE \"[^0-9: /-]+\" \"\" GIT_DATE \"${GIT_DATE}\")\n\nset(BUILD_VERSION_CC ${CMAKE_BINARY_DIR}/build_version.cc)\nconfigure_file(util/build_version.cc.in ${BUILD_VERSION_CC} @ONLY)\n\nadd_library(${ROCKSDB_STATIC_LIB} STATIC ${SOURCES} ${BUILD_VERSION_CC})\ntarget_include_directories(${ROCKSDB_STATIC_LIB} PUBLIC\n  $<BUILD_INTERFACE:${PROJECT_SOURCE_DIR}/include>)\ntarget_link_libraries(${ROCKSDB_STATIC_LIB} PRIVATE\n  ${THIRDPARTY_LIBS} ${SYSTEM_LIBS})\n\nif(ROCKSDB_BUILD_SHARED)\n  add_library(${ROCKSDB_SHARED_LIB} SHARED ${SOURCES} ${BUILD_VERSION_CC})\n  target_include_directories(${ROCKSDB_SHARED_LIB} PUBLIC\n    $<BUILD_INTERFACE:${PROJECT_SOURCE_DIR}/include>)\n  target_link_libraries(${ROCKSDB_SHARED_LIB} PRIVATE\n    ${THIRDPARTY_LIBS} ${SYSTEM_LIBS})\n\n  if(WIN32)\n    set_target_properties(${ROCKSDB_SHARED_LIB} PROPERTIES\n      COMPILE_DEFINITIONS \"ROCKSDB_DLL;ROCKSDB_LIBRARY_EXPORTS\")\n    if(MSVC)\n      set_target_properties(${ROCKSDB_STATIC_LIB} PROPERTIES\n        COMPILE_FLAGS \"/Fd${CMAKE_CFG_INTDIR}/${ROCKSDB_STATIC_LIB}.pdb\")\n      set_target_properties(${ROCKSDB_SHARED_LIB} PROPERTIES\n        COMPILE_FLAGS \"/Fd${CMAKE_CFG_INTDIR}/${ROCKSDB_SHARED_LIB}.pdb\")\n    endif()\n  else()\n    set_target_properties(${ROCKSDB_SHARED_LIB} PROPERTIES\n                          LINKER_LANGUAGE CXX\n                          VERSION ${rocksdb_VERSION}\n                          SOVERSION ${rocksdb_VERSION_MAJOR}\n                          OUTPUT_NAME \"rocksdb${ARTIFACT_SUFFIX}\")\n  endif()\nendif()\n\nif(ROCKSDB_BUILD_SHARED AND NOT WIN32)\n  set(ROCKSDB_LIB ${ROCKSDB_SHARED_LIB})\nelse()\n  set(ROCKSDB_LIB ${ROCKSDB_STATIC_LIB})\nendif()\n\noption(WITH_JNI \"build with JNI\" OFF)\n# Tests are excluded from Release builds\nCMAKE_DEPENDENT_OPTION(WITH_TESTS \"build with tests\" ON\n  \"CMAKE_BUILD_TYPE STREQUAL Debug\" OFF)\noption(WITH_BENCHMARK_TOOLS \"build with benchmarks\" ON)\noption(WITH_CORE_TOOLS \"build with ldb and sst_dump\" ON)\noption(WITH_TOOLS \"build with tools\" ON)\n\nif(WITH_TESTS OR WITH_BENCHMARK_TOOLS OR WITH_TOOLS OR WITH_JNI OR JNI)\n  include_directories(SYSTEM ${PROJECT_SOURCE_DIR}/third-party/gtest-1.8.1/fused-src)\nendif()\nif(WITH_JNI OR JNI)\n  message(STATUS \"JNI library is enabled\")\n  add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/java)\nelse()\n  message(STATUS \"JNI library is disabled\")\nendif()\n\n# Installation and packaging\nif(WIN32)\n  option(ROCKSDB_INSTALL_ON_WINDOWS \"Enable install target on Windows\" OFF)\nendif()\nif(NOT WIN32 OR ROCKSDB_INSTALL_ON_WINDOWS)\n  if(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT)\n    if(${CMAKE_SYSTEM_NAME} STREQUAL \"Linux\")\n      # Change default installation prefix on Linux to /usr\n      set(CMAKE_INSTALL_PREFIX /usr CACHE PATH \"Install path prefix, prepended onto install directories.\" FORCE)\n    endif()\n  endif()\n\n  include(GNUInstallDirs)\n  include(CMakePackageConfigHelpers)\n\n  set(package_config_destination ${CMAKE_INSTALL_LIBDIR}/cmake/rocksdb)\n\n  configure_package_config_file(\n    ${CMAKE_CURRENT_LIST_DIR}/cmake/RocksDBConfig.cmake.in RocksDBConfig.cmake\n    INSTALL_DESTINATION ${package_config_destination}\n  )\n\n  write_basic_package_version_file(\n    RocksDBConfigVersion.cmake\n    VERSION ${rocksdb_VERSION}\n    COMPATIBILITY SameMajorVersion\n  )\n\n  configure_file(\n    ${PROJECT_NAME}.pc.in\n    ${PROJECT_NAME}.pc\n    @ONLY\n  )\n\n  install(DIRECTORY include/rocksdb COMPONENT devel DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}\")\n\n  foreach (plugin ${PLUGINS})\n    foreach (header ${${plugin}_HEADERS})\n      install(FILES plugin/${plugin}/${header} DESTINATION ${CMAKE_INSTALL_INCLUDEDIR}/rocksdb/plugin/${plugin})\n    endforeach()\n  endforeach()\n\n  install(DIRECTORY \"${PROJECT_SOURCE_DIR}/cmake/modules\" COMPONENT devel DESTINATION ${package_config_destination})\n\n  install(\n    TARGETS ${ROCKSDB_STATIC_LIB}\n    EXPORT RocksDBTargets\n    COMPONENT devel\n    ARCHIVE DESTINATION \"${CMAKE_INSTALL_LIBDIR}\"\n    INCLUDES DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}\"\n  )\n\n  if(ROCKSDB_BUILD_SHARED)\n    install(\n      TARGETS ${ROCKSDB_SHARED_LIB}\n      EXPORT RocksDBTargets\n      COMPONENT runtime\n      ARCHIVE DESTINATION \"${CMAKE_INSTALL_LIBDIR}\"\n      RUNTIME DESTINATION \"${CMAKE_INSTALL_BINDIR}\"\n      LIBRARY DESTINATION \"${CMAKE_INSTALL_LIBDIR}\"\n      INCLUDES DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}\"\n    )\n  endif()\n\n  install(\n    EXPORT RocksDBTargets\n    COMPONENT devel\n    DESTINATION ${package_config_destination}\n    NAMESPACE RocksDB::\n  )\n\n  install(\n    FILES\n    ${CMAKE_CURRENT_BINARY_DIR}/RocksDBConfig.cmake\n    ${CMAKE_CURRENT_BINARY_DIR}/RocksDBConfigVersion.cmake\n    COMPONENT devel\n    DESTINATION ${package_config_destination}\n  )\n\n  install(\n    FILES\n    ${CMAKE_CURRENT_BINARY_DIR}/${PROJECT_NAME}.pc\n    COMPONENT devel\n    DESTINATION ${CMAKE_INSTALL_LIBDIR}/pkgconfig\n  )\nendif()\n\noption(WITH_ALL_TESTS \"Build all test, rather than a small subset\" ON)\n\nif(WITH_TESTS OR WITH_BENCHMARK_TOOLS)\n  add_subdirectory(third-party/gtest-1.8.1/fused-src/gtest)\n  add_library(testharness STATIC\n  test_util/mock_time_env.cc\n  test_util/secondary_cache_test_util.cc\n  test_util/testharness.cc)\n  target_link_libraries(testharness gtest)\nendif()\n\nif(WITH_TESTS)\n  set(TESTS\n        db/db_basic_test.cc\n        env/env_basic_test.cc\n  )\n  if(WITH_ALL_TESTS)\n    list(APPEND TESTS\n        cache/cache_reservation_manager_test.cc\n        cache/cache_test.cc\n        cache/compressed_secondary_cache_test.cc\n        cache/lru_cache_test.cc\n        cache/tiered_secondary_cache_test.cc\n        db/blob/blob_counting_iterator_test.cc\n        db/blob/blob_file_addition_test.cc\n        db/blob/blob_file_builder_test.cc\n        db/blob/blob_file_cache_test.cc\n        db/blob/blob_file_garbage_test.cc\n        db/blob/blob_file_reader_test.cc\n        db/blob/blob_garbage_meter_test.cc\n        db/blob/blob_source_test.cc\n        db/blob/db_blob_basic_test.cc\n        db/blob/db_blob_compaction_test.cc\n        db/blob/db_blob_corruption_test.cc\n        db/blob/db_blob_index_test.cc\n        db/column_family_test.cc\n        db/compact_files_test.cc\n        db/compaction/clipping_iterator_test.cc\n        db/compaction/compaction_job_stats_test.cc\n        db/compaction/compaction_job_test.cc\n        db/compaction/compaction_iterator_test.cc\n        db/compaction/compaction_picker_test.cc\n        db/compaction/compaction_service_test.cc\n        db/compaction/tiered_compaction_test.cc\n        db/comparator_db_test.cc\n        db/corruption_test.cc\n        db/cuckoo_table_db_test.cc\n        db/db_readonly_with_timestamp_test.cc\n        db/db_with_timestamp_basic_test.cc\n        db/db_block_cache_test.cc\n        db/db_bloom_filter_test.cc\n        db/db_compaction_filter_test.cc\n        db/db_compaction_test.cc\n        db/db_clip_test.cc\n        db/db_dynamic_level_test.cc\n        db/db_encryption_test.cc\n        db/db_flush_test.cc\n        db/db_inplace_update_test.cc\n        db/db_io_failure_test.cc\n        db/db_iter_test.cc\n        db/db_iter_stress_test.cc\n        db/db_iterator_test.cc\n        db/db_kv_checksum_test.cc\n        db/db_log_iter_test.cc\n        db/db_memtable_test.cc\n        db/db_merge_operator_test.cc\n        db/db_merge_operand_test.cc\n        db/db_options_test.cc\n        db/db_properties_test.cc\n        db/db_range_del_test.cc\n        db/db_rate_limiter_test.cc\n        db/db_secondary_test.cc\n        db/db_sst_test.cc\n        db/db_statistics_test.cc\n        db/db_table_properties_test.cc\n        db/db_tailing_iter_test.cc\n        db/db_test.cc\n        db/db_test2.cc\n        db/db_logical_block_size_cache_test.cc\n        db/db_universal_compaction_test.cc\n        db/db_wal_test.cc\n        db/db_with_timestamp_compaction_test.cc\n        db/db_write_buffer_manager_test.cc\n        db/db_write_test.cc\n        db/dbformat_test.cc\n        db/deletefile_test.cc\n        db/error_handler_fs_test.cc\n        db/obsolete_files_test.cc\n        db/external_sst_file_basic_test.cc\n        db/external_sst_file_test.cc\n        db/fault_injection_test.cc\n        db/file_indexer_test.cc\n        db/filename_test.cc\n        db/flush_job_test.cc\n        db/db_follower_test.cc\n        db/import_column_family_test.cc\n        db/listener_test.cc\n        db/log_test.cc\n        db/manual_compaction_test.cc\n        db/memtable_list_test.cc\n        db/merge_helper_test.cc\n        db/merge_test.cc\n        db/multi_cf_iterator_test.cc\n        db/options_file_test.cc\n        db/perf_context_test.cc\n        db/periodic_task_scheduler_test.cc\n        db/plain_table_db_test.cc\n        db/seqno_time_test.cc\n        db/prefix_test.cc\n        db/range_del_aggregator_test.cc\n        db/range_tombstone_fragmenter_test.cc\n        db/repair_test.cc\n        db/table_properties_collector_test.cc\n        db/version_builder_test.cc\n        db/version_edit_test.cc\n        db/version_set_test.cc\n        db/wal_manager_test.cc\n        db/wal_edit_test.cc\n        db/wide/db_wide_basic_test.cc\n        db/wide/wide_column_serialization_test.cc\n        db/wide/wide_columns_helper_test.cc\n        db/write_batch_test.cc\n        db/write_callback_test.cc\n        db/write_controller_test.cc\n        env/env_test.cc\n        env/io_posix_test.cc\n        env/mock_env_test.cc\n        file/delete_scheduler_test.cc\n        file/prefetch_test.cc\n        file/random_access_file_reader_test.cc\n        logging/auto_roll_logger_test.cc\n        logging/env_logger_test.cc\n        logging/event_logger_test.cc\n        memory/arena_test.cc\n        memory/memory_allocator_test.cc\n        memtable/inlineskiplist_test.cc\n        memtable/skiplist_test.cc\n        memtable/write_buffer_manager_test.cc\n        monitoring/histogram_test.cc\n        monitoring/iostats_context_test.cc\n        monitoring/statistics_test.cc\n        monitoring/stats_history_test.cc\n        options/configurable_test.cc\n        options/customizable_test.cc\n        options/options_settable_test.cc\n        options/options_test.cc\n        table/block_based/block_based_table_reader_test.cc\n        table/block_based/block_test.cc\n        table/block_based/data_block_hash_index_test.cc\n        table/block_based/full_filter_block_test.cc\n        table/block_based/partitioned_filter_block_test.cc\n        table/cleanable_test.cc\n        table/cuckoo/cuckoo_table_builder_test.cc\n        table/cuckoo/cuckoo_table_reader_test.cc\n        table/merger_test.cc\n        table/sst_file_reader_test.cc\n        table/table_test.cc\n        table/block_fetcher_test.cc\n        test_util/testutil_test.cc\n        trace_replay/block_cache_tracer_test.cc\n        trace_replay/io_tracer_test.cc\n        tools/block_cache_analyzer/block_cache_trace_analyzer_test.cc\n        tools/io_tracer_parser_test.cc\n        tools/ldb_cmd_test.cc\n        tools/reduce_levels_test.cc\n        tools/sst_dump_test.cc\n        tools/trace_analyzer_test.cc\n        util/autovector_test.cc\n        util/bloom_test.cc\n        util/coding_test.cc\n        util/crc32c_test.cc\n        util/defer_test.cc\n        util/dynamic_bloom_test.cc\n        util/file_reader_writer_test.cc\n        util/filelock_test.cc\n        util/hash_test.cc\n        util/heap_test.cc\n        util/random_test.cc\n        util/rate_limiter_test.cc\n        util/repeatable_thread_test.cc\n        util/ribbon_test.cc\n        util/slice_test.cc\n        util/slice_transform_test.cc\n        util/string_util_test.cc\n        util/timer_queue_test.cc\n        util/timer_test.cc\n        util/thread_list_test.cc\n        util/thread_local_test.cc\n        util/udt_util_test.cc\n        util/work_queue_test.cc\n        utilities/agg_merge/agg_merge_test.cc\n        utilities/backup/backup_engine_test.cc\n        utilities/blob_db/blob_db_test.cc\n        utilities/cassandra/cassandra_functional_test.cc\n        utilities/cassandra/cassandra_format_test.cc\n        utilities/cassandra/cassandra_row_merge_test.cc\n        utilities/cassandra/cassandra_serialize_test.cc\n        utilities/checkpoint/checkpoint_test.cc\n        utilities/env_timed_test.cc\n        utilities/memory/memory_test.cc\n        utilities/merge_operators/string_append/stringappend_test.cc\n        utilities/object_registry_test.cc\n        utilities/option_change_migration/option_change_migration_test.cc\n        utilities/options/options_util_test.cc\n        utilities/persistent_cache/hash_table_test.cc\n        utilities/persistent_cache/persistent_cache_test.cc\n        utilities/simulator_cache/cache_simulator_test.cc\n        utilities/simulator_cache/sim_cache_test.cc\n        utilities/table_properties_collectors/compact_for_tiering_collector_test.cc\n        utilities/table_properties_collectors/compact_on_deletion_collector_test.cc\n        utilities/transactions/optimistic_transaction_test.cc\n        utilities/transactions/transaction_test.cc\n        utilities/transactions/lock/point/point_lock_manager_test.cc\n        utilities/transactions/write_committed_transaction_ts_test.cc\n        utilities/transactions/write_prepared_transaction_test.cc\n        utilities/transactions/write_unprepared_transaction_test.cc\n        utilities/transactions/lock/range/range_locking_test.cc\n        utilities/transactions/timestamped_snapshot_test.cc\n        utilities/ttl/ttl_test.cc\n        utilities/types_util_test.cc\n        utilities/util_merge_operators_test.cc\n        utilities/write_batch_with_index/write_batch_with_index_test.cc\n\t${PLUGIN_TESTS}\n    )\n  endif()\n\n  set(TESTUTIL_SOURCE\n      db/db_test_util.cc\n      db/db_with_timestamp_test_util.cc\n      monitoring/thread_status_updater_debug.cc\n      table/mock_table.cc\n      utilities/agg_merge/test_agg_merge.cc\n      utilities/cassandra/test_utils.cc\n  )\n  enable_testing()\n  add_custom_target(rocksdb_check COMMAND ${CMAKE_CTEST_COMMAND})\n  set(TESTUTILLIB testutillib${ARTIFACT_SUFFIX})\n  add_library(${TESTUTILLIB} STATIC ${TESTUTIL_SOURCE})\n  target_link_libraries(${TESTUTILLIB} ${ROCKSDB_LIB} ${FOLLY_LIBS})\n  if(MSVC)\n    set_target_properties(${TESTUTILLIB} PROPERTIES COMPILE_FLAGS \"/Fd${CMAKE_CFG_INTDIR}/testutillib${ARTIFACT_SUFFIX}.pdb\")\n  endif()\n  set_target_properties(${TESTUTILLIB}\n        PROPERTIES EXCLUDE_FROM_DEFAULT_BUILD_RELEASE 1\n        EXCLUDE_FROM_DEFAULT_BUILD_MINRELEASE 1\n        EXCLUDE_FROM_DEFAULT_BUILD_RELWITHDEBINFO 1\n  )\n\n  foreach(sourcefile ${TESTS})\n      get_filename_component(exename ${sourcefile} NAME_WE)\n      add_executable(${exename}${ARTIFACT_SUFFIX} ${sourcefile})\n      set_target_properties(${exename}${ARTIFACT_SUFFIX}\n        PROPERTIES EXCLUDE_FROM_DEFAULT_BUILD_RELEASE 1\n        EXCLUDE_FROM_DEFAULT_BUILD_MINRELEASE 1\n        EXCLUDE_FROM_DEFAULT_BUILD_RELWITHDEBINFO 1\n        OUTPUT_NAME ${exename}${ARTIFACT_SUFFIX}\n      )\n      target_link_libraries(${exename}${ARTIFACT_SUFFIX} testutillib${ARTIFACT_SUFFIX} testharness gtest ${THIRDPARTY_LIBS} ${ROCKSDB_LIB})\n      if(NOT \"${exename}\" MATCHES \"db_sanity_test\")\n        gtest_discover_tests(${exename} DISCOVERY_TIMEOUT 120)\n        add_dependencies(rocksdb_check ${exename}${ARTIFACT_SUFFIX})\n      endif()\n  endforeach(sourcefile ${TESTS})\n\n  if(WIN32)\n    # C executables must link to a shared object\n    if(ROCKSDB_BUILD_SHARED)\n      set(ROCKSDB_LIB_FOR_C ${ROCKSDB_SHARED_LIB})\n    else()\n      set(ROCKSDB_LIB_FOR_C OFF)\n    endif()\n  else()\n    set(ROCKSDB_LIB_FOR_C ${ROCKSDB_LIB})\n  endif()\n\n  if(ROCKSDB_LIB_FOR_C)\n    set(C_TESTS db/c_test.c)\n    add_executable(c_test db/c_test.c)\n    target_link_libraries(c_test ${ROCKSDB_LIB_FOR_C} testharness)\n    add_test(NAME c_test COMMAND c_test${ARTIFACT_SUFFIX})\n    add_dependencies(rocksdb_check c_test)\n  endif()\nendif()\n\nif(WITH_BENCHMARK_TOOLS)\n  add_executable(db_bench${ARTIFACT_SUFFIX}\n    tools/simulated_hybrid_file_system.cc\n    tools/db_bench.cc\n    tools/db_bench_tool.cc)\n  target_link_libraries(db_bench${ARTIFACT_SUFFIX}\n    ${ROCKSDB_LIB} ${THIRDPARTY_LIBS})\n\n  add_executable(cache_bench${ARTIFACT_SUFFIX}\n    cache/cache_bench.cc\n    cache/cache_bench_tool.cc)\n  target_link_libraries(cache_bench${ARTIFACT_SUFFIX}\n    ${ROCKSDB_LIB} ${GFLAGS_LIB} ${FOLLY_LIBS})\n\n  add_executable(memtablerep_bench${ARTIFACT_SUFFIX}\n    memtable/memtablerep_bench.cc)\n  target_link_libraries(memtablerep_bench${ARTIFACT_SUFFIX}\n    ${ROCKSDB_LIB} ${GFLAGS_LIB} ${FOLLY_LIBS})\n\n  add_executable(range_del_aggregator_bench${ARTIFACT_SUFFIX}\n    db/range_del_aggregator_bench.cc)\n  target_link_libraries(range_del_aggregator_bench${ARTIFACT_SUFFIX}\n    ${ROCKSDB_LIB} ${GFLAGS_LIB} ${FOLLY_LIBS})\n\n  add_executable(table_reader_bench${ARTIFACT_SUFFIX}\n    table/table_reader_bench.cc)\n  target_link_libraries(table_reader_bench${ARTIFACT_SUFFIX}\n    ${ROCKSDB_LIB} testharness ${GFLAGS_LIB} ${FOLLY_LIBS})\n\n  add_executable(filter_bench${ARTIFACT_SUFFIX}\n    util/filter_bench.cc)\n  target_link_libraries(filter_bench${ARTIFACT_SUFFIX}\n    ${ROCKSDB_LIB} ${GFLAGS_LIB} ${FOLLY_LIBS})\n\n  add_executable(hash_table_bench${ARTIFACT_SUFFIX}\n    utilities/persistent_cache/hash_table_bench.cc)\n  target_link_libraries(hash_table_bench${ARTIFACT_SUFFIX}\n    ${ROCKSDB_LIB} ${GFLAGS_LIB} ${FOLLY_LIBS})\nendif()\n\noption(WITH_TRACE_TOOLS \"build with trace tools\" ON)\nif(WITH_TRACE_TOOLS)\n  add_executable(block_cache_trace_analyzer${ARTIFACT_SUFFIX}\n    tools/block_cache_analyzer/block_cache_trace_analyzer_tool.cc)\n  target_link_libraries(block_cache_trace_analyzer${ARTIFACT_SUFFIX}\n    ${ROCKSDB_LIB} ${GFLAGS_LIB} ${FOLLY_LIBS})\n\n  add_executable(trace_analyzer${ARTIFACT_SUFFIX}\n    tools/trace_analyzer.cc)\n  target_link_libraries(trace_analyzer${ARTIFACT_SUFFIX}\n    ${ROCKSDB_LIB} ${GFLAGS_LIB} ${FOLLY_LIBS})\n\nendif()\n\nif(WITH_CORE_TOOLS OR WITH_TOOLS)\n  add_subdirectory(tools)\n  add_custom_target(core_tools\n    DEPENDS ${core_tool_deps})\nendif()\n\nif(WITH_TOOLS)\n  add_subdirectory(db_stress_tool)\n  add_custom_target(tools\n    DEPENDS ${tool_deps})\nendif()\n\noption(WITH_EXAMPLES \"build with examples\" OFF)\nif(WITH_EXAMPLES)\n  add_subdirectory(examples)\nendif()\n\noption(WITH_BENCHMARK \"build benchmark tests\" OFF)\nif(WITH_BENCHMARK)\n  add_subdirectory(${PROJECT_SOURCE_DIR}/microbench/)\nendif()\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.27734375,
          "content": "# Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to make participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, sex characteristics, gender identity and expression,\nlevel of experience, education, socio-economic status, nationality, personal\nappearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\n  advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\n  address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies within all project spaces, and it also applies when\nan individual is representing the project or its community in public spaces.\nExamples of representing a project or community include using an official\nproject e-mail address, posting via an official social media account, or acting\nas an appointed representative at an online or offline event. Representation of\na project may be further defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the project team at <opensource-conduct@fb.com>. All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see\nhttps://www.contributor-covenant.org/faq\n\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 0.689453125,
          "content": "# Contributing to RocksDB\n\n## Code of Conduct\nThe code of conduct is described in [`CODE_OF_CONDUCT.md`](CODE_OF_CONDUCT.md)\n\n## Contributor License Agreement (\"CLA\")\n\nIn order to accept your pull request, we need you to submit a CLA. You\nonly need to do this once, so if you've done this for another Facebook\nopen source project, you're good to go. If you are submitting a pull\nrequest for the first time, just let us know that you have completed\nthe CLA and we can cross-check with your GitHub username.\n\nComplete your CLA here: <https://code.facebook.com/cla>\n\nIf you prefer to sign a paper copy, we can send you a PDF.  Send us an \ne-mail or create a new github issue to request the CLA in PDF format.\n"
        },
        {
          "name": "COPYING",
          "type": "blob",
          "size": 17.66796875,
          "content": "                    GNU GENERAL PUBLIC LICENSE\n                       Version 2, June 1991\n\n Copyright (C) 1989, 1991 Free Software Foundation, Inc.,\n 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n Everyone is permitted to copy and distribute verbatim copies\n of this license document, but changing it is not allowed.\n\n                            Preamble\n\n  The licenses for most software are designed to take away your\nfreedom to share and change it.  By contrast, the GNU General Public\nLicense is intended to guarantee your freedom to share and change free\nsoftware--to make sure the software is free for all its users.  This\nGeneral Public License applies to most of the Free Software\nFoundation's software and to any other program whose authors commit to\nusing it.  (Some other Free Software Foundation software is covered by\nthe GNU Lesser General Public License instead.)  You can apply it to\nyour programs, too.\n\n  When we speak of free software, we are referring to freedom, not\nprice.  Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthis service if you wish), that you receive source code or can get it\nif you want it, that you can change the software or use pieces of it\nin new free programs; and that you know you can do these things.\n\n  To protect your rights, we need to make restrictions that forbid\nanyone to deny you these rights or to ask you to surrender the rights.\nThese restrictions translate to certain responsibilities for you if you\ndistribute copies of the software, or if you modify it.\n\n  For example, if you distribute copies of such a program, whether\ngratis or for a fee, you must give the recipients all the rights that\nyou have.  You must make sure that they, too, receive or can get the\nsource code.  And you must show them these terms so they know their\nrights.\n\n  We protect your rights with two steps: (1) copyright the software, and\n(2) offer you this license which gives you legal permission to copy,\ndistribute and/or modify the software.\n\n  Also, for each author's protection and ours, we want to make certain\nthat everyone understands that there is no warranty for this free\nsoftware.  If the software is modified by someone else and passed on, we\nwant its recipients to know that what they have is not the original, so\nthat any problems introduced by others will not reflect on the original\nauthors' reputations.\n\n  Finally, any free program is threatened constantly by software\npatents.  We wish to avoid the danger that redistributors of a free\nprogram will individually obtain patent licenses, in effect making the\nprogram proprietary.  To prevent this, we have made it clear that any\npatent must be licensed for everyone's free use or not licensed at all.\n\n  The precise terms and conditions for copying, distribution and\nmodification follow.\n\n                    GNU GENERAL PUBLIC LICENSE\n   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION\n\n  0. This License applies to any program or other work which contains\na notice placed by the copyright holder saying it may be distributed\nunder the terms of this General Public License.  The \"Program\", below,\nrefers to any such program or work, and a \"work based on the Program\"\nmeans either the Program or any derivative work under copyright law:\nthat is to say, a work containing the Program or a portion of it,\neither verbatim or with modifications and/or translated into another\nlanguage.  (Hereinafter, translation is included without limitation in\nthe term \"modification\".)  Each licensee is addressed as \"you\".\n\nActivities other than copying, distribution and modification are not\ncovered by this License; they are outside its scope.  The act of\nrunning the Program is not restricted, and the output from the Program\nis covered only if its contents constitute a work based on the\nProgram (independent of having been made by running the Program).\nWhether that is true depends on what the Program does.\n\n  1. You may copy and distribute verbatim copies of the Program's\nsource code as you receive it, in any medium, provided that you\nconspicuously and appropriately publish on each copy an appropriate\ncopyright notice and disclaimer of warranty; keep intact all the\nnotices that refer to this License and to the absence of any warranty;\nand give any other recipients of the Program a copy of this License\nalong with the Program.\n\nYou may charge a fee for the physical act of transferring a copy, and\nyou may at your option offer warranty protection in exchange for a fee.\n\n  2. You may modify your copy or copies of the Program or any portion\nof it, thus forming a work based on the Program, and copy and\ndistribute such modifications or work under the terms of Section 1\nabove, provided that you also meet all of these conditions:\n\n    a) You must cause the modified files to carry prominent notices\n    stating that you changed the files and the date of any change.\n\n    b) You must cause any work that you distribute or publish, that in\n    whole or in part contains or is derived from the Program or any\n    part thereof, to be licensed as a whole at no charge to all third\n    parties under the terms of this License.\n\n    c) If the modified program normally reads commands interactively\n    when run, you must cause it, when started running for such\n    interactive use in the most ordinary way, to print or display an\n    announcement including an appropriate copyright notice and a\n    notice that there is no warranty (or else, saying that you provide\n    a warranty) and that users may redistribute the program under\n    these conditions, and telling the user how to view a copy of this\n    License.  (Exception: if the Program itself is interactive but\n    does not normally print such an announcement, your work based on\n    the Program is not required to print an announcement.)\n\nThese requirements apply to the modified work as a whole.  If\nidentifiable sections of that work are not derived from the Program,\nand can be reasonably considered independent and separate works in\nthemselves, then this License, and its terms, do not apply to those\nsections when you distribute them as separate works.  But when you\ndistribute the same sections as part of a whole which is a work based\non the Program, the distribution of the whole must be on the terms of\nthis License, whose permissions for other licensees extend to the\nentire whole, and thus to each and every part regardless of who wrote it.\n\nThus, it is not the intent of this section to claim rights or contest\nyour rights to work written entirely by you; rather, the intent is to\nexercise the right to control the distribution of derivative or\ncollective works based on the Program.\n\nIn addition, mere aggregation of another work not based on the Program\nwith the Program (or with a work based on the Program) on a volume of\na storage or distribution medium does not bring the other work under\nthe scope of this License.\n\n  3. You may copy and distribute the Program (or a work based on it,\nunder Section 2) in object code or executable form under the terms of\nSections 1 and 2 above provided that you also do one of the following:\n\n    a) Accompany it with the complete corresponding machine-readable\n    source code, which must be distributed under the terms of Sections\n    1 and 2 above on a medium customarily used for software interchange; or,\n\n    b) Accompany it with a written offer, valid for at least three\n    years, to give any third party, for a charge no more than your\n    cost of physically performing source distribution, a complete\n    machine-readable copy of the corresponding source code, to be\n    distributed under the terms of Sections 1 and 2 above on a medium\n    customarily used for software interchange; or,\n\n    c) Accompany it with the information you received as to the offer\n    to distribute corresponding source code.  (This alternative is\n    allowed only for noncommercial distribution and only if you\n    received the program in object code or executable form with such\n    an offer, in accord with Subsection b above.)\n\nThe source code for a work means the preferred form of the work for\nmaking modifications to it.  For an executable work, complete source\ncode means all the source code for all modules it contains, plus any\nassociated interface definition files, plus the scripts used to\ncontrol compilation and installation of the executable.  However, as a\nspecial exception, the source code distributed need not include\nanything that is normally distributed (in either source or binary\nform) with the major components (compiler, kernel, and so on) of the\noperating system on which the executable runs, unless that component\nitself accompanies the executable.\n\nIf distribution of executable or object code is made by offering\naccess to copy from a designated place, then offering equivalent\naccess to copy the source code from the same place counts as\ndistribution of the source code, even though third parties are not\ncompelled to copy the source along with the object code.\n\n  4. You may not copy, modify, sublicense, or distribute the Program\nexcept as expressly provided under this License.  Any attempt\notherwise to copy, modify, sublicense or distribute the Program is\nvoid, and will automatically terminate your rights under this License.\nHowever, parties who have received copies, or rights, from you under\nthis License will not have their licenses terminated so long as such\nparties remain in full compliance.\n\n  5. You are not required to accept this License, since you have not\nsigned it.  However, nothing else grants you permission to modify or\ndistribute the Program or its derivative works.  These actions are\nprohibited by law if you do not accept this License.  Therefore, by\nmodifying or distributing the Program (or any work based on the\nProgram), you indicate your acceptance of this License to do so, and\nall its terms and conditions for copying, distributing or modifying\nthe Program or works based on it.\n\n  6. Each time you redistribute the Program (or any work based on the\nProgram), the recipient automatically receives a license from the\noriginal licensor to copy, distribute or modify the Program subject to\nthese terms and conditions.  You may not impose any further\nrestrictions on the recipients' exercise of the rights granted herein.\nYou are not responsible for enforcing compliance by third parties to\nthis License.\n\n  7. If, as a consequence of a court judgment or allegation of patent\ninfringement or for any other reason (not limited to patent issues),\nconditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License.  If you cannot\ndistribute so as to satisfy simultaneously your obligations under this\nLicense and any other pertinent obligations, then as a consequence you\nmay not distribute the Program at all.  For example, if a patent\nlicense would not permit royalty-free redistribution of the Program by\nall those who receive copies directly or indirectly through you, then\nthe only way you could satisfy both it and this License would be to\nrefrain entirely from distribution of the Program.\n\nIf any portion of this section is held invalid or unenforceable under\nany particular circumstance, the balance of the section is intended to\napply and the section as a whole is intended to apply in other\ncircumstances.\n\nIt is not the purpose of this section to induce you to infringe any\npatents or other property right claims or to contest validity of any\nsuch claims; this section has the sole purpose of protecting the\nintegrity of the free software distribution system, which is\nimplemented by public license practices.  Many people have made\ngenerous contributions to the wide range of software distributed\nthrough that system in reliance on consistent application of that\nsystem; it is up to the author/donor to decide if he or she is willing\nto distribute software through any other system and a licensee cannot\nimpose that choice.\n\nThis section is intended to make thoroughly clear what is believed to\nbe a consequence of the rest of this License.\n\n  8. If the distribution and/or use of the Program is restricted in\ncertain countries either by patents or by copyrighted interfaces, the\noriginal copyright holder who places the Program under this License\nmay add an explicit geographical distribution limitation excluding\nthose countries, so that distribution is permitted only in or among\ncountries not thus excluded.  In such case, this License incorporates\nthe limitation as if written in the body of this License.\n\n  9. The Free Software Foundation may publish revised and/or new versions\nof the General Public License from time to time.  Such new versions will\nbe similar in spirit to the present version, but may differ in detail to\naddress new problems or concerns.\n\nEach version is given a distinguishing version number.  If the Program\nspecifies a version number of this License which applies to it and \"any\nlater version\", you have the option of following the terms and conditions\neither of that version or of any later version published by the Free\nSoftware Foundation.  If the Program does not specify a version number of\nthis License, you may choose any version ever published by the Free Software\nFoundation.\n\n  10. If you wish to incorporate parts of the Program into other free\nprograms whose distribution conditions are different, write to the author\nto ask for permission.  For software which is copyrighted by the Free\nSoftware Foundation, write to the Free Software Foundation; we sometimes\nmake exceptions for this.  Our decision will be guided by the two goals\nof preserving the free status of all derivatives of our free software and\nof promoting the sharing and reuse of software generally.\n\n                            NO WARRANTY\n\n  11. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY\nFOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN\nOTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES\nPROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED\nOR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\nMERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS\nTO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE\nPROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING,\nREPAIR OR CORRECTION.\n\n  12. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR\nREDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,\nINCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING\nOUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED\nTO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY\nYOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER\nPROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE\nPOSSIBILITY OF SUCH DAMAGES.\n\n                     END OF TERMS AND CONDITIONS\n\n            How to Apply These Terms to Your New Programs\n\n  If you develop a new program, and you want it to be of the greatest\npossible use to the public, the best way to achieve this is to make it\nfree software which everyone can redistribute and change under these terms.\n\n  To do so, attach the following notices to the program.  It is safest\nto attach them to the start of each source file to most effectively\nconvey the exclusion of warranty; and each file should have at least\nthe \"copyright\" line and a pointer to where the full notice is found.\n\n    <one line to give the program's name and a brief idea of what it does.>\n    Copyright (C) <year>  <name of author>\n\n    This program is free software; you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation; either version 2 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License along\n    with this program; if not, write to the Free Software Foundation, Inc.,\n    51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.\n\nAlso add information on how to contact you by electronic and paper mail.\n\nIf the program is interactive, make it output a short notice like this\nwhen it starts in an interactive mode:\n\n    Gnomovision version 69, Copyright (C) year name of author\n    Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\n    This is free software, and you are welcome to redistribute it\n    under certain conditions; type `show c' for details.\n\nThe hypothetical commands `show w' and `show c' should show the appropriate\nparts of the General Public License.  Of course, the commands you use may\nbe called something other than `show w' and `show c'; they could even be\nmouse-clicks or menu items--whatever suits your program.\n\nYou should also get your employer (if you work as a programmer) or your\nschool, if any, to sign a \"copyright disclaimer\" for the program, if\nnecessary.  Here is a sample; alter the names:\n\n  Yoyodyne, Inc., hereby disclaims all copyright interest in the program\n  `Gnomovision' (which makes passes at compilers) written by James Hacker.\n\n  <signature of Ty Coon>, 1 April 1989\n  Ty Coon, President of Vice\n\nThis General Public License does not permit incorporating your program into\nproprietary programs.  If your program is a subroutine library, you may\nconsider it more useful to permit linking proprietary applications with the\nlibrary.  If this is what you want to do, use the GNU Lesser General\nPublic License instead of this License.\n"
        },
        {
          "name": "DEFAULT_OPTIONS_HISTORY.md",
          "type": "blob",
          "size": 1.5166015625,
          "content": "# RocksDB default options change log (NO LONGER MAINTAINED)\n## Unreleased\n* delayed_write_rate takes the rate given by rate_limiter if not specified.\n\n## 5.2\n* Change the default of delayed slowdown value to 16MB/s and further increase the L0 stop condition to 36 files.\n\n## 5.0 (11/17/2016)\n* Options::allow_concurrent_memtable_write and Options::enable_write_thread_adaptive_yield are now true by default\n* Options.level0_stop_writes_trigger default value changes from 24 to 32.\n\n## 4.8.0 (5/2/2016)\n* options.max_open_files changes from 5000 to -1. It improves performance, but users need to set file descriptor limit to be large enough and watch memory usage for index and bloom filters.\n* options.base_background_compactions changes from max_background_compactions to 1. When users set higher max_background_compactions but the write throughput is not high, the writes are less spiky to disks.\n* options.wal_recovery_mode changes from kTolerateCorruptedTailRecords to kPointInTimeRecovery. Avoid some false positive when file system or hardware reorder the writes for file data and metadata.\n\n## 4.7.0 (4/8/2016)\n* options.write_buffer_size changes from 4MB to 64MB.\n* options.target_file_size_base changes from 2MB to 64MB.\n* options.max_bytes_for_level_base changes from 10MB to 256MB.\n* options.soft_pending_compaction_bytes_limit changes from 0 (disabled) to 64GB.\n* options.hard_pending_compaction_bytes_limit changes from 0 (disabled) to 256GB.\n* table_cache_numshardbits changes from 4 to 6.\n* max_file_opening_threads changes from 1 to 16.\n"
        },
        {
          "name": "DUMP_FORMAT.md",
          "type": "blob",
          "size": 0.7451171875,
          "content": "## RocksDB dump format\n\nThe version 1 RocksDB dump format is fairly simple:\n\n1) The dump starts with the magic 8 byte identifier \"ROCKDUMP\"\n\n2) The magic is followed by an 8 byte big-endian version which is 0x00000001.\n\n3) Next are arbitrarily sized chunks of bytes prepended by 4 byte little endian number indicating how large each chunk is.\n\n4) The first chunk is special and is a json string indicating some things about the creation of this dump.  It contains the following keys:\n* database-path: The path of the database this dump was created from.\n* hostname: The hostname of the machine where the dump was created.\n* creation-time: Unix seconds since epoc when this dump was created.\n\n5) Following the info dump the slices paired into are key/value pairs.\n"
        },
        {
          "name": "HISTORY.md",
          "type": "blob",
          "size": 341.2392578125,
          "content": "# Rocksdb Change Log\n> NOTE: Entries for next release do not go here. Follow instructions in `unreleased_history/README.txt`\n\n## 9.10.0 (12/12/2024)\n### New Features\n* Introduce `TransactionOptions::commit_bypass_memtable` to enable transaction commit to bypass memtable insertions. This can be beneficial for transactions with many operations, as it reduces commit time that is mostly spent on memtable insertion.\n\n### Public API Changes\n* Deprecated Remote Compaction APIs (StartV2, WaitForCompleteV2) are completely removed from the codebase\n\n### Behavior Changes\n* DB::KeyMayExist() now follows its function comment, which means `value` parameter can be null, and it will be set only if `value_found` is passed in.\n\n### Bug Fixes\n* Fix the issue where compaction incorrectly drops a key when there is a snapshot with a sequence number of zero.\n* Honor ConfigOptions.ignore_unknown_options in ParseStruct()\n\n### Performance Improvements\n* Enable reuse of file system allocated buffer for synchronous prefetching.\n* In buffered IO mode, try to align writes on power of 2 if checksum handoff is not enabled for the file type being written.\n\n## 9.9.0 (11/18/2024)\n### New Features\n* Multi-Column-Family-Iterator (CoalescingIterator/AttributeGroupIterator) is no longer marked as experimental\n* Adds a new table property \"rocksdb.newest.key.time\" which records the unix timestamp of the newest key. Uses this table property for FIFO TTL and temperature change compaction.\n\n### Public API Changes\n* Added a new API `Transaction::GetAttributeGroupIterator` that can be used to create a multi-column-family attribute group iterator over the specified column families, including the data from both the transaction and the underlying database. This API is currently supported for optimistic and write-committed pessimistic transactions.\n* Added a new API `Transaction::GetCoalescingIterator` that can be used to create a multi-column-family coalescing iterator over the specified column families, including the data from both the transaction and the underlying database. This API is currently supported for optimistic and write-committed pessimistic transactions.\n\n### Behavior Changes\n* `BaseDeltaIterator` now honors the read option `allow_unprepared_value`.\n\n### Bug Fixes\n* `BaseDeltaIterator` now calls `PrepareValue` on the base iterator in case it has been created with the `allow_unprepared_value` read option set. Earlier, such base iterators could lead to incorrect values being exposed from `BaseDeltaIterator`.\n* Fix a leak of obsolete blob files left open until DB::Close(). This bug was introduced in version 9.4.0.\n* Fix missing cases of corruption retry during DB open and read API processing.\n* Fix a bug for transaction db with 2pc where an old WAL may be retained longer than needed (#13127).\n* Fix leaks of some open SST files (until `DB::Close()`) that are written but never become live due to various failures. (We now have a check for such leaks with no outstanding issues.)\n* Fix a bug for replaying WALs for WriteCommitted transaction DB when its user-defined timestamps setting is toggled on/off between DB sessions.\n\n### Performance Improvements\n* Fix regression in issue #12038 due to `Options::compaction_readahead_size` greater than `max_sectors_kb` (i.e, largest I/O size that the OS issues to a block device defined in linux)\n\n## 9.8.0 (10/25/2024)\n### New Features\n* All non-`block_cache` options in `BlockBasedTableOptions` are now mutable with `DB::SetOptions()`. See also Bug Fixes below.\n* When using iterators with BlobDB, it is now possible to load large values on an on-demand basis, i.e. only if they are actually needed by the application. This can save I/O in use cases where the values associated with certain keys are not needed. For more details, see the new read option `allow_unprepared_value` and the iterator API `PrepareValue`.\n* Add a new file ingestion option `IngestExternalFileOptions::fill_cache` to support not adding blocks from ingested files into block cache during file ingestion.\n* The option `allow_unprepared_value` is now also supported for multi-column-family iterators (i.e. `CoalescingIterator` and `AttributeGroupIterator`).\n* When a file with just one range deletion (standalone range deletion file) is ingested via bulk loading, it will be marked for compaction. During compaction, this type of files can be used to directly filter out some input files that are not protected by any snapshots and completely deleted by the standalone range deletion file.\n\n### Behavior Changes\n* During file ingestion, overlapping files level assignment are done in multiple batches, so that they can potentially be assigned to lower levels other than always land on L0.\n* OPTIONS file to be loaded by remote worker is now preserved so that it does not get purged by the primary host. A similar technique as how we are preserving new SST files from getting purged is used for this. min_options_file_numbers_ is tracked like pending_outputs_ is tracked.\n* Trim readahead_size during scans so data blocks containing keys that are not in the same prefix as the seek key in `Seek()` are not prefetched when `ReadOptions::auto_readahead_size=true` (default value) and `ReadOptions::prefix_same_as_start = true`\n* Assigning levels for external files are done in the same way for universal compaction and leveled compaction. The old behavior tends to assign files to L0 while the new behavior will assign the files to the lowest level possible.\n\n### Bug Fixes\n* Fix a longstanding race condition in SetOptions for `block_based_table_factory` options. The fix has some subtle behavior changes because of copying and replacing the TableFactory on a change with SetOptions, including requiring an Iterator::Refresh() for an existing Iterator to use the latest options.\n* Fix under counting of allocated memory in the compressed secondary cache due to looking at the compressed block size rather than the actual memory allocated, which could be larger due to internal fragmentation.\n* `GetApproximateMemTableStats()` could return disastrously bad estimates 5-25% of the time. The function has been re-engineered to return much better estimates with similar CPU cost.\n* Skip insertion of compressed blocks in the secondary cache if the lowest_used_cache_tier DB option is kVolatileTier.\n* Fix an issue in level compaction where a small CF with small compaction debt can cause the DB to allow parallel compactions. (#13054)\n* Several DB option settings could be lost through `GetOptionsFromString()`, possibly elsewhere as well. Affected options, now fixed:`background_close_inactive_wals`, `write_dbid_to_manifest`, `write_identity_file`, `prefix_seek_opt_in_only`\n\n## 9.7.0 (09/20/2024)\n### New Features\n* Make Cache a customizable class that can be instantiated by the object registry.\n* Add new option `prefix_seek_opt_in_only` that makes iterators generally safer when you might set a `prefix_extractor`. When `prefix_seek_opt_in_only=true`, which is expected to be the future default, prefix seek is only used when `prefix_same_as_start` or `auto_prefix_mode` are set. Also, `prefix_same_as_start` and `auto_prefix_mode` now allow prefix filtering even with `total_order_seek=true`.\n* Add a new table property \"rocksdb.key.largest.seqno\" which records the largest sequence number of all keys in file. It is verified to be zero during SST file ingestion.\n\n### Behavior Changes\n* Changed the semantics of the BlobDB configuration option `blob_garbage_collection_force_threshold` to define a threshold for the overall garbage ratio of all blob files currently eligible for garbage collection (according to `blob_garbage_collection_age_cutoff`). This can provide better control over space amplification at the cost of slightly higher write amplification.\n* Set `write_dbid_to_manifest=true` by default. This means DB ID will now be preserved through backups, checkpoints, etc. by default. Also add `write_identity_file` option which can be set to false for anticipated future behavior.\n* In FIFO compaction, compactions for changing file temperature (configured by option `file_temperature_age_thresholds`) will compact one file at a time, instead of merging multiple eligible file together (#13018).\n* Support ingesting db generated files using hard link, i.e. IngestExternalFileOptions::move_files/link_files and IngestExternalFileOptions::allow_db_generated_files.\n* Add a new file ingestion option `IngestExternalFileOptions::link_files` to hard link input files and preserve original files links after ingestion.\n* DB::Close now untracks files in SstFileManager, making avaialble any space used\nby them. Prior to this change they would be orphaned until the DB is re-opened.\n\n### Bug Fixes\n* Fix a bug in CompactRange() where result files may not be compacted in any future compaction. This can only happen when users configure CompactRangeOptions::change_level to true and the change level step of manual compaction fails (#13009).\n* Fix handling of dynamic change of `prefix_extractor` with memtable prefix filter. Previously, prefix seek could mix different prefix interpretations between memtable and SST files. Now the latest `prefix_extractor` at the time of iterator creation or refresh is respected.\n* Fix a bug with manual_wal_flush and auto error recovery from WAL failure that may cause CFs to be inconsistent (#12995). The fix will set potential WAL write failure as fatal error when manual_wal_flush is true, and disables auto error recovery from these errors.\n\n## 9.6.0 (08/19/2024)\n### New Features\n* Best efforts recovery supports recovering to incomplete Version with a clean seqno cut that presents a valid point in time view from the user's perspective, if versioning history doesn't include atomic flush.\n* New option `BlockBasedTableOptions::decouple_partitioned_filters` should improve efficiency in serving read queries because filter and index partitions can consistently target the configured `metadata_block_size`. This option is currently opt-in.\n* Introduce a new mutable CF option `paranoid_memory_checks`. It enables additional validation on data integrity during reads/scanning. Currently, skip list based memtable will validate key ordering during look up and scans.\n\n### Public API Changes\n* Add ticker stats to count file read retries due to checksum mismatch\n* Adds optional installation callback function for remote compaction\n\n### Behavior Changes\n* There may be less intra-L0 compaction triggered by total L0 size being too small. We now use compensated file size (tombstones are assigned some value size) when calculating L0 size and reduce the threshold for L0 size limit. This is to avoid accumulating too much data/tombstones in L0.\n\n### Bug Fixes\n* Make DestroyDB supports slow deletion when it's configured in `SstFileManager`. The slow deletion is subject to the configured `rate_bytes_per_sec`, but not subject to the `max_trash_db_ratio`.\n* Fixed a bug where we set unprep_seqs_ even when WriteImpl() fails. This was caught by stress test write fault injection in WriteImpl(). This may have incorrectly caused iteration creation failure for unvalidated writes or returned wrong result for WriteUnpreparedTxn::GetUnpreparedSequenceNumbers().\n* Fixed a bug where successful write right after error recovery for last failed write finishes causes duplicate WAL entries\n* Fixed a data race involving the background error status in `unordered_write` mode.\n* Fix a bug where file snapshot functions like backup, checkpoint may attempt to copy a non-existing manifest file. #12882\n* Fix a bug where per kv checksum corruption may be ignored in MultiGet().\n* Fix a race condition in pessimistic transactions that could allow multiple transactions with the same name to be registered simultaneously, resulting in a crash or other unpredictable behavior.\n\n## 9.5.0 (07/19/2024)\n### Public API Changes\n* Introduced new C API function rocksdb_writebatch_iterate_cf for column family-aware iteration over the contents of a WriteBatch\n* Add support to ingest SST files generated by a DB instead of SstFileWriter. This can be enabled with experimental option `IngestExternalFileOptions::allow_db_generated_files`.\n\n### Behavior Changes\n* When calculating total log size for the `log_size_for_flush` argument in `CreateCheckpoint` API, the size of the archived log will not be included to avoid unnecessary flush\n\n### Bug Fixes\n* Fix a major bug in which an iterator using prefix filtering and SeekForPrev might miss data when the DB is using `whole_key_filtering=false` and `partition_filters=true`.\n* Fixed a bug where `OnErrorRecoveryBegin()` is not called before auto recovery starts.\n* Fixed a bug where event listener reads ErrorHandler's `bg_error_` member without holding db mutex(#12803).\n* Fixed a bug in handling MANIFEST write error that caused the latest valid MANIFEST file to get deleted, resulting in the DB being unopenable.\n* Fixed a race between error recovery due to manifest sync or write failure and external SST file ingestion. Both attempt to write a new manifest file, which causes an assertion failure.\n\n### Performance Improvements\n* Fix an issue where compactions were opening table files and reading table properties while holding db mutex_.\n* Reduce unnecessary filesystem queries and DB mutex acquires in creating backups and checkpoints.\n\n## 9.4.0 (06/23/2024)\n### New Features\n* Added a `CompactForTieringCollectorFactory` to auto trigger compaction for tiering use case.\n* Optimistic transactions and pessimistic transactions with the WriteCommitted policy now support the `GetEntityForUpdate` API.\n* Added a new \"count\" command to the ldb repl shell. By default, it prints a count of keys in the database from start to end. The options --from=<key> and/or --to=<key> can be specified to limit the range.\n* Add `rocksdb_writebatch_update_timestamps`, `rocksdb_writebatch_wi_update_timestamps` in C API.\n* Add `rocksdb_iter_refresh` in C API.\n* Add `rocksdb_writebatch_create_with_params`, `rocksdb_writebatch_wi_create_with_params` to create WB and WBWI with all options in C API\n\n### Public API Changes\n* Deprecated names `LogFile` and `VectorLogPtr` in favor of new names `WalFile` and `VectorWalPtr`.\n* Introduce a new universal compaction option CompactionOptionsUniversal::max_read_amp which allows user to define the limit on the number of sorted runs separately from the trigger for compaction (`level0_file_num_compaction_trigger`) #12477.\n\n### Behavior Changes\n* Inactive WALs are immediately closed upon being fully sync-ed rather than in a background thread. This is to ensure LinkFile() is not called on files still open for write, which might not be supported by some FileSystem implementations. This should not be a performance issue, but an opt-out is available with with new DB option `background_close_inactive_wals`.\n\n### Bug Fixes\n* Fix a rare case in which a hard-linked WAL in a Checkpoint is not fully synced (so might lose data on power loss).\n* Fixed the output of the `ldb dump_wal` command for `PutEntity` records so it prints the key and correctly resets the hexadecimal formatting flag after printing the wide-column entity.\n* Fixed an issue where `PutEntity` records were handled incorrectly while rebuilding transactions during recovery.\n* Various read operations could ignore various ReadOptions that might be relevant. Fixed many such cases, which can result in behavior change but a better reflection of specified options.\n\n### Performance Improvements\n* Improved write throughput to memtable when there's a large number of concurrent writers and allow_concurrent_memtable_write=true(#12545)\n\n## 9.3.0 (05/17/2024)\n### New Features\n* Optimistic transactions and pessimistic transactions with the WriteCommitted policy now support the `GetEntity` API.\n* Added new `Iterator` property, \"rocksdb.iterator.is-value-pinned\", for checking whether the `Slice` returned by `Iterator::value()` can be used until the `Iterator` is destroyed.\n* Optimistic transactions and WriteCommitted pessimistic transactions now support the `MultiGetEntity` API.\n* Optimistic transactions and pessimistic transactions with the WriteCommitted policy now support the `PutEntity` API. Support for read APIs and other write policies (WritePrepared, WriteUnprepared) will be added later.\n\n### Public API Changes\n* Exposed block based metadata cache options via C API\n* Exposed compaction pri via c api.\n* Add a kAdmPolicyAllowAll option to TieredAdmissionPolicy that admits all blocks evicted from the primary block cache into the compressed secondary cache.\n\n### Behavior Changes\n* CompactRange() with change_level=true on a CF with FIFO compaction will return Status::NotSupported().\n* External file ingestion with FIFO compaction will always ingest to L0.\n\n### Bug Fixes\n* Fixed a bug for databases using `DBOptions::allow_2pc == true` (all `TransactionDB`s except `OptimisticTransactionDB`) that have exactly one column family. Due to a missing WAL sync, attempting to open the DB could have returned a `Status::Corruption` with a message like \"SST file is ahead of WALs\".\n* Fix a bug in CreateColumnFamilyWithImport() where if multiple CFs are imported, we were not resetting files' epoch number and L0 files can have overlapping key range but the same epoch number.\n* Fixed race conditions when `ColumnFamilyOptions::inplace_update_support == true` between user overwrites and reads on the same key.\n* Fix a bug where `CompactFiles()` can compact files of range conflict with other ongoing compactions' when `preclude_last_level_data_seconds > 0` is used\n* Fixed a false positive `Status::Corruption` reported when reopening a DB that used `DBOptions::recycle_log_file_num > 0` and `DBOptions::wal_compression != kNoCompression`.\n* While WAL is locked with LockWAL(), some operations like Flush() and IngestExternalFile() are now blocked as they should have been.\n* Fixed a bug causing stale memory access when using the TieredSecondaryCache with an NVM secondary cache, and a file system that supports return an FS allocated buffer for MultiRead (FSSupportedOps::kFSBuffer is set).\n\n## 9.2.0 (05/01/2024)\n### New Features\n* Added two options `deadline` and `max_size_bytes` for CacheDumper to exit early\n* Added a new API `GetEntityFromBatchAndDB` to `WriteBatchWithIndex` that can be used for wide-column point lookups with read-your-own-writes consistency. Similarly to `GetFromBatchAndDB`, the API can combine data from the write batch with data from the underlying database if needed. See the API comments for more details.\n* [Experimental] Introduce two new cross-column-family iterators - CoalescingIterator and AttributeGroupIterator. The CoalescingIterator enables users to iterate over multiple column families and access their values and columns. During this iteration, if the same key exists in more than one column family, the keys in the later column family will overshadow the previous ones. The AttributeGroupIterator allows users to gather wide columns per Column Family and create attribute groups while iterating over keys across all CFs.\n* Added a new API `MultiGetEntityFromBatchAndDB` to `WriteBatchWithIndex` that can be used for batched wide-column point lookups with read-your-own-writes consistency. Similarly to `MultiGetFromBatchAndDB`, the API can combine data from the write batch with data from the underlying database if needed. See the API comments for more details.\n* Adds a `SstFileReader::NewTableIterator` API to support programmatically read a SST file as a raw table file.\n* Add an option to `WaitForCompactOptions` - `wait_for_purge` to make `WaitForCompact()` API wait for background purge to complete\n\n### Public API Changes\n* DeleteRange() will return NotSupported() if row_cache is configured since they don't work together in some cases.\n* Deprecated `CompactionOptions::compression` since `CompactionOptions`'s API for configuring compression was incomplete, unsafe, and likely unnecessary\n* Using `OptionChangeMigration()` to migrate from non-FIFO to FIFO compaction\nwith `Options::compaction_options_fifo.max_table_files_size` > 0 can cause\nthe whole DB to be dropped right after migration if the migrated data is larger than\n`max_table_files_size`\n\n### Behavior Changes\n* Enabling `BlockBasedTableOptions::block_align` is now incompatible (i.e., APIs will return `Status::InvalidArgument`) with more ways of enabling compression: `CompactionOptions::compression`, `ColumnFamilyOptions::compression_per_level`, and `ColumnFamilyOptions::bottommost_compression`.\n* Changed the default value of `CompactionOptions::compression` to `kDisableCompressionOption`, which means the compression type is determined by the `ColumnFamilyOptions`.\n* `BlockBasedTableOptions::optimize_filters_for_memory` is now set to true by default. When `partition_filters=false`, this could lead to somewhat increased average RSS memory usage by the block cache, but this \"extra\" usage is within the allowed memory budget and should make memory usage more consistent (by minimizing internal fragmentation for more kinds of blocks).\n* Dump all keys for cache dumper impl if `SetDumpFilter()` is not called\n* `CompactRange()` with `CompactRangeOptions::change_level = true` and `CompactRangeOptions::target_level = 0` that ends up moving more than 1 file from non-L0 to L0 will return `Status::Aborted()`.\n* On distributed file systems that support file system level checksum verification and reconstruction reads, RocksDB will now retry a file read if the initial read fails RocksDB block level or record level checksum verification. This applies to MANIFEST file reads when the DB is opened, and to SST file reads at all times.\n\n### Bug Fixes\n* Fix a bug causing `VerifyFileChecksums()` to return false-positive corruption under `BlockBasedTableOptions::block_align=true`\n* Provide consistent view of the database across the column families for `NewIterators()` API.\n* Fixed feature interaction bug for `DeleteRange()` together with `ColumnFamilyOptions::memtable_insert_with_hint_prefix_extractor`. The impact of this bug would likely be corruption or crashing.\n* Fixed hang in `DisableManualCompactions()` where compactions waiting to be scheduled due to conflicts would not be canceled promptly\n* Fixed a regression when `ColumnFamilyOptions::max_successive_merges > 0` where the CPU overhead for deciding whether to merge could have increased unless the user had set the option `ColumnFamilyOptions::strict_max_successive_merges`\n* Fixed a bug in `MultiGet()` and `MultiGetEntity()` together with blob files (`ColumnFamilyOptions::enable_blob_files == true`). An error looking up one of the keys could cause the results to be wrong for other keys for which the statuses were `Status::OK`.\n* Fixed a bug where wrong padded bytes are used to generate file checksum and `DataVerificationInfo::checksum` upon file creation\n* Correctly implemented the move semantics of `PinnableWideColumns`.\n* Fixed a bug when the recycle_log_file_num in DBOptions is changed from 0 to non-zero when a DB is reopened. On a subsequent reopen, if a log file created when recycle_log_file_num==0 was reused previously, is alive and is empty, we could end up inserting stale WAL records into the memtable.\n* Fix a bug where obsolete files' deletion during DB::Open are not rate limited with `SstFilemManager`'s slow deletion feature even if it's configured.\n\n## 9.1.0 (03/22/2024)\n### New Features\n* Added an option, `GetMergeOperandsOptions::continue_cb`, to give users the ability to end `GetMergeOperands()`'s lookup process before all merge operands were found.\n* Add sanity checks for ingesting external files that currently checks if the user key comparator used to create the file is compatible with the column family's user key comparator.\n*Support ingesting external files for column family that has user-defined timestamps in memtable only enabled.\n* On file systems that support storage level data checksum and reconstruction, retry SST block reads for point lookups, scans, and flush and compaction if there's a checksum mismatch on the initial read.\n* Some enhancements and fixes to experimental Temperature handling features, including new `default_write_temperature` CF option and opening an `SstFileWriter` with a temperature.\n* `WriteBatchWithIndex` now supports wide-column point lookups via the `GetEntityFromBatch` API. See the API comments for more details.\n* Implement experimental features: API `Iterator::GetProperty(\"rocksdb.iterator.write-time\")` to allow users to get data's approximate write unix time and write data with a specific write time via `WriteBatch::TimedPut` API.\n\n### Public API Changes\n* Best-effort recovery (`best_efforts_recovery == true`) may now be used together with atomic flush (`atomic_flush == true`). The all-or-nothing recovery guarantee for atomically flushed data will be upheld.\n* Remove deprecated option `bottommost_temperature`, already replaced by `last_level_temperature`\n* Added new PerfContext counters for block cache bytes read - block_cache_index_read_byte, block_cache_filter_read_byte, block_cache_compression_dict_read_byte, and block_cache_read_byte.\n* Deprecate experimental Remote Compaction APIs - StartV2() and WaitForCompleteV2() and introduce Schedule() and Wait(). The new APIs essentially does the same thing as the old APIs. They allow taking externally generated unique id to wait for remote compaction to complete.\n* For API `WriteCommittedTransaction::GetForUpdate`, if the column family enables user-defined timestamp, it was mandated that argument `do_validate` cannot be false, and UDT based validation has to be done with a user set read timestamp. It's updated to make the UDT based validation optional if user sets `do_validate` to false and does not set a read timestamp. With this, `GetForUpdate` skips UDT based validation and it's users' responsibility to enforce the UDT invariant. SO DO NOT skip this UDT-based validation if users do not have ways to enforce the UDT invariant. Ways to enforce the invariant on the users side include manage a monotonically increasing timestamp, commit transactions in a single thread etc.\n* Defined a new PerfLevel `kEnableWait` to measure time spent by user threads blocked in RocksDB other than mutex, such as a write thread waiting to be added to a write group, a write thread delayed or stalled etc.\n* `RateLimiter`'s API no longer requires the burst size to be the refill size. Users of `NewGenericRateLimiter()` can now provide burst size in `single_burst_bytes`. Implementors of `RateLimiter::SetSingleBurstBytes()` need to adapt their implementations to match the changed API doc.\n* Add `write_memtable_time` to the newly introduced PerfLevel `kEnableWait`.\n\n### Behavior Changes\n* `RateLimiter`s created by `NewGenericRateLimiter()` no longer modify the refill period when `SetSingleBurstBytes()` is called.\n* Merge writes will only keep merge operand count within `ColumnFamilyOptions::max_successive_merges` when the key's merge operands are all found in memory, unless `strict_max_successive_merges` is explicitly set.\n\n### Bug Fixes\n* Fixed `kBlockCacheTier` reads to return `Status::Incomplete` when I/O is needed to fetch a merge chain's base value from a blob file.\n* Fixed `kBlockCacheTier` reads to return `Status::Incomplete` on table cache miss rather than incorrectly returning an empty value.\n* Fixed a data race in WalManager that may affect how frequent PurgeObsoleteWALFiles() runs.\n* Re-enable the recycle_log_file_num option in DBOptions for kPointInTimeRecovery WAL recovery mode, which was previously disabled due to a bug in the recovery logic. This option is incompatible with WriteOptions::disableWAL. A Status::InvalidArgument() will be returned if disableWAL is specified.\n\n### Performance Improvements\n* Java API `multiGet()` variants now take advantage of the underlying batched `multiGet()` performance improvements.\nBefore\n```\nBenchmark (columnFamilyTestType) (keyCount) (keySize) (multiGetSize) (valueSize) Mode Cnt Score Error Units\nMultiGetBenchmarks.multiGetList10 no_column_family 10000 16 100 64 thrpt 25 6315.541  8.106 ops/s\nMultiGetBenchmarks.multiGetList10 no_column_family 10000 16 100 1024 thrpt 25 6975.468  68.964 ops/s\n```\nAfter\n```\nBenchmark (columnFamilyTestType) (keyCount) (keySize) (multiGetSize) (valueSize) Mode Cnt Score Error Units\nMultiGetBenchmarks.multiGetList10 no_column_family 10000 16 100 64 thrpt 25 7046.739  13.299 ops/s\nMultiGetBenchmarks.multiGetList10 no_column_family 10000 16 100 1024 thrpt 25 7654.521  60.121 ops/s\n```\n\n## 9.0.0 (02/16/2024)\n### New Features\n* Provide support for FSBuffer for point lookups. Also added support for scans and compactions that don't go through prefetching.\n* Make `SstFileWriter` create SST files without persisting user defined timestamps when the `Option.persist_user_defined_timestamps` flag is set to false.\n* Add support for user-defined timestamps in APIs `DeleteFilesInRanges` and `GetPropertiesOfTablesInRange`.\n* Mark wal\\_compression feature as production-ready. Currently only compatible with ZSTD compression.\n\n### Public API Changes\n* Allow setting Stderr logger via C API\n* Declare one Get and one MultiGet variant as pure virtual, and make all the other variants non-overridable. The methods required to be implemented by derived classes of DB allow returning timestamps. It is up to the implementation to check and return an error if timestamps are not supported. The non-batched MultiGet APIs are reimplemented in terms of batched MultiGet, so callers might see a performance improvement.\n* Exposed mode option to Rate Limiter via c api.\n* Removed deprecated option `access_hint_on_compaction_start`\n* Removed deprecated option `ColumnFamilyOptions::check_flush_compaction_key_order`\n* Remove the default `WritableFile::GetFileSize` and `FSWritableFile::GetFileSize` implementation that returns 0 and make it pure virtual, so that subclasses are enforced to explicitly provide an implementation.\n* Removed deprecated option `ColumnFamilyOptions::level_compaction_dynamic_file_size`\n* Removed tickers with typos \"rocksdb.error.handler.bg.errro.count\", \"rocksdb.error.handler.bg.io.errro.count\", \"rocksdb.error.handler.bg.retryable.io.errro.count\".\n* Remove the force mode for `EnableFileDeletions` API because it is unsafe with no known legitimate use.\n* Removed deprecated option `ColumnFamilyOptions::ignore_max_compaction_bytes_for_input`\n* `sst_dump --command=check` now compares the number of records in a table with `num_entries` in table property, and reports corruption if there is a mismatch. API `SstFileDumper::ReadSequential()` is updated to optionally do this verification. (#12322)\n\n### Behavior Changes\n* format\\_version=6 is the new default setting in BlockBasedTableOptions, for more robust data integrity checking. DBs and SST files written with this setting cannot be read by RocksDB versions before 8.6.0.\n* Compactions can be scheduled in parallel in an additional scenario: multiple files are marked for compaction within a single column family\n* For leveled compaction, RocksDB will try to do intra-L0 compaction if the total L0 size is small compared to Lbase (#12214). Users with atomic_flush=true are more likely to see the impact of this change.\n\n### Bug Fixes\n* Fixed a data race in `DBImpl::RenameTempFileToOptionsFile`.\n* Fix some perf context statistics error in write steps. which include missing write_memtable_time in unordered_write. missing write_memtable_time in PipelineWrite when Writer stat is STATE_PARALLEL_MEMTABLE_WRITER. missing write_delay_time when calling DelayWrite in WriteImplWALOnly function.\n* Fixed a bug that can, under rare circumstances, cause MultiGet to return an incorrect result for a duplicate key in a MultiGet batch.\n* Fix a bug where older data of an ingested key can be returned for read when universal compaction is used\n\n## 8.11.0 (01/19/2024)\n### New Features\n* Add new statistics: `rocksdb.sst.write.micros` measures time of each write to SST file; `rocksdb.file.write.{flush|compaction|db.open}.micros` measure time of each write to SST table (currently only block-based table format) and blob file for flush, compaction and db open.\n\n### Public API Changes\n* Added another enumerator `kVerify` to enum class `FileOperationType` in listener.h. Update your `switch` statements as needed.\n* Add CompressionOptions to the CompressedSecondaryCacheOptions structure to allow users to specify library specific options when creating the compressed secondary cache.\n* Deprecated several options: `level_compaction_dynamic_file_size`, `ignore_max_compaction_bytes_for_input`, `check_flush_compaction_key_order`, `flush_verify_memtable_count`, `compaction_verify_record_count`, `fail_if_options_file_error`, and `enforce_single_del_contracts`\n* Exposed options ttl via c api.\n\n### Behavior Changes\n* `rocksdb.blobdb.blob.file.write.micros` expands to also measure time writing the header and footer. Therefore the COUNT may be higher and values may be smaller than before. For stacked BlobDB, it no longer measures the time of explictly flushing blob file.\n* Files will be compacted to the next level if the data age exceeds periodic_compaction_seconds except for the last level.\n* Reduced the compaction debt ratio trigger for scheduling parallel compactions\n* For leveled compaction with default compaction pri (kMinOverlappingRatio), files marked for compaction will be prioritized over files not marked when picking a file from a level for compaction.\n\n### Bug Fixes\n* Fix bug in auto_readahead_size that combined with IndexType::kBinarySearchWithFirstKey + fails or iterator lands at a wrong key\n* Fixed some cases in which DB file corruption was detected but ignored on creating a backup with BackupEngine.\n* Fix bugs where `rocksdb.blobdb.blob.file.synced` includes blob files failed to get synced and `rocksdb.blobdb.blob.file.bytes.written` includes blob bytes failed to get written.\n* Fixed a possible memory leak or crash on a failure (such as I/O error) in automatic atomic flush of multiple column families.\n* Fixed some cases of in-memory data corruption using mmap reads with `BackupEngine`, `sst_dump`, or `ldb`.\n* Fixed issues with experimental `preclude_last_level_data_seconds` option that could interfere with expected data tiering.\n* Fixed the handling of the edge case when all existing blob files become unreferenced. Such files are now correctly deleted.\n\n## 8.10.0 (12/15/2023)\n### New Features\n* Provide support for async_io to trim readahead_size by doing block cache lookup\n* Added initial wide-column support in `WriteBatchWithIndex`. This includes the `PutEntity` API and support for wide columns in the existing read APIs (`GetFromBatch`, `GetFromBatchAndDB`, `MultiGetFromBatchAndDB`, and `BaseDeltaIterator`).\n\n### Public API Changes\n* Custom implementations of `TablePropertiesCollectorFactory` may now return a `nullptr` collector to decline processing a file, reducing callback overheads in such cases.\n\n### Behavior Changes\n* Make ReadOptions.auto_readahead_size default true which does prefetching optimizations for forward scans if iterate_upper_bound and block_cache is also specified.\n* Compactions can be scheduled in parallel in an additional scenario: high compaction debt relative to the data size\n* HyperClockCache now has built-in protection against excessive CPU consumption under the extreme stress condition of no (or very few) evictable cache entries, which can slightly increase memory usage such conditions. New option `HyperClockCacheOptions::eviction_effort_cap` controls the space-time trade-off of the response. The default should be generally well-balanced, with no measurable affect on normal operation.\n\n### Bug Fixes\n* Fix a corner case with auto_readahead_size where Prev Operation returns NOT SUPPORTED error when scans direction is changed from forward to backward.\n* Avoid destroying the periodic task scheduler's default timer in order to prevent static destruction order issues.\n* Fix double counting of BYTES_WRITTEN ticker when doing writes with transactions.\n* Fix a WRITE_STALL counter that was reporting wrong value in few cases.\n* A lookup by MultiGet in a TieredCache that goes to the local flash cache and finishes with very low latency, i.e before the subsequent call to WaitAll, is ignored, resulting in a false negative and a memory leak.\n\n### Performance Improvements\n* Java API extensions to improve consistency and completeness of APIs\n1 Extended `RocksDB.get([ColumnFamilyHandle columnFamilyHandle,] ReadOptions opt, ByteBuffer key, ByteBuffer value)` which now accepts indirect buffer parameters as well as direct buffer parameters\n2 Extended `RocksDB.put( [ColumnFamilyHandle columnFamilyHandle,] WriteOptions writeOpts, final ByteBuffer key, final ByteBuffer value)` which now accepts indirect buffer parameters as well as direct buffer parameters\n3 Added `RocksDB.merge([ColumnFamilyHandle columnFamilyHandle,] WriteOptions writeOptions, ByteBuffer key, ByteBuffer value)` methods with the same parameter options as `put(...)` - direct and indirect buffers are supported\n4 Added `RocksIterator.key( byte[] key [, int offset, int len])` methods which retrieve the iterator key into the supplied buffer\n5 Added `RocksIterator.value( byte[] value [, int offset, int len])` methods which retrieve the iterator value into the supplied buffer\n6 Deprecated `get(final ColumnFamilyHandle columnFamilyHandle, final ReadOptions readOptions, byte[])` in favour of `get(final ReadOptions readOptions, final ColumnFamilyHandle columnFamilyHandle, byte[])` which has consistent parameter ordering with other methods in the same class\n7 Added `Transaction.get( ReadOptions opt, [ColumnFamilyHandle columnFamilyHandle, ] byte[] key, byte[] value)` methods which retrieve the requested value into the supplied buffer\n8 Added `Transaction.get( ReadOptions opt, [ColumnFamilyHandle columnFamilyHandle, ] ByteBuffer key, ByteBuffer value)` methods which retrieve the requested value into the supplied buffer\n9 Added `Transaction.getForUpdate( ReadOptions readOptions, [ColumnFamilyHandle columnFamilyHandle, ] byte[] key, byte[] value, boolean exclusive [, boolean doValidate])` methods which retrieve the requested value into the supplied buffer\n10 Added `Transaction.getForUpdate( ReadOptions readOptions, [ColumnFamilyHandle columnFamilyHandle, ] ByteBuffer key, ByteBuffer value, boolean exclusive [, boolean doValidate])` methods which retrieve the requested value into the supplied buffer\n11 Added `Transaction.getIterator()` method as a convenience which defaults the `ReadOptions` value supplied to existing `Transaction.iterator()` methods. This mirrors the existing `RocksDB.iterator()` method.\n12 Added `Transaction.put([ColumnFamilyHandle columnFamilyHandle, ]  ByteBuffer key, ByteBuffer value [, boolean assumeTracked])` methods which supply the key, and the value to be written in a `ByteBuffer` parameter\n13 Added `Transaction.merge([ColumnFamilyHandle columnFamilyHandle, ] ByteBuffer key, ByteBuffer value [,  boolean assumeTracked])` methods which supply the key, and the value to be written/merged in a `ByteBuffer` parameter\n14 Added `Transaction.mergeUntracked([ColumnFamilyHandle columnFamilyHandle, ] ByteBuffer key, ByteBuffer value)` methods which supply the key, and the value to be written/merged in a `ByteBuffer` parameter\n\n\n## 8.9.0 (11/17/2023)\n### New Features\n* Add GetEntity() and PutEntity() API implementation for Attribute Group support. Through the use of Column Families, AttributeGroup enables users to logically group wide-column entities.\n\n### Public API Changes\n* Added rocksdb_ratelimiter_create_auto_tuned API to create an auto-tuned GenericRateLimiter.\n* Added clipColumnFamily() to the Java API to clip the entries in the CF according to the range [begin_key, end_key).\n* Make the `EnableFileDeletion` API not default to force enabling. For users that rely on this default behavior and still\nwant to continue to use force enabling, they need to explicitly pass a `true` to `EnableFileDeletion`.\n* Add new Cache APIs GetSecondaryCacheCapacity() and GetSecondaryCachePinnedUsage() to return the configured capacity, and cache reservation charged to the secondary cache.\n\n### Behavior Changes\n* During off-peak hours defined by `daily_offpeak_time_utc`, the compaction picker will select a larger number of files for periodic compaction. This selection will include files that are projected to expire by the next off-peak start time, ensuring that these files are not chosen for periodic compaction outside of off-peak hours.\n* If an error occurs when writing to a trace file after `DB::StartTrace()`, the subsequent trace writes are skipped to avoid writing to a file that has previously seen error. In this case, `DB::EndTrace()` will also return a non-ok status with info about the error occured previously in its status message.\n* Deleting stale files upon recovery are delegated to SstFileManger if available so they can be rate limited.\n* Make RocksDB only call `TablePropertiesCollector::Finish()` once.\n* When `WAL_ttl_seconds > 0`, we now process archived WALs for deletion at least every `WAL_ttl_seconds / 2` seconds. Previously it could be less frequent in case of small `WAL_ttl_seconds` values when size-based expiration (`WAL_size_limit_MB > 0 `) was simultaneously enabled.\n\n### Bug Fixes\n* Fixed a crash or assertion failure bug in experimental new HyperClockCache variant, especially when running with a SecondaryCache.\n* Fix a race between flush error recovery and db destruction that can lead to db crashing.\n* Fixed some bugs in the index builder/reader path for user-defined timestamps in Memtable only feature.\n\n## 8.8.0 (10/23/2023)\n### New Features\n* Introduce AttributeGroup by adding the first AttributeGroup support API, MultiGetEntity(). Through the use of Column Families, AttributeGroup enables users to logically group wide-column entities. More APIs to support AttributeGroup will come soon, including GetEntity, PutEntity, and others.\n* Added new tickers `rocksdb.fifo.{max.size|ttl}.compactions` to count FIFO compactions that drop files for different reasons\n* Add an experimental offpeak duration awareness by setting `DBOptions::daily_offpeak_time_utc` in \"HH:mm-HH:mm\" format. This information will be used for resource optimization in the future\n* Users can now change the max bytes granted in a single refill period (i.e, burst) during runtime by `SetSingleBurstBytes()` for RocksDB rate limiter\n\n### Public API Changes\n* The default value of `DBOptions::fail_if_options_file_error` changed from `false` to `true`. Operations that set in-memory options (e.g., `DB::Open*()`, `DB::SetOptions()`, `DB::CreateColumnFamily*()`, and `DB::DropColumnFamily()`) but fail to persist the change will now return a non-OK `Status` by default.\n\n### Behavior Changes\n* For non direct IO, eliminate the file system prefetching attempt for compaction read when `Options::compaction_readahead_size` is 0\n* During a write stop, writes now block on in-progress recovery attempts\n\n### Bug Fixes\n* Fix a bug in auto_readahead_size where first_internal_key of index blocks wasn't copied properly resulting in corruption error when first_internal_key was used for comparison.\n* Fixed a bug where compaction read under non direct IO still falls back to RocksDB internal prefetching after file system's prefetching returns non-OK status other than `Status::NotSupported()`\n* Add bounds check in WBWIIteratorImpl and make BaseDeltaIterator, WriteUnpreparedTxn and WritePreparedTxn respect the upper bound and lower bound in ReadOption. See 11680.\n* Fixed the handling of wide-column base values in the `max_successive_merges` logic.\n* Fixed a rare race bug involving a concurrent combination of Create/DropColumnFamily and/or Set(DB)Options that could lead to inconsistency between (a) the DB's reported options state, (b) the DB options in effect, and (c) the latest persisted OPTIONS file.\n* Fixed a possible underflow when computing the compressed secondary cache share of memory reservations while updating the compressed secondary to total block cache ratio.\n\n### Performance Improvements\n* Improved the I/O efficiency of DB::Open a new DB with `create_missing_column_families=true` and many column families.\n\n## 8.7.0 (09/22/2023)\n### New Features\n* Added an experimental new \"automatic\" variant of HyperClockCache that does not require a prior estimate of the average size of cache entries. This variant is activated when HyperClockCacheOptions::estimated\\_entry\\_charge = 0 and has essentially the same concurrency benefits as the existing HyperClockCache.\n* Add a new statistic `COMPACTION_CPU_TOTAL_TIME` that records cumulative compaction cpu time. This ticker is updated regularly while a compaction is running.\n* Add `GetEntity()` API for ReadOnly DB and Secondary DB.\n* Add a new iterator API `Iterator::Refresh(const Snapshot *)` that allows iterator to be refreshed while using the input snapshot to read.\n* Added a new read option `merge_operand_count_threshold`. When the number of merge operands applied during a successful point lookup exceeds this threshold, the query will return a special OK status with a new subcode `kMergeOperandThresholdExceeded`. Applications might use this signal to take action to reduce the number of merge operands for the affected key(s), for example by running a compaction.\n* For `NewRibbonFilterPolicy()`, made the `bloom_before_level` option mutable through the Configurable interface and the SetOptions API, allowing dynamic switching between all-Bloom and all-Ribbon configurations, and configurations in between. See comments on `NewRibbonFilterPolicy()`\n* RocksDB now allows the block cache to be stacked on top of a compressed secondary cache and a non-volatile secondary cache, thus creating a three-tier cache. To set it up, use the `NewTieredCache()` API in rocksdb/cache.h..\n* Added a new wide-column aware full merge API called `FullMergeV3` to `MergeOperator`. `FullMergeV3` supports wide columns both as base value and merge result, which enables the application to perform more general transformations during merges. For backward compatibility, the default implementation implements the earlier logic of applying the merge operation to the default column of any wide-column entities. Specifically, if there is no base value or the base value is a plain key-value, the default implementation falls back to `FullMergeV2`. If the base value is a wide-column entity, the default implementation invokes `FullMergeV2` to perform the merge on the default column, and leaves any other columns unchanged.\n* Add wide column support to ldb commands (scan, dump, idump, dump_wal) and sst_dump tool's scan command\n\n### Public API Changes\n* Expose more information about input files used in table creation (if any) in `CompactionFilter::Context`. See `CompactionFilter::Context::input_start_level`,`CompactionFilter::Context::input_table_properties` for more.\n* `Options::compaction_readahead_size` 's default value is changed from 0 to 2MB.\n* When using LZ4 compression, the `acceleration` parameter is configurable by setting the negated value in `CompressionOptions::level`. For example, `CompressionOptions::level=-10` will set `acceleration=10`\n* The `NewTieredCache` API has been changed to take the total cache capacity (inclusive of both the primary and the compressed secondary cache) and the ratio of total capacity to allocate to the compressed cache. These are specified in `TieredCacheOptions`. Any capacity specified in `LRUCacheOptions`, `HyperClockCacheOptions` and `CompressedSecondaryCacheOptions` is ignored. A new API, `UpdateTieredCache` is provided to dynamically update the total capacity, ratio of compressed cache, and admission policy.\n* The `NewTieredVolatileCache()` API in rocksdb/cache.h has been renamed to `NewTieredCache()`.\n\n### Behavior Changes\n* Compaction read performance will regress when `Options::compaction_readahead_size` is explicitly set to 0\n* Universal size amp compaction will conditionally exclude some of the newest L0 files when selecting input with a small negative impact to size amp. This is to prevent a large number of L0 files from being locked by a size amp compaction, potentially leading to write stop with a few more flushes.\n* Change ldb scan command delimiter from ':' to '==>'.\n\n### Bug Fixes\n* Fix a bug where if there is an error reading from offset 0 of a file from L1+ and that the file is not the first file in the sorted run, data can be lost in compaction and read/scan can return incorrect results.\n* Fix a bug where iterator may return incorrect result for DeleteRange() users if there was an error reading from a file.\n* Fix a bug with atomic_flush=true that can cause DB to stuck after a flush fails (#11872).\n* Fix a bug where RocksDB (with atomic_flush=false) can delete output SST files of pending flushes when a previous concurrent flush fails (#11865). This can result in DB entering read-only state with error message like `IO error: No such file or directory: While open a file for random read: /tmp/rocksdbtest-501/db_flush_test_87732_4230653031040984171/000013.sst`.\n* Fix an assertion fault during seek with async_io when readahead trimming is enabled.\n* When the compressed secondary cache capacity is reduced to 0, it should be completely disabled. Before this fix, inserts and lookups would still go to the backing `LRUCache` before returning, thus incurring locking overhead. With this fix, inserts and lookups are no-ops and do not add any overhead.\n* Updating the tiered cache (cache allocated using NewTieredCache()) by calling SetCapacity() on it was not working properly. The initial creation would set the primary cache capacity to the combined primary and compressed secondary cache capacity. But SetCapacity() would just set the primary cache capacity. With this fix, the user always specifies the total budget and compressed secondary cache ratio on creation. Subsequently, SetCapacity() will distribute the new capacity across the two caches by the same ratio.\n* Fixed a bug in `MultiGet` for cleaning up SuperVersion acquired with locking db mutex.\n* Fix a bug where row cache can falsely return kNotFound even though row cache entry is hit.\n* Fixed a race condition in `GenericRateLimiter` that could cause it to stop granting requests\n* Fix a bug (Issue #10257) where DB can hang after write stall since no compaction is scheduled (#11764).\n* Add a fix for async_io where during seek, when reading a block for seeking a target key in a file without any readahead, the iterator aligned the read on a page boundary and reading more than necessary. This increased the storage read bandwidth usage.\n* Fix an issue in sst dump tool to handle bounds specified for data with user-defined timestamps.\n* When auto_readahead_size is enabled, update readahead upper bound during readahead trimming when reseek changes iterate_upper_bound dynamically.\n* Fixed a bug where `rocksdb.file.read.verify.file.checksums.micros` is not populated\n\n### Performance Improvements\n* Added additional improvements in tuning readahead_size during Scans when auto_readahead_size is enabled. However it's not supported with Iterator::Prev operation and will return NotSupported error.\n* During async_io, the Seek happens in 2 phases. Phase 1 starts an asynchronous read on a block cache miss, and phase 2 waits for it to complete and finishes the seek. In both phases, it tries to lookup the block cache for the data block first before looking in the prefetch buffer. It's optimized by doing the block cache lookup only in the first phase that would save some CPU.\n\n## 8.6.0 (08/18/2023)\n### New Features\n* Added enhanced data integrity checking on SST files with new format_version=6. Performance impact is very small or negligible. Previously if SST data was misplaced or re-arranged by the storage layer, it could pass block checksum with higher than 1 in 4 billion probability. With format_version=6, block checksums depend on what file they are in and location within the file. This way, misplaced SST data is no more likely to pass checksum verification than randomly corrupted data. Also in format_version=6, SST footers are checksum-protected.\n* Add a new feature to trim readahead_size during scans upto upper_bound when iterate_upper_bound is specified. It's enabled through ReadOptions.auto_readahead_size. Users must also specify ReadOptions.iterate_upper_bound.\n* RocksDB will compare the number of input keys to the number of keys processed after each compaction. Compaction will fail and report Corruption status if the verification fails. Option `compaction_verify_record_count` is introduced for this purpose and is enabled by default.\n* Add a CF option `bottommost_file_compaction_delay` to allow specifying the delay of bottommost level single-file compactions.\n* Add support to allow enabling / disabling user-defined timestamps feature for an existing column family in combination with the in-Memtable only feature.\n* Implement a new admission policy for the compressed secondary cache that admits blocks evicted from the primary cache with the hit bit set. This policy can be specified in TieredVolatileCacheOptions by setting the newly added adm_policy option.\n* Add a column family option `memtable_max_range_deletions` that limits the number of range deletions in a memtable. RocksDB will try to do an automatic flush after the limit is reached. (#11358)\n* Add PutEntity API in sst_file_writer\n* Add `timeout` in microsecond option to `WaitForCompactOptions` to allow timely termination of prolonged waiting in scenarios like recurring recoverable errors, such as out-of-space situations and continuous write streams that sustain ongoing flush and compactions\n* New statistics `rocksdb.file.read.{get|multiget|db.iterator|verify.checksum|verify.file.checksums}.micros` measure read time of block-based SST tables or blob files during db open, `Get()`, `MultiGet()`, using db iterator, `VerifyFileChecksums()` and `VerifyChecksum()`. They require stats level greater than `StatsLevel::kExceptDetailedTimers`.\n* Add close_db option to `WaitForCompactOptions` to call Close() after waiting is done.\n* Add a new compression option `CompressionOptions::checksum` for enabling ZSTD's checksum feature to detect corruption during decompression.\n\n### Public API Changes\n* Mark `Options::access_hint_on_compaction_start` related APIs as deprecated. See #11631 for alternative behavior.\n\n### Behavior Changes\n* Statistics `rocksdb.sst.read.micros` now includes time spent on multi read and async read into the file\n* For Universal Compaction users, periodic compaction (option `periodic_compaction_seconds`) will be set to 30 days by default if block based table is used.\n\n### Bug Fixes\n* Fix a bug in FileTTLBooster that can cause users with a large number of levels (more than 65) to see errors like \"runtime error: shift exponent .. is too large..\" (#11673).\n\n## 8.5.0 (07/21/2023)\n### Public API Changes\n* Removed recently added APIs `GeneralCache` and `MakeSharedGeneralCache()` as our plan changed to stop exposing a general-purpose cache interface. The old forms of these APIs, `Cache` and `NewLRUCache()`, are still available, although general-purpose caching support will be dropped eventually.\n\n### Behavior Changes\n* Option `periodic_compaction_seconds` no longer supports FIFO compaction: setting it has no effect on FIFO compactions. FIFO compaction users should only set option `ttl` instead.\n* Move prefetching responsibility to page cache for compaction read for non directIO use case\n\n### Performance Improvements\n* In case of direct_io, if buffer passed by callee is already aligned, RandomAccessFileRead::Read will avoid realloacting a new buffer, reducing memcpy and use already passed aligned buffer.\n* Small efficiency improvement to HyperClockCache by reducing chance of compiler-generated heap allocations\n\n### Bug Fixes\n* Fix use_after_free bug in async_io MultiReads when underlying FS enabled kFSBuffer. kFSBuffer is when underlying FS pass their own buffer instead of using RocksDB scratch in FSReadRequest. Right now it's an experimental feature.\n\n## 8.4.0 (06/26/2023)\n### New Features\n* Add FSReadRequest::fs_scratch which is a data buffer allocated and provided by underlying FileSystem to RocksDB during reads, when FS wants to provide its own buffer with data instead of using RocksDB provided FSReadRequest::scratch. This can help in cpu optimization by avoiding copy from file system's buffer to RocksDB buffer. More details on how to use/enable it in file_system.h. Right now its supported only for MultiReads(async + sync) with non direct io.\n* Start logging non-zero user-defined timestamp sizes in WAL to signal user key format in subsequent records and use it during recovery. This change will break recovery from WAL files written by early versions that contain user-defined timestamps. The workaround is to ensure there are no WAL files to recover (i.e. by flushing before close) before upgrade.\n* Added new property \"rocksdb.obsolete-sst-files-size-property\" that reports the size of SST files that have become obsolete but have not yet been deleted or scheduled for deletion\n* Start to record the value of the flag `AdvancedColumnFamilyOptions.persist_user_defined_timestamps` in the Manifest and table properties for a SST file when it is created. And use the recorded flag when creating a table reader for the SST file. This flag is only explicitly record if it's false.\n* Add a new option OptimisticTransactionDBOptions::shared_lock_buckets that enables sharing mutexes for validating transactions between DB instances, for better balancing memory efficiency and validation contention across DB instances. Different column families and DBs also now use different hash seeds in this validation, so that the same set of key names will not contend across DBs or column families.\n* Add a new ticker `rocksdb.files.marked.trash.deleted` to track the number of trash files deleted by background thread from the trash queue.\n* Add an API NewTieredVolatileCache() in include/rocksdb/cache.h to allocate an instance of a block cache with a primary block cache tier and a compressed secondary cache tier. A cache of this type distributes memory reservations against the block cache, such as WriteBufferManager, table reader memory etc., proportionally across both the primary and compressed secondary cache.\n* Add `WaitForCompact()` to wait for all flush and compactions jobs to finish. Jobs to wait include the unscheduled (queued, but not scheduled yet).\n* Add `WriteBatch::Release()` that releases the batch's serialized data to the caller.\n\n### Public API Changes\n* Add C API `rocksdb_options_add_compact_on_deletion_collector_factory_del_ratio`.\n* change the FileSystem::use_async_io() API to SupportedOps API in order to extend it to various operations supported by underlying FileSystem. Right now it contains FSSupportedOps::kAsyncIO and FSSupportedOps::kFSBuffer. More details about FSSupportedOps in filesystem.h\n* Add new tickers: `rocksdb.error.handler.bg.error.count`, `rocksdb.error.handler.bg.io.error.count`, `rocksdb.error.handler.bg.retryable.io.error.count` to replace the misspelled ones: `rocksdb.error.handler.bg.errro.count`, `rocksdb.error.handler.bg.io.errro.count`, `rocksdb.error.handler.bg.retryable.io.errro.count` ('error' instead of 'errro'). Users should switch to use the new tickers before 9.0 release as the misspelled old tickers will be completely removed then.\n* Overload the API CreateColumnFamilyWithImport() to support creating ColumnFamily by importing multiple ColumnFamilies It requires that CFs should not overlap in user key range.\n\n### Behavior Changes\n* Change the default value for option `level_compaction_dynamic_level_bytes` to true. This affects users who use leveled compaction and do not set this option explicitly. These users may see additional background compactions following DB open. These compactions help to shape the LSM according to `level_compaction_dynamic_level_bytes` such that the size of each level Ln is approximately size of Ln-1 * `max_bytes_for_level_multiplier`. Turning on this option has other benefits too: see more detail in wiki: https://github.com/facebook/rocksdb/wiki/Leveled-Compaction#option-level_compaction_dynamic_level_bytes-and-levels-target-size and in option comment in advanced_options.h (#11525).\n* For Leveled Compaction users, `CompactRange()` will now always try to compact to the last non-empty level. (#11468)\nFor Leveled Compaction users, `CompactRange()` with `bottommost_level_compaction = BottommostLevelCompaction::kIfHaveCompactionFilter` will behave similar to `kForceOptimized` in that it will skip files created during this manual compaction when compacting files in the bottommost level. (#11468)\n* RocksDB will try to drop range tombstones during non-bottommost compaction when it is safe to do so. (#11459)\n* When a DB is openend with `allow_ingest_behind=true` (currently only Universal compaction is supported), files in the last level, i.e. the ingested files,  will not be included in any compaction. (#11489)\n* Statistics `rocksdb.sst.read.micros` scope is expanded to all SST reads except for file ingestion and column family import (some compaction reads were previously excluded).\n\n### Bug Fixes\n* Reduced cases of illegally using Env::Default() during static destruction by never destroying the internal PosixEnv itself (except for builds checking for memory leaks). (#11538)\n* Fix extra prefetching during seek in async_io when BlockBasedTableOptions.num_file_reads_for_auto_readahead is 1 leading to extra reads than required.\n* Fix a bug where compactions that are qualified to be run as 2 subcompactions were only run as one subcompaction.\n* Fix a use-after-move bug in block.cc.\n\n## 8.3.0 (05/19/2023)\n### New Features\n* Introduced a new option `block_protection_bytes_per_key`, which can be used to enable per key-value integrity protection for in-memory blocks in block cache (#11287).\n* Added `JemallocAllocatorOptions::num_arenas`. Setting `num_arenas > 1` may mitigate mutex contention in the allocator, particularly in scenarios where block allocations commonly bypass jemalloc tcache.\n* Improve the operational safety of publishing a DB or SST files to many hosts by using different block cache hash seeds on different hosts. The exact behavior is controlled by new option `ShardedCacheOptions::hash_seed`, which also documents the solved problem in more detail.\n* Introduced a new option `CompactionOptionsFIFO::file_temperature_age_thresholds` that allows FIFO compaction to compact files to different temperatures based on key age (#11428).\n* Added a new ticker stat to count how many times RocksDB detected a corruption while verifying a block checksum: `BLOCK_CHECKSUM_MISMATCH_COUNT`.\n* New statistics `rocksdb.file.read.db.open.micros` that measures read time of block-based SST tables or blob files during db open.\n* New statistics tickers for various iterator seek behaviors and relevant filtering, as \\*`_LEVEL_SEEK_`\\*. (#11460)\n\n### Public API Changes\n* EXPERIMENTAL: Add new API `DB::ClipColumnFamily` to clip the key in CF to a certain range. It will physically deletes all keys outside the range including tombstones.\n* Add `MakeSharedCache()` construction functions to various cache Options objects, and deprecated the `NewWhateverCache()` functions with long parameter lists.\n* Changed the meaning of various Bloom filter stats (prefix vs. whole key), with iterator-related filtering only being tracked in the new \\*`_LEVEL_SEEK_`\\*. stats. (#11460)\n\n### Behavior changes\n* For x86, CPU features are no longer detected at runtime nor in build scripts, but in source code using common preprocessor defines. This will likely unlock some small performance improvements on some newer hardware, but could hurt performance of the kCRC32c checksum, which is no longer the default, on some \"portable\" builds. See PR #11419 for details.\n\n### Bug Fixes\n* Delete an empty WAL file on DB open if the log number is less than the min log number to keep\n* Delete temp OPTIONS file on DB open if there is a failure to write it out or rename it\n\n### Performance Improvements\n* Improved the I/O efficiency of prefetching SST metadata by recording more information in the DB manifest. Opening files written with previous versions will still rely on heuristics for how much to prefetch (#11406).\n\n## 8.2.0 (04/24/2023)\n### Public API Changes\n* `SstFileWriter::DeleteRange()` now returns `Status::InvalidArgument` if the range's end key comes before its start key according to the user comparator. Previously the behavior was undefined.\n* Add `multi_get_for_update` to C API.\n* Remove unnecessary constructor for CompressionOptions.\n\n### Behavior changes\n* Changed default block cache size from an 8MB to 32MB LRUCache, which increases the default number of cache shards from 16 to 64. This change is intended to minimize cache mutex contention under stress conditions. See https://github.com/facebook/rocksdb/wiki/Block-Cache for more information.\n* For level compaction with `level_compaction_dynamic_level_bytes=true`, RocksDB now trivially moves levels down to fill LSM starting from bottommost level during DB open. See more in comments for option `level_compaction_dynamic_level_bytes` (#11321).\n* User-provided `ReadOptions` take effect for more reads of non-`CacheEntryRole::kDataBlock` blocks.\n* For level compaction with `level_compaction_dynamic_level_bytes=true`, RocksDB now drains unnecessary levels through background compaction automatically (#11340). This together with #11321 makes it automatic to migrate other compaction settings to level compaction with `level_compaction_dynamic_level_bytes=true`. In addition, a live DB that becomes smaller will now have unnecessary levels drained which can help to reduce read and space amp.\n* If `CompactRange()` is called with `CompactRangeOptions::bottommost_level_compaction=kForce*` to compact from L0 to L1, RocksDB now will try to do trivial move from L0 to L1 and then do an intra L1 compaction, instead of a L0 to L1 compaction with trivial move disabled (#11375)).\n\n### Bug Fixes\n* In the DB::VerifyFileChecksums API, ensure that file system reads of SST files are equal to the readahead_size in ReadOptions, if specified. Previously, each read was 2x the readahead_size.\n* In block cache tracing, fixed some cases of bad hit/miss information (and more) with MultiGet.\n\n### New Features\n* Add experimental `PerfContext` counters `iter_{next|prev|seek}_count` for db iterator, each counting the times of corresponding API being called.\n* Allow runtime changes to whether `WriteBufferManager` allows stall or not by calling `SetAllowStall()`\n* Added statistics tickers BYTES_COMPRESSED_FROM, BYTES_COMPRESSED_TO, BYTES_COMPRESSION_BYPASSED, BYTES_COMPRESSION_REJECTED, NUMBER_BLOCK_COMPRESSION_BYPASSED, and NUMBER_BLOCK_COMPRESSION_REJECTED. Disabled/deprecated histograms BYTES_COMPRESSED and BYTES_DECOMPRESSED, and ticker NUMBER_BLOCK_NOT_COMPRESSED. The new tickers offer more inight into compression ratios, rejected vs. disabled compression, etc. (#11388)\n* New statistics `rocksdb.file.read.{flush|compaction}.micros` that measure read time of block-based SST tables or blob files during flush or compaction.\n\n## 8.1.0 (03/18/2023)\n### Behavior changes\n* Compaction output file cutting logic now considers range tombstone start keys. For example, SST partitioner now may receive ParitionRequest for range tombstone start keys.\n* If the async_io ReadOption is specified for MultiGet or NewIterator on a platform that doesn't support IO uring, the option is ignored and synchronous IO is used.\n\n### Bug Fixes\n* Fixed an issue for backward iteration when user defined timestamp is enabled in combination with BlobDB.\n* Fixed a couple of cases where a Merge operand encountered during iteration wasn't reflected in the `internal_merge_count` PerfContext counter.\n* Fixed a bug in CreateColumnFamilyWithImport()/ExportColumnFamily() which did not support range tombstones (#11252).\n* Fixed a bug where an excluded column family from an atomic flush contains unflushed data that should've been included in this atomic flush (i.e, data of seqno less than the max seqno of this atomic flush), leading to potential data loss in this excluded column family when `WriteOptions::disableWAL == true` (#11148).\n\n### New Features\n* Add statistics rocksdb.secondary.cache.filter.hits, rocksdb.secondary.cache.index.hits, and rocksdb.secondary.cache.filter.hits\n* Added a new PerfContext counter `internal_merge_point_lookup_count` which tracks the number of Merge operands applied while serving point lookup queries.\n* Add new statistics rocksdb.table.open.prefetch.tail.read.bytes, rocksdb.table.open.prefetch.tail.{miss|hit}\n* Add support for SecondaryCache with HyperClockCache (`HyperClockCacheOptions` inherits `secondary_cache` option from `ShardedCacheOptions`)\n* Add new db properties `rocksdb.cf-write-stall-stats`, `rocksdb.db-write-stall-stats`and APIs to examine them in a structured way. In particular, users of `GetMapProperty()` with property `kCFWriteStallStats`/`kDBWriteStallStats` can now use the functions in `WriteStallStatsMapKeys` to find stats in the map.\n\n### Public API Changes\n* Changed various functions and features in `Cache` that are mostly relevant to custom implementations or wrappers. Especially, asychronous lookup functionality is moved from `Lookup()` to a new `StartAsyncLookup()` function.\n\n## 8.0.0 (02/19/2023)\n### Behavior changes\n* `ReadOptions::verify_checksums=false` disables checksum verification for more reads of non-`CacheEntryRole::kDataBlock` blocks.\n* In case of scan with async_io enabled, if posix doesn't support IOUring, Status::NotSupported error will be returned to the users. Initially that error was swallowed and reads were switched to synchronous reads.\n\n### Bug Fixes\n* Fixed a data race on `ColumnFamilyData::flush_reason` caused by concurrent flushes.\n* Fixed an issue in `Get` and `MultiGet` when user-defined timestamps is enabled in combination with BlobDB.\n* Fixed some atypical behaviors for `LockWAL()` such as allowing concurrent/recursive use and not expecting `UnlockWAL()` after non-OK result. See API comments.\n* Fixed a feature interaction bug where for blobs `GetEntity` would expose the blob reference instead of the blob value.\n* Fixed `DisableManualCompaction()` and `CompactRangeOptions::canceled` to cancel compactions even when they are waiting on conflicting compactions to finish\n* Fixed a bug in which a successful `GetMergeOperands()` could transiently return `Status::MergeInProgress()`\n* Return the correct error (Status::NotSupported()) to MultiGet caller when ReadOptions::async_io flag is true and IO uring is not enabled. Previously, Status::Corruption() was being returned when the actual failure was lack of async IO support.\n* Fixed a bug in DB open/recovery from a compressed WAL that was caused due to incorrect handling of certain record fragments with the same offset within a WAL block.\n\n### Feature Removal\n* Remove RocksDB Lite.\n* The feature block_cache_compressed is removed. Statistics related to it are removed too.\n* Remove deprecated Env::LoadEnv(). Use Env::CreateFromString() instead.\n* Remove deprecated FileSystem::Load(). Use FileSystem::CreateFromString() instead.\n* Removed the deprecated version of these utility functions and the corresponding Java bindings: `LoadOptionsFromFile`, `LoadLatestOptions`, `CheckOptionsCompatibility`.\n* Remove the FactoryFunc from the LoadObject method from the Customizable helper methods.\n\n### Public API Changes\n* Moved rarely-needed Cache class definition to new advanced_cache.h, and added a CacheWrapper class to advanced_cache.h. Minor changes to SimCache API definitions.\n* Completely removed the following deprecated/obsolete statistics: the tickers `BLOCK_CACHE_INDEX_BYTES_EVICT`, `BLOCK_CACHE_FILTER_BYTES_EVICT`, `BLOOM_FILTER_MICROS`, `NO_FILE_CLOSES`, `STALL_L0_SLOWDOWN_MICROS`, `STALL_MEMTABLE_COMPACTION_MICROS`, `STALL_L0_NUM_FILES_MICROS`, `RATE_LIMIT_DELAY_MILLIS`, `NO_ITERATORS`, `NUMBER_FILTERED_DELETES`, `WRITE_TIMEDOUT`, `BLOB_DB_GC_NUM_KEYS_OVERWRITTEN`, `BLOB_DB_GC_NUM_KEYS_EXPIRED`, `BLOB_DB_GC_BYTES_OVERWRITTEN`, `BLOB_DB_GC_BYTES_EXPIRED`, `BLOCK_CACHE_COMPRESSION_DICT_BYTES_EVICT` as well as the histograms `STALL_L0_SLOWDOWN_COUNT`, `STALL_MEMTABLE_COMPACTION_COUNT`, `STALL_L0_NUM_FILES_COUNT`, `HARD_RATE_LIMIT_DELAY_COUNT`, `SOFT_RATE_LIMIT_DELAY_COUNT`, `BLOB_DB_GC_MICROS`, and `NUM_DATA_BLOCKS_READ_PER_LEVEL`. Note that as a result, the C++ enum values of the still supported statistics have changed. Developers are advised to not rely on the actual numeric values.\n* Deprecated IngestExternalFileOptions::write_global_seqno and change default to false. This option only needs to be set to true to generate a DB compatible with RocksDB versions before 5.16.0.\n* Remove deprecated APIs `GetColumnFamilyOptionsFrom{Map|String}(const ColumnFamilyOptions&, ..)`, `GetDBOptionsFrom{Map|String}(const DBOptions&, ..)`, `GetBlockBasedTableOptionsFrom{Map|String}(const BlockBasedTableOptions& table_options, ..)` and ` GetPlainTableOptionsFrom{Map|String}(const PlainTableOptions& table_options,..)`.\n* Added a subcode of `Status::Corruption`, `Status::SubCode::kMergeOperatorFailed`, for users to identify corruption failures originating in the merge operator, as opposed to RocksDB's internally identified data corruptions\n\n### Build Changes\n* The `make` build now builds a shared library by default instead of a static library. Use `LIB_MODE=static` to override.\n\n### New Features\n* Compaction filters are now supported for wide-column entities by means of the `FilterV3` API. See the comment of the API for more details.\n* Added `do_not_compress_roles` to `CompressedSecondaryCacheOptions` to disable compression on certain kinds of block. Filter blocks are now not compressed by CompressedSecondaryCache by default.\n* Added a new `MultiGetEntity` API that enables batched wide-column point lookups. See the API comments for more details.\n\n## 7.10.0 (01/23/2023)\n### Behavior changes\n* Make best-efforts recovery verify SST unique ID before Version construction (#10962)\n* Introduce `epoch_number` and sort L0 files by `epoch_number` instead of `largest_seqno`. `epoch_number` represents the order of a file being flushed or ingested/imported. Compaction output file will be assigned with the minimum `epoch_number` among input files'. For L0, larger `epoch_number` indicates newer L0 file.\n\n### Bug Fixes\n* Fixed a regression in iterator where range tombstones after `iterate_upper_bound` is processed.\n* Fixed a memory leak in MultiGet with async_io read option, caused by IO errors during table file open\n* Fixed a bug that multi-level FIFO compaction deletes one file in non-L0 even when `CompactionOptionsFIFO::max_table_files_size` is no exceeded since #10348 or 7.8.0.\n* Fixed a bug caused by `DB::SyncWAL()` affecting `track_and_verify_wals_in_manifest`. Without the fix, application may see \"open error: Corruption: Missing WAL with log number\" while trying to open the db. The corruption is a false alarm but prevents DB open (#10892).\n* Fixed a BackupEngine bug in which RestoreDBFromLatestBackup would fail if the latest backup was deleted and there is another valid backup available.\n* Fix L0 file misorder corruption caused by ingesting files of overlapping seqnos with memtable entries' through introducing `epoch_number`. Before the fix, `force_consistency_checks=true` may catch the corruption before it's exposed to readers, in which case writes returning `Status::Corruption` would be expected. Also replace the previous incomplete fix (#5958) to the same corruption with this new and more complete fix.\n* Fixed a bug in LockWAL() leading to re-locking mutex (#11020).\n* Fixed a heap use after free bug in async scan prefetching when the scan thread and another thread try to read and load the same seek block into cache.\n* Fixed a heap use after free in async scan prefetching if dictionary compression is enabled, in which case sync read of the compression dictionary gets mixed with async prefetching\n* Fixed a data race bug of `CompactRange()` under `change_level=true` acts on overlapping range with an ongoing file ingestion for level compaction. This will either result in overlapping file ranges corruption at a certain level caught by `force_consistency_checks=true` or protentially two same keys both with seqno 0 in two different levels (i.e, new data ends up in lower/older level). The latter will be caught by assertion in debug build but go silently and result in read returning wrong result in release build. This fix is general so it also replaced previous fixes to a similar problem for `CompactFiles()` (#4665), general `CompactRange()` and auto compaction (commit 5c64fb6 and 87dfc1d).\n* Fixed a bug in compaction output cutting where small output files were produced due to TTL file cutting states were not being updated (#11075).\n\n### New Features\n* When an SstPartitionerFactory is configured, CompactRange() now automatically selects for compaction any files overlapping a partition boundary that is in the compaction range, even if no actual entries are in the requested compaction range. With this feature, manual compaction can be used to (re-)establish SST partition points when SstPartitioner changes, without a full compaction.\n* Add BackupEngine feature to exclude files from backup that are known to be backed up elsewhere, using `CreateBackupOptions::exclude_files_callback`. To restore the DB, the excluded files must be provided in alternative backup directories using `RestoreOptions::alternate_dirs`.\n\n### Public API Changes\n* Substantial changes have been made to the Cache class to support internal development goals. Direct use of Cache class members is discouraged and further breaking modifications are expected in the future. SecondaryCache has some related changes and implementations will need to be updated. (Unlike Cache, SecondaryCache is still intended to support user implementations, and disruptive changes will be avoided.) (#10975)\n* Add `MergeOperationOutput::op_failure_scope` for merge operator users to control the blast radius of merge operator failures. Existing merge operator users do not need to make any change to preserve the old behavior\n\n### Performance Improvements\n* Updated xxHash source code, which should improve kXXH3 checksum speed, at least on ARM (#11098).\n* Improved CPU efficiency of DB reads, from block cache access improvements (#10975).\n\n## 7.9.0 (11/21/2022)\n### Performance Improvements\n* Fixed an iterator performance regression for delete range users when scanning through a consecutive sequence of range tombstones (#10877).\n\n### Bug Fixes\n* Fix memory corruption error in scans if async_io is enabled. Memory corruption happened if there is IOError while reading the data leading to empty buffer and other buffer already in progress of async read goes again for reading.\n* Fix failed memtable flush retry bug that could cause wrongly ordered updates, which would surface to writers as `Status::Corruption` in case of `force_consistency_checks=true` (default). It affects use cases that enable both parallel flush (`max_background_flushes > 1` or `max_background_jobs >= 8`) and non-default memtable count (`max_write_buffer_number > 2`).\n* Fixed an issue where the `READ_NUM_MERGE_OPERANDS` ticker was not updated when the base key-value or tombstone was read from an SST file.\n* Fixed a memory safety bug when using a SecondaryCache with `block_cache_compressed`. `block_cache_compressed` no longer attempts to use SecondaryCache features.\n* Fixed a regression in scan for async_io. During seek, valid buffers were getting cleared causing a regression.\n* Tiered Storage: fixed excessive keys written to penultimate level in non-debug builds.\n\n### New Features\n* Add basic support for user-defined timestamp to Merge (#10819).\n* Add stats for ReadAsync time spent and async read errors.\n* Basic support for the wide-column data model is now available. Wide-column entities can be stored using the `PutEntity` API, and retrieved using `GetEntity` and the new `columns` API of iterator. For compatibility, the classic APIs `Get` and `MultiGet`, as well as iterator's `value` API return the value of the anonymous default column of wide-column entities; also, `GetEntity` and iterator's `columns` return any plain key-values in the form of an entity which only has the anonymous default column. `Merge` (and `GetMergeOperands`) currently also apply to the default column; any other columns of entities are unaffected by `Merge` operations. Note that some features like compaction filters, transactions, user-defined timestamps, and the SST file writer do not yet support wide-column entities; also, there is currently no `MultiGet`-like API to retrieve multiple entities at once. We plan to gradually close the above gaps and also implement new features like column-level operations (e.g. updating or querying only certain columns of an entity).\n* Marked HyperClockCache as a production-ready alternative to LRUCache for the block cache. HyperClockCache greatly improves hot-path CPU efficiency under high parallel load or high contention, with some documented caveats and limitations. As much as 4.5x higher ops/sec vs. LRUCache has been seen in db_bench under high parallel load.\n* Add periodic diagnostics to info_log (LOG file) for HyperClockCache block cache if performance is degraded by bad `estimated_entry_charge` option.\n\n### Public API Changes\n* Marked `block_cache_compressed` as a deprecated feature. Use SecondaryCache instead.\n* Added a `SecondaryCache::InsertSaved()` API, with default implementation depending on `Insert()`. Some implementations might need to add a custom implementation of `InsertSaved()`. (Details in API comments.)\n\n## 7.8.0 (10/22/2022)\n### New Features\n* `DeleteRange()` now supports user-defined timestamp.\n* Provide support for async_io with tailing iterators when ReadOptions.tailing is enabled during scans.\n* Tiered Storage: allow data moving up from the last level to the penultimate level if the input level is penultimate level or above.\n* Added `DB::Properties::kFastBlockCacheEntryStats`, which is similar to `DB::Properties::kBlockCacheEntryStats`, except returns cached (stale) values in more cases to reduce overhead.\n* FIFO compaction now supports migrating from a multi-level DB via DB::Open(). During the migration phase, FIFO compaction picker will:\n* picks the sst file with the smallest starting key in the bottom-most non-empty level.\n* Note that during the migration phase, the file purge order will only be an approximation of \"FIFO\" as files in lower-level might sometime contain newer keys than files in upper-level.\n* Added an option `ignore_max_compaction_bytes_for_input` to ignore max_compaction_bytes limit when adding files to be compacted from input level. This should help reduce write amplification. The option is enabled by default.\n* Tiered Storage: allow data moving up from the last level even if it's a last level only compaction, as long as the penultimate level is empty.\n* Add a new option IOOptions.do_not_recurse that can be used by underlying file systems to skip recursing through sub directories and list only files in GetChildren API.\n* Add option `preserve_internal_time_seconds` to preserve the time information for the latest data. Which can be used to determine the age of data when `preclude_last_level_data_seconds` is enabled. The time information is attached with SST in table property `rocksdb.seqno.time.map` which can be parsed by tool ldb or sst_dump.\n\n### Bug Fixes\n* Fix a bug in io_uring_prep_cancel in AbortIO API for posix which expects sqe->addr to match with read request submitted and wrong paramter was being passed.\n* Fixed a regression in iterator performance when the entire DB is a single memtable introduced in #10449. The fix is in #10705 and #10716.\n* Fixed an optimistic transaction validation bug caused by DBImpl::GetLatestSequenceForKey() returning non-latest seq for merge (#10724).\n* Fixed a bug in iterator refresh which could segfault for DeleteRange users (#10739).\n* Fixed a bug causing manual flush with `flush_opts.wait=false` to stall when database has stopped all writes (#10001).\n* Fixed a bug in iterator refresh that was not freeing up SuperVersion, which could cause excessive resource pinniung (#10770).\n* Fixed a bug where RocksDB could be doing compaction endlessly when allow_ingest_behind is true and the bottommost level is not filled (#10767).\n* Fixed a memory safety bug in experimental HyperClockCache (#10768)\n* Fixed some cases where `ldb update_manifest` and `ldb unsafe_remove_sst_file` are not usable because they were requiring the DB files to match the existing manifest state (before updating the manifest to match a desired state).\n\n### Performance Improvements\n* Try to align the compaction output file boundaries to the next level ones, which can reduce more than 10% compaction load for the default level compaction. The feature is enabled by default, to disable, set `AdvancedColumnFamilyOptions.level_compaction_dynamic_file_size` to false. As a side effect, it can create SSTs larger than the target_file_size (capped at 2x target_file_size) or smaller files.\n* Improve RoundRobin TTL compaction, which is going to be the same as normal RoundRobin compaction to move the compaction cursor.\n* Fix a small CPU regression caused by a change that UserComparatorWrapper was made Customizable, because Customizable itself has small CPU overhead for initialization.\n\n### Behavior Changes\n* Sanitize min_write_buffer_number_to_merge to 1 if atomic flush is enabled to prevent unexpected data loss when WAL is disabled in a multi-column-family setting (#10773).\n* With periodic stat dumper waits up every options.stats_dump_period_sec seconds, it won't dump stats for a CF if it has no change in the period, unless 7 periods have been skipped.\n* Only periodic stats dumper triggered by options.stats_dump_period_sec will update stats interval. Ones triggered by DB::GetProperty() will not update stats interval and will report based on an interval since the last time stats dump period.\n\n### Public API changes\n* Make kXXH3 checksum the new default, because it is faster on common hardware, especially with kCRC32c affected by a performance bug in some versions of clang (https://github.com/facebook/rocksdb/issues/9891). DBs written with this new setting can be read by RocksDB 6.27 and newer.\n* Refactor the classes, APIs and data structures for block cache tracing to allow a user provided trace writer to be used. Introduced an abstract BlockCacheTraceWriter class that takes a structured BlockCacheTraceRecord. The BlockCacheTraceWriter implementation can then format and log the record in whatever way it sees fit. The default BlockCacheTraceWriterImpl does file tracing using a user provided TraceWriter. More details in rocksdb/includb/block_cache_trace_writer.h.\n\n## 7.7.0 (09/18/2022)\n### Bug Fixes\n* Fixed a hang when an operation such as `GetLiveFiles` or `CreateNewBackup` is asked to trigger and wait for memtable flush on a read-only DB. Such indirect requests for memtable flush are now ignored on a read-only DB.\n* Fixed bug where `FlushWAL(true /* sync */)` (used by `GetLiveFilesStorageInfo()`, which is used by checkpoint and backup) could cause parallel writes at the tail of a WAL file to never be synced.\n* Fix periodic_task unable to re-register the same task type, which may cause `SetOptions()` fail to update periodical_task time like: `stats_dump_period_sec`, `stats_persist_period_sec`.\n* Fixed a bug in the rocksdb.prefetched.bytes.discarded stat. It was counting the prefetch buffer size, rather than the actual number of bytes discarded from the buffer.\n* Fix bug where the directory containing CURRENT can left unsynced after CURRENT is updated to point to the latest MANIFEST, which leads to risk of unsync data loss of CURRENT.\n* Update rocksdb.multiget.io.batch.size stat in non-async MultiGet as well.\n* Fix a bug in key range overlap checking with concurrent compactions when user-defined timestamp is enabled. User-defined timestamps should be EXCLUDED when checking if two ranges overlap.\n* Fixed a bug where the blob cache prepopulating logic did not consider the secondary cache (see #10603).\n* Fixed the rocksdb.num.sst.read.per.level, rocksdb.num.index.and.filter.blocks.read.per.level and rocksdb.num.level.read.per.multiget stats in the MultiGet coroutines\n\n### Public API changes\n* Add `rocksdb_column_family_handle_get_id`, `rocksdb_column_family_handle_get_name` to get name, id of column family in C API\n* Add a new stat rocksdb.async.prefetch.abort.micros to measure time spent waiting for async prefetch reads to abort\n\n### Java API Changes\n* Add CompactionPriority.RoundRobin.\n* Revert to using the default metadata charge policy when creating an LRU cache via the Java API.\n\n### Behavior Change\n* DBOptions::verify_sst_unique_id_in_manifest is now an on-by-default feature that verifies SST file identity whenever they are opened by a DB, rather than only at DB::Open time.\n* Right now, when the option migration tool (OptionChangeMigration()) migrates to FIFO compaction, it compacts all the data into one single SST file and move to L0. This might create a problem for some users: the giant file may be soon deleted to satisfy max_table_files_size, and might cayse the DB to be almost empty. We change the behavior so that the files are cut to be smaller, but these files might not follow the data insertion order. With the change, after the migration, migrated data might not be dropped by insertion order by FIFO compaction.\n* When a block is firstly found from `CompressedSecondaryCache`, we just insert a dummy block into the primary cache and dont erase the block from `CompressedSecondaryCache`. A standalone handle is returned to the caller. Only if the block is found again from `CompressedSecondaryCache` before the dummy block is evicted, we erase the block from `CompressedSecondaryCache` and insert it into the primary cache.\n* When a block is firstly evicted from the primary cache to `CompressedSecondaryCache`, we just insert a dummy block in `CompressedSecondaryCache`. Only if it is evicted again before the dummy block is evicted from the cache, it is treated as a hot block and is inserted into `CompressedSecondaryCache`.\n* Improved the estimation of memory used by cached blobs by taking into account the size of the object owning the blob value and also the allocator overhead if `malloc_usable_size` is available (see #10583).\n* Blob values now have their own category in the cache occupancy statistics, as opposed to being lumped into the \"Misc\" bucket (see #10601).\n* Change the optimize_multiget_for_io experimental ReadOptions flag to default on.\n\n### New Features\n*  RocksDB does internal auto prefetching if it notices 2 sequential reads if readahead_size is not specified. New option `num_file_reads_for_auto_readahead` is added in BlockBasedTableOptions which indicates after how many sequential reads internal auto prefetching should be start (default is 2).\n* Added new perf context counters `block_cache_standalone_handle_count`, `block_cache_real_handle_count`,`compressed_sec_cache_insert_real_count`, `compressed_sec_cache_insert_dummy_count`, `compressed_sec_cache_uncompressed_bytes`, and `compressed_sec_cache_compressed_bytes`.\n* Memory for blobs which are to be inserted into the blob cache is now allocated using the cache's allocator (see #10628 and #10647).\n* HyperClockCache is an experimental, lock-free Cache alternative for block cache that offers much improved CPU efficiency under high parallel load or high contention, with some caveats. As much as 4.5x higher ops/sec vs. LRUCache has been seen in db_bench under high parallel load.\n* `CompressedSecondaryCacheOptions::enable_custom_split_merge` is added for enabling the custom split and merge feature, which split the compressed value into chunks so that they may better fit jemalloc bins.\n\n### Performance Improvements\n* Iterator performance is improved for `DeleteRange()` users. Internally, iterator will skip to the end of a range tombstone when possible, instead of looping through each key and check individually if a key is range deleted.\n* Eliminated some allocations and copies in the blob read path. Also, `PinnableSlice` now only points to the blob value and pins the backing resource (cache entry or buffer) in all cases, instead of containing a copy of the blob value. See #10625 and #10647.\n* In case of scans with async_io enabled, few optimizations have been added to issue more asynchronous requests in parallel in order to avoid synchronous prefetching.\n* `DeleteRange()` users should see improvement in get/iterator performance from mutable memtable (see #10547).\n\n## 7.6.0 (08/19/2022)\n### New Features\n* Added `prepopulate_blob_cache` to ColumnFamilyOptions. If enabled, prepopulate warm/hot blobs which are already in memory into blob cache at the time of flush. On a flush, the blob that is in memory (in memtables) get flushed to the device. If using Direct IO, additional IO is incurred to read this blob back into memory again, which is avoided by enabling this option. This further helps if the workload exhibits high temporal locality, where most of the reads go to recently written data. This also helps in case of the remote file system since it involves network traffic and higher latencies.\n* Support using secondary cache with the blob cache. When creating a blob cache, the user can set a secondary blob cache by configuring `secondary_cache` in LRUCacheOptions.\n* Charge memory usage of blob cache when the backing cache of the blob cache and the block cache are different. If an operation reserving memory for blob cache exceeds the avaible space left in the block cache at some point (i.e, causing a cache full under `LRUCacheOptions::strict_capacity_limit` = true), creation will fail with `Status::MemoryLimit()`. To opt in this feature, enable charging `CacheEntryRole::kBlobCache` in `BlockBasedTableOptions::cache_usage_options`.\n* Improve subcompaction range partition so that it is likely to be more even. More evenly distribution of subcompaction will improve compaction throughput for some workloads. All input files' index blocks to sample some anchor key points from which we pick positions to partition the input range. This would introduce some CPU overhead in compaction preparation phase, if subcompaction is enabled, but it should be a small fraction of the CPU usage of the whole compaction process. This also brings a behavier change: subcompaction number is much more likely to maxed out than before.\n* Add CompactionPri::kRoundRobin, a compaction picking mode that cycles through all the files with a compact cursor in a round-robin manner. This feature is available since 7.5.\n* Provide support for subcompactions for user_defined_timestamp.\n* Added an option `memtable_protection_bytes_per_key` that turns on memtable per key-value checksum protection. Each memtable entry will be suffixed by a checksum that is computed during writes, and verified in reads/compaction. Detected corruption will be logged and with corruption status returned to user.\n* Added a blob-specific cache priority level - bottom level. Blobs are typically lower-value targets for caching than data blocks, since 1) with BlobDB, data blocks containing blob references conceptually form an index structure which has to be consulted before we can read the blob value, and 2) cached blobs represent only a single key-value, while cached data blocks generally contain multiple KVs. The user can specify the new option `low_pri_pool_ratio` in `LRUCacheOptions` to configure the ratio of capacity reserved for low priority cache entries (and therefore the remaining ratio is the space reserved for the bottom level), or configuring the new argument `low_pri_pool_ratio` in `NewLRUCache()` to achieve the same effect.\n\n### Public API changes\n* Removed Customizable support for RateLimiter and removed its CreateFromString() and Type() functions.\n* `CompactRangeOptions::exclusive_manual_compaction` is now false by default. This ensures RocksDB does not introduce artificial parallelism limitations by default.\n* Tiered Storage: change `bottommost_temperture` to `last_level_temperture`. The old option name is kept only for migration, please use the new option. The behavior is changed to apply temperature for the `last_level` SST files only.\n* Added a new experimental ReadOption flag called optimize_multiget_for_io, which when set attempts to reduce MultiGet latency by spawning coroutines for keys in multiple levels.\n\n### Bug Fixes\n* Fix a bug starting in 7.4.0 in which some fsync operations might be skipped in a DB after any DropColumnFamily on that DB, until it is re-opened. This can lead to data loss on power loss. (For custom FileSystem implementations, this could lead to `FSDirectory::Fsync` or `FSDirectory::Close` after the first `FSDirectory::Close`; Also, valgrind could report call to `close()` with `fd=-1`.)\n* Fix a bug where `GenericRateLimiter` could revert the bandwidth set dynamically using `SetBytesPerSecond()` when a user configures a structure enclosing it, e.g., using `GetOptionsFromString()` to configure an `Options` that references an existing `RateLimiter` object.\n* Fix race conditions in `GenericRateLimiter`.\n* Fix a bug in `FIFOCompactionPicker::PickTTLCompaction` where total_size calculating might cause underflow\n* Fix data race bug in hash linked list memtable. With this bug, read request might temporarily miss an old record in the memtable in a race condition to the hash bucket.\n* Fix a bug that `best_efforts_recovery` may fail to open the db with mmap read.\n* Fixed a bug where blobs read during compaction would pollute the cache.\n* Fixed a data race in LRUCache when used with a secondary_cache.\n* Fixed a bug where blobs read by iterators would be inserted into the cache even with the `fill_cache` read option set to false.\n* Fixed the segfault caused by `AllocateData()` in `CompressedSecondaryCache::SplitValueIntoChunks()` and `MergeChunksIntoValueTest`.\n* Fixed a bug in BlobDB where a mix of inlined and blob values could result in an incorrect value being passed to the compaction filter (see #10391).\n* Fixed a memory leak bug in stress tests caused by `FaultInjectionSecondaryCache`.\n\n### Behavior Change\n* Added checksum handshake during the copying of decompressed WAL fragment. This together with #9875, #10037, #10212, #10114 and #10319 provides end-to-end integrity protection for write batch during recovery.\n* To minimize the internal fragmentation caused by the variable size of the compressed blocks in `CompressedSecondaryCache`, the original block is split according to the jemalloc bin size in `Insert()` and then merged back in `Lookup()`.\n* PosixLogger is removed and by default EnvLogger will be used for info logging. The behavior of the two loggers should be very similar when using the default Posix Env.\n* Remove [min|max]_timestamp from VersionEdit for now since they are not tracked in MANIFEST anyway but consume two empty std::string (up to 64 bytes) for each file. Should they be added back in the future, we should store them more compactly.\n* Improve universal tiered storage compaction picker to avoid extra major compaction triggered by size amplification. If `preclude_last_level_data_seconds` is enabled, the size amplification is calculated within non last_level data only which skip the last level and use the penultimate level as the size base.\n* If an error is hit when writing to a file (append, sync, etc), RocksDB is more strict with not issuing more operations to it, except closing the file, with exceptions of some WAL file operations in error recovery path.\n* A `WriteBufferManager` constructed with `allow_stall == false` will no longer trigger write stall implicitly by thrashing until memtable count limit is reached. Instead, a column family can continue accumulating writes while that CF is flushing, which means memory may increase. Users who prefer stalling writes must now explicitly set `allow_stall == true`.\n* Add `CompressedSecondaryCache` into the stress tests.\n* Block cache keys have changed, which will cause any persistent caches to miss between versions.\n\n### Performance Improvements\n* Instead of constructing `FragmentedRangeTombstoneList` during every read operation, it is now constructed once and stored in immutable memtables. This improves speed of querying range tombstones from immutable memtables.\n* When using iterators with the integrated BlobDB implementation, blob cache handles are now released immediately when the iterator's position changes.\n* MultiGet can now do more IO in parallel by reading data blocks from SST files in multiple levels, if the optimize_multiget_for_io ReadOption flag is set.\n\n## 7.5.0 (07/15/2022)\n### New Features\n* Mempurge option flag `experimental_mempurge_threshold` is now a ColumnFamilyOptions and can now be dynamically configured using `SetOptions()`.\n* Support backward iteration when `ReadOptions::iter_start_ts` is set.\n* Provide support for ReadOptions.async_io with direct_io to improve Seek latency by using async IO to parallelize child iterator seek and doing asynchronous prefetching on sequential scans.\n* Added support for blob caching in order to cache frequently used blobs for BlobDB.\n  * User can configure the new ColumnFamilyOptions `blob_cache` to enable/disable blob caching.\n  * Either sharing the backend cache with the block cache or using a completely separate cache is supported.\n  * A new abstraction interface called `BlobSource` for blob read logic gives all users access to blobs, whether they are in the blob cache, secondary cache, or (remote) storage. Blobs can be potentially read both while handling user reads (`Get`, `MultiGet`, or iterator) and during compaction (while dealing with compaction filters, Merges, or garbage collection) but eventually all blob reads go through `Version::GetBlob` or, for MultiGet, `Version::MultiGetBlob` (and then get dispatched to the interface -- `BlobSource`).\n* Add experimental tiered compaction feature `AdvancedColumnFamilyOptions::preclude_last_level_data_seconds`, which makes sure the new data inserted within preclude_last_level_data_seconds won't be placed on cold tier (the feature is not complete).\n\n### Public API changes\n* Add metadata related structs and functions in C API, including\n  * `rocksdb_get_column_family_metadata()` and `rocksdb_get_column_family_metadata_cf()` to obtain `rocksdb_column_family_metadata_t`.\n  * `rocksdb_column_family_metadata_t` and its get functions & destroy function.\n  * `rocksdb_level_metadata_t` and its and its get functions & destroy function.\n  * `rocksdb_file_metadata_t` and its and get functions & destroy functions.\n* Add suggest_compact_range() and suggest_compact_range_cf() to C API.\n* When using block cache strict capacity limit (`LRUCache` with `strict_capacity_limit=true`), DB operations now fail with Status code `kAborted` subcode `kMemoryLimit` (`IsMemoryLimit()`) instead of `kIncomplete` (`IsIncomplete()`) when the capacity limit is reached, because Incomplete can mean other specific things for some operations. In more detail, `Cache::Insert()` now returns the updated Status code and this usually propagates through RocksDB to the user on failure.\n* NewClockCache calls temporarily return an LRUCache (with similar characteristics as the desired ClockCache). This is because ClockCache is being replaced by a new version (the old one had unknown bugs) but this is still under development.\n* Add two functions `int ReserveThreads(int threads_to_be_reserved)` and `int ReleaseThreads(threads_to_be_released)` into `Env` class. In the default implementation, both return 0. Newly added `xxxEnv` class that inherits `Env` should implement these two functions for thread reservation/releasing features.\n* Add `rocksdb_options_get_prepopulate_blob_cache` and `rocksdb_options_set_prepopulate_blob_cache` to C API.\n* Add `prepopulateBlobCache` and `setPrepopulateBlobCache` to Java API.\n\n### Bug Fixes\n* Fix a bug in which backup/checkpoint can include a WAL deleted by RocksDB.\n* Fix a bug where concurrent compactions might cause unnecessary further write stalling. In some cases, this might cause write rate to drop to minimum.\n* Fix a bug in Logger where if dbname and db_log_dir are on different filesystems, dbname creation would fail wrt to db_log_dir path returning an error and fails to open the DB.\n* Fix a CPU and memory efficiency issue introduce by https://github.com/facebook/rocksdb/pull/8336 which made InternalKeyComparator configurable as an unintended side effect.\n\n## Behavior Change\n* In leveled compaction with dynamic levelling, level multiplier is not anymore adjusted due to oversized L0. Instead, compaction score is adjusted by increasing size level target by adding incoming bytes from upper levels. This would deprioritize compactions from upper levels if more data from L0 is coming. This is to fix some unnecessary full stalling due to drastic change of level targets, while not wasting write bandwidth for compaction while writes are overloaded.\n* For track_and_verify_wals_in_manifest, revert to the original behavior before #10087: syncing of live WAL file is not tracked, and we track only the synced sizes of **closed** WALs. (PR #10330).\n* WAL compression now computes/verifies checksum during compression/decompression.\n\n### Performance Improvements\n* Rather than doing total sort against all files in a level, SortFileByOverlappingRatio() to only find the top 50 files based on score. This can improve write throughput for the use cases where data is loaded in increasing key order and there are a lot of files in one LSM-tree, where applying compaction results is the bottleneck.\n* In leveled compaction, L0->L1 trivial move will allow more than one file to be moved in one compaction. This would allow L0 files to be moved down faster when data is loaded in sequential order, making slowdown or stop condition harder to hit. Also seek L0->L1 trivial move when only some files qualify.\n* In leveled compaction, try to trivial move more than one files if possible, up to 4 files or max_compaction_bytes. This is to allow higher write throughput for some use cases where data is loaded in sequential order, where appying compaction results is the bottleneck.\n\n## 7.4.0 (06/19/2022)\n### Bug Fixes\n* Fixed a bug in calculating key-value integrity protection for users of in-place memtable updates. In particular, the affected users would be those who configure `protection_bytes_per_key > 0` on `WriteBatch` or `WriteOptions`, and configure `inplace_callback != nullptr`.\n* Fixed a bug where a snapshot taken during SST file ingestion would be unstable.\n* Fixed a bug for non-TransactionDB with avoid_flush_during_recovery = true and TransactionDB where in case of crash, min_log_number_to_keep may not change on recovery and persisting a new MANIFEST with advanced log_numbers for some column families, results in \"column family inconsistency\" error on second recovery. As a solution, RocksDB will persist the new MANIFEST after successfully syncing the new WAL. If a future recovery starts from the new MANIFEST, then it means the new WAL is successfully synced. Due to the sentinel empty write batch at the beginning, kPointInTimeRecovery of WAL is guaranteed to go after this point. If future recovery starts from the old MANIFEST, it means the writing the new MANIFEST failed. We won't have the \"SST ahead of WAL\" error.\n* Fixed a bug where RocksDB DB::Open() may creates and writes to two new MANIFEST files even before recovery succeeds. Now writes to MANIFEST are persisted only after recovery is successful.\n* Fix a race condition in WAL size tracking which is caused by an unsafe iterator access after container is changed.\n* Fix unprotected concurrent accesses to `WritableFileWriter::filesize_` by `DB::SyncWAL()` and `DB::Put()` in two write queue mode.\n* Fix a bug in WAL tracking. Before this PR (#10087), calling `SyncWAL()` on the only WAL file of the db will not log the event in MANIFEST, thus allowing a subsequent `DB::Open` even if the WAL file is missing or corrupted.\n* Fix a bug that could return wrong results with `index_type=kHashSearch` and using `SetOptions` to change the `prefix_extractor`.\n* Fixed a bug in WAL tracking with wal_compression. WAL compression writes a kSetCompressionType record which is not associated with any sequence number. As result, WalManager::GetSortedWalsOfType() will skip these WALs and not return them to caller, e.g. Checkpoint, Backup, causing the operations to fail.\n* Avoid a crash if the IDENTITY file is accidentally truncated to empty. A new DB ID will be written and generated on Open.\n* Fixed a possible corruption for users of `manual_wal_flush` and/or `FlushWAL(true /* sync */)`, together with `track_and_verify_wals_in_manifest == true`. For those users, losing unsynced data (e.g., due to power loss) could make future DB opens fail with a `Status::Corruption` complaining about missing WAL data.\n* Fixed a bug in `WriteBatchInternal::Append()` where WAL termination point in write batch was not considered and the function appends an incorrect number of checksums.\n* Fixed a crash bug introduced in 7.3.0 affecting users of MultiGet with `kDataBlockBinaryAndHash`.\n\n### Public API changes\n* Add new API GetUnixTime in Snapshot class which returns the unix time at which Snapshot is taken.\n* Add transaction `get_pinned` and `multi_get` to C API.\n* Add two-phase commit support to C API.\n* Add `rocksdb_transaction_get_writebatch_wi` and `rocksdb_transaction_rebuild_from_writebatch` to C API.\n* Add `rocksdb_options_get_blob_file_starting_level` and `rocksdb_options_set_blob_file_starting_level` to C API.\n* Add `blobFileStartingLevel` and `setBlobFileStartingLevel` to Java API.\n* Add SingleDelete for DB in C API\n* Add User Defined Timestamp in C API.\n  * `rocksdb_comparator_with_ts_create` to create timestamp aware comparator\n  * Put, Get, Delete, SingleDelete, MultiGet APIs has corresponding timestamp aware APIs with suffix `with_ts`\n  * And Add C API's for Transaction, SstFileWriter, Compaction as mentioned [here](https://github.com/facebook/rocksdb/wiki/User-defined-Timestamp-(Experimental))\n* The contract for implementations of Comparator::IsSameLengthImmediateSuccessor has been updated to work around a design bug in `auto_prefix_mode`.\n* The API documentation for `auto_prefix_mode` now notes some corner cases in which it returns different results than `total_order_seek`, due to design bugs that are not easily fixed. Users using built-in comparators and keys at least the size of a fixed prefix length are not affected.\n* Obsoleted the NUM_DATA_BLOCKS_READ_PER_LEVEL stat and introduced the NUM_LEVEL_READ_PER_MULTIGET and MULTIGET_COROUTINE_COUNT stats\n* Introduced `WriteOptions::protection_bytes_per_key`, which can be used to enable key-value integrity protection for live updates.\n\n### New Features\n* Add FileSystem::ReadAsync API in io_tracing\n* Add blob garbage collection parameters `blob_garbage_collection_policy` and `blob_garbage_collection_age_cutoff` to both force-enable and force-disable GC, as well as selectively override age cutoff when using CompactRange.\n* Add an extra sanity check in `GetSortedWalFiles()` (also used by `GetLiveFilesStorageInfo()`, `BackupEngine`, and `Checkpoint`) to reduce risk of successfully created backup or checkpoint failing to open because of missing WAL file.\n* Add a new column family option `blob_file_starting_level` to enable writing blob files during flushes and compactions starting from the specified LSM tree level.\n* Add support for timestamped snapshots (#9879)\n* Provide support for AbortIO in posix to cancel submitted asynchronous requests using io_uring.\n* Add support for rate-limiting batched `MultiGet()` APIs\n* Added several new tickers, perf context statistics, and DB properties to BlobDB\n  * Added new DB properties \"rocksdb.blob-cache-capacity\", \"rocksdb.blob-cache-usage\", \"rocksdb.blob-cache-pinned-usage\" to show blob cache usage.\n  * Added new perf context statistics `blob_cache_hit_count`, `blob_read_count`, `blob_read_byte`, `blob_read_time`, `blob_checksum_time` and `blob_decompress_time`.\n  * Added new tickers `BLOB_DB_CACHE_MISS`, `BLOB_DB_CACHE_HIT`, `BLOB_DB_CACHE_ADD`, `BLOB_DB_CACHE_ADD_FAILURES`, `BLOB_DB_CACHE_BYTES_READ` and `BLOB_DB_CACHE_BYTES_WRITE`.\n\n### Behavior changes\n* DB::Open(), DB::OpenAsSecondary() will fail if a Logger cannot be created (#9984)\n* DB::Write does not hold global `mutex_` if this db instance does not need to switch wal and mem-table (#7516).\n* Removed support for reading Bloom filters using obsolete block-based filter format. (Support for writing such filters was dropped in 7.0.) For good read performance on old DBs using these filters, a full compaction is required.\n* Per KV checksum in write batch is verified before a write batch is written to WAL to detect any corruption to the write batch (#10114).\n\n### Performance Improvements\n* When compiled with folly (Meta-internal integration; experimental in open source build), improve the locking performance (CPU efficiency) of LRUCache by using folly DistributedMutex in place of standard mutex.\n\n## 7.3.0 (05/20/2022)\n### Bug Fixes\n* Fixed a bug where manual flush would block forever even though flush options had wait=false.\n* Fixed a bug where RocksDB could corrupt DBs with `avoid_flush_during_recovery == true` by removing valid WALs, leading to `Status::Corruption` with message like \"SST file is ahead of WALs\" when attempting to reopen.\n* Fixed a bug in async_io path where incorrect length of data is read by FilePrefetchBuffer if data is consumed from two populated buffers and request for more data is sent.\n* Fixed a CompactionFilter bug. Compaction filter used to use `Delete` to remove keys, even if the keys should be removed with `SingleDelete`. Mixing `Delete` and `SingleDelete` may cause undefined behavior.\n* Fixed a bug in `WritableFileWriter::WriteDirect` and `WritableFileWriter::WriteDirectWithChecksum`. The rate_limiter_priority specified in ReadOptions was not passed to the RateLimiter when requesting a token.\n* Fixed a bug which might cause process crash when I/O error happens when reading an index block in MultiGet().\n\n### New Features\n* DB::GetLiveFilesStorageInfo is ready for production use.\n* Add new stats PREFETCHED_BYTES_DISCARDED which records number of prefetched bytes discarded by RocksDB FilePrefetchBuffer on destruction and POLL_WAIT_MICROS records wait time for FS::Poll API completion.\n* RemoteCompaction supports table_properties_collector_factories override on compaction worker.\n* Start tracking SST unique id in MANIFEST, which will be used to verify with SST properties during DB open to make sure the SST file is not overwritten or misplaced. A db option `verify_sst_unique_id_in_manifest` is introduced to enable/disable the verification, if enabled all SST files will be opened during DB-open to verify the unique id (default is false), so it's recommended to use it with `max_open_files = -1` to pre-open the files.\n* Added the ability to concurrently read data blocks from multiple files in a level in batched MultiGet. This can be enabled by setting the async_io option in ReadOptions. Using this feature requires a FileSystem that supports ReadAsync (PosixFileSystem is not supported yet for this), and for RocksDB to be compiled with folly and c++20.\n* Charge memory usage of file metadata. RocksDB holds one file metadata structure in-memory per on-disk table file. If an operation reserving memory for file metadata exceeds the avaible space left in the block\ncache at some point (i.e, causing a cache full under `LRUCacheOptions::strict_capacity_limit` = true), creation will fail with `Status::MemoryLimit()`. To opt in this feature,  enable charging `CacheEntryRole::kFileMetadata` in `BlockBasedTableOptions::cache_usage_options`.\n\n### Public API changes\n* Add rollback_deletion_type_callback to TransactionDBOptions so that write-prepared transactions know whether to issue a Delete or SingleDelete to cancel a previous key written during prior prepare phase. The PR aims to prevent mixing SingleDeletes and Deletes for the same key that can lead to undefined behaviors for write-prepared transactions.\n* EXPERIMENTAL: Add new API AbortIO in file_system to abort the read requests submitted asynchronously.\n* CompactionFilter::Decision has a new value: kRemoveWithSingleDelete. If CompactionFilter returns this decision, then CompactionIterator will use `SingleDelete` to mark a key as removed.\n* Renamed CompactionFilter::Decision::kRemoveWithSingleDelete to kPurge since the latter sounds more general and hides the implementation details of how compaction iterator handles keys.\n* Added ability to specify functions for Prepare and Validate to OptionsTypeInfo.  Added methods to OptionTypeInfo to set the functions via an API.  These methods are intended for RocksDB plugin developers for configuration management.\n* Added a new immutable db options, enforce_single_del_contracts. If set to false (default is true), compaction will NOT fail due to a single delete followed by a delete for the same key. The purpose of this temporay option is to help existing use cases migrate.\n* Introduce `BlockBasedTableOptions::cache_usage_options` and use that to replace `BlockBasedTableOptions::reserve_table_builder_memory` and  `BlockBasedTableOptions::reserve_table_reader_memory`.\n* Changed `GetUniqueIdFromTableProperties` to return a 128-bit unique identifier, which will be the standard size now. The old functionality (192-bit) is available from `GetExtendedUniqueIdFromTableProperties`. Both functions are no longer \"experimental\" and are ready for production use.\n* In IOOptions, mark `prio` as deprecated for future removal.\n* In `file_system.h`, mark `IOPriority` as deprecated for future removal.\n* Add an option, `CompressionOptions::use_zstd_dict_trainer`, to indicate whether zstd dictionary trainer should be used for generating zstd compression dictionaries. The default value of this option is true for backward compatibility. When this option is set to false, zstd API `ZDICT_finalizeDictionary` is used to generate compression dictionaries.\n* Seek API which positions itself every LevelIterator on the correct data block in the correct SST file which can be parallelized if ReadOptions.async_io option is enabled.\n* Add new stat number_async_seek in PerfContext that indicates number of async calls made by seek to prefetch data.\n* Add support for user-defined timestamps to read only DB.\n\n### Bug Fixes\n* RocksDB calls FileSystem::Poll API during FilePrefetchBuffer destruction which impacts performance as it waits for read requets completion which is not needed anymore. Calling FileSystem::AbortIO to abort those requests instead fixes that performance issue.\n* Fixed unnecessary block cache contention when queries within a MultiGet batch and across parallel batches access the same data block, which previously could cause severely degraded performance in this unusual case. (In more typical MultiGet cases, this fix is expected to yield a small or negligible performance improvement.)\n\n### Behavior changes\n* Enforce the existing contract of SingleDelete so that SingleDelete cannot be mixed with Delete because it leads to undefined behavior. Fix a number of unit tests that violate the contract but happen to pass.\n* ldb `--try_load_options` default to true if `--db` is specified and not creating a new DB, the user can still explicitly disable that by `--try_load_options=false` (or explicitly enable that by `--try_load_options`).\n* During Flush write or Compaction write/read, the WriteController is used to determine whether DB writes are stalled or slowed down. The priority (Env::IOPriority) can then be determined accordingly and be passed in IOOptions to the file system.\n\n### Performance Improvements\n* Avoid calling malloc_usable_size() in LRU Cache's mutex.\n* Reduce DB mutex holding time when finding obsolete files to delete. When a file is trivial moved to another level, the internal files will be referenced twice internally and sometimes opened twice too. If a deletion candidate file is not the last reference, we need to destroy the reference and close the file but not deleting the file. Right now we determine it by building a set of all live files. With the improvement, we check the file against all live LSM-tree versions instead.\n\n## 7.2.0 (04/15/2022)\n### Bug Fixes\n* Fixed bug which caused rocksdb failure in the situation when rocksdb was accessible using UNC path\n* Fixed a race condition when 2PC is disabled and WAL tracking in the MANIFEST is enabled. The race condition is between two background flush threads trying to install flush results, causing a WAL deletion not tracked in the MANIFEST. A future DB open may fail.\n* Fixed a heap use-after-free race with DropColumnFamily.\n* Fixed a bug that `rocksdb.read.block.compaction.micros` cannot track compaction stats (#9722).\n* Fixed `file_type`, `relative_filename` and `directory` fields returned by `GetLiveFilesMetaData()`, which were added in inheriting from `FileStorageInfo`.\n* Fixed a bug affecting `track_and_verify_wals_in_manifest`. Without the fix, application may see \"open error: Corruption: Missing WAL with log number\" while trying to open the db. The corruption is a false alarm but prevents DB open (#9766).\n* Fix segfault in FilePrefetchBuffer with async_io as it doesn't wait for pending jobs to complete on destruction.\n* Fix ERROR_HANDLER_AUTORESUME_RETRY_COUNT stat whose value was set wrong in portal.h\n* Fixed a bug for non-TransactionDB with avoid_flush_during_recovery = true and TransactionDB where in case of crash, min_log_number_to_keep may not change on recovery and persisting a new MANIFEST with advanced log_numbers for some column families, results in \"column family inconsistency\" error on second recovery. As a solution the corrupted WALs whose numbers are larger than the corrupted wal and smaller than the new WAL will be moved to archive folder.\n* Fixed a bug in RocksDB DB::Open() which may creates and writes to two new MANIFEST files even before recovery succeeds. Now writes to MANIFEST are persisted only after recovery is successful.\n\n### New Features\n* For db_bench when --seed=0 or --seed is not set then it uses the current time as the seed value. Previously it used the value 1000.\n* For db_bench when --benchmark lists multiple tests and each test uses a seed for a RNG then the seeds across tests will no longer be repeated.\n* Added an option to dynamically charge an updating estimated memory usage of block-based table reader to block cache if block cache available. To enable this feature, set `BlockBasedTableOptions::reserve_table_reader_memory = true`.\n* Add new stat ASYNC_READ_BYTES that calculates number of bytes read during async read call and users can check if async code path is being called by RocksDB internal automatic prefetching for sequential reads.\n* Enable async prefetching if ReadOptions.readahead_size is set along with ReadOptions.async_io in FilePrefetchBuffer.\n* Add event listener support on remote compaction compactor side.\n* Added a dedicated integer DB property `rocksdb.live-blob-file-garbage-size` that exposes the total amount of garbage in the blob files in the current version.\n* RocksDB does internal auto prefetching if it notices sequential reads. It starts with readahead size `initial_auto_readahead_size` which now can be configured through BlockBasedTableOptions.\n* Add a merge operator that allows users to register specific aggregation function so that they can does aggregation using different aggregation types for different keys. See comments in include/rocksdb/utilities/agg_merge.h for actual usage. The feature is experimental and the format is subject to change and we won't provide a migration tool.\n* Meta-internal / Experimental: Improve CPU performance by replacing many uses of std::unordered_map with folly::F14FastMap when RocksDB is compiled together with Folly.\n* Experimental: Add CompressedSecondaryCache, a concrete implementation of rocksdb::SecondaryCache, that integrates with compression libraries (e.g. LZ4) to hold compressed blocks.\n\n### Behavior changes\n* Disallow usage of commit-time-write-batch for write-prepared/write-unprepared transactions if TransactionOptions::use_only_the_last_commit_time_batch_for_recovery is false to prevent two (or more) uncommitted versions of the same key in the database. Otherwise, bottommost compaction may violate the internal key uniqueness invariant of SSTs if the sequence numbers of both internal keys are zeroed out (#9794).\n* Make DB::GetUpdatesSince() return NotSupported early for write-prepared/write-unprepared transactions, as the API contract indicates.\n\n### Public API changes\n* Exposed APIs to examine results of block cache stats collections in a structured way. In particular, users of `GetMapProperty()` with property `kBlockCacheEntryStats` can now use the functions in `BlockCacheEntryStatsMapKeys` to find stats in the map.\n* Add `fail_if_not_bottommost_level` to IngestExternalFileOptions so that ingestion will fail if the file(s) cannot be ingested to the bottommost level.\n* Add output parameter `is_in_sec_cache` to `SecondaryCache::Lookup()`. It is to indicate whether the handle is possibly erased from the secondary cache after the Lookup.\n\n## 7.1.0 (03/23/2022)\n### New Features\n* Allow WriteBatchWithIndex to index a WriteBatch that includes keys with user-defined timestamps. The index itself does not have timestamp.\n* Add support for user-defined timestamps to write-committed transaction without API change. The `TransactionDB` layer APIs do not allow timestamps because we require that all user-defined-timestamps-aware operations go through the `Transaction` APIs.\n* Added BlobDB options to `ldb`\n* `BlockBasedTableOptions::detect_filter_construct_corruption` can now be dynamically configured using `DB::SetOptions`.\n* Automatically recover from retryable read IO errors during backgorund flush/compaction.\n* Experimental support for preserving file Temperatures through backup and restore, and for updating DB metadata for outside changes to file Temperature (`UpdateManifestForFilesState` or `ldb update_manifest --update_temperatures`).\n* Experimental support for async_io in ReadOptions which is used by FilePrefetchBuffer to prefetch some of the data asynchronously,  if reads are sequential and auto readahead is enabled by rocksdb internally.\n\n### Bug Fixes\n* Fixed a major performance bug in which Bloom filters generated by pre-7.0 releases are not read by early 7.0.x releases (and vice-versa) due to changes to FilterPolicy::Name() in #9590. This can severely impact read performance and read I/O on upgrade or downgrade with existing DB, but not data correctness.\n* Fixed a data race on `versions_` between `DBImpl::ResumeImpl()` and threads waiting for recovery to complete (#9496)\n* Fixed a bug caused by race among flush, incoming writes and taking snapshots. Queries to snapshots created with these race condition can return incorrect result, e.g. resurfacing deleted data.\n* Fixed a bug that DB flush uses `options.compression` even `options.compression_per_level` is set.\n* Fixed a bug that DisableManualCompaction may assert when disable an unscheduled manual compaction.\n* Fix a race condition when cancel manual compaction with `DisableManualCompaction`. Also DB close can cancel the manual compaction thread.\n* Fixed a potential timer crash when open close DB concurrently.\n* Fixed a race condition for `alive_log_files_` in non-two-write-queues mode. The race is between the write_thread_ in WriteToWAL() and another thread executing `FindObsoleteFiles()`. The race condition will be caught if `__glibcxx_requires_nonempty` is enabled.\n* Fixed a bug that `Iterator::Refresh()` reads stale keys after DeleteRange() performed.\n* Fixed a race condition when disable and re-enable manual compaction.\n* Fixed automatic error recovery failure in atomic flush.\n* Fixed a race condition when mmaping a WritableFile on POSIX.\n\n### Public API changes\n* Added pure virtual FilterPolicy::CompatibilityName(), which is needed for fixing major performance bug involving FilterPolicy naming in SST metadata without affecting Customizable aspect of FilterPolicy. This change only affects those with their own custom or wrapper FilterPolicy classes.\n* `options.compression_per_level` is dynamically changeable with `SetOptions()`.\n* Added `WriteOptions::rate_limiter_priority`. When set to something other than `Env::IO_TOTAL`, the internal rate limiter (`DBOptions::rate_limiter`) will be charged at the specified priority for writes associated with the API to which the `WriteOptions` was provided. Currently the support covers automatic WAL flushes, which happen during live updates (`Put()`, `Write()`, `Delete()`, etc.) when `WriteOptions::disableWAL == false` and `DBOptions::manual_wal_flush == false`.\n* Add DB::OpenAndTrimHistory API. This API will open DB and trim data to the timestamp specified by trim_ts (The data with timestamp larger than specified trim bound will be removed). This API should only be used at a timestamp-enabled column families recovery. If the column family doesn't have timestamp enabled, this API won't trim any data on that column family. This API is not compatible with avoid_flush_during_recovery option.\n* Remove BlockBasedTableOptions.hash_index_allow_collision which already takes no effect.\n\n## 7.0.0 (02/20/2022)\n### Bug Fixes\n* Fixed a major bug in which batched MultiGet could return old values for keys deleted by DeleteRange when memtable Bloom filter is enabled (memtable_prefix_bloom_size_ratio > 0). (The fix includes a substantial MultiGet performance improvement in the unusual case of both memtable_whole_key_filtering and prefix_extractor.)\n* Fixed more cases of EventListener::OnTableFileCreated called with OK status, file_size==0, and no SST file kept. Now the status is Aborted.\n* Fixed a read-after-free bug in `DB::GetMergeOperands()`.\n* Fix a data loss bug for 2PC write-committed transaction caused by concurrent transaction commit and memtable switch (#9571).\n* Fixed NUM_INDEX_AND_FILTER_BLOCKS_READ_PER_LEVEL, NUM_DATA_BLOCKS_READ_PER_LEVEL, and NUM_SST_READ_PER_LEVEL stats to be reported once per MultiGet batch per level.\n\n### Performance Improvements\n* Mitigated the overhead of building the file location hash table used by the online LSM tree consistency checks, which can improve performance for certain workloads (see #9351).\n* Switched to using a sorted `std::vector` instead of `std::map` for storing the metadata objects for blob files, which can improve performance for certain workloads, especially when the number of blob files is high.\n* DisableManualCompaction() doesn't have to wait scheduled manual compaction to be executed in thread-pool to cancel the job.\n\n### Public API changes\n* Require C++17 compatible compiler (GCC >= 7, Clang >= 5, Visual Studio >= 2017) for compiling RocksDB and any code using RocksDB headers. See #9388.\n* Added `ReadOptions::rate_limiter_priority`. When set to something other than `Env::IO_TOTAL`, the internal rate limiter (`DBOptions::rate_limiter`) will be charged at the specified priority for file reads associated with the API to which the `ReadOptions` was provided.\n* Remove HDFS support from main repo.\n* Remove librados support from main repo.\n* Remove obsolete backupable_db.h and type alias `BackupableDBOptions`. Use backup_engine.h and `BackupEngineOptions`. Similar renamings are in the C and Java APIs.\n* Removed obsolete utility_db.h and `UtilityDB::OpenTtlDB`. Use db_ttl.h and `DBWithTTL::Open`.\n* Remove deprecated API DB::AddFile from main repo.\n* Remove deprecated API ObjectLibrary::Register() and the (now obsolete) Regex public API. Use ObjectLibrary::AddFactory() with PatternEntry instead.\n* Remove deprecated option DBOption::table_cache_remove_scan_count_limit.\n* Remove deprecated API AdvancedColumnFamilyOptions::soft_rate_limit.\n* Remove deprecated API AdvancedColumnFamilyOptions::hard_rate_limit.\n* Remove deprecated API DBOption::base_background_compactions.\n* Remove deprecated API DBOptions::purge_redundant_kvs_while_flush.\n* Remove deprecated overloads of API DB::CompactRange.\n* Remove deprecated option DBOptions::skip_log_error_on_recovery.\n* Remove ReadOptions::iter_start_seqnum which has been deprecated.\n* Remove DBOptions::preserved_deletes and DB::SetPreserveDeletesSequenceNumber().\n* Remove deprecated API AdvancedColumnFamilyOptions::rate_limit_delay_max_milliseconds.\n* Removed timestamp from WriteOptions. Accordingly, added to DB APIs Put, Delete, SingleDelete, etc. accepting an additional argument 'timestamp'. Added Put, Delete, SingleDelete, etc to WriteBatch accepting an additional argument 'timestamp'. Removed WriteBatch::AssignTimestamps(vector<Slice>) API. Renamed WriteBatch::AssignTimestamp() to WriteBatch::UpdateTimestamps() with clarified comments.\n* Changed type of cache buffer passed to `Cache::CreateCallback` from `void*` to `const void*`.\n* Significant updates to FilterPolicy-related APIs and configuration:\n  * Remove public API support for deprecated, inefficient block-based filter (use_block_based_builder=true).\n    * Old code and configuration strings that would enable it now quietly enable full filters instead, though any built-in FilterPolicy can still read block-based filters. This includes changing the longstanding default behavior of the Java API.\n    * Remove deprecated FilterPolicy::CreateFilter() and FilterPolicy::KeyMayMatch()\n    * Remove `rocksdb_filterpolicy_create()` from C API, as the only C API support for custom filter policies is now obsolete.\n    * If temporary memory usage in full filter creation is a problem, consider using partitioned filters, smaller SST files, or setting reserve_table_builder_memory=true.\n  * Remove support for \"filter_policy=experimental_ribbon\" configuration\n  string. Use something like \"filter_policy=ribbonfilter:10\" instead.\n  * Allow configuration string like \"filter_policy=bloomfilter:10\" without\n  bool, to minimize acknowledgement of obsolete block-based filter.\n  * Made FilterPolicy Customizable. Configuration of filter_policy is now accurately saved in OPTIONS file and can be loaded with LoadOptionsFromFile. (Loading an OPTIONS file generated by a previous version only enables reading and using existing filters, not generating new filters. Previously, no filter_policy would be configured from a saved OPTIONS file.)\n  * Change meaning of nullptr return from GetBuilderWithContext() from \"use\n    block-based filter\" to \"generate no filter in this case.\"\n    * Also, when user specifies bits_per_key < 0.5, we now round this down\n    to \"no filter\" because we expect a filter with >= 80% FP rate is\n    unlikely to be worth the CPU cost of accessing it (esp with\n    cache_index_and_filter_blocks=1 or partition_filters=1).\n    * bits_per_key >= 0.5 and < 1.0 is still rounded up to 1.0 (for 62% FP\n    rate)\n  * Remove class definitions for FilterBitsBuilder and FilterBitsReader from\n    public API, so these can evolve more easily as implementation details.\n    Custom FilterPolicy can still decide what kind of built-in filter to use\n    under what conditions.\n  * Also removed deprecated functions\n    * FilterPolicy::GetFilterBitsBuilder()\n    * NewExperimentalRibbonFilterPolicy()\n  * Remove default implementations of\n    * FilterPolicy::GetBuilderWithContext()\n* Remove default implementation of Name() from FileSystemWrapper.\n* Rename `SizeApproximationOptions.include_memtabtles` to `SizeApproximationOptions.include_memtables`.\n* Remove deprecated option DBOptions::max_mem_compaction_level.\n* Return Status::InvalidArgument from ObjectRegistry::NewObject if a factory exists but the object ould not be created (returns NotFound if the factory is missing).\n* Remove deprecated overloads of API DB::GetApproximateSizes.\n* Remove deprecated option DBOptions::new_table_reader_for_compaction_inputs.\n* Add Transaction::SetReadTimestampForValidation() and Transaction::SetCommitTimestamp(). Default impl returns NotSupported().\n* Add support for decimal patterns to ObjectLibrary::PatternEntry\n* Remove deprecated remote compaction APIs `CompactionService::Start()` and `CompactionService::WaitForComplete()`. Please use `CompactionService::StartV2()`, `CompactionService::WaitForCompleteV2()` instead, which provides the same information plus extra data like priority, db_id, etc.\n* `ColumnFamilyOptions::OldDefaults` and `DBOptions::OldDefaults` are marked deprecated, as they are no longer maintained.\n* Add subcompaction callback APIs: `OnSubcompactionBegin()` and `OnSubcompactionCompleted()`.\n* Add file Temperature information to `FileOperationInfo` in event listener API.\n* Change the type of SizeApproximationFlags from enum to enum class. Also update the signature of DB::GetApproximateSizes API from uint8_t to SizeApproximationFlags.\n* Add Temperature hints information from RocksDB in API `NewSequentialFile()`. backup and checkpoint operations need to open the source files with `NewSequentialFile()`, which will have the temperature hints. Other operations are not covered.\n\n### Behavior Changes\n* Disallow the combination of DBOptions.use_direct_io_for_flush_and_compaction == true and DBOptions.writable_file_max_buffer_size == 0. This combination can cause WritableFileWriter::Append() to loop forever, and it does not make much sense in direct IO.\n* `ReadOptions::total_order_seek` no longer affects `DB::Get()`. The original motivation for this interaction has been obsolete since RocksDB has been able to detect whether the current prefix extractor is compatible with that used to generate table files, probably RocksDB 5.14.0.\n\n## New Features\n* Introduced an option `BlockBasedTableOptions::detect_filter_construct_corruption` for detecting corruption during Bloom Filter (format_version >= 5) and Ribbon Filter construction.\n* Improved the SstDumpTool to read the comparator from table properties and use it to read the SST File.\n* Extended the column family statistics in the info log so the total amount of garbage in the blob files and the blob file space amplification factor are also logged. Also exposed the blob file space amp via the `rocksdb.blob-stats` DB property.\n* Introduced the API rocksdb_create_dir_if_missing in c.h that calls underlying file system's CreateDirIfMissing API to create the directory.\n* Added last level and non-last level read statistics: `LAST_LEVEL_READ_*`, `NON_LAST_LEVEL_READ_*`.\n* Experimental: Add support for new APIs ReadAsync in FSRandomAccessFile that reads the data asynchronously and Poll API in FileSystem that checks if requested read request has completed or not. ReadAsync takes a callback function. Poll API checks for completion of read IO requests and  should call callback functions to indicate completion of read requests.\n\n## 6.29.0 (01/21/2022)\nNote: The next release will be major release 7.0. See https://github.com/facebook/rocksdb/issues/9390 for more info.\n### Public API change\n* Added values to `TraceFilterType`: `kTraceFilterIteratorSeek`, `kTraceFilterIteratorSeekForPrev`, and `kTraceFilterMultiGet`. They can be set in `TraceOptions` to filter out the operation types after which they are named.\n* Added `TraceOptions::preserve_write_order`. When enabled it  guarantees write records are traced in the same order they are logged to WAL and applied to the DB. By default it is disabled (false) to match the legacy behavior and prevent regression.\n* Made the Env class extend the Customizable class.  Implementations need to be registered with the ObjectRegistry and to implement a Name() method in order to be created via this method.\n* `Options::OldDefaults` is marked deprecated, as it is no longer maintained.\n* Add ObjectLibrary::AddFactory and ObjectLibrary::PatternEntry classes.  This method and associated class are the preferred mechanism for registering factories with the ObjectLibrary going forward.  The ObjectLibrary::Register method, which uses regular expressions and may be problematic, is deprecated and will be in a future release.\n* Changed `BlockBasedTableOptions::block_size` from `size_t` to `uint64_t`.\n* Added API warning against using `Iterator::Refresh()` together with `DB::DeleteRange()`, which are incompatible and have always risked causing the refreshed iterator to return incorrect results.\n* Made `AdvancedColumnFamilyOptions.bottommost_temperature` dynamically changeable with `SetOptions()`.\n\n### Behavior Changes\n* `DB::DestroyColumnFamilyHandle()` will return Status::InvalidArgument() if called with `DB::DefaultColumnFamily()`.\n* On 32-bit platforms, mmap reads are no longer quietly disabled, just discouraged.\n\n### New Features\n* Added `Options::DisableExtraChecks()` that can be used to improve peak write performance by disabling checks that should not be necessary in the absence of software logic errors or CPU+memory hardware errors. (Default options are slowly moving toward some performance overheads for extra correctness checking.)\n\n### Performance Improvements\n* Improved read performance when a prefix extractor is used (Seek, Get, MultiGet), even compared to version 6.25 baseline (see bug fix below), by optimizing the common case of prefix extractor compatible with table file and unchanging.\n\n### Bug Fixes\n* Fix a bug that FlushMemTable may return ok even flush not succeed.\n* Fixed a bug of Sync() and Fsync() not using `fcntl(F_FULLFSYNC)` on OS X and iOS.\n* Fixed a significant performance regression in version 6.26 when a prefix extractor is used on the read path (Seek, Get, MultiGet). (Excessive time was spent in SliceTransform::AsString().)\n* Fixed a race condition in SstFileManagerImpl error recovery code that can cause a crash during process shutdown.\n\n### New Features\n* Added RocksJava support for MacOS universal binary (ARM+x86)\n\n## 6.28.0 (2021-12-17)\n### New Features\n* Introduced 'CommitWithTimestamp' as a new tag. Currently, there is no API for user to trigger a write with this tag to the WAL. This is part of the efforts to support write-commited transactions with user-defined timestamps.\n* Introduce SimulatedHybridFileSystem which can help simulating HDD latency in db_bench. Tiered Storage latency simulation can be enabled using -simulate_hybrid_fs_file (note that it doesn't work if db_bench is interrupted in the middle). -simulate_hdd can also be used to simulate all files on HDD.\n\n### Bug Fixes\n* Fixed a bug in rocksdb automatic implicit prefetching which got broken because of new feature adaptive_readahead and internal prefetching got disabled when iterator moves from one file to next.\n* Fixed a bug in TableOptions.prepopulate_block_cache which causes segmentation fault when used with TableOptions.partition_filters = true and TableOptions.cache_index_and_filter_blocks = true.\n* Fixed a bug affecting custom memtable factories which are not registered with the `ObjectRegistry`. The bug could result in failure to save the OPTIONS file.\n* Fixed a bug causing two duplicate entries to be appended to a file opened in non-direct mode and tracked by `FaultInjectionTestFS`.\n* Fixed a bug in TableOptions.prepopulate_block_cache to support block-based filters also.\n* Block cache keys no longer use `FSRandomAccessFile::GetUniqueId()` (previously used when available), so a filesystem recycling unique ids can no longer lead to incorrect result or crash (#7405). For files generated by RocksDB >= 6.24, the cache keys are stable across DB::Open and DB directory move / copy / import / export / migration, etc. Although collisions are still theoretically possible, they are (a) impossible in many common cases, (b) not dependent on environmental factors, and (c) much less likely than a CPU miscalculation while executing RocksDB.\n* Fixed a bug in C bindings causing iterator to return incorrect result (#9343).\n\n### Behavior Changes\n* MemTableList::TrimHistory now use allocated bytes when max_write_buffer_size_to_maintain > 0(default in TrasactionDB, introduced in PR#5022) Fix #8371.\n\n### Public API change\n* Extend WriteBatch::AssignTimestamp and AssignTimestamps API so that both functions can accept an optional `checker` argument that performs additional checking on timestamp sizes.\n* Introduce a new EventListener callback that will be called upon the end of automatic error recovery.\n* Add IncreaseFullHistoryTsLow API so users can advance each column family's full_history_ts_low seperately.\n* Add GetFullHistoryTsLow API so users can query current full_history_low value of specified column family.\n\n### Performance Improvements\n* Replaced map property `TableProperties::properties_offsets`  with uint64_t property `external_sst_file_global_seqno_offset` to save table properties's memory.\n* Block cache accesses are faster by RocksDB using cache keys of fixed size (16 bytes).\n\n### Java API Changes\n* Removed Java API `TableProperties.getPropertiesOffsets()` as it exposed internal details to external users.\n\n## 6.27.0 (2021-11-19)\n### New Features\n* Added new ChecksumType kXXH3 which is faster than kCRC32c on almost all x86\\_64 hardware.\n* Added a new online consistency check for BlobDB which validates that the number/total size of garbage blobs does not exceed the number/total size of all blobs in any given blob file.\n* Provided support for tracking per-sst user-defined timestamp information in MANIFEST.\n* Added new option \"adaptive_readahead\" in ReadOptions. For iterators, RocksDB does auto-readahead on noticing sequential reads and by enabling this option, readahead_size of current file (if reads are sequential) will be carried forward to next file instead of starting from the scratch at each level (except L0 level files). If reads are not sequential it will fall back to 8KB. This option is applicable only for RocksDB internal prefetch buffer and isn't supported with underlying file system prefetching.\n* Added the read count and read bytes related stats to Statistics for tiered storage hot, warm, and cold file reads.\n* Added an option to dynamically charge an updating estimated memory usage of block-based table building to block cache if block cache available. It currently only includes charging memory usage of constructing (new) Bloom Filter and Ribbon Filter to block cache. To enable this feature, set `BlockBasedTableOptions::reserve_table_builder_memory = true`.\n* Add a new API OnIOError in listener.h that notifies listeners when an IO error occurs during FileSystem operation along with filename, status etc.\n* Added compaction readahead support for blob files to the integrated BlobDB implementation, which can improve compaction performance when the database resides on higher-latency storage like HDDs or remote filesystems. Readahead can be configured using the column family option `blob_compaction_readahead_size`.\n\n### Bug Fixes\n* Prevent a `CompactRange()` with `CompactRangeOptions::change_level == true` from possibly causing corruption to the LSM state (overlapping files within a level) when run in parallel with another manual compaction. Note that setting `force_consistency_checks == true` (the default) would cause the DB to enter read-only mode in this scenario and return `Status::Corruption`, rather than committing any corruption.\n* Fixed a bug in CompactionIterator when write-prepared transaction is used. A released earliest write conflict snapshot may cause assertion failure in dbg mode and unexpected key in opt mode.\n* Fix ticker WRITE_WITH_WAL(\"rocksdb.write.wal\"), this bug is caused by a bad extra `RecordTick(stats_, WRITE_WITH_WAL)` (at 2 place), this fix remove the extra `RecordTick`s and fix the corresponding test case.\n* EventListener::OnTableFileCreated was previously called with OK status and file_size==0 in cases of no SST file contents written (because there was no content to add) and the empty file deleted before calling the listener. Now the status is Aborted.\n* Fixed a bug in CompactionIterator when write-preared transaction is used. Releasing earliest_snapshot during compaction may cause a SingleDelete to be output after a PUT of the same user key whose seq has been zeroed.\n* Added input sanitization on negative bytes passed into `GenericRateLimiter::Request`.\n* Fixed an assertion failure in CompactionIterator when write-prepared transaction is used. We prove that certain operations can lead to a Delete being followed by a SingleDelete (same user key). We can drop the SingleDelete.\n* Fixed a bug of timestamp-based GC which can cause all versions of a key under full_history_ts_low to be dropped. This bug will be triggered when some of the ikeys' timestamps are lower than full_history_ts_low, while others are newer.\n* In some cases outside of the DB read and compaction paths, SST block checksums are now checked where they were not before.\n* Explicitly check for and disallow the `BlockBasedTableOptions` if insertion into one of {`block_cache`, `block_cache_compressed`, `persistent_cache`} can show up in another of these. (RocksDB expects to be able to use the same key for different physical data among tiers.)\n* Users who configured a dedicated thread pool for bottommost compactions by explicitly adding threads to the `Env::Priority::BOTTOM` pool will no longer see RocksDB schedule automatic compactions exceeding the DB's compaction concurrency limit. For details on per-DB compaction concurrency limit, see API docs of `max_background_compactions` and `max_background_jobs`.\n* Fixed a bug of background flush thread picking more memtables to flush and prematurely advancing column family's log_number.\n* Fixed an assertion failure in ManifestTailer.\n* Fixed a bug that could, with WAL enabled, cause backups, checkpoints, and `GetSortedWalFiles()` to fail randomly with an error like `IO error: 001234.log: No such file or directory`\n\n### Behavior Changes\n* `NUM_FILES_IN_SINGLE_COMPACTION` was only counting the first input level files, now it's including all input files.\n* `TransactionUtil::CheckKeyForConflicts` can also perform conflict-checking based on user-defined timestamps in addition to sequence numbers.\n* Removed `GenericRateLimiter`'s minimum refill bytes per period previously enforced.\n\n### Public API change\n* When options.ttl is used with leveled compaction with compactinon priority kMinOverlappingRatio, files exceeding half of TTL value will be prioritized more, so that by the time TTL is reached, fewer extra compactions will be scheduled to clear them up. At the same time, when compacting files with data older than half of TTL, output files may be cut off based on those files' boundaries, in order for the early TTL compaction to work properly.\n* Made FileSystem and RateLimiter extend the Customizable class and added a CreateFromString method.  Implementations need to be registered with the ObjectRegistry and to implement a Name() method in order to be created via this method.\n* Clarified in API comments that RocksDB is not exception safe for callbacks and custom extensions. An exception propagating into RocksDB can lead to undefined behavior, including data loss, unreported corruption, deadlocks, and more.\n* Marked `WriteBufferManager` as `final` because it is not intended for extension.\n* Removed unimportant implementation details from table_properties.h\n* Add API `FSDirectory::FsyncWithDirOptions()`, which provides extra information like directory fsync reason in `DirFsyncOptions`. File system like btrfs is using that to skip directory fsync for creating a new file, or when renaming a file, fsync the target file instead of the directory, which improves the `DB::Open()` speed by ~20%.\n* `DB::Open()` is not going be blocked by obsolete file purge if `DBOptions::avoid_unnecessary_blocking_io` is set to true.\n* In builds where glibc provides `gettid()`, info log (\"LOG\" file) lines now print a system-wide thread ID from `gettid()` instead of the process-local `pthread_self()`. For all users, the thread ID format is changed from hexadecimal to decimal integer.\n* In builds where glibc provides `pthread_setname_np()`, the background thread names no longer contain an ID suffix. For example, \"rocksdb:bottom7\" (and all other threads in the `Env::Priority::BOTTOM` pool) are now named \"rocksdb:bottom\". Previously large thread pools could breach the name size limit (e.g., naming \"rocksdb:bottom10\" would fail).\n* Deprecating `ReadOptions::iter_start_seqnum` and `DBOptions::preserve_deletes`, please try using user defined timestamp feature instead. The options will be removed in a future release, currently it logs a warning message when using.\n\n### Performance Improvements\n* Released some memory related to filter construction earlier in `BlockBasedTableBuilder` for `FullFilter` and `PartitionedFilter` case (#9070)\n\n### Behavior Changes\n* `NUM_FILES_IN_SINGLE_COMPACTION` was only counting the first input level files, now it's including all input files.\n\n## 6.26.0 (2021-10-20)\n### Bug Fixes\n* Fixes a bug in directed IO mode when calling MultiGet() for blobs in the same blob file. The bug is caused by not sorting the blob read requests by file offsets.\n* Fix the incorrect disabling of SST rate limited deletion when the WAL and DB are in different directories. Only WAL rate limited deletion should be disabled if its in a different directory.\n* Fix `DisableManualCompaction()` to cancel compactions even when they are waiting on automatic compactions to drain due to `CompactRangeOptions::exclusive_manual_compactions == true`.\n* Fix contract of `Env::ReopenWritableFile()` and `FileSystem::ReopenWritableFile()` to specify any existing file must not be deleted or truncated.\n* Fixed bug in calls to `IngestExternalFiles()` with files for multiple column families. The bug could have introduced a delay in ingested file keys becoming visible after `IngestExternalFiles()` returned. Furthermore, mutations to ingested file keys while they were invisible could have been dropped (not necessarily immediately).\n* Fixed a possible race condition impacting users of `WriteBufferManager` who constructed it with `allow_stall == true`. The race condition led to undefined behavior (in our experience, typically a process crash).\n* Fixed a bug where stalled writes would remain stalled forever after the user calls `WriteBufferManager::SetBufferSize()` with `new_size == 0` to dynamically disable memory limiting.\n* Make `DB::close()` thread-safe.\n* Fix a bug in atomic flush where one bg flush thread will wait forever for a preceding bg flush thread to commit its result to MANIFEST but encounters an error which is mapped to a soft error (DB not stopped).\n* Fix a bug in `BackupEngine` where some internal callers of `GenericRateLimiter::Request()` do not honor `bytes <= GetSingleBurstBytes()`.\n\n### New Features\n* Print information about blob files when using \"ldb list_live_files_metadata\"\n* Provided support for SingleDelete with user defined timestamp.\n* Experimental new function DB::GetLiveFilesStorageInfo offers essentially a unified version of other functions like GetLiveFiles, GetLiveFilesChecksumInfo, and GetSortedWalFiles. Checkpoints and backups could show small behavioral changes and/or improved performance as they now use this new API.\n* Add remote compaction read/write bytes statistics: `REMOTE_COMPACT_READ_BYTES`, `REMOTE_COMPACT_WRITE_BYTES`.\n* Introduce an experimental feature to dump out the blocks from block cache and insert them to the secondary cache to reduce the cache warmup time (e.g., used while migrating DB instance). More information are in `class CacheDumper` and `CacheDumpedLoader` at `rocksdb/utilities/cache_dump_load.h` Note that, this feature is subject to the potential change in the future, it is still experimental.\n* Introduced a new BlobDB configuration option `blob_garbage_collection_force_threshold`, which can be used to trigger compactions targeting the SST files which reference the oldest blob files when the ratio of garbage in those blob files meets or exceeds the specified threshold. This can reduce space amplification with skewed workloads where the affected SST files might not otherwise get picked up for compaction.\n* Added EXPERIMENTAL support for table file (SST) unique identifiers that are stable and universally unique, available with new function `GetUniqueIdFromTableProperties`. Only SST files from RocksDB >= 6.24 support unique IDs.\n* Added `GetMapProperty()` support for \"rocksdb.dbstats\" (`DB::Properties::kDBStats`). As a map property, it includes DB-level internal stats accumulated over the DB's lifetime, such as user write related stats and uptime.\n\n### Public API change\n* Made SystemClock extend the Customizable class and added a CreateFromString method.  Implementations need to be registered with the ObjectRegistry and to implement a Name() method in order to be created via this method.\n* Made SliceTransform extend the Customizable class and added a CreateFromString method.  Implementations need to be registered with the ObjectRegistry and to implement a Name() method in order to be created via this method.  The Capped and Prefixed transform classes return a short name (no length); use GetId for the fully qualified name.\n* Made FileChecksumGenFactory, SstPartitionerFactory, TablePropertiesCollectorFactory, and WalFilter extend the Customizable class and added a CreateFromString method.\n* Some fields of SstFileMetaData are deprecated for compatibility with new base class FileStorageInfo.\n* Add `file_temperature` to `IngestExternalFileArg` such that when ingesting SST files, we are able to indicate the temperature of the this batch of files.\n* If `DB::Close()` failed with a non aborted status, calling `DB::Close()` again will return the original status instead of Status::OK.\n* Add CacheTier to advanced_options.h to describe the cache tier we used. Add a `lowest_used_cache_tier` option to `DBOptions` (immutable) and pass it to BlockBasedTableReader. By default it is `CacheTier::kNonVolatileBlockTier`, which means, we always use both block cache (kVolatileTier) and secondary cache (kNonVolatileBlockTier). By set it to `CacheTier::kVolatileTier`, the DB will not use the secondary cache.\n* Even when options.max_compaction_bytes is hit, compaction output files are only cut when it aligns with grandparent files' boundaries. options.max_compaction_bytes could be slightly violated with the change, but the violation is no more than one target SST file size, which is usually much smaller.\n\n### Performance Improvements\n* Improved CPU efficiency of building block-based table (SST) files (#9039 and #9040).\n\n### Java API Changes\n* Add Java API bindings for new integrated BlobDB options\n* `keyMayExist()` supports ByteBuffer.\n* Fix multiget throwing Null Pointer Exception for num of keys > 70k (https://github.com/facebook/rocksdb/issues/8039).\n\n## 6.25.0 (2021-09-20)\n### Bug Fixes\n* Allow secondary instance to refresh iterator. Assign read seq after referencing SuperVersion.\n* Fixed a bug of secondary instance's last_sequence going backward, and reads on the secondary fail to see recent updates from the primary.\n* Fixed a bug that could lead to duplicate DB ID or DB session ID in POSIX environments without /proc/sys/kernel/random/uuid.\n* Fix a race in DumpStats() with column family destruction due to not taking a Ref on each entry while iterating the ColumnFamilySet.\n* Fix a race in item ref counting in LRUCache when promoting an item from the SecondaryCache.\n* Fix a race in BackupEngine if RateLimiter is reconfigured during concurrent Restore operations.\n* Fix a bug on POSIX in which failure to create a lock file (e.g. out of space) can prevent future LockFile attempts in the same process on the same file from succeeding.\n* Fix a bug that backup_rate_limiter and restore_rate_limiter in BackupEngine could not limit read rates.\n* Fix the implementation of `prepopulate_block_cache = kFlushOnly` to only apply to flushes rather than to all generated files.\n* Fix WAL log data corruption when using DBOptions.manual_wal_flush(true) and WriteOptions.sync(true) together. The sync WAL should work with locked log_write_mutex_.\n* Add checks for validity of the IO uring completion queue entries, and fail the BlockBasedTableReader MultiGet sub-batch if there's an invalid completion\n* Add an interface RocksDbIOUringEnable() that, if defined by the user, will allow them to enable/disable the use of IO uring by RocksDB\n* Fix the bug that when direct I/O is used and MultiRead() returns a short result, RandomAccessFileReader::MultiRead() still returns full size buffer, with returned short value together with some data in original buffer. This bug is unlikely cause incorrect results, because (1) since FileSystem layer is expected to retry on short result, returning short results is only possible when asking more bytes in the end of the file, which RocksDB doesn't do when using MultiRead(); (2) checksum is unlikely to match.\n\n### New Features\n* RemoteCompaction's interface now includes `db_name`, `db_id`, `session_id`, which could help the user uniquely identify compaction job between db instances and sessions.\n* Added a ticker statistic, \"rocksdb.verify_checksum.read.bytes\", reporting how many bytes were read from file to serve `VerifyChecksum()` and `VerifyFileChecksums()` queries.\n* Added ticker statistics, \"rocksdb.backup.read.bytes\" and \"rocksdb.backup.write.bytes\", reporting how many bytes were read and written during backup.\n* Added properties for BlobDB: `rocksdb.num-blob-files`, `rocksdb.blob-stats`, `rocksdb.total-blob-file-size`, and `rocksdb.live-blob-file-size`. The existing property `rocksdb.estimate_live-data-size` was also extended to include live bytes residing in blob files.\n* Added two new RateLimiter IOPriorities: `Env::IO_USER`,`Env::IO_MID`. `Env::IO_USER` will have superior priority over all other RateLimiter IOPriorities without being subject to fair scheduling constraint.\n* `SstFileWriter` now supports `Put`s and `Delete`s with user-defined timestamps. Note that the ingestion logic itself is not timestamp-aware yet.\n* Allow a single write batch to include keys from multiple column families whose timestamps' formats can differ. For example, some column families may disable timestamp, while others enable timestamp.\n* Add compaction priority information in RemoteCompaction, which can be used to schedule high priority job first.\n* Added new callback APIs `OnBlobFileCreationStarted`,`OnBlobFileCreated`and `OnBlobFileDeleted` in `EventListener` class of listener.h. It notifies listeners during creation/deletion of individual blob files in Integrated BlobDB. It also log blob file creation finished event and deletion event in LOG file.\n* Batch blob read requests for `DB::MultiGet` using `MultiRead`.\n* Add support for fallback to local compaction, the user can return `CompactionServiceJobStatus::kUseLocal` to instruct RocksDB to run the compaction locally instead of waiting for the remote compaction result.\n* Add built-in rate limiter's implementation of `RateLimiter::GetTotalPendingRequest(int64_t* total_pending_requests, const Env::IOPriority pri)` for the total number of requests that are pending for bytes in the rate limiter.\n* Charge memory usage during data buffering, from which training samples are gathered for dictionary compression, to block cache. Unbuffering data can now be triggered if the block cache becomes full and `strict_capacity_limit=true` for the block cache, in addition to existing conditions that can trigger unbuffering.\n\n### Public API change\n* Remove obsolete implementation details FullKey and ParseFullKey from public API\n* Change `SstFileMetaData::size` from `size_t` to `uint64_t`.\n* Made Statistics extend the Customizable class and added a CreateFromString method.  Implementations of Statistics need to be registered with the ObjectRegistry and to implement a Name() method in order to be created via this method.\n* Extended `FlushJobInfo` and `CompactionJobInfo` in listener.h to provide information about the blob files generated by a flush/compaction and garbage collected during compaction in Integrated BlobDB. Added struct members `blob_file_addition_infos` and `blob_file_garbage_infos` that contain this information.\n* Extended parameter `output_file_names` of `CompactFiles` API to also include paths of the blob files generated by the compaction in Integrated BlobDB.\n* Most `BackupEngine` functions now return `IOStatus` instead of `Status`. Most existing code should be compatible with this change but some calls might need to be updated.\n* Add a new field `level_at_creation` in `TablePropertiesCollectorFactory::Context` to capture the level at creating the SST file (i.e, table), of which the properties are being collected.\n\n### Miscellaneous\n* Add a paranoid check where in case FileSystem layer doesn't fill the buffer but returns succeed, checksum is unlikely to match even if buffer contains a previous block. The byte modified is not useful anyway, so it isn't expected to change any behavior when FileSystem is satisfying its contract.\n\n## 6.24.0 (2021-08-20)\n### Bug Fixes\n* If the primary's CURRENT file is missing or inaccessible, the secondary instance should not hang repeatedly trying to switch to a new MANIFEST. It should instead return the error code encountered while accessing the file.\n* Restoring backups with BackupEngine is now a logically atomic operation, so that if a restore operation is interrupted, DB::Open on it will fail. Using BackupEngineOptions::sync (default) ensures atomicity even in case of power loss or OS crash.\n* Fixed a race related to the destruction of `ColumnFamilyData` objects. The earlier logic unlocked the DB mutex before destroying the thread-local `SuperVersion` pointers, which could result in a process crash if another thread managed to get a reference to the `ColumnFamilyData` object.\n* Removed a call to `RenameFile()` on a non-existent info log file (\"LOG\") when opening a new DB. Such a call was guaranteed to fail though did not impact applications since we swallowed the error. Now we also stopped swallowing errors in renaming \"LOG\" file.\n* Fixed an issue where `OnFlushCompleted` was not called for atomic flush.\n* Fixed a bug affecting the batched `MultiGet` API when used with keys spanning multiple column families and `sorted_input == false`.\n* Fixed a potential incorrect result in opt mode and assertion failures caused by releasing snapshot(s) during compaction.\n* Fixed passing of BlobFileCompletionCallback to Compaction job and Atomic flush job which was default paramter (nullptr). BlobFileCompletitionCallback is internal callback that manages addition of blob files to SSTFileManager.\n* Fixed MultiGet not updating the block_read_count and block_read_byte PerfContext counters.\n\n### New Features\n* Made the EventListener extend the Customizable class.\n* EventListeners that have a non-empty Name() and that are registered with the ObjectRegistry can now be serialized to/from the OPTIONS file.\n* Insert warm blocks (data blocks, uncompressed dict blocks, index and filter blocks) in Block cache during flush under option BlockBasedTableOptions.prepopulate_block_cache. Previously it was enabled for only data blocks.\n* BlockBasedTableOptions.prepopulate_block_cache can be dynamically configured using DB::SetOptions.\n* Add CompactionOptionsFIFO.age_for_warm, which allows RocksDB to move old files to warm tier in FIFO compactions. Note that file temperature is still an experimental feature.\n* Add a comment to suggest btrfs user to disable file preallocation by setting `options.allow_fallocate=false`.\n* Fast forward option in Trace replay changed to double type to allow replaying at a lower speed, by settings the value between 0 and 1. This option can be set via `ReplayOptions` in `Replayer::Replay()`, or via `--trace_replay_fast_forward` in db_bench.\n* Add property `LiveSstFilesSizeAtTemperature` to retrieve sst file size at different temperature.\n* Added a stat rocksdb.secondary.cache.hits.\n* Added a PerfContext counter secondary_cache_hit_count.\n* The integrated BlobDB implementation now supports the tickers `BLOB_DB_BLOB_FILE_BYTES_READ`, `BLOB_DB_GC_NUM_KEYS_RELOCATED`, and `BLOB_DB_GC_BYTES_RELOCATED`, as well as the histograms `BLOB_DB_COMPRESSION_MICROS` and `BLOB_DB_DECOMPRESSION_MICROS`.\n* Added hybrid configuration of Ribbon filter and Bloom filter where some LSM levels use Ribbon for memory space efficiency and some use Bloom for speed. See NewRibbonFilterPolicy. This also changes the default behavior of NewRibbonFilterPolicy to use Bloom for flushes under Leveled and Universal compaction and Ribbon otherwise. The C API function `rocksdb_filterpolicy_create_ribbon` is unchanged but adds new `rocksdb_filterpolicy_create_ribbon_hybrid`.\n\n### Public API change\n* Added APIs to decode and replay trace file via Replayer class. Added `DB::NewDefaultReplayer()` to create a default Replayer instance. Added `TraceReader::Reset()` to restart reading a trace file. Created trace_record.h, trace_record_result.h and utilities/replayer.h files to access the decoded Trace records, replay them, and query the actual operation results.\n* Added Configurable::GetOptionsMap to the public API for use in creating new Customizable classes.\n* Generalized bits_per_key parameters in C API from int to double for greater configurability. Although this is a compatible change for existing C source code, anything depending on C API signatures, such as foreign function interfaces, will need to be updated.\n\n### Performance Improvements\n* Try to avoid updating DBOptions if `SetDBOptions()` does not change any option value.\n\n### Behavior Changes\n* `StringAppendOperator` additionally accepts a string as the delimiter.\n* BackupEngineOptions::sync (default true) now applies to restoring backups in addition to creating backups. This could slow down restores, but ensures they are fully persisted before returning OK. (Consider increasing max_background_operations to improve performance.)\n\n## 6.23.0 (2021-07-16)\n### Behavior Changes\n* Obsolete keys in the bottommost level that were preserved for a snapshot will now be cleaned upon snapshot release in all cases. This form of compaction (snapshot release triggered compaction) previously had an artificial limitation that multiple tombstones needed to be present.\n### Bug Fixes\n* Blob file checksums are now printed in hexadecimal format when using the `manifest_dump` `ldb` command.\n* `GetLiveFilesMetaData()` now populates the `temperature`, `oldest_ancester_time`, and `file_creation_time` fields of its `LiveFileMetaData` results when the information is available. Previously these fields always contained zero indicating unknown.\n* Fix mismatches of OnCompaction{Begin,Completed} in case of DisableManualCompaction().\n* Fix continuous logging of an existing background error on every user write\n* Fix a bug that `Get()` return Status::OK() and an empty value for non-existent key when `read_options.read_tier = kBlockCacheTier`.\n* Fix a bug that stat in `get_context` didn't accumulate to statistics when query is failed.\n* Fixed handling of DBOptions::wal_dir with LoadLatestOptions() or ldb --try_load_options on a copied or moved DB. Previously, when the WAL directory is same as DB directory (default), a copied or moved DB would reference the old path of the DB as the WAL directory, potentially corrupting both copies. Under this change, the wal_dir from DB::GetOptions() or LoadLatestOptions() may now be empty, indicating that the current DB directory is used for WALs. This is also a subtle API change.\n\n### New Features\n* ldb has a new feature, `list_live_files_metadata`, that shows the live SST files, as well as their LSM storage level and the column family they belong to.\n* The new BlobDB implementation now tracks the amount of garbage in each blob file in the MANIFEST.\n* Integrated BlobDB now supports Merge with base values (Put/Delete etc.).\n* RemoteCompaction supports sub-compaction, the job_id in the user interface is changed from `int` to `uint64_t` to support sub-compaction id.\n* Expose statistics option in RemoteCompaction worker.\n\n### Public API change\n* Added APIs to the Customizable class to allow developers to create their own Customizable classes.  Created the utilities/customizable_util.h file to contain helper methods for developing new Customizable classes.\n* Change signature of SecondaryCache::Name().  Make SecondaryCache customizable and add SecondaryCache::CreateFromString method.\n\n## 6.22.0 (2021-06-18)\n### Behavior Changes\n* Added two additional tickers, MEMTABLE_PAYLOAD_BYTES_AT_FLUSH and MEMTABLE_GARBAGE_BYTES_AT_FLUSH. These stats can be used to estimate the ratio of \"garbage\" (outdated) bytes in the memtable that are discarded at flush time.\n* Added API comments clarifying safe usage of Disable/EnableManualCompaction and EventListener callbacks for compaction.\n### Bug Fixes\n* fs_posix.cc GetFreeSpace() always report disk space available to root even when running as non-root.  Linux defaults often have disk mounts with 5 to 10 percent of total space reserved only for root.  Out of space could result for non-root users.\n* Subcompactions are now disabled when user-defined timestamps are used, since the subcompaction boundary picking logic is currently not timestamp-aware, which could lead to incorrect results when different subcompactions process keys that only differ by timestamp.\n* Fix an issue that `DeleteFilesInRange()` may cause ongoing compaction reports corruption exception, or ASSERT for debug build. There's no actual data loss or corruption that we find.\n* Fixed confusingly duplicated output in LOG for periodic stats (\"DUMPING STATS\"), including \"Compaction Stats\" and \"File Read Latency Histogram By Level\".\n* Fixed performance bugs in background gathering of block cache entry statistics, that could consume a lot of CPU when there are many column families with a shared block cache.\n\n### New Features\n* Marked the Ribbon filter and optimize_filters_for_memory features as production-ready, each enabling memory savings for Bloom-like filters. Use `NewRibbonFilterPolicy` in place of `NewBloomFilterPolicy` to use Ribbon filters instead of Bloom, or `ribbonfilter` in place of `bloomfilter` in configuration string.\n* Allow `DBWithTTL` to use `DeleteRange` api just like other DBs. `DeleteRangeCF()` which executes `WriteBatchInternal::DeleteRange()` has been added to the handler in `DBWithTTLImpl::Write()` to implement it.\n* Add BlockBasedTableOptions.prepopulate_block_cache.  If enabled, it prepopulate warm/hot data blocks which are already in memory into block cache at the time of flush. On a flush, the data block that is in memory (in memtables) get flushed to the device. If using Direct IO, additional IO is incurred to read this data back into memory again, which is avoided by enabling this option and it also helps with Distributed FileSystem. More details in include/rocksdb/table.h.\n* Added a `cancel` field to `CompactRangeOptions`, allowing individual in-process manual range compactions to be cancelled.\n\n### New Features\n* Added BlobMetaData to the ColumnFamilyMetaData to return information about blob files\n\n### Public API change\n* Added GetAllColumnFamilyMetaData API to retrieve the ColumnFamilyMetaData about all column families.\n\n## 6.21.0 (2021-05-21)\n### Bug Fixes\n* Fixed a bug in handling file rename error in distributed/network file systems when the server succeeds but client returns error. The bug can cause CURRENT file to point to non-existing MANIFEST file, thus DB cannot be opened.\n* Fixed a bug where ingested files were written with incorrect boundary key metadata. In rare cases this could have led to a level's files being wrongly ordered and queries for the boundary keys returning wrong results.\n* Fixed a data race between insertion into memtables and the retrieval of the DB properties `rocksdb.cur-size-active-mem-table`, `rocksdb.cur-size-all-mem-tables`, and `rocksdb.size-all-mem-tables`.\n* Fixed the false-positive alert when recovering from the WAL file. Avoid reporting \"SST file is ahead of WAL\" on a newly created empty column family, if the previous WAL file is corrupted.\n* Fixed a bug where `GetLiveFiles()` output included a non-existent file called \"OPTIONS-000000\". Backups and checkpoints, which use `GetLiveFiles()`, failed on DBs impacted by this bug. Read-write DBs were impacted when the latest OPTIONS file failed to write and `fail_if_options_file_error == false`. Read-only DBs were impacted when no OPTIONS files existed.\n* Handle return code by io_uring_submit_and_wait() and io_uring_wait_cqe().\n* In the IngestExternalFile() API, only try to sync the ingested file if the file is linked and the FileSystem/Env supports reopening a writable file.\n* Fixed a bug that `AdvancedColumnFamilyOptions.max_compaction_bytes` is under-calculated for manual compaction (`CompactRange()`). Manual compaction is split to multiple compactions if the compaction size exceed the `max_compaction_bytes`. The bug creates much larger compaction which size exceed the user setting. On the other hand, larger manual compaction size can increase the subcompaction parallelism, you can tune that by setting `max_compaction_bytes`.\n\n### Behavior Changes\n* Due to the fix of false-postive alert of \"SST file is ahead of WAL\", all the CFs with no SST file (CF empty) will bypass the consistency check. We fixed a false-positive, but introduced a very rare true-negative which will be triggered in the following conditions: A CF with some delete operations in the last a few queries which will result in an empty CF (those are flushed to SST file and a compaction triggered which combines this file and all other SST files and generates an empty CF, or there is another reason to write a manifest entry for this CF after a flush that generates no SST file from an empty CF). The deletion entries are logged in a WAL and this WAL was corrupted, while the CF's log number points to the next WAL (due to the flush). Therefore, the DB can only recover to the point without these trailing deletions and cause the inconsistent DB status.\n\n### New Features\n* Add new option allow_stall passed during instance creation of WriteBufferManager. When allow_stall is set, WriteBufferManager will stall all writers shared across multiple DBs and columns if memory usage goes beyond specified WriteBufferManager::buffer_size (soft limit). Stall will be cleared when memory is freed after flush and memory usage goes down below buffer_size.\n* Allow `CompactionFilter`s to apply in more table file creation scenarios such as flush and recovery. For compatibility, `CompactionFilter`s by default apply during compaction. Users can customize this behavior by overriding `CompactionFilterFactory::ShouldFilterTableFileCreation()`.\n* Added more fields to FilterBuildingContext with LSM details, for custom filter policies that vary behavior based on where they are in the LSM-tree.\n* Added DB::Properties::kBlockCacheEntryStats for querying statistics on what percentage of block cache is used by various kinds of blocks, etc. using DB::GetProperty and DB::GetMapProperty. The same information is now dumped to info LOG periodically according to `stats_dump_period_sec`.\n* Add an experimental Remote Compaction feature, which allows the user to run Compaction on a different host or process. The feature is still under development, currently only works on some basic use cases. The interface will be changed without backward/forward compatibility support.\n* RocksDB would validate total entries read in flush, and compare with counter inserted into it. If flush_verify_memtable_count = true (default), flush will fail. Otherwise, only log to info logs.\n* Add `TableProperties::num_filter_entries`, which can be used with `TableProperties::filter_size` to calculate the effective bits per filter entry (unique user key or prefix) for a table file.\n\n### Performance Improvements\n* BlockPrefetcher is used by iterators to prefetch data if they anticipate more data to be used in future. It is enabled implicitly by rocksdb. Added change to take in account read pattern if reads are sequential. This would disable prefetching for random reads in MultiGet and iterators as readahead_size is increased exponential doing large prefetches.\n\n### Public API change\n* Removed a parameter from TableFactory::NewTableBuilder, which should not be called by user code because TableBuilder is not a public API.\n* Removed unused structure `CompactionFilterContext`.\n* The `skip_filters` parameter to SstFileWriter is now considered deprecated. Use `BlockBasedTableOptions::filter_policy` to control generation of filters.\n* ClockCache is known to have bugs that could lead to crash or corruption, so should not be used until fixed. Use NewLRUCache instead.\n* Added a new pure virtual function `ApplyToAllEntries` to `Cache`, to replace `ApplyToAllCacheEntries`. Custom `Cache` implementations must add an implementation. Because this function is for gathering statistics, an empty implementation could be acceptable for some applications.\n* Added the ObjectRegistry to the ConfigOptions class.  This registry instance will be used to find any customizable loadable objects during initialization.\n* Expanded the ObjectRegistry functionality to allow nested ObjectRegistry instances.  Added methods to register a set of functions with the registry/library as a group.\n* Deprecated backupable_db.h and BackupableDBOptions in favor of new versions with appropriate names: backup_engine.h and BackupEngineOptions. Old API compatibility is preserved.\n\n### Default Option Change\n* When options.arena_block_size <= 0 (default value 0), still use writer_buffer_size / 8 but cap to 1MB. Too large alloation size might not be friendly to allocator and might cause performance issues in extreme cases.\n\n### Build\n* By default, try to build with liburing. For make, if ROCKSDB_USE_IO_URING is not set, treat as enable, which means RocksDB will try to build with liburing. Users can disable it with ROCKSDB_USE_IO_URING=0. For cmake, add WITH_LIBURING to control it, with default on.\n\n## 6.20.0 (2021-04-16)\n### Behavior Changes\n* `ColumnFamilyOptions::sample_for_compression` now takes effect for creation of all block-based tables. Previously it only took effect for block-based tables created by flush.\n* `CompactFiles()` can no longer compact files from lower level to up level, which has the risk to corrupt DB (details: #8063). The validation is also added to all compactions.\n* Fixed some cases in which DB::OpenForReadOnly() could write to the filesystem. If you want a Logger with a read-only DB, you must now set DBOptions::info_log yourself, such as using CreateLoggerFromOptions().\n* get_iostats_context() will never return nullptr. If thread-local support is not available, and user does not opt-out iostats context, then compilation will fail. The same applies to perf context as well.\n* Added support for WriteBatchWithIndex::NewIteratorWithBase when overwrite_key=false.  Previously, this combination was not supported and would assert or return nullptr.\n* Improve the behavior of WriteBatchWithIndex for Merge operations.  Now more operations may be stored in order to return the correct merged result.\n\n### Bug Fixes\n* Use thread-safe `strerror_r()` to get error messages.\n* Fixed a potential hang in shutdown for a DB whose `Env` has high-pri thread pool disabled (`Env::GetBackgroundThreads(Env::Priority::HIGH) == 0`)\n* Made BackupEngine thread-safe and added documentation comments to clarify what is safe for multiple BackupEngine objects accessing the same backup directory.\n* Fixed crash (divide by zero) when compression dictionary is applied to a file containing only range tombstones.\n* Fixed a backward iteration bug with partitioned filter enabled: not including the prefix of the last key of the previous filter partition in current filter partition can cause wrong iteration result.\n* Fixed a bug that allowed `DBOptions::max_open_files` to be set with a non-negative integer with `ColumnFamilyOptions::compaction_style = kCompactionStyleFIFO`.\n\n### Performance Improvements\n* On ARM platform, use `yield` instead of `wfe` to relax cpu to gain better performance.\n\n### Public API change\n* Added `TableProperties::slow_compression_estimated_data_size` and `TableProperties::fast_compression_estimated_data_size`. When `ColumnFamilyOptions::sample_for_compression > 0`, they estimate what `TableProperties::data_size` would have been if the \"fast\" or \"slow\" (see `ColumnFamilyOptions::sample_for_compression` API doc for definitions) compression had been used instead.\n* Update DB::StartIOTrace and remove Env object from the arguments as its redundant and DB already has Env object that is passed down to IOTracer::StartIOTrace\n* Added `FlushReason::kWalFull`, which is reported when a memtable is flushed due to the WAL reaching its size limit; those flushes were previously reported as `FlushReason::kWriteBufferManager`. Also, changed the reason for flushes triggered by the write buffer manager to `FlushReason::kWriteBufferManager`; they were previously reported as `FlushReason::kWriteBufferFull`.\n* Extend file_checksum_dump ldb command and DB::GetLiveFilesChecksumInfo API for IntegratedBlobDB and get checksum of blob files along with SST files.\n\n### New Features\n* Added the ability to open BackupEngine backups as read-only DBs, using BackupInfo::name_for_open and env_for_open provided by BackupEngine::GetBackupInfo() with include_file_details=true.\n* Added BackupEngine support for integrated BlobDB, with blob files shared between backups when table files are shared. Because of current limitations, blob files always use the kLegacyCrc32cAndFileSize naming scheme, and incremental backups must read and checksum all blob files in a DB, even for files that are already backed up.\n* Added an optional output parameter to BackupEngine::CreateNewBackup(WithMetadata) to return the BackupID of the new backup.\n* Added BackupEngine::GetBackupInfo / GetLatestBackupInfo for querying individual backups.\n* Made the Ribbon filter a long-term supported feature in terms of the SST schema(compatible with version >= 6.15.0) though the API for enabling it is expected to change.\n\n## 6.19.0 (2021-03-21)\n### Bug Fixes\n* Fixed the truncation error found in APIs/tools when dumping block-based SST files in a human-readable format. After fix, the block-based table can be fully dumped as a readable file.\n* When hitting a write slowdown condition, no write delay (previously 1 millisecond) is imposed until `delayed_write_rate` is actually exceeded, with an initial burst allowance of 1 millisecond worth of bytes. Also, beyond the initial burst allowance, `delayed_write_rate` is now more strictly enforced, especially with multiple column families.\n\n### Public API change\n* Changed default `BackupableDBOptions::share_files_with_checksum` to `true` and deprecated `false` because of potential for data loss. Note that accepting this change in behavior can temporarily increase backup data usage because files are not shared between backups using the two different settings. Also removed obsolete option kFlagMatchInterimNaming.\n* Add a new option BlockBasedTableOptions::max_auto_readahead_size. RocksDB does auto-readahead for iterators on noticing more than two reads for a table file if user doesn't provide readahead_size. The readahead starts at 8KB and doubles on every additional read upto max_auto_readahead_size and now max_auto_readahead_size can be configured dynamically as well. Found that 256 KB readahead size provides the best performance, based on experiments, for auto readahead. Experiment data is in PR #3282. If value is set 0 then no automatic prefetching will be done by rocksdb. Also changing the value will only affect files opened after the change.\n* Add suppport to extend DB::VerifyFileChecksums API to also verify blob files checksum.\n* When using the new BlobDB, the amount of data written by flushes/compactions is now broken down into table files and blob files in the compaction statistics; namely, Write(GB) denotes the amount of data written to table files, while Wblob(GB) means the amount of data written to blob files.\n* New default BlockBasedTableOptions::format_version=5 to enable new Bloom filter implementation by default, compatible with RocksDB versions >= 6.6.0.\n* Add new SetBufferSize API to WriteBufferManager to allow dynamic management of memory allotted to all write buffers.  This allows user code to adjust memory monitoring provided by WriteBufferManager as process memory needs change datasets grow and shrink.\n* Clarified the required semantics of Read() functions in FileSystem and Env APIs. Please ensure any custom implementations are compliant.\n* For the new integrated BlobDB implementation, compaction statistics now include the amount of data read from blob files during compaction (due to garbage collection or compaction filters). Write amplification metrics have also been extended to account for data read from blob files.\n* Add EqualWithoutTimestamp() to Comparator.\n* Extend support to track blob files in SSTFileManager whenever a blob file is created/deleted. Blob files will be scheduled to delete via SSTFileManager and SStFileManager will now take blob files in account while calculating size and space limits along with SST files.\n* Add new Append and PositionedAppend API with checksum handoff to legacy Env.\n\n### New Features\n* Support compaction filters for the new implementation of BlobDB. Add `FilterBlobByKey()` to `CompactionFilter`. Subclasses can override this method so that compaction filters can determine whether the actual blob value has to be read during compaction. Use a new `kUndetermined` in `CompactionFilter::Decision` to indicated that further action is necessary for compaction filter to make a decision.\n* Add support to extend retrieval of checksums for blob files from the MANIFEST when checkpointing. During backup, rocksdb can detect corruption in blob files  during file copies.\n* Add new options for db_bench --benchmarks: flush, waitforcompaction, compact0, compact1.\n* Add an option to BackupEngine::GetBackupInfo to include the name and size of each backed-up file. Especially in the presence of file sharing among backups, this offers detailed insight into backup space usage.\n* Enable backward iteration on keys with user-defined timestamps.\n* Add statistics and info log for error handler: counters for bg error, bg io error, bg retryable io error, auto resume count, auto resume total retry number, and auto resume sucess; Histogram for auto resume retry count in each recovery call. Note that, each auto resume attempt will have one or multiple retries.\n\n### Behavior Changes\n* During flush, only WAL sync retryable IO error is mapped to hard error, which will stall the writes. When WAL is used but only SST file write has retryable IO error, it will be mapped to soft error and write will not be affected.\n\n## 6.18.0 (2021-02-19)\n### Behavior Changes\n* When retryable IO error occurs during compaction, it is mapped to soft error and set the BG error. However, auto resume is not called to clean the soft error since compaction will reschedule by itself. In this change, When retryable IO error occurs during compaction, BG error is not set. User will be informed the error via EventHelper.\n* Introduce a new trace file format for query tracing and replay and trace file version is bump up to 0.2. A payload map is added as the first portion of the payload. We will not have backward compatible issues when adding new entries to trace records. Added the iterator_upper_bound and iterator_lower_bound in Seek and SeekForPrev tracing function. Added them as the new payload member for iterator tracing.\n\n### New Features\n* Add support for key-value integrity protection in live updates from the user buffers provided to `WriteBatch` through the write to RocksDB's in-memory update buffer (memtable). This is intended to detect some cases of in-memory data corruption, due to either software or hardware errors. Users can enable protection by constructing their `WriteBatch` with `protection_bytes_per_key == 8`.\n* Add support for updating `full_history_ts_low` option in manual compaction, which is for old timestamp data GC.\n* Add a mechanism for using Makefile to build external plugin code into the RocksDB libraries/binaries. This intends to simplify compatibility and distribution for plugins (e.g., special-purpose `FileSystem`s) whose source code resides outside the RocksDB repo. See \"plugin/README.md\" for developer details, and \"PLUGINS.md\" for a listing of available plugins.\n* Added memory pre-fetching for experimental Ribbon filter, which especially optimizes performance with batched MultiGet.\n* A new, experimental version of BlobDB (key-value separation) is now available. The new implementation is integrated into the RocksDB core, i.e. it is accessible via the usual `rocksdb::DB` API, as opposed to the separate `rocksdb::blob_db::BlobDB` interface used by the earlier version, and can be configured on a per-column family basis using the configuration options `enable_blob_files`, `min_blob_size`, `blob_file_size`, `blob_compression_type`, `enable_blob_garbage_collection`, and `blob_garbage_collection_age_cutoff`. It extends RocksDB's consistency guarantees to blobs, and offers more features and better performance. Note that some features, most notably `Merge`, compaction filters, and backup/restore are not yet supported, and there is no support for migrating a database created by the old implementation.\n\n### Bug Fixes\n* Since 6.15.0, `TransactionDB` returns error `Status`es from calls to `DeleteRange()` and calls to `Write()` where the `WriteBatch` contains a range deletion. Previously such operations may have succeeded while not providing the expected transactional guarantees. There are certain cases where range deletion can still be used on such DBs; see the API doc on `TransactionDB::DeleteRange()` for details.\n* `OptimisticTransactionDB` now returns error `Status`es from calls to `DeleteRange()` and calls to `Write()` where the `WriteBatch` contains a range deletion. Previously such operations may have succeeded while not providing the expected transactional guarantees.\n* Fix `WRITE_PREPARED`, `WRITE_UNPREPARED` TransactionDB `MultiGet()` may return uncommitted data with snapshot.\n* In DB::OpenForReadOnly, if any error happens while checking Manifest file path, it was overridden by Status::NotFound. It has been fixed and now actual error is returned.\n\n### Public API Change\n* Added a \"only_mutable_options\" flag to the ConfigOptions.  When this flag is \"true\", the Configurable functions and convenience methods (such as GetDBOptionsFromString) will only deal with options that are marked as mutable.  When this flag is true, only options marked as mutable can be configured (a Status::InvalidArgument will be returned) and options not marked as mutable will not be returned or compared.  The default is \"false\", meaning to compare all options.\n* Add new Append and PositionedAppend APIs to FileSystem to bring the data verification information (data checksum information) from upper layer (e.g., WritableFileWriter) to the storage layer. In this way, the customized FileSystem is able to verify the correctness of data being written to the storage on time. Add checksum_handoff_file_types to DBOptions. User can use this option to control which file types (Currently supported file tyes: kWALFile, kTableFile, kDescriptorFile.) should use the new Append and PositionedAppend APIs to handoff the verification information. Currently, RocksDB only use crc32c to calculate the checksum for write handoff.\n* Add an option, `CompressionOptions::max_dict_buffer_bytes`, to limit the in-memory buffering for selecting samples for generating/training a dictionary. The limit is currently loosely adhered to.\n\n\n## 6.17.0 (2021-01-15)\n### Behavior Changes\n* When verifying full file checksum with `DB::VerifyFileChecksums()`, we now fail with `Status::InvalidArgument` if the name of the checksum generator used for verification does not match the name of the checksum generator used for protecting the file when it was created.\n* Since RocksDB does not continue write the same file if a file write fails for any reason, the file scope write IO error is treated the same as retryable IO error. More information about error handling of file scope IO error is included in `ErrorHandler::SetBGError`.\n\n### Bug Fixes\n* Version older than 6.15 cannot decode VersionEdits `WalAddition` and `WalDeletion`, fixed this by changing the encoded format of them to be ignorable by older versions.\n* Fix a race condition between DB startups and shutdowns in managing the periodic background worker threads. One effect of this race condition could be the process being terminated.\n\n### Public API Change\n* Add a public API WriteBufferManager::dummy_entries_in_cache_usage() which reports the size of dummy entries stored in cache (passed to WriteBufferManager). Dummy entries are used to account for DataBlocks.\n* Add a SystemClock class that contains the time-related methods from Env.  The original methods in Env may be deprecated in a future release.  This class will allow easier testing, development, and expansion of time-related features.\n* Add a public API GetRocksBuildProperties and GetRocksBuildInfoAsString to get properties about the current build.  These properties may include settings related to the GIT settings (branch, timestamp).  This change also sets the \"build date\" based on the GIT properties, rather than the actual build time, thereby enabling more reproducible builds.\n\n## 6.16.0 (2020-12-18)\n### Behavior Changes\n* Attempting to write a merge operand without explicitly configuring `merge_operator` now fails immediately, causing the DB to enter read-only mode. Previously, failure was deferred until the `merge_operator` was needed by a user read or a background operation.\n\n### Bug Fixes\n* Truncated WALs ending in incomplete records can no longer produce gaps in the recovered data when `WALRecoveryMode::kPointInTimeRecovery` is used. Gaps are still possible when WALs are truncated exactly on record boundaries; for complete protection, users should enable `track_and_verify_wals_in_manifest`.\n* Fix a bug where compressed blocks read by MultiGet are not inserted into the compressed block cache when use_direct_reads = true.\n* Fixed the issue of full scanning on obsolete files when there are too many outstanding compactions with ConcurrentTaskLimiter enabled.\n* Fixed the logic of populating native data structure for `read_amp_bytes_per_bit` during OPTIONS file parsing on big-endian architecture. Without this fix, original code introduced in PR7659, when running on big-endian machine, can mistakenly store read_amp_bytes_per_bit (an uint32) in little endian format. Future access to `read_amp_bytes_per_bit` will give wrong values. Little endian architecture is not affected.\n* Fixed prefix extractor with timestamp issues.\n* Fixed a bug in atomic flush: in two-phase commit mode, the minimum WAL log number to keep is incorrect.\n* Fixed a bug related to checkpoint in PR7789: if there are multiple column families, and the checkpoint is not opened as read only, then in rare cases, data loss may happen in the checkpoint. Since backup engine relies on checkpoint, it may also be affected.\n* When ldb --try_load_options is used with the --column_family option, the ColumnFamilyOptions for the specified column family was not loaded from the OPTIONS file. Fix it so its loaded from OPTIONS and then overridden with command line overrides.\n\n### New Features\n* User defined timestamp feature supports `CompactRange` and `GetApproximateSizes`.\n* Support getting aggregated table properties (kAggregatedTableProperties and kAggregatedTablePropertiesAtLevel) with DB::GetMapProperty, for easier access to the data in a structured format.\n* Experimental option BlockBasedTableOptions::optimize_filters_for_memory now works with experimental Ribbon filter (as well as Bloom filter).\n\n### Public API Change\n* Deprecated public but rarely-used FilterBitsBuilder::CalculateNumEntry, which is replaced with ApproximateNumEntries taking a size_t parameter and returning size_t.\n* To improve portability the functions `Env::GetChildren` and `Env::GetChildrenFileAttributes` will no longer return entries for the special directories `.` or `..`.\n* Added a new option `track_and_verify_wals_in_manifest`. If `true`, the log numbers and sizes of the synced WALs are tracked in MANIFEST, then during DB recovery, if a synced WAL is missing from disk, or the WAL's size does not match the recorded size in MANIFEST, an error will be reported and the recovery will be aborted. Note that this option does not work with secondary instance.\n* `rocksdb_approximate_sizes` and `rocksdb_approximate_sizes_cf` in the C API now requires an error pointer (`char** errptr`) for receiving any error.\n* All overloads of DB::GetApproximateSizes now return Status, so that any failure to obtain the sizes is indicated to the caller.\n\n## 6.15.0 (2020-11-13)\n### Bug Fixes\n* Fixed a bug in the following combination of features: indexes with user keys (`format_version >= 3`), indexes are partitioned (`index_type == kTwoLevelIndexSearch`), and some index partitions are pinned in memory (`BlockBasedTableOptions::pin_l0_filter_and_index_blocks_in_cache`). The bug could cause keys to be truncated when read from the index leading to wrong read results or other unexpected behavior.\n* Fixed a bug when indexes are partitioned (`index_type == kTwoLevelIndexSearch`), some index partitions are pinned in memory (`BlockBasedTableOptions::pin_l0_filter_and_index_blocks_in_cache`), and partitions reads could be mixed between block cache and directly from the file (e.g., with `enable_index_compression == 1` and `mmap_read == 1`, partitions that were stored uncompressed due to poor compression ratio would be read directly from the file via mmap, while partitions that were stored compressed would be read from block cache). The bug could cause index partitions to be mistakenly considered empty during reads leading to wrong read results.\n* Since 6.12, memtable lookup should report unrecognized value_type as corruption (#7121).\n* Since 6.14, fix false positive flush/compaction `Status::Corruption` failure when `paranoid_file_checks == true` and range tombstones were written to the compaction output files.\n* Since 6.14, fix a bug that could cause a stalled write to crash with mixed of slowdown and no_slowdown writes (`WriteOptions.no_slowdown=true`).\n* Fixed a bug which causes hang in closing DB when refit level is set in opt build. It was because ContinueBackgroundWork() was called in assert statement which is a no op. It was introduced in 6.14.\n* Fixed a bug which causes Get() to return incorrect result when a key's merge operand is applied twice. This can occur if the thread performing Get() runs concurrently with a background flush thread and another thread writing to the MANIFEST file (PR6069).\n* Reverted a behavior change silently introduced in 6.14.2, in which the effects of the `ignore_unknown_options` flag (used in option parsing/loading functions) changed.\n* Reverted a behavior change silently introduced in 6.14, in which options parsing/loading functions began returning `NotFound` instead of `InvalidArgument` for option names not available in the present version.\n* Fixed MultiGet bugs it doesn't return valid data with user defined timestamp.\n* Fixed a potential bug caused by evaluating `TableBuilder::NeedCompact()` before `TableBuilder::Finish()` in compaction job. For example, the `NeedCompact()` method of `CompactOnDeletionCollector` returned by built-in `CompactOnDeletionCollectorFactory` requires `BlockBasedTable::Finish()` to return the correct result. The bug can cause a compaction-generated file not to be marked for future compaction based on deletion ratio.\n* Fixed a seek issue with prefix extractor and timestamp.\n* Fixed a bug of encoding and parsing BlockBasedTableOptions::read_amp_bytes_per_bit as a 64-bit integer.\n* Fixed a bug of a recovery corner case, details in PR7621.\n\n### Public API Change\n* Deprecate `BlockBasedTableOptions::pin_l0_filter_and_index_blocks_in_cache` and `BlockBasedTableOptions::pin_top_level_index_and_filter`. These options still take effect until users migrate to the replacement APIs in `BlockBasedTableOptions::metadata_cache_options`. Migration guidance can be found in the API comments on the deprecated options.\n* Add new API `DB::VerifyFileChecksums` to verify SST file checksum with corresponding entries in the MANIFEST if present. Current implementation requires scanning and recomputing file checksums.\n\n### Behavior Changes\n* The dictionary compression settings specified in `ColumnFamilyOptions::compression_opts` now additionally affect files generated by flush and compaction to non-bottommost level. Previously those settings at most affected files generated by compaction to bottommost level, depending on whether `ColumnFamilyOptions::bottommost_compression_opts` overrode them. Users who relied on dictionary compression settings in `ColumnFamilyOptions::compression_opts` affecting only the bottommost level can keep the behavior by moving their dictionary settings to `ColumnFamilyOptions::bottommost_compression_opts` and setting its `enabled` flag.\n* When the `enabled` flag is set in `ColumnFamilyOptions::bottommost_compression_opts`, those compression options now take effect regardless of the value in `ColumnFamilyOptions::bottommost_compression`. Previously, those compression options only took effect when `ColumnFamilyOptions::bottommost_compression != kDisableCompressionOption`. Now, they additionally take effect when `ColumnFamilyOptions::bottommost_compression == kDisableCompressionOption` (such a setting causes bottommost compression type to fall back to `ColumnFamilyOptions::compression_per_level` if configured, and otherwise fall back to `ColumnFamilyOptions::compression`).\n\n### New Features\n* An EXPERIMENTAL new Bloom alternative that saves about 30% space compared to Bloom filters, with about 3-4x construction time and similar query times is available using NewExperimentalRibbonFilterPolicy.\n\n## 6.14 (2020-10-09)\n### Bug fixes\n* Fixed a bug after a `CompactRange()` with `CompactRangeOptions::change_level` set fails due to a conflict in the level change step, which caused all subsequent calls to `CompactRange()` with `CompactRangeOptions::change_level` set to incorrectly fail with a `Status::NotSupported(\"another thread is refitting\")` error.\n* Fixed a bug that the bottom most level compaction could still be a trivial move even if `BottommostLevelCompaction.kForce` or `kForceOptimized` is set.\n\n### Public API Change\n* The methods to create and manage EncrypedEnv have been changed.  The EncryptionProvider is now passed to NewEncryptedEnv as a shared pointer, rather than a raw pointer.  Comparably, the CTREncryptedProvider now takes a shared pointer, rather than a reference, to a BlockCipher.  CreateFromString methods have been added to BlockCipher and EncryptionProvider to provide a single API by which different ciphers and providers can be created, respectively.\n* The internal classes (CTREncryptionProvider, ROT13BlockCipher, CTRCipherStream) associated with the EncryptedEnv have been moved out of the public API.  To create a CTREncryptionProvider, one can either use EncryptionProvider::NewCTRProvider, or EncryptionProvider::CreateFromString(\"CTR\").  To create a new ROT13BlockCipher, one can either use BlockCipher::NewROT13Cipher or BlockCipher::CreateFromString(\"ROT13\").\n* The EncryptionProvider::AddCipher method has been added to allow keys to be added to an EncryptionProvider.  This API will allow future providers to support multiple cipher keys.\n* Add a new option \"allow_data_in_errors\". When this new option is set by users, it allows users to opt-in to get error messages containing corrupted keys/values. Corrupt keys, values will be logged in the messages, logs, status etc. that will help users with the useful information regarding affected data. By default value of this option is set false to prevent users data to be exposed in the messages so currently, data will be redacted from logs, messages, status by default.\n* AdvancedColumnFamilyOptions::force_consistency_checks is now true by default, for more proactive DB corruption detection at virtually no cost (estimated two extra CPU cycles per million on a major production workload). Corruptions reported by these checks now mention \"force_consistency_checks\" in case a false positive corruption report is suspected and the option needs to be disabled (unlikely). Since existing column families have a saved setting for force_consistency_checks, only new column families will pick up the new default.\n\n### General Improvements\n* The settings of the DBOptions and ColumnFamilyOptions are now managed by Configurable objects (see New Features).  The same convenience methods to configure these options still exist but the backend implementation has been unified under a common implementation.\n\n### New Features\n\n* Methods to configure serialize, and compare -- such as TableFactory -- are exposed directly through the Configurable base class (from which these objects inherit).  This change will allow for better and more thorough configuration management and retrieval in the future.  The options for a Configurable object can be set via the ConfigureFromMap, ConfigureFromString, or ConfigureOption method.  The serialized version of the options of an object can be retrieved via the GetOptionString, ToString, or GetOption methods.  The list of options supported by an object can be obtained via the GetOptionNames method.  The \"raw\" object (such as the BlockBasedTableOption) for an option may be retrieved via the GetOptions method.  Configurable options can be compared via the AreEquivalent method.  The settings within a Configurable object may be validated via the ValidateOptions method.  The object may be intialized (at which point only mutable options may be updated) via the PrepareOptions method.\n* Introduce options.check_flush_compaction_key_order with default value to be true. With this option, during flush and compaction, key order will be checked when writing to each SST file. If the order is violated, the flush or compaction will fail.\n* Added is_full_compaction to CompactionJobStats, so that the information is available through the EventListener interface.\n* Add more stats for MultiGet in Histogram to get number of data blocks, index blocks, filter blocks and sst files read from file system per level.\n* SST files have a new table property called db_host_id, which is set to the hostname by default. A new option in DBOptions, db_host_id, allows the property value to be overridden with a user specified string, or disable it completely by making the option string empty.\n* Methods to create customizable extensions -- such as TableFactory -- are exposed directly through the Customizable base class (from which these objects inherit).  This change will allow these Customizable classes to be loaded and configured in a standard way (via CreateFromString).  More information on how to write and use Customizable classes is in the customizable.h header file.\n\n## 6.13 (2020-09-12)\n### Bug fixes\n* Fix a performance regression introduced in 6.4 that makes a upper bound check for every Next() even if keys are within a data block that is within the upper bound.\n* Fix a possible corruption to the LSM state (overlapping files within a level) when a `CompactRange()` for refitting levels (`CompactRangeOptions::change_level == true`) and another manual compaction are executed in parallel.\n* Sanitize `recycle_log_file_num` to zero when the user attempts to enable it in combination with `WALRecoveryMode::kTolerateCorruptedTailRecords`. Previously the two features were allowed together, which compromised the user's configured crash-recovery guarantees.\n* Fix a bug where a level refitting in CompactRange() might race with an automatic compaction that puts the data to the target level of the refitting. The bug has been there for years.\n* Fixed a bug in version 6.12 in which BackupEngine::CreateNewBackup could fail intermittently with non-OK status when backing up a read-write DB configured with a DBOptions::file_checksum_gen_factory.\n* Fix useless no-op compactions scheduled upon snapshot release when options.disable-auto-compactions = true.\n* Fix a bug when max_write_buffer_size_to_maintain is set, immutable flushed memtable destruction is delayed until the next super version is installed. A memtable is not added to delete list because of its reference hold by super version and super version doesn't switch because of empt delete list. So memory usage keeps on increasing beyond write_buffer_size + max_write_buffer_size_to_maintain.\n* Avoid converting MERGES to PUTS when allow_ingest_behind is true.\n* Fix compression dictionary sampling together with `SstFileWriter`. Previously, the dictionary would be trained/finalized immediately with zero samples. Now, the whole `SstFileWriter` file is buffered in memory and then sampled.\n* Fix a bug with `avoid_unnecessary_blocking_io=1` and creating backups (BackupEngine::CreateNewBackup) or checkpoints (Checkpoint::Create). With this setting and WAL enabled, these operations could randomly fail with non-OK status.\n* Fix a bug in which bottommost compaction continues to advance the underlying InternalIterator to skip tombstones even after shutdown.\n\n### New Features\n* A new field `std::string requested_checksum_func_name` is added to `FileChecksumGenContext`, which enables the checksum factory to create generators for a suite of different functions.\n* Added a new subcommand, `ldb unsafe_remove_sst_file`, which removes a lost or corrupt SST file from a DB's metadata. This command involves data loss and must not be used on a live DB.\n\n### Performance Improvements\n* Reduce thread number for multiple DB instances by re-using one global thread for statistics dumping and persisting.\n* Reduce write-amp in heavy write bursts in `kCompactionStyleLevel` compaction style with `level_compaction_dynamic_level_bytes` set.\n* BackupEngine incremental backups no longer read DB table files that are already saved to a shared part of the backup directory, unless `share_files_with_checksum` is used with `kLegacyCrc32cAndFileSize` naming (discouraged).\n  * For `share_files_with_checksum`, we are confident there is no regression (vs. pre-6.12) in detecting DB or backup corruption at backup creation time, mostly because the old design did not leverage this extra checksum computation for detecting inconsistencies at backup creation time.\n  * For `share_table_files` without \"checksum\" (not recommended), there is a regression in detecting fundamentally unsafe use of the option, greatly mitigated by file size checking (under \"Behavior Changes\"). Almost no reason to use `share_files_with_checksum=false` should remain.\n  * `DB::VerifyChecksum` and `BackupEngine::VerifyBackup` with checksum checking are still able to catch corruptions that `CreateNewBackup` does not.\n\n### Public API Change\n* Expose kTypeDeleteWithTimestamp in EntryType and update GetEntryType() accordingly.\n* Added file_checksum and file_checksum_func_name to TableFileCreationInfo, which can pass the table file checksum information through the OnTableFileCreated callback during flush and compaction.\n* A warning is added to `DB::DeleteFile()` API describing its known problems and deprecation plan.\n* Add a new stats level, i.e. StatsLevel::kExceptTickers (PR7329) to exclude tickers even if application passes a non-null Statistics object.\n* Added a new status code IOStatus::IOFenced() for the Env/FileSystem to indicate that writes from this instance are fenced off. Like any other background error, this error is returned to the user in Put/Merge/Delete/Flush calls and can be checked using Status::IsIOFenced().\n\n### Behavior Changes\n* File abstraction `FSRandomAccessFile.Prefetch()` default return status is changed from `OK` to `NotSupported`. If the user inherited file doesn't implement prefetch, RocksDB will create internal prefetch buffer to improve read performance.\n* When retryabel IO error happens during Flush (manifest write error is excluded) and WAL is disabled, originally it is mapped to kHardError. Now,it is mapped to soft error. So DB will not stall the writes unless the memtable is full. At the same time, when auto resume is triggered to recover the retryable IO error during Flush, SwitchMemtable is not called to avoid generating to many small immutable memtables. If WAL is enabled, no behavior changes.\n* When considering whether a table file is already backed up in a shared part of backup directory, BackupEngine would already query the sizes of source (DB) and pre-existing destination (backup) files. BackupEngine now uses these file sizes to detect corruption, as at least one of (a) old backup, (b) backup in progress, or (c) current DB is corrupt if there's a size mismatch.\n\n### Others\n* Error in prefetching partitioned index blocks will not be swallowed. It will fail the query and return the IOError users.\n\n## 6.12 (2020-07-28)\n### Public API Change\n* Encryption file classes now exposed for inheritance in env_encryption.h\n* File I/O listener is extended to cover more I/O operations. Now class `EventListener` in listener.h contains new callback functions: `OnFileFlushFinish()`, `OnFileSyncFinish()`, `OnFileRangeSyncFinish()`, `OnFileTruncateFinish()`, and ``OnFileCloseFinish()``.\n* `FileOperationInfo` now reports `duration` measured by `std::chrono::steady_clock` and `start_ts` measured by `std::chrono::system_clock` instead of start and finish timestamps measured by `system_clock`. Note that `system_clock` is called before `steady_clock` in program order at operation starts.\n* `DB::GetDbSessionId(std::string& session_id)` is added. `session_id` stores a unique identifier that gets reset every time the DB is opened. This DB session ID should be unique among all open DB instances on all hosts, and should be unique among re-openings of the same or other DBs. This identifier is recorded in the LOG file on the line starting with \"DB Session ID:\".\n* `DB::OpenForReadOnly()` now returns `Status::NotFound` when the specified DB directory does not exist. Previously the error returned depended on the underlying `Env`. This change is available in all 6.11 releases as well.\n* A parameter `verify_with_checksum` is added to `BackupEngine::VerifyBackup`, which is false by default. If it is ture, `BackupEngine::VerifyBackup` verifies checksums and file sizes of backup files. Pass `false` for `verify_with_checksum` to maintain the previous behavior and performance of `BackupEngine::VerifyBackup`, by only verifying sizes of backup files.\n\n### Behavior Changes\n* Best-efforts recovery ignores CURRENT file completely. If CURRENT file is missing during recovery, best-efforts recovery still proceeds with MANIFEST file(s).\n* In best-efforts recovery, an error that is not Corruption or IOError::kNotFound or IOError::kPathNotFound will be overwritten silently. Fix this by checking all non-ok cases and return early.\n* When `file_checksum_gen_factory` is set to `GetFileChecksumGenCrc32cFactory()`, BackupEngine will compare the crc32c checksums of table files computed when creating a backup to the expected checksums stored in the DB manifest, and will fail `CreateNewBackup()` on mismatch (corruption). If the `file_checksum_gen_factory` is not set or set to any other customized factory, there is no checksum verification to detect if SST files in a DB are corrupt when read, copied, and independently checksummed by BackupEngine.\n* When a DB sets `stats_dump_period_sec > 0`, either as the initial value for DB open or as a dynamic option change, the first stats dump is staggered in the following X seconds, where X is an integer in `[0, stats_dump_period_sec)`. Subsequent stats dumps are still spaced `stats_dump_period_sec` seconds apart.\n* When the paranoid_file_checks option is true, a hash is generated of all keys and values are generated when the SST file is written, and then the values are read back in to validate the file.  A corruption is signaled if the two hashes do not match.\n\n### Bug fixes\n* Compressed block cache was automatically disabled with read-only DBs by mistake. Now it is fixed: compressed block cache will be in effective with read-only DB too.\n* Fix a bug of wrong iterator result if another thread finishes an update and a DB flush between two statement.\n* Disable file deletion after MANIFEST write/sync failure until db re-open or Resume() so that subsequent re-open will not see MANIFEST referencing deleted SSTs.\n* Fix a bug when index_type == kTwoLevelIndexSearch in PartitionedIndexBuilder to update FlushPolicy to point to internal key partitioner when it changes from user-key mode to internal-key mode in index partition.\n* Make compaction report InternalKey corruption while iterating over the input.\n* Fix a bug which may cause MultiGet to be slow because it may read more data than requested, but this won't affect correctness. The bug was introduced in 6.10 release.\n* Fail recovery and report once hitting a physical log record checksum mismatch, while reading MANIFEST. RocksDB should not continue processing the MANIFEST any further.\n* Fixed a bug in size-amp-triggered and periodic-triggered universal compaction, where the compression settings for the first input level were used rather than the compression settings for the output (bottom) level.\n\n### New Features\n* DB identity (`db_id`) and DB session identity (`db_session_id`) are added to table properties and stored in SST files. SST files generated from SstFileWriter and Repairer have DB identity SST Writer and DB Repairer, respectively. Their DB session IDs are generated in the same way as `DB::GetDbSessionId`. The session ID for SstFileWriter (resp., Repairer) resets every time `SstFileWriter::Open` (resp., `Repairer::Run`) is called.\n* Added experimental option BlockBasedTableOptions::optimize_filters_for_memory for reducing allocated memory size of Bloom filters (~10% savings with Jemalloc) while preserving the same general accuracy. To have an effect, the option requires format_version=5 and malloc_usable_size. Enabling this option is forward and backward compatible with existing format_version=5.\n* `BackupableDBOptions::share_files_with_checksum_naming` is added with new default behavior for naming backup files with `share_files_with_checksum`, to address performance and backup integrity issues. See API comments for details.\n* Added auto resume function to automatically recover the DB from background Retryable IO Error. When retryable IOError happens during flush and WAL write, the error is mapped to Hard Error and DB will be in read mode. When retryable IO Error happens during compaction, the error will be mapped to Soft Error. DB is still in write/read mode. Autoresume function will create a thread for a DB to call DB->ResumeImpl() to try the recover for Retryable IO Error during flush and WAL write. Compaction will be rescheduled by itself if retryable IO Error happens. Auto resume may also cause other Retryable IO Error during the recovery, so the recovery will fail. Retry the auto resume may solve the issue, so we use max_bgerror_resume_count to decide how many resume cycles will be tried in total. If it is <=0, auto resume retryable IO Error is disabled. Default is INT_MAX, which will lead to a infinit auto resume. bgerror_resume_retry_interval decides the time interval between two auto resumes.\n* Option `max_subcompactions` can be set dynamically using DB::SetDBOptions().\n* Added experimental ColumnFamilyOptions::sst_partitioner_factory to define determine the partitioning of sst files. This helps compaction to split the files on interesting boundaries (key prefixes) to make propagation of sst files less write amplifying (covering the whole key space).\n\n### Performance Improvements\n* Eliminate key copies for internal comparisons while accessing ingested block-based tables.\n* Reduce key comparisons during random access in all block-based tables.\n* BackupEngine avoids unnecessary repeated checksum computation for backing up a table file to the `shared_checksum` directory when using `share_files_with_checksum_naming = kUseDbSessionId` (new default), except on SST files generated before this version of RocksDB, which fall back on using `kLegacyCrc32cAndFileSize`.\n\n## 6.11 (2020-06-12)\n### Bug Fixes\n* Fix consistency checking error swallowing in some cases when options.force_consistency_checks = true.\n* Fix possible false NotFound status from batched MultiGet using index type kHashSearch.\n* Fix corruption caused by enabling delete triggered compaction (NewCompactOnDeletionCollectorFactory) in universal compaction mode, along with parallel compactions. The bug can result in two parallel compactions picking the same input files, resulting in the DB resurrecting older and deleted versions of some keys.\n* Fix a use-after-free bug in best-efforts recovery. column_family_memtables_ needs to point to valid ColumnFamilySet.\n* Let best-efforts recovery ignore corrupted files during table loading.\n* Fix corrupt key read from ingested file when iterator direction switches from reverse to forward at a key that is a prefix of another key in the same file. It is only possible in files with a non-zero global seqno.\n* Fix abnormally large estimate from GetApproximateSizes when a range starts near the end of one SST file and near the beginning of another. Now GetApproximateSizes consistently and fairly includes the size of SST metadata in addition to data blocks, attributing metadata proportionally among the data blocks based on their size.\n* Fix potential file descriptor leakage in PosixEnv's IsDirectory() and NewRandomAccessFile().\n* Fix false negative from the VerifyChecksum() API when there is a checksum mismatch in an index partition block in a BlockBasedTable format table file (index_type is kTwoLevelIndexSearch).\n* Fix sst_dump to return non-zero exit code if the specified file is not a recognized SST file or fails requested checks.\n* Fix incorrect results from batched MultiGet for duplicate keys, when the duplicate key matches the largest key of an SST file and the value type for the key in the file is a merge value.\n\n### Public API Change\n* Flush(..., column_family) may return Status::ColumnFamilyDropped() instead of Status::InvalidArgument() if column_family is dropped while processing the flush request.\n* BlobDB now explicitly disallows using the default column family's storage directories as blob directory.\n* DeleteRange now returns `Status::InvalidArgument` if the range's end key comes before its start key according to the user comparator. Previously the behavior was undefined.\n* ldb now uses options.force_consistency_checks = true by default and \"--disable_consistency_checks\" is added to disable it.\n* DB::OpenForReadOnly no longer creates files or directories if the named DB does not exist, unless create_if_missing is set to true.\n* The consistency checks that validate LSM state changes (table file additions/deletions during flushes and compactions) are now stricter, more efficient, and no longer optional, i.e. they are performed even if `force_consistency_checks` is `false`.\n* Disable delete triggered compaction (NewCompactOnDeletionCollectorFactory) in universal compaction mode and num_levels = 1 in order to avoid a corruption bug.\n* `pin_l0_filter_and_index_blocks_in_cache` no longer applies to L0 files larger than `1.5 * write_buffer_size` to give more predictable memory usage. Such L0 files may exist due to intra-L0 compaction, external file ingestion, or user dynamically changing `write_buffer_size` (note, however, that files that are already pinned will continue being pinned, even after such a dynamic change).\n* In point-in-time wal recovery mode, fail database recovery in case of IOError while reading the WAL to avoid data loss.\n* A new method `Env::LowerThreadPoolCPUPriority(Priority, CpuPriority)` is added to `Env` to be able to lower to a specific priority such as `CpuPriority::kIdle`.\n\n### New Features\n* sst_dump to add a new --readahead_size argument. Users can specify read size when scanning the data. Sst_dump also tries to prefetch tail part of the SST files so usually some number of I/Os are saved there too.\n* Generate file checksum in SstFileWriter if Options.file_checksum_gen_factory is set. The checksum and checksum function name are stored in ExternalSstFileInfo after the sst file write is finished.\n* Add a value_size_soft_limit in read options which limits the cumulative value size of keys read in batches in MultiGet. Once the cumulative value size of found keys exceeds read_options.value_size_soft_limit, all the remaining keys are returned with status Abort without further finding their values. By default the value_size_soft_limit is std::numeric_limits<uint64_t>::max().\n* Enable SST file ingestion with file checksum information when calling IngestExternalFiles(const std::vector<IngestExternalFileArg>& args). Added files_checksums and files_checksum_func_names to IngestExternalFileArg such that user can ingest the sst files with their file checksum information. Added verify_file_checksum to IngestExternalFileOptions (default is True). To be backward compatible, if DB does not enable file checksum or user does not provide checksum information (vectors of files_checksums and files_checksum_func_names are both empty), verification of file checksum is always sucessful. If DB enables file checksum, DB will always generate the checksum for each ingested SST file during Prepare stage of ingestion and store the checksum in Manifest, unless verify_file_checksum is False and checksum information is provided by the application. In this case, we only verify the checksum function name and directly store the ingested checksum in Manifest. If verify_file_checksum is set to True, DB will verify the ingested checksum and function name with the genrated ones. Any mismatch will fail the ingestion. Note that, if IngestExternalFileOptions::write_global_seqno is True, the seqno will be changed in the ingested file. Therefore, the checksum of the file will be changed. In this case, a new checksum will be generated after the seqno is updated and be stored in the Manifest.\n\n### Performance Improvements\n* Eliminate redundant key comparisons during random access in block-based tables.\n\n## 6.10 (2020-05-02)\n### Bug Fixes\n* Fix wrong result being read from ingested file. May happen when a key in the file happen to be prefix of another key also in the file. The issue can further cause more data corruption. The issue exists with rocksdb >= 5.0.0 since DB::IngestExternalFile() was introduced.\n* Finish implementation of BlockBasedTableOptions::IndexType::kBinarySearchWithFirstKey. It's now ready for use. Significantly reduces read amplification in some setups, especially for iterator seeks.\n* Fix a bug by updating CURRENT file so that it points to the correct MANIFEST file after best-efforts recovery.\n* Fixed a bug where ColumnFamilyHandle objects were not cleaned up in case an error happened during BlobDB's open after the base DB had been opened.\n* Fix a potential undefined behavior caused by trying to dereference nullable pointer (timestamp argument) in DB::MultiGet.\n* Fix a bug caused by not including user timestamp in MultiGet LookupKey construction. This can lead to wrong query result since the trailing bytes of a user key, if not shorter than timestamp, will be mistaken for user timestamp.\n* Fix a bug caused by using wrong compare function when sorting the input keys of MultiGet with timestamps.\n* Upgraded version of bzip library (1.0.6 -> 1.0.8) used with RocksJava to address potential vulnerabilities if an attacker can manipulate compressed data saved and loaded by RocksDB (not normal). See issue #6703.\n\n### Public API Change\n* Add a ConfigOptions argument to the APIs dealing with converting options to and from strings and files.  The ConfigOptions is meant to replace some of the options (such as input_strings_escaped and ignore_unknown_options) and allow for more parameters to be passed in the future without changing the function signature.\n* Add NewFileChecksumGenCrc32cFactory to the file checksum public API, such that the builtin Crc32c based file checksum generator factory can be used by applications.\n* Add IsDirectory to Env and FS to indicate if a path is a directory.\n\n### New Features\n* Added support for pipelined & parallel compression optimization for `BlockBasedTableBuilder`. This optimization makes block building, block compression and block appending a pipeline, and uses multiple threads to accelerate block compression. Users can set `CompressionOptions::parallel_threads` greater than 1 to enable compression parallelism. This feature is experimental for now.\n* Provide an allocator for memkind to be used with block cache. This is to work with memory technologies (Intel DCPMM is one such technology currently available) that require different libraries for allocation and management (such as PMDK and memkind). The high capacities available make it possible to provision large caches (up to several TBs in size) beyond what is achievable with DRAM.\n* Option `max_background_flushes` can be set dynamically using DB::SetDBOptions().\n* Added functionality in sst_dump tool to check the compressed file size for different compression levels and print the time spent on compressing files with each compression type. Added arguments `--compression_level_from` and `--compression_level_to` to report size of all compression levels and one compression_type must be specified with it so that it will report compressed sizes of one compression type with different levels.\n* Added statistics for redundant insertions into block cache: rocksdb.block.cache.*add.redundant. (There is currently no coordination to ensure that only one thread loads a table block when many threads are trying to access that same table block.)\n\n### Bug Fixes\n* Fix a bug when making options.bottommost_compression, options.compression_opts and options.bottommost_compression_opts dynamically changeable: the modified values are not written to option files or returned back to users when being queried.\n* Fix a bug where index key comparisons were unaccounted in `PerfContext::user_key_comparison_count` for lookups in files written with `format_version >= 3`.\n* Fix many bloom.filter statistics not being updated in batch MultiGet.\n\n### Performance Improvements\n* Improve performance of batch MultiGet with partitioned filters, by sharing block cache lookups to applicable filter blocks.\n* Reduced memory copies when fetching and uncompressing compressed blocks from sst files.\n\n## 6.9.0 (2020-03-29)\n### Behavior changes\n* Since RocksDB 6.8, ttl-based FIFO compaction can drop a file whose oldest key becomes older than options.ttl while others have not. This fix reverts this and makes ttl-based FIFO compaction use the file's flush time as the criterion. This fix also requires that max_open_files = -1 and compaction_options_fifo.allow_compaction = false to function properly.\n\n### Public API Change\n* Fix spelling so that API now has correctly spelled transaction state name `COMMITTED`, while the old misspelled `COMMITED` is still available as an alias.\n* Updated default format_version in BlockBasedTableOptions from 2 to 4. SST files generated with the new default can be read by RocksDB versions 5.16 and newer, and use more efficient encoding of keys in index blocks.\n* A new parameter `CreateBackupOptions` is added to both `BackupEngine::CreateNewBackup` and `BackupEngine::CreateNewBackupWithMetadata`, you can decrease CPU priority of `BackupEngine`'s background threads by setting `decrease_background_thread_cpu_priority` and `background_thread_cpu_priority` in `CreateBackupOptions`.\n* Updated the public API of SST file checksum. Introduce the FileChecksumGenFactory to create the FileChecksumGenerator for each SST file, such that the FileChecksumGenerator is not shared and it can be more general for checksum implementations. Changed the FileChecksumGenerator interface from Value, Extend, and GetChecksum to Update, Finalize, and GetChecksum. Finalize should be only called once after all data is processed to generate the final checksum. Temproal data should be maintained by the FileChecksumGenerator object itself and finally it can return the checksum string.\n\n### Bug Fixes\n* Fix a bug where range tombstone blocks in ingested files were cached incorrectly during ingestion. If range tombstones were read from those incorrectly cached blocks, the keys they covered would be exposed.\n* Fix a data race that might cause crash when calling DB::GetCreationTimeOfOldestFile() by a small chance. The bug was introduced in 6.6 Release.\n* Fix a bug where a boolean value optimize_filters_for_hits was for max threads when calling load table handles after a flush or compaction. The value is correct to 1. The bug should not cause user visible problems.\n* Fix a bug which might crash the service when write buffer manager fails to insert the dummy handle to the block cache.\n\n### Performance Improvements\n* In CompactRange, for levels starting from 0, if the level does not have any file with any key falling in the specified range, the level is skipped. So instead of always compacting from level 0, the compaction starts from the first level with keys in the specified range until the last such level.\n* Reduced memory copy when reading sst footer and blobdb in direct IO mode.\n* When restarting a database with large numbers of sst files, large amount of CPU time is spent on getting logical block size of the sst files, which slows down the starting progress, this inefficiency is optimized away with an internal cache for the logical block sizes.\n\n### New Features\n* Basic support for user timestamp in iterator. Seek/SeekToFirst/Next and lower/upper bounds are supported. Reverse iteration is not supported. Merge is not considered.\n* When file lock failure when the lock is held by the current process, return acquiring time and thread ID in the error message.\n* Added a new option, best_efforts_recovery (default: false), to allow database to open in a db dir with missing table files. During best efforts recovery, missing table files are ignored, and database recovers to the most recent state without missing table file. Cross-column-family consistency is not guaranteed even if WAL is enabled.\n* options.bottommost_compression, options.compression_opts and options.bottommost_compression_opts are now dynamically changeable.\n\n## 6.8.0 (2020-02-24)\n### Java API Changes\n* Major breaking changes to Java comparators, toward standardizing on ByteBuffer for performant, locale-neutral operations on keys (#6252).\n* Added overloads of common API methods using direct ByteBuffers for keys and values (#2283).\n\n### Bug Fixes\n* Fix incorrect results while block-based table uses kHashSearch, together with Prev()/SeekForPrev().\n* Fix a bug that prevents opening a DB after two consecutive crash with TransactionDB, where the first crash recovers from a corrupted WAL with kPointInTimeRecovery but the second cannot.\n* Fixed issue #6316 that can cause a corruption of the MANIFEST file in the middle when writing to it fails due to no disk space.\n* Add DBOptions::skip_checking_sst_file_sizes_on_db_open. It disables potentially expensive checking of all sst file sizes in DB::Open().\n* BlobDB now ignores trivially moved files when updating the mapping between blob files and SSTs. This should mitigate issue #6338 where out of order flush/compaction notifications could trigger an assertion with the earlier code.\n* Batched MultiGet() ignores IO errors while reading data blocks, causing it to potentially continue looking for a key and returning stale results.\n* `WriteBatchWithIndex::DeleteRange` returns `Status::NotSupported`. Previously it returned success even though reads on the batch did not account for range tombstones. The corresponding language bindings now cannot be used. In C, that includes `rocksdb_writebatch_wi_delete_range`, `rocksdb_writebatch_wi_delete_range_cf`, `rocksdb_writebatch_wi_delete_rangev`, and `rocksdb_writebatch_wi_delete_rangev_cf`. In Java, that includes `WriteBatchWithIndex::deleteRange`.\n* Assign new MANIFEST file number when caller tries to create a new MANIFEST by calling LogAndApply(..., new_descriptor_log=true). This bug can cause MANIFEST being overwritten during recovery if options.write_dbid_to_manifest = true and there are WAL file(s).\n\n### Performance Improvements\n* Perfom readahead when reading from option files. Inside DB, options.log_readahead_size will be used as the readahead size. In other cases, a default 512KB is used.\n\n### Public API Change\n* The BlobDB garbage collector now emits the statistics `BLOB_DB_GC_NUM_FILES` (number of blob files obsoleted during GC), `BLOB_DB_GC_NUM_NEW_FILES` (number of new blob files generated during GC), `BLOB_DB_GC_FAILURES` (number of failed GC passes), `BLOB_DB_GC_NUM_KEYS_RELOCATED` (number of blobs relocated during GC), and `BLOB_DB_GC_BYTES_RELOCATED` (total size of blobs relocated during GC). On the other hand, the following statistics, which are not relevant for the new GC implementation, are now deprecated: `BLOB_DB_GC_NUM_KEYS_OVERWRITTEN`, `BLOB_DB_GC_NUM_KEYS_EXPIRED`, `BLOB_DB_GC_BYTES_OVERWRITTEN`, `BLOB_DB_GC_BYTES_EXPIRED`, and `BLOB_DB_GC_MICROS`.\n* Disable recycle_log_file_num when an inconsistent recovery modes are requested: kPointInTimeRecovery and kAbsoluteConsistency\n\n### New Features\n* Added the checksum for each SST file generated by Flush or Compaction. Added sst_file_checksum_func to Options such that user can plugin their own SST file checksum function via override the FileChecksumFunc class. If user does not set the sst_file_checksum_func, SST file checksum calculation will not be enabled. The checksum information inlcuding uint32_t checksum value and a checksum function name (string). The checksum information is stored in FileMetadata in version store and also logged to MANIFEST. A new tool is added to LDB such that user can dump out a list of file checksum information from MANIFEST (stored in an unordered_map).\n* `db_bench` now supports `value_size_distribution_type`, `value_size_min`, `value_size_max` options for generating random variable sized value. Added `blob_db_compression_type` option for BlobDB to enable blob compression.\n* Replace RocksDB namespace \"rocksdb\" with flag \"ROCKSDB_NAMESPACE\" which if is not defined, defined as \"rocksdb\" in header file rocksdb_namespace.h.\n\n## 6.7.0 (2020-01-21)\n### Public API Change\n* Added a rocksdb::FileSystem class in include/rocksdb/file_system.h to encapsulate file creation/read/write operations, and an option DBOptions::file_system to allow a user to pass in an instance of rocksdb::FileSystem. If its a non-null value, this will take precendence over DBOptions::env for file operations. A new API rocksdb::FileSystem::Default() returns a platform default object. The DBOptions::env option and Env::Default() API will continue to be used for threading and other OS related functions, and where DBOptions::file_system is not specified, for file operations. For storage developers who are accustomed to rocksdb::Env, the interface in rocksdb::FileSystem is new and will probably undergo some changes as more storage systems are ported to it from rocksdb::Env. As of now, no env other than Posix has been ported to the new interface.\n* A new rocksdb::NewSstFileManager() API that allows the caller to pass in separate Env and FileSystem objects.\n* Changed Java API for RocksDB.keyMayExist functions to use Holder<byte[]> instead of StringBuilder, so that retrieved values need not decode to Strings.\n* A new `OptimisticTransactionDBOptions` Option that allows users to configure occ validation policy. The default policy changes from kValidateSerial to kValidateParallel to reduce mutex contention.\n\n### Bug Fixes\n* Fix a bug that can cause unnecessary bg thread to be scheduled(#6104).\n* Fix crash caused by concurrent CF iterations and drops(#6147).\n* Fix a race condition for cfd->log_number_ between manifest switch and memtable switch (PR 6249) when number of column families is greater than 1.\n* Fix a bug on fractional cascading index when multiple files at the same level contain the same smallest user key, and those user keys are for merge operands. In this case, Get() the exact key may miss some merge operands.\n* Delcare kHashSearch index type feature-incompatible with index_block_restart_interval larger than 1.\n* Fixed an issue where the thread pools were not resized upon setting `max_background_jobs` dynamically through the `SetDBOptions` interface.\n* Fix a bug that can cause write threads to hang when a slowdown/stall happens and there is a mix of writers with WriteOptions::no_slowdown set/unset.\n* Fixed an issue where an incorrect \"number of input records\" value was used to compute the \"records dropped\" statistics for compactions.\n* Fix a regression bug that causes segfault when hash is used, max_open_files != -1 and total order seek is used and switched back.\n\n### New Features\n* It is now possible to enable periodic compactions for the base DB when using BlobDB.\n* BlobDB now garbage collects non-TTL blobs when `enable_garbage_collection` is set to `true` in `BlobDBOptions`. Garbage collection is performed during compaction: any valid blobs located in the oldest N files (where N is the number of non-TTL blob files multiplied by the value of `BlobDBOptions::garbage_collection_cutoff`) encountered during compaction get relocated to new blob files, and old blob files are dropped once they are no longer needed. Note: we recommend enabling periodic compactions for the base DB when using this feature to deal with the case when some old blob files are kept alive by SSTs that otherwise do not get picked for compaction.\n* `db_bench` now supports the `garbage_collection_cutoff` option for BlobDB.\n* Introduce ReadOptions.auto_prefix_mode. When set to true, iterator will return the same result as total order seek, but may choose to use prefix seek internally based on seek key and iterator upper bound.\n* MultiGet() can use IO Uring to parallelize read from the same SST file. This featuer is by default disabled. It can be enabled with environment variable ROCKSDB_USE_IO_URING.\n\n## 6.6.2 (2020-01-13)\n### Bug Fixes\n* Fixed a bug where non-L0 compaction input files were not considered to compute the `creation_time` of new compaction outputs.\n\n## 6.6.1 (2020-01-02)\n### Bug Fixes\n* Fix a bug in WriteBatchWithIndex::MultiGetFromBatchAndDB, which is called by Transaction::MultiGet, that causes due to stale pointer access when the number of keys is > 32\n* Fixed two performance issues related to memtable history trimming. First, a new SuperVersion is now created only if some memtables were actually trimmed. Second, trimming is only scheduled if there is at least one flushed memtable that is kept in memory for the purposes of transaction conflict checking.\n* BlobDB no longer updates the SST to blob file mapping upon failed compactions.\n* Fix a bug in which a snapshot read through an iterator could be affected by a DeleteRange after the snapshot (#6062).\n* Fixed a bug where BlobDB was comparing the `ColumnFamilyHandle` pointers themselves instead of only the column family IDs when checking whether an API call uses the default column family or not.\n* Delete superversions in BackgroundCallPurge.\n* Fix use-after-free and double-deleting files in BackgroundCallPurge().\n\n## 6.6.0 (2019-11-25)\n### Bug Fixes\n* Fix data corruption caused by output of intra-L0 compaction on ingested file not being placed in correct order in L0.\n* Fix a data race between Version::GetColumnFamilyMetaData() and Compaction::MarkFilesBeingCompacted() for access to being_compacted (#6056). The current fix acquires the db mutex during Version::GetColumnFamilyMetaData(), which may cause regression.\n* Fix a bug in DBIter that is_blob_ state isn't updated when iterating backward using seek.\n* Fix a bug when format_version=3, partitioned filters, and prefix search are used in conjunction. The bug could result into Seek::(prefix) returning NotFound for an existing prefix.\n* Revert the feature \"Merging iterator to avoid child iterator reseek for some cases (#5286)\" since it might cause strong results when reseek happens with a different iterator upper bound.\n* Fix a bug causing a crash during ingest external file when background compaction cause severe error (file not found).\n* Fix a bug when partitioned filters and prefix search are used in conjunction, ::SeekForPrev could return invalid for an existing prefix. ::SeekForPrev might be called by the user, or internally on ::Prev, or within ::Seek if the return value involves Delete or a Merge operand.\n* Fix OnFlushCompleted fired before flush result persisted in MANIFEST when there's concurrent flush job. The bug exists since OnFlushCompleted was introduced in rocksdb 3.8.\n* Fixed an sst_dump crash on some plain table SST files.\n* Fixed a memory leak in some error cases of opening plain table SST files.\n* Fix a bug when a crash happens while calling WriteLevel0TableForRecovery for multiple column families, leading to a column family's log number greater than the first corrutped log number when the DB is being opened in PointInTime recovery mode during next recovery attempt (#5856).\n\n### New Features\n* Universal compaction to support options.periodic_compaction_seconds. A full compaction will be triggered if any file is over the threshold.\n* `GetLiveFilesMetaData` and `GetColumnFamilyMetaData` now expose the file number of SST files as well as the oldest blob file referenced by each SST.\n* A batched MultiGet API (DB::MultiGet()) that supports retrieving keys from multiple column families.\n* Full and partitioned filters in the block-based table use an improved Bloom filter implementation, enabled with format_version 5 (or above) because previous releases cannot read this filter. This replacement is faster and more accurate, especially for high bits per key or millions of keys in a single (full) filter. For example, the new Bloom filter has the same false positive rate at 9.55 bits per key as the old one at 10 bits per key, and a lower false positive rate at 16 bits per key than the old one at 100 bits per key.\n* Added AVX2 instructions to USE_SSE builds to accelerate the new Bloom filter and XXH3-based hash function on compatible x86_64 platforms (Haswell and later, ~2014).\n* Support options.ttl or options.periodic_compaction_seconds with options.max_open_files = -1. File's oldest ancester time and file creation time will be written to manifest. If it is availalbe, this information will be used instead of creation_time and file_creation_time in table properties.\n* Setting options.ttl for universal compaction now has the same meaning as setting periodic_compaction_seconds.\n* SstFileMetaData also returns file creation time and oldest ancester time.\n* The `sst_dump` command line tool `recompress` command now displays how many blocks were compressed and how many were not, in particular how many were not compressed because the compression ratio was not met (12.5% threshold for GoodCompressionRatio), as seen in the `number.block.not_compressed` counter stat since version 6.0.0.\n* The block cache usage is now takes into account the overhead of metadata per each entry. This results into more accurate management of memory. A side-effect of this feature is that less items are fit into the block cache of the same size, which would result to higher cache miss rates. This can be remedied by increasing the block cache size or passing kDontChargeCacheMetadata to its constuctor to restore the old behavior.\n* When using BlobDB, a mapping is maintained and persisted in the MANIFEST between each SST file and the oldest non-TTL blob file it references.\n* `db_bench` now supports and by default issues non-TTL Puts to BlobDB. TTL Puts can be enabled by specifying a non-zero value for the `blob_db_max_ttl_range` command line parameter explicitly.\n* `sst_dump` now supports printing BlobDB blob indexes in a human-readable format. This can be enabled by specifying the `decode_blob_index` flag on the command line.\n* A number of new information elements are now exposed through the EventListener interface. For flushes, the file numbers of the new SST file and the oldest blob file referenced by the SST are propagated. For compactions, the level, file number, and the oldest blob file referenced are passed to the client for each compaction input and output file.\n\n### Public API Change\n* RocksDB release 4.1 or older will not be able to open DB generated by the new release. 4.2 was released on Feb 23, 2016.\n* TTL Compactions in Level compaction style now initiate successive cascading compactions on a key range so that it reaches the bottom level quickly on TTL expiry. `creation_time` table property for compaction output files is now set to the minimum of the creation times of all compaction inputs.\n* With FIFO compaction style, options.periodic_compaction_seconds will have the same meaning as options.ttl. Whichever stricter will be used. With the default options.periodic_compaction_seconds value with options.ttl's default of 0, RocksDB will give a default of 30 days.\n* Added an API GetCreationTimeOfOldestFile(uint64_t* creation_time) to get the file_creation_time of the oldest SST file in the DB.\n* FilterPolicy now exposes additional API to make it possible to choose filter configurations based on context, such as table level and compaction style. See `LevelAndStyleCustomFilterPolicy` in db_bloom_filter_test.cc. While most existing custom implementations of FilterPolicy should continue to work as before, those wrapping the return of NewBloomFilterPolicy will require overriding new function `GetBuilderWithContext()`, because calling `GetFilterBitsBuilder()` on the FilterPolicy returned by NewBloomFilterPolicy is no longer supported.\n* An unlikely usage of FilterPolicy is no longer supported. Calling GetFilterBitsBuilder() on the FilterPolicy returned by NewBloomFilterPolicy will now cause an assertion violation in debug builds, because RocksDB has internally migrated to a more elaborate interface that is expected to evolve further. Custom implementations of FilterPolicy should work as before, except those wrapping the return of NewBloomFilterPolicy, which will require a new override of a protected function in FilterPolicy.\n* NewBloomFilterPolicy now takes bits_per_key as a double instead of an int. This permits finer control over the memory vs. accuracy trade-off in the new Bloom filter implementation and should not change source code compatibility.\n* The option BackupableDBOptions::max_valid_backups_to_open is now only used when opening BackupEngineReadOnly. When opening a read/write BackupEngine, anything but the default value logs a warning and is treated as the default. This change ensures that backup deletion has proper accounting of shared files to ensure they are deleted when no longer referenced by a backup.\n* Deprecate `snap_refresh_nanos` option.\n* Added DisableManualCompaction/EnableManualCompaction to stop and resume manual compaction.\n* Add TryCatchUpWithPrimary() to StackableDB in non-LITE mode.\n* Add a new Env::LoadEnv() overloaded function to return a shared_ptr to Env.\n* Flush sets file name to \"(nil)\" for OnTableFileCreationCompleted() if the flush does not produce any L0. This can happen if the file is empty thus delete by RocksDB.\n\n### Default Option Changes\n* Changed the default value of periodic_compaction_seconds to `UINT64_MAX - 1` which allows RocksDB to auto-tune periodic compaction scheduling. When using the default value, periodic compactions are now auto-enabled if a compaction filter is used. A value of `0` will turn off the feature completely.\n* Changed the default value of ttl to `UINT64_MAX - 1` which allows RocksDB to auto-tune ttl value. When using the default value, TTL will be auto-enabled to 30 days, when the feature is supported. To revert the old behavior, you can explicitly set it to 0.\n\n### Performance Improvements\n* For 64-bit hashing, RocksDB is standardizing on a slightly modified preview version of XXH3. This function is now used for many non-persisted hashes, along with fastrange64() in place of the modulus operator, and some benchmarks show a slight improvement.\n* Level iterator to invlidate the iterator more often in prefix seek and the level is filtered out by prefix bloom.\n\n## 6.5.2 (2019-11-15)\n### Bug Fixes\n* Fix a assertion failure in MultiGet() when BlockBasedTableOptions::no_block_cache is true and there is no compressed block cache\n* Fix a buffer overrun problem in BlockBasedTable::MultiGet() when compression is enabled and no compressed block cache is configured.\n* If a call to BackupEngine::PurgeOldBackups or BackupEngine::DeleteBackup suffered a crash, power failure, or I/O error, files could be left over from old backups that could only be purged with a call to GarbageCollect. Any call to PurgeOldBackups, DeleteBackup, or GarbageCollect should now suffice to purge such files.\n\n## 6.5.1 (2019-10-16)\n### Bug Fixes\n* Revert the feature \"Merging iterator to avoid child iterator reseek for some cases (#5286)\" since it might cause strange results when reseek happens with a different iterator upper bound.\n* Fix a bug in BlockBasedTableIterator that might return incorrect results when reseek happens with a different iterator upper bound.\n* Fix a bug when partitioned filters and prefix search are used in conjunction, ::SeekForPrev could return invalid for an existing prefix. ::SeekForPrev might be called by the user, or internally on ::Prev, or within ::Seek if the return value involves Delete or a Merge operand.\n\n## 6.5.0 (2019-09-13)\n### Bug Fixes\n* Fixed a number of data races in BlobDB.\n* Fix a bug where the compaction snapshot refresh feature is not disabled as advertised when `snap_refresh_nanos` is set to 0..\n* Fix bloom filter lookups by the MultiGet batching API when BlockBasedTableOptions::whole_key_filtering is false, by checking that a key is in the perfix_extractor domain and extracting the prefix before looking up.\n* Fix a bug in file ingestion caused by incorrect file number allocation when the number of column families involved in the ingestion exceeds 2.\n\n### New Features\n* Introduced DBOptions::max_write_batch_group_size_bytes to configure maximum limit on number of bytes that are written in a single batch of WAL or memtable write. It is followed when the leader write size is larger than 1/8 of this limit.\n* VerifyChecksum() by default will issue readahead. Allow ReadOptions to be passed in to those functions to override the readhead size. For checksum verifying before external SST file ingestion, a new option IngestExternalFileOptions.verify_checksums_readahead_size, is added for this readahead setting.\n* When user uses options.force_consistency_check in RocksDb, instead of crashing the process, we now pass the error back to the users without killing the process.\n* Add an option `memtable_insert_hint_per_batch` to WriteOptions. If it is true, each WriteBatch will maintain its own insert hints for each memtable in concurrent write. See include/rocksdb/options.h for more details.\n\n### Public API Change\n* Added max_write_buffer_size_to_maintain option to better control memory usage of immutable memtables.\n* Added a lightweight API GetCurrentWalFile() to get last live WAL filename and size. Meant to be used as a helper for backup/restore tooling in a larger ecosystem such as MySQL with a MyRocks storage engine.\n* The MemTable Bloom filter, when enabled, now always uses cache locality. Options::bloom_locality now only affects the PlainTable SST format.\n\n### Performance Improvements\n* Improve the speed of the MemTable Bloom filter, reducing the write overhead of enabling it by 1/3 to 1/2, with similar benefit to read performance.\n\n## 6.4.0 (2019-07-30)\n### Default Option Change\n* LRUCacheOptions.high_pri_pool_ratio is set to 0.5 (previously 0.0) by default, which means that by default midpoint insertion is enabled. The same change is made for the default value of high_pri_pool_ratio argument in NewLRUCache(). When block cache is not explicitly created, the small block cache created by BlockBasedTable will still has this option to be 0.0.\n* Change BlockBasedTableOptions.cache_index_and_filter_blocks_with_high_priority's default value from false to true.\n\n### Public API Change\n* Filter and compression dictionary blocks are now handled similarly to data blocks with regards to the block cache: instead of storing objects in the cache, only the blocks themselves are cached. In addition, filter and compression dictionary blocks (as well as filter partitions) no longer get evicted from the cache when a table is closed.\n* Due to the above refactoring, block cache eviction statistics for filter and compression dictionary blocks are temporarily broken. We plan to reintroduce them in a later phase.\n* The semantics of the per-block-type block read counts in the performance context now match those of the generic block_read_count.\n* Errors related to the retrieval of the compression dictionary are now propagated to the user.\n* db_bench adds a \"benchmark\" stats_history, which prints out the whole stats history.\n* Overload GetAllKeyVersions() to support non-default column family.\n* Added new APIs ExportColumnFamily() and CreateColumnFamilyWithImport() to support export and import of a Column Family. https://github.com/facebook/rocksdb/issues/3469\n* ldb sometimes uses a string-append merge operator if no merge operator is passed in. This is to allow users to print keys from a DB with a merge operator.\n* Replaces old Registra with ObjectRegistry to allow user to create custom object from string, also add LoadEnv() to Env.\n* Added new overload of GetApproximateSizes which gets SizeApproximationOptions object and returns a Status. The older overloads are redirecting their calls to this new method and no longer assert if the include_flags doesn't have either of INCLUDE_MEMTABLES or INCLUDE_FILES bits set. It's recommended to use the new method only, as it is more type safe and returns a meaningful status in case of errors.\n* LDBCommandRunner::RunCommand() to return the status code as an integer, rather than call exit() using the code.\n\n### New Features\n* Add argument `--secondary_path` to ldb to open the database as the secondary instance. This would keep the original DB intact.\n* Compression dictionary blocks are now prefetched and pinned in the cache (based on the customer's settings) the same way as index and filter blocks.\n* Added DBOptions::log_readahead_size which specifies the number of bytes to prefetch when reading the log. This is mostly useful for reading a remotely located log, as it can save the number of round-trips. If 0 (default), then the prefetching is disabled.\n* Added new option in SizeApproximationOptions used with DB::GetApproximateSizes. When approximating the files total size that is used to store a keys range, allow approximation with an error margin of up to total_files_size * files_size_error_margin. This allows to take some shortcuts in files size approximation, resulting in better performance, while guaranteeing the resulting error is within a reasonable margin.\n* Support loading custom objects in unit tests. In the affected unit tests, RocksDB will create custom Env objects based on environment variable TEST_ENV_URI. Users need to make sure custom object types are properly registered. For example, a static library should expose a `RegisterCustomObjects` function. By linking the unit test binary with the static library, the unit test can execute this function.\n\n### Performance Improvements\n* Reduce iterator key comparison for upper/lower bound check.\n* Improve performance of row_cache: make reads with newer snapshots than data in an SST file share the same cache key, except in some transaction cases.\n* The compression dictionary is no longer copied to a new object upon retrieval.\n\n### Bug Fixes\n* Fix ingested file and directory not being fsync.\n* Return TryAgain status in place of Corruption when new tail is not visible to TransactionLogIterator.\n* Fixed a regression where the fill_cache read option also affected index blocks.\n* Fixed an issue where using cache_index_and_filter_blocks==false affected partitions of partitioned indexes/filters as well.\n\n## 6.3.2 (2019-08-15)\n### Public API Change\n* The semantics of the per-block-type block read counts in the performance context now match those of the generic block_read_count.\n\n### Bug Fixes\n* Fixed a regression where the fill_cache read option also affected index blocks.\n* Fixed an issue where using cache_index_and_filter_blocks==false affected partitions of partitioned indexes as well.\n\n## 6.3.1 (2019-07-24)\n### Bug Fixes\n* Fix auto rolling bug introduced in 6.3.0, which causes segfault if log file creation fails.\n\n## 6.3.0 (2019-06-18)\n### Public API Change\n* Now DB::Close() will return Aborted() error when there is unreleased snapshot. Users can retry after all snapshots are released.\n* Index blocks are now handled similarly to data blocks with regards to the block cache: instead of storing objects in the cache, only the blocks themselves are cached. In addition, index blocks no longer get evicted from the cache when a table is closed, can now use the compressed block cache (if any), and can be shared among multiple table readers.\n* Partitions of partitioned indexes no longer affect the read amplification statistics.\n* Due to the above refactoring, block cache eviction statistics for indexes are temporarily broken. We plan to reintroduce them in a later phase.\n* options.keep_log_file_num will be enforced strictly all the time. File names of all log files will be tracked, which may take significantly amount of memory if options.keep_log_file_num is large and either of options.max_log_file_size or options.log_file_time_to_roll is set.\n* Add initial support for Get/Put with user timestamps. Users can specify timestamps via ReadOptions and WriteOptions when calling DB::Get and DB::Put.\n* Accessing a partition of a partitioned filter or index through a pinned reference is no longer considered a cache hit.\n* Add C bindings for secondary instance, i.e. DBImplSecondary.\n* Rate limited deletion of WALs is only enabled if DBOptions::wal_dir is not set, or explicitly set to db_name passed to DB::Open and DBOptions::db_paths is empty, or same as db_paths[0].path\n\n### New Features\n* Add an option `snap_refresh_nanos` (default to 0) to periodically refresh the snapshot list in compaction jobs. Assign to 0 to disable the feature.\n* Add an option `unordered_write` which trades snapshot guarantees with higher write throughput. When used with WRITE_PREPARED transactions with two_write_queues=true, it offers higher throughput with however no compromise on guarantees.\n* Allow DBImplSecondary to remove memtables with obsolete data after replaying MANIFEST and WAL.\n* Add an option `failed_move_fall_back_to_copy` (default is true) for external SST ingestion. When `move_files` is true and hard link fails, ingestion falls back to copy if `failed_move_fall_back_to_copy` is true. Otherwise, ingestion reports an error.\n* Add command `list_file_range_deletes` in ldb, which prints out tombstones in SST files.\n\n### Performance Improvements\n* Reduce binary search when iterator reseek into the same data block.\n* DBIter::Next() can skip user key checking if previous entry's seqnum is 0.\n* Merging iterator to avoid child iterator reseek for some cases\n* Log Writer will flush after finishing the whole record, rather than a fragment.\n* Lower MultiGet batching API latency by reading data blocks from disk in parallel\n\n### General Improvements\n* Added new status code kColumnFamilyDropped to distinguish between Column Family Dropped and DB Shutdown in progress.\n* Improve ColumnFamilyOptions validation when creating a new column family.\n\n### Bug Fixes\n* Fix a bug in WAL replay of secondary instance by skipping write batches with older sequence numbers than the current last sequence number.\n* Fix flush's/compaction's merge processing logic which allowed `Put`s covered by range tombstones to reappear. Note `Put`s may exist even if the user only ever called `Merge()` due to an internal conversion during compaction to the bottommost level.\n* Fix/improve memtable earliest sequence assignment and WAL replay so that WAL entries of unflushed column families will not be skipped after replaying the MANIFEST and increasing db sequence due to another flushed/compacted column family.\n* Fix a bug caused by secondary not skipping the beginning of new MANIFEST.\n* On DB open, delete WAL trash files left behind in wal_dir\n\n## 6.2.0 (2019-04-30)\n### New Features\n* Add an option `strict_bytes_per_sync` that causes a file-writing thread to block rather than exceed the limit on bytes pending writeback specified by `bytes_per_sync` or `wal_bytes_per_sync`.\n* Improve range scan performance by avoiding per-key upper bound check in BlockBasedTableIterator.\n* Introduce Periodic Compaction for Level style compaction. Files are re-compacted periodically and put in the same level.\n* Block-based table index now contains exact highest key in the file, rather than an upper bound. This may improve Get() and iterator Seek() performance in some situations, especially when direct IO is enabled and block cache is disabled. A setting BlockBasedTableOptions::index_shortening is introduced to control this behavior. Set it to kShortenSeparatorsAndSuccessor to get the old behavior.\n* When reading from option file/string/map, customized envs can be filled according to object registry.\n* Improve range scan performance when using explicit user readahead by not creating new table readers for every iterator.\n* Add index type BlockBasedTableOptions::IndexType::kBinarySearchWithFirstKey. It significantly reduces read amplification in some setups, especially for iterator seeks. It's not fully implemented yet: IO errors are not handled right.\n\n### Public API Change\n* Change the behavior of OptimizeForPointLookup(): move away from hash-based block-based-table index, and use whole key memtable filtering.\n* Change the behavior of OptimizeForSmallDb(): use a 16MB block cache, put index and filter blocks into it, and cost the memtable size to it. DBOptions.OptimizeForSmallDb() and ColumnFamilyOptions.OptimizeForSmallDb() start to take an optional cache object.\n* Added BottommostLevelCompaction::kForceOptimized to avoid double compacting newly compacted files in the bottommost level compaction of manual compaction. Note this option may prohibit the manual compaction to produce a single file in the bottommost level.\n\n### Bug Fixes\n* Adjust WriteBufferManager's dummy entry size to block cache from 1MB to 256KB.\n* Fix a race condition between WritePrepared::Get and ::Put with duplicate keys.\n* Fix crash when memtable prefix bloom is enabled and read/write a key out of domain of prefix extractor.\n* Close a WAL file before another thread deletes it.\n* Fix an assertion failure `IsFlushPending() == true` caused by one bg thread releasing the db mutex in ~ColumnFamilyData and another thread clearing `flush_requested_` flag.\n\n## 6.1.1 (2019-04-09)\n### New Features\n* When reading from option file/string/map, customized comparators and/or merge operators can be filled according to object registry.\n\n### Public API Change\n\n### Bug Fixes\n* Fix a bug in 2PC where a sequence of txn prepare, memtable flush, and crash could result in losing the prepared transaction.\n* Fix a bug in Encryption Env which could cause encrypted files to be read beyond file boundaries.\n\n## 6.1.0 (2019-03-27)\n### New Features\n* Introduce two more stats levels, kExceptHistogramOrTimers and kExceptTimers.\n* Added a feature to perform data-block sampling for compressibility, and report stats to user.\n* Add support for trace filtering.\n* Add DBOptions.avoid_unnecessary_blocking_io. If true, we avoid file deletion when destroying ColumnFamilyHandle and Iterator. Instead, a job is scheduled to delete the files in background.\n\n### Public API Change\n* Remove bundled fbson library.\n* statistics.stats_level_ becomes atomic. It is preferred to use statistics.set_stats_level() and statistics.get_stats_level() to access it.\n* Introduce a new IOError subcode, PathNotFound, to indicate trying to open a nonexistent file or directory for read.\n* Add initial support for multiple db instances sharing the same data in single-writer, multi-reader mode.\n* Removed some \"using std::xxx\" from public headers.\n\n### Bug Fixes\n* Fix JEMALLOC_CXX_THROW macro missing from older Jemalloc versions, causing build failures on some platforms.\n* Fix SstFileReader not able to open file ingested with write_glbal_seqno=true.\n\n## 6.0.0 (2019-02-19)\n### New Features\n* Enabled checkpoint on readonly db (DBImplReadOnly).\n* Make DB ignore dropped column families while committing results of atomic flush.\n* RocksDB may choose to preopen some files even if options.max_open_files != -1. This may make DB open slightly longer.\n* For users of dictionary compression with ZSTD v0.7.0+, we now reuse the same digested dictionary when compressing each of an SST file's data blocks for faster compression speeds.\n* For all users of dictionary compression who set `cache_index_and_filter_blocks == true`, we now store dictionary data used for decompression in the block cache for better control over memory usage. For users of ZSTD v1.1.4+ who compile with -DZSTD_STATIC_LINKING_ONLY, this includes a digested dictionary, which is used to increase decompression speed.\n* Add support for block checksums verification for external SST files before ingestion.\n* Introduce stats history which periodically saves Statistics snapshots and added `GetStatsHistory` API to retrieve these snapshots.\n* Add a place holder in manifest which indicate a record from future that can be safely ignored.\n* Add support for trace sampling.\n* Enable properties block checksum verification for block-based tables.\n* For all users of dictionary compression, we now generate a separate dictionary for compressing each bottom-level SST file. Previously we reused a single dictionary for a whole compaction to bottom level. The new approach achieves better compression ratios; however, it uses more memory and CPU for buffering/sampling data blocks and training dictionaries.\n* Add whole key bloom filter support in memtable.\n* Files written by `SstFileWriter` will now use dictionary compression if it is configured in the file writer's `CompressionOptions`.\n\n### Public API Change\n* Disallow CompactionFilter::IgnoreSnapshots() = false, because it is not very useful and the behavior is confusing. The filter will filter everything if there is no snapshot declared by the time the compaction starts. However, users can define a snapshot after the compaction starts and before it finishes and this new snapshot won't be repeatable, because after the compaction finishes, some keys may be dropped.\n* CompactionPri = kMinOverlappingRatio also uses compensated file size, which boosts file with lots of tombstones to be compacted first.\n* Transaction::GetForUpdate is extended with a do_validate parameter with default value of true. If false it skips validating the snapshot before doing the read. Similarly ::Merge, ::Put, ::Delete, and ::SingleDelete are extended with assume_tracked with default value of false. If true it indicates that call is assumed to be after a ::GetForUpdate.\n* `TableProperties::num_entries` and `TableProperties::num_deletions` now also account for number of range tombstones.\n* Remove geodb, spatial_db, document_db, json_document, date_tiered_db, and redis_lists.\n* With \"ldb ----try_load_options\", when wal_dir specified by the option file doesn't exist, ignore it.\n* Change time resolution in FileOperationInfo.\n* Deleting Blob files also go through SStFileManager.\n* Remove CuckooHash memtable.\n* The counter stat `number.block.not_compressed` now also counts blocks not compressed due to poor compression ratio.\n* Remove ttl option from `CompactionOptionsFIFO`. The option has been deprecated and ttl in `ColumnFamilyOptions` is used instead.\n* Support SST file ingestion across multiple column families via DB::IngestExternalFiles. See the function's comment about atomicity.\n* Remove Lua compaction filter.\n\n### Bug Fixes\n* Fix a deadlock caused by compaction and file ingestion waiting for each other in the event of write stalls.\n* Fix a memory leak when files with range tombstones are read in mmap mode and block cache is enabled\n* Fix handling of corrupt range tombstone blocks such that corruptions cannot cause deleted keys to reappear\n* Lock free MultiGet\n* Fix incorrect `NotFound` point lookup result when querying the endpoint of a file that has been extended by a range tombstone.\n* Fix with pipelined write, write leaders's callback failure lead to the whole write group fail.\n\n### Change Default Options\n* Change options.compaction_pri's default to kMinOverlappingRatio\n\n## 5.18.0 (2018-11-30)\n### New Features\n* Introduced `JemallocNodumpAllocator` memory allocator. When being use, block cache will be excluded from core dump.\n* Introduced `PerfContextByLevel` as part of `PerfContext` which allows storing perf context at each level. Also replaced `__thread` with `thread_local` keyword for perf_context. Added per-level perf context for bloom filter and `Get` query.\n* With level_compaction_dynamic_level_bytes = true, level multiplier may be adjusted automatically when Level 0 to 1 compaction is lagged behind.\n* Introduced DB option `atomic_flush`. If true, RocksDB supports flushing multiple column families and atomically committing the result to MANIFEST. Useful when WAL is disabled.\n* Added `num_deletions` and `num_merge_operands` members to `TableProperties`.\n* Added \"rocksdb.min-obsolete-sst-number-to-keep\" DB property that reports the lower bound on SST file numbers that are being kept from deletion, even if the SSTs are obsolete.\n* Add xxhash64 checksum support\n* Introduced `MemoryAllocator`, which lets the user specify custom memory allocator for block based table.\n* Improved `DeleteRange` to prevent read performance degradation. The feature is no longer marked as experimental.\n\n### Public API Change\n* `DBOptions::use_direct_reads` now affects reads issued by `BackupEngine` on the database's SSTs.\n* `NO_ITERATORS` is divided into two counters `NO_ITERATOR_CREATED` and `NO_ITERATOR_DELETE`. Both of them are only increasing now, just as other counters.\n\n### Bug Fixes\n* Fix corner case where a write group leader blocked due to write stall blocks other writers in queue with WriteOptions::no_slowdown set.\n* Fix in-memory range tombstone truncation to avoid erroneously covering newer keys at a lower level, and include range tombstones in compacted files whose largest key is the range tombstone's start key.\n* Properly set the stop key for a truncated manual CompactRange\n* Fix slow flush/compaction when DB contains many snapshots. The problem became noticeable to us in DBs with 100,000+ snapshots, though it will affect others at different thresholds.\n* Fix the bug that WriteBatchWithIndex's SeekForPrev() doesn't see the entries with the same key.\n* Fix the bug where user comparator was sometimes fed with InternalKey instead of the user key. The bug manifests when during GenerateBottommostFiles.\n* Fix a bug in WritePrepared txns where if the number of old snapshots goes beyond the snapshot cache size (128 default) the rest will not be checked when evicting a commit entry from the commit cache.\n* Fixed Get correctness bug in the presence of range tombstones where merge operands covered by a range tombstone always result in NotFound.\n* Start populating `NO_FILE_CLOSES` ticker statistic, which was always zero previously.\n* The default value of NewBloomFilterPolicy()'s argument use_block_based_builder is changed to false. Note that this new default may cause large temp memory usage when building very large SST files.\n\n## 5.17.0 (2018-10-05)\n### Public API Change\n* `OnTableFileCreated` will now be called for empty files generated during compaction. In that case, `TableFileCreationInfo::file_path` will be \"(nil)\" and `TableFileCreationInfo::file_size` will be zero.\n* Add `FlushOptions::allow_write_stall`, which controls whether Flush calls start working immediately, even if it causes user writes to stall, or will wait until flush can be performed without causing write stall (similar to `CompactRangeOptions::allow_write_stall`). Note that the default value is false, meaning we add delay to Flush calls until stalling can be avoided when possible. This is behavior change compared to previous RocksDB versions, where Flush calls didn't check if they might cause stall or not.\n* Application using PessimisticTransactionDB is expected to rollback/commit recovered transactions before starting new ones. This assumption is used to skip concurrency control during recovery.\n* Expose column family id to `OnCompactionCompleted`.\n\n### New Features\n* TransactionOptions::skip_concurrency_control allows pessimistic transactions to skip the overhead of concurrency control. Could be used for optimizing certain transactions or during recovery.\n\n### Bug Fixes\n* Avoid creating empty SSTs and subsequently deleting them in certain cases during compaction.\n* Sync CURRENT file contents during checkpoint.\n\n## 5.16.3 (2018-10-01)\n### Bug Fixes\n* Fix crash caused when `CompactFiles` run with `CompactionOptions::compression == CompressionType::kDisableCompressionOption`. Now that setting causes the compression type to be chosen according to the column family-wide compression options.\n\n## 5.16.2 (2018-09-21)\n### Bug Fixes\n* Fix bug in partition filters with format_version=4.\n\n## 5.16.1 (2018-09-17)\n### Bug Fixes\n* Remove trace_analyzer_tool from rocksdb_lib target in TARGETS file.\n* Fix RocksDB Java build and tests.\n* Remove sync point in Block destructor.\n\n## 5.16.0 (2018-08-21)\n### Public API Change\n* The merge operands are passed to `MergeOperator::ShouldMerge` in the reversed order relative to how they were merged (passed to FullMerge or FullMergeV2) for performance reasons\n* GetAllKeyVersions() to take an extra argument of `max_num_ikeys`.\n* Using ZSTD dictionary trainer (i.e., setting `CompressionOptions::zstd_max_train_bytes` to a nonzero value) now requires ZSTD version 1.1.3 or later.\n\n### New Features\n* Changes the format of index blocks by delta encoding the index values, which are the block handles. This saves the encoding of BlockHandle::offset of the non-head index entries in each restart interval. The feature is backward compatible but not forward compatible. It is disabled by default unless format_version 4 or above is used.\n* Add a new tool: trace_analyzer. Trace_analyzer analyzes the trace file generated by using trace_replay API. It can convert the binary format trace file to a human readable txt file, output the statistics of the analyzed query types such as access statistics and size statistics, combining the dumped whole key space file to analyze, support query correlation analyzing, and etc. Current supported query types are: Get, Put, Delete, SingleDelete, DeleteRange, Merge, Iterator (Seek, SeekForPrev only).\n* Add hash index support to data blocks, which helps reducing the cpu utilization of point-lookup operations. This feature is backward compatible with the data block created without the hash index. It is disabled by default unless BlockBasedTableOptions::data_block_index_type is set to data_block_index_type = kDataBlockBinaryAndHash.\n\n### Bug Fixes\n* Fix a bug in misreporting the estimated partition index size in properties block.\n\n## 5.15.0 (2018-07-17)\n### Public API Change\n* Remove managed iterator. ReadOptions.managed is not effective anymore.\n* For bottommost_compression, a compatible CompressionOptions is added via `bottommost_compression_opts`. To keep backward compatible, a new boolean `enabled` is added to CompressionOptions. For compression_opts, it will be always used no matter what value of `enabled` is. For bottommost_compression_opts, it will only be used when user set `enabled=true`, otherwise, compression_opts will be used for bottommost_compression as default.\n* With LRUCache, when high_pri_pool_ratio > 0, midpoint insertion strategy will be enabled to put low-pri items to the tail of low-pri list (the midpoint) when they first inserted into the cache. This is to make cache entries never get hit age out faster, improving cache efficiency when large background scan presents.\n* For users of `Statistics` objects created via `CreateDBStatistics()`, the format of the string returned by its `ToString()` method has changed.\n* The \"rocksdb.num.entries\" table property no longer counts range deletion tombstones as entries.\n\n### New Features\n* Changes the format of index blocks by storing the key in their raw form rather than converting them to InternalKey. This saves 8 bytes per index key. The feature is backward compatible but not forward compatible. It is disabled by default unless format_version 3 or above is used.\n* Avoid memcpy when reading mmap files with OpenReadOnly and max_open_files==-1.\n* Support dynamically changing `ColumnFamilyOptions::ttl` via `SetOptions()`.\n* Add a new table property, \"rocksdb.num.range-deletions\", which counts the number of range deletion tombstones in the table.\n* Improve the performance of iterators doing long range scans by using readahead, when using direct IO.\n* pin_top_level_index_and_filter (default true) in BlockBasedTableOptions can be used in combination with cache_index_and_filter_blocks to prefetch and pin the top-level index of partitioned index and filter blocks in cache. It has no impact when cache_index_and_filter_blocks is false.\n* Write properties meta-block at the end of block-based table to save read-ahead IO.\n\n### Bug Fixes\n* Fix deadlock with enable_pipelined_write=true and max_successive_merges > 0\n* Check conflict at output level in CompactFiles.\n* Fix corruption in non-iterator reads when mmap is used for file reads\n* Fix bug with prefix search in partition filters where a shared prefix would be ignored from the later partitions. The bug could report an eixstent key as missing. The bug could be triggered if prefix_extractor is set and partition filters is enabled.\n* Change default value of `bytes_max_delete_chunk` to 0 in NewSstFileManager() as it doesn't work well with checkpoints.\n* Fix a bug caused by not copying the block trailer with compressed SST file, direct IO, prefetcher and no compressed block cache.\n* Fix write can stuck indefinitely if enable_pipelined_write=true. The issue exists since pipelined write was introduced in 5.5.0.\n\n## 5.14.0 (2018-05-16)\n### Public API Change\n* Add a BlockBasedTableOption to align uncompressed data blocks on the smaller of block size or page size boundary, to reduce flash reads by avoiding reads spanning 4K pages.\n* The background thread naming convention changed (on supporting platforms) to \"rocksdb:<thread pool priority><thread number>\", e.g., \"rocksdb:low0\".\n* Add a new ticker stat rocksdb.number.multiget.keys.found to count number of keys successfully read in MultiGet calls\n* Touch-up to write-related counters in PerfContext. New counters added: write_scheduling_flushes_compactions_time, write_thread_wait_nanos. Counters whose behavior was fixed or modified: write_memtable_time, write_pre_and_post_process_time, write_delay_time.\n* Posix Env's NewRandomRWFile() will fail if the file doesn't exist.\n* Now, `DBOptions::use_direct_io_for_flush_and_compaction` only applies to background writes, and `DBOptions::use_direct_reads` applies to both user reads and background reads. This conforms with Linux's `open(2)` manpage, which advises against simultaneously reading a file in buffered and direct modes, due to possibly undefined behavior and degraded performance.\n* Iterator::Valid() always returns false if !status().ok(). So, now when doing a Seek() followed by some Next()s, there's no need to check status() after every operation.\n* Iterator::Seek()/SeekForPrev()/SeekToFirst()/SeekToLast() always resets status().\n* Introduced `CompressionOptions::kDefaultCompressionLevel`, which is a generic way to tell RocksDB to use the compression library's default level. It is now the default value for `CompressionOptions::level`. Previously the level defaulted to -1, which gave poor compression ratios in ZSTD.\n\n### New Features\n* Introduce TTL for level compaction so that all files older than ttl go through the compaction process to get rid of old data.\n* TransactionDBOptions::write_policy can be configured to enable WritePrepared 2PC transactions. Read more about them in the wiki.\n* Add DB properties \"rocksdb.block-cache-capacity\", \"rocksdb.block-cache-usage\", \"rocksdb.block-cache-pinned-usage\" to show block cache usage.\n* Add `Env::LowerThreadPoolCPUPriority(Priority)` method, which lowers the CPU priority of background (esp. compaction) threads to minimize interference with foreground tasks.\n* Fsync parent directory after deleting a file in delete scheduler.\n* In level-based compaction, if bottom-pri thread pool was setup via `Env::SetBackgroundThreads()`, compactions to the bottom level will be delegated to that thread pool.\n* `prefix_extractor` has been moved from ImmutableCFOptions to MutableCFOptions, meaning it can be dynamically changed without a DB restart.\n\n### Bug Fixes\n* Fsync after writing global seq number to the ingestion file in ExternalSstFileIngestionJob.\n* Fix WAL corruption caused by race condition between user write thread and FlushWAL when two_write_queue is not set.\n* Fix `BackupableDBOptions::max_valid_backups_to_open` to not delete backup files when refcount cannot be accurately determined.\n* Fix memory leak when pin_l0_filter_and_index_blocks_in_cache is used with partitioned filters\n* Disable rollback of merge operands in WritePrepared transactions to work around an issue in MyRocks. It can be enabled back by setting TransactionDBOptions::rollback_merge_operands to true.\n* Fix wrong results by ReverseBytewiseComparator::FindShortSuccessor()\n\n### Java API Changes\n* Add `BlockBasedTableConfig.setBlockCache` to allow sharing a block cache across DB instances.\n* Added SstFileManager to the Java API to allow managing SST files across DB instances.\n\n## 5.13.0 (2018-03-20)\n### Public API Change\n* RocksDBOptionsParser::Parse()'s `ignore_unknown_options` argument will only be effective if the option file shows it is generated using a higher version of RocksDB than the current version.\n* Remove CompactionEventListener.\n\n### New Features\n* SstFileManager now can cancel compactions if they will result in max space errors. SstFileManager users can also use SetCompactionBufferSize to specify how much space must be leftover during a compaction for auxiliary file functions such as logging and flushing.\n* Avoid unnecessarily flushing in `CompactRange()` when the range specified by the user does not overlap unflushed memtables.\n* If `ColumnFamilyOptions::max_subcompactions` is set greater than one, we now parallelize large manual level-based compactions.\n* Add \"rocksdb.live-sst-files-size\" DB property to return total bytes of all SST files belong to the latest LSM tree.\n* NewSstFileManager to add an argument bytes_max_delete_chunk with default 64MB. With this argument, a file larger than 64MB will be ftruncated multiple times based on this size.\n\n### Bug Fixes\n* Fix a leak in prepared_section_completed_ where the zeroed entries would not removed from the map.\n* Fix WAL corruption caused by race condition between user write thread and backup/checkpoint thread.\n\n## 5.12.0 (2018-02-14)\n### Public API Change\n* Iterator::SeekForPrev is now a pure virtual method. This is to prevent user who implement the Iterator interface fail to implement SeekForPrev by mistake.\n* Add `include_end` option to make the range end exclusive when `include_end == false` in `DeleteFilesInRange()`.\n* Add `CompactRangeOptions::allow_write_stall`, which makes `CompactRange` start working immediately, even if it causes user writes to stall. The default value is false, meaning we add delay to `CompactRange` calls until stalling can be avoided when possible. Note this delay is not present in previous RocksDB versions.\n* Creating checkpoint with empty directory now returns `Status::InvalidArgument`; previously, it returned `Status::IOError`.\n* Adds a BlockBasedTableOption to turn off index block compression.\n* Close() method now returns a status when closing a db.\n\n### New Features\n* Improve the performance of iterators doing long range scans by using readahead.\n* Add new function `DeleteFilesInRanges()` to delete files in multiple ranges at once for better performance.\n* FreeBSD build support for RocksDB and RocksJava.\n* Improved performance of long range scans with readahead.\n* Updated to and now continuously tested in Visual Studio 2017.\n\n### Bug Fixes\n* Fix `DisableFileDeletions()` followed by `GetSortedWalFiles()` to not return obsolete WAL files that `PurgeObsoleteFiles()` is going to delete.\n* Fix Handle error return from WriteBuffer() during WAL file close and DB close.\n* Fix advance reservation of arena block addresses.\n* Fix handling of empty string as checkpoint directory.\n\n## 5.11.0 (2018-01-08)\n### Public API Change\n* Add `autoTune` and `getBytesPerSecond()` to RocksJava RateLimiter\n\n### New Features\n* Add a new histogram stat called rocksdb.db.flush.micros for memtable flush.\n* Add \"--use_txn\" option to use transactional API in db_stress.\n* Disable onboard cache for compaction output in Windows platform.\n* Improve the performance of iterators doing long range scans by using readahead.\n\n### Bug Fixes\n* Fix a stack-use-after-scope bug in ForwardIterator.\n* Fix builds on platforms including Linux, Windows, and PowerPC.\n* Fix buffer overrun in backup engine for DBs with huge number of files.\n* Fix a mislabel bug for bottom-pri compaction threads.\n* Fix DB::Flush() keep waiting after flush finish under certain condition.\n\n## 5.10.0 (2017-12-11)\n### Public API Change\n* When running `make` with environment variable `USE_SSE` set and `PORTABLE` unset, will use all machine features available locally. Previously this combination only compiled SSE-related features.\n\n### New Features\n* Provide lifetime hints when writing files on Linux. This reduces hardware write-amp on storage devices supporting multiple streams.\n* Add a DB stat, `NUMBER_ITER_SKIP`, which returns how many internal keys were skipped during iterations (e.g., due to being tombstones or duplicate versions of a key).\n* Add PerfContext counters, `key_lock_wait_count` and `key_lock_wait_time`, which measure the number of times transactions wait on key locks and total amount of time waiting.\n\n### Bug Fixes\n* Fix IOError on WAL write doesn't propagate to write group follower\n* Make iterator invalid on merge error.\n* Fix performance issue in `IngestExternalFile()` affecting databases with large number of SST files.\n* Fix possible corruption to LSM structure when `DeleteFilesInRange()` deletes a subset of files spanned by a `DeleteRange()` marker.\n\n## 5.9.0 (2017-11-01)\n### Public API Change\n* `BackupableDBOptions::max_valid_backups_to_open == 0` now means no backups will be opened during BackupEngine initialization. Previously this condition disabled limiting backups opened.\n* `DBOptions::preserve_deletes` is a new option that allows one to specify that DB should not drop tombstones for regular deletes if they have sequence number larger than what was set by the new API call `DB::SetPreserveDeletesSequenceNumber(SequenceNumber seqnum)`. Disabled by default.\n* API call `DB::SetPreserveDeletesSequenceNumber(SequenceNumber seqnum)` was added, users who wish to preserve deletes are expected to periodically call this function to advance the cutoff seqnum (all deletes made before this seqnum can be dropped by DB). It's user responsibility to figure out how to advance the seqnum in the way so the tombstones are kept for the desired period of time, yet are eventually processed in time and don't eat up too much space.\n* `ReadOptions::iter_start_seqnum` was added;\nif set to something > 0 user will see 2 changes in iterators behavior 1) only keys written with sequence larger than this parameter would be returned and 2) the `Slice` returned by iter->key() now points to the memory that keep User-oriented representation of the internal key, rather than user key. New struct `FullKey` was added to represent internal keys, along with a new helper function `ParseFullKey(const Slice& internal_key, FullKey* result);`.\n* Deprecate trash_dir param in NewSstFileManager, right now we will rename deleted files to <name>.trash instead of moving them to trash directory\n* Allow setting a custom trash/DB size ratio limit in the SstFileManager, after which files that are to be scheduled for deletion are deleted immediately, regardless of any delete ratelimit.\n* Return an error on write if write_options.sync = true and write_options.disableWAL = true to warn user of inconsistent options. Previously we will not write to WAL and not respecting the sync options in this case.\n\n### New Features\n* CRC32C is now using the 3-way pipelined SSE algorithm `crc32c_3way` on supported platforms to improve performance. The system will choose to use this algorithm on supported platforms automatically whenever possible. If PCLMULQDQ is not supported it will fall back to the old Fast_CRC32 algorithm.\n* `DBOptions::writable_file_max_buffer_size` can now be changed dynamically.\n* `DBOptions::bytes_per_sync`, `DBOptions::compaction_readahead_size`, and `DBOptions::wal_bytes_per_sync` can now be changed dynamically, `DBOptions::wal_bytes_per_sync` will flush all memtables and switch to a new WAL file.\n* Support dynamic adjustment of rate limit according to demand for background I/O. It can be enabled by passing `true` to the `auto_tuned` parameter in `NewGenericRateLimiter()`. The value passed as `rate_bytes_per_sec` will still be respected as an upper-bound.\n* Support dynamically changing `ColumnFamilyOptions::compaction_options_fifo`.\n* Introduce `EventListener::OnStallConditionsChanged()` callback. Users can implement it to be notified when user writes are stalled, stopped, or resumed.\n* Add a new db property \"rocksdb.estimate-oldest-key-time\" to return oldest data timestamp. The property is available only for FIFO compaction with compaction_options_fifo.allow_compaction = false.\n* Upon snapshot release, recompact bottommost files containing deleted/overwritten keys that previously could not be dropped due to the snapshot. This alleviates space-amp caused by long-held snapshots.\n* Support lower bound on iterators specified via `ReadOptions::iterate_lower_bound`.\n* Support for differential snapshots (via iterator emitting the sequence of key-values representing the difference between DB state at two different sequence numbers). Supports preserving and emitting puts and regular deletes, doesn't support SingleDeletes, MergeOperator, Blobs and Range Deletes.\n\n### Bug Fixes\n* Fix a potential data inconsistency issue during point-in-time recovery. `DB:Open()` will abort if column family inconsistency is found during PIT recovery.\n* Fix possible metadata corruption in databases using `DeleteRange()`.\n\n## 5.8.0 (2017-08-30)\n### Public API Change\n* Users of `Statistics::getHistogramString()` will see fewer histogram buckets and different bucket endpoints.\n* `Slice::compare` and BytewiseComparator `Compare` no longer accept `Slice`s containing nullptr.\n* `Transaction::Get` and `Transaction::GetForUpdate` variants with `PinnableSlice` added.\n\n### New Features\n* Add Iterator::Refresh(), which allows users to update the iterator state so that they can avoid some initialization costs of recreating iterators.\n* Replace dynamic_cast<> (except unit test) so people can choose to build with RTTI off. With make, release mode is by default built with -fno-rtti and debug mode is built without it. Users can override it by setting USE_RTTI=0 or 1.\n* Universal compactions including the bottom level can be executed in a dedicated thread pool. This alleviates head-of-line blocking in the compaction queue, which cause write stalling, particularly in multi-instance use cases. Users can enable this feature via `Env::SetBackgroundThreads(N, Env::Priority::BOTTOM)`, where `N > 0`.\n* Allow merge operator to be called even with a single merge operand during compactions, by appropriately overriding `MergeOperator::AllowSingleOperand`.\n* Add `DB::VerifyChecksum()`, which verifies the checksums in all SST files in a running DB.\n* Block-based table support for disabling checksums by setting `BlockBasedTableOptions::checksum = kNoChecksum`.\n\n### Bug Fixes\n* Fix wrong latencies in `rocksdb.db.get.micros`, `rocksdb.db.write.micros`, and `rocksdb.sst.read.micros`.\n* Fix incorrect dropping of deletions during intra-L0 compaction.\n* Fix transient reappearance of keys covered by range deletions when memtable prefix bloom filter is enabled.\n* Fix potentially wrong file smallest key when range deletions separated by snapshot are written together.\n\n## 5.7.0 (2017-07-13)\n### Public API Change\n* DB property \"rocksdb.sstables\" now prints keys in hex form.\n\n### New Features\n* Measure estimated number of reads per file. The information can be accessed through DB::GetColumnFamilyMetaData or \"rocksdb.sstables\" DB property.\n* RateLimiter support for throttling background reads, or throttling the sum of background reads and writes. This can give more predictable I/O usage when compaction reads more data than it writes, e.g., due to lots of deletions.\n* [Experimental] FIFO compaction with TTL support. It can be enabled by setting CompactionOptionsFIFO.ttl > 0.\n* Introduce `EventListener::OnBackgroundError()` callback. Users can implement it to be notified of errors causing the DB to enter read-only mode, and optionally override them.\n* Partitioned Index/Filters exiting the experimental mode. To enable partitioned indexes set index_type to kTwoLevelIndexSearch and to further enable partitioned filters set partition_filters to true. To configure the partition size set metadata_block_size.\n\n\n### Bug Fixes\n* Fix discarding empty compaction output files when `DeleteRange()` is used together with subcompactions.\n\n## 5.6.0 (2017-06-06)\n### Public API Change\n* Scheduling flushes and compactions in the same thread pool is no longer supported by setting `max_background_flushes=0`. Instead, users can achieve this by configuring their high-pri thread pool to have zero threads.\n* Replace `Options::max_background_flushes`, `Options::max_background_compactions`, and `Options::base_background_compactions` all with `Options::max_background_jobs`, which automatically decides how many threads to allocate towards flush/compaction.\n* options.delayed_write_rate by default take the value of options.rate_limiter rate.\n* Replace global variable `IOStatsContext iostats_context` with `IOStatsContext* get_iostats_context()`; replace global variable `PerfContext perf_context` with `PerfContext* get_perf_context()`.\n\n### New Features\n* Change ticker/histogram statistics implementations to use core-local storage. This improves aggregation speed compared to our previous thread-local approach, particularly for applications with many threads.\n* Users can pass a cache object to write buffer manager, so that they can cap memory usage for memtable and block cache using one single limit.\n* Flush will be triggered when 7/8 of the limit introduced by write_buffer_manager or db_write_buffer_size is triggered, so that the hard threshold is hard to hit.\n* Introduce WriteOptions.low_pri. If it is true, low priority writes will be throttled if the compaction is behind.\n* `DB::IngestExternalFile()` now supports ingesting files into a database containing range deletions.\n\n### Bug Fixes\n* Shouldn't ignore return value of fsync() in flush.\n\n## 5.5.0 (2017-05-17)\n### New Features\n* FIFO compaction to support Intra L0 compaction too with CompactionOptionsFIFO.allow_compaction=true.\n* DB::ResetStats() to reset internal stats.\n* Statistics::Reset() to reset user stats.\n* ldb add option --try_load_options, which will open DB with its own option file.\n* Introduce WriteBatch::PopSavePoint to pop the most recent save point explicitly.\n* Support dynamically change `max_open_files` option via SetDBOptions()\n* Added DB::CreateColumnFamilie() and DB::DropColumnFamilies() to bulk create/drop column families.\n* Add debugging function `GetAllKeyVersions` to see internal versions of a range of keys.\n* Support file ingestion with universal compaction style\n* Support file ingestion behind with option `allow_ingest_behind`\n* New option enable_pipelined_write which may improve write throughput in case writing from multiple threads and WAL enabled.\n\n### Bug Fixes\n* Fix the bug that Direct I/O uses direct reads for non-SST file\n\n## 5.4.0 (2017-04-11)\n### Public API Change\n* random_access_max_buffer_size no longer has any effect\n* Removed Env::EnableReadAhead(), Env::ShouldForwardRawRequest()\n* Support dynamically change `stats_dump_period_sec` option via SetDBOptions().\n* Added ReadOptions::max_skippable_internal_keys to set a threshold to fail a request as incomplete when too many keys are being skipped when using iterators.\n* DB::Get in place of std::string accepts PinnableSlice, which avoids the extra memcpy of value to std::string in most of cases.\n    * PinnableSlice releases the pinned resources that contain the value when it is destructed or when ::Reset() is called on it.\n    * The old API that accepts std::string, although discouraged, is still supported.\n* Replace Options::use_direct_writes with Options::use_direct_io_for_flush_and_compaction. Read Direct IO wiki for details.\n* Added CompactionEventListener and EventListener::OnFlushBegin interfaces.\n\n### New Features\n* Memtable flush can be avoided during checkpoint creation if total log file size is smaller than a threshold specified by the user.\n* Introduce level-based L0->L0 compactions to reduce file count, so write delays are incurred less often.\n* (Experimental) Partitioning filters which creates an index on the partitions. The feature can be enabled by setting partition_filters when using kFullFilter. Currently the feature also requires two-level indexing to be enabled. Number of partitions is the same as the number of partitions for indexes, which is controlled by metadata_block_size.\n\n## 5.3.0 (2017-03-08)\n### Public API Change\n* Remove disableDataSync option.\n* Remove timeout_hint_us option from WriteOptions. The option has been deprecated and has no effect since 3.13.0.\n* Remove option min_partial_merge_operands. Partial merge operands will always be merged in flush or compaction if there are more than one.\n* Remove option verify_checksums_in_compaction. Compaction will always verify checksum.\n\n### Bug Fixes\n* Fix the bug that iterator may skip keys\n\n## 5.2.0 (2017-02-08)\n### Public API Change\n* NewLRUCache() will determine number of shard bits automatically based on capacity, if the user doesn't pass one. This also impacts the default block cache when the user doesn't explicit provide one.\n* Change the default of delayed slowdown value to 16MB/s and further increase the L0 stop condition to 36 files.\n* Options::use_direct_writes and Options::use_direct_reads are now ready to use.\n* (Experimental) Two-level indexing that partition the index and creates a 2nd level index on the partitions. The feature can be enabled by setting kTwoLevelIndexSearch as IndexType and configuring index_per_partition.\n\n### New Features\n* Added new overloaded function GetApproximateSizes that allows to specify if memtable stats should be computed only without computing SST files' stats approximations.\n* Added new function GetApproximateMemTableStats that approximates both number of records and size of memtables.\n* Add Direct I/O mode for SST file I/O\n\n### Bug Fixes\n* RangeSync() should work if ROCKSDB_FALLOCATE_PRESENT is not set\n* Fix wrong results in a data race case in Get()\n* Some fixes related to 2PC.\n* Fix bugs of data corruption in direct I/O\n\n## 5.1.0 (2017-01-13)\n* Support dynamically change `delete_obsolete_files_period_micros` option via SetDBOptions().\n* Added EventListener::OnExternalFileIngested which will be called when IngestExternalFile() add a file successfully.\n* BackupEngine::Open and BackupEngineReadOnly::Open now always return error statuses matching those of the backup Env.\n\n### Bug Fixes\n* Fix the bug that if 2PC is enabled, checkpoints may loss some recent transactions.\n* When file copying is needed when creating checkpoints or bulk loading files, fsync the file after the file copying.\n\n## 5.0.0 (2016-11-17)\n### Public API Change\n* Options::max_bytes_for_level_multiplier is now a double along with all getters and setters.\n* Support dynamically change `delayed_write_rate` and `max_total_wal_size` options via SetDBOptions().\n* Introduce DB::DeleteRange for optimized deletion of large ranges of contiguous keys.\n* Support dynamically change `delayed_write_rate` option via SetDBOptions().\n* Options::allow_concurrent_memtable_write and Options::enable_write_thread_adaptive_yield are now true by default.\n* Remove Tickers::SEQUENCE_NUMBER to avoid confusion if statistics object is shared among RocksDB instance. Alternatively DB::GetLatestSequenceNumber() can be used to get the same value.\n* Options.level0_stop_writes_trigger default value changes from 24 to 32.\n* New compaction filter API: CompactionFilter::FilterV2(). Allows to drop ranges of keys.\n* Removed flashcache support.\n* DB::AddFile() is deprecated and is replaced with DB::IngestExternalFile(). DB::IngestExternalFile() remove all the restrictions that existed for DB::AddFile.\n\n### New Features\n* Add avoid_flush_during_shutdown option, which speeds up DB shutdown by not flushing unpersisted data (i.e. with disableWAL = true). Unpersisted data will be lost. The options is dynamically changeable via SetDBOptions().\n* Add memtable_insert_with_hint_prefix_extractor option. The option is mean to reduce CPU usage for inserting keys into memtable, if keys can be group by prefix and insert for each prefix are sequential or almost sequential. See include/rocksdb/options.h for more details.\n* Add LuaCompactionFilter in utilities.  This allows developers to write compaction filters in Lua.  To use this feature, LUA_PATH needs to be set to the root directory of Lua.\n* No longer populate \"LATEST_BACKUP\" file in backup directory, which formerly contained the number of the latest backup. The latest backup can be determined by finding the highest numbered file in the \"meta/\" subdirectory.\n\n## 4.13.0 (2016-10-18)\n### Public API Change\n* DB::GetOptions() reflect dynamic changed options (i.e. through DB::SetOptions()) and return copy of options instead of reference.\n* Added Statistics::getAndResetTickerCount().\n\n### New Features\n* Add DB::SetDBOptions() to dynamic change base_background_compactions and max_background_compactions.\n* Added Iterator::SeekForPrev(). This new API will seek to the last key that less than or equal to the target key.\n\n## 4.12.0 (2016-09-12)\n### Public API Change\n* CancelAllBackgroundWork() flushes all memtables for databases containing writes that have bypassed the WAL (writes issued with WriteOptions::disableWAL=true) before shutting down background threads.\n* Merge options source_compaction_factor, max_grandparent_overlap_bytes and expanded_compaction_factor into max_compaction_bytes.\n* Remove ImmutableCFOptions.\n* Add a compression type ZSTD, which can work with ZSTD 0.8.0 or up. Still keep ZSTDNotFinal for compatibility reasons.\n\n### New Features\n* Introduce NewClockCache, which is based on CLOCK algorithm with better concurrent performance in some cases. It can be used to replace the default LRU-based block cache and table cache. To use it, RocksDB need to be linked with TBB lib.\n* Change ticker/histogram statistics implementations to accumulate data in thread-local storage, which improves CPU performance by reducing cache coherency costs. Callers of CreateDBStatistics do not need to change anything to use this feature.\n* Block cache mid-point insertion, where index and filter block are inserted into LRU block cache with higher priority. The feature can be enabled by setting BlockBasedTableOptions::cache_index_and_filter_blocks_with_high_priority to true and high_pri_pool_ratio > 0 when creating NewLRUCache.\n\n## 4.11.0 (2016-08-01)\n### Public API Change\n* options.memtable_prefix_bloom_huge_page_tlb_size => memtable_huge_page_size. When it is set, RocksDB will try to allocate memory from huge page for memtable too, rather than just memtable bloom filter.\n\n### New Features\n* A tool to migrate DB after options change. See include/rocksdb/utilities/option_change_migration.h.\n* Add ReadOptions.background_purge_on_iterator_cleanup. If true, we avoid file deletion when destroying iterators.\n\n## 4.10.0 (2016-07-05)\n### Public API Change\n* options.memtable_prefix_bloom_bits changes to options.memtable_prefix_bloom_bits_ratio and deprecate options.memtable_prefix_bloom_probes\n* enum type CompressionType and PerfLevel changes from char to unsigned char. Value of all PerfLevel shift by one.\n* Deprecate options.filter_deletes.\n\n### New Features\n* Add avoid_flush_during_recovery option.\n* Add a read option background_purge_on_iterator_cleanup to avoid deleting files in foreground when destroying iterators. Instead, a job is scheduled in high priority queue and would be executed in a separate background thread.\n* RepairDB support for column families. RepairDB now associates data with non-default column families using information embedded in the SST/WAL files (4.7 or later). For data written by 4.6 or earlier, RepairDB associates it with the default column family.\n* Add options.write_buffer_manager which allows users to control total memtable sizes across multiple DB instances.\n\n## 4.9.0 (2016-06-09)\n### Public API changes\n* Add bottommost_compression option, This option can be used to set a specific compression algorithm for the bottommost level (Last level containing files in the DB).\n* Introduce CompactionJobInfo::compression, This field state the compression algorithm used to generate the output files of the compaction.\n* Deprecate BlockBaseTableOptions.hash_index_allow_collision=false\n* Deprecate options builder (GetOptions()).\n\n### New Features\n* Introduce NewSimCache() in rocksdb/utilities/sim_cache.h. This function creates a block cache that is able to give simulation results (mainly hit rate) of simulating block behavior with a configurable cache size.\n\n## 4.8.0 (2016-05-02)\n### Public API Change\n* Allow preset compression dictionary for improved compression of block-based tables. This is supported for zlib, zstd, and lz4. The compression dictionary's size is configurable via CompressionOptions::max_dict_bytes.\n* Delete deprecated classes for creating backups (BackupableDB) and restoring from backups (RestoreBackupableDB). Now, BackupEngine should be used for creating backups, and BackupEngineReadOnly should be used for restorations. For more details, see https://github.com/facebook/rocksdb/wiki/How-to-backup-RocksDB%3F\n* Expose estimate of per-level compression ratio via DB property: \"rocksdb.compression-ratio-at-levelN\".\n* Added EventListener::OnTableFileCreationStarted. EventListener::OnTableFileCreated will be called on failure case. User can check creation status via TableFileCreationInfo::status.\n\n### New Features\n* Add ReadOptions::readahead_size. If non-zero, NewIterator will create a new table reader which performs reads of the given size.\n\n## 4.7.0 (2016-04-08)\n### Public API Change\n* rename options compaction_measure_io_stats to report_bg_io_stats and include flush too.\n* Change some default options. Now default options will optimize for server-workloads. Also enable slowdown and full stop triggers for pending compaction bytes. These changes may cause sub-optimal performance or significant increase of resource usage. To avoid these risks, users can open existing RocksDB with options extracted from RocksDB option files. See https://github.com/facebook/rocksdb/wiki/RocksDB-Options-File for how to use RocksDB option files. Or you can call Options.OldDefaults() to recover old defaults. DEFAULT_OPTIONS_HISTORY.md will track change history of default options.\n\n## 4.6.0 (2016-03-10)\n### Public API Changes\n* Change default of BlockBasedTableOptions.format_version to 2. It means default DB created by 4.6 or up cannot be opened by RocksDB version 3.9 or earlier.\n* Added strict_capacity_limit option to NewLRUCache. If the flag is set to true, insert to cache will fail if no enough capacity can be free. Signature of Cache::Insert() is updated accordingly.\n* Tickers [NUMBER_DB_NEXT, NUMBER_DB_PREV, NUMBER_DB_NEXT_FOUND, NUMBER_DB_PREV_FOUND, ITER_BYTES_READ] are not updated immediately. The are updated when the Iterator is deleted.\n* Add monotonically increasing counter (DB property \"rocksdb.current-super-version-number\") that increments upon any change to the LSM tree.\n\n### New Features\n* Add CompactionPri::kMinOverlappingRatio, a compaction picking mode friendly to write amplification.\n* Deprecate Iterator::IsKeyPinned() and replace it with Iterator::GetProperty() with prop_name=\"rocksdb.iterator.is.key.pinned\"\n\n## 4.5.0 (2016-02-05)\n### Public API Changes\n* Add a new perf context level between kEnableCount and kEnableTime. Level 2 now does not include timers for mutexes.\n* Statistics of mutex operation durations will not be measured by default. If you want to have them enabled, you need to set Statistics::stats_level_ to kAll.\n* DBOptions::delete_scheduler and NewDeleteScheduler() are removed, please use DBOptions::sst_file_manager and NewSstFileManager() instead\n\n### New Features\n* ldb tool now supports operations to non-default column families.\n* Add kPersistedTier to ReadTier.  This option allows Get and MultiGet to read only the persited data and skip mem-tables if writes were done with disableWAL = true.\n* Add DBOptions::sst_file_manager. Use NewSstFileManager() in include/rocksdb/sst_file_manager.h to create a SstFileManager that can be used to track the total size of SST files and control the SST files deletion rate.\n\n## 4.4.0 (2016-01-14)\n### Public API Changes\n* Change names in CompactionPri and add a new one.\n* Deprecate options.soft_rate_limit and add options.soft_pending_compaction_bytes_limit.\n* If options.max_write_buffer_number > 3, writes will be slowed down when writing to the last write buffer to delay a full stop.\n* Introduce CompactionJobInfo::compaction_reason, this field include the reason to trigger the compaction.\n* After slow down is triggered, if estimated pending compaction bytes keep increasing, slowdown more.\n* Increase default options.delayed_write_rate to 2MB/s.\n* Added a new parameter --path to ldb tool. --path accepts the name of either MANIFEST, SST or a WAL file. Either --db or --path can be used when calling ldb.\n\n## 4.3.0 (2015-12-08)\n### New Features\n* CompactionFilter has new member function called IgnoreSnapshots which allows CompactionFilter to be called even if there are snapshots later than the key.\n* RocksDB will now persist options under the same directory as the RocksDB database on successful DB::Open, CreateColumnFamily, DropColumnFamily, and SetOptions.\n* Introduce LoadLatestOptions() in rocksdb/utilities/options_util.h.  This function can construct the latest DBOptions / ColumnFamilyOptions used by the specified RocksDB intance.\n* Introduce CheckOptionsCompatibility() in rocksdb/utilities/options_util.h.  This function checks whether the input set of options is able to open the specified DB successfully.\n\n### Public API Changes\n* When options.db_write_buffer_size triggers, only the column family with the largest column family size will be flushed, not all the column families.\n\n## 4.2.0 (2015-11-09)\n### New Features\n* Introduce CreateLoggerFromOptions(), this function create a Logger for provided DBOptions.\n* Add GetAggregatedIntProperty(), which returns the sum of the GetIntProperty of all the column families.\n* Add MemoryUtil in rocksdb/utilities/memory.h.  It currently offers a way to get the memory usage by type from a list rocksdb instances.\n\n### Public API Changes\n* CompactionFilter::Context includes information of Column Family ID\n* The need-compaction hint given by TablePropertiesCollector::NeedCompact() will be persistent and recoverable after DB recovery. This introduces a breaking format change. If you use this experimental feature, including NewCompactOnDeletionCollectorFactory() in the new version, you may not be able to directly downgrade the DB back to version 4.0 or lower.\n* TablePropertiesCollectorFactory::CreateTablePropertiesCollector() now takes an option Context, containing the information of column family ID for the file being written.\n* Remove DefaultCompactionFilterFactory.\n\n\n## 4.1.0 (2015-10-08)\n### New Features\n* Added single delete operation as a more efficient way to delete keys that have not been overwritten.\n* Added experimental AddFile() to DB interface that allow users to add files created by SstFileWriter into an empty Database, see include/rocksdb/sst_file_writer.h and DB::AddFile() for more info.\n* Added support for opening SST files with .ldb suffix which enables opening LevelDB databases.\n* CompactionFilter now supports filtering of merge operands and merge results.\n\n### Public API Changes\n* Added SingleDelete() to the DB interface.\n* Added AddFile() to DB interface.\n* Added SstFileWriter class.\n* CompactionFilter has a new method FilterMergeOperand() that RocksDB applies to every merge operand during compaction to decide whether to filter the operand.\n* We removed CompactionFilterV2 interfaces from include/rocksdb/compaction_filter.h. The functionality was deprecated already in version 3.13.\n\n## 4.0.0 (2015-09-09)\n### New Features\n* Added support for transactions.  See include/rocksdb/utilities/transaction.h for more info.\n* DB::GetProperty() now accepts \"rocksdb.aggregated-table-properties\" and \"rocksdb.aggregated-table-properties-at-levelN\", in which case it returns aggregated table properties of the target column family, or the aggregated table properties of the specified level N if the \"at-level\" version is used.\n* Add compression option kZSTDNotFinalCompression for people to experiment ZSTD although its format is not finalized.\n* We removed the need for LATEST_BACKUP file in BackupEngine. We still keep writing it when we create new backups (because of backward compatibility), but we don't read it anymore.\n\n### Public API Changes\n* Removed class Env::RandomRWFile and Env::NewRandomRWFile().\n* Renamed DBOptions.num_subcompactions to DBOptions.max_subcompactions to make the name better match the actual functionality of the option.\n* Added Equal() method to the Comparator interface that can optionally be overwritten in cases where equality comparisons can be done more efficiently than three-way comparisons.\n* Previous 'experimental' OptimisticTransaction class has been replaced by Transaction class.\n\n## 3.13.0 (2015-08-06)\n### New Features\n* RollbackToSavePoint() in WriteBatch/WriteBatchWithIndex\n* Add NewCompactOnDeletionCollectorFactory() in utilities/table_properties_collectors, which allows rocksdb to mark a SST file as need-compaction when it observes at least D deletion entries in any N consecutive entries in that SST file.  Note that this feature depends on an experimental NeedCompact() API --- the result of this API will not persist after DB restart.\n* Add DBOptions::delete_scheduler. Use NewDeleteScheduler() in include/rocksdb/delete_scheduler.h to create a DeleteScheduler that can be shared among multiple RocksDB instances to control the file deletion rate of SST files that exist in the first db_path.\n\n### Public API Changes\n* Deprecated WriteOptions::timeout_hint_us. We no longer support write timeout. If you really need this option, talk to us and we might consider returning it.\n* Deprecated purge_redundant_kvs_while_flush option.\n* Removed BackupEngine::NewBackupEngine() and NewReadOnlyBackupEngine() that were deprecated in RocksDB 3.8. Please use BackupEngine::Open() instead.\n* Deprecated Compaction Filter V2. We are not aware of any existing use-cases. If you use this filter, your compile will break with RocksDB 3.13. Please let us know if you use it and we'll put it back in RocksDB 3.14.\n* Env::FileExists now returns a Status instead of a boolean\n* Add statistics::getHistogramString() to print detailed distribution of a histogram metric.\n* Add DBOptions::skip_stats_update_on_db_open.  When it is on, DB::Open() will run faster as it skips the random reads required for loading necessary stats from SST files to optimize compaction.\n\n## 3.12.0 (2015-07-02)\n### New Features\n* Added experimental support for optimistic transactions.  See include/rocksdb/utilities/optimistic_transaction.h for more info.\n* Added a new way to report QPS from db_bench (check out --report_file and --report_interval_seconds)\n* Added a cache for individual rows. See DBOptions::row_cache for more info.\n* Several new features on EventListener (see include/rocksdb/listener.h):\n - OnCompactionCompleted() now returns per-compaction job statistics, defined in include/rocksdb/compaction_job_stats.h.\n - Added OnTableFileCreated() and OnTableFileDeleted().\n* Add compaction_options_universal.enable_trivial_move to true, to allow trivial move while performing universal compaction. Trivial move will happen only when all the input files are non overlapping.\n\n### Public API changes\n* EventListener::OnFlushCompleted() now passes FlushJobInfo instead of a list of parameters.\n* DB::GetDbIdentity() is now a const function.  If this function is overridden in your application, be sure to also make GetDbIdentity() const to avoid compile error.\n* Move listeners from ColumnFamilyOptions to DBOptions.\n* Add max_write_buffer_number_to_maintain option\n* DB::CompactRange()'s parameter reduce_level is changed to change_level, to allow users to move levels to lower levels if allowed. It can be used to migrate a DB from options.level_compaction_dynamic_level_bytes=false to options.level_compaction_dynamic_level_bytes.true.\n* Change default value for options.compaction_filter_factory and options.compaction_filter_factory_v2 to nullptr instead of DefaultCompactionFilterFactory and DefaultCompactionFilterFactoryV2.\n* If CancelAllBackgroundWork is called without doing a flush after doing loads with WAL disabled, the changes which haven't been flushed before the call to CancelAllBackgroundWork will be lost.\n* WBWIIterator::Entry() now returns WriteEntry instead of `const WriteEntry&`\n* options.hard_rate_limit is deprecated.\n* When options.soft_rate_limit or options.level0_slowdown_writes_trigger is triggered, the way to slow down writes is changed to: write rate to DB is limited to to options.delayed_write_rate.\n* DB::GetApproximateSizes() adds a parameter to allow the estimation to include data in mem table, with default to be not to include. It is now only supported in skip list mem table.\n* DB::CompactRange() now accept CompactRangeOptions instead of multiple parameters. CompactRangeOptions is defined in include/rocksdb/options.h.\n* CompactRange() will now skip bottommost level compaction for level based compaction if there is no compaction filter, bottommost_level_compaction is introduced in CompactRangeOptions to control when it's possible to skip bottommost level compaction. This mean that if you want the compaction to produce a single file you need to set bottommost_level_compaction to BottommostLevelCompaction::kForce.\n* Add Cache.GetPinnedUsage() to get the size of memory occupied by entries that are in use by the system.\n* DB:Open() will fail if the compression specified in Options is not linked with the binary. If you see this failure, recompile RocksDB with compression libraries present on your system. Also, previously our default compression was snappy. This behavior is now changed. Now, the default compression is snappy only if it's available on the system. If it isn't we change the default to kNoCompression.\n* We changed how we account for memory used in block cache. Previously, we only counted the sum of block sizes currently present in block cache. Now, we count the actual memory usage of the blocks. For example, a block of size 4.5KB will use 8KB memory with jemalloc. This might decrease your memory usage and possibly decrease performance. Increase block cache size if you see this happening after an upgrade.\n* Add BackupEngineImpl.options_.max_background_operations to specify the maximum number of operations that may be performed in parallel. Add support for parallelized backup and restore.\n* Add DB::SyncWAL() that does a WAL sync without blocking writers.\n\n## 3.11.0 (2015-05-19)\n### New Features\n* Added a new API Cache::SetCapacity(size_t capacity) to dynamically change the maximum configured capacity of the cache. If the new capacity is less than the existing cache usage, the implementation will try to lower the usage by evicting the necessary number of elements following a strict LRU policy.\n* Added an experimental API for handling flashcache devices (blacklists background threads from caching their reads) -- NewFlashcacheAwareEnv\n* If universal compaction is used and options.num_levels > 1, compact files are tried to be stored in none-L0 with smaller files based on options.target_file_size_base. The limitation of DB size when using universal compaction is greatly mitigated by using more levels. You can set num_levels = 1 to make universal compaction behave as before. If you set num_levels > 1 and want to roll back to a previous version, you need to compact all files to a big file in level 0 (by setting target_file_size_base to be large and CompactRange(<cf_handle>, nullptr, nullptr, true, 0) and reopen the DB with the same version to rewrite the manifest, and then you can open it using previous releases.\n* More information about rocksdb background threads are available in Env::GetThreadList(), including the number of bytes read / written by a compaction job, mem-table size and current number of bytes written by a flush job and many more.  Check include/rocksdb/thread_status.h for more detail.\n\n### Public API changes\n* TablePropertiesCollector::AddUserKey() is added to replace TablePropertiesCollector::Add(). AddUserKey() exposes key type, sequence number and file size up to now to users.\n* DBOptions::bytes_per_sync used to apply to both WAL and table files. As of 3.11 it applies only to table files. If you want to use this option to sync WAL in the background, please use wal_bytes_per_sync\n\n## 3.10.0 (2015-03-24)\n### New Features\n* GetThreadStatus() is now able to report detailed thread status, including:\n - Thread Operation including flush and compaction.\n - The stage of the current thread operation.\n - The elapsed time in micros since the current thread operation started.\n More information can be found in include/rocksdb/thread_status.h.  In addition, when running db_bench with --thread_status_per_interval, db_bench will also report thread status periodically.\n* Changed the LRU caching algorithm so that referenced blocks (by iterators) are never evicted. This change made parameter removeScanCountLimit obsolete. Because of that NewLRUCache doesn't take three arguments anymore. table_cache_remove_scan_limit option is also removed\n* By default we now optimize the compilation for the compilation platform (using -march=native). If you want to build portable binary, use 'PORTABLE=1' before the make command.\n* We now allow level-compaction to place files in different paths by\n  specifying them in db_paths along with the target_size.\n  Lower numbered levels will be placed earlier in the db_paths and higher\n  numbered levels will be placed later in the db_paths vector.\n* Potentially big performance improvements if you're using RocksDB with lots of column families (100-1000)\n* Added BlockBasedTableOptions.format_version option, which allows user to specify which version of block based table he wants. As a general guideline, newer versions have more features, but might not be readable by older versions of RocksDB.\n* Added new block based table format (version 2), which you can enable by setting BlockBasedTableOptions.format_version = 2. This format changes how we encode size information in compressed blocks and should help with memory allocations if you're using Zlib or BZip2 compressions.\n* MemEnv (env that stores data in memory) is now available in default library build. You can create it by calling NewMemEnv().\n* Add SliceTransform.SameResultWhenAppended() to help users determine it is safe to apply prefix bloom/hash.\n* Block based table now makes use of prefix bloom filter if it is a full fulter.\n* Block based table remembers whether a whole key or prefix based bloom filter is supported in SST files. Do a sanity check when reading the file with users' configuration.\n* Fixed a bug in ReadOnlyBackupEngine that deleted corrupted backups in some cases, even though the engine was ReadOnly\n* options.level_compaction_dynamic_level_bytes, a feature to allow RocksDB to pick dynamic base of bytes for levels. With this feature turned on, we will automatically adjust max bytes for each level. The goal of this feature is to have lower bound on size amplification. For more details, see comments in options.h.\n* Added an abstract base class WriteBatchBase for write batches\n* Fixed a bug where we start deleting files of a dropped column families even if there are still live references to it\n\n### Public API changes\n* Deprecated skip_log_error_on_recovery and table_cache_remove_scan_count_limit options.\n* Logger method logv with log level parameter is now virtual\n\n### RocksJava\n* Added compression per level API.\n* MemEnv is now available in RocksJava via RocksMemEnv class.\n* lz4 compression is now included in rocksjava static library when running `make rocksdbjavastatic`.\n* Overflowing a size_t when setting rocksdb options now throws an IllegalArgumentException, which removes the necessity for a developer to catch these Exceptions explicitly.\n\n## 3.9.0 (2014-12-08)\n\n### New Features\n* Add rocksdb::GetThreadList(), which in the future will return the current status of all\n  rocksdb-related threads.  We will have more code instruments in the following RocksDB\n  releases.\n* Change convert function in rocksdb/utilities/convenience.h to return Status instead of boolean.\n  Also add support for nested options in convert function\n\n### Public API changes\n* New API to create a checkpoint added. Given a directory name, creates a new\n  database which is an image of the existing database.\n* New API LinkFile added to Env. If you implement your own Env class, an\n  implementation of the API LinkFile will have to be provided.\n* MemTableRep takes MemTableAllocator instead of Arena\n\n### Improvements\n* RocksDBLite library now becomes smaller and will be compiled with -fno-exceptions flag.\n\n## 3.8.0 (2014-11-14)\n\n### Public API changes\n* BackupEngine::NewBackupEngine() was deprecated; please use BackupEngine::Open() from now on.\n* BackupableDB/RestoreBackupableDB have new GarbageCollect() methods, which will clean up files from corrupt and obsolete backups.\n* BackupableDB/RestoreBackupableDB have new GetCorruptedBackups() methods which list corrupt backups.\n\n### Cleanup\n* Bunch of code cleanup, some extra warnings turned on (-Wshadow, -Wshorten-64-to-32, -Wnon-virtual-dtor)\n\n### New features\n* CompactFiles and EventListener, although they are still in experimental state\n* Full ColumnFamily support in RocksJava.\n\n## 3.7.0 (2014-11-06)\n### Public API changes\n* Introduce SetOptions() API to allow adjusting a subset of options dynamically online\n* Introduce 4 new convenient functions for converting Options from string: GetColumnFamilyOptionsFromMap(), GetColumnFamilyOptionsFromString(), GetDBOptionsFromMap(), GetDBOptionsFromString()\n* Remove WriteBatchWithIndex.Delete() overloads using SliceParts\n* When opening a DB, if options.max_background_compactions is larger than the existing low pri pool of options.env, it will enlarge it. Similarly, options.max_background_flushes is larger than the existing high pri pool of options.env, it will enlarge it.\n\n## 3.6.0 (2014-10-07)\n### Disk format changes\n* If you're using RocksDB on ARM platforms and you're using default bloom filter, there is a disk format change you need to be aware of. There are three steps you need to do when you convert to new release: 1. turn off filter policy, 2. compact the whole database, 3. turn on filter policy\n\n### Behavior changes\n* We have refactored our system of stalling writes.  Any stall-related statistics' meanings are changed. Instead of per-write stall counts, we now count stalls per-epoch, where epochs are periods between flushes and compactions. You'll find more information in our Tuning Perf Guide once we release RocksDB 3.6.\n* When disableDataSync=true, we no longer sync the MANIFEST file.\n* Add identity_as_first_hash property to CuckooTable. SST file needs to be rebuilt to be opened by reader properly.\n\n### Public API changes\n* Change target_file_size_base type to uint64_t from int.\n* Remove allow_thread_local. This feature was proved to be stable, so we are turning it always-on.\n\n## 3.5.0 (2014-09-03)\n### New Features\n* Add include/utilities/write_batch_with_index.h, providing a utility class to query data out of WriteBatch when building it.\n* Move BlockBasedTable related options to BlockBasedTableOptions from Options. Change corresponding JNI interface. Options affected include:\n  no_block_cache, block_cache, block_cache_compressed, block_size, block_size_deviation, block_restart_interval, filter_policy, whole_key_filtering. filter_policy is changed to shared_ptr from a raw pointer.\n* Remove deprecated options: disable_seek_compaction and db_stats_log_interval\n* OptimizeForPointLookup() takes one parameter for block cache size. It now builds hash index, bloom filter, and block cache.\n\n### Public API changes\n* The Prefix Extractor used with V2 compaction filters is now passed user key to SliceTransform::Transform instead of unparsed RocksDB key.\n\n## 3.4.0 (2014-08-18)\n### New Features\n* Support Multiple DB paths in universal style compactions\n* Add feature of storing plain table index and bloom filter in SST file.\n* CompactRange() will never output compacted files to level 0. This used to be the case when all the compaction input files were at level 0.\n* Added iterate_upper_bound to define the extent upto which the forward iterator will return entries. This will prevent iterating over delete markers and overwritten entries for edge cases where you want to break out the iterator anyways. This may improve performance in case there are a large number of delete markers or overwritten entries.\n\n### Public API changes\n* DBOptions.db_paths now is a vector of a DBPath structure which indicates both of path and target size\n* NewPlainTableFactory instead of bunch of parameters now accepts PlainTableOptions, which is defined in include/rocksdb/table.h\n* Moved include/utilities/*.h to include/rocksdb/utilities/*.h\n* Statistics APIs now take uint32_t as type instead of Tickers. Also make two access functions getTickerCount and histogramData const\n* Add DB property rocksdb.estimate-num-keys, estimated number of live keys in DB.\n* Add DB::GetIntProperty(), which returns DB properties that are integer as uint64_t.\n* The Prefix Extractor used with V2 compaction filters is now passed user key to SliceTransform::Transform instead of unparsed RocksDB key.\n\n## 3.3.0 (2014-07-10)\n### New Features\n* Added JSON API prototype.\n* HashLinklist reduces performance outlier caused by skewed bucket by switching data in the bucket from linked list to skip list. Add parameter threshold_use_skiplist in NewHashLinkListRepFactory().\n* RocksDB is now able to reclaim storage space more effectively during the compaction process.  This is done by compensating the size of each deletion entry by the 2X average value size, which makes compaction to be triggered by deletion entries more easily.\n* Add TimeOut API to write.  Now WriteOptions have a variable called timeout_hint_us.  With timeout_hint_us set to non-zero, any write associated with this timeout_hint_us may be aborted when it runs longer than the specified timeout_hint_us, and it is guaranteed that any write completes earlier than the specified time-out will not be aborted due to the time-out condition.\n* Add a rate_limiter option, which controls total throughput of flush and compaction. The throughput is specified in bytes/sec. Flush always has precedence over compaction when available bandwidth is constrained.\n\n### Public API changes\n* Removed NewTotalOrderPlainTableFactory because it is not used and implemented semantically incorrect.\n\n## 3.2.0 (2014-06-20)\n\n### Public API changes\n* We removed seek compaction as a concept from RocksDB because:\n1) It makes more sense for spinning disk workloads, while RocksDB is primarily designed for flash and memory,\n2) It added some complexity to the important code-paths,\n3) None of our internal customers were really using it.\nBecause of that, Options::disable_seek_compaction is now obsolete. It is still a parameter in Options, so it does not break the build, but it does not have any effect. We plan to completely remove it at some point, so we ask users to please remove this option from your code base.\n* Add two parameters to NewHashLinkListRepFactory() for logging on too many entries in a hash bucket when flushing.\n* Added new option BlockBasedTableOptions::hash_index_allow_collision. When enabled, prefix hash index for block-based table will not store prefix and allow hash collision, reducing memory consumption.\n\n### New Features\n* PlainTable now supports a new key encoding: for keys of the same prefix, the prefix is only written once. It can be enabled through encoding_type parameter of NewPlainTableFactory()\n* Add AdaptiveTableFactory, which is used to convert from a DB of PlainTable to BlockBasedTabe, or vise versa. It can be created using NewAdaptiveTableFactory()\n\n### Performance Improvements\n* Tailing Iterator re-implemeted with ForwardIterator + Cascading Search Hint , see ~20% throughput improvement.\n\n## 3.1.0 (2014-05-21)\n\n### Public API changes\n* Replaced ColumnFamilyOptions::table_properties_collectors with ColumnFamilyOptions::table_properties_collector_factories\n\n### New Features\n* Hash index for block-based table will be materialized and reconstructed more efficiently. Previously hash index is constructed by scanning the whole table during every table open.\n* FIFO compaction style\n\n## 3.0.0 (2014-05-05)\n\n### Public API changes\n* Added _LEVEL to all InfoLogLevel enums\n* Deprecated ReadOptions.prefix and ReadOptions.prefix_seek. Seek() defaults to prefix-based seek when Options.prefix_extractor is supplied. More detail is documented in https://github.com/facebook/rocksdb/wiki/Prefix-Seek-API-Changes\n* MemTableRepFactory::CreateMemTableRep() takes info logger as an extra parameter.\n\n### New Features\n* Column family support\n* Added an option to use different checksum functions in BlockBasedTableOptions\n* Added ApplyToAllCacheEntries() function to Cache\n\n## 2.8.0 (2014-04-04)\n\n* Removed arena.h from public header files.\n* By default, checksums are verified on every read from database\n* Change default value of several options, including: paranoid_checks=true, max_open_files=5000, level0_slowdown_writes_trigger=20, level0_stop_writes_trigger=24, disable_seek_compaction=true, max_background_flushes=1 and allow_mmap_writes=false\n* Added is_manual_compaction to CompactionFilter::Context\n* Added \"virtual void WaitForJoin()\" in class Env. Default operation is no-op.\n* Removed BackupEngine::DeleteBackupsNewerThan() function\n* Added new option -- verify_checksums_in_compaction\n* Changed Options.prefix_extractor from raw pointer to shared_ptr (take ownership)\n  Changed HashSkipListRepFactory and HashLinkListRepFactory constructor to not take SliceTransform object (use Options.prefix_extractor implicitly)\n* Added Env::GetThreadPoolQueueLen(), which returns the waiting queue length of thread pools\n* Added a command \"checkconsistency\" in ldb tool, which checks\n  if file system state matches DB state (file existence and file sizes)\n* Separate options related to block based table to a new struct BlockBasedTableOptions.\n* WriteBatch has a new function Count() to return total size in the batch, and Data() now returns a reference instead of a copy\n* Add more counters to perf context.\n* Supports several more DB properties: compaction-pending, background-errors and cur-size-active-mem-table.\n\n### New Features\n* If we find one truncated record at the end of the MANIFEST or WAL files,\n  we will ignore it. We assume that writers of these records were interrupted\n  and that we can safely ignore it.\n* A new SST format \"PlainTable\" is added, which is optimized for memory-only workloads. It can be created through NewPlainTableFactory() or NewTotalOrderPlainTableFactory().\n* A new mem table implementation hash linked list optimizing for the case that there are only few keys for each prefix, which can be created through NewHashLinkListRepFactory().\n* Merge operator supports a new function PartialMergeMulti() to allow users to do partial merges against multiple operands.\n* Now compaction filter has a V2 interface. It buffers the kv-pairs sharing the same key prefix, process them in batches, and return the batched results back to DB. The new interface uses a new structure CompactionFilterContext for the same purpose as CompactionFilter::Context in V1.\n* Geo-spatial support for locations and radial-search.\n\n## 2.7.0 (2014-01-28)\n\n### Public API changes\n\n* Renamed `StackableDB::GetRawDB()` to `StackableDB::GetBaseDB()`.\n* Renamed `WriteBatch::Data()` `const std::string& Data() const`.\n* Renamed class `TableStats` to `TableProperties`.\n* Deleted class `PrefixHashRepFactory`. Please use `NewHashSkipListRepFactory()` instead.\n* Supported multi-threaded `EnableFileDeletions()` and `DisableFileDeletions()`.\n* Added `DB::GetOptions()`.\n* Added `DB::GetDbIdentity()`.\n\n### New Features\n\n* Added [BackupableDB](https://github.com/facebook/rocksdb/wiki/How-to-backup-RocksDB%3F)\n* Implemented [TailingIterator](https://github.com/facebook/rocksdb/wiki/Tailing-Iterator), a special type of iterator that\n  doesn't create a snapshot (can be used to read newly inserted data)\n  and is optimized for doing sequential reads.\n* Added property block for table, which allows (1) a table to store\n  its metadata and (2) end user to collect and store properties they\n  are interested in.\n* Enabled caching index and filter block in block cache (turned off by default).\n* Supported error report when doing manual compaction.\n* Supported additional Linux platform flavors and Mac OS.\n* Put with `SliceParts` - Variant of `Put()` that gathers output like `writev(2)`\n* Bug fixes and code refactor for compatibility with upcoming Column\n  Family feature.\n\n### Performance Improvements\n\n* Huge benchmark performance improvements by multiple efforts. For example, increase in readonly QPS from about 530k in 2.6 release to 1.1 million in 2.7 [1]\n* Speeding up a way RocksDB deleted obsolete files - no longer listing the whole directory under a lock -- decrease in p99\n* Use raw pointer instead of shared pointer for statistics: [5b825d](https://github.com/facebook/rocksdb/commit/5b825d6964e26ec3b4bb6faa708ebb1787f1d7bd) -- huge increase in performance -- shared pointers are slow\n* Optimized locking for `Get()` -- [1fdb3f](https://github.com/facebook/rocksdb/commit/1fdb3f7dc60e96394e3e5b69a46ede5d67fb976c) -- 1.5x QPS increase for some workloads\n* Cache speedup - [e8d40c3](https://github.com/facebook/rocksdb/commit/e8d40c31b3cca0c3e1ae9abe9b9003b1288026a9)\n* Implemented autovector, which allocates first N elements on stack. Most of vectors in RocksDB are small. Also, we never want to allocate heap objects while holding a mutex. -- [c01676e4](https://github.com/facebook/rocksdb/commit/c01676e46d3be08c3c140361ef1f5884f47d3b3c)\n* Lots of efforts to move malloc, memcpy and IO outside of locks\n"
        },
        {
          "name": "INSTALL.md",
          "type": "blob",
          "size": 8.6220703125,
          "content": "## Compilation\n\n**Important**: If you plan to run RocksDB in production, don't compile using default\n`make` or `make all`. That will compile RocksDB in debug mode, which is much slower\nthan release mode.\n\nRocksDB's library should be able to compile without any dependency installed,\nalthough we recommend installing some compression libraries (see below).\nWe do depend on newer gcc/clang with C++17 support (GCC >= 7, Clang >= 5).\n\nThere are few options when compiling RocksDB:\n\n* [recommended] `make static_lib` will compile librocksdb.a, RocksDB static library. Compiles static library in release mode.\n\n* `make shared_lib` will compile librocksdb.so, RocksDB shared library. Compiles shared library in release mode.\n\n* `make check` will compile and run all the unit tests. `make check` will compile RocksDB in debug mode.\n\n* `make all` will compile our static library, and all our tools and unit tests. Our tools\ndepend on gflags 2.2.0 or newer. You will need to have gflags installed to run `make all`. This will compile RocksDB in debug mode. Don't\nuse binaries compiled by `make all` in production.\n\n* By default the binary we produce is optimized for the CPU you're compiling on\n(`-march=native` or the equivalent). To build a binary compatible with the most\ngeneral architecture supported by your CPU and compiler, set `PORTABLE=1` for\nthe build, but performance will suffer as many operations benefit from newer\nand wider instructions. In addition to `PORTABLE=0` (default) and `PORTABLE=1`,\nit can be set to an architecture name recognized by your compiler. For example,\non 64-bit x86, a reasonable compromise is `PORTABLE=haswell` which supports\nmany or most of the available optimizations while still being compatible with\nmost processors made since roughly 2013.\n\n## Dependencies\n\n* You can link RocksDB with following compression libraries:\n  - [zlib](http://www.zlib.net/) - a library for data compression.\n  - [bzip2](http://www.bzip.org/) - a library for data compression.\n  - [lz4](https://github.com/lz4/lz4) - a library for extremely fast data compression.\n  - [snappy](http://google.github.io/snappy/) - a library for fast\n      data compression.\n  - [zstandard](http://www.zstd.net) - Fast real-time compression\n      algorithm.\n\n* All our tools depend on:\n  - [gflags](https://gflags.github.io/gflags/) - a library that handles\n      command line flags processing. You can compile rocksdb library even\n      if you don't have gflags installed.\n\n* `make check` will also check code formatting, which requires [clang-format](https://clang.llvm.org/docs/ClangFormat.html)\n\n* If you wish to build the RocksJava static target, then cmake is required for building Snappy.\n\n* If you wish to run microbench (e.g, `make microbench`, `make ribbon_bench` or `cmake -DWITH_BENCHMARK=1`), Google benchmark >= 1.6.0 is needed.\n* You can do the following to install Google benchmark. These commands are copied from `./build_tools/ubuntu20_image/Dockerfile`:\n\n`$ git clone --depth 1 --branch v1.7.0 https://github.com/google/benchmark.git ~/benchmark`\n\n`$ cd ~/benchmark && mkdir build && cd build && cmake .. -GNinja -DCMAKE_BUILD_TYPE=Release -DBENCHMARK_ENABLE_GTEST_TESTS=0 && ninja && ninja install`\n\n## Supported platforms\n\n* **Linux - Ubuntu**\n    * Upgrade your gcc to version at least 7 to get C++17 support.\n    * Install gflags. First, try: `sudo apt-get install libgflags-dev`\n      If this doesn't work and you're using Ubuntu, here's a nice tutorial:\n      (http://askubuntu.com/questions/312173/installing-gflags-12-04)\n    * Install snappy. This is usually as easy as:\n      `sudo apt-get install libsnappy-dev`.\n    * Install zlib. Try: `sudo apt-get install zlib1g-dev`.\n    * Install bzip2: `sudo apt-get install libbz2-dev`.\n    * Install lz4: `sudo apt-get install liblz4-dev`.\n    * Install zstandard: `sudo apt-get install libzstd-dev`.\n\n* **Linux - CentOS / RHEL**\n    * Upgrade your gcc to version at least 7 to get C++17 support\n    * Install gflags:\n\n              git clone https://github.com/gflags/gflags.git\n              cd gflags\n              git checkout v2.2.0\n              ./configure && make && sudo make install\n\n      **Notice**: Once installed, please add the include path for gflags to your `CPATH` environment variable and the\n      lib path to `LIBRARY_PATH`. If installed with default settings, the include path will be `/usr/local/include`\n      and the lib path will be `/usr/local/lib`.\n\n    * Install snappy:\n\n              sudo yum install snappy snappy-devel\n\n    * Install zlib:\n\n              sudo yum install zlib zlib-devel\n\n    * Install bzip2:\n\n              sudo yum install bzip2 bzip2-devel\n\n    * Install lz4:\n\n              sudo yum install lz4-devel\n\n    * Install ASAN (optional for debugging):\n\n              sudo yum install libasan\n\n    * Install zstandard:\n        * With [EPEL](https://fedoraproject.org/wiki/EPEL):\n\n              sudo yum install libzstd-devel\n\n        * With CentOS 8:\n\n              sudo dnf install libzstd-devel\n\n        * From source:\n\n              wget https://github.com/facebook/zstd/archive/v1.1.3.tar.gz\n              mv v1.1.3.tar.gz zstd-1.1.3.tar.gz\n              tar zxvf zstd-1.1.3.tar.gz\n              cd zstd-1.1.3\n              make && sudo make install\n\n* **OS X**:\n    * Install latest C++ compiler that supports C++ 17:\n        * Update XCode:  run `xcode-select --install` (or install it from XCode App's settting).\n        * Install via [homebrew](http://brew.sh/).\n            * If you're first time developer in MacOS, you still need to run: `xcode-select --install` in your command line.\n    * run `brew install rocksdb`\n\n* **FreeBSD** (11.01):\n\n    * You can either install RocksDB from the Ports system using `cd /usr/ports/databases/rocksdb && make install`, or you can follow the details below to install dependencies and compile from source code:\n\n    * Install the dependencies for RocksDB:\n\n        export BATCH=YES\n        cd /usr/ports/devel/gmake && make install\n        cd /usr/ports/devel/gflags && make install\n\n        cd /usr/ports/archivers/snappy && make install\n        cd /usr/ports/archivers/bzip2 && make install\n        cd /usr/ports/archivers/liblz4 && make install\n        cd /usr/ports/archivesrs/zstd && make install\n\n        cd /usr/ports/devel/git && make install\n\n\n    * Install the dependencies for RocksJava (optional):\n\n        export BATCH=yes\n        cd /usr/ports/java/openjdk7 && make install\n\n    * Build RocksDB from source:\n        cd ~\n        git clone https://github.com/facebook/rocksdb.git\n        cd rocksdb\n        gmake static_lib\n\n    * Build RocksJava from source (optional):\n        cd rocksdb\n        export JAVA_HOME=/usr/local/openjdk7\n        gmake rocksdbjava\n\n* **OpenBSD** (6.3/-current):\n\n    * As RocksDB is not available in the ports yet you have to build it on your own:\n\n    * Install the dependencies for RocksDB:\n\n      `pkg_add gmake gflags snappy bzip2 lz4 zstd git bash findutils gnuwatch`\n\n    * Build RocksDB from source:\n\n        ```bash\n        cd ~\n        git clone https://github.com/facebook/rocksdb.git\n        cd rocksdb\n        gmake static_lib\n        ```\n\n    * Build RocksJava from source (optional):\n        * In OpenBSD, JDK depends on XWindows system, so please check that you installed OpenBSD with `xbase` package.\n        * Install dependencies : `pkg_add -v jdk%1.8`\n        ```bash\n        cd rocksdb\n        export JAVA_HOME=/usr/local/jdk-1.8.0\n        export PATH=$PATH:/usr/local/jdk-1.8.0/bin\n        gmake rocksdbjava SHA256_CMD='sha256 -q'\n        ```\n\n* **iOS**:\n  * Run: `TARGET_OS=IOS make static_lib`. When building the project which uses rocksdb iOS library, make sure to define an important pre-processing macros: `IOS_CROSS_COMPILE`.\n\n* **Windows** (Visual Studio 2017 to up):\n  * Read and follow the instructions at CMakeLists.txt\n  * Or install via [vcpkg](https://github.com/microsoft/vcpkg)\n       * run `vcpkg install rocksdb:x64-windows`\n\n* **AIX 6.1**\n    * Install AIX Toolbox rpms with gcc\n    * Use these environment variables:\n\n             export PORTABLE=1\n             export CC=gcc\n             export AR=\"ar -X64\"\n             export EXTRA_ARFLAGS=-X64\n             export EXTRA_CFLAGS=-maix64\n             export EXTRA_CXXFLAGS=-maix64\n             export PLATFORM_LDFLAGS=\"-static-libstdc++ -static-libgcc\"\n             export LIBPATH=/opt/freeware/lib\n             export JAVA_HOME=/usr/java8_64\n             export PATH=/opt/freeware/bin:$PATH\n\n* **Solaris Sparc**\n    * Install GCC 7 and higher.\n    * Use these environment variables:\n\n             export CC=gcc\n             export EXTRA_CFLAGS=-m64\n             export EXTRA_CXXFLAGS=-m64\n             export EXTRA_LDFLAGS=-m64\n             export PORTABLE=1\n             export PLATFORM_LDFLAGS=\"-static-libstdc++ -static-libgcc\"\n"
        },
        {
          "name": "LANGUAGE-BINDINGS.md",
          "type": "blob",
          "size": 1.2548828125,
          "content": "This is the list of all known third-party language bindings for RocksDB. If something is missing, please open a pull request to add it.\n\n* Java - https://github.com/facebook/rocksdb/tree/main/java\n* Python\n    * http://python-rocksdb.readthedocs.io/en/latest/\n    * http://pyrocksdb.readthedocs.org/en/latest/ (unmaintained)\n* Perl - https://metacpan.org/pod/RocksDB\n* Node.js - https://npmjs.org/package/rocksdb\n* Go \n  * https://github.com/linxGnu/grocksdb\n  * https://github.com/tecbot/gorocksdb (unmaintained)\n* Ruby - http://rubygems.org/gems/rocksdb-ruby\n* Haskell - https://hackage.haskell.org/package/rocksdb-haskell\n* PHP - https://github.com/Photonios/rocksdb-php\n* C#\n    * https://github.com/warrenfalk/rocksdb-sharp\n    * https://github.com/curiosity-ai/rocksdb-sharp\n* Rust\n    * https://github.com/pingcap/rust-rocksdb (used in production fork of https://github.com/spacejam/rust-rocksdb)\n    * https://github.com/spacejam/rust-rocksdb\n    * https://github.com/bh1xuw/rust-rocks\n* D programming language - https://github.com/b1naryth1ef/rocksdb\n* Erlang - https://gitlab.com/barrel-db/erlang-rocksdb\n* Elixir - https://github.com/urbint/rox\n* Nim - https://github.com/status-im/nim-rocksdb\n* Swift and Objective-C (iOS/OSX) - https://github.com/iabudiab/ObjectiveRocks \n"
        },
        {
          "name": "LICENSE.Apache",
          "type": "blob",
          "size": 11.091796875,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "LICENSE.leveldb",
          "type": "blob",
          "size": 1.53515625,
          "content": "This contains code that is from LevelDB, and that code is under the following license:\n\nCopyright (c) 2011 The LevelDB Authors. All rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n\n   * Redistributions of source code must retain the above copyright\nnotice, this list of conditions and the following disclaimer.\n   * Redistributions in binary form must reproduce the above\ncopyright notice, this list of conditions and the following disclaimer\nin the documentation and/or other materials provided with the\ndistribution.\n   * Neither the name of Google Inc. nor the names of its\ncontributors may be used to endorse or promote products derived from\nthis software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 102.05859375,
          "content": "# Copyright (c) 2011 The LevelDB Authors. All rights reserved.\n# Use of this source code is governed by a BSD-style license that can be\n# found in the LICENSE file. See the AUTHORS file for names of contributors.\n\n# Inherit some settings from environment variables, if available\n\n#-----------------------------------------------\n\nBASH_EXISTS := $(shell which bash)\nSHELL := $(shell which bash)\ninclude common.mk\n\nCLEAN_FILES = # deliberately empty, so we can append below.\nCFLAGS += ${EXTRA_CFLAGS}\nCXXFLAGS += ${EXTRA_CXXFLAGS}\nLDFLAGS += $(EXTRA_LDFLAGS)\nMACHINE ?= $(shell uname -m)\nARFLAGS = ${EXTRA_ARFLAGS} rs\nSTRIPFLAGS = -S -x\n\n# Transform parallel LOG output into something more readable.\nperl_command = perl -n \\\n  -e '@a=split(\"\\t\",$$_,-1); $$t=$$a[8];'\t\t\t\t\\\n  -e '$$t =~ /.*if\\s\\[\\[\\s\"(.*?\\.[\\w\\/]+)/ and $$t=$$1;'\t\t\\\n  -e '$$t =~ s,^\\./,,;'\t\t\t\t\t\t\t\\\n  -e '$$t =~ s, >.*,,; chomp $$t;'\t\t\t\t\t\\\n  -e '$$t =~ /.*--gtest_filter=(.*?\\.[\\w\\/]+)/ and $$t=$$1;'\t\t\\\n  -e 'printf \"%7.3f %s %s\\n\", $$a[3], $$a[6] == 0 ? \"PASS\" : \"FAIL\", $$t'\nquoted_perl_command = $(subst ','\\'',$(perl_command))\n\n# DEBUG_LEVEL can have three values:\n# * DEBUG_LEVEL=2; this is the ultimate debug mode. It will compile rocksdb\n# without any optimizations. To compile with level 2, issue `make dbg`\n# * DEBUG_LEVEL=1; debug level 1 enables all assertions and debug code, but\n# compiles rocksdb with -O2 optimizations. this is the default debug level.\n# `make all` or `make <binary_target>` compile RocksDB with debug level 1.\n# We use this debug level when developing RocksDB.\n# * DEBUG_LEVEL=0; this is the debug level we use for release. If you're\n# running rocksdb in production you most definitely want to compile RocksDB\n# with debug level 0. To compile with level 0, run `make shared_lib`,\n# `make install-shared`, `make static_lib`, `make install-static` or\n# `make install`\n\n# Set the default DEBUG_LEVEL to 1\nDEBUG_LEVEL?=1\n\n# OBJ_DIR is where the object files reside.  Default to the current directory\nOBJ_DIR?=.\n\n# Check the MAKECMDGOALS to set the DEBUG_LEVEL and LIB_MODE appropriately\n\nifneq ($(filter clean release install, $(MAKECMDGOALS)),)\n\tDEBUG_LEVEL=0\nendif\nifneq ($(filter dbg, $(MAKECMDGOALS)),)\n\tDEBUG_LEVEL=2\nelse ifneq ($(filter shared_lib install-shared, $(MAKECMDGOALS)),)\n\tDEBUG_LEVEL=0\n\tLIB_MODE=shared\nelse ifneq ($(filter static_lib install-static, $(MAKECMDGOALS)),)\n\tDEBUG_LEVEL=0\n\tLIB_MODE=static\nelse ifneq ($(filter jtest rocksdbjava%, $(MAKECMDGOALS)),)\n\tOBJ_DIR=jl\n\tLIB_MODE=shared\n\tifneq ($(findstring rocksdbjavastatic, $(MAKECMDGOALS)),)\n\t\tOBJ_DIR=jls\n\t\tifneq ($(DEBUG_LEVEL),2)\n\t\t\tDEBUG_LEVEL=0\n\t\tendif\n\t\tifeq ($(MAKECMDGOALS),rocksdbjavastaticpublish)\n\t\t\tDEBUG_LEVEL=0\n\t\tendif\n\tendif\nendif\n\n# LIB_MODE says whether or not to use/build \"shared\" or \"static\" libraries.\n# Mode \"static\" means to link against static libraries (.a)\n# Mode \"shared\" means to link against shared libraries (.so, .sl, .dylib, etc)\n#\nifeq ($(DEBUG_LEVEL), 0)\n# For optimized, set the default LIB_MODE to static for code size/efficiency\n\tLIB_MODE?=static\nelse\n# For debug, set the default LIB_MODE to shared for efficient `make check` etc.\n\tLIB_MODE?=shared\nendif\n\n$(info $$DEBUG_LEVEL is $(DEBUG_LEVEL), $$LIB_MODE is $(LIB_MODE))\n\n# Detect what platform we're building on.\n# Export some common variables that might have been passed as Make variables\n# instead of environment variables.\ndummy := $(shell (export ROCKSDB_ROOT=\"$(CURDIR)\"; \\\n                  export CXXFLAGS=\"$(EXTRA_CXXFLAGS)\"; \\\n                  export LDFLAGS=\"$(EXTRA_LDFLAGS)\"; \\\n                  export COMPILE_WITH_ASAN=\"$(COMPILE_WITH_ASAN)\"; \\\n                  export COMPILE_WITH_TSAN=\"$(COMPILE_WITH_TSAN)\"; \\\n                  export COMPILE_WITH_UBSAN=\"$(COMPILE_WITH_UBSAN)\"; \\\n                  export PORTABLE=\"$(PORTABLE)\"; \\\n                  export ROCKSDB_NO_FBCODE=\"$(ROCKSDB_NO_FBCODE)\"; \\\n                  export USE_CLANG=\"$(USE_CLANG)\"; \\\n                  export LIB_MODE=\"$(LIB_MODE)\"; \\\n\t\t  export ROCKSDB_CXX_STANDARD=\"$(ROCKSDB_CXX_STANDARD)\"; \\\n\t\t  export USE_FOLLY=\"$(USE_FOLLY)\"; \\\n\t\t  export USE_FOLLY_LITE=\"$(USE_FOLLY_LITE)\"; \\\n                  \"$(CURDIR)/build_tools/build_detect_platform\" \"$(CURDIR)/make_config.mk\"))\n# this file is generated by the previous line to set build flags and sources\ninclude make_config.mk\n\n# Figure out optimize level.\nifneq ($(DEBUG_LEVEL), 2)\n\tOPTIMIZE_LEVEL ?= -O2\nendif\n# `OPTIMIZE_LEVEL` is empty when the user does not set it and `DEBUG_LEVEL=2`.\n# In that case, the compiler default (`-O0` for gcc and clang) will be used.\nOPT += $(OPTIMIZE_LEVEL)\n\n# compile with -O2 if debug level is not 2\nifneq ($(DEBUG_LEVEL), 2)\nOPT += -fno-omit-frame-pointer\n# Skip for archs that don't support -momit-leaf-frame-pointer\nifeq (,$(shell $(CXX) -fsyntax-only -momit-leaf-frame-pointer -xc /dev/null 2>&1))\nOPT += -momit-leaf-frame-pointer\nendif\nendif\n\nifeq (,$(shell $(CXX) -fsyntax-only -maltivec -xc /dev/null 2>&1))\nCXXFLAGS += -DHAS_ALTIVEC\nCFLAGS += -DHAS_ALTIVEC\nHAS_ALTIVEC=1\nendif\n\nifeq (,$(shell $(CXX) -fsyntax-only -mcpu=power8 -xc /dev/null 2>&1))\nCXXFLAGS += -DHAVE_POWER8\nCFLAGS +=  -DHAVE_POWER8\nHAVE_POWER8=1\nendif\n\n# if we're compiling for shared libraries, add the shared flags\nifeq ($(LIB_MODE),shared)\nCXXFLAGS += $(PLATFORM_SHARED_CFLAGS) -DROCKSDB_DLL\nCFLAGS +=  $(PLATFORM_SHARED_CFLAGS) -DROCKSDB_DLL\nendif\n\nGIT_COMMAND ?= git\nifeq ($(USE_COROUTINES), 1)\n\tUSE_FOLLY = 1\n\t# glog/logging.h requires HAVE_CXX11_ATOMIC\n\tOPT += -DUSE_COROUTINES -DHAVE_CXX11_ATOMIC\n\tROCKSDB_CXX_STANDARD = c++2a\n\tUSE_RTTI = 1\nifneq ($(USE_CLANG), 1)\n\tROCKSDB_CXX_STANDARD = c++20\n\tPLATFORM_CXXFLAGS += -fcoroutines\nendif\nendif\n\n# if we're compiling for release, compile without debug code (-DNDEBUG)\nifeq ($(DEBUG_LEVEL),0)\nOPT += -DNDEBUG\n\nifneq ($(USE_RTTI), 1)\n\tCXXFLAGS += -fno-rtti\nelse\n\tCXXFLAGS += -DROCKSDB_USE_RTTI\nendif\nelse\nifneq ($(USE_RTTI), 0)\n\tCXXFLAGS += -DROCKSDB_USE_RTTI\nelse\n\tCXXFLAGS += -fno-rtti\nendif\n\nifdef ASSERT_STATUS_CHECKED\n# For ASC, turn off constructor elision, preventing the case where a constructor returned\n# by a method may pass the ASC check if the status is checked in the inner method.  Forcing\n# the copy constructor to be invoked disables the optimization and will cause the calling method\n# to check the status in order to prevent an error from being raised.\nPLATFORM_CXXFLAGS += -fno-elide-constructors\nifeq ($(filter -DROCKSDB_ASSERT_STATUS_CHECKED,$(OPT)),)\n\tOPT += -DROCKSDB_ASSERT_STATUS_CHECKED\nendif\nendif\n\n$(warning Warning: Compiling in debug mode. Don't use the resulting binary in production)\nendif\n\n# `USE_LTO=1` enables link-time optimizations. Among other things, this enables\n# more devirtualization opportunities and inlining across translation units.\n# This can save significant overhead introduced by RocksDB's pluggable\n# interfaces/internal abstractions, like in the iterator hierarchy. It works\n# better when combined with profile-guided optimizations (not currently\n# supported natively in Makefile).\nifeq ($(USE_LTO), 1)\n\tCXXFLAGS += -flto\n\tLDFLAGS += -flto -fuse-linker-plugin\nendif\n\n# `COERCE_CONTEXT_SWITCH=1` will inject spurious wakeup and\n# random length of sleep or context switch at critical\n# points (e.g, before acquring db mutex) in RocksDB.\n# In this way, it coerces as many excution orders as possible in the hope of\n# exposing the problematic excution order\nCOERCE_CONTEXT_SWITCH ?= 0\nifeq ($(COERCE_CONTEXT_SWITCH), 1)\nOPT += -DCOERCE_CONTEXT_SWITCH\nendif\n\n#-----------------------------------------------\ninclude src.mk\n\nAM_DEFAULT_VERBOSITY ?= 0\n\nAM_V_GEN = $(am__v_GEN_$(V))\nam__v_GEN_ = $(am__v_GEN_$(AM_DEFAULT_VERBOSITY))\nam__v_GEN_0 = @echo \"  GEN     \" $@;\nam__v_GEN_1 =\nAM_V_at = $(am__v_at_$(V))\nam__v_at_ = $(am__v_at_$(AM_DEFAULT_VERBOSITY))\nam__v_at_0 = @\nam__v_at_1 =\n\nAM_V_CC = $(am__v_CC_$(V))\nam__v_CC_ = $(am__v_CC_$(AM_DEFAULT_VERBOSITY))\nam__v_CC_0 = @echo \"  CC      \" $@;\nam__v_CC_1 =\n\nAM_V_CCLD = $(am__v_CCLD_$(V))\nam__v_CCLD_ = $(am__v_CCLD_$(AM_DEFAULT_VERBOSITY))\nifneq ($(SKIP_LINK), 1)\nam__v_CCLD_0 = @echo \"  CCLD    \" $@;\nam__v_CCLD_1 =\nelse\nam__v_CCLD_0 = @echo \"  !CCLD   \" $@; true skip\nam__v_CCLD_1 = true skip\nendif\nAM_V_AR = $(am__v_AR_$(V))\nam__v_AR_ = $(am__v_AR_$(AM_DEFAULT_VERBOSITY))\nam__v_AR_0 = @echo \"  AR      \" $@;\nam__v_AR_1 =\n\nAM_LINK = $(AM_V_CCLD)$(CXX) -L. $(patsubst lib%.a, -l%, $(patsubst lib%.$(PLATFORM_SHARED_EXT), -l%, $^)) $(EXEC_LDFLAGS) -o $@ $(LDFLAGS) $(COVERAGEFLAGS)\nAM_SHARE = $(AM_V_CCLD) $(CXX) $(PLATFORM_SHARED_LDFLAGS)$@ -L. $(patsubst lib%.$(PLATFORM_SHARED_EXT), -l%, $^) $(EXEC_LDFLAGS) $(LDFLAGS) -o $@\n\nROCKSDB_PLUGIN_MKS = $(foreach plugin, $(ROCKSDB_PLUGINS), plugin/$(plugin)/*.mk)\ninclude $(ROCKSDB_PLUGIN_MKS)\nROCKSDB_PLUGIN_PROTO =ROCKSDB_NAMESPACE::ObjectLibrary\\&, const std::string\\&\nROCKSDB_PLUGIN_SOURCES = $(foreach p, $(ROCKSDB_PLUGINS), $(foreach source, $($(p)_SOURCES), plugin/$(p)/$(source)))\nROCKSDB_PLUGIN_HEADERS = $(foreach p, $(ROCKSDB_PLUGINS), $(foreach header, $($(p)_HEADERS), plugin/$(p)/$(header)))\nROCKSDB_PLUGIN_LIBS = $(foreach p, $(ROCKSDB_PLUGINS), $(foreach lib, $($(p)_LIBS), -l$(lib)))\nROCKSDB_PLUGIN_W_FUNCS = $(foreach p, $(ROCKSDB_PLUGINS), $(if $($(p)_FUNC), $(p)))\nROCKSDB_PLUGIN_EXTERNS = $(foreach p, $(ROCKSDB_PLUGIN_W_FUNCS), int $($(p)_FUNC)($(ROCKSDB_PLUGIN_PROTO));)\nROCKSDB_PLUGIN_BUILTINS = $(foreach p, $(ROCKSDB_PLUGIN_W_FUNCS), {\\\"$(p)\\\"\\, $($(p)_FUNC)}\\,)\nROCKSDB_PLUGIN_LDFLAGS = $(foreach plugin, $(ROCKSDB_PLUGINS), $($(plugin)_LDFLAGS))\nROCKSDB_PLUGIN_PKGCONFIG_REQUIRES = $(foreach plugin, $(ROCKSDB_PLUGINS), $($(plugin)_PKGCONFIG_REQUIRES))\nROCKSDB_PLUGIN_TESTS = $(foreach p, $(ROCKSDB_PLUGINS), $(foreach test, $($(p)_TESTS), plugin/$(p)/$(test)))\n\nCXXFLAGS += $(foreach plugin, $(ROCKSDB_PLUGINS), $($(plugin)_CXXFLAGS))\nPLATFORM_LDFLAGS += $(ROCKSDB_PLUGIN_LDFLAGS)\n\n# Patch up the link flags for JNI from the plugins\nJAVA_LDFLAGS += $(ROCKSDB_PLUGIN_LDFLAGS)\nJAVA_STATIC_LDFLAGS += $(ROCKSDB_PLUGIN_LDFLAGS)\n\n# Patch up the list of java native sources with files from the plugins\nROCKSDB_PLUGIN_JNI_NATIVE_SOURCES = $(foreach plugin, $(ROCKSDB_PLUGINS), $(foreach source, $($(plugin)_JNI_NATIVE_SOURCES), plugin/$(plugin)/$(source)))\nALL_JNI_NATIVE_SOURCES = $(JNI_NATIVE_SOURCES) $(ROCKSDB_PLUGIN_JNI_NATIVE_SOURCES)\nROCKSDB_PLUGIN_JNI_CXX_INCLUDEFLAGS = $(foreach plugin, $(ROCKSDB_PLUGINS), -I./plugin/$(plugin))\n\nifneq ($(strip $(ROCKSDB_PLUGIN_PKGCONFIG_REQUIRES)),)\nLDFLAGS := $(LDFLAGS) $(shell pkg-config --libs $(ROCKSDB_PLUGIN_PKGCONFIG_REQUIRES))\nifneq ($(.SHELLSTATUS),0)\n$(error pkg-config failed)\nendif\nCXXFLAGS := $(CXXFLAGS) $(shell pkg-config --cflags $(ROCKSDB_PLUGIN_PKGCONFIG_REQUIRES))\nifneq ($(.SHELLSTATUS),0)\n$(error pkg-config failed)\nendif\nendif\n\nCXXFLAGS += $(ARCHFLAG)\n\nifeq (,$(shell $(CXX) -fsyntax-only -march=armv8-a+crc+crypto -xc /dev/null 2>&1))\nifneq ($(PLATFORM),OS_MACOSX)\nCXXFLAGS += -march=armv8-a+crc+crypto\nCFLAGS += -march=armv8-a+crc+crypto\nARMCRC_SOURCE=1\nendif\nendif\n\nexport JAVAC_ARGS\nCLEAN_FILES += make_config.mk rocksdb.pc\n\nifeq ($(V), 1)\n$(info $(shell uname -a))\n$(info $(shell $(CC) --version))\n$(info $(shell $(CXX) --version))\nendif\n\nmissing_make_config_paths := $(shell\t\t\t\t\\\n\tgrep \"\\./\\S*\\|/\\S*\" -o $(CURDIR)/make_config.mk | \t\\\n\twhile read path;\t\t\t\t\t\\\n\t\tdo [ -e $$path ] || echo $$path; \t\t\\\n\tdone | sort | uniq | grep -v \"/DOES/NOT/EXIST\")\n\n$(foreach path, $(missing_make_config_paths), \\\n\t$(warning Warning: $(path) does not exist))\n\nifeq ($(PLATFORM), OS_AIX)\n# no debug info\nelse ifneq ($(PLATFORM), IOS)\nCFLAGS += -g\nCXXFLAGS += -g\nelse\n# no debug info for IOS, that will make our library big\nOPT += -DNDEBUG\nendif\n\nifeq ($(PLATFORM), OS_AIX)\nARFLAGS = -X64 rs\nSTRIPFLAGS = -X64 -x\nendif\n\nifeq ($(PLATFORM), OS_SOLARIS)\n\tPLATFORM_CXXFLAGS += -D _GLIBCXX_USE_C99\nendif\n\nifeq ($(LIB_MODE),shared)\n# So that binaries are executable from build location, in addition to install location\nEXEC_LDFLAGS += -Wl,-rpath -Wl,'$$ORIGIN'\nendif\n\nifeq ($(PLATFORM), OS_MACOSX)\nifeq ($(ARCHFLAG), -arch arm64)\nifneq ($(MACHINE), arm64)\n# If we're building on a non-arm64 machine but targeting arm64 Mac, we need to disable\n# linking with jemalloc (as it won't be arm64-compatible) and remove some other options\n# set during platform detection\nDISABLE_JEMALLOC=1\nPLATFORM_CCFLAGS := $(filter-out -march=native, $(PLATFORM_CCFLAGS))\nPLATFORM_CXXFLAGS := $(filter-out -march=native, $(PLATFORM_CXXFLAGS))\nendif\nendif\nendif\n\n# ASAN doesn't work well with jemalloc. If we're compiling with ASAN, we should use regular malloc.\nifdef COMPILE_WITH_ASAN\n\tDISABLE_JEMALLOC=1\n\tASAN_OPTIONS?=detect_stack_use_after_return=1\n\texport ASAN_OPTIONS\n\tEXEC_LDFLAGS += -fsanitize=address\n\tPLATFORM_CCFLAGS += -fsanitize=address\n\tPLATFORM_CXXFLAGS += -fsanitize=address\nifeq ($(LIB_MODE),shared)\nifdef USE_CLANG\n# Fix false ODR violation; see https://github.com/google/sanitizers/issues/1017\n\tEXEC_LDFLAGS += -mllvm -asan-use-private-alias=1\n\tPLATFORM_CXXFLAGS += -mllvm -asan-use-private-alias=1\nendif\nendif\nendif\n\n# TSAN doesn't work well with jemalloc. If we're compiling with TSAN, we should use regular malloc.\nifdef COMPILE_WITH_TSAN\n\tDISABLE_JEMALLOC=1\n\tEXEC_LDFLAGS += -fsanitize=thread\n\tPLATFORM_CCFLAGS += -fsanitize=thread -fPIC -DFOLLY_SANITIZE_THREAD\n\tPLATFORM_CXXFLAGS += -fsanitize=thread -fPIC -DFOLLY_SANITIZE_THREAD\n        # Turn off -pg when enabling TSAN testing, because that induces\n        # a link failure.  TODO: find the root cause\n\tPROFILING_FLAGS =\n\t# LUA is not supported under TSAN\n\tLUA_PATH =\n\t# Limit keys for crash test under TSAN to avoid error:\n\t# \"ThreadSanitizer: DenseSlabAllocator overflow. Dying.\"\n\tCRASH_TEST_EXT_ARGS += --max_key=1000000\nendif\n\n# AIX doesn't work with -pg\nifeq ($(PLATFORM), OS_AIX)\n\tPROFILING_FLAGS =\nendif\n\n# USAN doesn't work well with jemalloc. If we're compiling with USAN, we should use regular malloc.\nifdef COMPILE_WITH_UBSAN\n\tDISABLE_JEMALLOC=1\n\t# Suppress alignment warning because murmurhash relies on casting unaligned\n\t# memory to integer. Fixing it may cause performance regression. 3-way crc32\n\t# relies on it too, although it can be rewritten to eliminate with minimal\n\t# performance regression.\n\tEXEC_LDFLAGS += -fsanitize=undefined -fno-sanitize-recover=all\n\tPLATFORM_CCFLAGS += -fsanitize=undefined -fno-sanitize-recover=all -DROCKSDB_UBSAN_RUN\n\tPLATFORM_CXXFLAGS += -fsanitize=undefined -fno-sanitize-recover=all -DROCKSDB_UBSAN_RUN\nendif\n\nifdef ROCKSDB_VALGRIND_RUN\n\tPLATFORM_CCFLAGS += -DROCKSDB_VALGRIND_RUN\n\tPLATFORM_CXXFLAGS += -DROCKSDB_VALGRIND_RUN\nendif\nifdef ROCKSDB_FULL_VALGRIND_RUN\n\t# Some tests are slow when run under valgrind and are only run when\n\t# explicitly requested via the ROCKSDB_FULL_VALGRIND_RUN compiler flag.\n\tPLATFORM_CCFLAGS += -DROCKSDB_VALGRIND_RUN -DROCKSDB_FULL_VALGRIND_RUN\n\tPLATFORM_CXXFLAGS += -DROCKSDB_VALGRIND_RUN -DROCKSDB_FULL_VALGRIND_RUN\nendif\n\nifndef DISABLE_JEMALLOC\n\tifdef JEMALLOC\n\t\tPLATFORM_CXXFLAGS += -DROCKSDB_JEMALLOC -DJEMALLOC_NO_DEMANGLE\n\t\tPLATFORM_CCFLAGS  += -DROCKSDB_JEMALLOC -DJEMALLOC_NO_DEMANGLE\n\t\tifeq ($(USE_FOLLY),1)\n\t\t\tPLATFORM_CXXFLAGS += -DUSE_JEMALLOC\n\t\t\tPLATFORM_CCFLAGS  += -DUSE_JEMALLOC\n\t\tendif\n\t\tifeq ($(USE_FOLLY_LITE),1)\n\t\t\tPLATFORM_CXXFLAGS += -DUSE_JEMALLOC\n\t\t\tPLATFORM_CCFLAGS  += -DUSE_JEMALLOC\n\t\tendif\n\tendif\n\tifdef WITH_JEMALLOC_FLAG\n\t\tPLATFORM_LDFLAGS += -ljemalloc\n\t\tJAVA_LDFLAGS += -ljemalloc\n\tendif\n\tEXEC_LDFLAGS := $(JEMALLOC_LIB) $(EXEC_LDFLAGS)\n\tPLATFORM_CXXFLAGS += $(JEMALLOC_INCLUDE)\n\tPLATFORM_CCFLAGS += $(JEMALLOC_INCLUDE)\nendif\n\nifndef USE_FOLLY\n\tUSE_FOLLY=0\nendif\n\nifndef GTEST_THROW_ON_FAILURE\n\texport GTEST_THROW_ON_FAILURE=1\nendif\nifndef GTEST_HAS_EXCEPTIONS\n\texport GTEST_HAS_EXCEPTIONS=1\nendif\n\nGTEST_DIR = third-party/gtest-1.8.1/fused-src\n# AIX: pre-defined system headers are surrounded by an extern \"C\" block\nifeq ($(PLATFORM), OS_AIX)\n\tPLATFORM_CCFLAGS += -I$(GTEST_DIR)\n\tPLATFORM_CXXFLAGS += -I$(GTEST_DIR)\nelse\n\tPLATFORM_CCFLAGS += -isystem $(GTEST_DIR)\n\tPLATFORM_CXXFLAGS += -isystem $(GTEST_DIR)\nendif\n\n# This provides a Makefile simulation of a Meta-internal folly integration.\n# It is not validated for general use.\n#\n# USE_FOLLY links the build targets with libfolly.a. The latter could be\n# built using 'make build_folly', or built externally and specified in\n# the CXXFLAGS and EXTRA_LDFLAGS env variables. The build_detect_platform\n# script tries to detect if an external folly dependency has been specified.\n# If not, it exports FOLLY_PATH to the path of the installed Folly and\n# dependency libraries.\n#\n# USE_FOLLY_LITE cherry picks source files from Folly to include in the\n# RocksDB library. Its faster and has fewer dependencies on 3rd party\n# libraries, but with limited functionality. For example, coroutine\n# functionality is not available.\nifeq ($(USE_FOLLY),1)\nifeq ($(USE_FOLLY_LITE),1)\n$(error Please specify only one of USE_FOLLY and USE_FOLLY_LITE)\nendif\nifneq ($(strip $(FOLLY_PATH)),)\n\tBOOST_PATH = $(shell (ls -d $(FOLLY_PATH)/../boost*))\n\tDBL_CONV_PATH = $(shell (ls -d $(FOLLY_PATH)/../double-conversion*))\n\tGFLAGS_PATH = $(shell (ls -d $(FOLLY_PATH)/../gflags*))\n\tGLOG_PATH = $(shell (ls -d $(FOLLY_PATH)/../glog*))\n\tLIBEVENT_PATH = $(shell (ls -d $(FOLLY_PATH)/../libevent*))\n\tXZ_PATH = $(shell (ls -d $(FOLLY_PATH)/../xz*))\n\tLIBSODIUM_PATH = $(shell (ls -d $(FOLLY_PATH)/../libsodium*))\n\tFMT_PATH = $(shell (ls -d $(FOLLY_PATH)/../fmt*))\n\n\t# For some reason, glog and fmt libraries are under either lib or lib64\n\tGLOG_LIB_PATH = $(shell (ls -d $(GLOG_PATH)/lib*))\n\tFMT_LIB_PATH = $(shell (ls -d $(FMT_PATH)/lib*))\n\n\t# AIX: pre-defined system headers are surrounded by an extern \"C\" block\n\tifeq ($(PLATFORM), OS_AIX)\n\t\tPLATFORM_CCFLAGS += -I$(BOOST_PATH)/include -I$(DBL_CONV_PATH)/include -I$(GLOG_PATH)/include -I$(LIBEVENT_PATH)/include -I$(XZ_PATH)/include -I$(LIBSODIUM_PATH)/include -I$(FOLLY_PATH)/include -I$(FMT_PATH)/include\n\t\tPLATFORM_CXXFLAGS += -I$(BOOST_PATH)/include -I$(DBL_CONV_PATH)/include -I$(GLOG_PATH)/include -I$(LIBEVENT_PATH)/include -I$(XZ_PATH)/include -I$(LIBSODIUM_PATH)/include -I$(FOLLY_PATH)/include -I$(FMT_PATH)/include\n\telse\n\t\tPLATFORM_CCFLAGS += -isystem $(BOOST_PATH)/include -isystem $(DBL_CONV_PATH)/include -isystem $(GLOG_PATH)/include -isystem $(LIBEVENT_PATH)/include -isystem $(XZ_PATH)/include -isystem $(LIBSODIUM_PATH)/include -isystem $(FOLLY_PATH)/include -isystem $(FMT_PATH)/include\n\t\tPLATFORM_CXXFLAGS += -isystem $(BOOST_PATH)/include -isystem $(DBL_CONV_PATH)/include -isystem $(GLOG_PATH)/include -isystem $(LIBEVENT_PATH)/include -isystem $(XZ_PATH)/include -isystem $(LIBSODIUM_PATH)/include -isystem $(FOLLY_PATH)/include -isystem $(FMT_PATH)/include\n\tendif\n\n\t# Add -ldl at the end as gcc resolves a symbol in a library by searching only in libraries specified later\n\t# in the command line\n\tPLATFORM_LDFLAGS += $(FOLLY_PATH)/lib/libfolly.a $(BOOST_PATH)/lib/libboost_context.a $(BOOST_PATH)/lib/libboost_filesystem.a $(BOOST_PATH)/lib/libboost_atomic.a $(BOOST_PATH)/lib/libboost_program_options.a $(BOOST_PATH)/lib/libboost_regex.a $(BOOST_PATH)/lib/libboost_system.a $(BOOST_PATH)/lib/libboost_thread.a $(DBL_CONV_PATH)/lib/libdouble-conversion.a $(FMT_LIB_PATH)/libfmt.a $(GLOG_LIB_PATH)/libglog.so $(GFLAGS_PATH)/lib/libgflags.so.2.2 $(LIBEVENT_PATH)/lib/libevent-2.1.so -ldl\n\tPLATFORM_LDFLAGS += -Wl,-rpath=$(GFLAGS_PATH)/lib -Wl,-rpath=$(GLOG_LIB_PATH) -Wl,-rpath=$(LIBEVENT_PATH)/lib -Wl,-rpath=$(LIBSODIUM_PATH)/lib -Wl,-rpath=$(LIBEVENT_PATH)/lib\nendif\n\tPLATFORM_CCFLAGS += -DUSE_FOLLY -DFOLLY_NO_CONFIG\n\tPLATFORM_CXXFLAGS += -DUSE_FOLLY -DFOLLY_NO_CONFIG\nendif\n\nifeq ($(USE_FOLLY_LITE),1)\n\t# Path to the Folly source code and include files\n\tFOLLY_DIR = ./third-party/folly\nifneq ($(strip $(BOOST_SOURCE_PATH)),)\n\tBOOST_INCLUDE = $(shell (ls -d $(BOOST_SOURCE_PATH)/boost*/))\n\t# AIX: pre-defined system headers are surrounded by an extern \"C\" block\n\tifeq ($(PLATFORM), OS_AIX)\n\t\tPLATFORM_CCFLAGS += -I$(BOOST_INCLUDE)\n\t\tPLATFORM_CXXFLAGS += -I$(BOOST_INCLUDE)\n\telse\n\t\tPLATFORM_CCFLAGS += -isystem $(BOOST_INCLUDE)\n\t\tPLATFORM_CXXFLAGS += -isystem $(BOOST_INCLUDE)\n\tendif\nendif  # BOOST_SOURCE_PATH\n\t# AIX: pre-defined system headers are surrounded by an extern \"C\" block\n\tifeq ($(PLATFORM), OS_AIX)\n\t\tPLATFORM_CCFLAGS += -I$(FOLLY_DIR)\n\t\tPLATFORM_CXXFLAGS += -I$(FOLLY_DIR)\n\telse\n\t\tPLATFORM_CCFLAGS += -isystem $(FOLLY_DIR)\n\t\tPLATFORM_CXXFLAGS += -isystem $(FOLLY_DIR)\n\tendif\n\tPLATFORM_CCFLAGS += -DUSE_FOLLY -DFOLLY_NO_CONFIG\n\tPLATFORM_CXXFLAGS += -DUSE_FOLLY -DFOLLY_NO_CONFIG\n# TODO: fix linking with fbcode compiler config\n\tPLATFORM_LDFLAGS += -lglog\nendif\n\nifdef TEST_CACHE_LINE_SIZE\n  PLATFORM_CCFLAGS += -DTEST_CACHE_LINE_SIZE=$(TEST_CACHE_LINE_SIZE)\n  PLATFORM_CXXFLAGS += -DTEST_CACHE_LINE_SIZE=$(TEST_CACHE_LINE_SIZE)\nendif\nifdef TEST_UINT128_COMPAT\n  PLATFORM_CCFLAGS += -DTEST_UINT128_COMPAT=1\n  PLATFORM_CXXFLAGS += -DTEST_UINT128_COMPAT=1\nendif\nifdef ROCKSDB_MODIFY_NPHASH\n  PLATFORM_CCFLAGS += -DROCKSDB_MODIFY_NPHASH=1\n  PLATFORM_CXXFLAGS += -DROCKSDB_MODIFY_NPHASH=1\nendif\n\n# This (the first rule) must depend on \"all\".\ndefault: all\n\nWARNING_FLAGS = -W -Wextra -Wall -Wsign-compare -Wshadow \\\n  -Wunused-parameter\n\nifeq (,$(filter amd64, $(MACHINE)))\n\tC_WARNING_FLAGS = -Wstrict-prototypes\nendif\n\nifdef USE_CLANG\n\t# Used by some teams in Facebook\n\tWARNING_FLAGS += -Wshift-sign-overflow -Wambiguous-reversed-operator \\\n\t  -Wimplicit-fallthrough -Wreinterpret-base-class -Wundefined-reinterpret-cast\nendif\n\nifeq ($(PLATFORM), OS_OPENBSD)\n\tWARNING_FLAGS += -Wno-unused-lambda-capture\nendif\n\nifndef DISABLE_WARNING_AS_ERROR\n\tWARNING_FLAGS += -Werror\nendif\n\n\nifdef LUA_PATH\n\nifndef LUA_INCLUDE\nLUA_INCLUDE=$(LUA_PATH)/include\nendif\n\nLUA_INCLUDE_FILE=$(LUA_INCLUDE)/lualib.h\n\nifeq (\"$(wildcard $(LUA_INCLUDE_FILE))\", \"\")\n# LUA_INCLUDE_FILE does not exist\n$(error Cannot find lualib.h under $(LUA_INCLUDE).  Try to specify both LUA_PATH and LUA_INCLUDE manually)\nendif\nLUA_FLAGS = -I$(LUA_INCLUDE) -DLUA -DLUA_COMPAT_ALL\nCFLAGS += $(LUA_FLAGS)\nCXXFLAGS += $(LUA_FLAGS)\n\nifndef LUA_LIB\nLUA_LIB = $(LUA_PATH)/lib/liblua.a\nendif\nifeq (\"$(wildcard $(LUA_LIB))\", \"\") # LUA_LIB does not exist\n$(error $(LUA_LIB) does not exist.  Try to specify both LUA_PATH and LUA_LIB manually)\nendif\nEXEC_LDFLAGS += $(LUA_LIB)\n\nendif\n\nifeq ($(NO_THREEWAY_CRC32C), 1)\n\tCXXFLAGS += -DNO_THREEWAY_CRC32C\nendif\n\nCFLAGS += $(C_WARNING_FLAGS) $(WARNING_FLAGS) -I. -I./include $(PLATFORM_CCFLAGS) $(OPT)\nCXXFLAGS += $(WARNING_FLAGS) -I. -I./include $(PLATFORM_CXXFLAGS) $(OPT) -Woverloaded-virtual -Wnon-virtual-dtor -Wno-missing-field-initializers\n\n# Allow offsetof to work on non-standard layout types. Some compiler could\n# completely reject our usage of offsetof, but we will solve that when it\n# happens.\nCXXFLAGS += -Wno-invalid-offsetof\n\nLDFLAGS += $(PLATFORM_LDFLAGS)\n\nLIB_OBJECTS = $(patsubst %.cc, $(OBJ_DIR)/%.o, $(LIB_SOURCES))\nLIB_OBJECTS += $(patsubst %.cc, $(OBJ_DIR)/%.o, $(ROCKSDB_PLUGIN_SOURCES))\nifeq ($(HAVE_POWER8),1)\nLIB_OBJECTS += $(patsubst %.c, $(OBJ_DIR)/%.o, $(LIB_SOURCES_C))\nLIB_OBJECTS += $(patsubst %.S, $(OBJ_DIR)/%.o, $(LIB_SOURCES_ASM))\nendif\n\nifeq ($(USE_FOLLY_LITE),1)\n  LIB_OBJECTS += $(patsubst %.cpp, $(OBJ_DIR)/%.o, $(FOLLY_SOURCES))\nendif\n\n# range_tree is not compatible with non GNU libc on ppc64\n# see https://jira.percona.com/browse/PS-7559\nifneq ($(PPC_LIBC_IS_GNU),0)\n  LIB_OBJECTS += $(patsubst %.cc, $(OBJ_DIR)/%.o, $(RANGE_TREE_SOURCES))\nendif\n\nGTEST = $(OBJ_DIR)/$(GTEST_DIR)/gtest/gtest-all.o\nTESTUTIL = $(OBJ_DIR)/test_util/testutil.o\nTESTHARNESS = $(OBJ_DIR)/test_util/testharness.o $(TESTUTIL) $(GTEST)\nVALGRIND_ERROR = 2\nVALGRIND_VER := $(join $(VALGRIND_VER),valgrind)\n\nVALGRIND_OPTS = --error-exitcode=$(VALGRIND_ERROR) --leak-check=full\n# Not yet supported: --show-leak-kinds=definite,possible,reachable --errors-for-leak-kinds=definite,possible,reachable\n\n# Work around valgrind hanging on systems with limited internet access\nifneq ($(shell which git 2>/dev/null && git config --get https.proxy),)\n  export DEBUGINFOD_URLS=\nendif\n\nTEST_OBJECTS = $(patsubst %.cc, $(OBJ_DIR)/%.o, $(TEST_LIB_SOURCES) $(MOCK_LIB_SOURCES)) $(GTEST)\nBENCH_OBJECTS = $(patsubst %.cc, $(OBJ_DIR)/%.o, $(BENCH_LIB_SOURCES))\nCACHE_BENCH_OBJECTS = $(patsubst %.cc, $(OBJ_DIR)/%.o, $(CACHE_BENCH_LIB_SOURCES))\nTOOL_OBJECTS = $(patsubst %.cc, $(OBJ_DIR)/%.o, $(TOOL_LIB_SOURCES))\nANALYZE_OBJECTS = $(patsubst %.cc, $(OBJ_DIR)/%.o, $(ANALYZER_LIB_SOURCES))\nSTRESS_OBJECTS =  $(patsubst %.cc, $(OBJ_DIR)/%.o, $(STRESS_LIB_SOURCES))\n\n# Exclude build_version.cc -- a generated source file -- from all sources.  Not needed for dependencies\nALL_SOURCES  = $(filter-out util/build_version.cc, $(LIB_SOURCES)) $(TEST_LIB_SOURCES) $(MOCK_LIB_SOURCES) $(GTEST_DIR)/gtest/gtest-all.cc\nALL_SOURCES += $(TOOL_LIB_SOURCES) $(BENCH_LIB_SOURCES) $(CACHE_BENCH_LIB_SOURCES) $(ANALYZER_LIB_SOURCES) $(STRESS_LIB_SOURCES)\nALL_SOURCES += $(TEST_MAIN_SOURCES) $(TOOL_MAIN_SOURCES) $(BENCH_MAIN_SOURCES)\nALL_SOURCES += $(ROCKSDB_PLUGIN_SOURCES) $(ROCKSDB_PLUGIN_TESTS)\n\nPLUGIN_TESTS = $(patsubst %.cc, %, $(notdir $(ROCKSDB_PLUGIN_TESTS)))\nTESTS = $(patsubst %.cc, %, $(notdir $(TEST_MAIN_SOURCES)))\nTESTS += $(patsubst %.c, %, $(notdir $(TEST_MAIN_SOURCES_C)))\nTESTS += $(PLUGIN_TESTS)\n\n# `make check-headers` to verify that each header file includes its own deps\n# and that public headers do not depend on internal headers\nifneq ($(filter check-headers, $(MAKECMDGOALS)),)\n# TODO: add/support JNI headers\n\tDEV_HEADER_DIRS := $(sort include/ $(dir $(ALL_SOURCES)))\n# Some headers like in port/ are platform-specific\n\tDEV_HEADERS_TO_CHECK := $(shell $(FIND) $(DEV_HEADER_DIRS) -type f -name '*.h' | grep -E -v 'port/|plugin/|lua/|range_tree/|secondary_index/')\n\tPUBLIC_HEADERS_TO_CHECK := $(shell $(FIND) include/ -type f -name '*.h' | grep -E -v 'lua/')\nelse\n\tDEV_HEADERS_TO_CHECK :=\n\tPUBLIC_HEADERS_TO_CHECK :=\nendif\nHEADER_OK_FILES = $(patsubst %.h, %.h.ok, $(DEV_HEADERS_TO_CHECK)) \\\n\t$(patsubst %.h, %.h.pub, $(PUBLIC_HEADERS_TO_CHECK))\n\nAM_V_CCH = $(am__v_CCH_$(V))\nam__v_CCH_ = $(am__v_CCH_$(AM_DEFAULT_VERBOSITY))\nam__v_CCH_0 = @echo \"  CC.h    \" $<;\nam__v_CCH_1 =\n\n# verify headers include their own dependencies, under dev build settings\n%.h.ok: %.h # .h.ok not actually created, so re-checked on each invocation\n# -DROCKSDB_NAMESPACE=42 ensures the namespace header is included\n\t$(AM_V_CCH) echo '#include \"$<\"' | $(CXX) $(CXXFLAGS) \\\n\t  -DROCKSDB_NAMESPACE=42 -x c++ -c - -o /dev/null\n\n# verify public headers do not depend on internal headers, under typical\n# user build settings\n%.h.pub: %.h # .h.pub not actually created, so re-checked on each invocation\n\t$(AM_V_CCH) cd include/ && echo '#include \"$(patsubst include/%,%,$<)\"' | \\\n\t  $(CXX) -I. -DROCKSDB_NAMESPACE=42 -x c++ -c - -o /dev/null\n\ncheck-headers: $(HEADER_OK_FILES)\n\n# options_settable_test doesn't pass with UBSAN as we use hack in the test\nifdef ASSERT_STATUS_CHECKED\n# TODO: finish fixing all tests to pass this check\nTESTS_FAILING_ASC = \\\n\tc_test \\\n\tenv_test \\\n\trange_locking_test \\\n\ttestutil_test \\\n\n# Since we have very few ASC exclusions left, excluding them from\n# the build is the most convenient way to exclude them from testing\nTESTS := $(filter-out $(TESTS_FAILING_ASC),$(TESTS))\nendif\n\nROCKSDBTESTS_SUBSET ?= $(TESTS)\n\n# c_test - doesn't use gtest\n# env_test - suspicious use of test::TmpDir\n# deletefile_test - serial because it generates giant temporary files in\n#   its various tests. Parallel can fill up your /dev/shm\n# db_bloom_filter_test - serial because excessive space usage by instances\n#   of DBFilterConstructionReserveMemoryTestWithParam can fill up /dev/shm\nNON_PARALLEL_TEST = \\\n\tc_test \\\n\tenv_test \\\n\tdeletefile_test \\\n\tdb_bloom_filter_test \\\n\t$(PLUGIN_TESTS) \\\n\nPARALLEL_TEST = $(filter-out $(NON_PARALLEL_TEST), $(TESTS))\n\n# Not necessarily well thought out or up-to-date, but matches old list\nTESTS_PLATFORM_DEPENDENT := \\\n\tdb_basic_test \\\n\tdb_blob_basic_test \\\n\tdb_encryption_test \\\n\texternal_sst_file_basic_test \\\n\tauto_roll_logger_test \\\n\tbloom_test \\\n\tdynamic_bloom_test \\\n\tc_test \\\n\tcheckpoint_test \\\n\tcrc32c_test \\\n\tcoding_test \\\n\tinlineskiplist_test \\\n\tenv_basic_test \\\n\tenv_test \\\n\tenv_logger_test \\\n\tio_posix_test \\\n\thash_test \\\n\trandom_test \\\n\tribbon_test \\\n\tthread_local_test \\\n\twork_queue_test \\\n\trate_limiter_test \\\n\tperf_context_test \\\n\tiostats_context_test \\\n\n# Sort ROCKSDBTESTS_SUBSET for filtering, except db_test is special (expensive)\n# so is placed first (out-of-order)\nROCKSDBTESTS_SUBSET := $(filter db_test, $(ROCKSDBTESTS_SUBSET)) $(sort $(filter-out db_test, $(ROCKSDBTESTS_SUBSET)))\n\nifdef ROCKSDBTESTS_START\n        ROCKSDBTESTS_SUBSET := $(shell echo $(ROCKSDBTESTS_SUBSET) | sed 's/^.*$(ROCKSDBTESTS_START)/$(ROCKSDBTESTS_START)/')\nendif\n\nifdef ROCKSDBTESTS_END\n        ROCKSDBTESTS_SUBSET := $(shell echo $(ROCKSDBTESTS_SUBSET) | sed 's/$(ROCKSDBTESTS_END).*//')\nendif\n\nifeq ($(ROCKSDBTESTS_PLATFORM_DEPENDENT), only)\n        ROCKSDBTESTS_SUBSET := $(filter $(TESTS_PLATFORM_DEPENDENT), $(ROCKSDBTESTS_SUBSET))\nelse ifeq ($(ROCKSDBTESTS_PLATFORM_DEPENDENT), exclude)\n        ROCKSDBTESTS_SUBSET := $(filter-out $(TESTS_PLATFORM_DEPENDENT), $(ROCKSDBTESTS_SUBSET))\nendif\n\n# bench_tool_analyer main is in bench_tool_analyzer_tool, or this would be simpler...\nTOOLS = $(patsubst %.cc, %, $(notdir $(patsubst %_tool.cc, %.cc, $(TOOLS_MAIN_SOURCES))))\n\nTEST_LIBS = \\\n\tlibrocksdb_env_basic_test.a\n\n# TODO: add back forward_iterator_bench, after making it build in all environemnts.\nBENCHMARKS = $(patsubst %.cc, %, $(notdir $(BENCH_MAIN_SOURCES)))\n\nMICROBENCHS = $(patsubst %.cc, %, $(notdir $(MICROBENCH_SOURCES)))\n\n# if user didn't config LIBNAME, set the default\nifeq ($(LIBNAME),)\n  LIBNAME=librocksdb\n# we should only run rocksdb in production with DEBUG_LEVEL 0\nifneq ($(DEBUG_LEVEL),0)\n  LIBDEBUG=_debug\nendif\nendif\nSTATIC_LIBRARY = ${LIBNAME}$(LIBDEBUG).a\nSTATIC_TEST_LIBRARY =  ${LIBNAME}_test$(LIBDEBUG).a\nSTATIC_TOOLS_LIBRARY = ${LIBNAME}_tools$(LIBDEBUG).a\nSTATIC_STRESS_LIBRARY = ${LIBNAME}_stress$(LIBDEBUG).a\n\nALL_STATIC_LIBS = $(STATIC_LIBRARY) $(STATIC_TEST_LIBRARY) $(STATIC_TOOLS_LIBRARY) $(STATIC_STRESS_LIBRARY)\n\nSHARED_TEST_LIBRARY =  ${LIBNAME}_test$(LIBDEBUG).$(PLATFORM_SHARED_EXT)\nSHARED_TOOLS_LIBRARY = ${LIBNAME}_tools$(LIBDEBUG).$(PLATFORM_SHARED_EXT)\nSHARED_STRESS_LIBRARY = ${LIBNAME}_stress$(LIBDEBUG).$(PLATFORM_SHARED_EXT)\n\nALL_SHARED_LIBS = $(SHARED1) $(SHARED2) $(SHARED3) $(SHARED4) $(SHARED_TEST_LIBRARY) $(SHARED_TOOLS_LIBRARY) $(SHARED_STRESS_LIBRARY)\n\nifeq ($(LIB_MODE),shared)\nLIBRARY=$(SHARED1)\nTEST_LIBRARY=$(SHARED_TEST_LIBRARY)\nTOOLS_LIBRARY=$(SHARED_TOOLS_LIBRARY)\nSTRESS_LIBRARY=$(SHARED_STRESS_LIBRARY)\nCLOUD_LIBRARY=$(SHARED_CLOUD_LIBRARY)\nelse\nLIBRARY=$(STATIC_LIBRARY)\nTEST_LIBRARY=$(STATIC_TEST_LIBRARY)\nTOOLS_LIBRARY=$(STATIC_TOOLS_LIBRARY)\nendif\nSTRESS_LIBRARY=$(STATIC_STRESS_LIBRARY)\n\nROCKSDB_MAJOR = $(shell grep -E \"ROCKSDB_MAJOR.[0-9]\" include/rocksdb/version.h | cut -d ' ' -f 3)\nROCKSDB_MINOR = $(shell grep -E \"ROCKSDB_MINOR.[0-9]\" include/rocksdb/version.h | cut -d ' ' -f 3)\nROCKSDB_PATCH = $(shell grep -E \"ROCKSDB_PATCH.[0-9]\" include/rocksdb/version.h | cut -d ' ' -f 3)\n\n# If NO_UPDATE_BUILD_VERSION is set we don't update util/build_version.cc, but\n# the file needs to already exist or else the build will fail\nifndef NO_UPDATE_BUILD_VERSION\n\n# By default, use the current date-time as the date.  If there are no changes,\n# we will use the last commit date instead.\nbuild_date := $(shell date \"+%Y-%m-%d %T\")\n\nifdef FORCE_GIT_SHA\n\tgit_sha := $(FORCE_GIT_SHA)\n\tgit_mod := 1\n\tgit_date := $(build_date)\nelse\n\tgit_sha := $(shell git rev-parse HEAD 2>/dev/null)\n\tgit_tag  := $(shell git symbolic-ref -q --short HEAD 2> /dev/null || git describe --tags --exact-match 2>/dev/null)\n\tgit_mod  := $(shell git diff-index HEAD --quiet 2>/dev/null; echo $$?)\n\tgit_date := $(shell git log -1 --date=format:\"%Y-%m-%d %T\" --format=\"%ad\" 2>/dev/null)\nendif\ngen_build_version = sed -e s/@GIT_SHA@/$(git_sha)/ -e s:@GIT_TAG@:\"$(git_tag)\": -e s/@GIT_MOD@/\"$(git_mod)\"/ -e s/@BUILD_DATE@/\"$(build_date)\"/ -e s/@GIT_DATE@/\"$(git_date)\"/ -e s/@ROCKSDB_PLUGIN_BUILTINS@/'$(ROCKSDB_PLUGIN_BUILTINS)'/ -e s/@ROCKSDB_PLUGIN_EXTERNS@/\"$(ROCKSDB_PLUGIN_EXTERNS)\"/ util/build_version.cc.in\n\n# Record the version of the source that we are compiling.\n# We keep a record of the git revision in this file.  It is then built\n# as a regular source file as part of the compilation process.\n# One can run \"strings executable_filename | grep _build_\" to find\n# the version of the source that we used to build the executable file.\nutil/build_version.cc: $(filter-out $(OBJ_DIR)/util/build_version.o, $(LIB_OBJECTS)) util/build_version.cc.in\n\t$(AM_V_GEN)rm -f $@-t\n\t$(AM_V_at)$(gen_build_version) > $@\nendif\nCLEAN_FILES += util/build_version.cc\n\ndefault: all\n\n#-----------------------------------------------\n# Create platform independent shared libraries.\n#-----------------------------------------------\nifneq ($(PLATFORM_SHARED_EXT),)\n\nifneq ($(PLATFORM_SHARED_VERSIONED),true)\nSHARED1 = ${LIBNAME}$(LIBDEBUG).$(PLATFORM_SHARED_EXT)\nSHARED2 = $(SHARED1)\nSHARED3 = $(SHARED1)\nSHARED4 = $(SHARED1)\nSHARED = $(SHARED1)\nelse\nSHARED_MAJOR = $(ROCKSDB_MAJOR)\nSHARED_MINOR = $(ROCKSDB_MINOR)\nSHARED_PATCH = $(ROCKSDB_PATCH)\nSHARED1 = ${LIBNAME}.$(PLATFORM_SHARED_EXT)\nifeq ($(PLATFORM), OS_MACOSX)\nSHARED_OSX = $(LIBNAME)$(LIBDEBUG).$(SHARED_MAJOR)\nSHARED2 = $(SHARED_OSX).$(PLATFORM_SHARED_EXT)\nSHARED3 = $(SHARED_OSX).$(SHARED_MINOR).$(PLATFORM_SHARED_EXT)\nSHARED4 = $(SHARED_OSX).$(SHARED_MINOR).$(SHARED_PATCH).$(PLATFORM_SHARED_EXT)\nelse\nSHARED2 = $(SHARED1).$(SHARED_MAJOR)\nSHARED3 = $(SHARED1).$(SHARED_MAJOR).$(SHARED_MINOR)\nSHARED4 = $(SHARED1).$(SHARED_MAJOR).$(SHARED_MINOR).$(SHARED_PATCH)\nendif # MACOSX\nSHARED = $(SHARED1) $(SHARED2) $(SHARED3) $(SHARED4)\n$(SHARED1): $(SHARED4) $(SHARED2)\n\tln -fs $(SHARED4) $(SHARED1)\n$(SHARED2): $(SHARED4) $(SHARED3)\n\tln -fs $(SHARED4) $(SHARED2)\n$(SHARED3): $(SHARED4)\n\tln -fs $(SHARED4) $(SHARED3)\n\nendif   # PLATFORM_SHARED_VERSIONED\n$(SHARED4): $(LIB_OBJECTS)\n\t$(AM_V_CCLD) $(CXX) $(PLATFORM_SHARED_LDFLAGS)$(SHARED3) $(LIB_OBJECTS) $(LDFLAGS) -o $@\nendif  # PLATFORM_SHARED_EXT\n\n.PHONY: check clean coverage ldb_tests package dbg gen-pc build_size \\\n\trelease tags tags0 valgrind_check format static_lib shared_lib all \\\n\trocksdbjavastatic rocksdbjava install install-static install-shared \\\n\tuninstall analyze tools tools_lib check-headers checkout_folly\n\nall: $(LIBRARY) $(BENCHMARKS) tools tools_lib test_libs $(TESTS)\n\nall_but_some_tests: $(LIBRARY) $(BENCHMARKS) tools tools_lib test_libs $(ROCKSDBTESTS_SUBSET)\n\nstatic_lib: $(STATIC_LIBRARY)\n\nshared_lib: $(SHARED)\n\nstress_lib: $(STRESS_LIBRARY)\n\ntools: $(TOOLS)\n\ntools_lib: $(TOOLS_LIBRARY)\n\ntest_libs: $(TEST_LIBS)\n\nbenchmarks: $(BENCHMARKS)\n\nmicrobench: $(MICROBENCHS)\n\nrun_microbench: $(MICROBENCHS)\n\tfor t in $(MICROBENCHS); do echo \"===== Running benchmark $$t (`date`)\"; ./$$t || exit 1; done;\n\ndbg: $(LIBRARY) $(BENCHMARKS) tools $(TESTS)\n\n# creates library and programs\nrelease: clean\n\tLIB_MODE=$(LIB_MODE) DEBUG_LEVEL=0 $(MAKE) $(LIBRARY) tools db_bench\n\ncoverage: clean\n\tCOVERAGEFLAGS=\"-fprofile-arcs -ftest-coverage\" LDFLAGS+=\"-lgcov\" $(MAKE) J=1 all check\n\tcd coverage && ./coverage_test.sh\n\t# Delete intermediate files\n\t$(FIND) . -type f \\( -name \"*.gcda\" -o -name \"*.gcno\" \\) -exec rm -f {} \\;\n\n# Run all tests in parallel, accumulating per-test logs in t/log-*.\n#\n# Each t/run-* file is a tiny generated bourne shell script that invokes one of\n# sub-tests. Why use a file for this?  Because that makes the invocation of\n# parallel below simpler, which in turn makes the parsing of parallel's\n# LOG simpler (the latter is for live monitoring as parallel\n# tests run).\n#\n# Test names are extracted by running tests with --gtest_list_tests.\n# This filter removes the \"#\"-introduced comments, and expands to\n# fully-qualified names by changing input like this:\n#\n#   DBTest.\n#     Empty\n#     WriteEmptyBatch\n#   MultiThreaded/MultiThreadedDBTest.\n#     MultiThreaded/0  # GetParam() = 0\n#     MultiThreaded/1  # GetParam() = 1\n#\n# into this:\n#\n#   DBTest.Empty\n#   DBTest.WriteEmptyBatch\n#   MultiThreaded/MultiThreadedDBTest.MultiThreaded/0\n#   MultiThreaded/MultiThreadedDBTest.MultiThreaded/1\n#\n\nparallel_tests = $(patsubst %,parallel_%,$(PARALLEL_TEST))\n.PHONY: gen_parallel_tests $(parallel_tests)\n$(parallel_tests):\n\t$(AM_V_at)TEST_BINARY=$(patsubst parallel_%,%,$@); \\\n  TEST_NAMES=` \\\n    (./$$TEST_BINARY --gtest_list_tests || echo \"  $${TEST_BINARY}__list_tests_failure\") \\\n    | awk '/^[^ ]/ { prefix = $$1 } /^[ ]/ { print prefix $$1 }'`; \\\n\techo \"  Generating parallel test scripts for $$TEST_BINARY\"; \\\n\tfor TEST_NAME in $$TEST_NAMES; do \\\n\t\tTEST_SCRIPT=t/run-$$TEST_BINARY-$${TEST_NAME//\\//-}; \\\n    printf '%s\\n' \\\n      '#!/bin/sh' \\\n      \"d=\\$(TEST_TMPDIR)$$TEST_SCRIPT\" \\\n      'mkdir -p $$d' \\\n      \"TEST_TMPDIR=\\$$d $(DRIVER) ./$$TEST_BINARY --gtest_filter=$$TEST_NAME\" \\\n\t\t> $$TEST_SCRIPT; \\\n\t\tchmod a=rx $$TEST_SCRIPT; \\\n\tdone\n\ngen_parallel_tests:\n\t$(AM_V_at)mkdir -p t\n\t$(AM_V_at)$(FIND) t -type f -name 'run-*' -exec rm -f {} \\;\n\t$(MAKE) $(parallel_tests)\n\n# Reorder input lines (which are one per test) so that the\n# longest-running tests appear first in the output.\n# Do this by prefixing each selected name with its duration,\n# sort the resulting names, and remove the leading numbers.\n# FIXME: the \"100\" we prepend is a fake time, for now.\n# FIXME: squirrel away timings from each run and use them\n# (when present) on subsequent runs to order these tests.\n#\n# Without this reordering, these two tests would happen to start only\n# after almost all other tests had completed, thus adding 100 seconds\n# to the duration of parallel \"make check\".  That's the difference\n# between 4 minutes (old) and 2m20s (new).\n#\n# 152.120 PASS t/DBTest.FileCreationRandomFailure\n# 107.816 PASS t/DBTest.EncodeDecompressedBlockSizeTest\n#\nslow_test_regexp = \\\n\t^.*MySQLStyleTransactionTest.*$$|^.*SnapshotConcurrentAccessTest.*$$|^.*SeqAdvanceConcurrentTest.*$$|^t/run-table_test-HarnessTest.Randomized$$|^t/run-db_test-.*(?:FileCreationRandomFailure|EncodeDecompressedBlockSizeTest)$$|^.*RecoverFromCorruptedWALWithoutFlush$$\nprioritize_long_running_tests =\t\t\t\t\t\t\\\n  perl -pe 's,($(slow_test_regexp)),100 $$1,'\t\t\t\t\\\n    | sort -k1,1gr\t\t\t\t\t\t\t\\\n    | sed 's/^[.0-9]* //'\n\n# \"make check\" uses\n# Run with \"make J=1 check\" to disable parallelism in \"make check\".\n# Run with \"make J=200% check\" to run two parallel jobs per core.\n# The default is to run one job per core (J=100%).\n# See \"man parallel\" for its \"-j ...\" option.\nJ ?= 100%\n\n# Use this regexp to select the subset of tests whose names match.\ntests-regexp = .\nEXCLUDE_TESTS_REGEX ?= \"^$$\"\n\nifeq ($(PRINT_PARALLEL_OUTPUTS), 1)\n\tparallel_redir =\nelse ifeq ($(QUIET_PARALLEL_TESTS), 1)\n\tparallel_redir = >& t/$(test_log_prefix)log-{/}\nelse\n# Default: print failure output only, as it happens\n# Note: gnu_parallel --eta is now always used, but has been modified to provide\n# only infrequent updates when not connected to a terminal. (CircleCI will\n# kill a job if no output for 10min.)\n\tparallel_redir = >& t/$(test_log_prefix)log-{/} || bash -c \"cat t/$(test_log_prefix)log-{/}; exit $$?\"\nendif\n\n.PHONY: check_0\ncheck_0:\n\t@printf '%s\\n' ''\t\t\t\t\t\t\\\n\t  'To monitor subtest <duration,pass/fail,name>,'\t\t\\\n\t  '  run \"make watch-log\" in a separate window' '';\t\t\\\n\t{ \\\n\t\tprintf './%s\\n' $(filter-out $(PARALLEL_TEST),$(TESTS)); \\\n\t\tfind t -name 'run-*' -print; \\\n\t} \\\n\t  | $(prioritize_long_running_tests)\t\t\t\t\\\n\t  | grep -E '$(tests-regexp)'\t\t\t\t\t\\\n\t  | grep -E -v '$(EXCLUDE_TESTS_REGEX)'\t\t\t\t\t\\\n\t  | build_tools/gnu_parallel -j$(J) --plain --joblog=LOG --eta --gnu \\\n\t    --tmpdir=$(TEST_TMPDIR) '{} $(parallel_redir)' ; \\\n\tparallel_retcode=$$? ; \\\n\tawk '{ if ($$7 != 0 || $$8 != 0) { if ($$7 == \"Exitval\") { h = $$0; } else { if (!f) print h; print; f = 1 } } } END { if(f) exit 1; }' < LOG ; \\\n\tawk_retcode=$$?; \\\n\tif [ $$parallel_retcode -ne 0 ] || [ $$awk_retcode -ne 0 ] ; then exit 1 ; fi\n\nvalgrind-exclude-regexp = InlineSkipTest.ConcurrentInsert|TransactionStressTest.DeadlockStress|DBCompactionTest.SuggestCompactRangeNoTwoLevel0Compactions|BackupableDBTest.RateLimiting|DBTest.CloseSpeedup|DBTest.ThreadStatusFlush|DBTest.RateLimitingTest|DBTest.EncodeDecompressedBlockSizeTest|FaultInjectionTest.UninstalledCompaction|HarnessTest.Randomized|ExternalSSTFileTest.CompactDuringAddFileRandom|ExternalSSTFileTest.IngestFileWithGlobalSeqnoRandomized|MySQLStyleTransactionTest.TransactionStressTest\n\n.PHONY: valgrind_check_0\nvalgrind_check_0: test_log_prefix := valgrind_\nvalgrind_check_0:\n\t@printf '%s\\n' ''\t\t\t\t\t\t\\\n\t  'To monitor subtest <duration,pass/fail,name>,'\t\t\\\n\t  '  run \"make watch-log\" in a separate window' '';\t\t\\\n\t{\t\t\t\t\t\t\t\t\\\n\t  printf './%s\\n' $(filter-out $(PARALLEL_TEST) %skiplist_test options_settable_test, $(TESTS));\t\t\\\n\t  find t -name 'run-*' -print; \\\n\t}\t\t\t\t\t\t\t\t\\\n\t  | $(prioritize_long_running_tests)\t\t\t\t\\\n\t  | grep -E '$(tests-regexp)'\t\t\t\t\t\\\n\t  | grep -E -v '$(valgrind-exclude-regexp)'\t\t\t\t\t\\\n\t  | build_tools/gnu_parallel -j$(J) --plain --joblog=LOG --eta --gnu \\\n\t   --tmpdir=$(TEST_TMPDIR) \\\n\t   '(if [[ \"{}\" == \"./\"* ]] ; then $(DRIVER) {}; else {}; fi) \\\n\t  $(parallel_redir)' \\\n\nCLEAN_FILES += t LOG $(TEST_TMPDIR)\n\n# When running parallel \"make check\", you can monitor its progress\n# from another window.\n# Run \"make watch_LOG\" to show the duration,PASS/FAIL,name of parallel\n# tests as they are being run.  We sort them so that longer-running ones\n# appear at the top of the list and any failing tests remain at the top\n# regardless of their duration. As with any use of \"watch\", hit ^C to\n# interrupt.\nwatch-log:\n\t$(WATCH) --interval=0 'sort -k7,7nr -k4,4gr LOG|$(quoted_perl_command)'\n\ndump-log:\n\tbash -c '$(quoted_perl_command)' < LOG\n\n# If J != 1 and GNU parallel is installed, run the tests in parallel,\n# via the check_0 rule above.  Otherwise, run them sequentially.\ncheck: all\n\t$(MAKE) gen_parallel_tests\n\t$(AM_V_GEN)if test \"$(J)\" != 1                                  \\\n\t    && (build_tools/gnu_parallel --gnu --help 2>/dev/null) |                    \\\n\t        grep -q 'GNU Parallel';                                 \\\n\tthen                                                            \\\n\t    $(MAKE) T=\"$$t\" check_0;                       \\\n\telse                                                            \\\n\t    for t in $(TESTS); do                                       \\\n\t      echo \"===== Running $$t (`date`)\"; ./$$t || exit 1; done;          \\\n\tfi\n\trm -rf $(TEST_TMPDIR)\nifneq ($(PLATFORM), OS_AIX)\n\t$(PYTHON) tools/check_all_python.py\nifndef ASSERT_STATUS_CHECKED # not yet working with these tests\n\t$(PYTHON) tools/ldb_test.py\n\tsh tools/rocksdb_dump_test.sh\nendif\nendif\nifndef SKIP_FORMAT_BUCK_CHECKS\n\t$(MAKE) check-format\n\t$(MAKE) check-buck-targets\n\t$(MAKE) check-sources\nendif\n\n# TODO add ldb_tests\ncheck_some: $(ROCKSDBTESTS_SUBSET)\n\tfor t in $(ROCKSDBTESTS_SUBSET); do echo \"===== Running $$t (`date`)\"; ./$$t || exit 1; done\n\n.PHONY: ldb_tests\nldb_tests: ldb\n\t$(PYTHON) tools/ldb_test.py\n\ninclude crash_test.mk\n\nasan_check: clean\n\tCOMPILE_WITH_ASAN=1 $(MAKE) check -j32\n\t$(MAKE) clean\n\nasan_crash_test: clean\n\tCOMPILE_WITH_ASAN=1 $(MAKE) crash_test\n\t$(MAKE) clean\n\nwhitebox_asan_crash_test: clean\n\tCOMPILE_WITH_ASAN=1 $(MAKE) whitebox_crash_test\n\t$(MAKE) clean\n\nblackbox_asan_crash_test: clean\n\tCOMPILE_WITH_ASAN=1 $(MAKE) blackbox_crash_test\n\t$(MAKE) clean\n\nasan_crash_test_with_atomic_flush: clean\n\tCOMPILE_WITH_ASAN=1 $(MAKE) crash_test_with_atomic_flush\n\t$(MAKE) clean\n\nasan_crash_test_with_txn: clean\n\tCOMPILE_WITH_ASAN=1 $(MAKE) crash_test_with_txn\n\t$(MAKE) clean\n\nasan_crash_test_with_best_efforts_recovery: clean\n\tCOMPILE_WITH_ASAN=1 $(MAKE) crash_test_with_best_efforts_recovery\n\t$(MAKE) clean\n\nubsan_check: clean\n\tCOMPILE_WITH_UBSAN=1 $(MAKE) check -j32\n\t$(MAKE) clean\n\nubsan_crash_test: clean\n\tCOMPILE_WITH_UBSAN=1 $(MAKE) crash_test\n\t$(MAKE) clean\n\nwhitebox_ubsan_crash_test: clean\n\tCOMPILE_WITH_UBSAN=1 $(MAKE) whitebox_crash_test\n\t$(MAKE) clean\n\nblackbox_ubsan_crash_test: clean\n\tCOMPILE_WITH_UBSAN=1 $(MAKE) blackbox_crash_test\n\t$(MAKE) clean\n\nubsan_crash_test_with_atomic_flush: clean\n\tCOMPILE_WITH_UBSAN=1 $(MAKE) crash_test_with_atomic_flush\n\t$(MAKE) clean\n\nubsan_crash_test_with_txn: clean\n\tCOMPILE_WITH_UBSAN=1 $(MAKE) crash_test_with_txn\n\t$(MAKE) clean\n\nubsan_crash_test_with_best_efforts_recovery: clean\n\tCOMPILE_WITH_UBSAN=1 $(MAKE) crash_test_with_best_efforts_recovery\n\t$(MAKE) clean\n\nfull_valgrind_test:\n\tROCKSDB_FULL_VALGRIND_RUN=1 DISABLE_JEMALLOC=1 PORTABLE=1 $(MAKE) valgrind_check\n\nfull_valgrind_test_some:\n\tROCKSDB_FULL_VALGRIND_RUN=1 DISABLE_JEMALLOC=1 PORTABLE=1 $(MAKE) valgrind_check_some\n\nvalgrind_test:\n\tROCKSDB_VALGRIND_RUN=1 DISABLE_JEMALLOC=1 PORTABLE=1 $(MAKE) valgrind_check\n\nvalgrind_test_some:\n\tROCKSDB_VALGRIND_RUN=1 DISABLE_JEMALLOC=1 PORTABLE=1 $(MAKE) valgrind_check_some\n\nvalgrind_check: $(TESTS)\n\t$(MAKE) DRIVER=\"$(VALGRIND_VER) $(VALGRIND_OPTS)\" gen_parallel_tests\n\t$(AM_V_GEN)if test \"$(J)\" != 1                                  \\\n\t    && (build_tools/gnu_parallel --gnu --help 2>/dev/null) |    \\\n\t        grep -q 'GNU Parallel';                                 \\\n\tthen                                                            \\\n\t  $(MAKE)                                                       \\\n\t  DRIVER=\"$(VALGRIND_VER) $(VALGRIND_OPTS)\" valgrind_check_0;   \\\n\telse                                                            \\\n\t\tfor t in $(filter-out %skiplist_test options_settable_test,$(TESTS)); do \\\n\t\t\t$(VALGRIND_VER) $(VALGRIND_OPTS) ./$$t; \\\n\t\t\tret_code=$$?; \\\n\t\t\tif [ $$ret_code -ne 0 ]; then \\\n\t\t\t\texit $$ret_code; \\\n\t\t\tfi; \\\n\t\tdone; \\\n\tfi\n\nvalgrind_check_some: $(ROCKSDBTESTS_SUBSET)\n\tfor t in $(ROCKSDBTESTS_SUBSET); do \\\n\t\t$(VALGRIND_VER) $(VALGRIND_OPTS) ./$$t; \\\n\t\tret_code=$$?; \\\n\t\tif [ $$ret_code -ne 0 ]; then \\\n\t\t\texit $$ret_code; \\\n\t\tfi; \\\n\tdone\n\ntest_names = \\\n  ./db_test --gtest_list_tests\t\t\t\t\t\t\\\n    | perl -n\t\t\t\t\t\t\t\t\\\n      -e 's/ *\\#.*//;'\t\t\t\t\t\t\t\\\n      -e '/^(\\s*)(\\S+)/; !$$1 and do {$$p=$$2; break};'\t\t\t\\\n      -e 'print qq! $$p$$2!'\n\nanalyze: clean\n\tUSE_CLANG=1 $(MAKE) analyze_incremental\n\nanalyze_incremental:\n\t$(CLANG_SCAN_BUILD) --use-analyzer=$(CLANG_ANALYZER) \\\n\t\t--use-c++=$(CXX) --use-cc=$(CC) --status-bugs \\\n\t\t-o $(CURDIR)/scan_build_report \\\n\t\t$(MAKE) SKIP_LINK=1 dbg\n\nCLEAN_FILES += unity.cc\nunity.cc: Makefile util/build_version.cc.in\n\trm -f $@ $@-t\n\t$(AM_V_at)$(gen_build_version) > util/build_version.cc\n\tfor source_file in $(LIB_SOURCES); do \\\n\t\techo \"#include \\\"$$source_file\\\"\" >> $@-t; \\\n\tdone\n\tchmod a=r $@-t\n\tmv $@-t $@\n\nunity.a: $(OBJ_DIR)/unity.o\n\t$(AM_V_AR)rm -f $@\n\t$(AM_V_at)$(AR) $(ARFLAGS) $@ $(OBJ_DIR)/unity.o\n\n\n# try compiling db_test with unity\nunity_test: $(OBJ_DIR)/db/db_basic_test.o $(OBJ_DIR)/db/db_test_util.o $(TEST_OBJECTS) $(TOOL_OBJECTS) unity.a\n\t$(AM_LINK)\n\t./unity_test\n\nrocksdb.h rocksdb.cc: build_tools/amalgamate.py Makefile $(LIB_SOURCES) unity.cc\n\tbuild_tools/amalgamate.py -I. -i./include unity.cc -x include/rocksdb/c.h -H rocksdb.h -o rocksdb.cc\n\nclean: clean-ext-libraries-all clean-rocks clean-rocksjava\n\nclean-not-downloaded: clean-ext-libraries-bin clean-rocks clean-not-downloaded-rocksjava\n\nclean-rocks:\n# Not practical to exactly match all versions/variants in naming (e.g. debug or not)\n\trm -f ${LIBNAME}*.so* ${LIBNAME}*.a\n\trm -f $(BENCHMARKS) $(TOOLS) $(TESTS) $(PARALLEL_TEST) $(MICROBENCHS)\n\trm -rf $(CLEAN_FILES) ios-x86 ios-arm scan_build_report\n\t$(FIND) . -name \"*.[oda]\" -exec rm -f {} \\;\n\t$(FIND) . -type f \\( -name \"*.gcda\" -o -name \"*.gcno\" \\) -exec rm -f {} \\;\n\nclean-rocksjava: clean-rocks\n\trm -rf jl jls\n\tcd java && $(MAKE) clean\n\nclean-not-downloaded-rocksjava:\n\tcd java && $(MAKE) clean-not-downloaded\n\nclean-ext-libraries-all:\n\trm -rf bzip2* snappy* zlib* lz4* zstd*\n\nclean-ext-libraries-bin:\n\tfind . -maxdepth 1 -type d \\( -name bzip2\\* -or -name snappy\\* -or -name zlib\\* -or -name lz4\\* -or -name zstd\\* \\) -prune -exec rm -rf {} \\;\n\ntags:\n\tctags -R .\n\tcscope -b `$(FIND) . -name '*.cc'` `$(FIND) . -name '*.h'` `$(FIND) . -name '*.c'`\n\tctags -e -R -o etags *\n\ntags0:\n\tctags -R .\n\tcscope -b `$(FIND) . -name '*.cc' -and ! -name '*_test.cc'` \\\n\t\t  `$(FIND) . -name '*.c' -and ! -name '*_test.c'` \\\n\t\t  `$(FIND) . -name '*.h' -and ! -name '*_test.h'`\n\tctags -e -R -o etags *\n\nformat:\n\tbuild_tools/format-diff.sh\n\ncheck-format:\n\tbuild_tools/format-diff.sh -c\n\ncheck-buck-targets:\n\tbuckifier/check_buck_targets.sh\n\ncheck-sources:\n\tbuild_tools/check-sources.sh\n\npackage:\n\tbash build_tools/make_package.sh $(SHARED_MAJOR).$(SHARED_MINOR)\n\n# ---------------------------------------------------------------------------\n# \tUnit tests and tools\n# ---------------------------------------------------------------------------\n$(STATIC_LIBRARY): $(LIB_OBJECTS)\n\t$(AM_V_AR)rm -f $@ $(SHARED1) $(SHARED2) $(SHARED3) $(SHARED4)\n\t$(AM_V_at)$(AR) $(ARFLAGS) $@ $(LIB_OBJECTS)\n\n$(STATIC_TEST_LIBRARY): $(TEST_OBJECTS)\n\t$(AM_V_AR)rm -f $@ $(SHARED_TEST_LIBRARY)\n\t$(AM_V_at)$(AR) $(ARFLAGS) $@ $^\n\n$(STATIC_TOOLS_LIBRARY): $(TOOL_OBJECTS)\n\t$(AM_V_AR)rm -f $@ $(SHARED_TOOLS_LIBRARY)\n\t$(AM_V_at)$(AR) $(ARFLAGS) $@ $^\n\n$(STATIC_STRESS_LIBRARY): $(ANALYZE_OBJECTS) $(STRESS_OBJECTS) $(TESTUTIL)\n\t$(AM_V_AR)rm -f $@ $(SHARED_STRESS_LIBRARY)\n\t$(AM_V_at)$(AR) $(ARFLAGS) $@ $^\n\n$(SHARED_TEST_LIBRARY): $(TEST_OBJECTS) $(SHARED1)\n\t$(AM_V_AR)rm -f $@ $(STATIC_TEST_LIBRARY)\n\t$(AM_SHARE)\n\n$(SHARED_TOOLS_LIBRARY): $(TOOL_OBJECTS) $(SHARED1)\n\t$(AM_V_AR)rm -f $@ $(STATIC_TOOLS_LIBRARY)\n\t$(AM_SHARE)\n\n$(SHARED_STRESS_LIBRARY): $(ANALYZE_OBJECTS) $(STRESS_OBJECTS) $(TESTUTIL) $(SHARED_TOOLS_LIBRARY) $(SHARED1)\n\t$(AM_V_AR)rm -f $@ $(STATIC_STRESS_LIBRARY)\n\t$(AM_SHARE)\n\nlibrocksdb_env_basic_test.a: $(OBJ_DIR)/env/env_basic_test.o $(LIB_OBJECTS) $(TESTHARNESS)\n\t$(AM_V_AR)rm -f $@\n\t$(AM_V_at)$(AR) $(ARFLAGS) $@ $^\n\ndb_bench: $(OBJ_DIR)/tools/db_bench.o $(BENCH_OBJECTS) $(TESTUTIL) $(LIBRARY)\n\t$(AM_LINK)\n\ntrace_analyzer: $(OBJ_DIR)/tools/trace_analyzer.o $(ANALYZE_OBJECTS) $(TOOLS_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nblock_cache_trace_analyzer: $(OBJ_DIR)/tools/block_cache_analyzer/block_cache_trace_analyzer_tool.o $(ANALYZE_OBJECTS) $(TOOLS_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ncache_bench: $(OBJ_DIR)/cache/cache_bench.o $(CACHE_BENCH_OBJECTS) $(LIBRARY)\n\t$(AM_LINK)\n\npersistent_cache_bench: $(OBJ_DIR)/utilities/persistent_cache/persistent_cache_bench.o $(LIBRARY)\n\t$(AM_LINK)\n\nmemtablerep_bench: $(OBJ_DIR)/memtable/memtablerep_bench.o $(LIBRARY)\n\t$(AM_LINK)\n\nfilter_bench: $(OBJ_DIR)/util/filter_bench.o $(LIBRARY)\n\t$(AM_LINK)\n\ndb_stress: $(OBJ_DIR)/db_stress_tool/db_stress.o $(STRESS_LIBRARY) $(TOOLS_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nwrite_stress: $(OBJ_DIR)/tools/write_stress.o $(LIBRARY)\n\t$(AM_LINK)\n\ndb_sanity_test: $(OBJ_DIR)/tools/db_sanity_test.o $(LIBRARY)\n\t$(AM_LINK)\n\ndb_repl_stress: $(OBJ_DIR)/tools/db_repl_stress.o $(LIBRARY)\n\t$(AM_LINK)\n\ndefine MakeTestRule\n$(notdir $(1:%.cc=%)): $(1:%.cc=$$(OBJ_DIR)/%.o) $$(TEST_LIBRARY) $$(LIBRARY)\n\t$$(AM_LINK)\nendef\n\n# For each PLUGIN test, create a rule to generate the test executable\n$(foreach test, $(ROCKSDB_PLUGIN_TESTS), $(eval $(call MakeTestRule, $(test))))\n\narena_test: $(OBJ_DIR)/memory/arena_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nmemory_allocator_test: memory/memory_allocator_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nautovector_test: $(OBJ_DIR)/util/autovector_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ncolumn_family_test: $(OBJ_DIR)/db/column_family_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ntable_properties_collector_test: $(OBJ_DIR)/db/table_properties_collector_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nbloom_test: $(OBJ_DIR)/util/bloom_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndynamic_bloom_test: $(OBJ_DIR)/util/dynamic_bloom_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nc_test: $(OBJ_DIR)/db/c_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ncache_test: $(OBJ_DIR)/cache/cache_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ncoding_test: $(OBJ_DIR)/util/coding_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nhash_test: $(OBJ_DIR)/util/hash_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nrandom_test: $(OBJ_DIR)/util/random_test.o  $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nribbon_test: $(OBJ_DIR)/util/ribbon_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\noption_change_migration_test: $(OBJ_DIR)/utilities/option_change_migration/option_change_migration_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nagg_merge_test: $(OBJ_DIR)/utilities/agg_merge/agg_merge_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nstringappend_test: $(OBJ_DIR)/utilities/merge_operators/string_append/stringappend_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ncassandra_format_test: $(OBJ_DIR)/utilities/cassandra/cassandra_format_test.o $(OBJ_DIR)/utilities/cassandra/test_utils.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ncassandra_functional_test: $(OBJ_DIR)/utilities/cassandra/cassandra_functional_test.o $(OBJ_DIR)/utilities/cassandra/test_utils.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ncassandra_row_merge_test: $(OBJ_DIR)/utilities/cassandra/cassandra_row_merge_test.o $(OBJ_DIR)/utilities/cassandra/test_utils.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ncassandra_serialize_test: $(OBJ_DIR)/utilities/cassandra/cassandra_serialize_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nhash_table_test: $(OBJ_DIR)/utilities/persistent_cache/hash_table_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nhistogram_test: $(OBJ_DIR)/monitoring/histogram_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nthread_local_test: $(OBJ_DIR)/util/thread_local_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nwork_queue_test: $(OBJ_DIR)/util/work_queue_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nudt_util_test: $(OBJ_DIR)/util/udt_util_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ncorruption_test: $(OBJ_DIR)/db/corruption_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ncrc32c_test: $(OBJ_DIR)/util/crc32c_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nslice_test: $(OBJ_DIR)/util/slice_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nslice_transform_test: $(OBJ_DIR)/util/slice_transform_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_basic_test: $(OBJ_DIR)/db/db_basic_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_blob_basic_test: $(OBJ_DIR)/db/blob/db_blob_basic_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_blob_compaction_test: $(OBJ_DIR)/db/blob/db_blob_compaction_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_readonly_with_timestamp_test: $(OBJ_DIR)/db/db_readonly_with_timestamp_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_wide_basic_test: $(OBJ_DIR)/db/wide/db_wide_basic_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_with_timestamp_basic_test: $(OBJ_DIR)/db/db_with_timestamp_basic_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_with_timestamp_compaction_test: db/db_with_timestamp_compaction_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_encryption_test: $(OBJ_DIR)/db/db_encryption_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_test: $(OBJ_DIR)/db/db_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_test2: $(OBJ_DIR)/db/db_test2.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_logical_block_size_cache_test: $(OBJ_DIR)/db/db_logical_block_size_cache_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_blob_index_test: $(OBJ_DIR)/db/blob/db_blob_index_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_block_cache_test: $(OBJ_DIR)/db/db_block_cache_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_bloom_filter_test: $(OBJ_DIR)/db/db_bloom_filter_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_log_iter_test: $(OBJ_DIR)/db/db_log_iter_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_compaction_filter_test: $(OBJ_DIR)/db/db_compaction_filter_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_compaction_test: $(OBJ_DIR)/db/db_compaction_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_clip_test: $(OBJ_DIR)/db/db_clip_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_dynamic_level_test: $(OBJ_DIR)/db/db_dynamic_level_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_flush_test: $(OBJ_DIR)/db/db_flush_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_inplace_update_test: $(OBJ_DIR)/db/db_inplace_update_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_iterator_test: $(OBJ_DIR)/db/db_iterator_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_kv_checksum_test: $(OBJ_DIR)/db/db_kv_checksum_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_memtable_test: $(OBJ_DIR)/db/db_memtable_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_merge_operator_test: $(OBJ_DIR)/db/db_merge_operator_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_merge_operand_test: $(OBJ_DIR)/db/db_merge_operand_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_options_test: $(OBJ_DIR)/db/db_options_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_range_del_test: $(OBJ_DIR)/db/db_range_del_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_rate_limiter_test: $(OBJ_DIR)/db/db_rate_limiter_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_sst_test: $(OBJ_DIR)/db/db_sst_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_statistics_test: $(OBJ_DIR)/db/db_statistics_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_write_test: $(OBJ_DIR)/db/db_write_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nerror_handler_fs_test: $(OBJ_DIR)/db/error_handler_fs_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nexternal_sst_file_basic_test: $(OBJ_DIR)/db/external_sst_file_basic_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nexternal_sst_file_test: $(OBJ_DIR)/db/external_sst_file_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nimport_column_family_test: $(OBJ_DIR)/db/import_column_family_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_tailing_iter_test: $(OBJ_DIR)/db/db_tailing_iter_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_iter_test: $(OBJ_DIR)/db/db_iter_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_iter_stress_test: $(OBJ_DIR)/db/db_iter_stress_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_universal_compaction_test: $(OBJ_DIR)/db/db_universal_compaction_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_wal_test: $(OBJ_DIR)/db/db_wal_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_io_failure_test: $(OBJ_DIR)/db/db_io_failure_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_properties_test: $(OBJ_DIR)/db/db_properties_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_table_properties_test: $(OBJ_DIR)/db/db_table_properties_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nlog_write_bench: $(OBJ_DIR)/util/log_write_bench.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK) $(PROFILING_FLAGS)\n\nseqno_time_test: $(OBJ_DIR)/db/seqno_time_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nplain_table_db_test: $(OBJ_DIR)/db/plain_table_db_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ncomparator_db_test: $(OBJ_DIR)/db/comparator_db_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ntable_reader_bench: $(OBJ_DIR)/table/table_reader_bench.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK) $(PROFILING_FLAGS)\n\nperf_context_test: $(OBJ_DIR)/db/perf_context_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nprefix_test: $(OBJ_DIR)/db/prefix_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nbackup_engine_test: $(OBJ_DIR)/utilities/backup/backup_engine_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ncheckpoint_test: $(OBJ_DIR)/utilities/checkpoint/checkpoint_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ncache_simulator_test: $(OBJ_DIR)/utilities/simulator_cache/cache_simulator_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nsim_cache_test: $(OBJ_DIR)/utilities/simulator_cache/sim_cache_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nenv_mirror_test: $(OBJ_DIR)/utilities/env_mirror_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nenv_timed_test: $(OBJ_DIR)/utilities/env_timed_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nobject_registry_test: $(OBJ_DIR)/utilities/object_registry_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nttl_test: $(OBJ_DIR)/utilities/ttl/ttl_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ntypes_util_test: $(OBJ_DIR)/utilities/types_util_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nwrite_batch_with_index_test: $(OBJ_DIR)/utilities/write_batch_with_index/write_batch_with_index_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nflush_job_test: $(OBJ_DIR)/db/flush_job_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ncompaction_iterator_test: $(OBJ_DIR)/db/compaction/compaction_iterator_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ncompaction_job_test: $(OBJ_DIR)/db/compaction/compaction_job_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ncompaction_job_stats_test: $(OBJ_DIR)/db/compaction/compaction_job_stats_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ncompaction_service_test: $(OBJ_DIR)/db/compaction/compaction_service_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ncompact_for_tiering_collector_test: $(OBJ_DIR)/utilities/table_properties_collectors/compact_for_tiering_collector_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ncompact_on_deletion_collector_test: $(OBJ_DIR)/utilities/table_properties_collectors/compact_on_deletion_collector_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nwal_manager_test: $(OBJ_DIR)/db/wal_manager_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nwal_edit_test: $(OBJ_DIR)/db/wal_edit_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndbformat_test: $(OBJ_DIR)/db/dbformat_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nmulti_cf_iterator_test: $(OBJ_DIR)/db/multi_cf_iterator_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nenv_basic_test: $(OBJ_DIR)/env/env_basic_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nenv_test: $(OBJ_DIR)/env/env_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nio_posix_test: $(OBJ_DIR)/env/io_posix_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nfault_injection_test: $(OBJ_DIR)/db/fault_injection_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nrate_limiter_test: $(OBJ_DIR)/util/rate_limiter_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndelete_scheduler_test: $(OBJ_DIR)/file/delete_scheduler_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nfilename_test: $(OBJ_DIR)/db/filename_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nrandom_access_file_reader_test: $(OBJ_DIR)/file/random_access_file_reader_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nfile_reader_writer_test: $(OBJ_DIR)/util/file_reader_writer_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nblock_based_table_reader_test: table/block_based/block_based_table_reader_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nfull_filter_block_test: $(OBJ_DIR)/table/block_based/full_filter_block_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\npartitioned_filter_block_test: $(OBJ_DIR)/table/block_based/partitioned_filter_block_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nlog_test: $(OBJ_DIR)/db/log_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ncleanable_test: $(OBJ_DIR)/table/cleanable_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ntable_test: $(OBJ_DIR)/table/table_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nblock_fetcher_test: table/block_fetcher_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nblock_test: $(OBJ_DIR)/table/block_based/block_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndata_block_hash_index_test: $(OBJ_DIR)/table/block_based/data_block_hash_index_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ninlineskiplist_test: $(OBJ_DIR)/memtable/inlineskiplist_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nskiplist_test: $(OBJ_DIR)/memtable/skiplist_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nwrite_buffer_manager_test: $(OBJ_DIR)/memtable/write_buffer_manager_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nversion_edit_test: $(OBJ_DIR)/db/version_edit_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nversion_set_test: $(OBJ_DIR)/db/version_set_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ncompaction_picker_test: $(OBJ_DIR)/db/compaction/compaction_picker_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nversion_builder_test: $(OBJ_DIR)/db/version_builder_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nfile_indexer_test: $(OBJ_DIR)/db/file_indexer_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nreduce_levels_test: $(OBJ_DIR)/tools/reduce_levels_test.o $(TOOLS_LIBRARY) $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nwrite_batch_test: $(OBJ_DIR)/db/write_batch_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nwrite_controller_test: $(OBJ_DIR)/db/write_controller_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nmerge_helper_test: $(OBJ_DIR)/db/merge_helper_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nmemory_test: $(OBJ_DIR)/utilities/memory/memory_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nmerge_test: $(OBJ_DIR)/db/merge_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nmerger_test: $(OBJ_DIR)/table/merger_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nutil_merge_operators_test: $(OBJ_DIR)/utilities/util_merge_operators_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\noptions_file_test: $(OBJ_DIR)/db/options_file_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndeletefile_test: $(OBJ_DIR)/db/deletefile_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nobsolete_files_test: $(OBJ_DIR)/db/obsolete_files_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nrocksdb_dump: $(OBJ_DIR)/tools/dump/rocksdb_dump.o $(LIBRARY)\n\t$(AM_LINK)\n\nrocksdb_undump: $(OBJ_DIR)/tools/dump/rocksdb_undump.o $(LIBRARY)\n\t$(AM_LINK)\n\ncuckoo_table_builder_test: $(OBJ_DIR)/table/cuckoo/cuckoo_table_builder_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ncuckoo_table_reader_test: $(OBJ_DIR)/table/cuckoo/cuckoo_table_reader_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ncuckoo_table_db_test: $(OBJ_DIR)/db/cuckoo_table_db_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nlistener_test: $(OBJ_DIR)/db/listener_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nstring_util_test: $(OBJ_DIR)/util/string_util_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nthread_list_test: $(OBJ_DIR)/util/thread_list_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ncompact_files_test: $(OBJ_DIR)/db/compact_files_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nconfigurable_test: options/configurable_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ncustomizable_test: options/customizable_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\noptions_test: $(OBJ_DIR)/options/options_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\noptions_settable_test: $(OBJ_DIR)/options/options_settable_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\noptions_util_test: $(OBJ_DIR)/utilities/options/options_util_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_bench_tool_test: $(OBJ_DIR)/tools/db_bench_tool_test.o $(BENCH_OBJECTS) $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ntrace_analyzer_test: $(OBJ_DIR)/tools/trace_analyzer_test.o $(ANALYZE_OBJECTS) $(TOOLS_LIBRARY) $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nevent_logger_test: $(OBJ_DIR)/logging/event_logger_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ntimer_queue_test: $(OBJ_DIR)/util/timer_queue_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nsst_dump_test: $(OBJ_DIR)/tools/sst_dump_test.o $(TOOLS_LIBRARY) $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\noptimistic_transaction_test: $(OBJ_DIR)/utilities/transactions/optimistic_transaction_test.o  $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nmock_env_test : $(OBJ_DIR)/env/mock_env_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nmanual_compaction_test: $(OBJ_DIR)/db/manual_compaction_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nfilelock_test: $(OBJ_DIR)/util/filelock_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nauto_roll_logger_test: $(OBJ_DIR)/logging/auto_roll_logger_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nenv_logger_test: $(OBJ_DIR)/logging/env_logger_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nmemtable_list_test: $(OBJ_DIR)/db/memtable_list_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nwrite_callback_test: $(OBJ_DIR)/db/write_callback_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nheap_test: $(OBJ_DIR)/util/heap_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\npoint_lock_manager_test: utilities/transactions/lock/point/point_lock_manager_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ntransaction_test: $(OBJ_DIR)/utilities/transactions/transaction_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nwrite_committed_transaction_ts_test: $(OBJ_DIR)/utilities/transactions/write_committed_transaction_ts_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nwrite_prepared_transaction_test: $(OBJ_DIR)/utilities/transactions/write_prepared_transaction_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nwrite_unprepared_transaction_test: $(OBJ_DIR)/utilities/transactions/write_unprepared_transaction_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ntimestamped_snapshot_test: $(OBJ_DIR)/utilities/transactions/timestamped_snapshot_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ntiered_compaction_test: $(OBJ_DIR)/db/compaction/tiered_compaction_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nsst_dump: $(OBJ_DIR)/tools/sst_dump.o $(TOOLS_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nblob_dump: $(OBJ_DIR)/tools/blob_dump.o $(TOOLS_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nrepair_test: $(OBJ_DIR)/db/repair_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nldb_cmd_test: $(OBJ_DIR)/tools/ldb_cmd_test.o $(TOOLS_LIBRARY) $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nldb: $(OBJ_DIR)/tools/ldb.o $(TOOLS_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\niostats_context_test: $(OBJ_DIR)/monitoring/iostats_context_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_V_CCLD)$(CXX) $^ $(EXEC_LDFLAGS) -o $@ $(LDFLAGS)\n\npersistent_cache_test: $(OBJ_DIR)/utilities/persistent_cache/persistent_cache_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nstatistics_test: $(OBJ_DIR)/monitoring/statistics_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nstats_history_test: $(OBJ_DIR)/monitoring/stats_history_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ncompressed_secondary_cache_test: $(OBJ_DIR)/cache/compressed_secondary_cache_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nlru_cache_test: $(OBJ_DIR)/cache/lru_cache_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ntiered_secondary_cache_test: $(OBJ_DIR)/cache/tiered_secondary_cache_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nrange_del_aggregator_test: $(OBJ_DIR)/db/range_del_aggregator_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nrange_del_aggregator_bench: $(OBJ_DIR)/db/range_del_aggregator_bench.o $(LIBRARY)\n\t$(AM_LINK)\n\nblob_db_test: $(OBJ_DIR)/utilities/blob_db/blob_db_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nrepeatable_thread_test: $(OBJ_DIR)/util/repeatable_thread_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nrange_locking_test: utilities/transactions/lock/range/range_locking_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nrange_tombstone_fragmenter_test: $(OBJ_DIR)/db/range_tombstone_fragmenter_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nsst_file_reader_test: $(OBJ_DIR)/table/sst_file_reader_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_secondary_test: $(OBJ_DIR)/db/db_secondary_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_follower_test: $(OBJ_DIR)/db/db_follower_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nblock_cache_tracer_test: $(OBJ_DIR)/trace_replay/block_cache_tracer_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nblock_cache_trace_analyzer_test: $(OBJ_DIR)/tools/block_cache_analyzer/block_cache_trace_analyzer_test.o $(OBJ_DIR)/tools/block_cache_analyzer/block_cache_trace_analyzer.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndefer_test: $(OBJ_DIR)/util/defer_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nblob_counting_iterator_test: $(OBJ_DIR)/db/blob/blob_counting_iterator_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nblob_file_addition_test: $(OBJ_DIR)/db/blob/blob_file_addition_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nblob_file_builder_test: $(OBJ_DIR)/db/blob/blob_file_builder_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nblob_file_cache_test: $(OBJ_DIR)/db/blob/blob_file_cache_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nblob_file_garbage_test: $(OBJ_DIR)/db/blob/blob_file_garbage_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nblob_file_reader_test: $(OBJ_DIR)/db/blob/blob_file_reader_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nblob_source_test: $(OBJ_DIR)/db/blob/blob_source_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nblob_garbage_meter_test: $(OBJ_DIR)/db/blob/blob_garbage_meter_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ntimer_test: $(OBJ_DIR)/util/timer_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nperiodic_task_scheduler_test: $(OBJ_DIR)/db/periodic_task_scheduler_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ntestutil_test: $(OBJ_DIR)/test_util/testutil_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nio_tracer_test: $(OBJ_DIR)/trace_replay/io_tracer_test.o $(OBJ_DIR)/trace_replay/io_tracer.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nprefetch_test: $(OBJ_DIR)/file/prefetch_test.o  $(OBJ_DIR)/tools/io_tracer_parser_tool.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nio_tracer_parser_test: $(OBJ_DIR)/tools/io_tracer_parser_test.o $(OBJ_DIR)/tools/io_tracer_parser_tool.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nio_tracer_parser: $(OBJ_DIR)/tools/io_tracer_parser.o $(TOOLS_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_blob_corruption_test: $(OBJ_DIR)/db/blob/db_blob_corruption_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\ndb_write_buffer_manager_test: $(OBJ_DIR)/db/db_write_buffer_manager_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nclipping_iterator_test: $(OBJ_DIR)/db/compaction/clipping_iterator_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nribbon_bench: $(OBJ_DIR)/microbench/ribbon_bench.o $(LIBRARY)\n\t$(AM_LINK)\n\ndb_basic_bench: $(OBJ_DIR)/microbench/db_basic_bench.o $(LIBRARY)\n\t$(AM_LINK)\n\ncache_reservation_manager_test: $(OBJ_DIR)/cache/cache_reservation_manager_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nwide_column_serialization_test: $(OBJ_DIR)/db/wide/wide_column_serialization_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\nwide_columns_helper_test: $(OBJ_DIR)/db/wide/wide_columns_helper_test.o $(TEST_LIBRARY) $(LIBRARY)\n\t$(AM_LINK)\n\n#-------------------------------------------------\n# make install related stuff\nPREFIX ?= /usr/local\nLIBDIR ?= $(PREFIX)/lib\nINSTALL_LIBDIR = $(DESTDIR)$(LIBDIR)\n\nuninstall:\n\trm -rf $(DESTDIR)$(PREFIX)/include/rocksdb \\\n\t  $(INSTALL_LIBDIR)/$(LIBRARY) \\\n\t  $(INSTALL_LIBDIR)/$(SHARED4) \\\n\t  $(INSTALL_LIBDIR)/$(SHARED3) \\\n\t  $(INSTALL_LIBDIR)/$(SHARED2) \\\n\t  $(INSTALL_LIBDIR)/$(SHARED1) \\\n\t  $(INSTALL_LIBDIR)/pkgconfig/rocksdb.pc\n\ninstall-headers: gen-pc\n\tinstall -d $(INSTALL_LIBDIR)\n\tinstall -d $(INSTALL_LIBDIR)/pkgconfig\n\tfor header_dir in `$(FIND) \"include/rocksdb\" -type d`; do \\\n\t\tinstall -d $(DESTDIR)/$(PREFIX)/$$header_dir; \\\n\tdone\n\tfor header in `$(FIND) \"include/rocksdb\" -type f -name *.h`; do \\\n\t\tinstall -C -m 644 $$header $(DESTDIR)/$(PREFIX)/$$header; \\\n\tdone\n\tfor header in $(ROCKSDB_PLUGIN_HEADERS); do \\\n\t\tinstall -d $(DESTDIR)/$(PREFIX)/include/rocksdb/`dirname $$header`; \\\n\t\tinstall -C -m 644 $$header $(DESTDIR)/$(PREFIX)/include/rocksdb/$$header; \\\n\tdone\n\tinstall -C -m 644 rocksdb.pc $(INSTALL_LIBDIR)/pkgconfig/rocksdb.pc\n\ninstall-static: install-headers $(LIBRARY)\n\tinstall -d $(INSTALL_LIBDIR)\n\tinstall -C -m 755 $(LIBRARY) $(INSTALL_LIBDIR)\n\ninstall-shared: install-headers $(SHARED4)\n\tinstall -d $(INSTALL_LIBDIR)\n\tinstall -C -m 755 $(SHARED4) $(INSTALL_LIBDIR)\n\tln -fs $(SHARED4) $(INSTALL_LIBDIR)/$(SHARED3)\n\tln -fs $(SHARED4) $(INSTALL_LIBDIR)/$(SHARED2)\n\tln -fs $(SHARED4) $(INSTALL_LIBDIR)/$(SHARED1)\n\n# install static by default + install shared if it exists\ninstall: install-static\n\t[ -e $(SHARED4) ] && $(MAKE) install-shared || :\n\n# Generate the pkg-config file\ngen-pc:\n\t-echo 'prefix=$(PREFIX)' > rocksdb.pc\n\t-echo 'exec_prefix=$${prefix}' >> rocksdb.pc\n\t-echo 'includedir=$${prefix}/include' >> rocksdb.pc\n\t-echo 'libdir=$(LIBDIR)' >> rocksdb.pc\n\t-echo '' >> rocksdb.pc\n\t-echo 'Name: rocksdb' >> rocksdb.pc\n\t-echo 'Description: An embeddable persistent key-value store for fast storage' >> rocksdb.pc\n\t-echo Version: $(shell ./build_tools/version.sh full) >> rocksdb.pc\n\t-echo 'Libs: -L$${libdir} $(EXEC_LDFLAGS) -lrocksdb' >> rocksdb.pc\n\t-echo 'Libs.private: $(PLATFORM_LDFLAGS)' >> rocksdb.pc\n\t-echo 'Cflags: -I$${includedir} $(PLATFORM_CXXFLAGS)' >> rocksdb.pc\n\t-echo 'Requires: $(subst \",,$(ROCKSDB_PLUGIN_PKGCONFIG_REQUIRES))' >> rocksdb.pc\n\n#-------------------------------------------------\n\n\n# ---------------------------------------------------------------------------\n# Jni stuff\n# ---------------------------------------------------------------------------\nJAVA_INCLUDE = -I$(JAVA_HOME)/include/ -I$(JAVA_HOME)/include/linux\nifeq ($(PLATFORM), OS_SOLARIS)\n\tARCH := $(shell isainfo -b)\nelse ifeq ($(PLATFORM), OS_OPENBSD)\n\tifneq (,$(filter amd64 ppc64 ppc64le s390x arm64 aarch64 riscv64 sparc64 loongarch64, $(MACHINE)))\n\t\tARCH := 64\n\telse\n\t\tARCH := 32\n\tendif\nelse\n\tARCH := $(shell getconf LONG_BIT)\nendif\n\nifeq ($(shell ldd /usr/bin/env 2>/dev/null | grep -q musl; echo $$?),0)\n        JNI_LIBC = musl\n# GNU LibC (or glibc) is so pervasive we can assume it is the default\n# else\n#        JNI_LIBC = glibc\nendif\n\nifneq ($(origin JNI_LIBC), undefined)\n  JNI_LIBC_POSTFIX = -$(JNI_LIBC)\nendif\n\nifeq (,$(ROCKSDBJNILIB))\nifneq (,$(filter ppc% s390x arm64 aarch64 riscv64 sparc64 loongarch64, $(MACHINE)))\n\tROCKSDBJNILIB = librocksdbjni-linux-$(MACHINE)$(JNI_LIBC_POSTFIX).so\nelse\n\tROCKSDBJNILIB = librocksdbjni-linux$(ARCH)$(JNI_LIBC_POSTFIX).so\nendif\nendif\nROCKSDB_JAVA_VERSION ?= $(ROCKSDB_MAJOR).$(ROCKSDB_MINOR).$(ROCKSDB_PATCH)\nROCKSDB_JAR = rocksdbjni-$(ROCKSDB_JAVA_VERSION)-linux$(ARCH)$(JNI_LIBC_POSTFIX).jar\nROCKSDB_JAR_ALL = rocksdbjni-$(ROCKSDB_JAVA_VERSION).jar\nROCKSDB_JAVADOCS_JAR = rocksdbjni-$(ROCKSDB_JAVA_VERSION)-javadoc.jar\nROCKSDB_SOURCES_JAR = rocksdbjni-$(ROCKSDB_JAVA_VERSION)-sources.jar\nSHA256_CMD = sha256sum\n\nZLIB_VER ?= 1.3.1\nZLIB_SHA256 ?= 9a93b2b7dfdac77ceba5a558a580e74667dd6fede4585b91eefb60f03b72df23\nZLIB_DOWNLOAD_BASE ?= http://zlib.net\nBZIP2_VER ?= 1.0.8\nBZIP2_SHA256 ?= ab5a03176ee106d3f0fa90e381da478ddae405918153cca248e682cd0c4a2269\nBZIP2_DOWNLOAD_BASE ?= http://sourceware.org/pub/bzip2\nSNAPPY_VER ?= 1.2.1\nSNAPPY_SHA256 ?= 736aeb64d86566d2236ddffa2865ee5d7a82d26c9016b36218fcc27ea4f09f86\nSNAPPY_DOWNLOAD_BASE ?= https://github.com/google/snappy/archive\nLZ4_VER ?= 1.9.4\nLZ4_SHA256 ?= 0b0e3aa07c8c063ddf40b082bdf7e37a1562bda40a0ff5272957f3e987e0e54b\nLZ4_DOWNLOAD_BASE ?= https://github.com/lz4/lz4/archive\nZSTD_VER ?= 1.5.5\nZSTD_SHA256 ?= 98e9c3d949d1b924e28e01eccb7deed865eefebf25c2f21c702e5cd5b63b85e1\nZSTD_DOWNLOAD_BASE ?= https://github.com/facebook/zstd/archive\nCURL_SSL_OPTS ?= --tlsv1\n\nifeq ($(PLATFORM), OS_MACOSX)\nifeq (,$(findstring librocksdbjni-osx,$(ROCKSDBJNILIB)))\nifeq ($(MACHINE),arm64)\n\tROCKSDBJNILIB = librocksdbjni-osx-arm64.jnilib\nelse ifeq ($(MACHINE),x86_64)\n\tROCKSDBJNILIB = librocksdbjni-osx-x86_64.jnilib\nelse\n\tROCKSDBJNILIB = librocksdbjni-osx.jnilib\nendif\nendif\n\tROCKSDB_JAR = rocksdbjni-$(ROCKSDB_JAVA_VERSION)-osx.jar\n\tSHA256_CMD = openssl sha256 -r\nifneq (\"$(wildcard $(JAVA_HOME)/include/darwin)\",\"\")\n\tJAVA_INCLUDE = -I$(JAVA_HOME)/include -I $(JAVA_HOME)/include/darwin\nelse\n\tJAVA_INCLUDE = -I/System/Library/Frameworks/JavaVM.framework/Headers/\nendif\nendif\n\nifeq ($(PLATFORM), OS_FREEBSD)\n\tJAVA_INCLUDE = -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/freebsd\n\tROCKSDBJNILIB = librocksdbjni-freebsd$(ARCH).so\n\tROCKSDB_JAR = rocksdbjni-$(ROCKSDB_JAVA_VERSION)-freebsd$(ARCH).jar\nendif\nifeq ($(PLATFORM), OS_SOLARIS)\n\tROCKSDBJNILIB = librocksdbjni-solaris$(ARCH).so\n\tROCKSDB_JAR = rocksdbjni-$(ROCKSDB_MAJOR).$(ROCKSDB_MINOR).$(ROCKSDB_PATCH)-solaris$(ARCH).jar\n\tJAVA_INCLUDE = -I$(JAVA_HOME)/include/ -I$(JAVA_HOME)/include/solaris\n\tSHA256_CMD = digest -a sha256\nendif\nifeq ($(PLATFORM), OS_AIX)\n\tJAVA_INCLUDE = -I$(JAVA_HOME)/include/ -I$(JAVA_HOME)/include/aix\n\tROCKSDBJNILIB = librocksdbjni-aix.so\n\tEXTRACT_SOURCES = gunzip < TAR_GZ | tar xvf -\n\tSNAPPY_MAKE_TARGET = libsnappy.la\nendif\nifeq ($(PLATFORM), OS_OPENBSD)\n\tJAVA_INCLUDE = -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/openbsd\n\tROCKSDBJNILIB = librocksdbjni-openbsd$(ARCH).so\n\tROCKSDB_JAR = rocksdbjni-$(ROCKSDB_JAVA_VERSION)-openbsd$(ARCH).jar\nendif\nexport SHA256_CMD\n\nzlib-$(ZLIB_VER).tar.gz:\n\tcurl --fail --output zlib-$(ZLIB_VER).tar.gz --location ${ZLIB_DOWNLOAD_BASE}/zlib-$(ZLIB_VER).tar.gz\n\tZLIB_SHA256_ACTUAL=`$(SHA256_CMD) zlib-$(ZLIB_VER).tar.gz | cut -d ' ' -f 1`; \\\n\tif [ \"$(ZLIB_SHA256)\" != \"$$ZLIB_SHA256_ACTUAL\" ]; then \\\n\t\techo zlib-$(ZLIB_VER).tar.gz checksum mismatch, expected=\\\"$(ZLIB_SHA256)\\\" actual=\\\"$$ZLIB_SHA256_ACTUAL\\\"; \\\n\t\texit 1; \\\n\tfi\n\nlibz.a: zlib-$(ZLIB_VER).tar.gz\n\t-rm -rf zlib-$(ZLIB_VER)\n\ttar xvzf zlib-$(ZLIB_VER).tar.gz\n\tif [ -n\"$(ARCHFLAG)\" ]; then \\\n\t\tcd zlib-$(ZLIB_VER) && CFLAGS='-fPIC ${JAVA_STATIC_DEPS_CCFLAGS} ${EXTRA_CFLAGS}' LDFLAGS='${JAVA_STATIC_DEPS_LDFLAGS} ${EXTRA_LDFLAGS}' ./configure --static --archs=\"$(ARCHFLAG)\" && $(MAKE);  \\\n\telse \\\n\t\tcd zlib-$(ZLIB_VER) && CFLAGS='-fPIC ${JAVA_STATIC_DEPS_CCFLAGS} ${EXTRA_CFLAGS}' LDFLAGS='${JAVA_STATIC_DEPS_LDFLAGS} ${EXTRA_LDFLAGS}' ./configure --static && $(MAKE);  \\\n\tfi\n\tcp zlib-$(ZLIB_VER)/libz.a .\n\nbzip2-$(BZIP2_VER).tar.gz:\n\tcurl --fail --output bzip2-$(BZIP2_VER).tar.gz --location ${CURL_SSL_OPTS} ${BZIP2_DOWNLOAD_BASE}/bzip2-$(BZIP2_VER).tar.gz\n\tBZIP2_SHA256_ACTUAL=`$(SHA256_CMD) bzip2-$(BZIP2_VER).tar.gz | cut -d ' ' -f 1`; \\\n\tif [ \"$(BZIP2_SHA256)\" != \"$$BZIP2_SHA256_ACTUAL\" ]; then \\\n\t\techo bzip2-$(BZIP2_VER).tar.gz checksum mismatch, expected=\\\"$(BZIP2_SHA256)\\\" actual=\\\"$$BZIP2_SHA256_ACTUAL\\\"; \\\n\t\texit 1; \\\n\tfi\n\nlibbz2.a: bzip2-$(BZIP2_VER).tar.gz\n\t-rm -rf bzip2-$(BZIP2_VER)\n\ttar xvzf bzip2-$(BZIP2_VER).tar.gz\n\tcd bzip2-$(BZIP2_VER) && $(MAKE) CFLAGS='-fPIC -O2 -g -D_FILE_OFFSET_BITS=64 $(ARCHFLAG) ${JAVA_STATIC_DEPS_CCFLAGS} ${EXTRA_CFLAGS}' LDFLAGS='${JAVA_STATIC_DEPS_LDFLAGS} ${EXTRA_LDFLAGS}' AR='ar ${EXTRA_ARFLAGS}' libbz2.a\n\tcp bzip2-$(BZIP2_VER)/libbz2.a .\n\nsnappy-$(SNAPPY_VER).tar.gz:\n\tcurl --fail --output snappy-$(SNAPPY_VER).tar.gz --location ${CURL_SSL_OPTS} ${SNAPPY_DOWNLOAD_BASE}/$(SNAPPY_VER).tar.gz\n\tSNAPPY_SHA256_ACTUAL=`$(SHA256_CMD) snappy-$(SNAPPY_VER).tar.gz | cut -d ' ' -f 1`; \\\n\tif [ \"$(SNAPPY_SHA256)\" != \"$$SNAPPY_SHA256_ACTUAL\" ]; then \\\n\t\techo snappy-$(SNAPPY_VER).tar.gz checksum mismatch, expected=\\\"$(SNAPPY_SHA256)\\\" actual=\\\"$$SNAPPY_SHA256_ACTUAL\\\"; \\\n\t\texit 1; \\\n\tfi\n\nlibsnappy.a: snappy-$(SNAPPY_VER).tar.gz\n\t-rm -rf snappy-$(SNAPPY_VER)\n\ttar xvzf snappy-$(SNAPPY_VER).tar.gz\n\tmkdir snappy-$(SNAPPY_VER)/build\n\tcd snappy-$(SNAPPY_VER)/build && CFLAGS='$(ARCHFLAG) ${JAVA_STATIC_DEPS_CCFLAGS} ${EXTRA_CFLAGS}' CXXFLAGS='$(ARCHFLAG) ${JAVA_STATIC_DEPS_CXXFLAGS} ${EXTRA_CXXFLAGS}' LDFLAGS='${JAVA_STATIC_DEPS_LDFLAGS} ${EXTRA_LDFLAGS}' cmake -DCMAKE_POSITION_INDEPENDENT_CODE=ON -DSNAPPY_BUILD_BENCHMARKS=OFF -DSNAPPY_BUILD_TESTS=OFF --compile-no-warning-as-error ${PLATFORM_CMAKE_FLAGS} .. && $(MAKE) ${SNAPPY_MAKE_TARGET}\n\tcp snappy-$(SNAPPY_VER)/build/libsnappy.a .\n\nlz4-$(LZ4_VER).tar.gz:\n\tcurl --fail --output lz4-$(LZ4_VER).tar.gz --location ${CURL_SSL_OPTS} ${LZ4_DOWNLOAD_BASE}/v$(LZ4_VER).tar.gz\n\tLZ4_SHA256_ACTUAL=`$(SHA256_CMD) lz4-$(LZ4_VER).tar.gz | cut -d ' ' -f 1`; \\\n\tif [ \"$(LZ4_SHA256)\" != \"$$LZ4_SHA256_ACTUAL\" ]; then \\\n\t\techo lz4-$(LZ4_VER).tar.gz checksum mismatch, expected=\\\"$(LZ4_SHA256)\\\" actual=\\\"$$LZ4_SHA256_ACTUAL\\\"; \\\n\t\texit 1; \\\n\tfi\n\nliblz4.a: lz4-$(LZ4_VER).tar.gz\n\t-rm -rf lz4-$(LZ4_VER)\n\ttar xvzf lz4-$(LZ4_VER).tar.gz\n\tcd lz4-$(LZ4_VER)/lib && $(MAKE) CFLAGS='-fPIC -O2 $(ARCHFLAG) ${JAVA_STATIC_DEPS_CCFLAGS} ${EXTRA_CFLAGS}' LDFLAGS='${JAVA_STATIC_DEPS_LDFLAGS} ${EXTRA_LDFLAGS}' all\n\tcp lz4-$(LZ4_VER)/lib/liblz4.a .\n\nzstd-$(ZSTD_VER).tar.gz:\n\tcurl --fail --output zstd-$(ZSTD_VER).tar.gz --location ${CURL_SSL_OPTS} ${ZSTD_DOWNLOAD_BASE}/v$(ZSTD_VER).tar.gz\n\tZSTD_SHA256_ACTUAL=`$(SHA256_CMD) zstd-$(ZSTD_VER).tar.gz | cut -d ' ' -f 1`; \\\n\tif [ \"$(ZSTD_SHA256)\" != \"$$ZSTD_SHA256_ACTUAL\" ]; then \\\n\t\techo zstd-$(ZSTD_VER).tar.gz checksum mismatch, expected=\\\"$(ZSTD_SHA256)\\\" actual=\\\"$$ZSTD_SHA256_ACTUAL\\\"; \\\n\t\texit 1; \\\n\tfi\n\nlibzstd.a: zstd-$(ZSTD_VER).tar.gz\n\t-rm -rf zstd-$(ZSTD_VER)\n\ttar xvzf zstd-$(ZSTD_VER).tar.gz\n\tcd zstd-$(ZSTD_VER)/lib && DESTDIR=. PREFIX= $(MAKE) CFLAGS='-fPIC -O2 $(ARCHFLAG) ${JAVA_STATIC_DEPS_CCFLAGS} ${EXTRA_CFLAGS}' LDFLAGS='${JAVA_STATIC_DEPS_LDFLAGS} ${EXTRA_LDFLAGS}' libzstd.a\n\tcp zstd-$(ZSTD_VER)/lib/libzstd.a .\n\n# A version of each $(LIB_OBJECTS) compiled with -fPIC and a fixed set of static compression libraries\nifneq ($(ROCKSDB_JAVA_NO_COMPRESSION), 1)\nJAVA_COMPRESSIONS = libz.a libbz2.a libsnappy.a liblz4.a libzstd.a\nendif\n\nJAVA_STATIC_FLAGS = -DZLIB -DBZIP2 -DSNAPPY -DLZ4 -DZSTD\nJAVA_STATIC_INCLUDES = -I./zlib-$(ZLIB_VER) -I./bzip2-$(BZIP2_VER) -I./snappy-$(SNAPPY_VER) -I./snappy-$(SNAPPY_VER)/build -I./lz4-$(LZ4_VER)/lib -I./zstd-$(ZSTD_VER)/lib -I./zstd-$(ZSTD_VER)/lib/dictBuilder\n\nifneq ($(findstring rocksdbjavastatic, $(filter-out rocksdbjavastatic_deps, $(MAKECMDGOALS))),)\nCXXFLAGS += $(JAVA_STATIC_FLAGS) $(JAVA_STATIC_INCLUDES)\nCFLAGS += $(JAVA_STATIC_FLAGS) $(JAVA_STATIC_INCLUDES)\nendif\nrocksdbjavastatic:\nifeq ($(JAVA_HOME),)\n\t$(error JAVA_HOME is not set)\nendif\n\t$(MAKE) rocksdbjavastatic_deps\n\t$(MAKE) rocksdbjavastatic_libobjects\n\t$(MAKE) rocksdbjavastatic_javalib\n\t$(MAKE) rocksdbjava_jar\n\nrocksdbjavastaticosx: rocksdbjavastaticosx_archs\n\tcd java; $(JAR_CMD)  -cf target/$(ROCKSDB_JAR) HISTORY*.md\n\tcd java/target; $(JAR_CMD) -uf $(ROCKSDB_JAR) librocksdbjni-osx-x86_64.jnilib librocksdbjni-osx-arm64.jnilib\n\tcd java/target/classes; $(JAR_CMD) -uf ../$(ROCKSDB_JAR) org/rocksdb/*.class org/rocksdb/util/*.class\n\topenssl sha1 java/target/$(ROCKSDB_JAR) | sed 's/.*= \\([0-9a-f]*\\)/\\1/' > java/target/$(ROCKSDB_JAR).sha1\n\nrocksdbjavastaticosx_ub: rocksdbjavastaticosx_archs\n\tcd java/target; lipo -create -output librocksdbjni-osx.jnilib librocksdbjni-osx-x86_64.jnilib librocksdbjni-osx-arm64.jnilib\n\tcd java; $(JAR_CMD)  -cf target/$(ROCKSDB_JAR) HISTORY*.md\n\tcd java/target; $(JAR_CMD) -uf $(ROCKSDB_JAR) librocksdbjni-osx.jnilib\n\tcd java/target/classes; $(JAR_CMD) -uf ../$(ROCKSDB_JAR) org/rocksdb/*.class org/rocksdb/util/*.class\n\topenssl sha1 java/target/$(ROCKSDB_JAR) | sed 's/.*= \\([0-9a-f]*\\)/\\1/' > java/target/$(ROCKSDB_JAR).sha1\n\nrocksdbjavastaticosx_archs:\n\t$(MAKE) rocksdbjavastaticosx_arch_x86_64\n\t$(MAKE) rocksdbjavastaticosx_arch_arm64\n\nrocksdbjavastaticosx_arch_%:\nifeq ($(JAVA_HOME),)\n\t$(error JAVA_HOME is not set)\nendif\n\t$(MAKE) clean-ext-libraries-bin\n\t$(MAKE) clean-rocks\n\tARCHFLAG=\"-arch $*\" $(MAKE) rocksdbjavastatic_deps\n\tARCHFLAG=\"-arch $*\" $(MAKE) rocksdbjavastatic_libobjects\n\tARCHFLAG=\"-arch $*\" ROCKSDBJNILIB=\"librocksdbjni-osx-$*.jnilib\" $(MAKE) rocksdbjavastatic_javalib\n\nifeq ($(JAR_CMD),)\nifneq ($(JAVA_HOME),)\nJAR_CMD := $(JAVA_HOME)/bin/jar\nelse\nJAR_CMD := jar\nendif\nendif\nrocksdbjavastatic_javalib:\n\tcd java; $(MAKE) javalib\n\trm -f java/target/$(ROCKSDBJNILIB)\n\t$(CXX) $(CXXFLAGS) -I./java/. $(JAVA_INCLUDE) -shared -fPIC \\\n\t  -o ./java/target/$(ROCKSDBJNILIB) $(ALL_JNI_NATIVE_SOURCES) \\\n\t  $(LIB_OBJECTS) $(COVERAGEFLAGS) \\\n\t  $(JAVA_COMPRESSIONS) $(JAVA_STATIC_LDFLAGS)\n\tcd java/target;if [ \"$(DEBUG_LEVEL)\" == \"0\" ]; then \\\n\t\tstrip $(STRIPFLAGS) $(ROCKSDBJNILIB); \\\n\tfi\n\nrocksdbjava_jar:\n\tcd java; $(JAR_CMD)  -cf target/$(ROCKSDB_JAR) HISTORY*.md\n\tcd java/target; $(JAR_CMD) -uf $(ROCKSDB_JAR) $(ROCKSDBJNILIB)\n\tcd java/target/classes; $(JAR_CMD) -uf ../$(ROCKSDB_JAR) org/rocksdb/*.class org/rocksdb/util/*.class\n\topenssl sha1 java/target/$(ROCKSDB_JAR) | sed 's/.*= \\([0-9a-f]*\\)/\\1/' > java/target/$(ROCKSDB_JAR).sha1\n\nrocksdbjava_javadocs_jar:\n\tcd java/target/apidocs; $(JAR_CMD) -cf ../$(ROCKSDB_JAVADOCS_JAR) *\n\topenssl sha1 java/target/$(ROCKSDB_JAVADOCS_JAR) | sed 's/.*= \\([0-9a-f]*\\)/\\1/' > java/target/$(ROCKSDB_JAVADOCS_JAR).sha1\n\nrocksdbjava_sources_jar:\n\tcd java/src/main/java; $(JAR_CMD) -cf ../../../target/$(ROCKSDB_SOURCES_JAR) org\n\topenssl sha1 java/target/$(ROCKSDB_SOURCES_JAR) | sed 's/.*= \\([0-9a-f]*\\)/\\1/' > java/target/$(ROCKSDB_SOURCES_JAR).sha1\n\nrocksdbjavastatic_deps: $(JAVA_COMPRESSIONS)\n\nrocksdbjavastatic_libobjects: $(LIB_OBJECTS)\n\nrocksdbjavastaticrelease: rocksdbjavastaticosx rocksdbjava_javadocs_jar rocksdbjava_sources_jar\n\tcd java/crossbuild && (vagrant destroy -f || true) && vagrant up linux32 && vagrant halt linux32 && vagrant up linux64 && vagrant halt linux64 && vagrant up linux64-musl && vagrant halt linux64-musl\n\tcd java; $(JAR_CMD) -cf target/$(ROCKSDB_JAR_ALL) HISTORY*.md\n\tcd java/target; $(JAR_CMD) -uf $(ROCKSDB_JAR_ALL) librocksdbjni-*.so librocksdbjni-*.jnilib\n\tcd java/target/classes; $(JAR_CMD) -uf ../$(ROCKSDB_JAR_ALL) org/rocksdb/*.class org/rocksdb/util/*.class\n\topenssl sha1 java/target/$(ROCKSDB_JAR_ALL) | sed 's/.*= \\([0-9a-f]*\\)/\\1/' > java/target/$(ROCKSDB_JAR_ALL).sha1\n\nrocksdbjavastaticreleasedocker: rocksdbjavastaticosx rocksdbjavastaticdockerx86 rocksdbjavastaticdockerx86_64 rocksdbjavastaticdockerx86musl rocksdbjavastaticdockerx86_64musl rocksdbjava_javadocs_jar rocksdbjava_sources_jar\n\tcd java; $(JAR_CMD) -cf target/$(ROCKSDB_JAR_ALL) HISTORY*.md\n\tcd java/target; $(JAR_CMD) -uf $(ROCKSDB_JAR_ALL) librocksdbjni-*.so librocksdbjni-*.jnilib\n\tcd java/target/classes; $(JAR_CMD) -uf ../$(ROCKSDB_JAR_ALL) org/rocksdb/*.class org/rocksdb/util/*.class\n\topenssl sha1 java/target/$(ROCKSDB_JAR_ALL) | sed 's/.*= \\([0-9a-f]*\\)/\\1/' > java/target/$(ROCKSDB_JAR_ALL).sha1\n\nrocksdbjavastaticdockerx86:\n\tmkdir -p java/target\n\tdocker run --rm --name rocksdb_linux_x86-be --platform linux/386 --attach stdin --attach stdout --attach stderr --volume $(HOME)/.m2:/root/.m2:ro --volume `pwd`:/rocksdb-host:ro --volume /rocksdb-local-build --volume `pwd`/java/target:/rocksdb-java-target --env DEBUG_LEVEL=$(DEBUG_LEVEL) --env J=$(J) evolvedbinary/rocksjava:centos6_x86-be /rocksdb-host/java/crossbuild/docker-build-linux.sh\n\nrocksdbjavastaticdockerx86_64:\n\tmkdir -p java/target\n\tdocker run --rm --name rocksdb_linux_x64-be --attach stdin --attach stdout --attach stderr --volume $(HOME)/.m2:/root/.m2:ro --volume `pwd`:/rocksdb-host:ro --volume /rocksdb-local-build --volume `pwd`/java/target:/rocksdb-java-target --env DEBUG_LEVEL=$(DEBUG_LEVEL) --env J=$(J) evolvedbinary/rocksjava:centos6_x64-be /rocksdb-host/java/crossbuild/docker-build-linux.sh\n\nrocksdbjavastaticdockerppc64le:\n\tmkdir -p java/target\n\tdocker run --rm --name rocksdb_linux_ppc64le-be --attach stdin --attach stdout --attach stderr --volume $(HOME)/.m2:/root/.m2:ro --volume `pwd`:/rocksdb-host:ro --volume /rocksdb-local-build --volume `pwd`/java/target:/rocksdb-java-target --env DEBUG_LEVEL=$(DEBUG_LEVEL) --env J=$(J) evolvedbinary/rocksjava:centos7_ppc64le-be /rocksdb-host/java/crossbuild/docker-build-linux.sh\n\nrocksdbjavastaticdockerarm64v8:\n\tmkdir -p java/target\n\tdocker run --rm --name rocksdb_linux_arm64v8-be --attach stdin --attach stdout --attach stderr --volume $(HOME)/.m2:/root/.m2:ro --volume `pwd`:/rocksdb-host:ro --volume /rocksdb-local-build --volume `pwd`/java/target:/rocksdb-java-target --env DEBUG_LEVEL=$(DEBUG_LEVEL) --env J=$(J) evolvedbinary/rocksjava:centos7_arm64v8-be /rocksdb-host/java/crossbuild/docker-build-linux.sh\n\nrocksdbjavastaticdockers390x:\n\tmkdir -p java/target\n\tdocker run --rm --name rocksdb_linux_s390x-be --attach stdin --attach stdout --attach stderr --volume $(HOME)/.m2:/root/.m2:ro --volume `pwd`:/rocksdb-host:ro --volume /rocksdb-local-build --volume `pwd`/java/target:/rocksdb-java-target --env DEBUG_LEVEL=$(DEBUG_LEVEL) --env J=$(J) evolvedbinary/rocksjava:ubuntu18_s390x-be /rocksdb-host/java/crossbuild/docker-build-linux.sh\n\nrocksdbjavastaticdockerriscv64:\n\tmkdir -p java/target\n\tdocker run --rm --name rocksdb_linux_riscv64-be --attach stdin --attach stdout --attach stderr --volume $(HOME)/.m2:/root/.m2:ro --volume `pwd`:/rocksdb-host:ro --volume /rocksdb-local-build --volume `pwd`/java/target:/rocksdb-java-target --env DEBUG_LEVEL=$(DEBUG_LEVEL) --env J=$(J) evolvedbinary/rocksjava:ubuntu20_riscv64-be /rocksdb-host/java/crossbuild/docker-build-linux.sh\n\nrocksdbjavastaticdockerx86musl:\n\tmkdir -p java/target\n\tdocker run --rm --name rocksdb_linux_x86-musl-be --platform linux/386 --attach stdin --attach stdout --attach stderr --volume $(HOME)/.m2:/root/.m2:ro --volume `pwd`:/rocksdb-host:ro --volume /rocksdb-local-build --volume `pwd`/java/target:/rocksdb-java-target --env DEBUG_LEVEL=$(DEBUG_LEVEL) --env J=$(J) evolvedbinary/rocksjava:alpine3_x86-be /rocksdb-host/java/crossbuild/docker-build-linux.sh\n\nrocksdbjavastaticdockerx86_64musl:\n\tmkdir -p java/target\n\tdocker run --rm --name rocksdb_linux_x64-musl-be --attach stdin --attach stdout --attach stderr --volume $(HOME)/.m2:/root/.m2:ro --volume `pwd`:/rocksdb-host:ro --volume /rocksdb-local-build --volume `pwd`/java/target:/rocksdb-java-target --env DEBUG_LEVEL=$(DEBUG_LEVEL) --env J=$(J) evolvedbinary/rocksjava:alpine3_x64-be /rocksdb-host/java/crossbuild/docker-build-linux.sh\n\nrocksdbjavastaticdockerppc64lemusl:\n\tmkdir -p java/target\n\tdocker run --rm --name rocksdb_linux_ppc64le-musl-be --attach stdin --attach stdout --attach stderr --volume $(HOME)/.m2:/root/.m2:ro --volume `pwd`:/rocksdb-host:ro --volume /rocksdb-local-build --volume `pwd`/java/target:/rocksdb-java-target --env DEBUG_LEVEL=$(DEBUG_LEVEL) --env J=$(J) evolvedbinary/rocksjava:alpine3_ppc64le-be /rocksdb-host/java/crossbuild/docker-build-linux.sh\n\nrocksdbjavastaticdockerarm64v8musl:\n\tmkdir -p java/target\n\tdocker run --rm --name rocksdb_linux_arm64v8-musl-be --attach stdin --attach stdout --attach stderr --volume $(HOME)/.m2:/root/.m2:ro --volume `pwd`:/rocksdb-host:ro --volume /rocksdb-local-build --volume `pwd`/java/target:/rocksdb-java-target --env DEBUG_LEVEL=$(DEBUG_LEVEL) --env J=$(J) evolvedbinary/rocksjava:alpine3_arm64v8-be /rocksdb-host/java/crossbuild/docker-build-linux.sh\n\nrocksdbjavastaticdockers390xmusl:\n\tmkdir -p java/target\n\tdocker run --rm --name rocksdb_linux_s390x-musl-be --attach stdin --attach stdout --attach stderr --volume $(HOME)/.m2:/root/.m2:ro --volume `pwd`:/rocksdb-host:ro --volume /rocksdb-local-build --volume `pwd`/java/target:/rocksdb-java-target --env DEBUG_LEVEL=$(DEBUG_LEVEL) --env J=$(J) evolvedbinary/rocksjava:alpine3_s390x-be /rocksdb-host/java/crossbuild/docker-build-linux.sh\n\nrocksdbjavastaticpublish: rocksdbjavastaticrelease rocksdbjavastaticpublishcentral\n\nrocksdbjavastaticpublishdocker: rocksdbjavastaticreleasedocker rocksdbjavastaticpublishcentral\n\nROCKSDB_JAVA_RELEASE_CLASSIFIERS = javadoc sources linux64 linux32 linux64-musl linux32-musl osx win64\n\nrocksdbjavastaticpublishcentral: rocksdbjavageneratepom\n\tmvn gpg:sign-and-deploy-file -Durl=https://oss.sonatype.org/service/local/staging/deploy/maven2/ -DrepositoryId=sonatype-nexus-staging -DpomFile=java/pom.xml -Dfile=java/target/rocksdbjni-$(ROCKSDB_JAVA_VERSION).jar\n\t$(foreach classifier, $(ROCKSDB_JAVA_RELEASE_CLASSIFIERS), mvn gpg:sign-and-deploy-file -Durl=https://oss.sonatype.org/service/local/staging/deploy/maven2/ -DrepositoryId=sonatype-nexus-staging -DpomFile=java/pom.xml -Dfile=java/target/rocksdbjni-$(ROCKSDB_JAVA_VERSION)-$(classifier).jar -Dclassifier=$(classifier);)\n\nrocksdbjavageneratepom:\n\tcd java;cat pom.xml.template | sed 's/\\$${ROCKSDB_JAVA_VERSION}/$(ROCKSDB_JAVA_VERSION)/' > pom.xml\n\nrocksdbjavastaticnexusbundlejar: rocksdbjavageneratepom\n\topenssl sha1 -r java/pom.xml | awk '{  print $$1 }' > java/target/pom.xml.sha1\n\topenssl sha1 -r java/target/rocksdbjni-$(ROCKSDB_JAVA_VERSION).jar | awk '{  print $$1 }' > java/target/rocksdbjni-$(ROCKSDB_JAVA_VERSION).jar.sha1\n\t$(foreach classifier, $(ROCKSDB_JAVA_RELEASE_CLASSIFIERS), openssl sha1 -r java/target/rocksdbjni-$(ROCKSDB_JAVA_VERSION)-$(classifier).jar | awk '{  print $$1 }' > java/target/rocksdbjni-$(ROCKSDB_JAVA_VERSION)-$(classifier).jar.sha1;)\n\tgpg --yes --output java/target/pom.xml.asc -ab java/pom.xml\n\tgpg --yes -ab java/target/rocksdbjni-$(ROCKSDB_JAVA_VERSION).jar\n\t$(foreach classifier, $(ROCKSDB_JAVA_RELEASE_CLASSIFIERS), gpg --yes -ab java/target/rocksdbjni-$(ROCKSDB_JAVA_VERSION)-$(classifier).jar;)\n\t$(JAR_CMD) cvf java/target/nexus-bundle-rocksdbjni-$(ROCKSDB_JAVA_VERSION).jar -C java pom.xml -C java/target pom.xml.sha1 -C java/target pom.xml.asc -C java/target rocksdbjni-$(ROCKSDB_JAVA_VERSION).jar -C java/target rocksdbjni-$(ROCKSDB_JAVA_VERSION).jar.sha1 -C java/target rocksdbjni-$(ROCKSDB_JAVA_VERSION).jar.asc\n\t$(foreach classifier, $(ROCKSDB_JAVA_RELEASE_CLASSIFIERS), $(JAR_CMD) uf java/target/nexus-bundle-rocksdbjni-$(ROCKSDB_JAVA_VERSION).jar -C java/target rocksdbjni-$(ROCKSDB_JAVA_VERSION)-$(classifier).jar -C java/target rocksdbjni-$(ROCKSDB_JAVA_VERSION)-$(classifier).jar.sha1 -C java/target rocksdbjni-$(ROCKSDB_JAVA_VERSION)-$(classifier).jar.asc;)\n\n\n# A version of each $(LIBOBJECTS) compiled with -fPIC\n\njl/%.o: %.cc\n\t$(AM_V_CC)mkdir -p $(@D) && $(CXX) $(CXXFLAGS) -fPIC -c $< -o $@ $(COVERAGEFLAGS)\n\nrocksdbjava: $(LIB_OBJECTS)\nifeq ($(JAVA_HOME),)\n\t$(error JAVA_HOME is not set)\nendif\n\t$(AM_V_GEN)cd java; $(MAKE) javalib;\n\t$(AM_V_at)rm -f ./java/target/$(ROCKSDBJNILIB)\n\t$(AM_V_at)$(CXX) $(CXXFLAGS) -I./java/. -I./java/rocksjni $(JAVA_INCLUDE) $(ROCKSDB_PLUGIN_JNI_CXX_INCLUDEFLAGS) -shared -fPIC -o ./java/target/$(ROCKSDBJNILIB) $(ALL_JNI_NATIVE_SOURCES) $(LIB_OBJECTS) $(JAVA_LDFLAGS) $(COVERAGEFLAGS)\n\t$(AM_V_at)cd java; $(JAR_CMD) -cf target/$(ROCKSDB_JAR) HISTORY*.md\n\t$(AM_V_at)cd java/target; $(JAR_CMD) -uf $(ROCKSDB_JAR) $(ROCKSDBJNILIB)\n\t$(AM_V_at)cd java/target/classes; $(JAR_CMD) -uf ../$(ROCKSDB_JAR) org/rocksdb/*.class org/rocksdb/util/*.class\n\t$(AM_V_at)openssl sha1 java/target/$(ROCKSDB_JAR) | sed 's/.*= \\([0-9a-f]*\\)/\\1/' > java/target/$(ROCKSDB_JAR).sha1\n\njclean:\n\tcd java;$(MAKE) clean;\n\njtest_compile: rocksdbjava\n\tcd java;$(MAKE) java_test\n\njtest_run:\n\tcd java;$(MAKE) run_test\n\njtest: rocksdbjava\n\tcd java;$(MAKE) sample test\n\njpmd: rocksdbjava rocksdbjavageneratepom\n\tcd java;$(MAKE) pmd\n\njdb_bench:\n\tcd java;$(MAKE) db_bench;\n\ncommit_prereq:\n\techo \"TODO: bring this back using parts of old precommit_checker.py and rocksdb-lego-determinator\"\n\tfalse # J=$(J) build_tools/precommit_checker.py unit clang_unit release clang_release tsan asan ubsan lite unit_non_shm\n\t# $(MAKE) clean && $(MAKE) jclean && $(MAKE) rocksdbjava;\n\n# For public CI runs, checkout folly in a way that can build with RocksDB.\n# This is mostly intended as a test-only simulation of Meta-internal folly\n# integration.\ncheckout_folly:\n\tif [ -e third-party/folly ]; then \\\n\t\tcd third-party/folly && ${GIT_COMMAND} fetch origin; \\\n\telse \\\n\t\tcd third-party && ${GIT_COMMAND} clone https://github.com/facebook/folly.git; \\\n\tfi\n\t@# Pin to a particular version for public CI, so that PR authors don't\n\t@# need to worry about folly breaking our integration. Update periodically\n\tcd third-party/folly && git reset --hard 62baa6ba07ff0a23ee4f2ea2f5207e4c88464deb\n\t@# NOTE: this hack is required for clang in some cases\n\tperl -pi -e 's/int rv = syscall/int rv = (int)syscall/' third-party/folly/folly/detail/Futex.cpp\n\t@# NOTE: this hack is required for gcc in some cases\n\tperl -pi -e 's/(__has_include.<experimental.memory_resource>.)/__cpp_rtti && $$1/' third-party/folly/folly/memory/MemoryResource.h\n\t@# NOTE: boost source will be needed for any build including `USE_FOLLY_LITE` builds as those depend on boost headers\n\tcd third-party/folly && $(PYTHON) build/fbcode_builder/getdeps.py fetch boost\n\nCXX_M_FLAGS = $(filter -m%, $(CXXFLAGS))\n\nbuild_folly:\n\tFOLLY_INST_PATH=`cd third-party/folly; $(PYTHON) build/fbcode_builder/getdeps.py show-inst-dir`; \\\n\tif [ \"$$FOLLY_INST_PATH\" ]; then \\\n\t\trm -rf $${FOLLY_INST_PATH}/../../*; \\\n\telse \\\n\t\techo \"Please run checkout_folly first\"; \\\n\t\tfalse; \\\n\tfi\n\tcd third-party/folly && \\\n\t\tCXXFLAGS=\" $(CXX_M_FLAGS) -DHAVE_CXX11_ATOMIC \" $(PYTHON) build/fbcode_builder/getdeps.py build --no-tests\n\n# ---------------------------------------------------------------------------\n#   Build size testing\n# ---------------------------------------------------------------------------\n\nREPORT_BUILD_STATISTIC?=echo STATISTIC:\n\nbuild_size:\n\t# === normal build, static ===\n\t$(MAKE) clean\n\t$(MAKE) static_lib\n\t$(REPORT_BUILD_STATISTIC) rocksdb.build_size.static_lib $$(stat --printf=\"%s\" librocksdb.a)\n\tstrip librocksdb.a\n\t$(REPORT_BUILD_STATISTIC) rocksdb.build_size.static_lib_stripped $$(stat --printf=\"%s\" librocksdb.a)\n\t# === normal build, shared ===\n\t$(MAKE) clean\n\t$(MAKE) shared_lib\n\t$(REPORT_BUILD_STATISTIC) rocksdb.build_size.shared_lib $$(stat --printf=\"%s\" `readlink -f librocksdb.so`)\n\tstrip `readlink -f librocksdb.so`\n\t$(REPORT_BUILD_STATISTIC) rocksdb.build_size.shared_lib_stripped $$(stat --printf=\"%s\" `readlink -f librocksdb.so`)\n\n# ---------------------------------------------------------------------------\n#  \tPlatform-specific compilation\n# ---------------------------------------------------------------------------\n\nifeq ($(PLATFORM), IOS)\n# For iOS, create universal object files to be used on both the simulator and\n# a device.\nXCODEROOT=$(shell xcode-select -print-path)\nPLATFORMSROOT=$(XCODEROOT)/Platforms\nSIMULATORROOT=$(PLATFORMSROOT)/iPhoneSimulator.platform/Developer\nDEVICEROOT=$(PLATFORMSROOT)/iPhoneOS.platform/Developer\nIOSVERSION=$(shell defaults read $(PLATFORMSROOT)/iPhoneOS.platform/version CFBundleShortVersionString)\n\n.cc.o:\n\tmkdir -p ios-x86/$(dir $@)\n\t$(CXX) $(CXXFLAGS) -isysroot $(SIMULATORROOT)/SDKs/iPhoneSimulator$(IOSVERSION).sdk -arch i686 -arch x86_64 -c $< -o ios-x86/$@\n\tmkdir -p ios-arm/$(dir $@)\n\txcrun -sdk iphoneos $(CXX) $(CXXFLAGS) -isysroot $(DEVICEROOT)/SDKs/iPhoneOS$(IOSVERSION).sdk -arch armv6 -arch armv7 -arch armv7s -arch arm64 -c $< -o ios-arm/$@\n\tlipo ios-x86/$@ ios-arm/$@ -create -output $@\n\n.c.o:\n\tmkdir -p ios-x86/$(dir $@)\n\t$(CC) $(CFLAGS) -isysroot $(SIMULATORROOT)/SDKs/iPhoneSimulator$(IOSVERSION).sdk -arch i686 -arch x86_64 -c $< -o ios-x86/$@\n\tmkdir -p ios-arm/$(dir $@)\n\txcrun -sdk iphoneos $(CC) $(CFLAGS) -isysroot $(DEVICEROOT)/SDKs/iPhoneOS$(IOSVERSION).sdk -arch armv6 -arch armv7 -arch armv7s -arch arm64 -c $< -o ios-arm/$@\n\tlipo ios-x86/$@ ios-arm/$@ -create -output $@\n\nelse\nifeq ($(HAVE_POWER8),1)\n$(OBJ_DIR)/util/crc32c_ppc.o: util/crc32c_ppc.c\n\t$(AM_V_CC)$(CC) $(CFLAGS) -c $< -o $@\n\n$(OBJ_DIR)/util/crc32c_ppc_asm.o: util/crc32c_ppc_asm.S\n\t$(AM_V_CC)$(CC) $(CFLAGS) -c $< -o $@\nendif\n$(OBJ_DIR)/%.o: %.cc\n\t$(AM_V_CC)mkdir -p $(@D) && $(CXX) $(CXXFLAGS) -c $< -o $@ $(COVERAGEFLAGS)\n\n$(OBJ_DIR)/%.o: %.cpp\n\t$(AM_V_CC)mkdir -p $(@D) && $(CXX) $(CXXFLAGS) -c $< -o $@ $(COVERAGEFLAGS)\n\n$(OBJ_DIR)/%.o: %.c\n\t$(AM_V_CC)$(CC) $(CFLAGS) -c $< -o $@\nendif\n\n# ---------------------------------------------------------------------------\n#  \tSource files dependencies detection\n# ---------------------------------------------------------------------------\n# If skip dependencies is ON, skip including the dep files\nifneq ($(SKIP_DEPENDS), 1)\nDEPFILES = $(patsubst %.cc, $(OBJ_DIR)/%.cc.d, $(ALL_SOURCES))\nDEPFILES+ = $(patsubst %.c, $(OBJ_DIR)/%.c.d, $(LIB_SOURCES_C) $(TEST_MAIN_SOURCES_C))\nifeq ($(USE_FOLLY_LITE),1)\n  DEPFILES +=$(patsubst %.cpp, $(OBJ_DIR)/%.cpp.d, $(FOLLY_SOURCES))\nendif\nendif\n\n# Add proper dependency support so changing a .h file forces a .cc file to\n# rebuild.\n\n# The .d file indicates .cc file's dependencies on .h files. We generate such\n# dependency by g++'s -MM option, whose output is a make dependency rule.\n$(OBJ_DIR)/%.cc.d: %.cc\n\t@mkdir -p $(@D) && $(CXX) $(CXXFLAGS) $(PLATFORM_SHARED_CFLAGS) \\\n\t  -MM -MT'$@' -MT'$(<:.cc=.o)' -MT'$(<:%.cc=$(OBJ_DIR)/%.o)' \\\n          \"$<\" -o '$@'\n\n$(OBJ_DIR)/%.cpp.d: %.cpp\n\t@mkdir -p $(@D) && $(CXX) $(CXXFLAGS) $(PLATFORM_SHARED_CFLAGS) \\\n\t  -MM -MT'$@' -MT'$(<:.cpp=.o)' -MT'$(<:%.cpp=$(OBJ_DIR)/%.o)' \\\n          \"$<\" -o '$@'\n\nifeq ($(HAVE_POWER8),1)\nDEPFILES_C = $(patsubst %.c, $(OBJ_DIR)/%.c.d, $(LIB_SOURCES_C))\nDEPFILES_ASM = $(patsubst %.S, $(OBJ_DIR)/%.S.d, $(LIB_SOURCES_ASM))\n\n$(OBJ_DIR)/%.c.d: %.c\n\t@$(CXX) $(CXXFLAGS) $(PLATFORM_SHARED_CFLAGS) \\\n\t  -MM -MT'$@' -MT'$(<:.c=.o)' \"$<\" -o '$@'\n\n$(OBJ_DIR)/%.S.d: %.S\n\t@$(CXX) $(CXXFLAGS) $(PLATFORM_SHARED_CFLAGS) \\\n\t  -MM -MT'$@' -MT'$(<:.S=.o)' \"$<\" -o '$@'\n\n$(DEPFILES_C): %.c.d\n\n$(DEPFILES_ASM): %.S.d\ndepend: $(DEPFILES) $(DEPFILES_C) $(DEPFILES_ASM)\nelse\ndepend: $(DEPFILES)\nendif\n\nbuild_subset_tests: $(ROCKSDBTESTS_SUBSET)\n\t$(AM_V_GEN)if [ -n \"$${ROCKSDBTESTS_SUBSET_TESTS_TO_FILE}\" ]; then echo \"$(ROCKSDBTESTS_SUBSET)\" > \"$${ROCKSDBTESTS_SUBSET_TESTS_TO_FILE}\"; else echo \"$(ROCKSDBTESTS_SUBSET)\"; fi\n\nlist_all_tests:\n\techo \"$(ROCKSDBTESTS_SUBSET)\"\n\n# Remove the rules for which dependencies should not be generated and see if any are left.\n#If so, include the dependencies; if not, do not include the dependency files\nROCKS_DEP_RULES=$(filter-out clean format check-format check-buck-targets check-headers check-sources jclean jtest package analyze tags rocksdbjavastatic% unity.% unity_test checkout_folly, $(MAKECMDGOALS))\nifneq (\"$(ROCKS_DEP_RULES)\", \"\")\n-include $(DEPFILES)\nendif\n"
        },
        {
          "name": "PLUGINS.md",
          "type": "blob",
          "size": 0.9521484375,
          "content": "This is the list of all known third-party plugins for RocksDB. If something is missing, please open a pull request to add it.\n\n* [Dedupfs](https://github.com/ajkr/dedupfs): an example for plugin developers to reference\n* [HDFS](https://github.com/riversand963/rocksdb-hdfs-env): an Env used for interacting with HDFS. Migrated from main RocksDB repo\n* [ZenFS](https://github.com/westerndigitalcorporation/zenfs): a file system for zoned block devices\n* [RADOS](https://github.com/riversand963/rocksdb-rados-env): an Env used for interacting with RADOS. Migrated from RocksDB main repo.\n* [PMEM](https://github.com/pmem/pmem-rocksdb-plugin): a collection of plugins to enable Persistent Memory on RocksDB.\n* [IPPCP](https://github.com/intel/ippcp-plugin-rocksdb): a plugin to enable encryption on RocksDB based on Intel optimized open source IPP-Crypto library.\n* [encfs](https://github.com/pegasus-kv/encfs): a plugin to enable encryption on RocksDB based on OpenSSL library."
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 1.6494140625,
          "content": "## RocksDB: A Persistent Key-Value Store for Flash and RAM Storage\n\n[![CircleCI Status](https://circleci.com/gh/facebook/rocksdb.svg?style=svg)](https://circleci.com/gh/facebook/rocksdb)\n\nRocksDB is developed and maintained by Facebook Database Engineering Team.\nIt is built on earlier work on [LevelDB](https://github.com/google/leveldb) by Sanjay Ghemawat (sanjay@google.com)\nand Jeff Dean (jeff@google.com)\n\nThis code is a library that forms the core building block for a fast\nkey-value server, especially suited for storing data on flash drives.\nIt has a Log-Structured-Merge-Database (LSM) design with flexible tradeoffs\nbetween Write-Amplification-Factor (WAF), Read-Amplification-Factor (RAF)\nand Space-Amplification-Factor (SAF). It has multi-threaded compactions,\nmaking it especially suitable for storing multiple terabytes of data in a\nsingle database.\n\nStart with example usage here: https://github.com/facebook/rocksdb/tree/main/examples\n\nSee the [github wiki](https://github.com/facebook/rocksdb/wiki) for more explanation.\n\nThe public interface is in `include/`.  Callers should not include or\nrely on the details of any other header files in this package.  Those\ninternal APIs may be changed without warning.\n\nQuestions and discussions are welcome on the [RocksDB Developers Public](https://www.facebook.com/groups/rocksdb.dev/) Facebook group and [email list](https://groups.google.com/g/rocksdb) on Google Groups.\n\n## License\n\nRocksDB is dual-licensed under both the GPLv2 (found in the COPYING file in the root directory) and Apache 2.0 License (found in the LICENSE.Apache file in the root directory).  You may select, at your option, one of the above-listed licenses.\n"
        },
        {
          "name": "USERS.md",
          "type": "blob",
          "size": 11.3896484375,
          "content": "This document lists users of RocksDB and their use cases. If you are using RocksDB, please open a pull request and add yourself to the list.\n\n## Facebook\nAt Facebook, we use RocksDB as storage engines in multiple data management services and a backend for many different stateful services, including:\n\n1. MyRocks -- https://github.com/MySQLOnRocksDB/mysql-5.6\n2. MongoRocks -- https://github.com/mongodb-partners/mongo-rocks\n3. ZippyDB --  Facebook's distributed key-value store with Paxos-style replication, built on top of RocksDB.[1] https://www.youtube.com/watch?v=DfiN7pG0D0khtt\n4. Laser -- Laser is a high query throughput, low (millisecond) latency, key-value storage service built on top of RocksDB.[1]\n4. Dragon -- a distributed graph query engine. https://code.facebook.com/posts/1737605303120405/dragon-a-distributed-graph-query-engine/\n5. Stylus -- a low-level stream processing framework writtenin C++.[1]\n6. LogDevice -- a distributed data store for logs [2]\n\n[1] https://research.facebook.com/publications/realtime-data-processing-at-facebook/\n\n[2] https://code.facebook.com/posts/357056558062811/logdevice-a-distributed-data-store-for-logs/\n\n## Bilibili\n[Bilibili](bilibili.com) [uses](https://www.alluxio.io/blog/when-ai-meets-alluxio-at-bilibili-building-an-efficient-ai-platform-for-data-preprocessing-and-model-training/) Alluxio to speed up its ML training workloads, and Alluxio uses RocksDB to store its filesystem metadata, so Bilibili uses RocksDB.\n\nBilibili's [real-time platform](https://www.alibabacloud.com/blog/architecture-and-practices-of-bilibilis-real-time-platform_596676) uses Flink, and uses RocksDB as Flink's state store.\n\n## TikTok\nTikTok, or its parent company ByteDance, uses RocksDB as the storage engine for some storage systems, such as its distributed graph database [ByteGraph](https://vldb.org/pvldb/vol15/p3306-li.pdf). \n\nAlso, TikTok uses [Alluxio](alluxio.io) to [speed up Presto queries](https://www.alluxio.io/resources/videos/improving-presto-performance-with-alluxio-at-tiktok/), and Alluxio stores the files' metadata in RocksDB.\n\n## FoundationDB\n[FoundationDB](https://www.foundationdb.org/) [uses](https://github.com/apple/foundationdb/blob/377f1f692da6ab2fe5bdac57035651db3e5fb66d/fdbserver/KeyValueStoreRocksDB.actor.cpp) RocksDB to implement a [key-value store interface](https://github.com/apple/foundationdb/blob/377f1f692da6ab2fe5bdac57035651db3e5fb66d/fdbserver/KeyValueStoreRocksDB.actor.cpp#L1127) in its server backend.\n\n## Apple\nApple [uses](https://opensource.apple.com/projects/foundationdb/) FoundationDB, so it also uses RocksDB.\n\n## Snowflake\nSnowflake [uses](https://www.snowflake.com/blog/how-foundationdb-powers-snowflake-metadata-forward/) FoundationDB, so it also uses RocksDB.\n\n## Microsoft\nThe Bing search engine from Microsoft uses RocksDB as the storage engine for its web data platform: https://blogs.bing.com/Engineering-Blog/october-2021/RocksDB-in-Microsoft-Bing\n\n## LinkedIn\n1. [Venice](https://venicedb.org/) is a derived data platform using RocksDB as its storage engine. It is LinkedIn's ML feature store, powering thousands of recommender use cases, including the Feed, Video recommendations, and People You May Know.\n2. LinkedIn's follow feed for storing user's activities. Check out the blog post: https://engineering.linkedin.com/blog/2016/03/followfeed--linkedin-s-feed-made-faster-and-smarter\n3. Apache Samza, open source framework for stream processing.\n\nLearn more about LinkedIn's follow feed and Apache Samza in a Tech Talk by Ankit Gupta and Naveen Somasundaram: http://www.youtube.com/watch?v=plqVp_OnSzg\n\n## Yahoo\nYahoo is using RocksDB as a storage engine for their biggest distributed data store Sherpa. Learn more about it here: http://yahooeng.tumblr.com/post/120730204806/sherpa-scales-new-heights\n\n## Tencent\n[PaxosStore](https://github.com/Tencent/paxosstore) is a distributed database supporting WeChat. It uses RocksDB as its storage engine.\n\n## Baidu\n[Apache Doris](http://doris.apache.org/master/en/) is a MPP analytical database engine released by Baidu. It [uses RocksDB](http://doris.apache.org/master/en/administrator-guide/operation/tablet-meta-tool.html) to manage its tablet's metadata.\n\n## CockroachDB\nCockroachDB is an open-source geo-replicated transactional database. They are using RocksDB as their storage engine. Check out their github: https://github.com/cockroachdb/cockroach\n\n## DNANexus\nDNANexus is using RocksDB to speed up processing of genomics data.\nYou can learn more from this great blog post by Mike Lin: http://devblog.dnanexus.com/faster-bam-sorting-with-samtools-and-rocksdb/\n\n## Iron.io\nIron.io is using RocksDB as a storage engine for their distributed queueing system.\nLearn more from Tech Talk by Reed Allman: http://www.youtube.com/watch?v=HTjt6oj-RL4\n\n## Tango Me\nTango is using RocksDB as a graph storage to store all users' connection data and other social activity data.\n\n## Turn\nTurn is using RocksDB as a storage layer for their key/value store, serving at peak 2.4MM QPS out of different datacenters.\nCheck out our RocksDB Protobuf merge operator at: https://github.com/vladb38/rocksdb_protobuf\n\n## Santander UK/Cloudera Profession Services\nCheck out their blog post: http://blog.cloudera.com/blog/2015/08/inside-santanders-near-real-time-data-ingest-architecture/\n\n## Airbnb\nAirbnb is using RocksDB as a storage engine for their personalized search service. You can learn more about it here: https://www.youtube.com/watch?v=ASQ6XMtogMs\n\n## Alluxio\n[Alluxio](https://www.alluxio.io) uses RocksDB to serve and scale file system metadata to beyond 1 Billion files. The detailed design and implementation is described in this engineering blog:\nhttps://www.alluxio.io/blog/scalable-metadata-service-in-alluxio-storing-billions-of-files/\n\n## Pinterest\nPinterest's Object Retrieval System uses RocksDB for storage: https://www.youtube.com/watch?v=MtFEVEs_2Vo\n\n## Smyte\n[Smyte](https://www.smyte.com/) uses RocksDB as the storage layer for their core key-value storage, high-performance counters and time-windowed HyperLogLog services.\n\n## Rakuten Marketing\n[Rakuten Marketing](https://marketing.rakuten.com/) uses RocksDB as the disk cache layer for the real-time bidding service in their Performance DSP.\n\n## VWO, Wingify\n[VWO's](https://vwo.com/) Smart Code checker and URL helper uses RocksDB to store all the URLs where VWO's Smart Code is installed.\n\n## quasardb\n[quasardb](https://www.quasardb.net) is a high-performance, distributed, transactional key-value database that integrates well with in-memory analytics engines such as Apache Spark.\nquasardb uses a heavily tuned RocksDB as its persistence layer.\n\n## Netflix\n[Netflix](http://techblog.netflix.com/2016/05/application-data-caching-using-ssds.html) Netflix uses RocksDB on AWS EC2 instances with local SSD drives to cache application data.\n\n## TiKV\n[TiKV](https://github.com/pingcap/tikv) is a GEO-replicated, high-performance, distributed, transactional key-value database. TiKV is powered by Rust and Raft. TiKV uses RocksDB as its persistence layer.\n\n## TiDB\n[TiDB](https://github.com/pingcap/tidb) uses the TiKV distributed key-value database, so it uses RocksDB.\n\n## PingCAP\n[PingCAP](https://www.pingcap.com/) is the company behind TiDB, its cloud database service uses RocksDB.\n\n## Apache Spark\n[Spark Structured Streaming](https://docs.databricks.com/structured-streaming/rocksdb-state-store.html) uses RocksDB as the local state store.\n\n## Databricks\n[Databricks](https://www.databricks.com/) [replaces AWS RDS with TiDB](https://www.pingcap.com/case-study/how-databricks-tackles-the-scalability-limit-with-a-mysql-alternative/) for scalability, so it uses RocksDB.\n\n## Apache Flink\n[Apache Flink](https://flink.apache.org/news/2016/03/08/release-1.0.0.html) uses RocksDB to store state locally on a machine.\n\n## Dgraph\n[Dgraph](https://github.com/dgraph-io/dgraph) is an open-source, scalable, distributed, low latency, high throughput Graph database .They use RocksDB to store state locally on a machine.\n\n## Uber\n[Uber](http://eng.uber.com/cherami/) uses RocksDB as a durable and scalable task queue.\n\n## 360 Pika\n[360](http://www.360.cn/) [Pika](https://github.com/Qihoo360/pika) is a nosql compatible with redis. With the huge amount of data stored, redis may suffer for a capacity bottleneck, and pika was born for solving it. It has widely been used in many companies.\n\n## LzLabs\nLzLabs is using RocksDB as a storage engine in their multi-database distributed framework to store application configuration and user data.\n\n## ProfaneDB\n[ProfaneDB](https://profanedb.gitlab.io/) is a database for Protocol Buffers, and uses RocksDB for storage. It is accessible via gRPC, and the schema is defined using directly `.proto` files.\n\n## IOTA Foundation\n [IOTA Foundation](https://www.iota.org/) is using RocksDB in the [IOTA Reference Implementation (IRI)](https://github.com/iotaledger/iri) to store the local state of the Tangle. The Tangle is the first open-source distributed ledger powering the future of the Internet of Things.\n\n## Avrio Project\n [Avrio Project](http://avrio-project.github.io/avrio.network/) is using RocksDB in [Avrio ](https://github.com/avrio-project/avrio) to store blocks, account balances and data and other blockchain-releated data. Avrio is a multiblockchain decentralized cryptocurrency empowering monetary transactions.\n\n## Crux\n[Crux](https://github.com/juxt/crux) is a document database that uses RocksDB for local [EAV](https://en.wikipedia.org/wiki/Entity%E2%80%93attribute%E2%80%93value_model) index storage to enable point-in-time bitemporal Datalog queries. The \"unbundled\" architecture uses Kafka to provide horizontal scalability.\n\n## Nebula Graph\n[Nebula Graph](https://github.com/vesoft-inc/nebula) is a distributed, scalable, lightning-fast, open source graph database capable of hosting super large scale graphs with dozens of billions of vertices (nodes) and trillions of edges, with milliseconds of latency.\n\n## YugabyteDB\n[YugabyteDB](https://www.yugabyte.com/) is an open source, high performance, distributed SQL database that uses RocksDB as its storage layer. For more information, please see https://github.com/yugabyte/yugabyte-db/.\n\n## ArangoDB\n[ArangoDB](https://www.arangodb.com/) is a native multi-model database with flexible data models for documents, graphs, and key-values, for building high performance applications using a convenient SQL-like query language or JavaScript extensions. It uses RocksDB as its storage engine.\n\n## Qdrant\n[Qdrant](https://qdrant.tech/) is an open source vector database, it [uses](https://qdrant.tech/documentation/concepts/storage/) RocksDB as its persistent storage.\n\n## Milvus\n[Milvus](https://milvus.io/) is an open source vector database for unstructured data. It uses RocksDB not only as one of the supported kv storage engines, but also as a message queue.\n\n## Kafka\n[Kafka](https://kafka.apache.org/) is an open-source distributed event streaming platform, it uses RocksDB to store state in Kafka Streams: https://www.confluent.io/blog/how-to-tune-rocksdb-kafka-streams-state-stores-performance/.\n\n## Solana Labs\n[Solana](https://github.com/solana-labs/solana) is a fast, secure, scalable, and decentralized blockchain.  It uses RocksDB as the underlying storage for its ledger store.\n\n## Apache Kvrocks\n\n[Apache Kvrocks](https://github.com/apache/kvrocks) is an open-source distributed key-value NoSQL database built on top of RocksDB. It serves as a cost-saving and capacity-increasing alternative drop-in replacement for Redis.\n\n## Others\nMore databases using RocksDB can be found at [dbdb.io](https://dbdb.io/browse?embeds=rocksdb).\n"
        },
        {
          "name": "Vagrantfile",
          "type": "blob",
          "size": 0.9931640625,
          "content": "# Vagrant file\nVagrant.configure(\"2\") do |config|\n\n  config.vm.provider \"virtualbox\" do |v|\n    v.memory = 4096\n    v.cpus = 2\n  end\n\n  config.vm.define \"ubuntu14\" do |box|\n    box.vm.box = \"ubuntu/trusty64\"\n  end\n\n  config.vm.define \"centos65\" do |box|\n    box.vm.box = \"chef/centos-6.5\"\n  end\n\n  config.vm.define \"centos7\" do |box|\n    box.vm.box = \"centos/7\"\n    box.vm.provision \"shell\", path: \"build_tools/setup_centos7.sh\"\n  end\n\n  config.vm.define \"FreeBSD10\" do |box|\n    box.vm.guest = :freebsd\n    box.vm.box = \"robin/freebsd-10\"\n    # FreeBSD does not support 'mount_virtualbox_shared_folder', use NFS\n    box.vm.synced_folder \".\", \"/vagrant\", :nfs => true, id: \"vagrant-root\"\n    box.vm.network \"private_network\", ip: \"10.0.1.10\"\n\n    # build everything after creating VM, skip using --no-provision\n    box.vm.provision \"shell\", inline: <<-SCRIPT\n      pkg install -y gmake clang35\n      export CXX=/usr/local/bin/clang++35\n      cd /vagrant\n      gmake clean\n      gmake all OPT=-g\n    SCRIPT\n  end\n\nend\n"
        },
        {
          "name": "WINDOWS_PORT.md",
          "type": "blob",
          "size": 12.5390625,
          "content": "# Microsoft Contribution Notes\n\n## Contributors\n* Alexander Zinoviev https://github.com/zinoale\n* Dmitri Smirnov https://github.com/yuslepukhin\n* Praveen Rao  https://github.com/PraveenSinghRao\n* Sherlock Huang  https://github.com/SherlockNoMad\n\n## Introduction\nRocksDB is a well proven open source key-value persistent store, optimized for fast storage. It provides scalability with number of CPUs and storage IOPS, to support IO-bound, in-memory and write-once workloads, most importantly, to be flexible to allow for innovation.\n\nAs Microsoft Bing team we have been continuously pushing hard to improve the scalability, efficiency of platform and eventually benefit Bing end-user satisfaction.  We would like to explore the opportunity to embrace open source, RocksDB here, to use, enhance and customize for our usage, and also contribute back to the RocksDB community. Herein, we are pleased to offer this RocksDB port for Windows platform.\n\nThese notes describe some decisions and changes we had to make with regards to porting RocksDB on Windows. We hope this will help both reviewers and users of the Windows port.\nWe are open for comments and improvements.\n\n## OS specifics\nAll of the porting, testing and benchmarking was done on Windows Server 2012 R2 Datacenter 64-bit but to the best of our knowledge there is not a specific API we used during porting that is unsupported on other Windows OS after Vista.\n\n## Porting goals\nWe strive to achieve the following goals:\n* make use of the existing porting interface of RocksDB\n* make minimum [WY2]modifications within platform independent code.\n* make all unit test pass both in debug and release builds. \n  * Note: latest introduction of SyncPoint seems to disable running db_test in Release.\n* make performance on par with published benchmarks accounting for HW differences\n* we would like to keep the port code inline with the main branch with no forking\n\n## Build system\nWe have chosen CMake as a widely accepted build system to build the Windows port. It is very fast and convenient. \n\nAt the same time it generates Visual Studio projects that are both usable from a command line and IDE.\n\nThe top-level CMakeLists.txt file contains description of all targets and build rules. It also provides brief instructions on how to build the software for Windows. One more build related file is thirdparty.inc that also resides on the top level. This file must be edited to point to actual third party libraries location.\nWe think that it would be beneficial to merge the existing make-based build system and the new cmake-based build system into a single one to use on all platforms.\n\nAll building and testing was done for 64-bit. We have not conducted any testing for 32-bit and early reports indicate that it will not run on 32-bit.\n\n## C++ and STL notes\nWe had to make some minimum changes within the portable files that either account for OS differences or the shortcomings of C++11 support in the current version of the MS compiler. Most or all of them are expected to be fixed in the upcoming compiler releases.\n\nWe plan to use this port for our business purposes here at Bing and this provided business justification for this port. This also means, we do not have at present to choose the compiler version at will.\n\n* Certain headers that are not present and not necessary on Windows were simply `#ifndef OS_WIN` in a few places (`unistd.h`)\n* All posix specific headers were replaced to port/port.h which worked well\n* Replaced `dirent.h` for `port/port_dirent.h` (very few places) with the implementation of the relevant interfaces within `rocksdb::port` namespace\n* Replaced `sys/time.h` to `port/sys_time.h` (few places) implemented equivalents within `rocksdb::port`\n* `printf %z` specification is not supported on Windows. To imitate existing standards we came up with a string macro `ROCKSDB_PRIszt` which expands to `zu` on posix systems and to `Iu` on windows.\n* in class member initialization were moved to a __ctors in some cases\n* `constexpr` is not supported. We had to replace `std::numeric_limits<>::max/min()` to its C macros for constants. Sometimes we had to make class members `static const` and place a definition within a .cc file.\n* `constexpr` for functions was replaced to a template specialization (1 place)\n* Union members that have non-trivial constructors were replaced to `char[]` in one place along with bug fixes (spatial experimental feature)\n* Zero-sized arrays are deemed a non-standard extension which we converted to 1 size array and that should work well for the purposes of these classes.\n* `std::chrono` lacks nanoseconds support (fixed in the upcoming release of the STL) and we had to use `QueryPerfCounter()` within env_win.cc\n* Function local statics initialization is still not safe. Used `std::once` to mitigate within WinEnv.\n\n## Windows Environments notes\nWe endeavored to make it functionally on par with posix_env. This means we replicated the functionality of the thread pool and other things as precise as possible, including:\n* Replicate posix logic using std:thread primitives.\n* Implement all posix_env disk access functionality.\n* Set `use_os_buffer=false` to disable OS disk buffering for WinWritableFile and WinRandomAccessFile.\n* Replace `pread/pwrite` with `WriteFile/ReadFile` with `OVERLAPPED` structure.\n* Use `SetFileInformationByHandle` to compensate absence of `fallocate`.\n\n### In detail\nEven though Windows provides its own efficient thread-pool implementation we chose to replicate posix logic using `std::thread` primitives. This allows anyone to quickly detect any changes within the posix source code and replicate them within windows env. This has proven to work very well. At the same time for anyone who wishes to replace the built-in thread-pool can do so using RocksDB stackable environments.\n\nFor disk access we implemented all of the functionality present within the posix_env which includes memory mapped files, random access, rate-limiter support etc.\nThe `use_os_buffer` flag on Posix platforms currently denotes disabling read-ahead log via `fadvise` mechanism. Windows does not have `fadvise` system call. What is more, it implements disk cache in a way that differs from Linux greatly. It's not an uncommon practice on Windows to perform un-buffered disk access to gain control of the memory consumption. We think that in our use case this may also be a good configuration option at the expense of disk throughput. To compensate one may increase the configured in-memory cache size instead. Thus we have chosen  `use_os_buffer=false` to disable OS disk buffering for `WinWritableFile` and `WinRandomAccessFile`. The OS imposes restrictions on the alignment of the disk offsets, buffers used and the amount of data that is read/written when accessing files in un-buffered mode. When the option is true, the classes behave in a standard way. This allows to perform writes and reads in cases when un-buffered access does not make sense such as WAL and MANIFEST.\n\nWe have replaced `pread/pwrite` with `WriteFile/ReadFile` with `OVERLAPPED` structure so we can atomically seek to the position of the disk operation but still perform the operation synchronously. Thus we able to emulate that functionality of `pread/pwrite` reasonably well. The only difference is that the file pointer is not returned to its original position but that hardly matters given the random nature of access.\n\nWe used `SetFileInformationByHandle` both to truncate files after writing a full final page to disk and to pre-allocate disk space for faster I/O thus compensating for the absence of `fallocate` although some differences remain. For example, the pre-allocated space is not filled with zeros like on Linux, however, on a positive note, the end of file position is also not modified after pre-allocation.\n\nRocksDB renames, copies and deletes files at will even though they may be opened with another handle at the same time. We had to relax and allow nearly all the concurrent access permissions possible.\n\n## Thread-Local Storage\nThread-Local storage plays a significant role for RocksDB performance. Rather than creating a separate implementation we chose to create inline wrappers that forward `pthread_specific` calls to Windows `Tls` interfaces within `rocksdb::port` namespace. This leaves the existing meat of the logic in tact and unchanged and just as maintainable.\n\nTo mitigate the lack of thread local storage cleanup on thread-exit we added a limited amount of windows specific code within the same thread_local.cc file that injects a cleanup callback into a `\"__tls\"` structure within `\".CRT$XLB\"` data segment. This approach guarantees that the callback is invoked regardless of whether RocksDB used within an executable, standalone DLL or within another DLL.\n\n## Jemalloc usage\n\nWhen RocksDB is used with Jemalloc the latter needs to be initialized before any of the C++ globals or statics. To accomplish that we injected an initialization routine into `\".CRT$XCT\"` that is automatically invoked by the runtime before initializing static objects. je-uninit is queued to `atexit()`. \n\nThe jemalloc redirecting `new/delete` global operators are used by the linker providing certain conditions are met. See build section in these notes.\n\n## Stack Trace and Unhandled Exception Handler\n\nWe decided not to implement these two features because the hosting program as a rule has these two things in it.\nWe experienced no inconveniences debugging issues in the debugger or analyzing process dumps if need be and thus we did not\nsee this as a priority.\n\n## Performance results\n### Setup\nAll of the benchmarks are run on the same set of machines. Here are the details of the test setup:\n* 2 Intel(R) Xeon(R) E5 2450 0 @ 2.10 GHz (total 16 cores)\n* 2 XK0480GDQPH SSD Device, total 894GB free disk\n* Machine has 128 GB of RAM\n* Operating System: Windows Server 2012 R2 Datacenter\n* 100 Million keys; each key is of size 10 bytes, each value is of size 800 bytes\n* total database size is ~76GB\n* The performance result is based on RocksDB 3.11.\n* The parameters used, unless specified, were exactly the same as published in the GitHub Wiki page. \n\n### RocksDB on flash storage\n\n#### Test 1. Bulk Load of keys in Random Order\n\nVersion 3.11 \n\n* Total Run Time: 17.6 min\n* Fillrandom: 5.480 micros/op 182465 ops/sec;  142.0 MB/s\n* Compact: 486056544.000 micros/op 0 ops/sec\n\nVersion 3.10 \n\n* Total Run Time: 16.2 min \n* Fillrandom: 5.018 micros/op 199269 ops/sec;  155.1 MB/s \n* Compact: 441313173.000 micros/op 0 ops/sec; \n\n\n#### Test 2. Bulk Load of keys in Sequential Order\n\nVersion 3.11 \n\n* Fillseq: 4.944 micros/op 202k ops/sec;  157.4 MB/s\n\nVersion 3.10\n\n* Fillseq: 4.105 micros/op 243.6k ops/sec;  189.6 MB/s \n\n\n#### Test 3. Random Write\n\nVersion 3.11 \n\n* Unbuffered I/O enabled\n* Overwrite: 52.661 micros/op 18.9k ops/sec;   14.8 MB/s\n\nVersion 3.10\n\n* Unbuffered I/O enabled \n* Overwrite: 52.661 micros/op 18.9k ops/sec; \n\n\n#### Test 4. Random Read\n\nVersion 3.11 \n\n* Unbuffered I/O enabled\n* Readrandom: 15.716 micros/op 63.6k ops/sec; 49.5 MB/s \n\nVersion 3.10\n\n* Unbuffered I/O enabled \n* Readrandom: 15.548 micros/op 64.3k ops/sec; \n\n\n#### Test 5. Multi-threaded read and single-threaded write\n\nVersion 3.11\n\n* Unbuffered I/O enabled\n* Readwhilewriting: 25.128 micros/op 39.7k ops/sec; \n\nVersion 3.10\n\n* Unbuffered I/O enabled \n* Readwhilewriting: 24.854 micros/op 40.2k ops/sec; \n\n\n### RocksDB In Memory \n\n#### Test 1. Point Lookup\n\nVersion 3.11\n\n80K writes/sec\n* Write Rate Achieved: 40.5k write/sec;\n* Readwhilewriting: 0.314 micros/op 3187455 ops/sec;  364.8 MB/s (715454999 of 715454999 found)\n\nVersion 3.10\n\n* Write Rate Achieved:  50.6k write/sec \n* Readwhilewriting: 0.316 micros/op 3162028 ops/sec; (719576999 of 719576999 found) \n\n\n*10K writes/sec*\n\nVersion 3.11\n\n* Write Rate Achieved: 5.8k/s write/sec\n* Readwhilewriting: 0.246 micros/op 4062669 ops/sec;  464.9 MB/s (915481999 of 915481999 found)\n\nVersion 3.10\n\n* Write Rate Achieved: 5.8k/s write/sec \n* Readwhilewriting: 0.244 micros/op 4106253 ops/sec; (927986999 of 927986999 found) \n\n\n#### Test 2. Prefix Range Query\n\nVersion 3.11\n\n80K writes/sec\n* Write Rate Achieved:  46.3k/s write/sec\n* Readwhilewriting: 0.362 micros/op 2765052 ops/sec;  316.4 MB/s (611549999 of 611549999 found)\n\nVersion 3.10\n\n* Write Rate Achieved: 45.8k/s write/sec \n* Readwhilewriting: 0.317 micros/op 3154941 ops/sec; (708158999 of 708158999 found) \n\nVersion 3.11\n\n10K writes/sec\n* Write Rate Achieved: 5.78k write/sec\n* Readwhilewriting: 0.269 micros/op 3716692 ops/sec;  425.3 MB/s (837401999 of 837401999 found)\n\nVersion 3.10\n\n* Write Rate Achieved: 5.7k write/sec \n* Readwhilewriting: 0.261 micros/op 3830152 ops/sec; (863482999 of 863482999 found) \n\n\nWe think that there is still big room to improve the performance, which will be an ongoing effort for us.\n\n"
        },
        {
          "name": "buckifier",
          "type": "tree",
          "content": null
        },
        {
          "name": "build_tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "cache",
          "type": "tree",
          "content": null
        },
        {
          "name": "cmake",
          "type": "tree",
          "content": null
        },
        {
          "name": "common.mk",
          "type": "blob",
          "size": 0.9404296875,
          "content": "ifndef PYTHON\n\n# Default to python3. Some distros like CentOS 8 do not have `python`.\nifeq ($(origin PYTHON), undefined)\n\tPYTHON := $(shell which python3 || which python || echo python3)\nendif\nexport PYTHON\n\nendif\n\n# To setup tmp directory, first recognize some old variables for setting\n# test tmp directory or base tmp directory. TEST_TMPDIR is usually read\n# by RocksDB tools though Env/FileSystem::GetTestDirectory.\nifeq ($(TEST_TMPDIR),)\nTEST_TMPDIR := $(TMPD)\nendif\nifeq ($(TEST_TMPDIR),)\nifeq ($(BASE_TMPDIR),)\nBASE_TMPDIR :=$(TMPDIR)\nendif\nifeq ($(BASE_TMPDIR),)\nBASE_TMPDIR :=/tmp\nendif\n# Use /dev/shm if it has the sticky bit set (otherwise, /tmp or other\n# base dir), and create a randomly-named rocksdb.XXXX directory therein.\nTEST_TMPDIR := $(shell f=/dev/shm; test -k $$f || f=$(BASE_TMPDIR); \\\n  perl -le 'use File::Temp \"tempdir\";'\t                            \\\n    -e 'print tempdir(\"'$$f'/rocksdb.XXXX\", CLEANUP => 0)')\nendif\nexport TEST_TMPDIR\n"
        },
        {
          "name": "coverage",
          "type": "tree",
          "content": null
        },
        {
          "name": "crash_test.mk",
          "type": "blob",
          "size": 4.724609375,
          "content": "# This file is used by Meta-internal infrastructure as well as by Makefile\n\n# When included from Makefile, there are rules to build DB_STRESS_CMD. When\n# used directly with `make -f crashtest.mk ...` there will be no rules to\n# build DB_STRESS_CMD so it must exist prior.\nDB_STRESS_CMD?=./db_stress\n\ninclude common.mk\n\nCRASHTEST_MAKE=$(MAKE) -f crash_test.mk\nCRASHTEST_PY=$(PYTHON) -u tools/db_crashtest.py --stress_cmd=$(DB_STRESS_CMD) --cleanup_cmd='$(DB_CLEANUP_CMD)'\n\n.PHONY: crash_test crash_test_with_atomic_flush crash_test_with_txn \\\n\tcrash_test_with_best_efforts_recovery crash_test_with_ts \\\n\tblackbox_crash_test blackbox_crash_test_with_atomic_flush \\\n\tblackbox_crash_test_with_txn blackbox_crash_test_with_ts \\\n\tblackbox_crash_test_with_best_efforts_recovery \\\n\twhitebox_crash_test whitebox_crash_test_with_atomic_flush \\\n\twhitebox_crash_test_with_txn whitebox_crash_test_with_ts \\\n\tblackbox_crash_test_with_multiops_wc_txn \\\n\tblackbox_crash_test_with_multiops_wp_txn \\\n\tcrash_test_with_tiered_storage blackbox_crash_test_with_tiered_storage \\\n\twhitebox_crash_test_with_tiered_storage \\\n\twhitebox_crash_test_with_optimistic_txn \\\n\tblackbox_crash_test_with_optimistic_txn \\\n\ncrash_test: $(DB_STRESS_CMD)\n# Do not parallelize\n\t$(CRASHTEST_MAKE) whitebox_crash_test\n\t$(CRASHTEST_MAKE) blackbox_crash_test\n\ncrash_test_with_atomic_flush: $(DB_STRESS_CMD)\n# Do not parallelize\n\t$(CRASHTEST_MAKE) whitebox_crash_test_with_atomic_flush\n\t$(CRASHTEST_MAKE) blackbox_crash_test_with_atomic_flush\n\ncrash_test_with_txn: $(DB_STRESS_CMD)\n# Do not parallelize\n\t$(CRASHTEST_MAKE) whitebox_crash_test_with_txn\n\t$(CRASHTEST_MAKE) blackbox_crash_test_with_txn\n\ncrash_test_with_optimistic_txn: $(DB_STRESS_CMD)\n# Do not parallelize\n\t$(CRASHTEST_MAKE) whitebox_crash_test_with_optimistic_txn\n\t$(CRASHTEST_MAKE) blackbox_crash_test_with_optimistic_txn\n\ncrash_test_with_best_efforts_recovery: blackbox_crash_test_with_best_efforts_recovery\n\ncrash_test_with_ts: $(DB_STRESS_CMD)\n# Do not parallelize\n\t$(CRASHTEST_MAKE) whitebox_crash_test_with_ts\n\t$(CRASHTEST_MAKE) blackbox_crash_test_with_ts\n\ncrash_test_with_tiered_storage: $(DB_STRESS_CMD)\n# Do not parallelize\n\t$(CRASHTEST_MAKE) whitebox_crash_test_with_tiered_storage\n\t$(CRASHTEST_MAKE) blackbox_crash_test_with_tiered_storage\n\ncrash_test_with_multiops_wc_txn: $(DB_STRESS_CMD)\n\t$(CRASHTEST_MAKE) blackbox_crash_test_with_multiops_wc_txn\n\ncrash_test_with_multiops_wp_txn: $(DB_STRESS_CMD)\n\t$(CRASHTEST_MAKE) blackbox_crash_test_with_multiops_wp_txn\n\nblackbox_crash_test: $(DB_STRESS_CMD)\n\t$(CRASHTEST_PY) --simple blackbox $(CRASH_TEST_EXT_ARGS)\n\t$(CRASHTEST_PY) blackbox $(CRASH_TEST_EXT_ARGS)\n\nblackbox_crash_test_with_atomic_flush: $(DB_STRESS_CMD)\n\t$(CRASHTEST_PY) --cf_consistency blackbox $(CRASH_TEST_EXT_ARGS)\n\nblackbox_crash_test_with_txn: $(DB_STRESS_CMD)\n\t$(CRASHTEST_PY) --txn blackbox $(CRASH_TEST_EXT_ARGS)\n\nblackbox_crash_test_with_best_efforts_recovery: $(DB_STRESS_CMD)\n\t$(CRASHTEST_PY) --test_best_efforts_recovery blackbox $(CRASH_TEST_EXT_ARGS)\n\nblackbox_crash_test_with_ts: $(DB_STRESS_CMD)\n\t$(CRASHTEST_PY) --enable_ts blackbox $(CRASH_TEST_EXT_ARGS)\n\nblackbox_crash_test_with_multiops_wc_txn: $(DB_STRESS_CMD)\n\t$(CRASHTEST_PY) --test_multiops_txn --write_policy write_committed blackbox $(CRASH_TEST_EXT_ARGS)\n\nblackbox_crash_test_with_multiops_wp_txn: $(DB_STRESS_CMD)\n\t$(CRASHTEST_PY) --test_multiops_txn --write_policy write_prepared blackbox $(CRASH_TEST_EXT_ARGS)\n\nblackbox_crash_test_with_tiered_storage: $(DB_STRESS_CMD)\n\t$(CRASHTEST_PY) --test_tiered_storage blackbox $(CRASH_TEST_EXT_ARGS)\n\nblackbox_crash_test_with_optimistic_txn: $(DB_STRESS_CMD)\n\t$(CRASHTEST_PY) --optimistic_txn blackbox $(CRASH_TEST_EXT_ARGS)\n\nifeq ($(CRASH_TEST_KILL_ODD),)\n  CRASH_TEST_KILL_ODD=888887\nendif\n\nwhitebox_crash_test: $(DB_STRESS_CMD)\n\t$(CRASHTEST_PY) --simple whitebox --random_kill_odd \\\n      $(CRASH_TEST_KILL_ODD) $(CRASH_TEST_EXT_ARGS)\n\t$(CRASHTEST_PY) whitebox  --random_kill_odd \\\n      $(CRASH_TEST_KILL_ODD) $(CRASH_TEST_EXT_ARGS)\n\nwhitebox_crash_test_with_atomic_flush: $(DB_STRESS_CMD)\n\t$(CRASHTEST_PY) --cf_consistency whitebox  --random_kill_odd \\\n      $(CRASH_TEST_KILL_ODD) $(CRASH_TEST_EXT_ARGS)\n\nwhitebox_crash_test_with_txn: $(DB_STRESS_CMD)\n\t$(CRASHTEST_PY) --txn whitebox --random_kill_odd \\\n      $(CRASH_TEST_KILL_ODD) $(CRASH_TEST_EXT_ARGS)\n\nwhitebox_crash_test_with_ts: $(DB_STRESS_CMD)\n\t$(CRASHTEST_PY) --enable_ts whitebox --random_kill_odd \\\n      $(CRASH_TEST_KILL_ODD) $(CRASH_TEST_EXT_ARGS)\n\nwhitebox_crash_test_with_tiered_storage: $(DB_STRESS_CMD)\n\t$(CRASHTEST_PY) --test_tiered_storage whitebox --random_kill_odd \\\n      $(CRASH_TEST_KILL_ODD) $(CRASH_TEST_EXT_ARGS)\n\nwhitebox_crash_test_with_optimistic_txn: $(DB_STRESS_CMD)\n\t$(CRASHTEST_PY) --optimistic_txn whitebox --random_kill_odd \\\n      $(CRASH_TEST_KILL_ODD) $(CRASH_TEST_EXT_ARGS)\n"
        },
        {
          "name": "db",
          "type": "tree",
          "content": null
        },
        {
          "name": "db_stress_tool",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "env",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "file",
          "type": "tree",
          "content": null
        },
        {
          "name": "fuzz",
          "type": "tree",
          "content": null
        },
        {
          "name": "include",
          "type": "tree",
          "content": null
        },
        {
          "name": "issue_template.md",
          "type": "blob",
          "size": 0.287109375,
          "content": "> Note: Please use Issues only for bug reports. For questions, discussions, feature requests, etc. post to dev group: https://groups.google.com/forum/#!forum/rocksdb or https://www.facebook.com/groups/rocksdb.dev\n\n### Expected behavior\n\n### Actual behavior\n\n### Steps to reproduce the behavior\n"
        },
        {
          "name": "java",
          "type": "tree",
          "content": null
        },
        {
          "name": "logging",
          "type": "tree",
          "content": null
        },
        {
          "name": "memory",
          "type": "tree",
          "content": null
        },
        {
          "name": "memtable",
          "type": "tree",
          "content": null
        },
        {
          "name": "microbench",
          "type": "tree",
          "content": null
        },
        {
          "name": "monitoring",
          "type": "tree",
          "content": null
        },
        {
          "name": "options",
          "type": "tree",
          "content": null
        },
        {
          "name": "plugin",
          "type": "tree",
          "content": null
        },
        {
          "name": "port",
          "type": "tree",
          "content": null
        },
        {
          "name": "rocksdb.pc.in",
          "type": "blob",
          "size": 0.28515625,
          "content": "prefix=\"@CMAKE_INSTALL_PREFIX@\"\nincludedir=\"${prefix}/@CMAKE_INSTALL_INCLUDEDIR@\"\nlibdir=\"${prefix}/@CMAKE_INSTALL_LIBDIR@\"\n\nName: @PROJECT_NAME@\nDescription: @PROJECT_DESCRIPTION@\nURL: @PROJECT_HOMEPAGE_URL@\nVersion: @PROJECT_VERSION@\nCflags: -I\"${includedir}\"\nLibs: -L\"${libdir}\" -lrocksdb\n"
        },
        {
          "name": "src.mk",
          "type": "blob",
          "size": 48.2890625,
          "content": "# These are the sources from which librocksdb.a is built:\nLIB_SOURCES =                                                   \\\n  cache/cache.cc                                                \\\n  cache/cache_entry_roles.cc                                    \\\n  cache/cache_key.cc                                            \\\n  cache/cache_helpers.cc                                        \\\n  cache/cache_reservation_manager.cc                            \\\n  cache/charged_cache.cc                                        \\\n  cache/clock_cache.cc                                          \\\n  cache/lru_cache.cc                                            \\\n  cache/compressed_secondary_cache.cc                           \\\n  cache/secondary_cache.cc                                      \\\n  cache/secondary_cache_adapter.cc                              \\\n  cache/sharded_cache.cc                                        \\\n  cache/tiered_secondary_cache.cc                               \\\n  db/arena_wrapped_db_iter.cc                                   \\\n  db/attribute_group_iterator_impl.cc                           \\\n  db/blob/blob_contents.cc                                      \\\n  db/blob/blob_fetcher.cc                                       \\\n  db/blob/blob_file_addition.cc                                 \\\n  db/blob/blob_file_builder.cc                                  \\\n  db/blob/blob_file_cache.cc                                    \\\n  db/blob/blob_file_garbage.cc                                  \\\n  db/blob/blob_file_meta.cc                                     \\\n  db/blob/blob_file_reader.cc                                   \\\n  db/blob/blob_garbage_meter.cc                                 \\\n  db/blob/blob_log_format.cc                                    \\\n  db/blob/blob_log_sequential_reader.cc                         \\\n  db/blob/blob_log_writer.cc                                    \\\n  db/blob/blob_source.cc                                        \\\n  db/blob/prefetch_buffer_collection.cc                         \\\n  db/builder.cc                                                 \\\n  db/c.cc                                                       \\\n  db/coalescing_iterator.cc                                     \\\n  db/column_family.cc                                           \\\n  db/compaction/compaction.cc                                   \\\n  db/compaction/compaction_iterator.cc                          \\\n  db/compaction/compaction_job.cc                               \\\n  db/compaction/compaction_picker.cc                            \\\n  db/compaction/compaction_picker_fifo.cc                       \\\n  db/compaction/compaction_picker_level.cc                      \\\n  db/compaction/compaction_picker_universal.cc                  \\\n  db/compaction/compaction_service_job.cc                       \\\n  db/compaction/compaction_state.cc                             \\\n  db/compaction/compaction_outputs.cc                           \\\n  db/compaction/sst_partitioner.cc                              \\\n  db/compaction/subcompaction_state.cc                          \\\n  db/convenience.cc                                             \\\n  db/db_filesnapshot.cc                                         \\\n  db/db_impl/compacted_db_impl.cc                               \\\n  db/db_impl/db_impl.cc                                         \\\n  db/db_impl/db_impl_compaction_flush.cc                        \\\n  db/db_impl/db_impl_debug.cc                                   \\\n  db/db_impl/db_impl_experimental.cc                            \\\n  db/db_impl/db_impl_files.cc                                   \\\n  db/db_impl/db_impl_follower.cc                                \\\n  db/db_impl/db_impl_open.cc                                    \\\n  db/db_impl/db_impl_readonly.cc                                \\\n  db/db_impl/db_impl_secondary.cc                               \\\n  db/db_impl/db_impl_write.cc                                   \\\n  db/db_info_dumper.cc                                          \\\n  db/db_iter.cc                                                 \\\n  db/dbformat.cc                                                \\\n  db/error_handler.cc                                           \\\n  db/event_helpers.cc                                           \\\n  db/experimental.cc                                            \\\n  db/external_sst_file_ingestion_job.cc                         \\\n  db/file_indexer.cc                                            \\\n  db/flush_job.cc                                               \\\n  db/flush_scheduler.cc                                         \\\n  db/forward_iterator.cc                                        \\\n  db/import_column_family_job.cc                                \\\n  db/internal_stats.cc                                          \\\n  db/logs_with_prep_tracker.cc                                  \\\n  db/log_reader.cc                                              \\\n  db/log_writer.cc                                              \\\n  db/malloc_stats.cc                                            \\\n  db/manifest_ops.cc                                            \\\n  db/memtable.cc                                                \\\n  db/memtable_list.cc                                           \\\n  db/merge_helper.cc                                            \\\n  db/merge_operator.cc                                          \\\n  db/output_validator.cc                                        \\\n  db/periodic_task_scheduler.cc                                 \\\n  db/range_del_aggregator.cc                                    \\\n  db/range_tombstone_fragmenter.cc                              \\\n  db/repair.cc                                                  \\\n  db/seqno_to_time_mapping.cc                                   \\\n  db/snapshot_impl.cc                                           \\\n  db/table_cache.cc                                             \\\n  db/table_properties_collector.cc                              \\\n  db/transaction_log_impl.cc                                    \\\n  db/trim_history_scheduler.cc                                  \\\n  db/version_builder.cc                                         \\\n  db/version_edit.cc                                            \\\n  db/version_edit_handler.cc                                    \\\n  db/version_set.cc                                             \\\n  db/wal_edit.cc                                                \\\n  db/wal_manager.cc                                             \\\n  db/wide/wide_column_serialization.cc                          \\\n  db/wide/wide_columns.cc                                       \\\n  db/wide/wide_columns_helper.cc                                \\\n  db/write_batch.cc                                             \\\n  db/write_batch_base.cc                                        \\\n  db/write_controller.cc                                        \\\n  db/write_stall_stats.cc                                       \\\n  db/write_thread.cc                                            \\\n  env/composite_env.cc                                          \\\n  env/env.cc                                                    \\\n  env/env_chroot.cc                                             \\\n  env/env_encryption.cc                                         \\\n  env/env_posix.cc                                              \\\n  env/file_system.cc                                            \\\n  env/fs_on_demand.cc                                               \\\n  env/fs_posix.cc                                               \\\n  env/fs_remap.cc                                               \\\n  env/file_system_tracer.cc                                     \\\n  env/io_posix.cc                                               \\\n  env/mock_env.cc                                               \\\n  env/unique_id_gen.cc                                          \\\n  file/delete_scheduler.cc                                      \\\n  file/file_prefetch_buffer.cc                                  \\\n  file/file_util.cc                                             \\\n  file/filename.cc                                              \\\n  file/line_file_reader.cc                                      \\\n  file/random_access_file_reader.cc                             \\\n  file/read_write_util.cc                                       \\\n  file/readahead_raf.cc                                         \\\n  file/sequence_file_reader.cc                                  \\\n  file/sst_file_manager_impl.cc                                 \\\n  file/writable_file_writer.cc                                  \\\n  logging/auto_roll_logger.cc                                   \\\n  logging/event_logger.cc                                       \\\n  logging/log_buffer.cc                                         \\\n  memory/arena.cc                                               \\\n  memory/concurrent_arena.cc                                    \\\n  memory/jemalloc_nodump_allocator.cc                           \\\n  memory/memkind_kmem_allocator.cc                              \\\n  memory/memory_allocator.cc                                    \\\n  memtable/alloc_tracker.cc                                     \\\n  memtable/hash_linklist_rep.cc                                 \\\n  memtable/hash_skiplist_rep.cc                                 \\\n  memtable/skiplistrep.cc                                       \\\n  memtable/vectorrep.cc                                         \\\n  memtable/wbwi_memtable.cc                                     \\\n  memtable/write_buffer_manager.cc                              \\\n  monitoring/histogram.cc                                       \\\n  monitoring/histogram_windowing.cc                             \\\n  monitoring/in_memory_stats_history.cc                         \\\n  monitoring/instrumented_mutex.cc                              \\\n  monitoring/iostats_context.cc                                 \\\n  monitoring/perf_context.cc                                    \\\n  monitoring/perf_level.cc                                      \\\n  monitoring/persistent_stats_history.cc                        \\\n  monitoring/statistics.cc                                      \\\n  monitoring/thread_status_impl.cc                              \\\n  monitoring/thread_status_updater.cc                           \\\n  monitoring/thread_status_updater_debug.cc                     \\\n  monitoring/thread_status_util.cc                              \\\n  monitoring/thread_status_util_debug.cc                        \\\n  options/cf_options.cc                                         \\\n  options/configurable.cc                                       \\\n  options/customizable.cc                                       \\\n  options/db_options.cc                                         \\\n  options/offpeak_time_info.cc                                  \\\n  options/options.cc                                            \\\n  options/options_helper.cc                                     \\\n  options/options_parser.cc                                     \\\n  port/mmap.cc                                                  \\\n  port/port_posix.cc                                            \\\n  port/win/env_default.cc                                       \\\n  port/win/env_win.cc                                           \\\n  port/win/io_win.cc                                            \\\n  port/win/port_win.cc                                          \\\n  port/win/win_logger.cc                                        \\\n  port/win/win_thread.cc                                        \\\n  port/stack_trace.cc                                           \\\n  table/adaptive/adaptive_table_factory.cc                      \\\n  table/block_based/binary_search_index_reader.cc               \\\n  table/block_based/block.cc                                    \\\n  table/block_based/block_based_table_builder.cc                \\\n  table/block_based/block_based_table_factory.cc                \\\n  table/block_based/block_based_table_iterator.cc               \\\n  table/block_based/block_based_table_reader.cc                 \\\n  table/block_based/block_builder.cc                            \\\n  table/block_based/block_cache.cc                              \\\n  table/block_based/block_prefetcher.cc                         \\\n  table/block_based/block_prefix_index.cc                       \\\n  table/block_based/data_block_hash_index.cc                    \\\n  table/block_based/data_block_footer.cc                        \\\n  table/block_based/filter_block_reader_common.cc               \\\n  table/block_based/filter_policy.cc                            \\\n  table/block_based/flush_block_policy.cc                       \\\n  table/block_based/full_filter_block.cc                        \\\n  table/block_based/hash_index_reader.cc                        \\\n  table/block_based/index_builder.cc                            \\\n  table/block_based/index_reader_common.cc                      \\\n  table/block_based/parsed_full_filter_block.cc                 \\\n  table/block_based/partitioned_filter_block.cc                 \\\n  table/block_based/partitioned_index_iterator.cc               \\\n  table/block_based/partitioned_index_reader.cc                 \\\n  table/block_based/reader_common.cc                            \\\n  table/block_based/uncompression_dict_reader.cc                \\\n  table/block_fetcher.cc                                        \\\n  table/cuckoo/cuckoo_table_builder.cc                          \\\n  table/cuckoo/cuckoo_table_factory.cc                          \\\n  table/cuckoo/cuckoo_table_reader.cc                           \\\n  table/format.cc                                               \\\n  table/get_context.cc                                          \\\n  table/iterator.cc                                             \\\n  table/merging_iterator.cc                                     \\\n  table/compaction_merging_iterator.cc                          \\\n  table/meta_blocks.cc                                          \\\n  table/persistent_cache_helper.cc                              \\\n  table/plain/plain_table_bloom.cc                              \\\n  table/plain/plain_table_builder.cc                            \\\n  table/plain/plain_table_factory.cc                            \\\n  table/plain/plain_table_index.cc                              \\\n  table/plain/plain_table_key_coding.cc                         \\\n  table/plain/plain_table_reader.cc                             \\\n  table/sst_file_dumper.cc                                      \\\n  table/sst_file_reader.cc                                      \\\n  table/sst_file_writer.cc                                      \\\n  table/table_factory.cc                                        \\\n  table/table_properties.cc                                     \\\n  table/two_level_iterator.cc                                   \\\n  table/unique_id.cc                                            \\\n  test_util/sync_point.cc                                       \\\n  test_util/sync_point_impl.cc                                  \\\n  test_util/transaction_test_util.cc                            \\\n  tools/dump/db_dump_tool.cc                                    \\\n  trace_replay/trace_record_handler.cc                          \\\n  trace_replay/trace_record_result.cc                           \\\n  trace_replay/trace_record.cc                                  \\\n  trace_replay/trace_replay.cc                                  \\\n  trace_replay/block_cache_tracer.cc                            \\\n  trace_replay/io_tracer.cc                                     \\\n  util/async_file_reader.cc\t\t\t\t\t\\\n  util/build_version.cc                                         \\\n  util/cleanable.cc                                             \\\n  util/coding.cc                                                \\\n  util/compaction_job_stats_impl.cc                             \\\n  util/comparator.cc                                            \\\n  util/compression.cc                                           \\\n  util/compression_context_cache.cc                             \\\n  util/concurrent_task_limiter_impl.cc                          \\\n  util/crc32c.cc                                                \\\n  util/crc32c_arm64.cc                                          \\\n  util/data_structure.cc                                        \\\n  util/dynamic_bloom.cc                                         \\\n  util/hash.cc                                                  \\\n  util/murmurhash.cc                                            \\\n  util/random.cc                                                \\\n  util/rate_limiter.cc                                          \\\n  util/ribbon_config.cc                                         \\\n  util/slice.cc                                                 \\\n  util/file_checksum_helper.cc                                  \\\n  util/status.cc                                                \\\n  util/stderr_logger.cc                                         \\\n  util/string_util.cc                                           \\\n  util/thread_local.cc                                          \\\n  util/threadpool_imp.cc                                        \\\n  util/udt_util.cc                                              \\\n  util/write_batch_util.cc                                      \\\n  util/xxhash.cc                                                \\\n  utilities/agg_merge/agg_merge.cc                              \\\n  utilities/backup/backup_engine.cc                             \\\n  utilities/blob_db/blob_compaction_filter.cc                   \\\n  utilities/blob_db/blob_db.cc                                  \\\n  utilities/blob_db/blob_db_impl.cc                             \\\n  utilities/blob_db/blob_db_impl_filesnapshot.cc                \\\n  utilities/blob_db/blob_file.cc                                \\\n  utilities/cache_dump_load.cc                                  \\\n  utilities/cache_dump_load_impl.cc                             \\\n  utilities/cassandra/cassandra_compaction_filter.cc            \\\n  utilities/cassandra/format.cc                                 \\\n  utilities/cassandra/merge_operator.cc                         \\\n  utilities/checkpoint/checkpoint_impl.cc                       \\\n  utilities/compaction_filters.cc                               \\\n  utilities/compaction_filters/remove_emptyvalue_compactionfilter.cc    \\\n  utilities/convenience/info_log_finder.cc                      \\\n  utilities/counted_fs.cc                                       \\\n  utilities/debug.cc                                            \\\n  utilities/env_mirror.cc                                       \\\n  utilities/env_timed.cc                                        \\\n  utilities/fault_injection_env.cc                              \\\n  utilities/fault_injection_fs.cc                               \\\n  utilities/fault_injection_secondary_cache.cc                  \\\n  utilities/leveldb_options/leveldb_options.cc                  \\\n  utilities/memory/memory_util.cc                               \\\n  utilities/merge_operators.cc                                  \\\n  utilities/merge_operators/max.cc                              \\\n  utilities/merge_operators/put.cc                              \\\n  utilities/merge_operators/sortlist.cc                         \\\n  utilities/merge_operators/string_append/stringappend.cc       \\\n  utilities/merge_operators/string_append/stringappend2.cc      \\\n  utilities/merge_operators/uint64add.cc                        \\\n  utilities/merge_operators/bytesxor.cc                         \\\n  utilities/object_registry.cc                                  \\\n  utilities/option_change_migration/option_change_migration.cc  \\\n  utilities/options/options_util.cc                             \\\n  utilities/persistent_cache/block_cache_tier.cc                \\\n  utilities/persistent_cache/block_cache_tier_file.cc           \\\n  utilities/persistent_cache/block_cache_tier_metadata.cc       \\\n  utilities/persistent_cache/persistent_cache_tier.cc           \\\n  utilities/persistent_cache/volatile_tier_impl.cc              \\\n  utilities/simulator_cache/cache_simulator.cc                  \\\n  utilities/simulator_cache/sim_cache.cc                        \\\n  utilities/table_properties_collectors/compact_for_tiering_collector.cc \\\n  utilities/table_properties_collectors/compact_on_deletion_collector.cc \\\n  utilities/trace/file_trace_reader_writer.cc                   \\\n  utilities/trace/replayer_impl.cc                              \\\n  utilities/transactions/lock/lock_manager.cc                   \\\n  utilities/transactions/lock/point/point_lock_tracker.cc       \\\n  utilities/transactions/lock/point/point_lock_manager.cc       \\\n  utilities/transactions/optimistic_transaction.cc              \\\n  utilities/transactions/optimistic_transaction_db_impl.cc      \\\n  utilities/transactions/pessimistic_transaction.cc             \\\n  utilities/transactions/pessimistic_transaction_db.cc          \\\n  utilities/transactions/snapshot_checker.cc                    \\\n  utilities/transactions/transaction_base.cc                    \\\n  utilities/transactions/transaction_db_mutex_impl.cc           \\\n  utilities/transactions/transaction_util.cc                    \\\n  utilities/transactions/write_prepared_txn.cc                  \\\n  utilities/transactions/write_prepared_txn_db.cc               \\\n  utilities/transactions/write_unprepared_txn.cc                \\\n  utilities/transactions/write_unprepared_txn_db.cc             \\\n  utilities/ttl/db_ttl_impl.cc                                  \\\n  utilities/types_util.cc                                       \\\n  utilities/wal_filter.cc                                       \\\n  utilities/write_batch_with_index/write_batch_with_index.cc    \\\n  utilities/write_batch_with_index/write_batch_with_index_internal.cc    \\\n\nifeq (,$(shell $(CXX) -fsyntax-only -maltivec -xc /dev/null 2>&1))\nLIB_SOURCES_ASM =\\\n  util/crc32c_ppc_asm.S\nLIB_SOURCES_C = \\\n  util/crc32c_ppc.c\nelse\nLIB_SOURCES_ASM =\nLIB_SOURCES_C =\nendif\n\nWITH_FAISS_LIB_SOURCES = \\\n  utilities/secondary_index/faiss_ivf_index.cc                  \\\n\nRANGE_TREE_SOURCES =\\\n  utilities/transactions/lock/range/range_tree/lib/locktree/concurrent_tree.cc \\\n  utilities/transactions/lock/range/range_tree/lib/locktree/keyrange.cc        \\\n  utilities/transactions/lock/range/range_tree/lib/locktree/lock_request.cc    \\\n  utilities/transactions/lock/range/range_tree/lib/locktree/locktree.cc        \\\n  utilities/transactions/lock/range/range_tree/lib/locktree/manager.cc         \\\n  utilities/transactions/lock/range/range_tree/lib/locktree/range_buffer.cc    \\\n  utilities/transactions/lock/range/range_tree/lib/locktree/treenode.cc        \\\n  utilities/transactions/lock/range/range_tree/lib/locktree/txnid_set.cc       \\\n  utilities/transactions/lock/range/range_tree/lib/locktree/wfg.cc             \\\n  utilities/transactions/lock/range/range_tree/lib/standalone_port.cc          \\\n  utilities/transactions/lock/range/range_tree/lib/util/dbt.cc                 \\\n  utilities/transactions/lock/range/range_tree/lib/util/memarena.cc            \\\n  utilities/transactions/lock/range/range_tree/range_tree_lock_manager.cc      \\\n  utilities/transactions/lock/range/range_tree/range_tree_lock_tracker.cc\n\nTOOL_LIB_SOURCES =                                              \\\n  tools/io_tracer_parser_tool.cc                                \\\n  tools/ldb_cmd.cc                                              \\\n  tools/ldb_tool.cc                                             \\\n  tools/sst_dump_tool.cc                                        \\\n  utilities/blob_db/blob_dump_tool.cc                           \\\n\nANALYZER_LIB_SOURCES =                                          \\\n  tools/block_cache_analyzer/block_cache_trace_analyzer.cc      \\\n  tools/trace_analyzer_tool.cc                                  \\\n\nMOCK_LIB_SOURCES =                                              \\\n  table/mock_table.cc                                           \\\n\nBENCH_LIB_SOURCES =                                             \\\n  tools/db_bench_tool.cc                                        \\\n  tools/simulated_hybrid_file_system.cc                         \\\n\nCACHE_BENCH_LIB_SOURCES =\t\t\t\t\t\\\n  cache/cache_bench_tool.cc                                     \\\n\nSTRESS_LIB_SOURCES =                                            \\\n  db_stress_tool/batched_ops_stress.cc                         \\\n  db_stress_tool/cf_consistency_stress.cc                      \\\n  db_stress_tool/db_stress_common.cc                           \\\n  db_stress_tool/db_stress_driver.cc                           \\\n  db_stress_tool/db_stress_filters.cc                          \\\n  db_stress_tool/db_stress_gflags.cc                           \\\n  db_stress_tool/db_stress_listener.cc                         \\\n  db_stress_tool/db_stress_shared_state.cc                     \\\n  db_stress_tool/db_stress_stat.cc                             \\\n  db_stress_tool/db_stress_test_base.cc                        \\\n  db_stress_tool/db_stress_tool.cc                             \\\n  db_stress_tool/db_stress_wide_merge_operator.cc              \\\n  db_stress_tool/expected_state.cc                             \\\n  db_stress_tool/expected_value.cc                             \\\n  db_stress_tool/no_batched_ops_stress.cc                      \\\n  db_stress_tool/multi_ops_txns_stress.cc                      \\\n\nTEST_LIB_SOURCES =                                              \\\n  db/db_test_util.cc                                            \\\n  db/db_with_timestamp_test_util.cc                             \\\n  test_util/mock_time_env.cc                                    \\\n  test_util/secondary_cache_test_util.cc                        \\\n  test_util/testharness.cc                                      \\\n  test_util/testutil.cc                                         \\\n  utilities/agg_merge/test_agg_merge.cc                                 \\\n  utilities/cassandra/test_utils.cc                             \\\n\nFOLLY_SOURCES =                                                 \\\n  $(FOLLY_DIR)/folly/container/detail/F14Table.cpp              \\\n  $(FOLLY_DIR)/folly/detail/Futex.cpp                           \\\n  $(FOLLY_DIR)/folly/lang/Exception.cpp                         \\\n  $(FOLLY_DIR)/folly/lang/SafeAssert.cpp                        \\\n  $(FOLLY_DIR)/folly/lang/ToAscii.cpp                           \\\n  $(FOLLY_DIR)/folly/ScopeGuard.cpp                             \\\n  $(FOLLY_DIR)/folly/synchronization/AtomicNotification.cpp     \\\n  $(FOLLY_DIR)/folly/synchronization/DistributedMutex.cpp       \\\n  $(FOLLY_DIR)/folly/synchronization/ParkingLot.cpp             \\\n\nTOOLS_MAIN_SOURCES =                                                    \\\n  db_stress_tool/db_stress.cc                                           \\\n  tools/blob_dump.cc                                                    \\\n  tools/block_cache_analyzer/block_cache_trace_analyzer_tool.cc         \\\n  tools/db_repl_stress.cc                                               \\\n  tools/db_sanity_test.cc                                               \\\n  tools/ldb.cc                                                          \\\n  tools/io_tracer_parser.cc                                             \\\n  tools/sst_dump.cc                                                     \\\n  tools/write_stress.cc                                                 \\\n  tools/dump/rocksdb_dump.cc                                            \\\n  tools/dump/rocksdb_undump.cc                                          \\\n  tools/trace_analyzer.cc                                               \\\n  tools/io_tracer_parser_tool.cc                                        \\\n\nBENCH_MAIN_SOURCES =                                                    \\\n  cache/cache_bench.cc                                                  \\\n  db/range_del_aggregator_bench.cc                                      \\\n  memtable/memtablerep_bench.cc                                         \\\n  table/table_reader_bench.cc                                           \\\n  tools/db_bench.cc                                                     \\\n  util/filter_bench.cc                                                  \\\n  utilities/persistent_cache/persistent_cache_bench.cc                  \\\n  #util/log_write_bench.cc                                               \\\n\nTEST_MAIN_SOURCES =                                                     \\\n  cache/cache_test.cc                                                   \\\n  cache/cache_reservation_manager_test.cc                               \\\n  cache/compressed_secondary_cache_test.cc                              \\\n  cache/lru_cache_test.cc                                               \\\n  cache/tiered_secondary_cache_test.cc\t\t\t\t\t\\\n  db/blob/blob_counting_iterator_test.cc                                \\\n  db/blob/blob_file_addition_test.cc                                    \\\n  db/blob/blob_file_builder_test.cc                                     \\\n  db/blob/blob_file_cache_test.cc                                       \\\n  db/blob/blob_file_garbage_test.cc                                     \\\n  db/blob/blob_file_reader_test.cc                                      \\\n  db/blob/blob_garbage_meter_test.cc                                    \\\n  db/blob/blob_source_test.cc                                           \\\n  db/blob/db_blob_basic_test.cc                                         \\\n  db/blob/db_blob_compaction_test.cc                                    \\\n  db/blob/db_blob_corruption_test.cc                                    \\\n  db/blob/db_blob_index_test.cc                                         \\\n  db/column_family_test.cc                                              \\\n  db/compact_files_test.cc                                              \\\n  db/compaction/clipping_iterator_test.cc                               \\\n  db/compaction/compaction_iterator_test.cc                             \\\n  db/compaction/compaction_job_test.cc                                  \\\n  db/compaction/compaction_job_stats_test.cc                            \\\n  db/compaction/compaction_picker_test.cc                               \\\n  db/compaction/compaction_service_test.cc                              \\\n  db/compaction/tiered_compaction_test.cc                               \\\n  db/comparator_db_test.cc                                              \\\n  db/corruption_test.cc                                                 \\\n  db/cuckoo_table_db_test.cc                                            \\\n  db/db_basic_test.cc                                                   \\\n  db/db_block_cache_test.cc                                             \\\n  db/db_bloom_filter_test.cc                                            \\\n  db/db_compaction_filter_test.cc                                       \\\n  db/db_compaction_test.cc                                              \\\n  db/db_clip_test.cc                                                    \\\n  db/db_dynamic_level_test.cc                                           \\\n  db/db_encryption_test.cc                                              \\\n  db/db_flush_test.cc                                                   \\\n  db/db_follower_test.cc\t\t\t\t\t\t\\\n  db/db_readonly_with_timestamp_test.cc                                 \\\n  db/db_with_timestamp_basic_test.cc                                    \\\n  db/import_column_family_test.cc                                       \\\n  db/db_inplace_update_test.cc                                          \\\n  db/db_io_failure_test.cc                                              \\\n  db/db_iter_test.cc                                                    \\\n  db/db_iter_stress_test.cc                                             \\\n  db/db_iterator_test.cc                                                \\\n  db/db_kv_checksum_test.cc                                             \\\n  db/db_log_iter_test.cc                                                \\\n  db/db_memtable_test.cc                                                \\\n  db/db_merge_operator_test.cc                                          \\\n  db/db_merge_operand_test.cc                                           \\\n  db/db_options_test.cc                                                 \\\n  db/db_properties_test.cc                                              \\\n  db/db_range_del_test.cc                                               \\\n  db/db_rate_limiter_test.cc                                            \\\n  db/db_secondary_test.cc                                               \\\n  db/db_sst_test.cc                                                     \\\n  db/db_statistics_test.cc                                              \\\n  db/db_table_properties_test.cc                                        \\\n  db/db_tailing_iter_test.cc                                            \\\n  db/db_test.cc                                                         \\\n  db/db_test2.cc                                                        \\\n  db/db_logical_block_size_cache_test.cc                                \\\n  db/db_universal_compaction_test.cc                                    \\\n  db/db_wal_test.cc                                                     \\\n  db/db_with_timestamp_compaction_test.cc                               \\\n  db/db_write_buffer_manager_test.cc                                    \\\n  db/db_write_test.cc                                                   \\\n  db/dbformat_test.cc                                                   \\\n  db/deletefile_test.cc                                                 \\\n  db/error_handler_fs_test.cc                                           \\\n  db/external_sst_file_basic_test.cc                                    \\\n  db/external_sst_file_test.cc                                          \\\n  db/fault_injection_test.cc                                            \\\n  db/file_indexer_test.cc                                               \\\n  db/filename_test.cc                                                   \\\n  db/flush_job_test.cc                                                  \\\n  db/listener_test.cc                                                   \\\n  db/log_test.cc                                                        \\\n  db/manual_compaction_test.cc                                          \\\n  db/memtable_list_test.cc                                              \\\n  db/merge_helper_test.cc                                               \\\n  db/merge_test.cc                                                      \\\n  db/multi_cf_iterator_test.cc                                          \\\n  db/obsolete_files_test.cc                                             \\\n  db/options_file_test.cc                                               \\\n  db/perf_context_test.cc                                               \\\n  db/periodic_task_scheduler_test.cc                                    \\\n  db/plain_table_db_test.cc                                             \\\n  db/prefix_test.cc                                                     \\\n  db/repair_test.cc                                                     \\\n  db/range_del_aggregator_test.cc                                       \\\n  db/range_tombstone_fragmenter_test.cc                                 \\\n  db/seqno_time_test.cc                                                 \\\n  db/table_properties_collector_test.cc                                 \\\n  db/version_builder_test.cc                                            \\\n  db/version_edit_test.cc                                               \\\n  db/version_set_test.cc                                                \\\n  db/wal_manager_test.cc                                                \\\n  db/wide/db_wide_basic_test.cc                                         \\\n  db/wide/wide_column_serialization_test.cc                             \\\n  db/wide/wide_columns_helper_test.cc                                   \\\n  db/write_batch_test.cc                                                \\\n  db/write_callback_test.cc                                             \\\n  db/write_controller_test.cc                                           \\\n  env/env_basic_test.cc                                                 \\\n  env/env_test.cc                                                       \\\n  env/io_posix_test.cc                                                  \\\n  env/mock_env_test.cc                                                  \\\n  file/delete_scheduler_test.cc                                         \\\n  file/prefetch_test.cc                                                 \\\n  file/random_access_file_reader_test.cc                                \\\n  logging/auto_roll_logger_test.cc                                      \\\n  logging/env_logger_test.cc                                            \\\n  logging/event_logger_test.cc                                          \\\n  memory/arena_test.cc                                                  \\\n  memory/memory_allocator_test.cc                                       \\\n  memtable/inlineskiplist_test.cc                                       \\\n  memtable/skiplist_test.cc                                             \\\n  memtable/write_buffer_manager_test.cc                                 \\\n  monitoring/histogram_test.cc                                          \\\n  monitoring/iostats_context_test.cc                                    \\\n  monitoring/statistics_test.cc                                         \\\n  monitoring/stats_history_test.cc                                      \\\n  options/configurable_test.cc                                          \\\n  options/customizable_test.cc                                          \\\n  options/options_settable_test.cc                                      \\\n  options/options_test.cc                                               \\\n  table/block_based/block_based_table_reader_test.cc                    \\\n  table/block_based/block_test.cc                                       \\\n  table/block_based/data_block_hash_index_test.cc                       \\\n  table/block_based/full_filter_block_test.cc                           \\\n  table/block_based/partitioned_filter_block_test.cc                    \\\n  table/cleanable_test.cc                                               \\\n  table/cuckoo/cuckoo_table_builder_test.cc                             \\\n  table/cuckoo/cuckoo_table_reader_test.cc                              \\\n  table/merger_test.cc                                                  \\\n  table/sst_file_reader_test.cc                                         \\\n  table/table_test.cc                                                   \\\n  table/block_fetcher_test.cc                                           \\\n  test_util/testutil_test.cc                                            \\\n  tools/block_cache_analyzer/block_cache_trace_analyzer_test.cc         \\\n  tools/io_tracer_parser_test.cc                                        \\\n  tools/ldb_cmd_test.cc                                                 \\\n  tools/reduce_levels_test.cc                                           \\\n  tools/sst_dump_test.cc                                                \\\n  tools/trace_analyzer_test.cc                                          \\\n  trace_replay/block_cache_tracer_test.cc                               \\\n  trace_replay/io_tracer_test.cc                                        \\\n  util/autovector_test.cc                                               \\\n  util/bloom_test.cc                                                    \\\n  util/coding_test.cc                                                   \\\n  util/crc32c_test.cc                                                   \\\n  util/defer_test.cc                                                    \\\n  util/dynamic_bloom_test.cc                                            \\\n  util/filelock_test.cc                                                 \\\n  util/file_reader_writer_test.cc                                       \\\n  util/hash_test.cc                                                     \\\n  util/heap_test.cc                                                     \\\n  util/random_test.cc                                                   \\\n  util/rate_limiter_test.cc                                             \\\n  util/repeatable_thread_test.cc                                        \\\n  util/ribbon_test.cc                                                   \\\n  util/slice_test.cc                                                    \\\n  util/slice_transform_test.cc                                          \\\n  util/timer_queue_test.cc                                              \\\n  util/timer_test.cc                                                    \\\n  util/thread_list_test.cc                                              \\\n  util/thread_local_test.cc                                             \\\n  util/udt_util_test.cc                                                 \\\n  util/work_queue_test.cc                                               \\\n  utilities/agg_merge/agg_merge_test.cc                                 \\\n  utilities/backup/backup_engine_test.cc                                \\\n  utilities/blob_db/blob_db_test.cc                                     \\\n  utilities/cassandra/cassandra_format_test.cc                          \\\n  utilities/cassandra/cassandra_functional_test.cc                      \\\n  utilities/cassandra/cassandra_row_merge_test.cc                       \\\n  utilities/cassandra/cassandra_serialize_test.cc                       \\\n  utilities/checkpoint/checkpoint_test.cc                               \\\n  utilities/env_timed_test.cc                                           \\\n  utilities/memory/memory_test.cc                                       \\\n  utilities/merge_operators/string_append/stringappend_test.cc          \\\n  utilities/object_registry_test.cc                                     \\\n  utilities/option_change_migration/option_change_migration_test.cc     \\\n  utilities/options/options_util_test.cc                                \\\n  utilities/persistent_cache/hash_table_test.cc                         \\\n  utilities/persistent_cache/persistent_cache_test.cc                   \\\n  utilities/simulator_cache/cache_simulator_test.cc                     \\\n  utilities/simulator_cache/sim_cache_test.cc                           \\\n  utilities/table_properties_collectors/compact_for_tiering_collector_test.cc \\\n  utilities/table_properties_collectors/compact_on_deletion_collector_test.cc  \\\n  utilities/transactions/optimistic_transaction_test.cc                 \\\n  utilities/transactions/lock/range/range_locking_test.cc               \\\n  utilities/transactions/transaction_test.cc                            \\\n  utilities/transactions/lock/point/point_lock_manager_test.cc          \\\n  utilities/transactions/write_prepared_transaction_test.cc             \\\n  utilities/transactions/write_unprepared_transaction_test.cc           \\\n  utilities/transactions/write_committed_transaction_ts_test.cc         \\\n  utilities/transactions/timestamped_snapshot_test.cc                   \\\n  utilities/ttl/ttl_test.cc                                             \\\n  utilities/types_util_test.cc                                          \\\n  utilities/util_merge_operators_test.cc                                \\\n  utilities/write_batch_with_index/write_batch_with_index_test.cc       \\\n\nTEST_MAIN_SOURCES_C = \\\n  db/c_test.c                                                           \\\n\nWITH_FAISS_TEST_MAIN_SOURCES = \\\n  utilities/secondary_index/faiss_ivf_index_test.cc                     \\\n\nMICROBENCH_SOURCES =                                          \\\n  microbench/ribbon_bench.cc                                  \\\n  microbench/db_basic_bench.cc                                  \\\n\nJNI_NATIVE_SOURCES =                                          \\\n  java/rocksjni/backupenginejni.cc                            \\\n  java/rocksjni/backup_engine_options.cc                      \\\n  java/rocksjni/checkpoint.cc                                 \\\n  java/rocksjni/clock_cache.cc                                \\\n  java/rocksjni/cache.cc                                      \\\n  java/rocksjni/columnfamilyhandle.cc                         \\\n  java/rocksjni/compact_range_options.cc                      \\\n  java/rocksjni/compaction_filter.cc                          \\\n  java/rocksjni/compaction_filter_factory.cc                  \\\n  java/rocksjni/compaction_filter_factory_jnicallback.cc      \\\n  java/rocksjni/compaction_job_info.cc                        \\\n  java/rocksjni/compaction_job_stats.cc                       \\\n  java/rocksjni/compaction_options.cc                         \\\n  java/rocksjni/compaction_options_fifo.cc                    \\\n  java/rocksjni/compaction_options_universal.cc               \\\n  java/rocksjni/comparator.cc                                 \\\n  java/rocksjni/comparatorjnicallback.cc                      \\\n  java/rocksjni/compression_options.cc                        \\\n  java/rocksjni/concurrent_task_limiter.cc                    \\\n  java/rocksjni/config_options.cc                             \\\n  java/rocksjni/export_import_files_metadatajni.cc            \\\n  java/rocksjni/env.cc                                        \\\n  java/rocksjni/env_options.cc                                \\\n  java/rocksjni/event_listener.cc                             \\\n  java/rocksjni/event_listener_jnicallback.cc                 \\\n  java/rocksjni/import_column_family_options.cc               \\\n  java/rocksjni/ingest_external_file_options.cc               \\\n  java/rocksjni/filter.cc                                     \\\n  java/rocksjni/hyper_clock_cache.cc                          \\\n  java/rocksjni/iterator.cc                                   \\\n  java/rocksjni/jni_perf_context.cc                           \\\n  java/rocksjni/jni_multiget_helpers.cc                       \\\n  java/rocksjni/jnicallback.cc                                \\\n  java/rocksjni/loggerjnicallback.cc                          \\\n  java/rocksjni/lru_cache.cc                                  \\\n  java/rocksjni/memtablejni.cc                                \\\n  java/rocksjni/memory_util.cc                                \\\n  java/rocksjni/merge_operator.cc                             \\\n  java/rocksjni/native_comparator_wrapper_test.cc             \\\n  java/rocksjni/optimistic_transaction_db.cc                  \\\n  java/rocksjni/optimistic_transaction_options.cc             \\\n  java/rocksjni/options.cc                                    \\\n  java/rocksjni/options_util.cc                               \\\n  java/rocksjni/persistent_cache.cc                           \\\n  java/rocksjni/ratelimiterjni.cc                             \\\n  java/rocksjni/remove_emptyvalue_compactionfilterjni.cc      \\\n  java/rocksjni/cassandra_compactionfilterjni.cc              \\\n  java/rocksjni/cassandra_value_operator.cc                   \\\n  java/rocksjni/restorejni.cc                                 \\\n  java/rocksjni/rocks_callback_object.cc                      \\\n  java/rocksjni/rocksjni.cc                                   \\\n  java/rocksjni/rocksdb_exception_test.cc                     \\\n  java/rocksjni/slice.cc                                      \\\n  java/rocksjni/snapshot.cc                                   \\\n  java/rocksjni/sst_file_manager.cc                           \\\n  java/rocksjni/sst_file_writerjni.cc                         \\\n  java/rocksjni/sst_file_readerjni.cc                         \\\n  java/rocksjni/sst_file_reader_iterator.cc                   \\\n  java/rocksjni/sst_partitioner.cc                            \\\n  java/rocksjni/statistics.cc                                 \\\n  java/rocksjni/statisticsjni.cc                              \\\n  java/rocksjni/stderr_logger.cc                              \\\n  java/rocksjni/table.cc                                      \\\n  java/rocksjni/table_filter.cc                               \\\n  java/rocksjni/table_filter_jnicallback.cc                   \\\n  java/rocksjni/table_properties_collector_factory.cc         \\\n  java/rocksjni/thread_status.cc                              \\\n  java/rocksjni/trace_writer.cc                               \\\n  java/rocksjni/trace_writer_jnicallback.cc                   \\\n  java/rocksjni/transaction.cc                                \\\n  java/rocksjni/transaction_db.cc                             \\\n  java/rocksjni/transaction_options.cc                        \\\n  java/rocksjni/transaction_db_options.cc                     \\\n  java/rocksjni/transaction_log.cc                            \\\n  java/rocksjni/transaction_notifier.cc                       \\\n  java/rocksjni/transaction_notifier_jnicallback.cc           \\\n  java/rocksjni/ttl.cc                                        \\\n  java/rocksjni/testable_event_listener.cc                    \\\n  java/rocksjni/wal_filter.cc                                 \\\n  java/rocksjni/wal_filter_jnicallback.cc                     \\\n  java/rocksjni/write_batch.cc                                \\\n  java/rocksjni/writebatchhandlerjnicallback.cc               \\\n  java/rocksjni/write_batch_test.cc                           \\\n  java/rocksjni/write_batch_with_index.cc                     \\\n  java/rocksjni/write_buffer_manager.cc\n"
        },
        {
          "name": "table",
          "type": "tree",
          "content": null
        },
        {
          "name": "test_util",
          "type": "tree",
          "content": null
        },
        {
          "name": "third-party",
          "type": "tree",
          "content": null
        },
        {
          "name": "thirdparty.inc",
          "type": "blob",
          "size": 7.833984375,
          "content": "# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\n# Edit definitions below to specify paths to include files and libraries of all 3rd party libraries\n\n# TODO: Make this work with find_package and/or get rid of it\n#\n# This example assumes all the libraries locate in directories under THIRDPARTY_HOME environment variable\n# Set environment variable THIRDPARTY_HOME to point to your third party libraries home (Unix style dir separators)\n# or change the paths below to reflect where the libraries actually reside\n#\nset (THIRDPARTY_LIBS \"\")         # Initialization, don't touch\n\n#\n# Defaults\n#\nset(GFLAGS_HOME $ENV{THIRDPARTY_HOME}/Gflags.Library)\nset(GFLAGS_INCLUDE ${GFLAGS_HOME}/build/native/include)\nset(GFLAGS_LIB_DEBUG ${GFLAGS_HOME}/lib/native/debug/amd64/gflags.lib)\nset(GFLAGS_LIB_RELEASE ${GFLAGS_HOME}/lib/native/retail/amd64/gflags.lib)\n\n# ================================================== GFLAGS ==================================================\n# For compatibility\nif (GFLAGS)\n  set(WITH_GFLAGS ON)\nendif ()\n\nif (WITH_GFLAGS)\n  message(STATUS \"GFLAGS library is enabled\")\n  \n  if(DEFINED ENV{GFLAGS_INCLUDE})\n    set(GFLAGS_INCLUDE $ENV{GFLAGS_INCLUDE})\n  endif()\n  \n  if(DEFINED ENV{GFLAGS_LIB_DEBUG})\n    set(GFLAGS_LIB_DEBUG $ENV{GFLAGS_LIB_DEBUG})\n  endif()\n\n  if(DEFINED ENV{GFLAGS_LIB_RELEASE})\n    set(GFLAGS_LIB_RELEASE $ENV{GFLAGS_LIB_RELEASE})\n  endif()\n  \n  set(GFLAGS_CXX_FLAGS -DGFLAGS=gflags)\n  set(GFLAGS_LIBS debug ${GFLAGS_LIB_DEBUG} optimized ${GFLAGS_LIB_RELEASE})\n\n  add_definitions(${GFLAGS_CXX_FLAGS})\n  include_directories(${GFLAGS_INCLUDE})\n  set (THIRDPARTY_LIBS ${THIRDPARTY_LIBS} ${GFLAGS_LIBS})\nelse ()\n  message(STATUS \"GFLAGS library is disabled\")\nendif ()\n\n# ================================================== SNAPPY ==================================================\n#\n# Edit these 4 lines to define paths to Snappy\n#\nset(SNAPPY_HOME $ENV{THIRDPARTY_HOME}/Snappy.Library)\nset(SNAPPY_INCLUDE ${SNAPPY_HOME}/build/native/inc/inc)\nset(SNAPPY_LIB_DEBUG ${SNAPPY_HOME}/lib/native/debug/amd64/snappy.lib)\nset(SNAPPY_LIB_RELEASE ${SNAPPY_HOME}/lib/native/retail/amd64/snappy.lib)\n\n# For compatibility\nif(SNAPPY)\n  set(WITH_SNAPPY ON)\nendif ()\n\nif (WITH_SNAPPY)\n  message(STATUS \"SNAPPY library is enabled\")\n\n  if(DEFINED ENV{SNAPPY_INCLUDE})\n    set(SNAPPY_INCLUDE $ENV{SNAPPY_INCLUDE})\n  endif()\n\n  if(DEFINED ENV{SNAPPY_LIB_DEBUG})\n    set(SNAPPY_LIB_DEBUG $ENV{SNAPPY_LIB_DEBUG})\n  endif()\n\n  if(DEFINED ENV{SNAPPY_LIB_RELEASE})\n    set(SNAPPY_LIB_RELEASE $ENV{SNAPPY_LIB_RELEASE})\n  endif()\n\n  set(SNAPPY_CXX_FLAGS -DSNAPPY)\n  set(SNAPPY_LIBS debug ${SNAPPY_LIB_DEBUG} optimized ${SNAPPY_LIB_RELEASE})\n\n  add_definitions(${SNAPPY_CXX_FLAGS})\n  include_directories(${SNAPPY_INCLUDE})\n  set (THIRDPARTY_LIBS ${THIRDPARTY_LIBS} ${SNAPPY_LIBS})\nelse ()\n  message(STATUS \"SNAPPY library is disabled\")\nendif ()\n\n# ================================================== LZ4 ==================================================\n#\n# Edit these 4 lines to define paths to LZ4\n#\nset(LZ4_HOME $ENV{THIRDPARTY_HOME}/LZ4.Library)\nset(LZ4_INCLUDE ${LZ4_HOME}/build/native/inc/inc)\nset(LZ4_LIB_DEBUG ${LZ4_HOME}/lib/native/debug/amd64/lz4.lib)\nset(LZ4_LIB_RELEASE ${LZ4_HOME}/lib/native/retail/amd64/lz4.lib)\n\n\n# For compatibility\nif (LZ4)\n  set(WITH_LZ4 ON)\nendif ()\n\nif (WITH_LZ4)\n  message(STATUS \"LZ4 library is enabled\")\n  \n  if(DEFINED ENV{LZ4_INCLUDE})\n    set(LZ4_INCLUDE $ENV{LZ4_INCLUDE})\n  endif()\n  \n  if(DEFINED ENV{LZ4_LIB_DEBUG})\n    set(LZ4_LIB_DEBUG $ENV{LZ4_LIB_DEBUG})\n  endif()\n\n  if(DEFINED ENV{LZ4_LIB_RELEASE})\n    set(LZ4_LIB_RELEASE $ENV{LZ4_LIB_RELEASE})\n  endif()\n  \n  set(LZ4_CXX_FLAGS -DLZ4)\n  set(LZ4_LIBS debug ${LZ4_LIB_DEBUG} optimized ${LZ4_LIB_RELEASE})\n\n  add_definitions(${LZ4_CXX_FLAGS})\n  include_directories(${LZ4_INCLUDE})\n  set (THIRDPARTY_LIBS ${THIRDPARTY_LIBS} ${LZ4_LIBS})\nelse ()\n  message(STATUS \"LZ4 library is disabled\")\nendif ()\n\n# ================================================== ZLIB ==================================================\n#\n# Edit these 4 lines to define paths to ZLIB\n#\nset(ZLIB_HOME $ENV{THIRDPARTY_HOME}/ZLIB.Library)\nset(ZLIB_INCLUDE ${ZLIB_HOME}/build/native/inc/inc)\nset(ZLIB_LIB_DEBUG ${ZLIB_HOME}/lib/native/debug/amd64/zlib.lib)\nset(ZLIB_LIB_RELEASE ${ZLIB_HOME}/lib/native/retail/amd64/zlib.lib)\n\n# For compatibilty\nif (ZLIB)\n  set(WITH_ZLIB ON)\nendif ()\n\nif (WITH_ZLIB)\n  message(STATUS \"ZLIB library is enabled\")\n\n  if(DEFINED ENV{ZLIB_INCLUDE})\n    set(ZLIB_INCLUDE $ENV{ZLIB_INCLUDE})\n  endif()\n  \n  if(DEFINED ENV{ZLIB_LIB_DEBUG})\n    set(ZLIB_LIB_DEBUG $ENV{ZLIB_LIB_DEBUG})\n  endif()\n\n  if(DEFINED ENV{ZLIB_LIB_RELEASE})\n    set(ZLIB_LIB_RELEASE $ENV{ZLIB_LIB_RELEASE})\n  endif()\n  \n  set(ZLIB_CXX_FLAGS -DZLIB)\n  set(ZLIB_LIBS debug ${ZLIB_LIB_DEBUG} optimized ${ZLIB_LIB_RELEASE})\n\n  add_definitions(${ZLIB_CXX_FLAGS})\n  include_directories(${ZLIB_INCLUDE})\n  set (THIRDPARTY_LIBS ${THIRDPARTY_LIBS} ${ZLIB_LIBS})\nelse ()\n  message(STATUS \"ZLIB library is disabled\")\nendif ()\n\n# ================================================== XPRESS ==================================================\n# This makes use of built-in Windows API, no additional includes, links to a system lib\n\n# For compatibilty\nif (XPRESS)\n  set(WITH_XPRESS ON)\nendif ()\n\nif (WITH_XPRESS)\n  message(STATUS \"XPRESS is enabled\")\n\n  add_definitions(-DXPRESS)\n  \n  # We are using the implementation provided by the system\n  set (SYSTEM_LIBS ${SYSTEM_LIBS} Cabinet.lib)\nelse ()\n  message(STATUS \"XPRESS is disabled\")\nendif ()\n\n\n# ================================================== ZSTD ==================================================\n#\n# Edit these 4 lines to define paths to ZSTD\n#\nset(ZSTD_HOME $ENV{THIRDPARTY_HOME}/ZSTD.Library)\nset(ZSTD_INCLUDE ${ZSTD_HOME}/build/native/inc)\nset(ZSTD_LIB_DEBUG ${ZSTD_HOME}/lib/native/debug/amd64/libzstd_static.lib)\nset(ZSTD_LIB_RELEASE ${ZSTD_HOME}/lib/native/retail/amd64/libzstd_static.lib)\n\n# For compatibility\nif (ZSTD)\n  set(WITH_ZSTD ON)\nendif ()\n\nif (WITH_ZSTD)\n  message(STATUS \"ZSTD library is enabled\")\n\n  if(DEFINED ENV{ZSTD_INCLUDE})\n    set(ZSTD_INCLUDE $ENV{ZSTD_INCLUDE})\n  endif()\n  \n  if(DEFINED ENV{ZSTD_LIB_DEBUG})\n    set(ZSTD_LIB_DEBUG $ENV{ZSTD_LIB_DEBUG})\n  endif()\n\n  if(DEFINED ENV{ZSTD_LIB_RELEASE})\n    set(ZSTD_LIB_RELEASE $ENV{ZSTD_LIB_RELEASE})\n  endif()\n\n  # ZSTD_STATIC_LINKING_ONLY only allows us to create an allocation functions override\n  # When jemalloc is in use\n  set(ZSTD_LIBS debug ${ZSTD_LIB_DEBUG} optimized ${ZSTD_LIB_RELEASE})\n\n  add_definitions(-DZSTD -DZSTD_STATIC_LINKING_ONLY)\n  include_directories(${ZSTD_INCLUDE})\n  set (THIRDPARTY_LIBS ${THIRDPARTY_LIBS} ${ZSTD_LIBS})\nelse ()\n  message(STATUS \"ZSTD library is disabled\")\nendif ()\n\n#\n# Edit these 4 lines to define paths to Jemalloc\n#\nset(JEMALLOC_HOME $ENV{THIRDPARTY_HOME}/Jemalloc.Library)\nset(JEMALLOC_INCLUDE ${JEMALLOC_HOME}/build/native/inc)\nset(JEMALLOC_LIB_DEBUG ${JEMALLOC_HOME}/lib/native/debug/amd64/jemalloc.lib)\nset(JEMALLOC_LIB_RELEASE ${JEMALLOC_HOME}/lib/native/retail/amd64/jemalloc.lib)\n\n# ================================================== JEMALLOC ==================================================\nif(JEMALLOC)\n  set(WITH_JEMALLOC ON)\nendif()\n\nif (WITH_JEMALLOC)\n  message(STATUS \"JEMALLOC library is enabled\")\n  set(JEMALLOC_CXX_FLAGS \"-DROCKSDB_JEMALLOC -DJEMALLOC_EXPORT= -DJEMALLOC_NO_RENAME\")\n  \n  if(DEFINED ENV{JEMALLOC_INCLUDE})\n    set(JEMALLOC_INCLUDE $ENV{JEMALLOC_INCLUDE})\n  endif()\n  \n  if(DEFINED ENV{JEMALLOC_LIB_DEBUG})\n    set(JEMALLOC_LIB_DEBUG $ENV{JEMALLOC_LIB_DEBUG})\n  endif()\n\n  if(DEFINED ENV{JEMALLOC_LIB_RELEASE})\n    set(JEMALLOC_LIB_RELEASE $ENV{JEMALLOC_LIB_RELEASE})\n  endif()\n\n  set(JEMALLOC_LIBS debug ${JEMALLOC_LIB_DEBUG} optimized ${JEMALLOC_LIB_RELEASE})\n\n  add_definitions(${JEMALLOC_CXX_FLAGS})\n  include_directories(${JEMALLOC_INCLUDE})\n  set (THIRDPARTY_LIBS ${THIRDPARTY_LIBS} ${JEMALLOC_LIBS})\n  set (ARTIFACT_SUFFIX \"_je\")\n\nelse ()\n  set (ARTIFACT_SUFFIX \"\")\n  message(STATUS \"JEMALLOC library is disabled\")\nendif ()\n"
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "trace_replay",
          "type": "tree",
          "content": null
        },
        {
          "name": "unreleased_history",
          "type": "tree",
          "content": null
        },
        {
          "name": "util",
          "type": "tree",
          "content": null
        },
        {
          "name": "utilities",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}