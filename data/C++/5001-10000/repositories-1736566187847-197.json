{
  "metadata": {
    "timestamp": 1736566187847,
    "page": 197,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjIwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "tiny-dnn/tiny-dnn",
      "stars": 5872,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 2.6826171875,
          "content": "---\nLanguage:        Cpp\n# BasedOnStyle:  Google\nAccessModifierOffset: -1\nAlignAfterOpenBracket: Align\nAlignConsecutiveAssignments: true\nAlignConsecutiveDeclarations: false\nAlignEscapedNewlinesLeft: true\nAlignOperands:   true\nAlignTrailingComments: true\nAllowAllParametersOfDeclarationOnNextLine: true\nAllowShortBlocksOnASingleLine: false\nAllowShortCaseLabelsOnASingleLine: true\nAllowShortFunctionsOnASingleLine: All\nAllowShortIfStatementsOnASingleLine: true\nAllowShortLoopsOnASingleLine: true\nAlwaysBreakAfterDefinitionReturnType: None\nAlwaysBreakAfterReturnType: None\nAlwaysBreakBeforeMultilineStrings: true\nAlwaysBreakTemplateDeclarations: true\nBinPackArguments: true\nBinPackParameters: false\nBraceWrapping:\n  AfterClass:      false\n  AfterControlStatement: false\n  AfterEnum:       false\n  AfterFunction:   false\n  AfterNamespace:  false\n  AfterObjCDeclaration: false\n  AfterStruct:     false\n  AfterUnion:      false\n  BeforeCatch:     false\n  BeforeElse:      false\n  IndentBraces:    false\nBreakBeforeBinaryOperators: None\nBreakBeforeBraces: Attach\nBreakBeforeTernaryOperators: true\nBreakConstructorInitializersBeforeComma: false\nBreakAfterJavaFieldAnnotations: false\nBreakStringLiterals: true\nColumnLimit:     80\nCommentPragmas:  '^ IWYU pragma:'\nConstructorInitializerAllOnOneLineOrOnePerLine: true\nConstructorInitializerIndentWidth: 2\nContinuationIndentWidth: 2\nCpp11BracedListStyle: true\nDerivePointerAlignment: true\nDisableFormat:   false\nExperimentalAutoDetectBinPacking: false\nForEachMacros:   [ foreach, Q_FOREACH, BOOST_FOREACH ]\nIncludeCategories:\n  - Regex:           '^<.*\\.h>'\n    Priority:        1\n  - Regex:           '^<.*'\n    Priority:        2\n  - Regex:           '.*'\n    Priority:        3\nIncludeIsMainRegex: '([-_](test|unittest))?$'\nIndentCaseLabels: true\nIndentWidth:     2\nIndentWrappedFunctionNames: false\nJavaScriptQuotes: Leave\nJavaScriptWrapImports: true\nKeepEmptyLinesAtTheStartOfBlocks: false\nMacroBlockBegin: ''\nMacroBlockEnd:   ''\nMaxEmptyLinesToKeep: 1\nNamespaceIndentation: None\nObjCBlockIndentWidth: 2\nObjCSpaceAfterProperty: false\nObjCSpaceBeforeProtocolList: false\nPenaltyBreakBeforeFirstCallParameter: 1\nPenaltyBreakComment: 300\nPenaltyBreakFirstLessLess: 120\nPenaltyBreakString: 1000\nPenaltyExcessCharacter: 1000000\nPenaltyReturnTypeOnItsOwnLine: 200\nPointerAlignment: Right\nReflowComments:  true\nSortIncludes:    true\nSpaceAfterCStyleCast: false\nSpaceBeforeAssignmentOperators: true\nSpaceBeforeParens: ControlStatements\nSpaceInEmptyParentheses: false\nSpacesBeforeTrailingComments: 2\nSpacesInAngles:  false\nSpacesInContainerLiterals: true\nSpacesInCStyleCastParentheses: false\nSpacesInParentheses: false\nSpacesInSquareBrackets: false\nStandard:        Auto\nTabWidth:        2\nUseTab:          Never\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.4716796875,
          "content": "# Auto detect text files and perform LF normalization\n* text=auto\n\n# Custom for Visual Studio\n*.cs     diff=csharp\n*.sln    merge=union\n*.csproj merge=union\n*.vbproj merge=union\n*.fsproj merge=union\n*.dbproj merge=union\n\n# Standard to msysgit\n*.doc\t diff=astextplain\n*.DOC\t diff=astextplain\n*.docx diff=astextplain\n*.DOCX diff=astextplain\n*.dot  diff=astextplain\n*.DOT  diff=astextplain\n*.pdf  diff=astextplain\n*.PDF\t diff=astextplain\n*.rtf\t diff=astextplain\n*.RTF\t diff=astextplain\n"
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 2.5380859375,
          "content": "#################\n## Eclipse\n#################\n\n*.pydevproject\n.project\n.metadata\nbin/\ntmp/\n*.tmp\n*.bak\n*.swp\n*~.nib\nlocal.properties\n.classpath\n.settings/\n.loadpath\nwaf-*\n.waf-*\n\n# External tool builders\n.externalToolBuilders/\n\n# Locally stored \"Eclipse launch configurations\"\n*.launch\n\n# CDT-specific\n.cproject\n\n# PDT-specific\n.buildpath\n\n\n#################\n## Visual Studio\n#################\n\n## Ignore Visual Studio temporary files, build results, and\n## files generated by popular Visual Studio add-ons.\n\n# User-specific files\n*.suo\n*.user\n*.sln.docstates\n\n# Build results\n[Dd]ebug/\n[Rr]elease/\n*_i.c\n*_p.c\n*.ilk\n*.meta\n*.obj\n*.pch\n*.pdb\n*.pgc\n*.pgd\n*.rsp\n*.sbr\n*.tlb\n*.tli\n*.tlh\n*.tmp\n*.vspscc\n.builds\n*.dotCover\n*.tlog\n*.ipdb\n*.iobj\n*.idb\n*.lastbuildstate\n*.unsuccessfulbuild\n*.db\n\n# Visual C++ cache files\nipch/\n*.aps\n*.ncb\n*.opensdf\n*.sdf\n\n\n# Visual Studio profiler\n*.psess\n*.vsp\n\n# ReSharper is a .NET coding add-in\n_ReSharper*\n\n# Installshield output folder\n[Ee]xpress\n\n# DocProject is a documentation generator add-in\nDocProject/buildhelp/\nDocProject/Help/*.HxT\nDocProject/Help/*.HxC\nDocProject/Help/*.hhc\nDocProject/Help/*.hhk\nDocProject/Help/*.hhp\nDocProject/Help/Html2\nDocProject/Help/html\n\n# Click-Once directory\npublish\n\n# Others\n[Bb]in\n[Oo]bj\nsql\nTestResults\n*.Cache\nClientBin\nstylecop.*\n~$*\n*.dbmdl\nGenerated_Code #added for RIA/Silverlight projects\n\n# Backup & report files from converting an old project file to a newer\n# Visual Studio version. Backup files are not needed, because we have git ;-)\n_UpgradeReport_Files/\nBackup*/\nUpgradeLog*.XML\n\n\n\n############\n## Windows\n############\n\n# Windows image file caches\nThumbs.db\n\n# Folder config file\nDesktop.ini\n\n\n#############\n## Python\n#############\n\n*.py[co]\n\n# Packages\n*.egg\n*.egg-info\ndist\nbuild\neggs\nparts\nbin\nvar\nsdist\ndevelop-eggs\n.installed.cfg\n\n# Installer logs\npip-log.txt\n\n# Unit test / coverage reports\n.coverage\n.tox\n\n#Translations\n*.mo\n\n#Mr Developer\n.mr.developer.cfg\n\n# Mac crap\n.DS_Store\n\n\n\n#################\n## Waf\n#################\nbuild\nwaf3*\n.lock-waf*\n\n#################\n## CMake\n#################\nCMakeCache.txt\nCMakeFiles*\nALL_BUILD*\nZERO_CHECK*\ncotire/\nMakefile\ncmake-uninstall.cmake\ncmake_install.cmake\ntinydnn-config-version.cmake\ntinydnn-config.cmake\ntinydnn-targets.cmake\nexamples/*.cmake\ntest/*.cmake\n\n#################\n## Google Tests\n#################\ngoogletest-build/\ngoogletest-download/\ngoogletest-src/\n\n#################\n## Docs\n#################\nhtml*\nlatex*\ndocs/_build\n\n#################\n## Other\n#################\n*.exe\n*.dll\n*.bin\n*.pb.cc\n*.pb.h\nCMakeFiles*\nbuild*\nDartConfiguration.tcl\n\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 2.5,
          "content": "sudo: required\ndist: trusty\nosx_image: xcode8\n\nlanguage: cpp\n\nos:\n  - linux\n  - osx\n\ncompiler:\n  - gcc\n  - clang\n\ncache:\n  pip: true\n  directories:\n    - $HOME/.pip-cache/\n\naddons:\n  apt:\n    sources:\n    - ubuntu-toolchain-r-test\n    - llvm-toolchain-precise-3.6\n    packages:\n    - gcc-4.9\n    - g++-4.9\n    - clang-3.6\n    - cmake\n    - git\n    # Optional dependencies\n    - libtbb-dev\n    # coveralls dependencies\n    - gem\n    - lcov\n    # caffe-importer dependencies\n    - libprotobuf-dev\n    - protobuf-compiler\n\nbranches:\n  only:\n    - master\n    #- feat/xtensor_integration\n    #- feat/decouple_activations\n\nenv:\n  global:\n    - USE_TBB=ON\n    - BUILD_TESTS=ON\n    - BUILD_EXAMPLES=ON\n    - COVERALLS=ON\n\n  matrix:\n    - USE_SSE=OFF USE_AVX=OFF USE_DOUBLE=OFF\n    - USE_SSE=ON  USE_AVX=ON USE_DOUBLE=OFF\n    - USE_SSE=ON  USE_AVX=ON USE_DOUBLE=ON\n\nmatrix:\n  exclude: # On OSX g++ is a symlink to clang++ by default\n    - os: osx\n      compiler: gcc\n\nbefore_install:\n  - if [ \"$TRAVIS_OS_NAME\" == \"linux\" ] && [ \"$CXX\" == \"g++\" ]; then\n      export CC=\"gcc-4.9\";\n      export CXX=\"g++-4.9\";\n    fi\n  - gcc --version\n  - g++ --version\n\ninstall:\n  - bash -x .travis/install.sh\n  - gem install coveralls-lcov\n  - pip install --user cpplint\n\nbefore_script:\n  - if [ \"$TRAVIS_OS_NAME\" == \"linux\" ] && [ \"$CXX\" == \"g++-4.9\" ]; then\n      lcov --directory . --zerocounters;\n      cmake -DUSE_TBB=$USE_TBB\n            -DUSE_SSE=$USE_SSE\n            -DUSE_AVX=$USE_AVX\n            -DUSE_DOUBLE=$USE_DOUBLE\n            -DBUILD_TESTS=$BUILD_TESTS\n            -DCOVERALLS=$COVERALLS\n            -DUSE_ASAN=ON\n            -DBUILD_EXAMPLES=$BUILD_EXAMPLES .;\n    fi\n  - if [ \"$TRAVIS_OS_NAME\" == \"linux\" ] && [ \"$CXX\" == \"clang++\" ]; then\n      cmake -DUSE_SSE=$USE_SSE\n            -DUSE_AVX=$USE_AVX\n            -DBUILD_TESTS=$BUILD_TESTS\n            -DBUILD_EXAMPLES=$BUILD_EXAMPLES .;\n    fi\n  - if [ \"$TRAVIS_OS_NAME\" == \"osx\" ]; then\n      cmake -DUSE_TBB=$USE_TBB\n            -DUSE_AVX=OFF\n            -DBUILD_TESTS=$BUILD_TESTS .;\n    fi\n  #- if [ \"$TRAVIS_OS_NAME\" == \"linux\" ]; then\n  #    make test_lints;\n  #  fi\n\nscript:\n  - make -j2\n  - test/tiny_dnn_test\n\nafter_success:\n  - if [ \"$TRAVIS_OS_NAME\" == \"linux\" ] && [ \"$CXX\" == \"g++-4.9\" ]; then\n      lcov --directory . --capture --output-file coverage.info;\n      lcov --remove coverage.info 'test/*' 'third_party/*' 'cereal/*' '/usr/*' 'tiny_dnn/io/caffe/caffe.pb.*' --output-file coverage.info;\n      lcov --list coverage.info;\n      coveralls-lcov --source-encoding=ISO-8859-1 coverage.info;\n    fi\n"
        },
        {
          "name": ".travis",
          "type": "tree",
          "content": null
        },
        {
          "name": "AUTHORS",
          "type": "blob",
          "size": 3.60546875,
          "content": "# Authors ordered by first contribution.\n\nTaiga Noumi <Noumi.Taiga@gmail.com>\nnyanp <Noumi.Taiga@gmail.com>\nmr <xgit@redmond5.com>\nFilippo Lazzarini <Filoz@users.noreply.github.com>\nMarco foco <marco.foco@codemachine.it>\nMarco foco <pansk@users.noreply.github.com>\nCraig Henderson <hello@craighenderson.co.uk>\nPatrik Huber <patrikhuber@users.noreply.github.com>\nChangxu <Changxu.mail@gmail.com>\nYan <yannick.verdie@gmail.com>\nVolker Grabe <vgrabe@users.noreply.github.com>\nstozpark <stozpark@gmail.com>\nBálint Fodor <balint.fodor@gmail.com>\nTony Di Croce <dicroce@gmail.com>\nrmsalinas <rmsalinas@uco.es>\nllerrito <pijama.cu@gmail.com>\nVojtech Mrazek <imrazek@fit.vutbr.cz>\nTolga Birdal <tbirdal@gmail.com>\nAziz Baibabaev <aziz@sightcorp.com>\nMarco Foco <pan@spinningkids.org>\nMarco Foco <pansk@users.noreply.github.com>\nstereomatchingkiss <stereomatchingkiss@gmail.com>\nAndre Holzner <holzner@andres-macbook-pro-2.fritz.box>\nRaphael Isemann <teemperor@googlemail.com>\nnyanp <nyanpn@gmail.com>\nRaphael Isemann <teemperor@gmail.com>\nAlex Z <TohnoSakuya@users.noreply.github.com>\nJuha Reunanen <juha.reunanen@tomaattinen.com>\nedgarriba <edgar.riba@gmail.com>\nJuan Mo <juan.mo.song@gmail.com>\nWangyida <wangyida123@outlook.com>\nberu <berupon@gmail.com>\nMikalai Drabovich <drabovich@gmail.com>\nRoland Persson <roland.persson@bontouch.com>\nEdgar Riba <edgar.riba@gmail.com>\nYida Wang <yidawang.cn@gmail.com>\nJuha Reunanen <juha.reunanen@gmail.com>\nAndrew Murray <radarhere@gmail.com>\nH4kor <niko.abeler@gmail.com>\nMasahiro Imai <masaz.dream@gmail.com>\nLior David <liorda@users.noreply.github.com>\nSyoyo Fujita <syoyo@lighttransport.com>\nJiaolong <jiaolongxu@gmail.com>\nKonfrareAlbert <lakonfrariadelavila@gmail.com>\nbhack <bhack@users.noreply.github.com>\njichao zhang <1632206636@qq.com>\nEvgeniy Zheltonozhskiy <zheltonozhskiy@gmail.com>\nGoran Rauker <goranr@gmail.com>\nazsane <azsane@users.noreply.github.com>\nKatsuhisa Yuasa <berupon@gmail.com>\nEvgenii <eabesea@rambler.ru>\nShan <uniwangshan@gmail.com>\nwdroz <william.droz.ch@gmail.com>\nNiklas Rosenstein <NiklasRosenstein@users.noreply.github.com>\nReinis Veips <festlv@users.noreply.github.com>\nyumetodo <yume-wikijp@live.jp>\nJohan Pauwels <jpauwels@users.noreply.github.com>\nCsaba Kertész <csaba.kertesz@vincit.fi>\nShashank Shekhar <sshkhrnwbie@users.noreply.github.com>\nRomuald Perrot <perrot.romuald@gmail.com>\nnotecola <notecola@gmail.com>\nLigang Wu <limitfan@gmail.com>\nOscar Takeshita <pliptor@users.noreply.github.com>\nkafendt <kafendt@users.noreply.github.com>\nReinis Veips <reinis.veips@wot.lv>\nAlessandro Gentilini <alessandro.gentilini@gmail.com>\ntomjaguarpaw <tom-github.com@jaguarpaw.co.uk>\nSam Wenke <wenkesj@users.noreply.github.com>\nKaran Desai <karandesai_96@live.com>\nMeiHui FAN <mhfan@ustc.edu>\nRui Huang <vowstar@users.noreply.github.com>\nSiddhartha Rao Kamalakara <srk97c@gmail.com>\nJaakko Rantala <jaakko.rantala@gmail.com>\nNishant Nikhil <i.nishantnikhil@gmail.com>\nGear <dev_kr@naver.com>\nZhuo Zhang <zchrissirhcz@gmail.com>\nLee Mracek <lee.mracek@gmail.com>\nwhenimg0ne <masaaki.korematsu@gmail.com>\nPau Rodriguez <prlz77@users.noreply.github.com>\nNauman Mustafa <14beenmustafa@seecs.nust.edu.pk>\nprlz77 <pau.rodri1@gmail.com>\nLucas Pedro Bordignon <lucaspbordignon99@gmail.com>\nAlbert <blackccpie@free.fr>\nEduardo Cáceres <eduherminio@users.noreply.github.com>\nDirk Groeneveld <groeneveld@gmail.com>\nsid <srk97c@gmail.com>\nblackccpie <blackccpie@free.fr>\nThomas van den Berg <thomas.g.vandenberg@gmail.com>\nLakshay Garg <lakshayg@outlook.in>\nberu <berunpon@gmail.com>\nJunbo Zhang <dr.jimbozhang@gmail.com>\nedeforas <etienne.deforas@gmail.com>\nHaozhe Xie <cshzxie@gmail.com>\n\n# Generated by scripts/update-authors.sh\n"
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 16.828125,
          "content": "####\n# Set minimum version of CMake. Since command 'project' use\n# VERSION sub-option we need at least 3.0.\n# Note: If you use 2.6 or 2.4, God kills a kitten. Seriously.\ncmake_minimum_required(VERSION 3.2 FATAL_ERROR)\n\n####\n# Set variables:\n#   * PROJECT_NAME\n#   * PROJECT_VERSION\nproject(tiny_dnn VERSION 1.0.0 LANGUAGES C CXX)\n\n#####\n# Enables link_directories() treat paths relative\n# to the source dir.\nif(POLICY CMP0015)\n    cmake_policy(SET CMP0015 NEW)\nendif(POLICY CMP0015)\n\n#####\n# Enables project() command manages VERSION variables.\nif(POLICY CMP0048)\n    cmake_policy(SET CMP0048 NEW)\nendif(POLICY CMP0048)\n\n#####\n# Change the default build type from Debug to Release, while still\n# supporting overriding the build type.\n#\n# The CACHE STRING logic here and elsewhere is needed to force CMake\n# to pay attention to the value of these variables.\nif(NOT CMAKE_BUILD_TYPE)\n    message(STATUS \"No build type specified; defaulting to CMAKE_BUILD_TYPE=Release.\")\n    set(CMAKE_BUILD_TYPE Release CACHE STRING\n        \"Choose the type of build, options are: None Debug Release RelWithDebInfo MinSizeRel.\"\n        FORCE)\nelse(NOT CMAKE_BUILD_TYPE)\n    if(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\n        message(\"==========================================================================================\")\n        message(STATUS \"Build type: Debug. Performance will be terrible!\")\n        message(STATUS \"Add -DCMAKE_BUILD_TYPE=Release to the CMake command line to get an optimized build.\")\n        message(\"==========================================================================================\")\n    endif(CMAKE_BUILD_TYPE STREQUAL \"Debug\")\nendif(NOT CMAKE_BUILD_TYPE)\n\n####\n# Define user options\noption(USE_SSE        \"Build tiny-dnn with SSE library support\"            ON)\noption(USE_AVX        \"Build tiny-dnn with AVX library support\"            ON)\noption(USE_AVX2       \"Build tiny-dnn with AVX2 library support\"           OFF)\noption(USE_TBB        \"Build tiny-dnn with TBB library support\"            OFF)\noption(USE_OMP        \"Build tiny-dnn with OMP library support\"            OFF)\noption(USE_NNPACK     \"Build tiny-dnn with NNPACK library support\"         OFF)\noption(USE_CBLAS      \"Build tiny-dnn with CBLAS library support\"          OFF)\noption(USE_INTEL_MKL  \"Build tiny-dnn with Intel MKL library support\"      OFF)\noption(USE_OPENCL     \"Build tiny-dnn with OpenCL library support\"         OFF)\noption(USE_LIBDNN     \"Build tiny-dnn with GreenteaLibDNN library support\" OFF)\noption(USE_SERIALIZER \"Build tiny-dnn with Serialization support\"          ON)\noption(USE_DOUBLE     \"Build tiny-dnn with double precision computations\"  OFF)\noption(USE_IMAGE_API  \"Build tiny-dnn with Image API support\"              ON)\noption(USE_GEMMLOWP   \"Build tiny-dnn with gemmlowp support\"               OFF)\n\noption(BUILD_TESTS      \"Set to ON to build tests\"              OFF)\noption(BUILD_EXAMPLES   \"Set to ON to build examples\"           OFF)\noption(BUILD_DOCS       \"Set to ON to build documentation\"      OFF)\noption(BUILD_BENCHMARKS \"Set to ON to build benchmarks\"         OFF)\noption(COVERALLS        \"Set to ON to build with code coverage\" OFF)\noption(PROFILE          \"Set to ON to build with profiling\"     OFF)\noption(USE_ASAN         \"Set to ON to build with ASan\"          OFF)\n\n####\n# Create the library target\n\nset(project_library_target_name ${PROJECT_NAME})\nset(PACKAGE_NAME TinyDNN)\n\nadd_library(${project_library_target_name} INTERFACE)\n\n####\n# Setup the optional dependencies\n\n# Using cmake scripts and modules\nlist(APPEND CMAKE_MODULE_PATH ${PROJECT_SOURCE_DIR}/cmake/Modules)\n\n# Tiny-dnn provides a couple of multithreading solutions.\n# The user can specify to use Intel Threading Building Blocks (TBB)\n# or Open Multi-Processing (OpenMP) as a backend for multi threading\n# processing. In case that none of this libraries are required, tiny-dnn\n# will use the standard C++11 Thread support library.\n\n# Find Intel Threading Building Blocks (TBB)\nfind_package(TBB QUIET)\nif(USE_TBB AND TBB_FOUND)\n    message(STATUS \"Found Intel TBB: ${TBB_INCLUDE_DIR}\")\n    # In case that TBB is found we force to disable OpenMP since\n    # tiny-dnn does not support mutiple multithreading backends.\n    set(USE_OMP OFF)\n    #TODO: add definitions in configure\n    add_definitions(-DCNN_USE_TBB)\n    include_directories(${TBB_INCLUDE_DIRS})\n    link_directories(${TBB_LIBRARY_DIRS})\n    list(APPEND REQUIRED_LIBRARIES ${TBB_LIBRARIES})\nelseif(USE_TBB AND NOT TBB_FOUND)\n    # In case the user sets the flag USE_TBB to ON, the CMake build-tree\n    # will require to find TBB in your system. Otherwise, the user can\n    # set the paths to headers and libs by hand.\n    message(FATAL_ERROR \"Intel TBB not found. Please set TBB_INCLUDE_DIRS & \"\n            \"TBB_LIBRARIES\")\nendif()\n\nif(NOT USE_SERIALIZER)\n    add_definitions(-DCNN_NO_SERIALIZATION)\nendif()\n\nif(USE_DOUBLE)\n    add_definitions(-DCNN_USE_DOUBLE)\nendif()\n\nif(USE_IMAGE_API)\n    add_definitions(-DDNN_USE_IMAGE_API)\nendif()\n\nif(USE_GEMMLOWP)\n    add_definitions(-DUSE_GEMMLOWP)\nendif()\n\n# Find Open Multi-Processing (OpenMP)\nfind_package(OpenMP QUIET)\nif(USE_OMP AND OPENMP_FOUND)\n    message(STATUS \"Found OpenMP\")\n    # In case that OMP is found we force to disable Intel TBB since\n    # tiny-dnn does not support mutiple multithreading backends.\n    set(USE_TBB OFF)\n    add_definitions(-DCNN_USE_OMP)\n    set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} ${OpenMP_C_FLAGS}\")\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} ${OpenMP_CXX_FLAGS}\")\n    set(CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS} ${OpenMP_EXE_LINKER_FLAGS}\")\nelseif(USE_OMP AND NOT OPENMP_FOUND)\n    # In case the user sets the flag USE_OMP to ON, the CMake build-tree\n    # will require to find OMP in your system. Otherwise, the user can\n    # set the CMAKE_C_FLAGS and CMAKE_CXX_FLAGS by hand.\n    message(FATAL_ERROR \"Can't find OpenMP. Please set OpenMP_C_FLAGS & \"\n            \"OpenMP_CXX_FLAGS\")\nendif()\n\n# Find NNPACK: Acceleration package for neural networks on multi-core CPUs\nfind_package(NNPACK QUIET)\nif(USE_NNPACK AND NNPACK_FOUND)\n    message(STATUS \"Found NNPACK: ${NNPACK_INCLUDE_DIR}\")\n    add_definitions(-DCNN_USE_NNPACK)\n    include_directories(SYSTEM ${NNPACK_INCLUDE_DIR})\n    include_directories(SYSTEM ${NNPACK_INCLUDE_DIR}/../third-party/pthreadpool/include)\n    list(APPEND REQUIRED_LIBRARIES ${NNPACK_LIB})\nelseif(USE_NNPACK AND NOT NNPACK_FOUND)\n    # In case the user sets the flag USE_NNPACK to ON, the CMake build-tree\n    # will require to find NNPACK in your system. Otherwise, the user can\n    # set the paths to headers and libs by hand.\n    message(FATAL_ERROR \"Can't find NNPACK. Please set NNPACK_INCLUDE_DIR \"\n            \" & NNPACK_LIB\")\nendif()\n\n# Find CBLAS: Acceleration package for linear algebra\nif(USE_CBLAS)\n    # In case the user sets the flag USE_CBLAS to ON, the CMake build-tree\n    # will require to find CBLAS in your system.\n    find_package(BLAS REQUIRED)\n    if(BLAS_FOUND)\n        if (NOT EXISTS \"/usr/include/cblas.h\" OR NOT EXISTS ${BLAS_LIBRARIES})\n            message(FATAL_ERROR \"CBLAS path error.\")\n        endif()\n        add_definitions(-DCNN_USE_CBLAS)\n        list(APPEND REQUIRED_LIBRARIES ${BLAS_LIBRARIES})\n    else()\n        message(FATAL_ERROR \"Can't find CBLAS. On Ubunbu, you may want to \"\n                \"install it by:\\n  sudo apt-get install libatlas-dev\")\n    endif()\nendif()\n\n# Find Intel MKL: CBLAS implementation from Intel\nif(USE_INTEL_MKL)\n    find_package(INTELMKL REQUIRED)\n    if(INTELMKL_FOUND)\n        message(STATUS \"Found Intel MKL: ${INTEL_MKL_INCLUDE_DIR}\")\n        add_definitions(-DCNN_USE_INTEL_MKL)\n        include_directories(SYSTEM ${INTEL_MKL_INCLUDE_DIR})\n        list(APPEND REQUIRED_LIBRARIES \"-Wl,--start-group ${INTEL_MKL_LIB_1} ${INTEL_MKL_LIB_2} ${INTEL_MKL_LIB_3} -Wl,--end-group -ldl\")\n    else(INTELMKL_FOUND)\n        # In case the user sets the flag USE_INTEL_MKL to ON, the CMake build-tree\n        # will require to find Intel MKL in your system. Otherwise, the user can\n        # set the paths to headers and libs by hand.\n        message(FATAL_ERROR \"Can't find Intel MKL. Please set MKLROOT\")\n    endif()\nendif(USE_INTEL_MKL)\n\n# in case that TBB and OMP are not enabled/found,\n# we enable standard C++11 multithread support.\nif((NOT USE_TBB) AND (NOT USE_OMP) AND (NOT WIN32))\n    #list(APPEND EXTRA_C_FLAGS -pthread)\n    set(USE_PTHREAD ON)\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -pthread\")\n    message(STATUS \"TBB and OMP disabled: Using Pthread instead.\")\nelse((NOT USE_TBB) AND (NOT USE_OMP))\n    set(USE_PTHREAD OFF)\nendif((NOT USE_TBB) AND (NOT USE_OMP) AND (NOT WIN32))\n\nfind_package(OpenCL QUIET)\nif(USE_OPENCL AND OpenCL_FOUND)\n    message(STATUS \"Found OpenCL: ${OpenCL_INCLUDE_DIRS}\")\n    #add_definitions(-DCNN_HAVE_OPENCL)\n    add_definitions(-DUSE_OPENCL)\n    include_directories(SYSTEM ${OpenCL_INCLUDE_DIRS})\n    list(APPEND REQUIRED_LIBRARIES ${OpenCL_LIBRARY})\nelseif(USE_OPENCL AND NOT OpenCL_FOUND)\n    # In case the user sets the flag USE_OPENCL to ON, the CMake build-tree\n    # will require to find OPENCL in your system. Otherwise, the user can\n    # set the paths to headers and libs by hand.\n    message(FATAL_ERROR \"Can't find OpenCL.\")\nendif()\n\nfind_package(GreenteaLibDNN QUIET)\nif(OpenCL_FOUND AND USE_LIBDNN AND GreenteaLibDNN_FOUND)\n    message(STATUS \"Found GreenteaLibDNN: ${GREENTEA_INCLUDE_DIRS}\")\n    add_definitions(-DCNN_USE_LIBDNN)\n    include_directories(SYSTEM ${GREENTEA_INCLUDE_DIRS})\n    list(APPEND REQUIRED_LIBRARIES greentea_libdnn ${GREENTEA_LIBRARIES})\nelseif(USE_LIBDNN AND NOT OpenCL_FOUND)\n    message(FATAL_ERROR \"OpenCL is needed for GreenteaLibDNN.\")\nelseif(USE_LIBDNN AND NOT LIBDNN_FOUND)\n    # In case the user sets the flag USE_LIBDNN to ON, the CMake build-tree\n    # will require to find LibDNN in your system. Otherwise, the user can\n    # set the paths to headers and libs by hand.\n    message(FATAL_ERROR \"Can't find LibDNN.\")\nendif()\n\n####\n# Setup the compiler options\n\n# set c++ standard to c++14.\n# Note: not working on CMake 2.8. We assume that user has\n#       a compiler with C++14 support.\n\nset(CMAKE_CXX_STANDARD 14)\nset(CMAKE_CXX_STANDARD_REQUIRED ON)\nmessage(STATUS \"C++14 support has been enabled by default.\")\n\ninclude(cotire)\n\n# Unix\nif(CMAKE_COMPILER_IS_GNUCXX OR MINGW OR\n   CMAKE_CXX_COMPILER_ID MATCHES \"Clang\")\n    include(CheckCXXCompilerFlag)\n    check_cxx_compiler_flag(\"-msse3\" COMPILER_HAS_SSE_FLAG)\n    check_cxx_compiler_flag(\"-mavx\"  COMPILER_HAS_AVX_FLAG)\n    check_cxx_compiler_flag(\"-mavx2\" COMPILER_HAS_AVX2_FLAG)\n    check_cxx_compiler_flag(\"-mfma\" COMPILER_HAS_AVX2_FLAG)\n\n    # set Streaming SIMD Extension (SSE) instructions\n    if(USE_SSE AND COMPILER_HAS_SSE_FLAG)\n        add_definitions(-DCNN_USE_SSE)\n        set(EXTRA_C_FLAGS \"${EXTRA_C_FLAGS} -msse3\")\n    endif(USE_SSE AND COMPILER_HAS_SSE_FLAG)\n    # set Advanced Vector Extensions (AVX)\n    if(USE_AVX AND COMPILER_HAS_AVX_FLAG)\n        add_definitions(-DCNN_USE_AVX)\n        set(EXTRA_C_FLAGS \"${EXTRA_C_FLAGS} -mavx\")\n    endif(USE_AVX AND COMPILER_HAS_AVX_FLAG)\n    # set Advanced Vector Extensions 2 (AVX2)\n    if(USE_AVX2 AND COMPILER_HAS_AVX2_FLAG)\n        add_definitions(-DCNN_USE_AVX2)\n        set(EXTRA_C_FLAGS \"${EXTRA_C_FLAGS} -mavx2 -mfma -march=core-avx2\")\n    endif(USE_AVX2 AND COMPILER_HAS_AVX2_FLAG)\n\n    # include extra flags to the compiler\n    # TODO: add info about those flags.\n    set(EXTRA_C_FLAGS \"${EXTRA_C_FLAGS} -Wall -Wpedantic -Wno-narrowing -Wno-deprecated\")\n    set(EXTRA_C_FLAGS_RELEASE \"${EXTRA_C_FLAGS_RELEASE} -O3\")\n    set(EXTRA_C_FLAGS_DEBUG   \"${EXTRA_C_FLAGS_DEBUG} -g3 -pthread\")\nelseif(MSVC)\n    if(USE_SSE)\n        add_definitions(-DCNN_USE_SSE)\n        set(EXTRA_C_FLAGS \"${EXTRA_C_FLAGS} /arch:SSE2\")\n    endif(USE_SSE)\n    if(USE_AVX)\n        add_definitions(-DCNN_USE_AVX)\n        set(EXTRA_C_FLAGS \"${EXTRA_C_FLAGS} /arch:AVX\")\n    endif(USE_AVX)\n    if(USE_AVX2)\n        add_definitions(-DCNN_USE_AVX2)\n        set(EXTRA_C_FLAGS \"${EXTRA_C_FLAGS} /arch:AVX2\")\n    endif(USE_AVX2)\n    # include specific flags for release and debug modes.\n    set(EXTRA_C_FLAGS_RELEASE \"${EXTRA_C_FLAGS_RELEASE}\n        /Ox /Oi /Ot /Oy /GL /fp:fast /GS-\")\n    set(CMAKE_EXE_LINKER_FLAGS_RELEASE \"${CMAKE_EXE_LINKER_FLAGS_RELEASE} /LTCG\")\n    set(EXTRA_C_FLAGS_DEBUG \"${EXTRA_C_FLAGS_DEBUG}\")\n    set(EXTRA_C_FLAGS \"${EXTRA_C_FLAGS} /W4 /bigobj\")\n    # this is fine\n    add_definitions(-D _CRT_SECURE_NO_WARNINGS)\n    add_definitions(-D _SCL_SECURE_NO_WARNINGS)\n    # prolly powerless with header-only project\n    set(EXTRA_C_FLAGS \"${EXTRA_C_FLAGS} /MP\")\nendif()\n\n####\n# Set compiler options\nset(CMAKE_CXX_FLAGS         \"${CMAKE_CXX_FLAGS} ${EXTRA_C_FLAGS}\")\nset(CMAKE_CXX_FLAGS_RELEASE \"${CMAKE_CXX_FLAGS_RELEASE} ${EXTRA_C_FLAGS_RELEASE}\")\nset(CMAKE_CXX_FLAGS_DEBUG   \"${CMAKE_CXX_FLAGS_DEBUG} ${EXTRA_C_FLAGS_DEBUG}\")\n\nif(PROFILE AND (CMAKE_COMPILER_IS_GNUCXX OR MINGW OR\n    CMAKE_CXX_COMPILER_ID MATCHES \"Clang\"))\n    set(CMAKE_CXX_FLAGS     \"${CMAKE_CXX_FLAGS} -pg\")\nendif()\n\nif (USE_ASAN)\n    #enable ASan\n    set(ENV{ASAN_OPTIONS} \"strict_string_checks=1:detect_stack_use_after_return=1:check_initialization_order=1:strict_init_order=1:symbolize=1\")\n    CHECK_CXX_COMPILER_FLAG(-fsanitize-address-use-after-scope HasUseAfterScope)\n    set(ASAN_FLAGS \"-fsanitize=address -fno-omit-frame-pointer\")\n    if (HasUseAfterScope)\n        set(ASAN_FLAGS \"${ASAN_FLAGS} -fsanitize-address-use-after-scope\")\n    endif()\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} ${ASAN_FLAGS}\")\nendif()\n####\n# Write the config.h\n# TODO: replace for tiny_dnn/config.h\n# configure_file(cmake/Templates/tinydnn_config.h.in\n#               \"${PROJECT_BINARY_DIR}/tinydnn_config.h\")\n\n####\n# Setup the cmake config files\nstring(REGEX REPLACE \"_\" \"\" PROJECT_NAME_JOINED ${PROJECT_NAME})\n\nset(cmake_conf_file         \"${PROJECT_NAME_JOINED}-config.cmake\")\nset(cmake_conf_version_file \"${PROJECT_NAME_JOINED}-config-version.cmake\")\nset(cmake_targets_file      \"${PROJECT_NAME_JOINED}-targets.cmake\")\n\nset(targets_export_name \"${PROJECT_NAME_JOINED}-targets\")\nset(namespace \"${PACKAGE_NAME}::\")\n\n# Set up install directories. INCLUDE_INSTALL_DIR and\n# CMAKECONFIG_INSTALL_DIR must not be absolute paths.\nif(WIN32)\n    set(include_install_dir Include)\n    set(include_install_dir_full Include)\n    set(config_install_dir CMake)\nelseif(UNIX)\n    set(include_install_dir include)\n    set(include_install_dir_postfix \"${project_library_target_name}\")\n    set(include_install_dir_full    \"${include_install_dir}/${include_install_dir_postfix}\")\n\n    set(config_install_dir share/${PACKAGE_NAME})\nelse()\n    message(FATAL_ERROR \"Not supported system type. Options: UNIX or WIN32.\")\nendif()\n\n# configure the library target\ntarget_include_directories(\n    ${project_library_target_name} INTERFACE\n    $<BUILD_INTERFACE:${PROJECT_SOURCE_DIR}>\n    $<INSTALL_INTERFACE:${include_install_dir_full}>)\n\n# uninstall target\nconfigure_file(\n    \"${CMAKE_CURRENT_SOURCE_DIR}/cmake/Templates/cmake-uninstall.cmake.in\"\n    \"${CMAKE_CURRENT_BINARY_DIR}/cmake-uninstall.cmake\"\n    IMMEDIATE @ONLY)\n\nadd_custom_target(uninstall\n    COMMAND ${CMAKE_COMMAND} -P ${CMAKE_CURRENT_BINARY_DIR}/cmake-uninstall.cmake)\n\ninclude(CMakePackageConfigHelpers)\nconfigure_package_config_file(\n    \"${CMAKE_CURRENT_SOURCE_DIR}/cmake/Templates/${cmake_conf_file}.in\"\n    \"${CMAKE_CURRENT_BINARY_DIR}/${cmake_conf_file}\"\n    PATH_VARS include_install_dir_full\n    INSTALL_DESTINATION ${config_install_dir})\n\nwrite_basic_package_version_file(\n    ${CMAKE_CURRENT_BINARY_DIR}/${cmake_conf_version_file}\n    VERSION ${PROJECT_VERSION}\n    COMPATIBILITY SameMajorVersion)\n\nset(CMAKE_CXX_FLAGS         \"${CMAKE_CXX_FLAGS} ${EXTRA_C_FLAGS}\")\n# Create *-targets.cmake file for build directory\ninstall(TARGETS ${project_library_target_name}\n        EXPORT  ${targets_export_name}\n        INCLUDES DESTINATION ${include_install_dir})\n\nexport(EXPORT ${targets_export_name}\n       FILE   ${CMAKE_CURRENT_BINARY_DIR}/${cmake_targets_file})\n\n# Install *-targets.cmake file\ninstall(EXPORT      ${targets_export_name}\n        NAMESPACE   ${namespace}\n        DESTINATION ${config_install_dir})\n\n# Install config files\ninstall(FILES\n    \"${CMAKE_CURRENT_BINARY_DIR}/${cmake_conf_file}\"\n    \"${CMAKE_CURRENT_BINARY_DIR}/${cmake_conf_version_file}\"\n    \"${PROJECT_SOURCE_DIR}/cmake/Modules/FindTBB.cmake\"\n    \"${PROJECT_SOURCE_DIR}/cmake/Modules/FindNNPACK.cmake\"\n    \"${PROJECT_SOURCE_DIR}/cmake/Modules/FindINTELMKL.cmake\"\n    DESTINATION ${config_install_dir} COMPONENT cmake)\n\n# Install headers\ninstall(DIRECTORY   ${PROJECT_SOURCE_DIR}/${project_library_target_name}\n        DESTINATION ${include_install_dir})\n\n# Check if protobuf available\ninclude(cmake/protoc.cmake)\n\n# Subdirectories for examples, testing and documentation\n# TODO: explain in brief about different examples, test and docs.\nif(BUILD_EXAMPLES)\n    add_subdirectory(examples)\nendif(BUILD_EXAMPLES)\n\nif(BUILD_TESTS)\n    add_subdirectory(test)\nendif(BUILD_TESTS)\n\nif(BUILD_DOCS)\n    add_subdirectory(docs)\nendif(BUILD_DOCS)\n\nif(BUILD_BENCHMARKS)\n    add_subdirectory(benchmarks)\nendif(BUILD_BENCHMARKS)\n\n####\n# Configuration summary\ninclude(cmake/summary.cmake)\ntinydnn_print_configuration_summary()\n\n\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 2.8935546875,
          "content": "How to contribute\n========\n\nThanks for taking the time to contribute to tiny-dnn! The following are a few guidelines for contributors.\nThese are just guidelines, not rules, and feel free to propose changes to this document in a pull request.\n\n## Getting Started\n- Make sure you have a C++11 compiler.\n- Make sure you have a GitHub account.\n- Register a report about your issue.\n    - Check [the issue list](https://github.com/tiny-dnn/tiny-dnn/issues) to see if the problem has already been reported.\n    - This can be skipped if the issue is trivial (fixing a typo, etc).\n\n## Making Changes\n- Create a topic branch where you want to base your work.\n    - This is usually the ```master``` branch.\n- Make commits.\n- Make sure you have added the necessary tests for your changes.\n- Make sure you're sticking with our code style. You can run [`clang-format`](http://clang.llvm.org/docs/ClangFormat.html) manually or by using [pre-commit hook](https://github.com/arraiy/dacron/blob/master/etc/git/hooks/pre-commit). Currently `clang-format-4.0` is used.\n- Submit a pull request.\n- Make sure all CI builds are passed.\n\n## Coding guides\n- Keep header-only\n- Keep dependency-free\n    - If your change requires 3rd party libraries, this should be __optional__ in tiny-dnn.\n    Please guard your 3rd party dependent code by ```#ifdef - #endif``` block, and write CMakelist option to enable the block - \n    but lesser these switches, the better.\n- Keep platform-independent\n    - Use C++ standard library instead of Windows/POSIX dependent API\n    - CPU/GPU optimized code should be extracted as a separated file, and should be guarded as preprocessor macro.\n\n### Preferred coding style \n- Use [Google coding style guide](https://google.github.io/styleguide/cppguide.html) with some exceptions:\n    - Use ```CNN_NAME_OF_THE_MACRO``` style for preprocessor macros.   \n    - Use ```snake_case``` for rest of identifiers.\n    - [\"We do not use C++ exceptions\"](https://google.github.io/styleguide/cppguide.html#Exceptions) - We are using exceptions which throw ```tiny_dnn::nn_error``` or its subclass to keep error handling simple.\n    - [\"Avoid using Run Time Type Information (RTTI)\"](https://google.github.io/styleguide/cppguide.html#Run-Time_Type_Information__RTTI_) - We are using RTTI for serialization/deserialization.\n    - [\"All parameters passed by reference must be labeled const\"](https://google.github.io/styleguide/cppguide.html#Reference_Arguments) - We sometimes use non-const reference to 1) avoid null-pointer dereference, or 2) keep code clean (especially when overloading ```operator << (std::ostream&,T)```.\n    - [\"All header files should have #define guards to prevent multiple inclusion\"](https://google.github.io/styleguide/cppguide.html#The__define_Guard) - We are using ```#pragma once``` because include guards are error-prone. It is implementation defined, but many compilers [support it](https://en.wikipedia.org/wiki/Pragma_once#Portability).\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.763671875,
          "content": "COPYRIGHT\n\nAll contributions by Taiga Nomi\nCopyright (c) 2013, Taiga Nomi\nAll rights reserved.\n\nAll other contributions:\nCopyright (c) 2013-2016, the respective contributors.\nAll rights reserved.\n\nEach contributor holds copyright over their respective contributions.\nThe project versioning (Git) records all such contribution source information.\n\nLICENSE\n\nThe BSD 3-Clause License\n\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n* Neither the name of tiny-dnn nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 10.17578125,
          "content": "<div align=\"center\">\n  <img src=\"https://github.com/tiny-dnn/tiny-dnn/blob/master/docs/logo/TinyDNN-logo-letters-alpha-version.png\"><br><br>\n</div>\n\n-----------------\n\n[![Maintainers Wanted](https://img.shields.io/badge/maintainers-wanted-red.svg)](https://github.com/pickhardt/maintainers-wanted)\n\n## The project may be abandoned since the maintainer(s) are just looking to move on. In the case anyone is interested in continuing the project, let us know so that we can discuss next steps.\n## Please visit: https://groups.google.com/forum/#!forum/tiny-dnn-dev\n\n-----------------\n\n[![Join the chat at https://gitter.im/tiny-dnn/users](https://badges.gitter.im/tiny-dnn/users.svg)](https://gitter.im/tiny-dnn/users) [![Docs](https://img.shields.io/badge/docs-latest-blue.svg)](http://tiny-dnn.readthedocs.io/) [![License](https://img.shields.io/badge/license-BSD--3--Clause-blue.svg)](https://raw.githubusercontent.com/tiny-dnn/tiny-dnn/master/LICENSE) [![Coverage Status](https://coveralls.io/repos/github/tiny-dnn/tiny-dnn/badge.svg?branch=master)](https://coveralls.io/github/tiny-dnn/tiny-dnn?branch=master)\n\n**tiny-dnn** is a C++14 implementation of deep learning. It is suitable for deep learning on limited computational resource, embedded systems and IoT devices.\n\n| **`Linux/Mac OS`** | **`Windows`** |\n|------------------|-------------|\n|[![Build Status](https://travis-ci.org/tiny-dnn/tiny-dnn.svg?branch=master)](https://travis-ci.org/tiny-dnn/tiny-dnn)|[![Build status](https://ci.appveyor.com/api/projects/status/a5syoifm8ct7b4l2?svg=true)](https://ci.appveyor.com/project/tinydnn/tiny-dnn)|\n\n## Table of contents\n\n* [Features](#features)\n* [Comparison with other libraries](#comparison-with-other-libraries)\n* [Supported networks](#supported-networks)\n* [Dependencies](#dependencies)\n* [Build](#build)\n* [Examples](#examples)\n* [Contributing](#contributing)\n* [References](#references)\n* [License](#license)\n* [Gitter rooms](#gitter-rooms)\n\nCheck out the [documentation](http://tiny-dnn.readthedocs.io/) for more info.\n\n## What's New\n- 2016/11/30 [v1.0.0a3 is released!](https://github.com/tiny-dnn/tiny-dnn/tree/v1.0.0a3)\n- 2016/9/14 [tiny-dnn v1.0.0alpha is released!](https://github.com/tiny-dnn/tiny-dnn/releases/tag/v1.0.0a)\n- 2016/8/7  tiny-dnn is now moved to organization account, and renamed into tiny-dnn :)\n- 2016/7/27 [tiny-dnn v0.1.1 released!](https://github.com/tiny-dnn/tiny-dnn/releases/tag/v0.1.1)\n\n## Features\n- Reasonably fast, without GPU:\n    - With TBB threading and SSE/AVX vectorization.\n    - 98.8% accuracy on MNIST in 13 minutes training (@Core i7-3520M).\n- Portable & header-only:\n    - Runs anywhere as long as you have a compiler which supports C++14.\n    - Just include tiny_dnn.h and write your model in C++. There is nothing to install.\n- Easy to integrate with real applications:\n    - No output to stdout/stderr.\n    - A constant throughput (simple parallelization model, no garbage collection).\n    - Works without throwing an exception.\n    - [Can import caffe's model](https://github.com/tiny-dnn/tiny-dnn/tree/master/examples/caffe_converter).\n- Simply implemented:\n    - A good library for learning neural networks.\n\n## Comparison with other libraries\n\nPlease see [wiki page](https://github.com/tiny-dnn/tiny-dnn/wiki/Comparison-with-other-libraries).\n\n## Supported networks\n### layer-types\n- core\n    - fully connected\n    - dropout\n    - linear operation\n    - zero padding\n    - power\n- convolution\n    - convolutional\n    - average pooling\n    - max pooling\n    - deconvolutional\n    - average unpooling\n\t- max unpooling\n- normalization\n    - contrast normalization (only forward pass)\n    - batch normalization\n- split/merge\n    - concat\n    - slice\n    - elementwise-add\n\n### activation functions\n* tanh\n* asinh\n* sigmoid\n* softmax\n* softplus\n* softsign\n* rectified linear(relu)\n* leaky relu\n* identity\n* scaled tanh\n* exponential linear units(elu)\n* scaled exponential linear units (selu)\n\n### loss functions\n* cross-entropy\n* mean squared error\n* mean absolute error\n* mean absolute error with epsilon range\n\n### optimization algorithms\n* stochastic gradient descent (with/without L2 normalization)\n* momentum and Nesterov momentum\n* adagrad\n* rmsprop\n* adam\n* adamax\n\n## Dependencies\nNothing. All you need is a C++14 compiler (gcc 4.9+, clang 3.6+ or VS 2015+).\n\n## Build\ntiny-dnn is header-only, so *there's nothing to build*. If you want to execute sample program or unit tests, you need to install [cmake](https://cmake.org/) and type the following commands:\n\n```\ncmake . -DBUILD_EXAMPLES=ON\nmake\n```\n\nThen change to `examples` directory and run executable files.\n\nIf you would like to use IDE like Visual Studio or Xcode, you can also use cmake to generate corresponding files:\n\n```\ncmake . -G \"Xcode\"            # for Xcode users\ncmake . -G \"NMake Makefiles\"  # for Windows Visual Studio users\n```\n\nThen open .sln file in visual studio and build(on windows/msvc), or type ```make``` command(on linux/mac/windows-mingw).\n\nSome cmake options are available:\n\n|options|description|default|additional requirements to use|\n|-----|-----|----|----|\n|USE_TBB|Use [Intel TBB](https://www.threadingbuildingblocks.org/) for parallelization|OFF<sup>1</sup>|[Intel TBB](https://www.threadingbuildingblocks.org/)|\n|USE_OMP|Use OpenMP for parallelization|OFF<sup>1</sup>|[OpenMP Compiler](http://openmp.org/wp/openmp-compilers/)|\n|USE_SSE|Use Intel SSE instruction set|ON|Intel CPU which supports SSE|\n|USE_AVX|Use Intel AVX instruction set|ON|Intel CPU which supports AVX|\n|USE_AVX2|Build tiny-dnn with AVX2 library support|OFF|Intel CPU which supports AVX2|\n|USE_NNPACK|Use NNPACK for convolution operation|OFF|[Acceleration package for neural networks on multi-core CPUs](https://github.com/Maratyszcza/NNPACK)|\n|USE_OPENCL|Enable/Disable OpenCL support (experimental)|OFF|[The open standard for parallel programming of heterogeneous systems](https://www.khronos.org/opencl/)|\n|USE_LIBDNN|Use Greentea LibDNN for convolution operation with GPU via OpenCL (experimental)|OFF|[An universal convolution implementation supporting CUDA and OpenCL](https://github.com/naibaf7/libdnn)|\n|USE_SERIALIZER|Enable model serialization|ON<sup>2</sup>|-|\n|USE_DOUBLE|Use double precision computations instead of single precision|OFF|-|\n|USE_ASAN|Use Address Sanitizer|OFF|clang or gcc compiler|\n|USE_IMAGE_API|Enable Image API support|ON|-|\n|USE_GEMMLOWP|Enable gemmlowp support|OFF|-|\n|BUILD_TESTS|Build unit tests|OFF<sup>3</sup>|-|\n|BUILD_EXAMPLES|Build example projects|OFF|-|\n|BUILD_DOCS|Build documentation|OFF|[Doxygen](http://www.doxygen.org/)|\n|PROFILE|Build unit tests|OFF|gprof|\n\n<sup>1</sup> tiny-dnn use C++14 standard library for parallelization by default.\n\n<sup>2</sup> If you don't use serialization, you can switch off to speedup compilation time.\n\n<sup>3</sup> tiny-dnn uses [Google Test](https://github.com/google/googletest) as default framework to run unit tests. No pre-installation required, it's  automatically downloaded during CMake configuration.\n\nFor example, type the following commands if you want to use Intel TBB and build tests:\n```bash\ncmake -DUSE_TBB=ON -DBUILD_TESTS=ON .\n```\n\n## Customize configurations\nYou can edit include/config.h to customize default behavior.\n\n## Examples\nConstruct convolutional neural networks\n\n```cpp\n#include \"tiny_dnn/tiny_dnn.h\"\nusing namespace tiny_dnn;\nusing namespace tiny_dnn::activation;\nusing namespace tiny_dnn::layers;\n\nvoid construct_cnn() {\n    using namespace tiny_dnn;\n\n    network<sequential> net;\n\n    // add layers\n    net << conv(32, 32, 5, 1, 6) << tanh()  // in:32x32x1, 5x5conv, 6fmaps\n        << ave_pool(28, 28, 6, 2) << tanh() // in:28x28x6, 2x2pooling\n        << fc(14 * 14 * 6, 120) << tanh()   // in:14x14x6, out:120\n        << fc(120, 10);                     // in:120,     out:10\n\n    assert(net.in_data_size() == 32 * 32);\n    assert(net.out_data_size() == 10);\n\n    // load MNIST dataset\n    std::vector<label_t> train_labels;\n    std::vector<vec_t> train_images;\n\n    parse_mnist_labels(\"train-labels.idx1-ubyte\", &train_labels);\n    parse_mnist_images(\"train-images.idx3-ubyte\", &train_images, -1.0, 1.0, 2, 2);\n\n    // declare optimization algorithm\n    adagrad optimizer;\n\n    // train (50-epoch, 30-minibatch)\n    net.train<mse, adagrad>(optimizer, train_images, train_labels, 30, 50);\n\n    // save\n    net.save(\"net\");\n\n    // load\n    // network<sequential> net2;\n    // net2.load(\"net\");\n}\n```\nConstruct multi-layer perceptron (mlp)\n\n```cpp\n#include \"tiny_dnn/tiny_dnn.h\"\nusing namespace tiny_dnn;\nusing namespace tiny_dnn::activation;\nusing namespace tiny_dnn::layers;\n\nvoid construct_mlp() {\n    network<sequential> net;\n\n    net << fc(32 * 32, 300) << sigmoid() << fc(300, 10);\n\n    assert(net.in_data_size() == 32 * 32);\n    assert(net.out_data_size() == 10);\n}\n```\n\nAnother way to construct mlp\n\n```cpp\n#include \"tiny_dnn/tiny_dnn.h\"\nusing namespace tiny_dnn;\nusing namespace tiny_dnn::activation;\n\nvoid construct_mlp() {\n    auto mynet = make_mlp<tanh>({ 32 * 32, 300, 10 });\n\n    assert(mynet.in_data_size() == 32 * 32);\n    assert(mynet.out_data_size() == 10);\n}\n```\n\nFor more samples, read examples/main.cpp or [MNIST example](https://github.com/tiny-dnn/tiny-dnn/tree/master/examples/mnist) page.\n\n## Contributing\nSince deep learning community is rapidly growing, we'd love to get contributions from you to accelerate tiny-dnn development!\nFor a quick guide to contributing, take a look at the [Contribution Documents](CONTRIBUTING.md).\n\n## References\n[1] Y. Bengio, [Practical Recommendations for Gradient-Based Training of Deep Architectures.](http://arxiv.org/pdf/1206.5533v2.pdf)\n    arXiv:1206.5533v2, 2012\n\n[2] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, [Gradient-based learning applied to document recognition.](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)\n    Proceedings of the IEEE, 86, 2278-2324.\n\nOther useful reference lists:\n- [UFLDL Recommended Readings](http://deeplearning.stanford.edu/wiki/index.php/UFLDL_Recommended_Readings)\n- [deeplearning.net reading list](http://deeplearning.net/reading-list/)\n\n## License\nThe BSD 3-Clause License\n\n## Gitter rooms\nWe have gitter rooms for discussing new features & QA.\nFeel free to join us!\n\n<table>\n<tr>\n    <td><b> developers </b></td>\n    <td> https://gitter.im/tiny-dnn/developers </td>\n</tr>\n<tr>\n    <td><b> users </b></td>\n    <td> https://gitter.im/tiny-dnn/users </td>\n</tr>\n</table>\n"
        },
        {
          "name": "appveyor.yml",
          "type": "blob",
          "size": 1.13671875,
          "content": "init:\n- ps: iex ((new-object net.webclient).DownloadString('https://raw.githubusercontent.com/appveyor/ci/master/scripts/enable-rdp.ps1'))\n\nenvironment:\n  home: C:\\projects\n  cmake: C:\\projects\\cmake-3.4.1-win32-x86\\bin\\cmake.exe\n  matrix:\n  - generator : Visual Studio 14\n  - generator : Visual Studio 14 Win64\n\nversion: '{branch}-{build}'\n\nos: Visual Studio 2015\n\nbranches:\n  only:\n    - master\n    - feat/xtensor_integration\n\ninstall:\n  # Clone submodule\n  - git submodule update --init --recursive\n  # Get a recent CMake:\n  - cmd: cd %home%\n  - ps: wget https://cmake.org/files/v3.4/cmake-3.4.1-win32-x86.zip -OutFile cmake.zip\n  - cmd: 7z x cmake.zip -o\"C:\\projects\" -y > nul # will extract to cmake-3.4.1-win32-x86\\\n  - cmd: '%cmake% --version'\n\n# gradient-check test is too slow to execute on debug mode\nconfiguration: Release\n\nbefore_build:\n  - cmd: mkdir build\n  - cmd: cd build\n  - cmd: '%cmake% -G \"%generator%\" -DUSE_SSE=ON -DBUILD_TESTS=ON -DBUILD_EXAMPLES=ON -DCMAKE_INSTALL_PREFIX=..\\install ..\\tiny-dnn'\n\nafter_build:\n  - cmd: 'cd C:\\projects\\build\\test\\Release'\n  - cmd: tiny_dnn_test.exe\n\nbuild_script:\n  - msbuild C:\\projects\\build\\tiny_dnn.sln\n"
        },
        {
          "name": "benchmarks",
          "type": "tree",
          "content": null
        },
        {
          "name": "cereal",
          "type": "tree",
          "content": null
        },
        {
          "name": "cmake",
          "type": "tree",
          "content": null
        },
        {
          "name": "data",
          "type": "tree",
          "content": null
        },
        {
          "name": "dev-env.sh",
          "type": "blob",
          "size": 0.5400390625,
          "content": "#!/bin/bash\n\nscript_link=\"${BASH_SOURCE[0]}\"\nwhile [ -h \"$script_link\" ]; do # resolve $script_link until the file is no longer a symlink\n  lib_dir=\"$( cd -P \"$( dirname \"$script_link\" )\" && pwd )\"\n  script_link=\"$(readlink \"$script_link\")\"\n  [[ $script_link != /* ]] && script_link=\"$lib_dir/$script_link\" # if $script_link was a relative symlink, we need to resolve it relative to the path where the symlink file was located\ndone\nlib_dir=\"$( cd -P \"$( dirname \"$script_link\" )\" && pwd )\"\n\ndocker run --rm -it -v $lib_dir:/opt/tiny-dnn tinydnn/tinydnn\n"
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "third_party",
          "type": "tree",
          "content": null
        },
        {
          "name": "tiny_dnn",
          "type": "tree",
          "content": null
        },
        {
          "name": "vc",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}