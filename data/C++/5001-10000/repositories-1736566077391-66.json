{
  "metadata": {
    "timestamp": 1736566077391,
    "page": 66,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjcw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "Ewenwan/MVision",
      "stars": 8119,
      "defaultBranch": "master",
      "files": [
        {
          "name": "3D_Object_Detection",
          "type": "tree",
          "content": null
        },
        {
          "name": "CNN",
          "type": "tree",
          "content": null
        },
        {
          "name": "Character",
          "type": "tree",
          "content": null
        },
        {
          "name": "GNN",
          "type": "tree",
          "content": null
        },
        {
          "name": "GUI",
          "type": "tree",
          "content": null
        },
        {
          "name": "LSLAM",
          "type": "tree",
          "content": null
        },
        {
          "name": "MXnet",
          "type": "tree",
          "content": null
        },
        {
          "name": "OpenGV",
          "type": "tree",
          "content": null
        },
        {
          "name": "OpenHPC",
          "type": "tree",
          "content": null
        },
        {
          "name": "PCL_APP",
          "type": "tree",
          "content": null
        },
        {
          "name": "Python_Machine_Learning",
          "type": "tree",
          "content": null
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 35.3505859375,
          "content": "# MVision　Machine Vision 机器视觉\n[AI算法工程师手册 数学基础 统计学习 深度学习 自然语言处理 工具使用](http://www.huaxiaozhuan.com/)\n\n[AI 安全数据科学和算法 ](https://github.com/Ewenwan/AI-Security-Learning)\n\n[澳大利亚机器人视觉研究中心](https://www.roboticvision.org/)\n\n[NIPS Neural Information Processing Systems](https://papers.nips.cc/)\n\n[icml Proceedings of Machine Learning Research PMLR](http://proceedings.mlr.press/index.html)\n\n[ICDM IEEE International Conference on Data Mining](http://www.cs.uvm.edu/~icdm/)\n\n[Computer Vision and Pattern Recognition arxiv.org 最新提交的论文](https://arxiv.org/list/cs.CV/recent)\n\n[papercept 会议论文投递](https://controls.papercept.net/conferences/scripts/start.pl)\n\n[easychair 会议论文投递](https://easychair.org/my/roles.cgi?welcome=1)\n\n[DBLP 计算机核心技术文献](https://dblp.uni-trier.de/)\n\n[技术刘 增强现实、图像识别、深度学习、机器人](http://liuxiao.org/category/robots/)\n\n[漫谈 SLAM 技术（上）](https://cloud.tencent.com/developer/article/1005894)\n\n[漫谈 SLAM 技术（下）](https://cloud.tencent.com/developer/article/1005893)\n\n[优秀的博客论文笔记](https://github.com/Ewenwan/antkillerfarm.github.com)\n\n[CSCI 1430: Introduction to Computer Vision 计算机视觉课程](http://cs.brown.edu/courses/csci1430/#schedule)\n\n[计算机视觉和算法 书籍](http://szeliski.org/Book/drafts/SzeliskiBook_20100903_draft.pdf)\n\n[Computer vision:models, learning and inference 书籍](http://web4.cs.ucl.ac.uk/staff/s.prince/book/book.pdf)\n\n[TLD：tracking-learning-detection 跟踪算法](https://github.com/Ewenwan/opencv_TLD)\n\n[机器人选修课](http://www.diag.uniroma1.it/%7Elanari/EIR/)\n\n[Andrew Davison的课程： Robotics Lecture Course (course code 333)](http://www.doc.ic.ac.uk/~ajd/Robotics/index.html)\n\n[Simultaneous Localization and Mapping: Part I ](http://www.doc.ic.ac.uk/~ajd/Robotics/RoboticsResources/SLAMTutorial1.pdf)\n\n[Simultaneous Localization and Mapping: Part II ](http://www.doc.ic.ac.uk/~ajd/Robotics/RoboticsResources/SLAMTutorial2.pdf)\n\n[瑞士苏黎世理工的学生练习](http://www.csc.kth.se/~kootstra/index.php?item=313&menu=300)\n\n[书籍 Robotics, Vision & Control 推荐！！！！](http://petercorke.com/wordpress/)\n\n[Robotics, Vision & Control.PDF 百度网盘](https://pan.baidu.com/s/1c1TcEgo)\n\n[Robotics, Vision and Control csdn](https://download.csdn.net/download/u013834525/10169878)\n\n[优达学城 机器人人工智能课程](https://classroom.udacity.com/courses/cs373)\n\n[学习无人驾驶车，你所必须知道的](https://zhuanlan.zhihu.com/p/27686577)\n\n[强化学习从入门到放弃的资料](https://zhuanlan.zhihu.com/p/34918639?utm_source=wechat_session&utm_medium=social&wechatShare=1&from=singlemessage&isappinstalled=0)\n\n[台大 机器学习深度学习课程](http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLSD15_2.html)\n\n[斯坦福CS231计算机视觉2017](http://www.mooc.ai/course/268/learn?lessonid=1819#lesson/1819)\n\n[深度学习程序示例 cs231n等](https://github.com/autoliuweijie/DeepLearning)\n\n[2018 MIT 6.S094 麻省理工深度学习和自动驾驶课程 中文](http://www.mooc.ai/course/483/notes)\n\n[MIT  深度学习和自动驾驶课程 英文](https://selfdrivingcars.mit.edu/)\n\n[DeepTraffic](https://selfdrivingcars.mit.edu/deeptraffic/)\n\n[SegFuse: Dynamic Driving Scene Segmentation](https://selfdrivingcars.mit.edu/segfuse/)\n\n[DeepTesla - End-to-End Steering Model](https://selfdrivingcars.mit.edu/deeptesla/)\n\n[中文slam首页](http://www.slamcn.org/index.php/%E9%A6%96%E9%A1%B5)\n\n[ORB-LSD-SVO比较-刘浩敏_bilibili](https://www.bilibili.com/video/av5934066/)\n\n[LSD算法代码解析](http://www.cnblogs.com/shhu1993/p/7136033.html)\n\n[SVO算法代码解析](http://www.cnblogs.com/shhu1993/p/7135847.html)\n\n[DSO 半闲居士 解析](https://zhuanlan.zhihu.com/p/29177540)\n\n[路径规划A*算法及SLAM自主地图创建导航算法](http://www.voidcn.com/article/p-yfjpnwte-tz.html)\n\n[冯兵的blog slam](http://www.fengbing.net)\n\n[imu和单目的数据融合开源代码（EKF)](https://github.com/ethz-asl/rovio)\n\n[imu和单目的数据融合开源代码(非线性优化）](https://github.com/ethz-asl/okvis_ros)\n\n[双目立体匹配](https://wenku.baidu.com/view/08f86102e518964bcf847c6c.html)\n\n[计算机视觉的一些库文件](https://blog.csdn.net/garfielder007/article/details/50533052)\n\n[人脸检测总结](https://blog.csdn.net/neu_chenguangq/article/details/52983093)\n\n[行为识别总结](https://blog.csdn.net/neu_chenguangq/article/details/79504214)\n\n[Free-SpaceEstimation 无障碍物空间估计 稠密地图 栅格地图 动态规划 高度分割 路面信息提取](http://www.cs.toronto.edu/~urtasun/courses/CSC2541/05_free_space.pdf)\n\n[2D Object Detection 2d目标检测 RCNN ](http://www.cs.toronto.edu/~urtasun/courses/CSC2541/05_2D_detection.pdf)\n\n[3D Object Detection 3D目标检测 动机](http://www.cs.toronto.edu/~urtasun/courses/CSC2541/06_3D_detection.pdf)\n\n[Semantic Segmentation 语义分割](http://www.cs.toronto.edu/~urtasun/courses/CSC2541/07_segmentation.pdf)\n\n[Instance-level Segmentation 实例分割](http://www.cs.toronto.edu/~urtasun/courses/CSC2541/08_instance.pdf)\n\n[Tracking 跟踪 ]()\n\n[Kalibr calibration toolbox 标定多目相机系统、相机 IMU 相 对 位 姿 和 卷 帘 快 门 相 机  ](https://github.com/Ewenwan/kalibr)\n\n[霍夫森林(Hough Forest) 随机森林和霍夫投票在计算机视觉中的应用，可以用在物体检测，跟踪和动作识别](https://github.com/Ewenwan/HoughForest)\n\n[百度自动驾驶开源框架 apollo](https://github.com/Ewenwan/apollo)\n\n[交通标志检测识别 数据集](https://cg.cs.tsinghua.edu.cn/traffic-sign/)\n\n[Halcon 使用参考](https://blog.csdn.net/maweifei/article/details/52613392)\n\n[有代码的论文](https://github.com/Ewenwan/pwc)\n\n[图像处理基本算法代码](http://www.cnblogs.com/Imageshop/p/3430742.html)\n\n# 感谢支持\n\n![](https://github.com/Ewenwan/EwenWan/blob/master/zf.jpg)\n\n# 无人驾驶的各个方面知识\n[参考](https://blog.csdn.net/qq_40027052/article/details/78485120)\n\n    1. 感知（Perception）：\n        主要涉及的技术点包括场景理解、交通状况分析、路面检测、空间检测、\n        障碍物检测、行人检测、路沿检测、车道检测。还有一个比较新颖有趣的是通过胎压去检测道路质量。\n        在无人驾驶行业，有一套通用的数据集——KITTI数据集，里面有不同的数据，包括双目视觉的数据、定位导航的数据等。\n        物体检测（Object Detection）：\n            传统方法主要是针对固定物体的检测。一般的方法是HOG（ 方向梯度直方图），然后再加一个SVM的分类器。\n            而对于动态物体的检测，主要使用的是DPM模型的方法，先把手和脚识别出来，再进行组合。\n            深度学习方法 RCNN YOLO\n       场景分割（Segmentation）  ：\n            人行道是一个场景，道路是一个场景，在场景中对不同的物体进行分类，是一个很重要的问题。\n            传统的方法是采用CRF（ 条件随机场），基本原理在于图像都是由像素点组成的，\n            若两个像素点都比较像车，那就把二者连接起来，形成对车辆的识别。\n\n            运用深度学习的方法则使用的是另一种模型，被称为PSPnet（语义分割）。\n            这是金字塔型的场景分解模型，将一个场景不断地压缩，把类似的物体聚类，然后再做判断。\n       双目 光流（Optical Flow）场景流（Scene Flow）：\n            光流是针对2D图像来说的，如果说一个图片流到另外一个图片，都是2D的物体移动，那就用光流来做。\n            如果是3D的物体流动，那我们就用场景流（Scene Flow），场景流在传统的方法就是使用的是SGBM，\n            利用的是双目成像的技术，把左图和右图合起来提取出空间的点，用光流在上面做，就能把场景的流动分析出来。\n\n            光流也可以利用深度学习的模型来做，把左右两图用同样的模型来提取特征，经过计算就能得出一个深度的信息。\n            但是这个方式的计算量非常大。\n\n       物体追踪（Object Tracking）：    \n            这也是无人驾驶中一个比较重要的技术。如何预测行人下一个动作、怎么去跟踪这个行人，也有一系列问题。\n            里面用到的是马尔可夫链的解决方案，这个技术叫做MDP，跟踪一个人，随时跟踪其下一个动作，预测其下一个动作。\n            以上其实都是一些传统的感知方法，而这些年随着深度学习的不断进步，应用也非常广泛。\n            \n    2. 运动规划（Motion Planning）：\n        主要涉及的技术点包括运动规划、轨迹规划、速度规划、运动模型。\n        比较有趣的一些进展包括通过赛车游戏去学习基于网格的运动规划，重量级货车的避障规划，普世的适用于无人驾驶的双轮模型等等。\n\n    3. 防碰撞（CollisionAvoidance）：\n        主要涉及如何通过车内的感知系统以及V2X 系统去辅助防碰撞。\n        比较有趣的一些进展包括如何实时地去评估当前驾驶行为的危险性，如何通过当前道路的拓扑去增强自行车骑士的安全性等等。\n\n    4. 地图与定位（Mapping andLocalization）：\n        主要涉及如何通过不同的传感器，包括激光雷达、视觉、GNSS，以及 V2X 去建图与定位。\n        比较有趣的一些进展包括如何在一些特殊的场景去定位，比如在长隧道里面，既没有 GNSS 信号，也没有太好的激光或者视觉特征的时候如何定位。\n\n    5. 合作系统（CooperativeSystems）：\n        主要涉及如何协同多个无人车去完成一些任务，比如在多个无人车同时在一个十字路口出现时如何调度，\n        还有就是当有多个无人车同时在停车场试如何有序的停车。\n\n    6. 控制策略（Control Strategy）：\n        主要研究在不同的细分场景下的控制策略，比如在十字路口如何控制，转线如何控制，在感知数据不可靠时如何尽量安全的控制等等。\n\n    7. 车辆检测与跟踪（VehicleDetection and Tracking）：\n        主要关注如何通过激光雷达、视觉，以及毫米波雷达进行车辆检测与跟踪。\n        比较有趣的工作包括通过深度学习与深度视觉的结合进行车辆跟踪，\n        通过单目视觉深度学习去尽量估计车体大小，通过传统视觉边缘检测方法去判断是否车体等等。\n\n    8. 静态物体检测（Static ObjectDetection）：\n        主要涉及通过视觉以及激光雷达去检测一些静态的物体，\n        包括交通灯、交通指示牌、路沿、路面等等，每个物体品类的检测都是一个细分方向。\n\n    9. 动态物体检测（Moving ObjectDetection）：\n        主要涉及通过视觉、激光雷达、毫米波雷达，以及传感器融合的方法去检测一些动态的物体，\n        包括行人、车辆、自行车骑士等等，并根据这些动态物体的动作去预测行为。\n\n    10. 道路与路口检测（Road andIntersection Detection）：\n        道路与路口检测由于其特殊性以及对安全的影响，被单独列出作为一个细分的小方向。\n        研究的前沿一般涉及一些细分场景，比如建筑工地的检测、停车位的检测等等。\n\n    11. 决策系统（Planning andDecision）：\n        主要涉及每个无人车的动作的决策，比如加速、刹车、换线、超车、调头等等。\n        研究的前沿一般涉及在高速行驶中如何安全的换线，在通过视觉理解了场景后如何决策，在感知信息缺失的时候（比如在隧道里面）如何决策等等。\n\n    12. 主动与被动安全（Active andPassive Safety）：\n        主要涉及如何通过不同传感器的感知去确保无人驾驶以及行人安全，\n        比较有趣的一些研究包括通过对 CAN 总线的异常检测去评估车辆的安全性，通过对停车场的视频监控去训练自动泊车模型等等。\n\n    13. 无人车与交通的交互（AutonomousVehicles: Interaction with Traffic）：\n        主要研究无人车如何与现有的交通生态共存，特别是传统车与无人车的共存。\n        比较有趣的一些研究包括 V2X 虚拟交通标志，通过视觉去评估旁边车道司机的驾驶行为等等。\n\n    14. 视觉定位（SLAM and VisualOdometry）：\n        主要研究如何用视觉与激光雷达进行实时定位与建图。\n        比较有趣的一些研究包括视觉的线上校准，使用车道线进行实时定位与导航等等。\n\n    15. 环境学习与建图（Mapping andLearning the Environment）：\n        主要研究如何建立精准的环境信息图。比较有趣的一些研究包括使用低空无人机去创建给无人驾驶使用的地图，\n        以及通过停车场监控摄像头建立辅助自动泊车的地图等等。\n\n## 无人驾驶面试知识点\n[参考博客](https://blog.csdn.net/xiangxianghehe/article/details/82528180)\n```\n1. 深度学习相关\n    机器学习和深度学习的区别，各自适用于什么问题\n    CNN基本原理，CNN的那些部分是神经元\n    CNN去掉激活函数会怎么样\n    介绍YOLO/SSD/RCNN/Faster-RCNN/Mask-RCNN算法\n    YOLO v1/v2/v3 区别细节，SSD如何改进有思考过嘛，知道DSSD和FSSD嘛\n    是否了解RPN，RoI pooling,和RoIAlign\n    YOLO/SSD里面有全连接层嘛\n    YOLO/SSD算法思想如何用到三维点云目标检测\n    目标检测算法one-stage和two-stage区别点在哪里\n    two-stage算法相比于one-stage有何优势\n    单张图片物体越多越密集，YOLO/SSD/Faster-RCNN中计算量是否也随着增加\n    CVPR/ECCV 2018 最新目标检测算法有了解过嘛\n    如何理解上采样，和下采样的区别是什么\n    上采样(UNSampling)与上池化(UnPooling)区别\n    全连接层理论上可以替代卷积层嘛\n    神经网络里面可以用什么方法替换掉pooling\n    神经网络提取特征的方式有哪些\n    介绍下你了解的轻量级CNN模型\n    网络模型压缩方面的剪枝，量化和二值化编码\n    基于视频的C3D三维网络模型有听说过嘛\n    2.5D卷积呢\n    什么是空洞卷积，什么是反卷积，作用是什么\n    如何一张RGB图片生成三维模型\n    PNG/JPG存储图像的原理\n    global average pooling 和average pooling区别\n    FPN的原理，为什么不同尺度feature map融合会有效果提升\n    无监督/半监督深度学习有了解过嘛\n    GAN的原理\n    基于RGB图的深度信息估计有了解过嘛\n    MobileNet V1/V2区别\n    ShuffleNet和SqueezeNet\n    模型量化方法有哪些\n    双线性插值，量化对齐\n    Relu为什么比sigmod好\n    目标识别算法常用评测方式\n    IOU和mAP，AUC和ROC分别是什么\n    介绍下常见损失函数，softmax一般和哪个激活函数使用\n    介绍下PointNet/PointNet++/VoxelNet以及他们的优缺点\n    PointCNN介绍一下\n    旋转矩阵是什么，有什么性质，PointNet中T-Net旋转矩阵的损失函数如何设计\n    如何计算旋转矩阵\n    介绍下机器学习和深度学习中常见的参数类算法和非参数类算法\n    随机梯度下降\n    神经网络训练如何解决过拟合和欠拟合\n    L1正则化和L2正则化区别，具体有何用途\n    L1正则化相比于 L2正则化为何具有稀疏解\n    \n2. C++开发相关\n    c++常见容器，vector容器capacity和size区别，如何动态增长\n    vector遍历有哪几种方式（尽可能多）\n    cv:Mat 有几种访问方式\n    map容器增删改查，和unorder_map区别，map底层如何实现\n    c++智能指针\n    c++14/17新特性\n    c++和c语言区别\n    c++如何实现多态，有几种方式，动态多态和静态多态区别\n    模板了解嘛\n    c++继承多态\n    c++深拷贝与浅拷贝\n    拷贝构造函数和委托构造函数\n    c++面向对象\n    右值引用，move语义，完美转发\n    emplace_back和push_back区别\n    Eigen库了解嘛\n    如何实现一个c++的单例模式\n    内联函数和宏的区别\n    如何实现一个只在堆或者栈上初始化的类\n    如何查找容器内所有符合条件的元素\n    \n3. Python开发相关\n    list tuple区别\n    生成器和迭代器\n    Python类的定义和实例化方法\n    \n4. 数据结构相关\n    红黑树结构，查找时间复杂度\n    堆排序的时间复杂度\n    Top K排序\n    如何用O(1)复杂度查找到stack里面的最小值\n    八皇后\n    C++自己实现一个队列\n    数组和链表的区别\n    什么是kd-tree，如何实现\n    青蛙跳台阶的递归和非递归实现\n    \n5. 操作系统相关\n    如何调试栈溢出\n    计算机内存堆和栈的区别\n    线程同步的方式，互斥锁和信号量的对比\n    进程和线程的区别\n    图片存储原理介绍一下\n    \n6. 深度学习框架相关\n    Tensorflow结构框架，如何用Tensorflow实现一个反向求梯度\n    Tensorflow如何合并两个Tensor\n    caffe和Pytorch了解嘛\n    caffe和Tensorflow区别在什么地方\n    Tensorflow serving和TensorRT有了解过嘛\n    caffe结构框架\n    \n7. 视觉SLAM相关\n    SLAM主要分为哪几个模块\n    ORB-SLAM2的优缺点分析，如何改进\n    ORB和FAST对比\n    BA和卡尔曼滤波\n    ORB-SLAM2的三个线程是什么\n    ORB-SLAM2的定位如何实现\n    如何理解ORB-SLAM2的图优化\n    结构光、TOF、双目视觉原理\n    直接法、半直接法、特征点法区别与联系\n    Apollo的感知模块原理\n    Apollo的2D和3D跟踪\n    如何求解旋转矩阵\n    如果只有32线雷达，个数不限，能实现360度视角覆盖吗，如何实现，64线呢？\n```\n\n##  公司\n[视觉领域的部分国内公司](http://www.ipcv.org/cvcom/)\n###  初创公司：\n[图普科技](http://www.tuputech.com/)---[Face++](http://www.faceplusplus.com.cn/)---[Linkface](http://www.linkface.cn/index.html)---[Minieye](http://www.minieye.cc/cn/)---[知图Cogtu](http://www.cogtu.com/?lang=zh)---[商汤科技Sensetime](http://www.sensetime.com/cn)---[亮风台Hiscene](http://www.hiscene.com/)---[掌赢科技](http://www.zhangying.mobi/index.html)---[格灵深瞳DeepPG](http://www.deepglint.com/)---[凌感科技usens](http://www.lagou.com/gongsi/j114187.html)---[图森TuSimple](http://www.tusimple.com/)---[中科视拓Seetatech(山世光)](http://www.seetatech.com/)---[第四范式](https://www.4paradigm.com/product/prophet)\n\n### 上市公司：\n[百度DL实验室](http://idl.baidu.com/)---[腾讯优图](http://youtu.qq.com/)---[阿里高德](http://www.newsmth.net/nForum/#!article/Career_Upgrade/429476)---[暴风魔镜](http://www.newsmth.net/nForum/#!article/Career_PHD/225254)---[搜狗](http://www.newsmth.net/nForum/#!article/Career_PHD/224449)---[乐视tv](http://www.newsmth.net/nForum/#!article/Career_PHD/222651)---[奇虎360](http://www.newsmth.net/nForum/#!article/Career_PHD/222379)---[京东实验室](http://www.newsmth.net/nForum/#!article/Career_PHD/223133/a>)---[阿里巴巴](http://www.newsmth.net/nForum/#!article/Career_PHD/222007)---[联想研究院](http://www.newsmth.net/nForum/#!article/Career_PHD/220225)---[华为研究院](http://www.newsmth.net/nForum/#!article/Career_PHD/225976)\n\n### 知名外企：\n[佳能信息](http://www.newsmth.net/nForum/#!article/Career_PHD/222548)---[索尼研究院](http://www.newsmth.net/nForum/#!article/Career_PHD/223437)---[富士通研发中心](http://www.newsmth.net/nForum/#!article/Career_PHD/220654)---[微软研究院](https://careers.microsoft.com/?rg=cn)---[英特尔研究院](http://www.newsmth.net/nForum/#!article/Career_PHD/221175)---[三星研究院](http://www.yingjiesheng.com/job-001-742-124.html)\n\n\n\n## 0 计算摄影　摄影几何\n[计算摄影方面的部分课程讲义](http://www.ipcv.org/cp-lecture/)\n[相机内部图像处理流程](http://www.comp.nus.edu.sg/~brown/ICIP2013_Brown.html)\n[pdf](http://www.comp.nus.edu.sg/~brown/ICIP2013_Tutorial_Brown.pdf)\n\n    相机 = 光测量装置(Camera = light-measuring device)\n        照明光源(Illumination source)（辐射(radiance)） --> \n        场景元素(Scene Element)   --->\n        成像系统(Imaging System)  --->\n        内部图像平面(Internal Image Plane) --->\n        输出（数字）图像(Output (digital) image) \n    图像 = 辐射能量测量(Image = radiant-energy measurement)  \n    \n    \n    现代摄影流水线　Modern photography pipeline \n    场景辐射　--->　相机前端(镜头过滤器 镜头Lens 快门Shutter 孔径)　--->　\n    相机内部(ccd响应response（RAW） CCD插值Demosaicing （原）)　--->　\n    相机后端处理(直方图均衡Hist equalization、空间扭曲Spatial warping)--->　输出\n    \n\n\n    透过棱镜的白光 　“White light” through a prism  ------> 折射光(Refracted light)----> 光谱 Spectral 　\n    我们的眼睛有三个受体（锥细胞），它们对可见光作出反应并产生颜色感。\n    \n[CSC320S: Introduction to Visual Computing 视觉计算导论 ](http://www.cs.toronto.edu/~kyros/courses/320/)\n\n[Facebook surround 360 《全景图拼接》](https://github.com/facebook/Surround360)\n\n        输入：17张raw图像，包括14张side images、2张top images、1张bottom image\n        输出：3D立体360度全景图像  \n[博客笔记](https://blog.csdn.net/electech6/article/details/53618965)   \n        \n\n[深度摄影风格转换 Deep Photo Style Transfer](https://github.com/luanfujun/deep-photo-styletransfer)\n\n### 图像形变 Image warping\n[参考](http://www.ipcv.org/image-warping/)\n### 色彩增强/转换　Color transfer\n[参考](http://www.ipcv.org/colortransfer/)\n### 图像修补 Image repair\n[参考](http://www.ipcv.org/imagerepair/)\n### 图像去噪 Image denoise\n[参考](http://www.ipcv.org/imagedenoise/)\n### 图像去模糊 Image deblur \n[参考](http://www.ipcv.org/imagedeblur/)\n###  图像滤波 Image filter\n[参考](http://www.ipcv.org/imagefilter/)\n\n###  超分辨率 Super-resolution\n[参考](http://www.ipcv.org/code-superresolution/)  \n\n\n## 1　三维重建 3D Modeling\n[参考](http://www.ipcv.org/category/code-data/3dd/)\n### 相机矫正　Camera calibration\n[参考](http://www.ipcv.org/poseestimation/)\n### 非刚体重建　Non-rigid modeling　\n[参考](http://www.ipcv.org/nonnigitreco/)\n### 三维重构 3D modeling\n[参考](http://www.ipcv.org/3dmodeling/)\n[视觉SLAM](http://www.ipcv.org/on-visual-slam/)\n\n[Self-augmented Convolutional Neural Networks](https://github.com/msraig/self-augmented-net)\n\n[运动估计 motion estimation](http://www.ipcv.org/on-motion-estimation/)\n\n[面部变形　face morphing　](http://www.ipcv.org/about-face-morphing/)\n\n[三维重建方面的视觉人物](http://www.ipcv.org/people-3d-modeling/)\n\n\n## 2  匹配/跟踪 Matching & Tracking\n[参考](http://www.ipcv.org/category/code-data/tracking/)\n\n### 2.a 特征提取 Feature extraction\n[参考](http://www.ipcv.org/featureextraction/)\n\n### 2.b 特征匹配 Feature matching\n[参考](http://www.ipcv.org/code-featmatching/)\n\n### 2.c 时空匹配 Space-time matching\n[参考](http://www.ipcv.org/code-spacetimematching/)\n\n### 2.d 区域匹配 Region matching\n[参考](http://www.ipcv.org/code-regionmatching/)\n\n### 2.e 轮廓匹配 Contour matching\n[参考](http://www.ipcv.org/code-coutourmatching/)\n\n### 2.f 立体匹配 Stereo matching \n[参考](http://www.ipcv.org/code-stereomatching/)\n\n[双目视觉自动驾 场景物体跟踪paper](http://www.cvlibs.net/publications/Menze2015CVPR.pdf)\n\n[kitti双目数据集解决方案](http://www.cvlibs.net/datasets/kitti/eval_scene_flow.php?benchmark=stereo)\n\n[将深度神经网络用于将2D电影转换为3D电影的转换](https://github.com/piiswrong/deep3d)\n\n[神经网络　双目匹配](https://github.com/jzbontar/mc-cnn)\n\n\n[中山大学张弛博士](http://chizhang.me/)\n\n    MeshStereo: A Global Stereo Model with Mesh Alignment Regularization for View Interpolation\n    1、讨论了立体视觉匹配（Stereo Matching）问题的定义及其与人眼感知深度的关系；\n    2、对Matching Cost Volume进行了可视化分析，以期望达到听者对其的直观且本质的理解；\n    3、讨论了立体视觉匹配问题中的四个经典方法（\n        Graph Cut，Adaptive Support Weight Aggregation, \n        Semi-Global Matching, \n        以及 PatchMatch Stereo）；\n    4、讨论了MeshStereo的试图统一disparity求解以及网格生成两个步骤的motivation，\n        以及formulate这样一个unified model会遇到的困难；\n    5、讨论了MeshStereo引入splitting probability的解决方案及其优化过程。\n    \n    Webinar最后展示了MeshStereo在深度估计以及新视角渲染两个任务中的结果。\n\n\n[Stereo Matching Using Tree Filtering non-local算法在双目立体匹配上的应用 ](https://blog.csdn.net/wsj998689aa/article/details/45584725)\n\n\n\n\n### 2.g 深度匹配 depth matching \n[深度匹配 depth matching ](http://www.ipcv.org/on-depth-matching/)\n\n### 2.h 姿态跟踪 Pose tracking \n[参考](http://www.ipcv.org/code-posetracking/)\n\n### 2.i 物体跟踪 Object tracking\n[参考](http://www.ipcv.org/code-objtracking/)\n\n### 2.j 群体分析 Crowd analysis\n[参考](http://www.ipcv.org/code-crowdanalysis/)\n[群体运动度量](https://github.com/metalbubble/collectiveness)\n\n### 2.k 光流场跟踪 Optical flow\n[参考](http://www.ipcv.org/code-opticalflow/)\n\n\n## 3 语义/实例分割&解析　Segmentation & Parsing\n[参考](http://www.ipcv.org/category/code-data/parsing/)\n### 3.a 视频分割  Video  segmentation\n[参考](http://www.ipcv.org/video-segmentation/)\n\n### 3.b 人体解析  Person parsing\n[参考](http://www.ipcv.org/code-poseparsing/)\n\n[person parsing](http://www.ipcv.org/about-person-parsing/)\n\n### 3.c 场景解析  Scene  parsing\n[scene parsing](http://www.ipcv.org/about-scene-parsing/)\n[参考](http://www.ipcv.org/code-sceneparsing/)\n\n### 3.d 边缘检测  Edge   detection\n[参考](http://www.ipcv.org/code-edgedetection/)\n[边缘检测](http://www.ipcv.org/on-edge-detection/)\n\n\n### 3.e 图像物体分割 Image object segmentation \n[参考](http://www.ipcv.org/code-imobjseg/)\n \n### 3.f 视频物体分割 Video object segmentation\n[参考](http://www.ipcv.org/code-viobseg/)\n[object segmentation](http://www.ipcv.org/about-video-object-segmentation/)\n\n\n### 3.g 交互式分割   Interactive segmentation\n[参考](http://www.ipcv.org/code-intseg/)\n\n### 3.h 共分割      Co-segmentation\n[参考](http://www.ipcv.org/code-cosegmentation/)\n\n### 3.i 背景差      Background subtraction \n[参考](http://www.ipcv.org/code-backsub/)\n\n### 3.j 图像分割方面 Image segmentation\n[参考](http://www.ipcv.org/code-imgseg/)\n \n\n## 4 识别/检测　Recognition & Detection\n[参考](http://www.ipcv.org/category/code-data/detect/)\n###  4.a 其他识别 Other recognition\n[参考](http://www.ipcv.org/otherrecog/)\n\n### 4.b 图像检索 Image retrieval\n[参考](http://www.ipcv.org/%e5%9b%be%e5%83%8f%e6%a3%80%e7%b4%a2/)\n\n### 4.c 显著检测 Saliency detection\n[参考](http://www.ipcv.org/saldetection/)\n\n### 4.d 通用物体检测 Object proposal\n[参考](http://www.ipcv.org/code-objproposal/)\n\n### 4.e 行为识别 Action recognition\n[参考](http://www.ipcv.org/code-actionrecogntion/)\n\n### 4.f 物体识别 Object recognition\n[参考](http://www.ipcv.org/code-objrecogntion/)\n\n### 4.g 行人检测 Human detection\n[参考](http://www.ipcv.org/code-humandetection/)\n\n### 4.h 人脸解析 Face Parsing\n[参考](http://www.ipcv.org/code-facerecog/)\n\n### 4.i 纹理分析 Texture Analysis\n[纹理分析 Texture Analysis](http://www.ipcv.org/on-texture-analysis/)\n[相关人物](http://www.ipcv.org/people-reidentity/)\n\n## 5 机器学习 Maching Learning\n[参考](http://www.ipcv.org/category/code-data/ml/)\n\n### 5.a 生成对抗网络 GAN Generative Adversarial Networks\n[参考](http://www.ipcv.org/adversarial-networks/)\n\n### 5.b 深度学习    Deep learning \n[参考](http://www.ipcv.org/deeplearning/)\n[深度学习方面的部分课程讲义](http://www.ipcv.org/lecture-deeplearning/)\n\n[CNN Models 卷积网络模型](http://www.ipcv.org/on-object-detection/)\n\n[Deep Learning Libraries　深度学习软件库](http://www.ipcv.org/deep_learning_libraries/)\n\n[深度学习方面的部分视觉人物](http://www.ipcv.org/dl-researcher/)\n\n### 5.c 能量优化    Energy optimization \n[参考](http://www.ipcv.org/energyopt/)\n\n### 5.d 模型设计    Model design\n[参考](http://www.ipcv.org/modelbuilding/)\n\n### 5.e 空间降维    Dimention reduction \n[参考](http://www.ipcv.org/dimention/)\n\n### 5.f 聚类       Clustering \n[参考](http://www.ipcv.org/clustering/)\n\n### 5.g 分类器     Classifier\n[参考](http://www.ipcv.org/classifier/)\n\n## 6 开源库　Open library\n[参考](http://www.ipcv.org/category/code-data/lib/)\n###\n###\n\n\n## 7 数据集　Public dataset\n[参考](http://www.ipcv.org/category/code-data/dataset/)\n### 7.a 其他方面 Other datasets\n[参考](http://www.ipcv.org/otherdb/)\n[人脸检测Face tracking and recognition database ](http://seqam.rutgers.edu/site/index.php?option=com_content&view=article&id=65&Itemid=76)\n\n[人脸检测Caltech 10,000 Web Faces](http://vision.caltech.edu/archive.html)\n\n[人脸检测Helen dataset](http://www.ifp.illinois.edu/~vuongle2/helen/)\n\n[深度图 RGB-D dataset](http://mobilerobotics.cs.washington.edu/projects/kdes/)\n\n[视频分割 2010 ECCV Efficient Hierarchical Graph Based Video Segmentation](http://www.cc.gatech.edu/cpl/projects/videosegmentation/)\n\n[手势跟踪 Hand dataset](https://engineering.purdue.edu/RVL/Database.html)\n\n[手势跟踪2](http://www.robots.ox.ac.uk/~vgg/research/hands/index.html)\n\n[车辆检测 2002 ECCV Learning a sparse representation for object detection](http://cogcomp.cs.illinois.edu/Data/Car/)\n\n### 7.b 人体检测 dataset on human annotation\n[参考](http://www.ipcv.org/humandetection/)\n[Caltech Pedestrian Detection Benchmark](http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/)\n\n[Ethz](http://www.vision.ee.ethz.ch/~aess/dataset/)\n[bleibe](http://www.vision.ee.ethz.ch/~bleibe/data/datasets.html)\n\n[RGB-D People Dataset](http://www.informatik.uni-freiburg.de/~spinello/RGBD-dataset.html)\n\n[TUD Campus](http://www.d2.mpi-inf.mpg.de/tud-brussels)\n[382](https://www.d2.mpi-inf.mpg.de/node/382)\n\n[PSU HUB Dataset](http://www.cse.psu.edu/~rcollins/software.html)\n\n[Pedestrian parsing](http://vision.ics.uci.edu/datasets/)\n\n[Human Eva](http://vision.cs.brown.edu/humaneva/)\n\n\n### 7.c 物体识别 dataset on object recognition\n\n[参考](http://www.ipcv.org/objectrecognition/)\n\n[ e-Lab Video Data Set](https://engineering.purdue.edu/elab/eVDS/)\n\n[Image Net](http://www.image-net.org/)\n\n[Places2 Database](http://places2.csail.mit.edu)\n\n[Microsoft CoCo: Common Objects in Context](http://mscoco.org/)\n\n[PASCAL VOC](http://host.robots.ox.ac.uk/pascal/VOC/)\n[MIT’s Place2]( http://places2.csail.mit.edu/)\n\n### 7.d 显著检测方面 dataset on saliency detection\n[参考](http://www.ipcv.org/saliencydetection/)\n\n[视觉显著性检测技术发展情况](http://blog.csdn.net/anshan1984/article/details/8657176)\n\n[2012 ECCV Salient Objects Dataset (SOD)](http://elderlab.yorku.ca/SOD/)\n\n[2012 ECCV Neil D. B. Bruce Eye Tracking Data](http://cs.umanitoba.ca/~bruce/datacode.html)\n\n[2012 ECCV DOVES:A database of visual eye movements](http://live.ece.utexas.edu/research/doves/)\n\n[2012 ECCV MSRA:Salient Object Database](http://research.microsoft.com/en-us/um/people/jiansun/SalientObject/salient_object.htm)\n\n[2012 ECCV NUS: Predicting Saliency Beyond Pixels](http://www.ece.nus.edu.sg/stfpage/eleqiz/predicting.html)\n\n[2012 ECCV saliency benchmark](http://people.csail.mit.edu/tjudd/SaliencyBenchmark/index.html)\n\n[2010 ECCV The DUT-OMRON Image Dataset](http://ice.dlut.edu.cn/lu/DUT-OMRON/Homepage.htm)\n\n[2010 ECCV An eye fixation database for saliency detection in images](http://mmas.comp.nus.edu.sg/NUSEF.html)\n\n### 7.e 行为识别 dataset on action recognition\n[参考](http://www.ipcv.org/actionrecognition/)\n\n[UCF](http://www.cs.ucf.edu/~liujg/YouTube_Action_dataset.html)\n[ChaoticInvariants](http://www.cs.ucf.edu/~sali/Projects/ChaoticInvariants/index.html)\n[datasetsActions](http://vision.eecs.ucf.edu/datasetsActions.html)\n\n[Hollywood Human Actions dataset](http://www.di.ens.fr/~laptev/download.html)\n[data](http://lear.inrialpes.fr/data)\n\n[Weizmann: Actionsas Space-Time Shapes](http://www.wisdom.weizmann.ac.il/~vision/SpaceTimeActions.html)\n\n[KTH](http://www.nada.kth.se/cvap/actions/)\n\n[UMD](http://www.umiacs.umd.edu/~zhuolin/Keckgesturedataset.html)\n\n[HMDB: A Large Video Database for Human Motion Recognition](http://serre-lab.clps.brown.edu/resources/HMDB/related_data/)\n\n[Collective Activity Dataset](http://www.eecs.umich.edu/vision/activity-dataset.html)\n\n[MSR Action Recognition Datasets and Codes](http://research.microsoft.com/en-us/um/people/zliu/ActionRecoRsrc/default.htm)\n\n[Visual Event Recognition in Videos](http://vc.sce.ntu.edu.sg/index_files/VisualEventRecognition/VisualEventRecognition.html)\n\n\n\n### 7.f 物体分割 dataset on object segmentation\n[参考](http://www.ipcv.org/objectsegmentation/)\n[microsoft MSRC-V2](http://research.microsoft.com/en-us/projects/objectclassrecognition/)\n\n[2010 CVPR iCoseg: Interactive cosegmentation by touch](http://chenlab.ece.cornell.edu/projects/touch-coseg/)\n\n[2010 CVPR Caltech-UCSD Birds 200](http://www.vision.caltech.edu/visipedia/CUB-200.html)\n\n[2010 CVPR Flower Datasets](http://www.robots.ox.ac.uk/~vgg/data/flowers/)\n\n[2009 ICCV An efficient algorithm for co-segmentation](http://www.biostat.wisc.edu/~vsingh/)\n\n[2008 CVPR Unsupervised Learning of Probabilistic Object Models (POMs) for Object Classification, Segmentation and Recognition](http://people.csail.mit.edu/leozhu/)\n\n[2008 CVPR Caltech101](http://www.vision.caltech.edu/Image_Datasets/Caltech101/)\n\n[2004 ECCV The Weizmann Horse Database](http://www.msri.org/people/members/eranb/)\n\n\n### 7.g 场景解析 dataset on scene parsing\n[参考](http://www.ipcv.org/sceneparsing/)\n\n[ImageNet](http://www.image-net.org/)\n\n[ADE 20k](http://sceneparsing.csail.mit.edu/)\n\n[Cityscapes](https://www.cityscapes-dataset.com/)\n\n[COCO](http://cocodataset.org/#home)\n\n[Lab, Koch](http://www.mis.tu-darmstadt.de/tudds)\n\n[uiuc, D hoiem](http://www.cs.illinois.edu/homes/dhoiem/)\n\n[mit, cbcl](http://cbcl.mit.edu/software-datasets/streetscenes/)\n\n[mit LabelMeVideo](http://labelme.csail.mit.edu/LabelMeVideo/)\n\n[2013 BMVC Hierarchical Scene Annotation](http://www.vision.caltech.edu/~mmaire/)\n\n[2010 ECCV SuperParsing: Scalable Nonparametric Image Parsing with Superpixels](http://www.cs.unc.edu/~jtighe/Papers/ECCV10/)\n\n[2009 CVPR Nonparametric Scene Parsing: Label Transfer via Dense Scene Alignment](ttp://people.csail.mit.edu/celiu/CVPR2009/)\n\n[2009 Scene Understanding Datasets](http://dags.stanford.edu/projects/scenedataset.html)\n\n[2008 IJCV 6D-Vision](http://www.6d-vision.com/scene-labeling)\n\n[2008 IJCV The Daimler Urban Segmentation Dataset](http://www.6d-vision.com/scene-labeling)\n\n[2008 ECCV Motion-based Segmentation and Recognition Dataset](http://mi.eng.cam.ac.uk/research/projects/VideoRec))/CamVid/\n\n[2008 York Urban Dataset](http://www.elderlab.yorku.ca/YorkUrbanDB/)\n\n[2008 IJCV LabelMe](http://labelme.csail.mit.edu/LabelMeToolbox/index.html)\n\n\n## 8 会议　期刊　\n### CVPR Computer vision  and  Pattern Reconition 计算机视觉和模式识别\n### ECCV European Conference on Computer Vision   欧洲计算机视觉国际会议 \n### ICCV IEEE International Conference on Computer Vision  国际计算机视觉大会\n### 其他\n[其他](http://www.ipcv.org/otherpaper/)\n###\n###\n###\n###\n\n\n## AR&VR\n[参考](http://www.ipcv.org/category/top-dir/arvr/)\n\n\n## \n"
        },
        {
          "name": "Speech",
          "type": "tree",
          "content": null
        },
        {
          "name": "UMCar",
          "type": "tree",
          "content": null
        },
        {
          "name": "darknect",
          "type": "tree",
          "content": null
        },
        {
          "name": "deepLearning",
          "type": "tree",
          "content": null
        },
        {
          "name": "github提交记录.txt",
          "type": "blob",
          "size": 0.8037109375,
          "content": "cd 目标文件夹\necho \"# MVsion\" >> README.md  # 添加文件\ngit init #初始化\ngit config --global user.email \"you@example.com\"  # 邮箱\ngit config --global user.name \"Your Name\"         # 用户名\ngit add README.md            # 添加文件\ngit commit -m \"first commit\" # 提交 \ngit remote add origin https://github.com/Ewenwan/MVision.git #增加一个远程服务器端版本库\ngit push -u origin master # 将本地文件提交到Github。\n\n提交所有文件:\ngit clone https://github.com/Ewenwan/PyML.git #复制本地\n将其他文件全部 放入 PyML 文件夹 \ngit add .\ngit commit -m \"add all files\"\ngit push -u origin master # 将本地文件提交到Github\n\n\ngit status  查看 文件修改情况\ngit add 对应文件\ngit commit -m \"add files\"\ngit push -u origin master # 将本地文件提交到Github\n"
        },
        {
          "name": "gnuplot",
          "type": "tree",
          "content": null
        },
        {
          "name": "machine-learning-cheat-sheet.pdf",
          "type": "blob",
          "size": 1977.6240234375,
          "content": null
        },
        {
          "name": "od.png",
          "type": "blob",
          "size": 63.6611328125,
          "content": null
        },
        {
          "name": "opencv_app",
          "type": "tree",
          "content": null
        },
        {
          "name": "pdf",
          "type": "tree",
          "content": null
        },
        {
          "name": "robot",
          "type": "tree",
          "content": null
        },
        {
          "name": "stereo",
          "type": "tree",
          "content": null
        },
        {
          "name": "vSLAM",
          "type": "tree",
          "content": null
        },
        {
          "name": "国际会议.md",
          "type": "blob",
          "size": 8.1015625,
          "content": "# 出版社：出版地\n    Internet Society:  Rosten, VA, USA\n    Springer: Berlin，German\n    ACM：New York, NY\n    IEEE：Piscataway, NJ\n    USENIX：Berkeley，CA\n\n[IEEE 会议模板](https://www.ieee.org/conferences/publishing/templates.html)\n\n[IEEE 期刊模板](https://journals.ieeeauthorcenter.ieee.org/create-your-ieee-article/authoring-tools-and-templates/ieee-article-templates/)\n\n# 数据库 \n\n## 一、A类\n\n会议简称   会议全称  出版社\n\n[SIGMOD| ACM Conference on Management of Data| ACM](http://www.sigmod.org)\n\n[VLDB International | Conference on Very Large Data Bases|Morgan Kaufmann/ACM](http://www.vldb.org)\n\n[ICDE| IEEE International Conference on Data Engineering| IEEE Computer Society](http://www.icde.org/)\n\n[SIGKDD| ACM Knowledge Discovery and Data Mining| ACM](http://www.acm.org/sigkdd/)\n\n \n## 二、B类\n\n[WWW| International World Wide Web Conferences| W3C](http://www.informatik.uni-trier.de/~ley/db/conf/www/index.html)\n\n[PODS| ACM SIGMOD Conference on Principles of DB Systems| ACM](http://www.informatik.uni-trier.de/~ley/db/conf/icde/)\n\n[EDBT| International Conference on Extending DB Technology| Springer  LNCS](http://www.edbt.org/)\n\n[SIGIR| International Conference on Research and Development in Information Retrieval| ACM](http://www.acm.org/sigir/)\n\n[ICDT| International Conference on Database Theory| Springer](http://alpha.uhasselt.be/~lucp1080/icdt/)\n\n[ICDM| IEEE International Conference on Data Mining| IEEE Computer Society](http://www.cs.uvm.edu/~icdm/)\n\n[CIKM| ACM International Conference on Information and Knowledge Management| ACM](http://www.cikm.org/)\n\n[PKDD| European Conference on Principles and Practice of Knowledge Discovery in Databases| Springer-Verlag LNAI](http://www.ecmlpkdd2008.org/)\n\n[ER| International Conference on Conceptual Modeling| Lecture Notes in Computer Science](http://www.er.byu.edu/)\n\n[SDM| SIAM International Conference on Data Mining| Society for Industrial and Applied Mathematics](http://www.siam.org/)\n\n \n\n## 三、C类\n\n[DEXA| Database and Expert System Applications| Springer LNCS](http://www.dexa.org/)\n\n[NLDB| Applications of Natural Language to Data Bases| Springer LNCS](http://www.nldb.org/)\n\n[WAIM| International Conference on Web Age Information Management| Springer LNCS](http://www.informatik.uni-trier.de/~ley/db/conf/waim/index.html)\n\n[APWeb| TheAsiaPacific Web Conference| Springer LNCS](http://www.informatik.uni-trier.de/~ley/db/conf/apweb/index.html)\n\n[WebDB| International ACM Workshop on Web and Databases| ACM](http://webdb2008.como.polimi.it/)\n\n[MobiDE| International Workshop on Data Engineering for Wireless and Mobile Access| ACM](http://www.cs.fsu.edu/mobide09/)\n\n[MDM| International Conference onMobileData Management| IEEE](http://adslab.cs.nctu.edu.tw/mdm2009/)\n\n[CIDR| International Conference on Innovation Database Research| Online Proceedings](http://www.cidrdb.org/)\n\n[SSDBM| International Conference on Scientific and Statistical DB Management| IEEE Computer Society](http://www.ssdbm.org/)\n\n[WISE| Web Information Systems Engineering| Lecture Notes in Computer Science](http://www.informatik.uni-trier.de/~ley/db/conf/wise/index.html)\n\n[SSTD| International Symposium on Spatial and Temporal Databases](http:www.informatik.uni-trier.de/~ley/db/conf/ssd/index.html)\n\n[PAKDD| Pacific-Asia Conference on Knowledge Discovery and Data Mining| Springer-Verlag LNCS/LNAI](http://www.informatik.uni-trier.de/~ley/db/conf/pakdd/index.html)\n\n[ DASFAA| Database Systems for Advanced Applications| Springer  LNCS](http://www.informatik.uni-trier.de/~ley/db/conf/dasfaa/index.html)\n\n[ ECIR| European Conference on IR Research| Springer](http://ecir2007.fub.it/)\n\n \n\n \n\n# 人工智能与模式识别\n\n## 一、A类\n\n会议简称  会议全称   出版社\n\n[IJCAI| International Joint Conference on Artificial Intelligence| Morgan Kaufmann](http://www.ijcai.org)\n\n[ICCV| International Conference on Computer Vision| IEEE](http://iccv2007.rutgers.edu/)\n\n[ICML| International Conference on Machine Learning| ACM](http://oregonstate.edu/conferences/icml2007/)\n\n[CVPR| IEEE Conference on Computer Vision and Pattern Recognition| IEEE](http://www.cvpr.org/)\n\n[AAAI| AAAI Conference on Artificial Intelligence| AAAI](http://www.aaai.org)\n\n \n\n## 二、B类\n\n[NIPS| Annual Conference on Neural Information Processing Systems| MIT Press](http://www.nips.cc)\n\n[KR| International Conference on Principles of Knowledge Representation and Reasoning| Morgan Kaufmann](http://www.kr.org/)\n\n[ACL| Annual Meeting of the Association for Computational Linguistics| ACL](http://www.aclweb.org/)\n\n[AAMAS| International Joint Conference on Autonomous Agents and Multi-agent Systems| Springer](http://www.aamas2007.org/)\n\n[ECCV| European Conference on Computer Vision| Springer](http://eccv2008.inrialpes.fr/)\n\n[ECML| European Conference on Machine Learning|Springer](http://www.ecmlpkdd2008.org)\n\n[ECAI| European Conference on Artificial Intelligence| IOS Press](http://www.ece.upatras.gr/ecai2008/)\n\n[COLT| Annual Conference on Computational Learning Theory| Springer](http://www.learningtheory.org/colt2007/)\n\n[UAI| International Conference on Uncertainty in Artificial Intelligence| AUAI](http://auai.org/)\n\n[ICAPS| International Conference on Automated Planning and Scheduling| AAAI](http://icaps07.icaps-conference.org/)\n\n[ICCBR| International Conference on Case-Based Reasoning| Springer](http://www.iccbr.org/)\n\n[COLING| International Conference on Computational Linguistics| ACM](http://www.coling2008.org.uk/)\n\n[ALT| International Conference on Algorithmic Learning Theory| Springer](http://www-alg.ist.hokudai.ac.jp/~thomas/ALT07/alt07.jhtml)\n\n[ILP| International Conference on Inductive Logic Programming| Springer](http://oregonstate.edu/conferences/ilp2007/)\n\n[ICRA| IEEE International Conference on Robotics and Automation| IEEE](http://www.icra07.org/)\n\n[CogSci| Cognitive Science Society Annual Conference| Psychology Press](http://www.cognitivesciencesociety.org/cogsci.html)\n\n[IJCAR| International Joint Conference on Automated Reasoning]()\n\n[EMNLPConference on Empirical Methods in Natural Language Processing| ACL](http://www.cs.jhu.edu/~yarowsky/SIGDAT/emnlp06.html)\n\n \n\n## 三、C类\n\n[PRICAI| Pacific Rim International Conference on Artificial Intelligence| Springer](http://www.pricai.org/)\n\n[NAACL| The Annual Conference of the North American Chapter of the Association for Computational Linguistics| NAACL](http://www.cs.rochester.edu/meetings/hlt-naacl07/)\n\n[ACCV| Asian Conference on Computer Vision| Springer](http://www.am.sanken.osaka-u.ac.jp/ACCV2007/)\n\n[IJCNN| International Joint Conference on Neural Networks| IEEE](http://www.ijcnn2007.org/)\n\n[ICASSP| IEEE International Conference on Acoustics, Speech and SP| IEEE](http://www.icassp2007.org/)\n\n[DS| International Conference on Discovery Science| Springer](http://www.i.kyushu-u.ac.jp/~ds07/)\n\n[ICTAI| IEEE International Conference on Tools with Artificial Intelligence| IEEE](http://ictai07.ceid.upatras.gr/)\n\n[ICANN| International Conference on Artificial Neural Networks| Springer](http://www.icann2007.org/)\n\n[ICDAR| International Conference on Document Analysis and Recognition| IEEE](http://www.icdar2007.org/)\n\n[GECCO| Genetic and Evolutionary Computation Conference| ACM](http://www.sigevo.org/gecco-2006/index.html)\n\n[CEC| IEEE Congress on Evolutionary Computation| IEEE](http://cec2007.nus.edu.sg/)\n\n[FUZZ-IEEE| IEEE International Conference on Fuzzy Systems| IEEE](http://www.fuzzieee2007.org/)\n\n[IJCNLP| International Joint Conference on Natural Language Processing| ACL](http://www.ijcnlp2008.org/)\n\n[ICONIP| International Conference on Neural Information Processing| Springer](http://www.iconip07.org/)\n\n[CVIR| International Conference on Content based Image and Video Retrieval| ACM]()\n\n \n\n[FGR| International Conference on Face and Gesture Recognition| IEEE]()\n\n\n[ICB| International Conference on Biometrics| IEEE]()\n\n[CoNLL| Conference on Natural Language Learning |CoNLL](http://www.cnts.ua.ac.be/conll2007/)\n\n[KSEM| International conference on Knowledge Science, Engineering and Management| Springer](http://www.deakin.edu.au/scitech/eit/ksem07/)\n\n[ICPR| International Conference on Pattern Recognition| IEEE](www.icpr2008.org/)\n\n[COSIT| International Conference on Spatial Information Theory]()\n"
        },
        {
          "name": "资料_baiduyun.txt",
          "type": "blob",
          "size": 9.7939453125,
          "content": "\n# SLAM 资料\n\n      作者：视觉IMAX\n  \n      1.PnP算法简介与代码解析（视频+PPT课件+代码解析）链接：https://pan.baidu.com/s/1d9e0FaIvK_s8m1pMJvNXtg 密码：hf22\n      2.LeastSquare_and_gps_fusion（视频+PDF）链接：https://pan.baidu.com/s/1hi-fvkGwNM40esUueIDQzQ 密码：upcc\n      3.Scan Matching in 2D SLAM（视频+PPT）链接：https://pan.baidu.com/s/1TZkuqp428bQZpnGw5-SiZg 密码：xocd\n      4.LSD-SLAM深度解析（视频）链接：https://pan.baidu.com/s/1yKnrkiC-8LS0ahBN5r0UBA 密码：74br\n      5.非线性优化与g2o（视频+PPT）链接：https://pan.baidu.com/s/1E3HuhLLrkrMLZGf1ZyNDag 密码：n1oh\n      6.COP-SLAM - 杨俊（视频+PPT+其他）链接：https://pan.baidu.com/s/1dxm3xzBTyQ50WPkd0IyjQw 密码：4285\n      7.KinectFusion 和 ElasticFusion 三维重建方法 （视频+PDF）链接：https://pan.baidu.com/s/1cVlvM6bdDXZmqxnjxDeZAQ 密码：23ky\n      8.rosbridge的原理和应用-董超（视频+PPT）链接：https://pan.baidu.com/s/1Xgc4y8-C5OnHF0MPXj2D0w 密码：r5tl\n      9.优化与求解（视频+PDF）链接：https://pan.baidu.com/s/1wIjg38aOdav1pi-dwwhy9g 密码：kmoz\n      10.图像技术在AR中的实践（视频+PDF）链接：https://pan.baidu.com/s/1xGBYrShOcZcDFtKMXg7dlA 密码：ylik\n      11.激光SLAM（视频+PDF）链接：https://pan.baidu.com/s/1KGsn8LfZzFxQNiI0f2aHtQ 密码：iw7y\n      12.双目视觉里程计（视频+课件+相关论文）链接：https://pan.baidu.com/s/1ckcc5pfmPgkMn9DxrCkVIg 密码：uj7l\n      13.MEMS IMU的入门与应用（视频+PPT）链接：https://pan.baidu.com/s/115ZXuku0fH6Rt-mKzusSVQ 密码：6s5z\n      14.IMU+动态背景消除（视频+PDF）链接：https://pan.baidu.com/s/1Ya36oenZpLS-6rTyAxEX2Q 密码：yrgu\n      15.视觉SLAM中的矩阵李群基础(视频+课件)链接：https://pan.baidu.com/s/1PqiwvyvGSJxx3yKSgeehDA 密码：0n30\n      16.TLS安全网络传输协议简介(视频+PDF)链接：https://pan.baidu.com/s/1lwAd_yd5IuP7sU-Rb-JF-w 密码：g9ky\n      17.深度学习及应用-颜沁睿链接：https://pan.baidu.com/s/1G_uSO-xonvWb8jU_c4_J9Q 密码：9c8g\n      18.SVO & LSD_SLAM解析(视频+课件+代码)链接：https://pan.baidu.com/s/1D4HxbPwKBLxQWm-1wQxlvw 密码：yhxx\n      19.caffe_intro(视频+课件)链接：https://pan.baidu.com/s/1EL4CtnujlCDpnAK-RMy62A 密码：a481\n      20.Robust camera Location Estimation(视频+课件)链接：https://pan.baidu.com/s/1-64qcmp0L9HWYb4GQYI9AQ 密码：ke3s\n      21.SLAM中的可视化库介绍(视频+课件+代码)链接：https://pan.baidu.com/s/1PovlM_a5jEDV7wP-ZH242Q 密码：1zrp\n      22.g2o简介(视频+课件)链接：https://pan.baidu.com/s/113ThVXOlLKqhjNvZb4cfGw 密码：vr7v\n      23.我们如何定位SLAM？——关于技术创新、产品开发和产管理的经验和教训(视频+课件)链接：https://pan.baidu.com/s/1M-imrVR1Pab8xyqrvcXsHA 密码：pzqj\n      24.矩阵流形上的优化(视频+课件)链接：https://pan.baidu.com/s/1SghsK6VL9-T7R6su0q6F4w 密码：brpz\n      25.里程计视觉融合slam(视频+课件)链接：https://pan.baidu.com/s/1PY06j-a8KjUhiCAlp5Nwmg 密码：ll6t\n      26.图匹配相关工作介绍(PPT+论文)链接：https://pan.baidu.com/s/1x-o2Y5mo-UYQm3aJ-AKKkw 密码：39zl\n      27.ORB-SLAM2源码详解(视频+课件+源码)链接：https://pan.baidu.com/s/1BWUUsxWw0osfVRz69uraog 密码：uz41\n      28.Absolute Scale Estimation链接：https://pan.baidu.com/s/197hJym21UDWm5z9KHFmoXw 密码：c35w\n      29.Structure Light Based 3D Surface Imaging链接：https://pan.baidu.com/s/14j1UFcPIKbZEZQeZp-vaBg 密码：xq0e\n      30.视觉场景流链接：https://pan.baidu.com/s/1a4OcCW-dCxXgzsANI2SF2Q 密码：yz85\n      31.Robust Sfm & SLAM in Challenging Environments(视频+代码)链接：https://pan.baidu.com/s/174Xm_DkxTcvoH8EdMdsLsQ 密码：ymi5\n      32.图像特征的非刚性匹配（视频+课件）链接：https://pan.baidu.com/s/1c0UN4cU8Vf7LApcgiCQ30w 密码：3vxu\n      33.DVS简介（视频+课件）链接：https://pan.baidu.com/s/1KQQaH_h5jNJhh8Jr8gDM9w 密码：17r8\n      34.Previewing ROSCon2016（视频+课件）链接：https://pan.baidu.com/s/153ZLgxHImvO4D9UQZWYd_Q 密码：cnu5\n      35.Event-based_Camera_VO（视频+课件） 链接：https://pan.baidu.com/s/1VDlBiXD9WuFxclAkS7J9pA  密码：4mnw  \n      36.build mobile game solvers - Surya（视频+课件）链接：https://pan.baidu.com/s/1h3qUMW8Zltn-Trd9cdRV4Q 密码：tks6\n      37.Template Attack（视频+课件）链接：https://pan.baidu.com/s/1OaYpRa-Wa1_FAJJWlAHv6Q 密码：tmgq\n      38.Visual SLAM and Applications_BuShuhui（视频+课件）链接：https://pan.baidu.com/s/1UXEhfXIX05SYgAk2PcK9aQ 密码：ifwh\n      39.Calibration for Mobile Robot System（视频+课件）链接：https://pan.baidu.com/s/1OVMeEC8YcyzyVLxyTtlNHA 密码：pw4m\n      40.基于生物启发的多机器人协同环航和协同猎捕（视频+课件）链接：https://pan.baidu.com/s/1Cg8Dy9okY_YBHf1t9xLSJQ 密码：wnff\n      41.压缩感知与量化表示（视频+PDF）链接：https://pan.baidu.com/s/1GSAOYdCQU7p52ljiNDggVg 密码：2plx\n      42.gtsam_tutorial（视频+PDF）链接：https://pan.baidu.com/s/1u2IZnwG37Dsf1FdzpnOXCA 密码：4kf2\n      43.DSO初探（视频+Demo课件）链接：https://pan.baidu.com/s/1cR6R9WgtBvvoMY1shnAHjg 密码：56pv\n      44.Planning in Robotics （视频+课件）链接：https://pan.baidu.com/s/13i56kiNCUggrsxtQsGa0Qw 密码：qtec\n      45.From SFM SLAM to Autonomous Robots（视频+课件）链接：https://pan.baidu.com/s/19hYJ05KwdlSD4nAX8TRV7A 密码：hncb\n      46. Real Time Tracking with DAVIS（课件）链接：https://pan.baidu.com/s/1LEQWSuVtBolraI91wKaj8A 密码：6bow\n      47.视觉+惯性传感器的空间定位方法（视频+课件）链接：https://pan.baidu.com/s/1SgwOhN4HpJVMaTr3Ylw_1Q 密码：b7d5\n      48.Invariance Theory EKF SLAM （视频+课件）链接：https://pan.baidu.com/s/1a8uwjKfeC6YsyMubygLkng 密码：55nw\n      49.DSO原理详解（视频+总结）链接：https://pan.baidu.com/s/1PQttBOOd--e67pYiUwxRig 密码：7l59\n      50.结构光与双目视觉（视频+课件）链接：https://pan.baidu.com/s/1bplcoAzOBNYPbU_Hbra-gQ 密码：b5uv\n      51.Keras Introduction（视频+课件）链接：https://pan.baidu.com/s/1-nZYWvWQmE58h8FMZOHcaw 密码：68sk\n      52.三维点云的地面分割算法介绍（视频+课件）链接：https://pan.baidu.com/s/15t4lV7DdXRVD9vB_VaF5Dw 密码：5slm\n      53.解密Google Tango（视频+课件）链接：https://pan.baidu.com/s/1t9Xbt43DNNlj2ALnwWNKVg 密码：rikl\n      54. Semantic SLAM初探（视频+课件）链接：https://pan.baidu.com/s/1Da1gk3Fn4VFpDOiSr2pgyw 密码：2oaa\n      55.A Snapshot of Image guided Robotic Interventions（视频+PPT）链接：https://pan.baidu.com/s/1wJqyiSZvQCSPYV7Hv5aXnw 密码：i3r6\n      56.浅谈波束成形（视频+课件）链接：https://pan.baidu.com/s/1fA2RJKj8OGU-w6AmU0nHWg 密码：589b\n      57.Geometry meets deep learning（视频+课件）链接：https://pan.baidu.com/s/1SDzz7rQtUDB0PrL6mD-A3A 密码：clq1\n      58.增强现实AR实战（视频+课件）链接：https://pan.baidu.com/s/1PiBAqGjguNKpPJbaGCuzMw 密码：qikp\n      59.2D激光雷达扫描匹配方法及其在轮式移动机器人中的应用（视频+课件）链接：https://pan.baidu.com/s/1g5HBOy8Z1XYygOx-BbHrKA 密码：ow7b\n      60.高斯过程在连续时间SLAM与运动规划中的应用（视频+课件）链接：https://pan.baidu.com/s/1iYi6g08bgYsIaVpHIrNYTQ 密码：pb1z\n      61.基于单目视觉与惯导融合的定位与建图（视频+课件）链接：https://pan.baidu.com/s/1b3U6eDjKRjiWMqluOrN72g 密码：9gv7\n      62.移动AR产品如何做好性能优化（课件）链接：https://pan.baidu.com/s/17oEp3UpBsKmi67CPHOy1kw 密码：s7q0\n      63.图匹配概述（视频+课件）链接：https://pan.baidu.com/s/1PeZQ2ooEpuj70Z32BFP2gQ 密码：z07t\n      64.ImageNet冠军模型SE（视频+课件）链接：https://pan.baidu.com/s/1QfrfNEddbVY9Bs27__mLSQ 密码：4dyj\n      65.ARkit上手教程（视频+教程PPT）链接：https://pan.baidu.com/s/12ZmoAfqgiDPoBSuYyE_VkA 密码：00w9\n      66.多相机视觉SLAM介绍（视频+课件）链接：https://pan.baidu.com/s/1HFxFF-69U_nG6Bye6GvNzg 密码：j8uv\n      67.Deep2Dvision（视频+课件）链接：https://pan.baidu.com/s/1iuD-FHLJlF9fj_0v-3YgRA 密码：5bgk\n      68. 深度相机在计算机视觉中的应用（视频+课件）链接：https://pan.baidu.com/s/1gL2dJRycky-yUcaLFImObA 密码：72gn\n      69. 路径规划-王超群链接：https://pan.baidu.com/s/1wbOp2AKqc-vDhUm1m2D7-g 密码：zcpz\n      70. 工业相机选型及介绍-刘富强链接：https://pan.baidu.com/s/11xbAtxB1TFRCj9Lq9WOQ6g 密码：7xhc\n      71. 摄像机自标定算法 - 张明链接：https://pan.baidu.com/s/1fEsshpS2MoGXokoQt3g-tw 密码：6v0n\n      72. 邱强_机械臂运动规划链接：https://pan.baidu.com/s/1mRKoolkGOGOsxzDQvYO-OA 密码：reyl\n      73.何安莉_硅谷文化与创业链接：https://pan.baidu.com/s/13LN2qx3bhSQgKbDZ3MCifg 密码：u0qc\n      74. TLS安全网络传输协议简介-侯涛链接：https://pan.baidu.com/s/12IpTgbPzIRmVK25VjM2n0w 密码：n6m7\n\n\n# 机器视觉 资料\n\n      1 图像处理软件的学习：https://pan.baidu.com/s/1MXGbr89rmMsCNt2eyO2_Ew 密码：jrkr\n        OpenCV视觉处理核心课程 \n        点云库PCL学习教程     \n\n      2 计算机视觉&图像信号处理【课程视频合集】\n        https://pan.baidu.com/s/1OWXwECQSgS8roYg-huB65g 密码：vz31\n\n      3 数学【课程录像合集】\n        https://pan.baidu.com/s/1ytbNq9Kf3WXgt_OfeGQaVg 密码：t34\n\n      4 编程【电子书】\n        https://pan.baidu.com/s/1YoMVTS5Mm7pdngUATC3qMA 密码：qz8m\n\n      5 计算机视觉【电子书】\n        https://pan.baidu.com/s/17Yd0goJXpJN1walwobJHAQ 密码：qxij\n\n      6 机器学习与深度学习【视频】\n        https://pan.baidu.com/s/1_NKHqOG4_AWqsdLhD06yXw 密码：5wuz\n\n\n  \n"
        }
      ]
    }
  ]
}