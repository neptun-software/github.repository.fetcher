{
  "metadata": {
    "timestamp": 1736566187108,
    "page": 196,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjIwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "zeux/meshoptimizer",
      "stars": 5884,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 0.37890625,
          "content": "Standard: Cpp03\nUseTab: ForIndentation\nTabWidth: 4\nIndentWidth: 4\nAccessModifierOffset: -4\nBreakBeforeBraces: Allman\nIndentCaseLabels: false\nColumnLimit: 0\nPointerAlignment: Left\nBreakConstructorInitializersBeforeComma: true\nNamespaceIndentation: None\nAlignEscapedNewlines: DontAlign\nAlignAfterOpenBracket: DontAlign\nIndentExternBlock: NoIndent\nMacros: [MESHOPTIMIZER_ALLOC_CALLCONV=&_&]\n"
        },
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 0.158203125,
          "content": "# See https://editorconfig.org/ for more info\n\n[*]\ncharset = utf-8\nindent_style = tab\nindent_size = 4\ntrim_trailing_whitespace = true\ninsert_final_newline = true\n"
        },
        {
          "name": ".git-blame-ignore-revs",
          "type": "blob",
          "size": 0.6708984375,
          "content": "# This file contains a list of Git commit hashes that should be hidden from the\n# regular Git history. Typically, this includes commits involving mass auto-formatting\n# or other normalizations. Commit hashes *must* use the full 40-character notation.\n# To apply the ignore list in your local Git client, you must run:\n#\n#   git config blame.ignoreRevsFile .git-blame-ignore-revs\n#\n# This file is automatically used by GitHub.com's blame view.\n\n# Convert CRLF to LF everywhere\nbb4aa0e1372751b74425e77c9a42f972971568bf\n\n# js: Reformat all sources with Prettier\n3dea31b5c248594a62f49a3e41fc88d7ceae2de3\n\n# Reformat workflow YAML files with Prettier\n52e8e1f61712928a36b5257a894bb098a4a98b22\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.125,
          "content": "# IDE integrations\n/.idea/\n/.vs/\n/.vscode/\n\n# Build files\n/build/\n/cmake-build-*/\n/out/\n/gltf/library.wasm\n\n# Test files\n/data/\n"
        },
        {
          "name": ".prettierrc",
          "type": "blob",
          "size": 0.203125,
          "content": "{\n\t\"useTabs\": true,\n\t\"tabWidth\": 4,\n\t\"semi\": true,\n\t\"singleQuote\": true,\n\t\"printWidth\": 150,\n\t\"trailingComma\": \"es5\",\n\t\"overrides\": [\n\t\t{\n\t\t\t\"files\": \"*.yml\",\n\t\t\t\"options\": {\n\t\t\t\t\"tabWidth\": 2\n\t\t\t}\n\t\t},\n\t]\n}\n"
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 5.525390625,
          "content": "cmake_minimum_required(VERSION 3.5...3.30)\n\nif(POLICY CMP0077)\n    cmake_policy(SET CMP0077 NEW) # Enables override of options from parent CMakeLists.txt\nendif()\n\nif(POLICY CMP0091)\n    cmake_policy(SET CMP0091 NEW) # Enables use of MSVC_RUNTIME_LIBRARY\nendif()\n\nif(POLICY CMP0092)\n    cmake_policy(SET CMP0092 NEW) # Enables clean /W4 override for MSVC\nendif()\n\nproject(meshoptimizer VERSION 0.22 LANGUAGES CXX)\n\noption(MESHOPT_BUILD_DEMO \"Build demo\" OFF)\noption(MESHOPT_BUILD_GLTFPACK \"Build gltfpack\" OFF)\noption(MESHOPT_BUILD_SHARED_LIBS \"Build shared libraries\" OFF)\noption(MESHOPT_WERROR \"Treat warnings as errors\" OFF)\noption(MESHOPT_INSTALL \"Install library\" ON)\nset(MESHOPT_BASISU_PATH \"\" CACHE STRING \"\")\n\nset(SOURCES\n    src/meshoptimizer.h\n    src/allocator.cpp\n    src/clusterizer.cpp\n    src/indexcodec.cpp\n    src/indexgenerator.cpp\n    src/overdrawanalyzer.cpp\n    src/overdrawoptimizer.cpp\n    src/quantization.cpp\n    src/simplifier.cpp\n    src/spatialorder.cpp\n    src/stripifier.cpp\n    src/vcacheanalyzer.cpp\n    src/vcacheoptimizer.cpp\n    src/vertexcodec.cpp\n    src/vertexfilter.cpp\n    src/vfetchanalyzer.cpp\n    src/vfetchoptimizer.cpp\n)\n\nset(GLTF_SOURCES\n    gltf/animation.cpp\n    gltf/basisenc.cpp\n    gltf/basislib.cpp\n    gltf/fileio.cpp\n    gltf/gltfpack.cpp\n    gltf/image.cpp\n    gltf/json.cpp\n    gltf/material.cpp\n    gltf/mesh.cpp\n    gltf/node.cpp\n    gltf/parseobj.cpp\n    gltf/parselib.cpp\n    gltf/parsegltf.cpp\n    gltf/stream.cpp\n    gltf/write.cpp\n)\n\nif(WIN32)\n    list(APPEND GLTF_SOURCES gltf/gltfpack.manifest)\nendif()\n\nif(MSVC)\n    add_compile_options(/W4)\nelse()\n    add_compile_options(-Wall -Wextra -Wshadow -Wno-missing-field-initializers)\nendif()\n\nif(MESHOPT_WERROR)\n    if(MSVC)\n        add_compile_options(/WX)\n    else()\n        add_compile_options(-Werror)\n    endif()\nendif()\n\nif(MESHOPT_BUILD_SHARED_LIBS)\n    add_library(meshoptimizer SHARED ${SOURCES})\nelse()\n    add_library(meshoptimizer STATIC ${SOURCES})\nendif()\n\ntarget_include_directories(meshoptimizer INTERFACE \"$<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/src>\")\n\nif(MESHOPT_BUILD_SHARED_LIBS)\n    set_target_properties(meshoptimizer PROPERTIES CXX_VISIBILITY_PRESET hidden)\n    set_target_properties(meshoptimizer PROPERTIES VISIBILITY_INLINES_HIDDEN ON)\n\n    # soversion may be requested via -DMESHOPT_SOVERSION=n; note that experimental APIs (marked with MESHOPTIMIZER_EXPERIMENTAL) are not ABI-stable\n    if(MESHOPT_SOVERSION)\n        set_target_properties(meshoptimizer PROPERTIES VERSION ${PROJECT_VERSION} SOVERSION ${MESHOPT_SOVERSION})\n    endif()\n\n    if(WIN32)\n        target_compile_definitions(meshoptimizer INTERFACE \"MESHOPTIMIZER_API=__declspec(dllimport)\")\n        target_compile_definitions(meshoptimizer PRIVATE \"MESHOPTIMIZER_API=__declspec(dllexport)\")\n    else()\n        target_compile_definitions(meshoptimizer PUBLIC \"MESHOPTIMIZER_API=__attribute__((visibility(\\\"default\\\")))\")\n    endif()\nendif()\n\nset(TARGETS meshoptimizer)\n\nif(MESHOPT_BUILD_DEMO)\n    add_executable(demo demo/main.cpp demo/nanite.cpp demo/tests.cpp tools/objloader.cpp)\n    target_link_libraries(demo meshoptimizer)\nendif()\n\nif(MESHOPT_BUILD_GLTFPACK)\n    add_executable(gltfpack ${GLTF_SOURCES})\n    set_target_properties(gltfpack PROPERTIES CXX_STANDARD 11)\n    target_link_libraries(gltfpack meshoptimizer)\n    list(APPEND TARGETS gltfpack)\n\n    if(MESHOPT_BUILD_SHARED_LIBS)\n        string(CONCAT RPATH \"$ORIGIN/../\" ${CMAKE_INSTALL_LIBDIR})\n        set_target_properties(gltfpack PROPERTIES INSTALL_RPATH ${RPATH})\n    endif()\n\n    if(NOT MESHOPT_BASISU_PATH STREQUAL \"\")\n        get_filename_component(BASISU_PATH ${MESHOPT_BASISU_PATH} ABSOLUTE)\n\n        target_compile_definitions(gltfpack PRIVATE WITH_BASISU)\n        set_source_files_properties(gltf/basisenc.cpp gltf/basislib.cpp PROPERTIES INCLUDE_DIRECTORIES ${BASISU_PATH})\n\n        if(NOT MSVC AND CMAKE_HOST_SYSTEM_PROCESSOR STREQUAL \"x86_64\")\n            set_source_files_properties(gltf/basislib.cpp PROPERTIES COMPILE_OPTIONS -msse4.1)\n        endif()\n\n        if(UNIX)\n            target_link_libraries(gltfpack pthread)\n        endif()\n    endif()\nendif()\n\nif(MESHOPT_INSTALL)\n\tinclude(GNUInstallDirs)\n\n\tinstall(TARGETS ${TARGETS} EXPORT meshoptimizerTargets\n\t    COMPONENT meshoptimizer\n\t    RUNTIME DESTINATION ${CMAKE_INSTALL_BINDIR}\n\t    LIBRARY DESTINATION ${CMAKE_INSTALL_LIBDIR}\n\t    ARCHIVE DESTINATION ${CMAKE_INSTALL_LIBDIR}\n\t    INCLUDES DESTINATION ${CMAKE_INSTALL_INCLUDEDIR})\n\n\tinstall(FILES src/meshoptimizer.h COMPONENT meshoptimizer DESTINATION ${CMAKE_INSTALL_INCLUDEDIR})\n\tinstall(EXPORT meshoptimizerTargets COMPONENT meshoptimizer DESTINATION ${CMAKE_INSTALL_LIBDIR}/cmake/meshoptimizer NAMESPACE meshoptimizer::)\n\n\tif(MSVC)\n\t    foreach(TARGET ${TARGETS})\n\t        get_target_property(TARGET_TYPE ${TARGET} TYPE)\n\t        if(NOT ${TARGET_TYPE} STREQUAL \"STATIC_LIBRARY\")\n\t            install(FILES $<TARGET_PDB_FILE:${TARGET}> COMPONENT meshoptimizer DESTINATION ${CMAKE_INSTALL_BINDIR} OPTIONAL)\n\t        endif()\n\t    endforeach(TARGET)\n\tendif()\n\n\tinclude(CMakePackageConfigHelpers)\n\n\tconfigure_package_config_file(config.cmake.in\n\t    ${CMAKE_CURRENT_BINARY_DIR}/meshoptimizerConfig.cmake\n\t    INSTALL_DESTINATION ${CMAKE_INSTALL_LIBDIR}/cmake/meshoptimizer NO_SET_AND_CHECK_MACRO)\n\n\twrite_basic_package_version_file(${CMAKE_CURRENT_BINARY_DIR}/meshoptimizerConfigVersion.cmake COMPATIBILITY ExactVersion)\n\n\tinstall(FILES\n\t    ${CMAKE_CURRENT_BINARY_DIR}/meshoptimizerConfig.cmake\n\t    ${CMAKE_CURRENT_BINARY_DIR}/meshoptimizerConfigVersion.cmake\n\t    COMPONENT meshoptimizer\n\t    DESTINATION ${CMAKE_INSTALL_LIBDIR}/cmake/meshoptimizer)\nendif()\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 4.6455078125,
          "content": "Thanks for deciding to contribute to meshoptimizer! These guidelines will try to help make the process painless and efficient.\n\n## Questions\n\nIf you have a question regarding the library usage, please [open a GitHub issue](https://github.com/zeux/meshoptimizer/issues/new).\nSome questions just need answers, but it's nice to keep them for future reference in case other people want to know the same thing.\nSome questions help improve the library interface or documentation by inspiring future changes.\n\n## Bugs\n\nIf the library doesn't compile on your system, compiles with warnings, doesn't seem to run correctly for your input data or if anything else is amiss, please [open a GitHub issue](https://github.com/zeux/meshoptimizer/issues/new).\nIt helps if you note the version of the library this issue happens in, the version of your compiler for compilation issues, and a reproduction case for runtime bugs.\n\nOf course, feel free to [create a pull request](https://help.github.com/articles/about-pull-requests/) to fix the bug yourself.\n\n## Features\n\nNew algorithms and improvements to existing algorithms are always welcome; you can open an issue or make the change yourself and submit a pull request.\n\nFor major features, consider opening an issue describing an improvement you'd like to see or make before opening a pull request.\nThis will give us a chance to discuss the idea before implementing it - some algorithms may not be easy to integrate into existing programs, may not be robust to arbitrary meshes or may be expensive to run or implement/maintain, so a discussion helps make sure these don't block the algorithm development.\n\n## Code style\n\nContributions to this project are expected to follow the existing code style.\n`.clang-format` file mostly defines syntactic styling rules (you can run `make format` to format the code accordingly).\n\nAs for naming conventions, this library uses `snake_case` for variables, `lowerCamelCase` for functions, `UpperCamelCase` for types, `kCamelCase` for global constants and `SCARY_CASE` for macros. All public functions/types must additionally have an extra `meshopt_` prefix to avoid symbol conflicts.\n\n## Dependencies\n\nPlease note that this library uses C89 interface for all APIs and a C++98 implementation - C++11 features can not be used.\nThis choice is made to maximize compatibility to make sure that any toolchain, including legacy proprietary gaming console toolchains, can compile this code.\n\nAdditionally, the library code has zero external dependencies, does not depend on STL and does not use RTTI or exceptions.\nThis, again, maximizes compatibility and makes sure the library can be used in environments where STL use is discouraged or prohibited, as well as maximizing runtime performance and minimizing compilation times.\n\nThe demo program uses STL since it serves as an example of usage and as a test harness, not as production-ready code.\n\n## Testing\n\nAll pull requests will run through a continuous integration pipeline using GitHub Actions that will run the built-in unit tests and integration tests on Windows, macOS and Linux with gcc, clang and msvc compilers.\nYou can run the tests yourself using `make test` or building the demo program with `cmake -DBUILD_DEMO=ON` and running it.\n\nUnit tests can be found in `demo/tests.cpp` and functional tests - in `demo/main.cpp`; when making code changes please try to make sure they are covered by an existing test or add a new test accordingly.\n\n## Documentation\n\nDocumentation for this library resides in the `meshoptimizer.h` header, with examples as part of a usage manual available in `README.md`.\nChanges to documentation are always welcome and should use issues/pull requests as outlined above; please note that `README.md` only contains documentation for stable algorithms, as experimental algorithms may change the interface without concern for backwards compatibility.\n\n## Sensitive communication\n\nIf you prefer to not disclose the issues or information relevant to the issue such as reproduction case to the public, you can always contact the author via e-mail (arseny.kapoulkine@gmail.com).\n\n## Contributor agreement\n\nAny code you submit will become part of the repository and be distributed under the [meshoptimizer license](https://github.com/zeux/meshoptimizer/blob/master/LICENSE.md). By submitting code to the project you agree that the code is your work and that you can give it to the project.\n\nYou also agree by submitting your code that you grant all transferrable rights to the code to the project maintainer, including for example re-licensing the code, modifying the code, and distributing it in source or binary forms. Specifically, this includes a requirement that you assign copyright to the project maintainer.\n"
        },
        {
          "name": "LICENSE.md",
          "type": "blob",
          "size": 1.0537109375,
          "content": "MIT License\n\nCopyright (c) 2016-2025 Arseny Kapoulkine\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 9.1357421875,
          "content": "MAKEFLAGS+=-r -j\n\nconfig=debug\nfiles=demo/pirate.obj\n\nBUILD=build/$(config)\n\nLIBRARY_SOURCES=$(wildcard src/*.cpp)\nLIBRARY_OBJECTS=$(LIBRARY_SOURCES:%=$(BUILD)/%.o)\n\nDEMO_SOURCES=$(wildcard demo/*.c demo/*.cpp) tools/objloader.cpp\nDEMO_OBJECTS=$(DEMO_SOURCES:%=$(BUILD)/%.o)\n\nGLTFPACK_SOURCES=$(wildcard gltf/*.cpp)\nGLTFPACK_OBJECTS=$(GLTFPACK_SOURCES:%=$(BUILD)/%.o)\n\nOBJECTS=$(LIBRARY_OBJECTS) $(DEMO_OBJECTS) $(GLTFPACK_OBJECTS)\n\nLIBRARY=$(BUILD)/libmeshoptimizer.a\nDEMO=$(BUILD)/meshoptimizer\n\nCFLAGS=-g -Wall -Wextra -std=c89\nCXXFLAGS=-g -Wall -Wextra -Wshadow -Wno-missing-field-initializers -std=gnu++98\nLDFLAGS=\n\n$(GLTFPACK_OBJECTS): CXXFLAGS+=-std=c++11\n\nifdef BASISU\n    $(GLTFPACK_OBJECTS): CXXFLAGS+=-DWITH_BASISU\n    $(BUILD)/gltf/basis%.cpp.o: CXXFLAGS+=-I$(BASISU)\n    gltfpack: LDFLAGS+=-lpthread\n\n    ifeq ($(HOSTTYPE),x86_64)\n        $(BUILD)/gltf/basislib.cpp.o: CXXFLAGS+=-msse4.1\n    endif\nendif\n\nifdef METIS\n    $(DEMO_OBJECTS): CXXFLAGS+=-DMETIS\n    $(DEMO): LDFLAGS+=-lmetis\nendif\n\nWASI_SDK?=/opt/wasi-sdk\nWASMCC?=$(WASI_SDK)/bin/clang++\nWASIROOT?=$(WASI_SDK)/share/wasi-sysroot\n\nWASM_FLAGS=--target=wasm32-wasi --sysroot=$(WASIROOT)\nWASM_FLAGS+=-Wall -Wextra\nWASM_FLAGS+=-O3 -DNDEBUG -nostartfiles -nostdlib -Wl,--no-entry -Wl,-s\nWASM_FLAGS+=-mcpu=mvp # make sure clang doesn't use post-MVP features like sign extension\nWASM_FLAGS+=-fno-slp-vectorize -fno-vectorize -fno-unroll-loops\nWASM_FLAGS+=-Wl,-z -Wl,stack-size=36864 -Wl,--initial-memory=65536\nWASM_EXPORT_PREFIX=-Wl,--export\n\nWASM_DECODER_SOURCES=src/vertexcodec.cpp src/indexcodec.cpp src/vertexfilter.cpp tools/wasmstubs.cpp\nWASM_DECODER_EXPORTS=meshopt_decodeVertexBuffer meshopt_decodeIndexBuffer meshopt_decodeIndexSequence meshopt_decodeFilterOct meshopt_decodeFilterQuat meshopt_decodeFilterExp sbrk __wasm_call_ctors\n\nWASM_ENCODER_SOURCES=src/vertexcodec.cpp src/indexcodec.cpp src/vertexfilter.cpp src/vcacheoptimizer.cpp src/vfetchoptimizer.cpp src/spatialorder.cpp tools/wasmstubs.cpp\nWASM_ENCODER_EXPORTS=meshopt_encodeVertexBuffer meshopt_encodeVertexBufferBound meshopt_encodeVertexBufferLevel meshopt_encodeIndexBuffer meshopt_encodeIndexBufferBound meshopt_encodeIndexSequence meshopt_encodeIndexSequenceBound meshopt_encodeVertexVersion meshopt_encodeIndexVersion meshopt_encodeFilterOct meshopt_encodeFilterQuat meshopt_encodeFilterExp meshopt_optimizeVertexCache meshopt_optimizeVertexCacheStrip meshopt_optimizeVertexFetchRemap meshopt_spatialSortRemap sbrk __wasm_call_ctors\n\nWASM_SIMPLIFIER_SOURCES=src/simplifier.cpp src/vfetchoptimizer.cpp tools/wasmstubs.cpp\nWASM_SIMPLIFIER_EXPORTS=meshopt_simplify meshopt_simplifyWithAttributes meshopt_simplifyScale meshopt_simplifyPoints meshopt_optimizeVertexFetchRemap sbrk __wasm_call_ctors\n\nWASM_CLUSTERIZER_SOURCES=src/clusterizer.cpp tools/wasmstubs.cpp\nWASM_CLUSTERIZER_EXPORTS=meshopt_buildMeshletsBound meshopt_buildMeshlets meshopt_computeClusterBounds meshopt_computeMeshletBounds meshopt_optimizeMeshlet sbrk __wasm_call_ctors\n\nifneq ($(werror),)\n\tCFLAGS+=-Werror\n\tCXXFLAGS+=-Werror\nendif\n\nifeq ($(config),iphone)\n\tIPHONESDK=/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS.sdk\n\tCFLAGS+=-arch armv7 -arch arm64 -isysroot $(IPHONESDK)\n\tCXXFLAGS+=-arch armv7 -arch arm64 -isysroot $(IPHONESDK) -stdlib=libc++\n\tLDFLAGS+=-arch armv7 -arch arm64 -isysroot $(IPHONESDK) -L $(IPHONESDK)/usr/lib -mios-version-min=7.0\nendif\n\nifeq ($(config),trace)\n\tCXXFLAGS+=-DTRACE=1\nendif\n\nifeq ($(config),tracev)\n\tCXXFLAGS+=-DTRACE=2\nendif\n\nifeq ($(config),release)\n\tCXXFLAGS+=-O3 -DNDEBUG\nendif\n\nifeq ($(config),coverage)\n\tCXXFLAGS+=-coverage\n\tLDFLAGS+=-coverage\nendif\n\nifeq ($(config),release-avx512)\n\tCXXFLAGS+=-O3 -DNDEBUG -mavx512vl -mavx512vbmi -mavx512vbmi2\nendif\n\nifeq ($(config),release-scalar)\n\tCXXFLAGS+=-O3 -DNDEBUG -DMESHOPTIMIZER_NO_SIMD\nendif\n\nifeq ($(config),coverage-scalar)\n\tCXXFLAGS+=-coverage -DMESHOPTIMIZER_NO_SIMD\n\tLDFLAGS+=-coverage\nendif\n\nifeq ($(config),sanitize)\n\tCXXFLAGS+=-fsanitize=address,undefined -fsanitize-undefined-trap-on-error\n\tLDFLAGS+=-fsanitize=address,undefined\nendif\n\nifeq ($(config),analyze)\n\tCXXFLAGS+=--analyze\nendif\n\nifeq ($(config),fuzz)\n    CXXFLAGS+=-O1 -fsanitize=address,fuzzer\n    LDFLAGS+=-fsanitize=address,fuzzer\n\n    $(GLTFPACK_OBJECTS): CXXFLAGS+=-DGLTFFUZZ\nendif\n\nall: $(DEMO)\n\ntest: $(DEMO)\n\t$(DEMO) $(files)\n\ncheck: $(DEMO)\n\t$(DEMO)\n\ndev: $(DEMO)\n\t$(DEMO) -d $(files)\n\nnanite: $(DEMO)\n\t$(DEMO) -n $(files)\n\nformat:\n\tclang-format -i src/*.h src/*.cpp demo/*.cpp gltf/*.h gltf/*.cpp\n\nformatjs:\n\tprettier -w js/*.js gltf/*.js demo/*.html js/*.ts\n\njs: js/meshopt_decoder.js js/meshopt_decoder.module.js js/meshopt_encoder.js js/meshopt_encoder.module.js js/meshopt_simplifier.js js/meshopt_simplifier.module.js js/meshopt_clusterizer.js js/meshopt_clusterizer.module.js\n\nsymbols: $(BUILD)/amalgamated.so\n\tnm $< -U -g\n\ngltfpack: $(BUILD)/gltfpack\n\tln -fs $^ $@\n\nifeq ($(config),fuzz)\ngltffuzz: $(BUILD)/gltfpack\n\tcp $^ $@\n\tmkdir -p /tmp/gltffuzz\n\tcp gltf/fuzz.glb /tmp/gltffuzz/\n\t./gltffuzz /tmp/gltffuzz -fork=16 -dict=gltf/fuzz.dict -ignore_crashes=1 -max_len=32768\nendif\n\n$(BUILD)/gltfpack: $(GLTFPACK_OBJECTS) $(LIBRARY)\n\t$(CXX) $^ $(LDFLAGS) -o $@\n\ngltfpack.wasm: gltf/library.wasm\n\ngltf/library.wasm: $(LIBRARY_SOURCES) $(GLTFPACK_SOURCES)\n\t$(WASMCC) $^ -o $@ -Wall -Os -DNDEBUG --target=wasm32-wasi --sysroot=$(WASIROOT) -nostartfiles -Wl,--no-entry -Wl,--export=pack -Wl,--export=malloc -Wl,--export=free -Wl,--export=__wasm_call_ctors -Wl,-s -Wl,--allow-undefined-file=gltf/wasistubs.txt\n\nbuild/decoder_base.wasm: $(WASM_DECODER_SOURCES)\n\t@mkdir -p build\n\t$(WASMCC) $^ $(WASM_FLAGS) $(patsubst %,$(WASM_EXPORT_PREFIX)=%,$(WASM_DECODER_EXPORTS)) -o $@\n\nbuild/decoder_simd.wasm: $(WASM_DECODER_SOURCES)\n\t@mkdir -p build\n\t$(WASMCC) $^ $(WASM_FLAGS) $(patsubst %,$(WASM_EXPORT_PREFIX)=%,$(WASM_DECODER_EXPORTS)) -o $@ -msimd128 -mbulk-memory\n\nbuild/encoder.wasm: $(WASM_ENCODER_SOURCES)\n\t@mkdir -p build\n\t$(WASMCC) $^ $(WASM_FLAGS) $(patsubst %,$(WASM_EXPORT_PREFIX)=%,$(WASM_ENCODER_EXPORTS)) -lc -o $@\n\nbuild/simplifier.wasm: $(WASM_SIMPLIFIER_SOURCES)\n\t@mkdir -p build\n\t$(WASMCC) $^ $(WASM_FLAGS) $(patsubst %,$(WASM_EXPORT_PREFIX)=%,$(WASM_SIMPLIFIER_EXPORTS)) -lc -o $@\n\nbuild/clusterizer.wasm: $(WASM_CLUSTERIZER_SOURCES)\n\t@mkdir -p build\n\t$(WASMCC) $^ $(WASM_FLAGS) $(patsubst %,$(WASM_EXPORT_PREFIX)=%,$(WASM_CLUSTERIZER_EXPORTS)) -lc -o $@\n\njs/meshopt_decoder.js: build/decoder_base.wasm build/decoder_simd.wasm tools/wasmpack.py\n\tsed -i \"s#Built with clang.*#Built with $$($(WASMCC) --version | head -n 1 | sed 's/\\s\\+(.*//')#\" $@\n\tsed -i \"s#Built from meshoptimizer .*#Built from meshoptimizer $$(cat src/meshoptimizer.h | grep -Po '(?<=version )[0-9.]+')#\" $@\n\tsed -i \"s#\\([\\\"']\\).*\\(;\\s*//\\s*embed! base\\)#\\\\1$$(cat build/decoder_base.wasm | python3 tools/wasmpack.py)\\\\1\\\\2#\" $@\n\tsed -i \"s#\\([\\\"']\\).*\\(;\\s*//\\s*embed! simd\\)#\\\\1$$(cat build/decoder_simd.wasm | python3 tools/wasmpack.py)\\\\1\\\\2#\" $@\n\njs/meshopt_encoder.js: build/encoder.wasm tools/wasmpack.py\njs/meshopt_simplifier.js: build/simplifier.wasm tools/wasmpack.py\njs/meshopt_clusterizer.js: build/clusterizer.wasm tools/wasmpack.py\n\njs/meshopt_encoder.js js/meshopt_simplifier.js js/meshopt_clusterizer.js:\n\tsed -i \"s#Built with clang.*#Built with $$($(WASMCC) --version | head -n 1 | sed 's/\\s\\+(.*//')#\" $@\n\tsed -i \"s#Built from meshoptimizer .*#Built from meshoptimizer $$(cat src/meshoptimizer.h | grep -Po '(?<=version )[0-9.]+')#\" $@\n\tsed -i \"s#\\([\\\"']\\).*\\(;\\s*//\\s*embed! wasm\\)#\\\\1$$(cat $< | python3 tools/wasmpack.py)\\\\1\\\\2#\" $@\n\njs/%.module.js: js/%.js\n\tsed '\\#// export!#q' <$< >$@\n\tsed -i \"/use strict.;/d\" $@\n\tsed -i \"s#// export! \\(.*\\)#export { \\\\1 };#\" $@\n\n$(DEMO): $(DEMO_OBJECTS) $(LIBRARY)\n\t$(CXX) $^ $(LDFLAGS) -o $@\n\nvcachetuner: tools/vcachetuner.cpp tools/objloader.cpp $(LIBRARY)\n\t$(CXX) $^ -fopenmp $(CXXFLAGS) -std=c++11 $(LDFLAGS) -o $@\n\ncodecbench: tools/codecbench.cpp $(LIBRARY)\n\t$(CXX) $^ $(CXXFLAGS) $(LDFLAGS) -o $@\n\ncodecbench.js: tools/codecbench.cpp $(LIBRARY_SOURCES)\n\temcc $^ -O3 -g -DNDEBUG -s TOTAL_MEMORY=268435456 -s SINGLE_FILE=1 -o $@\n\ncodecbench-simd.js: tools/codecbench.cpp $(LIBRARY_SOURCES)\n\temcc $^ -O3 -g -DNDEBUG -s TOTAL_MEMORY=268435456 -s SINGLE_FILE=1 -msimd128 -o $@\n\ncodecbench.wasm: tools/codecbench.cpp $(LIBRARY_SOURCES)\n\t$(WASMCC) $^ -fno-exceptions --target=wasm32-wasi --sysroot=$(WASIROOT) -lc++ -lc++abi -O3 -g -DNDEBUG -o $@\n\ncodecbench-simd.wasm: tools/codecbench.cpp $(LIBRARY_SOURCES)\n\t$(WASMCC) $^ -fno-exceptions --target=wasm32-wasi --sysroot=$(WASIROOT) -lc++ -lc++abi -O3 -g -DNDEBUG -msimd128 -o $@\n\ncodectest: tools/codectest.cpp $(LIBRARY)\n\t$(CXX) $^ $(CXXFLAGS) $(LDFLAGS) -o $@\n\ncodecfuzz: tools/codecfuzz.cpp src/vertexcodec.cpp src/indexcodec.cpp\n\t$(CXX) $^ -fsanitize=fuzzer,address,undefined -O1 -g -o $@\n\nsimplifyfuzz: tools/simplifyfuzz.cpp src/simplifier.cpp\n\t$(CXX) $^ -fsanitize=fuzzer,address,undefined -O1 -g -o $@\n\n$(LIBRARY): $(LIBRARY_OBJECTS)\n\tar rcs $@ $^\n\n$(BUILD)/amalgamated.so: $(LIBRARY_SOURCES)\n\t@mkdir -p $(dir $@)\n\tcat $^ | $(CXX) $(CXXFLAGS) -x c++ - -I src/ -o $@ -shared -fPIC\n\n$(BUILD)/%.cpp.o: %.cpp\n\t@mkdir -p $(dir $@)\n\t$(CXX) $< $(CXXFLAGS) -c -MMD -MP -o $@\n\n$(BUILD)/%.c.o: %.c\n\t@mkdir -p $(dir $@)\n\t$(CC) $< $(CFLAGS) -c -MMD -MP -o $@\n\n-include $(OBJECTS:.o=.d)\n\nclean:\n\trm -rf $(BUILD)\n\n.PHONY: all clean format js\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 53.30078125,
          "content": "# ðŸ‡ meshoptimizer [![Actions Status](https://github.com/zeux/meshoptimizer/workflows/build/badge.svg)](https://github.com/zeux/meshoptimizer/actions) [![codecov.io](https://codecov.io/github/zeux/meshoptimizer/coverage.svg?branch=master)](https://codecov.io/github/zeux/meshoptimizer?branch=master) ![MIT](https://img.shields.io/badge/license-MIT-blue.svg) [![GitHub](https://img.shields.io/badge/repo-github-green.svg)](https://github.com/zeux/meshoptimizer)\n\n## Purpose\n\nWhen a GPU renders triangle meshes, various stages of the GPU pipeline have to process vertex and index data. The efficiency of these stages depends on the data you feed to them; this library provides algorithms to help optimize meshes for these stages, as well as algorithms to reduce the mesh complexity and storage overhead.\n\nThe library provides a C and C++ interface for all algorithms; you can use it from C/C++ or from other languages via FFI (such as P/Invoke). If you want to use this library from Rust, you should use [meshopt crate](https://crates.io/crates/meshopt). JavaScript interface for some algorithms is available through [meshoptimizer.js](https://www.npmjs.com/package/meshoptimizer).\n\n[gltfpack](./gltf/README.md), which is a tool that can automatically optimize glTF files, is developed and distributed alongside the library.\n\n## Installing\n\nmeshoptimizer is hosted on GitHub; you can download the latest release using git:\n\n```\ngit clone -b v0.22 https://github.com/zeux/meshoptimizer.git\n```\n\nAlternatively you can [download the .zip archive from GitHub](https://github.com/zeux/meshoptimizer/archive/v0.22.zip).\n\nThe library is also available as a Linux package in several distributions ([ArchLinux](https://aur.archlinux.org/packages/meshoptimizer/), [Debian](https://packages.debian.org/libmeshoptimizer), [FreeBSD](https://www.freshports.org/misc/meshoptimizer/), [Nix](https://mynixos.com/nixpkgs/package/meshoptimizer), [Ubuntu](https://packages.ubuntu.com/libmeshoptimizer)), as well as a [Vcpkg port](https://github.com/microsoft/vcpkg/tree/master/ports/meshoptimizer) (see [installation instructions](https://learn.microsoft.com/en-us/vcpkg/get_started/get-started)) and a [Conan package](https://conan.io/center/recipes/meshoptimizer).\n\n[gltfpack](./gltf/README.md) is available as a pre-built binary on [Releases page](https://github.com/zeux/meshoptimizer/releases) or via [npm package](https://www.npmjs.com/package/gltfpack). Native binaries are recommended since they are more efficient and support texture compression.\n\n## Building\n\nmeshoptimizer is distributed as a set of C++ source files. To include it into your project, you can use one of the two options:\n\n* Use CMake to build the library (either as a standalone project or as part of your project)\n* Add source files to your project's build system\n\nThe source files are organized in such a way that you don't need to change your build-system settings, and you only need to add the source files for the algorithms you use. They should build without warnings or special compilation options on all major compilers.\n\n## Pipeline\n\nWhen optimizing a mesh, you should typically feed it through a set of optimizations (the order is important!):\n\n1. Indexing\n2. (optional, discussed last) Simplification\n3. Vertex cache optimization\n4. Overdraw optimization\n5. Vertex fetch optimization\n6. Vertex quantization\n7. Shadow indexing\n8. (optional) Vertex/index buffer compression\n\n## Indexing\n\nMost algorithms in this library assume that a mesh has a vertex buffer and an index buffer. For algorithms to work well and also for GPU to render your mesh efficiently, the vertex buffer has to have no redundant vertices; you can generate an index buffer from an unindexed vertex buffer or reindex an existing (potentially redundant) index buffer as follows:\n\n> Note: meshoptimizer generally works with 32-bit (`unsigned int`) indices, however when using C++ APIs you can use any integer type for index data by using the provided template overloads. By convention, remap tables always use `unsigned int`.\n\nFirst, generate a remap table from your existing vertex (and, optionally, index) data:\n\n```c++\nsize_t index_count = face_count * 3;\nsize_t unindexed_vertex_count = face_count * 3;\nstd::vector<unsigned int> remap(unindexed_vertex_count); // temporary remap table\nsize_t vertex_count = meshopt_generateVertexRemap(&remap[0], NULL, index_count, &unindexed_vertices[0], unindexed_vertex_count, sizeof(Vertex));\n```\n\nNote that in this case we only have an unindexed vertex buffer; when input mesh has an index buffer, it will need to be passed to `meshopt_generateVertexRemap` instead of `NULL`, along with the correct source vertex count. In either case, the remap table is generated based on binary equivalence of the input vertices, so the resulting mesh will render the same way. Binary equivalence considers all input bytes, including padding which should be zero-initialized if the vertex structure has gaps.\n\nAfter generating the remap table, you can allocate space for the target vertex buffer (`vertex_count` elements) and index buffer (`index_count` elements) and generate them:\n\n```c++\nmeshopt_remapIndexBuffer(indices, NULL, index_count, &remap[0]);\nmeshopt_remapVertexBuffer(vertices, &unindexed_vertices[0], unindexed_vertex_count, sizeof(Vertex), &remap[0]);\n```\n\nYou can then further optimize the resulting buffers by calling the other functions on them in-place.\n\n`meshopt_generateVertexRemap` uses binary equivalence of vertex data, which is generally a reasonable default; however, in some cases some attributes may have floating point drift causing extra vertices to be generated. For such cases, it may be necessary to quantize some attributes (most importantly, normals and tangents) before generating the remap, or use a custom weld algorithm that supports per-attribute tolerance instead.\n\n## Vertex cache optimization\n\nWhen the GPU renders the mesh, it has to run the vertex shader for each vertex; usually GPUs have a built-in fixed size cache that stores the transformed vertices (the result of running the vertex shader), and uses this cache to reduce the number of vertex shader invocations. This cache is usually small, 16-32 vertices, and can have different replacement policies; to use this cache efficiently, you have to reorder your triangles to maximize the locality of reused vertex references like so:\n\n```c++\nmeshopt_optimizeVertexCache(indices, indices, index_count, vertex_count);\n```\n\n## Overdraw optimization\n\nAfter transforming the vertices, GPU sends the triangles for rasterization which results in generating pixels that are usually first ran through the depth test, and pixels that pass it get the pixel shader executed to generate the final color. As pixel shaders get more expensive, it becomes more and more important to reduce overdraw. While in general improving overdraw requires view-dependent operations, this library provides an algorithm to reorder triangles to minimize the overdraw from all directions, which you should run after vertex cache optimization like this:\n\n```c++\nmeshopt_optimizeOverdraw(indices, indices, index_count, &vertices[0].x, vertex_count, sizeof(Vertex), 1.05f);\n```\n\nThe overdraw optimizer needs to read vertex positions as a float3 from the vertex; the code snippet above assumes that the vertex stores position as `float x, y, z`.\n\nWhen performing the overdraw optimization you have to specify a floating-point threshold parameter. The algorithm tries to maintain a balance between vertex cache efficiency and overdraw; the threshold determines how much the algorithm can compromise the vertex cache hit ratio, with 1.05 meaning that the resulting ratio should be at most 5% worse than before the optimization.\n\n## Vertex fetch optimization\n\nAfter the final triangle order has been established, we still can optimize the vertex buffer for memory efficiency. Before running the vertex shader GPU has to fetch the vertex attributes from the vertex buffer; the fetch is usually backed by a memory cache, and as such optimizing the data for the locality of memory access is important. You can do this by running this code:\n\n```c++\nmeshopt_optimizeVertexFetch(vertices, indices, index_count, vertices, vertex_count, sizeof(Vertex));\n```\n\nThis will reorder the vertices in the vertex buffer to try to improve the locality of reference, and rewrite the indices in place to match; if the vertex data is stored using multiple streams, you should use `meshopt_optimizeVertexFetchRemap` instead. This optimization has to be performed on the final index buffer since the optimal vertex order depends on the triangle order.\n\nNote that the algorithm does not try to model cache replacement precisely and instead just orders vertices in the order of use, which generally produces results that are close to optimal.\n\n## Vertex quantization\n\nTo optimize memory bandwidth when fetching the vertex data even further, and to reduce the amount of memory required to store the mesh, it is often beneficial to quantize the vertex attributes to smaller types. While this optimization can technically run at any part of the pipeline (and sometimes doing quantization as the first step can improve indexing by merging almost identical vertices), it generally is easier to run this after all other optimizations since some of them require access to float3 positions.\n\nQuantization is usually domain specific; it's common to quantize normals using 3 8-bit integers but you can use higher-precision quantization (for example using 10 bits per component in a 10_10_10_2 format), or a different encoding to use just 2 components. For positions and texture coordinate data the two most common storage formats are half precision floats, and 16-bit normalized integers that encode the position relative to the AABB of the mesh or the UV bounding rectangle.\n\nThe number of possible combinations here is very large but this library does provide the building blocks, specifically functions to quantize floating point values to normalized integers, as well as half-precision floats. For example, here's how you can quantize a normal:\n\n```c++\nunsigned int normal =\n    (meshopt_quantizeUnorm(v.nx, 10) << 20) |\n    (meshopt_quantizeUnorm(v.ny, 10) << 10) |\n     meshopt_quantizeUnorm(v.nz, 10);\n```\n\nand here's how you can quantize a position:\n\n```c++\nunsigned short px = meshopt_quantizeHalf(v.x);\nunsigned short py = meshopt_quantizeHalf(v.y);\nunsigned short pz = meshopt_quantizeHalf(v.z);\n```\n\nSince quantized vertex attributes often need to remain in their compact representations for efficient transfer and storage, they are usually dequantized during vertex processing by configuring the GPU vertex input correctly to expect normalized integers or half precision floats, which often needs no or minimal changes to the shader code. When CPU dequantization is required instead, `meshopt_dequantizeHalf` can be used to convert half precision values back to single precision; for normalized integer formats, the dequantization just requires dividing by 2^N-1 for unorm and 2^(N-1)-1 for snorm variants, for example manually reversing `meshopt_quantizeUnorm(v, 10)` can be done by dividing by 1023.\n\n## Shadow indexing\n\nMany rendering pipelines require meshes to be rendered to depth-only targets, such as shadow maps or during a depth pre-pass, in addition to color/G-buffer targets. While using the same geometry data for both cases is possible, reducing the number of unique vertices for depth-only rendering can be beneficial, especially when the source geometry has many attribute seams due to faceted shading or lightmap texture seams.\n\nTo achieve this, this library provides the `meshopt_generateShadowIndexBuffer` algorithm, which generates a second (shadow) index buffer that can be used with the original vertex data:\n\n```c++\nstd::vector<unsigned int> shadow_indices(index_count);\n// note: this assumes Vertex starts with float3 positions and should be adjusted accordingly for quantized positions\nmeshopt_generateShadowIndexBuffer(&shadow_indices[0], indices, index_count, &vertices[0].x, vertex_count, sizeof(float) * 3, sizeof(Vertex));\n```\n\nBecause the vertex data is shared, shadow indexing should be done after other optimizations of the vertex/index data. However, it's possible (and recommended) to optimize the resulting shadow index buffer for vertex cache:\n\n```c++\nmeshopt_optimizeVertexCache(&shadow_indices[0], &shadow_indices[0], index_count, vertex_count);\n```\n\nIn some cases, it may be beneficial to split the vertex positions into a separate buffer to maximize efficiency for depth-only rendering. Note that the example above assumes only positions are relevant for shadow rendering, but more complex materials may require adding texture coordinates (for alpha testing) or skinning data to the vertex portion used as a key. `meshopt_generateShadowIndexBufferMulti` can be useful for these cases if the relevant data is not contiguous.\n\n## Vertex/index buffer compression\n\nIn case storage size or transmission bandwidth is of importance, you might want to additionally compress vertex and index data. While several mesh compression libraries, like Google Draco, are available, they typically are designed to maximize the compression ratio at the cost of disturbing the vertex/index order (which makes the meshes inefficient to render on GPU) or decompression performance. They also frequently don't support custom game-ready quantized vertex formats and thus require to re-quantize the data after loading it, introducing extra quantization errors and making decoding slower.\n\nAlternatively you can use general purpose compression libraries like zstd or Oodle to compress vertex/index data - however these compressors aren't designed to exploit redundancies in vertex/index data and as such compression rates can be unsatisfactory.\n\nTo that end, this library provides algorithms to \"encode\" vertex and index data. The result of the encoding is generally significantly smaller than initial data, and remains compressible with general purpose compressors - so you can either store encoded data directly (for modest compression ratios and maximum decoding performance), or further compress it with zstd/Oodle to maximize compression ratio.\n\n> Note: this compression scheme is available as a glTF extension [EXT_meshopt_compression](https://github.com/KhronosGroup/glTF/blob/main/extensions/2.0/Vendor/EXT_meshopt_compression/README.md).\n\nTo encode, you need to allocate target buffers (preferably using the worst case bound) and call encoding functions:\n\n```c++\nstd::vector<unsigned char> vbuf(meshopt_encodeVertexBufferBound(vertex_count, sizeof(Vertex)));\nvbuf.resize(meshopt_encodeVertexBuffer(&vbuf[0], vbuf.size(), vertices, vertex_count, sizeof(Vertex)));\n\nstd::vector<unsigned char> ibuf(meshopt_encodeIndexBufferBound(index_count, vertex_count));\nibuf.resize(meshopt_encodeIndexBuffer(&ibuf[0], ibuf.size(), indices, index_count));\n```\n\nYou can then either serialize `vbuf`/`ibuf` as is, or compress them further. To decode the data at runtime, call decoding functions:\n\n```c++\nint resvb = meshopt_decodeVertexBuffer(vertices, vertex_count, sizeof(Vertex), &vbuf[0], vbuf.size());\nint resib = meshopt_decodeIndexBuffer(indices, index_count, &ibuf[0], ibuf.size());\nassert(resvb == 0 && resib == 0);\n```\n\nNote that vertex encoding assumes that vertex buffer was optimized for vertex fetch, and that vertices are quantized; index encoding assumes that the vertex/index buffers were optimized for vertex cache and vertex fetch. Feeding unoptimized data into the encoders will produce poor compression ratios. Both codecs are lossless - the only lossy step is quantization that happens before encoding.\n\nDecoding functions are heavily optimized and can directly target write-combined memory; you can expect both decoders to run at 3-5 GB/s on modern desktop CPUs. Compression ratios depend on the data; vertex data compression ratio is typically around 2-4x (compared to already quantized data), index data compression ratio is around 5-6x (compared to raw 16-bit index data). General purpose lossless compressors can further improve on these results.\n\nFor additional improvements in compression ratio and decoding performance, it is recommended to switch to vertex codec v1 (via `meshopt_encodeVertexVersion(1)`). This will result in smaller outputs that decode faster, and provide additional control over compression level - `meshopt_encodeVertexBuffer` will use compression level 2 by default, but using `meshopt_encodeVertexBufferLevel` allows to improve compression in certain cases by using level 3, or to reduce compression ratio and improve encoding speed by using level 1. Note that v1 format requires meshoptimizer v0.23 or later for decoding.\n\nWhen data is bit packed, using v1 vertex codec (via `meshopt_encodeVertexVersion(1)`) and specifying compression level 3 (`meshopt_encodeVertexBufferLevel`) can improve the compression further by redistributing bits between components.\n\nIndex buffer codec only supports triangle list topology; when encoding triangle strips or line lists, use `meshopt_encodeIndexSequence`/`meshopt_decodeIndexSequence` instead. This codec typically encodes indices into ~1 byte per index, but compressing the results further with a general purpose compressor can improve the results to 1-3 bits per index.\n\nThe following guarantees on data compatibility are provided for point releases (*no* guarantees are given for development branch):\n\n- Data encoded with older versions of the library can always be decoded with newer versions;\n- Data encoded with newer versions of the library can be decoded with older versions, provided that encoding versions are set correctly; if binary stability of encoded data is important, use `meshopt_encodeVertexVersion` and `meshopt_encodeIndexVersion` to 'pin' the data versions.\n\nDue to a very high decoding performance and compatibility with general purpose lossless compressors, the compression is a good fit for the use on the web. To that end, meshoptimizer provides both vertex and index decoders compiled into WebAssembly and wrapped into a module with JavaScript-friendly interface, `js/meshopt_decoder.js`, that you can use to decode meshes that were encoded offline:\n\n```js\n// ready is a Promise that is resolved when (asynchronous) WebAssembly compilation finishes\nawait MeshoptDecoder.ready;\n\n// decode from *Data (Uint8Array) into *Buffer (Uint8Array)\nMeshoptDecoder.decodeVertexBuffer(vertexBuffer, vertexCount, vertexSize, vertexData);\nMeshoptDecoder.decodeIndexBuffer(indexBuffer, indexCount, indexSize, indexData);\n```\n\n[Usage example](https://meshoptimizer.org/demo/) is available, with source in `demo/index.html`; this example uses .GLB files encoded using `gltfpack`.\n\n## Point cloud compression\n\nThe vertex encoding algorithms can be used to compress arbitrary streams of attribute data; one other use case besides triangle meshes is point cloud data. Typically point clouds come with position, color and possibly other attributes but don't have an implied point order.\n\nTo compress point clouds efficiently, it's recommended to first preprocess the points by sorting them using the spatial sort algorithm:\n\n```c++\nstd::vector<unsigned int> remap(point_count);\nmeshopt_spatialSortRemap(&remap[0], positions, point_count, sizeof(vec3));\n\n// for each attribute stream\nmeshopt_remapVertexBuffer(positions, positions, point_count, sizeof(vec3), &remap[0]);\n```\n\nAfter this the resulting arrays should be quantized (e.g. using 16-bit fixed point numbers for positions and 8-bit color components), and the result can be compressed using `meshopt_encodeVertexBuffer` as described in the previous section. To decompress, `meshopt_decodeVertexBuffer` will recover the quantized data that can be used directly or converted back to original floating-point data. The compression ratio depends on the nature of source data, for colored points it's typical to get 35-40 bits per point as a result.\n\n## Advanced compression\n\nBoth vertex and index codecs are designed to be used in a three-stage pipeline:\n\n- Preparation (quantization, filtering, ordering)\n- Encoding (`meshopt_encodeVertexBuffer`/`meshopt_encodeIndexBuffer`)\n- Optional compression (LZ4/zlib/zstd/Oodle)\n\nThe preparation stage is crucial for achieving good compression ratios; this section will cover some techniques that can be used to improve the results.\n\nThe index codec targets 1 byte per triangle as a best case; on real-world data, it's typical to achieve 1-1.2 bytes per triangle. To reach this, the data needs to be optimized for vertex cache and vertex fetch. Optimizations that do not disrupt triangle locality (such as overdraw) are safe to use in between.\nTo reduce the data size further, it's possible to use `meshopt_optimizeVertexCacheStrip` instead of `meshopt_optimizeVertexCache` when optimizing for vertex cache. This trades off some efficiency in vertex transform for smaller vertex and index data.\n\nWhen referenced vertex indices are not sequential, the index codec will use around 2 bytes per index. This can happen when the referenced vertices are a sparse subset of the vertex buffer, such as when encoding LODs. General-purpose compression can be especially helpful in this case.\n\nThe vertex codec tries to take advantage of the inherent locality of sequential vertices and identify bit patterns that repeat in consecutive vertices. Typically, vertex cache + vertex fetch provides a reasonably local vertex traversal order; without an index buffer, it is recommended to sort vertices spatially to improve the compression ratio.\nIt is crucial to correctly specify the stride when encoding vertex data; however, it does not matter whether the vertices are interleaved or deinterleaved, as the codecs perform full byte deinterleaving internally.\n\nFor optimal compression results, the values must be quantized to small integers. It can be valuable to use bit counts that are not multiples of 8. For example, instead of using 16 bits to represent texture coordinates, use 12-bit integers and divide by 4095 in the shader. Alternatively, using half-precision floats can often achieve good results.\nFor single-precision floating-point data, it's recommended to use `meshopt_quantizeFloat` to remove entropy from the lower bits of the mantissa. Due to current limitations of the codec, the bit count needs to be 15 (23-8) for good results (7 can be used for more extreme compression).\nFor normal or tangent vectors, using octahedral encoding is recommended over three components as it reduces redundancy. Similarly to other quantized values, consider using 10-12 bits per component instead of 16.\n\nWhen data is bit packed, using v1 vertex codec (via `meshopt_encodeVertexVersion(1)`) and specifying compression level 3 (`meshopt_encodeVertexBufferLevel`) can improve the compression further by redistributing bits between components.\n\nTo further leverage the inherent structure of some data, the preparation stage can use filters that encode and decode the data in a lossy manner. This is similar to quantization but can be used without having to change the shader code. After decoding, the filter transformation needs to be reversed. This library provides three filters:\n\n- Octahedral filter (`meshopt_encodeFilterOct`/`meshopt_decodeFilterOct`) encodes quantized (snorm) normal or tangent vectors using octahedral encoding. Any number of bits <= 16 can be used with 4 bytes or 8 bytes per vector.\n- Quaternion filter (`meshopt_encodeFilterQuat`/`meshopt_decodeFilterQuat`) encodes quantized (snorm) quaternion vectors; this can be used to encode rotations or tangent frames. Any number of bits between 4 and 16 can be used with 8 bytes per vector.\n- Exponential filter (`meshopt_encodeFilterExp`/`meshopt_decodeFilterExp`) encodes single-precision floating-point vectors; this can be used to encode arbitrary floating-point data more efficiently. In addition to an arbitrary bit count (<= 24), the filter takes a \"mode\" parameter that allows specifying how the exponent sharing is performed to trade off compression ratio and quality:\n\n    - `meshopt_EncodeExpSeparate` does not share exponents and results in the largest output\n    - `meshopt_EncodeExpSharedVector` shares exponents between different components of the same vector\n    - `meshopt_EncodeExpSharedComponent` shares exponents between the same component in different vectors\n    - `meshopt_EncodeExpClamped` does not share exponents but clamps the exponent range to reduce exponent entropy\n\nNote that all filters are lossy and require the data to be deinterleaved with one attribute per stream; this faciliates efficient SIMD implementation of filter decoders, allowing the overall decompression speed to be close to that of the raw codec.\n\n## Triangle strip conversion\n\nOn most hardware, indexed triangle lists are the most efficient way to drive the GPU. However, in some cases triangle strips might prove beneficial:\n\n- On some older GPUs, triangle strips may be a bit more efficient to render\n- On extremely memory constrained systems, index buffers for triangle strips could save a bit of memory\n\nThis library provides an algorithm for converting a vertex cache optimized triangle list to a triangle strip:\n\n```c++\nstd::vector<unsigned int> strip(meshopt_stripifyBound(index_count));\nunsigned int restart_index = ~0u;\nsize_t strip_size = meshopt_stripify(&strip[0], indices, index_count, vertex_count, restart_index);\n```\n\nTypically you should expect triangle strips to have ~50-60% of indices compared to triangle lists (~1.5-1.8 indices per triangle) and have ~5% worse ACMR.\nNote that triangle strips can be stitched with or without restart index support. Using restart indices can result in ~10% smaller index buffers, but on some GPUs restart indices may result in decreased performance.\n\nTo reduce the triangle strip size further, it's recommended to use `meshopt_optimizeVertexCacheStrip` instead of `meshopt_optimizeVertexCache` when optimizing for vertex cache. This trades off some efficiency in vertex transform for smaller index buffers.\n\n## Deinterleaved geometry\n\nAll of the examples above assume that geometry is represented as a single vertex buffer and a single index buffer. This requires storing all vertex attributes - position, normal, texture coordinate, skinning weights etc. - in a single contiguous struct. However, in some cases using multiple vertex streams may be preferable. In particular, if some passes require only positional data - such as depth pre-pass or shadow map - then it may be beneficial to split it from the rest of the vertex attributes to make sure the bandwidth use during these passes is optimal. On some mobile GPUs a position-only attribute stream also improves efficiency of tiling algorithms.\n\nMost of the functions in this library either only need the index buffer (such as vertex cache optimization) or only need positional information (such as overdraw optimization). However, several tasks require knowledge about all vertex attributes.\n\nFor indexing, `meshopt_generateVertexRemap` assumes that there's just one vertex stream; when multiple vertex streams are used, it's necessary to use `meshopt_generateVertexRemapMulti` as follows:\n\n```c++\nmeshopt_Stream streams[] = {\n    {&unindexed_pos[0], sizeof(float) * 3, sizeof(float) * 3},\n    {&unindexed_nrm[0], sizeof(float) * 3, sizeof(float) * 3},\n    {&unindexed_uv[0], sizeof(float) * 2, sizeof(float) * 2},\n};\n\nstd::vector<unsigned int> remap(index_count);\nsize_t vertex_count = meshopt_generateVertexRemapMulti(&remap[0], NULL, index_count, index_count, streams, sizeof(streams) / sizeof(streams[0]));\n```\n\nAfter this `meshopt_remapVertexBuffer` needs to be called once for each vertex stream to produce the correctly reindexed stream. For shadow indexing, similarly `meshopt_generateShadowIndexBufferMulti` is available as a replacement.\n\nInstead of calling `meshopt_optimizeVertexFetch` for reordering vertices in a single vertex buffer for efficiency, calling `meshopt_optimizeVertexFetchRemap` and then calling `meshopt_remapVertexBuffer` for each stream again is recommended.\n\nFinally, when compressing vertex data, `meshopt_encodeVertexBuffer` should be used on each vertex stream separately - this allows the encoder to best utilize corellation between attribute values for different vertices.\n\n## Simplification\n\nAll algorithms presented so far don't affect visual appearance at all, with the exception of quantization that has minimal controlled impact. However, fundamentally the most effective way at reducing the rendering or transmission cost of a mesh is to make the mesh simpler.\n\nThis library provides two simplification algorithms that reduce the number of triangles in the mesh. Given a vertex and an index buffer, they generate a second index buffer that uses existing vertices in the vertex buffer. This index buffer can be used directly for rendering with the original vertex buffer (preferably after vertex cache optimization), or a new compact vertex/index buffer can be generated using `meshopt_optimizeVertexFetch` that uses the optimal number and order of vertices.\n\nThe first simplification algorithm, `meshopt_simplify`, follows the topology of the original mesh in an attempt to preserve attribute seams, borders and overall appearance. For meshes with inconsistent topology or many seams, such as faceted meshes, it can result in simplifier getting \"stuck\" and not being able to simplify the mesh fully. Therefore it's critical that identical vertices are \"welded\" together, that is, the input vertex buffer does not contain duplicates. Additionally, it may be worthwhile to weld the vertices without taking into account vertex attributes that aren't critical and can be rebuilt later.\n\n```c++\nfloat threshold = 0.2f;\nsize_t target_index_count = size_t(index_count * threshold);\nfloat target_error = 1e-2f;\n\nstd::vector<unsigned int> lod(index_count);\nfloat lod_error = 0.f;\nlod.resize(meshopt_simplify(&lod[0], indices, index_count, &vertices[0].x, vertex_count, sizeof(Vertex),\n    target_index_count, target_error, /* options= */ 0, &lod_error));\n```\n\nTarget error is an approximate measure of the deviation from the original mesh using distance normalized to `[0..1]` range (e.g. `1e-2f` means that simplifier will try to maintain the error to be below 1% of the mesh extents). Note that the simplifier attempts to produce the requested number of indices at minimal error, but because of topological restrictions and error limit it is not guaranteed to reach the target index count and can stop earlier.\n\nTo disable the error limit, `target_error` can be set to `FLT_MAX`. This makes it more likely that the simplifier will reach the target index count, but it may produce a mesh that looks significantly different from the original, so using the resulting error to control viewing distance would be required. Conversely, setting `target_index_count` to 0 will simplify the input mesh as much as possible within the specified error limit; this can be useful for generating LODs that should look good at a given viewing distance.\n\nThe second simplification algorithm, `meshopt_simplifySloppy`, doesn't follow the topology of the original mesh. This means that it doesn't preserve attribute seams or borders, but it can collapse internal details that are too small to matter better because it can merge mesh features that are topologically disjoint but spatially close.\n\n```c++\nfloat threshold = 0.2f;\nsize_t target_index_count = size_t(index_count * threshold);\nfloat target_error = 1e-1f;\n\nstd::vector<unsigned int> lod(index_count);\nfloat lod_error = 0.f;\nlod.resize(meshopt_simplifySloppy(&lod[0], indices, index_count, &vertices[0].x, vertex_count, sizeof(Vertex),\n    target_index_count, target_error, &lod_error));\n```\n\nThis algorithm will not stop early due to topology restrictions but can still do so if target index count can't be reached without introducing an error larger than target. It is 5-6x faster than `meshopt_simplify` when simplification ratio is large, and is able to reach ~20M triangles/sec on a desktop CPU (`meshopt_simplify` works at ~3M triangles/sec).\n\nBoth algorithms can also return the resulting normalized deviation that can be used to choose the correct level of detail based on screen size or solid angle; the error can be converted to object space by multiplying by the scaling factor returned by `meshopt_simplifyScale`. For example, given a mesh with a precomputed LOD and a prescaled error, the screen-space normalized error can be computed and used for LOD selection:\n\n```c++\n// lod_factor can be 1 or can be adjusted for more or less aggressive LOD selection\nfloat d = max(0, distance(camera_position, mesh_center) - mesh_radius);\nfloat e = d * (tan(camera_fovy / 2) * 2 / screen_height); // 1px in mesh space\nbool lod_ok = e * lod_factor >= lod_error;\n```\n\nWhen a sequence of LOD meshes is generated that all use the original vertex buffer, care must be taken to order vertices optimally to not penalize mobile GPU architectures that are only capable of transforming a sequential vertex buffer range. It's recommended in this case to first optimize each LOD for vertex cache, then assemble all LODs in one large index buffer starting from the coarsest LOD (the one with fewest triangles), and call `meshopt_optimizeVertexFetch` on the final large index buffer. This will make sure that coarser LODs require a smaller vertex range and are efficient wrt vertex fetch and transform.\n\n## Advanced simplification\n\nThe main simplification algorithm, `meshopt_simplify`, exposes additional options and functions that can be used to control the simplification process in more detail.\n\nFor basic customization, a number of options can be passed via `options` bitmask that adjust the behavior of the simplifier:\n\n- `meshopt_SimplifyLockBorder` restricts the simplifier from collapsing edges that are on the border of the mesh. This can be useful for simplifying mesh subsets independently, so that the LODs can be combined without introducing cracks.\n- `meshopt_SimplifyErrorAbsolute` changes the error metric from relative to absolute both for the input error limit as well as for the resulting error. This can be used instead of `meshopt_simplifyScale`.\n- `meshopt_SimplifySparse` improves simplification performance assuming input indices are a sparse subset of the mesh. This can be useful when simplifying small mesh subsets independently, and is intended to be used for meshlet simplification. For consistency, it is recommended to use absolute errors when sparse simplification is desired, as this flag changes the meaning of the relative errors.\n- `meshopt_SimplifyPrune` allows the simplifier to remove isolated components regardless of the topological restrictions inside the component. This is generally recommended for full-mesh simplification as it can improve quality and reduce triangle count; note that with this option, triangles connected to locked vertices may be removed as part of their component.\n\nWhile `meshopt_simplify` is aware of attribute discontinuities by default (and infers them through the supplied index buffer) and tries to preserve them, it can be useful to provide information about attribute values. This allows the simplifier to take attribute error into account which can improve shading (by using vertex normals), texture deformation (by using texture coordinates), and may be necessary to preserve vertex colors when textures are not used in the first place. This can be done by using a variant of the simplification function that takes attribute values and weight factors, `meshopt_simplifyWithAttributes`:\n\n```c++\nconst float nrm_weight = 0.5f;\nconst float attr_weights[3] = {nrm_weight, nrm_weight, nrm_weight};\n\nstd::vector<unsigned int> lod(index_count);\nfloat lod_error = 0.f;\nlod.resize(meshopt_simplifyWithAttributes(&lod[0], indices, index_count, &vertices[0].x, vertex_count, sizeof(Vertex),\n    &vertices[0].nx, sizeof(Vertex), attr_weights, 3, /* vertex_lock= */ NULL,\n    target_index_count, target_error, /* options= */ 0, &lod_error));\n```\n\nThe attributes are passed as a separate buffer (in the example above it's a subset of the same vertex buffer) and should be stored as consecutive floats; attribute weights are used to control the importance of each attribute in the simplification process. For normalized attributes like normals and vertex colors, a weight around 1.0 is usually appropriate; internally, a change of `1/weight` in attribute value over a distance `d` is approximately equivalent to a change of `d` in position. Using higher weights may be appropriate to preserve attribute quality at the cost of position quality. If the attribute has a different scale (e.g. unnormalized vertex colors in [0..255] range), the weight should be divided by the scaling factor (1/255 in this example).\n\nBoth the target error and the resulting error combine positional error and attribute error, so the error can be used to control the LOD while taking attribute quality into account, assuming carefully chosen weights.\n\nWhen using `meshopt_simplifyWithAttributes`, it is also possible to lock certain vertices by providing a `vertex_lock` array that contains a boolean value for each vertex in the mesh. This can be useful to preserve certain vertices, such as the boundary of the mesh, with more control than `meshopt_SimplifyLockBorder` option provides.\n\nSimplification currently assumes that the input mesh is using the same material for all triangles. If the mesh uses multiple materials, it is possible to split the mesh into subsets based on the material and simplify each subset independently, using `meshopt_SimplifyLockBorder` or `vertex_lock` to preserve material boundaries; however, this limits the collapses and as a result may reduce the resulting quality. An alternative approach is to encode information about the material into the vertex buffer, ensuring that all three vertices referencing the same triangle have the same material ID; this may require duplicating vertices on the boundary between materials. After this, simplification can be performed as usual, and after simplification per-triangle material information can be computed from the vertex material IDs. There is no need to inform the simplifier of the value of the material ID: the implicit boundaries created by duplicating vertices with conflicting material IDs will be preserved automatically.\n\n## Point cloud simplification\n\nIn addition to triangle mesh simplification, this library provides a function to simplify point clouds. The algorithm reduces the point cloud to a specified number of points while preserving the overall appearance, and can optionally take per-point colors into account:\n\n```c++\nconst float color_weight = 1;\nstd::vector<unsigned int> indices(target_count);\nindices.resize(meshopt_simplifyPoints(&indices[0], &points[0].x, points.size(), sizeof(Point),\n    &points[0].r, sizeof(Point), color_weight, target_count));\n```\n\nThe resulting indices can be used to render the simplified point cloud; to reduce the memory footprint, the point cloud can be reindexed to create an array of points from the indices.\n\n## Mesh shading\n\nModern GPUs are beginning to deviate from the traditional rasterization model. NVidia GPUs starting from Turing and AMD GPUs starting from RDNA2 provide a new programmable geometry pipeline that, instead of being built around index buffers and vertex shaders, is built around mesh shaders - a new shader type that allows to provide a batch of work to the rasterizer.\n\nUsing mesh shaders in context of traditional mesh rendering provides an opportunity to use a variety of optimization techniques, starting from more efficient vertex reuse, using various forms of culling (e.g. cluster frustum or occlusion culling) and in-memory compression to maximize the utilization of GPU hardware. Beyond traditional rendering mesh shaders provide a richer programming model that can synthesize new geometry more efficiently than common alternatives such as geometry shaders. Mesh shading can be accessed via Vulkan or Direct3D 12 APIs; please refer to [Introduction to Turing Mesh Shaders](https://developer.nvidia.com/blog/introduction-turing-mesh-shaders/) and [Mesh Shaders and Amplification Shaders: Reinventing the Geometry Pipeline](https://devblogs.microsoft.com/directx/coming-to-directx-12-mesh-shaders-and-amplification-shaders-reinventing-the-geometry-pipeline/) for additional information.\n\nTo use mesh shaders for conventional rendering efficiently, geometry needs to be converted into a series of meshlets; each meshlet represents a small subset of the original mesh and comes with a small set of vertices and a separate micro-index buffer that references vertices in the meshlet. This information can be directly fed to the rasterizer from the mesh shader. This library provides algorithms to create meshlet data for a mesh, and - assuming geometry is static - can compute bounding information that can be used to perform cluster culling, a technique that can reject a meshlet if it's invisible on screen.\n\nTo generate meshlet data, this library provides `meshopt_buildMeshlets` algorithm, which tries to balance topological efficiency (by maximizing vertex reuse inside meshlets) with culling efficiency (by minimizing meshlet radius and triangle direction divergence) and produces GPU-friendly data. As an alternative (that can be useful for load-time processing), `meshopt_buildMeshletsScan` can create the meshlet data using a vertex cache-optimized index buffer as a starting point by greedily aggregating consecutive triangles until they go over the meshlet limits. `meshopt_buildMeshlets` is recommended for offline data processing even if cone culling is not used.\n\n```c++\nconst size_t max_vertices = 64;\nconst size_t max_triangles = 124;\nconst float cone_weight = 0.0f;\n\nsize_t max_meshlets = meshopt_buildMeshletsBound(indices.size(), max_vertices, max_triangles);\nstd::vector<meshopt_Meshlet> meshlets(max_meshlets);\nstd::vector<unsigned int> meshlet_vertices(max_meshlets * max_vertices);\nstd::vector<unsigned char> meshlet_triangles(max_meshlets * max_triangles * 3);\n\nsize_t meshlet_count = meshopt_buildMeshlets(meshlets.data(), meshlet_vertices.data(), meshlet_triangles.data(), indices.data(),\n    indices.size(), &vertices[0].x, vertices.size(), sizeof(Vertex), max_vertices, max_triangles, cone_weight);\n```\n\nTo generate the meshlet data, `max_vertices` and `max_triangles` need to be set within limits supported by the hardware; for NVidia the values of 64 and 124 are recommended (`max_triangles` must be divisible by 4 so 124 is the value closest to official NVidia's recommended 126). `cone_weight` should be left as 0 if cluster cone culling is not used, and set to a value between 0 and 1 to balance cone culling efficiency with other forms of culling like frustum or occlusion culling.\n\nEach resulting meshlet refers to a portion of `meshlet_vertices` and `meshlet_triangles` arrays; the arrays are overallocated for the worst case so it's recommended to trim them before saving them as an asset / uploading them to the GPU:\n\n```c++\nconst meshopt_Meshlet& last = meshlets[meshlet_count - 1];\n\nmeshlet_vertices.resize(last.vertex_offset + last.vertex_count);\nmeshlet_triangles.resize(last.triangle_offset + ((last.triangle_count * 3 + 3) & ~3));\nmeshlets.resize(meshlet_count);\n```\n\nHowever depending on the application other strategies of storing the data can be useful; for example, `meshlet_vertices` serves as indices into the original vertex buffer but it might be worthwhile to generate a mini vertex buffer for each meshlet to remove the extra indirection when accessing vertex data, or it might be desirable to compress vertex data as vertices in each meshlet are likely to be very spatially coherent.\n\nFor optimal performance, it is recommended to further optimize each meshlet in isolation for better triangle and vertex locality by calling `meshopt_optimizeMeshlet` on vertex and index data like so:\n\n```c++\nmeshopt_optimizeMeshlet(&meshlet_vertices[m.vertex_offset], &meshlet_triangles[m.triangle_offset], m.triangle_count, m.vertex_count);\n```\n\nDifferent applications will choose different strategies for rendering meshlets; on a GPU capable of mesh shading, meshlets can be rendered directly; for example, a basic GLSL shader for `VK_EXT_mesh_shader` extension could look like this (parts omitted for brevity):\n\n```glsl\nlayout(binding = 0) readonly buffer Meshlets { Meshlet meshlets[]; };\nlayout(binding = 1) readonly buffer MeshletVertices { uint meshlet_vertices[]; };\nlayout(binding = 2) readonly buffer MeshletTriangles { uint8_t meshlet_triangles[]; };\n\nvoid main() {\n    Meshlet meshlet = meshlets[gl_WorkGroupID.x];\n    SetMeshOutputsEXT(meshlet.vertex_count, meshlet.triangle_count);\n\n    for (uint i = gl_LocalInvocationIndex; i < meshlet.vertex_count; i += gl_WorkGroupSize.x) {\n        uint index = meshlet_vertices[meshlet.vertex_offset + i];\n        gl_MeshVerticesEXT[i].gl_Position = world_view_projection * vec4(vertex_positions[index], 1);\n    }\n\n    for (uint i = gl_LocalInvocationIndex; i < meshlet.triangle_count; i += gl_WorkGroupSize.x) {\n        uint offset = meshlet.triangle_offset + i * 3;\n        gl_PrimitiveTriangleIndicesEXT[i] = uvec3(\n            meshlet_triangles[offset], meshlet_triangles[offset + 1], meshlet_triangles[offset + 2]);\n    }\n}\n```\n\nAfter generating the meshlet data, it's also possible to generate extra data for each meshlet that can be saved and used at runtime to perform cluster culling, where each meshlet can be discarded if it's guaranteed to be invisible. To generate the data, `meshlet_computeMeshletBounds` can be used:\n\n```c++\nmeshopt_Bounds bounds = meshopt_computeMeshletBounds(&meshlet_vertices[m.vertex_offset], &meshlet_triangles[m.triangle_offset],\n    m.triangle_count, &vertices[0].x, vertices.size(), sizeof(Vertex));\n```\n\nThe resulting `bounds` values can be used to perform frustum or occlusion culling using the bounding sphere, or cone culling using the cone axis/angle (which will reject the entire meshlet if all triangles are guaranteed to be back-facing from the camera point of view):\n\n```c++\nif (dot(normalize(cone_apex - camera_position), cone_axis) >= cone_cutoff) reject();\n```\n\n## Efficiency analyzers\n\nWhile the only way to get precise performance data is to measure performance on the target GPU, it can be valuable to measure the impact of these optimization in a GPU-independent manner. To this end, the library provides analyzers for all three major optimization routines. For each optimization there is a corresponding analyze function, like `meshopt_analyzeOverdraw`, that returns a struct with statistics.\n\n`meshopt_analyzeVertexCache` returns vertex cache statistics. The common metric to use is ACMR - average cache miss ratio, which is the ratio of the total number of vertex invocations to the triangle count. The worst-case ACMR is 3 (GPU has to process 3 vertices for each triangle); on regular grids the optimal ACMR approaches 0.5. On real meshes it usually is in [0.5..1.5] range depending on the amount of vertex splits. One other useful metric is ATVR - average transformed vertex ratio - which represents the ratio of vertex shader invocations to the total vertices, and has the best case of 1.0 regardless of mesh topology (each vertex is transformed once).\n\n`meshopt_analyzeVertexFetch` returns vertex fetch statistics. The main metric it uses is overfetch - the ratio between the number of bytes read from the vertex buffer to the total number of bytes in the vertex buffer. Assuming non-redundant vertex buffers, the best case is 1.0 - each byte is fetched once.\n\n`meshopt_analyzeOverdraw` returns overdraw statistics. The main metric it uses is overdraw - the ratio between the number of pixel shader invocations to the total number of covered pixels, as measured from several different orthographic cameras. The best case for overdraw is 1.0 - each pixel is shaded once.\n\nNote that all analyzers use approximate models for the relevant GPU units, so the numbers you will get as the result are only a rough approximation of the actual performance.\n\n## Specialized processing\n\nIn addition to the core optimization techniques, the library provides several specialized algorithms for specific rendering techniques and pipeline optimizations that require a particular configuration of vertex and index data.\n\n### Geometry shader adjacency\n\nFor algorithms that use geometry shaders and require adjacency information, this library can generate an index buffer with adjacency data:\n\n```c++\nstd::vector<unsigned int> adjacency(indices.size() * 2);\nmeshopt_generateAdjacencyIndexBuffer(&adjacency[0], &indices[0], indices.size(), &vertices[0].x, vertices.size(), sizeof(Vertex));\n```\n\nThis creates an index buffer suitable for rendering with triangle-with-adjacency topology, providing 3 extra vertices per triangle that represent vertices opposite to each triangle's edge. This data can be used to compute silhouettes and perform other types of local geometric processing in geometry shaders. To render the mesh with adjacency data, the index buffer should be used with `D3D_PRIMITIVE_TOPOLOGY_TRIANGLELIST_ADJ`/`VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST_WITH_ADJACENCY`/`GL_TRIANGLES_ADJACENCY` topology.\n\nNote that the use of geometry shaders may have a performance impact on some GPUs; in some cases alternative implementation strategies may be more efficient.\n\n### Tessellation with displacement mapping\n\nFor hardware tessellation with crack-free displacement mapping, this library can generate a special index buffer that supports PN-AEN tessellation:\n\n```c++\nstd::vector<unsigned int> tess(indices.size() * 4);\nmeshopt_generateTessellationIndexBuffer(&tess[0], &indices[0], indices.size(), &vertices[0].x, vertices.size(), sizeof(Vertex));\n```\n\nThis generates a 12-vertex patch for each input triangle with the following layout:\n\n- 0, 1, 2: original triangle vertices\n- 3, 4: opposing edge for edge 0, 1\n- 5, 6: opposing edge for edge 1, 2\n- 7, 8: opposing edge for edge 2, 0\n- 9, 10, 11: dominant vertices for corners 0, 1, 2\n\nThis allows the use of hardware tessellation to implement PN-AEN and/or displacement mapping without cracks along UV seams or normal discontinuities. To render the mesh, the index buffer should be used with `D3D_PRIMITIVE_TOPOLOGY_12_CONTROL_POINT_PATCHLIST`/`VK_PRIMITIVE_TOPOLOGY_PATCH_LIST` (`patchControlPoints=12`) topology. For more details please refer to the following papers: [Crack-Free Point-Normal Triangles using Adjacent Edge Normals](https://developer.download.nvidia.com/whitepapers/2010/PN-AEN-Triangles-Whitepaper.pdf), [Tessellation on Any Budget](https://www.nvidia.com/content/pdf/gdc2011/john_mcdonald.pdf) and [My Tessellation Has Cracks!](https://developer.download.nvidia.com/assets/gamedev/files/gdc12/GDC12_DUDASH_MyTessellationHasCracks.pdf).\n\n### Visibility buffers\n\nTo render geometry into visibility buffers, access to primitive index in fragment shader is required. While it is possible to use `SV_PrimitiveID`/`gl_PrimitiveID` in the fragment shader, this can result in suboptimal performance on some GPUs (notably, AMD RDNA1 and all NVidia GPUs), and may not be supported on mobile or console hardware. Using mesh shaders to generate primitive IDs is efficient but requires hardware support that is not universally available. To work around these limitations, this library provides a way to generate a special index buffer that uses provoking vertex to encode primitive IDs:\n\n```c++\nstd::vector<unsigned int> provoke(indices.size());\nstd::vector<unsigned int> reorder(vertices.size() + indices.size() / 3);\nreorder.resize(meshopt_generateProvokingIndexBuffer(&provoke[0], &reorder[0], &indices[0], indices.size(), vertices.size()));\n```\n\nThis generates a special index buffer along with a reorder table that satisfies two constraints:\n\n- `provoke[3 * tri] == tri`\n- `reorder[provoke[x]]` refers to the original triangle vertices\n\nTo render the mesh with provoking vertex data, the application should use `provoke` as an index buffer and a vertex shader that passes vertex index (`SV_VertexID`/`gl_VertexIndex`) via a `flat`/`nointerpolation` attribute to the fragment shader as a primitive index, and loads vertex data manually by computing the real vertex index based on `reorder` table (`reorder[gl_VertexIndex]`). For more details please refer to [Variable Rate Shading with Visibility Buffer Rendering](https://advances.realtimerendering.com/s2024/content/Hable/Advances_SIGGRAPH_2024_VisibilityVRS-SIGGRAPH_Advances_2024.pptx); naturally, this technique does not require VRS.\n\nNote: This assumes the provoking vertex is the first vertex of a triangle, which is true for all graphics APIs except OpenGL/WebGL. For OpenGL/WebGL, you may need to rotate each triangle (abc -> bca) in the resulting index buffer, or use the `glProvokingVertex` function (OpenGL 3.2+) or `WEBGL_provoking_vertex` extension (WebGL2) to change the provoking vertex convention. For WebGL2, this is highly recommended to avoid a variety of emulation slowdowns that happen by default if `flat` attributes are used, such as an implicit use of geometry shaders.\n\n## Memory management\n\nMany algorithms allocate temporary memory to store intermediate results or accelerate processing. The amount of memory allocated is a function of various input parameters such as vertex count and index count. By default memory is allocated using `operator new` and `operator delete`; if these operators are overloaded by the application, the overloads will be used instead. Alternatively it's possible to specify custom allocation/deallocation functions using `meshopt_setAllocator`, e.g.\n\n```c++\nmeshopt_setAllocator(malloc, free);\n```\n\n> Note that the library expects the allocation function to either throw in case of out-of-memory (in which case the exception will propagate to the caller) or abort, so technically the use of `malloc` above isn't safe. If you want to handle out-of-memory errors without using C++ exceptions, you can use `setjmp`/`longjmp` instead.\n\nVertex and index decoders (`meshopt_decodeVertexBuffer`, `meshopt_decodeIndexBuffer`, `meshopt_decodeIndexSequence`) do not allocate memory and work completely within the buffer space provided via arguments.\n\nAll functions have bounded stack usage that does not exceed 32 KB for any algorithms.\n\n## License\n\nThis library is available to anybody free of charge, under the terms of MIT License (see LICENSE.md).\n"
        },
        {
          "name": "USERS.md",
          "type": "blob",
          "size": 3.22265625,
          "content": "meshoptimizer is widely used in the games industry as well as in many pipelines for processing 3D content for real-time rendering. This document contains a small selection of projects that rely on meshoptimizer.\n\nFor brevity, the projects listed below are limited to commercial software or open source software that has 5000+ stars on GitHub. Please feel free to contribute additions via pull requests.\n\n# Games\n\nIf you are shipping a game that is using meshoptimizer, listing the library in the credits or documentation would be appreciated!\n\n- [Alan Wake 2 (2023)](https://www.remedygames.com/games/alan-wake-2)\n- [Baldur's Gate 3 (2023)](https://baldursgate3.game/)\n- [Cities: Skylines II (2023)](https://www.paradoxinteractive.com/games/cities-skylines-ii/about)\n- [Counter-Strike 2 (2023)](https://www.counter-strike.net/cs2)\n- [Deadlock](https://store.steampowered.com/app/1422450/Deadlock/)\n- [Dota 2 (2013)](https://www.dota2.com/home)\n- [Half-Life: Alyx (2020)](https://store.steampowered.com/app/546560/HalfLife_Alyx/)\n- [Jagged Alliance 3 (2023)](https://jaggedalliance3.thqnordic.com/)\n- [The Legend of Zelda: Tears of the Kingdom (2023)](https://zelda.nintendo.com/tears-of-the-kingdom/)\n- [Manifold Garden (2019)](https://manifold.garden)\n- [Monaco 2](https://store.steampowered.com/app/1063030/Monaco_2/)\n- [Ravenswatch (2023)](https://store.steampowered.com/app/2071280/Ravenswatch/)\n- [The Settlers: New Allies (2023)](https://www.ubisoft.com/en-us/game/the-settlers/new-allies)\n- [Sky: Children of the Light (2019)](https://www.thatskygame.com/)\n- [Stranded: Alien Dawn (2023)](https://www.strandedaliendawn.com/en-US)\n- [Tunnet (2023)](https://store.steampowered.com/app/2286390/Tunnet/)\n\n# Engines\n\nIf you are shipping an engine that is using meshoptimizer, listing the library in the documentation would be appreciated!\n\n- [Bevy](https://bevyengine.org/)\n- [bgfx](https://github.com/bkaradzic/bgfx)\n- [filament](https://github.com/google/filament)\n- [Flax Engine](https://flaxengine.com/)\n- [The Forge](https://theforge.dev/)\n- [Godot](https://godotengine.org/)\n- [HypeHype](https://hypehype.com/en)\n- [Luxe Engine](https://luxeengine.com/)\n- [LWJGL](https://www.lwjgl.org/)\n- [Qt Quick 3D](https://doc.qt.io/qt-6/qtquick3d-index.html)\n- [Roblox](https://www.roblox.com/)\n- [Unigine](https://unigine.com/)\n- [Wicked Engine](https://wickedengine.net/)\n\nmeshoptimizer is also used in [Waymo](https://waymo.com/) internal stack.\n\n# Web\n\nmeshoptimizer supports various web projects through [meshoptimizer.js](https://www.npmjs.com/package/meshoptimizer).\nFor projects in the glTF ecosystem, [gltfpack](https://github.com/zeux/meshoptimizer/tree/master/gltf#-gltfpack) is developed alongside meshoptimizer, and `EXT_meshopt_compression` glTF extension is implemented by meshoptimizer.js.\n\nThis list contains a small selection of popular projects in the web ecosystem that use meshoptimizer; see also [a list of projects that depend on meshoptimizer through NPM](https://github.com/zeux/meshoptimizer/network/dependents).\n\n- [aframe](https://aframe.io/)\n- [Babylon.js](https://www.babylonjs.com/)\n- [CesiumJS](https://cesium.com/platform/cesiumjs/)\n- [three.js](https://threejs.org/)\n- [glTF-Transform](https://gltf-transform.dev/)\n- [Wonderland Engine](https://wonderlandengine.com/)\n"
        },
        {
          "name": "config.cmake.in",
          "type": "blob",
          "size": 0.1220703125,
          "content": "@PACKAGE_INIT@\r\n\r\ninclude(\"${CMAKE_CURRENT_LIST_DIR}/meshoptimizerTargets.cmake\")\r\ncheck_required_components(meshoptimizer)\r\n"
        },
        {
          "name": "demo",
          "type": "tree",
          "content": null
        },
        {
          "name": "extern",
          "type": "tree",
          "content": null
        },
        {
          "name": "gltf",
          "type": "tree",
          "content": null
        },
        {
          "name": "js",
          "type": "tree",
          "content": null
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}