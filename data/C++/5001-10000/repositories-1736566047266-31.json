{
  "metadata": {
    "timestamp": 1736566047266,
    "page": 31,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "alibaba/MNN",
      "stars": 8914,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 5.6982421875,
          "content": "\n# Created by https://www.gitignore.io/api/python,cmake,xcode,androidstudio\n# Edit at https://www.gitignore.io/?templates=python,cmake,xcode,androidstudio\n\n### AndroidStudio ###\n# Covers files to be ignored for android development using Android Studio.\n\n# Built application files\n*.apk\n*.ap_\n\n# Files for the ART/Dalvik VM\n*.dex\n\n# Java class files\n*.class\n\n# Generated files\nbin/\ngen/\nout/\n\n# Gradle files\n.gradle\n.gradle/\nbuild/\nbuildvisionOs/\n\n# Signing files\n.signing/\n\n# Local configuration file (sdk path, etc)\nlocal.properties\n\n# Proguard folder generated by Eclipse\nproguard/\n\n# Log Files\n*.log\n\n# Android Studio\n/*/build/\n/*/local.properties\n/*/out\n/*/*/build\n/*/*/production\ncaptures/\n.navigation/\n*.ipr\n*~\n*.swp\n\n# Android Patch\ngen-external-apklibs\n\n# External native build folder generated in Android Studio 2.2 and later\n.externalNativeBuild\n\n# NDK\nobj/\n\n# IntelliJ IDEA\n*.iml\n*.iws\n/out/\n\n# User-specific configurations\n.idea/caches/\n.idea/libraries/\n.idea/shelf/\n.idea/workspace.xml\n.idea/tasks.xml\n.idea/.name\n.idea/compiler.xml\n.idea/copyright/profiles_settings.xml\n.idea/encodings.xml\n.idea/misc.xml\n.idea/modules.xml\n.idea/scopes/scope_settings.xml\n.idea/dictionaries\n.idea/vcs.xml\n.idea/jsLibraryMappings.xml\n.idea/datasources.xml\n.idea/dataSources.ids\n.idea/sqlDataSources.xml\n.idea/dynamic.xml\n.idea/uiDesigner.xml\n.idea/assetWizardSettings.xml\n\n# OS-specific files\n.DS_Store\n.DS_Store?\n._*\n.Spotlight-V100\n.Trashes\nehthumbs.db\nThumbs.db\n\n# Legacy Eclipse project files\n.classpath\n.project\n.cproject\n.settings/\n\n# Mobile Tools for Java (J2ME)\n.mtj.tmp/\n\n# Package Files #\n*.war\n*.ear\n\n# virtual machine crash logs (Reference: http://www.java.com/en/download/help/error_hotspot.xml)\nhs_err_pid*\n\n## Plugin-specific files:\n\n# mpeltonen/sbt-idea plugin\n.idea_modules/\n\n# JIRA plugin\natlassian-ide-plugin.xml\n\n# Mongo Explorer plugin\n.idea/mongoSettings.xml\n\n# Crashlytics plugin (for Android Studio and IntelliJ)\ncom_crashlytics_export_strings.xml\ncrashlytics.properties\ncrashlytics-build.properties\nfabric.properties\n\n### AndroidStudio Patch ###\n\n!/gradle/wrapper/gradle-wrapper.jar\n\n### CMake ###\nCMakeLists.txt.user\nCMakeCache.txt\nCMakeFiles\nCMakeScripts\nTesting\nMakefile\ncmake_install.cmake\ninstall_manifest.txt\ncompile_commands.json\nCTestTestfile.cmake\n\n### Python ###\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[od]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\nlocal_settings.py\ndb.sqlite3\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n### Python Patch ###\n.venv/\n\n### Xcode ###\n# Xcode\n#\n# gitignore contributors: remember to update Global/Xcode.gitignore, Objective-C.gitignore & Swift.gitignore\n\n## User settings\nxcuserdata/\n\n## compatibility with Xcode 8 and earlier (ignoring not required starting Xcode 9)\n*.xcscmblueprint\n*.xccheckout\n\n## compatibility with Xcode 3 and earlier (ignoring not required starting Xcode 4)\nDerivedData/\n*.moved-aside\n*.pbxuser\n!default.pbxuser\n*.mode1v3\n!default.mode1v3\n*.mode2v3\n!default.mode2v3\n*.perspectivev3\n!default.perspectivev3\n\n### Xcode Patch ###\n*.xcodeproj/*\n!*.xcodeproj/project.pbxproj\n!*.xcodeproj/xcshareddata/\n!*.xcworkspace/contents.xcworkspacedata\n/*.gcno\n**/xcshareddata/WorkspaceSettings.xcsettings\nPods\n\n# End of https://www.gitignore.io/api/python,cmake,xcode,androidstudio\n\n\n\n### VSCode\n.vscode\n.tags\n\n### Build Result\nbuild32\nbuild64\nbuild.mac/\n\n### Projects\n*.podspec.json\ndemo/android/.idea\ndemo/android/.idea/gradle.xml\ndemo/android/.idea/misc.xml\ndemo/android/.idea/runConfigurations.xml\ndemo/android/.idea/vcs.xml\ndemo/android/.idea/caches/build_file_checksums.ser\ndemo/android/app/libs/\nproject/android/.idea/.name\nproject/android/.idea/gradle.xml\nproject/android/.idea/misc.xml\nproject/android/.idea/modules.xml\nproject/android/.idea/runConfigurations.xml\nproject/android/.idea/vcs.xml\nproject/android/.idea/caches/build_file_checksums.ser\n\n### Temps\n3rd_party/flatbuffers/tmp\n# FIXME(haijing): Xcode pre-build stage breaks compilation of flatbuffers by setting envs that do cmake cross-compilation for iOS\n# schema/current\nschema/private\ntools/converter/source/IR\nbenchmark/benchmark.txt\n\n### Python MNN\npymnn/android/build/\npymnn/android/local.properties\npymnn/android/.idea\npymnn/android/.idea/.name\npymnn/android/.idea/gradle.xml\npymnn/android/.idea/misc.xml\npymnn/android/.idea/modules.xml\npymnn/android/.idea/runConfigurations.xml\npymnn/android/.idea/vcs.xml\npymnn/android/.idea/caches/build_file_checksums.ser\npymnn/src/pybind_private/\n\nbuildios\nbuild*/\ninclude/MNN/VCS.h\nsource/backend/opengl/AllShader.cpp\ninclude/MNN/backend/opengl/shaders/AllShader.h\n.idea\nproject/ios/ios_64\nproject/ios/ios_32\nproject/ios/MNN.framework\n\npymnn_build/\n\n# mnncompress generated\nMNN_compression_pb2.py\n"
        },
        {
          "name": ".readthedocs.yaml",
          "type": "blob",
          "size": 1.00390625,
          "content": "# Read the Docs configuration file for Sphinx projects\n# See https://docs.readthedocs.io/en/stable/config-file/v2.html for details\n\n# Required\nversion: 2\n\n# Set the OS, Python version and other tools you might need\nbuild:\n  os: ubuntu-22.04\n  tools:\n    python: \"3.12\"\n    # You can also specify other tool versions:\n    # nodejs: \"20\"\n    # rust: \"1.70\"\n    # golang: \"1.20\"\n\n# Build documentation in the \"docs/\" directory with Sphinx\nsphinx:\n  configuration: docs/conf.py\n  # You can configure Sphinx to use a different builder, for instance use the dirhtml builder for simpler URLs\n  # builder: \"dirhtml\"\n  # Fail on all warnings to avoid broken references\n  # fail_on_warning: true\n\n# Optionally build your docs in additional formats such as PDF and ePub\n# formats:\n#   - pdf\n#   - epub\n\n# Optional but recommended, declare the Python requirements required\n# to build your documentation\n# See https://docs.readthedocs.io/en/stable/guides/reproducible-builds.html\npython:\n  install:\n    - requirements: docs/requirements.txt\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 5.7548828125,
          "content": "git:\n  depth: 3\n  quiet: true\nmatrix:\n  include:\n    - os: osx\n      language: cpp\n      osx_image: xcode11.2\n      compiler: clang\n      script:\n        - ./ciscripts/macOS/CPU_Metal.sh\n      name: \"macOS11.2 | CPU_Metal\"\n      env:\n        - MNNCITARGET=MACOSCPUMETAL\n    - os: osx\n      language: cpp\n      osx_image: xcode11.2\n      compiler: clang\n      script:\n        - ./ciscripts/macOS/CPU.sh\n      name: \"macOS11.2 | CPU\"\n      env:\n        - MNNCITARGET=MACOSCPU\n    - os: osx\n      language: cpp\n      osx_image: xcode11.2\n      compiler: clang\n      script:\n        - ./ciscripts/iOS/Xcode.sh\n      name: \"iOS | CPU_Metal | Xcode\"\n      env:\n        - MNNCITARGET=IOSCPUMETALXCODE\n    - os: osx\n      language: cpp\n      osx_image: xcode11.2\n      compiler: clang\n      script:\n        - ./ciscripts/iOS/CMake.sh\n      name: \"iOS | CPU_Metal | CMake\"\n      env:\n        - MNNCITARGET=IOSCPUMETALCMAKE\n    - os: linux\n      sudo: required\n      dist: bionic\n      language: cpp\n      install:\n        - sudo apt-get install ant libprotobuf-dev libvulkan-dev libglew-dev freeglut3-dev protobuf-compiler ocl-icd-opencl-dev libglfw3-dev\n      compiler: gcc\n      script:\n        - ./ciscripts/Linux/CL_ThreadPool_Vulkan.sh\n      name: \"Linux | CPU_CL_ThreadPool_Vulkan\"\n      env:\n        - MNNCITARGET=LINUXCLTHREADPOOLVULKAN\n    - os: linux\n      sudo: required\n      dist: bionic\n      language: cpp\n      install:\n        - sudo apt-get install ant libprotobuf-dev libvulkan-dev libglew-dev freeglut3-dev protobuf-compiler ocl-icd-opencl-dev libglfw3-dev\n      compiler: gcc\n      script:\n        - ./ciscripts/Linux/CL_OMP_Vulkan.sh\n      name: \"Linux | CPU_CL_OMP_Vulkan\"\n      env:\n        - MNNCITARGET=LINUXCLOMPVULKAN\n    - os: linux\n      sudo: required\n      dist: trusty\n      language: android\n      compiler: clang\n      android:\n        components:\n          - tools\n          - build-tools\n          - platform-tools\n          - android-21\n        licenses:\n          - 'android-sdk-preview-license-.+'\n          - 'android-sdk-license-.+'\n          - 'google-gdk-license-.+'\n      before_script:\n        - sudo apt-get install ant libprotobuf-dev protobuf-compiler\n        - sudo apt-get remove cmake\n        - echo yes | sdkmanager \"ndk-bundle\"\n        - echo yes | sdkmanager \"cmake;3.10.2.4988404\"\n        - export ANDROID_NDK=$ANDROID_HOME/ndk-bundle\n        - export PATH=/usr/local/android-sdk/cmake/3.10.2.4988404/bin/:$PATH\n      script:\n        - ./ciscripts/Android/32.sh\n      name: \"Android | AArch32_ThreadPool_Vulkan\"\n      env:\n        - MNNCITARGET=ARM32THREADPOOLVULKAN\n    - os: linux\n      sudo: required\n      dist: trusty\n      language: android\n      compiler: clang\n      android:\n        components:\n          - tools\n          - build-tools\n          - platform-tools\n          - android-21\n        licenses:\n          - 'android-sdk-preview-license-.+'\n          - 'android-sdk-license-.+'\n          - 'google-gdk-license-.+'\n      before_script:\n        - sudo apt-get install ant libprotobuf-dev protobuf-compiler\n        - echo yes | sdkmanager \"ndk-bundle\"\n        - echo yes | sdkmanager \"cmake;3.10.2.4988404\"\n        - export ANDROID_NDK=$ANDROID_HOME/ndk-bundle\n        - export PATH=/usr/local/android-sdk/cmake/3.10.2.4988404/bin/:$PATH\n      script:\n        - ./ciscripts/Android/32OMP.sh\n      name: \"Android | AArch32_OMP_Vulkan\"\n      env:\n        - MNNCITARGET=ARM32OMPVULKAN\n    - os: linux\n      sudo: required\n      dist: trusty\n      language: android\n      compiler: clang\n      android:\n        components:\n          - tools\n          - build-tools\n          - platform-tools\n          - android-21\n        licenses:\n          - 'android-sdk-preview-license-.+'\n          - 'android-sdk-license-.+'\n          - 'google-gdk-license-.+'\n      before_script:\n        - sudo apt-get install ant libprotobuf-dev protobuf-compiler\n        - echo yes | sdkmanager \"ndk-bundle\"\n        - echo yes | sdkmanager \"cmake;3.10.2.4988404\"\n        - export ANDROID_NDK=$ANDROID_HOME/ndk-bundle\n        - export PATH=/usr/local/android-sdk/cmake/3.10.2.4988404/bin/:$PATH\n      script:\n        - ./ciscripts/Android/64.sh\n      name: \"Android | AArch64_ThreadPool_Vulkan\"\n      env:\n        - MNNCITARGET=ARM64THREADPOOLVULKAN\n    - os: linux\n      sudo: required\n      dist: trusty\n      language: android\n      compiler: clang\n      android:\n        components:\n          - tools\n          - build-tools\n          - platform-tools\n          - android-21\n        licenses:\n          - 'android-sdk-preview-license-.+'\n          - 'android-sdk-license-.+'\n          - 'google-gdk-license-.+'\n      before_script:\n        - sudo apt-get install ant libprotobuf-dev protobuf-compiler\n        - echo yes | sdkmanager \"ndk-bundle\"\n        - echo yes | sdkmanager \"cmake;3.10.2.4988404\"\n        - export ANDROID_NDK=$ANDROID_HOME/ndk-bundle\n        - export PATH=/usr/local/android-sdk/cmake/3.10.2.4988404/bin/:$PATH\n      script:\n        - ./ciscripts/Android/64OMP.sh\n      name: \"Android | AArch64_OMP_Vulkan\"\n      env:\n        - MNNCITARGET=ARM64OMPVULKAN\n    - os: windows\n      language: cpp\n      install:\n        - PowerShell -Command 'Set-ExecutionPolicy -ExecutionPolicy RemoteSigned'\n        - choco install ninja\n      script:\n        - ciscripts/Windows/X64.bat\n      name: \"Windows | x64 CPU\"\n      env:\n        - MNNCITARGET=WINX64\n        - CXX=cl.exe\n        - CXX_FOR_BUILD=cl.exe\n        - CC=cl.exe\n        - CC_FOR_BUILD=cl.exe\n    - os: windows\n      language: cpp\n      install:\n        - PowerShell -Command 'Set-ExecutionPolicy -ExecutionPolicy RemoteSigned'\n        - choco install ninja\n      script:\n        - ciscripts/Windows/X86.bat\n      name: \"Windows | x86 CPU\"\n      env:\n        - MNNCITARGET=WINX86\n        - CXX=cl.exe\n        - CXX_FOR_BUILD=cl.exe\n        - CC=cl.exe\n        - CC_FOR_BUILD=cl.exe\n"
        },
        {
          "name": "3rd_party",
          "type": "tree",
          "content": null
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 36.052734375,
          "content": "cmake_minimum_required(VERSION 3.6)\n# Versioning stuff\nfile(STRINGS \"${CMAKE_CURRENT_LIST_DIR}/include/MNN/MNNDefine.h\" MNN_DEFINE)\nstring(REGEX MATCH \"MNN_VERSION_MAJOR [0-9]+\" MNN_VERSION_MAJOR_DEFINE ${MNN_DEFINE})\nstring(REGEX MATCH \"[0-9]+\" MNN_VERSION_MAJOR ${MNN_VERSION_MAJOR_DEFINE})\nstring(REGEX MATCH \"MNN_VERSION_MINOR [0-9]+\" MNN_VERSION_MINOR_DEFINE ${MNN_DEFINE})\nstring(REGEX MATCH \"[0-9]+\" MNN_VERSION_MINOR ${MNN_VERSION_MINOR_DEFINE})\nstring(REGEX MATCH \"MNN_VERSION_PATCH [0-9]+\" MNN_VERSION_PATCH_DEFINE ${MNN_DEFINE})\nstring(REGEX MATCH \"[0-9]+\" MNN_VERSION_PATCH ${MNN_VERSION_PATCH_DEFINE})\nset(MNN_VERSION ${MNN_VERSION_MAJOR}.${MNN_VERSION_MINOR}.${MNN_VERSION_PATCH})\n\n# Clear VERSION variables when no VERSION is given to project()\nif(POLICY CMP0048)\n  cmake_policy(SET CMP0048 NEW)\nendif()\n# MSVC runtime library flags are selected by an abstraction.\nif(POLICY CMP0091)\n  cmake_policy(SET CMP0091 NEW)\nendif()\nproject(MNN VERSION ${MNN_VERSION} LANGUAGES C CXX ASM)\n# complier options\nset(CMAKE_C_STANDARD 99)\nset(CMAKE_CXX_STANDARD 11)\nset(CMAKE_MODULE_PATH\n  ${CMAKE_MODULE_PATH}\n  \"${CMAKE_CURRENT_LIST_DIR}/cmake\"\n)\n\nif(WIN32)\n  if(NOT MSVC)\n    set(CMAKE_MSVC_RUNTIME_LIBRARY \"\")\n    set(MSVC_RUNTIME_LIBRARY \"\")\n  endif()\nendif()\n\n# build options\noption(MNN_USE_SYSTEM_LIB \"For opencl and vulkan, use system lib or use dlopen\" OFF)\noption(MNN_BUILD_HARD \"Build -mfloat-abi=hard or not\" OFF)\noption(MNN_BUILD_SHARED_LIBS \"MNN build shared or static lib\" ON)\noption(MNN_WIN_RUNTIME_MT \"MNN use /MT on Windows dll\" OFF)\noption(MNN_FORBID_MULTI_THREAD \"Disable Multi Thread\" OFF)\noption(MNN_OPENMP \"Use OpenMP's thread pool implementation. Does not work on iOS or Mac OS\" OFF)\noption(MNN_USE_THREAD_POOL \"Use MNN's own thread pool implementation\" ON)\noption(MNN_BUILD_TRAIN \"Build MNN's training framework\" OFF)\noption(MNN_BUILD_DEMO \"Build demo/exec or not\" OFF)\noption(MNN_BUILD_TOOLS \"Build tools/cpp or not\" ON)\noption(MNN_BUILD_QUANTOOLS \"Build Quantized Tools or not\" OFF)\noption(MNN_EVALUATION \"Build Evaluation Tools or not\" OFF)\noption(MNN_BUILD_CONVERTER \"Build Converter\" OFF)\noption(MNN_SUPPORT_DEPRECATED_OP \"Enable MNN's tflite quantized op\" OFF)\noption(MNN_DEBUG_MEMORY \"MNN Debug Memory Access\" OFF)\noption(MNN_DEBUG_TENSOR_SIZE \"Enable Tensor Size\" OFF)\noption(MNN_GPU_TRACE \"Enable MNN Gpu Debug\" OFF)\noption(MNN_SUPPORT_RENDER \"Enable MNN Render Ops\" OFF)\noption(MNN_SUPPORT_TRANSFORMER_FUSE \"Enable MNN transformer Fuse Ops\" OFF)\noption(MNN_PORTABLE_BUILD \"Link the static version of third party libraries where possible to improve the portability of built executables\" OFF)\noption(MNN_SEP_BUILD \"Build MNN Backends and expression separately. Only works with MNN_BUILD_SHARED_LIBS=ON\" ON)\noption(NATIVE_LIBRARY_OUTPUT \"Native Library Path\" OFF)\noption(NATIVE_INCLUDE_OUTPUT \"Native Include Path\" OFF)\noption(MNN_AAPL_FMWK \"Build MNN.framework instead of traditional .a/.dylib\" OFF)\noption(MNN_WITH_PLUGIN \"Build with plugin op support.\" OFF)\noption(MNN_BUILD_MINI \"Build MNN-MINI that just supports fixed shape models.\" OFF)\noption(MNN_USE_SSE \"Use SSE optimization for x86 if possiable\" ON)\noption(MNN_BUILD_CODEGEN \"Build with codegen\" OFF)\noption(MNN_ENABLE_COVERAGE \"Build with coverage enable\" OFF)\noption(MNN_BUILD_PROTOBUFFER \"Build with protobuffer in MNN\" ON)\noption(MNN_BUILD_OPENCV \"Build OpenCV api in MNN.\" OFF)\noption(MNN_BUILD_LLM \"Build llm library based MNN.\" OFF)\noption(MNN_BUILD_DIFFUSION \"Build diffusion demo based MNN.\" OFF)\noption(MNN_INTERNAL \"Build with MNN internal features, such as model authentication, metrics logging\" OFF)\noption(MNN_JNI \"Build MNN Jni for java to use\" OFF)\noption(MNN_SUPPORT_BF16 \"Enable MNN's bf16 op\" OFF)\noption(MNN_LOW_MEMORY \"Build MNN support low memory for weight quant model.\" OFF)\noption(MNN_CPU_WEIGHT_DEQUANT_GEMM \"Build MNN CPU weight dequant related gemm kernels.\" OFF)\noption(MNN_BUILD_AUDIO \"Build audio api in MNN.\" OFF)\n\nIF (OHOS AND MNN_INTERNAL)\n  include($ENV{NODE_PATH}/@ali/tcpkg/tcpkg.cmake)\n  export_headers(DIR ${CMAKE_SOURCE_DIR}/include/MNN)\n  IF (MNN_BUILD_OPENCV)\n    export_headers(DIR ${CMAKE_SOURCE_DIR}/tools/cv/include/cv)\n  ENDIF()\nENDIF()\n\nIF (NOT DEFINED MNN_USE_SPARSE_COMPUTE)\n   set(MNN_USE_SPARSE_COMPUTE ON)\nENDIF()\n\nIF(NOT MNN_BUILD_SHARED_LIBS AND MNN_SEP_BUILD)\n  message(WARNING \"Close MNN_SEP_BUILD for static library\")\n  SET(MNN_SEP_BUILD OFF CACHE BOOL \"<docstring>\" FORCE)\nENDIF()\nIF(APPLE AND MNN_AAPL_FMWK AND MNN_SEP_BUILD)\n  message(WARNING \"MNN_SEP_BUILD AND MNN_AAPL_FMWK can't coexist. Turning off MNN_SEP_BUILD\")\n  SET(MNN_SEP_BUILD OFF CACHE BOOL \"<docstring>\" FORCE)\nENDIF()\nIF(WIN32)\n  IF(MNN_SEP_BUILD)\n    message(WARNING \"MNN_SEP_BUILD IS TROUBLESOME ON Windows. Forcing OFF...\")\n    SET(MNN_SEP_BUILD OFF CACHE BOOL \"<docstring>\" FORCE)\n  ENDIF()\n  add_definitions(-D_CRT_SECURE_NO_WARNINGS)\n\n  IF(MSVC)\n    # generate optimized (release) exe and library with pdb debug file, https://stackoverflow.com/a/31264946\n    SET(CMAKE_EXE_LINKER_FLAGS_RELEASE \"${CMAKE_EXE_LINKER_FLAGS_RELEASE} /DEBUG /OPT:REF /OPT:ICF\")\n    SET(CMAKE_SHARED_LINKER_FLAGS_RELEASE \"${CMAKE_SHARED_LINKER_FLAGS_RELEASE} /DEBUG /OPT:REF /OPT:ICF\")\n    SET(CMAKE_C_FLAGS_RELEASE \"${CMAKE_C_FLAGS_RELEASE} /Zi\")\n    SET(CMAKE_CXX_FLAGS_RELEASE \"${CMAKE_CXX_FLAGS_RELEASE} /Zi\")\n\n    SET(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} /wd4267 /wd4018 /wd4251 /wd4996 /wd4244 /wd4146 /wd4129 /wd4305 /wd4275 /wd4101\")\n    SET(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /wd4267 /wd4018 /wd4251 /wd4996 /wd4244 /wd4146 /wd4129 /wd4305 /wd4275 /wd4101\")\n  ENDIF()\nENDIF()\n\n# for coverage test\nIF( MNN_ENABLE_COVERAGE)\n    SET(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fprofile-arcs -ftest-coverage\")\n    SET(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -fprofile-arcs -ftest-coverage\")\nENDIF()\n\nif ((CMAKE_SYSTEM_NAME STREQUAL \"Darwin\") AND CMAKE_OSX_ARCHITECTURES)\n  set(CMAKE_SYSTEM_PROCESSOR ${CMAKE_OSX_ARCHITECTURES})\nendif()\n\n# do this before protobuf, make sure wincrt config of protobuf and MNN is same\nif(MSVC)\n    # same as protobuf, otherwise config is inconsistent\n    if(CMAKE_VERSION VERSION_GREATER 3.15 OR CMAKE_VERSION VERSION_EQUAL 3.15)\n      set(CMAKE_MSVC_RUNTIME_LIBRARY MultiThreaded$<$<CONFIG:Debug>:Debug>)\n      if(NOT MNN_WIN_RUNTIME_MT)\n        set(CMAKE_MSVC_RUNTIME_LIBRARY ${CMAKE_MSVC_RUNTIME_LIBRARY}DLL)\n      endif()\n    else()\n      foreach(flag_var\n          CMAKE_C_FLAGS CMAKE_C_FLAGS_DEBUG CMAKE_C_FLAGS_RELEASE\n          CMAKE_C_FLAGS_MINSIZEREL CMAKE_C_FLAGS_RELWITHDEBINFO\n          CMAKE_CXX_FLAGS CMAKE_CXX_FLAGS_DEBUG CMAKE_CXX_FLAGS_RELEASE\n          CMAKE_CXX_FLAGS_MINSIZEREL CMAKE_CXX_FLAGS_RELWITHDEBINFO)\n          if (MNN_WIN_RUNTIME_MT)\n              if(${flag_var} MATCHES \"/MD\")\n                  string(REGEX REPLACE \"/MD\" \"/MT\" ${flag_var} \"${${flag_var}}\")\n              endif()\n          else ()\n              if(${flag_var} MATCHES \"/MT\")\n                  string(REGEX REPLACE \"/MT\" \"/MD\" ${flag_var} \"${${flag_var}}\")\n              endif()\n          endif ()\n      endforeach()\n    endif()\n    set(protobuf_BUILD_SHARED_LIBS ${MNN_BUILD_SHARED_LIBS})\nendif()\n\ninclude(${CMAKE_CURRENT_LIST_DIR}/cmake/macros.cmake)\nIF(MNN_BUILD_PROTOBUFFER)\nIF(MNN_BUILD_CONVERTER)\n  IF(MSVC)\n    set(protobuf_BUILD_SHARED_LIBS ${MNN_BUILD_SHARED_LIBS})\n    IF((NOT MNN_BUILD_SHARED_LIBS) AND (NOT MNN_WIN_RUNTIME_MT))\n      message(FATAL_ERROR \"When MNN_BUILD_CONVERTER=ON and MNN_BUILD_SHARED_LIBS=OFF, MNN_WIN_RUNTIME_MT must be ON. Because protobuf not support the config(static /MD)\")\n    ENDIF()\n  ENDIF()\n  add_subdirectory(${CMAKE_CURRENT_LIST_DIR}/3rd_party/protobuf/cmake)\nENDIF()\nENDIF()\n\n# specify source file encoding explicitly, fix cross-platform garbled output issue\n# we need do this after protobuf which set different execution-charset\nIF(MSVC)\n  set(CMAKE_C_FLAGS \"${CMAKE_CXX_FLAGS} /source-charset:utf-8\")\n  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /source-charset:utf-8\")\nENDIF()\n\nIF(CMAKE_CXX_COMPILER_ID STREQUAL \"GNU\" AND NOT MNN_BUILD_SHARED_LIBS AND NOT (MSVC OR WIN32))\n  SET(CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS}\")\n  SET(MNN_SEP_BUILD OFF CACHE BOOL \"<docstring>\" FORCE)\n  IF(MNN_BUILD_CONVERTER)\n    SET(MNN_PORTABLE_BUILD ON CACHE BOOL \"<docstring>\" FORCE)\n  ENDIF()\nENDIF()\n\nif(MNN_FORBID_MULTI_THREAD)\n    add_definitions(-DMNN_FORBIT_MULTI_THREADS)\nendif()\nif(MNN_SUPPORT_DEPRECATED_OP)\n    add_definitions(-DMNN_SUPPORT_DEPRECATED_OP)\nendif()\nif(MNN_SUPPORT_RENDER)\n    add_definitions(-DMNN_SUPPORT_RENDER)\nendif()\nif(MNN_SUPPORT_TRANSFORMER_FUSE)\n    add_definitions(-DMNN_SUPPORT_TRANSFORMER_FUSE)\nendif()\nif(MNN_BUILD_AUDIO)\n    add_definitions(-DMNN_BUILD_AUDIO)\nendif()\n# debug options\nif(MNN_DEBUG_MEMORY)\n    add_definitions(-DMNN_DEBUG_MEMORY)\nendif()\nif(MNN_DEBUG_TENSOR_SIZE)\n    add_definitions(-DMNN_DEBUG_TENSOR_SIZE)\nendif()\nif(MNN_GPU_TRACE)\n    add_definitions(-DMNN_GPU_FORCE_FINISH)\nendif()\n\n# backend options\noption(MNN_METAL \"Enable Metal\" OFF)\noption(MNN_OPENCL \"Enable OpenCL\" OFF)\noption(MNN_OPENGL \"Enable OpenGL\" OFF)\noption(MNN_VULKAN \"Enable Vulkan\" OFF)\noption(MNN_ARM82 \"Enable ARMv8.2's FP16 Compute\" ON)\noption(MNN_KLEIDIAI \"Enable KLEIDIAI\" OFF)\noption(MNN_ONEDNN \"Enable oneDNN\" OFF)\noption(MNN_AVX2 \"Open AVX2 Compile for x86 if possible\" ON)\noption(MNN_AVX512 \"Enable AVX512\" OFF)\noption(MNN_CUDA \"Enable CUDA\" OFF)\noption(MNN_TENSORRT \"Enable TensorRT\" OFF)\noption(MNN_COREML \"Enable CoreML\" OFF)\noption(MNN_NNAPI \"Enable NNAPI\" OFF)\n\noption(MNN_CUDA_PROFILE \"Enable CUDA profile\" OFF)\n\nif (NOT MNN_CUDA OR NOT CMAKE_SYSTEM_NAME MATCHES \"^Linux\")\n  set(MNN_CUDA_PROFILE OFF)\nendif()\n\nif (MNN_USE_THREAD_POOL)\n    message(STATUS \"Use Threadpool, forbid openmp\")\n    set(MNN_OPENMP OFF)\n    add_definitions(-DMNN_USE_THREAD_POOL)\nendif()\n\n# When build Android based on arm32 by MTL, force turn off MNN_ARM82\nif (CMAKE_SYSTEM_NAME MATCHES \"^Android\" AND CMAKE_SYSTEM_PROCESSOR MATCHES \"^armv7\" AND NOT MNN_BUILD_FOR_ANDROID_COMMAND)\n    message(STATUS \"force turn off MNN_ARM82 when build for Android based on arm32 by MTL\")\n    SET(MNN_ARM82 OFF CACHE BOOL \"Enable ARM82\" FORCE)\nendif()\n\n# target options\noption(MNN_BUILD_BENCHMARK \"Build benchmark or not\" OFF)\noption(MNN_BUILD_TEST \"Build tests or not\" OFF)\noption(MNN_BUILD_FOR_ANDROID_COMMAND \"Build from command\" OFF)\noption(MNN_USE_LOGCAT \"Use Logcat intead of print for info\" ON)\nset (MNN_HIDDEN FALSE)\nIF(CMAKE_BUILD_TYPE MATCHES Debug)\nELSE()\n    set(MNN_HIDDEN TRUE)\nENDIF(CMAKE_BUILD_TYPE MATCHES Debug)\n\nmessage(STATUS \">>>>>>>>>>>>>\")\nmessage(STATUS \"MNN BUILD INFO:\")\nmessage(STATUS \"\\tSystem: ${CMAKE_SYSTEM_NAME}\")\nmessage(STATUS \"\\tProcessor: ${CMAKE_SYSTEM_PROCESSOR}\")\nmessage(STATUS \"\\tVersion: ${MNN_VERSION}\")\nmessage(STATUS \"\\tMetal: ${MNN_METAL}\")\nmessage(STATUS \"\\tOpenCL: ${MNN_OPENCL}\")\nmessage(STATUS \"\\tOpenGL: ${MNN_OPENGL}\")\nmessage(STATUS \"\\tVulkan: ${MNN_VULKAN}\")\nmessage(STATUS \"\\tARM82: ${MNN_ARM82}\")\nmessage(STATUS \"\\tKleidiAI: ${MNN_KLEIDIAI}\")\nmessage(STATUS \"\\toneDNN: ${MNN_ONEDNN}\")\nmessage(STATUS \"\\tTensorRT: ${MNN_TENSORRT}\")\nmessage(STATUS \"\\tCoreML: ${MNN_COREML}\")\nmessage(STATUS \"\\tNNAPI: ${MNN_NNAPI}\")\nmessage(STATUS \"\\tCUDA: ${MNN_CUDA}\")\nmessage(STATUS \"\\tOpenMP: ${MNN_OPENMP}\")\nmessage(STATUS \"\\tBF16: ${MNN_SUPPORT_BF16}\")\nmessage(STATUS \"\\tThreadPool: ${MNN_USE_THREAD_POOL}\")\nmessage(STATUS \"\\tHidden: ${MNN_HIDDEN}\")\nmessage(STATUS \"\\tBuild Path: ${CMAKE_CURRENT_BINARY_DIR}\")\nmessage(STATUS \"\\tCUDA PROFILE: ${MNN_CUDA_PROFILE}\")\n\nif(CMAKE_SYSTEM_NAME MATCHES \"^Android\" OR CMAKE_SYSTEM_NAME MATCHES \"^Linux\")\n    add_definitions(-fPIC)\nendif()\n\n# Raspberry Pi 32-bit fix\nif(CMAKE_SYSTEM_NAME MATCHES \"^Linux\" AND CMAKE_SYSTEM_PROCESSOR MATCHES \"^armv7\")\n    add_definitions(-march=armv7-a -mfpu=neon-vfpv4)\nendif()\n\nif(CMAKE_SYSTEM_NAME MATCHES \"^Android\")\n    add_definitions(-DMNN_BUILD_FOR_ANDROID)\n    if(CMAKE_SYSTEM_PROCESSOR MATCHES \"^arm\")\n        add_definitions(-mfloat-abi=softfp -mfpu=neon)\n    endif()\nendif()\noption(MNN_USE_CPP11 \"Enable MNN use c++11\" ON)\nif (NOT MSVC)\n    if(MNN_CUDA AND MNN_SUPPORT_TRANSFORMER_FUSE)\n        set(CMAKE_CXX_STANDARD 17)\n        set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -std=gnu99\")\n        set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=c++17\")\n    elseif(MNN_USE_CPP11)\n        set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -std=gnu99\")\n        set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=c++11\")\n    else()\n        set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -std=gnu99\")\n        set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=c++0x\")\n    endif()\nendif()\n\nif(CMAKE_SYSTEM_NAME MATCHES \"^Linux\")\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -D__STRICT_ANSI__\")\n    if(CMAKE_SYSTEM_PROCESSOR MATCHES \"^armv7\")\n        add_definitions(-mfpu=neon)    #please define in project/cross-compile/arm.toolchain.cmake\n    endif()\n    if(MNN_BUILD_HARD)\n        add_definitions(-mfloat-abi=hard)  #better define in project/cross-compile/arm.toolchain.cmake\n    endif()\nendif()\n\nIF(MNN_DEBUG_MEMORY)\n    set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -fsanitize=address\")\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fsanitize=address\")\nendif()\n\nset(MNN_DEPS \"\")\nset(MNN_EXTRA_DEPENDS \"\")\n\nIF(CMAKE_BUILD_TYPE MATCHES Debug)\n    add_definitions(-DMNN_DEBUG -DDEBUG)\n    if(MSVC)\n        set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} /DEBUG\")\n        set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /DEBUG\")\n    else()\n        set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -g\")\n        set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -g\")\n    endif()\nelse()\n    if (MSVC)\n        set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} /O2\")\n        set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /O2\")\n    else()\n        set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -O3\")\n        set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -O3\")\n        if(CMAKE_SYSTEM_NAME MATCHES \"^Android\")\n            if(MNN_BUILD_FOR_ANDROID_COMMAND)\n                set(CMAKE_SHARED_LINKER_FLAGS \"${CMAKE_SHARED_LINKER_FLAGS} -s\")\n                set(CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS} -pie -fPIE -s\")\n                set(CMAKE_SHARED_LINKER_FLAGS \"${CMAKE_SHARED_LINKER_FLAGS} -Wl,--gc-sections\")\n            endif()\n        endif()\n    endif()\nENDIF(CMAKE_BUILD_TYPE MATCHES Debug)\nif(OHOS)\n    IF(MNN_USE_LOGCAT)\n        add_definitions(-DMNN_USE_LOGCAT)\n        add_definitions(-Wno-format-security)\n        list(APPEND MNN_EXTRA_DEPENDS libhilog_ndk.z.so)\n    ENDIF()\nendif()\nif(CMAKE_SYSTEM_NAME MATCHES \"^Android\")\n    IF(MNN_USE_LOGCAT)\n        add_definitions(-DMNN_USE_LOGCAT)\n    ENDIF()\n    IF (NOT MNN_BUILD_FOR_ANDROID_COMMAND)\n        set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${NATIVE_LIBRARY_OUTPUT}/${ANDROID_ABI})\n    ENDIF()\nendif()\n\nif(${CMAKE_SYSTEM_NAME} MATCHES \"^Linux\")\n    if((CMAKE_SYSTEM_PROCESSOR MATCHES \"^arm\") OR (CMAKE_SYSTEM_PROCESSOR MATCHES \"^aarch64\"))\n        set(aarch64_linux_include\n            #/usr/include/c++/4.9\n            #/usr/lib/gcc/x86_64-linux-gnu/4.9\n            #/usr/lib/gcc/x86_64-linux-gnu/4.9/include\n            #/usr/include/x86_64-linux-gnu/c++/4.9\n        )\n        include_directories(${aarch64_linux_include})\n    endif()\nendif()\ninclude_directories(${CMAKE_CURRENT_LIST_DIR}/include/\n                    ${CMAKE_CURRENT_LIST_DIR}/source/\n                    ${CMAKE_CURRENT_LIST_DIR}/express/\n                    ${CMAKE_CURRENT_LIST_DIR}/tools/\n                    ${CMAKE_CURRENT_LIST_DIR}/codegen/\n                    ${CMAKE_CURRENT_LIST_DIR}/schema/current/\n                    ${CMAKE_CURRENT_LIST_DIR}/3rd_party/\n                    ${CMAKE_CURRENT_LIST_DIR}/3rd_party/flatbuffers/include\n                    ${CMAKE_CURRENT_LIST_DIR}/3rd_party/half\n                    ${CMAKE_CURRENT_LIST_DIR}/3rd_party/imageHelper\n                    ${CMAKE_CURRENT_LIST_DIR}/3rd_party/OpenCLHeaders/\n                  )\n\n\nset(MNN_OBJECTS_TO_LINK \"\")\nset(MNN_TARGETS \"\")\n\n# Core\nFILE(GLOB MNN_Core_SRC ${CMAKE_CURRENT_LIST_DIR}/source/core/*)\nadd_library(MNNCore OBJECT ${MNN_Core_SRC})\nlist(APPEND MNN_OBJECTS_TO_LINK $<TARGET_OBJECTS:MNNCore>)\nlist(APPEND MNN_TARGETS MNNCore)\nif(MNN_BUILD_MINI)\n    target_compile_options(MNNCore PRIVATE -DMNN_BUILD_MINI)\nendif()\n\n# CV\nFILE(GLOB MNN_CV_SRC ${CMAKE_CURRENT_LIST_DIR}/source/cv/*)\nadd_library(MNNCV OBJECT ${MNN_CV_SRC})\nlist(APPEND MNN_OBJECTS_TO_LINK $<TARGET_OBJECTS:MNNCV>)\nlist(APPEND MNN_TARGETS MNNCV)\nif(CMAKE_SYSTEM_PROCESSOR MATCHES \"(x86_64)|(X86_64)|(x64)|(X64)|(amd64)|(AMD64)|(i686)\")\n    if (APPLE)\n        add_definitions(-fno-stack-check) # Workaround a Xcode 11.X bug\n    endif()\nendif()\n\n# Math\nFILE(GLOB MNN_Math_SRC ${CMAKE_CURRENT_LIST_DIR}/source/math/*)\nadd_library(MNNMath OBJECT ${MNN_Math_SRC})\nlist(APPEND MNN_OBJECTS_TO_LINK $<TARGET_OBJECTS:MNNMath>)\nlist(APPEND MNN_TARGETS MNNMath)\n\n# Transform\nFILE(GLOB_RECURSE MNN_Transform_SRC ${CMAKE_CURRENT_LIST_DIR}/source/shape/* ${CMAKE_CURRENT_LIST_DIR}/source/geometry/*)\nadd_library(MNNTransform OBJECT ${MNN_Transform_SRC})\nIF (NOT MNN_BUILD_MINI)\n    list(APPEND MNN_OBJECTS_TO_LINK $<TARGET_OBJECTS:MNNTransform>)\nENDIF()\nlist(APPEND MNN_TARGETS MNNTransform)\n\n# Utils\nFILE(GLOB MNN_Utils_SRC ${CMAKE_CURRENT_LIST_DIR}/source/utils/*)\nadd_library(MNNUtils OBJECT ${MNN_Utils_SRC})\nlist(APPEND MNN_OBJECTS_TO_LINK $<TARGET_OBJECTS:MNNUtils>)\nlist(APPEND MNN_TARGETS MNNUtils)\n\ninclude(${CMAKE_CURRENT_LIST_DIR}/source/backend/cpu/CMakeLists.txt)\n\n\nSET(MNN_PUB_HDRS \"\")\nSET(MNN_EXPR_PUB_HDRS \"\")\nset(MNN_EXTRA_HEADERS \"\")\n\nlist(APPEND MNN_PUB_HDRS \"${CMAKE_CURRENT_SOURCE_DIR}/include/MNN/MNNDefine.h\")\nlist(APPEND MNN_PUB_HDRS \"${CMAKE_CURRENT_SOURCE_DIR}/include/MNN/Interpreter.hpp\")\nlist(APPEND MNN_PUB_HDRS \"${CMAKE_CURRENT_SOURCE_DIR}/include/MNN/HalideRuntime.h\")\nlist(APPEND MNN_PUB_HDRS \"${CMAKE_CURRENT_SOURCE_DIR}/include/MNN/Tensor.hpp\")\nlist(APPEND MNN_PUB_HDRS \"${CMAKE_CURRENT_SOURCE_DIR}/include/MNN/ErrorCode.hpp\")\nlist(APPEND MNN_PUB_HDRS \"${CMAKE_CURRENT_SOURCE_DIR}/include/MNN/ImageProcess.hpp\")\nlist(APPEND MNN_PUB_HDRS \"${CMAKE_CURRENT_SOURCE_DIR}/include/MNN/Matrix.h\")\nlist(APPEND MNN_PUB_HDRS \"${CMAKE_CURRENT_SOURCE_DIR}/include/MNN/Rect.h\")\nlist(APPEND MNN_PUB_HDRS \"${CMAKE_CURRENT_SOURCE_DIR}/include/MNN/MNNForwardType.h\")\nlist(APPEND MNN_PUB_HDRS \"${CMAKE_CURRENT_SOURCE_DIR}/include/MNN/AutoTime.hpp\")\nlist(APPEND MNN_PUB_HDRS \"${CMAKE_CURRENT_SOURCE_DIR}/include/MNN/MNNSharedContext.h\")\nlist(APPEND MNN_EXPR_PUB_HDRS \"${CMAKE_CURRENT_SOURCE_DIR}/include/MNN/expr/Expr.hpp\")\nlist(APPEND MNN_EXPR_PUB_HDRS \"${CMAKE_CURRENT_SOURCE_DIR}/include/MNN/expr/ExprCreator.hpp\")\nlist(APPEND MNN_EXPR_PUB_HDRS \"${CMAKE_CURRENT_SOURCE_DIR}/include/MNN/expr/MathOp.hpp\")\nlist(APPEND MNN_EXPR_PUB_HDRS \"${CMAKE_CURRENT_SOURCE_DIR}/include/MNN/expr/NeuralNetWorkOp.hpp\")\nlist(APPEND MNN_EXPR_PUB_HDRS \"${CMAKE_CURRENT_SOURCE_DIR}/include/MNN/expr/Optimizer.hpp\")\nlist(APPEND MNN_EXPR_PUB_HDRS \"${CMAKE_CURRENT_SOURCE_DIR}/include/MNN/expr/Executor.hpp\")\nlist(APPEND MNN_EXPR_PUB_HDRS \"${CMAKE_CURRENT_SOURCE_DIR}/include/MNN/expr/Module.hpp\")\nlist(APPEND MNN_EXPR_PUB_HDRS \"${CMAKE_CURRENT_SOURCE_DIR}/include/MNN/expr/NeuralNetWorkOp.hpp\")\nlist(APPEND MNN_EXPR_PUB_HDRS \"${CMAKE_CURRENT_SOURCE_DIR}/include/MNN/expr/ExecutorScope.hpp\")\nlist(APPEND MNN_EXPR_PUB_HDRS \"${CMAKE_CURRENT_SOURCE_DIR}/include/MNN/expr/Scope.hpp\")\n\n# Add Extra Header\nIF(MNN_BUILD_OPENCV)\n  file(GLOB MNN_CV_HDRS ${CMAKE_CURRENT_SOURCE_DIR}/tools/cv/include/cv/*.hpp PARENT_SCOPE)\n  file(GLOB MNN_CV_IMGHDRS ${CMAKE_CURRENT_SOURCE_DIR}/tools/cv/include/cv/imgproc/*.hpp PARENT_SCOPE)\n  list(APPEND MNN_EXTRA_HEADERS ${MNN_CV_HDRS})\n  list(APPEND MNN_EXTRA_HEADERS ${MNN_CV_IMGHDRS})\nENDIF()\nIF(MNN_BUILD_AUDIO)\n  file(GLOB MNN_AUDIO_HDRS ${CMAKE_CURRENT_SOURCE_DIR}/tools/audio/include/audio/*.hpp PARENT_SCOPE)\n  list(APPEND MNN_EXTRA_HEADERS ${MNN_AUDIO_HDRS})\nENDIF()\nIF(MNN_BUILD_LLM)\n  file(GLOB MNN_LLM_HDRS ${CMAKE_CURRENT_SOURCE_DIR}/transformers/llm/engine/include/llm/*)\n  list(APPEND MNN_EXTRA_HEADERS ${CMAKE_CURRENT_SOURCE_DIR}/transformers/llm/engine/include/llm/llm.hpp)\nENDIF()\n\n\n\n# Add Thread dependency\nfind_package(Threads)\nlist(APPEND MNN_EXTRA_DEPENDS ${CMAKE_THREAD_LIBS_INIT})\nif(WIN32)\n  if(NOT MSVC)\n    set(CMAKE_SHARED_LINKER_FLAGS \"${CMAKE_SHARED_LINKER_FLAGS} -fuse-ld=lld-link -lmsvcrt\")\n    set(CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS} -fuse-ld=lld-link -lmsvcrt\")\n  endif()\nendif()\n\nif (NOT APPLE)\n  if(MNN_OPENMP)\n      message(STATUS \"[*] Checking OpenMP\")\n      find_package(OpenMP)\n      # For CMake < 3.9, we need to make the target ourselves\n      if(NOT TARGET OpenMP::OpenMP_CXX)\n          add_library(OpenMP::OpenMP_CXX IMPORTED INTERFACE)\n          set_property(TARGET OpenMP::OpenMP_CXX\n              PROPERTY INTERFACE_COMPILE_OPTIONS ${OpenMP_CXX_FLAGS})\n          # Only works if the same flag is passed to the linker; use CMake 3.9+ otherwise (Intel, AppleClang)\n          set_property(TARGET OpenMP::OpenMP_CXX\n              PROPERTY INTERFACE_LINK_LIBRARIES ${OpenMP_CXX_FLAGS} Threads::Threads)\n      endif()\n      # TODO: Don't pollute global CFLAGS\n      set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} ${OpenMP_C_FLAGS}\")\n      set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} ${OpenMP_CXX_FLAGS}\")\n      set(CMAKE_SHARED_LINKER_FLAGS \"${CMAKE_SHARED_LINKER_FLAGS} ${OpenMP_SHARED_LINKER_FLAGS}\")\n      set(CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS} ${OpenMP_EXE_LINKER_FLAGS}\")\n      if (MSVC)\n          set(OpenMP_C_FLAGS \"/openmp ${OpenMP_C_FLAGS}\")\n          set(OpenMP_CXX_FLAGS \"/openmp ${OpenMP_CXX_FLAGS}\")\n      endif()\n      list(APPEND MNN_EXTRA_DEPENDS OpenMP::OpenMP_CXX)\n    endif()\nendif()\n\nif ((NOT MSVC) AND MNN_HIDDEN)\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fvisibility-inlines-hidden -fvisibility=hidden\")\n    set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -fvisibility=hidden\")\n    # Omit frame pointer may cause difficult debug\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fomit-frame-pointer\")\nendif()\nif (NOT MSVC)\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fstrict-aliasing -ffunction-sections -fdata-sections -ffast-math -fno-rtti -fno-exceptions \")\n    set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -fstrict-aliasing -ffunction-sections -fdata-sections -ffast-math\")\nelse()\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /fp:precise\")\n    set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} /fp:precise\")\nendif()\n\n# Metal\nlist(APPEND MNN_DEPS MNN)\n\n# Plugin\nif(MNN_WITH_PLUGIN)\n    add_definitions(-DMNN_WITH_PLUGIN)\n    include(${CMAKE_CURRENT_LIST_DIR}/source/plugin/CMakeLists.txt)\nendif()\n\n# Metal\nif(MNN_METAL AND APPLE)\n    target_compile_options(MNNCore PRIVATE -DMNN_METAL_ENABLED=1)\n    include(${CMAKE_CURRENT_LIST_DIR}/source/backend/metal/CMakeLists.txt)\n    list(APPEND MNN_TARGETS MNNMetal)\n    list(APPEND MNN_OBJECTS_TO_LINK $<TARGET_OBJECTS:MNNMetal>)\nendif()\n\n# CoreML\nIF(MNN_COREML)\n    add_definitions(-DMNN_COREML_ENABLED=1)\n    include(${CMAKE_CURRENT_LIST_DIR}/source/backend/coreml/CMakeLists.txt)\n\n    list(APPEND MNN_TARGETS MNNCoreML)\n    list(APPEND MNN_OBJECTS_TO_LINK $<TARGET_OBJECTS:MNNCoreML>)\n\n    find_library(COREML CoreML)\n    find_library(FOUNDATION Foundation)\n    find_library(METAL Metal)\n    find_library(VIDEO CoreVideo)\n    list(APPEND MNN_EXTRA_DEPENDS ${COREML})\n    list(APPEND MNN_EXTRA_DEPENDS ${FOUNDATION})\n    list(APPEND MNN_EXTRA_DEPENDS ${METAL})\n    list(APPEND MNN_EXTRA_DEPENDS ${VIDEO})\nENDIF()\n\n# NNAPI\nIF(MNN_NNAPI)\n    add_definitions(-DMNN_NNAPI_ENABLED=1)\n    add_subdirectory(${CMAKE_CURRENT_LIST_DIR}/source/backend/nnapi/)\n    list(APPEND MNN_OBJECTS_TO_LINK $<TARGET_OBJECTS:MNN_NNAPI>)\nENDIF()\n\n# Vulkan\nIF(MNN_VULKAN)\n  add_subdirectory(${CMAKE_CURRENT_LIST_DIR}/source/backend/vulkan/)\n  IF(MNN_SEP_BUILD)\n    list(APPEND MNN_DEPS MNN_Vulkan)\n  ELSE()\n    list(APPEND MNN_TARGETS MNN_Vulkan)\n    list(APPEND MNN_OBJECTS_TO_LINK $<TARGET_OBJECTS:MNN_Vulkan>)\n    list(APPEND MNN_EXTRA_DEPENDS ${MNN_VULKAN_LIBS})\n  ENDIF()\nENDIF()\n\n# oneDNN\nIF(MNN_ONEDNN)\n    target_compile_definitions(MNNCPU PRIVATE \"-DMNN_USE_ONEDNN\")\n    add_dependencies(MNNCPU oneDNN)\n    include(cmake/oneDNN.cmake)\n    set(ONEDNN_DIR ${CMAKE_CURRENT_LIST_DIR}/3rd_party/oneDNN)\n    add_library(ONEDNN_COMMON OBJECT IMPORTED)\n    file(GLOB_RECURSE OBJECT_FILES ${ONEDNN_DIR}/src/common/CMakeFiles/dnnl_common.dir/*.o)\n    set_property(TARGET ONEDNN_COMMON PROPERTY IMPORTED_OBJECTS ${OBJECT_FILES})\n    add_library(ONEDNN_CPU OBJECT IMPORTED)\n    file(GLOB_RECURSE OBJECT_FILES ${ONEDNN_DIR}/src/cpu/CMakeFiles/dnnl_cpu.dir/*.o)\n    set_property(TARGET ONEDNN_CPU PROPERTY IMPORTED_OBJECTS ${OBJECT_FILES})\n    add_library(ONEDNN_CPU_X64 OBJECT IMPORTED)\n    file(GLOB_RECURSE OBJECT_FILES ${ONEDNN_DIR}/src/cpu/x64/CMakeFiles/dnnl_cpu_x64.dir/*.o)\n    set_property(TARGET ONEDNN_CPU_X64 PROPERTY IMPORTED_OBJECTS ${OBJECT_FILES})\n    include_directories(${ONEDNN_DIR}/include)\n    list(APPEND MNN_TARGETS ${ONEDNN_COMMON})\n    list(APPEND MNN_TARGETS ${ONEDNN_CPU})\n    list(APPEND MNN_TARGETS ${ONEDNN_CPU_X64})\n    list(APPEND MNN_OBJECTS_TO_LINK $<TARGET_OBJECTS:ONEDNN_COMMON>)\n    list(APPEND MNN_OBJECTS_TO_LINK $<TARGET_OBJECTS:ONEDNN_CPU>)\n    list(APPEND MNN_OBJECTS_TO_LINK $<TARGET_OBJECTS:ONEDNN_CPU_X64>)\nENDIF()\n\n# OpenCL\nIF(MNN_OPENCL)\n  add_subdirectory(${CMAKE_CURRENT_LIST_DIR}/source/backend/opencl/)\n  IF(MNN_SEP_BUILD)\n    list(APPEND MNN_DEPS MNN_CL)\n  ELSE()\n    add_definitions(-DMNN_OPENCL_ENABLED=1)\n    list(APPEND MNN_TARGETS MNN_CL)\n    list(APPEND MNN_OBJECTS_TO_LINK $<TARGET_OBJECTS:MNN_CL>)\n    list(APPEND MNN_EXTRA_DEPENDS ${MNN_OCL_LIBS})\n  ENDIF()\nENDIF()\n\n# OpenGL\nIF(MNN_OPENGL)\n  add_subdirectory(${CMAKE_CURRENT_LIST_DIR}/source/backend/opengl/)\n  IF(MNN_SEP_BUILD)\n    list(APPEND MNN_DEPS MNN_GL)\n  ELSE()\n    list(APPEND MNN_TARGETS MNN_GL)\n    list(APPEND MNN_OBJECTS_TO_LINK $<TARGET_OBJECTS:MNN_GL>)\n    list(APPEND MNN_EXTRA_DEPENDS GLESv3)\n    list(APPEND MNN_EXTRA_DEPENDS EGL)\n  ENDIF()\nENDIF()\n\n# CUDA\nIF(MNN_CUDA)\n  add_subdirectory(${CMAKE_CURRENT_LIST_DIR}/source/backend/cuda/)\n  list(APPEND MNN_TARGETS MNN_CUDA)\n  if (NOT MSVC)\n    list(APPEND MNN_OBJECTS_TO_LINK $<TARGET_OBJECTS:MNN_CUDA>)\n  endif()\n  list(APPEND MNN_EXTRA_DEPENDS ${MNN_CUDA_LIBS})\nENDIF()\n\n# Express\nadd_subdirectory(${CMAKE_CURRENT_LIST_DIR}/express/)\nIF(MNN_SEP_BUILD)\n  list(APPEND MNN_DEPS MNN_Express)\nELSE()\n   list(APPEND MNN_TARGETS MNN_Express)\n   list(APPEND MNN_OBJECTS_TO_LINK $<TARGET_OBJECTS:MNN_Express>)\nENDIF()\n\n# Model Internal. Enable MNN internal features such as model authentication and metrics logging.\nif (MNN_INTERNAL AND NOT OHOS) # TODO: support OHOS logging\n    target_compile_options(MNNCore PRIVATE -DMNN_INTERNAL_ENABLED)\n    target_compile_options(MNN_Express PRIVATE -DMNN_INTERNAL_ENABLED)\n    include(${CMAKE_CURRENT_LIST_DIR}/source/internal/logging/CMakeLists.txt)\n    if(CMAKE_SYSTEM_NAME MATCHES \"^Linux\")\n        list(APPEND MNN_EXTRA_DEPENDS \"-lcurl -lssl -lcrypto\")\n    endif()\nendif()\n\n# Train\nIF(MNN_BUILD_TRAIN OR MNN_BUILD_QUANTOOLS)\n  add_subdirectory(tools/train)\n  IF(MNN_SEP_BUILD)\n    list(APPEND MNN_DEPS MNNTrain)\n    list(APPEND MNN_DEPS MNNTrainUtils)\n  ELSE()\n    list(APPEND MNN_TARGETS MNNTrain)\n    list(APPEND MNN_TARGETS MNNTrainUtils)\n    list(APPEND MNN_OBJECTS_TO_LINK $<TARGET_OBJECTS:MNNTrain>)\n    list(APPEND MNN_OBJECTS_TO_LINK $<TARGET_OBJECTS:MNNTrainUtils>)\n  ENDIF()\nENDIF()\n\n#CodeGen\nIF(MNN_BUILD_CODEGEN)\n    add_definitions(-DMNN_BUILD_CODEGEN)\n    include(${CMAKE_CURRENT_LIST_DIR}/codegen/CMakeLists.txt)\nENDIF()\n\n# NPU\nIF(MNN_NPU)\n    add_subdirectory(${CMAKE_CURRENT_LIST_DIR}/source/backend/hiai/)\n    IF(MNN_SEP_BUILD)\n        list(APPEND MNN_DEPS MNN_NPU)\n    ELSE()\n        list(APPEND MNN_TARGETS MNN_NPU)\n        list(APPEND MNN_OBJECTS_TO_LINK $<TARGET_OBJECTS:MNN_NPU>)\n        list(APPEND MNN_EXTRA_DEPENDS ${CMAKE_CURRENT_LIST_DIR}/source/backend/hiai/3rdParty/${ANDROID_ABI}/libhiai.so)\n        list(APPEND MNN_EXTRA_DEPENDS ${CMAKE_CURRENT_LIST_DIR}/source/backend/hiai/3rdParty/${ANDROID_ABI}/libhiai_ir_build.so)\n        list(APPEND MNN_EXTRA_DEPENDS ${CMAKE_CURRENT_LIST_DIR}/source/backend/hiai/3rdParty/${ANDROID_ABI}/libhiai_ir.so)\n    ENDIF()\nENDIF()\n\n# TensorRT\nIF(MNN_TENSORRT)\n  add_subdirectory(${CMAKE_CURRENT_LIST_DIR}/source/backend/tensorrt/)\n  list(APPEND MNN_TARGETS MNN_TRT)\n  list(APPEND MNN_OBJECTS_TO_LINK $<TARGET_OBJECTS:MNN_TRT>)\n  list(APPEND MNN_EXTRA_DEPENDS ${MNN_TRT_LIBS})\nENDIF()\n\nIF(MNN_BUILD_LLM)\n    # add_definitions(-DMNN_BUILD_LLM)\n    include(${CMAKE_CURRENT_LIST_DIR}/transformers/llm/engine/CMakeLists.txt)\n    IF(NOT MNN_SEP_BUILD)\n      list(APPEND MNN_TARGETS llm)\n      list(APPEND MNN_OBJECTS_TO_LINK $<TARGET_OBJECTS:llm>)\n    ENDIF()\nENDIF()\n\nIF(MNN_SEP_BUILD)\n  add_library(MNN SHARED ${CMAKE_CURRENT_LIST_DIR}/cmake/dummy.cpp ${MNN_OBJECTS_TO_LINK} ${MNN_PUB_HDRS} ${MNN_EXPR_PUB_HDRS} ${MNN_EXTRA_HEADERS})\n  target_link_libraries(MNN PUBLIC ${MNN_EXTRA_DEPENDS})\nELSE()\n  IF(MNN_BUILD_SHARED_LIBS)\n    add_library(MNN SHARED ${CMAKE_CURRENT_LIST_DIR}/cmake/dummy.cpp ${MNN_OBJECTS_TO_LINK} ${MNN_PUB_HDRS} ${MNN_EXPR_PUB_HDRS} ${MNN_EXTRA_HEADERS})\n    if (WIN32)\n      foreach(TARGET ${MNN_TARGETS})\n        target_compile_definitions(${TARGET} PRIVATE \"-DBUILDING_MNN_DLL\")\n        target_compile_definitions(${TARGET} INTERFACE \"-DUSING_MNN_DLL\")\n      endforeach()\n      target_compile_definitions(MNN PRIVATE \"-DBUILDING_MNN_DLL\")\n      target_compile_definitions(MNN INTERFACE \"-DUSING_MNN_DLL\")\n    endif()\n  ELSE()\n    add_library(MNN STATIC ${CMAKE_CURRENT_LIST_DIR}/cmake/dummy.cpp ${MNN_OBJECTS_TO_LINK} ${MNN_PUB_HDRS} ${MNN_EXPR_PUB_HDRS} ${MNN_EXTRA_HEADERS})\n  ENDIF()\n  target_link_libraries(MNN PUBLIC ${MNN_EXTRA_DEPENDS})\nENDIF()\nif (MSVC)\n  target_link_options(MNN PRIVATE \"/IGNORE:4049,4217\")\n  if (MNN_CUDA)\n    if (MNN_BUILD_SHARED_LIBS)\n      target_link_options(MNN PRIVATE \"/WHOLEARCHIVE:$<TARGET_FILE:MNN_CUDA>\")\n    else()\n      add_custom_command(\n        TARGET MNN\n        POST_BUILD\n        COMMAND lib.exe ARGS /OUT:$<TARGET_FILE:MNN> $<TARGET_FILE:MNN> $<TARGET_FILE:MNN_CUDA>\n      )\n    endif()\n  endif()\nendif()\nif (MNN_ONEDNN)\n    add_dependencies(MNN ONEDNN_COMMON ONEDNN_CPU ONEDNN_CPU_X64)\nendif()\n\nif(APPLE)\n    IF(MNN_AAPL_FMWK)\n      set_target_properties(MNN PROPERTIES FRAMEWORK TRUE)\n      set_target_properties(MNN PROPERTIES\n          MACOSX_FRAMEWORK_IDENTIFIER com.alibaba.MNN\n          MACOSX_FRAMEWORK_SHORT_VERSION_STRING ${PACKAGE_VERSION}\n          MACOSX_FRAMEWORK_BUNDLE_VERSION ${PACKAGE_VERSION}\n          XCODE_ATTRIBUTE_CODE_SIGN_IDENTITY \"iPhone Developer\"\n      )\n      set_target_properties(MNN PROPERTIES MACOSX_FRAMEWORK_INFO_PLIST ${CMAKE_CURRENT_SOURCE_DIR}/project/ios/MNN/Info.plist)\n    ENDIF()\n    IF(MNN_METAL)\n      find_library(FOUNDATION Foundation REQUIRED)\n      target_link_libraries(MNN PUBLIC ${FOUNDATION})\n      find_library(METAL Metal REQUIRED)\n      target_link_libraries(MNN PUBLIC ${METAL})\n      find_library(GRAPHIC CoreGraphics)\n      target_link_libraries(MNN PUBLIC ${GRAPHIC})\n    ENDIF()\nendif()\nadd_dependencies(MNN MNNCore MNNCV MNNTransform MNNMath MNNCPU)\nadd_subdirectory(${CMAKE_CURRENT_LIST_DIR}/tools/converter)\nIF(WIN32 AND MNN_BUILD_CONVERTER AND MNN_BUILD_SHARED_LIBS)\n# Because of dllimport/dllexport, we merge MNN and MNNConvertDeps together, which depend protobuf\n  target_link_libraries(MNN PUBLIC ${Protobuf_LIBRARIES})\nENDIF()\n# Merge MNN/MNNExpress/MNNOpenCV and other backends into one .lib/.dll on Windows\nadd_subdirectory(${CMAKE_CURRENT_LIST_DIR}/tools/cv)\nIF(MNN_BUILD_OPENCV AND NOT MNN_SEP_BUILD)\n  IF(MSVC)\n    target_compile_definitions(MNNOpenCV PRIVATE \"-DBUILDING_MNN_DLL\" INTERFACE \"-DUSING_MNN_DLL\")\n  ENDIF()\n  target_sources(MNN PRIVATE $<TARGET_OBJECTS:MNNOpenCV>)\nENDIF()\nadd_subdirectory(${CMAKE_CURRENT_LIST_DIR}/tools/audio)\nIF(MNN_BUILD_AUDIO AND NOT MNN_SEP_BUILD)\n  IF(MSVC)\n    target_compile_definitions(MNNAudio PRIVATE \"-DBUILDING_MNN_DLL\" INTERFACE \"-DUSING_MNN_DLL\")\n  ENDIF()\n  message(STATUC \"### build MNNAudio into MNN\")\n  target_sources(MNN PRIVATE $<TARGET_OBJECTS:MNNAudio>)\nENDIF()\n\n\nif(CMAKE_SYSTEM_NAME MATCHES \"^Linux\")\n# Using -pthread, needed by thread-safe implemention of glibc, is better than only using -lpthread\n# https://stackoverflow.com/questions/23250863/difference-between-pthread-and-lpthread-while-compiling\n  target_link_libraries(MNN PUBLIC -pthread dl)\nelseif(CMAKE_SYSTEM_NAME MATCHES \"^Android\")\n  target_link_libraries(MNN PUBLIC log m)\nelse()\nendif()\nif (NOT MNN_BUILD_SHARED_LIBS)\n    if (CMAKE_CXX_COMPILER_ID MATCHES \"GNU\" OR CMAKE_CXX_COMPILER_ID MATCHES \"Clang\")\n        # Static-link will not replace thread-related weak symbol in glibc with strong symbol\n        # in pthread library, so we need use --whole-archive to pthread\n        # https://stackoverflow.com/questions/35116327/when-g-static-link-pthread-cause-segmentation-fault-why\n        if(CMAKE_SYSTEM_NAME MATCHES \"^Linux\")\n            set(MNN_DEPS -Wl,--whole-archive ${MNN_DEPS} -lpthread -Wl,--no-whole-archive)\n        else()\n          if(APPLE)\n            set(MNN_DEPS -Wl,-force_load ${MNN_DEPS})\n          else()\n            set(MNN_DEPS -Wl,--whole-archive ${MNN_DEPS} -Wl,--no-whole-archive)\n          endif()\n        endif()\n    endif()\nendif()\nlist(APPEND MNN_TARGETS MNN)\nlist(REMOVE_ITEM MNN_TARGETS MNN)\nIF(MNN_BUILD_DEMO)\ninclude(${CMAKE_CURRENT_LIST_DIR}/demo/exec/CMakeLists.txt)\nENDIF()\nIF(MNN_BUILD_DIFFUSION AND MNN_BUILD_OPENCV AND MNN_IMGCODECS)\ninclude(${CMAKE_CURRENT_LIST_DIR}/transformers/diffusion/CMakeLists.txt)\nENDIF()\nIF(MNN_BUILD_TOOLS)\ninclude(${CMAKE_CURRENT_LIST_DIR}/tools/cpp/CMakeLists.txt)\nENDIF()\nIF(MNN_BUILD_TEST)\ninclude(${CMAKE_CURRENT_LIST_DIR}/test/CMakeLists.txt)\nENDIF()\nIF(MNN_BUILD_BENCHMARK)\ninclude(${CMAKE_CURRENT_LIST_DIR}/benchmark/CMakeLists.txt)\nENDIF()\nIF(MNN_BUILD_QUANTOOLS)\ninclude(${CMAKE_CURRENT_LIST_DIR}/tools/quantization/CMakeLists.txt)\nENDIF()\nIF(MNN_EVALUATION)\ninclude(${CMAKE_CURRENT_LIST_DIR}/tools/evaluation/CMakeLists.txt)\nENDIF()\n\n# Install headers\nIF(CMAKE_SYSTEM_NAME MATCHES \"^Android\" AND NOT MNN_BUILD_FOR_ANDROID_COMMAND)\n    IF(NOT NATIVE_INCLUDE_OUTPUT)\n      set(NATIVE_INCLUDE_OUTPUT \".\")\n    ENDIF()\n    set(MNN_INCLUDE_OUTPUT ${NATIVE_INCLUDE_OUTPUT}/MNN)\n    add_custom_command(\n      TARGET MNN\n      POST_BUILD\n      COMMAND ${CMAKE_COMMAND}\n      -E make_directory \"${MNN_INCLUDE_OUTPUT}/\"\n    )\n    add_custom_command(\n      TARGET MNN\n      POST_BUILD\n      COMMAND ${CMAKE_COMMAND}\n      -E make_directory \"${MNN_INCLUDE_OUTPUT}/expr/\"\n    )\n    FOREACH(header ${MNN_PUB_HDRS})\n      add_custom_command(\n        TARGET MNN\n        POST_BUILD\n        COMMAND ${CMAKE_COMMAND}\n        ARGS -E copy ${header} \"${MNN_INCLUDE_OUTPUT}/\"\n      )\n    ENDFOREACH()\n    FOREACH(header ${MNN_EXPR_PUB_HDRS})\n      add_custom_command(\n        TARGET MNN\n        POST_BUILD\n        COMMAND ${CMAKE_COMMAND}\n        ARGS -E copy ${header} \"${MNN_INCLUDE_OUTPUT}/expr/\"\n      )\n    ENDFOREACH()\nELSEIF(NOT APPLE)\n  INSTALL(FILES ${MNN_PUB_HDRS} DESTINATION include/MNN/)\n  INSTALL(FILES ${MNN_EXPR_PUB_HDRS} DESTINATION include/MNN/expr/)\n  install(TARGETS MNN\n      LIBRARY DESTINATION lib\n      ARCHIVE DESTINATION lib\n  )\nELSE()\n  install(TARGETS MNN\n      LIBRARY DESTINATION lib\n      ARCHIVE DESTINATION lib\n      FRAMEWORK DESTINATION /Library/Frameworks/\n  )\n  IF(MNN_BUILD_OPENCV)\n    if (NOT MNN_AAPL_FMWK)\n        INSTALL(FILES ${MNN_CV_HDRS} DESTINATION include/MNN/cv)\n        INSTALL(FILES ${MNN_CV_IMGHDRS} DESTINATION include/MNN/cv/imgproc)\n    endif()\n    FOREACH(HDR ${MNN_CV_HDRS})\n      SET_SOURCE_FILES_PROPERTIES(${HDR} PROPERTIES MACOSX_PACKAGE_LOCATION Headers/cv/ )\n    ENDFOREACH()\n    FOREACH(HDR ${MNN_CV_IMGHDRS})\n      SET_SOURCE_FILES_PROPERTIES(${HDR} PROPERTIES MACOSX_PACKAGE_LOCATION Headers/cv/imgproc )\n    ENDFOREACH()\n  ENDIF()\n  IF(MNN_BUILD_AUDIO)\n    if (NOT MNN_AAPL_FMWK)\n      INSTALL(FILES ${MNN_AUDIO_HDRS} DESTINATION include/MNN/audio)\n    endif()\n    FOREACH(HDR ${MNN_AUDIO_HDRS})\n      SET_SOURCE_FILES_PROPERTIES(${HDR} PROPERTIES MACOSX_PACKAGE_LOCATION Headers/audio/ )\n    ENDFOREACH()\n  ENDIF()\n  IF(MNN_BUILD_LLM)\n    if (NOT MNN_AAPL_FMWK)\n        INSTALL(FILES ${MNN_LLM_HDRS} DESTINATION include/MNN/llm)\n    endif()\n    FOREACH(HDR ${MNN_LLM_HDRS})\n      SET_SOURCE_FILES_PROPERTIES(${HDR} PROPERTIES MACOSX_PACKAGE_LOCATION Headers/llm )\n    ENDFOREACH()\n  ENDIF()\n\n  if (NOT MNN_AAPL_FMWK)\n      INSTALL(FILES ${MNN_PUB_HDRS} DESTINATION include/MNN/)\n      INSTALL(FILES ${MNN_EXPR_PUB_HDRS} DESTINATION include/MNN/expr/)\n  endif()\n  FOREACH(HDR ${MNN_EXPR_PUB_HDRS})\n    SET_SOURCE_FILES_PROPERTIES(${HDR} PROPERTIES MACOSX_PACKAGE_LOCATION Headers/expr/ )\n  ENDFOREACH()\n  FOREACH(HDR ${MNN_PUB_HDRS})\n    SET_SOURCE_FILES_PROPERTIES(${HDR} PROPERTIES MACOSX_PACKAGE_LOCATION Headers/ )\n  ENDFOREACH()\n  IF(MNN_METAL)\n    SET_SOURCE_FILES_PROPERTIES(${CMAKE_CURRENT_BINARY_DIR}/mnn.metallib PROPERTIES MACOSX_PACKAGE_LOCATION Resources/)\n  ENDIF()\nENDIF()\nif (MNN_JNI)\n    add_subdirectory(${CMAKE_CURRENT_LIST_DIR}/source/jni/)\nendif()\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 3.5087890625,
          "content": "#  Contribute to My Amazing Fork of MNN \n\nThank you for considering contributing to this fantastic fork of MNN! Your contributions are like rocket fuel for this project, propelling us to new heights. Whether you're smashing bugs, adding awesome features, or turbocharging our documentation, you're a key player in this AI adventure. \n\n## Table of Contents\n- [How Can You Contribute?](#how-can-you-contribute)\n- [ Reporting Issues](#reporting-issues)\n- [ Feature Requests](#feature-requests)\n- [ Pull Requests](#pull-requests)\n- [ Coding Guidelines](#coding-guidelines)\n- [ License](#license)\n\n## How Can You Contribute?\n\nThere are several ways you can be part of this AI extravaganza:\n\n1. ** Report Issues:** Help us exterminate those pesky bugs by reporting them.\n2. ** Feature Requests:** Suggest mind-blowing features and improvements.\n3. ** Pull Requests:** Strap in and contribute code to launch this project to the stars.\n4. ** Documentation Improvements:** Create clear and engaging documentation to make our mission crystal clear.\n5. ** Spread the Word:** Shout about this project from the mountaintops and share it with fellow space explorers.\n\n##  Reporting Issues\n\nIf you stumble upon a space-time anomaly or any other glitches, please report them. We're looking for detailed, time-travel-quality issue reports.  Here's how to do it:\n\n1. Check if the issue has already been reported in the [ Issues](https://github.com/alibaba/MNN/issues) section.\n2. If it's an uncharted territory, hit the \"New Issue\" button and provide a clear and descriptive title, along with details about the anomaly.\n3. Share any relevant information, like star maps, your spacecraft's operating system, and steps to recreate the anomaly.\n\n##  Feature Requests\n\nGot a groundbreaking idea that could revolutionize our AI galaxy? Share it with us! Here's how to request a feature:\n\n1. Check if your concept is already orbiting in the [ Issues](https://github.com/alibaba/MNN/issues) section.\n2. If it's a new feature request, press the \"New Issue\" button and use the \"Feature Request\" template to beam down the details of your vision.\n\n##  Pull Requests\n\nWe invite you to join us on this cosmic journey. To submit a pull request, follow these stellar steps:\n\n1.  Fork this repository and create your very own starbase.\n2. Blast off with a `new-branch` branch for your galactic changes.\n3. Make your modifications, ensuring your code adheres to the project's cosmic coding guidelines.\n4. Perform gravity-defying tests to verify that your changes are warp-speed ready.\n5. Document your discoveries and provide clear commit messages.\n6. Transmit your changes to your starbase by pushing to your fork.\n7. Launch a pull request to the `new-branch` branch of this repository, and we'll navigate the rest of the way together.\n\nOur starship will review your pull request, communicate in warp speed, and collaborate to merge it into the main repository.\n\n##  Coding Guidelines\n\nPlease ensure your code adheres to the coding guidelines and coding style used in the original MNN project. Consistency in coding style helps maintain the integrity of our codebase.\n\n##  License\n\nBy joining this interstellar mission, you agree that your contributions will be licensed under the Apache 2.0 LICENSE. Together, we'll explore the AI universe and make it an exciting and accessible journey for all sentient beings in the galaxy. \n\nThank you for contributing to this amazing fork of MNN! Together, we'll reach the stars and beyond. \n"
        },
        {
          "name": "MNN.podspec",
          "type": "blob",
          "size": 4.021484375,
          "content": "Pod::Spec.new do |s|\n  s.name         = \"MNN\"\n  s.version      = \"2.2.0\"\n  s.summary      = \"MNN\"\n\n  s.description  = <<-DESC\n                    MNN is a lightweight deep neural network inference framework. It loads models and do inference on devices.\n                   DESC\n\n  s.homepage     = \"https://github.com/alibaba/MNN\"\n  s.license = {\n    :type => 'Apache License, Version 2.0',\n    :text => <<-LICENSE\n                      Copyright  2018, Alibaba Group Holding Limited\n\n                      Licensed under the Apache License, Version 2.0 (the \"License\");\n                      you may not use this file except in compliance with the License.\n                      You may obtain a copy of the License at\n\n                        http://www.apache.org/licenses/LICENSE-2.0\n\n                      Unless required by applicable law or agreed to in writing, software\n                      distributed under the License is distributed on an \"AS IS\" BASIS,\n                      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n                      See the License for the specific language governing permissions and\n                      limitations under the License.\n    LICENSE\n  }\n\n  s.author       = { \"MNN\" => \"MNN@alibaba-inc.com\" }\n  s.platform     = :ios\n  s.ios.deployment_target = '8.0'\n  s.requires_arc = true\n\n  #s.source =  { :git => \"git@github.com:alibaba/MNN.git\", :branch => 'master' }\n  s.source = {:git => \"/Users/zhang/Development/AliNNPrivate/\",:branch=> 'head'}\n  s.frameworks = 'Metal', 'Accelerate', 'CoreML'\n  s.library = 'c++'\n  s.source_files = \\\n  'include/MNN/*.{h,hpp}',\\\n  'include/MNN/expr/*.{h,hpp}',\\\n  'schema/current/*.{h}',\\\n  '3rd_party/flatbuffers/include/flatbuffers/*.{h}',\\\n  'source/internal/logging/*.{hpp,cpp}',\\\n  'source/internal/logging/ios/*.{h,c,m,mm,cc,hpp,cpp}',\\\n  'source/internal/logging/aliyun-log-c-sdk/src/*.{h,c,m,mm,cc,hpp,cpp}',\\\n  'source/core/**/*.{h,c,m,mm,cc,hpp,cpp}',\\\n  'source/common/**/*.{h,c,m,mm,cc,hpp,cpp}',\\\n  'source/utils/**/*.{h,c,m,mm,cc,hpp,cpp}',\\\n  'source/geometry/**/*.{h,c,m,mm,cc,hpp,cpp}',\\\n  'source/cv/**/*.{h,c,m,mm,cc,hpp,cpp}',\\\n  'source/math/**/*.{h,c,m,mm,cc,hpp,cpp,metal}',\\\n  'source/shape/*.{h,c,m,mm,cc,hpp,cpp}',\\\n  #'source/backend/arm82/*.{h,c,m,mm,cc,S,hpp,cpp}',\\\n  #'source/backend/arm82/asm/**/*.{h,c,m,mm,cc,S,hpp,cpp}',\\\n  'source/backend/cpu/*.{h,c,m,mm,cc,S,hpp,cpp}',\\\n  'source/backend/cpu/bf16/*.{h,c,m,mm,cc,S,hpp,cpp}',\\\n  'source/backend/cpu/arm/**/*.{h,c,m,mm,cc,S,hpp,cpp}',\\\n  'source/backend/cpu/compute/*.{h,c,m,mm,cc,S,hpp,cpp}',\\\n  'source/backend/metal/*.{h,c,m,mm,cc,hpp,cpp,metal}',\\\n  'source/backend/coreml/backend/*.{h,c,m,mm,cc,hpp,cpp,metal}',\\\n  'source/backend/coreml/execution/*.{h,c,m,mm,cc,hpp,cpp,metal}',\\\n  'source/backend/coreml/mlmodel/src/*.{h,c,m,mm,cc,hpp,cpp,metal}',\\\n  'express/**/*.{hpp,cpp}',\\\n  'tools/cv/include/**/*.{h,c,m,mm,cc,hpp,cpp,metal}',\\\n  'tools/cv/source/imgproc/*.{h,c,m,mm,cc,hpp,cpp,metal}',\\\n  'tools/cv/source/calib3d/*.{h,c,m,mm,cc,hpp,cpp,metal}'\n\n  s.header_mappings_dir = 'include'\n  s.subspec 'cv' do |sp|\n    sp.source_files = 'tools/cv/include/**/*.hpp'\n    sp.header_mappings_dir = 'tools/cv/include'\n    sp.xcconfig = { 'ALWAYS_SEARCH_USER_PATHS' => 'NO' }\n  end\n\n  s.compiler_flags = '-arch arm64 -march=armv8.2-a+simd+fp16'\n  s.pod_target_xcconfig = {'METAL_LIBRARY_FILE_BASE' => 'mnn', 'HEADER_SEARCH_PATHS' => '\"$(PODS_TARGET_SRCROOT)/include\" \"$(PODS_TARGET_SRCROOT)/3rd_party/flatbuffers/include\" \"$(PODS_TARGET_SRCROOT)/source\" \"$(PODS_TARGET_SRCROOT)/3rd_party/half\" \"$(PODS_TARGET_SRCROOT)/source/backend/coreml/mlmodel/include\" \"$(PODS_TARGET_SRCROOT)/tools/cv/include\"', 'GCC_PREPROCESSOR_DEFINITIONS' => '$(inherited) MNN_CODEGEN_REGISTER=1 MNN_SUPPORT_TFLITE_QUAN=1 MNN_METAL_ENABLED=1 MNN_SUPPORT_BF16=1 MNN_COREML_ENABLED=1 USE_LZ4_FLAG=1 MNN_INTERNAL_ENABLED=1 MNN_USE_SPARSE_COMPUTE=1'}\n  s.user_target_xcconfig = { 'OTHER_LDFLAGS' => '-force_load $(BUILD_DIR)/$(CONFIGURATION)$(EFFECTIVE_PLATFORM_NAME)/MNN/libMNN.a', 'HEADER_SEARCH_PATHS' => '\"$(PODS_TARGET_SRCROOT)/include\"' }\nend\n"
        },
        {
          "name": "MNN.sln",
          "type": "blob",
          "size": 0,
          "content": ""
        },
        {
          "name": "MNN_Render.podspec",
          "type": "blob",
          "size": 4.236328125,
          "content": "Pod::Spec.new do |s|\n  s.name         = \"MNN\"\n  s.version      = \"2.2.0\"\n  s.summary      = \"MNN\"\n\n  s.description  = <<-DESC\n                    MNN is a lightweight deep neural network inference framework. It loads models and do inference on devices.\n                   DESC\n\n  s.homepage     = \"https://github.com/alibaba/MNN\"\n  s.license = {\n    :type => 'Apache License, Version 2.0',\n    :text => <<-LICENSE\n                      Copyright  2018, Alibaba Group Holding Limited\n\n                      Licensed under the Apache License, Version 2.0 (the \"License\");\n                      you may not use this file except in compliance with the License.\n                      You may obtain a copy of the License at\n\n                        http://www.apache.org/licenses/LICENSE-2.0\n\n                      Unless required by applicable law or agreed to in writing, software\n                      distributed under the License is distributed on an \"AS IS\" BASIS,\n                      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n                      See the License for the specific language governing permissions and\n                      limitations under the License.\n    LICENSE\n  }\n\n  s.author       = { \"MNN\" => \"MNN@alibaba-inc.com\" }\n  s.platform     = :ios\n  s.ios.deployment_target = '8.0'\n  s.requires_arc = true\n\n  #s.source =  { :git => \"git@github.com:alibaba/MNN.git\", :branch => 'master' }\n  s.source = {:git => \"/Users/zhang/Development/AliNNPrivate/\",:branch=> 'head'}\n  s.frameworks = 'Metal', 'Accelerate', 'CoreML'\n  s.library = 'c++'\n  s.source_files = \\\n  'include/MNN/*.{h,hpp}',\\\n  'include/MNN/expr/*.{h,hpp}',\\\n  'schema/current/*.{h}',\\\n  '3rd_party/flatbuffers/include/flatbuffers/*.{h}',\\\n  'source/internal/logging/*.{hpp,cpp}',\\\n  'source/internal/logging/ios/*.{h,c,m,mm,cc,hpp,cpp}',\\\n  'source/internal/logging/aliyun-log-c-sdk/src/*.{h,c,m,mm,cc,hpp,cpp}',\\\n  'source/core/**/*.{h,c,m,mm,cc,hpp,cpp}',\\\n  'source/common/**/*.{h,c,m,mm,cc,hpp,cpp}',\\\n  'source/utils/**/*.{h,c,m,mm,cc,hpp,cpp}',\\\n  'source/geometry/**/*.{h,c,m,mm,cc,hpp,cpp}',\\\n  'source/cv/**/*.{h,c,m,mm,cc,hpp,cpp}',\\\n  'source/math/**/*.{h,c,m,mm,cc,hpp,cpp,metal}',\\\n  'source/shape/*.{h,c,m,mm,cc,hpp,cpp}',\\\n  'source/shape/render/*.{h,c,m,mm,cc,hpp,cpp}',\\\n  #'source/backend/arm82/*.{h,c,m,mm,cc,S,hpp,cpp}',\\\n  #'source/backend/arm82/asm/**/*.{h,c,m,mm,cc,S,hpp,cpp}',\\\n  'source/backend/cpu/*.{h,c,m,mm,cc,S,hpp,cpp}',\\\n  'source/backend/cpu/render/*.{h,c,m,mm,cc,S,hpp,cpp}',\\\n  'source/backend/cpu/bf16/*.{h,c,m,mm,cc,S,hpp,cpp}',\\\n  'source/backend/cpu/arm/**/*.{h,c,m,mm,cc,S,hpp,cpp}',\\\n  'source/backend/cpu/compute/*.{h,c,m,mm,cc,S,hpp,cpp}',\\\n  'source/backend/metal/*.{h,c,m,mm,cc,hpp,cpp,metal}',\\\n  'source/backend/metal/render/*.{h,c,m,mm,cc,hpp,cpp,metal}',\\\n  'source/backend/coreml/backend/*.{h,c,m,mm,cc,hpp,cpp,metal}',\\\n  'source/backend/coreml/execution/*.{h,c,m,mm,cc,hpp,cpp,metal}',\\\n  'source/backend/coreml/mlmodel/src/*.{h,c,m,mm,cc,hpp,cpp,metal}',\\\n  'express/**/*.{hpp,cpp}',\\\n  'tools/cv/include/**/*.{h,c,m,mm,cc,hpp,cpp,metal}',\\\n  'tools/cv/source/imgproc/*.{h,c,m,mm,cc,hpp,cpp,metal}',\\\n  'tools/cv/source/calib3d/*.{h,c,m,mm,cc,hpp,cpp,metal}'\n\n  s.header_mappings_dir = 'include'\n  s.subspec 'cv' do |sp|\n    sp.source_files = 'tools/cv/include/**/*.hpp'\n    sp.header_mappings_dir = 'tools/cv/include'\n    sp.xcconfig = { 'ALWAYS_SEARCH_USER_PATHS' => 'NO' }\n  end\n\n  s.compiler_flags = '-arch arm64 -march=armv8.2-a+simd+fp16'\n  s.pod_target_xcconfig = {'METAL_LIBRARY_FILE_BASE' => 'mnn', 'HEADER_SEARCH_PATHS' => '\"$(PODS_TARGET_SRCROOT)/include\" \"$(PODS_TARGET_SRCROOT)/3rd_party/flatbuffers/include\" \"$(PODS_TARGET_SRCROOT)/source\" \"$(PODS_TARGET_SRCROOT)/3rd_party/half\" \"$(PODS_TARGET_SRCROOT)/source/backend/coreml/mlmodel/include\" \"$(PODS_TARGET_SRCROOT)/tools/cv/include\"', 'GCC_PREPROCESSOR_DEFINITIONS' => '$(inherited) MNN_CODEGEN_REGISTER=1 MNN_SUPPORT_TFLITE_QUAN=1 MNN_METAL_ENABLED=1 MNN_METAL_FULL_PRECISION=1 MNN_SUPPORT_RENDER=1 MNN_SUPPORT_BF16=1 MNN_COREML_ENABLED=1 USE_LZ4_FLAG=1 MNN_INTERNAL_ENABLED=1 MNN_USE_SPARSE_COMPUTE=1'}\n  s.user_target_xcconfig = { 'OTHER_LDFLAGS' => '-force_load $(BUILD_DIR)/$(CONFIGURATION)$(EFFECTIVE_PLATFORM_NAME)/MNN/libMNN.a', 'HEADER_SEARCH_PATHS' => '\"$(PODS_TARGET_SRCROOT)/include\"' }\nend\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 8.8369140625,
          "content": "![MNN](doc/banner.png)\n\n[](README_CN.md)\n\n[MNN Homepage](http://www.mnn.zone)\n\n## Intro\nMNN is a highly efficient and lightweight deep learning framework. It supports inference and training of deep learning models and has industry-leading performance for inference and training on-device. At present, MNN has been integrated into more than 30 apps of Alibaba Inc, such as Taobao, Tmall, Youku, DingTalk, Xianyu, etc., covering more than 70 usage scenarios such as live broadcast, short video capture, search recommendation, product searching by image, interactive marketing, equity distribution, security risk control. In addition, MNN is also used on embedded devices, such as IoT.\n\n[MNN-LLM](https://github.com/alibaba/MNN/tree/master/transformers/llm) is a large language model runtime solution developed based on the MNN engine. The mission of this project is to deploy LLM models locally on everyone's platforms(Mobile Phone/PC/IOT). It supports popular large language models such as Qianwen, Baichuan, Zhipu, LLAMA, and others. [MNN-LLM User guide](https://mnn-docs.readthedocs.io/en/latest/transformers/llm.html)\n\n[MNN-Diffusion](https://github.com/alibaba/MNN/tree/master/transformers/diffusion) is a stable diffusion model runtime solution developed based on the MNN engine. The mission of this project is to deploy stable diffusion models locally on everyone's platforms. [MNN-Diffusion User guide](https://mnn-docs.readthedocs.io/en/latest/transformers/diffusion.html)\n\n![architecture](doc/architecture.png)\n\nInside Alibaba, [MNN](https://mp.weixin.qq.com/s/5I1ISpx8lQqvCS8tGd6EJw) works as the basic module of the compute container in the [Walle](https://mp.weixin.qq.com/s/qpeCETty0BqqNJV9CMJafA) System, the first end-to-end, general-purpose, and large-scale production system for device-cloud collaborative machine learning, which has been published in the top system conference OSDI22. The key design principles of MNN and the extensive benchmark testing results (vs. TensorFlow, TensorFlow Lite, PyTorch, PyTorch Mobile, TVM) can be found in the OSDI paper. The scripts and instructions for benchmark testing are put in the path /benchmark. If MNN or the design of Walle helps your research or production use, please cite our OSDI paper as follows:\n\n    @inproceedings {proc:osdi22:walle,\n        author = {Chengfei Lv and Chaoyue Niu and Renjie Gu and Xiaotang Jiang and Zhaode Wang and Bin Liu and Ziqi Wu and Qiulin Yao and Congyu Huang and Panos Huang and Tao Huang and Hui Shu and Jinde Song and Bin Zou and Peng Lan and Guohuan Xu and Fei Wu and Shaojie Tang and Fan Wu and Guihai Chen},\n        title = {Walle: An {End-to-End}, {General-Purpose}, and {Large-Scale} Production System for {Device-Cloud} Collaborative Machine Learning},\n        booktitle = {16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22)},\n        year = {2022},\n        isbn = {978-1-939133-28-1},\n        address = {Carlsbad, CA},\n        pages = {249--265},\n        url = {https://www.usenix.org/conference/osdi22/presentation/lv},\n        publisher = {USENIX Association},\n        month = jul,\n    }\n\n\n## Documentation and Workbench\nMNN's docs are in place in [Read the docs](https://mnn-docs.readthedocs.io/en/latest).\n\nYou can also read docs/README to build docs's html.\n\nMNN Workbench could be downloaded from [MNN's homepage](http://www.mnn.zone), which provides pretrained models, visualized training tools, and one-click deployment of models to devices.\n\n## Key Features\n### Lightweight\n- Optimized for devices, no dependencies, can be easily deployed to mobile devices and a variety of embedded devices.\n- iOS platform: static library size will full option for armv7+arm64 platforms is about 12MB, size increase of linked executables is about 2M.\n- Android platform: core so size is about 800KB (armv7a - c++_shared).\n- Using MNN_BUILD_MINI can reduce package size by about 25%, with a limit of fixed model input size\n- Support FP16 / Int8 quantize, can reduce model size 50%-70%\n\n### Versatility\n- Supports `Tensorflow`, `Caffe`, `ONNX`,`Torchscripts` and supports common neural networks such as `CNN`, `RNN`, `GAN`, `Transformer`.\n- Supports AI model with multi-inputs or multi-outputs, every kind of dimension format, dynamic inputs, controlflow.\n- MNN supports approximate full OPs used for the AI Model. The converter supports 178 `Tensorflow` OPs, 52 `Caffe` OPs, 163 `Torchscripts` OPs, 158 `ONNX` OPs.\n- Supports iOS 8.0+, Android 4.3+, and embedded devices with POSIX interface.\n- Supports hybrid computing on multiple devices. Currently supports CPU and GPU.\n\n\n### High performance\n- Implements core computing with lots of optimized assembly code to make full use of the ARM / x64 CPU.\n- Use Metal / OpenCL / Vulkan to support GPU inference on mobile.\n- Use CUDA and tensorcore to support NVIDIA GPU for better performance\n- Convolution and transposition convolution algorithms are efficient and stable. The Winograd convolution algorithm is widely used to better symmetric convolutions such as 3x3,4x4,5x5,6x6,7x7.\n- Twice speed increase for the new architecture ARM v8.2 with FP16 half-precision calculation support. 2.5 faster to use sdot for ARM v8.2 and VNNI.\n\n### Ease of use\n- Support use MNN's OP to do numerical calculating like numpy.\n- Support lightweight image process module like OpenCV, which is only 100k.\n- Support build model and train it on PC / mobile.\n- MNN Python API helps ML engineers to easily use MNN to infer, train, and process images, without dipping their toes in C++ code.\n\nThe Architecture / Precision MNN supported is shown below:\n\n- S Support and work well, deeply optimized, recommend to use\n- A Support and work well, can use\n- B Support but has bug or not optimized, no recommend to use\n- C Not Support\n\n| Architecture / Precision |  | Normal | FP16 | BF16 | Int8 |\n| --- | --- | --- | --- | --- | --- |\n| CPU | Native | B | C | B | B |\n|  | x86/x64-SSE4.1 | A | B | B | A |\n|  | x86/x64-AVX2 | S | B | B | A |\n|  | x86/x64-AVX512 | S | B | B | S |\n|  | ARMv7a | S | S (ARMv8.2) | S | S |\n|  | ARMv8 | S | S (ARMv8.2) | S(ARMv8.6) | S |\n| GPU | OpenCL | A | S | C | C |\n|  | Vulkan | A | A | C | C |\n|  | Metal | A | S | C | C |\n|  | CUDA | A | S | C | C |\n| NPU | CoreML | B | B | C | C |\n|  | HIAI | B | C | C | B |\n|  | NNAPI | B | B | C | C |\n\n\n\n## Tools\n\nBase on MNN (Tensor compute engine), we provided a series of tools for inference, train and general computation.\n\n- MNN-Converter: Convert other models to MNN models for inference, such as Tensorflow(lite), Caffe, ONNX, Torchscripts. And do graph optimization to reduce computation.\n- MNN-Compress: Compress model to reduce size and increase performance / speed\n- MNN-Express: Support model with controlflow, use MNN's OP to do general-purpose computing.\n- MNN-CV: An OpenCV-like library, but based on MNN and then much more lightweight.\n- MNN-Train: Support train MNN model.\n\n## How to Discuss and Get Help From the MNN Community\n\nThe group discussions are predominantly Chinese. But we welcome and will help English speakers.\n\nDingtalk discussion groups:\n\nGroup #1 (Full): 23329087\n\nGroup #2 (Full): 23350225\n\nGroup #3: QR code:\n\n![MNN-3](doc/dingdingmnn3.png)\n\n## Historical Paper\n\nThe preliminary version of MNN, as mobile inference engine and with the focus on manual optimization, has also been published in MLSys 2020. Please cite the paper, if MNN previously helped your research:\n\n\n    @inproceedings{alibaba2020mnn,\n      author = {Jiang, Xiaotang and Wang, Huan and Chen, Yiliu and Wu, Ziqi and Wang, Lichuan and Zou, Bin and Yang, Yafeng and Cui, Zongyang and Cai, Yu and Yu, Tianhang and Lv, Chengfei and Wu, Zhihua},\n      title = {MNN: A Universal and Efficient Inference Engine},\n      booktitle = {MLSys},\n      year = {2020}\n    }\n\n\n## License\nApache 2.0\n\n## Acknowledgement\nMNN participants: Taobao Technology Department, Search Engineering Team, DAMO Team, Youku and other Alibaba Group employees.\n\nMNN refers to the following projects:\n- [Caffe](https://github.com/BVLC/caffe)\n- [flatbuffer](https://github.com/google/flatbuffers)\n- [gemmlowp](https://github.com/google/gemmlowp)\n- [Google Vulkan demo](http://www.github.com/googlesamples/android-vulkan-tutorials)\n- [Halide](https://github.com/halide/Halide)\n- [Mace](https://github.com/XiaoMi/mace)\n- [ONNX](https://github.com/onnx/onnx)\n- [protobuffer](https://github.com/protocolbuffers/protobuf)\n- [skia](https://github.com/google/skia)\n- [Tensorflow](https://github.com/tensorflow/tensorflow)\n- [ncnn](https://github.com/Tencent/ncnn)\n- [paddle-mobile](https://github.com/PaddlePaddle/paddle-mobile)\n- [stb](https://github.com/nothings/stb)\n- [rapidjson](https://github.com/Tencent/rapidjson)\n- [pybind11](https://github.com/pybind/pybind11)\n- [pytorch](https://github.com/pytorch/pytorch)\n- [bolt](https://github.com/huawei-noah/bolt)\n- [libyuv](https://chromium.googlesource.com/libyuv/libyuv)\n- [libjpeg](https://github.com/libjpeg-turbo/libjpeg-turbo)\n- [opencv](https://github.com/opencv/opencv)\n"
        },
        {
          "name": "README_CN.md",
          "type": "blob",
          "size": 9.08984375,
          "content": "![MNN](doc/banner.png)\n\n[English Version](README.md)\n\n[MNN Homepage](http://www.mnn.zone)\n\n[MNN](https://github.com/alibaba/MNN)///MNN30App\n\n[MNN-LLM](https://github.com/alibaba/MNN/tree/master/transformers/llm)MNN(//)///LLAMA[MNN-LLM](https://mnn-docs.readthedocs.io/en/latest/transformers/llm.html)\n\n[MNN-Diffusion](https://github.com/alibaba/MNN/tree/master/transformers/diffusion)MNNStable DiffusionStable Diffusion[MNN-Diffusion](https://mnn-docs.readthedocs.io/en/latest/transformers/diffusion.html)\n\n![](doc/architecture.png)\n\n[MNN](https://mp.weixin.qq.com/s/5I1ISpx8lQqvCS8tGd6EJw)[Walle](https://mp.weixin.qq.com/s/qpeCETty0BqqNJV9CMJafA)WalleOSDI 2022WalleMNNMNNTensorFlow, TensorFlow Lite, PyTorch, PyTorch Mobile, TVMbenchmark/benchmarkMNNWalleOSDI\n\n    @inproceedings {proc:osdi22:walle,\n        author = {Chengfei Lv and Chaoyue Niu and Renjie Gu and Xiaotang Jiang and Zhaode Wang and Bin Liu and Ziqi Wu and Qiulin Yao and Congyu Huang and Panos Huang and Tao Huang and Hui Shu and Jinde Song and Bin Zou and Peng Lan and Guohuan Xu and Fei Wu and Shaojie Tang and Fan Wu and Guihai Chen},\n        title = {Walle: An {End-to-End}, {General-Purpose}, and {Large-Scale} Production System for {Device-Cloud} Collaborative Machine Learning},\n        booktitle = {16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22)},\n        year = {2022},\n        isbn = {978-1-939133-28-1},\n        address = {Carlsbad, CA},\n        pages = {249--265},\n        url = {https://www.usenix.org/conference/osdi22/presentation/lv},\n        publisher = {USENIX Association},\n        month = jul,\n    }\n\n## \nMNN\n- [(readthedocs)](https://mnn-docs.readthedocs.io/en/latest/index.html)\n\n-  docs/README \n\n\n[MNN](http://www.mnn.zone)MNNMNN\n\n## \n\n###  \n\n- CPU+GPU \n   - iOSMNN armv7+arm6412MB2M6.1M  600 KB\n   - Android armv7a - c++_shared 800KB\n-  Mini  25% \n- FP16/Int850% - 75% \n\n###  \n\n-  TensorflowCaffeONNXTorchscripts CNN / RNN / GAN / Transformer \n- \n-  178 Tensorflow Op52 Caffe Op163 Torchscipts Op158  ONNX OpONNX \n-   /  /  POSIX CPU / GPU  NPU IOS 11 + CoreML / Huawei + HIAI / Android + NNAPI\n-  Windows / iOS 8.0+ / Android 4.3+ / Linux POSIX\n\n### \n\n- iOS / Android / PC / Server CPUSIMD CPUCV\n-  Metal / OpenCL / Vulkan GPU\n-  CUDA  PC / Server  NVIDIA GPU \n-  Winograd WinogradStrassen\n-  int8 / fp16 / bf16 ARMv8.2  AVX512\n\n### \n\n-  MNN  numpy \n-  MNN CV  MNN_CV armv7a  100 k \n- \n-  python \n\nMNN\n\n- S \n- A \n- B \n- C \n\n| Architecture / Precision |  | Normal | FP16 | BF16 | Int8 |\n| --- | --- | --- | --- | --- | --- |\n| CPU | Native | B | C | B | B |\n|  | x86/x64-SSE4.1 | A | B | B | A |\n|  | x86/x64-AVX2 | S | B | B | A |\n|  | x86/x64-AVX512 | S | B | B | S |\n|  | ARMv7a | S | S (ARMv8.2) | S | S |\n|  | ARMv8 | S | S (ARMv8.2) | S(ARMv8.6) | S |\n| GPU | OpenCL | A | S | C | C |\n|  | Vulkan | A | A | C | C |\n|  | Metal | A | S | C | C |\n|  | CUDA | A | S | C | C |\n| NPU | CoreML | B | B | C | C |\n|  | HIAI | B | C | C | B |\n|  | NNAPI | B | B | C | C |\n\n\n## \n\nMNN ()\n\n\n- MNN-ConverterFrontendsGraph OptimizeMNNTensorflow(Lite)CaffeONNX(PyTorch/MXNetONNXMNN)Torchscripts\n- MNN-Compress: MNN\n- MNN-Express  MNN \n- MNN-CV  OpenCV  MNN \n- MNN-Train MNN \n\n## \n\n\n- 1:23329087 \n- 2:23350225\n- 3:\n\n![MNN-3](doc/dingdingmnn3.png)\n\n\n## \n\nMNN[](https://arxiv.org/pdf/2002.12418.pdf)MLSys 2020MNNMNNMNNMLSys\n\n\t@inproceedings{alibaba2020mnn,\n      author = {Jiang, Xiaotang and Wang, Huan and Chen, Yiliu and Wu, Ziqi and Wang, Lichuan and Zou, Bin and Yang, Yafeng and Cui, Zongyang and Cai, Yu and Yu, Tianhang and Lv, Chengfei and Wu, Zhihua},\n      title = {MNN: A Universal and Efficient Inference Engine},\n      booktitle = {MLSys},\n      year = {2020}\n    }\n\n## License\nApache 2.0\n\n## \nMNN\n\nMNN\n\n- [Caffe](https://github.com/BVLC/caffe)\n- [flatbuffer](https://github.com/google/flatbuffers)\n- [gemmlowp](https://github.com/google/gemmlowp)\n- [Google Vulkan demo](http://www.github.com/googlesamples/android-vulkan-tutorials)\n- [Halide](https://github.com/halide/Halide)\n- [Mace](https://github.com/XiaoMi/mace)\n- [ONNX](https://github.com/onnx/onnx)\n- [protobuffer](https://github.com/protocolbuffers/protobuf)\n- [skia](https://github.com/google/skia)\n- [Tensorflow](https://github.com/tensorflow/tensorflow)\n- [ncnn](https://github.com/Tencent/ncnn)\n- [paddle-mobile](https://github.com/PaddlePaddle/paddle-mobile)\n- [stb](https://github.com/nothings/stb)\n- [rapidjson](https://github.com/Tencent/rapidjson)\n- [pybind11](https://github.com/pybind/pybind11)\n- [pytorch](https://github.com/pytorch/pytorch)\n- [bolt](https://github.com/huawei-noah/bolt)\n- [libyuv](https://chromium.googlesource.com/libyuv/libyuv)\n- [libjpeg](https://github.com/libjpeg-turbo/libjpeg-turbo)\n- [opencv](https://github.com/opencv/opencv)\n\n"
        },
        {
          "name": "backupcode",
          "type": "tree",
          "content": null
        },
        {
          "name": "benchmark",
          "type": "tree",
          "content": null
        },
        {
          "name": "ciscripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "cmake",
          "type": "tree",
          "content": null
        },
        {
          "name": "codegen",
          "type": "tree",
          "content": null
        },
        {
          "name": "demo",
          "type": "tree",
          "content": null
        },
        {
          "name": "doc",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker_release.sh",
          "type": "blob",
          "size": 0.212890625,
          "content": "# using docker run release\ndocker start mnn_release\ndocker exec -i -e TEST_ID=$(pwd | awk -F \"/\" '{print $(NF-1)}') mnn_release bash <<'EOF'\ncd ~/yanxing_zhaode/cise/space/$TEST_ID/source && ./release.sh pymnn\nexit\nEOF"
        },
        {
          "name": "docker_run.sh",
          "type": "blob",
          "size": 0.1982421875,
          "content": "# using docker run test\ndocker start mnn_ci\ndocker exec -i -e TEST_ID=$(pwd | awk -F \"/\" '{print $(NF-1)}') mnn_ci bash <<'EOF'\ncd ~/yanxing_zhaode/cise/space/$TEST_ID/source && ./test.sh linux\nexit\nEOF\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "express",
          "type": "tree",
          "content": null
        },
        {
          "name": "include",
          "type": "tree",
          "content": null
        },
        {
          "name": "package_scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "project",
          "type": "tree",
          "content": null
        },
        {
          "name": "pymnn",
          "type": "tree",
          "content": null
        },
        {
          "name": "release.sh",
          "type": "blob",
          "size": 1.15234375,
          "content": "get_version() {\n    version_header=\"./include/MNN/MNNDefine.h\"\n    version_major='x'\n    version_minor='x'\n    version_patch='x'\n\n    #  version_header \n    while IFS='' read -r line || [[ -n \"$line\" ]]; do\n        if echo \"$line\" | grep -q '#define MNN_VERSION_MAJOR'; then\n            version_major=$(echo \"$line\" | awk '{print $3}')\n        elif echo \"$line\" | grep -q '#define MNN_VERSION_MINOR'; then\n            version_minor=$(echo \"$line\" | awk '{print $3}')\n        elif echo \"$line\" | grep -q '#define MNN_VERSION_PATCH'; then\n            version_patch=$(echo \"$line\" | awk '{print $3}')\n        fi\n    done < \"$version_header\"\n\n    mnn_version=\"$version_major.$version_minor.$version_patch\"\n}\n\n\nmnn() {\n    echo 'build mnn release package.'\n    # TODO\n}\n\npymnn() {\n    echo 'build pymnn release package.'\n    get_version\n    ./package_scripts/linux/build_whl.sh -v $mnn_version -o MNN-CPU/py_whl\n    /opt/python/cp39-cp39/bin/python -m twine upload ./MNN-CPU/py_whl/*\n}\n\ncase \"$1\" in\n    mnn)\n        mnn\n        ;;\n    pymnn)\n        pymnn\n        ;;\n    *)\n        $1\n        echo $\"Usage: $0 {mnn|pymnn}\"\n        exit 2\nesac\nexit $?\n"
        },
        {
          "name": "resource",
          "type": "tree",
          "content": null
        },
        {
          "name": "schema",
          "type": "tree",
          "content": null
        },
        {
          "name": "source",
          "type": "tree",
          "content": null
        },
        {
          "name": "test.bat",
          "type": "blob",
          "size": 0.185546875,
          "content": "if %1 EQU x86 (\n    @call \"%vs_env_setup%/vcvarsamd64_x86.bat\"\n    powershell \"%~dp0test.ps1\" -gpu -x86\n) else (\n    @call \"%vs_env_setup%/vcvars64.bat\"\n    powershell \"%~dp0test.ps1\" -gpu\n)"
        },
        {
          "name": "test.ps1",
          "type": "blob",
          "size": 8.78515625,
          "content": "# Powershell Script must be save as UTF-8 with BOM, otherwise system-wide code page will be used, causing garbled code\n\n# MNN-CPU-GPU\n#  |-- include\n#  |-- lib\n#  |    |-- x64\n#  |    |    |-- (Debug/Release x Dynamic/Static x MD/MT)\n#  |    |\n#  |    |-- x86\n#  |         |-- (Debug/Release x Dynamic/Static x MD/MT)\n#  |\n#  |-- tools (Release + Dynamic + MD)\n#  |    |-- x64\n#  |    |-- x86\n#  |\n#  |-- py_whl\n#  |-- py_bridge\n#       |-- include\n#       |-- wrapper\n#       |-- test (Release + Dynamic + MD)\n#            |-- x64\n#            |-- x86\n#       |-- lib\n#            |-- x64\n#            |    |-- (Debug/Release x Dynamic/Static x MD/MT)\n#            |\n#            |-- x86\n#                 |-- (Debug/Release x Dynamic/Static x MD/MT)\n\nParam(\n    [Switch]$gpu,\n    [Switch]$x86\n)\n\n$basedir = $(Split-Path -Parent $MyInvocation.MyCommand.Path)\n$outdir = \"$basedir/$(If ($gpu) {\"MNN-CPU-GPU\"} Else {\"MNN-CPU\"})\"\n$arch = \"$(If ($x86) {\"x86\"} Else {\"x64\"})\"\nWrite-Output $arch\n\n$test_avx512 = ((!$x86) -and $env:avx512_server -and $env:avx512_password)\nif ($test_avx512) {\n    $remote_home = $(Invoke-Expression 'plink -batch -ssh $env:avx512_server -pw $env:avx512_password powershell \"echo `$HOME\"')\n    $remote_dir = \"${remote_home}\\cise-space\\$(Split-Path -Path $(pushd .. ; pwd ; popd) -Leaf)\"\n}\nfunction sync_remote() {\n    Invoke-Expression 'plink -batch -ssh $env:avx512_server -pw $env:avx512_password powershell \"Remove-Item -Recurse $remote_dir -ErrorAction Ignore ; mkdir $remote_dir\"'\n    Invoke-Expression 'pscp -pw $env:avx512_password -r $outdir/tools ${env:avx512_server}:${remote_dir}'\n    Invoke-Expression 'pscp -pw $env:avx512_password tools/script/modelTest.py ${env:avx512_server}:${remote_dir}'\n}\n\nfunction run_remote([String]$cmd) {\n    $tmpfile = New-TemporaryFile\n    Set-Content -Path $tmpfile -Value \"powershell `\"cd ${remote_dir} ;  $cmd`\"\"\n    $output = $(Invoke-Expression 'plink -batch -ssh $env:avx512_server -pw $env:avx512_password -m $tmpfile')\n    Remove-Item $tmpfile\n    return $output\n}\n\nfunction log($case, $title, $blocked, $failed, $passed, $skipped) {\n    Write-Output \"TEST_NAME_${case}: $title\"\n    Write-Output \"TEST_CASE_AMOUNT_${case}: {`\"blocked`\":$blocked,`\"failed`\":$failed,`\"passed`\":$passed,`\"skipped`\":$skipped}\"\n}\n\nfunction failed() {\n    Write-Output \"TEST_NAME_EXCEPTION: Exception\"\n    Write-Output 'TEST_CASE_AMOUNT_EXCEPTION: {\"blocked\":0,\"failed\":1,\"passed\":0,\"skipped\":0}'\n    exit\n}\n\nfunction build_lib_test() {\n    # build_lib_release.ps1 just build release for speed\n    Invoke-Expression \"./package_scripts/win/build_lib_release.ps1 -path $outdir -cibuild $(If ($gpu) {\"-backends 'opencl,vulkan'\"}) $(If ($x86) {'-x86'})\"\n    $WrongNum = [int]$($LastExitCode -ne 0)\n    log \"WINDOWS_LIB\" \"Windows\" 0 $WrongNum $(1 - $WrongNum) 0\n    if ($WrongNum -ne 0) {\n        Write-Output \"### Windows\"\n        failed\n    }\n}\n\nfunction build_tool_test() {\n    Invoke-Expression \"./package_scripts/win/build_tools.ps1 -path $outdir/tools/$arch $(If ($gpu) {\"-backends 'opencl,vulkan'\"}) -build_all -dynamic_link\"\n    $WrongNum = $($LastExitCode -ne 0)\n    log \"WINDOWS_LIB\" \"Windows\" 0 $WrongNum $(1 - $WrongNum) 0\n    if ($WrongNum -ne 0) {\n        Write-Output \"### Windows\"\n        failed\n    }\n}\n\nfunction build_whl_test() {\n    $pyenvs = \"py27,py37,py38,py39\"\n    if ($x86) {\n        $pyenvs = \"py27-win32,py37-win32,py38-win32,py39-win32\"\n    }\n    Invoke-Expression \"./package_scripts/win/build_whl.ps1 -version ci_test -path $outdir/py_whl -pyenvs '$pyenvs' $(If ($x86) {'-x86'})\"\n    $WrongNum = $($LastExitCode -ne 0)\n    log \"WINDOWS_LIB\" \"Windows pymnn wheel\" 0 $WrongNum $(1 - $WrongNum) 0\n    if ($WrongNum -ne 0) {\n        Write-Output \"### Windows pymnn wheel\"\n        failed\n    }\n}\n\nfunction build_bridge_test() {\n    Invoke-Expression \"./package_scripts/win/build_bridge.ps1 -version ci_test -pyc_env py27 -mnn_path $outdir -python_path $HOME/PyBridgeDeps/python -numpy_path $HOME/PyBridgeDeps/numpy -path $outdir/py_bridge -train_api $(If ($x86) {'-x86'})\"\n    $WrongNum = $($LastExitCode -ne 0)\n    log \"WINDOWS_LIB\" \"Windows pymnn bridge\" 0 $WrongNum $(1 - $WrongNum) 0\n    if ($WrongNum -ne 0) {\n        Write-Output \"### Windows pymnn bridge\"\n        failed\n    }\n}\n\nfunction unit_test() {\n    Invoke-Expression \"$outdir/tools/$arch/run_test.out.exe\"\n    if ($LastExitCode -ne 0) {\n        Write-Output \"### CPU \"\n        failed\n    }\n    Invoke-Expression \"$outdir/tools/$arch/run_test.out.exe op 0 0 4\"\n    if ($LastExitCode -ne 0) {\n        Write-Output \"### CPU \"\n        failed\n    }\n    if ($test_avx512) {\n        $RemoteExitCode = run_remote \"cd tools/x64 ; ./run_test.out.exe > log.txt ; echo `$LastExitCode\"\n        Write-Output $(run_remote \"Get-Content -Path tools/x64/log.txt\")\n        if ($RemoteExitCode -ne 0) {\n            Write-Output \"### CPU(AVX512) \"\n            failed\n        }\n        $RemoteExitCode = run_remote \"cd tools/x64 ; ./run_test.out.exe op 0 0 4 > log.txt ; echo `$LastExitCode\"\n        Write-Output $(run_remote \"Get-Content -Path tools/x64/log.txt\")\n        if ($RemoteExitCode -ne 0) {\n            Write-Output \"### CPU(AVX512) \"\n            failed\n        }\n    }\n    #Invoke-Expression \"$outdir/tools/$arch/run_test.out.exe op 3\"\n    #if ($LastExitCode -ne 0) {\n    #    echo \"### OpenCL \"\n    #    failed\n    #}\n}\n\nfunction model_test() {\n    Push-Location $outdir/tools/$arch\n    python $basedir/tools/script/modelTest.py $HOME/AliNNModel 0 0.002\n    if ($LastExitCode -ne 0) {\n        Write-Output \"### CPU \"\n        Pop-Location\n        failed\n    }\n    python $basedir/tools/script/modelTest.py $HOME/AliNNModel 0 0.002 0 1\n    if ($LastExitCode -ne 0) {\n        Write-Output \"### CPU \"\n        Pop-Location\n        failed\n    }\n    if ($test_avx512) {\n        $RemoteExitCode = run_remote \"cd tools/x64 ; python ../../modelTest.py `$HOME/AliNNModel 0 0.002 > log.txt ; echo `$LastExitCode\"\n        Write-Output $(run_remote \"Get-Content -Path tools/x64/log.txt\")\n        if ($RemoteExitCode -ne 0) {\n            Write-Output \"### CPU(AVX512) \"\n            Pop-Location\n            failed\n        }\n        $RemoteExitCode = run_remote \"cd tools/x64 ; python ../../modelTest.py `$HOME/AliNNModel 0 0.002 0 1 > log.txt ; echo `$LastExitCode\"\n        Write-Output $(run_remote \"Get-Content -Path tools/x64/log.txt\")\n        if ($RemoteExitCode -ne 0) {\n            Write-Output \"### CPU(AVX512) \"\n            Pop-Location\n            failed\n        }\n    }\n    #python $basedir/tools/script/modelTest.py $HOME/AliNNModel 3 0.01\n    #if ($LastExitCode -ne 0) {\n    #    echo \"### OpenCL \"\n    #    Pop-Location\n    #    failed\n    #}\n    Pop-Location\n}\n\nfunction pymnn_whl_test() {\n    $pyarch = $(If ($x86) {\"win32\"} Else {\"amd64\"})\n    Push-Location pymnn/test\n    $local = \"$(Get-Location)/aone-site-packages\"\n    $pythonpath_backup = ${env:PYTHONPATH}\n    Foreach ($pyenv in @(\"27\", \"37\", \"38\", \"39\")) {\n        Invoke-Expression \"conda activate py$pyenv$(If($x86) {'-win32'})\"\n        Remove-Item -Recurse $local -ErrorAction Ignore\n        pip install --target $local $outdir/py_whl/$(Get-ChildItem -Path $outdir/py_whl -Include \"*$pyenv*$pyarch*\" -Name)\n        do {\n            # unit_test.py need torch, which isn't support on 32bit Windows and py27\n            # https://pytorch.org/docs/stable/notes/windows.html#package-not-found-in-win-32-channel\n            if ($x86 -or ($pyenv -eq \"27\")) {\n                break;\n            }\n            ${env:PYTHONPATH} = $local\n            python unit_test.py\n            ${env:PYTHONPATH} = $pythonpath_backup\n            if ($LastExitCode -ne 0) {\n                Write-Output \"### PYMNN\"\n                conda deactivate\n                Pop-Location\n                failed\n            }\n        } while(0);\n        ${env:PYTHONPATH} = \"$local\"\n        python model_test.py $HOME/AliNNModel\n        ${env:PYTHONPATH} = $pythonpath_backup\n        if ($LastExitCode -ne 0) {\n            Write-Output \"### PYMNN\"\n            conda deactivate\n            Pop-Location\n            failed\n        }\n        conda deactivate\n    }\n    Pop-Location\n}\n\nbuild_lib_test\n# TODO: open other test\n# build_tool_test\n# build_whl_test\n# build_bridge_test\n\n# if ($test_avx512) {\n#     sync_remote\n# }\n# unit_test\n# model_test\n# pymnn_whl_test"
        },
        {
          "name": "test.sh",
          "type": "blob",
          "size": 26.6416015625,
          "content": "# test script for MNN-Release\n#\n# 0. arg = local: [ test for your local build ]\n#       1. unit-test;\n#       2. model-test;\n#       3. onnx convert test\n#       4. tf convert test\n#       5. tflite convert test\n#       6. torch convert test\n#       7. ptq test\n#       8. pymnn test\n#\n# 1. arg = linux: [ all test on linux with coverage ]\n#       0. static check (if source change)\n#       1. pyc check (if *.py change)\n#       2. build for linux;\n#       3. unit-test;\n#       4. model-test;\n#       5. onnx convert test\n#       6. tf convert test\n#       7. tflite convert test\n#       8. torch convert test\n#       9. ptq test\n#      10. pymnn test (if pymnn change)\n#      11. opencv test (if opencv change)\n#      12. convert-report;\n#\n# 2. arg = android: [ simple test on android ]\n#       1. build Android with static_stl\n#       2. build Android arm64\n#       3. unit-test for Android arm64\n#       4. build Android arm32\n#       5. unit-test for Android arm32\n\n# 0. build for android\nUSER_NAME=`whoami`\nUSER_HOME=\"$(echo -n $(bash -c \"cd ~${USER_NAME} && pwd\"))\"\n\n# detect change\nSOURCE_CHANGE=$(git show --name-only | grep -E \"^source/(internal|backend|core|common|cv|geometry|math|plugin|shape|utils)/.*\\.(cpp|cc|c|hpp)$\" | \\\n                grep -Ev \"aliyun-log-c-sdk|hiai|tensorrt|Backend|FunctionDispatcher|ThreadPool\")\nPYMNN_CHANGE=$(git show --name-only | grep -E \"^pymnn/.*\\.(cpp|cc|c|h|hpp|py)$\")\nPY_CHANGE=$(git show --name-only | grep -E \"^pymnn/pip_package/MNN/.*\\.(py)$\")\nOPENCV_CHANGE=$(git show --name-only | grep -E \"^tools/cv/.*\\.(cpp|cc|c|h|hpp)$\")\n# OPENCL_CHANGE=$(git show --name-only | grep -E \"^source/backend/opencl/.*\\.(cpp|cc|c|h|hpp)$\")\nOPENCL_CHANGE=true\nfailed() {\n    printf \"TEST_NAME_EXCEPTION: Exception\\nTEST_CASE_AMOUNT_EXCEPTION: {\\\"blocked\\\":0,\\\"failed\\\":1,\\\"passed\\\":0,\\\"skipped\\\":0}\\n\"\n    exit 1\n}\n\n#############################################################################################\n#                                                                                           #\n#                                  Linux Test Functions                                     #\n#                                                                                           #\n#############################################################################################\ndoc_check() {\n    echo 'doc_check'\n    # 1. CHECK CMakeLists.txt:\n    cmake_files=$(find tools source demo test benchmark  -name \"CMakeLists.txt\")\n    cmake_files=\"$cmake_files CMakeLists.txt\"\n    macros=''\n    executables=''\n    for cmake_file in $cmake_files\n    do\n        executables=\"$executables $(cat $cmake_file | grep -oE \"add_executable\\((.+) \" | awk '{print $1}' | awk -F \"(\" '{print $2}')\"\n        macros=\"$macros $(cat $cmake_file | grep -oE \"option\\((.+) \" | awk '{print $1}' | awk -F \"(\" '{print $2}')\"\n    done\n    # 1.1 check all macro\n    for macro in $macros\n    do\n        if [ $(grep -c $macro ./docs/compile/cmake.md) -le 0 ]; then\n            echo 'DOC CHECK FAILED:' $macro 'not in ./docs/compile/cmake.md'\n            failed\n        fi\n    done\n    # 1.2 check executable\n    for executable in $executables\n    do\n        if [ $(grep -c $executable ./docs/compile/other.md) -le 0 ]; then\n            echo 'DOC CHECK FAILED:' $executable 'not in ./docs/compile/other.md'\n            failed\n        fi\n    done\n    # 2. CHECK Pymnn API:\n    # 2.1 check cv api\n    cv_apis=$(cat pymnn/src/cv.h | grep -oE \"        .+, \\\".+\\\"\" | awk '{ print $1 }' | awk -F ',' '{ print $1 }')\n    cv_apis=\"$cv_apis $(cat pymnn/pip_package/MNN/cv/__init__.py | grep -oE \"def .+\\(\" | awk '{ print $2 }' | awk -F '(' '{print $1}' | grep -v \"__\")\"\n    for cv_api in $cv_apis\n    do\n        if [ $(grep -c $cv_api ./docs/pymnn/cv.md) -le 0 ]; then\n            echo 'DOC CHECK FAILED:' $cv_api 'not in ./docs/pymnn/cv.md'\n            failed\n        fi\n    done\n    # 2.2 check numpy api\n    # np_apis=$(cat pymnn/pip_package/MNN/numpy/__init__.py | grep -oE \"def .+\\(\" | grep -v \"__\" | awk '{ print $2 }' | awk -F '(' '{print $1}')\n    # for np_api in $np_apis\n    # do\n    #     if [ $(grep -c $np_api ./docs/pymnn/numpy.md) -le 0 ]; then\n    #         echo 'DOC CHECK FAILED:' $np_api 'not in ./docs/pymnn/numpy.md'\n    #         # failed\n    #     fi\n    # done\n    # 2.3 check expr api\n    expr_apis=$(cat pymnn/src/expr.h | grep -oE \"        [a-z_]+, \\\"\" | awk '{ print $1 }' | awk -F ',' '{ print $1 }')\n    for expr_api in $expr_apis\n    do\n        if [ $(grep -c $expr_api ./docs/pymnn/expr.md) -le 0 ]; then\n            echo 'DOC CHECK FAILED:' $expr_api 'not in ./docs/pymnn/expr.md'\n            # failed\n        fi\n    done\n    # 3. CHECK C++ API:\n    # 3.1 check Interpreter\n    # 3.2 check Tensor\n}\n\npy_check() {\n    echo 'py_check'\n    if [ -z \"$PY_CHANGE\" ]; then\n        return\n    fi\n    pushd pymnn\n    ./update_mnn_wrapper_assets.sh -c\n    pyc_check_wrong=$[$? > 0]\n    printf \"TEST_NAME_PYC_CHECK: pyc\\nTEST_CASE_AMOUNT_PYC_CHECK: {\\\"blocked\\\":0,\\\"failed\\\":%d,\\\"passed\\\":%d,\\\"skipped\\\":0}\\n\" \\\n           $pyc_check_wrong $[1 - $pyc_check_wrong]\n    if [ $pyc_check_wrong -ne 0 ]; then\n        echo '### pyc'\n        failed\n    fi\n    popd\n}\n\nstatic_check() {\n    echo 'static_check'\n    if [ -z \"$SOURCE_CHANGE\" ]; then\n        return\n    fi\n    cppcheck --error-exitcode=1 --language=c++ --std=c++14 --addon=tools/script/mnn_rules.py $SOURCE_CHANGE 1> /dev/null\n    static_check_wrong=$[$? > 0]\n    printf \"TEST_NAME_STATIC_CHECK: cppcheck\\nTEST_CASE_AMOUNT_STATIC_CHECK: {\\\"blocked\\\":0,\\\"failed\\\":%d,\\\"passed\\\":%d,\\\"skipped\\\":0}\\n\" \\\n           $static_check_wrong $[1 - $static_check_wrong]\n    if [ $static_check_wrong -ne 0 ]; then\n        echo '### cppcheck'\n        failed\n    fi\n}\n\nandroid_static_build() {\n    BASH_FILE=\"$USER_HOME/.zshrc\"\n    if [ -f \"$BASH_FILE\" ]; then\n        source $BASH_FILE\n    fi\n    if [ ! $ANDROID_NDK ] || [ ! -d $ANDROID_NDK ]; then\n        export ANDROID_NDK=\"$USER_HOME/android-ndk-r21\"\n    fi\n    mkdir android_build\n    pushd android_build\n    cmake .. \\\n    -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK/build/cmake/android.toolchain.cmake \\\n    -DCMAKE_CXX_COMPILER_LAUNCHER=ccache \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DANDROID_ABI=\"arm64-v8a\" \\\n    -DANDROID_STL=c++_static \\\n    -DMNN_INTERNAL=ON \\\n    -DMNN_USE_LOGCAT=false \\\n    -DMNN_BUILD_BENCHMARK=ON \\\n    -DANDROID_NATIVE_API_LEVEL=android-26  \\\n    -DMNN_BUILD_FOR_ANDROID_COMMAND=true \\\n    -DMNN_OPENGL=true \\\n    -DMNN_BUILD_TRAIN=true \\\n    -DMNN_VULKAN=true \\\n    -DMNN_OPENCL=true \\\n    -DMNN_SUPPORT_BF16=true \\\n    -DMNN_OPENCL=true -DMNN_ARM82=true \\\n    -DMNN_SUPPORT_TRANSFORMER_FUSE=ON \\\n    -DNATIVE_LIBRARY_OUTPUT=. -DNATIVE_INCLUDE_OUTPUT=. $1 $2 $3\n    make -j16\n    android_build_wrong=$[$? > 0]\n    printf \"TEST_NAME_ANDROID_STATIC: AndroidStatic\\nTEST_CASE_AMOUNT_ANDROID_STATIC: {\\\"blocked\\\":0,\\\"failed\\\":%d,\\\"passed\\\":%d,\\\"skipped\\\":0}\\n\" \\\n           $android_build_wrong $[1 - $android_build_wrong]\n    if [ $android_build_wrong -ne 0 ]; then\n        echo '### AndroidStatic'\n        failed\n    fi\n    popd\n\n    mkdir android_build_32\n    pushd android_build_32\n    cmake .. \\\n    -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK/build/cmake/android.toolchain.cmake \\\n    -DCMAKE_CXX_COMPILER_LAUNCHER=ccache \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DANDROID_ABI=\"armeabi-v7a\" \\\n    -DANDROID_STL=c++_shared \\\n    -DMNN_USE_LOGCAT=false \\\n    -DMNN_BUILD_BENCHMARK=ON \\\n    -DMNN_INTERNAL=ON \\\n    -DANDROID_NATIVE_API_LEVEL=android-26  \\\n    -DMNN_BUILD_FOR_ANDROID_COMMAND=true \\\n    -DMNN_OPENGL=true \\\n    -DMNN_BUILD_TRAIN=true \\\n    -DMNN_VULKAN=true \\\n    -DMNN_OPENCL=true \\\n    -DMNN_BUILD_MINI=true \\\n    -DMNN_SUPPORT_BF16=true \\\n    -DMNN_ARM82=false \\\n    -DMNN_OPENCL=true \\\n    -DMNN_SUPPORT_TRANSFORMER_FUSE=ON \\\n    -DNATIVE_LIBRARY_OUTPUT=. -DNATIVE_INCLUDE_OUTPUT=.\n    make -j16\n    android_build_wrong=$[$? > 0]\n    printf \"TEST_NAME_ANDROID_32: Android 32-Mini \\nTEST_CASE_AMOUNT_ANDROID_32: {\\\"blocked\\\":0,\\\"failed\\\":%d,\\\"passed\\\":%d,\\\"skipped\\\":0}\\n\" $android_build_wrong $[1 - $android_build_wrong]\n    if [ $android_build_wrong -ne 0 ]; then\n        echo '### Android'\n        failed\n    fi\n    popd\n}\n\nlinux_build() {\n    if [ $# -gt 0 ]; then\n        COVERAGE=ON\n    else\n        COVERAGE=OFF\n    fi\n\n    mkdir build_non_sse\n    pushd build_non_sse\n    cmake .. -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DMNN_USE_SSE=OFF && make -j16\n\n    linux_build_wrong=$[$? > 0]\n    popd\n\n    mkdir build\n    pushd build\n    # copy libtorch avoid wget, speed up ci build\n    cp ~/libtorch-cxx11-abi-shared-with-deps-1.9.0+cpu.zip .\n    cmake .. \\\n        -DCMAKE_CXX_COMPILER_LAUNCHER=ccache \\\n        -DCMAKE_BUILD_TYPE=Release \\\n        -DMNN_BUILD_TEST=ON \\\n        -DMNN_CUDA=ON \\\n        -DMNN_OPENCL=ON \\\n        -DMNN_BUILD_QUANTOOLS=ON \\\n        -DMNN_BUILD_DEMO=ON \\\n        -DMNN_BUILD_TRAIN=ON \\\n        -DMNN_BUILD_CONVERTER=ON \\\n        -DMNN_BUILD_TORCH=ON \\\n        -DMNN_BUILD_OPENCV=ON \\\n        -DMNN_LOW_MEMORY=ON \\\n        -DMNN_IMGCODECS=ON \\\n        -DMNN_SUPPORT_TRANSFORMER_FUSE=ON \\\n        -DMNN_ENABLE_COVERAGE=$COVERAGE\n    make -j16\n\n    linux_build_wrong+=$[$? > 0]\n    printf \"TEST_NAME_LINUX: Linux\\nTEST_CASE_AMOUNT_LINUX: {\\\"blocked\\\":0,\\\"failed\\\":%d,\\\"passed\\\":%d,\\\"skipped\\\":0}\\n\" $linux_build_wrong $[2 - $linux_build_wrong]\n    if [ $linux_build_wrong -ne 0 ]; then\n        echo '### Linux'\n        failed\n    fi\n\n    # Don't remove this! It turn off MNN_CUDA and MNN_TENSORRT in build, workaround some bug in PTQTest\n    cmake .. -DMNN_CUDA=OFF -DMNN_TENSORRT=OFF && make -j16\n}\n\nunit_test() {\n    ./run_test.out\n    if [ $? -ne 0 ]; then\n        echo '### '\n        failed\n    fi\n\n    ./run_test.out op 0 0 4\n    if [ $? -ne 0 ]; then\n        echo '### '\n        failed\n    fi\n    if [ \"$OPENCL_CHANGE\" ]; then\n        ./run_test.out op 3 1 4\n        if [ $? -ne 0 ]; then\n            echo '### OpenCL'\n            failed\n        fi\n    fi\n}\n\nmodel_test() {\n    ../tools/script/modelTest.py ~/AliNNModel 0 0.002\n    if [ $? -ne 0 ]; then\n        echo '### '\n        failed\n    fi\n\n    ../tools/script/modelTest.py ~/AliNNModel 0 0.002 0 1\n    if [ $? -ne 0 ]; then\n        echo '### '\n        failed\n    fi\n\n    if [ \"$OPENCL_CHANGE\" ]; then\n        ../tools/script/modelTest.py ~/AliNNModel 3 0.002 1\n        if [ $? -ne 0 ]; then\n            echo '### OpenCL'\n            failed\n        fi\n    fi\n}\n\nonnx_convert_test() {\n    ../tools/script/convertOnnxTest.py ~/AliNNModel\n    if [ $? -ne 0 ]; then\n        echo '### ONNXConvert'\n        failed\n    fi\n}\n\ntf_convert_test() {\n    ../tools/script/convertTfTest.py ~/AliNNModel\n    if [ $? -ne 0 ]; then\n        echo '### TFConvert'\n        failed\n    fi\n}\n\ntflite_convert_test() {\n    ../tools/script/convertTfliteTest.py ~/AliNNModel\n    if [ $? -ne 0 ]; then\n        echo '### TFLITEConvert'\n        failed\n    fi\n}\n\ntorch_convert_test() {\n    ../tools/script/convertTorchTest.py ~/AliNNModel\n    if [ $? -ne 0 ]; then\n        echo '### TORCHConvert'\n        failed\n    fi\n}\n\nptq_test() {\n    ../tools/script/testPTQ.py ~/AliNNModel\n    if [ $? -ne 0 ]; then\n        echo '### PTQ'\n        failed\n    fi\n}\n\npymnn_test() {\n    if [ -z \"$PYMNN_CHANGE\" ]; then\n        return\n    fi\n    popd\n    pushd pymnn\n    # 1. build pymnn\n    pushd pip_package\n    python3 build_deps.py\n    # uninstall original MNN\n    pip uninstall --yes MNN MNN-Internal\n    python3 setup.py install --version 1.0 --install-lib=/usr/lib/python3/dist-packages\n    pymnn_build_wrong=$[$? > 0]\n    printf \"TEST_NAME_PYMNN_BUILD: PYMNN\\nTEST_CASE_AMOUNT_PYMNN_BUILD: {\\\"blocked\\\":0,\\\"failed\\\":%d,\\\"passed\\\":%d,\\\"skipped\\\":0}\\n\" \\\n            $pymnn_build_wrong $[1 - $pymnn_build_wrong]\n    if [ $pymnn_build_wrong -ne 0 ]; then\n        echo '### PYMNN'\n        failed\n    fi\n    popd\n    # 2. unit test\n    pushd test\n    python3 unit_test.py\n    if [ $? -ne 0 ]; then\n        echo '### PYMNN'\n        failed\n    fi\n    # 3. model test\n    python3 model_test.py ~/AliNNModel\n    if [ $? -ne 0 ]; then\n        echo '### PYMNN'\n        failed\n    fi\n    # 4. train test\n    ./train_test.sh\n    # 5. uninstall pymnn\n    pip uninstall --yes MNN-Internal\n    popd\n    popd\n    pushd build\n}\n\nopencv_test() {\n    if [ -z \"$OPENCV_CHANGE\" ]; then\n        return\n    fi\n    # 1. build opencv-test\n    cmake -DMNN_OPENCV_TEST=ON ..\n    make -j8\n    opencv_build_wrong=$[$? > 0]\n    printf \"TEST_NAME_OPENCV_BUILD: OPENCV\\nTEST_CASE_AMOUNT_OPENCV_BUILD: {\\\"blocked\\\":0,\\\"failed\\\":%d,\\\"passed\\\":%d,\\\"skipped\\\":0}\\n\" \\\n            $opencv_build_wrong $[1 - $opencv_build_wrong]\n    if [ $opencv_build_wrong -ne 0 ]; then\n        echo '### OPENCV'\n        failed\n    fi\n    # 2. run opencv unit test\n    ./opencv_test\n    if [ $? -gt 0 ]; then\n        echo '### OPENCV'\n        failed\n    fi\n}\n\nllm_test() {\n    # 1. build llm with low memory\n    cmake -DMNN_LOW_MEMORY=ON -DMNN_BUILD_LLM=ON -DMNN_SUPPORT_TRANSFORMER_FUSE=ON ..\n    make -j8\n    llm_build_wrong=$[$? > 0]\n    printf \"TEST_NAME_LLM_BUILD: LLM\\nTEST_CASE_AMOUNT_LLM_BUILD: {\\\"blocked\\\":0,\\\"failed\\\":%d,\\\"passed\\\":%d,\\\"skipped\\\":0}\\n\" \\\n            $llm_build_wrong $[1 - $llm_build_wrong]\n    if [ $llm_build_wrong -ne 0 ]; then\n        echo '### LLM'\n        failed\n    fi\n    # 2. run llm model test\n    ./llm_demo ~/AliNNModel/qwen1.5-0.5b-int4/config.json ~/AliNNModel/qwen1.5-0.5b-int4/prompt.txt\n    if [ $? -gt 0 ]; then\n        echo '### LLM'\n        failed\n    fi\n}\n\ncoverage_init() {\n    popd\n    lcov -c -i -d ./ -o init.info\n    pushd build\n}\n\ncoverage_report() {\n    popd\n    cover_report_dir=\"../../../../CoverageReport\"\n    lcov -c -d ./ -o cover.info\n    lcov -a init.info -a cover.info -o total.info\n    lcov --remove total.info \\\n    '*/usr/include/*' '*/usr/lib/*' '*/usr/lib64/*' '*/usr/local/*'  \\\n    '*/3rd_party/*' '*/build/*' '*/schema/*' '*/test/*' '/tmp/*' \\\n    '*/demo/*' '*/tools/cpp/*' '*/tools/train/*' '*/source/backend/cuda/*' \\\n    -o final.info\n    commitId=$(git log | head -n1 | awk '{print $2}')\n    genhtml -o cover_report --legend --title \"MNN Coverage Report [commit SHA1:${commitId}]\" --prefix=`pwd` final.info\n    coverage_wrong=$[$? > 0]\n    printf \"TEST_NAME_COVERAGE: (\\\"\\\")\\nTEST_CASE_AMOUNT_COVERAGE: {\\\"blocked\\\":0,\\\"failed\\\":%d,\\\"passed\\\":%d,\\\"skipped\\\":0}\\n\" $coverage_wrong $[1 - $coverage_wrong]\n    if [ $coverage_wrong -ne 0 ]; then\n        echo '### '\n        failed\n    else\n        hostIp=$(cat .aoneci.yml | grep host -m 1 | awk '{print $2}')\n        testId=$(pwd | awk -F \"/\" '{print $(NF-1)}')\n        mv cover_report $cover_report_dir/$testId\n        echo \"TEST_REPORT_COVERAGE: http://$hostIp/$testId\"\n    fi\n    # clean test dir\n    cd ../.. && rm -rf $testId\n}\n\n#############################################################################################\n#                                                                                           #\n#                                  Android Test Functions                                   #\n#                                                                                           #\n#############################################################################################\nandroid_unit_test() {\n    memory_mode=$2\n    adb shell \"cd /data/local/tmp/MNN&&export LD_LIBRARY_PATH=.&&./run_test.out all 0 0 1 $1 $memory_mode\"\n    if [ $? -ne 0 ]; then\n        echo '### Android'\n        failed\n    fi\n    adb shell \"cd /data/local/tmp/MNN&&export LD_LIBRARY_PATH=.&&./run_test.out op 0 0 4 multi$1 $memory_mode\"\n    if [ $? -ne 0 ]; then\n        echo '### Android'\n        failed\n    fi\n    adb shell \"cd /data/local/tmp/MNN&&export LD_LIBRARY_PATH=.&&./run_test.out op/convolution 0 2 4 fp16multi$1 $memory_mode\"\n    if [ $? -ne 0 ]; then\n        echo '### AndroidFP16'\n        failed\n    fi\n    adb shell \"cd /data/local/tmp/MNN&&export LD_LIBRARY_PATH=.&&./run_test.out op/col2im 0 2 4 fp16col2im$1 $memory_mode\"\n    if [ $? -ne 0 ]; then\n        echo '### AndroidFP16-col2im'\n        failed\n    fi\n    adb shell \"cd /data/local/tmp/MNN&&export LD_LIBRARY_PATH=.&&./run_test.out op/R 0 2 4 fp16roipooling$1 $memory_mode\"\n    if [ $? -ne 0 ]; then\n        echo '### AndroidFP16-roipooling'\n        failed\n    fi\n    if [ \"$OPENCL_CHANGE\" ]; then\n        adb shell \"cd /data/local/tmp/MNN&&export LD_LIBRARY_PATH=.&&./run_test.out op 3 1 4 $1 $memory_mode\"\n        if [ $? -ne 0 ]; then\n            echo '### AndroidOpenCL'\n            failed\n        fi\n    fi\n}\nandroid_model_test() {\n    fail_num=0\n    pass_num=0\n    fail_cl_num=0\n    pass_cl_num=0\n    models=`adb shell ls /data/local/tmp/AliNNModel/OpTestResource/`\n    for model in $models\n    do\n        adb shell \"cd /data/local/tmp/MNN&&export LD_LIBRARY_PATH=.&&./testModel.out ../AliNNModel/OpTestResource/$model/temp.bin ../AliNNModel/OpTestResource/$model/input_0.txt ../AliNNModel/OpTestResource/$model/output_0.txt 0 0.002\"\n        if [ $? -ne 0 ]; then\n            fail_num=$[$fail_num+1]\n        else\n            pass_num=$[$pass_num+1]\n        fi\n        if [ \"$OPENCL_CHANGE\" ]; then\n            adb shell \"cd /data/local/tmp/MNN&&export LD_LIBRARY_PATH=.&&./testModel.out ../AliNNModel/OpTestResource/$model/temp.bin ../AliNNModel/OpTestResource/$model/input_0.txt ../AliNNModel/OpTestResource/$model/output_0.txt 3 0.002 1\"\n            if [ $? -ne 0 ]; then\n                fail_cl_num=$[$fail_cl_num+1]\n            else\n                pass_cl_num=$[$pass_cl_num+1]\n            fi\n        fi\n    done\n\n    models=`adb shell ls /data/local/tmp/AliNNModel/TestResource/`\n    for model in $models\n    do\n        if [ $model == 'mobilenetv1quan' ]; then\n            adb shell \"cd /data/local/tmp/MNN&&export LD_LIBRARY_PATH=.&&./testModel.out ../AliNNModel/TestResource/$model/temp.bin ../AliNNModel/TestResource/$model/input_0.txt ../AliNNModel/TestResource/$model/output.txt 0 0.1\"\n        else\n            adb shell \"cd /data/local/tmp/MNN&&export LD_LIBRARY_PATH=.&&./testModel.out ../AliNNModel/TestResource/$model/temp.bin ../AliNNModel/TestResource/$model/input_0.txt ../AliNNModel/TestResource/$model/output.txt 0 0.002\"\n        fi\n        if [ $? -ne 0 ]; then\n            fail_num=$[$fail_num+1]\n        else\n            pass_num=$[$pass_num+1]\n        fi\n        if [ \"$OPENCL_CHANGE\" ]; then\n        if [ $model == 'mobilenetv1quan' ]; then\n            adb shell \"cd /data/local/tmp/MNN&&export LD_LIBRARY_PATH=.&&./testModel.out ../AliNNModel/TestResource/$model/temp.bin ../AliNNModel/TestResource/$model/input_0.txt ../AliNNModel/TestResource/$model/output.txt 3 0.1 1\"\n        else\n            adb shell \"cd /data/local/tmp/MNN&&export LD_LIBRARY_PATH=.&&./testModel.out ../AliNNModel/TestResource/$model/temp.bin ../AliNNModel/TestResource/$model/input_0.txt ../AliNNModel/TestResource/$model/output.txt 3 0.002 1\"\n        fi\n            if [ $? -ne 0 ]; then\n                fail_cl_num=$[$fail_cl_num+1]\n            else\n                pass_cl_num=$[$pass_cl_num+1]\n            fi\n        fi\n    done\n\n    models=`adb shell ls /data/local/tmp/AliNNModel/TestWithDescribe/`\n    for model in $models\n    do\n        adb shell \"cd /data/local/tmp/MNN&&export LD_LIBRARY_PATH=.&&./testModelWithDescribe.out ../AliNNModel/TestWithDescribe/$model/temp.bin ../AliNNModel/TestWithDescribe/$model/config.txt 0 0.002\"\n        if [ $? -ne 0 ]; then\n            fail_num=$[$fail_num+1]\n        else\n            pass_num=$[$pass_num+1]\n        fi\n        if [ \"$OPENCL_CHANGE\" ]; then\n            adb shell \"cd /data/local/tmp/MNN&&export LD_LIBRARY_PATH=.&&./testModelWithDescribe.out ../AliNNModel/TestWithDescribe/$model/temp.bin ../AliNNModel/TestWithDescribe/$model/config.txt 3 0.002 1\"\n            if [ $? -ne 0 ]; then\n                fail_cl_num=$[$fail_cl_num+1]\n            else\n                pass_cl_num=$[$pass_cl_num+1]\n            fi\n        fi\n    done\n    printf \"TEST_NAME_ANDROID_MODEL_TEST_$1: Android_$1\\nTEST_CASE_AMOUNT_ANDROID_MODEL_TEST_$1: {\\\"blocked\\\":0,\\\"failed\\\":$fail_num,\\\"passed\\\":$pass_num,\\\"skipped\\\":0}\\n\"\n    if [ $fail_num -ne 0 ]; then\n        echo '### Android'\n        failed\n    fi\n    if [ \"$OPENCL_CHANGE\" ]; then\n        printf \"TEST_NAME_ANDROID_MODEL_OPENCL_TEST_$1: Android_$1\\nTEST_CASE_AMOUNT_ANDROID_MODEL_TEST_$1: {\\\"blocked\\\":0,\\\"failed\\\":$fail_cl_num,\\\"passed\\\":$pass_cl_num,\\\"skipped\\\":0}\\n\"\n        if [ $fail_cl_num -ne 0 ]; then\n            echo '### Android OpenCL'\n            failed\n        fi\n    fi\n}\nandroid_unit_test_low_memory_armv8() {\n    adb shell \"cd /data/local/tmp/MNN&&export LD_LIBRARY_PATH=.&&./run_test.out op/lowMemory 0 1 1 $1 2\"\n    if [ $? -ne 0 ]; then\n        echo '### Android 64Low Memory,, precision=1, thread=1 '\n        failed\n    fi\n    adb shell \"cd /data/local/tmp/MNN&&export LD_LIBRARY_PATH=.&&./run_test.out op/lowMemory 0 2 1 $1 2\"\n    if [ $? -ne 0 ]; then\n        echo '### Android 64Low Memory,, precision=2, thread=1 '\n        failed\n    fi\n    adb shell \"cd /data/local/tmp/MNN&&export LD_LIBRARY_PATH=.&&./run_test.out op/lowMemory 0 1 4 $1 2\"\n    if [ $? -ne 0 ]; then\n        echo '### Android 64Low Memory,, precision=1, thread=4 '\n        failed\n    fi\n    adb shell \"cd /data/local/tmp/MNN&&export LD_LIBRARY_PATH=.&&./run_test.out op/lowMemory 0 2 4 $1 2\"\n    if [ $? -ne 0 ]; then\n        echo '### Android 64Low Memory,, precision=2, thread=4 '\n        failed\n    fi\n    adb shell \"cd /data/local/tmp/MNN&&export LD_LIBRARY_PATH=.&&./run_test.out op/lowMemory 0 1 1 $1\"\n    if [ $? -ne 0 ]; then\n        echo '### Android 64Low Memory , precision=1 '\n        failed\n    fi\n    adb shell \"cd /data/local/tmp/MNN&&export LD_LIBRARY_PATH=.&&./run_test.out op/lowMemory 0 2 1 $1\"\n    if [ $? -ne 0 ]; then\n        echo '### Android 64Low Memory , precision=2 '\n        failed\n    fi\n}\n\nandroid_unit_test_low_memory_armv7() {\n    adb shell \"cd /data/local/tmp/MNN&&export LD_LIBRARY_PATH=.&&./run_test.out op/lowMemory 0 1 1 $1 2\"\n    if [ $? -ne 0 ]; then\n        echo '### Android 32Low Memory,, precision=1, thread=1 '\n        failed\n    fi\n    adb shell \"cd /data/local/tmp/MNN&&export LD_LIBRARY_PATH=.&&./run_test.out op/lowMemory 0 2 1 $1 2\"\n    if [ $? -ne 0 ]; then\n        echo '### Android 32Low Memory,, precision=2, thread=1 '\n        failed\n    fi\n    adb shell \"cd /data/local/tmp/MNN&&export LD_LIBRARY_PATH=.&&./run_test.out op/lowMemory 0 1 4 $1 2\"\n    if [ $? -ne 0 ]; then\n        echo '### Android 32Low Memory,, precision=1, thread=4 '\n        failed\n    fi\n    adb shell \"cd /data/local/tmp/MNN&&export LD_LIBRARY_PATH=.&&./run_test.out op/lowMemory 0 2 4 $1 2\"\n    if [ $? -ne 0 ]; then\n        echo '### Android 32Low Memory,, precision=2, thread=4 '\n        failed\n    fi\n}\n\nandroid_test() {\n    pushd project/android\n    # 1. build Android32\n    mkdir build_32\n    pushd build_32\n    ../build_32.sh -DMNN_BUILD_TRAIN=OFF -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DMNN_OPENCL=true -DMNN_LOW_MEMORY=ON -DMNN_SUPPORT_TRANSFORMER_FUSE=ON -DMNN_ARM82=OFF\n    android32_build_wrong=$[$? > 0]\n    mnn32_size=$(ls -lh libMNN.so | awk '{print $5}')\n    expr32_size=$(ls -lh libMNN_Express.so | awk '{print $5}')\n    printf \"TEST_NAME_ANDROID_32: Android32(libMNN.so - %s, libMNN_Express.so - %s)\\nTEST_CASE_AMOUNT_ANDROID_32: {\\\"blocked\\\":0,\\\"failed\\\":%d,\\\"passed\\\":%d,\\\"skipped\\\":0}\\n\" \\\n           $mnn32_size $expr32_size $android32_build_wrong $[1 - $android32_build_wrong]\n    if [ $android32_build_wrong -ne 0 ]; then\n        echo '### Android32'\n        failed\n    fi\n    ../updateTest.sh\n    android_unit_test 32bit 1\n    android_unit_test_low_memory_armv7 32bit\n    android_model_test 32\n    popd\n\n    # 3. build Android64\n    mkdir build_64\n    pushd build_64\n    ../build_64.sh -DMNN_BUILD_TRAIN=OFF -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DMNN_ARM82=true -DMNN_OPENCL=true -DMNN_LOW_MEMORY=true -DMNN_SUPPORT_TRANSFORMER_FUSE=ON\n    android64_build_wrong=$[$? > 0]\n    mnn64_size=$(ls -lh libMNN.so | awk '{print $5}')\n    expr64_size=$(ls -lh libMNN_Express.so | awk '{print $5}')\n    printf \"TEST_NAME_ANDROID_64: Android64(libMNN.so - %s, libMNN_Express.so - %s)\\nTEST_CASE_AMOUNT_ANDROID_64: {\\\"blocked\\\":0,\\\"failed\\\":%d,\\\"passed\\\":%d,\\\"skipped\\\":0}\\n\" \\\n            $mnn64_size $expr64_size $android64_build_wrong $[1 - $android64_build_wrong]\n    if [ $android64_build_wrong -ne 0 ]; then\n        echo '### Android64'\n        failed\n    fi\n\n    # 4. test Android64\n    ../updateTest.sh\n    android_unit_test 64 0\n    android_unit_test_low_memory_armv8 64\n    android_model_test 64\n    popd\n\n    popd\n}\n\ncase \"$1\" in\n    local)\n        pushd build\n        unit_test\n        model_test\n        onnx_convert_test\n        tf_convert_test\n        tflite_convert_test\n        torch_convert_test\n        ptq_test\n        pymnn_test\n        ;;\n    linux)\n        doc_check\n        static_check\n        py_check\n        linux_build 1\n        coverage_init\n        unit_test\n        model_test\n        onnx_convert_test\n        tf_convert_test\n        tflite_convert_test\n        torch_convert_test\n        ptq_test\n        pymnn_test\n        opencv_test\n        llm_test\n        coverage_report\n        ;;\n    android)\n        android_static_build\n        android_test\n        ;;\n    static)\n        doc_check\n        static_check\n        py_check\n        ;;\n    *)\n        $1\n        echo $\"Usage: $0 {local|linux|android|func}\"\n        exit 2\nesac\nexit $?\n"
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "transformers",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}