{
  "metadata": {
    "timestamp": 1736566067049,
    "page": 54,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjYw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "xenia-project/xenia",
      "stars": 8390,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".appveyor.yml",
          "type": "blob",
          "size": 2.814453125,
          "content": "version: 1.0.{build}-{branch}\n\nbranches:\n  except:\n    - gh-pages\n\nskip_tags: true\n\nskip_commits:\n  files:\n    - .drone.star\n    - .github/**\n    - android/**\n    - docs/**\n    - src/**/*_posix.*\n    - src/**/*_linux.*\n    - src/**/*_gnulinux.*\n    - src/**/*_x11.*\n    - src/**/*_gtk.*\n    - src/**/*_android.*\n    - src/**/*_mac.*\n    - LICENSE\n    - README.md\n\nskip_branch_with_pr: true\n\npull_requests:\n  do_not_increment_build_number: true\n\nos: Visual Studio 2019\n\ninit:\n  - ps: |\n      If (-Not $env:APPVEYOR_PULL_REQUEST_NUMBER) {\n        $env:is_not_pr = \"true\"\n      }\n      If (-Not $env:APPVEYOR_REPO_COMMIT_MESSAGE_EXTENDED) {\n        $env:APPVEYOR_REPO_COMMIT_MESSAGE_EXTENDED = \" \"\n      }\n\ninstall:\n  - |\n    vcpkg integrate remove\n    xb setup\n\nplatform: Windows\n\nconfiguration: [Release, Checked]\n\nbuild_script:\n  - xb build --config=%CONFIGURATION% --target=src\\xenia-app --target=tests\\xenia-base-tests --target=tests\\xenia-cpu-ppc-tests --target=src\\xenia-vfs-dump\n\nafter_build:\n  - |\n      IF NOT \"%CONFIGURATION%\"==\"Checked\" SET \"ARCHIVE_SUFFIX=%APPVEYOR_REPO_BRANCH%\"\n      IF NOT \"%CONFIGURATION%\"==\"Checked\" SET \"ARCHIVE_SWITCHES=--\"\n      IF     \"%CONFIGURATION%\"==\"Checked\" SET \"ARCHIVE_SUFFIX=%APPVEYOR_REPO_BRANCH%_FOR-DEVS-ONLY\"\n      IF     \"%CONFIGURATION%\"==\"Checked\" SET \"ARCHIVE_SWITCHES=\"-pI know what I am doing.\" --\"\n      7z a xenia_%ARCHIVE_SUFFIX%.zip          %ARCHIVE_SWITCHES% LICENSE \"%APPVEYOR_BUILD_FOLDER%\\build\\bin\\%PLATFORM%\\%CONFIGURATION%\\xenia.exe\"          \"%APPVEYOR_BUILD_FOLDER%\\build\\bin\\%PLATFORM%\\%CONFIGURATION%\\xenia.pdb\"\n      7z a xenia-vfs-dump_%ARCHIVE_SUFFIX%.zip %ARCHIVE_SWITCHES% LICENSE \"%APPVEYOR_BUILD_FOLDER%\\build\\bin\\%PLATFORM%\\%CONFIGURATION%\\xenia-vfs-dump.exe\" \"%APPVEYOR_BUILD_FOLDER%\\build\\bin\\%PLATFORM%\\%CONFIGURATION%\\xenia-vfs-dump.pdb\"\n\nbefore_test:\n  - xb gentests\n\ntest_script:\n  - xb test --config=%CONFIGURATION% --no_build\n\nartifacts:\n  - path: '*.zip'\n  - path: xenia-cpu-ppc-test.log\n\ndeploy:\n  - provider: Environment\n    name: xenia-master\n    release: xenia-$(appveyor_repo_branch)-v$(appveyor_build_version)\n    artifact: '*.zip'\n    draft: false\n    prerelease: true\n    on:\n      branch: master\n      configuration: release\n      appveyor_repo_tag: true\n      is_not_pr: true\n  - provider: GitHub\n    name: xenia-master\n    repository: xenia-project/release-builds-windows\n    auth_token:\n      secure: /8he47z1WnPN7LcCTe5T5KMxxX0SmqFj9QMpeWEa3aZ64kMsfupOT/jKakqTM8af\n    tag: v$(appveyor_build_version)\n    release: v$(appveyor_build_version)\n    description: |\n      Windows release build for https://github.com/xenia-project/xenia/commit/$(APPVEYOR_REPO_COMMIT).\n      \n      $(APPVEYOR_REPO_COMMIT_MESSAGE)\n      \n      $(APPVEYOR_REPO_COMMIT_MESSAGE_EXTENDED)\n    draft: false\n    prerelease: false\n    on:\n      branch: master\n      configuration: release\n      is_not_pr: true\n"
        },
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 0.236328125,
          "content": "---\nBasedOnStyle: Google\nDerivePointerAlignment: false\nPointerAlignment: Left\nSortIncludes: true\n\n# Regroup causes unnecessary noise due to clang-format bug.\nIncludeBlocks: Preserve\n\n---\nLanguage: Java\nDisableFormat: true\nSortIncludes: false\n"
        },
        {
          "name": ".drone.star",
          "type": "blob",
          "size": 12.2939453125,
          "content": "def main(ctx):\n    return [\n        pipeline_lint(),\n        pipeline_linux_desktop('x86_64-linux-clang', image_linux_x86_64(), 'amd64', 'clang', True),\n        pipeline_linux_desktop('x86_64-linux-gcc', image_linux_x86_64(), 'amd64', 'gcc', False), # GCC release linking is really slow\n        pipeline_android('x86_64-android', image_linux_x86_64(), 'amd64', 'Android-x86_64'),\n        pipeline_android('aarch64-android', image_linux_x86_64(), 'amd64', 'Android-ARM64'),\n    ]\n\ndef image_linux_x86_64():\n    return 'xeniaproject/buildenv:2022-07-15'\n\ndef volume_build(toolchain, path='/drone/src/build'):\n    return {\n        'name': 'build-' + toolchain,\n        'path': path,\n    }\n\ndef command_cc(cc):\n    # set CC, CXX, ...\n    return 'export $(cat /{}.env | sed \\'s/#.*//g\\' | xargs)'.format(cc)\n\ndef command_ndk_build(platform, configuration, target):\n    return '$ANDROID_NDK_ROOT/build/ndk-build NDK_PROJECT_PATH:=./bin/{configuration} NDK_APPLICATION_MK:=./xenia.Application.mk PREMAKE_ANDROIDNDK_PLATFORMS:={platform} PREMAKE_ANDROIDNDK_CONFIGURATIONS:={configuration} -j$(nproc) {target}'.format(platform=platform, configuration=configuration, target=target)\n\ndef xenia_base_tests_filters():\n    # https://github.com/xenia-project/xenia/issues/2036\n    return 'exclude:\"Wait on Timer\" exclude:\"Wait on Multiple Timers\" exclude:\"HighResolutionTimer\"'\n\n# Run lint in a separate pipeline so that it will try building even if lint fails\ndef pipeline_lint():\n    return {\n        'kind': 'pipeline',\n        'type': 'docker',\n        'name': 'lint',\n        'steps': [\n            {\n                'name': 'lint',\n                'image': image_linux_x86_64(),\n                'commands': [\n                  'clang-format --version',\n                  './xenia-build lint --all',\n                ],\n            },\n        ],\n    }\n\ndef pipeline_linux_desktop(name, image, arch, cc, build_release_all):\n    return {\n        'kind': 'pipeline',\n        'type': 'docker',\n        'name': name,\n        'platform': {\n            'os': 'linux',\n            'arch': arch,\n        },\n        # These volumes will be mounted at the build directory, allowing to\n        # run different premake toolchains from the same source tree\n        'volumes': [\n          {\n            'name': 'build-premake',\n            'temp': {},\n          },\n          {\n            'name': 'build-cmake',\n            'temp': {},\n          },\n        ],\n\n        'steps': [\n            #\n            # Setup the source tree\n            #\n            {\n                'name': 'clone-submodules',\n                  'image': image,\n                  'commands': [\n                      'pwd',\n                      # May miss recursive submodules (but faster than xb setup)\n                      'git submodule update --init --depth 1 -j $(nproc)',\n                  ],\n              },\n\n\n            #\n            # Setup the two build systems\n            #\n\n            # Native premake Makefiles for production\n            {\n                'name': 'toolchain-premake',\n                'image': image,\n                'volumes': [volume_build('premake')],\n                'commands': [\n                    command_cc(cc),\n                    '$CXX --version',\n                    'python3 --version',\n                    './xenia-build premake --cc={}'.format(cc),\n              ],\n              'depends_on': ['clone-submodules'],\n            },\n\n            # Development toolchain\n            {\n                'name': 'toolchain-cmake',\n                'image': image,\n                'volumes': [volume_build('cmake')],\n                'commands': [\n                    command_cc(cc),\n                    '''\n                    ./xenia-build premake --cc={} --devenv=cmake\n                    cd build\n                    for c in Debug Release\n                    do\n                      mkdir cmake-$c\n                      cmake -S . -B cmake-$c -G Ninja -DCMAKE_BUILD_TYPE=$c\n                    done\n                    '''.format(cc),\n                ],\n                # Premake itself needs to be build first:\n                'depends_on': ['toolchain-premake'],\n            },\n\n            #\n            # Building\n            #\n\n            {\n                'name': 'build-premake-debug-tests',\n                'image': image,\n                'volumes': [volume_build('premake')],\n                'commands': [\n                    command_cc(cc),\n                    './xenia-build build --no_premake -j$(nproc) --config=Debug --target=xenia-base-tests',\n                ],\n                'depends_on': ['toolchain-premake'],\n            },\n            {\n                'name': 'build-premake-debug-all',\n                'image': image,\n                'volumes': [volume_build('premake')],\n                'commands': [\n                    command_cc(cc),\n                    './xenia-build build --no_premake -j$(nproc) --config=Debug',\n                ],\n                'depends_on': ['build-premake-debug-tests'],\n            },\n\n            {\n                'name': 'build-premake-release-tests',\n                'image': image,\n                'volumes': [volume_build('premake')],\n                'commands': [\n                    command_cc(cc),\n                    './xenia-build build --no_premake -j$(nproc) --config=Release --target=xenia-base-tests',\n                ],\n                'depends_on': ['toolchain-premake'],\n            },\n        ] + ([\n            {\n                'name': 'build-premake-release-all',\n                'image': image,\n                'volumes': [volume_build('premake')],\n                'commands': [\n                    command_cc(cc),\n                    './xenia-build build --no_premake -j$(nproc) --config=Release',\n                ],\n                'depends_on': ['build-premake-release-tests'],\n            },\n        ] if build_release_all else []) + [\n\n            {\n                'name': 'build-cmake-debug-all',\n                'image': image,\n                'volumes': [volume_build('cmake')],\n                'commands': [\n                    command_cc(cc),\n                    'cd build/cmake-Debug',\n                    'cmake --build . -j$(nproc)',\n                ],\n                'depends_on': ['toolchain-cmake'],\n            },\n\n            {\n                'name': 'build-cmake-release-tests',\n                'image': image,\n                'volumes': [volume_build('cmake')],\n                'commands': [\n                    command_cc(cc),\n                    'cd build/cmake-Release',\n                    'cmake --build . -j$(nproc) --target xenia-base-tests',\n                ],\n                'depends_on': ['toolchain-cmake'],\n            },\n        ] + ([\n            {\n                'name': 'build-cmake-release-all',\n                'image': image,\n                'volumes': [volume_build('cmake')],\n                'commands': [\n                    command_cc(cc),\n                    'cd build/cmake-Release',\n                    'cmake --build . -j$(nproc)',\n                ],\n                'depends_on': ['build-cmake-release-tests'],\n            },\n        ] if build_release_all else []) + [\n\n\n            #\n            # Tests\n            #\n\n            {\n                'name': 'test-premake-debug-valgrind',\n                'image': image,\n                'volumes': [volume_build('premake')],\n                'commands': [\n                    'valgrind --error-exitcode=99 ./build/bin/Linux/Debug/xenia-base-tests --durations yes ' + xenia_base_tests_filters(),\n                ],\n                'depends_on': ['build-premake-debug-tests'],\n            },\n\n            {\n                'name': 'test-premake-release',\n                'image': image,\n                'volumes': [volume_build('premake')],\n                'commands': [\n                    './build/bin/Linux/Release/xenia-base-tests --success --durations yes ' + xenia_base_tests_filters(),\n                ],\n                'depends_on': ['build-premake-release-tests'],\n            },\n\n            {\n                'name': 'test-cmake-release',\n                'image': image,\n                'volumes': [volume_build('cmake')],\n                'commands': [\n                    './build/bin/Linux/Release/xenia-base-tests --success --durations yes ' + xenia_base_tests_filters(),\n                ],\n                'depends_on': ['build-cmake-release-tests'],\n            },\n\n\n            #\n            # Stat\n            #\n\n            {\n                'name': 'stat',\n                'image': image,\n                'volumes': [\n                  volume_build('premake', '/build-premake'),\n                  volume_build('cmake', '/build-cmake'),\n                ],\n                'commands': [\n                    '''\n                    header() {\n                        SEP='============================================================'\n                        echo\n                        echo $SEP\n                        echo $@\n                        echo $SEP\n                    }\n\n                    for v in premake cmake\n                    do\n                        for c in Debug Release\n                        do\n                            header $v $c\n                            p=/build-$v/bin/Linux/$c\n                            ls -la $p\n                            sha256sum $p/*\n                        done\n                    done\n                    '''\n                ],\n                'depends_on': [\n                    'build-premake-debug-all',\n                    'build-cmake-debug-all',\n                ] + ([\n                    'build-premake-release-all',\n                    'build-cmake-release-all',\n                ] if build_release_all else [\n                    'build-premake-release-tests',\n                    'build-cmake-release-tests',\n                ]),\n            },\n        ],\n    }\n\n\ndef pipeline_android(name, image, arch, platform):\n    return {\n        'kind': 'pipeline',\n        'type': 'docker',\n        'name': name,\n        'platform': {\n            'os': 'linux',\n            'arch': arch,\n        },\n\n        'steps': [\n            #\n            # Setup the source tree\n            #\n            {\n                'name': 'clone-submodules',\n                  'image': image,\n                  'commands': [\n                      'pwd',\n                      # May miss recursive submodules (but faster than xb setup)\n                      'git submodule update --init --depth 1 -j $(nproc)',\n                  ],\n              },\n\n\n            #\n            # Build premake and generate NDK makefiles\n            #\n\n            # NDK Makefiles\n            {\n                'name': 'toolchain',\n                'image': image,\n                'commands': [\n                    'c++ --version',\n                    'python3 --version',\n                    './xenia-build premake --target_os android',\n              ],\n              'depends_on': ['clone-submodules'],\n            },\n\n\n            #\n            # Building\n            #\n            {\n                'name': 'build-debug',\n                'image': image,\n                'commands': [\n                    'cd build',\n                    command_ndk_build(platform, 'Debug', 'all'),\n                ],\n                'depends_on': ['toolchain'],\n            },\n\n            {\n                'name': 'build-release',\n                'image': image,\n                'commands': [\n                    'cd build',\n                    command_ndk_build(platform, 'Release', 'all'),\n                ],\n                'depends_on': ['toolchain'],\n            },\n\n\n            #\n            # Stat\n            #\n            {\n                'name': 'stat',\n                'image': image,\n                'commands': [\n                    '''\n                    header() {\n                        SEP='============================================================'\n                        echo\n                        echo $SEP\n                        echo $@\n                        echo $SEP\n                    }\n\n                    for c in Debug Release\n                    do\n                        header $c\n                        p=build/bin/$c/obj/local/*\n                        ls -la $p\n                        sha256sum $p/* || true\n                    done\n                    '''\n                ],\n                'depends_on': [\n                  'build-debug',\n                  'build-release',\n                ],\n            },\n        ],\n    }\n"
        },
        {
          "name": ".gdbinit",
          "type": "blob",
          "size": 0.3154296875,
          "content": "# Ignore HighResolutionTimer custom event\nhandle SIG34 nostop noprint\n# Ignore PosixTimer custom event\nhandle SIG35 nostop noprint\n# Ignore PosixThread exit event\nhandle SIG32 nostop noprint\n# Ignore PosixThread suspend event\nhandle SIG36 nostop noprint\n# Ignore PosixThread user callback event\nhandle SIG37 nostop noprint\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.369140625,
          "content": "*           text=auto whitespace=blank-at-eol,tab-in-indent,trailing-space,tabwidth=2\n\n*.bat       text eol=crlf\n*.sh        text eol=lf\n\n*.sln       text eol=crlf -whitespace\n*.csproj    text eol=crlf -whitespace merge=union\n*.vcxproj   text eol=crlf -whitespace merge=union\n*.props     text eol=crlf -whitespace merge=union\n\nsrc/**/shaders/bytecode/** linguist-generated=true\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.8720703125,
          "content": "# ==============================================================================\n# Misc system junk\n# ==============================================================================\n\n.DS_Store\n._*\n.Spotlight-V100\n.Trashes\n.com.apple.*\nThumbs.db\nDesktop.ini\n.svn\n\n# Microprofile settings\n.microprofilepreset.*\n\n# ==============================================================================\n# Projects/IDE files\n# ==============================================================================\n\n*~\n\n# Sublime Text\n*.sublime-project\n*.sublime-workspace\n\n# VIM\n.*.sw[a-z]\n*.un~\nSession.vim\n\n# TextMate\n*.tmproj\n*.tmproject\ntmtags\n\n# Eclipse\n.project\n.metadata\n\n# WebStorm\n.idea\n\n# VS\n.vs\n*.user\n*.sdf\n*.opensdf\n*.suo\nbin/\nobj/\n\n# VSCode\n.vscode\n\n# ==============================================================================\n# Temp generated code\n# ==============================================================================\n\n*.py[co]\n.coverage\n*.o\n*.aps\n\n# ==============================================================================\n# Logs and dumps\n# ==============================================================================\n\nnpm-debug.log\nprivate/\n*.trace\nimgui.ini\n*.log\n\n# ==============================================================================\n# Build system output\n# ==============================================================================\n\n# npm/node\n.lock-wscript\nnode_modules/\nnode_modules/**/build/\nnode_modules/.bin/\n\n# coverage/etc\n/scratch/\n\n/build/\n\n# ==============================================================================\n# Local-only paths\n# ==============================================================================\n\n.vagrant\n/attic/\n/content/\n/third_party/binutils/binutils-2.24.tar.gz\n/third_party/binutils/bin/\n/third_party/binutils/powerpc-none-elf/\n/third_party/binutils/share/\n/third_party/binutils/binutils*\n/third_party/vasm/\n/tools/shader-playground/*.dll\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 3.484375,
          "content": "[submodule \"third_party/xbyak\"]\n\tpath = third_party/xbyak\n\turl = https://github.com/xenia-project/xbyak.git\n[submodule \"third_party/imgui\"]\n\tpath = third_party/imgui\n\turl = https://github.com/ocornut/imgui.git\n[submodule \"third_party/binutils-ppc-cygwin\"]\n\tpath = third_party/binutils-ppc-cygwin\n\turl = https://github.com/benvanik/binutils-ppc-cygwin.git\n[submodule \"third_party/catch\"]\n\tpath = third_party/catch\n\turl = https://github.com/catchorg/Catch2.git\n[submodule \"third_party/premake-core\"]\n\tpath = third_party/premake-core\n\turl = https://github.com/xenia-project/premake-core.git\n[submodule \"third_party/snappy\"]\n\tpath = third_party/snappy\n\turl = https://github.com/xenia-project/snappy.git\n[submodule \"third_party/premake-export-compile-commands\"]\n\tpath = third_party/premake-export-compile-commands\n\turl = https://github.com/xenia-project/premake-export-compile-commands.git\n[submodule \"third_party/discord-rpc\"]\n\tpath = third_party/discord-rpc\n\turl = https://github.com/discordapp/discord-rpc.git\n[submodule \"third_party/rapidjson\"]\n\tpath = third_party/rapidjson\n\turl = https://github.com/Tencent/rapidjson.git\n[submodule \"third_party/aes_128\"]\n\tpath = third_party/aes_128\n\turl = https://github.com/openluopworld/aes_128.git\n[submodule \"third_party/capstone\"]\n\tpath = third_party/capstone\n\turl = https://github.com/xenia-project/capstone.git\n[submodule \"third_party/cpptoml\"]\n\tpath = third_party/cpptoml\n\turl = https://github.com/skystrife/cpptoml.git\n[submodule \"third_party/cxxopts\"]\n\tpath = third_party/cxxopts\n\turl = https://github.com/jarro2783/cxxopts.git\n[submodule \"third_party/SDL2\"]\n\tpath = third_party/SDL2\n\turl = https://github.com/libsdl-org/SDL.git\n[submodule \"third_party/utfcpp\"]\n\tpath = third_party/utfcpp\n\turl = https://github.com/xenia-project/utfcpp.git\n[submodule \"third_party/fmt\"]\n\tpath = third_party/fmt\n\turl = https://github.com/fmtlib/fmt.git\n[submodule \"third_party/disruptorplus\"]\n\tpath = third_party/disruptorplus\n\turl = https://github.com/xenia-project/disruptorplus.git\n[submodule \"third_party/DirectXShaderCompiler\"]\n\tpath = third_party/DirectXShaderCompiler\n\turl = https://github.com/microsoft/DirectXShaderCompiler.git\n[submodule \"third_party/premake-cmake\"]\n\tpath = third_party/premake-cmake\n\turl = https://github.com/JoelLinn/premake-cmake.git\n[submodule \"third_party/date\"]\n\tpath = third_party/date\n\turl = https://github.com/HowardHinnant/date.git\n[submodule \"third_party/xxhash\"]\n\tpath = third_party/xxhash\n\turl = https://github.com/Cyan4973/xxHash.git\n[submodule \"third_party/FFmpeg\"]\n\tpath = third_party/FFmpeg\n\turl = https://github.com/xenia-project/FFmpeg.git\n[submodule \"third_party/premake-androidndk\"]\n\tpath = third_party/premake-androidndk\n\turl = https://github.com/Triang3l/premake-androidndk.git\n[submodule \"third_party/FidelityFX-CAS\"]\n\tpath = third_party/FidelityFX-CAS\n\turl = https://github.com/GPUOpen-Effects/FidelityFX-CAS.git\n[submodule \"third_party/FidelityFX-FSR\"]\n\tpath = third_party/FidelityFX-FSR\n\turl = https://github.com/GPUOpen-Effects/FidelityFX-FSR.git\n[submodule \"third_party/Vulkan-Headers\"]\n\tpath = third_party/Vulkan-Headers\n\turl = https://github.com/KhronosGroup/Vulkan-Headers.git\n[submodule \"third_party/glslang\"]\n\tpath = third_party/glslang\n\turl = https://github.com/KhronosGroup/glslang.git\n[submodule \"third_party/SPIRV-Tools\"]\n\tpath = third_party/SPIRV-Tools\n\turl = https://github.com/KhronosGroup/SPIRV-Tools.git\n[submodule \"third_party/VulkanMemoryAllocator\"]\n\tpath = third_party/VulkanMemoryAllocator\n\turl = https://github.com/GPUOpen-LibrariesAndSDKs/VulkanMemoryAllocator.git\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.4462890625,
          "content": "Copyright (c) 2015, Ben Vanik.\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n    * Redistributions in binary form must reproduce the above copyright\n      notice, this list of conditions and the following disclaimer in the\n      documentation and/or other materials provided with the distribution.\n    * Neither the name of the project nor the\n      names of its contributors may be used to endorse or promote products\n      derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL BEN VANIK BE LIABLE FOR ANY\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 3.6337890625,
          "content": "<p align=\"center\">\n    <a href=\"https://github.com/xenia-project/xenia/tree/master/assets/icon\">\n        <img height=\"120px\" src=\"https://raw.githubusercontent.com/xenia-project/xenia/master/assets/icon/128.png\" />\n    </a>\n</p>\n\n<h1 align=\"center\">Xenia - Xbox 360 Emulator</h1>\n\nXenia is an experimental emulator for the Xbox 360. For more information, see the\n[main Xenia wiki](https://github.com/xenia-project/xenia/wiki).\n\n**Interested in supporting the core contributors?** Visit\n[Xenia Project on Patreon](https://www.patreon.com/xenia_project).\n\nCome chat with us about **emulator-related topics** on [Discord](https://discord.gg/Q9mxZf9).\nFor developer chat join `#dev` but stay on topic. Lurking is not only fine, but encouraged!\nPlease check the [FAQ](https://github.com/xenia-project/xenia/wiki/FAQ) page before asking questions.\nWe've got jobs/lives/etc, so don't expect instant answers.\n\nDiscussing illegal activities will get you banned.\n\n## Status\n\nBuildbot | Status | Releases\n-------- | ------ | --------\n[Windows](https://ci.appveyor.com/project/benvanik/xenia/branch/master) | [![Build status](https://ci.appveyor.com/api/projects/status/ftqiy86kdfawyx3a/branch/master?svg=true)](https://ci.appveyor.com/project/benvanik/xenia/branch/master) | [Latest](https://github.com/xenia-project/release-builds-windows/releases/latest) ◦ [All](https://github.com/xenia-project/release-builds-windows/releases)\n[Linux](https://cloud.drone.io/xenia-project/xenia) | [![Build status](https://cloud.drone.io/api/badges/xenia-project/xenia/status.svg)](https://cloud.drone.io/xenia-project/xenia)\n\nQuite a few real games run. Quite a few don't.\nSee the [Game compatibility list](https://github.com/xenia-project/game-compatibility/issues)\nfor currently tracked games, and feel free to contribute your own updates,\nscreenshots, and information there following the [existing conventions](https://github.com/xenia-project/game-compatibility/blob/master/README.md).\n\n## Disclaimer\n\nThe goal of this project is to experiment, research, and educate on the topic\nof emulation of modern devices and operating systems. **It is not for enabling\nillegal activity**. All information is obtained via reverse engineering of\nlegally purchased devices and games and information made public on the internet\n(you'd be surprised what's indexed on Google...).\n\n## Quickstart\n\nSee the [Quickstart](https://github.com/xenia-project/xenia/wiki/Quickstart) page.\n\n## Building\n\nSee [building.md](docs/building.md) for setup and information about the\n`xb` script. When writing code, check the [style guide](docs/style_guide.md)\nand be sure to run clang-format!\n\n## Contributors Wanted!\n\nHave some spare time, know advanced C++, and want to write an emulator?\nContribute! There's a ton of work that needs to be done, a lot of which\nis wide open greenfield fun.\n\n**For general rules and guidelines please see [CONTRIBUTING.md](.github/CONTRIBUTING.md).**\n\nFixes and optimizations are always welcome (please!), but in addition to\nthat there are some major work areas still untouched:\n\n* Help work through [missing functionality/bugs in games](https://github.com/xenia-project/xenia/labels/compat)\n* Reduce the size of Xenia's [huge log files](https://github.com/xenia-project/xenia/issues/1526)\n* Skilled with Linux? A strong contributor is needed to [help with porting](https://github.com/xenia-project/xenia/labels/platform-linux)\n\nSee more projects [good for contributors](https://github.com/xenia-project/xenia/labels/good%20first%20issue). It's a good idea to ask on Discord and check the issues page before beginning work on\nsomething.\n\n## FAQ\n\nSee the [frequently asked questions](https://github.com/xenia-project/xenia/wiki/FAQ) page.\n"
        },
        {
          "name": "android",
          "type": "tree",
          "content": null
        },
        {
          "name": "assets",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "premake5.lua",
          "type": "blob",
          "size": 8.2333984375,
          "content": "include(\"tools/build\")\nrequire(\"third_party/premake-export-compile-commands/export-compile-commands\")\nrequire(\"third_party/premake-androidndk/androidndk\")\nrequire(\"third_party/premake-cmake/cmake\")\n\nlocation(build_root)\ntargetdir(build_bin)\nobjdir(build_obj)\n\n-- Define an ARCH variable\n-- Only use this to enable architecture-specific functionality.\nif os.istarget(\"linux\") then\n  ARCH = os.outputof(\"uname -p\")\nelse\n  ARCH = \"unknown\"\nend\n\nincludedirs({\n  \".\",\n  \"src\",\n  \"third_party\",\n})\n\ndefines({\n  \"_UNICODE\",\n  \"UNICODE\",\n})\n\ncppdialect(\"C++17\")\nexceptionhandling(\"On\")\nrtti(\"On\")\nsymbols(\"On\")\n\n-- TODO(DrChat): Find a way to disable this on other architectures.\nif ARCH ~= \"ppc64\" then\n  filter(\"architecture:x86_64\")\n    vectorextensions(\"AVX\")\n  filter({})\nend\n\ncharacterset(\"Unicode\")\nflags({\n  \"FatalWarnings\",        -- Treat warnings as errors.\n})\n\nfilter(\"kind:StaticLib\")\n  defines({\n    \"_LIB\",\n  })\n\nfilter(\"configurations:Checked\")\n  runtime(\"Debug\")\n  optimize(\"Off\")\n  defines({\n    \"DEBUG\",\n  })\nfilter({\"configurations:Checked\", \"platforms:Windows\"})\n  buildoptions({\n    \"/RTCsu\",           -- Full Run-Time Checks.\n  })\nfilter({\"configurations:Checked\", \"platforms:Linux\"})\n  defines({\n    \"_GLIBCXX_DEBUG\",   -- libstdc++ debug mode\n  })\n\nfilter(\"configurations:Debug\")\n  runtime(\"Release\")\n  optimize(\"Off\")\n  defines({\n    \"DEBUG\",\n    \"_NO_DEBUG_HEAP=1\",\n  })\nfilter({\"configurations:Debug\", \"platforms:Linux\"})\n  defines({\n    \"_GLIBCXX_DEBUG\",   -- make dbg symbols work on some distros\n  })\n\nfilter(\"configurations:Release\")\n  runtime(\"Release\")\n  defines({\n    \"NDEBUG\",\n    \"_NO_DEBUG_HEAP=1\",\n  })\n  optimize(\"Speed\")\n  inlining(\"Auto\")\n  flags({\n    \"LinkTimeOptimization\",\n  })\n  -- Not using floatingpoint(\"Fast\") - NaN checks are used in some places\n  -- (though rarely), overall preferable to avoid any functional differences\n  -- between debug and release builds, and to have calculations involved in GPU\n  -- (especially anything that may affect vertex position invariance) and CPU\n  -- (such as constant propagation) emulation as predictable as possible,\n  -- including handling of specials since games make assumptions about them.\nfilter(\"platforms:Linux\")\n  system(\"linux\")\n  toolset(\"clang\")\n  buildoptions({\n    -- \"-mlzcnt\",  -- (don't) Assume lzcnt is supported.\n  })\n  pkg_config.all(\"gtk+-x11-3.0\")\n  links({\n    \"stdc++fs\",\n    \"dl\",\n    \"lz4\",\n    \"pthread\",\n    \"rt\",\n  })\n\nfilter({\"platforms:Linux\", \"kind:*App\"})\n  linkgroups(\"On\")\n\nfilter({\"platforms:Linux\", \"language:C++\", \"toolset:gcc\"})\n  disablewarnings({\n    \"unused-result\"\n  })\n\nfilter({\"platforms:Linux\", \"toolset:gcc\"})\n  if ARCH == \"ppc64\" then\n    buildoptions({\n      \"-m32\",\n      \"-mpowerpc64\"\n    })\n    linkoptions({\n      \"-m32\",\n      \"-mpowerpc64\"\n    })\n  end\n\nfilter({\"platforms:Linux\", \"language:C++\", \"toolset:clang\"})\n  disablewarnings({\n    \"deprecated-register\"\n  })\nfilter({\"platforms:Linux\", \"language:C++\", \"toolset:clang\", \"files:*.cc or *.cpp\"})\n  buildoptions({\n    \"-stdlib=libstdc++\",\n  })\n\nfilter(\"platforms:Android-*\")\n  system(\"android\")\n  systemversion(\"24\")\n  cppstl(\"c++\")\n  staticruntime(\"On\")\n  -- Hidden visibility is needed to prevent dynamic relocations in FFmpeg\n  -- AArch64 Neon libavcodec assembly with PIC (accesses extern lookup tables\n  -- using `adrp` and `add`, without the Global Object Table, expecting that all\n  -- FFmpeg symbols that aren't a part of the FFmpeg API are hidden by FFmpeg's\n  -- original build system) by resolving those relocations at link time instead.\n  visibility(\"Hidden\")\n  links({\n    \"android\",\n    \"dl\",\n    \"log\",\n  })\n\nfilter(\"platforms:Windows\")\n  system(\"windows\")\n  toolset(\"msc\")\n  buildoptions({\n    \"/utf-8\",   -- 'build correctly on systems with non-Latin codepages'.\n    -- Mark warnings as severe\n    \"/w14839\",  -- non-standard use of class 'type' as an argument to a variadic function\n    \"/w14840\",  -- non-portable use of class 'type' as an argument to a variadic function\n    -- Disable warnings\n    \"/wd4100\",  -- Unreferenced parameters are ok.\n    \"/wd4201\",  -- Nameless struct/unions are ok.\n    \"/wd4512\",  -- 'assignment operator was implicitly defined as deleted'.\n    \"/wd4127\",  -- 'conditional expression is constant'.\n    \"/wd4324\",  -- 'structure was padded due to alignment specifier'.\n    \"/wd4189\",  -- 'local variable is initialized but not referenced'.\n  })\n  flags({\n    \"MultiProcessorCompile\",  -- Multiprocessor compilation.\n    \"NoMinimalRebuild\",       -- Required for /MP above.\n  })\n\n  defines({\n    \"_CRT_NONSTDC_NO_DEPRECATE\",\n    \"_CRT_SECURE_NO_WARNINGS\",\n    \"WIN32\",\n    \"_WIN64=1\",\n    \"_AMD64=1\",\n  })\n  linkoptions({\n    \"/ignore:4006\",  -- Ignores complaints about empty obj files.\n    \"/ignore:4221\",\n  })\n  links({\n    \"ntdll\",\n    \"wsock32\",\n    \"ws2_32\",\n    \"xinput\",\n    \"comctl32\",\n    \"shcore\",\n    \"shlwapi\",\n    \"dxguid\",\n    \"bcrypt\",\n  })\n\n-- Embed the manifest for things like dependencies and DPI awareness.\nfilter({\"platforms:Windows\", \"kind:ConsoleApp or WindowedApp\"})\n  files({\n    \"src/xenia/base/app_win32.manifest\"\n  })\n\n-- Create scratch/ path\nif not os.isdir(\"scratch\") then\n  os.mkdir(\"scratch\")\nend\n\nworkspace(\"xenia\")\n  uuid(\"931ef4b0-6170-4f7a-aaf2-0fece7632747\")\n  startproject(\"xenia-app\")\n  if os.istarget(\"android\") then\n    platforms({\"Android-ARM64\", \"Android-x86_64\"})\n    filter(\"platforms:Android-ARM64\")\n      architecture(\"ARM64\")\n    filter(\"platforms:Android-x86_64\")\n      architecture(\"x86_64\")\n    filter({})\n  else\n    architecture(\"x86_64\")\n    if os.istarget(\"linux\") then\n      platforms({\"Linux\"})\n    elseif os.istarget(\"macosx\") then\n      platforms({\"Mac\"})\n      xcodebuildsettings({           \n        [\"ARCHS\"] = \"x86_64\"\n      })\n    elseif os.istarget(\"windows\") then\n      platforms({\"Windows\"})\n      -- 10.0.15063.0: ID3D12GraphicsCommandList1::SetSamplePositions.\n      -- 10.0.19041.0: D3D12_HEAP_FLAG_CREATE_NOT_ZEROED.\n      -- 10.0.22000.0: DWMWA_WINDOW_CORNER_PREFERENCE.\n      filter(\"action:vs2017\")\n        systemversion(\"10.0.22000.0\")\n      filter(\"action:vs2019\")\n        systemversion(\"10.0\")\n      filter({})\n    end\n  end\n  configurations({\"Checked\", \"Debug\", \"Release\"})\n\n  include(\"third_party/aes_128.lua\")\n  include(\"third_party/capstone.lua\")\n  include(\"third_party/dxbc.lua\")\n  include(\"third_party/discord-rpc.lua\")\n  include(\"third_party/cxxopts.lua\")\n  include(\"third_party/cpptoml.lua\")\n  include(\"third_party/FFmpeg/premake5.lua\")\n  include(\"third_party/fmt.lua\")\n  include(\"third_party/glslang-spirv.lua\")\n  include(\"third_party/imgui.lua\")\n  include(\"third_party/mspack.lua\")\n  include(\"third_party/snappy.lua\")\n  include(\"third_party/xxhash.lua\")\n\n  if not os.istarget(\"android\") then\n    -- SDL2 requires sdl2-config, and as of November 2020 isn't high-quality on\n    -- Android yet, most importantly in game controllers - the keycode and axis\n    -- enums are being ruined during conversion to SDL2 enums resulting in only\n    -- one controller (Nvidia Shield) being supported, digital triggers are also\n    -- not supported; lifecycle management (especially surface loss) is also\n    -- complicated.\n    include(\"third_party/SDL2.lua\")\n  end\n\n  -- Disable treating warnings as fatal errors for all third party projects, as\n  -- well as other things relevant only to Xenia itself.\n  for _, prj in ipairs(premake.api.scope.current.solution.projects) do\n    project(prj.name)\n    removefiles({\n      \"src/xenia/base/app_win32.manifest\"\n    })\n    removeflags({\n      \"FatalWarnings\",\n    })\n  end\n\n  include(\"src/xenia\")\n  include(\"src/xenia/app\")\n  include(\"src/xenia/app/discord\")\n  include(\"src/xenia/apu\")\n  include(\"src/xenia/apu/nop\")\n  include(\"src/xenia/base\")\n  include(\"src/xenia/cpu\")\n  include(\"src/xenia/cpu/backend/x64\")\n  include(\"src/xenia/debug/ui\")\n  include(\"src/xenia/gpu\")\n  include(\"src/xenia/gpu/null\")\n  include(\"src/xenia/gpu/vulkan\")\n  include(\"src/xenia/hid\")\n  include(\"src/xenia/hid/nop\")\n  include(\"src/xenia/kernel\")\n  include(\"src/xenia/ui\")\n  include(\"src/xenia/ui/vulkan\")\n  include(\"src/xenia/vfs\")\n\n  if not os.istarget(\"android\") then\n    include(\"src/xenia/apu/sdl\")\n    include(\"src/xenia/helper/sdl\")\n    include(\"src/xenia/hid/sdl\")\n  end\n\n  if os.istarget(\"windows\") then\n    include(\"src/xenia/apu/xaudio2\")\n    include(\"src/xenia/gpu/d3d12\")\n    include(\"src/xenia/hid/winkey\")\n    include(\"src/xenia/hid/xinput\")\n    include(\"src/xenia/ui/d3d12\")\n  end\n"
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "third_party",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "xb",
          "type": "blob",
          "size": 0.0107421875,
          "content": "xenia-build"
        },
        {
          "name": "xb.bat",
          "type": "blob",
          "size": 2.5673828125,
          "content": "@ECHO OFF\nREM Copyright 2022 Ben Vanik. All Rights Reserved.\n\nSET \"DIR=%~dp0\"\n\nREM ============================================================================\nREM Environment Validation\nREM ============================================================================\n\nSET \"PYTHON_MINIMUM_VERSION[0]=3\"\nSET \"PYTHON_MINIMUM_VERSION[1]=6\"\nCALL :check_python\nIF %_RESULT% NEQ 0 (\n  ECHO.\n  ECHO Python %PYTHON_MINIMUM_VERSION[0]%.%PYTHON_MINIMUM_VERSION[1]%+ must be installed and on PATH:\n  ECHO https://www.python.org/\n  GOTO :eof\n)\n\n\nREM ============================================================================\nREM Trampoline into xenia-build\nREM ============================================================================\n\n\"%PYTHON_EXE%\" \"%DIR%\\xenia-build\" %*\nEXIT /b %ERRORLEVEL%\n\n\nREM ============================================================================\nREM Utilities\nREM ============================================================================\n\n:check_python\nSETLOCAL ENABLEDELAYEDEXPANSION\n\nSET FOUND_PATH=\"\"\n\nSET \"CANDIDATE_PATHS[0]=C:\\python310\\python.exe\"\nSET \"CANDIDATE_PATHS[1]=C:\\python39\\python.exe\"\nSET \"CANDIDATE_PATHS[2]=C:\\python38\\python.exe\"\nSET \"CANDIDATE_PATHS[3]=C:\\python37\\python.exe\"\nSET \"CANDIDATE_PATHS[4]=C:\\python%PYTHON_MINIMUM_VERSION[0]%%PYTHON_MINIMUM_VERSION[1]%\\python.exe\"\nSET OUTPUT_INDEX=5\n\nFOR /F \"usebackq delims=\" %%L IN (`2^>NUL where python3`) DO (\n  IF %%~zL NEQ 0 (\n    SET \"CANDIDATE_PATHS[!OUTPUT_INDEX!]=%%L\"\n    SET /A OUTPUT_INDEX+=1\n  )\n)\nFOR /F \"usebackq delims=\" %%L IN (`2^>NUL where python`) DO (\n  IF %%~zL NEQ 0 (\n    SET \"CANDIDATE_PATHS[!OUTPUT_INDEX!]=%%L\"\n    SET /A OUTPUT_INDEX+=1\n  )\n)\n\nSET CANDIDATE_INDEX=0\n:check_candidate_loop\nIF NOT DEFINED CANDIDATE_PATHS[%CANDIDATE_INDEX%] (\n  GOTO :found_python\n)\nCALL SET CANDIDATE_PATH=%%CANDIDATE_PATHS[%CANDIDATE_INDEX%]%%\nIF NOT EXIST \"%CANDIDATE_PATH%\" (\n  SET /A CANDIDATE_INDEX+=1\n  GOTO :check_candidate_loop\n)\nSET \"FOUND_PATH=%CANDIDATE_PATH%\"\n\n:found_python\nIF \"%FOUND_PATH%\"==\"\" (\n  ECHO ERROR: no Python executable found on PATH.\n  ECHO Make sure you can run 'python' or 'python3' in a Command Prompt.\n  ENDLOCAL & SET _RESULT=1\n  GOTO :eof\n)\n\nCMD /C \"\"%FOUND_PATH%\" -c \"import sys; sys.exit(1 if not sys.version_info[:2] ^>= (%PYTHON_MINIMUM_VERSION[0]%, %PYTHON_MINIMUM_VERSION[1]%) else 0)\"\nIF %ERRORLEVEL% NEQ 0 (\n  ECHO ERROR: Python version mismatch, not at least %PYTHON_MINIMUM_VERSION[0]%.%PYTHON_MINIMUM_VERSION[1]%.\n  ECHO Found Python executable was \"%FOUND_PATH%\".\n  ENDLOCAL & SET _RESULT=1\n  GOTO :eof\n)\n\nENDLOCAL & (\n  SET _RESULT=0\n  SET \"PYTHON_EXE=%FOUND_PATH%\"\n)\nGOTO :eof\n"
        },
        {
          "name": "xb.ps1",
          "type": "blob",
          "size": 1.056640625,
          "content": "function Write-FatalError($message) {\n    [Console]::ForegroundColor = 'red'\n    [Console]::Error.WriteLine($message)\n    [Console]::ResetColor()\n    Exit 1\n}\n\n$pythonExecutables = 'python', 'python3'\nforeach ($pythonExecutable in $pythonExecutables) {\n    if (!$pythonPath) {\n        $pythonPath = powershell -NoLogo -NonInteractive \"(Get-Command -ErrorAction SilentlyContinue $pythonexecutable).Definition\" # Hack to not give command suggestion\n    } else {\n        break\n    }\n}\n# Neither found, error and exit\n$pythonMinimumVer = 3,6\nif (!$pythonPath) {\n    Write-FatalError \"ERROR: Python $($pythonMinimumVer[0]).$($pythonMinimumVer[1])+ must be installed and on PATH:`nhttps://www.python.org/\"\n}\n\n& $pythonPath -c \"import sys; sys.exit(1 if not sys.version_info[:2] >= ($($pythonMinimumVer[0]), $($pythonMinimumVer[1])) else 0)\"\nif ($LASTEXITCODE -gt 0) {\n    Write-FatalError \"ERROR: Python version mismatch, not at least $($pythonMinimumVer[0]).$($pythonMinimumVer[1]).`nFound Python executable was `\"$($pythonPath)`\".\"\n}\n\n& $pythonPath \"$($PSScriptRoot)/xenia-build\" $args\n"
        },
        {
          "name": "xenia-build",
          "type": "blob",
          "size": 64.3349609375,
          "content": "#!/usr/bin/env python3\n\n# Copyright 2022 Ben Vanik. All Rights Reserved.\n\n\"\"\"Main build script and tooling for xenia.\n\nRun with --help or no arguments for possible commands.\n\"\"\"\nfrom __future__ import print_function\nfrom datetime import datetime\nfrom multiprocessing import Pool\nfrom functools import partial\nimport argparse\nimport json\nimport os\nimport re\nimport shutil\nimport subprocess\nimport sys\n\n__author__ = 'ben.vanik@gmail.com (Ben Vanik)'\n\n\nself_path = os.path.dirname(os.path.abspath(__file__))\n\n\n# Detect if building on Android via Termux.\nhost_linux_platform_is_android = False\nif sys.platform == 'linux':\n    try:\n        host_linux_platform_is_android = subprocess.Popen(\n            ['uname', '-o'], stdout=subprocess.PIPE, stderr=subprocess.DEVNULL,\n            universal_newlines=True).communicate()[0] == 'Android\\n'\n    except Exception:\n        pass\n\n\ndef import_subprocess_environment(args):\n    popen = subprocess.Popen(\n        args, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)\n    variables, _ = popen.communicate()\n    envvars_to_save = (\n        'devenvdir',\n        'include',\n        'lib',\n        'libpath',\n        'path',\n        'pathext',\n        'systemroot',\n        'temp',\n        'tmp',\n        'windowssdkdir',\n        )\n    for line in variables.splitlines():\n        for envvar in envvars_to_save:\n            if re.match(envvar + '=', line.lower()):\n                var, setting = line.split('=', 1)\n                if envvar == 'path':\n                    setting = os.path.dirname(sys.executable) + os.pathsep + setting\n                os.environ[var.upper()] = setting\n                break\n\n\ndef import_vs_environment():\n    \"\"\"Finds the installed Visual Studio version and imports\n    interesting environment variables into os.environ.\n\n    Returns:\n      A version such as 2015 or None if no installation is found.\n    \"\"\"\n\n    if sys.platform != 'win32':\n        return None\n\n    version = 0\n    install_path = None\n    env_tool_args = None\n\n    vswhere = subprocess.check_output(\n        'tools/vswhere/vswhere.exe -version \"[15,)\" -latest -prerelease -format json -utf8 -products '\n        \"Microsoft.VisualStudio.Product.Enterprise \"\n        \"Microsoft.VisualStudio.Product.Professional \"\n        \"Microsoft.VisualStudio.Product.Community \"\n        \"Microsoft.VisualStudio.Product.BuildTools\",\n        shell=False,\n        universal_newlines=True,\n        encoding=\"utf-8\",\n    )\n    if vswhere:\n        vswhere = json.loads(vswhere)\n    if vswhere and len(vswhere) > 0:\n        version = int(vswhere[0].get(\"catalog\", {}).get(\"productLineVersion\", 2017))\n        install_path = vswhere[0].get(\"installationPath\", None)\n\n    if version < 2017:\n        if 'VS140COMNTOOLS' in os.environ:\n            version = 2015\n            vcvars_path = os.environ['VS140COMNTOOLS']\n            vcvars_path = os.path.join(vcvars_path, '..\\\\..\\\\vc\\\\vcvarsall.bat')\n            env_tool_args = [vcvars_path, 'x64', '&&', 'set']\n    else:\n        vsdevcmd_path = os.path.join(install_path, 'Common7\\\\Tools\\\\VsDevCmd.bat')\n        if os.path.isfile(vsdevcmd_path) and os.access(vsdevcmd_path, os.X_OK):\n            env_tool_args = [vsdevcmd_path, '-arch=amd64', '-host_arch=amd64', '&&', 'set']\n        else:\n            vcvars_path = os.path.join(install_path, 'VC\\\\Auxiliary\\\\Build\\\\vcvarsall.bat')\n            env_tool_args = [vcvars_path, 'x64', '&&', 'set']\n\n    if version == 0:\n        return None\n\n    import_subprocess_environment(env_tool_args)\n    os.environ['VSVERSION'] = str(version)\n    return version\n\n\nvs_version = import_vs_environment()\n\n\ndef main():\n    # Add self to the root search path.\n    sys.path.insert(0, self_path)\n\n    # Augment path to include our fancy things.\n    os.environ['PATH'] += os.pathsep + os.pathsep.join([\n        self_path,\n        os.path.abspath(os.path.join('tools', 'build')),\n        ])\n\n    # Check git exists.\n    if not has_bin('git'):\n        print('WARNING: Git should be installed and on PATH. Version info will be omitted from all binaries!')\n        print('')\n    elif not git_is_repository():\n        print('WARNING: The source tree is unversioned. Version info will be omitted from all binaries!')\n        print('')\n\n    # Check python version.\n    python_minimum_ver=3,6\n    if not sys.version_info[:2] >= (python_minimum_ver[0], python_minimum_ver[1]):\n        print('ERROR: Python ', python_minimum_ver[0], '.', python_minimum_ver[1], '+ must be installed and on PATH', sep='')\n        sys.exit(1)\n\n    # Grab Visual Studio version and execute shell to set up environment.\n    if sys.platform == 'win32' and vs_version is None:\n        print('WARNING: Visual Studio not found!')\n        print('Building for Windows will not be supported.')\n        print('Please refer to the building guide:')\n        print('https://github.com/xenia-project/xenia/blob/master/docs/building.md')\n\n    # Setup main argument parser and common arguments.\n    parser = argparse.ArgumentParser(prog='xenia-build')\n\n    # Grab all commands and populate the argument parser for each.\n    subparsers = parser.add_subparsers(title='subcommands',\n                                       dest='subcommand')\n    commands = discover_commands(subparsers)\n\n    # If the user passed no args, die nicely.\n    if len(sys.argv) == 1:\n        parser.print_help()\n        sys.exit(1)\n\n    # Gather any arguments that we want to pass to child processes.\n    command_args = sys.argv[1:]\n    pass_args = []\n    try:\n        pass_index = command_args.index('--')\n        pass_args = command_args[pass_index + 1:]\n        command_args = command_args[:pass_index]\n    except Exception:\n        pass\n\n    # Parse command name and dispatch.\n    args = vars(parser.parse_args(command_args))\n    command_name = args['subcommand']\n    try:\n        command = commands[command_name]\n        return_code = command.execute(args, pass_args, os.getcwd())\n    except Exception:\n        raise\n    sys.exit(return_code)\n\n\ndef print_box(msg):\n    \"\"\"Prints an important message inside a box\n    \"\"\"\n    print(\n        '┌{0:─^{2}}╖\\n'\n        '│{1: ^{2}}║\\n'\n        '╘{0:═^{2}}╝\\n'\n        .format('', msg, len(msg) + 2))\n\n\ndef has_bin(binary):\n    \"\"\"Checks whether the given binary is present.\n\n    Args:\n      binary: binary name (without .exe, etc).\n\n    Returns:\n      True if the binary exists.\n    \"\"\"\n    bin_path = get_bin(binary)\n    if not bin_path:\n        return False\n    return True\n\n\ndef get_bin(binary):\n    \"\"\"Checks whether the given binary is present and returns the path.\n\n    Args:\n      binary: binary name (without .exe, etc).\n\n    Returns:\n      Full path to the binary or None if not found.\n    \"\"\"\n    for path in os.environ['PATH'].split(os.pathsep):\n        path = path.strip('\"')\n        exe_file = os.path.join(path, binary)\n        if os.path.isfile(exe_file) and os.access(exe_file, os.X_OK):\n            return exe_file\n        exe_file += '.exe'\n        if os.path.isfile(exe_file) and os.access(exe_file, os.X_OK):\n            return exe_file\n    return None\n\n\ndef shell_call(command, throw_on_error=True, stdout_path=None, stderr_path=None, shell=False):\n    \"\"\"Executes a shell command.\n\n    Args:\n      command: Command to execute, as a list of parameters.\n      throw_on_error: Whether to throw an error or return the status code.\n      stdout_path: File path to write stdout output to.\n      stderr_path: File path to write stderr output to.\n\n    Returns:\n      If throw_on_error is False the status code of the call will be returned.\n    \"\"\"\n    stdout_file = None\n    if stdout_path:\n        stdout_file = open(stdout_path, 'w')\n    stderr_file = None\n    if stderr_path:\n        stderr_file = open(stderr_path, 'w')\n    result = 0\n    try:\n        if throw_on_error:\n            result = 1\n            subprocess.check_call(command, shell=shell, stdout=stdout_file, stderr=stderr_file)\n            result = 0\n        else:\n            result = subprocess.call(command, shell=shell, stdout=stdout_file, stderr=stderr_file)\n    finally:\n        if stdout_file:\n            stdout_file.close()\n        if stderr_file:\n            stderr_file.close()\n    return result\n\n\ndef generate_version_h():\n    \"\"\"Generates a build/version.h file that contains current git info.\n    \"\"\"\n    header_file = 'build/version.h'\n    pr_number = 0\n    pr_repo_name = \"\"\n    pr_branch_name = \"\"\n    pr_commit = \"\"\n    pr_commit_short = \"\"\n    if os.getenv('APPVEYOR') == 'True':\n      branch_name = os.getenv('APPVEYOR_REPO_BRANCH')\n      commit = os.getenv('APPVEYOR_REPO_COMMIT')\n      commit_short = commit[:9]\n      pr_number = os.getenv('APPVEYOR_PULL_REQUEST_NUMBER')\n      if not pr_number:\n        pr_number = 0\n      else:\n        pr_repo_name = os.getenv('APPVEYOR_PULL_REQUEST_HEAD_REPO_NAME')\n        pr_branch_name = os.getenv('APPVEYOR_PULL_REQUEST_HEAD_REPO_BRANCH')\n        pr_commit = os.getenv('APPVEYOR_PULL_REQUEST_HEAD_COMMIT')\n        pr_commit_short = pr_commit[:9]\n    elif git_is_repository():\n        (branch_name, commit, commit_short) = git_get_head_info()\n    else:\n        branch_name = 'tarball'\n        commit = ':(-dont-do-this'\n        commit_short = ':('\n\n    # header\n    contents_new = '''// Autogenerated by `xb premake`.\n#ifndef GENERATED_VERSION_H_\n#define GENERATED_VERSION_H_\n#define XE_BUILD_BRANCH \"{}\"\n#define XE_BUILD_COMMIT \"{}\"\n#define XE_BUILD_COMMIT_SHORT \"{}\"\n#define XE_BUILD_DATE __DATE__\n'''.format(branch_name, commit, commit_short)\n\n    # PR info (if available)\n    if pr_number != 0:\n      contents_new += '''#define XE_BUILD_IS_PR\n#define XE_BUILD_PR_NUMBER \"{}\"\n#define XE_BUILD_PR_REPO \"{}\"\n#define XE_BUILD_PR_BRANCH \"{}\"\n#define XE_BUILD_PR_COMMIT \"{}\"\n#define XE_BUILD_PR_COMMIT_SHORT \"{}\"\n'''.format(pr_number, pr_repo_name, pr_branch_name, pr_commit, pr_commit_short)\n\n    # footer\n    contents_new += '''#endif  // GENERATED_VERSION_H_\n'''\n\n    contents_old = None\n    if os.path.exists(header_file) and os.path.getsize(header_file) < 1024:\n        with open(header_file, 'r') as f:\n            contents_old = f.read()\n\n    if contents_old != contents_new:\n        with open(header_file, 'w') as f:\n            f.write(contents_new)\n\n\ndef generate_source_class(path):\n    header_path = '{}.h'.format(path)\n    source_path = '{}.cc'.format(path)\n\n    if os.path.isfile(header_path) or os.path.isfile(source_path):\n        print('ERROR: Target file already exists')\n        return 1\n\n    if generate_source_file(header_path) > 0:\n        return 1\n    if generate_source_file(source_path) > 0:\n        # remove header if source file generation failed\n        os.remove(os.path.join(source_root, header_path))\n        return 1\n\n    return 0\n\ndef generate_source_file(path):\n    \"\"\"Generates a source file at the specified path containing copyright notice\n    \"\"\"\n    copyright = '''/**\n ******************************************************************************\n * Xenia : Xbox 360 Emulator Research Project                                 *\n ******************************************************************************\n * Copyright {} Ben Vanik. All rights reserved.                             *\n * Released under the BSD license - see LICENSE in the root for more details. *\n ******************************************************************************\n */'''.format(datetime.now().year)\n\n    if os.path.isfile(path):\n        print('ERROR: Target file already exists')\n        return 1\n    try:\n        with open(path, 'w') as f:\n            f.write(copyright)\n    except Exception as e:\n        print('ERROR: Could not write to file [path {}]'.format(path))\n        return 1\n\n    return 0\n\n\n\ndef git_get_head_info():\n    \"\"\"Queries the current branch and commit checksum from git.\n\n    Returns:\n      (branch_name, commit, commit_short)\n      If the user is not on any branch the name will be 'detached'.\n    \"\"\"\n    p = subprocess.Popen([\n        'git',\n        'symbolic-ref',\n        '--short',\n        '-q',\n        'HEAD',\n        ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    (stdout, stderr) = p.communicate()\n    branch_name = stdout.decode('ascii').strip() or 'detached'\n    p = subprocess.Popen([\n        'git',\n        'rev-parse',\n        'HEAD',\n        ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    (stdout, stderr) = p.communicate()\n    commit = stdout.decode('ascii').strip() or 'unknown'\n    p = subprocess.Popen([\n        'git',\n        'rev-parse',\n        '--short',\n        'HEAD',\n        ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    (stdout, stderr) = p.communicate()\n    commit_short = stdout.decode('ascii').strip() or 'unknown'\n    return branch_name, commit, commit_short\n\n\ndef git_is_repository():\n    \"\"\"Checks if git is available and this source tree is versioned.\n    \"\"\"\n    if not has_bin('git'):\n        return False\n    return shell_call([\n        'git',\n        'rev-parse',\n        '--is-inside-work-tree',\n        ], throw_on_error=False, stdout_path=os.devnull, stderr_path=os.devnull) == 0\n\n\ndef git_submodule_update():\n    \"\"\"Runs a git submodule init and update.\n    \"\"\"\n    shell_call([\n        'git',\n        '-c',\n        'fetch.recurseSubmodules=on-demand',\n        'submodule',\n        'update',\n        '--init',\n        ])\n\n\ndef get_clang_format_binary():\n    \"\"\"Finds a clang-format binary. Aborts if none is found.\n\n    Returns:\n      A path to the clang-format executable.\n    \"\"\"\n    attempts = [\n        'C:\\\\Program Files\\\\LLVM\\\\bin\\\\clang-format.exe',\n        'C:\\\\Program Files (x86)\\\\LLVM\\\\bin\\\\clang-format.exe',\n        'clang-format-14',\n        'clang-format-13',\n        'clang-format',\n        ]\n    for binary in attempts:\n        if has_bin(binary):\n            return binary\n    print('ERROR: clang-format is not on PATH')\n    print('LLVM is available from https://llvm.org/releases/download.html')\n    print('At least version 13 is required.')\n    print('See docs/style_guide.md for instructions on how to get it.')\n    sys.exit(1)\n\n\ndef get_premake_target_os(target_os_override=None):\n    \"\"\"Gets the target --os to pass to premake, either for the current platform\n    or for the user-specified cross-compilation target.\n\n    Args:\n      target_os_override: override specified by the user for cross-compilation,\n        or None to target the host platform.\n\n    Returns:\n      Target --os to pass to premake. If a return value of this function valid\n      for the current configuration is passed to it again, the same value will\n      be returned.\n    \"\"\"\n    if sys.platform == 'darwin':\n        target_os = 'macosx'\n    elif sys.platform == 'win32':\n        target_os = 'windows'\n    elif host_linux_platform_is_android:\n        target_os = 'android'\n    else:\n        target_os = 'linux'\n    if target_os_override is not None and target_os_override != target_os:\n        if target_os_override == 'android':\n            target_os = target_os_override\n        else:\n            print(\n                'ERROR: cross-compilation is only supported for Android target')\n            sys.exit(0)\n    return target_os\n\n\ndef run_premake(target_os, action, cc=None):\n    \"\"\"Runs premake on the main project with the given format.\n\n    Args:\n      target_os: target --os to pass to premake.\n      action: action to preform.\n    \"\"\"\n    args = [\n        sys.executable,\n        os.path.join('tools', 'build', 'premake'),\n        '--file=premake5.lua',\n        '--os=%s' % target_os,\n        '--test-suite-mode=combined',\n        '--verbose',\n        action,\n    ]\n    if cc:\n        args.insert(4, '--cc=%s' % cc)\n\n    ret = subprocess.call(args, shell=False)\n\n    if ret == 0:\n        generate_version_h()\n\n    return ret\n\n\ndef run_platform_premake(target_os_override=None, cc='clang', devenv=None):\n    \"\"\"Runs all gyp configurations.\n    \"\"\"\n    target_os = get_premake_target_os(target_os_override)\n    if devenv is None:\n        if target_os == 'macosx':\n            devenv = 'xcode4'\n        elif target_os == 'windows':\n            vs_version = '2015'\n            if 'VSVERSION' in os.environ:\n                vs_version = os.environ['VSVERSION']\n            devenv = 'vs' + vs_version\n        elif target_os == 'android':\n            devenv = 'androidndk'\n        else:\n            devenv = 'gmake2'\n    if target_os != 'linux':\n        cc = None\n    return run_premake(target_os=target_os, action=devenv, cc=cc)\n\n\ndef get_build_bin_path(args):\n    \"\"\"Returns the path of the bin/ path with build results based on the\n    configuration specified in the parsed arguments.\n\n    Args:\n      args: Parsed arguments.\n\n    Returns:\n      A full path for the bin folder.\n    \"\"\"\n    if sys.platform == 'darwin':\n        platform = 'macosx'\n    elif sys.platform == 'win32':\n        platform = 'windows'\n    else:\n        platform = 'linux'\n    return os.path.join(self_path, 'build', 'bin', platform.capitalize(), args['config'].capitalize())\n\n\ndef create_clion_workspace():\n    \"\"\"Creates some basic workspace information inside the .idea directory for first start.\n    \"\"\"\n    if os.path.exists('.idea'):\n        # No first start\n        return False\n    print('Generating CLion workspace files...')\n    # Might become easier in the future: https://youtrack.jetbrains.com/issue/CPP-7911\n\n    # Set the location of the CMakeLists.txt\n    os.mkdir('.idea')\n    with open(os.path.join('.idea', 'misc.xml'), 'w') as f:\n        f.write(\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"CMakeWorkspace\" PROJECT_DIR=\"$PROJECT_DIR$/build\">\n    <contentRoot DIR=\"$PROJECT_DIR$\" />\n  </component>\n</project>\n\"\"\")\n\n    # Set available configurations\n    # TODO Find a way to trigger a cmake reload\n    with open(os.path.join('.idea', 'workspace.xml'), 'w') as f:\n        f.write(\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"CMakeSettings\">\n    <configurations>\n      <configuration PROFILE_NAME=\"Checked\" CONFIG_NAME=\"Checked\" />\n      <configuration PROFILE_NAME=\"Debug\" CONFIG_NAME=\"Debug\" />\n      <configuration PROFILE_NAME=\"Release\" CONFIG_NAME=\"Release\" />\n    </configurations>\n  </component>\n</project>\"\"\")\n\n    return True\n\n\ndef discover_commands(subparsers):\n    \"\"\"Looks for all commands and returns a dictionary of them.\n    In the future commands could be discovered on disk.\n\n    Args:\n      subparsers: Argument subparsers parent used to add command parsers.\n\n    Returns:\n      A dictionary containing name-to-Command mappings.\n    \"\"\"\n    commands = {\n        'setup': SetupCommand(subparsers),\n        'pull': PullCommand(subparsers),\n        'premake': PremakeCommand(subparsers),\n        'build': BuildCommand(subparsers),\n        'buildshaders': BuildShadersCommand(subparsers),\n        'devenv': DevenvCommand(subparsers),\n        'gentests': GenTestsCommand(subparsers),\n        'test': TestCommand(subparsers),\n        'gputest': GpuTestCommand(subparsers),\n        'clean': CleanCommand(subparsers),\n        'nuke': NukeCommand(subparsers),\n        'lint': LintCommand(subparsers),\n        'format': FormatCommand(subparsers),\n        'style': StyleCommand(subparsers),\n        'tidy': TidyCommand(subparsers),\n        'stub': StubCommand(subparsers),\n        }\n    return commands\n\n\nclass Command(object):\n    \"\"\"Base type for commands.\n    \"\"\"\n\n    def __init__(self, subparsers, name, help_short=None, help_long=None,\n                 *args, **kwargs):\n        \"\"\"Initializes a command.\n\n        Args:\n          subparsers: Argument subparsers parent used to add command parsers.\n          name: The name of the command exposed to the management script.\n          help_short: Help text printed alongside the command when queried.\n          help_long: Extended help text when viewing command help.\n        \"\"\"\n        self.name = name\n        self.help_short = help_short\n        self.help_long = help_long\n\n        self.parser = subparsers.add_parser(name,\n                                            help=help_short,\n                                            description=help_long)\n        self.parser.set_defaults(command_handler=self)\n\n    def execute(self, args, pass_args, cwd):\n        \"\"\"Executes the command.\n\n        Args:\n          args: Arguments hash for the command.\n          pass_args: Arguments list to pass to child commands.\n          cwd: Current working directory.\n\n        Returns:\n          Return code of the command.\n        \"\"\"\n        return 1\n\n\nclass SetupCommand(Command):\n    \"\"\"'setup' command.\"\"\"\n\n    def __init__(self, subparsers, *args, **kwargs):\n        super(SetupCommand, self).__init__(\n            subparsers,\n            name='setup',\n            help_short='Setup the build environment.',\n            *args, **kwargs)\n        self.parser.add_argument(\n            '--target_os', default=None,\n            help='Target OS passed to premake, for cross-compilation')\n\n    def execute(self, args, pass_args, cwd):\n        print('Setting up the build environment...')\n        print('')\n\n        # Setup submodules.\n        print('- git submodule init / update...')\n        if git_is_repository():\n            git_submodule_update()\n        else:\n            print('WARNING: Git not available or not a repository. Dependencies may be missing.')\n        print('')\n\n        print('- running premake...')\n        ret = run_platform_premake(target_os_override=args['target_os'])\n        print('')\n        print('Success!' if ret == 0 else 'Error!')\n\n        return ret\n\n\nclass PullCommand(Command):\n    \"\"\"'pull' command.\"\"\"\n\n    def __init__(self, subparsers, *args, **kwargs):\n        super(PullCommand, self).__init__(\n            subparsers,\n            name='pull',\n            help_short='Pulls the repo and all dependencies and rebases changes.',\n            *args, **kwargs)\n        self.parser.add_argument(\n            '--merge', action='store_true',\n             help='Merges on master instead of rebasing.')\n        self.parser.add_argument(\n            '--target_os', default=None,\n            help='Target OS passed to premake, for cross-compilation')\n\n    def execute(self, args, pass_args, cwd):\n        print('Pulling...')\n        print('')\n\n        print('- switching to master...')\n        shell_call([\n            'git',\n            'checkout',\n            'master',\n            ])\n        print('')\n\n        print('- pulling self...')\n        if args['merge']:\n            shell_call([\n                'git',\n                'pull',\n                ])\n        else:\n            shell_call([\n                'git',\n                'pull',\n                '--rebase',\n                ])\n        print('')\n\n        print('- pulling dependencies...')\n        git_submodule_update()\n        print('')\n\n        print('- running premake...')\n        if run_platform_premake(target_os_override=args['target_os']) == 0:\n            print('')\n            print('Success!')\n\n        return 0\n\n\nclass PremakeCommand(Command):\n    \"\"\"'premake' command.\"\"\"\n\n    def __init__(self, subparsers, *args, **kwargs):\n        super(PremakeCommand, self).__init__(\n            subparsers,\n            name='premake',\n            help_short='Runs premake to update all projects.',\n            *args, **kwargs)\n        self.parser.add_argument(\n            '--cc', default='clang', help='Compiler toolchain passed to premake')\n        self.parser.add_argument(\n            '--devenv', default=None, help='Development environment')\n        self.parser.add_argument(\n            '--target_os', default=None,\n            help='Target OS passed to premake, for cross-compilation')\n\n    def execute(self, args, pass_args, cwd):\n        # Update premake. If no binary found, it will be built from source.\n        print('Running premake...')\n        print('')\n        ret = run_platform_premake(target_os_override=args['target_os'],\n                                   cc=args['cc'], devenv=args['devenv'])\n        print('Success!' if ret == 0 else 'Error!')\n\n        return ret\n\n\nclass BaseBuildCommand(Command):\n    \"\"\"Base command for things that require building.\"\"\"\n\n    def __init__(self, subparsers, *args, **kwargs):\n        super(BaseBuildCommand, self).__init__(\n            subparsers,\n            *args, **kwargs)\n        self.parser.add_argument(\n            '--cc', default='clang', help='Compiler toolchain passed to premake')\n        self.parser.add_argument(\n            '--config', choices=['checked', 'debug', 'release'], default='debug',\n            type=str.lower, help='Chooses the build configuration.')\n        self.parser.add_argument(\n            '--target', action='append', default=[],\n            help='Builds only the given target(s).')\n        self.parser.add_argument(\n            '--force', action='store_true',\n            help='Forces a full rebuild.')\n        self.parser.add_argument(\n            '--no_premake', action='store_true',\n            help='Skips running premake before building.')\n        self.parser.add_argument(\n            '-j', default=4, type=int, help='Number of parallel threads')\n\n    def execute(self, args, pass_args, cwd):\n        if not args['no_premake']:\n            print('- running premake...')\n            run_platform_premake(cc=args['cc'])\n            print('')\n\n        threads = args['j']\n        if threads < 0:\n            threads = 0\n\n        print('- building (%s):%s...' % (\n            'all' if not len(args['target']) else ', '.join(args['target']),\n            args['config']))\n        if sys.platform == 'win32':\n            if vs_version is None:\n                print('ERROR: Visual Studio is not installed.');\n                result = 1\n            else:\n                targets = None\n                if len(args['target']):\n                    targets = '/t:' + ';'.join(\n                        target + (':Rebuild' if args['force'] else '')\n                        for target in args['target'])\n                else:\n                    targets = '/t:Rebuild' if args['force'] else None\n\n                result = subprocess.call([\n                    'msbuild',\n                    'build/xenia.sln',\n                    '/nologo',\n                    '/m',\n                    '/v:m',\n                    '/p:Configuration=' + args['config'],\n                    ] + ([targets] if targets is not None else []) + pass_args,\n                    shell=False)\n        elif sys.platform == 'darwin':\n            schemes = args['target'] if len(args['target']) else ['xenia-app']\n            nested_args = [['-scheme', scheme] for scheme in schemes]\n            scheme_args = [arg for pair in nested_args for arg in pair]\n            result = subprocess.call([\n                'xcodebuild',\n                '-workspace',\n                'build/xenia.xcworkspace',\n                '-configuration',\n                args['config']\n            ] + scheme_args + pass_args, shell=False, env=dict(os.environ))\n        else:\n            result = subprocess.call([\n                'make',\n                '-j' if threads == 0 else '-j%d' % threads,\n                '-Cbuild/',\n                'config=%s_linux' % (args['config']),\n            ] + pass_args + args['target'], shell=False, env=dict(os.environ))\n        print('')\n        if result != 0:\n            print('ERROR: build failed with one or more errors.')\n            return result\n        return 0\n\n\nclass BuildCommand(BaseBuildCommand):\n    \"\"\"'build' command.\"\"\"\n\n    def __init__(self, subparsers, *args, **kwargs):\n        super(BuildCommand, self).__init__(\n            subparsers,\n            name='build',\n            help_short='Builds the project with the default toolchain.',\n            *args, **kwargs)\n\n    def execute(self, args, pass_args, cwd):\n        print('Building %s...' % (args['config']))\n        print('')\n\n        result = super(BuildCommand, self).execute(args, pass_args, cwd)\n        if not result:\n            print('Success!')\n        return result\n\n\nclass BuildShadersCommand(Command):\n    \"\"\"'buildshaders' command.\"\"\"\n\n    def __init__(self, subparsers, *args, **kwargs):\n        super(BuildShadersCommand, self).__init__(\n            subparsers,\n            name='buildshaders',\n            help_short='Generates shader binaries for inclusion in C++ files.',\n            help_long='''\n            Generates the shader binaries under src/*/shaders/bytecode/.\n            Run after modifying any .hs/vs/ds/gs/ps/cs.glsl/hlsl/xesl files.\n            Direct3D shaders can be built only on a Windows host.\n            ''',\n            *args, **kwargs)\n        self.parser.add_argument(\n            '--target', action='append', choices=['dxbc', 'spirv'], default=[],\n            help='Builds only the given target(s).')\n\n    def execute(self, args, pass_args, cwd):\n        src_paths = [os.path.join(root, name)\n                     for root, dirs, files in os.walk('src')\n                     for name in files\n                     if (name.endswith('.glsl') or\n                         name.endswith('.hlsl') or\n                         name.endswith('.xesl'))]\n        targets = args['target']\n        all_targets = len(targets) == 0\n\n        # XeSL (\"Xenia Shading Language\") means shader files that can be\n        # compiled as multiple languages from a single file. Whenever possible,\n        # this is achieved without the involvement of the build script, using\n        # just conditionals, macros and functions in shaders, however, in some\n        # cases, that's necessary (such as to prepend `#version` in GLSL, as\n        # well as to enable `#include` in GLSL, to include `xesl.xesli` itself,\n        # without writing the same `#if` / `#extension` / `#endif` in every\n        # shader). Also, not all shading languages provide a built-in\n        # preprocessor definition for identification of them, so XESL_LANGUAGE_*\n        # is also defined via the build arguments. XESL_LANGUAGE_* is set\n        # regardless of whether the file is XeSL or a raw source file in a\n        # specific language, as XeSL headers may be used in language-specific\n        # sources.\n\n        # Direct3D DXBC.\n        if all_targets or 'dxbc' in targets:\n            if sys.platform == 'win32':\n                print('Building Direct3D 12 Shader Model 5.1 DXBC shaders...')\n\n                # Get the FXC path.\n                # TODO(Triang3l): Find FXC in the most recent Windows SDK.\n                program_files_path = os.environ['ProgramFiles(x86)']\n                if not os.path.exists(program_files_path):\n                    print('ERROR: could not find 32-bit Program Files')\n                    return 1\n                windows_sdk_bin_path = os.path.join(\n                    program_files_path, 'Windows Kits/10/bin/10.0.22000.0/x64')\n                if not os.path.exists(windows_sdk_bin_path):\n                    print('ERROR: could not find Windows 10 SDK binaries')\n                    return 1\n                fxc = os.path.join(windows_sdk_bin_path, 'fxc')\n                if not has_bin(fxc):\n                    print('ERROR: could not find fxc')\n                    return 1\n\n                # Build DXBC.\n                dxbc_stages = ['vs', 'hs', 'ds', 'gs', 'ps', 'cs']\n                for src_path in src_paths:\n                    src_name = os.path.basename(src_path)\n                    if ((not src_name.endswith('.hlsl') and\n                         not src_name.endswith('.xesl')) or\n                        len(src_name) <= 8 or src_name[-8] != '.'):\n                        continue\n                    dxbc_identifier = src_name[:-5].replace('.', '_')\n                    dxbc_stage = dxbc_identifier[-2:]\n                    if not dxbc_stage in dxbc_stages:\n                        continue\n                    print('- %s > d3d12_5_1' % (src_path))\n                    dxbc_dir_path = os.path.join(os.path.dirname(src_path),\n                                                 'bytecode/d3d12_5_1')\n                    os.makedirs(dxbc_dir_path, exist_ok=True)\n                    dxbc_file_path_base = os.path.join(dxbc_dir_path,\n                                                       dxbc_identifier)\n                    # Not enabling treating warnings as errors (/WX) because it\n                    # overrides #pragma warning, and the FXAA shader triggers a\n                    # bug in FXC causing an uninitialized variable warning if\n                    # early exit from a function is done.\n                    # FXC writes errors and warnings to stderr, not stdout, but\n                    # stdout receives generic status messages that only add\n                    # clutter in this case.\n                    if subprocess.call([\n                           fxc,\n                           '/D', 'XESL_LANGUAGE_HLSL=1',\n                           '/Fh', dxbc_file_path_base + '.h',\n                           '/T', dxbc_stage + '_5_1',\n                           '/Vn', dxbc_identifier,\n                           '/nologo',\n                           src_path,\n                           ], stdout=subprocess.DEVNULL) != 0:\n                        print('ERROR: failed to compile a DXBC shader')\n                        return 1\n            else:\n                if all_targets:\n                    print('WARNING: Direct3D DXBC shader building is supported '\n                          'only on Windows')\n                else:\n                    print('ERROR: Direct3D DXBC shader building is supported '\n                          'only on Windows')\n                    return 1\n\n        # Vulkan SPIR-V.\n        if all_targets or 'spirv' in targets:\n            print('Building Vulkan SPIR-V shaders...')\n\n            # Get the SPIR-V tool paths.\n            vulkan_sdk_path = os.environ['VULKAN_SDK']\n            if not os.path.exists(vulkan_sdk_path):\n                print('ERROR: could not find the Vulkan SDK in $VULKAN_SDK')\n                return 1\n            # bin is lowercase on Linux (even though it's uppercase on Windows).\n            vulkan_bin_path = os.path.join(vulkan_sdk_path, 'bin')\n            if not os.path.exists(vulkan_bin_path):\n                print('ERROR: could not find the Vulkan SDK binaries')\n                return 1\n            glslang = os.path.join(vulkan_bin_path, 'glslangValidator')\n            if not has_bin(glslang):\n                print('ERROR: could not find glslangValidator')\n                return 1\n            spirv_opt = os.path.join(vulkan_bin_path, 'spirv-opt')\n            if not has_bin(spirv_opt):\n                print('ERROR: could not find spirv-opt')\n                return 1\n            spirv_remap = os.path.join(vulkan_bin_path, 'spirv-remap')\n            if not has_bin(spirv_remap):\n                print('ERROR: could not find spirv-remap')\n                return 1\n            spirv_dis = os.path.join(vulkan_bin_path, 'spirv-dis')\n            if not has_bin(spirv_dis):\n                print('ERROR: could not find spirv-dis')\n                return 1\n\n            # Build SPIR-V.\n            spirv_stages = {\n                'vs': 'vert',\n                'hs': 'tesc',\n                'ds': 'tese',\n                'gs': 'geom',\n                'ps': 'frag',\n                'cs': 'comp',\n            }\n            # #version and extensions must be before everything else in a GLSL\n            # file, can't use a language conditional to add them. Use string\n            # interpolation to insert the file name. Using #include also\n            # preserves line numbers in error and warning messages.\n            spirv_xesl_wrapper =  \\\n                '#version 460\\n' + \\\n                '#extension GL_EXT_control_flow_attributes : require\\n' + \\\n                '#extension GL_EXT_samplerless_texture_functions : require\\n' + \\\n                '#extension GL_GOOGLE_include_directive : require\\n' + \\\n                '#include \"%s\"\\n'\n            for src_path in src_paths:\n                src_name = os.path.basename(src_path)\n                src_is_xesl = src_name.endswith('.xesl')\n                if ((not src_is_xesl and not src_name.endswith('.glsl')) or\n                    len(src_name) <= 8 or src_name[-8] != '.'):\n                    continue\n                spirv_identifier = src_name[:-5].replace('.', '_')\n                spirv_stage = spirv_stages.get(spirv_identifier[-2:], None)\n                if spirv_stage is None:\n                    continue\n                print('- %s > vulkan_spirv' % (src_path))\n                src_dir = os.path.dirname(src_path)\n                spirv_dir_path = os.path.join(src_dir, 'bytecode/vulkan_spirv')\n                os.makedirs(spirv_dir_path, exist_ok=True)\n                spirv_file_path_base = os.path.join(spirv_dir_path,\n                                                    spirv_identifier)\n                spirv_glslang_file_path = spirv_file_path_base + '.glslang.spv'\n                # --stdin must be before -S for some reason.\n                glslang_arguments = [glslang,\n                                     '--stdin' if src_is_xesl else src_path,\n                                     '-DXESL_LANGUAGE_GLSL=1',\n                                     '-S', spirv_stage,\n                                     '-o', spirv_glslang_file_path,\n                                     '-V']\n                # When compiling the code from stdin, there's no directory\n                # containing the file, add the include directory explicitly.\n                if src_is_xesl:\n                    glslang_arguments.append('-I' + src_dir)\n                if subprocess.run(\n                       glslang_arguments,\n                       input = (spirv_xesl_wrapper % src_name) if src_is_xesl\n                               else None,\n                       universal_newlines = True).returncode != 0:\n                    print('ERROR: failed to build a SPIR-V shader')\n                    return 1\n                # spirv-opt input and output files must be different.\n                spirv_file_path = spirv_file_path_base + '.spv'\n                if subprocess.call([\n                       spirv_opt,\n                       '-O',\n                       spirv_glslang_file_path,\n                       '-o', spirv_file_path,\n                       ]) != 0:\n                    print('ERROR: failed to optimize a SPIR-V shader')\n                    return 1\n                os.remove(spirv_glslang_file_path)\n                # spirv-remap takes the output directory, but it may be the same\n                # as the one the input is stored in.\n                if subprocess.call([\n                       spirv_remap,\n                       '--do-everything',\n                       '-i', spirv_file_path,\n                       '-o', spirv_dir_path,\n                       ]) != 0:\n                    print('ERROR: failed to remap a SPIR-V shader')\n                    return 1\n                spirv_dis_file_path = spirv_file_path_base + '.txt';\n                if subprocess.call([\n                       spirv_dis,\n                       '-o', spirv_dis_file_path,\n                       spirv_file_path,\n                       ]) != 0:\n                    print('ERROR: failed to disassemble a SPIR-V shader')\n                    return 1\n                # Generate the header from the disassembly and the binary.\n                with open(spirv_file_path_base + '.h', 'w') as out_file:\n                    out_file.write(\n                        '// Generated with `xb buildshaders`.\\n#if 0\\n')\n                    with open(spirv_dis_file_path, 'r') as spirv_dis_file:\n                        spirv_dis_data = spirv_dis_file.read()\n                        if len(spirv_dis_data) > 0:\n                            out_file.write(spirv_dis_data)\n                            if spirv_dis_data[-1] != '\\n':\n                                out_file.write('\\n')\n                    out_file.write('#endif\\n\\nconst uint32_t %s[] = {' %\n                                   spirv_identifier)\n                    with open(spirv_file_path, 'rb') as spirv_file:\n                        index = 0\n                        # SPIR-V consists of host-endian 32-bit words.\n                        c = spirv_file.read(4)\n                        while len(c) != 0:\n                            if len(c) != 4:\n                                print('ERROR: a SPIR-V shader is misaligned')\n                                return 1\n                            if index % 6 == 0:\n                                out_file.write('\\n    ')\n                            else:\n                                out_file.write(' ')\n                            index += 1\n                            out_file.write(\n                                '0x%08X,' % int.from_bytes(c, sys.byteorder))\n                            c = spirv_file.read(4)\n                    out_file.write('\\n};\\n')\n                os.remove(spirv_dis_file_path)\n                os.remove(spirv_file_path)\n        return 0\n\n\nclass TestCommand(BaseBuildCommand):\n    \"\"\"'test' command.\"\"\"\n\n    def __init__(self, subparsers, *args, **kwargs):\n        super(TestCommand, self).__init__(\n            subparsers,\n            name='test',\n            help_short='Runs automated tests that have been built with `xb build`.',\n            help_long='''\n            To pass arguments to the test executables separate them with `--`.\n            For example, you can run only the instr_foo.s tests with:\n              $ xb test -- instr_foo\n            ''',\n            *args, **kwargs)\n        self.parser.add_argument(\n            '--no_build', action='store_true',\n            help='Don\\'t build before running tests.')\n        self.parser.add_argument(\n            '--continue', action='store_true',\n            help='Don\\'t stop when a test errors, but continue running all.')\n\n    def execute(self, args, pass_args, cwd):\n        print('Testing...')\n        print('')\n\n        # The test executables that will be built and run.\n        test_targets = args['target'] or [\n            'xenia-base-tests',\n            'xenia-cpu-ppc-tests'\n            ]\n        args['target'] = test_targets\n\n        # Build all targets (if desired).\n        if not args['no_build']:\n            result = super(TestCommand, self).execute(args, [], cwd)\n            if result:\n                print('Failed to build, aborting test run.')\n                return result\n\n        # Ensure all targets exist before we run.\n        test_executables = [\n            get_bin(os.path.join(get_build_bin_path(args), test_target))\n            for test_target in test_targets]\n        for i in range(0, len(test_targets)):\n            if test_executables[i] is None:\n                print('ERROR: Unable to find %s - build it.' % (test_targets[i]))\n                return 1\n\n        # Run tests.\n        any_failed = False\n        for test_executable in test_executables:\n            print('- %s' % test_executable)\n            result = shell_call([test_executable] + pass_args,\n                                throw_on_error=False)\n            if result:\n                any_failed = True\n                if args['continue']:\n                    print('ERROR: test failed but continuing due to --continue.')\n                else:\n                    print('ERROR: test failed, aborting, use --continue to keep going.')\n                    return result\n\n        if any_failed:\n            print('ERROR: one or more tests failed.')\n            result = 1\n        return result\n\n\nclass GenTestsCommand(Command):\n    \"\"\"'gentests' command.\"\"\"\n\n    def __init__(self, subparsers, *args, **kwargs):\n        super(GenTestsCommand, self).__init__(\n            subparsers,\n            name='gentests',\n            help_short='Generates test binaries.',\n            help_long='''\n            Generates test binaries (under src/xenia/cpu/ppc/testing/bin/).\n            Run after modifying test .s files.\n            ''',\n            *args, **kwargs)\n\n    def process_src_file(test_bin, ppc_as, ppc_objdump, ppc_ld, ppc_nm, src_file):\n        print('- %s' % src_file)\n\n        def make_unix_path(p):\n            \"\"\"Forces a unix path separator style, as required by binutils.\n            \"\"\"\n            return p.replace(os.sep, '/')\n\n        src_name = os.path.splitext(os.path.basename(src_file))[0]\n        obj_file = os.path.join(test_bin, src_name) + '.o'\n        shell_call([\n            ppc_as,\n            '-a32',\n            '-be',\n            '-mregnames',\n            '-mpower7',\n            '-maltivec',\n            '-mvsx',\n            '-mvmx128',\n            '-R',\n            '-o%s' % (make_unix_path(obj_file)),\n            make_unix_path(src_file),\n            ])\n        dis_file = os.path.join(test_bin, src_name) + '.dis'\n        shell_call([\n            ppc_objdump,\n            '--adjust-vma=0x100000',\n            '-Mpower7',\n            '-Mvmx128',\n            '-D',\n            '-EB',\n            make_unix_path(obj_file),\n            ], stdout_path=dis_file)\n        # Eat the first 4 lines to kill the file path that'll differ across machines.\n        with open(dis_file) as f:\n            dis_file_lines = f.readlines()\n        with open(dis_file, 'w') as f:\n            f.writelines(dis_file_lines[4:])\n        shell_call([\n            ppc_ld,\n            '-A powerpc:common32',\n            '-melf32ppc',\n            '-EB',\n            '-nostdlib',\n            '--oformat=binary',\n            '-Ttext=0x80000000',\n            '-e0x80000000',\n            '-o%s' % (make_unix_path(os.path.join(test_bin, src_name) + '.bin')),\n            make_unix_path(obj_file),\n            ])\n        shell_call([\n            ppc_nm,\n            '--numeric-sort',\n            make_unix_path(obj_file),\n            ], stdout_path=os.path.join(test_bin, src_name) + '.map')\n\n    def execute(self, args, pass_args, cwd):\n        print('Generating test binaries...')\n        print('')\n\n        binutils_path = os.path.join('third_party', 'binutils-ppc-cygwin')\n        ppc_as = os.path.join(binutils_path, 'powerpc-none-elf-as')\n        ppc_ld = os.path.join(binutils_path, 'powerpc-none-elf-ld')\n        ppc_objdump = os.path.join(binutils_path, 'powerpc-none-elf-objdump')\n        ppc_nm = os.path.join(binutils_path, 'powerpc-none-elf-nm')\n\n        test_src = os.path.join('src', 'xenia', 'cpu', 'ppc', 'testing')\n        test_bin = os.path.join(test_src, 'bin')\n\n        # Ensure the test output path exists.\n        if not os.path.exists(test_bin):\n            os.mkdir(test_bin)\n\n        src_files = [os.path.join(root, name)\n                     for root, dirs, files in os.walk('src')\n                     for name in files\n                     if (name.startswith('instr_') or name.startswith('seq_'))\n                     and name.endswith(('.s'))]\n\n        any_errors = False\n\n        pool_func = partial(GenTestsCommand.process_src_file, test_bin, ppc_as, ppc_objdump, ppc_ld, ppc_nm)\n        with Pool() as pool:\n            pool.map(pool_func, src_files)\n\n\n        if any_errors:\n            print('ERROR: failed to build one or more tests.')\n            return 1\n\n        return 0\n\n\nclass GpuTestCommand(BaseBuildCommand):\n    \"\"\"'gputest' command.\"\"\"\n\n    def __init__(self, subparsers, *args, **kwargs):\n        super(GpuTestCommand, self).__init__(\n            subparsers,\n            name='gputest',\n            help_short='Runs automated GPU diff tests against reference imagery.',\n            help_long='''\n            To pass arguments to the test executables separate them with `--`.\n            ''',\n            *args, **kwargs)\n        self.parser.add_argument(\n            '--no_build', action='store_true',\n            help='Don\\'t build before running tests.')\n        self.parser.add_argument(\n            '--update_reference_files', action='store_true',\n            help='Update all reference imagery.')\n        self.parser.add_argument(\n            '--generate_missing_reference_files', action='store_true',\n            help='Create reference files for new traces.')\n\n    def execute(self, args, pass_args, cwd):\n        print('Testinging...')\n        print('')\n\n        # The test executables that will be built and run.\n        test_targets = args['target'] or [\n            'xenia-gpu-vulkan-trace-dump',\n            ]\n        args['target'] = test_targets\n\n        # Build all targets (if desired).\n        if not args['no_build']:\n            result = super(GpuTestCommand, self).execute(args, [], cwd)\n            if result:\n                print('Failed to build, aborting test run.')\n                return result\n\n        # Ensure all targets exist before we run.\n        test_executables = [\n            get_bin(os.path.join(get_build_bin_path(args), test_target))\n            for test_target in test_targets]\n        for i in range(0, len(test_targets)):\n            if test_executables[i] is None:\n                print('ERROR: Unable to find %s - build it.' % (test_targets[i]))\n                return 1\n\n        output_path = os.path.join(self_path, 'build', 'gputest')\n        if os.path.isdir(output_path):\n            shutil.rmtree(output_path)\n        os.makedirs(output_path)\n        print('Running tests and outputting to %s...' % (output_path))\n\n        reference_trace_root = os.path.join(self_path, 'testdata',\n                                            'reference-gpu-traces')\n\n        # Run tests.\n        any_failed = False\n        result = shell_call([\n            sys.executable,\n            os.path.join(self_path, 'tools', 'gpu-trace-diff'),\n            '--executable=' + test_executables[0],\n            '--trace_path=' + os.path.join(reference_trace_root, 'traces'),\n            '--output_path=' + output_path,\n            '--reference_path=' + os.path.join(reference_trace_root, 'references'),\n            ] + (['--generate_missing_reference_files'] if args['generate_missing_reference_files'] else []) +\n                (['--update_reference_files'] if args['update_reference_files'] else []) +\n                            pass_args,\n                            throw_on_error=False)\n        if result:\n            any_failed = True\n\n        if any_failed:\n            print('ERROR: one or more tests failed.')\n            result = 1\n        print('Check %s/results.html for more details.' % (output_path))\n        return result\n\n\nclass CleanCommand(Command):\n    \"\"\"'clean' command.\"\"\"\n\n    def __init__(self, subparsers, *args, **kwargs):\n        super(CleanCommand, self).__init__(\n            subparsers,\n            name='clean',\n            help_short='Removes intermediate files and build outputs.',\n            *args, **kwargs)\n        self.parser.add_argument(\n            '--target_os', default=None,\n            help='Target OS passed to premake, for cross-compilation')\n\n    def execute(self, args, pass_args, cwd):\n        print('Cleaning build artifacts...')\n        print('')\n\n        print('- premake clean...')\n        run_premake(get_premake_target_os(args['target_os']), 'clean')\n        print('')\n\n        print('Success!')\n        return 0\n\n\nclass NukeCommand(Command):\n    \"\"\"'nuke' command.\"\"\"\n\n    def __init__(self, subparsers, *args, **kwargs):\n        super(NukeCommand, self).__init__(\n            subparsers,\n            name='nuke',\n            help_short='Removes all build/ output.',\n            *args, **kwargs)\n        self.parser.add_argument(\n            '--target_os', default=None,\n            help='Target OS passed to premake, for cross-compilation')\n\n    def execute(self, args, pass_args, cwd):\n        print('Cleaning build artifacts...')\n        print('')\n\n        print('- removing build/...')\n        if os.path.isdir('build/'):\n            shutil.rmtree('build/')\n        print('')\n\n        print('- git reset to master...')\n        shell_call([\n            'git',\n            'reset',\n            '--hard',\n            'master',\n            ])\n        print('')\n\n        print('- running premake...')\n        run_platform_premake(target_os_override=args['target_os'])\n        print('')\n\n        print('Success!')\n        return 0\n\n\ndef find_xenia_source_files():\n    \"\"\"Gets all xenia source files in the project.\n\n    Returns:\n      A list of file paths.\n    \"\"\"\n    return [os.path.join(root, name)\n            for root, dirs, files in os.walk('src')\n            for name in files\n            if name.endswith(('.cc', '.c', '.h', '.inl', '.inc'))]\n\n\ndef find_all_source_files():\n    \"\"\"Gets all interesting source files in the project.\n\n    Returns:\n      A list of file paths.\n    \"\"\"\n    return find_xenia_source_files()\n\n\nclass LintCommand(Command):\n    \"\"\"'lint' command.\"\"\"\n\n    def __init__(self, subparsers, *args, **kwargs):\n        super(LintCommand, self).__init__(\n            subparsers,\n            name='lint',\n            help_short='Checks for lint errors with clang-format.',\n            *args, **kwargs)\n        self.parser.add_argument(\n            '--all', action='store_true',\n            help='Lint all files, not just those changed.')\n        self.parser.add_argument(\n            '--origin', action='store_true',\n            help='Lints all files changed relative to origin/master.')\n\n    def execute(self, args, pass_args, cwd):\n        clang_format_binary = get_clang_format_binary()\n\n        difftemp = '.difftemp.txt'\n\n        if args['all']:\n            all_files = find_all_source_files()\n            all_files.sort()\n            print('- linting %d files' % (len(all_files)))\n            any_errors = False\n            for file_path in all_files:\n                if os.path.exists(difftemp): os.remove(difftemp)\n                ret = shell_call([\n                    clang_format_binary,\n                    '-output-replacements-xml',\n                    '-style=file',\n                    file_path,\n                    ], throw_on_error=False, stdout_path=difftemp)\n                with open(difftemp) as f:\n                    had_errors = '<replacement ' in f.read()\n                if os.path.exists(difftemp): os.remove(difftemp)\n                if had_errors:\n                    any_errors = True\n                    print('')\n                    print(file_path)\n                    shell_call([\n                        clang_format_binary,\n                        '-style=file',\n                        file_path,\n                        ], throw_on_error=False, stdout_path=difftemp)\n                    shell_call([\n                        sys.executable,\n                        'tools/diff.py',\n                        file_path,\n                        difftemp,\n                        difftemp,\n                        ])\n                    shell_call([\n                        'type' if sys.platform == 'win32' else 'cat',\n                        difftemp,\n                        ], shell=True if sys.platform == 'win32' else False)\n                    if os.path.exists(difftemp): os.remove(difftemp)\n                    print('')\n            print('')\n            if any_errors:\n                print('ERROR: 1+ diffs. Stage changes and run \\'xb format\\' to fix.')\n                return 1\n            else:\n                print('Linting completed successfully.')\n                return 0\n        else:\n            print('- git-clang-format --diff')\n            if os.path.exists(difftemp): os.remove(difftemp)\n            ret = shell_call([\n                sys.executable,\n                'third_party/clang-format/git-clang-format',\n                '--binary=%s' % (clang_format_binary),\n                '--commit=%s' % ('origin/master' if args['origin'] else 'HEAD'),\n                '--style=file',\n                '--diff',\n                ], throw_on_error=False, stdout_path=difftemp)\n            with open(difftemp) as f:\n                contents = f.read()\n                not_modified = 'no modified files' in contents\n                not_modified = not_modified or 'did not modify' in contents\n                f.close()\n            if os.path.exists(difftemp): os.remove(difftemp)\n            if not not_modified:\n                any_errors = True\n                print('')\n                shell_call([\n                    sys.executable,\n                    'third_party/clang-format/git-clang-format',\n                    '--binary=%s' % (clang_format_binary),\n                    '--commit=%s' % ('origin/master' if args['origin'] else 'HEAD'),\n                    '--style=file',\n                    '--diff',\n                    ])\n                print('ERROR: 1+ diffs. Stage changes and run \\'xb format\\' to fix.')\n                return 1\n            else:\n                print('Linting completed successfully.')\n                return 0\n\n\nclass FormatCommand(Command):\n    \"\"\"'format' command.\"\"\"\n\n    def __init__(self, subparsers, *args, **kwargs):\n        super(FormatCommand, self).__init__(\n            subparsers,\n            name='format',\n            help_short='Reformats staged code with clang-format.',\n            *args, **kwargs)\n        self.parser.add_argument(\n            '--all', action='store_true',\n            help='Format all files, not just those changed.')\n        self.parser.add_argument(\n            '--origin', action='store_true',\n            help='Formats all files changed relative to origin/master.')\n\n    def execute(self, args, pass_args, cwd):\n        clang_format_binary = get_clang_format_binary()\n\n        if args['all']:\n            all_files = find_all_source_files()\n            all_files.sort()\n            print('- clang-format [%d files]' % (len(all_files)))\n            any_errors = False\n            for file_path in all_files:\n                ret = shell_call([\n                    clang_format_binary,\n                    '-i',\n                    '-style=file',\n                    file_path,\n                    ], throw_on_error=False)\n                if ret:\n                    any_errors = True\n            print('')\n            if any_errors:\n                print('ERROR: 1+ clang-format calls failed.')\n                print('Ensure all files are staged.')\n                return 1\n            else:\n                print('Formatting completed successfully.')\n                return 0\n        else:\n            print('- git-clang-format')\n            shell_call([\n                sys.executable,\n                'third_party/clang-format/git-clang-format',\n                '--binary=%s' % (clang_format_binary),\n                '--commit=%s' % ('origin/master' if args['origin'] else 'HEAD'),\n                ])\n            print('')\n\n        return 0\n\n\n# TODO(benvanik): merge into linter, or as lint --anal?\nclass StyleCommand(Command):\n    \"\"\"'style' command.\"\"\"\n\n    def __init__(self, subparsers, *args, **kwargs):\n        super(StyleCommand, self).__init__(\n            subparsers,\n            name='style',\n            help_short='Runs the style checker on all code.',\n            *args, **kwargs)\n\n    def execute(self, args, pass_args, cwd):\n        all_files = [file_path for file_path in find_all_source_files()\n                     if not file_path.endswith('_test.cc')]\n        print('- cpplint [%d files]' % (len(all_files)))\n        ret = shell_call([\n            sys.executable,\n            'third_party/google-styleguide/cpplint/cpplint.py',\n            '--output=vs7',\n            '--linelength=80',\n            '--filter=-build/c++11,+build/include_alpha',\n            '--root=src',\n            ] + all_files, throw_on_error=False)\n        print('')\n        if ret:\n            print('ERROR: 1+ cpplint calls failed.')\n            return 1\n        else:\n            print('Style linting completed successfully.')\n            return 0\n\n\n# TODO(benvanik): merge into linter, or as lint --anal?\nclass TidyCommand(Command):\n    \"\"\"'tidy' command.\"\"\"\n\n    def __init__(self, subparsers, *args, **kwargs):\n        super(TidyCommand, self).__init__(\n            subparsers,\n            name='tidy',\n            help_short='Runs the clang-tidy checker on all code.',\n            *args, **kwargs)\n        self.parser.add_argument(\n            '--fix', action='store_true',\n            help='Applies suggested fixes, where possible.')\n        self.parser.add_argument(\n            '--target_os', default=None,\n            help='Target OS passed to premake, for cross-compilation')\n\n    def execute(self, args, pass_args, cwd):\n        # Run premake to generate our compile_commands.json file for clang to use.\n        # TODO(benvanik): only do linux? whatever clang-tidy is ok with.\n        run_premake(get_premake_target_os(args['target_os']),\n                    'export-compile-commands')\n\n        platform_name = ''\n        if sys.platform == 'darwin':\n            platform_name = 'darwin'\n        elif sys.platform == 'win32':\n            platform_name = 'windows'\n        else:\n            platform_name = 'linux'\n        tool_root = 'build/llvm_tools/debug_%s' % platform_name\n\n        all_files = [file_path for file_path in find_all_source_files()\n                     if not file_path.endswith('_test.cc')]\n        # Tidy only likes .cc files.\n        all_files = [file_path for file_path in all_files\n                     if file_path.endswith('.cc')]\n\n        any_errors = False\n        for file in all_files:\n            print('- clang-tidy %s' % (file))\n            ret = shell_call([\n                'clang-tidy',\n                '-p', tool_root,\n                '-checks=' + ','.join([\n                    'clang-analyzer-*',\n                    'google-*',\n                    'misc-*',\n                    'modernize-*'\n                    # TODO(benvanik): pick the ones we want - some are silly.\n                    # 'readability-*',\n                ]),\n                ] + (['-fix'] if args['fix'] else []) + [\n                    file,\n                ], throw_on_error=False)\n            if ret:\n                any_errors = True\n\n        print('')\n        if any_errors:\n            print('ERROR: 1+ clang-tidy calls failed.')\n            return 1\n        else:\n            print('Tidy completed successfully.')\n            return 0\n\nclass StubCommand(Command):\n    \"\"\"'stub' command.\"\"\"\n\n    def __init__(self, subparsers, *args, **kwargs):\n        super(StubCommand, self).__init__(\n            subparsers,\n            name='stub',\n            help_short='Create new file(s) in the xenia source tree and run premake',\n            *args, **kwargs)\n        self.parser.add_argument(\n            '--file', default=None,\n            help='Generate a source file at the provided location in the source tree')\n        self.parser.add_argument(\n            '--class', default=None,\n            help='Generate a class pair (.cc/.h) at the provided location in the source tree')\n        self.parser.add_argument(\n            '--target_os', default=None,\n            help='Target OS passed to premake, for cross-compilation')\n\n    def execute(self, args, pass_args, cwd):\n        root = os.path.dirname(os.path.realpath(__file__))\n        source_root = os.path.join(root, os.path.normpath('src/xenia'))\n\n        if args['class']:\n            path = os.path.normpath(os.path.join(source_root, args['class']))\n            target_dir = os.path.dirname(path)\n            class_name = os.path.basename(path)\n\n            status = generate_source_class(path)\n            if status > 0:\n                return status\n\n            print('Created class \\'{0}\\' at {1}'.format(class_name, target_dir))\n\n        elif args['file']:\n            path = os.path.normpath(os.path.join(source_root, args['file']))\n            target_dir = os.path.dirname(path)\n            file_name = os.path.basename(path)\n\n            status = generate_source_file(path)\n            if status > 0:\n                return status\n\n            print('Created file \\'{0}\\' at {1}'.format(file_name, target_dir))\n\n        else:\n            print('ERROR: Please specify a file/class to generate')\n            return 1\n\n        run_platform_premake(target_os_override=args['target_os'])\n        return 0\n\nclass DevenvCommand(Command):\n    \"\"\"'devenv' command.\"\"\"\n\n    def __init__(self, subparsers, *args, **kwargs):\n        super(DevenvCommand, self).__init__(\n            subparsers,\n            name='devenv',\n            help_short='Launches the development environment.',\n            *args, **kwargs)\n\n    def execute(self, args, pass_args, cwd):\n        devenv = None\n        show_reload_prompt = False\n        if sys.platform == 'win32':\n            if vs_version is None:\n                print('ERROR: Visual Studio is not installed.');\n                return 1\n            print('Launching Visual Studio...')\n        elif sys.platform == 'darwin':\n            print('Launching Xcode...')\n            devenv = 'xcode4'\n        elif has_bin('clion') or has_bin('clion.sh'):\n            print('Launching CLion...')\n            show_reload_prompt = create_clion_workspace()\n            devenv = 'cmake'\n        else:\n            print('Launching CodeLite...')\n            devenv = 'codelite'\n        print('')\n\n        print('- running premake...')\n        run_platform_premake(devenv=devenv)\n        print('')\n\n        print('- launching devenv...')\n        if show_reload_prompt:\n            print_box('Please run \"File ⇒ ↺ Reload CMake Project\" from inside the IDE!')\n        if sys.platform == 'win32':\n            shell_call([\n                'devenv',\n                'build\\\\xenia.sln',\n            ])\n        elif sys.platform == 'darwin':\n            shell_call([\n                'xed',\n                'build/xenia.xcworkspace',\n            ])\n        elif has_bin('clion'):\n            shell_call([\n                'clion',\n                '.',\n            ])\n        elif has_bin('clion.sh'):\n            shell_call([\n                'clion.sh',\n                '.',\n            ])\n        else:\n            shell_call([\n                'codelite',\n                'build/xenia.workspace',\n            ])\n        print('')\n\n        return 0\n\n\nif __name__ == '__main__':\n    main()\n"
        },
        {
          "name": "xeniarc",
          "type": "blob",
          "size": 0.1181640625,
          "content": "# Copyright 2015 Ben Vanik. All Rights Reserved.\n#\n# Useful bash aliases and completions.\n\nalias xb='python xenia-build'\n"
        }
      ]
    }
  ]
}