{
  "metadata": {
    "timestamp": 1736566170088,
    "page": 180,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE4MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "facebook/redex",
      "stars": 6054,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".circleci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 1.32421875,
          "content": "---\nAccessModifierOffset: -1\nAlignEscapedNewlinesLeft: true\nAlignTrailingComments: false\nAllowAllParametersOfDeclarationOnNextLine: true\nAllowShortIfStatementsOnASingleLine: true\nAllowShortLoopsOnASingleLine: false\nAlwaysBreakBeforeMultilineStrings: true\nAlwaysBreakTemplateDeclarations: true\nBinPackArguments: true\nBinPackParameters: false\nBreakBeforeBinaryOperators: false\nBreakBeforeBraces: Attach\nBreakConstructorInitializersBeforeComma: false\nColumnLimit:     80\nConstructorInitializerAllOnOneLineOrOnePerLine: true\nConstructorInitializerIndentWidth: 4\nContinuationIndentWidth: 4\nCpp11BracedListStyle: true\nDerivePointerAlignment: false\nExperimentalAutoDetectBinPacking: true\nIndentCaseLabels: false\nIndentFunctionDeclarationAfterType: false\nIndentWidth:     2\nMaxEmptyLinesToKeep: 1\nNamespaceIndentation: None\nObjCSpaceBeforeProtocolList: false\nPenaltyBreakBeforeFirstCallParameter: 10\nPenaltyBreakComment: 60\nPenaltyBreakFirstLessLess: 20\nPenaltyBreakString: 1000\nPenaltyExcessCharacter: 1000000\nPenaltyReturnTypeOnItsOwnLine: 200\nPointerAlignment: Left\nSpaceAfterControlStatementKeyword: true\nSpaceBeforeAssignmentOperators: true\nSpaceInEmptyParentheses: false\nSpacesBeforeTrailingComments: 1\nSpacesInAngles: false\nSpacesInCStyleCastParentheses: false\nSpacesInParentheses: false\nStandard:        Cpp11\nTabWidth:        8\nUseTab:          Never\n...\n"
        },
        {
          "name": ".clang-tidy",
          "type": "blob",
          "size": 1.0107421875,
          "content": "---\n# NOTE there must be no spaces before the '-', so put the comma last.\nInheritParentConfig: true\nChecks: '\nbugprone-*,\n-bugprone-branch-clone,\n-bugprone-implicit-widening-of-multiplication-result,\n-bugprone-narrowing-conversions,\n-bugprone-easily-swappable-parameters,\n-bugprone-too-small-loop-variable,\n-bugprone-unchecked-optional-access,\nbugprone-macro-parentheses,\nmodernize-make-shared,\nperformance-*,\n-performance-inefficient-string-concatenation,\nreadability-const-return-type,\nreadability-container-size-empty,\nreadability-inconsistent-declaration-parameter-name,\nreadability-redundant-*,\nmisc-definitions-in-headers,\nmodernize-use-override,modernize-use-using,\ngoogle-explicit-constructor,hicpp-explicit-conversions,\nllvm-namespace-comment,\n'\nWarningsAsErrors: 'performance-*,readability-*,misc-definitions-in-headers,modernize-use-*,llvm-namespace-comment,google-explicit-constructor,hicpp-explicit-conversions,modernize-make-shared,bugprone-*'\nCheckOptions:\n  - key: modernize-use-override.IgnoreDestructors\n    value: 1\n"
        },
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.0205078125,
          "content": "*/node_modules\n*.log\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.7939453125,
          "content": ".DS_Store\n\n**/*.o\n**/*.lo\n**/*.la\n**/.deps\n**/.dirstamp\n**/*~\n**/Makefile\n**/Makefile.in\n\n/.libs\n/aclocal.m4\n/autom4te.cache\n/cmd.txt\n/compile\n/config.*\n/configure\n/depcomp\n/install-sh\n/libredex.la\n/libtool\n/ltmain.sh\n/m4/libtool.m4\n/m4/ltoptions.m4\n/m4/ltsugar.m4\n/m4/ltversion.m4\n/m4/lt~obsolete.m4\n/missing\n/protores/\n/redex\n/redex-all\n/redex.tar.gz\n/redexdump\n/stamp-h1\n/test/.libs/\n/test/googletest-release-*/\n/test/gtest-*.zip\n/test/setup_gtest\n/test/**/*.log\n/test/**/*.trs\n/test/**/*_test\n/test/**/*.jar\n/test/**/*.dex\n/test/**/*.tmp/\n/test-driver\n/.vs/\n/build-cmake/\nredex-src-strings-map.txt\npyredex/__pycache__\n\nwebsite/translated_docs\nwebsite/build/\nwebsite/yarn.lock\nwebsite/node_modules\nwebsite/i18n/*\nwebsite/package-lock.json\nwebsite/.docusaurus\nwebsite/.cache-loader\n\npackage-lock.json\nyarn.lock\n"
        },
        {
          "name": ".lldbinit",
          "type": "blob",
          "size": 0.2841796875,
          "content": "command alias dumpmethname expr dumpmethname()\ncommand alias dumpcfg expr dumpcfg()\ncommand alias dumpir expr dumpir()\ncommand regex dumpblock 's/(.+)/expr dumpblock(%1)/'\ncommand regex setdumpfile 's/(.+)/expr setdumpfile(%1)/'\ncommand regex dumpfilemode 's/(.+)/expr setdumpfilemode(%1)/'\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.431640625,
          "content": "sudo: required\nlanguage: cpp\ncompiler: gcc-5\ndist: xenial\n\nbefore_install:\n  - sudo apt-get install -y\n      automake\n      autoconf\n      autoconf-archive\n      libtool\n      liblz4-dev\n      liblzma-dev\n      make\n      zlib1g-dev\n      binutils-dev\n      libjemalloc-dev\n      libiberty-dev\n      libjsoncpp-dev\n      wget\n  - export CXX='g++-5'\n  - sudo sh get_boost.sh\n\nscript:\n  - autoreconf -ivf && ./configure CXX='g++-5' && make -j4\n"
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 4.3349609375,
          "content": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\ncmake_minimum_required(VERSION 3.0.2)\nproject(\"Redex\")\n\nset(CMAKE_MODULE_PATH \"${CMAKE_SOURCE_DIR}/cmake_modules\" ${CMAKE_MODULE_PATH})\ninclude(Commons)\n\nif (NOT CMAKE_BUILD_TYPE)\n    set(CMAKE_BUILD_TYPE Release)\nendif ()\n\nif(NOT BUILD_TYPE)\n    set(BUILD_TYPE Shared)\nendif ()\nif (MINGW)\n    set(BUILD_TYPE Static)\nendif ()\n\nif(BUILD_TYPE STREQUAL Static)\n    set(ENABLE_STATIC ON CACHE BOOL \"\" FORCE)\n    if (MINGW)\n        set(STATIC_LINK_FLAG \"-static\")\n    else (MINGW)\n        set(STATIC_LINK_FLAG \"\")\n    endif (MINGW)\nelseif (BUILD_TYPE STREQUAL Shared)\n    set(ENABLE_STATIC OFF CACHE BOOL \"\" FORCE)\n    set(STATIC_LINK_FLAG \"\")\nendif ()\n\nset_common_cxx_flags_for_redex()\nadd_dependent_packages_for_redex()\n\nfile(GLOB includes\n        \"analysis\"\n        \"libredex\"\n        \"service/*\"\n        \"opt/*\"\n        \"util\"\n        \"liblocator\"\n        \"libresource\"\n        \"shared\"\n        \"sparta/include\"\n        \"tools/common\"\n        )\n\ninclude_directories(\n        ${Boost_INCLUDE_DIRS}\n        ${JSONCPP_INCLUDE_DIRS}\n        ${ZLIB_INCLUDE_DIRS}\n        ${includes})\n\ninstall(DIRECTORY libredex util libresource shared service\n        DESTINATION include/redex\n        FILES_MATCHING PATTERN \"*.h\" PATTERN \"*.def\")\ninstall(DIRECTORY sparta/include/\n        DESTINATION include/redex/sparta\n        FILES_MATCHING PATTERN \"*.h\")\ninstall(DIRECTORY tools/common tools/tool\n        DESTINATION include/redex/tools\n        FILES_MATCHING PATTERN \"*.h\")\n\nfile(GLOB_RECURSE redex_srcs\n        \"analysis/max-depth/*.cpp\"\n        \"analysis/max-depth/*.h\"\n        \"analysis/ip-reflection-analysis/*.cpp\"\n        \"analysis/ip-reflection-analysis/*.h\"\n        \"libredex/*.cpp\"\n        \"libredex/*.h\"\n        \"service/*.cpp\"\n        \"service/*.h\"\n        \"opt/*.cpp\"\n        \"opt/*.h\"\n        \"util/CommandProfiling.cpp\"\n        \"util/CommandProfiling.h\"\n        \"util/JemallocUtil.cpp\"\n        \"util/JemallocUtil.h\"\n        \"util/Sha1.cpp\"\n        \"util/Sha1.h\"\n        \"shared/DexDefs.cpp\"\n        \"shared/DexDefs.h\"\n        \"shared/DexEncoding.cpp\"\n        \"shared/DexEncoding.h\"\n        \"shared/file-utils.cpp\"\n        \"shared/file-utils.h\"\n        \"liblocator/locator.cpp\"\n        \"liblocator/locator.h\"\n        )\n\nadd_library(redex STATIC ${redex_srcs})\n\ninstall(TARGETS redex ARCHIVE DESTINATION lib LIBRARY DESTINATION lib)\n\nfile(GLOB_RECURSE tool_srcs\n        \"tools/tool/*.cpp\"\n        \"tools/tool/*.h\"\n        )\n\nadd_library(tool STATIC ${tool_srcs})\n\ninstall(TARGETS tool ARCHIVE DESTINATION lib LIBRARY DESTINATION lib)\n\nfile(GLOB_RECURSE resource_srcs\n        \"libresource/*.cpp\"\n        \"libresource/*.h\"\n        )\n\nadd_library(resource STATIC ${resource_srcs})\n\ninstall(TARGETS resource ARCHIVE DESTINATION lib LIBRARY DESTINATION lib)\n\nfile(GLOB redex_all_srcs\n        \"tools/redex-all/*.cpp\"\n        \"tools/redex-all/*.h\"\n        \"tools/common/ToolsCommon.cpp\"\n        \"tools/common/ToolsCommon.h\"\n        )\n\nadd_executable(redex-all ${redex_all_srcs})\n\nif (MINGW)\n    set(MINGW_EXTRA_LIBS -Wl,-Bstatic ws2_32)\nelse (MINGW)\n    set(MINGW_EXTRA_LIBS \"\")\nendif (MINGW)\n\ntarget_link_libraries(redex-all\n        ${STATIC_LINK_FLAG}\n        ${Boost_LIBRARIES}\n        ${REDEX_JSONCPP_LIBRARY}\n        ${REDEX_ZLIB_LIBRARY}\n        ${CMAKE_DL_LIBS}\n        redex\n        resource\n        ${MINGW_EXTRA_LIBS}\n        m\n        )\n\ntarget_compile_definitions(redex-all PRIVATE)\n\nset_link_whole(redex-all redex)\n\ninstall(TARGETS redex-all DESTINATION bin)\n\n# redex.py things...\n\ninstall(FILES redex.py DESTINATION bin)\ninstall(DIRECTORY pyredex DESTINATION bin)\n\nfile(GLOB gen_packed_apilevels \"gen_packed_apilevels.py\")\nfile(GLOB api_level_srcs \"service/api-levels/framework_classes_api_*.txt\")\n\nadd_custom_command(\n    OUTPUT  generated_apilevels.py\n    COMMAND python3 ${gen_packed_apilevels} -o generated_apilevels.py ${api_level_srcs}\n    DEPENDS ${api_level_srcs} ${gen_packed_apilevels}\n)\nadd_custom_target(generated_apilevels ALL DEPENDS generated_apilevels.py)\ninstall(FILES ${CMAKE_CURRENT_BINARY_DIR}/generated_apilevels.py DESTINATION bin)\n\n# Misc stuff, for good measure.\ninstall(FILES LICENSE README.md config/default.config DESTINATION share/doc/redex)\n\nset(CPACK_INCLUDE_TOPLEVEL_DIRECTORY OFF)\nset(CPACK_GENERATOR \"ZIP\")\ninclude(CPack)\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.27734375,
          "content": "# Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to make participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, sex characteristics, gender identity and expression,\nlevel of experience, education, socio-economic status, nationality, personal\nappearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\n  advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\n  address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies within all project spaces, and it also applies when\nan individual is representing the project or its community in public spaces.\nExamples of representing a project or community include using an official\nproject e-mail address, posting via an official social media account, or acting\nas an appointed representative at an online or offline event. Representation of\na project may be further defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the project team at <opensource-conduct@fb.com>. All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see\nhttps://www.contributor-covenant.org/faq\n\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 1.828125,
          "content": "# Contributing to ReDex\n\nWe want to make contributing to this project as easy and transparent as\npossible.\n\n## Code of Conduct\n\nThe code of conduct is described in [`CODE_OF_CONDUCT.md`](CODE_OF_CONDUCT.md)\n\n## Our Development Process\n\nThis project is developed internally at Facebook inside a private repository.\nInternal changes are periodically pushed to the open-source branch. Pull\nrequests are integrated manually into our private repository first, and they\nthen get propagated to the public repository with the next push.\n\n## Pull Requests\n\nWe actively welcome your pull requests!\n\n1. Fork the repo and create your branch from `master`.\n2. If you've added code that should be tested, add tests.\n3. If you've changed APIs, update the documentation.\n4. Ensure the test suite passes.\n5. If you haven't already, complete the Contributor License Agreement (\"CLA\").\n\n## Contributor License Agreement (\"CLA\")\n\nIn order to accept your pull request, we need you to submit a CLA. You only need\nto do this once to work on any of Facebook's open source projects.\n\nComplete your CLA here: <https://code.facebook.com/cla>\n\n## Issues\n\nWe use GitHub issues to track public bugs. Please ensure your description is\nclear and has sufficient instructions to be able to reproduce the issue.\n\nFacebook has a [bounty program](https://www.facebook.com/whitehat/) for the safe\ndisclosure of security bugs. In those cases, please go through the process\noutlined on that page and do not file a public issue.\n\n## Coding Style  \n\nOur only hard-and-fast coding style rules are:\n* 2 spaces for indentation rather than tabs\n* 80 character line length\n\nIn general, if you use our [.clang-format file](https://github.com/facebook/redex/blob/master/.clang-format), no one\nwill complain.\n\n## License\n\nBy contributing to ReDex, you agree that your contributions will be licensed\nunder its MIT license.\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.14453125,
          "content": "FROM node:8.11.4\n\nWORKDIR /app/website\n\nEXPOSE 3000 35729\nCOPY ./docs /app/docs\nCOPY ./website /app/website\nRUN yarn install\n\nCMD [\"yarn\", \"start\"]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0625,
          "content": "MIT License\n\nCopyright (c) Meta Platforms, Inc. and affiliates.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "Makefile.am",
          "type": "blob",
          "size": 20.8828125,
          "content": "AUTOMAKE_OPTIONS = foreign\n\nSUBDIRS = . test\n\nACLOCAL_AMFLAGS = -I m4\n\n# Disable some warnings so we can enable -Werror for the rest.\n#\n# Using -Wno- as that is explicitly specified as backwards-compatible, while\n# I cannot find the same for the -Wno-error= form.\n\n# attributes: unsupported CFI attribute warnings.\n# comment: unhappy with use of \"\\\" in comments, which we use for diagrams.\n# unknown-warning-option: Clang doesn't follow GCC's \"no-\" backwards approach.\nDISABLED_WARNINGS_HARD = \\\n  -Wno-attributes \\\n  -Wno-comment \\\n  -Wno-unknown-warning-option\n\n# TODO: Minimize this list.\nDISABLED_WARNINGS = \\\n  $(DISABLED_WARNINGS_HARD) \\\n  -Wno-array-bounds \\\n  -Wno-class-memaccess \\\n  -Wno-deprecated-copy \\\n  -Wno-deprecated-declarations \\\n  -Wno-enum-constexpr-conversion \\\n  -Wno-format-truncation \\\n  -Wno-format-zero-length \\\n  -Wno-invalid-offsetof \\\n  -Wno-maybe-uninitialized \\\n  -Wno-parentheses \\\n  -Wno-range-loop-analysis \\\n  -Wno-redundant-move \\\n  -Wno-return-type \\\n  -Wno-shift-count-overflow \\\n  -Wno-sign-compare \\\n  -Wno-strict-aliasing \\\n  -Wno-stringop-overflow \\\n  -Wno-stringop-overread \\\n  -Wno-type-limits \\\n  -Wno-uninitialized \\\n  -Wno-unused-but-set-variable \\\n  -Wno-unused-function \\\n  -Wno-unused-parameter \\\n  -Wno-unused-private-field \\\n  -Wno-unused-result \\\n  -Wno-unused-value \\\n  -Wno-unused-variable\n\nAM_CXXFLAGS = --std=gnu++17 -O3 -Wall -Werror -Wextra $(DISABLED_WARNINGS) -g1\n\ninclude $(top_srcdir)/Makefile.inc\n\n#\n# Include paths\n#\nAM_CPPFLAGS = $(COMMON_INCLUDES)\n\n# Boost.\nAM_CPPFLAGS += $(BOOST_CPPFLAGS)\nAM_LDFLAGS = $(BOOST_LDFLAGS)\n\nnoinst_LTLIBRARIES = libredex.la libopt.la\n\nBUILT_SOURCES =\n\n#\n# build protobuf\n#\nif SET_PROTOBUF\n\nproto_res_in = \\\n\tproto/Resources.proto \\\n\tproto/Configuration.proto\n\nprotores/%.pb.cc protores/%.pb.h: proto/%.proto ; mkdir -p protores ; $(PROTOC) --proto_path=$(dir $^) --cpp_out=protores $^\n\nproto_res_header_out = $(addprefix protores/, $(notdir ${proto_res_in:.proto=.pb.h}))\nproto_res_body_out = $(addprefix protores/, $(notdir ${proto_res_in:.proto=.pb.cc}))\nBUILT_SOURCES += $(proto_res_header_out)\n\nproto_cfg_in = \\\n\tproto/config.proto\n\nprotocfg/%.pb.cc protocfg/%.pb.h: proto/config.proto ; mkdir -p protocfg ; $(PROTOC) --proto_path=$(dir $^) --cpp_out=protocfg $^\n\nproto_cfg_header_out = $(addprefix protocfg/, $(notdir ${proto_cfg_in:.proto=.pb.h}))\nproto_cfg_body_out = $(addprefix protocfg/, $(notdir ${proto_cfg_in:.proto=.pb.cc}))\nBUILT_SOURCES += $(proto_cfg_header_out)\n\nendif\n\n#\n# libredex: the optimizer's guts\n#\n\nlibredex_la_SOURCES = \\\n\tcheckers/DexLimitsChecker.cpp \\\n\tcheckers/NoInitClassInstructionsChecker.cpp \\\n\tcheckers/NoResolvablePureRefsChecker.cpp \\\n\tcheckers/NoUnreachableInstructionsChecker.cpp \\\n\tcheckers/NoWriteBarrierInstructionsChecker.cpp \\\n\tliblocator/locator.cpp \\\n\tlibredex/AggregateException.cpp \\\n\tlibredex/AnalysisUsage.cpp \\\n\tlibredex/AnnoUtils.cpp \\\n\tlibredex/AnnotationSignatureParser.cpp \\\n\tlibredex/ApiLevelChecker.cpp \\\n\tlibredex/ApkResources.cpp \\\n\tlibredex/AssetManager.cpp \\\n\tlibredex/BalancedPartitioning.cpp \\\n\tlibredex/BaselineProfile.cpp \\\n\tlibredex/BigBlocks.cpp \\\n\tlibredex/BundleResources.cpp \\\n\tlibredex/CFGMutation.cpp \\\n\tlibredex/CallGraph.cpp \\\n\tlibredex/ClassHierarchy.cpp \\\n\tlibredex/ClassUtil.cpp \\\n\tlibredex/ClassChecker.cpp \\\n\tlibredex/ClassReferencesCache.cpp \\\n\tlibredex/ConcurrentContainers.cpp \\\n\tlibredex/ConfigFiles.cpp \\\n\tlibredex/Configurable.cpp \\\n\tlibredex/ControlFlow.cpp \\\n\tlibredex/Creators.cpp \\\n\tlibredex/Debug.cpp \\\n\tlibredex/DexAccess.cpp \\\n\tlibredex/DexAssessments.cpp \\\n\tlibredex/DexAnnotation.cpp \\\n\tlibredex/DexAsm.cpp \\\n\tlibredex/DexCallSite.cpp \\\n\tlibredex/DexClass.cpp \\\n\tlibredex/DexDebugInstruction.cpp \\\n\tlibredex/DexHasher.cpp \\\n\tlibredex/DexIdx.cpp \\\n\tlibredex/DexInstruction.cpp \\\n\tlibredex/DexLimitsInfo.cpp  \\\n\tlibredex/DexLoader.cpp \\\n\tlibredex/DexMemberRefs.cpp \\\n\tlibredex/DexMethodHandle.cpp \\\n\tlibredex/DexOpcode.cpp \\\n\tlibredex/DexOutput.cpp \\\n\tlibredex/DexPosition.cpp \\\n\tlibredex/DexStats.cpp \\\n\tlibredex/DexStore.cpp \\\n\tlibredex/DexStoreUtil.cpp \\\n\tlibredex/DexStructure.cpp \\\n\tlibredex/DexTypeEnvironment.cpp \\\n\tlibredex/DexUtil.cpp \\\n\tlibredex/DexStoreUtil.cpp \\\n\tlibredex/DuplicateClasses.cpp \\\n\tlibredex/EditableCfgAdapter.cpp \\\n\tlibredex/FbjniMarker.cpp \\\n\tlibredex/FrameworkApi.cpp \\\n\tlibredex/FrequentlyUsedPointersCache.cpp \\\n\tlibredex/GlobalConfig.cpp \\\n\tlibredex/GraphVisualizer.cpp \\\n\tlibredex/HierarchyUtil.cpp \\\n\tlibredex/InitClassesWithSideEffects.cpp \\\n\tlibredex/InlinerConfig.cpp \\\n\tlibredex/InstructionLowering.cpp \\\n\tlibredex/InteractiveDebugging.cpp \\\n\tlibredex/IODIMetadata.cpp \\\n\tlibredex/IRAssembler.cpp \\\n\tlibredex/IRCode.cpp \\\n\tlibredex/IRInstruction.cpp \\\n\tlibredex/IRList.cpp \\\n\tlibredex/IRMetaIO.cpp \\\n\tlibredex/IROpcode.cpp \\\n\tlibredex/IRTypeChecker.cpp \\\n\tlibredex/IRTypeChecker.cpp \\\n\tlibredex/JarLoader.cpp \\\n\tlibredex/JavaParserUtil.cpp \\\n\tlibredex/JsonWrapper.cpp \\\n\tlibredex/KeepReason.cpp \\\n\tlibredex/Match.cpp \\\n\tlibredex/MatchFlow.cpp \\\n\tlibredex/MatchFlowDetail.cpp \\\n\tlibredex/MethodDevirtualizer.cpp \\\n\tlibredex/MethodFixup.cpp \\\n\tlibredex/MethodOverrideGraph.cpp \\\n\tlibredex/MethodProfiles.cpp \\\n\tlibredex/MethodSimilarityCompressionConsciousOrderer.cpp \\\n\tlibredex/MethodSimilarityGreedyOrderer.cpp \\\n\tlibredex/MethodUtil.cpp \\\n\tlibredex/MonitorCount.cpp \\\n\tlibredex/Mutators.cpp \\\n\tlibredex/Native.cpp \\\n\tlibredex/NativeNames.cpp \\\n\tlibredex/NoOptimizationsMatcher.cpp \\\n\tlibredex/NullnessDomain.cpp \\\n\tlibredex/OptData.cpp \\\n\tlibredex/Pass.cpp \\\n\tlibredex/PassManager.cpp \\\n\tlibredex/PassRegistry.cpp \\\n\tlibredex/PluginRegistry.cpp \\\n\tlibredex/PointsToSemantics.cpp \\\n\tlibredex/PointsToSemanticsUtils.cpp \\\n\tlibredex/PrintSeeds.cpp \\\n\tlibredex/ProguardConfiguration.cpp \\\n\tlibredex/ProguardLexer.cpp \\\n\tlibredex/ProguardLineRange.cpp \\\n\tlibredex/ProguardMap.cpp \\\n\tlibredex/ProguardMatcher.cpp \\\n\tlibredex/ProguardParser.cpp \\\n\tlibredex/ProguardPrintConfiguration.cpp \\\n\tlibredex/ProguardRegex.cpp \\\n\tlibredex/ProguardReporting.cpp \\\n\tlibredex/Purity.cpp \\\n\tlibredex/Reachability.cpp \\\n\tlibredex/ReachableClasses.cpp \\\n\tlibredex/RedexMappedFile.cpp \\\n\tlibredex/ReadMaybeMapped.cpp \\\n\tlibredex/RedexContext.cpp \\\n\tlibredex/RedexProperties.cpp \\\n\tlibredex/RedexPropertiesManager.cpp \\\n\tlibredex/RedexPropertyChecker.cpp \\\n\tlibredex/RedexPropertyCheckerRegistry.cpp \\\n\tlibredex/RedexException.cpp \\\n\tlibredex/RedexOptions.cpp \\\n\tlibredex/RedexResources.cpp \\\n\tlibredex/ReflectionAnalysis.cpp \\\n\tlibredex/RefChecker.cpp \\\n\tlibredex/RemoveUninstantiablesImpl.cpp \\\n\tlibredex/Resolver.cpp \\\n\tlibredex/ScopedMetrics.cpp \\\n\tlibredex/Show.cpp \\\n\tlibredex/SourceBlockConsistencyCheck.cpp \\\n\tlibredex/SourceBlocks.cpp \\\n\tlibredex/StringTreeSet.cpp \\\n\tlibredex/Timer.cpp \\\n\tlibredex/ThreadPool.cpp \\\n\tlibredex/ThrowPropagationImpl.cpp \\\n\tlibredex/Trace.cpp \\\n\tlibredex/Transform.cpp \\\n\tlibredex/TypeInference.cpp \\\n\tlibredex/TypeSystem.cpp \\\n\tlibredex/TypeUtil.cpp \\\n\tlibredex/UninitializedObjects.cpp \\\n\tlibredex/UnknownVirtuals.cpp \\\n\tlibredex/Vinfo.cpp \\\n\tlibredex/VirtualScope.cpp \\\n\tlibredex/Warning.cpp \\\n\tlibredex/WorkQueue.cpp \\\n\tlibresource/LocaleValue.cpp \\\n\tlibresource/LocaleData.cpp \\\n\tlibresource/ResourceTypes.cpp \\\n\tlibresource/Serialize.cpp \\\n\tlibresource/SharedBuffer.cpp \\\n\tlibresource/String16.cpp \\\n\tlibresource/String8.cpp \\\n\tlibresource/TypeWrappers.cpp \\\n\tlibresource/Unicode.cpp \\\n\tlibresource/VectorImpl.cpp \\\n\tlibresource/Visitor.cpp \\\n\tservice/api-levels/ApiLevelsUtils.cpp \\\n\tservice/branch-prefix-hoisting/BranchPrefixHoisting.cpp \\\n\tservice/class-merging/ApproximateShapeMerging.cpp \\\n\tservice/class-merging/ClassAssemblingUtils.cpp \\\n\tservice/class-merging/ClassMerging.cpp \\\n\tservice/class-merging/ConfigUtils.cpp \\\n\tservice/class-merging/InterDexGrouping.cpp \\\n\tservice/class-merging/MergeabilityCheck.cpp \\\n\tservice/class-merging/MergerType.cpp \\\n\tservice/class-merging/MergingStrategies.cpp \\\n\tservice/class-merging/ModelMerger.cpp \\\n\tservice/class-merging/ModelMethodMerger.cpp \\\n\tservice/class-merging/Model.cpp \\\n\tservice/class-merging/TypeTagUtils.cpp \\\n\tservice/class-splitting/ClassSplitting.cpp \\\n\tservice/cross-dex-ref-minimizer/CrossDexRefMinimizer.cpp \\\n\tservice/constant-propagation/ConstantPropagation.cpp \\\n\tservice/constant-propagation/ConstantPropagationAnalysis.cpp \\\n\tservice/constant-propagation/ConstantPropagationState.cpp \\\n\tservice/constant-propagation/ConstantPropagationTransform.cpp \\\n\tservice/constant-propagation/ConstantPropagationWholeProgramState.cpp \\\n\tservice/constant-propagation/ConstructorParams.cpp \\\n\tservice/constant-propagation/DefinitelyAssignedIFields.cpp \\\n\tservice/constant-propagation/IFieldAnalysisUtil.cpp \\\n\tservice/constant-propagation/IPConstantPropagationAnalysis.cpp \\\n\tservice/constant-propagation/ObjectDomain.cpp \\\n\tservice/constant-propagation/SignDomain.cpp \\\n\tservice/copy-propagation/AliasedRegisters.cpp \\\n\tservice/copy-propagation/CanonicalizeLocks.cpp \\\n\tservice/copy-propagation/CopyPropagation.cpp \\\n\tservice/cross-dex-ref-minimizer/CrossDexRefMinimizer.cpp \\\n\tservice/cse/CommonSubexpressionElimination.cpp \\\n\tservice/dataflow/LiveRange.cpp \\\n\tservice/dataflow/ConstantUses.cpp \\\n\tservice/dedup-blocks/DedupBlocks.cpp \\\n\tservice/dedup-blocks/DedupBlockValueNumbering.cpp \\\n\tservice/escape-analysis/BlamingAnalysis.cpp \\\n\tservice/escape-analysis/LocalPointersAnalysis.cpp \\\n\tservice/field-ops/FieldOpTracker.cpp \\\n\tservice/init-classes/InitClassPruner.cpp \\\n\tservice/init-deps/InitDeps.cpp \\\n\tservice/kotlin-instance-rewrite/KotlinInstanceRewriter.cpp \\\n\tservice/local-dce/LocalDce.cpp \\\n\tservice/loop-info/LoopInfo.cpp \\\n\tservice/method-dedup/ConstantLifting.cpp \\\n\tservice/method-dedup/ConstantValue.cpp \\\n\tservice/method-dedup/MethodDedup.cpp \\\n\tservice/method-dedup/NormalizeConstructor.cpp \\\n\tservice/method-dedup/TypeTags.cpp \\\n\tservice/method-inliner/CallSiteSummaries.cpp \\\n\tservice/method-inliner/CFGInliner.cpp \\\n\tservice/method-inliner/ConstructorAnalysis.cpp \\\n\tservice/method-inliner/Deleter.cpp \\\n\tservice/method-inliner/Inliner.cpp \\\n\tservice/method-inliner/LegacyInliner.cpp \\\n\tservice/method-inliner/MethodInliner.cpp \\\n\tservice/method-inliner/ObjectInlinePlugin.cpp \\\n\tservice/method-inliner/RecursionPruner.cpp \\\n\tservice/method-merger/MethodMerger.cpp \\\n\tservice/method-outliner/OutliningProfileGuidanceImpl.cpp \\\n\tservice/object-sensitive-dce/ObjectSensitiveDce.cpp \\\n\tservice/object-sensitive-dce/SideEffectSummary.cpp \\\n\tservice/object-sensitive-dce/UsedVarsAnalysis.cpp \\\n\tservice/reduce-boolean-branches/ReduceBooleanBranches.cpp \\\n\tservice/reference-update/MethodReference.cpp \\\n\tservice/reference-update/TypeReference.cpp \\\n\tservice/regalloc/GraphColoring.cpp \\\n\tservice/regalloc/Interference.cpp \\\n\tservice/regalloc/RegisterAllocation.cpp \\\n\tservice/regalloc/RegisterType.cpp \\\n\tservice/regalloc/Split.cpp \\\n\tservice/regalloc/VirtualRegistersFile.cpp \\\n\tservice/regalloc-fast/LinearScan.cpp \\\n\tservice/regalloc-fast/LiveInterval.cpp \\\n\tservice/remove_redundant_check_casts/CheckCastAnalysis.cpp \\\n\tservice/remove_redundant_check_casts/CheckCastTransform.cpp \\\n\tservice/resources/RClass.cpp \\\n\tservice/resources/StaticIds.cpp \\\n\tservice/shrinker/Shrinker.cpp \\\n\tservice/switch-dispatch/SwitchDispatch.cpp \\\n\tservice/switch-partitioning/SwitchEquivFinder.cpp \\\n\tservice/type-analysis/GlobalTypeAnalyzer.cpp \\\n\tservice/type-analysis/LocalTypeAnalyzer.cpp \\\n\tservice/type-analysis/WholeProgramState.cpp \\\n\tservice/type-analysis/TypeAnalysisTransform.cpp \\\n\tservice/type-analysis/TypeAnalysisRuntimeAssert.cpp \\\n\tservice/type-analysis/ResolveMethodRefs.cpp \\\n\tservice/type-string-rewriter/TypeStringRewriter.cpp \\\n\tservice/wrapped-primitives/WrappedPrimitives.cpp \\\n\tshared/DexDefs.cpp \\\n\tshared/DexEncoding.cpp \\\n\tshared/file-utils.cpp \\\n\tutil/CommandProfiling.cpp \\\n\tutil/JemallocUtil.cpp \\\n\tutil/Sha1.cpp\n\nlibredex_la_LIBADD = \\\n\t$(BOOST_FILESYSTEM_LIB) \\\n\t$(BOOST_SYSTEM_LIB) \\\n\t$(BOOST_REGEX_LIB) \\\n\t$(BOOST_IOSTREAMS_LIB) \\\n\t$(BOOST_THREAD_LIB) \\\n\t-lpthread\n\nif SET_PROTOBUF\nlibredex_la_SOURCES += \\\n\tprotores/Resources.pb.cc \\\n\tprotores/Configuration.pb.cc \\\n\tprotocfg/config.pb.cc\n\nlibredex_la_LIBADD += \\\n\t$(LIBPROTOBUF_LIBS)\nendif\n\n#\n# libopt: the optimization passes\n#\n\n# Autoconf + libtool does not handle whole-archive well, and it is not\n# supported on MacOS (\"-all_load\"). But we would need this for pass\n# registration. Instead, share sources and create libopt for the tests.\n\nlibopt_la_SOURCES = \\\n\tcheckers/HasSourceBlocksChecker.cpp \\\n\tcheckers/InitialRenameClassCheker.cpp \\\n\tcheckers/InjectionIdInstructionsChecker.cpp \\\n\tcheckers/NoInitClassInstructionsChecker.cpp \\\n\tcheckers/NoUnreachableInstructionsChecker.cpp \\\n\tcheckers/NoSpuriousGetClassCallsChecker.cpp \\\n\tcheckers/RenameClassChecker.cpp \\\n\tanalysis/max-depth/MaxDepthAnalysis.cpp \\\n\tanalysis/ip-reflection-analysis/IPReflectionAnalysis.cpp \\\n\topt/access-marking/AccessMarking.cpp \\\n\topt/add-secondary-dex/AddSecondaryDexPass.cpp \\\n\topt/annokill/AnnoKill.cpp \\\n\topt/analyze-pure-method/PureMethods.cpp \\\n\topt/app_module_usage/AppModuleUsage.cpp \\\n\topt/art-profile-writer/ArtProfileWriterPass.cpp \\\n\topt/builder_pattern/BuilderAnalysis.cpp \\\n\topt/builder_pattern/BuilderTransform.cpp \\\n\topt/builder_pattern/RemoveBuilderPattern.cpp \\\n\topt/branch-prefix-hoisting/BranchPrefixHoistingPass.cpp \\\n\topt/check_breadcrumbs/CheckBreadcrumbs.cpp \\\n\topt/check-recursion/CheckRecursion.cpp \\\n\topt/class-merging/AnonymousClassMergingPass.cpp \\\n\topt/class-merging/ClassMergingPass.cpp \\\n\topt/class-merging/IntraDexClassMergingPass.cpp \\\n\topt/class-merging/ModelSpecGenerator.cpp \\\n\topt/class-splitting/ClassSplittingPass.cpp \\\n\topt/clinit-outliner/ClinitOutlinePass.cpp \\\n\topt/const-class-branches/TransformConstClassBranches.cpp \\\n\topt/constant-propagation/ConstantPropagationPass.cpp \\\n\topt/constant-propagation/ConstantPropagationRuntimeAssert.cpp \\\n\topt/constant-propagation/IPConstantPropagation.cpp \\\n\topt/copy-propagation/CopyPropagationPass.cpp \\\n\topt/cse/CommonSubexpressionEliminationPass.cpp \\\n\topt/dedup_blocks/DedupBlocksPass.cpp \\\n\topt/dedup_resources/DedupResources.cpp \\\n\topt/dedup_resources/murmur_hash.cpp \\\n\topt/dedup-strings/DedupStrings.cpp \\\n\topt/delsuper/DelSuper.cpp \\\n\topt/evaluate_type_checks/EvaluateTypeChecks.cpp \\\n\topt/final_inline/FinalInline.cpp \\\n\topt/final_inline/FinalInlineV2.cpp \\\n\topt/fully-qualify-layouts/FullyQualifyLayouts.cpp \\\n\topt/init-classes/InitClassLoweringPass.cpp \\\n\topt/insert_debug_info/InsertDebugInfoPass.cpp \\\n\topt/insert-source-blocks/InsertSourceBlocks.cpp \\\n\topt/instrument/BlockInstrument.cpp \\\n\topt/instrument/Instrument.cpp \\\n\topt/int_type_patcher/IntTypePatcher.cpp \\\n\topt/interdex/DexRemovalPass.cpp \\\n\topt/interdex/InterDex.cpp \\\n\topt/interdex/InterDexPass.cpp \\\n\topt/interdex/InterDexReshuffleImpl.cpp \\\n\topt/interdex/InterDexReshufflePass.cpp \\\n\topt/interdex/SortRemainingClassesPass.cpp \\\n\topt/kotlin-lambda/RewriteKotlinSingletonInstance.cpp \\\n\topt/kotlin-lambda/KotlinObjectInliner.cpp \\\n\topt/layout-reachability/LayoutReachabilityPass.cpp \\\n\topt/local-dce/LocalDcePass.cpp \\\n\topt/merge_interface/MergeInterface.cpp \\\n\topt/nopper/Nopper.cpp \\\n\topt/nopper/NopperPass.cpp \\\n\topt/nullcheck_conversion/IntrinsifyNullChecksPass.cpp \\\n\topt/nullcheck_conversion/MaterializeNullChecksPass.cpp \\\n\topt/obfuscate/Obfuscate.cpp \\\n\topt/obfuscate/ObfuscateUtils.cpp \\\n\topt/obfuscate/VirtualRenamer.cpp \\\n\topt/obfuscate_resources/ObfuscateResourcesPass.cpp \\\n\topt/object-sensitive-dce/ObjectSensitiveDcePass.cpp \\\n\topt/optimize_enums/EnumClinitAnalysis.cpp \\\n\topt/optimize_enums/EnumConfig.cpp \\\n\topt/optimize_enums/EnumAnalyzeGeneratedMethods.cpp \\\n\topt/optimize_enums/EnumTransformer.cpp \\\n\topt/optimize_enums/EnumUpcastAnalysis.cpp \\\n\topt/optimize_enums/OptimizeEnumsAnalysis.cpp \\\n\topt/optimize_enums/OptimizeEnums.cpp \\\n\topt/optimize_enums/OptimizeEnumsUnmap.cpp \\\n\topt/original_name/OriginalNamePass.cpp \\\n\topt/package-private-preprocessor/PackagePrivatePreprocessor.cpp \\\n\topt/partial-application/PartialApplication.cpp \\\n\topt/peephole/Peephole.cpp \\\n\topt/peephole/RedundantCheckCastRemover.cpp \\\n\topt/print-kotlin-stats/PrintKotlinStats.cpp \\\n\topt/reachable-natives/ReachableNatives.cpp \\\n\topt/rearrange-enum-clinit/RearrangeEnumClinit.cpp \\\n\topt/rebindrefs/ReBindRefs.cpp \\\n\topt/regalloc/RegAlloc.cpp \\\n\topt/regalloc-fast/FastRegAlloc.cpp \\\n\topt/remove-builders/RemoveBuilders.cpp \\\n\topt/remove-builders/RemoveBuildersHelper.cpp \\\n\topt/remove-interfaces/RemoveInterfacePass.cpp \\\n\topt/remove-recursive-locks/RemoveRecursiveLocks.cpp \\\n\topt/remove_redundant_check_casts/RemoveRedundantCheckCasts.cpp \\\n\topt/remove-unreachable/RemoveUnreachable.cpp \\\n\topt/remove-unreachable/TypeAnalysisAwareRemoveUnreachable.cpp \\\n\topt/remove-nullcheck-string-arg/RemoveNullcheckStringArg.cpp \\\n\topt/remove-unused-fields/RemoveUnusedFields.cpp \\\n\topt/remove-unused-args/RemoveUnusedArgs.cpp \\\n\topt/renameclasses/InitialRenameClassesPass.cpp \\\n\topt/renameclasses/RenameClassesV2.cpp \\\n\topt/reorder-interfaces-decl/ReorderInterfacesDecl.cpp \\\n\topt/reduce-array-literals/ReduceArrayLiterals.cpp \\\n\topt/reduce-boolean-branches/ReduceBooleanBranchesPass.cpp \\\n\topt/reduce-gotos/ReduceGotos.cpp \\\n\topt/reduce-sparse-switches/ReduceSparseSwitchesPass.cpp \\\n\topt/resolve-refs/ResolveRefsPass.cpp \\\n\topt/resolve-refs/ExternalRefsManglingPass.cpp \\\n\topt/resolve-refs/SpecializeRtype.cpp \\\n\topt/result-propagation/ResultPropagation.cpp \\\n\topt/resolve-proguard-values/ResolveProguardAssumeValues.cpp \\\n\topt/resources-inlining-pass/ResourcesInliningPass.cpp \\\n\topt/shorten-srcstrings/Shorten.cpp \\\n\topt/shrinker/ShrinkerPass.cpp \\\n\topt/unreachable/UnreachableLoweringPass.cpp \\\n\topt/make-public/MakePublicPass.cpp \\\n\topt/methodinline/IntraDexInlinePass.cpp \\\n\topt/methodinline/LocalMethodInlinePass.cpp \\\n\topt/methodinline/MethodInlinePass.cpp \\\n\topt/methodinline/PerfMethodInlinePass.cpp \\\n\topt/methodinline/BridgeSynthInlinePass.cpp \\\n\topt/outliner/ClosureAggregator.cpp \\\n\topt/outliner/InstructionSequenceOutliner.cpp \\\n\topt/outliner/MethodClosures.cpp \\\n\topt/outliner/MethodSplitter.cpp \\\n\topt/outliner/MethodSplittingPass.cpp \\\n\topt/outliner/OutlinerTypeAnalysis.cpp \\\n\topt/outliner/PartialCandidateAdapter.cpp \\\n\topt/outliner/ReducedControlFlow.cpp \\\n\topt/outliner/ReducedCFGClosureAdapter.cpp \\\n\topt/outliner/SplittableClosures.cpp \\\n\topt/singleimpl/SingleImpl.cpp \\\n\topt/singleimpl/SingleImplAnalyze.cpp \\\n\topt/singleimpl/SingleImplOptimize.cpp \\\n\topt/singleimpl/SingleImplStats.cpp \\\n\topt/split_huge_switches/SplitHugeSwitchPass.cpp \\\n\topt/split_resource_tables/SplitResourceTables.cpp \\\n\topt/object-escape-analysis/ExpandableMethodParams.cpp \\\n\topt/object-escape-analysis/ObjectEscapeAnalysisImpl.cpp \\\n\topt/object-escape-analysis/ObjectEscapeAnalysis.cpp \\\n\topt/staticrelo/StaticReloV2.cpp \\\n\topt/string_concatenator/StringConcatenator.cpp \\\n\topt/stringbuilder-outliner/StringBuilderOutliner.cpp \\\n\topt/strip-debug-info/StripDebugInfo.cpp \\\n\topt/optimize_resources/OptimizeResources.cpp \\\n\topt/typedef-anno-checker/TypedefAnnoCheckerPass.cpp \\\n\topt/typedef-anno-checker/TypedefAnnoOptPass.cpp \\\n\topt/type-analysis/CallGraphFileGenerationPass.cpp \\\n\topt/type-analysis/GlobalTypeAnalysisPass.cpp \\\n\topt/type-analysis/TypeAnalysisCallGraphGenerationPass.cpp \\\n\topt/unmark_proguard_keep/UnmarkProguardKeep.cpp \\\n\topt/up-code-motion/UpCodeMotion.cpp \\\n\topt/uses-names/UsesNames.cpp \\\n\topt/verifier/Verifier.cpp \\\n\topt/vertical_merging/VerticalMerging.cpp \\\n\topt/virtual_merging/DedupVirtualMethods.cpp \\\n\topt/virtual_merging/VirtualMerging.cpp \\\n\topt/virtual_scope/MethodDevirtualizationPass.cpp \\\n\topt/wrapped-primitives/WrappedPrimitivesPass.cpp \\\n\topt/write_barrier/WriteBarrierLoweringPass.cpp\n\nlibopt_la_LIBADD = \\\n    libredex.la \\\n\t$(BOOST_FILESYSTEM_LIB) \\\n\t$(BOOST_SYSTEM_LIB) \\\n\t$(BOOST_REGEX_LIB) \\\n\t$(BOOST_IOSTREAMS_LIB) \\\n\t$(BOOST_THREAD_LIB) \\\n\t-lpthread\n\n#\n# redex-all: the main executable\n#\nbin_PROGRAMS = redexdump\nnoinst_PROGRAMS = redex-all\n\nredex_all_SOURCES = \\\n    $(libopt_la_SOURCES) \\\n\ttools/common/ToolsCommon.cpp \\\n\ttools/redex-all/main.cpp\n\n# Workaround for not using libopt.\nredex_all_CPPFLAGS = $(AM_CPPFLAGS)\n\nredex_all_LDADD = \\\n\tlibredex.la \\\n\t$(BOOST_FILESYSTEM_LIB) \\\n\t$(BOOST_SYSTEM_LIB) \\\n\t$(BOOST_REGEX_LIB) \\\n\t$(BOOST_IOSTREAMS_LIB) \\\n\t$(BOOST_PROGRAM_OPTIONS_LIB) \\\n\t$(BOOST_THREAD_LIB) \\\n\t-lpthread \\\n\t-ldl\n\nif SET_PROTOBUF\nredex_all_LDADD += \\\n\t$(LIBPROTOBUF_LIBS)\nendif\n\nredex_all_LDFLAGS = \\\n\t-rdynamic # function names in stack traces\n\nredexdump_SOURCES = \\\n\ttools/redexdump/DumpTables.cpp \\\n\ttools/redexdump/PrintUtil.cpp \\\n\ttools/redexdump/RedexDump.cpp \\\n\ttools/common/DexCommon.cpp \\\n\ttools/common/Formatters.cpp\n\nredexdump_LDADD = \\\n\tlibredex.la \\\n\t$(BOOST_FILESYSTEM_LIB) \\\n\t$(BOOST_SYSTEM_LIB) \\\n\t$(BOOST_REGEX_LIB) \\\n\t$(BOOST_THREAD_LIB) \\\n\t-lpthread \\\n\t-ldl\n\n#\n# redex: Python driver script\n#\nbin_SCRIPTS = redex apkutil\nCLEANFILES = redex\n\n# Embedded API level files.\nGEN_API_LEVELS_SCRIPT = $(srcdir)/gen_packed_apilevels.py\nGENERATED_API_LEVELS_MODULE = generated_apilevels.py\n$(GENERATED_API_LEVELS_MODULE): $(GEN_API_LEVELS_SCRIPT) $(srcdir)/service/api-levels/framework_classes_api_*.txt\n\tpython3 $(GEN_API_LEVELS_SCRIPT) -o $@ $(srcdir)/service/api-levels/framework_classes_api_*.txt\n\nBUILT_SOURCES += $(GENERATED_API_LEVELS_MODULE)\n\nPYTHON_SRCS := redex.py \\\n\tpyredex/__init__.py \\\n\tpyredex/logger.py \\\n\tpyredex/unpacker.py \\\n\tpyredex/utils.py \\\n\t$(GENERATED_API_LEVELS_MODULE)\n\nredex: redex-all $(PYTHON_SRCS)\n\tSRC_DIR=\"$(srcdir)\" $(srcdir)/bundle-redex.sh\n"
        },
        {
          "name": "Makefile.inc",
          "type": "blob",
          "size": 5.4736328125,
          "content": "#\n# Include paths\n#\nCOMMON_INCLUDES = \\\n\t-I$(top_srcdir)/analysis/ip-reflection-analysis \\\n\t-I$(top_srcdir)/analysis/max-depth \\\n\t-I$(top_srcdir)/checkers \\\n\t-I$(top_srcdir)/liblocator \\\n\t-I$(top_srcdir)/libredex \\\n\t-I$(top_srcdir)/libresource \\\n\t-I$(top_srcdir)/opt \\\n\t-I$(top_srcdir)/opt/access-marking \\\n\t-I$(top_srcdir)/opt/add-secondary-dex \\\n\t-I$(top_srcdir)/opt/add_redex_txt_to_apk \\\n\t-I$(top_srcdir)/opt/analyze-pure-method \\\n\t-I$(top_srcdir)/opt/app_module_usage \\\n\t-I$(top_srcdir)/opt/art-profile-writer \\\n\t-I$(top_srcdir)/opt/annoclasskill \\\n\t-I$(top_srcdir)/opt/annokill \\\n\t-I$(top_srcdir)/opt/basic-block \\\n\t-I$(top_srcdir)/opt/branch-prefix-hoisting \\\n\t-I$(top_srcdir)/opt/bridge \\\n\t-I$(top_srcdir)/opt/builder_pattern \\\n\t-I$(top_srcdir)/opt/check_breadcrumbs \\\n\t-I$(top_srcdir)/opt/class-merging \\\n\t-I$(top_srcdir)/opt/class-splitting \\\n\t-I$(top_srcdir)/opt/constant-propagation \\\n\t-I$(top_srcdir)/opt/copy-propagation \\\n\t-I$(top_srcdir)/opt/cse \\\n\t-I$(top_srcdir)/opt/dedup_blocks \\\n\t-I$(top_srcdir)/opt/dedup_resources \\\n\t-I$(top_srcdir)/opt/dedup-strings \\\n\t-I$(top_srcdir)/opt/delsuper \\\n\t-I$(top_srcdir)/opt/evaluate_type_checks \\\n\t-I$(top_srcdir)/opt/final_inline \\\n\t-I$(top_srcdir)/opt/init-classes \\\n\t-I$(top_srcdir)/opt/instrument \\\n\t-I$(top_srcdir)/opt/int_type_patcher \\\n\t-I$(top_srcdir)/opt/interdex \\\n\t-I$(top_srcdir)/opt/layout-reachability \\\n\t-I$(top_srcdir)/opt/local-dce \\\n\t-I$(top_srcdir)/opt/make-public \\\n\t-I$(top_srcdir)/opt/merge_interface \\\n\t-I$(top_srcdir)/opt/methodinline \\\n\t-I$(top_srcdir)/opt/obfuscate \\\n\t-I$(top_srcdir)/opt/obfuscate_resources \\\n\t-I$(top_srcdir)/opt/object-sensitive-dce \\\n\t-I$(top_srcdir)/opt/optimize_enums \\\n\t-I$(top_srcdir)/opt/optimize_resources \\\n\t-I$(top_srcdir)/opt/original_name \\\n\t-I$(top_srcdir)/opt/outliner \\\n\t-I$(top_srcdir)/opt/partial-application \\\n\t-I$(top_srcdir)/opt/peephole \\\n\t-I$(top_srcdir)/opt/print-members \\\n\t-I$(top_srcdir)/opt/print-kotlin-stats \\\n\t-I$(top_srcdir)/opt/rearrange-enum-clinit \\\n\t-I$(top_srcdir)/opt/rebindrefs \\\n\t-I$(top_srcdir)/opt/reduce-array-literals \\\n\t-I$(top_srcdir)/opt/reduce-boolean-branches \\\n\t-I$(top_srcdir)/opt/reduce-gotos \\\n\t-I$(top_srcdir)/opt/reduce-sparse-switches \\\n\t-I$(top_srcdir)/opt/redundant_move_elimination \\\n\t-I$(top_srcdir)/opt/regalloc \\\n\t-I$(top_srcdir)/opt/remove-apilevel-checks \\\n\t-I$(top_srcdir)/opt/remove-builders \\\n\t-I$(top_srcdir)/opt/remove_empty_classes \\\n\t-I$(top_srcdir)/opt/remove-interfaces \\\n\t-I$(top_srcdir)/opt/remove-nullcheck-string-arg \\\n\t-I$(top_srcdir)/opt/remove-recursive-locks \\\n\t-I$(top_srcdir)/opt/remove_redundant_check_casts \\\n\t-I$(top_srcdir)/opt/remove-uninstantiables \\\n\t-I$(top_srcdir)/opt/remove-unreachable \\\n\t-I$(top_srcdir)/opt/remove-unused-args \\\n\t-I$(top_srcdir)/opt/renameclasses \\\n\t-I$(top_srcdir)/opt/reorder-interfaces \\\n\t-I$(top_srcdir)/opt/resolve-proguard-values \\\n\t-I$(top_srcdir)/opt/resolve-refs \\\n\t-I$(top_srcdir)/opt/resources-inlining-pass \\\n\t-I$(top_srcdir)/opt/result-propagation \\\n\t-I$(top_srcdir)/opt/shrinker \\\n\t-I$(top_srcdir)/opt/shorten-srcstrings \\\n\t-I$(top_srcdir)/opt/singleimpl \\\n\t-I$(top_srcdir)/opt/split_huge_switches \\\n\t-I$(top_srcdir)/opt/split_resource_tables \\\n\t-I$(top_srcdir)/opt/staticrelo \\\n\t-I$(top_srcdir)/opt/static-sink \\\n\t-I$(top_srcdir)/opt/stringbuilder-outliner \\\n\t-I$(top_srcdir)/opt/string_concatenator \\\n\t-I$(top_srcdir)/opt/strip-debug-info \\\n\t-I$(top_srcdir)/opt/synth \\\n\t-I$(top_srcdir)/opt/test_cfg \\\n\t-I$(top_srcdir)/opt/throw-propagation \\\n\t-I$(top_srcdir)/opt/track_resources \\\n\t-I$(top_srcdir)/opt/type-analysis \\\n\t-I$(top_srcdir)/opt/unmark_proguard_keep \\\n\t-I$(top_srcdir)/opt/unreferenced_interfaces \\\n\t-I$(top_srcdir)/opt/unterface \\\n\t-I$(top_srcdir)/opt/up-code-motion \\\n\t-I$(top_srcdir)/opt/verifier \\\n\t-I$(top_srcdir)/opt/vertical_merging \\\n\t-I$(top_srcdir)/opt/virtual_merging \\\n\t-I$(top_srcdir)/opt/virtual_scope \\\n\t-I$(top_srcdir)/service/api-levels \\\n\t-I$(top_srcdir)/service/branch-prefix-hoisting \\\n\t-I$(top_srcdir)/service/class-init \\\n\t-I$(top_srcdir)/service/class-merging \\\n\t-I$(top_srcdir)/service/class-splitting \\\n\t-I$(top_srcdir)/service/constant-propagation \\\n\t-I$(top_srcdir)/service/copy-propagation \\\n\t-I$(top_srcdir)/service/cross-dex-ref-minimizer \\\n\t-I$(top_srcdir)/service/cse \\\n\t-I$(top_srcdir)/service/dataflow \\\n\t-I$(top_srcdir)/service/dedup-blocks \\\n\t-I$(top_srcdir)/service/escape-analysis \\\n\t-I$(top_srcdir)/service/field-ops \\\n\t-I$(top_srcdir)/service/init-classes \\\n\t-I$(top_srcdir)/service/init-deps \\\n\t-I$(top_srcdir)/service/local-dce \\\n\t-I$(top_srcdir)/service/loop-info \\\n\t-I$(top_srcdir)/service/method-dedup \\\n\t-I$(top_srcdir)/service/method-inliner \\\n\t-I$(top_srcdir)/service/method-outliner \\\n\t-I$(top_srcdir)/service/method-merger \\\n\t-I$(top_srcdir)/service/object-sensitive-dce \\\n\t-I$(top_srcdir)/service/kotlin-instance-rewrite \\\n\t-I$(top_srcdir)/service/reduce-boolean-branches \\\n\t-I$(top_srcdir)/service/reference-update \\\n\t-I$(top_srcdir)/service/regalloc \\\n\t-I$(top_srcdir)/service/regalloc-fast \\\n\t-I$(top_srcdir)/service/remove_redundant_check_casts \\\n\t-I$(top_srcdir)/service/resources \\\n\t-I$(top_srcdir)/service/shrinker \\\n\t-I$(top_srcdir)/service/switch-dispatch \\\n\t-I$(top_srcdir)/service/switch-partitioning \\\n\t-I$(top_srcdir)/service/type-analysis \\\n\t-I$(top_srcdir)/service/type-string-rewriter \\\n\t-I$(top_srcdir)/service/wrapped-primitives \\\n\t-I$(top_srcdir)/shared \\\n\t-I$(top_srcdir)/sparta/include \\\n\t-I$(top_srcdir)/tools/common \\\n\t-I$(top_srcdir)/tools/redexdump \\\n\t-I$(top_srcdir)/util \\\n\t-I/usr/include/jsoncpp\n\nif SET_PROTOBUF\nCOMMON_INCLUDES += \\\n\t-I$(builddir)/protores \\\n\t$(PROTOBUF_CXXFLAGS)\nendif\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 0.6611328125,
          "content": "# ReDex: An Android Bytecode Optimizer\n\nReDex is an Android bytecode (dex) optimizer originally developed at\nFacebook. It provides a framework for reading, writing, and analyzing .dex\nfiles, and a set of optimization passes that use this framework to improve the\nbytecode.  An APK optimized by ReDex should be smaller and faster than its\nsource.\n\nGo to https://fbredex.com for full documentation.\n\n## Contributions\n\nSee [CONTRIBUTING.md](https://github.com/facebook/redex/blob/master/CONTRIBUTING.md) to understand how to contribute to this project.\n\n## License\n\nThe ReDex repository is available under the [MIT License](https://github.com/facebook/redex/blob/master/LICENSE).\n"
        },
        {
          "name": "analysis",
          "type": "tree",
          "content": null
        },
        {
          "name": "apkutil",
          "type": "blob",
          "size": 3.7841796875,
          "content": "#!/usr/bin/env python3\n\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport os\nimport re\nimport subprocess\nimport sys\nimport zipfile\nfrom functools import wraps\n\nimport pyredex.unpacker as unpacker\nfrom pyredex.utils import abs_glob, make_temp_dir\n\nALL_COMMANDS = {}\n\ndef log(*args):\n    print(*args, file=sys.stderr)\n\ndef command(name, desc):\n    def wrap_function(f):\n        @wraps(f)\n        def wrapper(dexfiles, apk_dir, *args, **kwds):\n            return f(dexfiles, apk_dir, *args, **kwds)\n\n        wrapper.name = name\n        wrapper.desc = desc\n        ALL_COMMANDS[name] = wrapper\n        return wrapper\n    return wrap_function\n\n# -------------------------- Command Definitions -----------------------------\n\n@command(name='dexdump',\n         desc='Calls dexdump with dexes from apk. ' \\\n              'Output written to stdout. Accepts all dexdump options.')\ndef dexdump(dexfiles, apk_dir, *args):\n    dexdump_args = ['dexdump'] + list(args) + dexfiles\n    subprocess.check_call(dexdump_args)\n\n\n@command(name='redexdump',\n         desc='Calls redexdump with dexes from apk. ' \\\n                'Output written to stdout. Accepts all redexdump options.')\ndef redexdump(dexfiles, apk_dir, *args):\n    redexdump_args = ['redexdump'] + list(args) + dexfiles\n    subprocess.check_call(redexdump_args)\n\n\n@command(name='codesize',\n         desc='Prints total and primary dex size')\ndef codesize(dexfiles, apk_dir, *args):\n    one_mb = 1024. * 1024.\n    total_size = sum(os.path.getsize(d) for d in dexfiles)\n    primary_dex_size = sum(os.path.getsize(d)\n            for d in dexfiles if d.endswith('classes.dex'))\n\n    dex_count = len(dexfiles)\n    log('Total code size: {:.2f}MB in {} dex files'.format(\n            total_size / one_mb, dex_count))\n    log('Primary dex size: {:.2f}MB'.format(primary_dex_size / one_mb))\n\n\n@command(name='classes',\n         desc='Prints list of classes. Use -j for java-style names.')\ndef classes(dexfiles, apk_dir, *args):\n    java_style = '-j' in args\n    proc = subprocess.Popen(['dexdump', '-f'] + dexfiles,\n            stdout=subprocess.PIPE)\n\n    pattern = b\"  Class descriptor  : '([^']+)'\"\n    for line in proc.stdout:\n        match = re.match(pattern, line)\n        if match:\n            classname = match.group(1).decode()\n            if java_style:\n                classname = classname[1:-1].replace('/', '.')\n            print(classname)\n\n\n# ------------------------- End Command Definitions ---------------------------\n\ndef invoke_command(apk_path, cmd, *command_args):\n    extracted_apk_dir = make_temp_dir('.redex_extracted_apk')\n\n    log('Extracting apk...')\n    with zipfile.ZipFile(apk_path) as z:\n        z.extractall(extracted_apk_dir)\n\n    dex_mode = unpacker.detect_secondary_dex_mode(extracted_apk_dir)\n    log('Detected dex mode ' + str(type(dex_mode).__name__))\n    dex_dir = make_temp_dir('.redex_dexen')\n\n    log('Unpacking dex files')\n    dex_mode.unpackage(extracted_apk_dir, dex_dir)\n\n    dex_files = list(abs_glob(dex_dir, '*.dex'))\n\n    log('Running command ' + cmd.name + '...')\n    cmd(dex_files, apk_path, *command_args)\n\n\ndef show_usage():\n    log('Redex APK Utilties')\n    log('Usage: apkutil <path_to_apk> <command> [command args...]\\n')\n    log('Available commands:')\n\n    for name, tool in sorted(ALL_COMMANDS.items()):\n        log('    {:<12} {}'.format(name, tool.desc))\n\n\nif __name__ == '__main__':\n    if len(sys.argv) < 3:\n        show_usage()\n    else:\n        apk_path = sys.argv[1]\n        command_name = sys.argv[2]\n        if not os.path.isfile(apk_path):\n            log(apk_path + ' is not a file')\n        if command_name in ALL_COMMANDS:\n            args = [apk_path, ALL_COMMANDS[command_name]] + sys.argv[3:]\n            invoke_command(*args)\n"
        },
        {
          "name": "bundle-redex.sh",
          "type": "blob",
          "size": 0.517578125,
          "content": "#!/bin/bash\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nset -e\n\nSRC_DIR=\"${SRC_DIR:-.}\"\n\nif [ -f \"generated_apilevels.py\" ] ; then\n  GEN_APILEVELS_INPUT=\"generated_apilevels.py\"\nelse\n  GEN_APILEVELS_INPUT=\nfi\n\ntar czf redex.tar.gz redex-all \"${SRC_DIR}/redex.py\" \"${SRC_DIR}\"/pyredex/*.py $GEN_APILEVELS_INPUT\ncat \"${SRC_DIR}/selfextract.sh\" redex.tar.gz > redex\nchmod +x redex\nrm redex.tar.gz\n"
        },
        {
          "name": "checkers",
          "type": "tree",
          "content": null
        },
        {
          "name": "cmake_modules",
          "type": "tree",
          "content": null
        },
        {
          "name": "config",
          "type": "tree",
          "content": null
        },
        {
          "name": "configure.ac",
          "type": "blob",
          "size": 5.7734375,
          "content": "#                                               -*- Autoconf -*-\n# Process this file with autoconf to produce a configure script.\n\nAC_PREREQ([2.69])\nAC_INIT([redex], [1.0], [not-valid-yet@fb.com])\nAM_INIT_AUTOMAKE([subdir-objects])\n# clear out default cxx flags (was \"-O2 -g\") so that they don't override\n# the flags defined in AM_CXXFLAGS. add \"-std\" to work around gtest issue\n# on macos.\n: ${CXXFLAGS=\"-std=gnu++17\"}\n\n# Checks for programs.\nAC_PROG_CXX\nAC_PROG_CC\n\nLT_INIT\n\nAC_CONFIG_MACRO_DIR([m4])\n\nAM_PATH_PYTHON([3.0], [], [AC_MSG_ERROR([Redex requires python3])])\n\n# Checks for libraries.\nAX_PTHREAD\nAX_BOOST_BASE([1.71.0], [], [AC_MSG_ERROR(\n              [Please install boost >= 1.71 (including filesystem)])])\nAX_BOOST_FILESYSTEM\nAX_BOOST_REGEX\nAX_BOOST_PROGRAM_OPTIONS\nAX_BOOST_IOSTREAMS\nAX_BOOST_THREAD\nAC_CHECK_LIB([z], [adler32], [], [AC_MSG_ERROR([Please install zlib])])\nAC_CHECK_LIB([jsoncpp], [main], [], [AC_MSG_ERROR([Please install jsoncpp])])\n\n# check whether user enabled protobuf\nAC_ARG_ENABLE([protobuf],\n    [AS_HELP_STRING([--enable-protobuf],\n        [Enable the protobuf for AppBundle build])],\n    [ AC_DEFINE(HAS_PROTOBUF) ]\n)\n\nAS_IF([test \"x$enable_protobuf\" = \"xyes\"], [\n    # user enabled protobuf\n    # check if protobuf is installed\n\n    # proto compiler\n    # allow users to specify the path to protobuf compiler\n    # --with-protoc\n\n    AC_ARG_WITH([protoc],\n        [AS_HELP_STRING([--with-protoc=/path/to/protoc],\n            [Location of the protobuf compiler.])],\n        [PROTOC=\"$withval\"],\n        [ AS_IF([test \"x${PROTOC}\" == \"x\"],\n            [AC_PATH_PROG([PROTOC], [protoc], [no])])\n        ]\n    )\n    AS_IF([test \"${PROTOC}\" == \"no\"], [AC_MSG_ERROR([Protobuf compiler protoc not found.])])\n\n    # protobuf libraries\n    # allow users to specify the path to the protobuf libs\n    # --with-protolib\n\n    AC_ARG_WITH([protolib],\n        [AS_HELP_STRING([--with-protolib=/path/to/protolibs],\n            [Location of the protobuf lib dir.])],\n        [ # protobuf lib path set by user\n            LDFLAGS_ORIG=$LDFLAGS\n\n            # test protobuf\n            LDFLAGS=\"${LDFLAGS_ORIG} -L${withval}\"\n            AC_LANG_PUSH([C++])\n            AC_CHECK_LIB([protobuf], [main], [\n            # library found\n                AC_SUBST([LIBPROTOBUF_LIBS], \"-L${withval} -lprotobuf\")],\n                [AC_MSG_ERROR([Protobuf libraries not found for user specified path.])]\n            )\n            AC_LANG_POP([C++])\n            # restore original LDFLAGS\n            LDFLAGS=$LDFLAGS_ORIG\n        ],\n        [ # check default search path\n            AC_CHECK_LIB([protobuf], [main], [\n                AC_SUBST([LIBPROTOBUF_LIBS], \"-lprotobuf\")],\n                [AC_MSG_ERROR([Protobuf libraries not found.])]\n            )\n        ]\n    )\n\n    # protobuf headers\n    # allow users to specify the path to the protobuf headers\n    # --with-protoheader\n\n    AC_ARG_WITH([protoheader],\n        [AS_HELP_STRING([--with-protoheader=/path/to/protoheaders],\n            [Location of the protobuf include dir.])],\n        [ # protobuf header path set by user\n            CXXFLAGS_ORIG=$CXXFLAGS\n\n            # test protobuf header\n            CXXFLAGS=\"-std=gnu++17 ${CXXFLAGS_ORIG} -I${withval}\"\n            AC_LANG_PUSH([C++])\n            AC_CHECK_HEADER([google/protobuf/io/coded_stream.h], [\n                # library found\n                AC_SUBST([PROTOBUF_CXXFLAGS], \"-I${withval}\")],\n                [AC_MSG_ERROR([Protobuf headers not found for user specified path.])]\n            )\n            AC_LANG_POP([C++])\n            # restore original CXXFLAGS\n            CXXFLAGS=$CXXFLAGS_ORIG\n        ],\n        []\n    )\n])\nAM_CONDITIONAL([SET_PROTOBUF],[test \"x${enable_protobuf}\" = \"xyes\"])\n\n# Check for Android SDK (for tests).\nAC_ARG_WITH([android-sdk],\n    [AS_HELP_STRING([--with-android-sdk=/path/to/android-sdk],\n        [Location of the Android SDK, for testing.])],\n    [ANDROID_HOME=\"$withval\"],\n    [NO_ANDROID_HOME=\"no\"]\n    [ AS_IF([test \"x${PROTOC}\" == \"x\"],\n        [AC_PATH_PROG([PROTOC], [protoc], [no])])\n    ]\n)\n# Look for dx & android.jar.\nAS_IF([test \"x$NO_ANDROID_HOME\" = \"xno\"],\n    [],\n    [\n        # Do not assume a totally new SDK. Try platform 29.\n        AC_PATH_PROG(\n            DX,\n            dx,\n            no,\n            \"$ANDROID_HOME/build-tools/29.0.2:$PATH\"\n        )\n        AS_IF([test \"x$DX\" = \"xno\"],\n            [AC_MSG_ERROR([--with-android-sdk option was specified but does not seem to point at a valid Android SDK installation])]\n            []\n        )\n        AC_CHECK_FILE(\n            \"$ANDROID_HOME/platforms/android-29/android.jar\",\n            [\n                AC_SUBST(ANDROID_JAR,\"$ANDROID_HOME/platforms/android-29/android.jar\")\n                AC_SUBST(ANDROID_SDK,\"$ANDROID_HOME\")\n                AC_SUBST(ANDROID_PLATFORM_VERSION,\"android-29\")\n            ],\n            [AC_MSG_ERROR([--with-android-sdk option was specified but does not seem to point at a valid Android SDK installation])]\n        )\n    ]\n)\n\n# Checks for header files.\nAC_CHECK_HEADERS([arpa/inet.h fcntl.h inttypes.h memory.h netinet/in.h stddef.h stdint.h stdlib.h string.h sys/time.h unistd.h])\n\n# Checks for typedefs, structures, and compiler characteristics.\nAC_CHECK_HEADER_STDBOOL\nAC_C_INLINE\nAC_TYPE_INT16_T\nAC_TYPE_INT32_T\nAC_TYPE_INT64_T\nAC_TYPE_INT8_T\nAC_TYPE_OFF_T\nAC_TYPE_PID_T\nAC_TYPE_SIZE_T\nAC_TYPE_SSIZE_T\nAC_TYPE_UINT16_T\nAC_TYPE_UINT32_T\nAC_TYPE_UINT64_T\nAC_TYPE_UINT8_T\n\n# Checks for library functions.\nAC_FUNC_MALLOC\nAC_FUNC_MMAP\nAC_FUNC_REALLOC\nAC_CHECK_FUNCS([clock_gettime gettimeofday memmove memset munmap regcomp strchr strdup strerror strrchr strstr strtol])\n\nAC_CONFIG_FILES([\n        Makefile\n        test/Makefile\n        test/integ/Makefile\n        test/unit/Makefile\n        test/samples/Makefile\n        test/samples/more_resources/Makefile\n        test/samples/strings/Makefile\n        ])\nAC_OUTPUT\n"
        },
        {
          "name": "container",
          "type": "tree",
          "content": null
        },
        {
          "name": "data",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker-compose.yml",
          "type": "blob",
          "size": 0.4853515625,
          "content": "version: \"3\"\n\nservices:\n  docusaurus:\n    build: .\n    ports:\n      - 3000:3000\n      - 35729:35729\n    volumes:\n      - ./docs:/app/docs\n      - ./website/blog:/app/website/blog\n      - ./website/core:/app/website/core\n      - ./website/i18n:/app/website/i18n\n      - ./website/pages:/app/website/pages\n      - ./website/static:/app/website/static\n      - ./website/sidebars.json:/app/website/sidebars.json\n      - ./website/siteConfig.js:/app/website/siteConfig.js\n    working_dir: /app/website\n"
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "gen_packed_apilevels.py",
          "type": "blob",
          "size": 4.076171875,
          "content": "#!/usr/bin/env python3\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport argparse\nimport base64\nimport io\nimport logging\nimport os\nimport shutil\nimport zipfile\nfrom collections import namedtuple\n\n\ntry:\n    import lzma  # noqa(F401)\n    import tarfile\n\n    has_tar_lzma = True\nexcept ImportError:\n    has_tar_lzma = False\n\n\nArgs = namedtuple(\"Args\", [\"inputs\", \"output\", \"tarxz\"])\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser(\n        description=\"Generate packed API levels python module\"\n    )\n\n    parser.add_argument(\"api_files\", nargs=\"+\", help=\"API files\")\n    parser.add_argument(\n        \"-o\",\n        \"--out\",\n        nargs=1,\n        type=os.path.realpath,\n        help=\"Generated python wrapper\",\n    )\n    parser.add_argument(\n        \"--force-zip\",\n        action=\"store_true\",\n        help=\"Force the use of zip, even when tar and lzma are available\",\n    )\n\n    args = parser.parse_args()\n\n    global has_tar_lzma\n    return Args(args.api_files, args.out[0], has_tar_lzma and not args.force_zip)\n\n\ndef compress_zip(inputs):\n    logging.info(\"Compressing as zip\")\n    buf = io.BytesIO(b\"\")\n    with zipfile.ZipFile(buf, \"w\") as zf:\n        for input in inputs:\n            logging.info(\"Adding %s\", input)\n            with open(input, \"rb\") as f:\n                # Files are multi-MB, try to do it smartly.\n                with zf.open(os.path.basename(input), mode=\"w\") as f2:\n                    shutil.copyfileobj(f, f2)\n    buf.seek(0)\n    return buf\n\n\ndef compress_tar_xz(inputs):\n    logging.info(\"Compressing as tar.xz\")\n    buf = io.BytesIO(b\"\")\n    tar = tarfile.open(fileobj=buf, mode=\"w:xz\")\n\n    for input in inputs:\n        logging.info(\"Adding %s\", input)\n        # In case the inputs are symlinks, it's better to work with the file\n        # object outright.\n        with open(input, \"rb\") as f:\n            info = tar.gettarinfo(arcname=os.path.basename(input), fileobj=f)\n            tar.addfile(info, fileobj=f)\n\n    tar.close()\n    buf.seek(0)\n    return buf\n\n\ndef compress_and_base_64(inputs, tar_xz):\n    with compress_tar_xz(inputs) if tar_xz else compress_zip(inputs) as buf:\n        return base64.b64encode(buf.getbuffer())\n\n\n_FILE_TEMPLATE = \"\"\"\n#!/usr/bin/env python3\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport base64\nimport io\nimport re\n\n{extra_imports}\n\n\n_BASE64BLOB = \"{base64_blob}\"\n\n\n{compression_specific_api}\n\n\ndef get_api_level_file(level):\n    name = f\"framework_classes_api_{{level}}.txt\"\n    return _load(name)\n\n\ndef get_api_levels():\n    name_re = re.compile(r\"^framework_classes_api_(\\\\d+)\\\\.txt$\")\n    return {{\n        int(match.group(1)) for name in _all() for match in [name_re.match(name)] if match\n    }}\n\"\"\"\n\n\n_TAR_XZ_IMPORTS = \"\"\"\nimport lzma  # noqa(F401)\nimport tarfile\n\"\"\"\n_TAR_XZ_API = \"\"\"\n_TAR = tarfile.open(mode=\"r:xz\", fileobj=io.BytesIO(base64.b64decode(_BASE64BLOB)))\n\n\ndef _load(name):\n    global _TAR\n    return _TAR.extractfile(name).read()\n\n\ndef _all():\n    global _TAR\n    return _TAR.getnames()\n\"\"\"\n\n\n_ZIP_IMPORTS = \"import zipfile\"\n_ZIP_API = \"\"\"\n_ZIP = zipfile.ZipFile(io.BytesIO(base64.b64decode(_BASE64BLOB)), \"r\")\n\n\ndef _load(name):\n    global _ZIP\n    return _ZIP.read(name)\n\n\ndef _all():\n    global _ZIP\n    return _ZIP.namelist()\n\"\"\"\n\n\ndef write_py_wrapper(base_64_bytes_blob, filename, tar_xz):\n    base64_str = base_64_bytes_blob.decode(\"ascii\")\n    with open(filename, \"w\") as f:\n        f.write(\n            _FILE_TEMPLATE.format(\n                extra_imports=_TAR_XZ_IMPORTS if tar_xz else _ZIP_IMPORTS,\n                base64_blob=base64_str,\n                compression_specific_api=_TAR_XZ_API if tar_xz else _ZIP_API,\n            )\n        )\n\n\ndef main():\n    args = parse_args()\n    base64_blob = compress_and_base_64(args.inputs, args.tarxz)\n    write_py_wrapper(base64_blob, args.output, args.tarxz)\n\n\nif __name__ == \"__main__\":\n    logging.basicConfig(level=logging.INFO)\n    main()\n"
        },
        {
          "name": "gen_simple_module.py",
          "type": "blob",
          "size": 4.21875,
          "content": "#!/usr/bin/env python3\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport argparse\nimport base64\nimport io\nimport logging\nimport os\nimport zipfile\nfrom collections import namedtuple\n\n\ntry:\n    import lzma  # noqa(F401)\n    import tarfile\n\n    has_tar_lzma = True\nexcept ImportError:\n    has_tar_lzma = False\n\n\nArgs = namedtuple(\"Args\", [\"inputs\", \"output\", \"tarxz\"])\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser(\n        description=\"Generate simple module with the given file\"\n    )\n\n    parser.add_argument(\"args\", nargs=\"+\", help=\"name=filename list\")\n    parser.add_argument(\n        \"-o\",\n        \"--out\",\n        nargs=1,\n        type=os.path.realpath,\n        help=\"Generated python wrapper\",\n    )\n    parser.add_argument(\n        \"--force-zip\",\n        action=\"store_true\",\n        help=\"Force the use of zip, even when tar and lzma are available\",\n    )\n\n    args = parser.parse_args()\n\n    global has_tar_lzma\n    return Args(args.args, args.out[0], has_tar_lzma and not args.force_zip)\n\n\ndef compress_zip(inputs):\n    logging.info(\"Compressing as zip\")\n    buf = io.BytesIO(b\"\")\n    with zipfile.ZipFile(buf, \"w\") as zf:\n        for input in inputs:\n            logging.info(\"Adding %s\", input)\n            with open(input, \"rb\") as f:\n                zf.writestr(os.path.basename(input), f)\n    buf.seek(0)\n    return buf\n\n\ndef compress_tar_xz(inputs):\n    logging.info(\"Compressing as tar.xz\")\n    buf = io.BytesIO(b\"\")\n    tar = tarfile.open(fileobj=buf, mode=\"w:xz\")\n\n    for input in inputs:\n        logging.info(\"Adding %s\", input)\n        # In case the inputs are symlinks, it's better to work with the file\n        # object outright.\n        with open(input, \"rb\") as f:\n            info = tar.gettarinfo(arcname=os.path.basename(input), fileobj=f)\n            tar.addfile(info, fileobj=f)\n\n    tar.close()\n    buf.seek(0)\n    return buf\n\n\ndef compress_and_base_64(inputs, tar_xz):\n    with compress_tar_xz(inputs) if tar_xz else compress_zip(inputs) as buf:\n        return base64.b64encode(buf.getbuffer())\n\n\n_FILE_TEMPLATE = \"\"\"\n#!/usr/bin/env python3\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport base64\nimport io\nimport re\n\n{extra_imports}\n\n\n_BASE64BLOB = \"{base64_blob}\"\n\n\n{compression_specific_api}\n\n\n\"\"\"\n\n\n# def get_api_level_file(level):\n#     name = f\"framework_classes_api_{{level}}.txt\"\n#     return _load(name)\n\n\n# def get_api_levels():\n#     name_re = re.compile(r\"^framework_classes_api_(\\\\d+)\\\\.txt$\")\n#     return {{\n#         int(match.group(1)) for name in _all() for match in [name_re.match(name)] if match\n#     }}\n\n\n_TAR_XZ_IMPORTS = \"\"\"\nimport lzma  # noqa(F401)\nimport tarfile\n\"\"\"\n_TAR_XZ_API = \"\"\"\n_TAR = tarfile.open(mode=\"r:xz\", fileobj=io.BytesIO(base64.b64decode(_BASE64BLOB)))\n\n\ndef _load(name):\n    global _TAR\n    return _TAR.extractfile(name).read()\n\n\ndef _all():\n    global _TAR\n    return _TAR.getnames()\n\"\"\"\n\n\n_ZIP_IMPORTS = \"import zipfile\"\n_ZIP_API = \"\"\"\n_ZIP = zipfile.ZipFile(io.BytesIO(base64.b64decode(_BASE64BLOB)), \"r\")\n\n\ndef _load(name):\n    global _ZIP\n    return _ZIP.read(names)\n\n\ndef _all():\n    global _ZIP\n    return _ZIP.namelist()\n\"\"\"\n\n\ndef write_py_wrapper(base_64_bytes_blob, files, filename, tar_xz):\n    base64_str = base_64_bytes_blob.decode(\"ascii\")\n    with open(filename, \"w\") as f:\n        f.write(\n            _FILE_TEMPLATE.format(\n                extra_imports=_TAR_XZ_IMPORTS if tar_xz else _ZIP_IMPORTS,\n                base64_blob=base64_str,\n                compression_specific_api=_TAR_XZ_API if tar_xz else _ZIP_API,\n            )\n        )\n        for key, val in list(files.items()):\n            f.write(f'{key} = _load(\"{os.path.basename(val)}\")\\n')\n\n\ndef main():\n    args = parse_args()\n    files = {\n        key_val[: key_val.find(\"=\")]: key_val[key_val.find(\"=\") + 1 :]\n        for key_val in args.inputs\n    }\n    base64_blob = compress_and_base_64(list(files.values()), args.tarxz)\n    write_py_wrapper(base64_blob, files, args.output, args.tarxz)\n\n\nif __name__ == \"__main__\":\n    logging.basicConfig(level=logging.INFO)\n    main()\n"
        },
        {
          "name": "get_boost.sh",
          "type": "blob",
          "size": 1.009765625,
          "content": "#!/usr/bin/env bash\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nBOOST_VERSION=\"1.71.0\"\n\nBOOST_VERSION_UNDERSCORE=\"${BOOST_VERSION//./_}\"\nBOOST_FILE=\"boost_${BOOST_VERSION_UNDERSCORE}.tar.bz2\"\nBOOST_TAR_URL=\"https://boostorg.jfrog.io/artifactory/main/release/${BOOST_VERSION}/source/${BOOST_FILE}\"\nBOOST_CACHE_DIR=\"dl_cache/boost_cache\"\nBOOST_TAR_LOCAL=\"${BOOST_CACHE_DIR}/${BOOST_FILE}\"\nBOOST_DIR=\"boost_${BOOST_VERSION_UNDERSCORE}\"\n\nset -e\n\n# Check for cached artifacts.\nif [ ! -d \"$BOOST_CACHE_DIR\" ] ; then\n  mkdir -p \"$BOOST_CACHE_DIR\"\nfi\nif [ ! -f \"$BOOST_TAR_LOCAL\" ] ; then\n  echo \"Downloading Boost 1.71.0\"\n  wget \"$BOOST_TAR_URL\" -O \"$BOOST_TAR_LOCAL\"\nfi\n\nmkdir -p toolchain_install/boost\npushd toolchain_install/boost\n\ntar --bzip2 -xf \"../../$BOOST_TAR_LOCAL\"\n\ncd \"$BOOST_DIR\"\n./bootstrap.sh --with-libraries=filesystem,iostreams,program_options,regex,system,thread\n./b2 -j 4 -d0 install\n"
        },
        {
          "name": "java",
          "type": "tree",
          "content": null
        },
        {
          "name": "liblocator",
          "type": "tree",
          "content": null
        },
        {
          "name": "libredex",
          "type": "tree",
          "content": null
        },
        {
          "name": "libresource",
          "type": "tree",
          "content": null
        },
        {
          "name": "m4",
          "type": "tree",
          "content": null
        },
        {
          "name": "opt",
          "type": "tree",
          "content": null
        },
        {
          "name": "proto",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyredex",
          "type": "tree",
          "content": null
        },
        {
          "name": "redex.py",
          "type": "blob",
          "size": 51.6123046875,
          "content": "#!/usr/bin/env python3\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\n# pyre-strict\n\nimport argparse\nimport errno\nimport glob\nimport json\nimport logging\nimport os\nimport re\nimport shlex\nimport shutil\nimport subprocess\nimport sys\nimport tempfile\nimport timeit\nimport typing\nimport zipfile\nfrom os.path import abspath, dirname, getsize, isdir, isfile, join\nfrom pipes import quote\n\nimport pyredex.bintools as bintools\nimport pyredex.logger as logger\nfrom pyredex.buck import BuckConnectionScope, BuckPartScope\nfrom pyredex.packer import compress_entries, CompressionEntry, CompressionLevel\nfrom pyredex.unpacker import (\n    LibraryManager,\n    unpack_tar_xz,\n    UnpackManager,\n    ZipManager,\n    ZipReset,\n)\nfrom pyredex.utils import (\n    add_android_sdk_path,\n    add_tool_override,\n    argparse_yes_no_flag,\n    dex_glob,\n    find_zipalign,\n    get_android_sdk_path,\n    get_file_ext,\n    make_temp_dir,\n    omit_sdk_tool_discovery,\n    relocate_dexen_to_directories,\n    remove_comments,\n    sign_apk,\n    verify_dexes,\n    with_temp_cleanup,\n)\n\n\nIS_WINDOWS: bool = os.name == \"nt\"\nLOGGER: logging.Logger = logging.getLogger(\"redex\")  # Don't want __main__\n\n\n# Pyre helper.\nT = typing.TypeVar(\"T\")\n\n\ndef _assert_val(input: typing.Optional[T]) -> T:\n    assert input is not None\n    return input\n\n\ndef pgize(name: str) -> str:\n    return name.strip()[1:][:-1].replace(\"/\", \".\")\n\n\ndef dbg_prefix(dbg: str, src_root: typing.Optional[str] = None) -> typing.List[str]:\n    \"\"\"Return a debugger command prefix.\n\n    `dbg` is either \"gdb\" or \"lldb\", indicating which debugger to invoke.\n    `src_root` is an optional parameter that indicates the root directory that\n        all references to source files in debug information is relative to.\n\n    Returns a list of strings, which when prefixed onto a shell command\n        invocation will run that shell command under the debugger.\n    \"\"\"\n    assert dbg in [\"gdb\", \"lldb\"]\n\n    cmd = [dbg]\n    if src_root is not None:\n        if dbg == \"gdb\":\n            cmd += [\"-ex\", quote(\"directory %s\" % src_root)]\n        elif dbg == \"lldb\":\n            cmd += [\"-o\", f\"\"\"'settings set target.source-map \".\" {quote(src_root)}'\"\"\"]\n\n            # This makes assumptions about buck-out... I couldn't find an easy\n            # way to just get the config file beside this script...\n            dir_name = dirname(abspath(__file__))\n            dir_name = dirname(dir_name)\n            lldbinit_file = dir_name + \"/.lldbinit/.lldbinit\"\n            if isfile(lldbinit_file):\n                cmd += [\"-o\", f\"'command source {quote(lldbinit_file)}'\"]\n\n    DBG_END = {\"gdb\": \"--args\", \"lldb\": \"--\"}\n    cmd.append(DBG_END[dbg])\n\n    return cmd\n\n\ndef write_debugger_command(\n    dbg: str, src_root: typing.Optional[str], args: typing.Iterable[str]\n) -> str:\n    \"\"\"Write out a shell script that allows us to rerun redex-all under a debugger.\n\n    The choice of debugger is governed by `dbg` which can be either \"gdb\" or \"lldb\".\n    \"\"\"\n    assert not IS_WINDOWS  # It's a Linux/Mac script...\n    fd, script_name = tempfile.mkstemp(suffix=\".sh\", prefix=\"redex-{}-\".format(dbg))\n\n    # Parametrise redex binary.\n    args = [quote(a) for a in args]\n    redex_binary = args[0]\n    args[0] = '\"$REDEX_BINARY\"'\n\n    with os.fdopen(fd, \"w\") as f:\n        f.write(\"#! /usr/bin/env bash\\n\")\n        f.write('REDEX_BINARY=\"${REDEX_BINARY:-%s}\"\\n' % redex_binary)\n        f.write(\"cd %s || exit\\n\" % quote(os.getcwd()))\n        f.write(\" \".join(dbg_prefix(dbg, src_root)))\n        f.write(\" \")\n        f.write(\" \".join(args))\n        if not IS_WINDOWS:\n            os.fchmod(fd, 0o775)  # This is unsupported on windows.\n\n    return script_name\n\n\ndef add_extra_environment_args(env: typing.Dict[str, str]) -> None:\n    # If we haven't set MALLOC_CONF but we have requested to profile the memory\n    # of a specific pass, set some reasonable defaults\n    if \"MALLOC_PROFILE_PASS\" in env and \"MALLOC_CONF\" not in env:\n        env[\"MALLOC_CONF\"] = (\n            \"prof:true,prof_prefix:jeprof.out,prof_gdump:true,prof_active:false\"\n        )\n\n    # If we haven't set MALLOC_CONF, tune MALLOC_CONF for better perf\n    if \"MALLOC_CONF\" not in env:\n        env[\"MALLOC_CONF\"] = \"background_thread:true,metadata_thp:always,thp:always\"\n\n\ndef get_stop_pass_idx(passes_list: typing.Iterable[str], pass_name_and_num: str) -> int:\n    # Get the stop position\n    # pass_name_and num may be \"MyPass#0\", \"MyPass#3\" or \"MyPass\"\n    pass_name = pass_name_and_num\n    pass_order = 0\n    if \"#\" in pass_name_and_num:\n        pass_name, pass_order = pass_name_and_num.split(\"#\", 1)\n        try:\n            pass_order = int(pass_order)\n        except ValueError:\n            sys.exit(\n                \"Invalid stop-pass %s, should be in 'SomePass(#num)'\"\n                % pass_name_and_num\n            )\n    cur_order = 0\n    for _idx, _name in enumerate(passes_list):\n        if _name == pass_name:\n            if cur_order == pass_order:\n                return _idx\n            else:\n                cur_order += 1\n    sys.exit(\n        \"Invalid stop-pass %s. %d %s in passes_list\"\n        % (pass_name_and_num, cur_order, pass_name)\n    )\n\n\nclass ExceptionMessageFormatter:\n    def format_rerun_message(self, gdb_script_name: str, lldb_script_name: str) -> str:\n        return \"You can re-run it under gdb by running {} or under lldb by running {}\".format(\n            gdb_script_name, lldb_script_name\n        )\n\n    def format_message(\n        self,\n        err_out: typing.List[str],\n        default_error_msg: str,\n        gdb_script_name: str,\n        lldb_script_name: str,\n    ) -> str:\n        return \"{} {}\".format(\n            default_error_msg,\n            self.format_rerun_message(gdb_script_name, lldb_script_name),\n        )\n\n\nclass DexenSnapshot(object):\n    def __init__(self, dex_dir: str) -> None:\n        self.files_and_sizes: typing.Dict[str, int] = {\n            dexpath: os.path.getsize(dexpath) for dexpath in dex_glob(dex_dir)\n        }\n\n    def equals(self, other: \"DexenSnapshot\") -> bool:\n        return self.files_and_sizes == other.files_and_sizes\n\n\nclass State(object):\n    # This structure is only used for passing arguments between prepare_redex,\n    # launch_redex_binary, finalize_redex\n    def __init__(\n        self,\n        args: argparse.Namespace,\n        config_dict: typing.Dict[str, typing.Any],\n        debugger: typing.Optional[str],\n        dex_dir: str,\n        dexen: typing.List[str],\n        extracted_apk_dir: typing.Optional[str],\n        stop_pass_idx: int,\n        lib_manager: typing.Optional[LibraryManager],\n        unpack_manager: typing.Optional[UnpackManager],\n        zip_manager: typing.Optional[ZipManager],\n        dexen_initial_state: typing.Optional[DexenSnapshot],\n    ) -> None:\n        self.args = args\n        self.config_dict = config_dict\n        self.debugger = debugger\n        self.dex_dir = dex_dir\n        self.dexen = dexen\n        self.extracted_apk_dir = extracted_apk_dir\n        self.stop_pass_idx = stop_pass_idx\n        self.lib_manager = lib_manager\n        self.unpack_manager = unpack_manager\n        self.zip_manager = zip_manager\n        self.dexen_initial_state = dexen_initial_state\n\n\nclass RedexRunException(Exception):\n    def __init__(\n        self,\n        msg: str,\n        return_code: int,\n        abort_error: typing.Optional[str],\n        symbolized: typing.Optional[typing.List[str]],\n    ) -> None:\n        super().__init__(msg, return_code, abort_error, symbolized)\n        self.msg = msg\n        self.return_code = return_code\n        self.abort_error = abort_error\n        self.symbolized = symbolized\n\n    def __str__(self) -> str:\n        return self.msg\n\n\ndef run_redex_binary(\n    state: State,\n    exception_formatter: ExceptionMessageFormatter,\n    output_line_handler: typing.Optional[typing.Callable[[str], str]],\n) -> None:\n    if state.args.redex_binary is None:\n        state.args.redex_binary = shutil.which(\"redex-all\")\n\n    if state.args.redex_binary is None:\n        # __file__ can be /path/fb-redex.pex/redex.pyc\n        dir_name = dirname(abspath(__file__))\n        while not isdir(dir_name):\n            dir_name = dirname(dir_name)\n        state.args.redex_binary = join(dir_name, \"redex-all\")\n    if not isfile(state.args.redex_binary) or not os.access(\n        state.args.redex_binary, os.X_OK\n    ):\n        sys.exit(\n            \"redex-all is not found or is not executable: \" + state.args.redex_binary\n        )\n    LOGGER.debug(\"Running redex binary at %s\", state.args.redex_binary)\n\n    args: typing.List[str] = [state.args.redex_binary]\n\n    args += (\n        ([\"--dex-files\"] + state.args.dex_files)\n        if state.args.dex_files\n        else [\"--apkdir\", _assert_val(state.extracted_apk_dir)]\n    )\n    args += [\"--outdir\", state.dex_dir]\n\n    if state.args.cmd_prefix is not None:\n        args = shlex.split(state.args.cmd_prefix) + args\n\n    if state.args.config:\n        args += [\"--config\", state.args.config]\n\n    if state.args.verify_none_mode or state.config_dict.get(\"verify_none_mode\"):\n        args += [\"--verify-none-mode\"]\n\n    if state.args.is_art_build:\n        args += [\"--is-art-build\"]\n\n    if state.args.disable_dex_hasher:\n        args += [\"--disable-dex-hasher\"]\n\n    if state.args.enable_instrument_pass or state.config_dict.get(\n        \"enable_instrument_pass\"\n    ):\n        args += [\"--enable-instrument-pass\"]\n\n    if state.args.warn:\n        args += [\"--warn\", state.args.warn]\n    args += [\"--proguard-config=\" + x for x in state.args.proguard_configs]\n    if state.args.proguard_map:\n        args += [\"-Sproguard_map=\" + state.args.proguard_map]\n\n    args += [\"--jarpath=\" + x for x in state.args.jarpaths]\n    if state.args.printseeds:\n        args += [\"--printseeds=\" + state.args.printseeds]\n    if state.args.used_js_assets:\n        args += [\"--used-js-assets=\" + x for x in state.args.used_js_assets]\n    if state.args.arch:\n        args += [\"--arch=\" + state.args.arch]\n    if state.args.jni_summary:\n        args += [\"--jni-summary=\" + state.args.jni_summary]\n    args += [\"-S\" + x for x in state.args.passthru]\n    args += [\"-J\" + x for x in state.args.passthru_json]\n\n    if state.args.assert_abort:\n        args += [\"--assert-abort\", state.args.assert_abort]\n\n    args += state.dexen\n\n    # Stop before a pass and output intermediate dex and IR meta data.\n    if state.stop_pass_idx != -1:\n        args += [\n            \"--stop-pass\",\n            str(state.stop_pass_idx),\n            \"--output-ir\",\n            state.args.output_ir,\n        ]\n\n    debugger = state.debugger\n    prefix: typing.List[str] = (\n        dbg_prefix(debugger, state.args.debug_source_root)\n        if debugger is not None\n        else []\n    )\n\n    if state.args.debug:\n        print(\"cd %s && %s\" % (os.getcwd(), \" \".join(prefix + list(map(quote, args)))))\n        sys.exit()\n\n    env: typing.Dict[str, str] = os.environ.copy()\n    if state.args.quiet:\n        # Remove TRACE if it exists.\n        env.pop(\"TRACE\", None)\n    else:\n        # Check whether TRACE is set. If not, use \"TIME:1,PM:1\".\n        if \"TRACE\" not in env:\n            env[\"TRACE\"] = \"TIME:1,PM:1\"\n\n    env = logger.setup_trace_for_child(env)\n    logger.flush()\n\n    add_extra_environment_args(env)\n\n    def run() -> None:\n        with bintools.SigIntHandler() as sigint_handler:\n            trace_fp = logger.get_trace_file()\n            pass_fds = [trace_fp.fileno()] if trace_fp is not sys.stderr else []\n\n            proc, handler = bintools.run_and_stream_stderr(prefix + args, env, pass_fds)\n            sigint_handler.set_started(proc)\n\n            returncode, err_out = handler(output_line_handler)\n\n            sigint_handler.set_postprocessing()\n\n            if returncode == 0:\n                return\n\n            # Check for crash traces.\n            symbolized = bintools.maybe_addr2line(err_out)\n            if symbolized:\n                sys.stderr.write(\"\\n\")\n                sys.stderr.write(\"\\n\".join(symbolized))\n                sys.stderr.write(\"\\n\")\n                # Note: no need for store-logs, as this has failed anyways.\n\n            abort_error = None\n            if returncode == -6:  # SIGABRT\n                abort_error = bintools.find_abort_error(err_out)\n\n            default_error_msg = \"redex-all crashed with exit code {}!{}\".format(\n                returncode, \"\\n\" + abort_error if abort_error else \"\"\n            )\n            if IS_WINDOWS:\n                raise RuntimeError(default_error_msg)\n\n            gdb_script_name = write_debugger_command(\n                \"gdb\", state.args.debug_source_root, args\n            )\n            lldb_script_name = write_debugger_command(\n                \"lldb\", state.args.debug_source_root, args\n            )\n            msg = exception_formatter.format_message(\n                err_out,\n                default_error_msg,\n                gdb_script_name,\n                lldb_script_name,\n            )\n            raise RedexRunException(msg, returncode, abort_error, symbolized)\n\n    # Our CI system occasionally fails because it is trying to write the\n    # redex-all binary when this tries to run.  This shouldn't happen, and\n    # might be caused by a JVM bug.  Anyways, let's retry and hope it stops.\n    for i in range(5):\n        try:\n            run()\n            break\n        except OSError as err:\n            if err.errno == errno.ETXTBSY and i < 4:\n                continue\n            raise err\n\n\ndef zipalign(\n    unaligned_apk_path: str,\n    output_apk_path: str,\n    ignore_zipalign: bool,\n    page_align: bool,\n) -> None:\n    # Align zip and optionally perform good compression.\n    try:\n        zipalign = [\n            find_zipalign(),\n            \"4\",\n            unaligned_apk_path,\n            output_apk_path,\n        ]\n        if page_align:\n            zipalign.insert(1, \"-p\")\n\n        p = subprocess.Popen(zipalign, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n        out, _ = p.communicate()\n        if p.returncode == 0:\n            os.remove(unaligned_apk_path)\n            return\n        out_str = out.decode(sys.getfilesystemencoding())\n        raise RuntimeError(\"Failed to execute zipalign, output: {}\".format(out_str))\n    except OSError as e:\n        if e.errno == errno.ENOENT:\n            print(\"Couldn't find zipalign. See README.md to resolve this.\")\n        if not ignore_zipalign:\n            raise e\n        shutil.copy(unaligned_apk_path, output_apk_path)\n    except BaseException:\n        if not ignore_zipalign:\n            raise\n        shutil.copy(unaligned_apk_path, output_apk_path)\n    os.remove(unaligned_apk_path)\n\n\ndef align_and_sign_output_apk(\n    unaligned_apk_path: str,\n    output_apk_path: str,\n    reset_timestamps: bool,\n    sign: bool,\n    sign_v4: typing.Optional[bool],\n    keystore: str,\n    key_alias: str,\n    key_password: str,\n    ignore_zipalign: bool,\n    ignore_apksigner: bool,\n    page_align: bool,\n) -> None:\n    if isfile(output_apk_path):\n        os.remove(output_apk_path)\n\n    try:\n        os.makedirs(dirname(output_apk_path))\n    except OSError as e:\n        if e.errno != errno.EEXIST:\n            raise\n\n    zipalign(unaligned_apk_path, output_apk_path, ignore_zipalign, page_align)\n\n    if reset_timestamps:\n        ZipReset.reset_file(output_apk_path)\n\n    # Add new signature\n    if sign:\n        sign_apk(\n            sign_v4,\n            keystore,\n            key_password,\n            key_alias,\n            output_apk_path,\n            ignore_apksigner,\n        )\n\n\ndef copy_file_to_out_dir(\n    tmp: str, apk_output_path: str, name: str, human_name: str, out_name: str\n) -> None:\n    output_dir = os.path.dirname(apk_output_path)\n    output_path = os.path.join(output_dir, out_name)\n    tmp_path = tmp + \"/\" + name\n    if os.path.isfile(tmp_path):\n        shutil.copy2(tmp_path, output_path)\n        LOGGER.debug(\"Copying \" + human_name + \" map to output_dir: \" + output_path)\n    else:\n        LOGGER.debug(\"Skipping \" + human_name + \" copy, since no file found to copy\")\n\n\ndef copy_all_file_to_out_dir(\n    tmp: str, apk_output_path: str, ext: str, human_name: str\n) -> None:\n    tmp_path = tmp + \"/\" + ext\n    for file in glob.glob(tmp_path):\n        filename = os.path.basename(file)\n        copy_file_to_out_dir(\n            tmp, apk_output_path, filename, human_name + \" \" + filename, filename\n        )\n\n\ndef validate_args(args: argparse.Namespace) -> None:\n    if args.sign:\n\n        def raise_error(arg_name: str) -> None:\n            raise argparse.ArgumentTypeError(\n                \"Could not find a suitable default for --{} and no value \"\n                \"was provided.  This argument is required when --sign \"\n                \"is used\".format(arg_name)\n            )\n\n        if not args.keystore:\n            raise_error(\"keystore\")\n\n        if not args.keyalias:\n            raise_error(\"keyalias\")\n\n        if not args.keypass:\n            raise_error(\"keypass\")\n\n        if not isfile(args.keystore):\n            raise argparse.ArgumentTypeError(\n                f'Keystore path \"{args.keystore}\" is invalid.'\n            )\n\n\ndef arg_parser(\n    binary: typing.Optional[str] = None,\n    config: typing.Optional[str] = None,\n    keystore: typing.Optional[str] = None,\n    keyalias: typing.Optional[str] = None,\n    keypass: typing.Optional[str] = None,\n) -> argparse.ArgumentParser:\n    description = \"\"\"\nGiven an APK, produce a better APK!\n\n\"\"\"\n    parser = argparse.ArgumentParser(\n        formatter_class=argparse.RawDescriptionHelpFormatter, description=description\n    )\n\n    parser.add_argument(\"input_apk\", nargs=\"?\", help=\"Input APK file\")\n    parser.add_argument(\n        \"-o\",\n        \"--out\",\n        nargs=\"?\",\n        type=os.path.realpath,\n        default=\"redex-out.apk\",\n        help=\"Output APK file name (defaults to redex-out.apk)\",\n    )\n    parser.add_argument(\n        \"-j\",\n        \"--jarpath\",\n        dest=\"jarpaths\",\n        action=\"append\",\n        default=[],\n        help=\"Path to dependent library jar file\",\n    )\n\n    parser.add_argument(\n        \"--redex-binary\", nargs=\"?\", default=binary, help=\"Path to redex binary\"\n    )\n\n    parser.add_argument(\"-c\", \"--config\", default=config, help=\"Configuration file\")\n\n    argparse_yes_no_flag(parser, \"sign\", help=\"Sign the apk after optimizing it\")\n    argparse_yes_no_flag(\n        parser, \"sign-v4\", default=None, help=\"Sign the apk with v4 signing\"\n    )\n    parser.add_argument(\"-s\", \"--keystore\", nargs=\"?\", default=keystore)\n    parser.add_argument(\"-a\", \"--keyalias\", nargs=\"?\", default=keyalias)\n    parser.add_argument(\"-p\", \"--keypass\", nargs=\"?\", default=keypass)\n\n    parser.add_argument(\n        \"-u\",\n        \"--unpack-only\",\n        action=\"store_true\",\n        help=\"Unpack the apk and print the unpacked directories, don't \"\n        \"run any redex passes or repack the apk\",\n    )\n\n    parser.add_argument(\n        \"--unpack-dest\",\n        nargs=1,\n        help=\"Specify the base name of the destination directories; works with -u\",\n    )\n\n    parser.add_argument(\"-w\", \"--warn\", nargs=\"?\", help=\"Control verbosity of warnings\")\n\n    parser.add_argument(\n        \"-d\",\n        \"--debug\",\n        action=\"store_true\",\n        help=\"Unpack the apk and print the redex command line to run\",\n    )\n\n    parser.add_argument(\n        \"--dev\", action=\"store_true\", help=\"Optimize for development speed\"\n    )\n\n    parser.add_argument(\n        \"-m\",\n        \"--proguard-map\",\n        nargs=\"?\",\n        help=\"Path to proguard mapping.txt for deobfuscating names\",\n    )\n\n    parser.add_argument(\"--printseeds\", nargs=\"?\", help=\"File to print seeds to\")\n\n    parser.add_argument(\n        \"--used-js-assets\",\n        action=\"append\",\n        default=[],\n        help=\"A JSON file (or files) containing a list of resources used by JS\",\n    )\n\n    parser.add_argument(\n        \"-P\",\n        \"--proguard-config\",\n        dest=\"proguard_configs\",\n        action=\"append\",\n        default=[],\n        help=\"Path to proguard config\",\n    )\n\n    parser.add_argument(\n        \"-k\",\n        \"--keep\",\n        nargs=\"?\",\n        help=\"[deprecated] Path to file containing classes to keep\",\n    )\n\n    parser.add_argument(\n        \"-A\",\n        \"--arch\",\n        nargs=\"?\",\n        help='Architecture; one of arm/armv7/arm64/x86_64/x86\"',\n    )\n\n    parser.add_argument(\n        \"-S\",\n        dest=\"passthru\",\n        action=\"append\",\n        default=[],\n        help=\"Arguments passed through to redex\",\n    )\n    parser.add_argument(\n        \"-J\",\n        dest=\"passthru_json\",\n        action=\"append\",\n        default=[],\n        help=\"JSON-formatted arguments passed through to redex\",\n    )\n\n    parser.add_argument(\"--lldb\", action=\"store_true\", help=\"Run redex binary in lldb\")\n    parser.add_argument(\"--gdb\", action=\"store_true\", help=\"Run redex binary in gdb\")\n    parser.add_argument(\n        \"--ignore-zipalign\", action=\"store_true\", help=\"Ignore if zipalign is not found\"\n    )\n    parser.add_argument(\n        \"--ignore-apksigner\",\n        action=\"store_true\",\n        help=\"Ignore if apksigner is not found\",\n    )\n    parser.add_argument(\n        \"--verify-none-mode\",\n        action=\"store_true\",\n        help=\"Enable verify-none mode on redex\",\n    )\n    parser.add_argument(\n        \"--enable-instrument-pass\",\n        action=\"store_true\",\n        help=\"Enable InstrumentPass if any\",\n    )\n    parser.add_argument(\n        \"--is-art-build\",\n        action=\"store_true\",\n        help=\"States that this is an art only build\",\n    )\n    parser.add_argument(\n        \"--disable-dex-hasher\", action=\"store_true\", help=\"Disable DexHasher\"\n    )\n    parser.add_argument(\n        \"--page-align-libs\",\n        action=\"store_true\",\n        help=\"Preserve 4k page alignment for uncompressed libs\",\n    )\n\n    parser.add_argument(\n        \"--side-effect-summaries\", help=\"Side effect information for external methods\"\n    )\n\n    parser.add_argument(\n        \"--escape-summaries\", help=\"Escape information for external methods\"\n    )\n\n    parser.add_argument(\n        \"--stop-pass\",\n        default=\"\",\n        help=\"Stop before a pass and dump intermediate dex and IR meta data to a directory\",\n    )\n    parser.add_argument(\n        \"--output-ir\",\n        default=\"\",\n        help=\"Stop before stop_pass and dump intermediate dex and IR meta data to output_ir folder\",\n    )\n    parser.add_argument(\n        \"--debug-source-root\",\n        default=None,\n        nargs=\"?\",\n        help=\"Root directory that all references to source files in debug information is given relative to.\",\n    )\n\n    parser.add_argument(\n        \"--always-clean-up\",\n        action=\"store_true\",\n        help=\"Clean up temporaries even under failure\",\n    )\n\n    parser.add_argument(\"--cmd-prefix\", type=str, help=\"Prefix redex-all with\")\n\n    parser.add_argument(\n        \"--reset-zip-timestamps\",\n        action=\"store_true\",\n        help=\"Reset zip timestamps for deterministic output\",\n    )\n\n    parser.add_argument(\n        \"-q\",\n        \"--quiet\",\n        action=\"store_true\",\n        help=\"Do not be verbose, and override TRACE.\",\n    )\n\n    parser.add_argument(\"--android-sdk-path\", type=str, help=\"Path to Android SDK\")\n\n    parser.add_argument(\n        \"--suppress-android-jar-check\",\n        action=\"store_true\",\n        help=\"Do not look for an `android.jar` in the jar paths\",\n    )\n\n    parser.add_argument(\n        \"--omit-sdk-tool-discovery\",\n        action=\"store_true\",\n        help=\"Do not look attempt to search for SDK tools via path construction. Use the provided tool path overrides or the buck defaults\",\n    )\n\n    parser.add_argument(\"--addr2line\", help=\"Path to addr2line for crash symbolication\")\n\n    parser.add_argument(\n        \"--log-level\",\n        default=\"warning\",\n        help=\"Specify the python logging level\",\n    )\n    parser.add_argument(\n        \"--store-logs\", action=\"store_true\", help=\"Store all logs as meta\"\n    )\n\n    parser.add_argument(\n        \"--packed-profiles\",\n        type=str,\n        help=\"Path to packed profiles (expects tar.xz)\",\n    )\n\n    parser.add_argument(\n        \"--jni-summary\",\n        default=None,\n        type=str,\n        help=\"Path to JNI summary directory of json files.\",\n    )\n\n    parser.add_argument(\n        \"--verify-dexes\", type=str, help=\"Verify dex files with the supplied command\"\n    )\n\n    parser.add_argument(\n        \"--deep-data-enabled-interactions\",\n        default=None,\n        nargs=\"+\",\n        help=\"Override deep data enabled interactions\",\n    )\n\n    parser.add_argument(\n        \"--class-frequencies\",\n        type=str,\n        help=\"Path to a zipped file containing class frequencies for different interactions (expects .zip)\",\n    )\n\n    parser.add_argument(\"--assert-abort\", type=str, help=\"For testing only!\")\n\n    # Manual tool paths.\n\n    # Must be subclassed.\n    class ToolAction(argparse.Action):\n        def __init__(\n            self, tool_name, option_strings, dest, nargs=None, type=None, **kwargs\n        ):\n            if nargs is not None:\n                raise ValueError(\"nargs not allowed\")\n            if type is not None:\n                raise ValueError(\"type not allowed\")\n            super().__init__(option_strings, dest, type=str, **kwargs)\n            self.tool_name = tool_name\n\n        def __call__(self, parser, namespace, values, option_string=None):\n            if values is not None:\n                add_tool_override(self.tool_name, values)\n\n    class ZipAlignToolAction(ToolAction):\n        def __init__(self, **kwargs):\n            super().__init__(\"zipalign\", **kwargs)\n\n    parser.add_argument(\n        \"--zipalign-path\",\n        default=None,\n        action=ZipAlignToolAction,\n        help=\"Path to zipalign executable.\",\n    )\n\n    class ApkSignerToolAction(ToolAction):\n        def __init__(self, *args, **kwargs):\n            super().__init__(\"apksigner\", *args, **kwargs)\n\n    parser.add_argument(\n        \"--apksigner-path\",\n        default=None,\n        action=ApkSignerToolAction,\n        help=\"Path to apksigner executable.\",\n    )\n\n    # Passthrough mode.\n    parser.add_argument(\"--outdir\", type=str)\n    parser.add_argument(\"--dex-files\", nargs=\"+\", default=[])\n\n    parser.add_argument(\"--trace\", type=str)\n    parser.add_argument(\"--trace-file\", type=str)\n    # Relevant options to TraceClassAfterEachPass\n    parser.add_argument(\"--trace-class-name\", type=str)\n    parser.add_argument(\"--trace-method-name\", type=str)\n    parser.add_argument(\"--after-pass-trace-file\", type=str)\n\n    return parser\n\n\ndef _has_android_library_jars(pg_file: str) -> bool:\n    # We do not tokenize properly here. Minimum effort.\n    def _gen() -> typing.Generator[str, None, None]:\n        with open(pg_file, \"r\") as f:\n            for line in f:\n                yield line.strip()\n\n    gen = _gen()\n    for line in gen:\n        if line == \"-libraryjars\":\n            line = next(gen, \"a\")\n            parts = line.split(\":\")\n            for p in parts:\n                if p.endswith(\"android.jar\"):\n                    return True\n    return False\n\n\ndef _check_android_sdk_jar(args: argparse.Namespace) -> None:\n    if args.suppress_android_jar_check:\n        LOGGER.debug(\"No SDK jar check done\")\n        return\n\n    for jarpath in args.jarpaths:\n        if jarpath.endswith(\"android.jar\"):\n            LOGGER.debug(\"Found an SDK-looking jar: %s\", jarpath)\n            return\n\n    for pg_config in args.proguard_configs:\n        if _has_android_library_jars(pg_config):\n            LOGGER.debug(\"Found an SDK-looking jar in PG file %s\", pg_config)\n            return\n\n    # Check whether we can find and add one.\n    LOGGER.info(\n        \"No SDK jar found. If the detection is wrong, add `--suppress-android-jar-check`.\"\n    )\n    if args.omit_sdk_tool_discovery:\n        raise RuntimeError(\n            \"SDK tool discovery explicitly disabled, not attempting to locate SDK jar via SDK path. Failing due to no SDK jar provided.\"\n        )\n\n    LOGGER.info(\"Attempting to find an SDK-looking jar via SDK path\")\n\n    try:\n        sdk_path = get_android_sdk_path()\n        LOGGER.debug(\"SDK path is %s\", sdk_path)\n        platforms = join(sdk_path, \"platforms\")\n        if not os.path.exists(platforms):\n            raise RuntimeError(\"platforms directory does not exist\")\n        VERSION_REGEXP = r\"android-(\\d+)\"\n        version = max(\n            (\n                -1,\n                *[\n                    int(m.group(1))\n                    for d in os.listdir(platforms)\n                    for m in [re.match(VERSION_REGEXP, d)]\n                    if m\n                ],\n            ),\n        )\n        if version == -1:\n            raise RuntimeError(f\"No android jar directories found in {platforms}\")\n        jar_path = join(platforms, f\"android-{version}\", \"android.jar\")\n        if not os.path.exists(jar_path):\n            raise RuntimeError(f\"{jar_path} not found\")\n        LOGGER.info(\"Adding SDK jar path %s\", jar_path)\n        args.jarpaths.append(jar_path)\n    except BaseException as e:\n        LOGGER.warning(\"Could not find an SDK jar: %s\", e)\n\n\ndef _has_config_val(args: argparse.Namespace, path: typing.Iterable[str]) -> bool:\n    try:\n        with open(args.config, \"r\") as f:\n            json_obj = json.load(f)\n        for item in path:\n            if item not in json_obj:\n                LOGGER.debug(\"Did not find %s in %s\", item, json_obj)\n                return False\n            json_obj = json_obj[item]\n        return True\n    except BaseException as e:\n        LOGGER.error(\"%s\", e)\n        return False\n\n\ndef _check_shrinker_heuristics(args: argparse.Namespace) -> None:\n    arg_template = \"inliner.reg_alloc_random_forest=\"\n    for arg in args.passthru:\n        if arg.startswith(arg_template):\n            return\n\n    if _has_config_val(args, [\"inliner\", \"reg_alloc_random_forest\"]):\n        return\n\n    # Nothing found, check whether we have files embedded\n    LOGGER.info(\"No shrinking heuristic found, searching for default.\")\n    try:\n        from generated_shrinker_regalloc_heuristics import SHRINKER_HEURISTICS_FILE\n\n        LOGGER.info(\"Found embedded shrinker heuristics\")\n        tmp_dir = make_temp_dir(\"shrinker_heuristics\")\n        filename = os.path.join(tmp_dir, \"shrinker.forest\")\n        LOGGER.debug(\"Writing shrinker heuristics to %s\", filename)\n        with open(filename, \"wb\") as f:\n            f.write(SHRINKER_HEURISTICS_FILE)\n        arg = arg_template + filename\n        args.passthru.append(arg)\n    except ImportError:\n        LOGGER.info(\"No embedded files, please add manually!\")\n\n\ndef _check_android_sdk_api(args: argparse.Namespace) -> None:\n    arg_template = \"android_sdk_api_{level}_file=\"\n    arg_re = re.compile(\"^\" + arg_template.format(level=\"(\\\\d+)\"))\n    for arg in args.passthru:\n        if arg_re.match(arg):\n            return\n\n    # Nothing found, check whether we have files embedded\n    LOGGER.info(\"No android_sdk_api_XX_file parameters found.\")\n    try:\n        import generated_apilevels as ga\n\n        levels = ga.get_api_levels()\n        LOGGER.info(\"Found embedded API levels: %s\", levels)\n        api_dir = make_temp_dir(\"api_levels\")\n        LOGGER.debug(\"Writing API level files to %s\", api_dir)\n        for level in levels:\n            blob = ga.get_api_level_file(level)\n            filename = os.path.join(api_dir, f\"framework_classes_api_{level}.txt\")\n            with open(filename, \"wb\") as f:\n                f.write(blob)\n            arg = arg_template.format(level=level) + filename\n            args.passthru.append(arg)\n    except ImportError:\n        LOGGER.warning(\"No embedded files, please add manually!\")\n\n\ndef _handle_profiles(\n    args: argparse.Namespace, dd_enabled_interactions: typing.List[str]\n) -> None:\n    if not args.packed_profiles:\n        return\n\n    directory = make_temp_dir(\".redex_profiles\", False)\n    unpack_tar_xz(args.packed_profiles, directory)\n\n    method_profiles_paths = (\n        f'\"{f.path}\"'\n        for f in os.scandir(directory)\n        if f.is_file() and (\"method_stats\" in f.name or \"agg_stats\" in f.name)\n    )\n\n    if len(dd_enabled_interactions) > 0:\n        method_profiles_paths = [\n            mpp\n            for mpp in method_profiles_paths\n            if any([f\"_{i}_\" in mpp for i in dd_enabled_interactions])\n        ]\n\n    # Create input for method profiles.\n    method_profiles_str = \", \".join(method_profiles_paths)\n    if method_profiles_str:\n        LOGGER.debug(\"Found method profiles: %s\", method_profiles_str)\n        args.passthru_json.append(f\"agg_method_stats_files=[{method_profiles_str}]\")\n    else:\n        LOGGER.info(\"No method profiles found in %s\", args.packed_profiles)\n\n    # Create input for basic blocks.\n\n    block_profiles_paths = (\n        f\"{f.path}\"\n        for f in os.scandir(directory)\n        if f.is_file() and f.name.startswith(\"block_profiles_\")\n    )\n\n    if len(dd_enabled_interactions) > 0:\n        block_profiles_paths = [\n            bpp\n            for bpp in block_profiles_paths\n            if any([f\"_{i}_\" in bpp for i in dd_enabled_interactions])\n        ]\n\n    join_str = \";\" if IS_WINDOWS else \":\"\n    block_profiles_str = join_str.join(block_profiles_paths)\n    if block_profiles_str:\n        LOGGER.debug(\"Found block profiles: %s\", block_profiles_str)\n        # Assume there's at most one.\n        args.passthru.append(\n            f\"InsertSourceBlocksPass.profile_files={block_profiles_str}\"\n        )\n    else:\n        LOGGER.info(\"No block profiles found in %s\", args.packed_profiles)\n\n    coldstart_method_ordering_str = join_str.join(\n        f\"{f.path}\"\n        for f in os.scandir(directory)\n        if f.is_file() and f.name.startswith(\"coldstart_method_ordering\")\n    )\n    if coldstart_method_ordering_str:\n        LOGGER.debug(\"Found coldstart ordering: %s\", coldstart_method_ordering_str)\n        # Assume there's at most one.\n        args.passthru.append(f\"coldstart_methods_file={coldstart_method_ordering_str}\")\n    else:\n        LOGGER.info(\"No coldstart ordering found in %s\", args.packed_profiles)\n\n\ndef _handle_class_frequencies(args: argparse.Namespace) -> None:\n    if not args.class_frequencies:\n        return\n    class_freq_directory = make_temp_dir(\".redex_class_frequencies\", False)\n    with zipfile.ZipFile(args.class_frequencies, \"r\") as class_freq_zip:\n        class_freq_zip.extractall(path=class_freq_directory)\n\n    join_str = \";\" if IS_WINDOWS else \":\"\n    class_frequencies_str = join_str.join(\n        f\"{f.path}\"\n        for f in os.scandir(class_freq_directory)\n        if f.is_file() and f.name.startswith(\"class_freqs\")\n    )\n    if class_frequencies_str:\n        LOGGER.debug(\"Found class_frequencies: %s\", class_frequencies_str)\n        # Assume there's at most one.\n        args.passthru.append(f\"class_frequencies={class_frequencies_str}\")\n    else:\n        LOGGER.info(\"No class_frequencies found in %s\", args.class_frequencies)\n\n\ndef prepare_redex(args: argparse.Namespace) -> State:\n    LOGGER.debug(\"Preparing...\")\n    debug_mode = args.unpack_only or args.debug\n\n    if args.android_sdk_path:\n        add_android_sdk_path(args.android_sdk_path)\n\n    if args.omit_sdk_tool_discovery:\n        omit_sdk_tool_discovery()\n\n    if args.addr2line:\n        bintools.set_addr2line_path(args.addr2line)\n\n    # avoid accidentally mixing up file formats since we now support\n    # both apk files and Android bundle files\n    file_ext = get_file_ext(args.input_apk)\n    if not args.unpack_only:\n        assert file_ext == get_file_ext(args.out), (\n            'Input file extension (\"'\n            + file_ext\n            + '\") should be the same as output file extension (\"'\n            + get_file_ext(args.out)\n            + '\")'\n        )\n\n    extracted_apk_dir = None\n    dex_dir = None\n    if args.unpack_only and args.unpack_dest:\n        if args.unpack_dest[0] == \".\":\n            # Use APK's name\n            unpack_dir_basename = os.path.splitext(args.input_apk)[0]\n        else:\n            unpack_dir_basename = args.unpack_dest[0]\n        extracted_apk_dir = unpack_dir_basename + \".redex_extracted_apk\"\n        dex_dir = unpack_dir_basename + \".redex_dexen\"\n        try:\n            os.makedirs(extracted_apk_dir)\n            os.makedirs(dex_dir)\n            extracted_apk_dir = os.path.abspath(extracted_apk_dir)\n            dex_dir = os.path.abspath(dex_dir)\n        except OSError as e:\n            if e.errno == errno.EEXIST:\n                print(\"Error: destination directory already exists!\")\n                print(\"APK: \" + extracted_apk_dir)\n                print(\"DEX: \" + dex_dir)\n                sys.exit(1)\n            raise e\n\n    config = args.config\n    binary = args.redex_binary\n    LOGGER.debug(\"Using config %s\", config if config is not None else \"(default)\")\n    LOGGER.debug(\"Using binary %s\", binary if binary is not None else \"(default)\")\n\n    if args.unpack_only or config is None:\n        config_dict = {}\n    else:\n        with open(config) as config_file:\n            try:\n                lines = config_file.readlines()\n                config_dict = json.loads(remove_comments(lines))\n            except ValueError:\n                raise ValueError(\n                    \"Invalid JSON in ReDex config file: %s\" % config_file.name\n                )\n\n    # stop_pass_idx >= 0 means need stop before a pass and dump intermediate result\n    stop_pass_idx = -1\n    if args.stop_pass:\n        passes_list = config_dict.get(\"redex\", {}).get(\"passes\", [])\n        stop_pass_idx = get_stop_pass_idx(passes_list, args.stop_pass)\n        if not args.output_ir or isfile(args.output_ir):\n            print(\"Error: output_ir should be a directory\")\n            sys.exit(1)\n        try:\n            os.makedirs(args.output_ir)\n        except OSError as e:\n            if e.errno != errno.EEXIST:\n                raise e\n\n    with BuckPartScope(\"redex::Unpacking\", \"Unpacking Redex input\"):\n        with BuckPartScope(\"redex::UnpackApk\", \"Unpacking APK\"):\n            LOGGER.debug(\"Unpacking...\")\n            if not extracted_apk_dir:\n                extracted_apk_dir = make_temp_dir(\".redex_extracted_apk\", debug_mode)\n\n            directory = make_temp_dir(\".redex_unaligned\", False)\n            unaligned_apk_path = join(directory, \"redex-unaligned.\" + file_ext)\n            zip_manager = ZipManager(\n                args.input_apk, extracted_apk_dir, unaligned_apk_path\n            )\n            zip_manager.__enter__()\n\n            if not dex_dir:\n                dex_dir = make_temp_dir(\".redex_dexen\", debug_mode)\n\n            is_bundle = isfile(join(extracted_apk_dir, \"BundleConfig.pb\"))\n            unpack_manager = UnpackManager(\n                args.input_apk,\n                extracted_apk_dir,\n                dex_dir,\n                debug_mode=debug_mode,\n                fast_repackage=args.dev,\n                reset_timestamps=args.reset_zip_timestamps or args.dev,\n                is_bundle=is_bundle,\n            )\n            store_files = unpack_manager.__enter__()\n\n            lib_manager = LibraryManager(extracted_apk_dir, is_bundle=is_bundle)\n            lib_manager.__enter__()\n\n            if args.unpack_only:\n                print(\"APK: \" + extracted_apk_dir)\n                print(\"DEX: \" + dex_dir)\n                sys.exit()\n\n        # Unpack profiles, if they exist.\n        dd_enabled_interactions = (\n            args.deep_data_enabled_interactions\n            if args.deep_data_enabled_interactions\n            else config_dict.get(\"deep_data_enabled_interactions\", [])\n        )\n\n        _handle_profiles(args, dd_enabled_interactions)\n\n        _handle_class_frequencies(args)\n\n        LOGGER.debug(\"Moving contents to expected structure...\")\n        # Move each dex to a separate temporary directory to be operated by\n        # redex.\n        preserve_input_dexes = config_dict.get(\"preserve_input_dexes\")\n        dexen = relocate_dexen_to_directories(\n            dex_dir, dex_glob(dex_dir), preserve_input_dexes\n        )\n        dexen_initial_state = DexenSnapshot(dex_dir) if preserve_input_dexes else None\n\n        for store in sorted(store_files):\n            dexen.append(store)\n\n    if args.side_effect_summaries is not None:\n        args.passthru_json.append(\n            'ObjectSensitiveDcePass.side_effect_summaries=\"%s\"'\n            % args.side_effect_summaries\n        )\n\n    if args.escape_summaries is not None:\n        args.passthru_json.append(\n            'ObjectSensitiveDcePass.escape_summaries=\"%s\"' % args.escape_summaries\n        )\n\n    for key_value_str in args.passthru_json:\n        key_value = key_value_str.split(\"=\", 1)\n        if len(key_value) != 2:\n            LOGGER.debug(\n                \"Json Pass through %s is not valid. Split len: %s\",\n                key_value_str,\n                len(key_value),\n            )\n            continue\n        key = key_value[0]\n        value = key_value[1]\n        prev_value = config_dict.get(key, \"(No previous value)\")\n        LOGGER.debug(\n            \"Got Override %s = %s from %s. Previous %s\",\n            key,\n            value,\n            key_value_str,\n            prev_value,\n        )\n        config_dict[key] = json.loads(value)\n\n    # Scan for framework files. If not found, warn and add them if available.\n    _check_android_sdk_api(args)\n    # Check for shrinker heuristics.\n    _check_shrinker_heuristics(args)\n\n    # Scan for SDK jar provided. If not found, warn and add if available and allowed.\n    _check_android_sdk_jar(args)\n\n    LOGGER.debug(\"Running redex-all on %d dex files \", len(dexen))\n    if args.lldb:\n        debugger = \"lldb\"\n    elif args.gdb:\n        debugger = \"gdb\"\n    else:\n        debugger = None\n\n    return State(\n        args=args,\n        config_dict=config_dict,\n        debugger=debugger,\n        dex_dir=dex_dir,\n        dexen=dexen,\n        extracted_apk_dir=extracted_apk_dir,\n        stop_pass_idx=stop_pass_idx,\n        lib_manager=lib_manager,\n        unpack_manager=unpack_manager,\n        zip_manager=zip_manager,\n        dexen_initial_state=dexen_initial_state,\n    )\n\n\ndef _is_preserve_input_dexes(args: argparse.Namespace) -> bool:\n    if args.config is None:\n        return False\n\n    try:\n        with open(args.config) as config_file:\n            config_dict = json.load(config_file)\n\n        return config_dict.get(\"preserve_input_dexes\", False)\n    except Exception as e:\n        LOGGER.warning(\"Failed to read config file: %s\", e)\n    return False\n\n\ndef get_compression_list() -> typing.List[CompressionEntry]:\n    return [\n        CompressionEntry(\n            \"Redex Instrumentation Metadata\",\n            lambda args: args.enable_instrument_pass,\n            True,\n            [\"redex-instrument-metadata.txt\"],\n            [\n                \"redex-source-block-method-dictionary.csv\",\n                \"redex-source-blocks.csv\",\n                \"redex-source-block-idom-maps.csv\",\n                \"unique-idom-maps.txt\",\n            ],\n            \"redex-instrument-metadata.zip\",\n            \"redex-instrument-checksum.txt\",\n            CompressionLevel.BETTER,  # Not as time-sensitive.\n        ),\n        CompressionEntry(\n            \"Redex Class Sizes\",\n            lambda args: True,\n            True,\n            [],\n            [\"redex-class-sizes.csv\"],\n            None,\n            None,\n            CompressionLevel.DEFAULT,  # May be large.\n        ),\n        CompressionEntry(\n            \"Redex Stats\",\n            lambda args: True,\n            False,\n            [\"redex-stats.txt\"],\n            [],\n            None,\n            None,\n            CompressionLevel.BETTER,  # Usually small enough.\n        ),\n        CompressionEntry(\n            \"Redex Class Dependencies\",\n            lambda args: True,\n            True,\n            [],\n            [\"redex-class-dependencies.txt\"],\n            None,\n            None,\n            CompressionLevel.FAST,  # May be quite large.\n        ),\n        CompressionEntry(\n            \"Redex Unsafe Enums List\",\n            lambda args: True,\n            True,\n            [],\n            [\"redex-unsafe-enums.txt\"],\n            None,\n            None,\n            CompressionLevel.BETTER,  # Usually small enough.\n        ),\n        CompressionEntry(\n            \"Redex Accessed Proguard Rules\",\n            lambda args: True,\n            True,\n            [],\n            [\"redex-used-proguard-rules.txt\", \"redex-unused-proguard-rules.txt\"],\n            \"redex-accessed-proguard-rules.zip\",\n            None,\n            CompressionLevel.BETTER,  # Usually small enough.\n        ),\n        CompressionEntry(\n            \"Redex InsertSourceBlocksPass Unresolved Methods\",\n            lambda args: True,\n            True,\n            [],\n            [\"redex-isb-unresolved-methods.txt\"],\n            None,\n            None,\n            CompressionLevel.BETTER,  # Usually small enough.\n        ),\n        CompressionEntry(\n            \"Redex InsertSourceBlocksPass Failed Methods\",\n            lambda args: True,\n            True,\n            [],\n            [\"redex-isb-failed-methods.txt\"],\n            None,\n            None,\n            CompressionLevel.BETTER,  # Usually small enough.\n        ),\n        CompressionEntry(\n            \"Redex Full Rename Map\",\n            lambda args: not _is_preserve_input_dexes(args),\n            False,\n            [\"redex-full-rename-map.txt\"],\n            [],\n            \"redex-full-rename-map.txt.zst\",\n            None,\n            CompressionLevel.DEFAULT,  # Bit larger.\n        ),\n        CompressionEntry(\n            \"Redex Full Rename Map (JSON)\",\n            lambda args: not _is_preserve_input_dexes(args),\n            True,\n            [\"redex-full-rename-map.json\"],\n            [],\n            \"redex-full-rename-map.json.zst\",\n            None,\n            CompressionLevel.DEFAULT,  # Bit larger.\n        ),\n    ]\n\n\ndef finalize_redex(state: State) -> None:\n    if state.args.verify_dexes:\n        # with BuckPartScope(\"Redex::VerifyDexes\", \"Verifying output dex files\"):\n        verify_dexes(state.dex_dir, state.args.verify_dexes)\n\n    if state.dexen_initial_state is not None:\n        dexen_final_state = DexenSnapshot(state.dex_dir)\n        assert _assert_val(state.dexen_initial_state).equals(\n            dexen_final_state\n        ), \"initial state of preserved dex files does not match final state\"\n\n    _assert_val(state.lib_manager).__exit__(*sys.exc_info())\n\n    with BuckPartScope(\"Redex::OutputAPK\", \"Creating output APK\"):\n        with BuckPartScope(\"Redex::UnUnpack\", \"Undoing unpack\"):\n            _assert_val(state.unpack_manager).__exit__(*sys.exc_info())\n\n        meta_file_dir = join(state.dex_dir, \"meta/\")\n        assert os.path.isdir(meta_file_dir), (\n            \"meta dir %s does not exist\" % meta_file_dir\n        )\n\n        with BuckPartScope(\"Redex::ReZip\", \"Rezipping\"):\n            resource_file_mapping = join(meta_file_dir, \"resource-mapping.txt\")\n            if os.path.exists(resource_file_mapping):\n                _assert_val(state.zip_manager).set_resource_file_mapping(\n                    resource_file_mapping\n                )\n            _assert_val(state.zip_manager).__exit__(*sys.exc_info())\n\n        with BuckPartScope(\"Redex::AlignAndSign\", \"Aligning and signing\"):\n            align_and_sign_output_apk(\n                _assert_val(state.zip_manager).output_apk,\n                state.args.out,\n                # In dev mode, reset timestamps.\n                state.args.reset_zip_timestamps or state.args.dev,\n                state.args.sign,\n                state.args.sign_v4,\n                state.args.keystore,\n                state.args.keyalias,\n                state.args.keypass,\n                state.args.ignore_zipalign,\n                state.args.ignore_apksigner,\n                state.args.page_align_libs,\n            )\n\n    with BuckPartScope(\"Redex::OutputDir\", \"Arranging output dir\"):\n        compress_entries(\n            get_compression_list(),\n            meta_file_dir,\n            os.path.dirname(state.args.out),\n            state.args,\n        )\n\n        copy_all_file_to_out_dir(\n            meta_file_dir, state.args.out, \"*\", \"all redex generated artifacts\"\n        )\n\n        redex_stats_filename = state.config_dict.get(\"stats_output\", \"redex-stats.txt\")\n        redex_stats_file = join(dirname(meta_file_dir), redex_stats_filename)\n        if isfile(redex_stats_file):\n            with open(redex_stats_file, \"r\") as fr:\n                apk_input_size = getsize(state.args.input_apk)\n                apk_output_size = getsize(state.args.out)\n                redex_stats_json = json.load(fr)\n                redex_stats_json[\"input_stats\"][\"total_stats\"][\n                    \"num_compressed_apk_bytes\"\n                ] = apk_input_size\n                redex_stats_json[\"output_stats\"][\"total_stats\"][\n                    \"num_compressed_apk_bytes\"\n                ] = apk_output_size\n                update_redex_stats_file = join(\n                    dirname(state.args.out), redex_stats_filename\n                )\n                with open(update_redex_stats_file, \"w\") as fw:\n                    json.dump(redex_stats_json, fw)\n\n        # Write invocation file\n        with open(join(dirname(state.args.out), \"redex.py-invocation.txt\"), \"w\") as f:\n            print(\"%s\" % \" \".join(map(shlex.quote, sys.argv)), file=f)\n\n        copy_all_file_to_out_dir(\n            state.dex_dir, state.args.out, \"*.dot\", \"approximate shape graphs\"\n        )\n\n    # Write stored logs, if any.\n    logger.copy_store_logs_to(join(dirname(state.args.out), \"redex-log.txt.xz\"))\n\n\ndef _init_logging(level_str: str) -> None:\n    levels = {\n        \"critical\": logging.CRITICAL,\n        \"error\": logging.ERROR,\n        \"warn\": logging.WARNING,\n        \"warning\": logging.WARNING,\n        \"info\": logging.INFO,\n        \"debug\": logging.DEBUG,\n    }\n    level = levels[level_str]\n    logging.basicConfig(\n        level=level,\n        format=\"[%(levelname)-8s][%(asctime)-23s][%(name)-16s] %(message)s\",\n    )\n\n\ndef run_redex_passthrough(\n    args: argparse.Namespace,\n    exception_formatter: ExceptionMessageFormatter,\n    output_line_handler: typing.Optional[typing.Callable[[str], str]],\n) -> None:\n    assert args.outdir\n    assert args.dex_files\n\n    if args.addr2line:\n        bintools.set_addr2line_path(args.addr2line)\n\n    state = State(\n        args=args,\n        config_dict={},\n        debugger=None,\n        dex_dir=args.outdir,\n        dexen=[],\n        extracted_apk_dir=None,\n        stop_pass_idx=-1,\n        lib_manager=None,\n        unpack_manager=None,\n        zip_manager=None,\n        dexen_initial_state=None,\n    )\n    run_redex_binary(state, exception_formatter, output_line_handler)\n\n\ndef run_redex(\n    args: argparse.Namespace,\n    exception_formatter: typing.Optional[ExceptionMessageFormatter] = None,\n    output_line_handler: typing.Optional[typing.Callable[[str], str]] = None,\n) -> None:\n    with BuckConnectionScope():\n        if exception_formatter is None:\n            exception_formatter = ExceptionMessageFormatter()\n\n        if args.outdir or args.dex_files:\n            run_redex_passthrough(args, exception_formatter, output_line_handler)\n            return\n        else:\n            assert args.input_apk\n\n        with BuckPartScope(\"redex::Preparing\", \"Prepare to run redex\"):\n            state = prepare_redex(args)\n\n        with BuckPartScope(\"redex::Run redex-all\", \"Actually run redex binary\"):\n            run_redex_binary(state, exception_formatter, output_line_handler)\n\n        if args.stop_pass:\n            # Do not remove temp dirs\n            sys.exit()\n\n        finalize_redex(state)\n\n\ndef early_apply_args(args: argparse.Namespace) -> None:\n    # This is late, but hopefully early enough.\n    _init_logging(args.log_level)\n    if args.store_logs:\n        logger.setup_store_logs_temp_file()\n\n    # Translate these to the regular environment variables.\n    if args.trace:\n        os.environ[\"TRACE\"] = args.trace\n\n    if args.trace_file:\n        os.environ[\"TRACEFILE\"] = args.trace_file\n    if args.after_pass_trace_file:\n        os.environ[\"TRACE_CLASS_FILE\"] = args.after_pass_trace_file\n    if args.trace_class_name:\n        os.environ[\"TRACE_CLASS_NAME\"] = args.trace_class_name\n    if args.trace_method_name:\n        os.environ[\"TRACE_METHOD_NAME\"] = args.trace_method_name\n\n\nif __name__ == \"__main__\":\n    keys: typing.Dict[str, str] = {}\n    try:\n        keystore: str = join(os.environ[\"HOME\"], \".android\", \"debug.keystore\")\n        if isfile(keystore):\n            keys[\"keystore\"] = keystore\n            keys[\"keyalias\"] = \"androiddebugkey\"\n            keys[\"keypass\"] = \"android\"\n    except Exception:\n        pass\n    args: argparse.Namespace = arg_parser(**keys).parse_args()\n    early_apply_args(args)\n    validate_args(args)\n    with_temp_cleanup(lambda: run_redex(args), args.always_clean_up)\n"
        },
        {
          "name": "redex_gdb_hooks.py",
          "type": "blob",
          "size": 5.4267578125,
          "content": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\n# Defines GDB Pretty printing support for Redex\nimport gdb\n\n\nclass CallableBase(object):\n    def __init__(self, val, cmd, reftype):\n        self.val = val\n        self.cmd = cmd\n        self.reftype = reftype\n\n    def to_string(self):\n        if self.reftype and int(self.val) == 0:\n            return \"NULL\"\n        try:\n            res = gdb.execute(self.cmd, False, True)\n            # Print instead of returning the string to handle newlines\n            prncmd = 'call printf (\"%s\", \"{0}\\\\n\")'.format(\n                res.rstrip().replace('\"', \"\")\n            )\n            gdb.execute(prncmd, False, True)\n            return \"\"\n        except BaseException:\n            return \"\"\n\n\ndef Show(CallableBase):\n    def printer(val):\n        cmd = \"call('show({0} const)'({1}))\".format(type, val)\n        return CallableBase(val, cmd, False)\n\n    return printer\n\n\ndef ShowDeref(type):\n    def printer(val):\n        cmd = \"call('show({0} const*)'({1}))\".format(type, hex(val))\n        return CallableBase(val, cmd, True)\n\n    return printer\n\n\ndef ShowDerefAsRef(type):\n    def printer(val):\n        cmd = \"call('show({0} const&)'(*{1}))\".format(type, hex(val))\n        return CallableBase(val, cmd, True)\n\n    return printer\n\n\ndef ShowRef(type):\n    def printer(val):\n        val = val.address\n        cmd = \"call('show({0} const&)'(*{1}))\".format(type, hex(val))\n        return CallableBase(val, cmd, True)\n\n    return printer\n\n\ndef ShowDeobfuscated(type):\n    def printer(val):\n        cmd = \"call('show_deobfuscated({0} const*)'({1})\".format(type, hex(val))\n        return CallableBase(val, cmd, True)\n\n    return printer\n\n\npretty_printers_dict = {\n    # type.unqualified() doesnt seem to remove \"const\" qualifier.\n    \"cfg::ControlFlowGraph *\": ShowDerefAsRef(\"cfg::ControlFlowGraph\"),\n    \"const cfg::ControlFlowGraph *\": ShowDerefAsRef(\"cfg::ControlFlowGraph\"),\n    \"cfg::ControlFlowGraph &\": ShowRef(\"cfg::ControlFlowGraph\"),\n    \"const cfg::ControlFlowGraph &\": ShowRef(\"cfg::ControlFlowGraph\"),\n    \"cfg::Edge *\": ShowDeref(\"cfg::Edge\"),\n    \"const cfg::Edge *\": ShowDeref(\"cfg::Edge\"),\n    \"cfg::Block *\": ShowDeref(\"cfg::Block\"),\n    \"const cfg::Block *\": ShowDeref(\"cfg::Block\"),\n    \"DexAnnotation *\": ShowDeref(\"DexAnnotation\"),\n    \"const DexAnnotation *\": ShowDeref(\"DexAnnotation\"),\n    \"DexAnnotationDirectory *\": ShowDeref(\"DexAnnotationDirectory\"),\n    \"const DexAnnotationDirectory *\": ShowDeref(\"DexAnnotationDirectory\"),\n    \"DexAnnotationSet *\": ShowDeref(\"DexAnnotationSet\"),\n    \"const DexAnnotationSet *\": ShowDeref(\"DexAnnotationSet\"),\n    \"DexCode *\": ShowDeref(\"DexCode\"),\n    \"const DexCode *\": ShowDeref(\"DexCode\"),\n    \"DexFieldRef *\": ShowDeref(\"DexFieldRef\"),\n    \"cost DexFieldRef *\": ShowDeref(\"DexFieldRef\"),\n    \"DexField *\": ShowDeref(\"DexField\"),\n    \"const DexField *\": ShowDeref(\"DexField\"),\n    \"DexInstruction *\": ShowDeref(\"DexInstruction\"),\n    \"const DexInstruction *\": ShowDeref(\"DexInstruction\"),\n    \"DexOpcode\": Show(\"DexOpcode\"),\n    \"const DexOpcode\": Show(\"DexOpcode\"),\n    \"DexProto *\": ShowDeref(\"DexProto\"),\n    \"const DexProto *\": ShowDeref(\"DexProto\"),\n    \"DexString *\": ShowDeref(\"DexString\"),\n    \"const DexString *\": ShowDeref(\"DexString\"),\n    \"DexClass *\": ShowDeref(\"DexClass\"),\n    \"const DexClass *\": ShowDeref(\"DexClass\"),\n    \"DexMethodRef *\": ShowDeref(\"DexMethodRef\"),\n    \"const DexMethodRef *\": ShowDeref(\"DexMethodRef\"),\n    \"DexMethod *\": ShowDeref(\"DexMethod\"),\n    \"const DexMethod *\": ShowDeref(\"DexMethod\"),\n    \"DexType *\": ShowDeref(\"DexType\"),\n    \"const DexType *\": ShowDeref(\"DexType\"),\n    \"DexTypeList *\": ShowDeref(\"DexTypeList\"),\n    \"const DexTypeList *\": ShowDeref(\"DexTypeList\"),\n    \"IRInstruction *\": ShowDeref(\"IRInstruction\"),\n    \"const IRInstruction *\": ShowDeref(\"IRInstruction\"),\n    # TODO printing IRCode seems to crash gdb\n    # \"IRCode *\": ShowDeref(\"IRCode\"),\n    # \"const IRCode *\": ShowDeref(\"IRCode\"),\n    \"IRList *\": ShowDeref(\"IRList\"),\n    \"const IRList *\": ShowDeref(\"IRList\"),\n    \"IROpcode\": Show(\"IROpcode\"),\n    \"const IROpcode\": Show(\"IROpcode\"),\n}\n\n\ndef lookup_function(val):\n    if val is None or val.type is None:\n        return None\n    type = val.type\n    type_name = str(type.unqualified().strip_typedefs())\n    if type_name in pretty_printers_dict:\n        return pretty_printers_dict[type_name](val)\n    return None\n\n\ndef register_pretty_printer(obj):\n    if obj is None:\n        obj = gdb\n    obj.pretty_printers.insert(0, lookup_function)\n\n\ndef get_gdb_val_for_str(arg):\n    val = gdb.lookup_symbol(arg)\n    if not (val[0] is None):\n        frame = gdb.selected_frame()\n        return val[0].value(frame)\n    val = gdb.lookup_global_symbol(arg)\n    if not (val is None):\n        return val.value()\n    val = gdb.lookup_static_symbol(arg)\n    if not (val is None):\n        return val.value()\n    return None\n\n\nclass pp(gdb.Command):\n    def __init__(self):\n        gdb.Command.__init__(self, \"pp\", gdb.COMMAND_DATA, gdb.COMPLETE_SYMBOL, True)\n\n    def invoke(self, arg, from_tty):\n        val = get_gdb_val_for_str(arg)\n        printer = lookup_function(val)\n        if printer is None:\n            print(('No symbol \"{0}\" in current context'.format(arg)))\n            return\n        printer.to_string()\n\n\npp()\n# register_pretty_printer(gdb.current_objfile())\nprint(\"Redex pretty printers added.\")\nprint(\"Use custom command pp to print Redex symbols\")\n"
        },
        {
          "name": "selfextract.sh",
          "type": "blob",
          "size": 0.39453125,
          "content": "#!/bin/bash\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nexport TMPDIR=`mktemp -d /tmp/redex.XXXXXX`\nARCHIVE=`awk '/^__ARCHIVE_BELOW__/ { print NR + 1; exit 0 }' $0`\ntail -n+$ARCHIVE $0 | tar xz -C $TMPDIR\n\n$TMPDIR/redex.py $@\n\nrm -rf $TMPDIR\nexit 0\n\n__ARCHIVE_BELOW__\n"
        },
        {
          "name": "service",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup_oss_toolchain.sh",
          "type": "blob",
          "size": 4.259765625,
          "content": "#!/usr/bin/env bash\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\n# Set-up the dependencies necessary to build and run Redex on Ubuntu 16.04\n# Xenial, using APT for software management.\n\n# Exit on any command failing\nset -e\n\n# Root directory of repository\nROOT=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" >/dev/null 2>&1 && pwd)\"\n\n# Temporary directory for toolchain sources. Build artifacts will be\n# installed to /usr/local.\necho \"toolchain tmp = $TOOLCHAIN_TMP\"\nif [ -z \"$TOOLCHAIN_TMP\" ] ; then\n  TOOLCHAIN_TMP=$(mktemp -d 2>/dev/null)\n  trap 'rm -r $TOOLCHAIN_TMP' EXIT\nelse\n  echo \"Using toolchain tmp $TOOLCHAIN_TMP\"\n  mkdir -p \"$TOOLCHAIN_TMP\"\nfi\n\nif [ \"$1\" = \"32\" ] ; then\n  BITNESS=\"32\"\n  BITNESS_SUFFIX=\":i386\"\n  BITNESS_CONFIGURE=\"--host=i686-linux-gnu CFLAGS=-m32 CXXFLAGS=-m32 LDFLAGS=-m32\"\n  BITNESS_PKGS=\"gcc-multilib g++-multilib\"\n\n  echo \"Use --host=i686-linux-gnu CFLAGS=-m32 CXXFLAGS=-m32 LDFLAGS=-m32 for ./configure\"\nelse\n  BITNESS=\"64\"  # Assumption here, really means host-preferred arch.\n  BITNESS_SUFFIX=\":\"\n  BITNESS_CONFIGURE=\"\"\n  BITNESS_PKGS=\"\"\nfi\n\nDEB_UBUNTU_PKGS=\"unzip\"\n\nBOOST_DEB_UBUNTU_PKGS=\"libboost-filesystem-dev$BITNESS_SUFFIX\n                       libboost-iostreams-dev$BITNESS_SUFFIX\n                       libboost-program-options-dev$BITNESS_SUFFIX\n                       libboost-regex-dev$BITNESS_SUFFIX\n                       libboost-system-dev$BITNESS_SUFFIX\n                       libboost-thread-dev$BITNESS_SUFFIX\"\n\nPROTOBUF_DEB_UBUNTU_PKGS=\"libprotobuf-dev$BITNESS_SUFFIX\n                          protobuf-compiler\"\n\nfunction install_boost_from_source {\n    pushd \"$TOOLCHAIN_TMP\"\n    \"$ROOT\"/get_boost.sh\n}\n\nfunction install_protobuf3_from_source {\n    pushd \"$TOOLCHAIN_TMP\"\n    mkdir -p dl_cache/protobuf\n    if [ ! -f dl_cache/protobuf/protobuf-cpp-3.17.3.tar.gz ] ; then\n      wget https://github.com/protocolbuffers/protobuf/releases/download/v3.17.3/protobuf-cpp-3.17.3.tar.gz -O dl_cache/protobuf/protobuf-cpp-3.17.3.tar.gz\n    fi\n\n    mkdir -p toolchain_install/protobuf\n    pushd toolchain_install/protobuf\n    tar -xf ../../dl_cache/protobuf/protobuf-cpp-3.17.3.tar.gz --no-same-owner\n\n    pushd protobuf-3.17.3\n    ./configure $BITNESS_CONFIGURE\n    make -j 4 V=0 && make install V=0\n}\n\nfunction install_from_apt {\n  PKGS=\"autoconf\n        autoconf-archive\n        automake\n        binutils-dev\n        bzip2\n        ca-certificates\n        g++\n        libiberty-dev$BITNESS_SUFFIX\n        libjemalloc-dev$BITNESS_SUFFIX\n        libjsoncpp-dev$BITNESS_SUFFIX\n        liblz4-dev$BITNESS_SUFFIX\n        liblzma-dev$BITNESS_SUFFIX\n        libtool\n        make\n        wget\n        zlib1g-dev$BITNESS_SUFFIX $BITNESS_PKGS $*\"\n  apt-get update -q\n  apt-get install -q --no-install-recommends -y ${PKGS}\n}\n\nfunction handle_debian {\n    case $1 in\n        [1-9])\n            echo \"Unsupported Debian version $1\"\n            exit 1\n            ;;\n        10)\n            if [ \"$BITNESS\" == \"32\" ] ; then\n                echo \"32-bit compile unsupported because of boost\"\n                exit 1\n            fi\n            install_from_apt python3 ${DEB_UBUNTU_PKGS} ${PROTOBUF_DEB_UBUNTU_PKGS}\n            install_boost_from_source\n            ;;\n        *)\n            install_from_apt  python3 ${DEB_UBUNTU_PKGS} ${BOOST_DEB_UBUNTU_PKGS} ${PROTOBUF_DEB_UBUNTU_PKGS}\n            ;;\n    esac\n}\n\nfunction handle_ubuntu {\n    case $1 in\n        1[7-9]*)\n            if [ \"$BITNESS\" == \"32\" ] ; then\n                echo \"32-bit compile unsupported because of boost\"\n                exit 1\n            fi\n            install_from_apt python3 ${DEB_UBUNTU_PKGS}\n            install_boost_from_source\n            install_protobuf3_from_source\n            ;;\n        2*)\n            install_from_apt python3 ${DEB_UBUNTU_PKGS} ${BOOST_DEB_UBUNTU_PKGS} ${PROTOBUF_DEB_UBUNTU_PKGS}\n            ;;\n        *)\n            echo \"Unsupported Ubuntu version $1\"\n            exit 1\n            ;;\n    esac\n}\n\n# Read ID and VERSION_ID from /etc/os-release.\ndeclare $(grep -E '^(ID|VERSION_ID)=' /etc/os-release | xargs)\n\ncase $ID in\nubuntu)\n    handle_ubuntu \"$VERSION_ID\"\n    ;;\ndebian)\n    handle_debian \"$VERSION_ID\"\n    ;;\n*)\n    echo \"Unsupported OS $ID - $VERSION_ID\"\n    exit 1\nesac\n"
        },
        {
          "name": "shared",
          "type": "tree",
          "content": null
        },
        {
          "name": "sparta",
          "type": "tree",
          "content": null
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "util",
          "type": "tree",
          "content": null
        },
        {
          "name": "website",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}