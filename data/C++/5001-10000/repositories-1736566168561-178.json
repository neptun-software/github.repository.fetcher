{
  "metadata": {
    "timestamp": 1736566168561,
    "page": 178,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE4MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "google/gemma.cpp",
      "stars": 6083,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".bazelrc",
          "type": "blob",
          "size": 0.0224609375,
          "content": "common --enable_bzlmod\n"
        },
        {
          "name": ".bazelversion",
          "type": "blob",
          "size": 0.005859375,
          "content": "7.1.1\n"
        },
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 0.0341796875,
          "content": "Language: Cpp\nBasedOnStyle: Google\n"
        },
        {
          "name": ".clang-tidy",
          "type": "blob",
          "size": 8.84375,
          "content": "FormatStyle: file\nWarningsAsErrors: \"*\"\nChecks: \"-*,\\\n          abseil-*,\\\n          -abseil-string-find-startswith,\\\n          -abseil-string-find-str-contains,\\\n          bugprone-*,\\\n          -bugprone-argument-comment,\\\n          -bugprone-assert-side-effect,\\\n          -bugprone-bad-signal-to-kill-thread,\\\n          -bugprone-bool-pointer-implicit-conversion,\\\n          -bugprone-branch-clone,\\\n          -bugprone-copy-constructor-init,\\\n          -bugprone-dangling-handle,\\\n          -bugprone-dynamic-static-initializers,\\\n          -bugprone-easily-swappable-parameters,\\\n          -bugprone-exception-escape,\\\n          -bugprone-fold-init-type,\\\n          -bugprone-forward-declaration-namespace,\\\n          -bugprone-forwarding-reference-overload,\\\n          -bugprone-implicit-widening-of-multiplication-result,\\\n          -bugprone-inaccurate-erase,\\\n          -bugprone-incorrect-roundings,\\\n          -bugprone-infinite-loop,\\\n          -bugprone-integer-division,\\\n          -bugprone-lambda-function-name,\\\n          -bugprone-macro-parentheses,\\\n          -bugprone-macro-repeated-side-effects,\\\n          -bugprone-misplaced-operator-in-strlen-in-alloc,\\\n          -bugprone-misplaced-widening-cast,\\\n          -bugprone-move-forwarding-reference,\\\n          -bugprone-multiple-statement-macro,\\\n          -bugprone-narrowing-conversions,\\\n          -bugprone-no-escape,\\\n          -bugprone-not-null-terminated-result,\\\n          -bugprone-parent-virtual-call,\\\n          -bugprone-posix-return,\\\n          -bugprone-redundant-branch-condition,\\\n          -bugprone-reserved-identifier,\\\n          -bugprone-signal-handler,\\\n          -bugprone-signed-char-misuse,\\\n          -bugprone-sizeof-container,\\\n          -bugprone-sizeof-expression,\\\n          -bugprone-spuriously-wake-up-functions,\\\n          -bugprone-string-constructor,\\\n          -bugprone-string-integer-assignment,\\\n          -bugprone-string-literal-with-embedded-nul,\\\n          -bugprone-stringview-nullptr,\\\n          -bugprone-suspicious-enum-usage,\\\n          -bugprone-suspicious-include,\\\n          -bugprone-suspicious-memory-comparison,\\\n          -bugprone-suspicious-memset-usage,\\\n          -bugprone-suspicious-missing-comma,\\\n          -bugprone-suspicious-semicolon,\\\n          -bugprone-suspicious-string-compare,\\\n          -bugprone-swapped-arguments,\\\n          -bugprone-terminating-continue,\\\n          -bugprone-throw-keyword-missing,\\\n          -bugprone-too-small-loop-variable,\\\n          -bugprone-undefined-memory-manipulation,\\\n          -bugprone-undelegated-constructor,\\\n          -bugprone-unhandled-exception-at-new,\\\n          -bugprone-unhandled-self-assignment,\\\n          -bugprone-unused-raii,\\\n          -bugprone-unused-return-value,\\\n          -bugprone-use-after-move,\\\n          -bugprone-virtual-near-miss,\\\n          cert-*,\\\n          -cert-dcl16-c,\\\n          -cert-dcl21-cpp,\\\n          -cert-dcl37-c,\\\n          -cert-dcl50-cpp,\\\n          -cert-dcl51-cpp,\\\n          -cert-dcl54-cpp,\\\n          -cert-dcl58-cpp,\\\n          -cert-err33-c,\\\n          -cert-msc30-c,\\\n          -cert-msc32-c,\\\n          -cert-msc50-cpp,\\\n          -cert-msc51-cpp,\\\n          -cert-oop54-cpp,\\\n          -cert-str34-c,\\\n          -cert-str34-c,\\\n          -cert-str34-c,\\\n          -cert-str34-c,\\\n          -clang-analyzer-*,\\\n          concurrency-*,\\\n          -concurrency-mt-unsafe,\\\n          cppcoreguidelines-*,\\\n          -concurrency-mt-unsafe,\\\n          -cppcoreguidelines-avoid-c-arrays,\\\n          -cppcoreguidelines-avoid-const-or-ref-data-members,\\\n          -cppcoreguidelines-avoid-do-while,\\\n          -cppcoreguidelines-avoid-goto,\\\n          -cppcoreguidelines-avoid-magic-numbers,\\\n          -cppcoreguidelines-avoid-non-const-global-variables,\\\n          -cppcoreguidelines-c-copy-assignment-signature,\\\n          -cppcoreguidelines-explicit-virtual-functions,\\\n          -cppcoreguidelines-init-variables,\\\n          -cppcoreguidelines-interfaces-global-init,\\\n          -cppcoreguidelines-macro-usage,\\\n          -cppcoreguidelines-narrowing-conversions,\\\n          -cppcoreguidelines-no-malloc,\\\n          -cppcoreguidelines-non-private-member-variables-in-classes,\\\n          -cppcoreguidelines-owning-memory,\\\n          -cppcoreguidelines-prefer-member-initializer,\\\n          -cppcoreguidelines-pro-bounds-array-to-pointer-decay,\\\n          -cppcoreguidelines-pro-bounds-constant-array-index,\\\n          -cppcoreguidelines-pro-bounds-pointer-arithmetic,\\\n          -cppcoreguidelines-pro-type-const-cast,\\\n          -cppcoreguidelines-pro-type-member-init,\\\n          -cppcoreguidelines-pro-type-reinterpret-cast,\\\n          -cppcoreguidelines-pro-type-static-cast-downcast,\\\n          -cppcoreguidelines-pro-type-union-access,\\\n          -cppcoreguidelines-pro-type-vararg,\\\n          -cppcoreguidelines-slicing,\\\n          -cppcoreguidelines-special-member-functions,\\\n          -cppcoreguidelines-virtual-class-destructor,\\\n          google-*,\\\n          -google-default-arguments,\\\n          -google-explicit-constructor,\\\n          -google-readability-avoid-underscore-in-googletest-name,\\\n          -google-readability-braces-around-statements,\\\n          -google-readability-casting,\\\n          -google-readability-namespace-comments,\\\n          -google-readability-todo,\\\n          -google-runtime-int,\\\n          -google-upgrade-googletest-case,\\\n          misc-*,\\\n          -misc-misplaced-const,\\\n          -misc-new-delete-overloads,\\\n          -misc-non-private-member-variables-in-classes,\\\n          -misc-no-recursion,\\\n          -misc-redundant-expression,\\\n          -misc-uniqueptr-reset-release,\\\n          -misc-unconventional-assign-operator,\\\n          -misc-unused-parameters,\\\n          -misc-unused-using-decls,\\\n          modernize-*,\\\n          -modernize-avoid-c-arrays,\\\n          -modernize-concat-nested-namespaces,\\\n          -modernize-deprecated-headers,\\\n          -modernize-loop-convert,\\\n          -modernize-macro-to-enum,\\\n          -modernize-make-unique,\\\n          -modernize-pass-by-value,\\\n          -modernize-raw-string-literal,\\\n          -modernize-redundant-void-arg,\\\n          -modernize-return-braced-init-list,\\\n          -modernize-unary-static-assert,\\\n          -modernize-use-auto,\\\n          -modernize-use-bool-literals,\\\n          -modernize-use-default-member-init,\\\n          -modernize-use-emplace,\\\n          -modernize-use-equals-default,\\\n          -modernize-use-equals-delete,\\\n          -modernize-use-nodiscard,\\\n          -modernize-use-nullptr,\\\n          -modernize-use-override,\\\n          -modernize-use-trailing-return-type,\\\n          -modernize-use-transparent-functors,\\\n          -modernize-use-using,\\\n          performance-*,\\\n          -performance-faster-string-find,\\\n          -performance-for-range-copy,\\\n          -performance-inefficient-algorithm,\\\n          -performance-inefficient-string-concatenation,\\\n          -performance-inefficient-vector-operation,\\\n          -performance-move-const-arg,\\\n          -performance-no-automatic-move,\\\n          -performance-noexcept-move-constructor,\\\n          -performance-no-int-to-ptr,\\\n          -performance-trivially-destructible,\\\n          -performance-unnecessary-copy-initialization,\\\n          -performance-unnecessary-value-param,\\\n          portability-*,\\\n          readability-*,\\\n          -readability-avoid-const-params-in-decls,\\\n          -readability-braces-around-statements,\\\n          -readability-const-return-type,\\\n          -readability-container-data-pointer,\\\n          -readability-container-size-empty,\\\n          -readability-convert-member-functions-to-static,\\\n          -readability-else-after-return,\\\n          -readability-function-cognitive-complexity,\\\n          -readability-identifier-length,\\\n          -readability-implicit-bool-conversion,\\\n          -readability-inconsistent-declaration-parameter-name,\\\n          -readability-isolate-declaration,\\\n          -readability-magic-numbers,\\\n          -readability-make-member-function-const,\\\n          -readability-named-parameter,\\\n          -readability-non-const-parameter,\\\n          -readability-qualified-auto,\\\n          -readability-redundant-access-specifiers,\\\n          -readability-redundant-control-flow,\\\n          -readability-redundant-declaration,\\\n          -readability-redundant-member-init,\\\n          -readability-redundant-smartptr-get,\\\n          -readability-redundant-string-cstr,\\\n          -readability-redundant-string-init,\\\n          -readability-simplify-boolean-expr,\\\n          -readability-static-accessed-through-instance,\\\n          -readability-static-definition-in-anonymous-namespace,\\\n          -readability-suspicious-call-argument,\\\n          -readability-uppercase-literal-suffix,\\\n          -readability-use-anyofallof\n          \"\nCheckOptions:\n    - { key: readability-identifier-naming.ConstexprVariableCase,    value: CamelCase }\n    - { key: readability-identifier-naming.ConstexprVariablePrefix,  value: k         }\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0458984375,
          "content": ".cache/\nbazel-*/\nbuild-*/\npython/*/__pycache__\n"
        },
        {
          "name": ".vscode",
          "type": "tree",
          "content": null
        },
        {
          "name": "BUILD.bazel",
          "type": "blob",
          "size": 14.21484375,
          "content": "# gemma.cpp is a lightweight, standalone C++ inference engine for the Gemma\n# foundation models from Google.\n\nload(\"@rules_license//rules:license.bzl\", \"license\")\n\npackage(\n    default_applicable_licenses = [\n        \"//:license\",  # Placeholder comment, do not modify\n    ],\n    default_visibility = [\"//visibility:public\"],\n)\n\nlicense(\n    name = \"license\",\n    package_name = \"gemma_cpp\",\n)\n\n# Dual-licensed Apache 2 and 3-clause BSD.\nlicenses([\"notice\"])\n\nexports_files([\"LICENSE\"])\n\ncc_library(\n    name = \"basics\",\n    hdrs = [\"util/basics.h\"],\n    deps = [\n        \"@highway//:hwy\",\n    ],\n)\n\ncc_library(\n    name = \"threading\",\n    srcs = [\"util/threading.cc\"],\n    hdrs = [\"util/threading.h\"],\n    deps = [\n        \":basics\",\n        # Placeholder for container detection, do not remove\n        \"@highway//:hwy\",\n        \"@highway//:thread_pool\",\n        \"@highway//:topology\",\n    ],\n)\n\ncc_library(\n    name = \"allocator\",\n    srcs = [\"util/allocator.cc\"],\n    hdrs = [\"util/allocator.h\"],\n    deps = [\n        \":basics\",\n        \":threading\",\n        \"@highway//:hwy\",\n        \"@highway//:thread_pool\",\n    ],\n)\n\ncc_library(\n    name = \"test_util\",\n    hdrs = [\"util/test_util.h\"],\n    deps = [\n        \"@highway//:hwy\",\n        \"@highway//:hwy_test_util\",\n        \"@highway//:stats\",\n    ],\n)\n\ncc_test(\n    name = \"threading_test\",\n    srcs = [\"util/threading_test.cc\"],\n    deps = [\n        \":threading\",\n        \"@googletest//:gtest_main\",\n        \"@highway//:hwy\",\n        \"@highway//:hwy_test_util\",\n        \"@highway//:thread_pool\",\n    ],\n)\n\ncc_library(\n    name = \"ops\",\n    hdrs = [\n        \"ops/matmul.h\",\n    ],\n    textual_hdrs = [\n        \"ops/dot-inl.h\",\n        \"ops/sum-inl.h\",\n        \"ops/fp_arith-inl.h\",\n        \"ops/matmul-inl.h\",\n        \"ops/matvec-inl.h\",\n        \"ops/ops-inl.h\",\n    ],\n    deps = [\n        \":allocator\",\n        \":basics\",\n        \":threading\",\n        \"//compression:compress\",\n        \"@highway//:algo\",\n        \"@highway//:hwy\",\n        \"@highway//:math\",\n        \"@highway//:matvec\",\n        \"@highway//:profiler\",\n        \"@highway//:thread_pool\",\n    ],\n)\n\ncc_test(\n    name = \"dot_test\",\n    size = \"small\",\n    timeout = \"long\",\n    srcs = [\"ops/dot_test.cc\"],\n    local_defines = [\"HWY_IS_TEST\"],\n    # for test_suite.\n    tags = [\"hwy_ops_test\"],\n    deps = [\n        \":allocator\",\n        \":ops\",\n        \":test_util\",\n        \":threading\",\n        \"@googletest//:gtest_main\",  # buildcleaner: keep\n        \"//compression:compress\",\n        \"//compression:test_util\",\n        \"@highway//:hwy\",\n        \"@highway//:hwy_test_util\",\n        \"@highway//:nanobenchmark\",  #buildcleaner: keep\n        \"@highway//:profiler\",\n        \"@highway//:stats\",\n        \"@highway//:thread_pool\",\n    ],\n)\n\ncc_test(\n    name = \"ops_test\",\n    size = \"small\",\n    timeout = \"eternal\",\n    srcs = [\"ops/ops_test.cc\"],\n    local_defines = [\"HWY_IS_TEST\"],\n    # for test_suite.\n    tags = [\"hwy_ops_test\"],\n    deps = [\n        \":allocator\",\n        \":common\",\n        \":gemma_lib\",\n        \":ops\",\n        \":test_util\",\n        \"@googletest//:gtest_main\",  # buildcleaner: keep\n        \"//compression:compress\",\n        \"@highway//:hwy\",\n        \"@highway//:hwy_test_util\",\n        \"@highway//:nanobenchmark\",  #buildcleaner: keep\n    ],\n)\n\ncc_test(\n    name = \"gemma_matvec_test\",\n    size = \"small\",\n    timeout = \"long\",\n    srcs = [\"ops/gemma_matvec_test.cc\"],\n    local_defines = [\"HWY_IS_TEST\"],\n    # for test_suite.\n    tags = [\"hwy_ops_test\"],\n    deps = [\n        \":ops\",\n        \"@googletest//:gtest_main\",  # buildcleaner: keep\n        \"//compression:compress\",\n        \"@highway//:hwy\",\n        \"@highway//:hwy_test_util\",\n        \"@highway//:thread_pool\",\n    ],\n)\n\ncc_test(\n    name = \"matmul_unit_test\",\n    size = \"small\",\n    timeout = \"long\",\n    srcs = [\"ops/matmul_unit_test.cc\"],\n    local_defines = [\"HWY_IS_TEST\"],\n    # for test_suite.\n    tags = [\"hwy_ops_test\"],\n    deps = [\n        \":allocator\",\n        \":basics\",\n        \":ops\",\n        \":test_util\",\n        \"@googletest//:gtest_main\",  # buildcleaner: keep\n        \"//compression:compress\",\n        \"@highway//:hwy\",\n        \"@highway//:hwy_test_util\",\n    ],\n)\n\ncc_test(\n    name = \"matmul_test\",\n    size = \"small\",\n    timeout = \"long\",\n    srcs = [\"ops/matmul_test.cc\"],\n    local_defines = [\"HWY_IS_TEST\"],\n    # for test_suite.\n    tags = [\"hwy_ops_test\"],\n    deps = [\n        \":allocator\",\n        \":basics\",\n        \":ops\",\n        \":threading\",\n        \"@googletest//:gtest_main\",  # buildcleaner: keep\n        \"//compression:compress\",\n        \"@highway//:hwy\",\n        \"@highway//:hwy_test_util\",\n        \"@highway//:nanobenchmark\",\n        \"@highway//:thread_pool\",\n    ],\n)\n\ncc_test(\n    name = \"bench_matmul\",\n    size = \"small\",\n    timeout = \"long\",\n    srcs = [\"ops/bench_matmul.cc\"],\n    local_defines = [\"HWY_IS_TEST\"],\n    # for test_suite.\n    tags = [\"hwy_ops_test\"],\n    deps = [\n        \":allocator\",\n        \":basics\",\n        \":ops\",\n        \":threading\",\n        \"@googletest//:gtest_main\",  # buildcleaner: keep\n        \"//compression:compress\",\n        \"@highway//:hwy\",\n        \"@highway//:hwy_test_util\",\n        \"@highway//:nanobenchmark\",\n        \"@highway//:thread_pool\",\n    ],\n)\n\ncc_library(\n    name = \"common\",\n    srcs = [\n        \"gemma/common.cc\",\n        \"gemma/configs.cc\",\n        \"gemma/tensor_index.cc\",\n    ],\n    hdrs = [\n        \"gemma/common.h\",\n        \"gemma/configs.h\",\n        \"gemma/tensor_index.h\",\n    ],\n    deps = [\n        \"//compression:sfp\",\n        \"@highway//:hwy\",  # base.h\n        \"@highway//:thread_pool\",\n    ],\n)\n\ncc_test(\n    name = \"configs_test\",\n    srcs = [\"gemma/configs_test.cc\"],\n    deps = [\n        \":common\",\n        \"@googletest//:gtest_main\",\n    ],\n)\n\ncc_test(\n    name = \"tensor_index_test\",\n    srcs = [\"gemma/tensor_index_test.cc\"],\n    deps = [\n        \":basics\",\n        \":common\",\n        \":weights\",\n        \"@googletest//:gtest_main\",\n        \"//compression:compress\",\n        \"@highway//:hwy\",\n        \"@highway//:thread_pool\",\n    ],\n)\n\ncc_library(\n    name = \"weights\",\n    srcs = [\"gemma/weights.cc\"],\n    hdrs = [\"gemma/weights.h\"],\n    deps = [\n        \":common\",\n        \"//compression:blob_store\",\n        \"//compression:compress\",\n        \"//compression:io\",\n        \"@highway//:hwy\",\n        \"@highway//:profiler\",\n        \"@highway//:stats\",\n        \"@highway//:thread_pool\",\n    ],\n)\n\ncc_library(\n    name = \"tokenizer\",\n    srcs = [\"gemma/tokenizer.cc\"],\n    hdrs = [\"gemma/tokenizer.h\"],\n    deps = [\n        \":common\",\n        \"//compression:io\",\n        \"//compression:sfp\",\n        \"@highway//:hwy\",\n        \"@highway//:profiler\",\n        \"@com_google_sentencepiece//:sentencepiece_processor\",\n    ],\n)\n\ncc_library(\n    name = \"kv_cache\",\n    srcs = [\"gemma/kv_cache.cc\"],\n    hdrs = [\"gemma/kv_cache.h\"],\n    deps = [\n        \":common\",\n        \"@highway//:hwy\",\n    ],\n)\n\ncc_library(\n    name = \"gemma_lib\",\n    srcs = [\n        \"gemma/gemma.cc\",\n        \"gemma/instantiations/bf16.cc\",\n        \"gemma/instantiations/f32.cc\",\n        \"gemma/instantiations/nuq.cc\",\n        \"gemma/instantiations/sfp.cc\",\n    ],\n    hdrs = [\n        \"gemma/activations.h\",\n        \"gemma/gemma.h\",\n    ],\n    exec_properties = {\n        # Avoid linker OOMs when building with sanitizer instrumentation.\n        \"mem\": \"28g\",\n    },\n    textual_hdrs = [\n        \"gemma/gemma-inl.h\",\n        # Placeholder for internal file2, do not remove,\n    ],\n    deps = [\n        \":allocator\",\n        \":basics\",\n        \":common\",\n        \":ops\",\n        \":tokenizer\",\n        \":kv_cache\",\n        \":weights\",\n        \":threading\",\n        \"//compression:compress\",\n        \"//compression:io\",\n        \"//compression:sfp\",\n        \"//paligemma:image\",\n        \"@highway//:hwy\",\n        \"@highway//:bit_set\",\n        \"@highway//:nanobenchmark\",  # timer\n        \"@highway//:profiler\",\n        \"@highway//:thread_pool\",\n    ],\n)\n\ncc_library(\n    name = \"cross_entropy\",\n    srcs = [\"evals/cross_entropy.cc\"],\n    hdrs = [\"evals/cross_entropy.h\"],\n    deps = [\n        \":common\",\n        \":gemma_lib\",\n        \":ops\",\n        \"@highway//:hwy\",\n    ],\n)\n\ncc_library(\n    name = \"args\",\n    hdrs = [\"util/args.h\"],\n    deps = [\n        \":basics\",\n        \"//compression:io\",\n        \"@highway//:hwy\",\n    ],\n)\n\ncc_library(\n    name = \"app\",\n    hdrs = [\"util/app.h\"],\n    deps = [\n        \":args\",\n        \":basics\",\n        \":common\",\n        \":gemma_lib\",\n        \":ops\",\n        \":threading\",\n        \"//compression:io\",\n        \"@highway//:hwy\",\n    ],\n)\n\ncc_library(\n    name = \"benchmark_helper\",\n    srcs = [\"evals/benchmark_helper.cc\"],\n    hdrs = [\"evals/benchmark_helper.h\"],\n    deps = [\n        \":app\",\n        \":args\",\n        \":common\",\n        \":cross_entropy\",\n        \":gemma_lib\",\n        \":kv_cache\",\n        \":threading\",\n        # Placeholder for internal dep, do not remove.,\n        \"@google_benchmark//:benchmark\",\n        \"//compression:compress\",\n        \"@highway//:hwy\",\n        \"@highway//:nanobenchmark\",\n        \"@highway//:topology\",\n    ],\n)\n\ncc_test(\n    name = \"gemma_test\",\n    srcs = [\"evals/gemma_test.cc\"],\n    # Requires model files\n    tags = [\n        \"local\",\n        \"manual\",\n        \"no_tap\",\n    ],\n    deps = [\n        \":benchmark_helper\",\n        \":common\",\n        \":gemma_lib\",\n        \"@googletest//:gtest_main\",\n        \"@highway//:hwy\",\n        \"@highway//:hwy_test_util\",\n    ],\n)\n\ncc_test(\n    name = \"gemma_batch_bench\",\n    srcs = [\"evals/gemma_batch_bench.cc\"],\n    # Requires model files\n    tags = [\n        \"local\",\n        \"manual\",\n        \"no_tap\",\n    ],\n    deps = [\n        \":benchmark_helper\",\n        \":common\",\n        \":gemma_lib\",\n        \":tokenizer\",\n        \"@googletest//:gtest_main\",\n        \"@highway//:hwy\",\n        \"@highway//:hwy_test_util\",\n    ],\n)\n\ncc_binary(\n    name = \"gemma\",\n    srcs = [\"gemma/run.cc\"],\n    deps = [\n        \":app\",\n        \":args\",\n        \":benchmark_helper\",\n        \":common\",\n        \":gemma_lib\",\n        \":threading\",\n        # Placeholder for internal dep, do not remove.,\n        \"//compression:sfp\",\n        \"//paligemma:image\",\n        \"@highway//:hwy\",\n        \"@highway//:profiler\",\n        \"@highway//:thread_pool\",\n    ],\n)\n\ncc_binary(\n    name = \"single_benchmark\",\n    srcs = [\"evals/benchmark.cc\"],\n    deps = [\n        \":args\",\n        \":benchmark_helper\",\n        \":common\",\n        \":cross_entropy\",\n        \":gemma_lib\",\n        \"//compression:io\",\n        \"@highway//:hwy\",\n        \"@highway//:nanobenchmark\",\n        \"@nlohmann_json//:json\",\n    ],\n)\n\ncc_library(\n    name = \"benchmark_prompts\",\n    hdrs = [\"evals/prompts.h\"],\n    deps = [\"@highway//:hwy\"],\n)\n\ncc_binary(\n    name = \"benchmarks\",\n    srcs = [\n        \"evals/benchmarks.cc\",\n        \"evals/prompts.h\",\n    ],\n    deps = [\n        \":benchmark_helper\",\n        \":benchmark_prompts\",\n        \"@google_benchmark//:benchmark\",\n        \"@highway//:hwy\",  # base.h\n    ],\n)\n\ncc_binary(\n    name = \"debug_prompt\",\n    srcs = [\n        \"evals/debug_prompt.cc\",\n    ],\n    deps = [\n        \":args\",\n        \":benchmark_helper\",\n        \":gemma_lib\",\n        \"//compression:io\",\n        \"@highway//:hwy\",\n        \"@nlohmann_json//:json\",\n    ],\n)\n\ncc_binary(\n    name = \"gemma_mmlu\",\n    srcs = [\"evals/run_mmlu.cc\"],\n    deps = [\n        \":args\",\n        \":benchmark_helper\",\n        \":gemma_lib\",\n        \"//compression:io\",\n        \"@highway//:hwy\",\n        \"@highway//:profiler\",\n        \"@highway//:thread_pool\",\n        \"@nlohmann_json//:json\",\n    ],\n)\n\ncc_library(\n    name = \"prompt\",\n    hdrs = [\"backprop/prompt.h\"],\n    deps = [],\n)\n\ncc_library(\n    name = \"sampler\",\n    hdrs = [\"backprop/sampler.h\"],\n    deps = [\n        \":prompt\",\n    ],\n)\n\ncc_library(\n    name = \"backprop\",\n    srcs = [\n        \"backprop/backward.cc\",\n        \"backprop/forward.cc\",\n    ],\n    hdrs = [\n        \"backprop/activations.h\",\n        \"backprop/backward.h\",\n        \"backprop/forward.h\",\n    ],\n    textual_hdrs = [\n        \"backprop/backward-inl.h\",\n        \"backprop/forward-inl.h\",\n    ],\n    deps = [\n        \":allocator\",\n        \":common\",\n        \":ops\",\n        \":prompt\",\n        \":weights\",\n        \"//compression:compress\",\n        \"@highway//:dot\",\n        \"@highway//:hwy\",  # base.h\n        \"@highway//:thread_pool\",\n    ],\n)\n\ncc_library(\n    name = \"backprop_scalar\",\n    hdrs = [\n        \"backprop/activations.h\",\n        \"backprop/backward_scalar.h\",\n        \"backprop/common_scalar.h\",\n        \"backprop/forward_scalar.h\",\n    ],\n    deps = [\n        \":common\",\n        \":prompt\",\n        \":weights\",\n        \"//compression:compress\",\n        \"@highway//:hwy\",\n    ],\n)\n\ncc_test(\n    name = \"backward_scalar_test\",\n    size = \"large\",\n    srcs = [\n        \"backprop/backward_scalar_test.cc\",\n        \"backprop/test_util.h\",\n    ],\n    deps = [\n        \":backprop_scalar\",\n        \":common\",\n        \":prompt\",\n        \":sampler\",\n        \":weights\",\n        \"@googletest//:gtest_main\",\n        \"//compression:compress\",\n        \"@highway//:thread_pool\",\n    ],\n)\n\ncc_test(\n    name = \"backward_test\",\n    size = \"large\",\n    srcs = [\n        \"backprop/backward_test.cc\",\n        \"backprop/test_util.h\",\n    ],\n    exec_properties = {\n        # Avoid linker OOMs when building with sanitizer instrumentation.\n        \"mem\": \"28g\",\n    },\n    deps = [\n        \":allocator\",\n        \":backprop\",\n        \":backprop_scalar\",\n        \":common\",\n        \":gemma_lib\",\n        \":ops\",\n        \":prompt\",\n        \":sampler\",\n        \":weights\",\n        \"@googletest//:gtest_main\",\n        \"//compression:compress\",\n        \"@highway//:hwy\",\n        \"@highway//:hwy_test_util\",\n        \"@highway//:thread_pool\",\n    ],\n)\n\ncc_library(\n    name = \"optimizer\",\n    srcs = [\"backprop/optimizer.cc\"],\n    hdrs = [\"backprop/optimizer.h\"],\n    deps = [\n        \":allocator\",\n        \":common\",\n        \":weights\",\n        \"//compression:compress\",\n        \"@highway//:hwy\",\n        \"@highway//:thread_pool\",\n    ],\n)\n\ncc_test(\n    name = \"optimize_test\",\n    srcs = [\n        \"backprop/optimize_test.cc\",\n    ],\n    exec_properties = {\n        # Avoid linker OOMs when building with sanitizer instrumentation.\n        \"mem\": \"28g\",\n    },\n    deps = [\n        \":allocator\",\n        \":backprop\",\n        \":basics\",\n        \":common\",\n        \":gemma_lib\",\n        \":optimizer\",\n        \":prompt\",\n        \":sampler\",\n        \":threading\",\n        \":weights\",\n        \"@googletest//:gtest_main\",\n        \"//compression:sfp\",\n        \"@highway//:thread_pool\",\n    ],\n)\n"
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 6.08203125,
          "content": "# Copyright 2019 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\ncmake_minimum_required(VERSION 3.11)\n\ninclude(FetchContent)\n\nproject(gemma)\n\nset(CMAKE_CXX_STANDARD 17)\nset(CMAKE_CXX_STANDARD_REQUIRED ON)\nset(CMAKE_EXPORT_COMPILE_COMMANDS ON)\n\nFetchContent_Declare(highway GIT_REPOSITORY https://github.com/google/highway.git GIT_TAG 2b565e87d50b151660494624af532ac0b6076c79 EXCLUDE_FROM_ALL)\nFetchContent_MakeAvailable(highway)\n\n## Note: absl needs to be installed by sentencepiece. This will only happen if\n## cmake is invoked with -DSPM_ENABLE_SHARED=OFF and -DSPM_ABSL_PROVIDER=module\nFetchContent_Declare(sentencepiece GIT_REPOSITORY https://github.com/google/sentencepiece GIT_TAG 53de76561cfc149d3c01037f0595669ad32a5e7c EXCLUDE_FROM_ALL)\nFetchContent_MakeAvailable(sentencepiece)\n\nFetchContent_Declare(json GIT_REPOSITORY https://github.com/nlohmann/json.git GIT_TAG 9cca280a4d0ccf0c08f47a99aa71d1b0e52f8d03 EXCLUDE_FROM_ALL)\nFetchContent_MakeAvailable(json)\n\nset(BENCHMARK_ENABLE_TESTING OFF)\nset(BENCHMARK_ENABLE_GTEST_TESTS OFF)\n\nFetchContent_Declare(benchmark GIT_REPOSITORY https://github.com/google/benchmark.git GIT_TAG v1.8.2 EXCLUDE_FROM_ALL)\nFetchContent_MakeAvailable(benchmark)\n\nset(SOURCES\n  compression/blob_store.cc\n  compression/blob_store.h\n  compression/compress.cc\n  compression/compress.h\n  compression/compress-inl.h\n  compression/fields.cc\n  compression/fields.h\n  compression/io_win.cc\n  compression/io.cc\n  compression/io.h\n  compression/nuq-inl.h\n  compression/sfp-inl.h\n  compression/shared.h\n  compression/test_util-inl.h\n  backprop/activations.h\n  backprop/backward.cc\n  backprop/backward.h\n  backprop/backward-inl.h\n  backprop/backward_scalar.h\n  backprop/common_scalar.h\n  backprop/forward.cc\n  backprop/forward.h\n  backprop/forward-inl.h\n  backprop/forward_scalar.h\n  backprop/optimizer.cc\n  backprop/optimizer.h\n  evals/benchmark_helper.cc\n  evals/benchmark_helper.h\n  evals/cross_entropy.cc\n  evals/cross_entropy.h\n  gemma/activations.h\n  gemma/common.cc\n  gemma/common.h\n  gemma/configs.cc\n  gemma/configs.h\n  gemma/gemma-inl.h\n  gemma/gemma.cc\n  gemma/gemma.h\n  gemma/instantiations/bf16.cc\n  gemma/instantiations/f32.cc\n  gemma/instantiations/nuq.cc\n  gemma/instantiations/sfp.cc\n  gemma/kv_cache.cc\n  gemma/kv_cache.h\n  gemma/tensor_index.cc\n  gemma/tensor_index.h\n  gemma/tokenizer.cc\n  gemma/tokenizer.h\n  gemma/weights.cc\n  gemma/weights.h\n  ops/dot-inl.h\n  ops/matmul-inl.h\n  ops/matvec-inl.h\n  ops/ops-inl.h\n  ops/sum-inl.h\n  paligemma/image.cc\n  paligemma/image.h\n  util/allocator.cc\n  util/allocator.h\n  util/app.h\n  util/args.h\n  util/basics.h\n  util/test_util.h\n  util/threading.cc\n  util/threading.h\n  )\n\nif(NOT CMAKE_BUILD_TYPE)\n    set(CMAKE_BUILD_TYPE \"Release\")\nendif()\n\nFetchContent_GetProperties(sentencepiece)\n\n## Library Target\n\nadd_library(libgemma ${SOURCES})\nset_property(TARGET libgemma PROPERTY CXX_STANDARD 17)\nset_target_properties(libgemma PROPERTIES PREFIX \"\")\nset_property(TARGET libgemma PROPERTY POSITION_INDEPENDENT_CODE ON)\ntarget_include_directories(libgemma PUBLIC ./)\ntarget_link_libraries(libgemma hwy hwy_contrib sentencepiece-static)\ntarget_include_directories(libgemma PUBLIC ${sentencepiece_SOURCE_DIR})\ntarget_compile_definitions(libgemma PRIVATE $<$<PLATFORM_ID:Windows>:_CRT_SECURE_NO_WARNINGS NOMINMAX>)\ntarget_compile_options(libgemma PRIVATE $<$<PLATFORM_ID:Windows>:-Wno-deprecated-declarations>)\ninstall(TARGETS libgemma DESTINATION lib)\n\n# Executable Target\n\nadd_executable(gemma gemma/run.cc)\ntarget_link_libraries(gemma libgemma hwy hwy_contrib)\ninstall(TARGETS gemma DESTINATION bin)\n\nadd_executable(single_benchmark evals/benchmark.cc)\ntarget_link_libraries(single_benchmark libgemma hwy hwy_contrib nlohmann_json::nlohmann_json)\n\nadd_executable(gemma_batch_bench evals/gemma_batch_bench.cc)\ntarget_link_libraries(gemma_batch_bench libgemma hwy hwy_contrib nlohmann_json::nlohmann_json)\n\nadd_executable(benchmarks evals/benchmarks.cc)\ntarget_link_libraries(benchmarks libgemma hwy hwy_contrib nlohmann_json::nlohmann_json benchmark)\n\nadd_executable(debug_prompt evals/debug_prompt.cc)\ntarget_link_libraries(debug_prompt libgemma hwy hwy_contrib nlohmann_json::nlohmann_json)\n\n## Tests\nset(GEMMA_ENABLE_TESTS OFF CACHE BOOL \"Enable Gemma tests\")\nif (GEMMA_ENABLE_TESTS)\n\nenable_testing()\ninclude(GoogleTest)\n\nset(GEMMA_TEST_FILES\n  backprop/backward_scalar_test.cc\n  backprop/backward_test.cc\n  backprop/optimize_test.cc\n  compression/blob_store_test.cc\n  compression/compress_test.cc\n  compression/distortion_test.cc\n  compression/fields_test.cc\n  compression/nuq_test.cc\n  compression/sfp_test.cc\n  evals/gemma_test.cc\n  gemma/tensor_index_test.cc\n  ops/bench_matmul.cc\n  ops/dot_test.cc\n  ops/gemma_matvec_test.cc\n  ops/matmul_test.cc\n  ops/matmul_unit_test.cc\n  ops/ops_test.cc\n  paligemma/image_test.cc\n  paligemma/paligemma_test.cc\n  util/threading_test.cc\n)\n\nforeach (TESTFILE IN LISTS GEMMA_TEST_FILES)\n  # The TESTNAME is the name without the extension or directory.\n  get_filename_component(TESTNAME ${TESTFILE} NAME_WE)\n  add_executable(${TESTNAME} ${TESTFILE})\n  # Test all targets, not just the best/baseline. This changes the default\n  # policy to all-attainable; note that setting -DHWY_COMPILE_* directly can\n  # cause compile errors because only one may be set, and other CMakeLists.txt\n  # that include us may set them.\n  target_compile_options(${TESTNAME} PRIVATE -DHWY_IS_TEST=1)\n\n  target_link_libraries(${TESTNAME} PRIVATE libgemma GTest::gtest_main hwy hwy_contrib hwy_test)\n\n  gtest_discover_tests(${TESTNAME})\nendforeach ()\nendif()  # GEMMA_ENABLE_TESTS\n\n## Tools\n\nadd_executable(compress_weights compression/compress_weights.cc)\ntarget_link_libraries(compress_weights libgemma hwy hwy_contrib)\n"
        },
        {
          "name": "CMakePresets.json",
          "type": "blob",
          "size": 1.359375,
          "content": "{\n    \"version\": 3,\n    \"cmakeMinimumRequired\": {\n      \"major\": 3,\n      \"minor\": 11,\n      \"patch\": 0\n    },\n    \"configurePresets\": [\n      {\n        \"name\": \"__defaults__\",\n        \"hidden\": true,\n        \"binaryDir\": \"${sourceDir}/build\"\n      },\n      {\n        \"name\": \"make\",\n        \"inherits\": \"__defaults__\",\n        \"displayName\": \"Make\",\n        \"description\": \"Unix Makefiles\",\n        \"generator\": \"Unix Makefiles\",\n        \"binaryDir\": \"${sourceDir}/build\"\n      },\n      {\n        \"name\": \"windows\",\n        \"inherits\": \"__defaults__\",\n        \"displayName\": \"Windows\",\n        \"description\": \"Visual Studio 2022 with Clang/LLVM frontend\",\n        \"generator\": \"Visual Studio 17 2022\",\n        \"toolset\": \"ClangCL\",\n        \"condition\": {\n          \"type\": \"equals\",\n          \"lhs\": \"${hostSystemName}\",\n          \"rhs\": \"Windows\"\n        }\n      }\n    ],\n    \"buildPresets\": [\n      {\n        \"name\": \"__defaults__\",\n        \"hidden\": true,\n        \"targets\": [\n            \"gemma\",\n            \"libgemma\"\n        ]\n      },\n      {\n        \"name\": \"make\",\n        \"inherits\": \"__defaults__\",\n        \"displayName\": \"Unix Makefiles\",\n        \"configurePreset\": \"make\"\n      },\n      {\n        \"name\": \"windows\",\n        \"inherits\": \"__defaults__\",\n        \"displayName\": \"Windows\",\n        \"configuration\": \"Release\",\n        \"configurePreset\": \"windows\"\n      }\n    ]\n  }\n"
        },
        {
          "name": "DEVELOPERS.md",
          "type": "blob",
          "size": 9.7216796875,
          "content": "# Developer Notes\n\n## Motivation: A Minimalist C++ LLM Runtime for Research and Experimentation\n\nIn the past, neural network inference has been similar to a simple, opaque,\nstateless function function with a single input and output. By contrast,\nfoundation model runtimes are better considered as systems with multiple forms\nof state, subsystems, and heterogeneous inputs and outputs. They are often\nintegrated with a wide variety of other systems that have their own resources\n(e.g. RAG and tools) and potentially interact with an external environment. They\nhave become compute engines to embed proximal tasks and goals within expansively\nbroad, general-purpose world models.\n\nWith this in mind, we believe that developing an experimental runtime that is\nflexible and approachable will allow us to explore the design space of co-design\nbetween high level model concerns and low-level runtime computation.\n\n## Design Priorities\n\nGiven these motivations, we propose the following priorities for\nmaking decisions regarding the direction and design of the codebase.\n\n**Maximize Leverage with a Narrow Scope.** We focus on direct implementations of\nfoundation models like Gemma. This allows us to focus effort on bottlenecks of\nspecific models. We are willing to trade off generality to keep implementation\ncode relatively simple and readable at all layers of the stack, achieve good\nperformance, and maintain the velocity of a small team.\n\n**Data Oriented Design.** Follow data oriented design principles where possible\nto minimize unnecessary performance pessimization. It's best to apply these\noptimizations during the initial design, or when refactoring a subcomponent. The\nfirst step is to think in terms of batches or tuples of plain old data (POD)\ntypes: separate arrays, instead of an array of structs. The second is to\nde-emphasize control flow (if statements, virtual functions and class\nhierarchies). The third step is to know intrinsic properties of data and bake\nthat into the layout and algorithm.\n\n**Prioritize Small Batch Latency** Since production serving solutions are\navailable for large-scale serving powered by accelerators and optimizing for\nthroughput, this project focuses on the possibilities of local, interactive use\nof foundation models. Although throughput remains important, low latency and\nsmall batch sizes are prioritized, other things being equal.\n\n**Maintain a Portable Baseline** Our starting point is a portable CPU SIMD (via\n[highway](https://github.com/google/highway)). We expect to add accelerator and\nhybrid CPU/GPU support in the future, but the project should continue to allow\nbuilds using this portable baseline. This ensures that research-oriented and\nexperimental runtimes and hardware platforms will have a minimum viable option\nto run Gemma even if specialized production-ready deployment paths are not\navailable.\n\n## Code Organization\n\nThe implementation code is roughly split into 4 layers, from high to low level:\n\n1.  Frontends (`run.cc`) - Either interactive interfaces or automation\n    orchestration that interacts. Frontend code implements a use case objective\n    in terms of invocations to model inference and generation (2). Projects that\n    use gemma.cpp as a library are considered alternative frontends to `run.cc`.\n    We will add examples of additional frontends in the future.\n\n2.  Models (`gemma.cc`, `gemma.h`, `configs.h`) - Implements the compute graph\n    of the model including supporting functions such as loading and compressing\n    weights using transformer operations provided by layer (3).\n\n3.  Operations (`ops.h`) - A minimal set of transformer and supporting\n    mathematical operations implementations using compute backends (4). This\n    code should be agnostic to the specifics of the compute graph of the model\n    implementation (2).\n\n4.  Backend (`highway`) - Low-level hardware interface (SIMD in the case of\n    highway) supporting the implementations in (3).\n\nBesides these layers, supporting utilities are:\n\n- `compression/` - model compression operations. The 8-bit switched floating\n  point model conversion is here.\n- `util/` - command line argument handling and any other utilities.\n\n## Style and Formatting\n\nA `.clang-format` configuration is provided with our defaults, please run source\nfiles through `clang-format` (or a formatter that produces equivalent behavior)\nbefore finalizing PR for submission.\n\n## Converting weights\n\nWe use a stripped down binary blob (.sbs) artifact to accelerate weight loading\nin C++. These files can be downloaded directly from Kaggle and HuggingFace. You\ncan also convert Pytorch or Keras checkpoints to .sbs, but most end users should\nnot have to do this.\n\nIf starting with Keras, first run this script to convert to Pytorch:\nhttps://github.com/keras-team/keras-nlp/blob/master/tools/gemma/export_gemma_to_torch_xla.py\n\nFrom Pytorch, use the following script to generate uncompressed weights:\nhttps://github.com/google/gemma.cpp/blob/dev/compression/convert_weights.py\n\nThen run `compression/compress_weights.cc` (Bazel target\n`compression:compress_weights`), specifying the resulting file as `--weights`\nand the desired .sbs name as the `--compressed_weights`.\n\n## Compile-Time Flags (Advanced)\n\nThere are several compile-time flags to be aware of (note these may or may not\nbe exposed to the build system):\n\n- `GEMMA_MAX_SEQ_LEN` : Sets maximum sequence length to preallocate for the KV\n  Cache. The default is 4096 tokens but can be overridden. This is not exposed\n  through `CMakeLists.txt` yet.\n\nIn the medium term this will likely be deprecated in favor of handling options\nat runtime - dynamically resizing the KV cache as needed.\n\n## Using gemma.cpp as a Library (Advanced)\n\nUnless you are doing lower level implementations or research, from an\napplication standpoint you can think of gemma.h and gemma.cc as the \"core\" of\nthe library.\n\nYou can regard `run.cc` as an example application that your own application is\nsubstituting for, so the invocations into gemma.h and gemma.cc you see in\n`run.cc` are probably the functions you'll be invoking. You can find examples of\nthe invocations to tokenizer methods and `Generate()` in `run.cc`.\n\nKeep in mind gemma.cpp is oriented at more experimental / prototype / research\napplications. If you're targeting production, there's more standard paths via\njax / pytorch / keras / XNNPACK for NN deployments.\n\n### Gemma struct contains all the state of the inference engine - tokenizer, weights, and activations\n\n`Gemma(...)` - constructor, creates a gemma model object.\n\nIn a standard LLM chat app, you'll probably use a Gemma object directly, in\nmore exotic data processing or research applications, you might decompose\nworking with weights, kv cache and activations (e.g. you might have multiple kv\ncaches and activations for a single set of weights) more directly rather than\nonly using a Gemma object.\n\n### Use the tokenizer in the Gemma object (or interact with the Tokenizer object directly)\n\nThe Gemma object contains contains a pointer to a Tokenizer object. The main\noperations performed on the tokenizer are to load the tokenizer model from a\nfile (usually `tokenizer.spm`), call `Encode()` to go from string prompts to\ntoken id vectors, or `Decode()` to go from token id vector outputs from the\nmodel back to strings. `benchmark_helper.h` provides wrapper functions that make\nthem easier to use.\n\n### `model.Generate()` is the entrypoint for token generation\n\nCalling into `model.Generate` with a tokenized prompt will\n\n1.  mutate the activation values in `model` and\n2.  invoke `StreamFunc` - a lambda callback for each generated token.\n\nYour application defines its own `StreamFunc` as a lambda callback to do\nsomething every time a token string is streamed from the engine (e.g., print to\nthe screen, write data to the disk, send the string to a server, etc.). You can\nsee in `run.cc` the `StreamFunc` lambda takes care of printing each token to the\nscreen as it arrives.\n\nOptionally you can define `accept_token` as another lambda - this is mostly for\nconstrained decoding type of use cases where you want to force the generation to\nfit a grammar. If you're not doing this, you can send an empty lambda or\n`std::function` as a no-op which is what `run.cc` does.\n\n### `Transformer()` implements the inference (i.e. `forward()` method in PyTorch or Jax) computation of the neural network\n\nFor high-level applications, you might only call `model.Generate()` and never\ninteract directly with the neural network, but if you're doing something a bit\nmore custom you can call transformer which performs a single inference operation\non a single token and mutates the Activations and the KVCache through the neural\nnetwork computation.\n\nNote that an experimental backward pass is available in backprop/, which may be\nuseful for fine tuning.\n\n### For low level operations, defining new architectures, call `ops.h` functions directly\n\nYou use `ops.h` if you're writing other NN architectures or modifying the\ninference path of the Gemma model.\n\n## Building with Bazel\n\nThe sentencepiece library we depend on requires some additional work to build\nwith the Bazel build system. First, it does not export its BUILD file, so we\nprovide `bazel/sentencepiece.bazel`. Second, it ships with a vendored subset of\nthe Abseil library. `bazel/sentencepiece.patch` changes the code to support\nAbseil as a standalone dependency without third_party/ prefixes, similar to the\ntransforms we apply to Gemma via Copybara.\n\n## Debugging\n\nAt the first sign of incorrect or unexpected results, we recommend running with\nASan/MSan enabled. When using bazel, you can add `--config=asan` or\n`--config=msan-track-origins` to the build command. In addition to their checks\nfor memory overruns or uninitialized memory, we also enable debug-only asserts\nin Gemma.cpp for those build configurations.\n\n## Discord\n\nWe're also trying out a discord server for discussion here -\nhttps://discord.gg/H5jCBAWxAe\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License."
        },
        {
          "name": "LICENSE-BSD3",
          "type": "blob",
          "size": 1.4814453125,
          "content": "Copyright (c) The gemma.cpp Project Authors. All rights reserved.\n\nRedistribution and use in source and binary forms, with or without modification,\nare permitted provided that the following conditions are met:\n\n1.  Redistributions of source code must retain the above copyright notice, this\n    list of conditions and the following disclaimer.\n\n2.  Redistributions in binary form must reproduce the above copyright notice,\n    this list of conditions and the following disclaimer in the documentation\n    and/or other materials provided with the distribution.\n\n3.  Neither the name of the copyright holder nor the names of its\n    contributors may be used to endorse or promote products derived from\n    this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
        },
        {
          "name": "MODULE.bazel",
          "type": "blob",
          "size": 1.765625,
          "content": "module(\n    name = \"gemma\",\n    version = \"0.1.0\",\n)\n\nbazel_dep(name = \"abseil-cpp\", version = \"20240722.0\")\nbazel_dep(name = \"bazel_skylib\", version = \"1.6.1\")\nbazel_dep(name = \"googletest\", version = \"1.15.2\")\nbazel_dep(name = \"highway\", version = \"1.1.0\")\nbazel_dep(name = \"nlohmann_json\", version = \"3.11.3\")\nbazel_dep(name = \"platforms\", version = \"0.0.10\")\nbazel_dep(name = \"pybind11_bazel\", version = \"2.12.0\")\nbazel_dep(name = \"rules_cc\", version = \"0.0.9\")\nbazel_dep(name = \"rules_license\", version = \"0.0.7\")\nbazel_dep(name = \"google_benchmark\", version = \"1.8.5\")\n\n# Require a more recent version.\ngit_override(\n    module_name = \"highway\",\n    commit = \"2b565e87d50b151660494624af532ac0b6076c79\",\n    remote = \"https://github.com/google/highway\",\n)\n\nhttp_archive = use_repo_rule(\"@bazel_tools//tools/build_defs/repo:http.bzl\", \"http_archive\")\n\nhttp_archive(\n    name = \"com_google_sentencepiece\",\n    build_file = \"@//bazel:sentencepiece.bazel\",\n    patch_args = [\"-p1\"],\n    patches = [\"@//bazel:sentencepiece.patch\"],\n    sha256 = \"8409b0126ebd62b256c685d5757150cf7fcb2b92a2f2b98efb3f38fc36719754\",\n    strip_prefix = \"sentencepiece-0.1.96\",\n    urls = [\"https://github.com/google/sentencepiece/archive/refs/tags/v0.1.96.zip\"],\n)\n\n# For sentencepiece\nhttp_archive(\n    name = \"darts_clone\",\n    build_file_content = \"\"\"\nlicenses([\"notice\"])\nexports_files([\"LICENSE\"])\npackage(default_visibility = [\"//visibility:public\"])\ncc_library(\n    name = \"darts_clone\",\n    hdrs = [\n        \"include/darts.h\",\n    ],\n)\n\"\"\",\n    sha256 = \"c97f55d05c98da6fcaf7f9ecc6a6dc6bc5b18b8564465f77abff8879d446491c\",\n    strip_prefix = \"darts-clone-e40ce4627526985a7767444b6ed6893ab6ff8983\",\n    urls = [\n        \"https://github.com/s-yata/darts-clone/archive/e40ce4627526985a7767444b6ed6893ab6ff8983.zip\",\n    ],\n)\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 20.6435546875,
          "content": "# gemma.cpp\n\ngemma.cpp is a lightweight, standalone C++ inference engine for the Gemma\nfoundation models from Google.\n\nFor additional information about Gemma, see\n[ai.google.dev/gemma](https://ai.google.dev/gemma). Model weights, including gemma.cpp\nspecific artifacts, are [available on\nkaggle](https://www.kaggle.com/models/google/gemma).\n\nNOTE: 2024-04-04: if using 2B models, please re-download weights from Kaggle and\nensure you have the latest version (-mqa or version 3). We are changing the code\nto match the new weights. If you wish to use old weights, change `ConfigGemma2B`\nin `configs.h` back to `kVocabSize = 256128` and `kKVHeads = 8`.\n\n## Who is this project for?\n\nModern LLM inference engines are sophisticated systems, often with bespoke\ncapabilities extending beyond traditional neural network runtimes. With this\ncomes opportunities for research and innovation through co-design of high level\nalgorithms and low-level computation. However, there is a gap between\ndeployment-oriented C++ inference runtimes, which are not designed for\nexperimentation, and Python-centric ML research frameworks, which abstract away\nlow-level computation through compilation.\n\ngemma.cpp provides a minimalist implementation of Gemma-1 and Gemma-2 models,\nfocusing on simplicity and directness rather than full generality. This is\ninspired by vertically-integrated model implementations such as\n[ggml](https://github.com/ggerganov/ggml),\n[llama.c](https://github.com/karpathy/llama2.c), and\n[llama.rs](https://github.com/srush/llama2.rs).\n\ngemma.cpp targets experimentation and research use cases. It is intended to be\nstraightforward to embed in other projects with minimal dependencies and also\neasily modifiable with a small ~2K LoC core implementation (along with ~4K LoC\nof supporting utilities). We use the [Google\nHighway](https://github.com/google/highway) Library to take advantage of\nportable SIMD for CPU inference.\n\nFor production-oriented edge deployments we recommend standard deployment\npathways using Python frameworks like JAX, Keras, PyTorch, and Transformers\n([all model variations here](https://www.kaggle.com/models/google/gemma)).\n\n## Contributing\n\nCommunity contributions large and small are welcome. See\n[DEVELOPERS.md](https://github.com/google/gemma.cpp/blob/main/DEVELOPERS.md)\nfor additional notes contributing developers and [join the discord by following\nthis invite link](https://discord.gg/H5jCBAWxAe). This project follows\n[Google's Open Source Community\nGuidelines](https://opensource.google.com/conduct/).\n\n*Active development is currently done on the `dev` branch. Please open pull\nrequests targeting `dev` branch instead of `main`, which is intended to be more\nstable.*\n\n## Quick Start\n\n### System requirements\n\nBefore starting, you should have installed:\n\n- [CMake](https://cmake.org/)\n- [Clang C++ compiler](https://clang.llvm.org/get_started.html), supporting at\n  least C++17.\n- `tar` for extracting archives from Kaggle.\n\nBuilding natively on Windows requires the Visual Studio 2012 Build Tools with the\noptional Clang/LLVM C++ frontend (`clang-cl`). This can be installed from the\ncommand line with\n[`winget`](https://learn.microsoft.com/en-us/windows/package-manager/winget/):\n\n```sh\nwinget install --id Kitware.CMake\nwinget install --id Microsoft.VisualStudio.2022.BuildTools --force --override \"--passive --wait --add Microsoft.VisualStudio.Workload.VCTools;installRecommended --add Microsoft.VisualStudio.Component.VC.Llvm.Clang --add Microsoft.VisualStudio.Component.VC.Llvm.ClangToolset\"\n```\n\n### Step 1: Obtain model weights and tokenizer from Kaggle or Hugging Face Hub\n\nVisit the\n[Kaggle page for Gemma-2](https://www.kaggle.com/models/google/gemma-2/gemmaCpp)\n[or Gemma-1](https://www.kaggle.com/models/google/gemma/frameworks/gemmaCpp),\nand select `Model Variations |> Gemma C++`.\n\nOn this tab, the `Variation` dropdown includes the options below. Note bfloat16\nweights are higher fidelity, while 8-bit switched floating point weights enable\nfaster inference. In general, we recommend starting with the `-sfp` checkpoints.\n\nIf you are unsure which model to start with, we recommend starting with the\nsmallest Gemma-2 model, i.e. `2.0-2b-it-sfp`.\n\nAlternatively, visit the\n[gemma.cpp](https://huggingface.co/models?other=gemma.cpp) models on the Hugging\nFace Hub. First go the model repository of the model of interest (see\nrecommendations below). Then, click the `Files and versions` tab and download\nthe model and tokenizer files. For programmatic downloading, if you have\n`huggingface_hub` installed, you can also download by running:\n\n```\nhuggingface-cli login # Just the first time\nhuggingface-cli download google/gemma-2b-sfp-cpp --local-dir build/\n```\n\nGemma-1 2B instruction-tuned (`it`) and pre-trained (`pt`) models:\n\n| Model name  | Description |\n| ----------- | ----------- |\n| `2b-it`     | 2 billion parameter instruction-tuned model, bfloat16 |\n| `2b-it-sfp` | 2 billion parameter instruction-tuned model, 8-bit switched floating point |\n| `2b-pt`     | 2 billion parameter pre-trained model, bfloat16 |\n| `2b-pt-sfp` | 2 billion parameter pre-trained model, 8-bit switched floating point |\n\nGemma-1 7B instruction-tuned (`it`) and pre-trained (`pt`) models:\n\n| Model name  | Description |\n| ----------- | ----------- |\n| `7b-it`     | 7 billion parameter instruction-tuned model, bfloat16 |\n| `7b-it-sfp` | 7 billion parameter instruction-tuned model, 8-bit switched floating point |\n| `7b-pt`     | 7 billion parameter pre-trained model, bfloat16 |\n| `7b-pt-sfp` | 7 billion parameter pre-trained model, 8-bit switched floating point |\n\n> [!NOTE]\n> **Important**: We strongly recommend starting off with the `2b-it-sfp` model to\n> get up and running.\n\nGemma 2 models are named `gemma2-2b-it` for 2B and `9b-it` or `27b-it`. See the\n`kModelFlags` definition in `common.cc`.\n\n### Step 2: Extract Files\n\nIf you downloaded the models from Hugging Face, skip to step 3.\n\nAfter filling out the consent form, the download should proceed to retrieve a\ntar archive file `archive.tar.gz`. Extract files from `archive.tar.gz` (this can\ntake a few minutes):\n\n```\ntar -xf archive.tar.gz\n```\n\nThis should produce a file containing model weights such as `2b-it-sfp.sbs` and\na tokenizer file (`tokenizer.spm`). You may want to move these files to a\nconvenient directory location (e.g. the `build/` directory in this repo).\n\n### Step 3: Build\n\nThe build system uses [CMake](https://cmake.org/). To build the gemma inference\nruntime, create a build directory and generate the build files using `cmake`\nfrom the top-level project directory. Note if you previous ran `cmake` and are\nre-running with a different setting, be sure to delete all files in the `build/`\ndirectory with `rm -rf build/*`.\n\n#### Unix-like Platforms\n```sh\ncmake -B build\n```\n\nAfter running `cmake`, you can enter the `build/` directory and run `make` to\nbuild the `./gemma` executable:\n\n```sh\n# Configure `build` directory\ncmake --preset make\n\n# Build project using make\ncmake --build --preset make -j [number of parallel threads to use]\n```\n\nReplace `[number of parallel threads to use]` with a number - the number of\ncores available on your system is a reasonable heuristic.  For example,\n`make -j4 gemma` will build using 4 threads. If the `nproc` command is\navailable, you can use `make -j$(nproc) gemma` as a reasonable default\nfor the number of threads.\n\nIf you aren't sure of the right value for the `-j` flag, you can simply run\n`make gemma` instead and it should still build the `./gemma` executable.\n\n> [!NOTE]\n> On Windows Subsystem for Linux (WSL) users should set the number of\n> parallel threads to 1. Using a larger number may result in errors.\n\nIf the build is successful, you should now have a `gemma` executable in the `build/` directory.\n\n#### Windows\n\n```sh\n# Configure `build` directory\ncmake --preset windows\n\n# Build project using Visual Studio Build Tools\ncmake --build --preset windows -j [number of parallel threads to use]\n```\n\nIf the build is successful, you should now have a `gemma.exe` executable in the `build/` directory.\n\n#### Bazel\n\n```sh\nbazel build -c opt --cxxopt=-std=c++20 :gemma\n```\n\nIf the build is successful, you should now have a `gemma` executable in the `bazel-bin/` directory.\n\n#### Make\n\nIf you prefer Makefiles, @jart has made one available here:\n\nhttps://github.com/jart/gemma3/blob/main/Makefile\n\n### Step 4: Run\n\nYou can now run `gemma` from inside the `build/` directory.\n\n`gemma` has the following required arguments:\n\nArgument        | Description                  | Example value\n--------------- | ---------------------------- | -----------------------\n`--model`       | The model type.              | `2b-it` ... (see below)\n`--weights`     | The compressed weights file. | `2b-it-sfp.sbs`\n`--weight_type` | The compressed weight type.  | `sfp`\n`--tokenizer`   | The tokenizer file.          | `tokenizer.spm`\n\n`gemma` is invoked as:\n\n```sh\n./gemma \\\n--tokenizer [tokenizer file] \\\n--weights [compressed weights file] \\\n--weight_type [f32 or bf16 or sfp] \\\n--model [2b-it or 2b-pt or 7b-it or 7b-pt or ...]\n```\n\nExample invocation for the following configuration:\n\n- Compressed weights file `2b-it-sfp.sbs` (2B instruction-tuned model, 8-bit\n  switched floating point).\n- Tokenizer file `tokenizer.spm`.\n\n```sh\n./gemma \\\n--tokenizer tokenizer.spm \\\n--weights 2b-it-sfp.sbs --weight_type sfp --model 2b-it\n```\n\n### RecurrentGemma\n\nThis repository includes a version of Gemma based on Griffin\n([paper](https://arxiv.org/abs/2402.19427),\n[code](https://github.com/google-deepmind/recurrentgemma)). Its architecture\nincludes both recurrent layers and local attention, thus it is more efficient\nfor longer sequences and has a smaller memory footprint than standard Gemma. We\nhere provide a C++ implementation of this model based on the paper.\n\nTo use the recurrent version of Gemma included in this repository, build the\ngemma binary as noted above in Step 3. Download the compressed weights and\ntokenizer from the RecurrentGemma\n[Kaggle](https://www.kaggle.com/models/google/recurrentgemma/gemmaCpp) as in\nStep 1, and run the binary as follows:\n\n`./gemma --tokenizer tokenizer.spm --model gr2b-it --weights 2b-it-sfp.sbs`\n\n### PaliGemma Vision-Language Model\n\nThis repository includes a version of the PaliGemma VLM\n([paper](https://arxiv.org/abs/2407.07726),\n[code](https://github.com/google-research/big_vision/tree/main/big_vision/configs/proj/paligemma)).\nWe  provide a C++ implementation of this model here.\n\nTo use the version of PaliGemma included in this repository, build the gemma\nbinary as noted above in Step 3. Download the compressed weights and tokenizer\nfrom\n[Kaggle](https://www.kaggle.com/models/google/paligemma/gemmaCpp/paligemma-3b-mix-224)\nand run the binary as follows:\n\n```sh\n./gemma \\\n--tokenizer paligemma_tokenizer.model \\\n--model paligemma-224 \\\n--weights paligemma-3b-mix-224-sfp.sbs \\\n--image_file paligemma/testdata/image.ppm\n```\n\nNote that the image reading code is very basic to avoid depending on an image\nprocessing library for now. We currently only support reading binary PPMs (P6).\nSo use a tool like `convert` to first convert your images into that format, e.g.\n\n`convert image.jpeg -resize 224x224^ image.ppm`\n\n(As the image will be resized for processing anyway, we can already resize at\nthis stage for slightly faster loading.)\n\nThe interaction with the image (using the mix-224 checkpoint) may then look\nsomething like this:\n\n```\n> Describe the image briefly\nA large building with two towers in the middle of a city.\n> What type of building is it?\nchurch\n> What color is the church?\ngray\n> caption image\nA large building with two towers stands tall on the water's edge. The building\nhas a brown roof and a window on the side. A tree stands in front of the\nbuilding, and a flag waves proudly from its top. The water is calm and blue,\nreflecting the sky above. A bridge crosses the water, and a red and white boat\nrests on its surface. The building has a window on the side, and a flag on top.\nA tall tree stands in front of the building, and a window on the building is\nvisible from the water. The water is green, and the sky is blue.\n```\n\n### Troubleshooting and FAQs\n\n**Running `./gemma` fails with \"Failed to read cache gating_ein_0 (error 294) ...\"**\n\nThe most common problem is that the `--weight_type` argument does not match that\nof the model file. Revisit step #3 and check which weights you downloaded.\n\nNote that we have already moved weight type from a compile-time decision to a\nruntime argument. In a subsequent step, we plan to bake this information into\nthe weights.\n\n**Problems building in Windows / Visual Studio**\n\nCurrently if you're using Windows, we recommend building in WSL (Windows\nSubsystem for Linux). We are exploring options to enable other build\nconfigurations, see issues for active discussion.\n\n**Model does not respond to instructions and produces strange output**\n\nA common issue is that you are using a pre-trained model, which is not\ninstruction-tuned and thus does not respond to instructions. Make sure you are\nusing an instruction-tuned model (`2b-it-sfp`, `2b-it`, `7b-it-sfp`, `7b-it`)\nand not a pre-trained model (any model with a `-pt` suffix).\n\n**How do I convert my fine-tune to a `.sbs` compressed model file?**\n\nWe're working on a python script to convert a standard model format to `.sbs`,\nand hope have it available soon. Follow\n[this issue](https://github.com/google/gemma.cpp/issues/11) for updates.\n\n**What are some easy ways to make the model run faster?**\n\n1. Make sure you are using the 8-bit switched floating point `-sfp` models.\n2. If you're on a laptop, make sure power mode is set to maximize performance\nand saving mode is **off**. For most laptops, the power saving modes get\nactivated automatically if the computer is not plugged in.\n3. Close other unused cpu-intensive applications.\n4. On macs, anecdotally we observe a \"warm-up\" ramp-up in speed as performance\ncores get engaged.\n5. Experiment with the `--num_threads` argument value. Depending on the device,\nlarger numbers don't always mean better performance.\n\nWe're also working on algorithmic and optimization approaches for faster\ninference, stay tuned.\n\n## Usage\n\n`gemma` has different usage modes, controlled by the verbosity flag.\n\nAll usage modes are currently interactive, triggering text generation upon\nnewline input.\n\n| Verbosity       | Usage mode | Details                                       |\n| --------------- | ---------- | --------------------------------------------- |\n| `--verbosity 0` | Minimal | Only prints generation output. Suitable as a CLI tool. |\n| `--verbosity 1` | Default | Standard user-facing terminal UI. |\n| `--verbosity 2` | Detailed | Shows additional developer and debug info. |\n\n### Interactive Terminal App\n\nBy default, verbosity is set to 1, bringing up a terminal-based interactive\ninterface when `gemma` is invoked:\n\n```console\n$ ./gemma [...]\n  __ _  ___ _ __ ___  _ __ ___   __ _   ___ _ __  _ __\n / _` |/ _ \\ '_ ` _ \\| '_ ` _ \\ / _` | / __| '_ \\| '_ \\\n| (_| |  __/ | | | | | | | | | | (_| || (__| |_) | |_) |\n \\__, |\\___|_| |_| |_|_| |_| |_|\\__,_(_)___| .__/| .__/\n  __/ |                                    | |   | |\n |___/                                     |_|   |_|\n\ntokenizer                     : tokenizer.spm\ncompressed_weights            : 2b-it-sfp.sbs\nmodel                         : 2b-it\nweights                       : [no path specified]\nmax_generated_tokens          : 2048\n\n*Usage*\n  Enter an instruction and press enter (%C reset conversation, %Q quits).\n\n*Examples*\n  - Write an email to grandma thanking her for the cookies.\n  - What are some historical attractions to visit around Massachusetts?\n  - Compute the nth fibonacci number in javascript.\n  - Write a standup comedy bit about WebGPU programming.\n\n> What are some outdoorsy places to visit around Boston?\n\n[ Reading prompt ] .....................\n\n\n**Boston Harbor and Islands:**\n\n* **Boston Harbor Islands National and State Park:** Explore pristine beaches, wildlife, and maritime history.\n* **Charles River Esplanade:** Enjoy scenic views of the harbor and city skyline.\n* **Boston Harbor Cruise Company:** Take a relaxing harbor cruise and admire the city from a different perspective.\n* **Seaport Village:** Visit a charming waterfront area with shops, restaurants, and a seaport museum.\n\n**Forest and Nature:**\n\n* **Forest Park:** Hike through a scenic forest with diverse wildlife.\n* **Quabbin Reservoir:** Enjoy boating, fishing, and hiking in a scenic setting.\n* **Mount Forest:** Explore a mountain with breathtaking views of the city and surrounding landscape.\n\n...\n```\n\n### Usage as a Command Line Tool\n\nFor using the `gemma` executable as a command line tool, it may be useful to\ncreate an alias for gemma.cpp with arguments fully specified:\n\n```sh\nalias gemma2b=\"~/gemma.cpp/build/gemma -- --tokenizer ~/gemma.cpp/build/tokenizer.spm --weights ~/gemma.cpp/build/gemma2-2b-it-sfp.sbs --model gemma2-2b-it --verbosity 0\"\n```\n\nReplace the above paths with your own paths to the model and tokenizer paths\nfrom the download.\n\nHere is an example of prompting `gemma` with a truncated input\nfile (using a `gemma2b` alias like defined above):\n\n```sh\ncat configs.h | tail -n 35 | tr '\\n' ' ' | xargs -0 echo \"What does this C++ code do: \" | gemma2b\n```\n\n> [!NOTE]\n> CLI usage of gemma.cpp is experimental and should take context length\n> limitations into account.\n\nThe output of the above command should look like:\n\n```console\n[ Reading prompt ] [...]\nThis C++ code snippet defines a set of **constants** used in a large language model (LLM) implementation, likely related to the **attention mechanism**.\n\nLet's break down the code:\n[...]\n```\n\n### Incorporating gemma.cpp as a Library in your Project\n\nThe easiest way to incorporate gemma.cpp in your own project is to pull in\ngemma.cpp and dependencies using `FetchContent`. You can add the following to your\nCMakeLists.txt:\n\n```\ninclude(FetchContent)\n\nFetchContent_Declare(sentencepiece GIT_REPOSITORY https://github.com/google/sentencepiece GIT_TAG 53de76561cfc149d3c01037f0595669ad32a5e7c)\nFetchContent_MakeAvailable(sentencepiece)\n\nFetchContent_Declare(gemma GIT_REPOSITORY https://github.com/google/gemma.cpp GIT_TAG origin/main)\nFetchContent_MakeAvailable(gemma)\n\nFetchContent_Declare(highway GIT_REPOSITORY https://github.com/google/highway.git GIT_TAG da250571a45826b21eebbddc1e50d0c1137dee5f)\nFetchContent_MakeAvailable(highway)\n```\n\nNote for the gemma.cpp `GIT_TAG`, you may replace `origin/main` for a specific\ncommit hash if you would like to pin the library version.\n\nAfter your executable is defined (substitute your executable name for\n`[Executable Name]` below):\n\n```\ntarget_link_libraries([Executable Name] libgemma hwy hwy_contrib sentencepiece)\nFetchContent_GetProperties(gemma)\nFetchContent_GetProperties(sentencepiece)\ntarget_include_directories([Executable Name] PRIVATE ${gemma_SOURCE_DIR})\ntarget_include_directories([Executable Name] PRIVATE ${sentencepiece_SOURCE_DIR})\n```\n\n### Building gemma.cpp as a Library\n\ngemma.cpp can also be used as a library dependency in your own project. The\nshared library artifact can be built by modifying the make invocation to build\nthe `libgemma` target instead of `gemma`.\n\n> [!NOTE]\n> If you are using gemma.cpp in your own project with the `FetchContent` steps\n> in the previous section, building the library is done automatically by `cmake`\n> and this section can be skipped.\n\nFirst, run `cmake`:\n\n```sh\ncmake -B build\n```\n\nThen, run `make` with the `libgemma` target:\n\n```sh\ncd build\nmake -j [number of parallel threads to use] libgemma\n```\n\nIf this is successful, you should now have a `libgemma` library file in the\n`build/` directory. On Unix platforms, the filename is `libgemma.a`.\n\n## Independent Projects Using gemma.cpp\n\nSome independent projects using gemma.cpp:\n\n- [gemma-cpp-python - Python bindings](https://github.com/namtranase/gemma-cpp-python)\n- [lua-cgemma - Lua bindings](https://github.com/ufownl/lua-cgemma)\n- [Godot engine demo project](https://github.com/Rliop913/Gemma-godot-demo-project)\n\nIf you would like to have your project included, feel free to get in touch or\nsubmit a PR with a `README.md` edit.\n\n## Acknowledgements and Contacts\n\ngemma.cpp was started in fall 2023 by [Austin Huang](mailto:austinvhuang@google.com)\nand [Jan Wassenberg](mailto:janwas@google.com), and subsequently released February 2024\nthanks to contributions from Phil Culliton, Paul Chang, and Dan Zheng.\n\nGriffin support was implemented in April 2024 thanks to contributions by Andrey\nMikhaylov, Eugene Kliuchnikov, Jan Wassenberg, Jyrki Alakuijala, Lode\nVandevenne, Luca Versari, Martin Bruse, Phil Culliton, Sami Boukortt, Thomas\nFischbacher and Zoltan Szabadka.\n\nGemma-2 support was implemented in June/July 2024 with the help of several\npeople.\n\nPaliGemma support was implemented in September 2024 with contributions from\nDaniel Keysers.\n\n[Jan Wassenberg](mailto:janwas@google.com) has continued to contribute many\nimprovements, including major gains in efficiency, since the initial release.\n\nThis is not an officially supported Google product.\n"
        },
        {
          "name": "WORKSPACE",
          "type": "blob",
          "size": 0.126953125,
          "content": "workspace(name = \"gemma\")\n\n# This file marks the root of the Bazel workspace.\n# See MODULE.bazel for external dependencies setup.\n"
        },
        {
          "name": "backprop",
          "type": "tree",
          "content": null
        },
        {
          "name": "bazel",
          "type": "tree",
          "content": null
        },
        {
          "name": "build",
          "type": "tree",
          "content": null
        },
        {
          "name": "cmake.sh",
          "type": "blob",
          "size": 8.486328125,
          "content": "#!/usr/bin/env bash\n# Copyright 2024 Google LLC\n# SPDX-License-Identifier: Apache-2.0\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nMYDIR=$(dirname $(realpath \"$0\"))\nBUILD_DIR=\"${BUILD_DIR:-${MYDIR}/build}\"\n\nCMAKE_BUILD_TYPE=\"${CMAKE_BUILD_TYPE:-RelWithDebInfo}\"\nCMAKE_C_COMPILER=\"${CMAKE_C_COMPILER:-clang-14}\"\nCMAKE_CXX_COMPILER=\"${CMAKE_CXX_COMPILER:-clang++-14}\"\n# Convenience flag to pass both CMAKE_C_FLAGS and CMAKE_CXX_FLAGS\nCMAKE_FLAGS=\"${CMAKE_FLAGS:-}\"\nCMAKE_C_FLAGS=\"${CMAKE_C_FLAGS:-} ${CMAKE_FLAGS}\"\nCMAKE_CXX_FLAGS=\"${CMAKE_CXX_FLAGS:-} ${CMAKE_FLAGS}\"\nCMAKE_EXE_LINKER_FLAGS=\"${CMAKE_EXE_LINKER_FLAGS:-}\"\nCMAKE_MODULE_LINKER_FLAGS=\"${CMAKE_MODULE_LINKER_FLAGS:-}\"\nCMAKE_SHARED_LINKER_FLAGS=\"${CMAKE_SHARED_LINKER_FLAGS:-}\"\n\n# Local flags passed to sanitizers.\nUBSAN_FLAGS=(\n  -fsanitize=alignment\n  -fsanitize=bool\n  -fsanitize=bounds\n  -fsanitize=builtin\n  -fsanitize=enum\n  -fsanitize=float-cast-overflow\n  -fsanitize=float-divide-by-zero\n  -fsanitize=integer-divide-by-zero\n  -fsanitize=null\n  -fsanitize=object-size\n  -fsanitize=pointer-overflow\n  -fsanitize=return\n  -fsanitize=returns-nonnull-attribute\n  -fsanitize=shift-base\n  -fsanitize=shift-exponent\n  -fsanitize=unreachable\n  -fsanitize=vla-bound\n\n  -fno-sanitize-recover=undefined\n  -fsanitize-recover=alignment\n)\n\nCLANG_VERSION=\"${CLANG_VERSION:-}\"\n# Detect the clang version suffix and store it in CLANG_VERSION. For example,\n# \"6.0\" for clang 6 or \"7\" for clang 7.\ndetect_clang_version() {\n  if [[ -n \"${CLANG_VERSION}\" ]]; then\n    return 0\n  fi\n  local clang_version=$(\"${CMAKE_C_COMPILER:-clang}\" --version | head -n1)\n  clang_version=${clang_version#\"Debian \"}\n  clang_version=${clang_version#\"Ubuntu \"}\n  local llvm_tag\n  case \"${clang_version}\" in\n    \"clang version 6.\"*)\n      CLANG_VERSION=\"6.0\"\n      ;;\n    \"clang version \"*)\n      # Any other clang version uses just the major version number.\n      local suffix=\"${clang_version#clang version }\"\n      CLANG_VERSION=\"${suffix%%.*}\"\n      ;;\n    \"emcc\"*)\n      # We can't use asan or msan in the emcc case.\n      ;;\n    *)\n      echo \"Unknown clang version: ${clang_version}\" >&2\n      return 1\n  esac\n}\n\n# Temporary files cleanup hooks.\nCLEANUP_FILES=()\ncleanup() {\n  if [[ ${#CLEANUP_FILES[@]} -ne 0 ]]; then\n    rm -fr \"${CLEANUP_FILES[@]}\"\n  fi\n}\n\n# Executed on exit.\non_exit() {\n  local retcode=\"$1\"\n  # Always cleanup the CLEANUP_FILES.\n  cleanup\n}\n\ntrap 'retcode=$?; { set +x; } 2>/dev/null; on_exit ${retcode}' INT TERM EXIT\n\n\n# Install libc++ libraries compiled with msan in the msan_prefix for the current\n# compiler version.\ncmd_msan_install() {\n  local tmpdir=$(mktemp -d)\n  CLEANUP_FILES+=(\"${tmpdir}\")\n  # Detect the llvm to install:\n  detect_clang_version\n  # Allow overriding the LLVM checkout.\n  local llvm_root=\"${LLVM_ROOT:-}\"\n  if [ -z \"${llvm_root}\" ]; then\n    local llvm_tag=\"llvmorg-${CLANG_VERSION}.0.0\"\n    case \"${CLANG_VERSION}\" in\n      \"6.0\")\n        llvm_tag=\"llvmorg-6.0.1\"\n        ;;\n      \"7\")\n        llvm_tag=\"llvmorg-7.0.1\"\n        ;;\n    esac\n    local llvm_targz=\"${tmpdir}/${llvm_tag}.tar.gz\"\n    curl -L --show-error -o \"${llvm_targz}\" \\\n      \"https://github.com/llvm/llvm-project/archive/${llvm_tag}.tar.gz\"\n    tar -C \"${tmpdir}\" -zxf \"${llvm_targz}\"\n    llvm_root=\"${tmpdir}/llvm-project-${llvm_tag}\"\n  fi\n\n  local msan_prefix=\"${HOME}/.msan/${CLANG_VERSION}\"\n  rm -rf \"${msan_prefix}\"\n\n  declare -A CMAKE_EXTRAS\n  CMAKE_EXTRAS[libcxx]=\"\\\n    -DLIBCXX_CXX_ABI=libstdc++ \\\n    -DLIBCXX_INSTALL_EXPERIMENTAL_LIBRARY=ON \\\n    -DLIBCXX_INCLUDE_BENCHMARKS=OFF\"\n\n  for project in libcxx; do\n    local proj_build=\"${tmpdir}/build-${project}\"\n    local proj_dir=\"${llvm_root}/${project}\"\n    mkdir -p \"${proj_build}\"\n    cmake -B\"${proj_build}\" -H\"${proj_dir}\" \\\n      -G Ninja \\\n      -DCMAKE_BUILD_TYPE=Release \\\n      -DLLVM_USE_SANITIZER=Memory \\\n      -DLLVM_PATH=\"${llvm_root}/llvm\" \\\n      -DLLVM_CONFIG_PATH=\"$(which llvm-config llvm-config-7 llvm-config-6.0 | \\\n                            head -n1)\" \\\n      -DCMAKE_C_COMPILER=\"${CMAKE_C_COMPILER}\" \\\n      -DCMAKE_CXX_COMPILER=\"${CMAKE_CXX_COMPILER}\" \\\n      -DCMAKE_C_FLAGS=\"${CMAKE_C_FLAGS}\" \\\n      -DCMAKE_CXX_FLAGS=\"${CMAKE_CXX_FLAGS}\" \\\n      -DCMAKE_EXE_LINKER_FLAGS=\"${CMAKE_EXE_LINKER_FLAGS}\" \\\n      -DCMAKE_SHARED_LINKER_FLAGS=\"${CMAKE_SHARED_LINKER_FLAGS}\" \\\n      -DCMAKE_INSTALL_PREFIX=\"${msan_prefix}\" \\\n      ${CMAKE_EXTRAS[${project}]}\n    cmake --build \"${proj_build}\"\n    ninja -C \"${proj_build}\" install\n  done\n}\n\ncmd_msan() {\n  detect_clang_version\n  local msan_prefix=\"${HOME}/.msan/${CLANG_VERSION}\"\n  if [[ ! -d \"${msan_prefix}\" || -e \"${msan_prefix}/lib/libc++abi.a\" ]]; then\n    # Install msan libraries for this version if needed or if an older version\n    # with libc++abi was installed.\n    cmd_msan_install\n  fi\n\n  local msan_c_flags=(\n    -fsanitize=memory\n    -fno-omit-frame-pointer\n\n    -g\n    -DMEMORY_SANITIZER\n\n    # Force gtest to not use the cxxbai.\n    -DGTEST_HAS_CXXABI_H_=0\n\n    -fsanitize-memory-track-origins\n  )\n\n  local msan_cxx_flags=(\n    \"${msan_c_flags[@]}\"\n\n    # Some C++ sources don't use the std at all, so the -stdlib=libc++ is unused\n    # in those cases. Ignore the warning.\n    -Wno-unused-command-line-argument\n    -stdlib=libc++\n\n    # We include the libc++ from the msan directory instead, so we don't want\n    # the std includes.\n    -nostdinc++\n    -cxx-isystem\"${msan_prefix}/include/c++/v1\"\n  )\n\n  local msan_linker_flags=(\n    -L\"${msan_prefix}\"/lib\n    -Wl,-rpath -Wl,\"${msan_prefix}\"/lib/\n  )\n\n  CMAKE_C_FLAGS+=\" ${msan_c_flags[@]} ${UBSAN_FLAGS[@]}\"\n  CMAKE_CXX_FLAGS+=\" ${msan_cxx_flags[@]} ${UBSAN_FLAGS[@]}\"\n  CMAKE_EXE_LINKER_FLAGS+=\" ${msan_linker_flags[@]}\"\n  CMAKE_MODULE_LINKER_FLAGS+=\" ${msan_linker_flags[@]}\"\n  CMAKE_SHARED_LINKER_FLAGS+=\" ${msan_linker_flags[@]}\"\n  cmake_configure \"$@\" \\\n    -DCMAKE_CROSSCOMPILING=1 -DRUN_HAVE_STD_REGEX=0 -DRUN_HAVE_POSIX_REGEX=0 \\\n    -DCMAKE_REQUIRED_LINK_OPTIONS=\"${msan_linker_flags[@]}\"\n}\n\ncmake_configure() {\n  local args=(\n    -B\"${BUILD_DIR}\" -H\"${MYDIR}\"\n    -DCMAKE_BUILD_TYPE=\"${CMAKE_BUILD_TYPE}\"\n    -G Ninja\n    -DCMAKE_C_COMPILER=\"${CMAKE_C_COMPILER}\"\n    -DCMAKE_CXX_COMPILER=\"${CMAKE_CXX_COMPILER}\"\n    -DCMAKE_C_FLAGS=\"${CMAKE_C_FLAGS}\"\n    -DCMAKE_CXX_FLAGS=\"${CMAKE_CXX_FLAGS}\"\n    -DCMAKE_EXE_LINKER_FLAGS=\"${CMAKE_EXE_LINKER_FLAGS}\"\n    -DCMAKE_MODULE_LINKER_FLAGS=\"${CMAKE_MODULE_LINKER_FLAGS}\"\n    -DCMAKE_SHARED_LINKER_FLAGS=\"${CMAKE_SHARED_LINKER_FLAGS}\"\n    -DGEMMA_ENABLE_TESTS=ON\n  )\n\n  cmake \"${args[@]}\" \"$@\"\n}\n\ncmd_opt() {\n  CMAKE_BUILD_TYPE=\"RelWithDebInfo\"\n  cmake_configure \"$@\"\n}\n\ncmd_asan() {\n  CMAKE_C_FLAGS+=\" -g -DADDRESS_SANITIZER -fsanitize=address  ${UBSAN_FLAGS[@]}\"\n  CMAKE_CXX_FLAGS+=\" -g -DADDRESS_SANITIZER -fsanitize=address \\\n    ${UBSAN_FLAGS[@]}\"\n  cmake_configure \"$@\"\n}\n\ncmd_tsan() {\n  SANITIZER=\"tsan\"\n  local tsan_args=(\n    -g\n    -DTHREAD_SANITIZER\n    ${UBSAN_FLAGS[@]}\n    -fsanitize=thread\n  )\n  CMAKE_C_FLAGS+=\" ${tsan_args[@]}\"\n  CMAKE_CXX_FLAGS+=\" ${tsan_args[@]}\"\n\n  CMAKE_BUILD_TYPE=\"RelWithDebInfo\"\n  cmake_configure \"$@\"\n}\n\nmain() {\n  local cmd=\"${1:-}\"\n  if [[ -z \"${cmd}\" ]]; then\n    cat >&2 <<EOF\nUse: $0 CMD\n\nWhere cmd is one of:\n opt       Build and test a Release with symbols build.\n asan      Build and test an ASan (AddressSanitizer) build.\n msan      Build and test an MSan (MemorySanitizer) build. Needs to have msan\n           c++ libs installed with msan_install first.\n msan_install Install the libc++ libraries required to build in msan mode. This\n              needs to be done once.\n tsan      Build and test a TSan (ThreadSanitizer) build.\n\nYou can pass some optional environment variables as well:\n - BUILD_DIR: The output build directory (by default \"$$repo/build\")\n - CMAKE_FLAGS: Convenience flag to pass both CMAKE_C_FLAGS and CMAKE_CXX_FLAGS.\n\nThese optional environment variables are forwarded to the cmake call as\nparameters:\n - CMAKE_BUILD_TYPE\n - CMAKE_C_FLAGS\n - CMAKE_CXX_FLAGS\n - CMAKE_C_COMPILER\n - CMAKE_CXX_COMPILER\n - CMAKE_EXE_LINKER_FLAGS\n - CMAKE_MODULE_LINKER_FLAGS\n - CMAKE_SHARED_LINKER_FLAGS\n\nExample:\n  BUILD_DIR=/tmp/build $0 opt\nEOF\n    exit 1\n  fi\n\n  cmd=\"cmd_${cmd}\"\n  shift\n  set -x\n  \"${cmd}\" \"$@\"\n}\n\nmain \"$@\"\n"
        },
        {
          "name": "compression",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "evals",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "experimental",
          "type": "tree",
          "content": null
        },
        {
          "name": "gemma",
          "type": "tree",
          "content": null
        },
        {
          "name": "goldens",
          "type": "tree",
          "content": null
        },
        {
          "name": "ops",
          "type": "tree",
          "content": null
        },
        {
          "name": "paligemma",
          "type": "tree",
          "content": null
        },
        {
          "name": "util",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}