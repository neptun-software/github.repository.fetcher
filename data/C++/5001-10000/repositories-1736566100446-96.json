{
  "metadata": {
    "timestamp": 1736566100446,
    "page": 96,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjEwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "openvinotoolkit/openvino",
      "stars": 7587,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.09375,
          "content": "*\n!install_build_dependencies.sh\n!scripts/install_dependencies/install_openvino_dependencies.sh\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 2.962890625,
          "content": "###############################################################################\n# Set default behavior to automatically normalize line endings.\n###############################################################################\n* text=auto\n###############################################################################\n# Set default behavior for command prompt diff.\n#\n# This is need for earlier builds of msysgit that does not have it on by\n# default for csharp files.\n# Note: This is only used by command line\n###############################################################################\n#*.cs     diff=csharp\n*.py text eol=lf\n###############################################################################\n# Set the merge driver for project and solution files\n#\n# Merging from the command prompt will add diff markers to the files if there\n# are conflicts (Merging from VS is not affected by the settings below, in VS\n# the diff markers are never inserted). Diff markers may cause the following \n# file extensions to fail to load in VS. An alternative would be to treat\n# these files as binary and thus will always conflict and require user\n# intervention with every merge. To do so, just uncomment the entries below\n###############################################################################\n#*.sln       merge=binary\n#*.csproj    merge=binary\n#*.vbproj    merge=binary\n#*.vcxproj   merge=binary\n#*.vcproj    merge=binary\n#*.dbproj    merge=binary\n#*.fsproj    merge=binary\n#*.lsproj    merge=binary\n#*.wixproj   merge=binary\n#*.modelproj merge=binary\n#*.sqlproj   merge=binary\n#*.wwaproj   merge=binary\n###############################################################################\n# behavior for image files\n#\n# image files are treated as binary by default.\n###############################################################################\n#*.jpg   binary\n#*.png   binary\n#*.gif   binary\n###############################################################################\n# diff behavior for common document formats\n# \n# Convert binary document formats to text before diffing them. This feature\n# is only available from the command line. Turn it on by uncommenting the \n# entries below.\n###############################################################################\n#*.doc   diff=astextplain\n#*.DOC   diff=astextplain\n#*.docx  diff=astextplain\n#*.DOCX  diff=astextplain\n#*.dot   diff=astextplain\n#*.DOT   diff=astextplain\n#*.pdf   diff=astextplain\n#*.PDF   diff=astextplain\n#*.rtf   diff=astextplain\n#*.RTF   diff=astextplain\n*.PNG filter=lfs diff=lfs merge=lfs -text\n*.png filter=lfs diff=lfs merge=lfs -text\n*.jpg filter=lfs diff=lfs merge=lfs -text\n*.gif filter=lfs diff=lfs merge=lfs -text\n*.vsdx filter=lfs diff=lfs merge=lfs -text\n*.bmp filter=lfs diff=lfs merge=lfs -text\n*.svg filter=lfs diff=lfs merge=lfs -text\n.github/scripts/workflow_rerun/tests/data/log_archive_with_error.zip filter=lfs diff=lfs merge=lfs -text\n.github/scripts/workflow_rerun/tests/data/log_archive_wo_error.zip filter=lfs diff=lfs merge=lfs -text\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.0078125,
          "content": "# build/artifact dirs\n_*\n[Bb]uild*/\ncmake-build*\n\n# but ensure we don't skip __init__.py and __main__.py\n!__init__.py\n!__main__.py\n# and sphinx documentation folders\n!docs/sphinx_setup/_*\n\n# developer tools\n*.idea\n.vscode\n.vs/\n.vsconan/\n.DS_Store\n**/tags\ncompile_commands.json\nbin/\n.local_vimrc\n.gdb_history\n.vimspector.json\ndoc/\ndocs/build_documentation/work_dir/\ntemp/\n.repo/\nCMakeLists.txt.user\ndocs/IE_PLUGIN_DG/html/\nCMakeUserPresets.json\nvenv\n\n*.project\n*.cproject\n*.pydevproject\n*.settings\n*/gen/\n*.swp\n/config.xml\n\n# Python-specific\n*.?env*\n*.pyc\n__pycache__\n# Tests-specific\n*.coverage\n*htmlcov\n*pylint_report.txt\n*pylint_report_comments.txt\n\n# JS specific\n!__tests__\n__tests__/runner/*\n# Dependency directory\nnode_modules\n# Coverage directory used by tools like istanbul\ncoverage\n*.lcov\n# Optional npm cache directory\n.npm\n\n# Artifacts\n/src/plugins/intel_cpu/tools/commit_slider/*.json\n/src/plugins/intel_cpu/tools/commit_slider/slider_cache/*\n/src/plugins/intel_cpu/thirdparty/ComputeLibrary/build/*\n.github/GITHUB_OUTPUT"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 3.48828125,
          "content": "[submodule \"src/plugins/intel_cpu/thirdparty/onednn\"]\n\tpath = src/plugins/intel_cpu/thirdparty/onednn\n\turl = https://github.com/openvinotoolkit/oneDNN.git\n\tignore = dirty\n[submodule \"thirdparty/xbyak\"]\n\tpath = thirdparty/xbyak\n\turl = https://github.com/herumi/xbyak.git\n\tignore = dirty\n[submodule \"thirdparty/zlib/zlib\"]\n\tpath = thirdparty/zlib/zlib\n\turl = https://github.com/madler/zlib.git\n\tignore = dirty\n[submodule \"thirdparty/pugixml\"]\n\tpath = thirdparty/pugixml\n\turl = https://github.com/zeux/pugixml.git\n\tignore = dirty\n[submodule \"thirdparty/gflags/gflags\"]\n\tpath = thirdparty/gflags/gflags\n\turl = https://github.com/gflags/gflags.git\n\tignore = dirty\n[submodule \"thirdparty/gtest/gtest\"]\n\tpath = thirdparty/gtest/gtest\n\turl = https://github.com/openvinotoolkit/googletest.git\n\tignore = dirty\n[submodule \"thirdparty/ocl/icd_loader\"]\n\tpath = thirdparty/ocl/icd_loader\n\turl = https://github.com/KhronosGroup/OpenCL-ICD-Loader.git\n\tignore = dirty\n[submodule \"thirdparty/ocl/cl_headers\"]\n\tpath = thirdparty/ocl/cl_headers\n\turl = https://github.com/KhronosGroup/OpenCL-Headers.git\n\tignore = dirty\n[submodule \"thirdparty/ocl/clhpp_headers\"]\n\tpath = thirdparty/ocl/clhpp_headers\n\turl = https://github.com/KhronosGroup/OpenCL-CLHPP.git\n\tignore = dirty\n[submodule \"thirdparty/onnx\"]\n\tpath = thirdparty/onnx/onnx\n\turl = https://github.com/onnx/onnx.git\n[submodule \"thirdparty/protobuf\"]\n\tpath = thirdparty/protobuf/protobuf\n\turl = https://github.com/protocolbuffers/protobuf.git\n[submodule \"src/bindings/python/thirdparty/pybind11\"]\n\tpath = src/bindings/python/thirdparty/pybind11\n\turl = https://github.com/pybind/pybind11.git\n[submodule \"thirdparty/ittapi/ittapi\"]\n\tpath = thirdparty/ittapi/ittapi\n\turl = https://github.com/intel/ittapi.git\n[submodule \"ncc\"]\n\tpath = cmake/developer_package/ncc_naming_style/ncc\n\turl = https://github.com/nithinn/ncc.git\n[submodule \"thirdparty/onednn_gpu\"]\n\tpath = src/plugins/intel_gpu/thirdparty/onednn_gpu\n\turl = https://github.com/oneapi-src/oneDNN.git\n[submodule \"thirdparty/json/nlohmann_json\"]\n\tpath = thirdparty/json/nlohmann_json\n\turl = https://github.com/nlohmann/json.git\n\tshallow = true\n[submodule \"thirdparty/flatbuffers/flatbuffers\"]\n\tpath = thirdparty/flatbuffers/flatbuffers\n\turl = https://github.com/google/flatbuffers.git\n[submodule \"thirdparty/snappy\"]\n\tpath = thirdparty/snappy\n\turl = https://github.com/google/snappy.git\n[submodule \"ARMComputeLibrary\"]\n\tpath = src/plugins/intel_cpu/thirdparty/ComputeLibrary\n\turl = https://github.com/ARM-software/ComputeLibrary.git\n\tignore = dirty\n[submodule \"src/plugins/intel_cpu/thirdparty/mlas\"]\n\tpath = src/plugins/intel_cpu/thirdparty/mlas\n\turl = https://github.com/openvinotoolkit/mlas.git\n[submodule \"thirdparty/level_zero/level-zero\"]\n\tpath = thirdparty/level_zero/level-zero\n\turl = https://github.com/oneapi-src/level-zero.git\n[submodule \"src/plugins/intel_npu/thirdparty/level-zero-ext\"]\n\tpath = src/plugins/intel_npu/thirdparty/level-zero-ext\n\turl = https://github.com/intel/level-zero-npu-extensions.git\n[submodule \"src/plugins/intel_npu/thirdparty/yaml-cpp\"]\n\tpath = src/plugins/intel_npu/thirdparty/yaml-cpp\n\turl = https://github.com/jbeder/yaml-cpp.git\n[submodule \"thirdparty/telemetry\"]\n\tpath = thirdparty/telemetry\n\turl = https://github.com/openvinotoolkit/telemetry.git\n[submodule \"src/plugins/intel_cpu/thirdparty/libxsmm\"]\n\tpath = src/plugins/intel_cpu/thirdparty/libxsmm\n\turl = https://github.com/libxsmm/libxsmm.git\n[submodule \"src/plugins/intel_cpu/thirdparty/shl\"]\n\tpath = src/plugins/intel_cpu/thirdparty/shl\n\turl = https://github.com/openvinotoolkit/shl.git\n"
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 6.8193359375,
          "content": "# Copyright (C) 2018-2024 Intel Corporation\n# SPDX-License-Identifier: Apache-2.0\n#\n\nif(DEFINED BUILD_SHARED_LIBS AND NOT BUILD_SHARED_LIBS)\n    # 3.17: 'target_link_libraries' does not work correctly when called from\n    # different directory where 'add_library' is called: CMake generates\n    # incorrect OpenVINOConfig.cmake in this case\n    # 3.18: add_library cannot create ALIAS for non-GLOBAL targets\n    cmake_minimum_required(VERSION 3.18)\nelse()\n    if(CPACK_GENERATOR STREQUAL \"DEB\")\n        # we have to use CPACK_DEBIAN_PACKAGE_SHLIBDEPS_PRIVATE_DIRS variable\n        cmake_minimum_required(VERSION 3.20)\n    else()\n        if(WIN32)\n            # 3.16: FindPython3.cmake can find Python via -DPython3_EXECUTABLE\n            # 3.18: FindPython3.cmake can find Python automatically from virtualenv\n            cmake_minimum_required(VERSION 3.16)\n        else()\n            # 3.13: default choice\n            cmake_minimum_required(VERSION 3.13)\n        endif()\n    endif()\nendif()\n\nif(POLICY CMP0091)\n    cmake_policy(SET CMP0091 NEW) # Enables use of MSVC_RUNTIME_LIBRARY\nendif()\n\n# Avoid warning about DOWNLOAD_EXTRACT_TIMESTAMP in CMake 3.24:\nif(POLICY CMP0135)\n    cmake_policy(SET CMP0135 NEW)\nendif()\n\nif(POLICY CMP0149)\n    # VS generator looks for most recent Windows SDK, ignoring\n    # CMAKE_SYSTEM_VERSION and allowing override by WindowsSDKVersion\n    # environment variable. New in 3.27. This is to allow override\n    # in the Windows CI builds.\n    cmake_policy(SET CMP0149 NEW)\nendif()\n\nproject(OpenVINO\n        DESCRIPTION \"OpenVINO toolkit\"\n        HOMEPAGE_URL \"https://docs.openvino.ai/2024/home.html\"\n        LANGUAGES C CXX)\n\nfind_package(OpenVINODeveloperScripts REQUIRED\n             PATHS \"${OpenVINO_SOURCE_DIR}/cmake/developer_package\"\n             NO_CMAKE_FIND_ROOT_PATH\n             NO_DEFAULT_PATH)\n\ninclude(cmake/features.cmake)\n\n# These options are shared with 3rdparty plugins by means of developer package\ninclude(cmake/dependencies.cmake)\n\nif(ENABLE_COVERAGE)\n    include(cmake/coverage.cmake)\nendif()\n\nif(APPLE AND CMAKE_OSX_DEPLOYMENT_TARGET AND\n    CMAKE_OSX_DEPLOYMENT_TARGET VERSION_LESS 10.15)\n    message(FATAL_ERROR \"OpenVINO requires MACOSX_DEPLOYMENT_TARGET at least 10.15, specified ${CMAKE_OSX_DEPLOYMENT_TARGET}\")\nendif()\n\n# resolving dependencies for the project\nmessage (STATUS \"CMAKE_VERSION ......................... \" ${CMAKE_VERSION})\nmessage (STATUS \"CMAKE_CROSSCOMPILING .................. \" ${CMAKE_CROSSCOMPILING})\nmessage (STATUS \"OpenVINO_SOURCE_DIR ................... \" ${OpenVINO_SOURCE_DIR})\nmessage (STATUS \"OpenVINO_BINARY_DIR ................... \" ${OpenVINO_BINARY_DIR})\nmessage (STATUS \"CMAKE_GENERATOR ....................... \" ${CMAKE_GENERATOR})\nmessage (STATUS \"CPACK_GENERATOR ....................... \" ${CPACK_GENERATOR})\nmessage (STATUS \"CMAKE_C_COMPILER_ID ................... \" ${CMAKE_C_COMPILER_ID})\nmessage (STATUS \"CMAKE_CXX_COMPILER_ID ................. \" ${CMAKE_CXX_COMPILER_ID})\nmessage (STATUS \"CMAKE_CXX_STANDARD .................... \" ${CMAKE_CXX_STANDARD})\nif(OV_GENERATOR_MULTI_CONFIG)\n    string(REPLACE \";\" \" \" config_types \"${CMAKE_CONFIGURATION_TYPES}\")\n    message (STATUS \"CMAKE_CONFIGURATION_TYPES ............. \" ${config_types})\n    unset(config_types)\n    if(CMAKE_GENERATOR STREQUAL \"Ninja Multi-Config\")\n        message (STATUS \"CMAKE_DEFAULT_BUILD_TYPE .............. \" ${CMAKE_DEFAULT_BUILD_TYPE})\n    endif()\nelse()\n    message (STATUS \"CMAKE_BUILD_TYPE ...................... \" ${CMAKE_BUILD_TYPE})\nendif()\nif(CMAKE_GENERATOR_PLATFORM)\n    message (STATUS \"CMAKE_GENERATOR_PLATFORM .............. \" ${CMAKE_GENERATOR_PLATFORM})\nendif()\nif(CMAKE_GENERATOR_TOOLSET)\n    message (STATUS \"CMAKE_GENERATOR_TOOLSET ............... \" ${CMAKE_GENERATOR_TOOLSET})\nendif()\nif(CMAKE_TOOLCHAIN_FILE)\n    message (STATUS \"CMAKE_TOOLCHAIN_FILE .................. \" ${CMAKE_TOOLCHAIN_FILE})\nendif()\nif(NOT OV_LIBC_VERSION VERSION_EQUAL 0.0)\n    message (STATUS \"LIBC_VERSION .......................... \" ${OV_LIBC_VERSION})\nendif()\nif(DEFINED OPENVINO_STDLIB)\n    message (STATUS \"STDLIB ................................ \" ${OPENVINO_STDLIB})\nendif()\n\n# remove file with exported targets to force its regeneration\nfile(REMOVE \"${CMAKE_BINARY_DIR}/OpenVINOTargets.cmake\")\n\n# remove exported developer targets files to force its regeneration\nmacro(ov_clean_developer_package_targets)\n    file(REMOVE \"${CMAKE_BINARY_DIR}/openvino_developer_package_targets.cmake\")\n    unset(_OPENVINO_DEVELOPER_PACKAGE_TARGETS CACHE)\n    unset(openvino_installed_targets CACHE)\nendmacro()\nov_clean_developer_package_targets()\n\nfunction(ov_developer_package_export_targets)\n    cmake_parse_arguments(EXPORT \"\" \"TARGET;INSTALL_DESTIONATION\" \"INSTALL_INCLUDE_DIRECTORIES\" ${ARGN})\n\n    # to allow exporting of aliased targets with the original names\n    if(TARGET \"${EXPORT_TARGET}\")\n        get_target_property(original_name ${EXPORT_TARGET} ALIASED_TARGET)\n        if(TARGET \"${original_name}\")\n            # replace target with its original name\n            set(EXPORT_TARGET ${original_name})\n        endif()\n        list(APPEND _OPENVINO_DEVELOPER_PACKAGE_TARGETS ${EXPORT_TARGET})\n\n        if(EXPORT_INSTALL_INCLUDE_DIRECTORIES)\n            if(NOT EXPORT_INSTALL_DESTIONATION)\n                set(EXPORT_INSTALL_DESTIONATION \"developer_package/include/${EXPORT_TARGET}\")\n            endif()\n\n            target_include_directories(${EXPORT_TARGET} INTERFACE \"$<INSTALL_INTERFACE:${EXPORT_INSTALL_DESTIONATION}>\")\n\n            foreach(install_dir IN LISTS EXPORT_INSTALL_INCLUDE_DIRECTORIES)\n                install(DIRECTORY \"${install_dir}\"\n                        DESTINATION \"${EXPORT_INSTALL_DESTIONATION}\"\n                        COMPONENT developer_package EXCLUDE_FROM_ALL)\n            endforeach()\n        endif()\n    else()\n        message(FATAL_ERROR \"Internal error: '${EXPORT_TARGET}' does not represent a cmake target\")\n    endif()\n\n    list(REMOVE_DUPLICATES _OPENVINO_DEVELOPER_PACKAGE_TARGETS)\n    set(_OPENVINO_DEVELOPER_PACKAGE_TARGETS \"${_OPENVINO_DEVELOPER_PACKAGE_TARGETS}\" CACHE INTERNAL\n        \"A list of OpenVINO Developer Package exported targets\" FORCE)\nendfunction()\n\n#\n# Build\n#\n\nif(ENABLE_TESTS)\n    # add target with processed tests model zoo\n    include(cmake/test_model_zoo.cmake)\nendif()\n\ninclude(thirdparty/dependencies.cmake)\nadd_subdirectory(src)\n\nif(ENABLE_SAMPLES OR ENABLE_TESTS)\n    add_subdirectory(samples)\nendif()\n\n# Enable interpreter backend for tests\nif(ENABLE_TESTS OR ENABLE_TEMPLATE)\n    add_subdirectory(src/plugins/template/backend)\nendif()\n\ninclude(cmake/extra_modules.cmake)\nadd_subdirectory(docs)\nadd_subdirectory(tools)\nadd_subdirectory(scripts)\nadd_subdirectory(licensing)\n\nif(ENABLE_TESTS)\n    # layers and other more high-level / e2e tests\n    add_subdirectory(tests)\nendif()\n\n#\n# CPack\n#\n\n# provides a callback function to describe each component in repo\ninclude(cmake/packaging/packaging.cmake)\n\nov_cpack(${OV_CPACK_COMPONENTS_ALL})\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 4.7529296875,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nWe as members, contributors, and leaders pledge to make participation in our\ncommunity a harassment-free experience for everyone, regardless of age, body\nsize, visible or invisible disability, ethnicity, sex characteristics, gender\nidentity and expression, level of experience, education, socio-economic status,\nnationality, personal appearance, race, religion, or sexual identity\nand orientation.\n\nWe pledge to act and interact in ways that contribute to an open, welcoming,\ndiverse, inclusive, and healthy community.\n\n## Our Standards\n\nExamples of behavior that contributes to a positive environment for our\ncommunity include:\n\n* Demonstrating empathy and kindness toward other people\n* Being respectful of differing opinions, viewpoints, and experiences\n* Giving and gracefully accepting constructive feedback\n* Accepting responsibility and apologizing to those affected by our mistakes,\n  and learning from the experience\n* Focusing on what is best not just for us as individuals, but for the\n  overall community\n\nExamples of unacceptable behavior include:\n\n* The use of sexualized language or imagery, and sexual attention or\n  advances of any kind\n* Trolling, insulting or derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or email\n  address, without their explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Enforcement Responsibilities\n\nCommunity leaders are responsible for clarifying and enforcing our standards of\nacceptable behavior and will take appropriate and fair corrective action in\nresponse to any behavior that they deem inappropriate, threatening, offensive,\nor harmful.\n\nCommunity leaders have the right and responsibility to remove, edit, or reject\ncomments, commits, code, wiki edits, issues, and other contributions that are\nnot aligned to this Code of Conduct, and will communicate reasons for moderation\ndecisions when appropriate.\n\n## Scope\n\nThis Code of Conduct applies within all community spaces, and also applies when\nan individual is officially representing the community in public spaces.\nExamples of representing our community include using an official email address,\nposting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported to the community leaders responsible for enforcement at\nopenvino_codeofconduct At intel DOT com.\nAll complaints will be reviewed and investigated promptly and fairly.\n\nAll community leaders are obligated to respect the privacy and security of the\nreporter of any incident.\n\n## Enforcement Guidelines\n\nCommunity leaders will follow these Community Impact Guidelines in determining\nthe consequences for any action they deem in violation of this Code of Conduct:\n\n### 1. Correction\n\n**Community Impact**: Use of inappropriate language or other behavior deemed\nunprofessional or unwelcome in the community.\n\n**Consequence**: A private, written warning from community leaders, providing\nclarity around the nature of the violation and an explanation of why the\nbehavior was inappropriate. A public apology may be requested.\n\n### 2. Warning\n\n**Community Impact**: A violation through a single incident or series\nof actions.\n\n**Consequence**: A warning with consequences for continued behavior. No\ninteraction with the people involved, including unsolicited interaction with\nthose enforcing the Code of Conduct, for a specified period of time. This\nincludes avoiding interactions in community spaces as well as external channels\nlike social media. Violating these terms may lead to a temporary or\npermanent ban.\n\n### 3. Temporary Ban\n\n**Community Impact**: A serious violation of community standards, including\nsustained inappropriate behavior.\n\n**Consequence**: A temporary ban from any sort of interaction or public\ncommunication with the community for a specified period of time. No public or\nprivate interaction with the people involved, including unsolicited interaction\nwith those enforcing the Code of Conduct, is allowed during this period.\nViolating these terms may lead to a permanent ban.\n\n### 4. Permanent Ban\n\n**Community Impact**: Demonstrating a pattern of violation of community\nstandards, including sustained inappropriate behavior,  harassment of an\nindividual, or aggression toward or disparagement of classes of individuals.\n\n**Consequence**: A permanent ban from any sort of public interaction within\nthe community.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage],\nversion 2.0, available at\n[https://www.contributor-covenant.org/version/2/0/code_of_conduct.html][v2.0].\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 9.2255859375,
          "content": "# Contributing to OpenVINO\n\n## How to contribute to the OpenVINO project\n\nOpenVINO™ is always looking for opportunities to improve and your contributions\nplay a big role in this process. There are several ways you can make the\nproduct better.\n\n# Table of Contents\n1. [Forms of contribution](#Forms-of-contribution)\n2. [Technical guide](#Technical-guide)\n\n\n## Forms of contribution\n\n### Provide Feedback\n\n   * **Report bugs / issues**\n     If you experience faulty behavior in OpenVINO or its components, you can\n     [create a new issue](https://github.com/openvinotoolkit/openvino/issues)\n     in the GitHub issue tracker.\n\n   * **Propose new features / improvements**\n     If you have a suggestion for improving OpenVINO or want to share your ideas, you can open a new\n     [GitHub Discussion](https://github.com/openvinotoolkit/openvino/discussions).\n     If your idea is already well defined, you can also create a\n     [Feature Request Issue](https://github.com/openvinotoolkit/openvino/issues/new?assignees=octocat&labels=enhancement%2Cfeature&projects=&template=feature_request.yml&title=%5BFeature+Request%5D%3A+)\n     In both cases, provide a detailed description, including use cases, benefits, and potential challenges.\n     If your points are especially well aligned with the product vision, they will be included in the\n     development roadmap.\n     User feedback is crucial for OpenVINO development and even if your input is not immediately prioritized,\n     it may be used at a later time or undertaken by the community, regardless of the official roadmap.\n\n\n### Contribute Code Changes\n\n   * **Fix Bugs or Develop New Features**\n     If you want to help improving OpenVINO, choose one of the issues reported in\n     [GitHub Issue Tracker](https://github.com/openvinotoolkit/openvino/issues) and\n     [create a Pull Request](./CONTRIBUTING_PR.md) addressing it. If you want to start with something simple,\n     check out the [first-time contributions section](#3-start-working-on-your-good-first-issue).\n     If the feature you want to develop is more complex or not well defined by the reporter,\n     it is always a good idea to [discuss it](https://github.com/openvinotoolkit/openvino/discussions)\n     with OpenVINO developers first. Before creating a new PR, check if nobody is already\n     working on it. In such a case, you may still help, having aligned with the other developer.\n\n     Importantly, always check if the change hasn't been implemented before you start working on it!\n     You can build OpenVINO using the latest master branch and make sure that it still needs your\n     changes. Also, do not address issues that only affect older non-LTS releases, like 2022.2.\n\n   * **Develop a New Device Plugin**\n     Since the market of computing devices is constantly evolving, OpenVINO is always open to extending\n     its support for new hardware. If you want to run inference on a device that is currently not supported,\n     you can see how to develop a new plugin for it in the\n     [Plugin Developer Guide](https://docs.openvino.ai/2024/documentation/openvino-extensibility/openvino-plugin-library.html).\n\n\n### Improve documentation\n\n   * **OpenVINO developer documentation** is contained entirely in this repository, under the\n     [./docs/dev](https://github.com/openvinotoolkit/openvino/tree/master/docs/dev) folder.\n\n   * **User documentation** is built from several sources and published at\n     [docs.openvino.ai](https://docs.openvino.ai/), which is the recommended place for reading\n     these documents. Use the files maintained in this repository only for editing purposes.\n\n   * The easiest way to help with documentation is to review it and provide feedback on the\n     existing articles. Whether you notice a mistake, see the possibility of improving the text,\n     or think more information should be added, you can reach out to any of the documentation\n     contributors to discuss the potential changes.\n\n     You can also create a Pull Request directly, following the [editor's guide](./CONTRIBUTING_DOCS.md).\n\n\n### Promote and Support OpenVINO\n\n   * **Popularize OpenVINO**\n     Articles, tutorials, blog posts, demos, videos, and any other involvement\n     in the OpenVINO community is always a welcome contribution. If you discuss\n     or present OpenVINO on various social platforms, you are raising awareness\n     of the product among A.I. enthusiasts and enabling other people to discover\n     the toolkit. Feel free to reach out to OpenVINO developers if you need help\n     with making such community-based content.\n\n   * **Help Other Community Members**\n     If you are an experienced OpenVINO user and want to help, you can always\n     share your expertise with the community. Check GitHub Discussions and\n     Issues to see if you can help someone.\n\n## Technical guide\n\nThis section lists all the necessary steps required to set up your environment, build OpenVINO locally, and run tests for specific components. It's a perfect place to start when you have just picked a Good First Issue and are wondering how to start working on it.\n\nKeep in mind that we are here to help - **do not hesitate to ask the development team if something is not clear**. Such questions allow us to keep improving our documentation.\n\n### 1. Prerequisites\n\nYou can start with the following links:\n- [What is OpenVINO?](https://github.com/openvinotoolkit/openvino#what-is-openvino-toolkit)\n- [OpenVINO architecture](https://github.com/openvinotoolkit/openvino/blob/master/src/docs/architecture.md)\n- [User documentation](https://docs.openvino.ai/)\n- [Blog post on contributing to OpenVINO](https://medium.com/openvino-toolkit/how-to-contribute-to-an-ai-open-source-project-c741f48e009e)\n- [Pick up a Good First Issue](https://github.com/orgs/openvinotoolkit/projects/3)\n- Check out [Intel DevHub Discord server](https://discord.gg/7pVRxUwdWG) - engage in discussions, ask questions and talk to OpenVINO developers\n\n### 2. Building the project\n\nIn order to build the project, follow the [build instructions for your specific OS](https://github.com/openvinotoolkit/openvino/blob/master/docs/dev/build.md).\n\n### 3. Familiarize yourself with the component you'll be working with\n\nChoose the component your Good First Issue is related to. You can run tests to make sure it works correctly.\n\n##### APIs\n- [C API](https://github.com/openvinotoolkit/openvino/tree/master/src/bindings/c)\n- [Core](https://github.com/openvinotoolkit/openvino/tree/master/src/core)\n- [Python API](https://github.com/openvinotoolkit/openvino/tree/master/src/bindings/python)\n- [Node.js API](https://github.com/openvinotoolkit/openvino/tree/master/src/bindings/js/node)\n\n##### Frontends\n- [IR Frontend](https://github.com/openvinotoolkit/openvino/tree/master/src/frontends/ir)\n- [ONNX Frontend](https://github.com/openvinotoolkit/openvino/tree/master/src/frontends/onnx)\n- [PaddlePaddle Frontend](https://github.com/openvinotoolkit/openvino/tree/master/src/frontends/paddle)\n- [PyTorch Frontend](https://github.com/openvinotoolkit/openvino/tree/master/src/frontends/pytorch)\n- [TensorFlow Frontend](https://github.com/openvinotoolkit/openvino/tree/master/src/frontends/tensorflow)\n\n##### Plugins\n- [Auto plugin](https://github.com/openvinotoolkit/openvino/blob/master/src/plugins/auto)\n- [CPU plugin](https://github.com/openvinotoolkit/openvino/blob/master/src/plugins/intel_cpu)\n- [GPU plugin](https://github.com/openvinotoolkit/openvino/blob/master/src/plugins/intel_gpu)\n- [NPU plugin](https://github.com/openvinotoolkit/openvino/blob/master/src/plugins/intel_npu)\n- [Hetero plugin](https://github.com/openvinotoolkit/openvino/blob/master/src/plugins/hetero)\n- [Template plugin](https://github.com/openvinotoolkit/openvino/tree/master/src/plugins/template)\n\n##### Tools\n- [Benchmark Tool](https://github.com/openvinotoolkit/openvino/tree/master/tools/benchmark_tool)\n- [OpenVINO Model Converter](https://github.com/openvinotoolkit/openvino/tree/master/tools/ovc)\n\n##### Others\n- [Documentation](https://github.com/openvinotoolkit/openvino/blob/master/CONTRIBUTING_DOCS.md)\n\n### 3. Start working on your Good First Issue\n\nTo start contributing, pick a task from the [Good First Issues board](https://github.com/orgs/openvinotoolkit/projects/3).\n\nTo be assigned to an issue, simply leave a comment with the `.take` command in the selected issue.\nUse the issue description and build OpenVINO locally to complete the task.\n\nYou can always ask users tagged in the \"Contact points\" section for help!\nVisit [Intel DevHub Discord server](https://discord.gg/7pVRxUwdWG) and ask\nquestions in the channel dedicated to Good First Issue support.\n\n### 4. Submit a PR with your changes\n\nFollow our [Good Pull Request guidelines](https://github.com/openvinotoolkit/openvino/blob/master/CONTRIBUTING_PR.md). Please remember about [linking your Pull Request to the issue](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue#manually-linking-a-pull-request-to-an-issue-using-the-pull-request-sidebar) it addresses.\n\n### 5. Wait for a review\n\nWe'll make sure to review your Pull Request as soon as possible and provide you with our feedback. You can expect a merge once your changes are validated with automatic tests and approved by maintainers.\n\n## License\n\nBy contributing to the OpenVINO project, you agree that your contributions will be\nlicensed under the terms stated in the [LICENSE](./LICENSE) file.\n"
        },
        {
          "name": "CONTRIBUTING_DOCS.md",
          "type": "blob",
          "size": 4.228515625,
          "content": "# OpenVINO Documentation Guide\n\n## Basic article structure\n\nOpenVINO documentation is built using Sphinx and the reStructuredText formatting. \nThat means the basic formatting rules need to be used:\n\n\n### White Spaces\n\nOpenVINO documentation is developed to be easily readable in both html and \nreStructuredText. Here are some suggestions on how to make it render nicely \nand improve document clarity.\n\n### Headings (including the article title)\n\nThey are made by \"underscoring\" text with punctuation marks (at least as \nmany marks as letters in the underscored header). We use the following convention:\n\n```\n   H1\n   ==================== \n    \n   H2\n   ####################  \n    \n   H3\n   ++++++++++++++++++++ \n    \n   H4\n   --------------------\n    \n   H5\n   ....................\n```\n\n### Line length\n\nIn programming, a limit of 80 characters per line is a common BKM. It may also apply \nto reading natural languages fairly well. For this reason, we aim at lines of around \n70 to 100 characters long. The limit is not a strict rule but rather a guideline to \nfollow in most cases. The breaks will not translate to html, and rightly so, but will \nmake reading and editing documents in GitHub or an editor much easier.\n\n### Tables \n\nTables may be difficult to implement well in websites. For example, longer portions \nof text, like descriptions, may render them difficult to read (e.g. improper cell \nwidths or heights). Complex tables may also be difficult to read in source files. \nTo prevent that, check the [table directive documentation](https://www.sphinx-doc.org/en/master/usage/restructuredtext/directives.html#table-directives)\nand see our custom directives. Use the following guidelines for easier editing:\n\n* For very big and complex data sets: use a list instead of a table or remove \n  the problematic content from the table and implement it differently. \n* For very big and complex data sets that need to use tables: use an external \n  file (e.g. PDF) and link to it.\n* For medium tables that look bad in source (e.g. due to long lines of text), \n  use the reStructuredText list table format.\n* For medium and small tables, use the reStructuredText grid or simple table formats.\n\n\n## Cross-linking\n\nThere are several directives Sphinx uses for linking, each has its purpose and format. \nFollow these guidelines for consistent results:\n\n* Avoid absolute references to internal documents as much as possible (link to source, not html).\n* Note that sphinx uses the \"back-tick\" character and not the \"inverted-comma\" => ` vs. '\n* When a file path starts at the same directory is used, put \"./\" at its beginning.\n* Always add a space before the opening angle bracket (\"<\") for target files.\n\nUse the following formatting for different links:\n\n* link to an external page / file\n  * `` `text <url> `__ ``\n  * use a double underscore for consistency\n\n* link to an internal documentation page / file\n  * `` :doc:`a docs page <relative file path>` ``\n  * Link to an rst or md file within our documentation, so that it renders properly in html\n\n* link to a header on the same page\n  * `` 'a header in the same article <this-is-section-header-title>`__ ``\n  * anchors are created automatically for all existing headers\n  * such anchor looks like the header, with minor adjustments:\n    * all letters are lower case,\n    * remove all special glyphs, like brackets,\n    * replace spaces with hyphens \n\n* Create an anchor in an article\n   * `` .. _anchor-in-the target-article:: ``\n   * put it before the header to which you want to link\n   * See the rules for naming anchors / labels at the bottom of this article\n   \n* link to an anchor on a different page in our documentation\n   * `` :ref:`the created anchor <anchor-in-the target-article>` ``\n   * link to the anchor using just its name\n\n\n* anchors / labels \n\n  Read about anchors \n\n  Sphinx uses labels to create html anchors, which can be linked to from anywhere in documentation. \n  Although they may be put at the top of any article to make linking to it very easy, we do not use \n  this approach. Every label definition starts with an underscore, the underscore is not used in links.\n\n  Most importantly, every label needs to be globally unique. It means that it is always a good \n  practice to start their labels with a clear identifier of the article they reside in.\n\n\n"
        },
        {
          "name": "CONTRIBUTING_PR.md",
          "type": "blob",
          "size": 3.36328125,
          "content": "# How to Prepare a Good PR\n\n   OpenVINO is an open-source project and you can contribute to its code directly. \n   To do so, follow these guidelines for creating Pull Requests, so that your \n   changes get the highest chance of being merged.\n\n\n## General Rules of a Good Pull Request\n\n* Create your own fork of the repository and use it to create PRs. \n  Avoid creating change branches in the main repository.\n* Choose a proper branch for your work and create your own branch based on it. \n* Give your branches, commits, and Pull Requests meaningful names and descriptions. \n  It helps to track changes later. If your changes cover a particular component, \n  you can indicate it in the PR name as a prefix, for example: ``[DOCS] PR name``.\n* Follow the [OpenVINO code style guide](https://github.com/openvinotoolkit/openvino/blob/master/docs/dev/coding_style.md).\n* Make your PRs small - each PR should address one issue. Remove all changes \n  unrelated to the PR.\n* [Link your Pull Request to an issue](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue#manually-linking-a-pull-request-to-an-issue-using-the-pull-request-sidebar) if it addresses one.\n* Document your contribution! If your changes may impact how the user works with\n  OpenVINO, provide the information in proper articles. You can do it yourself, \n  or contact one of OpenVINO documentation contributors to work together on\n  developing the right content. \n* For Work In Progress, or checking test results early, use a Draft PR.\n\n\n## Ensure Change Quality\n\nYour pull request will be automatically tested by OpenVINO™'s pre-commit and marked \nas \"green\" if it is ready for merging. If any builders fail, the status is \"red,\" \nyou need to fix the issues listed in console logs. Any change to the PR branch will \nautomatically trigger the checks, so you don't need to recreate the PR, Just wait\nfor the updated results. \n\nRegardless of the automated tests, you should ensure the quality of your changes:\n\n* Test your changes locally:\n  * Make sure to double-check your code. \n  * Run tests locally to identify and fix potential issues (execute test binaries \n    from the artifacts directory, e.g. ``<source dir>/bin/intel64/Release/ieFuncTests``)\n* Before creating a PR, make sure that your branch is up to date with the latest \n  state of the branch you want to contribute to (e.g. git fetch upstream && git \n  merge upstream/master).\n\n\n## Branching Policy\n\n* The \"master\" branch is used for development and constitutes the base for each new release.\n* Each OpenVINO release has its own branch: ``releases/<year>/<release number>``.\n* The final release each year is considered a Long Term Support version, \n  which means it remains active.\n* Contributions are accepted only by active branches, which are:\n  * the \"master\" branch for future releases,\n  * the most recently published version for fixes,\n  * LTS versions (for two years from their release dates).\n\n\n## Need Additional Help? Check these Articles\n\n* [How to create a fork](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/working-with-forks/fork-a-repo) \n* [Install Git](https://git-scm.com/book/en/v2/Getting-Started-First-Time-Git-Setup)\n* If you want to add a new sample, please have a look at the Guide for contributing\n  to C++/C/Python OV samples and add the license statement at the top of new files for\n  C++ example, Python example.\n"
        },
        {
          "name": "Jenkinsfile",
          "type": "blob",
          "size": 0.646484375,
          "content": "#!groovy\n\nproperties([\n    parameters([\n        booleanParam(defaultValue: false,\n                     description: 'Cancel the rest of parallel stages if one of them fails and return status immediately',\n                     name: 'failFast'),\n        booleanParam(defaultValue: true,\n                     description: 'Whether to propagate commit status to GitHub',\n                     name: 'propagateStatus'),\n        string(defaultValue: '',\n               description: 'Pipeline shared library version (branch/tag/commit). Determined automatically if empty',\n               name: 'library_version')\n    ])\n])\n\nloadOpenVinoLibrary {\n    entrypoint(this)\n}\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 11.21484375,
          "content": "<div align=\"center\">\n<img src=\"docs/dev/assets/openvino-logo-purple-black.svg\" width=\"400px\">\n\n<h3 align=\"center\">\nOpen-source software toolkit for optimizing and deploying deep learning models.\n</h3>\n\n<p align=\"center\">\n <a href=\"https://docs.openvino.ai/2024/index.html\"><b>Documentation</b></a> • <a href=\"https://blog.openvino.ai\"><b>Blog</b></a> • <a href=\"https://docs.openvino.ai/2024/about-openvino/key-features.html\"><b>Key Features</b></a> • <a href=\"https://docs.openvino.ai/2024/learn-openvino.html\"><b>Tutorials</b></a> • <a href=\"https://docs.openvino.ai/2024/documentation/openvino-ecosystem.html\"><b>Integrations</b></a> • <a href=\"https://docs.openvino.ai/2024/about-openvino/performance-benchmarks.html\"><b>Benchmarks</b></a> • <a href=\"https://github.com/openvinotoolkit/openvino.genai\"><b>Generative AI</b></a>\n</p>\n\n[![PyPI Status](https://badge.fury.io/py/openvino.svg)](https://badge.fury.io/py/openvino)\n[![Anaconda Status](https://anaconda.org/conda-forge/openvino/badges/version.svg)](https://anaconda.org/conda-forge/openvino)\n[![brew Status](https://img.shields.io/homebrew/v/openvino)](https://formulae.brew.sh/formula/openvino)\n\n[![PyPI Downloads](https://static.pepy.tech/badge/openvino)](https://pepy.tech/project/openvino)\n[![Anaconda Downloads](https://anaconda.org/conda-forge/libopenvino/badges/downloads.svg)](https://anaconda.org/conda-forge/openvino/files)\n[![brew Downloads](https://img.shields.io/homebrew/installs/dy/openvino)](https://formulae.brew.sh/formula/openvino)\n </div>\n\n\n- **Inference Optimization**: Boost deep learning performance in computer vision, automatic speech recognition, generative AI, natural language processing with large and small language models, and many other common tasks.\n- **Flexible Model Support**: Use models trained with popular frameworks such as PyTorch, TensorFlow, ONNX, Keras, PaddlePaddle, and JAX/Flax. Directly integrate models built with transformers and diffusers from the Hugging Face Hub using Optimum Intel. Convert and deploy models without original frameworks.\n- **Broad Platform Compatibility**: Reduce resource demands and efficiently deploy on a range of platforms from edge to cloud. OpenVINO™ supports inference on CPU (x86, ARM), GPU (OpenCL capable, integrated and discrete) and AI accelerators (Intel NPU).\n- **Community and Ecosystem**: Join an active community contributing to the enhancement of deep learning performance across various domains.\n\nCheck out the [OpenVINO Cheat Sheet](https://docs.openvino.ai/2024/_static/download/OpenVINO_Quick_Start_Guide.pdf) and [Key Features](https://docs.openvino.ai/2024/about-openvino/key-features.html) for a quick reference.\n\n\n## Installation\n\n[Get your preferred distribution of OpenVINO](https://docs.openvino.ai/2024/get-started/install-openvino.html) or use this command for quick installation:\n\n```sh\npip install -U openvino\n```\n\nCheck [system requirements](https://docs.openvino.ai/2024/about-openvino/system-requirements.html) and [supported devices](https://docs.openvino.ai/2024/about-openvino/compatibility-and-support/supported-devices.html) for detailed information.\n\n## Tutorials and Examples\n\n[OpenVINO Quickstart example](https://docs.openvino.ai/2024/get-started.html) will walk you through the basics of deploying your first model.\n\nLearn how to optimize and deploy popular models with the [OpenVINO Notebooks](https://github.com/openvinotoolkit/openvino_notebooks)📚:\n- [Create an LLM-powered Chatbot using OpenVINO](https://github.com/openvinotoolkit/openvino_notebooks/blob/latest/notebooks/llm-chatbot/llm-chatbot-generate-api.ipynb)\n- [YOLOv11 Optimization](https://github.com/openvinotoolkit/openvino_notebooks/blob/latest/notebooks/yolov11-optimization/yolov11-object-detection.ipynb)\n- [Text-to-Image Generation](https://github.com/openvinotoolkit/openvino_notebooks/blob/latest/notebooks/text-to-image-genai/text-to-image-genai.ipynb)\n- [Multimodal assistant with LLaVa and OpenVINO](https://github.com/openvinotoolkit/openvino_notebooks/blob/latest/notebooks/llava-multimodal-chatbot/llava-multimodal-chatbot-genai.ipynb)\n- [Automatic speech recognition using Whisper and OpenVINO](https://github.com/openvinotoolkit/openvino_notebooks/blob/latest/notebooks/whisper-asr-genai/whisper-asr-genai.ipynb)\n\nDiscover more examples in the [OpenVINO Samples (Python & C++)](https://docs.openvino.ai/2024/learn-openvino/openvino-samples.html) and [Notebooks (Python)](https://docs.openvino.ai/2024/learn-openvino/interactive-tutorials-python.html).\n\nHere are easy-to-follow code examples demonstrating how to run PyTorch and TensorFlow model inference using OpenVINO:\n\n**PyTorch Model**\n\n```python\nimport openvino as ov\nimport torch\nimport torchvision\n\n# load PyTorch model into memory\nmodel = torch.hub.load(\"pytorch/vision\", \"shufflenet_v2_x1_0\", weights=\"DEFAULT\")\n\n# convert the model into OpenVINO model\nexample = torch.randn(1, 3, 224, 224)\nov_model = ov.convert_model(model, example_input=(example,))\n\n# compile the model for CPU device\ncore = ov.Core()\ncompiled_model = core.compile_model(ov_model, 'CPU')\n\n# infer the model on random data\noutput = compiled_model({0: example.numpy()})\n```\n\n**TensorFlow Model**\n\n```python\nimport numpy as np\nimport openvino as ov\nimport tensorflow as tf\n\n# load TensorFlow model into memory\nmodel = tf.keras.applications.MobileNetV2(weights='imagenet')\n\n# convert the model into OpenVINO model\nov_model = ov.convert_model(model)\n\n# compile the model for CPU device\ncore = ov.Core()\ncompiled_model = core.compile_model(ov_model, 'CPU')\n\n# infer the model on random data\ndata = np.random.rand(1, 224, 224, 3)\noutput = compiled_model({0: data})\n```\n\nOpenVINO supports the CPU, GPU, and NPU [devices](https://docs.openvino.ai/2024/openvino-workflow/running-inference/inference-devices-and-modes.html) and works with models from PyTorch, TensorFlow, ONNX, TensorFlow Lite, PaddlePaddle, and JAX/Flax [frameworks](https://docs.openvino.ai/2024/openvino-workflow/model-preparation.html). It includes [APIs](https://docs.openvino.ai/2024/api/api_reference.html) in C++, Python, C, NodeJS, and offers the GenAI API for optimized model pipelines and performance.\n\n## Generative AI with OpenVINO\n\nGet started with the OpenVINO GenAI [installation](https://docs.openvino.ai/2024/get-started/install-openvino/install-openvino-genai.html) and refer to the [detailed guide](https://docs.openvino.ai/2024/learn-openvino/llm_inference_guide/genai-guide.html) to explore the capabilities of Generative AI using OpenVINO.\n\nLearn how to run LLMs and GenAI with [Samples](https://github.com/openvinotoolkit/openvino.genai/tree/master/samples) in the [OpenVINO™ GenAI repo](https://github.com/openvinotoolkit/openvino.genai). See GenAI in action with Jupyter notebooks: [LLM-powered Chatbot](https://github.com/openvinotoolkit/openvino_notebooks/blob/latest/notebooks/llm-chatbot/README.md) and [LLM Instruction-following pipeline](https://github.com/openvinotoolkit/openvino_notebooks/blob/latest/notebooks/llm-question-answering/README.md).\n\n## Documentation\n\n[User documentation](https://docs.openvino.ai/) contains detailed information about OpenVINO and guides you from installation through optimizing and deploying models for your AI applications.\n\n[Developer documentation](./docs/dev/index.md) focuses on the OpenVINO architecture and describes [building](./docs/dev/build.md)  and [contributing](./CONTRIBUTING.md) processes.\n\n## OpenVINO Ecosystem\n\n### OpenVINO Tools\n\n-   [Neural Network Compression Framework (NNCF)](https://github.com/openvinotoolkit/nncf) - advanced model optimization techniques including quantization, filter pruning, binarization, and sparsity.\n-   [GenAI Repository](https://github.com/openvinotoolkit/openvino.genai) and [OpenVINO Tokenizers](https://github.com/openvinotoolkit/openvino_tokenizers) - resources and tools for developing and optimizing Generative AI applications.\n-   [OpenVINO™ Model Server (OVMS)](https://github.com/openvinotoolkit/model_server) - a scalable, high-performance solution for serving models optimized for Intel architectures.\n-   [Intel® Geti™](https://geti.intel.com/) - an interactive video and image annotation tool for computer vision use cases.\n\n### Integrations\n\n-   [🤗Optimum Intel](https://github.com/huggingface/optimum-intel) - grab and use models leveraging OpenVINO within the Hugging Face API.\n-   [Torch.compile](https://docs.openvino.ai/2024/openvino-workflow/torch-compile.html) - use OpenVINO for Python-native applications by JIT-compiling code into optimized kernels.\n-   [OpenVINO LLMs inference and serving with vLLM​](https://docs.vllm.ai/en/stable/getting_started/openvino-installation.html) - enhance vLLM's fast and easy model serving with the OpenVINO backend.\n-   [OpenVINO Execution Provider for ONNX Runtime](https://onnxruntime.ai/docs/execution-providers/OpenVINO-ExecutionProvider.html) - use OpenVINO as a backend with your existing ONNX Runtime code.\n-   [LlamaIndex](https://docs.llamaindex.ai/en/stable/examples/llm/openvino/) - build context-augmented GenAI applications with the LlamaIndex framework and enhance runtime performance with OpenVINO.\n-   [LangChain](https://python.langchain.com/docs/integrations/llms/openvino/) - integrate OpenVINO with the LangChain framework to enhance runtime performance for GenAI applications.\n-   [Keras 3](https://github.com/keras-team/keras) - Keras 3 is a multi-backend deep learning framework. Users can switch model inference to the OpenVINO backend using the Keras API.\n\nCheck out the [Awesome OpenVINO](https://github.com/openvinotoolkit/awesome-openvino) repository to discover a collection of community-made AI projects based on OpenVINO!\n\n## Performance\n\nExplore [OpenVINO Performance Benchmarks](https://docs.openvino.ai/2024/about-openvino/performance-benchmarks.html) to discover the optimal hardware configurations and plan your AI deployment based on verified data.\n\n## Contribution and Support\n\nCheck out [Contribution Guidelines](./CONTRIBUTING.md) for more details.\nRead the [Good First Issues section](./CONTRIBUTING.md#3-start-working-on-your-good-first-issue), if you're looking for a place to start contributing. We welcome contributions of all kinds!\n\nYou can ask questions and get support on:\n\n* [GitHub Issues](https://github.com/openvinotoolkit/openvino/issues).\n* OpenVINO channels on the [Intel DevHub Discord server](https://discord.gg/7pVRxUwdWG).\n* The [`openvino`](https://stackoverflow.com/questions/tagged/openvino) tag on Stack Overflow\\*.\n\n\n## Resources\n\n* [Release Notes](https://docs.openvino.ai/2024/about-openvino/release-notes-openvino.html)\n* [OpenVINO Blog](https://blog.openvino.ai/)\n* [OpenVINO™ toolkit on Medium](https://medium.com/@openvino)\n\n\n## Telemetry\n\nOpenVINO™ collects software performance and usage data for the purpose of improving OpenVINO™ tools.\nThis data is collected directly by OpenVINO™ or through the use of Google Analytics 4.\nYou can opt-out at any time by running the command:\n\n``` bash\nopt_in_out --opt_out\n```\n\nMore Information is available at [OpenVINO™ Telemetry](https://docs.openvino.ai/2024/about-openvino/additional-resources/telemetry.html).\n\n## License\n\nOpenVINO™ Toolkit is licensed under [Apache License Version 2.0](LICENSE).\nBy contributing to the project, you agree to the license and copyright terms therein and release your contribution under these terms.\n\n---\n\\* Other names and brands may be claimed as the property of others.\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.673828125,
          "content": "# Security Policy\n\n## Security practices\n\n[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/9611/badge)](https://www.bestpractices.dev/projects/9611)\n[![Coverity](https://scan.coverity.com/projects/21921/badge.svg)](https://scan.coverity.com/projects/openvino)\n\n## Report a Vulnerability\n\nPlease report security issues or vulnerabilities to the [Intel® Security Center].\n\nFor more information on how Intel® works to resolve security issues, see\n[Vulnerability Handling Guidelines].\n\n[Intel® Security Center]:https://www.intel.com/security\n\n[Vulnerability Handling Guidelines]:https://www.intel.com/content/www/us/en/security-center/vulnerability-handling-guidelines.html\n"
        },
        {
          "name": "cmake",
          "type": "tree",
          "content": null
        },
        {
          "name": "conan.lock",
          "type": "blob",
          "size": 2.119140625,
          "content": "{\n    \"version\": \"0.5\",\n    \"requires\": [\n        \"xbyak/6.73#250bc3bc73379f90f255876c1c00a4cd%1691853024.351\",\n        \"snappy/1.1.10#916523630083f6d855cb2977de8eefb6%1689780661.062\",\n        \"rapidjson/cci.20220822#8ca51918340f3a21127822258e95ec0f%1663194355.698\",\n        \"pybind11/2.12.0#1bf487c19d580200ba9b74afcc4174b4%1711607911.876\",\n        \"pugixml/1.13#f615c1fcec55122b2e177d17061276e7%1691917296.869\",\n        \"protobuf/3.21.12#d9f5f4e3b86552552dda4c0a2e928eeb%1685218275.69\",\n        \"opencl-icd-loader/2023.04.17#5f73dd9f0c023d416a7f162e320b9c77%1692732261.088\",\n        \"opencl-headers/2023.04.17#3d98f2d12a67c2400de6f11d5335b5a6%1683936272.16\",\n        \"opencl-clhpp-headers/2023.04.17#7c62fcc7ac2559d4839150d2ebaac5c8%1685450803.672\",\n        \"onnx/1.17.0#c79fdfca3ae149874153de15a20f4598%1727864447.241\",\n        \"onetbb/2021.10.0#cbb2fc43088070b48f6e4339bc8fa0e1%1693812561.235\",\n        \"ittapi/3.24.0#9246125f13e7686dee2b0c992b71db94%1682969872.743\",\n        \"hwloc/2.9.2#1c63e2eccac57048ae226e6c946ebf0e%1688677682.002\",\n        \"flatbuffers/23.5.26#b153646f6546daab4c7326970b6cd89c%1685838458.449\"\n    ],\n    \"build_requires\": [\n        \"zlib/1.2.13#97d5730b529b4224045fe7090592d4c1%1692672717.049\",\n        \"protobuf/3.21.12#d9f5f4e3b86552552dda4c0a2e928eeb%1685218275.69\",\n        \"pkgconf/1.9.5#743ca0d41d35a84b1f89af337ddaa1a0%1688570267.802\",\n        \"patchelf/0.13#0eaada8970834919c3ce14355afe7fac%1680534241.341\",\n        \"ninja/1.11.1#77587f8c8318662ac8e5a7867eb4be21%1684431244.21\",\n        \"meson/1.0.0#15586c0ac6f682805875ef903dbe7ee2%1673885561.647\",\n        \"m4/1.4.19#c1c4b1ee919e34630bb9b50046253d3c%1676610086.39\",\n        \"libtool/2.4.6#9ee8efc04c2e106e7fba13bb1e477617%1677509454.345\",\n        \"gnu-config/cci.20210814#15c3bf7dfdb743977b84d0321534ad90%1681250000.747\",\n        \"flatbuffers/23.5.26#b153646f6546daab4c7326970b6cd89c%1685838458.449\",\n        \"cmake/3.27.4#a7e78418b024dccacccc887f049f47ed%1693515860.005\",\n        \"automake/1.16.5#058bda3e21c36c9aa8425daf3c1faf50%1688481772.751\",\n        \"autoconf/2.71#53be95d228b2dcb30dc199cb84262d8f%1693395343.513\"\n    ],\n    \"python_requires\": [],\n    \"config_requires\": []\n}\n"
        },
        {
          "name": "conanfile.txt",
          "type": "blob",
          "size": 0.4697265625,
          "content": "[requires]\nonetbb/[>=2021.2.1]\npugixml/[>=1.10]\nprotobuf/3.21.12\nittapi/[>=3.23.0]\nopencl-icd-loader/[>=2023.04.17]\nrapidjson/[>=1.1.0]\nxbyak/[>=6.62]\nsnappy/[>=1.1.7]\nonnx/1.17.0\npybind11/[>=2.12.0]\nflatbuffers/[>=22.9.24]\n\n[tool_requires]\ncmake/[>=3.20]\npkgconf/1.9.5\npatchelf/[>=0.12]\nprotobuf/3.21.12\nflatbuffers/[>=22.9.24]\n\n[options]\nprotobuf/*:lite=True\nprotobuf/*:with_zlib=False\nprotobuf/*:shared=False\nflatbuffers/*:header_only=True\n\n[generators]\nCMakeDeps\nCMakeToolchain"
        },
        {
          "name": "cspell.json",
          "type": "blob",
          "size": 7.61328125,
          "content": "{\n    \"version\": \"0.2\",\n    \"ignorePaths\": [],\n    \"dictionaryDefinitions\": [],\n    \"dictionaries\": [],\n    \"words\": [\n        \"aarch64\",\n        \"acdadcfa\",\n        \"acea\",\n        \"abmrd\",\n        \"acfb\",\n        \"acosh\",\n        \"Acosh\",\n        \"adfcd\",\n        \"addcmul\",\n        \"addif\",\n        \"addmm\",\n        \"aeaa\",\n        \"agem\",\n        \"agew\",\n        \"armeabi\",\n        \"armhf\",\n        \"artefacts\",\n        \"ARTEFACTS\",\n        \"Asinh\",\n        \"asynch\",\n        \"Atanh\",\n        \"autodoc\",\n        \"Autograd\",\n        \"autoplugin\",\n        \"AUTOPLUGIN\",\n        \"autoremove\",\n        \"autosummary\",\n        \"bace\",\n        \"Backprop\",\n        \"bblayers\",\n        \"Beautif\",\n        \"Bilat\",\n        \"bindir\",\n        \"bitbake\",\n        \"BFYX\",\n        \"BFXY\",\n        \"bkgr\",\n        \"brctl\",\n        \"Bucketize\",\n        \"BUILDDIR\",\n        \"buildtools\",\n        \"buildsystems\",\n        \"BYXF\",\n        \"bvalue\",\n        \"bvlc\",\n        \"caffe\",\n        \"caffemodel\",\n        \"camvid\",\n        \"cbba\",\n        \"cbcd\",\n        \"cdad\",\n        \"cdrom\",\n        \"chrpath\",\n        \"classov\",\n        \"cldnn\",\n        \"clumber\",\n        \"codepath\",\n        \"codepaths\",\n        \"coeffs\",\n        \"concat\",\n        \"Concat\",\n        \"Conts\",\n        \"constexpr\",\n        \"consts\",\n        \"Consts\",\n        \"conv\",\n        \"Convolutional\",\n        \"CPPLINT\",\n        \"cpplint\",\n        \"crbegin\",\n        \"crend\",\n        \"ctest\",\n        \"ctput\",\n        \"CVAT\",\n        \"cython\",\n        \"dadb\",\n        \"DANDROID\",\n        \"DARM\",\n        \"Datumaro\",\n        \"datumaro\",\n        \"DBUILD\",\n        \"DCMAKE\",\n        \"ddepth\",\n        \"Depthwise\",\n        \"dearmor\",\n        \"devicesupport\",\n        \"dequantization\",\n        \"Dequantization\",\n        \"deeplabv\",\n        \"deeced\",\n        \"DENABLE\",\n        \"delif\",\n        \"denormal\",\n        \"DENORMAL\",\n        \"denormalized\",\n        \"Detectron\",\n        \"Dequantize\",\n        \"devel\",\n        \"devtoolset\",\n        \"dgpu\",\n        \"diffstat\",\n        \"dldt\",\n        \"dlstreamer\",\n        \"dkms\",\n        \"Dockerfiles\",\n        \"DOPENVINO\",\n        \"downscript\",\n        \"doxid\",\n        \"doxygen\",\n        \"Doxygen\",\n        \"doxygensnippet\",\n        \"DTHREADING\",\n        \"dpkg\",\n        \"DPYTHON\",\n        \"DSELECTIVE\",\n        \"dylib\",\n        \"DWORD\",\n        \"efficientdet\",\n        \"Efficientdet\",\n        \"Einsum\",\n        \"Elems\",\n        \"Elementwise\",\n        \"elementwise\",\n        \"Eltwise\",\n        \"endsphinxdirective\",\n        \"enumov\",\n        \"emcmake\",\n        \"emmake\",\n        \"emod\",\n        \"emom\",\n        \"emow\",\n        \"Emscripten\",\n        \"emscripten\",\n        \"emsdk\",\n        \"epel\",\n        \"ERRORLEVEL\",\n        \"evolutionally\",\n        \"executionpolicy\",\n        \"fafe\",\n        \"fdupes\",\n        \"flatbuffers\",\n        \"FLATBUFFERS\",\n        \"frontends\",\n        \"Frontends\",\n        \"FYXB\",\n        \"gaddb\",\n        \"GAPI\",\n        \"gapi\",\n        \"Gaussed\",\n        \"gcompoundkernel\",\n        \"gcomputation\",\n        \"GCPU\",\n        \"gcpukernel\",\n        \"Gelu\",\n        \"GELU\",\n        \"Geti\",\n        \"getitem\",\n        \"gimg\",\n        \"gitee\",\n        \"gflags\",\n        \"globbing\",\n        \"gmmlib\",\n        \"GNAs\",\n        \"gmock\",\n        \"gnueabihf\",\n        \"googlenet\",\n        \"gpgcheck\",\n        \"gpgkey\",\n        \"graphviz\",\n        \"Graphviz\",\n        \"groupov\",\n        \"gtest\",\n        \"hardtanh\",\n        \"hashfile\",\n        \"HDDL\",\n        \"HKLM\",\n        \"HOSTTOOLS\",\n        \"Hotspots\",\n        \"hotspots\",\n        \"hostnet\",\n        \"hwloc\",\n        \"hwquote\",\n        \"idbf\",\n        \"IDFT\",\n        \"iigd\",\n        \"ifdef\",\n        \"ifdown\",\n        \"ifup\",\n        \"imgproc\",\n        \"imshow\",\n        \"inet\",\n        \"INTEGRITYCHECK\",\n        \"ILSVRC\",\n        \"inferenced\",\n        \"Informations\",\n        \"insmod\",\n        \"intelocl\",\n        \"INTERPROCEDURAL\",\n        \"INSTALLDIR\",\n        \"IRDFT\",\n        \"jemalloc\",\n        \"kaldi\",\n        \"Keras\",\n        \"keypress\",\n        \"keyrings\",\n        \"Khronos\",\n        \"KROIs\",\n        \"Landm\",\n        \"landm\",\n        \"Latency\",\n        \"Lcov\",\n        \"ldconfig\",\n        \"libc\",\n        \"libopencl\",\n        \"libopencv\",\n        \"libpython\",\n        \"libtbb\",\n        \"libtbbbind\",\n        \"libtpm\",\n        \"libvirtd\",\n        \"linmac\",\n        \"Liskov\",\n        \"lowlatency\",\n        \"LTSC\",\n        \"LSTM\",\n        \"makefiles\",\n        \"malloc\",\n        \"memleaks\",\n        \"manylinux\",\n        \"maxdepth\",\n        \"miktext\",\n        \"Mish\",\n        \"mklink\",\n        \"mmap\",\n        \"mobilenet\",\n        \"Mobilenet\",\n        \"monodepth\",\n        \"mozallowfullscreen\",\n        \"msallowfullscreen\",\n        \"MSVC\",\n        \"msvc\",\n        \"Multiclass\",\n        \"muxed\",\n        \"mxnet\",\n        \"namespaceov\",\n        \"NCHW\",\n        \"ncpu\",\n        \"netdev\",\n        \"netplan\",\n        \"ngraph\",\n        \"nireq\",\n        \"NNCF\",\n        \"nncf\",\n        \"nocache\",\n        \"noglob\",\n        \"nohup\",\n        \"nlohmann\",\n        \"norestart\",\n        \"noqueue\",\n        \"nproc\",\n        \"NUMA\",\n        \"numpy\",\n        \"Numpy\",\n        \"oallowfullscreen\",\n        \"ocloc\",\n        \"OCSP\",\n        \"oneapi\",\n        \"onetbb\",\n        \"onnx\",\n        \"opencl\",\n        \"openembedded\",\n        \"openvino\",\n        \"Opset\",\n        \"opset\",\n        \"opsets\",\n        \"OVMS\",\n        \"ovms\",\n        \"ovsa\",\n        \"OVSA\",\n        \"ovsatool\",\n        \"OVTF\",\n        \"PACKAGECONFIG\",\n        \"paddlepaddle\",\n        \"parameterizable\",\n        \"partitioner\",\n        \"patchelf\",\n        \"passpattern\",\n        \"Pexels\",\n        \"pdmodel\",\n        \"PDPD\",\n        \"pkgdata\",\n        \"pkgs\",\n        \"pkill\",\n        \"polylines\",\n        \"postproc\",\n        \"postprocess\",\n        \"preprocess\",\n        \"Preprocess\",\n        \"protobuf\",\n        \"Protobuf\",\n        \"PROTOBUF\",\n        \"prototxt\",\n        \"PSROI\",\n        \"Pugi\",\n        \"pugixml\",\n        \"PUGIXML\",\n        \"pypi\",\n        \"PYTHONPATH\",\n        \"pzstd\",\n        \"qcow\",\n        \"qlen\",\n        \"QSPECTRE\",\n        \"Qspectre\",\n        \"quantizer\",\n        \"Rects\",\n        \"Relu\",\n        \"relu\",\n        \"rcnn\",\n        \"RCNN\",\n        \"RDFT\",\n        \"Redistributable\",\n        \"remotesigned\",\n        \"repolist\",\n        \"reproject\",\n        \"reshapable\",\n        \"Requantize\",\n        \"retval\",\n        \"RHODS\",\n        \"rmmod\",\n        \"runtool\",\n        \"scons\",\n        \"SCONS\",\n        \"segm\",\n        \"Selu\",\n        \"servercore\",\n        \"setuptools\",\n        \"setupvars\",\n        \"SETX\",\n        \"SIMD\",\n        \"Softmax\",\n        \"skylake\",\n        \"sphinxdirective\",\n        \"Strided\",\n        \"squeezenet\",\n        \"SWTPM\",\n        \"swtpm\",\n        \"TBBBIND\",\n        \"TBBROOT\",\n        \"Tensro\",\n        \"texlive\",\n        \"textrm\",\n        \"tflite\",\n        \"thirdparty\",\n        \"Thresholded\",\n        \"toctree\",\n        \"toolset\",\n        \"Torchvision\",\n        \"tpmrm\",\n        \"tpmstate\",\n        \"tput\",\n        \"Tunables\",\n        \"unet\",\n        \"Uninstallation\",\n        \"unixio\",\n        \"unsharp\",\n        \"Unsharp\",\n        \"Unsh\",\n        \"Unsqueeze\",\n        \"Usecase\",\n        \"usecases\",\n        \"USERPROFILE\",\n        \"userspace\",\n        \"VAAPI\",\n        \"valgrind\",\n        \"vcpkg\",\n        \"vcvars\",\n        \"venv\",\n        \"virbr\",\n        \"virsh\",\n        \"virt\",\n        \"virtio\",\n        \"VMHWM\",\n        \"VMRSS\",\n        \"VNNI\",\n        \"vtune\",\n        \"vtunesummary\",\n        \"vtunebottonup\",\n        \"WHOLEARCHIVE\",\n        \"WDDM\",\n        \"WORKDIR\",\n        \"WORKSIZE\",\n        \"xbyak\",\n        \"Xbyak\",\n        \"xdot\",\n        \"xvfz\",\n        \"yocto\",\n        \"yolo\",\n        \"YOLO\",\n        \"yolov\",\n        \"Yolov\",\n        \"YXFB\",\n        \"zstd\"\n    ],\n    \"ignoreWords\": [],\n    \"import\": []\n}\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "install_build_dependencies.sh",
          "type": "blob",
          "size": 9.517578125,
          "content": "#!/bin/bash\n\n# Copyright (C) 2018-2024 Intel Corporation\n# SPDX-License-Identifier: Apache-2.0\n\nif [ $EUID -ne 0 ]; then\n    echo \"ERROR: this script must be run as root to install 3rd party packages.\" >&2\n    echo \"Please try again with \\\"sudo -E $0\\\", or as root.\" >&2\n    exit 1\nfi\n\n# install dependencies\nif [ -f /etc/lsb-release ] || [ -f /etc/debian_version ] ; then\n    # Ubuntu\n    host_cpu=$(uname -m)\n\n    x86_64_specific_packages=()\n    if [ \"$host_cpu\" = \"x86_64\" ]; then\n        # to build 32-bit or ARM binaries on 64-bit host\n        x86_64_specific_packages+=(gcc-multilib g++-multilib)\n    fi\n\n    if ! command -v cmake &> /dev/null; then\n        cmake_packages=(cmake)\n    fi\n\n    apt update\n    apt-get install -y --no-install-recommends \\\n        `# for python3-pip` \\\n        ca-certificates \\\n        file \\\n        `# build tools` \\\n        build-essential \\\n        ninja-build \\\n        scons \\\n        ccache \\\n        \"${cmake_packages[@]}\" \\\n        \"${x86_64_specific_packages[@]}\" \\\n        `# to find dependencies` \\\n        pkgconf \\\n        `# to deternime product version via git` \\\n        git \\\n        `# check bash scripts for correctness` \\\n        shellcheck \\\n        `# to build and check pip packages` \\\n        patchelf \\\n        fdupes \\\n        `# archive debian changelog file` \\\n        gzip \\\n        `# to check debian package correctness` \\\n        lintian \\\n        `# openvino main dependencies` \\\n        libtbb-dev \\\n        libpugixml-dev \\\n        `# OpenCL for GPU` \\\n        ocl-icd-opencl-dev \\\n        opencl-headers \\\n        rapidjson-dev \\\n        `# GPU plugin extensions` \\\n        libva-dev \\\n        `# For TF FE saved models` \\\n        libsnappy-dev \\\n        `# python API` \\\n        python3-pip \\\n        python3-venv \\\n        python3-setuptools \\\n        libpython3-dev \\\n        pybind11-dev \\\n        libffi-dev \\\n        `# spell checking for MO sources` \\\n        python3-enchant \\\n        `# tools` \\\n        wget\n    # TF lite frontend\n    if apt-cache search --names-only '^libflatbuffers-dev'| grep -q libflatbuffers-dev; then\n        apt-get install -y --no-install-recommends libflatbuffers-dev\n    fi\n    # git-lfs is not available on debian9\n    if apt-cache search --names-only '^git-lfs'| grep -q git-lfs; then\n        apt-get install -y --no-install-recommends git-lfs\n    fi\n    # for python3-enchant\n    if apt-cache search --names-only 'libenchant1c2a'| grep -q libenchant1c2a; then\n        apt-get install -y --no-install-recommends libenchant1c2a\n    fi\n    # samples\n    if apt-cache search --names-only '^nlohmann-json3-dev'| grep -q nlohmann-json3; then\n        apt-get install -y --no-install-recommends nlohmann-json3-dev\n    else\n        apt-get install -y --no-install-recommends nlohmann-json-dev\n    fi\nelif [ -f /etc/redhat-release ] || grep -q \"rhel\\|tencentos\\|opencloudos\" /etc/os-release ; then\n    yum update\n    # RHEL 8 / CentOS 7\n    if [ -f /etc/redhat-release ] || grep -q \"rhel\" /etc/os-release ; then\n        yum install -y centos-release-scl\n        yum install -y epel-release\n        yum install -y \\\n            `# to build and check pip packages` \\\n            patchelf \\\n            `# check bash scripts for correctness` \\\n            ShellCheck\n    else\n        yum install -y epol-release\n    fi\n    yum install -y \\\n        file \\\n        `# build tools` \\\n        cmake3 \\\n        ccache \\\n        ninja-build \\\n        scons \\\n        gcc \\\n        gcc-c++ \\\n        make \\\n        `# to determine openvino version via git` \\\n        git \\\n        fdupes \\\n        `# to build and check rpm packages` \\\n        rpm-build \\\n        rpmlint \\\n        `# main openvino dependencies` \\\n        tbb-devel \\\n        pugixml-devel \\\n        `# GPU plugin dependency` \\\n        libva-devel \\\n        `# For TF FE saved models` \\\n        snappy-devel \\\n        `# OpenCL for GPU` \\\n        ocl-icd-devel \\\n        opencl-headers \\\n        `# python API` \\\n        python3-pip \\\n        python3-devel\nelif [ -f /etc/os-release ] && grep -q \"SUSE\" /etc/os-release ; then\n    zypper refresh\n    zypper install -y \\\n        file \\\n        `# build tools` \\\n        patterns-devel-C-C++-devel_C_C++ \\\n        cmake \\\n        ccache \\\n        ninja \\\n        scons \\\n        gcc \\\n        gcc-c++ \\\n        make \\\n        `# to determine openvino version via git` \\\n        git \\\n        `# to build and check pip packages` \\\n        patchelf \\\n        fdupes \\\n        `# to build and check rpm packages` \\\n        rpm-build \\\n        rpmlint \\\n        `# check bash scripts for correctness` \\\n        ShellCheck \\\n        `# main openvino dependencies` \\\n        tbb-devel \\\n        pugixml-devel \\\n        `# GPU plugin dependency` \\\n        libva-devel \\\n        `# For TF FE saved models` \\\n        snappy-devel \\\n        `# OpenCL for GPU` \\\n        ocl-icd-devel \\\n        opencl-cpp-headers \\\n        opencl-headers \\\n        `# python API` \\\n        python39-pip \\\n        python39-setuptools \\\n        python39-devel\nelif [ -f /etc/os-release ] && grep -q \"raspbian\" /etc/os-release; then\n    # Raspbian\n    apt update\n    apt-get install -y --no-install-recommends \\\n        file \\\n        `# build tools` \\\n        build-essential \\\n        ccache \\\n        ninja-build \\\n        scons \\\n        `# to find dependencies` \\\n        pkg-config \\\n        `# to determine product version via git` \\\n        git \\\n        `# to build and check pip packages` \\\n        patchelf \\\n        fdupes \\\n        `# archive debian changelog file` \\\n        gzip \\\n        `# openvino main dependencies` \\\n        libtbb-dev \\\n        libpugixml-dev \\\n        `# python API` \\\n        python3-pip \\\n        python3-venv \\\n        python3-setuptools \\\n        libpython3-dev\nelif [ -f /etc/os-release ] && grep -q \"void\" /etc/os-release; then\n    #Void Linux\n    xbps-install -Syu\n    xbps-install -y \\\n        `# for python3-pip` \\\n        `# ca-certificates (already included)` \\\n        file \\\n        `# build tools` \\\n        base-devel \\\n        ninja \\\n        scons \\\n        ccache \\\n        cmake \\\n        `# to find dependencies` \\\n        pkgconf \\\n        `# to determine product version via git` \\\n        git \\\n        `# to check bash scripts for correctness` \\\n        shellcheck \\\n        `# to build and check pip packages` \\\n        patchelf \\\n        fdupes \\\n        `# main openvino dependencies` \\\n        tbb-devel \\\n        pugixml-devel \\\n        `# OpenCL for GPU` \\\n        ocl-icd-devel \\\n        OpenCL-Headers \\\n        OpenCL-CLHPP \\\n        rapidjson \\\n        `# GPU plugin dependency` \\\n        libva-devel \\\n        `# For TF FE saved models` \\\n        snappy-devel \\\n        `# For Python API` \\\n        python3-pip \\\n        python3-wheel \\\n        python3-setuptools \\\n        python3-devel \\\n        python3-pybind11 \\\n        libffi-devel \\\n        `# Spell checking for MO sources` \\\n        python3-enchant \\\n        `# tools` \\\n        wget \\\n        git-lfs \\\n        `# TF Lite Frontend` \\\n        flatbuffers-devel \\\n        `# for python3-enchant` \\\n        enchant2-devel \\\n        `# samples` \\\n        json-c++\nelif [ -f /etc/os-release ] && grep -q \"alpine\" /etc/os-release; then\n    #Alpine Linux\n    apk --no-cache add \\\n        `# for python3-pip` \\\n\tca-certificates \\\n        file \\\n        `# build tools` \\\n        build-base \\\n        ninja-is-really-ninja \\\n        scons \\\n        ccache \\\n        cmake \\\n        `# to find dependencies` \\\n        pkgconf \\\n        `# to determine product version via git` \\\n        git \\\n        `# to check bash scripts for correctness` \\\n        shellcheck \\\n        `# to build and check pip packages` \\\n        patchelf \\\n        fdupes \\\n        `# main openvino dependencies` \\\n        onetbb-dev \\\n        py3-tbb \\\n        pugixml-dev \\\n        `# OpenCL for GPU` \\\n        opencl-dev `#(includes opencl-headers)`\\\n        rapidjson-dev \\\n        `# GPU plugin dependency` \\\n        libva-dev \\\n        `# For TF FE saved models` \\\n        snappy-dev \\\n        `# For Python API` \\\n        py3-pip `#(includes py3-setuptools)`\\\n        py3-wheel \\\n        py3-virtualenv \\\n        python3-dev \\\n        py3-pybind11-dev \\\n        libffi-dev \\\n        `# Spell checking for MO sources` \\\n        py3-enchant \\\n        `# tools` \\\n        wget \\\n        git-lfs \\\n        `# TF Lite Frontend` \\\n        flatbuffers-dev \\\n        `# for python3-enchant` \\\n        enchant2 \\\n        `# samples` \\\n        nlohmann-json\nelse\n    echo \"Unknown OS, please install build dependencies manually\"\nfi\n\n# cmake 3.20.0 or higher is required to build OpenVINO\n\nif command -v cmake &> /dev/null; then\n    cmake_command=cmake\nelif command -v cmake3 &> /dev/null; then\n    cmake_command=cmake3\nfi\n\ncurrent_cmake_ver=$($cmake_command --version | sed -ne 's/[^0-9]*\\(\\([0-9]\\.\\)\\{0,4\\}[0-9][^.]\\).*/\\1/p')\nrequired_cmake_ver=3.24.0\nif [ ! \"$(printf '%s\\n' \"$required_cmake_ver\" \"$current_cmake_ver\" | sort -V | head -n1)\" = \"$required_cmake_ver\" ]; then\n    installed_cmake_ver=3.26.0\n    arch=$(uname -m)\n\n    if command -v apt-get &> /dev/null; then\n        apt-get install -y --no-install-recommends wget\n    elif command -v yum &> /dev/null; then\n        yum install -y wget\n    elif command -v zypper &> /dev/null; then\n        zypper in -y wget\n    fi\n\n    cmake_install_bin=\"cmake-${installed_cmake_ver}-linux-${arch}.sh\"\n    github_cmake_release=\"https://github.com/Kitware/CMake/releases/download/v${installed_cmake_ver}/${cmake_install_bin}\"\n    wget \"${github_cmake_release}\" -O \"${cmake_install_bin}\"\n    chmod +x \"${cmake_install_bin}\"\n    \"./${cmake_install_bin}\" --skip-license --prefix=/usr/local\n    rm -rf \"${cmake_install_bin}\"\nfi\n"
        },
        {
          "name": "licensing",
          "type": "tree",
          "content": null
        },
        {
          "name": "samples",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "thirdparty",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "vcpkg.json",
          "type": "blob",
          "size": 4.57421875,
          "content": "{\n    \"$schema\": \"https://raw.githubusercontent.com/microsoft/vcpkg-tool/main/docs/vcpkg.schema.json\",\n    \"name\": \"openvino\",\n    \"version\": \"2025.0.0\",\n    \"maintainers\": \"OpenVINO Developers <openvino@intel.com>\",\n    \"summary\": \"This is a port for Open Visual Inference And Optimization toolkit for AI inference\",\n    \"description\": [\n        \"Intel® Distribution of OpenVINO™ toolkit is an open-source toolkit for optimizing \",\n        \"and deploying AI inference. It can be used to develop applications and solutions based \",\n        \"on deep learning tasks, such as: emulation of human vision, automatic speech recognition, \",\n        \"natural language processing, recommendation systems, etc. It provides high-performance \",\n        \"and rich deployment options, from edge to cloud\"\n    ],\n    \"homepage\": \"https://github.com/openvinotoolkit/openvino\",\n    \"documentation\": \"https://docs.openvino.ai/latest/index.html\",\n    \"license\": \"Apache-2.0\",\n    \"builtin-baseline\": \"b322364f06308bdd24823f9d8f03fe0cc86fd46f\",\n    \"dependencies\": [\n        {\n            \"name\": \"pkgconf\",\n            \"host\": true\n        },\n        \"pugixml\",\n        {\n            \"name\": \"tbb\",\n            \"version>=\": \"2021.10.0#2\"\n        },\n        \"rapidjson\",\n        {\n            \"name\": \"xbyak\",\n            \"platform\": \"!(arm | uwp)\",\n            \"version>=\": \"6.69\"\n        }\n    ],\n    \"default-features\": [\n        \"auto\",\n        \"auto-batch\",\n        {\n          \"name\": \"cpu\",\n          \"platform\": \"!(windows & arm)\"\n        },\n        {\n          \"name\": \"gpu\",\n          \"platform\": \"(x64 | arm64) & !(arm64 & windows) & !(osx | uwp)\"\n        },\n        \"hetero\",\n        \"ir\",\n        \"onnx\",\n        \"paddle\",\n        \"pytorch\",\n        \"tensorflow\",\n        \"tensorflow-lite\"\n      ],\n    \"features\": {\n        \"auto\": {\n            \"description\": \"Enables Auto plugin for inference\"\n        },\n        \"auto-batch\": {\n            \"description\": \"Enables Auto Batch plugin for inference, useful for throughput mode\"\n        },\n        \"cpu\": {\n            \"description\": \"Enables CPU plugin for inference\",\n            \"supports\": \"!(windows & arm)\"\n        },\n        \"gpu\": {\n            \"description\": \"Enables GPU plugin for inference\",\n            \"supports\": \"(x64 | arm64) & !(arm64 & windows) & !(osx | uwp)\",\n            \"dependencies\": [\n                \"opencl\"\n            ]\n        },\n        \"hetero\": {\n            \"description\": \"Enables Hetero plugin for inference\"\n        },\n        \"ir\": {\n            \"description\": \"Enables IR frontend for reading models in OpenVINO IR format\"\n        },\n        \"onnx\": {\n            \"description\": \"Enables ONNX frontend for reading models in ONNX format\",\n            \"dependencies\": [\n                {\n                    \"name\": \"onnx\",\n                    \"version>=\": \"1.16.2\"\n                },\n                {\n                    \"name\": \"protobuf\",\n                    \"version>=\": \"3.21.2\"\n                },\n                {\n                    \"name\": \"protobuf\",\n                    \"host\": true,\n                    \"version>=\": \"3.21.2\"\n                }\n            ]\n        },\n        \"paddle\": {\n            \"description\": \"Enables PaddlePaddle frontend for reading models in PaddlePaddle format\",\n            \"dependencies\": [\n                {\n                    \"name\": \"protobuf\",\n                    \"version>=\": \"3.21.2\"\n                },\n                {\n                    \"name\": \"protobuf\",\n                    \"host\": true,\n                    \"version>=\": \"3.21.2\"\n                }\n            ]\n        },\n        \"pytorch\": {\n            \"description\": \"Enables PyTorch frontend to convert models in PyTorch format\"\n        },\n        \"tensorflow\": {\n            \"description\": \"Enables TensorFlow frontend for reading models in TensorFlow format\",\n            \"dependencies\": [\n                {\n                    \"name\": \"protobuf\",\n                    \"version>=\": \"3.21.2\"\n                },\n                {\n                    \"name\": \"protobuf\",\n                    \"host\": true,\n                    \"version>=\": \"3.21.2\"\n                },\n                \"snappy\"\n            ]\n        },\n        \"tensorflow-lite\": {\n            \"description\": \"Enables TensorFlow Lite frontend for reading models in TensorFlow Lite format\",\n            \"dependencies\": [\n                {\n                    \"name\": \"flatbuffers\",\n                    \"version>=\": \"2.0.6\"\n                },\n                {\n                    \"name\": \"flatbuffers\",\n                    \"host\": true,\n                    \"version>=\": \"2.0.6\"\n                }\n            ]\n        }\n    }\n}\n"
        }
      ]
    }
  ]
}