{
  "metadata": {
    "timestamp": 1736566233539,
    "page": 248,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI1MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "mlpack/mlpack",
      "stars": 5192,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".ci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.15234375,
          "content": "build*/\nxcode*\n.DS_Store\n.vscode\nsrc/mlpack/core/util/gitversion.hpp\nsrc/mlpack/core/util/arma_config.hpp\n.idea\ncmake-build-*\n*.pyc\nTesting/\n*.swp\n*.swo\n*~\n"
        },
        {
          "name": "CMake",
          "type": "tree",
          "content": null
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 22.1943359375,
          "content": "cmake_minimum_required(VERSION 3.6)\nproject(mlpack C CXX)\n\ninclude(CMake/CheckHash.cmake)\ninclude(CMake/Autodownload.cmake)\ninclude(CMake/ConfigureCrossCompile.cmake)\ninclude(CMake/CheckAtomic.cmake)\n\n# First, define all the compilation options.\n# We default to debugging mode for developers.\noption(DEBUG \"Compile with debugging information.\" OFF)\noption(PROFILE \"Compile with profiling information.\" OFF)\noption(ARMA_EXTRA_DEBUG \"Compile with extra Armadillo debugging symbols.\" OFF)\noption(TEST_VERBOSE \"Run test cases with verbose output.\" OFF)\noption(BUILD_TESTS \"Build tests. (Note: time consuming!)\" OFF)\noption(BUILD_CLI_EXECUTABLES \"Build command-line executables.\" ON)\noption(DOWNLOAD_DEPENDENCIES \"Automatically download dependencies if not available.\" OFF)\noption(BUILD_GO_SHLIB \"Build Go shared library.\" OFF)\noption(USE_PRECOMPILED_HEADERS \"Use precompiled headers for mlpack_test build.\" ON)\n\n# Set minimum library versions required by mlpack.\n#\n# For Armadillo, try to keep the minimum required version less than or equal to\n# what's available on the current Ubuntu LTS or most recent stable RHEL release.\n# See https://github.com/mlpack/mlpack/issues/3033 for some more discussion.\nset(ARMADILLO_VERSION \"10.8\")\nset(ENSMALLEN_VERSION \"2.10.0\")\nset(CEREAL_VERSION \"1.1.2\")\n\n# Consider using ccache\nfind_program(CCACHE_PROGRAM ccache)\nif(CCACHE_PROGRAM)\n  set_property(GLOBAL PROPERTY RULE_LAUNCH_COMPILE \"${CCACHE_PROGRAM}\")\nendif()\n\n# If BUILD_SHARED_LIBS is OFF then the mlpack library will be built statically.\n# In addition, all mlpack CLI bindings will be linked statically as well.\nif (WIN32)\n  option(BUILD_SHARED_LIBS\n      \"Compile shared objects for tests and bindings (if OFF, static libraries and binaries are compiled).\" OFF)\n\n  set(DLL_COPY_DIRS \"\" CACHE STRING \"List of directories (separated by ';') containing DLLs to copy for runtime.\")\n  set(DLL_COPY_LIBS \"\" CACHE STRING \"List of DLLs (separated by ';') that should be copied for runtime.\")\nelseif(CMAKE_CROSSCOMPILING)\n  option(BUILD_SHARED_LIBS\n      \"Compile shared libraries (if OFF, static libraries and binaries are compiled).\" OFF)\nelse()\n  option(BUILD_SHARED_LIBS\n      \"Compile shared objects for tests and bindings (if OFF, static libraries and binaries are compiled).\" ON)\nendif()\n\n# Enable auto-download if we are cross compiling.\nif (CMAKE_CROSSCOMPILING)\n  set(DOWNLOAD_DEPENDENCIES ON)\nendif()\n\n# Support preference of static libs by adjusting CMAKE_FIND_LIBRARY_SUFFIXES.\nif (NOT BUILD_SHARED_LIBS)\n  if(WIN32)\n    list(INSERT CMAKE_FIND_LIBRARY_SUFFIXES 0 .lib .a)\n  else()\n    set(CMAKE_FIND_LIBRARY_SUFFIXES .a)\n  endif()\nendif()\n\n# Detect whether the user passed BUILD_PYTHON_BINDINGS in order to determine if\n# we should fail if Python isn't found.\nif (BUILD_PYTHON_BINDINGS)\n  set(FORCE_BUILD_PYTHON_BINDINGS ON)\nelse()\n  set(FORCE_BUILD_PYTHON_BINDINGS OFF)\nendif()\noption(BUILD_PYTHON_BINDINGS \"Build Python bindings.\" OFF)\n\n# Detect whether the user passed BUILD_JULIA_BINDINGS in order to determine if\n# we should fail if Julia isn't found.\nif (BUILD_JULIA_BINDINGS)\n  set(FORCE_BUILD_JULIA_BINDINGS ON)\nelse()\n  set(FORCE_BUILD_JULIA_BINDINGS OFF)\nendif()\noption(BUILD_JULIA_BINDINGS \"Build Julia bindings.\" OFF)\n\n# Detect whether the user passed BUILD_GO_BINDINGS in order to determine if\n# we should fail if Go isn't found.\nif (BUILD_GO_BINDINGS)\n  set(FORCE_BUILD_GO_BINDINGS ON)\nelse()\n  set(FORCE_BUILD_GO_BINDINGS OFF)\nendif()\noption(BUILD_GO_BINDINGS \"Build Go bindings.\" OFF)\n\n# If building Go bindings then build go shared libraries.\nif (BUILD_GO_BINDINGS)\n  set(BUILD_GO_SHLIB ON)\nendif()\n\n# Detect whether the user passed BUILD_R_BINDINGS in order to determine if\n# we should fail if R isn't found.\nif (BUILD_R_BINDINGS)\n  set(FORCE_BUILD_R_BINDINGS ON)\nelse()\n  set(FORCE_BUILD_R_BINDINGS OFF)\nendif()\noption(BUILD_R_BINDINGS \"Build R bindings.\" OFF)\n# Build Markdown bindings for documentation.  This is used as part of website\n# generation.\noption(BUILD_MARKDOWN_BINDINGS \"Build Markdown bindings for website documentation.\" OFF)\n\noption(MATHJAX\n    \"Use MathJax for HTML Doxygen output (disabled by default).\" OFF)\noption(USE_OPENMP \"If available, use OpenMP for parallelization.\" ON)\nenable_testing()\n\n# Set required standard to C++17.\nset(CMAKE_CXX_STANDARD 17)\nset(CMAKE_CXX_STANDARD_REQUIRED ON)\n\n# Ensure that GCC is new enough, if the compiler is GCC.\nif (CMAKE_COMPILER_IS_GNUCC AND CMAKE_CXX_COMPILER_VERSION VERSION_LESS 8)\n  message(FATAL_ERROR \"GCC version (${CMAKE_CXX_COMPILER_VERSION}) is too old! 8.x or newer is required.\")\nendif ()\n\n# Include modules in the CMake directory.\nset(CMAKE_MODULE_PATH ${CMAKE_MODULE_PATH} \"${CMAKE_CURRENT_SOURCE_DIR}/CMake\")\n\n# If we are not using Visual Studio, use the GNU install directories module.\n# Otherwise set the values manually.\nif (NOT MSVC)\n  include(GNUInstallDirs)\nelse ()\n  set(CMAKE_INSTALL_BINDIR ${CMAKE_INSTALL_PREFIX}/bin)\n  set(CMAKE_INSTALL_LIBDIR ${CMAKE_INSTALL_PREFIX}/lib)\n  set(CMAKE_INSTALL_MANDIR ${CMAKE_INSTALL_PREFIX}/man)\n  set(CMAKE_INSTALL_DOCDIR ${CMAKE_INSTALL_PREFIX}/share/doc/mlpack)\n  set(CMAKE_INSTALL_INCLUDEDIR ${CMAKE_INSTALL_PREFIX}/include)\nendif ()\n\n# This is as of yet unused.\n# option(PGO \"Use profile-guided optimization if not a debug build\" ON)\n\n# Set the CFLAGS and CXXFLAGS depending on the options the user specified.\n# Only GCC-like compilers support -Wextra, and other compilers give tons of\n# output for -Wall, so only -Wall and -Wextra on GCC.\nif (CMAKE_COMPILER_IS_GNUCC OR \"${CMAKE_CXX_COMPILER_ID}\" STREQUAL \"Clang\")\n  # Ensure that we can't compile with clang 3.4, since this causes strange\n  # issues.\n  if (CMAKE_CXX_COMPILER_VERSION VERSION_LESS 3.5)\n    message(FATAL_ERROR \"mlpack does not build correctly with clang < 3.5.  \"\n        \"Please upgrade your compiler and reconfigure mlpack.\")\n  endif ()\n\n  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -Wall -Wextra -ftemplate-depth=1000\")\n  set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -Wall -Wextra\")\n\n  # To remove unused functions warnings as well as missing-field-inits (from STB)\n  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -Wno-unused-function -Wno-missing-field-initializers\")\n  set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -Wno-unused-function\")\nendif()\n\n# Check if atomics need -latomic linking.\n#include(CheckAtomic)\nif (NOT HAVE_CXX_ATOMICS_WITHOUT_LIB AND\n    NOT HAVE_CXX_ATOMICS64_WITHOUT_LIB AND\n    NOT MSVC)\n  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -latomic\")\n  set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -latomic\")\nendif ()\n\n# If we are using MSVC, we need /bigobj.\nif (MSVC)\n  set(CMAKE_CXX_STANDARD 17)\n  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /bigobj /Zc:__cplusplus\")\nendif ()\n\n# If we are using MINGW, we need sections and big-obj, otherwise we create too\n# many sections.\nif (CMAKE_COMPILER_IS_GNUCC AND WIN32)\n  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -Wa,-mbig-obj\")\n  set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -Wa,-mbig-obj\")\nendif()\n\n# If using clang, we have to link against libc++ depending on the\n# OS (at least on some systems). Further, gcc sometimes optimizes calls to\n# math.h functions, making -lm unnecessary with gcc, but it may still be\n# necessary with clang.\nif (\"${CMAKE_CXX_COMPILER_ID}\" STREQUAL \"Clang\")\n  if (APPLE)\n    # Detect OS X version. Use '/usr/bin/sw_vers -productVersion' to\n    # extract V from '10.V.x'.\n    exec_program(/usr/bin/sw_vers ARGS\n        -productVersion OUTPUT_VARIABLE MACOSX_VERSION_RAW)\n    string(REGEX REPLACE\n        \"([0-9]+)(\\\\.([0-9]+).*)*\" \"\\\\1\"\n        MACOSX_MAJOR_VERSION\n        \"${MACOSX_VERSION_RAW}\")\n\n    string(REGEX REPLACE\n        \"([0-9]+)(\\\\.([0-9]+).*)*\" \"\\\\3\"\n        MACOSX_MINOR_VERSION\n        \"${MACOSX_VERSION_RAW}\")\n\n     # OSX Lion (10.7) and OS X Mountain Lion (10.8) doesn't automatically\n     # select the right stdlib.\n    if (${MACOSX_MAJOR_VERSION} LESS 11 AND ${MACOSX_MINOR_VERSION} LESS 9)\n      set(CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS} -stdlib=libc++\")\n      set(CMAKE_SHARED_LINKER_FLAGS\n          \"${CMAKE_SHARED_LINKER_FLAGS} -stdlib=libc++\")\n      set(CMAKE_MODULE_LINKER_FLAGS\n          \"${CMAKE_MODULE_LINKER_FLAGS} -stdlib=libc++\")\n      set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -stdlib=libc++\")\n     endif()\n  endif()\n\n  # Link everything with -lm.\n  set(MLPACK_LIBRARIES ${MLPACK_LIBRARIES} \"m\")\n  # Use -pthread, but not on OS X.\n  if (NOT APPLE)\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -pthread\")\n  endif ()\nendif()\n\n# If we're using gcc, then we need to link against pthreads to use std::thread,\n# which we do in the tests.\nif (CMAKE_COMPILER_IS_GNUCC)\n  find_package(Threads)\n  set(MLPACK_LIBRARIES ${MLPACK_LIBRARIES} ${CMAKE_THREAD_LIBS_INIT})\nendif()\n\n# Debugging CFLAGS.  Turn optimizations off; turn debugging symbols on.\nset (BFD_DL_AVAILABLE \"NO\")\nif (DEBUG)\n  if (NOT MSVC)\n    add_definitions(-DDEBUG)\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -g -O0 -ftemplate-backtrace-limit=0\")\n    set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -std=c99 -g -O0\")\n  endif()\n\n  # mlpack uses it's own mlpack::backtrace class based on Binary File Descriptor\n  # <bfd.h> and linux Dynamic Loader <libdl.h> and more portable version in future\n  if (CMAKE_SYSTEM_NAME STREQUAL \"Linux\")\n    find_package(Bfd)\n    find_package(LibDL)\n    if (LIBBFD_FOUND AND LIBDL_FOUND)\n      set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -rdynamic\")\n      set(MLPACK_INCLUDE_DIRS ${MLPACK_INCLUDE_DIRS} ${LIBBFD_INCLUDE_DIRS}\n          ${LIBDL_INCLUDE_DIRS})\n      set(MLPACK_LIBRARIES ${MLPACK_LIBRARIES} ${LIBBFD_LIBRARIES}\n          ${LIBDL_LIBRARIES})\n      set(BFD_DL_AVAILABLE \"YES\")\n    else()\n      message(WARNING \"No libBFD and/or libDL has been found!\")\n    endif()\n  endif()\nelse()\n  add_definitions(-DNDEBUG)\n  if (NOT MSVC)\n    if (NOT CMAKE_CROSSCOMPILING)\n      set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -O3\")\n      set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -std=c99 -O3\")\n    else()\n      set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -std=c99\")\n    endif()\n  else ()\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /O3\")\n    set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} /O3\")\n  endif ()\nendif()\n\n# Profiling CFLAGS.  Turn profiling information on.\nif (CMAKE_COMPILER_IS_GNUCC AND PROFILE)\n  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -pg\")\n  set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -pg\")\n  set(CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS} -pg\")\nendif()\n\n# If the user asked for extra Armadillo debugging output, turn that on.\nif (ARMA_EXTRA_DEBUG)\n  add_definitions(-DARMA_EXTRA_DEBUG)\nendif()\n\n# Now, find the libraries we need to compile against.  Several variables can be\n# set to manually specify the directory in which each of these libraries\n# resides.\n#   ARMADILLO_LIBRARY - location of libarmadillo.so / armadillo.lib\n#   ARMADILLO_INCLUDE_DIR - directory containing <armadillo>\n#   ARMADILLO_INCLUDE_DIRS - directories necessary for Armadillo includes\n#   CEREAL_INCLUDE_DIR - include directory for cereal\n#   ENSMALLEN_INCLUDE_DIR - include directory for ensmallen\n#   STB_IMAGE_INCLUDE_DIR - include directory for STB image library\n#   MATHJAX_ROOT - root of MathJax installation\n\n# Download and compile OpenBLAS if we are cross compiling mlpack for a specific\n# architecture. The function takes the version of OpenBLAS as variable.\nif (CMAKE_CROSSCOMPILING)\n  search_openblas(0.3.28)\nendif()\n\nif (NOT DOWNLOAD_DEPENDENCIES)\n  find_package(Armadillo \"${ARMADILLO_VERSION}\" REQUIRED)\nelse()\n  find_package(Armadillo \"${ARMADILLO_VERSION}\")\n  if (NOT ARMADILLO_FOUND)\n    if (NOT CMAKE_CROSSCOMPILING)\n      find_package(BLAS QUIET)\n      find_package(LAPACK QUIET)\n      if (NOT BLAS_FOUND AND NOT LAPACK_FOUND)\n        message(FATAL_ERROR \"Can not find BLAS or LAPACK!  These are required for Armadillo.  Please install one of them---or install Armadillo---before installing mlpack.\")\n      endif()\n    endif()\n    get_deps(https://files.mlpack.org/armadillo-12.6.5.tar.gz armadillo armadillo-12.6.5.tar.gz)\n    set(ARMADILLO_INCLUDE_DIR ${GENERIC_INCLUDE_DIR})\n    find_package(Armadillo REQUIRED)\n  endif()\nendif()\n# Include directories for the previous dependencies.\nset(MLPACK_INCLUDE_DIRS ${MLPACK_INCLUDE_DIRS} ${ARMADILLO_INCLUDE_DIRS})\nset(MLPACK_LIBRARIES ${MLPACK_LIBRARIES} ${ARMADILLO_LIBRARIES})\n\n# Find stb_image.h and stb_image_write.h.\nif (NOT DOWNLOAD_DEPENDENCIES)\n  find_package(StbImage)\nelse()\n  find_package(StbImage)\n  if (NOT StbImage_FOUND)\n    get_deps(https://mlpack.org/files/stb.tar.gz stb stb.tar.gz)\n    set(STB_IMAGE_INCLUDE_DIR ${GENERIC_INCLUDE_DIR})\n    find_package(StbImage REQUIRED)\n  endif()\nendif()\n\nif (StbImage_FOUND)\n  set(STB_AVAILABLE \"1\")\n  set(MLPACK_INCLUDE_DIRS ${MLPACK_INCLUDE_DIRS} \"${STB_IMAGE_INCLUDE_DIR}\")\n\n  # Make sure that we can link STB in multiple translation units.\n  include(CMake/TestStaticSTB.cmake)\n  if (NOT CMAKE_HAS_WORKING_STATIC_STB)\n    message(FATAL_ERROR \"STB implementations's static mode cannot link across \"\n        \"multiple translation units!  Try upgrading your STB implementation, \"\n        \"or using the auto-downloader (set DOWNLOAD_DEPENDENCIES=ON in the \"\n        \"CMake configuration command.\")\n  endif ()\nendif()\n\n# Find ensmallen.\nif (NOT DOWNLOAD_DEPENDENCIES)\n  find_package(Ensmallen \"${ENSMALLEN_VERSION}\" REQUIRED)\nelse()\n  find_package(Ensmallen \"${ENSMALLEN_VERSION}\")\n  if (NOT ENSMALLEN_FOUND)\n    get_deps(https://www.ensmallen.org/files/ensmallen-latest.tar.gz ensmallen ensmallen-latest.tar.gz)\n    set(ENSMALLEN_INCLUDE_DIR ${GENERIC_INCLUDE_DIR})\n    find_package(Ensmallen REQUIRED)\n  endif()\nendif()\nset(MLPACK_INCLUDE_DIRS ${MLPACK_INCLUDE_DIRS} \"${ENSMALLEN_INCLUDE_DIR}\")\n\n# Find cereal.\nif (NOT DOWNLOAD_DEPENDENCIES)\n  find_package(cereal \"${CEREAL_VERSION}\" REQUIRED)\nelse()\n  find_package(cereal \"${CEREAL_VERSION}\")\n  if (NOT CEREAL_FOUND)\n    get_deps(https://github.com/USCiLab/cereal/archive/refs/tags/v1.3.0.tar.gz cereal cereal-1.3.0.tar.gz)\n    set(CEREAL_INCLUDE_DIR ${GENERIC_INCLUDE_DIR})\n    find_package(cereal REQUIRED)\n  endif()\nendif()\nset(MLPACK_INCLUDE_DIRS ${MLPACK_INCLUDE_DIRS} ${CEREAL_INCLUDE_DIR})\n\n# Detect OpenMP support in a compiler. If the compiler supports OpenMP, flags\n# to compile with OpenMP are returned and added.  Note that MSVC does not\n# support a new-enough version of OpenMP to be useful.\nif (USE_OPENMP)\n  find_package(OpenMP)\nendif ()\n\nif (OpenMP_FOUND AND OpenMP_CXX_VERSION VERSION_GREATER_EQUAL 3.0.0)\n  set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} ${OpenMP_C_FLAGS}\")\n  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} ${OpenMP_CXX_FLAGS}\")\n  set(MLPACK_LIBRARIES ${MLPACK_LIBRARIES} ${OpenMP_CXX_LIBRARIES})\nelse ()\n  # Disable warnings for all the unknown OpenMP pragmas.\n  if (NOT MSVC)\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -Wno-unknown-pragmas\")\n  else ()\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /wd4068\")\n  endif ()\n  set(OpenMP_CXX_FLAGS \"\")\nendif ()\n\n# Create a 'distclean' target in case the user is using an in-source build for\n# some reason.\ninclude(CMake/TargetDistclean.cmake OPTIONAL)\n\ninclude_directories(BEFORE ${MLPACK_INCLUDE_DIRS})\ninclude_directories(BEFORE ${CMAKE_CURRENT_SOURCE_DIR}/src/)\n\n# On Windows, things end up under Debug/ or Release/.\nif (WIN32)\n  set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR})\n  set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR})\n  set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR})\n\n  # Copy all necessary DLLs for runtime to the build directory.\n  # This is a little hackish, but I can't figure out clear ways to make CMake\n  # consistently link everything 100% statically across platforms or set the\n  # runtime path right always, so this is the best I know how to do for now.\n  foreach(dir ${DLL_COPY_DIRS})\n    file(GLOB dir_dll_list \"${dir}/*.dll\")\n    file(COPY ${dir_dll_list} DESTINATION ${CMAKE_BINARY_DIR}/Release/)\n    file(COPY ${dir_dll_list} DESTINATION ${CMAKE_BINARY_DIR}/Debug/)\n  endforeach ()\n\n  foreach(file ${DLL_COPY_LIBS})\n    file(COPY ${file} DESTINATION ${CMAKE_BINARY_DIR}/Release/)\n    file(COPY ${file} DESTINATION ${CMAKE_BINARY_DIR}/Debug/)\n  endforeach()\nelse ()\n  # If not on Windows, put them under more standard UNIX-like places.  This is\n  # necessary, otherwise they would all end up in\n  # ${CMAKE_BINARY_DIR}/src/mlpack/methods/... or somewhere else random like\n  # that.\n  set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib/)\n  set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin/)\n  set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib/)\nendif ()\n\n# Determine whether or not this is a git repository, so that we can set the\n# version number if necessary.\nfind_package(Git)\nset (USING_GIT \"NO\")\nif (GIT_FOUND)\n  # Run 'git rev-parse HEAD' to find out if this is a working copy. If the\n  # return code is not 0, then it isn't.\n  execute_process(COMMAND ${GIT_EXECUTABLE} rev-parse HEAD\n      WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}\n      OUTPUT_VARIABLE MLPACK_TMP_REV_INFO\n      ERROR_VARIABLE MLPACK_TMP_REV_INFO_ERROR\n      RESULT_VARIABLE MLPACK_TMP_REV_INFO_RESULT\n      OUTPUT_STRIP_TRAILING_WHITESPACE)\n  if (${MLPACK_TMP_REV_INFO_RESULT} EQUAL 0)\n    set (USING_GIT \"YES\")\n    add_definitions(-DMLPACK_GIT_VERSION)\n    include(CMake/CreateGitVersionHeader.cmake)\n\n    add_custom_target(mlpack_gitversion ALL\n        COMMAND ${CMAKE_COMMAND} -P CMake/CreateGitVersionHeader.cmake\n        WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}\n        COMMENT \"Updating gitversion.hpp (if necessary)\")\n  # Add gitversion.hpp to the list of sources.\n  set(MLPACK_SRCS ${MLPACK_SRCS}\n      \"${CMAKE_CURRENT_SOURCE_DIR}/src/mlpack/core/util/gitversion.hpp\")\n  endif ()\nendif ()\n\n# Make a target to generate the man page documentation, but only if we are on a\n# UNIX-like system.\nif (BUILD_CLI_EXECUTABLES AND UNIX)\n  find_program(TXT2MAN txt2man)\n\n  # It's not a requirement that we make man pages.\n  if (NOT TXT2MAN)\n    message(WARNING \"txt2man not found; man pages will not be generated.\")\n  else ()\n    # We have the tools.  We can make them.\n    add_custom_target(man ALL\n        ${CMAKE_CURRENT_SOURCE_DIR}/CMake/allexec2man.sh\n            ${CMAKE_CURRENT_SOURCE_DIR}/CMake/exec2man.sh\n            ${CMAKE_BINARY_DIR}/share/man\n        WORKING_DIRECTORY\n          ${CMAKE_BINARY_DIR}/bin\n        COMMENT \"Generating man pages from built executables.\"\n    )\n\n    # Set the rules to install the documentation.\n    install(DIRECTORY \"${CMAKE_BINARY_DIR}/share/man/\"\n        DESTINATION \"${CMAKE_INSTALL_MANDIR}\")\n  endif ()\nendif ()\n\n# Modify config.hpp as necessary.\nfile(READ ${CMAKE_SOURCE_DIR}/src/mlpack/config.hpp CONFIG_CONTENTS)\nif (BFD_DL_AVAILABLE)\n  string(REGEX REPLACE \"// #define MLPACK_HAS_BFD_DL\\n\"\n      \"#define MLPACK_HAS_BFD_DL\\n\" CONFIG_CONTENTS \"${CONFIG_CONTENTS}\")\nendif ()\nif (STB_AVAILABLE)\n  string(REGEX REPLACE \"// #define MLPACK_HAS_STB\\n\"\n      \"#define MLPACK_HAS_STB\\n\" CONFIG_CONTENTS \"${CONFIG_CONTENTS}\")\n  if (NOT STB_INCLUDE_NEEDS_STB_SUFFIX)\n    string(REGEX REPLACE \"// #define MLPACK_HAS_NO_STB_DIR\\n\"\n        \"#define MLPACK_HAS_NO_STB_DIR\\n\" CONFIG_CONTENTS \"${CONFIG_CONTENTS}\")\n  endif ()\nendif ()\nif (USING_GIT)\n  string(REGEX REPLACE \"// #define MLPACK_GIT_VERSION\\n\"\n      \"#define MLPACK_GIT_VERSION\\n\" CONFIG_CONTENTS \"${CONFIG_CONTENTS}\")\nendif ()\nfile(WRITE ${CMAKE_BINARY_DIR}/include/mlpack/config-local.hpp \"${CONFIG_CONTENTS}\")\ninclude_directories(${CMAKE_BINARY_DIR}/include/)\nadd_definitions(-DMLPACK_CUSTOM_CONFIG_FILE=mlpack/config-local.hpp)\n\n# Finally, add any cross-compilation support libraries (they may need to come\n# last).  If we are not cross-compiling, no changes will happen here.\nset(MLPACK_LIBRARIES ${MLPACK_LIBRARIES} ${CROSS_COMPILE_SUPPORT_LIBRARIES})\n\n# Recurse into the rest of the project.\nadd_subdirectory(src/mlpack)\n\n# Create the pkg-config file, if we have pkg-config.\nfind_package(PkgConfig)\nif (PKG_CONFIG_FOUND)\n  # mlpack.pc must be generated as a separate target, otherwise it is possible\n  # that the given version could be out of date.  We don't need to worry about\n  # the library or include directories changing, because CMake will re-run this\n  # portion of the code whenever any of those changes.  But the version must be\n  # re-extracted every time the library is built.\n\n  # So, we have to parse our list of library directories, libraries, and include\n  # directories in order to get the correct line to give to pkg-config.\n  # Next, adapt the list of include directories.\n  list(REMOVE_DUPLICATES MLPACK_INCLUDE_DIRS)\n  foreach (incldir ${MLPACK_INCLUDE_DIRS})\n    # Filter out some obviously unnecessary directories.\n    if (NOT \"${incldir}\" STREQUAL \"/usr/include\")\n      set(MLPACK_INCLUDE_DIRS_STRING\n          \"${MLPACK_INCLUDE_DIRS_STRING} -I${incldir}\")\n    endif ()\n  endforeach ()\n  # Add the install directory too.\n  set(MLPACK_INCLUDE_DIRS_STRING\n      \"${MLPACK_INCLUDE_DIRS_STRING} -I${CMAKE_INSTALL_PREFIX}/include/\")\n\n  # Create the list of link directories.\n  set(MLPACK_LIBRARIES_LIST)\n  foreach (linkdir ${MLPACK_LIBRARY_DIRS})\n    list(APPEND MLPACK_LIBRARIES_LIST \"-L${linkdir}\")\n  endforeach ()\n\n  foreach(lib ${MLPACK_LIBRARIES})\n    string(SUBSTRING \"${lib}\" 0 1 first)\n    if (\"${first}\" STREQUAL \"/\")\n      # We need to split the directory and the library.\n      string(REGEX REPLACE \"(.*/)[^/]*$\" \"\\\\1\" library_dir \"${lib}\")\n      string(REGEX REPLACE \".*/lib([^/]*)[.][a-z]*[.]*$\" \"\\\\1\" library_name \"${lib}\")\n\n      list(APPEND MLPACK_LIBRARIES_LIST \"-L${library_dir}\")\n      list(APPEND MLPACK_LIBRARIES_LIST \"-l${library_name}\")\n    elseif (\"${first}\" STREQUAL \"-\")\n      # This argument is already in the right format.  (This happens with, e.g.,\n      # `-lpthread`.)\n      list(APPEND MLPACK_LIBRARIES_LIST \"${lib}\")\n    else ()\n      list(APPEND MLPACK_LIBRARIES_LIST \"-l${lib}\")\n    endif ()\n  endforeach ()\n\n  # Filter duplicate dependencies and directories.\n  list(REMOVE_DUPLICATES MLPACK_LIBRARIES_LIST)\n\n  # Filter out known unnecessary directories.\n  list(REMOVE_ITEM MLPACK_LIBRARIES_LIST\n      \"-L/usr/lib\"\n      \"-L/usr/lib/\"\n      \"-L/usr/lib/x86_64-linux-gnu\"\n      \"-L/usr/lib/x86_64-linux-gnu/\"\n      \"-L/usr/lib/i386-linux-gnu\"\n      \"-L/usr/lib/i386-linux-gnu/\")\n\n  string(REPLACE \";\" \" \" MLPACK_LIBRARIES_STRING \"${MLPACK_LIBRARIES_LIST}\")\n\n  # Do first stage of configuration.\n  set(MLPACK_VERSION_STRING \"@MLPACK_VERSION_STRING@\")\n  configure_file(\n    ${CMAKE_CURRENT_SOURCE_DIR}/CMake/mlpack.pc.in\n    ${CMAKE_BINARY_DIR}/CMake/mlpack.pc.in.partial @ONLY)\n\n  add_custom_target(pkgconfig ALL\n      ${CMAKE_COMMAND}\n          -D MLPACK_SOURCE_DIR=\"${CMAKE_SOURCE_DIR}\"\n          -P \"${CMAKE_CURRENT_SOURCE_DIR}/CMake/GeneratePkgConfig.cmake\"\n      COMMENT \"Generating mlpack.pc (pkg-config) file.\")\n\n  install(FILES \"${CMAKE_CURRENT_BINARY_DIR}/lib/pkgconfig/mlpack.pc\"\n      DESTINATION \"${CMAKE_INSTALL_LIBDIR}/pkgconfig/\")\n\nendif ()\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 4.5556640625,
          "content": "# mlpack Code of Conduct\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to making participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, sex characteristics, gender identity and\nexpression, level of experience, education, socio-economic status, nationality,\npersonal appearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\n  advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\n  address, without explicit permission\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies within all project spaces, and it also applies when\nan individual is representing the project or its community in public spaces.\nExamples of representing a project or community include using an official\nproject e-mail address, posting via an official social media account, or acting\nas an appointed representative at an online or offline event. Representation of\na project may be further defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the project team at conduct@mlpack.org. All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Reporting\n\nIf you believe someone is violating the code of conduct we ask that you report\nit by emailing conduct@mlpack.org. All reports will be kept confidential. In\nsome cases we may determine that a public statement will need to be made. If\nthat's the case, the identities of all victims and reporters will remain\nconfidential unless those individuals instruct us otherwise.\n\nIf you are unsure whether the incident is a violation, or whether the space\nwhere it happened is covered by this Code of Conduct, we encourage you to still\nreport it. We would much rather have a few extra reports where we decide to take\nno action, rather than miss a report of an actual violation. We do not look\nnegatively on you if we find the incident is not a violation. And knowing about\nincidents that are not violations, or happen outside our spaces, can also help\nus to improve the Code of Conduct or the processes surrounding it.\n\nIn your report please include:\n\n* Your contact info (so we can get in touch with you if we need to follow up)\n* Names (real, nicknames, or pseudonyms) of any individuals involved. If there\n  were other witnesses besides you, please try to include them as well.\n* When and where the incident occurred. Please be as specific as possible.\n* Your account of what occurred. If there is a publicly available record\n  (e.g. a mailing list archive or a public IRC logger) please include a link.\n* Any extra context you believe existed for the incident.\n* If you believe this incident is ongoing.\n* Any other information you believe we should have.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage],\nversion 1.4, available at\nhttps://www.contributor-covenant.org/version/1/4/code-of-conduct.html, and\nincludes some aspects of the Drupal Code of Conduct.\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 3.33984375,
          "content": "# Contributing to mlpack\n\nmlpack is a community-led project; that means that anyone is welcome to\ncontribute to mlpack and join the community!  If you would like to make\nimprovements to the library, add new features that are useful to you and others,\nor have found a bug that you know how to fix, please submit a pull request!\n\nIf you would like to learn more about how to get started contributing, see the\n[Community](https://www.mlpack.org/doc/developer/community.html) page, and if you are\ninterested in participating in Google Summer of Code, see\n[mlpack and Google Summer of Code](http://www.mlpack.org/doc/developer/gsoc.html).\n\n## Pull request process\n\nOnce a pull request is submitted, it must be approved by at least one member of\nmlpack's Contributors team, to ensure that (if applicable):\n\n * the design meshes with the rest of mlpack\n * the style matches the\n   [Style Guide](http://github.com/mlpack/mlpack/wiki/DesignGuidelines)\n * any new functionality is tested and working\n\nThe pull request can be merged as soon as it receives two approvals; 24 hours\nafter the first approval, mlpack-bot will provide a second approval.  This is to\nleave time for anyone to comment on the PR before it is merged.\n\nMembers of the Contributors team are encouraged to review pull requests that\nhave already been reviewed, and pull request contributors are encouraged to seek\nmultiple reviews.  Reviews from anyone not on the Contributors team are always\nappreciated and encouraged!\n\n## Reviewing Pull Requests\n\nAll mlpack contributors who choose to review and provide feedback on pull\nrequests have a responsibility to both the project and the individual making\nthe contribution. \n\nReviews and feedback should be\n[helpful, insightful, and geared towards improving the contribution](\n  https://www.youtube.com/watch?v=NNXk_WJzyMI).\nIf there are reasons why you feel the PR should not be merged, explain\nwhat those are. Be open to having your mind changed. Be open to\nworking with the contributor to make the pull request better.\n\nPlease don't leave dismissive or disrespectful reviews!  It's not helpful for\nanyone.\n\nWhen reviewing a pull request, the primary goals are:\n\n- For the codebase/project to improve\n- For the person submitting the request to succeed\n\nEven if a pull request does not get merged, the submitters should come away\nfrom the experience feeling like their effort was not wasted or unappreciated.\nEvery pull request from a new contributor is an opportunity to grow the community. \n\nWhen changes are necessary, request them, do not demand them, and do not assume\nthat the contributor already knows how to do that. Be there to lend a helping\nhand in case of need.\n\nSince there can sometimes be a lot more pull requests being opened than\nreviewed, we highly encourage everyone to review each others pull request\nkeeping in mind all the above mentioned points.\n\nLet's welcome new contributors with ❤️.\n\n## Pull Request Waiting Time \n\nmlpack is a community-driven project, so everyone only works on it in their\nfree time; this means it may take some time for them to review pull requests.\nWhile gentle reminders are welcome, please be patient and avoid constantly\nmessaging contributors or tagging them on pull requests.\n\nTypically small PRs will be reviewed within a handful of days; larger PRs might\ntake a few weeks for an initial review, and it may be a little bit longer in \ntimes of high activity.\n"
        },
        {
          "name": "COPYRIGHT.txt",
          "type": "blob",
          "size": 10.3994140625,
          "content": "Format: http://www.debian.org/doc/packaging-manuals/copyright-format/1.0/\nUpstream-Name: mlpack\nUpstream-Contact: Ryan Curtin <ryan@ratml.org>\nSource:\n  http://www.mlpack.org/\n  git://github.com/mlpack/mlpack.git\n\nFiles: *\nCopyright:\n  Copyright 2008-2023, Ryan Curtin <ryan@ratml.org>\n  Copyright 2008-2013, Bill March <march@gatech.edu>\n  Copyright 2008-2012, Dongryeol Lee <dongryel@cc.gatech.edu>\n  Copyright 2008-2013, Nishant Mehta <niche@cc.gatech.edu>\n  Copyright 2008-2013, Parikshit Ram <p.ram@gatech.edu>\n  Copyright 2010-2012, James Cline <james.cline@gatech.edu>\n  Copyright 2010-2013, Sterling Peet <sterling.peet@gatech.edu>\n  Copyright 2011-2012, Matthew Amidon <mamidon@gatech.edu>\n  Copyright 2011-2012, Neil Slagle <npslagle@gmail.com>\n  Copyright 2011, Ajinkya Kale <kaleajinkya@gmail.com>\n  Copyright 2011, Vlad Grantcharov <vlad321@gatech.edu>\n  Copyright 2011, Noah Kauffman <notoriousnoah@gmail.com>\n  Copyright 2012, Rajendran Mohan <rmohan88@gatech.edu>\n  Copyright 2012, Trironk Kiatkungwanglai <trironk@gmail.com>\n  Copyright 2012, Patrick Mason <patrick.s.mason@gmail.com>\n  Copyright 2013-2020, Marcus Edel <marcus.edel@fu-berlin.de>\n  Copyright 2013, Mudit Raj Gupta <mudit.raaj.gupta@gmail.com>\n  Copyright 2013-2018, Sumedh Ghaisas <sumedhghaisas@gmail.com>\n  Copyright 2014, Michael Fox <michaelfox99@gmail.com>\n  Copyright 2014,2020, Ryan Birmingham <birm@gatech.edu>\n  Copyright 2014, Siddharth Agrawal <siddharth.950@gmail.com>\n  Copyright 2014, Saheb Motiani <saheb210692@gmail.com>\n  Copyright 2014, Yash Vadalia <yashdv@gmail.com>\n  Copyright 2014, Abhishek Laddha <laddhaabhishek11@gmail.com>\n  Copyright 2014, Vahab Akbarzadeh <v.akbarzadeh@gmail.com>\n  Copyright 2014, Andrew Wells <andrewmw94@gmail.com>\n  Copyright 2014, Zhihao Lou <lzh1984@gmail.com>\n  Copyright 2014, Udit Saxena <saxenda.udit@gmail.com>\n  Copyright 2014-2015, Stephen Tu <tu.stephenl@gmail.com>\n  Copyright 2014-2015, Jaskaran Singh <jaskaranvirdi@ymail.com>\n  Copyright 2015,2017, Shangtong Zhang <zhangshangtong.cpp@gmail.com>\n  Copyright 2015, Hritik Jain <hritik.jain.cse13@itbhu.ac.in>\n  Copyright 2015, Vladimir Glazachev <glazachev.vladimir@gmail.com>\n  Copyright 2015, QiaoAn Chen <kazenoyumechen@gmail.com>\n  Copyright 2015, Janzen Brewer <jahabrewer@gmail.com>\n  Copyright 2015, Trung Dinh <dinhanhtrung@gmail.com>\n  Copyright 2015-2017, Tham Ngap Wei <thamngapwei@gmail.com>\n  Copyright 2015, Grzegorz Krajewski <krajekg@gmail.com>\n  Copyright 2015, Joseph Mariadassou <joe.mariadassou@gmail.com>\n  Copyright 2015, Pavel Zhigulin <pashaworking@gmail.com>\n  Copyright 2016, Andy Fang <AndyFang.DZ@gmail.com>\n  Copyright 2016-2018, Barak Pearlmutter <barak+git@pearlmutter.net>\n  Copyright 2016, Ivari Horm <ivari@risk.ee>\n  Copyright 2016, Dhawal Arora <d.p.arora1@gmail.com>\n  Copyright 2016, Alexander Leinoff <alexander-leinoff@uiowa.edu>\n  Copyright 2016, Palash Ahuja <abhor902@gmail.com>\n  Copyright 2016, Yannis Mentekidis <mentekid@gmail.com>\n  Copyright 2016, Ranjan Mondal <ranjan.rev@gmail.com>\n  Copyright 2016-2020, Mikhail Lozhnikov <lozhnikovma@gmail.com>\n  Copyright 2016, Marcos Pividori <marcos.pividori@gmail.com>\n  Copyright 2016, Keon Kim <kwk236@gmail.com>\n  Copyright 2016, Nilay Jain <nilayjain13@gmail.com>\n  Copyright 2016, Peter Lehner <peter.lehner@dlr.de>\n  Copyright 2016, Anuraj Kanodia <akanuraj200@gmail.com>\n  Copyright 2016, Ivan Georgiev <ivan@jonan.info>\n  Copyright 2016, Shikhar Bhardwaj <shikharbhardwaj68@gmail.com>\n  Copyright 2016, Yashu Seth <yashuseth2503@gmail.com>\n  Copyright 2016, Mike Izbicki <mike@izbicki.me>\n  Copyright 2017, Sudhanshu Ranjan <sranjan.sud@gmail.com>\n  Copyright 2017, Piyush Jaiswal <piyush.jaiswal@st.niituniversity.in>\n  Copyright 2017, Dinesh Raj <dinu.iota@gmail.com>\n  Copyright 2017, Vivek Pal <vivekpal.dtu@gmail.com>\n  Copyright 2017, Prasanna Patil <prasannapatil08@gmail.com>\n  Copyright 2017, Lakshya Agrawal <zeeshan.lakshya@gmail.com>\n  Copyright 2017, Praveen Ch <chvsp972911@gmail.com>\n  Copyright 2017, Kirill Mishchenko <ki.mishchenko@gmail.com>\n  Copyright 2017, Abhinav Moudgil <abhinavmoudgil95@gmail.com>\n  Copyright 2017, Thyrix Yang <thyrixyang@gmail.com>\n  Copyright 2017, Sagar B Hathwar <sagarbhathwar@gmail.com>\n  Copyright 2017, Nishanth Hegde <hegde.nishanth@gmail.com>\n  Copyright 2017, Parminder Singh <parmsingh101@gmail.com>\n  Copyright 2017, CodeAi <benjamin.bales@assrc.us>\n  Copyright 2017, Franciszek Stokowacki <franek.stokowacki@gmail.com>\n  Copyright 2017, Samikshya Chand <samikshya289@gmail.com>\n  Copyright 2017, N Rajiv Vaidyanathan <rajivvaidyanathan4@gmail.com>\n  Copyright 2017, Kartik Nighania <kartiknighania@gmail.com>\n  Copyright 2017-2024, Dirk Eddelbuettel <edd@debian.org>\n  Copyright 2017-2018, Eugene Freyman <evg.freyman@gmail.com>\n  Copyright 2017-2019, Manish Kumar <manish887kr@gmail.com>\n  Copyright 2017-2018, Haritha Sreedharan Nair <haritha1313@gmail.com>\n  Copyright 2017-2018, Sourabh Varshney <sourabhvarshney111@gmail.com>\n  Copyright 2018, Projyal Dev <projyal@gmail.com>\n  Copyright 2018, Nikhil Goel <nikhilgoel199797@gmail.com>\n  Copyright 2018-2020, Shikhar Jaiswal <jaiswalshikhar87@gmail.com>\n  Copyright 2018, B Kartheek Reddy <bkartheekreddy@gmail.com>\n  Copyright 2018-2019, Atharva Khandait <akhandait45@gmail.com>\n  Copyright 2018, Wenhao Huang <wenhao.huang.work@gmail.com>\n  Copyright 2018-2019, Roberto Hueso <robertohueso96@gmail.com>\n  Copyright 2018, Prabhat Sharma <prabhatsharma7298@gmail.com>\n  Copyright 2018, Tan Jun An <yamidarkxxx@gmail.com>\n  Copyright 2018, Moksh Jain <mokshjn00@gmail.com>\n  Copyright 2018, Manthan-R-Sheth <manthanrsheth96@gmail.com>\n  Copyright 2018, Namrata Mukhija <namratamukhija@gmail.com>\n  Copyright 2018, Conrad Sanderson\n  Copyright 2018, Thanasis Mattas <mattasa@auth.gr>\n  Copyright 2018, Shashank Shekhar <contactshashankshekhar@gmail.com>\n  Copyright 2018, Yasmine Dumouchel <yasmine.dumouchel@gmail.com>\n  Copyright 2018, German Lancioni\n  Copyright 2018, Arash Abghari <arash.abghari@gmail.com>\n  Copyright 2018, Ayush Chamoli\n  Copyright 2018, Tommi Laivamaa <tommi.laivamaa@protonmail.com>\n  Copyright 2019, Kim SangYeon <sy0814k@gmail.com>\n  Copyright 2019, Niteya Shah <niteya.56@gmail.com>\n  Copyright 2019, Toshal Agrawal <tagrawal1339@gmail.com>\n  Copyright 2019, Dan Timson\n  Copyright 2019, Miguel Canteras <mcanteras@gmail.com>\n  Copyright 2019, Bishwa Karki <karkeebishwa1@gmail.com>\n  Copyright 2019, Mehul Kumar Nirala <mehulkumarnirala@gmail.com>\n  Copyright 2019-2020, Yashwant Singh Parihar <yashwantsingh.sngh@gmail.com>\n  Copyright 2019, Heet Sankesara <heetsankesara3@gmail.com>\n  Copyright 2019-2020, Jeffin Sam <sam.jeffin@gmail.com>\n  Copyright 2019, Vikas S Shetty <shettyvikas209@gmail.com>\n  Copyright 2019, Khizir Siddiqui <khizirsiddiqui@gmail.com>\n  Copyright 2019, Tejasvi Tomar <tstomar@outlook.com>\n  Copyright 2019, Jai Agarwal <jai.bhageria@gmail.com>\n  Copyright 2019, Ziyang Jiang <zij004@alumni.stanford.edu>\n  Copyright 2019, Rohit Kartik <rohit.audrey@gmail.com>\n  Copyright 2019, Aditya Viki <adityaviki01@gmail.com>\n  Copyright 2019-2020, Kartik Dutt <kartikdutt@live.in>\n  Copyright 2019, Suryoday Basak <suryodaybasak@gmail.com>\n  Copyright 2020, Sriram S K <sriramsk1999@gmail.com>\n  Copyright 2020, Manoranjan Kumar Bharti ( Nakul Bharti ) <knakul853@gmail.com>\n  Copyright 2020, Saraansh Tandon <saraanshtandon1999@gmail.com>\n  Copyright 2020, Gaurav Singh <gs8763076@gmail.com>\n  Copyright 2020, Lakshya Ojha <ojhalakshya@gmail.com>\n  Copyright 2020, Bisakh Mondal <bisakhmondal00@gmail.com>\n  Copyright 2020, Benson Muite <benson_muite@emailplus.org>\n  Copyright 2020, Sarthak Bhardwaj <7sarthakbhardwaj@gmail.com>\n  Copyright 2020, Aakash Kaushik <kaushikaakash7539@gmail.com>\n  Copyright 2020, Anush Kini <anushkini@gmail.com>\n  Copyright 2020, Nippun Sharma <inbox.nippun@gmail.com>\n  Copyright 2020, Rishabh Garg <rishabhgarg108@gmail.com>\n  Copyright 2020, Sudhakar Brar <dxhrmhall1449@tutanota.com>\n  Copyright 2020, Alex Nguyen <alexvn.edu@gmail.com>\n  Copyright 2020, Gaurav Ghati <gauravghatii@gmail.com>\n  Copyright 2020, Anmolpreet Singh <anmol323c@gmail.com>\n  Copyright 2020, Anjishnu Mukherjee <amukher6@gmu.edu>\n  Copyright 2020-2023, Omar Shrit <omar@shrit.me>\n  Copyright 2021, Tru Hoang <trugiahoang@gmail.com>\n  Copyright 2021, Mark Fischinger <markfischinger@gmail.com>\n  Copyright 2021, Muhammad Fawwaz Mayda <maydafawwaz@gmail.com>\n  Copyright 2021, Roshan Nrusing Swain <swainroshan001@gmail.com>\n  Copyright 2021, Suvarsha Chennareddy <suvarshachennareddy@gmail.com>\n  Copyright 2021, Shubham Agrawal <shubham.agra1206@gmail.com>\n  Copyright 2020-2024, James Balamuta <james.balamuta@gmail.com>\n  Copyright 2022, Sri Madhan M <srimadhan11@gmail.com>\n  Copyright 2022, Zhuojin Liu <zhuojinliu.cs@gmail.com>\n  Copyright 2022, Richèl Bilderbeek <richel@richelbilderbeek.nl>\n  Copyright 2022, Chetan Pandey <chetanpandey1266@gmail.com>\n  Copyright 2024, Nikolay Apanasov <nikolay@apanasov.org>\n  Copyright 2024, Martin Lambertsen <github@lambertsen.one>\n  Copyright 2024, Andrea Novellini <andre.novellini@gmail.com>\n\nLicense: BSD-3-clause\n  All rights reserved.\n  .\n  Redistribution and use of mlpack in source and binary forms, with or without\n  modification, are permitted provided that the following conditions are met:\n  .\n  1. Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n  .\n  2. Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation and/or\n  other materials provided with the distribution.\n  .\n  3. Neither the name of the copyright holder nor the names of its contributors\n  may be used to endorse or promote products derived from this software without\n  specific prior written permission.\n  .\n  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\n  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n  WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR\n  ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n  LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\n  ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n  SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "GOVERNANCE.md",
          "type": "blob",
          "size": 5.33203125,
          "content": "# mlpack governance structure\n\nRevised Oct. 21st, 2019.\n\n## Introduction\n\nmlpack has grown much since its initial inception as a small project out of a\nuniversity research lab.  Now that there are over 150 contributors, it's\nimportant that we have a clearly defined process for making our decisions and\norganizing ourselves.\n\nThis document aims to clarify the governance of mlpack.  This is a living\ndocument: it may change over time.  The process for making these changes is\ndetailed in the \"Governance Changes\" section.\n\n## Code of Conduct\n\nmlpack aims to be an open and welcoming environment, and as such, we have a\ncode of conduct that helps foster this environment.  See\n[here](https://github.com/mlpack/mlpack/blob/master/CODE_OF_CONDUCT.md) for\nmore information.\n\n## Teams & Roles\n\nTo keep overhead minimal, mlpack's teams and roles are simple: there is only\nthe [Committers](https://github.com/orgs/mlpack/teams/contributors) team, and\nthe [NumFOCUS leadership team](TODO:link).\n\nMembers of the Committers team have commit access to all mlpack repositories\nand help guide the development directions and goals of mlpack.  Committers\nshould be familiar with the [contribution\nprocess](https://github.com/mlpack/mlpack/blob/master/CONTRIBUTING.md) and\nfollow it when merging code and reviewing pull requests; this is important for\nthe continued stability and quality of mlpack's codebase.  Responsibilities and\nactivities of Committers team members can include:\n\n * Welcoming new members to the community: helping support users and point\n   potential contributors in the correct direction.\n\n * Reviewing pull requests and approving them when they are ready.\n\n * Merging pull requests after they have been approved by others for merge.\n\n * Communicating and coordinating with contributors to help get code merged and\n   improve the software.\n\n * Helping map out mlpack's development directions and processes.\n\n * Maintaining mlpack infrastructure (build systems, continuous integration,\n   etc.).\n\nMembership on the Committers team does not expire.  Contributors who have\nrepeatedly shown that their code quality is high, demonstrated adherence to the\ncode of conduct, and shown that they have a strong interest in the project can\nbe added to the Committers team using the organizational decision process in\nthe next section.\n\nThe NumFOCUS leadership team is a subset of the Committers team whose\nadditional responsibilities are to coordinate with NumFOCUS and maintain this\ngovernance document.  Membership in the NumFOCUS leadership team is limited to\nfive people, and does not confer any special voting power or decision rights.\n\n## Voting and Organizational Decisions\n\nHistorically, mlpack organizational decisions have not been controversial and\nthis has allowed efficient decision making.  Therefore, a vote on a proposal is\nnot required unless there is any explicit disagreement or concern with the\nproposal.  The topics of a proposal might be:\n\n * Adding/removing a new member to/from the Committers team.\n\n * Participating in a program such as Google Summer of Code or Outreachy.\n\n * A change to some part of the mlpack infrastructure or contribution process.\n\n * Refactoring or change of an important public part of the API.\n\n * Use of funds for a particular project.\n\nThat list is not inclusive.  Introducing a proposal or idea can be done\ninformally in a public place, such as the mlpack mailing list or on Github as\nan issue.  It's a good idea (but not mandatory) to make the proposal discussion\nfully public so that people who are not on the Committers team can also comment\nand provide opinions---after all, this is a community-led project so we should\nbe sure to include the *entire* community whenever possible.\n\nIf there is any disagreement or concern with the proposal, the person who\nintroduced the proposal should work to try and find a resolution or compromise\nif possible.  If that is not possible, then the proposal can be brought to a\nvote.\n\nFor a proposal to pass, a simple majority vote suffices.  Each Committer has\none equal vote, and they may choose to abstain from voting if they do prefer.\nSince some Committers may be inactive or busy, it is not required for every\nCommitter to participate in every vote; instead, someone who has a proposal\nshould make a good-faith effort to post the proposal in a public location so\nthat interested and active Committers can respond.  Voting for any proposal\nshould be open for at least five days to allow sufficient time.\n\nIf a proposal passes despite votes against it, it is generally a good idea for\nthe Committer who introduced the proposal to spend some time considering and\nunderstanding the arguments that were presented against the proposal, or if\nappropriate, for the Committer to try and find an acceptable compromise or\nalternate strategy that addresses the given feedback.\n\n## Governance Changes\n\nThe NumFOCUS leadership team is responsible for this governance document, and\nthus any changes to this document, NumFOCUS membership, or the NumFOCUS\nleadership team must be approved by that team, also by a simple majority vote.\nBecause every member of the NumFOCUS leadership team should be an active\nCommitter, efforts should be made to collect votes from all five members.\nVoting for any proposal should be open for at least five days to allow\nsufficient time. If necessary, every active member of the NumFOCUS leadership\nteam can ask for an extension of the voting deadline.\n"
        },
        {
          "name": "HISTORY.md",
          "type": "blob",
          "size": 40.9072265625,
          "content": "# mlpack changelog\n\n## mlpack ?.?.?\n\n_????-??-??_\n\n * Fix command-line duplicate output bug when loading matrices for some bindings\n   (#3838).\n \n * Add `MLPACK_NO_STD_MUTEX` to allow disabling `std::mutex` (#3868).\n\n## mlpack 4.5.1\n\n_2024-12-02_\n\n * Fix compilation with clang 19 (#3799).\n\n * Deprecate version of `data::Split()` that returns a `std::tuple` for\n   consistency; use other overloads instead (#3803).\n\n * Fix LSTM layer copy/move constructors (#3809).\n\n * Fix compilation if only including `mlpack/methods/kde/kde_model.hpp` (#3800).\n\n * Fix serialization and `MinDistance()` bugs with `HollowBallBound` (#3808).\n\n## mlpack 4.5.0\n\n_2024-09-17_\n\n * Distribute STB headers as part of R package (#3724, #3726).\n\n * Added OpenMP parallelization to Hamerly, Naive, and Elkan k-means (#3761, #3762, #3764).\n\n * Added OpenMP support for fast approximation (#3685).\n\n * Implemented the Find and Fill algorithm into the Dropout Layer and added OpenMP support (#3684).\n\n * Update Python bindings to support NumPy 2.x (#3752).\n\n * Bump minimum Armadillo version to 10.8 (#3760).\n\n * Adapt `NearestInterpolation` ANN layer to new Layer Inteface (#3768).\n\n * Add support for arbitrary matrix types to `Radical` and deprecate\n   `Radical::DoRadical()` in favor of `Radical::Apply()` (#3787).\n\n## mlpack 4.4.0\n\n_2024-05-26_\n\n  * Add `print_training_accuracy` option to LogisticRegression bindings (#3552).\n\n  * Fix `preprocess_split()` call in documentation for `LinearRegression` and\n    `AdaBoost` Python classes (#3563).\n\n  * Added `Repeat` ANN layer type (#3565).\n\n  * Remove `round()` implementation for old MSVC compilers (#3570).\n\n  * (R) Added inline plugin to the R bindings to allow for other R packages to\n    link to headers (#3626, h/t @cgiachalis).\n\n  * (R) Removed extra gcc-specific options from `Makevars.win`  (#3627, h/t\n    @kalibera).\n\n  * (R) Changed roxygen package-level documentation from using\n    `@docType package` to `\"_PACKAGE\"`. (#3636)\n\n  * Fix floating-point accuracy issue for decision trees that sometimes caused\n    crashes (#3595).\n\n  * Use templates metaprog to distinguish between a matrix and a cube type\n    (#3602), (#3585).\n\n  * Use `MatType` instead of `arma::Mat<eT>`, (#3567), (#3607), (#3608),\n    (#3609), (#3568).\n\n  * Generalize matrix operations for armadillo and bandicoot, (#3619), (#3617),\n    (#3610), (#3643), (#3600), (#3605), (#3629).\n\n  * Change `arma::conv_to` to `ConvTo` using a local shim for bandicoot support\n    (#3614).\n\n  * Fix a bug for the stddev and mean in `RandNormal()` #(3651).\n\n  * Allow PCA to take different matrix types (#3677).\n\n  * Fix usage of precompiled headers; remove cotire (#3635).\n\n  * Fix non-working `verbose` option for R bindings (#3691), and add global\n    `mlpack.verbose` option (#3706).\n\n  * Fix divide-by-zero edge case for LARS (#3701).\n\n  * Templatize `SparseCoding` and `LocalCoordinateCoding` to allow different\n    matrix types (#3709, #3711).\n\n  * Fix handling of unused atoms in `LocalCoordinateCoding` (#3711).\n\n  * Move minimum required C++ version from C++14 to C++17 (#3704).\n\n## mlpack 4.3.0\n\n_2023-11-27_\n\n  * Fix include ordering issue for `LinearRegression` (#3541).\n\n  * Fix L1 regularization in case where weight is zero (#3545).\n\n  * Use HTTPS for all auto-downloaded dependencies (#3550).\n\n  * More robust detection of C++17 mode in the MSVC \"compiler\" (#3555, #3557).\n\n  * Fix setting number of classes correctly in `SoftmaxRegression::Train()`\n    (#3553).\n\n  * Adapt `MultiheadAttention` and `LayerNorm` ANN layers to new Layer interface\n    (#3547).\n\n  * Fix inconsistent use of the \"input\" parameter to the Backward method in ANNs\n    (#3551).\n\n  * Allow passing weak learner hyperparameters directly to AdaBoost (#3560).\n\n## mlpack 4.2.1\n\n_2023-09-05_\n\n  * Reinforcement Learning: Gaussian noise (#3515).\n\n  * Reinforcement Learning: Twin Delayed Deep Deterministic Policy Gradient\n    (#3512).\n\n  * Reinforcement Learning: Ornstein-Uhlenbeck noise (#3499).\n\n  * Reinforcement Learning: Deep Deterministic Policy Gradient (#3494).\n\n  * Add `ClassProbabilities()` member to `DecisionTree` so that the internal\n    details of trees can be more easily inspected (#3511).\n\n  * Bipolar sigmoid activation function added and invertible functions\n    fixed (#3506).\n\n  * Add auto-configured `mlpack/config.hpp` to contain configuration details of\n    mlpack that are required at compile time.  STB detection is now done in this\n    file with the `MLPACK_HAS_STB` macro (#3519).\n\n  * Fix CRAN package alias for R bindings (#3543).\n\n## mlpack 4.2.0\n\n_2023-06-14_\n\n  * Adapt `C_ReLU`, `ReLU6`, `FlexibleReLU` layers for the new neural network\n    API (#3445).\n\n  * Fix PReLU, add integration test to it (#3473).\n\n  * Fix bug in LogSoftMax derivative (#3469).\n\n  * Add `serialize` method to `GaussianInitialization`,\n    `LecunNormalInitialization`,\n    `KathirvalavakumarSubavathiInitialization`, `NguyenWidrowInitialization`,\n    and `OrthogonalInitialization` (#3483).\n\n  * Allow categorical features to `preprocess_one_hot_encode` (#3487).\n\n  * Install mlpack and cereal headers as part of R package (#3488).\n\n  * Add intercept and normalization support to LARS (#3493).\n\n  * Allow adding two features simultaneously to LARS models (#3493).\n\n  * Adapt FTSwish activation function (#3485).\n\n  * Adapt Hyper-Sinh activation function (#3491).\n\n## mlpack 4.1.0\n\n_2023-04-26_\n\n  * Adapt HardTanH layer (#3454).\n\n  * Adapt Softmin layer for new neural network API (#3437).\n\n  * Adapt PReLU layer for new neural network API (#3420).\n\n  * Add CF decomposition methods: `QUIC_SVDPolicy` and `BlockKrylovSVDPolicy`\n    (#3413, #3404).\n\n  * Update outdated code in tutorials (#3398, #3401).\n\n  * Bugfix for non-square convolution kernels (#3376).\n\n  * Fix a few missing includes in `<mlpack.hpp>` (#3374).\n\n  * Fix DBSCAN handling of non-core points (#3346).\n\n  * Avoid deprecation warnings in Armadillo 11.4.4+ (#3405).\n\n  * Issue runtime error when serialization of neural networks is attempted but\n    `MLPACK_ENABLE_ANN_SERIALIZATION` is not defined (#3451).\n\n## mlpack 4.0.1\n\n_2022-12-23_\n\n  * Fix mapping of categorical data for Julia bindings (#3305).\n\n  * Bugfix: catch all exceptions when running bindings from Julia, instead of\n    crashing (#3304).\n\n  * Various Python configuration fixes for Windows and OS X (#3312, #3313,\n    #3311, #3309, #3308, #3297, #3302).\n\n  * Optimize and strip compiled Python bindings when possible, resulting in\n    significant size minimization (#3310).\n\n  * The `/std:c++17` and `/Zc:__cplusplus` options are now required when using\n    Visual Studio (#3318).  Documentation and compile-time checks added.\n\n  * Set `BUILD_TESTS` to `OFF` by default.  If you want to build tests, like\n    `mlpack_test`, manually set `BUILD_TESTS` to `ON` in your CMake\n    configuration step (#3316).\n\n  * Fix handling of transposed matrix parameters in Python, Julia, R, and Go\n    bindings (#3327).\n\n  * Comment out definition of ARMA_NO DEBUG. This allows various Armadillo\n    run-time checks such as non-conforming matrices and out-of-bounds\n    element access. In turn this helps tracking down bugs and incorrect\n    usage (#3322).\n\n## mlpack 4.0.0\n\n_2022-10-23_\n\n  * Bump C++ standard requirement to C++14 (#3233).\n\n  * Fix `Perceptron` to work with cross-validation framework (#3190).\n\n  * Migrate from boost tests to Catch2 framework (#2523), (#2584).\n\n  * Bump minimum armadillo version from 8.400 to 9.800 (#3043), (#3048).\n\n  * Adding a copy constructor in the Convolution layer (#3067).\n\n  * Replace `boost::spirit` parser by a local efficient implementation (#2942).\n\n  * Disable correctly the autodownloader + fix tests stability (#3076).\n\n  * Replace `boost::any` with `core::v2::any` or `std::any` if available (#3006).\n\n  * Remove old non used Boost headers (#3005).\n\n  * Replace `boost::enable_if` with `std::enable_if` (#2998).\n\n  * Replace `boost::is_same` with `std::is_same` (#2993).\n\n  * Remove invalid option for emsmallen and STB (#2960).\n\n  * Check for armadillo dependencies before downloading armadillo (#2954).\n\n  * Disable the usage of autodownloader by default (#2953).\n\n  * Install dependencies downloaded with the autodownloader (#2952).\n\n  * Download older Boost if the compiler is old (#2940).\n\n  * Add support for embedded systems (#2531).\n\n  * Build mlpack executable statically if the library is statically linked (#2931).\n\n  * Fix cover tree loop bug on embedded arm systems (#2869).\n\n  * Fix a LAPACK bug in `FindArmadillo.cmake` (#2929).\n\n  * Add an autodownloader to get mlpack dependencies (#2927).\n\n  * Remove Coverage files and configurations from CMakeLists (#2866).\n\n  * Added `Multi Label Soft Margin Loss` loss function for neural networks\n   (#2345).\n\n  * Added Decision Tree Regressor (#2905). It can be used using the class\n    `mlpack::tree::DecisionTreeRegressor`. It is accessible only though C++.\n\n  * Added dict-style inspection of mlpack models in python bindings (#2868).\n\n  * Added Extra Trees Algorithm (#2883). Currently, it can be used using the\n    class `mlpack::tree::ExtraTrees`, but only through C++.\n\n  * Add Flatten T Swish activation function (`flatten-t-swish.hpp`)\n\n  * Added warm start feature to Random Forest (#2881); this feature is\n    accessible from mlpack's bindings to different languages.\n\n  * Added Pixel Shuffle layer (#2563).\n\n  * Add \"check_input_matrices\" option to python bindings that checks\n    for NaN and inf values in all the input matrices (#2787).\n\n  * Add Adjusted R squared functionality to R2Score::Evaluate (#2624).\n\n  * Disabled all the bindings by default in CMake (#2782).\n\n  * Added an implementation to Stratify Data (#2671).\n\n  * Add `BUILD_DOCS` CMake option to control whether Doxygen documentation is\n    built (default ON) (#2730).\n\n  * Add Triplet Margin Loss function (#2762).\n\n  * Add finalizers to Julia binding model types to fix memory handling (#2756).\n\n  * HMM: add functions to calculate likelihood for data stream with/without\n    pre-calculated emission probability (#2142).\n\n  * Replace Boost serialization library with Cereal (#2458).\n\n  * Add `PYTHON_INSTALL_PREFIX` CMake option to specify installation root for\n    Python bindings (#2797).\n\n  * Removed `boost::visitor` from model classes for `knn`, `kfn`, `cf`,\n    `range_search`, `krann`, and `kde` bindings (#2803).\n\n  * Add k-means++ initialization strategy (#2813).\n\n  * `NegativeLogLikelihood<>` now expects classes in the range `0` to\n    `numClasses - 1` (#2534).\n\n  * Add `Lambda1()`, `Lambda2()`, `UseCholesky()`, and `Tolerance()` members to\n    `LARS` so parameters for training can be modified (#2861).\n\n  * Remove unused `ElemType` template parameter from `DecisionTree` and\n    `RandomForest` (#2874).\n\n  * Fix Python binding build when the CMake variable `USE_OPENMP` is set to\n    `OFF` (#2884).\n\n  * The `mlpack_test` target is no longer built as part of `make all`.  Use\n    `make mlpack_test` to build the tests.\n\n  * Fixes to `HoeffdingTree`: ensure that training still works when empty\n    constructor is used (#2964).\n\n  * Fix Julia model serialization bug (#2970).\n\n  * Fix `LoadCSV()` to use pre-populated `DatasetInfo` objects (#2980).\n\n  * Add `probabilities` option to softmax regression binding, to get class\n    probabilities for test points (#3001).\n\n  * Fix thread safety issues in mlpack bindings to other languages (#2995).\n\n  * Fix double-free of model pointers in R bindings (#3034).\n\n  * Fix Julia, Python, R, and Go handling of categorical data for\n    `decision_tree()` and `hoeffding_tree()` (#2971).\n\n  * Depend on `pkgbuild` for R bindings (#3081).\n\n  * Replaced Numpy deprecated code in Python bindings (#3126).\n\n## mlpack 3.4.2\n\n_2020-10-26_\n\n  * Added Mean Absolute Percentage Error.\n\n  * Added Softmin activation function as layer in ann/layer.\n\n  * Fix spurious ARMA_64BIT_WORD compilation warnings on 32-bit systems (#2665).\n\n## mlpack 3.4.1\n\n_2020-09-07_\n\n  * Fix incorrect parsing of required matrix/model parameters for command-line\n    bindings (#2600).\n\n  * Add manual type specification support to `data::Load()` and `data::Save()`\n    (#2084, #2135, #2602).\n\n  * Remove use of internal Armadillo functionality (#2596, #2601, #2602).\n\n## mlpack 3.4.0\n\n_2020-09-01_\n\n  * Issue warnings when metrics produce NaNs in KFoldCV (#2595).\n\n  * Added bindings for _R_ during Google Summer of Code (#2556).\n\n  * Added common striptype function for all bindings (#2556).\n\n  * Refactored common utility function of bindings to bindings/util (#2556).\n\n  * Renamed InformationGain to HoeffdingInformationGain in\n    methods/hoeffding_trees/information_gain.hpp (#2556).\n\n  * Added macro for changing stream of printing and warnings/errors (#2556).\n\n  * Added Spatial Dropout layer (#2564).\n\n  * Force CMake to show error when it didn't find Python/modules (#2568).\n\n  * Refactor `ProgramInfo()` to separate out all the different\n    information (#2558).\n\n  * Add bindings for one-hot encoding (#2325).\n\n  * Added Soft Actor-Critic to RL methods (#2487).\n\n  * Added Categorical DQN to q_networks (#2454).\n\n  * Added N-step DQN to q_networks (#2461).\n\n  * Add Silhoutte Score metric and Pairwise Distances (#2406).\n\n  * Add Go bindings for some missed models (#2460).\n\n  * Replace boost program_options dependency with CLI11 (#2459).\n\n  * Additional functionality for the ARFF loader (#2486); use case sensitive\n    categories (#2516).\n\n  * Add `bayesian_linear_regression` binding for the command-line, Python,\n    Julia, and Go.  Also called \"Bayesian Ridge\", this is equivalent to a\n    version of linear regression where the regularization parameter is\n    automatically tuned (#2030).\n\n  * Fix defeatist search for spill tree traversals (#2566, #1269).\n\n  * Fix incremental training of logistic regression models (#2560).\n\n  * Change default configuration of `BUILD_PYTHON_BINDINGS` to `OFF` (#2575).\n\n## mlpack 3.3.2\n\n_2020-06-18_\n\n  * Added Noisy DQN to q_networks (#2446).\n\n  * Add Go bindings (#1884).\n\n  * Added Dueling DQN to q_networks, Noisy linear layer to ann/layer\n    and Empty loss to ann/loss_functions (#2414).\n\n  * Storing and adding accessor method for action in q_learning (#2413).\n\n  * Added accessor methods for ANN layers (#2321).\n\n  * Addition of `Elliot` activation function (#2268).\n\n  * Add adaptive max pooling and adaptive mean pooling layers (#2195).\n\n  * Add parameter to avoid shuffling of data in preprocess_split (#2293).\n\n  * Add `MatType` parameter to `LSHSearch`, allowing sparse matrices to be used\n    for search (#2395).\n\n  * Documentation fixes to resolve Doxygen warnings and issues (#2400).\n\n  * Add Load and Save of Sparse Matrix (#2344).\n\n  * Add Intersection over Union (IoU) metric for bounding boxes (#2402).\n\n  * Add Non Maximal Supression (NMS) metric for bounding boxes (#2410).\n\n  * Fix `no_intercept` and probability computation for linear SVM bindings\n    (#2419).\n\n  * Fix incorrect neighbors for `k > 1` searches in `approx_kfn` binding, for\n    the `QDAFN` algorithm (#2448).\n\n  * Fix serialization of kernels with state for FastMKS (#2452).\n\n  * Add `RBF` layer in ann module to make `RBFN` architecture (#2261).\n\n## mlpack 3.3.1\n\n_2020-04-29_\n\n  * Minor Julia and Python documentation fixes (#2373).\n\n  * Updated terminal state and fixed bugs for Pendulum environment (#2354,\n    #2369).\n\n  * Added `EliSH` activation function (#2323).\n\n  * Add L1 Loss function (#2203).\n\n  * Pass CMAKE_CXX_FLAGS (compilation options) correctly to Python build\n    (#2367).\n\n  * Expose ensmallen Callbacks for sparseautoencoder (#2198).\n\n  * Bugfix for LARS class causing invalid read (#2374).\n\n  * Add serialization support from Julia; use `mlpack.serialize()` and\n    `mlpack.deserialize()` to save and load from `IOBuffer`s.\n\n## mlpack 3.3.0\n\n_2020-04-07_\n\n  * Added `Normal Distribution` to `ann/dists` (#2382).\n\n  * Templated return type of `Forward function` of loss functions (#2339).\n\n  * Added `R2 Score` regression metric (#2323).\n\n  * Added `poisson negative log likelihood` loss function (#2196).\n\n  * Added `huber` loss function (#2199).\n\n  * Added `mean squared logarithmic error` loss function for neural networks\n    (#2210).\n\n  * Added `mean bias loss function` for neural networks (#2210).\n\n  * The DecisionStump class has been marked deprecated; use the `DecisionTree`\n    class with `NoRecursion=true` or use `ID3DecisionStump` instead (#2099).\n\n  * Added `probabilities_file` parameter to get the probabilities matrix of\n    AdaBoost classifier (#2050).\n\n  * Fix STB header search paths (#2104).\n\n  * Add `DISABLE_DOWNLOADS` CMake configuration option (#2104).\n\n  * Add padding layer in TransposedConvolutionLayer (#2082).\n\n  * Fix pkgconfig generation on non-Linux systems (#2101).\n\n  * Use log-space to represent HMM initial state and transition probabilities\n    (#2081).\n\n  * Add functions to access parameters of `Convolution` and `AtrousConvolution`\n    layers (#1985).\n\n  * Add Compute Error function in lars regression and changing Train function to\n    return computed error (#2139).\n\n  * Add Julia bindings (#1949).  Build settings can be controlled with the\n    `BUILD_JULIA_BINDINGS=(ON/OFF)` and `JULIA_EXECUTABLE=/path/to/julia` CMake\n    parameters.\n\n  * CMake fix for finding STB include directory (#2145).\n\n  * Add bindings for loading and saving images (#2019); `mlpack_image_converter`\n    from the command-line, `mlpack.image_converter()` from Python.\n\n  * Add normalization support for CF binding (#2136).\n\n  * Add Mish activation function (#2158).\n\n  * Update `init_rules` in AMF to allow users to merge two initialization\n    rules (#2151).\n\n  * Add GELU activation function (#2183).\n\n  * Better error handling of eigendecompositions and Cholesky decompositions\n    (#2088, #1840).\n\n  * Add LiSHT activation function (#2182).\n\n  * Add Valid and Same Padding for Transposed Convolution layer (#2163).\n\n  * Add CELU activation function (#2191)\n\n  * Add Log-Hyperbolic-Cosine Loss function (#2207).\n\n  * Change neural network types to avoid unnecessary use of rvalue references\n    (#2259).\n\n  * Bump minimum Boost version to 1.58 (#2305).\n\n  * Refactor STB support so `HAS_STB` macro is not needed when compiling against\n    mlpack (#2312).\n\n  * Add Hard Shrink Activation Function (#2186).\n\n  * Add Soft Shrink Activation Function (#2174).\n\n  * Add Hinge Embedding Loss Function (#2229).\n\n  * Add Cosine Embedding Loss Function (#2209).\n\n  * Add Margin Ranking Loss Function (#2264).\n\n  * Bugfix for incorrect parameter vector sizes in logistic regression and\n    softmax regression (#2359).\n\n## mlpack 3.2.2\n\n_2019-11-26_\n\n  * Add `valid` and `same` padding option in `Convolution` and `Atrous\n    Convolution` layer (#1988).\n\n  * Add Model() to the FFN class to access individual layers (#2043).\n\n  * Update documentation for pip and conda installation packages (#2044).\n\n  * Add bindings for linear SVM (#1935); `mlpack_linear_svm` from the\n    command-line, `linear_svm()` from Python.\n\n  * Add support to return the layer name as `std::string` (#1987).\n\n  * Speed and memory improvements for the Transposed Convolution layer (#1493).\n\n  * Fix Windows Python build configuration (#1885).\n\n  * Validate md5 of STB library after download (#2087).\n\n  * Add `__version__` to `__init__.py` (#2092).\n\n  * Correctly handle RNN sequences that are shorter than the value of rho (#2102).\n\n## mlpack 3.2.1\n\n_2019-10-01_\n\n  * Enforce CMake version check for ensmallen (#2032).\n\n  * Fix CMake check for Armadillo version (#2029).\n\n  * Better handling of when STB is not installed (#2033).\n\n  * Fix Naive Bayes classifier computations in high dimensions (#2022).\n\n## mlpack 3.2.0\n\n_2019-09-25_\n\n  * Fix some potential infinity errors in Naive Bayes Classifier (#2022).\n\n  * Fix occasionally-failing RADICAL test (#1924).\n\n  * Fix gcc 9 OpenMP compilation issue (#1970).\n\n  * Added support for loading and saving of images (#1903).\n\n  * Add Multiple Pole Balancing Environment (#1901, #1951).\n\n  * Added functionality for scaling of data (#1876); see the command-line\n    binding `mlpack_preprocess_scale` or Python binding `preprocess_scale()`.\n\n  * Add new parameter `maximum_depth` to decision tree and random forest\n    bindings (#1916).\n\n  * Fix prediction output of softmax regression when test set accuracy is\n    calculated (#1922).\n\n  * Pendulum environment now checks for termination. All RL environments now\n    have an option to terminate after a set number of time steps (no limit\n    by default) (#1941).\n\n  * Add support for probabilistic KDE (kernel density estimation) error bounds\n    when using the Gaussian kernel (#1934).\n\n  * Fix negative distances for cover tree computation (#1979).\n\n  * Fix cover tree building when all pairwise distances are 0 (#1986).\n\n  * Improve KDE pruning by reclaiming not used error tolerance (#1954, #1984).\n\n  * Optimizations for sparse matrix accesses in z-score normalization for CF\n    (#1989).\n\n  * Add `kmeans_max_iterations` option to GMM training binding `gmm_train_main`.\n\n  * Bump minimum Armadillo version to 8.400.0 due to ensmallen dependency\n    requirement (#2015).\n\n## mlpack 3.1.1\n\n_2019-05-26_\n\n  * Fix random forest bug for numerical-only data (#1887).\n\n  * Significant speedups for random forest (#1887).\n\n  * Random forest now has `minimum_gain_split` and `subspace_dim` parameters\n    (#1887).\n\n  * Decision tree parameter `print_training_error` deprecated in favor of\n    `print_training_accuracy`.\n\n  * `output` option changed to `predictions` for adaboost and perceptron\n    binding. Old options are now deprecated and will be preserved until mlpack\n    4.0.0 (#1882).\n\n  * Concatenated ReLU layer (#1843).\n\n  * Accelerate NormalizeLabels function using hashing instead of linear search\n    (see `src/mlpack/core/data/normalize_labels_impl.hpp`) (#1780).\n\n  * Add `ConfusionMatrix()` function for checking performance of classifiers\n    (#1798).\n\n  * Install ensmallen headers when it is downloaded during build (#1900).\n\n## mlpack 3.1.0\n\n_2019-04-25_\n\n  * Add DiagonalGaussianDistribution and DiagonalGMM classes to speed up the\n    diagonal covariance computation and deprecate DiagonalConstraint (#1666).\n\n  * Add kernel density estimation (KDE) implementation with bindings to other\n    languages (#1301).\n\n  * Where relevant, all models with a `Train()` method now return a `double`\n    value representing the goodness of fit (i.e. final objective value, error,\n    etc.) (#1678).\n\n  * Add implementation for linear support vector machine (see\n    `src/mlpack/methods/linear_svm`).\n\n  * Change DBSCAN to use PointSelectionPolicy and add OrderedPointSelection (#1625).\n\n  * Residual block support (#1594).\n\n  * Bidirectional RNN (#1626).\n\n  * Dice loss layer (#1674, #1714) and hard sigmoid layer (#1776).\n\n  * `output` option changed to `predictions` and `output_probabilities` to\n    `probabilities` for Naive Bayes binding (`mlpack_nbc`/`nbc()`).  Old options\n    are now deprecated and will be preserved until mlpack 4.0.0 (#1616).\n\n  * Add support for Diagonal GMMs to HMM code (#1658, #1666).  This can provide\n    large speedup when a diagonal GMM is acceptable as an emission probability\n    distribution.\n\n  * Python binding improvements: check parameter type (#1717), avoid copying\n    Pandas dataframes (#1711), handle Pandas Series objects (#1700).\n\n## mlpack 3.0.4\n\n_2018-11-13_\n\n  * Bump minimum CMake version to 3.3.2.\n\n  * CMake fixes for Ninja generator by Marc Espie.\n\n## mlpack 3.0.3\n\n_2018-07-27_\n\n  * Fix Visual Studio compilation issue (#1443).\n\n  * Allow running local_coordinate_coding binding with no initial_dictionary\n    parameter when input_model is not specified (#1457).\n\n  * Make use of OpenMP optional via the CMake 'USE_OPENMP' configuration\n    variable (#1474).\n\n  * Accelerate FNN training by 20-30% by avoiding redundant calculations\n    (#1467).\n\n  * Fix math::RandomSeed() usage in tests (#1462, #1440).\n\n  * Generate better Python setup.py with documentation (#1460).\n\n## mlpack 3.0.2\n\n_2018-06-08_\n\n  * Documentation generation fixes for Python bindings (#1421).\n\n  * Fix build error for man pages if command-line bindings are not being built\n    (#1424).\n\n  * Add 'shuffle' parameter and Shuffle() method to KFoldCV (#1412).  This will\n    shuffle the data when the object is constructed, or when Shuffle() is\n    called.\n\n  * Added neural network layers: AtrousConvolution (#1390), Embedding (#1401),\n    and LayerNorm (layer normalization) (#1389).\n\n  * Add Pendulum environment for reinforcement learning (#1388) and update\n    Mountain Car environment (#1394).\n\n## mlpack 3.0.1\n\n_2018-05-10_\n\n  * Fix intermittently failing tests (#1387).\n\n  * Add big-batch SGD (BBSGD) optimizer in\n    src/mlpack/core/optimizers/bigbatch_sgd/ (#1131).\n\n  * Fix simple compiler warnings (#1380, #1373).\n\n  * Simplify NeighborSearch constructor and Train() overloads (#1378).\n\n  * Add warning for OpenMP setting differences (#1358/#1382).  When mlpack is\n    compiled with OpenMP but another application is not (or vice versa), a\n    compilation warning will now be issued.\n\n  * Restructured loss functions in src/mlpack/methods/ann/ (#1365).\n\n  * Add environments for reinforcement learning tests (#1368, #1370, #1329).\n\n  * Allow single outputs for multiple timestep inputs for recurrent neural\n    networks (#1348).\n\n  * Add He and LeCun normal initializations for neural networks (#1342).\n    Neural networks: add He and LeCun normal initializations (#1342), add FReLU\n    and SELU activation functions (#1346, #1341), add alpha-dropout (#1349).\n\n## mlpack 3.0.0\n\n_2018-03-30_\n\n  * Speed and memory improvements for DBSCAN.  --single_mode can now be used for\n    situations where previously RAM usage was too high.\n\n  * Bump minimum required version of Armadillo to 6.500.0.\n\n  * Add automatically generated Python bindings.  These have the same interface\n    as the command-line programs.\n\n  * Add deep learning infrastructure in src/mlpack/methods/ann/.\n\n  * Add reinforcement learning infrastructure in\n    src/mlpack/methods/reinforcement_learning/.\n\n  * Add optimizers: AdaGrad, CMAES, CNE, FrankeWolfe, GradientDescent,\n    GridSearch, IQN, Katyusha, LineSearch, ParallelSGD, SARAH, SCD, SGDR,\n    SMORMS3, SPALeRA, SVRG.\n\n  * Add hyperparameter tuning infrastructure and cross-validation infrastructure\n    in src/mlpack/core/cv/ and src/mlpack/core/hpt/.\n\n  * Fix bug in mean shift.\n\n  * Add random forests (see src/mlpack/methods/random_forest).\n\n  * Numerous other bugfixes and testing improvements.\n\n  * Add randomized Krylov SVD and Block Krylov SVD.\n\n## mlpack 2.2.5\n\n_2017-08-25_\n\n  * Compilation fix for some systems (#1082).\n\n  * Fix PARAM_INT_OUT() (#1100).\n\n## mlpack 2.2.4\n\n_2017-07-18_\n\n  * Speed and memory improvements for DBSCAN. --single_mode can now be used for\n    situations where previously RAM usage was too high.\n\n  * Fix bug in CF causing incorrect recommendations.\n\n## mlpack 2.2.3\n\n_2017-05-24_\n\n  * Bug fix for --predictions_file in mlpack_decision_tree program.\n\n## mlpack 2.2.2\n\n_2017-05-04_\n\n  * Install backwards-compatibility mlpack_allknn and mlpack_allkfn programs;\n    note they are deprecated and will be removed in mlpack 3.0.0 (#992).\n\n  * Fix RStarTree bug that surfaced on OS X only (#964).\n\n  * Small fixes for MiniBatchSGD and SGD and tests.\n\n## mlpack 2.2.1\n\n_2017-04-13_\n\n  * Compilation fix for mlpack_nca and mlpack_test on older Armadillo versions\n    (#984).\n\n## mlpack 2.2.0\n\n_2017-03-21_\n\n  * Bugfix for mlpack_knn program (#816).\n\n  * Add decision tree implementation in methods/decision_tree/.  This is very\n    similar to a C4.5 tree learner.\n\n  * Add DBSCAN implementation in methods/dbscan/.\n\n  * Add support for multidimensional discrete distributions (#810, #830).\n\n  * Better output for Log::Debug/Log::Info/Log::Warn/Log::Fatal for Armadillo\n    objects (#895, #928).\n\n  * Refactor categorical CSV loading with boost::spirit for faster loading\n    (#681).\n\n## mlpack 2.1.1\n\n_2016-12-22_\n\n  * HMMs now use random initialization; this should fix some convergence issues\n    (#828).\n\n  * HMMs now initialize emissions according to the distribution of observations\n    (#833).\n\n  * Minor fix for formatted output (#814).\n\n  * Fix DecisionStump to properly work with any input type.\n\n## mlpack 2.1.0\n\n_2016-10-31_\n\n  * Fixed CoverTree to properly handle single-point datasets.\n\n  * Fixed a bug in CosineTree (and thus QUIC-SVD) that caused split failures for\n    some datasets (#717).\n\n  * Added mlpack_preprocess_describe program, which can be used to print\n    statistics on a given dataset (#742).\n\n  * Fix prioritized recursion for k-furthest-neighbor search (mlpack_kfn and the\n    KFN class), leading to orders-of-magnitude speedups in some cases.\n\n  * Bump minimum required version of Armadillo to 4.200.0.\n\n  * Added simple Gradient Descent optimizer, found in\n    src/mlpack/core/optimizers/gradient_descent/ (#792).\n\n  * Added approximate furthest neighbor search algorithms QDAFN and\n    DrusillaSelect in src/mlpack/methods/approx_kfn/, with command-line program\n    mlpack_approx_kfn.\n\n## mlpack 2.0.3\n\n_2016-07-21_\n\n  * Added multiprobe LSH (#691).  The parameter 'T' to LSHSearch::Search() can\n    now be used to control the number of extra bins that are probed, as can the\n    -T (--num_probes) option to mlpack_lsh.\n\n  * Added the Hilbert R tree to src/mlpack/core/tree/rectangle_tree/ (#664).  It\n    can be used as the typedef HilbertRTree, and it is now an option in the\n    mlpack_knn, mlpack_kfn, mlpack_range_search, and mlpack_krann command-line\n    programs.\n\n  * Added the mlpack_preprocess_split and mlpack_preprocess_binarize programs,\n    which can be used for preprocessing code (#650, #666).\n\n  * Added OpenMP support to LSHSearch and mlpack_lsh (#700).\n\n## mlpack 2.0.2\n\n_2016-06-20_\n\n  * Added the function LSHSearch::Projections(), which returns an arma::cube\n    with each projection table in a slice (#663).  Instead of Projection(i), you\n    should now use Projections().slice(i).\n\n  * A new constructor has been added to LSHSearch that creates objects using\n    projection tables provided in an arma::cube (#663).\n\n  * Handle zero-variance dimensions in DET (#515).\n\n  * Add MiniBatchSGD optimizer (src/mlpack/core/optimizers/minibatch_sgd/) and\n    allow its use in mlpack_logistic_regression and mlpack_nca programs.\n\n  * Add better backtrace support from Grzegorz Krajewski for Log::Fatal messages\n    when compiled with debugging and profiling symbols.  This requires libbfd\n    and libdl to be present during compilation.\n\n  * CosineTree test fix from Mikhail Lozhnikov (#358).\n\n  * Fixed HMM initial state estimation (#600).\n\n  * Changed versioning macros __MLPACK_VERSION_MAJOR, __MLPACK_VERSION_MINOR,\n    and __MLPACK_VERSION_PATCH to MLPACK_VERSION_MAJOR, MLPACK_VERSION_MINOR,\n    and MLPACK_VERSION_PATCH.  The old names will remain in place until\n    mlpack 3.0.0.\n\n  * Renamed mlpack_allknn, mlpack_allkfn, and mlpack_allkrann to mlpack_knn,\n    mlpack_kfn, and mlpack_krann.  The mlpack_allknn, mlpack_allkfn, and\n    mlpack_allkrann programs will remain as copies until mlpack 3.0.0.\n\n  * Add --random_initialization option to mlpack_hmm_train, for use when no\n    labels are provided.\n\n  * Add --kill_empty_clusters option to mlpack_kmeans and KillEmptyClusters\n    policy for the KMeans class (#595, #596).\n\n## mlpack 2.0.1\n\n_2016-02-04_\n\n  * Fix CMake to properly detect when MKL is being used with Armadillo.\n\n  * Minor parameter handling fixes to mlpack_logistic_regression (#504, #505).\n\n  * Properly install arma_config.hpp.\n\n  * Memory handling fixes for Hoeffding tree code.\n\n  * Add functions that allow changing training-time parameters to HoeffdingTree\n    class.\n\n  * Fix infinite loop in sparse coding test.\n\n  * Documentation spelling fixes (#501).\n\n  * Properly handle covariances for Gaussians with large condition number\n    (#496), preventing GMMs from filling with NaNs during training (and also\n    HMMs that use GMMs).\n\n  * CMake fixes for finding LAPACK and BLAS as Armadillo dependencies when ATLAS\n    is used.\n\n  * CMake fix for projects using mlpack's CMake configuration from elsewhere\n    (#512).\n\n## mlpack 2.0.0\n\n_2015-12-24_\n\n  * Removed overclustering support from k-means because it is not well-tested,\n    may be buggy, and is (I think) unused.  If this was support you were using,\n    open a bug or get in touch with us; it would not be hard for us to\n    reimplement it.\n\n  * Refactored KMeans to allow different types of Lloyd iterations.\n\n  * Added implementations of k-means: Elkan's algorithm, Hamerly's algorithm,\n    Pelleg-Moore's algorithm, and the DTNN (dual-tree nearest neighbor)\n    algorithm.\n\n  * Significant acceleration of LRSDP via the use of accu(a % b) instead of\n    trace(a * b).\n\n  * Added MatrixCompletion class (matrix_completion), which performs nuclear\n    norm minimization to fill unknown values of an input matrix.\n\n  * No more dependence on Boost.Random; now we use C++11 STL random support.\n\n  * Add softmax regression, contributed by Siddharth Agrawal and QiaoAn Chen.\n\n  * Changed NeighborSearch, RangeSearch, FastMKS, LSH, and RASearch API; these\n    classes now take the query sets in the Search() method, instead of in the\n    constructor.\n\n  * Use OpenMP, if available.  For now OpenMP support is only available in the\n    DET training code.\n\n  * Add support for predicting new test point values to LARS and the\n    command-line `lars` program.\n\n  * Add serialization support for `Perceptron` and `LogisticRegression`.\n\n  * Refactor SoftmaxRegression to predict into an `arma::Row<size_t>` object,\n    and add a `softmax_regression` program.\n\n  * Refactor LSH to allow loading and saving of models.\n\n  * ToString() is removed entirely (#487).\n\n  * Add `--input_model_file` and `--output_model_file` options to appropriate\n    machine learning algorithms.\n\n  * Rename all executables to start with an \"mlpack\" prefix (#229).\n\n  * Add HoeffdingTree and `mlpack_hoeffding_tree`, an implementation of the\n    streaming decision tree methodology from Domingos and Hulten in 2000.\n\n## mlpack 1.0.12\n\n_2015-01-07_\n\n  * Switch to 3-clause BSD license (from LGPL).\n\n## mlpack 1.0.11\n\n_2014-12-11_\n\n  * Proper handling of dimension calculation in PCA.\n\n  * Load parameter vectors properly for LinearRegression models.\n\n  * Linker fixes for AugLagrangian specializations under Visual Studio.\n\n  * Add support for observation weights to LinearRegression.\n\n  * `MahalanobisDistance<>` now takes the root of the distance by default and\n    therefore satisfies the triangle inequality (TakeRoot now defaults to true).\n\n  * Better handling of optional Armadillo HDF5 dependency.\n\n  * Fixes for numerous intermittent test failures.\n\n  * math::RandomSeed() now sets the random seed for recent (>=3.930) Armadillo\n    versions.\n\n  * Handle Newton method convergence better for\n    SparseCoding::OptimizeDictionary() and make maximum iterations a parameter.\n\n  * Known bug: CosineTree construction may fail in some cases on i386 systems\n    (#358).\n\n## mlpack 1.0.10\n\n_2014-08-29_\n\n  * Bugfix for NeighborSearch regression which caused very slow allknn/allkfn.\n    Speeds are now restored to approximately 1.0.8 speeds, with significant\n    improvement for the cover tree (#347).\n\n  * Detect dependencies correctly when ARMA_USE_WRAPPER is not being defined\n    (i.e., libarmadillo.so does not exist).\n\n  * Bugfix for compilation under Visual Studio (#348).\n\n## mlpack 1.0.9\n\n_2014-07-28_\n\n  * GMM initialization is now safer and provides a working GMM when constructed\n    with only the dimensionality and number of Gaussians (#301).\n\n  * Check for division by 0 in Forward-Backward Algorithm in HMMs (#301).\n\n  * Fix MaxVarianceNewCluster (used when re-initializing clusters for k-means)\n    (#301).\n\n  * Fixed implementation of Viterbi algorithm in HMM::Predict() (#303).\n\n  * Significant speedups for dual-tree algorithms using the cover tree (#235,\n    #314) including a faster implementation of FastMKS.\n\n  * Fix for LRSDP optimizer so that it compiles and can be used (#312).\n\n  * CF (collaborative filtering) now expects users and items to be zero-indexed,\n    not one-indexed (#311).\n\n  * CF::GetRecommendations() API change: now requires the number of\n    recommendations as the first parameter.  The number of users in the local\n    neighborhood should be specified with CF::NumUsersForSimilarity().\n\n  * Removed incorrect PeriodicHRectBound (#58).\n\n  * Refactor LRSDP into LRSDP class and standalone function to be optimized\n    (#305).\n\n  * Fix for centering in kernel PCA (#337).\n\n  * Added simulated annealing (SA) optimizer, contributed by Zhihao Lou.\n\n  * HMMs now support initial state probabilities; these can be set in the\n    constructor, trained, or set manually with HMM::Initial() (#302).\n\n  * Added Nyström method for kernel matrix approximation by Marcus Edel.\n\n  * Kernel PCA now supports using Nyström method for approximation.\n\n  * Ball trees now work with dual-tree algorithms, via the BallBound<> bound\n    structure (#307); fixed by Yash Vadalia.\n\n  * The NMF class is now AMF<>, and supports far more types of factorizations,\n    by Sumedh Ghaisas.\n\n  * A QUIC-SVD implementation has returned, written by Siddharth Agrawal and\n    based on older code from Mudit Gupta.\n\n  * Added perceptron and decision stump by Udit Saxena (these are weak learners\n    for an eventual AdaBoost class).\n\n  * Sparse autoencoder added by Siddharth Agrawal.\n\n## mlpack 1.0.8\n\n_2014-01-06_\n\n  * Memory leak in NeighborSearch index-mapping code fixed (#298).\n\n  * GMMs can be trained using the existing model as a starting point by\n    specifying an additional boolean parameter to GMM::Estimate() (#296).\n\n  * Logistic regression implementation added in methods/logistic_regression (see\n    also #293).\n\n  * L-BFGS optimizer now returns its function via Function().\n\n  * Version information is now obtainable via mlpack::util::GetVersion() or the\n    __MLPACK_VERSION_MAJOR, __MLPACK_VERSION_MINOR, and  __MLPACK_VERSION_PATCH\n    macros (#297).\n\n  * Fix typos in allkfn and allkrann output.\n\n## mlpack 1.0.7\n\n_2013-10-04_\n\n  * Cover tree support for range search (range_search), rank-approximate nearest\n    neighbors (allkrann), minimum spanning tree calculation (emst), and FastMKS\n    (fastmks).\n\n  * Dual-tree FastMKS implementation added and tested.\n\n  * Added collaborative filtering package (cf) that can provide recommendations\n    when given users and items.\n\n  * Fix for correctness of Kernel PCA (kernel_pca) (#270).\n\n  * Speedups for PCA and Kernel PCA (#198).\n\n  * Fix for correctness of Neighborhood Components Analysis (NCA) (#279).\n\n  * Minor speedups for dual-tree algorithms.\n\n  * Fix for Naive Bayes Classifier (nbc) (#269).\n\n  * Added a ridge regression option to LinearRegression (linear_regression)\n    (#286).\n\n  * Gaussian Mixture Models (gmm::GMM<>) now support arbitrary covariance matrix\n    constraints (#283).\n\n  * MVU (mvu) removed because it is known to not work (#183).\n\n  * Minor updates and fixes for kernels (in mlpack::kernel).\n\n## mlpack 1.0.6\n\n_2013-06-13_\n\n  * Minor bugfix so that FastMKS gets built.\n\n## mlpack 1.0.5\n\n_2013-05-01_\n\n  * Speedups of cover tree traversers (#235).\n\n  * Addition of rank-approximate nearest neighbors (RANN), found in\n    src/mlpack/methods/rann/.\n\n  * Addition of fast exact max-kernel search (FastMKS), found in\n    src/mlpack/methods/fastmks/.\n\n  * Fix for EM covariance estimation; this should improve GMM training time.\n\n  * More parameters for GMM estimation.\n\n  * Force GMM and GaussianDistribution covariance matrices to be positive\n    definite, so that training converges much more often.\n\n  * Add parameter for the tolerance of the Baum-Welch algorithm for HMM\n    training.\n\n  * Fix for compilation with clang compiler.\n\n  * Fix for k-furthest-neighbor-search.\n\n## mlpack 1.0.4\n\n_2013-02-08_\n\n  * Force minimum Armadillo version to 2.4.2.\n\n  * Better output of class types to streams; a class with a ToString() method\n    implemented can be sent to a stream with operator<<.\n\n  * Change return type of GMM::Estimate() to double (#257).\n\n  * Style fixes for k-means and RADICAL.\n\n  * Handle size_t support correctly with Armadillo 3.6.2 (#258).\n\n  * Add locality-sensitive hashing (LSH), found in src/mlpack/methods/lsh/.\n\n  * Better tests for SGD (stochastic gradient descent) and NCA (neighborhood\n    components analysis).\n\n## mlpack 1.0.3\n\n_2012-09-16_\n\n  * Remove internal sparse matrix support because Armadillo 3.4.0 now includes\n    it.  When using Armadillo versions older than 3.4.0, sparse matrix support\n    is not available.\n\n  * NCA (neighborhood components analysis) now support an arbitrary optimizer\n    (#245), including stochastic gradient descent (#249).\n\n## mlpack 1.0.2\n\n_2012-08-15_\n\n  * Added density estimation trees, found in src/mlpack/methods/det/.\n\n  * Added non-negative matrix factorization, found in src/mlpack/methods/nmf/.\n\n  * Added experimental cover tree implementation, found in\n    src/mlpack/core/tree/cover_tree/ (#157).\n\n  * Better reporting of boost::program_options errors (#225).\n\n  * Fix for timers on Windows (#212, #211).\n\n  * Fix for allknn and allkfn output (#204).\n\n  * Sparse coding dictionary initialization is now a template parameter (#220).\n\n## mlpack 1.0.1\n\n_2012-03-03_\n\n  * Added kernel principal components analysis (kernel PCA), found in\n    src/mlpack/methods/kernel_pca/ (#74).\n\n  * Fix for Lovasz-Theta AugLagrangian tests (#182).\n\n  * Fixes for allknn output (#185, #186).\n\n  * Added range search executable (#192).\n\n  * Adapted citations in documentation to BibTeX; no citations in -h output\n    (#195).\n\n  * Stop use of 'const char*' and prefer 'std::string' (#176).\n\n  * Support seeds for random numbers (#177).\n\n## mlpack 1.0.0\n\n_2011-12-17_\n\n  * Initial release.  See any resolved tickets numbered less than #196 or\n    execute this query:\n    http://www.mlpack.org/trac/query?status=closed&milestone=mlpack+1.0.0\n"
        },
        {
          "name": "LICENSE.txt",
          "type": "blob",
          "size": 1.99609375,
          "content": "mlpack is provided without any warranty of fitness for any purpose.  You\ncan redistribute the library and/or modify it under the terms of the 3-clause\nBSD license.  The text of the 3-clause BSD license is contained below.\n\n----\nCopyright (c) 2007-2023, mlpack contributors (see COPYRIGHT.txt)\nAll rights reserved.\n\nRedistribution and use of mlpack in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\nlist of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\nthis list of conditions and the following disclaimer in the documentation and/or\nother materials provided with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its contributors\nmay be used to endorse or promote products derived from this software without\nspecific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR\nANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\nANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n------\nmlpack also contains some usage of the source code of MNMLSTC Core library,\nwhich is a backport of C++17 features to C++11. MNMLSTC is licensed under the\nApache 2.0 License. This code can be found in src/mlpack/core/std_backport/ and\nmore details about licensing can be found there.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 8.5908203125,
          "content": "<h2 align=\"center\">\n  <a href=\"https://mlpack.org\"><img src=\"https://cdn.jsdelivr.net/gh/mlpack/mlpack.org@e7d36ed8/mlpack-black.svg\" style=\"background-color:rgba(0,0,0,0);\" height=230 alt=\"mlpack: a fast, header-only machine learning library\"></a>\n  <br>a fast, header-only machine learning library<br>\n</h2>\n\n<h5 align=\"center\">\n  <a href=\"https://mlpack.org\">Home</a> |\n  <a href=\"https://www.mlpack.org/download.html\">Download</a> |\n  <a href=\"https://www.mlpack.org/doc/index.html\">Documentation</a> |\n  <a href=\"https://www.mlpack.org/questions.html\">Help</a> |\n</h5>\n\n<p align=\"center\">\n  <a href=\"https://dev.azure.com/mlpack/mlpack/_build?definitionId=1\"><img alt=\"Azure DevOps builds (job)\" src=\"https://img.shields.io/azure-devops/build/mlpack/84320e87-76e3-4b6e-8b6e-3adaf6b36eed/1/master?job=Linux&label=Linux%20Build&style=flat-square\"></a>\n  <a href=\"https://opensource.org/license/BSD-3-Clause\"><img src=\"https://img.shields.io/badge/License-BSD%203--Clause-blue.svg?style=flat-square\" alt=\"License\"></a>\n  <a href=\"https://numfocus.org/donate-to-mlpack\"><img src=\"https://img.shields.io/badge/sponsored%20by-NumFOCUS-orange.svg?style=flat-square&colorA=E1523D&colorB=007D8A\" alt=\"NumFOCUS\"></a>\n</p>\n\n<p align=\"center\">\n  <em>\n    Download:\n    <a href=\"https://www.mlpack.org/files/mlpack-4.5.1.tar.gz\">current stable version (4.5.1)</a>\n  </em>\n</p>\n\n**mlpack** is an intuitive, fast, and flexible header-only C++ machine learning\nlibrary with bindings to other languages.  It is meant to be a machine learning\nanalog to LAPACK, and aims to implement a wide array of machine learning methods\nand functions as a \"swiss army knife\" for machine learning researchers.\n\nmlpack's lightweight C++ implementation makes it ideal for deployment, and it\ncan also be used for interactive prototyping via C++ notebooks (these can be\nseen in action on mlpack's [homepage](https://www.mlpack.org/)).\n\nIn addition to its powerful C++ interface, mlpack also provides command-line\nprograms, Python bindings, Julia bindings, Go bindings and R bindings.\n\n***Quick links:***\n\n - Quickstart guides: [C++](doc/quickstart/cpp.md),\n   [CLI](doc/quickstart/cli.md), [Python](doc/quickstart/python.md),\n   [R](doc/quickstart/r.md), [Julia](doc/quickstart/julia.md),\n   [Go](doc/quickstart/go.md)\n - [mlpack homepage](https://www.mlpack.org/)\n - [mlpack documentation](https://www.mlpack.org/doc/index.html)\n - [Examples repository](https://github.com/mlpack/examples/)\n - [Tutorials](doc/user/tutorials.md)\n - [Development Site (Github)](https://github.com/mlpack/mlpack/)\n\n[//]: # (numfocus-fiscal-sponsor-attribution)\n\nmlpack uses an [open governance model](./GOVERNANCE.md) and is fiscally\nsponsored by [NumFOCUS](https://numfocus.org/).  Consider making a\n[tax-deductible donation](https://numfocus.org/donate-to-mlpack) to help the\nproject pay for developer time, professional services, travel, workshops, and a\nvariety of other needs.\n\n<div align=\"center\">\n  <a href=\"https://numfocus.org/\">\n    <img height=\"60\"\n         src=\"https://raw.githubusercontent.com/numfocus/templates/master/images/numfocus-logo.png\"\n         align=\"middle\"\n         alt=\"NumFOCUS logo\">\n  </a>\n</div>\n<br>\n\n## 0. Contents\n\n 1. [Citation details](#1-citation-details)\n 2. [Dependencies](#2-dependencies)\n 3. [Installation](#3-installation)\n 4. [Usage from C++](#4-usage-from-c)\n     1. [Reducing compile time](#41-reducing-compile-time)\n 5. [Building mlpack's test suite](#5-building-mlpacks-test-suite)\n 6. [Further resources](#6-further-resources)\n\n## 1. Citation details\n\nIf you use mlpack in your research or software, please cite mlpack using the\ncitation below (given in BibTeX format):\n\n    @article{mlpack2023,\n        title     = {mlpack 4: a fast, header-only C++ machine learning library},\n        author    = {Ryan R. Curtin and Marcus Edel and Omar Shrit and \n                     Shubham Agrawal and Suryoday Basak and James J. Balamuta and \n                     Ryan Birmingham and Kartik Dutt and Dirk Eddelbuettel and \n                     Rishabh Garg and Shikhar Jaiswal and Aakash Kaushik and \n                     Sangyeon Kim and Anjishnu Mukherjee and Nanubala Gnana Sai and \n                     Nippun Sharma and Yashwant Singh Parihar and Roshan Swain and \n                     Conrad Sanderson},\n        journal   = {Journal of Open Source Software},\n        volume    = {8},\n        number    = {82},\n        pages     = {5026},\n        year      = {2023},\n        doi       = {10.21105/joss.05026},\n        url       = {https://doi.org/10.21105/joss.05026}\n    }\n\nCitations are beneficial for the growth and improvement of mlpack.\n\n## 2. Dependencies\n\n**mlpack** requires the following additional dependencies:\n\n - C++17 compiler\n - [Armadillo](https://arma.sourceforge.net)      &nbsp;&emsp;>= 10.8\n - [ensmallen](https://ensmallen.org)      &emsp;>= 2.10.0\n - [cereal](http://uscilab.github.io/cereal/)         &ensp;&nbsp;&emsp;&emsp;>= 1.1.2\n\nIf the STB library headers are available, image loading support will be\navailable.\n\nIf you are compiling Armadillo by hand, ensure that LAPACK and BLAS are enabled.\n\n## 3. Installation\n\nDetailed installation instructions can be found on the\n[Installing mlpack](doc/user/install.md) page.\n\n## 4. Usage from C++\n\nOnce headers are installed with `make install`, using mlpack in an application\nconsists only of including it.  So, your program should include mlpack:\n\n```c++\n#include <mlpack.hpp>\n```\n\nand when you link, be sure to link against Armadillo.  If your example program\nis `my_program.cpp`, your compiler is GCC, and you would like to compile with\nOpenMP support (recommended) and optimizations, compile like this:\n\n```sh\ng++ -O3 -std=c++17 -o my_program my_program.cpp -larmadillo -fopenmp\n```\n\nNote that if you want to serialize (save or load) neural networks, you should\nadd `#define MLPACK_ENABLE_ANN_SERIALIZATION` before including `<mlpack.hpp>`.\nIf you don't define `MLPACK_ENABLE_ANN_SERIALIZATION` and your code serializes a\nneural network, a compilation error will occur.\n\n***Warning:*** older versions of OpenBLAS (0.3.26 and older) compiled to use\npthreads may use too many threads for computation, causing significant slowdown.\nOpenBLAS versions compiled with OpenMP do not suffer from this issue.  See the\n[test build guide](doc/user/install.md#build-tests) for more details and simple\nworkarounds.\n\nSee also:\n\n * the [test program compilation section](doc/user/install.md#compiling-a-test-program)\n   of the installation documentation,\n * the [C++ quickstart](doc/quickstart/cpp.md), and\n * the [examples repository](https://github.com/mlpack/examples) repository for\n   some examples of mlpack applications in C++, with corresponding `Makefile`s.\n\n### 4.1. Reducing compile time\n\nmlpack is a template-heavy library, and if care is not used, compilation time of\na project can be very high.  Fortunately, there are a number of ways to reduce\ncompilation time:\n\n * Include individual headers, like `<mlpack/methods/decision_tree.hpp>`, if you\n   are only using one component, instead of `<mlpack.hpp>`.  This reduces the\n   amount of work the compiler has to do.\n\n * Only use the `MLPACK_ENABLE_ANN_SERIALIZATION` definition if you are\n   serializing neural networks in your code.  When this define is enabled,\n   compilation time will increase significantly, as the compiler must generate\n   code for every possible type of layer.  (The large amount of extra\n   compilation overhead is why this is not enabled by default.)\n\n * If you are using mlpack in multiple .cpp files, consider using [`extern\n   templates`](https://isocpp.org/wiki/faq/cpp11-language-templates) so that the\n   compiler only instantiates each template once; add an explicit template\n   instantiation for each mlpack template type you want to use in a .cpp file,\n   and then use `extern` definitions elsewhere to let the compiler know it\n   exists in a different file.\n\nOther strategies exist too, such as precompiled headers, compiler options,\n[`ccache`](https://ccache.dev), and others.\n\n## 5. Building mlpack's test suite\n\nSee the [installation instruction section](doc/user/install.md#build-tests).\n\n## 6. Further Resources\n\nMore documentation is available for both users and developers.\n\n * [Documentation homepage](https://www.mlpack.org/doc/index.html)\n\nTo learn about the development goals of mlpack in the short- and medium-term\nfuture, see the [vision document](https://www.mlpack.org/papers/vision.pdf).\n\nIf you have problems, find a bug, or need help, you can try visiting\nthe [mlpack help](https://www.mlpack.org/questions.html) page, or [mlpack on\nGithub](https://github.com/mlpack/mlpack/).  Alternately, mlpack help can be\nfound on Matrix at `#mlpack`; see also the\n[community](https://www.mlpack.org/doc/developer/community.html) page.\n"
        },
        {
          "name": "UPDATING.txt",
          "type": "blob",
          "size": 1.5400390625,
          "content": "mlpack uses semantic versioning for its versioning conventions\n(http://semver.org).\n\nBecause of the complexity and huge API of mlpack, it is worth elaborating on\nprecisely when and how backwards compatibility will be broken.  This will, of\ncourse, happen, as mlpack developers settle on increasingly effective\nabstractions for machine learning algorithms.\n\n * The command-line programs, bindings, and top-level classes for each machine\n   learning algorithm, as well as the code in core/, are considered the \"public\n   API\".  So, for instance, the mlpack_linear_regression program,\n   LinearRegression<>, and any bindings for LinearRegression<> are considered\n   the \"public API\"; additionally, core utilities like data::Load() and\n   data::Save() are considered \"public\".\n\n * Support classes for machine learning algorithms are considered the \"private\n   API\".  An example might be the mlpack::kmeans::MaxVarianceNewCluster class.\n   This is a support class for mlpack::kmeans::KMeans<> and generally isn't used\n   by end users.\n\nThus, with this relatively simple definition of \"public API\" and \"private API\",\nwe can provide a simple versioning scheme based completely on the semantic\nversioning guidelines:\n\n----\n\n  Given a version number MAJOR.MINOR.PATCH, increment the:\n\n  MAJOR version when you make incompatible public API changes,\n  MINOR version when you add public API functionality in a backwards-compatible\n      manner or make incompatible private API changes, and\n  PATCH version when you make backwards-compatible bug fixes or documentation\n      updates.\n\n----\n"
        },
        {
          "name": "dist",
          "type": "tree",
          "content": null
        },
        {
          "name": "doc",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}