{
  "metadata": {
    "timestamp": 1736565361757,
    "page": 192,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjIwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "PetoiCamp/OpenCat",
      "stars": 3727,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.4619140625,
          "content": ".idea/*\npyUI/.idea/*\npyUI/logfile*\npyUI/genApp4Mac/*\npyUI/genApp4Win/*\npyUI/lib/*\n*.DS_Store\n*.pyc\npyUI/defaultConfig.txt\npyUI/README.txt\npyUI/README_Mac.txt\npyUI/README_Windows.txt\npyUI/PetoiDesktopApp/*\n*.cfg\n*.svd\nModuleTests/testDoubleLight/debug_custom.json\nModuleTests/testDoubleAnalog/debug_custom.json\nModuleTests/testVoiceCommander/debug_custom.json\nModuleTests/testI2cDevice/debug_custom.json\n.vscode/*\npyUI/README.txt\npyUI/README_Mac.txt\npyUI/README_Windows.txt\n"
        },
        {
          "name": "ChangeLog.md",
          "type": "blob",
          "size": 16.1591796875,
          "content": "# Change Log\n\n## Mar6, 2023\n* Recover the skillName stored in **newCmd** array because the newCmd's memory is altered when formatting new skill data. \n* Fix the segfault caused by different string terminators: '\\0', '\\n', or '\\~'.\n* Fix the casting between int, char, and int8_t in the template function arrayNCPY().\n* When turning a joint instruction into a new posture, allow large joint angles to be stored into an int8_t array. \n* Fix the positive feedback when gyro data is combined into targetAngles.\n* SkillComposer: Disable the Gyro and Random buttons.\n* ardSerial: Simplify the slicing algorithm when sending long commands.\n* Differentiate the serial timeout for long commands over Bluetooth.\n* Simplify some skills to save memory. \n* Safer auto-connection algorithm when trying to connect to a camera that's not connected to any alternative addresses. \n* Mobile app: Find the optimal delay between the mobile app's package slices to avoid overflow or timeout on the mainboard. \n* Add a token 'S' to toggle on/off the boot-up melody. \n* Add a macro to inverse the servo's rotation directions.\n* Allow the robot to detect the falling-over event and recover even in turbo mode. \n* Desktop App: Add traditional Chinese and German translations. \n\n\n## Mar 1, 2023\n* Combine the **newCmd** array used for receiving different kinds(ASCII/Binary, long/short) of serial commands. \n* Simplify the token cases into upper/lower letters for Binary/ASCII encodings.\n* Shift the skill angle data to the end of the **newCmd** array. It allows new incoming messages to be stored at the beginning of the **newCmd** array while keeping the skill angles unchanged so that the previous skill can resume after finishing the current non-skill command. \n* It now supports much longer commands and skills, such as a behavior with **23** frames (23 * 20 + 7 = 467 bytes), a gait with (467-4)/8 = **57** frames or a long melody with 467/2 = **233** notes. On BiBoard, it supports a behavior with **125** frames (125 * 20 + 7 = 2507 bytes), a gait with (2507-4)/8 = **312** frames or a long melody with 2507/2 = **1253** notes.\n* Overflow protection when the incoming message is longer than the size of **newCmd** to avoid a crash. \n* Redesign the voice commands table and their encodings. \n* Add an alias skill \"up\" for \"balance\" to save memory and convenience. \n* Move the keys of the customized voice commands to PROGMEM.\n* Add new skills:\n\n| New Skill Name | Serial Code |\n|-----------|:------|\n|hug      \t|khg    |\n|handstand  |khdsd  |\n|hands up   |khu \t  |\n|handshake\t|khsk  \t|\n|sniff\t\t  |ksnf\t  |\n|dig\t    \t|kdg\t  |\n|scratch    |kscrh  |\n|be table \t|ktbl\t  |\n|boxing\t  \t|kbx\t  |\n|kick\t\t    |kkc\t  |\n|come here\t|kcmh\t  |\n|high five\t|kfiv\t  |\n|jump\t\t    |kjmp\t  |\n\n* With so many new skills saved to the I2C EEPROM, fix the overflow (wrapped overwriting) when a long 'K' skill data is written to the nearly full memory.\n* 'T' token is used to extract the last transferred skill data. Fixed the segfault when a newly configured board has never received a 'K' command but is required to read from an unknown memory. \n\n## Feb 25, 2023\n* Unbind the free joints' motion during walking and keep balancing reaction after the i,I,m,M commands. The free joints are unrelated to walking and balancing. By default, they move by trigonometric functions synced with the legs' pace. If a command requires specific joint movement, it will be unbound and taken over by the higher-level controller. Using the token 'i' or 'I' without more argument will re-bind them to the legs' motion.\n\nWhen sending joint instructions, the rules are:\n\n|     |All are free joints (head, tail, etc.) |Contain joints related to walking|\n|:--------------:|------------------------------|-------------------------------|\n|Gait\t\t\t       |move in perform() => gait  \t  |move in tranform() => convert to a new posture\t|\n|Posture         |move in perform() => posture  |move in tranform() => convert to a new posture\t|\n|Non-skill       |move in transform() => lastToken|move in tranform() => convert to a new posture => lastToken|\n\n* Allow explicitly assigning directions of skills. Only the neutral and the leftward skills are stored in the skill table with the suffix -F (only for gaits), -L, or no capitalized letter in the key. Previously all skills are called with random directions, except the gaits. \n\nLet Name be the skill's name. The new rules are:\n\n|       | Match?              |Mirror it?   |\n|-------|:-------------------:|:-----------:|\n|gaitF  |All characters       |N            |\n|nameL  |All characters       |N            |\n|nameR  |the first n-1 chars  |Mirror nameL |\n|name\t\t|All characters       |Random\t      |\n|nameX  |All characters \t    |Random       |\n\n* Debug the creation, pop, and deletion of TaskQueue for safer and more efficient memory management. Optimize the corresponding examples for light, touch, pir, gesture, camera, and voice sensors.\n\n## Feb 10, 2023\n* Allow controlling head group while walking.\n* Solve serial overflow.\n* Add random skill command: kx. It can call a random skill in the preset skill list. \n* Add macros to disable some unused tokens to save space.\n\n## Feb 7, 2023\n* Improve the serial read logics. \n* Print software version on boot up.\n* Add demos for pir, touch, light modules.\n* Allow sending long (450 bytes or 225 notes) melody over the serial port.\n\n## Feb 1, 2023\n* Add task queue within the Arduino code. A sequence of tasks can be performed without the need of another master computer. \n* Add demo code for 10 customized voice commands. \n\n## Jan 19, 2023\n* Allow manually select the serial port when the automatic algorithm fails.\n\n## Jan 12, 2023\n* Add demo code for the voice command module. \n* SkillComposer: Allow importing multiple skills from InstinctX.h.\n\n## Jan 5, 2023\n* Avoid the servos' shaking when booting up.\n* Add demo code for the gesture module.\n\n## Dec 29, 2022\n* SkillComposer: Avoid freezing when dragging the joint sliders.\n\n## Dec 26, 2022\n* Allow a unplug and replug algorithm to tell the intended serial port.\n* SkillCompser: Read the robot's name when starting up.\n\n## Dec 13, 2022\n* Improve the self-calibration algorithm of PCA9685\n\n## Dec 7, 2022\n* SkillComposer: Show warning forlower Python versions.\n\n## Nov 28, 2022\n* FirmwareUploader: Support BiBoard.\n\n## Nov 10, 2022\n* Create test8266Master.ino that can control the robot's motion in sequence.\n\n## Oct 26, 2022\n* Move the detailed initializing functions in **OpenCat.ino**'s setup() to OpenCat.h. \n* Add a simple example to elaborate the integration of customized sensors. You need to enable \"#define OTHER_MODULES\" to see its effects. \n\n## Aug 31, 2022\n* Add a watchdog to reset the board if the initialization for MPU or skills fails.\n* At the last stage of the first configuration process (with #define MAIN_SKETCH commented out), provide an optional step to calibrate the PCA9685's PWM frequency. The calibration value is saved in the EEPROM table to be loaded by the main sketch. \n* Change the unit of the duration for music notes ('b' and 'B' token) from duration (miliseconds) to half notes (use 2, 4, 8 to represent 1/2, 1/4, 1/8).\n* For Bittle: Add front flip, roll left, roll right, and tune back flip. It's better to remove its head to perform those tricks. \n* Shrink the size of codes for getting and saving MPU offsets.\n* Won't repeat the last behavior after roll recover.\n* ESP8266WiFiController: won't refresh the page after sending command to save time\n* ESP8266WiFiController: Simplify the cases on the main command page with a dictionary. \n* Add some new moduleTest codes\n\n## May 8, 2022\n* pyUI/ui.py: Add names to trigger axis\n* pyUI/ui.py: Optimize the layout for Windows machines\n* pyUI/ui.py: Add add hover tips to some buttons\n\n## May 4, 2022\n* pyUI/ui.py: Import and export files\n\n## May 2, 2022\n* pyUI/ui.py: Improve performance with large angles\n* pyUI/ui.py: Show connected ports\n* pyUI/ui.py: Improve logic and workflow for connecting multiple robots\n* pyUI/ui.py: Support connect to one or all robots dynamically\n* pyUI/ui.py: Improve global orientation and translation sliders\n* pyUI/ui.py: Change dial buttons from regular buttons to press-down buttons\n\n## Apr 30, 2022\n* pyUI/ui.py: Mirror single frame during editing\n* pyUI/ui.py: Fix bug in the loop structure when exporting \n\n## Apr 29, 2022\n* pyUI/ui.py: Add binders (both positive and negative) for joint sliders to control several joints together.\n* pyUI/ui.py: Can control multiple robots at once. \n* ardSerial: Get return value from threads.\n\n## Apr 24, 2022\n* pyUI/ui.py: Support loading and sending large angles\n* pyUI/ui.py: Optimize panel sizes\n\n## Apr 22, 2022\n* pyUI/ui.py: Support selecting different robot models. Update the center image for the model. \n* pyUI/ui.py: Support different lanuguages.\n* pyUI/ui.py: Support importing and exporting a multi-frame skill as a behavior or gait. A single frame will always be exported as a posture.\n* pyUI/ui.py: Update the skill frame's state for delete operations.\n* pyUI/ui.py: Check the format of skill data that's manually entered. Pop up a warning window.  \n\n## Apr 20, 2022\n* pyUI/ui.py: Support trigger axis and angles for behaviors\n* pyUI/ui.py: Allow stop when playing frames\n* Add a button to connect and disconnect the robot in the \"State Dials\" block\n* Change the texts of the state dials to indicate their states\n\n## Apr 19, 2022\n* pyUI/ui.py: Support importing existing skill array and editing them frame by frame. Speed and delay are included. The trigger axis of behaviors has not been implemented.\n* pyUI/ui.py: Export the skill to the robot and print the skill data array in the terminal. \n\n## Apr 6, 2022\n* Add ui.py in pyUI to allow changing the robot's postures and body tilts with sliders. \n* Improve the structure of ardSerial.py to allow continuous inputs when it's used as a commandline tool. \n* Fix a bug when a static posture is called after a gait by resetting the frame to 0.\n\n## Mar 29, 2022\n* Use dataBuffer to hold the incoming serial commands to allow a longer melody and other instructions. newCmd will only be used to hold skill names that are shorter. \n* Save the serial skill data from the dataBuffer to I2C EEPROM so that it can be recalled. \n\n## Mar 20, 2022\n* A schedulerToSkill function in serialMaster to summerize the motion commands and generate a new skill array that can be directly used in the instinct.h.\n* Design a convenient macro switch for regular walker, ultrasonic, and voice modes. \n```cpp\n//you can activate the following modes (they will diable the gyro to save programming space)\n//allowed combinations: RANDOM_MIND, ULTRASONIC, RANDOM_MIND + ULTRASONIC, VOICE\n//#define RANDOM_MIND     //let the robot do random stuffs. use token 'z' to activate/deactivate\n//#define ULTRASONIC      //for Nybble's ultrasonic sensor\n//#define VOICE           //for LD3320 module\n```\n\n## Mar 17, 2022\n### OpenCat2.0 is pushed to the branch 2.0 for beta testers.\n### New Features:\n* **Complete redesign of the code structure to make it easier to understand and insert 3rd party codes.**\n* **Combine WriteInstinct.ino and OpenCat.ino into a single OpenCat.ino.** Use the ```#define MAIN_SKETCH``` macro to switch between the modes. \n* Fixed many bugs in the original workflow. For example, the robot no longer skips commands randomly.\n* Improved the smoothness of motion and the speed of balance adaption. \n* A better documented serialMaster Python module and provide a command scheduler in example.py. \n* **Designd a new token \"K\"** to send a whole skill array from the Python serial master through serial in realtime then run it locally on the robot.\n* Optimized the token definitions. Print the token after finishing one task as a confirmation to the master program. \n* Used a new MPU6050 function to avoid using the interrupt pin. **Accelerate the IMU calibration process.** \n* Enter the joint calibration state by booting up the robot with one side up. \n* Write a formalized servo class inherited from the AdafruitPWM servo library. Make it easier to change parameters of 3rd party servos.\n* **Use the built-in tone function to generate clean beeps and melody.**\n* Add random actions for the robot to make it more life-like. Use token ‘z’ to turn on/off the feature. \n* Add angle limits to avoid most cases of of self-collision.\n* Put the skill-related functions into the Skill Class. Combine reused code blocks into single functions.\n* Make more use of the EEPROM and PRGMEM memory to save resources for flash and SRAM.\n* Mirror rightward gaits from the leftward gaits, to save static memory. \n* Allow both “newline” and “no line ending” for the serial monitor.\n* Add support for LD3320 voice recognition module (the current code works for Chinese).\n\n## Jan 30, 2022\n* Fix type conversion warnings of skill data.\n* Add demo for testBuzzer.ino using Arduino's built-in tone function. However, it cannot be used for the main program because ATmega328P has only two timers, used up by the IR and IMU. \n\n## Jan 11, 2022\n* Create a mirror function to allow the robot pick random directions of behaviors. It makes the robot more unpredictable and helps it get rid of an infinite loop, such as failed fall-recovering against a wall.  \n\n## Jan 3, 2022\n* Put the dependent libraries within the OpenCat folder so that no more downloading is required to configure OpenCat's environment in Arduino. \n\nIt's nasty to include the **src/** libraries here rather than Arduino's desinated library folder, especially when we have to duplicate the **src/** in two layers within the same project folder.  \n\nWe do this only to help those users who are new to Arduino and complained about the difficulties of configuring the Arduino environment. You may find more informative comments within those library files. \n\n\n## Dec 29, 2021\n* Organinzed serialMaster/ and its demo codes\n* fixed the divide by zero bug in calibratedPWM()\n\n## Dec 11, 2021\n* Fix bug of \"wrong key!\" messages after g, p\n\n## Dec 3, 2021\n* Modified the \"hi\" behavior of Nybble so its tail will not push Nybble over;\n* Replaced the \"look up\" behavior with \"stand\". Make sure you hold Nybble when first trying it. \n\n## Nov 28, 2021\n* Add the march gait that only works well with gyro off; \n* Fix many typos with the help of Grammarly.\n\n## Sep 29, 2021\n* Print the robot's state (paused and gyro) when \"g\" and \"p\" is entered:\n\n| State  | True  | False |\n|:----------|:----------|:----------|\n| Pause    | P (paused)    | p (unpaused)    |\n| Gyro   | G (on)    | g (off)   |\n\n## Sep 26, 2021\n* Move the codes for EEPROM to function configureEEPROM() in OpenCat.h;\n\n## Sep 18, 2021\n* Copied the required files of IRremote library to OpenCat/src/ to help new Arduino users config the environment. \n* Cancel \"pause\" of motion if other commands are received. \n\n\n## Sep 16, 2021\n* Move the EEPROM related functions from WriteInstinct.ino to OpenCat.h.\n* Added a \"stand\" behavior for Nybble so that it can stand up with its hind legs and tail. \n\n## Sep 9, 2021\n* Print the list of calibration offsets before the joints' movements to help the App read the values.\n\n\n## Aug 31, 2021\n* Moved the device's model info (Nybble/Bittle) to the top of booting printouts.\n* Added a shorter encoding for the IR remote to save flash by about 178 Bytes.\n\n## Aug 25, 2021\n* Added an 'M' token to move multiple indexed joints to angles (ASCII format entered in the serial monitor) simultaneously;\n* Re-arranged the IR keymap for the new customized IR panel.\n\n## Jun 29, 2021\n* OpenCat.ino will print out the model name (Bittle/Nybble) at booting up.\n* Moved #define I2C_EEPROM to the beginning OpenCat.h.\n\n## Jun 7, 2021\n\n* Adjusted the threshold voltage so that Bittle will keep beeping when the battery goes under 6.5V, a few moments before the battery power shuts off;\n* Adjusted the gaits so that the elbow won't hit the body in the accelerated phase. \n* The trot on key \"1\" is tuned to be faster.\n* Removed the running gait on the IR remote key \"2\" and replaced it with \"check around\" behavior previously on key \"3\";\n* Assigned a \"play dead\" trick to IR remote key \"3\". Bittle will fall on its back then roll back (if the gyro is activated);\n* Removed the behavior when the robot is tilted at a large angle to avoid an occasional bug. Will put the behavior back if the bug can be fixed; \n* Added an auto-detection code for a new sound&light sensor connected to the analog Grove pin. Some new automated behaviors are being developed. The code block won't be active if the sensor is not connected to the Analog Grove socket;\n\n\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0439453125,
          "content": "MIT License\n\nCopyright (c) 2022 Rongzhong Li\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "ModuleTests",
          "type": "tree",
          "content": null
        },
        {
          "name": "OpenCat.ino",
          "type": "blob",
          "size": 6.8759765625,
          "content": "/*\n   The driver for OpenCat, runs on ATmega328P-based NyBoard (as Arduino Uno).\n   Compatible with Petoi Nybble, Bittle, and many other 8 or 12 DoF quadruped robots.\n   Drives up to 16 PWM servos.\n\n   Rongzhong Li\n   Mar 15rd, 2022\n   Copyright (c) 2022 Petoi LLC.\n\n   This sketch may also include others' codes under MIT or other open-source licenses.\n   Check those licenses in the corresponding module test folders.\n   Feel free to contact us if you find any missing references.\n\n  The MIT License\n\n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to deal\n  in the Software without restriction, including without limitation the rights\n  to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n  copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n  The above copyright notice and this permission notice shall be included in all\n  copies or substantial portions of the Software.\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n  SOFTWARE.\n*/\n\n/*\n  To configure the board:\n  1. Select your robot and board version.\n  2. Comment out #define MAIN_SKETCH and upload. Upload and follow the serial prompts to proceed.\n  3. Uncomment #define MAIN_SKETCH to make it active. Then upload the program for main functions.\n*/\n\n#define MAIN_SKETCH  //the Petoi App only works when this mode is on\n// #define AUTO_INIT //automatically select 'Y' for the reset joint and IMU prompts\n// #define DEVELOPER //to print out some verbose debugging data\n// it may increase the code size and crash the bootloader.\n// make sure you know ISP and how to reset the bootloader!!!\n\n#define BITTLE  //Petoi 9 DOF robot dog: 1x on head + 8x on leg\n// #define NYBBLE  //Petoi 11 DOF robot cat: 2x on head + 1x on tail + 8x on leg\n\n// #define NyBoard_V0_1\n// #define NyBoard_V0_2\n// #define NyBoard_V1_0\n// #define NyBoard_V1_1\n#define NyBoard_V1_2\n\n// you can also activate the following modes (they will disable the gyro to save programming space)\n// allowed combinations: RANDOM_MIND + ULTRASONIC, RANDOM_MIND, ULTRASONIC, VOICE, CAMERA\n// #define RANDOM_MIND  //advanced random behaviors. use token 'z' to activate/deactivate\n// #define TASK_QUEUE  //allow executing a sequence of tasks, if you enabled the other modules, the task queue will be automatically enabled. \\\n                    // because it takes up memory, it will be disabled if the GYRO is enabled. See \"#undef TASK_QUEUE\" under ifdef GYRO\n// #define ULTRASONIC      //for Nybble's ultrasonic sensor\n// #define VOICE  //Petoi Grove voice module\n// #define VOICE_LD3320    //for LD3320 module\n// #define PIR             //for PIR (Passive Infrared) sensor\n//#define DOUBLE_TOUCH  //for double touch sensor\n//#define DOUBLE_LIGHT  //for double light sensor\n// #define DOUBLE_INFRARED_DISTANCE  //for double infrared distance sensor\n// #define GESTURE  //for Gesture module\n// #define CAMERA  //for human body tracking or ball tracking using an intelligent camera\n// You need to install https://github.com/mu-opensource/MuVisionSensor3 as a zip library in Arduino IDE.\n// Set the four dial switches on the camera as **v ^ v v** (the second switch dialed up to I2C) and connect the camera module to the I2C grove on NyBoard.\n// The battery should be turned on to drive the servos.\n//\n// You can use these 3D printed structures to attach the camera module.\n// https://github.com/PetoiCamp/NonCodeFiles/blob/master/stl/MuIntelligentCamera_mount.stl\n// https://github.com/PetoiCamp/NonCodeFiles/blob/master/stl/bone.stl\n// After uploading the code, you may need to press the reset buttons on the module and then the NyBoard.\n// The tracking demo works the best with a yellow tennis ball or some other round objects. Demo: https://www.youtube.com/watch?v=CxGI-MzCGWM\n// #define GROVE_SERIAL_PASS_THROUGH  //allow analog/digital read/write GPIO pins through serial protocol\n// #define OTHER_MODULES  //uncomment this line to disable the gyroscope code to save programming resources for other modules.\n// #define ROBOT_ARM\n\n#define IR_PIN 4  // Signal Pin of IR receiver to Arduino Digital Pin 4\n#include \"src/OpenCat.h\"\n\nvoid setup() {\n  Serial.begin(BAUD_RATE);\n  Serial.setTimeout(SERIAL_TIMEOUT);\n  // while (Serial.available() && Serial.read());  // empty buffer\n\n  // join I2C bus (I2Cdev library doesn't do this automatically)\n  //#if I2CDEV_IMPLEMENTATION == I2CDEV_ARDUINO_WIRE\n  Wire.begin();\n  //  TWBR = 24; // 400kHz I2C clock (200kHz if CPU is 8MHz)\n  Wire.setClock(500000L);\n  //#elif I2CDEV_IMPLEMENTATION == I2CDEV_BUILTIN_FASTWIRE\n  //  Fastwire::setup(400, true);\n  //#endif\n  initRobot();\n}\n\nvoid loop() {\n#ifdef MAIN_SKETCH\n#ifdef GYRO_PIN\n  readEnvironment();     //reads the IMU (Inertia Measurement Unit, i.e. acceleration and angles).\n                         //May read more sensors in the future\n  dealWithExceptions();  //fall over, lifted, etc.\n#endif\n\n#ifdef TASK_QUEUE\n  if (!tQueue->empty()) {\n    tQueue->popTask();\n  } else\n#endif\n  {\n    readSignal();  //commands sent by user interfaces and sensors\n#ifdef OTHER_MODULES\n    otherModule();  //you can create your own code here\n                    //or put it in the readSignal() function of src/io.h\n#endif\n  }\n  reaction();  //handle different commands\n#ifdef VOLTAGE_DETECTION_PIN\n  lowBattery();  //  block the loop if battery is low\n  //  can be disabled to save programming space and reduce the low voltage interruptions\n#endif\n#else\n  calibratePCA9685();\n#endif\n}\n\n#ifdef OTHER_MODULES  //remember to activate the #define OTHER_MODULES at the begining of this code to activate the following section\nint prevReading = 0;\nvoid otherModule() {  //this is an example that use the analog input pin A2 as a touch pad\n                      //The A2 pin is in the second Grove socket of the NyBoard\n  int currentReading = analogRead(A2);\n  if (abs(currentReading - prevReading) > 50) {  //filter noise\n    PT(\"Reading on pin A2:\\t\");\n    PTL(currentReading);\n    if (currentReading < 100) {  //touch and hold on the A2 pin until the condition is met\n      beep(10, 20, 50, 3);       //make sound within this function body\n      tQueue->createTask();      //more tokens are defined in OpenCat.h\n    } else {\n      strcpy(newCmd, \"sit\");          //load a skill to be processed by the later reaction function\n      if (strcmp(lastCmd, newCmd)) {  //won't repeatively load the same skill\n        newCmdIdx = 5;\n        token = T_SKILL;  //T_SKILL loads a skill\n      }\n    }\n  }\n  prevReading = currentReading;\n}\n#endif\n"
        },
        {
          "name": "OpenCatPythonAPI",
          "type": "tree",
          "content": null
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 9.6904296875,
          "content": "# OpenCat\n\nOpenCat is the open-source Arduino and Raspberry Pi-based quadruped robotic pet framework developed by Petoi, the maker of futuristic programmable robotic pets.\n\n![](https://github.com/PetoiCamp/NonCodeFiles/blob/master/gif/walk.gif?raw=true)\n\n![](https://github.com/PetoiCamp/NonCodeFiles/blob/master/gif/run.gif?raw=true)\n\nInspired by Boston Dynamics' Big Dog and Spot Mini, Dr. Rongzhong Li started the project in his dorm at Wake Forest University in 2016. After one year of R&D, he founded Petoi LLC and devoted all his resources to developing open source robots. \n\nThe goal is to foster collaboration in quadruped(four-legged) robotic research, education, and engineering development of agile and affordable quadruped robot pets, bring STEM concepts to the mass, and inspire newcomers (including many kids and adults) to join the robotic AI revolution to create more applications.\n\n![](https://github.com/PetoiCamp/NonCodeFiles/blob/master/gif/slope.gif?raw=true)\n\nThe project is [a complex quadruped robot system](https://www.petoi.com/pages/petoi-programmable-quadruped-robot-system) for anyone exploring quadruped robotics. We want to share our design and work with the community and bring down the hardware and software costs with mass production. OpenCat has been deployed on all Petoi's bionic palm-sized, realistic lifelike [cute robot cat Nybble](https://www.petoi.com/collections/robots/products/petoi-nybble-robot-cat?utm_source=github&utm_medium=code&utm_campaign=nybble) and\n[high-performance robot dog Bittle](https://www.petoi.com/collections/robots/products/petoi-bittle-robot-dog?utm_source=github&utm_medium=code&utm_campaign=bittle). We now have established a production line and can ship these [affordable robotic kits and accessories](https://www.petoi.com/store?utm_source=github&utm_medium=code&utm_campaign=store) worldwide.\n\nThis project provides a base open source platform to create amazing programmable gaits, locomotion, and deployment of inverse kinematics quadruped robots and bring simulations to the real world via block-based coding/C/C++/Python programming languages.  \n\nOur users have deployed many robotics/AI/IoT applications:\n- [robot dog with autonomous movement & object detection](https://www.petoi.com/blogs/blog/reid-graves-robotics-ai-applications-with-bittle-robot-dog-raspberry-pi)\n- [Raspberry Pi robotics projects](https://www.petoi.com/blogs/blog/raspberry-pi-robotics-projects-with-petoi-open-source-quadruped-robots)\n- [NVIDIA Issac simulations and reinforcement learning on our robots](https://www.youtube.com/playlist?list=PLHMFXft_rV6MWNGyofDzRhpatxZuUZMdg)\n- [developed visual and lidar-based SLAM with ROS using Bittle and Raspberry Pi](https://www.youtube.com/watch?v=uXpQUIF_Jyk&list=PLHMFXft_rV6MWNGyofDzRhpatxZuUZMdg&index=6)\n- [imitation learning using Tiny Machine Learning Models with Petoi Bittle and Raspberry Pi](https://www.learnwitharobot.com/p/imitation-learning-with-petoi-bittle)\n- [IoT automation of a robot fleet with AWS to improve worker safety](https://www.petoi.com/blogs/blog/aws-iot-robot-fleet-demo-with-petoi-bittle)\n- [3D-Printed Accessories](https://www.petoi.com/blogs/blog/petoi-bittle-bittle-x-robots-3d-printed-robot-accessories)\n- build their own [DIY 3D-print robot pets](https://www.petoi.com/pages/3d-printed-robot-dog-robot-cat) powered by OpenCat\n\n![](https://github.com/PetoiCamp/NonCodeFiles/blob/master/gif/stand.gif?raw=true)\n\n![](https://github.com/PetoiCamp/NonCodeFiles/blob/master/gif/NybbleBalance.gif?raw=true)\n\nWe've successfully crowdfunded these two mini robot kits and shipped thousands of units worldwide. \n\nWith our [customized Arduino-Uno board](https://www.petoi.com/products/nyboard-customized-arduino-board) and [high-performance servos](https://www.petoi.com/products/quadruped-robot-dog-bittle-servo-set) coordinating all instinctive and sophisticated movements(walking, running, jumping, backflipping), one can clip on [various sensors](https://www.petoi.com/products/petoi-sensor-pack) and [camera](https://www.petoi.com/products/intelligent-camera-module) to bring in perception and inject artificial intelligence capabilities by mounting a Raspberry Pi or other AI chips(such as Nvidia Jetson Nano) through wired/wireless connections. \n \nPlease see [Petoi FAQs](https://www.petoi.com/pages/faq?utm_source=github&utm_medium=code&utm_campaign=faq) for more info.\n\nAlso, Check out [all of the OpenCat and Petoi robot user showcases](https://www.petoi.camp/forum/showcase).\n\n![](https://github.com/PetoiCamp/NonCodeFiles/blob/master/gif/ball.gif?raw=true)\n\n## Setup  Process:\n\nOpenCat software works on both Nybble and Bittle, controlled by NyBoard based on ATmega328P. More detailed documentation can be found at the [Petoi Doc Center](https://docs.petoi.com).\n\nTo configure the board:\n\n1. Download the repo and unfold. Remove the **-main** (or any branch name) suffix of the folder.\n\n2. Open the file OpenCat.ino, select your robot and board version.\n```cpp\n#define BITTLE    //Petoi 9 DOF robot dog: 1x on head + 8x on leg\n//#define NYBBLE  //Petoi 11 DOF robot cat: 2x on head + 1x on tail + 8x on leg\n\n//#define NyBoard_V0_1\n//#define NyBoard_V0_2\n#define NyBoard_V1_0\n//#define NyBoard_V1_1\n```\n\n3. Comment out ```#define MAIN_SKETCH``` so that it will turn the code to the board configuration mode. Upload and follow the serial prompts to proceed.\n```cpp\n// #define MAIN_SKETCH\n```\n\n4. If you activate ```#define AUTO_INIT```, the program will automatically set up without prompts. It will not reset joint offsets but calibrate the IMU. It's just a convenient option for our production line.\n\n5. Plug the USB uploader to the NyBoard and install the driver if no USB port is found under Arduino -> Tools -> Port.\n\n6. Press the upload button (->) at the top-left corner in Arduino IDE.\n\n7. Open the serial monitor of Arduino IDE. You can find the button either under Tools, or at the top-right corner of the IDE.\n\nSet the serial monitor as **no line ending** and **115200** baud rate.\nThe serial prompts:\n```\nReset joint offsets? (Y/n)\nY\n```\n\nInput ‘Y’ and hit enter, if you want to reset all the joint offsets to 0.\n\nThe program will do the reset, then update the constants and instinctive skills in the static memory.\n\n8. IMU (Inertial Measurement Unit) calibration.\n\nThe serial prompts:\n```\nCalibrate the IMU? (Y/n):\nY\n```\nInput ‘Y’ and hit enter, if you have never calibrated the IMU or want to redo calibration.\n\nPut the robot flat on the table and don't touch it. The robot will long beep six times to give you enough time. Then it will read hundreds of sensor data and save the offsets. It will beep when the calibration finishes.\n\nWhen the serial monitor prints \"Ready!\", you can close the serial monitor to do the next step.\n\n9. Uncomment ```#define MAIN_SKETCH``` to make it active. This time the code becomes the normal program for the major functionalities. Upload the code.\n```cpp\n#define MAIN_SKETCH\n```\nWhen the serial monitor prints \"Ready!\", the robot is ready to take your next instructions.\n\n10. If you have never calibrated the joints’ offsets or reset the offsets in Step2, you need to calibrate them. If you boot up the robot with one side up, it will enter the calibration state automatically for you to install the legs. Otherwise, it will enter the normal rest state\n\n11. You can use the serial monitor to calibrate it directly. Or you may plug in the Bluetooth dongle, and use the Petoi app (on Android/iOS) for a more user-friendly interface. The mobile app is available on:\n\n* IOS: [App Store](https://apps.apple.com/us/app/petoi/id1581548095)\n* Android: [Google Play](https://play.google.com/store/apps/details?id=com.petoi.petoiapp)\n\nYou can refer to the calibration section in the user manual (https://bittle.petoi.com/6-calibration) and Guide for the Petoi App(https://docs.petoi.com/app-guide).\n\n12. you can use the infrared remote or other applications (such as the Petoi App, Python, serial monitor ... etc.) to play with the robot (https://bittle.petoi.com/7-play-with-bittle).\n\nFor updates:\n* star this repository to receive timely notifications on changes.\n* visit www.petoi.com and [subscribe to our official newsletters](https://www.petoi.com/pages/subscribe-petoi-newsletter) for project announcements. We also host a forum at [petoi.camp](https://www.petoi.com/forum).\n* follow us on [Twitter](https://twitter.com/petoicamp), [Instagram](https://www.instagram.com/petoicamp/), [Facebook](https://www.facebook.com/PetoiCamp/), [Linkedin](https://www.linkedin.com/company/33449768/admin/dashboard/), and [YouTube channel](https://www.youtube.com/c/rongzhongli) for fun videos and community activities.\n\n![](https://github.com/PetoiCamp/NonCodeFiles/blob/master/gif/backflip.gif?raw=true)\n\n## Resources:\n* [Advanced tutorials made by users](https://www.youtube.com/playlist?list=PLHMFXft_rV6MWNGyofDzRhpatxZuUZMdg)\n* [Review, open-box, and demos by users](https://www.youtube.com/playlist?list=PLHMFXft_rV6PSS3Qu5yQ-0iPW-ohu1sM3)\n* [OpenCat robot showcase by users](https://www.petoi.com/pages/petoi-open-source-extensions-user-demos-and-hacks)\n* [OpenCat robot gallery](https://www.petoi.com/pages/robot-pet-gallery)\n\nOpenCat robots have been used in robotics education for K12 schools and colleges to teach students about STEM, coding, and robotics:\n- [robotics education showcases](https://www.petoi.com/blogs/blog/tagged/showcase+education)\n- [STEM & Robotics Curriculum & Resources for Teaching Coding & Robotics](https://www.petoi.com/pages/resources-curriculum-stem-coding-robot)\n- [Robotics competitions](https://www.petoi.com/blogs/blog/robot-competitions-with-petoi)\n- [Petoi robotics contest](https://www.petoi.com/blogs/blog/petoi-spring-2024-robotics-contest-winners)\n\nThe [old repository for OpenCat](https://github.com/PetoiCamp/OpenCat-Old) is too redundant with large image logs and is obsolete with no further updates.\n"
        },
        {
          "name": "Resources",
          "type": "tree",
          "content": null
        },
        {
          "name": "SkillLibrary",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyUI",
          "type": "tree",
          "content": null
        },
        {
          "name": "serialMaster",
          "type": "tree",
          "content": null
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}