{
  "metadata": {
    "timestamp": 1736565532660,
    "page": 408,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQxMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "mkleehammer/pyodbc",
      "stars": 2964,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".flake8",
          "type": "blob",
          "size": 0.1796875,
          "content": "[flake8]\nmax_line_length: 95\nignore =\n  E221,\n  # multi spaces before op - I line up assignments often\n  E401,\n  # multiple imports on one line\n  E722,\n  # ignore bare except in tests\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.7060546875,
          "content": "# This file is based largely on the GitHub .gitignore template for Python:\n# https://github.com/github/gitignore/blob/master/Python.gitignore\n\n# Python\n__pycache__/\n*.py[cod]\nsetup.cfg\n\n# C extensions\n*.so\n*.dll\n\n# Distribution / packaging\nbuild/\ndist/\nlib/\nlib64/\nMANIFEST\n/PKG-INFO\nsdist/\nwheelhouse/\n*.egg-info/\n*.egg\n\n# Unit test / coverage reports\n.tox/\n.coverage\npytest.ini\n\n# Virtual Environments\n/venv*\n/.env/\n/.venv\n\n# JetBrains\n.idea/\n\n# Visual Studio\n.vscode/\n.vs/\n*.sln\n*.vcxproj*\nx64/\nx86/\n*.pdb\n\n# Executables\n*.exe\n\n# Linters\n.flake8\n.pylintrc\n.ruff_cache/\nruff.toml\n\n# Other\npyodbc.conf\ntmp\ntags\nxxx_*\n\n# The Access unit tests copy empty.accdb and empty.mdb to these names and use them.\ntest.accdb\ntest.mdb\n"
        },
        {
          "name": "HACKING.md",
          "type": "blob",
          "size": 0.970703125,
          "content": "\n\n# Development Testing\n\nWe use tox for complete testing, but when you are in the middle of development you need fast\nturn around.  In this mode you need to be able to build and run tests using pytest manually.\nTo do this, build from the root of the directory using `--inplace` which will build the library\ninto the root.  Run pytest from the same root directory and the new pyodbc library you built\nwill be in the path for your test:\n\n    python setup.py build_ext --inplace\n    pytest test/test_postgresql.py -vxk test_text\n\nIf a segmentation fault occurs while running tests, pytest will have eaten the output.  Add\n-s to the command line:\n\n    python setup.py build_ext --inplace -D PYODBC_TRACE\n    pytest test/test_postgresql.py -vxk test_text -vs\n\n\n# Notes\n\n## uint16_t\n\nYou'll notice we use uint16_t instead of SQLWCHAR.  The unixODBC headers would define SQLWCHAR\nas wchar_t even when wchar_t as defined by the C library as uint32_t.  The data in the buffer\nwas still 16 bit however.\n\n"
        },
        {
          "name": "LICENSE.txt",
          "type": "blob",
          "size": 0.84765625,
          "content": "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated\r\ndocumentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the\r\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to\r\npermit persons to whom the Software is furnished to do so.\r\n \r\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE\r\nWARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS\r\nOR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\r\nOTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.181640625,
          "content": "include src/*.h\r\ninclude src/*.cpp\r\ninclude tests/*\r\ninclude README.*\r\ninclude LICENSE.txt\r\n\r\n# Include this file, needed for bdist_rpm\r\ninclude MANIFEST.in\r\n\r\nglobal-exclude *.py[cod]\r\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 1.8017578125,
          "content": "# pyodbc\n\n[![Windows build](https://ci.appveyor.com/api/projects/status/github/mkleehammer/pyodbc?branch=master&svg=true&passingText=Windows%20build&failingText=Windows%20build)](https://ci.appveyor.com/project/mkleehammer/pyodbc)\n[![Ubuntu build](https://github.com/mkleehammer/pyodbc/actions/workflows/ubuntu_build.yml/badge.svg)](https://github.com/mkleehammer/pyodbc/actions/workflows/ubuntu_build.yml)\n[![PyPI](https://img.shields.io/pypi/v/pyodbc?color=brightgreen)](https://pypi.org/project/pyodbc/)\n\npyodbc is an open source Python module that makes accessing ODBC databases simple.  It\nimplements the [DB API 2.0](https://www.python.org/dev/peps/pep-0249) specification but is packed with even more Pythonic convenience.\n\nThe easiest way to install pyodbc is to use pip:\n\n    python -m pip install pyodbc\n\nOn Macs, you should probably install unixODBC first if you don't already have an ODBC\ndriver manager installed.  For example, using the [homebrew](https://brew.sh/) package manager:\n\n    brew install unixodbc\n    python -m pip install pyodbc\n\nSimilarly, on Unix you should make sure you have an ODBC driver manager installed before\ninstalling pyodbc.  See the [docs](https://github.com/mkleehammer/pyodbc/wiki/Install)\nfor more information about how to do this on different Unix flavors.  (On Windows, the\nODBC driver manager is built-in.)\n\nPrecompiled binary wheels are provided for multiple Python versions on most Windows, macOS,\nand Linux platforms.  On other platforms pyodbc will be built from the source code.  Note,\npyodbc contains C++ extensions so you will need a suitable C++ compiler when building from\nsource.  See the [docs](https://github.com/mkleehammer/pyodbc/wiki/Install) for details.\n\n[Documentation](https://github.com/mkleehammer/pyodbc/wiki)\n\n[Release Notes](https://github.com/mkleehammer/pyodbc/releases)\n"
        },
        {
          "name": "appveyor.yml",
          "type": "blob",
          "size": 3.1259765625,
          "content": "# This AppVeyor CI configuration file:\n#   - builds pyodbc with multiple versions of Python\n#   - tests the generated pyodbc module against various databases and drivers\n#   - (optionally) creates \"wheel\" files for distribution, and stores them as\n#     AppVeyor artifacts which can be downloaded from the AppVeyor UI\n#\n# Various aspects of this file's behavior can be controlled by setting environment\n# variables in the AppVeyor UI (see the Settings tab -> Environment ->\n# Environment variables).  You will need an AppVeyor account for this.  Here are\n# the relevant variables and their possible string values, where \"*\" indicates the\n# defaults:\n#   - APVYR_RUN_TESTS - run the unit tests, overall control (true*/false)\n#   - APVYR_RUN_MSSQL_TESTS - run the MS SQL Server unit tests (true*/false)\n#   - APVYR_RUN_POSTGRES_TESTS - run the PostgreSQL unit tests (true*/false)\n#   - APVYR_RUN_MYSQL_TESTS - run the MySQL unit tests (true*/false)\n#   - APVYR_GENERATE_WHEELS - generate distributable wheel files (true/false*)\n#   - APVYR_VERBOSE - output more information to the logs (true*/false)\n#\n# For more information about appveyor.yml files, see: https://www.appveyor.com/docs/appveyor-yml/\n\n\n# the AppVeyor cache is used to carry files between jobs, so make sure the jobs are serialized\nmax_jobs: 1\n\n# the default AppVeyor image for the jobs\nimage: Visual Studio 2022\n\nenvironment:\n\n  global:\n    # the following variables can be overridden as necessary through the AppVeyor UI\n    APVYR_RUN_TESTS: \"true\"\n    APVYR_RUN_MSSQL_TESTS: \"true\"\n    APVYR_RUN_POSTGRES_TESTS: \"true\"\n    APVYR_RUN_MYSQL_TESTS: \"true\"\n    APVYR_GENERATE_WHEELS: \"false\"\n    APVYR_VERBOSE: \"true\"\n    # database-related variables, which must match the \"init:\" and \"services:\" sections below\n    # ref: https://www.appveyor.com/docs/services-databases/\n    MSSQL_INSTANCE: \"(local)\\\\SQL2019\"\n    POSTGRES_PATH: \"C:\\\\Program Files\\\\PostgreSQL\\\\13\"\n    MYSQL_PATH: \"C:\\\\Program Files\\\\MySQL\\\\MySQL Server 8.0\"\n    # the cache should always be saved, even on failure, to be available for the next run\n    APPVEYOR_SAVE_CACHE_ON_ERROR: \"true\"\n\n  matrix:\n    # all the Python versions to be tested, both 32-bit and 64-bit\n    # ref: https://www.appveyor.com/docs/windows-images-software/#python\n    - PYTHON_HOME: \"C:\\\\Python313-x64\"\n    - PYTHON_HOME: \"C:\\\\Python313\"\n    - PYTHON_HOME: \"C:\\\\Python312-x64\"\n    - PYTHON_HOME: \"C:\\\\Python312\"\n    - PYTHON_HOME: \"C:\\\\Python311-x64\"\n    - PYTHON_HOME: \"C:\\\\Python311\"\n    - PYTHON_HOME: \"C:\\\\Python310-x64\"\n    - PYTHON_HOME: \"C:\\\\Python310\"\n    - PYTHON_HOME: \"C:\\\\Python39-x64\"\n    - PYTHON_HOME: \"C:\\\\Python39\"\n    - PYTHON_HOME: \"C:\\\\Python38-x64\"\n    - PYTHON_HOME: \"C:\\\\Python38\"\n\n# ref: https://www.appveyor.com/docs/services-databases/\ninit:\n  - net start MSSQL$SQL2019\n  - ps: Start-Service MySQL80\n\ncache:\n  - apvyr_cache\n\ninstall:\n  - ps: .\\appveyor\\install.ps1\n  - call .\\appveyor\\install.cmd\n\n# ref: https://www.appveyor.com/docs/services-databases/\nservices:\n  - postgresql13\n\nbuild_script:\n  - call .\\appveyor\\build_script.cmd\n\ntest_script:\n  - call .\\appveyor\\test_script.cmd\n\nafter_test:\n  - call .\\appveyor\\after_test.cmd\n\nartifacts:\n  - path: 'dist\\*.whl'\n"
        },
        {
          "name": "appveyor",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "issue_template.md",
          "type": "blob",
          "size": 0.412109375,
          "content": "Please first make sure you have looked at:\n\n* Documentation: https://github.com/mkleehammer/pyodbc/wiki\n* Other issues\n\n### Environment\n\nTo diagnose, we usually need to know the following, including version numbers.  On Windows, be\nsure to specify 32-bit Python or 64-bit:\n\n- Python: \n- pyodbc: \n- OS: \n- DB:\n- driver:\n\n### Issue\n\nOften it is easiest to describe your issue as \"expected behavior\" and \"observed behavior\".\n"
        },
        {
          "name": "notes.txt",
          "type": "blob",
          "size": 2.283203125,
          "content": "\nUnicode\n-------\n\nhttp://support.microsoft.com/default.aspx?scid=kb;EN-US;q294169\n\n    \"\"\"\n    For many of these Unicode functions, the ODBC Programmer's Reference provides incorrect or\n    ambiguous descriptions for some of the function arguments. Specifically, this problem\n    relates to arguments that are used to specify the length of character string input and\n    output values.\"\n\n    Regardless of what the documentation says for each ODBC function, the following paragraph\n    from the Unicode section of \"Chapter 17: Programming Considerations\" in the ODBC\n    Programmer's Reference is the ultimate rule to use for length arguments in Unicode\n    functions:\n\n        \"Unicode functions that always return or take strings or length arguments are passed as\n        count-of-characters. For functions that return length information for server data, the\n        display size and precision are described in number of characters. When a length\n        (transfer size of the data) could refer to string or nonstring data, the length is\n        described in octet lengths. For example, SQLGetInfoW will still take the length as\n        count-of-bytes, but SQLExecDirectW will use count-of-characters.\"\n\n    This means that if the argument in question describes the length of another argument that\n    is always a string (typically represented as a SQLCHAR), then the length reflects the\n    number of characters in the string. If the length argument describes another argument that\n    could be a string or some other data type (typically represented as a SQLPOINTER), the\n    length is in bytes.\n    \"\"\"\n\n\nDriver Support\"\n\n  * PostgreSQL seems to correct use UCS-2.\n    http://archives.postgresql.org/pgsql-odbc/2006-02/msg00112.php\n\n  * MS SQL Server on Windows & Linux.  Obviously correctly uses UCS-2.  SQL\n    Server 2012 and higher now support UTF16.\n\n  * mysql: Seems to be broken.  To handle this, probably need to provide a 'charset' option\n    that causes us to convert to the given charset and use the ANSI/ASCII calls and data types.\n\n    http://mysqlworkbench.org/?p=1399\n\n  * FreeTDS\n\n    http://www.freetds.org/userguide/unicodefreetds.htm\n  \n    Definitely use 0.91 or later.\n\n    Have seen reference to a new --wide-unicode flag for 0.92+ (broken in 0.91) which causes\n    SQL_WCHAR to equal wchar_t instead of UTF16.\n"
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 1.3369140625,
          "content": "[project]\nname = \"pyodbc\"\nversion = \"5.2.0\"\n\nrequires-python = \">=3.8\"\n# This is used by the GitHub action that builds release artifacts using cibuildwheel.\n# cibuildwheel reads this directly:\n#\n# https://cibuildwheel.readthedocs.io/en/stable/options/#requires-python\n\ndescription = \"DB API module for ODBC\"\nreadme = \"README.md\"\nlicense = {text = \"MIT-0 License\"}\n\nauthors = [{name = \"Michael Kleehammer\", email=\"michael@kleehammer.com\"}]\n\nmaintainers = [{name = \"Michael Kleehammer\", email=\"michael@kleehammer.com\"}]\n# There are a lot of contributors and I'd like to include everyone that puts in a lot of\n# effort, but is this for the more technical meaning of who makes builds?  Would adding\n# contributors cause confusion.\n\nclassifiers=['Development Status :: 5 - Production/Stable',\n             'Intended Audience :: Developers',\n             'Intended Audience :: System Administrators',\n             'License :: OSI Approved :: MIT No Attribution License (MIT-0)',\n             'Operating System :: Microsoft :: Windows',\n             'Operating System :: POSIX',\n             'Programming Language :: Python',\n             'Programming Language :: Python :: 3',\n             'Topic :: Database',\n             ]\n\n[project.urls]\nHomepage = \"https://github.com/mkleehammer/pyodbc\"\n\n[build-system]\nrequires = [\"setuptools\"]\nbuild-backend = \"setuptools.build_meta\"\n"
        },
        {
          "name": "requirements-dev.txt",
          "type": "blob",
          "size": 0.40234375,
          "content": "# https://pip.pypa.io/en/stable/reference/requirements-file-format/\n# https://peps.python.org/pep-0508/\n# https://peps.python.org/pep-0440/\n\nsetuptools ~= 67.7\npytest ~= 7.3\n\n# I'm going to try leaving the versions off since we're supporting drastically different Python\n# versions.  I want the most up to date I can get in each, at least until one of them makes a\n# backwards incompatible change.\nflake8\npylint\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 6.939453125,
          "content": "#!/usr/bin/env python\n\nimport sys, os, shlex, re\nfrom os.path import exists, join, isdir, relpath, expanduser\nfrom pathlib import Path\nfrom inspect import cleandoc\n\nfrom setuptools import setup\nfrom setuptools.extension import Extension\n\n\ndef _getversion():\n    # CAREFUL: We need the version in this file so we can set it in a C macro to set\n    # pyodbc.__version__, plus the setup function might require it.  We also need it in the\n    # toml file or cibuildwheel will fail.  Instead of requiring a toml parser for older\n    # versions of Python, we'll parse it out with a regexp, which is very simple.\n    path = Path(__file__).parent / 'pyproject.toml'\n    assert path.exists(), f'Cannot find {path}'\n    text = path.read_text(encoding='utf8')\n    m = re.search(\n        r\"\"\"\n        ^ \\s* version \\s*=\\s* \"([^\"]+)\"\n        \"\"\",\n        text,\n        flags=re.VERBOSE | re.MULTILINE | re.IGNORECASE)\n    if not m:\n        sys.exit(f'Did not find version in {path}')\n    return m.group(1)\n\n\nVERSION = _getversion()\n\n\ndef main():\n    settings = get_compiler_settings()\n\n    files = [relpath(join('src', f)) for f in os.listdir('src') if f.endswith('.cpp')]\n\n    if exists('MANIFEST'):\n        os.remove('MANIFEST')\n\n    setup(\n        name=\"pyodbc\",\n        version=VERSION,\n        description=\"DB API Module for ODBC\",\n        long_description=cleandoc(\"\"\"\n            pyodbc is an open source Python module that makes accessing ODBC databases simple.\n            It implements the [DB API 2.0](https://www.python.org/dev/peps/pep-0249)\n            specification but is packed with even more Pythonic convenience.\"\"\"),\n        maintainer=\"Michael Kleehammer\",\n        maintainer_email=\"michael@kleehammer.com\",\n        url='https://github.com/mkleehammer/pyodbc',\n        ext_modules=[Extension('pyodbc', sorted(files), **settings)],\n        include_package_data=False,\n        packages=[''],\n        package_dir={'': 'src'},\n        package_data={'': ['pyodbc.pyi']},  # places pyodbc.pyi alongside pyodbc.{platform}.{pyd|so} in site-packages\n        license='MIT-0',\n        python_requires='>=3.8',\n        classifiers=['Development Status :: 5 - Production/Stable',\n                     'Intended Audience :: Developers',\n                     'Intended Audience :: System Administrators',\n                     'License :: OSI Approved :: MIT No Attribution License (MIT-0)',\n                     'Operating System :: Microsoft :: Windows',\n                     'Operating System :: POSIX',\n                     'Programming Language :: Python',\n                     'Programming Language :: Python :: 3',\n                     'Topic :: Database',\n                     ],\n        options={\n            'bdist_wininst': {'user_access_control': 'auto'}\n        }\n    )\n\n\ndef get_compiler_settings():\n\n    settings = {\n        'extra_compile_args': [],\n        'extra_link_args': [],\n        'libraries': [],\n        'include_dirs': [],\n        'define_macros': [('PYODBC_VERSION', VERSION)]\n    }\n\n    if os.name == 'nt':\n        settings['extra_compile_args'].extend([\n            '/Wall',\n            '/wd4514',     # unreference inline function removed\n            '/wd4820',     # padding after struct member\n            '/wd4668',     # is not defined as a preprocessor macro\n            '/wd4711',     # function selected for automatic inline expansion\n            '/wd4100',     # unreferenced formal parameter\n            '/wd4127',     # \"conditional expression is constant\" testing compilation constants\n            '/wd4191',     # casts to PYCFunction which doesn't have the keywords parameter\n        ])\n\n        if '--windbg' in sys.argv:\n            # Used only temporarily to add some debugging flags to get better stack traces in\n            # the debugger.  This is not related to building debug versions of Python which use\n            # \"--debug\".\n            sys.argv.remove('--windbg')\n            settings['extra_compile_args'].extend('/Od /Ge /GS /GZ /RTC1 /Wp64 /Yd'.split())\n\n        # Visual Studio 2019 defaults to using __CxxFrameHandler4 which is in\n        # VCRUNTIME140_1.DLL which Python 3.7 and earlier are not linked to.  This requirement\n        # means pyodbc will not load unless the user has installed a UCRT update.  Turn this\n        # off to match the Python 3.7 settings.\n        #\n        # Unfortunately these are *hidden* settings.  I guess we should be glad they actually\n        # made the settings.\n        # https://lectem.github.io/msvc/reverse-engineering/build/2019/01/21/MSVC-hidden-flags.html\n\n        settings['extra_compile_args'].append('/d2FH4-')\n        settings['extra_link_args'].append('/d2:-FH4-')\n\n        settings['libraries'].append('odbc32')\n        settings['libraries'].append('advapi32')\n\n    elif os.environ.get(\"OS\", '').lower().startswith('windows'):\n        # Windows Cygwin (posix on windows)\n        # OS name not windows, but still on Windows\n        settings['libraries'].append('odbc32')\n\n    elif sys.platform == 'darwin':\n        # Python functions take a lot of 'char *' that really should be const.  gcc complains\n        # about this *a lot*.\n        settings['extra_compile_args'].extend([\n            '-Wno-write-strings',\n            '-Wno-deprecated-declarations'\n        ])\n\n        # Homebrew installs odbc_config\n        pipe = os.popen('odbc_config --cflags --libs 2>/dev/null')\n        cflags, ldflags = pipe.readlines()\n        exit_status = pipe.close()\n\n        if exit_status is None:\n            settings['extra_compile_args'].extend(shlex.split(cflags))\n            settings['extra_link_args'].extend(shlex.split(ldflags))\n        else:\n            settings['libraries'].append('odbc')\n            # Add directories for MacPorts and Homebrew.\n            dirs = [\n                '/usr/local/include',\n                '/opt/local/include',\n                '/opt/homebrew/include',\n                expanduser('~/homebrew/include'),\n            ]\n            settings['include_dirs'].extend(dir for dir in dirs if isdir(dir))\n            # unixODBC make/install places libodbc.dylib in /usr/local/lib/ by default\n            # ( also OS/X since El Capitan prevents /usr/lib from being accessed )\n            settings['library_dirs'] = ['/usr/local/lib', '/opt/homebrew/lib']\n    else:\n        # Other posix-like: Linux, Solaris, etc.\n\n        # Python functions take a lot of 'char *' that really should be const.  gcc complains\n        # about this *a lot*.\n        settings['extra_compile_args'].append('-Wno-write-strings')\n\n        fd = os.popen('odbc_config --cflags 2>/dev/null')\n        cflags = fd.read().strip()\n        fd.close()\n        if cflags:\n            settings['extra_compile_args'].extend(cflags.split())\n        fd = os.popen('odbc_config --libs 2>/dev/null')\n        ldflags = fd.read().strip()\n        fd.close()\n        if ldflags:\n            settings['extra_link_args'].extend(ldflags.split())\n\n        # What is the proper way to detect iODBC, MyODBC, unixODBC, etc.?\n        settings['libraries'].append('odbc')\n\n    return settings\n\n\nif __name__ == '__main__':\n    main()\n"
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "tox.ini",
          "type": "blob",
          "size": 1.556640625,
          "content": "# USAGE\n# First, install tox.  Tox should typically be available from the command line, so it\n# is recommended to install it using pipx (pipx install tox).\n#\n# The unit test scripts get database connection strings from environment variables,\n# and those values should be stored in a \"pytest.ini\" configuration file in this\n# directory.  Here is an example of pytest.ini:\n#\n# [pytest]\n# env =\n#     PYODBC_SQLSERVER=DSN=pyodbc-sqlserver\n#     PYODBC_POSTGRESQL=DSN=pyodbc-postgres\n#     PYODBC_MYSQL=DSN=mysql;charset=utf8mb4\n# # addopts=-rA --disable-warnings\n# # pythonpath=.\n#\n# Set PYODBC_SQLSERVER, PYODBC_POSTGRESQL, and PYODBC_MYSQL accordingly.\n#\n# Naturally, test databases must be up and available before running the tests.\n# Run the unit tests against multiple versions of Python by calling \"tox\" from\n# this directory.  To run tests against only one version of Python, call, for\n# example, \"tox -e py37\".\n# To run tests against only certain databases, comment out the relevant \"pytest\"\n# commands below.\n# To override the pytest default parameters, use \"--\", e.g. \"tox -e py37 -- -rA\".\n\n[tox]\nskipsdist = true\nenv_list = py{37,38,39,310,311}\n\n[testenv]\ndescription = Run the pyodbc unit tests\ndeps =\n    pytest\n    pytest-env\nsitepackages = false\ncommands =\n    python -m pip install --quiet --force-reinstall --no-deps .\n    python -m pytest {posargs:--no-header --disable-warnings} ./tests/sqlserver_test.py\n    python -m pytest {posargs:--no-header --disable-warnings} ./tests/postgresql_test.py\n    python -m pytest {posargs:--no-header --disable-warnings} ./tests/mysql_test.py\n"
        },
        {
          "name": "utils",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}