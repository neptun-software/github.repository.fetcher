{
  "metadata": {
    "timestamp": 1736565354226,
    "page": 182,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE5MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "AnswerDotAI/gpu.cpp",
      "stars": 3786,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.28515625,
          "content": "build/*\n# any build subdirectory in the tree\n**/build/\nexamples/hello_gpu/build/*\nexamples/raymarch/build/*\ndocs/html\nsource\n.DS_Store\nthird_party/lib/*\nthird_party/local/*\n\n# formatter files\n.cmake-format.py\n\n# cmake build directories\nout\nbuild\n\n# clangd files\n.cache\ncompile_commands.json\n\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.2666015625,
          "content": "[submodule \"third_party/local/WebGPU-distribution\"]\n\tpath = third_party/local/WebGPU-distribution\n\turl = https://github.com/eliemichel/WebGPU-distribution.git\n\tbranch = dawn\n[submodule \"third_party/llm.c\"]\n\tpath = third_party/llm.c\n\turl = https://github.com/karpathy/llm.c\n"
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 1.4228515625,
          "content": "cmake_minimum_required(VERSION 3.28)\nproject(gpu)\n\ninclude(\"${CMAKE_CURRENT_SOURCE_DIR}/cmake/webgpu.cmake\")\n\nset(CMAKE_EXPORT_COMPILE_COMMANDS ON) # export compile_commands.json to use with\n                                      # LSP\nset(CMAKE_CXX_STANDARD 17)\nset(CMAKE_CXX_STANDARD_REQUIRED ON)\n\noption(USE_LOCAL_LIBS\n       \"Use local libraries instead of fetching from the internet\" OFF)\n\n# Ensure the build type is set\nif(NOT CMAKE_BUILD_TYPE)\n    set(CMAKE_BUILD_TYPE\n        Release\n        CACHE STRING \"Choose the type of build: Debug or Release\" FORCE)\nendif()\n\noption(FASTBUILD \"Option to enable fast builds\" OFF)\nif(FASTBUILD)\n    set(CMAKE_BUILD_TYPE None) # Avoid default flags of predefined build types\n    set(CMAKE_CXX_FLAGS \"-O0\")\nendif()\n\noption(DEBUG \"Option to enable debug flags\" OFF)\nif(DEBUG)\n    set(CMAKE_BUILD_TYPE Debug)\n    set(CMAKE_CXX_FLAGS \"-O0 -g\")\nendif()\n\nif(WIN64)\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -DWEBGPU_BACKEND_DAWN\")\nendif()\n\ninclude(\"${CMAKE_CURRENT_SOURCE_DIR}/cmake/gpu.cmake\")\n\nmessage(STATUS \"CMAKE_CURRENT_SOURCE_DIR: ${CMAKE_CURRENT_SOURCE_DIR}\")\nmessage(\n    STATUS\n        \"Include directories for wgpu: ${CMAKE_CURRENT_SOURCE_DIR}/third_party/headers\"\n)\n\nadd_library(gpud SHARED gpu.hpp)\nset_target_properties(gpud PROPERTIES LINKER_LANGUAGE CXX)\ntarget_link_libraries(gpud PRIVATE wgpu)\ntarget_link_libraries(gpud PRIVATE webgpu)\ntarget_link_libraries(gpud PRIVATE gpu)\ninstall(TARGETS gpud)\n"
        },
        {
          "name": "Doxyfile",
          "type": "blob",
          "size": 117.513671875,
          "content": "# Doxyfile 1.11.0YES\n\n#---------------------------------------------------------------------------\n# Project related configuration options\n#---------------------------------------------------------------------------\n\nDOXYFILE_ENCODING      = UTF-8\n\n# Don't show project name and version number since this will be embedded in the\n# website\n\nPROJECT_NAME           = \"gpu.cpp\"\nPROJECT_NUMBER         = \"0.1.0\"\n\n# Using the PROJECT_BRIEF tag one can provide an optional one line description\n# for a project that appears at the top of each page and should give viewer a\n# quick idea about the purpose of the project. Keep the description short.\n\nPROJECT_BRIEF          =\n\n# With the PROJECT_LOGO tag one can specify a logo or an icon that is included\n# in the documentation. The maximum height of the logo should not exceed 55\n# pixels and the maximum width should not exceed 200 pixels. Doxygen will copy\n# the logo to the output directory.\n\nPROJECT_LOGO           =\n\n# With the PROJECT_ICON tag one can specify an icon that is included in the tabs\n# when the HTML document is shown. Doxygen will copy the logo to the output\n# directory.\n\nPROJECT_ICON           =\n\nOUTPUT_DIRECTORY       = docs\n\n# If the CREATE_SUBDIRS tag is set to YES then doxygen will create up to 4096\n# sub-directories (in 2 levels) under the output directory of each output format\n# and will distribute the generated files over these directories. Enabling this\n# option can be useful when feeding doxygen a huge amount of source files, where\n# putting all generated files in the same directory would otherwise causes\n# performance problems for the file system. Adapt CREATE_SUBDIRS_LEVEL to\n# control the number of sub-directories.\n# The default value is: NO.\n\nCREATE_SUBDIRS         = NO\n\n# Controls the number of sub-directories that will be created when\n# CREATE_SUBDIRS tag is set to YES. Level 0 represents 16 directories, and every\n# level increment doubles the number of directories, resulting in 4096\n# directories at level 8 which is the default and also the maximum value. The\n# sub-directories are organized in 2 levels, the first level always has a fixed\n# number of 16 directories.\n# Minimum value: 0, maximum value: 8, default value: 8.\n# This tag requires that the tag CREATE_SUBDIRS is set to YES.\n\nCREATE_SUBDIRS_LEVEL   = 8\n\n# If the ALLOW_UNICODE_NAMES tag is set to YES, doxygen will allow non-ASCII\n# characters to appear in the names of generated files. If set to NO, non-ASCII\n# characters will be escaped, for example _xE3_x81_x84 will be used for Unicode\n# U+3044.\n# The default value is: NO.\n\nALLOW_UNICODE_NAMES    = NO\n\n# The OUTPUT_LANGUAGE tag is used to specify the language in which all\n# documentation generated by doxygen is written. Doxygen will use this\n# information to generate all constant output in the proper language.\n# Possible values are: Afrikaans, Arabic, Armenian, Brazilian, Bulgarian,\n# Catalan, Chinese, Chinese-Traditional, Croatian, Czech, Danish, Dutch, English\n# (United States), Esperanto, Farsi (Persian), Finnish, French, German, Greek,\n# Hindi, Hungarian, Indonesian, Italian, Japanese, Japanese-en (Japanese with\n# English messages), Korean, Korean-en (Korean with English messages), Latvian,\n# Lithuanian, Macedonian, Norwegian, Persian (Farsi), Polish, Portuguese,\n# Romanian, Russian, Serbian, Serbian-Cyrillic, Slovak, Slovene, Spanish,\n# Swedish, Turkish, Ukrainian and Vietnamese.\n# The default value is: English.\n\nOUTPUT_LANGUAGE        = English\n\n# If the BRIEF_MEMBER_DESC tag is set to YES, doxygen will include brief member\n# descriptions after the members that are listed in the file and class\n# documentation (similar to Javadoc). Set to NO to disable this.\n# The default value is: YES.\n\nBRIEF_MEMBER_DESC      = YES\n\n# If the REPEAT_BRIEF tag is set to YES, doxygen will prepend the brief\n# description of a member or function before the detailed description\n#\n# Note: If both HIDE_UNDOC_MEMBERS and BRIEF_MEMBER_DESC are set to NO, the\n# brief descriptions will be completely suppressed.\n# The default value is: YES.\n\nREPEAT_BRIEF           = YES\n\n# This tag implements a quasi-intelligent brief description abbreviator that is\n# used to form the text in various listings. Each string in this list, if found\n# as the leading text of the brief description, will be stripped from the text\n# and the result, after processing the whole list, is used as the annotated\n# text. Otherwise, the brief description is used as-is. If left blank, the\n# following values are used ($name is automatically replaced with the name of\n# the entity):The $name class, The $name widget, The $name file, is, provides,\n# specifies, contains, represents, a, an and the.\n\nABBREVIATE_BRIEF       = \"The $name class\" \\\n                         \"The $name widget\" \\\n                         \"The $name file\" \\\n                         is \\\n                         provides \\\n                         specifies \\\n                         contains \\\n                         represents \\\n                         a \\\n                         an \\\n                         the\n\n# If the ALWAYS_DETAILED_SEC and REPEAT_BRIEF tags are both set to YES then\n# doxygen will generate a detailed section even if there is only a brief\n# description.\n# The default value is: NO.\n\nALWAYS_DETAILED_SEC    = NO\n\n# If the INLINE_INHERITED_MEMB tag is set to YES, doxygen will show all\n# inherited members of a class in the documentation of that class as if those\n# members were ordinary class members. Constructors, destructors and assignment\n# operators of the base classes will not be shown.\n# The default value is: NO.\n\nINLINE_INHERITED_MEMB  = NO\n\n# If the FULL_PATH_NAMES tag is set to YES, doxygen will prepend the full path\n# before files name in the file list and in the header files. If set to NO the\n# shortest path that makes the file name unique will be used\n# The default value is: YES.\n\nFULL_PATH_NAMES        = YES\n\n# The STRIP_FROM_PATH tag can be used to strip a user-defined part of the path.\n# Stripping is only done if one of the specified strings matches the left-hand\n# part of the path. The tag can be used to show relative paths in the file list.\n# If left blank the directory from which doxygen is run is used as the path to\n# strip.\n#\n# Note that you can specify absolute paths here, but also relative paths, which\n# will be relative from the directory where doxygen is started.\n# This tag requires that the tag FULL_PATH_NAMES is set to YES.\n\nSTRIP_FROM_PATH        =\n\n# The STRIP_FROM_INC_PATH tag can be used to strip a user-defined part of the\n# path mentioned in the documentation of a class, which tells the reader which\n# header file to include in order to use a class. If left blank only the name of\n# the header file containing the class definition is used. Otherwise one should\n# specify the list of include paths that are normally passed to the compiler\n# using the -I flag.\n\nSTRIP_FROM_INC_PATH    =\n\n# If the SHORT_NAMES tag is set to YES, doxygen will generate much shorter (but\n# less readable) file names. This can be useful is your file systems doesn't\n# support long names like on DOS, Mac, or CD-ROM.\n# The default value is: NO.\n\nSHORT_NAMES            = NO\n\n# If the JAVADOC_AUTOBRIEF tag is set to YES then doxygen will interpret the\n# first line (until the first dot) of a Javadoc-style comment as the brief\n# description. If set to NO, the Javadoc-style will behave just like regular Qt-\n# style comments (thus requiring an explicit @brief command for a brief\n# description.)\n# The default value is: NO.\n\nJAVADOC_AUTOBRIEF      = NO\n\n# If the JAVADOC_BANNER tag is set to YES then doxygen will interpret a line\n# such as\n# /***************\n# as being the beginning of a Javadoc-style comment \"banner\". If set to NO, the\n# Javadoc-style will behave just like regular comments and it will not be\n# interpreted by doxygen.\n# The default value is: NO.\n\nJAVADOC_BANNER         = NO\n\n# If the QT_AUTOBRIEF tag is set to YES then doxygen will interpret the first\n# line (until the first dot) of a Qt-style comment as the brief description. If\n# set to NO, the Qt-style will behave just like regular Qt-style comments (thus\n# requiring an explicit \\brief command for a brief description.)\n# The default value is: NO.\n\nQT_AUTOBRIEF           = NO\n\n# The MULTILINE_CPP_IS_BRIEF tag can be set to YES to make doxygen treat a\n# multi-line C++ special comment block (i.e. a block of //! or /// comments) as\n# a brief description. This used to be the default behavior. The new default is\n# to treat a multi-line C++ comment block as a detailed description. Set this\n# tag to YES if you prefer the old behavior instead.\n#\n# Note that setting this tag to YES also means that rational rose comments are\n# not recognized any more.\n# The default value is: NO.\n\nMULTILINE_CPP_IS_BRIEF = NO\n\n# By default Python docstrings are displayed as preformatted text and doxygen's\n# special commands cannot be used. By setting PYTHON_DOCSTRING to NO the\n# doxygen's special commands can be used and the contents of the docstring\n# documentation blocks is shown as doxygen documentation.\n# The default value is: YES.\n\nPYTHON_DOCSTRING       = YES\n\n# If the INHERIT_DOCS tag is set to YES then an undocumented member inherits the\n# documentation from any documented member that it re-implements.\n# The default value is: YES.\n\nINHERIT_DOCS           = YES\n\n# If the SEPARATE_MEMBER_PAGES tag is set to YES then doxygen will produce a new\n# page for each member. If set to NO, the documentation of a member will be part\n# of the file/class/namespace that contains it.\n# The default value is: NO.\n\nSEPARATE_MEMBER_PAGES  = NO\n\n# The TAB_SIZE tag can be used to set the number of spaces in a tab. Doxygen\n# uses this value to replace tabs by spaces in code fragments.\n# Minimum value: 1, maximum value: 16, default value: 4.\n\nTAB_SIZE               = 4\n\n# This tag can be used to specify a number of aliases that act as commands in\n# the documentation. An alias has the form:\n# name=value\n# For example adding\n# \"sideeffect=@par Side Effects:^^\"\n# will allow you to put the command \\sideeffect (or @sideeffect) in the\n# documentation, which will result in a user-defined paragraph with heading\n# \"Side Effects:\". Note that you cannot put \\n's in the value part of an alias\n# to insert newlines (in the resulting output). You can put ^^ in the value part\n# of an alias to insert a newline as if a physical newline was in the original\n# file. When you need a literal { or } or , in the value part of an alias you\n# have to escape them by means of a backslash (\\), this can lead to conflicts\n# with the commands \\{ and \\} for these it is advised to use the version @{ and\n# @} or use a double escape (\\\\{ and \\\\})\n\nALIASES                =\n\n# Set the OPTIMIZE_OUTPUT_FOR_C tag to YES if your project consists of C sources\n# only. Doxygen will then generate output that is more tailored for C. For\n# instance, some of the names that are used will be different. The list of all\n# members will be omitted, etc.\n# The default value is: NO.\n\nOPTIMIZE_OUTPUT_FOR_C  = NO\n\n# Set the OPTIMIZE_OUTPUT_JAVA tag to YES if your project consists of Java or\n# Python sources only. Doxygen will then generate output that is more tailored\n# for that language. For instance, namespaces will be presented as packages,\n# qualified scopes will look different, etc.\n# The default value is: NO.\n\nOPTIMIZE_OUTPUT_JAVA   = NO\n\n# Set the OPTIMIZE_FOR_FORTRAN tag to YES if your project consists of Fortran\n# sources. Doxygen will then generate output that is tailored for Fortran.\n# The default value is: NO.\n\nOPTIMIZE_FOR_FORTRAN   = NO\n\n# Set the OPTIMIZE_OUTPUT_VHDL tag to YES if your project consists of VHDL\n# sources. Doxygen will then generate output that is tailored for VHDL.\n# The default value is: NO.\n\nOPTIMIZE_OUTPUT_VHDL   = NO\n\n# Set the OPTIMIZE_OUTPUT_SLICE tag to YES if your project consists of Slice\n# sources only. Doxygen will then generate output that is more tailored for that\n# language. For instance, namespaces will be presented as modules, types will be\n# separated into more groups, etc.\n# The default value is: NO.\n\nOPTIMIZE_OUTPUT_SLICE  = NO\n\n# Doxygen selects the parser to use depending on the extension of the files it\n# parses. With this tag you can assign which parser to use for a given\n# extension. Doxygen has a built-in mapping, but you can override or extend it\n# using this tag. The format is ext=language, where ext is a file extension, and\n# language is one of the parsers supported by doxygen: IDL, Java, JavaScript,\n# Csharp (C#), C, C++, Lex, D, PHP, md (Markdown), Objective-C, Python, Slice,\n# VHDL, Fortran (fixed format Fortran: FortranFixed, free formatted Fortran:\n# FortranFree, unknown formatted Fortran: Fortran. In the later case the parser\n# tries to guess whether the code is fixed or free formatted code, this is the\n# default for Fortran type files). For instance to make doxygen treat .inc files\n# as Fortran files (default is PHP), and .f files as C (default is Fortran),\n# use: inc=Fortran f=C.\n#\n# Note: For files without extension you can use no_extension as a placeholder.\n#\n# Note that for custom extensions you also need to set FILE_PATTERNS otherwise\n# the files are not read by doxygen. When specifying no_extension you should add\n# * to the FILE_PATTERNS.\n#\n# Note see also the list of default file extension mappings.\n\nEXTENSION_MAPPING      =\n\n# If the MARKDOWN_SUPPORT tag is enabled then doxygen pre-processes all comments\n# according to the Markdown format, which allows for more readable\n# documentation. See https://daringfireball.net/projects/markdown/ for details.\n# The output of markdown processing is further processed by doxygen, so you can\n# mix doxygen, HTML, and XML commands with Markdown formatting. Disable only in\n# case of backward compatibilities issues.\n# The default value is: YES.\n\nMARKDOWN_SUPPORT       = YES\n\n# When the TOC_INCLUDE_HEADINGS tag is set to a non-zero value, all headings up\n# to that level are automatically included in the table of contents, even if\n# they do not have an id attribute.\n# Note: This feature currently applies only to Markdown headings.\n# Minimum value: 0, maximum value: 99, default value: 6.\n# This tag requires that the tag MARKDOWN_SUPPORT is set to YES.\n\nTOC_INCLUDE_HEADINGS   = 6\n\n# The MARKDOWN_ID_STYLE tag can be used to specify the algorithm used to\n# generate identifiers for the Markdown headings. Note: Every identifier is\n# unique.\n# Possible values are: DOXYGEN use a fixed 'autotoc_md' string followed by a\n# sequence number starting at 0 and GITHUB use the lower case version of title\n# with any whitespace replaced by '-' and punctuation characters removed.\n# The default value is: DOXYGEN.\n# This tag requires that the tag MARKDOWN_SUPPORT is set to YES.\n\nMARKDOWN_ID_STYLE      = DOXYGEN\n\n# When enabled doxygen tries to link words that correspond to documented\n# classes, or namespaces to their corresponding documentation. Such a link can\n# be prevented in individual cases by putting a % sign in front of the word or\n# globally by setting AUTOLINK_SUPPORT to NO.\n# The default value is: YES.\n\nAUTOLINK_SUPPORT       = YES\n\n# If you use STL classes (i.e. std::string, std::vector, etc.) but do not want\n# to include (a tag file for) the STL sources as input, then you should set this\n# tag to YES in order to let doxygen match functions declarations and\n# definitions whose arguments contain STL classes (e.g. func(std::string);\n# versus func(std::string) {}). This also makes the inheritance and\n# collaboration diagrams that involve STL classes more complete and accurate.\n# The default value is: NO.\n\nBUILTIN_STL_SUPPORT    = NO\n\n# If you use Microsoft's C++/CLI language, you should set this option to YES to\n# enable parsing support.\n# The default value is: NO.\n\nCPP_CLI_SUPPORT        = NO\n\n# Set the SIP_SUPPORT tag to YES if your project consists of sip (see:\n# https://www.riverbankcomputing.com/software) sources only. Doxygen will parse\n# them like normal C++ but will assume all classes use public instead of private\n# inheritance when no explicit protection keyword is present.\n# The default value is: NO.\n\nSIP_SUPPORT            = NO\n\n# For Microsoft's IDL there are propget and propput attributes to indicate\n# getter and setter methods for a property. Setting this option to YES will make\n# doxygen to replace the get and set methods by a property in the documentation.\n# This will only work if the methods are indeed getting or setting a simple\n# type. If this is not the case, or you want to show the methods anyway, you\n# should set this option to NO.\n# The default value is: YES.\n\nIDL_PROPERTY_SUPPORT   = YES\n\n# If member grouping is used in the documentation and the DISTRIBUTE_GROUP_DOC\n# tag is set to YES then doxygen will reuse the documentation of the first\n# member in the group (if any) for the other members of the group. By default\n# all members of a group must be documented explicitly.\n# The default value is: NO.\n\nDISTRIBUTE_GROUP_DOC   = NO\n\n# If one adds a struct or class to a group and this option is enabled, then also\n# any nested class or struct is added to the same group. By default this option\n# is disabled and one has to add nested compounds explicitly via \\ingroup.\n# The default value is: NO.\n\nGROUP_NESTED_COMPOUNDS = NO\n\n# Set the SUBGROUPING tag to YES to allow class member groups of the same type\n# (for instance a group of public functions) to be put as a subgroup of that\n# type (e.g. under the Public Functions section). Set it to NO to prevent\n# subgrouping. Alternatively, this can be done per class using the\n# \\nosubgrouping command.\n# The default value is: YES.\n\nSUBGROUPING            = YES\n\n# When the INLINE_GROUPED_CLASSES tag is set to YES, classes, structs and unions\n# are shown inside the group in which they are included (e.g. using \\ingroup)\n# instead of on a separate page (for HTML and Man pages) or section (for LaTeX\n# and RTF).\n#\n# Note that this feature does not work in combination with\n# SEPARATE_MEMBER_PAGES.\n# The default value is: NO.\n\nINLINE_GROUPED_CLASSES = NO\n\n# When the INLINE_SIMPLE_STRUCTS tag is set to YES, structs, classes, and unions\n# with only public data fields or simple typedef fields will be shown inline in\n# the documentation of the scope in which they are defined (i.e. file,\n# namespace, or group documentation), provided this scope is documented. If set\n# to NO, structs, classes, and unions are shown on a separate page (for HTML and\n# Man pages) or section (for LaTeX and RTF).\n# The default value is: NO.\n\nINLINE_SIMPLE_STRUCTS  = NO\n\n# When TYPEDEF_HIDES_STRUCT tag is enabled, a typedef of a struct, union, or\n# enum is documented as struct, union, or enum with the name of the typedef. So\n# typedef struct TypeS {} TypeT, will appear in the documentation as a struct\n# with name TypeT. When disabled the typedef will appear as a member of a file,\n# namespace, or class. And the struct will be named TypeS. This can typically be\n# useful for C code in case the coding convention dictates that all compound\n# types are typedef'ed and only the typedef is referenced, never the tag name.\n# The default value is: NO.\n\nTYPEDEF_HIDES_STRUCT   = NO\n\n# The size of the symbol lookup cache can be set using LOOKUP_CACHE_SIZE. This\n# cache is used to resolve symbols given their name and scope. Since this can be\n# an expensive process and often the same symbol appears multiple times in the\n# code, doxygen keeps a cache of pre-resolved symbols. If the cache is too small\n# doxygen will become slower. If the cache is too large, memory is wasted. The\n# cache size is given by this formula: 2^(16+LOOKUP_CACHE_SIZE). The valid range\n# is 0..9, the default is 0, corresponding to a cache size of 2^16=65536\n# symbols. At the end of a run doxygen will report the cache usage and suggest\n# the optimal cache size from a speed point of view.\n# Minimum value: 0, maximum value: 9, default value: 0.\n\nLOOKUP_CACHE_SIZE      = 0\n\n# The NUM_PROC_THREADS specifies the number of threads doxygen is allowed to use\n# during processing. When set to 0 doxygen will based this on the number of\n# cores available in the system. You can set it explicitly to a value larger\n# than 0 to get more control over the balance between CPU load and processing\n# speed. At this moment only the input processing can be done using multiple\n# threads. Since this is still an experimental feature the default is set to 1,\n# which effectively disables parallel processing. Please report any issues you\n# encounter. Generating dot graphs in parallel is controlled by the\n# DOT_NUM_THREADS setting.\n# Minimum value: 0, maximum value: 32, default value: 1.\n\nNUM_PROC_THREADS       = 1\n\n# If the TIMESTAMP tag is set different from NO then each generated page will\n# contain the date or date and time when the page was generated. Setting this to\n# NO can help when comparing the output of multiple runs.\n# Possible values are: YES, NO, DATETIME and DATE.\n# The default value is: NO.\n\nTIMESTAMP              = NO\n\n#---------------------------------------------------------------------------\n# Build related configuration options\n#---------------------------------------------------------------------------\n\n# If the EXTRACT_ALL tag is set to YES, doxygen will assume all entities in\n# documentation are documented, even if no documentation was available. Private\n# class members and static file members will be hidden unless the\n# EXTRACT_PRIVATE respectively EXTRACT_STATIC tags are set to YES.\n# Note: This will also disable the warnings about undocumented members that are\n# normally produced when WARNINGS is set to YES.\n# The default value is: NO.\n\nEXTRACT_ALL            = YES\nGENERATE_MARKDOWN      = YES\n\n# If the EXTRACT_PRIVATE tag is set to YES, all private members of a class will\n# be included in the documentation.\n# The default value is: NO.\n\nEXTRACT_PRIVATE        = NO\n\n# If the EXTRACT_PRIV_VIRTUAL tag is set to YES, documented private virtual\n# methods of a class will be included in the documentation.\n# The default value is: NO.\n\nEXTRACT_PRIV_VIRTUAL   = NO\n\n# If the EXTRACT_PACKAGE tag is set to YES, all members with package or internal\n# scope will be included in the documentation.\n# The default value is: NO.\n\nEXTRACT_PACKAGE        = NO\n\n# If the EXTRACT_STATIC tag is set to YES, all static members of a file will be\n# included in the documentation.\n# The default value is: NO.\n\nEXTRACT_STATIC         = YES\n\n# If the EXTRACT_LOCAL_CLASSES tag is set to YES, classes (and structs) defined\n# locally in source files will be included in the documentation. If set to NO,\n# only classes defined in header files are included. Does not have any effect\n# for Java sources.\n# The default value is: YES.\n\nEXTRACT_LOCAL_CLASSES  = YES\n\n# This flag is only useful for Objective-C code. If set to YES, local methods,\n# which are defined in the implementation section but not in the interface are\n# included in the documentation. If set to NO, only methods in the interface are\n# included.\n# The default value is: NO.\n\nEXTRACT_LOCAL_METHODS  = NO\n\n# If this flag is set to YES, the members of anonymous namespaces will be\n# extracted and appear in the documentation as a namespace called\n# 'anonymous_namespace{file}', where file will be replaced with the base name of\n# the file that contains the anonymous namespace. By default anonymous namespace\n# are hidden.\n# The default value is: NO.\n\nEXTRACT_ANON_NSPACES   = NO\n\n# If this flag is set to YES, the name of an unnamed parameter in a declaration\n# will be determined by the corresponding definition. By default unnamed\n# parameters remain unnamed in the output.\n# The default value is: YES.\n\nRESOLVE_UNNAMED_PARAMS = YES\n\n# If the HIDE_UNDOC_MEMBERS tag is set to YES, doxygen will hide all\n# undocumented members inside documented classes or files. If set to NO these\n# members will be included in the various overviews, but no documentation\n# section is generated. This option has no effect if EXTRACT_ALL is enabled.\n# The default value is: NO.\n\nHIDE_UNDOC_MEMBERS     = NO\n\n# If the HIDE_UNDOC_CLASSES tag is set to YES, doxygen will hide all\n# undocumented classes that are normally visible in the class hierarchy. If set\n# to NO, these classes will be included in the various overviews. This option\n# will also hide undocumented C++ concepts if enabled. This option has no effect\n# if EXTRACT_ALL is enabled.\n# The default value is: NO.\n\nHIDE_UNDOC_CLASSES     = NO\n\n# If the HIDE_FRIEND_COMPOUNDS tag is set to YES, doxygen will hide all friend\n# declarations. If set to NO, these declarations will be included in the\n# documentation.\n# The default value is: NO.\n\nHIDE_FRIEND_COMPOUNDS  = NO\n\n# If the HIDE_IN_BODY_DOCS tag is set to YES, doxygen will hide any\n# documentation blocks found inside the body of a function. If set to NO, these\n# blocks will be appended to the function's detailed documentation block.\n# The default value is: NO.\n\nHIDE_IN_BODY_DOCS      = NO\n\n# The INTERNAL_DOCS tag determines if documentation that is typed after a\n# \\internal command is included. If the tag is set to NO then the documentation\n# will be excluded. Set it to YES to include the internal documentation.\n# The default value is: NO.\n\nINTERNAL_DOCS          = NO\n\n# With the correct setting of option CASE_SENSE_NAMES doxygen will better be\n# able to match the capabilities of the underlying filesystem. In case the\n# filesystem is case sensitive (i.e. it supports files in the same directory\n# whose names only differ in casing), the option must be set to YES to properly\n# deal with such files in case they appear in the input. For filesystems that\n# are not case sensitive the option should be set to NO to properly deal with\n# output files written for symbols that only differ in casing, such as for two\n# classes, one named CLASS and the other named Class, and to also support\n# references to files without having to specify the exact matching casing. On\n# Windows (including Cygwin) and MacOS, users should typically set this option\n# to NO, whereas on Linux or other Unix flavors it should typically be set to\n# YES.\n# Possible values are: SYSTEM, NO and YES.\n# The default value is: SYSTEM.\n\nCASE_SENSE_NAMES       = SYSTEM\n\n# If the HIDE_SCOPE_NAMES tag is set to NO then doxygen will show members with\n# their full class and namespace scopes in the documentation. If set to YES, the\n# scope will be hidden.\n# The default value is: NO.\n\nHIDE_SCOPE_NAMES       = NO\n\n# If the HIDE_COMPOUND_REFERENCE tag is set to NO (default) then doxygen will\n# append additional text to a page's title, such as Class Reference. If set to\n# YES the compound reference will be hidden.\n# The default value is: NO.\n\nHIDE_COMPOUND_REFERENCE= NO\n\n# If the SHOW_HEADERFILE tag is set to YES then the documentation for a class\n# will show which file needs to be included to use the class.\n# The default value is: YES.\n\nSHOW_HEADERFILE        = YES\n\n# If the SHOW_INCLUDE_FILES tag is set to YES then doxygen will put a list of\n# the files that are included by a file in the documentation of that file.\n# The default value is: YES.\n\nSHOW_INCLUDE_FILES     = YES\n\n# If the SHOW_GROUPED_MEMB_INC tag is set to YES then Doxygen will add for each\n# grouped member an include statement to the documentation, telling the reader\n# which file to include in order to use the member.\n# The default value is: NO.\n\nSHOW_GROUPED_MEMB_INC  = NO\n\n# If the FORCE_LOCAL_INCLUDES tag is set to YES then doxygen will list include\n# files with double quotes in the documentation rather than with sharp brackets.\n# The default value is: NO.\n\nFORCE_LOCAL_INCLUDES   = NO\n\n# If the INLINE_INFO tag is set to YES then a tag [inline] is inserted in the\n# documentation for inline members.\n# The default value is: YES.\n\nINLINE_INFO            = YES\n\n# If the SORT_MEMBER_DOCS tag is set to YES then doxygen will sort the\n# (detailed) documentation of file and class members alphabetically by member\n# name. If set to NO, the members will appear in declaration order.\n# The default value is: YES.\n\nSORT_MEMBER_DOCS       = YES\n\n# If the SORT_BRIEF_DOCS tag is set to YES then doxygen will sort the brief\n# descriptions of file, namespace and class members alphabetically by member\n# name. If set to NO, the members will appear in declaration order. Note that\n# this will also influence the order of the classes in the class list.\n# The default value is: NO.\n\nSORT_BRIEF_DOCS        = NO\n\n# If the SORT_MEMBERS_CTORS_1ST tag is set to YES then doxygen will sort the\n# (brief and detailed) documentation of class members so that constructors and\n# destructors are listed first. If set to NO the constructors will appear in the\n# respective orders defined by SORT_BRIEF_DOCS and SORT_MEMBER_DOCS.\n# Note: If SORT_BRIEF_DOCS is set to NO this option is ignored for sorting brief\n# member documentation.\n# Note: If SORT_MEMBER_DOCS is set to NO this option is ignored for sorting\n# detailed member documentation.\n# The default value is: NO.\n\nSORT_MEMBERS_CTORS_1ST = NO\n\n# If the SORT_GROUP_NAMES tag is set to YES then doxygen will sort the hierarchy\n# of group names into alphabetical order. If set to NO the group names will\n# appear in their defined order.\n# The default value is: NO.\n\nSORT_GROUP_NAMES       = NO\n\n# If the SORT_BY_SCOPE_NAME tag is set to YES, the class list will be sorted by\n# fully-qualified names, including namespaces. If set to NO, the class list will\n# be sorted only by class name, not including the namespace part.\n# Note: This option is not very useful if HIDE_SCOPE_NAMES is set to YES.\n# Note: This option applies only to the class list, not to the alphabetical\n# list.\n# The default value is: NO.\n\nSORT_BY_SCOPE_NAME     = NO\n\n# If the STRICT_PROTO_MATCHING option is enabled and doxygen fails to do proper\n# type resolution of all parameters of a function it will reject a match between\n# the prototype and the implementation of a member function even if there is\n# only one candidate or it is obvious which candidate to choose by doing a\n# simple string match. By disabling STRICT_PROTO_MATCHING doxygen will still\n# accept a match between prototype and implementation in such cases.\n# The default value is: NO.\n\nSTRICT_PROTO_MATCHING  = NO\n\n# The GENERATE_TODOLIST tag can be used to enable (YES) or disable (NO) the todo\n# list. This list is created by putting \\todo commands in the documentation.\n# The default value is: YES.\n\nGENERATE_TODOLIST      = YES\n\n# The GENERATE_TESTLIST tag can be used to enable (YES) or disable (NO) the test\n# list. This list is created by putting \\test commands in the documentation.\n# The default value is: YES.\n\nGENERATE_TESTLIST      = YES\n\n# The GENERATE_BUGLIST tag can be used to enable (YES) or disable (NO) the bug\n# list. This list is created by putting \\bug commands in the documentation.\n# The default value is: YES.\n\nGENERATE_BUGLIST       = YES\n\n# The GENERATE_DEPRECATEDLIST tag can be used to enable (YES) or disable (NO)\n# the deprecated list. This list is created by putting \\deprecated commands in\n# the documentation.\n# The default value is: YES.\n\nGENERATE_DEPRECATEDLIST= YES\n\n# The ENABLED_SECTIONS tag can be used to enable conditional documentation\n# sections, marked by \\if <section_label> ... \\endif and \\cond <section_label>\n# ... \\endcond blocks.\n\nENABLED_SECTIONS       =\n\n# The MAX_INITIALIZER_LINES tag determines the maximum number of lines that the\n# initial value of a variable or macro / define can have for it to appear in the\n# documentation. If the initializer consists of more lines than specified here\n# it will be hidden. Use a value of 0 to hide initializers completely. The\n# appearance of the value of individual variables and macros / defines can be\n# controlled using \\showinitializer or \\hideinitializer command in the\n# documentation regardless of this setting.\n# Minimum value: 0, maximum value: 10000, default value: 30.\n\nMAX_INITIALIZER_LINES  = 30\n\n# Set the SHOW_USED_FILES tag to NO to disable the list of files generated at\n# the bottom of the documentation of classes and structs. If set to YES, the\n# list will mention the files that were used to generate the documentation.\n# The default value is: YES.\n\nSHOW_USED_FILES        = YES\n\n# Set the SHOW_FILES tag to NO to disable the generation of the Files page. This\n# will remove the Files entry from the Quick Index and from the Folder Tree View\n# (if specified).\n# The default value is: YES.\n\nSHOW_FILES             = YES\n\n# Set the SHOW_NAMESPACES tag to NO to disable the generation of the Namespaces\n# page. This will remove the Namespaces entry from the Quick Index and from the\n# Folder Tree View (if specified).\n# The default value is: YES.\n\nSHOW_NAMESPACES        = YES\n\n# The FILE_VERSION_FILTER tag can be used to specify a program or script that\n# doxygen should invoke to get the current version for each file (typically from\n# the version control system). Doxygen will invoke the program by executing (via\n# popen()) the command command input-file, where command is the value of the\n# FILE_VERSION_FILTER tag, and input-file is the name of an input file provided\n# by doxygen. Whatever the program writes to standard output is used as the file\n# version. For an example see the documentation.\n\nFILE_VERSION_FILTER    =\n\n# The LAYOUT_FILE tag can be used to specify a layout file which will be parsed\n# by doxygen. The layout file controls the global structure of the generated\n# output files in an output format independent way. To create the layout file\n# that represents doxygen's defaults, run doxygen with the -l option. You can\n# optionally specify a file name after the option, if omitted DoxygenLayout.xml\n# will be used as the name of the layout file. See also section \"Changing the\n# layout of pages\" for information.\n#\n# Note that if you run doxygen from a directory containing a file called\n# DoxygenLayout.xml, doxygen will parse it automatically even if the LAYOUT_FILE\n# tag is left empty.\n\nLAYOUT_FILE            =\n\n# The CITE_BIB_FILES tag can be used to specify one or more bib files containing\n# the reference definitions. This must be a list of .bib files. The .bib\n# extension is automatically appended if omitted. This requires the bibtex tool\n# to be installed. See also https://en.wikipedia.org/wiki/BibTeX for more info.\n# For LaTeX the style of the bibliography can be controlled using\n# LATEX_BIB_STYLE. To use this feature you need bibtex and perl available in the\n# search path. See also \\cite for info how to create references.\n\nCITE_BIB_FILES         =\n\n#---------------------------------------------------------------------------\n# Configuration options related to warning and progress messages\n#---------------------------------------------------------------------------\n\n# The QUIET tag can be used to turn on/off the messages that are generated to\n# standard output by doxygen. If QUIET is set to YES this implies that the\n# messages are off.\n# The default value is: NO.\n\nQUIET                  = NO\n\n# The WARNINGS tag can be used to turn on/off the warning messages that are\n# generated to standard error (stderr) by doxygen. If WARNINGS is set to YES\n# this implies that the warnings are on.\n#\n# Tip: Turn warnings on while writing the documentation.\n# The default value is: YES.\n\nWARNINGS               = YES\n\n# If the WARN_IF_UNDOCUMENTED tag is set to YES then doxygen will generate\n# warnings for undocumented members. If EXTRACT_ALL is set to YES then this flag\n# will automatically be disabled.\n# The default value is: YES.\n\nWARN_IF_UNDOCUMENTED   = YES\n\n# If the WARN_IF_DOC_ERROR tag is set to YES, doxygen will generate warnings for\n# potential errors in the documentation, such as documenting some parameters in\n# a documented function twice, or documenting parameters that don't exist or\n# using markup commands wrongly.\n# The default value is: YES.\n\nWARN_IF_DOC_ERROR      = YES\n\n# If WARN_IF_INCOMPLETE_DOC is set to YES, doxygen will warn about incomplete\n# function parameter documentation. If set to NO, doxygen will accept that some\n# parameters have no documentation without warning.\n# The default value is: YES.\n\nWARN_IF_INCOMPLETE_DOC = YES\n\n# This WARN_NO_PARAMDOC option can be enabled to get warnings for functions that\n# are documented, but have no documentation for their parameters or return\n# value. If set to NO, doxygen will only warn about wrong parameter\n# documentation, but not about the absence of documentation. If EXTRACT_ALL is\n# set to YES then this flag will automatically be disabled. See also\n# WARN_IF_INCOMPLETE_DOC\n# The default value is: NO.\n\nWARN_NO_PARAMDOC       = NO\n\n# If WARN_IF_UNDOC_ENUM_VAL option is set to YES, doxygen will warn about\n# undocumented enumeration values. If set to NO, doxygen will accept\n# undocumented enumeration values. If EXTRACT_ALL is set to YES then this flag\n# will automatically be disabled.\n# The default value is: NO.\n\nWARN_IF_UNDOC_ENUM_VAL = NO\n\n# If the WARN_AS_ERROR tag is set to YES then doxygen will immediately stop when\n# a warning is encountered. If the WARN_AS_ERROR tag is set to FAIL_ON_WARNINGS\n# then doxygen will continue running as if WARN_AS_ERROR tag is set to NO, but\n# at the end of the doxygen process doxygen will return with a non-zero status.\n# If the WARN_AS_ERROR tag is set to FAIL_ON_WARNINGS_PRINT then doxygen behaves\n# like FAIL_ON_WARNINGS but in case no WARN_LOGFILE is defined doxygen will not\n# write the warning messages in between other messages but write them at the end\n# of a run, in case a WARN_LOGFILE is defined the warning messages will be\n# besides being in the defined file also be shown at the end of a run, unless\n# the WARN_LOGFILE is defined as - i.e. standard output (stdout) in that case\n# the behavior will remain as with the setting FAIL_ON_WARNINGS.\n# Possible values are: NO, YES, FAIL_ON_WARNINGS and FAIL_ON_WARNINGS_PRINT.\n# The default value is: NO.\n\nWARN_AS_ERROR          = NO\n\n# The WARN_FORMAT tag determines the format of the warning messages that doxygen\n# can produce. The string should contain the $file, $line, and $text tags, which\n# will be replaced by the file and line number from which the warning originated\n# and the warning text. Optionally the format may contain $version, which will\n# be replaced by the version of the file (if it could be obtained via\n# FILE_VERSION_FILTER)\n# See also: WARN_LINE_FORMAT\n# The default value is: $file:$line: $text.\n\nWARN_FORMAT            = \"$file:$line: $text\"\n\n# In the $text part of the WARN_FORMAT command it is possible that a reference\n# to a more specific place is given. To make it easier to jump to this place\n# (outside of doxygen) the user can define a custom \"cut\" / \"paste\" string.\n# Example:\n# WARN_LINE_FORMAT = \"'vi $file +$line'\"\n# See also: WARN_FORMAT\n# The default value is: at line $line of file $file.\n\nWARN_LINE_FORMAT       = \"at line $line of file $file\"\n\n# The WARN_LOGFILE tag can be used to specify a file to which warning and error\n# messages should be written. If left blank the output is written to standard\n# error (stderr). In case the file specified cannot be opened for writing the\n# warning and error messages are written to standard error. When as file - is\n# specified the warning and error messages are written to standard output\n# (stdout).\n\nWARN_LOGFILE           =\n\n#---------------------------------------------------------------------------\n# Configuration options related to the input files\n#---------------------------------------------------------------------------\n\n# The INPUT tag is used to specify the files and/or directories that contain\n# documented source files. You may enter file names like myfile.cpp or\n# directories like /usr/src/myproject. Separate the files or directories with\n# spaces. See also FILE_PATTERNS and EXTENSION_MAPPING\n# Note: If this tag is empty the current directory is searched.\n\nINPUT                  = . examples utils nn\n\n# This tag can be used to specify the character encoding of the source files\n# that doxygen parses. Internally doxygen uses the UTF-8 encoding. Doxygen uses\n# libiconv (or the iconv built into libc) for the transcoding. See the libiconv\n# documentation (see:\n# https://www.gnu.org/software/libiconv/) for the list of possible encodings.\n# See also: INPUT_FILE_ENCODING\n# The default value is: UTF-8.\n\nINPUT_ENCODING         = UTF-8\n\n# This tag can be used to specify the character encoding of the source files\n# that doxygen parses The INPUT_FILE_ENCODING tag can be used to specify\n# character encoding on a per file pattern basis. Doxygen will compare the file\n# name with each pattern and apply the encoding instead of the default\n# INPUT_ENCODING) if there is a match. The character encodings are a list of the\n# form: pattern=encoding (like *.php=ISO-8859-1).\n# See also: INPUT_ENCODING for further information on supported encodings.\n\nINPUT_FILE_ENCODING    =\n\n# If the value of the INPUT tag contains directories, you can use the\n# FILE_PATTERNS tag to specify one or more wildcard patterns (like *.cpp and\n# *.h) to filter out the source-files in the directories.\n#\n# Note that for custom extensions or not directly supported extensions you also\n# need to set EXTENSION_MAPPING for the extension otherwise the files are not\n# read by doxygen.\n#\n# Note the list of default checked file patterns might differ from the list of\n# default file extension mappings.\n#\n# If left blank the following patterns are tested:*.c, *.cc, *.cxx, *.cxxm,\n# *.cpp, *.cppm, *.ccm, *.c++, *.c++m, *.java, *.ii, *.ixx, *.ipp, *.i++, *.inl,\n# *.idl, *.ddl, *.odl, *.h, *.hh, *.hxx, *.hpp, *.h++, *.ixx, *.l, *.cs, *.d,\n# *.php, *.php4, *.php5, *.phtml, *.inc, *.m, *.markdown, *.md, *.mm, *.dox (to\n# be provided as doxygen C comment), *.py, *.pyw, *.f90, *.f95, *.f03, *.f08,\n# *.f18, *.f, *.for, *.vhd, *.vhdl, *.ucf, *.qsf and *.ice.\n\nFILE_PATTERNS          = *.c \\\n                         *.cc \\\n                         *.cxx \\\n                         *.cxxm \\\n                         *.cpp \\\n                         *.cppm \\\n                         *.ccm \\\n                         *.c++ \\\n                         *.c++m \\\n                         *.java \\\n                         *.ii \\\n                         *.ixx \\\n                         *.ipp \\\n                         *.i++ \\\n                         *.inl \\\n                         *.idl \\\n                         *.ddl \\\n                         *.odl \\\n                         *.h \\\n                         *.hh \\\n                         *.hxx \\\n                         *.hpp \\\n                         *.h++ \\\n                         *.ixx \\\n                         *.l \\\n                         *.cs \\\n                         *.d \\\n                         *.php \\\n                         *.php4 \\\n                         *.php5 \\\n                         *.phtml \\\n                         *.inc \\\n                         *.m \\\n                         *.markdown \\\n                         *.md \\\n                         *.mm \\\n                         *.dox \\\n                         *.py \\\n                         *.pyw \\\n                         *.f90 \\\n                         *.f95 \\\n                         *.f03 \\\n                         *.f08 \\\n                         *.f18 \\\n                         *.f \\\n                         *.for \\\n                         *.vhd \\\n                         *.vhdl \\\n                         *.ucf \\\n                         *.qsf \\\n                         *.ice\n\n# The RECURSIVE tag can be used to specify whether or not subdirectories should\n# be searched for input files as well.\n# The default value is: NO.\n\nRECURSIVE              = NO\n\n# The EXCLUDE tag can be used to specify files and/or directories that should be\n# excluded from the INPUT source files. This way you can easily exclude a\n# subdirectory from a directory tree whose root is specified with the INPUT tag.\n#\n# Note that relative paths are relative to the directory from which doxygen is\n# run.\n\n# since this is embedded in the website, no need to render README\nEXCLUDE                = \"./setup.py\" \"./examples\" \"./README.md\"\nEXCLUDE_PATTERNS       = \"*/third_party/* */docs/* */examples/* *.py\"\nEXCLUDE_SYMLINKS       = NO\nEXCLUDE_SYMBOLS        = \"third_party/ docs/ examples/\"\n\n EXAMPLE_PATH           = \"examples/\"\n\nEXAMPLE_PATTERNS       = *\nEXAMPLE_RECURSIVE      = YES\n\n# The IMAGE_PATH tag can be used to specify one or more files or directories\n# that contain images that are to be included in the documentation (see the\n# \\image command).\n\nIMAGE_PATH             =\n\nINPUT_FILTER           =\nFILTER_PATTERNS        =\nFILTER_SOURCE_FILES    = NO\nFILTER_SOURCE_PATTERNS =\n\n# If the USE_MDFILE_AS_MAINPAGE tag refers to the name of a markdown file that\n# is part of the input, its contents will be placed on the main page\n# (index.html). This can be useful if you have a project on for instance GitHub\n# and want to reuse the introduction page also for the doxygen output.\n\n# USE_MDFILE_AS_MAINPAGE = \nUSE_MDFILE_AS_MAINPAGE = README.md\n\n#---------------------------------------------------------------------------\n# Configuration options related to source browsing\n#---------------------------------------------------------------------------\n\n# If the SOURCE_BROWSER tag is set to YES then a list of source files will be\n# generated. Documented entities will be cross-referenced with these sources.\n#\n# Note: To get rid of all source code in the generated output, make sure that\n# also VERBATIM_HEADERS is set to NO.\n# The default value is: NO.\n\nSOURCE_BROWSER         = YES\n\n# Setting the INLINE_SOURCES tag to YES will include the body of functions,\n# multi-line macros, enums or list initialized variables directly into the\n# documentation.\n# The default value is: NO.\n\nINLINE_SOURCES         = YES\n\n# Setting the STRIP_CODE_COMMENTS tag to YES will instruct doxygen to hide any\n# special comment blocks from generated source code fragments. Normal C, C++ and\n# Fortran comments will always remain visible.\n# The default value is: YES.\n\nSTRIP_CODE_COMMENTS    = YES\n\n# If the REFERENCED_BY_RELATION tag is set to YES then for each documented\n# entity all documented functions referencing it will be listed.\n# The default value is: NO.\n\nREFERENCED_BY_RELATION = NO\n\n# If the REFERENCES_RELATION tag is set to YES then for each documented function\n# all documented entities called/used by that function will be listed.\n# The default value is: NO.\n\nREFERENCES_RELATION    = NO\n\n# If the REFERENCES_LINK_SOURCE tag is set to YES and SOURCE_BROWSER tag is set\n# to YES then the hyperlinks from functions in REFERENCES_RELATION and\n# REFERENCED_BY_RELATION lists will link to the source code. Otherwise they will\n# link to the documentation.\n# The default value is: YES.\n\nREFERENCES_LINK_SOURCE = YES\n\n# If SOURCE_TOOLTIPS is enabled (the default) then hovering a hyperlink in the\n# source code will show a tooltip with additional information such as prototype,\n# brief description and links to the definition and documentation. Since this\n# will make the HTML file larger and loading of large files a bit slower, you\n# can opt to disable this feature.\n# The default value is: YES.\n# This tag requires that the tag SOURCE_BROWSER is set to YES.\n\nSOURCE_TOOLTIPS        = YES\n\n# If the USE_HTAGS tag is set to YES then the references to source code will\n# point to the HTML generated by the htags(1) tool instead of doxygen built-in\n# source browser. The htags tool is part of GNU's global source tagging system\n# (see https://www.gnu.org/software/global/global.html). You will need version\n# 4.8.6 or higher.\n#\n# To use it do the following:\n# - Install the latest version of global\n# - Enable SOURCE_BROWSER and USE_HTAGS in the configuration file\n# - Make sure the INPUT points to the root of the source tree\n# - Run doxygen as normal\n#\n# Doxygen will invoke htags (and that will in turn invoke gtags), so these\n# tools must be available from the command line (i.e. in the search path).\n#\n# The result: instead of the source browser generated by doxygen, the links to\n# source code will now point to the output of htags.\n# The default value is: NO.\n# This tag requires that the tag SOURCE_BROWSER is set to YES.\n\nUSE_HTAGS              = NO\n\n# If the VERBATIM_HEADERS tag is set the YES then doxygen will generate a\n# verbatim copy of the header file for each class for which an include is\n# specified. Set to NO to disable this.\n# See also: Section \\class.\n# The default value is: YES.\n\nVERBATIM_HEADERS       = YES\n\n#---------------------------------------------------------------------------\n# Configuration options related to the alphabetical class index\n#---------------------------------------------------------------------------\n\n# If the ALPHABETICAL_INDEX tag is set to YES, an alphabetical index of all\n# compounds will be generated. Enable this if the project contains a lot of\n# classes, structs, unions or interfaces.\n# The default value is: YES.\n\nALPHABETICAL_INDEX     = YES\n\n# The IGNORE_PREFIX tag can be used to specify a prefix (or a list of prefixes)\n# that should be ignored while generating the index headers. The IGNORE_PREFIX\n# tag works for classes, function and member names. The entity will be placed in\n# the alphabetical list under the first letter of the entity name that remains\n# after removing the prefix.\n# This tag requires that the tag ALPHABETICAL_INDEX is set to YES.\n\nIGNORE_PREFIX          =\n\n#---------------------------------------------------------------------------\n# Configuration options related to the HTML output\n#---------------------------------------------------------------------------\n\n# If the GENERATE_HTML tag is set to YES, doxygen will generate HTML output\n# The default value is: YES.\n\nGENERATE_HTML          = YES\n\n# The HTML_OUTPUT tag is used to specify where the HTML docs will be put. If a\n# relative path is entered the value of OUTPUT_DIRECTORY will be put in front of\n# it.\n# The default directory is: html.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nHTML_OUTPUT            = html\n\n# The HTML_FILE_EXTENSION tag can be used to specify the file extension for each\n# generated HTML page (for example: .htm, .php, .asp).\n# The default value is: .html.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nHTML_FILE_EXTENSION    = .html\n\n# The HTML_HEADER tag can be used to specify a user-defined HTML header file for\n# each generated HTML page. If the tag is left blank doxygen will generate a\n# standard header.\n#\n# To get valid HTML the header file that includes any scripts and style sheets\n# that doxygen needs, which is dependent on the configuration options used (e.g.\n# the setting GENERATE_TREEVIEW). It is highly recommended to start with a\n# default header using\n# doxygen -w html new_header.html new_footer.html new_stylesheet.css\n# YourConfigFile\n# and then modify the file new_header.html. See also section \"Doxygen usage\"\n# for information on how to generate the default header that doxygen normally\n# uses.\n# Note: The header is subject to change so you typically have to regenerate the\n# default header when upgrading to a newer version of doxygen. For a description\n# of the possible markers and block names see the documentation.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nHTML_HEADER            =\n\n# The HTML_FOOTER tag can be used to specify a user-defined HTML footer for each\n# generated HTML page. If the tag is left blank doxygen will generate a standard\n# footer. See HTML_HEADER for more information on how to generate a default\n# footer and what special commands can be used inside the footer. See also\n# section \"Doxygen usage\" for information on how to generate the default footer\n# that doxygen normally uses.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nHTML_FOOTER            =\n\n# The HTML_STYLESHEET tag can be used to specify a user-defined cascading style\n# sheet that is used by each HTML page. It can be used to fine-tune the look of\n# the HTML output. If left blank doxygen will generate a default style sheet.\n# See also section \"Doxygen usage\" for information on how to generate the style\n# sheet that doxygen normally uses.\n# Note: It is recommended to use HTML_EXTRA_STYLESHEET instead of this tag, as\n# it is more robust and this tag (HTML_STYLESHEET) will in the future become\n# obsolete.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nHTML_STYLESHEET        =\n\n## Use the Doxygen Awesome CSS\nHTML_EXTRA_STYLESHEET  = docs/doxygen-awesome/doxygen-awesome.css\nHTML_EXTRA_FILES       = docs/doxygen-awesome/doxygen-awesome-darkmode-toggle.js\nEXTENSION_MAPPING      = .md=markdown\nGENERATE_MAINPAGE      = NO\n\nHTML_EXTRA_FILES       =\n\n# The HTML_COLORSTYLE tag can be used to specify if the generated HTML output\n# should be rendered with a dark or light theme.\n# Possible values are: LIGHT always generates light mode output, DARK always\n# generates dark mode output, AUTO_LIGHT automatically sets the mode according\n# to the user preference, uses light mode if no preference is set (the default),\n# AUTO_DARK automatically sets the mode according to the user preference, uses\n# dark mode if no preference is set and TOGGLE allows a user to switch between\n# light and dark mode via a button.\n# The default value is: AUTO_LIGHT.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nHTML_COLORSTYLE        = AUTO_LIGHT\n\n# The HTML_COLORSTYLE_HUE tag controls the color of the HTML output. Doxygen\n# will adjust the colors in the style sheet and background images according to\n# this color. Hue is specified as an angle on a color-wheel, see\n# https://en.wikipedia.org/wiki/Hue for more information. For instance the value\n# 0 represents red, 60 is yellow, 120 is green, 180 is cyan, 240 is blue, 300\n# purple, and 360 is red again.\n# Minimum value: 0, maximum value: 359, default value: 220.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nHTML_COLORSTYLE_HUE    = 220\n\n# The HTML_COLORSTYLE_SAT tag controls the purity (or saturation) of the colors\n# in the HTML output. For a value of 0 the output will use gray-scales only. A\n# value of 255 will produce the most vivid colors.\n# Minimum value: 0, maximum value: 255, default value: 100.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nHTML_COLORSTYLE_SAT    = 100\n\n# The HTML_COLORSTYLE_GAMMA tag controls the gamma correction applied to the\n# luminance component of the colors in the HTML output. Values below 100\n# gradually make the output lighter, whereas values above 100 make the output\n# darker. The value divided by 100 is the actual gamma applied, so 80 represents\n# a gamma of 0.8, The value 220 represents a gamma of 2.2, and 100 does not\n# change the gamma.\n# Minimum value: 40, maximum value: 240, default value: 80.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nHTML_COLORSTYLE_GAMMA  = 80\n\n# If the HTML_DYNAMIC_MENUS tag is set to YES then the generated HTML\n# documentation will contain a main index with vertical navigation menus that\n# are dynamically created via JavaScript. If disabled, the navigation index will\n# consists of multiple levels of tabs that are statically embedded in every HTML\n# page. Disable this option to support browsers that do not have JavaScript,\n# like the Qt help browser.\n# The default value is: YES.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nHTML_DYNAMIC_MENUS     = YES\n\n# If the HTML_DYNAMIC_SECTIONS tag is set to YES then the generated HTML\n# documentation will contain sections that can be hidden and shown after the\n# page has loaded.\n# The default value is: NO.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nHTML_DYNAMIC_SECTIONS  = NO\n\n# If the HTML_CODE_FOLDING tag is set to YES then classes and functions can be\n# dynamically folded and expanded in the generated HTML source code.\n# The default value is: YES.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nHTML_CODE_FOLDING      = YES\n\n# If the HTML_COPY_CLIPBOARD tag is set to YES then doxygen will show an icon in\n# the top right corner of code and text fragments that allows the user to copy\n# its content to the clipboard. Note this only works if supported by the browser\n# and the web page is served via a secure context (see:\n# https://www.w3.org/TR/secure-contexts/), i.e. using the https: or file:\n# protocol.\n# The default value is: YES.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nHTML_COPY_CLIPBOARD    = YES\n\n# Doxygen stores a couple of settings persistently in the browser (via e.g.\n# cookies). By default these settings apply to all HTML pages generated by\n# doxygen across all projects. The HTML_PROJECT_COOKIE tag can be used to store\n# the settings under a project specific key, such that the user preferences will\n# be stored separately.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nHTML_PROJECT_COOKIE    =\n\n# With HTML_INDEX_NUM_ENTRIES one can control the preferred number of entries\n# shown in the various tree structured indices initially; the user can expand\n# and collapse entries dynamically later on. Doxygen will expand the tree to\n# such a level that at most the specified number of entries are visible (unless\n# a fully collapsed tree already exceeds this amount). So setting the number of\n# entries 1 will produce a full collapsed tree by default. 0 is a special value\n# representing an infinite number of entries and will result in a full expanded\n# tree by default.\n# Minimum value: 0, maximum value: 9999, default value: 100.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nHTML_INDEX_NUM_ENTRIES = 100\n\n# If the GENERATE_DOCSET tag is set to YES, additional index files will be\n# generated that can be used as input for Apple's Xcode 3 integrated development\n# environment (see:\n# https://developer.apple.com/xcode/), introduced with OSX 10.5 (Leopard). To\n# create a documentation set, doxygen will generate a Makefile in the HTML\n# output directory. Running make will produce the docset in that directory and\n# running make install will install the docset in\n# ~/Library/Developer/Shared/Documentation/DocSets so that Xcode will find it at\n# startup. See https://developer.apple.com/library/archive/featuredarticles/Doxy\n# genXcode/_index.html for more information.\n# The default value is: NO.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nGENERATE_DOCSET        = NO\n\n# This tag determines the name of the docset feed. A documentation feed provides\n# an umbrella under which multiple documentation sets from a single provider\n# (such as a company or product suite) can be grouped.\n# The default value is: Doxygen generated docs.\n# This tag requires that the tag GENERATE_DOCSET is set to YES.\n\nDOCSET_FEEDNAME        = \"Doxygen generated docs\"\n\n# This tag determines the URL of the docset feed. A documentation feed provides\n# an umbrella under which multiple documentation sets from a single provider\n# (such as a company or product suite) can be grouped.\n# This tag requires that the tag GENERATE_DOCSET is set to YES.\n\nDOCSET_FEEDURL         =\n\n# This tag specifies a string that should uniquely identify the documentation\n# set bundle. This should be a reverse domain-name style string, e.g.\n# com.mycompany.MyDocSet. Doxygen will append .docset to the name.\n# The default value is: org.doxygen.Project.\n# This tag requires that the tag GENERATE_DOCSET is set to YES.\n\nDOCSET_BUNDLE_ID       = org.doxygen.Project\n\n# The DOCSET_PUBLISHER_ID tag specifies a string that should uniquely identify\n# the documentation publisher. This should be a reverse domain-name style\n# string, e.g. com.mycompany.MyDocSet.documentation.\n# The default value is: org.doxygen.Publisher.\n# This tag requires that the tag GENERATE_DOCSET is set to YES.\n\nDOCSET_PUBLISHER_ID    = org.doxygen.Publisher\n\n# The DOCSET_PUBLISHER_NAME tag identifies the documentation publisher.\n# The default value is: Publisher.\n# This tag requires that the tag GENERATE_DOCSET is set to YES.\n\nDOCSET_PUBLISHER_NAME  = Publisher\n\n# If the GENERATE_HTMLHELP tag is set to YES then doxygen generates three\n# additional HTML index files: index.hhp, index.hhc, and index.hhk. The\n# index.hhp is a project file that can be read by Microsoft's HTML Help Workshop\n# on Windows. In the beginning of 2021 Microsoft took the original page, with\n# a.o. the download links, offline the HTML help workshop was already many years\n# in maintenance mode). You can download the HTML help workshop from the web\n# archives at Installation executable (see:\n# http://web.archive.org/web/20160201063255/http://download.microsoft.com/downlo\n# ad/0/A/9/0A939EF6-E31C-430F-A3DF-DFAE7960D564/htmlhelp.exe).\n#\n# The HTML Help Workshop contains a compiler that can convert all HTML output\n# generated by doxygen into a single compiled HTML file (.chm). Compiled HTML\n# files are now used as the Windows 98 help format, and will replace the old\n# Windows help format (.hlp) on all Windows platforms in the future. Compressed\n# HTML files also contain an index, a table of contents, and you can search for\n# words in the documentation. The HTML workshop also contains a viewer for\n# compressed HTML files.\n# The default value is: NO.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nGENERATE_HTMLHELP      = NO\n\n# The CHM_FILE tag can be used to specify the file name of the resulting .chm\n# file. You can add a path in front of the file if the result should not be\n# written to the html output directory.\n# This tag requires that the tag GENERATE_HTMLHELP is set to YES.\n\nCHM_FILE               =\n\n# The HHC_LOCATION tag can be used to specify the location (absolute path\n# including file name) of the HTML help compiler (hhc.exe). If non-empty,\n# doxygen will try to run the HTML help compiler on the generated index.hhp.\n# The file has to be specified with full path.\n# This tag requires that the tag GENERATE_HTMLHELP is set to YES.\n\nHHC_LOCATION           =\n\n# The GENERATE_CHI flag controls if a separate .chi index file is generated\n# (YES) or that it should be included in the main .chm file (NO).\n# The default value is: NO.\n# This tag requires that the tag GENERATE_HTMLHELP is set to YES.\n\nGENERATE_CHI           = NO\n\n# The CHM_INDEX_ENCODING is used to encode HtmlHelp index (hhk), content (hhc)\n# and project file content.\n# This tag requires that the tag GENERATE_HTMLHELP is set to YES.\n\nCHM_INDEX_ENCODING     =\n\n# The BINARY_TOC flag controls whether a binary table of contents is generated\n# (YES) or a normal table of contents (NO) in the .chm file. Furthermore it\n# enables the Previous and Next buttons.\n# The default value is: NO.\n# This tag requires that the tag GENERATE_HTMLHELP is set to YES.\n\nBINARY_TOC             = NO\n\n# The TOC_EXPAND flag can be set to YES to add extra items for group members to\n# the table of contents of the HTML help documentation and to the tree view.\n# The default value is: NO.\n# This tag requires that the tag GENERATE_HTMLHELP is set to YES.\n\nTOC_EXPAND             = NO\n\n# The SITEMAP_URL tag is used to specify the full URL of the place where the\n# generated documentation will be placed on the server by the user during the\n# deployment of the documentation. The generated sitemap is called sitemap.xml\n# and placed on the directory specified by HTML_OUTPUT. In case no SITEMAP_URL\n# is specified no sitemap is generated. For information about the sitemap\n# protocol see https://www.sitemaps.org\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nSITEMAP_URL            =\n\n# If the GENERATE_QHP tag is set to YES and both QHP_NAMESPACE and\n# QHP_VIRTUAL_FOLDER are set, an additional index file will be generated that\n# can be used as input for Qt's qhelpgenerator to generate a Qt Compressed Help\n# (.qch) of the generated HTML documentation.\n# The default value is: NO.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nGENERATE_QHP           = NO\n\n# If the QHG_LOCATION tag is specified, the QCH_FILE tag can be used to specify\n# the file name of the resulting .qch file. The path specified is relative to\n# the HTML output folder.\n# This tag requires that the tag GENERATE_QHP is set to YES.\n\nQCH_FILE               =\n\n# The QHP_NAMESPACE tag specifies the namespace to use when generating Qt Help\n# Project output. For more information please see Qt Help Project / Namespace\n# (see:\n# https://doc.qt.io/archives/qt-4.8/qthelpproject.html#namespace).\n# The default value is: org.doxygen.Project.\n# This tag requires that the tag GENERATE_QHP is set to YES.\n\nQHP_NAMESPACE          = org.doxygen.Project\n\n# The QHP_VIRTUAL_FOLDER tag specifies the namespace to use when generating Qt\n# Help Project output. For more information please see Qt Help Project / Virtual\n# Folders (see:\n# https://doc.qt.io/archives/qt-4.8/qthelpproject.html#virtual-folders).\n# The default value is: doc.\n# This tag requires that the tag GENERATE_QHP is set to YES.\n\nQHP_VIRTUAL_FOLDER     = doc\n\n# If the QHP_CUST_FILTER_NAME tag is set, it specifies the name of a custom\n# filter to add. For more information please see Qt Help Project / Custom\n# Filters (see:\n# https://doc.qt.io/archives/qt-4.8/qthelpproject.html#custom-filters).\n# This tag requires that the tag GENERATE_QHP is set to YES.\n\nQHP_CUST_FILTER_NAME   =\n\n# The QHP_CUST_FILTER_ATTRS tag specifies the list of the attributes of the\n# custom filter to add. For more information please see Qt Help Project / Custom\n# Filters (see:\n# https://doc.qt.io/archives/qt-4.8/qthelpproject.html#custom-filters).\n# This tag requires that the tag GENERATE_QHP is set to YES.\n\nQHP_CUST_FILTER_ATTRS  =\n\n# The QHP_SECT_FILTER_ATTRS tag specifies the list of the attributes this\n# project's filter section matches. Qt Help Project / Filter Attributes (see:\n# https://doc.qt.io/archives/qt-4.8/qthelpproject.html#filter-attributes).\n# This tag requires that the tag GENERATE_QHP is set to YES.\n\nQHP_SECT_FILTER_ATTRS  =\n\n# The QHG_LOCATION tag can be used to specify the location (absolute path\n# including file name) of Qt's qhelpgenerator. If non-empty doxygen will try to\n# run qhelpgenerator on the generated .qhp file.\n# This tag requires that the tag GENERATE_QHP is set to YES.\n\nQHG_LOCATION           =\n\n# If the GENERATE_ECLIPSEHELP tag is set to YES, additional index files will be\n# generated, together with the HTML files, they form an Eclipse help plugin. To\n# install this plugin and make it available under the help contents menu in\n# Eclipse, the contents of the directory containing the HTML and XML files needs\n# to be copied into the plugins directory of eclipse. The name of the directory\n# within the plugins directory should be the same as the ECLIPSE_DOC_ID value.\n# After copying Eclipse needs to be restarted before the help appears.\n# The default value is: NO.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nGENERATE_ECLIPSEHELP   = NO\n\n# A unique identifier for the Eclipse help plugin. When installing the plugin\n# the directory name containing the HTML and XML files should also have this\n# name. Each documentation set should have its own identifier.\n# The default value is: org.doxygen.Project.\n# This tag requires that the tag GENERATE_ECLIPSEHELP is set to YES.\n\nECLIPSE_DOC_ID         = org.doxygen.Project\n\n# If you want full control over the layout of the generated HTML pages it might\n# be necessary to disable the index and replace it with your own. The\n# DISABLE_INDEX tag can be used to turn on/off the condensed index (tabs) at top\n# of each HTML page. A value of NO enables the index and the value YES disables\n# it. Since the tabs in the index contain the same information as the navigation\n# tree, you can set this option to YES if you also set GENERATE_TREEVIEW to YES.\n# The default value is: NO.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nDISABLE_INDEX          = YES\nGENERATE_TREEVIEW      = YES\nFULL_SIDEBAR           = YES\n\n\n# The GENERATE_TREEVIEW tag is used to specify whether a tree-like index\n# structure should be generated to display hierarchical information. If the tag\n# value is set to YES, a side panel will be generated containing a tree-like\n# index structure (just like the one that is generated for HTML Help). For this\n# to work a browser that supports JavaScript, DHTML, CSS and frames is required\n# (i.e. any modern browser). Windows users are probably better off using the\n# HTML help feature. Via custom style sheets (see HTML_EXTRA_STYLESHEET) one can\n# further fine tune the look of the index (see \"Fine-tuning the output\"). As an\n# example, the default style sheet generated by doxygen has an example that\n# shows how to put an image at the root of the tree instead of the PROJECT_NAME.\n# Since the tree basically has the same information as the tab index, you could\n# consider setting DISABLE_INDEX to YES when enabling this option.\n# The default value is: NO.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\n# GENERATE_TREEVIEW      = NO\n\n# When both GENERATE_TREEVIEW and DISABLE_INDEX are set to YES, then the\n# FULL_SIDEBAR option determines if the side bar is limited to only the treeview\n# area (value NO) or if it should extend to the full height of the window (value\n# YES). Setting this to YES gives a layout similar to\n# https://docs.readthedocs.io with more room for contents, but less room for the\n# project logo, title, and description. If either GENERATE_TREEVIEW or\n# DISABLE_INDEX is set to NO, this option has no effect.\n# The default value is: NO.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nFULL_SIDEBAR           = NO\n\n# The ENUM_VALUES_PER_LINE tag can be used to set the number of enum values that\n# doxygen will group on one line in the generated HTML documentation.\n#\n# Note that a value of 0 will completely suppress the enum values from appearing\n# in the overview section.\n# Minimum value: 0, maximum value: 20, default value: 4.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nENUM_VALUES_PER_LINE   = 4\n\n# If the treeview is enabled (see GENERATE_TREEVIEW) then this tag can be used\n# to set the initial width (in pixels) of the frame in which the tree is shown.\n# Minimum value: 0, maximum value: 1500, default value: 250.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nTREEVIEW_WIDTH         = 250\n\n# If the EXT_LINKS_IN_WINDOW option is set to YES, doxygen will open links to\n# external symbols imported via tag files in a separate window.\n# The default value is: NO.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nEXT_LINKS_IN_WINDOW    = NO\n\n# If the OBFUSCATE_EMAILS tag is set to YES, doxygen will obfuscate email\n# addresses.\n# The default value is: YES.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nOBFUSCATE_EMAILS       = YES\n\n# If the HTML_FORMULA_FORMAT option is set to svg, doxygen will use the pdf2svg\n# tool (see https://github.com/dawbarton/pdf2svg) or inkscape (see\n# https://inkscape.org) to generate formulas as SVG images instead of PNGs for\n# the HTML output. These images will generally look nicer at scaled resolutions.\n# Possible values are: png (the default) and svg (looks nicer but requires the\n# pdf2svg or inkscape tool).\n# The default value is: png.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nHTML_FORMULA_FORMAT    = png\n\n# Use this tag to change the font size of LaTeX formulas included as images in\n# the HTML documentation. When you change the font size after a successful\n# doxygen run you need to manually remove any form_*.png images from the HTML\n# output directory to force them to be regenerated.\n# Minimum value: 8, maximum value: 50, default value: 10.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nFORMULA_FONTSIZE       = 10\n\n# The FORMULA_MACROFILE can contain LaTeX \\newcommand and \\renewcommand commands\n# to create new LaTeX commands to be used in formulas as building blocks. See\n# the section \"Including formulas\" for details.\n\nFORMULA_MACROFILE      =\n\n# Enable the USE_MATHJAX option to render LaTeX formulas using MathJax (see\n# https://www.mathjax.org) which uses client side JavaScript for the rendering\n# instead of using pre-rendered bitmaps. Use this if you do not have LaTeX\n# installed or if you want to formulas look prettier in the HTML output. When\n# enabled you may also need to install MathJax separately and configure the path\n# to it using the MATHJAX_RELPATH option.\n# The default value is: NO.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nUSE_MATHJAX            = NO\n\n# With MATHJAX_VERSION it is possible to specify the MathJax version to be used.\n# Note that the different versions of MathJax have different requirements with\n# regards to the different settings, so it is possible that also other MathJax\n# settings have to be changed when switching between the different MathJax\n# versions.\n# Possible values are: MathJax_2 and MathJax_3.\n# The default value is: MathJax_2.\n# This tag requires that the tag USE_MATHJAX is set to YES.\n\nMATHJAX_VERSION        = MathJax_2\n\n# When MathJax is enabled you can set the default output format to be used for\n# the MathJax output. For more details about the output format see MathJax\n# version 2 (see:\n# http://docs.mathjax.org/en/v2.7-latest/output.html) and MathJax version 3\n# (see:\n# http://docs.mathjax.org/en/latest/web/components/output.html).\n# Possible values are: HTML-CSS (which is slower, but has the best\n# compatibility. This is the name for Mathjax version 2, for MathJax version 3\n# this will be translated into chtml), NativeMML (i.e. MathML. Only supported\n# for MathJax 2. For MathJax version 3 chtml will be used instead.), chtml (This\n# is the name for Mathjax version 3, for MathJax version 2 this will be\n# translated into HTML-CSS) and SVG.\n# The default value is: HTML-CSS.\n# This tag requires that the tag USE_MATHJAX is set to YES.\n\nMATHJAX_FORMAT         = HTML-CSS\n\n# When MathJax is enabled you need to specify the location relative to the HTML\n# output directory using the MATHJAX_RELPATH option. The destination directory\n# should contain the MathJax.js script. For instance, if the mathjax directory\n# is located at the same level as the HTML output directory, then\n# MATHJAX_RELPATH should be ../mathjax. The default value points to the MathJax\n# Content Delivery Network so you can quickly see the result without installing\n# MathJax. However, it is strongly recommended to install a local copy of\n# MathJax from https://www.mathjax.org before deployment. The default value is:\n# - in case of MathJax version 2: https://cdn.jsdelivr.net/npm/mathjax@2\n# - in case of MathJax version 3: https://cdn.jsdelivr.net/npm/mathjax@3\n# This tag requires that the tag USE_MATHJAX is set to YES.\n\nMATHJAX_RELPATH        =\n\n# The MATHJAX_EXTENSIONS tag can be used to specify one or more MathJax\n# extension names that should be enabled during MathJax rendering. For example\n# for MathJax version 2 (see\n# https://docs.mathjax.org/en/v2.7-latest/tex.html#tex-and-latex-extensions):\n# MATHJAX_EXTENSIONS = TeX/AMSmath TeX/AMSsymbols\n# For example for MathJax version 3 (see\n# http://docs.mathjax.org/en/latest/input/tex/extensions/index.html):\n# MATHJAX_EXTENSIONS = ams\n# This tag requires that the tag USE_MATHJAX is set to YES.\n\nMATHJAX_EXTENSIONS     =\n\n# The MATHJAX_CODEFILE tag can be used to specify a file with javascript pieces\n# of code that will be used on startup of the MathJax code. See the MathJax site\n# (see:\n# http://docs.mathjax.org/en/v2.7-latest/output.html) for more details. For an\n# example see the documentation.\n# This tag requires that the tag USE_MATHJAX is set to YES.\n\nMATHJAX_CODEFILE       =\n\n# When the SEARCHENGINE tag is enabled doxygen will generate a search box for\n# the HTML output. The underlying search engine uses javascript and DHTML and\n# should work on any modern browser. Note that when using HTML help\n# (GENERATE_HTMLHELP), Qt help (GENERATE_QHP), or docsets (GENERATE_DOCSET)\n# there is already a search function so this one should typically be disabled.\n# For large projects the javascript based search engine can be slow, then\n# enabling SERVER_BASED_SEARCH may provide a better solution. It is possible to\n# search using the keyboard; to jump to the search box use <access key> + S\n# (what the <access key> is depends on the OS and browser, but it is typically\n# <CTRL>, <ALT>/<option>, or both). Inside the search box use the <cursor down\n# key> to jump into the search results window, the results can be navigated\n# using the <cursor keys>. Press <Enter> to select an item or <escape> to cancel\n# the search. The filter options can be selected when the cursor is inside the\n# search box by pressing <Shift>+<cursor down>. Also here use the <cursor keys>\n# to select a filter and <Enter> or <escape> to activate or cancel the filter\n# option.\n# The default value is: YES.\n# This tag requires that the tag GENERATE_HTML is set to YES.\n\nSEARCHENGINE           = YES\n\n# When the SERVER_BASED_SEARCH tag is enabled the search engine will be\n# implemented using a web server instead of a web client using JavaScript. There\n# are two flavors of web server based searching depending on the EXTERNAL_SEARCH\n# setting. When disabled, doxygen will generate a PHP script for searching and\n# an index file used by the script. When EXTERNAL_SEARCH is enabled the indexing\n# and searching needs to be provided by external tools. See the section\n# \"External Indexing and Searching\" for details.\n# The default value is: NO.\n# This tag requires that the tag SEARCHENGINE is set to YES.\n\nSERVER_BASED_SEARCH    = NO\n\n# When EXTERNAL_SEARCH tag is enabled doxygen will no longer generate the PHP\n# script for searching. Instead the search results are written to an XML file\n# which needs to be processed by an external indexer. Doxygen will invoke an\n# external search engine pointed to by the SEARCHENGINE_URL option to obtain the\n# search results.\n#\n# Doxygen ships with an example indexer (doxyindexer) and search engine\n# (doxysearch.cgi) which are based on the open source search engine library\n# Xapian (see:\n# https://xapian.org/).\n#\n# See the section \"External Indexing and Searching\" for details.\n# The default value is: NO.\n# This tag requires that the tag SEARCHENGINE is set to YES.\n\nEXTERNAL_SEARCH        = NO\n\n# The SEARCHENGINE_URL should point to a search engine hosted by a web server\n# which will return the search results when EXTERNAL_SEARCH is enabled.\n#\n# Doxygen ships with an example indexer (doxyindexer) and search engine\n# (doxysearch.cgi) which are based on the open source search engine library\n# Xapian (see:\n# https://xapian.org/). See the section \"External Indexing and Searching\" for\n# details.\n# This tag requires that the tag SEARCHENGINE is set to YES.\n\nSEARCHENGINE_URL       =\n\n# When SERVER_BASED_SEARCH and EXTERNAL_SEARCH are both enabled the unindexed\n# search data is written to a file for indexing by an external tool. With the\n# SEARCHDATA_FILE tag the name of this file can be specified.\n# The default file is: searchdata.xml.\n# This tag requires that the tag SEARCHENGINE is set to YES.\n\nSEARCHDATA_FILE        = searchdata.xml\n\n# When SERVER_BASED_SEARCH and EXTERNAL_SEARCH are both enabled the\n# EXTERNAL_SEARCH_ID tag can be used as an identifier for the project. This is\n# useful in combination with EXTRA_SEARCH_MAPPINGS to search through multiple\n# projects and redirect the results back to the right project.\n# This tag requires that the tag SEARCHENGINE is set to YES.\n\nEXTERNAL_SEARCH_ID     =\n\n# The EXTRA_SEARCH_MAPPINGS tag can be used to enable searching through doxygen\n# projects other than the one defined by this configuration file, but that are\n# all added to the same external search index. Each project needs to have a\n# unique id set via EXTERNAL_SEARCH_ID. The search mapping then maps the id of\n# to a relative location where the documentation can be found. The format is:\n# EXTRA_SEARCH_MAPPINGS = tagname1=loc1 tagname2=loc2 ...\n# This tag requires that the tag SEARCHENGINE is set to YES.\n\nEXTRA_SEARCH_MAPPINGS  =\n\n#---------------------------------------------------------------------------\n# Configuration options related to the LaTeX output\n#---------------------------------------------------------------------------\n\n# If the GENERATE_LATEX tag is set to YES, doxygen will generate LaTeX output.\n# The default value is: YES.\n\nGENERATE_LATEX         = NO\n\n# The LATEX_OUTPUT tag is used to specify where the LaTeX docs will be put. If a\n# relative path is entered the value of OUTPUT_DIRECTORY will be put in front of\n# it.\n# The default directory is: latex.\n# This tag requires that the tag GENERATE_LATEX is set to YES.\n\nLATEX_OUTPUT           = latex\n\n# The LATEX_CMD_NAME tag can be used to specify the LaTeX command name to be\n# invoked.\n#\n# Note that when not enabling USE_PDFLATEX the default is latex when enabling\n# USE_PDFLATEX the default is pdflatex and when in the later case latex is\n# chosen this is overwritten by pdflatex. For specific output languages the\n# default can have been set differently, this depends on the implementation of\n# the output language.\n# This tag requires that the tag GENERATE_LATEX is set to YES.\n\nLATEX_CMD_NAME         =\n\n# The MAKEINDEX_CMD_NAME tag can be used to specify the command name to generate\n# index for LaTeX.\n# Note: This tag is used in the Makefile / make.bat.\n# See also: LATEX_MAKEINDEX_CMD for the part in the generated output file\n# (.tex).\n# The default file is: makeindex.\n# This tag requires that the tag GENERATE_LATEX is set to YES.\n\nMAKEINDEX_CMD_NAME     = makeindex\n\n# The LATEX_MAKEINDEX_CMD tag can be used to specify the command name to\n# generate index for LaTeX. In case there is no backslash (\\) as first character\n# it will be automatically added in the LaTeX code.\n# Note: This tag is used in the generated output file (.tex).\n# See also: MAKEINDEX_CMD_NAME for the part in the Makefile / make.bat.\n# The default value is: makeindex.\n# This tag requires that the tag GENERATE_LATEX is set to YES.\n\nLATEX_MAKEINDEX_CMD    = makeindex\n\n# If the COMPACT_LATEX tag is set to YES, doxygen generates more compact LaTeX\n# documents. This may be useful for small projects and may help to save some\n# trees in general.\n# The default value is: NO.\n# This tag requires that the tag GENERATE_LATEX is set to YES.\n\nCOMPACT_LATEX          = NO\n\n# The PAPER_TYPE tag can be used to set the paper type that is used by the\n# printer.\n# Possible values are: a4 (210 x 297 mm), letter (8.5 x 11 inches), legal (8.5 x\n# 14 inches) and executive (7.25 x 10.5 inches).\n# The default value is: a4.\n# This tag requires that the tag GENERATE_LATEX is set to YES.\n\nPAPER_TYPE             = a4\n\n# The EXTRA_PACKAGES tag can be used to specify one or more LaTeX package names\n# that should be included in the LaTeX output. The package can be specified just\n# by its name or with the correct syntax as to be used with the LaTeX\n# \\usepackage command. To get the times font for instance you can specify :\n# EXTRA_PACKAGES=times or EXTRA_PACKAGES={times}\n# To use the option intlimits with the amsmath package you can specify:\n# EXTRA_PACKAGES=[intlimits]{amsmath}\n# If left blank no extra packages will be included.\n# This tag requires that the tag GENERATE_LATEX is set to YES.\n\nEXTRA_PACKAGES         =\n\n# The LATEX_HEADER tag can be used to specify a user-defined LaTeX header for\n# the generated LaTeX document. The header should contain everything until the\n# first chapter. If it is left blank doxygen will generate a standard header. It\n# is highly recommended to start with a default header using\n# doxygen -w latex new_header.tex new_footer.tex new_stylesheet.sty\n# and then modify the file new_header.tex. See also section \"Doxygen usage\" for\n# information on how to generate the default header that doxygen normally uses.\n#\n# Note: Only use a user-defined header if you know what you are doing!\n# Note: The header is subject to change so you typically have to regenerate the\n# default header when upgrading to a newer version of doxygen. The following\n# commands have a special meaning inside the header (and footer): For a\n# description of the possible markers and block names see the documentation.\n# This tag requires that the tag GENERATE_LATEX is set to YES.\n\nLATEX_HEADER           =\n\n# The LATEX_FOOTER tag can be used to specify a user-defined LaTeX footer for\n# the generated LaTeX document. The footer should contain everything after the\n# last chapter. If it is left blank doxygen will generate a standard footer. See\n# LATEX_HEADER for more information on how to generate a default footer and what\n# special commands can be used inside the footer. See also section \"Doxygen\n# usage\" for information on how to generate the default footer that doxygen\n# normally uses. Note: Only use a user-defined footer if you know what you are\n# doing!\n# This tag requires that the tag GENERATE_LATEX is set to YES.\n\nLATEX_FOOTER           =\n\n# The LATEX_EXTRA_STYLESHEET tag can be used to specify additional user-defined\n# LaTeX style sheets that are included after the standard style sheets created\n# by doxygen. Using this option one can overrule certain style aspects. Doxygen\n# will copy the style sheet files to the output directory.\n# Note: The order of the extra style sheet files is of importance (e.g. the last\n# style sheet in the list overrules the setting of the previous ones in the\n# list).\n# This tag requires that the tag GENERATE_LATEX is set to YES.\n\nLATEX_EXTRA_STYLESHEET =\n\n# The LATEX_EXTRA_FILES tag can be used to specify one or more extra images or\n# other source files which should be copied to the LATEX_OUTPUT output\n# directory. Note that the files will be copied as-is; there are no commands or\n# markers available.\n# This tag requires that the tag GENERATE_LATEX is set to YES.\n\nLATEX_EXTRA_FILES      =\n\n# If the PDF_HYPERLINKS tag is set to YES, the LaTeX that is generated is\n# prepared for conversion to PDF (using ps2pdf or pdflatex). The PDF file will\n# contain links (just like the HTML output) instead of page references. This\n# makes the output suitable for online browsing using a PDF viewer.\n# The default value is: YES.\n# This tag requires that the tag GENERATE_LATEX is set to YES.\n\nPDF_HYPERLINKS         = YES\n\n# If the USE_PDFLATEX tag is set to YES, doxygen will use the engine as\n# specified with LATEX_CMD_NAME to generate the PDF file directly from the LaTeX\n# files. Set this option to YES, to get a higher quality PDF documentation.\n#\n# See also section LATEX_CMD_NAME for selecting the engine.\n# The default value is: YES.\n# This tag requires that the tag GENERATE_LATEX is set to YES.\n\nUSE_PDFLATEX           = YES\n\n# The LATEX_BATCHMODE tag signals the behavior of LaTeX in case of an error.\n# Possible values are: NO same as ERROR_STOP, YES same as BATCH, BATCH In batch\n# mode nothing is printed on the terminal, errors are scrolled as if <return> is\n# hit at every error; missing files that TeX tries to input or request from\n# keyboard input (\\read on a not open input stream) cause the job to abort,\n# NON_STOP In nonstop mode the diagnostic message will appear on the terminal,\n# but there is no possibility of user interaction just like in batch mode,\n# SCROLL In scroll mode, TeX will stop only for missing files to input or if\n# keyboard input is necessary and ERROR_STOP In errorstop mode, TeX will stop at\n# each error, asking for user intervention.\n# The default value is: NO.\n# This tag requires that the tag GENERATE_LATEX is set to YES.\n\nLATEX_BATCHMODE        = NO\n\n# If the LATEX_HIDE_INDICES tag is set to YES then doxygen will not include the\n# index chapters (such as File Index, Compound Index, etc.) in the output.\n# The default value is: NO.\n# This tag requires that the tag GENERATE_LATEX is set to YES.\n\nLATEX_HIDE_INDICES     = NO\n\n# The LATEX_BIB_STYLE tag can be used to specify the style to use for the\n# bibliography, e.g. plainnat, or ieeetr. See\n# https://en.wikipedia.org/wiki/BibTeX and \\cite for more info.\n# The default value is: plain.\n# This tag requires that the tag GENERATE_LATEX is set to YES.\n\nLATEX_BIB_STYLE        = plain\n\n# The LATEX_EMOJI_DIRECTORY tag is used to specify the (relative or absolute)\n# path from which the emoji images will be read. If a relative path is entered,\n# it will be relative to the LATEX_OUTPUT directory. If left blank the\n# LATEX_OUTPUT directory will be used.\n# This tag requires that the tag GENERATE_LATEX is set to YES.\n\nLATEX_EMOJI_DIRECTORY  =\n\n#---------------------------------------------------------------------------\n# Configuration options related to the RTF output\n#---------------------------------------------------------------------------\n\n# If the GENERATE_RTF tag is set to YES, doxygen will generate RTF output. The\n# RTF output is optimized for Word 97 and may not look too pretty with other RTF\n# readers/editors.\n# The default value is: NO.\n\nGENERATE_RTF           = NO\n\n# The RTF_OUTPUT tag is used to specify where the RTF docs will be put. If a\n# relative path is entered the value of OUTPUT_DIRECTORY will be put in front of\n# it.\n# The default directory is: rtf.\n# This tag requires that the tag GENERATE_RTF is set to YES.\n\nRTF_OUTPUT             = rtf\n\n# If the COMPACT_RTF tag is set to YES, doxygen generates more compact RTF\n# documents. This may be useful for small projects and may help to save some\n# trees in general.\n# The default value is: NO.\n# This tag requires that the tag GENERATE_RTF is set to YES.\n\nCOMPACT_RTF            = NO\n\n# If the RTF_HYPERLINKS tag is set to YES, the RTF that is generated will\n# contain hyperlink fields. The RTF file will contain links (just like the HTML\n# output) instead of page references. This makes the output suitable for online\n# browsing using Word or some other Word compatible readers that support those\n# fields.\n#\n# Note: WordPad (write) and others do not support links.\n# The default value is: NO.\n# This tag requires that the tag GENERATE_RTF is set to YES.\n\nRTF_HYPERLINKS         = NO\n\n# Load stylesheet definitions from file. Syntax is similar to doxygen's\n# configuration file, i.e. a series of assignments. You only have to provide\n# replacements, missing definitions are set to their default value.\n#\n# See also section \"Doxygen usage\" for information on how to generate the\n# default style sheet that doxygen normally uses.\n# This tag requires that the tag GENERATE_RTF is set to YES.\n\nRTF_STYLESHEET_FILE    =\n\n# Set optional variables used in the generation of an RTF document. Syntax is\n# similar to doxygen's configuration file. A template extensions file can be\n# generated using doxygen -e rtf extensionFile.\n# This tag requires that the tag GENERATE_RTF is set to YES.\n\nRTF_EXTENSIONS_FILE    =\n\n# The RTF_EXTRA_FILES tag can be used to specify one or more extra images or\n# other source files which should be copied to the RTF_OUTPUT output directory.\n# Note that the files will be copied as-is; there are no commands or markers\n# available.\n# This tag requires that the tag GENERATE_RTF is set to YES.\n\nRTF_EXTRA_FILES        =\n\n#---------------------------------------------------------------------------\n# Configuration options related to the man page output\n#---------------------------------------------------------------------------\n\n# If the GENERATE_MAN tag is set to YES, doxygen will generate man pages for\n# classes and files.\n# The default value is: NO.\n\nGENERATE_MAN           = NO\n\n# The MAN_OUTPUT tag is used to specify where the man pages will be put. If a\n# relative path is entered the value of OUTPUT_DIRECTORY will be put in front of\n# it. A directory man3 will be created inside the directory specified by\n# MAN_OUTPUT.\n# The default directory is: man.\n# This tag requires that the tag GENERATE_MAN is set to YES.\n\nMAN_OUTPUT             = man\n\n# The MAN_EXTENSION tag determines the extension that is added to the generated\n# man pages. In case the manual section does not start with a number, the number\n# 3 is prepended. The dot (.) at the beginning of the MAN_EXTENSION tag is\n# optional.\n# The default value is: .3.\n# This tag requires that the tag GENERATE_MAN is set to YES.\n\nMAN_EXTENSION          = .3\n\n# The MAN_SUBDIR tag determines the name of the directory created within\n# MAN_OUTPUT in which the man pages are placed. If defaults to man followed by\n# MAN_EXTENSION with the initial . removed.\n# This tag requires that the tag GENERATE_MAN is set to YES.\n\nMAN_SUBDIR             =\n\n# If the MAN_LINKS tag is set to YES and doxygen generates man output, then it\n# will generate one additional man file for each entity documented in the real\n# man page(s). These additional files only source the real man page, but without\n# them the man command would be unable to find the correct page.\n# The default value is: NO.\n# This tag requires that the tag GENERATE_MAN is set to YES.\n\nMAN_LINKS              = NO\n\n#---------------------------------------------------------------------------\n# Configuration options related to the XML output\n#---------------------------------------------------------------------------\n\n# If the GENERATE_XML tag is set to YES, doxygen will generate an XML file that\n# captures the structure of the code including all documentation.\n# The default value is: NO.\n\nGENERATE_XML           = NO\n\n# The XML_OUTPUT tag is used to specify where the XML pages will be put. If a\n# relative path is entered the value of OUTPUT_DIRECTORY will be put in front of\n# it.\n# The default directory is: xml.\n# This tag requires that the tag GENERATE_XML is set to YES.\n\nXML_OUTPUT             = xml\n\n# If the XML_PROGRAMLISTING tag is set to YES, doxygen will dump the program\n# listings (including syntax highlighting and cross-referencing information) to\n# the XML output. Note that enabling this will significantly increase the size\n# of the XML output.\n# The default value is: YES.\n# This tag requires that the tag GENERATE_XML is set to YES.\n\nXML_PROGRAMLISTING     = YES\n\n# If the XML_NS_MEMB_FILE_SCOPE tag is set to YES, doxygen will include\n# namespace members in file scope as well, matching the HTML output.\n# The default value is: NO.\n# This tag requires that the tag GENERATE_XML is set to YES.\n\nXML_NS_MEMB_FILE_SCOPE = NO\n\n#---------------------------------------------------------------------------\n# Configuration options for the AutoGen Definitions output\n#---------------------------------------------------------------------------\n\n# If the GENERATE_AUTOGEN_DEF tag is set to YES, doxygen will generate an\n# AutoGen Definitions (see https://autogen.sourceforge.net/) file that captures\n# the structure of the code including all documentation. Note that this feature\n# is still experimental and incomplete at the moment.\n# The default value is: NO.\n\nGENERATE_AUTOGEN_DEF   = NO\n\n#---------------------------------------------------------------------------\n# Configuration options related to Sqlite3 output\n#---------------------------------------------------------------------------\n\n# If the GENERATE_SQLITE3 tag is set to YES doxygen will generate a Sqlite3\n# database with symbols found by doxygen stored in tables.\n# The default value is: NO.\n\nGENERATE_SQLITE3       = NO\n\n# The SQLITE3_OUTPUT tag is used to specify where the Sqlite3 database will be\n# put. If a relative path is entered the value of OUTPUT_DIRECTORY will be put\n# in front of it.\n# The default directory is: sqlite3.\n# This tag requires that the tag GENERATE_SQLITE3 is set to YES.\n\nSQLITE3_OUTPUT         = sqlite3\n\n# The SQLITE3_RECREATE_DB tag is set to YES, the existing doxygen_sqlite3.db\n# database file will be recreated with each doxygen run. If set to NO, doxygen\n# will warn if a database file is already found and not modify it.\n# The default value is: YES.\n# This tag requires that the tag GENERATE_SQLITE3 is set to YES.\n\nSQLITE3_RECREATE_DB    = YES\n\n#---------------------------------------------------------------------------\n# Configuration options related to the Perl module output\n#---------------------------------------------------------------------------\n\n# If the GENERATE_PERLMOD tag is set to YES, doxygen will generate a Perl module\n# file that captures the structure of the code including all documentation.\n#\n# Note that this feature is still experimental and incomplete at the moment.\n# The default value is: NO.\n\nGENERATE_PERLMOD       = NO\n\n# If the PERLMOD_LATEX tag is set to YES, doxygen will generate the necessary\n# Makefile rules, Perl scripts and LaTeX code to be able to generate PDF and DVI\n# output from the Perl module output.\n# The default value is: NO.\n# This tag requires that the tag GENERATE_PERLMOD is set to YES.\n\nPERLMOD_LATEX          = NO\n\n# If the PERLMOD_PRETTY tag is set to YES, the Perl module output will be nicely\n# formatted so it can be parsed by a human reader. This is useful if you want to\n# understand what is going on. On the other hand, if this tag is set to NO, the\n# size of the Perl module output will be much smaller and Perl will parse it\n# just the same.\n# The default value is: YES.\n# This tag requires that the tag GENERATE_PERLMOD is set to YES.\n\nPERLMOD_PRETTY         = YES\n\n# The names of the make variables in the generated doxyrules.make file are\n# prefixed with the string contained in PERLMOD_MAKEVAR_PREFIX. This is useful\n# so different doxyrules.make files included by the same Makefile don't\n# overwrite each other's variables.\n# This tag requires that the tag GENERATE_PERLMOD is set to YES.\n\nPERLMOD_MAKEVAR_PREFIX =\n\n#---------------------------------------------------------------------------\n# Markdown\n#---------------------------------------------------------------------------\n\nGENERATE_MARKDOWN      = YES\nMARKDOWN_OUTPUT        = \"markdown\"\n\n#---------------------------------------------------------------------------\n# Configuration options related to the preprocessor\n#---------------------------------------------------------------------------\n\n# If the ENABLE_PREPROCESSING tag is set to YES, doxygen will evaluate all\n# C-preprocessor directives found in the sources and include files.\n# The default value is: YES.\n\nENABLE_PREPROCESSING   = YES\n\n# If the MACRO_EXPANSION tag is set to YES, doxygen will expand all macro names\n# in the source code. If set to NO, only conditional compilation will be\n# performed. Macro expansion can be done in a controlled way by setting\n# EXPAND_ONLY_PREDEF to YES.\n# The default value is: NO.\n# This tag requires that the tag ENABLE_PREPROCESSING is set to YES.\n\nMACRO_EXPANSION        = NO\n\n# If the EXPAND_ONLY_PREDEF and MACRO_EXPANSION tags are both set to YES then\n# the macro expansion is limited to the macros specified with the PREDEFINED and\n# EXPAND_AS_DEFINED tags.\n# The default value is: NO.\n# This tag requires that the tag ENABLE_PREPROCESSING is set to YES.\n\nEXPAND_ONLY_PREDEF     = NO\n\n# If the SEARCH_INCLUDES tag is set to YES, the include files in the\n# INCLUDE_PATH will be searched if a #include is found.\n# The default value is: YES.\n# This tag requires that the tag ENABLE_PREPROCESSING is set to YES.\n\nSEARCH_INCLUDES        = YES\n\n# The INCLUDE_PATH tag can be used to specify one or more directories that\n# contain include files that are not input files but should be processed by the\n# preprocessor. Note that the INCLUDE_PATH is not recursive, so the setting of\n# RECURSIVE has no effect here.\n# This tag requires that the tag SEARCH_INCLUDES is set to YES.\n\nINCLUDE_PATH           =\n\n# You can use the INCLUDE_FILE_PATTERNS tag to specify one or more wildcard\n# patterns (like *.h and *.hpp) to filter out the header-files in the\n# directories. If left blank, the patterns specified with FILE_PATTERNS will be\n# used.\n# This tag requires that the tag ENABLE_PREPROCESSING is set to YES.\n\nINCLUDE_FILE_PATTERNS  =\n\n# The PREDEFINED tag can be used to specify one or more macro names that are\n# defined before the preprocessor is started (similar to the -D option of e.g.\n# gcc). The argument of the tag is a list of macros of the form: name or\n# name=definition (no spaces). If the definition and the \"=\" are omitted, \"=1\"\n# is assumed. To prevent a macro definition from being undefined via #undef or\n# recursively expanded use the := operator instead of the = operator.\n# This tag requires that the tag ENABLE_PREPROCESSING is set to YES.\n\nPREDEFINED             =\n\n# If the MACRO_EXPANSION and EXPAND_ONLY_PREDEF tags are set to YES then this\n# tag can be used to specify a list of macro names that should be expanded. The\n# macro definition that is found in the sources will be used. Use the PREDEFINED\n# tag if you want to use a different macro definition that overrules the\n# definition found in the source code.\n# This tag requires that the tag ENABLE_PREPROCESSING is set to YES.\n\nEXPAND_AS_DEFINED      =\n\n# If the SKIP_FUNCTION_MACROS tag is set to YES then doxygen's preprocessor will\n# remove all references to function-like macros that are alone on a line, have\n# an all uppercase name, and do not end with a semicolon. Such function macros\n# are typically used for boiler-plate code, and will confuse the parser if not\n# removed.\n# The default value is: YES.\n# This tag requires that the tag ENABLE_PREPROCESSING is set to YES.\n\nSKIP_FUNCTION_MACROS   = YES\n\n#---------------------------------------------------------------------------\n# Configuration options related to external references\n#---------------------------------------------------------------------------\n\n# The TAGFILES tag can be used to specify one or more tag files. For each tag\n# file the location of the external documentation should be added. The format of\n# a tag file without this location is as follows:\n# TAGFILES = file1 file2 ...\n# Adding location for the tag files is done as follows:\n# TAGFILES = file1=loc1 \"file2 = loc2\" ...\n# where loc1 and loc2 can be relative or absolute paths or URLs. See the\n# section \"Linking to external documentation\" for more information about the use\n# of tag files.\n# Note: Each tag file must have a unique name (where the name does NOT include\n# the path). If a tag file is not located in the directory in which doxygen is\n# run, you must also specify the path to the tagfile here.\n\nTAGFILES               =\n\n# When a file name is specified after GENERATE_TAGFILE, doxygen will create a\n# tag file that is based on the input files it reads. See section \"Linking to\n# external documentation\" for more information about the usage of tag files.\n\nGENERATE_TAGFILE       =\n\n# If the ALLEXTERNALS tag is set to YES, all external classes and namespaces\n# will be listed in the class and namespace index. If set to NO, only the\n# inherited external classes will be listed.\n# The default value is: NO.\n\nALLEXTERNALS           = NO\n\n# If the EXTERNAL_GROUPS tag is set to YES, all external groups will be listed\n# in the topic index. If set to NO, only the current project's groups will be\n# listed.\n# The default value is: YES.\n\nEXTERNAL_GROUPS        = YES\n\n# If the EXTERNAL_PAGES tag is set to YES, all external pages will be listed in\n# the related pages index. If set to NO, only the current project's pages will\n# be listed.\n# The default value is: YES.\n\nEXTERNAL_PAGES         = YES\n\n#---------------------------------------------------------------------------\n# Configuration options related to diagram generator tools\n#---------------------------------------------------------------------------\n\n# If set to YES the inheritance and collaboration graphs will hide inheritance\n# and usage relations if the target is undocumented or is not a class.\n# The default value is: YES.\n\nHIDE_UNDOC_RELATIONS   = YES\n\n# If you set the HAVE_DOT tag to YES then doxygen will assume the dot tool is\n# available from the path. This tool is part of Graphviz (see:\n# https://www.graphviz.org/), a graph visualization toolkit from AT&T and Lucent\n# Bell Labs. The other options in this section have no effect if this option is\n# set to NO\n# The default value is: NO.\n\nHAVE_DOT               = NO\n\n# The DOT_NUM_THREADS specifies the number of dot invocations doxygen is allowed\n# to run in parallel. When set to 0 doxygen will base this on the number of\n# processors available in the system. You can set it explicitly to a value\n# larger than 0 to get control over the balance between CPU load and processing\n# speed.\n# Minimum value: 0, maximum value: 32, default value: 0.\n# This tag requires that the tag HAVE_DOT is set to YES.\n\nDOT_NUM_THREADS        = 0\n\n# DOT_COMMON_ATTR is common attributes for nodes, edges and labels of\n# subgraphs. When you want a differently looking font in the dot files that\n# doxygen generates you can specify fontname, fontcolor and fontsize attributes.\n# For details please see <a href=https://graphviz.org/doc/info/attrs.html>Node,\n# Edge and Graph Attributes specification</a> You need to make sure dot is able\n# to find the font, which can be done by putting it in a standard location or by\n# setting the DOTFONTPATH environment variable or by setting DOT_FONTPATH to the\n# directory containing the font. Default graphviz fontsize is 14.\n# The default value is: fontname=Helvetica,fontsize=10.\n# This tag requires that the tag HAVE_DOT is set to YES.\n\nDOT_COMMON_ATTR        = \"fontname=Helvetica,fontsize=10\"\n\n# DOT_EDGE_ATTR is concatenated with DOT_COMMON_ATTR. For elegant style you can\n# add 'arrowhead=open, arrowtail=open, arrowsize=0.5'. <a\n# href=https://graphviz.org/doc/info/arrows.html>Complete documentation about\n# arrows shapes.</a>\n# The default value is: labelfontname=Helvetica,labelfontsize=10.\n# This tag requires that the tag HAVE_DOT is set to YES.\n\nDOT_EDGE_ATTR          = \"labelfontname=Helvetica,labelfontsize=10\"\n\n# DOT_NODE_ATTR is concatenated with DOT_COMMON_ATTR. For view without boxes\n# around nodes set 'shape=plain' or 'shape=plaintext' <a\n# href=https://www.graphviz.org/doc/info/shapes.html>Shapes specification</a>\n# The default value is: shape=box,height=0.2,width=0.4.\n# This tag requires that the tag HAVE_DOT is set to YES.\n\nDOT_NODE_ATTR          = \"shape=box,height=0.2,width=0.4\"\n\n# You can set the path where dot can find font specified with fontname in\n# DOT_COMMON_ATTR and others dot attributes.\n# This tag requires that the tag HAVE_DOT is set to YES.\n\nDOT_FONTPATH           =\n\n# If the CLASS_GRAPH tag is set to YES or GRAPH or BUILTIN then doxygen will\n# generate a graph for each documented class showing the direct and indirect\n# inheritance relations. In case the CLASS_GRAPH tag is set to YES or GRAPH and\n# HAVE_DOT is enabled as well, then dot will be used to draw the graph. In case\n# the CLASS_GRAPH tag is set to YES and HAVE_DOT is disabled or if the\n# CLASS_GRAPH tag is set to BUILTIN, then the built-in generator will be used.\n# If the CLASS_GRAPH tag is set to TEXT the direct and indirect inheritance\n# relations will be shown as texts / links. Explicit enabling an inheritance\n# graph or choosing a different representation for an inheritance graph of a\n# specific class, can be accomplished by means of the command \\inheritancegraph.\n# Disabling an inheritance graph can be accomplished by means of the command\n# \\hideinheritancegraph.\n# Possible values are: NO, YES, TEXT, GRAPH and BUILTIN.\n# The default value is: YES.\n\nCLASS_GRAPH            = NO\n\n# If the COLLABORATION_GRAPH tag is set to YES then doxygen will generate a\n# graph for each documented class showing the direct and indirect implementation\n# dependencies (inheritance, containment, and class references variables) of the\n# class with other documented classes. Explicit enabling a collaboration graph,\n# when COLLABORATION_GRAPH is set to NO, can be accomplished by means of the\n# command \\collaborationgraph. Disabling a collaboration graph can be\n# accomplished by means of the command \\hidecollaborationgraph.\n# The default value is: YES.\n# This tag requires that the tag HAVE_DOT is set to YES.\n\nCOLLABORATION_GRAPH    = YES\n\n# If the GROUP_GRAPHS tag is set to YES then doxygen will generate a graph for\n# groups, showing the direct groups dependencies. Explicit enabling a group\n# dependency graph, when GROUP_GRAPHS is set to NO, can be accomplished by means\n# of the command \\groupgraph. Disabling a directory graph can be accomplished by\n# means of the command \\hidegroupgraph. See also the chapter Grouping in the\n# manual.\n# The default value is: YES.\n# This tag requires that the tag HAVE_DOT is set to YES.\n\nGROUP_GRAPHS           = YES\n\n# If the UML_LOOK tag is set to YES, doxygen will generate inheritance and\n# collaboration diagrams in a style similar to the OMG's Unified Modeling\n# Language.\n# The default value is: NO.\n# This tag requires that the tag HAVE_DOT is set to YES.\n\nUML_LOOK               = NO\n\n# If the UML_LOOK tag is enabled, the fields and methods are shown inside the\n# class node. If there are many fields or methods and many nodes the graph may\n# become too big to be useful. The UML_LIMIT_NUM_FIELDS threshold limits the\n# number of items for each type to make the size more manageable. Set this to 0\n# for no limit. Note that the threshold may be exceeded by 50% before the limit\n# is enforced. So when you set the threshold to 10, up to 15 fields may appear,\n# but if the number exceeds 15, the total amount of fields shown is limited to\n# 10.\n# Minimum value: 0, maximum value: 100, default value: 10.\n# This tag requires that the tag UML_LOOK is set to YES.\n\nUML_LIMIT_NUM_FIELDS   = 10\n\n# If the DOT_UML_DETAILS tag is set to NO, doxygen will show attributes and\n# methods without types and arguments in the UML graphs. If the DOT_UML_DETAILS\n# tag is set to YES, doxygen will add type and arguments for attributes and\n# methods in the UML graphs. If the DOT_UML_DETAILS tag is set to NONE, doxygen\n# will not generate fields with class member information in the UML graphs. The\n# class diagrams will look similar to the default class diagrams but using UML\n# notation for the relationships.\n# Possible values are: NO, YES and NONE.\n# The default value is: NO.\n# This tag requires that the tag UML_LOOK is set to YES.\n\nDOT_UML_DETAILS        = NO\n\n# The DOT_WRAP_THRESHOLD tag can be used to set the maximum number of characters\n# to display on a single line. If the actual line length exceeds this threshold\n# significantly it will be wrapped across multiple lines. Some heuristics are\n# applied to avoid ugly line breaks.\n# Minimum value: 0, maximum value: 1000, default value: 17.\n# This tag requires that the tag HAVE_DOT is set to YES.\n\nDOT_WRAP_THRESHOLD     = 17\n\n# If the TEMPLATE_RELATIONS tag is set to YES then the inheritance and\n# collaboration graphs will show the relations between templates and their\n# instances.\n# The default value is: NO.\n# This tag requires that the tag HAVE_DOT is set to YES.\n\nTEMPLATE_RELATIONS     = NO\n\n# If the INCLUDE_GRAPH, ENABLE_PREPROCESSING and SEARCH_INCLUDES tags are set to\n# YES then doxygen will generate a graph for each documented file showing the\n# direct and indirect include dependencies of the file with other documented\n# files. Explicit enabling an include graph, when INCLUDE_GRAPH is is set to NO,\n# can be accomplished by means of the command \\includegraph. Disabling an\n# include graph can be accomplished by means of the command \\hideincludegraph.\n# The default value is: YES.\n# This tag requires that the tag HAVE_DOT is set to YES.\n\nINCLUDE_GRAPH          = YES\n\n# If the INCLUDED_BY_GRAPH, ENABLE_PREPROCESSING and SEARCH_INCLUDES tags are\n# set to YES then doxygen will generate a graph for each documented file showing\n# the direct and indirect include dependencies of the file with other documented\n# files. Explicit enabling an included by graph, when INCLUDED_BY_GRAPH is set\n# to NO, can be accomplished by means of the command \\includedbygraph. Disabling\n# an included by graph can be accomplished by means of the command\n# \\hideincludedbygraph.\n# The default value is: YES.\n# This tag requires that the tag HAVE_DOT is set to YES.\n\nINCLUDED_BY_GRAPH      = YES\n\n# If the CALL_GRAPH tag is set to YES then doxygen will generate a call\n# dependency graph for every global function or class method.\n#\n# Note that enabling this option will significantly increase the time of a run.\n# So in most cases it will be better to enable call graphs for selected\n# functions only using the \\callgraph command. Disabling a call graph can be\n# accomplished by means of the command \\hidecallgraph.\n# The default value is: NO.\n# This tag requires that the tag HAVE_DOT is set to YES.\n\nCALL_GRAPH             = NO\n\n# If the CALLER_GRAPH tag is set to YES then doxygen will generate a caller\n# dependency graph for every global function or class method.\n#\n# Note that enabling this option will significantly increase the time of a run.\n# So in most cases it will be better to enable caller graphs for selected\n# functions only using the \\callergraph command. Disabling a caller graph can be\n# accomplished by means of the command \\hidecallergraph.\n# The default value is: NO.\n# This tag requires that the tag HAVE_DOT is set to YES.\n\nCALLER_GRAPH           = NO\n\n# If the GRAPHICAL_HIERARCHY tag is set to YES then doxygen will graphical\n# hierarchy of all classes instead of a textual one.\n# The default value is: YES.\n# This tag requires that the tag HAVE_DOT is set to YES.\n\nGRAPHICAL_HIERARCHY    = NO\n\n# If the DIRECTORY_GRAPH tag is set to YES then doxygen will show the\n# dependencies a directory has on other directories in a graphical way. The\n# dependency relations are determined by the #include relations between the\n# files in the directories. Explicit enabling a directory graph, when\n# DIRECTORY_GRAPH is set to NO, can be accomplished by means of the command\n# \\directorygraph. Disabling a directory graph can be accomplished by means of\n# the command \\hidedirectorygraph.\n# The default value is: YES.\n# This tag requires that the tag HAVE_DOT is set to YES.\n\nDIRECTORY_GRAPH        = YES\n\n# The DIR_GRAPH_MAX_DEPTH tag can be used to limit the maximum number of levels\n# of child directories generated in directory dependency graphs by dot.\n# Minimum value: 1, maximum value: 25, default value: 1.\n# This tag requires that the tag DIRECTORY_GRAPH is set to YES.\n\nDIR_GRAPH_MAX_DEPTH    = 1\n\n# The DOT_IMAGE_FORMAT tag can be used to set the image format of the images\n# generated by dot. For an explanation of the image formats see the section\n# output formats in the documentation of the dot tool (Graphviz (see:\n# https://www.graphviz.org/)).\n# Note: If you choose svg you need to set HTML_FILE_EXTENSION to xhtml in order\n# to make the SVG files visible in IE 9+ (other browsers do not have this\n# requirement).\n# Possible values are: png, jpg, gif, svg, png:gd, png:gd:gd, png:cairo,\n# png:cairo:gd, png:cairo:cairo, png:cairo:gdiplus, png:gdiplus and\n# png:gdiplus:gdiplus.\n# The default value is: png.\n# This tag requires that the tag HAVE_DOT is set to YES.\n\nDOT_IMAGE_FORMAT       = png\n\n# If DOT_IMAGE_FORMAT is set to svg, then this option can be set to YES to\n# enable generation of interactive SVG images that allow zooming and panning.\n#\n# Note that this requires a modern browser other than Internet Explorer. Tested\n# and working are Firefox, Chrome, Safari, and Opera.\n# Note: For IE 9+ you need to set HTML_FILE_EXTENSION to xhtml in order to make\n# the SVG files visible. Older versions of IE do not have SVG support.\n# The default value is: NO.\n# This tag requires that the tag HAVE_DOT is set to YES.\n\nINTERACTIVE_SVG        = NO\n\n# The DOT_PATH tag can be used to specify the path where the dot tool can be\n# found. If left blank, it is assumed the dot tool can be found in the path.\n# This tag requires that the tag HAVE_DOT is set to YES.\n\nDOT_PATH               =\n\n# The DOTFILE_DIRS tag can be used to specify one or more directories that\n# contain dot files that are included in the documentation (see the \\dotfile\n# command).\n# This tag requires that the tag HAVE_DOT is set to YES.\n\nDOTFILE_DIRS           =\n\n# You can include diagrams made with dia in doxygen documentation. Doxygen will\n# then run dia to produce the diagram and insert it in the documentation. The\n# DIA_PATH tag allows you to specify the directory where the dia binary resides.\n# If left empty dia is assumed to be found in the default search path.\n\nDIA_PATH               =\n\n# The DIAFILE_DIRS tag can be used to specify one or more directories that\n# contain dia files that are included in the documentation (see the \\diafile\n# command).\n\nDIAFILE_DIRS           =\n\n# When using plantuml, the PLANTUML_JAR_PATH tag should be used to specify the\n# path where java can find the plantuml.jar file or to the filename of jar file\n# to be used. If left blank, it is assumed PlantUML is not used or called during\n# a preprocessing step. Doxygen will generate a warning when it encounters a\n# \\startuml command in this case and will not generate output for the diagram.\n\nPLANTUML_JAR_PATH      =\n\n# When using plantuml, the PLANTUML_CFG_FILE tag can be used to specify a\n# configuration file for plantuml.\n\nPLANTUML_CFG_FILE      =\n\n# When using plantuml, the specified paths are searched for files specified by\n# the !include statement in a plantuml block.\n\nPLANTUML_INCLUDE_PATH  =\n\n# The DOT_GRAPH_MAX_NODES tag can be used to set the maximum number of nodes\n# that will be shown in the graph. If the number of nodes in a graph becomes\n# larger than this value, doxygen will truncate the graph, which is visualized\n# by representing a node as a red box. Note that if the number of direct\n# children of the root node in a graph is already larger than\n# DOT_GRAPH_MAX_NODES then the graph will not be shown at all. Also note that\n# the size of a graph can be further restricted by MAX_DOT_GRAPH_DEPTH.\n# Minimum value: 0, maximum value: 10000, default value: 50.\n# This tag requires that the tag HAVE_DOT is set to YES.\n\nDOT_GRAPH_MAX_NODES    = 50\n\n# The MAX_DOT_GRAPH_DEPTH tag can be used to set the maximum depth of the graphs\n# generated by dot. A depth value of 3 means that only nodes reachable from the\n# root by following a path via at most 3 edges will be shown. Nodes that lay\n# further from the root node will be omitted. Note that setting this option to 1\n# or 2 may greatly reduce the computation time needed for large code bases. Also\n# note that the size of a graph can be further restricted by\n# DOT_GRAPH_MAX_NODES. Using a depth of 0 means no depth restriction.\n# Minimum value: 0, maximum value: 1000, default value: 0.\n# This tag requires that the tag HAVE_DOT is set to YES.\n\nMAX_DOT_GRAPH_DEPTH    = 0\n\n# Set the DOT_MULTI_TARGETS tag to YES to allow dot to generate multiple output\n# files in one run (i.e. multiple -o and -T options on the command line). This\n# makes dot run faster, but since only newer versions of dot (>1.8.10) support\n# this, this feature is disabled by default.\n# The default value is: NO.\n# This tag requires that the tag HAVE_DOT is set to YES.\n\nDOT_MULTI_TARGETS      = NO\n\n# If the GENERATE_LEGEND tag is set to YES doxygen will generate a legend page\n# explaining the meaning of the various boxes and arrows in the dot generated\n# graphs.\n# Note: This tag requires that UML_LOOK isn't set, i.e. the doxygen internal\n# graphical representation for inheritance and collaboration diagrams is used.\n# The default value is: YES.\n# This tag requires that the tag HAVE_DOT is set to YES.\n\nGENERATE_LEGEND        = YES\n\n# If the DOT_CLEANUP tag is set to YES, doxygen will remove the intermediate\n# files that are used to generate the various graphs.\n#\n# Note: This setting is not only used for dot files but also for msc temporary\n# files.\n# The default value is: YES.\n\nDOT_CLEANUP            = YES\n\n# You can define message sequence charts within doxygen comments using the \\msc\n# command. If the MSCGEN_TOOL tag is left empty (the default), then doxygen will\n# use a built-in version of mscgen tool to produce the charts. Alternatively,\n# the MSCGEN_TOOL tag can also specify the name an external tool. For instance,\n# specifying prog as the value, doxygen will call the tool as prog -T\n# <outfile_format> -o <outputfile> <inputfile>. The external tool should support\n# output file formats \"png\", \"eps\", \"svg\", and \"ismap\".\n\nMSCGEN_TOOL            =\n\n# The MSCFILE_DIRS tag can be used to specify one or more directories that\n# contain msc files that are included in the documentation (see the \\mscfile\n# command).\n\nMSCFILE_DIRS           =\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 4.7216796875,
          "content": "NUM_JOBS=$(shell nproc)\nCXX=clang++\n\n.PHONY: default examples/hello_world/build/hello_world tests libgpu debug build check-clang clean-build clean all watch-tests docs\n\nGPUCPP ?= $(PWD)\nLIBDIR ?= $(GPUCPP)/third_party/lib\nLIBSPEC ?= . $(GPUCPP)/source\nINCLUDES ?= -I$(GPUCPP) -I$(GPUCPP)/third_party/headers\nifeq ($(shell $(CXX) -std=c++17 -x c++ -E -include array - < /dev/null > /dev/null 2>&1 ; echo $$?),0)\n    STDLIB :=\nelse\n    STDLIB := -stdlib=libc++\nendif\n\ndefault: examples/hello_world/build/hello_world\n\npch:\n\tmkdir -p build && $(CXX) -std=c++17 $(INCLUDES) -x c++-header gpu.hpp -o build/gpu.hpp.pch\n\n# TODO(avh): change extension based on platform\nlib:\n\tmkdir -p build && $(CXX) -std=c++17 $(INCLUDES) -L$(LIBDIR) -ldawn -ldl -shared -fPIC gpu.cpp -o build/libgpucpp.dylib\n\nexamples/hello_world/build/hello_world: check-clang dawnlib examples/hello_world/run.cpp check-linux-vulkan\n\t$(LIBSPEC) && cd examples/hello_world && make build/hello_world && ./build/hello_world\n\ndawnlib: $(if $(wildcard third_party/lib/libdawn.so third_party/lib/libdawn.dylib),,run_setup)\n\nrun_setup: check-python\n\tpython3 setup.py\n\nall: dawnlib check-clang check-linux-vulkan lib pch\n\tcd examples/float16 && make build/float16\n\tcd examples/gpu_puzzles && make build/gpu_puzzles\n\tcd examples/hello_world && make build/hello_world\n\tcd examples/matmul && make build/matmul\n\tcd examples/physics && make build/physics\n\tcd examples/render && make build/render\n\tcd examples/shadertui && make build/shadertui\n\tcd examples/transpose && make build/transpose\n\n# Test 16-bit floating point type\ntest-half: dawnlib check-clang\n\t$(LIBSPEC) && clang++ -std=c++17 $(INCLUDES) numeric_types/half.cpp -L$(LIBDIR) -ldawn -ldl -o build/half && ./build/half\n\ndocs: Doxyfile\n\tdoxygen Doxyfile\n\n################################################################################\n# cmake targets (optional - precompiled binaries is preferred)\n################################################################################\n\nCMAKE_CMD = mkdir -p build && cd build && cmake ..\n# Add --trace to see the cmake commands\nFLAGS = -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON -DCMAKE_CXX_COMPILER=$(CXX) -DABSL_INTERNAL_AT_LEAST_CXX20=OFF\nFASTBUILD_FLAGS = $(FLAGS) -DFASTBUILD:BOOL=ON\nDEBUG_FLAGS = $(FLAGS) -DDEBUG:BOOL=ON\nRELEASE_FLAGS = $(FLAGS) -DFASTBUILD:BOOL=OFF\nTARGET_LIB=gpu\n\nlibgpu-cmake: check-clang check-cmake\n\t$(CMAKE_CMD) $(RELEASE_FLAGS) && make -j$(NUM_JOBS) gpu\n\ndebug-cmake: check-clang check-cmake\n\t$(CMAKE_CMD) $(DEBUG_FLAGS) && make -j$(NUM_JOBS) $(TARGET_ALL)\n\nall-cmake: check-clang check-cmake\n\t$(CMAKE_CMD) $(RELEASE_FLAGS) && make -j$(NUM_JOBS) $(TARGET_ALL)\n\n################################################################################\n# Cleanup\n################################################################################\n\nclean-dawnlib:\n\trm -f third_party/lib/libdawn.so third_party/lib/libdawn.dylib\n\nclean:\n\tread -r -p \"This will delete the contents of build/*. Are you sure? [CTRL-C to abort] \" response && rm -rf build/*\n\trm -rf examples/float16/build/*\n\trm -rf examples/gpu_puzzles/build/*\n\trm -rf examples/hello_world/build/*\n\trm -rf examples/matmul/build/matmul\n\trm -rf examples/physics/build/*\n\trm -rf examples/render/build/*\n\trm -rf examples/shadertui/build/*\n\trm -rf examples/transpose/build/transpose\n\trm -f build/gpu.hpp.pch\n\trm -f build/libgpucpp.so\n\trm -f build/half\n\nclean-all:\n\tread -r -p \"This will delete the contents of build/* and third_party/*. Are you sure? [CTRL-C to abort] \" response && rm -rf build/* third_party/fetchcontent/* third_party/gpu-build third_party/gpu-subbuild third_party/gpu-src third_party/lib/libdawn.so third_party/lib/libdawn.dylib\n\n################################################################################\n# Checks\n################################################################################\n\n# check for the existence of clang++ and cmake\ncheck-clang:\n\t@command -v clang++ >/dev/null 2>&1 || { echo >&2 \"Please install clang++ with 'sudo apt-get install clang' or 'brew install llvm'\"; exit 1; }\n\ncheck-cmake:\n\t@command -v cmake >/dev/null 2>&1 || { echo >&2 \"Please install cmake with 'sudo apt-get install cmake' or 'brew install cmake'\"; exit 1; }\n\ncheck-python:\n\t@command -v python3 >/dev/null 2>&1 || { echo >&2 \"Python needs to be installed and in your path.\"; exit 1; } \n\ncheck-linux-vulkan:\n\t@echo \"Checking system type and Vulkan availability...\"\n\t@if [ \"$$(uname)\" = \"Linux\" ]; then \\\n\t    if command -v vulkaninfo >/dev/null 2>&1; then \\\n\t        echo \"Vulkan is installed.\"; \\\n\t        vulkaninfo; \\\n\t    else \\\n\t\techo \"Vulkan is not installed. Please install Vulkan drivers to continue. On Debian / Ubuntu: sudo apt install libvulkan1 mesa-vulkan-drivers vulkan-tools\"; \\\n\t        exit 1; \\\n\t    fi \\\n\telse \\\n\t    echo \"Non-Linux system detected. Skipping Vulkan check.\"; \\\n\tfi\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 22.4765625,
          "content": "# gpu.cpp\n\ngpu.cpp is a lightweight library that makes portable GPU compute with C++ simple.\n\nIt focuses on general purpose native GPU computation, leveraging the WebGPU\nspecification as a portable low-level GPU interface. This means we can drop in\nGPU code in C++ projects and have it run on Nvidia, Intel, AMD, and other GPUs.\nThe same C++ code can work on a wide variety of laptops, workstations, mobile\ndevices or virtually any hardware with Vulkan, Metal, or DirectX support.\n\n## Technical Objectives: Lightweight, Fast Iteration, and Low Boilerplate\n\nWith gpu.cpp we want to enable a high-leverage library for individual developers and researchers to incorporate GPU computation into programs relying on nothing more than a standard C++ compiler as tooling. Our goals are:\n\n- High power-to-weight ratio API: Provide the smallest API surface area that can cover the full range of GPU compute needs.\n- Fast compile/run cycles: Ensure projects can build nearly instantaneously, compile/run cycles should be <5 seconds on a modern laptop.\n- Minimal dependencies and tooling overhead: A standard clang C++ compiler should be enough, no external library dependencies beyond the WebGPU native implementation.\n\nThe implementation aims for a small API surface area with minimum boilerplate. There are a small number of library operations to carry out an broad range of low-level GPU operations. We avoid abstractions that add layers of indirection, making the mapping between the gpu.cpp library to raw WebGPU API clear when it's needed.\n\nIn this spirit of fast experimentation, we also want near-instantaneous C++ builds taking no more than a second or two even on modestly capable personal computing devices. With this in mind, we not only keep the API surface area small, but also keep the implementation small and we also provide a prebuilt binary of the Dawn native WebGPU implementation.\n\nThe core library implementation in the header-only `gpu.hpp` source code is around 1000 lines of code. In addition to enabling instantaneous, semi-interactive compilation cycles, the small implementation surface area keeps maintenance burden low and the velocity of improvements high.\nWe also pre-build Google's Dawn WebGPU implementation as a shared library binary. This allows builds to link the shared library with each build and incorporate Google's powerful native WebGPU implementation without paying the cost of re-compiling Dawn during development cycles.\n\nFor more advanced users and release deployments, we include `cmake` examples for building both Dawn with gpu.cpp end-to-end, but this is not required nor recommended for most users to get started.\n\n## Quick Start: Building and Running\n\nTo build a gpu.cpp project, you will need to have installed on your system:\n\n- `clang++` compiler installed with support for C++17.\n- `python3` and above, to run the script which downloads the Dawn shared library.\n- `make` to build the project.\n- Only on Linux systems - Vulkan drivers. If Vulkan is not installed, you can run `sudo apt install libvulkan1 mesa-vulkan-drivers vulkan-tools` to install them.\n\nThe only library dependency of gpu.cpp is a WebGPU implementation. Currently we support the Dawn native backend, but we plan to support other targets and WebGPU implementations (web browsers or other native implementations such as wgpu). Currently we support MacOS, Linux, and Windows (via WSL).\n\nOptionally, Dawn can be built from scratch with gpu.cpp using the cmake build scripts provided - see the -cmake targets in the Makefile. However, this is recommended for advanced users only. Building Dawn dependencies with cmake takes much longer than using the precompiled Dawn shared library.\n\nAfter cloning the repo, from the top-level gpu.cpp, you should be able to build and run the hello world GELU example by typing:\n\n```\nmake\n```\n\nThe first time you build and run the project this way, it will download a prebuilt shared library for the Dawn native WebGPU implementation automatically (using the setup.py script). This places the Dawn shared library in the `third_party/lib` directory. Afterwards you should see `libdawn.dylib` on MacOS or `libdawn.so` on Linux. This download only occurs once.\n\nThe build process itself should take a few seconds. If the build and executions is successful, you should see the output of the GELU computation:\n\n```\nHello gpu.cpp!\n--------------\n\n  gelu(0.00) = 0.00\n  gelu(0.10) = 0.05\n  gelu(0.20) = 0.12\n  gelu(0.30) = 0.19\n  gelu(0.40) = 0.26\n  gelu(0.50) = 0.35\n  gelu(0.60) = 0.44\n  gelu(0.70) = 0.53\n  gelu(0.80) = 0.63\n  gelu(0.90) = 0.73\n  gelu(1.00) = 0.84\n  gelu(1.10) = 0.95\n  ...\n\nComputed 10000 values of GELU(x)\n```\n\nIf you need to clean up the build artifacts, you can run:\n\n```\nmake clean\n```\n\n## Hello World Tutorial: A GELU Kernel\n\nAs a real-world example for how to use gpu.cpp, let's start with a practical-but-simple example of a GPU kernel from neural networks.\n\nGELU is a non-linear embarassingly parallel operation often used in modern large language model transformer-based architectures.\n\nIt takes as input a vector of floats and applies the GELU function to each element of the vector. The function is nonlinear, attenuating values below zero to near zero, approximating the y = x identity function for large positive values. For values close to zero, GELU smoothly interpolates between the identity function and the zero function.\n\nThe GELU code below will illustrate the three main aspects of setting up a GPU computation with gpu.cpp:\n\n1. The code that runs on the GPU (in WebGPU Shading Language, or WGSL), implementing the compute operation.\n\n2. The code that runs on the CPU (in C++) that sets up the GPU computation by allocating and preparing resources. For high performance, this code should be run ahead-of-time from the hot paths of the application.\n\n3. The code that runs on the CPU (in C++) that dispatches the GPU computation and retrieves the results. The key concern of hot-path dispatch code is to eliminate or minimize any unnecessary resource allocation or data movement (offloading such concerns to step 2). A secondary consideration is that GPU dispatches are asynchronous. We work with standard C++ asynchronous primitives to manage the asynchronous aspect of kernel dispatch.\n\nHere's a GELU kernel implemented (based on the CUDA implementation in [llm.c](https://github.com/karpathy/llm.c)) as on-device WebGPU WGSL code and invoked from the host using gpu.cpp library functions and types. It can be compiled using a standard C++ compiler (we recommend Clang):\n\n```cpp\n#include <array>\n#include <cstdio>\n#include <future>\n\n#include \"gpu.hpp\"\n\nusing namespace gpu; // createContext, createTensor, createKernel,\n                     // dispatchKernel, wait, toCPU Bindings,\n                     // Tensor, Kernel, Context, Shape, kf32\n\nstatic const char *kGelu = R\"(\nconst GELU_SCALING_FACTOR: f32 = 0.7978845608028654; // sqrt(2.0 / PI)\n@group(0) @binding(0) var<storage, read_write> inp: array<{{precision}}>;\n@group(0) @binding(1) var<storage, read_write> out: array<{{precision}}>;\n@compute @workgroup_size({{workgroupSize}})\nfn main(\n    @builtin(global_invocation_id) GlobalInvocationID: vec3<u32>) {\n    let i: u32 = GlobalInvocationID.x;\n    if (i < arrayLength(&inp)) {\n        let x: f32 = inp[i];\n        out[i] = select(0.5 * x * (1.0 + tanh(GELU_SCALING_FACTOR\n                 * (x + .044715 * x * x * x))), x, x > 10.0);\n    }\n}\n)\";\n\nint main(int argc, char **argv) {\n  Context ctx = createContext();\n  static constexpr size_t N = 10000;\n  std::array<float, N> inputArr, outputArr;\n  for (int i = 0; i < N; ++i) {\n    inputArr[i] = static_cast<float>(i) / 10.0; // dummy input data\n  }\n  Tensor input = createTensor(ctx, Shape{N}, kf32, inputArr.data());\n  Tensor output = createTensor(ctx, Shape{N}, kf32);\n  std::promise<void> promise;\n  std::future<void> future = promise.get_future();\n  Kernel op = createKernel(ctx, {kGelu, /* 1-D workgroup size */ 256, kf32},\n                           Bindings{input, output},\n                           /* number of workgroups */ {cdiv(N, 256), 1, 1});\n  dispatchKernel(ctx, op, promise);\n  wait(ctx, future);\n  toCPU(ctx, output, outputArr.data(), sizeof(outputArr));\n  for (int i = 0; i < 16; ++i) {\n    printf(\"  gelu(%.2f) = %.2f\\n\", inputArr[i], outputArr[i]);\n  }\n  return 0;\n}\n```\n\nHere we see the GPU code is quoted in a domain specific language called WGSL (WebGPU Shading Language). In a larger project, you might store this code in a separate file to be loaded at runtime (see [examples/shadertui](https://github.com/AnswerDotAI/gpu.cpp/tree/main/examples/shadertui) for a demonstration of live WGSL code re-loading).\n\nThe CPU code in main() sets up the host coordination for the GPU computation.\nWe can think of the use of gpu.cpp library as a collection of GPU nouns and\nverbs.\n\nThe \"nouns\" are GPU resources modeled by the type definitions of the library\nand the \"verbs\" actions on GPU resources, modeled by the functions of the\nlibrary. The ahead-of-time resource acquisition functions are prefaced with\n`create*`, such as:\n\n- `createContext()` - constructs a reference to the GPU device context (`Context`).\n- `createTensor()` - acquires a contiguous buffer on the GPU (`Tensor`).\n- `createKernel()` - constructs a handle to resources for the GPU computation (`Kernel`), taking the shader code as input and the tensor resources to bind.\n\nThese resource acquisition functions are tied to resource types for interacting with the GPU:\n\n- `Context` - a handle to the state of resources for interacting with the GPU device.\n- `Tensor` - a buffer of data on the GPU.\n- `KernelCode` - the code for a WGSL program that can be dispatched to the\n  GPU. This is a thin wrapper around a WGSL string and also includes the\n  workgroup size the code is designed to run with.\n- `Kernel` - a GPU program that can be dispatched to the GPU. This accepts a\n  `KernelCode` and a list of `Tensor` resources to bind for the dispatch\n  computation. This takes an argument `Bindings` that is a list of `Tensor` instances and should map the bindings declared at the top of the WGSL code. In this example there's two bindings corresponding to the `input` buffer on the GPU and the `ouptut` buffer on the GPU.\n\nIn this example, the GELU computation is performed only once and the program immediately exits so preparing resources and dispatch are side-by-side. Other examples in the [examples/](https://github.com/AnswerDotAI/gpu.cpp/blob/main/examples/) directory illustrate how resource acquisition is prepared ahead of time and dispatch occurs in the hot path like a render, model inference, or simulation loop.\n\nBesides the `create*` resource acquisition functions, there are a few more \"verbs\" in the gpu.cpp library for handling dispatching execution to the GPU and data movement:\n\n- `dispatchKernel()` - dispatches a `Kernel` to the GPU for computation. This is an asynchronous operation that returns immediately.\n- `wait()` - blocks until the GPU computation is complete. This is a standard C++ future/promise pattern.\n- `toCPU()` - moves data from the GPU to the CPU. This is a synchronous operation that blocks until the data is copied.\n- `toGPU()` - moves data from the CPU to the GPU. This is a synchronous operation that blocks until the data is copied. In this particular example, `toGPU()` is not used because there's only one data movement from CPU to GPU in the program and that happens when the `createTensor()` function is called.\n\nThis example is available in [examples/hello_world/run.cpp](https://github.com/AnswerDotAI/gpu.cpp/blob/main/examples/hello_world/run.cpp).\n\n## Other Examples: Matrix Multiplication, Physics Sim, and SDF Rendering\n\nYou can explore the example projects in\n[examples/](https://github.com/AnswerDotAI/gpu.cpp/blob/main/examples/) which\nillustrate how to use gpu.cpp as a library.\n\nAfter you have run `make` in the top-level directory which retrieves the prebuilt Dawn shared library, you can run each example by navigating to its directory and running `make` from the example's directory.\n\nAn example of tiled matrix multiplication is in [examples/matmul](https://github.com/AnswerDotAI/gpu.cpp/blob/main/examples/matmul/). This implements a WebGPU version of the first few kernels of Simon Boehm's [How to Optimize a CUDA Matmul Kernel for cuBLAS-like Performance: a Worklog](https://siboehm.com/articles/22/CUDA-MMM) post. It currently runs at ~ 2.5+ TFLOPs on a Macbook Pro M1 Max laptop, which has a theoretical peak of 10.4 TFLOPs. Contributions to optimize this further are welcome.\n\nA parallel physics simulation of an ensemble of double pendulums simulated in parallel with different initial conditions on the GPU is shown in [examples/physics](https://github.com/AnswerDotAI/gpu.cpp/tree/main/examples/physics).\n\n<div align=\"center\">\n<img src=\"docs/images/matmul.png\" alt=\"matmul example output\" width=40%>\n<img src=\"docs/images/pendulum.gif\" alt=\"physics example animated gif\" width=42%>\n</div>\n\nWe also show some examples of signed distance function computations, rendered in the terminal as ascii. A 3D SDF of spheres is shown in [examples/render](https://github.com/AnswerDotAI/gpu.cpp/tree/main/examples/render]) and a shadertoy-like live-reloading example is in [examples/shadertui](https://github.com/AnswerDotAI/gpu.cpp/tree/main/examples/shadertui).\n\nInterestingly, given a starting example, LLMs such as Claude 3.5 Sonnet can be quite capable at writing low-level WGSL code for you - the other shaders in the shadertui example are written by the LLM.\n\n<div align=\"center\">\n  <img src=\"docs/images/shadertui.gif\" alt=\"shadertui example animated gif\" width=88%>\n</div>\n\n## Who is gpu.cpp for?\n\ngpu.cpp is aimed at enabling projects requiring portable on-device GPU computation with minimal implementation complexity and friction. Some example use cases are:\n\n- Development of GPU algorithms to be run on personal computing devices\n- Direct standalone implementations of neural network models\n- Physics simulations and simulation environments\n- Multimodal applications - audio and video processing\n- Offline graphics rendering\n- ML inference engines and runtimes\n- Parallel compute intensive data processing applications\n\nAlthough gpu.cpp is meant for any general purpose GPU computation and not strictly AI, one area we're interested in is pushing the limits exploring the intersection of new algorithms for post-training and on-device compute.\n\nTo date, AI research has primarily been built with CUDA as the privileged first-class target. CUDA has been dominant at large scale training and inference but at the other end of the the spectrum in the world of GPU compute on personal devices, there exists far more heterogeneity in the hardware and software stack.\n\nGPU compute in this personal device ecosystem has been largely limited to a small group of experts such as game engine developers and engineers working directly on ML compilers or inference runtimes. Along with that, implementing against the Vulkan or even WebGPU API directly tends to be targeted mostly towards infrastructure scale efforts - game engines, production ML inference engines, large software packages.\n\nWe want to make it easier for a broader range of projects to harness the power of GPUs on personal devices. With a small amount of code, we can access the GPU at a low-level, focusing on directly implementing algorithms rather than the scaffolding and tech stack around the GPU. For example, in our AI research there's much to explore with the various forms of dynamic/conditional post-training computation - dynamic use of adapters, sparsity, model compression, realtime multimodal integrations etc.\n\ngpu.cpp lets us implement and drop-in any algorithm with fine-grained control of data movement and GPU code, and explore outside boundaries of what is supported by existing production-oriented inference runtimes. At the same time we can write code that is portable and immediately usable on a wide variety of and GPU vendors and compute form factors - workstations, laptops, mobile, or even emerging hardware platforms such as AR/VR and robotics.\n\n## What gpu.cpp is not\n\ngpu.cpp is meant for developers with some familiarity with C++ and GPU programming. It is not a high-level numerical computing or machine learning framework or inference engine, though it can be used in support of such implementations.\n\nSecond, in spite of the name, WebGPU has native implementations decoupled from the web and the browser. gpu.cpp leverages WebGPU as a portable _native_ GPU API first and foremost, with the possibility of running in the browser being a convenient additional benefit in the future.\n\nIf you find it counterintuitive, as many do, that WebGPU is a native technology and not just for the web, watch Elie Michel's excellent talk [\"WebGPU is Not Just About the Web\"](https://www.youtube.com/watch?v=qHrx41aOTUQ).\n\nFinally, the focus of gpu.cpp is general-purpose GPU computation rather than rendering/graphics on the GPU, although it can be useful for offline rendering or video processing use cases. We may explore directions with graphics in the future, but for now our focus is GPU compute.\n\n## Limitations and Upcoming Features\n\n_API Improvements_ - gpu.cpp is a work-in-progress and there are many features and improvements to come. At this early stage, we expect the API design to evolve as we identify improvements / needs from use cases. In particular, the handling of structured parameters and asynchronous dispatch will undergo refinement and maturation in the short-term.\n\n_Browser Targets_ - In spite of using WebGPU we haven't tested builds targeting the browser yet though this is a short-term priority.\n\n_Reusable Kernel Library_ - Currently the core library is strictly the operations and types for interfacing with the WebGPU API, with some specific use case example WGSL implementations in `examples/`. Over time, as kernel implementations mature we may migrate some of the reusable operations from specific examples into a small reusable kernel library.\n\n_More Use Case Examples and Tests_ - Expect an iteration loop of use cases to design tweaks and improvements, which in turn make the use cases cleaner and easier to write. One short term use cases to flesh out the kernels from [llm.c](https://github.com/karpathy/llm.c) in WebGPU form. As these mature into a reusable kernel library, we hope to help realize the potential for WebGPU compute in AI.\n\n## Troubleshooting\n\nIf you run into issues building the project, please open an issue.\n\n## Acknowledgements\n\ngpu.cpp makes use of:\n\n- [Dawn](https://dawn.googlesource.com/dawn) as the WebGPU implementation\n- [webgpu-dawn-binaries](https://github.com/jspanchu/webgpu-dawn-binaries) by\n  @jspanchu to build a binary artifact of Dawn.\n- [webgpu-distribution](https://github.com/eliemichel/WebGPU-distribution) by\n  @eliemichel for cmake builds.\n\nThanks also to fellow colleagues at Answer.AI team for their support, testing help, and feedback.\n\n## Discord Community and Contributing\n\nJoin our community in the `#gpu-cpp` channel on the [AnswerDotAI Discord with this invite link](https://discord.gg/zmJVhXsC7f). Feel free to get in touch via X [@austinvhuang](https://twitter.com/austinvhuang) as well.\n\nFeedback, issues and pull requests are welcome.\n\n## Code Guidelines for Contributors\n\nFor contributors, here are general rules of thumb regarding the design and\nstyle of the gpu.cpp library:\n\nAesthetics - Maximize Leverage and Account for Sources of Friction:\n\n- In addition to performance, time-to-grok the codebase, compilation time,\n  number of failure modes for builds are things worth optimizing for.\n- Increase the implementation surface area only when there's a clear goal\n  behind doing so. This maximizes leverage per unit effort, increases\n  optionality in how the library can be used, and keeps compile times low.\n- Taking inspiration from the time-tested horizontal extensibility\n  of neural network libraries like PyTorch, to a first approximation the library\n  architecture could be described as a bag of composable functions.\n- Design choices general attempt to blend the composability of functional\n  programming with the performance awareness of data oriented design.\n\nOverloads and Templates:\n\n- Prefer value-level types over type-level templates, especially for core\n  implementation code. It's easy to add a more typesafe templated wrapper\n  around a value type core implementation. Whereas moving templated core\n  implementations from comptime to runtime leads to a more significant\n  refactor.\n- For comptime polymorphism, prefer trivial function overloads over templates.\n  Besides compile time benefits, this reasoning about which version of a\n  function is being called becomes explicit and scanable in the codebase.\n\nAvoid Encapsulation and Methods:\n\n- To build systems effectively, we need to construct them out of subsystems for\n  which the behavior is known and thereby composable and predictable.\n  Therefore, we prefer transparency and avoid encapsulation. Don't use abstract\n  classes as interface specifications, the library and its function signatures\n  is the interface.\n- Use struct as a default over class unless there's a clear reason otherwise.\n- Instead of methods, pass the \"owning object\" object as a reference to a\n  function. In general this convention can perform any operation that a method\n  can, but with more flexibility and less coupling. Using mutating functions\n  generalizes more cleanly to operations that have side effects on more than\n  one parameter, whereas methods priveledge the the owning class, treating the\n  single variable case as a special case and making it harder to generalize to\n  multiple parameters.\n- Methods are usually only used for constructor/destructor/operator priveledged\n  cases.\n- For operations requesting GPU resources and more complex initialization, use\n  factory functions following the `create[X]` convention - createTensor,\n  createKernel, createContext etc.\n- Use (as-trivial-as-possible) constructors for simple supporting types (mostly\n  providing metadata for a dispatch) Shape, KernelCode, etc.\n\nOwnership:\n\n- Prefer stack allocation for ownership, use unique_ptr for ownership when the\n  heap is needed. Use raw pointers only for non-owning views. Avoid shared_ptr\n  unless there's a clear rationale for shared ownership.\n- Use pools as a single point of control to manage sets of resources. Consider\n  incorporating a pool in Context if the resource is universal enough to the\n  overall API.\n\nSeparating Resource Acquisition from Hot Paths:\n\n- In general, resource acquisition should be done ahead of time from the hot\n  paths of the application. This is to ensure that the hot paths are as fast as\n  possible and don't have to deal with resource allocation or data movement.\n- Operations in the API should be implemented with a use in mind - typically\n  either ahead-of-time resource preparation/acquisition, hot-paths, or\n  non-critical testing/observability code.\n"
        },
        {
          "name": "README_cn.md",
          "type": "blob",
          "size": 19.9345703125,
          "content": "# gpu.cpp\n\ngpu.cpp是轻量级的C++库，可以简化调用便携式GPU进行计算的流程。\n\n它专注于通用原生GPU计算，并利用WebGPU规范作为便携式低级GPU接口。\n这意味着我们可以在C++项目中加入GPU代码，并使其在Nvidia, Intel, AMD和其它品牌的GPU上运行。\n并且同样的C++代码可以在各种笔记本电脑、工作站、移动设备和几乎任何支持 Vulkan、Metal 或 DirectX 的硬件上运行。\n\n## 技术目标：轻量级、快速迭代和低样板\n\n借助gpu.cpp，我们希望为个人开发人员和研究人员提供一个高附加值的库，使他们能够将gpu计算整合到只依赖标准C++编译器作为工具的程序中。我们的目标是：\n\n- 高效的API：提供最小的、可以满足所有GPU计算需求的API。\n- 快速的编译/运行周期：确保项目几乎可以即时构建，在现代笔记本电脑上编译/运行周期应 < 5秒。\n- 最小的依赖项和工具开销：一个标准的 clang C++ 编译器就足够了，除了 WebGPU 原生实现之外，没有外部库依赖项。\n\n该项目的目标是以最少的样板实现较小的 API。通过少量的库操作执行广泛的低级 GPU 操作。我们避免了添加间接层的抽象，从而在需要时明确了 gpu.cpp 库与原始 WebGPU API 之间的映射。\n\n本着这种快速实现的精神，我们还希望即使在性能一般的个人计算设备上，也能达到一两秒左右的近乎即时的 C++ 构建。考虑到这一点，我们不仅保持较小的 API，而且保持较小的实现，并且我们还提供了 Dawn 原生 WebGPU 实现的预构建二进制文件。\n\n单头文件源代码`gpu.hpp`中的核心库实现大约有 1000 行代码。除了支持即时、半交互式的编译周期外，较小的实现还保持了较低的维护负担和较高的改进速度。 \n我们还将 Google 的 Dawn WebGPU 实现预构建为共享库二进制文件。这允许将共享库与每个构建链接起来，并整合 Google 强大的原生 WebGPU 实现，而无需在开发周期中支付重新编译 Dawn 的成本。\n\n对于更高级的用户和发布部署操作，我们提供了使用 gpu.cpp 端到端构建 Dawn 的示例`cmake`，但对于大多数用户来说，这不是必需的，也不建议这样做。\n\n## 快速入门：构建和运行\n\n要构建 gpu.cpp 项目，您需要在系统上安装：\n\n- `clang++` 支持 C++17的clang++编译器。\n- `python3` Python3 或更高版本，用于运行下载 Dawn 共享库的脚本。\n- `make` 用于构建项目。\n- 仅在 Linux 系统上需要 - Vulkan 驱动程序 。如果未安装 Vulkan，您可以运行`sudo apt install libvulkan1 mesa-vulkan-drivers vulkan-tools`来安装它们。\n\ngpu.cpp 的唯一库依赖项是 WebGPU。目前我们支持 Dawn 原生后端，但我们计划支持其他目标和 WebGPU 实现（Web 浏览器或其他原生实现，例如 wgpu）。目前，我们支持 MacOS、Linux 和 Windows（通过 WSL）。\n\n或者，可以使用 gpu.cpp 提供的 cmake 构建脚本使用从头开始构建 Dawn - 请参阅 Makefile 中的 -cmake 目标。但是，仅建议高级用户使用。使用 cmake 构建 Dawn 依赖项比使用预编译的 Dawn 共享库花费的时间要长得多。\n\n克隆该存储库后，您应该能够从 gpu.cpp 根目录构建并运行hello world GELU 示例，方法是在终端输入:\n\n```\nmake\n```\n\n首次以这种方式构建和运行项目时，它将自动（使用 setup.py 脚本）下载 Dawn 原生 WebGPU 实现的预构建共享库。这会将 Dawn 共享库放置在`third_party/lib`目录中。之后您应该在  MacOS 操作系统上看到`libdawn.dylib` 或  Linux 操作系统上看到`libdawn.so`。此下载仅发生一次。\n\n构建过程本身应该需要几秒钟。如果构建和执行成功，您应该会看到 GELU 计算的输出：\n\n```\nHello gpu.cpp!\n--------------\n\n  gelu(0.00) = 0.00\n  gelu(0.10) = 0.05\n  gelu(0.20) = 0.12\n  gelu(0.30) = 0.19\n  gelu(0.40) = 0.26\n  gelu(0.50) = 0.35\n  gelu(0.60) = 0.44\n  gelu(0.70) = 0.53\n  gelu(0.80) = 0.63\n  gelu(0.90) = 0.73\n  gelu(1.00) = 0.84\n  gelu(1.10) = 0.95\n  ...\n\nComputed 10000 values of GELU(x)\n```\n\n如果需要清理构建产物，可以运行：\n\n```\nmake clean\n```\n\n## Hello World 教程：GELU 内核\n\n作为如何使用 gpu.cpp 的真实示例，让我们从一个实用但简单的神经网络 GPU 内核示例开始。\n\nGELU是一种非线性并行操作，通常用于基于 transformer 架构的现代大语言模型中。\n\n它采用浮点数向量作为输入，并将 GELU 函数应用于向量的每个元素。该函数是非线性的，将小于零的值衰减到接近零的值，对于较大的正值，近似于 y = x 恒等函数。对于接近零的值，GELU 会在恒等函数和 zero 函数之间平滑插值。\n\n下面的 GELU 代码将说明使用 gpu.cpp 驱动 GPU 计算的三个主要方面：\n\n1. 在 GPU（使用 WebGPU 着色语言或 WGSL）上运行的代码，用于实现计算操作。\n\n2. 在 CPU 上运行的代码（使用 C++），通过分配和准备资源来设置 GPU 计算。为了获得高性能，因在应用程序的 Hot paths（即你的程序中那些会频繁执行到的代码） 之前运行此代码。\n\n3. 在 CPU 上运行的代码（使用 C++），用于调度 GPU 计算并检索结果。该部分代码的主要关注点是消除或最小化任何不必要的资源分配或数据移动（将此类关注点转移到第 2 步）。第二个考虑因素是 GPU 调度是异步的。我们使用标准 C++ 异步基元来管理内核调度的异步方面。\n\n这是一个 GELU 内核（基于 [llm.c](https://github.com/karpathy/llm.c) 中的 CUDA 实现）作为设备上的 WebGPU WGSL 代码实现，并使用 gpu.cpp 库函数和类型。它可以使用标准 C++ 编译器（我们推荐 Clang）进行编译：\n\n```cpp\n#include <array>\n#include <cstdio>\n#include <future>\n\n#include \"gpu.h\"\n\nusing namespace gpu; // createContext, createTensor, createKernel,\n                     // dispatchKernel, wait, toCPU Bindings,\n                     // Tensor, Kernel, Context, Shape, kf32\n\nstatic const char *kGelu = R\"(\nconst GELU_SCALING_FACTOR: f32 = 0.7978845608028654; // sqrt(2.0 / PI)\n@group(0) @binding(0) var<storage, read_write> inp: array<{{precision}}>;\n@group(0) @binding(1) var<storage, read_write> out: array<{{precision}}>;\n@compute @workgroup_size({{workgroupSize}})\nfn main(\n    @builtin(global_invocation_id) GlobalInvocationID: vec3<u32>) {\n    let i: u32 = GlobalInvocationID.x;\n    if (i < arrayLength(&inp)) {\n        let x: f32 = inp[i];\n        out[i] = select(0.5 * x * (1.0 + tanh(GELU_SCALING_FACTOR\n                 * (x + .044715 * x * x * x))), x, x > 10.0);\n    }\n}\n)\";\n\nint main(int argc, char **argv) {\n  Context ctx = createContext();\n  static constexpr size_t N = 10000;\n  std::array<float, N> inputArr, outputArr;\n  for (int i = 0; i < N; ++i) {\n    inputArr[i] = static_cast<float>(i) / 10.0; // dummy input data\n  }\n  Tensor input = createTensor(ctx, Shape{N}, kf32, inputArr.data());\n  Tensor output = createTensor(ctx, Shape{N}, kf32);\n  std::promise<void> promise;\n  std::future<void> future = promise.get_future();\n  Kernel op = createKernel(ctx, {kGelu, /* 1-D workgroup size */ 256, kf32},\n                           Bindings{input, output},\n                           /* number of workgroups */ {cdiv(N, 256), 1, 1});\n  dispatchKernel(ctx, op, promise);\n  wait(ctx, future);\n  toCPU(ctx, output, outputArr.data(), sizeof(outputArr));\n  for (int i = 0; i < 16; ++i) {\n    printf(\"  gelu(%.2f) = %.2f\\n\", inputArr[i], outputArr[i]);\n  }\n  return 0;\n}\n```\n\n在这里，我们看到 GPU 代码以一种称为 WGSL（WebGPU 着色语言）的特定领域的语言被引用。在较大的项目中，您可以将此代码存储在一个单独的文件中，以便在运行时加载（有关实时 WGSL 代码重新加载的演示，请参阅 [examples/shadertui](https://github.com/AnswerDotAI/gpu.cpp/tree/main/examples/shadertui)）。\n\nmain()函数中的 CPU 代码为 GPU 计算设置主机协调。 \n我们可以将对 gpu.cpp 库的使用视为gpu名词和动词的集合。\n\n“GPU名词”是由库中的类型定义建模的GPU资源而“GPU动词”是 GPU 资源上的由库中的函数定义的 操作。提前资源获取函数以`create*`开头，例如：\n\n- `createContext()` - 构造对 GPU 设备上下文的引用 （`Context`）。\n- `createTensor()` - 在 GPU 上获取连续缓冲区 （`Tensor`）。\n- `createKernel()` - 构造 GPU 计算资源的句柄 （`Kernel`），将着色器代码作为输入，并将 Tensor 资源绑定。\n\n这些资源获取功能与用于与GPU交互的资源类型相关联：\n\n- `Context` - 用于与 GPU 设备交互的资源状态的句柄。\n- `Tensor` - GPU 上的数据缓冲区。\n- `KernelCode` - 可以分派到 GPU 的 WGSL 程序的代码。这是一个围绕 WGSL 字符串的精简包装，还包括被设计用于运行的代码的工作组大小。\n- `Kernel` - 可以分派给 GPU 的 GPU 程序。它接受一个 `KernelCode` 和一个 `Tensor` 资源列表来绑定调度计算。这需要一个参数`Bindings` ，它是一个 `Tensor` 实例的列表，应该映射在WGSL代码顶部声明的绑定。在这个例子中，有两个绑定对应于GPU上的 `input` 缓冲区和GPU上的 `ouptut` 缓冲区。\n\n在此示例中，GELU 计算仅执行一次，之后程序立即退出，因此准备资源和分派是并行的。[examples/](https://github.com/AnswerDotAI/gpu.cpp/blob/main/examples/) 目录中的其他示例说明如何提前准备资源获取，以及如何在Hot paths中进行调度，如渲染、模型推理或仿真循环。\n\n除了资源获取`create*`函数之外，gpu.cpp 库中还有一些 “动词” 用于处理 GPU 的调度执行和数据移动：\n\n- `dispatchKernel()` - 将一个 `Kernel` 分派给 GPU 进行计算。这是一个立即返回的异步操作。\n- `wait()` - 阻塞到 GPU 计算完成。这是一个标准的 C++ future/promise 模式。\n- `toCPU()` - 将数据从 GPU 移动到 CPU。这是一个同步操作，在复制数据完成之前会阻塞。\n- `toGPU()` - 将数据从 CPU 移动到 GPU。这是一个同步操作，在复制数据完成之前会阻塞。在这个特定示例中，`toGPU()`没有使用 ，因为程序中只有一个从 CPU 到 GPU 的数据移动，并且发生在调用函数`createTensor()`时。\n\n此示例位于 [examples/hello_world/run.cpp](https://github.com/AnswerDotAI/gpu.cpp/blob/main/examples/hello_world/run.cpp)中。\n\n## 其他示例：矩阵乘法、物理模拟和 SDF 渲染\n\n您可以在[examples/](https://github.com/AnswerDotAI/gpu.cpp/blob/main/examples/)中探索示例项目，这些示例说明了如何使用gpu.cpp库。\n\n在项目根目录中运行 `make`获取预构建的 Dawn 共享库后，您可以切换到示例目录并在示例的目录下运行 `make`来运行每个示例。\n\n平铺矩阵乘法的一个示例在 [examples/matmul](https://github.com/AnswerDotAI/gpu.cpp/blob/main/examples/matmul/) 中。这实现了 Simon Boehm 的 [How to Optimize a CUDA Matmul Kernel for cuBLAS-like Performance: a Worklog](https://siboehm.com/articles/22/CUDA-MMM)帖子的前几个内核的 WebGPU 版本。它目前在 Macbook Pro M1 Max 笔记本电脑上的运行速度为 ~ 2.5+ TFLOPs，理论峰值为 10.4 TFLOPs。欢迎为进一步优化这一点做出贡献。\n\n[examples/physics](https://github.com/AnswerDotAI/gpu.cpp/tree/main/examples/physics)中显示了在 GPU 上以不同初始条件并行模拟的双摆系综的并行物理模拟。\n\n<div align=\"center\">\n<img src=\"docs/images/matmul.png\" alt=\"matmul example output\" width=40%>\n<img src=\"docs/images/pendulum.gif\" alt=\"physics example animated gif\" width=42%>\n</div>\n\n我们还展示了一些有符号距离函数计算的示例，在终端中以ascii字符呈现。球体的 3D SDF 的示例在 [examples/render](https://github.com/AnswerDotAI/gpu.cpp/tree/main/examples/render]) 中，类似 shadertoy 的实时重新加载示例显示在 [examples/shadertui](https://github.com/AnswerDotAI/gpu.cpp/tree/main/examples/shadertui) 中。\n\n有趣的是，给定一个起始示例，诸如 Claude 3.5 Sonnet 之类的 LLM 可以非常有力的为您编写低级 WGSL 代码 - shadertui 示例中的其他着色器就是由 LLM 编写的。\n\n<div align=\"center\">\n  <img src=\"docs/images/shadertui.gif\" alt=\"shadertui example animated gif\" width=88%>\n</div>\n\n## gpu.cpp 适合哪些人？\n\ngpu.cpp 旨在支持需要便携式设备 GPU 计算的项目，同时将其实现复杂性和开发阻力降至最低。一些示例用例包括：\n\n- 开发可在个人计算设备上运行的 GPU 算法\n- 神经网络模型的直接独立实现\n- 物理模拟和环境模拟\n- 多模态应用程序 - 音频和视频处理\n- 离线图形渲染\n- ML 推理引擎和运行时间\n- 并行计算密集型数据处理应用程序\n\n尽管 gpu.cpp 适用于任何通用 GPU 计算，而不是仅适用于 AI，但我们感兴趣的一个领域是突破极限，探索用于后训练和设备计算的新算法的交叉点。\n\n迄今为止，AI 研究主要是以CUDA为基础而建立的。CUDA 在大规模训练和推理中一直占据主导地位，但在另一端的个人设备上的 GPU 计算领域，硬件和软件中存在更多的异质性。\n\n在个人设备生态系统中，GPU 计算在很大程度上仅限于一小群专家，例如游戏引擎开发人员和直接使用 ML 编译器或推理运行时的工程师。除此之外，针对 Vulkan 甚至 WebGPU API 的直接开发往往主要针对基础设施的工作 - 游戏引擎、生产 ML 推理引擎、大型软件包。\n\n我们希望让更广泛的项目能够更轻松地在个人设备上利用 GPU 的强大功能。只需少量代码，我们就可以在底层访问 GPU，专注于直接实现算法，而不是围绕 GPU 的脚手架和技术堆栈。例如，在我们的 AI 研究中，各种形式的动态/条件训练后计算有很多值得探索的地方——适配器的动态使用、稀疏性、模型压缩、实时多模态集成等等。\n\ngpu.cpp 使我们能够通过对数据移动和 GPU 代码的精细控制来实现和插入任何算法，并探索现有面向生产的推理运行时所支持的边界之外。同时，我们可以编写可移植的代码，并立即在各种 GPU 和计算设备上使用 - 工作站、笔记本电脑、移动设备，甚至是 AR/VR 和机器人等新兴硬件平台。\n\n## gpu.cpp 不是什么\n\ngpu.cpp 适用于对 C++ 和 GPU 编程有一定了解的开发人员。它不是高级数值计算或机器学习框架或推理引擎，尽管它可以用于支持此类实现。\n\n其次，尽管名称如此，但 WebGPU 具有与 Web 和浏览器解耦的原生实现。gpu.cpp主要利用 WebGPU 作为可移植的本地 gpu API，在浏览器中运行的可能性是未来的一个方便的额外的好处。\n\n如果您和许多人一样觉得 “WebGPU 是一种原生技术，而不仅仅是用于 Web” 是违反直觉，请观看 Elie Michel 的精彩演讲[\"WebGPU is Not Just About the Web\"](https://www.youtube.com/watch?v=qHrx41aOTUQ)。\n\n最后，gpu.cpp 的重点是通用 GPU 计算，而不是在 GPU 上进行渲染/图形计算，尽管它对于离线渲染或视频处理可能很有用。我们将来可能会探索图形计算的发展方向，但目前我们的重点是 GPU 计算。\n\n## 限制和即将推出的功能\n\n_API 改进_ - gpu.cpp 是一项正在进行的工作，即将推出许多功能和改进。在这个早期阶段，我们预计 API 设计会随着我们的用例的需求而确定改进并发展。特别是，结构化参数的处理和异步调度将在短期内进行改进和成熟。\n\n_浏览器目标_ - 尽管使用了 WebGPU，但我们还没有测试针对浏览器的构建，尽管这是一个短期的优先事项。\n\n_可重用内核库_ - 目前的核心库严格来说是接入 WebGPU API 接口的操作和类型的集合，在`examples/`中有一些特定的示例 WGSL 实现。随着时间的推移，随着内核实现的成熟，我们可能会将特定示例中的一些可重用操作迁移到一个小型的可重用内核库中。\n\n_更多示例和测试_ - 期待用例的迭代循环会被设计调整和改进，这反过来又使用例更简洁、更易于编写。一个短期用例，以 WebGPU 形式从[llm.c](https://github.com/karpathy/llm.c)中充实内核。随着这些内核库逐渐成熟为可重用的内核库，我们希望帮助实现 WebGPU 计算在 AI 中的潜力。\n\n## 故障排除\n\n如果您在构建项目时遇到问题，请发起一个 issue。\n\n## 致谢\n\ngpu.cpp 使用：\n\n- [Dawn](https://dawn.googlesource.com/dawn) 作为 WebGPU 实现\n- [webgpu-dawn-binaries](https://github.com/jspanchu/webgpu-dawn-binaries) 由 @jspanchu构建的 Dawn 的二进制共享库。\n- [webgpu-distribution](https://github.com/eliemichel/WebGPU-distribution) @eliemichel的项目，用于 cmake 构建。\n\n还要感谢 Answer.AI 团队的同事们的支持、测试帮助和反馈。\n\n## Discord 社区和贡献\n\n通过此邀请链接加入我们的[AnswerDotAI Discord](https://discord.gg/zmJVhXsC7f)。也请随时通过 X [@austinvhuang](https://twitter.com/austinvhuang) 与我们联系。\n\n欢迎提供反馈、问题和拉取请求。\n\n## 贡献者代码准则\n\n对于代码贡献者，以下是关于 gpu.cpp 库的设计和风格的一般规则：\n\n美学 - 最大化效率并考虑开发阻力：\n\n- 除了性能之外，检索代码库的时间、编译时间、构建的故障模式数量也是值得优化的。\n- 只有在有明确目标的情况下，才能增加对外的API。这可以最大限度地提高单位工作量的利用率，增加库使用方式的可选性，并保持较低的编译时间。\n- 从久经考验的可扩展的神经网络库中（如 PyTorch）汲取灵感。首先，库架构应被描述为一组可组合的函数。\n- 设计时尽量选择将函数式编程的可组合性与面向数据设计的性能意识相结合。\n\n重载和模板：\n\n- 与类型级模板相比，首选值级，特别是对于核心实现代码。在值类型核心实现周围添加一个更类型安全的模板包装器很容易。而将模板化的核心实现从编译时转移到运行时会导致更困难的重构。\n- 对于 comptime 多态性，首选简单的函数重载而不是模板。 除了编译时的好处外，关于调用哪个版本的函数的推理在代码库中变得明确且可扫描。\n\n避免封装和方法：\n\n- 为了有效地构建系统，我们需要从行为已知的子系统中构建它们，从而使其具有可组合性和可预测性。 因此，我们更喜欢一目了然的编程规范，避免封装。不要使用抽象类作为接口规范，库及其函数签名就是接口。\n- 使用 struct 而不是 class ，除非有明确的原因。\n- 将“所属对象”作为函数的引用传递，而不是方法。一般来说，这种约定可以执行方法可以执行的任何操作，且具有更大的灵活性和更少的耦合性。使用原地修改函数可以更清晰地推广到对多个参数有作用的操作，而方法则为所属类提供了特权，将单变量情况视为特例，使推广到多个参数变得更加困难。\n- 方法通常仅用于构造函数/析构函数/运算符私有的情况。\n- 对于请求 GPU 资源和更复杂的初始化的操作，请使用遵循`create[X]` 约定的工厂函数-createTensor、createKernel、createContext等。\n- 使用（尽可能简单）构造函数来支持简单的类型（主要是为分派提供元数据）Shape、KernelCode等。\n\n所有权：\n\n- 更推荐使用栈分配变量内存，当需要堆时，请使用unique_ptr。仅对非拥有视图使用原始指针。避免shared_ptr，除非有明确的共享所有权理由。\n- 使用池作为单一控制点来管理资源集。如果资源对于整个API足够通用，请考虑在Context中合并池。\n\n将资源获取与Hot paths分开：\n\n- 一般来说，因在应用程序的Hot paths前进行资源获取。这是为了确保Hot paths 尽可能快，不必处理资源分配或数据移动。\n- 调用 API 来实现所需功能前应考虑用途 - 通常包括提前准备/获取资源、Hot paths 或非关键测试/可观察性代码。"
        },
        {
          "name": "cmake",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "experimental",
          "type": "tree",
          "content": null
        },
        {
          "name": "gpu.cpp",
          "type": "blob",
          "size": 0.0185546875,
          "content": "#include \"gpu.hpp\"\n"
        },
        {
          "name": "gpu.hpp",
          "type": "blob",
          "size": 50.087890625,
          "content": "#ifndef GPU_HPP\n#define GPU_HPP\n\n#include <array>\n#include <cassert>\n#include <cstring>\n#include <future>\n#include <initializer_list>\n#include <memory>\n#include <set>\n#include <string>\n#include <tuple>\n#include <type_traits>\n#include <unordered_map>\n#include <utility> // std::pair\n#include <vector>\n\n#include \"webgpu/webgpu.h\"\n\n#include \"numeric_types/half.hpp\"\n#include \"utils/logging.hpp\"\n\n#ifdef __EMSCRIPTEN__\n#include \"emscripten/emscripten.h\"\n#endif\n\n#ifdef USE_DAWN_API\n#include \"dawn/native/DawnNative.h\"\n\ntypedef WGPUBufferUsage WGPUBufferUsageFlags;\n#endif\n\nnamespace gpu {\n\n/**\n * @brief Represents a buffer of values on the GPU.\n */\nstruct Array {\n  WGPUBuffer buffer;\n  WGPUBufferUsageFlags usage;\n  size_t size; // in bytes\n};\n\n/**\n * @brief Represents the shape of a tensor.\n *\n * The rank of the tensor is the\n * number of dimensions in the shape. The data array stores the size of each\n * dimension. For now, we limit the rank to 8 to avoid dynamic allocation.\n *\n * @code\n * Shape shape = {256, 256};\n * @endcode\n */\nstruct Shape {\n  static constexpr size_t kMaxRank = 8; // Maximum rank of a tensor, avoids\n                                        // dynamic allocation for shape data\n  std::array<size_t, kMaxRank> data = {0};\n  size_t rank = 0;\n  inline Shape() = default;\n  inline Shape(std::initializer_list<size_t> dims) {\n    assert(dims.size() <= kMaxRank);\n    std::copy(dims.begin(), dims.end(), data.begin());\n    rank = dims.size();\n  }\n  inline size_t &operator[](size_t index) {\n    assert(index < rank);\n    return data[index];\n  }\n  inline const size_t &operator[](size_t index) const {\n    assert(index < rank);\n    return data[index];\n  }\n};\n\n/**\n * @brief Returns the number of elements in a tensor with the given shape,\n * which is equal to the product of the dimensions.\n * @param[in] shape Shape of the tensor\n * @return Number of elements in the tensor\n *\n * @code\n * size({256, 256}) -> 65536\n * @endcode\n */\ninline size_t size(const Shape &shape) {\n  size_t numels = 1;\n  for (size_t i = 0; i < shape.rank; i++) {\n    numels *= shape.data[i];\n  }\n  return numels;\n}\n\n/**\n * @brief Represents a tensor on the GPU, which is a buffer of values with a\n * shape.\n *\n * @code\n * Tensor tensor = createTensor(ctx, {256, 256}, kf32);\n * @endcode\n */\nstruct Tensor {\n  Array data;\n  Shape shape;\n};\n\n/**\n * @brief Represents a non-owning view into a tensor specifying an offset and a\n * subspan. This is useful for specifying a slice of a tensor on the GPU\n * without copying the data.\n *\n * @code\n * TensorView view = {tensor, 0, 256};\n * @endcode\n */\nstruct TensorView {\n  Tensor data; // non-owning view\n  size_t offset = 0;\n  size_t span = 0;\n};\n\n/**\n * @brief Represents an ordered collection of WGPUBuffers (wrapped as tensors,\n * non-overlapping views, or arrays) for the purpose of binding them to a\n * kernel operation to make them accessible to the GPU kernel.\n *\n * The ordering of the bindings should match the binding indices in the WGSL\n * code.\n */\ntemplate <std::size_t N> struct Bindings {\n  std::array<Tensor, N> data;\n  std::array<size_t, N> viewOffsets;\n  std::array<size_t, N> viewSpans;\n  Bindings(const std::initializer_list<Tensor> &init) {\n    std::copy(begin(init), end(init), begin(data));\n    std::fill(begin(viewOffsets), end(viewOffsets), 0);\n    for (size_t i = 0; i < N; ++i) {\n      viewSpans[i] = data[i].data.size;\n    }\n  }\n\n  Bindings(const std::array<Tensor, N> &init) {\n    std::copy(begin(init), end(init), begin(data));\n    std::fill(begin(viewOffsets), end(viewOffsets), 0);\n    for (size_t i = 0; i < N; ++i) {\n      viewSpans[i] = data[i].data.size;\n    }\n  }\n\n  Bindings(const std::initializer_list<TensorView> &init) {\n    size_t i = 0;\n    for (const auto &tv : init) {\n      data[i] = tv.data;\n      viewOffsets[i] = tv.offset;\n      viewSpans[i] = tv.span;\n      ++i;\n    }\n  }\n\n  Bindings(const std::initializer_list<Array> &init) {\n    std::copy(begin(init), end(init), begin(data));\n    std::fill(begin(viewOffsets), end(viewOffsets), 0);\n    for (size_t i = 0; i < N; ++i) {\n      viewSpans[i] = data[i].size;\n    }\n  }\n\n  Tensor &operator[](std::size_t index) { return data[index]; }\n  const Tensor &operator[](std::size_t index) const { return data[index]; }\n};\n\n/**\n * @brief Deduction guide for Bindings\n */\ntemplate <std::size_t N> Bindings(std::array<Tensor, N>) -> Bindings<N>;\ntemplate <typename... Args> Bindings(Args...) -> Bindings<sizeof...(Args)>;\n\nstruct Context; // Forward declaration so that TensorPool can have a pointer to\n                // Context\n\n/**\n * @brief Represents a pool of tensors to manage GPU resources. The pool is\n * responsible for managing the lifetime of the tensors and freeing them when\n * the pool is destroyed.\n *\n * Most users do not need to interact with the TensorPool type, as there is a\n * member instance in the Context struct to simplify lifetime management of GPU\n * resources.\n */\nstruct TensorPool {\n  inline TensorPool(Context *ctx) : ctx(ctx), data() {};\n  Context *ctx;\n  std::unordered_map<WGPUBuffer, Tensor> data;\n  ~TensorPool();\n};\n\nenum NumType {\n  kf16, // (experimental)\n  kf32,\n  ki32\n};\n\n/**\n * @brief Returns the number of bytes of a number type.\n */\ninline size_t sizeBytes(const NumType &type) {\n  switch (type) {\n  case kf16:\n    return sizeof(uint16_t);\n  case kf32:\n    return sizeof(float);\n  case ki32:\n    return sizeof(int32_t);\n  default:\n    LOG(kDefLog, kError, \"Invalid NumType in size calculation.\");\n    return 0;\n  }\n}\n\n/**\n * @brief Converts NumType to string.\n */\ninline std::string toString(NumType type) {\n  switch (type) {\n  case kf16:\n    return \"f16\";\n  case kf32:\n    return \"f32\";\n  case ki32:\n    return \"i32\";\n  default:\n    LOG(kDefLog, kError, \"Invalid NumType in string conversion.\");\n    return \"unknown\";\n  }\n}\n\n/**\n * @brief Converts Shape to string. The string formatting is meant to be\n * slotted into WGSL code (hence no additional parentheses or brackets).\n */\ninline std::string toString(const Shape &shape) {\n  std::string str;\n  for (size_t i = 0; i < shape.rank; i++) {\n    str += std::to_string(shape.data[i]);\n    if (i < shape.rank - 1) {\n      str += \", \";\n    }\n  }\n  return str;\n}\n\n/**\n * @brief Converts size_t to string. Wraps std::to_string for consistency,\n * instead of having to remember to switch between std::to_string and toString\n * depending on the type.\n */\ninline std::string toString(size_t value) { return std::to_string(value); }\n\n/**\n * @brief simple in-place string replacement helper function for substituting\n * placeholders in a WGSL string template.\n *\n * Note this is not meant to be used in performance-critical code paths and\n * should be used ahead-of-time before any performance-critical codepath to\n * preprocess WGSL code strings.\n *\n * @param[in] str String to mutate with substitution replacements.\n * @param[in] from Substring to replace\n * @param[in] to Substring to replace with\n *\n * @code\n * replaceAll(str, \"{{workgroupSize}}\", \"256\");\n * @endcode\n */\ninline void replaceAll(std::string &str, const std::string &from,\n                       const std::string &to) {\n  size_t start_pos = 0;\n  while ((start_pos = str.find(from, start_pos)) != std::string::npos) {\n    str.replace(start_pos, from.length(), to);\n    start_pos += to.length();\n  }\n}\n\n/**\n * @brief KernelCode is the representation of WGSL GPU code with template\n * substitutions applied. It is a type around the code string with additional\n * metadata for workgroup size and precision since they are specified in the\n * WGSL code. Additionally, label and entryPoint are used by `createKernel()`\n * to specify the label and entry point of the kernel.\n */\nstruct KernelCode {\n  /**\n   * @brief Constructor to create a code object from a template\n   * string and optional workgroup size and precision.\n   *\n   * @param[in] pData Shader template string with placeholders\n   * @param[in] workgroupSize Shape of the workgroup. Unlike tensor shapes which\n   * can be of arbitrary rank, workgroup size is always of rank 3 corresponding\n   * to x y and z. workgroupSize is stored as a field in the KernelCode instance\n   * that is returned by createShader().\n   * @param[in] precision Data type precision to be substituted for\n   * {{precision}} in the WGSL code. As with workgroupSize, precision is stored\n   * as a field in the KernelCode instance that is returned by createShader().\n   * @code\n   * KernelCode code = {kShaderText, {256, 1, 1}, kf32};\n   * @endcode\n   */\n  inline KernelCode(const std::string &pData = \"\", size_t workgroupSize = 256,\n                    NumType precision = kf32)\n      : data(pData), workgroupSize({workgroupSize, 1, 1}),\n        precision(precision) {\n    if (precision == kf16) {\n      data = \"enable f16;\\n\" + data;\n    }\n    replaceAll(data, \"{{workgroupSize}}\", toString({workgroupSize, 1, 1}));\n    replaceAll(data, \"{{precision}}\", toString(precision));\n    LOG(kDefLog, kTrace, \"Shader code:\\n%s\", data.c_str());\n  }\n\n  /**\n   * @brief Overload of the constructor to create a code object from a template\n   * string and workgroup size. This overload takes a single size_t\n   * workgroupSize parameter instead of a 3D shape for the workgroup size and\n   * instantiates a 3D shape with the workgroupSize in the x dimension and 1 in\n   * the y and z dimensions.\n   *\n   * @param[in] pData Shader template string with placeholders @param[in]\n   * workgroupSize 3D Workgroup size \n   * @param[in] precision Data type precision for the shader\n   *\n   * @code KernelCode code = {kPuzzle1, 256, kf32}; @endcode\n   */\n  inline KernelCode(const std::string &pData, const Shape &workgroupSize =\n      {256, 1, 1}, NumType precision = kf32) : data(pData),\n  workgroupSize(workgroupSize), precision(precision) { if (precision == kf16) {\n    data = \"enable f16;\\n\" + data; } replaceAll(data, \"{{workgroupSize}}\",\n        toString(workgroupSize)); replaceAll(data, \"{{precision}}\",\n        toString(precision)); LOG(kDefLog, kInfo, \"Shader code:\\n%s\",\n        data.c_str()); }\n\n\n  /**\n   * @brief Overload of the constructor, adding totalWorkgroups parameter to\n   * perform a string replacement for the total number of workgroups in the\n   * kernel code.\n   *\n   * @param[in] pData Shader template string with placeholders\n   * @param[in] workgroupSize 3D Workgroup size\n   * @param[in] precision Data type precision for the shader\n   * @param[in] totalWorkgroups Total number of workgroups in the kernel\n   *\n   * @code\n   * KernelCode code = {kPuzzle1, {256, 1, 1}, kf32, {2, 2, 1}};\n   * @endcode\n   */\n  inline KernelCode(const std::string &pData,\n                    const Shape &workgroupSize,\n                    NumType precision,\n                    const Shape &totalWorkgroups)\n      : data(pData), workgroupSize(workgroupSize), precision(precision) {\n    if (precision == kf16) {\n      data = \"enable f16;\\n\" + data;\n    }\n    replaceAll(data, \"{{workgroupSize}}\", toString(workgroupSize));\n    replaceAll(data, \"{{precision}}\", toString(precision));\n    replaceAll(data, \"{{totalWorkgroups}}\", toString(totalWorkgroups));\n    LOG(kDefLog, kInfo, \"Shader code:\\n%s\", data.c_str());\n  }\n\n\n  /**\n   * @brief Overload of the constructor, adding totalWorkgroups parameter as\n   * well as the size_t 1D workgroupSize parameter.\n   *\n   * @param[in] pData Shader template string with placeholders\n   * @param[in] workgroupSize Workgroup size in the x dimension\n   * @param[in] precision Data type precision for the shader\n   * @param[in] totalWorkgroups Total number of workgroups in the kernel\n   *\n   * @code\n   * KernelCode code = {kPuzzle1, {256, 1, 1}, kf32, {2, 2, 1}};\n   * @endcode\n   */\n  inline KernelCode(const std::string &pData,\n                    const size_t &workgroupSize,\n                    NumType precision,\n                    const Shape &totalWorkgroups)\n      : data(pData), workgroupSize({workgroupSize, 1, 1}), precision(precision) {\n    if (precision == kf16) {\n      data = \"enable f16;\\n\" + data;\n    }\n    replaceAll(data, \"{{workgroupSize}}\", toString({workgroupSize, 1, 1}));\n    replaceAll(data, \"{{precision}}\", toString(precision));\n    replaceAll(data, \"{{totalWorkgroups}}\", toString(totalWorkgroups));\n    LOG(kDefLog, kInfo, \"Shader code:\\n%s\", data.c_str());\n  }\n\n  std::string data;\n  Shape workgroupSize;\n  NumType precision = kf32;\n  std::string label = \"kernel\";\n  std::string entryPoint = \"main\";\n};\n\n/**\n * @brief Overload of the string replacement helper function to replace\n * multiple substrings in a string with multiple replacements.\n *\n * @param[in] str String to mutate with substitution replacements.\n * @param[in] reps Vector of pairs of substrings to replace and their\n * replacements.\n *\n * @code\n * replaceAll(str, {{\"{{workgroupSize}}\", \"256\"}, {\"{{precision}}\",\n * @endcode\n * \"f32\"}});\n */\ninline void\nreplaceAll(std::string &str,\n           const std::vector<std::pair<std::string, std::string>> &reps) {\n  for (const auto &rep : reps) {\n    replaceAll(str, rep.first, rep.second);\n  }\n}\n\n/**\n * @brief Used for on-done callback data for asynchronous operations sduch as\n * kernel launching.\n */\nstruct CallbackData {\n  WGPUBuffer buffer; // managed by owning Kernel\n  size_t bufferSize;\n  void *output; // non-owning, only for target memory in toCPU, not used for\n                // kernel invocations\n  std::promise<void> *promise;\n  std::future<void> *future;\n};\n\n/**\n * @brief Staging buffer and callback data for copying data between the GPU and\n * CPU.\n */\nstruct CopyData {\n  WGPUCommandBuffer commandBuffer;\n  WGPUBuffer readbackBuffer;\n  std::promise<void> promise;\n  std::future<void> future;\n};\n\n/**\n * @brief Represents handles + metadata for a reusable kernel on the GPU.\n * The struct members can be divided into \"consumed upon dispatch\"\n * (commandBuffer) and reusable ahead-of-time setup (all other members).\n */\nstruct Kernel {\n  std::unique_ptr<WGPUBuffer[]> buffers; // non-owning\n  std::unique_ptr<size_t[]> bufferSizes;\n  size_t numBindings;\n  Shape totalWorkgroups;\n  WGPUBindGroup bindGroup;             // persists between submission\n  WGPUComputePipeline computePipeline; // persists between submission\n  WGPUCommandBuffer commandBuffer;     // destroyed upon submission\n};\n\n\n/**\n * @brief A struct to package the result of a WGSL code compilation.\n */\nstruct CompilationInfo {\n  WGPUCompilationInfoRequestStatus status;\n  std::vector<std::string> messages;\n  std::vector<uint64_t> lineNums;\n  std::vector<uint64_t> linePos;\n  bool finished; // true if the compilation is finished\n};\n\n/**\n * @brief Operator implementation to make the Kernel type hashable.\n * @param[in] lhs First Kernel instance to compare\n * @param[in] rhs Second Kernel instance to compare\n * @return True if lhs < rhs, false otherwise\n */\ninline bool operator<(const Kernel &lhs, const Kernel &rhs) {\n  return lhs.commandBuffer < rhs.commandBuffer;\n}\n\n/**\n * @brief A pool of kernels to manage GPU resources. For simple use cases this\n * is instantiated as a member in the Context struct although it's possible to\n * have multiple resource pools of kernels in more complex scenarios.\n */\nstruct KernelPool {\n  inline KernelPool(Context *ctx) : ctx(ctx), data() {}\n  Context *ctx;\n  std::set<Kernel *> data;\n  inline ~KernelPool() {\n    // Note : Some kernel resources such as commandBuffer are harvested by\n    // queue submission, explicitly destroying readback and callback buffers\n    // produces runtime errors.\n    data.clear();\n  }\n};\n\ninline void processEvents(const WGPUInstance &instance) {\n#ifdef __EMSCRIPTEN__\n  emscripten_sleep(0);\n#else\n  wgpuInstanceProcessEvents(instance);\n#endif\n}\n\n/**\n * @brief Represents a GPU context, aggregates WebGPU API handles to interact\n * with the GPU including the instance, adapter, device, and queue.\n *\n * Additionally contains a TensorPool and KernelPool for managing GPU resources\n * to simplify lifetime management of GPU resources.\n */\nstruct Context {\n  WGPUInstance instance;\n  WGPUAdapter adapter;\n  WGPUDevice device;\n  WGPUQueue queue;\n  TensorPool pool = TensorPool(this);\n  KernelPool kernelPool = KernelPool(this);\n  ~Context() {\n    LOG(kDefLog, kTrace, \"Destroying context\");\n    if (queue) {\n      wgpuQueueRelease(queue);\n    } else {\n      LOG(kDefLog, kWarn, \"Queue is null\");\n    }\n    if (device) {\n      wgpuDeviceRelease(device);\n      processEvents(instance);\n    } else {\n      LOG(kDefLog, kWarn, \"Device is null\");\n    }\n    if (adapter) {\n      wgpuAdapterRelease(adapter);\n      processEvents(instance);\n    } else {\n      LOG(kDefLog, kWarn, \"Adapter is null\");\n    }\n    if (instance) {\n      wgpuInstanceRelease(instance);\n    } else {\n      LOG(kDefLog, kWarn, \"Instance is null\");\n    }\n    LOG(kDefLog, kInfo, \"Context destroyed\");\n  }\n};\n\n/**\n * @brief Tensor factory function to create a tensor (a Tensor type is simply\n * an Array with an N-dimensional  Shape specification) on the GPU. The tensor\n * is created with the given shape, data type, and usage flags, added to the\n * TensorPool, and returned.\n *\n * This is the core implementation which takes the minimal set of parameters in\n * terms of the raw WebGPU API, and is used by the other createTensor overloads\n * which provide more ergonomic interfaces.\n *\n * @param[in] pool TensorPool instance to manage the tensor\n * @param[in] device WGPUDevice instance to create the tensor on\n * @param[in] shape Shape of the tensor\n * @param[in] dtype Data type of the tensor (e.g. kf32)\n * @param[in] usage Usage flags for the tensor buffer\n * @return Tensor instance representing the created tensor\n *\n * @code\n * Tensor tensor = createTensor(pool, device, {256, 256}, kf32);\n * @endcode\n */\ninline Tensor\ncreateTensor(TensorPool &pool, WGPUDevice &device, const Shape &shape,\n             NumType dtype,\n             WGPUBufferUsageFlags usage = WGPUBufferUsage_Storage |\n                                          WGPUBufferUsage_CopyDst |\n                                          WGPUBufferUsage_CopySrc) {\n  LOG(kDefLog, kTrace, \"Creating tensor\");\n  size_t numElements = size(shape);\n  size_t size = sizeBytes(dtype) * numElements;\n  WGPUBufferDescriptor bufferDesc = {\n      .usage = usage,\n      .size = size,\n  };\n  WGPUBuffer buffer = wgpuDeviceCreateBuffer(device, &bufferDesc);\n  pool.data[buffer] = Tensor{\n      .data = Array{.buffer = buffer, .usage = usage, .size = size},\n      .shape = shape,\n  };\n  return pool.data[buffer];\n}\n\n/**\n * @brief Overload of the tensor factory function to instantiate a tensor on\n * the GPU with a given shape and data type.\n *\n * Instead of taking the TensoPool and raw WebGPU API WGPUDevice and\n * WGPUBufferUsageFlags arguments, this is a convenience wrapper around the\n * core createTensor function which has default usage flags for a storage\n * buffer, and also takes in the Context object.\n *\n * instance instead of the narrower TensorPool object.\n * @param[in] ctx Context instance to manage the tensor\n * @param[in] shape Shape of the tensor\n * @param[in] dtype Data type of the tensor (e.g. kf32)\n * @return Tensor instance representing the created tensor\n *\n * @code\n * Tensor tensor = createTensor(ctx, {256, 256}, kf32);\n * @endcode\n */\ninline Tensor createTensor(Context &ctx, const Shape &shape, NumType dtype) {\n  return createTensor(ctx.pool, ctx.device, shape, dtype);\n}\n\n/**\n * @brief Overload of the tensor factory function to instantiate a tensor on\n * the GPU with a given shape, data type. This overload also takes initial\n * float* data to populate the tensor with.\n *\n * The data is assumed to be of size equal to the product of the dimensions in\n * the shape, and is copied to the GPU buffer.\n *\n * @param[in] ctx Context instance to manage the tensor\n * @param[in] shape Shape of the tensor\n * @param[in] dtype Data type of the tensor (e.g. kf32)\n * @param[in] data Initial data to populate the tensor with\n * @return Tensor instance representing the created tensor\n *\n * @code\n * Tensor tensor = createTensor(ctx, {256, 256}, kf32, data);\n * @endcode\n */\ninline Tensor createTensor(Context &ctx, const Shape &shape, NumType dtype,\n                           const float *data) {\n  assert(dtype == kf32);\n  Tensor tensor =\n      createTensor(ctx.pool, ctx.device, shape, dtype,\n                   WGPUBufferUsage_Storage | WGPUBufferUsage_CopyDst |\n                       WGPUBufferUsage_CopySrc);\n  wgpuQueueWriteBuffer(ctx.queue, tensor.data.buffer, 0, data,\n                       tensor.data.size);\n  return tensor;\n}\n\ninline Tensor createTensor(Context &ctx, const Shape &shape, NumType dtype,\n                           const int32_t *data) {\n  assert(dtype == ki32);\n  Tensor tensor =\n      createTensor(ctx.pool, ctx.device, shape, dtype,\n                   WGPUBufferUsage_Storage | WGPUBufferUsage_CopyDst |\n                       WGPUBufferUsage_CopySrc);\n  wgpuQueueWriteBuffer(ctx.queue, tensor.data.buffer, 0, data,\n                       tensor.data.size);\n  return tensor;\n}\n\n/**\n * @brief Overload of the tensor factory function to instantiate a tensor on\n * the GPU with a given shape, data type. This overload also takes initial\n * half* data to populate the tensor with.\n *\n * The data is assumed to be of size equal to the product of the dimensions in\n * the shape, and is copied to the GPU buffer.\n *\n * @param[in] ctx Context instance to manage the tensor\n * @param[in] shape Shape of the tensor\n * @param[in] dtype Data type of the tensor (e.g. kf32)\n * @param[in] data Initial data to populate the tensor with\n * @return Tensor instance representing the created tensor\n *\n * @code\n * Tensor tensor = createTensor(ctx, {256, 256}, kf32, data);\n * @endcode\n */\ninline Tensor createTensor(Context &ctx, const Shape &shape, NumType dtype,\n                           const half *data) {\n  assert(dtype == kf16);\n  Tensor tensor =\n      createTensor(ctx.pool, ctx.device, shape, dtype,\n                   WGPUBufferUsage_Storage | WGPUBufferUsage_CopyDst |\n                       WGPUBufferUsage_CopySrc);\n  wgpuQueueWriteBuffer(ctx.queue, tensor.data.buffer, 0, data,\n                       tensor.data.size);\n  return tensor;\n}\n\n/**\n * @brief Frees a tensor resource and updates the tensor pool.\n *\n * Only needed if the use case requires manually managing resource lifetimes of\n * GPU tensors. For simple use cases, the TensorPool destructor will\n * automatically free all tensors.\n *\n * @param[in] pool TensorPool instance to manage the tensor\n * @param[in] tensor Tensor instance to free\n *\n * @code\n * FreeTensor(pool, tensor);\n * @endcode\n */\ninline void FreeTensor(TensorPool &pool, Tensor tensor) {\n  if (tensor.data.buffer) {\n    wgpuBufferRelease(tensor.data.buffer);\n  } else {\n    LOG(kDefLog, kWarn, \"Tried to free tensor with null buffer\");\n  }\n  if (pool.data.find(tensor.data.buffer) != pool.data.end()) {\n    pool.data.erase(tensor.data.buffer);\n  } else {\n    LOG(kDefLog, kWarn, \"Tried to free tensor that was not in pool\");\n  }\n}\n\n/**\n * @brief Destructor for TensorPool which frees all tensors in the pool.\n */\ninline TensorPool::~TensorPool() {\n  // Need to get keys in a separate iteration, otherwise iterator is getting\n  // invalidated during erase.\n  std::vector<WGPUBuffer> keys;\n  for (auto &pair : data) {\n    keys.push_back(pair.first);\n  }\n  for (auto &key : keys) {\n    FreeTensor(*this, data[key]);\n    LOG(kDefLog, kTrace, \"Freed tensor\");\n  }\n}\n\n/**\n * @brief Checks a condition and logs an error message if the condition is\n * false.\n * @param[in] condition The condition to check.\n * @param[in] message The error message to log if the condition is false.\n * @param[in] file The source file where the check is performed.\n * @param[in] line The line number in the source file where the check is\n * performed.\n */\ninline void check(bool condition, const char *message,\n                  const char *file = \"unkown\", int line = -1) {\n  if (!condition) {\n    LOG(kDefLog, kError, \"Error in file %s line %d:\\n%s\", file, line, message);\n  } else {\n    LOG(kDefLog, kTrace, \"Success in file %s line %d:\\n%s\", file, line,\n        message);\n  }\n}\n\n/**\n * @brief Factory function to create a GPU context, which aggregates WebGPU API\n * handles to interact with the GPU including the instance, adapter, device, and\n * queue.\n *\n * The function takes optional descriptor parameters for the instance\n * descriptor, adapter request options, and device descriptor, which are passed\n * through to the WebGPU API calls to create the instance, adapter, and device.\n *\n * If dawn is used, it also sets up an error callback for device loss.\n *\n * @param[in] desc Instance descriptor for the WebGPU instance (optional)\n * @param[in] adapterOpts Adapter request options for the WebGPU adapter\n * (optional)\n * @param[in] devDescriptor Device descriptor for the WebGPU device (optional)\n * @return Context instance representing the created GPU context\n *\n * @code\n * Context ctx = createContext();\n * @endcode\n */\ninline Context createContext(const WGPUInstanceDescriptor &desc = {},\n                             const WGPURequestAdapterOptions &adapterOpts = {},\n                             const WGPUDeviceDescriptor &devDescriptor = {}) {\n  Context context;\n  {\n#ifdef __EMSCRIPTEN__\n    // Emscripten does not support the instance descriptor\n    // and throws an assertion error if it is not nullptr.\n    context.instance = wgpuCreateInstance(nullptr);\n#else\n    context.instance = wgpuCreateInstance(&desc);\n#endif\n    check(context.instance, \"Initialize WebGPU\", __FILE__, __LINE__);\n  }\n\n  LOG(kDefLog, kInfo, \"Requesting adapter\");\n  {\n    struct AdapterData {\n      WGPUAdapter adapter = nullptr;\n      bool requestEnded = false;\n    };\n    AdapterData adapterData;\n    auto onAdapterRequestEnded = [](WGPURequestAdapterStatus status,\n                                    WGPUAdapter adapter, char const *message,\n                                    void *pUserData) {\n      AdapterData &adapterData = *reinterpret_cast<AdapterData *>(pUserData);\n#ifdef __EMSCRIPTEN__\n      if (status != WGPURequestAdapterStatus_Success) {\n        LOG(kDefLog, kError, \"Could not get WebGPU adapter: %s\", message);\n        LOG(kDefLog, kError,\n            \"\\n\\nA common reason is that the browser does not have WebGPU \"\n            \"enabled, particularly on Linux.\\n\"\n            \"- Open `chrome://flags/` in the browser and make sure \"\n            \"\\\"WebGPU Support\\\" is enabled.\\n\"\n            \"- Chrome is launched with vulkan enabled. From the command line \"\n            \"launch chrome as `google-chrome --enable-features=Vulkan`\\n\");\n      }\n#endif\n      check(status == WGPURequestAdapterStatus_Success,\n            \"Request WebGPU adapter\", __FILE__, __LINE__);\n      adapterData.adapter = adapter;\n      adapterData.requestEnded = true;\n    };\n\n    wgpuInstanceRequestAdapter(context.instance, &adapterOpts,\n                               onAdapterRequestEnded, (void *)&adapterData);\n\n    while (!adapterData.requestEnded) {\n      processEvents(context.instance);\n    }\n    assert(adapterData.requestEnded);\n    context.adapter = adapterData.adapter;\n  }\n\n  LOG(kDefLog, kInfo, \"Requesting device\");\n  {\n    struct DeviceData {\n      WGPUDevice device = nullptr;\n      bool requestEnded = false;\n    };\n    DeviceData devData;\n    auto onDeviceRequestEnded = [](WGPURequestDeviceStatus status,\n                                   WGPUDevice device, char const *message,\n                                   void *pUserData) {\n      DeviceData &devData = *reinterpret_cast<DeviceData *>(pUserData);\n      check(status == WGPURequestDeviceStatus_Success,\n            \"Could not get WebGPU device.\", __FILE__, __LINE__);\n      LOG(kDefLog, kTrace, \"Device Request succeeded %x\",\n          static_cast<void *>(device));\n      devData.device = device;\n      devData.requestEnded = true;\n    };\n    wgpuAdapterRequestDevice(context.adapter, &devDescriptor,\n                             onDeviceRequestEnded, (void *)&devData);\n    LOG(kDefLog, kInfo, \"Waiting for device request to end\");\n    while (!devData.requestEnded) {\n      processEvents(context.instance);\n    }\n    LOG(kDefLog, kInfo, \"Device request ended\");\n    assert(devData.requestEnded);\n    context.device = devData.device;\n    wgpuDeviceSetUncapturedErrorCallback(\n        context.device,\n        [](WGPUErrorType type, char const *message, void *devData) {\n          LOG(kDefLog, kError, \"Device uncaptured error: %s\", message);\n          throw std::runtime_error(\"Device uncaptured exception.\");\n        },\n        nullptr);\n  }\n  context.queue = wgpuDeviceGetQueue(context.device);\n  return context;\n}\n\n\n#ifdef USE_DAWN_API\n/**\n * @brief Factory function to create a GPU context, which aggregates WebGPU API\n * handles to interact with the GPU including the instance, adapter, device, and\n * queue.\n *\n * The function takes gpu index to support for multi GPUs.\n * To activate this function, it needs not only webgpu's headers but also DAWN's headers.\n *\n * If dawn is used, it also sets up an error callback for device loss.\n *\n * @param[in] gpuIdx GPU index\n * @param[in] desc Instance descriptor for the WebGPU instance (optional)\n * @param[in] devDescriptor Device descriptor for the WebGPU device (optional)\n * @return Context instance representing the created GPU context\n *\n * @code\n * Context ctx = createContextByGpuIdx(1);\n * @endcode\n */\ninline Context createContextByGpuIdx(int gpuIdx,\n\t\t\t\t     const WGPUInstanceDescriptor &desc = {},\n\t\t\t\t     const WGPUDeviceDescriptor &devDescriptor = {}) {\n  Context context;\n  {\n#ifdef __EMSCRIPTEN__\n    // Emscripten does not support the instance descriptor\n    // and throws an assertion error if it is not nullptr.\n    context.instance = wgpuCreateInstance(nullptr);\n#else\n    context.instance = wgpuCreateInstance(&desc);\n#endif\n    // check status\n    check(context.instance, \"Initialize WebGPU\", __FILE__, __LINE__);\n  }\n\n  LOG(kDefLog, kInfo, \"Requesting adapter\");\n  {\n    std::vector<dawn::native::Adapter> adapters =\n      dawn::native::Instance(reinterpret_cast<dawn::native::InstanceBase*>(context.instance))\n      .EnumerateAdapters();\n    LOG(kDefLog, kInfo, \"The number of GPUs=%d\\n\", adapters.size());\n    // Note: Second gpu is not available on Macos, but the number of GPUs is 2 on Macos.\n    //       Calling wgpuAdapterGetInfo function for the second gpu becomes segfault.\n    //       When you check all GPUs on linux, uncomment out following codes.\n    //\n    // for (size_t i = 0; i < adapters.size(); i++) {\n    //   WGPUAdapterInfo info {};\n    //   auto ptr = adapters[i].Get();\n    //   if (ptr && adapters[i]) {\n    //     wgpuAdapterGetInfo(ptr, &info);\n    //     LOG(kDefLog, kInfo, \"GPU(Adapter)[%d] = %s\\n\", i, info.description);\n    //     wgpuAdapterInfoFreeMembers(info);\n    //   } \n    // }\n\n    {\n      LOG(kDefLog, kInfo, \"Use GPU(Adapter)[%d]\\n\", gpuIdx);\n      auto ptr = adapters[gpuIdx].Get();\n      if (ptr) {\n\tWGPUAdapterInfo info {};\n\twgpuAdapterGetInfo(ptr, &info);\n\tLOG(kDefLog, kInfo, \"GPU(Adapter)[%d] = %s\\n\", gpuIdx, info.description);\n\twgpuAdapterInfoFreeMembers(info);\n      } \n      context.adapter = adapters[gpuIdx].Get();\n      dawn::native::GetProcs().adapterAddRef(context.adapter);\n    }\n  }\n\n  LOG(kDefLog, kInfo, \"Requesting device\");\n  {\n    struct DeviceData {\n      WGPUDevice device = nullptr;\n      bool requestEnded = false;\n    };\n    DeviceData devData;\n    auto onDeviceRequestEnded = [](WGPURequestDeviceStatus status,\n                                   WGPUDevice device, char const *message,\n                                   void *pUserData) {\n      DeviceData &devData = *reinterpret_cast<DeviceData *>(pUserData);\n      check(status == WGPURequestDeviceStatus_Success,\n            \"Could not get WebGPU device.\", __FILE__, __LINE__);\n      LOG(kDefLog, kTrace, \"Device Request succeeded %x\",\n          static_cast<void *>(device));\n      devData.device = device;\n      devData.requestEnded = true;\n    };\n    wgpuAdapterRequestDevice(context.adapter, &devDescriptor,\n                             onDeviceRequestEnded, (void *)&devData);\n    LOG(kDefLog, kInfo, \"Waiting for device request to end\");\n    while (!devData.requestEnded) {\n      processEvents(context.instance);\n    }\n    LOG(kDefLog, kInfo, \"Device request ended\");\n    assert(devData.requestEnded);\n    context.device = devData.device;\n    wgpuDeviceSetUncapturedErrorCallback(\n        context.device,\n        [](WGPUErrorType type, char const *message, void *devData) {\n          LOG(kDefLog, kError, \"Device uncaptured error: %s\", message);\n          throw std::runtime_error(\"Device uncaptured exception.\");\n        },\n        nullptr);\n  }\n  context.queue = wgpuDeviceGetQueue(context.device);\n  return context;\n}\n#endif\n\ninline void wait(Context &ctx, std::future<void> &future) {\n  while (future.wait_for(std::chrono::seconds(0)) !=\n         std::future_status::ready) {\n    processEvents(ctx.instance);\n  }\n}\n\n/**\n * @brief Copies data from a GPU buffer to CPU memory.\n * @param[in] ctx Context instance to manage the operation\n * @param[in] tensor Tensor instance representing the GPU buffer to copy from\n * @param[out] data Pointer to the CPU memory to copy the data to\n * @param[in] bufferSize Size of the data buffer in bytes\n * @param[in] op StagingBuffer instance to manage the operation\n *\n * @code\n * toCPU(ctx, tensor, data, bufferSize);\n * @endcode\n */\ninline void toCPU(Context &ctx, Tensor &tensor, void *data, size_t bufferSize,\n                  CopyData &op) {\n  wgpuQueueSubmit(ctx.queue, 1, &op.commandBuffer);\n  CallbackData callbackData = {op.readbackBuffer, bufferSize, data, &op.promise,\n                               &op.future};\n  wgpuQueueOnSubmittedWorkDone(\n      ctx.queue,\n      [](WGPUQueueWorkDoneStatus status, void *callbackData) {\n        check(status == WGPUQueueWorkDoneStatus_Success, \"Queue work done\",\n              __FILE__, __LINE__);\n        const auto *data = static_cast<CallbackData *>(callbackData);\n        wgpuBufferMapAsync(\n            data->buffer, WGPUMapMode_Read, 0, data->bufferSize,\n            [](WGPUBufferMapAsyncStatus status, void *captureData) {\n              const auto *data = static_cast<CallbackData *>(captureData);\n              check(status == WGPUBufferMapAsyncStatus_Success,\n                    \"Map readbackBuffer\", __FILE__, __LINE__);\n              const void *mappedData = wgpuBufferGetConstMappedRange(\n                  data->buffer, /*offset=*/0, data->bufferSize);\n              check(mappedData, \"Get mapped range\", __FILE__, __LINE__);\n              memcpy(data->output, mappedData, data->bufferSize);\n              wgpuBufferUnmap(data->buffer);\n              data->promise->set_value();\n            },\n            callbackData);\n      },\n      &callbackData);\n  wait(ctx, op.future);\n}\n\n/**\n * @brief Overload of the toCPU function to copy data from a GPU buffer to CPU\n * but initializes a staging buffer and promise/future for the operation for\n * you.\n *\n * For simple use cases, this overload is recommended as it abstracts away the\n * staging buffer and promise/future management. For more custom use cases\n * where the staging buffer is initialized ahead of time, use the other\n * overload.\n *\n * @param[in] ctx Context instance to manage the operation\n * @param[in] tensor Tensor instance representing the GPU buffer to copy from\n * @param[in] bufferSize Size of the data buffer in bytes\n * @param[out] data Pointer to the CPU memory to copy the data to\n */\ninline void toCPU(Context &ctx, Tensor &tensor, void *data, size_t bufferSize) {\n  CopyData op;\n  op.future = op.promise.get_future();\n  {\n    WGPUBufferDescriptor readbackBufferDescriptor = {\n        .usage = WGPUBufferUsage_CopyDst | WGPUBufferUsage_MapRead,\n        .size = bufferSize,\n    };\n    op.readbackBuffer =\n        wgpuDeviceCreateBuffer(ctx.device, &readbackBufferDescriptor);\n  }\n  {\n    WGPUCommandEncoder commandEncoder;\n    WGPUComputePassEncoder computePassEncoder;\n    commandEncoder = wgpuDeviceCreateCommandEncoder(ctx.device, nullptr);\n    wgpuCommandEncoderCopyBufferToBuffer(commandEncoder, tensor.data.buffer, 0,\n                                         op.readbackBuffer, 0, bufferSize);\n    op.commandBuffer = wgpuCommandEncoderFinish(commandEncoder, nullptr);\n    check(op.commandBuffer, \"Create command buffer\", __FILE__, __LINE__);\n  }\n  toCPU(ctx, tensor, data, bufferSize, op);\n}\n\n/**\n * @brief Overload of the toCPU function to copy data from a GPU buffer to CPU\n * memory for an array of floats instead of a pointer to a float buffer.\n * @param[in] ctx Context instance to manage the operation\n * @param[in] tensor Tensor instance representing the GPU buffer to copy from\n * @param[out] data Array of floats to copy the data to\n *\n * @code\n * toCPU(ctx, tensor, data);\n * @endcode\n */\ntemplate <size_t N>\nvoid toCPU(Context &ctx, Tensor &tensor, std::array<float, N> &data) {\n  toCPU(ctx, tensor, data.data(), sizeof(data));\n}\n\n/**\n * @brief Copies data from CPU memory to a GPU buffer. The toGPU overloads are\n * effectively a convenience wrapper around the WebGPU API call\n * wgpuQueueWriteBuffer.\n *\n * @param[in] ctx Context instance to manage the operation\n * @param[in] data Pointer to the CPU memory to copy from\n * @param[in] buffer WGPUBuffer instance representing the GPU buffer to copy\n * to\n * @param[in] size Size of the data buffer in bytes\n *\n * @code\n * toGPU(ctx, data, buffer, size);\n * @endcode\n */\ninline void toGPU(Context &ctx, const void *data, WGPUBuffer buffer,\n                  size_t size) {\n  wgpuQueueWriteBuffer(ctx.queue, buffer, 0, data, size);\n}\n\n/**\n * @brief Overload of the toGPU function to copy data from CPU memory to a GPU\n * taking a Tensor instance instead of a WGPUBuffer instance.\n * @param[in] ctx Context instance to manage the operation\n * @param[in] data Pointer to the CPU memory to copy from\n * @param[in] tensor Tensor instance representing the GPU buffer to copy to\n *\n * @code\n * toGPU(ctx, data, tensor);\n * @endcode\n */\ninline void toGPU(Context &ctx, const float *data, Tensor &tensor) {\n  wgpuQueueWriteBuffer(ctx.queue, tensor.data.buffer, 0, data,\n                       tensor.data.size);\n}\n\ninline void toGPU(Context &ctx, const half *data, Tensor &tensor) {\n  wgpuQueueWriteBuffer(ctx.queue, tensor.data.buffer, 0, data,\n                       tensor.data.size);\n}\n\ntemplate <typename Params>\ninline void toGPU(Context &ctx, Params &params, Kernel &op) {\n  // TODO(avh): Maintain params metadata in Kernel and check for consistency.\n  // If a kernel does not have parameters this will quietly overwrite\n  // the last buffer in the bind group with the parameters buffer.\n  if (op.numBindings > 0) {\n    wgpuQueueWriteBuffer(ctx.queue, op.buffers[op.numBindings - 1], 0,\n                         static_cast<void *>(&params), sizeof(params));\n  }\n}\n\n/**\n * @brief Resets the command buffer in preparation for a kernel dispatch.\n * Since command buffers are consumed upon submission, this function is used\n * both in the initial kernel creation and every time the kernel is to be\n * reused for a dispatch.\n * @param[in] device WGPUDevice instance to manage the operation\n * @param[in] op Kernel instance representing the kernel to reset\n *\n * @code\n * resetCommandBuffer(device, op);\n * @endcode\n */\ninline void resetCommandBuffer(WGPUDevice &device, Kernel &op) {\n  {\n    WGPUCommandEncoder commandEncoder =\n        wgpuDeviceCreateCommandEncoder(device, nullptr);\n    WGPUComputePassEncoder computePassEncoder =\n        wgpuCommandEncoderBeginComputePass(commandEncoder, nullptr);\n    wgpuComputePassEncoderSetPipeline(computePassEncoder, op.computePipeline);\n    wgpuComputePassEncoderSetBindGroup(computePassEncoder, 0, op.bindGroup, 0,\n                                       nullptr);\n    wgpuComputePassEncoderDispatchWorkgroups(\n        computePassEncoder, op.totalWorkgroups[0], op.totalWorkgroups[1],\n        op.totalWorkgroups[2]);\n    wgpuComputePassEncoderEnd(computePassEncoder);\n    op.commandBuffer = wgpuCommandEncoderFinish(commandEncoder, nullptr);\n  }\n}\n\n/**\n * @brief NoParam is a no-op type used to indicate that a kernel does not have\n * any parameters.\n */\nstruct NoParam {};\ntemplate <typename T> constexpr bool IsNoParam = std::is_same_v<T, NoParam>;\n\n/**\n * @brief Ceiling division.\n */\ninline size_t cdiv(size_t n, size_t d) { return (n + d - 1) / d; }\n\n/**\n * @brief cdiv for shape specification. Mostly useful for evenly dividing\n * total # threads by workgroup size dimensions.\n */\ninline Shape cdiv(Shape total, Shape group) {\n  assert(total.rank == group.rank);\n  Shape result;\n  result.rank = total.rank;\n  for (size_t dim = 0; dim < total.rank; ++dim) {\n    result[dim] = cdiv(total[dim], group[dim]);\n  }\n  return result;\n}\n\n/**\n * @brief A factory function to create a kernel on the GPU. The kernel is\n * created with the given WGSL code, input tensors, output tensor, and\n * optional parameters.\n *\n * Note that the values of the input tensors are not used here, only the\n * reference handles to the underlying buffers as well as the size of the\n * buffers.\n *\n * @param[in] ctx Context instance to manage the kernel\n * @param[in] code WGSL code for the kernel\n * @param[in] dataBindings Pointer to a span of tensors bound to the kernel\n * @param[in] numTensors Number of tensors in the dataBindings span\n * @param[in] viewOffsets Pointer to an array of view offsets for the input\n * tensors\n * @param[in] totalWorkgroups Shape of the workgroup\n * @param[in] params Optional parameters for the kernel. If the kernel does\n * not have any parameters, use NoParam. This is cast as void* to allow for\n * arbitrary types to be passed as parameters.\n * @param[in] paramsSize Size of the parameters buffer in bytes.\n * @return Kernel instance representing the created kernel\n *\n * @code\n * Kernel kernel = createKernel(ctx, code, dataBindings, numInputs,\n * @endcode\n * output, nThreads, params, paramsSize);\n */\ninline Kernel createKernel(Context &ctx, const KernelCode &code,\n                           const Tensor *dataBindings, size_t numTensors,\n                           const size_t *viewOffsets, const Shape &totalWorkgroups,\n                           const void *params = nullptr,\n                           size_t paramsSize = 0,\n                           CompilationInfo* compilationInfo = nullptr) {\n  assert(totalWorkgroups.rank == 3);\n  WGPUDevice device = ctx.device;\n  WGPUQueue queue = ctx.queue;\n  Kernel op;\n  // paramIndex is the index into bgLayoutEntries for the parameters buffer If\n  // there are no parameters for the kernel, paramsSize == 0 and paramIndex is\n  // effectively undefined (== -1)\n  size_t paramIndex = -1;\n  // Note: paramIndex is undefined unless paramsSize > 0\n  size_t numBindings = numTensors;\n  if (paramsSize > 0) {\n    numBindings++;                // parameters buffer\n    paramIndex = numBindings - 1; // index of the parameters buffer within\n                                  // op.buffers, op.bufferSizes and\n                                  // bgLayoutEntries\n  }\n  op.buffers = std::make_unique<WGPUBuffer[]>(numBindings);\n  op.bufferSizes = std::make_unique<size_t[]>(numBindings);\n  op.numBindings = numBindings;\n  std::vector<WGPUBindGroupLayoutEntry> bgLayoutEntries(numBindings);\n  // Create layout entries for input buffers\n  for (size_t i = 0; i < numTensors; ++i) {\n    bgLayoutEntries[i] = WGPUBindGroupLayoutEntry{\n        .binding = static_cast<uint32_t>(i),\n        .visibility = WGPUShaderStage_Compute,\n        .buffer =\n            WGPUBufferBindingLayout{\n                .type = WGPUBufferBindingType_Storage,\n                .minBindingSize = dataBindings[i].data.size,\n            },\n    };\n  }\n  if (paramsSize > 0) {\n    LOG(kDefLog, kInfo, \"Create layout entry for the params buffer\");\n    // Create layout entry for the params buffer\n    bgLayoutEntries[paramIndex] = WGPUBindGroupLayoutEntry{\n        .binding = static_cast<uint32_t>(paramIndex),\n        .visibility = WGPUShaderStage_Compute,\n        .buffer =\n            WGPUBufferBindingLayout{\n                .type = WGPUBufferBindingType_Uniform,\n                .minBindingSize = paramsSize,\n            },\n    };\n  }\n  WGPUBindGroupLayoutDescriptor bgLayoutDesc = {\n      .entryCount = static_cast<uint32_t>(bgLayoutEntries.size()),\n      .entries = bgLayoutEntries.data(),\n  };\n  WGPUBindGroupLayout bgLayout =\n      wgpuDeviceCreateBindGroupLayout(device, &bgLayoutDesc);\n  for (size_t i = 0; i < numTensors; ++i) {\n    op.buffers[i] = dataBindings[i].data.buffer;\n    op.bufferSizes[i] = dataBindings[i].data.size;\n  }\n  // Create a buffer for the Params struct\n  if (paramsSize > 0) {\n    WGPUBufferDescriptor paramsBufferDesc = {\n        .usage = WGPUBufferUsage_Uniform | WGPUBufferUsage_CopyDst,\n        .size = paramsSize,\n        .mappedAtCreation = false,\n    };\n    op.buffers[paramIndex] = wgpuDeviceCreateBuffer(device, &paramsBufferDesc);\n    op.bufferSizes[paramIndex] = paramsSize;\n    wgpuQueueWriteBuffer(queue, op.buffers[paramIndex], 0, params, paramsSize);\n    LOG(kDefLog, kTrace, \"Params buffer written\");\n  } else {\n    LOG(kDefLog, kTrace, \"No params buffer needed\");\n  }\n  std::vector<WGPUBindGroupEntry> bindGroupEntries(numBindings);\n  for (size_t i = 0; i < numTensors; ++i) {\n    bindGroupEntries[i] = WGPUBindGroupEntry{\n        .binding = static_cast<uint32_t>(i),\n        .buffer = op.buffers[i],\n        .offset = viewOffsets[i],\n        .size = op.bufferSizes[i],\n    };\n  }\n  if (paramsSize > 0) {\n    LOG(kDefLog, kInfo, \"Create bind group entry for the params buffer\");\n    LOG(kDefLog, kInfo, \"paramIndex: %d\", paramIndex);\n    bindGroupEntries[paramIndex] = WGPUBindGroupEntry{\n        .binding = static_cast<uint32_t>(paramIndex),\n        .buffer = op.buffers[paramIndex],\n        .offset = 0,\n        .size = paramsSize,\n    };\n  }\n  LOG(kDefLog, kTrace, \"BG Entries Size: %d\", numBindings);\n  WGPUBindGroupDescriptor bindGroupDesc = {\n      .layout = bgLayout,\n      .entryCount = static_cast<uint32_t>(numBindings),\n      .entries = bindGroupEntries.data(),\n  };\n  op.bindGroup = wgpuDeviceCreateBindGroup(device, &bindGroupDesc);\n\n  WGPUPipelineLayoutDescriptor pipelineLayoutDesc = {\n      .bindGroupLayoutCount = 1,\n      .bindGroupLayouts = &bgLayout,\n  };\n  WGPUPipelineLayout pipelineLayout =\n      wgpuDeviceCreatePipelineLayout(device, &pipelineLayoutDesc);\n  WGPUShaderModuleWGSLDescriptor wgslDesc = {\n      .code = code.data.c_str(),\n  };\n  wgslDesc.chain.sType = WGPUSType_ShaderModuleWGSLDescriptor;\n  WGPUShaderModuleDescriptor shaderModuleDesc = {};\n  shaderModuleDesc.nextInChain = &wgslDesc.chain;\n  shaderModuleDesc.label = code.label.c_str();\n  WGPUComputePipelineDescriptor computePipelineDesc = {};\n  computePipelineDesc.layout = pipelineLayout;\n  computePipelineDesc.compute.module =\n      wgpuDeviceCreateShaderModule(device, &shaderModuleDesc);\n\n  computePipelineDesc.compute.entryPoint = code.entryPoint.c_str();\n  computePipelineDesc.label = code.label.c_str();\n  op.computePipeline =\n      wgpuDeviceCreateComputePipeline(device, &computePipelineDesc);\n  op.totalWorkgroups = {totalWorkgroups[0], totalWorkgroups[1], totalWorkgroups[2]};\n  resetCommandBuffer(device, op);\n  ctx.kernelPool.data.insert(&op);\n\n  WGPUCompilationInfoCallback cb =\n      [](WGPUCompilationInfoRequestStatus status,\n         WGPUCompilationInfo const *compilationInfo, void *userData) {\n        CompilationInfo *result = static_cast<CompilationInfo *>(userData);\n        if (compilationInfo && result) {\n          result->status = status;\n          for (uint32_t i = 0; i < compilationInfo->messageCount; ++i) {\n            printf(\"Message %d: %s\\n\", i, compilationInfo->messages[i].message);\n            result->messages.push_back(compilationInfo->messages[i].message);\n            result->lineNums.push_back(compilationInfo->messages[i].lineNum);\n            result->linePos.push_back(compilationInfo->messages[i].linePos);\n          }\n          result->finished = true;\n        } else {\n          LOG(kDefLog, kTrace, \"No compilation info or result\");\n        }\n      };\n\n  wgpuShaderModuleGetCompilationInfo(\n      computePipelineDesc.compute.module, cb, static_cast<void *>(compilationInfo));\n\n  while (compilationInfo && !compilationInfo->finished) {\n    processEvents(ctx.instance);\n  }\n  return op;\n\n}\n\n/**\n * @brief Overload which wraps the createKernel factory function to create a\n * kernel on the GPU. This overload uses takes a static collection of input\n * tensors instead of a pointer and a statically determined ParamsType instead\n * of casting params to a void pointer.\n *\n * @param[in] ctx Context instance to manage the kernel\n * @param[in] code WGSL code for the kernel\n * @param[in] dataBindings A Bindings of tensors whose GPU buffers are bound\n * to the kernel as inputs and outputs.\n * @param[in] totalWorkgroups Number of workgroups in the x, y, z grid, must be a\n * Shape of rank == 3.\n * @param[in] params Optional parameters for the kernel. If the kernel does\n * not have any parameters, use NoParam.\n * @return Kernel instance representing the created kernel\n *\n * @code\n * Kernel kernel = createKernel(ctx, code, tensorData, output,\n * @endcode\n * totalWorkgroups, params);\n */\ntemplate <typename ParamsType = NoParam, size_t numInputs>\nKernel createKernel(Context &ctx, const KernelCode &code,\n                    const Bindings<numInputs> &dataBindings,\n                    const Shape &totalWorkgroups,\n                    const ParamsType &params = ParamsType{},\n                    CompilationInfo* compilationInfo = nullptr \n                    ) {\n  if constexpr (!IsNoParam<ParamsType>) {\n    return createKernel(ctx, code, dataBindings.data.data(), numInputs,\n                        dataBindings.viewOffsets.data(), totalWorkgroups,\n                        reinterpret_cast<const void *>(&params),\n                        sizeof(ParamsType), compilationInfo);\n  } else {\n    return createKernel(ctx, code, dataBindings.data.data(), numInputs,\n                        dataBindings.viewOffsets.data(), totalWorkgroups, nullptr,\n                        0, compilationInfo);\n  }\n}\n\n/**\n * @brief Asynchronously submits a kernel to the GPU queue for execution.\n * It also sets up a callback to notify when the kernel has finished executing\n * by setting the value of the promise in the kernel instance argument.\n *\n * dispatchKernel does *not* wait for the kernel to finish executing and\n * returns immediately. The caller can wait for the kernel to finish executing\n * by calling wait() on the future in the kernel instance.\n *\n * @param[in] ctx Context instance to manage the kernel, from which the queue\n * for the GPU is obtained\n * @param[in] kernel Kernel instance to dispatch\n * @param[in] promise Promise to set when the kernel has finished executing\n *\n * @code\n * dispatchKernel(ctx, kernel);\n * @endcode\n */\ninline void dispatchKernel(Context &ctx, Kernel &kernel,\n                           std::promise<void> &promise) {\n  // Submit the command buffer\n  wgpuQueueSubmit(ctx.queue, 1, &kernel.commandBuffer);\n  wgpuQueueOnSubmittedWorkDone(\n      ctx.queue,\n      [](WGPUQueueWorkDoneStatus status, void *data) {\n        check(status == WGPUQueueWorkDoneStatus_Success, \"Queue work done\",\n              __FILE__, __LINE__);\n        auto *promise = static_cast<std::promise<void> *>(data);\n        promise->set_value();\n      },\n      &promise);\n}\n\n} // namespace gpu\n\n#endif // GPU_H\n"
        },
        {
          "name": "numeric_types",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 3.6376953125,
          "content": "import os\nimport platform\nimport sys\nimport ssl\nimport urllib.request\nfrom pathlib import Path\n\ndef get_os_name():\n    system = platform.system()\n    if system == \"Windows\":\n        return \"Windows 64-bit\" if platform.machine().endswith('64') else \"Windows 32-bit\"\n    elif system == \"Darwin\":\n        return \"macOS\"\n    elif system == \"Linux\":\n        return \"Linux\"\n    elif system == \"FreeBSD\":\n        return \"FreeBSD\"\n    elif system.startswith(\"CYGWIN\"):\n        return \"Cygwin\"\n    else:\n        return \"Other\"\n\ndef download_file(url, output_filename):\n    total_downloaded = 0\n    total_truncated = 0 # only print download progress every 2MB to avoid spamming logs\n\n    def report_progress(block_num, block_size, total_size):\n        nonlocal total_downloaded\n        nonlocal total_truncated\n        total_downloaded += block_size\n        if total_downloaded // (1024 * 1024) > total_truncated:\n            total_truncated = total_downloaded // (1024 * 1024)\n            if total_truncated % 2 == 0:\n                print(f\"\\rDownloaded {total_downloaded // (1024 * 1024)} MB\", end=\"\")\n\n    try:\n        ssl._create_default_https_context = ssl._create_stdlib_context\n        urllib.request.urlretrieve(url, output_filename, reporthook=report_progress)\n        print(f\"\\nDownloaded {output_filename}\")\n        return True\n    except Exception as e:\n        print(f\"\\nFailed to download {output_filename}\")\n        print(f\"Error: {str(e)}\")\n        sys.exit(1)\n\ndef check_os(os_name):\n    print(\"\\nChecking System\")\n    print(\"===============\\n\")\n    print(f\"  Operating System : {os_name}\")\n    supported = {\"macOS\", \"Linux\"}\n    if os_name not in supported:\n        print(\"Unsupported operating system\")\n        sys.exit(1)\n\ndef download_dawn(os_name):\n    print(\"\\nDownload Dawn Library\")\n    print(\"=====================\\n\")\n\n    outfile_map = {\n        \"macOS\": \"third_party/lib/libdawn.dylib\",\n        \"Linux\": \"third_party/lib/libdawn.so\",\n    }\n    url_map = {\n        \"macOS\": \"https://github.com/austinvhuang/dawn-artifacts/releases/download/prerelease/libdawn.dylib\",\n        \"Linux\": \"https://github.com/austinvhuang/dawn-artifacts/releases/download/prerelease/libdawn.so\",\n    }\n\n    outfile = outfile_map.get(os_name)\n    url = url_map.get(os_name)\n\n    if not outfile or not url:\n        print(f\"No download information for {os_name}\")\n        sys.exit(1)\n\n    print(f\"  URL              : {url}\")\n    print(f\"  Download File    : {outfile}\\n\")\n    print(\"  Downloading ...\\n\")\n\n    if Path(outfile).exists():\n        print(f\"  File {outfile} already exists, skipping.\")\n        sys.exit(0)\n\n    Path(outfile).parent.mkdir(parents=True, exist_ok=True)\n    download_file(url, outfile)\n\ndef setup_env(os_name):\n    print(\"\\nEnvironment Setup\")\n    print(\"=================\\n\")\n    \n    current_dir = os.getcwd()\n    lib_dir = os.path.join(current_dir, \"third_party\", \"lib\")\n    \n    if os_name == \"macOS\":\n        print(\"  Before running the program, run the following command or add it to your shell profile:\")\n        print(f\"  export DYLD_LIBRARY_PATH=$DYLD_LIBRARY_PATH:{lib_dir}\")\n        \n        with open(\"source\", \"w\") as f:\n            f.write(f\"export DYLD_LIBRARY_PATH=$DYLD_LIBRARY_PATH:{lib_dir}\\n\")\n    if os_name == \"Linux\":\n        print(\"  Before running the program, run the following command or add it to your shell profile:\")\n        print(f\"  export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:{lib_dir}\")\n        \n        with open(\"source\", \"w\") as f:\n            f.write(f\"export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:{lib_dir}\\n\")\n\ndef main():\n    os_name = get_os_name()\n    check_os(os_name)\n    download_dawn(os_name)\n    setup_env(os_name)\n    print()\n\nif __name__ == \"__main__\":\n    main()\n"
        },
        {
          "name": "third_party",
          "type": "tree",
          "content": null
        },
        {
          "name": "utils",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}