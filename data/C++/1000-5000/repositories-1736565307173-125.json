{
  "metadata": {
    "timestamp": 1736565307173,
    "page": 125,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjEzMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "ydb-platform/ydb",
      "stars": 4095,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".arcadia.root",
          "type": "blob",
          "size": 0,
          "content": ""
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.677734375,
          "content": "# Ignore generated binaries -- any file without extension\n# Ignore all\n*\n# Unignore all with extensions\n!*.*\n# Unignore all dirs\n!*/\n# Unignore all files inside canondata dir\n!**/canondata/**\n# Allow docker files\n!Dockerfile\n\n/canonization_show_res.log\n\n# C libraries\n*.so\n*.a\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# Generated protos\n*_pb2.py\n*_pb2_grpc.py\n*_pb2.pyi\n*.pb.h\n*.pb.cc\n\n# Other generated\n*.fbs.h\n\n# MacOS specific\n.DS_Store\n\n# clangd cache\n/.cache\n\n/compile_commands.json\n\n/build_*\n/build-*\n\n.idea/\n.vscode/\n.clangd\n.antlr/\n\n# KDevelop IDE\n*.kdev4\n\n# Other symlinks\ncontrib/python/protobuf/py3/google.protobuf.internal._api_implementation.reg3.cpp\ncontrib/python/protobuf/py3/google.protobuf.pyext._message.reg3.cpp\ncontrib/tools/python3/src/Modules/_sqlite/_sqlite3.reg3.cpp\ncontrib/tools/ragel6/all_cd.cpp\ncontrib/tools/ragel6/all_cs.cpp\ncontrib/tools/ragel6/all_fs.cpp\ncontrib/tools/ragel6/all_go.cpp\ncontrib/tools/ragel6/all_ml.cpp\ncontrib/tools/ragel6/all_other.cpp\ncontrib/tools/ragel6/all_r.cpp\nlibrary/python/runtime_py3/__res.pyx.cpp\nlibrary/python/runtime_py3/__res.reg3.cpp\nlibrary/python/runtime_py3/sitecustomize.pyx.cpp\nlibrary/python/runtime_py3/sitecustomize.reg3.cpp\nlibrary/python/symbols/module/library.python.symbols.module.syms.reg3.cpp\nutil/all_datetime.cpp\nutil/all_digest.cpp\nutil/all_folder.cpp\nutil/all_generic.cpp\nutil/all_memory.cpp\nutil/all_network.cpp\nutil/all_random.cpp\nutil/all_stream.cpp\nutil/all_string.cpp\nutil/all_system_1.cpp\nutil/all_system_2.cpp\nutil/all_thread.cpp\nutil/all_util.cpp\nutil/charset/all_charset.cpp\n\nlist_result.log\nbin/config.json\n\n.vs/\n\n# handy for local junk, which is not intended to appear in the repo\njunk/\n"
        },
        {
          "name": ".mapping.json",
          "type": "blob",
          "size": 0.2861328125,
          "content": "{\n  \"build/mapping.conf.json\":\"devtools/ya/opensource/mapping.conf.json\",\n  \"build/scripts\":\"build/export_generators/hardcoded-cmake/build/scripts\",\n  \"build/ya.conf.json\":\"devtools/ya/opensource/ya.conf.json\",\n  \"ya\":\"devtools/ya/opensource/ya\",\n  \"ya.conf\":\"devtools/ya/opensource/ya.conf\"\n}"
        },
        {
          "name": ".piglet-meta.json",
          "type": "blob",
          "size": 0.048828125,
          "content": "{\n  \"project\":\"ydblib\",\n  \"repository\":\"arcadia\"\n}"
        },
        {
          "name": "AUTHORS",
          "type": "blob",
          "size": 2.8994140625,
          "content": "The following authors have created the source code of ¬´YDB¬ª published and distributed by YANDEX LLC as the owner.\n\nNote: This list does not necessarily include everyone who has contributed code, especially since many employees of\none corporation may be contributing. The revision history in source control gives the full list of contributors.\n\nThe project was started by Andrey Fomichev <andrey.fomichev@gmail.com> and Denis Podluzhny <ddoarn@gmail.com>\nin the end of 2013, first commit was made on 2014-01-10.\n\nIt's hard to imagine YDB project without these people even if they didn't contribute to the code much:\n    Alexander Chubinskiy <chubinskiy@gmail.com>\n    Oleg Bondar <oleshiy@gmail.com>\n    Anton Kovalenko <robocomp2@gmail.com>\n    Ilya Yatsishin <hq.zero.iq@gmail.com>\n\nList of most significant contributors:\n    Alexander Gololobov <agololobov@gmail.com>\n    Aleksey Stankevichus <the_ancient_one@aol.com>\n    Vitaly Stoyan <vitstn@gmail.com>\n    Sergey Puchin <s.puchin@gmail.com>\n    Alexey Borzenkov <snaury@gmail.com>\n    Vitalii Gridnev <gridnevvvit@gmail.com>\n    Alexander Rutkovsky <alexander.rutkovsky@gmail.com>\n    Alexey Efimov <xeno@prnwatch.com>\n    Maxim Gorbunov <m.v.gorbunov@gmail.com>\n    Semen Checherinda <checherinda@gmail.com>\n    Ilnaz Nizametdinov <i.nizametdinov@gmail.com>\n    Igor Makunin <igor.makunin@gmail.com>\n    Anton Romanov <anton.romanoff@gmail.com>\n    Roman Udovichenko <grsshun11@gmail.com>\n    Artem Zuikov <chertus@gmail.com>\n    Vladislav Kuznecov <va.kuznecov@physics.msu.ru>\n    Aleksei Nikolaevskii <alexnikolaevsky@gmail.com>\n    Sergey Ierusalimov <wintchester@gmail.com>\n    Daniil Cherednik <dan.cherednik@gmail.com>\n    Andrey Neporada <neporada@gmail.com>\n    Ilya Enkovich <enkovich@gmail.com>\n    Andrey Satarin <asatarin@yandex.ru>\n    Vadim Skipin <vadim.skipin@gmail.com>\n    Alexander Soloviev <single@yandex-team.ru>\n    Vasily Gerasimov <UgnineSirdis@gmail.com>\n    Sergey Trifonov <svtrifonov@gmail.com>\n    Alexander Dmitriev <alexd.65536@gmail.com>\n    Nikolay Perfilov <pnv902@gmail.com>\n    Alexander Kryukov <kru.bash.all@gmail.com>\n    Alexander Smirnov <plimouthrock@gmail.com>\n    Alexey Ozeritskiy <aozeritsky@gmail.com>\n    Sergey Polovko <http://www.jamel.org>\n    Igor Seliverstov <gvvinblade@gmail.com>\n    Iuliia Sidorina <ulya.sidorina@gmail.com>\n    Evgeniy Ivanov <i@eivanov.com>\n    Nikita Lapkov <nikita.lapkov@gmail.com>\n    Sergey Uzhakov <uzhastik@gmail.com>\n    Oleg Doronin <fortan57@gmail.com>\n    Alexey Bogolyubskiy <i@bogolyubskiyalexey.ru>\n    Konstantin Melekhov <mekose2304@gmail.com>\n    Anton Zelenov <zelenoff@gmail.com>\n    Ivan Blinkov <yandex@blinkov.ru>\n    Stas Kelvich <stas.kelvich@gmail.com>\n    Dmitrii Mokhnatkin <dmitriy.mokhnatkin@gmail.com>\n    Aleksandr Khoroshilov <hor911@gmail.com>\n    Evgenii Beloshabskii <beloshabskiy@gmail.com>\n    Aidar Samerkhanov <darych90@gmail.com>\n\nYou can be added to this list by a request to Andrey Fomichev.\n\n"
        },
        {
          "name": "BUILD.md",
          "type": "blob",
          "size": 7.505859375,
          "content": "# Building YDB from sources\n\nFrom this repository you can build YDB Server and YDB CLI (Command Line Interface utility) executables. You can build using either Yatool or CMake:\n\n- [Yatool](https://github.com/yandex/yatool) is the primary multilanguage build/test system being used to [build and test YDB](https://ydb.tech/docs/en/development/build-ya). You need to use Yatool and follow the [YDB development process](https://ydb.tech/docs/en/development/suggest-change) to make contributions to the YDB project.\n- [CMake](https://en.wikipedia.org/wiki/CMake) is a secondary build system available, with CMakelists.txt automatically pregenerated by Yatool. You can build any binary artifact of YDB using CMake.\n\n## Create the work directory. \n> :warning: Please make sure you have at least 80Gb of free space. We also recommend placing this directory on SSD to reduce build times.\n\n```bash\nmkdir ~/ydbwork && cd ~/ydbwork\n```\n\n## Clone the ydb repository\n\n```bash\ngit clone https://github.com/ydb-platform/ydb.git\n```\n\nChange the current working directory to the cloned repository root to perform further commands:\n\n```\ncd ydb\n```\n\n## Checkout a branch for build\n\nThere are two branches for the latest development update in the YDB repository:\n\n- `main` - the primary development branch for **Yatool** build\n- `cmakebuild` - the follower branch for **CMake** build, synced from `main` every hour, with generated CMakelists.txt files\n\nBuild from the development mainline branches may sometimes be broken for short periods of time, and also some tests may fail. So, you may prefer to build the latest stable versions of YDB Server and CLI. As stable versions of the YDB Server and CLI belong to different commits, it is not possible to get both server and CLI stable executables with a single checkout/build. Checkout and build server first, then CLI, or vice versa.\n\nStable versions can be built by both **Yatool** and **CMake**.\n\n### Checkout the latest development update for Yatool build\n\nBy default, the `main` branch is checked out, so you can run Yatool build without executing a checkout command.\n\n### Checkout the latest development update for CMake build\n\nTo checkout the latest development update for CMake build, run the following command:\n\n```bash\ngit checkout cmakebuild\n```\n\n### Check out the latest stable YDB Server version\n\nTo build the latest stable version of a YDB Server, check out the latest stable Server tag from the repository. To do so, visit the https://github.com/ydb-platform/ydb/releases/latest page and use the provided 'tag' value in the `git checkout <tag>` command.\n\nFor example, at the time of writing the latest stable release was [YDB Server 23.2.12](https://github.com/ydb-platform/ydb/releases/tag/23.2.12) with a tag `23.2.12`, so the checkout command looks like this:\n\n```bash\ngit checkout 23.2.12\n```\n\n### Check out the latest stable YDB CLI version\n\nTo build a latest stable version of a YDB CLI, check out the latest stable CLI tag from the repository. To do so, visit the https://github.com/ydb-platform/ydb/releases page, scroll down to the top-most 'YDB CLI' release, and use the provided 'tag' value in the `git checkout <tag>` command.\n\nFor example, at the time of writing the latest YDB CLI release was [YDB CLI 2.5.0](https://github.com/ydb-platform/ydb/releases/tag/CLI_2.5.0) with a tag `CLI_2.5.0`, so the checkout command looks like this:\n\n```bash\ngit checkout CLI_2.5.0\n```\n\n## Build using Yatool\n\nYou can use the native Yatool build for x86_64 under Ubuntu Linux 18+.\n\nRun `ya make` from the repository root, followed by an optional relative path to the build target. By default, `ya make` compiles a `debug` configuration, while you can choose to have `release` or `relwithdebinfo`. The latter is recommended for faster builds, as it leverages the YDB remote build cache.\n\nTo build a binary, Yatool downloads and caches relevant toolchains from the YDB S3 storage, so you do not need to install anything on the build machine.\n\nTo build YDB server run:\n\n```\n./ya make ydb/apps/ydbd --build relwithdebinfo\n```\n\nTo build YDB CLI run:\n\n```\n./ya make ydb/apps/ydb --build relwithdebinfo\n```\n\nUpon completion, you will have the `ydbd`/`ydb` executables in the `ydb/apps/ydbd`/`ydb/apps/ydb` directories, respectively.\n\nYou can read more about Yatool options in the [YDB documentation](https://ydb.tech/docs/development/build-ya).\n\n## Build using CMake\n\nYou can use CMake to build YDB for various architectures and operating systems.\n\nYDB server can be built for Ubuntu 18.04, 20.04 and 22.04. Other Linux distributions are likely to work, but additional effort may be required.\n\nYDB CLI can be built for Ubuntu 18+, Windows, and macOS. Instructions below are provided for Ubuntu only, other options are to be described later.\n\n### For Ubuntu versions earlier than 22.04\n\nIt is recommended to build YDB on Ubuntu 22.04. Follow these additional instructions if you don't have access to it and need to use an earlier version.\n\n<details>\n   <summary>For Ubuntu 18.04, install Python 3.8, create and activate a new virtual environment, and install the latest PIP.</summary>\n\n   ```bash\n   apt-get install python3.8 python3.8-venv python3-venv\n   python3.8 -m venv ~/ydbwork/ve\n   source ~/ydbwork/ve/bin/activate\n   pip install -U pip\n   ```\n</details>\n\n<details>\n   <summary>For Ubuntu 18.04 and Ubuntu 20.04, add CMake and LLVM APT repositories.</summary>\n\n   ```bash\n   wget -O - https://apt.kitware.com/keys/kitware-archive-latest.asc | sudo apt-key add -\n   echo \"deb http://apt.kitware.com/ubuntu/ $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/kitware.list >/dev/null\n   \n   wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | sudo apt-key add -\n   echo \"deb http://apt.llvm.org/$(lsb_release -cs)/ llvm-toolchain-$(lsb_release -cs)-14 main\" | sudo tee /etc/apt/sources.list.d/llvm.list >/dev/null\n   \n   sudo apt-get update\n   \n   ```\n\n</details>\n\n### Install dependencies\n\n```bash\nsudo apt-get update && \\\nsudo apt-get -y install git cmake python3-pip ninja-build antlr3 m4 clang-14 lld-14 libidn11-dev \\\n libaio1 libaio-dev llvm-14 curl\nsudo pip3 install conan==1.59 grpcio-tools==1.57.0\n\n```\n\n### Create the build directory. \n\n```bash\ncd ~/ydbwork\nmkdir build\n```\n\n### Install ccache\n\n1. Install `ccache` into `/usr/local/bin/`. The recommended version is `4.8.1` or above, the minimum required version is `4.7`.\n    ```bash\n    (V=4.8.1; curl -L https://github.com/ccache/ccache/releases/download/v${V}/ccache-${V}-linux-x86_64.tar.xz | \\\n     sudo tar -xJ -C /usr/local/bin/ --strip-components=1 --no-same-owner ccache-${V}-linux-x86_64/ccache)\n    ```\n\n2. To speed up the first build time, you may configure `ccache` to use remote storage of YDB build artifacts:\n    ```bash\n    ccache -o remote_storage=\"http://cachesrv.ydb.tech:8080|read-only|layout=bazel\"\n    ccache -o sloppiness=locale \n    ccache -o base_dir=~/ydbwork/\n    ```\n   If you use a non-default work directory, adjust the `base_dir` ccache option to match it.\n\n\n### Configure\n\n1. Change Conan's home folder to the build folder for better remote cache hit \n    ```bash\n    export CONAN_USER_HOME=~/ydbwork/build\n    ```\n\n2. Generate build configuration using `ccache`\n    ```bash\n    cd build\n    cmake -G Ninja -DCMAKE_BUILD_TYPE=Release \\\n    -DCCACHE_PATH=/usr/local/bin/ccache \\\n    -DCMAKE_TOOLCHAIN_FILE=../ydb/clang.toolchain \\\n    ../ydb  \n    ```\n\n### Build\n\nTo build YDB Server run:\n```bash\nninja ydb/apps/ydbd/all\n```\n\nA YDB server binary can be found at:\n```\nydb/apps/ydbd/ydbd\n```\n\nTo build YDB CLI (Command Line Interface utility) run:\n```bash\nninja ydb/apps/ydb/all\n```\n\nA YDB CLI binary can be found at:\n```\nydb/apps/ydb/ydb\n```\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 0.087890625,
          "content": "We welcome everyone to contribute to our product, see [CONTRIBUTING.md](CONTRIBUTING.md).\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 1.0546875,
          "content": "# Notice to external contributors\n\n## Common\n\nYDB is a free and open project and we appreciate to receive contributions from our community.\n\n## Contributing code changes\n\nIf you would like to contribute a new feature or a bug fix, please discuss your idea first on the GitHub issue.\nIf there is no issue for your idea, please open one. It may be that somebody is already working on it,\nor that there are some complex obstacles that you should know about before starting the implementation.\nUsually there are several ways to fix a problem and it is important to find the right approach before spending time on a PR\nthat cannot be merged.\n\n## Provide a contribution\n\nTo make a contribution you should submit a pull request. There will probably be discussion about the pull request and,\nif any changes are needed, we would love to work with you to get your pull request merged.\n\nFollow this link to have more information about the YDB build and test system: https://ydb.tech/docs/development/build-ya.\n\n## Other questions\n\nIf you have any questions, please mail us at info@ydb.tech.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0791015625,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2022-2024 YANDEX LLC\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 5.759765625,
          "content": "<img width=\"64\" src=\"ydb/docs/_assets/logo.svg\" /><br/>\n\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://github.com/ydb-platform/ydb/blob/main/LICENSE)\n[![Release](https://img.shields.io/github/v/release/ydb-platform/ydb.svg?style=flat-square)](https://github.com/ydb-platform/ydb/releases)\n[![Discord](https://img.shields.io/discord/1158573985894772827?logo=discord&logoColor=%23fff)](https://discord.gg/R5MvZTESWc)\n\n## YDB\n\n[Website](https://ydb.tech) |\n[Documentation](https://ydb.tech/docs/en/) |\n[Official Repository](https://github.com/ydb-platform/ydb) |\n[Blog](https://blog-redirect.ydb.tech) |\n[YouTube](https://www.youtube.com/c/YDBPlatform) |\n[Discord](https://discord.gg/R5MvZTESWc) |\n[Telegram](https://t.me/ydb_en) |\n[LinkedIn](https://www.linkedin.com/company/ydb-platform) |\n[X](https://x.com/YDBPlatform)\n\nYDB is an open source Distributed SQL Database that combines high availability and scalability with strict consistency and ACID transactions.\n\n[![YDB Product Video](ydb/docs/_assets/ydb-promo-video.png)](https://youtu.be/bxZRUtMAlFI)\n\n## Main YDB Advantages\n\nYDB was designed from scratch to respond to the growing demand for scalable interactive web services. Scalability, strict consistency, and effective cross-row transactions were a must for such an OLTP-like workload. YDB was built by people with strong backgrounds in databases and distributed systems who have experience developing a NoSQL database and the MapReduce system for one of the largest search engines in the world.\n\nBasic YDB features:\n\n- Both row-oriented and column-oriented [tables](https://ydb.tech/docs/en/concepts/datamodel/table) for transactional and analytical workloads. Also, [persistent queues (topics)](https://ydb.tech/docs/en/concepts/topic) for moving data around.\n- Fault-tolerant configuration that survives disk, node, rack, or even datacenter outages.\n- Automatic disaster recovery with minimum latency disruptions for applications.\n- Independent horizontal scalability of storage and compute layers.\n- ACID transactions across multiple nodes and tables with strict consistency.\n- Rich [SQL dialect (YQL)](https://ydb.tech/docs/en/yql/reference/) for data manipulation and schema definition.\n- [PostgreSQL-compatible mode](https://ydb.tech/docs/en/postgresql/intro) for table operations and [Kafka-compatible mode](https://ydb.tech/docs/en/reference/kafka-api/) for topics.\n- YDB clusters can be deployed with [Ansible](https://ydb.tech/docs/en/devops/ansible/), [Kubernetes](https://ydb.tech/docs/en/devops/kubernetes/), or [manually](https://ydb.tech/docs/en/devops/manual/).\n\n### Fault-tolerant Configurations\n\nYDB can be deployed in three availability zones (datacenters). A cluster remains available for both reads and writes during a complete outage of a single zone. Availability zones and regions are covered in more detail [in documentation](https://ydb.tech/en/docs/concepts/databases#regions-az).\n\n### Horizontal Scalability\n\nUnlike traditional relational databases, YDB [scales out](https://en.wikipedia.org/wiki/Scalability#Horizontal_or_scale_out), providing developers with the capability to simply extend clusters with computation or storage resources to handle increasing load. YDB has disaggregated storage and compute layers, which allow you to scale storage and compute resources independently.\n\nCurrent production installations have over 10000 nodes, store petabytes of data, and handle millions of distributed transactions per second.\n\n### Automatic Disaster Recovery\n\nYDB's built-in automatic recovery support allows it to seamlessly survive hardware failures. After unpredictable disk, node, rack, or even datacenter failure, YDB remains fully available for reads and writes and automatically restores required data redundancy.\n\n### Multitenant and Serverless Database\n\nYDB supports multitenant and serverless setups. A user can run a YDB cluster and create several databases that share one pool of storage and have different compute nodes. Alternatively, a user can run several serverless databases that share one pool of compute resources to utilize them effectively.\n\n## Supported Platforms\n\n### Minimal system requirements\n\nYDB runs on x86 64-bit platforms with at least 8 GB of RAM.\n\n### Operating Systems\n\nIn most production environments, YDB runs on 64-bit x86 machines working under Ubuntu Linux.\n\nFor development purposes, it is regularly tested that YDB can be compiled and run under the latest versions of MacOS and Microsoft Windows.\n\n## Getting Started\n\nIf you want to experiment with YDB, start with the [Quick Start guide](https://ydb.tech/docs/en/quickstart). It will yield a single-node cluster suitable for functional testing, app development, and similar tasks.\n\nSuppose you want to jump into more serious scenarios like testing YDB fault tolerance, running performance benchmarks, or even running production or preproduction workloads. In that case, you'll need a full-fledged multi-node YDB cluster that can be deployed with either [Ansible](https://ydb.tech/docs/en/devops/ansible/initial-deployment) for bare metal or virtual machines or [Kubernetes](https://ydb.tech/docs/en/devops/kubernetes/initial-deployment) for containers.\n\n## How to Build from Source Code\n\nInstructions on how to build YDB server (ydbd) and client (ydb) binaries are provided in [BUILD.md](BUILD.md). Also, see documentation on [Ya Make build system](https://ydb.tech/docs/en/contributor/build-ya).\n\n## How to Contribute\n\nWe are glad to welcome new contributors! The [contributor's guide](CONTRIBUTING.md) provides more details on how to get started as a contributor.\n\nThere's also a separate section of [YDB documentation for contributors](https://ydb.tech/docs/en/contributor/), mostly with more technical content.\n\n## Success Stories\n\nVisit YDB [website](https://ydb.tech/) for the latest success stories and user scenarios.\n\n\n"
        },
        {
          "name": "ROADMAP.md",
          "type": "blob",
          "size": 8.9052734375,
          "content": "# YDB Roadmap\n## Intro\nThe document contains high-level roadmap for YDB. Take a look at [üëë Epics Project](https://github.com/orgs/ydb-platform/projects/46/) also.\n## Legend\nWe use the following symbols as abbreviations:\n\n1. „âì - feature appeared in the Roadmap for 2023;\n1. „âî - feature appeared in the Roadmap for 2024;\n1. ‚úÖ - feature has been released;\n1. üöß - feature is partially available and is under development;\n1. ‚ùå - feature has been refused;\n1. üî• - not yet released, but we are in rush.\n\n## Query Processor\n\n1. „âî **Unique secondary indexes**\n1. „âî Apply **indexes automatically** to optimize data fetching\n1. „âî **Default values** for table columns\n1. „âî **Asynchronous LLVM JIT** query compilation\n1. „âî **Parameters in DECLARE clause are becoming optional**, better SQL compatibility\n1. üöß„âî **Cost-based optimizer** for join order and join algorithm selection\n1. „âî **``INSERT INTO table FROM SELECT``** for large datasets\n1. „âî Support for **transactional writes into both row and column tables**\n1. „âî Support for **computed columns in a table**\n1. „âî Support for **temporary tables**\n1. „âî Support for **VIEW** SQL clause\n1. „âî **Data Spilling** in case there is issufient amount of RAM\n1. „âî **TPC-H, TPC-DS for 100TB** dataset\n1. ‚úÖ „âì Support for **Snapshot Readonly** transactions mode\n1. üöß „âì **Better resource management** for KQP Resource Manager (share information about nodes resources, avoid OOMs)\n1. ‚úÖ „âì Switch to **New Engine** for OLTP queries\n1. ‚úÖ „âì Support **`not null` for PK (primary key) table columns**\n1. ‚úÖ „âì **Aggregates and predicates push down to column-oriented tables**\n1. ‚úÖ „âì **Optimize data formats** for data transition between query phases\n1. ‚úÖ „âì **Index Rename/Rebuild**\n1. ‚úÖ „âì **KQP Session Actor** as a replacement for KQP Worker Actor (optimize to reduce CPU usage)\n1. **PostgreSQL compatibility**\n    * ‚úÖ „âì Support PostgreSQL datatypes **serialization/deserialization** in YDB Public API\n    * üöß „âì PostgreSQL compatible **query execution** (TPC-C, TPC-H queries should work)\n    * ‚úÖ „âì Support for PostgreSQL **wire protocol**\n1. „âì Support a single **Database connection string** instead of multiple parameters\n1. „âì Support **constraints in query optimizer**\n1. **Query Processor 3.0** (a set of tasks to be more like traditional database in case of query execution functionality)\n    * „âì Support for **Streaming Lookup Join** via MVCC snapshots (avoid distributed transactions, scalability is better)\n    * „âì **Universal API call for DML, DDL with unlimited results size for OLTP/OLAP workload** (aka ExecuteQuery)\n    * ‚úÖ „âì Support for **secondary indexes in ScanQuery**\n    * ‚úÖ „âì **Transaction can see its own updates** (updates made during transaction execution are not buffered in RAM anymore, but rather are written to disk and available to read by this transaction)\n1. ‚úÖ „âì **Computation graphs caching (compute/datashard programs)** (optimize CPU usage)\n1. üöß „âì **RPC Deadline & Cancellation propagation** (smooth timeout management)\n1. ‚úÖ „âì **DDL for column-oriented tables**\n\n## Database Core (Tablets, etc)\n1. ‚úÖ „âî **Exact Nearest Neighbor Vector Search**\n1. „âî **Approximate Nearest Neighbor Vector Search**. [Global vector index](https://github.com/ydb-platform/ydb/issues/8967)\n1. „âî **Volatile transactions**. YDB Distributed transactions 2.0, minimize network round trips in happy path\n1. „âî **Table statistics** for cost-based optimizer\n1. „âî **Memory optimization for row tables** (avoid full [SST index loading](https://github.com/ydb-platform/ydb/issues/1483), dynamic cache adjusting)\n1. „âî Reduce minimum requirements for **the number of cores to 2** for YDB node\n1. „âî **Incremental backup** and **Point-in-time recovery**\n1. „âî **``ALTER CHANGEFEED``**\n1. „âî **Async Replication** between YDB databases (column tables, topics)\n1. „âî **Async Replication** between YDB databases (schema changes)\n1. „âî Support for **Debezium** format\n1. „âî **Topics autoscaling** (increase/decrease number of partitions in the topic automatically)\n1. „âî **Extended Kafka API** protocol to YDB Topics support (balance reads, support for v19)\n1. „âî **Schema for YDB Topics**\n1. „âî **Message-level parallelism** in YDB Topics\n1. ‚úÖ „âì Get **YDB topics** (aka pers queue, streams) ready for production\n1. ‚úÖ „âì Turn on **MVCC support** by default\n1. ‚úÖ „âì Enable **Snapshot read mode** by default (take and use MVCC snapshot for reads instead of running distributed transaction for reads)\n1. ‚úÖ „âì **Change Data Capture** (be able to get change feed of table updates)\n1. üî• „âì **Async Replication** between YDB databases  (first version, row tables, w/o schema changes)\n1. ‚úÖ „âì **Background compaction for DataShards**\n1. ‚úÖ „âì **Compressed Backups**. Add functionality to compress backup data\n1. „âì Process of **Extending State Storage** without cluster downtime. If a cluster grows from, say, 9 nodes to 900 State Storage configuration stays the same (9 nodes), it leads to a performance bottleneck.\n1. **Split/Merge DataShards *BY LOAD* by default**. Most users require this feature turned on by default\n1. ‚úÖ „âì Support **PostgreSQL datatypes** in tablet local database\n1. **Basic histogram for DataShards** (first step towards cost based optimizations)\n1. ‚úÖ „âì **Transaction can see its own updates** (updates made during transaction execution are not buffered in RAM anymore, but rather are written to disk and available to read by this transaction)\n1. „âì **Data Ingestion from topic to table** (implement built-in compatibility to ingest data to YDB tables from topics)\n1. „âì Support **snapshot read over read replicas** (consistent reads against read replicas)\n1. „âì üöß **Transactions between topics and tables**\n1. ‚úÖ „âì Support for **Kafka API compatible protocol** to YDB Topics\n\n### Hardcore or system wide\n1. „âî **Tracing** capabilities\n1. „âî Automatically **balance tablet channels** via BlobStorage groups\n1. ‚úÖ „âì **Datashard iterator reads via MVCC**\n1. ‚ùå *(refused)* „âì **Switch to TRope** (or don't use TString/std::string directly, provide zero-copy data passing between components)\n1. „âì **Avoid Node Broker as SPF** (NBS must work without Node Broker under emergency conditions)\n1. „âì **Subscriptions in SchemeBoard** (optimize interaction with SchemeBoard via subsription to updates)\n\n## Security\n1. ‚úÖ „âì Basic LDAP Support\n1. „âî Support for OpenID Connect\n1. „âî Authentication via KeyCloack\n1. „âî Support for SASL framework\n\n## BlobStorage\n1. „âî BlobStorage **latency optimization** (p999), less CPU consumption\n1. „âî **ActorSystem performance optimizations**\n1. „âî Optimize **ActorSystem for ARM processors**\n1. „âî **Effortless initial cluster deployment** (provide only nodes and disks description)\n1. „âî **Reduce number of BlobStorage groups** for a database (add ability to remove unneeded groups)\n1. „âì **\"One leg\" storage migration without downtime** (migrate 1/3 of the cluster from one AZ to another for mirror3-dc erasure encoding)\n1. ‚úÖ „âì **ActorSystem 1.5** (dynamically reassign threads in different thread pools)\n1. ‚úÖ „âì **Publish an utility for BlobStorage management** (it's called ds_tool for now, improve it and open)\n1. „âì **Self-heal for degrated BlobStorage groups** (automatic self-heal for groups with two broken disks, get VDisk Donors production ready)\n1. „âì **BlobDepot** (a component for smooth blobs management between groups)\n1. „âì **Avoid BSC (BlobStorage Controller) as SPF** (be able to run the cluster without BSC in emergency cases)\n1. „âì **BSC manages static group** (reconfiguration of the static BlobStorage group must be done BlobStorage Controller as for any other group)\n1. „âì **(Semi-)Hard disk space separation** (Better guarantees for disk space usage by VDisks on a single PDisk)\n1. „âì **Reduce space amplification** (Optimize storage layer)\n1. ‚úÖ „âì **Storage nodes decommission** (Add ability to remove storage nodes)\n\n## Analytical Capabilities\n1. „âî **Backup** for column tables\n1. „âî Column tables **autosharding**\n1. „âì üöß **Log Store** (log friendly column-oriented storage which allows to create 1+ million tables for logs storing)\n1. „âì üöß **Column-oriented Tables** (introduce a Column-oriented tables in additon to Row-orinted tables)\n1. „âì **Tiered Storage for Column-oriented Tables** (with the ability to store the data in S3)\n\n## Federated Query\n1. ‚úÖ „âì **Run the first version**\n\n## Embedded UI\nDetailed roadmap could be found at [YDB Embedded UI repo](https://github.com/ydb-platform/ydb-embedded-ui/blob/main/ROADMAP.md).\n\n## Command Line Utility\n1. üöß „âì Use a **single `ydb yql`** instead of `ydb table query` or `ydb scripting`\n1. ‚úÖ „âì Interactive CLI\n\n## Tests and Benchmarks\n1. „âì **Built-in load test for DataShards** in YCSB manner\n1. ‚úÖ „âì **`ydb workload` for topics**\n1. ‚úÖ „âî **Jepsen tests support** [Blog post](https://blog.ydb.tech/hardening-ydb-with-jepsen-lessons-learned-e3238a7ef4f2)\n\n## Experiments\n1. ‚ùå *(refused)* Try **RTMR-tablet** for key-value workload\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 1.22265625,
          "content": "# Security Policy\n\n## Reporting a Vulnerability\n\nWe're extremely grateful for security researchers and users who report vulnerabilities they discovered in YDB. All reports are thoroughly investigated.\n\nTo report a potential vulnerability in YDB please email details to [security@ydb.tech](mailto:security@ydb.tech).\n\n### When Should I Report a Vulnerability?\n\n- You think you discovered a potential security vulnerability in YDB\n- You are unsure how a vulnerability affects YDB\n\n## Security Vulnerability Response\n\nEach report is acknowledged and analyzed by YDB maintainers within 5 working days.\nWe will keep the reporter informed about the issue progress.\n\n## Public Disclosure Timing\n\nA public disclosure date is negotiated by YDB maintainers and the bug submitter. We prefer to fully disclose the bug as soon as possible once a mitigation is available for YDB users. It is reasonable to delay disclosure when the bug or the fix is not yet fully understood, the solution is not well-tested, or for vendor coordination. The timeframe for disclosure is from immediate (especially if it's already publicly known) to 90 days. For a vulnerability with a straightforward mitigation, we expect report date to disclosure date to be on the order of 7 days.\n"
        },
        {
          "name": "build",
          "type": "tree",
          "content": null
        },
        {
          "name": "certs",
          "type": "tree",
          "content": null
        },
        {
          "name": "clang.toolchain",
          "type": "blob",
          "size": 0.73046875,
          "content": "set(CMAKE_C_COMPILER clang-16)\nset(CMAKE_CXX_COMPILER clang++-16)\nset(CMAKE_EXE_LINKER_FLAGS \"-fuse-ld=lld -rdynamic\")\nset(CMAKE_SHARED_LINKER_FLAGS \"-fuse-ld=lld\")\nset(CMAKE_C_STANDARD_LIBRARIES \"-lc -lm\")\nset(CMAKE_CXX_STANDARD_LIBRARIES \"-lc -lm\")\nif (CCACHE_PATH)\n    set(CMAKE_C_COMPILER_LAUNCHER \"${CCACHE_PATH}\"  CACHE STRING \"C compiler launcher\")\n    set(CMAKE_CXX_COMPILER_LAUNCHER \"${CCACHE_PATH}\" CACHE STRING \"C++ compiler launcher\")\nendif()\n\nset(CMAKE_C_FLAGS_RELEASE \"${CMAKE_C_FLAGS_RELEASE} -O3 -UNDEBUG\"  CACHE STRING \"C compiler flags\")\nset(CMAKE_CXX_FLAGS_RELEASE \"${CMAKE_CXX_FLAGS_RELEASE} -O3 -UNDEBUG\" CACHE STRING \"C++ compiler flags\")\n\nset(ENV{CC} clang-16)\nset(ENV{CXX} clang++-16)\n\nset(REQUIRED_LLVM_TOOLING_VERSION 16)\n"
        },
        {
          "name": "conanfile.py",
          "type": "blob",
          "size": 0.861328125,
          "content": "from conan import ConanFile\n\n\nclass App(ConanFile):\n\n    settings = \"os\", \"compiler\", \"build_type\", \"arch\"\n\n    default_options = {\"libiconv:shared\": \"True\"}\n\n    def requirements(self):\n        self.requires(\"libiconv/1.15\")\n\n    def build_requirements(self):\n        self.tool_requires(\"bison/3.8.2\")\n        self.tool_requires(\"m4/1.4.19\")\n        self.tool_requires(\"ragel/6.10\")\n        self.tool_requires(\"yasm/1.3.0\")\n\n    generators = \"cmake_find_package\", \"cmake_paths\"\n\n    def imports(self):\n        self.copy(pattern=\"*yasm*\", src=\"bin\", dst=\"./bin\")\n        self.copy(pattern=\"bison*\", src=\"bin\", dst=\"./bin/bison/bin\")\n        self.copy(pattern=\"m4*\", src=\"bin\", dst=\"./bin/m4/bin\")\n        self.copy(pattern=\"ragel*\", src=\"bin\", dst=\"./bin\")\n        self.copy(pattern=\"ytasm*\", src=\"bin\", dst=\"./bin\")\n        self.copy(pattern=\"*\", src=\"res\", dst=\"./bin/bison/res\")\n"
        },
        {
          "name": "contrib",
          "type": "tree",
          "content": null
        },
        {
          "name": "devtools",
          "type": "tree",
          "content": null
        },
        {
          "name": "generate_cmake",
          "type": "blob",
          "size": 8.400390625,
          "content": "#!/usr/bin/env python3\n\nimport sys\nimport os\nimport shutil\nimport subprocess\nimport multiprocessing\nimport json\nimport stat\nimport filecmp\nimport urllib.request\nfrom argparse import ArgumentParser\n\n\ndef mkdir(path):\n    try:\n        os.mkdir(path)\n    except FileExistsError as e:\n        pass\n\n\ndef remove_file(path):\n    try:\n        os.remove(path)\n    except FileNotFoundError as e:\n        pass\n\n\ndef compare_files(lhs_file_path, rhs_file_path):\n    try:\n        return filecmp.cmp(lhs_file_path, rhs_file_path)\n    except FileNotFoundError as e:\n        return False\n\n\ndef rmtree(path):\n    try:\n        shutil.rmtree(path)\n    except FileNotFoundError as e:\n        pass\n\n\ndef generate_graph_for_platform(generate_graph_for_platform):\n    platform = generate_graph_for_platform[0]\n    generate_graph_command = generate_graph_for_platform[1]\n\n    output = subprocess.check_output(\n        generate_graph_command, stderr=subprocess.STDOUT, shell=True\n    ).decode(\"utf-8\")\n\n    allowed_error_patterns = [\n        \"to directory without ya.make: [[imp]]$S/build/platform/\",\n        \"to missing directory: [[imp]]$S/build/platform/\",\n        \"to directory without ya.make: [[imp]]$S/build/external_resources/\",\n        \"to missing directory: [[imp]]$S/build/external_resources/\",\n        \"could not resolve include file: [[imp]]openssl\",\n        \"could not resolve include file: [[imp]]zlib\",\n        \"could not resolve include file: [[imp]]ares.h\",\n        \"in $B/contrib/libs/openssl/\",\n        \"in $B/contrib/libs/zlib\",\n        \"in $B/contrib/libs/c-ares\",\n        \"in $B/contrib/libs/libc_compat/ubuntu_14/liblibs-libc_compat-ubuntu_14.a\",\n        \"in $B/contrib/libs/linux-headers/libcontrib-libs-linux-headers.a\",\n        \"in $B/contrib/libs/farmhash/\",\n        \"in $B/contrib/libs/curl/\",\n        \"in $B/contrib/libs/libxml/\",\n        \"in $B/contrib/libs/apache/arrow/\",\n        \"in $B/contrib/libs/grpc/\",\n        \"in $S/contrib/tools/protoc/plugins/cpp_styleguide/ya.make\",\n        \"in $S/contrib/tools/protoc/plugins/grpc_cpp\",\n        \"in $B/contrib/restricted/boost/\",\n        \"in $B/library/cpp/charset/\",\n        \"in $B/library/cpp/uri/\",\n        \"in $B/library/cpp/unicode/punycode/\",\n        \"in $B/library/cpp/config/\",\n        \"in $S/tools/rescompiler/bin/\",\n        # Fix\n        \"in $B/ydb/library/actors/dnsresolver/ut/library-cpp-actors-dnsresolver-ut\",\n        \"in $B/ydb/library/pdisk_io/libydb-library-pdisk_io\",\n        \"skip unknown statement: ADD_YTEST vector of size\",\n        \"skip unknown statement: _REGISTER_NO_CHECK_IMPORTS vector of size\",\n        \"skip unknown statement: CHECK_CONTRIB_CREDITS vector of size\",\n        \"skip unknown statement: ASSERT vector of size\",\n        \"skip unknown statement: FILES vector of size\",\n        \"skip unknown statement: ADD_CHECK vector of size\",\n        \"skip unknown statement: COPY vector of size\",\n        \"skip unknown statement: PY_EXTRALIBS vector of size\",\n        \"skip unknown statement: LLVM_BC vector of size\",\n        \"skip unknown statement: SUPPRESSIONS vector of size\",\n        \". It is not intended for export.\",\n    ]\n\n    if platform == \"windows-x86_64\":\n        # Fix\n        allowed_error_patterns.append(\"in $B/ydb/core/tx/tiering/core-tx-tiering\")\n        allowed_error_patterns.append(\n            \"in $B/ydb/library/yql/providers/s3/serializations/providers-s3-serializations\"\n        )\n\n    result_errors = []\n    for line in output.split(\"\\n\"):\n        if not line.startswith(\"Error\"):\n            continue\n\n        error_is_allowed = False\n        for allowed_error_pattern in allowed_error_patterns:\n            if allowed_error_pattern in line:\n                error_is_allowed = True\n                break\n\n        if error_is_allowed:\n            continue\n\n        result_errors.append(line)\n\n    return result_errors\n\n\nif __name__ == \"__main__\":\n    parser = ArgumentParser(description=\"Generate CMake files from Ya make files\")\n    parser.add_argument(\"--ymake_bin\", help=\"Path to ymake binary\")\n    parser.add_argument(\"--yexport_bin\", help=\"Path to yexport binary\")\n    parser.add_argument(\"--tmp\", help=\"Path to tmp dir\")\n    parser.add_argument(\n        \"-k\", \"--keep-going\", action=\"store_true\", default=False, help=\"Ignore unknown build graph errors and try to perform export\")\n    parser.add_argument(\n        \"--debug\", action=\"store_true\", default=False, help=\"Run script in debug mode\"\n    )\n\n    try:\n        args = parser.parse_args()\n    except Exception as e:\n        print(e, file=sys.stderr)\n        sys.exit(1)\n\n    tmp_folder_path = args.tmp\n    if tmp_folder_path is None:\n        tmp_folder_path = \"/tmp/ydb-generate-cmake\"\n\n    ymake_binary_path = args.ymake_bin\n    yexport_binary_path = args.yexport_bin\n    debug = args.debug\n    keep_going = args.keep_going\n    root_folder = os.getcwd()\n\n    ydb_tmp_folder_path = tmp_folder_path + \"/ydb\"\n    ydb_metadata_folder_path = tmp_folder_path + \"/metadata\"\n    plugins_folder_path = root_folder + \"/build/plugins\"\n\n    mkdir(tmp_folder_path)\n    mkdir(ydb_metadata_folder_path)\n\n    if ymake_binary_path is None:\n        ymake_binary_path = root_folder + \"/ya tool ymake\"\n\n    if yexport_binary_path is None:\n        # libiconv_path=\"contrib/libs/libiconv/dynamic\"\n        # compile_libiconv_command = f\"{root_folder}/ya make -r {libiconv_path}\"\n        # print(\"Compliling libiconv...\")\n        # subprocess.check_output(compile_libiconv_command, shell=True)\n        # yexport_binary_path = f\"LD_LIBRARY_PATH={libiconv_path} {root_folder}/ya tool yexport\"\n        yexport_binary_path = f\"{root_folder}/ya tool yexport\"\n\n    platforms = [\n        \"linux-x86_64\",\n        \"linux-aarch64\",\n        \"darwin-x86_64\",\n        \"darwin-arm64\",\n        \"windows-x86_64\",\n    ]\n\n    generate_graph_for_platform_commands = []\n\n    for platform in platforms:\n        target_platform = \"default-\" + platform\n        print(f\"Platform {platform} target platform {target_platform}\")\n\n        dump_export_path = f\"{ydb_metadata_folder_path}/{platform}.conf\"\n        graph_export_path = f\"{ydb_metadata_folder_path}/sem.{platform}.json\"\n\n        generate_dump_command = f\"{root_folder}/scripts/generate_dump.sh {platform} {target_platform} > {dump_export_path}\"\n        print(f\"Generate dump command {generate_dump_command}\")\n\n        subprocess.check_output(generate_dump_command, shell=True)\n\n        # In original script there are targets kikimr/docs/ru/docs_oss ydb ydb/tests/oss/launch library/cpp/actors tools/rescompiler/bin\n        generate_graph_command = f'{ymake_binary_path} --build-root \"{ydb_tmp_folder_path}\" --config \"{dump_export_path}\"\\\n            --plugins-root \"{plugins_folder_path}\" --xs --xx --sem-graph --keep-going\\\n            ydb ydb/tests/oss/launch tools/rescompiler/bin > {graph_export_path}'\n        print(f\"Generate graph command {generate_graph_command}\")\n\n        generate_graph_for_platform_commands.append((platform, generate_graph_command))\n\n    errors_for_platform = []\n    with multiprocessing.Pool(len(generate_graph_for_platform_commands)) as pool:\n        errors_for_platform = pool.map(\n            generate_graph_for_platform, generate_graph_for_platform_commands\n        )\n\n    yexport_args = [yexport_binary_path, \"--export-root\", f\"\\\"{root_folder}\\\"\", \"--target\", \"YDB\", \"--generator\", \"cmake\"]\n\n    for index, platform in enumerate(platforms):\n        errors_for_platform_size = len(errors_for_platform[index])\n\n        if errors_for_platform_size == 0:\n            yexport_args += [\n                \"--semantic-graph\",\n                f\"\\\"{ydb_metadata_folder_path + '/sem.' + platform + '.json'}\\\"\",\n                \"--platforms\",\n                platform,\n            ]\n            continue\n\n        print(\n            f\"Found {errors_for_platform_size} errors for platform {platform}\",\n            file=sys.stderr,\n        )\n        for error in errors_for_platform[index]:\n            print(error, file=sys.stderr)\n\n        if not keep_going:\n            sys.exit(1)\n\n    yexport_command = ' '.join(yexport_args)\n\n    print(f\"yexport command {yexport_command}\")\n\n    yexport_output = subprocess.check_output(\n        yexport_command, stderr=subprocess.STDOUT, shell=True\n    ).decode(\"utf-8\")\n\n    if debug:\n        print(\"yexport output\")\n        print(yexport_output)\n\n    sys.exit(0)\n\n    rsync_command = f'rsync --recursive --delete  --perms\\\n        --exclude .git --exclude contrib --exclude library/cpp/actors\\\n        \"{ydb_tmp_folder_path}/\" \"{root_folder}/\"'\n\n    print(f\"rsync command {rsync_command}\")\n    subprocess.check_output(rsync_command, shell=True)\n\n    sys.exit(0)\n"
        },
        {
          "name": "library",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "util",
          "type": "tree",
          "content": null
        },
        {
          "name": "vendor",
          "type": "tree",
          "content": null
        },
        {
          "name": "ya",
          "type": "blob",
          "size": 10.2529296875,
          "content": "#!/usr/bin/env sh\n\n# Please, keep this script in sync with arcadia/ya\n\n# Shell commands follow\n# Next line is bilingual: it starts a comment in Python, but do nothing in shell\n\"\"\":\"\n\n# Find a suitable python interpreter\nfor cmd in python3 python; do\n    command -v > /dev/null $cmd && exec \"$(command -v $cmd)\" \"$0\" \"$@\"\ndone\n\necho \"Python interpreter is not found in this system, please, install python\" >&2\n\nexit 2\n\n\":\"\"\"\n# Previous line is bilingual: it ends a comment in Python, but do nothing in shell\n# Shell commands end here\n# Python script follows\n\nimport os\nimport sys\nimport platform\nimport time\n\ndef add_stage_start_to_environ(stage_name):\n    stages = os.environ.get('YA_STAGES', '')\n    os.environ['YA_STAGES'] = stages + (':' if stages else '') + '{}@{}'.format(stage_name, time.time())\n\nRETRIES = 5\nHASH_PREFIX = 10\n\nREGISTRY_ENDPOINT = os.environ.get(\"YA_REGISTRY_ENDPOINT\", \"https://devtools-registry.s3.yandex.net\")\n\n# Please do not change this dict, it is updated automatically\n# Start of mapping\nPLATFORM_MAP = {\n    \"data\": {\n        \"darwin\": {\n            \"md5\": \"2aeff4a8b56c294648e2a7fe5bcaf2f5\",\n            \"urls\": [\n                f\"{REGISTRY_ENDPOINT}/7750410363\"\n            ]\n        },\n        \"darwin-arm64\": {\n            \"md5\": \"f4388ea2cd6cf37a66ad839c13356535\",\n            \"urls\": [\n                f\"{REGISTRY_ENDPOINT}/7750409498\"\n            ]\n        },\n        \"linux-aarch64\": {\n            \"md5\": \"8199dfd101c2eeddc2926e0bd8931a66\",\n            \"urls\": [\n                f\"{REGISTRY_ENDPOINT}/7750408525\"\n            ]\n        },\n        \"win32-clang-cl\": {\n            \"md5\": \"12257bbee911ec403eb302a15c7c22b0\",\n            \"urls\": [\n                f\"{REGISTRY_ENDPOINT}/7750411200\"\n            ]\n        },\n        \"linux\": {\n            \"md5\": \"b921725a0c13639344aec267bef973c0\",\n            \"urls\": [\n                f\"{REGISTRY_ENDPOINT}/7750412171\"\n            ]\n        }\n    }\n} # End of mapping\n\nadd_stage_start_to_environ('ya-script-initialization')\n\ndef create_dirs(path):\n    try:\n        os.makedirs(path)\n    except OSError as e:\n        import errno\n\n        if e.errno != errno.EEXIST:\n            raise\n\n    return path\n\n\ndef home_dir():\n    # Do not trust $HOME, as it is unreliable in certain environments\n    # Temporarily delete os.environ[\"HOME\"] to force reading current home directory from /etc/passwd\n    home_from_env = os.environ.pop(\"HOME\", None)\n    try:\n        home_from_passwd = os.path.expanduser(\"~\")\n        if os.path.isabs(home_from_passwd):\n            # This home dir is valid, prefer it over $HOME\n            return home_from_passwd\n        else:\n            # When python is built with musl (this is quire weird though),\n            # only users from /etc/passwd will be properly resolved,\n            # as musl does not have nss module for LDAP integration.\n            return home_from_env\n\n    finally:\n        if home_from_env is not None:\n            os.environ[\"HOME\"] = home_from_env\n\n\ndef misc_root():\n    return create_dirs(os.getenv('YA_CACHE_DIR') or os.path.join(home_dir(), '.ya'))\n\n\ndef tool_root():\n    return create_dirs(os.getenv('YA_CACHE_DIR_TOOLS') or os.path.join(misc_root(), 'tools'))\n\n\n# TODO: remove when switched to S3, won't be needed in OSS\ndef ya_token():\n    def get_token_from_file():\n        try:\n            with open(os.environ.get('YA_TOKEN_PATH', os.path.join(home_dir(), '.ya_token')), 'r') as f:\n                return f.read().strip()\n        except:\n            pass\n\n    return os.getenv('YA_TOKEN') or get_token_from_file()\n\n\nTOOLS_DIR = tool_root()\n\n\ndef uniq(size=6):\n    import string\n    import random\n\n    return ''.join(random.choice(string.ascii_lowercase + string.digits) for _ in range(size))\n\n\n_ssl_is_tuned = False\n\n\ndef _tune_ssl():\n    global _ssl_is_tuned\n    if _ssl_is_tuned:\n        return\n\n    try:\n        import ssl\n\n        ssl._create_default_https_context = ssl._create_unverified_context\n    except AttributeError:\n        pass\n\n    try:\n        import urllib3\n\n        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n    except (AttributeError, ImportError):\n        pass\n    _ssl_is_tuned = True\n\n\ndef _fetch(url, into):\n    import hashlib\n\n    _tune_ssl()\n\n    add_stage_start_to_environ('ya-script-download')\n\n    from urllib.request import urlopen\n    from urllib.request import Request\n    from urllib.parse import urlparse\n\n    request = Request(str(url))\n    # TODO: Remove when switched to S3 distribution\n    request.add_header('User-Agent', 'ya-bootstrap')\n    token = ya_token()\n    if token:\n        request.add_header('Authorization', 'OAuth {}'.format(token))\n\n    md5 = hashlib.md5()\n    sys.stderr.write('Downloading %s ' % url)\n    sys.stderr.flush()\n    conn = urlopen(request, timeout=10)\n    sys.stderr.write('[')\n    sys.stderr.flush()\n    try:\n        with open(into, 'wb') as f:\n            while True:\n                block = conn.read(1024 * 1024)\n                sys.stderr.write('.')\n                sys.stderr.flush()\n                if block:\n                    md5.update(block)\n                    f.write(block)\n                else:\n                    break\n        return md5.hexdigest()\n\n    finally:\n        sys.stderr.write('] ')\n        sys.stderr.flush()\n\n\ndef _atomic_fetch(url, into, md5):\n    tmp_dest = into + '.' + uniq()\n    try:\n        real_md5 = _fetch(url, tmp_dest)\n        if real_md5 != md5:\n            raise Exception('MD5 mismatched: %s differs from %s' % (real_md5, md5))\n        os.rename(tmp_dest, into)\n        sys.stderr.write('OK\\n')\n    except Exception as e:\n        sys.stderr.write('ERROR: ' + str(e) + '\\n')\n        raise\n    finally:\n        try:\n            os.remove(tmp_dest)\n        except OSError:\n            pass\n\n\ndef _extract(path, into):\n    import tarfile\n\n    tar = tarfile.open(path, errorlevel=2)\n\n    # tar.extractall() will try to set file ownership according to the attributes stored in the archive\n    # by calling TarFile.chown() method.\n    # As this information is hardly relevant to the point of deployment / extraction,\n    # it will just fail (python2) if ya is executed with root euid, or silently set non-existent numeric owner (python3)\n    # to the files being extracted.\n    # mock it with noop to retain current user ownership.\n    tar.chown = lambda *args, **kwargs: None\n\n    if sys.version_info >= (3, 12):\n        tar.extractall(path=into, filter='data')\n    else:\n        tar.extractall(path=into)\n    tar.close()\n\n\ndef _get(urls, md5):\n    dest_path = os.path.join(TOOLS_DIR, md5[:HASH_PREFIX])\n\n    if not os.path.exists(dest_path):\n        for iter in range(RETRIES):\n            try:\n                _atomic_fetch(urls[iter % len(urls)], dest_path, md5)\n                break\n            except Exception:\n                if iter + 1 == RETRIES:\n                    raise\n                else:\n                    time.sleep(iter)\n\n    return dest_path\n\n\ndef _get_dir(urls, md5, ya_name):\n    dest_dir = os.path.join(TOOLS_DIR, md5[:HASH_PREFIX] + '_d')\n\n    if os.path.isfile(os.path.join(dest_dir, ya_name)):\n        return dest_dir\n\n    try:\n        packed_path = _get(urls, md5)\n    except Exception:\n        if os.path.isfile(os.path.join(dest_dir, ya_name)):\n            return dest_dir\n        raise\n\n    add_stage_start_to_environ('ya-script-extract')\n\n    tmp_dir = dest_dir + '.' + uniq()\n    try:\n        try:\n            _extract(packed_path, tmp_dir)\n        except Exception:\n            if os.path.isfile(os.path.join(dest_dir, ya_name)):\n                return dest_dir\n            raise\n\n        try:\n            os.rename(tmp_dir, dest_dir)\n        except OSError as e:\n            import errno\n\n            if e.errno != errno.ENOTEMPTY:\n                raise\n\n        return dest_dir\n    finally:\n        import shutil\n\n        shutil.rmtree(tmp_dir, ignore_errors=True)\n        try:\n            os.remove(packed_path)\n        except Exception:\n            pass\n\n\ndef _mine_repo_root():\n    # We think that this script is located in the root of the repo.\n    return os.path.dirname(os.path.realpath(__file__))\n\n\ndef main():\n    if not os.path.exists(TOOLS_DIR):\n        os.makedirs(TOOLS_DIR)\n\n    result_args = sys.argv[1:]\n\n    meta = PLATFORM_MAP['data']\n    my_platform = platform.system().lower()\n    my_machine = platform.machine().lower()\n    if my_platform == 'linux':\n        if 'ppc64le' in platform.platform():\n            my_platform = 'linux-ppc64le'\n        elif 'aarch64' in platform.platform():\n            my_platform = 'linux-aarch64'\n        else:\n            my_platform = 'linux_musl'\n    if my_platform == 'darwin' and my_machine == 'arm64':\n        my_platform = 'darwin-arm64'\n\n    def _platform_key(target_platform):\n        \"\"\"match by max prefix length, prefer shortest\"\"\"\n\n        def _key_for_platform(platform):\n            return len(os.path.commonprefix([target_platform, platform])), -len(platform)\n\n        return _key_for_platform\n\n    best_key = max(meta.keys(), key=_platform_key(my_platform))\n    value = meta[best_key]\n\n    ya_name = {'win32': 'ya-bin.exe', 'win32-clang-cl': 'ya-bin.exe'}.get(best_key, 'ya-bin')  # XXX\n    ya_dir = _get_dir(value['urls'], value['md5'], ya_name)\n    add_stage_start_to_environ('ya-script-prepare')\n\n    # Popen `args` must have `str` type\n    ya_path = str(os.path.join(ya_dir, ya_name))\n\n    env = os.environ.copy()\n    if 'YA_SOURCE_ROOT' not in env:\n        src_root = _mine_repo_root()\n        if src_root is not None:\n            env['YA_SOURCE_ROOT'] = src_root\n\n    # Disable respawn for opensource/ya\n    if __file__.endswith('ya/opensource/ya'):\n        env['YA_NO_RESPAWN'] = os.environ.get('YA_NO_RESPAWN', '1')\n\n    for env_name in [\n        'LD_PRELOAD',\n        'Y_PYTHON_SOURCE_ROOT',\n    ]:\n        if env_name in os.environ:\n            sys.stderr.write(\n                \"Warn: {}='{}' is specified and may affect the correct operation of the ya\\n\".format(\n                    env_name, env[env_name]\n                )\n            )\n\n    if os.name == 'nt':\n        import subprocess\n\n        p = subprocess.Popen([ya_path] + result_args, env=env)\n        p.wait()\n        sys.exit(p.returncode)\n    else:\n        os.execve(ya_path, [ya_path] + result_args, env)\n\n\nif __name__ == '__main__':\n    try:\n        main()\n    except Exception as e:\n        sys.stderr.write('ERROR: ' + str(e) + '\\n')\n        from traceback import format_exc\n\n        sys.stderr.write(format_exc() + \"\\n\")\n        sys.exit(1)\n"
        },
        {
          "name": "ya.bat",
          "type": "blob",
          "size": 2.236328125,
          "content": "@echo off\r\nrem Ya Simple Windows launcher\r\nsetlocal\r\ncall :dbg Ya Simple Windows Launcher (Debug)\r\ncall :find_ya\r\nif ERRORLEVEL 1 exit /b 1\r\ncall :dbg Ya: %YA_BAT_REAL%\r\ncall :fix_env\r\ncall :find_python\r\nif ERRORLEVEL 1 exit /b 1\r\ncall :dbg Python: \"%YA_BAT_PYTHON%\"\r\ncall \"%YA_BAT_PYTHON%\" %YA_PY_KNOB% \"%YA_BAT_REAL%\" %*\r\nexit /b %ERRORLEVEL%\r\n\r\n:find_ya\r\ncall :dbg Searching for ya near ya.bat...\r\nset YA_BAT_REAL=%~dp0ya\r\nif exist \"%YA_BAT_REAL%\" exit /b 0\r\ncall :err Ya not found\r\nexit /b 1\r\n\r\n:fix_env\r\ncall :dbg Fixing environment...\r\nfor /f \"delims=: tokens=2\" %%F in ('chcp') do (\r\n    if \"%%F\" == \" 65001\" (\r\n        call :dbg -- Forcing I/O encoding for python: utf-8\r\n        set PYTHONIOENCODING=utf-8\r\n        set PYTHONUTF8=1\r\n    )\r\n)\r\nexit /b 0\r\n\r\n:find_python\r\ncall :dbg Searching for python in PATH...\r\nfor /f \"delims=\" %%F in ('where python 2^>nul') do (\r\n    call :test_python %%~sF\r\n    if not ERRORLEVEL 1 (\r\n        set YA_BAT_PYTHON=%%F\r\n        if /I \"%%F\" == \"C:\\Windows\\py.exe\" (\r\n            set YA_PY_KNOB=-3\r\n        )\r\n        exit /b 0\r\n    )\r\n)\r\ncall :dbg Searching for python in ftypes...\r\nfor /f delims^=^=^\"^ tokens^=2 %%F in ('ftype Python.File 2^>nul') do (\r\n    call :test_python %%F\r\n    if not ERRORLEVEL 1 (\r\n        set YA_BAT_PYTHON=%%F\r\n        if /I \"%%F\" == \"C:\\Windows\\py.exe\" (\r\n            set YA_PY_KNOB=-3\r\n        )\r\n        exit /b 0\r\n    )\r\n)\r\ncall :dbg Searching for python with Get-Command...\r\nfor /f \"delims=\" %%i in ('powershell -Command \"Get-Command python | Select-Object -ExpandProperty Source\"') do (\r\n    call :test_python %%i\r\n    if not ERRORLEVEL 1 (\r\n        set YA_BAT_PYTHON=%%i\r\n        exit /b 0\r\n    )\r\n)\r\ncall :err Python not found\r\nexit /b 1\r\n\r\n:test_python\r\ncall :dbg -- Checking python: %1\r\nif not exist %1 (\r\n    call :dbg ---- Not found\r\n    exit /b 1\r\n)\r\nfor /f %%P in ('%1 -c \"import os, sys; sys.stdout.write(os.name + '\\n')\" 2^>nul') do set YA_BAT_PYTHON_PLATFORM=%%P\r\nif not defined YA_BAT_PYTHON_PLATFORM (\r\n    call :dbg ---- Not runnable\r\n    exit /b 2\r\n)\r\nif not \"%YA_BAT_PYTHON_PLATFORM%\"==\"nt\" (\r\n    call :dbg ---- Non-windows: %YA_BAT_PYTHON_PLATFORM%\r\n    exit /b 3\r\n)\r\nexit /b 0\r\n\r\n:dbg\r\nif defined YA_BAT_DEBUG echo [ya.bat] %* 1>&2\r\nexit /b 0\r\n\r\n:err\r\necho [ya.bat] Error: %* 1>&2\r\nexit /b 0\r\n"
        },
        {
          "name": "ya.conf",
          "type": "blob",
          "size": 0.826171875,
          "content": "# Please keep this in sync with arcadia/ya.conf\n\nbuild_cache = true\nbuild_cache_conf = ['cas_logging=true', 'graph_info=true']\nbuild_cache_master = true\ncache_codec = ''\ncache_size = 150374182400\ncontent_uids = true\ndir_outputs = true\ndir_outputs_test_mode = true\ndump_debug_enabled = true\nfail_maven_export_with_tests = true\nincremental_build_dirs_cleanup = true\noauth_exchange_ssh_keys = true\nremove_implicit_data_path = true\nremove_result_node = true\ntools_cache = true\ntools_cache_master = true\nuse_atd_revisions_info = true\nuse_jstyle_server = true\nuse_command_file_in_testtool = true\n\n# ===== opensource only table params =====\n\n[host_platform_flags]\nOPENSOURCE = \"yes\"\nUSE_PREBUILT_TOOLS = \"no\"\nAPPLE_SDK_LOCAL = \"yes\"\nUSE_CLANG_CL = \"yes\"\n\n[flags]\nOPENSOURCE = \"yes\"\nUSE_PREBUILT_TOOLS = \"no\"\nAPPLE_SDK_LOCAL = \"yes\"\nUSE_CLANG_CL = \"yes\"\n"
        },
        {
          "name": "ydb",
          "type": "tree",
          "content": null
        },
        {
          "name": "yql",
          "type": "tree",
          "content": null
        },
        {
          "name": "yt",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}