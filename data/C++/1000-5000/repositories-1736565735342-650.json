{
  "metadata": {
    "timestamp": 1736565735342,
    "page": 650,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjY1MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "pytorch/executorch",
      "stars": 2384,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".buckconfig",
          "type": "blob",
          "size": 0.7021484375,
          "content": "[executorch]\n  is_oss = 1\n\n[buildfile]\n  name = TARGETS\n\n[repositories]\n  root = .\n  prelude = third-party/prelude\n  shim = shim\n\n[repository_aliases]\n  config = prelude\n  ovr_config = prelude\n  toolchains = shim\n  fbcode = shim\n  fbcode_macros = shim\n  fbsource = shim\n  buck = shim\n\n[cxx]\n  cxxflags = -g -std=c++17\n\n[parser]\n  target_platform_detector_spec = target:root//...->prelude//platforms:default target:shim//...->prelude//platforms:default\n\n# Limit the number of files that the buck daemon needs to monitor. If every\n# submodule is cloned recursively, some system can fail to build with \"OS file\n# watch limit reached\".\n[project]\n  ignore = \\\n      .git, \\\n      **/.git, \\\n      cmake-out, \\\n      pip-out\n"
        },
        {
          "name": ".ci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 6.609375,
          "content": "---\nLanguage:        Cpp\nAccessModifierOffset: -1\nAlignAfterOpenBracket: AlwaysBreak\nAlignArrayOfStructures: None\nAlignConsecutiveAssignments:\n  Enabled:         false\n  AcrossEmptyLines: false\n  AcrossComments:  false\n  AlignCompound:   false\n  AlignFunctionPointers: false\n  PadOperators:    true\nAlignConsecutiveBitFields:\n  Enabled:         false\n  AcrossEmptyLines: false\n  AcrossComments:  false\n  AlignCompound:   false\n  AlignFunctionPointers: false\n  PadOperators:    true\nAlignConsecutiveDeclarations:\n  Enabled:         false\n  AcrossEmptyLines: false\n  AcrossComments:  false\n  AlignCompound:   false\n  AlignFunctionPointers: false\n  PadOperators:    true\nAlignConsecutiveMacros:\n  Enabled:         false\n  AcrossEmptyLines: false\n  AcrossComments:  false\n  AlignCompound:   false\n  AlignFunctionPointers: false\n  PadOperators:    true\nAlignConsecutiveShortCaseStatements:\n  Enabled:         false\n  AcrossEmptyLines: false\n  AcrossComments:  false\n  AlignCaseColons: false\nAlignEscapedNewlines: Left\nAlignOperands:   DontAlign\nAlignTrailingComments:\n  Kind:            Never\n  OverEmptyLines:  0\nAllowAllArgumentsOnNextLine: true\nAllowAllParametersOfDeclarationOnNextLine: false\nAllowBreakBeforeNoexceptSpecifier: Never\nAllowShortBlocksOnASingleLine: Never\nAllowShortCaseLabelsOnASingleLine: false\nAllowShortCompoundRequirementOnASingleLine: true\nAllowShortEnumsOnASingleLine: true\nAllowShortFunctionsOnASingleLine: Empty\nAllowShortIfStatementsOnASingleLine: Never\nAllowShortLambdasOnASingleLine: All\nAllowShortLoopsOnASingleLine: false\nAlwaysBreakAfterDefinitionReturnType: None\nAlwaysBreakAfterReturnType: None\nAlwaysBreakBeforeMultilineStrings: true\nAlwaysBreakTemplateDeclarations: Yes\nAttributeMacros:\n  - __capability\nBinPackArguments: false\nBinPackParameters: false\nBitFieldColonSpacing: Both\nBraceWrapping:\n  AfterCaseLabel:  false\n  AfterClass:      false\n  AfterControlStatement: Never\n  AfterEnum:       false\n  AfterExternBlock: false\n  AfterFunction:   false\n  AfterNamespace:  false\n  AfterObjCDeclaration: false\n  AfterStruct:     false\n  AfterUnion:      false\n  BeforeCatch:     false\n  BeforeElse:      false\n  BeforeLambdaBody: false\n  BeforeWhile:     false\n  IndentBraces:    false\n  SplitEmptyFunction: true\n  SplitEmptyRecord: true\n  SplitEmptyNamespace: true\nBreakAdjacentStringLiterals: true\nBreakAfterAttributes: Leave\nBreakAfterJavaFieldAnnotations: false\nBreakArrays:     true\nBreakBeforeBinaryOperators: None\nBreakBeforeConceptDeclarations: Always\nBreakBeforeBraces: Attach\nBreakBeforeInlineASMColon: OnlyMultiline\nBreakBeforeTernaryOperators: true\nBreakConstructorInitializers: BeforeColon\nBreakInheritanceList: BeforeColon\nBreakStringLiterals: false\nColumnLimit:     80\nCommentPragmas:  '^ IWYU pragma:'\nCompactNamespaces: false\nConstructorInitializerIndentWidth: 4\nContinuationIndentWidth: 4\nCpp11BracedListStyle: true\nDerivePointerAlignment: false\nDisableFormat:   false\nEmptyLineAfterAccessModifier: Never\nEmptyLineBeforeAccessModifier: LogicalBlock\nExperimentalAutoDetectBinPacking: false\nFixNamespaceComments: true\nForEachMacros:\n  - FOR_EACH\n  - FOR_EACH_R\n  - FOR_EACH_RANGE\nIfMacros:\n  - KJ_IF_MAYBE\nIncludeBlocks:   Preserve\nIncludeCategories:\n  - Regex:           '^<.*\\.h(pp)?>'\n    Priority:        1\n    SortPriority:    0\n    CaseSensitive:   false\n  - Regex:           '^<.*'\n    Priority:        2\n    SortPriority:    0\n    CaseSensitive:   false\n  - Regex:           '.*'\n    Priority:        3\n    SortPriority:    0\n    CaseSensitive:   false\nIncludeIsMainRegex: '(Test)?$'\nIncludeIsMainSourceRegex: ''\nIndentAccessModifiers: false\nIndentCaseBlocks: false\nIndentCaseLabels: true\nIndentExternBlock: AfterExternBlock\nIndentGotoLabels: true\nIndentPPDirectives: None\nIndentRequiresClause: true\nIndentWidth:     2\nIndentWrappedFunctionNames: false\nInsertBraces:    false\nInsertNewlineAtEOF: false\nInsertTrailingCommas: None\nIntegerLiteralSeparator:\n  Binary:          0\n  BinaryMinDigits: 0\n  Decimal:         0\n  DecimalMinDigits: 0\n  Hex:             0\n  HexMinDigits:    0\nJavaScriptQuotes: Leave\nJavaScriptWrapImports: true\nKeepEmptyLinesAtTheStartOfBlocks: false\nKeepEmptyLinesAtEOF: false\nLambdaBodyIndentation: Signature\nLineEnding:      DeriveLF\nMacroBlockBegin: ''\nMacroBlockEnd:   ''\nMaxEmptyLinesToKeep: 1\nNamespaceIndentation: None\nObjCBinPackProtocolList: Auto\nObjCBlockIndentWidth: 2\nObjCBreakBeforeNestedBlockParam: true\nObjCSpaceAfterProperty: false\nObjCSpaceBeforeProtocolList: false\nPackConstructorInitializers: NextLine\nPenaltyBreakAssignment: 2\nPenaltyBreakBeforeFirstCallParameter: 1\nPenaltyBreakComment: 300\nPenaltyBreakFirstLessLess: 120\nPenaltyBreakOpenParenthesis: 0\nPenaltyBreakScopeResolution: 500\nPenaltyBreakString: 1000\nPenaltyBreakTemplateDeclaration: 10\nPenaltyExcessCharacter: 1000000\nPenaltyIndentedWhitespace: 0\nPenaltyReturnTypeOnItsOwnLine: 200\nPointerAlignment: Left\nPPIndentWidth:   -1\nQualifierAlignment: Leave\nReferenceAlignment: Pointer\nReflowComments:  true\nRemoveBracesLLVM: false\nRemoveParentheses: Leave\nRemoveSemicolon: false\nRequiresClausePosition: OwnLine\nRequiresExpressionIndentation: OuterScope\nSeparateDefinitionBlocks: Leave\nShortNamespaceLines: 1\nSkipMacroDefinitionBody: false\nSortIncludes:    CaseSensitive\nSortJavaStaticImport: Before\nSortUsingDeclarations: LexicographicNumeric\nSpaceAfterCStyleCast: false\nSpaceAfterLogicalNot: false\nSpaceAfterTemplateKeyword: true\nSpaceAroundPointerQualifiers: Default\nSpaceBeforeAssignmentOperators: true\nSpaceBeforeCaseColon: false\nSpaceBeforeCpp11BracedList: false\nSpaceBeforeCtorInitializerColon: true\nSpaceBeforeInheritanceColon: true\nSpaceBeforeJsonColon: false\nSpaceBeforeParens: ControlStatements\nSpaceBeforeParensOptions:\n  AfterControlStatements: true\n  AfterForeachMacros: true\n  AfterFunctionDefinitionName: false\n  AfterFunctionDeclarationName: false\n  AfterIfMacros:   true\n  AfterOverloadedOperator: false\n  AfterPlacementOperator: true\n  AfterRequiresInClause: false\n  AfterRequiresInExpression: false\n  BeforeNonEmptyParentheses: false\nSpaceBeforeRangeBasedForLoopColon: true\nSpaceBeforeSquareBrackets: false\nSpaceInEmptyBlock: false\nSpacesBeforeTrailingComments: 1\nSpacesInAngles:  Never\nSpacesInContainerLiterals: true\nSpacesInLineCommentPrefix:\n  Minimum:         1\n  Maximum:         -1\nSpacesInParens:  Never\nSpacesInParensOptions:\n  InCStyleCasts:   false\n  InConditionalStatements: false\n  InEmptyParentheses: false\n  Other:           false\nSpacesInSquareBrackets: false\nStandard:        Latest\nStatementAttributeLikeMacros:\n  - Q_EMIT\nStatementMacros:\n  - Q_UNUSED\n  - QT_REQUIRE_VERSION\nTabWidth:        8\nUseTab:          Never\nVerilogBreakBetweenInstancePorts: true\nWhitespaceSensitiveMacros:\n  - BOOST_PP_STRINGIZE\n  - CF_SWIFT_NAME\n  - NS_SWIFT_NAME\n  - PP_STRINGIZE\n  - STRINGIZE\n...\n"
        },
        {
          "name": ".clang-tidy",
          "type": "blob",
          "size": 0.212890625,
          "content": "---\n# NOTE there must be no spaces before the '-', so put the comma last.\nInheritParentConfig: true\nChecks: '\n-facebook-hte-BadMemberName,\n-facebook-hte-NullableReturn,\n'\nAnalyzeTemporaryDtors: false\nCheckOptions:\n...\n"
        },
        {
          "name": ".cmake-format.yaml",
          "type": "blob",
          "size": 0.0498046875,
          "content": "first_comment_is_literal: true\ndangle_parens: true\n"
        },
        {
          "name": ".cmakelintrc",
          "type": "blob",
          "size": 0.2392578125,
          "content": "filter=-convention/filename,-linelength,-package/consistency,-readability/logic,+readability/mixedcase,-readability/wonkycase,-syntax,-whitespace/eol,+whitespace/extra,-whitespace/indent,-whitespace/mismatch,-whitespace/newline,-whitespace/tabs\n"
        },
        {
          "name": ".flake8",
          "type": "blob",
          "size": 0.9697265625,
          "content": "[flake8]\nselect = B,C,E,F,P,W,B9,TOR0,TOR1,TOR2\nmax-line-length = 80\nignore =\n    # Black conflicts and overlaps.\n    B950,\n    E111,\n    E115,\n    E117,\n    E121,\n    E122,\n    E123,\n    E124,\n    E125,\n    E126,\n    E127,\n    E128,\n    E129,\n    E131,\n    E201,\n    E202,\n    E203,\n    E221,\n    E222,\n    E225,\n    E226,\n    E227,\n    E231,\n    E241,\n    E251,\n    E252,\n    E261,\n    E262,\n    E265,\n    E271,\n    E272,\n    E301,\n    E302,\n    E303,\n    E305,\n    E306,\n    E501,\n    E502,\n    E701,\n    E702,\n    E703,\n    E704,\n    W291,\n    W292,\n    W293,\n    W391,\n    W504,\n\n    # Too opinionated.\n    E265,\n    E266,\n    E402,\n    E722,\n    B001,\n    P207,\n    B003,\n    P208,\n    C403,\n    W503,\n\n    # Bugbear has opinions: https://github.com/PyCQA/flake8-bugbear#opinionated-warnings\n    B904,\n    B905,\n    B906,\n    B907,\nexclude =\n    ./.git,\n    ./backends/xnnpack/third-party,\n    ./build,\n    ./configurations,\n    ./docs,\n    ./third_party,\n    *.pyi\n\nmax-complexity = 12\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.42578125,
          "content": ".hypothesis\nbuck-out/\n.mypy_cache/\nbuck2-bin/\ncmake-out*\n.DS_Store\ncmake-android-out/\ncmake-out-android/\ncmake-ios-out/\nethos-u-scratch/\nexecutorch.egg-info\npip-out/\n__pycache__/\n\n# Any exported models and profiling outputs\n*.pte\n*.model\n!test_tiktoken_tokenizer.model\n*.bin\n!test_bpe_tokenizer.bin\n\n# Editor temporaries\n*.swa\n*.swb\n*.swc\n*.swd\n*.swe\n*.swf\n*.swg\n*.swh\n*.swi\n*.swj\n*.swk\n*.swl\n*.swm\n*.swn\n*.swo\n*.swp\n*~\n.~lock.*\n*.idea\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 3.2900390625,
          "content": "[submodule \"backends/arm/third-party/ethos-u-core-driver\"]\n\tpath = backends/arm/third-party/ethos-u-core-driver\n\turl = https://github.com/pytorch-labs/ethos-u-core-driver-mirror\n[submodule \"backends/arm/third-party/serialization_lib\"]\n\tpath = backends/arm/third-party/serialization_lib\n\turl = https://github.com/pytorch-labs/tosa_serialization_lib-mirror\n[submodule \"backends/vulkan/third-party/Vulkan-Headers\"]\n\tpath = backends/vulkan/third-party/Vulkan-Headers\n\turl = https://github.com/KhronosGroup/Vulkan-Headers\n[submodule \"backends/vulkan/third-party/VulkanMemoryAllocator\"]\n\tpath = backends/vulkan/third-party/VulkanMemoryAllocator\n\turl = https://github.com/GPUOpen-LibrariesAndSDKs/VulkanMemoryAllocator.git\n[submodule \"backends/vulkan/third-party/volk\"]\n\tpath = backends/vulkan/third-party/volk\n\turl = https://github.com/zeux/volk\n[submodule \"backends/xnnpack/third-party/FP16\"]\n\tpath = backends/xnnpack/third-party/FP16\n\turl = https://github.com/Maratyszcza/FP16.git\n[submodule \"backends/xnnpack/third-party/FXdiv\"]\n\tpath = backends/xnnpack/third-party/FXdiv\n\turl = https://github.com/Maratyszcza/FXdiv.git\n[submodule \"backends/xnnpack/third-party/XNNPACK\"]\n\tpath = backends/xnnpack/third-party/XNNPACK\n\turl = https://github.com/google/XNNPACK.git\n[submodule \"backends/xnnpack/third-party/cpuinfo\"]\n\tpath = backends/xnnpack/third-party/cpuinfo\n\turl = https://github.com/pytorch/cpuinfo.git\n[submodule \"backends/xnnpack/third-party/pthreadpool\"]\n\tpath = backends/xnnpack/third-party/pthreadpool\n\turl = https://github.com/Maratyszcza/pthreadpool.git\n[submodule \"extension/llm/third-party/abseil-cpp\"]\n\tpath = extension/llm/third-party/abseil-cpp\n\turl = https://github.com/abseil/abseil-cpp.git\n[submodule \"extension/llm/third-party/re2\"]\n\tpath = extension/llm/third-party/re2\n\turl = https://github.com/google/re2.git\n[submodule \"extension/llm/third-party/sentencepiece\"]\n\tpath = extension/llm/third-party/sentencepiece\n\turl = https://github.com/google/sentencepiece.git\n[submodule \"kernels/optimized/third-party/eigen\"]\n\tpath = kernels/optimized/third-party/eigen\n\turl = https://gitlab.com/libeigen/eigen.git\n[submodule \"third-party/flatbuffers\"]\n\tpath = third-party/flatbuffers\n\turl = https://github.com/google/flatbuffers.git\n[submodule \"third-party/flatcc\"]\n\tpath = third-party/flatcc\n\turl = https://github.com/dvidelabs/flatcc.git\n[submodule \"third-party/gflags\"]\n\tpath = third-party/gflags\n\turl = https://github.com/gflags/gflags.git\n[submodule \"third-party/googletest\"]\n\tpath = third-party/googletest\n\turl = https://github.com/google/googletest.git\n[submodule \"third-party/ios-cmake\"]\n\tpath = third-party/ios-cmake\n\turl = https://github.com/leetal/ios-cmake\n[submodule \"backends/cadence/hifi/third-party/nnlib/nnlib-hifi4\"]\n\tpath = backends/cadence/hifi/third-party/nnlib/nnlib-hifi4\n\turl = https://github.com/foss-xtensa/nnlib-hifi4.git\n[submodule \"third-party/prelude\"]\n\tpath = third-party/prelude\n\turl = https://github.com/facebook/buck2-prelude.git\n[submodule \"third-party/pybind11\"]\n\tpath = third-party/pybind11\n\turl = https://github.com/pybind/pybind11.git\n[submodule \"backends/cadence/fusion_g3/third-party/nnlib/nnlib-FusionG3\"]\n\tpath = backends/cadence/fusion_g3/third-party/nnlib/nnlib-FusionG3\n\turl = https://github.com/foss-xtensa/nnlib-FusionG3.git\n[submodule \"third-party/ao\"]\n\tpath = third-party/ao\n\turl = https://github.com/pytorch/ao.git\n"
        },
        {
          "name": ".lintrunner.toml",
          "type": "blob",
          "size": 6.92578125,
          "content": "merge_base_with = \"origin/main\"\n\n[[linter]]\ncode = 'FLAKE8'\ninclude_patterns = ['**/*.py']\nexclude_patterns = [\n    'third-party/**',\n    '**/third-party/**',\n    '.github/scripts/**',\n    'exir/serde/**',\n]\ncommand = [\n    'python',\n    '-m',\n    'lintrunner_adapters',\n    'run',\n    'flake8_linter',\n    '--',\n    '@{{PATHSFILE}}'\n]\ninit_command = [\n    'python',\n    '-m',\n    'lintrunner_adapters',\n    'run',\n    'pip_init',\n    '--dry-run={{DRYRUN}}',\n    '--requirement=requirements-lintrunner.txt',\n]\n\n# Black + usort\n[[linter]]\ncode = 'UFMT'\ninclude_patterns = [\n    '**/*.py',\n    '**/*.pyi',\n]\nexclude_patterns = [\n    'third-party/**',\n    '**/third-party/**',\n    'exir/serde/**',\n]\ncommand = [\n    'python',\n    '-m',\n    'lintrunner_adapters',\n    'run',\n    'ufmt_linter',\n    '--',\n    '@{{PATHSFILE}}'\n]\ninit_command = [\n    'python',\n    '-m',\n    'lintrunner_adapters',\n    'run',\n    'pip_init',\n    '--dry-run={{DRYRUN}}',\n    '--no-black-binary',\n    '--requirement=requirements-lintrunner.txt',\n]\nis_formatter = true\n\n#CLANGFORMAT\n[[linter]]\ncode = 'CLANGFORMAT'\ninclude_patterns = [\n    '**/*.h',\n    '**/*.cpp',\n]\nexclude_patterns = [\n    'third-party/**',\n    '**/third-party/**',\n    # NB: Objective-C is not supported\n    'examples/apple/**',\n    'examples/demo-apps/apple_ios/**',\n    'examples/demo-apps/react-native/rnllama/ios/**',\n    # File contains @generated\n    'extension/llm/custom_ops/spinquant/fast_hadamard_transform_special.h',\n    'extension/llm/custom_ops/spinquant/test/fast_hadamard_transform_special_unstrided_cpu.h',\n]\ncommand = [\n    'python',\n    '-m',\n    'lintrunner_adapters',\n    'run',\n    'clangformat_linter',\n    '--binary=clang-format',\n    '--fallback',\n    '--',\n    '@{{PATHSFILE}}'\n]\ninit_command = [\n    'python',\n    '-m',\n    'lintrunner_adapters',\n    'run',\n    'pip_init',\n    '--dry-run={{DRYRUN}}',\n    '--requirement=requirements-lintrunner.txt',\n]\nis_formatter = true\n\n[[linter]]\ncode = 'CMAKE'\ninclude_patterns = [\n    \"**/*.cmake\",\n    \"**/*.cmake.in\",\n    \"**/CMakeLists.txt\",\n]\nexclude_patterns = [\n    'third-party/**',\n    '**/third-party/**',\n]\ncommand = [\n    'python',\n    '-m',\n    'lintrunner_adapters',\n    'run',\n    'cmake_linter',\n    '--config=.cmakelintrc',\n    '--',\n    '@{{PATHSFILE}}',\n]\ninit_command = [\n    'python',\n    '-m',\n    'lintrunner_adapters',\n    'run',\n    'pip_init',\n    '--dry-run={{DRYRUN}}',\n    '--requirement=requirements-lintrunner.txt',\n]\n\n[[linter]]\ncode = 'ETCAPITAL'\ninclude_patterns = [\n    '**/*.py',\n    '**/*.pyi',\n    '**/*.h',\n    '**/*.cpp',\n    '**/*.md',\n    '**/*.rst',\n]\nexclude_patterns = [\n    'third-party/**',\n    '**/third-party/**',\n]\ncommand = [\n    'python',\n    '-m',\n    'lintrunner_adapters',\n    'run',\n    'grep_linter',\n    # Exclude \"ExecuTorch\" pattern within URLs\n    '--pattern= Executorch(?!\\\\W*(://|\\\\.[a-z]{2,}))\\\\W+',\n    '--linter-name=ExecuTorchCapitalization',\n    '--error-name=Incorrect capitalization for ExecuTorch',\n    \"\"\"--error-description=\n    Please use ExecuTorch with capital T for consistency.\n    https://fburl.com/workplace/nsx6hib2\n    \"\"\",\n    '--',\n    '@{{PATHSFILE}}',\n]\n\n[[linter]]\ncode = 'NEWLINE'\ninclude_patterns = ['**']\nexclude_patterns = [\n    'third-party/**',\n    '**/third-party/**',\n    '**/*.png',\n    '**/*.webp',\n    '**/*.jpeg',\n    '**/*.mp4',\n    '**/*.pte',\n    '**/*.pth',\n    '**/*.bin',\n    '**/*.patch',\n    '**/*.svg',\n    '**/*.bat',\n    '**/*.jpg',\n    '**/*.jar',\n    '**/*.gif',\n    # File contains @generated\n    'extension/llm/custom_ops/spinquant/fast_hadamard_transform_special.h',\n    'extension/llm/custom_ops/spinquant/test/fast_hadamard_transform_special_unstrided_cpu.h',\n]\ncommand = [\n    'python',\n    '-m',\n    'lintrunner_adapters',\n    'run',\n    'newlines_linter',\n    '--',\n    '@{{PATHSFILE}}',\n]\nis_formatter = true\n\n[[linter]]\ncode = 'NOSTDINC'\ninclude_patterns = [\n    \"**/*.c\",\n    \"**/*.cpp\",\n    \"**/*.h\",\n    \"**/*.hpp\",\n]\nexclude_patterns = [\n    '**/devtools/**',\n    '**/test/**',\n    '**/testing_util/**',\n    '**/third-party/**',\n    'backends/**',\n    'devtools/**',\n    'examples/**',\n    'extension/**',\n    'kernels/optimized/**',\n    'scripts/**',\n    'third-party/**',\n    'util/**',\n]\ncommand = [\n    'python',\n    '-m',\n    'lintrunner_adapters',\n    'run',\n    'grep_linter',\n    '--pattern=([^\\\\S\\r\\n]*#include\\s*<(deque|exception|forward_list|functional|list|map|multimap|multiset|priority_queue|queue|set|stack|string|unordered_map|unordered_multimap|unordered_multiset|unordered_set|vector)>)',\n    '--linter-name=NOSTDINC',\n    '--error-name=Standard C++ container include in core',\n    \"\"\"--error-description=\\\n        Standard library containers should not be included in ExecuTorch core \\\n        because they may call malloc, which is not allowed in core. \\\n    \"\"\",\n    '--',\n    '@{{PATHSFILE}}',\n]\n\n[[linter]]\ncode = 'NOTORCHINC'\ninclude_patterns = [\n    \"**/*.c\",\n    \"**/*.cpp\",\n    \"**/*.h\",\n    \"**/*.hpp\",\n]\nexclude_patterns = [\n    '**/devtools/**',\n    '**/fb/**',\n    '**/test/**',\n    '**/tests/**',\n    '**/testing_util/**',\n    '**/third-party/**',\n    'backends/**',\n    'codegen/templates/RegisterDispatchKeyCustomOps.cpp',\n    'codegen/templates/RegisterSchema.cpp',\n    'devtools/**',\n    'examples/**',\n    'exir/verification/bindings.cpp',\n    'extension/**',\n    'kernels/optimized/**',\n    'runtime/core/exec_aten/**',\n    'runtime/executor/tensor_parser_aten.cpp',\n    'scripts/**',\n    'test/**',\n    'third-party/**',\n    'util/**',\n]\ncommand = [\n    'python',\n    '-m',\n    'lintrunner_adapters',\n    'run',\n    'grep_linter',\n    '--pattern=#include\\s+[<\"](aten/|ATen/|torch/)',\n    '--linter-name=NOTORCHINC',\n    '--error-name=ATen or torch include',\n    \"\"\"--error-description=\\\n        PyTorch includes in ExecuTorch core are prohibited to prevent \\\n        accidentally breaking core's requirements; please make sure this \\\n        header complies (e.g., no streams/malloc/syscalls) and then include \\\n        a patch to update this linter.\\\n    \"\"\",\n    '--',\n    '@{{PATHSFILE}}',\n]\n\n[[linter]]\ncode = 'MYPY'\ninclude_patterns = [\n    # TODO(https://github.com/pytorch/executorch/issues/7441): Gradually start enabling all folders.\n    # 'backends/**/*.py',\n    'build/**/*.py',\n    'codegen/**/*.py',\n    # 'devtools/**/*.py',\n    'docs/**/*.py',\n    # 'examples/**/*.py',\n    # 'exir/**/*.py',\n    # 'extension/**/*.py',\n    'kernels/**/*.py',\n    'profiler/**/*.py',\n    'runtime/**/*.py',\n    'scripts/**/*.py',\n    'test/**/*.py',\n    'util/**/*.py',\n    '*.py',\n]\nexclude_patterns = [\n    'third-party/**',\n    '**/third-party/**',\n    'scripts/check_binary_dependencies.py',\n    'profiler/test/test_profiler_e2e.py',\n]\ncommand = [\n    'python',\n    '-m',\n    'lintrunner_adapters',\n    'run',\n    'mypy_linter',\n    '--config=.mypy.ini',\n    '--show-disable',\n    '--',\n    '--explicit-package-bases',\n    '@{{PATHSFILE}}'\n]\ninit_command = [\n    'python',\n    '-m',\n    'lintrunner_adapters',\n    'run',\n    'pip_init',\n    '--dry-run={{DRYRUN}}',\n    '--requirement=requirements-lintrunner.txt',\n]\n"
        },
        {
          "name": ".mypy.ini",
          "type": "blob",
          "size": 1.591796875,
          "content": "[mypy]\nallow_redefinition = True\nwarn_unused_configs = True\nwarn_redundant_casts = True\nshow_error_codes = True\nshow_column_numbers = True\ndisallow_untyped_decorators = True\nfollow_imports = normal\nlocal_partial_types = True\nenable_error_code = possibly-undefined\nwarn_unused_ignores = False\n\nfiles =\n    backends,\n    codegen,\n    devtools\n    examples,\n    exir,\n    extension,\n    kernels,\n    profiler,\n    runtime,\n    scripts,\n    test,\n    util\n\nmypy_path = executorch\n\n[mypy-executorch.backends.*]\nfollow_untyped_imports = True\n\n[mypy-executorch.codegen.*]\nfollow_untyped_imports = True\n\n[mypy-executorch.devtools.*]\nfollow_untyped_imports = True\n\n[mypy-executorch.exir.*]\nfollow_untyped_imports = True\n\n[mypy-executorch.extension.*]\nfollow_untyped_imports = True\n\n[mypy-executorch.kernels.*]\nfollow_untyped_imports = True\n\n[mypy-executorch.profiler.*]\nfollow_untyped_imports = True\n\n[mypy-executorch.runtime.*]\nfollow_untyped_imports = True\n\n[mypy-executorch.test.*]\nfollow_untyped_imports = True\n\n[mypy-functorch.*]\nfollow_untyped_imports = True\n\n[mypy-requests.*]\nfollow_untyped_imports = True\n\n[mypy-torchgen.*]\nfollow_untyped_imports = True\n\n[mypy-buck_util]\nignore_missing_imports = True\n\n[mypy-docutils.*]\nignore_missing_imports = True\n\n[mypy-pandas]\nignore_missing_imports = True\n\n[mypy-pytorch_sphinx_theme]\nignore_missing_imports = True\n\n[mypy-ruamel]\nignore_missing_imports = True\n\n[mypy-setuptools.*]\nignore_missing_imports = True\n\n[mypy-sphinx.*]\nignore_missing_imports = True\n\n[mypy-tomllib]\nignore_missing_imports = True\n\n[mypy-yaml]\nignore_missing_imports = True\n\n[mypy-zstd]\nignore_missing_imports = True\n"
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 25.62890625,
          "content": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n# All rights reserved.\n#\n# This source code is licensed under the BSD-style license found in the\n# LICENSE file in the root directory of this source tree.\n\n#\n# Simple CMake build system for runtime components.\n#\n# ### One-time setup ###\n#\n# Configure the CMake build system. It's good practice to do this whenever\n# cloning or pulling the upstream repo. Once this is done, you don't need to do\n# it again until you pull from the upstream repo again.\n#\n# NOTE: Build options can be configured by passing arguments to cmake. For\n# example, to enable the EXECUTORCH_BUILD_XNNPACK option, change the cmake\n# command to 'cmake -DEXECUTORCH_BUILD_XNNPACK=ON ..'.\n#[[\n  (rm -rf cmake-out \\\n    && mkdir cmake-out \\\n    && cd cmake-out \\\n    && cmake ..)\n]]\n#\n# ### Build ###\n#\n# NOTE: The `-j` argument specifies how many jobs/processes to use when\n# building, and tends to speed up the build significantly. It's typical to use\n# \"core count + 1\" as the `-j` value.\n# ~~~\n# cmake --build cmake-out -j9\n# ~~~\n#\n# ### Editing this file ###\n#\n# This file should be formatted with\n# ~~~\n# cmake-format -i CMakeLists.txt\n# ~~~\n# It should also be cmake-lint clean.\n#\n\ncmake_minimum_required(VERSION 3.19)\nproject(executorch)\ninclude(build/Utils.cmake)\ninclude(CMakeDependentOption)\n\nset(CMAKE_EXPORT_COMPILE_COMMANDS ON)\n\nif(NOT CMAKE_CXX_STANDARD)\n  set(CMAKE_CXX_STANDARD 17)\nendif()\n\nif(NOT CMAKE_BUILD_TYPE)\n  set(CMAKE_BUILD_TYPE Debug)\nendif()\n\n# Setup RPATH.\n# See https://gitlab.kitware.com/cmake/community/-/wikis/doc/cmake/RPATH-handling\n# Use separate rpaths during build and install phases\nset(CMAKE_SKIP_BUILD_RPATH OFF)\n# Don't use the install-rpath during the build phase\nset(CMAKE_BUILD_WITH_INSTALL_RPATH ON)\n# Automatically add all linked folders that are NOT in the build directory to\n# the rpath (per library?)\n# TODO: Doesn't work for us right now because we are not installing .so's into the\n# correct locations. For example we have libcustom_ops_aot_lib.so depending on\n# _portable_lib.so, which was eventually put under <site-packages>/executorch/extension/pybindings/\n# but this rpath is not automatically added because at build time it seems `portable_lib`\n# is being built under the same directory, so no extra rpath is being added. To\n# properly fix this we need to install `portable_lib` into the correct path.\nset(CMAKE_INSTALL_RPATH_USE_LINK_PATH ON)\n# ------------------------------ OPTIONS -------------------------------------\n# WARNING: Please don't add example specific options in this CMakeLists.txt.\n# Instead please use `find_package(executorch REQUIRED)` in the example\n# directory and add a new executable in the example `CMakeLists.txt`.\n\n# _default_release_disabled_options: default value for options that should be\n# disabled in Release mode by default. Users can still manually enable them,\n# though.\nif(CMAKE_BUILD_TYPE STREQUAL \"Release\")\n  set(_default_release_disabled_options OFF)\nelse()\n  set(_default_release_disabled_options ON)\nendif()\n\n# Let users override which PAL defaults to use.\n#\n# TODO(dbort): Add another option that lets users point to a specific source\n# file; if set, would override the default option.\nset(EXECUTORCH_PAL_DEFAULT\n    \"posix\"\n    CACHE STRING\n          \"Which PAL default implementation to use: one of {posix, minimal}\"\n)\n\noption(EXECUTORCH_ENABLE_LOGGING \"Build with ET_LOG_ENABLED\"\n       ${_default_release_disabled_options}\n)\nif(NOT EXECUTORCH_ENABLE_LOGGING)\n  # Avoid pulling in the logging strings, which can be large. Note that this\n  # will set the compiler flag for all targets in this directory, and for all\n  # subdirectories included after this point.\n  add_definitions(-DET_LOG_ENABLED=0)\nendif()\n\n# Configure log level. Must be one of debug, info, error, fatal.\nset(EXECUTORCH_LOG_LEVEL\n    \"Info\"\n    CACHE STRING \"Build with the given ET_MIN_LOG_LEVEL value\"\n)\nstring(TOLOWER \"${EXECUTORCH_LOG_LEVEL}\" LOG_LEVEL_LOWER)\nif(LOG_LEVEL_LOWER STREQUAL \"debug\")\n  add_definitions(-DET_MIN_LOG_LEVEL=Debug)\nelseif(LOG_LEVEL_LOWER STREQUAL \"info\")\n  add_definitions(-DET_MIN_LOG_LEVEL=Info)\nelseif(LOG_LEVEL_LOWER STREQUAL \"error\")\n  add_definitions(-DET_MIN_LOG_LEVEL=Error)\nelseif(LOG_LEVEL_LOWER STREQUAL \"fatal\")\n  add_definitions(-DET_MIN_LOG_LEVEL=Fatal)\nelse()\n  message(\n    SEND_ERROR\n      \"Unknown log level \\\"${EXECUTORCH_LOG_LEVEL}\\\". Expected one of Debug, \"\n      + \"Info, Error, or Fatal.\"\n  )\nendif()\n\noption(EXECUTORCH_ENABLE_PROGRAM_VERIFICATION\n       \"Build with ET_ENABLE_PROGRAM_VERIFICATION\"\n       ${_default_release_disabled_options}\n)\nif(NOT EXECUTORCH_ENABLE_PROGRAM_VERIFICATION)\n  # Avoid pulling in the flatbuffer data verification logic, which can add about\n  # 20kB. Note that this will set the compiler flag for all targets in this\n  # directory, and for all subdirectories included after this point.\n  add_definitions(-DET_ENABLE_PROGRAM_VERIFICATION=0)\nendif()\n\noption(EXECUTORCH_ENABLE_EVENT_TRACER \"Build with ET_EVENT_TRACER_ENABLED=ON\"\n       OFF\n)\nif(EXECUTORCH_ENABLE_EVENT_TRACER)\n  add_definitions(-DET_EVENT_TRACER_ENABLED)\nendif()\n\n# -ffunction-sections -fdata-sections: breaks function and data into sections so\n# they can be properly gc'd. -s: strip symbol. -fno-exceptions -fno-rtti:\n# disables exceptions and runtime type.\nset(CMAKE_CXX_FLAGS_RELEASE\n    \"-ffunction-sections -fdata-sections -fno-exceptions -fno-rtti\"\n)\nif(CMAKE_CXX_COMPILER_ID STREQUAL \"GNU\")\n  set(CMAKE_CXX_FLAGS_RELEASE \"${CMAKE_CXX_FLAGS_RELEASE} -s\")\nendif()\n\noption(OPTIMIZE_SIZE \"Build executorch runtime optimizing for binary size\" OFF)\nif(OPTIMIZE_SIZE)\n  # -Os: Optimize for size\n  set(CMAKE_CXX_FLAGS_RELEASE \"-Os ${CMAKE_CXX_FLAGS_RELEASE}\")\nelse()\n  # -O2: Moderate opt.\n  set(CMAKE_CXX_FLAGS_RELEASE \"-O2 ${CMAKE_CXX_FLAGS_RELEASE}\")\nendif()\n\nset(CMAKE_CXX_FLAGS_DEBUG \"-O0 -g\")\n\noption(EXECUTORCH_BUILD_ANDROID_JNI \"Build Android JNI\" OFF)\n\noption(EXECUTORCH_BUILD_ARM_BAREMETAL\n       \"Build the Arm Baremetal flow for Cortex-M and Ethos-U\" OFF\n)\n\noption(EXECUTORCH_BUILD_COREML \"Build the Core ML backend\" OFF)\n\noption(EXECUTORCH_BUILD_KERNELS_CUSTOM \"Build the custom kernels\" OFF)\n\noption(EXECUTORCH_BUILD_KERNELS_CUSTOM_AOT \"Build the custom ops lib for AOT\"\n       OFF\n)\n\noption(EXECUTORCH_BUILD_EXTENSION_DATA_LOADER \"Build the Data Loader extension\"\n       OFF\n)\n\noption(EXECUTORCH_BUILD_EXTENSION_MODULE \"Build the Module extension\" OFF)\n\noption(EXECUTORCH_BUILD_EXTENSION_RUNNER_UTIL \"Build the Runner Util extension\"\n       OFF\n)\n\noption(EXECUTORCH_BUILD_EXTENSION_TENSOR \"Build the Tensor extension\" OFF)\n\noption(EXECUTORCH_BUILD_EXTENSION_TRAINING \"Build the training extension\" OFF)\n\noption(EXECUTORCH_BUILD_MPS \"Build the MPS backend\" OFF)\n\noption(EXECUTORCH_BUILD_NEURON \"Build the backends/mediatek directory\" OFF)\n\noption(EXECUTORCH_BUILD_PYBIND \"Build the Python Bindings\" OFF)\n\noption(EXECUTORCH_BUILD_QNN \"Build the Qualcomm backend\" OFF)\n\noption(EXECUTORCH_BUILD_KERNELS_OPTIMIZED \"Build the optimized kernels\" OFF)\n\noption(EXECUTORCH_BUILD_KERNELS_QUANTIZED \"Build the quantized kernels\" OFF)\n\noption(EXECUTORCH_BUILD_DEVTOOLS \"Build the ExecuTorch Developer Tools\")\n\noption(EXECUTORCH_BUILD_TESTS \"Build CMake-based unit tests\" OFF)\n\noption(EXECUTORCH_NNLIB_OPT \"Build Cadence backend Hifi nnlib kernel\" OFF)\n\noption(EXECUTORCH_CADENCE_CPU_RUNNER \"Build Cadence backend CPU runner\" OFF)\n\noption(EXECUTORCH_BUILD_SIZE_TEST \"Build the size test\" OFF)\n\noption(EXECUTORCH_BUILD_XNNPACK \"Build the XNNPACK backend\" OFF)\n\noption(EXECUTORCH_BUILD_VULKAN \"Build the Vulkan backend\" OFF)\n\noption(BUILD_EXECUTORCH_PORTABLE_OPS \"Build portable_ops library\" ON)\n\noption(EXECUTORCH_USE_DL \"Use libdl library\" ON)\n\noption(EXECUTORCH_BUILD_CADENCE \"Build the Cadence DSP backend\" OFF)\n\n#\n# pthreadpool: build pthreadpool library. Disable on unsupported platforms\n#\ncmake_dependent_option(\n  EXECUTORCH_BUILD_PTHREADPOOL \"Build pthreadpool library.\" ON\n  \"NOT EXECUTORCH_BUILD_ARM_BAREMETAL\" OFF\n)\n\n#\n# cpuinfo: build cpuinfo library. Disable on unsupported platforms\n#\ncmake_dependent_option(\n  EXECUTORCH_BUILD_CPUINFO \"Build cpuinfo library.\" ON\n  \"NOT EXECUTORCH_BUILD_ARM_BAREMETAL\" OFF\n)\n\nif(EXECUTORCH_BUILD_KERNELS_CUSTOM_AOT)\n  set(EXECUTORCH_BUILD_EXTENSION_TENSOR ON)\n  set(EXECUTORCH_BUILD_KERNELS_CUSTOM ON)\nendif()\n\nif(EXECUTORCH_BUILD_KERNELS_CUSTOM)\n  set(EXECUTORCH_BUILD_KERNELS_OPTIMIZED ON)\nendif()\n\nif(NOT DEFINED FXDIV_SOURCE_DIR)\n  set(ORIGINAL_CMAKE_POSITION_INDEPENDENT_CODE_FLAG\n    ${CMAKE_POSITION_INDEPENDENT_CODE}\n  )\n  set(FXDIV_SOURCE_DIR \"backends/xnnpack/third-party/FXdiv\")\n  add_subdirectory(\"${FXDIV_SOURCE_DIR}\")\n  set(CMAKE_POSITION_INDEPENDENT_CODE\n      ${ORIGINAL_CMAKE_POSITION_INDEPENDENT_CODE_FLAG}\n  )\nendif()\n\nif(EXECUTORCH_BUILD_CPUINFO)\n  # --- cpuinfo\n  set(ORIGINAL_CMAKE_POSITION_INDEPENDENT_CODE_FLAG\n      ${CMAKE_POSITION_INDEPENDENT_CODE}\n  )\n  set(CMAKE_POSITION_INDEPENDENT_CODE ON)\n  set(CPUINFO_SOURCE_DIR \"backends/xnnpack/third-party/cpuinfo\")\n  set(CPUINFO_BUILD_TOOLS\n      OFF\n      CACHE BOOL \"\"\n  )\n  set(CPUINFO_BUILD_UNIT_TESTS\n      OFF\n      CACHE BOOL \"\"\n  )\n  set(CPUINFO_BUILD_MOCK_TESTS\n      OFF\n      CACHE BOOL \"\"\n  )\n  set(CPUINFO_BUILD_BENCHMARKS\n      OFF\n      CACHE BOOL \"\"\n  )\n  set(CPUINFO_LIBRARY_TYPE\n      \"static\"\n      CACHE STRING \"\"\n  )\n  set(CPUINFO_LOG_LEVEL\n      \"error\"\n      CACHE STRING \"\"\n  )\n  set(CLOG_SOURCE_DIR \"${CPUINFO_SOURCE_DIR}/deps/clog\")\n  add_subdirectory(\"${CPUINFO_SOURCE_DIR}\")\n  set(CMAKE_POSITION_INDEPENDENT_CODE\n      ${ORIGINAL_CMAKE_POSITION_INDEPENDENT_CODE_FLAG}\n  )\nendif()\n\nif(EXECUTORCH_BUILD_PTHREADPOOL)\n  # --- pthreadpool\n  set(ORIGINAL_CMAKE_POSITION_INDEPENDENT_CODE_FLAG\n      ${CMAKE_POSITION_INDEPENDENT_CODE}\n  )\n  set(CMAKE_POSITION_INDEPENDENT_CODE ON)\n  set(PTHREADPOOL_SOURCE_DIR \"backends/xnnpack/third-party/pthreadpool\")\n  set(PTHREADPOOL_BUILD_TESTS\n      OFF\n      CACHE BOOL \"\"\n  )\n  set(PTHREADPOOL_BUILD_BENCHMARKS\n      OFF\n      CACHE BOOL \"\"\n  )\n  set(PTHREADPOOL_LIBRARY_TYPE\n      \"static\"\n      CACHE STRING \"\"\n  )\n  set(PTHREADPOOL_ALLOW_DEPRECATED_API\n      ON\n      CACHE BOOL \"\"\n  )\n  if(APPLE)\n    set(PTHREADPOOL_SYNC_PRIMITIVE\n        \"condvar\"\n        CACHE STRING \"\"\n    )\n  endif()\n  add_subdirectory(\"${PTHREADPOOL_SOURCE_DIR}\")\n  set(CMAKE_POSITION_INDEPENDENT_CODE\n      ${ORIGINAL_CMAKE_POSITION_INDEPENDENT_CODE_FLAG}\n  )\nendif()\n\nif(EXECUTORCH_BUILD_TESTS)\n  include(CTest)\nendif()\n\nif(NOT PYTHON_EXECUTABLE)\n  resolve_python_executable()\nendif()\nmessage(STATUS \"Using python executable '${PYTHON_EXECUTABLE}'\")\n\n# TODO(dbort): Fix these warnings and remove this flag.\nset(_common_compile_options -Wno-deprecated-declarations -fPIC)\n\n# Let files say \"include <executorch/path/to/header.h>\".\n# TODO(#6475): This requires/assumes that the repo lives in a directory named\n# exactly `executorch`. Check the assumption first. Remove this check once we\n# stop relying on the assumption.\ncmake_path(GET CMAKE_CURRENT_SOURCE_DIR FILENAME _repo_dir_name)\nif(NOT \"${_repo_dir_name}\" STREQUAL \"executorch\")\n  message(\n    FATAL_ERROR\n      \"The ExecuTorch repo must be cloned into a directory named exactly \"\n      \"`executorch`; found `${_repo_dir_name}`. See \"\n      \"https://github.com/pytorch/executorch/issues/6475 for progress on a \"\n      \"fix for this restriction.\"\n  )\nendif()\nset(_common_include_directories ${CMAKE_CURRENT_SOURCE_DIR}/..)\n\n#\n# The `_<target>_srcs` lists are defined by including ${EXECUTORCH_SRCS_FILE}.\n#\n\nif(NOT EXECUTORCH_SRCS_FILE)\n  # Find or download buck2 binary.\n  resolve_buck2()\n\n  # A file wasn't provided. Run a script to extract the source lists from the\n  # buck2 build system and write them to a file we can include.\n  #\n  # NOTE: This will only happen once during cmake setup, so it will not re-run\n  # if the buck2 targets change.\n  message(STATUS \"executorch: Generating source lists\")\n  set(EXECUTORCH_SRCS_FILE \"${CMAKE_CURRENT_BINARY_DIR}/executorch_srcs.cmake\")\n  extract_sources(${EXECUTORCH_SRCS_FILE})\nendif()\n\n# This file defines the `_<target>__srcs` variables used below.\nmessage(STATUS \"executorch: Using sources file ${EXECUTORCH_SRCS_FILE}\")\ninclude(${EXECUTORCH_SRCS_FILE})\n\n#\n# Modify default options when cross-compiling.\n#\n# The intent is for the EXECUTORCH_BUILD_HOST_TARGETS option to affect the\n# default ON/OFF values of host targets around the tree. This way, a user can\n# disable EXECUTORCH_BUILD_HOST_TARGETS to disable all host targets, and then\n# optionally re-enable some of those targets. Or they could leave\n# EXECUTORCH_BUILD_HOST_TARGETS enabled and then optionally disable any given\n# host target.\n#\n# We can then use various cross-compilation hints to set the default value of\n# EXECUTORCH_BUILD_HOST_TARGETS, which can still be overridden if desired.\n#\n\n# Detect if an iOS toolchain is set.\nif(CMAKE_TOOLCHAIN_FILE MATCHES \".*(iOS|ios\\.toolchain)\\.cmake$\")\n  set(CMAKE_TOOLCHAIN_IOS ON)\nelse()\n  set(CMAKE_TOOLCHAIN_IOS OFF)\nendif()\n\n# Detect if an Android toolchain is set.\nif(CMAKE_TOOLCHAIN_FILE MATCHES \".*android\\.toolchain\\.cmake$\")\n  set(CMAKE_TOOLCHAIN_ANDROID ON)\nif(NOT ANDROID_PLATFORM)\n  set(ANDROID_PLATFORM android-30)\nendif()\nelse()\n  set(CMAKE_TOOLCHAIN_ANDROID OFF)\nendif()\n\n# Add code coverage flags to supported compilers\nif(EXECUTORCH_USE_CPP_CODE_COVERAGE)\n  if(\"${CMAKE_CXX_COMPILER_ID}\" STREQUAL \"GNU\")\n    string(APPEND CMAKE_C_FLAGS \" --coverage -fprofile-abs-path\")\n    string(APPEND CMAKE_CXX_FLAGS \" --coverage -fprofile-abs-path\")\n  elseif(\"${CMAKE_CXX_COMPILER_ID}\" MATCHES \"Clang\")\n    string(APPEND CMAKE_C_FLAGS \" -fprofile-instr-generate -fcoverage-mapping\")\n    string(APPEND CMAKE_CXX_FLAGS\n           \" -fprofile-instr-generate -fcoverage-mapping\"\n    )\n  else()\n    message(ERROR\n            \"Code coverage for compiler ${CMAKE_CXX_COMPILER_ID} is unsupported\"\n    )\n  endif()\nendif()\n\n# EXECUTORCH_BUILD_HOST_TARGETS: Option to control the building of host-only\n# tools like `flatc`, along with example executables like `executor_runner` and\n# libraries that it uses, like `gflags`. Disabling this can be helpful when\n# cross-compiling, but some required tools that would have been built need to be\n# provided directly (via, for example, FLATC_EXECUTABLE).\ncmake_dependent_option(\n  EXECUTORCH_BUILD_HOST_TARGETS \"Build host-only targets.\" ON\n  \"NOT CMAKE_TOOLCHAIN_IOS\" OFF\n)\n\n#\n# flatc: Flatbuffer commandline tool to generate .h files from .fbs files\n#\ncmake_dependent_option(\n  EXECUTORCH_BUILD_FLATC \"Build the flatc executable.\" ON\n  \"NOT FLATC_EXECUTABLE;EXECUTORCH_BUILD_HOST_TARGETS\" OFF\n)\n\nif(EXECUTORCH_BUILD_FLATC)\n  if(FLATC_EXECUTABLE)\n    # We could ignore this, but it could lead to confusion about which `flatc`\n    # is actually being used.\n    message(\n      FATAL_ERROR \"May not set both EXECUTORCH_BUILD_FLATC and FLATC_EXECUTABLE\"\n    )\n  endif()\n  set(FLATC_EXECUTABLE flatc)\n  set(FLATBUFFERS_BUILD_FLATC\n      ON\n      CACHE BOOL \"\"\n  )\n  set(FLATBUFFERS_BUILD_FLATHASH\n      OFF\n      CACHE BOOL \"\"\n  )\n  set(FLATBUFFERS_BUILD_FLATLIB\n      OFF\n      CACHE BOOL \"\"\n  )\n  set(FLATBUFFERS_BUILD_TESTS\n      OFF\n      CACHE BOOL \"\"\n  )\n  set(FLATBUFFERS_INSTALL\n      OFF\n      CACHE BOOL \"\"\n  )\n  add_subdirectory(third-party/flatbuffers)\n\n  # exir lets users set the alignment of tensor data embedded in the flatbuffer,\n  # and some users need an alignment larger than the default, which is typically\n  # 32.\n  target_compile_definitions(flatc PRIVATE FLATBUFFERS_MAX_ALIGNMENT=1024)\nendif()\nif(NOT FLATC_EXECUTABLE)\n  message(\n    FATAL_ERROR\n      \"FLATC_EXECUTABLE must be set when EXECUTORCH_BUILD_FLATC is disabled. \"\n      \"Note that EXECUTORCH_BUILD_FLATC may be disabled implicitly when \"\n      \"cross-compiling or when EXECUTORCH_BUILD_HOST_TARGETS is disabled.\"\n  )\nendif()\n\n#\n# program_schema: Generated .h files from schema/*.fbs inputs\n#\nadd_subdirectory(schema)\n\n#\n# executorch_core: Minimal runtime library\n#\n# The bare-minimum runtime library, supporting the Program and Method\n# interfaces. Does not contain any operators, including primitive ops. Does not\n# contain any backends.\n#\n\n# Remove any PAL-definition files from the sources.\nlist(FILTER _executorch_core__srcs EXCLUDE REGEX\n     \"runtime/platform/default/[^/]*.cpp$\"\n)\n\n# Add the source file that maps to the requested default PAL implementation.\nif(EXECUTORCH_PAL_DEFAULT MATCHES \"^(posix|minimal)$\")\n  message(STATUS \"executorch: Using PAL default '${EXECUTORCH_PAL_DEFAULT}'\")\n  list(APPEND _executorch_core__srcs\n       \"runtime/platform/default/${EXECUTORCH_PAL_DEFAULT}.cpp\"\n  )\nelse()\n  message(\n    FATAL_ERROR \"Unknown EXECUTORCH_PAL_DEFAULT \\\"${EXECUTORCH_PAL_DEFAULT}\\\". \"\n                \"Expected one of {posix, minimal}.\"\n  )\nendif()\n\nadd_library(executorch_core ${_executorch_core__srcs})\n\n# Legacy name alias.\nadd_library(executorch_no_prim_ops ALIAS executorch_core)\n\ntarget_link_libraries(executorch_core PRIVATE program_schema)\nif(EXECUTORCH_USE_DL)\n  # Check if dl exists for this toolchain and only then link it.\n  find_library(DL_LIBRARY_EXISTS NAMES dl)\n  # Check if the library was found\n  if(DL_LIBRARY_EXISTS)\n    target_link_libraries(executorch_core PRIVATE dl) # For dladdr()\n  endif()\nendif()\ntarget_include_directories(\n  executorch_core PUBLIC ${_common_include_directories}\n)\ntarget_compile_options(executorch_core PUBLIC ${_common_compile_options})\nif(MAX_KERNEL_NUM)\n  target_compile_definitions(\n    executorch_core PRIVATE MAX_KERNEL_NUM=${MAX_KERNEL_NUM}\n  )\nendif()\n\nif(EXECUTORCH_BUILD_PYBIND AND APPLE)\n  # shared version\n  add_library(\n    executorch_core_shared SHARED ${_executorch_core__srcs}\n  )\n  target_link_libraries(executorch_core_shared PRIVATE program_schema)\n  if(DL_LIBRARY_EXISTS)\n    # For dladdr()\n    target_link_libraries(executorch_core_shared PRIVATE dl)\n  endif()\n  target_include_directories(\n    executorch_core_shared PUBLIC ${_common_include_directories}\n  )\n  target_compile_options(\n    executorch_core_shared PUBLIC ${_common_compile_options}\n  )\n  if(MAX_KERNEL_NUM)\n    target_compile_definitions(\n      executorch_core_shared PRIVATE MAX_KERNEL_NUM=${MAX_KERNEL_NUM}\n    )\n  endif()\nendif()\n\n#\n# executorch: Primary runtime library with primitive operators.\n#\n# Provides the Program and Method interfaces, along with primitive operators.\n# Does not contain portable kernels or other full operators. Does not contain\n# any backends.\n#\nadd_library(executorch ${_executorch__srcs})\ntarget_link_libraries(executorch PRIVATE executorch_core)\ntarget_include_directories(executorch PUBLIC ${_common_include_directories})\ntarget_compile_options(executorch PUBLIC ${_common_compile_options})\ntarget_link_options_shared_lib(executorch)\n\n#\n# portable_ops_lib: A library to register core ATen ops using portable kernels,\n# see kernels/portable/CMakeLists.txt.\n#\n# Real integrations should supply their own YAML file that only lists the\n# operators necessary for the models that will run.\n#\nif(BUILD_EXECUTORCH_PORTABLE_OPS)\n  add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/kernels/portable)\nendif()\n\nif(EXECUTORCH_BUILD_KERNELS_OPTIMIZED)\n  add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/kernels/optimized)\nendif()\n\nadd_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/configurations)\n\n#\n# gflags: Commandline flag host library.\n#\ncmake_dependent_option(\n  EXECUTORCH_BUILD_GFLAGS \"Build the gflags library.\" ON\n  EXECUTORCH_BUILD_HOST_TARGETS OFF\n)\nif(EXECUTORCH_BUILD_GFLAGS)\n  add_subdirectory(third-party/gflags)\nendif()\n\n# Install `executorch` library as well as `executorch-config.cmake` under\n# ${CMAKE_INSTALL_PREFIX}/\ninstall(\n  TARGETS executorch executorch_core\n  DESTINATION lib\n  INCLUDES\n  DESTINATION ${_common_include_directories}\n)\ninstall(FILES build/executorch-config.cmake DESTINATION lib/cmake/ExecuTorch)\n\n#\n# executor_runner: Host tool that demonstrates program execution.\n#\ncmake_dependent_option(\n  EXECUTORCH_BUILD_EXECUTOR_RUNNER \"Build the executor_runner executable\" ON\n  EXECUTORCH_BUILD_HOST_TARGETS OFF\n)\n\n# Add googletest if any test targets should be built\nif(BUILD_TESTING)\n  add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/third-party/googletest)\nendif()\n\nif(EXECUTORCH_BUILD_ARM_BAREMETAL)\n  add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/backends/arm)\nendif()\n\nif(EXECUTORCH_BUILD_CADENCE)\n  add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/backends/cadence)\nendif()\n\nif(EXECUTORCH_BUILD_COREML)\n  add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/backends/apple/coreml)\nendif()\n\nif(EXECUTORCH_BUILD_MPS)\n  add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/backends/apple/mps)\nendif()\n\nif(EXECUTORCH_BUILD_NEURON)\n  add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/backends/mediatek)\nendif()\n\nif(EXECUTORCH_BUILD_QNN)\n  add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/backends/qualcomm)\nendif()\n\nif(EXECUTORCH_BUILD_XNNPACK)\n  add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/backends/xnnpack)\nendif()\n\nif(EXECUTORCH_BUILD_DEVTOOLS)\n  if(NOT EXECUTORCH_BUILD_ARM_BAREMETAL)\n    set(EXECUTORCH_BUILD_EXTENSION_DATA_LOADER\n        ON\n        CACHE BOOL \"EXECUTORCH_BUILD_EXTENSION_DATA_LOADER\" FORCE\n    )\n  else()\n    set(EXECUTORCH_BUILD_EXTENSION_DATA_LOADER\n        OFF\n        CACHE BOOL \"EXECUTORCH_BUILD_EXTENSION_DATA_LOADER\" FORCE\n    )\n  endif()\n  add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/devtools)\nendif()\n\nif(EXECUTORCH_BUILD_EXTENSION_APPLE)\n  add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/extension/apple)\nendif()\n\nif(EXECUTORCH_BUILD_EXTENSION_DATA_LOADER)\n  add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/extension/data_loader)\nendif()\n\nif(EXECUTORCH_BUILD_EXTENSION_MODULE)\n  add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/extension/module)\nendif()\n\nif(EXECUTORCH_BUILD_EXTENSION_TRAINING)\n  add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/extension/training)\nendif()\n\nif(EXECUTORCH_BUILD_EXTENSION_RUNNER_UTIL)\n  add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/extension/runner_util)\nendif()\n\nif(EXECUTORCH_BUILD_EXTENSION_TENSOR)\n  add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/extension/tensor)\nendif()\n\nif(EXECUTORCH_BUILD_PTHREADPOOL\n   AND EXECUTORCH_BUILD_CPUINFO\n   AND CMAKE_CXX_STANDARD GREATER_EQUAL 14\n)\n  add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/extension/threadpool)\nendif()\n\nif(EXECUTORCH_BUILD_PYBIND)\n  add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/third-party/pybind11)\n\n  if(NOT EXECUTORCH_BUILD_EXTENSION_DATA_LOADER)\n    add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/extension/data_loader)\n  endif()\n\n  if(NOT EXECUTORCH_BUILD_DEVTOOLS)\n    add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/devtools)\n  endif()\n\n  # find pytorch lib, to allow pybind to take at::Tensor as input/output\n  find_package(Torch CONFIG REQUIRED)\n  find_library(\n    TORCH_PYTHON_LIBRARY torch_python PATHS \"${TORCH_INSTALL_PREFIX}/lib\"\n  )\n\n  set(_dep_libs\n      ${TORCH_PYTHON_LIBRARY}\n      bundled_program\n      etdump\n      executorch\n      extension_data_loader\n      util\n      torch\n  )\n\n  if(EXECUTORCH_BUILD_KERNELS_OPTIMIZED)\n    list(APPEND _dep_libs optimized_native_cpu_ops_lib)\n  else()\n    list(APPEND _dep_libs portable_ops_lib)\n  endif()\n\n  if(EXECUTORCH_BUILD_COREML)\n    list(APPEND _dep_libs coremldelegate)\n  endif()\n\n  if(EXECUTORCH_BUILD_MPS)\n    list(APPEND _dep_libs mpsdelegate)\n  endif()\n\n  if(EXECUTORCH_BUILD_XNNPACK)\n    # need to explicitly specify XNNPACK and microkernels-prod\n    # here otherwise uses XNNPACK and microkernel-prod symbols from libtorch_cpu\n    list(APPEND _dep_libs xnnpack_backend XNNPACK microkernels-prod)\n  endif()\n\n  # compile options for pybind\n  set(_pybind_compile_options\n      -Wno-deprecated-declarations\n      -fPIC\n      -frtti\n      -fexceptions\n  )\n\n  # util lib\n  add_library(\n    util ${CMAKE_CURRENT_SOURCE_DIR}/extension/evalue_util/print_evalue.cpp\n         ${CMAKE_CURRENT_SOURCE_DIR}/extension/aten_util/aten_bridge.cpp\n  )\n  target_include_directories(\n    util PUBLIC ${_common_include_directories} ${TORCH_INCLUDE_DIRS}\n  )\n  target_compile_options(util PUBLIC ${_pybind_compile_options})\n  target_link_libraries(util PRIVATE torch c10 executorch extension_tensor)\n\n  # pybind portable_lib\n  pybind11_add_module(portable_lib SHARED extension/pybindings/pybindings.cpp)\n  # The actual output file needs a leading underscore so it can coexist with\n  # portable_lib.py in the same python package.\n  set_target_properties(portable_lib PROPERTIES OUTPUT_NAME \"_portable_lib\")\n  target_compile_definitions(\n    portable_lib PUBLIC EXECUTORCH_PYTHON_MODULE_NAME=_portable_lib\n  )\n  target_include_directories(portable_lib PRIVATE ${TORCH_INCLUDE_DIRS})\n  target_compile_options(portable_lib PUBLIC ${_pybind_compile_options})\n  target_link_libraries(portable_lib PRIVATE ${_dep_libs})\n\n  install(TARGETS portable_lib\n          LIBRARY DESTINATION executorch/extension/pybindings\n  )\nendif()\n\nif(EXECUTORCH_BUILD_KERNELS_CUSTOM)\n  # TODO: move all custom kernels to ${CMAKE_CURRENT_SOURCE_DIR}/kernels/custom\n  add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/extension/llm/custom_ops)\nendif()\n\nif(EXECUTORCH_BUILD_KERNELS_QUANTIZED)\n  add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/kernels/quantized)\n  target_link_options_shared_lib(quantized_ops_lib)\nendif()\n\nif(EXECUTORCH_BUILD_EXECUTOR_RUNNER)\n  # Baseline libraries that executor_runner will link against.\n  set(_executor_runner_libs executorch gflags)\n\n  if(EXECUTORCH_BUILD_KERNELS_OPTIMIZED)\n    list(APPEND _executor_runner_libs optimized_native_cpu_ops_lib)\n  elseif(EXECUTORCH_BUILD_CADENCE)\n    list(APPEND _executor_runner_libs cadence_ops_lib)\n  else()\n    list(APPEND _executor_runner_libs portable_ops_lib)\n  endif()\n\n  # Generate lib to register quantized ops\n  if(EXECUTORCH_BUILD_KERNELS_QUANTIZED)\n    list(APPEND _executor_runner_libs quantized_ops_lib)\n  endif()\n\n  add_executable(executor_runner ${_executor_runner__srcs})\n  if(CMAKE_BUILD_TYPE STREQUAL \"Release\")\n    if(APPLE)\n      target_link_options(executor_runner PRIVATE \"LINKER:-dead_strip\")\n    else()\n      target_link_options(executor_runner PRIVATE \"LINKER:--gc-sections\")\n    endif()\n  endif()\n  target_link_libraries(executor_runner ${_executor_runner_libs})\n  target_compile_options(executor_runner PUBLIC ${_common_compile_options})\nendif()\n\nif(EXECUTORCH_BUILD_VULKAN)\n  add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/backends/vulkan)\nendif()\n\ninclude(Test.cmake)\n\n# Print all summary\nexecutorch_print_configuration_summary()\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.4541015625,
          "content": "# Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to make participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, sex characteristics, gender identity and expression,\nlevel of experience, education, socio-economic status, nationality, personal\nappearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\nadvances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\naddress, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\nprofessional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies within all project spaces, and it also applies when\nan individual is representing the project or its community in public spaces.\nExamples of representing a project or community include using an official\nproject e-mail address, posting via an official social media account, or acting\nas an appointed representative at an online or offline event. Representation of\na project may be further defined and clarified by project maintainers.\n\nThis Code of Conduct also applies outside the project spaces when there is a\nreasonable belief that an individual's behavior may have a negative impact on\nthe project or its community.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the project team at <opensource-conduct@meta.com>. All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see\nhttps://www.contributor-covenant.org/faq\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 14.94140625,
          "content": "Thank you for your interest in contributing to ExecuTorch! We want to make\nit easy to contribute to this project.\n\n&nbsp;\n\n## Dev Install\n\nSet up your environment by following the instructions at\nhttps://pytorch.org/executorch/stable/getting-started-setup.html to clone\nthe repo and install the necessary requirements.\n\n&nbsp;\n\n## Contributing workflow\nWe actively welcome your pull requests (PRs).\n\n1. [Claim an issue](#claiming-issues), if present, before starting work. If an\n   issue doesn't cover the work you plan to do, consider creating one to provide\n   context about it, and to build consensus about the scope and solution.\n1. Create your new branch from `main` in your forked repo, with a name\n   describing the work you're completing; e.g., `add-feature-x`.\n1. If you've added code that should be tested, add tests. Ensure all tests pass.\n   See the [testing section](#testing) for more information.\n1. If you've changed APIs or added a new tool or feature, [update the\n   documentation](#updating-documentation).\n1. If you added an experimental API or deprecated an existing API, follow the\n   [API Life Cycle and Deprecation Policy](/docs/source/api-life-cycle.md).\n1. Make sure your code follows the [style guides](#coding-style) and passes the\n   [lint checks](#lintrunner).\n1. If you haven't already, complete the [Contributor License Agreement (\"CLA\")](#contributor-license-agreement-cla).\n1. Create a pull request in the `pytorch/executorch` Github repo using the\n   [instructions below](#pull-requests).\n\n&nbsp;\n\n## Issues\n\n### Creating Issues\nWe use GitHub issues to track public bugs and feature requests. Ensure that the\nissue title is clear and descriptive, and that the description has sufficient\ninstructions to be able to reproduce the issue.\n\nMeta has a [bounty program](https://www.facebook.com/whitehat/) for the safe\ndisclosure of security bugs. In those cases, please go through the process\noutlined on that page and do not file a public issue.\n\n### Claiming Issues\nWe'd love your help closing out [open\nissues](https://github.com/pytorch/executorch/issues?q=sort%3Aupdated-desc+is%3Aissue+is%3Aopen)\nin the Github repo.\n\n1. Find an issue with the\n   [`actionable`](https://github.com/pytorch/executorch/issues?q=sort%3Aupdated-desc+is%3Aissue+is%3Aopen+label%3Aactionable)\n   or [`good first\n   issue`](https://github.com/pytorch/executorch/issues?q=sort%3Aupdated-desc+is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22)\n   label that is not currently assigned to anyone.\n   - If you'd like to work on an issue that is assigned but hasn't been updated\n     in a while, discuss a hand-off with the current assignee in the issue\n     comments.\n   - If you'd like to work on an issue that isn't marked `actionable`, please\n     comment on the issue to ask about its status and wait for a response.\n1. Set yourself as the assignee of the issue.\n1. If you decide not to finish the issue, update the issue with information to\n   help the next person, then remove yourself from the assignee list.\n1. When creating pull requests (PRs), mention the issue number like `#1234` in\n   the PR description details (the first comment in the PR conversation thread).\n1. When the final PR has merged and resolves the issue, close the issue with the\n   button at the bottom of the issue's page.\n\n&nbsp;\n\n## Coding Style\n\nGoal: Encourage standards that make it easier to read, edit, maintain, and debug\nthe ExecuTorch code.\n\n### lintrunner\n\nWe use [`lintrunner`](https://pypi.org/project/lintrunner/) to help make sure the\ncode follows our standards. Set it up with:\n\n```\npip install lintrunner==0.12.7\npip install lintrunner-adapters==0.12.4\nlintrunner init\n```\n\nThen run `lintrunner` from the root of the repo to see its suggestions, or run\n`lintrunner -a` to automatically apply the suggestions.\n\n### Python Style\n\nExecuTorch Python code follows the style used by the PyTorch core project.\n\n### C++ Style\n\nExecuTorch code uses the [Google C++\nStyle](https://google.github.io/styleguide/cppguide.html), with modifications.\n\nRationale: Google style is close to the C++ style used by PyTorch core, although\nPyTorch core does not explicitly document its C++ style. Google style is well\ndocumented, and has exceptional tooling support.\n\n**Modifications** to the Google C++ style, to make it closer to the code in\nPyTorch core:\n- Function and method names should use `lower_snake_case()`. This follows the\n  convention that PyTorch core inherited from its namesake Python, and is the\n  biggest modification to the Google C++ style.\n- File names should use `lower_snake_case.cpp` (not `.cc`, and not\n  `PascalCase.cpp`). This follows the most common pattern in PyTorch core.\n- Headers should use `#pragma once` instead of manual include guards. This\n  follows the most common pattern in PyTorch core.\n- All includes should use `<angle brackets>`, not `\"double quotes\"`. This\n  ensures that headers are included using the compiler's include path, and not\n  relative to the local file.\n- Documentation comments should follow Doxygen syntax, either `//** ... */`\n  (multi-line) or `/// ...` (single line), with `@`-style parameters like\n  `@param`, `@retval`. Public APIs must be documented in the `.h` files that\n  declare them.\n- TODOs should prefer to reference a task or issue number like `TODO(#123):\n  <description>`, rather than a username. A task can manage much-more-nuanced\n  information, and can change ownership as people leave and join the project.\n\nSee the rest of this file for other portability- and efficiency-related\nmodifications to the Google C++ style guide.\n\n### C++ Portability Guidelines\n\nSee also [Portable C++ Programming](/docs/source/portable-cpp-programming.md)\nfor detailed advice.\n\n#### C++ language version\n\n**C++17.**\n\nRationale: This is a compromise between being compatible with older, proprietary\ntoolchains, and having access to relatively modern C++ features.\n\n#### C/C++ standard library usage\n\n**Restricted usage of the C++ standard library.**\n\nRationale: ExecuTorch is intended to be portable to bare-metal systems that lack\ncertain features, like dynamic memory, threading, and locking, required by parts\nof the standard library. It is also intended to be as small as possible, and\nsome convenient stdlib features may grow the binary size unacceptably.\n\nGenerally, do not instantiate types that allocate memory under the hood, like\n`std::vector` or `std::string`. Do not call `new`, `malloc()` or `mmap()`; do\nnot use iostreams; do not operate on files.\n\nHowever, it is convenient and portable (and sometimes necessary) to use static\nstandard library concepts like `std::move`, or metaprogramming helpers like\n`std::is_floating_point<>`.  Pure code like `<cmath>` and `<cstring>` is fine,\nas long as you stay away from functions that allocate memory (like `strdup()`).\n\nIt is also allowed (and sometimes necessary) to use \"placement `new`\", but be\ncareful to also manually destroy objects initialized in this way.\n\n#### C++ language features\n\n**Exceptions: Do not use.**\n- Rationale: Exceptions are not widely supported on some classes of\n  microcontrollers and DSPs, and they can significantly increase binary size.\n\n**Threads, thread_local, locking: Do not use, except in optional libraries that\nmust work with threading**\n- Rationale: The core runtime must work on systems that do not have threading\n  support.\n\n**RTTI, dynamic_cast, and `<typeid>`: Do not use.**\n- Rationale: RTTI adds extra data to every virtual class. ExecuTorch doesn't\n  have a strong need for `dynamic_cast` and friends, so it's better to reduce\n  the binary size.\n\n**Templates and template metaprogramming: Be careful and avoid if possible.**\n- Rationale: Most templating results in code generation, and is one of the most\n  common sources of binary bloat. Some use of templates is fine (e.g. an\n  `ArrayRef<T>`, or code that handles multiple `ScalarType` types), but for the\n  most part avoid them if possible.\n\n&nbsp;\n\n## Testing\n\n### Writing Tests\nTo help keep code quality high, ExecuTorch uses a combination of unit tests and\nend-to-end (e2e) tests. If you add a new feature or fix a bug, please add tests\nto ensure that the feature/fix works properly and continues to work properly.\n\nMost directories in the repo already contain test files. In many cases, you can\nadd a test to an existing file, and the existing CI jobs will run it will run\nautomatically. If you do this, please take a look at the CI job logs to ensure\nthat it did actually run.\n\nIf it's not clear how to add a test for your PR, take a look at the blame for\nthe code you're modifying and find an author who has more context. Ask them\nfor their help in the PR comments.\n\nThe `test/run_oss_cpp_tests.sh` script will build and run C++ tests locally.\n\n### Continuous Integration\nSee https://hud.pytorch.org/hud/pytorch/executorch/main for the current state of\nthe CI (continuous integration) jobs. If `main` is broken, consider rebasing\nyour PR onto the `viable/strict` branch, which points to the most recent\nall-green commit.\n\n&nbsp;\n\n## Updating Documentation\n\n### APIs\nExecuTorch documents its APIs using inline code comments: doc strings for\nPython, and Doxygen comments for C++. When modifying or adding an API, be sure\nto modify or add documentation to the interfaces that you change. If the API\ndoesn't have inline documentation yet, please help improve the code by adding\ndocumentation and describing the rest of the piece you modified.\n\nAlso search for references to the API you modified under `docs/source` to see if\nany docs need to be modified to reflect your changes; these are the files that\nare published on https://pytorch.org/executorch. If you are adding a new API,\nlook for places in the docs that would benefit from talking about that API, or\neven create a new document for it. A job on the PR will give you a link to a\nwebsite preview based on your changes.\n\n&nbsp;\n\n## Pull Requests\nThis repo uses Github pull requests (PRs) to stage and review code before\nmerging it into the `main` branch. See the [Github\ndocs](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request-from-a-fork)\nfor basics.\n\n1. Push your branch to your fork of `pytorch/executorch`. Most people do not\n  have permission to push a branch directoy to the upstream repo.\n1. Create your PR\n   - Use the `main` branch as the base.\n   - Give the PR a clear and descriptive title. It will become the title of the\n     merged commit, so it needs to be useful in the output of `git log`.\n     - Bad title: \"Fix a bug\"\n     - Good title: \"Add XYZ method to ABC\"\n   - Give the PR a clear and thorough description. Don't just describe what the PR\n     does: the diff will do that. Explain *why* you are making this change, in a\n     way that will make sense to someone years from now.\n   - Explain how you have tested your changes by including repeatable instructions for\n     testing the PR.\n     - If you added tests, this can be as simple as the command you used to run the\n       tests.\n     - If you tested the PR manually, include the steps and the outputs. Help a\n       future editor understand how to test the code that you're modifying\n       today.\n   - If your PR contains or is representative of a feature/bug fix that should be\n     called out in the release notes, please add a label for \"Release notes: \\<area\\>\",\n\t where \\<area\\> describes which part of ExecuTorch the change pertains to, e.g.\n\t \"Release notes: runtime\". Here are all of the categories:\n     - `Release notes: runtime`: changes related to the core runtime which loads the program methods, initializes delegates, and runs the lowered graph.\n     - `Release notes: exir`: changes to any internal representations, such as any edge-related dialects. Also any changes to passes that may modify the exir, such as memory planning.\n     - `Release notes: quantization`: changes to quantization.\n     - `Release notes: ops & kernels`: changes to the opset and any new / changed kernel implementations.\n     - `Release notes: api`: changes to public facing apis (any interfaces, pybinded runtime methods, etc.).\n     - `Release notes: backends`: changes to any of the backend delegates.\n     - `Release notes: build`: changes related to the build system, including major dependency upgrades, notable build flags, optimizations, etc.\n     - `Release notes: devtools`: changes to any of ExecuTorch's developer tools, for example the debugger & profiler.\n     - `Release notes: examples`: changes to any code under `examples/`.\n     - `Release notes: misc`: anything notable that doesn't belong in the above categories.\n   - See https://github.com/pytorch/executorch/pull/3612 for an example PR that\n     follows this advice.\n1. Before asking for a review, ensure that all [CI (continuous integration)\n   jobs](#continuous-integration) on your pull request succeed.\n   - If the jobs on your PR are broken but you're not sure why, add a comment\n     and proceed to finding a reviewer.\n   - Not all users can trigger the CI jobs. If the jobs don't run on your PR,\n     proceed to finding a reviewer.\n1. Find reviewers\n   - If you have been working with a member of the ExecuTorch repo, add them\n     as a reviewer (*not* an \"assignee\").\n   - If not, look at the blame for the files that the PR modifies, and try\n     picking one or two ExecuTorch repo members as reviewers (*not*\n     \"assignees\").\n   - If you are unsure, leave a comment on the PR and keep it unassigned with no\n     reviewers. A member of the ExecuTorch repo will find someone to review it.\n1. Address and discuss comments left by reviewers\n   - If the reviewers have requests or questions, follow up with them.\n   - The goal of the reviewer is to ensure that the code in the `main` branch of\n     the repo is consistent, maintainable, and of high quality.\n1. Once the PR has been approved,\n   - If you have the \"write permission\" in this repo, you can merge it yourself\n     by clicking the \"Squash and merge\" button once it is green and all CI\n     signals are passing.\n   - If you don't have \"write permission\" in this repo, the reviewer will take\n     care of the PR. The reviewer may import the PR into Meta's internal system\n     to validate it against internal CI.\n   - If the PR is approved but not merged within 5 business days, please comment\n     on the PR to ask about its status.\n   - Note that if the `main` [CI](#continuous-integration) jobs are broken, we\n     will only merge PRs that fix the broken jobs until all critical jobs are\n     fixed.\n\n&nbsp;\n\n## For Backend Delegate Authors\n\n- Use [this](/docs/source/backend-delegates-integration.md) guide when\n  integrating your delegate with ExecuTorch.\n- Refer to [this](/docs/source/backend-delegates-dependencies.md) set of\n  guidelines when including a third-party depenency for your delegate.\n\n&nbsp;\n\n## License\nBy contributing to ExecuTorch, you agree that your contributions will be\nlicensed under the LICENSE file in the root directory of this source tree.\n\n&nbsp;\n\n## Contributor License Agreement (\"CLA\")\nIn order to accept your pull request, we need you to submit a CLA. You only need\nto do this once to work on any of Meta's open source projects.\n\nComplete your CLA here: <https://code.facebook.com/cla>\n\n&nbsp;\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.63671875,
          "content": "BSD License\n\nFor \"ExecuTorch\" software\n\nCopyright (c) Meta Platforms, Inc. and affiliates.\nCopyright 2023 Arm Limited and/or its affiliates.\nCopyright (c) Qualcomm Innovation Center, Inc.\nCopyright (c) 2023 Apple Inc.\nCopyright (c) 2024 MediaTek Inc.\n\nRedistribution and use in source and binary forms, with or without modification,\nare permitted provided that the following conditions are met:\n\n * Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n * Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n * Neither the name Meta nor the names of its contributors may be used to\n   endorse or promote products derived from this software without specific\n   prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR\nANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\nANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "README-wheel.md",
          "type": "blob",
          "size": 2.119140625,
          "content": "**ExecuTorch** is a [PyTorch](https://pytorch.org/) platform that provides\ninfrastructure to run PyTorch programs everywhere from AR/VR wearables to\nstandard on-device iOS and Android mobile deployments. One of the main goals for\nExecuTorch is to enable wider customization and deployment capabilities of the\nPyTorch programs.\n\nThe `executorch` pip package is in alpha.\n* Supported python versions: 3.10, 3.11\n* Compatible systems: Linux x86_64, macOS aarch64\n\nThe prebuilt `executorch.extension.pybindings.portable_lib` module included in\nthis package provides a way to run ExecuTorch `.pte` files, with some\nrestrictions:\n* Only [core ATen\n  operators](https://pytorch.org/executorch/stable/ir-ops-set-definition.html)\n  are linked into the prebuilt module\n* Only the [XNNPACK backend\n  delegate](https://pytorch.org/executorch/main/native-delegates-executorch-xnnpack-delegate.html)\n  is linked into the prebuilt module\n* [macOS only] [Core ML](https://pytorch.org/executorch/main/build-run-coreml.html) and [MPS](https://pytorch.org/executorch/main/build-run-mps.html) backend delegates are linked into the prebuilt module.\n\nPlease visit the [ExecuTorch website](https://pytorch.org/executorch/) for\ntutorials and documentation. Here are some starting points:\n* [Getting\n  Started](https://pytorch.org/executorch/stable/getting-started-setup.html)\n  * Set up the ExecuTorch environment and run PyTorch models locally.\n* [Working with\n  local LLMs](https://pytorch.org/executorch/stable/llm/getting-started.html)\n  * Learn how to use ExecuTorch to export and accelerate a large-language model\n    from scratch.\n* [Exporting to\n  ExecuTorch](https://pytorch.org/executorch/main/tutorials/export-to-executorch-tutorial.html)\n  * Learn the fundamentals of exporting a PyTorch `nn.Module` to ExecuTorch, and\n    optimizing its performance using quantization and hardware delegation.\n* Running LLaMA on\n  [iOS](https://pytorch.org/executorch/stable/llm/llama-demo-ios.html) and\n  [Android](https://pytorch.org/executorch/stable/llm/llama-demo-android.html)\n  devices.\n  * Build and run LLaMA in a demo mobile app, and learn how to integrate models\n    with your own apps.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 7.0693359375,
          "content": "# ExecuTorch\n\n**ExecuTorch** is an end-to-end solution for enabling on-device inference\ncapabilities across mobile and edge devices including wearables, embedded\ndevices and microcontrollers. It is part of the PyTorch Edge ecosystem and\nenables efficient deployment of PyTorch models to edge devices.\n\nKey value propositions of ExecuTorch are:\n\n- **Portability:** Compatibility with a wide variety of computing platforms,\n  from high-end mobile phones to highly constrained embedded systems and\n  microcontrollers.\n- **Productivity:** Enabling developers to use the same toolchains and Developer\n  Tools from PyTorch model authoring and conversion, to debugging and deployment\n  to a wide variety of platforms.\n- **Performance:** Providing end users with a seamless and high-performance\n  experience due to a lightweight runtime and utilizing full hardware\n  capabilities such as CPUs, NPUs, and DSPs.\n\nFor a comprehensive technical overview of ExecuTorch and step-by-step tutorials,\nplease visit our documentation website [for the latest release](https://pytorch.org/executorch/stable/index.html) (or the [main branch](https://pytorch.org/executorch/main/index.html)).\n\nCheck out the [Getting Started](https://pytorch.org/executorch/stable/getting-started-setup.html#quick-setup-colab-jupyter-notebook-prototype) page for a quick spin.\n\nCheck out the examples of [Llama](./examples/models/llama/README.md), [Llava](./examples/models/llava/README.md) and [other models](./examples/README.md) running on edge devices using ExecuTorch.\n\n\n**[UPDATE - 10/24]** We have added support for running [Llama 3.2 Quantized 1B/3B](./examples/models/llama/README.md) models via ExecuTorch.\n\n## Feedback\n\nWe welcome any feedback, suggestions, and bug reports from the community to help\nus improve our technology. Please use the [PyTorch\nForums](https://discuss.pytorch.org/c/executorch) for discussion and feedback\nabout ExecuTorch using the **ExecuTorch** category, and our [GitHub\nrepository](https://github.com/pytorch/executorch/issues) for bug reporting.\n\nWe recommend using the latest release tag from the\n[Releases](https://github.com/pytorch/executorch/releases) page when developing.\n\n## Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for details about issues, PRs, code\nstyle, CI jobs, and other development topics.\n\nTo connect with us and other community members, we invite you to join PyTorch Slack community by filling out this [form](https://docs.google.com/forms/d/e/1FAIpQLSeADnUNW36fjKjYzyHDOzEB_abKQE9b6gqqW9NXse6O0MWh0A/viewform). Once you've joined, you can:\n* Head to the `#executorch-general` channel for general questions, discussion, and community support.\n* Join the `#executorch-contributors` channel if you're interested in contributing directly to project development.\n\n\n## Directory Structure\n\n```\nexecutorch\n backends                        #  Backend delegate implementations.\n build                           #  Utilities for managing the build system.\n codegen                         #  Tooling to autogenerate bindings between kernels and the runtime.\n configurations\n docs                            #  Static docs tooling.\n examples                        #  Examples of various user flows, such as model export, delegates, and runtime execution.\n exir                            #  Ahead-of-time library: model capture and lowering APIs.\n|    _serialize                  #  Serialize final export artifact.\n|    backend                     #  Backend delegate ahead of time APIs\n|    capture                     #  Program capture.\n|    dialects                    #  Op sets for various dialects in the export process.\n|    emit                        #  Conversion from ExportedProgram to ExecuTorch execution instructions.\n|    operator                    #  Operator node manipulation utilities.\n|    passes                      #  Built-in compiler passes.\n|    program                     #  Export artifacts.\n|    serde                       #  Graph module\nserialization/deserialization.\n|    verification                #  IR verification.\n extension                       #  Extensions built on top of the runtime.\n|    android                     #  ExecuTorch wrappers for Android apps.\n|    apple                       #  ExecuTorch wrappers for iOS apps.\n|    aten_util                   #  Converts to and from PyTorch ATen types.\n|    data_loader                 #  1st party data loader implementations.\n|    evalue_util                 #  Helpers for working with EValue objects.\n|    gguf_util                   #  Tools to convert from the GGUF format.\n|    kernel_util                 #  Helpers for registering kernels.\n|    memory_allocator            #  1st party memory allocator implementations.\n|    module                      #  A simplified C++ wrapper for the runtime.\n|    parallel                    #  C++ threadpool integration.\n|    pybindings                  #  Python API for executorch runtime.\n|    pytree                      #  C++ and Python flattening and unflattening lib for pytrees.\n|    runner_util                 #  Helpers for writing C++ PTE-execution\ntools.\n|    testing_util                #  Helpers for writing C++ tests.\n|    training                    #  Experimental libraries for on-device training\n kernels                         #  1st party kernel implementations.\n|    aten\n|    optimized\n|    portable                    #  Reference implementations of ATen operators.\n|    prim_ops                    #  Special ops used in executorch runtime for control flow and symbolic primitives.\n|    quantized\n profiler                        #  Utilities for profiling runtime execution.\n runtime                         #  Core C++ runtime.\n|    backend                     #  Backend delegate runtime APIs.\n|    core                        #  Core structures used across all levels of the runtime.\n|    executor                    #  Model loading, initialization, and execution.\n|    kernel                      #  Kernel registration and management.\n|    platform                    #  Layer between architecture specific code and portable C++.\n schema                          #  ExecuTorch PTE file format flatbuffer\nschemas.\n scripts                         #  Utility scripts for size management, dependency management, etc.\n devtools                        #  Model profiling, debugging, and introspection.\n shim                            #  Compatibility layer between OSS and Internal builds\n test                            #  Broad scoped end-to-end tests.\n third-party                     #  Third-party dependencies.\n util                            #  Various helpers and scripts.\n```\n\n## License\nExecuTorch is BSD licensed, as found in the LICENSE file.\n"
        },
        {
          "name": "Test.cmake",
          "type": "blob",
          "size": 1.0400390625,
          "content": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n# All rights reserved.\n#\n# This source code is licensed under the BSD-style license found in the\n# LICENSE file in the root directory of this source tree.\n\n#\n# A helper CMake file to trigger C++ unit tests.\n#\n\nif(BUILD_TESTING)\n  # This contains the list of tests which are always built\n  add_subdirectory(extension/evalue_util/test)\n  add_subdirectory(extension/kernel_util/test)\n  add_subdirectory(extension/memory_allocator/test)\n  add_subdirectory(extension/parallel/test)\n  add_subdirectory(extension/pytree/test)\n  add_subdirectory(kernels/portable/cpu/util/test)\n  add_subdirectory(kernels/prim_ops/test)\n  add_subdirectory(kernels/test)\n  add_subdirectory(runtime/core/exec_aten/testing_util/test)\n  add_subdirectory(runtime/core/exec_aten/util/test)\n  add_subdirectory(runtime/core/portable_type/test)\n  add_subdirectory(runtime/core/test)\n  add_subdirectory(runtime/executor/test)\n  add_subdirectory(runtime/kernel/test)\n  add_subdirectory(runtime/platform/test)\n  add_subdirectory(test/utils)\nendif()\n"
        },
        {
          "name": "backends",
          "type": "tree",
          "content": null
        },
        {
          "name": "build",
          "type": "tree",
          "content": null
        },
        {
          "name": "codegen",
          "type": "tree",
          "content": null
        },
        {
          "name": "configurations",
          "type": "tree",
          "content": null
        },
        {
          "name": "devtools",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "exir",
          "type": "tree",
          "content": null
        },
        {
          "name": "extension",
          "type": "tree",
          "content": null
        },
        {
          "name": "install_requirements.bat",
          "type": "blob",
          "size": 0.560546875,
          "content": "@ECHO OFF\r\n\r\nrem Copyright (c) Meta Platforms, Inc. and affiliates.\r\nrem All rights reserved.\r\n\r\nrem This batch file provides a basic functionality similar to the bash script.\r\n\r\ncd /d \"%~dp0\"\r\n\r\nrem Find the names of the python tools to use (replace with your actual python installation)\r\nif \"%PYTHON_EXECUTABLE%\"==\"\" (\r\n  if \"%CONDA_DEFAULT_ENV%\"==\"\" OR \"%CONDA_DEFAULT_ENV%\"==\"base\" OR NOT EXIST \"python\" (\r\n    set PYTHON_EXECUTABLE=python3\r\n  ) else (\r\n    set PYTHON_EXECUTABLE=python\r\n  )\r\n)\r\n\r\n\"%PYTHON_EXECUTABLE%\" install_requirements.py %*\r\n\r\nexit /b %ERRORLEVEL%"
        },
        {
          "name": "install_requirements.py",
          "type": "blob",
          "size": 7.4921875,
          "content": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n# All rights reserved.\n#\n# This source code is licensed under the BSD-style license found in the\n# LICENSE file in the root directory of this source tree.\n\n\nimport glob\nimport os\nimport platform\nimport re\nimport shutil\nimport subprocess\nimport sys\n\n# Before doing anything, cd to the directory containing this script.\nos.chdir(os.path.dirname(os.path.abspath(__file__)))\n\n\ndef python_is_compatible():\n    # Scrape the version range from pyproject.toml, which should be in the current directory.\n    version_specifier = None\n    with open(\"pyproject.toml\", \"r\") as file:\n        for line in file:\n            if line.startswith(\"requires-python\"):\n                match = re.search(r'\"([^\"]*)\"', line)\n                if match:\n                    version_specifier = match.group(1)\n                    break\n\n    if not version_specifier:\n        print(\n            \"WARNING: Skipping python version check: version range not found\",\n            file=sys.stderr,\n        )\n        return False\n\n    # Install the packaging module if necessary.\n    try:\n        import packaging\n    except ImportError:\n        subprocess.run(\n            [sys.executable, \"-m\", \"pip\", \"install\", \"packaging\"], check=True\n        )\n    # Compare the current python version to the range in version_specifier. Exits\n    # with status 1 if the version is not compatible, or with status 0 if the\n    # version is compatible or the logic itself fails.\n    try:\n        import packaging.specifiers\n        import packaging.version\n\n        python_version = packaging.version.parse(platform.python_version())\n        version_range = packaging.specifiers.SpecifierSet(version_specifier)\n        if python_version not in version_range:\n            print(\n                f'ERROR: ExecuTorch does not support python version {python_version}: must satisfy \"{version_specifier}\"',\n                file=sys.stderr,\n            )\n            return False\n    except Exception as e:\n        print(f\"WARNING: Skipping python version check: {e}\", file=sys.stderr)\n    return True\n\n\nif not python_is_compatible():\n    sys.exit(1)\n\n# Parse options.\n\nEXECUTORCH_BUILD_PYBIND = \"\"\nCMAKE_ARGS = os.getenv(\"CMAKE_ARGS\", \"\")\nCMAKE_BUILD_ARGS = os.getenv(\"CMAKE_BUILD_ARGS\", \"\")\nUSE_PYTORCH_NIGHTLY = True\n\nargs = sys.argv[1:]\nfor arg in args:\n    if arg == \"--pybind\":\n        pass\n    elif arg in [\"coreml\", \"mps\", \"xnnpack\"]:\n        if \"--pybind\" in args:\n            arg_upper = arg.upper()\n            EXECUTORCH_BUILD_PYBIND = \"ON\"\n            CMAKE_ARGS += f\" -DEXECUTORCH_BUILD_{arg_upper}=ON\"\n        else:\n            print(f\"Error: {arg} must follow --pybind\")\n            sys.exit(1)\n    elif arg == \"off\":\n        if \"--pybind\" in args:\n            if EXECUTORCH_BUILD_PYBIND == \"ON\":\n                print(\"Cannot turnoff pybind option as it is already set.\")\n                sys.exit(1)\n            EXECUTORCH_BUILD_PYBIND = \"OFF\"\n        else:\n            print(f\"Error: {arg} must follow --pybind\")\n            sys.exit(1)\n\n    elif arg == \"--clean\":\n        print(\"Cleaning build artifacts...\")\n        print(\"Cleaning pip-out/...\")\n        shutil.rmtree(\"pip-out/\", ignore_errors=True)\n        dirs = glob.glob(\"cmake-out*/\") + glob.glob(\"cmake-android-out/\")\n        for d in dirs:\n            print(f\"Cleaning {d}...\")\n            shutil.rmtree(d, ignore_errors=True)\n        print(\"Done cleaning build artifacts.\")\n        sys.exit(0)\n    elif arg == \"--use-pt-pinned-commit\":\n        # This option is used in CI to make sure that PyTorch build from the pinned commit\n        # is used instead of nightly. CI jobs wouldn't be able to catch regression from the\n        # latest PT commit otherwise\n        USE_PYTORCH_NIGHTLY = False\n    else:\n        print(f\"Error: Unknown option {arg}\")\n        sys.exit(1)\n\n# If --pybind is not set explicitly for backends (e.g., --pybind xnnpack)\n# or is not turned off explicitly (--pybind off)\n# then install XNNPACK by default.\nif EXECUTORCH_BUILD_PYBIND == \"\":\n    EXECUTORCH_BUILD_PYBIND = \"ON\"\n    CMAKE_ARGS += \" -DEXECUTORCH_BUILD_XNNPACK=ON\"\n\n# Use ClangCL on Windows.\n# ClangCL is an alias to Clang that configures it to work in an MSVC-compatible\n# mode. Using it on Windows to avoid compiler compatibility issues for MSVC.\nif os.name == \"nt\":\n    CMAKE_ARGS += \" -T ClangCL\"\n\n# Since ExecuTorch often uses main-branch features of pytorch, only the nightly\n# pip versions will have the required features.\n#\n# NOTE: If a newly-fetched version of the executorch repo changes the value of\n# NIGHTLY_VERSION, you should re-run this script to install the necessary\n# package versions.\nNIGHTLY_VERSION = \"dev20250104\"\n\n# The pip repository that hosts nightly torch packages.\nTORCH_NIGHTLY_URL = \"https://download.pytorch.org/whl/nightly/cpu\"\n\n# pip packages needed by exir.\nEXIR_REQUIREMENTS = [\n    # Setting USE_PYTORCH_NIGHTLY to false to test the pinned PyTorch commit. Note\n    # that we don't need to set any version number there because they have already\n    # been installed on CI before this step, so pip won't reinstall them\n    f\"torch==2.6.0.{NIGHTLY_VERSION}\" if USE_PYTORCH_NIGHTLY else \"torch\",\n    (\n        f\"torchvision==0.22.0.{NIGHTLY_VERSION}\"\n        if USE_PYTORCH_NIGHTLY\n        else \"torchvision\"\n    ),  # For testing.\n    \"typing-extensions\",\n]\n\n# pip packages needed to run examples.\n# TODO: Make each example publish its own requirements.txt\nEXAMPLES_REQUIREMENTS = [\n    \"timm==1.0.7\",\n    f\"torchaudio==2.6.0.{NIGHTLY_VERSION}\" if USE_PYTORCH_NIGHTLY else \"torchaudio\",\n    \"torchsr==1.0.4\",\n    \"transformers==4.46.1\",\n]\n\n# pip packages needed for development.\nDEVEL_REQUIREMENTS = [\n    \"cmake\",  # For building binary targets.\n    \"pip>=23\",  # For building the pip package.\n    \"pyyaml\",  # Imported by the kernel codegen tools.\n    \"setuptools>=63\",  # For building the pip package.\n    \"tomli\",  # Imported by extract_sources.py when using python < 3.11.\n    \"wheel\",  # For building the pip package archive.\n    \"zstd\",  # Imported by resolve_buck.py.\n]\n\n# Assemble the list of requirements to actually install.\n# TODO: Add options for reducing the number of requirements.\nREQUIREMENTS_TO_INSTALL = EXIR_REQUIREMENTS + DEVEL_REQUIREMENTS + EXAMPLES_REQUIREMENTS\n\n# Install the requirements. `--extra-index-url` tells pip to look for package\n# versions on the provided URL if they aren't available on the default URL.\nsubprocess.run(\n    [\n        sys.executable,\n        \"-m\",\n        \"pip\",\n        \"install\",\n        *REQUIREMENTS_TO_INSTALL,\n        \"--extra-index-url\",\n        TORCH_NIGHTLY_URL,\n    ],\n    check=True,\n)\n\nLOCAL_REQUIREMENTS = [\n    \"third-party/ao\",  # We need the latest kernels for fast iteration, so not relying on pypi.\n]\n\n# Install packages directly from local copy instead of pypi.\n# This is usually not recommended.\nsubprocess.run(\n    [\n        sys.executable,\n        \"-m\",\n        \"pip\",\n        \"install\",\n        *LOCAL_REQUIREMENTS,\n    ],\n    check=True,\n)\n\n#\n# Install executorch pip package. This also makes `flatc` available on the path.\n# The --extra-index-url may be necessary if pyproject.toml has a dependency on a\n# pre-release or nightly version of a torch package.\n#\n\n# Set environment variables\nos.environ[\"EXECUTORCH_BUILD_PYBIND\"] = EXECUTORCH_BUILD_PYBIND\nos.environ[\"CMAKE_ARGS\"] = CMAKE_ARGS\nos.environ[\"CMAKE_BUILD_ARGS\"] = CMAKE_BUILD_ARGS\n\n# Run the pip install command\nsubprocess.run(\n    [\n        sys.executable,\n        \"-m\",\n        \"pip\",\n        \"install\",\n        \".\",\n        \"--no-build-isolation\",\n        \"-v\",\n        \"--extra-index-url\",\n        TORCH_NIGHTLY_URL,\n    ],\n    check=True,\n)\n"
        },
        {
          "name": "install_requirements.sh",
          "type": "blob",
          "size": 0.7255859375,
          "content": "#!/bin/bash\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n# All rights reserved.\n#\n# This source code is licensed under the BSD-style license found in the\n# LICENSE file in the root directory of this source tree.\n\n# Before doing anything, cd to the directory containing this script.\ncd -- \"$( dirname -- \"${BASH_SOURCE[0]}\" )\" &> /dev/null || /bin/true\n\n# Find the names of the python tools to use.\nif [[ -z $PYTHON_EXECUTABLE ]];\nthen\n  if [[ -z $CONDA_DEFAULT_ENV ]] || [[ $CONDA_DEFAULT_ENV == \"base\" ]] || [[ ! -x \"$(command -v python)\" ]];\n  then\n    PYTHON_EXECUTABLE=python3\n  else\n    PYTHON_EXECUTABLE=python\n  fi\nfi\n\n$PYTHON_EXECUTABLE ./install_requirements.py \"$@\"\n\n# Exit with the same status as the python script.\nexit $?\n"
        },
        {
          "name": "kernels",
          "type": "tree",
          "content": null
        },
        {
          "name": "profiler",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 3.39453125,
          "content": "[build-system]\nrequires = [\n  \"cmake\",  # For building binary targets in the wheel.\n  \"pip>=23\",  # For building the pip package.\n  \"pyyaml\",  # Imported by the kernel codegen tools.\n  \"setuptools>=63\",  # For building the pip package contents.\n  \"tomli\",  # Imported by extract_sources.py when using python < 3.11.\n  \"wheel\",  # For building the pip package archive.\n  \"zstd\",  # Imported by resolve_buck.py.\n]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"executorch\"\ndynamic = [\n  # setup.py will set the version.\n  'version',\n]\ndescription = \"On-device AI across mobile, embedded and edge for PyTorch\"\nreadme = \"README-wheel.md\"\nauthors = [\n  {name=\"PyTorch Team\", email=\"packages@pytorch.org\"},\n]\nlicense = {file = \"LICENSE\"}\nkeywords = [\"pytorch\", \"machine learning\"]\n# PyPI package information.\nclassifiers = [\n    # How mature is this project? Common values are\n    #   3 - Alpha\n    #   4 - Beta\n    #   5 - Production/Stable\n    \"Development Status :: 4 - Beta\",\n    \"Intended Audience :: Developers\",\n    \"Intended Audience :: Education\",\n    \"Intended Audience :: Science/Research\",\n    \"License :: OSI Approved :: BSD License\",\n    \"Topic :: Scientific/Engineering\",\n    \"Topic :: Scientific/Engineering :: Mathematics\",\n    \"Topic :: Scientific/Engineering :: Artificial Intelligence\",\n    \"Topic :: Software Development\",\n    \"Topic :: Software Development :: Libraries\",\n    \"Topic :: Software Development :: Libraries :: Python Modules\",\n    \"Programming Language :: C++\",\n    \"Programming Language :: Python :: 3\",\n    # Update this as we support more versions of python.\n    \"Programming Language :: Python :: 3.10\",\n    \"Programming Language :: Python :: 3.11\",\n    \"Programming Language :: Python :: 3.12\",\n]\n\n# Python dependencies required for use.\nrequires-python = \">=3.10\"\ndependencies=[\n  \"expecttest\",\n  \"flatbuffers\",\n  \"hypothesis\",\n  \"mpmath==1.3.0\",\n  \"numpy==1.21.3; python_version == '3.10'\",\n  \"numpy==1.23.2; python_version == '3.11'\",\n  \"numpy; python_version >= '3.12'\",\n  \"packaging\",\n  \"pandas==2.0.3; python_version == '3.10'\",\n  \"pandas; python_version >= '3.11'\",\n  \"parameterized\",\n  \"pytest\",\n  \"pytest-xdist\",\n  \"pyyaml\",\n  \"ruamel.yaml\",\n  \"sympy\",\n  \"tabulate\",\n  \"typing-extensions\",\n]\n\n[project.urls]\n# The keys are arbitrary but will be visible on PyPI.\nHomepage = \"https://pytorch.org/executorch/\"\nRepository = \"https://github.com/pytorch/executorch\"\nIssues = \"https://github.com/pytorch/executorch/issues\"\nChangelog = \"https://github.com/pytorch/executorch/releases\"\n\n# Tell setuptools to generate commandline wrappers for tools that we install\n# under data/bin in the pip package. This will put these commands on the user's\n# path.\n[project.scripts]\nflatc = \"executorch.data.bin:flatc\"\n\n[tool.setuptools.package-data]\n# TODO(dbort): Prune /test[s]/ dirs, /third-party/ dirs, yaml files that we\n# don't need.\n\"*\" = [\n  # Some backends like XNNPACK need their .fbs files.\n  \"*.fbs\",\n  # Some kernel libraries need their .yaml files.\n  \"*.yaml\",\n]\n\n[tool.setuptools.exclude-package-data]\n\"*\" = [\"*.pyc\"]\n\n[tool.usort]\n# Do not try to put \"first-party\" imports in their own section.\nfirst_party_detection = false\n\n[tool.black]\n# Emit syntax compatible with older versions of python instead of only the range\n# specified by `requires-python`. TODO: Remove this once we support these older\n# versions of python and can expand the `requires-python` range.\ntarget-version = [\"py38\", \"py39\", \"py310\", \"py311\", \"py312\"]\n"
        },
        {
          "name": "pytest.ini",
          "type": "blob",
          "size": 2.9716796875,
          "content": "[pytest]\naddopts =\n    # show summary of all tests that did not pass\n    -rEfX\n    # Make tracebacks shorter\n    --tb=native\n    # capture only Python print and C++ py::print, but not C output (low-level Python errors)\n    --capture=sys\n    # don't suppress warnings, but don't shove them all to the end either\n    -p no:warnings\n    # Ignore backends/arm tests you need to run examples/arm/setup.sh to install some tool to make them work\n    # For GitHub testing this is setup/executed in the unittest-arm job see .github/workflows/pull.yml for more info.\n    --ignore-glob=backends/arm/**/*\n    # explicitly list out tests that are running successfully in oss\n    examples/models/test\n    devtools/\n    # examples\n    examples/models/llama/tests\n    examples/models/llama3_2_vision/preprocess\n    examples/models/llama3_2_vision/vision_encoder/test\n    examples/models/llama3_2_vision/text_decoder/test\n    # examples/models/llava/test TODO: enable this\n    # exir\n    exir/_serialize/test\n    exir/backend/test\n    exir/dialects/backend/test\n    exir/dialects/edge/test\n    exir/dialects/test\n    exir/emit/test\n    exir/program/test\n    exir/tests/\n    # kernels/\n    kernels/prim_ops/test\n    kernels/quantized\n    # Because this test depends on test only cpp ops lib\n    # Will add test only cmake targets to re-enable this test\n    # but maybe it is a bit of anti-pattern\n    --ignore=kernels/quantized/test/test_quant_dequant_per_token.py\n    kernels/test/test_case_gen.py\n    # backends/xnnpack\n    backends/xnnpack/test/ops\n    --ignore=backends/xnnpack/test/ops/test_bmm.py\n    --ignore=backends/xnnpack/test/ops/test_conv2d.py\n    --ignore=backends/xnnpack/test/ops/test_linear.py\n    --ignore=backends/xnnpack/test/ops/test_sdpa.py\n    backends/xnnpack/test/passes\n    backends/xnnpack/test/serialization\n    # extension/\n    extension/llm/modules/test\n    extension/pybindings/test\n    # Runtime\n    runtime\n    # test TODO: fix these tests\n    # test/end2end/test_end2end.py\n    --ignore=backends/xnnpack/test/ops/linear.py\n    --ignore=backends/xnnpack/test/models/llama2_et_example.py\n    # T200992559: Add torchao to ET as core dependency\n    --ignore=examples/models/llama/tests/test_pre_quantization_transforms.py\n    --ignore=exir/backend/test/demos\n    --ignore=exir/backend/test/test_backends.py\n    --ignore=exir/backend/test/test_backends_lifted.py\n    --ignore=exir/backend/test/test_compatibility.py\n    --ignore=exir/backend/test/test_lowered_backend_module.py\n    --ignore=exir/backend/test/test_partitioner.py\n    --ignore=exir/tests/test_common.py\n    --ignore=exir/tests/test_memory_format_ops_pass_aten.py\n    --ignore=exir/tests/test_memory_planning.py\n    --ignore=exir/tests/test_op_convert.py\n    --ignore=exir/tests/test_passes.py\n    --ignore=exir/tests/test_quant_fusion_pass.py\n    --ignore=exir/tests/test_quantization.py\n    --ignore=exir/tests/test_verification.py\n\n# run the same tests multiple times to determine their\n# flakiness status. Default to 50 re-runs\nflake-finder = true\nflake-runs = 50\n"
        },
        {
          "name": "requirements-lintrunner.txt",
          "type": "blob",
          "size": 0.3798828125,
          "content": "# Lintrunner itself\nlintrunner==0.12.7\nlintrunner-adapters==0.12.4\n\n# Flake 8 and its dependencies\nflake8==6.1.0\nflake8-breakpoint==1.1.0\nflake8-bugbear==24.4.26\nflake8-comprehensions==3.14.0\nflake8-pyi==23.5.0\nmccabe==0.7.0\npycodestyle==2.11.1\ntorchfix==0.6.0\n\n# UFMT\nblack==24.4.2\nufmt==2.8.0\nusort==1.0.8.post1\n\n# Other linters\nclang-format==18.1.3\ncmakelint==1.4.1\n\n# MyPy\nmypy==1.14.1"
        },
        {
          "name": "runtime",
          "type": "tree",
          "content": null
        },
        {
          "name": "schema",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 30.1171875,
          "content": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n# Copyright 2024 Arm Limited and/or its affiliates.\n# All rights reserved.\n#\n# This source code is licensed under the BSD-style license found in the\n# LICENSE file in the root directory of this source tree.\n\n# Part of this code is from pybind11 cmake_example:\n# https://github.com/pybind/cmake_example/blob/master/setup.py so attach the\n# license below.\n\n# Copyright (c) 2016 The Pybind Development Team, All rights reserved.\n#\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n#\n# 1. Redistributions of source code must retain the above copyright notice, this\n#    list of conditions and the following disclaimer.\n#\n# 2. Redistributions in binary form must reproduce the above copyright notice,\n#    this list of conditions and the following disclaimer in the documentation\n#    and/or other materials provided with the distribution.\n#\n# 3. Neither the name of the copyright holder nor the names of its contributors\n#    may be used to endorse or promote products derived from this software\n#    without specific prior written permission.\n#\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\n# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n#\n# You are under no obligation whatsoever to provide any bug fixes, patches, or\n# upgrades to the features, functionality or performance of the source code\n# (\"Enhancements\") to anyone; however, if you choose to make your Enhancements\n# available either publicly, or directly to the author of this software, without\n# imposing a separate written license agreement for such Enhancements, then you\n# hereby grant the following license: a non-exclusive, royalty-free perpetual\n# license to install, use, modify, prepare derivative works, incorporate into\n# other computer software, distribute, and sublicense such enhancements or\n# derivative works thereof, in binary and source code form.\n\nimport contextlib\nimport os\nimport platform\nimport re\nimport sys\n\n# Import this before distutils so that setuptools can intercept the distuils\n# imports.\nimport setuptools  # noqa: F401 # usort: skip\n\nfrom distutils import log\nfrom distutils.sysconfig import get_python_lib\nfrom pathlib import Path\nfrom typing import List, Optional\n\nfrom setuptools import Extension, setup\nfrom setuptools.command.build import build\nfrom setuptools.command.build_ext import build_ext\nfrom setuptools.command.build_py import build_py\n\n# For information on setuptools Command subclassing see\n# https://setuptools.pypa.io/en/latest/userguide/extension.html\n\n\nclass ShouldBuild:\n    \"\"\"Indicates whether to build various components.\"\"\"\n\n    @staticmethod\n    def _is_env_enabled(env_var: str, default: bool = False) -> bool:\n        val = os.environ.get(env_var, None)\n        if val is None:\n            return default\n        if val in (\"OFF\", \"0\", \"\"):\n            return False\n        return True\n\n    @classmethod\n    def pybindings(cls) -> bool:\n        return cls._is_env_enabled(\"EXECUTORCH_BUILD_PYBIND\", default=False)\n\n    @classmethod\n    def llama_custom_ops(cls) -> bool:\n        return cls._is_env_enabled(\"EXECUTORCH_BUILD_KERNELS_CUSTOM_AOT\", default=True)\n\n    @classmethod\n    def flatc(cls) -> bool:\n        return cls._is_env_enabled(\"EXECUTORCH_BUILD_FLATC\", default=True)\n\n\nclass Version:\n    \"\"\"Static strings that describe the version of the pip package.\"\"\"\n\n    # Cached values returned by the properties.\n    __root_dir_attr: Optional[str] = None\n    __string_attr: Optional[str] = None\n    __git_hash_attr: Optional[str] = None\n\n    @classmethod\n    def _root_dir(cls) -> str:\n        \"\"\"The path to the root of the git repo.\"\"\"\n        if cls.__root_dir_attr is None:\n            # This setup.py file lives in the root of the repo.\n            cls.__root_dir_attr = str(Path(__file__).parent.resolve())\n        return str(cls.__root_dir_attr)\n\n    @classmethod\n    def git_hash(cls) -> Optional[str]:\n        \"\"\"The current git hash, if known.\"\"\"\n        if cls.__git_hash_attr is None:\n            import subprocess\n\n            try:\n                cls.__git_hash_attr = (\n                    subprocess.check_output(\n                        [\"git\", \"rev-parse\", \"HEAD\"], cwd=cls._root_dir()\n                    )\n                    .decode(\"ascii\")\n                    .strip()\n                )\n            except subprocess.CalledProcessError:\n                cls.__git_hash_attr = \"\"  # Non-None but empty.\n        # A non-None but empty value indicates that we don't know it.\n        return cls.__git_hash_attr if cls.__git_hash_attr else None\n\n    @classmethod\n    def string(cls) -> str:\n        \"\"\"The version string.\"\"\"\n        if cls.__string_attr is None:\n            # If set, BUILD_VERSION should override any local version\n            # information. CI will use this to manage, e.g., release vs. nightly\n            # versions.\n            version = os.getenv(\"BUILD_VERSION\", \"\").strip()\n            if not version:\n                # Otherwise, read the version from a local file and add the git\n                # commit if available.\n                version = (\n                    open(os.path.join(cls._root_dir(), \"version.txt\")).read().strip()\n                )\n                if cls.git_hash():\n                    version += \"+\" + cls.git_hash()[:7]  # type: ignore[index]\n            cls.__string_attr = version\n        return cls.__string_attr\n\n    @classmethod\n    def write_to_python_file(cls, path: str) -> None:\n        \"\"\"Creates a file similar to PyTorch core's `torch/version.py`.\"\"\"\n        lines = [\n            \"from typing import Optional\",\n            '__all__ = [\"__version__\", \"git_version\"]',\n            f'__version__ = \"{cls.string()}\"',\n            # A string or None.\n            f\"git_version: Optional[str] = {repr(cls.git_hash())}\",\n        ]\n        with open(path, \"w\") as fp:\n            fp.write(\"\\n\".join(lines) + \"\\n\")\n\n\n# The build type is determined by the DEBUG environment variable. If DEBUG is\n# set to a non-empty value, the build type is Debug. Otherwise, the build type\n# is Release.\ndef get_build_type(is_debug=None) -> str:\n    debug = int(os.environ.get(\"DEBUG\", 0)) if is_debug is None else is_debug\n    cfg = \"Debug\" if debug else \"Release\"\n    return cfg\n\n\ndef get_dynamic_lib_name(name: str) -> str:\n    if platform.system() == \"Windows\":\n        return name + \".dll\"\n    elif platform.system() == \"Darwin\":\n        return \"lib\" + name + \".dylib\"\n    else:\n        return \"lib\" + name + \".so\"\n\n\ndef get_executable_name(name: str) -> str:\n    if platform.system() == \"Windows\":\n        return name + \".exe\"\n    else:\n        return name\n\n\nclass _BaseExtension(Extension):\n    \"\"\"A base class that maps an abstract source to an abstract destination.\"\"\"\n\n    def __init__(self, src: str, dst: str, name: str):\n        # Source path; semantics defined by the subclass.\n        self.src: str = src\n\n        # Destination path relative to a namespace defined elsewhere. If this ends\n        # in \"/\", it is treated as a directory. If this is \"\", it is treated as the\n        # root of the namespace.\n        # Destination path; semantics defined by the subclass.\n        self.dst: str = dst\n\n        # Other parts of setuptools expects .name to exist. For actual extensions\n        # this can be the module path, but otherwise it should be somehing unique\n        # that doesn't look like a module path.\n        self.name: str = name\n\n        super().__init__(name=self.name, sources=[])\n\n    def src_path(self, installer: \"InstallerBuildExt\") -> Path:\n        \"\"\"Returns the path to the source file, resolving globs.\n\n        Args:\n            installer: The InstallerBuildExt instance that is installing the\n                file.\n        \"\"\"\n        # Share the cmake-out location with CustomBuild.\n        build_cmd = installer.get_finalized_command(\"build\")\n        if hasattr(build_cmd, \"cmake_cache_dir\"):\n            cmake_cache_dir = Path(build_cmd.cmake_cache_dir)\n        else:\n            # If we're in editable mode, use a default or fallback value for cmake_cache_dir\n            # This could be a hardcoded path, or a path derived from the current working directory\n            cmake_cache_dir = Path(\".\")\n        cfg = get_build_type(installer.debug)\n\n        if os.name == \"nt\":\n            # Replace %BUILD_TYPE% with the current build type.\n            self.src = self.src.replace(\"%BUILD_TYPE%\", cfg)\n        else:\n            # Remove %BUILD_TYPE% from the path.\n            self.src = self.src.replace(\"/%BUILD_TYPE%\", \"\")\n\n        # Construct the full source path, resolving globs. If there are no glob\n        # pattern characters, this will just ensure that the source file exists.\n        srcs = tuple(cmake_cache_dir.glob(self.src))\n        if len(srcs) != 1:\n            raise ValueError(\n                f\"\"\"Expected exactly one file matching '{self.src}'; found {repr(srcs)}. \n\nIf that file is a CMake-built extension module file, and we are installing in editable mode, please disable the corresponding build option since it's not supported yet.\n\nTry: \n\nEXECUTORCH_BUILD_FLATC=OFF EXECUTORCH_BUILD_KERNELS_CUSTOM_AOT=OFF pip install -e .\n\"\"\"\n            )\n        return srcs[0]\n\n\nclass BuiltFile(_BaseExtension):\n    \"\"\"An extension that installs a single file that was built by cmake.\n\n    This isn't technically a `build_ext` style python extension, but there's no\n    dedicated command for installing arbitrary data. It's convenient to use\n    this, though, because it lets us manage the files to install as entries in\n    `ext_modules`.\n    \"\"\"\n\n    def __init__(\n        self,\n        src_dir: str,\n        src_name: str,\n        dst: str,\n        is_executable: bool = False,\n        is_dynamic_lib: bool = False,\n    ):\n        \"\"\"Initializes a BuiltFile.\n\n        Args:\n            src_dir: The directory of the file to install, relative to the cmake-out\n                directory. A placeholder %BUILD_TYPE% will be replaced with the build\n                type for multi-config generators (like Visual Studio) where the build\n                output is in a subdirectory named after the build type. For single-\n                config generators (like Makefile Generators or Ninja), this placeholder\n                will be removed.\n            src_name: The name of the file to install\n            dst: The path to install to, relative to the root of the pip\n                package. If dst ends in \"/\", it is treated as a directory.\n                Otherwise it is treated as a filename.\n            is_executable: If True, the file is an executable. This is used to\n                determine the destination filename for executable.\n            is_dynamic_lib: If True, the file is a dynamic library. This is used\n                to determine the destination filename for dynamic library.\n        \"\"\"\n        if is_executable and is_dynamic_lib:\n            raise ValueError(\"is_executable and is_dynamic_lib cannot be both True.\")\n        if is_executable:\n            src_name = get_executable_name(src_name)\n        elif is_dynamic_lib:\n            src_name = get_dynamic_lib_name(src_name)\n        src = os.path.join(src_dir, src_name)\n        # This is not a real extension, so use a unique name that doesn't look\n        # like a module path. Some of setuptools's autodiscovery will look for\n        # extension names with prefixes that match certain module paths.\n        super().__init__(src=src, dst=dst, name=f\"@EXECUTORCH_BuiltFile_{src}:{dst}\")\n\n    def dst_path(self, installer: \"InstallerBuildExt\") -> Path:\n        \"\"\"Returns the path to the destination file.\n\n        Args:\n            installer: The InstallerBuildExt instance that is installing the\n                file.\n        \"\"\"\n        dst_root = Path(installer.build_lib).resolve()\n\n        if self.dst.endswith(\"/\"):\n            # Destination looks like a directory. Use the basename of the source\n            # file for its final component.\n            return dst_root / Path(self.dst) / self.src_path(installer).name\n        else:\n            # Destination looks like a file.\n            return dst_root / Path(self.dst)\n\n\nclass BuiltExtension(_BaseExtension):\n    \"\"\"An extension that installs a python extension that was built by cmake.\"\"\"\n\n    def __init__(self, src: str, modpath: str):\n        \"\"\"Initializes a BuiltExtension.\n\n        Args:\n            src: The path to the file to install (typically a shared library),\n                relative to the cmake-out directory. May be an fnmatch-style\n                glob that matches exactly one file. If the path ends in `.so`,\n                this class will also look for similarly-named `.dylib` files.\n            modpath: The dotted path of the python module that maps to the\n                extension.\n        \"\"\"\n        assert (\n            \"/\" not in modpath\n        ), f\"modpath must be a dotted python module path: saw '{modpath}'\"\n        # This is a real extension, so use the modpath as the name.\n        super().__init__(src=src, dst=modpath, name=modpath)\n\n    def src_path(self, installer: \"InstallerBuildExt\") -> Path:\n        \"\"\"Returns the path to the source file, resolving globs.\n\n        Args:\n            installer: The InstallerBuildExt instance that is installing the\n                file.\n        \"\"\"\n        try:\n            return super().src_path(installer)\n        except ValueError:\n            # Probably couldn't find the file. If the path ends with .so, try\n            # looking for a .dylib file instead, in case we're running on macos.\n            if self.src.endswith(\".so\"):\n                dylib_src = re.sub(r\"\\.so$\", \".dylib\", self.src)\n                return BuiltExtension(src=dylib_src, modpath=self.dst).src_path(\n                    installer\n                )\n            else:\n                raise\n\n    def dst_path(self, installer: \"InstallerBuildExt\") -> Path:\n        \"\"\"Returns the path to the destination file.\n\n        Args:\n            installer: The InstallerBuildExt instance that is installing the\n                file.\n        \"\"\"\n        # Our destination is a dotted module path. get_ext_fullpath() returns\n        # the relative path to the .so/.dylib/etc. file that maps to the module\n        # path: that's the file we're creating.\n        return Path(installer.get_ext_fullpath(self.dst))\n\n\nclass InstallerBuildExt(build_ext):\n    \"\"\"Installs files that were built by cmake.\"\"\"\n\n    # TODO(dbort): Depend on the \"build\" command to ensure it runs first\n\n    def build_extension(self, ext: _BaseExtension) -> None:\n        src_file: Path = ext.src_path(self)\n        dst_file: Path = ext.dst_path(self)\n\n        # Ensure that the destination directory exists.\n        self.mkpath(os.fspath(dst_file.parent))\n\n        # Copy the file.\n        self.copy_file(os.fspath(src_file), os.fspath(dst_file))\n\n        # Ensure that the destination file is writable, even if the source was\n        # not. build_py does this by passing preserve_mode=False to copy_file,\n        # but that would clobber the X bit on any executables. TODO(dbort): This\n        # probably won't work on Windows.\n        if not os.access(src_file, os.W_OK):\n            # Make the file writable. This should respect the umask.\n            os.chmod(src_file, os.stat(src_file).st_mode | 0o222)\n\n\nclass CustomBuildPy(build_py):\n    \"\"\"Copies platform-independent files from the source tree into the output\n    package directory.\n\n    Override it so we can copy some files to locations that don't match their\n    original relative locations.\n\n    Standard setuptools features like package_data and MANIFEST.in can only\n    include or exclude a file in the source tree; they don't have a way to map\n    a file to a different relative location under the output package directory.\n    \"\"\"\n\n    def run(self):\n        # Copy python files to the output directory. This set of files is\n        # defined by the py_module list and package_data patterns.\n        build_py.run(self)\n\n        # dst_root is the root of the `executorch` module in the output package\n        # directory. build_lib is the platform-independent root of the output\n        # package, and will look like `pip-out/lib`. It can contain multiple\n        # python packages, so be sure to copy the files into the `executorch`\n        # package subdirectory.\n        if self.editable_mode:\n            # In editable mode, the package directory is the original source directory\n            dst_root = self.get_package_dir(\".\")\n        else:\n            dst_root = os.path.join(self.build_lib, self.get_package_dir(\"executorch\"))\n\n        # Create the version file.\n        Version.write_to_python_file(os.path.join(dst_root, \"version.py\"))\n\n        # Manually copy files into the output package directory. These are\n        # typically python \"resource\" files that will live alongside the python\n        # code that uses them.\n        src_to_dst = [\n            # TODO(dbort): See if we can add a custom pyproject.toml section for\n            # these, instead of hard-coding them here. See\n            # https://setuptools.pypa.io/en/latest/userguide/extension.html\n            (\"schema/scalar_type.fbs\", \"exir/_serialize/scalar_type.fbs\"),\n            (\"schema/program.fbs\", \"exir/_serialize/program.fbs\"),\n            (\n                \"devtools/bundled_program/schema/bundled_program_schema.fbs\",\n                \"devtools/bundled_program/serialize/bundled_program_schema.fbs\",\n            ),\n            (\n                \"devtools/bundled_program/schema/scalar_type.fbs\",\n                \"devtools/bundled_program/serialize/scalar_type.fbs\",\n            ),\n            # Install executorch-wheel-config.cmake to pip package.\n            (\n                \"build/executorch-wheel-config.cmake\",\n                \"share/cmake/executorch-config.cmake\",\n            ),\n        ]\n        # Copy all the necessary headers into include/executorch/ so that they can\n        # be found in the pip package. This is the subset of headers that are\n        # essential for building custom ops extensions.\n        # TODO: Use cmake to gather the headers instead of hard-coding them here.\n        # For example: https://discourse.cmake.org/t/installing-headers-the-modern-\n        # way-regurgitated-and-revisited/3238/3\n        for include_dir in [\n            \"runtime/core/\",\n            \"runtime/kernel/\",\n            \"runtime/platform/\",\n            \"extension/kernel_util/\",\n            \"extension/tensor/\",\n            \"extension/threadpool/\",\n        ]:\n            src_list = Path(include_dir).rglob(\"*.h\")\n            for src in src_list:\n                src_to_dst.append(\n                    (str(src), os.path.join(\"include/executorch\", str(src)))\n                )\n        for src, dst in src_to_dst:\n            dst = os.path.join(dst_root, dst)\n\n            # When modifying the filesystem, use the self.* methods defined by\n            # Command to benefit from the same logging and dry_run logic as\n            # setuptools.\n\n            # Ensure that the destination directory exists.\n            self.mkpath(os.path.dirname(dst))\n            # Follow the example of the base build_py class by not preserving\n            # the mode. This ensures that the output file is read/write even if\n            # the input file is read-only.\n            self.copy_file(src, dst, preserve_mode=False)\n\n\nclass Buck2EnvironmentFixer(contextlib.AbstractContextManager):\n    \"\"\"Removes HOME from the environment when running as root.\n\n    This script is sometimes run as root in docker containers. buck2 doesn't\n    allow running as root unless $HOME is owned by root or is not set.\n\n    TODO(pytorch/test-infra#5091): Remove this once the CI jobs stop running as\n    root.\n    \"\"\"\n\n    def __init__(self):\n        self.saved_env = {}\n\n    def __enter__(self):\n        if os.name != \"nt\" and os.geteuid() == 0 and \"HOME\" in os.environ:\n            log.info(\"temporarily unsetting HOME while running as root\")\n            self.saved_env[\"HOME\"] = os.environ.pop(\"HOME\")\n        return self\n\n    def __exit__(self, *args, **kwargs):\n        if \"HOME\" in self.saved_env:\n            log.info(\"restored HOME\")\n            os.environ[\"HOME\"] = self.saved_env[\"HOME\"]\n\n\n# TODO(dbort): For editable wheels, may need to update get_source_files(),\n# get_outputs(), and get_output_mapping() to satisfy\n# https://setuptools.pypa.io/en/latest/userguide/extension.html#setuptools.command.build.SubCommand.get_output_mapping\n\n\nclass CustomBuild(build):\n    def initialize_options(self):\n        super().initialize_options()\n        # The default build_base directory is called \"build\", but we have a\n        # top-level directory with that name. Setting build_base in setup()\n        # doesn't affect this, so override the core build command.\n        #\n        # See build.initialize_options() in\n        # setuptools/_distutils/command/build.py for the default.\n        self.build_base = \"pip-out\"\n\n        # Default build parallelism based on number of cores, but allow\n        # overriding through the environment.\n        default_parallel = str(os.cpu_count() - 1)\n        self.parallel = os.environ.get(\"CMAKE_BUILD_PARALLEL_LEVEL\", default_parallel)\n\n    def run(self):\n        self.dump_options()\n\n        cfg = get_build_type(self.debug)\n\n        # get_python_lib() typically returns the path to site-packages, where\n        # all pip packages in the environment are installed.\n        cmake_prefix_path = os.environ.get(\"CMAKE_PREFIX_PATH\", get_python_lib())\n\n        # The root of the repo should be the current working directory. Get\n        # the absolute path.\n        repo_root = os.fspath(Path.cwd())\n\n        # If blank, the cmake build system will find an appropriate binary.\n        buck2 = os.environ.get(\n            \"BUCK2_EXECUTABLE\", os.environ.get(\"BUCK2\", os.environ.get(\"BUCK\", \"\"))\n        )\n\n        cmake_args = [\n            f\"-DBUCK2={buck2}\",\n            f\"-DPYTHON_EXECUTABLE={sys.executable}\",\n            # Let cmake calls like `find_package(Torch)` find cmake config files\n            # like `TorchConfig.cmake` that are provided by pip packages.\n            f\"-DCMAKE_PREFIX_PATH={cmake_prefix_path}\",\n            f\"-DCMAKE_BUILD_TYPE={cfg}\",\n            # Enable logging even when in release mode. We are building for\n            # desktop, where saving a few kB is less important than showing\n            # useful error information to users.\n            \"-DEXECUTORCH_ENABLE_LOGGING=ON\",\n            \"-DEXECUTORCH_LOG_LEVEL=Info\",\n            \"-DCMAKE_OSX_DEPLOYMENT_TARGET=10.15\",\n            # The separate host project is only required when cross-compiling,\n            # and it can cause build race conditions (libflatcc.a errors) when\n            # enabled. TODO(dbort): Remove this override once this option is\n            # managed by cmake itself.\n            \"-DEXECUTORCH_SEPARATE_FLATCC_HOST_PROJECT=OFF\",\n        ]\n\n        build_args = [f\"-j{self.parallel}\"]\n\n        # TODO(dbort): Try to manage these targets and the cmake args from the\n        # extension entries themselves instead of hard-coding them here.\n        build_args += [\"--target\", \"flatc\"]\n\n        if ShouldBuild.pybindings():\n            cmake_args += [\n                \"-DEXECUTORCH_BUILD_PYBIND=ON\",\n                \"-DEXECUTORCH_BUILD_KERNELS_QUANTIZED=ON\",  # add quantized ops to pybindings.\n                \"-DEXECUTORCH_BUILD_KERNELS_QUANTIZED_AOT=ON\",\n            ]\n            build_args += [\"--target\", \"portable_lib\"]\n            # To link backends into the portable_lib target, callers should\n            # add entries like `-DEXECUTORCH_BUILD_XNNPACK=ON` to the CMAKE_ARGS\n            # environment variable.\n\n        if ShouldBuild.llama_custom_ops():\n            cmake_args += [\n                \"-DEXECUTORCH_BUILD_KERNELS_CUSTOM=ON\",  # add llama sdpa ops to pybindings.\n                \"-DEXECUTORCH_BUILD_KERNELS_CUSTOM_AOT=ON\",\n                \"-DEXECUTORCH_BUILD_KERNELS_QUANTIZED=ON\",  # add quantized ops to pybindings.\n                \"-DEXECUTORCH_BUILD_KERNELS_QUANTIZED_AOT=ON\",\n            ]\n            build_args += [\"--target\", \"custom_ops_aot_lib\"]\n            build_args += [\"--target\", \"quantized_ops_aot_lib\"]\n        # Allow adding extra cmake args through the environment. Used by some\n        # tests and demos to expand the set of targets included in the pip\n        # package.\n        if \"CMAKE_ARGS\" in os.environ:\n            cmake_args += [item for item in os.environ[\"CMAKE_ARGS\"].split(\" \") if item]\n\n        # Allow adding extra build args through the environment. Used by some\n        # tests and demos to expand the set of targets included in the pip\n        # package.\n        if \"CMAKE_BUILD_ARGS\" in os.environ:\n            build_args += [\n                item for item in os.environ[\"CMAKE_BUILD_ARGS\"].split(\" \") if item\n            ]\n\n        # CMAKE_BUILD_TYPE variable specifies the build type (configuration) for\n        # single-configuration generators (e.g., Makefile Generators or Ninja).\n        # For multi-config generators (like Visual Studio), CMAKE_BUILD_TYPE\n        # isnt directly applicable.\n        # During the build step, --config specifies the configuration to build\n        # for multi-config generators.\n        build_args += [\"--config\", cfg]\n\n        # Put the cmake cache under the temp directory, like\n        # \"pip-out/temp.<plat>/cmake-out\".\n        cmake_cache_dir = os.path.join(repo_root, self.build_temp, \"cmake-out\")\n        self.mkpath(cmake_cache_dir)\n\n        # Generate the cmake cache from scratch to ensure that the cache state\n        # is predictable.\n        cmake_cache_file = Path(cmake_cache_dir) / \"CMakeCache.txt\"\n        log.info(f\"deleting {cmake_cache_file}\")\n        if not self.dry_run:\n            # Dry run should log the command but not actually run it.\n            (Path(cmake_cache_dir) / \"CMakeCache.txt\").unlink(missing_ok=True)\n        with Buck2EnvironmentFixer():\n            # The context manager may patch the environment while running this\n            # cmake command, which happens to run buck2 to get some source\n            # lists.\n\n            # Generate the build system files.\n            self.spawn([\"cmake\", \"-S\", repo_root, \"-B\", cmake_cache_dir, *cmake_args])\n\n        # Build the system.\n        self.spawn([\"cmake\", \"--build\", cmake_cache_dir, *build_args])\n\n        # Non-python files should live under this data directory.\n        data_root = os.path.join(self.build_lib, \"executorch\", \"data\")\n\n        # Directories like bin/ and lib/ live under data/.\n        bin_dir = os.path.join(data_root, \"bin\")\n\n        # Copy the bin wrapper so that users can run any executables under\n        # data/bin, as long as they are listed in the [project.scripts] section\n        # of pyproject.toml.\n        self.mkpath(bin_dir)\n        self.copy_file(\n            \"build/pip_data_bin_init.py.in\",\n            os.path.join(bin_dir, \"__init__.py\"),\n        )\n        # Share the cmake-out location with _BaseExtension.\n        self.cmake_cache_dir = cmake_cache_dir\n\n        # Finally, run the underlying subcommands like build_py, build_ext.\n        build.run(self)\n\n\ndef get_ext_modules() -> List[Extension]:\n    \"\"\"Returns the set of extension modules to build.\"\"\"\n    ext_modules = []\n    if ShouldBuild.flatc():\n        ext_modules.append(\n            BuiltFile(\n                src_dir=\"third-party/flatbuffers/%BUILD_TYPE%/\",\n                src_name=\"flatc\",\n                dst=\"executorch/data/bin/\",\n                is_executable=True,\n            )\n        )\n\n    if ShouldBuild.pybindings():\n        ext_modules.append(\n            # Install the prebuilt pybindings extension wrapper for the runtime,\n            # portable kernels, and a selection of backends. This lets users\n            # load and execute .pte files from python.\n            BuiltExtension(\n                \"_portable_lib.*\", \"executorch.extension.pybindings._portable_lib\"\n            )\n        )\n    if ShouldBuild.llama_custom_ops():\n        ext_modules.append(\n            BuiltFile(\n                src_dir=\"extension/llm/custom_ops/%BUILD_TYPE%/\",\n                src_name=\"custom_ops_aot_lib\",\n                dst=\"executorch/extension/llm/custom_ops\",\n                is_dynamic_lib=True,\n            )\n        )\n        ext_modules.append(\n            # Install the prebuilt library for quantized ops required by custom ops.\n            BuiltFile(\n                src_dir=\"kernels/quantized/%BUILD_TYPE%/\",\n                src_name=\"quantized_ops_aot_lib\",\n                dst=\"executorch/kernels/quantized/\",\n                is_dynamic_lib=True,\n            )\n        )\n\n    # Note that setuptools uses the presence of ext_modules as the main signal\n    # that a wheel is platform-specific. If we install any platform-specific\n    # files, this list must be non-empty. Therefore, we should always install\n    # platform-specific files using InstallerBuildExt.\n    return ext_modules\n\n\nsetup(\n    version=Version.string(),\n    # TODO(dbort): Could use py_modules to restrict the set of modules we\n    # package, and package_data to restrict the set up non-python files we\n    # include. See also setuptools/discovery.py for custom finders.\n    package_dir={\n        \"executorch/backends\": \"backends\",\n        \"executorch/codegen\": \"codegen\",\n        # TODO(mnachin T180504136): Do not put examples/models\n        # into core pip packages. Refactor out the necessary utils\n        # or core models files into a separate package.\n        \"executorch/examples/models\": \"examples/models\",\n        \"executorch/exir\": \"exir\",\n        \"executorch/extension\": \"extension\",\n        \"executorch/kernels/quantized\": \"kernels/quantized\",\n        \"executorch/schema\": \"schema\",\n        \"executorch/devtools\": \"devtools\",\n        \"executorch/devtools/bundled_program\": \"devtools/bundled_program\",\n        \"executorch/runtime\": \"runtime\",\n        \"executorch/util\": \"util\",\n    },\n    cmdclass={\n        \"build\": CustomBuild,\n        \"build_ext\": InstallerBuildExt,\n        \"build_py\": CustomBuildPy,\n    },\n    ext_modules=get_ext_modules(),\n)\n"
        },
        {
          "name": "shim",
          "type": "tree",
          "content": null
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "third-party",
          "type": "tree",
          "content": null
        },
        {
          "name": "util",
          "type": "tree",
          "content": null
        },
        {
          "name": "version.txt",
          "type": "blob",
          "size": 0.0078125,
          "content": "0.5.0a0\n"
        }
      ]
    }
  ]
}